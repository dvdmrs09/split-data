{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output(self, name='',dest=''):\n        \"Output PDF to some destination\"\n        #Finish document if necessary\n        if(self.state<3):\n            self.close()\n        dest=dest.upper()\n        if(dest==''):\n            if(name==''):\n                name='doc.pdf'\n                dest='I'\n            else:\n                dest='F'\n        if dest=='I':\n            print(self.buffer)\n        elif dest=='D':\n            print(self.buffer)\n        elif dest=='F':\n            #Save to local file\n            f=open(name,'wb')\n            if(not f):\n                self.error('Unable to create output file: '+name)\n            if PY3K:\n                # manage binary data as latin1 until PEP461 or similar is implemented\n                f.write(self.buffer.encode(\"latin1\"))\n            else:\n                f.write(self.buffer)\n            f.close()\n        elif dest=='S':\n            #Return as a string\n            return self.buffer\n        else:\n            self.error('Incorrect output destination: '+dest)\n        return ''", "response": "Output PDF to some destination"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_text(self, txt):\n        \"Check that text input is in the correct format/encoding\"\n        # - for TTF unicode fonts: unicode object (utf8 encoding)\n        # - for built-in fonts: string instances (latin 1 encoding)\n        if self.unifontsubset and isinstance(txt, str) and not PY3K:\n            txt = txt.decode('utf8')\n        elif not self.unifontsubset and isinstance(txt, unicode) and not PY3K:\n            txt = txt.encode('latin1')\n        return txt", "response": "Check that text input is in the correct format / encoding"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef interleaved2of5(self, txt, x, y, w=1.0, h=10.0):\n        \"Barcode I2of5 (numeric), adds a 0 if odd lenght\"\n        narrow = w / 3.0\n        wide = w\n\n        # wide/narrow codes for the digits\n        bar_char={'0': 'nnwwn', '1': 'wnnnw', '2': 'nwnnw', '3': 'wwnnn',\n                  '4': 'nnwnw', '5': 'wnwnn', '6': 'nwwnn', '7': 'nnnww',\n                  '8': 'wnnwn', '9': 'nwnwn', 'A': 'nn', 'Z': 'wn'}\n\n        self.set_fill_color(0)\n        code = txt\n        # add leading zero if code-length is odd\n        if len(code) % 2 != 0:\n            code = '0' + code\n\n        # add start and stop codes\n        code = 'AA' + code.lower() + 'ZA'\n\n        for i in range(0, len(code), 2):\n            # choose next pair of digits\n            char_bar = code[i]\n            char_space = code[i+1]\n            # check whether it is a valid digit\n            if not char_bar in bar_char.keys():\n                raise RuntimeError ('Char \"%s\" invalid for I25: ' % char_bar)\n            if not char_space in bar_char.keys():\n                raise RuntimeError ('Char \"%s\" invalid for I25: ' % char_space)\n\n            # create a wide/narrow-seq (first digit=bars, second digit=spaces)\n            seq = ''\n            for s in range(0, len(bar_char[char_bar])):\n                seq += bar_char[char_bar][s] + bar_char[char_space][s]\n\n            for bar in range(0, len(seq)):\n                # set line_width depending on value\n                if seq[bar] == 'n':\n                    line_width = narrow\n                else:\n                    line_width = wide\n\n                # draw every second value, the other is represented by space\n                if bar % 2 == 0:\n                    self.rect(x, y, line_width, h, 'F')\n\n                x += line_width", "response": "Barcode I2of5 ( numeric ) adds a 0 if odd lenght"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef jsonp_loader(url, prefix_regex=r'^(.*\\()', suffix_regex=r'(\\);)$', sub_d=None, sub_by=''):\n    \n    hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.77 Safari/535.7'}\n    req = urllib.request.Request(url, headers=hdr)\n    page = urlopen(req)\n    result = page.read().decode(\"utf-8\")\n    # replace all the redundant info with sub_by \n    if sub_d:\n        result = re.sub(sub_d, sub_by, result)\n\n    prefix = re.search(prefix_regex, result).group()\n    suffix = re.search(suffix_regex, result).group()\n    if result.startswith(prefix) and result.endswith(suffix):\n        result = result[len(prefix):-len(suffix)]\n    return json.loads(result, encoding='utf8', cls=JSONPDecoder)", "response": "This function is used to request data from a server in a different domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(self, json_string):\n\n        default_obj = super(JSONPDecoder, self).decode(json_string)\n        \n        return list(self._iterdecode(default_obj))[0]", "response": "decode returns the object that was decoded from the given json_string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the string contains Date. UTC function and return match group(s) if there is", "response": "def is_js_date_utc(json):\n        \"\"\"Check if the string contains Date.UTC function \n        and return match group(s) if there is\n        \"\"\"\n        \n        JS_date_utc_pattern = r'Date\\.UTC\\(([0-9]+,[0-9]+,[0-9]+)(,[0-9]+,[0-9]+,[0-9]+)?(,[0-9]+)?\\)'\n        re_date = re.compile(JS_date_utc_pattern, re.M)\n\n        if re_date.search(json):\n            return re_date.search(json).group(0)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_JSsource(self, new_src):\n        if isinstance(new_src, list):\n            for h in new_src:\n                self.JSsource.append(h)\n        elif isinstance(new_src, basestring):\n            self.JSsource.append(new_src)\n        else:\n            raise OptionTypeError(\"Option: %s Not Allowed For Series Type: %s\" % type(new_src))", "response": "add additional js script source"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding additional css source", "response": "def add_CSSsource(self, new_src):\n        \"\"\"add additional css source(s)\"\"\"\n        if isinstance(new_src, list):\n            for h in new_src:\n                self.CSSsource.append(h)\n        elif isinstance(new_src, basestring):\n            self.CSSsource.append(new_src)\n        else:\n            raise OptionTypeError(\"Option: %s Not Allowed For Series Type: %s\" % type(new_src))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd data for series option in highmaps", "response": "def add_data_set(self, data, series_type=\"map\", name=None, is_coordinate = False, **kwargs):\n        \"\"\"set data for series option in highmaps \"\"\"\n        \n        self.data_set_count += 1\n        if not name:\n            name = \"Series %d\" % self.data_set_count\n        kwargs.update({'name':name})\n\n        if is_coordinate:\n            self.data_is_coordinate = True\n            self.add_JSsource('https://cdnjs.cloudflare.com/ajax/libs/proj4js/2.3.6/proj4.js')\n            if self.map and not self.data_temp:\n                series_data = Series([], series_type='map', **{'mapData': self.map})\n                series_data.__options__().update(SeriesOptions(series_type='map', **{'mapData': self.map}).__options__())\n                self.data_temp.append(series_data)\n\n        if self.map and 'mapData' in kwargs.keys():\n            kwargs.update({'mapData': self.map})\n\n        series_data = Series(data, series_type=series_type, **kwargs)\n       \n        series_data.__options__().update(SeriesOptions(series_type=series_type, **kwargs).__options__())\n        self.data_temp.append(series_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_drilldown_data_set(self, data, series_type, id, **kwargs):\n        self.drilldown_data_set_count += 1\n        if self.drilldown_flag == False:\n            self.drilldown_flag = True\n        \n        kwargs.update({'id':id})\n        series_data = Series(data, series_type=series_type, **kwargs)\n        series_data.__options__().update(SeriesOptions(series_type=series_type, **kwargs).__options__())\n        self.drilldown_data_temp.append(series_data)", "response": "add drilldown data set in highmaps \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds data directly from a jsonp source", "response": "def add_data_from_jsonp(self, data_src, data_name = 'json_data', series_type=\"map\", name=None, **kwargs):\n        \"\"\"add data directly from a https source\n        the data_src is the https link for data using jsonp\n        \"\"\"\n        self.jsonp_data_flag = True\n        self.jsonp_data_url = json.dumps(data_src)\n        if data_name == 'data':\n            data_name = 'json_'+ data_name\n        self.jsonp_data = data_name\n        self.add_data_set(RawJavaScriptText(data_name), series_type, name=name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding javascript in the beginning or end of script", "response": "def add_JSscript(self, js_script, js_loc):\n        \"\"\"add (highcharts) javascript in the beginning or at the end of script\n        use only if necessary\n        \"\"\"\n        if js_loc == 'head':\n            self.jscript_head_flag = True\n            if self.jscript_head:\n                self.jscript_head = self.jscript_head + '\\n' +  js_script\n            else:\n                self.jscript_head = js_script\n        elif js_loc == 'end':\n            self.jscript_end_flag = True\n            if self.jscript_end:\n                self.jscript_end = self.jscript_end + '\\n' +  js_script\n            else:\n                self.jscript_end = js_script\n        else:\n            raise OptionTypeError(\"Not An Accepted script location: %s, either 'head' or 'end'\" \n                                % js_loc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_map_source(self, map_src, jsonp_map = False):\n\n        if not map_src:\n            raise OptionTypeError(\"No map source input, please refer to: https://code.highcharts.com/mapdata/\")\n        \n        if  jsonp_map:\n            self.jsonp_map_flag = True\n            self.map = 'geojson'\n            self.jsonp_map_url = json.dumps(map_src)\n        else:\n            self.add_JSsource(map_src)\n            map_name = self._get_jsmap_name(map_src)\n            self.map = 'geojson'\n            self.jsmap = self.map + ' = Highcharts.geojson(' + map_name + ');'\n            self.add_JSscript('var ' + self.jsmap, 'head')\n\n        if self.data_temp:\n            self.data_temp[0].__options__().update({'mapData': MapObject(self.map)})", "response": "set map data \n        use if the mapData is loaded directly from a https source"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting options for dictionary - like inputs", "response": "def set_dict_options(self, options):\n        \"\"\"for dictionary-like inputs (as object in Javascript)\n        options must be in python dictionary format\n        \"\"\"\n        if isinstance(options, dict):\n            for key, option_data in options.items():\n                self.set_options(key, option_data)\n        else:\n            raise OptionTypeError(\"Not An Accepted Input Format: %s. Must be Dictionary\" %type(options))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn name of the map in. js format", "response": "def _get_jsmap_name(self, url):\n        \"\"\"return 'name' of the map in .js format\"\"\"\n        \n        ret = urlopen(url)\n        return ret.read().decode('utf-8').split('=')[0].replace(\" \", \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the HTML page containing the highcharts.", "response": "def buildhtml(self):\n        \"\"\"Build the HTML page\n        Create the htmlheader with css / js\n        Create html page\n        \"\"\"\n        self.buildcontent()\n        self.buildhtmlheader()\n        self.content = self._htmlcontent.decode('utf-8') # need to ensure unicode\n        self._htmlcontent = self.template_page_highcharts.render(chart=self)\n        return self._htmlcontent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate HTML header content", "response": "def buildhtmlheader(self):\n        \"\"\"generate HTML header content\"\"\"\n        #Highcharts lib/ needs to make sure it's up to date\n        \n        if self.drilldown_flag:\n            self.add_JSsource('https://code.highcharts.com/maps/modules/drilldown.js')\n\n        self.header_css = [\n            '<link href=\"%s\" rel=\"stylesheet\" />' % h for h in self.CSSsource\n        ]\n\n        self.header_js = [\n            '<script type=\"text/javascript\" src=\"%s\"></script>' % h for h in self.JSsource\n        ]\n\n        self.htmlheader = ''\n        for css in self.header_css:\n            self.htmlheader += css\n        for js in self.header_js:\n            self.htmlheader += js"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buildcontainer(self):\n        if self.container:\n            return\n        # Create HTML div with style\n        if self.options['chart'].width:\n            if str(self.options['chart'].width)[-1] != '%':\n                self.div_style += 'width:%spx;' % self.options['chart'].width\n            else:\n                self.div_style += 'width:%s;' % self.options['chart'].width\n        if self.options['chart'].height:\n            if str(self.options['chart'].height)[-1] != '%':\n                self.div_style += 'height:%spx;' % self.options['chart'].height\n            else:\n                self.div_style += 'height:%s;' % self.options['chart'].height\n\n        self.div_name = self.options['chart'].__dict__['renderTo'] # recheck div name\n        self.container = self.containerheader + \\\n            '<div id=\"%s\" style=\"%s\">%s</div>\\n' % (self.div_name, self.div_style, self.loading)", "response": "generate HTML div with style"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd data for series option in highcharts", "response": "def add_data_set(self, data, series_type=\"line\", name=None, **kwargs):\n        \"\"\"set data for series option in highcharts\"\"\"\n\n        self.data_set_count += 1\n        if not name:\n            name = \"Series %d\" % self.data_set_count\n        kwargs.update({'name':name})\n\n        if series_type == 'treemap':\n            self.add_JSsource('http://code.highcharts.com/modules/treemap.js')\n\n        series_data = Series(data, series_type=series_type, **kwargs)\n       \n        series_data.__options__().update(SeriesOptions(series_type=series_type, **kwargs).__options__())\n        self.data_temp.append(series_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef buildcontent(self):\n\n        self.buildcontainer()\n        self.option = json.dumps(self.options, cls = HighchartsEncoder)\n        self.setoption = json.dumps(self.setOptions, cls = HighchartsEncoder)\n        self.data = json.dumps(self.data_temp, cls = HighchartsEncoder)\n\n        # DEM 2017/04/25: Make 'data' available as an array\n        # ... this permits jinja2 array access to each data definition\n        # ... which is useful for looping over multiple data sources\n        self.data_list = [json.dumps(x, cls = HighchartsEncoder) for x in self.data_temp]\n\n        if self.drilldown_flag: \n            self.drilldown_data = json.dumps(self.drilldown_data_temp, cls = HighchartsEncoder)\n        self._htmlcontent = self.template_content_highcharts.render(chart=self).encode('utf-8')", "response": "build HTML content only no header or body tags"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating HTML header content", "response": "def buildhtmlheader(self):\n        \"\"\"generate HTML header content\"\"\"\n        \n        if self.drilldown_flag:\n            self.add_JSsource('http://code.highcharts.com/modules/drilldown.js')\n\n\n\n        if self.offline:\n            opener = urllib.request.build_opener()\n            opener.addheaders = [('User-Agent', 'Mozilla/5.0')]\n\n            self.header_css = [\n                '<style>%s</style>' % opener.open(h).read() for h in self.CSSsource\n            ]\n\n            self.header_js = [\n                '<script type=\"text/javascript\">%s</script>' % opener.open(h).read() for h in self.JSsource\n            ]\n        else:\n            self.header_css = [\n                '<link href=\"%s\" rel=\"stylesheet\" />' % h for h in self.CSSsource\n            ]\n\n            self.header_js = [\n                '<script type=\"text/javascript\" src=\"%s\"></script>' % h for h in self.JSsource\n            ]\n\n        self.htmlheader = ''\n        for css in self.header_css:\n            self.htmlheader += css\n        for js in self.header_js:\n            self.htmlheader += js"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload map data from a. js source.", "response": "def js_map_loader(url):\n    \"\"\"Load map data from a .js source. It is designed for using highcharts' map collection:\n    https://code.highcharts.com/mapdata/. Map data from other sources are not guaranteed\n    \"\"\"\n\n    hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.77 Safari/535.7'}\n    req = urllib.request.Request(url, headers=hdr)\n    page = urlopen(req)\n    result = page.read().decode('utf-8')\n    result = result[len(re.search(r'^.* = ', result).group()):]\n\n    return json.loads(result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef geojson_handler(geojson, hType='map'):\n\n    hType_dict = {\n    'map': ['polygon', 'multipolygon'],\n    'mapline': ['linestring', 'multilinestring'],\n    'mappoint': ['point', 'multipoint'],    \n    }\n\n\n    oldlist = [x for x in geojson['features'] if x['geometry']['type'].lower() in hType_dict[hType]]\n    newlist = []\n    for each_dict in oldlist:\n        geojson_type = each_dict['geometry']['type'].lower()\n\n        if hType == 'mapline':\n            newlist.append(\n            {'name': each_dict['properties'].get('name', None), \n             'path': _coordinates_to_path(each_dict['geometry']['coordinates'], hType, geojson_type),\n             'properties': each_dict['properties'],\n             }\n            )\n        elif hType == 'map':\n            newlist.append(\n            {'name': each_dict['properties']['name'], \n             'path': _coordinates_to_path(each_dict['geometry']['coordinates'], hType, geojson_type),\n             'properties': each_dict['properties'],\n             }\n            )\n        elif hType == 'mappoint':\n            newlist.append(\n            {'name': each_dict['properties']['name'], \n             'x': each_dict['geometry']['coordinates'][0],\n             'y': -each_dict['geometry']['coordinates'][1],\n             'properties': each_dict['properties'],\n             }\n            )\n        \n    return newlist", "response": "This function handles the GeoJSON data structure and returns a list of highcharts that can be converted into a single highcharts object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef json2datetime(json):\n        \n        json_m = re.search(r'([0-9]+,[0-9]+,[0-9]+)(,[0-9]+,[0-9]+,[0-9]+)?(,[0-9]+)?', json)\n        args=json_m.group(0).split(',')\n        \n        try:\n            args=map(int, args)\n        except ValueError:\n            raise ValueError('Invalid arguments: %s'%json)\n\n        if len(args)==3: \n            return datetime.datetime(args[0], args[1]+1, args[2])\n        elif len(args)==6: \n            return datetime.datetime(args[0], args[1]+1, args[2], \n                                    args[3], args[4], args[5], tzinfo=UTC())\n        elif len(args)==7:\n            args[6]*=1000\n            return datetime.datetime(args[0], args[1]+1, args[2], \n                                    args[3], args[4], args[5], args[6], tzinfo=UTC())\n        raise ValueError('Invalid number of arguments: %s'%json)", "response": "Convert JSON representation to date or datetime object depending on the argument count. Requires UTC datetime representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_navi_series(self, data, series_type=\"line\", **kwargs):\n\n        self.navi_seri_flag = True\n        series_data = Series(data, series_type=series_type, **kwargs)\n        series_data.__options__().update(SeriesOptions(series_type=series_type, **kwargs).__options__())           \n        self.navi_seri_temp = series_data", "response": "add a series for navigator option in highstocks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a series from a JSONP data source", "response": "def add_navi_series_from_jsonp(self, data_src=None, data_name='json_data', series_type=\"line\", **kwargs):\n        \"\"\"set series for navigator option in highstocks\"\"\"\n\n        if not self.jsonp_data_flag:\n            self.jsonp_data_flag = True\n            self.jsonp_data_url = json.dumps(data_src) \n            \n            if data_name == 'data':\n                data_name = 'json_'+ data_name\n            \n            self.jsonp_data = data_name\n        \n        self.add_navi_series(RawJavaScriptText(self.jsonp_data), series_type, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds HTML content only no header or body tags", "response": "def buildcontent(self):\n        \"\"\"build HTML content only, no header or body tags\"\"\"\n\n        self.buildcontainer()\n        self.option = json.dumps(self.options, cls = HighchartsEncoder)\n        self.setoption = json.dumps(self.setOptions, cls = HighchartsEncoder) \n        self.data = json.dumps(self.data_temp, cls = HighchartsEncoder)\n\n        # DEM 2017/04/25: Make 'data' available as an array\n        # ... this permits jinja2 array access to each data definition\n        # ... which is useful for looping over multiple data sources\n        self.data_list = [json.dumps(x, cls = HighchartsEncoder) for x in self.data_temp]\n        \n        if self.navi_seri_flag:        \n            self.navi_seri = json.dumps(self.navi_seri_temp, cls = HighchartsEncoder)\n\n        self._htmlcontent = self.template_content_highcharts.render(chart=self).encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_file(self, filename = 'StockChart'):\n        filename = filename + '.html'\n        \n        with open(filename, 'w') as f:\n            #self.buildhtml()\n            f.write(self.htmlcontent)\n        \n        f.closed", "response": "save htmlcontent as. html file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef acceptNavigationRequest(self, url, kind, is_main_frame):\n        ready_url = url.toEncoded().data().decode()\n        is_clicked = kind == self.NavigationTypeLinkClicked\n        if is_clicked and self.root_url not in ready_url:\n            QtGui.QDesktopServices.openUrl(url)\n            return False\n        return super(WebPage, self).acceptNavigationRequest(url, kind, is_main_frame)", "response": "Override acceptNavigationRequest to open external links in browser and internal links in the webview."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _safe_attr(attr, camel_killer=False, replacement_char='x'):\n    allowed = string.ascii_letters + string.digits + '_'\n\n    attr = _safe_key(attr)\n\n    if camel_killer:\n        attr = _camel_killer(attr)\n\n    attr = attr.replace(' ', '_')\n\n    out = ''\n    for character in attr:\n        out += character if character in allowed else \"_\"\n    out = out.strip(\"_\")\n\n    try:\n        int(out[0])\n    except (ValueError, IndexError):\n        pass\n    else:\n        out = '{0}{1}'.format(replacement_char, out)\n\n    if out in kwlist:\n        out = '{0}{1}'.format(replacement_char, out)\n\n    return re.sub('_+', '_', out)", "response": "Convert a key into something that is accessible as an attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _camel_killer(attr):\n    try:\n        attr = str(attr)\n    except UnicodeEncodeError:\n        attr = attr.encode(\"utf-8\", \"ignore\")\n\n    s1 = _first_cap_re.sub(r'\\1_\\2', attr)\n    s2 = _all_cap_re.sub(r'\\1_\\2', s1)\n    return re.sub('_+', '_', s2.casefold() if hasattr(s2, 'casefold')\n                  else s2.lower())", "response": "CamelKiller, qu'est-ce que c'est?\n\n    Taken from http://stackoverflow.com/a/1176023/3244542"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms value lookup for all items in current dictionary and then run all sub Box objects.", "response": "def box_it_up(self):\n        \"\"\"\n        Perform value lookup for all items in current dictionary,\n        generating all sub Box objects, while also running `box_it_up` on\n        any of those sub box objects.\n        \"\"\"\n        for k in self:\n            _conversion_checks(k, self.keys(), self._box_config,\n                               check_only=True)\n            if self[k] is not self and hasattr(self[k], 'box_it_up'):\n                self[k].box_it_up()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dict(self):\n        out_dict = dict(self)\n        for k, v in out_dict.items():\n            if v is self:\n                out_dict[k] = out_dict\n            elif hasattr(v, 'to_dict'):\n                out_dict[k] = v.to_dict()\n            elif hasattr(v, 'to_list'):\n                out_dict[k] = v.to_list()\n        return out_dict", "response": "Turn the Box and sub Boxes back into a native\n        python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming the Box object into a JSON string.", "response": "def to_json(self, filename=None,\n                encoding=\"utf-8\", errors=\"strict\", **json_kwargs):\n        \"\"\"\n        Transform the Box object into a JSON string.\n\n        :param filename: If provided will save to file\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param json_kwargs: additional arguments to pass to json.dump(s)\n        :return: string of JSON or return of `json.dump`\n        \"\"\"\n        return _to_json(self.to_dict(), filename=filename,\n                        encoding=encoding, errors=errors, **json_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_json(cls, json_string=None, filename=None,\n                  encoding=\"utf-8\", errors=\"strict\", **kwargs):\n        \"\"\"\n        Transform a json object string into a Box object. If the incoming\n        json is a list, you must use BoxList.from_json.\n\n        :param json_string: string to pass to `json.loads`\n        :param filename: filename to open and pass to `json.load`\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param kwargs: parameters to pass to `Box()` or `json.loads`\n        :return: Box object from json data\n        \"\"\"\n        bx_args = {}\n        for arg in kwargs.copy():\n            if arg in BOX_PARAMETERS:\n                bx_args[arg] = kwargs.pop(arg)\n\n        data = _from_json(json_string, filename=filename,\n                          encoding=encoding, errors=errors, **kwargs)\n\n        if not isinstance(data, dict):\n            raise BoxError('json data not returned as a dictionary, '\n                           'but rather a {0}'.format(type(data).__name__))\n        return cls(data, **bx_args)", "response": "Transform a json object string into a Box object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms the BoxList object into a JSON string.", "response": "def to_json(self, filename=None,\n                encoding=\"utf-8\", errors=\"strict\",\n                multiline=False, **json_kwargs):\n        \"\"\"\n        Transform the BoxList object into a JSON string.\n\n        :param filename: If provided will save to file\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param multiline: Put each item in list onto it's own line\n        :param json_kwargs: additional arguments to pass to json.dump(s)\n        :return: string of JSON or return of `json.dump`\n        \"\"\"\n        if filename and multiline:\n            lines = [_to_json(item, filename=False, encoding=encoding,\n                              errors=errors, **json_kwargs) for item in self]\n            with open(filename, 'w', encoding=encoding, errors=errors) as f:\n                f.write(\"\\n\".join(lines).decode('utf-8') if\n                        sys.version_info < (3, 0) else \"\\n\".join(lines))\n        else:\n            return _to_json(self.to_list(), filename=filename,\n                            encoding=encoding, errors=errors, **json_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bool(self, item, default=None):\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n\n        if isinstance(item, (bool, int)):\n            return bool(item)\n\n        if (isinstance(item, str) and\n                item.lower() in ('n', 'no', 'false', 'f', '0')):\n            return False\n\n        return True if item else False", "response": "Return value of key as a boolean"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn value of key as an int", "response": "def int(self, item, default=None):\n        \"\"\" Return value of key as an int\n\n        :param item: key of value to transform\n        :param default: value to return if item does not exist\n        :return: int of value\n        \"\"\"\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n        return int(item)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef float(self, item, default=None):\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n        return float(item)", "response": "Return value of key as a float"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_from_file(filepath):\n        class_inst = None\n        expected_class = \"Py3status\"\n        module_name, file_ext = os.path.splitext(os.path.split(filepath)[-1])\n        if file_ext.lower() == \".py\":\n            py_mod = imp.load_source(module_name, filepath)\n            if hasattr(py_mod, expected_class):\n                class_inst = py_mod.Py3status()\n        return class_inst", "response": "Load user - written class object from given file path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a py3status bundled module.", "response": "def load_from_namespace(module_name):\n        \"\"\"\n        Load a py3status bundled module.\n        \"\"\"\n        class_inst = None\n        name = \"py3status.modules.{}\".format(module_name)\n        py_mod = __import__(name)\n        components = name.split(\".\")\n        for comp in components[1:]:\n            py_mod = getattr(py_mod, comp)\n        class_inst = py_mod.Py3status()\n        return class_inst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare the module for use by the modules.", "response": "def prepare_module(self):\n        \"\"\"\n        Ready the module to get it ready to start.\n        \"\"\"\n        # Modules can define a post_config_hook() method which will be run\n        # after the module has had it config settings applied and before it has\n        # its main method(s) called for the first time.  This allows modules to\n        # perform any necessary setup.\n        if self.has_post_config_hook:\n            try:\n                self.module_class.post_config_hook()\n            except Exception as e:\n                # An exception has been thrown in post_config_hook() disable\n                # the module and show error in module output\n                self.terminated = True\n                self.error_index = 0\n\n                self.error_messages = [\n                    self.module_nice_name,\n                    u\"{}: {}\".format(\n                        self.module_nice_name, str(e) or e.__class__.__name__\n                    ),\n                ]\n                self.error_output(self.error_messages[0])\n                msg = \"Exception in `%s` post_config_hook()\" % self.module_full_name\n                self._py3_wrapper.report_exception(msg, notify_user=False)\n                self._py3_wrapper.log(\"terminating module %s\" % self.module_full_name)\n        self.enabled = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows the error in the bar", "response": "def runtime_error(self, msg, method):\n        \"\"\"\n        Show the error in the bar\n        \"\"\"\n        if self.testing:\n            self._py3_wrapper.report_exception(msg)\n            raise KeyboardInterrupt\n\n        if self.error_hide:\n            self.hide_errors()\n            return\n\n        # only show first line of error\n        msg = msg.splitlines()[0]\n\n        errors = [self.module_nice_name, u\"{}: {}\".format(self.module_nice_name, msg)]\n\n        # if we have shown this error then keep in the same state\n        if self.error_messages != errors:\n            self.error_messages = errors\n            self.error_index = 0\n        self.error_output(self.error_messages[self.error_index], method)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hide_errors(self):\n        for method in self.methods.values():\n            method[\"last_output\"] = {}\n\n        self.allow_config_clicks = False\n        self.error_hide = True\n        self.set_updated()", "response": "hide the module in the i3bar"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the module running.", "response": "def start_module(self):\n        \"\"\"\n        Start the module running.\n        \"\"\"\n        self.prepare_module()\n        if not (self.disabled or self.terminated):\n            # Start the module and call its output method(s)\n            self._py3_wrapper.log(\"starting module %s\" % self.module_full_name)\n            self._py3_wrapper.timeout_queue_add(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef force_update(self):\n        if self.disabled or self.terminated or not self.enabled:\n            return\n        # clear cached_until for each method to allow update\n        for meth in self.methods:\n            self.methods[meth][\"cached_until\"] = time()\n            if self.config[\"debug\"]:\n                self._py3_wrapper.log(\"clearing cache for method {}\".format(meth))\n        # set module to update\n        self._py3_wrapper.timeout_queue_add(self)", "response": "Forces an update of the module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_updated(self):\n        # get latest output\n        output = []\n        for method in self.methods.values():\n            data = method[\"last_output\"]\n            if isinstance(data, list):\n                if self.testing and data:\n                    data[0][\"cached_until\"] = method.get(\"cached_until\")\n                output.extend(data)\n            else:\n                # if the output is not 'valid' then don't add it.\n                if data.get(\"full_text\") or \"separator\" in data:\n                    if self.testing:\n                        data[\"cached_until\"] = method.get(\"cached_until\")\n                    output.append(data)\n        # if changed store and force display update.\n        if output != self.last_output:\n            # has the modules output become urgent?\n            # we only care the update that this happens\n            # not any after then.\n            urgent = True in [x.get(\"urgent\") for x in output]\n            if urgent != self.urgent:\n                self.urgent = urgent\n            else:\n                urgent = False\n            self.last_output = output\n            self._py3_wrapper.notify_update(self.module_full_name, urgent)", "response": "Mark the module as updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_module_options(self, module):\n        self.i3bar_module_options = {}\n        self.i3bar_gaps_module_options = {}\n        self.py3status_module_options = {}\n        fn = self._py3_wrapper.get_config_attribute\n\n        def make_quotes(options):\n            x = [\"`{}`\".format(x) for x in options]\n            if len(x) > 2:\n                x = [\", \".join(x[:-1]), x[-1]]\n            return \" or \".join(x)\n\n        # i3bar\n        min_width = fn(self.module_full_name, \"min_width\")\n        if not hasattr(min_width, \"none_setting\"):\n            if not isinstance(min_width, int):\n                err = \"Invalid `min_width` attribute, should be an int. \"\n                err += \"Got `{}`.\".format(min_width)\n                raise TypeError(err)\n            self.i3bar_module_options[\"min_width\"] = min_width\n\n            align = fn(self.module_full_name, \"align\")\n            if not hasattr(align, \"none_setting\"):\n                if align not in POSITIONS:\n                    err = \"Invalid `align` attribute, should be \"\n                    err += make_quotes(POSITIONS)\n                    err += \". Got `{}`.\".format(align)\n                    raise ValueError(err)\n                self.i3bar_module_options[\"align\"] = align\n\n        separator = fn(self.module_full_name, \"separator\")\n        if not hasattr(separator, \"none_setting\"):\n            if not isinstance(separator, bool):\n                err = \"Invalid `separator` attribute, should be a boolean. \"\n                err += \"Got `{}`.\".format(separator)\n                raise TypeError(err)\n            self.i3bar_module_options[\"separator\"] = separator\n\n        separator_block_width = fn(self.module_full_name, \"separator_block_width\")\n        if not hasattr(separator_block_width, \"none_setting\"):\n            if not isinstance(separator_block_width, int):\n                err = \"Invalid `separator_block_width` attribute, \"\n                err += \"should be an int. \"\n                err += \"Got `{}`.\".format(separator_block_width)\n                raise TypeError(err)\n            self.i3bar_module_options[\"separator_block_width\"] = separator_block_width\n\n        # i3bar_gaps\n        background = fn(self.module_full_name, \"background\")\n        if not hasattr(background, \"none_setting\"):\n            color = self.module_class.py3._get_color(background)\n            if not color:\n                err = \"Invalid `background` attribute should be a color. \"\n                err += \"Got `{}`.\".format(background)\n                raise ValueError(err)\n            self.i3bar_gaps_module_options[\"background\"] = color\n\n        border = fn(self.module_full_name, \"border\")\n        if not hasattr(border, \"none_setting\"):\n            color = self.module_class.py3._get_color(border)\n            if not color:\n                err = \"Invalid `border` attribute, should be a color. \"\n                err += \"Got `{}`.\".format(border)\n                raise ValueError(err)\n            self.i3bar_gaps_module_options[\"border\"] = color\n\n            borders = [\"top\", \"right\", \"bottom\", \"left\"]\n            for name in [\"border_\" + x for x in borders]:\n                param = fn(self.module_full_name, name)\n                if hasattr(param, \"none_setting\"):\n                    param = 1\n                elif not isinstance(param, int):\n                    err = \"Invalid `{}` attribute, \".format(name)\n                    err += \"should be an int. \"\n                    err += \"Got `{}`.\".format(param)\n                    raise TypeError(err)\n                self.i3bar_gaps_module_options[name] = param\n\n        # py3status\n        min_length = fn(self.module_full_name, \"min_length\")\n        if not hasattr(min_length, \"none_setting\"):\n            if not isinstance(min_length, int):\n                err = \"Invalid `min_length` attribute, should be an int. \"\n                err += \"Got `{}`.\".format(min_length)\n                raise TypeError(err)\n            self.py3status_module_options[\"min_length\"] = min_length\n            self.random_int = randint(0, 1)\n\n            position = fn(self.module_full_name, \"position\")\n            if not hasattr(position, \"none_setting\"):\n                if position not in POSITIONS:\n                    err = \"Invalid `position` attribute, should be \"\n                    err += make_quotes(POSITIONS)\n                    err += \". Got `{}`.\".format(position)\n                    raise ValueError(err)\n                self.py3status_module_options[\"position\"] = position\n\n        # i3bar, py3status\n        markup = fn(self.module_full_name, \"markup\")\n        if not hasattr(markup, \"none_setting\"):\n            if markup not in MARKUP_LANGUAGES:\n                err = \"Invalid `markup` attribute, should be \"\n                err += make_quotes(MARKUP_LANGUAGES)\n                err += \". Got `{}`.\".format(markup)\n                raise ValueError(err)\n            self.i3bar_module_options[\"markup\"] = markup\n            self.py3status_module_options[\"markup\"] = markup", "response": "Set the universal module options to be interpreted by i3bar"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_composite(self, response):\n        composite = response[\"composite\"]\n\n        # if the composite is of not Composite make it one so we can simplify\n        # it.\n        if not isinstance(composite, Composite):\n            composite = Composite(composite)\n\n        # simplify and get underlying list.\n        composite = composite.simplify().get_content()\n        response[\"composite\"] = composite\n\n        if not isinstance(composite, list):\n            raise Exception('expecting \"composite\" key in response')\n        # if list is empty nothing to do\n        if not len(composite):\n            return\n        if \"full_text\" in response:\n            err = 'conflicting \"full_text\" and \"composite\" in response'\n            raise Exception(err)\n\n        # set markup\n        if \"markup\" in self.py3status_module_options:\n            markup = self.py3status_module_options[\"markup\"]\n            for item in composite:\n                item[\"markup\"] = markup\n\n        # set universal options on last component\n        composite[-1].update(self.i3bar_module_options)\n        # update all components\n        color = response.get(\"color\")\n        urgent = response.get(\"urgent\")\n        composite_length = len(response[\"composite\"]) - 1\n        for index, item in enumerate(response[\"composite\"]):\n            # validate the response\n            if \"full_text\" not in item:\n                raise KeyError('missing \"full_text\" key in response')\n            # make sure all components have a name\n            if \"name\" not in item:\n                instance_index = item.get(\"index\", index)\n                item[\"instance\"] = \"{} {}\".format(self.module_inst, instance_index)\n                item[\"name\"] = self.module_name\n            # hide separator for all inner components unless existing\n            if index != composite_length:\n                if \"separator\" not in item:\n                    item[\"separator\"] = False\n                    item[\"separator_block_width\"] = 0\n            # If a color was supplied for the composite and a composite\n            # part does not supply a color, use the composite color.\n            if color and \"color\" not in item:\n                item[\"color\"] = color\n            # Remove any none color from our output\n            if hasattr(item.get(\"color\"), \"none_setting\"):\n                del item[\"color\"]\n\n            # set background and border colors. set left/right border widths\n            # only on first/last composites and no border width for inner\n            # composites or we will see border lines between composites.\n            for key, value in self.i3bar_gaps_module_options.items():\n                if (key == \"border_left\" and index != 0) or (\n                    key == \"border_right\" and index != composite_length\n                ):\n                    item[key] = 0\n                else:\n                    item[key] = value\n\n            # set urgent based on available user-defined settings\n            if not self.allow_urgent:\n                if \"urgent\" in item:\n                    del item[\"urgent\"]\n            elif urgent:\n                if self.i3bar_gaps_urgent_options:\n                    # set background and border colors. set left/right border widths\n                    # only on first/last composites and no border width for inner\n                    # composites or we will see border lines between composites.\n                    for key, value in self.i3bar_gaps_urgent_options.items():\n                        if (key == \"border_left\" and index != 0) or (\n                            key == \"border_right\" and index != composite_length\n                        ):\n                            item[key] = 0\n                        elif key == \"foreground\":\n                            item[\"color\"] = value\n                        else:\n                            item[key] = value\n                    if \"urgent\" in item:\n                        del item[\"urgent\"]\n                else:\n                    item[\"urgent\"] = urgent\n\n        # set min_length\n        if \"min_length\" in self.py3status_module_options:\n            min_length = self.py3status_module_options[\"min_length\"]\n\n            # get length, skip if length exceeds min_length\n            length = sum([len(x[\"full_text\"]) for x in response[\"composite\"]])\n            if length >= min_length:\n                return\n\n            # sometimes we go under min_length to pad both side evenly,\n            # we will add extra space on either side to honor min_length\n            padding = int((min_length / 2.0) - (length / 2.0))\n            offset = min_length - ((padding * 2) + length)\n\n            # set position\n            position = self.py3status_module_options.get(\"position\", \"left\")\n            if position == \"center\":\n                left = right = \" \" * padding\n                if self.random_int:\n                    left += \" \" * offset\n                else:\n                    right += \" \" * offset\n            elif position == \"left\":\n                left, right = \"\", \" \" * (padding * 2 + offset)\n            elif position == \"right\":\n                right, left = \"\", \" \" * (padding * 2 + offset)\n\n            # padding\n            if left:\n                response[\"composite\"][0][\"full_text\"] = (\n                    left + response[\"composite\"][0][\"full_text\"]\n                )\n            if right:\n                response[\"composite\"][-1][\"full_text\"] += right", "response": "Process a composite response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _params_type(self, method_name, instance):\n\n        method = getattr(instance, method_name, None)\n        if not method:\n            return False\n\n        # Check the parameters we simply count the number of args and don't\n        # allow any extras like keywords.\n        arg_count = 1\n        # on_click method has extra events parameter\n        if method_name == \"on_click\":\n            arg_count = 2\n        args, vargs, kw, defaults = inspect.getargspec(method)\n        if len(args) == arg_count and not vargs and not kw:\n            return self.PARAMS_NEW\n        else:\n            return self.PARAMS_LEGACY", "response": "Check if the method has parameters and return the type of the parameter list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_methods(self, module, user_modules):\n        if not self.module_class:\n            # user provided modules take precedence over py3status provided modules\n            if self.module_name in user_modules:\n                include_path, f_name = user_modules[self.module_name]\n                module_path = os.path.join(include_path, f_name)\n                self._py3_wrapper.log(\n                    'loading module \"{}\" from {}'.format(module, module_path)\n                )\n                self.module_class = self.load_from_file(module_path)\n            # load from py3status provided modules\n            else:\n                self._py3_wrapper.log(\n                    'loading module \"{}\" from py3status.modules.{}'.format(\n                        module, self.module_name\n                    )\n                )\n                self.module_class = self.load_from_namespace(self.module_name)\n\n        class_inst = self.module_class\n        if class_inst:\n\n            try:\n                # containers have items attribute set to a list of contained\n                # module instance names.  If there are no contained items then\n                # ensure that we have a empty list.\n                if class_inst.Meta.container:\n                    class_inst.items = []\n            except AttributeError:\n                pass\n\n            # module configuration\n            mod_config = self.config[\"py3_config\"].get(module, {})\n\n            # process any deprecated configuration settings\n            try:\n                deprecated = class_inst.Meta.deprecated\n            except AttributeError:\n                deprecated = None\n\n            if deprecated:\n\n                def deprecation_log(item):\n                    # log the deprecation\n                    # currently this is just done to the log file as the user\n                    # does not need to take any action.\n                    if \"msg\" in item:\n                        msg = item[\"msg\"]\n                        param = item.get(\"param\")\n                        if param:\n                            msg = \"`{}` {}\".format(param, msg)\n                        msg = \"DEPRECATION WARNING: {} {}\".format(\n                            self.module_full_name, msg\n                        )\n                        self._py3_wrapper.log(msg)\n\n                if \"rename\" in deprecated:\n                    # renamed parameters\n                    for item in deprecated[\"rename\"]:\n                        param = item[\"param\"]\n                        new_name = item[\"new\"]\n                        if param in mod_config:\n                            if new_name not in mod_config:\n                                mod_config[new_name] = mod_config[param]\n                                # remove from config\n                                del mod_config[param]\n                            deprecation_log(item)\n                if \"format_fix_unnamed_param\" in deprecated:\n                    # format update where {} was previously allowed\n                    for item in deprecated[\"format_fix_unnamed_param\"]:\n                        param = item[\"param\"]\n                        placeholder = item[\"placeholder\"]\n                        if \"{}\" in mod_config.get(param, \"\"):\n                            mod_config[param] = mod_config[param].replace(\n                                \"{}\", \"{%s}\" % placeholder\n                            )\n                            deprecation_log(item)\n                if \"rename_placeholder\" in deprecated:\n                    # rename placeholders\n                    placeholders = {}\n                    for item in deprecated[\"rename_placeholder\"]:\n                        placeholders[item[\"placeholder\"]] = item[\"new\"]\n                        format_strings = item[\"format_strings\"]\n                        for format_param in format_strings:\n                            format_string = mod_config.get(format_param)\n                            if not format_string:\n                                continue\n                            format = Formatter().update_placeholders(\n                                format_string, placeholders\n                            )\n                            mod_config[format_param] = format\n\n                if \"update_placeholder_format\" in deprecated:\n                    # update formats for placeholders if a format is not set\n                    for item in deprecated[\"update_placeholder_format\"]:\n                        placeholder_formats = item.get(\"placeholder_formats\", {})\n                        if \"function\" in item:\n                            placeholder_formats.update(item[\"function\"](mod_config))\n                        format_strings = item[\"format_strings\"]\n                        for format_param in format_strings:\n                            format_string = mod_config.get(format_param)\n                            if not format_string:\n                                continue\n                            format = Formatter().update_placeholder_formats(\n                                format_string, placeholder_formats\n                            )\n                            mod_config[format_param] = format\n                if \"substitute_by_value\" in deprecated:\n                    # one parameter sets the value of another\n                    for item in deprecated[\"substitute_by_value\"]:\n                        param = item[\"param\"]\n                        value = item[\"value\"]\n                        substitute = item[\"substitute\"]\n                        substitute_param = substitute[\"param\"]\n                        substitute_value = substitute[\"value\"]\n                        if (\n                            mod_config.get(param) == value\n                            and substitute_param not in mod_config\n                        ):\n                            mod_config[substitute_param] = substitute_value\n                            deprecation_log(item)\n                if \"function\" in deprecated:\n                    # parameter set by function\n                    for item in deprecated[\"function\"]:\n                        updates = item[\"function\"](mod_config)\n                        for name, value in updates.items():\n                            if name not in mod_config:\n                                mod_config[name] = value\n                if \"remove\" in deprecated:\n                    # obsolete parameters forcibly removed\n                    for item in deprecated[\"remove\"]:\n                        param = item[\"param\"]\n                        if param in mod_config:\n                            del mod_config[param]\n                            deprecation_log(item)\n\n            # apply module configuration\n            for config, value in mod_config.items():\n                # names starting with '.' are private\n                if not config.startswith(\".\"):\n                    setattr(self.module_class, config, value)\n\n            # process any update_config settings\n            try:\n                update_config = class_inst.Meta.update_config\n            except AttributeError:\n                update_config = None\n\n            if update_config:\n                if \"update_placeholder_format\" in update_config:\n                    # update formats for placeholders if a format is not set\n                    for item in update_config[\"update_placeholder_format\"]:\n                        placeholder_formats = item.get(\"placeholder_formats\", {})\n                        format_strings = item[\"format_strings\"]\n                        for format_param in format_strings:\n                            format_string = getattr(class_inst, format_param, None)\n                            if not format_string:\n                                continue\n                            format = Formatter().update_placeholder_formats(\n                                format_string, placeholder_formats\n                            )\n                            setattr(class_inst, format_param, format)\n\n            # Add the py3 module helper if modules self.py3 is not defined\n            if not hasattr(self.module_class, \"py3\"):\n                setattr(self.module_class, \"py3\", Py3(self))\n\n            # Subscribe to udev events if on_udev_* dynamic variables are\n            # configured on the module\n            for param in dir(self.module_class):\n                if param.startswith(\"on_udev_\"):\n                    trigger_action = getattr(self.module_class, param)\n                    self.add_udev_trigger(trigger_action, param[8:])\n\n            # allow_urgent\n            # get the value form the config or use the module default if\n            # supplied.\n            fn = self._py3_wrapper.get_config_attribute\n            param = fn(self.module_full_name, \"allow_urgent\")\n            if hasattr(param, \"none_setting\"):\n                param = True\n            self.allow_urgent = param\n\n            # urgent background\n            urgent_background = fn(self.module_full_name, \"urgent_background\")\n            if not hasattr(urgent_background, \"none_setting\"):\n                color = self.module_class.py3._get_color(urgent_background)\n                if not color:\n                    err = \"Invalid `urgent_background` attribute, should be \"\n                    err += \"a color. Got `{}`.\".format(urgent_background)\n                    raise ValueError(err)\n                self.i3bar_gaps_urgent_options[\"background\"] = color\n\n            # urgent foreground\n            urgent_foreground = fn(self.module_full_name, \"urgent_foreground\")\n            if not hasattr(urgent_foreground, \"none_setting\"):\n                color = self.module_class.py3._get_color(urgent_foreground)\n                if not color:\n                    err = \"Invalid `urgent_foreground` attribute, should be \"\n                    err += \"a color. Got `{}`.\".format(urgent_foreground)\n                    raise ValueError(err)\n                self.i3bar_gaps_urgent_options[\"foreground\"] = color\n\n            # urgent urgent_borders\n            urgent_border = fn(self.module_full_name, \"urgent_border\")\n            if not hasattr(urgent_border, \"none_setting\"):\n                color = self.module_class.py3._get_color(urgent_border)\n                if not color:\n                    err = \"Invalid `urgent_border` attribute, should be a color. \"\n                    err += \"Got `{}`.\".format(urgent_border)\n                    raise ValueError(err)\n                self.i3bar_gaps_urgent_options[\"border\"] = color\n\n                urgent_borders = [\"top\", \"right\", \"bottom\", \"left\"]\n                for name in [\"urgent_border_\" + x for x in urgent_borders]:\n                    param = fn(self.module_full_name, name)\n                    if hasattr(param, \"none_setting\"):\n                        param = 1\n                    elif not isinstance(param, int):\n                        err = \"Invalid `{}` attribute, \".format(name)\n                        err += \"should be an int. \"\n                        err += \"Got `{}`.\".format(param)\n                        raise TypeError(err)\n                    self.i3bar_gaps_urgent_options[name[7:]] = param\n\n            # get the available methods for execution\n            for method in sorted(dir(class_inst)):\n                if method.startswith(\"_\"):\n                    continue\n                else:\n                    m_type = type(getattr(class_inst, method))\n                    if \"method\" in str(m_type):\n                        params_type = self._params_type(method, class_inst)\n                        if method == \"on_click\":\n                            self.click_events = params_type\n                        elif method == \"kill\":\n                            self.has_kill = params_type\n                        elif method == \"post_config_hook\":\n                            self.has_post_config_hook = True\n                        else:\n                            # the method_obj stores infos about each method\n                            # of this module.\n                            method_obj = {\n                                \"cached_until\": time(),\n                                \"call_type\": params_type,\n                                \"instance\": None,\n                                \"last_output\": {\"name\": method, \"full_text\": \"\"},\n                                \"method\": method,\n                                \"name\": None,\n                            }\n                            self.methods[method] = method_obj\n\n        # done, log some debug info\n        if self.config[\"debug\"]:\n            self._py3_wrapper.log(\n                'module \"{}\" click_events={} has_kill={} methods={}'.format(\n                    module, self.click_events, self.has_kill, self.methods.keys()\n                )\n            )", "response": "Load the user - written py3status class file and store its methods."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef click_event(self, event):\n        # we can prevent request that a refresh after the event has happened\n        # by setting this to True.  Modules should do this via\n        # py3.prevent_refresh()\n        self.prevent_refresh = False\n        try:\n            if self.error_messages:\n                # we have error messages\n                button = event[\"button\"]\n                if button == 1:\n                    # cycle through to next message\n                    self.error_index = (self.error_index + 1) % len(self.error_messages)\n                    error = self.error_messages[self.error_index]\n                    self.error_output(error)\n                if button == 3:\n                    self.hide_errors()\n                if button != 2 or (self.terminated or self.disabled):\n                    self.prevent_refresh = True\n\n            elif self.click_events:\n                click_method = getattr(self.module_class, \"on_click\")\n                if self.click_events == self.PARAMS_NEW:\n                    # new style modules\n                    click_method(event)\n                else:\n                    # legacy modules had extra parameters passed\n                    click_method(\n                        self.i3status_thread.json_list,\n                        self.config[\"py3_config\"][\"general\"],\n                        event,\n                    )\n                self.set_updated()\n            else:\n                # nothing has happened so no need for refresh\n                self.prevent_refresh = True\n        except Exception:\n            msg = \"on_click event in `{}` failed\".format(self.module_full_name)\n            self._py3_wrapper.report_exception(msg)", "response": "Execute the on_click method of the module with the given event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute every method found for this module and return the result.", "response": "def run(self):\n        \"\"\"\n        On a timely fashion, execute every method found for this module.\n        We will respect and set a cache timeout for each method if the user\n        didn't already do so.\n        We will execute the 'kill' method of the module when we terminate.\n        \"\"\"\n        if self._py3_wrapper.running:\n            cache_time = None\n            # execute each method of this module\n            for meth, obj in self.methods.items():\n                my_method = self.methods[meth]\n\n                # always check py3status is running\n                if not self._py3_wrapper.running:\n                    break\n\n                # respect the cache set for this method\n                if time() < obj[\"cached_until\"]:\n                    if not cache_time or obj[\"cached_until\"] < cache_time:\n                        cache_time = obj[\"cached_until\"]\n                    continue\n\n                try:\n                    # execute method and get its output\n                    method = getattr(self.module_class, meth)\n                    if my_method[\"call_type\"] == self.PARAMS_NEW:\n                        # new style modules\n                        response = method()\n                    else:\n                        # legacy modules had parameters passed\n                        response = method(\n                            self.i3status_thread.json_list,\n                            self.config[\"py3_config\"][\"general\"],\n                        )\n\n                    if isinstance(response, dict):\n                        # this is a shiny new module giving a dict response\n                        result = response\n                    elif isinstance(response, tuple):\n                        # this is an old school module reporting its position\n                        position, result = response\n                        if not isinstance(result, dict):\n                            raise TypeError(\"response should be a dict\")\n                    else:\n                        raise TypeError(\"response should be a dict\")\n\n                    if isinstance(response.get(\"full_text\"), (list, Composite)):\n                        response[\"composite\"] = response[\"full_text\"]\n                        del response[\"full_text\"]\n                    if \"composite\" in response:\n                        self.process_composite(response)\n                    else:\n                        # validate the response\n                        if \"full_text\" not in result:\n                            err = 'missing \"full_text\" key in response'\n                            raise KeyError(err)\n                        # Remove any none color from our output\n                        if hasattr(result.get(\"color\"), \"none_setting\"):\n                            del result[\"color\"]\n                        # remove urgent if not allowed\n                        if not self.allow_urgent and \"urgent\" in result:\n                            del result[\"urgent\"]\n                        # set universal module options in result\n                        result.update(self.i3bar_module_options)\n\n                    result[\"instance\"] = self.module_inst\n                    result[\"name\"] = self.module_name\n\n                    # initialize method object\n                    if my_method[\"name\"] is None:\n                        my_method[\"name\"] = result[\"name\"]\n                        if \"instance\" in result:\n                            my_method[\"instance\"] = result[\"instance\"]\n                        else:\n                            my_method[\"instance\"] = result[\"name\"]\n\n                    # update method object cache\n                    if \"cached_until\" in result:\n                        cached_until = result[\"cached_until\"]\n                        # remove this so we can check later for output changes\n                        del result[\"cached_until\"]\n                    else:\n                        # get module default cached_until\n                        cached_until = self.module_class.py3.time_in()\n                    my_method[\"cached_until\"] = cached_until\n                    if not cache_time or cached_until < cache_time:\n                        cache_time = cached_until\n\n                    # update method object output\n                    if \"composite\" in response:\n                        my_method[\"last_output\"] = result[\"composite\"]\n                    else:\n                        my_method[\"last_output\"] = result\n\n                    # debug info\n                    if self.config[\"debug\"]:\n                        self._py3_wrapper.log(\n                            \"method {} returned {} \".format(meth, result)\n                        )\n                    # module working correctly so ensure module works as\n                    # expected\n                    self.allow_config_clicks = True\n                    self.error_messages = None\n                    self.error_hide = False\n\n                    # mark module as updated\n                    self.set_updated()\n\n                except ModuleErrorException as e:\n                    # module has indicated that it has an error\n                    self.runtime_error(e.msg, meth)\n                    if e.timeout:\n                        if e.timeout is PY3_CACHE_FOREVER:\n                            cache_time = PY3_CACHE_FOREVER\n                        else:\n                            cache_time = time() + e.timeout\n                    else:\n                        cache_time = time() + getattr(\n                            self.module_class,\n                            \"cache_timeout\",\n                            self.config[\"cache_timeout\"],\n                        )\n\n                except Exception as e:\n                    msg = \"Instance `{}`, user method `{}` failed\"\n                    msg = msg.format(self.module_full_name, meth)\n                    if not self.testing:\n                        self._py3_wrapper.report_exception(msg, notify_user=False)\n                    # added error\n                    self.runtime_error(str(e) or e.__class__.__name__, meth)\n                    cache_time = time() + getattr(\n                        self.module_class, \"cache_timeout\", self.config[\"cache_timeout\"]\n                    )\n\n            if cache_time is None:\n                cache_time = time() + self.config[\"cache_timeout\"]\n            self.cache_time = cache_time\n            # new style modules can signal they want to cache forever\n            if cache_time == PY3_CACHE_FOREVER:\n                return\n            # don't be hasty mate\n            # set timeout to do update next time one is needed\n            if not cache_time:\n                cache_time = time() + self.config[\"minimum_interval\"]\n\n            self._py3_wrapper.timeout_queue_add(self, cache_time)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsubscribing to the requested udev subsystem and apply the given action.", "response": "def add_udev_trigger(self, trigger_action, subsystem):\n        \"\"\"\n        Subscribe to the requested udev subsystem and apply the given action.\n        \"\"\"\n        if self._py3_wrapper.udev_monitor.subscribe(self, trigger_action, subsystem):\n            if trigger_action == \"refresh_and_freeze\":\n                # FIXME: we may want to disable refresh instead of using cache_timeout\n                self.module_class.cache_timeout = PY3_CACHE_FOREVER"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_credentials(self):\n        client_secret_path = os.path.dirname(self.client_secret)\n        auth_token_path = os.path.dirname(self.auth_token)\n\n        if not os.path.exists(auth_token_path):\n            os.makedirs(auth_token_path)\n\n        if not os.path.exists(client_secret_path):\n            os.makedirs(client_secret_path)\n\n        flags = tools.argparser.parse_args(args=[])\n        store = Storage(self.auth_token)\n        credentials = store.get()\n\n        if not credentials or credentials.invalid:\n            try:\n                flow = client.flow_from_clientsecrets(self.client_secret, SCOPES)\n                flow.user_agent = APPLICATION_NAME\n                if flags:\n                    credentials = tools.run_flow(flow, store, flags)\n                else:  # Needed only for compatibility with Python 2.6\n                    credentials = tools.run(flow, store)\n            except clientsecrets.InvalidClientSecretsError:\n                raise Exception(\"missing client_secret\")\n            \"\"\"\n            Have to restart i3 after getting credentials to prevent bad output.\n            This only has to be done once on the first run of the module.\n            \"\"\"\n            self.py3.command_run(\"{} restart\".format(self.py3.get_wm_msg()))\n\n        return credentials", "response": "Gets valid user credentials from storage."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _authorize_credentials(self):\n        try:\n            http = self.credentials.authorize(httplib2.Http())\n            self.service = discovery.build(\"calendar\", \"v3\", http=http)\n            return True\n        except ServerNotFoundError:\n            return False", "response": "Fetches an access token by authorizing OAuth 2. 0 credentials."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_events(self):\n        self.last_update = datetime.datetime.now()\n        time_min = datetime.datetime.utcnow()\n        time_max = time_min + datetime.timedelta(hours=self.events_within_hours)\n        events = []\n\n        try:\n            eventsResult = (\n                self.service.events()\n                .list(\n                    calendarId=\"primary\",\n                    timeMax=time_max.isoformat() + \"Z\",  # 'Z' indicates UTC time\n                    timeMin=time_min.isoformat() + \"Z\",  # 'Z' indicates UTC time\n                    singleEvents=True,\n                    orderBy=\"startTime\",\n                )\n                .execute(num_retries=5)\n            )\n        except Exception:\n            return self.events or events\n        else:\n            for event in eventsResult.get(\"items\", []):\n                # filter out events that we did not accept (default)\n                # unless we organized them with no attendees\n                i_organized = event.get(\"organizer\", {}).get(\"self\", False)\n                has_attendees = event.get(\"attendees\", [])\n                for attendee in event.get(\"attendees\", []):\n                    if attendee.get(\"self\") is True:\n                        if attendee[\"responseStatus\"] in self.response:\n                            break\n                else:\n                    # we did not organize the event or we did not accept it\n                    if not i_organized or has_attendees:\n                        continue\n\n                # strip and lower case output if needed\n                for key in [\"description\", \"location\", \"summary\"]:\n                    event[key] = event.get(key, \"\").strip()\n                    if self.force_lowercase is True:\n                        event[key] = event[key].lower()\n\n                # ignore all day events if configured\n                if event[\"start\"].get(\"date\") is not None:\n                    if self.ignore_all_day_events:\n                        continue\n\n                # filter out blacklisted event names\n                if event[\"summary\"] is not None:\n                    if event[\"summary\"].lower() in map(\n                        lambda e: e.lower(), self.blacklist_events\n                    ):\n                        continue\n\n                events.append(event)\n\n        return events[: self.num_events]", "response": "Fetches the events from the calendar into a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the time until an event starts is less than or equal to the warn_threshold. If True issue a warning with self. py3. notify_user.", "response": "def _check_warn_threshold(self, time_to, event_dict):\n        \"\"\"\n        Checks if the time until an event starts is less than or equal to the\n        warn_threshold. If True, issue a warning with self.py3.notify_user.\n        \"\"\"\n        if time_to[\"total_minutes\"] <= self.warn_threshold:\n            warn_message = self.py3.safe_format(self.format_notification, event_dict)\n            self.py3.notify_user(warn_message, \"warning\", self.warn_timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns in a dict the number of days hours minutes and total minutes until date_time.", "response": "def _delta_time(self, date_time):\n        \"\"\"\n        Returns in a dict the number of days/hours/minutes and total minutes\n        until date_time.\n        \"\"\"\n        now = datetime.datetime.now(tzlocal())\n        diff = date_time - now\n\n        days = int(diff.days)\n        hours = int(diff.seconds / 3600)\n        minutes = int((diff.seconds / 60) - (hours * 60)) + 1\n        total_minutes = int((diff.seconds / 60) + (days * 24 * 60)) + 1\n\n        return {\n            \"days\": days,\n            \"hours\": hours,\n            \"minutes\": minutes,\n            \"total_minutes\": total_minutes,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the dict time_delta to containg days hours and minutes until an ancipline event starts into a composite according to time_to_formatted.", "response": "def _format_timedelta(self, index, time_delta, is_current):\n        \"\"\"\n        Formats the dict time_to containg days/hours/minutes until an\n        event starts into a composite according to time_to_formatted.\n\n        Returns: A formatted composite.\n        \"\"\"\n        time_delta_formatted = \"\"\n\n        if time_delta[\"total_minutes\"] <= self.time_to_max:\n            time_delta_formatted = self.py3.safe_format(\n                self.format_timer,\n                {\n                    \"days\": time_delta[\"days\"],\n                    \"hours\": time_delta[\"hours\"],\n                    \"minutes\": time_delta[\"minutes\"],\n                    \"is_current\": is_current,\n                },\n            )\n\n        return time_delta_formatted"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the composite response for the module by looping through all events and formatting the necessary strings.", "response": "def _build_response(self):\n        \"\"\"\n        Builds the composite reponse to be output by the module by looping\n        through all events and formatting the necessary strings.\n\n        Returns: A composite containing the individual response for each event.\n        \"\"\"\n        responses = []\n        self.event_urls = []\n\n        for index, event in enumerate(self.events):\n            self.py3.threshold_get_color(index + 1, \"event\")\n            self.py3.threshold_get_color(index + 1, \"time\")\n\n            event_dict = {}\n\n            event_dict[\"summary\"] = event.get(\"summary\")\n            event_dict[\"location\"] = event.get(\"location\")\n            event_dict[\"description\"] = event.get(\"description\")\n            self.event_urls.append(event[\"htmlLink\"])\n\n            if event[\"start\"].get(\"date\") is not None:\n                start_dt = self._gstr_to_date(event[\"start\"].get(\"date\"))\n                end_dt = self._gstr_to_date(event[\"end\"].get(\"date\"))\n            else:\n                start_dt = self._gstr_to_datetime(event[\"start\"].get(\"dateTime\"))\n                end_dt = self._gstr_to_datetime(event[\"end\"].get(\"dateTime\"))\n\n            if end_dt < datetime.datetime.now(tzlocal()):\n                continue\n\n            event_dict[\"start_time\"] = self._datetime_to_str(start_dt, self.format_time)\n            event_dict[\"end_time\"] = self._datetime_to_str(end_dt, self.format_time)\n\n            event_dict[\"start_date\"] = self._datetime_to_str(start_dt, self.format_date)\n            event_dict[\"end_date\"] = self._datetime_to_str(end_dt, self.format_date)\n\n            time_delta = self._delta_time(start_dt)\n            if time_delta[\"days\"] < 0:\n                time_delta = self._delta_time(end_dt)\n                is_current = True\n            else:\n                is_current = False\n\n            event_dict[\"format_timer\"] = self._format_timedelta(\n                index, time_delta, is_current\n            )\n\n            if self.warn_threshold > 0:\n                self._check_warn_threshold(time_delta, event_dict)\n\n            event_formatted = self.py3.safe_format(\n                self.format_event,\n                {\n                    \"is_toggled\": self.button_states[index],\n                    \"summary\": event_dict[\"summary\"],\n                    \"location\": event_dict[\"location\"],\n                    \"description\": event_dict[\"description\"],\n                    \"start_time\": event_dict[\"start_time\"],\n                    \"end_time\": event_dict[\"end_time\"],\n                    \"start_date\": event_dict[\"start_date\"],\n                    \"end_date\": event_dict[\"end_date\"],\n                    \"format_timer\": event_dict[\"format_timer\"],\n                },\n            )\n\n            self.py3.composite_update(event_formatted, {\"index\": index})\n            responses.append(event_formatted)\n\n            self.no_update = False\n\n        format_separator = self.py3.safe_format(self.format_separator)\n        self.py3.composite_update(format_separator, {\"index\": \"sep\"})\n        responses = self.py3.composite_join(format_separator, responses)\n\n        return {\"events\": responses}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef command_parser():\n\n    class Parser(argparse.ArgumentParser):\n        # print usages and exit on errors\n        def error(self, message):\n            print(\"\\x1b[1;31merror: \\x1b[0m{}\".format(message))\n            self.print_help()\n            self.exit(1)\n\n        # hide choices on errors\n        def _check_value(self, action, value):\n            if action.choices is not None and value not in action.choices:\n                raise argparse.ArgumentError(\n                    action, \"invalid choice: '{}'\".format(value)\n                )\n\n    # make parser\n    parser = Parser(formatter_class=argparse.RawTextHelpFormatter)\n\n    # parser: add verbose, version\n    for short, name, msg in INFORMATION:\n        short = \"-%s\" % short\n        arg = \"--%s\" % name\n        parser.add_argument(short, arg, action=\"store_true\", help=msg)\n\n    # make subparsers // ALIAS_DEPRECATION: remove metavar later\n    metavar = \"{click,list,refresh}\"\n    subparsers = parser.add_subparsers(dest=\"command\", metavar=metavar)\n    sps = {}\n\n    # subparsers: add click, list, refresh... hide docstring\n    data = {\"formatter_class\": argparse.RawTextHelpFormatter}\n    for name, msg, nargs in SUBPARSERS:\n        data.update({\"epilog\": EPILOGS[name], \"help\": msg})\n        # don't show docstring in py3-cmd --help\n        if name in [\"docstring\"]:\n            del data[\"help\"]\n        sps[name] = subparsers.add_parser(name, **data)\n        sps[name].add_argument(nargs=nargs, dest=\"module\", help=\"module name\")\n\n    # ALIAS_DEPRECATION: subparsers: add click (aliases)\n    buttons = {\n        \"leftclick\": 1,\n        \"middleclick\": 2,\n        \"rightclick\": 3,\n        \"scrollup\": 4,\n        \"scrolldown\": 5,\n    }\n    for name in sorted(buttons):\n        sps[name] = subparsers.add_parser(name)\n        sps[name].add_argument(nargs=\"+\", dest=\"module\", help=\"module name\")\n\n    # click subparser: add button, index, width, height, relative_{x,y}, x, y\n    sp = sps[\"click\"]\n    for name, msg in CLICK_OPTIONS:\n        arg = \"--{}\".format(name)\n        if name == \"button\":\n            sp.add_argument(arg, metavar=\"INT\", type=int, help=msg, default=1)\n        elif name == \"index\":\n            sp.add_argument(arg, metavar=\"INDEX\", help=msg)\n        elif name == \"modifiers\":\n            sp.add_argument(arg, metavar=\"KEY\", help=msg)\n        else:\n            sp.add_argument(arg, metavar=\"INT\", type=int, help=msg)\n\n    # docstring subparser: add check, diff, update\n    sp = sps[\"docstring\"]\n    for name, msg in DOCSTRING_OPTIONS:\n        arg = \"--{}\".format(name)\n        sp.add_argument(arg, action=\"store_true\", help=msg)\n\n    # refresh subparser: add all\n    sp = sps[\"refresh\"]\n    for name, msg in REFRESH_OPTIONS:\n        arg = \"--{}\".format(name)\n        sp.add_argument(arg, action=\"store_true\", help=msg)\n\n    # list subparser: add all, core, user, full\n    sp = sps[\"list\"]\n    for short, name, msg in LIST_OPTIONS:\n        name = \"--{}\".format(name)\n        if short:\n            short = \"-{}\".format(short)\n            sp.add_argument(short, name, action=\"store_true\", help=msg)\n        else:\n            sp.add_argument(name, action=\"store_true\", help=msg)\n\n    # parse args, post-processing\n    options = parser.parse_args()\n\n    if options.command == \"click\":\n        # cast string index to int\n        if options.index:\n            try:\n                options.index = int(options.index)\n            except ValueError:\n                pass\n        # specify modifiers, optionally joined by plus signs\n        if options.modifiers:\n            options.modifiers = options.modifiers.split(\"+\")\n        else:\n            options.modifiers = []\n    elif options.command == \"refresh\":\n        # refresh all\n        # ALL_DEPRECATION\n        if options.module is None:\n            options.module = []\n        # end\n        valid = False\n        if options.all:  # keep this\n            options.command = \"refresh_all\"\n            options.module = []\n            valid = True\n        if \"all\" in options.module:  # remove this later\n            options.command = \"refresh_all\"\n            options.module = []\n            valid = True\n        if not options.module and not valid:\n            sps[\"refresh\"].error(\"missing positional or optional arguments\")\n    elif options.command in [\"list\", \"docstring\"]:\n        parse_list_or_docstring(options, sps)\n        parser.exit()\n    elif options.version:\n        # print version\n        from platform import python_version\n        from py3status.version import version\n\n        print(\"py3status {} (python {})\".format(version, python_version()))\n        parser.exit()\n    elif not options.command:\n        parser.error(\"too few arguments\")\n\n    # ALIAS_DEPRECATION\n    alias = options.command in buttons\n\n    # py3-cmd click 3 dpms ==> py3-cmd click --button 3 dpms\n    new_modules = []\n    for index, name in enumerate(options.module):\n        if name.isdigit():\n            if alias:\n                continue\n            if not index:  # zero index\n                options.button = int(name)\n        else:\n            new_modules.append(name)\n\n    # ALIAS_DEPRECATION: Convert (click) aliases to buttons\n    if alias:\n        options.button = buttons[options.command]\n        options.command = \"click\"\n\n    if options.command == \"click\" and not new_modules:\n        sps[options.command].error(\"too few arguments\")\n    options.module = new_modules\n\n    return options", "response": "build and return our command parser"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling py3 - cmd list and docstring options.", "response": "def parse_list_or_docstring(options, sps):\n    \"\"\"\n    Handle py3-cmd list and docstring options.\n    \"\"\"\n    import py3status.docstrings as docstrings\n\n    # HARDCODE: make include path to search for user modules\n    home_path = os.path.expanduser(\"~\")\n    xdg_home_path = os.environ.get(\"XDG_CONFIG_HOME\", \"{}/.config\".format(home_path))\n    options.include_paths = [\n        \"{}/py3status/modules\".format(xdg_home_path),\n        \"{}/i3status/py3status\".format(xdg_home_path),\n        \"{}/i3/py3status\".format(xdg_home_path),\n        \"{}/.i3/py3status\".format(home_path),\n    ]\n    include_paths = []\n    for path in options.include_paths:\n        path = os.path.abspath(path)\n        if os.path.isdir(path) and os.listdir(path):\n            include_paths.append(path)\n    options.include_paths = include_paths\n\n    # init\n    config = vars(options)\n    modules = [x.rsplit(\".py\", 1)[0] for x in config[\"module\"]]\n\n    # list module names and details\n    if config[\"command\"] == \"list\":\n        tests = [not config[x] for x in [\"all\", \"user\", \"core\"]]\n        if all([not modules] + tests):\n            msg = \"missing positional or optional arguments\"\n            sps[\"list\"].error(msg)\n        docstrings.show_modules(config, modules)\n\n    # docstring formatting and checking\n    elif config[\"command\"] == \"docstring\":\n        if config[\"check\"]:\n            docstrings.check_docstrings(False, config, modules)\n        elif config[\"diff\"]:\n            docstrings.check_docstrings(True, config, None)\n        elif config[\"update\"]:\n            if not modules:\n                msg = \"missing positional arguments or `modules`\"\n                sps[\"docstring\"].error(msg)\n            if \"modules\" in modules:\n                docstrings.update_docstrings()\n            else:\n                docstrings.update_readme_for_modules(modules)\n        else:\n            msg = \"missing positional or optional arguments\"\n            sps[\"docstring\"].error(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_command():\n\n    def verbose(msg):\n        \"\"\"\n        print output if verbose is set.\n        \"\"\"\n        if options.verbose:\n            print(msg)\n\n    options = command_parser()\n    msg = json.dumps(vars(options)).encode(\"utf-8\")\n    if len(msg) > MAX_SIZE:\n        verbose(\"Message length too long, max length (%s)\" % MAX_SIZE)\n\n    # find all likely socket addresses\n    uds_list = glob.glob(\"{}.[0-9]*\".format(SERVER_ADDRESS))\n\n    verbose('message \"%s\"' % msg)\n    for uds in uds_list:\n        # Create a UDS socket\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n\n        # Connect the socket to the port where the server is listening\n        verbose(\"connecting to %s\" % uds)\n        try:\n            sock.connect(uds)\n        except socket.error:\n            # this is a stale socket so delete it\n            verbose(\"stale socket deleting\")\n            try:\n                os.unlink(uds)\n            except OSError:\n                pass\n            continue\n        try:\n            # Send data\n            verbose(\"sending\")\n            sock.sendall(msg)\n        finally:\n            verbose(\"closing socket\")\n            sock.close()", "response": "Send a command to all uds sockets."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the modules given the name list", "response": "def find_modules(self, requested_names):\n        \"\"\"\n        find the module(s) given the name(s)\n        \"\"\"\n        found_modules = set()\n        for requested_name in requested_names:\n            is_instance = \" \" in requested_name\n\n            for module_name, module in self.py3_wrapper.output_modules.items():\n                if module[\"type\"] == \"py3status\":\n                    name = module[\"module\"].module_nice_name\n                else:\n                    name = module[\"module\"].module_name\n                if is_instance:\n                    if requested_name == name:\n                        found_modules.add(module_name)\n                else:\n                    if requested_name == name.split(\" \")[0]:\n                        found_modules.add(module_name)\n\n        if self.debug:\n            self.py3_wrapper.log(\"found %s\" % found_modules)\n        return found_modules"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the modules and i3status output", "response": "def refresh(self, data):\n        \"\"\"\n        refresh the module(s)\n        \"\"\"\n        modules = data.get(\"module\")\n        # for i3status modules we have to refresh the whole i3status output.\n        update_i3status = False\n        for module_name in self.find_modules(modules):\n            module = self.py3_wrapper.output_modules[module_name]\n            if self.debug:\n                self.py3_wrapper.log(\"refresh %s\" % module)\n            if module[\"type\"] == \"py3status\":\n                module[\"module\"].force_update()\n            else:\n                update_i3status = True\n        if update_i3status:\n            self.py3_wrapper.i3status_thread.refresh_i3status()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef click(self, data):\n        modules = data.get(\"module\")\n        for module_name in self.find_modules(modules):\n            module = self.py3_wrapper.output_modules[module_name]\n            if module[\"type\"] == \"py3status\":\n                name = module[\"module\"].module_name\n                instance = module[\"module\"].module_inst\n            else:\n                name = module[\"module\"].name\n                instance = module[\"module\"].instance\n            # make an event\n            event = {\"name\": name, \"instance\": instance}\n            for name, message in CLICK_OPTIONS:\n                event[name] = data.get(name)\n\n            if self.debug:\n                self.py3_wrapper.log(event)\n            # trigger the event\n            self.py3_wrapper.events_thread.dispatch_event(event)", "response": "send a click event to the modules"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the given command and send to the correct dispatcher", "response": "def run_command(self, data):\n        \"\"\"\n        check the given command and send to the correct dispatcher\n        \"\"\"\n        command = data.get(\"command\")\n        if self.debug:\n            self.py3_wrapper.log(\"Running remote command %s\" % command)\n        if command == \"refresh\":\n            self.refresh(data)\n        elif command == \"refresh_all\":\n            self.py3_wrapper.refresh_modules()\n        elif command == \"click\":\n            self.click(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kill(self):\n        try:\n            os.unlink(self.server_address)\n        except OSError:\n            if os.path.exists(self.server_address):\n                raise", "response": "Remove the socket as it is no longer needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        while True:\n            try:\n                data = None\n                # Wait for a connection\n                if self.debug:\n                    self.py3_wrapper.log(\"waiting for a connection\")\n\n                connection, client_address = self.sock.accept()\n                try:\n                    if self.debug:\n                        self.py3_wrapper.log(\"connection from\")\n\n                    data = connection.recv(MAX_SIZE)\n                    if data:\n                        data = json.loads(data.decode(\"utf-8\"))\n                        if self.debug:\n                            self.py3_wrapper.log(u\"received %s\" % data)\n                        self.command_runner.run_command(data)\n                finally:\n                    # Clean up the connection\n                    connection.close()\n            except Exception:\n                if data:\n                    self.py3_wrapper.log(\"Command error\")\n                    self.py3_wrapper.log(data)\n                self.py3_wrapper.report_exception(\"command failed\")", "response": "This method is run in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _change_volume(self, increase):\n        sign = \"+\" if increase else \"-\"\n        delta = \"%d%%%s\" % (self.volume_tick, sign)\n        self._run([\"amixer\", \"-q\", \"sset\", \"Master\", delta])", "response": "Change volume using amixer"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetects running player process and return the name of the first player that is available.", "response": "def _detect_running_player(self):\n        \"\"\"Detect running player process, if any\n        \"\"\"\n        supported_players = self.supported_players.split(\",\")\n        running_players = []\n        for pid in os.listdir(\"/proc\"):\n            if not pid.isdigit():\n                continue\n\n            fn = os.path.join(\"/proc\", pid, \"comm\")\n            try:\n                with open(fn, \"rb\") as f:\n                    player_name = f.read().decode().rstrip()\n            except:  # noqa e722\n                # (IOError, FileNotFoundError):  # (assumed py2, assumed py3)\n                continue\n\n            if player_name in supported_players:\n                running_players.append(player_name)\n\n        # Pick which player to use based on the order in self.supported_players\n        for player_name in supported_players:\n            if player_name in running_players:\n                if self.debug:\n                    self.py3.log(\"found player: %s\" % player_name)\n\n                # those players need the dbus module\n                if player_name in (\"vlc\") and not dbus_available:\n                    self.py3.log(\"%s requires the dbus python module\" % player_name)\n                    return None\n\n                return player_name\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset next cycle update time synced to nearest second or 0. 1 of second.", "response": "def _set_cycle_time(self):\n        \"\"\"\n        Set next cycle update time synced to nearest second or 0.1 of second.\n        \"\"\"\n        now = time()\n        try:\n            cycle_time = now - self._cycle_time\n            if cycle_time < 0:\n                cycle_time = 0\n        except AttributeError:\n            cycle_time = 0\n        cycle_time += self.cycle_time\n        if cycle_time == int(cycle_time):\n            self._cycle_time = math.ceil(now + cycle_time)\n        else:\n            self._cycle_time = math.ceil((now + cycle_time) * 10) / 10\n        self._cycle_time = now + self.cycle_time"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_current_output(self):\n        output = []\n        for item in self.items:\n            out = self.py3.get_output(item)\n            if out and \"separator\" not in out[-1]:\n                out[-1][\"separator\"] = True\n            output += out\n        return output", "response": "Get child modules output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a custom color for a given module name.", "response": "def get_color_for_name(module_name):\n    \"\"\"\n    Create a custom color for a given string.\n    This allows the screenshots to each have a unique color but also for that\n    color to be consistent.\n    \"\"\"\n    # all screenshots of the same module should be a uniform color\n    module_name = module_name.split(\"-\")[0]\n\n    saturation = 0.5\n    value = 243.2\n    try:\n        # we must be bytes to allow the md5 hash to be calculated\n        module_name = module_name.encode(\"utf-8\")\n    except AttributeError:\n        pass\n    hue = int(md5(module_name).hexdigest(), 16) / 16 ** 32\n    hue *= 6\n    hue += 3.708\n    r, g, b = (\n        (\n            value,\n            value - value * saturation * abs(1 - hue % 2),\n            value - value * saturation,\n        )\n        * 3\n    )[5 ** int(hue) // 3 % 3 :: int(hue) % 2 + 1][:3]\n    return \"#\" + \"%02x\" * 3 % (int(r), int(g), int(b))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npillow only looks for glyphs in the font used so we need to make sure that the glyph is not found in the font.", "response": "def contains_bad_glyph(glyph_data, data):\n    \"\"\"\n    Pillow only looks for glyphs in the font used so we need to make sure our\n    font has the glygh.  Although we could substitute a glyph from another font\n    eg symbola but this adds more complexity and is of limited value.\n    \"\"\"\n\n    def check_glyph(char):\n        for cmap in glyph_data[\"cmap\"].tables:\n            if cmap.isUnicode():\n                if char in cmap.cmap:\n                    return True\n        return False\n\n    for part in data:\n        text = part.get(\"full_text\", \"\")\n        try:\n            # for python 2\n            text = text.decode(\"utf8\")\n        except AttributeError:\n            pass\n\n        for char in text:\n            if not check_glyph(ord(char)):\n                # we have not found a character in the font\n                print(u\"%s (%s) missing\" % (char, ord(char)))\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate screenshot of py3status output and save to path", "response": "def create_screenshot(name, data, path, font, is_module):\n    \"\"\"\n    Create screenshot of py3status output and save to path\n    \"\"\"\n    desktop_color = get_color_for_name(name)\n\n    # if this screenshot is for a module then add modules name etc\n    if is_module:\n        data.append(\n            {\"full_text\": name.split(\"-\")[0], \"color\": desktop_color, \"separator\": True}\n        )\n        data.append(\n            {\"full_text\": \"py3status\", \"color\": COLOR_PY3STATUS, \"separator\": True}\n        )\n\n    img = Image.new(\"RGB\", (WIDTH, HEIGHT), COLOR_BG)\n    d = ImageDraw.Draw(img)\n\n    # top bar\n    d.rectangle((0, 0, WIDTH, TOP_BAR_HEIGHT), fill=desktop_color)\n    x = X_OFFSET\n\n    # add text and separators\n    for part in reversed(data):\n        text = part.get(\"full_text\")\n        color = part.get(\"color\", COLOR)\n        background = part.get(\"background\")\n        separator = part.get(\"separator\")\n        urgent = part.get(\"urgent\")\n\n        # urgent background\n        if urgent:\n            color = COLOR_URGENT\n            background = COLOR_URGENT_BG\n\n        size = font.getsize(text)\n\n        if background:\n            d.rectangle(\n                (\n                    WIDTH - x - (size[0] // SCALE),\n                    TOP_BAR_HEIGHT + PADDING,\n                    WIDTH - x - 1,\n                    HEIGHT - PADDING,\n                ),\n                fill=background,\n            )\n\n        x += size[0] // SCALE\n\n        txt = Image.new(\"RGB\", size, background or COLOR_BG)\n        d_text = ImageDraw.Draw(txt)\n        d_text.text((0, 0), text, font=font, fill=color)\n        # resize to actual size wanted and add to image\n        txt = txt.resize((size[0] // SCALE, size[1] // SCALE), Image.ANTIALIAS)\n        img.paste(txt, (WIDTH - x, TOP_BAR_HEIGHT + PADDING))\n\n        if separator:\n            x += SEP_PADDING_RIGHT\n            d.line(\n                (\n                    (WIDTH - x, TOP_BAR_HEIGHT + PADDING),\n                    (WIDTH - x, TOP_BAR_HEIGHT + 1 + PADDING + FONT_SIZE),\n                ),\n                fill=COLOR_SEP,\n                width=1,\n            )\n            x += SEP_PADDING_LEFT\n\n    img.save(os.path.join(path, \"%s.png\" % name))\n    print(\" %s.png\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_sample_data(sample_data, module_name):\n    samples = {}\n    for index, chunk in enumerate(sample_data.split(\"\\n\\n\")):\n        chunk = \"{}-{}-{}\".format(module_name, index, chunk)\n        name, sample = re.split(\"-?\\n\", chunk, 1)\n        try:\n            samples[name] = ast.literal_eval(sample)\n        except SyntaxError:\n            samples[name] = SAMPLE_DATA_ERROR\n    return samples", "response": "Parse sample output definitions and return a dict\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlooks in all core modules and get any samples from the docstrings", "response": "def get_samples():\n    \"\"\"\n    Look in all core modules and get any samples from the docstrings.\n    return a dict {screenshot_name: sample_output}\n    \"\"\"\n    samples = {}\n    module_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"modules\")\n    for file in sorted(os.listdir(module_dir)):\n        if file.endswith(\".py\") and file != \"__init__.py\":\n            #  remove .py\n            module_name = file[:-3]\n            with open(os.path.join(module_dir, file), \"r\") as f:\n                try:\n                    module = ast.parse(f.read())\n                except SyntaxError:\n                    continue\n                raw_docstring = ast.get_docstring(module)\n                if raw_docstring is None:\n                    continue\n                parts = re.split(\"^SAMPLE OUTPUT$\", raw_docstring, flags=re.M)\n                if len(parts) == 1:\n                    continue\n                sample_data = parts[1]\n                samples.update(parse_sample_data(sample_data, module_name))\n    return samples"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process(name, path, data, module=True):\n    # create dir if not exists\n    try:\n        os.makedirs(path)\n    except OSError:\n        pass\n\n    global font, glyph_data\n    if font is None:\n        font = ImageFont.truetype(FONT, FONT_SIZE * SCALE)\n    if glyph_data is None:\n        glyph_data = TTFont(font.path)\n\n    # make sure that the data is in list form\n    if not isinstance(data, list):\n        data = [data]\n\n    if contains_bad_glyph(glyph_data, data):\n        print(\"** %s has characters not in %s **\" % (name, font.getname()[0]))\n    else:\n        create_screenshot(name, data, path, font=font, is_module=module)", "response": "Process data to create a screenshot which will be saved in docs / screenshots/<name >. png\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate screenshots for all core modules.", "response": "def create_screenshots(quiet=False):\n    \"\"\"\n    create screenshots for all core modules.\n    The screenshots directory will have all .png files deleted before new shots\n    are created.\n    \"\"\"\n    if os.environ.get(\"READTHEDOCS\") == \"True\":\n        path = \"../doc/screenshots\"\n    else:\n        path = os.path.join(\n            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),\n            \"doc/screenshots\",\n        )\n\n    print(\"Creating screenshots...\")\n    samples = get_samples()\n    for name, data in sorted(samples.items()):\n        process(name, path, data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_cli_args():\n    # get config paths\n    home_path = os.path.expanduser(\"~\")\n    xdg_home_path = os.environ.get(\"XDG_CONFIG_HOME\", \"{}/.config\".format(home_path))\n    xdg_dirs_path = os.environ.get(\"XDG_CONFIG_DIRS\", \"/etc/xdg\")\n\n    # get i3status path\n    try:\n        with open(os.devnull, \"w\") as devnull:\n            command = [\"which\", \"i3status\"]\n            i3status_path = (\n                subprocess.check_output(command, stderr=devnull).decode().strip()\n            )\n    except subprocess.CalledProcessError:\n        i3status_path = None\n\n    # get window manager\n    with open(os.devnull, \"w\") as devnull:\n        if subprocess.call([\"pgrep\", \"i3\"], stdout=devnull) == 0:\n            wm = \"i3\"\n        else:\n            wm = \"sway\"\n\n    # i3status config file default detection\n    # respect i3status' file detection order wrt issue #43\n    i3status_config_file_candidates = [\n        \"{}/py3status/config\".format(xdg_home_path),\n        \"{}/i3status/config\".format(xdg_home_path),\n        \"{}/i3/i3status.conf\".format(xdg_home_path),  # custom\n        \"{}/.i3status.conf\".format(home_path),\n        \"{}/.i3/i3status.conf\".format(home_path),  # custom\n        \"{}/i3status/config\".format(xdg_dirs_path),\n        \"/etc/i3status.conf\",\n    ]\n    for fn in i3status_config_file_candidates:\n        if os.path.isfile(fn):\n            i3status_config_file_default = fn\n            break\n    else:\n        # if files does not exists, defaults to ~/.i3/i3status.conf\n        i3status_config_file_default = i3status_config_file_candidates[3]\n\n    class Parser(argparse.ArgumentParser):\n        # print usages and exit on errors\n        def error(self, message):\n            print(\"\\x1b[1;31merror: \\x1b[0m{}\".format(message))\n            self.print_help()\n            self.exit(1)\n\n        # hide choices on errors\n        def _check_value(self, action, value):\n            if action.choices is not None and value not in action.choices:\n                raise argparse.ArgumentError(\n                    action, \"invalid choice: '{}'\".format(value)\n                )\n\n    class HelpFormatter(argparse.ArgumentDefaultsHelpFormatter):\n        def _format_action_invocation(self, action):\n            metavar = self._format_args(action, action.dest.upper())\n            return \"{} {}\".format(\", \".join(action.option_strings), metavar)\n\n    # command line options\n    parser = Parser(\n        description=\"The agile, python-powered, i3status wrapper\",\n        formatter_class=HelpFormatter,\n    )\n    parser.add_argument(\n        \"-b\",\n        \"--dbus-notify\",\n        action=\"store_true\",\n        dest=\"dbus_notify\",\n        help=\"send notifications via dbus instead of i3-nagbar\",\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--config\",\n        action=\"store\",\n        default=i3status_config_file_default,\n        dest=\"i3status_config_path\",\n        help=\"load config\",\n        metavar=\"FILE\",\n        type=str,\n    )\n    parser.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"enable debug logging in syslog and --log-file\",\n    )\n    parser.add_argument(\n        \"-g\",\n        \"--gevent\",\n        action=\"store_true\",\n        dest=\"gevent\",\n        help=\"enable gevent monkey patching\",\n    )\n    parser.add_argument(\n        \"-i\",\n        \"--include\",\n        action=\"append\",\n        dest=\"include_paths\",\n        help=\"append additional user-defined module paths\",\n        metavar=\"PATH\",\n    )\n    parser.add_argument(\n        \"-l\",\n        \"--log-file\",\n        action=\"store\",\n        dest=\"log_file\",\n        help=\"enable logging to FILE\",\n        metavar=\"FILE\",\n        type=str,\n    )\n    parser.add_argument(\n        \"-s\",\n        \"--standalone\",\n        action=\"store_true\",\n        dest=\"standalone\",\n        help=\"run py3status without i3status\",\n    )\n    parser.add_argument(\n        \"-t\",\n        \"--timeout\",\n        action=\"store\",\n        default=60,\n        dest=\"cache_timeout\",\n        help=\"default module cache timeout in seconds\",\n        metavar=\"INT\",\n        type=int,\n    )\n    parser.add_argument(\n        \"-m\",\n        \"--disable-click-events\",\n        action=\"store_true\",\n        dest=\"disable_click_events\",\n        help=\"disable all click events\",\n    )\n    parser.add_argument(\n        \"-u\",\n        \"--i3status\",\n        action=\"store\",\n        default=i3status_path,\n        dest=\"i3status_path\",\n        help=\"specify i3status path\",\n        metavar=\"PATH\",\n        type=str,\n    )\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"store_true\",\n        dest=\"print_version\",\n        help=\"show py3status version and exit\",\n    )\n    parser.add_argument(\n        \"--wm\",\n        action=\"store\",  # add comment to preserve formatting\n        dest=\"wm\",\n        metavar=\"WINDOW_MANAGER\",\n        default=wm,\n        choices=[\"i3\", \"sway\"],\n        help=\"specify window manager i3 or sway\",\n    )\n\n    # deprecations\n    parser.add_argument(\"-n\", \"--interval\", help=argparse.SUPPRESS)\n\n    # parse options, command, etc\n    options = parser.parse_args()\n\n    # make versions\n    options.python_version = python_version()\n    options.version = version\n    if options.print_version:\n        msg = \"py3status version {version} (python {python_version}) on {wm}\"\n        print(msg.format(**vars(options)))\n        parser.exit()\n\n    # get wm\n    options.wm_name = options.wm\n    options.wm = {\n        \"i3\": {\"msg\": \"i3-msg\", \"nag\": \"i3-nagbar\"},\n        \"sway\": {\"msg\": \"swaymsg\", \"nag\": \"swaynag\"},\n    }[options.wm]\n\n    # make it i3status if None\n    if not options.i3status_path:\n        options.i3status_path = \"i3status\"\n\n    # make include path to search for user modules if None\n    if not options.include_paths:\n        options.include_paths = [\n            \"{}/py3status/modules\".format(xdg_home_path),\n            \"{}/i3status/py3status\".format(xdg_home_path),\n            \"{}/i3/py3status\".format(xdg_home_path),\n            \"{}/.i3/py3status\".format(home_path),\n        ]\n\n    include_paths = []\n    for path in options.include_paths:\n        path = os.path.abspath(path)\n        if os.path.isdir(path) and os.listdir(path):\n            include_paths.append(path)\n    options.include_paths = include_paths\n\n    # defaults\n    del options.interval\n    del options.print_version\n    options.minimum_interval = 0.1  # minimum module update interval\n    options.click_events = not options.__dict__.pop(\"disable_click_events\")\n\n    # all done\n    return options", "response": "Parse the command line arguments of the i3status command line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the i3status. conf file and return a dict of the i3status config.", "response": "def process_config(config_path, py3_wrapper=None):\n    \"\"\"\n    Parse i3status.conf so we can adapt our code to the i3status config.\n    \"\"\"\n\n    def notify_user(error):\n        if py3_wrapper:\n            py3_wrapper.notify_user(error)\n        else:\n            print(error)\n\n    def parse_config(config):\n        \"\"\"\n        Parse text or file as a py3status config file.\n        \"\"\"\n\n        if hasattr(config, \"readlines\"):\n            config = \"\".join(config.readlines())\n        parser = ConfigParser(config, py3_wrapper)\n        parser.parse()\n        parsed = parser.config\n        del parser\n        return parsed\n\n    def parse_config_error(e, config_path):\n        # There was a problem use our special error config\n        error = e.one_line(config_path)\n        notify_user(error)\n        # to display correctly in i3bar we need to do some substitutions\n        for char in ['\"', \"{\", \"|\"]:\n            error = error.replace(char, \"\\\\\" + char)\n        error_config = Template(ERROR_CONFIG).substitute(error=error)\n        return parse_config(error_config)\n\n    config = {}\n\n    # get the file encoding this is important with multi-byte unicode chars\n    try:\n        encoding = check_output(\n            [\"file\", \"-b\", \"--mime-encoding\", \"--dereference\", config_path]\n        )\n        encoding = encoding.strip().decode(\"utf-8\")\n    except CalledProcessError:\n        # bsd does not have the --mime-encoding so assume utf-8\n        encoding = \"utf-8\"\n    try:\n        with codecs.open(config_path, \"r\", encoding) as f:\n            try:\n                config_info = parse_config(f)\n            except ParseException as e:\n                config_info = parse_config_error(e, config_path)\n    except LookupError:\n        with codecs.open(config_path) as f:\n            try:\n                config_info = parse_config(f)\n            except ParseException as e:\n                config_info = parse_config_error(e, config_path)\n\n    # update general section with defaults\n    general_defaults = GENERAL_DEFAULTS.copy()\n    if \"general\" in config_info:\n        general_defaults.update(config_info[\"general\"])\n    config[\"general\"] = general_defaults\n\n    config[\"py3status\"] = config_info.get(\"py3status\", {})\n    modules = {}\n    on_click = {}\n    i3s_modules = []\n    py3_modules = []\n    module_groups = {}\n\n    def process_onclick(key, value, group_name):\n        \"\"\"\n        Check on_click events are valid.  Store if they are good\n        \"\"\"\n        button_error = False\n        button = \"\"\n        try:\n            button = key.split()[1]\n            if int(button) not in range(1, 20):\n                button_error = True\n        except (ValueError, IndexError):\n            button_error = True\n\n        if button_error:\n            err = \"Invalid on_click for `{}`. Number not in range 1-20: `{}`.\"\n            notify_user(err.format(group_name, button))\n            return False\n        clicks = on_click.setdefault(group_name, {})\n        clicks[button] = value\n        return True\n\n    def get_module_type(name):\n        \"\"\"\n        i3status or py3status?\n        \"\"\"\n        if name.split()[0] in I3S_MODULE_NAMES:\n            return \"i3status\"\n        return \"py3status\"\n\n    def process_module(name, module, parent):\n        if parent:\n            modules[parent][\"items\"].append(name)\n            mg = module_groups.setdefault(name, [])\n            mg.append(parent)\n            if get_module_type(name) == \"py3status\":\n                module[\".group\"] = parent\n\n        # check module content\n        for k, v in list(module.items()):\n            if k.startswith(\"on_click\"):\n                # on_click event\n                process_onclick(k, v, name)\n                # on_click should not be passed to the module via the config.\n                del module[k]\n            if isinstance(v, ModuleDefinition):\n                # we are a container\n                module[\"items\"] = []\n        return module\n\n    def get_modules(data, parent=None):\n        for k, v in data.items():\n            if isinstance(v, ModuleDefinition):\n                module = process_module(k, v, parent)\n                modules[k] = module\n                get_modules(v, parent=k)\n\n    get_modules(config_info)\n\n    config[\"order\"] = []\n\n    def remove_any_contained_modules(module):\n        \"\"\"\n        takes a module definition and returns a dict without any modules that\n        may be defined with it.\n        \"\"\"\n        fixed = {}\n        for k, v in module.items():\n            if not isinstance(v, ModuleDefinition):\n                fixed[k] = v\n        return fixed\n\n    def append_modules(item):\n        module_type = get_module_type(item)\n        if module_type == \"i3status\":\n            if item not in i3s_modules:\n                i3s_modules.append(item)\n        else:\n            if item not in py3_modules:\n                py3_modules.append(item)\n\n    def add_container_items(module_name):\n        module = modules.get(module_name, {})\n        items = module.get(\"items\", [])\n        for item in items:\n            if item in config:\n                continue\n\n            append_modules(item)\n            module = modules.get(item, {})\n            config[item] = remove_any_contained_modules(module)\n            # add any children\n            add_container_items(item)\n\n    # create config for modules in order\n    for name in config_info.get(\"order\", []):\n        if name in module_groups:\n            msg = \"Module `{}` should not be listed in the 'order' directive, use\"\n            msg += \" its parent group instead.\"\n            notify_user(msg.format(name))\n            continue\n        module_name = name.split(\" \")[0]\n        if module_name in RETIRED_MODULES:\n            notify_user(\n                \"Module `{}` is no longer available\".format(module_name)\n                + \". Alternative modules are: {}.\".format(\n                    \", \".join(\"`{}`\".format(x) for x in RETIRED_MODULES[module_name])\n                )\n            )\n            continue\n        module = modules.get(name, {})\n        config[\"order\"].append(name)\n        add_container_items(name)\n        append_modules(name)\n\n        config[name] = remove_any_contained_modules(module)\n\n    config[\"on_click\"] = on_click\n    config[\"i3s_modules\"] = i3s_modules\n    config[\"py3_modules\"] = py3_modules\n    config[\".module_groups\"] = module_groups\n\n    # time and tztime modules need a format for correct processing\n    for name in config:\n        if name.split()[0] in TIME_MODULES and \"format\" not in config[name]:\n            if name.split()[0] == \"time\":\n                config[name][\"format\"] = TIME_FORMAT\n            else:\n                config[name][\"format\"] = TZTIME_FORMAT\n\n    if not config[\"order\"]:\n        notify_user(\n            \"Your configuration file does not list any module\"\n            ' to be loaded with the \"order\" directive.'\n        )\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_child_friendly(self, name):\n        name = name.split()[0]\n        if name in self.container_modules:\n            return\n        root = os.path.dirname(os.path.realpath(__file__))\n        module_path = os.path.join(root, \"modules\")\n        try:\n            info = imp.find_module(name, [module_path])\n        except ImportError:\n            return\n        if not info:\n            return\n        (file, pathname, description) = info\n        try:\n            py_mod = imp.load_module(name, file, pathname, description)\n        except Exception:\n            # We cannot load the module!  We could error out here but then the\n            # user gets informed that the problem is with their config.  This\n            # is not correct.  Better to say that all is well and then the\n            # config can get parsed and py3status loads.  The error about the\n            # failing module load is better handled at that point, and will be.\n            return\n        try:\n            container = py_mod.Py3status.Meta.container\n        except AttributeError:\n            container = False\n        # delete the module\n        del py_mod\n        if container:\n            self.container_modules.append(name)\n        else:\n            self.error(\"Module `{}` cannot contain others\".format(name))", "response": "Check if a module is a container and so can have children."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_module_name(self, name, offset=0):\n        if name in [\"general\"]:\n            return\n        split_name = name.split()\n        if len(split_name) > 1 and split_name[0] in I3S_SINGLE_NAMES:\n            self.current_token -= len(split_name) - 1 - offset\n            self.error(\"Invalid name cannot have 2 tokens\")\n        if len(split_name) > 2:\n            self.current_token -= len(split_name) - 2 - offset\n            self.error(\"Invalid name cannot have more than 2 tokens\")", "response": "Checks a module name eg. some i3status modules cannot have an instance name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef error(self, msg, previous=False):\n        token = self.tokens[self.current_token - 1]\n        line_no = self.line\n        if previous:\n            line_no -= 1\n        line = self.raw[line_no]\n        position = token[\"start\"] - self.line_start\n        if previous:\n            position = len(line) + 2\n        raise ParseException(msg, line, line_no + 1, position, token[\"value\"])", "response": "Raise a ParseException.\n        We provide information to help locate the error in the config to allow\n        easy config debugging for users.  previous indicates that the error\n        actually occurred at the end of the previous line."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tokenize(self, config):\n        tokens = []\n        reg_ex = re.compile(self.TOKENS[0], re.M | re.I)\n\n        for token in re.finditer(reg_ex, config):\n            value = token.group(0)\n            if token.group(\"operator\"):\n                t_type = \"operator\"\n            elif token.group(\"literal\"):\n                t_type = \"literal\"\n            elif token.group(\"newline\"):\n                t_type = \"newline\"\n            elif token.group(\"function\"):\n                t_type = \"function\"\n            elif token.group(\"unknown\"):\n                t_type = \"unknown\"\n            else:\n                continue\n            tokens.append(\n                {\"type\": t_type, \"value\": value, \"match\": token, \"start\": token.start()}\n            )\n        self.tokens = tokens", "response": "Break the config into a series of tokens\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the next token in the config.", "response": "def next(self):\n        \"\"\"\n        Return the next token.  Keep track of our current position in the\n        config for nice errors.\n        \"\"\"\n        if self.current_token == len(self.tokens):\n            return None\n        token = self.tokens[self.current_token]\n        if token[\"type\"] == \"newline\":\n            self.line += 1\n            self.line_start = token[\"start\"]\n        self.current_token += 1\n        if token[\"type\"] == \"unknown\":\n            self.error(\"Unknown token\")\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving any surrounding quotes from a value and unescape any contained quotes of that type.", "response": "def remove_quotes(self, value):\n        \"\"\"\n        Remove any surrounding quotes from a value and unescape any contained\n        quotes of that type.\n        \"\"\"\n        # beware the empty string\n        if not value:\n            return value\n\n        if value[0] == value[-1] == '\"':\n            return value[1:-1].replace('\\\\\"', '\"')\n        if value[0] == value[-1] == \"'\":\n            return value[1:-1].replace(\"\\\\'\", \"'\")\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfix unicode escape sequences in the config file.", "response": "def unicode_escape_sequence_fix(self, value):\n        \"\"\"\n        It is possible to define unicode characters in the config either as the\n        actual utf-8 character or using escape sequences the following all will\n        show the Greek delta character.\n        \u0394 \\N{GREEK CAPITAL LETTER DELTA} \\U00000394  \\u0394\n        \"\"\"\n\n        def fix_fn(match):\n            # we don't escape an escaped backslash\n            if match.group(0) == r\"\\\\\":\n                return r\"\\\\\"\n            return match.group(0).encode(\"utf-8\").decode(\"unicode-escape\")\n\n        return re.sub(r\"\\\\\\\\|\\\\u\\w{4}|\\\\U\\w{8}|\\\\N\\{([^}\\\\]|\\\\.)+\\}\", fix_fn, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert to actual value or remains as string.", "response": "def make_value(self, value):\n        \"\"\"\n        Converts to actual value, or remains as string.\n        \"\"\"\n        # ensure any escape sequences are converted to unicode\n        value = self.unicode_escape_sequence_fix(value)\n\n        if value and value[0] in ['\"', \"'\"]:\n            return self.remove_quotes(value)\n\n        try:\n            return int(value)\n        except ValueError:\n            pass\n        try:\n            return float(value)\n        except ValueError:\n            pass\n        if value.lower() == \"true\":\n            return True\n        if value.lower() == \"false\":\n            return False\n        if value.lower() == \"none\":\n            return None\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a config function from a token", "response": "def config_function(self, token):\n        \"\"\"\n        Process a config function from a token\n        \"\"\"\n        match = token[\"match\"]\n        function = match.group(2).lower()\n        param = match.group(3) or \"\"\n        value_type = match.group(6) or \"auto\"\n\n        # fix any escaped closing parenthesis\n        param = param.replace(r\"\\)\", \")\")\n\n        CONFIG_FUNCTIONS = {\n            \"base64\": self.make_function_value_private,\n            \"env\": self.make_value_from_env,\n            \"hide\": self.make_function_value_private,\n            \"shell\": self.make_value_from_shell,\n        }\n\n        return CONFIG_FUNCTIONS[function](param, value_type, function)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts string into type used by config functions", "response": "def value_convert(self, value, value_type):\n        \"\"\"\n        convert string into type used by `config functions`\n        \"\"\"\n        CONVERSION_OPTIONS = {\n            \"str\": str,\n            \"int\": int,\n            \"float\": float,\n            # Treat booleans specially\n            \"bool\": (lambda val: val.lower() in (\"true\", \"1\")),\n            # Auto-guess the type\n            \"auto\": self.make_value,\n        }\n\n        try:\n            return CONVERSION_OPTIONS[value_type](value)\n        except (TypeError, ValueError):\n            self.notify_user(\"Bad type conversion\")\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_value_from_env(self, param, value_type, function):\n        value = os.getenv(param)\n        if value is None:\n            self.notify_user(\"Environment variable `%s` undefined\" % param)\n        return self.value_convert(value, value_type)", "response": "converts a value from an environment variable"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake value from shell command", "response": "def make_value_from_shell(self, param, value_type, function):\n        \"\"\"\n        run command in the shell\n        \"\"\"\n        try:\n            value = check_output(param, shell=True).rstrip()\n        except CalledProcessError:\n            # for value_type of 'bool' we return False on error code\n            if value_type == \"bool\":\n                value = False\n            else:\n                if self.py3_wrapper:\n                    self.py3_wrapper.report_exception(\n                        msg=\"shell: called with command `%s`\" % param\n                    )\n                self.notify_user(\"shell script exited with an error\")\n                value = None\n        else:\n            # if the value_type is 'bool' then we return True for success\n            if value_type == \"bool\":\n                value = True\n            else:\n                # convert bytes to unicode\n                value = value.decode(\"utf-8\")\n                value = self.value_convert(value, value_type)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a private value for the current module and function.", "response": "def make_function_value_private(self, value, value_type, function):\n        \"\"\"\n        Wraps converted value so that it is hidden in logs etc.\n        Note this is not secure just reduces leaking info\n\n        Allows base 64 encode stuff using base64() or plain hide() in the\n        config\n        \"\"\"\n        # remove quotes\n        value = self.remove_quotes(value)\n\n        if function == \"base64\":\n            try:\n                import base64\n\n                value = base64.b64decode(value).decode(\"utf-8\")\n            except TypeError as e:\n                self.notify_user(\"base64(..) error %s\" % str(e))\n\n        # check we are in a module definition etc\n        if not self.current_module:\n            self.notify_user(\"%s(..) used outside of module or section\" % function)\n            return None\n\n        module = self.current_module[-1].split()[0]\n        if module in CONFIG_FILE_SPECIAL_SECTIONS + I3S_MODULE_NAMES:\n            self.notify_user(\n                \"%s(..) cannot be used outside of py3status module \"\n                \"configuration\" % function\n            )\n            return None\n\n        value = self.value_convert(value, value_type)\n        module_name = self.current_module[-1]\n        return PrivateHide(value, module_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading through tokens till the required separator is found.", "response": "def separator(self, separator=\",\", end_token=None):\n        \"\"\"\n        Read through tokens till the required separator is found.  We ignore\n        newlines.  If an end token is supplied raise a ParseEnd exception if it\n        is found.\n        \"\"\"\n        while True:\n            token = self.next()\n            t_value = token[\"value\"]\n            if end_token and t_value == end_token:\n                raise self.ParseEnd()\n            if t_value == separator:\n                return\n            if t_value == \"\\n\":\n                continue\n            self.error(\"Unexpected character\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_key(self):\n        while True:\n            token = self.next()\n            t_value = token[\"value\"]\n            if t_value == \"\\n\":\n                continue\n            if t_value == \"}\":\n                raise self.ParseEnd()\n            if token[\"type\"] == \"literal\":\n                return self.make_value(t_value)\n            self.error(\"Invalid Key\")", "response": "Find the next key in a dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of key value pairs.", "response": "def make_dict(self):\n        \"\"\"\n        We are in a dict so get key value pairs until the end token.\n        \"\"\"\n        out = {}\n        while True:\n            try:\n                key = self.dict_key()\n                self.separator(separator=\":\")\n                value = self.value_assign(end_token=\"]\")\n                out[key] = value\n                self.separator(end_token=\"}\")\n            except self.ParseEnd:\n                return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nassigns a value to a specific key.", "response": "def value_assign(self, end_token=None):\n        \"\"\"\n        We are expecting a value (literal, list, dict, tuple).\n        If end_token then we are inside a list, dict or tuple so we are allow\n        newlines and also check for the end token.\n        \"\"\"\n        while True:\n            token = self.next()\n            t_value = token[\"value\"]\n            if end_token:\n                if t_value == end_token:\n                    raise self.ParseEnd()\n                elif t_value == \"\\n\":\n                    continue\n            if token[\"type\"] == \"literal\":\n                return self.make_value(t_value)\n            if token[\"type\"] == \"function\":\n                return self.config_function(token)\n            elif t_value == \"[\":\n                return self.make_list()\n            elif t_value == \"{\":\n                return self.make_dict()\n            elif t_value == \"(\":\n                return tuple(self.make_list(end_token=\")\"))\n            else:\n                self.error(\"Value expected\", previous=not (end_token))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef module_def(self):\n        if self.module_level == MAX_NESTING_LEVELS:\n            self.error(\"Module nested too deep\")\n        self.module_level += 1\n        module = ModuleDefinition()\n        self.parse(module, end_token=\"}\")\n        self.module_level -= 1\n        self.current_module.pop()\n        return module", "response": "Parse the next module definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, dictionary=None, end_token=None):\n        self.level += 1\n        name = []\n        if dictionary is None:\n            dictionary = self.config\n        while True:\n            token = self.next()\n            if token is None:\n                # we have got to the end of the config\n                break\n            t_type = token[\"type\"]\n            t_value = token[\"value\"]\n            if t_type == \"newline\":\n                continue\n            elif t_value == end_token:\n                self.level -= 1\n                return\n            elif t_type == \"literal\":\n                value = self.remove_quotes(t_value)\n                if not name and not re.match(\"[a-zA-Z_]\", value):\n                    self.error(\"Invalid name\")\n                name.append(value)\n            elif t_type == \"function\":\n                self.error(\"Name expected\")\n            elif t_type == \"operator\":\n                name = \" \".join(name)\n                if not name:\n                    self.error(\"Name expected\")\n                elif t_value == \"+=\" and name not in dictionary:\n                    # deal with encoded names\n                    if name.split(\":\")[0] not in dictionary:\n                        # order is treated specially\n                        if not (self.level == 1 and name == \"order\"):\n                            self.error(\"{} does not exist\".format(name))\n                if t_value in [\"{\"]:\n                    if self.current_module:\n                        self.check_child_friendly(self.current_module[-1])\n                    self.check_module_name(name)\n                    self.current_module.append(name)\n                value = self.assignment(token)\n                # order is treated specially to create a list\n                if self.level == 1 and name == \"order\":\n                    if not value:\n                        self.error(\"Invalid module\")\n                    self.check_module_name(value, offset=1)\n                    dictionary.setdefault(name, []).append(value)\n                # assignment of  module definition\n                elif t_value == \"{\":\n                    # If this is an py3status module and in a container and has\n                    # no instance name then give it an anon one.  This allows\n                    # us to have multiple non-instance named modules defined\n                    # without them clashing.\n                    if (\n                        self.level > 1\n                        and \" \" not in name\n                        and name not in I3S_MODULE_NAMES\n                    ):\n                        name = \"{} _anon_module_{}\".format(name, self.anon_count)\n                        self.anon_count += 1\n                    dictionary[name] = value\n                # assignment of value\n                elif t_value == \"=\":\n                    try:\n                        name, value = self.process_value(\n                            name, value, self.current_module[-1]\n                        )\n                    except IndexError:\n                        self.error(\"Missing {\", previous=True)\n                    dictionary[name] = value\n                # appending to existing values\n                elif t_value == \"+=\":\n                    dictionary[name] += value\n                else:\n                    self.error(\"Unexpected character\")\n                name = []", "response": "Parse through the tokens and create a dictionary of module names and values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_click(self, event):\n        button = event[\"button\"]\n        if button == self.button_pause:\n            if self.state == \"STOP\":\n                self.py3.command_run(\"mocp --play\")\n            else:\n                self.py3.command_run(\"mocp --toggle-pause\")\n        elif button == self.button_stop:\n            self.py3.command_run(\"mocp --stop\")\n        elif button == self.button_next:\n            self.py3.command_run(\"mocp --next\")\n        elif button == self.button_previous:\n            self.py3.command_run(\"mocp --prev\")\n        else:\n            self.py3.prevent_refresh()", "response": "Control moc with mouse clicks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_click(self, event):\n        button = event[\"button\"]\n        # volume up\n        if button == self.button_up:\n            self.backend.volume_up(self.volume_delta)\n        # volume down\n        elif button == self.button_down:\n            self.backend.volume_down(self.volume_delta)\n        # toggle mute\n        elif button == self.button_mute:\n            self.backend.toggle_mute()", "response": "Volume up and volume down and toggle mute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post_config_hook(self):\n        if not self.py3.check_commands(\"vnstat\"):\n            raise Exception(STRING_NOT_INSTALLED)\n        elif self.statistics_type not in [\"d\", \"m\"]:\n            raise Exception(STRING_INVALID_TYPE)\n        self.slice = slice(*(3, 6) if self.statistics_type == \"d\" else (8, 11))\n        self.value_format = \"{value:%s.%sf} {unit}\" % (self.left_align, self.precision)\n        # list of units, first one - value/initial_multi, second - value/1024,\n        # third - value/1024^2, etc...\n        self.units = [\"kb\", \"mb\", \"gb\", \"tb\"]\n\n        # deprecations\n        self.coloring = getattr(self, \"coloring\", None)\n        if self.coloring and not self.thresholds:\n            self.thresholds = [\n                (num * 1024 ** 2, col) for num, col in self.coloring.items()\n            ]\n\n        self.thresholds_init = self.py3.get_color_names_list(self.format)", "response": "Set up the format of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _thresholds_init(self):\n        thresholds = getattr(self._py3status_module, \"thresholds\", [])\n        self._thresholds = {}\n        if isinstance(thresholds, list):\n            try:\n                thresholds.sort()\n            except TypeError:\n                pass\n            self._thresholds[None] = [(x[0], self._get_color(x[1])) for x in thresholds]\n            return\n        elif isinstance(thresholds, dict):\n            for key, value in thresholds.items():\n                if isinstance(value, list):\n                    try:\n                        value.sort()\n                    except TypeError:\n                        pass\n                    self._thresholds[key] = [\n                        (x[0], self._get_color(x[1])) for x in value\n                    ]", "response": "Initiate and check any thresholds set\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _report_exception(self, msg, frame_skip=2):\n        # We use a hash to see if the message is being repeated.\n        msg_hash = hash(msg)\n        if msg_hash in self._report_exception_cache:\n            return\n        self._report_exception_cache.add(msg_hash)\n\n        # If we just report the error the traceback will end in the try\n        # except block that we are calling from.\n        # We want to show the traceback originating from the module that\n        # called the Py3 method so get the correct error frame and pass this\n        # along.\n        error_frame = sys._getframe(0)\n        while frame_skip:\n            error_frame = error_frame.f_back\n            frame_skip -= 1\n        self._py3_wrapper.report_exception(\n            msg, notify_user=False, error_frame=error_frame\n        )", "response": "Report an exception that occurs inside of a Py3 method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flatten_dict(self, d, delimiter=\"-\", intermediates=False, parent_key=None):\n        items = []\n        if isinstance(d, list):\n            d = dict(enumerate(d))\n        for k, v in d.items():\n            if parent_key:\n                k = u\"{}{}{}\".format(parent_key, delimiter, k)\n            if intermediates:\n                items.append((k, v))\n            if isinstance(v, list):\n                v = dict(enumerate(v))\n            if isinstance(v, collections.Mapping):\n                items.extend(\n                    self.flatten_dict(v, delimiter, intermediates, str(k)).items()\n                )\n            else:\n                items.append((str(k), v))\n        return dict(items)", "response": "Flatten a dictionary.\n\n        Values that are dictionaries are flattened using delimiter in between\n        (eg. parent-child)\n\n        Values that are lists are flattened using delimiter\n        followed by the index (eg. parent-0)\n\n        example:\n\n        .. code-block:: python\n\n            {\n                'fish_facts': {\n                    'sharks': 'Most will drown if they stop moving',\n                    'skates': 'More than 200 species',\n                },\n                'fruits': ['apple', 'peach', 'watermelon'],\n                'number': 52\n            }\n\n            # becomes\n\n            {\n                'fish_facts-sharks': 'Most will drown if they stop moving',\n                'fish_facts-skates': 'More than 200 species',\n                'fruits-0': 'apple',\n                'fruits-1': 'peach',\n                'fruits-2': 'watermelon',\n                'number': 52\n            }\n\n            # if intermediates is True then we also get unflattened elements\n            # as well as the flattened ones.\n\n            {\n                'fish_facts': {\n                    'sharks': 'Most will drown if they stop moving',\n                    'skates': 'More than 200 species',\n                },\n                'fish_facts-sharks': 'Most will drown if they stop moving',\n                'fish_facts-skates': 'More than 200 species',\n                'fruits': ['apple', 'peach', 'watermelon'],\n                'fruits-0': 'apple',\n                'fruits-1': 'peach',\n                'fruits-2': 'watermelon',\n                'number': 52\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a value and formats it for user output.", "response": "def format_units(self, value, unit=\"B\", optimal=5, auto=True, si=False):\n        \"\"\"\n        Takes a value and formats it for user output, we can choose the unit to\n        use eg B, MiB, kbits/second.  This is mainly for use with bytes/bits it\n        converts the value into a human readable form.  It has various\n        additional options but they are really only for special cases.\n\n        The function returns a tuple containing the new value (this is a number\n        so that the user can still format it if required) and a unit that is\n        the units that we have been converted to.\n\n        By supplying unit to the function we can force those units to be used\n        eg ``unit=KiB`` would force the output to be in Kibibytes.  By default we\n        use non-si units but if the unit is si eg kB then we will switch to si\n        units.  Units can also be things like ``Mbit/sec``.\n\n        If the auto parameter is False then we use the unit provided.  This\n        only makes sense when the unit is singular eg 'Bytes' and we want the\n        result in bytes and not say converted to MBytes.\n\n        optimal is used to control the size of the output value.  We try to\n        provide an output value of that number of characters (including decimal\n        point), it may also be less due to rounding.  If a fixed unit is used\n        the output may be more than this number of characters.\n        \"\"\"\n\n        UNITS = \"KMGTPEZY\"\n        DECIMAL_SIZE = 1000\n        BINARY_SIZE = 1024\n        CUTOFF = 1000\n\n        can_round = False\n\n        if unit:\n            # try to guess the unit.  Do we have a known prefix too it?\n            if unit[0].upper() in UNITS:\n                index = UNITS.index(unit[0].upper()) + 1\n                post = unit[1:]\n                si = len(unit) > 1 and unit[1] != \"i\"\n                if si:\n                    post = post[1:]\n                    if unit[1] == \"b\":\n                        value *= 8\n                auto = False\n            else:\n                index = 0\n                post = unit\n        if si:\n            size = DECIMAL_SIZE\n        else:\n            size = BINARY_SIZE\n\n        if auto:\n            # we will try to use an appropriate prefix\n            if value < CUTOFF:\n                unit_out = post\n            else:\n                value /= size\n                for prefix in UNITS:\n                    if abs(value) < CUTOFF:\n                        break\n                    value /= size\n                if si:\n                    # si kilo is lowercase\n                    if prefix == \"K\":\n                        prefix = \"k\"\n                else:\n                    post = \"i\" + post\n\n                unit_out = prefix + post\n                can_round = True\n        else:\n            # we are using a fixed unit\n            unit_out = unit\n            size = pow(size, index)\n            if size:\n                value /= size\n                can_round = True\n\n        if can_round and optimal and value:\n            # we will try to make the output value the desired size\n            # we need to keep out value as a numeric type\n            places = int(log10(abs(value)))\n            if places >= optimal - 2:\n                value = int(value)\n            else:\n                value = round(value, max(optimal - places - 2, 0))\n\n        return value, unit_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_my_event(self, event):\n\n        return (\n            event.get(\"name\") == self._module.module_name\n            and event.get(\"instance\") == self._module.module_inst\n        )", "response": "Checks if an event triggered belongs to the module receiving it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log(self, message, level=LOG_INFO):\n        assert level in [\n            self.LOG_ERROR,\n            self.LOG_INFO,\n            self.LOG_WARNING,\n        ], \"level must be LOG_ERROR, LOG_INFO or LOG_WARNING\"\n\n        # nicely format logs if we can using pretty print\n        if isinstance(message, (dict, list, set, tuple)):\n            message = pformat(message)\n        # start on new line if multi-line output\n        try:\n            if \"\\n\" in message:\n                message = \"\\n\" + message\n        except:  # noqa e722\n            pass\n        message = \"Module `{}`: {}\".format(self._module.module_full_name, message)\n        self._py3_wrapper.log(message, level)", "response": "Log the message.\n        The level must be one of LOG_ERROR, LOG_INFO or LOG_WARNING"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, module_name=None):\n        if not module_name:\n            return self._module.force_update()\n        else:\n            module_info = self._get_module_info(module_name)\n            if module_info:\n                module_info[\"module\"].force_update()", "response": "Update a module.  If module_name is supplied the module of that\n        name is updated.  Otherwise the module calling is updated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_output(self, module_name):\n        output = []\n        module_info = self._get_module_info(module_name)\n        if module_info:\n            output = module_info[\"module\"].get_latest()\n        # we do a deep copy so that any user does not change the actual output\n        # of the module.\n        return deepcopy(output)", "response": "Return the output of the named module."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntriggers an event on a named module.", "response": "def trigger_event(self, module_name, event):\n        \"\"\"\n        Trigger an event on a named module.\n        \"\"\"\n        if module_name:\n            self._py3_wrapper.events_thread.process_event(module_name, event)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a notification to the user.", "response": "def notify_user(self, msg, level=\"info\", rate_limit=5, title=None, icon=None):\n        \"\"\"\n        Send a notification to the user.\n        level must be 'info', 'error' or 'warning'.\n        rate_limit is the time period in seconds during which this message\n        should not be repeated.\n        icon must be an icon path or icon name.\n        \"\"\"\n        module_name = self._module.module_full_name\n        if isinstance(msg, Composite):\n            msg = msg.text()\n        if title is None:\n            title = \"py3status: {}\".format(module_name)\n        elif isinstance(title, Composite):\n            title = title.text()\n        # force unicode for python2 str\n        if self._is_python_2:\n            if isinstance(msg, str):\n                msg = msg.decode(\"utf-8\")\n            if isinstance(title, str):\n                title = title.decode(\"utf-8\")\n        if msg:\n            self._py3_wrapper.notify_user(\n                msg=msg,\n                level=level,\n                rate_limit=rate_limit,\n                module_name=module_name,\n                title=title,\n                icon=icon,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a function for the module.", "response": "def register_function(self, function_name, function):\n        \"\"\"\n        Register a function for the module.\n\n        The following functions can be registered\n\n\n            ..  py:function:: content_function()\n\n            Called to discover what modules a container is displaying.  This is\n            used to determine when updates need passing on to the container and\n            also when modules can be put to sleep.\n\n            the function must return a set of module names that are being\n            displayed.\n\n            .. note::\n\n                This function should only be used by containers.\n\n            ..  py:function:: urgent_function(module_names)\n\n            This function will be called when one of the contents of a container\n            has changed from a non-urgent to an urgent state.  It is used by the\n            group module to switch to displaying the urgent module.\n\n            ``module_names`` is a list of modules that have become urgent\n\n            .. note::\n\n                This function should only be used by containers.\n        \"\"\"\n        my_info = self._get_module_info(self._module.module_full_name)\n        my_info[function_name] = function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time_in(self, seconds=None, sync_to=None, offset=0):\n\n        # if called with CACHE_FOREVER we just return this\n        if seconds is self.CACHE_FOREVER:\n            return self.CACHE_FOREVER\n\n        if seconds is None:\n            # If we have a sync_to then seconds can be 0\n            if sync_to and sync_to > 0:\n                seconds = 0\n            else:\n                try:\n                    # use py3status modules cache_timeout\n                    seconds = self._py3status_module.cache_timeout\n                except AttributeError:\n                    # use default cache_timeout\n                    seconds = self._module.config[\"cache_timeout\"]\n\n        # Unless explicitly set we sync to the nearest second\n        # Unless the requested update is in less than a second\n        if sync_to is None:\n            if seconds and seconds < 1:\n                if 1 % seconds == 0:\n                    sync_to = seconds\n                else:\n                    sync_to = 0\n            else:\n                sync_to = 1\n                if seconds:\n                    seconds -= 0.1\n\n        requested = time() + seconds - offset\n\n        # if sync_to then we find the sync time for the requested time\n        if sync_to:\n            requested = (requested + sync_to) - (requested % sync_to)\n\n        return requested + offset", "response": "Returns the time a given number of seconds into the future."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_contains(self, format_string, names):\n        # We cache things to prevent parsing the format_string more than needed\n        if isinstance(names, list):\n            key = str(names)\n        else:\n            key = names\n            names = [names]\n        try:\n            return self._format_placeholders_cache[format_string][key]\n        except KeyError:\n            pass\n\n        if format_string not in self._format_placeholders:\n            placeholders = self._formatter.get_placeholders(format_string)\n            self._format_placeholders[format_string] = placeholders\n        else:\n            placeholders = self._format_placeholders[format_string]\n\n        if format_string not in self._format_placeholders_cache:\n            self._format_placeholders_cache[format_string] = {}\n\n        for name in names:\n            for placeholder in placeholders:\n                if fnmatch(placeholder, name):\n                    self._format_placeholders_cache[format_string][key] = True\n                    return True\n        self._format_placeholders_cache[format_string][key] = False\n        return False", "response": "Determines if the format_string contains a placeholder string or a list of placeholders names."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_color_names_list(self, format_strings):\n        if not format_strings:\n            return []\n        if not getattr(self._py3status_module, \"thresholds\", None):\n            return []\n        if isinstance(format_strings, basestring):\n            format_strings = [format_strings]\n        names = set()\n        for string in format_strings:\n            names.update(self._formatter.get_color_names(string))\n        return list(names)", "response": "Returns a list of color names in format_string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of placeholders in format_string.", "response": "def get_placeholders_list(self, format_string, matches=None):\n        \"\"\"\n        Returns a list of placeholders in ``format_string``.\n\n        If ``matches`` is provided then it is used to filter the result\n        using fnmatch so the following patterns can be used:\n\n\n        .. code-block:: none\n\n            * \t    matches everything\n            ? \t    matches any single character\n            [seq] \tmatches any character in seq\n            [!seq] \tmatches any character not in seq\n\n        This is useful because we just get simple placeholder without any\n        formatting that may be applied to them\n        eg ``'{placeholder:.2f}'`` will give ``['{placeholder}']``\n        \"\"\"\n        if format_string not in self._format_placeholders:\n            placeholders = self._formatter.get_placeholders(format_string)\n            self._format_placeholders[format_string] = placeholders\n        else:\n            placeholders = self._format_placeholders[format_string]\n\n        if not matches:\n            return list(placeholders)\n        elif isinstance(matches, basestring):\n            matches = [matches]\n        # filter matches\n        found = set()\n        for match in matches:\n            for placeholder in placeholders:\n                if fnmatch(placeholder, match):\n                    found.add(placeholder)\n        return list(found)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef safe_format(\n        self, format_string, param_dict=None, force_composite=False, attr_getter=None\n    ):\n        r\"\"\"\n        Parser for advanced formatting.\n\n        Unknown placeholders will be shown in the output eg ``{foo}``.\n\n        Square brackets ``[]`` can be used. The content of them will be removed\n        from the output if there is no valid placeholder contained within.\n        They can also be nested.\n\n        A pipe (vertical bar) ``|`` can be used to divide sections the first\n        valid section only will be shown in the output.\n\n        A backslash ``\\`` can be used to escape a character eg ``\\[`` will show ``[``\n        in the output.\n\n        ``\\?`` is special and is used to provide extra commands to the format\n        string,  example ``\\?color=#FF00FF``. Multiple commands can be given\n        using an ampersand ``&`` as a separator, example ``\\?color=#FF00FF&show``.\n\n        ``\\?if=<placeholder>`` can be used to check if a placeholder exists. An\n        exclamation mark ``!`` after the equals sign ``=`` can be used to negate\n        the condition.\n\n        ``\\?if=<placeholder>=<value>`` can be used to determine if {<placeholder>}\n        would be replaced with <value>. ``[]`` in <value> don't need to be escaped.\n\n        ``{<placeholder>}`` will be converted, or removed if it is None or empty.\n        Formatting can also be applied to the placeholder Eg\n        ``{number:03.2f}``.\n\n        example format_string:\n\n        ``\"[[{artist} - ]{title}]|{file}\"``\n        This will show ``artist - title`` if artist is present,\n        ``title`` if title but no artist,\n        and ``file`` if file is present but not artist or title.\n\n        param_dict is a dictionary of placeholders that will be substituted.\n        If a placeholder is not in the dictionary then if the py3status module\n        has an attribute with the same name then it will be used.\n\n        .. note::\n\n            Added in version 3.3\n\n        Composites can be included in the param_dict.\n\n        The result returned from this function can either be a string in the\n        case of simple parsing or a Composite if more complex.\n\n        If force_composite parameter is True a composite will always be\n        returned.\n\n        attr_getter is a function that will when called with an attribute name\n        as a parameter will return a value.\n        \"\"\"\n        try:\n            return self._formatter.format(\n                format_string,\n                self._py3status_module,\n                param_dict,\n                force_composite=force_composite,\n                attr_getter=attr_getter,\n            )\n        except Exception:\n            self._report_exception(u\"Invalid format `{}`\".format(format_string))\n            return \"invalid format\"", "response": "r Returns a string that can be used to parse the log entry into a safe format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a composite output from a format string.", "response": "def build_composite(\n        self, format_string, param_dict=None, composites=None, attr_getter=None\n    ):\n        \"\"\"\n        .. note::\n            deprecated in 3.3 use safe_format().\n\n        Build a composite output using a format string.\n\n        Takes a format_string and treats it the same way as ``safe_format()`` but\n        also takes a composites dict where each key/value is the name of the\n        placeholder and either an output eg ``{'full_text': 'something'}`` or a\n        list of outputs.\n        \"\"\"\n\n        if param_dict is None:\n            param_dict = {}\n\n        # merge any composites into the param_dict.\n        # as they are no longer dealt with separately\n        if composites:\n            for key, value in composites.items():\n                param_dict[key] = Composite(value)\n\n        try:\n            return self._formatter.format(\n                format_string,\n                self._py3status_module,\n                param_dict,\n                force_composite=True,\n                attr_getter=attr_getter,\n            )\n        except Exception:\n            self._report_exception(u\"Invalid format `{}`\".format(format_string))\n            return [{\"full_text\": \"invalid format\"}]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef composite_update(self, item, update_dict, soft=False):\n        return Composite.composite_update(item, update_dict, soft)", "response": "Updates all entries in the a\n        Composite with values from update_dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_commands(self, cmd_list):\n        # if a string is passed then convert it to a list.  This prevents an\n        # easy mistake that could be made\n        if isinstance(cmd_list, basestring):\n            cmd_list = [cmd_list]\n\n        for cmd in cmd_list:\n            if self.command_run(\"which {}\".format(cmd)) == 0:\n                return cmd", "response": "Checks to see if commands in list are available using which."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command and returns the exit code.", "response": "def command_run(self, command):\n        \"\"\"\n        Runs a command and returns the exit code.\n        The command can either be supplied as a sequence or string.\n\n        An Exception is raised if an error occurs\n        \"\"\"\n        # convert the command to sequence if a string\n        if isinstance(command, basestring):\n            command = shlex.split(command)\n        try:\n            return Popen(command, stdout=PIPE, stderr=PIPE, close_fds=True).wait()\n        except Exception as e:\n            # make a pretty command for error loggings and...\n            if isinstance(command, basestring):\n                pretty_cmd = command\n            else:\n                pretty_cmd = \" \".join(command)\n            msg = \"Command `{cmd}` {error}\".format(cmd=pretty_cmd, error=e.errno)\n            raise exceptions.CommandError(msg, error_code=e.errno)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a command and return its output as unicode.", "response": "def command_output(\n        self, command, shell=False, capture_stderr=False, localized=False\n    ):\n        \"\"\"\n        Run a command and return its output as unicode.\n        The command can either be supplied as a sequence or string.\n\n        :param command: command to run can be a str or list\n        :param shell: if `True` then command is run through the shell\n        :param capture_stderr: if `True` then STDERR is piped to STDOUT\n        :param localized: if `False` then command is forced to use its default (English) locale\n\n        A CommandError is raised if an error occurs\n        \"\"\"\n        # make a pretty command for error loggings and...\n        if isinstance(command, basestring):\n            pretty_cmd = command\n        else:\n            pretty_cmd = \" \".join(command)\n        # convert the non-shell command to sequence if it is a string\n        if not shell and isinstance(command, basestring):\n            command = shlex.split(command)\n\n        stderr = STDOUT if capture_stderr else PIPE\n        env = self._english_env if not localized else None\n\n        try:\n            process = Popen(\n                command,\n                stdout=PIPE,\n                stderr=stderr,\n                close_fds=True,\n                universal_newlines=True,\n                shell=shell,\n                env=env,\n            )\n        except Exception as e:\n            msg = \"Command `{cmd}` {error}\".format(cmd=pretty_cmd, error=e)\n            raise exceptions.CommandError(msg, error_code=e.errno)\n\n        output, error = process.communicate()\n        if self._is_python_2 and isinstance(output, str):\n            output = output.decode(\"utf-8\")\n            error = error.decode(\"utf-8\")\n        retcode = process.poll()\n        if retcode:\n            # under certain conditions a successfully run command may get a\n            # return code of -15 even though correct output was returned see\n            # #664.  This issue seems to be related to arch linux but the\n            # reason is not entirely clear.\n            if retcode == -15:\n                msg = \"Command `{cmd}` returned SIGTERM (ignoring)\"\n                self.log(msg.format(cmd=pretty_cmd))\n            else:\n                msg = \"Command `{cmd}` returned non-zero exit status {error}\"\n                output_oneline = output.replace(\"\\n\", \" \")\n                if output_oneline:\n                    msg += \" ({output})\"\n                msg = msg.format(cmd=pretty_cmd, error=retcode, output=output_oneline)\n                raise exceptions.CommandError(\n                    msg, error_code=retcode, error=error, output=output\n                )\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures that storage is initialized.", "response": "def _storage_init(self):\n        \"\"\"\n        Ensure that storage is initialized.\n        \"\"\"\n        if not self._storage.initialized:\n            self._storage.init(self._module._py3_wrapper, self._is_python_2)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef storage_set(self, key, value):\n        if not self._module:\n            return\n        self._storage_init()\n        module_name = self._module.module_full_name\n        return self._storage.storage_set(module_name, key, value)", "response": "Store a value for the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef storage_get(self, key):\n        if not self._module:\n            return\n        self._storage_init()\n        module_name = self._module.module_full_name\n        return self._storage.storage_get(module_name, key)", "response": "Retrieve a value for the specified key from the module s storage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the value stored with the key from storage.", "response": "def storage_del(self, key=None):\n        \"\"\"\n        Remove the value stored with the key from storage.\n        If key is not supplied then all values for the module are removed.\n        \"\"\"\n        if not self._module:\n            return\n        self._storage_init()\n        module_name = self._module.module_full_name\n        return self._storage.storage_del(module_name, key=key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef storage_keys(self):\n        if not self._module:\n            return []\n        self._storage_init()\n        module_name = self._module.module_full_name\n        return self._storage.storage_keys(module_name)", "response": "Return a list of the keys for the values stored for the module."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the key value pairs of the stored data for the module.", "response": "def storage_items(self):\n        \"\"\"\n        Return key, value pairs of the stored data for the module.\n\n        Keys will contain the following metadata entries:\n        - '_ctime': storage creation timestamp\n        - '_mtime': storage last modification timestamp\n        \"\"\"\n        if not self._module:\n            return {}.items()\n        self._storage_init()\n        items = []\n        module_name = self._module.module_full_name\n        for key in self._storage.storage_keys(module_name):\n            value = self._storage.storage_get(module_name, key)\n            items.add((key, value))\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play_sound(self, sound_file):\n        self.stop_sound()\n        if sound_file:\n            cmd = self.check_commands([\"ffplay\", \"paplay\", \"play\"])\n            if cmd:\n                if cmd == \"ffplay\":\n                    cmd = \"ffplay -autoexit -nodisp -loglevel 0\"\n                sound_file = os.path.expanduser(sound_file)\n                c = shlex.split(\"{} {}\".format(cmd, sound_file))\n                self._audio = Popen(c)", "response": "Plays sound_file if possible."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef threshold_get_color(self, value, name=None):\n        # If first run then process the threshold data.\n        if self._thresholds is None:\n            self._thresholds_init()\n\n        # allow name with different values\n        if isinstance(name, tuple):\n            name_used = \"{}/{}\".format(name[0], name[1])\n            if name[2]:\n                self._thresholds[name_used] = [\n                    (x[0], self._get_color(x[1])) for x in name[2]\n                ]\n            name = name[0]\n        else:\n            # if name not in thresholds info then use defaults\n            name_used = name\n            if name_used not in self._thresholds:\n                name_used = None\n\n        # convert value to int/float\n        thresholds = self._thresholds.get(name_used)\n        color = None\n        try:\n            value = float(value)\n        except (TypeError, ValueError):\n            pass\n\n        # skip on empty thresholds/values\n        if not thresholds or value in [None, \"\"]:\n            pass\n        elif isinstance(value, basestring):\n            # string\n            for threshold in thresholds:\n                if value == threshold[0]:\n                    color = threshold[1]\n                    break\n        else:\n            # int/float\n            try:\n                if self._get_config_setting(\"gradients\"):\n                    try:\n                        colors, minimum, maximum = self._threshold_gradients[name_used]\n                    except KeyError:\n                        colors = self._gradients.make_threshold_gradient(\n                            self, thresholds\n                        )\n                        minimum = min(thresholds)[0]\n                        maximum = max(thresholds)[0]\n                        self._threshold_gradients[name_used] = (\n                            colors,\n                            minimum,\n                            maximum,\n                        )\n\n                    if value < minimum:\n                        color = colors[0]\n                    elif value > maximum:\n                        color = colors[-1]\n                    else:\n                        value -= minimum\n                        col_index = int(\n                            ((len(colors) - 1) / (maximum - minimum)) * value\n                        )\n                        color = colors[col_index]\n                else:\n                    color = thresholds[0][1]\n                    for threshold in thresholds:\n                        if value >= threshold[0]:\n                            color = threshold[1]\n                        else:\n                            break\n            except TypeError:\n                color = None\n\n        # save color so it can be accessed via safe_format()\n        if name:\n            color_name = \"color_threshold_%s\" % name\n        else:\n            color_name = \"color_threshold\"\n        setattr(self._py3status_module, color_name, color)\n\n        return color", "response": "This function will take a value from the thresholds and return the color for that value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a request to a url and retrieve the results. If the headers parameter does not provide an 'User-Agent' key, one will be added automatically following the convention: py3status/<version> <per session random uuid> :param url: url to request eg `http://example.com` :param params: extra query string parameters as a dict :param data: POST data as a dict. If this is not supplied the GET method will be used :param headers: http headers to be added to the request as a dict :param timeout: timeout for the request in seconds :param auth: authentication info as tuple `(username, password)` :param cookiejar: an object of a CookieJar subclass :returns: HttpResponse", "response": "def request(\n        self,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        timeout=None,\n        auth=None,\n        cookiejar=None,\n    ):\n        \"\"\"\n        Make a request to a url and retrieve the results.\n\n        If the headers parameter does not provide an 'User-Agent' key, one will\n        be added automatically following the convention:\n\n            py3status/<version> <per session random uuid>\n\n        :param url: url to request eg `http://example.com`\n        :param params: extra query string parameters as a dict\n        :param data: POST data as a dict.  If this is not supplied the GET method will be used\n        :param headers: http headers to be added to the request as a dict\n        :param timeout: timeout for the request in seconds\n        :param auth: authentication info as tuple `(username, password)`\n        :param cookiejar: an object of a CookieJar subclass\n\n        :returns: HttpResponse\n        \"\"\"\n\n        # The aim of this function is to be a limited lightweight replacement\n        # for the requests library but using only pythons standard libs.\n\n        # IMPORTANT NOTICE\n        # This function is excluded from private variable hiding as it is\n        # likely to need api keys etc which people may have obfuscated.\n        # Therefore it is important that no logging is done in this function\n        # that might reveal this information.\n\n        if headers is None:\n            headers = {}\n\n        if timeout is None:\n            timeout = getattr(self._py3status_module, \"request_timeout\", 10)\n\n        if \"User-Agent\" not in headers:\n            headers[\"User-Agent\"] = \"py3status/{} {}\".format(version, self._uid)\n\n        return HttpResponse(\n            url,\n            params=params,\n            data=data,\n            headers=headers,\n            timeout=timeout,\n            auth=auth,\n            cookiejar=cookiejar,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting given line to stdout.", "response": "def print_line(line):\n    \"\"\"\n    Print given line to stdout (i3bar).\n    \"\"\"\n    sys.__stdout__.write(\"{}\\n\".format(line))\n    sys.__stdout__.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_ip(self, interface):\n        if interface in ni.interfaces():\n            addresses = ni.ifaddresses(interface)\n            if ni.AF_INET in addresses:\n                return addresses[ni.AF_INET][0][\"addr\"]\n        return \"\"", "response": "Returns the IPv4 address of the interface if it exists and has a valid ASN. 1 IPv4 address otherwise returns an empty string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay a notification following the specified format", "response": "def on_click(self, event):\n        \"\"\"\n        Display a notification following the specified format\n        \"\"\"\n        if not self.notification:\n            return\n\n        if self.charging:\n            format = self.format_notify_charging\n        else:\n            format = self.format_notify_discharging\n\n        message = self.py3.safe_format(\n            format,\n            dict(\n                ascii_bar=self.ascii_bar,\n                icon=self.icon,\n                percent=self.percent_charged,\n                time_remaining=self.time_remaining,\n            ),\n        )\n\n        if message:\n            self.py3.notify_user(message, \"info\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the battery info from the acpi output.", "response": "def _extract_battery_info_from_acpi(self):\n        \"\"\"\n        Get the battery info from acpi\n\n        # Example acpi -bi raw output (Discharging):\n        Battery 0: Discharging, 94%, 09:23:28 remaining\n        Battery 0: design capacity 5703 mAh, last full capacity 5283 mAh = 92%\n        Battery 1: Unknown, 98%\n        Battery 1: design capacity 1880 mAh, last full capacity 1370 mAh = 72%\n\n        # Example Charging\n        Battery 0: Charging, 96%, 00:20:40 until charged\n        Battery 0: design capacity 5566 mAh, last full capacity 5156 mAh = 92%\n        Battery 1: Unknown, 98%\n        Battery 1: design capacity 1879 mAh, last full capacity 1370 mAh = 72%\n        \"\"\"\n\n        def _parse_battery_info(acpi_battery_lines):\n            battery = {}\n            battery[\"percent_charged\"] = int(\n                findall(\"(?<= )(\\d+)(?=%)\", acpi_battery_lines[0])[0]\n            )\n            battery[\"charging\"] = \"Charging\" in acpi_battery_lines[0]\n            battery[\"capacity\"] = int(\n                findall(\"(?<= )(\\d+)(?= mAh)\", acpi_battery_lines[1])[1]\n            )\n\n            # ACPI only shows time remaining if battery is discharging or\n            # charging\n            try:\n                battery[\"time_remaining\"] = \"\".join(\n                    findall(\n                        \"(?<=, )(\\d+:\\d+:\\d+)(?= remaining)|\"\n                        \"(?<=, )(\\d+:\\d+:\\d+)(?= until)\",\n                        acpi_battery_lines[0],\n                    )[0]\n                )\n            except IndexError:\n                battery[\"time_remaining\"] = FULLY_CHARGED\n\n            return battery\n\n        acpi_list = self.py3.command_output([\"acpi\", \"-b\", \"-i\"]).splitlines()\n\n        # Separate the output because each pair of lines corresponds to a\n        # single battery.  Now the list index will correspond to the index of\n        # the battery we want to look at\n        acpi_list = [acpi_list[i : i + 2] for i in range(0, len(acpi_list) - 1, 2)]\n\n        return [_parse_battery_info(battery) for battery in acpi_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_battery_info_from_sys(self):\n\n        if not os.listdir(self.sys_battery_path):\n            return []\n\n        def _parse_battery_info(sys_path):\n            \"\"\"\n            Extract battery information from uevent file, already convert to\n            int if necessary\n            \"\"\"\n            raw_values = {}\n            with open(os.path.join(sys_path, u\"uevent\")) as f:\n                for var in f.read().splitlines():\n                    k, v = var.split(\"=\")\n                    try:\n                        raw_values[k] = int(v)\n                    except ValueError:\n                        raw_values[k] = v\n            return raw_values\n\n        battery_list = []\n        for path in iglob(os.path.join(self.sys_battery_path, \"BAT*\")):\n            r = _parse_battery_info(path)\n\n            capacity = r.get(\n                \"POWER_SUPPLY_ENERGY_FULL\", r.get(\"POWER_SUPPLY_CHARGE_FULL\")\n            )\n            present_rate = r.get(\n                \"POWER_SUPPLY_POWER_NOW\",\n                r.get(\"POWER_SUPPLY_CURRENT_NOW\", r.get(\"POWER_SUPPLY_VOLTAGE_NOW\")),\n            )\n            remaining_energy = r.get(\n                \"POWER_SUPPLY_ENERGY_NOW\", r.get(\"POWER_SUPPLY_CHARGE_NOW\")\n            )\n\n            battery = {}\n            battery[\"capacity\"] = capacity\n            battery[\"charging\"] = \"Charging\" in r[\"POWER_SUPPLY_STATUS\"]\n            battery[\"percent_charged\"] = int(\n                math.floor(remaining_energy / capacity * 100)\n            )\n            try:\n                if battery[\"charging\"]:\n                    time_in_secs = (capacity - remaining_energy) / present_rate * 3600\n                else:\n                    time_in_secs = remaining_energy / present_rate * 3600\n                battery[\"time_remaining\"] = self._seconds_to_hms(time_in_secs)\n            except ZeroDivisionError:\n                # Battery is either full charged or is not discharging\n                battery[\"time_remaining\"] = FULLY_CHARGED\n\n            battery_list.append(battery)\n        return battery_list", "response": "Extract battery information from sys battery files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nswitching the displayed module or pass the event on to the active module", "response": "def on_click(self, event):\n        \"\"\"\n        Switch the displayed module or pass the event on to the active module\n        \"\"\"\n        if event[\"button\"] == self.button_toggle:\n            # we only toggle if button was used\n            if event.get(\"index\") == \"button\" and self.py3.is_my_event(event):\n                self.urgent = False\n                self.open = not self.open"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntoggle between display modes ip and status", "response": "def on_click(self, event):\n        \"\"\"\n        Toggle between display modes 'ip' and 'status'\n        \"\"\"\n        button = event[\"button\"]\n        if button == self.button_toggle:\n            self.toggled = True\n            if self.mode == \"ip\":\n                self.mode = \"status\"\n            else:\n                self.mode = \"ip\"\n        elif button == self.button_refresh:\n            self.idle_time = 0\n        else:\n            self.py3.prevent_refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post_config_hook(self):\n        self._no_force_on_change = True\n        self.active_comb = None\n        self.active_layout = None\n        self.active_mode = \"extend\"\n        self.displayed = None\n        self.max_width = 0", "response": "Initialize the object after config is complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_layout(self):\n        connected = list()\n        active_layout = list()\n        disconnected = list()\n        layout = OrderedDict(\n            {\"connected\": OrderedDict(), \"disconnected\": OrderedDict()}\n        )\n\n        current = self.py3.command_output(\"xrandr\")\n        for line in current.splitlines():\n            try:\n                s = line.split(\" \")\n                infos = line[line.find(\"(\") :]\n                if s[1] == \"connected\":\n                    output, state, mode = s[0], s[1], None\n                    for index, x in enumerate(s[2:], 2):\n                        if \"x\" in x and \"+\" in x:\n                            mode = x\n                            active_layout.append(output)\n                            infos = line[line.find(s[index + 1]) :]\n                            break\n                        elif \"(\" in x:\n                            break\n                    connected.append(output)\n                elif s[1] == \"disconnected\":\n                    output, state, mode = s[0], s[1], None\n                    disconnected.append(output)\n                else:\n                    continue\n            except Exception as err:\n                self.py3.log('xrandr error=\"{}\"'.format(err))\n            else:\n                layout[state][output] = {\"infos\": infos, \"mode\": mode, \"state\": state}\n\n        # initialize the active layout\n        if self.active_layout is None:\n            self.active_comb = tuple(active_layout)\n            self.active_layout = self._get_string_and_set_width(\n                tuple(active_layout), self.active_mode\n            )\n\n        return layout", "response": "Get the outputs layout from xrandr and try to detect the currently active layout."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates all connected outputs combinations and set the max display width while iterating.", "response": "def _set_available_combinations(self):\n        \"\"\"\n        Generate all connected outputs combinations and\n        set the max display width while iterating.\n        \"\"\"\n        available = set()\n        combinations_map = {}\n\n        whitelist = None\n        if self.output_combinations:\n            whitelist = self.output_combinations.split(\"|\")\n\n        self.max_width = 0\n        for output in range(len(self.layout[\"connected\"])):\n            for comb in combinations(self.layout[\"connected\"], output + 1):\n                for mode in [\"clone\", \"extend\"]:\n                    string = self._get_string_and_set_width(comb, mode)\n                    if whitelist and string not in whitelist:\n                        continue\n                    if len(comb) == 1:\n                        combinations_map[string] = (comb, None)\n                    else:\n                        combinations_map[string] = (comb, mode)\n                    available.add(string)\n\n        # Preserve the order in which user defined the output combinations\n        if whitelist:\n            available = reversed([comb for comb in whitelist if comb in available])\n\n        self.available_combinations = deque(available)\n        self.combinations_map = combinations_map"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct the string to be displayed and record the max width.", "response": "def _get_string_and_set_width(self, combination, mode):\n        \"\"\"\n        Construct the string to be displayed and record the max width.\n        \"\"\"\n        show = \"{}\".format(self._separator(mode)).join(combination)\n        show = show.rstrip(\"{}\".format(self._separator(mode)))\n        self.max_width = max([self.max_width, len(show)])\n        return show"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _choose_what_to_display(self, force_refresh=False):\n        for _ in range(len(self.available_combinations)):\n            if (\n                self.displayed is None\n                and self.available_combinations[0] == self.active_layout\n            ):\n                self.displayed = self.available_combinations[0]\n                break\n            else:\n                if self.displayed == self.available_combinations[0]:\n                    break\n                else:\n                    self.available_combinations.rotate(1)\n        else:\n            if force_refresh:\n                self.displayed = self.available_combinations[0]\n            else:\n                self.py3.log('xrandr error=\"displayed combination is not available\"')", "response": "Choose what combination to display on the bar."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall xrandr and apply the selected combination mode.", "response": "def _apply(self, force=False):\n        \"\"\"\n        Call xrandr and apply the selected (displayed) combination mode.\n        \"\"\"\n        if self.displayed == self.active_layout and not force:\n            # no change, do nothing\n            return\n\n        combination, mode = self.combinations_map.get(self.displayed, (None, None))\n        if combination is None and mode is None:\n            # displayed combination cannot be activated, ignore\n            return\n\n        cmd = \"xrandr\"\n        outputs = list(self.layout[\"connected\"].keys())\n        outputs += list(self.layout[\"disconnected\"].keys())\n        previous_output = None\n        primary_added = False\n        for output in outputs:\n            cmd += \" --output {}\".format(output)\n            #\n            if output in combination:\n                pos = getattr(self, \"{}_pos\".format(output), \"0x0\")\n                primary = getattr(self, \"{}_primary\".format(output), None)\n                resolution = getattr(self, \"{}_mode\".format(output), None)\n                resolution = \"--mode {}\".format(resolution) if resolution else \"--auto\"\n                rotation = getattr(self, \"{}_rotate\".format(output), \"normal\")\n                if rotation not in [\"inverted\", \"left\", \"normal\", \"right\"]:\n                    self.py3.log(\"configured rotation {} is not valid\".format(rotation))\n                    rotation = \"normal\"\n                #\n                if primary is True and not primary_added:\n                    primary_added = True\n                    cmd += \" --primary\"\n                if mode == \"clone\" and previous_output is not None:\n                    cmd += \" {} --same-as {}\".format(resolution, previous_output)\n                else:\n                    if (\n                        \"above\" in pos\n                        or \"below\" in pos\n                        or \"left-of\" in pos\n                        or \"right-of\" in pos\n                    ):\n                        cmd += \" {} --{} --rotate {}\".format(resolution, pos, rotation)\n                    else:\n                        cmd += \" {} --pos {} --rotate {}\".format(\n                            resolution, pos, rotation\n                        )\n                previous_output = output\n            else:\n                cmd += \" --off\"\n        #\n        code = self.py3.command_run(cmd)\n        if code == 0:\n            self.active_comb = combination\n            self.active_layout = self.displayed\n            self.active_mode = mode\n        self.py3.log('command \"{}\" exit code {}'.format(cmd, code))\n\n        if self.command:\n            self.py3.command_run(self.command)\n\n        # move workspaces to outputs as configured\n        self._apply_workspaces(combination, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _apply_workspaces(self, combination, mode):\n        if len(combination) > 1 and mode == \"extend\":\n            sleep(3)\n            for output in combination:\n                workspaces = getattr(self, \"{}_workspaces\".format(output), \"\").split(\n                    \",\"\n                )\n                for workspace in workspaces:\n                    if not workspace:\n                        continue\n                    # switch to workspace\n                    cmd = '{} workspace \"{}\"'.format(self.py3.get_wm_msg(), workspace)\n                    self.py3.command_run(cmd)\n                    # move it to output\n                    cmd = '{} move workspace to output \"{}\"'.format(\n                        self.py3.get_wm_msg(), output\n                    )\n                    self.py3.command_run(cmd)\n                    # log this\n                    self.py3.log(\n                        \"moved workspace {} to output {}\".format(workspace, output)\n                    )", "response": "Allows user to force move a comma separated list of workspaces to the\n            given output when it s activated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fallback_to_available_output(self):\n        if len(self.active_comb) == 1:\n            self._choose_what_to_display(force_refresh=True)\n            self._apply()\n            self.py3.update()", "response": "Fallback to the first available output when the active layout has only one output."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nforces the user configured mode on start.", "response": "def _force_force_on_start(self):\n        \"\"\"\n        Force the user configured mode on start.\n        \"\"\"\n        if self.force_on_start in self.available_combinations:\n            self.displayed = self.force_on_start\n            self._choose_what_to_display(force_refresh=True)\n            self._apply(force=True)\n            self.py3.update()\n        self.force_on_start = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _force_on_change(self):\n        for layout in self.force_on_change:\n            if layout in self.available_combinations:\n                if self.active_layout != layout:\n                    self.displayed = layout\n                    self._apply(force=True)\n                    self.py3.update()\n                    break\n                else:\n                    break", "response": "Force on change feature."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles events on click", "response": "def on_click(self, event):\n        \"\"\"\n        Click events\n            - left click & scroll up/down: switch between modes\n            - right click: apply selected mode\n            - middle click: force refresh of available modes\n        \"\"\"\n        self._no_force_on_change = True\n        button = event[\"button\"]\n        if button == 4:\n            self._switch_selection(-1)\n        if button in [1, 5]:\n            self._switch_selection(1)\n        if button == 2:\n            self._choose_what_to_display(force_refresh=True)\n        if button == 3:\n            self._apply()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreduces the zone to reduce the size of fetched data on refresh", "response": "def _set_optimal_area(self, data):\n        \"\"\"\n        Reduce the zone to reduce the size of fetched data on refresh\n        \"\"\"\n        lats = [station[\"latitude\"] for station in data.values()]\n        longs = [station[\"longitude\"] for station in data.values()]\n        self.gps.update(\n            {\n                \"gpsTopLatitude\": max(lats),\n                \"gpsTopLongitude\": max(longs),\n                \"gpsBotLatitude\": min(lats),\n                \"gpsBotLongitude\": min(longs),\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the text of the current metadata.", "response": "def _get_text(self):\n        \"\"\"\n        Get the current metadata\n        \"\"\"\n        if self._data.get(\"state\") == PLAYING:\n            color = self.py3.COLOR_PLAYING or self.py3.COLOR_GOOD\n            state_symbol = self.state_play\n        elif self._data.get(\"state\") == PAUSED:\n            color = self.py3.COLOR_PAUSED or self.py3.COLOR_DEGRADED\n            state_symbol = self.state_pause\n        else:\n            color = self.py3.COLOR_STOPPED or self.py3.COLOR_BAD\n            state_symbol = self.state_stop\n\n        if self._data.get(\"error_occurred\"):\n            color = self.py3.COLOR_BAD\n\n        try:\n            ptime_ms = self._player.Position\n            ptime = _get_time_str(ptime_ms)\n        except Exception:\n            ptime = None\n\n        if (\n            self.py3.format_contains(self.format, \"time\")\n            and self._data.get(\"state\") == PLAYING\n        ):\n            # Don't get trapped in aliasing errors!\n            update = time() + 0.5\n        else:\n            update = self.py3.CACHE_FOREVER\n\n        placeholders = {\n            \"player\": self._data.get(\"player\"),\n            \"state\": state_symbol,\n            \"album\": self._data.get(\"album\"),\n            \"artist\": self._data.get(\"artist\"),\n            \"length\": self._data.get(\"length\"),\n            \"time\": ptime,\n            \"title\": self._data.get(\"title\") or \"No Track\",\n            \"full_name\": self._player_details.get(\"full_name\"),  # for debugging ;p\n        }\n\n        return (placeholders, color, update)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting self. _player self. _player_details.", "response": "def _set_player(self):\n        \"\"\"\n        Sort the current players into priority order and set self._player\n        Players are ordered by working state then prefernce supplied by user\n        and finally by instance if a player has more than one running.\n        \"\"\"\n        players = []\n        for name, p in self._mpris_players.items():\n            # we set the priority here as we need to establish the player name\n            # which might not be immediately available.\n            if \"_priority\" not in p:\n                if self.player_priority:\n                    try:\n                        priority = self.player_priority.index(p[\"name\"])\n                    except ValueError:\n                        try:\n                            priority = self.player_priority.index(\"*\")\n                        except ValueError:\n                            priority = None\n                else:\n                    priority = 0\n                if priority is not None:\n                    p[\"_priority\"] = priority\n            if p.get(\"_priority\") is not None:\n                players.append((p[\"_state_priority\"], p[\"_priority\"], p[\"index\"], name))\n        if players:\n            top_player = self._mpris_players.get(sorted(players)[0][3])\n        else:\n            top_player = {}\n\n        self._player = top_player.get(\"_dbus_player\")\n        self._player_details = top_player\n\n        self.py3.update()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_player(self, player_id):\n        if not player_id.startswith(SERVICE_BUS):\n            return False\n\n        player = self._dbus.get(player_id, SERVICE_BUS_URL)\n\n        if player.Identity not in self._mpris_names:\n            self._mpris_names[player.Identity] = player_id.split(\".\")[-1]\n            for p in self._mpris_players.values():\n                if not p[\"name\"] and p[\"identity\"] in self._mpris_names:\n                    p[\"name\"] = self._mpris_names[p[\"identity\"]]\n                    p[\"full_name\"] = u\"{} {}\".format(p[\"name\"], p[\"index\"])\n\n        identity = player.Identity\n        name = self._mpris_names.get(identity)\n        if (\n            self.player_priority != []\n            and name not in self.player_priority\n            and \"*\" not in self.player_priority\n        ):\n            return False\n\n        if identity not in self._mpris_name_index:\n            self._mpris_name_index[identity] = 0\n\n        status = player.PlaybackStatus\n        state_priority = WORKING_STATES.index(status)\n        index = self._mpris_name_index[identity]\n        self._mpris_name_index[identity] += 1\n        try:\n            subscription = player.PropertiesChanged.connect(\n                self._player_monitor(player_id)\n            )\n        except AttributeError:\n            subscription = {}\n\n        self._mpris_players[player_id] = {\n            \"_dbus_player\": player,\n            \"_id\": player_id,\n            \"_state_priority\": state_priority,\n            \"index\": index,\n            \"identity\": identity,\n            \"name\": name,\n            \"full_name\": u\"{} {}\".format(name, index),\n            \"status\": status,\n            \"subscription\": subscription,\n        }\n\n        return True", "response": "Add a player to the internal list of available mpris_players."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _remove_player(self, player_id):\n        player = self._mpris_players.get(player_id)\n        if player:\n            if player.get(\"subscription\"):\n                player[\"subscription\"].disconnect()\n            del self._mpris_players[player_id]", "response": "Remove a player from the list of available players."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mpris(self):\n        if self._kill:\n            raise KeyboardInterrupt\n        current_player_id = self._player_details.get(\"id\")\n        cached_until = self.py3.CACHE_FOREVER\n\n        if self._player is None:\n            text = self.format_none\n            color = self.py3.COLOR_BAD\n            composite = [{\"full_text\": text, \"color\": color}]\n            self._data = {}\n        else:\n            self._init_data()\n            (text, color, cached_until) = self._get_text()\n            self._control_states = self._get_control_states()\n            buttons = self._get_response_buttons()\n            composite = self.py3.safe_format(self.format, dict(text, **buttons))\n\n        if self._data.get(\n            \"error_occurred\"\n        ) or current_player_id != self._player_details.get(\"id\"):\n            # Something went wrong or the player changed during our processing\n            # This is usually due to something like a player being killed\n            # whilst we are checking its details\n            # Retry but limit the number of attempts\n            self._tries += 1\n            if self._tries < 3:\n                return self.mpris()\n            # Max retries hit we need to output something\n            composite = [\n                {\"full_text\": \"Something went wrong\", \"color\": self.py3.COLOR_BAD}\n            ]\n            cached_until = self.py3.time_in(1)\n\n        response = {\n            \"cached_until\": cached_until,\n            \"color\": color,\n            \"composite\": composite,\n        }\n\n        # we are outputing so reset tries\n        self._tries = 0\n        return response", "response": "Get the current output format and return it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle click events on the related control class", "response": "def on_click(self, event):\n        \"\"\"\n        Handles click events\n        \"\"\"\n        index = event[\"index\"]\n        button = event[\"button\"]\n\n        if index not in self._control_states.keys():\n            if button == self.button_toggle:\n                index = \"toggle\"\n            elif button == self.button_stop:\n                index = \"stop\"\n            elif button == self.button_next:\n                index = \"next\"\n            elif button == self.button_previous:\n                index = \"previous\"\n            else:\n                return\n        elif button != 1:\n            return\n\n        try:\n            control_state = self._control_states.get(index)\n            if self._player and self._get_button_state(control_state):\n                getattr(self._player, self._control_states[index][\"action\"])()\n        except GError as err:\n            self.py3.log(str(err).split(\":\", 1)[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_timezone(self, tz):\n        # special Local timezone\n        if tz == \"Local\":\n            try:\n                return tzlocal.get_localzone()\n            except pytz.UnknownTimeZoneError:\n                return \"?\"\n\n        # we can use a country code to get tz\n        # FIXME this is broken for multi-timezone countries eg US\n        # for now we just grab the first one\n        if len(tz) == 2:\n            try:\n                zones = pytz.country_timezones(tz)\n            except KeyError:\n                return \"?\"\n            tz = zones[0]\n\n        # get the timezone\n        try:\n            zone = pytz.timezone(tz)\n        except pytz.UnknownTimeZoneError:\n            return \"?\"\n        return zone", "response": "Find and return the time zone if possible"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nswitching the displayed module or pass the event on to the active module", "response": "def on_click(self, event):\n        \"\"\"\n        Switch the displayed module or pass the event on to the active module\n        \"\"\"\n        if event[\"button\"] == self.button_reset:\n            self._change_active(0)\n        elif event[\"button\"] == self.button_change_time_format:\n            self.active_time_format += 1\n            if self.active_time_format >= len(self.format_time):\n                self.active_time_format = 0\n            # save the active format_time\n            time_format = self.format_time[self.active_time_format]\n            self.py3.storage_set(\"time_format\", time_format)\n        elif event[\"button\"] == self.button_change_format:\n            self._change_active(1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup(sphinx):\n    create_auto_documentation()\n\n    # add the py3status lexer (for code blocks)\n    from sphinx.highlighting import lexers\n    lexers['py3status'] = Py3statusLexer()\n\n    # enable screenshot directive for dynamic screenshots\n    sphinx.add_directive('screenshot', ScreenshotDirective)", "response": "This function will be called by sphinx."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compile_re(self, expression):\n        meta_words = \"|\".join(self.sanitize_words)\n        expression = expression.replace(\"META_WORDS_HERE\", meta_words)\n        return re.compile(expression, re.IGNORECASE)", "response": "Compile given regular expression for current sanitize words"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the current text from the DBus API.", "response": "def _get_text(self):\n        \"\"\"\n        Get the current song metadatas (artist - title)\n        \"\"\"\n        bus = dbus.SessionBus()\n        try:\n            self.__bus = bus.get_object(\n                \"org.mpris.MediaPlayer2.spotify\", \"/org/mpris/MediaPlayer2\"\n            )\n            self.player = dbus.Interface(self.__bus, \"org.freedesktop.DBus.Properties\")\n\n            try:\n                metadata = self.player.Get(\"org.mpris.MediaPlayer2.Player\", \"Metadata\")\n                album = metadata.get(\"xesam:album\")\n                artist = metadata.get(\"xesam:artist\")[0]\n                microtime = metadata.get(\"mpris:length\")\n                rtime = str(timedelta(microseconds=microtime))[:-7]\n                title = metadata.get(\"xesam:title\")\n                if self.sanitize_titles:\n                    album = self._sanitize_title(album)\n                    title = self._sanitize_title(title)\n\n                playback_status = self.player.Get(\n                    \"org.mpris.MediaPlayer2.Player\", \"PlaybackStatus\"\n                )\n                if playback_status.strip() == \"Playing\":\n                    color = self.py3.COLOR_PLAYING or self.py3.COLOR_GOOD\n                else:\n                    color = self.py3.COLOR_PAUSED or self.py3.COLOR_DEGRADED\n            except Exception:\n                return (\n                    self.format_stopped,\n                    self.py3.COLOR_PAUSED or self.py3.COLOR_DEGRADED,\n                )\n\n            return (\n                self.py3.safe_format(\n                    self.format,\n                    dict(title=title, artist=artist, album=album, time=rtime),\n                ),\n                color,\n            )\n        except Exception:\n            return (self.format_down, self.py3.COLOR_OFFLINE or self.py3.COLOR_BAD)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove redunant meta data from title and return it.", "response": "def _sanitize_title(self, title):\n        \"\"\"\n        Remove redunant meta data from title and return it\n        \"\"\"\n        title = re.sub(self.inside_brackets, \"\", title)\n        title = re.sub(self.after_delimiter, \"\", title)\n        return title.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spotify(self):\n        (text, color) = self._get_text()\n        response = {\n            \"cached_until\": self.py3.time_in(self.cache_timeout),\n            \"color\": color,\n            \"full_text\": text,\n        }\n        return response", "response": "Get the current artist - title and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_legacy_storage_path(self):\n        config_dir = os.path.dirname(\n            self.py3_wrapper.config.get(\"i3status_config_path\", \"/tmp\")\n        )\n        storage_path = os.path.join(config_dir, \"py3status.data\")\n        if os.path.exists(storage_path):\n            return storage_path\n        else:\n            return None", "response": "Detect and return existing legacy storage path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self):\n        with NamedTemporaryFile(\n            dir=os.path.dirname(self.storage_path), delete=False\n        ) as f:\n            # we use protocol=2 for python 2/3 compatibility\n            dump(self.data, f, protocol=2)\n            f.flush()\n            os.fsync(f.fileno())\n            tmppath = f.name\n        os.rename(tmppath, self.storage_path)", "response": "Save our data to disk."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix(self, item):\n        if not self.is_python_2:\n            return item\n        if isinstance(item, str):\n            return item.decode(\"utf-8\")\n        if isinstance(item, unicode):  # noqa <-- python3 has no unicode\n            return item\n        if isinstance(item, Mapping):\n            return dict(map(self.fix, item.items()))\n        elif isinstance(item, Iterable):\n            return type(item)(map(self.fix, item))\n\n        return item", "response": "Fix unicode strings in a dictionary and return a new dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts seconds to days hours minutes and seconds.", "response": "def secs_to_dhms(time_in_secs):\n        \"\"\"Convert seconds to days, hours, minutes, seconds.\n\n        Using days as the largest unit of time.  Blindly using the days in\n        `time.gmtime()` will fail if it's more than one month (days > 31).\n        \"\"\"\n        days = int(time_in_secs / SECS_IN_DAY)\n        remaining_secs = time_in_secs % SECS_IN_DAY\n        hours = int(remaining_secs / SECS_IN_HOUR)\n        remaining_secs = remaining_secs % SECS_IN_HOUR\n        mins = int(remaining_secs / SECS_IN_MIN)\n        secs = int(remaining_secs % SECS_IN_MIN)\n        return days, hours, mins, secs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_click(self, event):\n        if event[\"button\"] == 1:\n            if self._running:\n                self._running = False\n                self._time_left = self._end_time - time()\n                if self._timer:\n                    self._timer.cancel()\n            else:\n                self._running = True\n                self._end_time = time() + self._time_left\n                if self._timer:\n                    self._timer.cancel()\n                self._timer = Timer(self._time_left, self._time_up)\n                self._timer.start()\n                if self._active:\n                    self.py3.play_sound(self.sound_pomodoro_start)\n\n        elif event[\"button\"] == 2:\n            # reset\n            self._init()\n            if self._timer:\n                self._timer.cancel()\n\n        elif event[\"button\"] == 3:\n            # advance\n            self._advance(user_action=True)\n            if self._timer:\n                self._timer.cancel()", "response": "Handles mouse click events."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pomodoro(self):\n        if not self._initialized:\n            self._init()\n\n        cached_until = self.py3.time_in(0)\n        if self._running:\n            self._time_left = ceil(self._end_time - time())\n            time_left = ceil(self._time_left)\n        else:\n            time_left = ceil(self._time_left)\n\n        vals = {\"ss\": int(time_left), \"mm\": int(ceil(time_left / 60))}\n\n        if self.py3.format_contains(self.format, \"mmss\"):\n            hours, rest = divmod(time_left, 3600)\n            mins, seconds = divmod(rest, 60)\n\n            if hours:\n                vals[\"mmss\"] = u\"%d%s%02d%s%02d\" % (\n                    hours,\n                    self.format_separator,\n                    mins,\n                    self.format_separator,\n                    seconds,\n                )\n            else:\n                vals[\"mmss\"] = u\"%d%s%02d\" % (mins, self.format_separator, seconds)\n\n        if self.py3.format_contains(self.format, \"bar\"):\n            vals[\"bar\"] = self._setup_bar()\n\n        formatted = self.format.format(**vals)\n\n        if self._running:\n            if self._active:\n                format = self.format_active\n            else:\n                format = self.format_break\n        else:\n            if self._active:\n                format = self.format_stopped\n            else:\n                format = self.format_break_stopped\n            cached_until = self.py3.CACHE_FOREVER\n\n        response = {\n            \"full_text\": format.format(\n                breakno=self._break_number, format=formatted, **vals\n            ),\n            \"cached_until\": cached_until,\n        }\n\n        if self._alert:\n            response[\"urgent\"] = True\n            self._alert = False\n\n        if not self._running:\n            response[\"color\"] = self.py3.COLOR_BAD\n        else:\n            if self._active:\n                response[\"color\"] = self.py3.COLOR_GOOD\n            else:\n                response[\"color\"] = self.py3.COLOR_DEGRADED\n\n        return response", "response": "This method returns a Pomodoro response handling and countdowns of the current countdown."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_click(self, event):\n        button = event[\"button\"]\n        if button in [1, 4, 5]:\n            self.scrolling = True\n            self._switch_selection()\n        elif button == 3:\n            self._apply()", "response": "Click events\n            - left click & scroll up / down"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _setup_pyudev_monitoring(self):\n        context = pyudev.Context()\n        monitor = pyudev.Monitor.from_netlink(context)\n        self.udev_observer = pyudev.MonitorObserver(monitor, self._udev_event)\n        self.udev_observer.start()\n        self.py3_wrapper.log(\"udev monitoring enabled\")", "response": "Setup the udev monitoring."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subscribe(self, py3_module, trigger_action, subsystem):\n        if self.pyudev_available:\n            # lazy load the udev monitor\n            if self.udev_observer is None:\n                self._setup_pyudev_monitoring()\n            if trigger_action not in ON_TRIGGER_ACTIONS:\n                self.py3_wrapper.log(\n                    \"module %s: invalid action %s on udev events subscription\"\n                    % (py3_module.module_full_name, trigger_action)\n                )\n                return False\n            self.udev_consumers[subsystem].append((py3_module, trigger_action))\n            self.py3_wrapper.log(\n                \"module %s subscribed to udev events on %s\"\n                % (py3_module.module_full_name, subsystem)\n            )\n            return True\n        else:\n            self.py3_wrapper.log(\n                \"pyudev module not installed: module %s not subscribed to events on %s\"\n                % (py3_module.module_full_name, subsystem)\n            )\n            return False", "response": "Subscribe the given module to the given udev subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trigger_actions(self, subsystem):\n        for py3_module, trigger_action in self.udev_consumers[subsystem]:\n            if trigger_action in ON_TRIGGER_ACTIONS:\n                self.py3_wrapper.log(\n                    \"%s udev event, refresh consumer %s\"\n                    % (subsystem, py3_module.module_full_name)\n                )\n                py3_module.force_update()", "response": "Refresh all modules which subscribed to the given subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        if self.update_time_value():\n            self.i3status.py3_wrapper.notify_update(self.module_name)\n        due_time = self.py3.time_in(sync_to=self.time_delta)\n\n        self.i3status.py3_wrapper.timeout_queue_add(self, due_time)", "response": "Updates the modules output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the internal state of the object based on the item. Returns True if item has changed.", "response": "def update_from_item(self, item):\n        \"\"\"\n        Update from i3status output. returns if item has changed.\n        \"\"\"\n        if not self.is_time_module:\n            # correct the output\n            # Restore the name/instance.\n            item[\"name\"] = self.name\n            item[\"instance\"] = self.instance\n\n            # change color good/bad is set specifically for module\n            if \"color\" in item and item[\"color\"] in self.color_map:\n                item[\"color\"] = self.color_map[item[\"color\"]]\n\n            # have we updated?\n            is_updated = self.item != item\n            self.item = item\n        else:\n            # If no timezone or a minute has passed update timezone\n            t = time()\n            if self.time_zone_check_due < t:\n                # If we are late for our timezone update then schedule the next\n                # update to happen when we next get new data from i3status\n                interval = self.i3status.update_interval\n                if not self.set_time_zone(item):\n                    # we had an issue with an invalid time zone probably due to\n                    # suspending.  re check the time zone when we next can.\n                    self.time_zone_check_due = 0\n                elif self.time_zone_check_due and (\n                    t - self.time_zone_check_due > 5 + interval\n                ):\n                    self.time_zone_check_due = 0\n                else:\n                    # Check again in 30 mins.  We do this in case the timezone\n                    # used has switched to/from summer time\n                    self.time_zone_check_due = ((int(t) // 1800) * 1800) + 1800\n                if not self.time_started:\n                    self.time_started = True\n                    self.i3status.py3_wrapper.timeout_queue_add(self)\n            is_updated = False\n            # update time to be shown\n        return is_updated"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_time_zone(self, item):\n        # parse i3status date\n        i3s_time = item[\"full_text\"].encode(\"UTF-8\", \"replace\")\n        try:\n            # python3 compatibility code\n            i3s_time = i3s_time.decode()\n        except:  # noqa e722\n            pass\n\n        # get datetime and time zone info\n        parts = i3s_time.split()\n        i3s_datetime = \" \".join(parts[:2])\n        # occassionally we do not get the timezone name\n        if len(parts) < 3:\n            return True\n        else:\n            i3s_time_tz = parts[2]\n\n        date = datetime.strptime(i3s_datetime, TIME_FORMAT)\n        # calculate the time delta\n        utcnow = datetime.utcnow()\n        delta = datetime(\n            date.year, date.month, date.day, date.hour, date.minute\n        ) - datetime(utcnow.year, utcnow.month, utcnow.day, utcnow.hour, utcnow.minute)\n        # create our custom timezone\n        try:\n            self.tz = Tz(i3s_time_tz, delta)\n        except ValueError:\n            return False\n        return True", "response": "Work out the time zone and create a shim tzinfo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndo any setup work needed to run i3status modules", "response": "def setup(self):\n        \"\"\"\n        Do any setup work needed to run i3status modules\n        \"\"\"\n        for conf_name in self.py3_config[\"i3s_modules\"]:\n            module = I3statusModule(conf_name, self)\n            self.i3modules[conf_name] = module\n            if module.is_time_module:\n                self.time_modules.append(module)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a given parameter name is a valid parameter for i3status.", "response": "def valid_config_param(self, param_name, cleanup=False):\n        \"\"\"\n        Check if a given section name is a valid parameter for i3status.\n        \"\"\"\n        if cleanup:\n            valid_config_params = [\n                _\n                for _ in self.i3status_module_names\n                if _ not in [\"cpu_usage\", \"ddate\", \"ipv6\", \"load\", \"time\"]\n            ]\n        else:\n            valid_config_params = self.i3status_module_names + [\"general\", \"order\"]\n        return param_name.split(\" \")[0] in valid_config_params"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the given i3status responses on their respective configuration.", "response": "def set_responses(self, json_list):\n        \"\"\"\n        Set the given i3status responses on their respective configuration.\n        \"\"\"\n        self.update_json_list()\n        updates = []\n        for index, item in enumerate(self.json_list):\n            conf_name = self.py3_config[\"i3s_modules\"][index]\n\n            module = self.i3modules[conf_name]\n            if module.update_from_item(item):\n                updates.append(conf_name)\n        if updates:\n            self.py3_wrapper.notify_update(updates)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_in_tmpfile(text, tmpfile):\n        try:\n            tmpfile.write(text)\n        except TypeError:\n            tmpfile.write(str.encode(text))\n        except UnicodeEncodeError:\n            tmpfile.write(text.encode(\"utf-8\"))", "response": "Write the given text in the given tmpfile in python2 and python3."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_tmp_i3status_config(self, tmpfile):\n        # order += ...\n        for module in self.py3_config[\"i3s_modules\"]:\n            self.write_in_tmpfile('order += \"%s\"\\n' % module, tmpfile)\n        self.write_in_tmpfile(\"\\n\", tmpfile)\n        # config params for general section and each module\n        for section_name in [\"general\"] + self.py3_config[\"i3s_modules\"]:\n            section = self.py3_config[section_name]\n            self.write_in_tmpfile(\"%s {\\n\" % section_name, tmpfile)\n            for key, value in section.items():\n                # don't include color values except in the general section\n                if key.startswith(\"color\"):\n                    if (\n                        section_name.split(\" \")[0] not in I3S_COLOR_MODULES\n                        or key not in I3S_ALLOWED_COLORS\n                    ):\n                        continue\n                # Set known fixed format for time and tztime so we can work\n                # out the timezone\n                if section_name.split()[0] in TIME_MODULES:\n                    if key == \"format\":\n                        value = TZTIME_FORMAT\n                    if key == \"format_time\":\n                        continue\n                if isinstance(value, bool):\n                    value = \"{}\".format(value).lower()\n                self.write_in_tmpfile('    %s = \"%s\"\\n' % (key, value), tmpfile)\n            self.write_in_tmpfile(\"}\\n\\n\", tmpfile)\n        tmpfile.flush()", "response": "Write a valid i3status config file based on the parsed one from i3status_config_path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nspawning i3status using a self generated config file and poll its output.", "response": "def spawn_i3status(self):\n        \"\"\"\n        Spawn i3status using a self generated config file and poll its output.\n        \"\"\"\n        try:\n            with NamedTemporaryFile(prefix=\"py3status_\") as tmpfile:\n                self.write_tmp_i3status_config(tmpfile)\n\n                i3status_pipe = Popen(\n                    [self.i3status_path, \"-c\", tmpfile.name],\n                    stdout=PIPE,\n                    stderr=PIPE,\n                    # Ignore the SIGTSTP signal for this subprocess\n                    preexec_fn=lambda: signal(SIGTSTP, SIG_IGN),\n                )\n\n                self.py3_wrapper.log(\n                    \"i3status spawned using config file {}\".format(tmpfile.name)\n                )\n\n                self.poller_inp = IOPoller(i3status_pipe.stdout)\n                self.poller_err = IOPoller(i3status_pipe.stderr)\n                self.tmpfile_path = tmpfile.name\n\n                # Store the pipe so we can signal it\n                self.i3status_pipe = i3status_pipe\n\n                try:\n                    # loop on i3status output\n                    while self.py3_wrapper.running:\n                        line = self.poller_inp.readline()\n                        if line:\n                            # remove leading comma if present\n                            if line[0] == \",\":\n                                line = line[1:]\n                            if line.startswith(\"[{\"):\n                                json_list = loads(line)\n                                self.last_output = json_list\n                                self.set_responses(json_list)\n                                self.ready = True\n                        else:\n                            err = self.poller_err.readline()\n                            code = i3status_pipe.poll()\n                            if code is not None:\n                                msg = \"i3status died\"\n                                if err:\n                                    msg += \" and said: {}\".format(err)\n                                else:\n                                    msg += \" with code {}\".format(code)\n                                raise IOError(msg)\n                except IOError:\n                    err = sys.exc_info()[1]\n                    self.error = err\n                    self.py3_wrapper.log(err, \"error\")\n        except OSError:\n            self.error = \"Problem starting i3status maybe it is not installed\"\n        except Exception:\n            self.py3_wrapper.report_exception(\"\", notify_user=True)\n        self.i3status_pipe = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef catch_factory(attr):\n\n    def _catch(s, *args, **kw):\n        \"\"\"\n        This is used to catch and process all calls.\n        \"\"\"\n\n        def process(value):\n            \"\"\"\n            return the actual value after processing\n            \"\"\"\n            if attr.startswith(\"__\"):\n                # __repr__, __str__ etc\n                return getattr(value, attr)(*args, **kw)\n            else:\n                # upper, lower etc\n                return getattr(u\"\".__class__, attr)(value, *args, **kw)\n\n        stack = inspect.stack()\n        mod = inspect.getmodule(stack[1][0])\n        # We are called from the owning module so allow\n        if mod.__name__.split(\".\")[-1] == s._module_name:\n            return process(s._value)\n        # very shallow calling no stack\n        if len(stack) < 3:\n            return process(s._private)\n        # Check if this is an internal or external module.  We need to allow\n        # calls to modules like requests etc\n        remote = not inspect.getmodule(stack[2][0]).__name__.startswith(\"py3status\")\n        valid = False\n        # go through the stack to see how we came through the code\n        for frame in stack[2:]:\n            mod = inspect.getmodule(frame[0])\n            if remote and mod.__name__.split(\".\")[-1] == s._module_name:\n                # the call to an external module started in the correct module\n                # so allow this usage\n                valid = True\n                break\n            if mod.__name__ == \"py3status.py3\" and frame[3] == \"request\":\n                # Py3.request has special needs due so it is allowed to access\n                # private variables.\n                valid = True\n                break\n            if mod.__name__.startswith(\"py3status\"):\n                # We were somewhere else in py3status than the module, maybe we\n                # are doing some logging.  Prevent usage\n                return process(s._private)\n        if valid:\n            return process(s._value)\n        return process(s._private)\n\n    return _catch", "response": "Returns a catch function that returns a new object that can be used to catch and process all calls."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget count for requests that return total_count in the json response.", "response": "def _github_count(self, url):\n        \"\"\"\n        Get counts for requests that return 'total_count' in the json response.\n        \"\"\"\n        url = self.url_api + url + \"&per_page=1\"\n        # if we have authentication details use them as we get better\n        # rate-limiting.\n        if self.username and self.auth_token:\n            auth = (self.username, self.auth_token)\n        else:\n            auth = None\n        try:\n            info = self.py3.request(url, auth=auth)\n        except (self.py3.RequestException):\n            return\n        if info and info.status_code == 200:\n            return int(info.json()[\"total_count\"])\n        if info.status_code == 422:\n            if not self.repo_warning:\n                self.py3.notify_user(\"Github repo cannot be found.\")\n                self.repo_warning = True\n        return \"?\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _notifications(self):\n        if not self.username or not self.auth_token:\n            if not self.notification_warning:\n                self.py3.notify_user(\n                    \"Github module needs username and \"\n                    \"auth_token to check notifications.\"\n                )\n                self.notification_warning = True\n            return \"?\"\n        if self.notifications == \"all\" or not self.repo:\n            url = self.url_api + \"/notifications\"\n        else:\n            url = self.url_api + \"/repos/\" + self.repo + \"/notifications\"\n        url += \"?per_page=100\"\n        try:\n            info = self.py3.request(url, auth=(self.username, self.auth_token))\n        except (self.py3.RequestException):\n            return\n        if info.status_code == 200:\n            links = info.headers.get(\"Link\")\n\n            if not links:\n                return len(info.json())\n\n            last_page = 1\n            for link in links.split(\",\"):\n                if 'rel=\"last\"' in link:\n                    last_url = link[link.find(\"<\") + 1 : link.find(\">\")]\n                    parsed = urlparse.urlparse(last_url)\n                    last_page = int(urlparse.parse_qs(parsed.query)[\"page\"][0])\n\n            if last_page == 1:\n                return len(info.json())\n            try:\n                last_page_info = self.py3.request(\n                    last_url, auth=(self.username, self.auth_token)\n                )\n            except self.py3.RequestException:\n                return\n\n            return len(info.json()) * (last_page - 1) + len(last_page_info.json())\n\n        if info.status_code == 404:\n            if not self.repo_warning:\n                self.py3.notify_user(\"Github repo cannot be found.\")\n                self.repo_warning = True", "response": "Get the number of unread notifications."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlook for the attribute in the config section of the named module and then try the general section of the config section of the named module and then try the general section of the config section of the named module.", "response": "def get_config_attribute(self, name, attribute):\n        \"\"\"\n        Look for the attribute in the config.  Start with the named module and\n        then walk up through any containing group and then try the general\n        section of the config.\n        \"\"\"\n\n        # A user can set a param to None in the config to prevent a param\n        # being used.  This is important when modules do something like\n        #\n        # color = self.py3.COLOR_MUTED or self.py3.COLOR_BAD\n        config = self.config[\"py3_config\"]\n        param = config[name].get(attribute, self.none_setting)\n        if hasattr(param, \"none_setting\") and name in config[\".module_groups\"]:\n            for module in config[\".module_groups\"][name]:\n                if attribute in config.get(module, {}):\n                    param = config[module].get(attribute)\n                    break\n        if hasattr(param, \"none_setting\"):\n            # check py3status config section\n            param = config[\"py3status\"].get(attribute, self.none_setting)\n        if hasattr(param, \"none_setting\"):\n            # check py3status general section\n            param = config[\"general\"].get(attribute, self.none_setting)\n        if param and (attribute == \"color\" or attribute.startswith(\"color_\")):\n            if param[0] != \"#\":\n                # named color\n                param = COLOR_NAMES.get(param.lower(), self.none_setting)\n            elif len(param) == 4:\n                # This is a color like #123 convert it to #112233\n                param = (\n                    \"#\"\n                    + param[1]\n                    + param[1]\n                    + param[2]\n                    + param[2]\n                    + param[3]\n                    + param[3]\n                )\n        return param"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef report_exception(self, msg, notify_user=True, level=\"error\", error_frame=None):\n        # Get list of paths that our stack trace should be found in.\n        py3_paths = [os.path.dirname(__file__)] + self.config[\"include_paths\"]\n        traceback = None\n\n        try:\n            # We need to make sure to delete tb even if things go wrong.\n            exc_type, exc_obj, tb = sys.exc_info()\n            stack = extract_tb(tb)\n            error_str = \"{}: {}\\n\".format(exc_type.__name__, exc_obj)\n            traceback = [error_str]\n\n            if error_frame:\n                # The error occurred in a py3status module so the traceback\n                # should be made to appear correct.  We caught the exception\n                # but make it look as though we did not.\n                traceback += format_stack(error_frame, 1) + format_tb(tb)\n                filename = os.path.basename(error_frame.f_code.co_filename)\n                line_no = error_frame.f_lineno\n            else:\n                # This is a none module based error\n                traceback += format_tb(tb)\n                # Find first relevant trace in the stack.\n                # it should be in py3status or one of it's modules.\n                found = False\n                for item in reversed(stack):\n                    filename = item[0]\n                    for path in py3_paths:\n                        if filename.startswith(path):\n                            # Found a good trace\n                            filename = os.path.basename(item[0])\n                            line_no = item[1]\n                            found = True\n                            break\n                    if found:\n                        break\n            # all done!  create our message.\n            msg = \"{} ({}) {} line {}.\".format(\n                msg, exc_type.__name__, filename, line_no\n            )\n        except:  # noqa e722\n            # something went wrong report what we can.\n            msg = \"{}.\".format(msg)\n        finally:\n            # delete tb!\n            del tb\n        # log the exception and notify user\n        self.py3_wrapper.log(msg, \"warning\")\n        if traceback:\n            # if debug is not in the config  then we are at an early stage of\n            # running py3status and logging is not yet available so output the\n            # error to STDERR so it can be seen\n            if \"debug\" not in self.config:\n                print_stderr(\"\\n\".join(traceback))\n            elif self.config.get(\"log_file\"):\n                self.py3_wrapper.log(\"\".join([\"Traceback\\n\"] + traceback))\n        if notify_user:\n            self.py3_wrapper.notify_user(msg, level=level)", "response": "Report details of an exception in the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef timeout_queue_add(self, item, cache_time=0):\n        # add the info to the add queue.  We do this so that actually adding\n        # the module is done in the core thread.\n        self.timeout_add_queue.append((item, cache_time))\n        # if the timeout_add_queue is not due to be processed until after this\n        # update request is due then trigger an update now.\n        if self.timeout_due is None or cache_time < self.timeout_due:\n            self.update_request.set()", "response": "Add an item to be run at a future time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timeout_process_add_queue(self, module, cache_time):\n        # If already set to update do nothing\n        if module in self.timeout_update_due:\n            return\n\n        # remove if already in the queue\n        key = self.timeout_queue_lookup.get(module)\n        if key:\n            queue_item = self.timeout_queue[key]\n            queue_item.remove(module)\n            if not queue_item:\n                del self.timeout_queue[key]\n                self.timeout_keys.remove(key)\n\n        if cache_time == 0:\n            # if cache_time is 0 we can just trigger the module update\n            self.timeout_update_due.append(module)\n            self.timeout_queue_lookup[module] = None\n        else:\n            # add the module to the timeout queue\n            if cache_time not in self.timeout_keys:\n                self.timeout_queue[cache_time] = set([module])\n                self.timeout_keys.append(cache_time)\n                # sort keys so earliest is first\n                self.timeout_keys.sort()\n\n                # when is next timeout due?\n                try:\n                    self.timeout_due = self.timeout_keys[0]\n                except IndexError:\n                    self.timeout_due = None\n            else:\n                self.timeout_queue[cache_time].add(module)\n            # note that the module is in the timeout_queue\n            self.timeout_queue_lookup[module] = cache_time", "response": "Add a module to the timeout queue if it is due for an update immediately trigger that."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess the timeout queue and set any due modules to update.", "response": "def timeout_queue_process(self):\n        \"\"\"\n        Check the timeout_queue and set any due modules to update.\n        \"\"\"\n        # process any items that need adding to the queue\n        while self.timeout_add_queue:\n            self.timeout_process_add_queue(*self.timeout_add_queue.popleft())\n        now = time.time()\n        due_timeouts = []\n        # find any due timeouts\n        for timeout in self.timeout_keys:\n            if timeout > now:\n                break\n            due_timeouts.append(timeout)\n\n        if due_timeouts:\n            # process them\n            for timeout in due_timeouts:\n                modules = self.timeout_queue[timeout]\n                # remove from the queue\n                del self.timeout_queue[timeout]\n                self.timeout_keys.remove(timeout)\n\n                for module in modules:\n                    # module no longer in queue\n                    del self.timeout_queue_lookup[module]\n                    # tell module to update\n                    self.timeout_update_due.append(module)\n\n            # when is next timeout due?\n            try:\n                self.timeout_due = self.timeout_keys[0]\n            except IndexError:\n                self.timeout_due = None\n\n        # process any finished modules.\n        # Now that the module has finished running it may have been marked to\n        # be triggered again. This is most likely to happen when events are\n        # being processed and the events are arriving much faster than the\n        # module can handle them.  It is important as a module may handle\n        # events but not trigger the module update.  If during the event the\n        # module is due to update the update is not actioned but it needs to be\n        # once the events have finished or else the module will no longer\n        # continue to update.\n        while self.timeout_finished:\n            module_name = self.timeout_finished.popleft()\n            self.timeout_running.discard(module_name)\n            if module_name in self.timeout_missed:\n                module = self.timeout_missed.pop(module_name)\n                self.timeout_update_due.append(module)\n\n        # run any modules that are due\n        while self.timeout_update_due:\n            module = self.timeout_update_due.popleft()\n            module_name = getattr(module, \"module_full_name\", None)\n            # if the module is running then we do not want to trigger it but\n            # instead wait till it has finished running and then trigger\n            if module_name and module_name in self.timeout_running:\n                self.timeout_missed[module_name] = module\n            else:\n                self.timeout_running.add(module_name)\n                Runner(module, self, module_name)\n\n        # we return how long till we next need to process the timeout_queue\n        if self.timeout_due is not None:\n            return self.timeout_due - time.time()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreporting effective gevent monkey patching on the logs.", "response": "def gevent_monkey_patch_report(self):\n        \"\"\"\n        Report effective gevent monkey patching on the logs.\n        \"\"\"\n        try:\n            import gevent.socket\n            import socket\n\n            if gevent.socket.socket is socket.socket:\n                self.log(\"gevent monkey patching is active\")\n                return True\n            else:\n                self.notify_user(\"gevent monkey patching failed.\")\n        except ImportError:\n            self.notify_user(\"gevent is not installed, monkey patching failed.\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a dictionary of user provided modules.", "response": "def get_user_modules(self):\n        \"\"\"\n        Search configured include directories for user provided modules.\n\n        user_modules: {\n            'weather_yahoo': ('~/i3/py3status/', 'weather_yahoo.py')\n        }\n        \"\"\"\n        user_modules = {}\n        for include_path in self.config[\"include_paths\"]:\n            for f_name in sorted(os.listdir(include_path)):\n                if not f_name.endswith(\".py\"):\n                    continue\n                module_name = f_name[:-3]\n                # do not overwrite modules if already found\n                if module_name in user_modules:\n                    pass\n                user_modules[module_name] = (include_path, f_name)\n        return user_modules"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a dict of all available and configured py3status modules in the user s i3status. conf.", "response": "def get_user_configured_modules(self):\n        \"\"\"\n        Get a dict of all available and configured py3status modules\n        in the user's i3status.conf.\n        \"\"\"\n        user_modules = {}\n        if not self.py3_modules:\n            return user_modules\n        for module_name, module_info in self.get_user_modules().items():\n            for module in self.py3_modules:\n                if module_name == module.split(\" \")[0]:\n                    include_path, f_name = module_info\n                    user_modules[module_name] = (include_path, f_name)\n        return user_modules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the given modules from the list of modules_list.", "response": "def load_modules(self, modules_list, user_modules):\n        \"\"\"\n        Load the given modules from the list (contains instance name) with\n        respect to the user provided modules dict.\n\n        modules_list: ['weather_yahoo paris', 'net_rate']\n        user_modules: {\n            'weather_yahoo': ('/etc/py3status.d/', 'weather_yahoo.py')\n        }\n        \"\"\"\n        for module in modules_list:\n            # ignore already provided modules (prevents double inclusion)\n            if module in self.modules:\n                continue\n            try:\n                my_m = Module(module, user_modules, self)\n                # only handle modules with available methods\n                if my_m.methods:\n                    self.modules[module] = my_m\n                elif self.config[\"debug\"]:\n                    self.log('ignoring module \"{}\" (no methods found)'.format(module))\n            except Exception:\n                err = sys.exc_info()[1]\n                msg = 'Loading module \"{}\" failed ({}).'.format(module, err)\n                self.report_exception(msg, level=\"warning\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(self):\n\n        # SIGTSTP will be received from i3bar indicating that all output should\n        # stop and we should consider py3status suspended.  It is however\n        # important that any processes using i3 ipc should continue to receive\n        # those events otherwise it can lead to a stall in i3.\n        signal(SIGTSTP, self.i3bar_stop)\n        # SIGCONT indicates output should be resumed.\n        signal(SIGCONT, self.i3bar_start)\n\n        # log py3status and python versions\n        self.log(\"=\" * 8)\n        msg = \"Starting py3status version {version} python {python_version}\"\n        self.log(msg.format(**self.config))\n\n        try:\n            # if running from git then log the branch and last commit\n            # we do this by looking in the .git directory\n            git_path = os.path.join(os.path.dirname(__file__), \"..\", \".git\")\n            # branch\n            with open(os.path.join(git_path, \"HEAD\"), \"r\") as f:\n                out = f.readline()\n            branch = \"/\".join(out.strip().split(\"/\")[2:])\n            self.log(\"git branch: {}\".format(branch))\n            # last commit\n            log_path = os.path.join(git_path, \"logs\", \"refs\", \"heads\", branch)\n            with open(log_path, \"r\") as f:\n                out = f.readlines()[-1]\n            sha = out.split(\" \")[1][:7]\n            msg = \":\".join(out.strip().split(\"\\t\")[-1].split(\":\")[1:])\n            self.log(\"git commit: {}{}\".format(sha, msg))\n        except:  # noqa e722\n            pass\n\n        self.log(\"window manager: {}\".format(self.config[\"wm_name\"]))\n\n        if self.config[\"debug\"]:\n            self.log(\"py3status started with config {}\".format(self.config))\n\n        if self.config[\"gevent\"]:\n            self.is_gevent = self.gevent_monkey_patch_report()\n        else:\n            self.is_gevent = False\n\n        # read i3status.conf\n        config_path = self.config[\"i3status_config_path\"]\n        self.log(\"config file: {}\".format(self.config[\"i3status_config_path\"]))\n        self.config[\"py3_config\"] = process_config(config_path, self)\n\n        # setup i3status thread\n        self.i3status_thread = I3status(self)\n\n        # If standalone or no i3status modules then use the mock i3status\n        # else start i3status thread.\n        i3s_modules = self.config[\"py3_config\"][\"i3s_modules\"]\n        if self.config[\"standalone\"] or not i3s_modules:\n            self.i3status_thread.mock()\n            i3s_mode = \"mocked\"\n        else:\n            for module in i3s_modules:\n                self.log(\"adding module {}\".format(module))\n            i3s_mode = \"started\"\n            self.i3status_thread.start()\n            while not self.i3status_thread.ready:\n                if not self.i3status_thread.is_alive():\n                    # i3status is having a bad day, so tell the user what went\n                    # wrong and do the best we can with just py3status modules.\n                    err = self.i3status_thread.error\n                    self.notify_user(err)\n                    self.i3status_thread.mock()\n                    i3s_mode = \"mocked\"\n                    break\n                time.sleep(0.1)\n        if self.config[\"debug\"]:\n            self.log(\n                \"i3status thread {} with config {}\".format(\n                    i3s_mode, self.config[\"py3_config\"]\n                )\n            )\n\n        # add i3status thread monitoring task\n        if i3s_mode == \"started\":\n            task = CheckI3StatusThread(self.i3status_thread, self)\n            self.timeout_queue_add(task)\n\n        # setup input events thread\n        self.events_thread = Events(self)\n        self.events_thread.daemon = True\n        self.events_thread.start()\n        if self.config[\"debug\"]:\n            self.log(\"events thread started\")\n\n        # initialise the command server\n        self.commands_thread = CommandServer(self)\n        self.commands_thread.daemon = True\n        self.commands_thread.start()\n        if self.config[\"debug\"]:\n            self.log(\"commands thread started\")\n\n        # initialize the udev monitor (lazy)\n        self.udev_monitor = UdevMonitor(self)\n\n        # suppress modules' ouput wrt issue #20\n        if not self.config[\"debug\"]:\n            sys.stdout = open(\"/dev/null\", \"w\")\n            sys.stderr = open(\"/dev/null\", \"w\")\n\n        # get the list of py3status configured modules\n        self.py3_modules = self.config[\"py3_config\"][\"py3_modules\"]\n\n        # get a dict of all user provided modules\n        self.log(\"modules include paths: {}\".format(self.config[\"include_paths\"]))\n        user_modules = self.get_user_configured_modules()\n        if self.config[\"debug\"]:\n            self.log(\"user_modules={}\".format(user_modules))\n\n        if self.py3_modules:\n            # load and spawn i3status.conf configured modules threads\n            self.load_modules(self.py3_modules, user_modules)", "response": "Setup py3status and spawn i3status threads."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notify_user(\n        self,\n        msg,\n        level=\"error\",\n        rate_limit=None,\n        module_name=\"\",\n        icon=None,\n        title=\"py3status\",\n    ):\n        \"\"\"\n        Display notification to user via i3-nagbar or send-notify\n        We also make sure to log anything to keep trace of it.\n\n        NOTE: Message should end with a '.' for consistency.\n        \"\"\"\n        dbus = self.config.get(\"dbus_notify\")\n        if dbus:\n            # force msg, icon, title to be a string\n            title = u\"{}\".format(title)\n            msg = u\"{}\".format(msg)\n            if icon:\n                icon = u\"{}\".format(icon)\n        else:\n            msg = u\"py3status: {}\".format(msg)\n        if level != \"info\" and module_name == \"\":\n            fix_msg = u\"{} Please try to fix this and reload i3wm (Mod+Shift+R)\"\n            msg = fix_msg.format(msg)\n        # Rate limiting. If rate limiting then we need to calculate the time\n        # period for which the message should not be repeated.  We just use\n        # A simple chunked time model where a message cannot be repeated in a\n        # given time period. Messages can be repeated more frequently but must\n        # be in different time periods.\n\n        limit_key = \"\"\n        if rate_limit:\n            try:\n                limit_key = time.time() // rate_limit\n            except TypeError:\n                pass\n        # We use a hash to see if the message is being repeated.  This is crude\n        # and imperfect but should work for our needs.\n        msg_hash = hash(u\"{}#{}#{}#{}\".format(module_name, limit_key, msg, title))\n        if msg_hash in self.notified_messages:\n            return\n        elif module_name:\n            log_msg = 'Module `%s` sent a notification. \"%s: %s\"' % (\n                module_name,\n                title,\n                msg,\n            )\n            self.log(log_msg, level)\n        else:\n            self.log(msg, level)\n        self.notified_messages.add(msg_hash)\n\n        try:\n            if dbus:\n                # fix any html entities\n                msg = msg.replace(\"&\", \"&amp;\")\n                msg = msg.replace(\"<\", \"&lt;\")\n                msg = msg.replace(\">\", \"&gt;\")\n                cmd = [\"notify-send\"]\n                if icon:\n                    cmd += [\"-i\", icon]\n                cmd += [\"-u\", DBUS_LEVELS.get(level, \"normal\"), \"-t\", \"10000\"]\n                cmd += [title, msg]\n            else:\n                py3_config = self.config.get(\"py3_config\", {})\n                nagbar_font = py3_config.get(\"py3status\", {}).get(\"nagbar_font\")\n                wm_nag = self.config[\"wm\"][\"nag\"]\n                cmd = [wm_nag, \"-m\", msg, \"-t\", level]\n                if nagbar_font:\n                    cmd += [\"-f\", nagbar_font]\n            Popen(cmd, stdout=open(\"/dev/null\", \"w\"), stderr=open(\"/dev/null\", \"w\"))\n        except Exception as err:\n            self.log(\"notify_user error: %s\" % err)", "response": "Send a message to a user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        self.running = False\n        # stop the command server\n        try:\n            self.commands_thread.kill()\n        except:  # noqa e722\n            pass\n\n        try:\n            self.lock.set()\n            if self.config[\"debug\"]:\n                self.log(\"lock set, exiting\")\n            # run kill() method on all py3status modules\n            for module in self.modules.values():\n                module.kill()\n        except:  # noqa e722\n            pass", "response": "Stop the event server and all modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates modules. if module_string is None all modules are refreshed if module_string then modules with the exact name or those starting with the given string depending on exact parameter will be refreshed. If a module is an i3status one then we refresh i3status. To prevent abuse, we rate limit this function to 100ms for full refreshes.", "response": "def refresh_modules(self, module_string=None, exact=True):\n        \"\"\"\n        Update modules.\n        if module_string is None all modules are refreshed\n        if module_string then modules with the exact name or those starting\n        with the given string depending on exact parameter will be refreshed.\n        If a module is an i3status one then we refresh i3status.\n        To prevent abuse, we rate limit this function to 100ms for full\n        refreshes.\n        \"\"\"\n        if not module_string:\n            if time.time() > (self.last_refresh_ts + 0.1):\n                self.last_refresh_ts = time.time()\n            else:\n                # rate limiting\n                return\n        update_i3status = False\n        for name, module in self.output_modules.items():\n            if (\n                module_string is None\n                or (exact and name == module_string)\n                or (not exact and name.startswith(module_string))\n            ):\n                if module[\"type\"] == \"py3status\":\n                    if self.config[\"debug\"]:\n                        self.log(\"refresh py3status module {}\".format(name))\n                    module[\"module\"].force_update()\n                else:\n                    if self.config[\"debug\"]:\n                        self.log(\"refresh i3status module {}\".format(name))\n                    update_i3status = True\n        if update_i3status:\n            self.i3status_thread.refresh_i3status()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a module from the modules list.", "response": "def purge_module(self, module_name):\n        \"\"\"\n        A module has been removed e.g. a module that had an error.\n        We need to find any containers and remove the module from them.\n        \"\"\"\n        containers = self.config[\"py3_config\"][\".module_groups\"]\n        containers_to_update = set()\n        if module_name in containers:\n            containers_to_update.update(set(containers[module_name]))\n        for container in containers_to_update:\n            try:\n                self.modules[container].module_class.items.remove(module_name)\n            except ValueError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef notify_update(self, update, urgent=False):\n        if not isinstance(update, list):\n            update = [update]\n        self.update_queue.extend(update)\n\n        # find containers that use the modules that updated\n        containers = self.config[\"py3_config\"][\".module_groups\"]\n        containers_to_update = set()\n        for item in update:\n            if item in containers:\n                containers_to_update.update(set(containers[item]))\n        # force containers to update\n        for container in containers_to_update:\n            container_module = self.output_modules.get(container)\n            if container_module:\n                # If the container registered a urgent_function then call it\n                # if this update is urgent.\n                if urgent and container_module.get(\"urgent_function\"):\n                    container_module[\"urgent_function\"](update)\n                # If a container has registered a content_function we use that\n                # to see if the container needs to be updated.\n                # We only need to update containers if their active content has\n                # changed.\n                if container_module.get(\"content_function\"):\n                    if set(update) & container_module[\"content_function\"]():\n                        container_module[\"module\"].force_update()\n                else:\n                    # we don't know so just update.\n                    container_module[\"module\"].force_update()\n\n        # we need to update the output\n        if self.update_queue:\n            self.update_request.set()", "response": "Notify the containers that the modules have updated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlogging a message to syslog or user provided logfile.", "response": "def log(self, msg, level=\"info\"):\n        \"\"\"\n        log this information to syslog or user provided logfile.\n        \"\"\"\n        if not self.config.get(\"log_file\"):\n            # If level was given as a str then convert to actual level\n            level = LOG_LEVELS.get(level, level)\n            syslog(level, u\"{}\".format(msg))\n        else:\n            # Binary mode so fs encoding setting is not an issue\n            with open(self.config[\"log_file\"], \"ab\") as f:\n                log_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n                # nice formating of data structures using pretty print\n                if isinstance(msg, (dict, list, set, tuple)):\n                    msg = pformat(msg)\n                    # if multiline then start the data output on a fresh line\n                    # to aid readability.\n                    if \"\\n\" in msg:\n                        msg = u\"\\n\" + msg\n                out = u\"{} {} {}\\n\".format(log_time, level.upper(), msg)\n                try:\n                    # Encode unicode strings to bytes\n                    f.write(out.encode(\"utf-8\"))\n                except (AttributeError, UnicodeDecodeError):\n                    # Write any byte strings straight to log\n                    f.write(out)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_output_modules(self):\n        py3_config = self.config[\"py3_config\"]\n        i3modules = self.i3status_thread.i3modules\n        output_modules = self.output_modules\n        # position in the bar of the modules\n        positions = {}\n        for index, name in enumerate(py3_config[\"order\"]):\n            if name not in positions:\n                positions[name] = []\n            positions[name].append(index)\n\n        # py3status modules\n        for name in self.modules:\n            if name not in output_modules:\n                output_modules[name] = {}\n                output_modules[name][\"position\"] = positions.get(name, [])\n                output_modules[name][\"module\"] = self.modules[name]\n                output_modules[name][\"type\"] = \"py3status\"\n                output_modules[name][\"color\"] = self.mappings_color.get(name)\n        # i3status modules\n        for name in i3modules:\n            if name not in output_modules:\n                output_modules[name] = {}\n                output_modules[name][\"position\"] = positions.get(name, [])\n                output_modules[name][\"module\"] = i3modules[name]\n                output_modules[name][\"type\"] = \"i3status\"\n                output_modules[name][\"color\"] = self.mappings_color.get(name)\n\n        self.output_modules = output_modules", "response": "Create our output modules for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate any mappings needed for global substitutions eg. colors", "response": "def create_mappings(self, config):\n        \"\"\"\n        Create any mappings needed for global substitutions eg. colors\n        \"\"\"\n        mappings = {}\n        for name, cfg in config.items():\n            # Ignore special config sections.\n            if name in CONFIG_SPECIAL_SECTIONS:\n                continue\n            color = self.get_config_attribute(name, \"color\")\n            if hasattr(color, \"none_setting\"):\n                color = None\n            mappings[name] = color\n        # Store mappings for later use.\n        self.mappings_color = mappings"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_module_output(self, module):\n        outputs = module[\"module\"].get_latest()\n        color = module[\"color\"]\n        if color:\n            for output in outputs:\n                # Color: substitute the config defined color\n                if \"color\" not in output:\n                    output[\"color\"] = color\n        # Create the json string output.\n        return \",\".join([dumps(x) for x in outputs])", "response": "Process the output for a module and return a json string representing it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        # SIGUSR1 forces a refresh of the bar both for py3status and i3status,\n        # this mimics the USR1 signal handling of i3status (see man i3status)\n        signal(SIGUSR1, self.sig_handler)\n        signal(SIGTERM, self.terminate)\n\n        # initialize usage variables\n        py3_config = self.config[\"py3_config\"]\n\n        # prepare the color mappings\n        self.create_mappings(py3_config)\n\n        # self.output_modules needs to have been created before modules are\n        # started.  This is so that modules can do things like register their\n        # content_function.\n        self.create_output_modules()\n\n        # start up all our modules\n        for module in self.modules.values():\n            task = ModuleRunner(module)\n            self.timeout_queue_add(task)\n\n        # this will be our output set to the correct length for the number of\n        # items in the bar\n        output = [None] * len(py3_config[\"order\"])\n\n        write = sys.__stdout__.write\n        flush = sys.__stdout__.flush\n\n        # start our output\n        header = {\n            \"version\": 1,\n            \"click_events\": self.config[\"click_events\"],\n            \"stop_signal\": SIGTSTP,\n        }\n        write(dumps(header))\n        write(\"\\n[[]\\n\")\n\n        update_due = None\n        # main loop\n        while True:\n            # process the timeout_queue and get interval till next update due\n            update_due = self.timeout_queue_process()\n\n            # wait until an update is requested\n            if self.update_request.wait(timeout=update_due):\n                # event was set so clear it\n                self.update_request.clear()\n\n            while not self.i3bar_running:\n                time.sleep(0.1)\n\n            # check if an update is needed\n            if self.update_queue:\n                while len(self.update_queue):\n                    module_name = self.update_queue.popleft()\n                    module = self.output_modules[module_name]\n                    out = self.process_module_output(module)\n\n                    for index in module[\"position\"]:\n                        # store the output as json\n                        output[index] = out\n\n                # build output string\n                out = \",\".join([x for x in output if x])\n                # dump the line to stdout\n                write(\",[{}]\\n\".format(out))\n                flush()", "response": "Main main loop for i3status modules and i3status output i3status and modules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a hex color to rgb", "response": "def hex_2_rgb(self, color):\n        \"\"\"\n        convert a hex color to rgb\n        \"\"\"\n        if not self.RE_HEX.match(color):\n            color = \"#FFF\"\n        if len(color) == 7:\n            return (int(color[i : i + 2], 16) / 255 for i in [1, 3, 5])\n        return (int(c, 16) / 15 for c in color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rgb_2_hex(self, r, g, b):\n        return \"#{:02X}{:02X}{:02X}\".format(int(r * 255), int(g * 255), int(b * 255))", "response": "convert a rgb color to hex"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a hsv color to hex", "response": "def hsv_2_hex(self, h, s, v):\n        \"\"\"\n        convert a hsv color to hex\n        \"\"\"\n        return self.rgb_2_hex(*hsv_to_rgb(h, s, v))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a mid color between color1 and color2.", "response": "def make_mid_color(self, color1, color2, distance, long_route=False):\n        \"\"\"\n        Generate a mid color between color1 and color2.\n        Colors should be a tuple (hue, saturation, value).\n\n        distance is a float between 0.0 and 1.0 describing how far between\n        color1 and color2 we want to return the color. 0.0 would return color1,\n        1.0 color2, and 0.5 a color midway.\n\n        long_route allows us to choose how we get from color1 to color2 around\n        the color wheel if True we go the long way, through as many colors as\n        we can, if False we go through the minimum number\n        \"\"\"\n\n        def fade(a, b):\n            x = b * distance\n            x += a * (1 - distance)\n            return x\n\n        h1, s1, v1 = color1\n        h2, s2, v2 = color2\n\n        hue_diff = h1 - h2\n        if long_route:\n            if hue_diff < 0.5 and hue_diff > -0.5:\n                h1 += 1\n        else:\n            if hue_diff > 0.5:\n                h2 += 1\n            elif hue_diff < -0.5:\n                h1 += 1\n        return (modf(fade(h1, h2))[0], fade(s1, s2), fade(v1, v2))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a gradient of size for a list of colors.", "response": "def generate_gradient(self, color_list, size=101):\n        \"\"\"\n        Create a gradient of size colors that passes through the colors\n        give in the list (the resultant list may not be exactly size long).\n        The gradient will be evenly distributed.\n        colors should be in hex format eg '#FF00FF'\n        \"\"\"\n        list_length = len(color_list)\n        gradient_step = size / (list_length - 1)\n\n        gradient_data = []\n        for x in range(list_length):\n            gradient_data.append((int(gradient_step * x), color_list[x]))\n\n        data = []\n        for i in range(len(gradient_data) - 1):\n            start, color1 = gradient_data[i]\n            end, color2 = gradient_data[i + 1]\n\n            color1 = self.hex_2_hsv(color1)\n            color2 = self.hex_2_hsv(color2)\n\n            steps = end - start\n            for j in range(steps):\n                data.append(\n                    self.hsv_2_hex(*self.make_mid_color(color1, color2, j / (steps)))\n                )\n        data.append(self.hsv_2_hex(*color2))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of thresholds creates a gradient list that covers the range of the thresholds.", "response": "def make_threshold_gradient(self, py3, thresholds, size=100):\n\n        \"\"\"\n        Given a thresholds list, creates a gradient list that covers the range\n        of the thresholds.\n        The number of colors in the gradient is limited by size.\n        Because of how the range is split the exact number of colors in the\n        gradient cannot be guaranteed.\n        \"\"\"\n        thresholds = sorted(thresholds)\n        key = \"{}|{}\".format(thresholds, size)\n        try:\n            return self._gradients_cache[key]\n        except KeyError:\n            pass\n        minimum = min(thresholds)[0]\n        maximum = max(thresholds)[0]\n        if maximum - minimum > size:\n            steps_size = size / (maximum - minimum)\n        else:\n            steps_size = 1\n        colors = []\n        for index in range(len(thresholds) - 1):\n            color_list = [thresholds[index][1], thresholds[index + 1][1]]\n            num_colors = int(\n                (thresholds[index + 1][0] - thresholds[index][0]) * steps_size\n            )\n            colors.extend(self.generate_gradient(color_list, num_colors))\n        # cache gradient\n        self._gradients_cache[key] = colors\n        return colors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a line from the file and return it.", "response": "def readline(self, timeout=500):\n        \"\"\"\n        Try to read our I/O for 'timeout' milliseconds, return None otherwise.\n        This makes calling and reading I/O non blocking !\n        \"\"\"\n        poll_result = self.poller.poll(timeout)\n        if poll_result:\n            line = self.io.readline().strip()\n            if self.io == sys.stdin and line == \"[\":\n                # skip first event line wrt issue #19\n                line = self.io.readline().strip()\n            try:\n                # python3 compatibility code\n                line = line.decode()\n            except (AttributeError, UnicodeDecodeError):\n                pass\n            return line\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the full text for the module and the partial text for the event.", "response": "def get_module_text(self, module_name, event):\n        \"\"\"\n        Get the full text for the module as well as the partial text if the\n        module is a composite.  Partial text is the text for just the single\n        section of a composite.\n        \"\"\"\n        index = event.get(\"index\")\n        module_info = self.py3_wrapper.output_modules.get(module_name)\n        output = module_info[\"module\"].get_latest()\n        full_text = u\"\".join([out[\"full_text\"] for out in output])\n\n        partial = None\n        if index is not None:\n            if isinstance(index, int):\n                partial = output[index]\n            else:\n                for item in output:\n                    if item.get(\"index\") == index:\n                        partial = item\n                        break\n        if partial:\n            partial_text = partial[\"full_text\"]\n        else:\n            partial_text = full_text\n        return full_text, partial_text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndispatch on click events to i3wm", "response": "def on_click_dispatcher(self, module_name, event, command):\n        \"\"\"\n        Dispatch on_click config parameters to either:\n            - Our own methods for special py3status commands (listed below)\n            - The i3-msg program which is part of i3wm\n        \"\"\"\n        if command is None:\n            return\n        elif command == \"refresh_all\":\n            self.py3_wrapper.refresh_modules()\n        elif command == \"refresh\":\n            self.py3_wrapper.refresh_modules(module_name)\n        else:\n            # In commands we are able to use substitutions for the text output\n            # of a module\n            if \"$OUTPUT\" in command or \"$OUTPUT_PART\" in command:\n                full_text, partial_text = self.get_module_text(module_name, event)\n                command = command.replace(\"$OUTPUT_PART\", shell_quote(partial_text))\n                command = command.replace(\"$OUTPUT\", shell_quote(full_text))\n\n            # this is a i3 message\n            self.wm_msg(module_name, command)\n            # to make the bar more responsive to users we ask for a refresh\n            # of the module or of i3status if the module is an i3status one\n            self.py3_wrapper.refresh_modules(module_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the message with i3 - msg or swaymsg and log its output.", "response": "def wm_msg(self, module_name, command):\n        \"\"\"\n        Execute the message with i3-msg or swaymsg and log its output.\n        \"\"\"\n        wm_msg = self.config[\"wm\"][\"msg\"]\n        pipe = Popen([wm_msg, command], stdout=PIPE)\n        self.py3_wrapper.log(\n            '{} module=\"{}\" command=\"{}\" stdout={}'.format(\n                wm_msg, module_name, command, pipe.stdout.read()\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the event for the named module.", "response": "def process_event(self, module_name, event, default_event=False):\n        \"\"\"\n        Process the event for the named module.\n        Events may have been declared in i3status.conf, modules may have\n        on_click() functions. There is a default middle click event etc.\n        \"\"\"\n\n        # get the module that the event is for\n        module_info = self.output_modules.get(module_name)\n\n        # if module is a py3status one call it.\n        if module_info[\"type\"] == \"py3status\":\n            module = module_info[\"module\"]\n            module.click_event(event)\n            if self.config[\"debug\"]:\n                self.py3_wrapper.log(\"dispatching event {}\".format(event))\n\n            # to make the bar more responsive to users we refresh the module\n            # unless the on_click event called py3.prevent_refresh()\n            if not module.prevent_refresh:\n                self.py3_wrapper.refresh_modules(module_name)\n                default_event = False\n\n        if default_event:\n            # default button 2 action is to clear this method's cache\n            if self.config[\"debug\"]:\n                self.py3_wrapper.log(\"dispatching default event {}\".format(event))\n            self.py3_wrapper.refresh_modules(module_name)\n\n        # find container that holds the module and call its onclick\n        module_groups = self.py3_config[\".module_groups\"]\n        containers = module_groups.get(module_name, [])\n        for container in containers:\n            self.process_event(container, event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndispatches an event to the i3bar modules.", "response": "def dispatch_event(self, event):\n        \"\"\"\n        Takes an event dict.  Logs the event if needed and cleans up the dict\n        such as setting the index needed for composits.\n        \"\"\"\n        if self.config[\"debug\"]:\n            self.py3_wrapper.log(\"received event {}\".format(event))\n\n        # usage variables\n        event[\"index\"] = event.get(\"index\", \"\")\n        instance = event.get(\"instance\", \"\")\n        name = event.get(\"name\", \"\")\n\n        # composites have an index which is passed to i3bar with\n        # the instance.  We need to separate this out here and\n        # clean up the event.  If index\n        # is an integer type then cast it as such.\n        if \" \" in instance:\n            instance, index = instance.split(\" \", 1)\n            try:\n                index = int(index)\n            except ValueError:\n                pass\n            event[\"index\"] = index\n            event[\"instance\"] = instance\n\n        if self.config[\"debug\"]:\n            self.py3_wrapper.log(\n                'trying to dispatch event to module \"{}\"'.format(\n                    \"{} {}\".format(name, instance).strip()\n                )\n            )\n\n        # guess the module config name\n        module_name = \"{} {}\".format(name, instance).strip()\n\n        default_event = False\n        module_info = self.output_modules.get(module_name)\n        module = module_info[\"module\"]\n        # execute any configured i3-msg command\n        # we do not do this for containers\n        # modules that have failed do not execute their config on_click\n        if module.allow_config_clicks:\n            button = event.get(\"button\", 0)\n            on_click = self.on_click.get(module_name, {}).get(str(button))\n            if on_click:\n                task = EventClickTask(module_name, event, self, on_click)\n                self.py3_wrapper.timeout_queue_add(task)\n            # otherwise setup default action on button 2 press\n            elif button == 2:\n                default_event = True\n\n        # do the work\n        task = EventTask(module_name, event, default_event, self)\n        self.py3_wrapper.timeout_queue_add(task)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait for an i3bar JSON event, then find the right module to dispatch the message to based on the 'name' and 'instance' of the event. In case the module does NOT support click_events, the default implementation is to clear the module's cache when the MIDDLE button (2) is pressed on it. Example event: {'y': 13, 'x': 1737, 'button': 1, 'name': 'empty', 'instance': 'first'}", "response": "def run(self):\n        \"\"\"\n        Wait for an i3bar JSON event, then find the right module to dispatch\n        the message to based on the 'name' and 'instance' of the event.\n\n        In case the module does NOT support click_events, the default\n        implementation is to clear the module's cache\n        when the MIDDLE button (2) is pressed on it.\n\n        Example event:\n        {'y': 13, 'x': 1737, 'button': 1, 'name': 'empty', 'instance': 'first'}\n        \"\"\"\n        try:\n            while self.py3_wrapper.running:\n                event_str = self.poller_inp.readline()\n                if not event_str:\n                    continue\n                try:\n                    # remove leading comma if present\n                    if event_str[0] == \",\":\n                        event_str = event_str[1:]\n                    event = loads(event_str)\n                    self.dispatch_event(event)\n                except Exception:\n                    self.py3_wrapper.report_exception(\"Event failed\")\n        except:  # noqa e722\n            err = \"Events thread died, click events are disabled.\"\n            self.py3_wrapper.report_exception(err, notify_user=False)\n            self.py3_wrapper.notify_user(err, level=\"warning\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _start_handler_thread(self):\n        # Create handler thread\n        t = Thread(target=self._start_loop)\n        t.daemon = True\n\n        # Start handler thread\n        t.start()\n        self.thread_started = True", "response": "Called once to start the event handler thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start_loop(self):\n        # Create our main loop, get our bus, and add the signal handler\n        loop = GObject.MainLoop()\n        bus = SystemBus()\n        manager = bus.get(\".NetworkManager\")\n        manager.onPropertiesChanged = self._vpn_signal_handler\n\n        # Loop forever\n        loop.run()", "response": "Starts main event handler loop run in handler thread t."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _vpn_signal_handler(self, args):\n        # Args is a dictionary of changed properties\n        # We only care about changes in ActiveConnections\n        active = \"ActiveConnections\"\n        # Compare current ActiveConnections to last seen ActiveConnections\n        if active in args.keys() and sorted(self.active) != sorted(args[active]):\n            self.active = args[active]\n            self.py3.update()", "response": "Called on NetworkManager PropertiesChanged signal"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_vpn_status(self):\n        # Sleep for a bit to let any changes in state finish\n        sleep(0.3)\n        # Check if any active connections are a VPN\n        bus = SystemBus()\n        ids = []\n        for name in self.active:\n            conn = bus.get(\".NetworkManager\", name)\n            if conn.Vpn:\n                ids.append(conn.Id)\n        # No active VPN\n        return ids", "response": "Returns None if no VPN active Id if active."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vpn_status(self):\n\n        # Start signal handler thread if it should be running\n        if not self.check_pid and not self.thread_started:\n            self._start_handler_thread()\n\n        # Set color_bad as default output. Replaced if VPN active.\n        name = None\n        color = self.py3.COLOR_BAD\n\n        # If we are acting like the default i3status module\n        if self.check_pid:\n            if self._check_pid():\n                name = \"yes\"\n                color = self.py3.COLOR_GOOD\n\n        # Otherwise, find the VPN name, if it is active\n        else:\n            vpn = self._get_vpn_status()\n            if vpn:\n                name = \", \".join(vpn)\n                color = self.py3.COLOR_GOOD\n\n        # Format and create the response dict\n        full_text = self.py3.safe_format(self.format, {\"name\": name})\n        response = {\n            \"full_text\": full_text,\n            \"color\": color,\n            \"cached_until\": self.py3.CACHE_FOREVER,\n        }\n\n        # Cache forever unless in check_pid mode\n        if self.check_pid:\n            response[\"cached_until\"] = self.py3.time_in(self.cache_timeout)\n        return response", "response": "Returns the i3status module for VPN"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append(self, item):\n        if isinstance(item, Composite):\n            self._content += item.get_content()\n        elif isinstance(item, list):\n            self._content += item\n        elif isinstance(item, dict):\n            self._content.append(item)\n        elif isinstance(item, basestring):\n            self._content.append({\"full_text\": item})\n        else:\n            msg = \"{!r} not suitable to append to Composite\"\n            raise Exception(msg.format(item))", "response": "Add an item to the Composite."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsimplify the content of a Composite by merging any parts that can be and returning the new Composite as well as updating itself internally.", "response": "def simplify(self):\n        \"\"\"\n        Simplify the content of a Composite merging any parts that can be\n        and returning the new Composite as well as updating itself internally\n        \"\"\"\n        final_output = []\n        diff_last = None\n        item_last = None\n        for item in self._content:\n            # remove any undefined colors\n            if hasattr(item.get(\"color\"), \"none_setting\"):\n                del item[\"color\"]\n            # ignore empty items\n            if not item.get(\"full_text\") and not item.get(\"separator\"):\n                continue\n            # merge items if we can\n            diff = item.copy()\n            del diff[\"full_text\"]\n\n            if diff == diff_last or (item[\"full_text\"].strip() == \"\" and item_last):\n                item_last[\"full_text\"] += item[\"full_text\"]\n            else:\n                diff_last = diff\n                item_last = item.copy()  # copy item as we may change it\n                final_output.append(item_last)\n        self._content = final_output\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef composite_join(separator, items):\n        output = Composite()\n        first_item = True\n        for item in items:\n            # skip empty items\n            if not item:\n                continue\n            # skip separator on first item\n            if first_item:\n                first_item = False\n            else:\n                output.append(separator)\n            output.append(item)\n        return output", "response": "Join a list of items with a separator and return a Composite."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a Composite item and updates all entries with values from update_dict.", "response": "def composite_update(item, update_dict, soft=False):\n        \"\"\"\n        Takes a Composite (item) and updates all entries with values from\n        update_dict.  Updates can be soft in which case existing values are not\n        overwritten.\n\n        If item is of type string it is first converted to a Composite\n        \"\"\"\n        item = Composite(item)\n\n        for part in item.get_content():\n            if soft:\n                for key, value in update_dict.items():\n                    if key not in part:\n                        part[key] = value\n            else:\n                part.update(update_dict)\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_dbus(self):\n        _bus = SessionBus()\n\n        if self.device_id is None:\n            self.device_id = self._get_device_id(_bus)\n            if self.device_id is None:\n                return False\n\n        try:\n            self._dev = _bus.get(SERVICE_BUS, DEVICE_PATH + \"/%s\" % self.device_id)\n        except Exception:\n            return False\n\n        return True", "response": "Initialize the DBus object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the device id", "response": "def _get_device_id(self, bus):\n        \"\"\"\n        Find the device id\n        \"\"\"\n        _dbus = bus.get(SERVICE_BUS, PATH)\n        devices = _dbus.devices()\n\n        if self.device is None and self.device_id is None and len(devices) == 1:\n            return devices[0]\n\n        for id in devices:\n            self._dev = bus.get(SERVICE_BUS, DEVICE_PATH + \"/%s\" % id)\n            if self.device == self._dev.name:\n                return id\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the device object", "response": "def _get_device(self):\n        \"\"\"\n        Get the device\n        \"\"\"\n        try:\n            device = {\n                \"name\": self._dev.name,\n                \"isReachable\": self._dev.isReachable,\n                \"isTrusted\": self._get_isTrusted(),\n            }\n        except Exception:\n            return None\n\n        return device"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the battery of the current user", "response": "def _get_battery(self):\n        \"\"\"\n        Get the battery\n        \"\"\"\n        try:\n            battery = {\n                \"charge\": self._dev.charge(),\n                \"isCharging\": self._dev.isCharging() == 1,\n            }\n        except Exception:\n            return None\n\n        return battery"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_battery_status(self, battery):\n        if battery[\"charge\"] == -1:\n            return (UNKNOWN_SYMBOL, UNKNOWN, \"#FFFFFF\")\n\n        if battery[\"isCharging\"]:\n            status = self.status_chr\n            color = self.py3.COLOR_GOOD\n        else:\n            status = self.status_bat\n            color = self.py3.COLOR_DEGRADED\n\n        if not battery[\"isCharging\"] and battery[\"charge\"] <= self.low_threshold:\n            color = self.py3.COLOR_BAD\n\n        if battery[\"charge\"] > 99:\n            status = self.status_full\n\n        return (battery[\"charge\"], status, color)", "response": "Get the battery status"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the status of the notifications", "response": "def _get_notifications_status(self, notifications):\n        \"\"\"\n        Get the notifications status\n        \"\"\"\n        if notifications:\n            size = len(notifications[\"activeNotifications\"])\n        else:\n            size = 0\n        status = self.status_notif if size > 0 else self.status_no_notif\n\n        return (size, status)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_text(self):\n        device = self._get_device()\n        if device is None:\n            return (UNKNOWN_DEVICE, self.py3.COLOR_BAD)\n\n        if not device[\"isReachable\"] or not device[\"isTrusted\"]:\n            return (\n                self.py3.safe_format(\n                    self.format_disconnected, {\"name\": device[\"name\"]}\n                ),\n                self.py3.COLOR_BAD,\n            )\n\n        battery = self._get_battery()\n        (charge, bat_status, color) = self._get_battery_status(battery)\n\n        notif = self._get_notifications()\n        (notif_size, notif_status) = self._get_notifications_status(notif)\n\n        return (\n            self.py3.safe_format(\n                self.format,\n                dict(\n                    name=device[\"name\"],\n                    charge=charge,\n                    bat_status=bat_status,\n                    notif_size=notif_size,\n                    notif_status=notif_status,\n                ),\n            ),\n            color,\n        )", "response": "Get the text of the current metadatas."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kdeconnector(self):\n        if self._init_dbus():\n            (text, color) = self._get_text()\n        else:\n            text = UNKNOWN_DEVICE\n            color = self.py3.COLOR_BAD\n\n        response = {\n            \"cached_until\": self.py3.time_in(self.cache_timeout),\n            \"full_text\": text,\n            \"color\": color,\n        }\n        return response", "response": "Get the current state and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dpms(self):\n        if \"DPMS is Enabled\" in self.py3.command_output(\"xset -q\"):\n            _format = self.icon_on\n            color = self.color_on\n        else:\n            _format = self.icon_off\n            color = self.color_off\n\n        icon = self.py3.safe_format(_format)\n\n        return {\n            \"cached_until\": self.py3.time_in(self.cache_timeout),\n            \"full_text\": self.py3.safe_format(self.format, {\"icon\": icon}),\n            \"color\": color,\n        }", "response": "Display a colorful state of DPMS."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncontrols DPMS with mouse clicks.", "response": "def on_click(self, event):\n        \"\"\"\n        Control DPMS with mouse clicks.\n        \"\"\"\n        if event[\"button\"] == self.button_toggle:\n            if \"DPMS is Enabled\" in self.py3.command_output(\"xset -q\"):\n                self.py3.command_run(\"xset -dpms s off\")\n            else:\n                self.py3.command_run(\"xset +dpms s on\")\n\n        if event[\"button\"] == self.button_off:\n            self.py3.command_run(\"xset dpms force off\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget current progress of emerge.", "response": "def _get_progress(self):\n        \"\"\"\n        Get current progress of emerge.\n        Returns a dict containing current and total value.\n        \"\"\"\n        input_data = []\n        ret = {}\n\n        # traverse emerge.log from bottom up to get latest information\n        last_lines = self.py3.command_output([\"tail\", \"-50\", self.emerge_log_file])\n        input_data = last_lines.split(\"\\n\")\n        input_data.reverse()\n\n        for line in input_data:\n            if \"*** terminating.\" in line:\n                # copy content of ret_default, not only the references\n                ret = copy.deepcopy(self.ret_default)\n                break\n            else:\n                status_re = re.compile(\n                    \"\\((?P<cu>[\\d]+) of (?P<t>[\\d]+)\\) \"\n                    \"(?P<a>[a-zA-Z\\/]+( [a-zA-Z]+)?) \"\n                    \"\\((?P<ca>[\\w\\-]+)\\/(?P<p>[\\w\\.]+)\"\n                )\n                res = status_re.search(line)\n                if res is not None:\n                    ret[\"action\"] = res.group(\"a\").lower()\n                    ret[\"category\"] = res.group(\"ca\")\n                    ret[\"current\"] = res.group(\"cu\")\n                    ret[\"pkg\"] = res.group(\"p\")\n                    ret[\"total\"] = res.group(\"t\")\n                    break\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _idle(self):\n        socket = None\n\n        try:\n            # build a new command tag (Xnnn) as bytes:\n            self.command_tag = (self.command_tag + 1) % 1000\n            command_tag = b\"X\" + bytes(str(self.command_tag).zfill(3), \"ascii\")\n\n            # make sure we have selected anything before idling:\n            directories = self.mailbox.split(\",\")\n            self.connection.select(directories[0])\n\n            socket = self.connection.socket()\n\n            # send IDLE command and check response:\n            socket.write(command_tag + b\" IDLE\\r\\n\")\n            try:\n                response = socket.read(4096).decode(\"ascii\")\n            except socket_error:\n                raise imaplib.IMAP4.abort(\"Server didn't respond to 'IDLE' in time\")\n            if not response.lower().startswith(\"+ idling\"):\n                raise imaplib.IMAP4.abort(\"While initializing IDLE: \" + str(response))\n\n            # wait for changes (EXISTS, EXPUNGE, etc.):\n            socket.settimeout(self.cache_timeout)\n            while True:\n                try:\n                    response = socket.read(4096).decode(\"ascii\")\n                    if response.upper().startswith(\"* OK\"):\n                        continue  # ignore '* OK Still here'\n                    else:\n                        break\n                except socket_error:  # IDLE timed out\n                    break\n\n        finally:  # terminate IDLE command gracefully\n            if socket is None:\n                return\n\n            socket.settimeout(self.read_timeout)\n            socket.write(b\"DONE\\r\\n\")  # important! Can't query IMAP again otherwise\n            try:\n                response = socket.read(4096).decode(\"ascii\")\n            except socket_error:\n                raise imaplib.IMAP4.abort(\"Server didn't respond to 'DONE' in time\")\n\n            # sometimes, more messages come in between reading and DONEing; so read them again:\n            if response.startswith(\"* \"):\n                try:\n                    response = socket.read(4096).decode(\"ascii\")\n                except socket_error:\n                    raise imaplib.IMAP4.abort(\n                        \"Server sent more continuations, but no 'DONE' ack\"\n                    )\n\n            expected_response = (command_tag + b\" OK\").decode(\"ascii\")\n            if not response.lower().startswith(expected_response.lower()):\n                raise imaplib.IMAP4.abort(\"While terminating IDLE: \" + response)", "response": "This method is used to send an IDLE command to the IMAP server and wait for changes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the memory size total_mem Used_mem percentage used_mem and total_unit of used memory and units of mem.", "response": "def _calc_mem_info(self, unit, meminfo, memory):\n        \"\"\"\n        Parse /proc/meminfo, grab the memory capacity and used size\n        then return; Memory size 'total_mem', Used_mem, percentage\n        of used memory, and units of mem (KiB, MiB, GiB).\n        \"\"\"\n        if memory:\n            total_mem_kib = meminfo[\"MemTotal:\"]\n            used_mem_kib = (\n                total_mem_kib\n                - meminfo[\"MemFree:\"]\n                - (\n                    meminfo[\"Buffers:\"]\n                    + meminfo[\"Cached:\"]\n                    + (meminfo[\"SReclaimable:\"] - meminfo[\"Shmem:\"])\n                )\n            )\n        else:\n            total_mem_kib = meminfo[\"SwapTotal:\"]\n            used_mem_kib = total_mem_kib - meminfo[\"SwapFree:\"]\n\n        used_percent = 100 * used_mem_kib / total_mem_kib\n\n        unit = \"B\" if unit == \"dynamic\" else unit\n        (total, total_unit) = self.py3.format_units(total_mem_kib * 1024, unit)\n        (used, used_unit) = self.py3.format_units(used_mem_kib * 1024, unit)\n        return total, total_unit, used, used_unit, used_percent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_cputemp_with_lmsensors(self, zone=None):\n\n        sensors = None\n        command = [\"sensors\"]\n        if zone:\n            try:\n                sensors = self.py3.command_output(command + [zone])\n            except self.py3.CommandError:\n                pass\n        if not sensors:\n            sensors = self.py3.command_output(command)\n        m = re.search(\"(Core 0|CPU Temp).+\\+(.+).+\\(.+\", sensors)\n        if m:\n            cpu_temp = float(m.groups()[1].strip()[:-2])\n        else:\n            cpu_temp = \"?\"\n\n        return cpu_temp", "response": "Tries to determine the CPU temperature using the sensors command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the tokenized format_string.", "response": "def tokens(self, format_string):\n        \"\"\"\n        Get the tokenized format_string.\n        Tokenizing is resource intensive so we only do it once and cache it\n        \"\"\"\n        if format_string not in self.format_string_cache:\n            if python2 and isinstance(format_string, str):\n                format_string = format_string.decode(\"utf-8\")\n            tokens = list(re.finditer(self.reg_ex, format_string))\n            self.format_string_cache[format_string] = tokens\n        return self.format_string_cache[format_string]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the format_string and returns a set of color names.", "response": "def get_color_names(self, format_string):\n        \"\"\"\n        Parses the format_string and returns a set of color names.\n        \"\"\"\n        names = set()\n        # Tokenize the format string and process them\n        for token in self.tokens(format_string):\n            if token.group(\"command\"):\n                name = dict(parse_qsl(token.group(\"command\"))).get(\"color\")\n                if (\n                    not name\n                    or name in COLOR_NAMES_EXCLUDED\n                    or name in COLOR_NAMES\n                    or name[0] == \"#\"\n                ):\n                    continue\n                names.add(name)\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_placeholders(self, format_string):\n        placeholders = set()\n        # Tokenize the format string and process them\n        for token in self.tokens(format_string):\n            if token.group(\"placeholder\"):\n                placeholders.add(token.group(\"key\"))\n            elif token.group(\"command\"):\n                # get any placeholders used in commands\n                commands = dict(parse_qsl(token.group(\"command\")))\n                # placeholders only used in `if`\n                if_ = commands.get(\"if\")\n                if if_:\n                    placeholders.add(Condition(if_).variable)\n        return placeholders", "response": "Parses the format_string and returns a set of placeholders."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_placeholder_formats_list(self, format_string):\n        placeholders = []\n        # Tokenize the format string and process them\n        for token in self.tokens(format_string):\n            if token.group(\"placeholder\"):\n                placeholders.append((token.group(\"key\"), token.group(\"format\")))\n        return placeholders", "response": "Parses the format_string and returns a list of tuples containing the key and format of the placeholders."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_placeholders(self, format_string, placeholders):\n        # Tokenize the format string and process them\n        output = []\n        for token in self.tokens(format_string):\n            if token.group(\"key\") in placeholders:\n                output.append(\n                    \"{%s%s}\" % (placeholders[token.group(\"key\")], token.group(\"format\"))\n                )\n                continue\n            elif token.group(\"command\"):\n                # update any placeholders used in commands\n                commands = parse_qsl(token.group(\"command\"), keep_blank_values=True)\n                # placeholders only used in `if`\n                if \"if\" in [x[0] for x in commands]:\n                    items = []\n                    for key, value in commands:\n                        if key == \"if\":\n                            # we have to rebuild from the parts we have\n                            condition = Condition(value)\n                            variable = condition.variable\n                            if variable in placeholders:\n                                variable = placeholders[variable]\n                                # negation via `!`\n                                not_ = \"!\" if not condition.default else \"\"\n                                condition_ = condition.condition or \"\"\n                                # if there is no condition then there is no\n                                # value\n                                if condition_:\n                                    value_ = condition.value\n                                else:\n                                    value_ = \"\"\n                                value = \"{}{}{}{}\".format(\n                                    not_, variable, condition_, value_\n                                )\n                        if value:\n                            items.append(\"{}={}\".format(key, value))\n                        else:\n                            items.append(key)\n\n                    # we cannot use urlencode because it will escape things\n                    # like `!`\n                    output.append(r\"\\?{} \".format(\"&\".join(items)))\n                    continue\n            value = token.group(0)\n            output.append(value)\n        return u\"\".join(output)", "response": "Update the format string with the placeholders."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_placeholder_formats(self, format_string, placeholder_formats):\n        # Tokenize the format string and process them\n        output = []\n        for token in self.tokens(format_string):\n            if (\n                token.group(\"placeholder\")\n                and (not token.group(\"format\"))\n                and token.group(\"key\") in placeholder_formats\n            ):\n                output.append(\n                    \"{%s%s}\"\n                    % (token.group(\"key\"), placeholder_formats[token.group(\"key\")])\n                )\n                continue\n            value = token.group(0)\n            output.append(value)\n        return u\"\".join(output)", "response": "Update a format string adding formats if they are not already present."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_block(self, format_string):\n        first_block = Block(None, py3_wrapper=self.py3_wrapper)\n        block = first_block\n\n        # Tokenize the format string and process them\n        for token in self.tokens(format_string):\n            value = token.group(0)\n            if token.group(\"block_start\"):\n                # Create new block\n                block = block.new_block()\n            elif token.group(\"block_end\"):\n                # Close block setting any valid state as needed\n                # and return to parent block to continue\n                if not block.parent:\n                    raise Exception(\"Too many `]`\")\n                block = block.parent\n            elif token.group(\"switch\"):\n                # a new option has been created\n                block = block.switch()\n            elif token.group(\"placeholder\"):\n                # Found a {placeholder}\n                key = token.group(\"key\")\n                format = token.group(\"format\")\n                block.add(Placeholder(key, format))\n            elif token.group(\"literal\"):\n                block.add(Literal(value))\n            elif token.group(\"lost_brace\"):\n                # due to how parsing happens we can get a lonesome }\n                # eg in format_string '{{something}' this fixes that issue\n                block.add(Literal(value))\n            elif token.group(\"command\"):\n                # a block command has been found\n                block.set_commands(token.group(\"command\"))\n            elif token.group(\"escaped\"):\n                # escaped characters add unescaped values\n                if value[0] in [\"\\\\\", \"{\", \"}\"]:\n                    value = value[1:]\n                block.add(Literal(value))\n\n        if block.parent:\n            raise Exception(\"Block not closed\")\n        # add to the cache\n        self.block_cache[format_string] = first_block", "response": "Parses the format string and returns a block containing the format string and the cache of the cache entries."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat a string in the cache.", "response": "def format(\n        self,\n        format_string,\n        module=None,\n        param_dict=None,\n        force_composite=False,\n        attr_getter=None,\n    ):\n        \"\"\"\n        Format a string, substituting place holders which can be found in\n        param_dict, attributes of the supplied module, or provided via calls to\n        the attr_getter function.\n        \"\"\"\n        # fix python 2 unicode issues\n        if python2 and isinstance(format_string, str):\n            format_string = format_string.decode(\"utf-8\")\n\n        if param_dict is None:\n            param_dict = {}\n\n        # if the processed format string is not in the cache then create it.\n        if format_string not in self.block_cache:\n            self.build_block(format_string)\n\n        first_block = self.block_cache[format_string]\n\n        def get_parameter(key):\n            \"\"\"\n            function that finds and returns the value for a placeholder.\n            \"\"\"\n            if key in param_dict:\n                # was a supplied parameter\n                param = param_dict.get(key)\n            elif module and hasattr(module, key):\n                param = getattr(module, key)\n                if hasattr(param, \"__call__\"):\n                    # we don't allow module methods\n                    raise Exception()\n            elif attr_getter:\n                # get value from attr_getter function\n                try:\n                    param = attr_getter(key)\n                except:  # noqa e722\n                    raise Exception()\n            else:\n                raise Exception()\n            if isinstance(param, Composite):\n                if param.text():\n                    param = param.copy()\n                else:\n                    param = u\"\"\n            elif python2 and isinstance(param, str):\n                param = param.decode(\"utf-8\")\n            return param\n\n        # render our processed format\n        valid, output = first_block.render(get_parameter, module)\n\n        # clean things up a little\n        if isinstance(output, list):\n            output = Composite(output)\n        if not output:\n            if force_composite:\n                output = Composite()\n            else:\n                output = \"\"\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the correct value for the key in the parameter set", "response": "def get(self, get_params, block):\n        \"\"\"\n        return the correct value for the placeholder\n        \"\"\"\n        value = \"{%s}\" % self.key\n        try:\n            value = value_ = get_params(self.key)\n            if self.format.startswith(\":\"):\n                # if a parameter has been set to be formatted as a numeric\n                # type then we see if we can coerce it to be.  This allows\n                # the user to format types that normally would not be\n                # allowed eg '123' it also allows {:d} to be used as a\n                # shorthand for {:.0f}.  Use {:g} to remove insignificant\n                # trailing zeroes and the decimal point too if there are\n                # no remaining digits following it.  If the parameter cannot\n                # be successfully converted then the format will be removed.\n                try:\n                    if \"ceil\" in self.format:\n                        value = int(ceil(float(value)))\n                    if \"f\" in self.format:\n                        value = float(value)\n                    if \"g\" in self.format:\n                        value = float(value)\n                    if \"d\" in self.format:\n                        value = int(float(value))\n                    output = u\"{[%s]%s}\" % (self.key, self.format)\n                    value = output.format({self.key: value})\n                    value_ = float(value)\n                except ValueError:\n                    pass\n            elif self.format.startswith(\"!\"):\n                output = u\"{%s%s}\" % (self.key, self.format)\n                value = value_ = output.format(**{self.key: value})\n\n            if block.commands.not_zero:\n                valid = value_ not in [\"\", None, False, \"0\", \"0.0\", 0, 0.0]\n            else:\n                # '', None, and False are ignored\n                # numbers like 0 and 0.0 are not.\n                valid = not (value_ in [\"\", None] or value_ is False)\n            enough = False\n        except:  # noqa e722\n            # Exception raised when we don't have the param\n            enough = True\n            valid = False\n\n        return valid, value, enough"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the condition has been met.", "response": "def _check_valid_condition(self, get_params):\n        \"\"\"\n        Check if the condition has been met.\n        We need to make sure that we are of the correct type.\n        \"\"\"\n        try:\n            variable = get_params(self.variable)\n        except:  # noqa e722\n            variable = None\n        value = self.value\n\n        # if None, return oppositely\n        if variable is None:\n            return not self.default\n\n        # convert the value to a correct type\n        if isinstance(variable, bool):\n            value = bool(self.value)\n        elif isinstance(variable, Number):\n            try:\n                value = int(self.value)\n            except:  # noqa e722\n                try:\n                    value = float(self.value)\n                except:  # noqa e722\n                    # could not parse\n                    return not self.default\n\n        # compare and return the result\n        if self.condition == \"=\":\n            return (variable == value) == self.default\n        elif self.condition == \">\":\n            return (variable > value) == self.default\n        elif self.condition == \"<\":\n            return (variable < value) == self.default"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_valid_basic(self, get_params):\n        try:\n            if get_params(self.variable):\n                return self.default\n        except:  # noqa e722\n            pass\n        return not self.default", "response": "Simple check that the variable is set\n        and that the value is not None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_commands(self, commands_str):\n        commands = dict(parse_qsl(commands_str, keep_blank_values=True))\n        _if = commands.get(\"if\", self._if)\n        if _if:\n            self._if = Condition(_if)\n        self._set_int(commands, \"max_length\")\n        self._set_int(commands, \"min_length\")\n        self.color = self._check_color(commands.get(\"color\"))\n\n        self.not_zero = \"not_zero\" in commands or self.not_zero\n        self.show = \"show\" in commands or self.show\n        self.soft = \"soft\" in commands or self.soft", "response": "Update the internal state of the internal state with the commands from the block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_int(self, commands, name):\n        if name in commands:\n            try:\n                value = int(commands[name])\n                setattr(self, name, value)\n            except ValueError:\n                pass", "response": "set integer value from commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new sub block and return it", "response": "def new_block(self):\n        \"\"\"\n        create a new sub block to the current block and return it.\n        the sub block is added to the current block.\n        \"\"\"\n        child = Block(self, py3_wrapper=self.py3_wrapper)\n        self.add(child)\n        return child"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef switch(self):\n        base_block = self.base_block or self\n        self.next_block = Block(\n            self.parent, base_block=base_block, py3_wrapper=self.py3_wrapper\n        )\n        return self.next_block", "response": "Switches the current block to the next entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_valid(self, get_params):\n        if self.commands._if:\n            return self.commands._if.check_valid(get_params)", "response": "check if the if condition for a specific entry is valid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the block and return the output.", "response": "def render(self, get_params, module, _if=None):\n        \"\"\"\n        render the block and return the output.\n        \"\"\"\n        enough = False\n        output = []\n        valid = None\n\n        if self.commands.show:\n            valid = True\n        if self.parent and self.commands.soft and _if is None:\n            return None, self\n        if _if:\n            valid = True\n        elif self.commands._if:\n            valid = self.check_valid(get_params)\n        if valid is not False:\n            for item in self.content:\n                if isinstance(item, Placeholder):\n                    sub_valid, sub_output, enough = item.get(get_params, self)\n                    output.append(sub_output)\n                elif isinstance(item, Literal):\n                    sub_valid = None\n                    enough = True\n                    output.append(item.text)\n                elif isinstance(item, Block):\n                    sub_valid, sub_output = item.render(get_params, module)\n                    if sub_valid is None:\n                        output.append(sub_output)\n                    else:\n                        output.extend(sub_output)\n                valid = valid or sub_valid\n        if not valid:\n            if self.next_block:\n                valid, output = self.next_block.render(\n                    get_params, module, _if=self.commands._if\n                )\n            elif self.parent is None and (\n                (not self.next_block and enough) or self.base_block\n            ):\n                valid = True\n            else:\n                output = []\n\n        # clean\n        color = self.commands.color\n        if color and color[0] != \"#\":\n            color_name = \"color_%s\" % color\n            threshold_color_name = \"color_threshold_%s\" % color\n            # substitute color\n            color = (\n                getattr(module, color_name, None)\n                or getattr(module, threshold_color_name, None)\n                or getattr(module.py3, color_name.upper(), None)\n            )\n            if color == \"hidden\":\n                return False, []\n\n        text = u\"\"\n        out = []\n        if isinstance(output, str):\n            output = [output]\n\n        # merge as much output as we can.\n        # we need to convert values to unicode for concatination.\n        if python2:\n            conversion = unicode  # noqa\n            convertables = (str, bool, int, float, unicode)  # noqa\n        else:\n            conversion = str\n            convertables = (str, bool, int, float, bytes)\n\n        first = True\n        last_block = None\n        for index, item in enumerate(output):\n            is_block = isinstance(item, Block)\n            if not is_block and item:\n                last_block = None\n            if isinstance(item, convertables) or item is None:\n                text += conversion(item)\n                continue\n            elif text:\n                if not first and (text == \"\" or out and out[-1].get(\"color\") == color):\n                    out[-1][\"full_text\"] += text\n                else:\n                    part = {\"full_text\": text}\n                    if color:\n                        part[\"color\"] = color\n                    out.append(part)\n                text = u\"\"\n            if isinstance(item, Composite):\n                if color:\n                    item.composite_update(item, {\"color\": color}, soft=True)\n                out.extend(item.get_content())\n            elif is_block:\n                # if this is a block then likely it is soft.\n                if not out:\n                    continue\n                for x in range(index + 1, len(output)):\n                    if output[x] and not isinstance(output[x], Block):\n                        valid, _output = item.render(get_params, module, _if=True)\n                        if _output and _output != last_block:\n                            last_block = _output\n                            out.extend(_output)\n                        break\n            else:\n                if item:\n                    out.append(item)\n            first = False\n\n        # add any left over text\n        if text:\n            part = {\"full_text\": text}\n            if color:\n                part[\"color\"] = color\n            out.append(part)\n\n        # process any min/max length commands\n        max_length = self.commands.max_length\n        min_length = self.commands.min_length\n\n        if max_length or min_length:\n            for item in out:\n                if max_length is not None:\n                    item[\"full_text\"] = item[\"full_text\"][:max_length]\n                    max_length -= len(item[\"full_text\"])\n                if min_length:\n                    min_length -= len(item[\"full_text\"])\n            if min_length > 0:\n                out[0][\"full_text\"] = u\" \" * min_length + out[0][\"full_text\"]\n                min_length = 0\n\n        return valid, out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _urgent_function(self, module_list):\n        for module in module_list:\n            if module in self.items:\n                self.active = self.items.index(module)\n                self.urgent = True", "response": "This function is called when the user is about to display the urgent status of the items."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswitch the displayed module or pass the event on to the active module", "response": "def on_click(self, event):\n        \"\"\"\n        Switch the displayed module or pass the event on to the active module\n        \"\"\"\n        button = event[\"button\"]\n        index = event[\"index\"]\n\n        # if click_mode is button, prevent the contents from changing when\n        # if the events are not registered on the button index. this allow\n        # the users to interact with the modules via scrolling or clicking\n        # without group getting in the way of the contents.\n        if self.click_mode == \"button\":\n            if not self.py3.is_my_event(event) or index != \"button\":\n                return\n\n        self.cycle = self.cycle_timeout\n        self.cycle_time = time() + self.cycle\n\n        if button == self.button_next:\n            if self.open:\n                self._change_active(+1)\n        elif button == self.button_prev:\n            if self.open:\n                self._change_active(-1)\n        elif button == self.button_toggle:\n            if index == \"button\":\n                self.open = not self.open"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the backend info so that we can find the correct one.", "response": "def get_backends():\n    \"\"\"\n    Get backends info so that we can find the correct one.\n    We just look in the directory structure to find modules.\n    \"\"\"\n    IGNORE_DIRS = [\"core\", \"tools\", \"utils\"]\n\n    global backends\n    if backends is None:\n        backends = {}\n        i3pystatus_dir = os.path.dirname(i3pystatus.__file__)\n        subdirs = [\n            x\n            for x in next(os.walk(i3pystatus_dir))[1]\n            if not x.startswith(\"_\") and x not in IGNORE_DIRS\n        ]\n        for subdir in subdirs:\n            dirs = next(os.walk(os.path.join(i3pystatus_dir, subdir)))[2]\n            backends.update(\n                {\n                    x[:-3]: \"i3pystatus.%s.%s\" % (subdir, x[:-3])\n                    for x in dirs\n                    if not x.startswith(\"_\") and x.endswith(\".py\")\n                }\n            )\n    return backends"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trigger(self):\n        if self.last_button:\n            button_index = min(self.last_button, len(self.callbacks)) - 1\n            click_style = 0 if self.clicks == 1 else 1\n            callback = self.callbacks[button_index][click_style]\n            if callback:\n                # we can do test for str as only python > 3 is supported\n                if isinstance(callback, str):\n                    # no parameters\n                    callback_name = callback\n                    callback_args = []\n                else:\n                    # has parameters\n                    callback_name = callback[0]\n                    callback_args = callback[1:]\n                callback_function = getattr(self.parent.module, callback_name)\n                callback_function(*callback_args)\n                # We want to ensure that the module has the latest output.  The\n                # best way is to call the run method of the module\n                self.parent.module.run()\n            else:\n                self.parent.py3.prevent_refresh()\n        self.last_button = None\n        self.clicks = 0", "response": "Trigger the event in the event store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef event(self, button):\n        # cancel any pending timer\n        if self.timer:\n            self.timer.cancel()\n        if self.last_button != button:\n            if self.last_button:\n                # new button clicked process the one before.\n                self.trigger()\n            self.clicks = 1\n        else:\n            self.clicks += 1\n        # do we accept double clicks on this button?\n        # if not then just process the click\n        button_index = min(button, len(self.callbacks)) - 1\n        if not self.callbacks[button_index][1]:\n            # set things up correctly for the trigger\n            self.clicks = 1\n            self.last_button = button\n            self.trigger()\n        else:\n            # set a timeout to trigger the click\n            # this will be cancelled if we click again before it runs\n            self.last_button = button\n            self.timer = Timer(self.click_time, self.trigger)\n            self.timer.start()", "response": "Called when a button is clicked."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_price(self, data, market, field):\n        for m in data:\n            if m[\"symbol\"] == market:\n                return m[field]", "response": "Given the data returns the price field for a given market"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting statistics from devfile in list of lists of words", "response": "def _get_stat(self):\n        \"\"\"\n        Get statistics from devfile in list of lists of words\n        \"\"\"\n\n        def dev_filter(x):\n            # get first word and remove trailing interface number\n            x = x.strip().split(\" \")[0][:-1]\n\n            if x in self.interfaces_blacklist:\n                return False\n\n            if self.all_interfaces:\n                return True\n\n            if x in self.interfaces:\n                return True\n\n            return False\n\n        # read devfile, skip two header files\n        x = filter(dev_filter, open(self.devfile).readlines()[2:])\n\n        try:\n            # split info into words, filter empty ones\n            return [list(filter(lambda x: x, _x.split(\" \"))) for _x in x]\n\n        except StopIteration:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the value for the log entry", "response": "def _format_value(self, value):\n        \"\"\"\n        Return formatted string\n        \"\"\"\n        value, unit = self.py3.format_units(value, unit=self.unit, si=self.si_units)\n        return self.py3.safe_format(self.format_value, {\"value\": value, \"unit\": unit})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the command inside a thread and store the output of each line in self. persistent_output.", "response": "def _persist(self):\n        \"\"\"\n        Run the command inside a thread so that we can catch output for each\n        line as it comes in and display it.\n        \"\"\"\n        # run the block/command\n        for command in self.commands:\n            try:\n                process = Popen(\n                    [command],\n                    stdout=PIPE,\n                    stderr=PIPE,\n                    universal_newlines=True,\n                    env=self.env,\n                    shell=True,\n                )\n            except Exception as e:\n                retcode = process.poll()\n                msg = \"Command '{cmd}' {error} retcode {retcode}\"\n                self.py3.log(msg.format(cmd=command, error=e, retcode=retcode))\n\n            # persistent blocklet output can be of two forms.  Either each row\n            # of the output is on a new line this is much easier to deal with)\n            # or else the output can be continuous and just flushed when ready.\n            # The second form is more tricky, if we find newlines then we\n            # switch to easy parsing of the output.\n\n            # When we have output we store in self.persistent_output and then\n            # trigger the module to update.\n\n            fd = process.stdout.fileno()\n            fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n            has_newlines = False\n            while True:\n                line = process.stdout.read(1)\n                # switch to a non-blocking read as we do not know the output\n                # length\n                fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n                line += process.stdout.read(1024)\n                # switch back to blocking so we can wait for the next output\n                fcntl.fcntl(fd, fcntl.F_SETFL, fl)\n                if process.poll():\n                    break\n                if self.py3.is_python_2():\n                    line = line.decode(\"utf-8\")\n                self.persistent_output = line\n                self.py3.update()\n                if line[-1] == \"\\n\":\n                    has_newlines = True\n                    break\n                if line == \"\":\n                    break\n            if has_newlines:\n                msg = \"Switch to newline persist method {cmd}\"\n                self.py3.log(msg.format(cmd=command))\n                # just read the output in a sane manner\n                for line in iter(process.stdout.readline, b\"\"):\n                    if process.poll():\n                        break\n                    if self.py3.is_python_2():\n                        line = line.decode(\"utf-8\")\n                    self.persistent_output = line\n                    self.py3.update()\n        self.py3.log(\"command exited {cmd}\".format(cmd=command))\n        self.persistent_output = \"Error\\nError\\n{}\".format(\n            self.py3.COLOR_ERROR or self.py3.COLOR_BAD\n        )\n        self.py3.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the command and return output and urgency.", "response": "def _run_command(self, env):\n        \"\"\"\n        Run command(s) and return output and urgency.\n        \"\"\"\n        output = \"\"\n        urgent = False\n        # run the block/command\n        for command in self.commands:\n            try:\n                process = Popen(\n                    command,\n                    stdout=PIPE,\n                    stderr=PIPE,\n                    universal_newlines=True,\n                    env=env,\n                    shell=True,\n                )\n            except Exception as e:\n                msg = \"Command '{cmd}' {error}\"\n                raise Exception(msg.format(cmd=command, error=e))\n\n            _output, _error = process.communicate()\n            if self.py3.is_python_2():\n                _output = _output.decode(\"utf-8\")\n                _error = _error.decode(\"utf-8\")\n            retcode = process.poll()\n\n            # return code of 33 means urgent\n            _urgent = retcode == 33\n\n            if retcode and retcode != 33 or _error:\n                msg = \"i3block command '{cmd}' had an error see log for details.\"\n                msg = msg.format(cmd=command)\n                self.py3.notify_user(msg, rate_limit=None)\n                msg = \"i3block command '{cmd}' had error {error} returned {retcode}\"\n                msg = msg.format(cmd=command, error=_error, retcode=retcode)\n                if hash(msg) not in self.errors:\n                    self.py3.log(msg, level=self.py3.LOG_ERROR)\n                    self.errors.append(hash(msg))\n                _output = \"Error\\nError\\n{}\".format(\n                    self.py3.COLOR_ERROR or self.py3.COLOR_BAD\n                )\n            # we have got output so update the received output\n            # this provides support for i3blocks pseudo click support\n            if _output:\n                output = _output\n                urgent = _urgent\n        return output, urgent"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts markdown to restructured text", "response": "def markdown_2_rst(lines):\n    \"\"\"\n    Convert markdown to restructured text\n    \"\"\"\n    out = []\n    code = False\n    for line in lines:\n        # code blocks\n        if line.strip() == \"```\":\n            code = not code\n            space = \" \" * (len(line.rstrip()) - 3)\n            if code:\n                out.append(\"\\n\\n%s.. code-block:: none\\n\\n\" % space)\n            else:\n                out.append(\"\\n\")\n        else:\n            if code and line.strip():\n                line = \"    \" + line\n            else:\n                # escape any backslashes\n                line = line.replace(\"\\\\\", \"\\\\\\\\\")\n            out.append(line)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsort a list of files in a nice way.", "response": "def file_sort(my_list):\n    \"\"\"\n    Sort a list of files in a nice way.\n    eg item-10 will be after item-9\n    \"\"\"\n\n    def alphanum_key(key):\n        \"\"\"\n        Split the key into str/int parts\n        \"\"\"\n        return [int(s) if s.isdigit() else s for s in re.split(\"([0-9]+)\", key)]\n\n    my_list.sort(key=alphanum_key)\n    return my_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef screenshots(screenshots_data, module_name):\n    shots = screenshots_data.get(module_name)\n    if not shots:\n        return \"\"\n\n    out = []\n    for shot in file_sort(shots):\n        if not os.path.exists(\"../doc/screenshots/%s.png\" % shot):\n            continue\n        out.append(u\"\\n.. image:: screenshots/{}.png\\n\\n\".format(shot))\n    return u\"\".join(out)", "response": "Create. rst output for any screenshots a module may have."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates documentation for modules.", "response": "def create_module_docs():\n    \"\"\"\n    Create documentation for modules.\n    \"\"\"\n    data = core_module_docstrings(format=\"rst\")\n    # get screenshot data\n    screenshots_data = {}\n    samples = get_samples()\n    for sample in samples.keys():\n        module = sample.split(\"-\")[0]\n        if module not in screenshots_data:\n            screenshots_data[module] = []\n        screenshots_data[module].append(sample)\n\n    out = []\n    # details\n    for module in sorted(data.keys()):\n        out.append(\"\\n.. _module_%s:\\n\" % module)  # reference for linking\n        out.append(\n            \"\\n{name}\\n{underline}\\n\\n{screenshots}{details}\\n\".format(\n                name=module,\n                screenshots=screenshots(screenshots_data, module),\n                underline=\"-\" * len(module),\n                details=\"\".join(markdown_2_rst(data[module])).strip(),\n            )\n        )\n    # write include file\n    with open(\"../doc/modules-info.inc\", \"w\") as f:\n        f.write(\"\".join(out))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_variable_docstrings(filename):\n\n    def walk_node(parent, values=None, prefix=\"\"):\n        \"\"\"\n        walk the ast searching for docstrings/values\n        \"\"\"\n        docstrings = {}\n        if values is None:\n            values = {}\n        key = None\n        for node in ast.iter_child_nodes(parent):\n            if isinstance(node, ast.ClassDef):\n                # We are in a class so walk the class\n                docs = walk_node(node, values, prefix + node.name + \".\")[0]\n                docstrings[node.name] = docs\n            elif isinstance(node, ast.Assign):\n                key = node.targets[0].id\n                if isinstance(node.value, ast.Num):\n                    values[key] = node.value.n\n                if isinstance(node.value, ast.Str):\n                    values[key] = node.value.s\n                if isinstance(node.value, ast.Name):\n                    if node.value.id in values:\n                        values[prefix + key] = values[node.value.id]\n            elif isinstance(node, ast.Expr) and key:\n                docstrings[key] = node.value.s\n            else:\n                key = None\n        return docstrings, values\n\n    with open(filename, \"r\") as f:\n        source = f.read()\n    return walk_node(ast.parse(source))", "response": "Get all documented variables from a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_py3_docs():\n    # we want the correct .rst 'type' for our data\n    trans = {\"methods\": \"function\", \"exceptions\": \"exception\", \"constants\": \"attribute\"}\n    data = get_py3_info()\n    for k, v in data.items():\n        output = []\n        for name, desc in v:\n            output.append(\"\")\n            output.append(\".. _%s:\" % name)  # reference for linking\n            output.append(\"\")\n            output.append(\".. py:%s:: %s\" % (trans[k], name))\n            output.append(\"\")\n            output.extend(auto_undent(desc))\n        with open(\"../doc/py3-%s-info.inc\" % k, \"w\") as f:\n            f.write(\"\\n\".join(output))", "response": "Create the include files for py3 documentation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the timer expires.", "response": "def _time_up(self):\n        \"\"\"\n        Called when the timer expires\n        \"\"\"\n        self.running = False\n        self.color = self.py3.COLOR_BAD\n        self.time_left = 0\n        self.done = True\n        if self.sound:\n            self.py3.play_sound(self.sound)\n            self.alarm = True\n        self.timer()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the http status code for the response", "response": "def status_code(self):\n        \"\"\"\n        Get the http status code for the response\n        \"\"\"\n        try:\n            return self._status_code\n        except AttributeError:\n            self._status_code = self._response.getcode()\n        return self._status_code"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef text(self):\n        try:\n            return self._text\n        except AttributeError:\n            if IS_PYTHON_3:\n                encoding = self._response.headers.get_content_charset(\"utf-8\")\n            else:\n                encoding = self._response.headers.getparam(\"charset\")\n            self._text = self._response.read().decode(encoding or \"utf-8\")\n        return self._text", "response": "Get the raw text for the response\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json(self):\n        try:\n            return self._json\n        except AttributeError:\n            try:\n                self._json = json.loads(self.text)\n                return self._json\n            except:  # noqa e722\n                raise RequestInvalidJSON(\"Invalid JSON received\")", "response": "Return the json for the current request"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the headers from the response.", "response": "def headers(self):\n        \"\"\"\n        Get the headers from the response.\n        \"\"\"\n        try:\n            return self._headers\n        except AttributeError:\n            self._headers = self._response.headers\n            return self._headers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef modules_directory():\n    return os.path.join(os.path.dirname(os.path.abspath(__file__)), \"modules\")", "response": "Get the core modules directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_readme():\n    name = None\n    re_mod = re.compile(r'^\\#\\#\\# <a name=\"(?P<name>[a-z_0-9]+)\"></a>')\n    readme_file = os.path.join(modules_directory(), \"README.md\")\n    modules_dict = {}\n    with open(readme_file) as f:\n        for row in f.readlines():\n            match = re_mod.match(row)\n            if match:\n                name = match.group(\"name\")\n                modules_dict[name] = []\n                continue\n            if row.startswith(\"---\"):\n                name = None\n                continue\n            if name:\n                modules_dict[name].append(row)\n    return modules_dict", "response": "Crude parsing of modules. md\n    returns a dict of module_name > documentation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget docstrings for all core modules and user ones if requested returns a dict of module_name > docstring", "response": "def core_module_docstrings(\n    include_core=True, include_user=False, config=None, format=\"md\"\n):\n    \"\"\"\n    Get docstrings for all core modules and user ones if requested\n    returns a dict of {<module_name>: <docstring>}\n    \"\"\"\n    paths = {}\n    docstrings = {}\n    if include_core:\n        for file in os.listdir(modules_directory()):\n            if file.endswith(\".py\"):\n                name = file[:-3]\n                if name != \"__init__\":\n                    paths[name] = (os.path.join(modules_directory(), file), \"core\")\n\n    if include_user:\n        # include user modules\n        for include_path in sorted(config[\"include_paths\"]):\n            for file in sorted(os.listdir(include_path)):\n                if not file.endswith(\".py\"):\n                    continue\n                name = file[:-3]\n                paths[name] = (os.path.join(include_path, file), \"user\")\n    for name in paths:\n        path, module_type = paths[name]\n        with open(path) as f:\n            try:\n                module = ast.parse(f.read())\n            except SyntaxError:\n                # there is a syntax error so ignore module\n                continue\n            raw_docstring = ast.get_docstring(module)\n\n            # prevent issue when no docstring exists\n            if raw_docstring is None:\n                continue\n\n            # remove any sample outputs\n            parts = re.split(\"^SAMPLE OUTPUT$\", raw_docstring, flags=re.M)\n            docstring = parts[0]\n\n            if format == \"md\":\n                docstring = [\n                    d for d in _from_docstring_md(str(docstring).strip().split(\"\\n\"))\n                ]\n            elif format == \"rst\":\n                docstring = [\n                    d for d in _from_docstring_rst(str(docstring).strip().split(\"\\n\"))\n                ]\n            else:\n                raise Exception(\"`md` and `rst` format supported only\")\n\n            docstrings[name] = docstring + [\"\\n\"]\n    return docstrings"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating README. md text for the given module data.", "response": "def create_readme(data):\n    \"\"\"\n    Create README.md text for the given module data.\n    \"\"\"\n    out = ['<a name=\"top\"></a>Modules\\n========\\n\\n']\n    # Links\n    for module in sorted(data.keys()):\n        desc = \"\".join(data[module]).strip().split(\"\\n\")[0]\n        format_str = \"\\n**[{name}](#{name})** \u2014 {desc}\\n\"\n        out.append(format_str.format(name=module, desc=desc))\n    # details\n    for module in sorted(data.keys()):\n        out.append(\n            '\\n---\\n\\n### <a name=\"{name}\"></a>{name}\\n\\n{details}\\n'.format(\n                name=module, details=\"\".join(data[module]).strip()\n            )\n        )\n    return \"\".join(out)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reformat_docstring(doc, format_fn, code_newline=\"\"):\n    out = []\n    status = {\"listing\": False, \"add_line\": False, \"eat_line\": False}\n    code = False\n    for line in doc:\n        if status[\"add_line\"]:\n            out.append(\"\\n\")\n        status[\"add_line\"] = False\n        if status[\"eat_line\"]:\n            status[\"eat_line\"] = False\n            if line.strip() == \"\":\n                continue\n        # check for start/end of code block\n        if line.strip() == \"```\":\n            code = not code\n            out.append(line + code_newline)\n            continue\n        if not code:\n            # if we are in a block listing a blank line ends it\n            if line.rstrip() == \"\":\n                status[\"listing\"] = False\n            # format the line\n            line = format_fn(line, status)\n            # see if block start\n            if re_listing.match(line):\n                status[\"listing\"] = True\n        out.append(line.rstrip() + \"\\n\")\n    return out", "response": "Reformat a docstring into a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting from Markdown to docstring", "response": "def _to_docstring(doc):\n    \"\"\"\n    format from Markdown to docstring\n    \"\"\"\n\n    def format_fn(line, status):\n        \"\"\" format function \"\"\"\n        # swap &lt; &gt; to < >\n        line = re_to_tag.sub(r\"<\\1>\", line)\n        if re_to_data.match(line):\n            line = re_to_data.sub(r\"@\\1 \", line)\n            status[\"eat_line\"] = True\n        line = re_to_defaults.sub(r\"\\1\", line)\n        if status[\"listing\"]:\n            # parameters\n            if re_to_param.match(line):\n                line = re_to_param.sub(r\"    \\1: \", line)\n            # status items\n            elif re_to_status.match(line):\n                line = re_to_status.sub(r\"    \\1 \", line)\n            # bullets\n            elif re_to_item.match(line):\n                line = re_to_item.sub(r\"    -\", line)\n            # is continuation line\n            else:\n                line = \" \" * 8 + line.lstrip()\n        return line\n\n    return _reformat_docstring(doc, format_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats from docstring to Markdown", "response": "def _from_docstring_md(doc):\n    \"\"\"\n    format from docstring to Markdown\n    \"\"\"\n\n    def format_fn(line, status):\n        \"\"\" format function \"\"\"\n\n        def fix_tags(line):\n            # In markdown we need to escape < > and & for display\n            # but we don't want to do this is the value is quoted\n            # by backticks ``\n\n            def fn(match):\n                # swap matched chars\n                found = match.group(1)\n                if found == \"<\":\n                    return \"&lt;\"\n                if found == \">\":\n                    return \"&gt;\"\n                if found == \"&\":\n                    return \"&amp;\"\n                return match.group(0)\n\n            return re_from_tag.sub(fn, line)\n\n        if re_from_data.match(line):\n            line = re_from_data.sub(r\"**\\1** \", line)\n            status[\"add_line\"] = True\n        line = re_from_defaults.sub(r\"*\\1*\", line)\n        if status[\"listing\"]:\n            # parameters\n            if re_from_param.match(line):\n                m = re_from_param.match(line)\n                line = \"  - `{}` {}\".format(m.group(1), fix_tags(m.group(3)))\n            # status items\n            elif re_from_status.match(line):\n                m = re_from_status.match(line)\n                line = \"  - `{}` {}\".format(m.group(1), fix_tags(m.group(3)))\n            # bullets\n            elif re_from_item.match(line):\n                line = re_from_item.sub(r\"  -\", fix_tags(line))\n            # is continuation line\n            else:\n                line = fix_tags(line)\n                line = \" \" * 4 + line.lstrip()\n        else:\n            line = fix_tags(line)\n        return line\n\n    return _reformat_docstring(doc, format_fn, code_newline=\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _from_docstring_rst(doc):\n\n    def format_fn(line, status):\n        \"\"\" format function \"\"\"\n\n        if re_from_data.match(line):\n            line = re_from_data.sub(r\"**\\1** \", line)\n            status[\"add_line\"] = True\n        line = re_from_defaults.sub(r\"*\\1*\", line)\n        if status[\"listing\"]:\n            # parameters\n            if re_from_param.match(line):\n                m = re_from_param.match(line)\n                line = \"  - ``{}`` {}\".format(m.group(1), m.group(3))\n            # status items\n            elif re_from_status.match(line):\n                m = re_from_status.match(line)\n                line = \"  - ``{}`` {}\".format(m.group(1), m.group(3))\n            # bullets\n            elif re_from_item.match(line):\n                line = re_from_item.sub(r\"  -\", line)\n            # is continuation line\n            else:\n                line = \" \" * 4 + line.lstrip()\n        # in .rst format code samples use double backticks vs single ones for\n        # .md This converts them.\n        line = re_lone_backtick.sub(\"``\", line)\n        return line\n\n    return _reformat_docstring(doc, format_fn, code_newline=\"\\n\")", "response": "format from docstring to ReStructured Text\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the docstring of each module in the modules directory", "response": "def update_docstrings():\n    \"\"\"\n    update the docstring of each module using info in the\n    modules/README.md file\n    \"\"\"\n    modules_dict = parse_readme()\n    files = {}\n    # update modules\n    for mod in modules_dict:\n        mod_file = os.path.join(modules_directory(), mod + \".py\")\n        with open(mod_file) as f:\n            files[mod] = f.readlines()\n\n    for mod in files:\n        replaced = False\n        done = False\n        lines = False\n        out = []\n        quotes = None\n        for row in files[mod]:\n            # deal with single or double quoted docstring\n            if not quotes:\n                if row.strip().startswith('\"\"\"'):\n                    quotes = '\"\"\"'\n                if row.strip().startswith(\"'''\"):\n                    quotes = \"'''\"\n            if quotes and row.strip().startswith(quotes) and not done:\n                out.append(row)\n                if not replaced:\n                    out = out + [\n                        \"\".join(_to_docstring(modules_dict[mod])).strip() + \"\\n\"\n                    ]\n                    replaced = True\n                if lines:\n                    done = True\n                if not done and not lines:\n                    lines = True\n                continue\n            if not lines or done:\n                out.append(row)\n        mod_file = os.path.join(modules_directory(), mod + \".py\")\n        with open(mod_file, \"w\") as f:\n            f.writelines(out)\n    print_stderr(\"Modules updated from README.md\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_docstrings(show_diff=False, config=None, mods=None):\n\n    readme = parse_readme()\n    modules_readme = core_module_docstrings(config=config)\n    warned = False\n    if create_readme(readme) != create_readme(modules_readme):\n        for module in sorted(readme):\n            if mods and module not in mods:\n                continue\n            err = None\n            if module not in modules_readme:\n                err = \"Module {} in README but not in /modules\".format(module)\n            elif (\n                \"\".join(readme[module]).strip()\n                != \"\".join(modules_readme[module]).strip()\n            ):\n                err = \"Module {} docstring does not match README\".format(module)\n            if err:\n                if not warned:\n                    print_stderr(\"Documentation does not match!\\n\")\n                    warned = True\n                print_stderr(err)\n\n        for module in modules_readme:\n            if mods and module not in mods:\n                continue\n            if module not in readme:\n                print_stderr(\"Module {} in /modules but not in README\".format(module))\n        if show_diff:\n            print_stderr(\n                \"\\n\".join(\n                    difflib.unified_diff(\n                        create_readme(readme).split(\"\\n\"),\n                        create_readme(modules_readme).split(\"\\n\"),\n                    )\n                )\n            )\n        else:\n            if warned:\n                print_stderr(\"\\nUse `py3-cmd docstring --diff` to view diff.\")", "response": "Check docstrings in README. md and README. md files match the README. md files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_readme_for_modules(modules):\n    readme = parse_readme()\n    module_docstrings = core_module_docstrings()\n    if modules == [\"__all__\"]:\n        modules = core_module_docstrings().keys()\n    for module in modules:\n        if module in module_docstrings:\n            print_stderr(\"Updating README.md for module {}\".format(module))\n            readme[module] = module_docstrings[module]\n        else:\n            print_stderr(\"Module {} not in core modules\".format(module))\n\n    # write the file\n    readme_file = os.path.join(modules_directory(), \"README.md\")\n    with open(readme_file, \"w\") as f:\n        f.write(create_readme(readme))", "response": "Update the README. md for the modules listed in modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_modules(config, modules_list):\n    details = config[\"full\"]\n    core_mods = not config[\"user\"]\n    user_mods = not config[\"core\"]\n\n    modules = core_module_docstrings(\n        include_core=core_mods, include_user=user_mods, config=config\n    )\n\n    new_modules = []\n    if modules_list:\n        from fnmatch import fnmatch\n\n        for _filter in modules_list:\n            for name in modules.keys():\n                if fnmatch(name, _filter):\n                    if name not in new_modules:\n                        new_modules.append(name)\n    else:\n        new_modules = modules.keys()\n\n    for name in sorted(new_modules):\n        module = _to_docstring(modules[name])\n        desc = module[0][:-1]\n        if details:\n            dash_len = len(name) + 4\n            print(\"#\" * dash_len)\n            print(\"# {} #\".format(name))\n            print(\"#\" * dash_len)\n            for description in module:\n                print(description[:-1])\n        else:\n            print(\"%-22s %s\" % (name, desc))", "response": "Prints the modules available optionally with details."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new(self, injection_site_fn):\n        return _InjectionContext(\n            injection_site_fn, binding_stack=[], scope_id=scoping.UNSCOPED,\n            is_scope_usable_from_scope_fn=self._is_scope_usable_from_scope_fn)", "response": "Creates a _InjectionContext object from the given function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a child injection context.", "response": "def get_child(self, injection_site_fn, binding):\n        \"\"\"Creates a child injection context.\n\n        A \"child\" injection context is a context for a binding used to\n        inject something into the current binding's provided value.\n\n        Args:\n          injection_site_fn: the child function being injected into\n          binding: a Binding\n        Returns:\n          a new _InjectionContext\n        \"\"\"\n        child_scope_id = binding.scope_id\n        new_binding_stack = self._binding_stack + [binding]\n        if binding in self._binding_stack:\n            raise errors.CyclicInjectionError(new_binding_stack)\n        if not self._is_scope_usable_from_scope_fn(\n                child_scope_id, self._scope_id):\n            raise errors.BadDependencyScopeError(\n                self.get_injection_site_desc(),\n                self._scope_id, child_scope_id, binding.binding_key)\n        return _InjectionContext(\n            injection_site_fn, new_binding_stack, child_scope_id,\n            self._is_scope_usable_from_scope_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_object_graph(\n        modules=finding.ALL_IMPORTED_MODULES, classes=None, binding_specs=None,\n        only_use_explicit_bindings=False, allow_injecting_none=False,\n        configure_method_name='configure',\n        dependencies_method_name='dependencies',\n        get_arg_names_from_class_name=(\n            bindings.default_get_arg_names_from_class_name),\n        get_arg_names_from_provider_fn_name=(\n            providing.default_get_arg_names_from_provider_fn_name),\n        id_to_scope=None, is_scope_usable_from_scope=lambda _1, _2: True,\n        use_short_stack_traces=True):\n    \"\"\"Creates a new object graph.\n\n    Args:\n      modules: the modules in which to search for classes for which to create\n          implicit bindings; if None, then no modules; by default, all\n          modules imported at the time of calling this method\n      classes: the classes for which to create implicit bindings; if None (the\n          default), then no classes\n      binding_specs: the BindingSpec subclasses to get bindings and provider\n          methods from; if None (the default), then no binding specs\n      only_use_explicit_bindings: whether to use only explicit bindings (i.e.,\n          created by binding specs or @pinject.injectable, etc.)\n      allow_injecting_none: whether to allow a provider method to provide None\n      configure_method_name: the name of binding specs' configure method\n      dependencies_method_name: the name of binding specs' dependencies method\n      get_arg_names_from_class_name: a function mapping a class name to a\n          sequence of the arg names to which those classes should be\n          implicitly bound (if any)\n      get_arg_names_from_provider_fn_name: a function mapping a provider\n          method name to a sequence of the arg names for which that method is\n          a provider (if any)\n      id_to_scope: a map from scope ID to the concrete Scope implementation\n          instance for that scope\n      is_scope_usable_from_scope: a function taking two scope IDs and\n          returning whether an object in the first scope can be injected into\n          an object from the second scope; by default, injection is allowed\n          from any scope into any other scope\n      use_short_stack_traces: whether to shorten the stack traces for\n          exceptions that Pinject raises, so that they don't contain the\n          innards of Pinject\n    Returns:\n      an ObjectGraph\n    Raises:\n      Error: the object graph is not creatable as specified\n\n    \"\"\"\n    try:\n        if modules is not None and modules is not finding.ALL_IMPORTED_MODULES:\n            support.verify_module_types(modules, 'modules')\n        if classes is not None:\n            support.verify_class_types(classes, 'classes')\n        if binding_specs is not None:\n            support.verify_subclasses(\n                binding_specs, bindings.BindingSpec, 'binding_specs')\n        if get_arg_names_from_class_name is not None:\n            support.verify_callable(get_arg_names_from_class_name,\n                                    'get_arg_names_from_class_name')\n        if get_arg_names_from_provider_fn_name is not None:\n            support.verify_callable(get_arg_names_from_provider_fn_name,\n                                    'get_arg_names_from_provider_fn_name')\n        if is_scope_usable_from_scope is not None:\n            support.verify_callable(is_scope_usable_from_scope,\n                                    'is_scope_usable_from_scope')\n        injection_context_factory = injection_contexts.InjectionContextFactory(\n            is_scope_usable_from_scope)\n        id_to_scope = scoping.get_id_to_scope_with_defaults(id_to_scope)\n        bindable_scopes = scoping.BindableScopes(id_to_scope)\n        known_scope_ids = id_to_scope.keys()\n\n        found_classes = finding.find_classes(modules, classes)\n        if only_use_explicit_bindings:\n            implicit_class_bindings = []\n        else:\n            implicit_class_bindings = bindings.get_implicit_class_bindings(\n                found_classes, get_arg_names_from_class_name)\n        explicit_bindings = bindings.get_explicit_class_bindings(\n            found_classes, get_arg_names_from_class_name)\n        binder = bindings.Binder(explicit_bindings, known_scope_ids)\n        required_bindings = required_bindings_lib.RequiredBindings()\n        if binding_specs is not None:\n            binding_specs = list(binding_specs)\n            processed_binding_specs = set()\n            while binding_specs:\n                binding_spec = binding_specs.pop()\n                if binding_spec in processed_binding_specs:\n                    continue\n                processed_binding_specs.add(binding_spec)\n                all_kwargs = {'bind': binder.bind,\n                              'require': required_bindings.require}\n                has_configure = hasattr(binding_spec, configure_method_name)\n                if has_configure:\n                    configure_method = getattr(binding_spec, configure_method_name)\n                    configure_kwargs = _pare_to_present_args(\n                        all_kwargs, configure_method)\n                    if not configure_kwargs:\n                        raise errors.ConfigureMethodMissingArgsError(\n                            configure_method, all_kwargs.keys())\n                    try:\n                        configure_method(**configure_kwargs)\n                    except NotImplementedError:\n                        has_configure = False\n                dependencies = None\n                if hasattr(binding_spec, dependencies_method_name):\n                    dependencies_method = (\n                        getattr(binding_spec, dependencies_method_name))\n                    dependencies = dependencies_method()\n                    binding_specs.extend(dependencies)\n                provider_bindings = bindings.get_provider_bindings(\n                    binding_spec, known_scope_ids,\n                    get_arg_names_from_provider_fn_name)\n                explicit_bindings.extend(provider_bindings)\n                if (not has_configure and\n                    not dependencies and\n                    not provider_bindings):\n                    raise errors.EmptyBindingSpecError(binding_spec)\n        binding_key_to_binding, collided_binding_key_to_bindings = (\n            bindings.get_overall_binding_key_to_binding_maps(\n                [implicit_class_bindings, explicit_bindings]))\n        binding_mapping = bindings.BindingMapping(\n            binding_key_to_binding, collided_binding_key_to_bindings)\n        binding_mapping.verify_requirements(required_bindings.get())\n    except errors.Error as e:\n        if use_short_stack_traces:\n            raise e\n        else:\n            raise\n\n    is_injectable_fn = {True: decorators.is_explicitly_injectable,\n                        False: (lambda cls: True)}[only_use_explicit_bindings]\n    obj_provider = object_providers.ObjectProvider(\n        binding_mapping, bindable_scopes, allow_injecting_none)\n    return ObjectGraph(\n        obj_provider, injection_context_factory, is_injectable_fn,\n        use_short_stack_traces)", "response": "Creates a new object graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproviding an instance of cls.", "response": "def provide(self, cls):\n        \"\"\"Provides an instance of the given class.\n\n        Args:\n          cls: a class (not an instance)\n        Returns:\n          an instance of cls\n        Raises:\n          Error: an instance of cls is not providable\n        \"\"\"\n        support.verify_class_type(cls, 'cls')\n        if not self._is_injectable_fn(cls):\n            provide_loc = locations.get_back_frame_loc()\n            raise errors.NonExplicitlyBoundClassError(provide_loc, cls)\n        try:\n            return self._obj_provider.provide_class(\n                cls, self._injection_context_factory.new(cls.__init__),\n                direct_init_pargs=[], direct_init_kwargs={})\n        except errors.Error as e:\n            if self._use_short_stack_traces:\n                raise e\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the type name of a target object.", "response": "def _get_type_name(target_thing):\n    \"\"\"\n    Functions, bound methods and unbound methods change significantly in Python 3.\n\n    For instance:\n\n    class SomeObject(object):\n        def method():\n            pass\n\n    In Python 2:\n    - Unbound method inspect.ismethod(SomeObject.method) returns True\n    - Unbound inspect.isfunction(SomeObject.method) returns False\n    - Unbound hasattr(SomeObject.method, 'im_class') returns True\n    - Bound method inspect.ismethod(SomeObject().method) returns True\n    - Bound method inspect.isfunction(SomeObject().method) returns False\n    - Bound hasattr(SomeObject().method, 'im_class') returns True\n\n    In Python 3:\n    - Unbound method inspect.ismethod(SomeObject.method) returns False\n    - Unbound inspect.isfunction(SomeObject.method) returns True\n    - Unbound hasattr(SomeObject.method, 'im_class') returns False\n    - Bound method inspect.ismethod(SomeObject().method) returns True\n    - Bound method inspect.isfunction(SomeObject().method) returns False\n    - Bound hasattr(SomeObject().method, 'im_class') returns False\n\n    This method tries to consolidate the approach for retrieving the\n    enclosing type of a bound/unbound method and functions.\n    \"\"\"\n    thing = target_thing\n    if hasattr(thing, 'im_class'):\n        # only works in Python 2\n        return thing.im_class.__name__\n    if inspect.ismethod(thing):\n        for cls in inspect.getmro(thing.__self__.__class__):\n            if cls.__dict__.get(thing.__name__) is thing:\n                return cls.__name__\n        thing = thing.__func__\n    if inspect.isfunction(thing) and hasattr(thing, '__qualname__'):\n        qualifier = thing.__qualname__\n        if LOCALS_TOKEN in qualifier:\n            return _get_local_type_name(thing)\n        return _get_external_type_name(thing)\n    return inspect.getmodule(target_thing).__name__"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines which args have no arg binding keys.", "response": "def get_unbound_arg_names(arg_names, arg_binding_keys):\n    \"\"\"Determines which args have no arg binding keys.\n\n    Args:\n      arg_names: a sequence of the names of possibly bound args\n      arg_binding_keys: a sequence of ArgBindingKey each of whose arg names is\n          in arg_names\n    Returns:\n      a sequence of arg names that is a (possibly empty, possibly non-proper)\n          subset of arg_names\n\n    \"\"\"\n    bound_arg_names = [abk._arg_name for abk in arg_binding_keys]\n    return [arg_name for arg_name in arg_names\n            if arg_name not in bound_arg_names]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an ArgBindingKey. Args: arg_name: the name of the bound arg annotation: an Annotation, or None to create an unannotated arg binding key Returns: a new ArgBindingKey", "response": "def new(arg_name, annotated_with=None):\n    \"\"\"Creates an ArgBindingKey.\n\n    Args:\n      arg_name: the name of the bound arg\n      annotation: an Annotation, or None to create an unannotated arg binding\n          key\n    Returns:\n      a new ArgBindingKey\n    \"\"\"\n    if arg_name.startswith(_PROVIDE_PREFIX):\n        binding_key_name = arg_name[_PROVIDE_PREFIX_LEN:]\n        provider_indirection = provider_indirections.INDIRECTION\n    else:\n        binding_key_name = arg_name\n        provider_indirection = provider_indirections.NO_INDIRECTION\n    binding_key = binding_keys.new(binding_key_name, annotated_with)\n    return ArgBindingKey(arg_name, binding_key, provider_indirection)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_overall_binding_key_to_binding_maps(bindings_lists):\n\n    \"\"\"bindings_lists from lowest to highest priority.  Last item in\n    bindings_lists is assumed explicit.\n\n    \"\"\"\n    binding_key_to_binding = {}\n    collided_binding_key_to_bindings = {}\n\n    for index, bindings in enumerate(bindings_lists):\n        is_final_index = (index == (len(bindings_lists) - 1))\n        handle_binding_collision_fn = {\n            True: _handle_explicit_binding_collision,\n            False: _handle_implicit_binding_collision}[is_final_index]\n        this_binding_key_to_binding, this_collided_binding_key_to_bindings = (\n            _get_binding_key_to_binding_maps(\n                bindings, handle_binding_collision_fn))\n        for good_binding_key in this_binding_key_to_binding:\n            collided_binding_key_to_bindings.pop(good_binding_key, None)\n        binding_key_to_binding.update(this_binding_key_to_binding)\n        collided_binding_key_to_bindings.update(\n            this_collided_binding_key_to_bindings)\n\n    return binding_key_to_binding, collided_binding_key_to_bindings", "response": "Returns a tuple of all the key - to - binding maps for all the bindings in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert normal class names into normal arg names.", "response": "def default_get_arg_names_from_class_name(class_name):\n    \"\"\"Converts normal class names into normal arg names.\n\n    Normal class names are assumed to be CamelCase with an optional leading\n    underscore.  Normal arg names are assumed to be lower_with_underscores.\n\n    Args:\n      class_name: a class name, e.g., \"FooBar\" or \"_FooBar\"\n    Returns:\n      all likely corresponding arg names, e.g., [\"foo_bar\"]\n    \"\"\"\n    parts = []\n    rest = class_name\n    if rest.startswith('_'):\n        rest = rest[1:]\n    while True:\n        m = re.match(r'([A-Z][a-z]+)(.*)', rest)\n        if m is None:\n            break\n        parts.append(m.group(1))\n        rest = m.group(2)\n    if not parts:\n        return []\n    return ['_'.join(part.lower() for part in parts)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef annotate_arg(arg_name, with_annotation):\n    arg_binding_key = arg_binding_keys.new(arg_name, with_annotation)\n    return _get_pinject_wrapper(locations.get_back_frame_loc(),\n                                arg_binding_key=arg_binding_key)", "response": "Returns a function that adds an annotation to an injected arg."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks an initializer explicitly as injectable. An initializer marked with @inject will be usable even when setting only_use_explicit_bindings=True when calling new_object_graph(). This decorator can be used on an initializer or provider method to separate the injectable args from the args that will be passed directly. If arg_names is specified, then it must be a sequence, and only those args are injected (and the rest must be passed directly). If all_except is specified, then it must be a sequence, and only those args are passed directly (and the rest must be specified). If neither arg_names nor all_except are specified, then all args are injected (and none may be passed directly). arg_names or all_except, when specified, must not be empty and must contain a (possibly empty, possibly non-proper) subset of the named args of the decorated function. all_except may not be all args of the decorated function (because then why call that provider method or initialzer via Pinject?). At most one of arg_names and all_except may be specified. A function may be decorated by @inject at most once.", "response": "def inject(arg_names=None, all_except=None):\n    \"\"\"Marks an initializer explicitly as injectable.\n\n    An initializer marked with @inject will be usable even when setting\n    only_use_explicit_bindings=True when calling new_object_graph().\n\n    This decorator can be used on an initializer or provider method to\n    separate the injectable args from the args that will be passed directly.\n    If arg_names is specified, then it must be a sequence, and only those args\n    are injected (and the rest must be passed directly).  If all_except is\n    specified, then it must be a sequence, and only those args are passed\n    directly (and the rest must be specified).  If neither arg_names nor\n    all_except are specified, then all args are injected (and none may be\n    passed directly).\n\n    arg_names or all_except, when specified, must not be empty and must\n    contain a (possibly empty, possibly non-proper) subset of the named args\n    of the decorated function.  all_except may not be all args of the\n    decorated function (because then why call that provider method or\n    initialzer via Pinject?).  At most one of arg_names and all_except may be\n    specified.  A function may be decorated by @inject at most once.\n\n    \"\"\"\n    back_frame_loc = locations.get_back_frame_loc()\n    if arg_names is not None and all_except is not None:\n        raise errors.TooManyArgsToInjectDecoratorError(back_frame_loc)\n    for arg, arg_value in [('arg_names', arg_names), ('all_except', all_except)]:\n        if arg_value is not None:\n            if not arg_value:\n                raise errors.EmptySequenceArgError(back_frame_loc, arg)\n            if (not support.is_sequence(arg_value) or\n                    support.is_string(arg_value)):\n                raise errors.WrongArgTypeError(\n                    arg, 'sequence (of arg names)', type(arg_value).__name__)\n    if arg_names is None and all_except is None:\n        all_except = []\n    return _get_pinject_wrapper(\n        back_frame_loc, inject_arg_names=arg_names,\n        inject_all_except_arg_names=all_except)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a function that will be used to create a binding for a provider method.", "response": "def provides(arg_name=None, annotated_with=None, in_scope=None):\n    \"\"\"Modifies the binding of a provider method.\n\n    If arg_name is specified, then the created binding is for that arg name\n    instead of the one gotten from the provider method name (e.g., 'foo' from\n    'provide_foo').\n\n    If annotated_with is specified, then the created binding includes that\n    annotation object.\n\n    If in_scope is specified, then the created binding is in the scope with\n    that scope ID.\n\n    At least one of the args must be specified.  A provider method may not be\n    decorated with @provides() twice.\n\n    Args:\n      arg_name: the name of the arg to annotate on the decorated function\n      annotated_with: an annotation object\n      in_scope: a scope ID\n    Returns:\n      a function that will decorate functions passed to it\n    \"\"\"\n    if arg_name is None and annotated_with is None and in_scope is None:\n        raise errors.EmptyProvidesDecoratorError(locations.get_back_frame_loc())\n    return _get_pinject_wrapper(locations.get_back_frame_loc(),\n                                provider_arg_name=arg_name,\n                                provider_annotated_with=annotated_with,\n                                provider_in_scope_id=in_scope)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_provider_fn_decorations(provider_fn, default_arg_names):\n    if hasattr(provider_fn, _IS_WRAPPER_ATTR):\n        provider_decorations = getattr(provider_fn, _PROVIDER_DECORATIONS_ATTR)\n        if provider_decorations:\n            expanded_provider_decorations = []\n            for provider_decoration in provider_decorations:\n                # TODO(kurts): seems like default scope should be done at\n                # ProviderDecoration instantiation time.\n                if provider_decoration.in_scope_id is None:\n                    provider_decoration.in_scope_id = scoping.DEFAULT_SCOPE\n                if provider_decoration.arg_name is not None:\n                    expanded_provider_decorations.append(provider_decoration)\n                else:\n                    expanded_provider_decorations.extend(\n                        [ProviderDecoration(default_arg_name,\n                                            provider_decoration.annotated_with,\n                                            provider_decoration.in_scope_id)\n                         for default_arg_name in default_arg_names])\n            return expanded_provider_decorations\n    return [ProviderDecoration(default_arg_name,\n                               annotated_with=None,\n                               in_scope_id=scoping.DEFAULT_SCOPE)\n            for default_arg_name in default_arg_names]", "response": "Returns the provider method - relevant info set by decorators."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new(arg_name, annotated_with=None):\n    if annotated_with is not None:\n        annotation = annotations.Annotation(annotated_with)\n    else:\n        annotation = annotations.NO_ANNOTATION\n    return BindingKey(arg_name, annotation)", "response": "Creates a BindingKey.\n\n    Args:\n      arg_name: the name of the bound arg\n      annotation: an Annotation, or None to create an unannotated binding key\n    Returns:\n      a new BindingKey"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __setkey(key):\n    global C, D, KS, E\n\n    shifts = (1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1)\n\n    # First, generate C and D by permuting the key. The lower order bit of each\n    # 8-bit char is not used, so C and D are only 28 bits apiece.\n    for i in range(28):\n        C[i] = key[PC1_C[i] - 1]\n        D[i] = key[PC1_D[i] - 1]\n\n    for i in range(16):\n        # rotate\n        for k in range(shifts[i]):\n            temp = C[0]\n\n            for j in range(27):\n                C[j] = C[j + 1]\n\n            C[27] = temp\n            temp = D[0]\n            for j in range(27):\n                D[j] = D[j + 1]\n\n            D[27] = temp\n\n        # get Ki. Note C and D are concatenated\n        for j in range(24):\n            KS[i][j] = C[PC2_C[j] - 1]\n            KS[i][j + 24] = D[PC2_D[j] - 28 - 1]\n\n    # load E with the initial E bit selections\n    for i in range(48):\n        E[i] = e2[i]", "response": "Set up the key schedule from the encryption key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a string into a date object.", "response": "def date_parse(s):\n    \"\"\"\n    Parses value of a DATE type.\n    :param s: string to parse into date\n    :return: an instance of datetime.date\n    :raises NotSupportedError when a date Before Christ is encountered\n    \"\"\"\n    s = as_str(s)\n    if s.endswith(' BC'):\n        raise errors.NotSupportedError('Dates Before Christ are not supported. Got: {0}'.format(s))\n\n    # Value error, year might be over 9999\n    return date(*map(lambda x: min(int(x), 9999), s.split('-')))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert either bytes or unicode string to bytes using utf - 8 encoding for text.", "response": "def as_bytes(bytes_or_text, encoding='utf-8'):\n    \"\"\"Converts either bytes or unicode to `bytes`, using utf-8 encoding for text.\n    Args:\n      bytes_or_text: A `bytes`, `str`, or `unicode` object.\n      encoding: A string indicating the charset for encoding unicode.\n    Returns:\n      A `bytes` object.\n    Raises:\n      TypeError: If `bytes_or_text` is not a binary or unicode string.\n    \"\"\"\n    if isinstance(bytes_or_text, _six.text_type):\n        return bytes_or_text.encode(encoding)\n    elif isinstance(bytes_or_text, bytes):\n        return bytes_or_text\n    else:\n        raise TypeError('Expected binary or unicode string, got %r' %\n                        (bytes_or_text,))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_text(bytes_or_text, encoding='utf-8'):\n    if isinstance(bytes_or_text, _six.text_type):\n        return bytes_or_text\n    elif isinstance(bytes_or_text, bytes):\n        return bytes_or_text.decode(encoding)\n    else:\n        raise TypeError('Expected binary or unicode string, got %r' % bytes_or_text)", "response": "Returns the given argument as a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nextset(self):\n        # skip any data for this set if exists\n        self.flush_to_end_of_result()\n\n        if self._message is None:\n            return False\n        elif isinstance(self._message, END_OF_RESULT_RESPONSES):\n            # there might be another set, read next message to find out\n            self._message = self.connection.read_message()\n            if isinstance(self._message, messages.RowDescription):\n                self.description = [Column(fd, self.unicode_error) for fd in self._message.fields]\n                self._message = self.connection.read_message()\n                return True\n            elif isinstance(self._message, messages.BindComplete):\n                self._message = self.connection.read_message()\n                return True\n            elif isinstance(self._message, messages.ReadyForQuery):\n                return False\n            elif isinstance(self._message, END_OF_RESULT_RESPONSES):\n                # result of a DDL/transaction\n                return True\n            elif isinstance(self._message, messages.ErrorResponse):\n                raise errors.QueryError.from_error_response(self._message, self.operation)\n            else:\n                raise errors.MessageError(\n                    'Unexpected nextset() state after END_OF_RESULT_RESPONSES: {0}'.format(self._message))\n        elif isinstance(self._message, messages.ReadyForQuery):\n            # no more sets left to be read\n            return False\n        else:\n            raise errors.MessageError('Unexpected nextset() state: {0}'.format(self._message))", "response": "Returns True if there is a next available result set or False if there are no more rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies data from the database to the local cache.", "response": "def copy(self, sql, data, **kwargs):\n        \"\"\"\n        \n        EXAMPLE:\n        >> with open(\"/tmp/file.csv\", \"rb\") as fs:\n        >>     cursor.copy(\"COPY table(field1,field2) FROM STDIN DELIMITER ',' ENCLOSED BY ''''\",\n        >>                 fs, buffer_size=65536)\n\n        \"\"\"\n        sql = as_text(sql)\n\n        if self.closed():\n            raise errors.InterfaceError('Cursor is closed')\n\n        self.flush_to_query_ready()\n\n        if isinstance(data, binary_type):\n            stream = BytesIO(data)\n        elif isinstance(data, text_type):\n            stream = StringIO(data)\n        elif isinstance(data, file_type):\n            stream = data\n        else:\n            raise TypeError(\"Not valid type of data {0}\".format(type(data)))\n\n        self.connection.write(messages.Query(sql))\n\n        while True:\n            message = self.connection.read_message()\n\n            self._message = message\n            if isinstance(message, messages.ErrorResponse):\n                raise errors.QueryError.from_error_response(message, sql)\n\n            self.connection.process_message(message=message)\n\n            if isinstance(message, messages.ReadyForQuery):\n                break\n            elif isinstance(message, messages.CopyInResponse):\n                self.connection.write(messages.CopyStream(stream, **kwargs))\n                self.connection.write(messages.CopyDone())\n\n        if self.error is not None:\n            raise self.error"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a simple query and return the result.", "response": "def _execute_simple_query(self, query):\n        \"\"\"\n        Send the query to the server using the simple query protocol.\n        Return True if this query contained no SQL (e.g. the string \"--comment\")\n        \"\"\"\n        self._logger.info(u'Execute simple query: [{}]'.format(query))\n\n        # All of the statements in the query are sent here in a single message\n        self.connection.write(messages.Query(query))\n\n        # The first response could be a number of things:\n        #   ErrorResponse: Something went wrong on the server.\n        #   EmptyQueryResponse: The query being executed is empty.\n        #   RowDescription: This is the \"normal\" case when executing a query.\n        #                   It marks the start of the results.\n        #   CommandComplete: This occurs when executing DDL/transactions.\n        self._message = self.connection.read_message()\n        if isinstance(self._message, messages.ErrorResponse):\n            raise errors.QueryError.from_error_response(self._message, query)\n        elif isinstance(self._message, messages.RowDescription):\n            self.description = [Column(fd, self.unicode_error) for fd in self._message.fields]\n            self._message = self.connection.read_message()\n            if isinstance(self._message, messages.ErrorResponse):\n                raise errors.QueryError.from_error_response(self._message, query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _prepare(self, query):\n        self._logger.info(u'Prepare a statement: [{}]'.format(query))\n\n        # Send Parse message to server\n        # We don't need to tell the server the parameter types yet\n        self.connection.write(messages.Parse(self.prepared_name, query, param_types=()))\n        # Send Describe message to server\n        self.connection.write(messages.Describe('prepared_statement', self.prepared_name))\n        self.connection.write(messages.Flush())\n\n        # Read expected message: ParseComplete\n        self._message = self.connection.read_expected_message(messages.ParseComplete, self._error_handler)\n\n        # Read expected message: ParameterDescription\n        self._message = self.connection.read_expected_message(messages.ParameterDescription, self._error_handler)\n        self._param_metadata = self._message.parameters\n\n        # Read expected message: RowDescription or NoData\n        self._message = self.connection.read_expected_message(\n                        (messages.RowDescription, messages.NoData), self._error_handler)\n        if isinstance(self._message, messages.NoData):\n            self.description = None # response was NoData for a DDL/transaction PreparedStatement\n        else:\n            self.description = [Column(fd, self.unicode_error) for fd in self._message.fields]\n\n        # Read expected message: CommandDescription\n        self._message = self.connection.read_expected_message(messages.CommandDescription, self._error_handler)\n        if len(self._message.command_tag) == 0:\n            msg = 'The statement being prepared is empty'\n            self._logger.error(msg)\n            self.connection.write(messages.Sync())\n            raise errors.EmptyQueryError(msg)\n\n        self._logger.info('Finish preparing the statement')", "response": "Send the query to the server and parse the query and return some metadata."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend multiple statement parameter sets to the server using the extended query protocol.", "response": "def _execute_prepared_statement(self, list_of_parameter_values):\n        \"\"\"\n        Send multiple statement parameter sets to the server using the extended\n        query protocol. The server would bind and execute each set of parameter\n        values.\n\n        This function should not be called without first calling _prepare() to\n        prepare a statement.\n        \"\"\"\n        portal_name = \"\"\n        parameter_type_oids = [metadata['data_type_oid'] for metadata in self._param_metadata]\n        parameter_count = len(self._param_metadata)\n\n        try:\n            if len(list_of_parameter_values) == 0:\n                raise ValueError(\"Empty list/tuple, nothing to execute\")\n            for parameter_values in list_of_parameter_values:\n                if parameter_values is None:\n                    parameter_values = ()\n                self._logger.info(u'Bind parameters: {}'.format(parameter_values))\n                if len(parameter_values) != parameter_count:\n                    msg = (\"Invalid number of parameters for {}: {} given, {} expected\"\n                           .format(parameter_values, len(parameter_values), parameter_count))\n                    raise ValueError(msg)\n                self.connection.write(messages.Bind(portal_name, self.prepared_name,\n                                             parameter_values, parameter_type_oids))\n                self.connection.write(messages.Execute(portal_name, 0))\n            self.connection.write(messages.Sync())\n        except Exception as e:\n            self._logger.error(str(e))\n            # the server will not send anything until we issue a sync\n            self.connection.write(messages.Sync())\n            self._message = self.connection.read_message()\n            raise\n\n        self.connection.write(messages.Flush())\n\n        # Read expected message: BindComplete\n        self.connection.read_expected_message(messages.BindComplete)\n\n        self._message = self.connection.read_message()\n        if isinstance(self._message, messages.ErrorResponse):\n            raise errors.QueryError.from_error_response(self._message, self.prepared_sql)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses the prepared statement on the server.", "response": "def _close_prepared_statement(self):\n        \"\"\"\n        Close the prepared statement on the server.\n        \"\"\"\n        self.prepared_sql = None\n        self.flush_to_query_ready()\n        self.connection.write(messages.Close('prepared_statement', self.prepared_name))\n        self.connection.write(messages.Flush())\n        self._message = self.connection.read_expected_message(messages.CloseComplete)\n        self.connection.write(messages.Sync())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring that a directory exists and protect against a race condition", "response": "def ensure_dir_exists(cls, filepath):\n        \"\"\"Ensure that a directory exists\n\n        If it doesn't exist, try to create it and protect against a race condition\n        if another process is doing the same.\n        \"\"\"\n        directory = os.path.dirname(filepath)\n        if directory != '' and not os.path.exists(directory):\n            try:\n                os.makedirs(directory)\n            except OSError as e:\n                if e.errno != errno.EEXIST:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the base type name according to the data type_oid and type_modifier", "response": "def getTypeName(data_type_oid, type_modifier):\n    \"\"\"Returns the base type name according to data_type_oid and type_modifier\"\"\"\n\n    if data_type_oid == VerticaType.BOOL:\n        return \"Boolean\"\n    elif data_type_oid == VerticaType.INT8:\n        return \"Integer\"\n    elif data_type_oid == VerticaType.FLOAT8:\n        return \"Float\"\n    elif data_type_oid == VerticaType.CHAR:\n        return \"Char\"\n    elif data_type_oid in (VerticaType.VARCHAR, VerticaType.UNKNOWN):\n        return \"Varchar\"\n    elif data_type_oid == VerticaType.LONGVARCHAR:\n        return \"Long Varchar\"\n    elif data_type_oid == VerticaType.DATE:\n        return \"Date\"\n    elif data_type_oid == VerticaType.TIME:\n        return \"Time\"\n    elif data_type_oid == VerticaType.TIMETZ:\n        return \"TimeTz\"\n    elif data_type_oid == VerticaType.TIMESTAMP:\n        return \"Timestamp\"\n    elif data_type_oid == VerticaType.TIMESTAMPTZ:\n        return \"TimestampTz\"\n    elif data_type_oid in (VerticaType.INTERVAL, VerticaType.INTERVALYM):\n        return \"Interval \" + getIntervalRange(data_type_oid, type_modifier)\n    elif data_type_oid == VerticaType.BINARY:\n        return \"Binary\"\n    elif data_type_oid == VerticaType.VARBINARY:\n        return \"Varbinary\"\n    elif data_type_oid == VerticaType.LONGVARBINARY:\n        return \"Long Varbinary\"\n    elif data_type_oid == VerticaType.NUMERIC:\n        return \"Numeric\"\n    elif data_type_oid == VerticaType.UUID:\n        return \"Uuid\"\n    else:\n        return \"Unknown\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getIntervalRange(data_type_oid, type_modifier):\n\n    if data_type_oid not in (VerticaType.INTERVAL, VerticaType.INTERVALYM):\n        raise ValueError(\"Invalid data type OID: {}\".format(data_type_oid))\n\n    if type_modifier == -1:   # assume the default\n        if data_type_oid == VerticaType.INTERVALYM:\n            return \"Year to Month\"\n        elif data_type_oid == VerticaType.INTERVAL:\n            return \"Day to Second\"\n\n    if data_type_oid == VerticaType.INTERVALYM: # Year/Month intervals\n        if (type_modifier & INTERVAL_MASK_YEAR2MONTH) == INTERVAL_MASK_YEAR2MONTH:\n            return \"Year to Month\"\n        elif (type_modifier & INTERVAL_MASK_YEAR) == INTERVAL_MASK_YEAR:\n            return \"Year\"\n        elif (type_modifier & INTERVAL_MASK_MONTH) == INTERVAL_MASK_MONTH:\n            return \"Month\"\n        else:\n            return \"Year to Month\"\n\n    if data_type_oid == VerticaType.INTERVAL:  # Day/Time intervals\n        if (type_modifier & INTERVAL_MASK_DAY2SEC) == INTERVAL_MASK_DAY2SEC:\n            return \"Day to Second\"\n        elif (type_modifier & INTERVAL_MASK_DAY2MIN) == INTERVAL_MASK_DAY2MIN:\n            return \"Day to Minute\"\n        elif (type_modifier & INTERVAL_MASK_DAY2HOUR) == INTERVAL_MASK_DAY2HOUR:\n            return \"Day to Hour\"\n        elif (type_modifier & INTERVAL_MASK_DAY) == INTERVAL_MASK_DAY:\n            return \"Day\"\n        elif (type_modifier & INTERVAL_MASK_HOUR2SEC) == INTERVAL_MASK_HOUR2SEC:\n            return \"Hour to Second\"\n        elif (type_modifier & INTERVAL_MASK_HOUR2MIN) == INTERVAL_MASK_HOUR2MIN:\n            return \"Hour to Minute\"\n        elif (type_modifier & INTERVAL_MASK_HOUR) == INTERVAL_MASK_HOUR:\n            return \"Hour\"\n        elif (type_modifier & INTERVAL_MASK_MIN2SEC) == INTERVAL_MASK_MIN2SEC:\n            return \"Minute to Second\"\n        elif (type_modifier & INTERVAL_MASK_MINUTE) == INTERVAL_MASK_MINUTE:\n            return \"Minute\"\n        elif (type_modifier & INTERVAL_MASK_SECOND) == INTERVAL_MASK_SECOND:\n            return \"Second\"\n        else:\n            return \"Day to Second\"", "response": "Extracts an interval s range from the bits set in its type_modifier"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the leading precision for an interval.", "response": "def getIntervalLeadingPrecision(data_type_oid, type_modifier):\n    \"\"\"\n    Returns the leading precision for an interval, which is the largest number\n    of digits that can fit in the leading field of the interval.\n\n    All Year/Month intervals are defined in terms of months, even if the\n    type_modifier forbids months to be specified (i.e. INTERVAL YEAR).\n    Similarly, all Day/Time intervals are defined as a number of microseconds.\n    Because of this, interval types with shorter ranges will have a larger\n    leading precision.\n\n    For example, an INTERVAL DAY's leading precision is\n    ((2^63)-1)/MICROSECS_PER_DAY, while an INTERVAL HOUR's leading precision\n    is ((2^63)-1)/MICROSECS_PER_HOUR\n    \"\"\"\n\n    interval_range = getIntervalRange(data_type_oid, type_modifier)\n    if interval_range in (\"Year\", \"Year to Month\"):\n        return 18\n    elif interval_range == \"Month\":\n        return 19\n    elif interval_range in (\"Day\", \"Day to Hour\", \"Day to Minute\", \"Day to Second\"):\n        return 9\n    elif interval_range in (\"Hour\", \"Hour to Minute\", \"Hour to Second\"):\n        return 10\n    elif interval_range in (\"Minute\", \"Minute to Second\"):\n        return 12\n    elif interval_range == \"Second\":\n        return 13\n    else:\n        raise ValueError(\"Invalid interval range: {}\".format(interval_range))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPrecision(data_type_oid, type_modifier):\n\n    if data_type_oid == VerticaType.NUMERIC:\n        if type_modifier == -1:\n            return 1024\n        return ((type_modifier - 4) >> 16) & 0xFFFF\n    elif data_type_oid in (VerticaType.TIME, VerticaType.TIMETZ,\n                           VerticaType.TIMESTAMP, VerticaType.TIMESTAMPTZ,\n                           VerticaType.INTERVAL, VerticaType.INTERVALYM):\n        if type_modifier == -1:\n            return 6\n        return type_modifier & 0xF\n    else:\n        return None", "response": "Returns the precision for the given Vertica type with consideration of the type modifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the display size of the given Vertica type with type modifier.", "response": "def getDisplaySize(data_type_oid, type_modifier):\n    \"\"\"\n    Returns the column display size for the given Vertica type with\n    consideration of the type modifier.\n\n    The display size of a column is the maximum number of characters needed to\n    display data in character form.\n    \"\"\"\n\n    if data_type_oid == VerticaType.BOOL:\n        # T or F\n        return 1\n    elif data_type_oid == VerticaType.INT8:\n        # a sign and 19 digits if signed or 20 digits if unsigned\n        return 20\n    elif data_type_oid == VerticaType.FLOAT8:\n        # a sign, 15 digits, a decimal point, the letter E, a sign, and 3 digits\n        return 22\n    elif data_type_oid == VerticaType.NUMERIC:\n        # a sign, precision digits, and a decimal point\n        return getPrecision(data_type_oid, type_modifier) + 2\n    elif data_type_oid == VerticaType.DATE:\n        # yyyy-mm-dd, a space, and the calendar era (BC)\n        return 13\n    elif data_type_oid == VerticaType.TIME:\n        seconds_precision = getPrecision(data_type_oid, type_modifier)\n        if seconds_precision == 0:\n            # hh:mm:ss\n            return 8\n        else:\n            # hh:mm:ss.[fff...]\n            return 9 + seconds_precision\n    elif data_type_oid == VerticaType.TIMETZ:\n        seconds_precision = getPrecision(data_type_oid, type_modifier)\n        if seconds_precision == 0:\n            # hh:mm:ss, a sign, hh:mm\n            return 14\n        else:\n            # hh:mm:ss.[fff...], a sign, hh:mm\n            return 15 + seconds_precision\n    elif data_type_oid == VerticaType.TIMESTAMP:\n        seconds_precision = getPrecision(data_type_oid, type_modifier)\n        if seconds_precision == 0:\n            # yyyy-mm-dd hh:mm:ss, a space, and the calendar era (BC)\n            return 22\n        else:\n            # yyyy-mm-dd hh:mm:ss[.fff...], a space, and the calendar era (BC)\n            return 23 + seconds_precision\n    elif data_type_oid == VerticaType.TIMESTAMPTZ:\n        seconds_precision = getPrecision(data_type_oid, type_modifier)\n        if seconds_precision == 0:\n            # yyyy-mm-dd hh:mm:ss, a sign, hh:mm, a space, and the calendar era (BC)\n            return 28\n        else:\n            # yyyy-mm-dd hh:mm:ss.[fff...], a sign, hh:mm, a space, and the calendar era (BC)\n            return 29 + seconds_precision\n    elif data_type_oid in (VerticaType.INTERVAL, VerticaType.INTERVALYM):\n        leading_precision = getIntervalLeadingPrecision(data_type_oid, type_modifier)\n        seconds_precision = getPrecision(data_type_oid, type_modifier)\n        interval_range = getIntervalRange(data_type_oid, type_modifier)\n        if interval_range in (\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\"):\n            # a sign, [range...]\n            return 1 + leading_precision\n        elif interval_range in (\"Day to Hour\", \"Year to Month\", \"Hour to Minute\"):\n            # a sign, [dd...] hh; a sign, [yy...]-mm; a sign, [hh...]:mm\n            return 1 + leading_precision + 3\n        elif interval_range == \"Day to Minute\":\n            # a sign, [dd...] hh:mm\n            return 1 + leading_precision + 6\n        elif interval_range == \"Second\":\n            if seconds_precision == 0:\n                # a sign, [ss...]\n                return 1 + leading_precision\n            else:\n                # a sign, [ss...].[fff...]\n                return 1 + leading_precision + 1 + seconds_precision\n        elif interval_range == \"Day to Second\":\n            if seconds_precision == 0:\n                # a sign, [dd...] hh:mm:ss\n                return 1 + leading_precision + 9\n            else:\n                # a sign, [dd...] hh:mm:ss.[fff...]\n                return 1 + leading_precision + 10 + seconds_precision\n        elif interval_range == \"Hour to Second\":\n            if seconds_precision == 0:\n                # a sign, [hh...]:mm:ss\n                return 1 + leading_precision + 6\n            else:\n                # a sign, [hh...]:mm:ss.[fff...]\n                return 1 + leading_precision + 7 + seconds_precision\n        elif interval_range == \"Minute to Second\":\n            if seconds_precision == 0:\n                # a sign, [mm...]:ss\n                return 1 + leading_precision + 3\n            else:\n                # a sign, [mm...]:ss.[fff...]\n                return 1 + leading_precision + 4 + seconds_precision\n    elif data_type_oid == VerticaType.UUID:\n        # aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee\n        return 36\n    elif data_type_oid in (VerticaType.CHAR,\n                           VerticaType.VARCHAR,\n                           VerticaType.BINARY,\n                           VerticaType.VARBINARY,\n                           VerticaType.UNKNOWN):\n        # the defined maximum octet length of the column\n        return MAX_STRING_LEN if type_modifier <= -1 else (type_modifier - 4)\n    elif data_type_oid in (VerticaType.LONGVARCHAR,\n                           VerticaType.LONGVARBINARY):\n        return MAX_LONG_STRING_LEN if type_modifier <= -1 else (type_modifier - 4)\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _jython_set_classpath(jars):\n    '''\n    import a jar at runtime (needed for JDBC [Class.forName])\n\n    adapted by Bastian Bowe from\n    http://stackoverflow.com/questions/3015059/jython-classpath-sys-path-and-jdbc-drivers\n    '''\n    from java.net import URL, URLClassLoader\n    from java.lang import ClassLoader\n    from java.io import File\n    m = URLClassLoader.getDeclaredMethod(\"addURL\", [URL])\n    m.accessible = 1\n    urls = [File(i).toURL() for i in jars]\n    m.invoke(ClassLoader.getSystemClassLoader(), urls)", "response": "Sets the classpath for the given jars."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting CLASSPATH from system environment variable as JPype doesn t seem to respect that variable.", "response": "def _get_classpath():\n    \"\"\"Extract CLASSPATH from system environment as JPype doesn't seem\n    to respect that variable.\n    \"\"\"\n    try:\n        orig_cp = os.environ['CLASSPATH']\n    except KeyError:\n        return []\n    expanded_cp = []\n    for i in orig_cp.split(os.path.pathsep):\n        expanded_cp.extend(_jar_glob(i))\n    return expanded_cp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(jclassname, url, driver_args=None, jars=None, libs=None):\n    if isinstance(driver_args, string_type):\n        driver_args = [ driver_args ]\n    if not driver_args:\n       driver_args = []\n    if jars:\n        if isinstance(jars, string_type):\n            jars = [ jars ]\n    else:\n        jars = []\n    if libs:\n        if isinstance(libs, string_type):\n            libs = [ libs ]\n    else:\n        libs = []\n    jconn = _jdbc_connect(jclassname, url, driver_args, jars, libs)\n    return Connection(jconn, _converters)", "response": "Open a connection to a JDBC database using a JDBC driver and return a Connection instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_converters(types_map):\n    global _converters\n    _converters = {}\n    for i in _DEFAULT_CONVERTERS:\n        const_val = types_map[i]\n        _converters[const_val] = _DEFAULT_CONVERTERS[i]", "response": "Prepares the converters for conversion of java types to python\n    objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _close_last(self):\n        if self._rs:\n            self._rs.close()\n        self._rs = None\n        if self._prep:\n            self._prep.close()\n        self._prep = None\n        self._meta = None\n        self._description = None", "response": "Close the resultset and reset collected meta data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nactivate the thread local entry for the given span.", "response": "def activate(self, span, finish_on_close):\n        \"\"\"\n        Make a :class:`~opentracing.Span` instance active.\n\n        :param span: the :class:`~opentracing.Span` that should become active.\n        :param finish_on_close: whether *span* should automatically be\n            finished when :meth:`Scope.close()` is called.\n\n        :return: a :class:`~opentracing.Scope` instance to control the end\n            of the active period for the :class:`~opentracing.Span`.\n            It is a programming error to neglect to call :meth:`Scope.close()`\n            on the returned instance.\n        \"\"\"\n        scope = _ThreadLocalScope(self, span, finish_on_close)\n        setattr(self._tls_scope, 'active', scope)\n        return scope"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_global_tracer(value):\n    if value is None:\n        raise ValueError('The global Tracer tracer cannot be None')\n\n    global tracer, is_tracer_registered\n    tracer = value\n    is_tracer_registered = True", "response": "Sets the global tracer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs the current state of the user.", "response": "def log(self, **kwargs):\n        \"\"\"DEPRECATED\"\"\"\n        key_values = {}\n        if logs.EVENT in kwargs:\n            key_values[logs.EVENT] = kwargs[logs.EVENT]\n        if 'payload' in kwargs:\n            key_values['payload'] = kwargs['payload']\n        timestamp = None\n        if 'timestamp' in kwargs:\n            timestamp = kwargs['timestamp']\n        return self.log_kv(key_values, timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef activate(self, span, finish_on_close):\n\n        context = self._get_context()\n        if context is None:\n            return super(TornadoScopeManager, self).activate(span,\n                                                             finish_on_close)\n\n        scope = _TornadoScope(self, span, finish_on_close)\n        context.active = scope\n\n        return scope", "response": "Activate a new span and return a new scope."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the currently active scope.", "response": "def active(self):\n        \"\"\"\n        Return the currently active :class:`~opentracing.Scope` which\n        can be used to access the currently active\n        :attr:`Scope.span`.\n\n        :return: the :class:`~opentracing.Scope` that is active,\n            or ``None`` if not available.\n        \"\"\"\n\n        context = self._get_context()\n        if not context:\n            return super(TornadoScopeManager, self).active\n\n        return context.active"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new scope that starts and activated a new active span.", "response": "def start_active_span(self,\n                          operation_name,\n                          child_of=None,\n                          references=None,\n                          tags=None,\n                          start_time=None,\n                          ignore_active_span=False,\n                          finish_on_close=True):\n        \"\"\"Returns a newly started and activated :class:`Scope`.\n\n        The returned :class:`Scope` supports with-statement contexts. For\n        example::\n\n            with tracer.start_active_span('...') as scope:\n                scope.span.set_tag('http.method', 'GET')\n                do_some_work()\n            # Span.finish() is called as part of scope deactivation through\n            # the with statement.\n\n        It's also possible to not finish the :class:`Span` when the\n        :class:`Scope` context expires::\n\n            with tracer.start_active_span('...',\n                                          finish_on_close=False) as scope:\n                scope.span.set_tag('http.method', 'GET')\n                do_some_work()\n            # Span.finish() is not called as part of Scope deactivation as\n            # `finish_on_close` is `False`.\n\n        :param operation_name: name of the operation represented by the new\n            :class:`Span` from the perspective of the current service.\n        :type operation_name: str\n\n        :param child_of: (optional) a :class:`Span` or :class:`SpanContext`\n            instance representing the parent in a REFERENCE_CHILD_OF reference.\n            If specified, the `references` parameter must be omitted.\n        :type child_of: Span or SpanContext\n\n        :param references: (optional) references that identify one or more\n            parent :class:`SpanContext`\\ s. (See the Reference documentation\n            for detail).\n        :type references: :obj:`list` of :class:`Reference`\n\n        :param tags: an optional dictionary of :class:`Span` tags. The caller\n            gives up ownership of that dictionary, because the :class:`Tracer`\n            may use it as-is to avoid extra data copying.\n        :type tags: dict\n\n        :param start_time: an explicit :class:`Span` start time as a unix\n            timestamp per :meth:`time.time()`.\n        :type start_time: float\n\n        :param ignore_active_span: (optional) an explicit flag that ignores\n            the current active :class:`Scope` and creates a root :class:`Span`.\n        :type ignore_active_span: bool\n\n        :param finish_on_close: whether :class:`Span` should automatically be\n            finished when :meth:`Scope.close()` is called.\n        :type finish_on_close: bool\n\n        :rtype: Scope\n        :return: a :class:`Scope`, already registered via the\n            :class:`ScopeManager`.\n        \"\"\"\n        return self._noop_scope"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting and returns a new root or child span.", "response": "def start_span(self,\n                   operation_name=None,\n                   child_of=None,\n                   references=None,\n                   tags=None,\n                   start_time=None,\n                   ignore_active_span=False):\n        \"\"\"Starts and returns a new :class:`Span` representing a unit of work.\n\n\n        Starting a root :class:`Span` (a :class:`Span` with no causal\n        references)::\n\n            tracer.start_span('...')\n\n\n        Starting a child :class:`Span` (see also :meth:`start_child_span()`)::\n\n            tracer.start_span(\n                '...',\n                child_of=parent_span)\n\n\n        Starting a child :class:`Span` in a more verbose way::\n\n            tracer.start_span(\n                '...',\n                references=[opentracing.child_of(parent_span)])\n\n\n        :param operation_name: name of the operation represented by the new\n            :class:`Span` from the perspective of the current service.\n        :type operation_name: str\n\n        :param child_of: (optional) a :class:`Span` or :class:`SpanContext`\n            representing the parent in a REFERENCE_CHILD_OF reference.  If\n            specified, the `references` parameter must be omitted.\n        :type child_of: Span or SpanContext\n\n        :param references: (optional) references that identify one or more\n            parent :class:`SpanContext`\\ s. (See the Reference documentation\n            for detail).\n        :type references: :obj:`list` of :class:`Reference`\n\n        :param tags: an optional dictionary of :class:`Span` tags. The caller\n            gives up ownership of that dictionary, because the :class:`Tracer`\n            may use it as-is to avoid extra data copying.\n        :type tags: dict\n\n        :param start_time: an explicit Span start time as a unix timestamp per\n            :meth:`time.time()`\n        :type start_time: float\n\n        :param ignore_active_span: an explicit flag that ignores the current\n            active :class:`Scope` and creates a root :class:`Span`.\n        :type ignore_active_span: bool\n\n        :rtype: Span\n        :return: an already-started :class:`Span` instance.\n        \"\"\"\n        return self._noop_span"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inject(self, span_context, format, carrier):\n        if format in Tracer._supported_formats:\n            return\n        raise UnsupportedFormatException(format)", "response": "Injects span_context into carrier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(self, format, carrier):\n        if format in Tracer._supported_formats:\n            return self._noop_span_context\n        raise UnsupportedFormatException(format)", "response": "Extracts a SpanContext instance from a given format and carrier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef activate(self, span, finish_on_close):\n\n        task = self._get_task()\n        if not task:\n            return super(AsyncioScopeManager, self).activate(span,\n                                                             finish_on_close)\n\n        scope = _AsyncioScope(self, span, finish_on_close)\n        self._set_task_scope(scope, task)\n\n        return scope", "response": "Activate the current thread - local cache for the given span."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the currently active scope.", "response": "def active(self):\n        \"\"\"\n        Return the currently active :class:`~opentracing.Scope` which\n        can be used to access the currently active\n        :attr:`Scope.span`.\n\n        :return: the :class:`~opentracing.Scope` that is active,\n            or ``None`` if not available.\n        \"\"\"\n\n        task = self._get_task()\n        if not task:\n            return super(AsyncioScopeManager, self).active\n\n        return self._get_task_scope(task)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nactivates the current active period.", "response": "def activate(self, span, finish_on_close):\n        \"\"\"\n        Make a :class:`~opentracing.Span` instance active.\n\n        :param span: the :class:`~opentracing.Span` that should become active.\n        :param finish_on_close: whether *span* should automatically be\n            finished when :meth:`Scope.close()` is called.\n\n        :return: a :class:`~opentracing.Scope` instance to control the end\n            of the active period for the :class:`~opentracing.Span`.\n            It is a programming error to neglect to call :meth:`Scope.close()`\n            on the returned instance.\n        \"\"\"\n\n        scope = _GeventScope(self, span, finish_on_close)\n        self._set_greenlet_scope(scope)\n\n        return scope"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef SolicitarCTGInicial(self, numero_carta_de_porte, codigo_especie,\n        cuit_canjeador, cuit_destino, cuit_destinatario, codigo_localidad_origen,\n        codigo_localidad_destino, codigo_cosecha, peso_neto_carga, \n        cant_horas=None, patente_vehiculo=None, cuit_transportista=None, \n        km_a_recorrer=None, remitente_comercial_como_canjeador=None, \n        cuit_corredor=None, remitente_comercial_como_productor=None, \n        turno=None,\n        **kwargs):\n        \"Solicitar CTG Desde el Inicio\"\n        # ajusto par\u00e1metros seg\u00fan validaciones de AFIP:\n        if not cuit_canjeador or int(cuit_canjeador) == 0:\n            cuit_canjeador = None         # nulo\n        if not cuit_corredor or int(cuit_corredor) == 0:\n            cuit_corredor = None         # nulo\n        if not remitente_comercial_como_canjeador:\n            remitente_comercial_como_canjeador = None\n        if not remitente_comercial_como_productor:\n            remitente_comercial_como_productor = None\n        if turno == '':\n            turno  = None                # nulo\n\n        ret = self.client.solicitarCTGInicial(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                         datosSolicitarCTGInicial=dict(\n                            cartaPorte=numero_carta_de_porte, \n                            codigoEspecie=codigo_especie,\n                            cuitCanjeador=cuit_canjeador or None, \n                            remitenteComercialComoCanjeador=remitente_comercial_como_canjeador,\n                            cuitDestino=cuit_destino, \n                            cuitDestinatario=cuit_destinatario, \n                            codigoLocalidadOrigen=codigo_localidad_origen,\n                            codigoLocalidadDestino=codigo_localidad_destino, \n                            codigoCosecha=codigo_cosecha, \n                            pesoNeto=peso_neto_carga, \n                            cuitTransportista=cuit_transportista,\n                            cantHoras=cant_horas,\n                            patente=patente_vehiculo, \n                            kmARecorrer=km_a_recorrer,\n                            cuitCorredor=cuit_corredor,\n                            remitenteComercialcomoProductor=remitente_comercial_como_productor,\n                            turno=turno,\n                            )))['response']\n        self.__analizar_errores(ret)\n        self.Observaciones = ret['observacion']\n        datos = ret.get('datosSolicitarCTGResponse')\n        if datos:\n            self.CartaPorte = str(datos['cartaPorte'])\n            datos_ctg = datos.get('datosSolicitarCTG')\n            if datos_ctg:\n                self.NumeroCTG = str(datos_ctg['ctg'])\n                self.FechaHora = str(datos_ctg['fechaEmision'])\n                self.VigenciaDesde = str(datos_ctg['fechaVigenciaDesde'])\n                self.VigenciaHasta = str(datos_ctg['fechaVigenciaHasta'])\n                self.TarifaReferencia = str(datos_ctg.get('tarifaReferencia'))\n            self.__analizar_controles(datos)\n        return self.NumeroCTG or 0", "response": "Solicitar CTG Desde el Inicio."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ConfirmarDefinitivo(self, numero_carta_de_porte, numero_ctg, \n                            establecimiento=None, codigo_cosecha=None, peso_neto_carga=None, \n                            **kwargs):\n        \"Confirma arribo definitivo CTG\"\n        ret = self.client.confirmarDefinitivo(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                        datosConfirmarDefinitivo=dict(\n                            cartaPorte=numero_carta_de_porte, \n                            ctg=numero_ctg,\n                            establecimiento=establecimiento,\n                            codigoCosecha=codigo_cosecha,\n                            pesoNeto=peso_neto_carga,\n                            )))['response']\n        self.__analizar_errores(ret)\n        datos = ret.get('datosResponse')\n        if datos:\n            self.CartaPorte = str(datos['cartaPorte'])\n            self.NumeroCTG = str(datos['ctg'])\n            self.FechaHora = str(datos['fechaHora'])\n            self.CodigoTransaccion = str(datos.get('codigoOperacion', \"\"))\n            self.Observaciones = \"\"\n        return self.CodigoTransaccion", "response": "Confirmar arribo definitivo CTG"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarCTGRechazados(self):\n        \"Consulta de CTGs Otorgados, CTGs Rechazados y CTGs Confirmados\"\n        ret = self.client.consultarCTGRechazados(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                            ))['response']\n        self.__analizar_errores(ret)\n        datos = ret.get('arrayConsultarCTGRechazados')\n        if datos:\n            self.DatosCTG = datos\n            self.LeerDatosCTG(pop=False)\n            return True\n        else:\n            self.DatosCTG = []\n        return False", "response": "Consulta de CTGs Otorgados CTGs Rechazados y CTGs Confirmados"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconsults de CTGs activos por patente", "response": "def ConsultarCTGActivosPorPatente(self, patente=\"ZZZ999\"):\n        \"Consulta de CTGs activos por patente\"\n        ret = self.client.consultarCTGActivosPorPatente(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                        patente=patente,\n                            ))['response']\n        self.__analizar_errores(ret)\n        datos = ret.get('arrayConsultarCTGActivosPorPatenteResponse')\n        if datos:\n            self.DatosCTG = datos\n            self.LeerDatosCTG(pop=False)\n            return True\n        else:\n            self.DatosCTG = []\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconsults de CTGs Otorgados CTGs Rechazados y CTGs Confirmados", "response": "def CTGsPendientesResolucion(self):\n        \"Consulta de CTGs Otorgados, CTGs Rechazados y CTGs Confirmados\"\n        ret = self.client.CTGsPendientesResolucion(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                            ))['response']\n        self.__analizar_errores(ret)\n        if ret:\n            self.DatosCTG = ret\n            return True\n        else:\n            self.DatosCTG = {}\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef LeerDatosCTG(self, clave='', pop=True):\n        \"Recorro los datos devueltos y devuelvo el primero si existe\"\n                \n        if clave and self.DatosCTG:\n            # obtengo la lista por estado pendiente de resoluci\u00f3n (\"array\")\n            datos = self.DatosCTG[clave]\n        else:\n            # uso directamente la lista devuelta por la consulta\n            datos = self.DatosCTG\n        if datos:\n            # extraigo el primer item\n            if pop:\n                datos = datos.pop(0)\n            else:\n                datos = datos[0]\n            for det in ('datosConsultarCTG', 'detalleConsultaCTGRechazado', \n                          'detalleConsultaCTGActivo'):\n                if det in datos:\n                    datos_ctg = datos[det]\n                    break\n            else:\n                # elemento del array no encontrado:\n                return \"\"\n            self.CartaPorte = str(datos_ctg['cartaPorte'])\n            self.NumeroCTG = str(datos_ctg['ctg'])\n            self.Estado = unicode(datos_ctg.get('estado', \"\"))\n            self.ImprimeConstancia = str(datos_ctg.get('imprimeConstancia', \"\"))\n            for campo in (\"fechaRechazo\", \"fechaEmision\", \"fechaSolicitud\",\n                          \"fechaConfirmacionArribo\"):\n                if campo in datos_ctg:\n                    self.FechaHora = str(datos_ctg.get(campo))\n            self.Destino = datos_ctg.get(\"destino\", \"\")\n            self.Destinatario = datos_ctg.get(\"destinatario\", \"\")\n            self.Observaciones = datos_ctg.get(\"observaciones\", \"\")\n            self.Patente = datos_ctg.get(\"patente\")\n            self.PesoNeto = datos_ctg.get(\"pesoNeto\")\n            self.FechaVencimiento = datos_ctg.get(\"fechaVencimiento\")\n            self.UsuarioSolicitante = datos_ctg.get(\"usuarioSolicitante\")\n            self.UsuarioReal = datos_ctg.get(\"usuarioReal\")\n            self.CtcCodigo = datos_ctg.get(\"ctcCodigo\")\n            self.Turno = datos_ctg.get(\"turno\")\n            return self.NumeroCTG\n        else:\n            return \"\"", "response": "Recorro los datos devueltos y devuelvo el primero si existe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarCTGExcel(self, numero_carta_de_porte=None, numero_ctg=None, \n                     patente=None, cuit_solicitante=None, cuit_destino=None,\n                     fecha_emision_desde=None, fecha_emision_hasta=None,\n                     archivo=\"planilla.xls\"):\n        \"Operaci\u00f3n que realiza consulta de CTGs, graba una planilla xls\"\n        ret = self.client.consultarCTGExcel(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                        consultarCTGDatos=dict(\n                            cartaPorte=numero_carta_de_porte, \n                            ctg=numero_ctg,\n                            patente=patente,\n                            cuitSolicitante=cuit_solicitante,\n                            cuitDestino=cuit_destino,\n                            fechaEmisionDesde=fecha_emision_desde,\n                            fechaEmisionHasta=fecha_emision_hasta,\n                            )))['response']\n        self.__analizar_errores(ret)\n        datos = base64.b64decode(ret.get('archivo') or \"\")\n        f = open(archivo, \"wb\")\n        f.write(datos)\n        f.close()\n        return True", "response": "Operaci\u00f3n que realiza consulta de CTGs graba una planilla xls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarDetalleCTG(self, numero_ctg=None):\n        \"Operaci\u00f3n mostrar este detalle de la  solicitud de CTG seleccionada.\"\n        ret = self.client.consultarDetalleCTG(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                        ctg=numero_ctg, \n                        ))['response']\n        self.__analizar_errores(ret)\n        datos = ret.get('consultarDetalleCTGDatos')\n        if datos:\n            self.NumeroCTG = str(datos['ctg'])\n            self.CartaPorte = str(datos['cartaPorte'])\n            self.Estado = unicode(datos['estado'])\n            self.FechaHora = str(datos['fechaEmision'])\n            self.VigenciaDesde = str(datos['fechaVigenciaDesde'])\n            self.VigenciaHasta = str(datos['fechaVigenciaHasta'])\n            self.TarifaReferencia = str(datos['tarifaReferencia'])\n            self.Detalle = str(datos.get('detalle', \"\"))\n        return True", "response": "Operaci\u00f3n mostrar este detalle de la solicitud de CTG seleccionada."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ConsultarConstanciaCTGPDF(self, numero_ctg=None, \n                                        archivo=\"constancia.pdf\"):\n        \"Operaci\u00f3n Consultar Constancia de CTG en PDF\"\n        ret = self.client.consultarConstanciaCTGPDF(request=dict(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuitRepresentado': self.Cuit, },\n                        ctg=numero_ctg, \n                        ))['response']\n        self.__analizar_errores(ret)\n        datos = base64.b64decode(ret.get('archivo', \"\"))\n        f = open(archivo, \"wb\")\n        f.write(datos)\n        f.close()\n        return True", "response": "Operaci\u00f3n Consultar Constancia de CTG en PDF"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CrearLiquidacion(self, nro_orden=None, cuit_comprador=None, \n               nro_act_comprador=None, nro_ing_bruto_comprador=None,\n               cod_tipo_operacion=None,\n               es_liquidacion_propia=None, es_canje=None,\n               cod_puerto=None, des_puerto_localidad=None, cod_grano=None,\n               cuit_vendedor=None, nro_ing_bruto_vendedor=None,\n               actua_corredor=None, liquida_corredor=None, cuit_corredor=None,\n               comision_corredor=None, nro_ing_bruto_corredor=None,\n               fecha_precio_operacion=None,\n               precio_ref_tn=None, cod_grado_ref=None, cod_grado_ent=None,\n               factor_ent=None, precio_flete_tn=None, cont_proteico=None,\n               alic_iva_operacion=None, campania_ppal=None,\n               cod_localidad_procedencia=None,\n               datos_adicionales=None, pto_emision=1, cod_prov_procedencia=None, \n               peso_neto_sin_certificado=None, val_grado_ent=None,\n               cod_localidad_procedencia_sin_certificado=None,\n               cod_prov_procedencia_sin_certificado=None,\n               nro_contrato=None,\n               **kwargs\n               ):\n        \"Inicializa internamente los datos de una liquidaci\u00f3n para autorizar\"\n\n        # limpio los campos especiales (segun validaciones de AFIP)\n        if alic_iva_operacion == 0:\n            alic_iva_operacion = None   # no informar alicuota p/ monotributo\n        if val_grado_ent == 0:\n            val_grado_ent = None\n        # borrando datos corredor si no corresponden\n        if actua_corredor == \"N\":\n            cuit_corredor = None\n            comision_corredor = None\n            nro_ing_bruto_corredor = None\n        \n        # si no corresponde elimino el peso neto certificado campo opcional\n        if not peso_neto_sin_certificado or not int(peso_neto_sin_certificado):\n            peso_neto_sin_certificado = None\n        \n        if cod_puerto and int(cod_puerto) != 14:\n            des_puerto_localidad = None             # validacion 1630\n\n        # limpio los campos opcionales para no enviarlos si no corresponde:\n        if cod_grado_ref == \"\":\n            cod_grado_ref = None\n        if cod_grado_ent == \"\":\n            cod_grado_ent = None\n        if val_grado_ent == 0:\n            val_grado_ent = None\n\n        # creo el diccionario con los campos generales de la liquidaci\u00f3n:\n        self.liquidacion = dict(\n                            ptoEmision=pto_emision,\n                            nroOrden=nro_orden,\n                            cuitComprador=cuit_comprador,\n                            nroActComprador=nro_act_comprador,\n                            nroIngBrutoComprador=nro_ing_bruto_comprador,\n                            codTipoOperacion=cod_tipo_operacion,\n                            esLiquidacionPropia=es_liquidacion_propia,\n                            esCanje=es_canje,\n                            codPuerto=cod_puerto,\n                            desPuertoLocalidad=des_puerto_localidad,\n                            codGrano=cod_grano,\n                            cuitVendedor=cuit_vendedor,\n                            nroIngBrutoVendedor=nro_ing_bruto_vendedor,\n                            actuaCorredor=actua_corredor,\n                            liquidaCorredor=liquida_corredor,\n                            cuitCorredor=cuit_corredor,\n                            comisionCorredor=comision_corredor,\n                            nroIngBrutoCorredor=nro_ing_bruto_corredor,\n                            fechaPrecioOperacion=fecha_precio_operacion,\n                            precioRefTn=precio_ref_tn,\n                            codGradoRef=cod_grado_ref,\n                            codGradoEnt=cod_grado_ent,\n                            valGradoEnt=val_grado_ent,\n                            factorEnt=factor_ent,\n                            precioFleteTn=precio_flete_tn,\n                            contProteico=cont_proteico,\n                            alicIvaOperacion=alic_iva_operacion,\n                            campaniaPPal=campania_ppal,\n                            codLocalidadProcedencia=cod_localidad_procedencia,\n                            codProvProcedencia=cod_prov_procedencia,\n                            datosAdicionales=datos_adicionales,\n                            pesoNetoSinCertificado=peso_neto_sin_certificado,\n                            numeroContrato=nro_contrato or None,\n                            certificados=[],\n            )\n        # para compatibilidad hacia atras, \"copiar\" los campos si no hay cert:\n        if peso_neto_sin_certificado:\n            if cod_localidad_procedencia_sin_certificado is None:\n                cod_localidad_procedencia_sin_certificado = cod_localidad_procedencia\n            if cod_prov_procedencia_sin_certificado is None:\n                cod_prov_procedencia_sin_certificado = cod_prov_procedencia\n            self.liquidacion.update(dict(\n                codLocalidadProcedenciaSinCertificado=cod_localidad_procedencia_sin_certificado,\n                codProvProcedenciaSinCertificado=cod_prov_procedencia_sin_certificado,\n                ))\n\n        # inicializo las listas que contentran las retenciones y deducciones:\n        self.retenciones = []\n        self.deducciones = []\n        self.percepciones = []\n        self.opcionales = []        # para anticipo\n        # limpio las estructuras internas no utilizables en este caso\n        self.certificacion = None\n        return True", "response": "Inicializa internamente los datos de una liquidaci\u00f3n para autorizar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CrearLiqSecundariaBase(self, pto_emision=1, nro_orden=None, \n            nro_contrato=None,\n            cuit_comprador=None, nro_ing_bruto_comprador=None,\n            cod_puerto=None, des_puerto_localidad=None, \n            cod_grano=None, cantidad_tn=None,\n            cuit_vendedor=None, nro_act_vendedor=None,  # nuevo!!\n            nro_ing_bruto_vendedor=None,\n            actua_corredor=None, liquida_corredor=None, cuit_corredor=None,\n            nro_ing_bruto_corredor=None, \n            fecha_precio_operacion=None, precio_ref_tn=None,\n            precio_operacion=None, alic_iva_operacion=None, campania_ppal=None,\n            cod_localidad_procedencia=None, cod_prov_procedencia=None,\n            datos_adicionales=None,\n            **kwargs):\n        \"Inicializa los datos de una liquidaci\u00f3n secundaria de granos (base)\"\n \n        # creo el diccionario con los campos generales de la liquidaci\u00f3n:\n        self.liquidacion = dict(\n            ptoEmision=pto_emision, nroOrden=nro_orden,\n            numeroContrato=nro_contrato or None, cuitComprador=cuit_comprador, \n            nroIngBrutoComprador=nro_ing_bruto_comprador,\n            codPuerto=cod_puerto, desPuertoLocalidad=des_puerto_localidad,\n            codGrano=cod_grano, cantidadTn=cantidad_tn,\n            cuitVendedor=cuit_vendedor, nroActVendedor=nro_act_vendedor,\n            nroIngBrutoVendedor=nro_ing_bruto_vendedor,\n            actuaCorredor=actua_corredor, liquidaCorredor=liquida_corredor,\n            cuitCorredor=cuit_corredor or None, \n            nroIngBrutoCorredor=nro_ing_bruto_corredor or None,\n            fechaPrecioOperacion=fecha_precio_operacion,\n            precioRefTn=precio_ref_tn, precioOperacion=precio_operacion,\n            alicIvaOperacion=alic_iva_operacion or None, \n            campaniaPPal=campania_ppal,\n            codLocalidad=cod_localidad_procedencia, \n            codProvincia=cod_prov_procedencia,\n            datosAdicionales=datos_adicionales,\n            )\n        # inicializo las listas que contentran las retenciones y deducciones:\n        self.deducciones = []\n        self.percepciones = []\n        self.opcionales = []\n        self.factura_papel = None\n        return True", "response": "Inicializa los datos de una liquidaci\u00f3n secundaria de granos."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AgregarCertificado(self, tipo_certificado_deposito=None,\n                           nro_certificado_deposito=None,\n                           peso_neto=None,\n                           cod_localidad_procedencia=None,\n                           cod_prov_procedencia=None,\n                           campania=None, fecha_cierre=None, \n                           peso_neto_total_certificado=None,\n                           coe_certificado_deposito=None,       # WSLPGv1.6\n                           **kwargs):\n        \"Agrego el certificado a la liquidaci\u00f3n / certificaci\u00f3n de granos\"\n        # limpio campos opcionales:\n        if not peso_neto_total_certificado:\n            peso_neto_total_certificado = None  # 0 no es v\u00e1lido\n        # coe_certificado_deposito no es para LPG, unificar en futuras versiones\n        if tipo_certificado_deposito and int(tipo_certificado_deposito) == 332:\n            if coe_certificado_deposito and long(coe_certificado_deposito):\n                nro_certificado_deposito = coe_certificado_deposito\n                coe_certificado_deposito = None\n        cert = dict(\n                        tipoCertificadoDeposito=tipo_certificado_deposito,\n                        nroCertificadoDeposito=nro_certificado_deposito,\n                        pesoNeto=peso_neto,\n                        codLocalidadProcedencia=cod_localidad_procedencia,\n                        codProvProcedencia=cod_prov_procedencia,\n                        campania=campania,\n                        fechaCierre=fecha_cierre,\n                        pesoNetoTotalCertificado=peso_neto_total_certificado,\n                        coeCertificadoDeposito=coe_certificado_deposito,\n                        coe=coe_certificado_deposito,       # WSLPGv1.17\n                        pesoAjustado=peso_neto,             # WSLPGv1.17\n                      )\n        if self.liquidacion:\n            self.liquidacion['certificados'].append({'certificado': cert})\n        else:\n            self.certificacion['retiroTransferencia']['certificadoDeposito'] = cert\n        return True", "response": "AgregarCertificado a la liquidaci\u00f3n de granos."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AgregarPercepcion(self, codigo_concepto=None, detalle_aclaratoria=None,\n                               base_calculo=None, alicuota=None, importe_final=None,\n                               **kwargs):\n        \"Agrega la informaci\u00f3n referente a las percepciones de la liquidaci\u00f3n\"\n        # liquidaci\u00f3n secundaria (sin importe final)\n        self.percepciones.append(dict(\n                                percepcion=dict(\n                                    detalleAclaratoria=detalle_aclaratoria,\n                                    baseCalculo=base_calculo,\n                                    alicuota=alicuota,\n                                    importeFinal=importe_final,\n                                ))\n                        )            \n        return True", "response": "Agrega la informaci\u00f3n referente a las percepciones de la liquidaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AgregarOpcional(self, codigo=None, descripcion=None, **kwargs):\n        \"Agrega la informaci\u00f3n referente a los opcionales de la liq. seq.\"\n        self.opcionales.append(dict(\n                                    opcional=dict(\n                                        codigo=codigo,\n                                        descripcion=descripcion,\n                                    ))\n                            )\n        return True", "response": "Agrega la informaci\u00f3n referente a los opcionales de la liq. seq."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AutorizarLiquidacion(self):\n        \"Autorizar Liquidaci\u00f3n Primaria Electr\u00f3nica de Granos\"\n        \n        # limpio los elementos que no correspondan por estar vacios:\n        if not self.liquidacion['certificados']:\n            del self.liquidacion['certificados']\n        if not self.retenciones:\n            self.retenciones = None\n        if not self.deducciones:\n            self.deducciones = None\n        if not self.percepciones:\n            self.percepciones = None\n        else:\n            # ajustar los nombres de campos que varian entre LPG y LSG\n            for it in self.percepciones:\n                per = it['percepcion']\n                per['descripcion'] = per.pop(\"detalleAclaratoria\")\n                del per['baseCalculo']\n                del per['alicuota']\n        \n        # llamo al webservice:\n        ret = self.client.liquidacionAutorizar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        liquidacion=self.liquidacion,\n                        retenciones=self.retenciones,\n                        deducciones=self.deducciones,\n                        percepciones=self.percepciones,\n                        )\n\n        # analizo la respusta\n        ret = ret['liqReturn']\n        self.__analizar_errores(ret)\n        self.AnalizarLiquidacion(ret.get('autorizacion'), self.liquidacion)\n        return True", "response": "Autorizar Liquidaci\u00f3n Primaria Electr\u00f3nica de Granos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CancelarAnticipo(self, pto_emision=None, nro_orden=None, coe=None, \n                               pdf=None):\n        \"Cancelar Anticipo de una Liquidaci\u00f3n Primaria Electr\u00f3nica de Granos\"\n        \n        # llamo al webservice:\n        ret = self.client.lpgCancelarAnticipo(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        coe=coe,\n                        ptoEmision=pto_emision,\n                        nroOrden=nro_orden,\n                        pdf=\"S\" if pdf else \"N\",\n                        )\n\n        # analizo la respusta\n        ret = ret['liqConsReturn']\n        self.__analizar_errores(ret)\n        if 'liquidacion' in ret:\n            aut = ret['autorizacion']\n            liq = ret['liquidacion']\n            self.AnalizarLiquidacion(aut, liq)\n        # guardo el PDF si se indico archivo y vino en la respuesta:\n        if pdf and 'pdf' in ret:\n            open(pdf, \"wb\").write(ret['pdf'])\n        return True", "response": "Cancelar Anticipo de una Liquidaci\u00f3n Primaria Electr\u00f3nica de Granos"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CrearAjusteBase(self, \n               pto_emision=1, nro_orden=None,       # unificado, contrato, papel\n               coe_ajustado=None,                   # unificado\n               nro_contrato=None,                   # contrato\n               tipo_formulario=None,                # papel\n               nro_formulario=None,                 # papel\n               actividad=None,                      # contrato / papel\n               cod_grano=None,                      # contrato / papel\n               cuit_vendedor=None,                  # contrato / papel\n               cuit_comprador=None,                 # contrato / papel\n               cuit_corredor=None,                  # contrato / papel\n               nro_ing_bruto_vendedor=None,         # papel\n               nro_ing_bruto_comprador=None,        # papel\n               nro_ing_bruto_corredor=None,         # papel\n               tipo_operacion=None,                 # papel\n               precio_ref_tn=None,                  # contrato\n               cod_grado_ent=None,                  # contrato\n               val_grado_ent=None,                  # contrato\n               precio_flete_tn=None,                # contrato\n               cod_puerto=None,                     # contrato\n               des_puerto_localidad=None,           # contrato\n               cod_provincia=None,                  # unificado, contrato, papel\n               cod_localidad=None,                  # unificado, contrato, papel\n               comision_corredor=None,              # papel\n               **kwargs\n               ):\n        \"Inicializa internamente los datos de una liquidaci\u00f3n para ajustar\"\n\n        # ajusto nombre de campos para compatibilidad hacia atr\u00e1s (encabezado):\n        if 'cod_localidad_procedencia' in kwargs:\n            cod_localidad = kwargs['cod_localidad_procedencia']\n        if 'cod_provincia_procedencia' in kwargs:\n            cod_provincia = kwargs['cod_provincia_procedencia']\n        if 'nro_act_comprador' in kwargs:\n            actividad = kwargs['nro_act_comprador']\n        if 'cod_tipo_operacion' in kwargs:\n            tipo_operacion = kwargs['cod_tipo_operacion']\n            \n        # limpio los campos especiales (segun validaciones de AFIP)\n        if val_grado_ent == 0:\n            val_grado_ent = None\n        # borrando datos si no corresponden\n        if cuit_corredor and int(cuit_corredor) == 0:\n            cuit_corredor = None\n            comision_corredor = None\n            nro_ing_bruto_corredor = None\n               \n        if cod_puerto and int(cod_puerto) != 14:\n            des_puerto_localidad = None             # validacion 1630\n\n        # limpio los campos opcionales para no enviarlos si no corresponde:\n        if cod_grado_ent == \"\":\n            cod_grado_ent = None\n        if val_grado_ent == 0:\n            val_grado_ent = None\n\n        # creo el diccionario con los campos generales del ajuste base:\n        self.ajuste = { 'ajusteBase': {\n                            'ptoEmision': pto_emision,\n                            'nroOrden': nro_orden,\n                            'coeAjustado': coe_ajustado,\n                            'nroContrato': nro_contrato,\n                            'tipoFormulario': tipo_formulario,\n                            'nroFormulario': nro_formulario,\n                            'actividad': actividad,\n                            'codGrano': cod_grano,\n                            'cuitVendedor': cuit_vendedor,\n                            'cuitComprador': cuit_comprador,\n                            'cuitCorredor': cuit_corredor,\n                            'nroIngBrutoVendedor': nro_ing_bruto_vendedor,\n                            'nroIngBrutoComprador': nro_ing_bruto_comprador,\n                            'nroIngBrutoCorredor': nro_ing_bruto_corredor,\n                            'tipoOperacion': tipo_operacion,\n                            'codPuerto': cod_puerto,\n                            'desPuertoLocalidad': des_puerto_localidad,\n                            'comisionCorredor': comision_corredor,\n                            'precioRefTn': precio_ref_tn,\n                            'codGradoEnt': cod_grado_ent,\n                            'valGradoEnt': val_grado_ent,\n                            'precioFleteTn': precio_flete_tn,\n                            'codLocalidad': cod_localidad,\n                            'codProv': cod_provincia,\n                            'certificados': [],\n                            }\n                        }\n        # para compatibilidad con AgregarCertificado\n        self.liquidacion = self.ajuste['ajusteBase']\n        # inicializar temporales\n        self.__ajuste_base = None\n        self.__ajuste_debito = None\n        self.__ajuste_credito = None\n        return True", "response": "Inicializa internamente los datos de una liquidaci\u00f3n para ajustar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CrearAjusteCredito(self, \n               datos_adicionales=None,              # unificado, contrato, papel\n               concepto_importe_iva_0=None,         # unificado, contrato, papel\n               importe_ajustar_iva_0=None,          # unificado, contrato, papel\n               concepto_importe_iva_105=None,       # unificado, contrato, papel\n               importe_ajustar_iva_105=None,        # unificado, contrato, papel\n               concepto_importe_iva_21=None,        # unificado, contrato, papel\n               importe_ajustar_iva_21=None,         # unificado, contrato, papel\n               diferencia_peso_neto=None,           # unificado\n               diferencia_precio_operacion=None,    # unificado\n               cod_grado=None,                      # unificado\n               val_grado=None,                      # unificado  \n               factor=None,                         # unificado\n               diferencia_precio_flete_tn=None,     # unificado\n               **kwargs\n               ):\n        \"Inicializa internamente los datos del cr\u00e9dito del ajuste\"\n\n        self.ajuste['ajusteCredito'] = {\n            'diferenciaPesoNeto': diferencia_peso_neto,\n            'diferenciaPrecioOperacion': diferencia_precio_operacion,\n            'codGrado': cod_grado,\n            'valGrado': val_grado,\n            'factor': factor,\n            'diferenciaPrecioFleteTn': diferencia_precio_flete_tn,\n            'datosAdicionales': datos_adicionales,\n            'opcionales': None,\n            'conceptoImporteIva0': concepto_importe_iva_0,\n            'importeAjustarIva0': importe_ajustar_iva_0,\n            'conceptoImporteIva105': concepto_importe_iva_105,\n            'importeAjustarIva105': importe_ajustar_iva_105,\n            'conceptoImporteIva21': concepto_importe_iva_21,\n            'importeAjustarIva21': importe_ajustar_iva_21,\n            'deducciones': [],\n            'retenciones': [],\n            'percepciones': [],\n            'certificados': [],\n            }\n        # vinculaci\u00f3n con AgregarOpcional:\n        self.opcionales = self.ajuste['ajusteCredito']['opcionales']\n        # vinculaci\u00f3n con AgregarRetencion y AgregarDeduccion\n        self.deducciones = self.ajuste['ajusteCredito']['deducciones']\n        self.retenciones = self.ajuste['ajusteCredito']['retenciones']\n        # para LSG:\n        self.percepciones = self.ajuste['ajusteCredito']['percepciones']\n        # para compatibilidad con AgregarCertificado (WSLPGv1.17)\n        self.liquidacion = self.ajuste['ajusteCredito']\n        return True", "response": "Inicializa internamente los datos del cr\u00e9dito del ajuste"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AgregarFusion(self, nro_ing_brutos, nro_actividad, **kwargs):\n        \"Datos de comprador o vendedor seg\u00fan liquidaci\u00f3n a ajustar (fusi\u00f3n.)\"\n        self.ajuste['ajusteBase']['fusion'] = {'nroIngBrutos': nro_ing_brutos, \n                                               'nroActividad': nro_actividad,\n                                              }\n        return True", "response": "Datos de comprador o vendedor seg\u00fan liquidaci\u00f3n a ajustar ( fusi\u00f3n."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AjustarLiquidacionContrato(self):\n        \"Ajustar Liquidaci\u00f3n activas relacionadas a un contrato\"\n        \n        # limpiar arrays no enviados:\n        if not self.ajuste['ajusteBase']['certificados']:\n            del self.ajuste['ajusteBase']['certificados']\n        for k1 in ('ajusteCredito', 'ajusteDebito'):\n            for k2 in ('retenciones', 'deducciones'):\n                if not self.ajuste[k1][k2]:\n                    del self.ajuste[k1][k2]\n\n        ret = self.client.liquidacionAjustarContrato(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        **self.ajuste\n                        )\n        ret = ret['ajusteContratoReturn']\n        self.__analizar_errores(ret)\n        if 'ajusteContrato' in ret:\n            aut = ret['ajusteContrato']\n            self.AnalizarAjuste(aut)\n        return True", "response": "Ajustar Liquidaci\u00f3n activas relacionadas a un contrato"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AnalizarAjuste(self, aut, base=True):\n        \"M\u00e9todo interno para analizar la respuesta de AFIP (ajustes)\"\n\n        self.__ajuste_base = None\n        self.__ajuste_debito = None\n        self.__ajuste_credito = None\n        \n        # para compatibilidad con la generacion de PDF (completo datos)\n        if hasattr(self, \"liquidacion\") and self.liquidacion and base:\n            self.AnalizarLiquidacion(aut=None, liq=self.liquidacion)\n            \n        self.params_out['errores'] = self.errores\n            \n        # proceso la respuesta de autorizar, ajustar (y consultar):\n        if aut:\n            # en caso de anulaci\u00f3n o no ser ajuste, ahora no devuelve datos:\n            self.COE = str(aut.get('coe', \"\"))\n            self.COEAjustado = aut.get('coeAjustado')\n            self.NroContrato = aut.get('nroContrato')\n            self.Estado = aut.get('estado', \"\")\n\n            totunif = aut.get(\"totalesUnificados\") or {}\n            self.Subtotal = totunif.get('subTotalGeneral')\n            self.TotalIva105 = totunif.get('iva105')\n            self.TotalIva21 = totunif.get('iva21')\n            self.TotalRetencionesGanancias = totunif.get('retencionesGanancias')\n            self.TotalRetencionesIVA = totunif.get('retencionesIVA')\n            self.TotalOtrasRetenciones = totunif.get('importeOtrasRetenciones')\n            self.TotalNetoAPagar = totunif.get('importeNeto')\n            self.TotalIvaRg4310_18 = totunif.get('ivaRG4310_18')\n            self.TotalPagoSegunCondicion = totunif.get('pagoSCondicion')\n            \n            # actualizo par\u00e1metros de salida:\n            self.params_out['coe'] = self.COE\n            self.params_out['coe_ajustado'] = self.COEAjustado\n            self.params_out['estado'] = self.Estado\n            self.params_out['nro_orden'] = aut.get('nroOrden')\n            self.params_out['cod_tipo_operacion'] = aut.get('codTipoOperacion')\n            self.params_out['nro_contrato'] = aut.get('nroContrato')\n            self.params_out['nro_op_comercial'] = aut.get('nroOpComercial', \"\")\n\n            \n            # actualizo totales solo para ajuste base (liquidacion general) \n            if base:\n                self.params_out['subtotal'] = self.Subtotal\n                self.params_out['iva_deducciones'] = totunif.get('ivaDeducciones')\n                self.params_out['subtotal_deb_cred'] = totunif.get('subTotalDebCred')\n                self.params_out['total_base_deducciones'] = totunif.get('totalBaseDeducciones')\n                self.params_out['total_iva_10_5'] = self.TotalIva105\n                self.params_out['total_iva_21'] = self.TotalIva21\n                self.params_out['total_retenciones_ganancias'] = self.TotalRetencionesGanancias\n                self.params_out['total_retenciones_iva'] = self.TotalRetencionesIVA\n                self.params_out['total_otras_retenciones'] = self.TotalOtrasRetenciones\n                self.params_out['total_neto_a_pagar'] = self.TotalNetoAPagar\n                self.params_out['total_iva_rg_4310_18'] = self.TotalIvaRg4310_18\n                self.params_out['total_pago_segun_condicion'] = self.TotalPagoSegunCondicion\n            \n                # almaceno los datos de ajustes cr\u00e9dito y d\u00e9bito para usarlos luego\n                self.__ajuste_base = aut\n                self.__ajuste_debito = aut.get('ajusteDebito') or {}\n                self.__ajuste_credito = aut.get('ajusteCredito') or {}\n        return True", "response": "Analizar la respuesta de AFIP."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AnalizarAjusteCredito(self):\n        \"M\u00e9todo para analizar la respuesta de AFIP para Ajuste Credito\"\n        liq = {}\n        if hasattr(self, \"liquidacion\") and self.liquidacion:\n            liq.update(self.liquidacion)\n        if hasattr(self, \"ajuste\") and 'ajusteCredito' in self.ajuste:\n            liq.update(self.ajuste['ajusteCredito'])\n        if self.__ajuste_credito:\n            liq.update(self.__ajuste_credito)\n            self.AnalizarLiquidacion(aut=self.__ajuste_credito, liq=liq, ajuste=True)\n            self.AnalizarAjuste(self.__ajuste_base, base=False)  # datos generales\n        return True", "response": "M\u00e9todo para analizar la respuesta de AFIP para Ajuste Credito"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AgregarCalidad(self, analisis_muestra=None, nro_boletin=None,\n                             cod_grado=None, valor_grado=None, \n                             valor_contenido_proteico=None, valor_factor=None, \n                             **kwargs):\n        \"Agrega la informaci\u00f3n sobre la calidad, al autorizar o posteriormente\"\n        self.certificacion['primaria']['calidad'] = dict(\n                analisisMuestra=analisis_muestra,\n                nroBoletin=nro_boletin,\n                codGrado=cod_grado,                 # G1 G2 G3 F1 F2 F3\n                valorGrado=valor_grado or None,                     # opcional\n                valorContProteico=valor_contenido_proteico,\n                valorFactor=valor_factor,\n                detalleMuestraAnalisis=[],     # <!--1 or more repetitions:-->\n                )\n        return True", "response": "Agrega la informaci\u00f3n sobre la calidad al autorizar o posteriormente"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef AgregarDetalleMuestraAnalisis(self, descripcion_rubro=None, \n                                      tipo_rubro=None, porcentaje=None, \n                                      valor=None,\n                                      **kwargs):\n        \"Agrega la informaci\u00f3n referente al detalle de la certificaci\u00f3n\"\n        \n        det = dict(\n                descripcionRubro=descripcion_rubro,\n                tipoRubro=tipo_rubro,\n                porcentaje=porcentaje,\n                valor=valor,\n            )\n        self.certificacion['primaria']['calidad']['detalleMuestraAnalisis'].append(det)\n        return True", "response": "Agrega la informaci\u00f3n referente al detalle de la certificaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef AutorizarCertificacion(self):\n        \"Autoriza una Certificaci\u00f3n Primaria de Dep\u00f3sito de Granos (C1116A/RT)\"\n        \n        # limpio los elementos que no correspondan por estar vacios:\n        for k1 in ('primaria', 'retiroTransferencia'):\n            dic = self.certificacion.get(k1)\n            if not dic: continue\n            for k2 in ('ctg', 'detalleMuestraAnalisis', 'certificadoDeposito'):\n                if k2 in dic and not dic[k2]:\n                    del dic[k2]\n            \n        # llamo al webservice:\n        ret = self.client.cgAutorizar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        **self.certificacion\n                        )\n\n        # analizo la respusta\n        ret = ret['oReturn']\n        self.__analizar_errores(ret)\n        self.AnalizarAutorizarCertificadoResp(ret)\n        return True", "response": "Autorizar una Certificaci\u00f3n Primaria de Dep\u00f3sito de Granos ( C1116A / RT )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AnalizarAutorizarCertificadoResp(self, ret):\n        \"Metodo interno para extraer datos de la Respuesta de Certificaci\u00f3n\"\n        aut = ret.get('autorizacion')\n        if aut:\n            self.PtoEmision = aut['ptoEmision']\n            self.NroOrden = aut['nroOrden']\n            self.FechaCertificacion = str(aut.get('fechaCertificacion', \"\"))\n            self.COE = str(aut['coe'])\n            self.Estado = aut['estado']\n            # actualizo par\u00e1metros de salida:\n            self.params_out['coe'] = self.COE\n            self.params_out['estado'] = self.Estado\n            self.params_out['nro_orden'] = self.NroOrden\n            self.params_out['fecha_certificacion'] = self.FechaCertificacion.replace(\"-\", \"\")\n            if \"planta\" in aut:\n                p = aut.get(\"planta\")\n                self.params_out['nro_planta'] = p.get(\"nroPlanta\")\n                self.params_out['cuit_titular_planta'] = p.get(\"cuitTitularPlanta\")\n                self.params_out['razon_social_titular_planta'] = p.get(\"razonSocialTitularPlanta\")\n            # otros campos devueltos (opcionales)\n            p = aut.get('pesosResumen', {})\n            self.params_out['peso_bruto_certificado'] = p.get(\"pesoBrutoCertificado\")\n            self.params_out['peso_merma_secado'] = p.get(\"pesoMermaSecado\")\n            self.params_out['peso_merma_volatil'] = p.get(\"pesoMermaVolatil\")\n            self.params_out['peso_merma_zarandeo'] = p.get(\"pesoMermaZarandeo\")\n            self.params_out['peso_neto_certificado'] = p.get(\"pesoNetoCertificado\")\n            p = aut.get('serviciosResumen', {})\n            self.params_out['importe_iva'] = p.get(\"importeIVA\")\n            self.params_out['servicio_gastos_generales'] = p.get(\"servicioGastosGenerales\")\n            self.params_out['servicio_otros'] = p.get(\"servicioOtros\")\n            self.params_out['servicio_total'] = p.get(\"servicioTotal\")\n            self.params_out['servicio_zarandeo'] = p.get(\"servicioZarandeo\")\n        # datos devueltos seg\u00fan el tipo de certificacion (consultas):\n        cab = ret.get('cabecera')\n        if cab:\n            self.params_out['pto_emision'] = cab.get('ptoEmision')\n            self.params_out['nro_orden'] = cab.get('nroOrden')\n            self.params_out['tipo_certificado'] = cab.get('tipoCertificado')\n            self.params_out['nro_planta'] = cab.get('nroPlanta')\n            self.params_out['nro_ing_bruto_depositario'] = cab.get('nroIngBrutoDepositario')\n            self.params_out['titular_grano'] = cab.get('titularGrano')\n            self.params_out['cuit_depositante'] = cab.get('cuitDepositante')\n            self.params_out['nro_ing_bruto_depositante'] = cab.get('nroIngBrutoDepositante')\n            self.params_out['cuit_corredor'] = cab.get('cuitCorredor')\n            self.params_out['cod_grano'] = cab.get('codGrano')\n            self.params_out['campania'] = cab.get('campania')\n            self.params_out['datos_adicionales'] = cab.get('datosAdicionales')\n        pri = ret.get('primaria')\n        if pri:\n            self.params_out['nro_act_depositario'] = pri.get('nroActDepositario')\n            self.params_out['descripcion_tipo_grano'] = pri.get('descripcionTipoGrano')\n            self.params_out['monto_almacenaje'] = pri.get('montoAlmacenaje')\n            self.params_out['monto_acarreo'] = pri.get('montoAcarreo')\n            self.params_out['monto_gastos_generales'] = pri.get('montoGastosGenerales')\n            self.params_out['monto_zarandeo'] = pri.get('montoZarandeo')\n            self.params_out['porcentaje_secado_de'] = pri.get('porcentajeSecadoDe')\n            self.params_out['porcentaje_secado_a'] = pri.get('porcentajeSecadoA')\n            self.params_out['monto_secado'] = pri.get('montoSecado')\n            self.params_out['monto_por_cada_punto_exceso'] = pri.get('montoPorCadaPuntoExceso')\n            self.params_out['monto_otros'] = pri.get('montoOtros')\n            self.params_out['porcentaje_merma_volatil'] = pri.get('porcentajeMermaVolatil')\n            self.params_out['porcentaje_merma_secado'] = pri.get('porcentajeMermaSecado')\n            self.params_out['peso_neto_merma_secado'] = pri.get('pesoNetoMermaSecado')\n            self.params_out['porcentaje_merma_zarandeo'] = pri.get('pesoNetoMermaZarandeo')\n            self.params_out['peso_neto_certificado'] = pri.get('pesoNetoCertificado')\n            self.params_out['servicios_secado'] = pri.get('serviciosSecado')\n            self.params_out['servicios_zarandeo'] = pri.get('serviciosZarandeo')\n            self.params_out['servicios_otros'] = pri.get('serviciosOtros')\n            self.params_out['servicios_forma_de_pago'] = pri.get('serviciosFormaDePago')\n            # otros campos no documentados:\n            self.params_out['servicios_conceptos_no_gravados'] = pri.get(\"serviciosConceptosNoGravados\")\n            self.params_out['servicios_percepciones_iva'] = pri.get(\"serviciosPercepcionesIVA\")\n            self.params_out['servicios_otras_percepciones'] = pri.get(\"serviciosOtrasPercepciones\")            \n            # sub estructuras:\n            self.params_out['ctgs'] = []\n            self.params_out['det_muestra_analisis'] = []\n            for ctg in pri.get(\"ctg\", []):\n                self.params_out['ctgs'].append({\n                    'nro_ctg': ctg.get('nroCTG'),\n                    'nro_carta_porte': ctg.get('nroCartaDePorte'),\n                    'peso_neto_confirmado_definitivo': ctg.get('pesoNetoConfirmadoDefinitivo'),\n                    'porcentaje_secado_humedad': ctg.get('porcentajeSecadoHumedad'),\n                    'importe_secado': ctg.get('importeSecado'),\n                    'peso_neto_merma_secado': ctg.get('pesoNetoMermaSecado'),\n                    'importe_zarandeo': ctg.get('importeZarandeo'),\n                    'peso_neto_merma_zarandeo': ctg.get('pesoNetoMermaZarandeo'),\n                    'tarifa_zarandeo': ctg.get('tarifaZarandeo'),\n                    })\n            self.params_out['calidad'] = []\n            for cal in [pri.get(\"calidad\", {})]:\n                self.params_out['calidad'].append({\n                    'analisis_muestra': cal.get('analisisMuestra'),\n                    'nro_boletin': cal.get('nroBoletin'),\n                    'nro_act_depositario': cal.get('nroActDepositario'),\n                    'cod_grado': cal.get('codGrado'),\n                    'valor_grado': cal.get('valorGrado'),\n                    'valor_contenido_proteico': cal.get('valorContProteico'),\n                    'valor_factor': cal.get('valorFactor')\n                    })\n                for det in cal.get(\"detalleMuestraAnalisis\", []):\n                    self.params_out['det_muestra_analisis'].append({\n                        'descripcion_rubro': det.get('descripcionRubro'),\n                        'tipo_rubro': det.get('tipoRubro'),\n                        'porcentaje': det.get('porcentaje'),\n                        'valor': det.get('valor'),\n                        })\n        rt = ret.get('retiroTransferencia')\n        if rt:\n            self.params_out['nro_act_depositario'] = rt.get('nroActDepositario')\n            self.params_out['cuit_receptor'] = rt.get('cuitReceptor')\n            self.params_out['nro_carta_porte_a_utilizar'] = rt.get('nroCartaPorteAUtilizar')\n            # sub estructuras:\n            self.params_out['certificados'] = []\n            cert = rt.get(\"certificadoDeposito\")\n            if cert:\n                self.params_out['certificados'].append({\n                    'coe_certificado_deposito': cert.get('coeCertificadoDeposito'),\n                    'peso_neto': cert.get('pesoNeto'),\n                    })\n        pre = ret.get('preexistente')\n        if pre:\n            self.params_out['nro_planta'] = pre.get('nroPlanta')\n            self.params_out['tipo_certificado_deposito_preexistente'] = pre.get('tipoCertificadoDepositoPreexistente')\n            self.params_out['nro_certificado_deposito_preexistente'] = pre.get('nroCertificadoDepositoPreexistente')\n            self.params_out['cac_certificado_deposito_preexistente'] = pre.get('cacCertificadoDepositoPreexistente')\n            self.params_out['fecha_emision_certificado_deposito_preexistente'] = pre.get('fechaEmisionCertificadoDepositoPreexistente')\n            self.params_out['peso_neto'] = pre.get('pesoNeto')\n        \n        self.params_out['errores'] = self.errores", "response": "Metodo interno para extraer datos de la Respuesta de Certificaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef InformarCalidadCertificacion(self, coe):\n        \"Informar calidad de un certificado (C1116A/RT)\"\n        \n        # llamo al webservice:\n        ret = self.client.cgInformarCalidad(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        coe=coe,\n                        calidad=self.certificacion['primaria']['calidad'],\n                        )\n\n        # analizo la respusta\n        ret = ret['oReturn']\n        self.__analizar_errores(ret)\n        self.AnalizarAutorizarCertificadoResp(ret)\n        return True", "response": "Informar calidad de un certificado ( C1116A / RT )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConsultarLiquidacionSecundaria(self, pto_emision=None, nro_orden=None, \n                                             coe=None, pdf=None):\n        \"Consulta una liquidaci\u00f3n sequndaria por No de orden o coe\"\n        if coe:\n            ret = self.client.lsgConsultarXCoe(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        coe=coe,\n                        pdf='S' if pdf else 'N',\n                        )\n        else:\n            ret = self.client.lsgConsultarXNroOrden(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        ptoEmision=pto_emision,\n                        nroOrden=nro_orden,\n                        )\n        ret = ret['oReturn']\n        self.__analizar_errores(ret)\n        for it in ret['liquidaciones']:\n            aut = it['autorizacion']\n            if 'liquidacion' in it:\n                liq = it['liquidacion']\n            elif 'ajuste' in it:\n                liq = it['ajuste']\n            self.AnalizarLiquidacion(aut, liq)\n        # guardo el PDF si se indico archivo y vino en la respuesta:\n        if pdf and 'pdf' in ret:\n            open(pdf, \"wb\").write(ret['pdf'])\n        return True", "response": "Consulta una liquidaci\u00f3n sequndaria por No de orden o coe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarCertificacion(self, pto_emision=None, nro_orden=None, \n                                     coe=None, pdf=None):\n        \"Consulta una certificacion por No de orden o COE\"\n        if coe:\n            ret = self.client.cgConsultarXCoe(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        coe=coe,\n                        pdf='S' if pdf else 'N',\n                        )\n        else:\n            ret = self.client.cgConsultarXNroOrden(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        ptoEmision=pto_emision,\n                        nroOrden=nro_orden,\n                        )\n        ret = ret['oReturn']\n        self.__analizar_errores(ret)\n        if 'autorizacion' in ret:\n            self.AnalizarAutorizarCertificadoResp(ret)\n        # guardo el PDF si se indico archivo y vino en la respuesta:\n        if pdf and 'pdf' in ret:\n            open(pdf, \"wb\").write(ret['pdf'])\n        return True", "response": "Consulta una certificacion por No de orden o COE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconsult un ajuste de liquidaci\u00f3n por No de orden o numero de contrato", "response": "def ConsultarAjuste(self, pto_emision=None, nro_orden=None, nro_contrato=None,\n                              coe=None, pdf=None):\n        \"Consulta un ajuste de liquidaci\u00f3n por No de orden o numero de contrato\"\n        if nro_contrato:\n            ret = self.client.ajustePorContratoConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        nroContrato=nro_contrato,\n                        )\n            ret = ret['ajusteContratoReturn']\n        elif coe is None or pdf is None:\n            ret = self.client.ajusteXNroOrdenConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        ptoEmision=pto_emision,\n                        nroOrden=nro_orden,\n                        pdf='S' if pdf else 'N',\n                        )\n            ret = ret['ajusteXNroOrdenConsReturn']\n        else:\n            ret = self.client.ajusteXCoeConsultar(\n                       auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        coe=coe,\n                        pdf='S' if pdf else 'N',\n                        )\n            ret = ret['ajusteConsReturn']\n\n        self.__analizar_errores(ret)\n        if 'ajusteUnificado' in ret:\n            aut = ret['ajusteUnificado']\n            self.AnalizarAjuste(aut)\n        # guardo el PDF si se indico archivo y vino en la respuesta:\n        if pdf and 'pdf' in ret:\n            open(pdf, \"wb\").write(ret['pdf'])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConsultarUltNroOrden(self, pto_emision=1):\n        \"Consulta el \u00faltimo No de orden registrado\"\n        ret = self.client.liquidacionUltimoNroOrdenConsultar(\n                    auth={\n                        'token': self.Token, 'sign': self.Sign,\n                        'cuit': self.Cuit, },\n                    ptoEmision=pto_emision,\n                    )\n        ret = ret['liqUltNroOrdenReturn']\n        self.__analizar_errores(ret)\n        self.NroOrden = ret['nroOrden']\n        return True", "response": "Consulta el \u00faltimo No de orden registrado"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconsult el \u00faltimo No de orden registrado para LSG", "response": "def ConsultarLiquidacionSecundariaUltNroOrden(self, pto_emision=1):\n        \"Consulta el \u00faltimo No de orden registrado para LSG\"\n        ret = self.client.lsgConsultarUltimoNroOrden(\n                    auth={\n                        'token': self.Token, 'sign': self.Sign,\n                        'cuit': self.Cuit, },\n                    ptoEmision=pto_emision,\n                    )\n        ret = ret['liqUltNroOrdenReturn']\n        self.__analizar_errores(ret)\n        self.NroOrden = ret['nroOrden']\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconsult el \u00faltimo No de orden registrado para CG", "response": "def ConsultarCertificacionUltNroOrden(self, pto_emision=1):\n        \"Consulta el \u00faltimo No de orden registrado para CG\"\n        ret = self.client.cgConsultarUltimoNroOrden(\n                    auth={\n                        'token': self.Token, 'sign': self.Sign,\n                        'cuit': self.Cuit, },\n                    ptoEmision=pto_emision,\n                    )\n        ret = ret['liqUltNroOrdenReturn']\n        self.__analizar_errores(ret)\n        self.NroOrden = ret['nroOrden']\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AnularLiquidacionSecundaria(self, coe):\n        \"Anular liquidaci\u00f3n secundaria activa\"\n        ret = self.client.lsgAnular(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        coe=coe,\n                        )\n        ret = ret['anulacionReturn']\n        self.__analizar_errores(ret)\n        self.Resultado = ret['resultado']\n        return self.COE", "response": "Anular liquidaci\u00f3n secundaria activa"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConsultarCodigoGradoReferencia(self, sep=\"||\"):\n        \"Consulta de Grados seg\u00fan Grano.\"\n        ret = self.client.codigoGradoReferenciaConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['gradoRefReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('gradosRef', [])\n        if sep is None:\n            return dict([(it['codigoDescripcion']['codigo'], \n                          it['codigoDescripcion']['descripcion']) \n                           for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]", "response": "Consulta de Grados seg\u00fan Grano."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconsult de Grado y Valor seg\u00fan Grano Entregado.", "response": "def ConsultarGradoEntregadoXTipoGrano(self, cod_grano, sep=\"||\"):\n        \"Consulta de Grado y Valor seg\u00fan Grano Entregado.\"\n        ret = self.client.codigoGradoEntregadoXTipoGranoConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        codGrano=cod_grano,\n                            )['gradoEntReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('gradoEnt', [])\n        if sep is None:\n            return dict([(it['gradoEnt']['codigoDescripcion']['codigo'],\n                          it['gradoEnt']['valor'])\n                         for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s %%s %s\" % (sep, sep, sep, sep)) %\n                    (it['gradoEnt']['codigoDescripcion']['codigo'], \n                     it['gradoEnt']['codigoDescripcion']['descripcion'],\n                     it['gradoEnt']['valor'],\n                     ) \n               for it in array]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarTipoCertificadoDeposito(self, sep=\"||\"):\n        \"Consulta de tipos de Certificados de Dep\u00f3sito\"\n        ret = self.client.tipoCertificadoDepositoConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['tipoCertDepReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('tiposCertDep', [])\n        return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]", "response": "Consulta de tipos de Certificados de Dep\u00f3sito"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarTipoDeduccion(self, sep=\"||\"):\n        \"Consulta de tipos de Deducciones\"\n        ret = self.client.tipoDeduccionConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['tipoDeduccionReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('tiposDeduccion', [])\n        return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]", "response": "Consulta de tipos de Deducciones"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconsult de tipos de Retenciones.", "response": "def ConsultarTipoRetencion(self, sep=\"||\"):\n        \"Consulta de tipos de Retenciones.\"\n        ret = self.client.tipoRetencionConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['tipoRetencionReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('tiposRetencion', [])\n        return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ConsultarPuerto(self, sep=\"||\"):\n        \"Consulta de Puertos habilitados\"\n        ret = self.client.puertoConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['puertoReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('puertos', [])\n        return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]", "response": "Consulta de Puertos habilitados"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconsults de Tipos de Actividad.", "response": "def ConsultarTipoActividad(self, sep=\"||\"):\n        \"Consulta de Tipos de Actividad.\"\n        ret = self.client.tipoActividadConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['tipoActividadReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('tiposActividad', [])\n        return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ConsultarTipoActividadRepresentado(self, sep=\"||\"):\n        \"Consulta de Tipos de Actividad inscripta en el RUOCA.\"\n        try:\n            ret = self.client.tipoActividadRepresentadoConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['tipoActividadReturn']\n            self.__analizar_errores(ret)\n            array = ret.get('tiposActividad', [])\n            self.Excepcion = self.Traceback = \"\"\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]\n        except Exception:\n            ex = utils.exception_info()\n            self.Excepcion = ex['msg']\n            self.Traceback = ex['tb']\n            if sep:\n                return [\"ERROR\"]", "response": "Consulta de Tipos de Actividad inscripta en el RUOCA."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConsultarProvincias(self, sep=\"||\"):\n        \"Consulta las provincias habilitadas\"\n        ret = self.client.provinciasConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['provinciasReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('provincias', [])\n        if sep is None:\n            return dict([(int(it['codigoDescripcion']['codigo']), \n                              it['codigoDescripcion']['descripcion']) \n                         for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n               for it in array]", "response": "Consulta las provincias habilitadas"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConsultarTiposOperacion(self, sep=\"||\"):\n        \"Consulta tipo de Operaci\u00f3n por Actividad.\"\n        ops = []\n        ret = self.client.tipoActividadConsultar(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['tipoActividadReturn']\n        self.__analizar_errores(ret)\n        for it_act in ret.get('tiposActividad', []):\n\n            ret = self.client.tipoOperacionXActividadConsultar(\n                            auth={\n                                'token': self.Token, 'sign': self.Sign,\n                                'cuit': self.Cuit, },\n                            nroActLiquida=it_act['codigoDescripcion']['codigo'],\n                            )['tipoOperacionReturn']\n            self.__analizar_errores(ret)\n            array = ret.get('tiposOperacion', [])\n            if sep:\n                ops.extend([(\"%s %%s %s %%s %s %%s %s\" % (sep, sep, sep, sep)) % \n                    (it_act['codigoDescripcion']['codigo'],\n                     it['codigoDescripcion']['codigo'], \n                     it['codigoDescripcion']['descripcion']) \n                   for it in array])\n            else:\n                ops.extend([(it_act['codigoDescripcion']['codigo'],\n                             it['codigoDescripcion']['codigo'], \n                             it['codigoDescripcion']['descripcion']) \n                           for it in array])\n        return ops", "response": "Consulta tipo de Operaci\u00f3n por Actividad."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef AgregarCampoPDF(self, nombre, tipo, x1, y1, x2, y2, \n                           font=\"Arial\", size=12,\n                           bold=False, italic=False, underline=False, \n                           foreground= 0x000000, background=0xFFFFFF,\n                           align=\"L\", text=\"\", priority=0, **kwargs):\n        \"Agrego un campo a la plantilla\"\n        # convierto colores de string (en hexadecimal)\n        if isinstance(foreground, basestring): foreground = int(foreground, 16)\n        if isinstance(background, basestring): background = int(background, 16)\n        if isinstance(text, unicode): text = text.encode(\"latin1\")\n        field = {\n                'name': nombre, \n                'type': tipo, \n                'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2, \n                'font': font, 'size': size,\n                'bold': bold, 'italic': italic, 'underline': underline, \n                'foreground': foreground, 'background': background,\n                'align': align, 'text': text, 'priority': priority}\n        field.update(kwargs)\n        self.elements.append(field)\n        return True", "response": "Agrego un campo a la plantilla"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CrearPlantillaPDF(self, papel=\"A4\", orientacion=\"portrait\"):\n        \"Iniciar la creaci\u00f3n del archivo PDF\"\n        \n        # genero el renderizador con propiedades del PDF\n        t = Template(\n                 format=papel, orientation=orientacion,\n                 title=\"F 1116 B/C %s\" % (self.NroOrden),\n                 author=\"CUIT %s\" % self.Cuit,\n                 subject=\"COE %s\" % self.params_out.get('coe'),\n                 keywords=\"AFIP Liquidacion Electronica Primaria de Granos\", \n                 creator='wslpg.py %s (http://www.PyAfipWs.com.ar)' % __version__,)\n        self.template = t\n        return True", "response": "Iniciar la creaci\u00f3n del archivo PDF"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ProcesarPlantillaPDF(self, num_copias=1, lineas_max=24, qty_pos='izq', \n                                   clave=''):\n        \"Generar el PDF seg\u00fan la factura creada y plantilla cargada\"\n        try:\n            f = self.template\n            liq = self.params_out\n            # actualizo los campos seg\u00fan la clave (ajuste debitos / creditos)\n            if clave and clave in liq:\n                liq = liq.copy()\n                liq.update(liq[clave])  # unificar con AnalizarAjusteCredito/Debito\n\n            if HOMO:\n                self.AgregarDatoPDF(\"homo\", u\"HOMOLOGACI\u00d3N\")\n\n            copias = {1: 'Original', 2: 'Duplicado', 3: 'Triplicado', \n                      4: 'Cuadruplicado', 5: 'Quintuplicado'}\n                        \n            # convierto el formato de intercambio para representar los valores:        \n            fmt_encabezado = dict([(v[0], v[1:]) for v in ENCABEZADO])\n            fmt_deduccion = dict([(v[0], v[1:]) for v in DEDUCCION])\n            fmt_retencion = dict([(v[0], v[1:]) for v in RETENCION])\n            \n            def formatear(campo, valor, formato):\n                \"Convertir el valor a una cadena correctamente s/ formato ($ % ...)\"\n                if campo in formato and v is not None:\n                    fmt = formato[campo]\n                    if fmt[1] == N:\n                        if 'cuit' in campo:\n                            c = str(valor)\n                            if len(c) == 11:\n                                valor = \"%s-%s-%s\" % (c[0:2], c[2:10], c[10:])\n                            else:\n                                valor = \"\"\n                        elif 'peso' in campo:\n                            valor = \"%s Kg\" % valor\n                        elif valor is not None and valor != \"\":\n                            valor = \"%d\" % int(valor)\n                        else:\n                            valor = \"\"\n                    elif fmt[1] == I:\n                        valor = (\"%%0.%df\" % fmt[2]) % valor\n                        if 'alic' in campo or 'comision' in campo:\n                            valor = valor + \" %\"\n                        elif 'factor' in campo or 'cont' in campo or 'cant' in campo:\n                            pass\n                        else:\n                            valor = \"$ \" + valor\n                    elif 'fecha' in campo:\n                        d = valor\n                        if isinstance(d, (datetime.date, datetime.datetime)):\n                            valor = d.strftime(\"%d/%m/%Y\")\n                        else:\n                            valor = \"%s/%s/%s\" % (d[8:10], d[5:7], d[0:4])\n                return valor\n\n            def buscar_localidad_provincia(cod_prov, cod_localidad): \n                \"obtener la descripci\u00f3n de la provincia/localidad (usar cache)\"\n                cod_prov = int(cod_prov)\n                cod_localidad = str(cod_localidad)\n                provincia = datos.PROVINCIAS[cod_prov]\n                localidad = self.BuscarLocalidades(cod_prov, cod_localidad)\n                return localidad, provincia                \n\n            # divido los datos adicionales (debe haber renglones 1 al 9):\n            if liq.get('datos_adicionales') and f.has_key('datos_adicionales1'):\n                d = liq.get('datos_adicionales')\n                for i, ds in enumerate(f.split_multicell(d, 'datos_adicionales1')):\n                    liq['datos_adicionales%s' % (i + 1)] = ds\n                \n            for copia in range(1, num_copias+1):\n                \n                # completo campos y hojas\n                f.add_page()                   \n                f.set('copia', copias.get(copia, \"Adicional %s\" % copia))\n                \n                f.set('anulado', {'AC': '', '': 'SIN ESTADO',\n                                  'AN': \"ANULADO\"}.get(liq['estado'], \"ERROR\"))\n\n                try:\n                    cod_tipo_ajuste = int(liq[\"cod_tipo_ajuste\"] or '0')\n                except: \n                    cod_tipo_ajuste = None\n                f.set('tipo_ajuste', {3: u'Liquidaci\u00f3n de D\u00e9bito', \n                                      4: u'Liquidaci\u00f3n de Cr\u00e9dito',\n                                      }.get(cod_tipo_ajuste, ''))\n\n                # limpio datos del corredor si no corresponden:\n                if liq.get('actua_corredor', 'N') == 'N':\n                    if liq.get('cuit_corredor', None) == 0:\n                        del liq['cuit_corredor']\n                    \n                # establezco campos seg\u00fan tabla encabezado:\n                for k,v in liq.items():\n                    v = formatear(k, v, fmt_encabezado)\n                    if isinstance(v, (basestring, int, long, float)):\n                        f.set(k, v)\n                    elif isinstance(v, decimal.Decimal):\n                        f.set(k, str(v))\n                    elif isinstance(v, datetime.datetime):\n                        f.set(k, str(v))\n\n                import wslpg_datos as datos\n                \n                campania = int(liq.get('campania_ppal') or 0)\n                f.set(\"campania_ppal\", datos.CAMPANIAS.get(campania, campania))\n                f.set(\"tipo_operacion\", datos.TIPOS_OP.get(int(liq.get('cod_tipo_operacion') or 0), \"\"))\n                f.set(\"actividad\", datos.ACTIVIDADES.get(int(liq.get('nro_act_comprador') or 0), \"\"))\n                if 'cod_grano' in liq and liq['cod_grano']:\n                    cod_grano = int(liq['cod_grano'])\n                else:\n                    cod_grano = int(self.datos.get('cod_grano') or 0)\n                f.set(\"grano\", datos.GRANOS.get(cod_grano, \"\"))\n                cod_puerto = int(liq.get('cod_puerto', self.datos.get('cod_puerto')) or 0)\n                if cod_puerto in datos.PUERTOS:\n                    f.set(\"des_puerto_localidad\", datos.PUERTOS[cod_puerto])\n\n                cod_grado_ref = liq.get('cod_grado_ref', self.datos.get('cod_grado_ref')) or \"\"\n                if cod_grado_ref in datos.GRADOS_REF:\n                    f.set(\"des_grado_ref\", datos.GRADOS_REF[cod_grado_ref])\n                else:\n                    f.set(\"des_grado_ref\", cod_grado_ref)\n                cod_grado_ent = liq.get('cod_grado_ent', self.datos.get('cod_grado_ent'))\n                if 'val_grado_ent' in liq and int(liq.get('val_grado_ent') or 0):\n                    val_grado_ent = liq['val_grado_ent']\n                elif 'val_grado_ent' in self.datos:\n                    val_grado_ent = self.datos.get('val_grado_ent')\n                elif cod_grano in datos.GRADO_ENT_VALOR: \n                    valores = datos.GRADO_ENT_VALOR[cod_grano]\n                    if cod_grado_ent in valores:\n                        val_grado_ent = valores[cod_grado_ent]\n                    else:\n                        val_grado_ent = \"\"\n                else:\n                    val_grado_ent = \"\"\n                f.set(\"valor_grado_ent\", \"%s %s\" % (cod_grado_ent or \"\", val_grado_ent or \"\"))\n                f.set(\"cont_proteico\", liq.get('cont_proteico', self.datos.get('cont_proteico', \"\")))\n                \n                if liq.get('certificados'):\n                    # uso la procedencia del certificado de dep\u00f3sito \n                    cert = liq['certificados'][0]\n                    localidad, provincia = buscar_localidad_provincia(\n                        cert['cod_prov_procedencia'],\n                        cert['cod_localidad_procedencia'])\n                elif liq.get('cod_prov_procedencia_sin_certificado'):\n                    localidad, provincia = buscar_localidad_provincia(\n                        liq['cod_prov_procedencia_sin_certificado'], \n                        liq['cod_localidad_procedencia_sin_certificado'])\n                else:\n                    localidad, provincia = \"\", \"\"\n    \n                f.set(\"procedencia\", \"%s - %s\" % (localidad, provincia))\n                \n                # si no se especif\u00edca, uso la procedencia para el lugar\n                if not self.datos.get('lugar_y_fecha'):\n                    localidad, provincia = buscar_localidad_provincia(\n                        liq['cod_prov_procedencia'], \n                        liq['cod_localidad_procedencia'])\n                    lugar = \"%s - %s \" % (localidad, provincia)\n                    fecha = datetime.datetime.today().strftime(\"%d/%m/%Y\")\n                    f.set(\"lugar_y_fecha\", \"%s, %s\" % (fecha, lugar))\n                    if 'lugar_y_fecha' in self.datos:\n                        del self.datos['lugar_y_fecha']\n\n                if HOMO:\n                    homo = \"(pruebas)\"\n                else:\n                    homo = \"\"\n                \n                if int(liq['cod_tipo_operacion'] or 0) == 1: \n                    f.set(\"comprador.L\", \"COMPRADOR:\")\n                    f.set(\"vendedor.L\", \"VENDEDOR:\")\n                    f.set(\"formulario\", u\"Form. Electr\u00f3nico 1116 B %s\" % homo)\n                else:\n                    f.set(\"comprador.L\", \"MANDATARIO/CONSIGNATARIO:\")\n                    f.set(\"vendedor.L\", \"MANDANTE/COMITENTE:\")\n                    f.set(\"formulario\", u\"Form. Electr\u00f3nico 1116 C %s\" % homo)\n                \n                if int(liq.get(\"coe_ajustado\") or 0) or int(liq.get(\"nro_contrato\") or 0):\n                    f.set(\"formulario\", u\"Ajuste Unificado %s\" % homo)\n\n                certs = []\n                for cert in liq.get('certificados', []):\n                    certs.append(u\"%s N\u00ba %s\" % (\n                        datos.TIPO_CERT_DEP[int(cert['tipo_certificado_deposito'])],\n                        cert['nro_certificado_deposito']))\n                f.set(\"certificados_deposito\", ', '.join(certs))\n\n                for i, deduccion in enumerate(liq.get('deducciones', [])):\n                    for k, v in deduccion.items():\n                        v = formatear(k, v, fmt_deduccion)\n                        f.set(\"deducciones_%s_%02d\" % (k, i + 1), v)\n\n                for i, retencion in enumerate(liq.get('retenciones', [])):\n                    for k, v in retencion.items():\n                        v = formatear(k, v, fmt_retencion)\n                        f.set(\"retenciones_%s_%02d\" % (k, i + 1), v)\n                    if retencion['importe_certificado_retencion']:\n                        d = retencion['fecha_certificado_retencion']\n                        f.set('retenciones_cert_retencion_%02d' % (i + 1),\n                            \"%s $ %0.2f %s\" % (\n                                retencion['nro_certificado_retencion'] or '',\n                                retencion['importe_certificado_retencion'],\n                                \"%s/%s/%s\" % (d[8:10], d[5:7], d[2:4]), \n                            ))\n\n                # cargo campos adicionales ([PDF] en .ini y AgregarDatoPDF)\n                for k,v in self.datos.items():\n                    f.set(k, v)\n                \n                # Ajustes:\n                \n                if clave:\n                    f.set('subtipo_ajuste', {'ajuste_debito': u'AJUSTE D\u00c9BITO',\n                           'ajuste_credito': u'AJUSTE CR\u00c9DITO'}[clave])\n                \n                if int(liq.get('coe_ajustado') or 0):\n                    f.set(\"leyenda_coe_nro\", \"COE Ajustado:\")\n                    f.set(\"nro_contrato_o_coe_ajustado\", liq['coe_ajustado'])\n                    f.set(\"coe_relacionados.L\", \"\")\n                    f.set(\"coe_relacionados\", \"\")\n                elif liq.get('nro_contrato'):\n                    f.set(\"leyenda_coe_nro\", \"Contrato Ajustado:\")\n                    f.set(\"nro_contrato_o_coe_ajustado\", liq['nro_contrato'])\n                    ##f.set(\"coe_relacionados\", TODO)\n                    \n            return True\n        except Exception, e:\n            ex = utils.exception_info()\n            try:\n                f.set('anulado', \"%(name)s:%(lineno)s\" % ex)\n            except:\n                pass\n            self.Excepcion = ex['msg']\n            self.Traceback = ex['tb']\n            if DEBUG:\n                print self.Excepcion\n                print self.Traceback\n            return False", "response": "Generar el PDF seg\u00fan la factura creada y plantilla cargada"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AnalizarXml(self, xml=\"\"):\n        \"Analiza un mensaje XML (por defecto la respuesta)\"\n        try:\n            if not xml:\n                xml = self.XmlResponse\n            self.xml = SimpleXMLElement(xml)\n            return True\n        except Exception, e:\n            self.Excepcion = u\"%s\" % (e)\n            return False", "response": "Analiza un mensaje XML (por defecto la respuesta )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __analizar_errores(self, ret):\n        \"Comprueba y extrae errores si existen en la respuesta XML\"\n        errores = []\n        if 'errores' in ret:\n            errores.extend(ret['errores'])\n        if errores:\n            self.Errores = [\"%(codigo)s: %(descripcion)s\" % err['error'][0]\n                            for err in errores]\n            self.errores = [\n                {'codigo': err['error'][0]['codigo'],\n                 'descripcion': err['error'][0]['descripcion'].replace(\"\\n\", \"\")\n                                .replace(\"\\r\", \"\")} \n                             for err in errores]\n            self.ErrCode = ' '.join(self.Errores)\n            self.ErrMsg = '\\n'.join(self.Errores)", "response": "Analizar errores en la respuesta XML"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AgregarPrecioClase(self, clase_tabaco, precio, total_kilos=None, total_fardos=None, **kwargs):\n        \"Agrego un PrecioClase a la liq.\"\n        precioclase = dict(claseTabaco=clase_tabaco, precio=precio,\n                           totalKilos=total_kilos, totalFardos=total_fardos)\n        self.solicitud['precioClase'].append(precioclase)\n        return True", "response": "Agrego un PrecioClase a la liq."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AgregarFlete(self, descripcion, importe):\n        \"Agrega la informaci\u00f3n referente al flete de la liquidaci\u00f3n (opcional)\"\n        flete = dict(descripcion=descripcion, importe=importe)\n        self.solicitud['flete'] = flete\n        return True", "response": "Agrega la informaci\u00f3n referente al flete de la liquidaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AnalizarLiquidacion(self, liq):\n        \"M\u00e9todo interno para analizar la respuesta de AFIP\"\n        # proceso los datos b\u00e1sicos de la liquidaci\u00f3n (devuelto por consultar):\n        if liq:\n            cab = liq['cabecera']\n            self.CAE = str(cab['cae'])\n            self.FechaLiquidacion = cab['fechaLiquidacion']\n            self.NroComprobante = cab['nroComprobante']\n            tot = liq['totalesOperacion']\n            self.AlicuotaIVA = tot['alicuotaIVA']\n            self.ImporteNeto = tot['importeNeto']\n            self.ImporteIVA = tot['importeIVA']\n            self.Subtotal = tot['subtotal']\n            self.TotalRetenciones = tot['totalRetenciones']\n            self.TotalTributos = tot['totalTributos']\n            self.Total = tot['total']\n\n            # par\u00e1metros de salida:\n            self.params_out = dict(\n                tipo_cbte=liq['cabecera']['tipoComprobante'],\n                pto_vta=liq['cabecera']['puntoVenta'],\n                nro_cbte=liq['cabecera']['nroComprobante'],\n                fecha=liq['cabecera']['fechaLiquidacion'],\n                cod_deposito_acopio=liq['cabecera']['codDepositoAcopio'],\n                cae=str(liq['cabecera']['cae']),\n                domicilio_punto_venta=liq['cabecera']['domicilioPuntoVenta'],\n                domicilio_deposito_acopio=liq['cabecera']['domicilioDepositoAcopio'],\n                emisor=dict(\n                    cuit=liq['emisor']['cuit'],\n                    razon_social=liq['emisor']['razonSocial'],\n                    situacion_iva=liq['emisor']['situacionIVA'],\n                    domicilio=liq['emisor']['domicilio'],\n                    fecha_inicio_actividad=liq['emisor']['fechaInicioActividad'],\n                    ),\n                receptor=dict(\n                    cuit=liq['receptor']['cuit'],\n                    razon_social=liq['receptor']['razonSocial'],\n                    nro_fet=liq['receptor'].get('nroFET'),\n                    nro_socio=liq['receptor'].get('nroSocio'),\n                    situacion_iva=liq['receptor']['situacionIVA'],\n                    domicilio=liq['receptor']['domicilio'],\n                    iibb=liq['receptor'].get('iibb'),\n                    ),\n                control=liq['datosOperacion'].get('control'),\n                nro_interno=liq['datosOperacion'].get('nroInterno'),\n                condicion_venta=liq['datosOperacion'].get('condicionVenta'),\n                variedad_tabaco=liq['datosOperacion']['variedadTabaco'],\n                puerta=liq['datosOperacion'].get('puerta'),\n                nro_tarjeta=liq['datosOperacion'].get('nroTarjeta'),\n                horas=liq['datosOperacion'].get('horas'),\n                cod_provincia_origen_tabaco=liq['datosOperacion'].get('codProvinciaOrigenTabaco'),\n                tipo_compra=liq['datosOperacion'].get('tipoCompra'),\n                peso_total_fardos_kg=liq['detalleOperacion']['pesoTotalFardosKg'],\n                cantidad_total_fardos=liq['detalleOperacion']['cantidadTotalFardos'],\n                romaneos=[],\n                alicuota_iva=liq['totalesOperacion']['alicuotaIVA'],\n                importe_iva=liq['totalesOperacion']['importeIVA'],\n                importe_neto=liq['totalesOperacion']['importeNeto'],\n                subtotal=liq['totalesOperacion']['subtotal'],\n                total_retenciones=liq['totalesOperacion']['totalRetenciones'],\n                total_tributos=liq['totalesOperacion']['totalTributos'],\n                total=liq['totalesOperacion']['total'],\n                retenciones=[],\n                tributos=[],               \n                cae_ajustado=liq.get(\"caeAjustado\"),\n                pdf=liq.get('pdf'),\n                )\n            for romaneo in liq['detalleOperacion'].get('romaneo', []):\n                self.params_out['romaneos'].append(dict(\n                    fecha_romaneo=romaneo['fechaRomaneo'],\n                    nro_romaneo=romaneo['nroRomaneo'],\n                    detalle_clase=[dict(\n                        cantidad_fardos=det['cantidadFardos'],\n                        cod_clase=det['codClase'],\n                        importe=det['importe'],\n                        peso_fardos_kg=det['pesoFardosKg'],\n                        precio_x_kg_fardo=det['precioXKgFardo'],\n                        ) for det in romaneo['detalleClase']],\n                    ))\n            for ret in liq.get('retencion', []):\n                self.params_out['retenciones'].append(dict(\n                    retencion_codigo=ret['codigo'],\n                    retencion_importe=ret['importe'],\n                    ))\n            for trib in liq.get('tributo',[]):\n                self.params_out['tributos'].append(dict(\n                    tributo_descripcion=trib.get('descripcion', \"\"),\n                    tributo_base_imponible=trib['baseImponible'],\n                    tributo_alicuota=trib['alicuota'],\n                    tributo_codigo=trib['codigo'],\n                    tributo_importe=trib['importe'],\n                    ))\n            if DEBUG:\n                import pprint\n                pprint.pprint(self.params_out)\n        self.params_out['errores'] = self.errores", "response": "Analizar la respuesta de AFIP para analizar la liquidaci\u00f3n."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CrearAjuste(self, tipo_cbte, pto_vta, nro_cbte, fecha, \n            cod_deposito_acopio=None, tipo_ajuste=None, cuit_receptor=None, \n            iibb_emisor=None, iibb_receptor=None, fecha_inicio_actividad=None,\n            **kwargs):\n        \"Inicializa internamente los datos de una liquidaci\u00f3n para ajustar\"\n        # codDepositoAcopio, tipoAjuste, cuitReceptor obligatorio ajustar liq.\n        # WSLTVv1.3 fechaLiquidacion/fechaInicioActividad para ajuste f\u00edsico\n        # creo el diccionario con los campos generales de la liquidaci\u00f3n:\n        liq = dict(tipoComprobante=tipo_cbte, \n                   nroComprobante=nro_cbte, \n                   puntoVenta=pto_vta, \n                   fechaAjusteLiquidacion=fecha, \n                   fechaLiquidacion=fecha,\n                   fechaInicioActividad=fecha_inicio_actividad,\n                   codDepositoAcopio=cod_deposito_acopio, \n                   tipoAjuste=tipo_ajuste,\n                   cuitReceptor=cuit_receptor,\n                   iibbReceptor=iibb_receptor,\n                   iibbEmisor=iibb_emisor,\n                   comprobanteAAjustar=[],\n                   )\n        self.solicitud = dict(liquidacion=liq,\n                              precioClase=[],\n                              retencion=[],\n                              tributo=[],\n                             )\n        return True", "response": "Inicializa internamente los datos de una liquidaci\u00f3n para ajustar."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AgregarComprobanteAAjustar(self, tipo_cbte, pto_vta, nro_cbte):\n        \"Agrega comprobante a ajustar\"\n        cbte = dict(tipoComprobante=tipo_cbte, puntoVenta=pto_vta, nroComprobante=nro_cbte)\n        self.solicitud['liquidacion'][\"comprobanteAAjustar\"].append(cbte)\n        return True", "response": "Agrega comprobante a ajustar"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AjustarLiquidacion(self):\n        \"Ajustar Liquidaci\u00f3n de Tabaco Verde\"\n        \n        # renombrar la clave principal de la estructura\n        if 'liquidacion' in self.solicitud:\n            liq = self.solicitud.pop('liquidacion')\n            self.solicitud[\"liquidacionAjuste\"] = liq\n        \n        # llamar al webservice:\n        ret = self.client.ajustarLiquidacion(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud=self.solicitud,\n                        )\n        # analizo la respusta\n        ret = ret['respuesta']\n        self.__analizar_errores(ret)\n        liqs = ret.get('liquidacion', [])\n        liq = liqs[0] if liqs else None\n        self.AnalizarLiquidacion(liq)\n        return True", "response": "Ajustar Liquidaci\u00f3n de Tabaco Verde"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GenerarAjusteFisico(self):\n        \"Generar Ajuste F\u00edsico de Liquidaci\u00f3n de Tabaco Verde (WSLTVv1.3)\"\n        \n        # renombrar la clave principal de la estructura\n        if 'liquidacion' in self.solicitud:\n            liq = self.solicitud.pop('liquidacion')\n            self.solicitud = liq\n        \n        # llamar al webservice:\n        ret = self.client.generarAjusteFisico(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud=self.solicitud,\n                        )\n        # analizar el resultado:\n        ret = ret['respuesta']\n        self.__analizar_errores(ret)\n        liqs = ret.get('liquidacion', [])\n        liq = liqs[0] if liqs else None\n        self.AnalizarLiquidacion(liq)\n        return True", "response": "Generar Ajuste F\u00edsico de Liquidaci\u00f3n de Tabaco Verde ( WSLTVv1. 3 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarTributos(self, sep=\"||\"):\n        \"Retorna un listado de tributos con c\u00f3digo, descripci\u00f3n y signo.\"\n        ret = self.client.consultarTributos(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('tributo', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Retorna un listado de tributos con c\u00f3digo descripci\u00f3n y signo."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarRetencionesTabacaleras(self, sep=\"||\"):\n        \"Retorna un listado de retenciones tabacaleras con c\u00f3digo y descripci\u00f3n\"\n        ret = self.client.consultarRetencionesTabacaleras(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('retencion', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Retorna un listado de retenciones tabacaleras con c\u00f3digo y descripci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConsultarDepositosAcopio(self, sep=\"||\"):\n        \"Retorna los dep\u00f3sitos de acopio pertenencientes al contribuyente\"\n        ret = self.client.consultarDepositosAcopio(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('acopio', [])\n        if sep is None:\n            return array\n        else:\n            return [(\"%s %%s %s %%s %s %%s %s %%s %s\" % (sep, sep, sep, sep, sep)) %\n                    (it['codigo'], it['direccion'], it['localidad'], it['codigoPostal']) \n                    for it in array]", "response": "Retorna los dep\u00f3sitos de acopio pertenencientes al contribuyente"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inicializar_y_capturar_excepciones_simple(func):\n    \"Decorador para inicializar y capturar errores (versi\u00f3n b\u00e1sica indep.)\"\n    @functools.wraps(func)\n    def capturar_errores_wrapper(self, *args, **kwargs):\n        self.inicializar()\n        try:\n            return func(self, *args, **kwargs)\n        except:\n            ex = exception_info()\n            self.Excepcion = ex['name']\n            self.Traceback = ex['msg']\n            if self.LanzarExcepciones:\n                raise\n            else:\n                return False\n    return capturar_errores_wrapper", "response": "Decorador para inicializar y capturar errores ( versi\u00f3n b\u00e1sica indep."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef escribir(dic, formato, contraer_fechas=False):\n    \"Genera una cadena dado un formato y un diccionario de claves/valores\"\n    linea = \" \" * sum([fmt[1] for fmt in formato])\n    comienzo = 1\n    for fmt in formato:\n        clave, longitud, tipo = fmt[0:3]\n        try:\n            dec = (len(fmt)>3 and isinstance(fmt[3], int)) and fmt[3] or 2\n            if clave.capitalize() in dic:\n                clave = clave.capitalize()\n            s = dic.get(clave,\"\")\n            if isinstance(s, unicode):\n                s = s.encode(\"latin1\")\n            if s is None:\n                valor = \"\"\n            else:\n                valor = str(s)\n            # reemplazo saltos de linea por tabulaci{on vertical\n            valor = valor.replace(\"\\n\\r\", \"\\v\").replace(\"\\n\", \"\\v\").replace(\"\\r\", \"\\v\")\n            if tipo == N and valor and valor!=\"NULL\":\n                valor = (\"%%0%dd\" % longitud) % long(valor)\n            elif tipo == I and valor:\n                valor = (\"%%0%d.%df\" % (longitud+1, dec) % float(valor)).replace(\".\", \"\")\n            elif contraer_fechas and clave.lower().startswith(\"fec\") and longitud <= 8 and valor:\n                valor = valor.replace(\"-\", \"\")\n            else:\n                valor = (\"%%-0%ds\" % longitud) % valor\n            linea = linea[:comienzo-1] + valor + linea[comienzo-1+longitud:]\n            comienzo += longitud\n        except Exception, e:\n            warnings.warn(\"Error al escribir campo %s pos %s val '%s': %s\" % (\n                clave, comienzo, valor, str(e)))\n    return linea + \"\\n\"", "response": "Genera una cadena dado un formato y un diccionario de claves / valor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef norm(x, encoding=\"latin1\"):\n    \"Convertir acentos codificados en ISO 8859-1 u otro, a ASCII regular\"\n    if not isinstance(x, basestring):\n        x = unicode(x)\n    elif isinstance(x, str):\n        x = x.decode(encoding, 'ignore')\n    return unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore')", "response": "Convertir acentos codificados en ISO 8859 - 1 u otro a ASCII regular"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date(fmt=None,timestamp=None):\n    \"Manejo de fechas (simil PHP)\"\n    if fmt=='U': # return timestamp\n        t = datetime.datetime.now()\n        return int(time.mktime(t.timetuple()))\n    if fmt=='c': # return isoformat \n        d = datetime.datetime.fromtimestamp(timestamp)\n        return d.isoformat()\n    if fmt=='Ymd':\n        d = datetime.datetime.now()\n        return d.strftime(\"%Y%m%d\")", "response": "Manejo de fechas ( simil PHP )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef abrir_conf(config_file, debug=False):\n    \"Abrir el archivo de configuraci\u00f3n (usar primer par\u00e1metro como ruta)\"\n    # en principio, usar el nombre de archivo predeterminado\n    # si se pasa el archivo de configuraci\u00f3n por par\u00e1metro, confirmar que exista\n    # y descartar que sea una opci\u00f3n\n    if len(sys.argv)>1:\n        if os.path.splitext(sys.argv[1])[1].lower() == \".ini\":\n            config_file = sys.argv.pop(1)\n    if not os.path.exists(config_file) or not os.path.isfile(config_file):\n        warnings.warn(\"Archivo de configuracion %s invalido\" % config_file)\n\n    if debug: print \"CONFIG_FILE:\", config_file\n    \n    config = SafeConfigParser()\n    config.read(config_file)\n\n    return config", "response": "Abrir el archivo de configuraci\u00f3n."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log(self, msg):\n        \"Dejar mensaje en bitacora de depuraci\u00f3n (m\u00e9todo interno)\"\n        if not isinstance(msg, unicode):\n            msg = unicode(msg, 'utf8', 'ignore')\n        if not self.Log:\n            self.Log = StringIO()\n        self.Log.write(msg)\n        self.Log.write('\\n\\r')\n        if DEBUG:\n            warnings.warn(msg)", "response": "Dejar mensaje en bitacora de depuraci\u00f3n ( m\u00e9todo interno )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ObtenerTagXml(self, *tags):\n        \"Busca en el Xml analizado y devuelve el tag solicitado\"\n        # convierto el xml a un objeto\n        try:\n            if self.xml:\n                xml = self.xml\n                # por cada tag, lo busco segun su nombre o posici\u00f3n\n                for tag in tags:\n                    xml = xml(tag) # atajo a getitem y getattr\n                # vuelvo a convertir a string el objeto xml encontrado\n                return str(xml)\n        except Exception, e:\n            self.Excepcion = traceback.format_exception_only( sys.exc_type, sys.exc_value)[0]", "response": "Busca en el Xml analizado y devuelve el tag solicitado"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SetParametros(self, cuit, token, sign):\n        \"Establece un par\u00e1metro general\"\n        self.Token = token\n        self.Sign = sign\n        self.Cuit = cuit\n        return True", "response": "Establece un par\u00e1metro general"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetTicketAcceso(self, ta_string):\n        \"Establecer el token y sign desde un ticket de acceso XML\"\n        if ta_string:\n            ta = SimpleXMLElement(ta_string)\n            self.Token = str(ta.credentials.token)\n            self.Sign = str(ta.credentials.sign)\n            return True\n        else:\n            raise RuntimeError(\"Ticket de Acceso vacio!\")", "response": "Establecer el token y sign desde un ticket de acceso XML"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetParametro(self, clave, clave1=None, clave2=None, clave3=None, clave4=None):\n        \"Devuelve un par\u00e1metro de salida (establecido por llamada anterior)\"\n        # \u00fatil para par\u00e1metros de salida (por ej. campos de TransaccionPlainWS)\n        valor = self.params_out.get(clave)\n        # busco datos \"anidados\" (listas / diccionarios)\n        for clave in (clave1, clave2, clave3, clave4):\n            if clave is not None and valor is not None:\n                if isinstance(clave1, basestring) and clave.isdigit():\n                    clave = int(clave)\n                try:\n                    valor = valor[clave]\n                except (KeyError, IndexError):\n                    valor = None\n        if valor is not None:\n            if isinstance(valor, basestring):\n                return valor\n            else:\n                return str(valor)\n        else:\n            return \"\"", "response": "Devuelve un par\u00e1metro de salida."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __analizar_errores(self, ret):\n        \"Comprueba y extrae errores si existen en la respuesta XML\"\n        self.Errores = [err['codigoDescripcion'] for err in ret.get('arrayErrores', [])]\n        self.ErroresFormato = [err['codigoDescripcionString'] for err in ret.get('arrayErroresFormato', [])]\n        errores = self.Errores + self.ErroresFormato\n        self.ErrCode = ' '.join([\"%(codigo)s\" % err for err in errores])\n        self.ErrMsg = '\\n'.join([\"%(codigo)s: %(descripcion)s\" % err for err in errores])", "response": "Analizar errores si existen en la respuesta XML"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CrearRemito(self, tipo_comprobante, punto_emision, tipo_movimiento, categoria_emisor, cuit_titular_mercaderia, cod_dom_origen,\n                    tipo_receptor, categoria_receptor=None, cuit_receptor=None, cuit_depositario=None,\n                    cod_dom_destino=None, cod_rem_redestinar=None, cod_remito=None, estado=None,\n                    **kwargs):\n        \"Inicializa internamente los datos de un remito para autorizar\"\n        self.remito = {'tipoComprobante': tipo_comprobante, 'puntoEmision': punto_emision, 'categoriaEmisor': categoria_emisor,\n                       'cuitTitularMercaderia': cuit_titular_mercaderia, 'cuitDepositario': cuit_depositario,\n                       'tipoReceptor': tipo_receptor, 'categoriaReceptor': categoria_receptor, 'cuitReceptor': cuit_receptor,\n                       'codDomOrigen': cod_dom_origen, 'codDomDestino': cod_dom_destino, 'tipoMovimiento': tipo_movimiento, \n                       'estado': estado, 'codRemito': cod_remito,\n                       'codRemRedestinado': cod_rem_redestinar,\n                       'arrayMercaderias': [], 'arrayContingencias': [],\n                      }\n        return True", "response": "Inicializa internamente los datos de un remito para autorizar"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AgregarViaje(self, cuit_transportista=None, cuit_conductor=None, fecha_inicio_viaje=None, distancia_km=None, **kwargs):\n        \"Agrega la informaci\u00f3n referente al viaje del remito electr\u00f3nico c\u00e1rnico\"\n        self.remito['viaje'] = {'cuitTransportista': cuit_transportista, \n                                'cuitConductor': cuit_conductor,\n                                'fechaInicioViaje': fecha_inicio_viaje ,\n                                'distanciaKm': distancia_km,\n                                'vehiculo': {}\n                               }\n        return True", "response": "Agrega la informaci\u00f3n referente al viaje del remito electr\u00f3nico c\u00e1rnico"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AgregarVehiculo(self, dominio_vehiculo=None, dominio_acoplado=None, **kwargs):\n        \"Agrega la informaci\u00f3n referente al vehiculo usado en el viaje del remito electr\u00f3nico c\u00e1rnico\"\n        self.remito['viaje']['vehiculo'] = {'dominioVehiculo': dominio_vehiculo, 'dominioAcoplado': dominio_acoplado}\n        return True", "response": "Agrega la informaci\u00f3n referente al vehiculo usado en el viaje del remito electr\u00f3nico c\u00e1rnico"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AutorizarRemito(self, archivo=\"qr.png\"):\n        \"Autorizar o denegar un remito (cuando corresponde autorizacion) por parte del titular/depositario\"\n        response = self.client.autorizarRemito(\n                                authRequest={'token': self.Token, 'sign': self.Sign, 'cuitRepresentada': self.Cuit},\n                                codRemito=self.remito['codRemito'],\n                                estado=self.remito['estado'])\n        ret = response.get(\"autorizarRemitoReturn\")\n        if ret:\n            self.__analizar_errores(ret)\n            self.__analizar_observaciones(ret)\n            self.__analizar_evento(ret)\n            self.AnalizarRemito(ret, archivo)\n        return bool(self.CodRemito)", "response": "Autorizar o denegar un remito por parte del titular / depositario"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarUltimoRemitoEmitido(self, tipo_comprobante=995, punto_emision=1):\n        \"Obtener el \u00faltimo n\u00famero de remito que se emiti\u00f3 por tipo de comprobante y punto de emisi\u00f3n\"\n        response = self.client.consultarUltimoRemitoEmitido(\n                                authRequest={'token': self.Token, 'sign': self.Sign, 'cuitRepresentada': self.Cuit},\n                                tipoComprobante=tipo_comprobante,\n                                puntoEmision=punto_emision)\n        ret = response.get(\"consultarUltimoRemitoReturn\", {})\n        id_req = ret.get(\"idReq\", 0)\n        rec = ret.get(\"remito\", {})\n        self.__analizar_errores(ret)\n        self.__analizar_observaciones(ret)\n        self.__analizar_evento(ret)\n        self.AnalizarRemito(rec)\n        return id_req", "response": "Obtener el \u00faltimo n\u00famero de remito que se emiti\u00f3 por tipo de comprobante y punto de emisi\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConsultarTiposComprobante(self, sep=\"||\"):\n        \"Obtener el c\u00f3digo y descripci\u00f3n para tipo de comprobante\"\n        ret = self.client.consultarTiposComprobante(\n                            authRequest={\n                                'token': self.Token, 'sign': self.Sign,\n                                'cuitRepresentada': self.Cuit, },\n                                )['consultarTiposComprobanteReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('arrayTiposComprobante', [])\n        lista = [it['codigoDescripcion'] for it in array]\n        return [(u\"%s {codigo} %s {descripcion} %s\" % (sep, sep, sep)).format(**it) if sep else it for it in lista]", "response": "Obtener el c\u00f3digo y descripci\u00f3n para tipo de comprobante"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarTiposContingencia(self, sep=\"||\"):\n        \"Obtener el c\u00f3digo y descripci\u00f3n para cada tipo de contingencia que puede reportar\"\n        ret = self.client.consultarTiposContingencia(\n                            authRequest={\n                                'token': self.Token, 'sign': self.Sign,\n                                'cuitRepresentada': self.Cuit, },\n                                )['consultarTiposContingenciaReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('arrayTiposContingencia', [])\n        lista = [it['codigoDescripcion'] for it in array]\n        return [(u\"%s {codigo} %s {descripcion} %s\" % (sep, sep, sep)).format(**it) if sep else it for it in lista]", "response": "Obtener el c\u00f3digo y descripci\u00f3n para cada tipo de contingencia que puede reportar"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarTiposCategoriaEmisor(self, sep=\"||\"):\n        \"Obtener el c\u00f3digo y descripci\u00f3n para tipos de categor\u00edas de emisor\"\n        ret = self.client.consultarTiposCategoriaEmisor(\n                            authRequest={\n                                'token': self.Token, 'sign': self.Sign,\n                                'cuitRepresentada': self.Cuit, },\n                                )['consultarCategoriasEmisorReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('arrayCategoriasEmisor', [])\n        lista = [it['codigoDescripcionString'] for it in array]\n        return [(u\"%s {codigo} %s {descripcion} %s\" % (sep, sep, sep)).format(**it) if sep else it for it in lista]", "response": "Obtener el c\u00f3digo y descripci\u00f3n para tipos de categor\u00edas de emisor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarTiposCategoriaReceptor(self, sep=\"||\"):\n        \"Obtener el c\u00f3digo y descripci\u00f3n para cada tipos de categor\u00edas de receptor\"\n        ret = self.client.consultarTiposCategoriaReceptor(\n                            authRequest={\n                                'token': self.Token, 'sign': self.Sign,\n                                'cuitRepresentada': self.Cuit, },\n                                )['consultarCategoriasReceptorReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('arrayCategoriasReceptor', [])\n        lista = [it['codigoDescripcionString'] for it in array]\n        return [(u\"%s {codigo} %s {descripcion} %s\" % (sep, sep, sep)).format(**it) if sep else it for it in lista]", "response": "Obtener el c\u00f3digo y descripci\u00f3n para cada tipos de categor\u00edas de receptor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarTiposCarne(self, cod_grupo_carne=1, sep=\"||\"):\n        \"Obtener el c\u00f3digo y descripci\u00f3n para tipos de corte de carne\"\n        ret = self.client.consultarTiposCarne(\n                            authRequest={\n                                'token': self.Token, 'sign': self.Sign,\n                                'cuitRepresentada': self.Cuit, },\n                            codGrupoCarne=cod_grupo_carne,\n                            )['consultarTiposCarneReturn']\n        self.__analizar_errores(ret)\n        array = ret.get('arrayTiposCarne', [])\n        lista = [it['codigoDescripcionString'] for it in array]\n        return [(u\"%s {codigo} %s {descripcion} %s\" % (sep, sep, sep)).format(**it) if sep else it for it in lista]", "response": "Obtener el c\u00f3digo y descripci\u00f3n para tipos de corte de carne"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CrearLiquidacion(self, cod_operacion, fecha_cbte, fecha_op, cod_motivo,\n                         cod_localidad_procedencia, cod_provincia_procedencia, \n                         cod_localidad_destino, cod_provincia_destino,\n                         lugar_realizacion=None,\n                         fecha_recepcion=None, fecha_faena=None, \n                         datos_adicionales=None, **kwargs):\n        \"Inicializa internamente los datos de una liquidaci\u00f3n para autorizar\"\n        # creo el diccionario con los campos generales de la liquidaci\u00f3n:\n        liq = { 'fechaComprobante': fecha_cbte, 'fechaOperacion': fecha_op, \n                'lugarRealizacion': lugar_realizacion, \n                'codMotivo': cod_motivo, \n                'codLocalidadProcedencia': cod_localidad_procedencia, \n                'codProvinciaProcedencia': cod_provincia_procedencia, \n                'codLocalidadDestino': cod_localidad_destino, \n                'codProvinciaDestino': cod_provincia_destino, \n                'fechaRecepcion': fecha_recepcion, \n                'fechaFaena': fecha_faena, \n              }\n        self.solicitud = dict(codOperacion=cod_operacion,\n                              emisor={}, receptor={},\n                              datosLiquidacion=liq,\n                              itemDetalleLiquidacion=[],\n                              guia=[], dte=[],\n                              tributo=[], gasto=[],\n                              datosAdicionales=datos_adicionales, \n                             )\n        return True", "response": "Inicializa internamente los datos de una liquidaci\u00f3n para autorizar"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AgregarEmisor(self, tipo_cbte, pto_vta, nro_cbte, cod_caracter=None,\n                      fecha_inicio_act=None, iibb=None, nro_ruca=None,\n                      nro_renspa=None, cuit_autorizado=None, **kwargs):\n        \"Agrego los datos del emisor a la liq.\"\n        # cod_caracter y fecha_inicio_act no es requerido para ajustes\n        d = {'tipoComprobante': tipo_cbte, 'puntoVenta': pto_vta,\n             'nroComprobante': nro_cbte, \n             'codCaracter': cod_caracter,\n             'fechaInicioActividades': fecha_inicio_act,\n             'iibb': iibb,\n             'nroRUCA': nro_ruca,\n             'nroRenspa': nro_renspa,\n             'cuitAutorizado': cuit_autorizado}\n        self.solicitud['emisor'].update(d)\n        return True", "response": "Agrego los datos del emisor a la liq."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AgregarReceptor(self, cod_caracter, **kwargs):\n        \"Agrego los datos del receptor a la liq.\"\n        d = {'codCaracter': cod_caracter}\n        self.solicitud['receptor'].update(d)\n        return True", "response": "Agrego los datos del receptor a la liq."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AgregarOperador(self, cuit, iibb=None, nro_ruca=None, nro_renspa=None, \n                        cuit_autorizado=None, **kwargs):\n        \"Agrego los datos del operador a la liq.\"\n        d = {'cuit': cuit, \n             'iibb': iibb,\n             'nroRUCA': nro_ruca,\n             'nroRenspa': nro_renspa,\n             'cuitAutorizado': cuit_autorizado}\n        self.solicitud['receptor']['operador'] = d\n        return True", "response": "Agrego los datos del operador a la liq."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AgregarGasto(self, cod_gasto, descripcion=None, base_imponible=None,\n                     alicuota=None, importe=None, alicuota_iva=None,\n                     tipo_iva_nulo=None):\n        \"Agrega la informaci\u00f3n referente a los gastos de la liquidaci\u00f3n\"\n        # WSLSPv1.4.1: tipo_iva_nulo debe ser NG, NA, EX: Exento.\n        if alicuota_iva == 0:\n            alicuota_iva = None         # s\u00f3lo acepta [10.5, 21.0]\n        elif alicuota_iva:\n            tipo_iva_nulo = None\n        gasto = {'codGasto': cod_gasto, 'descripcion': descripcion, \n                 'baseImponible': base_imponible, 'alicuota': alicuota, \n                 'importe': importe, 'alicuotaIVA': alicuota_iva,\n                 'tipoIVANulo': tipo_iva_nulo,\n                }\n        if 'ajusteFinanciero' in self.solicitud:\n            self.solicitud['ajusteFinanciero']['gasto'].append(gasto)\n        else:\n            self.solicitud['gasto'].append(gasto)\n        return True", "response": "Agrega la informaci\u00f3n referente a los gastos de la liquidaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AgregarDTE(self, nro_dte, nro_renspa=None):\n        \"Agrega la informaci\u00f3n referente a DTE (multiples)\"\n        d = {\"nroDTE\": nro_dte, \"nroRenspa\": nro_renspa}\n        self.solicitud['dte'].append(d)\n        return True", "response": "Agrega la informaci\u00f3n referente a DTE"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AutorizarLiquidacion(self):\n        \"Generar o ajustar una liquidaci\u00f3n \u00fanica y obtener del CAE\"\n        # limpio los elementos que no correspondan por estar vacios:\n        for campo in [\"guia\", \"dte\", \"gasto\", \"tributo\"]:\n            if campo in self.solicitud and not self.solicitud[campo]:\n                del self.solicitud[campo]\n        for item in self.solicitud['itemDetalleLiquidacion']:\n            if not item.get(\"liquidacionCompraAsociada\", True):\n                del item[\"liquidacionCompraAsociada\"]\n        # llamo al webservice:\n        ret = self.client.generarLiquidacion(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud=self.solicitud,\n                        )\n        # analizo la respusta\n        ret = ret['respuesta']\n        self.__analizar_errores(ret)\n        self.AnalizarLiquidacion(ret)\n        return True", "response": "Generar o ajustar una liquidaci\u00f3n \u00fanica y obtener del CAE"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AnalizarLiquidacion(self, liq):\n        \"M\u00e9todo interno para analizar la respuesta de AFIP\"\n        # proceso los datos b\u00e1sicos de la liquidaci\u00f3n (devuelto por consultar):\n        cab = liq.get('cabecera')\n        if cab:\n            self.CAE = str(cab.get('cae', ''))\n            self.FechaVencimientoCae = str(cab.get('fechaVencimientoCae', ''))\n            self.FechaProcesoAFIP = str(cab.get('fechaProcesoAFIP', ''))\n            self.NroCodigoBarras =  cab.get('nroCodigoBarras')\n            datos = liq.get('datosLiquidacion', {})\n            self.FechaComprobante = str(datos.get('fechaComprobante', ''))\n            emisor = liq.get('emisor', {})\n            self.NroComprobante = emisor.get('nroComprobante')\n            tot = liq.get('resumenTotales', {})\n            self.ImporteBruto = tot.get('importeBruto')\n            self.ImporteTotalGastos = tot.get('importeTotalGastos')\n            self.ImporteTotalTributos = tot.get('importeTotalTributos')\n            self.ImporteTotalNeto = tot.get('importeTotalNeto')\n            self.ImporteIVASobreBruto = tot.get('importeIVASobreBruto')\n            self.ImporteIVASobreGastos = tot.get('importeIVASobreGastos')\n            receptor = liq.get('receptor', {})\n\n            # par\u00e1metros de salida:\n            self.params_out = dict(\n                tipo_cbte=emisor.get('tipoComprobante'),\n                pto_vta=emisor.get('puntoVenta'),\n                nro_cbte=emisor.get('nroComprobante'),\n                fecha=datos.get('fechaComprobante'),\n                cae=cab.get('cae'),\n                emisor=dict(\n                    razon_social=emisor.get('razonSocial'),\n                    domicilio_punto_venta=emisor.get('domicilioPuntoVenta'),\n                    ),\n                receptor=dict(\n                    nombre=receptor.get('nombre'),\n                    domicilio=receptor.get('domicilio'),\n                    ),\n                bruto=tot.get('importeBruto'),\n                iva_bruto=tot.get('importeIVASobreBruto'),\n                iva_gastos=tot.get('importeIVASobreGastos'),\n                total_neto=tot.get('importeTotalNeto'),\n                total_tributos=tot.get('importeTotalTributos'),\n                total_gastos=tot.get('importeTotalGastos'),\n                gasto=[],\n                guia=[],\n                tributo=[],\n                pdf=liq.get('pdf'),\n                )\n            for ret in liq.get('gasto', []):\n                self.params_out['gasto'].append(dict(\n                    cod_gasto=ret['codGasto'],\n                    importe=ret['importe'],\n                    ))\n            for trib in liq.get('tributo',[]):\n                self.params_out['tributo'].append(dict(\n                    descripcion=trib.get('descripcion', \"\"),\n                    base_imponible=trib.get('baseImponible'),\n                    alicuota=trib.get('alicuota'),\n                    codigo=trib['codTributo'],\n                    importe=trib['importe'],\n                    ))\n            # analizar datos del ajuste generado:\n            ajuste = liq.get('ajuste', {})\n            if ajuste:\n                self.params_out.update(dict(\n                    tipo_ajuste=ajuste['tipoAjuste'],\n                    modo_ajuste=ajuste['modoAjuste'],\n                    ))\n                ajustado = ajuste.get('comprobanteAjustado')\n                if ajustado:\n                    self.params_out.update(dict(\n                        cbte_ajuste=dict(\n                            tipo_cbte=ajustado['tipoComprobante'],\n                            pto_vta=ajustado['puntoVenta'],\n                            nro_cbte=ajustado['nroComprobante'],\n                            )\n                        ))\n            if DEBUG:\n                import pprint\n                pprint.pprint(self.params_out)\n        self.params_out['errores'] = self.errores", "response": "Analizar la respuesta de AFIP."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ConsultarUltimoComprobante(self, tipo_cbte=151, pto_vta=1):\n        \"Consulta el \u00faltimo No de Comprobante registrado\"\n        ret = self.client.consultarUltimoNroComprobantePorPtoVta(\n                    auth={\n                        'token': self.Token, 'sign': self.Sign,\n                        'cuit': self.Cuit, },\n                    solicitud={\n                        'puntoVenta': pto_vta,\n                        'tipoComprobante': tipo_cbte},\n                    )\n        ret = ret['respuesta']\n        self.__analizar_errores(ret)\n        self.NroComprobante = ret['nroComprobante']\n        return True", "response": "Consulta el \u00faltimo No de Comprobante registrado"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AgregarItemDetalleAjuste(self, nro_item_ajustar, **kwargs):\n        \"Agrega el detalle de item a un ajuste de liquidaci\u00f3n\"\n        d = {'nroItemAjustar': nro_item_ajustar, 'ajusteCompraAsociada': []}\n        self.solicitud['itemDetalleAjusteLiquidacion'].append(d)\n        return True", "response": "Agrega el detalle de item a un ajuste de liquidaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AgregarAjusteMonetario(self, precio_unitario, precio_recupero=None, \n                               **kwargs):\n        \"Agrega campos al detalle de item por un ajuste monetario\"\n        d = {'precioUnitario': precio_unitario, \n             'precioRecupero': precio_recupero,\n            }\n        item_liq = self.solicitud['itemDetalleAjusteLiquidacion'][-1]\n        item_liq['ajusteMonetario'] = d\n        return True", "response": "Agrega campos al detalle de item por un ajuste monetario"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AjustarLiquidacion(self):\n        \"Generar y ajustar una liquidaci\u00f3n para obtener del CAE\"\n        # limpio los elementos que no correspondan por estar vacios:\n        for item_liq in self.solicitud['itemDetalleAjusteLiquidacion']:\n            campo = 'ajusteCompraAsociada'\n            if campo in item_liq and not item_liq[campo]:\n                del item_liq[campo]\n        for campo in self.solicitud.get('ajusteFinanciero', {}).copy():\n            if not self.solicitud['ajusteFinanciero'][campo]:\n                del self.solicitud['ajusteFinanciero'][campo]\n        # llamo al webservice:\n        ret = self.client.generarAjuste(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud=self.solicitud,\n                        )\n        # analizo la respusta\n        ret = ret['respuesta']\n        self.__analizar_errores(ret)\n        self.AnalizarLiquidacion(ret)\n        return True", "response": "Generar y ajustar una liquidaci\u00f3n para obtener del CAE"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ConsultarLocalidades(self, cod_provincia, sep=\"||\"):\n        \"Consulta las localidades habilitadas\"\n        ret = self.client.consultarLocalidadesPorProvincia(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud={'codProvincia': cod_provincia},\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('localidad', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Consulta las localidades habilitadas"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ConsultarGastos(self, sep=\"||\"):\n        \"Retorna un listado de gastos con c\u00f3digo y descripci\u00f3n\"\n        ret = self.client.consultarGastos(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('gasto', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Retorna un listado de gastos con c\u00f3digo y descripci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ConsultarTiposLiquidacion(self, sep=\"||\"):\n        \"Retorna un listado de tipos de liquidaci\u00f3n con c\u00f3digo y descripci\u00f3n\"\n        ret = self.client.consultarTiposLiquidacion(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('tipoLiquidacion', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Retorna un listado de tipos de liquidaci\u00f3n con c\u00f3digo y descripci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ConsultarMotivos(self, sep=\"||\"):\n        \"Retorna listado de motivos existentes (c\u00f3digo, descripci\u00f3n)\"\n        ret = self.client.consultarMotivos(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('motivo', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Retorna listado de motivos existentes ( c\u00f3digo descripci\u00f3n )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConsultarRazas(self, sep=\"||\"):\n        \"Retorna listado de razas -vacunas y porcinos- (c\u00f3digo, descripci\u00f3n)\"\n        ret = self.client.consultarRazas(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        array = ret.get('raza', []) + ret.get('razaPorcina', [])\n        if sep is None:\n            return dict([(it['codigo'], it['descripcion']) for it in array])\n        else:\n            return [(\"%s %%s %s %%s %s\" % (sep, sep, sep)) %\n                    (it['codigo'], it['descripcion']) for it in array]", "response": "Retorna listado de razas - vacunas y porcinos - ( c\u00f3digo descripci\u00f3n )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Buscar(self, nro_doc, tipo_doc=80):\n        \"Devuelve True si fue encontrado y establece atributos con datos\"\n        # cuit: codigo \u00fanico de identificaci\u00f3n tributaria del contribuyente\n        #       (sin guiones)\n        self.cursor.execute(\"SELECT * FROM padron WHERE \"\n                            \" tipo_doc=? AND nro_doc=?\", [tipo_doc, nro_doc])\n        row = self.cursor.fetchone()\n        for key in [k for k, l, t, d in FORMATO]:\n            if row:\n                val = row[key]\n                if not isinstance(val, basestring):\n                    val = str(row[key])\n                setattr(self, key, val)\n            else:\n                setattr(self, key, '')\n        if self.tipo_doc == 80:\n            self.cuit = self.nro_doc\n        elif self.tipo_doc == 96:\n            self.dni = self.nro_doc\n        # determinar categor\u00eda de IVA (tentativa)\n        try:\n            cat_iva = int(self.cat_iva)\n        except ValueError:\n            cat_iva = None\n        if cat_iva:\n            pass\n        elif self.imp_iva in ('AC', 'S'):\n            self.cat_iva = 1  # RI\n        elif self.imp_iva == 'EX':\n            self.cat_iva = 4  # EX\n        elif self.monotributo:\n            self.cat_iva = 6  # MT\n        else:\n            self.cat_iva = 5  # CF\n        return True if row else False", "response": "Devuelve True si fue encontrado y establece atributos con datos"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Consultar(self, nro_doc):\n        \"Llama a la API p\u00fablica de AFIP para obtener los datos de una persona\"\n        n = 0\n        while n <= 4:\n            n += 1                          # reintentar 3 veces\n            try:\n                if not self.client:\n                    if DEBUG:\n                        warnings.warn(\"reconectando intento [%d]...\" % n)\n                    self.Conectar()\n                self.response = self.client(\"sr-padron\", \"v2\", \"persona\", str(nro_doc))\n            except Exception as e:\n                self.client = None\n                ex = exception_info()\n                self.Traceback = ex.get(\"tb\", \"\")\n                try:\n                    self.Excepcion = norm(ex.get(\"msg\", \"\").replace(\"\\n\", \"\"))\n                except:\n                    self.Excepcion = \"<no disponible>\"\n                if DEBUG:\n                    warnings.warn(\"Error %s [%d]\" % (self.Excepcion, n))\n            else:\n                break\n        else:\n            return False\n        result = json.loads(self.response)\n        if result['success']:\n            data = result['data']\n            # extraigo datos generales del contribuyente:\n            self.cuit = data[\"idPersona\"]\n            self.tipo_persona = data[\"tipoPersona\"]\n            self.tipo_doc = TIPO_CLAVE.get(data[\"tipoClave\"])\n            self.dni = data.get(\"numeroDocumento\")\n            self.estado = data.get(\"estadoClave\")\n            self.denominacion = data.get(\"nombre\")\n            # analizo el domicilio\n            domicilio = data.get(\"domicilioFiscal\")\n            if domicilio:\n                self.direccion = domicilio.get(\"direccion\", \"\")\n                self.localidad = domicilio.get(\"localidad\", \"\")  # no usado en CABA\n                self.provincia = PROVINCIAS.get(domicilio.get(\"idProvincia\"), \"\")\n                self.cod_postal = domicilio.get(\"codPostal\")\n            else:\n                self.direccion = self.localidad = self.provincia = \"\"\n                self.cod_postal = \"\"\n            # retrocompatibilidad:\n            self.domicilios = [\"%s - %s (%s) - %s\" % (\n                                    self.direccion, self.localidad, \n                                    self.cod_postal, self.provincia,) ]\n            # analizo impuestos:\n            self.impuestos = data.get(\"impuestos\", [])\n            self.actividades = data.get(\"actividades\", [])\n            if 32 in self.impuestos:\n                self.imp_iva = \"EX\"\n            elif 33 in self.impuestos:\n                self.imp_iva = \"NI\"\n            elif 34 in self.impuestos:\n                self.imp_iva = \"NA\"\n            else:\n                self.imp_iva = \"S\" if 30 in self.impuestos else \"N\"\n            mt = data.get(\"categoriasMonotributo\", {})\n            self.monotributo = \"S\" if mt else \"N\"\n            self.actividad_monotributo = \"\" # TODO: mt[0].get(\"idCategoria\")\n            self.integrante_soc = \"\"\n            self.empleador = \"S\" if 301 in self.impuestos else \"N\"\n            self.cat_iva = \"\"\n            self.data = data\n        else:\n            error = result['error']\n            self.Excepcion = error['mensaje']\n        return True", "response": "Consultar los datos de una persona"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DescargarConstancia(self, nro_doc, filename=\"constancia.pdf\"):\n        \"Llama a la API para descargar una constancia de inscripcion (PDF)\"\n        if not self.client:\n            self.Conectar()\n        self.response = self.client(\"sr-padron\", \"v1\", \"constancia\", str(nro_doc))\n        if self.response.startswith(\"{\"):\n            result = json.loads(self.response)\n            assert not result[\"success\"]\n            self.Excepcion = result['error']['mensaje']\n            return False\n        else:\n            with open(filename, \"wb\") as f:\n                f.write(self.response)\n            return True", "response": "Descargar una constancia de inscripcion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Conectar(self, cache=None, url=\"\", proxy=\"\", wrapper=\"\", cacert=None, timeout=30):\n        \"Establecer la conexi\u00f3n a los servidores de la AFIP\"\n        # llamo al constructor heredado:\n        ok = BaseWS.Conectar(self, cache, url, proxy, wrapper, cacert, timeout)\n        if False and ok:        \n            # corrijo ubicaci\u00f3n del servidor (puerto htttp 80 en el WSDL)\n            location = self.client.services['LumService']['ports']['LumEndPoint']['location']\n            if location.startswith(\"http://\"):\n                print \"Corrigiendo WSDL ...\", location,\n                location = location.replace(\"http://\", \"https://\").replace(\":80\", \":443\")\n                self.client.services['LumService']['ports']['LumEndPoint']['location'] = location\n                print location\n        return ok", "response": "Establecer la conexi\u00f3n a los servidores de la AFIP"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CrearLiquidacion(self, tipo_cbte, pto_vta, nro_cbte, fecha, periodo,\n                         iibb_adquirente=None, domicilio_sede=None,\n                         inscripcion_registro_publico=None, \n                         datos_adicionales=None, alicuota_iva=None, **kwargs):\n        \"Inicializa internamente los datos de una liquidaci\u00f3n para autorizar\"\n        # creo el diccionario con los campos generales de la liquidaci\u00f3n:\n        liq = {'tipoComprobante': tipo_cbte, 'puntoVenta': pto_vta,\n                'nroComprobante': nro_cbte, 'fechaComprobante': fecha, \n                'periodo': periodo, 'iibbAdquirente': iibb_adquirente, \n                'domicilioSede': domicilio_sede, \n                'inscripcionRegistroPublico': inscripcion_registro_publico, \n                'datosAdicionales': datos_adicionales, \n                'alicuotaIVA': alicuota_iva, \n              }\n        liq[\"condicionVenta\"] = []\n        self.solicitud = dict(liquidacion=liq,\n                              bonificacionPenalizacion=[],\n                              otroImpuesto=[],\n                              remito=[]\n                             )\n        return True", "response": "Inicializa internamente los datos de una liquidaci\u00f3n para autorizar"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AgregarTambero(self, cuit, iibb=None, **kwargs):\n        \"Agrego los datos del productor a la liq.\"\n        tambero = {'cuit': cuit, 'iibb': iibb}\n        self.solicitud['tambero'] = tambero\n        return True", "response": "Agrego los datos del productor a la liq."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AgregarUbicacionTambo(self, latitud, longitud, domicilio,\n                              cod_localidad, cod_provincia, codigo_postal,\n                              nombre_partido_depto, **kwargs):\n        \"Agrego los datos del productor a la liq.\"\n        ubic_tambo = {'latitud': latitud, \n                      'longitud': longitud,\n                      'domicilio': domicilio,\n                      'codLocalidad': cod_localidad,\n                      'codProvincia': cod_provincia,\n                      'nombrePartidoDepto': nombre_partido_depto,\n                      'codigoPostal': codigo_postal}\n        self.solicitud['tambo']['ubicacionTambo'] = ubic_tambo\n        return True", "response": "Agrego los datos del productor a la liq."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AgregarOtroImpuesto(self, tipo, base_imponible, alicuota, detalle=None):\n        \"Agrega la informaci\u00f3n referente a otros tributos de la liquidaci\u00f3n\"\n        trib = dict(tipo=tipo, baseImponible=base_imponible, alicuota=alicuota,\n                    detalle=detalle)\n        self.solicitud['otroImpuesto'].append(trib)\n        return True", "response": "Agrega la informaci\u00f3n referente a otros tributos de la liquidaci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AgregarAjuste(self, cai, tipo_cbte, pto_vta, nro_cbte, cae_a_ajustar):\n        \"Agrega comprobante a ajustar\"\n        ajuste = self.solicitud['liquidacion']['ajuste'] = {}\n        if cae_a_ajustar:\n            ajuste['caeAAjustar'] = cae_a_ajustar\n        if cai:\n            cbte = dict(cai=cai, caeAAjustar=cae_a_ajustar, \n                        tipoComprobante=tipo_cbte, puntoVenta=pto_vta, \n                        nroComprobante=nro_cbte)\n            ajuste['formularioPapel'] = cbte\n        return True", "response": "Agrega comprobante a ajustar"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ConsultarLiquidacion(self, tipo_cbte=None, pto_vta=None, nro_cbte=None,\n                                   cae=None, cuit_comprador=None, pdf=\"liq.pdf\"):\n        \"Consulta una liquidaci\u00f3n por No de Comprobante o CAE\"\n        if cae:\n            ret = self.client.consultarLiquidacionPorCae(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud={\n                            'cae': cae,\n                            'pdf': pdf and True or False,\n                            },\n                        )\n        else:\n            ret = self.client.consultarLiquidacionPorNroComprobante(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                        solicitud={\n                            'cuitComprador': cuit_comprador,\n                            'puntoVenta': pto_vta,\n                            'nroComprobante': nro_cbte,\n                            'tipoComprobante': tipo_cbte,\n                            'pdf': pdf and True or False,\n                            },\n                        )\n        ret = ret['respuesta']\n        self.__analizar_errores(ret)\n        if 'liquidacion' in ret:\n            liqs = ret.get('liquidacion', [])\n            liq = liqs[0] if liqs else None\n            self.AnalizarLiquidacion(liq)\n            # guardo el PDF si se indico archivo y vino en la respuesta:\n            if pdf and 'pdf' in liq:\n                open(pdf, \"wb\").write(liq['pdf'])\n        return True", "response": "Consulta una liquidaci\u00f3n por No de Comprobante o CAE"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConsultarBonificacionesPenalizaciones(self, sep=\"||\"):\n        \"Retorna un listado de bonificaciones/penalizaciones con c\u00f3digo y descripci\u00f3n\"\n        ret = self.client.consultarBonificacionesPenalizaciones(\n                        auth={\n                            'token': self.Token, 'sign': self.Sign,\n                            'cuit': self.Cuit, },\n                            )['respuesta']\n        self.__analizar_errores(ret)\n        self.XmlResponse = self.client.xml_response\n        array = ret.get('tipo', [])\n        if sep is None:\n            # sin separador, devuelve un diccionario con clave cod_variadedad\n            # y valor: {\"descripcion\": ds_variedad, \"clases\": lista_clases}\n            # siendo lista_clases = [{'codigo': ..., 'descripcion': ...}]\n            return dict([(it['codigo'], {'descripcion': it['descripcion'], \n                                         'subtipo': it['subtipo']}) \n                         for it in array])\n        else:\n            # con separador, devuelve una lista de strings:\n            # || cod.variedad || desc.variedad || desc.clase || cod.clase ||\n            ret = []\n            for it in array:\n                for subtipo in it['subtipo']:\n                    ret.append(\n                        (\"%s %%s %s %%s %s %%s %s %%s %s %%s %s %%s %s\" % \n                            (sep, sep, sep, sep, sep, sep, sep)) %\n                        (it['codigo'], it['descripcion'], \n                         subtipo['descripcion'], subtipo['codigo'],\n                         subtipo['valor'], subtipo['signo']) \n                        )\n            return ret", "response": "Retorna un listado de bonificaciones / penalizaciones con c\u00f3digo y descripci\u00f3n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting the given vars in the form flag = value", "response": "def format_vars(args):\n    \"\"\"Format the given vars in the form: 'flag=value'\"\"\"\n    variables = []\n    for key, value in args.items():\n        if value:\n            variables += ['{0}={1}'.format(key, value)]\n    return variables"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list with all the installed and notinstalled packages", "response": "def list_packages(self, installed=True, notinstalled=True):\n        \"\"\"Return a list with all the installed/notinstalled packages\"\"\"\n\n        self.profile = Profile()\n\n        # Classify packages\n        installed_packages = []\n        notinstalled_packages = []\n\n        for package in self.packages:\n            data = {\n                'name': package,\n                'version': None,\n                'description': self.packages.get(package).get('description')\n            }\n            if package in self.profile.packages:\n                data['version'] = self.profile.get_package_version(\n                    package, self.get_package_release_name(package))\n                installed_packages += [data]\n            else:\n                notinstalled_packages += [data]\n\n        # Print tables\n        terminal_width, _ = click.get_terminal_size()\n\n        if installed and installed_packages:\n\n            # - Print installed packages table\n            click.echo('\\nInstalled packages:\\n')\n\n            PACKAGELIST_TPL = ('{name:20} {description:30} {version:<8}')\n\n            click.echo('-' * terminal_width)\n            click.echo(PACKAGELIST_TPL.format(\n                name=click.style('Name', fg='cyan'), version='Version',\n                description='Description'))\n            click.echo('-' * terminal_width)\n\n            for package in installed_packages:\n                click.echo(PACKAGELIST_TPL.format(\n                    name=click.style(package.get('name'), fg='cyan'),\n                    version=package.get('version'),\n                    description=package.get('description')))\n\n        if notinstalled and notinstalled_packages:\n\n            # - Print not installed packages table\n            click.echo('\\nNot installed packages:\\n')\n\n            PACKAGELIST_TPL = ('{name:20} {description:30}')\n\n            click.echo('-' * terminal_width)\n            click.echo(PACKAGELIST_TPL.format(\n                name=click.style('Name', fg='yellow'),\n                description='Description'))\n            click.echo('-' * terminal_width)\n\n            for package in notinstalled_packages:\n                click.echo(PACKAGELIST_TPL.format(\n                    name=click.style(package.get('name'), fg='yellow'),\n                    description=package.get('description')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list with all the supported boards", "response": "def list_boards(self):\n        \"\"\"Return a list with all the supported boards\"\"\"\n\n        # Print table\n        click.echo('\\nSupported boards:\\n')\n\n        BOARDLIST_TPL = ('{board:25} {fpga:20} {type:<5} {size:<5} {pack:<10}')\n        terminal_width, _ = click.get_terminal_size()\n\n        click.echo('-' * terminal_width)\n        click.echo(BOARDLIST_TPL.format(\n            board=click.style('Board', fg='cyan'), fpga='FPGA', type='Type',\n            size='Size', pack='Pack'))\n        click.echo('-' * terminal_width)\n\n        for board in self.boards:\n            fpga = self.boards.get(board).get('fpga')\n            click.echo(BOARDLIST_TPL.format(\n                board=click.style(board, fg='cyan'),\n                fpga=fpga,\n                type=self.fpgas.get(fpga).get('type'),\n                size=self.fpgas.get(fpga).get('size'),\n                pack=self.fpgas.get(fpga).get('pack')))\n\n        click.secho(BOARDS_MSG, fg='green')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list with all the supported FPGAs", "response": "def list_fpgas(self):\n        \"\"\"Return a list with all the supported FPGAs\"\"\"\n\n        # Print table\n        click.echo('\\nSupported FPGAs:\\n')\n\n        FPGALIST_TPL = ('{fpga:30} {type:<5} {size:<5} {pack:<10}')\n        terminal_width, _ = click.get_terminal_size()\n\n        click.echo('-' * terminal_width)\n        click.echo(FPGALIST_TPL.format(\n            fpga=click.style('FPGA', fg='cyan'), type='Type',\n            size='Size', pack='Pack'))\n        click.echo('-' * terminal_width)\n\n        for fpga in self.fpgas:\n            click.echo(FPGALIST_TPL.format(\n                fpga=click.style(fpga, fg='cyan'),\n                type=self.fpgas.get(fpga).get('type'),\n                size=self.fpgas.get(fpga).get('size'),\n                pack=self.fpgas.get(fpga).get('pack')))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, command, variables=[], board=None, packages=[]):\n\n        # -- Check for the SConstruct file\n        if not isfile(util.safe_join(util.get_project_dir(), 'SConstruct')):\n            variables += ['-f']\n            variables += [util.safe_join(\n                util.get_folder('resources'), 'SConstruct')]\n        else:\n            click.secho('Info: use custom SConstruct file')\n\n        # -- Resolve packages\n        if self.profile.check_exe_default():\n            # Run on `default` config mode\n            if not util.resolve_packages(\n              packages,\n              self.profile.packages,\n              self.resources.distribution.get('packages')\n             ):\n                # Exit if a package is not installed\n                raise Exception\n        else:\n            click.secho('Info: native config mode')\n\n        # -- Execute scons\n        return self._execute_scons(command, variables, board)", "response": "Executes scons for building"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean the previous generated files.", "response": "def cli(ctx, project_dir):\n    \"\"\"Clean the previous generated files.\"\"\"\n    exit_code = SCons(project_dir).clean()\n    ctx.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlint the verilog code.", "response": "def cli(ctx, all, top, nostyle, nowarn, warn, project_dir):\n    \"\"\"Lint the verilog code.\"\"\"\n\n    exit_code = SCons(project_dir).lint({\n        'all': all,\n        'top': top,\n        'nostyle': nostyle,\n        'nowarn': nowarn,\n        'warn': warn\n    })\n    ctx.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_sconstruct(self, project_dir='', sayyes=False):\n\n        project_dir = util.check_dir(project_dir)\n\n        sconstruct_name = 'SConstruct'\n        sconstruct_path = util.safe_join(project_dir, sconstruct_name)\n        local_sconstruct_path = util.safe_join(\n            util.get_folder('resources'), sconstruct_name)\n\n        if isfile(sconstruct_path):\n            # -- If sayyes, skip the question\n            if sayyes:\n                self._copy_sconstruct_file(sconstruct_name, sconstruct_path,\n                                           local_sconstruct_path)\n            else:\n                click.secho(\n                    'Warning: {} file already exists'.format(sconstruct_name),\n                    fg='yellow')\n\n                if click.confirm('Do you want to replace it?'):\n                    self._copy_sconstruct_file(sconstruct_name,\n                                               sconstruct_path,\n                                               local_sconstruct_path)\n                else:\n                    click.secho('Abort!', fg='red')\n\n        else:\n            self._copy_sconstruct_file(sconstruct_name, sconstruct_path,\n                                       local_sconstruct_path)", "response": "Creates a default SConstruct file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new apio project file", "response": "def create_ini(self, board, project_dir='', sayyes=False):\n        \"\"\"Creates a new apio project file\"\"\"\n\n        project_dir = util.check_dir(project_dir)\n\n        ini_path = util.safe_join(project_dir, PROJECT_FILENAME)\n\n        # Check board\n        boards = Resources().boards\n        if board not in boards.keys():\n            click.secho(\n                'Error: no such board \\'{}\\''.format(board),\n                fg='red')\n            sys.exit(1)\n\n        if isfile(ini_path):\n            # -- If sayyes, skip the question\n            if sayyes:\n                self._create_ini_file(board, ini_path, PROJECT_FILENAME)\n            else:\n                click.secho(\n                    'Warning: {} file already exists'.format(PROJECT_FILENAME),\n                    fg='yellow')\n                if click.confirm('Do you want to replace it?'):\n                    self._create_ini_file(board, ini_path, PROJECT_FILENAME)\n                else:\n                    click.secho('Abort!', fg='red')\n        else:\n            self._create_ini_file(board, ini_path, PROJECT_FILENAME)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the project config file and update the board field", "response": "def read(self):\n        \"\"\"Read the project config file\"\"\"\n\n        # -- If no project finel found, just return\n        if not isfile(PROJECT_FILENAME):\n            print('Info: No {} file'.format(PROJECT_FILENAME))\n            return\n\n        # -- Read stored board\n        board = self._read_board()\n\n        # -- Update board\n        self.board = board\n        if not board:\n            print('Error: invalid {} project file'.format(\n                PROJECT_FILENAME))\n            print('No \\'board\\' field defined in project file')\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying the verilog code.", "response": "def cli(ctx, project_dir):\n    \"\"\"Verify the verilog code.\"\"\"\n    exit_code = SCons(project_dir).verify()\n    ctx.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmanage FPGA boards drivers.", "response": "def cli(ctx, ftdi_enable, ftdi_disable, serial_enable, serial_disable):\n    \"\"\"Manage FPGA boards drivers.\"\"\"\n\n    exit_code = 0\n\n    if ftdi_enable:   # pragma: no cover\n        exit_code = Drivers().ftdi_enable()\n    elif ftdi_disable:   # pragma: no cover\n        exit_code = Drivers().ftdi_disable()\n    elif serial_enable:   # pragma: no cover\n        exit_code = Drivers().serial_enable()\n    elif serial_disable:   # pragma: no cover\n        exit_code = Drivers().serial_disable()\n    else:\n        click.secho(ctx.get_help())\n\n    ctx.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload the bitstream to the FPGA.", "response": "def cli(ctx, board, serial_port, ftdi_id, sram, project_dir,\n        verbose, verbose_yosys, verbose_arachne):\n    \"\"\"Upload the bitstream to the FPGA.\"\"\"\n\n    drivers = Drivers()\n    drivers.pre_upload()\n    # Run scons\n    exit_code = SCons(project_dir).upload({\n        'board': board,\n        'verbose': {\n            'all': verbose,\n            'yosys': verbose_yosys,\n            'arachne': verbose_arachne\n        }\n    }, serial_port, ftdi_id, sram)\n    drivers.post_upload()\n    ctx.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(ctx):\n\n    current_version = get_distribution('apio').version\n    latest_version = get_pypi_latest_version()\n\n    if latest_version is None:\n        ctx.exit(1)\n\n    if latest_version == current_version:\n        click.secho('You\\'re up-to-date!\\nApio {} is currently the '\n                    'newest version available.'.format(latest_version),\n                    fg='green')\n    else:\n        click.secho('You\\'re not updated\\nPlease execute '\n                    '`pip install -U apio` to upgrade.',\n                    fg=\"yellow\")", "response": "Check the latest Apio version."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes sure a Unicode string is returned", "response": "def unicoder(p):\n    \"\"\" Make sure a Unicode string is returned \"\"\"\n    if isinstance(p, unicode):\n        return p\n    if isinstance(p, str):\n        return decoder(p)\n    else:\n        return unicode(decoder(p))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\njoins a list of paths in a Unicode - safe way", "response": "def safe_join(*paths):\n    \"\"\" Join paths in a Unicode-safe way \"\"\"\n    try:\n        return join(*paths)\n    except UnicodeDecodeError:\n        npaths = ()\n        for path in paths:\n            npaths += (unicoder(path),)\n        return join(*npaths)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_apt_get():\n    check = False\n    if 'TESTING' not in os.environ:\n        result = exec_command(['dpkg', '-l', 'apio'])\n        if result and result.get('returncode') == 0:\n            match = re.findall('rc\\s+apio', result.get('out')) + \\\n                    re.findall('ii\\s+apio', result.get('out'))\n            check = len(match) > 0\n    return check", "response": "Check if apio can be installed through apt - get"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, cmd):\n\n    exit_code = util.call(cmd)\n    ctx.exit(exit_code)", "response": "Execute commands using Apio packages."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cli(ctx, list, dir, files, project_dir, sayno):\n\n    exit_code = 0\n\n    if list:\n        exit_code = Examples().list_examples()\n    elif dir:\n        exit_code = Examples().copy_example_dir(dir, project_dir, sayno)\n    elif files:\n        exit_code = Examples().copy_example_files(files, project_dir, sayno)\n    else:\n        click.secho(ctx.get_help())\n        click.secho(Examples().examples_of_use_cad())\n\n    ctx.exit(exit_code)", "response": "Manage verilog examples.\\n\n       Install with `apio install examples`"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlaunching the verilog simulation.", "response": "def cli(ctx, project_dir):\n    \"\"\"Launch the verilog simulation.\"\"\"\n\n    exit_code = SCons(project_dir).sim()\n    ctx.exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of fields to use for index", "response": "def get_index_fields(self):\n        \"\"\"\n        List of fields to use for index\n        \"\"\"\n        index_fields = self.get_meta_option('index', [])\n        if index_fields:\n            return index_fields\n\n        model = getattr(self.model_serializer_meta, 'model', None)\n        if model:\n            pk_name = model._meta.pk.name\n            if pk_name in self.child.get_fields():\n                return [pk_name]\n\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform_dataframe(self, dataframe):\n        dataframe.columns.name = \"\"\n\n        for i in range(len(self.get_header_fields())):\n            dataframe = dataframe.unstack()\n\n        # Remove blank rows / columns\n        dataframe = dataframe.dropna(\n            axis=0, how='all'\n        ).dropna(\n            axis=1, how='all'\n        )\n        return dataframe", "response": "Unstack the dataframe so header fields are across the top."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform_dataframe(self, dataframe):\n        coord_fields = self.get_coord_fields()\n        header_fields = self.get_header_fields()\n\n        # Remove any pairs that don't have data for both x & y\n        for i in range(len(coord_fields)):\n            dataframe = dataframe.unstack()\n        dataframe = dataframe.dropna(axis=1, how='all')\n        dataframe = dataframe.dropna(axis=0, how='any')\n\n        # Unstack series header\n        for i in range(len(header_fields)):\n            dataframe = dataframe.unstack()\n\n        # Compute new column headers\n        columns = []\n        for i in range(len(header_fields) + 1):\n            columns.append([])\n\n        for col in dataframe.columns:\n            value_name = col[0]\n            coord_names = list(col[1:len(coord_fields) + 1])\n            header_names = list(col[len(coord_fields) + 1:])\n            coord_name = ''\n            for name in coord_names:\n                if name != self.index_none_value:\n                    coord_name += name + '-'\n            coord_name += value_name\n            columns[0].append(coord_name)\n            for i, header_name in enumerate(header_names):\n                columns[1 + i].append(header_name)\n\n        dataframe.columns = columns\n        dataframe.columns.names = [''] + header_fields\n\n        return dataframe", "response": "Unstack the dataframe so that the header consists of a composite value header plus any other header fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform_dataframe(self, dataframe):\n        grouping = self.get_grouping(dataframe)\n        group_field = self.get_group_field()\n        header_fields = self.get_header_fields()\n\n        if \"series\" in grouping:\n            # Unstack so each series is a column\n            for i in range(len(header_fields) + 1):\n                dataframe = dataframe.unstack()\n\n        groups = {\n            col: dataframe[col]\n            for col in dataframe.columns\n        }\n\n        if \"year\" in grouping:\n            interval = \"year\"\n        elif \"month\" in grouping:\n            interval = \"month\"\n        else:\n            interval = None\n\n        # Compute stats for each column, potentially grouped by year\n        series_infos = OrderedDict()\n        for header, series in groups.items():\n            if interval:\n                series_stats = self.boxplots_for_interval(series, interval)\n            else:\n                series_stats = [self.compute_boxplot(series)]\n\n            for series_stat in series_stats:\n                if isinstance(header, tuple):\n                    value_name = header[0]\n                    col_values = header[1:]\n                else:\n                    value_name = header\n                    col_values = []\n                col_names = tuple(zip(dataframe.columns.names[1:], col_values))\n                if interval in series_stat:\n                    col_names += ((interval, series_stat[interval]),)\n                series_infos.setdefault(col_names, dict(col_names))\n                series_info = series_infos[col_names]\n                for stat_name, val in series_stat.items():\n                    if stat_name != interval:\n                        series_info[value_name + '-' + stat_name] = val\n\n        dataframe = DataFrame(list(series_infos.values()))\n        if 'series' in grouping:\n            index = header_fields + [group_field]\n            unstack = len(header_fields)\n            if interval:\n                index = [interval] + index\n                unstack += 1\n        else:\n            index = [interval]\n            unstack = 0\n\n        dataframe.set_index(index, inplace=True)\n        dataframe.columns.name = ''\n        for i in range(unstack):\n            dataframe = dataframe.unstack()\n\n        # Remove blank columns\n        dataframe = dataframe.dropna(axis=1, how='all')\n        return dataframe", "response": "Transform a pandas dataframe to a boxplot dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute boxplot for given pandas Series.", "response": "def compute_boxplot(self, series):\n        \"\"\"\n        Compute boxplot for given pandas Series.\n        \"\"\"\n        from matplotlib.cbook import boxplot_stats\n        series = series[series.notnull()]\n        if len(series.values) == 0:\n            return {}\n        elif not is_numeric_dtype(series):\n            return self.non_numeric_stats(series)\n        stats = boxplot_stats(list(series.values))[0]\n        stats['count'] = len(series.values)\n        stats['fliers'] = \"|\".join(map(str, stats['fliers']))\n        return stats"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_cls(cls_name):\n    path_components = cls_name.split('.')\n    module = __import__('.'.join(path_components[:-1]),\n                        locals(),\n                        globals(),\n                        fromlist=path_components[-1:])\n    return getattr(module, path_components[-1])", "response": "Import class by its fully qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nauthenticate user and upload photo.", "response": "def main(uid, password, photo, users_service, auth_service, photos_service):\n    \"\"\"Authenticate user and upload photo.\"\"\"\n    user = users_service.get_user_by_id(uid)\n    auth_service.authenticate(user, password)\n    photos_service.upload_photo(user['uid'], photo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes use case handling.", "response": "def execute(self, email):\n        \"\"\"Execute use case handling.\"\"\"\n        print('Sign up user {0}'.format(email))\n        self.email_sender.send(email, 'Welcome, \"{}\"'.format(email))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_all(self):\n        with open(self._csv_file_path) as csv_file:\n            csv_reader = csv.reader(csv_file, delimiter=self._delimiter)\n            return [self._movie_model(*row) for row in csv_reader]", "response": "Return all found movies."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all found movies.", "response": "def find_all(self):\n        \"\"\"Return all found movies.\n\n        :rtype: list[movies.models.Movie]\n        :return: List of movie instances.\n        \"\"\"\n        with self._database:\n            rows = self._database.execute('SELECT name, year, director '\n                                          'FROM movies')\n            return [self._movie_model(*row) for row in rows]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding user by his id and return user model.", "response": "def get_by_id(self, id):\n        \"\"\"Find user by his id and return user model.\"\"\"\n        return self.user_cls(id=id, password='secret' + str(id))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_by_id(self, id):\n        user = super(ExtendedUsersService, self).get_by_id(id)\n        user.first_name = 'John' + str(id)\n        user.last_name = 'Smith' + str(id)\n        user.gender = 'male'\n        return user", "response": "Find user by his id and return user model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_by_id(self, uid):\n        self.logger.debug('User %s has been found in database', uid)\n        return dict(uid=uid, password_hash='secret_hash')", "response": "Return user s data by identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn user s main photo.", "response": "def main_photo(self):\n        \"\"\"Return user's main photo.\"\"\"\n        if not self._main_photo:\n            self._main_photo = self.photos_factory()\n        return self._main_photo"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns application. This program prints info about all movies that were directed by different persons and then prints all movies that were released in 2015. :param movie_lister: Movie lister instance :type movie_lister: movies.listers.MovieLister", "response": "def main(movie_lister):\n    \"\"\"Run application.\n\n    This program prints info about all movies that were directed by different\n    persons and then prints all movies that were released in 2015.\n\n    :param movie_lister: Movie lister instance\n    :type movie_lister: movies.listers.MovieLister\n    \"\"\"\n    print(movie_lister.movies_directed_by('Francis Lawrence'))\n    print(movie_lister.movies_directed_by('Patricia Riggen'))\n    print(movie_lister.movies_directed_by('JJ Abrams'))\n\n    print(movie_lister.movies_released_in(2015))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing sqlite3 movies database.", "response": "def init_sqlite(movies_data, database):\n    \"\"\"Initialize sqlite3 movies database.\n\n    :param movies_data: Data about movies\n    :type movies_data: tuple[tuple]\n\n    :param database: Connection to sqlite database with movies data\n    :type database: sqlite3.Connection\n    \"\"\"\n    with database:\n        database.execute('CREATE TABLE IF NOT EXISTS movies '\n                         '(name text, year int, director text)')\n        database.execute('DELETE FROM movies')\n        database.executemany('INSERT INTO movies VALUES (?,?,?)', movies_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the csv movies database.", "response": "def init_csv(movies_data, csv_file_path, delimiter):\n    \"\"\"Initialize csv movies database.\n\n    :param movies_data: Data about movies\n    :type movies_data: tuple[tuple]\n\n    :param csv_file_path: Path to csv file with movies data\n    :type csv_file_path: str\n\n    :param delimiter: Csv file's delimiter\n    :type delimiter: str\n    \"\"\"\n    with open(csv_file_path, 'w') as csv_file:\n        csv.writer(csv_file, delimiter=delimiter).writerows(movies_data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating user with hashed password.", "response": "def create_user(self, name, password):\n        \"\"\"Create user with hashed password.\"\"\"\n        hashed_password = self._password_hasher(password)\n        return dict(name=name, password=hashed_password)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(self, operation, data):\n        print('API call [{0}:{1}], method - {2}, data - {3}'.format(\n            self.host, self.api_key, operation, repr(data)))", "response": "Make some network operations."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef movies_directed_by(self, director):\n        return [movie for movie in self._movie_finder.find_all()\n                if movie.director == director]", "response": "Return list of movies that were directed by certain person."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef movies_released_in(self, year):\n        return [movie for movie in self._movie_finder.find_all()\n                if movie.year == year]", "response": "Return list of movies that were released in a certain year."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing database if it has not been initialized yet.", "response": "def init_database(self):\n        \"\"\"Initialize database, if it has not been initialized yet.\"\"\"\n        with contextlib.closing(self.database.cursor()) as cursor:\n            cursor.execute(\"\"\"\n              CREATE TABLE IF NOT EXISTS users(\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                name VARCHAR(32)\n              )\n            \"\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, name):\n        with contextlib.closing(self.database.cursor()) as cursor:\n            cursor.execute('INSERT INTO users(name) VALUES (?)', (name,))\n            return cursor.lastrowid", "response": "Create user with provided name and return his id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_by_id(self, id):\n        with contextlib.closing(self.database.cursor()) as cursor:\n            cursor.execute('SELECT id, name FROM users WHERE id=?', (id,))\n            return cursor.fetchone()", "response": "Return user info by user id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_top_headlines(self, q=None, sources=None, language='en', country=None, category=None, page_size=None,\n                          page=None):\n        \"\"\"\n            Returns live top and breaking headlines for a country, specific category in a country, single source, or multiple sources..\n\n            Optional parameters:\n                (str) q - return headlines w/ specific keyword or phrase. For example:\n                          'bitcoin', 'trump', 'tesla', 'ethereum', etc.\n\n                (str) sources - return headlines of news sources! some Valid values are:\n                                'bbc-news', 'the-verge', 'abc-news', 'crypto coins news',\n                                'ary news','associated press','wired','aftenposten','australian financial review','axios',\n\t\t\t\t'bbc news','bild','blasting news','bloomberg','business insider','engadget','google news',\n\t\t\t\t'hacker news','info money,'recode','techcrunch','techradar','the next web','the verge' etc.\n\n\t\t(str) language - The 2-letter ISO-639-1 code of the language you want to get headlines for. Valid values are:\n\t\t\t\t 'ar','de','en','es','fr','he','it','nl','no','pt','ru','se','ud','zh'\n\n                (str) country - The 2-letter ISO 3166-1 code of the country you want to get headlines! Valid values are:\n                                'ae','ar','at','au','be','bg','br','ca','ch','cn','co','cu','cz','de','eg','fr','gb','gr',\n                                'hk','hu','id','ie','il','in','it','jp','kr','lt','lv','ma','mx','my','ng','nl','no','nz',\n                                'ph','pl','pt','ro','rs','ru','sa','se','sg','si','sk','th','tr','tw','ua','us'\n\n\t\t(str) category - The category you want to get headlines for! Valid values are:\n\t\t\t\t 'business','entertainment','general','health','science','sports','technology'\n\n\t\t(int) page_size - The number of results to return per page (request). 20 is the default, 100 is the maximum.\n\n\t\t(int) page - Use this to page through the results if the total results found is greater than the page size.\n        \"\"\"\n\n        # Define Payload\n        payload = {}\n\n        # Keyword/Phrase\n        if q is not None:\n            if type(q) == str:\n                payload['q'] = q\n            else:\n                raise TypeError('keyword/phrase q param should be a of type str')\n\n        # Sources\n        if (sources is not None) and ((country is not None) or (category is not None)):\n            raise ValueError('cannot mix country/category param with sources param.')\n\n        # Sources\n        if sources is not None:\n            if type(sources) == str:\n                payload['sources'] = sources\n            else:\n                raise TypeError('sources param should be of type str')\n\n        # Language\n        if language is not None:\n            if type(language) == str:\n                if language in const.languages:\n                    payload['language'] = language\n                else:\n                    raise ValueError('invalid language')\n            else:\n                raise TypeError('language param should be of type str')\n\n        # Country\n        if country is not None:\n            if type(country) == str:\n                if country in const.countries:\n                    payload['country'] = country\n                else:\n                    raise ValueError('invalid country')\n            else:\n                raise TypeError('country param should be of type str')\n\n        # Category\n        if category is not None:\n            if type(category) == str:\n                if category in const.categories:\n                    payload['category'] = category\n                else:\n                    raise ValueError('invalid category')\n            else:\n                raise TypeError('category param should be of type str')\n\n        # Page Size\n        if page_size is not None:\n            if type(page_size) == int:\n                if 0 <= page_size <= 100:\n                    payload['pageSize'] = page_size\n                else:\n                    raise ValueError('page_size param should be an int between 1 and 100')\n            else:\n                raise TypeError('page_size param should be an int')\n\n        # Page\n        if page is not None:\n            if type(page) == int:\n                if page > 0:\n                    payload['page'] = page\n                else:\n                    raise ValueError('page param should be an int greater than 0')\n            else:\n                raise TypeError('page param should be an int')\n\n        # Send Request\n        r = requests.get(const.TOP_HEADLINES_URL, auth=self.auth, timeout=30, params=payload)\n\n        # Check Status of Request\n        if r.status_code != requests.codes.ok:\n            raise NewsAPIException(r.json())\n\n        return r.json()", "response": "Returns live top and breaking headlines for a specific category in a specific language in a single source or multiple sources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch through millions of articles from over 5,000 large and small news sources and blogs. Optional parameters: (str) q - return headlines w/ specified coin! Valid values are: 'bitcoin', 'trump', 'tesla', 'ethereum', etc (str) sources - return headlines of news sources! some Valid values are: 'bbc-news', 'the-verge', 'abc-news', 'crypto coins news', 'ary news','associated press','wired','aftenposten','australian financial review','axios', 'bbc news','bild','blasting news','bloomberg','business insider','engadget','google news', 'hacker news','info money,'recode','techcrunch','techradar','the next web','the verge' etc. (str) domains - A comma-seperated string of domains (eg bbc.co.uk, techcrunch.com, engadget.com) to restrict the search to. (str) exclude_domains - A comma_seperated string of domains to be excluded from the search (str) from_param - A date and optional time for the oldest article allowed. (e.g. 2018-03-05 or 2018-03-05T03:46:15) (str) to - A date and optional time for the newest article allowed. (str) language - The 2-letter ISO-639-1 code of the language you want to get headlines for. Valid values are: 'ar','de','en','es','fr','he','it','nl','no','pt','ru','se','ud','zh' (str) sort_by - The order to sort the articles in. Valid values are: 'relevancy','popularity','publishedAt' (int) page_size - The number of results to return per page (request). 20 is the default, 100 is the maximum. (int) page - Use this to page through the results if the total results found is greater than the page size.", "response": "def get_everything(self, q=None, sources=None, domains=None, exclude_domains=None,\n                       from_param=None, to=None, language=None, sort_by=None, page=None,\n                       page_size=None):\n        \"\"\"\n            Search through millions of articles from over 5,000 large and small news sources and blogs.\n\n            Optional parameters:\n                (str) q - return headlines w/ specified coin! Valid values are:\n                            'bitcoin', 'trump', 'tesla', 'ethereum', etc\n\n                (str) sources - return headlines of news sources! some Valid values are:\n                            'bbc-news', 'the-verge', 'abc-news', 'crypto coins news',\n                            'ary news','associated press','wired','aftenposten','australian financial review','axios',\n\t\t\t    'bbc news','bild','blasting news','bloomberg','business insider','engadget','google news',\n\t\t  \t    'hacker news','info money,'recode','techcrunch','techradar','the next web','the verge' etc.\n\n\t\t(str) domains - A comma-seperated string of domains (eg bbc.co.uk, techcrunch.com, engadget.com) to restrict the search to.\n\n        (str) exclude_domains - A comma_seperated string of domains to be excluded from the search\n\n\t\t(str) from_param - A date and optional time for the oldest article allowed.\n                                       (e.g. 2018-03-05 or 2018-03-05T03:46:15)\n\n\t\t(str) to - A date and optional time for the newest article allowed.\n\n\t\t(str) language - The 2-letter ISO-639-1 code of the language you want to get headlines for. Valid values are:\n\t\t\t\t'ar','de','en','es','fr','he','it','nl','no','pt','ru','se','ud','zh'\n\n\t\t(str) sort_by - The order to sort the articles in. Valid values are: 'relevancy','popularity','publishedAt'\n\n\t\t(int) page_size - The number of results to return per page (request). 20 is the default, 100 is the maximum.\n\n\t\t(int) page - Use this to page through the results if the total results found is greater than the page size.\n        \"\"\"\n\n        # Define Payload\n        payload = {}\n\n        # Keyword/Phrase\n        if q is not None:\n            if type(q) == str:\n                payload['q'] = q\n            else:\n                raise TypeError('keyword/phrase q param should be of type str')\n\n        # Sources\n        if sources is not None:\n            if type(sources) == str:\n                payload['sources'] = sources\n            else:\n                raise TypeError('sources param should be of type str')\n\n        # Domains To Search\n        if domains is not None:\n            if type(domains) == str:\n                payload['domains'] = domains\n            else:\n                raise TypeError('domains param should be of type str')\n\n        if exclude_domains is not None:\n            if isinstance(exclude_domains, str):\n                payload['excludeDomains'] = exclude_domains\n            else:\n                raise TypeError('exclude_domains param should be of type str')\n\n        # Search From This Date ...\n        if from_param is not None:\n            if type(from_param) == str:\n                if (len(from_param)) >= 10:\n                    for i in range(len(from_param)):\n                        if (i == 4 and from_param[i] != '-') or (i == 7 and from_param[i] != '-'):\n                            raise ValueError('from_param should be in the format of YYYY-MM-DD')\n                        else:\n                            payload['from'] = from_param\n                else:\n                    raise ValueError('from_param should be in the format of YYYY-MM-DD')\n            else:\n                raise TypeError('from_param should be of type str')\n\n        # ... To This Date\n        if to is not None:\n            if type(to) == str:\n                if (len(to)) >= 10:\n                    for i in range(len(to)):\n                        if (i == 4 and to[i] != '-') or (i == 7 and to[i] != '-'):\n                            raise ValueError('to should be in the format of YYYY-MM-DD')\n                        else:\n                            payload['to'] = to\n                else:\n                    raise ValueError('to param should be in the format of YYYY-MM-DD')\n            else:\n                raise TypeError('to param should be of type str')\n\n        # Language\n        if language is not None:\n            if type(language) == str:\n                if language not in const.languages:\n                    raise ValueError('invalid language')\n                else:\n                    payload['language'] = language\n            else:\n                raise TypeError('language param should be of type str')\n\n        # Sort Method\n        if sort_by is not None:\n            if type(sort_by) == str:\n                if sort_by in const.sort_method:\n                    payload['sortBy'] = sort_by\n                else:\n                    raise ValueError('invalid sort')\n            else:\n                raise TypeError('sort_by param should be of type str')\n\n        # Page Size\n        if page_size is not None:\n            if type(page_size) == int:\n                if 0 <= page_size <= 100:\n                    payload['pageSize'] = page_size\n                else:\n                    raise ValueError('page_size param should be an int between 1 and 100')\n            else:\n                raise TypeError('page_size param should be an int')\n\n        # Page\n        if page is not None:\n            if type(page) == int:\n                if page > 0:\n                    payload['page'] = page\n                else:\n                    raise ValueError('page param should be an int greater than 0')\n            else:\n                raise TypeError('page param should be an int')\n\n        # Send Request\n        r = requests.get(const.EVERYTHING_URL, auth=self.auth, timeout=30, params=payload)\n\n        # Check Status of Request\n        if r.status_code != requests.codes.ok:\n            raise NewsAPIException(r.json())\n\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the subset of news publishers that top headlines...", "response": "def get_sources(self, category=None, language=None, country=None):\n        \"\"\"\n            Returns the subset of news publishers that top headlines...\n\n            Optional parameters:\n                (str) category - The category you want to get headlines for! Valid values are:\n\t\t\t\t 'business','entertainment','general','health','science','sports','technology'\n\n\t\t(str) language - The 2-letter ISO-639-1 code of the language you want to get headlines for. Valid values are:\n\t\t\t\t'ar','de','en','es','fr','he','it','nl','no','pt','ru','se','ud','zh'\n\n                (str) country - The 2-letter ISO 3166-1 code of the country you want to get headlines! Valid values are:\n                                'ae','ar','at','au','be','bg','br','ca','ch','cn','co','cu','cz','de','eg','fr','gb','gr',\n                                'hk','hu','id','ie','il','in','it','jp','kr','lt','lv','ma','mx','my','ng','nl','no','nz',\n                                'ph','pl','pt','ro','rs','ru','sa','se','sg','si','sk','th','tr','tw','ua','us'\n\n\t\t\t\t(str) category - The category you want to get headlines for! Valid values are:\n\t\t\t\t\t\t'business','entertainment','general','health','science','sports','technology'\n\n        \"\"\"\n\n        # Define Payload\n        payload = {}\n\n        # Language\n        if language is not None:\n            if type(language) == str:\n                if language in const.languages:\n                    payload['language'] = language\n                else:\n                    raise ValueError('invalid language')\n            else:\n                raise TypeError('language param should be of type str')\n\n        # Country\n        if country is not None:\n            if type(country) == str:\n                if country in const.countries:\n                    payload['country'] = country\n                else:\n                    raise ValueError('invalid country')\n            else:\n                raise TypeError('country param should be of type str')\n\n                # Category\n        if category is not None:\n            if type(category) == str:\n                if category in const.categories:\n                    payload['category'] = category\n                else:\n                    raise ValueError('invalid category')\n            else:\n                raise TypeError('category param should be of type str')\n\n        # Send Request\n        r = requests.get(const.SOURCES_URL, auth=self.auth, timeout=30, params=payload)\n\n        # Check Status of Request\n        if r.status_code != requests.codes.ok:\n            raise NewsAPIException(r.json())\n\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new logger instance with the specified name logfile and level and maxBytes.", "response": "def setup_logger(name=None, logfile=None, level=logging.DEBUG, formatter=None, maxBytes=0, backupCount=0, fileLoglevel=None, disableStderrLogger=False):\n    \"\"\"\n    Configures and returns a fully configured logger instance, no hassles.\n    If a logger with the specified name already exists, it returns the existing instance,\n    else creates a new one.\n\n    If you set the ``logfile`` parameter with a filename, the logger will save the messages to the logfile,\n    but does not rotate by default. If you want to enable log rotation, set both ``maxBytes`` and ``backupCount``.\n\n    Usage:\n\n    .. code-block:: python\n\n        from logzero import setup_logger\n        logger = setup_logger()\n        logger.info(\"hello\")\n\n    :arg string name: Name of the `Logger object <https://docs.python.org/2/library/logging.html#logger-objects>`_. Multiple calls to ``setup_logger()`` with the same name will always return a reference to the same Logger object. (default: ``__name__``)\n    :arg string logfile: If set, also write logs to the specified filename.\n    :arg int level: Minimum `logging-level <https://docs.python.org/2/library/logging.html#logging-levels>`_ to display (default: ``logging.DEBUG``).\n    :arg Formatter formatter: `Python logging Formatter object <https://docs.python.org/2/library/logging.html#formatter-objects>`_ (by default uses the internal LogFormatter).\n    :arg int maxBytes: Size of the logfile when rollover should occur. Defaults to 0, rollover never occurs.\n    :arg int backupCount: Number of backups to keep. Defaults to 0, rollover never occurs.\n    :arg int fileLoglevel: Minimum `logging-level <https://docs.python.org/2/library/logging.html#logging-levels>`_ for the file logger (is not set, it will use the loglevel from the ``level`` argument)\n    :arg bool disableStderrLogger: Should the default stderr logger be disabled. Defaults to False.\n    :return: A fully configured Python logging `Logger object <https://docs.python.org/2/library/logging.html#logger-objects>`_ you can use with ``.debug(\"msg\")``, etc.\n    \"\"\"\n    _logger = logging.getLogger(name or __name__)\n    _logger.propagate = False\n    _logger.setLevel(level)\n\n    # Reconfigure existing handlers\n    stderr_stream_handler = None\n    for handler in list(_logger.handlers):\n        if hasattr(handler, LOGZERO_INTERNAL_LOGGER_ATTR):\n            if isinstance(handler, logging.FileHandler):\n                # Internal FileHandler needs to be removed and re-setup to be able\n                # to set a new logfile.\n                _logger.removeHandler(handler)\n                continue\n            elif isinstance(handler, logging.StreamHandler):\n                stderr_stream_handler = handler\n\n        # reconfigure handler\n        handler.setLevel(level)\n        handler.setFormatter(formatter or LogFormatter())\n\n    # remove the stderr handler (stream_handler) if disabled\n    if disableStderrLogger:\n        if stderr_stream_handler is not None:\n            _logger.removeHandler(stderr_stream_handler)\n    elif stderr_stream_handler is None:\n        stderr_stream_handler = logging.StreamHandler()\n        setattr(stderr_stream_handler, LOGZERO_INTERNAL_LOGGER_ATTR, True)\n        stderr_stream_handler.setLevel(level)\n        stderr_stream_handler.setFormatter(formatter or LogFormatter())\n        _logger.addHandler(stderr_stream_handler)\n\n    if logfile:\n        rotating_filehandler = RotatingFileHandler(filename=logfile, maxBytes=maxBytes, backupCount=backupCount)\n        setattr(rotating_filehandler, LOGZERO_INTERNAL_LOGGER_ATTR, True)\n        rotating_filehandler.setLevel(fileLoglevel or level)\n        rotating_filehandler.setFormatter(formatter or LogFormatter(color=False))\n        _logger.addHandler(rotating_filehandler)\n\n    return _logger"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_unicode(value):\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    if not isinstance(value, bytes):\n        raise TypeError(\n            \"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.decode(\"utf-8\")", "response": "Converts a string argument to a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_default_logger(logfile=None, level=logging.DEBUG, formatter=None, maxBytes=0, backupCount=0, disableStderrLogger=False):\n    global logger\n    logger = setup_logger(name=LOGZERO_DEFAULT_LOGGER, logfile=logfile, level=level, formatter=formatter, disableStderrLogger=disableStderrLogger)\n    return logger", "response": "This function creates a default logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset the internal default logger to the initial configuration", "response": "def reset_default_logger():\n    \"\"\"\n    Resets the internal default logger to the initial configuration\n    \"\"\"\n    global logger\n    global _loglevel\n    global _logfile\n    global _formatter\n    _loglevel = logging.DEBUG\n    _logfile = None\n    _formatter = None\n    logger = setup_logger(name=LOGZERO_DEFAULT_LOGGER, logfile=_logfile, level=_loglevel, formatter=_formatter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the minimum loglevel for the default logger.", "response": "def loglevel(level=logging.DEBUG, update_custom_handlers=False):\n    \"\"\"\n    Set the minimum loglevel for the default logger (`logzero.logger`).\n\n    This reconfigures only the internal handlers of the default logger (eg. stream and logfile).\n    You can also update the loglevel for custom handlers by using `update_custom_handlers=True`.\n\n    :arg int level: Minimum `logging-level <https://docs.python.org/2/library/logging.html#logging-levels>`_ to display (default: `logging.DEBUG`).\n    :arg bool update_custom_handlers: If you added custom handlers to this logger and want this to update them too, you need to set `update_custom_handlers` to `True`\n    \"\"\"\n    logger.setLevel(level)\n\n    # Reconfigure existing internal handlers\n    for handler in list(logger.handlers):\n        if hasattr(handler, LOGZERO_INTERNAL_LOGGER_ATTR) or update_custom_handlers:\n            # Don't update the loglevel if this handler uses a custom one\n            if hasattr(handler, LOGZERO_INTERNAL_HANDLER_IS_CUSTOM_LOGLEVEL):\n                continue\n\n            # Update the loglevel for all default handlers\n            handler.setLevel(level)\n\n    global _loglevel\n    _loglevel = level"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the formatter for all loggers.", "response": "def formatter(formatter, update_custom_handlers=False):\n    \"\"\"\n    Set the formatter for all handlers of the default logger (``logzero.logger``).\n\n    This reconfigures only the logzero internal handlers by default, but you can also\n    reconfigure custom handlers by using ``update_custom_handlers=True``.\n\n    Beware that setting a formatter which uses colors also may write the color codes\n    to logfiles.\n\n    :arg Formatter formatter: `Python logging Formatter object <https://docs.python.org/2/library/logging.html#formatter-objects>`_ (by default uses the internal LogFormatter).\n    :arg bool update_custom_handlers: If you added custom handlers to this logger and want this to update them too, you need to set ``update_custom_handlers`` to `True`\n    \"\"\"\n    for handler in list(logger.handlers):\n        if hasattr(handler, LOGZERO_INTERNAL_LOGGER_ATTR) or update_custom_handlers:\n            handler.setFormatter(formatter)\n\n    global _formatter\n    _formatter = formatter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef logfile(filename, formatter=None, mode='a', maxBytes=0, backupCount=0, encoding=None, loglevel=None, disableStderrLogger=False):\n    # Step 1: If an internal RotatingFileHandler already exists, remove it\n    __remove_internal_loggers(logger, disableStderrLogger)\n\n    # Step 2: If wanted, add the RotatingFileHandler now\n    if filename:\n        rotating_filehandler = RotatingFileHandler(filename, mode=mode, maxBytes=maxBytes, backupCount=backupCount, encoding=encoding)\n\n        # Set internal attributes on this handler\n        setattr(rotating_filehandler, LOGZERO_INTERNAL_LOGGER_ATTR, True)\n        if loglevel:\n            setattr(rotating_filehandler, LOGZERO_INTERNAL_HANDLER_IS_CUSTOM_LOGLEVEL, True)\n\n        # Configure the handler and add it to the logger\n        rotating_filehandler.setLevel(loglevel or _loglevel)\n        rotating_filehandler.setFormatter(formatter or _formatter or LogFormatter(color=False))\n        logger.addHandler(rotating_filehandler)", "response": "Write a logfile to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving internal loggers from the specific logger_to_update.", "response": "def __remove_internal_loggers(logger_to_update, disableStderrLogger=True):\n    \"\"\"\n    Remove the internal loggers (e.g. stderr logger and file logger) from the specific logger\n    :param logger_to_update: the logger to remove internal loggers from\n    :param disableStderrLogger: should the default stderr logger be disabled? defaults to True\n    \"\"\"\n    for handler in list(logger_to_update.handlers):\n        if hasattr(handler, LOGZERO_INTERNAL_LOGGER_ATTR):\n            if isinstance(handler, RotatingFileHandler):\n                logger_to_update.removeHandler(handler)\n            elif isinstance(handler, SysLogHandler):\n                logger_to_update.removeHandler(handler)\n            elif isinstance(handler, logging.StreamHandler) and disableStderrLogger:\n                logger_to_update.removeHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nintegrating angular velocity at time t0 t1 and R0.", "response": "def integrate_angular_velocity(Omega, t0, t1, R0=None, tolerance=1e-12):\n    \"\"\"Compute frame with given angular velocity\n\n    Parameters\n    ==========\n    Omega: tuple or callable\n        Angular velocity from which to compute frame.  Can be\n          1) a 2-tuple of float arrays (t, v) giving the angular velocity vector at a series of times,\n          2) a function of time that returns the 3-vector angular velocity, or\n          3) a function of time and orientation (t, R) that returns the 3-vector angular velocity\n        In case 1, the angular velocity will be interpolated to the required times.  Note that accuracy\n        is poor in case 1.\n    t0: float\n        Initial time\n    t1: float\n        Final time\n    R0: quaternion, optional\n        Initial frame orientation.  Defaults to 1 (the identity orientation).\n    tolerance: float, optional\n        Absolute tolerance used in integration.  Defaults to 1e-12.\n\n    Returns\n    =======\n    t: float array\n    R: quaternion array\n\n    \"\"\"\n    import warnings\n    from scipy.integrate import ode\n\n    if R0 is None:\n        R0 = quaternion.one\n\n    input_is_tabulated = False\n\n    try:\n        t_Omega, v = Omega\n        from scipy.interpolate import InterpolatedUnivariateSpline\n        Omega_x = InterpolatedUnivariateSpline(t_Omega, v[:, 0])\n        Omega_y = InterpolatedUnivariateSpline(t_Omega, v[:, 1])\n        Omega_z = InterpolatedUnivariateSpline(t_Omega, v[:, 2])\n        def Omega_func(t, R):\n            return [Omega_x(t), Omega_y(t), Omega_z(t)]\n        Omega_func(t0, R0)\n        input_is_tabulated = True\n    except (TypeError, ValueError):\n        def Omega_func(t, R):\n            return Omega(t, R)\n        try:\n            Omega_func(t0, R0)\n        except TypeError:\n            def Omega_func(t, R):\n                return Omega(t)\n            Omega_func(t0, R0)\n\n    def RHS(t, y):\n        R = quaternion.quaternion(*y)\n        return (0.5 * quaternion.quaternion(0.0, *Omega_func(t, R)) * R).components\n\n    y0 = R0.components\n\n    if input_is_tabulated:\n        from scipy.integrate import solve_ivp\n        t = t_Omega\n        t_span = [t_Omega[0], t_Omega[-1]]\n        solution = solve_ivp(RHS, t_span, y0, t_eval=t_Omega, atol=tolerance, rtol=100*np.finfo(float).eps)\n        R = quaternion.from_float_array(solution.y.T)\n    else:\n        solver = ode(RHS)\n        solver.set_initial_value(y0, t0)\n        solver.set_integrator('dop853', nsteps=1, atol=tolerance, rtol=0.0)\n        solver._integrator.iwork[2] = -1  # suppress Fortran-printed warning\n        t = appending_array((int(t1-t0),))\n        t.append(solver.t)\n        R = appending_array((int(t1-t0), 4))\n        R.append(solver.y)\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        t_last = solver.t\n        while solver.t < t1:\n            solver.integrate(t1, step=True)\n            if solver.t > t_last:\n                t.append(solver.t)\n                R.append(solver.y)\n                t_last = solver.t\n        warnings.resetwarnings()\n        t = t.a\n        R = quaternion.as_quat_array(R.a)\n\n    return t, R"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef minimal_rotation(R, t, iterations=2):\n    from scipy.interpolate import InterpolatedUnivariateSpline as spline\n    if iterations == 0:\n        return R\n    R = quaternion.as_float_array(R)\n    Rdot = np.empty_like(R)\n    for i in range(4):\n        Rdot[:, i] = spline(t, R[:, i]).derivative()(t)\n    R = quaternion.from_float_array(R)\n    Rdot = quaternion.from_float_array(Rdot)\n    halfgammadot = quaternion.as_float_array(Rdot * quaternion.z * R.conjugate())[:, 0]\n    halfgamma = spline(t, halfgammadot).antiderivative()(t)\n    Rgamma = np.exp(quaternion.z * halfgamma)\n    return minimal_rotation(R * Rgamma, t, iterations=iterations-1)", "response": "Adjusts the frame so that there is no rotation about z axis and the angular velocity has no component along the z axis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the rotor that is closest to all R in the least - squares sense", "response": "def mean_rotor_in_chordal_metric(R, t=None):\n    \"\"\"Return rotor that is closest to all R in the least-squares sense\n\n    This can be done (quasi-)analytically because of the simplicity of\n    the chordal metric function.  The only approximation is the simple\n    2nd-order discrete formula for the definite integral of the input\n    rotor function.\n\n    Note that the `t` argument is optional.  If it is present, the\n    times are used to weight the corresponding integral.  If it is not\n    present, a simple sum is used instead (which may be slightly\n    faster).\n\n    \"\"\"\n    if not t:\n        return np.quaternion(*(np.sum(as_float_array(R)))).normalized()\n    mean = np.empty((4,), dtype=float)\n    definite_integral(as_float_array(R), t, mean)\n    return np.quaternion(*mean).normalized()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_float_array(a):\n    return np.asarray(a, dtype=np.quaternion).view((np.double, 4))", "response": "View the quaternion array as an array of floats"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef as_quat_array(a):\n    a = np.asarray(a, dtype=np.double)\n\n    # fast path\n    if a.shape == (4,):\n        return quaternion(a[0], a[1], a[2], a[3])\n\n    # view only works if the last axis is C-contiguous\n    if not a.flags['C_CONTIGUOUS'] or a.strides[-1] != a.itemsize:\n        a = a.copy(order='C')\n    try:\n        av = a.view(np.quaternion)\n    except ValueError as e:\n        message = (str(e) + '\\n            '\n                   + 'Failed to view input data as a series of quaternions.  '\n                   + 'Please ensure that the last dimension has size divisible by 4.\\n            '\n                   + 'Input data has shape {0} and dtype {1}.'.format(a.shape, a.dtype))\n        raise ValueError(message)\n\n    # special case: don't create an axis for a single quaternion, to\n    # match the output of `as_float_array`\n    if av.shape[-1] == 1:\n        av = av.reshape(a.shape[:-1])\n\n    return av", "response": "View a float array as an array of quaternions containing the last four components of the last order order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_spinor_array(a):\n    a = np.atleast_1d(a)\n    assert a.dtype == np.dtype(np.quaternion)\n    # I'm not sure why it has to be so complicated, but all of these steps\n    # appear to be necessary in this case.\n    return a.view(np.float).reshape(a.shape + (4,))[..., [0, 3, 2, 1]].ravel().view(np.complex).reshape(a.shape + (2,))", "response": "View a quaternion array as spinors in two - complex representation"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts input quaternion to 3x3 rotation matrix.", "response": "def as_rotation_matrix(q):\n    \"\"\"Convert input quaternion to 3x3 rotation matrix\n\n    Parameters\n    ----------\n    q: quaternion or array of quaternions\n        The quaternion(s) need not be normalized, but must all be nonzero\n\n    Returns\n    -------\n    rot: float array\n        Output shape is q.shape+(3,3).  This matrix should multiply (from\n        the left) a column vector to produce the rotated column vector.\n\n    Raises\n    ------\n    ZeroDivisionError\n        If any of the input quaternions have norm 0.0.\n\n    \"\"\"\n    if q.shape == () and not isinstance(q, np.ndarray):  # This is just a single quaternion\n        n = q.norm()\n        if n == 0.0:\n            raise ZeroDivisionError(\"Input to `as_rotation_matrix({0})` has zero norm\".format(q))\n        elif abs(n-1.0) < _eps:  # Input q is basically normalized\n            return np.array([\n                [1 - 2*(q.y**2 + q.z**2),   2*(q.x*q.y - q.z*q.w),      2*(q.x*q.z + q.y*q.w)],\n                [2*(q.x*q.y + q.z*q.w),     1 - 2*(q.x**2 + q.z**2),    2*(q.y*q.z - q.x*q.w)],\n                [2*(q.x*q.z - q.y*q.w),     2*(q.y*q.z + q.x*q.w),      1 - 2*(q.x**2 + q.y**2)]\n            ])\n        else:  # Input q is not normalized\n            return np.array([\n                [1 - 2*(q.y**2 + q.z**2)/n,   2*(q.x*q.y - q.z*q.w)/n,      2*(q.x*q.z + q.y*q.w)/n],\n                [2*(q.x*q.y + q.z*q.w)/n,     1 - 2*(q.x**2 + q.z**2)/n,    2*(q.y*q.z - q.x*q.w)/n],\n                [2*(q.x*q.z - q.y*q.w)/n,     2*(q.y*q.z + q.x*q.w)/n,      1 - 2*(q.x**2 + q.y**2)/n]\n            ])\n    else:  # This is an array of quaternions\n        n = np.norm(q)\n        if np.any(n == 0.0):\n            raise ZeroDivisionError(\"Array input to `as_rotation_matrix` has at least one element with zero norm\")\n        else:  # Assume input q is not normalized\n            m = np.empty(q.shape + (3, 3))\n            q = as_float_array(q)\n            m[..., 0, 0] = 1.0 - 2*(q[..., 2]**2 + q[..., 3]**2)/n\n            m[..., 0, 1] = 2*(q[..., 1]*q[..., 2] - q[..., 3]*q[..., 0])/n\n            m[..., 0, 2] = 2*(q[..., 1]*q[..., 3] + q[..., 2]*q[..., 0])/n\n            m[..., 1, 0] = 2*(q[..., 1]*q[..., 2] + q[..., 3]*q[..., 0])/n\n            m[..., 1, 1] = 1.0 - 2*(q[..., 1]**2 + q[..., 3]**2)/n\n            m[..., 1, 2] = 2*(q[..., 2]*q[..., 3] - q[..., 1]*q[..., 0])/n\n            m[..., 2, 0] = 2*(q[..., 1]*q[..., 3] - q[..., 2]*q[..., 0])/n\n            m[..., 2, 1] = 2*(q[..., 2]*q[..., 3] + q[..., 1]*q[..., 0])/n\n            m[..., 2, 2] = 1.0 - 2*(q[..., 1]**2 + q[..., 2]**2)/n\n            return m"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert input 3x3 rotation matrix to unit quaternion.", "response": "def from_rotation_matrix(rot, nonorthogonal=True):\n    \"\"\"Convert input 3x3 rotation matrix to unit quaternion\n\n    By default, if scipy.linalg is available, this function uses\n    Bar-Itzhack's algorithm to allow for non-orthogonal matrices.\n    [J. Guidance, Vol. 23, No. 6, p. 1085 <http://dx.doi.org/10.2514/2.4654>]\n    This will almost certainly be quite a bit slower than simpler versions,\n    though it will be more robust to numerical errors in the rotation matrix.\n    Also note that Bar-Itzhack uses some pretty weird conventions.  The last\n    component of the quaternion appears to represent the scalar, and the\n    quaternion itself is conjugated relative to the convention used\n    throughout this module.\n\n    If scipy.linalg is not available or if the optional\n    `nonorthogonal` parameter is set to `False`, this function falls\n    back to the possibly faster, but less robust, algorithm of Markley\n    [J. Guidance, Vol. 31, No. 2, p. 440\n    <http://dx.doi.org/10.2514/1.31730>].\n\n    Parameters\n    ----------\n    rot: (...Nx3x3) float array\n        Each 3x3 matrix represents a rotation by multiplying (from the left)\n        a column vector to produce a rotated column vector.  Note that this\n        input may actually have ndims>3; it is just assumed that the last\n        two dimensions have size 3, representing the matrix.\n    nonorthogonal: bool, optional\n        If scipy.linalg is available, use the more robust algorithm of\n        Bar-Itzhack.  Default value is True.\n\n    Returns\n    -------\n    q: array of quaternions\n        Unit quaternions resulting in rotations corresponding to input\n        rotations.  Output shape is rot.shape[:-2].\n\n    Raises\n    ------\n    LinAlgError\n        If any of the eigenvalue solutions does not converge\n\n    \"\"\"\n    try:\n        from scipy import linalg\n    except ImportError:\n        linalg = False\n\n    rot = np.array(rot, copy=False)\n    shape = rot.shape[:-2]\n\n    if linalg and nonorthogonal:\n        from operator import mul\n        from functools import reduce\n\n        K3 = np.empty(shape+(4, 4))\n        K3[..., 0, 0] = (rot[..., 0, 0] - rot[..., 1, 1] - rot[..., 2, 2])/3.0\n        K3[..., 0, 1] = (rot[..., 1, 0] + rot[..., 0, 1])/3.0\n        K3[..., 0, 2] = (rot[..., 2, 0] + rot[..., 0, 2])/3.0\n        K3[..., 0, 3] = (rot[..., 1, 2] - rot[..., 2, 1])/3.0\n        K3[..., 1, 0] = K3[..., 0, 1]\n        K3[..., 1, 1] = (rot[..., 1, 1] - rot[..., 0, 0] - rot[..., 2, 2])/3.0\n        K3[..., 1, 2] = (rot[..., 2, 1] + rot[..., 1, 2])/3.0\n        K3[..., 1, 3] = (rot[..., 2, 0] - rot[..., 0, 2])/3.0\n        K3[..., 2, 0] = K3[..., 0, 2]\n        K3[..., 2, 1] = K3[..., 1, 2]\n        K3[..., 2, 2] = (rot[..., 2, 2] - rot[..., 0, 0] - rot[..., 1, 1])/3.0\n        K3[..., 2, 3] = (rot[..., 0, 1] - rot[..., 1, 0])/3.0\n        K3[..., 3, 0] = K3[..., 0, 3]\n        K3[..., 3, 1] = K3[..., 1, 3]\n        K3[..., 3, 2] = K3[..., 2, 3]\n        K3[..., 3, 3] = (rot[..., 0, 0] + rot[..., 1, 1] + rot[..., 2, 2])/3.0\n\n        if not shape:\n            q = zero.copy()\n            eigvals, eigvecs = linalg.eigh(K3.T, eigvals=(3, 3))\n            q.components[0] = eigvecs[-1]\n            q.components[1:] = -eigvecs[:-1].flatten()\n            return q\n        else:\n            q = np.empty(shape+(4,), dtype=np.float)\n            for flat_index in range(reduce(mul, shape)):\n                multi_index = np.unravel_index(flat_index, shape)\n                eigvals, eigvecs = linalg.eigh(K3[multi_index], eigvals=(3, 3))\n                q[multi_index+(0,)] = eigvecs[-1]\n                q[multi_index+(slice(1,None),)] = -eigvecs[:-1].flatten()\n            return as_quat_array(q)\n\n    else:  # No scipy.linalg or not `nonorthogonal`\n        diagonals = np.empty(shape+(4,))\n        diagonals[..., 0] = rot[..., 0, 0]\n        diagonals[..., 1] = rot[..., 1, 1]\n        diagonals[..., 2] = rot[..., 2, 2]\n        diagonals[..., 3] = rot[..., 0, 0] + rot[..., 1, 1] + rot[..., 2, 2]\n\n        indices = np.argmax(diagonals, axis=-1)\n\n        q = diagonals  # reuse storage space\n        indices_i = (indices == 0)\n        if np.any(indices_i):\n            if indices_i.shape == ():\n                indices_i = Ellipsis\n            rot_i = rot[indices_i, :, :]\n            q[indices_i, 0] = rot_i[..., 2, 1] - rot_i[..., 1, 2]\n            q[indices_i, 1] = 1 + rot_i[..., 0, 0] - rot_i[..., 1, 1] - rot_i[..., 2, 2]\n            q[indices_i, 2] = rot_i[..., 0, 1] + rot_i[..., 1, 0]\n            q[indices_i, 3] = rot_i[..., 0, 2] + rot_i[..., 2, 0]\n        indices_i = (indices == 1)\n        if np.any(indices_i):\n            if indices_i.shape == ():\n                indices_i = Ellipsis\n            rot_i = rot[indices_i, :, :]\n            q[indices_i, 0] = rot_i[..., 0, 2] - rot_i[..., 2, 0]\n            q[indices_i, 1] = rot_i[..., 1, 0] + rot_i[..., 0, 1]\n            q[indices_i, 2] = 1 - rot_i[..., 0, 0] + rot_i[..., 1, 1] - rot_i[..., 2, 2]\n            q[indices_i, 3] = rot_i[..., 1, 2] + rot_i[..., 2, 1]\n        indices_i = (indices == 2)\n        if np.any(indices_i):\n            if indices_i.shape == ():\n                indices_i = Ellipsis\n            rot_i = rot[indices_i, :, :]\n            q[indices_i, 0] = rot_i[..., 1, 0] - rot_i[..., 0, 1]\n            q[indices_i, 1] = rot_i[..., 2, 0] + rot_i[..., 0, 2]\n            q[indices_i, 2] = rot_i[..., 2, 1] + rot_i[..., 1, 2]\n            q[indices_i, 3] = 1 - rot_i[..., 0, 0] - rot_i[..., 1, 1] + rot_i[..., 2, 2]\n        indices_i = (indices == 3)\n        if np.any(indices_i):\n            if indices_i.shape == ():\n                indices_i = Ellipsis\n            rot_i = rot[indices_i, :, :]\n            q[indices_i, 0] = 1 + rot_i[..., 0, 0] + rot_i[..., 1, 1] + rot_i[..., 2, 2]\n            q[indices_i, 1] = rot_i[..., 2, 1] - rot_i[..., 1, 2]\n            q[indices_i, 2] = rot_i[..., 0, 2] - rot_i[..., 2, 0]\n            q[indices_i, 3] = rot_i[..., 1, 0] - rot_i[..., 0, 1]\n\n        q /= np.linalg.norm(q, axis=-1)[..., np.newaxis]\n\n        return as_quat_array(q)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting input 3 - vector in axis - angle representation to unit quaternion.", "response": "def from_rotation_vector(rot):\n    \"\"\"Convert input 3-vector in axis-angle representation to unit quaternion\n\n    Parameters\n    ----------\n    rot: (Nx3) float array\n        Each vector represents the axis of the rotation, with norm\n        proportional to the angle of the rotation in radians.\n\n    Returns\n    -------\n    q: array of quaternions\n        Unit quaternions resulting in rotations corresponding to input\n        rotations.  Output shape is rot.shape[:-1].\n\n    \"\"\"\n    rot = np.array(rot, copy=False)\n    quats = np.zeros(rot.shape[:-1]+(4,))\n    quats[..., 1:] = rot[...]/2\n    quats = as_quat_array(quats)\n    return np.exp(quats)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens Pandora s Box .", "response": "def as_euler_angles(q):\n    \"\"\"Open Pandora's Box\n\n    If somebody is trying to make you use Euler angles, tell them no, and\n    walk away, and go and tell your mum.\n\n    You don't want to use Euler angles.  They are awful.  Stay away.  It's\n    one thing to convert from Euler angles to quaternions; at least you're\n    moving in the right direction.  But to go the other way?!  It's just not\n    right.\n\n    Assumes the Euler angles correspond to the quaternion R via\n\n        R = exp(alpha*z/2) * exp(beta*y/2) * exp(gamma*z/2)\n\n    The angles are naturally in radians.\n\n    NOTE: Before opening an issue reporting something \"wrong\" with this\n    function, be sure to read all of the following page, *especially* the\n    very last section about opening issues or pull requests.\n    <https://github.com/moble/quaternion/wiki/Euler-angles-are-horrible>\n\n    Parameters\n    ----------\n    q: quaternion or array of quaternions\n        The quaternion(s) need not be normalized, but must all be nonzero\n\n    Returns\n    -------\n    alpha_beta_gamma: float array\n        Output shape is q.shape+(3,).  These represent the angles (alpha,\n        beta, gamma) in radians, where the normalized input quaternion\n        represents `exp(alpha*z/2) * exp(beta*y/2) * exp(gamma*z/2)`.\n\n    Raises\n    ------\n    AllHell\n        ...if you try to actually use Euler angles, when you could have\n        been using quaternions like a sensible person.\n\n    \"\"\"\n    alpha_beta_gamma = np.empty(q.shape + (3,), dtype=np.float)\n    n = np.norm(q)\n    q = as_float_array(q)\n    alpha_beta_gamma[..., 0] = np.arctan2(q[..., 3], q[..., 0]) + np.arctan2(-q[..., 1], q[..., 2])\n    alpha_beta_gamma[..., 1] = 2*np.arccos(np.sqrt((q[..., 0]**2 + q[..., 3]**2)/n))\n    alpha_beta_gamma[..., 2] = np.arctan2(q[..., 3], q[..., 0]) - np.arctan2(-q[..., 1], q[..., 2])\n    return alpha_beta_gamma"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_euler_angles(alpha_beta_gamma, beta=None, gamma=None):\n    # Figure out the input angles from either type of input\n    if gamma is None:\n        alpha_beta_gamma = np.asarray(alpha_beta_gamma, dtype=np.double)\n        alpha = alpha_beta_gamma[..., 0]\n        beta  = alpha_beta_gamma[..., 1]\n        gamma = alpha_beta_gamma[..., 2]\n    else:\n        alpha = np.asarray(alpha_beta_gamma, dtype=np.double)\n        beta  = np.asarray(beta, dtype=np.double)\n        gamma = np.asarray(gamma, dtype=np.double)\n\n    # Set up the output array\n    R = np.empty(np.broadcast(alpha, beta, gamma).shape + (4,), dtype=np.double)\n\n    # Compute the actual values of the quaternion components\n    R[..., 0] =  np.cos(beta/2)*np.cos((alpha+gamma)/2)  # scalar quaternion components\n    R[..., 1] = -np.sin(beta/2)*np.sin((alpha-gamma)/2)  # x quaternion components\n    R[..., 2] =  np.sin(beta/2)*np.cos((alpha-gamma)/2)  # y quaternion components\n    R[..., 3] =  np.cos(beta/2)*np.sin((alpha+gamma)/2)  # z quaternion components\n\n    return as_quat_array(R)", "response": "Improve your life drastically\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_spherical_coords(theta_phi, phi=None):\n    # Figure out the input angles from either type of input\n    if phi is None:\n        theta_phi = np.asarray(theta_phi, dtype=np.double)\n        theta = theta_phi[..., 0]\n        phi  = theta_phi[..., 1]\n    else:\n        theta = np.asarray(theta_phi, dtype=np.double)\n        phi = np.asarray(phi, dtype=np.double)\n\n    # Set up the output array\n    R = np.empty(np.broadcast(theta, phi).shape + (4,), dtype=np.double)\n\n    # Compute the actual values of the quaternion components\n    R[..., 0] =  np.cos(phi/2)*np.cos(theta/2)  # scalar quaternion components\n    R[..., 1] = -np.sin(phi/2)*np.sin(theta/2)  # x quaternion components\n    R[..., 2] =  np.cos(phi/2)*np.sin(theta/2)  # y quaternion components\n    R[..., 3] =  np.sin(phi/2)*np.cos(theta/2)  # z quaternion components\n\n    return as_quat_array(R)", "response": "Return the quaternion corresponding to these spherical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrotates vectors by given quaternions For simplicity, this function simply converts the input quaternion(s) to a matrix, and rotates the input vector(s) by the usual matrix multiplication. However, it should be noted that if each input quaternion is only used to rotate a single vector, it is more efficient (in terms of operation counts) to use the formula v' = v + 2 * r x (s * v + r x v) / m where x represents the cross product, s and r are the scalar and vector parts of the quaternion, respectively, and m is the sum of the squares of the components of the quaternion. If you are looping over a very large number of quaternions, and just rotating a single vector each time, you might want to implement that alternative algorithm using numba (or something that doesn't use python). Parameters ========== R: quaternion array Quaternions by which to rotate the input vectors v: float array Three-vectors to be rotated. axis: int Axis of the `v` array to use as the vector dimension. This axis of `v` must have length 3. Returns ======= vprime: float array The rotated vectors. This array has shape R.shape+v.shape.", "response": "def rotate_vectors(R, v, axis=-1):\n    \"\"\"Rotate vectors by given quaternions\n\n    For simplicity, this function simply converts the input\n    quaternion(s) to a matrix, and rotates the input vector(s) by the\n    usual matrix multiplication.  However, it should be noted that if\n    each input quaternion is only used to rotate a single vector, it\n    is more efficient (in terms of operation counts) to use the\n    formula\n\n      v' = v + 2 * r x (s * v + r x v) / m\n\n    where x represents the cross product, s and r are the scalar and\n    vector parts of the quaternion, respectively, and m is the sum of\n    the squares of the components of the quaternion.  If you are\n    looping over a very large number of quaternions, and just rotating\n    a single vector each time, you might want to implement that\n    alternative algorithm using numba (or something that doesn't use\n    python).\n\n\n    Parameters\n    ==========\n    R: quaternion array\n        Quaternions by which to rotate the input vectors\n    v: float array\n        Three-vectors to be rotated.\n    axis: int\n        Axis of the `v` array to use as the vector dimension.  This\n        axis of `v` must have length 3.\n\n    Returns\n    =======\n    vprime: float array\n        The rotated vectors.  This array has shape R.shape+v.shape.\n\n    \"\"\"\n    R = np.asarray(R, dtype=np.quaternion)\n    v = np.asarray(v, dtype=float)\n    if v.ndim < 1 or 3 not in v.shape:\n        raise ValueError(\"Input `v` does not have at least one dimension of length 3\")\n    if v.shape[axis] != 3:\n        raise ValueError(\"Input `v` axis {0} has length {1}, not 3.\".format(axis, v.shape[axis]))\n    m = as_rotation_matrix(R)\n    m_axes = list(range(m.ndim))\n    v_axes = list(range(m.ndim, m.ndim+v.ndim))\n    mv_axes = list(v_axes)\n    mv_axes[axis] = m_axes[-2]\n    mv_axes = m_axes[:-2] + mv_axes\n    v_axes[axis] = m_axes[-1]\n    return np.einsum(m, m_axes, v, v_axes, mv_axes)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef isclose(a, b, rtol=4*np.finfo(float).eps, atol=0.0, equal_nan=False):\n    def within_tol(x, y, atol, rtol):\n        with np.errstate(invalid='ignore'):\n            result = np.less_equal(abs(x-y), atol + rtol * abs(y))\n        if np.isscalar(a) and np.isscalar(b):\n            result = bool(result)\n        return result\n\n    x = np.array(a, copy=False, subok=True, ndmin=1)\n    y = np.array(b, copy=False, subok=True, ndmin=1)\n\n    # Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\n    # This will cause casting of x later. Also, make sure to allow subclasses\n    # (e.g., for numpy.ma).\n    try:\n        dt = np.result_type(y, 1.)\n    except TypeError:\n        dt = np.dtype(np.quaternion)\n    y = np.array(y, dtype=dt, copy=False, subok=True)\n\n    xfin = np.isfinite(x)\n    yfin = np.isfinite(y)\n    if np.all(xfin) and np.all(yfin):\n        return within_tol(x, y, atol, rtol)\n    else:\n        finite = xfin & yfin\n        cond = np.zeros_like(finite, subok=True)\n        # Because we're using boolean indexing, x & y must be the same shape.\n        # Ideally, we'd just do x, y = broadcast_arrays(x, y). It's in\n        # lib.stride_tricks, though, so we can't import it here.\n        x = x * np.ones_like(cond)\n        y = y * np.ones_like(cond)\n        # Avoid subtraction with infinite/nan values...\n        cond[finite] = within_tol(x[finite], y[finite], atol, rtol)\n        # Check for equality of infinite values...\n        cond[~finite] = (x[~finite] == y[~finite])\n        if equal_nan:\n            # Make NaN == NaN\n            both_nan = np.isnan(x) & np.isnan(y)\n            cond[both_nan] = both_nan[both_nan]\n\n        if np.isscalar(a) and np.isscalar(b):\n            return bool(cond)\n        else:\n            return cond", "response": "This function returns a numpy. isclose function that returns a copy of the array a and b where two arrays are element - wise equal within rtol and atol."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef allclose(a, b, rtol=4*np.finfo(float).eps, atol=0.0, equal_nan=False, verbose=False):\n    close = isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)\n    result = np.all(close)\n    if verbose and not result:\n        print('Non-close values:')\n        for i in np.argwhere(close == False):\n            i = tuple(i)\n            print('\\n    x[{0}]={1}\\n    y[{0}]={2}'.format(i, a[i], b[i]))\n    return result", "response": "Returns a single boolean value of True if all elements in two arrays are element - wise equal within a given absolute tolerance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(model_or_iterable, **options):\n    from modeltranslation.translator import translator, TranslationOptions\n\n    def wrapper(opts_class):\n        if not issubclass(opts_class, TranslationOptions):\n            raise ValueError('Wrapped class must subclass TranslationOptions.')\n        translator.register(model_or_iterable, opts_class, **options)\n        return opts_class\n\n    return wrapper", "response": "Decorator for creating a new object that can be used to translate a list of models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an active language code that is guaranteed to be in settings. LANGUAGES.", "response": "def get_language():\n    \"\"\"\n    Return an active language code that is guaranteed to be in\n    settings.LANGUAGES (Django does not seem to guarantee this for us).\n    \"\"\"\n    lang = _get_language()\n    if lang is None:  # Django >= 1.8\n        return settings.DEFAULT_LANGUAGE\n    if lang not in settings.AVAILABLE_LANGUAGES and '-' in lang:\n        lang = lang.split('-')[0]\n    if lang in settings.AVAILABLE_LANGUAGES:\n        return lang\n    return settings.DEFAULT_LANGUAGE"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_css_class(localized_fieldname, prefix=''):\n    bits = localized_fieldname.split('_')\n    css_class = ''\n    if len(bits) == 1:\n        css_class = str(localized_fieldname)\n    elif len(bits) == 2:\n        # Fieldname without underscore and short language code\n        # Examples:\n        # 'foo_de' --> 'foo-de',\n        # 'bar_en' --> 'bar-en'\n        css_class = '-'.join(bits)\n    elif len(bits) > 2:\n        # Try regionalized language code\n        # Examples:\n        # 'foo_es_ar' --> 'foo-es_ar',\n        # 'foo_bar_zh_tw' --> 'foo_bar-zh_tw'\n        css_class = _join_css_class(bits, 2)\n        if not css_class:\n            # Try short language code\n            # Examples:\n            # 'foo_bar_de' --> 'foo_bar-de',\n            # 'foo_bar_baz_de' --> 'foo_bar_baz-de'\n            css_class = _join_css_class(bits, 1)\n    return '%s-%s' % (prefix, css_class) if prefix else css_class", "response": "Builds a css class based on a localized field name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a generator yielding unique values in order.", "response": "def unique(seq):\n    \"\"\"\n    Returns a generator yielding unique sequence members in order\n\n    A set by itself will return unique values without any regard for order.\n\n    >>> list(unique([1, 2, 3, 2, 2, 4, 1]))\n    [1, 2, 3, 4]\n    \"\"\"\n    seen = set()\n    return (x for x in seq if x not in seen and not seen.add(x))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolution_order(lang, override=None):\n    if not settings.ENABLE_FALLBACKS:\n        return (lang,)\n    if override is None:\n        override = {}\n    fallback_for_lang = override.get(lang, settings.FALLBACK_LANGUAGES.get(lang, ()))\n    fallback_def = override.get('default', settings.FALLBACK_LANGUAGES['default'])\n    order = (lang,) + fallback_for_lang + fallback_def\n    return tuple(unique(order))", "response": "Return order of languages which should be checked for parameter language."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auto_populate(mode='all'):\n    current_population_mode = settings.AUTO_POPULATE\n    settings.AUTO_POPULATE = mode\n    try:\n        yield\n    finally:\n        settings.AUTO_POPULATE = current_population_mode", "response": "A context manager that automatically populates the language of the untranslated fixtures."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts result from single - value or dict - type setting like fallback_values.", "response": "def parse_field(setting, field_name, default):\n    \"\"\"\n    Extract result from single-value or dict-type setting like fallback_values.\n    \"\"\"\n    if isinstance(setting, dict):\n        return setting.get(field_name, default)\n    else:\n        return setting"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding all translated fields to the given set of fields.", "response": "def append_fallback(model, fields):\n    \"\"\"\n    If translated field is encountered, add also all its fallback fields.\n    Returns tuple: (set_of_new_fields_to_use, set_of_translated_field_names)\n    \"\"\"\n    fields = set(fields)\n    trans = set()\n    from modeltranslation.translator import translator\n    opts = translator.get_options_for_model(model)\n    for key, _ in opts.fields.items():\n        if key in fields:\n            langs = resolution_order(get_language(), getattr(model, key).fallback_languages)\n            fields = fields.union(build_localized_fieldname(key, lang) for lang in langs)\n            fields.remove(key)\n            trans.add(key)\n    return fields, trans"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef append_translated(model, fields):\n    \"If translated field is encountered, add also all its translation fields.\"\n    fields = set(fields)\n    from modeltranslation.translator import translator\n    opts = translator.get_options_for_model(model)\n    for key, translated in opts.fields.items():\n        if key in fields:\n            fields = fields.union(f.name for f in translated)\n    return fields", "response": "If translated field is encountered add also all its translation fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform spanned__lookup__key into all possible translation versions on all levels", "response": "def append_lookup_key(model, lookup_key):\n    \"Transform spanned__lookup__key into all possible translation versions, on all levels\"\n    pieces = lookup_key.split('__', 1)\n\n    fields = append_translated(model, (pieces[0],))\n\n    if len(pieces) > 1:\n        # Check if we are doing a lookup to a related trans model\n        fields_to_trans_models = get_fields_to_translatable_models(model)\n        if pieces[0] in fields_to_trans_models:\n            transmodel = fields_to_trans_models[pieces[0]]\n            rest = append_lookup_key(transmodel, pieces[1])\n            fields = set('__'.join(pr) for pr in itertools.product(fields, rest))\n        else:\n            fields = set('%s__%s' % (f, pieces[1]) for f in fields)\n    return fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrewrite fields in already applied filters and ordering.", "response": "def _rewrite_applied_operations(self):\n        \"\"\"\n        Rewrite fields in already applied filters/ordering.\n        Useful when converting any QuerySet into MultilingualQuerySet.\n        \"\"\"\n        self._rewrite_where(self.query.where)\n        self._rewrite_order()\n        self._rewrite_select_related()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrewrites field names inside WHERE tree.", "response": "def _rewrite_where(self, q):\n        \"\"\"\n        Rewrite field names inside WHERE tree.\n        \"\"\"\n        if isinstance(q, Lookup):\n            self._rewrite_col(q.lhs)\n        if isinstance(q, Node):\n            for child in q.children:\n                self._rewrite_where(child)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrewrites field names inside Q call.", "response": "def _rewrite_q(self, q):\n        \"\"\"Rewrite field names inside Q call.\"\"\"\n        if isinstance(q, tuple) and len(q) == 2:\n            return rewrite_lookup_key(self.model, q[0]), q[1]\n        if isinstance(q, Node):\n            q.children = list(map(self._rewrite_q, q.children))\n        return q"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _rewrite_f(self, q):\n        if isinstance(q, models.F):\n            q.name = rewrite_lookup_key(self.model, q.name)\n            return q\n        if isinstance(q, Node):\n            q.children = list(map(self._rewrite_f, q.children))\n        # Django >= 1.8\n        if hasattr(q, 'lhs'):\n            q.lhs = self._rewrite_f(q.lhs)\n        if hasattr(q, 'rhs'):\n            q.rhs = self._rewrite_f(q.rhs)\n        return q", "response": "Rewrite field names inside F call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding the default order_by method to rewrite the field names in an order_by argument.", "response": "def order_by(self, *field_names):\n        \"\"\"\n        Change translatable field names in an ``order_by`` argument\n        to translation fields for the current language.\n        \"\"\"\n        if not self._rewrite:\n            return super(MultilingualQuerySet, self).order_by(*field_names)\n        new_args = []\n        for key in field_names:\n            new_args.append(rewrite_order_lookup_key(self.model, key))\n        return super(MultilingualQuerySet, self).order_by(*new_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new MultilingualQuerySet.", "response": "def create(self, **kwargs):\n        \"\"\"\n        Allows to override population mode with a ``populate`` method.\n        \"\"\"\n        with auto_populate(self._populate_mode):\n            return super(MultilingualQuerySet, self).create(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides the default get_or_create method to override population mode.", "response": "def get_or_create(self, **kwargs):\n        \"\"\"\n        Allows to override population mode with a ``populate`` method.\n        \"\"\"\n        with auto_populate(self._populate_mode):\n            return super(MultilingualQuerySet, self).get_or_create(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_translation_fields(model, opts):\n    model_empty_values = getattr(opts, 'empty_values', NONE)\n    for field_name in opts.local_fields.keys():\n        field_empty_value = parse_field(model_empty_values, field_name, NONE)\n        for l in mt_settings.AVAILABLE_LANGUAGES:\n            # Create a dynamic translation field\n            translation_field = create_translation_field(\n                model=model, field_name=field_name, lang=l, empty_value=field_empty_value)\n            # Construct the name for the localized field\n            localized_field_name = build_localized_fieldname(field_name, l)\n            # Check if the model already has a field by that name\n\n            if hasattr(model, localized_field_name):\n                # Check if are not dealing with abstract field inherited.\n                for cls in model.__mro__:\n                    if hasattr(cls, '_meta') and cls.__dict__.get(localized_field_name, None):\n                        cls_opts = translator._get_options_for_model(cls)\n                        if not cls._meta.abstract or field_name not in cls_opts.local_fields:\n                            raise ValueError(\"Error adding translation field. Model '%s' already\"\n                                             \" contains a field named '%s'.\" %\n                                             (model._meta.object_name, localized_field_name))\n            # This approach implements the translation fields as full valid\n            # django model fields and therefore adds them via add_to_class\n            model.add_to_class(localized_field_name, translation_field)\n            opts.add_translation_field(field_name, translation_field)\n\n    # Rebuild information about parents fields. If there are opts.local_fields, field cache would be\n    # invalidated (by model._meta.add_field() function). Otherwise, we need to do it manually.\n    if len(opts.local_fields) == 0:\n        model._meta._expire_cache()\n        model._meta.get_fields()", "response": "Adds new translation fields to the given model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether manager ( or its parents ) has declared some custom get_queryset method.", "response": "def has_custom_queryset(manager):\n    \"Check whether manager (or its parents) has declared some custom get_queryset method.\"\n    old_diff = getattr(manager, 'get_query_set', None) != getattr(Manager, 'get_query_set', None)\n    new_diff = getattr(manager, 'get_queryset', None) != getattr(Manager, 'get_queryset', None)\n    return old_diff or new_diff"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_manager(model):\n    if model._meta.abstract:\n        return\n    # Make all managers local for this model to fix patching parent model managers\n    model._meta.local_managers = model._meta.managers\n\n    for current_manager in model._meta.local_managers:\n        prev_class = current_manager.__class__\n        patch_manager_class(current_manager)\n        if model._default_manager.__class__ is prev_class:\n            # Normally model._default_manager is a reference to one of model's managers\n            # (and would be patched by the way).\n            # However, in some rare situations (mostly proxy models)\n            # model._default_manager is not the same instance as one of managers, but it\n            # share the same class.\n            model._default_manager.__class__ = current_manager.__class__\n    patch_manager_class(model._base_manager)\n    model._meta.base_manager_name = 'objects'\n    model._meta._expire_cache()", "response": "Adds a manager to the multilingual model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmonkey patches the original model to rewrite fields names in __init__", "response": "def patch_constructor(model):\n    \"\"\"\n    Monkey patches the original model to rewrite fields names in __init__\n    \"\"\"\n    old_init = model.__init__\n\n    def new_init(self, *args, **kwargs):\n        self._mt_init = True\n        populate_translation_fields(self.__class__, kwargs)\n        for key, val in list(kwargs.items()):\n            new_key = rewrite_lookup_key(model, key)\n            # Old key is intentionally left in case old_init wants to play with it\n            kwargs.setdefault(new_key, val)\n        old_init(self, *args, **kwargs)\n    model.__init__ = new_init"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npatches clean_fields method to handle different form types submission.", "response": "def patch_clean_fields(model):\n    \"\"\"\n    Patch clean_fields method to handle different form types submission.\n    \"\"\"\n    old_clean_fields = model.clean_fields\n\n    def new_clean_fields(self, exclude=None):\n        if hasattr(self, '_mt_form_pending_clear'):\n            # Some form translation fields has been marked as clearing value.\n            # Check if corresponding translated field was also saved (not excluded):\n            # - if yes, it seems like form for MT-unaware app. Ignore clearing (left value from\n            #   translated field unchanged), as if field was omitted from form\n            # - if no, then proceed as normally: clear the field\n            for field_name, value in self._mt_form_pending_clear.items():\n                field = self._meta.get_field(field_name)\n                orig_field_name = field.translated_field.name\n                if orig_field_name in exclude:\n                    field.save_form_data(self, value, check=False)\n            delattr(self, '_mt_form_pending_clear')\n        old_clean_fields(self, exclude)\n    model.clean_fields = new_clean_fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npatch Django > = 1. 8 to detect deferred fields. Crucial for only and defer to work.", "response": "def patch_get_deferred_fields(model):\n    \"\"\"\n    Django >= 1.8: patch detecting deferred fields. Crucial for only/defer to work.\n    \"\"\"\n    if not hasattr(model, 'get_deferred_fields'):\n        return\n    old_get_deferred_fields = model.get_deferred_fields\n\n    def new_get_deferred_fields(self):\n        sup = old_get_deferred_fields(self)\n        if hasattr(self, '_fields_were_deferred'):\n            sup.update(self._fields_were_deferred)\n        return sup\n    model.get_deferred_fields = new_get_deferred_fields"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef patch_refresh_from_db(model):\n    if not hasattr(model, 'refresh_from_db'):\n        return\n    old_refresh_from_db = model.refresh_from_db\n\n    def new_refresh_from_db(self, using=None, fields=None):\n        if fields is not None:\n            fields = append_translated(self.__class__, fields)\n        return old_refresh_from_db(self, using, fields)\n    model.refresh_from_db = new_refresh_from_db", "response": "Patch refresh_from_db to add translated fields to the list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef populate_translation_fields(sender, kwargs):\n    populate = mt_settings.AUTO_POPULATE\n    if not populate:\n        return\n    if populate is True:\n        # What was meant by ``True`` is now called ``all``.\n        populate = 'all'\n\n    opts = translator.get_options_for_model(sender)\n    for key, val in list(kwargs.items()):\n        if key in opts.fields:\n            if populate == 'all':\n                # Set the value for every language.\n                for translation_field in opts.fields[key]:\n                    kwargs.setdefault(translation_field.name, val)\n            elif populate == 'default':\n                default = build_localized_fieldname(key, mt_settings.DEFAULT_LANGUAGE)\n                kwargs.setdefault(default, val)\n            elif populate == 'required':\n                default = build_localized_fieldname(key, mt_settings.DEFAULT_LANGUAGE)\n                if not sender._meta.get_field(key).null:\n                    kwargs.setdefault(default, val)\n            else:\n                raise AttributeError(\"Unknown population mode '%s'.\" % populate)", "response": "Populate the translation fields of the untranslated object with the values provided in kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npatch SingleRelatedObjectDescriptor or ReverseSingleRelatedObjectDescriptor to use ArcGIS language - aware caching.", "response": "def patch_related_object_descriptor_caching(ro_descriptor):\n    \"\"\"\n    Patch SingleRelatedObjectDescriptor or ReverseSingleRelatedObjectDescriptor to use\n    language-aware caching.\n    \"\"\"\n    class NewSingleObjectDescriptor(LanguageCacheSingleObjectDescriptor, ro_descriptor.__class__):\n        pass\n\n    if django.VERSION[0] == 2:\n        ro_descriptor.related.get_cache_name = partial(\n            NewSingleObjectDescriptor.get_cache_name,\n            ro_descriptor,\n        )\n\n    ro_descriptor.accessor = ro_descriptor.related.get_accessor_name()\n    ro_descriptor.__class__ = NewSingleObjectDescriptor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates with options from a superclass.", "response": "def update(self, other):\n        \"\"\"\n        Update with options from a superclass.\n        \"\"\"\n        if other.model._meta.abstract:\n            self.local_fields.update(other.local_fields)\n        self.fields.update(other.fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new translation field to both fields dicts.", "response": "def add_translation_field(self, field, translation_field):\n        \"\"\"\n        Add a new translation field to both fields dicts.\n        \"\"\"\n        self.local_fields[field].add(translation_field)\n        self.fields[field].add(translation_field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters the given models with the given options.", "response": "def register(self, model_or_iterable, opts_class=None, **options):\n        \"\"\"\n        Registers the given model(s) with the given translation options.\n\n        The model(s) should be Model classes, not instances.\n\n        Fields declared for translation on a base class are inherited by\n        subclasses. If the model or one of its subclasses is already\n        registered for translation, this will raise an exception.\n        \"\"\"\n        if isinstance(model_or_iterable, ModelBase):\n            model_or_iterable = [model_or_iterable]\n\n        for model in model_or_iterable:\n            # Ensure that a base is not registered after a subclass (_registry\n            # is closed with respect to taking bases, so we can just check if\n            # we've seen the model).\n            if model in self._registry:\n                if self._registry[model].registered:\n                    raise AlreadyRegistered(\n                        'Model \"%s\" is already registered for translation' %\n                        model.__name__)\n                else:\n                    descendants = [d.__name__ for d in self._registry.keys()\n                                   if issubclass(d, model) and d != model]\n                    if descendants:\n                        raise DescendantRegistered(\n                            'Model \"%s\" cannot be registered after its subclass'\n                            ' \"%s\"' % (model.__name__, descendants[0]))\n\n            # Find inherited fields and create options instance for the model.\n            opts = self._get_options_for_model(model, opts_class, **options)\n\n            # If an exception is raised during registration, mark model as not-registered\n            try:\n                self._register_single_model(model, opts)\n            except Exception:\n                self._registry[model].registered = False\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_registered_models(self, abstract=True):\n        return [model for (model, opts) in self._registry.items()\n                if opts.registered and (not model._meta.abstract or abstract)]", "response": "Returns a list of all registered models."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an instance of TranslationOptions with translated fields defined for the model and inherited from superclasses.", "response": "def _get_options_for_model(self, model, opts_class=None, **options):\n        \"\"\"\n        Returns an instance of translation options with translated fields\n        defined for the ``model`` and inherited from superclasses.\n        \"\"\"\n        if model not in self._registry:\n            # Create a new type for backwards compatibility.\n            opts = type(\"%sTranslationOptions\" % model.__name__,\n                        (opts_class or TranslationOptions,), options)(model)\n\n            # Fields for translation may be inherited from abstract\n            # superclasses, so we need to look at all parents.\n            for base in model.__bases__:\n                if not hasattr(base, '_meta'):\n                    # Things without _meta aren't functional models, so they're\n                    # uninteresting parents.\n                    continue\n                opts.update(self._get_options_for_model(base))\n\n            # Cache options for all models -- we may want to compute options\n            # of registered subclasses of unregistered models.\n            self._registry[model] = opts\n\n        return self._registry[model]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_options_for_model(self, model):\n        opts = self._get_options_for_model(model)\n        if not opts.registered and not opts.related:\n            raise NotRegistered('The model \"%s\" is not registered for '\n                                'translation' % model.__name__)\n        return opts", "response": "Returns a dictionary of options for the given model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version(version=None):\n    if version is None:\n        from modeltranslation import VERSION as version\n    else:\n        assert len(version) == 5\n        assert version[3] in ('alpha', 'beta', 'rc', 'final')\n\n    # Now build the two parts of the version number:\n    # main = X.Y[.Z]\n    # sub = .devN - for pre-alpha releases\n    #     | {a|b|c}N - for alpha, beta and rc releases\n\n    parts = 2 if version[2] == 0 else 3\n    main = '.'.join(str(x) for x in version[:parts])\n\n    sub = ''\n    if version[3] == 'alpha' and version[4] == 0:\n        git_changeset = get_git_changeset()\n        if git_changeset:\n            sub = '.dev%s' % git_changeset\n\n    elif version[3] != 'final':\n        mapping = {'alpha': 'a', 'beta': 'b', 'rc': 'rc'}\n        sub = mapping[version[3]] + str(version[4])\n\n    return str(main + sub)", "response": "Returns a PEP 386 - compliant version number from VERSION."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(self, *args, **options):\n        self.cursor = connection.cursor()\n        self.introspection = connection.introspection\n        self.interactive = options['interactive']\n\n        found_missing_fields = False\n        models = translator.get_registered_models(abstract=False)\n        for model in models:\n            db_table = model._meta.db_table\n            model_name = model._meta.model_name\n            model_full_name = '%s.%s' % (model._meta.app_label, model_name)\n            opts = translator.get_options_for_model(model)\n            for field_name, fields in opts.local_fields.items():\n                # Take `db_column` attribute into account\n                try:\n                    field = list(fields)[0]\n                except IndexError:\n                    # Ignore IndexError for ProxyModel\n                    # maybe there is better way to handle this\n                    continue\n                column_name = field.db_column if field.db_column else field_name\n                missing_langs = list(self.get_missing_languages(column_name, db_table))\n                if missing_langs:\n                    found_missing_fields = True\n                    print_missing_langs(missing_langs, field_name, model_full_name)\n                    sql_sentences = self.get_sync_sql(field_name, missing_langs, model)\n                    execute_sql = ask_for_confirmation(\n                        sql_sentences, model_full_name, self.interactive)\n                    if execute_sql:\n                        print('Executing SQL...')\n                        for sentence in sql_sentences:\n                            self.cursor.execute(sentence)\n                        print('Done')\n                    else:\n                        print('SQL not executed')\n\n        if not found_missing_fields:\n            print('No new translatable fields detected')", "response": "Handles the command execution."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_table_fields(self, db_table):\n        db_table_desc = self.introspection.get_table_description(self.cursor, db_table)\n        return [t[0] for t in db_table_desc]", "response": "Gets table fields from schema.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets only missings fields.", "response": "def get_missing_languages(self, field_name, db_table):\n        \"\"\"\n        Gets only missings fields.\n        \"\"\"\n        db_table_fields = self.get_table_fields(db_table)\n        for lang_code in AVAILABLE_LANGUAGES:\n            if build_localized_fieldname(field_name, lang_code) not in db_table_fields:\n                yield lang_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sync_sql(self, field_name, missing_langs, model):\n        qn = connection.ops.quote_name\n        style = no_style()\n        sql_output = []\n        db_table = model._meta.db_table\n        for lang in missing_langs:\n            new_field = build_localized_fieldname(field_name, lang)\n            f = model._meta.get_field(new_field)\n            col_type = f.db_type(connection=connection)\n            field_sql = [style.SQL_FIELD(qn(f.column)), style.SQL_COLTYPE(col_type)]\n            # column creation\n            stmt = \"ALTER TABLE %s ADD COLUMN %s\" % (qn(db_table), ' '.join(field_sql))\n            if not f.null:\n                stmt += \" \" + style.SQL_KEYWORD('NOT NULL')\n            sql_output.append(stmt + \";\")\n        return sql_output", "response": "Returns SQL needed for sync schema for a new translatable field."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a translation field based on a model and a language.", "response": "def create_translation_field(model, field_name, lang, empty_value):\n    \"\"\"\n    Translation field factory. Returns a ``TranslationField`` based on a\n    fieldname and a language.\n\n    The list of supported fields can be extended by defining a tuple of field\n    names in the projects settings.py like this::\n\n        MODELTRANSLATION_CUSTOM_FIELDS = ('MyField', 'MyOtherField',)\n\n    If the class is neither a subclass of fields in ``SUPPORTED_FIELDS``, nor\n    in ``CUSTOM_FIELDS`` an ``ImproperlyConfigured`` exception will be raised.\n    \"\"\"\n    if empty_value not in ('', 'both', None, NONE):\n        raise ImproperlyConfigured('%s is not a valid empty_value.' % empty_value)\n    field = model._meta.get_field(field_name)\n    cls_name = field.__class__.__name__\n    if not (isinstance(field, SUPPORTED_FIELDS) or cls_name in mt_settings.CUSTOM_FIELDS):\n        raise ImproperlyConfigured(\n            '%s is not supported by modeltranslation.' % cls_name)\n    translation_class = field_factory(field.__class__)\n    return translation_class(translated_field=field, language=lang, empty_value=empty_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns proper formfield according to empty_values setting.", "response": "def formfield(self, *args, **kwargs):\n        \"\"\"\n        Returns proper formfield, according to empty_values setting\n        (only for ``forms.CharField`` subclasses).\n\n        There are 3 different formfields:\n        - CharField that stores all empty values as empty strings;\n        - NullCharField that stores all empty values as None (Null);\n        - NullableField that can store both None and empty string.\n\n        By default, if no empty_values was specified in model's translation options,\n        NullCharField would be used if the original field is nullable, CharField otherwise.\n\n        This can be overridden by setting empty_values to '' or None.\n\n        Setting 'both' will result in NullableField being used.\n        Textual widgets (subclassing ``TextInput`` or ``Textarea``) used for\n        nullable fields are enriched with a clear checkbox, allowing ``None``\n        values to be preserved rather than saved as empty strings.\n\n        The ``forms.CharField`` somewhat surprising behaviour is documented as a\n        \"won't fix\": https://code.djangoproject.com/ticket/9590.\n        \"\"\"\n        formfield = super(TranslationField, self).formfield(*args, **kwargs)\n        if isinstance(formfield, forms.CharField):\n            if self.empty_value is None:\n                from modeltranslation.forms import NullCharField\n                form_class = formfield.__class__\n                kwargs['form_class'] = type(\n                    'Null%s' % form_class.__name__, (NullCharField, form_class), {})\n                formfield = super(TranslationField, self).formfield(*args, **kwargs)\n            elif self.empty_value == 'both':\n                from modeltranslation.forms import NullableField\n                form_class = formfield.__class__\n                kwargs['form_class'] = type(\n                    'Nullable%s' % form_class.__name__, (NullableField, form_class), {})\n                formfield = super(TranslationField, self).formfield(*args, **kwargs)\n                if isinstance(formfield.widget, (forms.TextInput, forms.Textarea)):\n                    formfield.widget = ClearableWidgetWrapper(formfield.widget)\n        return formfield"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef south_field_triple(self):\n        # We'll just introspect the _actual_ field.\n        from south.modelsinspector import introspector\n        try:\n            # Check if the field provides its own 'field_class':\n            field_class = self.translated_field.south_field_triple()[0]\n        except AttributeError:\n            field_class = '%s.%s' % (self.translated_field.__class__.__module__,\n                                     self.translated_field.__class__.__name__)\n        args, kwargs = introspector(self)\n        # That's our definition!\n        return (field_class, args, kwargs)", "response": "Returns a suitable description of this field for South."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef meaningful_value(self, val, undefined):\n        if isinstance(val, fields.files.FieldFile):\n            return val.name and not (\n                isinstance(undefined, fields.files.FieldFile) and val == undefined)\n        return val is not None and val != undefined", "response": "Check if the value is meaningful."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cache_name(self):\n        lang = get_language()\n        cache = build_localized_fieldname(self.accessor, lang)\n        return \"_%s_cache\" % cache", "response": "Return the cache name for this object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_orig_field(self, option):\n        if option:\n            option_new = list(option)\n            for opt in option:\n                if opt in self.trans_opts.fields:\n                    index = option_new.index(opt)\n                    option_new[index:index + 1] = get_translation_fields(opt)\n                elif isinstance(opt, (tuple, list)) and (\n                        [o for o in opt if o in self.trans_opts.fields]):\n                    index = option_new.index(opt)\n                    option_new[index:index + 1] = self.replace_orig_field(opt)\n            option = option_new\n        return option", "response": "Replaces each original field in option that is registered for\n        translation by its translation fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_form_or_formset(self, request, obj, **kwargs):\n        if self.exclude is None:\n            exclude = []\n        else:\n            exclude = list(self.exclude)\n        exclude.extend(self.get_readonly_fields(request, obj))\n        if not self.exclude and hasattr(self.form, '_meta') and self.form._meta.exclude:\n            # Take the custom ModelForm's Meta.exclude into account only if the\n            # ModelAdmin doesn't define its own.\n            exclude.extend(self.form._meta.exclude)\n        # If exclude is an empty list we pass None to be consistant with the\n        # default on modelform_factory\n        exclude = self.replace_orig_field(exclude) or None\n        exclude = self._exclude_original_fields(exclude)\n        kwargs.update({'exclude': exclude})\n\n        return kwargs", "response": "Generic code shared by get_form and get_formset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_translation_field_excludes(self, exclude_languages=None):\n        if exclude_languages is None:\n            exclude_languages = []\n        excl_languages = []\n        if exclude_languages:\n            excl_languages = exclude_languages\n        exclude = []\n        for orig_fieldname, translation_fields in self.trans_opts.fields.items():\n            for tfield in translation_fields:\n                if tfield.language in excl_languages and tfield not in exclude:\n                    exclude.append(tfield)\n        return tuple(exclude)", "response": "Returns a tuple of translation field names to exclude based on exclude_languages arg."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncombine media of both components and adds a small script that unchecks the clear box when a value in any wrapped input is modified.", "response": "def media(self):\n        \"\"\"\n        Combines media of both components and adds a small script that unchecks\n        the clear box, when a value in any wrapped input is modified.\n        \"\"\"\n        return self.widget.media + self.checkbox.media + Media(self.Media)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends a checkbox for clearing the value (that is, setting the field with the ``empty_value``).", "response": "def render(self, name, value, attrs=None, renderer=None):\n        \"\"\"\n        Appends a checkbox for clearing the value (that is, setting the field\n        with the ``empty_value``).\n        \"\"\"\n        wrapped = self.widget.render(name, value, attrs, renderer)\n        checkbox_name = self.clear_checkbox_name(name)\n        checkbox_id = self.clear_checkbox_id(checkbox_name)\n        checkbox_label = self.clear_checkbox_label\n        checkbox = self.checkbox.render(\n            checkbox_name,\n            value == self.empty_value,\n            attrs={'id': checkbox_id},\n            renderer=renderer)\n        return mark_safe(self.template.format(\n            conditional_escape(wrapped),\n            conditional_escape(checkbox_id),\n            conditional_escape(checkbox_label),\n            conditional_escape(checkbox)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value_from_datadict(self, data, files, name):\n        clear = self.checkbox.value_from_datadict(data, files, self.clear_checkbox_name(name))\n        if clear:\n            return self.empty_value\n        return self.widget.value_from_datadict(data, files, name)", "response": "Returns the value of the attribute from the data dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef docs(**kwargs):\n\n    def wrapper(func):\n        kwargs[\"produces\"] = [\"application/json\"]\n        if not hasattr(func, \"__apispec__\"):\n            func.__apispec__ = {\"parameters\": [], \"responses\": {}}\n        extra_parameters = kwargs.pop(\"parameters\", [])\n        extra_responses = kwargs.pop(\"responses\", {})\n        func.__apispec__[\"parameters\"].extend(extra_parameters)\n        func.__apispec__[\"responses\"].update(extra_responses)\n        func.__apispec__.update(kwargs)\n        return func\n\n    return wrapper", "response": "Decorator for the base documentation view function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request_schema(schema, locations=None, **kwargs):\n    if callable(schema):\n        schema = schema()\n    # location kwarg added for compatibility with old versions\n    locations = locations or []\n    if not locations:\n        locations = kwargs.get(\"location\")\n        if locations:\n            locations = [locations]\n        else:\n            locations = None\n\n    options = {\"required\": kwargs.get(\"required\", False)}\n    if locations:\n        options[\"default_in\"] = locations[0]\n\n    def wrapper(func):\n        if not hasattr(func, \"__apispec__\"):\n            func.__apispec__ = {\"parameters\": [], \"responses\": {}}\n        func.__apispec__[\"options\"] = options\n        func.__apispec__[\"schema\"] = schema\n        if not hasattr(func, \"__schemas__\"):\n            func.__schemas__ = []\n        if locations and \"body\" in locations:\n            body_schema_exists = (\n                \"body\" in func_schema[\"locations\"] for func_schema in func.__schemas__\n            )\n            if any(body_schema_exists):\n                raise RuntimeError(\"Multiple body parameters are not allowed\")\n        func.__schemas__.append({\"schema\": schema, \"locations\": locations})\n\n        return func\n\n    return wrapper", "response": "Decorator for adding request info into the swagger spec and the decorated view function"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef response_schema(schema, code=200, required=False, description=None):\n    if callable(schema):\n        schema = schema()\n\n    def wrapper(func):\n        if not hasattr(func, \"__apispec__\"):\n            func.__apispec__ = {\"parameters\": [], \"responses\": {}}\n        func.__apispec__[\"responses\"][\"%s\" % code] = {\n            \"schema\": schema,\n            \"required\": required,\n            \"description\": description,\n        }\n        return func\n\n    return wrapper", "response": "Decorator for adding response info into the swagger spec"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid_input_array(x, ndim=None):\n    x = np.asarray(x)\n\n    if ndim is None or ndim == 1:\n        return x.ndim == 1 and x.size > 1 or x.ndim == 2 and x.shape[0] == 1\n    else:\n        return x.ndim == 2 and x.shape[0] == ndim", "response": "Test if x is a correctly shaped point array in R^d."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_input_meshgrid(x, ndim):\n    # This case is triggered in FunctionSpaceElement.__call__ if the\n    # domain does not have an 'ndim' attribute. We return False and\n    # continue.\n    if ndim is None:\n        return False\n\n    if not isinstance(x, tuple):\n        return False\n\n    if ndim > 1:\n        try:\n            np.broadcast(*x)\n        except (ValueError, TypeError):  # cannot be broadcast\n            return False\n\n    return (len(x) == ndim and\n            all(isinstance(xi, np.ndarray) for xi in x) and\n            all(xi.ndim == ndim for xi in x))", "response": "Test if x is a meshgrid sequence for points in R^d."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the broadcast output shape from a meshgrid.", "response": "def out_shape_from_meshgrid(mesh):\n    \"\"\"Get the broadcast output shape from a `meshgrid`.\"\"\"\n    if len(mesh) == 1:\n        return (len(mesh[0]),)\n    else:\n        return np.broadcast(*mesh).shape"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the output shape from an array.", "response": "def out_shape_from_array(arr):\n    \"\"\"Get the output shape from an array.\"\"\"\n    arr = np.asarray(arr)\n    if arr.ndim == 1:\n        return arr.shape\n    else:\n        return (arr.shape[1],)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _wrapper(func, *vect_args, **vect_kwargs):\n        if not hasattr(func, '__name__'):\n            # Set name if not available. Happens if func is actually a function\n            func.__name__ = '{}.__call__'.format(func.__class__.__name__)\n\n        return wraps(func)(_NumpyVectorizeWrapper(func, *vect_args,\n                                                  **vect_kwargs))", "response": "Return the vectorized wrapper function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an array - like object of operators to a sparse matrix.", "response": "def _convert_to_spmatrix(operators):\n        \"\"\"Convert an array-like object of operators to a sparse matrix.\"\"\"\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        # Convert ops to sparse representation. This is not trivial because\n        # operators can be indexable themselves and give the wrong impression\n        # of an extra dimension. So we have to infer the shape manually\n        # first and extract the indices of nonzero positions.\n        nrows = len(operators)\n        ncols = None\n        irow, icol, data = [], [], []\n        for i, row in enumerate(operators):\n            try:\n                iter(row)\n            except TypeError:\n                raise ValueError(\n                    '`operators` must be a matrix of `Operator` objects, `0` '\n                    'or `None`, got {!r} (row {} = {!r} is not iterable)'\n                    ''.format(operators, i, row))\n\n            if isinstance(row, Operator):\n                raise ValueError(\n                    '`operators` must be a matrix of `Operator` objects, `0` '\n                    'or `None`, but row {} is an `Operator` {!r}'\n                    ''.format(i, row))\n\n            if ncols is None:\n                ncols = len(row)\n            elif len(row) != ncols:\n                raise ValueError(\n                    'all rows in `operators` must have the same length, but '\n                    'length {} of row {} differs from previous common length '\n                    '{}'.format(len(row), i, ncols))\n\n            for j, col in enumerate(row):\n                if col is None or col is 0:\n                    pass\n                elif isinstance(col, Operator):\n                    irow.append(i)\n                    icol.append(j)\n                    data.append(col)\n                else:\n                    raise ValueError(\n                        '`operators` must be a matrix of `Operator` objects, '\n                        '`0` or `None`, got entry {!r} at ({}, {})'\n                        ''.format(col, i, j))\n\n        # Create object array explicitly, threby avoiding erroneous conversion\n        # in `coo_matrix.__init__`\n        data_arr = np.empty(len(data), dtype=object)\n        data_arr[:] = data\n        return scipy.sparse.coo_matrix((data_arr, (irow, icol)),\n                                       shape=(nrows, ncols))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the operators on the parts of x.", "response": "def _call(self, x, out=None):\n        \"\"\"Call the operators on the parts of ``x``.\"\"\"\n        # TODO: add optimization in case an operator appears repeatedly in a\n        # row\n        if out is None:\n            out = self.range.zero()\n            for i, j, op in zip(self.ops.row, self.ops.col, self.ops.data):\n                out[i] += op(x[j])\n        else:\n            has_evaluated_row = np.zeros(len(self.range), dtype=bool)\n            for i, j, op in zip(self.ops.row, self.ops.col, self.ops.data):\n                if not has_evaluated_row[i]:\n                    op(x[j], out=out[i])\n                else:\n                    # TODO: optimize\n                    out[i] += op(x[j])\n\n                has_evaluated_row[i] = True\n\n            for i, evaluated in enumerate(has_evaluated_row):\n                if not evaluated:\n                    out[i].set_zero()\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef derivative(self, x):\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        # Short circuit optimization\n        if self.is_linear:\n            return self\n\n        deriv_ops = [op.derivative(x[col]) for op, col in zip(self.ops.data,\n                                                              self.ops.col)]\n        data = np.empty(len(deriv_ops), dtype=object)\n        data[:] = deriv_ops\n        indices = [self.ops.row, self.ops.col]\n        shape = self.ops.shape\n        deriv_matrix = scipy.sparse.coo_matrix((data, indices), shape)\n        return ProductSpaceOperator(deriv_matrix, self.domain, self.range)", "response": "Returns the derivative of the product space operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprojects x onto the subspace.", "response": "def _call(self, x, out=None):\n        \"\"\"Project ``x`` onto the subspace.\"\"\"\n        if out is None:\n            out = x[self.index].copy()\n        else:\n            out.assign(x[self.index])\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _call(self, x, out=None):\n        if out is None:\n            out = self.range.zero()\n        else:\n            out.set_zero()\n\n        out[self.index] = x\n        return out", "response": "Extend x from the subspace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate all operators in x and broadcast.", "response": "def _call(self, x, out=None):\n        \"\"\"Evaluate all operators in ``x`` and broadcast.\"\"\"\n        wrapped_x = self.prod_op.domain.element([x], cast=False)\n        return self.prod_op(wrapped_x, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the derivative of the broadcast operator.", "response": "def derivative(self, x):\n        \"\"\"Derivative of the broadcast operator.\n\n        Parameters\n        ----------\n        x : `domain` element\n            The point to take the derivative in\n\n        Returns\n        -------\n        adjoint : linear `BroadcastOperator`\n            The derivative\n\n        Examples\n        --------\n        Example with an affine operator:\n\n        >>> I = odl.IdentityOperator(odl.rn(3))\n        >>> residual_op = I - I.domain.element([1, 1, 1])\n        >>> op = BroadcastOperator(residual_op, 2 * residual_op)\n\n        Calling operator offsets by ``[1, 1, 1]``:\n\n        >>> x = [1, 2, 3]\n        >>> op(x)\n        ProductSpace(rn(3), 2).element([\n            [ 0.,  1.,  2.],\n            [ 0.,  2.,  4.]\n        ])\n\n        The derivative of this affine operator does not have an offset:\n\n        >>> op.derivative(x)(x)\n        ProductSpace(rn(3), 2).element([\n            [ 1.,  2.,  3.],\n            [ 2.,  4.,  6.]\n        ])\n        \"\"\"\n        return BroadcastOperator(*[op.derivative(x) for op in\n                                   self.operators])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply operators to x and sum.", "response": "def _call(self, x, out=None):\n        \"\"\"Apply operators to ``x`` and sum.\"\"\"\n        if out is None:\n            return self.prod_op(x)[0]\n        else:\n            wrapped_out = self.prod_op.range.element([out], cast=False)\n            pspace_result = self.prod_op(x, out=wrapped_out)\n            return pspace_result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derivative(self, x):\n        return ReductionOperator(*[op.derivative(xi)\n                                   for op, xi in zip(self.operators, x)])", "response": "Returns the derivative of the reduction operator."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the derivative of this operator.", "response": "def derivative(self, point):\n        \"\"\"Derivative of this operator.\n\n        For example, if A and B are operators\n\n            [[A, 0],\n             [0, B]]\n\n        The derivative is given by:\n\n            [[A', 0],\n             [0, B']]\n\n        This is only well defined if each sub-operator has a derivative\n\n        Parameters\n        ----------\n        point : `element-like` in ``domain``\n            The point in which the derivative should be taken.\n\n        Returns\n        -------\n        derivative : `DiagonalOperator`\n            The derivative operator\n\n        See Also\n        --------\n        ProductSpaceOperator.derivative\n        \"\"\"\n        point = self.domain.element(point)\n\n        derivs = [op.derivative(p) for op, p in zip(self.operators, point)]\n        return DiagonalOperator(*derivs,\n                                domain=self.domain, range=self.range)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef adjoint(self):\n        adjoints = [op.adjoint for op in self.operators]\n        return DiagonalOperator(*adjoints,\n                                domain=self.range, range=self.domain)", "response": "Adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inverse(self):\n        inverses = [op.inverse for op in self.operators]\n        return DiagonalOperator(*inverses,\n                                domain=self.range, range=self.domain)", "response": "Inverse of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_julia_with_Shearlab():\n    # Importing base\n    j = julia.Julia()\n    j.eval('using Shearlab')\n    j.eval('using PyPlot')\n    j.eval('using Images')\n    return j", "response": "Function to load Shearlab and PyPlot from the Julia library."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to load images with certain size.", "response": "def load_image(name, n, m=None, gpu=None, square=None):\n    \"\"\"Function to load images with certain size.\"\"\"\n    if m is None:\n        m = n\n    if gpu is None:\n        gpu = 0\n    if square is None:\n        square = 0\n    command = ('Shearlab.load_image(\"{}\", {}, {}, {}, {})'.format(name,\n               n, m, gpu, square))\n    return j.eval(command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imageplot(f, str=None, sbpt=None):\n    # Function to plot images\n    if str is None:\n        str = ''\n    if sbpt is None:\n        sbpt = []\n    if sbpt != []:\n        plt.subplot(sbpt[0], sbpt[1], sbpt[2])\n    imgplot = plt.imshow(f, interpolation='nearest')\n    imgplot.set_cmap('gray')\n    plt.axis('off')\n    if str != '':\n        plt.title(str)", "response": "Function to plot an image generated by the library."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getshearletsystem2D(rows, cols, nScales, shearLevels=None,\n                        full=None,\n                        directionalFilter=None,\n                        quadratureMirrorFilter=None):\n    \"\"\"Function to generate de 2D system.\"\"\"\n    if shearLevels is None:\n        shearLevels = [float(ceil(i / 2)) for i in range(1, nScales + 1)]\n    if full is None:\n        full = 0\n    if directionalFilter is None:\n        directionalFilter = 'Shearlab.filt_gen(\"directional_shearlet\")'\n    if quadratureMirrorFilter is None:\n        quadratureMirrorFilter = 'Shearlab.filt_gen(\"scaling_shearlet\")'\n    j.eval('rows=' + str(rows))\n    j.eval('cols=' + str(cols))\n    j.eval('nScales=' + str(nScales))\n    j.eval('shearLevels=' + str(shearLevels))\n    j.eval('full=' + str(full))\n    j.eval('directionalFilter=' + directionalFilter)\n    j.eval('quadratureMirrorFilter=' + quadratureMirrorFilter)\n    j.eval('shearletsystem=Shearlab.getshearletsystem2D(rows, '\n           'cols, nScales, shearLevels, full, directionalFilter, '\n           'quadratureMirrorFilter) ')\n    shearlets = j.eval('shearletsystem.shearlets')\n    size = j.eval('shearletsystem.size')\n    shearLevels = j.eval('shearletsystem.shearLevels')\n    full = j.eval('shearletsystem.full')\n    nShearlets = j.eval('shearletsystem.nShearlets')\n    shearletIdxs = j.eval('shearletsystem.shearletIdxs')\n    dualFrameWeights = j.eval('shearletsystem.dualFrameWeights')\n    RMS = j.eval('shearletsystem.RMS')\n    isComplex = j.eval('shearletsystem.isComplex')\n    j.eval('shearletsystem = 0')\n    return Shearletsystem2D(shearlets, size, shearLevels, full, nShearlets,\n                            shearletIdxs, dualFrameWeights, RMS, isComplex)", "response": "Function to generate de 2D system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef submarine(space, smooth=True, taper=20.0):\n    if space.ndim == 2:\n        if smooth:\n            return _submarine_2d_smooth(space, taper)\n        else:\n            return _submarine_2d_nonsmooth(space)\n    else:\n        raise ValueError('phantom only defined in 2 dimensions, got {}'\n                         ''.format(space.ndim))", "response": "Return a submarine phantom consisting of an ellipsoid and a box."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _submarine_2d_smooth(space, taper):\n\n    def logistic(x, c):\n        \"\"\"Smoothed step function from 0 to 1, centered at 0.\"\"\"\n        return 1. / (1 + np.exp(-c * x))\n\n    def blurred_ellipse(x):\n        \"\"\"Blurred characteristic function of an ellipse.\n\n        If ``space.domain`` is a rectangle ``[0, 1] x [0, 1]``,\n        the ellipse is centered at ``(0.6, 0.3)`` and has half-axes\n        ``(0.4, 0.14)``. For other domains, the values are scaled\n        accordingly.\n        \"\"\"\n        halfaxes = np.array([0.4, 0.14]) * space.domain.extent\n        center = np.array([0.6, 0.3]) * space.domain.extent\n        center += space.domain.min()\n\n        # Efficiently calculate |z|^2, z = (x - center) / radii\n        sq_ndist = np.zeros_like(x[0])\n        for xi, rad, cen in zip(x, halfaxes, center):\n            sq_ndist = sq_ndist + ((xi - cen) / rad) ** 2\n\n        out = np.sqrt(sq_ndist)\n        out -= 1\n        # Return logistic(taper * (1 - |z|))\n        return logistic(out, -taper)\n\n    def blurred_rect(x):\n        \"\"\"Blurred characteristic function of a rectangle.\n\n        If ``space.domain`` is a rectangle ``[0, 1] x [0, 1]``,\n        the rect has lower left ``(0.56, 0.4)`` and upper right\n        ``(0.76, 0.6)``. For other domains, the values are scaled\n        accordingly.\n        \"\"\"\n        xlower = np.array([0.56, 0.4]) * space.domain.extent\n        xlower += space.domain.min()\n        xupper = np.array([0.76, 0.6]) * space.domain.extent\n        xupper += space.domain.min()\n\n        out = np.ones_like(x[0])\n        for xi, low, upp in zip(x, xlower, xupper):\n            length = upp - low\n            out = out * (logistic((xi - low) / length, taper) *\n                         logistic((upp - xi) / length, taper))\n        return out\n\n    out = space.element(blurred_ellipse)\n    out += space.element(blurred_rect)\n    return out.ufuncs.minimum(1, out=out)", "response": "Return a 2d smooth submarine phantom."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a 2d nonsmooth submarine phantom.", "response": "def _submarine_2d_nonsmooth(space):\n    \"\"\"Return a 2d nonsmooth 'submarine' phantom.\"\"\"\n\n    def ellipse(x):\n        \"\"\"Characteristic function of an ellipse.\n\n        If ``space.domain`` is a rectangle ``[0, 1] x [0, 1]``,\n        the ellipse is centered at ``(0.6, 0.3)`` and has half-axes\n        ``(0.4, 0.14)``. For other domains, the values are scaled\n        accordingly.\n        \"\"\"\n        halfaxes = np.array([0.4, 0.14]) * space.domain.extent\n        center = np.array([0.6, 0.3]) * space.domain.extent\n        center += space.domain.min()\n\n        sq_ndist = np.zeros_like(x[0])\n        for xi, rad, cen in zip(x, halfaxes, center):\n            sq_ndist = sq_ndist + ((xi - cen) / rad) ** 2\n\n        return np.where(sq_ndist <= 1, 1, 0)\n\n    def rect(x):\n        \"\"\"Characteristic function of a rectangle.\n\n        If ``space.domain`` is a rectangle ``[0, 1] x [0, 1]``,\n        the rect has lower left ``(0.56, 0.4)`` and upper right\n        ``(0.76, 0.6)``. For other domains, the values are scaled\n        accordingly.\n        \"\"\"\n        xlower = np.array([0.56, 0.4]) * space.domain.extent\n        xlower += space.domain.min()\n        xupper = np.array([0.76, 0.6]) * space.domain.extent\n        xupper += space.domain.min()\n\n        out = np.ones_like(x[0])\n        for xi, low, upp in zip(x, xlower, xupper):\n            out = out * ((xi >= low) & (xi <= upp))\n        return out\n\n    out = space.element(ellipse)\n    out += space.element(rect)\n    return out.ufuncs.minimum(1, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef text(space, text, font=None, border=0.2, inverted=True):\n    from PIL import Image, ImageDraw, ImageFont\n\n    if space.ndim != 2:\n        raise ValueError('`space` must be two-dimensional')\n\n    if font is None:\n        platform = sys.platform\n        if platform == 'win32':\n            # Windows\n            font = 'arial'\n        elif platform == 'darwin':\n            # Mac OSX\n            font = 'Helvetica'\n        else:\n            # Assume platform is linux\n            font = 'LiberationSans-Regular'\n\n    text = str(text)\n\n    # Figure out what font size we should use by creating a very high\n    # resolution font and calculating the size of the text in this font\n    init_size = 1000\n    init_pil_font = ImageFont.truetype(font + \".ttf\", size=init_size,\n                                       encoding=\"unic\")\n    init_text_width, init_text_height = init_pil_font.getsize(text)\n\n    # True size is given by how much too large (or small) the example was\n    scaled_init_size = (1.0 - border) * init_size\n    size = scaled_init_size * min([space.shape[0] / init_text_width,\n                                   space.shape[1] / init_text_height])\n    size = int(size)\n\n    # Create font\n    pil_font = ImageFont.truetype(font + \".ttf\", size=size,\n                                  encoding=\"unic\")\n    text_width, text_height = pil_font.getsize(text)\n\n    # create a blank canvas with extra space between lines\n    canvas = Image.new('RGB', space.shape, (255, 255, 255))\n\n    # draw the text onto the canvas\n    draw = ImageDraw.Draw(canvas)\n    offset = ((space.shape[0] - text_width) // 2,\n              (space.shape[1] - text_height) // 2)\n    white = \"#000000\"\n    draw.text(offset, text, font=pil_font, fill=white)\n\n    # Convert the canvas into an array with values in [0, 1]\n    arr = np.asarray(canvas)\n    arr = np.sum(arr, -1)\n    arr = arr / np.max(arr)\n    arr = np.rot90(arr, -1)\n\n    if inverted:\n        arr = 1 - arr\n\n    return space.element(arr)", "response": "Create a phantom from text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef norm(self, x):\n        return float(np.sqrt(self.inner(x, x).real))", "response": "Calculate the norm of an element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_valid(self):\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        if scipy.sparse.isspmatrix(self.matrix):\n            raise NotImplementedError('validation not supported for sparse '\n                                      'matrices')\n        elif self._eigval is not None:\n            return np.all(np.greater(self._eigval, 0))\n        else:\n            try:\n                np.linalg.cholesky(self.matrix)\n                return np.array_equal(self.matrix, self.matrix.conj().T)\n            except np.linalg.LinAlgError:\n                return False", "response": "Test if the matrix is positive definite Hermitian."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef matrix_decomp(self, cache=None):\n        # Lazy import to improve `import odl` time\n        import scipy.linalg\n        import scipy.sparse\n\n        # TODO: fix dead link `scipy.linalg.decomp.eigh`\n        if scipy.sparse.isspmatrix(self.matrix):\n            raise NotImplementedError('sparse matrix not supported')\n\n        if cache is None:\n            cache = self._cache_mat_decomp\n\n        if self._eigval is None or self._eigvec is None:\n            eigval, eigvec = scipy.linalg.eigh(self.matrix)\n            if cache:\n                self._eigval = eigval\n                self._eigvec = eigvec\n        else:\n            eigval, eigvec = self._eigval, self._eigvec\n\n        return eigval, eigvec", "response": "Compute a Hermitian eigenbasis decomposition of the matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if two weighting objects are equivalent.", "response": "def equiv(self, other):\n        \"\"\"Test if other is an equivalent weighting.\n\n        Returns\n        -------\n        equivalent : bool\n            ``True`` if ``other`` is a `Weighting` instance with the same\n            `Weighting.impl`, which yields the same result as this\n            weighting for any input, ``False`` otherwise. This is checked\n            by entry-wise comparison of matrices/arrays/constants.\n        \"\"\"\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        # Optimization for equality\n        if self == other:\n            return True\n\n        elif self.exponent != getattr(other, 'exponent', -1):\n            return False\n\n        elif isinstance(other, MatrixWeighting):\n            if self.matrix.shape != other.matrix.shape:\n                return False\n\n            if scipy.sparse.isspmatrix(self.matrix):\n                if other.matrix_issparse:\n                    # Optimization for different number of nonzero elements\n                    if self.matrix.nnz != other.matrix.nnz:\n                        return False\n                    else:\n                        # Most efficient out-of-the-box comparison\n                        return (self.matrix != other.matrix).nnz == 0\n                else:  # Worst case: compare against dense matrix\n                    return np.array_equal(self.matrix.todense(), other.matrix)\n\n            else:  # matrix of `self` is dense\n                if other.matrix_issparse:\n                    return np.array_equal(self.matrix, other.matrix.todense())\n                else:\n                    return np.array_equal(self.matrix, other.matrix)\n\n        elif isinstance(other, ArrayWeighting):\n            if scipy.sparse.isspmatrix(self.matrix):\n                return (np.array_equiv(self.matrix.diagonal(),\n                                       other.array) and\n                        np.array_equal(self.matrix.asformat('dia').offsets,\n                                       np.array([0])))\n            else:\n                return np.array_equal(\n                    self.matrix, other.array * np.eye(self.matrix.shape[0]))\n\n        elif isinstance(other, ConstWeighting):\n            if scipy.sparse.isspmatrix(self.matrix):\n                return (np.array_equiv(self.matrix.diagonal(), other.const) and\n                        np.array_equal(self.matrix.asformat('dia').offsets,\n                                       np.array([0])))\n            else:\n                return np.array_equal(\n                    self.matrix, other.const * np.eye(self.matrix.shape[0]))\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repr_part(self):\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        if scipy.sparse.isspmatrix(self.matrix):\n            optargs = [('matrix', str(self.matrix), '')]\n        else:\n            optargs = [('matrix', array_str(self.matrix, nprint=10), '')]\n\n        optargs.append(('exponent', self.exponent, 2.0))\n        return signature_string([], optargs, mod=[[], ['!s', ':.4']])", "response": "Return a string usable in a space s __repr__ method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef equiv(self, other):\n        # Optimization for equality\n        if self == other:\n            return True\n        elif (not isinstance(other, Weighting) or\n              self.exponent != other.exponent):\n            return False\n        elif isinstance(other, MatrixWeighting):\n            return other.equiv(self)\n        elif isinstance(other, ConstWeighting):\n            return np.array_equiv(self.array, other.const)\n        else:\n            return np.array_equal(self.array, other.array)", "response": "Return True if self is equivalent to other."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef repr_part(self):\n        optargs = [('weighting', array_str(self.array, nprint=10), ''),\n                   ('exponent', self.exponent, 2.0)]\n        return signature_string([], optargs, sep=',\\n',\n                                mod=[[], ['!s', ':.4']])", "response": "String usable in a space s __repr__ method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if this weighting is equivalent to other.", "response": "def equiv(self, other):\n        \"\"\"Test if other is an equivalent weighting.\n\n        Returns\n        -------\n        equivalent : bool\n            ``True`` if other is a `Weighting` instance with the same\n            `Weighting.impl`, which yields the same result as this\n            weighting for any input, ``False`` otherwise. This is checked\n            by entry-wise comparison of matrices/arrays/constants.\n        \"\"\"\n        if isinstance(other, ConstWeighting):\n            return self == other\n        elif isinstance(other, (ArrayWeighting, MatrixWeighting)):\n            return other.equiv(self)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstrings usable in a space s __repr__ method.", "response": "def repr_part(self):\n        \"\"\"String usable in a space's ``__repr__`` method.\"\"\"\n        optargs = [('weighting', self.const, 1.0),\n                   ('exponent', self.exponent, 2.0)]\n        return signature_string([], optargs, mod=':.4')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string usable in a space s __repr__ method.", "response": "def repr_part(self):\n        \"\"\"Return a string usable in a space's ``__repr__`` method.\"\"\"\n        optargs = [('norm', self.norm, ''),\n                   ('exponent', self.exponent, 2.0)]\n        return signature_string([], optargs, mod=[[], ['!r', ':.4']])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the SLSheardec2D of the class.", "response": "def _call(self, x):\n        \"\"\"Return ``self(x)``.\"\"\"\n        with self.mutex:\n            result = pyshearlab.SLsheardec2D(x, self.shearlet_system)\n            return np.moveaxis(result, -1, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a SLShearadjoint2D object.", "response": "def _call(self, x):\n        \"\"\"Return ``self(x)``.\"\"\"\n        with self.op.mutex:\n            x = np.moveaxis(x, 0, -1)\n            return pyshearlab.SLshearadjoint2D(x, self.op.shearlet_system)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the SLShearrecadjoint of the class.", "response": "def _call(self, x):\n        \"\"\"Return ``self(x)``.\"\"\"\n        with self.op.mutex:\n            result = pyshearlab.SLshearrecadjoint2D(x, self.op.shearlet_system)\n            return np.moveaxis(result, -1, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prox_dca(x, f, g, niter, gamma, callback=None):\n    space = f.domain\n    if g.domain != space:\n        raise ValueError('`f.domain` and `g.domain` need to be equal, but '\n                         '{} != {}'.format(space, g.domain))\n    for _ in range(niter):\n        f.proximal(gamma)(x.lincomb(1, x, gamma, g.gradient(x)), out=x)\n\n        if callback is not None:\n            callback(x)", "response": "Proximal DCA of Sun Sampaio and Candido."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef doubleprox_dc_simple(x, y, f, phi, g, K, niter, gamma, mu):\n    for _ in range(niter):\n        f.proximal(gamma)(x + gamma * K.adjoint(y) -\n                          gamma * phi.gradient(x), out=x)\n        g.convex_conj.proximal(mu)(y + mu * K(x), out=y)", "response": "Non - optimized version of doubleprox_dc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef matrix_representation(op):\n\n    if not op.is_linear:\n        raise ValueError('the operator is not linear')\n\n    if not (isinstance(op.domain, TensorSpace) or\n            (isinstance(op.domain, ProductSpace) and\n             op.domain.is_power_space and\n             all(isinstance(spc, TensorSpace) for spc in op.domain))):\n        raise TypeError('operator domain {!r} is neither `TensorSpace` '\n                        'nor `ProductSpace` with only equal `TensorSpace` '\n                        'components'.format(op.domain))\n\n    if not (isinstance(op.range, TensorSpace) or\n            (isinstance(op.range, ProductSpace) and\n             op.range.is_power_space and\n             all(isinstance(spc, TensorSpace) for spc in op.range))):\n        raise TypeError('operator range {!r} is neither `TensorSpace` '\n                        'nor `ProductSpace` with only equal `TensorSpace` '\n                        'components'.format(op.range))\n\n    # Generate the matrix\n    dtype = np.promote_types(op.domain.dtype, op.range.dtype)\n    matrix = np.zeros(op.range.shape + op.domain.shape, dtype=dtype)\n    tmp_ran = op.range.element()  # Store for reuse in loop\n    tmp_dom = op.domain.zero()  # Store for reuse in loop\n\n    for j in nd_iterator(op.domain.shape):\n        tmp_dom[j] = 1.0\n\n        op(tmp_dom, out=tmp_ran)\n        matrix[(Ellipsis,) + j] = tmp_ran.asarray()\n\n        tmp_dom[j] = 0.0\n\n    return matrix", "response": "Return a matrix representation of a linear operator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef power_method_opnorm(op, xstart=None, maxiter=100, rtol=1e-05, atol=1e-08,\n                        callback=None):\n    r\"\"\"Estimate the operator norm with the power method.\n\n    Parameters\n    ----------\n    op : `Operator`\n        Operator whose norm is to be estimated. If its `Operator.range`\n        range does not coincide with its `Operator.domain`, an\n        `Operator.adjoint` must be defined (which implies that the\n        operator must be linear).\n    xstart : ``op.domain`` `element-like`, optional\n        Starting point of the iteration. By default an `Operator.domain`\n        element containing noise is used.\n    maxiter : positive int, optional\n        Number of iterations to perform. If the domain and range of ``op``\n        do not match, it needs to be an even number. If ``None`` is given,\n        iterate until convergence.\n    rtol : float, optional\n        Relative tolerance parameter (see Notes).\n    atol : float, optional\n        Absolute tolerance parameter (see Notes).\n    callback : callable, optional\n        Function called with the current iterate in each iteration.\n\n    Returns\n    -------\n    est_opnorm : float\n        The estimated operator norm of ``op``.\n\n    Examples\n    --------\n    Verify that the identity operator has norm close to 1:\n\n    >>> space = odl.uniform_discr(0, 1, 5)\n    >>> id = odl.IdentityOperator(space)\n    >>> estimation = power_method_opnorm(id)\n    >>> round(estimation, ndigits=3)\n    1.0\n\n    Notes\n    -----\n    The operator norm :math:`||A||` is defined by as the smallest number\n    such that\n\n    .. math::\n        ||A(x)|| \\leq ||A|| ||x||\n\n    for all :math:`x` in the domain of :math:`A`.\n\n    The operator is evaluated until ``maxiter`` operator calls or until the\n    relative error is small enough. The error measure is given by\n\n        ``abs(a - b) <= (atol + rtol * abs(b))``,\n\n    where ``a`` and ``b`` are consecutive iterates.\n    \"\"\"\n    if maxiter is None:\n        maxiter = np.iinfo(int).max\n\n    maxiter, maxiter_in = int(maxiter), maxiter\n    if maxiter <= 0:\n        raise ValueError('`maxiter` must be positive, got {}'\n                         ''.format(maxiter_in))\n\n    if op.domain == op.range:\n        use_normal = False\n        ncalls = maxiter\n    else:\n        # Do the power iteration for A*A; the norm of A*A(x_N) is then\n        # an estimate of the square of the operator norm\n        # We do only half the number of iterations compared to the usual\n        # case to have the same number of operator evaluations.\n        use_normal = True\n        ncalls = maxiter // 2\n        if ncalls * 2 != maxiter:\n            raise ValueError('``maxiter`` must be an even number for '\n                             'non-self-adjoint operator, got {}'\n                             ''.format(maxiter_in))\n\n    # Make sure starting point is ok or select initial guess\n    if xstart is None:\n        x = noise_element(op.domain)\n    else:\n        # copy to ensure xstart is not modified\n        x = op.domain.element(xstart).copy()\n\n    # Take first iteration step to normalize input\n    x_norm = x.norm()\n    if x_norm == 0:\n        raise ValueError('``xstart`` must be nonzero')\n    x /= x_norm\n\n    # utility to calculate opnorm from xnorm\n    def calc_opnorm(x_norm):\n        if use_normal:\n            return np.sqrt(x_norm)\n        else:\n            return x_norm\n\n    # initial guess of opnorm\n    opnorm = calc_opnorm(x_norm)\n\n    # temporary to improve performance\n    tmp = op.range.element()\n\n    # Use the power method to estimate opnorm\n    for i in range(ncalls):\n        if use_normal:\n            op(x, out=tmp)\n            op.adjoint(tmp, out=x)\n        else:\n            op(x, out=tmp)\n            x, tmp = tmp, x\n\n        # Calculate x norm and verify it is valid\n        x_norm = x.norm()\n        if x_norm == 0:\n            raise ValueError('reached ``x=0`` after {} iterations'.format(i))\n        if not np.isfinite(x_norm):\n            raise ValueError('reached nonfinite ``x={}`` after {} iterations'\n                             ''.format(x, i))\n\n        # Calculate opnorm\n        opnorm, opnorm_old = calc_opnorm(x_norm), opnorm\n\n        # If the breaking condition holds, stop. Else rescale and go on.\n        if np.isclose(opnorm, opnorm_old, rtol, atol):\n            break\n        else:\n            x /= x_norm\n\n        if callback is not None:\n            callback(x)\n\n    return opnorm", "response": "r Estimates the operator norm of an identity operator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap an operator that is linear and return a new object.", "response": "def as_scipy_operator(op):\n    \"\"\"Wrap ``op`` as a ``scipy.sparse.linalg.LinearOperator``.\n\n    This is intended to be used with the scipy sparse linear solvers.\n\n    Parameters\n    ----------\n    op : `Operator`\n        A linear operator that should be wrapped\n\n    Returns\n    -------\n    ``scipy.sparse.linalg.LinearOperator`` : linear_op\n        The wrapped operator, has attributes ``matvec`` which calls ``op``,\n        and ``rmatvec`` which calls ``op.adjoint``.\n\n    Examples\n    --------\n    Wrap operator and solve simple problem (here toy problem ``Ix = b``)\n\n    >>> op = odl.IdentityOperator(odl.rn(3))\n    >>> scipy_op = as_scipy_operator(op)\n    >>> import scipy.sparse.linalg as scipy_solvers\n    >>> result, status = scipy_solvers.cg(scipy_op, [0, 1, 0])\n    >>> result\n    array([ 0.,  1.,  0.])\n\n    Notes\n    -----\n    If the data representation of ``op``'s domain and range is of type\n    `NumpyTensorSpace` this incurs no significant overhead. If the space\n    type is ``CudaFn`` or some other nonlocal type, the overhead is\n    significant.\n    \"\"\"\n    # Lazy import to improve `import odl` time\n    import scipy.sparse\n\n    if not op.is_linear:\n        raise ValueError('`op` needs to be linear')\n\n    dtype = op.domain.dtype\n    if op.range.dtype != dtype:\n        raise ValueError('dtypes of ``op.domain`` and ``op.range`` needs to '\n                         'match')\n\n    shape = (native(op.range.size), native(op.domain.size))\n\n    def matvec(v):\n        return (op(v.reshape(op.domain.shape))).asarray().ravel()\n\n    def rmatvec(v):\n        return (op.adjoint(v.reshape(op.range.shape))).asarray().ravel()\n\n    return scipy.sparse.linalg.LinearOperator(shape=shape,\n                                              matvec=matvec,\n                                              rmatvec=rmatvec,\n                                              dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_scipy_functional(func, return_gradient=False):\n    def func_call(arr):\n        return func(np.asarray(arr).reshape(func.domain.shape))\n\n    if return_gradient:\n        def func_gradient_call(arr):\n            return np.asarray(\n                func.gradient(np.asarray(arr).reshape(func.domain.shape)))\n\n        return func_call, func_gradient_call\n    else:\n        return func_call", "response": "Wrap op as a function operating on linear arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps an operator as a proximal. BlackBox.", "response": "def as_proximal_lang_operator(op, norm_bound=None):\n    \"\"\"Wrap ``op`` as a ``proximal.BlackBox``.\n\n    This is intended to be used with the `ProxImaL language solvers.\n    <https://github.com/comp-imaging/proximal>`_\n\n    For documentation on the proximal language (ProxImaL) see [Hei+2016].\n\n    Parameters\n    ----------\n    op : `Operator`\n        Linear operator to be wrapped. Its domain and range must implement\n        ``shape``, and elements in these need to implement ``asarray``.\n    norm_bound : float, optional\n        An upper bound on the spectral norm of the operator. Note that this is\n        the norm as defined by ProxImaL, and hence use the unweighted spaces.\n\n    Returns\n    -------\n    ``proximal.BlackBox`` : proximal_lang_operator\n        The wrapped operator.\n\n    Notes\n    -----\n    If the data representation of ``op``'s domain and range is of type\n    `NumpyTensorSpace` this incurs no significant overhead. If the data\n    space is implemented with CUDA or some other non-local representation,\n    the overhead is significant.\n\n    References\n    ----------\n    [Hei+2016] Heide, F et al. *ProxImaL: Efficient Image Optimization using\n    Proximal Algorithms*. ACM Transactions on Graphics (TOG), 2016.\n    \"\"\"\n    # TODO: use out parameter once \"as editable array\" is added\n\n    def forward(inp, out):\n        out[:] = op(inp).asarray()\n\n    def adjoint(inp, out):\n        out[:] = op.adjoint(inp).asarray()\n\n    import proximal\n    return proximal.LinOpFactory(input_shape=op.domain.shape,\n                                 output_shape=op.range.shape,\n                                 forward=forward,\n                                 adjoint=adjoint,\n                                 norm_bound=norm_bound)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef skimage_sinogram_space(geometry, volume_space, sinogram_space):\n    padded_size = int(np.ceil(volume_space.shape[0] * np.sqrt(2)))\n    det_width = volume_space.domain.extent[0] * np.sqrt(2)\n    skimage_detector_part = uniform_partition(-det_width / 2.0,\n                                              det_width / 2.0,\n                                              padded_size)\n\n    skimage_range_part = geometry.motion_partition.insert(\n        1, skimage_detector_part)\n\n    skimage_range = uniform_discr_frompartition(skimage_range_part,\n                                                interp=sinogram_space.interp,\n                                                dtype=sinogram_space.dtype)\n\n    return skimage_range", "response": "Create a range adapted to the skimage radon geometry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clamped_interpolation(skimage_range, sinogram):\n    min_x = skimage_range.domain.min()[1]\n    max_x = skimage_range.domain.max()[1]\n\n    def interpolation_wrapper(x):\n        x = (x[0], np.maximum(min_x, np.minimum(max_x, x[1])))\n\n        return sinogram.interpolation(x)\n    return interpolation_wrapper", "response": "Interpolate in a possibly smaller space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef skimage_radon_forward(volume, geometry, range, out=None):\n    # Lazy import due to significant import time\n    from skimage.transform import radon\n\n    # Check basic requirements. Fully checking should be in wrapper\n    assert volume.shape[0] == volume.shape[1]\n\n    theta = skimage_theta(geometry)\n    skimage_range = skimage_sinogram_space(geometry, volume.space, range)\n\n    # Rotate volume from (x, y) to (rows, cols)\n    sino_arr = radon(np.rot90(volume.asarray(), 1),\n                     theta=theta, circle=False)\n    sinogram = skimage_range.element(sino_arr.T)\n\n    if out is None:\n        out = range.element()\n\n    out.sampling(clamped_interpolation(skimage_range, sinogram))\n\n    scale = volume.space.cell_sides[0]\n\n    out *= scale\n\n    return out", "response": "Calculate the forward projection using skimage."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the forward projection using skimage.", "response": "def skimage_radon_back_projector(sinogram, geometry, range, out=None):\n    \"\"\"Calculate forward projection using skimage.\n\n    Parameters\n    ----------\n    sinogram : `DiscreteLpElement`\n        Sinogram (projections) to backproject.\n    geometry : `Geometry`\n        The projection geometry to use.\n    range : `DiscreteLp`\n        range of this projection (volume space).\n    out : ``range`` element, optional\n        An element in range that the result should be written to.\n\n    Returns\n    -------\n    sinogram : ``range`` element\n        Sinogram given by the projection.\n    \"\"\"\n    # Lazy import due to significant import time\n    from skimage.transform import iradon\n\n    theta = skimage_theta(geometry)\n    skimage_range = skimage_sinogram_space(geometry, range, sinogram.space)\n\n    skimage_sinogram = skimage_range.element()\n    skimage_sinogram.sampling(clamped_interpolation(range, sinogram))\n\n    if out is None:\n        out = range.element()\n    else:\n        # Only do asserts here since these are backend functions\n        assert out in range\n\n    # Rotate back from (rows, cols) to (x, y)\n    backproj = iradon(skimage_sinogram.asarray().T, theta,\n                      output_size=range.shape[0], filter=None, circle=False)\n    out[:] = np.rot90(backproj, -1)\n\n    # Empirically determined value, gives correct scaling\n    scaling_factor = 4.0 * float(geometry.motion_params.length) / (2 * np.pi)\n\n    # Correct in case of non-weighted spaces\n    proj_extent = float(sinogram.space.partition.extent.prod())\n    proj_size = float(sinogram.space.partition.size)\n    proj_weighting = proj_extent / proj_size\n\n    scaling_factor *= (sinogram.space.weighting.const /\n                       proj_weighting)\n    scaling_factor /= (range.weighting.const /\n                       range.cell_volume)\n\n    # Correctly scale the output\n    out *= scaling_factor\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscale x and write to out.", "response": "def _call(self, x, out=None):\n        \"\"\"Scale ``x`` and write to ``out`` if given.\"\"\"\n        if out is None:\n            out = self.scalar * x\n        else:\n            out.lincomb(self.scalar, x)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the inverse operator.", "response": "def inverse(self):\n        \"\"\"Return the inverse operator.\n\n        Examples\n        --------\n        >>> r3 = odl.rn(3)\n        >>> vec = r3.element([1, 2, 3])\n        >>> op = ScalingOperator(r3, 2.0)\n        >>> inv = op.inverse\n        >>> inv(op(vec)) == vec\n        True\n        >>> op(inv(vec)) == vec\n        True\n        \"\"\"\n        if self.scalar == 0.0:\n            raise ZeroDivisionError('scaling operator not invertible for '\n                                    'scalar==0')\n        return ScalingOperator(self.domain, 1.0 / self.scalar)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjoint(self):\n        if complex(self.scalar).imag == 0.0:\n            return self\n        else:\n            return ScalingOperator(self.domain, self.scalar.conjugate())", "response": "Adjoint given as scaling with the conjugate of the scalar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _call(self, x, out=None):\n        if out is None:\n            out = self.range.element()\n        out.lincomb(self.a, x[0], self.b, x[1])\n        return out", "response": "Linearly combine x and write to out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _call(self, x, out=None):\n        if out is None:\n            return x * self.multiplicand\n        elif not self.__range_is_field:\n            if self.__domain_is_field:\n                out.lincomb(x, self.multiplicand)\n            else:\n                out.assign(self.multiplicand * x)\n        else:\n            raise ValueError('can only use `out` with `LinearSpace` range')", "response": "Multiply x and write to out."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adjoint(self):\n        if self.__domain_is_field:\n            if isinstance(self.domain, RealNumbers):\n                return InnerProductOperator(self.multiplicand)\n            elif isinstance(self.domain, ComplexNumbers):\n                return InnerProductOperator(self.multiplicand.conjugate())\n            else:\n                raise NotImplementedError(\n                    'adjoint not implemented for domain{!r}'\n                    ''.format(self.domain))\n        elif self.domain.is_complex:\n            return MultiplyOperator(np.conj(self.multiplicand),\n                                    domain=self.range, range=self.domain)\n        else:\n            return MultiplyOperator(self.multiplicand,\n                                    domain=self.range, range=self.domain)", "response": "Adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _call(self, x, out=None):\n        if out is None:\n            return x ** self.exponent\n        elif self.__domain_is_field:\n            raise ValueError('cannot use `out` with field')\n        else:\n            out.assign(x)\n            out **= self.exponent", "response": "Take the power of x and write to out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef derivative(self, point):\n        return self.exponent * MultiplyOperator(point ** (self.exponent - 1),\n                                                domain=self.domain,\n                                                range=self.range)", "response": "Derivative of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef derivative(self, point):\n        point = self.domain.element(point)\n        norm = point.norm()\n        if norm == 0:\n            raise ValueError('not differentiable in 0')\n\n        return InnerProductOperator(point / norm)", "response": "r Returns the derivative of this operator in point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derivative(self, point):\n        point = self.domain.element(point)\n        diff = point - self.vector\n        dist = self.vector.dist(point)\n        if dist == 0:\n            raise ValueError('not differentiable at the reference vector {!r}'\n                             ''.format(self.vector))\n\n        return InnerProductOperator(diff / dist)", "response": "Return the derivative operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(self, x, out=None):\n        if out is None:\n            return self.range.element(copy(self.constant))\n        else:\n            out.assign(self.constant)", "response": "Return the constant vector or assign it to out."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _call(self, x, out=None):\n        if self.domain == self.range:\n            if out is None:\n                out = 0 * x\n            else:\n                out.lincomb(0, x)\n        else:\n            result = self.range.zero()\n            if out is None:\n                out = result\n            else:\n                out.assign(result)\n        return out", "response": "Return the zero vector or assign it to out."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the inverse of the internal system.", "response": "def inverse(self):\n        \"\"\"Return the pseudoinverse.\n\n        Examples\n        --------\n        The inverse is the zero operator if the domain is real:\n\n        >>> r3 = odl.rn(3)\n        >>> op = ImagPart(r3)\n        >>> op.inverse(op([1, 2, 3]))\n        rn(3).element([ 0.,  0.,  0.])\n\n        This is not a true inverse, only a pseudoinverse, the real part\n        will by necessity be lost.\n\n        >>> c3 = odl.cn(3)\n        >>> op = ImagPart(c3)\n        >>> op.inverse(op([1 + 2j, 2, 3 - 1j]))\n        cn(3).element([ 0.+2.j,  0.+0.j, -0.-1.j])\n        \"\"\"\n        if self.space_is_real:\n            return ZeroOperator(self.domain)\n        else:\n            return ComplexEmbedding(self.domain, scalar=1j)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the left adjoint of the weaker domain.", "response": "def adjoint(self):\n        r\"\"\"Return the (left) adjoint.\n\n        Notes\n        -----\n        Due to technicalities of operators from a complex space into a real\n        space, this does not satisfy the usual adjoint equation:\n\n        .. math::\n            \\langle Ax, y \\rangle = \\langle x, A^*y \\rangle\n\n        Instead it is an adjoint in a weaker sense as follows:\n\n        .. math::\n            \\langle AA^*x, y \\rangle = \\langle A^*x, A^*y \\rangle\n\n        Examples\n        --------\n        The adjoint satisfies the adjoint equation for real spaces:\n\n        >>> r3 = odl.rn(3)\n        >>> op = ImagPart(r3)\n        >>> x = op.domain.element([1, 2, 3])\n        >>> y = op.range.element([3, 2, 1])\n        >>> x.inner(op.adjoint(y)) == op(x).inner(y)\n        True\n\n        If the domain is complex, it only satisfies the weaker definition:\n\n        >>> c3 = odl.cn(3)\n        >>> op = ImagPart(c3)\n        >>> x = op.range.element([1, 2, 3])\n        >>> y = op.range.element([3, 2, 1])\n        >>> AtAxy = op(op.adjoint(x)).inner(y)\n        >>> AtxAty = op.adjoint(x).inner(op.adjoint(y))\n        >>> AtAxy == AtxAty\n        True\n        \"\"\"\n        if self.space_is_real:\n            return ZeroOperator(self.domain)\n        else:\n            return ComplexEmbedding(self.domain, scalar=1j)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _call(self, x, out):\n        if self.domain.is_real:\n            # Real domain, multiply separately\n            out.real = self.scalar.real * x\n            out.imag = self.scalar.imag * x\n        else:\n            # Complex domain\n            out.lincomb(self.scalar, x)", "response": "Return self. scalar x."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inverse(self):\n        if self.domain.is_real:\n            # Real domain\n            # Optimizations for simple cases.\n            if self.scalar.real == self.scalar:\n                return (1 / self.scalar.real) * RealPart(self.range)\n            elif 1j * self.scalar.imag == self.scalar:\n                return (1 / self.scalar.imag) * ImagPart(self.range)\n            else:\n                # General case\n                inv_scalar = (1 / self.scalar).conjugate()\n                return ((inv_scalar.real) * RealPart(self.range) +\n                        (inv_scalar.imag) * ImagPart(self.range))\n        else:\n            # Complex domain\n            return ComplexEmbedding(self.range, self.scalar.conjugate())", "response": "Return the left inverse of the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the right adjoint of the current instance of the current instance of the class.", "response": "def adjoint(self):\n        r\"\"\"Return the (right) adjoint.\n\n        Notes\n        -----\n        Due to technicalities of operators from a real space into a complex\n        space, this does not satisfy the usual adjoint equation:\n\n        .. math::\n            \\langle Ax, y \\rangle = \\langle x, A^*y \\rangle\n\n        Instead it is an adjoint in a weaker sense as follows:\n\n        .. math::\n            \\langle A^*Ax, y \\rangle = \\langle Ax, Ay \\rangle\n\n        Examples\n        --------\n        The adjoint satisfies the adjoint equation for complex spaces\n\n        >>> c3 = odl.cn(3)\n        >>> op = ComplexEmbedding(c3, scalar=1j)\n        >>> x = c3.element([1 + 1j, 2 + 2j, 3 + 3j])\n        >>> y = c3.element([3 + 1j, 2 + 2j, 3 + 1j])\n        >>> Axy = op(x).inner(y)\n        >>> xAty = x.inner(op.adjoint(y))\n        >>> Axy == xAty\n        True\n\n        For real domains, it only satisfies the (right) adjoint equation\n\n        >>> r3 = odl.rn(3)\n        >>> op = ComplexEmbedding(r3, scalar=1j)\n        >>> x = r3.element([1, 2, 3])\n        >>> y = r3.element([3, 2, 3])\n        >>> AtAxy = op.adjoint(op(x)).inner(y)\n        >>> AxAy = op(x).inner(op(y))\n        >>> AtAxy == AxAy\n        True\n        \"\"\"\n        if self.domain.is_real:\n            # Real domain\n            # Optimizations for simple cases.\n            if self.scalar.real == self.scalar:\n                return self.scalar.real * RealPart(self.range)\n            elif 1j * self.scalar.imag == self.scalar:\n                return self.scalar.imag * ImagPart(self.range)\n            else:\n                # General case\n                return (self.scalar.real * RealPart(self.range) +\n                        self.scalar.imag * ImagPart(self.range))\n        else:\n            # Complex domain\n            return ComplexEmbedding(self.range, self.scalar.conjugate())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derivative(self, x):\n        op = self\n        x = self.domain.element(x)\n\n        class ComplexModulusDerivative(Operator):\n\n            \"\"\"Derivative of the complex modulus operator.\"\"\"\n\n            def _call(self, y, out):\n                \"\"\"Return ``self(y)``.\"\"\"\n                out[:] = x.real * y.real\n                out += x.imag * y.imag\n                out /= op(x)\n                return out\n\n            @property\n            def adjoint(self):\n                r\"\"\"Adjoint in the \"C = R^2\" sense.\n\n                Examples\n                --------\n                Adjoint of the derivative:\n\n                >>> c2 = odl.cn(2)\n                >>> op = odl.ComplexModulus(c2)\n                >>> op([3 + 4j, 2])\n                rn(2).element([ 5.,  2.])\n                >>> deriv = op.derivative([3 + 4j, 2])\n                >>> adj = deriv.adjoint\n                >>> adj.domain\n                rn(2)\n                >>> adj.range\n                cn(2)\n                >>> adj([5, 5])  # [5*(3 + 4j)/5, 5*2/2]\n                cn(2).element([ 3.+4.j,  5.+0.j])\n\n                Adjointness only holds in the weaker sense that inner products\n                are the same when testing with vectors from the real space, but\n                not when testing complex vectors:\n\n                >>> y1 = deriv.range.element([5, 5])\n                >>> y2 = deriv.range.element([1, 2])\n                >>> adj(y1).inner(adj(y2))  # <M^* y1, M^* y2>\n                (15+0j)\n                >>> deriv(adj(y1)).inner(y2)  # <M M^* y1, y2>\n                15.0\n                >>> x1 = deriv.domain.element([6 + 3j, 2j])\n                >>> x2 = deriv.domain.element([5, 10 + 4j])\n                >>> deriv(x1).inner(deriv(x2))  # <M x1, M x2>\n                18.0\n                >>> adj(deriv(x1)).inner(x2)  # <M^* M x1, x2>\n                (18+24j)\n\n                Notes\n                -----\n                The complex modulus derivative is given by\n\n                .. math::\n                    &M'(x): X(\\mathbb{C}) \\to X(\\mathbb{R}), \\\\\n                    &M'(x)(y) = \\frac{\\Re(x)\\,\\Re(y) + \\Im(x)\\,\\Im(y)}{M(x)}.\n\n                Thus, its adjoint can (formally) be identified as\n\n                .. math::\n                    &M'(x)^*: X(\\mathbb{R}) \\to X(\\mathbb{C}), \\\\\n                    &M'(x)^*(u) = \\frac{(\\Re(x)\\,u,\\ \\Im(x)\\,u}{M(x)}.\n\n                The operator :math:`A = M'(x)` has the weak adjointness\n                property\n\n                .. math::\n                    \\langle A^* y_1,\\ A^* y_2 \\rangle_{X(\\mathbb{C})} =\n                    \\langle AA^* y_1,\\ y_2 \\rangle_{X(\\mathbb{R})},\n\n                but in general,\n\n                .. math::\n                    \\langle A x,\\ y \\rangle_{X(\\mathbb{R})} \\neq\n                    \\langle x,\\ A^* y \\rangle_{X(\\mathbb{C})},\n\n                in particular\n\n                .. math::\n                    \\langle A x_1,\\ A x_2 \\rangle_{X(\\mathbb{R})} \\neq\n                    \\langle A^*A x_1,\\ x_2 \\rangle_{X(\\mathbb{C})}.\n                \"\"\"\n                deriv = self\n\n                class ComplexModulusDerivativeAdjoint(Operator):\n\n                    def _call(self, u, out):\n                        \"\"\"Implement ``self(u, out)``.\"\"\"\n                        out.assign(x)\n                        tmp = u / op(x)\n                        out.real *= tmp\n                        out.imag *= tmp\n                        return out\n\n                    @property\n                    def adjoint(self):\n                        \"\"\"Adjoint in the \"C = R^2\" sense.\"\"\"\n                        return deriv\n\n                return ComplexModulusDerivativeAdjoint(\n                    deriv.range, deriv.domain, linear=deriv.domain.is_real)\n\n        return ComplexModulusDerivative(op.domain, op.range,\n                                        linear=op.domain.is_real)", "response": "r Return the derivative operator in the complex domain element of two real spaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the derivative operator in the C = R^2 sense.", "response": "def derivative(self, x):\n        r\"\"\"Return the derivative operator in the \"C = R^2\" sense.\n\n        The returned operator (``self``) is the derivative of the\n        operator variant where the complex domain is reinterpreted as\n        a product of two real spaces.\n\n        Parameters\n        ----------\n        x : `domain` element\n            Point in which to take the derivative.\n\n        Examples\n        --------\n        >>> c2 = odl.cn(2)\n        >>> op = odl.ComplexModulusSquared(c2)\n        >>> op([3 + 4j, 2])\n        rn(2).element([ 25.,   4.])\n        >>> deriv = op.derivative([3 + 4j, 2])\n        >>> deriv.domain\n        cn(2)\n        >>> deriv.range\n        rn(2)\n        >>> deriv([2 + 1j, 4j])  # [(3*2 + 4*1) / 5, (2*0 + 0*4) / 2]\n        rn(2).element([ 10.,   0.])\n\n        Notes\n        -----\n        The derivative of the squared complex modulus\n\n        .. math::\n            &S: X(\\mathbb{C}) \\to X(\\mathbb{R}), \\\\\n            &S(x) = \\Re(x)^2 + \\Im(x)^2,\n\n        with :math:`X(\\mathbb{F}) = \\mathbb{F}^n` or\n        :math:`L^2(\\Omega, \\mathbb{F})`, is given as\n\n        .. math::\n            &S'(x): X(\\mathbb{C}) \\to X(\\mathbb{R}), \\\\\n            &S'(x)(y) = \\Re(x)\\,\\Re(y) + \\Im(x)\\,\\Im(y).\n\n        It is linear when identifying :math:`\\mathbb{C}` with\n        :math:`\\mathbb{R}^2`, but not complex-linear.\n        \"\"\"\n        op = self\n        x = self.domain.element(x)\n\n        class ComplexModulusSquaredDerivative(Operator):\n\n            \"\"\"Derivative of the squared complex modulus operator.\"\"\"\n\n            def _call(self, y, out):\n                \"\"\"Return ``self(y)``.\"\"\"\n                x.real.multiply(y.real, out=out)\n                out += x.imag * y.imag\n                return out\n\n            @property\n            def adjoint(self):\n                r\"\"\"Adjoint in the \"C = R^2\" sense.\n\n                Adjoint of the derivative:\n\n                Examples\n                --------\n                >>> c2 = odl.cn(2)\n                >>> op = odl.ComplexModulusSquared(c2)\n                >>> deriv = op.derivative([3 + 4j, 2])\n                >>> adj = deriv.adjoint\n                >>> adj.domain\n                rn(2)\n                >>> adj.range\n                cn(2)\n                >>> adj([2, 1])  # [2*(3 + 4j), 1*2]\n                cn(2).element([ 6.+8.j,  2.+0.j])\n\n                Adjointness only holds in the weaker sense that inner products\n                are the same when testing with vectors from the real space, but\n                not when testing complex vectors:\n\n                >>> y1 = deriv.range.element([1, 1])\n                >>> y2 = deriv.range.element([1, -1])\n                >>> adj(y1).inner(adj(y2))  # <M^* y1, M^* y2>\n                (21+0j)\n                >>> deriv(adj(y1)).inner(y2)  # <M M^* y1, y2>\n                21.0\n                >>> x1 = deriv.domain.element([1j, 1j])\n                >>> x2 = deriv.domain.element([1 + 1j, 1j])\n                >>> deriv(x1).inner(deriv(x2))  # <M x1, M x2>\n                28.0\n                >>> adj(deriv(x1)).inner(x2)  # <M^* M x1, x2>\n                (28+4j)\n\n                Notes\n                -----\n                The squared complex modulus derivative is given by\n\n                .. math::\n                    &S'(x): X(\\mathbb{C}) \\to X(\\mathbb{R}), \\\\\n                    &S'(x)(y) = \\Re(x)\\,\\Re(y) + \\Im(x)\\,\\Im(y).\n\n                Thus, its adjoint can (formally) be identified as\n\n                .. math::\n                    &S'(x)^*: X(\\mathbb{R}) \\to X(\\mathbb{C}), \\\\\n                    &S'(x)^*(u) = (\\Re(x)\\,u,\\ \\Im(x)\\,u).\n\n                The operator :math:`A = S'(x)` has the weak adjointness\n                property\n\n                .. math::\n                    \\langle A^* y_1,\\ A^* y_2 \\rangle_{X(\\mathbb{C})} =\n                    \\langle AA^* y_1,\\ y_2 \\rangle_{X(\\mathbb{R})},\n\n                but in general,\n\n                .. math::\n                    \\langle A x,\\ y \\rangle_{X(\\mathbb{R})} \\neq\n                    \\langle x,\\ A^* y \\rangle_{X(\\mathbb{C})},\n\n                in particular\n\n                .. math::\n                    \\langle A x_1,\\ A x_2 \\rangle_{X(\\mathbb{R})} \\neq\n                    \\langle A^*A x_1,\\ x_2 \\rangle_{X(\\mathbb{C})}.\n                \"\"\"\n                deriv = self\n\n                class ComplexModulusSquaredDerivAdj(Operator):\n\n                    def _call(self, u, out):\n                        \"\"\"Implement ``self(u, out)``.\"\"\"\n                        out.assign(x)\n                        out.real *= u\n                        out.imag *= u\n                        return out\n\n                    @property\n                    def adjoint(self):\n                        \"\"\"Adjoint in the \"C = R^2\" sense.\"\"\"\n                        return deriv\n\n                return ComplexModulusSquaredDerivAdj(\n                    deriv.range, deriv.domain, linear=deriv.domain.is_real)\n\n        return ComplexModulusSquaredDerivative(op.domain, op.range,\n                                               linear=op.domain.is_real)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an image to standardized format.", "response": "def convert(image, shape, gray=False, dtype='float64', normalize='max'):\n    \"\"\"Convert image to standardized format.\n\n    Several properties of the input image may be changed including the shape,\n    data type and maximal value of the image. In addition, this function may\n    convert the image into an ODL object and/or a gray scale image.\n    \"\"\"\n\n    image = image.astype(dtype)\n\n    if gray:\n        image[..., 0] *= 0.2126\n        image[..., 1] *= 0.7152\n        image[..., 2] *= 0.0722\n        image = np.sum(image, axis=2)\n\n    if shape is not None:\n        image = skimage.transform.resize(image, shape, mode='constant')\n        image = image.astype(dtype)\n\n    if normalize == 'max':\n        image /= image.max()\n    elif normalize == 'sum':\n        image /= image.sum()\n    else:\n        assert False\n\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolution_phantom(shape=None):\n    # TODO: Store data in some ODL controlled url\n    # TODO: This can be also done with ODL's ellipse_phantom\n    name = 'phantom_resolution.mat'\n    url = URL_CAM + name\n    dct = get_data(name, subset=DATA_SUBSET, url=url)\n    im = np.rot90(dct['im'], k=3)\n\n    return convert(im, shape)", "response": "Resolution phantom for tomographic simulations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the image of the Centre for Mathematical Sciences in Cambridge.", "response": "def building(shape=None, gray=False):\n    \"\"\"Photo of the Centre for Mathematical Sciences in Cambridge.\n\n    Returns\n    -------\n    An image with the following properties:\n        image type: color (or gray scales if `gray=True`)\n        size: [442, 331] (if not specified by `size`)\n        scale: [0, 1]\n        type: float64\n    \"\"\"\n    # TODO: Store data in some ODL controlled url\n    name = 'cms.mat'\n    url = URL_CAM + name\n    dct = get_data(name, subset=DATA_SUBSET, url=url)\n    im = np.rot90(dct['im'], k=3)\n\n    return convert(im, shape, gray=gray)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nblurring kernel for convolution simulations.", "response": "def blurring_kernel(shape=None):\n    \"\"\"Blurring kernel for convolution simulations.\n\n    The kernel is scaled to sum to one.\n\n    Returns\n    -------\n    An image with the following properties:\n        image type: gray scales\n        size: [100, 100] (if not specified by `size`)\n        scale: [0, 1]\n        type: float64\n\n    \"\"\"\n    # TODO: Store data in some ODL controlled url\n    name = 'motionblur.mat'\n    url = URL_CAM + name\n    dct = get_data(name, subset=DATA_SUBSET, url=url)\n\n    return convert(255 - dct['im'], shape, normalize='sum')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef real_space(self):\n        if not is_numeric_dtype(self.dtype):\n            raise ValueError(\n                '`real_space` not defined for non-numeric `dtype`')\n        return self.astype(self.real_dtype)", "response": "The space corresponding to this space s real_dtype."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef complex_space(self):\n        if not is_numeric_dtype(self.dtype):\n            raise ValueError(\n                '`complex_space` not defined for non-numeric `dtype`')\n        return self.astype(self.complex_dtype)", "response": "The space corresponding to this space s complex_dtype."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _astype(self, dtype):\n        kwargs = {}\n        if is_floating_dtype(dtype):\n            # Use weighting only for floating-point types, otherwise, e.g.,\n            # `space.astype(bool)` would fail\n            weighting = getattr(self, 'weighting', None)\n            if weighting is not None:\n                kwargs['weighting'] = weighting\n\n        return type(self)(self.shape, dtype=dtype, **kwargs)", "response": "Internal helper for astype."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of this space with new dtype.", "response": "def astype(self, dtype):\n        \"\"\"Return a copy of this space with new ``dtype``.\n\n        Parameters\n        ----------\n        dtype :\n            Scalar data type of the returned space. Can be provided\n            in any way the `numpy.dtype` constructor understands, e.g.\n            as built-in type or as a string. Data types with non-trivial\n            shapes are not allowed.\n\n        Returns\n        -------\n        newspace : `TensorSpace`\n            Version of this space with given data type.\n        \"\"\"\n        if dtype is None:\n            # Need to filter this out since Numpy iterprets it as 'float'\n            raise ValueError('`None` is not a valid data type')\n\n        dtype = np.dtype(dtype)\n        if dtype == self.dtype:\n            return self\n\n        if is_numeric_dtype(self.dtype):\n            # Caching for real and complex versions (exact dtype mappings)\n            if dtype == self.__real_dtype:\n                if self.__real_space is None:\n                    self.__real_space = self._astype(dtype)\n                return self.__real_space\n            elif dtype == self.__complex_dtype:\n                if self.__complex_space is None:\n                    self.__complex_space = self._astype(dtype)\n                return self.__complex_space\n            else:\n                return self._astype(dtype)\n        else:\n            return self._astype(dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns example random vectors.", "response": "def examples(self):\n        \"\"\"Return example random vectors.\"\"\"\n        # Always return the same numbers\n        rand_state = np.random.get_state()\n        np.random.seed(1337)\n\n        if is_numeric_dtype(self.dtype):\n            yield ('Linearly spaced samples', self.element(\n                np.linspace(0, 1, self.size).reshape(self.shape)))\n            yield ('Normally distributed noise',\n                   self.element(np.random.standard_normal(self.shape)))\n\n        if self.is_real:\n            yield ('Uniformly distributed noise',\n                   self.element(np.random.uniform(size=self.shape)))\n        elif self.is_complex:\n            yield ('Uniformly distributed noise',\n                   self.element(np.random.uniform(size=self.shape) +\n                                np.random.uniform(size=self.shape) * 1j))\n        else:\n            # TODO: return something that always works, like zeros or ones?\n            raise NotImplementedError('no examples available for non-numeric'\n                                      'data type')\n\n        np.random.set_state(rand_state)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying the function graphically.", "response": "def show(self, title=None, method='', indices=None, force_show=False,\n             fig=None, **kwargs):\n        \"\"\"Display the function graphically.\n\n        Parameters\n        ----------\n        title : string, optional\n            Set the title of the figure\n\n        method : string, optional\n            1d methods:\n\n                ``'plot'`` : graph plot\n\n                ``'scatter'`` : scattered 2d points (2nd axis <-> value)\n\n            2d methods:\n\n                ``'imshow'`` : image plot with coloring according to\n                value, including a colorbar.\n\n                ``'scatter'`` : cloud of scattered 3d points\n                (3rd axis <-> value)\n\n        indices : index expression, optional\n            Display a slice of the array instead of the full array. The\n            index expression is most easily created with the `numpy.s_`\n            constructor, i.e. supply ``np.s_[:, 1, :]`` to display the\n            first slice along the second axis.\n            For data with 3 or more dimensions, the 2d slice in the first\n            two axes at the \"middle\" along the remaining axes is shown\n            (semantically ``[:, :, shape[2:] // 2]``).\n            This option is mutually exclusive to ``coords``.\n\n        force_show : bool, optional\n            Whether the plot should be forced to be shown now or deferred until\n            later. Note that some backends always displays the plot, regardless\n            of this value.\n\n        fig : `matplotlib.figure.Figure`, optional\n            The figure to show in. Expected to be of same \"style\", as\n            the figure given by this function. The most common use case\n            is that ``fig`` is the return value of an earlier call to\n            this function.\n\n        kwargs : {'figsize', 'saveto', 'clim', ...}, optional\n            Extra keyword arguments passed on to the display method.\n            See the Matplotlib functions for documentation of extra\n            options.\n\n        Returns\n        -------\n        fig : `matplotlib.figure.Figure`\n            The resulting figure. It is also shown to the user.\n\n        See Also\n        --------\n        odl.util.graphics.show_discrete_data : Underlying implementation\n        \"\"\"\n        from odl.discr import uniform_grid\n        from odl.util.graphics import show_discrete_data\n\n        # Default to showing x-y slice \"in the middle\"\n        if indices is None and self.ndim >= 3:\n            indices = tuple(\n                [slice(None)] * 2 + [n // 2 for n in self.space.shape[2:]]\n            )\n\n        if isinstance(indices, (Integral, slice)):\n            indices = (indices,)\n        elif indices is None or indices == Ellipsis:\n            indices = (slice(None),) * self.ndim\n        else:\n            indices = tuple(indices)\n\n        # Replace None by slice(None)\n        indices = tuple(slice(None) if idx is None else idx for idx in indices)\n\n        if Ellipsis in indices:\n            # Replace Ellipsis with the correct number of [:] expressions\n            pos = indices.index(Ellipsis)\n            indices = (indices[:pos] +\n                       (np.s_[:], ) * (self.ndim - len(indices) + 1) +\n                       indices[pos + 1:])\n\n        if len(indices) < self.ndim:\n            raise ValueError('too few axes ({} < {})'.format(len(indices),\n                                                             self.ndim))\n        if len(indices) > self.ndim:\n            raise ValueError('too many axes ({} > {})'.format(len(indices),\n                                                              self.ndim))\n\n        # Squeeze grid and values according to the index expression\n        full_grid = uniform_grid([0] * self.ndim, np.array(self.shape) - 1,\n                                 self.shape)\n        grid = full_grid[indices].squeeze()\n        values = self.asarray()[indices].squeeze()\n\n        return show_discrete_data(values, grid, title=title, method=method,\n                                  force_show=force_show, fig=fig, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef astra_supports(feature):\n    from odl.util.utility import pkg_supports\n    return pkg_supports(feature, ASTRA_VERSION, ASTRA_FEATURES)", "response": "Return bool indicating whether current ASTRA supports feature."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef astra_volume_geometry(reco_space):\n    if not isinstance(reco_space, DiscreteLp):\n        raise TypeError('`reco_space` {!r} is not a DiscreteLp instance'\n                        ''.format(reco_space))\n\n    if not reco_space.is_uniform:\n        raise ValueError('`reco_space` {} is not uniformly discretized')\n\n    vol_shp = reco_space.partition.shape\n    vol_min = reco_space.partition.min_pt\n    vol_max = reco_space.partition.max_pt\n\n    if reco_space.ndim == 2:\n        # ASTRA does in principle support custom minimum and maximum\n        # values for the volume extent also in earlier versions, but running\n        # the algorithm fails if voxels are non-isotropic.\n        if (not reco_space.partition.has_isotropic_cells and\n                not astra_supports('anisotropic_voxels_2d')):\n            raise NotImplementedError(\n                'non-isotropic pixels in 2d volumes not supported by ASTRA '\n                'v{}'.format(ASTRA_VERSION))\n        # Given a 2D array of shape (x, y), a volume geometry is created as:\n        #    astra.create_vol_geom(x, y, y_min, y_max, x_min, x_max)\n        # yielding a dictionary:\n        #   {'GridRowCount': x,\n        #    'GridColCount': y,\n        #    'WindowMinX': y_min,\n        #    'WindowMaxX': y_max,\n        #    'WindowMinY': x_min,\n        #    'WindowMaxY': x_max}\n        #\n        # NOTE: this setting is flipped with respect to x and y. We do this\n        # as part of a global rotation of the geometry by -90 degrees, which\n        # avoids rotating the data.\n        # NOTE: We need to flip the sign of the (ODL) x component since\n        # ASTRA seems to move it in the other direction. Not quite clear\n        # why.\n        vol_geom = astra.create_vol_geom(vol_shp[0], vol_shp[1],\n                                         vol_min[1], vol_max[1],\n                                         -vol_max[0], -vol_min[0])\n    elif reco_space.ndim == 3:\n        # Not supported in all versions of ASTRA\n        if (not reco_space.partition.has_isotropic_cells and\n                not astra_supports('anisotropic_voxels_3d')):\n            raise NotImplementedError(\n                'non-isotropic voxels in 3d volumes not supported by ASTRA '\n                'v{}'.format(ASTRA_VERSION))\n        # Given a 3D array of shape (x, y, z), a volume geometry is created as:\n        #    astra.create_vol_geom(y, z, x, z_min, z_max, y_min, y_max,\n        #                          x_min, x_max),\n        # yielding a dictionary:\n        #   {'GridColCount': z,\n        #    'GridRowCount': y,\n        #    'GridSliceCount': x,\n        #    'WindowMinX': z_max,\n        #    'WindowMaxX': z_max,\n        #    'WindowMinY': y_min,\n        #    'WindowMaxY': y_min,\n        #    'WindowMinZ': x_min,\n        #    'WindowMaxZ': x_min}\n        vol_geom = astra.create_vol_geom(vol_shp[1], vol_shp[2], vol_shp[0],\n                                         vol_min[2], vol_max[2],\n                                         vol_min[1], vol_max[1],\n                                         vol_min[0], vol_max[0])\n    else:\n        raise ValueError('{}-dimensional volume geometries not supported '\n                         'by ASTRA'.format(reco_space.ndim))\n    return vol_geom", "response": "Create an ASTRA volume geometry from the discretized domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef astra_conebeam_3d_geom_to_vec(geometry):\n    angles = geometry.angles\n    vectors = np.zeros((angles.size, 12))\n\n    # Source position\n    vectors[:, 0:3] = geometry.src_position(angles)\n\n    # Center of detector in 3D space\n    mid_pt = geometry.det_params.mid_pt\n    vectors[:, 3:6] = geometry.det_point_position(angles, mid_pt)\n\n    # Vectors from detector pixel (0, 0) to (1, 0) and (0, 0) to (0, 1)\n    # `det_axes` gives shape (N, 2, 3), swap to get (2, N, 3)\n    det_axes = moveaxis(geometry.det_axes(angles), -2, 0)\n    px_sizes = geometry.det_partition.cell_sides\n    # Swap detector axes to have better memory layout in  projection data.\n    # ASTRA produces `(v, theta, u)` layout, and to map to ODL layout\n    # `(theta, u, v)` a complete roll must be performed, which is the\n    # worst case (compeltely discontiguous).\n    # Instead we swap `u` and `v`, resulting in the effective ASTRA result\n    # `(u, theta, v)`. Here we only need to swap axes 0 and 1, which\n    # keeps at least contiguous blocks in `v`.\n    vectors[:, 9:12] = det_axes[0] * px_sizes[0]\n    vectors[:, 6:9] = det_axes[1] * px_sizes[1]\n\n    # ASTRA has (z, y, x) axis convention, in contrast to (x, y, z) in ODL,\n    # so we need to adapt to this by changing the order.\n    newind = []\n    for i in range(4):\n        newind += [2 + 3 * i, 1 + 3 * i, 0 + 3 * i]\n    vectors = vectors[:, newind]\n\n    return vectors", "response": "Create vectors for an ASTRA cone beam from an ODL geometry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating vectors for an ASTRA projection geometry from an ODL geometry.", "response": "def astra_conebeam_2d_geom_to_vec(geometry):\n    \"\"\"Create vectors for ASTRA projection geometries from ODL geometry.\n\n    The 2D vectors are used to create an ASTRA projection geometry for\n    fan beam geometries, see ``'fanflat_vec'`` in the\n    `ASTRA projection geometry documentation`_.\n\n    Each row of the returned vectors corresponds to a single projection\n    and consists of ::\n\n        (srcX, srcY, dX, dY, uX, uY)\n\n    with\n\n        - ``src``: the ray source position\n        - ``d``  : the center of the detector\n        - ``u``  : the vector from detector pixel 0 to 1\n\n    Parameters\n    ----------\n    geometry : `Geometry`\n        ODL projection geometry from which to create the ASTRA geometry.\n\n    Returns\n    -------\n    vectors : `numpy.ndarray`\n        Array of shape ``(num_angles, 6)`` containing the vectors.\n\n    References\n    ----------\n    .. _ASTRA projection geometry documentation:\n       http://www.astra-toolbox.com/docs/geom2d.html#projection-geometries\n    \"\"\"\n    # Instead of rotating the data by 90 degrees counter-clockwise,\n    # we subtract pi/2 from the geometry angles, thereby rotating the\n    # geometry by 90 degrees clockwise\n    rot_minus_90 = euler_matrix(-np.pi / 2)\n    angles = geometry.angles\n    vectors = np.zeros((angles.size, 6))\n\n    # Source position\n    src_pos = geometry.src_position(angles)\n    vectors[:, 0:2] = rot_minus_90.dot(src_pos.T).T  # dot along 2nd axis\n\n    # Center of detector\n    mid_pt = geometry.det_params.mid_pt\n    # Need to cast `mid_pt` to float since otherwise the empty axis is\n    # not removed\n    centers = geometry.det_point_position(angles, float(mid_pt))\n    vectors[:, 2:4] = rot_minus_90.dot(centers.T).T\n\n    # Vector from detector pixel 0 to 1\n    det_axis = rot_minus_90.dot(geometry.det_axis(angles).T).T\n    px_size = geometry.det_partition.cell_sides[0]\n    vectors[:, 4:6] = det_axis * px_size\n\n    return vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates vectors for an ASTRA projection geometry from parallel 3D geometries.", "response": "def astra_parallel_3d_geom_to_vec(geometry):\n    \"\"\"Create vectors for ASTRA projection geometries from ODL geometry.\n\n    The 3D vectors are used to create an ASTRA projection geometry for\n    parallel beam geometries, see ``'parallel3d_vec'`` in the\n    `ASTRA projection geometry documentation`_.\n\n    Each row of the returned vectors corresponds to a single projection\n    and consists of ::\n\n        (rayX, rayY, rayZ, dX, dY, dZ, uX, uY, uZ, vX, vY, vZ)\n\n    with\n\n        - ``ray``: the ray direction\n        - ``d``  : the center of the detector\n        - ``u``  : the vector from detector pixel ``(0,0)`` to ``(0,1)``\n        - ``v``  : the vector from detector pixel ``(0,0)`` to ``(1,0)``\n\n    Parameters\n    ----------\n    geometry : `Geometry`\n        ODL projection geometry from which to create the ASTRA geometry.\n\n    Returns\n    -------\n    vectors : `numpy.ndarray`\n        Array of shape ``(num_angles, 12)`` containing the vectors.\n\n    References\n    ----------\n    .. _ASTRA projection geometry documentation:\n       http://www.astra-toolbox.com/docs/geom3d.html#projection-geometries\n    \"\"\"\n    angles = geometry.angles\n    mid_pt = geometry.det_params.mid_pt\n\n    vectors = np.zeros((angles.shape[-1], 12))\n\n    # Ray direction = -(detector-to-source normal vector)\n    vectors[:, 0:3] = -geometry.det_to_src(angles, mid_pt)\n\n    # Center of the detector in 3D space\n    vectors[:, 3:6] = geometry.det_point_position(angles, mid_pt)\n\n    # Vectors from detector pixel (0, 0) to (1, 0) and (0, 0) to (0, 1)\n    # `det_axes` gives shape (N, 2, 3), swap to get (2, N, 3)\n    det_axes = moveaxis(geometry.det_axes(angles), -2, 0)\n    px_sizes = geometry.det_partition.cell_sides\n    # Swap detector axes to have better memory layout in  projection data.\n    # ASTRA produces `(v, theta, u)` layout, and to map to ODL layout\n    # `(theta, u, v)` a complete roll must be performed, which is the\n    # worst case (compeltely discontiguous).\n    # Instead we swap `u` and `v`, resulting in the effective ASTRA result\n    # `(u, theta, v)`. Here we only need to swap axes 0 and 1, which\n    # keeps at least contiguous blocks in `v`.\n    vectors[:, 9:12] = det_axes[0] * px_sizes[0]\n    vectors[:, 6:9] = det_axes[1] * px_sizes[1]\n\n    # ASTRA has (z, y, x) axis convention, in contrast to (x, y, z) in ODL,\n    # so we need to adapt to this by changing the order.\n    new_ind = []\n    for i in range(4):\n        new_ind += [2 + 3 * i, 1 + 3 * i, 0 + 3 * i]\n    vectors = vectors[:, new_ind]\n    return vectors"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an ASTRA projection geometry from an ODL geometry object.", "response": "def astra_projection_geometry(geometry):\n    \"\"\"Create an ASTRA projection geometry from an ODL geometry object.\n\n    As of ASTRA version 1.7, the length values are not required any more to be\n    rescaled for 3D geometries and non-unit (but isotropic) voxel sizes.\n\n    Parameters\n    ----------\n    geometry : `Geometry`\n        ODL projection geometry from which to create the ASTRA geometry.\n\n    Returns\n    -------\n    proj_geom : dict\n        Dictionary defining the ASTRA projection geometry.\n    \"\"\"\n    if not isinstance(geometry, Geometry):\n        raise TypeError('`geometry` {!r} is not a `Geometry` instance'\n                        ''.format(geometry))\n\n    if 'astra' in geometry.implementation_cache:\n        # Shortcut, reuse already computed value.\n        return geometry.implementation_cache['astra']\n\n    if not geometry.det_partition.is_uniform:\n        raise ValueError('non-uniform detector sampling is not supported')\n\n    if (isinstance(geometry, ParallelBeamGeometry) and\n            isinstance(geometry.detector, (Flat1dDetector, Flat2dDetector)) and\n            geometry.ndim == 2):\n        # TODO: change to parallel_vec when available\n        det_width = geometry.det_partition.cell_sides[0]\n        det_count = geometry.detector.size\n        # Instead of rotating the data by 90 degrees counter-clockwise,\n        # we subtract pi/2 from the geometry angles, thereby rotating the\n        # geometry by 90 degrees clockwise\n        angles = geometry.angles - np.pi / 2\n        proj_geom = astra.create_proj_geom('parallel', det_width, det_count,\n                                           angles)\n\n    elif (isinstance(geometry, DivergentBeamGeometry) and\n          isinstance(geometry.detector, (Flat1dDetector, Flat2dDetector)) and\n          geometry.ndim == 2):\n        det_count = geometry.detector.size\n        vec = astra_conebeam_2d_geom_to_vec(geometry)\n        proj_geom = astra.create_proj_geom('fanflat_vec', det_count, vec)\n\n    elif (isinstance(geometry, ParallelBeamGeometry) and\n          isinstance(geometry.detector, (Flat1dDetector, Flat2dDetector)) and\n          geometry.ndim == 3):\n        # Swap detector axes (see astra_*_3d_to_vec)\n        det_row_count = geometry.det_partition.shape[0]\n        det_col_count = geometry.det_partition.shape[1]\n        vec = astra_parallel_3d_geom_to_vec(geometry)\n        proj_geom = astra.create_proj_geom('parallel3d_vec', det_row_count,\n                                           det_col_count, vec)\n\n    elif (isinstance(geometry, DivergentBeamGeometry) and\n          isinstance(geometry.detector, (Flat1dDetector, Flat2dDetector)) and\n          geometry.ndim == 3):\n        # Swap detector axes (see astra_*_3d_to_vec)\n        det_row_count = geometry.det_partition.shape[0]\n        det_col_count = geometry.det_partition.shape[1]\n        vec = astra_conebeam_3d_geom_to_vec(geometry)\n        proj_geom = astra.create_proj_geom('cone_vec', det_row_count,\n                                           det_col_count, vec)\n    else:\n        raise NotImplementedError('unknown ASTRA geometry type {!r}'\n                                  ''.format(geometry))\n\n    if 'astra' not in geometry.implementation_cache:\n        # Save computed value for later\n        geometry.implementation_cache['astra'] = proj_geom\n\n    return proj_geom"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef astra_data(astra_geom, datatype, data=None, ndim=2, allow_copy=False):\n    if data is not None:\n        if isinstance(data, (DiscreteLpElement, np.ndarray)):\n            ndim = data.ndim\n        else:\n            raise TypeError('`data` {!r} is neither DiscreteLpElement '\n                            'instance nor a `numpy.ndarray`'.format(data))\n    else:\n        ndim = int(ndim)\n\n    if datatype == 'volume':\n        astra_dtype_str = '-vol'\n    elif datatype == 'projection':\n        astra_dtype_str = '-sino'\n    else:\n        raise ValueError('`datatype` {!r} not understood'.format(datatype))\n\n    # Get the functions from the correct module\n    if ndim == 2:\n        link = astra.data2d.link\n        create = astra.data2d.create\n    elif ndim == 3:\n        link = astra.data3d.link\n        create = astra.data3d.create\n    else:\n        raise ValueError('{}-dimensional data not supported'\n                         ''.format(ndim))\n\n    # ASTRA checks if data is c-contiguous and aligned\n    if data is not None:\n        if allow_copy:\n            data_array = np.asarray(data, dtype='float32', order='C')\n            return link(astra_dtype_str, astra_geom, data_array)\n        else:\n            if isinstance(data, np.ndarray):\n                return link(astra_dtype_str, astra_geom, data)\n            elif data.tensor.impl == 'numpy':\n                return link(astra_dtype_str, astra_geom, data.asarray())\n            else:\n                # Something else than NumPy data representation\n                raise NotImplementedError('ASTRA supports data wrapping only '\n                                          'for `numpy.ndarray` instances, got '\n                                          '{!r}'.format(data))\n    else:\n        return create(astra_dtype_str, astra_geom)", "response": "Create an ASTRA internal data object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef astra_projector(vol_interp, astra_vol_geom, astra_proj_geom, ndim, impl):\n    if vol_interp not in ('nearest', 'linear'):\n        raise ValueError(\"`vol_interp` '{}' not understood\"\n                         ''.format(vol_interp))\n    impl = str(impl).lower()\n    if impl not in ('cpu', 'cuda'):\n        raise ValueError(\"`impl` '{}' not understood\"\n                         ''.format(impl))\n\n    if 'type' not in astra_proj_geom:\n        raise ValueError('invalid projection geometry dict {}'\n                         ''.format(astra_proj_geom))\n    if ndim == 3 and impl == 'cpu':\n        raise ValueError('3D projectors not supported on CPU')\n\n    ndim = int(ndim)\n\n    proj_type = astra_proj_geom['type']\n    if proj_type not in ('parallel', 'fanflat', 'fanflat_vec',\n                         'parallel3d', 'parallel3d_vec', 'cone', 'cone_vec'):\n        raise ValueError('invalid geometry type {!r}'.format(proj_type))\n\n    # Mapping from interpolation type and geometry to ASTRA projector type.\n    # \"I\" means probably mathematically inconsistent. Some projectors are\n    # not implemented, e.g. CPU 3d projectors in general.\n    type_map_cpu = {'parallel': {'nearest': 'line',\n                                 'linear': 'linear'},  # I\n                    'fanflat': {'nearest': 'line_fanflat',\n                                'linear': 'line_fanflat'},  # I\n                    'parallel3d': {'nearest': 'linear3d',  # I\n                                   'linear': 'linear3d'},  # I\n                    'cone': {'nearest': 'linearcone',  # I\n                             'linear': 'linearcone'}}  # I\n    type_map_cpu['fanflat_vec'] = type_map_cpu['fanflat']\n    type_map_cpu['parallel3d_vec'] = type_map_cpu['parallel3d']\n    type_map_cpu['cone_vec'] = type_map_cpu['cone']\n\n    # GPU algorithms not necessarily require a projector, but will in future\n    # releases making the interface more coherent regarding CPU and GPU\n    type_map_cuda = {'parallel': 'cuda',  # I\n                     'parallel3d': 'cuda3d'}  # I\n    type_map_cuda['fanflat'] = type_map_cuda['parallel']\n    type_map_cuda['fanflat_vec'] = type_map_cuda['fanflat']\n    type_map_cuda['cone'] = type_map_cuda['parallel3d']\n    type_map_cuda['parallel3d_vec'] = type_map_cuda['parallel3d']\n    type_map_cuda['cone_vec'] = type_map_cuda['cone']\n\n    # create config dict\n    proj_cfg = {}\n    if impl == 'cpu':\n        proj_cfg['type'] = type_map_cpu[proj_type][vol_interp]\n    else:  # impl == 'cuda'\n        proj_cfg['type'] = type_map_cuda[proj_type]\n    proj_cfg['VolumeGeometry'] = astra_vol_geom\n    proj_cfg['ProjectionGeometry'] = astra_proj_geom\n    proj_cfg['options'] = {}\n\n    # Add the hacky 1/r^2 weighting exposed in intermediate versions of\n    # ASTRA\n    if (proj_type in ('cone', 'cone_vec') and\n            astra_supports('cone3d_hacky_density_weighting')):\n        proj_cfg['options']['DensityWeighting'] = True\n\n    if ndim == 2:\n        return astra.projector.create(proj_cfg)\n    else:\n        return astra.projector3d.create(proj_cfg)", "response": "Create an ASTRA internal projector configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef astra_algorithm(direction, ndim, vol_id, sino_id, proj_id, impl):\n    if direction not in ('forward', 'backward'):\n        raise ValueError(\"`direction` '{}' not understood\".format(direction))\n    if ndim not in (2, 3):\n        raise ValueError('{}-dimensional projectors not supported'\n                         ''.format(ndim))\n    if impl not in ('cpu', 'cuda'):\n        raise ValueError(\"`impl` type '{}' not understood\"\n                         ''.format(impl))\n    if ndim == 3 and impl == 'cpu':\n        raise NotImplementedError(\n            '3d algorithms for CPU not supported by ASTRA')\n    if proj_id is None and impl == 'cpu':\n        raise ValueError(\"'cpu' implementation requires projector ID\")\n\n    algo_map = {'forward': {2: {'cpu': 'FP', 'cuda': 'FP_CUDA'},\n                            3: {'cpu': None, 'cuda': 'FP3D_CUDA'}},\n                'backward': {2: {'cpu': 'BP', 'cuda': 'BP_CUDA'},\n                             3: {'cpu': None, 'cuda': 'BP3D_CUDA'}}}\n\n    algo_cfg = {'type': algo_map[direction][ndim][impl],\n                'ProjectorId': proj_id,\n                'ProjectionDataId': sino_id}\n    if direction is 'forward':\n        algo_cfg['VolumeDataId'] = vol_id\n    else:\n        algo_cfg['ReconstructionDataId'] = vol_id\n\n    # Create ASTRA algorithm object\n    return astra.algorithm.create(algo_cfg)", "response": "Create an ASTRA internal algorithm object for the given projector."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_tensorflow_layer(odl_op, name='ODLOperator',\n                        differentiable=True):\n    \"\"\"Convert `Operator` or `Functional` to a tensorflow layer.\n\n    Parameters\n    ----------\n    odl_op : `Operator` or `Functional`\n        The operator that should be wrapped as a tensorflow layer.\n    name : str\n        Default name for tensorflow layers created.\n    differentiable : boolean\n        ``True`` if the layer should be differentiable, in which case\n        ``odl_op`` should implement `Operator.derivative` which in turn\n        implements `Operator.adjoint`. In this case, the adjoint of the\n        derivative is properly wrapped in ``tensorflow_layer``, and\n        gradients propagate as expected.\n\n        If ``False``, the gradient is defined as everywhere zero.\n\n    Returns\n    -------\n    tensorflow_layer : callable\n        Callable that, when called with a `tensorflow.Tensor` of shape\n        ``(n,) + odl_op.domain.shape + (1,)`` where ``n`` is the batch size,\n        returns another `tensorflow.Tensor` which is a lazy evaluation of\n        ``odl_op``.\n\n        If ``odl_op`` is an `Operator`, the shape of the returned tensor is\n        ``(n,) + odl_op.range.shape + (1,)``.\n\n        If ``odl_op`` is an `Functional`, the shape of the returned tensor is\n        ``(n,)``.\n\n        The ``dtype`` of the tensor is ``odl_op.range.dtype``.\n    \"\"\"\n    default_name = name\n\n    def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n        \"\"\"Define custom py_func which takes also a grad op as argument.\n\n        We need to overwrite this function since the default tensorflow\n        `tf.py_func` does not support custom gradients.\n\n        See tensorflow `issue #1095`_ for more information.\n\n        Parameters\n        ----------\n        func : callable\n            Python function that takes and returns numpy arrays.\n        inp : sequence of `tensorflow.Tensor`\n            Input tensors for the function\n        Tout : sequence of `tensorflow.dtype`\n            Datatype of the output(s).\n        stateful : bool, optional\n            If the function has internal state, i.e. if calling the function\n            with a given input repeatedly could give different output.\n        name : string, optional\n            Name of the python function.\n        grad : callbable, optional\n            Gradient of the function.\n\n        References\n        ----------\n        .. _issue #1095: https://github.com/tensorflow/tensorflow/issues/1095\n        \"\"\"\n        if grad is None:\n            return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n        else:\n            if stateful:\n                override_name = 'PyFunc'\n            else:\n                override_name = 'PyFuncStateless'\n\n            # Need to generate a unique name to avoid duplicates:\n            rnd_name = override_name + 'Grad' + str(uuid.uuid4())\n\n            tf.RegisterGradient(rnd_name)(grad)\n            g = tf.get_default_graph()\n\n            with g.gradient_override_map({override_name: rnd_name}):\n                return tf.py_func(func, inp, Tout, stateful=stateful,\n                                  name=name)\n\n    def tensorflow_layer_grad_impl(x, dy, name):\n        \"\"\"Implementation of the tensorflow gradient.\n\n        Gradient in tensorflow is equivalent to the adjoint of the derivative\n        in ODL.\n\n        Returns a `tensorflow.Tensor` that represents a lazy application of ::\n\n            odl_op.derivative(x).adjoint(dy)\n\n        Parameters\n        ----------\n        x : `numpy.ndarray`\n            Point(s) in which the derivative should be taken.\n            If ``odl_op`` is an `Operator` the axes are:\n                0 : batch id. This is a constant if ``fixed_size`` is\n                    ``True``, otherwise it is dynamic.\n                1, ..., n-2 : spatial dimensions of data.\n                n-1 : (currently) unused data channel.\n            If ``odl_op`` is a `Functional` the axes are:\n                0 : batch id.\n        dy : `tensorflow.Tensor`\n            Point(s) in which the adjoint of the derivative of the\n            operator should be evaluated.\n            The axes are:\n                0 : batch id. Should be pairwise matched with ``x``.\n                1, ..., m-2 : spatial dimensions of data.\n                m-1 : (currently) unused data channel.\n        name : string\n            Name of the tensor.\n\n        Returns\n        -------\n        result : `tensorflow.Tensor`\n            Lazy result of the computation.\n            If ``odl_op`` is an `Operator` the axes are:\n                0 : batch id.\n                1, ..., n-2 : spatial dimensions of data.\n                n-1 : (currently) unused data channel.\n            If ``odl_op`` is a `Functional` the axes are:\n                0 : batch id.\n        \"\"\"\n        with tf.name_scope(name):\n            # Validate the input/output shape\n            x_shape = x.get_shape()\n            dy_shape = dy.get_shape()\n            try:\n                # Lazy check if the first dimension is dynamic\n                n_x = int(x_shape[0])\n                fixed_size = True\n            except TypeError:\n                n_x = x_shape[0]\n                fixed_size = False\n\n            if odl_op.is_functional:\n                in_shape = (n_x,)\n            else:\n                in_shape = (n_x,) + space_shape(odl_op.range) + (1,)\n            out_shape = (n_x,) + space_shape(odl_op.domain) + (1,)\n\n            assert x_shape[1:] == space_shape(odl_op.domain) + (1,)\n            if odl_op.is_functional:\n                assert dy_shape[1:] == ()\n            else:\n                assert dy_shape[1:] == space_shape(odl_op.range) + (1,)\n\n            def _impl(x, dy):\n                \"\"\"Implementation of the adjoint of the derivative.\n\n                Returns ::\n\n                    odl_op.derivative(x).adjoint(dy)\n\n                Parameters\n                ----------\n                x : `numpy.ndarray`\n                    Point(s) in which the derivative should be taken.\n                    If ``odl_op`` is an `Operator` the axes are:\n                        0 : batch id. This is a constant if ``fixed_size`` is\n                            true, otherwise it is dynamic.\n                        1, ..., n-2 : spatial dimensions of data.\n                        n-1 : (currently) unused data channel.\n                    If ``odl_op`` is a `Functional` the axes are:\n                        0 : batch id.\n                dy : `numpy.ndarray`\n                    Point(s) in which the adjoint of the derivative of the\n                    operator should be evaluated.\n                    The axes are:\n                        0 : batch id. Should be pairwise matched with ``x``.\n                        1, ..., m-2 : spatial dimensions of data.\n                        m-1 : (currently) unused data channel.\n\n                Returns\n                -------\n                result : `numpy.ndarray`\n                    Result of the computation.\n\n                    If ``odl_op`` is an `Operator` the axes are:\n                        0 : batch id.\n                        1, ..., n-2 : spatial dimensions of data.\n                        n-1 : (currently) unused data channel.\n                    If ``odl_op`` is a `Functional` the axes are:\n                        0 : batch id.\n                \"\"\"\n                # Validate the shape of the given input\n                if fixed_size:\n                    x_out_shape = out_shape\n                    assert x.shape == out_shape\n                    assert dy.shape == in_shape\n                else:\n                    x_out_shape = (x.shape[0],) + out_shape[1:]\n                    assert x.shape[1:] == out_shape[1:]\n                    assert dy.shape[1:] == in_shape[1:]\n\n                # Evaluate the operator on all inputs in the batch.\n                out = np.empty(x_out_shape, odl_op.domain.dtype)\n                out_element = odl_op.domain.element()\n                for i in range(x_out_shape[0]):\n                    if odl_op.is_functional:\n                        xi = x[i, ..., 0]\n                        dyi = dy[i]\n                        out[i, ..., 0] = np.asarray(odl_op.gradient(xi)) * dyi\n                    else:\n                        xi = x[i, ..., 0]\n                        dyi = dy[i, ..., 0]\n                        odl_op.derivative(xi).adjoint(dyi,\n                                                      out=out_element)\n                        out[i, ..., 0] = np.asarray(out_element)\n\n                # Rescale the domain/range according to the weighting since\n                # tensorflow does not have weighted spaces.\n                try:\n                    dom_weight = odl_op.domain.weighting.const\n                except AttributeError:\n                    dom_weight = 1.0\n\n                try:\n                    ran_weight = odl_op.range.weighting.const\n                except AttributeError:\n                    ran_weight = 1.0\n\n                scale = dom_weight / ran_weight\n                out *= scale\n\n                return out\n\n            with ops.name_scope(name + '_pyfunc', values=[x, dy]) as name_call:\n                result = py_func(_impl,\n                                 [x, dy],\n                                 [odl_op.domain.dtype],\n                                 name=name_call,\n                                 stateful=False)\n\n                # We must manually set the output shape since tensorflow cannot\n                # figure it out\n                result = result[0]\n                result.set_shape(out_shape)\n                return result\n\n    def tensorflow_layer(x, name=None):\n        \"\"\"Implementation of the tensorflow call.\n\n        Returns a `tensorflow.Tensor` that represents a lazy application of\n        ``odl_op`` to ``x``.\n\n        Parameters\n        ----------\n        x : `tensorflow.Tensor`\n            Point(s) to which the layer should be applied.\n            The axes are:\n                0 : batch id. Can be fixed or dynamic.\n                1, ..., n-2 : spatial dimensions of data.\n                n-1 : (currently) unused data channel.\n        name : string\n            Name of the tensor. Default: Defaultname.\n\n        Returns\n        -------\n        result : `tensorflow.Tensor`\n            Lazy result of the computation.\n            If ``odl_op`` is an `Operator` the axes are:\n                0 : batch id.\n                1, ..., m-2 : spatial dimensions of data.\n                m-1 : (currently) unused data channel.\n            If ``odl_op`` is a `Functional` the axes are:\n                0 : batch id.\n        \"\"\"\n        if name is None:\n            name = default_name\n\n        with tf.name_scope(name):\n            # Validate input shape\n            x_shape = x.get_shape()\n            try:\n                # Lazy check if the first dimension is dynamic\n                n_x = int(x_shape[0])\n                fixed_size = True\n            except TypeError:\n                n_x = x_shape[0]\n                fixed_size = False\n\n            in_shape = (n_x,) + space_shape(odl_op.domain) + (1,)\n            if odl_op.is_functional:\n                out_shape = (n_x,)\n            else:\n                out_shape = (n_x,) + space_shape(odl_op.range) + (1,)\n\n            assert x_shape[1:] == space_shape(odl_op.domain) + (1,)\n\n            out_dtype = getattr(odl_op.range, 'dtype',\n                                odl_op.domain.dtype)\n\n            def _impl(x):\n                \"\"\"Implementation of the tensorflow layer.\n\n                Parameters\n                ----------\n                x : `numpy.ndarray`\n                    Point(s) in which the operator should be evaluated.\n                    The axes are:\n                        0 : batch id. This is a constant if ``fixed_size`` is\n                            true, otherwise it is dynamic.\n                        1, ..., n-2 : spatial dimensions of data.\n                        n-1 : (currently) unused data channel.\n\n                Returns\n                -------\n                result : `numpy.ndarray`\n                    Result of the computation.\n                    The axes are:\n                        0 : batch id. Data is pairwise matched with ``x``.\n                        1, ..., m-2 : spatial dimensions of data.\n                        m-1 : (currently) unused data channel.\n                \"\"\"\n                # Validate input shape\n                if fixed_size:\n                    x_out_shape = out_shape\n                    assert x.shape == in_shape\n                else:\n                    x_out_shape = (x.shape[0],) + out_shape[1:]\n                    assert x.shape[1:] == in_shape[1:]\n\n                # Evaluate the operator on all inputs in the batch.\n                out = np.empty(x_out_shape, out_dtype)\n                out_element = odl_op.range.element()\n                for i in range(x_out_shape[0]):\n                    if odl_op.is_functional:\n                        out[i] = odl_op(x[i, ..., 0])\n                    else:\n                        odl_op(x[i, ..., 0], out=out_element)\n                        out[i, ..., 0] = np.asarray(out_element)\n\n                return out\n\n            if differentiable:\n                def tensorflow_layer_grad(op, grad):\n                    \"\"\"Thin wrapper for the gradient.\"\"\"\n                    x = op.inputs[0]\n                    return tensorflow_layer_grad_impl(x, grad,\n                                                      name=name + '_grad')\n            else:\n                tensorflow_layer_grad = None\n\n            with ops.name_scope(name + '_pyfunc', values=[x]) as name_call:\n                result = py_func(_impl,\n                                 [x],\n                                 [out_dtype],\n                                 name=name_call,\n                                 stateful=False,\n                                 grad=tensorflow_layer_grad)\n\n                # We must manually set the output shape since tensorflow cannot\n                # figure it out\n                result = result[0]\n                result.set_shape(out_shape)\n                return result\n\n    return tensorflow_layer", "response": "Convert an operator or functional to a tensorflow layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef space_shape(space):\n    if isinstance(space, odl.ProductSpace) and space.is_power_space:\n        return (len(space),) + space[0].shape\n    else:\n        return space.shape", "response": "Return the base shape of a product space including power space base shape."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimplement calling the operator by calling scipy. signal. fftconvolve.", "response": "def _call(self, x):\n        \"\"\"Implement calling the operator by calling scipy.\"\"\"\n        return scipy.signal.fftconvolve(self.kernel, x, mode='same')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a function to the boundary of an n - dimensional array.", "response": "def apply_on_boundary(array, func, only_once=True, which_boundaries=None,\n                      axis_order=None, out=None):\n    \"\"\"Apply a function of the boundary of an n-dimensional array.\n\n    All other values are preserved as-is.\n\n    Parameters\n    ----------\n    array : `array-like`\n        Modify the boundary of this array\n    func : callable or sequence of callables\n        If a single function is given, assign\n        ``array[slice] = func(array[slice])`` on the boundary slices,\n        e.g. use ``lamda x: x / 2`` to divide values by 2.\n        A sequence of functions is applied per axis separately. It\n        must have length ``array.ndim`` and may consist of one function\n        or a 2-tuple of functions per axis.\n        ``None`` entries in a sequence cause the axis (side) to be\n        skipped.\n    only_once : bool, optional\n        If ``True``, ensure that each boundary point appears in exactly\n        one slice. If ``func`` is a list of functions, the\n        ``axis_order`` determines which functions are applied to nodes\n        which appear in multiple slices, according to the principle\n        \"first-come, first-served\".\n    which_boundaries : sequence, optional\n        If provided, this sequence determines per axis whether to\n        apply the function at the boundaries in each axis. The entry\n        in each axis may consist in a single bool or a 2-tuple of\n        bool. In the latter case, the first tuple entry decides for\n        the left, the second for the right boundary. The length of the\n        sequence must be ``array.ndim``. ``None`` is interpreted as\n        \"all boundaries\".\n    axis_order : sequence of ints, optional\n        Permutation of ``range(array.ndim)`` defining the order in which\n        to process the axes. If combined with ``only_once`` and a\n        function list, this determines which function is evaluated in\n        the points that are potentially processed multiple times.\n    out : `numpy.ndarray`, optional\n        Location in which to store the result, can be the same as ``array``.\n        Default: copy of ``array``\n\n    Examples\n    --------\n    >>> arr = np.ones((3, 3))\n    >>> apply_on_boundary(arr, lambda x: x / 2)\n    array([[ 0.5,  0.5,  0.5],\n           [ 0.5,  1. ,  0.5],\n           [ 0.5,  0.5,  0.5]])\n\n    If called with ``only_once=False``, the function is applied repeatedly:\n\n    >>> apply_on_boundary(arr, lambda x: x / 2, only_once=False)\n    array([[ 0.25,  0.5 ,  0.25],\n           [ 0.5 ,  1.  ,  0.5 ],\n           [ 0.25,  0.5 ,  0.25]])\n\n    >>> apply_on_boundary(arr, lambda x: x / 2, only_once=True,\n    ...                   which_boundaries=((True, False), True))\n    array([[ 0.5,  0.5,  0.5],\n           [ 0.5,  1. ,  0.5],\n           [ 0.5,  1. ,  0.5]])\n\n    Use the ``out`` parameter to store the result in an existing array:\n\n    >>> out = np.empty_like(arr)\n    >>> result = apply_on_boundary(arr, lambda x: x / 2, out=out)\n    >>> result\n    array([[ 0.5,  0.5,  0.5],\n           [ 0.5,  1. ,  0.5],\n           [ 0.5,  0.5,  0.5]])\n    >>> result is out\n    True\n    \"\"\"\n    array = np.asarray(array)\n\n    if callable(func):\n        func = [func] * array.ndim\n    elif len(func) != array.ndim:\n        raise ValueError('sequence of functions has length {}, expected {}'\n                         ''.format(len(func), array.ndim))\n\n    if which_boundaries is None:\n        which_boundaries = ([(True, True)] * array.ndim)\n    elif len(which_boundaries) != array.ndim:\n        raise ValueError('`which_boundaries` has length {}, expected {}'\n                         ''.format(len(which_boundaries), array.ndim))\n\n    if axis_order is None:\n        axis_order = list(range(array.ndim))\n    elif len(axis_order) != array.ndim:\n        raise ValueError('`axis_order` has length {}, expected {}'\n                         ''.format(len(axis_order), array.ndim))\n\n    if out is None:\n        out = array.copy()\n    else:\n        out[:] = array  # Self assignment is free, in case out is array\n\n    # The 'only_once' functionality is implemented by storing for each axis\n    # if the left and right boundaries have been processed. This information\n    # is stored in a list of slices which is reused for the next axis in the\n    # list.\n    slices = [slice(None)] * array.ndim\n    for ax, function, which in zip(axis_order, func, which_boundaries):\n        if only_once:\n            slc_l = list(slices)  # Make a copy; copy() exists in Py3 only\n            slc_r = list(slices)\n        else:\n            slc_l = [slice(None)] * array.ndim\n            slc_r = [slice(None)] * array.ndim\n\n        # slc_l and slc_r select left and right boundary, resp, in this axis.\n        slc_l[ax] = 0\n        slc_r[ax] = -1\n\n        slc_l, slc_r = tuple(slc_l), tuple(slc_r)\n\n        try:\n            # Tuple of functions in this axis\n            func_l, func_r = function\n        except TypeError:\n            # Single function\n            func_l = func_r = function\n\n        try:\n            # Tuple of bool\n            mod_left, mod_right = which\n        except TypeError:\n            # Single bool\n            mod_left = mod_right = which\n\n        if mod_left and func_l is not None:\n            out[slc_l] = func_l(out[slc_l])\n            start = 1\n        else:\n            start = None\n\n        if mod_right and func_r is not None:\n            out[slc_r] = func_r(out[slc_r])\n            end = -1\n        else:\n            end = None\n\n        # Write the information for the processed axis into the slice list.\n        # Start and end include the boundary if it was processed.\n        slices[ax] = slice(start, end)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfast multiplication of an n-dim array with an outer product. This method implements the multiplication of an n-dimensional array with an outer product of one-dimensional arrays, e.g.:: a = np.ones((10, 10, 10)) x = np.random.rand(10) a *= x[:, None, None] * x[None, :, None] * x[None, None, :] Basically, there are two ways to do such an operation: 1. First calculate the factor on the right-hand side and do one \"big\" multiplication; or 2. Multiply by one factor at a time. The procedure of building up the large factor in the first method is relatively cheap if the number of 1d arrays is smaller than the number of dimensions. For exactly n vectors, the second method is faster, although it loops of the array ``a`` n times. This implementation combines the two ideas into a hybrid scheme: - If there are less 1d arrays than dimensions, choose 1. - Otherwise, calculate the factor array for n-1 arrays and multiply it to the large array. Finally, multiply with the last 1d array. The advantage of this approach is that it is memory-friendly and loops over the big array only twice. Parameters ---------- ndarr : `array-like` Array to multiply to onedim_arrs : sequence of `array-like`'s One-dimensional arrays to be multiplied with ``ndarr``. The sequence may not be longer than ``ndarr.ndim``. axes : sequence of ints, optional Take the 1d transform along these axes. ``None`` corresponds to the last ``len(onedim_arrs)`` axes, in ascending order. out : `numpy.ndarray`, optional Array in which the result is stored Returns ------- out : `numpy.ndarray` Result of the modification. If ``out`` was given, the returned object is a reference to it.", "response": "def fast_1d_tensor_mult(ndarr, onedim_arrs, axes=None, out=None):\n    \"\"\"Fast multiplication of an n-dim array with an outer product.\n\n    This method implements the multiplication of an n-dimensional array\n    with an outer product of one-dimensional arrays, e.g.::\n\n        a = np.ones((10, 10, 10))\n        x = np.random.rand(10)\n        a *= x[:, None, None] * x[None, :, None] * x[None, None, :]\n\n    Basically, there are two ways to do such an operation:\n\n    1. First calculate the factor on the right-hand side and do one\n       \"big\" multiplication; or\n    2. Multiply by one factor at a time.\n\n    The procedure of building up the large factor in the first method\n    is relatively cheap if the number of 1d arrays is smaller than the\n    number of dimensions. For exactly n vectors, the second method is\n    faster, although it loops of the array ``a`` n times.\n\n    This implementation combines the two ideas into a hybrid scheme:\n\n    - If there are less 1d arrays than dimensions, choose 1.\n    - Otherwise, calculate the factor array for n-1 arrays\n      and multiply it to the large array. Finally, multiply with the\n      last 1d array.\n\n    The advantage of this approach is that it is memory-friendly and\n    loops over the big array only twice.\n\n    Parameters\n    ----------\n    ndarr : `array-like`\n        Array to multiply to\n    onedim_arrs : sequence of `array-like`'s\n        One-dimensional arrays to be multiplied with ``ndarr``. The\n        sequence may not be longer than ``ndarr.ndim``.\n    axes : sequence of ints, optional\n        Take the 1d transform along these axes. ``None`` corresponds to\n        the last ``len(onedim_arrs)`` axes, in ascending order.\n    out : `numpy.ndarray`, optional\n        Array in which the result is stored\n\n    Returns\n    -------\n    out : `numpy.ndarray`\n        Result of the modification. If ``out`` was given, the returned\n        object is a reference to it.\n    \"\"\"\n    if out is None:\n        out = np.array(ndarr, copy=True)\n    else:\n        out[:] = ndarr  # Self-assignment is free if out is ndarr\n\n    if not onedim_arrs:\n        raise ValueError('no 1d arrays given')\n\n    if axes is None:\n        axes = list(range(out.ndim - len(onedim_arrs), out.ndim))\n        axes_in = None\n    elif len(axes) != len(onedim_arrs):\n        raise ValueError('there are {} 1d arrays, but {} axes entries'\n                         ''.format(len(onedim_arrs), len(axes)))\n    else:\n        # Make axes positive\n        axes, axes_in = np.array(axes, dtype=int), axes\n        axes[axes < 0] += out.ndim\n        axes = list(axes)\n\n    if not all(0 <= ai < out.ndim for ai in axes):\n        raise ValueError('`axes` {} out of bounds for {} dimensions'\n                         ''.format(axes_in, out.ndim))\n\n    # Make scalars 1d arrays and squeezable arrays 1d\n    alist = [np.atleast_1d(np.asarray(a).squeeze()) for a in onedim_arrs]\n    if any(a.ndim != 1 for a in alist):\n        raise ValueError('only 1d arrays allowed')\n\n    if len(axes) < out.ndim:\n        # Make big factor array (start with 0d)\n        factor = np.array(1.0)\n        for ax, arr in zip(axes, alist):\n            # Meshgrid-style slice\n            slc = [None] * out.ndim\n            slc[ax] = slice(None)\n            factor = factor * arr[tuple(slc)]\n\n        out *= factor\n\n    else:\n        # Hybrid approach\n\n        # Get the axis to spare for the final multiplication, the one\n        # with the largest stride.\n        last_ax = np.argmax(out.strides)\n        last_arr = alist[axes.index(last_ax)]\n\n        # Build the semi-big array and multiply\n        factor = np.array(1.0)\n        for ax, arr in zip(axes, alist):\n            if ax == last_ax:\n                continue\n\n            slc = [None] * out.ndim\n            slc[ax] = slice(None)\n            factor = factor * arr[tuple(slc)]\n\n        out *= factor\n\n        # Finally multiply by the remaining 1d array\n        slc = [None] * out.ndim\n        slc[last_ax] = slice(None)\n        out *= last_arr[tuple(slc)]\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resize_array(arr, newshp, offset=None, pad_mode='constant', pad_const=0,\n                 direction='forward', out=None):\n    \"\"\"Return the resized version of ``arr`` with shape ``newshp``.\n\n    In axes where ``newshp > arr.shape``, padding is applied according\n    to the supplied options.\n    Where ``newshp < arr.shape``, the array is cropped to the new\n    size.\n\n    See `the online documentation\n    <https://odlgroup.github.io/odl/math/resizing_ops.html>`_\n    on resizing operators for mathematical details.\n\n    Parameters\n    ----------\n    arr : `array-like`\n        Array to be resized.\n    newshp : sequence of ints\n        Desired shape of the output array.\n    offset : sequence of ints, optional\n        Specifies how many entries are added to/removed from the \"left\"\n        side (corresponding to low indices) of ``arr``.\n    pad_mode : string, optional\n        Method to be used to fill in missing values in an enlarged array.\n\n        ``'constant'``: Fill with ``pad_const``.\n\n        ``'symmetric'``: Reflect at the boundaries, not doubling the\n        outmost values. This requires left and right padding sizes\n        to be strictly smaller than the original array shape.\n\n        ``'periodic'``: Fill in values from the other side, keeping\n        the order. This requires left and right padding sizes to be\n        at most as large as the original array shape.\n\n        ``'order0'``: Extend constantly with the outmost values\n        (ensures continuity).\n\n        ``'order1'``: Extend with constant slope (ensures continuity of\n        the first derivative). This requires at least 2 values along\n        each axis where padding is applied.\n\n    pad_const : scalar, optional\n        Value to be used in the ``'constant'`` padding mode.\n    direction : {'forward', 'adjoint'}\n        Determines which variant of the resizing is applied.\n\n        'forward' : in axes where ``out`` is larger than ``arr``,\n        apply padding. Otherwise, restrict to the smaller size.\n\n        'adjoint' : in axes where ``out`` is larger than ``arr``,\n        apply zero-padding. Otherwise, restrict to the smaller size\n        and add the outside contributions according to ``pad_mode``.\n\n    out : `numpy.ndarray`, optional\n        Array to write the result to. Must have shape ``newshp`` and\n        be able to hold the data type of the input array.\n\n    Returns\n    -------\n    resized : `numpy.ndarray`\n        Resized array created according to the above rules. If ``out``\n        was given, the returned object is a reference to it.\n\n    Examples\n    --------\n    The input can be shrunk by simply providing a smaller size.\n    By default, values are removed from the right. When enlarging,\n    zero-padding is applied by default, and the zeros are added to\n    the right side. That behavior can be changed with the ``offset``\n    parameter:\n\n    >>> from odl.util.numerics import resize_array\n    >>> resize_array([1, 2, 3], (1,))\n    array([1])\n    >>> resize_array([1, 2, 3], (1,), offset=2)\n    array([3])\n    >>> resize_array([1, 2, 3], (6,))\n    array([1, 2, 3, 0, 0, 0])\n    >>> resize_array([1, 2, 3], (7,), offset=2)\n    array([0, 0, 1, 2, 3, 0, 0])\n\n    The padding constant can be changed, as well as the padding\n    mode:\n\n    >>> resize_array([1, 2, 3], (7,), pad_const=-1, offset=2)\n    array([-1, -1,  1,  2,  3, -1, -1])\n    >>> resize_array([1, 2, 3], (7,), pad_mode='periodic', offset=2)\n    array([2, 3, 1, 2, 3, 1, 2])\n    >>> resize_array([1, 2, 3], (7,), pad_mode='symmetric', offset=2)\n    array([3, 2, 1, 2, 3, 2, 1])\n    >>> resize_array([1, 2, 3], (7,), pad_mode='order0', offset=2)\n    array([1, 1, 1, 2, 3, 3, 3])\n    >>> resize_array([1, 2, 3], (7,), pad_mode='order1', offset=2)\n    array([-1,  0,  1,  2,  3,  4,  5])\n\n    Everything works for arbitrary number of dimensions:\n\n    >>> # Take the middle two columns and extend rows symmetrically\n    >>> resize_array([[1, 2, 3, 4],\n    ...               [5, 6, 7, 8],\n    ...               [9, 10, 11, 12]],\n    ...               (5, 2), pad_mode='symmetric', offset=[1, 1])\n    array([[ 6,  7],\n           [ 2,  3],\n           [ 6,  7],\n           [10, 11],\n           [ 6,  7]])\n    >>> # Take the rightmost two columns and extend rows symmetrically\n    >>> # downwards\n    >>> resize_array([[1, 2, 3, 4],\n    ...               [5, 6, 7, 8],\n    ...               [9, 10, 11, 12]], (5, 2), pad_mode='symmetric',\n    ...              offset=[0, 2])\n    array([[ 3,  4],\n           [ 7,  8],\n           [11, 12],\n           [ 7,  8],\n           [ 3,  4]])\n    \"\"\"\n    # Handle arrays and shapes\n    try:\n        newshp = tuple(newshp)\n    except TypeError:\n        raise TypeError('`newshp` must be a sequence, got {!r}'.format(newshp))\n\n    if out is not None:\n        if not isinstance(out, np.ndarray):\n            raise TypeError('`out` must be a `numpy.ndarray` instance, got '\n                            '{!r}'.format(out))\n        if out.shape != newshp:\n            raise ValueError('`out` must have shape {}, got {}'\n                             ''.format(newshp, out.shape))\n\n        order = 'C' if out.flags.c_contiguous else 'F'\n        arr = np.asarray(arr, dtype=out.dtype, order=order)\n        if arr.ndim != out.ndim:\n            raise ValueError('number of axes of `arr` and `out` do not match '\n                             '({} != {})'.format(arr.ndim, out.ndim))\n    else:\n        arr = np.asarray(arr)\n        order = 'C' if arr.flags.c_contiguous else 'F'\n        out = np.empty(newshp, dtype=arr.dtype, order=order)\n        if len(newshp) != arr.ndim:\n            raise ValueError('number of axes of `arr` and `len(newshp)` do '\n                             'not match ({} != {})'\n                             ''.format(arr.ndim, len(newshp)))\n\n    # Handle offset\n    if offset is None:\n        offset = [0] * out.ndim\n    else:\n        offset = normalized_scalar_param_list(\n            offset, out.ndim, param_conv=safe_int_conv, keep_none=False)\n\n    # Handle padding\n    pad_mode, pad_mode_in = str(pad_mode).lower(), pad_mode\n    if pad_mode not in _SUPPORTED_RESIZE_PAD_MODES:\n        raise ValueError(\"`pad_mode` '{}' not understood\".format(pad_mode_in))\n\n    if (pad_mode == 'constant' and\n        not np.can_cast(pad_const, out.dtype) and\n        any(n_new > n_orig\n            for n_orig, n_new in zip(arr.shape, out.shape))):\n        raise ValueError('`pad_const` {} cannot be safely cast to the data '\n                         'type {} of the output array'\n                         ''.format(pad_const, out.dtype))\n\n    # Handle direction\n    direction, direction_in = str(direction).lower(), direction\n    if direction not in ('forward', 'adjoint'):\n        raise ValueError(\"`direction` '{}' not understood\"\n                         \"\".format(direction_in))\n\n    if direction == 'adjoint' and pad_mode == 'constant' and pad_const != 0:\n        raise ValueError(\"`pad_const` must be 0 for 'adjoint' direction, \"\n                         \"got {}\".format(pad_const))\n\n    if direction == 'forward' and pad_mode == 'constant' and pad_const != 0:\n        out.fill(pad_const)\n    else:\n        out.fill(0)\n\n    # Perform the resizing\n    if direction == 'forward':\n        if pad_mode == 'constant':\n            # Constant padding does not require the helper function\n            _assign_intersection(out, arr, offset)\n        else:\n            # First copy the inner part and use it for padding\n            _assign_intersection(out, arr, offset)\n            _apply_padding(out, arr, offset, pad_mode, 'forward')\n    else:\n        if pad_mode == 'constant':\n            # Skip the padding helper\n            _assign_intersection(out, arr, offset)\n        else:\n            # Apply adjoint padding to a copy of the input and copy the inner\n            # part when finished\n            tmp = arr.copy()\n            _apply_padding(tmp, out, offset, pad_mode, 'adjoint')\n            _assign_intersection(out, tmp, offset)\n\n    return out", "response": "Returns the resized version of an array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _intersection_slice_tuples(lhs_arr, rhs_arr, offset):\n    lhs_slc, rhs_slc = [], []\n    for istart, n_lhs, n_rhs in zip(offset, lhs_arr.shape, rhs_arr.shape):\n\n        # Slice for the inner part in the larger array corresponding to the\n        # small one, offset by the given amount\n        istop = istart + min(n_lhs, n_rhs)\n        inner_slc = slice(istart, istop)\n\n        if n_lhs > n_rhs:\n            # Extension\n            lhs_slc.append(inner_slc)\n            rhs_slc.append(slice(None))\n        elif n_lhs < n_rhs:\n            # Restriction\n            lhs_slc.append(slice(None))\n            rhs_slc.append(inner_slc)\n        else:\n            # Same size, so full slices for both\n            lhs_slc.append(slice(None))\n            rhs_slc.append(slice(None))\n\n    return tuple(lhs_slc), tuple(rhs_slc)", "response": "Return tuples to yield the intersecting part of both given arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _assign_intersection(lhs_arr, rhs_arr, offset):\n    lhs_slc, rhs_slc = _intersection_slice_tuples(lhs_arr, rhs_arr, offset)\n    lhs_arr[lhs_slc] = rhs_arr[rhs_slc]", "response": "Assign the intersecting region from lhs_arr to rhs_arr."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning slices into the outer array part where padding is applied.", "response": "def _padding_slices_outer(lhs_arr, rhs_arr, axis, offset):\n    \"\"\"Return slices into the outer array part where padding is applied.\n\n    When padding is performed, these slices yield the outer (excess) part\n    of the larger array that is to be filled with values. Slices for\n    both sides of the arrays in a given ``axis`` are returned.\n\n    The same slices are used also in the adjoint padding correction,\n    however in a different way.\n\n    See `the online documentation\n    <https://odlgroup.github.io/odl/math/resizing_ops.html>`_\n    on resizing operators for details.\n    \"\"\"\n    istart_inner = offset[axis]\n    istop_inner = istart_inner + min(lhs_arr.shape[axis], rhs_arr.shape[axis])\n    return slice(istart_inner), slice(istop_inner, None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _padding_slices_inner(lhs_arr, rhs_arr, axis, offset, pad_mode):\n    # Calculate the start and stop indices for the inner part\n    istart_inner = offset[axis]\n    n_large = max(lhs_arr.shape[axis], rhs_arr.shape[axis])\n    n_small = min(lhs_arr.shape[axis], rhs_arr.shape[axis])\n    istop_inner = istart_inner + n_small\n    # Number of values padded to left and right\n    n_pad_l = istart_inner\n    n_pad_r = n_large - istop_inner\n\n    if pad_mode == 'periodic':\n        # left: n_pad_l forward, ending at istop_inner - 1\n        pad_slc_l = slice(istop_inner - n_pad_l, istop_inner)\n        # right: n_pad_r forward, starting at istart_inner\n        pad_slc_r = slice(istart_inner, istart_inner + n_pad_r)\n\n    elif pad_mode == 'symmetric':\n        # left: n_pad_l backward, ending at istart_inner + 1\n        pad_slc_l = slice(istart_inner + n_pad_l, istart_inner, -1)\n        # right: n_pad_r backward, starting at istop_inner - 2\n        # For the corner case that the stopping index is -1, we need to\n        # replace it with None, since -1 as stopping index is equivalent\n        # to the last index, which is not what we want (0 as last index).\n        istop_r = istop_inner - 2 - n_pad_r\n        if istop_r == -1:\n            istop_r = None\n        pad_slc_r = slice(istop_inner - 2, istop_r, -1)\n\n    elif pad_mode in ('order0', 'order1'):\n        # left: only the first entry, using a slice to avoid squeezing\n        pad_slc_l = slice(istart_inner, istart_inner + 1)\n        # right: only last entry\n        pad_slc_r = slice(istop_inner - 1, istop_inner)\n\n    else:\n        # Slices are not used, returning trivial ones. The function should not\n        # be used for other modes anyway.\n        pad_slc_l, pad_slc_r = slice(0), slice(0)\n\n    return pad_slc_l, pad_slc_r", "response": "Return slices into the inner array part for a given padding mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _apply_padding(lhs_arr, rhs_arr, offset, pad_mode, direction):\n    if pad_mode not in ('periodic', 'symmetric', 'order0', 'order1'):\n        return\n\n    full_slc = [slice(None)] * lhs_arr.ndim\n    intersec_slc, _ = _intersection_slice_tuples(lhs_arr, rhs_arr, offset)\n\n    if direction == 'forward':\n        working_slc = list(intersec_slc)\n    else:\n        working_slc = list(full_slc)\n\n    # TODO: order axes according to padding size for optimization (largest\n    # last)? Axis strides could be important, too.\n    for axis, (n_lhs, n_rhs) in enumerate(zip(lhs_arr.shape, rhs_arr.shape)):\n\n        if n_lhs <= n_rhs:\n            continue  # restriction, nothing to do\n\n        n_pad_l = offset[axis]\n        n_pad_r = n_lhs - n_rhs - n_pad_l\n\n        # Error scenarios with illegal lengths\n        if pad_mode == 'order0' and n_rhs == 0:\n            raise ValueError('in axis {}: the smaller array must have size '\n                             '>= 1 for order 0 padding, got 0'\n                             ''.format(axis))\n\n        if pad_mode == 'order1' and n_rhs < 2:\n            raise ValueError('in axis {}: the smaller array must have size '\n                             '>= 2 for order 1 padding, got {}'\n                             ''.format(axis, n_rhs))\n\n        for lr, pad_len in [('left', n_pad_l), ('right', n_pad_r)]:\n            if pad_mode == 'periodic' and pad_len > n_rhs:\n                raise ValueError('in axis {}: {} padding length {} exceeds '\n                                 'the size {} of the smaller array; this is '\n                                 'not allowed for periodic padding'\n                                 ''.format(axis, lr, pad_len, n_rhs))\n\n            elif pad_mode == 'symmetric' and pad_len >= n_rhs:\n                raise ValueError('in axis {}: {} padding length {} is larger '\n                                 'or equal to the size {} of the smaller '\n                                 'array; this is not allowed for symmetric '\n                                 'padding'\n                                 ''.format(axis, lr, pad_len, n_rhs))\n\n        # Slice tuples used to index LHS and RHS for left and right padding,\n        # respectively; we make 4 copies of `working_slc` as lists\n        lhs_slc_l, lhs_slc_r, rhs_slc_l, rhs_slc_r = map(\n            list, [working_slc] * 4)\n\n        # We're always using the outer (excess) parts involved in padding\n        # on the LHS of the assignment, so we set them here.\n        pad_slc_outer_l, pad_slc_outer_r = _padding_slices_outer(\n            lhs_arr, rhs_arr, axis, offset)\n\n        if direction == 'forward':\n            lhs_slc_l[axis] = pad_slc_outer_l\n            lhs_slc_r[axis] = pad_slc_outer_r\n        else:\n            rhs_slc_l[axis] = pad_slc_outer_l\n            rhs_slc_r[axis] = pad_slc_outer_r\n\n        if pad_mode in ('periodic', 'symmetric'):\n            pad_slc_inner_l, pad_slc_inner_r = _padding_slices_inner(\n                lhs_arr, rhs_arr, axis, offset, pad_mode)\n\n            # Using `lhs_arr` on both sides of the assignment such that the\n            # shapes match and the \"corner\" blocks are properly assigned\n            # or used in the addition for the adjoint, respectively.\n            if direction == 'forward':\n                rhs_slc_l[axis] = pad_slc_inner_l\n                rhs_slc_r[axis] = pad_slc_inner_r\n                lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r = map(\n                    tuple, [lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r])\n\n                lhs_arr[lhs_slc_l] = lhs_arr[rhs_slc_l]\n                lhs_arr[lhs_slc_r] = lhs_arr[rhs_slc_r]\n            else:\n                lhs_slc_l[axis] = pad_slc_inner_l\n                lhs_slc_r[axis] = pad_slc_inner_r\n                lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r = map(\n                    tuple, [lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r])\n\n                lhs_arr[lhs_slc_l] += lhs_arr[rhs_slc_l]\n                lhs_arr[lhs_slc_r] += lhs_arr[rhs_slc_r]\n\n        elif pad_mode == 'order0':\n            # The `_padding_slices_inner` helper returns the slices for the\n            # boundary values.\n            left_slc, right_slc = _padding_slices_inner(\n                lhs_arr, rhs_arr, axis, offset, pad_mode)\n\n            if direction == 'forward':\n                rhs_slc_l[axis] = left_slc\n                rhs_slc_r[axis] = right_slc\n                lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r = map(\n                    tuple, [lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r])\n\n                lhs_arr[lhs_slc_l] = lhs_arr[rhs_slc_l]\n                lhs_arr[lhs_slc_r] = lhs_arr[rhs_slc_r]\n            else:\n                lhs_slc_l[axis] = left_slc\n                lhs_slc_r[axis] = right_slc\n                lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r = map(\n                    tuple, [lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r])\n\n                lhs_arr[lhs_slc_l] += np.sum(\n                    lhs_arr[rhs_slc_l],\n                    axis=axis, keepdims=True, dtype=lhs_arr.dtype)\n                lhs_arr[lhs_slc_r] += np.sum(\n                    lhs_arr[rhs_slc_r],\n                    axis=axis, keepdims=True, dtype=lhs_arr.dtype)\n\n        elif pad_mode == 'order1':\n            # Some extra work necessary: need to compute the derivative at\n            # the boundary and use that to continue with constant derivative.\n\n            # Slice for broadcasting of a 1D array along `axis`\n            bcast_slc = [None] * lhs_arr.ndim\n            bcast_slc[axis] = slice(None)\n            bcast_slc = tuple(bcast_slc)\n\n            # Slices for the boundary in `axis`\n            left_slc, right_slc = _padding_slices_inner(\n                lhs_arr, rhs_arr, axis, offset, pad_mode)\n\n            # Create slice tuples for indexing of the boundary values\n            bdry_slc_l = list(working_slc)\n            bdry_slc_l[axis] = left_slc\n            bdry_slc_l = tuple(bdry_slc_l)\n            bdry_slc_r = list(working_slc)\n            bdry_slc_r[axis] = right_slc\n            bdry_slc_r = tuple(bdry_slc_r)\n\n            # For the slope at the boundary, we need two neighboring points.\n            # We create the corresponding slices from the boundary slices.\n            slope_slc_l = list(working_slc)\n            slope_slc_l[axis] = slice(left_slc.start, left_slc.stop + 1)\n            slope_slc_l = tuple(slope_slc_l)\n            slope_slc_r = list(working_slc)\n            slope_slc_r[axis] = slice(right_slc.start - 1, right_slc.stop)\n            slope_slc_r = tuple(slope_slc_r)\n\n            # The `np.arange`s, broadcast along `axis`, are used to create the\n            # constant-slope continuation (forward) or to calculate the\n            # first order moments (adjoint).\n            arange_l = np.arange(-n_pad_l, 0,\n                                 dtype=lhs_arr.dtype)[bcast_slc]\n            arange_r = np.arange(1, n_pad_r + 1,\n                                 dtype=lhs_arr.dtype)[bcast_slc]\n\n            lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r = map(\n                tuple, [lhs_slc_l, rhs_slc_l, lhs_slc_r, rhs_slc_r])\n\n            if direction == 'forward':\n                # Take first order difference to get the derivative\n                # along `axis`.\n                slope_l = np.diff(lhs_arr[slope_slc_l], n=1, axis=axis)\n                slope_r = np.diff(lhs_arr[slope_slc_r], n=1, axis=axis)\n\n                # Finally assign the constant slope values\n                lhs_arr[lhs_slc_l] = lhs_arr[bdry_slc_l] + arange_l * slope_l\n                lhs_arr[lhs_slc_r] = lhs_arr[bdry_slc_r] + arange_r * slope_r\n            else:\n                # Same as in 'order0'\n                lhs_arr[bdry_slc_l] += np.sum(lhs_arr[rhs_slc_l],\n                                              axis=axis, keepdims=True,\n                                              dtype=lhs_arr.dtype)\n                lhs_arr[bdry_slc_r] += np.sum(lhs_arr[rhs_slc_r],\n                                              axis=axis, keepdims=True,\n                                              dtype=lhs_arr.dtype)\n\n                # Calculate the order 1 moments\n                moment1_l = np.sum(arange_l * lhs_arr[rhs_slc_l],\n                                   axis=axis, keepdims=True,\n                                   dtype=lhs_arr.dtype)\n                moment1_r = np.sum(arange_r * lhs_arr[rhs_slc_r],\n                                   axis=axis, keepdims=True,\n                                   dtype=lhs_arr.dtype)\n\n                # Add moment1 at the \"width-2 boundary layers\", with the sign\n                # corresponding to the sign in the derivative calculation\n                # of the forward padding.\n                sign = np.array([-1, 1])[bcast_slc]\n                lhs_arr[slope_slc_l] += moment1_l * sign\n                lhs_arr[slope_slc_r] += moment1_r * sign\n\n        if direction == 'forward':\n            working_slc[axis] = full_slc[axis]\n        else:\n            working_slc[axis] = intersec_slc[axis]", "response": "Helper function to apply padding to the base array of the base array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zscore(arr):\n    arr = arr - np.mean(arr)\n    std = np.std(arr)\n    if std != 0:\n        arr /= std\n    return arr", "response": "Return arr normalized with mean 0 and unit variance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_out_arg(func):\n    if sys.version_info.major > 2:\n        spec = inspect.getfullargspec(func)\n        kw_only = spec.kwonlyargs\n    else:\n        spec = inspect.getargspec(func)\n        kw_only = ()\n\n    if spec.varargs is not None:\n        raise TypeError('*args not allowed in function signature')\n\n    pos_args = spec.args\n    pos_defaults = () if spec.defaults is None else spec.defaults\n\n    has_out = 'out' in pos_args or 'out' in kw_only\n    if 'out' in pos_args:\n        has_out = True\n        out_is_optional = (\n            pos_args.index('out') >= len(pos_args) - len(pos_defaults))\n    elif 'out' in kw_only:\n        has_out = out_is_optional = True\n    else:\n        has_out = out_is_optional = False\n\n    return has_out, out_is_optional", "response": "Check if the signature of func has an optional out argument."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _default_in_place(func, x, out, **kwargs):\n    result = np.array(func._call_out_of_place(x, **kwargs), copy=False)\n    if result.dtype == object:\n        # Different shapes encountered, need to broadcast\n        flat_results = result.ravel()\n        if is_valid_input_array(x, func.domain.ndim):\n            scalar_out_shape = out_shape_from_array(x)\n        elif is_valid_input_meshgrid(x, func.domain.ndim):\n            scalar_out_shape = out_shape_from_meshgrid(x)\n        else:\n            raise RuntimeError('bad input')\n\n        bcast_results = [np.broadcast_to(res, scalar_out_shape)\n                         for res in flat_results]\n        # New array that is flat in the `out_shape` axes, reshape it\n        # to the final `out_shape + scalar_shape`, using the same\n        # order ('C') as the initial `result.ravel()`.\n        result = np.array(bcast_results, dtype=func.scalar_out_dtype)\n        result = result.reshape(func.out_shape + scalar_out_shape)\n\n    # The following code is required to remove extra axes, e.g., when\n    # the result has shape (2, 1, 3) but should have shape (2, 3).\n    # For those cases, broadcasting doesn't apply.\n    try:\n        reshaped = result.reshape(out.shape)\n    except ValueError:\n        # This is the case when `result` must be broadcast\n        out[:] = result\n    else:\n        out[:] = reshaped\n\n    return out", "response": "Default in - place evaluation method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _default_out_of_place(func, x, **kwargs):\n    if is_valid_input_array(x, func.domain.ndim):\n        scalar_out_shape = out_shape_from_array(x)\n    elif is_valid_input_meshgrid(x, func.domain.ndim):\n        scalar_out_shape = out_shape_from_meshgrid(x)\n    else:\n        raise TypeError('cannot use in-place method to implement '\n                        'out-of-place non-vectorized evaluation')\n\n    dtype = func.space.scalar_out_dtype\n    if dtype is None:\n        dtype = np.result_type(*x)\n\n    out_shape = func.out_shape + scalar_out_shape\n    out = np.empty(out_shape, dtype=dtype)\n    func._call_in_place(x, out=out, **kwargs)\n    return out", "response": "Default out - of - place evaluation method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if fcall has optional output argument.", "response": "def _fcall_out_type(fcall):\n    \"\"\"Check if ``fcall`` has (optional) output argument.\n\n    This function is intended to work with all types of callables\n    that are used as input to `FunctionSpace.element`.\n    \"\"\"\n    if isinstance(fcall, FunctionSpaceElement):\n        call_has_out = fcall._call_has_out\n        call_out_optional = fcall._call_out_optional\n\n    # Numpy Ufuncs and similar objects (e.g. Numba DUfuncs)\n    elif hasattr(fcall, 'nin') and hasattr(fcall, 'nout'):\n        if fcall.nin != 1:\n            raise ValueError('ufunc {} has {} input parameter(s), '\n                             'expected 1'\n                             ''.format(fcall.__name__, fcall.nin))\n        if fcall.nout > 1:\n            raise ValueError('ufunc {} has {} output parameter(s), '\n                             'expected at most 1'\n                             ''.format(fcall.__name__, fcall.nout))\n        call_has_out = call_out_optional = (fcall.nout == 1)\n    elif inspect.isfunction(fcall):\n        call_has_out, call_out_optional = _check_out_arg(fcall)\n    elif callable(fcall):\n        call_has_out, call_out_optional = _check_out_arg(fcall.__call__)\n    else:\n        raise TypeError('object {!r} not callable'.format(fcall))\n\n    return call_has_out, call_out_optional"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new FunctionSpaceElement.", "response": "def element(self, fcall=None, vectorized=True):\n        \"\"\"Create a `FunctionSpace` element.\n\n        Parameters\n        ----------\n        fcall : callable, optional\n            The actual instruction for out-of-place evaluation.\n            It must return a `FunctionSpace.range` element or a\n            `numpy.ndarray` of such (vectorized call).\n            If ``fcall`` is a `FunctionSpaceElement`, it is wrapped\n            as a new `FunctionSpaceElement`.\n            Default: `zero`.\n        vectorized : bool, optional\n            If ``True``, assume that ``fcall`` supports vectorized\n            evaluation. For ``False``, the function is decorated with a\n            vectorizer, which implies that two elements created this way\n            from the same function are regarded as not equal.\n            The ``False`` option cannot be used if ``fcall`` has an\n            ``out`` parameter.\n\n        Returns\n        -------\n        element : `FunctionSpaceElement`\n            The new element, always supporting vectorization.\n\n        Examples\n        --------\n        Scalar-valued functions are straightforward to create:\n\n        >>> fspace = odl.FunctionSpace(odl.IntervalProd(0, 1))\n        >>> func = fspace.element(lambda x: x - 1)\n        >>> func(0.5)\n        -0.5\n        >>> func([0.1, 0.5, 0.6])\n        array([-0.9, -0.5, -0.4])\n\n        It is also possible to use functions with parameters. Note that\n        such extra parameters have to be given by keyword when calling\n        the function:\n\n        >>> def f(x, b):\n        ...     return x + b\n        >>> func = fspace.element(f)\n        >>> func([0.1, 0.5, 0.6], b=1)\n        array([ 1.1, 1.5,  1.6])\n        >>> func([0.1, 0.5, 0.6], b=-1)\n        array([-0.9, -0.5, -0.4])\n\n        Vector-valued functions can eiter be given as a sequence of\n        scalar-valued functions or as a single function that returns\n        a sequence:\n\n        >>> # Space of vector-valued functions with 2 components\n        >>> fspace = odl.FunctionSpace(odl.IntervalProd(0, 1),\n        ...                            out_dtype=(float, (2,)))\n        >>> # Possibility 1: provide component functions\n        >>> func1 = fspace.element([lambda x: x + 1, np.negative])\n        >>> func1(0.5)\n        array([ 1.5, -0.5])\n        >>> func1([0.1, 0.5, 0.6])\n        array([[ 1.1,  1.5,  1.6],\n               [-0.1, -0.5, -0.6]])\n        >>> # Possibility 2: single function returning a sequence\n        >>> func2 = fspace.element(lambda x: (x + 1, -x))\n        >>> func2(0.5)\n        array([ 1.5, -0.5])\n        >>> func2([0.1, 0.5, 0.6])\n        array([[ 1.1,  1.5,  1.6],\n               [-0.1, -0.5, -0.6]])\n\n        If the function(s) include(s) an ``out`` parameter, it can be\n        provided to hold the final result:\n\n        >>> # Sequence of functions with `out` parameter\n        >>> def f1(x, out):\n        ...     out[:] = x + 1\n        >>> def f2(x, out):\n        ...     out[:] = -x\n        >>> func = fspace.element([f1, f2])\n        >>> out = np.empty((2, 3))  # needs to match expected output shape\n        >>> result = func([0.1, 0.5, 0.6], out=out)\n        >>> out\n        array([[ 1.1,  1.5,  1.6],\n               [-0.1, -0.5, -0.6]])\n        >>> result is out\n        True\n        >>> # Single function assigning to components of `out`\n        >>> def f(x, out):\n        ...     out[0] = x + 1\n        ...     out[1] = -x\n        >>> func = fspace.element(f)\n        >>> out = np.empty((2, 3))  # needs to match expected output shape\n        >>> result = func([0.1, 0.5, 0.6], out=out)\n        >>> out\n        array([[ 1.1,  1.5,  1.6],\n               [-0.1, -0.5, -0.6]])\n        >>> result is out\n        True\n\n        Tensor-valued functions and functions defined on higher-dimensional\n        domains work just analogously:\n\n        >>> fspace = odl.FunctionSpace(odl.IntervalProd([0, 0], [1, 1]),\n        ...                            out_dtype=(float, (2, 3)))\n        >>> def pyfunc(x):\n        ...     return [[x[0], x[1], x[0] + x[1]],\n        ...             [1, 0, 2 * (x[0] + x[1])]]\n        >>> func1 = fspace.element(pyfunc)\n        >>> # Points are given such that the first axis indexes the\n        >>> # components and the second enumerates the points.\n        >>> # We evaluate at [0.0, 0.5] and [0.0, 1.0] here.\n        >>> eval_pts = np.array([[0.0, 0.5],\n        ...                      [0.0, 1.0]]).T\n        >>> func1(eval_pts).shape\n        (2, 3, 2)\n        >>> func1(eval_pts)\n        array([[[ 0. ,  0. ],\n                [ 0.5,  1. ],\n                [ 0.5,  1. ]],\n        <BLANKLINE>\n               [[ 1. ,  1. ],\n                [ 0. ,  0. ],\n                [ 1. ,  2. ]]])\n\n        Furthermore, it is allowed to use scalar constants instead of\n        functions if the function is given as sequence:\n\n        >>> seq = [[lambda x: x[0], lambda x: x[1], lambda x: x[0] + x[1]],\n        ...        [1, 0, lambda x: 2 * (x[0] + x[1])]]\n        >>> func2 = fspace.element(seq)\n        >>> func2(eval_pts)\n        array([[[ 0. ,  0. ],\n                [ 0.5,  1. ],\n                [ 0.5,  1. ]],\n        <BLANKLINE>\n               [[ 1. ,  1. ],\n                [ 0. ,  0. ],\n                [ 1. ,  2. ]]])\n        \"\"\"\n        if fcall is None:\n            return self.zero()\n        elif fcall in self:\n            return fcall\n        elif callable(fcall):\n            if not vectorized:\n                if hasattr(fcall, 'nin') and hasattr(fcall, 'nout'):\n                    warnings.warn('`fcall` {!r} is a ufunc-like object, '\n                                  'use vectorized=True'.format(fcall),\n                                  RuntimeWarning)\n                has_out, _ = _check_out_arg(fcall)\n                if has_out:\n                    raise TypeError('non-vectorized `fcall` with `out` '\n                                    'parameter not allowed')\n                if self.field is not None:\n                    otypes = [self.scalar_out_dtype]\n                else:\n                    otypes = []\n\n                fcall = vectorize(otypes=otypes)(fcall)\n            return self.element_type(self, fcall)\n        else:\n            # This is for the case that an array-like of callables\n            # is provided\n            if np.shape(fcall) != self.out_shape:\n                raise ValueError(\n                    'invalid `fcall` {!r}: expected `None`, a callable or '\n                    'an array-like of callables whose shape matches '\n                    '`out_shape` {}'.format(self.out_shape))\n\n            fcalls = np.array(fcall, dtype=object, ndmin=1).ravel().tolist()\n            if not vectorized:\n                if self.field == RealNumbers():\n                    otypes = ['float64']\n                elif self.field == ComplexNumbers():\n                    otypes = ['complex128']\n                else:\n                    otypes = []\n\n                # Vectorize, preserving scalars\n                fcalls = [f if np.isscalar(f) else vectorize(otypes=otypes)(f)\n                          for f in fcalls]\n\n            def wrapper(x, out=None, **kwargs):\n                \"\"\"Function wrapping an array of callables.\n\n                This wrapper does the following for out-of-place\n                evaluation (when ``out=None``):\n\n                1. Collect the results of all function evaluations into\n                   a list, handling all kinds of sequence entries\n                   (normal function, ufunc, constant, etc.).\n                2. Broadcast all results to the desired shape that is\n                   determined by the space's ``out_shape`` and the\n                   shape(s) of the input.\n                3. Form a big array containing the final result.\n\n                The in-place version is simpler because broadcasting\n                happens automatically when assigning to the components\n                of ``out``. Hence, we only have\n\n                1. Assign the result of the evaluation of the i-th\n                   function to ``out_flat[i]``, possibly using the\n                   ``out`` parameter of the function.\n                \"\"\"\n                if is_valid_input_meshgrid(x, self.domain.ndim):\n                    scalar_out_shape = out_shape_from_meshgrid(x)\n                elif is_valid_input_array(x, self.domain.ndim):\n                    scalar_out_shape = out_shape_from_array(x)\n                else:\n                    raise RuntimeError('bad input')\n\n                if out is None:\n                    # Out-of-place evaluation\n\n                    # Collect results of member functions into a list.\n                    # Put simply, all that happens here is\n                    # `results.append(f(x))`, just for a bunch of cases\n                    # and with or without `out`.\n                    results = []\n                    for f in fcalls:\n                        if np.isscalar(f):\n                            # Constant function\n                            results.append(f)\n                        elif not callable(f):\n                            raise TypeError('element {!r} of sequence not '\n                                            'callable'.format(f))\n                        elif hasattr(f, 'nin') and hasattr(f, 'nout'):\n                            # ufunc-like object\n                            results.append(f(x, **kwargs))\n                        else:\n                            try:\n                                has_out = 'out' in getargspec(f).args\n                            except TypeError:\n                                raise TypeError('unsupported callable {!r}'\n                                                ''.format(f))\n                            else:\n                                if has_out:\n                                    out = np.empty(scalar_out_shape,\n                                                   dtype=self.scalar_out_dtype)\n                                    f(x, out=out, **kwargs)\n                                    results.append(out)\n                                else:\n                                    results.append(f(x, **kwargs))\n\n                    # Broadcast to required shape and convert to array.\n                    # This will raise an error if the shape of some member\n                    # array is wrong, since in that case the resulting\n                    # dtype would be `object`.\n                    bcast_results = []\n                    for res in results:\n                        try:\n                            reshaped = np.reshape(res, scalar_out_shape)\n                        except ValueError:\n                            bcast_results.append(\n                                np.broadcast_to(res, scalar_out_shape))\n                        else:\n                            bcast_results.append(reshaped)\n\n                    out_arr = np.array(bcast_results,\n                                       dtype=self.scalar_out_dtype)\n\n                    return out_arr.reshape(self.out_shape + scalar_out_shape)\n\n                else:\n                    # In-place evaluation\n\n                    # This is a precaution in case out is not contiguous\n                    with writable_array(out) as out_arr:\n                        # Flatten tensor axes to work on one tensor\n                        # component (= scalar function) at a time\n                        out_comps = out.reshape((-1,) + scalar_out_shape)\n                        for f, out_comp in zip(fcalls, out_comps):\n                            if np.isscalar(f):\n                                out_comp[:] = f\n                            else:\n                                has_out, _ = _fcall_out_type(f)\n                                if has_out:\n                                    f(x, out=out_comp, **kwargs)\n                                else:\n                                    out_comp[:] = f(x, **kwargs)\n\n            return self.element_type(self, wrapper)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a zero array for the current object.", "response": "def zero(self):\n        \"\"\"Function mapping anything to zero.\"\"\"\n        # Since `FunctionSpace.lincomb` may be slow, we implement this\n        # function directly.\n        # The unused **kwargs are needed to support combination with\n        # functions that take parameters.\n        def zero_vec(x, out=None, **kwargs):\n            \"\"\"Zero function, vectorized.\"\"\"\n            if is_valid_input_meshgrid(x, self.domain.ndim):\n                scalar_out_shape = out_shape_from_meshgrid(x)\n            elif is_valid_input_array(x, self.domain.ndim):\n                scalar_out_shape = out_shape_from_array(x)\n            else:\n                raise TypeError('invalid input type')\n\n            # For tensor-valued functions\n            out_shape = self.out_shape + scalar_out_shape\n\n            if out is None:\n                return np.zeros(out_shape, dtype=self.scalar_out_dtype)\n            else:\n                # Need to go through an array to fill with the correct\n                # zero value for all dtypes\n                fill_value = np.zeros(1, dtype=self.scalar_out_dtype)[0]\n                out.fill(fill_value)\n\n        return self.element_type(self, zero_vec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions mapping anything to one.", "response": "def one(self):\n        \"\"\"Function mapping anything to one.\"\"\"\n        # See zero() for remarks\n        def one_vec(x, out=None, **kwargs):\n            \"\"\"One function, vectorized.\"\"\"\n            if is_valid_input_meshgrid(x, self.domain.ndim):\n                scalar_out_shape = out_shape_from_meshgrid(x)\n            elif is_valid_input_array(x, self.domain.ndim):\n                scalar_out_shape = out_shape_from_array(x)\n            else:\n                raise TypeError('invalid input type')\n\n            out_shape = self.out_shape + scalar_out_shape\n\n            if out is None:\n                return np.ones(out_shape, dtype=self.scalar_out_dtype)\n            else:\n                fill_value = np.ones(1, dtype=self.scalar_out_dtype)[0]\n                out.fill(fill_value)\n\n        return self.element_type(self, one_vec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef astype(self, out_dtype):\n        out_dtype = np.dtype(out_dtype)\n        if out_dtype == self.out_dtype:\n            return self\n\n        # Try to use caching for real and complex versions (exact dtype\n        # mappings). This may fail for certain dtype, in which case we\n        # just go to `_astype` directly.\n        real_dtype = getattr(self, 'real_out_dtype', None)\n        if real_dtype is None:\n            return self._astype(out_dtype)\n        else:\n            if out_dtype == real_dtype:\n                if self.__real_space is None:\n                    self.__real_space = self._astype(out_dtype)\n                return self.__real_space\n            elif out_dtype == self.complex_out_dtype:\n                if self.__complex_space is None:\n                    self.__complex_space = self._astype(out_dtype)\n                return self.__complex_space\n            else:\n                return self._astype(out_dtype)", "response": "Return a copy of this space with new output data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _multiply(self, f1, f2, out):\n        # Avoid infinite recursions by making a copy of the functions\n        f1_copy = f1.copy()\n        f2_copy = f2.copy()\n\n        def product_oop(x, **kwargs):\n            \"\"\"Product out-of-place evaluation function.\"\"\"\n            return np.asarray(f1_copy(x, **kwargs) * f2_copy(x, **kwargs),\n                              dtype=self.scalar_out_dtype)\n\n        out._call_out_of_place = product_oop\n        decorator = preload_first_arg(out, 'in-place')\n        out._call_in_place = decorator(_default_in_place)\n        out._call_has_out = out._call_out_optional = False\n        return out", "response": "Pointwise multiplication of f1 and f2."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _scalar_power(self, f, p, out):\n        # Avoid infinite recursions by making a copy of the function\n        f_copy = f.copy()\n\n        def pow_posint(x, n):\n            \"\"\"Power function for positive integer ``n``, out-of-place.\"\"\"\n            if isinstance(x, np.ndarray):\n                y = x.copy()\n                return ipow_posint(y, n)\n            else:\n                return x ** n\n\n        def ipow_posint(x, n):\n            \"\"\"Power function for positive integer ``n``, in-place.\"\"\"\n            if n == 1:\n                return x\n            elif n % 2 == 0:\n                x *= x\n                return ipow_posint(x, n // 2)\n            else:\n                tmp = x.copy()\n                x *= x\n                ipow_posint(x, n // 2)\n                x *= tmp\n                return x\n\n        def power_oop(x, **kwargs):\n            \"\"\"Power out-of-place evaluation function.\"\"\"\n            if p == 0:\n                return self.one()\n            elif p == int(p) and p >= 1:\n                return np.asarray(pow_posint(f_copy(x, **kwargs), int(p)),\n                                  dtype=self.scalar_out_dtype)\n            else:\n                result = np.power(f_copy(x, **kwargs), p)\n                return result.astype(self.scalar_out_dtype)\n\n        out._call_out_of_place = power_oop\n        decorator = preload_first_arg(out, 'in-place')\n        out._call_in_place = decorator(_default_in_place)\n        out._call_has_out = out._call_out_optional = False\n        return out", "response": "Compute the p - th power of f for p scalar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _realpart(self, f):\n        def f_re(x, **kwargs):\n            result = np.asarray(f(x, **kwargs),\n                                dtype=self.scalar_out_dtype)\n            return result.real\n\n        if is_real_dtype(self.out_dtype):\n            return f\n        else:\n            return self.real_space.element(f_re)", "response": "Function returning the real part of the result from f."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _imagpart(self, f):\n        def f_im(x, **kwargs):\n            result = np.asarray(f(x, **kwargs),\n                                dtype=self.scalar_out_dtype)\n            return result.imag\n\n        if is_real_dtype(self.out_dtype):\n            return self.zero()\n        else:\n            return self.real_space.element(f_im)", "response": "Function returning the imaginary part of the result from f."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction returning the complex conjugate of a result.", "response": "def _conj(self, f):\n        \"\"\"Function returning the complex conjugate of a result.\"\"\"\n        def f_conj(x, **kwargs):\n            result = np.asarray(f(x, **kwargs),\n                                dtype=self.scalar_out_dtype)\n            return result.conj()\n\n        if is_real_dtype(self.out_dtype):\n            return f\n        else:\n            return self.element(f_conj)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nobject to index along output dimensions. This is only valid for non-trivial `out_shape`. Examples -------- Indexing with integers or slices: >>> domain = odl.IntervalProd(0, 1) >>> fspace = odl.FunctionSpace(domain, out_dtype=(float, (2, 3, 4))) >>> fspace.byaxis_out[0] FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (2,))) >>> fspace.byaxis_out[1] FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (3,))) >>> fspace.byaxis_out[1:] FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (3, 4))) Lists can be used to stack spaces arbitrarily: >>> fspace.byaxis_out[[2, 1, 2]] FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (4, 3, 4)))", "response": "def byaxis_out(self):\n        \"\"\"Object to index along output dimensions.\n\n        This is only valid for non-trivial `out_shape`.\n\n        Examples\n        --------\n        Indexing with integers or slices:\n\n        >>> domain = odl.IntervalProd(0, 1)\n        >>> fspace = odl.FunctionSpace(domain, out_dtype=(float, (2, 3, 4)))\n        >>> fspace.byaxis_out[0]\n        FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (2,)))\n        >>> fspace.byaxis_out[1]\n        FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (3,)))\n        >>> fspace.byaxis_out[1:]\n        FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (3, 4)))\n\n        Lists can be used to stack spaces arbitrarily:\n\n        >>> fspace.byaxis_out[[2, 1, 2]]\n        FunctionSpace(IntervalProd(0.0, 1.0), out_dtype=('float64', (4, 3, 4)))\n        \"\"\"\n        space = self\n\n        class FspaceByaxisOut(object):\n\n            \"\"\"Helper class for indexing by output axes.\"\"\"\n\n            def __getitem__(self, indices):\n                \"\"\"Return ``self[indices]``.\n\n                Parameters\n                ----------\n                indices : index expression\n                    Object used to index the output components.\n\n                Returns\n                -------\n                space : `FunctionSpace`\n                    The resulting space with same domain and scalar output\n                    data type, but indexed output components.\n\n                Raises\n                ------\n                IndexError\n                    If this is a space of scalar-valued functions.\n                \"\"\"\n                try:\n                    iter(indices)\n                except TypeError:\n                    newshape = space.out_shape[indices]\n                else:\n                    newshape = tuple(space.out_shape[int(i)] for i in indices)\n\n                dtype = (space.scalar_out_dtype, newshape)\n                return FunctionSpace(space.domain, out_dtype=dtype)\n\n            def __repr__(self):\n                \"\"\"Return ``repr(self)``.\"\"\"\n                return repr(space) + '.byaxis_out'\n\n        return FspaceByaxisOut()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nobjects to index ``self`` along input dimensions. Examples -------- Indexing with integers or slices: >>> domain = odl.IntervalProd([0, 0, 0], [1, 2, 3]) >>> fspace = odl.FunctionSpace(domain) >>> fspace.byaxis_in[0] FunctionSpace(IntervalProd(0.0, 1.0)) >>> fspace.byaxis_in[1] FunctionSpace(IntervalProd(0.0, 2.0)) >>> fspace.byaxis_in[1:] FunctionSpace(IntervalProd([ 0., 0.], [ 2., 3.])) Lists can be used to stack spaces arbitrarily: >>> fspace.byaxis_in[[2, 1, 2]] FunctionSpace(IntervalProd([ 0., 0., 0.], [ 3., 2., 3.]))", "response": "def byaxis_in(self):\n        \"\"\"Object to index ``self`` along input dimensions.\n\n        Examples\n        --------\n        Indexing with integers or slices:\n\n        >>> domain = odl.IntervalProd([0, 0, 0], [1, 2, 3])\n        >>> fspace = odl.FunctionSpace(domain)\n        >>> fspace.byaxis_in[0]\n        FunctionSpace(IntervalProd(0.0, 1.0))\n        >>> fspace.byaxis_in[1]\n        FunctionSpace(IntervalProd(0.0, 2.0))\n        >>> fspace.byaxis_in[1:]\n        FunctionSpace(IntervalProd([ 0.,  0.], [ 2.,  3.]))\n\n        Lists can be used to stack spaces arbitrarily:\n\n        >>> fspace.byaxis_in[[2, 1, 2]]\n        FunctionSpace(IntervalProd([ 0.,  0.,  0.], [ 3.,  2.,  3.]))\n        \"\"\"\n        space = self\n\n        class FspaceByaxisIn(object):\n\n            \"\"\"Helper class for indexing by input axes.\"\"\"\n\n            def __getitem__(self, indices):\n                \"\"\"Return ``self[indices]``.\n\n                Parameters\n                ----------\n                indices : index expression\n                    Object used to index the space domain.\n\n                Returns\n                -------\n                space : `FunctionSpace`\n                    The resulting space with same output data type, but\n                    indexed domain.\n                \"\"\"\n                domain = space.domain[indices]\n                return FunctionSpace(domain, out_dtype=space.out_dtype)\n\n            def __repr__(self):\n                \"\"\"Return ``repr(self)``.\"\"\"\n                return repr(space) + '.byaxis_in'\n\n        return FspaceByaxisIn()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef examples(self):\n        # TODO: adapt for tensor-valued functions\n\n        # Get the points and calculate some statistics on them\n        mins = self.domain.min()\n        maxs = self.domain.max()\n        means = (maxs + mins) / 2.0\n        stds = (maxs - mins) / 4.0\n        ndim = getattr(self.domain, 'ndim', 0)\n\n        # Zero and One\n        yield ('Zero', self.zero())\n        yield ('One', self.one())\n\n        # Indicator function in first dimension\n        def step_fun(x):\n            return (x[0] > means[0])\n\n        yield ('Step', self.element(step_fun))\n\n        # Indicator function on hypercube\n        def cube_fun(x):\n            result = True\n            for points, mean, std in zip(x, means, stds):\n                result = np.logical_and(result, points < mean + std)\n                result = np.logical_and(result, points > mean - std)\n            return result\n\n        yield ('Cube', self.element(cube_fun))\n\n        # Indicator function on a ball\n        if ndim > 1:  # Only if ndim > 1, don't duplicate cube\n            def ball_fun(x):\n                r = sum((xi - mean) ** 2 / std ** 2\n                        for xi, mean, std in zip(x, means, stds))\n                return r < 1.0\n\n            yield ('Ball', self.element(ball_fun))\n\n        # Gaussian function\n        def gaussian_fun(x):\n            r2 = sum((xi - mean) ** 2 / (2 * std ** 2)\n                     for xi, mean, std in zip(x, means, stds))\n            return np.exp(-r2)\n\n        yield ('Gaussian', self.element(gaussian_fun))\n\n        # Gradient in each dimensions\n        for axis in range(ndim):\n            def gradient_fun(x):\n                return (x[axis] - mins[axis]) / (maxs[axis] - mins[axis])\n\n            yield ('Grad {}'.format(axis), self.element(gradient_fun))\n\n        # Gradient in all dimensions\n        if ndim > 1:  # Only if ndim > 1, don't duplicate grad 0\n            def all_gradient_fun(x):\n                return sum((xi - xmin) / (xmax - xmin)\n                           for xi, xmin, xmax in zip(x, mins, maxs))\n\n            yield ('Grad all', self.element(all_gradient_fun))", "response": "Return an iterator over the examples in the space."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassigns other to self.", "response": "def assign(self, other):\n        \"\"\"Assign ``other`` to ``self``.\n\n        This is implemented without `FunctionSpace.lincomb` to ensure that\n        ``self == other`` evaluates to True after ``self.assign(other)``.\n        \"\"\"\n        if other not in self.space:\n            raise TypeError('`other` {!r} is not an element of the space '\n                            '{} of this function'\n                            ''.format(other, self.space))\n        self._call_in_place = other._call_in_place\n        self._call_out_of_place = other._call_out_of_place\n        self._call_has_out = other._call_has_out\n        self._call_out_optional = other._call_out_optional"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        result = self.space.element()\n        result.assign(self)\n        return result", "response": "Create an identical deep copy of this element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef optimal_parameters(reconstruction, fom, phantoms, data,\n                       initial=None, univariate=False):\n    r\"\"\"Find the optimal parameters for a reconstruction method.\n\n    Notes\n    -----\n    For a forward operator :math:`A : X \\to Y`, a reconstruction operator\n    parametrized by :math:`\\theta` is some operator\n    :math:`R_\\theta : Y \\to X`\n    such that\n\n    .. math::\n        R_\\theta(A(x)) \\approx x.\n\n    The optimal choice of :math:`\\theta` is given by\n\n    .. math::\n        \\theta = \\arg\\min_\\theta fom(R(A(x) + noise), x)\n\n    where :math:`fom : X \\times X \\to \\mathbb{R}` is a figure of merit.\n\n    Parameters\n    ----------\n    reconstruction : callable\n        Function that takes two parameters:\n\n            * data : The data to be reconstructed\n            * parameters : Parameters of the reconstruction method\n\n        The function should return the reconstructed image.\n    fom : callable\n        Function that takes two parameters:\n\n            * reconstructed_image\n            * true_image\n\n        and returns a scalar figure of merit.\n    phantoms : sequence\n        True images.\n    data : sequence\n        The data to reconstruct from.\n    initial : array-like or pair\n        Initial guess for the parameters. It is\n        - a required array in the multivariate case\n        - an optional pair in the univariate case.\n    univariate : bool, optional\n        Whether to use a univariate solver\n\n    Returns\n    -------\n    parameters : 'numpy.ndarray'\n        The  optimal parameters for the reconstruction problem.\n    \"\"\"\n\n    def func(lam):\n        # Function to be minimized by scipy\n        return sum(fom(reconstruction(datai, lam), phantomi)\n                   for phantomi, datai in zip(phantoms, data))\n\n    # Pick resolution to fit the one used by the space\n    tol = np.finfo(phantoms[0].space.dtype).resolution * 10\n\n    if univariate:\n        # We use a faster optimizer for the one parameter case\n        result = scipy.optimize.minimize_scalar(\n            func, bracket=initial, tol=tol, bounds=None,\n            options={'disp': False})\n        return result.x\n    else:\n        # Use a gradient free method to find the best parameters\n        initial = np.asarray(initial)\n        parameters = scipy.optimize.fmin_powell(\n            func, initial, xtol=tol, ftol=tol, disp=False)\n        return parameters", "response": "r Finds the optimal parameters for a reconstruction method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the forward pass on the input.", "response": "def forward(self, input):\n        \"\"\"Evaluate forward pass on the input.\n\n        Parameters\n        ----------\n        input : `torch.tensor._TensorBase`\n            Point at which to evaluate the operator.\n\n        Returns\n        -------\n        result : `torch.autograd.variable.Variable`\n            Variable holding the result of the evaluation.\n\n        Examples\n        --------\n        Perform a matrix multiplication:\n\n        >>> matrix = np.array([[1, 0, 1],\n        ...                    [0, 1, 1]], dtype='float32')\n        >>> odl_op = odl.MatrixOperator(matrix)\n        >>> torch_op = OperatorAsAutogradFunction(odl_op)\n        >>> x = torch.Tensor([1, 2, 3])\n        >>> x_var = torch.autograd.Variable(x)\n        >>> torch_op(x_var)\n        Variable containing:\n         4\n         5\n        [torch.FloatTensor of size 2]\n\n        Evaluate a functional, i.e., an operator with scalar output:\n\n        >>> odl_func = odl.solvers.L2NormSquared(odl.rn(3, dtype='float32'))\n        >>> torch_func = OperatorAsAutogradFunction(odl_func)\n        >>> x = torch.Tensor([1, 2, 3])\n        >>> x_var = torch.autograd.Variable(x)\n        >>> torch_func(x_var)\n        Variable containing:\n         14\n        [torch.FloatTensor of size 1]\n        \"\"\"\n        # TODO: batched evaluation\n        if not self.operator.is_linear:\n            # Only needed for nonlinear operators\n            self.save_for_backward(input)\n\n        # TODO: use GPU memory directly if possible\n        input_arr = input.cpu().detach().numpy()\n        if any(s == 0 for s in input_arr.strides):\n            # TODO: remove when Numpy issue #9165 is fixed\n            # https://github.com/numpy/numpy/pull/9177\n            input_arr = input_arr.copy()\n\n        op_result = self.operator(input_arr)\n        if np.isscalar(op_result):\n            # For functionals, the result is funnelled through `float`,\n            # so we wrap it into a Numpy array with the same dtype as\n            # `operator.domain`\n            op_result = np.array(op_result, ndmin=1,\n                                 dtype=self.operator.domain.dtype)\n        tensor = torch.from_numpy(np.array(op_result, copy=False, ndmin=1))\n        tensor = tensor.to(input.device)\n        return tensor"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the forward - pass of this module on x.", "response": "def forward(self, x):\n        \"\"\"Compute forward-pass of this module on ``x``.\n\n        Parameters\n        ----------\n        x : `torch.autograd.variable.Variable`\n            Input of this layer. The contained tensor must have shape\n            ``extra_shape + operator.domain.shape``, and\n            ``len(extra_shape)`` must be at least 1 (batch axis).\n\n        Returns\n        -------\n        out : `torch.autograd.variable.Variable`\n            The computed output. Its tensor will have shape\n            ``extra_shape + operator.range.shape``, where ``extra_shape``\n            are the extra axes of ``x``.\n\n        Examples\n        --------\n        Evaluating on a 2D tensor, where the operator expects a 1D input,\n        i.e., with extra batch axis only:\n\n        >>> matrix = np.array([[1, 0, 0],\n        ...                    [0, 1, 1]], dtype='float32')\n        >>> odl_op = odl.MatrixOperator(matrix)\n        >>> odl_op.domain.shape\n        (3,)\n        >>> odl_op.range.shape\n        (2,)\n        >>> op_mod = OperatorAsModule(odl_op)\n        >>> t = torch.ones(3)\n        >>> x = autograd.Variable(t[None, :]) # \"fake\" batch axis\n        >>> op_mod(x)\n        Variable containing:\n         1  2\n        [torch.FloatTensor of size 1x2]\n        >>> t = torch.ones(3)\n        >>> x_tensor = torch.stack([0 * t, 1 * t])\n        >>> x = autograd.Variable(x_tensor)  # batch of 2 inputs\n        >>> op_mod(x)\n        Variable containing:\n         0  0\n         1  2\n        [torch.FloatTensor of size 2x2]\n\n        An arbitrary number of axes is supported:\n\n        >>> x = autograd.Variable(t[None, None, :])  # \"fake\" batch and channel\n        >>> op_mod(x)\n        Variable containing:\n        (0 ,.,.) =\n          1  2\n        [torch.FloatTensor of size 1x1x2]\n        >>> x_tensor = torch.stack([torch.stack([0 * t, 1 * t]),\n        ...                         torch.stack([2 * t, 3 * t]),\n        ...                         torch.stack([4 * t, 5 * t])])\n        >>> x = autograd.Variable(x_tensor)  # batch of 3x2 inputs\n        >>> op_mod(x)\n        Variable containing:\n        (0 ,.,.) =\n           0   0\n           1   2\n        <BLANKLINE>\n        (1 ,.,.) =\n           2   4\n           3   6\n        <BLANKLINE>\n        (2 ,.,.) =\n           4   8\n           5  10\n        [torch.FloatTensor of size 3x2x2]\n        \"\"\"\n        in_shape = x.data.shape\n        op_in_shape = self.op_func.operator.domain.shape\n        op_out_shape = self.op_func.operator.range.shape\n\n        extra_shape = in_shape[:-len(op_in_shape)]\n\n        if in_shape[-len(op_in_shape):] != op_in_shape or not extra_shape:\n            shp_str = str(op_in_shape).strip('()')\n            raise ValueError('expected input of shape (N, *, {}), got input '\n                             'with shape {}'.format(shp_str, in_shape))\n\n        # Flatten extra axes, then do one entry at a time\n        newshape = (int(np.prod(extra_shape)),) + op_in_shape\n        x_flat_xtra = x.reshape(*newshape)\n        results = []\n        for i in range(x_flat_xtra.data.shape[0]):\n            results.append(self.op_func(x_flat_xtra[i]))\n\n        # Reshape the resulting stack to the expected output shape\n        stack_flat_xtra = torch.stack(results)\n        return stack_flat_xtra.view(extra_shape + op_out_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mean_squared_error(data, ground_truth, mask=None,\n                       normalized=False, force_lower_is_better=True):\n    r\"\"\"Return mean squared L2 distance between ``data`` and ``ground_truth``.\n\n    See also `this Wikipedia article\n    <https://en.wikipedia.org/wiki/Mean_squared_error>`_.\n\n    Parameters\n    ----------\n    data : `Tensor` or `array-like`\n        Input data to compare to the ground truth. If not a `Tensor`, an\n        unweighted tensor space will be assumed.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    mask : `array-like`, optional\n        If given, ``data * mask`` is compared to ``ground_truth * mask``.\n    normalized  : bool, optional\n        If ``True``, the output values are mapped to the interval\n        :math:`[0, 1]` (see `Notes` for details).\n    force_lower_is_better : bool, optional\n        If ``True``, it is ensured that lower values correspond to better\n        matches. For the mean squared error, this is already the case, and\n        the flag is only present for compatibility to other figures of merit.\n\n    Returns\n    -------\n    mse : float\n        FOM value, where a lower value means a better match.\n\n    Notes\n    -----\n    The FOM evaluates\n\n    .. math::\n        \\mathrm{MSE}(f, g) = \\frac{\\| f - g \\|_2^2}{\\| 1 \\|_2^2},\n\n    where :math:`\\| 1 \\|^2_2` is the volume of the domain of definition\n    of the functions. For :math:`\\mathbb{R}^n` type spaces, this is equal\n    to the number of elements :math:`n`.\n\n    The normalized form is\n\n    .. math::\n        \\mathrm{MSE_N} = \\frac{\\| f - g \\|_2^2}{(\\| f \\|_2 + \\| g \\|_2)^2}.\n\n    The normalized variant takes values in :math:`[0, 1]`.\n    \"\"\"\n    if not hasattr(data, 'space'):\n        data = odl.vector(data)\n\n    space = data.space\n    ground_truth = space.element(ground_truth)\n\n    l2norm = odl.solvers.L2Norm(space)\n\n    if mask is not None:\n        data = data * mask\n        ground_truth = ground_truth * mask\n\n    diff = data - ground_truth\n    fom = l2norm(diff) ** 2\n\n    if normalized:\n        fom /= (l2norm(data) + l2norm(ground_truth)) ** 2\n    else:\n        fom /= l2norm(space.one()) ** 2\n\n    # Ignore `force_lower_is_better` since that's already the case\n\n    return fom", "response": "r Returns the mean squared error between data and ground_truth."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mean_absolute_error(data, ground_truth, mask=None,\n                        normalized=False, force_lower_is_better=True):\n    r\"\"\"Return L1-distance between ``data`` and ``ground_truth``.\n\n    See also `this Wikipedia article\n    <https://en.wikipedia.org/wiki/Mean_absolute_error>`_.\n\n    Parameters\n    ----------\n    data : `Tensor` or `array-like`\n        Input data to compare to the ground truth. If not a `Tensor`, an\n        unweighted tensor space will be assumed.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    mask : `array-like`, optional\n        If given, ``data * mask`` is compared to ``ground_truth * mask``.\n    normalized  : bool, optional\n        If ``True``, the output values are mapped to the interval\n        :math:`[0, 1]` (see `Notes` for details), otherwise return the\n        original mean absolute error.\n    force_lower_is_better : bool, optional\n        If ``True``, it is ensured that lower values correspond to better\n        matches. For the mean absolute error, this is already the case, and\n        the flag is only present for compatibility to other figures of merit.\n\n    Returns\n    -------\n    mae : float\n        FOM value, where a lower value means a better match.\n\n    Notes\n    -----\n    The FOM evaluates\n\n    .. math::\n        \\mathrm{MAE}(f, g) = \\frac{\\| f - g \\|_1}{\\| 1 \\|_1},\n\n    where :math:`\\| 1 \\|_1` is the volume of the domain of definition\n    of the functions. For :math:`\\mathbb{R}^n` type spaces, this is equal\n    to the number of elements :math:`n`.\n\n    The normalized form is\n\n    .. math::\n        \\mathrm{MAE_N}(f, g) = \\frac{\\| f - g \\|_1}{\\| f \\|_1 + \\| g \\|_1}.\n\n    The normalized variant takes values in :math:`[0, 1]`.\n    \"\"\"\n    if not hasattr(data, 'space'):\n        data = odl.vector(data)\n\n    space = data.space\n    ground_truth = space.element(ground_truth)\n\n    l1_norm = odl.solvers.L1Norm(space)\n    if mask is not None:\n        data = data * mask\n        ground_truth = ground_truth * mask\n\n    diff = data - ground_truth\n    fom = l1_norm(diff)\n\n    if normalized:\n        fom /= (l1_norm(data) + l1_norm(ground_truth))\n    else:\n        fom /= l1_norm(space.one())\n\n    # Ignore `force_lower_is_better` since that's already the case\n\n    return fom", "response": "r Returns the L1 - distance between data and ground_truth."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mean_value_difference(data, ground_truth, mask=None, normalized=False,\n                          force_lower_is_better=True):\n    r\"\"\"Return difference in mean value between ``data`` and ``ground_truth``.\n\n    Parameters\n    ----------\n    data : `Tensor` or `array-like`\n        Input data to compare to the ground truth. If not a `Tensor`, an\n        unweighted tensor space will be assumed.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    mask : `array-like`, optional\n        If given, ``data * mask`` is compared to ``ground_truth * mask``.\n    normalized  : bool, optional\n        Boolean flag to switch between unormalized and normalized FOM.\n    force_lower_is_better : bool, optional\n        If ``True``, it is ensured that lower values correspond to better\n        matches. For the mean value difference, this is already the case, and\n        the flag is only present for compatibility to other figures of merit.\n\n    Returns\n    -------\n    mvd : float\n        FOM value, where a lower value means a better match.\n\n    Notes\n    -----\n    The FOM evaluates\n\n    .. math::\n         \\mathrm{MVD}(f, g) =\n         \\Big| \\overline{f} - \\overline{g} \\Big|,\n\n    or, in normalized form\n\n    .. math::\n         \\mathrm{MVD_N}(f, g) =\n         \\frac{\\Big| \\overline{f} - \\overline{g} \\Big|}\n               {|\\overline{f}| + |\\overline{g}|}\n\n    where :math:`\\overline{f}` is the mean value of :math:`f`,\n\n    .. math::\n        \\overline{f} = \\frac{\\langle f, 1\\rangle}{\\|1|_1}.\n\n    The normalized variant takes values in :math:`[0, 1]`.\n    \"\"\"\n    if not hasattr(data, 'space'):\n        data = odl.vector(data)\n\n    space = data.space\n    ground_truth = space.element(ground_truth)\n\n    l1_norm = odl.solvers.L1Norm(space)\n    if mask is not None:\n        data = data * mask\n        ground_truth = ground_truth * mask\n\n    # Volume of space\n    vol = l1_norm(space.one())\n\n    data_mean = data.inner(space.one()) / vol\n    ground_truth_mean = ground_truth.inner(space.one()) / vol\n\n    fom = np.abs(data_mean - ground_truth_mean)\n\n    if normalized:\n        fom /= (np.abs(data_mean) + np.abs(ground_truth_mean))\n\n    # Ignore `force_lower_is_better` since that's already the case\n\n    return fom", "response": "r Return difference in mean value between data and ground_truth."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef range_difference(data, ground_truth, mask=None, normalized=False,\n                     force_lower_is_better=True):\n    r\"\"\"Return dynamic range difference between ``data`` and ``ground_truth``.\n\n    Evaluates difference in range between input (``data``) and reference\n    data (``ground_truth``). Allows for normalization (``normalized``) and a\n    masking of the two spaces (``mask``).\n\n    Parameters\n    ----------\n    data : `array-like`\n        Input data to compare to the ground truth.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    mask : `array-like`, optional\n        Binary mask or index array to define ROI in which FOM evaluation\n        is performed.\n    normalized  : bool, optional\n        If ``True``, normalize the FOM to lie in [0, 1].\n    force_lower_is_better : bool, optional\n        If ``True``, it is ensured that lower values correspond to better\n        matches. For the range difference, this is already the case, and\n        the flag is only present for compatibility to other figures of merit.\n\n    Returns\n    -------\n    rd : float\n        FOM value, where a lower value means a better match.\n\n    Notes\n    -----\n    The FOM evaluates\n\n    .. math::\n        \\mathrm{RD}(f, g) = \\Big|\n            \\big(\\max(f) - \\min(f) \\big) -\n            \\big(\\max(g) - \\min(g) \\big)\n            \\Big|\n\n    or, in normalized form\n\n    .. math::\n        \\mathrm{RD_N}(f, g) = \\frac{\n            \\Big|\n            \\big(\\max(f) - \\min(f) \\big) -\n            \\big(\\max(g) - \\min(g) \\big)\n            \\Big|}{\n            \\big(\\max(f) - \\min(f) \\big) +\n            \\big(\\max(g) - \\min(g) \\big)}\n\n    The normalized variant takes values in :math:`[0, 1]`.\n    \"\"\"\n    data = np.asarray(data)\n    ground_truth = np.asarray(ground_truth)\n\n    if mask is not None:\n        mask = np.asarray(mask, dtype=bool)\n        data = data[mask]\n        ground_truth = ground_truth[mask]\n\n    data_range = np.ptp(data)\n    ground_truth_range = np.ptp(ground_truth)\n    fom = np.abs(data_range - ground_truth_range)\n\n    if normalized:\n        denom = np.abs(data_range + ground_truth_range)\n        if denom == 0:\n            fom = 0.0\n        else:\n            fom /= denom\n\n    return fom", "response": "r Return dynamic range difference between data and ground_truth."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning mask emphasizing areas outside the given foreground.", "response": "def false_structures_mask(foreground, smoothness_factor=None):\n    \"\"\"Return mask emphasizing areas outside ``foreground``.\n\n    Parameters\n    ----------\n    foreground : `Tensor` or `array-like`\n        The region that should be de-emphasized. If not a `Tensor`, an\n        unweighted tensor space will be assumed.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    foreground : `FnBaseVector`\n        The region that should be de-emphasized.\n    smoothness_factor : float, optional\n        Positive real number. Higher value gives smoother transition\n        between foreground and its complement.\n\n    Returns\n    -------\n    result : `Tensor` or `numpy.ndarray`\n         Euclidean distances of elements in ``foreground``. The return value\n         is a `Tensor` if ``foreground`` is one, too, otherwise a NumPy array.\n\n    Examples\n    --------\n    >>> space = odl.uniform_discr(0, 1, 5)\n    >>> foreground = space.element([0, 0, 1.0, 0, 0])\n    >>> mask = false_structures_mask(foreground)\n    >>> np.asarray(mask)\n    array([ 0.4,  0.2,  0. ,  0.2,  0.4])\n\n    Raises\n    ------\n    ValueError\n        If foreground is all zero or all one, or contains values not in {0, 1}.\n\n    Notes\n    -----\n    This helper function computes the Euclidean distance transform from each\n    point in ``foreground.space`` to ``foreground``.\n\n    The weighting gives higher values to structures outside the foreground\n    as defined by the mask.\n    \"\"\"\n    try:\n        space = foreground.space\n        has_space = True\n    except AttributeError:\n        has_space = False\n        foreground = np.asarray(foreground)\n        space = odl.tensor_space(foreground.shape, foreground.dtype)\n        foreground = space.element(foreground)\n\n    from scipy.ndimage.morphology import distance_transform_edt\n\n    unique = np.unique(foreground)\n    if not np.array_equiv(unique, [0., 1.]):\n        raise ValueError('`foreground` is not a binary mask or has '\n                         'either only true or only false values {!r}'\n                         ''.format(unique))\n\n    result = distance_transform_edt(\n        1.0 - foreground, sampling=getattr(space, 'cell_sides', 1.0)\n    )\n    if has_space:\n        return space.element(result)\n    else:\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ssim(data, ground_truth, size=11, sigma=1.5, K1=0.01, K2=0.03,\n         dynamic_range=None, normalized=False, force_lower_is_better=False):\n    r\"\"\"Structural SIMilarity between ``data`` and ``ground_truth``.\n\n    The SSIM takes value -1 for maximum dissimilarity and +1 for maximum\n    similarity.\n\n    See also `this Wikipedia article\n    <https://en.wikipedia.org/wiki/Structural_similarity>`_.\n\n    Parameters\n    ----------\n    data : `array-like`\n        Input data to compare to the ground truth.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    size : odd int, optional\n        Size in elements per axis of the Gaussian window that is used\n        for all smoothing operations.\n    sigma : positive float, optional\n        Width of the Gaussian function used for smoothing.\n    K1, K2 : positive float, optional\n        Small constants to stabilize the result. See [Wan+2004] for details.\n    dynamic_range : nonnegative float, optional\n        Difference between the maximum and minimum value that the pixels\n        can attain. Use 255 if pixel range is :math:`[0, 255]` and 1 if\n        it is :math:`[0, 1]`. Default: `None`, obtain maximum and minimum\n        from the ground truth.\n    normalized  : bool, optional\n        If ``True``, the output values are mapped to the interval\n        :math:`[0, 1]` (see `Notes` for details), otherwise return the\n        original SSIM.\n    force_lower_is_better : bool, optional\n        If ``True``, it is ensured that lower values correspond to better\n        matches by returning the negative of the SSIM, otherwise the (possibly\n        normalized) SSIM is returned. If both `normalized` and\n        `force_lower_is_better` are ``True``, then the order is reversed before\n        mapping the outputs, so that the latter are still in the interval\n        :math:`[0, 1]`.\n\n    Returns\n    -------\n    ssim : float\n        FOM value, where a higher value means a better match\n        if `force_lower_is_better` is ``False``.\n\n    Notes\n    -----\n    The SSIM is computed on small windows and then averaged over the whole\n    image. The SSIM between two windows :math:`x` and :math:`y` of size\n    :math:`N \\times N`\n\n    .. math::\n        SSIM(x,y) = \\frac{(2\\mu_x\\mu_y + c_1)(2\\sigma_{xy} + c_2)}\n                    {(\\mu_x^2 + \\mu_y^2 + c_1)(\\sigma_x^2 + \\sigma_y^2 + c_2)}\n\n    where:\n\n    * :math:`\\mu_x`, :math:`\\mu_y` is the mean of :math:`x` and :math:`y`,\n      respectively.\n    * :math:`\\sigma_x`, :math:`\\sigma_y` is the standard deviation of\n      :math:`x` and :math:`y`, respectively.\n    * :math:`\\sigma_{xy}` the covariance of :math:`x` and :math:`y`\n    * :math:`c_1 = (k_1L)^2`, :math:`c_2 = (k_2L)^2` where :math:`L` is the\n      dynamic range of the image.\n\n    The unnormalized values are contained in the interval :math:`[-1, 1]`,\n    where 1 corresponds to a perfect match. The normalized values are given by\n\n    .. math::\n        SSIM_{normalized}(x, y) = \\frac{SSIM(x, y) + 1}{2}\n\n    References\n    ----------\n    [Wan+2004] Wang, Z, Bovik, AC, Sheikh, HR, and Simoncelli, EP.\n    *Image Quality Assessment: From Error Visibility to Structural Similarity*.\n    IEEE Transactions on Image Processing, 13.4 (2004), pp 600--612.\n    \"\"\"\n    from scipy.signal import fftconvolve\n\n    data = np.asarray(data)\n    ground_truth = np.asarray(ground_truth)\n\n    # Compute gaussian on a `size`-sized grid in each axis\n    coords = np.linspace(-(size - 1) / 2, (size - 1) / 2, size)\n    grid = sparse_meshgrid(*([coords] * data.ndim))\n\n    window = np.exp(-(sum(xi ** 2 for xi in grid) / (2.0 * sigma ** 2)))\n    window /= np.sum(window)\n\n    def smoothen(img):\n        \"\"\"Smoothes an image by convolving with a window function.\"\"\"\n        return fftconvolve(window, img, mode='valid')\n\n    if dynamic_range is None:\n        dynamic_range = np.max(ground_truth) - np.min(ground_truth)\n\n    C1 = (K1 * dynamic_range) ** 2\n    C2 = (K2 * dynamic_range) ** 2\n    mu1 = smoothen(data)\n    mu2 = smoothen(ground_truth)\n\n    mu1_sq = mu1 * mu1\n    mu2_sq = mu2 * mu2\n    mu1_mu2 = mu1 * mu2\n\n    sigma1_sq = smoothen(data * data) - mu1_sq\n    sigma2_sq = smoothen(ground_truth * ground_truth) - mu2_sq\n    sigma12 = smoothen(data * ground_truth) - mu1_mu2\n\n    num = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n    denom = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n    pointwise_ssim = num / denom\n\n    result = np.mean(pointwise_ssim)\n\n    if force_lower_is_better:\n        result = -result\n\n    if normalized:\n        result = (result + 1.0) / 2.0\n\n    return result", "response": "r Returns the SSIM of the data between the given ground truth."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the Peak Signal - To - Noise Ratio of data wrt ground_truth.", "response": "def psnr(data, ground_truth, use_zscore=False, force_lower_is_better=False):\n    \"\"\"Return the Peak Signal-to-Noise Ratio of ``data`` wrt ``ground_truth``.\n\n    See also `this Wikipedia article\n    <https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio>`_.\n\n    Parameters\n    ----------\n    data : `Tensor` or `array-like`\n        Input data to compare to the ground truth. If not a `Tensor`, an\n        unweighted tensor space will be assumed.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    use_zscore : bool\n        If ``True``, normalize ``data`` and ``ground_truth`` to have zero mean\n        and unit variance before comparison.\n    force_lower_is_better : bool\n        If ``True``, then lower value indicates better fit. In this case the\n        output is negated.\n\n    Returns\n    -------\n    psnr : float\n        FOM value, where a higher value means a better match.\n\n    Examples\n    --------\n    Compute the PSNR for two vectors:\n\n    >>> spc = odl.rn(5)\n    >>> data = spc.element([1, 1, 1, 1, 1])\n    >>> ground_truth = spc.element([1, 1, 1, 1, 2])\n    >>> result = psnr(data, ground_truth)\n    >>> print('{:.3f}'.format(result))\n    13.010\n\n    If data == ground_truth, the result is positive infinity:\n\n    >>> psnr(ground_truth, ground_truth)\n    inf\n\n    With ``use_zscore=True``, scaling differences and constant offsets\n    are ignored:\n\n    >>> (psnr(data, ground_truth, use_zscore=True) ==\n    ...  psnr(data, 3 + 4 * ground_truth, use_zscore=True))\n    True\n    \"\"\"\n    if use_zscore:\n        data = odl.util.zscore(data)\n        ground_truth = odl.util.zscore(ground_truth)\n\n    mse = mean_squared_error(data, ground_truth)\n    max_true = np.max(np.abs(ground_truth))\n\n    if mse == 0:\n        result = np.inf\n    elif max_true == 0:\n        result = -np.inf\n    else:\n        result = 20 * np.log10(max_true) - 10 * np.log10(mse)\n\n    if force_lower_is_better:\n        return -result\n    else:\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the Noise Power Spectrum of the given data.", "response": "def noise_power_spectrum(data, ground_truth, radial=False,\n                         radial_binning_factor=2.0):\n    \"\"\"Return the Noise Power Spectrum (NPS).\n\n    The NPS is given by the squared magnitude of the Fourier transform of the\n    noise.\n\n    Parameters\n    ----------\n    data : `DiscreteLpElement` or `array-like`\n        Input data to compare to the ground truth. If not a\n        `DiscreteLpElement`, a default space with cell size 1 will be assumed.\n    ground_truth : `array-like`\n        Reference to which ``data`` should be compared.\n    radial : bool\n        If ``True``, compute the radial NPS.\n    radial_binning_factor : positive float, optional\n        Reduce the number of radial bins by this factor. Increasing this\n        number can help reducing fluctuations due to the variance of points\n        that fall in a particular annulus.\n        A binning factor of ``1`` corresponds to a bin size equal to\n        image pixel size for images with square pixels, otherwise ::\n\n            max(norm2(c)) / norm2(shape)\n\n        where the maximum is taken over all corners of the image domain.\n\n    Returns\n    -------\n    noise_power_spectrum : `DiscreteLp`-element\n        The space is the Fourier space corresponding to ``space``, and\n        hence the axes indicate frequency.\n        If ``radial`` is ``True``, an average over concentric annuli is\n        taken. The result is an element of a one-dimensional space with\n        domain ``[0, rmax]``, where ``rmax`` is the radius of the smallest\n        ball containing ``space.domain``. Its shape is ``(N,)`` with ::\n\n            N = int(sqrt(sum(n ** 2 for n in image.shape)) / binning_factor)\n    \"\"\"\n    try:\n        space = data.space\n        assert isinstance(space, odl.DiscreteLp)\n    except (AttributeError, AssertionError):\n        data = np.asarray(data)\n        space = odl.uniform_discr(\n            [0] * data.ndim, data.shape, data.shape, data.dtype\n        )\n        data = space.element(data)\n\n    ft = odl.trafos.FourierTransform(space, halfcomplex=False)\n    nps = np.abs(ft(data - ground_truth)).real ** 2\n\n    if radial:\n        return spherical_sum(nps, binning_factor=radial_binning_factor)\n    else:\n        return nps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the unit vector perpendicular to the detector surface at the given parameter.", "response": "def surface_normal(self, param):\n        \"\"\"Unit vector perpendicular to the detector surface at ``param``.\n\n        The orientation is chosen as follows:\n\n            - In 2D, the system ``(normal, tangent)`` should be\n              right-handed.\n            - In 3D, the system ``(tangent[0], tangent[1], normal)``\n              should be right-handed.\n\n        Here, ``tangent`` is the return value of `surface_deriv` at\n        ``param``.\n\n        Parameters\n        ----------\n        param : `array-like` or sequence\n            Parameter value(s) at which to evaluate.  If ``ndim >= 2``,\n            a sequence of length `ndim` must be provided.\n\n        Returns\n        -------\n        normal : `numpy.ndarray`\n            Unit vector(s) perpendicular to the detector surface at\n            ``param``.\n            If ``param`` is a single parameter, an array of shape\n            ``(space_ndim,)`` representing a single vector is returned.\n            Otherwise the shape of the returned array is\n\n            - ``param.shape + (space_ndim,)`` if `ndim` is 1,\n            - ``param.shape[:-1] + (space_ndim,)`` otherwise.\n        \"\"\"\n        # Checking is done by `surface_deriv`\n        if self.ndim == 1 and self.space_ndim == 2:\n            return -perpendicular_vector(self.surface_deriv(param))\n        elif self.ndim == 2 and self.space_ndim == 3:\n            deriv = self.surface_deriv(param)\n            if deriv.ndim > 2:\n                # Vectorized, need to reshape (N, 2, 3) to (2, N, 3)\n                deriv = moveaxis(deriv, -2, 0)\n            normal = np.cross(*deriv, axis=-1)\n            normal /= np.linalg.norm(normal, axis=-1, keepdims=True)\n            return normal\n        else:\n            raise NotImplementedError(\n                'no default implementation of `surface_normal` available '\n                'for `ndim = {}` and `space_ndim = {}`'\n                ''.format(self.ndim, self.space_ndim))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef surface_measure(self, param):\n        # Checking is done by `surface_deriv`\n        if self.ndim == 1:\n            scalar_out = (np.shape(param) == ())\n            measure = np.linalg.norm(self.surface_deriv(param), axis=-1)\n            if scalar_out:\n                measure = float(measure)\n\n            return measure\n\n        elif self.ndim == 2 and self.space_ndim == 3:\n            scalar_out = (np.shape(param) == (2,))\n            deriv = self.surface_deriv(param)\n            if deriv.ndim > 2:\n                # Vectorized, need to reshape (N, 2, 3) to (2, N, 3)\n                deriv = moveaxis(deriv, -2, 0)\n            cross = np.cross(*deriv, axis=-1)\n            measure = np.linalg.norm(cross, axis=-1)\n            if scalar_out:\n                measure = float(measure)\n\n            return measure\n\n        else:\n            raise NotImplementedError(\n                'no default implementation of `surface_measure` available '\n                'for `ndim={}` and `space_ndim={}`'\n                ''.format(self.ndim, self.space_ndim))", "response": "This method evaluates the density of the entry point at the given parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the detector surface point corresponding to param.", "response": "def surface(self, param):\n        \"\"\"Return the detector surface point corresponding to ``param``.\n\n        For parameter value ``p``, the surface point is given by ::\n\n            surf = p * axis\n\n        Parameters\n        ----------\n        param : float or `array-like`\n            Parameter value(s) at which to evaluate.\n\n        Returns\n        -------\n        point : `numpy.ndarray`\n            Vector(s) pointing from the origin to the detector surface\n            point at ``param``.\n            If ``param`` is a single parameter, the returned array has\n            shape ``(2,)``, otherwise ``param.shape + (2,)``.\n\n        Examples\n        --------\n        The method works with a single parameter, resulting in a single\n        vector:\n\n        >>> part = odl.uniform_partition(0, 1, 10)\n        >>> det = Flat1dDetector(part, axis=[1, 0])\n        >>> det.surface(0)\n        array([ 0.,  0.])\n        >>> det.surface(1)\n        array([ 1.,  0.])\n\n        It is also vectorized, i.e., it can be called with multiple\n        parameters at once (or an n-dimensional array of parameters):\n\n        >>> det.surface([0, 1])\n        array([[ 0.,  0.],\n               [ 1.,  0.]])\n        >>> det.surface(np.zeros((4, 5))).shape\n        (4, 5, 2)\n        \"\"\"\n        squeeze_out = (np.shape(param) == ())\n        param = np.array(param, dtype=float, copy=False, ndmin=1)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param, self.params))\n\n        # Create outer product of `params` and `axis`, resulting in shape\n        # params.shape + axis.shape\n        surf = np.multiply.outer(param, self.axis)\n        if squeeze_out:\n            surf = surf.squeeze()\n\n        return surf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the surface derivative at param.", "response": "def surface_deriv(self, param):\n        \"\"\"Return the surface derivative at ``param``.\n\n        This is a constant function evaluating to `axis` everywhere.\n\n        Parameters\n        ----------\n        param : float or `array-like`\n            Parameter value(s) at which to evaluate.\n\n        Returns\n        -------\n        deriv : `numpy.ndarray`\n            Array representing the derivative vector(s) at ``param``.\n            If ``param`` is a single parameter, the returned array has\n            shape ``(2,)``, otherwise ``param.shape + (2,)``.\n\n        Examples\n        --------\n        The method works with a single parameter, resulting in a single\n        vector:\n\n        >>> part = odl.uniform_partition(0, 1, 10)\n        >>> det = Flat1dDetector(part, axis=[1, 0])\n        >>> det.surface_deriv(0)\n        array([ 1.,  0.])\n        >>> det.surface_deriv(1)\n        array([ 1.,  0.])\n\n        It is also vectorized, i.e., it can be called with multiple\n        parameters at once (or an n-dimensional array of parameters):\n\n        >>> det.surface_deriv([0, 1])\n        array([[ 1.,  0.],\n               [ 1.,  0.]])\n        >>> det.surface_deriv(np.zeros((4, 5))).shape\n        (4, 5, 2)\n        \"\"\"\n        squeeze_out = (np.shape(param) == ())\n        param = np.array(param, dtype=float, copy=False, ndmin=1)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param, self.params))\n        if squeeze_out:\n            return self.axis\n        else:\n            # Produce array of shape `param.shape + (ndim,)` by broadcasting\n            bcast_slc = (None,) * param.ndim + (slice(None),)\n            return np.broadcast_to(\n                self.axis[bcast_slc], param.shape + self.axis.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef surface(self, param):\n        squeeze_out = (np.broadcast(*param).shape == ())\n        param_in = param\n        param = tuple(np.array(p, dtype=float, copy=False, ndmin=1)\n                      for p in param)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param_in, self.params))\n\n        # Compute outer product of the i-th spatial component of the\n        # parameter and sum up the contributions\n        surf = sum(np.multiply.outer(p, ax) for p, ax in zip(param, self.axes))\n        if squeeze_out:\n            surf = surf.squeeze()\n\n        return surf", "response": "Return the detector surface point corresponding to param."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the surface derivative at param.", "response": "def surface_deriv(self, param):\n        \"\"\"Return the surface derivative at ``param``.\n\n        This is a constant function evaluating to `axes` everywhere.\n\n        Parameters\n        ----------\n        param : `array-like` or sequence\n            Parameter value(s) at which to evaluate. A sequence of\n            parameters must have length 2.\n\n        Returns\n        -------\n        deriv : `numpy.ndarray`\n            Array containing the derivative vectors. The first dimension\n            enumerates the axes, i.e., has always length 2.\n            If ``param`` is a single parameter, the returned array has\n            shape ``(2, 3)``, otherwise\n            ``broadcast(*param).shape + (2, 3)``.\n\n        Notes\n        -----\n        To get an array that enumerates the derivative vectors in the first\n        dimension, move the second-to-last axis to the first position::\n\n            deriv = surface_deriv(param)\n            axes_enumeration = np.moveaxis(deriv, -2, 0)\n\n        Examples\n        --------\n        The method works with a single parameter, resulting in a 2-tuple\n        of vectors:\n\n        >>> part = odl.uniform_partition([0, 0], [1, 1], (10, 10))\n        >>> det = Flat2dDetector(part, axes=[(1, 0, 0), (0, 0, 1)])\n        >>> det.surface_deriv([0, 0])\n        array([[ 1.,  0.,  0.],\n               [ 0.,  0.,  1.]])\n        >>> det.surface_deriv([1, 1])\n        array([[ 1.,  0.,  0.],\n               [ 0.,  0.,  1.]])\n\n        It is also vectorized, i.e., it can be called with multiple\n        parameters at once (or n-dimensional arrays of parameters):\n\n        >>> # 2 pairs of parameters, resulting in 3 vectors for each axis\n        >>> deriv = det.surface_deriv([[0, 1],\n        ...                            [0, 1]])\n        >>> deriv[0]  # first pair of vectors\n        array([[ 1.,  0.,  0.],\n               [ 0.,  0.,  1.]])\n        >>> deriv[1]  # second pair of vectors\n        array([[ 1.,  0.,  0.],\n               [ 0.,  0.,  1.]])\n        >>> # Pairs of parameters in a (4, 5) array each\n        >>> param = (np.zeros((4, 5)), np.zeros((4, 5)))  # pairs of params\n        >>> det.surface_deriv(param).shape\n        (4, 5, 2, 3)\n        >>> # Using broadcasting for \"outer product\" type result\n        >>> param = (np.zeros((4, 1)), np.zeros((1, 5)))  # broadcasting\n        >>> det.surface_deriv(param).shape\n        (4, 5, 2, 3)\n        \"\"\"\n        squeeze_out = (np.broadcast(*param).shape == ())\n        param_in = param\n        param = tuple(np.array(p, dtype=float, copy=False, ndmin=1)\n                      for p in param)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param_in, self.params))\n\n        if squeeze_out:\n            return self.axes\n        else:\n            return np.broadcast_to(\n                self.axes, np.broadcast(*param).shape + self.axes.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef surface(self, param):\n        squeeze_out = (np.shape(param) == ())\n        param = np.array(param, dtype=float, copy=False, ndmin=1)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param, self.params))\n\n        surf = np.empty(param.shape + (2,))\n        surf[..., 0] = np.cos(param)\n        surf[..., 1] = -np.sin(param)\n        surf *= self.radius\n        surf = np.matmul(surf, np.transpose(self.rotation_matrix))\n        surf += self.translation\n        if squeeze_out:\n            surf = surf.squeeze()\n\n        return surf", "response": "Return the detector surface point corresponding to param."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef surface_deriv(self, param):\n        squeeze_out = (np.shape(param) == ())\n        param = np.array(param, dtype=float, copy=False, ndmin=1)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param, self.params))\n\n        deriv = np.empty(param.shape + (2,))\n        deriv[..., 0] = -np.sin(param)\n        deriv[..., 1] = -np.cos(param)\n        deriv *= self.radius\n        deriv = np.matmul(deriv, np.transpose(self.rotation_matrix))\n\n        if squeeze_out:\n            deriv = deriv.squeeze()\n\n        return deriv", "response": "Return the surface derivative at the given parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the arc length measure at param. This method is a constant function evaluating to radius everywhere.", "response": "def surface_measure(self, param):\n        \"\"\"Return the arc length measure at ``param``.\n\n        This is a constant function evaluating to `radius` everywhere.\n\n        Parameters\n        ----------\n        param : float or `array-like`\n            Parameter value(s) at which to evaluate.\n\n        Returns\n        -------\n        measure : float or `numpy.ndarray`\n            Constant value(s) of the arc length measure at ``param``.\n            If ``param`` is a single parameter, a float is returned,\n            otherwise an array of shape ``param.shape``.\n\n        See Also\n        --------\n        surface\n        surface_deriv\n\n        Examples\n        --------\n        The method works with a single parameter, resulting in a float:\n\n        >>> part = odl.uniform_partition(-np.pi / 2, np.pi / 2, 10)\n        >>> det = CircularDetector(part, axis=[1, 0], radius=2)\n        >>> det.surface_measure(0)\n        2.0\n        >>> det.surface_measure(np.pi / 2)\n        2.0\n\n        It is also vectorized, i.e., it can be called with multiple\n        parameters at once (or an n-dimensional array of parameters):\n\n        >>> det.surface_measure([0, np.pi / 2])\n        array([ 2.,  2.])\n        >>> det.surface_measure(np.zeros((4, 5))).shape\n        (4, 5)\n        \"\"\"\n        scalar_out = (np.shape(param) == ())\n        param = np.array(param, dtype=float, copy=False, ndmin=1)\n        if self.check_bounds and not is_inside_bounds(param, self.params):\n            raise ValueError('`param` {} not in the valid range '\n                             '{}'.format(param, self.params))\n\n        if scalar_out:\n            return self.radius\n        else:\n            return self.radius * np.ones(param.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x):\n        result = self.sess.run(self.output_tensor,\n                               feed_dict={self.input_tensor: np.asarray(x)})\n\n        return result", "response": "Call self with x."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adupdates_simple(x, g, L, stepsize, inner_stepsizes, niter,\n                     random=False):\n    \"\"\"Non-optimized version of ``adupdates``.\n    This function is intended for debugging. It makes a lot of copies and\n    performs no error checking.\n    \"\"\"\n    # Initializations\n    length = len(g)\n    ranges = [Li.range for Li in L]\n    duals = [space.zero() for space in ranges]\n\n    # Iteratively find a solution\n    for _ in range(niter):\n        # Update x = x - 1/stepsize * sum([ops[i].adjoint(duals[i])\n        # for i in range(length)])\n        for i in range(length):\n            x -= (1.0 / stepsize) * L[i].adjoint(duals[i])\n\n        rng = np.random.permutation(range(length)) if random else range(length)\n\n        for j in rng:\n            dual_tmp = ranges[j].element()\n            dual_tmp = (g[j].convex_conj.proximal\n                        (stepsize * inner_stepsizes[j]\n                         if np.isscalar(inner_stepsizes[j])\n                         else stepsize * np.asarray(inner_stepsizes[j]))\n                        (duals[j] + stepsize * inner_stepsizes[j] * L[j](x)\n                         if np.isscalar(inner_stepsizes[j])\n                         else duals[j] + stepsize *\n                         np.asarray(inner_stepsizes[j]) * L[j](x)))\n            x -= 1.0 / stepsize * L[j].adjoint(dual_tmp - duals[j])\n            duals[j].assign(dual_tmp)", "response": "Non - optimized version of adupdates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a ParallelHoleCollimatorGeometry from a matrix.", "response": "def frommatrix(cls, apart, dpart, det_radius, init_matrix, **kwargs):\n        \"\"\"Create a `ParallelHoleCollimatorGeometry` using a matrix.\n\n        This alternative constructor uses a matrix to rotate and\n        translate the default configuration. It is most useful when\n        the transformation to be applied is already given as a matrix.\n\n        Parameters\n        ----------\n        apart : 1-dim. `RectPartition`\n            Partition of the parameter interval.\n        dpart : 2-dim. `RectPartition`\n            Partition of the detector parameter set.\n        det_radius : positive float\n            Radius of the circular detector orbit.\n        init_matrix : `array_like`, shape ``(3, 3)`` or ``(3, 4)``, optional\n            Transformation matrix whose left ``(3, 3)`` block is multiplied\n            with the default ``det_pos_init`` and ``det_axes_init`` to\n            determine the new vectors. If present, the fourth column acts\n            as a translation after the initial transformation.\n            The resulting ``det_axes_init`` will be normalized.\n        kwargs :\n            Further keyword arguments passed to the class constructor.\n\n        Returns\n        -------\n        geometry : `ParallelHoleCollimatorGeometry`\n            The resulting geometry.\n        \"\"\"\n        # Get transformation and translation parts from `init_matrix`\n        init_matrix = np.asarray(init_matrix, dtype=float)\n        if init_matrix.shape not in ((3, 3), (3, 4)):\n            raise ValueError('`matrix` must have shape (3, 3) or (3, 4), '\n                             'got array with shape {}'\n                             ''.format(init_matrix.shape))\n        trafo_matrix = init_matrix[:, :3]\n        translation = init_matrix[:, 3:].squeeze()\n\n        # Transform the default vectors\n        default_axis = cls._default_config['axis']\n        # Normalized version, just in case\n        default_orig_to_det_init = (\n            np.array(cls._default_config['det_pos_init'], dtype=float) /\n            np.linalg.norm(cls._default_config['det_pos_init']))\n        default_det_axes_init = cls._default_config['det_axes_init']\n        vecs_to_transform = ((default_orig_to_det_init,) +\n                             default_det_axes_init)\n        transformed_vecs = transform_system(\n            default_axis, None, vecs_to_transform, matrix=trafo_matrix)\n\n        # Use the standard constructor with these vectors\n        axis, orig_to_det, det_axis_0, det_axis_1 = transformed_vecs\n        if translation.size != 0:\n            kwargs['translation'] = translation\n\n        return cls(apart, dpart, det_radius, axis,\n                   orig_to_det_init=orig_to_det,\n                   det_axes_init=[det_axis_0, det_axis_1],\n                   **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _compute_nearest_weights_edge(idcs, ndist, variant):\n    # Get out-of-bounds indices from the norm_distances. Negative\n    # means \"too low\", larger than or equal to 1 means \"too high\"\n    lo = (ndist < 0)\n    hi = (ndist > 1)\n\n    # For \"too low\" nodes, the lower neighbor gets weight zero;\n    # \"too high\" gets 1.\n    if variant == 'left':\n        w_lo = np.where(ndist <= 0.5, 1.0, 0.0)\n    else:\n        w_lo = np.where(ndist < 0.5, 1.0, 0.0)\n\n    w_lo[lo] = 0\n    w_lo[hi] = 1\n\n    # For \"too high\" nodes, the upper neighbor gets weight zero;\n    # \"too low\" gets 1.\n    if variant == 'left':\n        w_hi = np.where(ndist <= 0.5, 0.0, 1.0)\n    else:\n        w_hi = np.where(ndist < 0.5, 0.0, 1.0)\n\n    w_hi[lo] = 1\n    w_hi[hi] = 0\n\n    # For upper/lower out-of-bounds nodes, we need to set the\n    # lower/upper neighbors to the last/first grid point\n    edge = [idcs, idcs + 1]\n    edge[0][hi] = -1\n    edge[1][lo] = 0\n\n    return w_lo, w_hi, edge", "response": "Helper function for nearest interpolation mimicing the linear case."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_linear_weights_edge(idcs, ndist):\n    # Get out-of-bounds indices from the norm_distances. Negative\n    # means \"too low\", larger than or equal to 1 means \"too high\"\n    lo = np.where(ndist < 0)\n    hi = np.where(ndist > 1)\n\n    # For \"too low\" nodes, the lower neighbor gets weight zero;\n    # \"too high\" gets 2 - yi (since yi >= 1)\n    w_lo = (1 - ndist)\n    w_lo[lo] = 0\n    w_lo[hi] += 1\n\n    # For \"too high\" nodes, the upper neighbor gets weight zero;\n    # \"too low\" gets 1 + yi (since yi < 0)\n    w_hi = np.copy(ndist)\n    w_hi[lo] += 1\n    w_hi[hi] = 0\n\n    # For upper/lower out-of-bounds nodes, we need to set the\n    # lower/upper neighbors to the last/first grid point\n    edge = [idcs, idcs + 1]\n    edge[0][hi] = -1\n    edge[1][lo] = 0\n\n    return w_lo, w_hi, edge", "response": "Helper for linear interpolation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall a function on the current object.", "response": "def _call(self, func, out=None, **kwargs):\n        \"\"\"Return ``self(func[, out, **kwargs])``.\"\"\"\n        mesh = self.grid.meshgrid\n        if out is None:\n            out = func(mesh, **kwargs)\n        else:\n            with writable_array(out) as out_arr:\n                func(mesh, out=out_arr, **kwargs)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x, out=None):\n        # TODO: pass reasonable options on to the interpolator\n        def nearest(arg, out=None):\n            \"\"\"Interpolating function with vectorization.\"\"\"\n            if is_valid_input_meshgrid(arg, self.grid.ndim):\n                input_type = 'meshgrid'\n            else:\n                input_type = 'array'\n\n            interpolator = _NearestInterpolator(\n                self.grid.coord_vectors, x, variant=self.variant,\n                input_type=input_type)\n\n            return interpolator(arg, out=out)\n\n        return self.range.element(nearest, vectorized=True)", "response": "Return the nearest element of the set of elements in x."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value of the object with vectorization.", "response": "def _call(self, x, out=None):\n        \"\"\"Return ``self(x[, out])``.\"\"\"\n        # TODO: pass reasonable options on to the interpolator\n        def linear(arg, out=None):\n            \"\"\"Interpolating function with vectorization.\"\"\"\n            if is_valid_input_meshgrid(arg, self.grid.ndim):\n                input_type = 'meshgrid'\n            else:\n                input_type = 'array'\n\n            interpolator = _LinearInterpolator(\n                self.grid.coord_vectors, x, input_type=input_type)\n\n            return interpolator(arg, out=out)\n\n        return self.range.element(linear, vectorized=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call(self, x, out=None):\n        def per_axis_interp(arg, out=None):\n            \"\"\"Interpolating function with vectorization.\"\"\"\n            if is_valid_input_meshgrid(arg, self.grid.ndim):\n                input_type = 'meshgrid'\n            else:\n                input_type = 'array'\n\n            interpolator = _PerAxisInterpolator(\n                self.grid.coord_vectors, x,\n                schemes=self.schemes, nn_variants=self.nn_variants,\n                input_type=input_type)\n\n            return interpolator(arg, out=out)\n\n        return self.range.element(per_axis_interp, vectorized=True)", "response": "Create an interpolator from grid values x."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_indices(self, x):\n        # find relevant edges between which xi are situated\n        index_vecs = []\n        # compute distance to lower edge in unity units\n        norm_distances = []\n\n        # iterate through dimensions\n        for xi, cvec in zip(x, self.coord_vecs):\n            idcs = np.searchsorted(cvec, xi) - 1\n\n            idcs[idcs < 0] = 0\n            idcs[idcs > cvec.size - 2] = cvec.size - 2\n            index_vecs.append(idcs)\n\n            norm_distances.append((xi - cvec[idcs]) /\n                                  (cvec[idcs + 1] - cvec[idcs]))\n\n        return index_vecs, norm_distances", "response": "Find indices and distances of the given nodes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _evaluate(self, indices, norm_distances, out=None):\n        # slice for broadcasting over trailing dimensions in self.values\n        vslice = (slice(None),) + (None,) * (self.values.ndim - len(indices))\n\n        if out is None:\n            out_shape = out_shape_from_meshgrid(norm_distances)\n            out_dtype = self.values.dtype\n            out = np.zeros(out_shape, dtype=out_dtype)\n        else:\n            out[:] = 0.0\n\n        # Weights and indices (per axis)\n        low_weights, high_weights, edge_indices = _create_weight_edge_lists(\n            indices, norm_distances, self.schemes, self.nn_variants)\n\n        # Iterate over all possible combinations of [i, i+1] for each\n        # axis, resulting in a loop of length 2**ndim\n        for lo_hi, edge in zip(product(*([['l', 'h']] * len(indices))),\n                               product(*edge_indices)):\n            weight = 1.0\n            # TODO: determine best summation order from array strides\n            for lh, w_lo, w_hi in zip(lo_hi, low_weights, high_weights):\n\n                # We don't multiply in-place to exploit the cheap operations\n                # in the beginning: sizes grow gradually as following:\n                # (n, 1, 1, ...) -> (n, m, 1, ...) -> ...\n                # Hence, it is faster to build up the weight array instead\n                # of doing full-size operations from the beginning.\n                if lh == 'l':\n                    weight = weight * w_lo\n                else:\n                    weight = weight * w_hi\n            out += np.asarray(self.values[edge]) * weight[vslice]\n        return np.array(out, copy=False, ndmin=1)", "response": "Evaluate linear interpolation.\n\n        Modified for in-place evaluation and treatment of out-of-bounds\n        points by implicitly assuming 0 at the next node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine if BLAS routines can be applied or not.", "response": "def _blas_is_applicable(*args):\n    \"\"\"Whether BLAS routines can be applied or not.\n\n    BLAS routines are available for single and double precision\n    float or complex data only. If the arrays are non-contiguous,\n    BLAS methods are usually slower, and array-writing routines do\n    not work at all. Hence, only contiguous arrays are allowed.\n\n    Parameters\n    ----------\n    x1,...,xN : `NumpyTensor`\n        The tensors to be tested for BLAS conformity.\n\n    Returns\n    -------\n    blas_is_applicable : bool\n        ``True`` if all mentioned requirements are met, ``False`` otherwise.\n    \"\"\"\n    if any(x.dtype != args[0].dtype for x in args[1:]):\n        return False\n    elif any(x.dtype not in _BLAS_DTYPES for x in args):\n        return False\n    elif not (all(x.flags.f_contiguous for x in args) or\n              all(x.flags.c_contiguous for x in args)):\n        return False\n    elif any(x.size > np.iinfo('int32').max for x in args):\n        # Temporary fix for 32 bit int overflow in BLAS\n        # TODO: use chunking instead\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noptimize implementation of ``out[:] = a * x1 + b * x2``.", "response": "def _lincomb_impl(a, x1, b, x2, out):\n    \"\"\"Optimized implementation of ``out[:] = a * x1 + b * x2``.\"\"\"\n    # Lazy import to improve `import odl` time\n    import scipy.linalg\n\n    size = native(x1.size)\n\n    if size < THRESHOLD_SMALL:\n        # Faster for small arrays\n        out.data[:] = a * x1.data + b * x2.data\n        return\n\n    elif (size < THRESHOLD_MEDIUM or\n          not _blas_is_applicable(x1.data, x2.data, out.data)):\n\n        def fallback_axpy(x1, x2, n, a):\n            \"\"\"Fallback axpy implementation avoiding copy.\"\"\"\n            if a != 0:\n                x2 /= a\n                x2 += x1\n                x2 *= a\n            return x2\n\n        def fallback_scal(a, x, n):\n            \"\"\"Fallback scal implementation.\"\"\"\n            x *= a\n            return x\n\n        def fallback_copy(x1, x2, n):\n            \"\"\"Fallback copy implementation.\"\"\"\n            x2[...] = x1[...]\n            return x2\n\n        axpy, scal, copy = (fallback_axpy, fallback_scal, fallback_copy)\n        x1_arr = x1.data\n        x2_arr = x2.data\n        out_arr = out.data\n\n    else:\n        # Need flat data for BLAS, otherwise in-place does not work.\n        # Raveling must happen in fixed order for non-contiguous out,\n        # otherwise 'A' is applied to arrays, which makes the outcome\n        # dependent on their respective contiguousness.\n        if out.data.flags.f_contiguous:\n            ravel_order = 'F'\n        else:\n            ravel_order = 'C'\n\n        x1_arr = x1.data.ravel(order=ravel_order)\n        x2_arr = x2.data.ravel(order=ravel_order)\n        out_arr = out.data.ravel(order=ravel_order)\n        axpy, scal, copy = scipy.linalg.blas.get_blas_funcs(\n            ['axpy', 'scal', 'copy'], arrays=(x1_arr, x2_arr, out_arr))\n\n    if x1 is x2 and b != 0:\n        # x1 is aligned with x2 -> out = (a+b)*x1\n        _lincomb_impl(a + b, x1, 0, x1, out)\n    elif out is x1 and out is x2:\n        # All the vectors are aligned -> out = (a+b)*out\n        if (a + b) != 0:\n            scal(a + b, out_arr, size)\n        else:\n            out_arr[:] = 0\n    elif out is x1:\n        # out is aligned with x1 -> out = a*out + b*x2\n        if a != 1:\n            scal(a, out_arr, size)\n        if b != 0:\n            axpy(x2_arr, out_arr, size, b)\n    elif out is x2:\n        # out is aligned with x2 -> out = a*x1 + b*out\n        if b != 1:\n            scal(b, out_arr, size)\n        if a != 0:\n            axpy(x1_arr, out_arr, size, a)\n    else:\n        # We have exhausted all alignment options, so x1 is not x2 is not out\n        # We now optimize for various values of a and b\n        if b == 0:\n            if a == 0:  # Zero assignment -> out = 0\n                out_arr[:] = 0\n            else:  # Scaled copy -> out = a*x1\n                copy(x1_arr, out_arr, size)\n                if a != 1:\n                    scal(a, out_arr, size)\n\n        else:  # b != 0\n            if a == 0:  # Scaled copy -> out = b*x2\n                copy(x2_arr, out_arr, size)\n                if b != 1:\n                    scal(b, out_arr, size)\n\n            elif a == 1:  # No scaling in x1 -> out = x1 + b*x2\n                copy(x1_arr, out_arr, size)\n                axpy(x2_arr, out_arr, size, b)\n            else:  # Generic case -> out = a*x1 + b*x2\n                copy(x2_arr, out_arr, size)\n                if b != 1:\n                    scal(b, out_arr, size)\n                axpy(x1_arr, out_arr, size, a)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a weighting whose type is inferred from the arguments.", "response": "def _weighting(weights, exponent):\n    \"\"\"Return a weighting whose type is inferred from the arguments.\"\"\"\n    if np.isscalar(weights):\n        weighting = NumpyTensorSpaceConstWeighting(weights, exponent)\n    elif weights is None:\n        weighting = NumpyTensorSpaceConstWeighting(1.0, exponent)\n    else:  # last possibility: make an array\n        arr = np.asarray(weights)\n        weighting = NumpyTensorSpaceArrayWeighting(arr, exponent)\n    return weighting"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _norm_default(x):\n    # Lazy import to improve `import odl` time\n    import scipy.linalg\n\n    if _blas_is_applicable(x.data):\n        nrm2 = scipy.linalg.blas.get_blas_funcs('nrm2', dtype=x.dtype)\n        norm = partial(nrm2, n=native(x.size))\n    else:\n        norm = np.linalg.norm\n    return norm(x.data.ravel())", "response": "Default Euclidean norm implementation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefaults p - norm implementation.", "response": "def _pnorm_default(x, p):\n    \"\"\"Default p-norm implementation.\"\"\"\n    return np.linalg.norm(x.data.ravel(), ord=p)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pnorm_diagweight(x, p, w):\n    # Ravel both in the same order (w is a numpy array)\n    order = 'F' if all(a.flags.f_contiguous for a in (x.data, w)) else 'C'\n\n    # This is faster than first applying the weights and then summing with\n    # BLAS dot or nrm2\n    xp = np.abs(x.data.ravel(order))\n    if p == float('inf'):\n        xp *= w.ravel(order)\n        return np.max(xp)\n    else:\n        xp = np.power(xp, p, out=xp)\n        xp *= w.ravel(order)\n        return np.sum(xp) ** (1 / p)", "response": "Diagonally weighted p - norm implementation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefaults Euclidean inner product implementation.", "response": "def _inner_default(x1, x2):\n    \"\"\"Default Euclidean inner product implementation.\"\"\"\n    # Ravel both in the same order\n    order = 'F' if all(a.data.flags.f_contiguous for a in (x1, x2)) else 'C'\n\n    if is_real_dtype(x1.dtype):\n        if x1.size > THRESHOLD_MEDIUM:\n            # This is as fast as BLAS dotc\n            return np.tensordot(x1, x2, [range(x1.ndim)] * 2)\n        else:\n            # Several times faster for small arrays\n            return np.dot(x1.data.ravel(order),\n                          x2.data.ravel(order))\n    else:\n        # x2 as first argument because we want linearity in x1\n        return np.vdot(x2.data.ravel(order),\n                       x1.data.ravel(order))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element(self, inp=None, data_ptr=None, order=None):\n        if order is not None and str(order).upper() not in ('C', 'F'):\n            raise ValueError(\"`order` {!r} not understood\".format(order))\n\n        if inp is None and data_ptr is None:\n            if order is None:\n                arr = np.empty(self.shape, dtype=self.dtype,\n                               order=self.default_order)\n            else:\n                arr = np.empty(self.shape, dtype=self.dtype, order=order)\n\n            return self.element_type(self, arr)\n\n        elif inp is None and data_ptr is not None:\n            if order is None:\n                raise ValueError('`order` cannot be None for element '\n                                 'creation from pointer')\n\n            ctype_array_def = ctypes.c_byte * self.nbytes\n            as_ctype_array = ctype_array_def.from_address(data_ptr)\n            as_numpy_array = np.ctypeslib.as_array(as_ctype_array)\n            arr = as_numpy_array.view(dtype=self.dtype)\n            arr = arr.reshape(self.shape, order=order)\n            return self.element_type(self, arr)\n\n        elif inp is not None and data_ptr is None:\n            if inp in self and order is None:\n                # Short-circuit for space elements and no enforced ordering\n                return inp\n\n            # Try to not copy but require dtype and order if given\n            # (`order=None` is ok as np.array argument)\n            arr = np.array(inp, copy=False, dtype=self.dtype, ndmin=self.ndim,\n                           order=order)\n            # Make sure the result is writeable, if not make copy.\n            # This happens for e.g. results of `np.broadcast_to()`.\n            if not arr.flags.writeable:\n                arr = arr.copy()\n            if arr.shape != self.shape:\n                raise ValueError('shape of `inp` not equal to space shape: '\n                                 '{} != {}'.format(arr.shape, self.shape))\n            return self.element_type(self, arr)\n\n        else:\n            raise TypeError('cannot provide both `inp` and `data_ptr`')", "response": "Create a new element from an array - like input."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tensor of all zeros.", "response": "def zero(self):\n        \"\"\"Return a tensor of all zeros.\n\n        Examples\n        --------\n        >>> space = odl.rn(3)\n        >>> x = space.zero()\n        >>> x\n        rn(3).element([ 0.,  0.,  0.])\n        \"\"\"\n        return self.element(np.zeros(self.shape, dtype=self.dtype,\n                                     order=self.default_order))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef one(self):\n        return self.element(np.ones(self.shape, dtype=self.dtype,\n                                    order=self.default_order))", "response": "Return a tensor of all ones."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef available_dtypes():\n        all_dtypes = []\n        for lst in np.sctypes.values():\n            for dtype in lst:\n                if dtype not in (np.object, np.void):\n                    all_dtypes.append(np.dtype(dtype))\n        # Need to add these manually since np.sctypes['others'] will only\n        # contain one of them (depending on Python version)\n        all_dtypes.extend([np.dtype('S'), np.dtype('U')])\n        return tuple(sorted(set(all_dtypes)))", "response": "Return the set of data types available in this implementation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default_dtype(field=None):\n        if field is None or field == RealNumbers():\n            return np.dtype('float64')\n        elif field == ComplexNumbers():\n            return np.dtype('complex128')\n        else:\n            raise ValueError('no default data type defined for field {}'\n                             ''.format(field))", "response": "Return the default data type of this class for a given field."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements the linear combination of x1 and x2.", "response": "def _lincomb(self, a, x1, b, x2, out):\n        \"\"\"Implement the linear combination of ``x1`` and ``x2``.\n\n        Compute ``out = a*x1 + b*x2`` using optimized\n        BLAS routines if possible.\n\n        This function is part of the subclassing API. Do not\n        call it directly.\n\n        Parameters\n        ----------\n        a, b : `TensorSpace.field` element\n            Scalars to multiply ``x1`` and ``x2`` with.\n        x1, x2 : `NumpyTensor`\n            Summands in the linear combination.\n        out : `NumpyTensor`\n            Tensor to which the result is written.\n\n        Examples\n        --------\n        >>> space = odl.rn(3)\n        >>> x = space.element([0, 1, 1])\n        >>> y = space.element([0, 0, 1])\n        >>> out = space.element()\n        >>> result = space.lincomb(1, x, 2, y, out)\n        >>> result\n        rn(3).element([ 0.,  1.,  3.])\n        >>> result is out\n        True\n        \"\"\"\n        _lincomb_impl(a, x1, b, x2, out)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the entry-wise product ``out = x1 * x2``. This function is part of the subclassing API. Do not call it directly. Parameters ---------- x1, x2 : `NumpyTensor` Factors in the product. out : `NumpyTensor` Element to which the result is written. Examples -------- >>> space = odl.rn(3) >>> x = space.element([1, 0, 3]) >>> y = space.element([-1, 1, -1]) >>> space.multiply(x, y) rn(3).element([-1., 0., -3.]) >>> out = space.element() >>> result = space.multiply(x, y, out=out) >>> result rn(3).element([-1., 0., -3.]) >>> result is out True", "response": "def _multiply(self, x1, x2, out):\n        \"\"\"Compute the entry-wise product ``out = x1 * x2``.\n\n        This function is part of the subclassing API. Do not\n        call it directly.\n\n        Parameters\n        ----------\n        x1, x2 : `NumpyTensor`\n            Factors in the product.\n        out : `NumpyTensor`\n            Element to which the result is written.\n\n        Examples\n        --------\n        >>> space = odl.rn(3)\n        >>> x = space.element([1, 0, 3])\n        >>> y = space.element([-1, 1, -1])\n        >>> space.multiply(x, y)\n        rn(3).element([-1.,  0., -3.])\n        >>> out = space.element()\n        >>> result = space.multiply(x, y, out=out)\n        >>> result\n        rn(3).element([-1.,  0., -3.])\n        >>> result is out\n        True\n        \"\"\"\n        np.multiply(x1.data, x2.data, out=out.data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _divide(self, x1, x2, out):\n        np.divide(x1.data, x2.data, out=out.data)", "response": "Compute the entry - wise quotient x1 and x2 and write the result to out."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new NpyTensorSpace object indexed along one or several dimensions.", "response": "def byaxis(self):\n        \"\"\"Return the subspace defined along one or several dimensions.\n\n        Examples\n        --------\n        Indexing with integers or slices:\n\n        >>> space = odl.rn((2, 3, 4))\n        >>> space.byaxis[0]\n        rn(2)\n        >>> space.byaxis[1:]\n        rn((3, 4))\n\n        Lists can be used to stack spaces arbitrarily:\n\n        >>> space.byaxis[[2, 1, 2]]\n        rn((4, 3, 4))\n        \"\"\"\n        space = self\n\n        class NpyTensorSpacebyaxis(object):\n\n            \"\"\"Helper class for indexing by axis.\"\"\"\n\n            def __getitem__(self, indices):\n                \"\"\"Return ``self[indices]``.\"\"\"\n                try:\n                    iter(indices)\n                except TypeError:\n                    newshape = space.shape[indices]\n                else:\n                    newshape = tuple(space.shape[i] for i in indices)\n\n                if isinstance(space.weighting, ArrayWeighting):\n                    new_array = np.asarray(space.weighting.array[indices])\n                    weighting = NumpyTensorSpaceArrayWeighting(\n                        new_array, space.weighting.exponent)\n                else:\n                    weighting = space.weighting\n\n                return type(space)(newshape, space.dtype, weighting=weighting)\n\n            def __repr__(self):\n                \"\"\"Return ``repr(self)``.\"\"\"\n                return repr(space) + '.byaxis'\n\n        return NpyTensorSpacebyaxis()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the data of this array as a numpy. ndarray.", "response": "def asarray(self, out=None):\n        \"\"\"Extract the data of this array as a ``numpy.ndarray``.\n\n        This method is invoked when calling `numpy.asarray` on this\n        tensor.\n\n        Parameters\n        ----------\n        out : `numpy.ndarray`, optional\n            Array in which the result should be written in-place.\n            Has to be contiguous and of the correct dtype.\n\n        Returns\n        -------\n        asarray : `numpy.ndarray`\n            Numpy array with the same data type as ``self``. If\n            ``out`` was given, the returned object is a reference\n            to it.\n\n        Examples\n        --------\n        >>> space = odl.rn(3, dtype='float32')\n        >>> x = space.element([1, 2, 3])\n        >>> x.asarray()\n        array([ 1.,  2.,  3.], dtype=float32)\n        >>> np.asarray(x) is x.asarray()\n        True\n        >>> out = np.empty(3, dtype='float32')\n        >>> result = x.asarray(out=out)\n        >>> out\n        array([ 1.,  2.,  3.], dtype=float32)\n        >>> result is out\n        True\n        >>> space = odl.rn((2, 3))\n        >>> space.one().asarray()\n        array([[ 1.,  1.,  1.],\n               [ 1.,  1.,  1.]])\n        \"\"\"\n        if out is None:\n            return self.data\n        else:\n            out[:] = self.data\n            return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef astype(self, dtype):\n        return self.space.astype(dtype).element(self.data.astype(dtype))", "response": "Return a copy of this element with new dtype."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the imaginary part of the avec.", "response": "def imag(self):\n        \"\"\"Imaginary part of ``self``.\n\n        Returns\n        -------\n        imag : `NumpyTensor`\n            Imaginary part this element as an element of a\n            `NumpyTensorSpace` with real data type.\n\n        Examples\n        --------\n        Get the imaginary part:\n\n        >>> space = odl.cn(3)\n        >>> x = space.element([1 + 1j, 2, 3 - 3j])\n        >>> x.imag\n        rn(3).element([ 1.,  0., -3.])\n\n        Set the imaginary part:\n\n        >>> space = odl.cn(3)\n        >>> x = space.element([1 + 1j, 2, 3 - 3j])\n        >>> zero = odl.rn(3).zero()\n        >>> x.imag = zero\n        >>> x\n        cn(3).element([ 1.+0.j,  2.+0.j,  3.+0.j])\n\n        Other array-like types and broadcasting:\n\n        >>> x.imag = 1.0\n        >>> x\n        cn(3).element([ 1.+1.j,  2.+1.j,  3.+1.j])\n        >>> x.imag = [2, 3, 4]\n        >>> x\n        cn(3).element([ 1.+2.j,  2.+3.j,  3.+4.j])\n        \"\"\"\n        if self.space.is_real:\n            return self.space.zero()\n        elif self.space.is_complex:\n            real_space = self.space.astype(self.space.real_dtype)\n            return real_space.element(self.data.imag)\n        else:\n            raise NotImplementedError('`imag` not defined for non-numeric '\n                                      'dtype {}'.format(self.dtype))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef imag(self, newimag):\n        if self.space.is_real:\n            raise ValueError('cannot set imaginary part in real spaces')\n        self.imag.data[:] = newimag", "response": "Setter for the imaginary part of this element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef conj(self, out=None):\n        if self.space.is_real:\n            if out is None:\n                return self\n            else:\n                out[:] = self\n                return out\n\n        if not is_numeric_dtype(self.space.dtype):\n            raise NotImplementedError('`conj` not defined for non-numeric '\n                                      'dtype {}'.format(self.dtype))\n\n        if out is None:\n            return self.space.element(self.data.conj())\n        else:\n            if out not in self.space:\n                raise LinearSpaceTypeError('`out` {!r} not in space {!r}'\n                                           ''.format(out, self.space))\n            self.data.conj(out.data)\n            return out", "response": "Return the complex conjugate of self."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the weighted inner product of x1 and x2.", "response": "def inner(self, x1, x2):\n        \"\"\"Return the weighted inner product of ``x1`` and ``x2``.\n\n        Parameters\n        ----------\n        x1, x2 : `NumpyTensor`\n            Tensors whose inner product is calculated.\n\n        Returns\n        -------\n        inner : float or complex\n            The inner product of the two provided vectors.\n        \"\"\"\n        if self.exponent != 2.0:\n            raise NotImplementedError('no inner product defined for '\n                                      'exponent != 2 (got {})'\n                                      ''.format(self.exponent))\n        else:\n            inner = _inner_default(x1 * self.array, x2)\n            if is_real_dtype(x1.dtype):\n                return float(inner)\n            else:\n                return complex(inner)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef norm(self, x):\n        if self.exponent == 2.0:\n            norm_squared = self.inner(x, x).real  # TODO: optimize?!\n            if norm_squared < 0:\n                norm_squared = 0.0  # Compensate for numerical error\n            return float(np.sqrt(norm_squared))\n        else:\n            return float(_pnorm_diagweight(x, self.exponent, self.array))", "response": "Return the weighted norm of x."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the weighted inner product of x1 and x2.", "response": "def inner(self, x1, x2):\n        \"\"\"Return the weighted inner product of ``x1`` and ``x2``.\n\n        Parameters\n        ----------\n        x1, x2 : `NumpyTensor`\n            Tensors whose inner product is calculated.\n\n        Returns\n        -------\n        inner : float or complex\n            The inner product of the two provided tensors.\n        \"\"\"\n        if self.exponent != 2.0:\n            raise NotImplementedError('no inner product defined for '\n                                      'exponent != 2 (got {})'\n                                      ''.format(self.exponent))\n        else:\n            inner = self.const * _inner_default(x1, x2)\n            if x1.space.field is None:\n                return inner\n            else:\n                return x1.space.field.element(inner)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the weighted norm of x.", "response": "def norm(self, x):\n        \"\"\"Return the weighted norm of ``x``.\n\n        Parameters\n        ----------\n        x1 : `NumpyTensor`\n            Tensor whose norm is calculated.\n\n        Returns\n        -------\n        norm : float\n            The norm of the tensor.\n        \"\"\"\n        if self.exponent == 2.0:\n            return float(np.sqrt(self.const) * _norm_default(x))\n        elif self.exponent == float('inf'):\n            return float(self.const * _pnorm_default(x, self.exponent))\n        else:\n            return float((self.const ** (1 / self.exponent) *\n                          _pnorm_default(x, self.exponent)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dist(self, x1, x2):\n        if self.exponent == 2.0:\n            return float(np.sqrt(self.const) * _norm_default(x1 - x2))\n        elif self.exponent == float('inf'):\n            return float(self.const * _pnorm_default(x1 - x2, self.exponent))\n        else:\n            return float((self.const ** (1 / self.exponent) *\n                          _pnorm_default(x1 - x2, self.exponent)))", "response": "Return the weighted distance between x1 and x2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(self):\n        import tqdm\n        self.iter = 0\n        self.pbar = tqdm.tqdm(total=self.niter, **self.kwargs)", "response": "Reset iterator to 0."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nissue a matplotlib pause without the warning.", "response": "def warning_free_pause():\n    \"\"\"Issue a matplotlib pause without the warning.\"\"\"\n    import matplotlib.pyplot as plt\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\",\n                                message=\"Using default event loop until \"\n                                        \"function specific to this GUI is \"\n                                        \"implemented\")\n        plt.pause(0.0001)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate min and max of array with guards for nan and inf.", "response": "def _safe_minmax(values):\n    \"\"\"Calculate min and max of array with guards for nan and inf.\"\"\"\n\n    # Nan and inf guarded min and max\n    isfinite = np.isfinite(values)\n    if np.any(isfinite):\n        # Only use finite values\n        values = values[isfinite]\n\n    minval = np.min(values)\n    maxval = np.max(values)\n\n    return minval, maxval"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the ticks in the colorbar.", "response": "def _colorbar_ticks(minval, maxval):\n    \"\"\"Return the ticks (values show) in the colorbar.\"\"\"\n    if not (np.isfinite(minval) and np.isfinite(maxval)):\n        return [0, 0, 0]\n    elif minval == maxval:\n        return [minval]\n    else:\n        # Add eps to ensure values stay inside the range of the colorbar.\n        # Otherwise they may occationally not display.\n        eps = (maxval - minval) / 1e5\n        return [minval + eps, (maxval + minval) / 2., maxval - eps]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _digits(minval, maxval):\n    if minval == maxval:\n        return 3\n    else:\n        return min(10, max(2, int(1 + abs(np.log10(maxval - minval)))))", "response": "Returns the number of digits needed to comforatbly display values in minval and maxval"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _colorbar_format(minval, maxval):\n    if not (np.isfinite(minval) and np.isfinite(maxval)):\n        return str(maxval)\n    else:\n        return '%.{}f'.format(_digits(minval, maxval))", "response": "Return the format string for the colorbar."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay a discrete 1d or 2d function.", "response": "def show_discrete_data(values, grid, title=None, method='',\n                       force_show=False, fig=None, **kwargs):\n    \"\"\"Display a discrete 1d or 2d function.\n\n    Parameters\n    ----------\n    values : `numpy.ndarray`\n        The values to visualize.\n\n    grid : `RectGrid` or `RectPartition`\n        Grid of the values.\n\n    title : string, optional\n        Set the title of the figure.\n\n    method : string, optional\n        1d methods:\n\n        'plot' : graph plot\n\n        'scatter' : scattered 2d points\n        (2nd axis <-> value)\n\n        2d methods:\n\n        'imshow' : image plot with coloring according to value,\n        including a colorbar.\n\n        'scatter' : cloud of scattered 3d points\n        (3rd axis <-> value)\n\n        'wireframe', 'plot_wireframe' : surface plot\n\n    force_show : bool, optional\n        Whether the plot should be forced to be shown now or deferred until\n        later. Note that some backends always displays the plot, regardless\n        of this value.\n\n    fig : `matplotlib.figure.Figure`, optional\n        The figure to show in. Expected to be of same \"style\", as the figure\n        given by this function. The most common usecase is that fig is the\n        return value from an earlier call to this function.\n        Default: New figure\n\n    interp : {'nearest', 'linear'}, optional\n        Interpolation method to use.\n        Default: 'nearest'\n\n    axis_labels : string, optional\n        Axis labels, default: ['x', 'y']\n\n    update_in_place : bool, optional\n        Update the content of the figure in-place. Intended for faster real\n        time plotting, typically ~5 times faster.\n        This is only performed for ``method == 'imshow'`` with real data and\n        ``fig != None``. Otherwise this parameter is treated as False.\n        Default: False\n\n    axis_fontsize : int, optional\n        Fontsize for the axes. Default: 16\n\n    colorbar : bool, optional\n        Argument relevant for 2d plots using ``method='imshow'``. If ``True``,\n        include a colorbar in the plot.\n        Default: True\n\n    kwargs : {'figsize', 'saveto', ...}, optional\n        Extra keyword arguments passed on to display method\n        See the Matplotlib functions for documentation of extra\n        options.\n\n    Returns\n    -------\n    fig : `matplotlib.figure.Figure`\n        The resulting figure. It is also shown to the user.\n\n    See Also\n    --------\n    matplotlib.pyplot.plot : Show graph plot\n\n    matplotlib.pyplot.imshow : Show data as image\n\n    matplotlib.pyplot.scatter : Show scattered 3d points\n    \"\"\"\n    # Importing pyplot takes ~2 sec, only import when needed.\n    import matplotlib.pyplot as plt\n\n    args_re = []\n    args_im = []\n    dsp_kwargs = {}\n    sub_kwargs = {}\n    arrange_subplots = (121, 122)  # horzontal arrangement\n\n    # Create axis labels which remember their original meaning\n    axis_labels = kwargs.pop('axis_labels', ['x', 'y'])\n\n    values_are_complex = not is_real_dtype(values.dtype)\n    figsize = kwargs.pop('figsize', None)\n    saveto = kwargs.pop('saveto', None)\n    interp = kwargs.pop('interp', 'nearest')\n    axis_fontsize = kwargs.pop('axis_fontsize', 16)\n    colorbar = kwargs.pop('colorbar', True)\n\n    # Normalize input\n    interp, interp_in = str(interp).lower(), interp\n    method, method_in = str(method).lower(), method\n\n    # Check if we should and can update the plot in-place\n    update_in_place = kwargs.pop('update_in_place', False)\n    if (update_in_place and\n            (fig is None or values_are_complex or values.ndim != 2 or\n             (values.ndim == 2 and method not in ('', 'imshow')))):\n        update_in_place = False\n\n    if values.ndim == 1:  # TODO: maybe a plotter class would be better\n        if not method:\n            if interp == 'nearest':\n                method = 'step'\n                dsp_kwargs['where'] = 'mid'\n            elif interp == 'linear':\n                method = 'plot'\n            else:\n                raise ValueError('`interp` {!r} not supported'\n                                 ''.format(interp_in))\n\n        if method == 'plot' or method == 'step' or method == 'scatter':\n            args_re += [grid.coord_vectors[0], values.real]\n            args_im += [grid.coord_vectors[0], values.imag]\n        else:\n            raise ValueError('`method` {!r} not supported'\n                             ''.format(method_in))\n\n    elif values.ndim == 2:\n        if not method:\n            method = 'imshow'\n\n        if method == 'imshow':\n            args_re = [np.rot90(values.real)]\n            args_im = [np.rot90(values.imag)] if values_are_complex else []\n\n            extent = [grid.min()[0], grid.max()[0],\n                      grid.min()[1], grid.max()[1]]\n\n            if interp == 'nearest':\n                interpolation = 'nearest'\n            elif interp == 'linear':\n                interpolation = 'bilinear'\n            else:\n                raise ValueError('`interp` {!r} not supported'\n                                 ''.format(interp_in))\n\n            dsp_kwargs.update({'interpolation': interpolation,\n                               'cmap': 'bone',\n                               'extent': extent,\n                               'aspect': 'auto'})\n        elif method == 'scatter':\n            pts = grid.points()\n            args_re = [pts[:, 0], pts[:, 1], values.ravel().real]\n            args_im = ([pts[:, 0], pts[:, 1], values.ravel().imag]\n                       if values_are_complex else [])\n            sub_kwargs.update({'projection': '3d'})\n        elif method in ('wireframe', 'plot_wireframe'):\n            method = 'plot_wireframe'\n            x, y = grid.meshgrid\n            args_re = [x, y, np.rot90(values.real)]\n            args_im = ([x, y, np.rot90(values.imag)] if values_are_complex\n                       else [])\n            sub_kwargs.update({'projection': '3d'})\n        else:\n            raise ValueError('`method` {!r} not supported'\n                             ''.format(method_in))\n\n    else:\n        raise NotImplementedError('no method for {}d display implemented'\n                                  ''.format(values.ndim))\n\n    # Additional keyword args are passed on to the display method\n    dsp_kwargs.update(**kwargs)\n\n    if fig is not None:\n        # Reuse figure if given as input\n        if not isinstance(fig, plt.Figure):\n            raise TypeError('`fig` {} not a matplotlib figure'.format(fig))\n\n        if not plt.fignum_exists(fig.number):\n            # If figure does not exist, user either closed the figure or\n            # is using IPython, in this case we need a new figure.\n\n            fig = plt.figure(figsize=figsize)\n            updatefig = False\n        else:\n            # Set current figure to given input\n            fig = plt.figure(fig.number)\n            updatefig = True\n\n            if values.ndim > 1 and not update_in_place:\n                # If the figure is larger than 1d, we can clear it since we\n                # dont reuse anything. Keeping it causes performance problems.\n                fig.clf()\n    else:\n        fig = plt.figure(figsize=figsize)\n        updatefig = False\n\n    if values_are_complex:\n        # Real\n        if len(fig.axes) == 0:\n            # Create new axis if needed\n            sub_re = plt.subplot(arrange_subplots[0], **sub_kwargs)\n            sub_re.set_title('Real part')\n            sub_re.set_xlabel(axis_labels[0], fontsize=axis_fontsize)\n            if values.ndim == 2:\n                sub_re.set_ylabel(axis_labels[1], fontsize=axis_fontsize)\n            else:\n                sub_re.set_ylabel('value')\n        else:\n            sub_re = fig.axes[0]\n\n        display_re = getattr(sub_re, method)\n        csub_re = display_re(*args_re, **dsp_kwargs)\n\n        # Axis ticks\n        if method == 'imshow' and not grid.is_uniform:\n            (xpts, xlabels), (ypts, ylabels) = _axes_info(grid)\n            plt.xticks(xpts, xlabels)\n            plt.yticks(ypts, ylabels)\n\n        if method == 'imshow' and len(fig.axes) < 2:\n            # Create colorbar if none seems to exist\n\n            # Use clim from kwargs if given\n            if 'clim' not in kwargs:\n                minval_re, maxval_re = _safe_minmax(values.real)\n            else:\n                minval_re, maxval_re = kwargs['clim']\n\n            ticks_re = _colorbar_ticks(minval_re, maxval_re)\n            fmt_re = _colorbar_format(minval_re, maxval_re)\n\n            plt.colorbar(csub_re, orientation='horizontal',\n                         ticks=ticks_re, format=fmt_re)\n\n        # Imaginary\n        if len(fig.axes) < 3:\n            sub_im = plt.subplot(arrange_subplots[1], **sub_kwargs)\n            sub_im.set_title('Imaginary part')\n            sub_im.set_xlabel(axis_labels[0], fontsize=axis_fontsize)\n            if values.ndim == 2:\n                sub_im.set_ylabel(axis_labels[1], fontsize=axis_fontsize)\n            else:\n                sub_im.set_ylabel('value')\n        else:\n            sub_im = fig.axes[2]\n\n        display_im = getattr(sub_im, method)\n        csub_im = display_im(*args_im, **dsp_kwargs)\n\n        # Axis ticks\n        if method == 'imshow' and not grid.is_uniform:\n            (xpts, xlabels), (ypts, ylabels) = _axes_info(grid)\n            plt.xticks(xpts, xlabels)\n            plt.yticks(ypts, ylabels)\n\n        if method == 'imshow' and len(fig.axes) < 4:\n            # Create colorbar if none seems to exist\n\n            # Use clim from kwargs if given\n            if 'clim' not in kwargs:\n                minval_im, maxval_im = _safe_minmax(values.imag)\n            else:\n                minval_im, maxval_im = kwargs['clim']\n\n            ticks_im = _colorbar_ticks(minval_im, maxval_im)\n            fmt_im = _colorbar_format(minval_im, maxval_im)\n\n            plt.colorbar(csub_im, orientation='horizontal',\n                         ticks=ticks_im, format=fmt_im)\n\n    else:\n        if len(fig.axes) == 0:\n            # Create new axis object if needed\n            sub = plt.subplot(111, **sub_kwargs)\n            sub.set_xlabel(axis_labels[0], fontsize=axis_fontsize)\n            if values.ndim == 2:\n                sub.set_ylabel(axis_labels[1], fontsize=axis_fontsize)\n            else:\n                sub.set_ylabel('value')\n            try:\n                # For 3d plots\n                sub.set_zlabel('z')\n            except AttributeError:\n                pass\n        else:\n            sub = fig.axes[0]\n\n        if update_in_place:\n            import matplotlib as mpl\n            imgs = [obj for obj in sub.get_children()\n                    if isinstance(obj, mpl.image.AxesImage)]\n            if len(imgs) > 0 and updatefig:\n                imgs[0].set_data(args_re[0])\n                csub = imgs[0]\n\n                # Update min-max\n                if 'clim' not in kwargs:\n                    minval, maxval = _safe_minmax(values)\n                else:\n                    minval, maxval = kwargs['clim']\n\n                csub.set_clim(minval, maxval)\n            else:\n                display = getattr(sub, method)\n                csub = display(*args_re, **dsp_kwargs)\n        else:\n            display = getattr(sub, method)\n            csub = display(*args_re, **dsp_kwargs)\n\n        # Axis ticks\n        if method == 'imshow' and not grid.is_uniform:\n            (xpts, xlabels), (ypts, ylabels) = _axes_info(grid)\n            plt.xticks(xpts, xlabels)\n            plt.yticks(ypts, ylabels)\n\n        if method == 'imshow' and colorbar:\n            # Add colorbar\n            # Use clim from kwargs if given\n            if 'clim' not in kwargs:\n                minval, maxval = _safe_minmax(values)\n            else:\n                minval, maxval = kwargs['clim']\n\n            ticks = _colorbar_ticks(minval, maxval)\n            fmt = _colorbar_format(minval, maxval)\n            if len(fig.axes) < 2:\n                # Create colorbar if none seems to exist\n                plt.colorbar(mappable=csub, ticks=ticks, format=fmt)\n            elif update_in_place:\n                # If it exists and we should update it\n                csub.colorbar.set_clim(minval, maxval)\n                csub.colorbar.set_ticks(ticks)\n                if '%' not in fmt:\n                    labels = [fmt] * len(ticks)\n                else:\n                    labels = [fmt % t for t in ticks]\n                csub.colorbar.set_ticklabels(labels)\n                csub.colorbar.draw_all()\n\n    # Set title of window\n    if title is not None:\n        if not values_are_complex:\n            # Do not overwrite title for complex values\n            plt.title(title)\n        fig.canvas.manager.set_window_title(title)\n\n    # Fixes overlapping stuff at the expense of potentially squashed subplots\n    if not update_in_place:\n        fig.tight_layout()\n\n    if updatefig or plt.isinteractive():\n        # If we are running in interactive mode, we can always show the fig\n        # This causes an artifact, where users of `CallbackShow` without\n        # interactive mode only shows the figure after the second iteration.\n        plt.show(block=False)\n        if not update_in_place:\n            plt.draw()\n            warning_free_pause()\n        else:\n            try:\n                sub.draw_artist(csub)\n                fig.canvas.blit(fig.bbox)\n                fig.canvas.update()\n                fig.canvas.flush_events()\n            except AttributeError:\n                plt.draw()\n                warning_free_pause()\n\n    if force_show:\n        plt.show()\n\n    if saveto is not None:\n        fig.savefig(saveto)\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports all submodules of a module.", "response": "def import_submodules(package, name=None, recursive=True):\n    \"\"\"Import all submodules of ``package``.\n\n    Parameters\n    ----------\n    package : `module` or string\n        Package whose submodules to import.\n    name : string, optional\n        Override the package name with this value in the full\n        submodule names. By default, ``package`` is used.\n    recursive : bool, optional\n        If ``True``, recursively import all submodules of ``package``.\n        Otherwise, import only the modules at the top level.\n\n    Returns\n    -------\n    pkg_dict : dict\n        Dictionary where keys are the full submodule names and values\n        are the corresponding module objects.\n    \"\"\"\n    if isinstance(package, str):\n        package = importlib.import_module(package)\n\n    if name is None:\n        name = package.__name__\n\n    submodules = [m[0] for m in inspect.getmembers(package, inspect.ismodule)\n                  if m[1].__name__.startswith('odl')]\n\n    results = {}\n    for pkgname in submodules:\n        full_name = name + '.' + pkgname\n        try:\n            results[full_name] = importlib.import_module(full_name)\n        except ImportError:\n            pass\n        else:\n            if recursive:\n                results.update(import_submodules(full_name, full_name))\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_interface():\n    modnames = ['odl'] + list(import_submodules(odl).keys())\n\n    for modname in modnames:\n        if not modname.startswith('odl'):\n            modname = 'odl.' + modname\n\n        shortmodname = modname.split('.')[-1]\n        print('{: <25} : generated {}.rst'.format(shortmodname, modname))\n\n        line = '=' * len(shortmodname)\n\n        module = importlib.import_module(modname)\n\n        docstring = module.__doc__\n        submodules = [m[0] for m in inspect.getmembers(\n            module, inspect.ismodule) if m[1].__name__.startswith('odl')]\n        functions = [m[0] for m in inspect.getmembers(\n            module, inspect.isfunction) if m[1].__module__ == modname]\n        classes = [m[0] for m in inspect.getmembers(\n            module, inspect.isclass) if m[1].__module__ == modname]\n\n        docstring = '' if docstring is None else docstring\n\n        submodules = [modname + '.' + mod for mod in submodules]\n        functions = ['~' + modname + '.' + fun\n                     for fun in functions if not fun.startswith('_')]\n        classes = ['~' + modname + '.' + cls\n                   for cls in classes if not cls.startswith('_')]\n\n        if len(submodules) > 0:\n            this_mod_string = module_string.format('\\n   '.join(submodules))\n        else:\n            this_mod_string = ''\n\n        if len(functions) > 0:\n            this_fun_string = fun_string.format('\\n   '.join(functions))\n        else:\n            this_fun_string = ''\n\n        if len(classes) > 0:\n            this_class_string = class_string.format('\\n   '.join(classes))\n        else:\n            this_class_string = ''\n\n        with open(modname + '.rst', 'w') as text_file:\n            text_file.write(string.format(shortname=shortmodname,\n                                          name=modname,\n                                          line=line,\n                                          docstring=docstring,\n                                          module_string=this_mod_string,\n                                          fun_string=this_fun_string,\n                                          class_string=this_class_string))", "response": "Generate the RST files for the API doc of ODL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Lp - norm of x.", "response": "def _call(self, x):\n        \"\"\"Return the Lp-norm of ``x``.\"\"\"\n        if self.exponent == 0:\n            return self.domain.one().inner(np.not_equal(x, 0))\n        elif self.exponent == 1:\n            return x.ufuncs.absolute().inner(self.domain.one())\n        elif self.exponent == 2:\n            return np.sqrt(x.inner(x))\n        elif np.isfinite(self.exponent):\n            tmp = x.ufuncs.absolute()\n            tmp.ufuncs.power(self.exponent, out=tmp)\n            return np.power(tmp.inner(self.domain.one()), 1 / self.exponent)\n        elif self.exponent == np.inf:\n            return x.ufuncs.absolute().ufuncs.max()\n        elif self.exponent == -np.inf:\n            return x.ufuncs.absolute().ufuncs.min()\n        else:\n            raise RuntimeError('unknown exponent')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef proximal(self):\n        if self.exponent == 1:\n            return proximal_l1(space=self.domain)\n        elif self.exponent == 2:\n            return proximal_l2(space=self.domain)\n        elif self.exponent == np.inf:\n            return proximal_linfty(space=self.domain)\n        else:\n            raise NotImplementedError('`proximal` only implemented for p=1, '\n                                      'p=2, and p=inf')", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gradient(self):\n        functional = self\n\n        if self.exponent == 1:\n            class L1Gradient(Operator):\n\n                \"\"\"The gradient operator of this functional.\"\"\"\n\n                def __init__(self):\n                    \"\"\"Initialize a new instance.\"\"\"\n                    super(L1Gradient, self).__init__(\n                        functional.domain, functional.domain, linear=False)\n\n                def _call(self, x):\n                    \"\"\"Apply the gradient operator to the given point.\"\"\"\n                    return x.ufuncs.sign()\n\n                def derivative(self, x):\n                    \"\"\"Derivative is a.e. zero.\"\"\"\n                    return ZeroOperator(self.domain)\n\n            return L1Gradient()\n\n        elif self.exponent == 2:\n            class L2Gradient(Operator):\n\n                \"\"\"The gradient operator of this functional.\"\"\"\n\n                def __init__(self):\n                    \"\"\"Initialize a new instance.\"\"\"\n                    super(L2Gradient, self).__init__(\n                        functional.domain, functional.domain, linear=False)\n\n                def _call(self, x):\n                    \"\"\"Apply the gradient operator to the given point.\n\n                    The gradient is not defined in 0.\n                    \"\"\"\n                    norm_of_x = x.norm()\n                    if norm_of_x == 0:\n                        return self.domain.zero()\n                    else:\n                        return x / norm_of_x\n\n            return L2Gradient()\n\n        else:\n            raise NotImplementedError('`gradient` only implemented for p=1 '\n                                      'and p=2')", "response": "Returns the gradient operator of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the group L1 - norm of x.", "response": "def _call(self, x):\n        \"\"\"Return the group L1-norm of ``x``.\"\"\"\n        # TODO: update when integration operator is in place: issue #440\n        pointwise_norm = self.pointwise_norm(x)\n        return pointwise_norm.inner(pointwise_norm.space.one())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gradient(self):\n        functional = self\n\n        class GroupL1Gradient(Operator):\n\n            \"\"\"The gradient operator of the `GroupL1Norm` functional.\"\"\"\n\n            def __init__(self):\n                \"\"\"Initialize a new instance.\"\"\"\n                super(GroupL1Gradient, self).__init__(\n                    functional.domain, functional.domain, linear=False)\n\n            def _call(self, x, out):\n                \"\"\"Return ``self(x)``.\"\"\"\n                pwnorm_x = functional.pointwise_norm(x)\n                pwnorm_x.ufuncs.sign(out=pwnorm_x)\n                functional.pointwise_norm.derivative(x).adjoint(pwnorm_x,\n                                                                out=out)\n\n                return out\n\n        return GroupL1Gradient()", "response": "r Returns the gradient operator of the group L1 norm."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef proximal(self):\n        if self.pointwise_norm.exponent == 1:\n            return proximal_l1(space=self.domain)\n        elif self.pointwise_norm.exponent == 2:\n            return proximal_l1_l2(space=self.domain)\n        else:\n            raise NotImplementedError('`proximal` only implemented for p = 1 '\n                                      'or 2')", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _call(self, x):\n        x_norm = self.pointwise_norm(x).ufuncs.max()\n\n        if x_norm > 1:\n            return np.inf\n        else:\n            return 0", "response": "Return the value of the class attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef proximal(self):\n        if self.pointwise_norm.exponent == np.inf:\n            return proximal_convex_conj_l1(space=self.domain)\n        elif self.pointwise_norm.exponent == 2:\n            return proximal_convex_conj_l1_l2(space=self.domain)\n        else:\n            raise NotImplementedError('`proximal` only implemented for p = 1 '\n                                      'or 2')", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convex_conj(self):\n        conj_exp = conj_exponent(self.pointwise_norm.exponent)\n        return GroupL1Norm(self.domain, exponent=conj_exp)", "response": "Convex conjugate functional of IndicatorLpUnitBall."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x):\n        x_norm = self.__norm(x)\n\n        if x_norm > 1:\n            return np.inf\n        else:\n            return 0", "response": "Apply the functional to the given point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convex_conj(self):\n        if self.exponent == np.inf:\n            return L1Norm(self.domain)\n        elif self.exponent == 2:\n            return L2Norm(self.domain)\n        else:\n            return LpNorm(self.domain, exponent=conj_exponent(self.exponent))", "response": "The convex conjugate functional of IndicatorLpUnitBall."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef proximal(self):\n        if self.exponent == np.inf:\n            return proximal_convex_conj_l1(space=self.domain)\n        elif self.exponent == 2:\n            return proximal_convex_conj_l2(space=self.domain)\n        elif self.exponent == 1:\n            return proximal_convex_conj_linfty(space=self.domain)\n        else:\n            raise NotImplementedError('`proximal` only implemented for p=1, '\n                                      'p=2 or p=inf')", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply the functional to the given point.", "response": "def _call(self, x):\n        \"\"\"Apply the functional to the given point.\"\"\"\n        # Since the proximal projects onto our feasible set we can simply\n        # check if it changes anything\n        proj = self.proximal(1)(x)\n        return np.inf if x.dist(proj) > 0 else 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x):\n        # Lazy import to improve `import odl` time\n        import scipy.special\n\n        with np.errstate(invalid='ignore', divide='ignore'):\n            if self.prior is None:\n                res = (x - 1 - np.log(x)).inner(self.domain.one())\n            else:\n                xlogy = scipy.special.xlogy(self.prior, self.prior / x)\n                res = (x - self.prior + xlogy).inner(self.domain.one())\n\n        if not np.isfinite(res):\n            # In this case, some element was less than or equal to zero\n            return np.inf\n        else:\n            return res", "response": "Return the KL - diveregnce in the point x."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the proximal factory of the functional.", "response": "def proximal(self):\n        \"\"\"Return the `proximal factory` of the functional.\n\n        See Also\n        --------\n        odl.solvers.nonsmooth.proximal_operators.proximal_convex_conj_kl :\n            `proximal factory` for convex conjugate of KL.\n        odl.solvers.nonsmooth.proximal_operators.proximal_convex_conj :\n            Proximal of the convex conjugate of a functional.\n        \"\"\"\n        return proximal_convex_conj(proximal_convex_conj_kl(space=self.domain,\n                                                            g=self.prior))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gradient(self):\n        functional = self\n\n        class KLCrossEntropyGradient(Operator):\n\n            \"\"\"The gradient operator of this functional.\"\"\"\n\n            def __init__(self):\n                \"\"\"Initialize a new instance.\"\"\"\n                super(KLCrossEntropyGradient, self).__init__(\n                    functional.domain, functional.domain, linear=False)\n\n            def _call(self, x):\n                \"\"\"Apply the gradient operator to the given point.\n\n                The gradient is not defined in for points with components less\n                than or equal to zero.\n                \"\"\"\n                if functional.prior is None:\n                    tmp = np.log(x)\n                else:\n                    tmp = np.log(x / functional.prior)\n\n                if np.all(np.isfinite(tmp)):\n                    return tmp\n                else:\n                    # The derivative is not defined.\n                    raise ValueError('The gradient of the Kullback-Leibler '\n                                     'Cross Entropy functional is not defined '\n                                     'for `x` with one or more components '\n                                     'less than or equal to zero.'.format(x))\n\n        return KLCrossEntropyGradient()", "response": "Returns the gradient of the Kullback - Leibler functional."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef proximal(self):\n        return proximal_convex_conj(proximal_convex_conj_kl_cross_entropy(\n            space=self.domain, g=self.prior))", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _call(self, x):\n        if self.prior is None:\n            tmp = self.domain.element((np.exp(x) - 1)).inner(self.domain.one())\n        else:\n            tmp = (self.prior * (np.exp(x) - 1)).inner(self.domain.one())\n        return tmp", "response": "Return the value in the point x."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the gradient operator of the functional.", "response": "def gradient(self):\n        \"\"\"Gradient operator of the functional.\"\"\"\n        functional = self\n\n        class KLCrossEntCCGradient(Operator):\n\n            \"\"\"The gradient operator of this functional.\"\"\"\n\n            def __init__(self):\n                \"\"\"Initialize a new instance.\"\"\"\n                super(KLCrossEntCCGradient, self).__init__(\n                    functional.domain, functional.domain, linear=False)\n\n            def _call(self, x):\n                \"\"\"Apply the gradient operator to the given point.\"\"\"\n                if functional.prior is None:\n                    return self.domain.element(np.exp(x))\n                else:\n                    return functional.prior * np.exp(x)\n\n        return KLCrossEntCCGradient()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the separable sum evaluated in x.", "response": "def _call(self, x):\n        \"\"\"Return the separable sum evaluated in ``x``.\"\"\"\n        return sum(fi(xi) for xi, fi in zip(x, self.functionals))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gradient(self):\n        gradients = [func.gradient for func in self.functionals]\n        return DiagonalOperator(*gradients)", "response": "Gradient operator of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef proximal(self):\n        proximals = [func.proximal for func in self.functionals]\n        return combine_proximals(*proximals)", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _asarray(self, vec):\n        shape = self.domain[0, 0].shape + self.pshape\n        arr = np.empty(shape, dtype=self.domain.dtype)\n        for i, xi in enumerate(vec):\n            for j, xij in enumerate(xi):\n                arr[..., i, j] = xij.asarray()\n\n        return arr", "response": "Convert x to an array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _asvector(self, arr):\n        result = moveaxis(arr, [-2, -1], [0, 1])\n        return self.domain.element(result)", "response": "Convert an array to a domain element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef proximal(self):\n        if self.outernorm.exponent != 1:\n            raise NotImplementedError('`proximal` only implemented for '\n                                      '`outer_exp==1`')\n        if self.pwisenorm.exponent not in [1, 2, np.inf]:\n            raise NotImplementedError('`proximal` only implemented for '\n                                      '`singular_vector_exp` in [1, 2, inf]')\n\n        def nddot(a, b):\n            \"\"\"Compute pointwise matrix product in the last indices.\"\"\"\n            return np.einsum('...ij,...jk->...ik', a, b)\n\n        func = self\n\n        # Add epsilon to fix rounding errors, i.e. make sure that when we\n        # project on the unit ball, we actually end up slightly inside the unit\n        # ball. Without, we may end up slightly outside.\n        dtype = getattr(self.domain, 'dtype', float)\n        eps = np.finfo(dtype).resolution * 10\n\n        class NuclearNormProximal(Operator):\n            \"\"\"Proximal operator of `NuclearNorm`.\"\"\"\n\n            def __init__(self, sigma):\n                self.sigma = float(sigma)\n                super(NuclearNormProximal, self).__init__(\n                    func.domain, func.domain, linear=False)\n\n            def _call(self, x):\n                \"\"\"Return ``self(x)``.\"\"\"\n                arr = func._asarray(x)\n\n                # Compute SVD\n                U, s, Vt = np.linalg.svd(arr, full_matrices=False)\n\n                # transpose pointwise\n                V = Vt.swapaxes(-1, -2)\n\n                # Take pseudoinverse of s\n                sinv = s.copy()\n                sinv[sinv != 0] = 1 / sinv[sinv != 0]\n\n                # Take pointwise proximal operator of s w.r.t. the norm\n                # on the singular vectors\n                if func.pwisenorm.exponent == 1:\n                    abss = np.abs(s) - (self.sigma - eps)\n                    sprox = np.sign(s) * np.maximum(abss, 0)\n                elif func.pwisenorm.exponent == 2:\n                    s_reordered = moveaxis(s, -1, 0)\n                    snorm = func.pwisenorm(s_reordered).asarray()\n                    snorm = np.maximum(self.sigma, snorm, out=snorm)\n                    sprox = ((1 - eps) - self.sigma / snorm)[..., None] * s\n                elif func.pwisenorm.exponent == np.inf:\n                    snorm = np.sum(np.abs(s), axis=-1)\n                    snorm = np.maximum(self.sigma, snorm, out=snorm)\n                    sprox = ((1 - eps) - self.sigma / snorm)[..., None] * s\n                else:\n                    raise RuntimeError\n\n                # Compute s matrix\n                sproxsinv = (sprox * sinv)[..., :, None]\n\n                # Compute the final result\n                result = nddot(nddot(arr, V), sproxsinv * Vt)\n\n                # Cast to vector and return. Note array and vector have\n                # different shapes.\n                return func._asvector(result)\n\n            def __repr__(self):\n                \"\"\"Return ``repr(self)``.\"\"\"\n                return '{!r}.proximal({})'.format(func, self.sigma)\n\n        return NuclearNormProximal", "response": "Return the proximal operator of the nuclear norm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convex_conj(self):\n        return IndicatorNuclearNormUnitBall(\n            self.domain,\n            conj_exponent(self.outernorm.exponent),\n            conj_exponent(self.pwisenorm.exponent))", "response": "Returns the convex conjugate of the nuclear norm."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convex_conj(self):\n        return NuclearNorm(self.domain,\n                           conj_exponent(self.__norm.outernorm.exponent),\n                           conj_exponent(self.__norm.pwisenorm.exponent))", "response": "Returns the convex conjugate of the unit ball indicator of the nuclear norm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x):\n\n        sum_constr = abs(x.ufuncs.sum() / self.diameter - 1) <= self.sum_rtol\n\n        nonneq_constr = x.ufuncs.greater_equal(0).asarray().all()\n\n        if sum_constr and nonneq_constr:\n            return 0\n        else:\n            return np.inf", "response": "Return the value of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef proximal(self):\n\n        domain = self.domain\n        diameter = self.diameter\n\n        class ProximalSimplex(Operator):\n            \"\"\"Proximal operator implemented by the algorithm of [D+2008].\n\n            [D+2008] Duchi, J., Shalev-Shwartz, S., Singer, Y., and Chandra, T.\n            *Efficient Projections onto the L1-ball for Learning in High\n            dimensions*. ICML 2008, pp. 272-279.\n            http://doi.org/10.1145/1390156.1390191\n            \"\"\"\n\n            def __init__(self, sigma):\n                self.sigma = sigma\n                super(ProximalSimplex, self).__init__(\n                    domain=domain, range=domain, linear=False)\n\n            def _call(self, x, out):\n\n                # projection onto simplex\n                proj_simplex(x, diameter, out)\n\n        return ProximalSimplex", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(self, x):\n\n        if abs(x.ufuncs.sum() / self.sum_value - 1) <= self.sum_rtol:\n            return 0\n        else:\n            return np.inf", "response": "Return the value of the class attribute."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef proximal(self):\n\n        domain = self.domain\n\n        class ProximalSum(Operator):\n            \"\"\"Proximal operator.\"\"\"\n\n            def __init__(self, sigma):\n                self.sigma = sigma\n                super(ProximalSum, self).__init__(\n                    domain=domain, range=domain, linear=False)\n\n            def _call(self, x, out):\n\n                offset = 1 / x.size * (self.sum_value - x.ufuncs.sum())\n                out.assign(x)\n                out += offset\n\n        return ProximalSum", "response": "Return the proximal factory of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gradient(self):\n\n        functional = self\n\n        class HuberGradient(Operator):\n\n            \"\"\"The gradient operator of this functional.\"\"\"\n\n            def __init__(self):\n                \"\"\"Initialize a new instance.\"\"\"\n                super(HuberGradient, self).__init__(\n                    functional.domain, functional.domain, linear=False)\n\n            def _call(self, x):\n                \"\"\"Apply the gradient operator to the given point.\"\"\"\n                if isinstance(self.domain, ProductSpace):\n                    norm = PointwiseNorm(self.domain, 2)(x)\n                else:\n                    norm = x.ufuncs.absolute()\n\n                grad = x / functional.gamma\n\n                index = norm.ufuncs.greater_equal(functional.gamma)\n                if isinstance(self.domain, ProductSpace):\n                    for xi, gi in zip(x, grad):\n                        gi[index] = xi[index] / norm[index]\n                else:\n                    grad[index] = x[index] / norm[index]\n\n                return grad\n\n        return HuberGradient()", "response": "r Gradient operator of the huber functional."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_node(self, x):\n        x = theano.tensor.as_tensor_variable(x)\n\n        # Create tensor type with correct dtype.\n        # The second argument specifies the number of dimensions of the output.\n        # False means that we do not support broadcasting.\n        if isinstance(self.operator, Functional):\n            # Make scalar out type\n            out_type = theano.tensor.TensorVariable(\n                theano.tensor.TensorType(self.operator.domain.dtype, ()))\n        else:\n            out_type = theano.tensor.TensorVariable(\n                theano.tensor.TensorType(\n                    self.operator.range.dtype,\n                    [False] * len(self.operator.range.shape)))\n\n        return theano.Apply(self, [x], [out_type.type()])", "response": "Create a node for the computation graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perform(self, node, inputs, output_storage):\n        x = inputs[0]\n        z = output_storage[0]\n        z[0] = np.asarray(self.operator(x))", "response": "Evaluate this node s computation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninferring the shape of the output of the node based on input_shapes.", "response": "def infer_shape(self, node, input_shapes):\n        \"\"\"Return a list of output shapes based on ``input_shapes``.\n\n        This method is optional. It allows to compute the shape of the\n        output without having to evaluate.\n\n        Parameters\n        ----------\n        node : `theano.gof.graph.Apply`\n            The node of this Op in the computation graph.\n        input_shapes : 1-element list of `theano.compile.ops.Shape`\n            Symbolic shape of the input.\n\n        Returns\n        -------\n        output_shapes : 1-element list of tuples\n            Fixed shape of the output determined by `odl_op`.\n        \"\"\"\n        if isinstance(self.operator, Functional):\n            return [()]\n        else:\n            # Need to convert to native to avoid error in Theano from\n            # future.int\n            return [tuple(native(si) for si in self.operator.range.shape)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef R_op(self, inputs, eval_points):\n        # ODL weights spaces, Theano does not. We need to handle this\n        try:\n            dom_weight = self.operator.domain.weighting.const\n        except AttributeError:\n            dom_weight = 1.0\n\n        try:\n            ran_weight = self.operator.range.weighting.const\n        except AttributeError:\n            ran_weight = 1.0\n\n        scale = dom_weight / ran_weight\n\n        op = self\n\n        class TheanoJacobianAdjoint(theano.Op):\n\n            __props__ = ()\n\n            \"\"\"Wrap ``op.derivative(x).adjoint(v)`` into a Theano Op.\n\n            This Op has two inputs, ``x`` and ``v``, where ``x``\n            is the point at which the Jacobian is taken, and ``v`` the\n            tensor to which its adjoint is applied. There is only one output,\n            which is of the same type as ``v`` (and ``x``).\n            \"\"\"\n\n            def make_node(self, x, v):\n                \"\"\"Create a node for the computation graph.\"\"\"\n                x = theano.tensor.as_tensor_variable(x)\n                v = theano.tensor.as_tensor_variable(v)\n                return theano.Apply(self, [x, v], [x.type()])\n\n            def perform(self, node, inputs_storage, output_storage):\n                \"\"\"Evaluate this node's computation.\n\n                This method computes ::\n\n                    op.derivative(x).adjoint(v)\n                \"\"\"\n                x = inputs_storage[0]\n                v = inputs_storage[1]\n                out = output_storage[0]\n                out[0] = np.asarray(op.operator.derivative(x).adjoint(v))\n                if scale != 1.0:\n                    out[0] *= scale\n\n            def infer_shape(self, node, input_shapes):\n                \"\"\"Return a list of output shapes based on ``input_shapes``.\"\"\"\n                # Need to convert to native to avoid error in theano from\n                # future.int\n                return [tuple(native(si) for si in op.operator.domain.shape)]\n\n        r_op = TheanoJacobianAdjoint()\n        r_op_apply = r_op(inputs[0], eval_points[0])\n        return [r_op_apply]", "response": "This method applies the adjoint of the Jacobian at inputs to eval_points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reciprocal_grid(grid, shift=True, axes=None, halfcomplex=False):\n    if axes is None:\n        axes = list(range(grid.ndim))\n    else:\n        try:\n            axes = [int(axes)]\n        except TypeError:\n            axes = list(axes)\n\n    # List indicating shift or not per \"active\" axis, same length as axes\n    shift_list = normalized_scalar_param_list(shift, length=len(axes),\n                                              param_conv=bool)\n\n    # Full-length vectors\n    stride = grid.stride.copy()\n    stride[stride == 0] = 1\n    shape = np.array(grid.shape)\n    rmin = grid.min_pt.copy()\n    rmax = grid.max_pt.copy()\n    rshape = list(shape)\n\n    # Shifted axes (full length to avoid ugly double indexing)\n    shifted = np.zeros(grid.ndim, dtype=bool)\n    shifted[axes] = shift_list\n    rmin[shifted] = -np.pi / stride[shifted]\n    # Length min->max increases by double the shift, so we\n    # have to compensate by a full stride\n    rmax[shifted] = (-rmin[shifted] -\n                     2 * np.pi / (stride[shifted] * shape[shifted]))\n\n    # Non-shifted axes\n    not_shifted = np.zeros(grid.ndim, dtype=bool)\n    not_shifted[axes] = np.logical_not(shift_list)\n    rmin[not_shifted] = ((-1.0 + 1.0 / shape[not_shifted]) *\n                         np.pi / stride[not_shifted])\n    rmax[not_shifted] = -rmin[not_shifted]\n\n    # Change last axis shape and max if halfcomplex\n    if halfcomplex:\n        rshape[axes[-1]] = shape[axes[-1]] // 2 + 1\n\n        # - Odd and shifted: - stride / 2\n        # - Even and not shifted: + stride / 2\n        # - Otherwise: 0\n        last_odd = shape[axes[-1]] % 2 == 1\n        last_shifted = shift_list[-1]\n        half_rstride = np.pi / (shape[axes[-1]] * stride[axes[-1]])\n\n        if last_odd and last_shifted:\n            rmax[axes[-1]] = -half_rstride\n        elif not last_odd and not last_shifted:\n            rmax[axes[-1]] = half_rstride\n        else:\n            rmax[axes[-1]] = 0\n\n    return uniform_grid(rmin, rmax, rshape)", "response": "This function calculates the reciprocal of a given regular grid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef realspace_grid(recip_grid, x0, axes=None, halfcomplex=False,\n                   halfcx_parity='even'):\n    \"\"\"Return the real space grid from the given reciprocal grid.\n\n    Given a reciprocal grid::\n\n        xi[j] = xi[0] + j * sigma,\n\n    with a multi-index ``j = (j[0], ..., j[d-1])`` in the range\n    ``0 <= j < M``, this function calculates the original grid::\n\n        x[k] = x[0] + k * s\n\n    by using a provided ``x[0]`` and calculating the stride ``s``.\n\n    If the reciprocal grid is interpreted as coming from a usual\n    complex-to-complex FFT, it is ``N == M``, and the stride is::\n\n        s = 2*pi / (sigma * N)\n\n    For a reciprocal grid from a real-to-complex (half-complex) FFT,\n    it is ``M[i] = floor(N[i]/2) + 1`` in the last transform axis ``i``.\n    To resolve the ambiguity regarding the parity of ``N[i]``, the\n    it must be specified if the output shape should be even or odd,\n    resulting in::\n\n        odd : N[i] = 2 * M[i] - 1\n        even: N[i] = 2 * M[i] - 2\n\n    The output stride is calculated with this ``N`` as above in this\n    case.\n\n    Parameters\n    ----------\n    recip_grid : uniform `RectGrid`\n        Sampling grid in reciprocal space.\n    x0 : `array-like`\n        Desired minimum point of the real space grid.\n    axes : int or sequence of ints, optional\n        Dimensions in which to calculate the real space grid. The sequence\n        must have the same length as ``shift`` if the latter is given\n        as a sequence. ``None`` means \"all axes\".\n    halfcomplex : bool, optional\n        If ``True``, interpret the given grid as the reciprocal as used\n        in a half-complex FFT (see above). Otherwise, the grid is\n        regarded as being used in a complex-to-complex transform.\n    halfcx_parity : {'even', 'odd'}\n        Use this parity for the shape of the returned grid in the\n        last axis of ``axes`` in the case ``halfcomplex=True``\n\n    Returns\n    -------\n    irecip : uniform `RectGrid`\n        The inverse reciprocal grid.\n    \"\"\"\n    if axes is None:\n        axes = list(range(recip_grid.ndim))\n    else:\n        try:\n            axes = [int(axes)]\n        except TypeError:\n            axes = list(axes)\n\n    rstride = recip_grid.stride\n    rshape = recip_grid.shape\n\n    # Calculate shape of the output grid by adjusting in axes[-1]\n    irshape = list(rshape)\n    if halfcomplex:\n        if str(halfcx_parity).lower() == 'even':\n            irshape[axes[-1]] = 2 * rshape[axes[-1]] - 2\n        elif str(halfcx_parity).lower() == 'odd':\n            irshape[axes[-1]] = 2 * rshape[axes[-1]] - 1\n        else:\n            raise ValueError(\"`halfcomplex` parity '{}' not understood\"\n                             \"\".format(halfcx_parity))\n\n    irmin = np.asarray(x0)\n    irshape = np.asarray(irshape)\n    irstride = np.copy(rstride)\n    irstride[axes] = 2 * np.pi / (irshape[axes] * rstride[axes])\n    irmax = irmin + (irshape - 1) * irstride\n\n    return uniform_grid(irmin, irmax, irshape)", "response": "Return the real space grid from a reciprocal grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dft_preprocess_data(arr, shift=True, axes=None, sign='-', out=None):\n    arr = np.asarray(arr)\n    if not is_numeric_dtype(arr.dtype):\n        raise ValueError('array has non-numeric data type {}'\n                         ''.format(dtype_repr(arr.dtype)))\n    elif is_real_dtype(arr.dtype) and not is_real_floating_dtype(arr.dtype):\n        arr = arr.astype('float64')\n\n    if axes is None:\n        axes = list(range(arr.ndim))\n    else:\n        try:\n            axes = [int(axes)]\n        except TypeError:\n            axes = list(axes)\n\n    shape = arr.shape\n    shift_list = normalized_scalar_param_list(shift, length=len(axes),\n                                              param_conv=bool)\n\n    # Make a copy of arr with correct data type if necessary, or copy values.\n    if out is None:\n        if is_real_dtype(arr.dtype) and not all(shift_list):\n            out = np.array(arr, dtype=complex_dtype(arr.dtype), copy=True)\n        else:\n            out = arr.copy()\n    else:\n        out[:] = arr\n\n    if is_real_dtype(out.dtype) and not shift:\n        raise ValueError('cannot pre-process real input in-place without '\n                         'shift')\n\n    if sign == '-':\n        imag = -1j\n    elif sign == '+':\n        imag = 1j\n    else:\n        raise ValueError(\"`sign` '{}' not understood\".format(sign))\n\n    def _onedim_arr(length, shift):\n        if shift:\n            # (-1)^indices\n            factor = np.ones(length, dtype=out.dtype)\n            factor[1::2] = -1\n        else:\n            factor = np.arange(length, dtype=out.dtype)\n            factor *= -imag * np.pi * (1 - 1.0 / length)\n            np.exp(factor, out=factor)\n        return factor.astype(out.dtype, copy=False)\n\n    onedim_arrs = []\n    for axis, shift in zip(axes, shift_list):\n        length = shape[axis]\n        onedim_arrs.append(_onedim_arr(length, shift))\n\n    fast_1d_tensor_mult(out, onedim_arrs, axes=axes, out=out)\n    return out", "response": "Pre - processes the real - space data before DFT."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _interp_kernel_ft(norm_freqs, interp):\n    # Numpy's sinc(x) is equal to the 'math' sinc(pi * x)\n    ker_ft = np.sinc(norm_freqs)\n    interp_ = str(interp).lower()\n    if interp_ == 'nearest':\n        pass\n    elif interp_ == 'linear':\n        ker_ft *= ker_ft\n    else:\n        raise ValueError(\"`interp` '{}' not understood\".format(interp))\n\n    ker_ft /= np.sqrt(2 * np.pi)\n    return ker_ft", "response": "Function that computes the FT of a one - dimensional interpolation kernel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dft_postprocess_data(arr, real_grid, recip_grid, shift, axes,\n                         interp, sign='-', op='multiply', out=None):\n    \"\"\"Post-process the Fourier-space data after DFT.\n\n    This function multiplies the given data with the separable\n    function::\n\n        q(xi) = exp(+- 1j * dot(x[0], xi)) * s * phi_hat(xi_bar)\n\n    where ``x[0]`` and ``s`` are the minimum point and the stride of\n    the real-space grid, respectively, and ``phi_hat(xi_bar)`` is the FT\n    of the interpolation kernel. The sign of the exponent depends on the\n    choice of ``sign``. Note that for ``op='divide'`` the\n    multiplication with ``s * phi_hat(xi_bar)`` is replaced by a\n    division with the same array.\n\n    In discretized form on the reciprocal grid, the exponential part\n    of this function becomes an array::\n\n        q[k] = exp(+- 1j * dot(x[0], xi[k]))\n\n    and the arguments ``xi_bar`` to the interpolation kernel\n    are the normalized frequencies::\n\n        for 'shift=True'  : xi_bar[k] = -pi + pi * (2*k) / N\n        for 'shift=False' : xi_bar[k] = -pi + pi * (2*k+1) / N\n\n    See [Pre+2007], Section 13.9 \"Computing Fourier Integrals Using\n    the FFT\" for a similar approach.\n\n    Parameters\n    ----------\n    arr : `array-like`\n        Array to be pre-processed. An array with real data type is\n        converted to its complex counterpart.\n    real_grid : uniform `RectGrid`\n        Real space grid in the transform.\n    recip_grid : uniform `RectGrid`\n        Reciprocal grid in the transform\n    shift : bool or sequence of bools\n        If ``True``, the grid is shifted by half a stride in the negative\n        direction in the corresponding axes. The sequence must have the\n        same length as ``axes``.\n    axes : int or sequence of ints\n        Dimensions along which to take the transform. The sequence must\n        have the same length as ``shifts``.\n    interp : string or sequence of strings\n        Interpolation scheme used in the real-space.\n    sign : {'-', '+'}, optional\n        Sign of the complex exponent.\n    op : {'multiply', 'divide'}, optional\n        Operation to perform with the stride times the interpolation\n        kernel FT\n    out : `numpy.ndarray`, optional\n        Array in which the result is stored. If ``out is arr``, an\n        in-place modification is performed.\n\n    Returns\n    -------\n    out : `numpy.ndarray`\n        Result of the post-processing. If ``out`` was given, the returned\n        object is a reference to it.\n\n    References\n    ----------\n    [Pre+2007] Press, W H, Teukolsky, S A, Vetterling, W T, and Flannery, B P.\n    *Numerical Recipes in C - The Art of Scientific Computing* (Volume 3).\n    Cambridge University Press, 2007.\n    \"\"\"\n    arr = np.asarray(arr)\n    if is_real_floating_dtype(arr.dtype):\n        arr = arr.astype(complex_dtype(arr.dtype))\n    elif not is_complex_floating_dtype(arr.dtype):\n        raise ValueError('array data type {} is not a complex floating point '\n                         'data type'.format(dtype_repr(arr.dtype)))\n\n    if out is None:\n        out = arr.copy()\n    elif out is not arr:\n        out[:] = arr\n\n    if axes is None:\n        axes = list(range(arr.ndim))\n    else:\n        try:\n            axes = [int(axes)]\n        except TypeError:\n            axes = list(axes)\n\n    shift_list = normalized_scalar_param_list(shift, length=len(axes),\n                                              param_conv=bool)\n\n    if sign == '-':\n        imag = -1j\n    elif sign == '+':\n        imag = 1j\n    else:\n        raise ValueError(\"`sign` '{}' not understood\".format(sign))\n\n    op, op_in = str(op).lower(), op\n    if op not in ('multiply', 'divide'):\n        raise ValueError(\"kernel `op` '{}' not understood\".format(op_in))\n\n    # Make a list from interp if that's not the case already\n    if is_string(interp):\n        interp = [str(interp).lower()] * arr.ndim\n\n    onedim_arrs = []\n    for ax, shift, intp in zip(axes, shift_list, interp):\n        x = real_grid.min_pt[ax]\n        xi = recip_grid.coord_vectors[ax]\n\n        # First part: exponential array\n        onedim_arr = np.exp(imag * x * xi)\n\n        # Second part: interpolation kernel\n        len_dft = recip_grid.shape[ax]\n        len_orig = real_grid.shape[ax]\n        halfcomplex = (len_dft < len_orig)\n        odd = len_orig % 2\n\n        fmin = -0.5 if shift else -0.5 + 1.0 / (2 * len_orig)\n        if halfcomplex:\n            # maximum lies around 0, possibly half a cell left or right of it\n            if shift and odd:\n                fmax = - 1.0 / (2 * len_orig)\n            elif not shift and not odd:\n                fmax = 1.0 / (2 * len_orig)\n            else:\n                fmax = 0.0\n\n        else:  # not halfcomplex\n            # maximum lies close to 0.5, half or full cell left of it\n            if shift:\n                # -0.5 + (N-1)/N = 0.5 - 1/N\n                fmax = 0.5 - 1.0 / len_orig\n            else:\n                # -0.5 + 1/(2*N) + (N-1)/N = 0.5 - 1/(2*N)\n                fmax = 0.5 - 1.0 / (2 * len_orig)\n\n        freqs = np.linspace(fmin, fmax, num=len_dft)\n        stride = real_grid.stride[ax]\n\n        interp_kernel = _interp_kernel_ft(freqs, intp)\n        interp_kernel *= stride\n\n        if op == 'multiply':\n            onedim_arr *= interp_kernel\n        else:\n            onedim_arr /= interp_kernel\n\n        onedim_arrs.append(onedim_arr.astype(out.dtype, copy=False))\n\n    fast_1d_tensor_mult(out, onedim_arrs, axes=axes, out=out)\n    return out", "response": "Post - process the Fourier - space data after DFT."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the range of the Fourier transform on the given space.", "response": "def reciprocal_space(space, axes=None, halfcomplex=False, shift=True,\n                     **kwargs):\n    \"\"\"Return the range of the Fourier transform on ``space``.\n\n    Parameters\n    ----------\n    space : `DiscreteLp`\n        Real space whose reciprocal is calculated. It must be\n        uniformly discretized.\n    axes : sequence of ints, optional\n        Dimensions along which the Fourier transform is taken.\n        Default: all axes\n    halfcomplex : bool, optional\n        If ``True``, take only the negative frequency part along the last\n        axis for. For ``False``, use the full frequency space.\n        This option can only be used if ``space`` is a space of\n        real-valued functions.\n    shift : bool or sequence of bools, optional\n        If ``True``, the reciprocal grid is shifted by half a stride in\n        the negative direction. With a boolean sequence, this option\n        is applied separately to each axis.\n        If a sequence is provided, it must have the same length as\n        ``axes`` if supplied. Note that this must be set to ``True``\n        in the halved axis in half-complex transforms.\n        Default: ``True``\n    impl : string, optional\n        Implementation back-end for the created space.\n        Default: ``'numpy'``\n    exponent : float, optional\n        Create a space with this exponent. By default, the conjugate\n        exponent ``q = p / (p - 1)`` of the exponent of ``space`` is\n        used, where ``q = inf`` for ``p = 1`` and vice versa.\n    dtype : optional\n        Complex data type of the created space. By default, the\n        complex counterpart of ``space.dtype`` is used.\n\n    Returns\n    -------\n    rspace : `DiscreteLp`\n        Reciprocal of the input ``space``. If ``halfcomplex=True``, the\n        upper end of the domain (where the half space ends) is chosen to\n        coincide with the grid node.\n    \"\"\"\n    if not isinstance(space, DiscreteLp):\n        raise TypeError('`space` {!r} is not a `DiscreteLp` instance'\n                        ''.format(space))\n    if axes is None:\n        axes = tuple(range(space.ndim))\n    axes = normalized_axes_tuple(axes, space.ndim)\n\n    if not all(space.is_uniform_byaxis[axis] for axis in axes):\n        raise ValueError('`space` is not uniformly discretized in the '\n                         '`axes` of the transform')\n\n    if halfcomplex and space.field != RealNumbers():\n        raise ValueError('`halfcomplex` option can only be used with real '\n                         'spaces')\n\n    exponent = kwargs.pop('exponent', None)\n    if exponent is None:\n        exponent = conj_exponent(space.exponent)\n\n    dtype = kwargs.pop('dtype', None)\n    if dtype is None:\n        dtype = complex_dtype(space.dtype)\n    else:\n        if not is_complex_floating_dtype(dtype):\n            raise ValueError('{} is not a complex data type'\n                             ''.format(dtype_repr(dtype)))\n\n    impl = kwargs.pop('impl', 'numpy')\n\n    # Calculate range\n    recip_grid = reciprocal_grid(space.grid, shift=shift,\n                                 halfcomplex=halfcomplex, axes=axes)\n\n    # Need to do this for axes of length 1 that are not transformed\n    non_axes = [i for i in range(space.ndim) if i not in axes]\n    min_pt = {i: space.min_pt[i] for i in non_axes}\n    max_pt = {i: space.max_pt[i] for i in non_axes}\n\n    # Make a partition with nodes on the boundary in the last transform axis\n    # if `halfcomplex == True`, otherwise a standard partition.\n    if halfcomplex:\n        max_pt[axes[-1]] = recip_grid.max_pt[axes[-1]]\n\n    part = uniform_partition_fromgrid(recip_grid, min_pt, max_pt)\n\n    # Use convention of adding a hat to represent fourier transform of variable\n    axis_labels = list(space.axis_labels)\n    for i in axes:\n        # Avoid double math\n        label = axis_labels[i].replace('$', '')\n        axis_labels[i] = '$\\\\^{{{}}}$'.format(label)\n\n    recip_spc = uniform_discr_frompartition(part, exponent=exponent,\n                                            dtype=dtype, impl=impl,\n                                            axis_labels=axis_labels)\n\n    return recip_spc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _initialize_if_needed():\n    global IS_INITIALIZED, TENSOR_SPACE_IMPLS\n    if not IS_INITIALIZED:\n        # pkg_resources has long import time\n        from pkg_resources import iter_entry_points\n        for entry_point in iter_entry_points(group='odl.space', name=None):\n            try:\n                module = entry_point.load()\n            except ImportError:\n                pass\n            else:\n                TENSOR_SPACE_IMPLS.update(module.tensor_space_impls())\n        IS_INITIALIZED = True", "response": "Initialize TENSOR_SPACE_IMPLS if not already done."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the class corresponding to the given tensor space implementation.", "response": "def tensor_space_impl(impl):\n    \"\"\"Tensor space class corresponding to the given impl name.\n\n    Parameters\n    ----------\n    impl : str\n        Name of the implementation, see `tensor_space_impl_names` for\n        the full list.\n\n    Returns\n    -------\n    tensor_space_impl : type\n        Class inheriting from `TensorSpace`.\n\n    Raises\n    ------\n    ValueError\n        If ``impl`` is not a valid name of a tensor space imlementation.\n    \"\"\"\n    if impl != 'numpy':\n        # Shortcut to improve \"import odl\" times since most users do not use\n        # non-numpy backends\n        _initialize_if_needed()\n\n    try:\n        return TENSOR_SPACE_IMPLS[impl]\n    except KeyError:\n        raise ValueError(\"`impl` {!r} does not correspond to a valid tensor \"\n                         \"space implmentation\".format(impl))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef steepest_descent(f, x, line_search=1.0, maxiter=1000, tol=1e-16,\n                     projection=None, callback=None):\n    r\"\"\"Steepest descent method to minimize an objective function.\n\n    General implementation of steepest decent (also known as gradient\n    decent) for solving\n\n    .. math::\n        \\min f(x)\n\n    The algorithm is intended for unconstrained problems. It needs line\n    search in order guarantee convergence. With appropriate line search,\n    it can also be used for constrained problems where one wants to\n    minimize over some given set :math:`C`. This can be done by defining\n    :math:`f(x) = \\infty` for :math:`x\\\\not\\\\in C`, or by providing a\n    ``projection`` function that projects the iterates on :math:`C`.\n\n    The algorithm is described in [BV2004], section 9.3--9.4\n    (`book available online\n    <http://stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf>`_),\n    [GNS2009], Section 12.2, and wikipedia\n    `Gradient_descent\n    <https://en.wikipedia.org/wiki/Gradient_descent>`_.\n\n    Parameters\n    ----------\n    f : `Functional`\n        Goal functional. Needs to have ``f.gradient``.\n    x : ``f.domain`` element\n        Starting point of the iteration\n    line_search : float or `LineSearch`, optional\n        Strategy to choose the step length. If a float is given, uses it as a\n        fixed step length.\n    maxiter : int, optional\n        Maximum number of iterations.\n    tol : float, optional\n        Tolerance that should be used for terminating the iteration.\n    projection : callable, optional\n        Function that can be used to modify the iterates in each iteration,\n        for example enforcing positivity. The function should take one\n        argument and modify it in-place.\n    callback : callable, optional\n        Object executing code per iteration, e.g. plotting each iterate\n\n    See Also\n    --------\n    odl.solvers.iterative.iterative.landweber :\n        Optimized solver for the case ``f(x) = ||Ax - b||_2^2``\n    odl.solvers.iterative.iterative.conjugate_gradient :\n        Optimized solver for the case ``f(x) = x^T Ax - 2 x^T b``\n\n    References\n    ----------\n    [BV2004] Boyd, S, and Vandenberghe, L. *Convex optimization*.\n    Cambridge university press, 2004.\n\n    [GNS2009] Griva, I, Nash, S G, and Sofer, A. *Linear and nonlinear\n    optimization*. Siam, 2009.\n    \"\"\"\n    grad = f.gradient\n    if x not in grad.domain:\n        raise TypeError('`x` {!r} is not in the domain of `grad` {!r}'\n                        ''.format(x, grad.domain))\n\n    if not callable(line_search):\n        line_search = ConstantLineSearch(line_search)\n\n    grad_x = grad.range.element()\n    for _ in range(maxiter):\n        grad(x, out=grad_x)\n\n        dir_derivative = -grad_x.norm() ** 2\n        if np.abs(dir_derivative) < tol:\n            return  # we have converged\n        step = line_search(x, -grad_x, dir_derivative)\n\n        x.lincomb(1, x, -step, grad_x)\n\n        if projection is not None:\n            projection(x)\n\n        if callback is not None:\n            callback(x)", "response": "r Solve a function f for a given iteration and return the first iteration of the next iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef adam(f, x, learning_rate=1e-3, beta1=0.9, beta2=0.999, eps=1e-8,\n         maxiter=1000, tol=1e-16, callback=None):\n    r\"\"\"ADAM method to minimize an objective function.\n\n    General implementation of ADAM for solving\n\n    .. math::\n        \\min f(x)\n\n    where :math:`f` is a differentiable functional.\n\n    The algorithm is described in [KB2015] (`arxiv\n    <https://arxiv.org/abs/1412.6980>`_). All parameter names and default\n    valuesare taken from the article.\n\n    Parameters\n    ----------\n    f : `Functional`\n        Goal functional. Needs to have ``f.gradient``.\n    x : ``f.domain`` element\n        Starting point of the iteration, updated in place.\n    learning_rate : positive float, optional\n        Step length of the method.\n    beta1 : float in [0, 1), optional\n        Update rate for first order moment estimate.\n    beta2 : float in [0, 1), optional\n        Update rate for second order moment estimate.\n    eps : positive float, optional\n        A small constant for numerical stability.\n    maxiter : int, optional\n        Maximum number of iterations.\n    tol : positive float, optional\n        Tolerance that should be used for terminating the iteration.\n    callback : callable, optional\n        Object executing code per iteration, e.g. plotting each iterate.\n\n    See Also\n    --------\n    odl.solvers.smooth.gradient.steepest_descent : Simple gradient descent.\n    odl.solvers.iterative.iterative.landweber :\n        Optimized solver for the case ``f(x) = ||Ax - b||_2^2``.\n    odl.solvers.iterative.iterative.conjugate_gradient :\n        Optimized solver for the case ``f(x) = x^T Ax - 2 x^T b``.\n\n    References\n    ----------\n    [KB2015] Kingma, D P and Ba, J.\n    *Adam: A Method for Stochastic Optimization*, ICLR 2015.\n    \"\"\"\n    grad = f.gradient\n    if x not in grad.domain:\n        raise TypeError('`x` {!r} is not in the domain of `grad` {!r}'\n                        ''.format(x, grad.domain))\n\n    m = grad.domain.zero()\n    v = grad.domain.zero()\n\n    grad_x = grad.range.element()\n    for _ in range(maxiter):\n        grad(x, out=grad_x)\n\n        if grad_x.norm() < tol:\n            return\n\n        m.lincomb(beta1, m, 1 - beta1, grad_x)\n        v.lincomb(beta2, v, 1 - beta2, grad_x ** 2)\n\n        step = learning_rate * np.sqrt(1 - beta2) / (1 - beta1)\n\n        x.lincomb(1, x, -step, m / (np.sqrt(v) + eps))\n\n        if callback is not None:\n            callback(x)", "response": "r A simple algorithm for solving an ADAM function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntests if elements x and y are approximately equal.", "response": "def _approx_equal(x, y, eps):\n    \"\"\"Test if elements ``x`` and ``y`` are approximately equal.\n\n    ``eps`` is a given absolute tolerance.\n    \"\"\"\n    if x.space != y.space:\n        return False\n\n    if x is y:\n        return True\n\n    try:\n        return x.dist(y) <= eps\n    except NotImplementedError:\n        try:\n            return x == y\n        except NotImplementedError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the data directory.", "response": "def get_data_dir():\n    \"\"\"Get the data directory.\"\"\"\n    base_odl_dir = os.environ.get('ODL_HOME', expanduser(join('~', '.odl')))\n    data_home = join(base_odl_dir, 'datasets')\n    if not exists(data_home):\n        os.makedirs(data_home)\n    return data_home"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_data(filename, subset, url):\n    # check if this data set has been already downloaded\n    data_dir = join(get_data_dir(), subset)\n    if not exists(data_dir):\n        os.makedirs(data_dir)\n\n    filename = join(data_dir, filename)\n\n    # if the file does not exist, download it\n    if not exists(filename):\n        print('data {}/{} not in local storage, downloading from {}'\n              ''.format(subset, filename, url))\n\n        # open the url of the data\n        with contextlib.closing(urlopen(url)) as data_url:\n            # store downloaded file locally\n            with open(filename, 'w+b') as storage_file:\n                copyfileobj(data_url, storage_file)\n\n    # load dataset file\n    with open(filename, 'rb') as storage_file:\n        data_dict = io.loadmat(storage_file)\n\n    return data_dict", "response": "Get a dataset with from a url with local caching."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef samples(*sets):\n    if len(sets) == 1:\n        for example in sets[0].examples:\n            yield example\n    else:\n        generators = [set_.examples for set_ in sets]\n        for examples in product(*generators):\n            yield examples", "response": "Generate samples from the given sets using their examples method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef defrise(space, nellipses=8, alternating=False, min_pt=None, max_pt=None):\n    ellipses = defrise_ellipses(space.ndim, nellipses=nellipses,\n                                alternating=alternating)\n    return ellipsoid_phantom(space, ellipses, min_pt, max_pt)", "response": "Returns a new phantom with regularily spaced ellipses."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new base - 2 or 3 - dimensional Defrise phantom with the specified number of ellipses.", "response": "def defrise_ellipses(ndim, nellipses=8, alternating=False):\n    \"\"\"Ellipses for the standard Defrise phantom in 2 or 3 dimensions.\n\n    Parameters\n    ----------\n    ndim : {2, 3}\n        Dimension of the space for the ellipses/ellipsoids.\n    nellipses : int, optional\n        Number of ellipses. If more ellipses are used, each ellipse becomes\n        thinner.\n    alternating : bool, optional\n        True if the ellipses should have alternating densities (+1, -1),\n        otherwise all ellipses have value +1.\n\n    See Also\n    --------\n    odl.phantom.geometric.ellipsoid_phantom :\n        Function for creating arbitrary ellipsoids phantoms\n    odl.phantom.transmission.shepp_logan_ellipsoids\n    \"\"\"\n    ellipses = []\n    if ndim == 2:\n        for i in range(nellipses):\n            if alternating:\n                value = (-1.0 + 2.0 * (i % 2))\n            else:\n                value = 1.0\n\n            axis_1 = 0.5\n            axis_2 = 0.5 / (nellipses + 1)\n            center_x = 0.0\n            center_y = -1 + 2.0 / (nellipses + 1.0) * (i + 1)\n            rotation = 0\n            ellipses.append(\n                [value, axis_1, axis_2, center_x, center_y, rotation])\n    elif ndim == 3:\n        for i in range(nellipses):\n            if alternating:\n                value = (-1.0 + 2.0 * (i % 2))\n            else:\n                value = 1.0\n\n            axis_1 = axis_2 = 0.5\n            axis_3 = 0.5 / (nellipses + 1)\n            center_x = center_y = 0.0\n            center_z = -1 + 2.0 / (nellipses + 1.0) * (i + 1)\n            rotation_phi = rotation_theta = rotation_psi = 0\n\n            ellipses.append(\n                [value, axis_1, axis_2, axis_3,\n                 center_x, center_y, center_z,\n                 rotation_phi, rotation_theta, rotation_psi])\n\n    return ellipses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef indicate_proj_axis(space, scale_structures=0.5):\n    if not 0 < scale_structures <= 1:\n        raise ValueError('`scale_structures` ({}) is not in (0, 1]'\n                         ''.format(scale_structures))\n\n    assert space.ndim in (2, 3)\n\n    shape = space.shape\n    phan = np.zeros(shape)\n    shape = np.array(shape) - 1\n    cen = np.round(0.5 * shape)\n    dx = np.floor(scale_structures * 0.25 * shape)\n    dx[dx == 0] = 1\n\n    # cube of size 2 * dx, offset in x axis, symmetric in others\n    ix0 = int((cen - 3 * dx)[0])\n    if space.ndim == 2:\n        ix, iy = (cen - 1 * dx).astype(int)\n        phan[ix0:ix, iy:-iy] = 1\n    elif space.ndim == 3:\n        ix, iy, iz = (cen - 1 * dx).astype(int)\n        phan[ix0:ix, iy:-iy, iz:-iz] = 1\n\n    # 1st cuboid of size (dx[0], dx[1], 2 * dx[2]), offset in x and y axes,\n    # symmetric in z axis\n    ix0 = int((cen + 1 * dx)[1])\n    ix1 = int((cen + 2 * dx)[1])\n    iy0 = int(cen[1])\n    if space.ndim == 2:\n        phan[ix0:ix1, iy0:-iy] = 1\n    elif space.ndim == 3:\n        iz = int((cen - dx)[2])\n        phan[ix0:ix1, iy0:-iy, iz:-iz] = 1\n\n    # 2nd cuboid of (dx[0], dx[1], 2 * dx[2]) touching the first diagonally\n    # at a long edge; offset in x and y axes, symmetric in z axis\n    ix0 = int((cen + 2 * dx)[1])\n    ix1 = int((cen + 3 * dx)[1])\n    iy1 = int(cen[1])\n    if space.ndim == 2:\n        phan[ix0:ix1, iy:iy1] = 1\n    elif space.ndim == 3:\n        iz = int((cen - dx)[2])\n        phan[ix0:ix1, iy:iy1, iz:-iz] = 1\n\n    return space.element(phan)", "response": "This function creates a 2D phantom that indicates along which axis it is projected."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getshapes_2d(center, max_radius, shape):\n    index_mean = shape * center\n    index_radius = max_radius / 2.0 * np.array(shape)\n\n    # Avoid negative indices\n    min_idx = np.maximum(np.floor(index_mean - index_radius), 0).astype(int)\n    max_idx = np.ceil(index_mean + index_radius).astype(int)\n    idx = [slice(minx, maxx) for minx, maxx in zip(min_idx, max_idx)]\n    shapes = [(idx[0], slice(None)),\n              (slice(None), idx[1])]\n    return tuple(idx), tuple(shapes)", "response": "Calculate indices and slices for the bounding box of a disk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a 2D ellipse phantom of ellipses in 2d space.", "response": "def _ellipse_phantom_2d(space, ellipses):\n    \"\"\"Create a phantom of ellipses in 2d space.\n\n    Parameters\n    ----------\n    space : `DiscreteLp`\n        Uniformly discretized space in which the phantom should be generated.\n        If ``space.shape`` is 1 in an axis, a corresponding slice of the\n        phantom is created (instead of squashing the whole phantom into the\n        slice).\n    ellipses : list of lists\n        Each row should contain the entries ::\n\n            'value',\n            'axis_1', 'axis_2',\n            'center_x', 'center_y',\n            'rotation'\n\n        The provided ellipses need to be specified relative to the\n        reference rectangle ``[-1, -1] x [1, 1]``. Angles are to be given\n        in radians.\n\n    Returns\n    -------\n    phantom : ``space`` element\n        2D ellipse phantom in ``space``.\n\n    See Also\n    --------\n    shepp_logan : The typical use-case for this function.\n    \"\"\"\n    # Blank image\n    p = np.zeros(space.shape, dtype=space.dtype)\n\n    minp = space.grid.min_pt\n    maxp = space.grid.max_pt\n\n    # Create the pixel grid\n    grid_in = space.grid.meshgrid\n\n    # move points to [-1, 1]\n    grid = []\n    for i in range(2):\n        mean_i = (minp[i] + maxp[i]) / 2.0\n        # Where space.shape = 1, we have minp = maxp, so we set diff_i = 1\n        # to avoid division by zero. Effectively, this allows constructing\n        # a slice of a 2D phantom.\n        diff_i = (maxp[i] - minp[i]) / 2.0 or 1.0\n        grid.append((grid_in[i] - mean_i) / diff_i)\n\n    for ellip in ellipses:\n        assert len(ellip) == 6\n\n        intensity = ellip[0]\n        a_squared = ellip[1] ** 2\n        b_squared = ellip[2] ** 2\n        x0 = ellip[3]\n        y0 = ellip[4]\n        theta = ellip[5]\n\n        scales = [1 / a_squared, 1 / b_squared]\n        center = (np.array([x0, y0]) + 1.0) / 2.0\n\n        # Create the offset x,y and z values for the grid\n        if theta != 0:\n            # Rotate the points to the expected coordinate system.\n            ctheta = np.cos(theta)\n            stheta = np.sin(theta)\n\n            mat = np.array([[ctheta, stheta],\n                            [-stheta, ctheta]])\n\n            # Calculate the points that could possibly be inside the volume\n            # Since the points are rotated, we cannot do anything directional\n            # without more logic\n            max_radius = np.sqrt(\n                np.abs(mat).dot([a_squared, b_squared]))\n            idx, shapes = _getshapes_2d(center, max_radius, space.shape)\n\n            subgrid = [g[idi] for g, idi in zip(grid, shapes)]\n            offset_points = [vec * (xi - x0i)[..., None]\n                             for xi, vec, x0i in zip(subgrid,\n                                                     mat.T,\n                                                     [x0, y0])]\n            rotated = offset_points[0] + offset_points[1]\n            np.square(rotated, out=rotated)\n            radius = np.dot(rotated, scales)\n        else:\n            # Calculate the points that could possibly be inside the volume\n            max_radius = np.sqrt([a_squared, b_squared])\n            idx, shapes = _getshapes_2d(center, max_radius, space.shape)\n\n            subgrid = [g[idi] for g, idi in zip(grid, shapes)]\n            squared_dist = [ai * (xi - x0i) ** 2\n                            for xi, ai, x0i in zip(subgrid,\n                                                   scales,\n                                                   [x0, y0])]\n\n            # Parentheses to get best order for broadcasting\n            radius = squared_dist[0] + squared_dist[1]\n\n        # Find the points within the ellipse\n        inside = radius <= 1\n\n        # Add the ellipse intensity to those points\n        p[idx][inside] += intensity\n\n    return space.element(p)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ellipsoid_phantom_3d(space, ellipsoids):\n    # Blank volume\n    p = np.zeros(space.shape, dtype=space.dtype)\n\n    minp = space.grid.min_pt\n    maxp = space.grid.max_pt\n\n    # Create the pixel grid\n    grid_in = space.grid.meshgrid\n\n    # Move points to [-1, 1]\n    grid = []\n    for i in range(3):\n        mean_i = (minp[i] + maxp[i]) / 2.0\n        # Where space.shape = 1, we have minp = maxp, so we set diff_i = 1\n        # to avoid division by zero. Effectively, this allows constructing\n        # a slice of a 3D phantom.\n        diff_i = (maxp[i] - minp[i]) / 2.0 or 1.0\n        grid.append((grid_in[i] - mean_i) / diff_i)\n\n    for ellip in ellipsoids:\n        assert len(ellip) == 10\n\n        intensity = ellip[0]\n        a_squared = ellip[1] ** 2\n        b_squared = ellip[2] ** 2\n        c_squared = ellip[3] ** 2\n        x0 = ellip[4]\n        y0 = ellip[5]\n        z0 = ellip[6]\n        phi = ellip[7]\n        theta = ellip[8]\n        psi = ellip[9]\n\n        scales = [1 / a_squared, 1 / b_squared, 1 / c_squared]\n        center = (np.array([x0, y0, z0]) + 1.0) / 2.0\n\n        # Create the offset x,y and z values for the grid\n        if any([phi, theta, psi]):\n            # Rotate the points to the expected coordinate system.\n            cphi = np.cos(phi)\n            sphi = np.sin(phi)\n            ctheta = np.cos(theta)\n            stheta = np.sin(theta)\n            cpsi = np.cos(psi)\n            spsi = np.sin(psi)\n\n            mat = np.array([[cpsi * cphi - ctheta * sphi * spsi,\n                             cpsi * sphi + ctheta * cphi * spsi,\n                             spsi * stheta],\n                            [-spsi * cphi - ctheta * sphi * cpsi,\n                             -spsi * sphi + ctheta * cphi * cpsi,\n                             cpsi * stheta],\n                            [stheta * sphi,\n                             -stheta * cphi,\n                             ctheta]])\n\n            # Calculate the points that could possibly be inside the volume\n            # Since the points are rotated, we cannot do anything directional\n            # without more logic\n            max_radius = np.sqrt(\n                np.abs(mat).dot([a_squared, b_squared, c_squared]))\n            idx, shapes = _getshapes_3d(center, max_radius, space.shape)\n\n            subgrid = [g[idi] for g, idi in zip(grid, shapes)]\n            offset_points = [vec * (xi - x0i)[..., None]\n                             for xi, vec, x0i in zip(subgrid,\n                                                     mat.T,\n                                                     [x0, y0, z0])]\n            rotated = offset_points[0] + offset_points[1] + offset_points[2]\n            np.square(rotated, out=rotated)\n            radius = np.dot(rotated, scales)\n        else:\n            # Calculate the points that could possibly be inside the volume\n            max_radius = np.sqrt([a_squared, b_squared, c_squared])\n            idx, shapes = _getshapes_3d(center, max_radius, space.shape)\n\n            subgrid = [g[idi] for g, idi in zip(grid, shapes)]\n            squared_dist = [ai * (xi - x0i) ** 2\n                            for xi, ai, x0i in zip(subgrid,\n                                                   scales,\n                                                   [x0, y0, z0])]\n\n            # Parentheses to get best order for broadcasting\n            radius = squared_dist[0] + (squared_dist[1] + squared_dist[2])\n\n        # Find the points within the ellipse\n        inside = radius <= 1\n\n        # Add the ellipse intensity to those points\n        p[idx][inside] += intensity\n\n    return space.element(p)", "response": "Create an ellipsoid phantom in 3d space."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a phantom given by the provided ellipsoids.", "response": "def ellipsoid_phantom(space, ellipsoids, min_pt=None, max_pt=None):\n    \"\"\"Return a phantom given by ellipsoids.\n\n    Parameters\n    ----------\n    space : `DiscreteLp`\n        Space in which the phantom should be created, must be 2- or\n        3-dimensional. If ``space.shape`` is 1 in an axis, a corresponding\n        slice of the phantom is created (instead of squashing the whole\n        phantom into the slice).\n    ellipsoids : sequence of sequences\n        If ``space`` is 2-dimensional, each row should contain the entries ::\n\n            'value',\n            'axis_1', 'axis_2',\n            'center_x', 'center_y',\n            'rotation'\n\n        If ``space`` is 3-dimensional, each row should contain the entries ::\n\n            'value',\n            'axis_1', 'axis_2', 'axis_3',\n            'center_x', 'center_y', 'center_z',\n            'rotation_phi', 'rotation_theta', 'rotation_psi'\n\n        The provided ellipsoids need to be specified relative to the\n        reference rectangle ``[-1, -1] x [1, 1]``, or analogously in 3d.\n        The angles are to be given in radians.\n\n    min_pt, max_pt : array-like, optional\n        If provided, use these vectors to determine the bounding box of the\n        phantom instead of ``space.min_pt`` and ``space.max_pt``.\n        It is currently required that ``min_pt >= space.min_pt`` and\n        ``max_pt <= space.max_pt``, i.e., shifting or scaling outside the\n        original space is not allowed.\n\n        Providing one of them results in a shift, e.g., for ``min_pt``::\n\n            new_min_pt = min_pt\n            new_max_pt = space.max_pt + (min_pt - space.min_pt)\n\n        Providing both results in a scaled version of the phantom.\n\n    Notes\n    -----\n    The phantom is created by adding the values of each ellipse. The\n    ellipses are defined by a center point\n    ``(center_x, center_y, [center_z])``, the lengths of its principial\n    axes ``(axis_1, axis_2, [axis_2])``, and a rotation angle ``rotation``\n    in 2D or Euler angles ``(rotation_phi, rotation_theta, rotation_psi)``\n    in 3D.\n\n    This function is heavily optimized, achieving runtimes about 20 times\n    faster than \"trivial\" implementations. It is therefore recommended to use\n    it in all phantoms where applicable.\n\n    The main optimization is that it only considers a subset of all the\n    points when updating for each ellipse. It does this by first finding\n    a subset of points that could possibly be inside the ellipse. This\n    optimization is very good for \"spherical\" ellipsoids, but not so\n    much for elongated or rotated ones.\n\n    It also does calculations wherever possible on the meshgrid instead of\n    individual points.\n\n    Examples\n    --------\n    Create a circle with a smaller circle inside:\n\n    >>> space = odl.uniform_discr([-1, -1], [1, 1], [5, 5])\n    >>> ellipses = [[1.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n    ...             [1.0, 0.6, 0.6, 0.0, 0.0, 0.0]]\n    >>> print(ellipsoid_phantom(space, ellipses))\n    [[ 0.,  0.,  1.,  0.,  0.],\n     [ 0.,  1.,  2.,  1.,  0.],\n     [ 1.,  2.,  2.,  2.,  1.],\n     [ 0.,  1.,  2.,  1.,  0.],\n     [ 0.,  0.,  1.,  0.,  0.]]\n\n    See Also\n    --------\n    odl.phantom.transmission.shepp_logan : Classical Shepp-Logan phantom,\n        typically used for transmission imaging\n    odl.phantom.transmission.shepp_logan_ellipsoids : Ellipses for the\n        Shepp-Logan phantom\n    odl.phantom.geometric.defrise_ellipses : Ellipses for the\n        Defrise phantom\n    \"\"\"\n    if space.ndim == 2:\n        _phantom = _ellipse_phantom_2d\n    elif space.ndim == 3:\n        _phantom = _ellipsoid_phantom_3d\n    else:\n        raise ValueError('dimension not 2 or 3, no phantom available')\n\n    if min_pt is None and max_pt is None:\n        return _phantom(space, ellipsoids)\n\n    else:\n        # Generate a temporary space with given `min_pt` and `max_pt`\n        # (snapped to the cell grid), create the phantom in that space and\n        # resize to the target size for `space`.\n        # The snapped points are constructed by finding the index of\n        # `min/max_pt` in the space partition, indexing the partition with\n        # that index, yielding a single-cell partition, and then taking\n        # the lower-left/upper-right corner of that cell.\n        if min_pt is None:\n            snapped_min_pt = space.min_pt\n        else:\n            min_pt_cell = space.partition[space.partition.index(min_pt)]\n            snapped_min_pt = min_pt_cell.min_pt\n\n        if max_pt is None:\n            snapped_max_pt = space.max_pt\n        else:\n            max_pt_cell = space.partition[space.partition.index(max_pt)]\n            snapped_max_pt = max_pt_cell.max_pt\n            # Avoid snapping to the next cell where max_pt falls exactly on\n            # a boundary\n            for i in range(space.ndim):\n                if max_pt[i] in space.partition.cell_boundary_vecs[i]:\n                    snapped_max_pt[i] = max_pt[i]\n\n        tmp_space = uniform_discr_fromdiscr(\n            space, min_pt=snapped_min_pt, max_pt=snapped_max_pt,\n            cell_sides=space.cell_sides)\n\n        tmp_phantom = _phantom(tmp_space, ellipsoids)\n        offset = space.partition.index(tmp_space.min_pt)\n        return space.element(\n            resize_array(tmp_phantom, space.shape, offset))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef smooth_cuboid(space, min_pt=None, max_pt=None, axis=0):\n    dom_min_pt = space.domain.min()\n    dom_max_pt = space.domain.max()\n\n    if min_pt is None:\n        min_pt = dom_min_pt * 0.75 + dom_max_pt * 0.25\n    if max_pt is None:\n        max_pt = dom_min_pt * 0.25 + dom_max_pt * 0.75\n\n    min_pt = np.atleast_1d(min_pt)\n    max_pt = np.atleast_1d(max_pt)\n\n    axis = np.array(axis, dtype=int, ndmin=1)\n\n    if min_pt.shape != (space.ndim,):\n        raise ValueError('shape of `min_pt` must be {}, got {}'\n                         ''.format((space.ndim,), min_pt.shape))\n    if max_pt.shape != (space.ndim,):\n        raise ValueError('shape of `max_pt` must be {}, got {}'\n                         ''.format((space.ndim,), max_pt.shape))\n\n    sign = 0\n    for i, coord in enumerate(space.meshgrid):\n        sign = sign | (coord < min_pt[i]) | (coord > max_pt[i])\n\n    values = 0\n    for i in axis:\n        coord = space.meshgrid[i]\n        extent = (dom_max_pt[i] - dom_min_pt[i])\n        values = values + 2 * (coord - dom_min_pt[i]) / extent - 1\n\n    # Properly scale using sign\n    sign = (3 * sign - 2) / axis.size\n\n    # Fit in [0, 1]\n    values = values * sign\n    values = (values - np.min(values)) / (np.max(values) - np.min(values))\n\n    return space.element(values)", "response": "Returns a new cuboid with smooth variations."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tgv_phantom(space, edge_smoothing=0.2):\n    if space.ndim != 2:\n        raise ValueError('`space.ndim` must be 2, got {}'\n                         ''.format(space.ndim))\n\n    y, x = space.meshgrid\n\n    # Use a smooth sigmoid to get some anti-aliasing across edges.\n    scale = edge_smoothing / np.min(space.shape)\n\n    def sigmoid(val):\n        if edge_smoothing != 0:\n            val = val / scale\n            return 1 / (1 + np.exp(-val))\n        else:\n            return (val > 0).astype(val.dtype)\n\n    # Normalize to [0, 1]\n    x = (x - np.min(x)) / (np.max(x) - np.min(x))\n    y = (y - np.min(y)) / (np.max(y) - np.min(y))\n\n    # Background\n    values = -(x + y) / 2\n\n    # Square-ish region\n    indicator = np.ones(space.shape)\n    indicator *= sigmoid(-(0.015199034981905914 * x - y + 0.13896260554885403))\n    indicator *= sigmoid((0.3333333333333323 * y - x + 0.598958333333334))\n    indicator *= sigmoid((-2.4193548387096726 * y - x + 2.684979838709672))\n\n    values += indicator * 2 * (x + y - 1)\n\n    # Ellipse part\n    x_c = x - 0.71606842360499456\n    y_c = y - 0.18357884949910641\n\n    width = 0.55677657235995637\n    height = 0.37279391542283741\n    phi = 0.62911754900697558\n\n    x_c_rot = (np.cos(phi) * x_c - np.sin(phi) * y_c) / width\n    y_c_rot = (np.sin(phi) * x_c + np.cos(phi) * y_c) / height\n\n    indicator = sigmoid(np.sqrt(x_c_rot ** 2 + y_c_rot ** 2) - 1)\n\n    values = indicator * values + 1.5 * (1 - indicator) * (-x - 2 * y + 0.6)\n\n    # Normalize values\n    values = (values - np.min(values)) / (np.max(values) - np.min(values))\n\n    return space.element(values)", "response": "Generate a piecewise affine phantom."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_objective(x):\n    value = 0\n    for minp, maxp in rectangles:\n        x_proj = np.minimum(np.maximum(x, minp), maxp)\n        value += (x - x_proj).norm()\n    print('Point = [{:.4f}, {:.4f}], Value = {:.4f}'.format(x[0], x[1], value))", "response": "Calculate the objective value and prints it."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a sparse meshgrid by adding empty dimensions.", "response": "def sparse_meshgrid(*x):\n    \"\"\"Make a sparse `meshgrid` by adding empty dimensions.\n\n    Parameters\n    ----------\n    x1,...,xN : `array-like`\n        Input arrays to turn into sparse meshgrid vectors.\n\n    Returns\n    -------\n    meshgrid : tuple of `numpy.ndarray`'s\n        Sparse coordinate vectors representing an N-dimensional grid.\n\n    See Also\n    --------\n    numpy.meshgrid : dense or sparse meshgrids\n\n    Examples\n    --------\n    >>> x, y = [0, 1], [2, 3, 4]\n    >>> mesh = sparse_meshgrid(x, y)\n    >>> sum(xi for xi in mesh).ravel()  # first axis slowest\n    array([2, 3, 4, 3, 4, 5])\n    \"\"\"\n    n = len(x)\n    mesh = []\n    for ax, xi in enumerate(x):\n        xi = np.asarray(xi)\n        slc = [None] * n\n        slc[ax] = slice(None)\n        mesh.append(np.ascontiguousarray(xi[tuple(slc)]))\n\n    return tuple(mesh)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a grid from sampling an interval product uniformly.", "response": "def uniform_grid_fromintv(intv_prod, shape, nodes_on_bdry=True):\n    \"\"\"Return a grid from sampling an interval product uniformly.\n\n    The resulting grid will by default include ``intv_prod.min_pt`` and\n    ``intv_prod.max_pt`` as grid points. If you want a subdivision into\n    equally sized cells with grid points in the middle, use\n    `uniform_partition` instead.\n\n    Parameters\n    ----------\n    intv_prod : `IntervalProd`\n        Set to be sampled.\n    shape : int or sequence of ints\n        Number of nodes per axis. Entries corresponding to degenerate axes\n        must be equal to 1.\n    nodes_on_bdry : bool or sequence, optional\n        If a sequence is provided, it determines per axis whether to\n        place the last grid point on the boundary (``True``) or shift it\n        by half a cell size into the interior (``False``). In each axis,\n        an entry may consist in a single bool or a 2-tuple of\n        bool. In the latter case, the first tuple entry decides for\n        the left, the second for the right boundary. The length of the\n        sequence must be ``array.ndim``.\n\n        A single boolean is interpreted as a global choice for all\n        boundaries.\n\n    Returns\n    -------\n    sampling : `RectGrid`\n        Uniform sampling grid for the interval product.\n\n    Examples\n    --------\n    >>> rbox = odl.IntervalProd([-1.5, 2], [-0.5, 3])\n    >>> grid = uniform_grid_fromintv(rbox, (3, 3))\n    >>> grid.coord_vectors\n    (array([-1.5, -1. , -0.5]), array([ 2. ,  2.5,  3. ]))\n\n    To have the nodes in the \"middle\", use ``nodes_on_bdry=False``:\n\n    >>> grid = uniform_grid_fromintv(rbox, (2, 2), nodes_on_bdry=False)\n    >>> grid.coord_vectors\n    (array([-1.25, -0.75]), array([ 2.25,  2.75]))\n\n    See Also\n    --------\n    uniform_grid : Create a uniform grid directly.\n    odl.discr.partition.uniform_partition_fromintv :\n        divide interval product into equally sized subsets\n    \"\"\"\n    if not isinstance(intv_prod, IntervalProd):\n        raise TypeError('{!r} is not an `IntervalProd` instance'\n                        ''.format(intv_prod))\n\n    if (np.any(np.isinf(intv_prod.min_pt)) or\n            np.any(np.isinf(intv_prod.max_pt))):\n        raise ValueError('`intv_prod` must be finite, got {!r}'\n                         ''.format('intv_prod'))\n\n    shape = normalized_scalar_param_list(shape, intv_prod.ndim, safe_int_conv)\n\n    if np.shape(nodes_on_bdry) == ():\n        nodes_on_bdry = ([(bool(nodes_on_bdry), bool(nodes_on_bdry))] *\n                         intv_prod.ndim)\n    elif intv_prod.ndim == 1 and len(nodes_on_bdry) == 2:\n        nodes_on_bdry = [nodes_on_bdry]\n    elif len(nodes_on_bdry) != intv_prod.ndim:\n        raise ValueError('`nodes_on_bdry` has length {}, expected {}'\n                         ''.format(len(nodes_on_bdry), intv_prod.ndim))\n    else:\n        shape = tuple(int(n) for n in shape)\n\n    # We need to determine the placement of the grid minimum and maximum\n    # points based on the choices in nodes_on_bdry. If in a given axis,\n    # and for a given side (left or right), the entry is True, the node lies\n    # on the boundary, so this coordinate can simply be taken as-is.\n    #\n    # Otherwise, the following conditions must be met:\n    #\n    # 1. The node should be half a stride s away from the boundary\n    # 2. Adding or subtracting (n-1)*s should give the other extremal node.\n    #\n    # If both nodes are to be shifted half a stride inside,\n    # the second condition yields\n    # a + s/2 + (n-1)*s = b - s/2 => s = (b - a) / n,\n    # hence the extremal grid points are\n    # gmin = a + s/2 = a + (b - a) / (2 * n),\n    # gmax = b - s/2 = b - (b - a) / (2 * n).\n    #\n    # In the case where one node, say the rightmost, lies on the boundary,\n    # the condition 2. reads as\n    # a + s/2 + (n-1)*s = b => s = (b - a) / (n - 1/2),\n    # thus\n    # gmin = a + (b - a) / (2 * n - 1).\n\n    gmin, gmax = [], []\n    for n, xmin, xmax, on_bdry in zip(shape, intv_prod.min_pt,\n                                      intv_prod.max_pt, nodes_on_bdry):\n\n        # Unpack the tuple if possible, else use bool globally for this axis\n        try:\n            bdry_l, bdry_r = on_bdry\n        except TypeError:\n            bdry_l = bdry_r = on_bdry\n\n        if bdry_l and bdry_r:\n            gmin.append(xmin)\n            gmax.append(xmax)\n        elif bdry_l and not bdry_r:\n            gmin.append(xmin)\n            gmax.append(xmax - (xmax - xmin) / (2 * n - 1))\n        elif not bdry_l and bdry_r:\n            gmin.append(xmin + (xmax - xmin) / (2 * n - 1))\n            gmax.append(xmax)\n        else:\n            gmin.append(xmin + (xmax - xmin) / (2 * n))\n            gmax.append(xmax - (xmax - xmin) / (2 * n))\n\n    # Create the grid\n    coord_vecs = [np.linspace(mi, ma, num, endpoint=True, dtype=np.float64)\n                  for mi, ma, num in zip(gmin, gmax, shape)]\n    return RectGrid(*coord_vecs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uniform_grid(min_pt, max_pt, shape, nodes_on_bdry=True):\n    return uniform_grid_fromintv(IntervalProd(min_pt, max_pt), shape,\n                                 nodes_on_bdry=nodes_on_bdry)", "response": "Return a uniform grid from sampling an implicit interval product uniformly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnumbering of dimensions of the grid.", "response": "def ndim(self):\n        \"\"\"Number of dimensions of the grid.\"\"\"\n        try:\n            return self.__ndim\n        except AttributeError:\n            ndim = len(self.coord_vectors)\n            self.__ndim = ndim\n            return ndim"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the shape of the grid points per axis.", "response": "def shape(self):\n        \"\"\"Number of grid points per axis.\"\"\"\n        try:\n            return self.__shape\n        except AttributeError:\n            shape = tuple(len(vec) for vec in self.coord_vectors)\n            self.__shape = shape\n            return shape"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntotal number of grid points in the archive.", "response": "def size(self):\n        \"\"\"Total number of grid points.\"\"\"\n        # Since np.prod(()) == 1.0 we need to handle that by ourselves\n        return (0 if self.shape == () else\n                int(np.prod(self.shape, dtype='int64')))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef min(self, **kwargs):\n        out = kwargs.get('out', None)\n        if out is not None:\n            out[:] = self.min_pt\n            return out\n        else:\n            return self.min_pt", "response": "Return the minimum value of the set of keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef max(self, **kwargs):\n        out = kwargs.get('out', None)\n        if out is not None:\n            out[:] = self.max_pt\n            return out\n        else:\n            return self.max_pt", "response": "Return `max_pt`.\n\n        Parameters\n        ----------\n        kwargs\n            For duck-typing with `numpy.amax`\n\n        See Also\n        --------\n        min\n        odl.set.domain.IntervalProd.max\n\n        Examples\n        --------\n        >>> g = RectGrid([1, 2, 5], [-2, 1.5, 2])\n        >>> g.max()\n        array([ 5.,  2.])\n\n        Also works with Numpy:\n\n        >>> np.max(g)\n        array([ 5.,  2.])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a numpy array of the stride of the current region.", "response": "def stride(self):\n        \"\"\"Step per axis between neighboring points of a uniform grid.\n\n        If the grid contains axes that are not uniform, ``stride`` has\n        a ``NaN`` entry.\n\n        For degenerate (length 1) axes, ``stride`` has value ``0.0``.\n\n        Returns\n        -------\n        stride : numpy.array\n            Array of dtype ``float`` and length `ndim`.\n\n        Examples\n        --------\n        >>> rg = uniform_grid([-1.5, -1], [-0.5, 3], (2, 3))\n        >>> rg.stride\n        array([ 1.,  2.])\n\n        NaN returned for non-uniform dimension:\n\n        >>> g = RectGrid([0, 1, 2], [0, 1, 4])\n        >>> g.stride\n        array([ 1.,  nan])\n\n        0.0 returned for degenerate dimension:\n\n        >>> g = RectGrid([0, 1, 2], [0])\n        >>> g.stride\n        array([ 1.,  0.])\n        \"\"\"\n        # Cache for efficiency instead of re-computing\n        if self.__stride is None:\n            strd = []\n            for i in range(self.ndim):\n                if not self.is_uniform_byaxis[i]:\n                    strd.append(float('nan'))\n                elif self.nondegen_byaxis[i]:\n                    strd.append(self.extent[i] / (self.shape[i] - 1.0))\n                else:\n                    strd.append(0.0)\n            self.__stride = np.array(strd)\n\n        return self.__stride.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef approx_equals(self, other, atol):\n        if other is self:\n            return True\n\n        return (type(other) is type(self) and\n                self.ndim == other.ndim and\n                self.shape == other.shape and\n                all(np.allclose(vec_s, vec_o, atol=atol, rtol=0.0)\n                    for (vec_s, vec_o) in zip(self.coord_vectors,\n                                              other.coord_vectors)))", "response": "Test if this grid is equal to another grid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef approx_contains(self, other, atol):\n        other = np.atleast_1d(other)\n        return (other.shape == (self.ndim,) and\n                all(np.any(np.isclose(vector, coord, atol=atol, rtol=0.0))\n                    for vector, coord in zip(self.coord_vectors, other)))", "response": "Test if this grid contains other."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if this grid is a subgrid of other.", "response": "def is_subgrid(self, other, atol=0.0):\n        \"\"\"Return ``True`` if this grid is a subgrid of ``other``.\n\n        Parameters\n        ----------\n        other :  `RectGrid`\n            The other grid which is supposed to contain this grid\n        atol : float, optional\n            Allow deviations up to this number in absolute value\n            per coordinate vector entry.\n\n        Returns\n        -------\n        is_subgrid : bool\n            ``True`` if all coordinate vectors of ``self`` are within\n            absolute distance ``atol`` of the other grid, else ``False``.\n\n        Examples\n        --------\n        >>> rg = uniform_grid([-2, -2], [0, 4], (3, 4))\n        >>> rg.coord_vectors\n        (array([-2., -1.,  0.]), array([-2.,  0.,  2.,  4.]))\n        >>> rg_sub = uniform_grid([-1, 2], [0, 4], (2, 2))\n        >>> rg_sub.coord_vectors\n        (array([-1.,  0.]), array([ 2.,  4.]))\n        >>> rg_sub.is_subgrid(rg)\n        True\n\n        Fuzzy check is also possible. Note that the tolerance still\n        applies to the coordinate vectors.\n\n        >>> rg_sub = uniform_grid([-1.015, 2], [0, 3.99], (2, 2))\n        >>> rg_sub.is_subgrid(rg, atol=0.01)\n        False\n        >>> rg_sub.is_subgrid(rg, atol=0.02)\n        True\n        \"\"\"\n        # Optimization for some common cases\n        if other is self:\n            return True\n        if not isinstance(other, RectGrid):\n            return False\n        if not all(self.shape[i] <= other.shape[i] and\n                   self.min_pt[i] >= other.min_pt[i] - atol and\n                   self.max_pt[i] <= other.max_pt[i] + atol\n                   for i in range(self.ndim)):\n            return False\n        if self.size == 0:\n            return True\n\n        if self.is_uniform and other.is_uniform:\n            # For uniform grids, it suffices to show that min_pt, max_pt\n            # and g[1,...,1] are contained in the other grid. For axes\n            # with less than 2 points, this reduces to min_pt and max_pt,\n            # and the corresponding indices in the other check point are\n            # set to 0.\n            minmax_contained = (\n                other.approx_contains(self.min_pt, atol=atol) and\n                other.approx_contains(self.max_pt, atol=atol))\n            check_idx = np.zeros(self.ndim, dtype=int)\n            check_idx[np.array(self.shape) >= 3] = 1\n            checkpt_contained = other.approx_contains(self[tuple(check_idx)],\n                                                      atol=atol)\n            return minmax_contained and checkpt_contained\n\n        else:\n            # Array version of the fuzzy subgrid test, about 3 times faster\n            # than the loop version.\n            for vec_o, vec_s in zip(other.coord_vectors, self.coord_vectors):\n                # Create array of differences of all entries in vec_o and\n                # vec_s. If there is no almost zero entry in each row,\n                # return False.\n                vec_o_mg, vec_s_mg = sparse_meshgrid(vec_o, vec_s)\n                if not np.all(np.any(np.isclose(vec_s_mg, vec_o_mg, atol=atol),\n                                     axis=0)):\n                    return False\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy with grids inserted before index.", "response": "def insert(self, index, *grids):\n        \"\"\"Return a copy with ``grids`` inserted before ``index``.\n\n        The given grids are inserted (as a block) into ``self``, yielding\n        a new grid whose number of dimensions is the sum of the numbers of\n        dimensions of all involved grids.\n        Note that no changes are made in-place.\n\n        Parameters\n        ----------\n        index : int\n            The index of the dimension before which ``grids`` are to\n            be inserted. Negative indices count backwards from\n            ``self.ndim``.\n        grid1, ..., gridN :  `RectGrid`\n            The grids to be inserted into ``self``.\n\n        Returns\n        -------\n        newgrid : `RectGrid`\n            The enlarged grid.\n\n        Examples\n        --------\n        >>> g1 = RectGrid([0, 1], [-1, 0, 2])\n        >>> g2 = RectGrid([1], [-6, 15])\n        >>> g1.insert(1, g2)\n        RectGrid(\n            [ 0.,  1.],\n            [ 1.],\n            [ -6.,  15.],\n            [-1.,  0.,  2.]\n        )\n        >>> g1.insert(1, g2, g2)\n        RectGrid(\n            [ 0.,  1.],\n            [ 1.],\n            [ -6.,  15.],\n            [ 1.],\n            [ -6.,  15.],\n            [-1.,  0.,  2.]\n        )\n\n        See Also\n        --------\n        append\n        \"\"\"\n        index, index_in = safe_int_conv(index), index\n        if not -self.ndim <= index <= self.ndim:\n            raise IndexError('index {0} outside the valid range -{1} ... {1}'\n                             ''.format(index_in, self.ndim))\n        if index < 0:\n            index += self.ndim\n\n        if len(grids) == 0:\n            # Copy of `self`\n            return RectGrid(*self.coord_vectors)\n        elif len(grids) == 1:\n            # Insert single grid\n            grid = grids[0]\n            if not isinstance(grid, RectGrid):\n                raise TypeError('{!r} is not a `RectGrid` instance'\n                                ''.format(grid))\n            new_vecs = (self.coord_vectors[:index] + grid.coord_vectors +\n                        self.coord_vectors[index:])\n            return RectGrid(*new_vecs)\n        else:\n            # Recursively insert first grid and the remaining into the result\n            return self.insert(index, grids[0]).insert(\n                index + grids[0].ndim, *(grids[1:]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef squeeze(self, axis=None):\n        if axis is None:\n            rng = range(self.ndim)\n        else:\n            rng = list(np.atleast_1d(np.arange(self.ndim)[axis]))\n\n        new_indcs = [i for i in range(self.ndim)\n                     if i not in rng or self.nondegen_byaxis[i]]\n        coord_vecs = [self.coord_vectors[axis] for axis in new_indcs]\n        return RectGrid(*coord_vecs)", "response": "Return the grid with removed degenerate ( length 1 ) dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef corner_grid(self):\n        minmax_vecs = []\n        for axis in range(self.ndim):\n            if self.shape[axis] == 1:\n                minmax_vecs.append(self.coord_vectors[axis][0])\n            else:\n                minmax_vecs.append((self.coord_vectors[axis][0],\n                                    self.coord_vectors[axis][-1]))\n\n        return RectGrid(*minmax_vecs)", "response": "Return a grid with only the corner points."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finite_diff(f, axis, dx=1.0, method='forward', out=None, **kwargs):\n    f_arr = np.asarray(f)\n    ndim = f_arr.ndim\n\n    if f_arr.shape[axis] < 2:\n        raise ValueError('in axis {}: at least two elements required, got {}'\n                         ''.format(axis, f_arr.shape[axis]))\n\n    if axis < 0:\n        axis += ndim\n    if not (0 <= axis < ndim):\n        raise IndexError('`axis` {} outside the valid range 0 ... {}'\n                         ''.format(axis, ndim - 1))\n\n    dx, dx_in = float(dx), dx\n    if dx <= 0 or not np.isfinite(dx):\n        raise ValueError(\"`dx` must be positive, got {}\".format(dx_in))\n\n    method, method_in = str(method).lower(), method\n    if method not in _SUPPORTED_DIFF_METHODS:\n        raise ValueError('`method` {} was not understood'.format(method_in))\n\n    pad_mode = kwargs.pop('pad_mode', 'constant')\n    if pad_mode not in _SUPPORTED_PAD_MODES:\n        raise ValueError('`pad_mode` {} not understood'\n                         ''.format(pad_mode))\n\n    pad_const = kwargs.pop('pad_const', 0)\n    pad_const = f.dtype.type(pad_const)\n\n    if out is None:\n        out = np.empty_like(f_arr)\n    else:\n        if out.shape != f.shape:\n            raise ValueError('expected output shape {}, got {}'\n                             ''.format(f.shape, out.shape))\n\n    if f_arr.shape[axis] < 2 and pad_mode == 'order1':\n        raise ValueError(\"size of array to small to use 'order1', needs at \"\n                         \"least 2 elements along axis {}.\".format(axis))\n    if f_arr.shape[axis] < 3 and pad_mode == 'order2':\n        raise ValueError(\"size of array to small to use 'order2', needs at \"\n                         \"least 3 elements along axis {}.\".format(axis))\n\n    if kwargs:\n        raise ValueError('unkown keyword argument(s): {}'.format(kwargs))\n\n    # create slice objects: initially all are [:, :, ..., :]\n\n    # Swap axes so that the axis of interest is first. This is a O(1)\n    # operation and is done to simplify the code below.\n    out, out_in = np.swapaxes(out, 0, axis), out\n    f_arr = np.swapaxes(f_arr, 0, axis)\n\n    # Interior of the domain of f\n    if method == 'central':\n        # 1D equivalent: out[1:-1] = (f[2:] - f[:-2])/2.0\n        np.subtract(f_arr[2:], f_arr[:-2], out=out[1:-1])\n        out[1:-1] /= 2.0\n\n    elif method == 'forward':\n        # 1D equivalent: out[1:-1] = (f[2:] - f[1:-1])\n        np.subtract(f_arr[2:], f_arr[1:-1], out=out[1:-1])\n\n    elif method == 'backward':\n        # 1D equivalent: out[1:-1] = (f[1:-1] - f[:-2])\n        np.subtract(f_arr[1:-1], f_arr[:-2], out=out[1:-1])\n\n    # Boundaries\n    if pad_mode == 'constant':\n        # Assume constant value c for indices outside the domain of ``f``\n\n        # With padding the method used on endpoints is the same as in the\n        # interior of the domain of f\n\n        if method == 'central':\n            out[0] = (f_arr[1] - pad_const) / 2.0\n            out[-1] = (pad_const - f_arr[-2]) / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[1] - f_arr[0]\n            out[-1] = pad_const - f_arr[-1]\n\n        elif method == 'backward':\n            out[0] = f_arr[0] - pad_const\n            out[-1] = f_arr[-1] - f_arr[-2]\n\n    elif pad_mode == 'symmetric':\n        # Values of f for indices outside the domain of f are replicates of\n        # the edge values\n\n        # With padding the method used on endpoints is the same as in the\n        # interior of the domain of f\n\n        if method == 'central':\n            out[0] = (f_arr[1] - f_arr[0]) / 2.0\n            out[-1] = (f_arr[-1] - f_arr[-2]) / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[1] - f_arr[0]\n            out[-1] = 0\n\n        elif method == 'backward':\n            out[0] = 0\n            out[-1] = f_arr[-1] - f_arr[-2]\n\n    elif pad_mode == 'symmetric_adjoint':\n        # The adjoint case of symmetric\n\n        if method == 'central':\n            out[0] = (f_arr[1] + f_arr[0]) / 2.0\n            out[-1] = (-f_arr[-1] - f_arr[-2]) / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[1]\n            out[-1] = -f_arr[-1]\n\n        elif method == 'backward':\n            out[0] = f_arr[0]\n            out[-1] = -f_arr[-2]\n\n    elif pad_mode == 'periodic':\n        # Values of f for indices outside the domain of f are replicates of\n        # the edge values on the other side\n\n        if method == 'central':\n            out[0] = (f_arr[1] - f_arr[-1]) / 2.0\n            out[-1] = (f_arr[0] - f_arr[-2]) / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[1] - f_arr[0]\n            out[-1] = f_arr[0] - f_arr[-1]\n\n        elif method == 'backward':\n            out[0] = f_arr[0] - f_arr[-1]\n            out[-1] = f_arr[-1] - f_arr[-2]\n\n    elif pad_mode == 'order0':\n        # Values of f for indices outside the domain of f are replicates of\n        # the edge value.\n\n        if method == 'central':\n            out[0] = (f_arr[1] - f_arr[0]) / 2.0\n            out[-1] = (f_arr[-1] - f_arr[-2]) / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[1] - f_arr[0]\n            out[-1] = 0\n\n        elif method == 'backward':\n            out[0] = 0\n            out[-1] = f_arr[-1] - f_arr[-2]\n\n    elif pad_mode == 'order0_adjoint':\n        # Values of f for indices outside the domain of f are replicates of\n        # the edge value.\n\n        if method == 'central':\n            out[0] = (f_arr[0] + f_arr[1]) / 2.0\n            out[-1] = -(f_arr[-1] + f_arr[-2]) / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[1]\n            out[-1] = -f_arr[-1]\n\n        elif method == 'backward':\n            out[0] = f_arr[0]\n            out[-1] = -f_arr[-2]\n\n    elif pad_mode == 'order1':\n        # Values of f for indices outside the domain of f are linearly\n        # extrapolated from the inside.\n\n        # independent of ``method``\n\n        out[0] = f_arr[1] - f_arr[0]\n        out[-1] = f_arr[-1] - f_arr[-2]\n\n    elif pad_mode == 'order1_adjoint':\n        # Values of f for indices outside the domain of f are linearly\n        # extrapolated from the inside.\n\n        if method == 'central':\n            out[0] = f_arr[0] + f_arr[1] / 2.0\n            out[-1] = -f_arr[-1] - f_arr[-2] / 2.0\n\n            # Increment in case array is very short and we get aliasing\n            out[1] -= f_arr[0] / 2.0\n            out[-2] += f_arr[-1] / 2.0\n\n        elif method == 'forward':\n            out[0] = f_arr[0] + f_arr[1]\n            out[-1] = -f_arr[-1]\n\n            # Increment in case array is very short and we get aliasing\n            out[1] -= f_arr[0]\n\n        elif method == 'backward':\n            out[0] = f_arr[0]\n            out[-1] = -f_arr[-1] - f_arr[-2]\n\n            # Increment in case array is very short and we get aliasing\n            out[-2] += f_arr[-1]\n\n    elif pad_mode == 'order2':\n        # 2nd order edges\n\n        out[0] = -(3.0 * f_arr[0] - 4.0 * f_arr[1] + f_arr[2]) / 2.0\n        out[-1] = (3.0 * f_arr[-1] - 4.0 * f_arr[-2] + f_arr[-3]) / 2.0\n\n    elif pad_mode == 'order2_adjoint':\n        # Values of f for indices outside the domain of f are quadratically\n        # extrapolated from the inside.\n\n        if method == 'central':\n            out[0] = 1.5 * f_arr[0] + 0.5 * f_arr[1]\n            out[-1] = -1.5 * f_arr[-1] - 0.5 * f_arr[-2]\n\n            # Increment in case array is very short and we get aliasing\n            out[1] -= 1.5 * f_arr[0]\n            out[2] += 0.5 * f_arr[0]\n            out[-3] -= 0.5 * f_arr[-1]\n            out[-2] += 1.5 * f_arr[-1]\n\n        elif method == 'forward':\n            out[0] = 1.5 * f_arr[0] + 1.0 * f_arr[1]\n            out[-1] = -1.5 * f_arr[-1]\n\n            # Increment in case array is very short and we get aliasing\n            out[1] -= 2.0 * f_arr[0]\n            out[2] += 0.5 * f_arr[0]\n            out[-3] -= 0.5 * f_arr[-1]\n            out[-2] += 1.0 * f_arr[-1]\n\n        elif method == 'backward':\n            out[0] = 1.5 * f_arr[0]\n            out[-1] = -1.0 * f_arr[-2] - 1.5 * f_arr[-1]\n\n            # Increment in case array is very short and we get aliasing\n            out[1] -= 1.0 * f_arr[0]\n            out[2] += 0.5 * f_arr[0]\n            out[-3] -= 0.5 * f_arr[-1]\n            out[-2] += 2.0 * f_arr[-1]\n    else:\n        raise NotImplementedError('unknown pad_mode')\n\n    # divide by step size\n    out /= dx\n\n    return out_in", "response": "Calculates the finite difference of a given array along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate partial derivative of x.", "response": "def _call(self, x, out=None):\n        \"\"\"Calculate partial derivative of ``x``.\"\"\"\n        if out is None:\n            out = self.range.element()\n\n        # TODO: this pipes CUDA arrays through NumPy. Write native operator.\n        with writable_array(out) as out_arr:\n            finite_diff(x.asarray(), axis=self.axis, dx=self.dx,\n                        method=self.method, pad_mode=self.pad_mode,\n                        pad_const=self.pad_const, out=out_arr)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the derivative operator.", "response": "def derivative(self, point=None):\n        \"\"\"Return the derivative operator.\n\n        The partial derivative is usually linear, but in case the 'constant'\n        ``pad_mode`` is used with nonzero ``pad_const``, the\n        derivative is given by the derivative with 0 ``pad_const``.\n\n        Parameters\n        ----------\n        point : `domain` `element-like`, optional\n            The point to take the derivative in. Does not change the result\n            since the operator is affine.\n        \"\"\"\n        if self.pad_mode == 'constant' and self.pad_const != 0:\n            return PartialDerivative(self.domain, self.axis, self.range,\n                                     self.method, self.pad_mode, 0)\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjoint(self):\n        if not self.is_linear:\n            raise ValueError('operator with nonzero pad_const ({}) is not'\n                             ' linear and has no adjoint'\n                             ''.format(self.pad_const))\n\n        return -PartialDerivative(self.range, self.axis, self.domain,\n                                  _ADJ_METHOD[self.method],\n                                  _ADJ_PADDING[self.pad_mode],\n                                  self.pad_const)", "response": "Return the adjoint operator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the spatial gradient of x.", "response": "def _call(self, x, out=None):\n        \"\"\"Calculate the spatial gradient of ``x``.\"\"\"\n        if out is None:\n            out = self.range.element()\n\n        x_arr = x.asarray()\n        ndim = self.domain.ndim\n        dx = self.domain.cell_sides\n\n        for axis in range(ndim):\n            with writable_array(out[axis]) as out_arr:\n                finite_diff(x_arr, axis=axis, dx=dx[axis], method=self.method,\n                            pad_mode=self.pad_mode,\n                            pad_const=self.pad_const,\n                            out=out_arr)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derivative(self, point=None):\n        if self.pad_mode == 'constant' and self.pad_const != 0:\n            return Gradient(self.domain, self.range, self.method,\n                            pad_mode=self.pad_mode,\n                            pad_const=0)\n        else:\n            return self", "response": "Return the derivative operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _call(self, x, out=None):\n        if out is None:\n            out = self.range.element()\n\n        ndim = self.range.ndim\n        dx = self.range.cell_sides\n\n        tmp = np.empty(out.shape, out.dtype, order=out.space.default_order)\n        with writable_array(out) as out_arr:\n            for axis in range(ndim):\n                finite_diff(x[axis], axis=axis, dx=dx[axis],\n                            method=self.method, pad_mode=self.pad_mode,\n                            pad_const=self.pad_const,\n                            out=tmp)\n                if axis == 0:\n                    out_arr[:] = tmp\n                else:\n                    out_arr += tmp\n\n        return out", "response": "Calculate the divergence of x."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call(self, x, out=None):\n        if out is None:\n            out = self.range.zero()\n        else:\n            out.set_zero()\n\n        x_arr = x.asarray()\n        out_arr = out.asarray()\n        tmp = np.empty(out.shape, out.dtype, order=out.space.default_order)\n\n        ndim = self.domain.ndim\n        dx = self.domain.cell_sides\n\n        with writable_array(out) as out_arr:\n            for axis in range(ndim):\n                # TODO: this can be optimized\n                finite_diff(x_arr, axis=axis, dx=dx[axis] ** 2,\n                            method='forward',\n                            pad_mode=self.pad_mode,\n                            pad_const=self.pad_const, out=tmp)\n\n                out_arr += tmp\n\n                finite_diff(x_arr, axis=axis, dx=dx[axis] ** 2,\n                            method='backward',\n                            pad_mode=self.pad_mode,\n                            pad_const=self.pad_const, out=tmp)\n\n                out_arr -= tmp\n\n        return out", "response": "Calculate the spatial Laplacian of x."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef derivative(self, point=None):\n        if self.pad_mode == 'constant' and self.pad_const != 0:\n            return Laplacian(self.domain, self.range,\n                             pad_mode=self.pad_mode, pad_const=0)\n        else:\n            return self", "response": "Return the derivative operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the adjoint operator.", "response": "def adjoint(self):\n        \"\"\"Return the adjoint operator.\n\n        The laplacian is self-adjoint, so this returns ``self``.\n        \"\"\"\n        return Laplacian(self.range, self.domain,\n                         pad_mode=self.pad_mode, pad_const=0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef divide_1Darray_equally(ind, nsub):\n\n    n_ind = len(ind)\n    sub2ind = partition_equally_1d(ind, nsub, order='interlaced')\n\n    ind2sub = []\n    for i in range(n_ind):\n        ind2sub.append([])\n\n    for i in range(nsub):\n        for j in sub2ind[i]:\n            ind2sub[j].append(i)\n\n    return (sub2ind, ind2sub)", "response": "Divide an array into equal chunks to be used for instance in OSEM."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef total_variation(domain, grad=None):\n\n    if grad is None:\n        grad = odl.Gradient(domain, method='forward', pad_mode='symmetric')\n        grad.norm = 2 * np.sqrt(sum(1 / grad.domain.cell_sides**2))\n    else:\n        grad = grad\n\n    f = odl.solvers.GroupL1Norm(grad.range, exponent=2)\n\n    return f * grad", "response": "Total variation functional.\n\n    Parameters\n    ----------\n    domain : odlspace\n        domain of TV functional\n    grad : gradient operator, optional\n        Gradient operator of the total variation functional. This may be any\n        linear operator and thereby generalizing TV. default=forward\n        differences with Neumann boundary conditions\n\n    Examples\n    --------\n    Check that the total variation of a constant is zero\n\n    >>> import odl.contrib.spdhg as spdhg, odl\n    >>> space = odl.uniform_discr([0, 0], [3, 3], [3, 3])\n    >>> tv = spdhg.total_variation(space)\n    >>> x = space.one()\n    >>> tv(x) < 1e-10"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fgp_dual(p, data, alpha, niter, grad, proj_C, proj_P, tol=None, **kwargs):\n\n    # Callback object\n    callback = kwargs.pop('callback', None)\n    if callback is not None and not callable(callback):\n        raise TypeError('`callback` {} is not callable'.format(callback))\n\n    factr = 1 / (grad.norm**2 * alpha)\n\n    q = p.copy()\n    x = data.space.zero()\n\n    t = 1.\n\n    if tol is None:\n        def convergence_eval(p1, p2):\n            return False\n    else:\n        def convergence_eval(p1, p2):\n            return (p1 - p2).norm() / p1.norm() < tol\n\n    pnew = p.copy()\n\n    if callback is not None:\n        callback(p)\n\n    for k in range(niter):\n        t0 = t\n        grad.adjoint(q, out=x)\n        proj_C(data - alpha * x, out=x)\n        grad(x, out=pnew)\n        pnew *= factr\n        pnew += q\n\n        proj_P(pnew, out=pnew)\n\n        converged = convergence_eval(p, pnew)\n\n        if not converged:\n            # update step size\n            t = (1 + np.sqrt(1 + 4 * t0 ** 2)) / 2.\n\n            # calculate next iterate\n            q[:] = pnew + (t0 - 1) / t * (pnew - p)\n\n        p[:] = pnew\n\n        if converged:\n            t = None\n            break\n\n        if callback is not None:\n            callback(p)\n\n    # get current image estimate\n    x = proj_C(data - alpha * grad.adjoint(p))\n\n    return x", "response": "This function computes a solution to the ROF problem with the fast gradient projection algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef proximal(self, sigma):\n\n        if sigma == 0:\n            return odl.IdentityOperator(self.domain)\n\n        else:\n            def tv_prox(z, out=None):\n\n                if out is None:\n                    out = z.space.zero()\n\n                opts = self.prox_options\n\n                sigma_ = np.copy(sigma)\n                z_ = z.copy()\n\n                if self.strong_convexity > 0:\n                    sigma_ /= (1 + sigma * self.strong_convexity)\n                    z_ /= (1 + sigma * self.strong_convexity)\n\n                if opts['name'] == 'FGP':\n                    if opts['warmstart']:\n                        if opts['p'] is None:\n                            opts['p'] = self.grad.range.zero()\n\n                        p = opts['p']\n                    else:\n                        p = self.grad.range.zero()\n\n                    sigma_sqrt = np.sqrt(sigma_)\n\n                    z_ /= sigma_sqrt\n                    grad = sigma_sqrt * self.grad\n                    grad.norm = sigma_sqrt * self.grad.norm\n                    niter = opts['niter']\n                    alpha = self.alpha\n                    out[:] = fgp_dual(p, z_, alpha, niter, grad, self.proj_C,\n                                      self.proj_P, tol=opts['tol'])\n\n                    out *= sigma_sqrt\n\n                    return out\n\n                else:\n                    raise NotImplementedError('Not yet implemented')\n\n            return tv_prox", "response": "Proximal operator of TV. It allows the proximal step length to be a\n        vector of positive elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the KL - diveregnce in the point x.", "response": "def _call(self, x):\n        \"\"\"Return the KL-diveregnce in the point ``x``.\n\n        If any components of ``x`` is non-positive, the value is positive\n        infinity.\n        \"\"\"\n        y = self.data\n        r = self.background\n\n        obj = self.domain.zero()\n\n        # x + r - y + y * log(y / (x + r)) = x - y * log(x + r) + c1\n        # with c1 = r - y + y * log y\n        i = x.ufuncs.greater_equal(0)\n        obj[i] = x[i] + r[i] - y[i]\n\n        j = y.ufuncs.greater(0)\n        k = i.ufuncs.logical_and(j)\n        obj[k] += y[k] * (y[k] / (x[k] + r[k])).ufuncs.log()\n\n        # (y / (2 * r^2)) * x^2 + (1 - y / r) * x + r - b + b * log(b / r)\n        # = (y / (2 * r^2)) * x^2 + (1 - y / r) * x + c2\n        # with c2 = r - b + b * log(b / r)\n        i = i.ufuncs.logical_not()\n        obj[i] += (y[i] / (2 * r[i]**2) * x[i]**2 + (1 - y[i] / r[i]) * x[i] +\n                   r[i] - y[i])\n\n        k = i.ufuncs.logical_and(j)\n        obj[k] += y[k] * (y[k] / r[k]).ufuncs.log()\n\n        return obj.inner(self.domain.one())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a specification and return a list of fields.", "response": "def _fields_from_table(spec_table, id_key):\n    \"\"\"Read a specification and return a list of fields.\n\n    The given specification is assumed to be in\n    `reST grid table format\n    <http://docutils.sourceforge.net/docs/user/rst/quickref.html#tables>`_.\n\n    Parameters\n    ----------\n    spec_table : str\n        Specification given as a string containing a definition table.\n    id_key : str\n        Dictionary key (= column header) for the ID labels in ``spec``.\n\n    Returns\n    -------\n    fields : tuple of dicts\n        Field list of the specification with combined multi-line entries.\n        Each field corresponds to one (multi-)line of the spec.\n    \"\"\"\n    # Reformat the table, throwing away lines not starting with '|'\n    spec_lines = [line[1:-1].rstrip() for line in spec_table.splitlines()\n                  if line.startswith('|')]\n\n    # Guess the CSV dialect and read the table, producing an iterable\n    dialect = csv.Sniffer().sniff(spec_lines[0], delimiters='|')\n    reader = csv.DictReader(spec_lines, dialect=dialect)\n\n    # Read the fields as dictionaries and transform keys and values to\n    # lowercase.\n    fields = []\n    for row in reader:\n        new_row = {}\n        if row[id_key].strip():\n            # Start of a new field, indicated by a nontrivial ID entry\n            for key, val in row.items():\n                new_row[key.strip()] = val.strip()\n            fields.append(new_row)\n        else:\n            # We have the second row of a multi-line field. We\n            # append all stripped values to the corresponding existing entry\n            # value with an extra space.\n\n            if not fields:\n                # Just to make sure that this situation did not happen at\n                # the very beginning of the table\n                continue\n\n            for key, val in row.items():\n                fields[-1][key.strip()] += (' ' + val).rstrip()\n\n    return tuple(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef header_fields_from_table(spec_table, keys, dtype_map):\n    field_list = _fields_from_table(spec_table, id_key=keys['id'])\n\n    # Parse the fields and represent them in a unfied way\n    conv_list = []\n    for field in field_list:\n        new_field = {}\n\n        # Name and description: lowercase name, copy description\n        new_field['name'] = field[keys['name']].lower()\n        new_field['description'] = field[keys['description']]\n\n        # Get byte range and set start\n        byte_range = field[keys['byte_range']].split('-')\n        offset_bytes = int(byte_range[0]) - 1\n        end_bytes = int(byte_range[-1]) - 1\n        size_bytes = end_bytes - offset_bytes + 1\n        new_field['offset'] = offset_bytes\n        new_field['size'] = size_bytes\n\n        # Data type: transform to Numpy format and get shape\n        dtype_shape = field[keys['dtype']].split('(')\n        dtype = dtype_map[dtype_shape[0]]\n        new_field['dtype'] = dtype\n\n        if len(dtype_shape) == 2:\n            # Shape was given in data type specification\n\n            # Re-attach left parenthesis that was removed in the split\n            dshape = np.atleast_1d(eval('(' + dtype_shape[-1]))\n            size_bytes_from_shape = np.prod(dshape) * dtype.itemsize\n            if size_bytes_from_shape >= size_bytes:\n                raise ValueError(\n                    \"entry '{}': field size {} from shape {} and \"\n                    \"dtype.itemsize {} larger than field size {} from spec\"\n                    \"\".format(field[keys['name']], size_bytes_from_shape,\n                              dshape, dtype.itemsize, size_bytes))\n\n            # Try to complete the given shape\n            if size_bytes % size_bytes_from_shape:\n                raise ValueError(\n                    \"entry '{}': shape {} cannot be completed consistently \"\n                    \"using field size {} and `dtype.itemsize` {}\"\n                    \"\".format(field[keys['name']], dshape, size_bytes,\n                              dtype.itemsize))\n\n            dshape = (size_bytes // size_bytes_from_shape,) + tuple(dshape)\n\n        else:\n            if size_bytes % dtype.itemsize:\n                raise ValueError(\n                    \"entry '{}': field size {} not a multiple of \"\n                    \"`dtype.itemsize` {}\"\n                    \"\".format(field[keys['name']], field[keys['byte_range']],\n                              dtype.itemsize, field[keys['dtype']]))\n            dshape = (size_bytes // dtype.itemsize,)\n\n        new_field['dshape'] = dshape\n\n        conv_list.append(new_field)\n\n    return tuple(conv_list)", "response": "Convert the specification table to a standardized format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef header_size(self):\n        if not self.header:\n            return 0\n\n        # Determine header size by finding the largest offset and the\n        # value of the corresponding entry. The header size is the\n        # offset plus the size of the entry.\n        max_entry = max(self.header.values(),\n                        key=lambda val: val['offset'])\n        return max_entry['offset'] + max_entry['value'].nbytes", "response": "Returns the size of the file s header in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_header(self):\n        # Read all fields except data. We use an OrderedDict such that\n        # the order is the same as in `header_fields`. This makes it simple\n        # to write later on in the correct order, based only on `header`.\n        header = OrderedDict()\n        for field in self.header_fields:\n            # Get all the values from the dictionary\n            name = field['name']\n            if name == 'data':\n                continue\n            entry = {'description': field.get('description', '')}\n            offset_bytes = int(field['offset'])\n            entry['offset'] = offset_bytes\n            size_bytes = int(field['size'])\n            dtype = np.dtype(field['dtype'])\n            shape = field.get('dshape', -1)  # no-op by default\n\n            if size_bytes is None:\n                # Default if 'size' is omitted\n                num_elems = 1\n            else:\n                num_elems = size_bytes / dtype.itemsize\n\n            if size_bytes % dtype.itemsize:\n                raise RuntimeError(\n                    \"field '{}': `size` {} and `dtype.itemsize` {} \"\n                    \" result in non-integer number of elements\"\n                    \"\".format(name, size_bytes, dtype.itemsize))\n\n            # Create format string for struct module to unpack the binary\n            # data\n            if np.issubdtype(dtype, np.dtype('S')):\n                # Have conversion only for 'S1', so we need to translate\n                fmt = (str(int(num_elems) * dtype.itemsize) + 's')\n            else:\n                # Format character can be obtained as dtype.char\n                fmt = str(int(num_elems)) + dtype.char\n\n            if struct.calcsize(fmt) != size_bytes:\n                raise RuntimeError(\n                    \"field '{}': format '{}' results in {} bytes, but \"\n                    \"`size` is {}\"\n                    \"\".format(name, fmt, struct.calcsize(fmt), size_bytes))\n\n            self.file.seek(offset_bytes)\n            packed_value = self.file.read(size_bytes)\n\n            if np.issubdtype(dtype, np.dtype('S')):\n                # Bytestring type, decode instead of unpacking. Replace\n                # \\x00 characters with whitespace so the final length is\n                # correct\n                packed_value = packed_value.replace(b'\\x00', b' ')\n                value = np.fromiter(packed_value.decode().ljust(size_bytes),\n                                    dtype=dtype)\n                entry['value'] = value.reshape(shape)\n            else:\n                value = np.array(struct.unpack_from(fmt, packed_value),\n                                 dtype=dtype)\n                entry['value'] = value.reshape(shape)\n\n            header[name] = entry\n\n        # Store information gained from the header\n        self.__header = header\n\n        return header", "response": "Read the header from the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_data(self, dstart=None, dend=None):\n        self.file.seek(0, 2)  # 2 means \"from the end\"\n        filesize_bytes = self.file.tell()\n        if dstart is None:\n            dstart_abs = int(self.header_size)\n        elif dstart < 0:\n            dstart_abs = filesize_bytes + int(dstart)\n        else:\n            dstart_abs = int(dstart)\n\n        if dend is None:\n            dend_abs = int(filesize_bytes)\n        elif dend < 0:\n            dend_abs = int(dend) + filesize_bytes\n        else:\n            dend_abs = int(dend)\n\n        if dstart_abs >= dend_abs:\n            raise ValueError('invalid `dstart` and `dend`, resulting in '\n                             'absolute `dstart` >= `dend` ({} >= {})'\n                             ''.format(dstart_abs, dend_abs))\n        if dstart_abs < self.header_size:\n            raise ValueError('invalid `dstart`, resulting in absolute '\n                             '`dstart` < `header_size` ({} < {})'\n                             ''.format(dstart_abs, self.header_size))\n        if dend_abs > filesize_bytes:\n            raise ValueError('invalid `dend`, resulting in absolute '\n                             '`dend` > `filesize_bytes` ({} < {})'\n                             ''.format(dend_abs, filesize_bytes))\n\n        num_elems = (dend_abs - dstart_abs) / self.data_dtype.itemsize\n        if num_elems != int(num_elems):\n            raise ValueError(\n                'trying to read {} bytes, which is not a multiple of '\n                'the itemsize {} of the data type {}'\n                ''.format(dend_abs - dstart_abs, self.data_dtype.itemsize,\n                          self.data_dtype))\n        self.file.seek(dstart_abs)\n        array = np.empty(int(num_elems), dtype=self.data_dtype)\n        self.file.readinto(array.data)\n        return array", "response": "Read data from the file and return it as Numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite header to file.", "response": "def write_header(self):\n        \"\"\"Write `header` to `file`.\n\n        See Also\n        --------\n        write_data\n        \"\"\"\n        for properties in self.header.values():\n            value = properties['value']\n            offset_bytes = int(properties['offset'])\n            self.file.seek(offset_bytes)\n            value.tofile(self.file)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_data(self, data, dstart=None, reshape_order='C'):\n        data = np.asarray(data).reshape(-1, order=reshape_order)\n        if dstart is None:\n            dstart = int(self.header_size)\n        elif dstart < 0:\n            raise ValueError('`dstart` must be non-negative, got {}'\n                             ''.format(dstart))\n        else:\n            dstart = int(dstart)\n\n        if dstart < self.header_size:\n            raise ValueError('invalid `dstart`, resulting in absolute '\n                             '`dstart` < `header_size` ({} < {})'\n                             ''.format(dstart, self.header_size))\n\n        self.file.seek(dstart)\n        data.tofile(self.file)", "response": "Write data to the log file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call(self, x):\n        result = 0\n        for i in range(0, self.domain.size - 1):\n            result += (self.scale * (x[i + 1] - x[i] ** 2) ** 2 +\n                       (x[i] - 1) ** 2)\n\n        return result", "response": "Return the value of the class attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalized_scalar_param_list(param, length, param_conv=None,\n                                 keep_none=True, return_nonconv=False):\n    \"\"\"Return a list of given length from a scalar parameter.\n\n    The typical use case is when a single value or a sequence of\n    values is accepted as input. This function makes a list from\n    a given sequence or a list of identical elements from a single\n    value, with cast to a given parameter type if desired.\n\n    To distinguish a parameter sequence from a single parameter, the\n    following rules are applied:\n\n    * If ``param`` is not a sequence, it is treated as a single\n      parameter (e.g. ``1``).\n    * If ``len(param) == length == 1``, then ``param`` is interpreted\n      as a single parameter (e.g. ``[1]`` or ``'1'``).\n    * If ``len(param) == length != 1``, then ``param`` is interpreted as\n      sequence of parameters.\n    * Otherwise, ``param`` is interpreted as a single parameter.\n\n    Note that this function is not applicable to parameters which are\n    themselves iterable (e.g. ``'abc'`` with ``length=3`` will be\n    interpreted as equivalent to ``['a', 'b', 'c']``).\n\n    Parameters\n    ----------\n    param :\n        Input parameter to turn into a list.\n    length : nonnegative int\n        Desired length of the output list.\n    param_conv : callable, optional\n        Conversion applied to each list element. ``None`` means no conversion.\n    keep_none : bool, optional\n        If ``True``, ``None`` is not converted.\n    return_nonconv : bool, optional\n        If ``True``, return also the list where no conversion has been\n        applied.\n\n    Returns\n    -------\n    plist : list\n        Input parameter turned into a list of length ``length``.\n    nonconv : list\n        The same as ``plist``, but without conversion. This is only\n        returned if ``return_nonconv == True``.\n\n    Examples\n    --------\n    Turn input into a list of given length, possibly by broadcasting.\n    By default, no conversion is performed.\n\n    >>> normalized_scalar_param_list((1, 2, 3), 3)\n    [1, 2, 3]\n    >>> normalized_scalar_param_list((1, None, 3.0), 3)\n    [1, None, 3.0]\n\n    Single parameters are broadcast to the given length.\n\n    >>> normalized_scalar_param_list(1, 3)\n    [1, 1, 1]\n    >>> normalized_scalar_param_list('10', 3)\n    ['10', '10', '10']\n    >>> normalized_scalar_param_list(None, 3)\n    [None, None, None]\n\n    List entries can be explicitly converted using ``param_conv``. If\n    ``None`` should be kept, set ``keep_none`` to ``True``:\n\n    >>> normalized_scalar_param_list(1, 3, param_conv=float)\n    [1.0, 1.0, 1.0]\n    >>> normalized_scalar_param_list('10', 3, param_conv=int)\n    [10, 10, 10]\n    >>> normalized_scalar_param_list((1, None, 3.0), 3, param_conv=int,\n    ...                              keep_none=True)  # default\n    [1, None, 3]\n\n    The conversion parameter can be any callable:\n\n    >>> def myconv(x):\n    ...     return False if x is None else bool(x)\n    >>> normalized_scalar_param_list((0, None, 3.0), 3, param_conv=myconv,\n    ...                              keep_none=False)\n    [False, False, True]\n    \"\"\"\n    length, length_in = int(length), length\n    if length < 0:\n        raise ValueError('`length` must be nonnegative, got {}'\n                         ''.format(length_in))\n\n    param = np.array(param, dtype=object, copy=True, ndmin=1)\n    nonconv_list = list(np.broadcast_to(param, (length,)))\n\n    if len(nonconv_list) != length:\n        raise ValueError('sequence `param` has length {}, expected {}'\n                         ''.format(len(nonconv_list), length))\n\n    if param_conv is None:\n        out_list = list(nonconv_list)\n    else:\n        out_list = []\n        for p in nonconv_list:\n            if p is None and keep_none:\n                out_list.append(p)\n            else:\n                out_list.append(param_conv(p))\n\n    if return_nonconv:\n        return out_list, nonconv_list\n    else:\n        return out_list", "response": "Return a list of given length from a scalar parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalized_index_expression(indices, shape, int_to_slice=False):\n    ndim = len(shape)\n    # Support indexing with fewer indices as indexing along the first\n    # corresponding axes. In the other cases, normalize the input.\n    if np.isscalar(indices):\n        indices = [indices, Ellipsis]\n    elif (isinstance(indices, slice) or indices is Ellipsis):\n        indices = [indices]\n\n    indices = list(indices)\n    if len(indices) < ndim and Ellipsis not in indices:\n        indices.append(Ellipsis)\n\n    # Turn Ellipsis into the correct number of slice(None)\n    if Ellipsis in indices:\n        if indices.count(Ellipsis) > 1:\n            raise ValueError('cannot use more than one Ellipsis.')\n\n        eidx = indices.index(Ellipsis)\n        extra_dims = ndim - len(indices) + 1\n        indices = (indices[:eidx] + [slice(None)] * extra_dims +\n                   indices[eidx + 1:])\n\n    # Turn single indices into length-1 slices if desired\n    for (i, idx), n in zip(enumerate(indices), shape):\n        if np.isscalar(idx):\n            if idx < 0:\n                idx += n\n\n            if idx >= n:\n                raise IndexError('Index {} is out of bounds for axis '\n                                 '{} with size {}.'\n                                 ''.format(idx, i, n))\n            if int_to_slice:\n                indices[i] = slice(idx, idx + 1)\n\n    # Catch most common errors\n    if any(s.start == s.stop and s.start is not None or\n           s.start == n\n           for s, n in zip(indices, shape) if isinstance(s, slice)):\n        raise ValueError('Slices with empty axes not allowed.')\n    if None in indices:\n        raise ValueError('creating new axes is not supported.')\n    if len(indices) > ndim:\n        raise IndexError('too may indices: {} > {}.'\n                         ''.format(len(indices), ndim))\n\n    return tuple(indices)", "response": "Enable indexing with almost Numpy - like capabilities."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalized_nodes_on_bdry(nodes_on_bdry, length):\n    shape = np.shape(nodes_on_bdry)\n    if shape == ():\n        out_list = [(bool(nodes_on_bdry), bool(nodes_on_bdry))] * length\n    elif length == 1 and shape == (2,):\n        out_list = [(bool(nodes_on_bdry[0]), bool(nodes_on_bdry[1]))]\n    elif len(nodes_on_bdry) == length:\n        out_list = []\n\n        for i, on_bdry in enumerate(nodes_on_bdry):\n            shape_i = np.shape(on_bdry)\n            if shape_i == ():\n                out_list.append((bool(on_bdry), bool(on_bdry)))\n            elif shape_i == (2,):\n                out_list.append((bool(on_bdry[0]), bool(on_bdry[1])))\n            else:\n                raise ValueError('in axis {}: `nodes_on_bdry` has shape {}, '\n                                 'expected (2,)'\n                                 .format(i, shape_i))\n    else:\n        raise ValueError('`nodes_on_bdry` has shape {}, expected ({},)'\n                         ''.format(shape, length))\n\n    return out_list", "response": "This function returns a list of 2 - tuples of bool from the input parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a tuple of axes converted to positive integers.", "response": "def normalized_axes_tuple(axes, ndim):\n    \"\"\"Return a tuple of ``axes`` converted to positive integers.\n\n    This function turns negative entries into equivalent positive\n    ones according to standard Python indexing \"from the right\".\n\n    Parameters\n    ----------\n    axes : int or sequence of ints\n        Single integer or integer sequence of arbitrary length.\n        Duplicate entries are not allowed. All entries must fulfill\n        ``-ndim <= axis <= ndim - 1``.\n    ndim : positive int\n        Number of available axes determining the valid axis range.\n\n    Returns\n    -------\n    axes_list : tuple of ints\n        The converted tuple of axes.\n\n    Examples\n    --------\n    Normalizing a sequence of axes:\n\n    >>> normalized_axes_tuple([0, -1, 2], ndim=3)\n    (0, 2, 2)\n\n    Single integer works, too:\n\n    >>> normalized_axes_tuple(-3, ndim=3)\n    (0,)\n    \"\"\"\n    try:\n        axes, axes_in = (int(axes),), axes\n    except TypeError:\n        axes, axes_in = tuple(int(axis) for axis in axes), axes\n        if any(axis != axis_in for axis, axis_in in zip(axes, axes_in)):\n            raise ValueError('`axes` may only contain integers, got {}'\n                             ''.format(axes_in))\n    else:\n        if axes[0] != axes_in:\n            raise TypeError('`axes` must be integer or sequence, got {}'\n                            ''.format(axes_in))\n\n    if len(set(axes)) != len(axes):\n        raise ValueError('`axes` may not contain duplicate entries')\n\n    ndim, ndim_in = int(ndim), ndim\n    if ndim <= 0:\n        raise ValueError('`ndim` must be positive, got {}'.format(ndim_in))\n\n    axes_arr = np.array(axes)\n    axes_arr[axes_arr < 0] += ndim\n    if np.any((axes_arr < 0) | (axes_arr >= ndim)):\n        raise ValueError('all `axes` entries must satisfy -{0} <= axis < {0}, '\n                         'got {1}'.format(ndim, axes_in))\n\n    return tuple(axes_arr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_int_conv(number):\n    try:\n        return int(np.array(number).astype(int, casting='safe'))\n    except TypeError:\n        raise ValueError('cannot safely convert {} to integer'.format(number))", "response": "Safely convert a single number to integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef astra_cpu_forward_projector(vol_data, geometry, proj_space, out=None):\n    if not isinstance(vol_data, DiscreteLpElement):\n        raise TypeError('volume data {!r} is not a `DiscreteLpElement` '\n                        'instance.'.format(vol_data))\n    if vol_data.space.impl != 'numpy':\n        raise TypeError(\"`vol_data.space.impl` must be 'numpy', got {!r}\"\n                        \"\".format(vol_data.space.impl))\n    if not isinstance(geometry, Geometry):\n        raise TypeError('geometry  {!r} is not a Geometry instance'\n                        ''.format(geometry))\n    if not isinstance(proj_space, DiscreteLp):\n        raise TypeError('`proj_space` {!r} is not a DiscreteLp '\n                        'instance.'.format(proj_space))\n    if proj_space.impl != 'numpy':\n        raise TypeError(\"`proj_space.impl` must be 'numpy', got {!r}\"\n                        \"\".format(proj_space.impl))\n    if vol_data.ndim != geometry.ndim:\n        raise ValueError('dimensions {} of volume data and {} of geometry '\n                         'do not match'\n                         ''.format(vol_data.ndim, geometry.ndim))\n    if out is None:\n        out = proj_space.element()\n    else:\n        if out not in proj_space:\n            raise TypeError('`out` {} is neither None nor a '\n                            'DiscreteLpElement instance'.format(out))\n\n    ndim = vol_data.ndim\n\n    # Create astra geometries\n    vol_geom = astra_volume_geometry(vol_data.space)\n    proj_geom = astra_projection_geometry(geometry)\n\n    # Create projector\n    if not all(s == vol_data.space.interp_byaxis[0]\n               for s in vol_data.space.interp_byaxis):\n        raise ValueError('volume interpolation must be the same in each '\n                         'dimension, got {}'.format(vol_data.space.interp))\n    vol_interp = vol_data.space.interp\n    proj_id = astra_projector(vol_interp, vol_geom, proj_geom, ndim,\n                              impl='cpu')\n\n    # Create ASTRA data structures\n    vol_data_arr = np.asarray(vol_data)\n    vol_id = astra_data(vol_geom, datatype='volume', data=vol_data_arr,\n                        allow_copy=True)\n\n    with writable_array(out, dtype='float32', order='C') as out_arr:\n        sino_id = astra_data(proj_geom, datatype='projection', data=out_arr,\n                             ndim=proj_space.ndim)\n\n        # Create algorithm\n        algo_id = astra_algorithm('forward', ndim, vol_id, sino_id, proj_id,\n                                  impl='cpu')\n\n        # Run algorithm\n        astra.algorithm.run(algo_id)\n\n    # Delete ASTRA objects\n    astra.algorithm.delete(algo_id)\n    astra.data2d.delete((vol_id, sino_id))\n    astra.projector.delete(proj_id)\n\n    return out", "response": "Run an ASTRA forward projection on the given data using the CPU."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns an ASTRA back - projection on the given data using the CPU.", "response": "def astra_cpu_back_projector(proj_data, geometry, reco_space, out=None):\n    \"\"\"Run an ASTRA back-projection on the given data using the CPU.\n\n    Parameters\n    ----------\n    proj_data : `DiscreteLpElement`\n        Projection data to which the back-projector is applied\n    geometry : `Geometry`\n        Geometry defining the tomographic setup\n    reco_space : `DiscreteLp`\n        Space to which the calling operator maps\n    out : ``reco_space`` element, optional\n        Element of the reconstruction space to which the result is written.\n        If ``None``, an element in ``reco_space`` is created.\n\n    Returns\n    -------\n    out : ``reco_space`` element\n        Reconstruction data resulting from the application of the backward\n        projector. If ``out`` was provided, the returned object is a\n        reference to it.\n    \"\"\"\n    if not isinstance(proj_data, DiscreteLpElement):\n        raise TypeError('projection data {!r} is not a DiscreteLpElement '\n                        'instance'.format(proj_data))\n    if proj_data.space.impl != 'numpy':\n        raise TypeError('`proj_data` must be a `numpy.ndarray` based, '\n                        \"container got `impl` {!r}\"\n                        \"\".format(proj_data.space.impl))\n    if not isinstance(geometry, Geometry):\n        raise TypeError('geometry  {!r} is not a Geometry instance'\n                        ''.format(geometry))\n    if not isinstance(reco_space, DiscreteLp):\n        raise TypeError('reconstruction space {!r} is not a DiscreteLp '\n                        'instance'.format(reco_space))\n    if reco_space.impl != 'numpy':\n        raise TypeError(\"`reco_space.impl` must be 'numpy', got {!r}\"\n                        \"\".format(reco_space.impl))\n    if reco_space.ndim != geometry.ndim:\n        raise ValueError('dimensions {} of reconstruction space and {} of '\n                         'geometry do not match'.format(\n                             reco_space.ndim, geometry.ndim))\n    if out is None:\n        out = reco_space.element()\n    else:\n        if out not in reco_space:\n            raise TypeError('`out` {} is neither None nor a '\n                            'DiscreteLpElement instance'.format(out))\n\n    ndim = proj_data.ndim\n\n    # Create astra geometries\n    vol_geom = astra_volume_geometry(reco_space)\n    proj_geom = astra_projection_geometry(geometry)\n\n    # Create ASTRA data structure\n    sino_id = astra_data(proj_geom, datatype='projection', data=proj_data,\n                         allow_copy=True)\n\n    # Create projector\n    # TODO: implement with different schemes for angles and detector\n    if not all(s == proj_data.space.interp_byaxis[0]\n               for s in proj_data.space.interp_byaxis):\n        raise ValueError('data interpolation must be the same in each '\n                         'dimension, got {}'\n                         ''.format(proj_data.space.interp_byaxis))\n    proj_interp = proj_data.space.interp\n    proj_id = astra_projector(proj_interp, vol_geom, proj_geom, ndim,\n                              impl='cpu')\n\n    # Convert out to correct dtype and order if needed.\n    with writable_array(out, dtype='float32', order='C') as out_arr:\n        vol_id = astra_data(vol_geom, datatype='volume', data=out_arr,\n                            ndim=reco_space.ndim)\n        # Create algorithm\n        algo_id = astra_algorithm('backward', ndim, vol_id, sino_id, proj_id,\n                                  impl='cpu')\n\n        # Run algorithm\n        astra.algorithm.run(algo_id)\n\n    # Weight the adjoint by appropriate weights\n    scaling_factor = float(proj_data.space.weighting.const)\n    scaling_factor /= float(reco_space.weighting.const)\n\n    out *= scaling_factor\n\n    # Delete ASTRA objects\n    astra.algorithm.delete(algo_id)\n    astra.data2d.delete((vol_id, sino_id))\n    astra.projector.delete(proj_id)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndefaults out - of - place evaluation.", "response": "def _default_call_out_of_place(op, x, **kwargs):\n    \"\"\"Default out-of-place evaluation.\n\n    Parameters\n    ----------\n    op : `Operator`\n        Operator to call\n    x : ``op.domain`` element\n        Point in which to call the operator.\n    kwargs:\n        Optional arguments to the operator.\n\n    Returns\n    -------\n    out : `range` element\n        An object in the operator range. The result of an operator\n        evaluation.\n    \"\"\"\n    out = op.range.element()\n    result = op._call_in_place(x, out, **kwargs)\n    if result is not None and result is not out:\n        raise ValueError('`op` returned a different value than `out`.'\n                         'With in-place evaluation, the operator can '\n                         'only return nothing (`None`) or the `out` '\n                         'parameter.')\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefaults in - place evaluation using the operator. _call_out_of_place method.", "response": "def _default_call_in_place(op, x, out, **kwargs):\n    \"\"\"Default in-place evaluation using ``Operator._call()``.\n\n    Parameters\n    ----------\n    op : `Operator`\n        Operator to call\n    x : ``op.domain`` element\n        Point in which to call the operator.\n    out : ``op.range`` element\n        An object in the operator range. The result of an operator\n        evaluation is written here.\n    kwargs:\n        Optional arguments to the operator.\n    \"\"\"\n    out.assign(op.range.element(op._call_out_of_place(x, **kwargs)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _function_signature(func):\n    if sys.version_info.major > 2:\n        # Python 3 already implements this functionality\n        return func.__name__ + str(inspect.signature(func))\n\n    # In Python 2 we have to do it manually, unfortunately\n    spec = inspect.getargspec(func)\n    posargs = spec.args\n    defaults = spec.defaults if spec.defaults is not None else []\n    varargs = spec.varargs\n    kwargs = spec.keywords\n    deflen = 0 if defaults is None else len(defaults)\n    nodeflen = 0 if posargs is None else len(posargs) - deflen\n\n    args = ['{}'.format(arg) for arg in posargs[:nodeflen]]\n    args.extend('{}={}'.format(arg, dval)\n                for arg, dval in zip(posargs[nodeflen:], defaults))\n    if varargs:\n        args.append('*{}'.format(varargs))\n    if kwargs:\n        args.append('**{}'.format(kwargs))\n\n    argstr = ', '.join(args)\n\n    return '{}({})'.format(func.__name__, argstr)", "response": "Return the signature of a callable as a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _dispatch_call_args(cls=None, bound_call=None, unbound_call=None,\n                        attr='_call'):\n    \"\"\"Check the arguments of ``_call()`` or similar for conformity.\n\n    The ``_call()`` method of `Operator` is allowed to have the\n    following signatures:\n\n    Python 2 and 3:\n        - ``_call(self, x)``\n        - ``_call(self, vec, out)``\n        - ``_call(self, x, out=None)``\n\n    Python 3 only:\n        - ``_call(self, x, *, out=None)`` (``out`` as keyword-only\n          argument)\n\n    For disambiguation, the instance name (the first argument) **must**\n    be 'self'.\n\n    The name of the ``out`` argument **must** be 'out', the second\n    argument may have any name.\n\n    Additional variable ``**kwargs`` and keyword-only arguments\n    (Python 3 only) are also allowed.\n\n    Not allowed:\n        - ``_call(self)`` -- No arguments except instance:\n        - ``_call(x)`` -- 'self' missing, i.e. ``@staticmethod``\n        - ``_call(cls, x)``  -- 'self' missing, i.e. ``@classmethod``\n        - ``_call(self, out, x)`` -- ``out`` as second argument\n        - ``_call(self, *x)`` -- Variable arguments\n        - ``_call(self, x, y, out=None)`` -- more positional arguments\n        - ``_call(self, x, out=False)`` -- default other than None for\n          ``out``\n\n    In particular, static or class methods are not allowed.\n\n    Parameters\n    ----------\n    cls : `class`, optional\n        The ``_call()`` method of this class is checked. If omitted,\n        provide ``unbound_call`` instead to check directly.\n    bound_call : callable, optional\n        Check this bound method instead of ``cls``\n    unbound_call : callable, optional\n        Check this unbound function instead of ``cls``\n    attr : string, optional\n        Check this attribute instead of ``_call``, e.g. ``__call__``\n\n    Returns\n    -------\n    has_out : bool\n        Whether the call has an ``out`` argument\n    out_is_optional : bool\n        Whether the ``out`` argument is optional\n    spec : `inspect.ArgSpec` or `inspect.FullArgSpec`\n        Argument specification of the checked call function\n\n    Raises\n    ------\n    ValueError\n        if the signature of the function is malformed\n    \"\"\"\n    py3 = (sys.version_info.major > 2)\n\n    specs = ['_call(self, x[, **kwargs])',\n             '_call(self, x, out[, **kwargs])',\n             '_call(self, x, out=None[, **kwargs])']\n\n    if py3:\n        specs += ['_call(self, x, *, out=None[, **kwargs])']\n\n    spec_msg = \"\\nPossible signatures are ('[, **kwargs]' means optional):\\n\\n\"\n    spec_msg += '\\n'.join(specs)\n    spec_msg += '\\n\\nStatic or class methods are not allowed.'\n\n    if sum(arg is not None for arg in (cls, bound_call, unbound_call)) != 1:\n        raise ValueError('exactly one object to check must be given')\n\n    if cls is not None:\n        # Get the actual implementation, including ancestors\n        for parent in cls.mro():\n            call = parent.__dict__.get(attr, None)\n            if call is not None:\n                break\n        # Static and class methods are not allowed\n        if isinstance(call, staticmethod):\n            raise TypeError(\"'{}.{}' is a static method. \"\n                            \"\".format(cls.__name__, attr) + spec_msg)\n        elif isinstance(call, classmethod):\n            raise TypeError(\"'{}.{}' is a class method. \"\n                            \"\".format(cls.__name__, attr) + spec_msg)\n\n    elif bound_call is not None:\n        call = bound_call\n        if not inspect.ismethod(call):\n            raise TypeError('{} is not a bound method'.format(call))\n    else:\n        call = unbound_call\n\n    if py3:\n        # support kw-only args and annotations\n        spec = inspect.getfullargspec(call)\n        kw_only = spec.kwonlyargs\n        kw_only_defaults = spec.kwonlydefaults\n    else:\n        spec = inspect.getargspec(call)\n        kw_only = ()\n        kw_only_defaults = {}\n\n    signature = _function_signature(call)\n\n    pos_args = spec.args\n    if unbound_call is not None:\n        # Add 'self' to positional arg list to satisfy the checker\n        pos_args.insert(0, 'self')\n\n    pos_defaults = spec.defaults\n    varargs = spec.varargs\n\n    # Variable args are not allowed\n    if varargs is not None:\n        raise ValueError(\"bad signature '{}': variable arguments not allowed\"\n                         \"\".format(signature) + spec_msg)\n\n    if len(pos_args) not in (2, 3):\n        raise ValueError(\"bad signature '{}'\".format(signature) + spec_msg)\n\n    true_pos_args = pos_args[1:]\n    if len(true_pos_args) == 1:  # 'out' kw-only\n        if 'out' in true_pos_args:  # 'out' positional and 'x' kw-only -> no\n            raise ValueError(\"bad signature '{}': `out` cannot be the only \"\n                             \"positional argument\"\n                             \"\".format(signature) + spec_msg)\n        else:\n            if 'out' not in kw_only:\n                has_out = out_optional = False\n            elif kw_only_defaults['out'] is not None:\n                raise ValueError(\n                    \"bad signature '{}': `out` can only default to \"\n                    \"`None`, got '{}'\"\n                    \"\".format(signature, kw_only_defaults['out']) +\n                    spec_msg)\n            else:\n                has_out = True\n                out_optional = True\n\n    elif len(true_pos_args) == 2:  # Both args positional\n        if true_pos_args[0] == 'out':  # out must come second\n            py3_txt = ' or keyword-only. ' if py3 else '. '\n            raise ValueError(\"bad signature '{}': `out` can only be the \"\n                             \"second positional argument\".format(signature) +\n                             py3_txt + spec_msg)\n        elif true_pos_args[1] != 'out':  # 'out' must be 'out'\n            raise ValueError(\"bad signature '{}': output parameter must \"\n                             \"be called 'out', got '{}'\"\n                             \"\".format(signature, true_pos_args[1]) +\n                             spec_msg)\n        else:\n            has_out = True\n            out_optional = bool(pos_defaults)\n            if pos_defaults and pos_defaults[-1] is not None:\n                raise ValueError(\"bad signature '{}': `out` can only \"\n                                 \"default to `None`, got '{}'\"\n                                 \"\".format(signature, pos_defaults[-1]) +\n                                 spec_msg)\n\n    else:  # Too many positional args\n        raise ValueError(\"bad signature '{}': too many positional arguments\"\n                         \" \".format(signature) + spec_msg)\n\n    return has_out, out_optional, spec", "response": "Dispatches the arguments of the _call method of the Operator class or method of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the operator norm of this operator.", "response": "def norm(self, estimate=False, **kwargs):\n        \"\"\"Return the operator norm of this operator.\n\n        If this operator is non-linear, this should be the Lipschitz constant.\n\n        Parameters\n        ----------\n        estimate : bool\n            If true, estimate the operator norm. By default, it is estimated\n            using `power_method_opnorm`, which is only applicable for linear\n            operators.\n            Subclasses are allowed to ignore this parameter if they can provide\n            an exact value.\n\n        Other Parameters\n        ----------------\n        kwargs :\n            If ``estimate`` is True, pass these arguments to the\n            `power_method_opnorm` call.\n\n        Returns\n        -------\n        norm : float\n\n        Examples\n        --------\n        Some operators know their own operator norm and do not need an estimate\n\n        >>> spc = odl.rn(3)\n        >>> id = odl.IdentityOperator(spc)\n        >>> id.norm(True)\n        1.0\n\n        For others, there is no closed form expression and an estimate is\n        needed:\n\n        >>> spc = odl.uniform_discr(0, 1, 3)\n        >>> grad = odl.Gradient(spc)\n        >>> opnorm = grad.norm(estimate=True)\n        \"\"\"\n        if not estimate:\n            raise NotImplementedError('`Operator.norm()` not implemented, use '\n                                      '`Operator.norm(estimate=True)` to '\n                                      'obtain an estimate.')\n        else:\n            norm = getattr(self, '__norm', None)\n            if norm is not None:\n                return norm\n            else:\n                from odl.operator.oputils import power_method_opnorm\n                self.__norm = power_method_opnorm(self, **kwargs)\n                return self.__norm"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef derivative(self, x):\n        if self.is_linear:\n            return self\n        else:\n            return OperatorSum(self.left.derivative(x),\n                               self.right.derivative(x),\n                               self.__tmp_dom, self.__tmp_ran)", "response": "Return the derivative of the two operators at x."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the adjoint of the operator sum.", "response": "def adjoint(self):\n        \"\"\"Adjoint of this operator.\n\n        The adjoint of the operator sum is the sum of the operator\n        adjoints:\n\n            ``OperatorSum(left, right).adjoint ==\n            OperatorSum(left.adjoint, right.adjoint)``\n\n        Returns\n        -------\n        adjoint : `OperatorSum`\n\n        Raises\n        ------\n        OpNotImplementedError\n            If either of the underlying operators are non-linear.\n        \"\"\"\n        if not self.is_linear:\n            raise OpNotImplementedError('nonlinear operators have no adjoint')\n\n        return OperatorSum(self.left.adjoint, self.right.adjoint,\n                           self.__tmp_dom, self.__tmp_ran)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninverse of this operator.", "response": "def inverse(self):\n        \"\"\"Inverse of this operator.\n\n        The inverse of the operator composition is the composition of\n        the inverses in reverse order:\n\n            ``OperatorComp(left, right).inverse ==``\n            ``OperatorComp(right.inverse, left.inverse)``\n        \"\"\"\n        return OperatorComp(self.right.inverse, self.left.inverse,\n                            self.__tmp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the derivative of the operator composition.", "response": "def derivative(self, x):\n        \"\"\"Return the operator derivative.\n\n        The derivative of the operator composition follows the chain\n        rule:\n\n            ``OperatorComp(left, right).derivative(y) ==\n            OperatorComp(left.derivative(right(y)), right.derivative(y))``\n\n        Parameters\n        ----------\n        x : `domain` `element-like`\n            Evaluation point of the derivative. Needs to be usable as\n            input for the ``right`` operator.\n        \"\"\"\n        if self.is_linear:\n            return self\n        else:\n            if self.left.is_linear:\n                left_deriv = self.left\n            else:\n                left_deriv = self.left.derivative(self.right(x))\n\n            right_deriv = self.right.derivative(x)\n\n            return OperatorComp(left_deriv, right_deriv,\n                                self.__tmp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef adjoint(self):\n        if not self.is_linear:\n            raise OpNotImplementedError('nonlinear operators have no adjoint')\n\n        return OperatorComp(self.right.adjoint, self.left.adjoint,\n                            self.__tmp)", "response": "Return the adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(self, x, out=None):\n        if out is None:\n            return self.left(x) * self.right(x)\n        else:\n            tmp = self.right.range.element()\n            # Write to `tmp` first, otherwise aliased `x` and `out` lead\n            # to wrong result\n            self.left(x, out=tmp)\n            self.right(x, out=out)\n            out *= tmp", "response": "Implement self x [ out ]."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the derivative at x.", "response": "def derivative(self, x):\n        \"\"\"Return the derivative at ``x``.\"\"\"\n        if self.is_linear:\n            return self\n        else:\n            left = self.right(x) * self.left.derivative(x)\n            right = self.left(x) * self.right.derivative(x)\n            return left + right"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(self, x, out=None):\n        if out is None:\n            return self.scalar * self.operator(x)\n        else:\n            self.operator(x, out=out)\n            out *= self.scalar", "response": "Implement self x [ out ]."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inverse(self):\n        if self.scalar == 0.0:\n            raise ZeroDivisionError('{} not invertible'.format(self))\n\n        return self.operator.inverse * (1.0 / self.scalar)", "response": "Inverse of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef adjoint(self):\n\n        if not self.is_linear:\n            raise OpNotImplementedError('nonlinear operators have no adjoint')\n\n        return self.scalar.conjugate() * self.operator.adjoint", "response": "Adjoint of the operator multiplication is the adjoint of the underlying operator multiplication."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x, out=None):\n        if out is None:\n            return self.operator(self.scalar * x)\n        else:\n            if self.__tmp is not None:\n                tmp = self.__tmp\n            else:\n                tmp = self.domain.element()\n            tmp.lincomb(self.scalar, x)\n            self.operator(tmp, out=out)", "response": "Implement self ( x out = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef derivative(self, x):\n        return self.scalar * self.operator.derivative(self.scalar * x)", "response": "Return the derivative at x."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x, out=None):\n        if out is None:\n            return self.vector * self.functional(x)\n        else:\n            scalar = self.functional(x)\n            out.lincomb(scalar, self.vector)", "response": "Implement self ( x out = None )."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the derivative at x.", "response": "def derivative(self, x):\n        \"\"\"Return the derivative at ``x``.\n\n        Left scalar multiplication and derivative are commutative:\n\n            ``FunctionalLeftVectorMult(op, y).derivative(z) ==\n            FunctionalLeftVectorMult(op.derivative(z), y)``\n\n        Returns\n        -------\n        derivative : `FunctionalLeftVectorMult`\n        \"\"\"\n        if self.is_linear:\n            return self\n        else:\n            return FunctionalLeftVectorMult(self.functional.derivative(x),\n                                            self.vector)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef adjoint(self):\n\n        if not self.is_linear:\n            raise OpNotImplementedError('nonlinear operators have no adjoint')\n\n        return OperatorComp(self.functional.adjoint, self.vector.T)", "response": "Adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimplementing self x [ out ].", "response": "def _call(self, x, out=None):\n        \"\"\"Implement ``self(x[, out])``.\"\"\"\n        if out is None:\n            return self.operator(x) * self.vector\n        else:\n            self.operator(x, out=out)\n            out *= self.vector"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call(self, x, out=None):\n        if out is None:\n            return self.operator(x * self.vector)\n        else:\n            tmp = self.domain.element()\n            x.multiply(self.vector, out=tmp)\n            self.operator(tmp, out=out)", "response": "Implement self x [ out ]."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef derivative(self, x):\n        if self.is_linear:\n            return self\n        else:\n            return self.operator.derivative(self.vector * x) * self.vector", "response": "Return the derivative at x."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the adjoint of the underlying operator.", "response": "def adjoint(self):\n        \"\"\"Adjoint of this operator.\n\n        The adjoint of the operator right vector multiplication is the left\n        multiplication of the given operator by the complex conjugate of the\n        given vector.\n\n            ``OperatorRightVectorMult(op, y).adjoint ==\n            OperatorLeftVectorMult(op.adjoint, y.conj())``\n\n        Returns\n        -------\n        adjoint : `OperatorLeftVectorMult`\n\n        Raises\n        ------\n        OpNotImplementedError\n            If the underlying operator is non-linear.\n        \"\"\"\n        if not self.is_linear:\n            raise OpNotImplementedError('nonlinear operators have no adjoint')\n\n        if self.vector.space.is_real:\n            # The complex conjugate of a real vector is the vector itself.\n            return self.vector * self.operator.adjoint\n        else:\n            return self.vector.conj() * self.operator.adjoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _broadcast_arithmetic(op):\n    def _broadcast_arithmetic_impl(self, other):\n        if (self.space.is_power_space and other in self.space[0]):\n            results = []\n            for xi in self:\n                res = getattr(xi, op)(other)\n                if res is NotImplemented:\n                    return NotImplemented\n                else:\n                    results.append(res)\n\n            return self.space.element(results)\n        else:\n            return getattr(LinearSpaceElement, op)(self, other)\n\n    # Set docstring\n    docstring = \"\"\"Broadcasted {op}.\"\"\".format(op=op)\n    _broadcast_arithmetic_impl.__doc__ = docstring\n\n    return _broadcast_arithmetic_impl", "response": "Returns a function that performs broadcasting of the given operator with the given other."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstripping the SPACE. element part from a repr.", "response": "def _strip_space(x):\n    \"\"\"Strip the SPACE.element( ... ) part from a repr.\"\"\"\n    r = repr(x)\n    space_repr = '{!r}.element('.format(x.space)\n    if r.startswith(space_repr) and r.endswith(')'):\n        r = r[len(space_repr):-1]\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nindents a string by 4 characters.", "response": "def _indent(x):\n    \"\"\"Indent a string by 4 characters.\"\"\"\n    lines = x.splitlines()\n    for i, line in enumerate(lines):\n        lines[i] = '    ' + line\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the shape of the product space.", "response": "def shape(self):\n        \"\"\"Total spaces per axis, computed recursively.\n\n        The recursion ends at the fist level that does not have a shape.\n\n        Examples\n        --------\n        >>> r2, r3 = odl.rn(2), odl.rn(3)\n        >>> pspace = odl.ProductSpace(r2, r3)\n        >>> pspace.shape\n        (2,)\n        >>> pspace2 = odl.ProductSpace(pspace, 3)\n        >>> pspace2.shape\n        (3, 2)\n\n        If the space is a \"pure\" product space, shape recurses all the way\n        into the components:\n\n        >>> r2_2 = odl.ProductSpace(r2, 3)\n        >>> r2_2.shape\n        (3, 2)\n        \"\"\"\n        if len(self) == 0:\n            return ()\n        elif self.is_power_space:\n            try:\n                sub_shape = self[0].shape\n            except AttributeError:\n                sub_shape = ()\n        else:\n            sub_shape = ()\n\n        return (len(self),) + sub_shape"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dtype(self):\n        dtypes = [space.dtype for space in self.spaces]\n\n        if all(dtype == dtypes[0] for dtype in dtypes):\n            return dtypes[0]\n        else:\n            raise AttributeError(\"`dtype`'s of subspaces not equal\")", "response": "The data type of this space."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef astype(self, dtype):\n        if dtype is None:\n            # Need to filter this out since Numpy iterprets it as 'float'\n            raise ValueError('`None` is not a valid data type')\n\n        dtype = np.dtype(dtype)\n        current_dtype = getattr(self, 'dtype', object)\n\n        if dtype == current_dtype:\n            return self\n        else:\n            return ProductSpace(*[space.astype(dtype)\n                                  for space in self.spaces])", "response": "Return a copy of this space with new dtype."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element(self, inp=None, cast=True):\n        # If data is given as keyword arg, prefer it over arg list\n        if inp is None:\n            inp = [space.element() for space in self.spaces]\n\n        if inp in self:\n            return inp\n\n        if len(inp) != len(self):\n            raise ValueError('length of `inp` {} does not match length of '\n                             'space {}'.format(len(inp), len(self)))\n\n        if (all(isinstance(v, LinearSpaceElement) and v.space == space\n                for v, space in zip(inp, self.spaces))):\n            parts = list(inp)\n        elif cast:\n            # Delegate constructors\n            parts = [space.element(arg)\n                     for arg, space in zip(inp, self.spaces)]\n        else:\n            raise TypeError('input {!r} not a sequence of elements of the '\n                            'component spaces'.format(inp))\n\n        return self.element_type(self, parts)", "response": "Create an element in the product space."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef examples(self):\n        for examples in product(*[spc.examples for spc in self.spaces]):\n            name = ', '.join(name for name, _ in examples)\n            element = self.element([elem for _, elem in examples])\n            yield (name, element)", "response": "Return examples from all sub - spaces."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _lincomb(self, a, x, b, y, out):\n        for space, xp, yp, outp in zip(self.spaces, x.parts, y.parts,\n                                       out.parts):\n            space._lincomb(a, xp, b, yp, outp)", "response": "Linear combination of two log objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmultiply two sets of class - level products.", "response": "def _multiply(self, x1, x2, out):\n        \"\"\"Product ``out = x1 * x2``.\"\"\"\n        for spc, xp, yp, outp in zip(self.spaces, x1.parts, x2.parts,\n                                     out.parts):\n            spc._multiply(xp, yp, outp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the data of this vector as a numpy array.", "response": "def asarray(self, out=None):\n        \"\"\"Extract the data of this vector as a numpy array.\n\n        Only available if `is_power_space` is True.\n\n        The ordering is such that it commutes with indexing::\n\n            self[ind].asarray() == self.asarray()[ind]\n\n        Parameters\n        ----------\n        out : `numpy.ndarray`, optional\n            Array in which the result should be written in-place.\n            Has to be contiguous and of the correct dtype and\n            shape.\n\n        Raises\n        ------\n        ValueError\n            If `is_power_space` is false.\n\n        Examples\n        --------\n        >>> spc = odl.ProductSpace(odl.rn(3), 2)\n        >>> x = spc.element([[ 1.,  2.,  3.],\n        ...                  [ 4.,  5.,  6.]])\n        >>> x.asarray()\n        array([[ 1.,  2.,  3.],\n               [ 4.,  5.,  6.]])\n        \"\"\"\n        if not self.space.is_power_space:\n            raise ValueError('cannot use `asarray` if `space.is_power_space` '\n                             'is `False`')\n        else:\n            if out is None:\n                out = np.empty(self.shape, self.dtype)\n\n            for i in range(len(self)):\n                out[i] = np.asarray(self[i])\n            return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef real(self):\n        real_part = [part.real for part in self.parts]\n        return self.space.real_space.element(real_part)", "response": "Real part of the element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef real(self, newreal):\n        try:\n            iter(newreal)\n        except TypeError:\n            # `newreal` is not iterable, assume it can be assigned to\n            # all indexed parts\n            for part in self.parts:\n                part.real = newreal\n            return\n\n        if self.space.is_power_space:\n            try:\n                # Set same value in all parts\n                for part in self.parts:\n                    part.real = newreal\n            except (ValueError, TypeError):\n                # Iterate over all parts and set them separately\n                for part, new_re in zip(self.parts, newreal):\n                    part.real = new_re\n                pass\n        elif len(newreal) == len(self):\n            for part, new_re in zip(self.parts, newreal):\n                part.real = new_re\n        else:\n            raise ValueError(\n                'dimensions of the new real part does not match the space, '\n                'got element {} to set real part of {}'.format(newreal, self))", "response": "Setter for the real part of this element."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imag(self):\n        imag_part = [part.imag for part in self.parts]\n        return self.space.real_space.element(imag_part)", "response": "Imaginary part of the element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef imag(self, newimag):\n        try:\n            iter(newimag)\n        except TypeError:\n            # `newimag` is not iterable, assume it can be assigned to\n            # all indexed parts\n            for part in self.parts:\n                part.imag = newimag\n            return\n\n        if self.space.is_power_space:\n            try:\n                # Set same value in all parts\n                for part in self.parts:\n                    part.imag = newimag\n            except (ValueError, TypeError):\n                # Iterate over all parts and set them separately\n                for part, new_im in zip(self.parts, newimag):\n                    part.imag = new_im\n                pass\n        elif len(newimag) == len(self):\n            for part, new_im in zip(self.parts, newimag):\n                part.imag = new_im\n        else:\n            raise ValueError(\n                'dimensions of the new imaginary part does not match the '\n                'space, got element {} to set real part of {}}'\n                ''.format(newimag, self))", "response": "Setter for the imaginary part of this element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncomplex conjugate of the element.", "response": "def conj(self):\n        \"\"\"Complex conjugate of the element.\"\"\"\n        complex_conj = [part.conj() for part in self.parts]\n        return self.space.element(complex_conj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show(self, title=None, indices=None, **kwargs):\n        if title is None:\n            title = 'ProductSpaceElement'\n\n        if indices is None:\n            if len(self) < 5:\n                indices = list(range(len(self)))\n            else:\n                indices = list(np.linspace(0, len(self) - 1, 4, dtype=int))\n        else:\n            if (isinstance(indices, tuple) or\n                    (isinstance(indices, list) and\n                     not all(isinstance(idx, Integral) for idx in indices))):\n                # Tuples or lists containing non-integers index by axis.\n                # We use the first index for the current pspace and pass\n                # on the rest.\n                indices, kwargs['indices'] = indices[0], indices[1:]\n\n            # Support `indices=[None, 0, None]` like syntax (`indices` is\n            # the first entry as of now in that case)\n            if indices is None:\n                indices = slice(None)\n\n            if isinstance(indices, slice):\n                indices = list(range(*indices.indices(len(self))))\n            elif isinstance(indices, Integral):\n                indices = [indices]\n            else:\n                # Use `indices` as-is\n                pass\n\n        in_figs = kwargs.pop('fig', None)\n        in_figs = [None] * len(indices) if in_figs is None else in_figs\n\n        figs = []\n        parts = self[indices]\n        if len(parts) == 0:\n            return ()\n        elif len(parts) == 1:\n            # Don't extend the title if there is only one plot\n            fig = parts[0].show(title=title, fig=in_figs[0], **kwargs)\n            figs.append(fig)\n        else:\n            # Extend titles by indexed part to make them distinguishable\n            for i, part, fig in zip(indices, parts, in_figs):\n                fig = part.show(title='{}. Part {}'.format(title, i), fig=fig,\n                                **kwargs)\n                figs.append(fig)\n\n        return tuple(figs)", "response": "Display the parts of this product space element graphically."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inner(self, x1, x2):\n        if self.exponent != 2.0:\n            raise NotImplementedError('no inner product defined for '\n                                      'exponent != 2 (got {})'\n                                      ''.format(self.exponent))\n\n        inners = np.fromiter(\n            (x1i.inner(x2i) for x1i, x2i in zip(x1, x2)),\n            dtype=x1[0].space.dtype, count=len(x1))\n\n        inner = np.dot(inners, self.array)\n        if is_real_dtype(x1[0].dtype):\n            return float(inner)\n        else:\n            return complex(inner)", "response": "Calculate the array - weighted inner product of two elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef norm(self, x):\n        if self.exponent == 2.0:\n            norm_squared = self.inner(x, x).real  # TODO: optimize?!\n            return np.sqrt(norm_squared)\n        else:\n            norms = np.fromiter(\n                (xi.norm() for xi in x), dtype=np.float64, count=len(x))\n            if self.exponent in (1.0, float('inf')):\n                norms *= self.array\n            else:\n                norms *= self.array ** (1.0 / self.exponent)\n\n            return float(np.linalg.norm(norms, ord=self.exponent))", "response": "Calculate the array - weighted norm of an element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inner(self, x1, x2):\n        if self.exponent != 2.0:\n            raise NotImplementedError('no inner product defined for '\n                                      'exponent != 2 (got {})'\n                                      ''.format(self.exponent))\n\n        inners = np.fromiter(\n            (x1i.inner(x2i) for x1i, x2i in zip(x1, x2)),\n            dtype=x1[0].space.dtype, count=len(x1))\n\n        inner = self.const * np.sum(inners)\n        return x1.space.field.element(inner)", "response": "Calculate the constant - weighted inner product of two products."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the constant - weighted distance between two products.", "response": "def dist(self, x1, x2):\n        \"\"\"Calculate the constant-weighted distance between two elements.\n\n        Parameters\n        ----------\n        x1, x2 : `ProductSpaceElement`\n            Elements whose mutual distance is calculated.\n\n        Returns\n        -------\n        dist : float\n            The distance between the elements.\n        \"\"\"\n        dnorms = np.fromiter(\n            ((x1i - x2i).norm() for x1i, x2i in zip(x1, x2)),\n            dtype=np.float64, count=len(x1))\n\n        if self.exponent == float('inf'):\n            return self.const * np.linalg.norm(dnorms, ord=self.exponent)\n        else:\n            return (self.const ** (1 / self.exponent) *\n                    np.linalg.norm(dnorms, ord=self.exponent))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef euler_matrix(phi, theta=None, psi=None):\n    if theta is None and psi is None:\n        squeeze_out = (np.shape(phi) == ())\n        ndim = 2\n        phi = np.array(phi, dtype=float, copy=False, ndmin=1)\n        theta = psi = 0.0\n    else:\n        # `None` broadcasts like a scalar\n        squeeze_out = (np.broadcast(phi, theta, psi).shape == ())\n        ndim = 3\n        phi = np.array(phi, dtype=float, copy=False, ndmin=1)\n        if theta is None:\n            theta = 0.0\n        if psi is None:\n            psi = 0.0\n        theta = np.array(theta, dtype=float, copy=False, ndmin=1)\n        psi = np.array(psi, dtype=float, copy=False, ndmin=1)\n        ndim = 3\n\n    cph = np.cos(phi)\n    sph = np.sin(phi)\n    cth = np.cos(theta)\n    sth = np.sin(theta)\n    cps = np.cos(psi)\n    sps = np.sin(psi)\n\n    if ndim == 2:\n        mat = np.array([[cph, -sph],\n                        [sph, cph]])\n    else:\n        mat = np.array([\n            [cph * cps - sph * cth * sps,\n             -cph * sps - sph * cth * cps,\n             sph * sth],\n            [sph * cps + cph * cth * sps,\n             -sph * sps + cph * cth * cps,\n             -cph * sth],\n            [sth * sps + 0 * cph,\n             sth * cps + 0 * cph,\n             cth + 0 * (cph + cps)]])  # Make sure all components broadcast\n\n    if squeeze_out:\n        return mat.squeeze()\n    else:\n        # Move the `(ndim, ndim)` axes to the end\n        extra_dims = len(np.broadcast(phi, theta, psi).shape)\n        newaxes = list(range(2, 2 + extra_dims)) + [0, 1]\n        return np.transpose(mat, newaxes)", "response": "Return a rotation matrix corresponding to the given angles."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef axis_rotation(axis, angle, vectors, axis_shift=(0, 0, 0)):\n    rot_matrix = axis_rotation_matrix(axis, angle)\n    vectors = np.asarray(vectors, dtype=float)\n    if vectors.shape == (3,):\n        vectors = vectors[None, :]\n    elif vectors.ndim == 2 and vectors.shape[1] == 3:\n        pass\n    else:\n        raise ValueError('`vectors` must have shape (3,) or (N, 3), got array '\n                         'with shape {}'.format(vectors.shape))\n\n    # Get `axis_shift` part that is perpendicular to `axis`\n    axis_shift = np.asarray(axis_shift, dtype=float)\n    axis = np.asarray(axis, dtype=float)\n    axis_shift = axis_shift - axis.dot(axis_shift) * axis\n\n    # Shift vectors with the negative of the axis shift to move the rotation\n    # center to the origin. Then rotate and shift back.\n    centered_vecs = vectors - axis_shift[None, :]\n    # Need to transpose the vectors to make the axis of length 3 come first\n    rot_vecs = rot_matrix.dot(centered_vecs.T).T\n    return axis_shift[None, :] + rot_vecs", "response": "Return a sequence of vectors rotated around an axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef axis_rotation_matrix(axis, angle):\n    scalar_out = (np.shape(angle) == ())\n    axis = np.asarray(axis)\n    if axis.shape != (3,):\n        raise ValueError('`axis` shape must be (3,), got {}'\n                         ''.format(axis.shape))\n\n    angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n\n    cross_mat = np.array([[0, -axis[2], axis[1]],\n                          [axis[2], 0, -axis[0]],\n                          [-axis[1], axis[0], 0]])\n    dy_mat = np.outer(axis, axis)\n    id_mat = np.eye(3)\n    cos_ang = np.cos(angle)\n    sin_ang = np.sin(angle)\n\n    # Add extra dimensions for broadcasting\n    extra_dims = cos_ang.ndim\n    mat_slc = (None,) * extra_dims + (slice(None), slice(None))\n    ang_slc = (slice(None),) * extra_dims + (None, None)\n    # Matrices will have shape (1, ..., 1, ndim, ndim)\n    cross_mat = cross_mat[mat_slc]\n    dy_mat = dy_mat[mat_slc]\n    id_mat = id_mat[mat_slc]\n    # Angle arrays will have shape (..., 1, 1)\n    cos_ang = cos_ang[ang_slc]\n    sin_ang = sin_ang[ang_slc]\n\n    axis_mat = cos_ang * id_mat + (1. - cos_ang) * dy_mat + sin_ang * cross_mat\n    if scalar_out:\n        return axis_mat.squeeze()\n    else:\n        return axis_mat", "response": "Return the matrix of the rotation around an axis in 3d."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform_system(principal_vec, principal_default, other_vecs,\n                     matrix=None):\n    \"\"\"Transform vectors with either ``matrix`` or based on ``principal_vec``.\n\n    The logic of this function is as follows:\n\n    - If ``matrix`` is not ``None``, transform ``principal_vec`` and\n      all vectors in ``other_vecs`` by ``matrix``, ignoring\n      ``principal_default``.\n    - If ``matrix`` is ``None``, compute the rotation matrix from\n      ``principal_default`` to ``principal_vec``, not including the\n      dilation. Apply that rotation to all vectors in ``other_vecs``.\n\n    **Note:** All vectors must have the same shape and match the shape\n    of ``matrix`` if given.\n\n    Parameters\n    ----------\n    principal_vec : `array-like`, shape ``(ndim,)``\n        Vector that defines the transformation if ``matrix`` is not\n        provided.\n    principal_default : `array-like`, shape ``(ndim,)``\n        Default value for ``principal_vec``. The deviation from this\n        determines the transformation.\n        If ``matrix`` is given, this has no effect.\n    other_vecs : sequence of ``None`` or `array-like`'s with shape ``(ndim,)``\n        The other vectors that should be transformed. ``None`` entries\n        are just appended as-is.\n    matrix : `array-like`, shape ``(ndim, ndim)``, optional\n        Explicit transformation matrix to be applied to the vectors.\n        It is allowed to include a constant scaling but shouldn't have\n        strongly varying directional scaling (bad condition).\n\n    Returns\n    -------\n    transformed_vecs : tuple of `numpy.ndarray`, shape ``(ndim,)``\n        The transformed vectors. The first entry is (the transformed)\n        ``principal_vec``, followed by the transformed ``other_vecs``.\n        Thus the length of the tuple is ``len(other_vecs) + 1``.\n    \"\"\"\n    transformed_vecs = []\n    principal_vec = np.asarray(principal_vec, dtype=float)\n    ndim = principal_vec.shape[0]\n\n    if matrix is None:\n        # Separate into dilation and rotation. The dilation is only used\n        # for comparison, not in the final matrix.\n        principal_default = np.asarray(principal_default, dtype=float)\n\n        pr_norm = np.linalg.norm(principal_vec)\n        pr_default_norm = np.linalg.norm(principal_default)\n\n        if pr_default_norm == 0.0 and pr_norm != 0.0:\n            raise ValueError('no transformation from {} to {}'\n                             ''.format(principal_default, principal_vec))\n        elif pr_norm == 0.0 and pr_default_norm != 0.0:\n            raise ValueError('transformation from {} to {} is singular'\n                             ''.format(principal_default, principal_vec))\n        elif pr_norm == 0.0 and pr_default_norm == 0.0:\n            dilation = 1.0\n        else:\n            dilation = (np.linalg.norm(principal_vec) /\n                        np.linalg.norm(principal_default))\n\n        # Determine the rotation part\n        if np.allclose(principal_vec, dilation * principal_default):\n            # Dilation only\n            matrix = np.eye(ndim)\n        else:\n            matrix = rotation_matrix_from_to(principal_default, principal_vec)\n\n        # This one goes straight in\n        transformed_vecs.append(principal_vec)\n\n    else:\n        matrix = np.asarray(matrix, dtype=float)\n        if matrix.shape != (ndim, ndim):\n            raise ValueError('matrix shape must be {}, got {}'\n                             ''.format((ndim, ndim), matrix.shape))\n\n        # Check matrix condition\n        svals = np.linalg.svd(matrix, compute_uv=False)\n        condition = np.inf if 0.0 in svals else svals[0] / svals[-1]\n        if condition > 1e6:\n            raise np.linalg.LinAlgError(\n                'matrix is badly conditioned: condition number is {}'\n                ''.format(condition))\n\n        transformed_vecs.append(matrix.dot(principal_vec))\n\n    for vec in other_vecs:\n        if vec is None:\n            transformed_vecs.append(None)\n        else:\n            transformed_vecs.append(matrix.dot(vec))\n\n    return tuple(transformed_vecs)", "response": "Transform a set of vectors with either matrix or based on principal_vec and other_vecs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perpendicular_vector(vec):\n    squeeze_out = (np.ndim(vec) == 1)\n    vec = np.array(vec, dtype=float, copy=False, ndmin=2)\n\n    if np.any(np.all(vec == 0, axis=-1)):\n        raise ValueError('zero vector')\n\n    result = np.zeros(vec.shape)\n    cond = np.any(vec[..., :2] != 0, axis=-1)\n    result[cond, 0] = -vec[cond, 1]\n    result[cond, 1] = vec[cond, 0]\n    result[~cond, 0] = 1\n    result /= np.linalg.norm(result, axis=-1, keepdims=True)\n\n    if squeeze_out:\n        result = result.squeeze()\n\n    return result", "response": "Return a vector perpendicular to a set of time - series components."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_inside_bounds(value, params):\n    if value in params:\n        # Single parameter\n        return True\n    else:\n        if params.ndim == 1:\n            return params.contains_all(np.ravel(value))\n        else:\n            # Flesh out and flatten to check bounds\n            bcast_value = np.broadcast_arrays(*value)\n            stacked_value = np.vstack(bcast_value)\n            flat_value = stacked_value.reshape(params.ndim, -1)\n            return params.contains_all(flat_value)", "response": "Check if value is contained in params."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pyfftw_call(array_in, array_out, direction='forward', axes=None,\n                halfcomplex=False, **kwargs):\n    \"\"\"Calculate the DFT with pyfftw.\n\n    The discrete Fourier (forward) transform calcuates the sum::\n\n        f_hat[k] = sum_j( f[j] * exp(-2*pi*1j * j*k/N) )\n\n    where the summation is taken over all indices\n    ``j = (j[0], ..., j[d-1])`` in the range ``0 <= j < N``\n    (component-wise), with ``N`` being the shape of the input array.\n\n    The output indices ``k`` lie in the same range, except\n    for half-complex transforms, where the last axis ``i`` in ``axes``\n    is shortened to ``0 <= k[i] < floor(N[i]/2) + 1``.\n\n    In the backward transform, sign of the the exponential argument\n    is flipped.\n\n    Parameters\n    ----------\n    array_in : `numpy.ndarray`\n        Array to be transformed\n    array_out : `numpy.ndarray`\n        Output array storing the transformed values, may be aliased\n        with ``array_in``.\n    direction : {'forward', 'backward'}, optional\n        Direction of the transform\n    axes : int or sequence of ints, optional\n        Dimensions along which to take the transform. ``None`` means\n        using all axes and is equivalent to ``np.arange(ndim)``.\n    halfcomplex : bool, optional\n        If ``True``, calculate only the negative frequency part along the\n        last axis. If ``False``, calculate the full complex FFT.\n        This option can only be used with real input data.\n\n    Other Parameters\n    ----------------\n    fftw_plan : ``pyfftw.FFTW``, optional\n        Use this plan instead of calculating a new one. If specified,\n        the options ``planning_effort``, ``planning_timelimit`` and\n        ``threads`` have no effect.\n    planning_effort : str, optional\n        Flag for the amount of effort put into finding an optimal\n        FFTW plan. See the `FFTW doc on planner flags\n        <http://www.fftw.org/fftw3_doc/Planner-Flags.html>`_.\n        Available options: {'estimate', 'measure', 'patient', 'exhaustive'}\n        Default: 'estimate'\n    planning_timelimit : float or ``None``, optional\n        Limit planning time to roughly this many seconds.\n        Default: ``None`` (no limit)\n    threads : int, optional\n        Number of threads to use.\n        Default: Number of CPUs if the number of data points is larger\n        than 4096, else 1.\n    normalise_idft : bool, optional\n        If ``True``, the result of the backward transform is divided by\n        ``1 / N``, where ``N`` is the total number of points in\n        ``array_in[axes]``. This ensures that the IDFT is the true\n        inverse of the forward DFT.\n        Default: ``False``\n    import_wisdom : filename or file handle, optional\n        File to load FFTW wisdom from. If the file does not exist,\n        it is ignored.\n    export_wisdom : filename or file handle, optional\n        File to append the accumulated FFTW wisdom to\n\n    Returns\n    -------\n    fftw_plan : ``pyfftw.FFTW``\n        The plan object created from the input arguments. It can be\n        reused for transforms of the same size with the same data types.\n        Note that reuse only gives a speedup if the initial plan\n        used a planner flag other than ``'estimate'``.\n        If ``fftw_plan`` was specified, the returned object is a\n        reference to it.\n\n    Notes\n    -----\n    * The planning and direction flags can also be specified as\n      capitalized and prepended by ``'FFTW_'``, i.e. in the original\n      FFTW form.\n    * For a ``halfcomplex`` forward transform, the arrays must fulfill\n      ``array_out.shape[axes[-1]] == array_in.shape[axes[-1]] // 2 + 1``,\n      and vice versa for backward transforms.\n    * All planning schemes except ``'estimate'`` require an internal copy\n      of the input array but are often several times faster after the\n      first call (measuring results are cached). Typically,\n      'measure' is a good compromise. If you cannot afford the copy,\n      use ``'estimate'``.\n    * If a plan is provided via the ``fftw_plan`` parameter, no copy\n      is needed internally.\n    \"\"\"\n    import pickle\n\n    if not array_in.flags.aligned:\n        raise ValueError('input array not aligned')\n\n    if not array_out.flags.aligned:\n        raise ValueError('output array not aligned')\n\n    if axes is None:\n        axes = tuple(range(array_in.ndim))\n\n    axes = normalized_axes_tuple(axes, array_in.ndim)\n\n    direction = _pyfftw_to_local(direction)\n    fftw_plan_in = kwargs.pop('fftw_plan', None)\n    planning_effort = _pyfftw_to_local(kwargs.pop('planning_effort',\n                                                  'estimate'))\n    planning_timelimit = kwargs.pop('planning_timelimit', None)\n    threads = kwargs.pop('threads', None)\n    normalise_idft = kwargs.pop('normalise_idft', False)\n    wimport = kwargs.pop('import_wisdom', '')\n    wexport = kwargs.pop('export_wisdom', '')\n\n    # Cast input to complex if necessary\n    array_in_copied = False\n    if is_real_dtype(array_in.dtype) and not halfcomplex:\n        # Need to cast array_in to complex dtype\n        array_in = array_in.astype(complex_dtype(array_in.dtype))\n        array_in_copied = True\n\n    # Do consistency checks on the arguments\n    _pyfftw_check_args(array_in, array_out, axes, halfcomplex, direction)\n\n    # Import wisdom if possible\n    if wimport:\n        try:\n            with open(wimport, 'rb') as wfile:\n                wisdom = pickle.load(wfile)\n        except IOError:\n            wisdom = []\n        except TypeError:  # Got file handle\n            wisdom = pickle.load(wimport)\n\n        if wisdom:\n            pyfftw.import_wisdom(wisdom)\n\n    # Copy input array if it hasn't been done yet and the planner is likely\n    # to destroy it. If we already have a plan, we don't have to worry.\n    planner_destroys = _pyfftw_destroys_input(\n        [planning_effort], direction, halfcomplex, array_in.ndim)\n    must_copy_array_in = fftw_plan_in is None and planner_destroys\n\n    if must_copy_array_in and not array_in_copied:\n        plan_arr_in = np.empty_like(array_in)\n        flags = [_local_to_pyfftw(planning_effort), 'FFTW_DESTROY_INPUT']\n    else:\n        plan_arr_in = array_in\n        flags = [_local_to_pyfftw(planning_effort)]\n\n    if fftw_plan_in is None:\n        if threads is None:\n            if plan_arr_in.size <= 4096:  # Trade-off wrt threading overhead\n                threads = 1\n            else:\n                threads = cpu_count()\n\n        fftw_plan = pyfftw.FFTW(\n            plan_arr_in, array_out, direction=_local_to_pyfftw(direction),\n            flags=flags, planning_timelimit=planning_timelimit,\n            threads=threads, axes=axes)\n    else:\n        fftw_plan = fftw_plan_in\n\n    fftw_plan(array_in, array_out, normalise_idft=normalise_idft)\n\n    if wexport:\n        try:\n            with open(wexport, 'ab') as wfile:\n                pickle.dump(pyfftw.export_wisdom(), wfile)\n        except TypeError:  # Got file handle\n            pickle.dump(pyfftw.export_wisdom(), wexport)\n\n    return fftw_plan", "response": "This function calls the pyfftw. Fourier transform with the input array and outputs the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pyfftw_destroys_input(flags, direction, halfcomplex, ndim):\n    if any(flag in flags or _pyfftw_to_local(flag) in flags\n           for flag in ('FFTW_MEASURE', 'FFTW_PATIENT', 'FFTW_EXHAUSTIVE',\n                        'FFTW_DESTROY_INPUT')):\n        return True\n    elif (direction in ('backward', 'FFTW_BACKWARD') and halfcomplex and\n          ndim != 1):\n        return True\n    else:\n        return False", "response": "Return True if FFTW destroys an input array False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _pyfftw_check_args(arr_in, arr_out, axes, halfcomplex, direction):\n    if len(set(axes)) != len(axes):\n        raise ValueError('duplicate axes are not allowed')\n\n    if direction == 'forward':\n        out_shape = list(arr_in.shape)\n        if halfcomplex:\n            try:\n                out_shape[axes[-1]] = arr_in.shape[axes[-1]] // 2 + 1\n            except IndexError:\n                raise IndexError('axis index {} out of range for array '\n                                 'with {} axes'\n                                 ''.format(axes[-1], arr_in.ndim))\n\n        if arr_out.shape != tuple(out_shape):\n            raise ValueError('expected output shape {}, got {}'\n                             ''.format(tuple(out_shape), arr_out.shape))\n\n        if is_real_dtype(arr_in.dtype):\n            out_dtype = complex_dtype(arr_in.dtype)\n        elif halfcomplex:\n            raise ValueError('cannot combine halfcomplex forward transform '\n                             'with complex input')\n        else:\n            out_dtype = arr_in.dtype\n\n        if arr_out.dtype != out_dtype:\n            raise ValueError('expected output dtype {}, got {}'\n                             ''.format(dtype_repr(out_dtype),\n                                       dtype_repr(arr_out.dtype)))\n\n    elif direction == 'backward':\n        in_shape = list(arr_out.shape)\n        if halfcomplex:\n            try:\n                in_shape[axes[-1]] = arr_out.shape[axes[-1]] // 2 + 1\n            except IndexError as err:\n                raise IndexError('axis index {} out of range for array '\n                                 'with {} axes'\n                                 ''.format(axes[-1], arr_out.ndim))\n\n        if arr_in.shape != tuple(in_shape):\n            raise ValueError('expected input shape {}, got {}'\n                             ''.format(tuple(in_shape), arr_in.shape))\n\n        if is_real_dtype(arr_out.dtype):\n            in_dtype = complex_dtype(arr_out.dtype)\n        elif halfcomplex:\n            raise ValueError('cannot combine halfcomplex backward transform '\n                             'with complex output')\n        else:\n            in_dtype = arr_out.dtype\n\n        if arr_in.dtype != in_dtype:\n            raise ValueError('expected input dtype {}, got {}'\n                             ''.format(dtype_repr(in_dtype),\n                                       dtype_repr(arr_in.dtype)))\n\n    else:  # Shouldn't happen\n        raise RuntimeError", "response": "Raise an error if anything is not ok with in and out."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of the method at the given point.", "response": "def _call(self, dx):\n        \"\"\"Return ``self(x)``.\"\"\"\n        x = self.point\n\n        dx_norm = dx.norm()\n        if dx_norm == 0:\n            return 0\n\n        scaled_dx = dx * (self.step / dx_norm)\n\n        if self.method == 'backward':\n            dAdx = self.operator(x) - self.operator(x - scaled_dx)\n        elif self.method == 'forward':\n            dAdx = self.operator(x + scaled_dx) - self.operator(x)\n        elif self.method == 'central':\n            dAdx = (self.operator(x + scaled_dx / 2) -\n                    self.operator(x - scaled_dx / 2))\n        else:\n            raise RuntimeError('unknown method')\n\n        return dAdx * (dx_norm / self.step)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the functional vector at a time.", "response": "def _call(self, x):\n        \"\"\"Return ``self(x)``.\"\"\"\n        # The algorithm takes finite differences in one dimension at a time\n        # reusing the dx vector to improve efficiency.\n        dfdx = self.domain.zero()\n        dx = self.domain.zero()\n\n        if self.method == 'backward':\n            fx = self.functional(x)\n            for i in range(self.domain.size):\n                dx[i - 1] = 0  # reset step from last iteration\n                dx[i] = self.step\n                dfdx[i] = fx - self.functional(x - dx)\n        elif self.method == 'forward':\n            fx = self.functional(x)\n            for i in range(self.domain.size):\n                dx[i - 1] = 0  # reset step from last iteration\n                dx[i] = self.step\n                dfdx[i] = self.functional(x + dx) - fx\n        elif self.method == 'central':\n            for i in range(self.domain.size):\n                dx[i - 1] = 0  # reset step from last iteration\n                dx[i] = self.step / 2\n                dfdx[i] = self.functional(x + dx) - self.functional(x - dx)\n        else:\n            raise RuntimeError('unknown method')\n\n        dfdx /= self.step\n        return dfdx"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derivative(self, point):\n        return NumericalDerivative(self, point,\n                                   method=self.method, step=np.sqrt(self.step))", "response": "Return the derivative of the gradient of this object at point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning index offset corresponding to given spaces.", "response": "def _offset_from_spaces(dom, ran):\n    \"\"\"Return index offset corresponding to given spaces.\"\"\"\n    affected = np.not_equal(dom.shape, ran.shape)\n    diff_l = np.abs(ran.grid.min() - dom.grid.min())\n    offset_float = diff_l / dom.cell_sides\n    offset = np.around(offset_float).astype(int)\n    for i in range(dom.ndim):\n        if affected[i] and not np.isclose(offset[i], offset_float[i]):\n            raise ValueError('in axis {}: range is shifted relative to domain '\n                             'by a non-multiple {} of cell_sides'\n                             ''.format(i, offset_float[i] - offset[i]))\n    offset[~affected] = 0\n    return tuple(offset)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resize_discr(discr, newshp, offset, discr_kwargs):\n    nodes_on_bdry = discr_kwargs.get('nodes_on_bdry', False)\n    if np.shape(nodes_on_bdry) == ():\n        nodes_on_bdry = ([(bool(nodes_on_bdry), bool(nodes_on_bdry))] *\n                         discr.ndim)\n    elif discr.ndim == 1 and len(nodes_on_bdry) == 2:\n        nodes_on_bdry = [nodes_on_bdry]\n    elif len(nodes_on_bdry) != discr.ndim:\n        raise ValueError('`nodes_on_bdry` has length {}, expected {}'\n                         ''.format(len(nodes_on_bdry), discr.ndim))\n\n    dtype = discr_kwargs.pop('dtype', discr.dtype)\n    impl = discr_kwargs.pop('impl', discr.impl)\n    exponent = discr_kwargs.pop('exponent', discr.exponent)\n    interp = discr_kwargs.pop('interp', discr.interp)\n    weighting = discr_kwargs.pop('weighting', discr.weighting)\n\n    affected = np.not_equal(newshp, discr.shape)\n    ndim = discr.ndim\n    for i in range(ndim):\n        if affected[i] and not discr.is_uniform_byaxis[i]:\n            raise ValueError('cannot resize in non-uniformly discretized '\n                             'axis {}'.format(i))\n\n    grid_min, grid_max = discr.grid.min(), discr.grid.max()\n    cell_size = discr.cell_sides\n    new_minpt, new_maxpt = [], []\n\n    for axis, (n_orig, n_new, off, on_bdry) in enumerate(zip(\n            discr.shape, newshp, offset, nodes_on_bdry)):\n\n        if not affected[axis]:\n            new_minpt.append(discr.min_pt[axis])\n            new_maxpt.append(discr.max_pt[axis])\n            continue\n\n        n_diff = n_new - n_orig\n        if off is None:\n            num_r = n_diff // 2\n            num_l = n_diff - num_r\n        else:\n            num_r = n_diff - off\n            num_l = off\n\n        try:\n            on_bdry_l, on_bdry_r = on_bdry\n        except TypeError:\n            on_bdry_l = on_bdry\n            on_bdry_r = on_bdry\n\n        if on_bdry_l:\n            new_minpt.append(grid_min[axis] - num_l * cell_size[axis])\n        else:\n            new_minpt.append(grid_min[axis] - (num_l + 0.5) * cell_size[axis])\n\n        if on_bdry_r:\n            new_maxpt.append(grid_max[axis] + num_r * cell_size[axis])\n        else:\n            new_maxpt.append(grid_max[axis] + (num_r + 0.5) * cell_size[axis])\n\n    fspace = FunctionSpace(IntervalProd(new_minpt, new_maxpt),\n                           out_dtype=dtype)\n    tspace = tensor_space(newshp, dtype=dtype, impl=impl, exponent=exponent,\n                          weighting=weighting)\n\n    # Stack together the (unchanged) nonuniform axes and the (new) uniform\n    # axes in the right order\n    part = uniform_partition([], [], ())\n    for i in range(ndim):\n        if discr.is_uniform_byaxis[i]:\n            part = part.append(\n                uniform_partition(new_minpt[i], new_maxpt[i], newshp[i],\n                                  nodes_on_bdry=nodes_on_bdry[i]))\n        else:\n            part = part.append(discr.partition.byaxis[i])\n\n    return DiscreteLp(fspace, part, tspace, interp=interp)", "response": "Return a new random discretized space based on discr and newshp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying resampling operator. The element ``x`` is resampled using the sampling and interpolation operators of the underlying spaces.", "response": "def _call(self, x, out=None):\n        \"\"\"Apply resampling operator.\n\n        The element ``x`` is resampled using the sampling and interpolation\n        operators of the underlying spaces.\n        \"\"\"\n        if out is None:\n            return x.interpolation\n        else:\n            out.sampling(x.interpolation)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef derivative(self, point):\n        if self.pad_mode == 'constant' and self.pad_const != 0:\n            return ResizingOperator(\n                domain=self.domain, range=self.range, pad_mode='constant',\n                pad_const=0.0)\n        else:  # operator is linear\n            return self", "response": "Derivative of this operator at point."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an adjoint of the current object.", "response": "def adjoint(self):\n        \"\"\"Adjoint of this operator.\"\"\"\n        if not self.is_linear:\n            raise NotImplementedError('this operator is not linear and '\n                                      'thus has no adjoint')\n\n        forward_op = self\n\n        class ResizingOperatorAdjoint(ResizingOperatorBase):\n\n            \"\"\"Adjoint of `ResizingOperator`.\n\n            See `the online documentation\n            <https://odlgroup.github.io/odl/math/resizing_ops.html>`_\n            on resizing operators for mathematical details.\n            \"\"\"\n\n            def _call(self, x, out):\n                \"\"\"Implement ``self(x, out)``.\"\"\"\n                with writable_array(out) as out_arr:\n                    resize_array(x.asarray(), self.range.shape,\n                                 offset=self.offset, pad_mode=self.pad_mode,\n                                 pad_const=0, direction='adjoint',\n                                 out=out_arr)\n\n            @property\n            def adjoint(self):\n                \"\"\"Adjoint of the adjoint, i.e. the original operator.\"\"\"\n                return forward_op\n\n            @property\n            def inverse(self):\n                \"\"\"(Pseudo-)Inverse of this operator.\n\n                Note that in axes where ``self`` extends, the returned operator\n                acts as a proper inverse, while in restriction axes, the\n                operation is not invertible.\n                \"\"\"\n                return ResizingOperatorAdjoint(\n                    domain=self.range, range=self.domain,\n                    pad_mode=self.pad_mode)\n\n        return ResizingOperatorAdjoint(domain=self.range, range=self.domain,\n                                       pad_mode=self.pad_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a pseudo - inverse of this operator.", "response": "def inverse(self):\n        \"\"\"(Pseudo-)Inverse of this operator.\n\n        Note that in axes where ``self`` extends, the returned operator\n        acts as left inverse, while in restriction axes, it is a\n        right inverse.\n        \"\"\"\n        return ResizingOperator(domain=self.range, range=self.domain,\n                                pad_mode=self.pad_mode,\n                                pad_const=self.pad_const)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contains_all(self, other):\n        dtype = getattr(other, 'dtype', None)\n        if dtype is None:\n            dtype = np.result_type(*other)\n        dtype_str = np.dtype('S{}'.format(self.length))\n        dtype_uni = np.dtype('<U{}'.format(self.length))\n        return dtype in (dtype_str, dtype_uni)", "response": "Return True if all strings in other have size length."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an element from inp or from scratch.", "response": "def element(self, inp=None):\n        \"\"\"Return an element from ``inp`` or from scratch.\"\"\"\n        if inp is not None:\n            s = str(inp)[:self.length]\n            s += ' ' * (self.length - len(s))\n            return s\n        else:\n            return ' ' * self.length"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef examples(self):\n        hello_str = 'hello'[:self.length]\n        hello_str += ' ' * (self.length - len(hello_str))\n        world_str = 'world'[:self.length]\n        world_str += ' ' * (self.length - len(world_str))\n        return [('hello', hello_str), ('world', world_str)]", "response": "Return example strings hello world ( size adapted )."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if self contains all other complex numbers.", "response": "def contains_all(self, other):\n        \"\"\"Return ``True`` if ``other`` is a sequence of complex numbers.\"\"\"\n        dtype = getattr(other, 'dtype', None)\n        if dtype is None:\n            dtype = np.result_type(*other)\n        return is_numeric_dtype(dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a complex number from inp or from scratch.", "response": "def element(self, inp=None):\n        \"\"\"Return a complex number from ``inp`` or from scratch.\"\"\"\n        if inp is not None:\n            # Workaround for missing __complex__ of numpy.ndarray\n            # for Numpy version < 1.12\n            # TODO: remove when Numpy >= 1.12 is required\n            if isinstance(inp, np.ndarray):\n                return complex(inp.reshape([1])[0])\n            else:\n                return complex(inp)\n        else:\n            return complex(0.0, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef contains_set(self, other):\n        if other is self:\n            return True\n\n        return (isinstance(other, RealNumbers) or\n                isinstance(other, Integers))", "response": "Return True if other is a subset of the real numbers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contains_all(self, array):\n        dtype = getattr(array, 'dtype', None)\n        if dtype is None:\n            dtype = np.result_type(*array)\n        return is_real_dtype(dtype)", "response": "Test if array is an array of real numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef contains_all(self, other):\n        dtype = getattr(other, 'dtype', None)\n        if dtype is None:\n            dtype = np.result_type(*other)\n        return is_int_dtype(dtype)", "response": "Return True if other is a sequence of integers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef element(self, inp=None):\n        if inp is None:\n            tpl = tuple(set_.element() for set_ in self.sets)\n        else:\n            tpl = tuple(set_.element(inpt)\n                        for inpt, set_ in zip(inp, self.sets))\n\n            if len(tpl) != len(self):\n                raise ValueError('input provides only {} values, needed '\n                                 'are {}'.format(len(tpl), len(self)))\n\n        return tpl", "response": "Create a CartesianProduct element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef element(self, inp=None):\n        for set in self.sets:\n            try:\n                return set.element(inp)\n            except NotImplementedError:\n                pass\n        raise NotImplementedError('`element` not implemented for any of the '\n                                  'subsets')", "response": "Create a new element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef element(self, inp=None):\n        if inp is None:\n            return self.elements[0]\n        elif inp in self.elements:\n            return inp\n        else:\n            raise ValueError('cannot convert inp {} to element in {}'\n                             ''.format(inp, self))", "response": "Create a new element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimplement ``self(x, out[, **kwargs])``. Parameters ---------- x : `domain` element Discretized function to be transformed out : `range` element Element to which the output is written Notes ----- See the ``pyfftw_call`` function for ``**kwargs`` options. The parameters ``axes`` and ``halfcomplex`` cannot be overridden. See Also -------- odl.trafos.backends.pyfftw_bindings.pyfftw_call : Call pyfftw backend directly", "response": "def _call(self, x, out, **kwargs):\n        \"\"\"Implement ``self(x, out[, **kwargs])``.\n\n        Parameters\n        ----------\n        x : `domain` element\n            Discretized function to be transformed\n        out : `range` element\n            Element to which the output is written\n\n        Notes\n        -----\n        See the ``pyfftw_call`` function for ``**kwargs`` options.\n        The parameters ``axes`` and ``halfcomplex`` cannot be\n        overridden.\n\n        See Also\n        --------\n        odl.trafos.backends.pyfftw_bindings.pyfftw_call :\n            Call pyfftw backend directly\n        \"\"\"\n        # TODO: Implement zero padding\n        if self.impl == 'numpy':\n            out[:] = self._call_numpy(x.asarray())\n        else:\n            out[:] = self._call_pyfftw(x.asarray(), out.asarray(), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimplementing self using pyfftw.", "response": "def _call_pyfftw(self, x, out, **kwargs):\n        \"\"\"Implement ``self(x[, out, **kwargs])`` using pyfftw.\n\n        Parameters\n        ----------\n        x : `numpy.ndarray`\n            Input array to be transformed\n        out : `numpy.ndarray`\n            Output array storing the result\n        flags : sequence of strings, optional\n            Flags for the transform. ``'FFTW_UNALIGNED'`` is not\n            supported, and ``'FFTW_DESTROY_INPUT'`` is enabled by\n            default. See the `pyfftw API documentation`_\n            for futher information.\n            Default: ``('FFTW_MEASURE',)``\n        threads : positive int, optional\n            Number of threads to use. Default: 1\n        planning_timelimit : float or ``None``, optional\n            Rough upper limit in seconds for the planning step of the\n            transform. ``None`` means no limit. See the\n            `pyfftw API documentation`_ for futher information.\n\n        Returns\n        -------\n        out : `numpy.ndarray`\n            Result of the transform. If ``out`` was given, the returned\n            object is a reference to it.\n\n        References\n        ----------\n        .. _pyfftw API documentation:\n           https://pyfftw.readthedocs.io\n        \"\"\"\n        assert isinstance(x, np.ndarray)\n        assert isinstance(out, np.ndarray)\n\n        kwargs.pop('normalise_idft', None)  # Using `False` here\n        kwargs.pop('axes', None)\n        kwargs.pop('halfcomplex', None)\n        flags = list(_pyfftw_to_local(flag) for flag in\n                     kwargs.pop('flags', ('FFTW_MEASURE',)))\n        try:\n            flags.remove('unaligned')\n        except ValueError:\n            pass\n        try:\n            flags.remove('destroy_input')\n        except ValueError:\n            pass\n        effort = flags[0] if flags else 'measure'\n\n        direction = 'forward' if self.sign == '-' else 'backward'\n        self._fftw_plan = pyfftw_call(\n            x, out, direction=direction, axes=self.axes,\n            halfcomplex=self.halfcomplex, planning_effort=effort,\n            fftw_plan=self._fftw_plan, normalise_idft=False)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_fftw_plan(self, planning_effort='measure', **kwargs):\n        if self.impl != 'pyfftw':\n            raise ValueError('cannot create fftw plan without fftw backend')\n\n        x = self.domain.element()\n        y = self.range.element()\n        kwargs.pop('planning_timelimit', None)\n\n        direction = 'forward' if self.sign == '-' else 'backward'\n        self._fftw_plan = pyfftw_call(\n            x.asarray(), y.asarray(), direction=direction,\n            halfcomplex=self.halfcomplex, axes=self.axes,\n            planning_effort=planning_effort, **kwargs)", "response": "Initialize the FFTW plan for this transform for later use."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _call_numpy(self, x):\n        assert isinstance(x, np.ndarray)\n\n        if self.halfcomplex:\n            return np.fft.rfftn(x, axes=self.axes)\n        else:\n            if self.sign == '-':\n                return np.fft.fftn(x, axes=self.axes)\n            else:\n                # Need to undo Numpy IFFT scaling\n                return (np.prod(np.take(self.domain.shape, self.axes)) *\n                        np.fft.ifftn(x, axes=self.axes))", "response": "Return the numpy version of the IFFT using numpy."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call_numpy(self, x):\n        if self.halfcomplex:\n            return np.fft.irfftn(x, axes=self.axes)\n        else:\n            if self.sign == '+':\n                return np.fft.ifftn(x, axes=self.axes)\n            else:\n                return (np.fft.fftn(x, axes=self.axes) /\n                        np.prod(np.take(self.domain.shape, self.axes)))", "response": "Return the result of numpy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing self using pyfftw.", "response": "def _call_pyfftw(self, x, out, **kwargs):\n        \"\"\"Implement ``self(x[, out, **kwargs])`` using pyfftw.\n\n        Parameters\n        ----------\n        x : `domain` element\n            Input element to be transformed.\n        out : `range` element\n            Output element storing the result.\n        flags : sequence of strings, optional\n            Flags for the transform. ``'FFTW_UNALIGNED'`` is not\n            supported, and ``'FFTW_DESTROY_INPUT'`` is enabled by\n            default. See the `pyfftw API documentation`_\n            for futher information.\n            Default: ``('FFTW_MEASURE',)``\n        threads : positive int, optional\n            Number of threads to use. Default: 1\n        planning_timelimit : float, optional\n            Rough upper limit in seconds for the planning step of the\n            transform. The default is no limit. See the\n            `pyfftw API documentation`_ for futher information.\n\n        Returns\n        -------\n        out : `range` element\n            Result of the transform. If ``out`` was given, the returned\n            object is a reference to it.\n\n        References\n        ----------\n        .. _pyfftw API documentation:\n           https://pyfftw.readthedocs.io\n        \"\"\"\n        kwargs.pop('normalise_idft', None)  # Using `True` here\n        kwargs.pop('axes', None)\n        kwargs.pop('halfcomplex', None)\n        flags = list(_pyfftw_to_local(flag) for flag in\n                     kwargs.pop('flags', ('FFTW_MEASURE',)))\n        try:\n            flags.remove('unaligned')\n        except ValueError:\n            pass\n        try:\n            flags.remove('destroy_input')\n        except ValueError:\n            pass\n        effort = flags[0] if flags else 'measure'\n\n        direction = 'forward' if self.sign == '-' else 'backward'\n        self._fftw_plan = pyfftw_call(\n            x, out, direction=direction, axes=self.axes,\n            halfcomplex=self.halfcomplex, planning_effort=effort,\n            fftw_plan=self._fftw_plan, normalise_idft=True)\n\n        # Need to normalize for 'forward', no way to force pyfftw\n        if self.sign == '-':\n            out /= np.prod(np.take(self.domain.shape, self.axes))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallocates and store reusable temporaries.", "response": "def create_temporaries(self, r=True, f=True):\n        \"\"\"Allocate and store reusable temporaries.\n\n        Existing temporaries are overridden.\n\n        Parameters\n        ----------\n        r : bool, optional\n            Create temporary for the real space\n        f : bool, optional\n            Create temporary for the frequency space\n\n        Notes\n        -----\n        To save memory, clear the temporaries when the transform is\n        no longer used.\n\n        See Also\n        --------\n        clear_temporaries\n        clear_fftw_plan : can also hold references to the temporaries\n        \"\"\"\n        inverse = isinstance(self, FourierTransformInverse)\n\n        if inverse:\n            rspace = self.range\n            fspace = self.domain\n        else:\n            rspace = self.domain\n            fspace = self.range\n\n        if r:\n            self._tmp_r = rspace.element().asarray()\n        if f:\n            self._tmp_f = fspace.element().asarray()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_fftw_plan(self, planning_effort='measure', **kwargs):\n        if self.impl != 'pyfftw':\n            raise ValueError('cannot create fftw plan without fftw backend')\n\n        # Using available temporaries if possible\n        inverse = isinstance(self, FourierTransformInverse)\n\n        if inverse:\n            rspace = self.range\n            fspace = self.domain\n        else:\n            rspace = self.domain\n            fspace = self.range\n\n        if rspace.field == ComplexNumbers():\n            # C2C: Use either one of 'r' or 'f' temporary if initialized\n            if self._tmp_r is not None:\n                arr_in = arr_out = self._tmp_r\n            elif self._tmp_f is not None:\n                arr_in = arr_out = self._tmp_f\n            else:\n                arr_in = arr_out = rspace.element().asarray()\n\n        elif self.halfcomplex:\n            # R2HC / HC2R: Use 'r' and 'f' temporary distinctly if initialized\n            if self._tmp_r is not None:\n                arr_r = self._tmp_r\n            else:\n                arr_r = rspace.element().asarray()\n            if self._tmp_f is not None:\n                arr_f = self._tmp_f\n            else:\n                arr_f = fspace.element().asarray()\n\n            if inverse:\n                arr_in, arr_out = arr_f, arr_r\n            else:\n                arr_in, arr_out = arr_r, arr_f\n\n        else:\n            # R2C / C2R: Use 'f' temporary for both sides if initialized\n            if self._tmp_f is not None:\n                arr_in = arr_out = self._tmp_f\n            else:\n                arr_in = arr_out = fspace.element().asarray()\n\n        kwargs.pop('planning_timelimit', None)\n\n        direction = 'forward' if self.sign == '-' else 'backward'\n        self._fftw_plan = pyfftw_call(\n            arr_in, arr_out, direction=direction,\n            halfcomplex=self.halfcomplex, axes=self.axes,\n            planning_effort=planning_effort, **kwargs)", "response": "Initialize the FFTW plan for this transform for later use."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the pre - processed version of x.", "response": "def _preprocess(self, x, out=None):\n        \"\"\"Return the pre-processed version of ``x``.\n\n        C2C: use ``tmp_r`` or ``tmp_f`` (C2C operation)\n        R2C: use ``tmp_f`` (R2C operation)\n        HALFC: use ``tmp_r`` (R2R operation)\n\n        The result is stored in ``out`` if given, otherwise in\n        a temporary or a new array.\n        \"\"\"\n        if out is None:\n            if self.domain.field == ComplexNumbers():\n                out = self._tmp_r if self._tmp_r is not None else self._tmp_f\n            elif self.domain.field == RealNumbers() and not self.halfcomplex:\n                out = self._tmp_f\n            else:\n                out = self._tmp_r\n        return dft_preprocess_data(\n            x, shift=self.shifts, axes=self.axes, sign=self.sign,\n            out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the post - processed version of x.", "response": "def _postprocess(self, x, out=None):\n        \"\"\"Return the post-processed version of ``x``.\n\n        C2C: use ``tmp_f`` (C2C operation)\n        R2C: use ``tmp_f`` (C2C operation)\n        HALFC: use ``tmp_f`` (C2C operation)\n\n        The result is stored in ``out`` if given, otherwise in\n        a temporary or a new array.\n        \"\"\"\n        if out is None:\n            if self.domain.field == ComplexNumbers():\n                out = self._tmp_r if self._tmp_r is not None else self._tmp_f\n            else:\n                out = self._tmp_f\n        return dft_postprocess_data(\n            out, real_grid=self.domain.grid, recip_grid=self.range.grid,\n            shift=self.shifts, axes=self.axes, sign=self.sign,\n            interp=self.domain.interp, op='multiply', out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the function x for numpy back - end.", "response": "def _call_numpy(self, x):\n        \"\"\"Return ``self(x)`` for numpy back-end.\n\n        Parameters\n        ----------\n        x : `numpy.ndarray`\n            Array representing the function to be transformed\n\n        Returns\n        -------\n        out : `numpy.ndarray`\n            Result of the transform\n        \"\"\"\n        # Pre-processing before calculating the DFT\n        # Note: since the FFT call is out-of-place, it does not matter if\n        # preprocess produces real or complex output in the R2C variant.\n        # There is no significant time difference between (full) R2C and\n        # C2C DFT in Numpy.\n        preproc = self._preprocess(x)\n\n        # The actual call to the FFT library, out-of-place unfortunately\n        if self.halfcomplex:\n            out = np.fft.rfftn(preproc, axes=self.axes)\n        else:\n            if self.sign == '-':\n                out = np.fft.fftn(preproc, axes=self.axes)\n            else:\n                out = np.fft.ifftn(preproc, axes=self.axes)\n                # Numpy's FFT normalizes by 1 / prod(shape[axes]), we\n                # need to undo that\n                out *= np.prod(np.take(self.domain.shape, self.axes))\n\n        # Post-processing accounting for shift, scaling and interpolation\n        self._postprocess(out, out=out)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimplement self for pyfftw back - end.", "response": "def _call_pyfftw(self, x, out, **kwargs):\n        \"\"\"Implement ``self(x[, out, **kwargs])`` for pyfftw back-end.\n\n        Parameters\n        ----------\n        x : `numpy.ndarray`\n            Array representing the function to be transformed\n        out : `numpy.ndarray`\n            Array to which the output is written\n        planning_effort : {'estimate', 'measure', 'patient', 'exhaustive'}\n            Flag for the amount of effort put into finding an optimal\n            FFTW plan. See the `FFTW doc on planner flags\n            <http://www.fftw.org/fftw3_doc/Planner-Flags.html>`_.\n        planning_timelimit : float or ``None``, optional\n            Limit planning time to roughly this many seconds.\n            Default: ``None`` (no limit)\n        threads : int, optional\n            Number of threads to use. Default: 1\n\n        Returns\n        -------\n        out : `numpy.ndarray`\n            Result of the transform. The returned object is a reference\n            to the input parameter ``out``.\n        \"\"\"\n        # We pop some kwargs options here so that we always use the ones\n        # given during init or implicitly assumed.\n        kwargs.pop('axes', None)\n        kwargs.pop('halfcomplex', None)\n        kwargs.pop('normalise_idft', None)  # We use `False`\n\n        # Pre-processing before calculating the sums, in-place for C2C and R2C\n        if self.halfcomplex:\n            preproc = self._preprocess(x)\n            assert is_real_dtype(preproc.dtype)\n        else:\n            # out is preproc in this case\n            preproc = self._preprocess(x, out=out)\n            assert is_complex_floating_dtype(preproc.dtype)\n\n        # The actual call to the FFT library. We store the plan for re-use.\n        # The FFT is calculated in-place, except if the range is real and\n        # we don't use halfcomplex.\n        direction = 'forward' if self.sign == '-' else 'backward'\n        self._fftw_plan = pyfftw_call(\n            preproc, out, direction=direction, halfcomplex=self.halfcomplex,\n            axes=self.axes, normalise_idft=False, **kwargs)\n\n        assert is_complex_floating_dtype(out.dtype)\n\n        # Post-processing accounting for shift, scaling and interpolation\n        out = self._postprocess(out, out=out)\n        assert is_complex_floating_dtype(out.dtype)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the post - processed version of x.", "response": "def _postprocess(self, x, out=None):\n        \"\"\"Return the post-processed version of ``x``.\n\n        C2C: use ``tmp_r`` or ``tmp_f`` (C2C operation)\n        R2C: use ``tmp_f`` (C2C operation)\n        HALFC: use ``tmp_r`` (R2R operation)\n\n        The result is stored in ``out`` if given, otherwise in\n        a temporary or a new array.\n        \"\"\"\n        if out is None:\n            if self.range.field == ComplexNumbers():\n                out = self._tmp_r if self._tmp_r is not None else self._tmp_f\n            elif self.range.field == RealNumbers() and not self.halfcomplex:\n                out = self._tmp_f\n            else:  # halfcomplex\n                out = self._tmp_r\n        return dft_preprocess_data(\n            x, shift=self.shifts, axes=self.axes, sign=self.sign, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the function x for numpy back - end.", "response": "def _call_numpy(self, x):\n        \"\"\"Return ``self(x)`` for numpy back-end.\n\n        Parameters\n        ----------\n        x : `numpy.ndarray`\n            Array representing the function to be transformed\n\n        Returns\n        -------\n        out : `numpy.ndarray`\n            Result of the transform\n        \"\"\"\n        # Pre-processing before calculating the DFT\n        preproc = self._preprocess(x)\n\n        # The actual call to the FFT library\n        # Normalization by 1 / prod(shape[axes]) is done by Numpy's FFT if\n        # one of the \"i\" functions is used. For sign='-' we need to do it\n        # ourselves.\n        if self.halfcomplex:\n            s = np.asarray(self.range.shape)[list(self.axes)]\n            out = np.fft.irfftn(preproc, axes=self.axes, s=s)\n        else:\n            if self.sign == '-':\n                out = np.fft.fftn(preproc, axes=self.axes)\n                out /= np.prod(np.take(self.domain.shape, self.axes))\n            else:\n                out = np.fft.ifftn(preproc, axes=self.axes)\n\n        # Post-processing in IFT = pre-processing in FT (in-place)\n        self._postprocess(out, out=out)\n        if self.halfcomplex:\n            assert is_real_dtype(out.dtype)\n\n        if self.range.field == RealNumbers():\n            return out.real\n        else:\n            return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing self for pyfftw back - end.", "response": "def _call_pyfftw(self, x, out, **kwargs):\n        \"\"\"Implement ``self(x[, out, **kwargs])`` for pyfftw back-end.\n\n        Parameters\n        ----------\n        x : `numpy.ndarray`\n            Array representing the function to be transformed\n        out : `numpy.ndarray`\n            Array to which the output is written\n        planning_effort : {'estimate', 'measure', 'patient', 'exhaustive'}\n            Flag for the amount of effort put into finding an optimal\n            FFTW plan. See the `FFTW doc on planner flags\n            <http://www.fftw.org/fftw3_doc/Planner-Flags.html>`_.\n        planning_timelimit : float or ``None``, optional\n            Limit planning time to roughly this many seconds.\n            Default: ``None`` (no limit)\n        threads : int, optional\n            Number of threads to use. Default: 1\n\n        Returns\n        -------\n        out : `numpy.ndarray`\n            Result of the transform. If ``out`` was given, the returned\n            object is a reference to it.\n        \"\"\"\n\n        # We pop some kwargs options here so that we always use the ones\n        # given during init or implicitly assumed.\n        kwargs.pop('axes', None)\n        kwargs.pop('halfcomplex', None)\n        kwargs.pop('normalise_idft', None)  # We use `True`\n\n        # Pre-processing in IFT = post-processing in FT, but with division\n        # instead of multiplication and switched grids. In-place for C2C only.\n        if self.range.field == ComplexNumbers():\n            # preproc is out in this case\n            preproc = self._preprocess(x, out=out)\n        else:\n            preproc = self._preprocess(x)\n\n        # The actual call to the FFT library. We store the plan for re-use.\n        direction = 'forward' if self.sign == '-' else 'backward'\n        if self.range.field == RealNumbers() and not self.halfcomplex:\n            # Need to use a complex array as out if we do C2R since the\n            # FFT has to be C2C\n            self._fftw_plan = pyfftw_call(\n                preproc, preproc, direction=direction,\n                halfcomplex=self.halfcomplex, axes=self.axes,\n                normalise_idft=True, **kwargs)\n            fft_arr = preproc\n        else:\n            # Only here we can use out directly\n            self._fftw_plan = pyfftw_call(\n                preproc, out, direction=direction,\n                halfcomplex=self.halfcomplex, axes=self.axes,\n                normalise_idft=True, **kwargs)\n            fft_arr = out\n\n        # Normalization is only done for 'backward', we need it for 'forward',\n        # too.\n        if self.sign == '-':\n            fft_arr /= np.prod(np.take(self.domain.shape, self.axes))\n\n        # Post-processing in IFT = pre-processing in FT. In-place for\n        # C2C and HC2R. For C2R, this is out-of-place and discards the\n        # imaginary part.\n        self._postprocess(fft_arr, out=out)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninverses of the inverse the forward FT.", "response": "def inverse(self):\n        \"\"\"Inverse of the inverse, the forward FT.\"\"\"\n        sign = '+' if self.sign == '-' else '-'\n        return FourierTransform(\n            domain=self.range, range=self.domain, impl=self.impl,\n            axes=self.axes, halfcomplex=self.halfcomplex, shift=self.shifts,\n            sign=sign, tmp_r=self._tmp_r, tmp_f=self._tmp_f)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef moveaxis(a, source, destination):\n    import numpy\n    if hasattr(numpy, 'moveaxis'):\n        return numpy.moveaxis(a, source, destination)\n\n    try:\n        source = list(source)\n    except TypeError:\n        source = [source]\n    try:\n        destination = list(destination)\n    except TypeError:\n        destination = [destination]\n\n    source = [ax + a.ndim if ax < 0 else ax for ax in source]\n    destination = [ax + a.ndim if ax < 0 else ax for ax in destination]\n\n    order = [n for n in range(a.ndim) if n not in source]\n\n    for dest, src in sorted(zip(destination, source)):\n        order.insert(dest, src)\n\n    return a.transpose(order)", "response": "Move axes of an array to new positions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreverse the order of elements in an array along the given axis.", "response": "def flip(a, axis):\n    \"\"\"Reverse the order of elements in an array along the given axis.\n\n    This function is a backport of `numpy.flip` introduced in NumPy 1.12.\n\n    See Also\n    --------\n    numpy.flip\n    \"\"\"\n    if not hasattr(a, 'ndim'):\n        a = np.asarray(a)\n    indexer = [slice(None)] * a.ndim\n    try:\n        indexer[axis] = slice(None, None, -1)\n    except IndexError:\n        raise ValueError('axis={} is invalid for the {}-dimensional input '\n                         'array'.format(axis, a.ndim))\n    return a[tuple(indexer)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_projections(folder, indices):\n    datasets = []\n\n    # Get the relevant file names\n    file_names = sorted([f for f in os.listdir(folder) if f.endswith(\".dcm\")])\n\n    if len(file_names) == 0:\n        raise ValueError('No DICOM files found in {}'.format(folder))\n\n    file_names = file_names[indices]\n\n    data_array = None\n\n    for i, file_name in enumerate(tqdm.tqdm(file_names,\n                                            'Loading projection data')):\n        # read the file\n        dataset = dicom.read_file(folder + '/' + file_name)\n\n        # Get some required data\n        rows = dataset.NumberofDetectorRows\n        cols = dataset.NumberofDetectorColumns\n        hu_factor = dataset.HUCalibrationFactor\n        rescale_intercept = dataset.RescaleIntercept\n        rescale_slope = dataset.RescaleSlope\n\n        # Load the array as bytes\n        proj_array = np.array(np.frombuffer(dataset.PixelData, 'H'),\n                              dtype='float32')\n        proj_array = proj_array.reshape([rows, cols], order='F').T\n\n        # Rescale array\n        proj_array *= rescale_slope\n        proj_array += rescale_intercept\n        proj_array /= hu_factor\n\n        # Store results\n        if data_array is None:\n            # We need to load the first dataset before we know the shape\n            data_array = np.empty((len(file_names), cols, rows),\n                                  dtype='float32')\n\n        data_array[i] = proj_array[:, ::-1]\n        datasets.append(dataset)\n\n    return datasets, data_array", "response": "Read mayo projections from a folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload geometry and data stored in Mayo format from folder.", "response": "def load_projections(folder, indices=None):\n    \"\"\"Load geometry and data stored in Mayo format from folder.\n\n    Parameters\n    ----------\n    folder : str\n        Path to the folder where the Mayo DICOM files are stored.\n    indices : optional\n        Indices of the projections to load.\n        Accepts advanced indexing such as slice or list of indices.\n\n    Returns\n    -------\n    geometry : ConeFlatGeometry\n        Geometry corresponding to the Mayo projector.\n    proj_data : `numpy.ndarray`\n        Projection data, given as the line integral of the linear attenuation\n        coefficient (g/cm^3). Its unit is thus g/cm^2.\n    \"\"\"\n    datasets, data_array = _read_projections(folder, indices)\n\n    # Get the angles\n    angles = [d.DetectorFocalCenterAngularPosition for d in datasets]\n    angles = -np.unwrap(angles) - np.pi  # different defintion of angles\n\n    # Set minimum and maximum corners\n    shape = np.array([datasets[0].NumberofDetectorColumns,\n                      datasets[0].NumberofDetectorRows])\n    pixel_size = np.array([datasets[0].DetectorElementTransverseSpacing,\n                           datasets[0].DetectorElementAxialSpacing])\n\n    # Correct from center of pixel to corner of pixel\n    minp = -(np.array(datasets[0].DetectorCentralElement) - 0.5) * pixel_size\n    maxp = minp + shape * pixel_size\n\n    # Select geometry parameters\n    src_radius = datasets[0].DetectorFocalCenterRadialDistance\n    det_radius = (datasets[0].ConstantRadialDistance -\n                  datasets[0].DetectorFocalCenterRadialDistance)\n\n    # For unknown reasons, mayo does not include the tag\n    # \"TableFeedPerRotation\", which is what we want.\n    # Instead we manually compute the pitch\n    pitch = ((datasets[-1].DetectorFocalCenterAxialPosition -\n              datasets[0].DetectorFocalCenterAxialPosition) /\n             ((np.max(angles) - np.min(angles)) / (2 * np.pi)))\n\n    # Get flying focal spot data\n    offset_axial = np.array([d.SourceAxialPositionShift for d in datasets])\n    offset_angular = np.array([d.SourceAngularPositionShift for d in datasets])\n    offset_radial = np.array([d.SourceRadialDistanceShift for d in datasets])\n\n    # TODO(adler-j): Implement proper handling of flying focal spot.\n    # Currently we do not fully account for it, merely making some \"first\n    # order corrections\" to the detector position and radial offset.\n\n    # Update angles with flying focal spot (in plane direction).\n    # This increases the resolution of the reconstructions.\n    angles = angles - offset_angular\n\n    # We correct for the mean offset due to the rotated angles, we need to\n    # shift the detector.\n    offset_detector_by_angles = det_radius * np.mean(offset_angular)\n    minp[0] -= offset_detector_by_angles\n    maxp[0] -= offset_detector_by_angles\n\n    # We currently apply only the mean of the offsets\n    src_radius = src_radius + np.mean(offset_radial)\n\n    # Partially compensate for a movement of the source by moving the object\n    # instead. We need to rescale by the magnification to get the correct\n    # change in the detector. This approximation is only exactly valid on the\n    # axis of rotation.\n    mean_offset_along_axis_for_ffz = np.mean(offset_axial) * (\n        src_radius / (src_radius + det_radius))\n\n    # Create partition for detector\n    detector_partition = odl.uniform_partition(minp, maxp, shape)\n\n    # Convert offset to odl defintions\n    offset_along_axis = (mean_offset_along_axis_for_ffz +\n                         datasets[0].DetectorFocalCenterAxialPosition -\n                         angles[0] / (2 * np.pi) * pitch)\n\n    # Assemble geometry\n    angle_partition = odl.nonuniform_partition(angles)\n    geometry = odl.tomo.ConeFlatGeometry(angle_partition,\n                                         detector_partition,\n                                         src_radius=src_radius,\n                                         det_radius=det_radius,\n                                         pitch=pitch,\n                                         offset_along_axis=offset_along_axis)\n\n    # Create a *temporary* ray transform (we need its range)\n    spc = odl.uniform_discr([-1] * 3, [1] * 3, [32] * 3)\n    ray_trafo = odl.tomo.RayTransform(spc, geometry, interp='linear')\n\n    # convert coordinates\n    theta, up, vp = ray_trafo.range.grid.meshgrid\n    d = src_radius + det_radius\n    u = d * np.arctan(up / d)\n    v = d / np.sqrt(d**2 + up**2) * vp\n\n    # Calculate projection data in rectangular coordinates since we have no\n    # backend that supports cylindrical\n    proj_data_cylinder = ray_trafo.range.element(data_array)\n    interpolated_values = proj_data_cylinder.interpolation((theta, u, v))\n    proj_data = ray_trafo.range.element(interpolated_values)\n\n    return geometry, proj_data.asarray()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_reconstruction(folder, slice_start=0, slice_end=-1):\n    file_names = sorted([f for f in os.listdir(folder) if f.endswith(\".IMA\")])\n\n    if len(file_names) == 0:\n        raise ValueError('No DICOM files found in {}'.format(folder))\n\n    volumes = []\n    datasets = []\n\n    file_names = file_names[slice_start:slice_end]\n\n    for file_name in tqdm.tqdm(file_names, 'loading volume data'):\n        # read the file\n        dataset = dicom.read_file(folder + '/' + file_name)\n\n        # Get parameters\n        pixel_size = np.array(dataset.PixelSpacing)\n        pixel_thickness = float(dataset.SliceThickness)\n        rows = dataset.Rows\n        cols = dataset.Columns\n\n        # Get data array and convert to correct coordinates\n        data_array = np.array(np.frombuffer(dataset.PixelData, 'H'),\n                              dtype='float32')\n        data_array = data_array.reshape([cols, rows], order='C')\n        data_array = np.rot90(data_array, -1)\n\n        # Convert from storage type to densities\n        # TODO: Optimize these computations\n        hu_values = (dataset.RescaleSlope * data_array +\n                     dataset.RescaleIntercept)\n        densities = (hu_values + 1000) / 1000\n\n        # Store results\n        volumes.append(densities)\n        datasets.append(dataset)\n\n    voxel_size = np.array(list(pixel_size) + [pixel_thickness])\n    shape = np.array([rows, cols, len(volumes)])\n\n    # Compute geometry parameters\n    mid_pt = (np.array(dataset.ReconstructionTargetCenterPatient) -\n              np.array(dataset.DataCollectionCenterPatient))\n    reconstruction_size = (voxel_size * shape)\n    min_pt = mid_pt - reconstruction_size / 2\n    max_pt = mid_pt + reconstruction_size / 2\n\n    # axis 1 has reversed convention\n    min_pt[1], max_pt[1] = -max_pt[1], -min_pt[1]\n\n    if len(datasets) > 1:\n        slice_distance = np.abs(\n            float(datasets[1].DataCollectionCenterPatient[2]) -\n            float(datasets[0].DataCollectionCenterPatient[2]))\n    else:\n        # If we only have one slice, we must approximate the distance.\n        slice_distance = pixel_thickness\n\n    # The middle of the minimum/maximum slice can be computed from the\n    # DICOM attribute \"DataCollectionCenterPatient\". Since ODL uses corner\n    # points (e.g. edge of volume) we need to add half a voxel thickness to\n    # both sides.\n    min_pt[2] = -np.array(datasets[0].DataCollectionCenterPatient)[2]\n    min_pt[2] -= 0.5 * slice_distance\n    max_pt[2] = -np.array(datasets[-1].DataCollectionCenterPatient)[2]\n    max_pt[2] += 0.5 * slice_distance\n\n    partition = odl.uniform_partition(min_pt, max_pt, shape)\n\n    volume = np.transpose(np.array(volumes), (1, 2, 0))\n\n    return partition, volume", "response": "Loads a volume from folder and returns the corresponding partition."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _bfgs_direction(s, y, x, hessinv_estimate=None):\n    assert len(s) == len(y)\n\n    r = x.copy()\n    alphas = np.zeros(len(s))\n    rhos = np.zeros(len(s))\n\n    for i in reversed(range(len(s))):\n        rhos[i] = 1.0 / y[i].inner(s[i])\n        alphas[i] = rhos[i] * (s[i].inner(r))\n        r.lincomb(1, r, -alphas[i], y[i])\n\n    if hessinv_estimate is not None:\n        r = hessinv_estimate(r)\n\n    for i in range(len(s)):\n        beta = rhos[i] * (y[i].inner(r))\n        r.lincomb(1, r, alphas[i] - beta, s[i])\n\n    return r", "response": "r Compute the Hn^ - 1 direction of the BFGS update."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _broydens_direction(s, y, x, hessinv_estimate=None, impl='first'):\n    assert len(s) == len(y)\n\n    if hessinv_estimate is not None:\n        r = hessinv_estimate(x)\n    else:\n        r = x.copy()\n\n    for i in range(len(s)):\n        if impl == 'first':\n            r.lincomb(1, r, y[i].inner(r), s[i])\n        elif impl == 'second':\n            r.lincomb(1, r, y[i].inner(x), s[i])\n        else:\n            raise RuntimeError('unknown `impl`')\n\n    return r", "response": "r Compute the Hn^ - 1 of the product of two sets of LinearSpaceElements s and y."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef newtons_method(f, x, line_search=1.0, maxiter=1000, tol=1e-16,\n                   cg_iter=None, callback=None):\n    r\"\"\"Newton's method for minimizing a functional.\n\n    Notes\n    -----\n    This is a general and optimized implementation of Newton's method\n    for solving the problem:\n\n    .. math::\n        \\min f(x)\n\n    for a differentiable function\n    :math:`f: \\mathcal{X}\\to \\mathbb{R}` on a Hilbert space\n    :math:`\\mathcal{X}`. It does so by finding a zero of the gradient\n\n    .. math::\n        \\nabla f: \\mathcal{X} \\to \\mathcal{X}.\n\n    of finding a root of a function.\n\n    The algorithm is well-known and there is a vast literature about it.\n    Among others, the method is described in [BV2004], Sections 9.5\n    and 10.2 (`book available online\n    <http://stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf>`_),\n    [GNS2009],  Section 2.7 for solving nonlinear equations and Section\n    11.3 for its use in minimization, and wikipedia on `Newton's_method\n    <https://en.wikipedia.org/wiki/Newton's_method>`_.\n\n    The algorithm works by iteratively solving\n\n    .. math::\n        \\partial f(x_k)p_k = -f(x_k)\n\n    and then updating as\n\n    .. math::\n        x_{k+1} = x_k + \\alpha x_k,\n\n    where :math:`\\alpha` is a suitable step length (see the\n    references). In this implementation the system of equations are\n    solved using the conjugate gradient method.\n\n    Parameters\n    ----------\n    f : `Functional`\n        Goal functional. Needs to have ``f.gradient`` and\n        ``f.gradient.derivative``.\n    x : ``op.domain`` element\n        Starting point of the iteration\n    line_search : float or `LineSearch`, optional\n        Strategy to choose the step length. If a float is given, uses it as a\n        fixed step length.\n    maxiter : int, optional\n        Maximum number of iterations.\n    tol : float, optional\n        Tolerance that should be used for terminating the iteration.\n    cg_iter : int, optional\n        Number of iterations in the the conjugate gradient solver,\n        for computing the search direction.\n    callback : callable, optional\n        Object executing code per iteration, e.g. plotting each iterate\n\n    References\n    ----------\n    [BV2004] Boyd, S, and Vandenberghe, L. *Convex optimization*.\n    Cambridge university press, 2004.\n\n    [GNS2009] Griva, I, Nash, S G, and Sofer, A. *Linear and nonlinear\n    optimization*. Siam, 2009.\n    \"\"\"\n    # TODO: update doc\n    grad = f.gradient\n    if x not in grad.domain:\n        raise TypeError('`x` {!r} is not in the domain of `f` {!r}'\n                        ''.format(x, grad.domain))\n\n    if not callable(line_search):\n        line_search = ConstantLineSearch(line_search)\n\n    if cg_iter is None:\n        # Motivated by that if it is Ax = b, x and b in Rn, it takes at most n\n        # iterations to solve with cg\n        cg_iter = grad.domain.size\n\n    # TODO: optimize by using lincomb and avoiding to create copies\n    for _ in range(maxiter):\n\n        # Initialize the search direction to 0\n        search_direction = x.space.zero()\n\n        # Compute hessian (as operator) and gradient in the current point\n        hessian = grad.derivative(x)\n        deriv_in_point = grad(x)\n\n        # Solving A*x = b for x, in this case f''(x)*p = -f'(x)\n        # TODO: Let the user provide/choose method for how to solve this?\n        try:\n            hessian_inverse = hessian.inverse\n        except NotImplementedError:\n            conjugate_gradient(hessian, search_direction,\n                               -deriv_in_point, cg_iter)\n        else:\n            hessian_inverse(-deriv_in_point, out=search_direction)\n\n        # Computing step length\n        dir_deriv = search_direction.inner(deriv_in_point)\n        if np.abs(dir_deriv) <= tol:\n            return\n\n        step_length = line_search(x, search_direction, dir_deriv)\n\n        # Updating\n        x += step_length * search_direction\n\n        if callback is not None:\n            callback(x)", "response": "r Newton s method for minimizing a functional."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bfgs_method(f, x, line_search=1.0, maxiter=1000, tol=1e-15, num_store=None,\n                hessinv_estimate=None, callback=None):\n    r\"\"\"Quasi-Newton BFGS method to minimize a differentiable function.\n\n    Can use either the regular BFGS method, or the limited memory BFGS method.\n\n    Notes\n    -----\n    This is a general and optimized implementation of a quasi-Newton\n    method with BFGS update for solving a general unconstrained\n    optimization problem\n\n    .. math::\n        \\min f(x)\n\n    for a differentiable function\n    :math:`f: \\mathcal{X}\\to \\mathbb{R}` on a Hilbert space\n    :math:`\\mathcal{X}`. It does so by finding a zero of the gradient\n\n    .. math::\n        \\nabla f: \\mathcal{X} \\to \\mathcal{X}.\n\n    The QN method is an approximate Newton method, where the Hessian\n    is approximated and gradually updated in each step. This\n    implementation uses the rank-one BFGS update schema where the\n    inverse of the Hessian is recalculated in each iteration.\n\n    The algorithm is described in [GNS2009], Section 12.3 and in the\n    `BFGS Wikipedia article\n    <https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93\\\nGoldfarb%E2%80%93Shanno_algorithm>`_\n\n    Parameters\n    ----------\n    f : `Functional`\n        Functional with ``f.gradient``.\n    x : ``f.domain`` element\n        Starting point of the iteration\n    line_search : float or `LineSearch`, optional\n        Strategy to choose the step length. If a float is given, uses it as a\n        fixed step length.\n    maxiter : int, optional\n        Maximum number of iterations.\n    tol : float, optional\n        Tolerance that should be used for terminating the iteration.\n    num_store : int, optional\n        Maximum number of correction factors to store. For ``None``, the method\n        is the regular BFGS method. For an integer, the method becomes the\n        Limited Memory BFGS method.\n    hessinv_estimate : `Operator`, optional\n        Initial estimate of the inverse of the Hessian operator. Needs to be an\n        operator from ``f.domain`` to ``f.domain``.\n        Default: Identity on ``f.domain``\n    callback : callable, optional\n        Object executing code per iteration, e.g. plotting each iterate.\n\n    References\n    ----------\n    [GNS2009] Griva, I, Nash, S G, and Sofer, A. *Linear and nonlinear\n    optimization*. Siam, 2009.\n    \"\"\"\n    grad = f.gradient\n    if x not in grad.domain:\n        raise TypeError('`x` {!r} is not in the domain of `grad` {!r}'\n                        ''.format(x, grad.domain))\n\n    if not callable(line_search):\n        line_search = ConstantLineSearch(line_search)\n\n    ys = []\n    ss = []\n\n    grad_x = grad(x)\n    for i in range(maxiter):\n        # Determine a stepsize using line search\n        search_dir = -_bfgs_direction(ss, ys, grad_x, hessinv_estimate)\n        dir_deriv = search_dir.inner(grad_x)\n        if np.abs(dir_deriv) == 0:\n            return  # we found an optimum\n        step = line_search(x, direction=search_dir, dir_derivative=dir_deriv)\n\n        # Update x\n        x_update = search_dir\n        x_update *= step\n        x += x_update\n\n        grad_x, grad_diff = grad(x), grad_x\n        # grad_diff = grad(x) - grad(x_old)\n        grad_diff.lincomb(-1, grad_diff, 1, grad_x)\n\n        y_inner_s = grad_diff.inner(x_update)\n\n        # Test for convergence\n        if np.abs(y_inner_s) < tol:\n            if grad_x.norm() < tol:\n                return\n            else:\n                # Reset if needed\n                ys = []\n                ss = []\n                continue\n\n        # Update Hessian\n        ys.append(grad_diff)\n        ss.append(x_update)\n        if num_store is not None:\n            # Throw away factors if they are too many.\n            ss = ss[-num_store:]\n            ys = ys[-num_store:]\n\n        if callback is not None:\n            callback(x)", "response": "r Quasi - Newton BFGS method to minimize a differentiable function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _rotation_direction_in_detector(geometry):\n    du, dv = geometry.det_axes_init\n    axis = geometry.axis\n    det_normal = np.cross(dv, du)\n    rot_dir = np.cross(axis, det_normal)\n    c = np.array([np.vdot(rot_dir, du), np.vdot(rot_dir, dv)])\n    cnorm = np.linalg.norm(c)\n\n    # Check for numerical errors\n    assert cnorm != 0\n\n    return c / cnorm", "response": "A vector in the detector plane that points in the rotation direction."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a FBP filter for a given frequency.", "response": "def _fbp_filter(norm_freq, filter_type, frequency_scaling):\n    \"\"\"Create a smoothing filter for FBP.\n\n    Parameters\n    ----------\n    norm_freq : `array-like`\n        Frequencies normalized to lie in the interval [0, 1].\n    filter_type : {'Ram-Lak', 'Shepp-Logan', 'Cosine', 'Hamming', 'Hann',\n                   callable}\n        The type of filter to be used.\n        If a string is given, use one of the standard filters with that name.\n        A callable should take an array of values in [0, 1] and return the\n        filter for these frequencies.\n    frequency_scaling : float\n        Scaling of the frequencies for the filter. All frequencies are scaled\n        by this number, any relative frequency above ``frequency_scaling`` is\n        set to 0.\n\n    Returns\n    -------\n    smoothing_filter : `numpy.ndarray`\n\n    Examples\n    --------\n    Create an FBP filter\n\n    >>> norm_freq = np.linspace(0, 1, 10)\n    >>> filt = _fbp_filter(norm_freq,\n    ...                    filter_type='Hann',\n    ...                    frequency_scaling=0.8)\n    \"\"\"\n    filter_type, filter_type_in = str(filter_type).lower(), filter_type\n    if callable(filter_type):\n        filt = filter_type(norm_freq)\n    elif filter_type == 'ram-lak':\n        filt = np.copy(norm_freq)\n    elif filter_type == 'shepp-logan':\n        filt = norm_freq * np.sinc(norm_freq / (2 * frequency_scaling))\n    elif filter_type == 'cosine':\n        filt = norm_freq * np.cos(norm_freq * np.pi / (2 * frequency_scaling))\n    elif filter_type == 'hamming':\n        filt = norm_freq * (\n            0.54 + 0.46 * np.cos(norm_freq * np.pi / (frequency_scaling)))\n    elif filter_type == 'hann':\n        filt = norm_freq * (\n            np.cos(norm_freq * np.pi / (2 * frequency_scaling)) ** 2)\n    else:\n        raise ValueError('unknown `filter_type` ({})'\n                         ''.format(filter_type_in))\n\n    indicator = (norm_freq <= frequency_scaling)\n    filt *= indicator\n    return filt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tam_danielson_window(ray_trafo, smoothing_width=0.05, n_pi=1):\n    # Extract parameters\n    src_radius = ray_trafo.geometry.src_radius\n    det_radius = ray_trafo.geometry.det_radius\n    pitch = ray_trafo.geometry.pitch\n\n    if pitch == 0:\n        raise ValueError('Tam-Danielson window is only defined with '\n                         '`pitch!=0`')\n\n    smoothing_width = float(smoothing_width)\n    if smoothing_width < 0:\n        raise ValueError('`smoothing_width` should be a positive float')\n\n    if n_pi % 2 != 1:\n        raise ValueError('`n_pi` must be odd, got {}'.format(n_pi))\n\n    # Find projection of axis on detector\n    axis_proj = _axis_in_detector(ray_trafo.geometry)\n    rot_dir = _rotation_direction_in_detector(ray_trafo.geometry)\n\n    # Find distance from projection of rotation axis for each pixel\n    dx = (rot_dir[0] * ray_trafo.range.meshgrid[1]\n          + rot_dir[1] * ray_trafo.range.meshgrid[2])\n\n    dx_axis = dx * src_radius / (src_radius + det_radius)\n\n    def Vn(u):\n        return (pitch / (2 * np.pi)\n                * (1 + (u / src_radius) ** 2)\n                * (n_pi * np.pi / 2.0 - np.arctan(u / src_radius)))\n\n    lower_proj_axis = -Vn(dx_axis)\n    upper_proj_axis = Vn(-dx_axis)\n\n    lower_proj = lower_proj_axis * (src_radius + det_radius) / src_radius\n    upper_proj = upper_proj_axis * (src_radius + det_radius) / src_radius\n\n    # Compute a smoothed width\n    interval = (upper_proj - lower_proj)\n    width = interval * smoothing_width / np.sqrt(2)\n\n    # Create window function\n    def window_fcn(x):\n        # Lazy import to improve `import odl` time\n        import scipy.special\n\n        x_along_axis = axis_proj[0] * x[1] + axis_proj[1] * x[2]\n        if smoothing_width != 0:\n            lower_wndw = 0.5 * (\n                1 + scipy.special.erf((x_along_axis - lower_proj) / width))\n            upper_wndw = 0.5 * (\n                1 + scipy.special.erf((upper_proj - x_along_axis) / width))\n        else:\n            lower_wndw = (x_along_axis >= lower_proj)\n            upper_wndw = (x_along_axis <= upper_proj)\n\n        return lower_wndw * upper_wndw\n\n    return ray_trafo.range.element(window_fcn) / n_pi", "response": "Create a Tam - Danielson window from a RayTransform."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a parker weighting function for a RayTransform.", "response": "def parker_weighting(ray_trafo, q=0.25):\n    \"\"\"Create parker weighting for a `RayTransform`.\n\n    Parker weighting is a weighting function that ensures that oversampled\n    fan/cone beam data are weighted such that each line has unit weight. It is\n    useful in analytic reconstruction methods such as FBP to give a more\n    accurate result and can improve convergence rates for iterative methods.\n\n    See the article `Parker weights revisited`_ for more information.\n\n    Parameters\n    ----------\n    ray_trafo : `RayTransform`\n        The ray transform for which to compute the weights.\n    q : float, optional\n        Parameter controlling the speed of the roll-off at the edges of the\n        weighting. 1.0 gives the classical Parker weighting, while smaller\n        values in general lead to lower noise but stronger discretization\n        artifacts.\n\n    Returns\n    -------\n    parker_weighting : ``ray_trafo.range`` element\n\n    See Also\n    --------\n    fbp_op : Filtered back-projection operator from `RayTransform`\n    tam_danielson_window : Indicator function for helical data\n    odl.tomo.geometry.conebeam.FanBeamGeometry : Use case in 2d\n    odl.tomo.geometry.conebeam.ConeFlatGeometry : Use case in 3d (for pitch 0)\n\n    References\n    ----------\n    .. _Parker weights revisited: https://www.ncbi.nlm.nih.gov/pubmed/11929021\n    \"\"\"\n    # Note: Parameter names taken from WES2002\n\n    # Extract parameters\n    src_radius = ray_trafo.geometry.src_radius\n    det_radius = ray_trafo.geometry.det_radius\n    ndim = ray_trafo.geometry.ndim\n    angles = ray_trafo.range.meshgrid[0]\n    min_rot_angle = ray_trafo.geometry.motion_partition.min_pt\n    alen = ray_trafo.geometry.motion_params.length\n\n    # Parker weightings are not defined for helical geometries\n    if ray_trafo.geometry.ndim != 2:\n        pitch = ray_trafo.geometry.pitch\n        if pitch != 0:\n            raise ValueError('Parker weighting window is only defined with '\n                             '`pitch==0`')\n\n    # Find distance from projection of rotation axis for each pixel\n    if ndim == 2:\n        dx = ray_trafo.range.meshgrid[1]\n    elif ndim == 3:\n        # Find projection of axis on detector\n        rot_dir = _rotation_direction_in_detector(ray_trafo.geometry)\n        # If axis is aligned to a coordinate axis, save some memory and time by\n        # using broadcasting\n        if rot_dir[0] == 0:\n            dx = rot_dir[1] * ray_trafo.range.meshgrid[2]\n        elif rot_dir[1] == 0:\n            dx = rot_dir[0] * ray_trafo.range.meshgrid[1]\n        else:\n            dx = (rot_dir[0] * ray_trafo.range.meshgrid[1]\n                  + rot_dir[1] * ray_trafo.range.meshgrid[2])\n\n    # Compute parameters\n    dx_abs_max = np.max(np.abs(dx))\n    max_fan_angle = 2 * np.arctan2(dx_abs_max, src_radius + det_radius)\n    delta = max_fan_angle / 2\n    epsilon = alen - np.pi - max_fan_angle\n\n    if epsilon < 0:\n        raise Exception('data not sufficiently sampled for parker weighting')\n\n    # Define utility functions\n    def S(betap):\n        return (0.5 * (1.0 + np.sin(np.pi * betap)) * (np.abs(betap) < 0.5)\n                + (betap >= 0.5))\n\n    def b(alpha):\n        return q * (2 * delta - 2 * alpha + epsilon)\n\n    # Create weighting function\n    beta = np.asarray(angles - min_rot_angle,\n                      dtype=ray_trafo.range.dtype)  # rotation angle\n    alpha = np.asarray(np.arctan2(dx, src_radius + det_radius),\n                       dtype=ray_trafo.range.dtype)\n\n    # Compute sum in place to save memory\n    S_sum = S(beta / b(alpha) - 0.5)\n    S_sum += S((beta - 2 * delta + 2 * alpha - epsilon) / b(alpha) + 0.5)\n    S_sum -= S((beta - np.pi + 2 * alpha) / b(-alpha) - 0.5)\n    S_sum -= S((beta - np.pi - 2 * delta - epsilon) / b(-alpha) + 0.5)\n\n    scale = 0.5 * alen / np.pi\n    return ray_trafo.range.element(\n        np.broadcast_to(S_sum * scale, ray_trafo.range.shape))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a filter operator for FBP from a RayTransform.", "response": "def fbp_filter_op(ray_trafo, padding=True, filter_type='Ram-Lak',\n                  frequency_scaling=1.0):\n    \"\"\"Create a filter operator for FBP from a `RayTransform`.\n\n    Parameters\n    ----------\n    ray_trafo : `RayTransform`\n        The ray transform (forward operator) whose approximate inverse should\n        be computed. Its geometry has to be any of the following\n\n        `Parallel2dGeometry` : Exact reconstruction\n\n        `Parallel3dAxisGeometry` : Exact reconstruction\n\n        `FanBeamGeometry` : Approximate reconstruction, correct in limit of\n        fan angle = 0.\n        Only flat detectors are supported (det_curvature_radius is None).\n\n        `ConeFlatGeometry`, pitch = 0 (circular) : Approximate reconstruction,\n        correct in the limit of fan angle = 0 and cone angle = 0.\n\n        `ConeFlatGeometry`, pitch > 0 (helical) : Very approximate unless a\n        `tam_danielson_window` is used. Accurate with the window.\n\n        Other geometries: Not supported\n\n    padding : bool, optional\n        If the data space should be zero padded. Without padding, the data may\n        be corrupted due to the circular convolution used. Using padding makes\n        the algorithm slower.\n    filter_type : optional\n        The type of filter to be used.\n        The predefined options are, in approximate order from most noise\n        senstive to least noise sensitive:\n        ``'Ram-Lak'``, ``'Shepp-Logan'``, ``'Cosine'``, ``'Hamming'`` and\n        ``'Hann'``.\n        A callable can also be provided. It must take an array of values in\n        [0, 1] and return the filter for these frequencies.\n    frequency_scaling : float, optional\n        Relative cutoff frequency for the filter.\n        The normalized frequencies are rescaled so that they fit into the range\n        [0, frequency_scaling]. Any frequency above ``frequency_scaling`` is\n        set to zero.\n\n    Returns\n    -------\n    filter_op : `Operator`\n        Filtering operator for FBP based on ``ray_trafo``.\n\n    See Also\n    --------\n    tam_danielson_window : Windowing for helical data\n    \"\"\"\n    impl = 'pyfftw' if PYFFTW_AVAILABLE else 'numpy'\n    alen = ray_trafo.geometry.motion_params.length\n\n    if ray_trafo.domain.ndim == 2:\n        # Define ramp filter\n        def fourier_filter(x):\n            abs_freq = np.abs(x[1])\n            norm_freq = abs_freq / np.max(abs_freq)\n            filt = _fbp_filter(norm_freq, filter_type, frequency_scaling)\n            scaling = 1 / (2 * alen)\n            return filt * np.max(abs_freq) * scaling\n\n        # Define (padded) fourier transform\n        if padding:\n            # Define padding operator\n            ran_shp = (ray_trafo.range.shape[0],\n                       ray_trafo.range.shape[1] * 2 - 1)\n            resizing = ResizingOperator(ray_trafo.range, ran_shp=ran_shp)\n\n            fourier = FourierTransform(resizing.range, axes=1, impl=impl)\n            fourier = fourier * resizing\n        else:\n            fourier = FourierTransform(ray_trafo.range, axes=1, impl=impl)\n\n    elif ray_trafo.domain.ndim == 3:\n        # Find the direction that the filter should be taken in\n        rot_dir = _rotation_direction_in_detector(ray_trafo.geometry)\n\n        # Find what axes should be used in the fourier transform\n        used_axes = (rot_dir != 0)\n        if used_axes[0] and not used_axes[1]:\n            axes = [1]\n        elif not used_axes[0] and used_axes[1]:\n            axes = [2]\n        else:\n            axes = [1, 2]\n\n        # Add scaling for cone-beam case\n        if hasattr(ray_trafo.geometry, 'src_radius'):\n            scale = (ray_trafo.geometry.src_radius\n                     / (ray_trafo.geometry.src_radius\n                        + ray_trafo.geometry.det_radius))\n\n            if ray_trafo.geometry.pitch != 0:\n                # In helical geometry the whole volume is not in each\n                # projection and we need to use another weighting.\n                # Ideally each point in the volume effects only\n                # the projections in a half rotation, so we assume that that\n                # is the case.\n                scale *= alen / (np.pi)\n        else:\n            scale = 1.0\n\n        # Define ramp filter\n        def fourier_filter(x):\n            # If axis is aligned to a coordinate axis, save some memory and\n            # time by using broadcasting\n            if not used_axes[0]:\n                abs_freq = np.abs(rot_dir[1] * x[2])\n            elif not used_axes[1]:\n                abs_freq = np.abs(rot_dir[0] * x[1])\n            else:\n                abs_freq = np.abs(rot_dir[0] * x[1] + rot_dir[1] * x[2])\n            norm_freq = abs_freq / np.max(abs_freq)\n            filt = _fbp_filter(norm_freq, filter_type, frequency_scaling)\n            scaling = scale * np.max(abs_freq) / (2 * alen)\n            return filt * scaling\n\n        # Define (padded) fourier transform\n        if padding:\n            # Define padding operator\n            if used_axes[0]:\n                padded_shape_u = ray_trafo.range.shape[1] * 2 - 1\n            else:\n                padded_shape_u = ray_trafo.range.shape[1]\n\n            if used_axes[1]:\n                padded_shape_v = ray_trafo.range.shape[2] * 2 - 1\n            else:\n                padded_shape_v = ray_trafo.range.shape[2]\n\n            ran_shp = (ray_trafo.range.shape[0],\n                       padded_shape_u,\n                       padded_shape_v)\n            resizing = ResizingOperator(ray_trafo.range, ran_shp=ran_shp)\n\n            fourier = FourierTransform(resizing.range, axes=axes, impl=impl)\n            fourier = fourier * resizing\n        else:\n            fourier = FourierTransform(ray_trafo.range, axes=axes, impl=impl)\n    else:\n        raise NotImplementedError('FBP only implemented in 2d and 3d')\n\n    # Create ramp in the detector direction\n    ramp_function = fourier.range.element(fourier_filter)\n\n    weight = 1\n    if not ray_trafo.range.is_weighted:\n        # Compensate for potentially unweighted range of the ray transform\n        weight *= ray_trafo.range.cell_volume\n\n    if not ray_trafo.domain.is_weighted:\n        # Compensate for potentially unweighted domain of the ray transform\n        weight /= ray_trafo.domain.cell_volume\n\n    ramp_function *= weight\n\n    # Create ramp filter via the convolution formula with fourier transforms\n    return fourier.inverse * ramp_function * fourier"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a filtered back - projection operator from a RayTransform.", "response": "def fbp_op(ray_trafo, padding=True, filter_type='Ram-Lak',\n           frequency_scaling=1.0):\n    \"\"\"Create filtered back-projection operator from a `RayTransform`.\n\n    The filtered back-projection is an approximate inverse to the ray\n    transform.\n\n    Parameters\n    ----------\n    ray_trafo : `RayTransform`\n        The ray transform (forward operator) whose approximate inverse should\n        be computed. Its geometry has to be any of the following\n\n        `Parallel2dGeometry` : Exact reconstruction\n\n        `Parallel3dAxisGeometry` : Exact reconstruction\n\n        `FanBeamGeometry` : Approximate reconstruction, correct in limit of fan\n        angle = 0.\n        Only flat detectors are supported (det_curvature_radius is None).\n\n        `ConeFlatGeometry`, pitch = 0 (circular) : Approximate reconstruction,\n        correct in the limit of fan angle = 0 and cone angle = 0.\n\n        `ConeFlatGeometry`, pitch > 0 (helical) : Very approximate unless a\n        `tam_danielson_window` is used. Accurate with the window.\n\n        Other geometries: Not supported\n\n    padding : bool, optional\n        If the data space should be zero padded. Without padding, the data may\n        be corrupted due to the circular convolution used. Using padding makes\n        the algorithm slower.\n    filter_type : optional\n        The type of filter to be used.\n        The predefined options are, in approximate order from most noise\n        senstive to least noise sensitive:\n        ``'Ram-Lak'``, ``'Shepp-Logan'``, ``'Cosine'``, ``'Hamming'`` and\n        ``'Hann'``.\n        A callable can also be provided. It must take an array of values in\n        [0, 1] and return the filter for these frequencies.\n    frequency_scaling : float, optional\n        Relative cutoff frequency for the filter.\n        The normalized frequencies are rescaled so that they fit into the range\n        [0, frequency_scaling]. Any frequency above ``frequency_scaling`` is\n        set to zero.\n\n    Returns\n    -------\n    fbp_op : `Operator`\n        Approximate inverse operator of ``ray_trafo``.\n\n    See Also\n    --------\n    tam_danielson_window : Windowing for helical data.\n    parker_weighting : Windowing for overcomplete fan-beam data.\n    \"\"\"\n    return ray_trafo.adjoint * fbp_filter_op(ray_trafo, padding, filter_type,\n                                             frequency_scaling)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef derenzo_sources(space, min_pt=None, max_pt=None):\n    if space.ndim == 2:\n        return ellipsoid_phantom(space, _derenzo_sources_2d(), min_pt, max_pt)\n    if space.ndim == 3:\n        return ellipsoid_phantom(\n            space, cylinders_from_ellipses(_derenzo_sources_2d()),\n            min_pt, max_pt)\n    else:\n        raise ValueError('dimension not 2, no phantom available')", "response": "Create the PET / SPECT Derenzo sources phantom."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef poisson_noise(intensity, seed=None):\n    from odl.space import ProductSpace\n\n    with NumpyRandomSeed(seed):\n        if isinstance(intensity.space, ProductSpace):\n            values = [poisson_noise(subintensity)\n                      for subintensity in intensity]\n        else:\n            values = np.random.poisson(intensity.asarray())\n\n    return intensity.space.element(values)", "response": "r Generate a Poisson distributed noise with given intensity."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds salt and pepper noise to vector.", "response": "def salt_pepper_noise(vector, fraction=0.05, salt_vs_pepper=0.5,\n                      low_val=None, high_val=None, seed=None):\n    \"\"\"Add salt and pepper noise to vector.\n\n    Salt and pepper noise replaces random elements in ``vector`` with\n    ``low_val`` or ``high_val``.\n\n    Parameters\n    ----------\n    vector : element of `TensorSpace` or `ProductSpace`\n        The vector that noise should be added to.\n    fraction : float, optional\n        The propotion of the elements in ``vector`` that should be converted\n        to noise.\n    salt_vs_pepper : float, optional\n        Relative abundance of salt (high) vs pepper (low) noise. A high value\n        means more salt than pepper noise.\n    low_val : float, optional\n        The \"pepper\" color in the noise.\n        Default: minimum value of ``vector``. For product spaces the minimum\n        value per subspace is taken.\n    high_val : float, optional\n        The \"salt\" value in the noise.\n        Default: maximuim value of ``vector``. For product spaces the maximum\n        value per subspace is taken.\n    seed : int, optional\n        Random seed to use for generating the noise.\n        For ``None``, use the current seed.\n\n    Returns\n    -------\n    salt_pepper_noise : ``vector.space`` element\n        ``vector`` with salt and pepper noise.\n\n    See Also\n    --------\n    white_noise\n    poisson_noise\n    uniform_noise\n    \"\"\"\n    from odl.space import ProductSpace\n\n    # Validate input parameters\n    fraction, fraction_in = float(fraction), fraction\n    if not (0 <= fraction <= 1):\n        raise ValueError('`fraction` ({}) should be a float in the interval '\n                         '[0, 1]'.format(fraction_in))\n\n    salt_vs_pepper, salt_vs_pepper_in = float(salt_vs_pepper), salt_vs_pepper\n    if not (0 <= salt_vs_pepper <= 1):\n        raise ValueError('`salt_vs_pepper` ({}) should be a float in the '\n                         'interval [0, 1]'.format(salt_vs_pepper_in))\n\n    with NumpyRandomSeed(seed):\n        if isinstance(vector.space, ProductSpace):\n            values = [salt_pepper_noise(subintensity, fraction, salt_vs_pepper,\n                                        low_val, high_val)\n                      for subintensity in vector]\n        else:\n            # Extract vector of values\n            values = vector.asarray().flatten()\n\n            # Determine fill-in values if not given\n            if low_val is None:\n                low_val = np.min(values)\n            if high_val is None:\n                high_val = np.max(values)\n\n            # Create randomly selected points as a subset of image.\n            a = np.arange(vector.size)\n            np.random.shuffle(a)\n            salt_indices = a[:int(fraction * vector.size * salt_vs_pepper)]\n            pepper_indices = a[int(fraction * vector.size * salt_vs_pepper):\n                               int(fraction * vector.size)]\n\n            values[salt_indices] = high_val\n            values[pepper_indices] = -low_val\n            values = values.reshape(vector.space.shape)\n\n    return vector.space.element(values)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a uniform partition of an interval product into equally sized cells.", "response": "def uniform_partition_fromintv(intv_prod, shape, nodes_on_bdry=False):\n    \"\"\"Return a partition of an interval product into equally sized cells.\n\n    Parameters\n    ----------\n    intv_prod : `IntervalProd`\n        Interval product to be partitioned\n    shape : int or sequence of ints\n        Number of nodes per axis. For 1d intervals, a single integer\n        can be specified.\n    nodes_on_bdry : bool or sequence, optional\n        If a sequence is provided, it determines per axis whether to\n        place the last grid point on the boundary (``True``) or shift it\n        by half a cell size into the interior (``False``). In each axis,\n        an entry may consist in a single bool or a 2-tuple of\n        bool. In the latter case, the first tuple entry decides for\n        the left, the second for the right boundary. The length of the\n        sequence must be ``intv_prod.ndim``.\n\n        A single boolean is interpreted as a global choice for all\n        boundaries.\n\n    See Also\n    --------\n    uniform_partition_fromgrid\n\n    Examples\n    --------\n    By default, no grid points are placed on the boundary:\n\n    >>> interval = odl.IntervalProd(0, 1)\n    >>> part = odl.uniform_partition_fromintv(interval, 4)\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]),)\n    >>> part.grid.coord_vectors\n    (array([ 0.125,  0.375,  0.625,  0.875]),)\n\n    This can be changed with the nodes_on_bdry parameter:\n\n    >>> part = odl.uniform_partition_fromintv(interval, 3,\n    ...                                       nodes_on_bdry=True)\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.75,  1.  ]),)\n    >>> part.grid.coord_vectors\n    (array([ 0. ,  0.5,  1. ]),)\n\n    We can specify this per axis, too. In this case we choose both\n    in the first axis and only the rightmost in the second:\n\n    >>> rect = odl.IntervalProd([0, 0], [1, 1])\n    >>> part = odl.uniform_partition_fromintv(\n    ...     rect, (3, 3), nodes_on_bdry=(True, (False, True)))\n    ...\n    >>> part.cell_boundary_vecs[0]  # first axis, as above\n    array([ 0.  ,  0.25,  0.75,  1.  ])\n    >>> part.grid.coord_vectors[0]\n    array([ 0. ,  0.5,  1. ])\n    >>> part.cell_boundary_vecs[1]  # second, asymmetric axis\n    array([ 0. ,  0.4,  0.8,  1. ])\n    >>> part.grid.coord_vectors[1]\n    array([ 0.2,  0.6,  1. ])\n    \"\"\"\n    grid = uniform_grid_fromintv(intv_prod, shape, nodes_on_bdry=nodes_on_bdry)\n    return RectPartition(intv_prod, grid)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uniform_partition_fromgrid(grid, min_pt=None, max_pt=None):\n    # Make dictionaries from `min_pt` and `max_pt` and fill with `None` where\n    # no value is given (taking negative indices into account)\n    if min_pt is None:\n        min_pt = {i: None for i in range(grid.ndim)}\n    elif not hasattr(min_pt, 'items'):  # array-like\n        min_pt = np.atleast_1d(min_pt)\n        min_pt = {i: float(v) for i, v in enumerate(min_pt)}\n    else:\n        min_pt.update({i: None for i in range(grid.ndim)\n                       if i not in min_pt and i - grid.ndim not in min_pt})\n\n    if max_pt is None:\n        max_pt = {i: None for i in range(grid.ndim)}\n    elif not hasattr(max_pt, 'items'):\n        max_pt = np.atleast_1d(max_pt)\n        max_pt = {i: float(v) for i, v in enumerate(max_pt)}\n    else:\n        max_pt.update({i: None for i in range(grid.ndim)\n                      if i not in max_pt and i - grid.ndim not in max_pt})\n\n    # Set the values in the vectors by computing (None) or directly from the\n    # given vectors (otherwise).\n    min_pt_vec = np.empty(grid.ndim)\n    for ax, xmin in min_pt.items():\n        if xmin is None:\n            cvec = grid.coord_vectors[ax]\n            if len(cvec) == 1:\n                raise ValueError('in axis {}: cannot calculate `min_pt` with '\n                                 'only 1 grid point'.format(ax))\n            min_pt_vec[ax] = cvec[0] - (cvec[1] - cvec[0]) / 2\n        else:\n            min_pt_vec[ax] = xmin\n\n    max_pt_vec = np.empty(grid.ndim)\n    for ax, xmax in max_pt.items():\n        if xmax is None:\n            cvec = grid.coord_vectors[ax]\n            if len(cvec) == 1:\n                raise ValueError('in axis {}: cannot calculate `max_pt` with '\n                                 'only 1 grid point'.format(ax))\n            max_pt_vec[ax] = cvec[-1] + (cvec[-1] - cvec[-2]) / 2\n        else:\n            max_pt_vec[ax] = xmax\n\n    return RectPartition(IntervalProd(min_pt_vec, max_pt_vec), grid)", "response": "Return a uniform version of the set of intervals from a given grid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new set of uniform cells.", "response": "def uniform_partition(min_pt=None, max_pt=None, shape=None, cell_sides=None,\n                      nodes_on_bdry=False):\n    \"\"\"Return a partition with equally sized cells.\n\n    Parameters\n    ----------\n    min_pt, max_pt : float or sequence of float, optional\n        Vectors defining the lower/upper limits of the intervals in an\n        `IntervalProd` (a rectangular box). ``None`` entries mean\n        \"compute the value\".\n    shape : int or sequence of ints, optional\n        Number of nodes per axis. ``None`` entries mean\n        \"compute the value\".\n    cell_sides : float or sequence of floats, optional\n        Side length of the partition cells per axis. ``None`` entries mean\n        \"compute the value\".\n    nodes_on_bdry : bool or sequence, optional\n        If a sequence is provided, it determines per axis whether to\n        place the last grid point on the boundary (``True``) or shift it\n        by half a cell size into the interior (``False``). In each axis,\n        an entry may consist in a single bool or a 2-tuple of\n        bool. In the latter case, the first tuple entry decides for\n        the left, the second for the right boundary. The length of the\n        sequence must be ``array.ndim``.\n\n        A single boolean is interpreted as a global choice for all\n        boundaries.\n\n    Notes\n    -----\n    In each axis, 3 of the 4 possible parameters ``min_pt``, ``max_pt``,\n    ``shape`` and ``cell_sides`` must be given. If all four are\n    provided, they are checked for consistency.\n\n    See Also\n    --------\n    uniform_partition_fromintv : partition an existing set\n    uniform_partition_fromgrid : use an existing grid as basis\n\n    Examples\n    --------\n    Any combination of three of the four parameters can be used for\n    creation of a partition:\n\n    >>> part = odl.uniform_partition(min_pt=0, max_pt=2, shape=4)\n    >>> part.cell_boundary_vecs\n    (array([ 0. ,  0.5,  1. ,  1.5,  2. ]),)\n    >>> part = odl.uniform_partition(min_pt=0, shape=4, cell_sides=0.5)\n    >>> part.cell_boundary_vecs\n    (array([ 0. ,  0.5,  1. ,  1.5,  2. ]),)\n    >>> part = odl.uniform_partition(max_pt=2, shape=4, cell_sides=0.5)\n    >>> part.cell_boundary_vecs\n    (array([ 0. ,  0.5,  1. ,  1.5,  2. ]),)\n    >>> part = odl.uniform_partition(min_pt=0, max_pt=2, cell_sides=0.5)\n    >>> part.cell_boundary_vecs\n    (array([ 0. ,  0.5,  1. ,  1.5,  2. ]),)\n\n    In higher dimensions, the parameters can be given differently in\n    each axis. Where ``None`` is given, the value will be computed:\n\n    >>> part = odl.uniform_partition(min_pt=[0, 0], max_pt=[1, 2],\n    ...                              shape=[4, 2])\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]), array([ 0.,  1.,  2.]))\n    >>> part = odl.uniform_partition(min_pt=[0, 0], max_pt=[1, 2],\n    ...                              shape=[None, 2], cell_sides=[0.25, None])\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]), array([ 0.,  1.,  2.]))\n    >>> part = odl.uniform_partition(min_pt=[0, None], max_pt=[None, 2],\n    ...                              shape=[4, 2], cell_sides=[0.25, 1])\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]), array([ 0.,  1.,  2.]))\n\n    By default, no grid points are placed on the boundary:\n\n    >>> part = odl.uniform_partition(0, 1, 4)\n    >>> part.nodes_on_bdry\n    False\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ]),)\n    >>> part.grid.coord_vectors\n    (array([ 0.125,  0.375,  0.625,  0.875]),)\n\n    This can be changed with the nodes_on_bdry parameter:\n\n    >>> part = odl.uniform_partition(0, 1, 3, nodes_on_bdry=True)\n    >>> part.nodes_on_bdry\n    True\n    >>> part.cell_boundary_vecs\n    (array([ 0.  ,  0.25,  0.75,  1.  ]),)\n    >>> part.grid.coord_vectors\n    (array([ 0. ,  0.5,  1. ]),)\n\n    We can specify this per axis, too. In this case we choose both\n    in the first axis and only the rightmost in the second:\n\n    >>> part = odl.uniform_partition([0, 0], [1, 1], (3, 3),\n    ...                              nodes_on_bdry=(True, (False, True)))\n    ...\n    >>> part.cell_boundary_vecs[0]  # first axis, as above\n    array([ 0.  ,  0.25,  0.75,  1.  ])\n    >>> part.grid.coord_vectors[0]\n    array([ 0. ,  0.5,  1. ])\n    >>> part.cell_boundary_vecs[1]  # second, asymmetric axis\n    array([ 0. ,  0.4,  0.8,  1. ])\n    >>> part.grid.coord_vectors[1]\n    array([ 0.2,  0.6,  1. ])\n    \"\"\"\n    # Normalize partition parameters\n\n    # np.size(None) == 1, so that would screw it for sizes 0 of the rest\n    sizes = [np.size(p) for p in (min_pt, max_pt, shape, cell_sides)\n             if p is not None]\n    ndim = int(np.max(sizes))\n\n    min_pt = normalized_scalar_param_list(min_pt, ndim, param_conv=float,\n                                          keep_none=True)\n    max_pt = normalized_scalar_param_list(max_pt, ndim, param_conv=float,\n                                          keep_none=True)\n    shape = normalized_scalar_param_list(shape, ndim, param_conv=safe_int_conv,\n                                         keep_none=True)\n    cell_sides = normalized_scalar_param_list(cell_sides, ndim,\n                                              param_conv=float, keep_none=True)\n\n    nodes_on_bdry = normalized_nodes_on_bdry(nodes_on_bdry, ndim)\n\n    # Calculate the missing parameters in min_pt, max_pt, shape\n    for i, (xmin, xmax, n, dx, on_bdry) in enumerate(\n            zip(min_pt, max_pt, shape, cell_sides, nodes_on_bdry)):\n        num_params = sum(p is not None for p in (xmin, xmax, n, dx))\n        if num_params < 3:\n            raise ValueError('in axis {}: expected at least 3 of the '\n                             'parameters `min_pt`, `max_pt`, `shape`, '\n                             '`cell_sides`, got {}'\n                             ''.format(i, num_params))\n\n        # Unpack the tuple if possible, else use bool globally for this axis\n        try:\n            bdry_l, bdry_r = on_bdry\n        except TypeError:\n            bdry_l = bdry_r = on_bdry\n\n        # For each node on the boundary, we subtract 1/2 from the number of\n        # full cells between min_pt and max_pt.\n        if xmin is None:\n            min_pt[i] = xmax - (n - sum([bdry_l, bdry_r]) / 2.0) * dx\n        elif xmax is None:\n            max_pt[i] = xmin + (n - sum([bdry_l, bdry_r]) / 2.0) * dx\n        elif n is None:\n            # Here we add to n since (e-b)/s gives the reduced number of cells.\n            n_calc = (xmax - xmin) / dx + sum([bdry_l, bdry_r]) / 2.0\n            n_round = int(round(n_calc))\n            if abs(n_calc - n_round) > 1e-5:\n                raise ValueError('in axis {}: calculated number of nodes '\n                                 '{} = ({} - {}) / {} too far from integer'\n                                 ''.format(i, n_calc, xmax, xmin, dx))\n            shape[i] = n_round\n        elif dx is None:\n            pass\n        else:\n            xmax_calc = xmin + (n - sum([bdry_l, bdry_r]) / 2.0) * dx\n            if not np.isclose(xmax, xmax_calc):\n                raise ValueError('in axis {}: calculated endpoint '\n                                 '{} = {} + {} * {} too far from given '\n                                 'endpoint {}.'\n                                 ''.format(i, xmax_calc, xmin, n, dx, xmax))\n\n    return uniform_partition_fromintv(\n        IntervalProd(min_pt, max_pt), shape, nodes_on_bdry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a non - uniformly sized cell - wise partition of the given set of coordinates.", "response": "def nonuniform_partition(*coord_vecs, **kwargs):\n    \"\"\"Return a partition with un-equally sized cells.\n\n    Parameters\n    ----------\n    coord_vecs1, ... coord_vecsN : `array-like`\n        Arrays of coordinates of the mid-points of the partition cells.\n    min_pt, max_pt : float or sequence of floats, optional\n        Vectors defining the lower/upper limits of the intervals in an\n        `IntervalProd` (a rectangular box). ``None`` entries mean\n        \"compute the value\".\n    nodes_on_bdry : bool or sequence, optional\n        If a sequence is provided, it determines per axis whether to\n        place the last grid point on the boundary (``True``) or shift it\n        by half a cell size into the interior (``False``). In each axis,\n        an entry may consist in a single bool or a 2-tuple of\n        bool. In the latter case, the first tuple entry decides for\n        the left, the second for the right boundary. The length of the\n        sequence must be ``array.ndim``.\n\n        A single boolean is interpreted as a global choice for all\n        boundaries.\n\n        Cannot be given with both min_pt and max_pt since they determine the\n        same thing.\n\n        Default: ``False``\n\n    See Also\n    --------\n    uniform_partition : uniformly spaced points\n    uniform_partition_fromintv : partition an existing set\n    uniform_partition_fromgrid : use an existing grid as basis\n\n    Examples\n    --------\n    With uniformly spaced points the result is the same as a\n    uniform partition:\n\n    >>> odl.nonuniform_partition([0, 1, 2, 3])\n    uniform_partition(-0.5, 3.5, 4)\n    >>> odl.nonuniform_partition([0, 1, 2, 3], [1, 2])\n    uniform_partition([-0.5,  0.5], [ 3.5,  2.5], (4, 2))\n\n    If the points are not uniformly spaced, a nonuniform partition is\n    created. Note that the containing interval is calculated by assuming\n    that the points are in the middle of the sub-intervals:\n\n    >>> odl.nonuniform_partition([0, 1, 3])\n    nonuniform_partition(\n        [ 0.,  1.,  3.]\n    )\n\n    Higher dimensional partitions are created by specifying the gridpoints\n    along each dimension:\n\n    >>> odl.nonuniform_partition([0, 1, 3], [1, 2])\n    nonuniform_partition(\n        [ 0.,  1.,  3.],\n        [ 1.,  2.]\n    )\n\n    Partitions with a single element are by default degenerate\n\n    >>> odl.nonuniform_partition(1)\n    uniform_partition(1.0, 1.0, 1, nodes_on_bdry=True)\n\n    If the endpoints should be on the boundary, the ``nodes_on_bdry`` parameter\n    can be used:\n\n    >>> odl.nonuniform_partition([0, 1, 3], nodes_on_bdry=True)\n    nonuniform_partition(\n        [ 0.,  1.,  3.],\n        nodes_on_bdry=True\n    )\n\n    Users can also manually specify the containing intervals dimensions by\n    using the ``min_pt`` and ``max_pt`` arguments:\n\n    >>> odl.nonuniform_partition([0, 1, 3], min_pt=-2, max_pt=3)\n    nonuniform_partition(\n        [ 0.,  1.,  3.],\n        min_pt=-2.0, max_pt=3.0\n    )\n    \"\"\"\n    # Get parameters from kwargs\n    min_pt = kwargs.pop('min_pt', None)\n    max_pt = kwargs.pop('max_pt', None)\n    nodes_on_bdry = kwargs.pop('nodes_on_bdry', False)\n\n    # np.size(None) == 1\n    sizes = [len(coord_vecs)] + [np.size(p) for p in (min_pt, max_pt)]\n    ndim = int(np.max(sizes))\n\n    min_pt = normalized_scalar_param_list(min_pt, ndim, param_conv=float,\n                                          keep_none=True)\n    max_pt = normalized_scalar_param_list(max_pt, ndim, param_conv=float,\n                                          keep_none=True)\n    nodes_on_bdry = normalized_nodes_on_bdry(nodes_on_bdry, ndim)\n\n    # Calculate the missing parameters in min_pt, max_pt\n    for i, (xmin, xmax, (bdry_l, bdry_r), coords) in enumerate(\n            zip(min_pt, max_pt, nodes_on_bdry, coord_vecs)):\n        # Check input for redundancy\n        if xmin is not None and bdry_l:\n            raise ValueError('in axis {}: got both `min_pt` and '\n                             '`nodes_on_bdry=True`'.format(i))\n        if xmax is not None and bdry_r:\n            raise ValueError('in axis {}: got both `max_pt` and '\n                             '`nodes_on_bdry=True`'.format(i))\n\n        # Handle length 1 inputs\n        coords = np.array(coords, copy=False, ndmin=1)\n\n        # Compute boundary position if not given by user\n        if xmin is None:\n            if bdry_l or len(coords) == 1:\n                min_pt[i] = coords[0]\n            else:\n                min_pt[i] = coords[0] - (coords[1] - coords[0]) / 2.0\n        if xmax is None:\n            if bdry_r or len(coords) == 1:\n                max_pt[i] = coords[-1]\n            else:\n                max_pt[i] = coords[-1] + (coords[-1] - coords[-2]) / 2.0\n\n    interval = IntervalProd(min_pt, max_pt)\n    grid = RectGrid(*coord_vecs)\n    return RectPartition(interval, grid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a tuple of all grid points lying on the boundary.", "response": "def nodes_on_bdry(self):\n        \"\"\"Encoding of grid points lying on the boundary.\n\n        Examples\n        --------\n        Using global option (default ``False``):\n\n        >>> part = odl.nonuniform_partition([0, 2, 3], [1, 3])\n        >>> part.nodes_on_bdry\n        False\n        >>> part = odl.nonuniform_partition([0, 2, 3], [1, 3],\n        ...                                 nodes_on_bdry=True)\n        >>> part.nodes_on_bdry\n        True\n\n        ``False`` in axis 0, ``True`` in axis 1:\n\n        >>> part = odl.nonuniform_partition([0, 2, 3], [1, 3],\n        ...                                 nodes_on_bdry=[False, True])\n        >>> part.nodes_on_bdry\n        (False, True)\n\n        In axis 0, ``False`` left and ``True`` right, in axis 1 ``False``:\n\n        >>> part = odl.nonuniform_partition([0, 2, 3], [1, 3],\n        ...                                 nodes_on_bdry=[[False, True],\n        ...                                                False])\n        >>> part.nodes_on_bdry\n        ((False, True), False)\n        \"\"\"\n        if self.size == 0:\n            return True\n\n        nodes_on_bdry = []\n        for on_bdry in self.nodes_on_bdry_byaxis:\n            left, right = on_bdry\n            if left == right:\n                nodes_on_bdry.append(left)\n            else:\n                nodes_on_bdry.append((left, right))\n        if all(on_bdry == nodes_on_bdry[0] for on_bdry in nodes_on_bdry[1:]):\n            return nodes_on_bdry[0]\n        else:\n            return tuple(nodes_on_bdry)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrues if grid is uniform and cell_sides are all equal.", "response": "def has_isotropic_cells(self):\n        \"\"\"``True`` if `grid` is uniform and `cell_sides` are all equal.\n\n        Always ``True`` for 1D partitions.\n\n        Examples\n        --------\n        >>> part = uniform_partition([0, -1], [1, 1], (5, 10))\n        >>> part.has_isotropic_cells\n        True\n        >>> part = uniform_partition([0, -1], [1, 1], (5, 5))\n        >>> part.has_isotropic_cells\n        False\n        \"\"\"\n        return self.is_uniform and np.allclose(self.cell_sides[:-1],\n                                               self.cell_sides[1:])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple of contained fractions of boundary cells.", "response": "def boundary_cell_fractions(self):\n        \"\"\"Return a tuple of contained fractions of boundary cells.\n\n        Since the outermost grid points can have any distance to the\n        boundary of the partitioned set, the \"natural\" outermost cell\n        around these points can either be cropped or extended. This\n        property is a tuple of (float, float) tuples, one entry per\n        dimension, where the fractions of the left- and rightmost\n        cells inside the set are stored. If a grid point lies exactly\n        on the boundary, the value is 1/2 since the cell is cut in half.\n        Otherwise, any value larger than 1/2 is possible.\n\n        Returns\n        -------\n        on_bdry : tuple of 2-tuples of floats\n            Each 2-tuple contains the fraction of the leftmost\n            (first entry) and rightmost (second entry) cell in the\n            partitioned set in the corresponding dimension.\n\n        See Also\n        --------\n        cell_boundary_vecs\n\n        Examples\n        --------\n        We create a partition of the rectangle [0, 1.5] x [-2, 2] with\n        the grid points [0, 1] x [-1, 0, 2]. The \"natural\" cells at the\n        boundary would be:\n\n            [-0.5, 0.5] and [0.5, 1.5] in the first axis\n\n            [-1.5, -0.5] and [1, 3] in the second axis\n\n        Thus, in the first axis, the fractions contained in [0, 1.5]\n        are 0.5 and 1, and in the second axis, [-2, 2] contains the\n        fractions 1.5 and 0.5.\n\n        >>> rect = odl.IntervalProd([0, -2], [1.5, 2])\n        >>> grid = odl.RectGrid([0, 1], [-1, 0, 2])\n        >>> part = odl.RectPartition(rect, grid)\n        >>> part.boundary_cell_fractions\n        ((0.5, 1.0), (1.5, 0.5))\n        \"\"\"\n        frac_list = []\n        for ax, (cvec, bmin, bmax) in enumerate(zip(\n                self.grid.coord_vectors, self.set.min_pt, self.set.max_pt)):\n            # Degenerate axes have a value of 1.0 (this is used as weight\n            # in integration formulas later)\n            if len(cvec) == 1:\n                frac_list.append((1.0, 1.0))\n            else:\n                left_frac = 0.5 + (cvec[0] - bmin) / (cvec[1] - cvec[0])\n                right_frac = 0.5 + (bmax - cvec[-1]) / (cvec[-1] - cvec[-2])\n                frac_list.append((left_frac, right_frac))\n\n        return tuple(frac_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cell_sizes_vecs(self):\n        csizes = []\n        for ax, cvec in enumerate(self.grid.coord_vectors):\n            if len(cvec) == 1:\n                csizes.append(np.array([0.0]))\n            else:\n                csize = np.empty_like(cvec)\n                csize[1:-1] = (cvec[2:] - cvec[:-2]) / 2.0\n                csize[0] = (cvec[0] + cvec[1]) / 2 - self.min()[ax]\n                csize[-1] = self.max()[ax] - (cvec[-2] + cvec[-1]) / 2\n                csizes.append(csize)\n\n        return tuple(csizes)", "response": "Return the cell sizes as coordinate vectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cell_sides(self):\n        sides = self.grid.stride\n        sides[sides == 0] = self.extent[sides == 0]\n        return sides", "response": "Side lengths of all inner cells of a uniform partition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the two sets and grids are equal.", "response": "def approx_equals(self, other, atol):\n        \"\"\"Return ``True`` in case of approximate equality.\n\n        Returns\n        -------\n        approx_eq : bool\n            ``True`` if ``other`` is a `RectPartition` instance with\n            ``self.set == other.set`` up to ``atol`` and\n            ``self.grid == other.other`` up to ``atol``, ``False`` otherwise.\n        \"\"\"\n        if other is self:\n            return True\n        elif not isinstance(other, RectPartition):\n            return False\n        else:\n            return (self.set.approx_equals(other.set, atol=atol) and\n                    self.grid.approx_equals(other.grid, atol=atol))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert(self, index, *parts):\n        if not all(isinstance(p, RectPartition) for p in parts):\n            raise TypeError('`parts` must all be `RectPartition` instances, '\n                            'got ({})'\n                            ''.format(', '.join(repr(p) for p in parts)))\n\n        newgrid = self.grid.insert(index, *(p.grid for p in parts))\n        newset = self.set.insert(index, *(p.set for p in parts))\n        return RectPartition(newset, newgrid)", "response": "Return a copy with parts inserted before index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the partition with removed degenerate dimensions.", "response": "def squeeze(self, axis=None):\n        \"\"\"Return the partition with removed degenerate (length 1) dimensions.\n\n        Parameters\n        ----------\n        axis : None or index expression, optional\n            Subset of the axes to squeeze. Default: All axes.\n\n        Returns\n        -------\n        squeezed : `RectPartition`\n            Squeezed partition.\n\n        Examples\n        --------\n        >>> p = odl.uniform_partition([0, -1], [1, 2], (3, 1))\n        >>> p.squeeze()\n        uniform_partition(0.0, 1.0, 3)\n\n        The axis argument can be used to only squeeze some axes (if applicable)\n\n        >>> p.squeeze(axis=0)\n        uniform_partition([ 0., -1.], [ 1.,  2.], (3, 1))\n\n        Notes\n        -----\n        This is not equivalent to\n        ``RectPartiton(self.set.squeeze(), self.grid.squeeze())`` since the\n        definition of degenerate is different in sets and grids. This method\n        follow the definition used in grids, that is, an axis is degenerate if\n        it has only one element.\n\n        See Also\n        --------\n        odl.discr.grid.RectGrid.squeeze\n        odl.set.domain.IntervalProd.squeeze\n        \"\"\"\n        if axis is None:\n            rng = range(self.ndim)\n        else:\n            rng = list(np.atleast_1d(np.arange(self.ndim)[axis]))\n\n        new_indcs = [i for i in range(self.ndim)\n                     if i not in rng or self.grid.nondegen_byaxis[i]]\n        newset = self.set[new_indcs]\n        return RectPartition(newset, self.grid.squeeze(axis))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index(self, value, floating=False):\n        value = np.atleast_1d(self.set.element(value))\n        result = []\n        for val, cell_bdry_vec in zip(value, self.cell_boundary_vecs):\n            ind = np.searchsorted(cell_bdry_vec, val)\n            if floating:\n                if cell_bdry_vec[ind] == val:\n                    # Value is on top of edge\n                    result.append(float(ind))\n                else:\n                    # interpolate between\n                    csize = float(cell_bdry_vec[ind] - cell_bdry_vec[ind - 1])\n                    result.append(ind - (cell_bdry_vec[ind] - val) / csize)\n            else:\n                if cell_bdry_vec[ind] == val and ind != len(cell_bdry_vec) - 1:\n                    # Value is on top of edge, but not last edge\n                    result.append(ind)\n                else:\n                    result.append(ind - 1)\n\n        if self.ndim == 1:\n            result = result[0]\n        else:\n            result = tuple(result)\n\n        return result", "response": "Return the index of a value in the domain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef byaxis(self):\n        partition = self\n\n        class RectPartitionByAxis(object):\n\n            \"\"\"Helper class for accessing `RectPartition` by axis.\"\"\"\n\n            def __getitem__(self, indices):\n                \"\"\"Return ``self[indices]``.\"\"\"\n                try:\n                    iter(indices)\n                except TypeError:\n                    # Slice or integer\n                    slc = np.zeros(partition.ndim, dtype=object)\n                    slc[indices] = slice(None)\n                    squeeze_axes = np.where(slc == 0)[0]\n                    newpart = partition[tuple(slc)].squeeze(squeeze_axes)\n                else:\n                    # Sequence, stack together from single-integer indexing\n                    indices = [int(i) for i in indices]\n                    byaxis = partition.byaxis\n                    parts = [byaxis[i] for i in indices]\n                    if not parts:\n                        newpart = uniform_partition([], [], ())\n                    else:\n                        newpart = parts[0].append(*(parts[1:]))\n\n                return newpart\n\n            def __repr__(self):\n                \"\"\"Return ``repr(self)``.\n\n                Examples\n                --------\n                >>> p = odl.uniform_partition(0, 1, 5)\n                >>> p.byaxis\n                uniform_partition(0, 1, 5).byaxis\n                \"\"\"\n                return '{!r}.byaxis'.format(partition)\n\n        return RectPartitionByAxis()", "response": "Return a new object that is indexed along the specified axes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef det_point_position(self, mparam, dparam):\n        # Always call the downstream methods with vectorized arguments\n        # to be able to reliably manipulate the final axes of the result\n        if self.motion_params.ndim == 1:\n            squeeze_mparam = (np.shape(mparam) == ())\n            mparam = np.array(mparam, dtype=float, copy=False, ndmin=1)\n            matrix = self.rotation_matrix(mparam)  # shape (m, ndim, ndim)\n        else:\n            squeeze_mparam = (np.broadcast(*mparam).shape == ())\n            mparam = tuple(np.array(a, dtype=float, copy=False, ndmin=1)\n                           for a in mparam)\n            matrix = self.rotation_matrix(mparam)  # shape (m, ndim, ndim)\n\n        if self.det_params.ndim == 1:\n            squeeze_dparam = (np.shape(dparam) == ())\n            dparam = np.array(dparam, dtype=float, copy=False, ndmin=1)\n        else:\n            squeeze_dparam = (np.broadcast(*dparam).shape == ())\n            dparam = tuple(np.array(p, dtype=float, copy=False, ndmin=1)\n                           for p in dparam)\n\n        surf = self.detector.surface(dparam)  # shape (d, ndim)\n\n        # Perform matrix-vector multiplication along the last axis of both\n        # `matrix` and `surf` while \"zipping\" all axes that do not\n        # participate in the matrix-vector product. In other words, the axes\n        # are labelled\n        # [0, 1, ..., r-1, r, r+1] for `matrix` and\n        # [0, 1, ..., r-1, r+1] for `surf`, and the output axes are set to\n        # [0, 1, ..., r-1, r]. This automatically supports broadcasting\n        # along the axes 0, ..., r-1.\n        matrix_axes = list(range(matrix.ndim))\n        surf_axes = list(range(matrix.ndim - 2)) + [matrix_axes[-1]]\n        out_axes = list(range(matrix.ndim - 1))\n        det_part = np.einsum(matrix, matrix_axes, surf, surf_axes, out_axes)\n\n        refpt = self.det_refpoint(mparam)\n        det_pt_pos = refpt + det_part\n        if squeeze_mparam and squeeze_dparam:\n            det_pt_pos = det_pt_pos.squeeze()\n\n        return det_pt_pos", "response": "Return the detector point at the given motion parameter and detector parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef det_to_src(self, angle, dparam, normalized=True):\n        # Always call the downstream methods with vectorized arguments\n        # to be able to reliably manipulate the final axes of the result\n        if self.motion_params.ndim == 1:\n            squeeze_angle = (np.shape(angle) == ())\n            angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n        else:\n            squeeze_angle = (np.broadcast(*angle).shape == ())\n            angle = tuple(np.array(a, dtype=float, copy=False, ndmin=1)\n                          for a in angle)\n\n        if self.det_params.ndim == 1:\n            squeeze_dparam = (np.shape(dparam) == ())\n            dparam = np.array(dparam, dtype=float, copy=False, ndmin=1)\n        else:\n            squeeze_dparam = (np.broadcast(*dparam).shape == ())\n            dparam = tuple(np.array(p, dtype=float, copy=False, ndmin=1)\n                           for p in dparam)\n\n        det_to_src = (self.src_position(angle) -\n                      self.det_point_position(angle, dparam))\n\n        if normalized:\n            det_to_src /= np.linalg.norm(det_to_src, axis=-1, keepdims=True)\n\n        if squeeze_angle and squeeze_dparam:\n            det_to_src = det_to_src.squeeze()\n\n        return det_to_src", "response": "Vector or direction from a detector location to the source."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rotation_matrix(self, angle):\n        squeeze_out = (np.shape(angle) == ())\n        angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n        if (self.check_bounds and\n                not is_inside_bounds(angle, self.motion_params)):\n            raise ValueError('`angle` {} not in the valid range {}'\n                             ''.format(angle, self.motion_params))\n\n        matrix = axis_rotation_matrix(self.axis, angle)\n        if squeeze_out:\n            matrix = matrix.squeeze()\n\n        return matrix", "response": "Return the rotation matrix to the system state at angle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef elekta_icon_geometry(sad=780.0, sdd=1000.0,\n                         piercing_point=(390.0, 0.0),\n                         angles=None, num_angles=None,\n                         detector_shape=(780, 720)):\n    \"\"\"Tomographic geometry of the Elekta Icon CBCT system.\n\n    See the [whitepaper]_ for specific descriptions of each parameter.\n\n    All measurments are given in millimeters unless otherwise stated.\n\n    Parameters\n    ----------\n    sad : float, optional\n        Source to Axis distance.\n    sdd : float, optional\n        Source to Detector distance.\n    piercing_point : sequence of foat, optional\n        Position in the detector (in pixel coordinates) that a beam from the\n        source, passing through the axis of rotation perpendicularly, hits.\n    angles : array-like, optional\n        List of angles given in radians that the projection images were taken\n        at. Exclusive with num_angles.\n        Default: np.linspace(1.2, 5.0, 332)\n    num_angles : int, optional\n        Number of angles. Exclusive with angles.\n        Default: 332\n    detector_shape : sequence of int, optional\n        Shape of the detector (in pixels). Useful if a sub-sampled system\n        should be studied.\n\n    Returns\n    -------\n    elekta_icon_geometry : `ConeFlatGeometry`\n\n    Examples\n    --------\n    Create default geometry:\n\n    >>> from odl.contrib import tomo\n    >>> geometry = tomo.elekta_icon_geometry()\n\n    Use a smaller detector (improves efficiency):\n\n    >>> small_geometry = tomo.elekta_icon_geometry(detector_shape=[100, 100])\n\n    See Also\n    --------\n    elekta_icon_space : Default reconstruction space for the Elekta Icon CBCT.\n    elekta_icon_fbp: Default reconstruction method for the Elekta Icon CBCT.\n\n    References\n    ----------\n    .. [whitepaper] *Design and performance characteristics of a Cone Beam\n       CT system for Leksell Gamma Knife Icon*\n    \"\"\"\n    sad = float(sad)\n    assert sad > 0\n    sdd = float(sdd)\n    assert sdd > sad\n    piercing_point = np.array(piercing_point, dtype=float)\n    assert piercing_point.shape == (2,)\n\n    if angles is not None and num_angles is not None:\n        raise ValueError('cannot provide both `angles` and `num_angles`')\n    elif angles is not None:\n        angles = odl.nonuniform_partition(angles)\n        assert angles.ndim == 1\n    elif num_angles is not None:\n        angles = odl.uniform_partition(1.2, 5.0, num_angles)\n    else:\n        angles = odl.uniform_partition(1.2, 5.0, 332)\n\n    detector_shape = np.array(detector_shape, dtype=int)\n\n    # Constant system parameters\n    pixel_size = 0.368\n    det_extent_mm = np.array([287.04, 264.96])\n\n    # Compute the detector partition\n    piercing_point_mm = pixel_size * piercing_point\n    det_min_pt = -piercing_point_mm\n    det_max_pt = det_min_pt + det_extent_mm\n    detector_partition = odl.uniform_partition(min_pt=det_min_pt,\n                                               max_pt=det_max_pt,\n                                               shape=detector_shape)\n\n    # Create the geometry\n    geometry = odl.tomo.ConeFlatGeometry(\n        angles, detector_partition,\n        src_radius=sad, det_radius=sdd - sad)\n\n    return geometry", "response": "Returns the Tomographic geometry of the Elekta Icon CBCT system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef elekta_icon_space(shape=(448, 448, 448), **kwargs):\n    if 'dtype' not in kwargs:\n        kwargs['dtype'] = 'float32'\n    return odl.uniform_discr(min_pt=[-112.0, -112.0, 0.0],\n                             max_pt=[112.0, 112.0, 224.0],\n                             shape=shape,\n                             **kwargs)", "response": "Default reconstruction space for the Elekta Icon CBCT."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefaults reconstruction space for the Elekta XVI CBCT.", "response": "def elekta_xvi_space(shape=(512, 512, 512), **kwargs):\n    \"\"\"Default reconstruction space for the Elekta XVI CBCT.\n\n    Parameters\n    ----------\n    shape : sequence of int, optional\n        Shape of the space, in voxels.\n    kwargs :\n        Keyword arguments to pass to `uniform_discr` to modify the space, e.g.\n        use another backend. By default, the dtype is set to float32.\n\n    Returns\n    -------\n    elekta_xvi_space : `DiscreteLp`\n\n    Examples\n    --------\n    Create default space:\n\n    >>> from odl.contrib import tomo\n    >>> space = tomo.elekta_xvi_space()\n\n    Create sub-sampled space:\n\n    >>> space = tomo.elekta_xvi_space(shape=(100, 100, 100))\n\n    See Also\n    --------\n    elekta_xvi_geometry: Geometry for the Elekta XVI CBCT.\n    elekta_xvi_fbp: Default reconstruction method for the Elekta XVI CBCT.\n    \"\"\"\n    if 'dtype' not in kwargs:\n        kwargs['dtype'] = 'float32'\n    return odl.uniform_discr(min_pt=[-128.0, -128, -128.0],\n                             max_pt=[128.0, 128.0, 128.0],\n                             shape=shape,\n                             **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef elekta_xvi_fbp(ray_transform,\n                   padding=False, filter_type='Hann', frequency_scaling=0.6):\n    \"\"\"Approximation of the FDK reconstruction used in the Elekta XVI.\n\n    Parameters\n    ----------\n    ray_transform : `RayTransform`\n        The ray transform to be used, should have an Elekta XVI geometry.\n    padding : bool, optional\n        Whether the FBP filter should use padding, increases memory use\n        significantly.\n    filter_type : str, optional\n        Type of filter to apply in the FBP filter.\n    frequency_scaling : float, optional\n        Frequency scaling for FBP filter.\n\n    Returns\n    -------\n    elekta_xvi_fbp : `DiscreteLp`\n\n    Examples\n    --------\n    Create default FBP for default geometry:\n\n    >>> from odl.contrib import tomo\n    >>> geometry = tomo.elekta_xvi_geometry()\n    >>> space = tomo.elekta_xvi_space()\n    >>> ray_transform = odl.tomo.RayTransform(space, geometry)\n    >>> fbp_op = tomo.elekta_xvi_fbp(ray_transform)\n    \"\"\"\n    fbp_op = odl.tomo.fbp_op(ray_transform,\n                             padding=padding,\n                             filter_type=filter_type,\n                             frequency_scaling=frequency_scaling)\n\n    return fbp_op", "response": "Approximation of the FDK reconstruction used in the Elekta XVI geometry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _modified_shepp_logan_ellipsoids(ellipsoids):\n    intensities = [1.0, -0.8, -0.2, -0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n\n    # Add minimal numbers to ensure that the result is nowhere negative.\n    # This is needed due to numerical issues.\n    intensities[2] += 5e-17\n    intensities[3] += 5e-17\n\n    assert len(ellipsoids) == len(intensities)\n\n    for ellipsoid, intensity in zip(ellipsoids, intensities):\n        ellipsoid[0] = intensity", "response": "Modify ellipsoids to give the modified Shepp - Logan phantom."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an arbitrary set of ellipsoids for the standard Shepp - Logan phantom in 2 or 3 dimensions.", "response": "def shepp_logan_ellipsoids(ndim, modified=False):\n    \"\"\"Ellipsoids for the standard Shepp-Logan phantom in 2 or 3 dimensions.\n\n    Parameters\n    ----------\n    ndim : {2, 3}\n        Dimension of the space the ellipsoids should be in.\n    modified : bool, optional\n        True if the modified Shepp-Logan phantom should be given.\n        The modified phantom has greatly amplified contrast to aid\n        visualization.\n\n    See Also\n    --------\n    odl.phantom.geometric.ellipsoid_phantom :\n        Function for creating arbitrary ellipsoids phantoms\n    shepp_logan : Create a phantom with these ellipsoids\n\n    References\n    ----------\n    .. _Shepp-Logan phantom: https://en.wikipedia.org/wiki/Shepp-Logan_phantom\n    \"\"\"\n    if ndim == 2:\n        ellipsoids = _shepp_logan_ellipse_2d()\n    elif ndim == 3:\n        ellipsoids = _shepp_logan_ellipsoids_3d()\n    else:\n        raise ValueError('dimension not 2 or 3, no phantom available')\n\n    if modified:\n        _modified_shepp_logan_ellipsoids(ellipsoids)\n\n    return ellipsoids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _analytical_forbild_phantom(resolution, ear):\n    sha = 0.2 * np.sqrt(3)\n    y016b = -14.294530834372887\n    a16b = 0.443194085308632\n    b16b = 3.892760834372886\n\n    E = [[-4.7, 4.3, 1.79989, 1.79989, 0, 0.010, 0],  # 1\n         [4.7, 4.3, 1.79989, 1.79989, 0, 0.010, 0],  # 2\n         [-1.08, -9, 0.4, 0.4, 0, 0.0025, 0],  # 3\n         [1.08, -9, 0.4, 0.4, 0, -0.0025, 0],  # 4\n         [0, 0, 9.6, 12, 0, 1.800, 0],  # 5\n         [0, 8.4, 1.8, 3.0, 0, -1.050, 0],  # 7\n         [1.9, 5.4, 0.41633, 1.17425, -31.07698, 0.750, 0],  # 8\n         [-1.9, 5.4, 0.41633, 1.17425, 31.07698, 0.750, 0],  # 9\n         [-4.3, 6.8, 1.8, 0.24, -30, 0.750, 0],  # 10\n         [4.3, 6.8, 1.8, 0.24, 30, 0.750, 0],  # 11\n         [0, -3.6, 1.8, 3.6, 0, -0.005, 0],  # 12\n         [6.39395, -6.39395, 1.2, 0.42, 58.1, 0.005, 0],  # 13\n         [0, 3.6, 2, 2, 0, 0.750, 4],  # 14\n         [0, 9.6, 1.8, 3.0, 0, 1.800, 4],  # 15\n         [0, 0, 9.0, 11.4, 0, 0.750, 3],  # 16a\n         [0, y016b, a16b, b16b, 0, 0.750, 1],  # 16b\n         [0, 0, 9.0, 11.4, 0, -0.750, ear],  # 6\n         [9.1, 0, 4.2, 1.8, 0, 0.750, 1]]  # R_ear\n    E = np.array(E)\n\n    # generate the air cavities in the right ear\n    cavity1 = np.arange(8.8, 5.6, -0.4)[:, None]\n    cavity2 = np.zeros([9, 1])\n    cavity3_7 = np.ones([53, 1]) * [0.15, 0.15, 0, -1.800, 0]\n\n    for j in range(1, 4):\n        kj = 8 - 2 * int(np.floor(j / 3))\n        dj = 0.2 * int(np.mod(j, 2))\n\n        cavity1 = np.vstack((cavity1,\n                             cavity1[0:kj] - dj,\n                             cavity1[0:kj] - dj))\n        cavity2 = np.vstack((cavity2,\n                             j * sha * np.ones([kj, 1]),\n                             -j * sha * np.ones([kj, 1])))\n\n    E_cavity = np.hstack((cavity1, cavity2, cavity3_7))\n\n    # generate the left ear (resolution pattern)\n    x0 = -7.0\n    y0 = -1.0\n    d0_xy = 0.04\n\n    d_xy = [0.0357, 0.0312, 0.0278, 0.0250]\n    ab = 0.5 * np.ones([5, 1]) * d_xy\n    ab = ab.T.ravel()[:, None] * np.ones([1, 4])\n    abr = ab.T.ravel()[:, None]\n\n    leftear4_7 = np.hstack([abr, abr, np.ones([80, 1]) * [0, 0.75, 0]])\n\n    x00 = np.zeros([0, 1])\n    y00 = np.zeros([0, 1])\n    for i in range(1, 5):\n        y00 = np.vstack((y00,\n                         (y0 + np.arange(0, 5) * 2 * d_xy[i - 1])[:, None]))\n        x00 = np.vstack((x00,\n                         (x0 + 2 * (i - 1) * d0_xy) * np.ones([5, 1])))\n\n    x00 = x00 * np.ones([1, 4])\n    x00 = x00.T.ravel()[:, None]\n    y00 = np.vstack([y00, y00 + 12 * d0_xy,\n                     y00 + 24 * d0_xy, y00 + 36 * d0_xy])\n\n    leftear = np.hstack([x00, y00, leftear4_7])\n    C = [[1.2, 1.2, 0.27884, 0.27884, 0.60687, 0.60687, 0.2,\n          0.2, -2.605, -2.605, -10.71177, y016b + 10.71177, 8.88740, -0.21260],\n         [0, 180, 90, 270, 90, 270, 0,\n          180, 15, 165, 90, 270, 0, 0]]\n    C = np.array(C)\n\n    if not resolution and not ear:\n        phantomE = E[:17, :]\n        phantomC = C[:, :12]\n    elif not resolution and ear:\n        phantomE = np.vstack([E, E_cavity])\n        phantomC = C\n    elif resolution and not ear:\n        phantomE = np.vstack([leftear, E[:17, :]])\n        phantomC = C[:, :12]\n    else:\n        phantomE = np.vstack([leftear, E, E_cavity])\n        phantomC = C\n\n    return phantomE, phantomC", "response": "Analytical description of a FORBILD phantom."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uniform_discr_frompartition(partition, dtype=None, impl='numpy', **kwargs):\n    if not isinstance(partition, RectPartition):\n        raise TypeError('`partition` {!r} is not a `RectPartition` instance'\n                        ''.format(partition))\n    if not partition.is_uniform:\n        raise ValueError('`partition` is not uniform')\n\n    if dtype is not None:\n        dtype = np.dtype(dtype)\n\n    fspace = FunctionSpace(partition.set, out_dtype=dtype)\n    ds_type = tspace_type(fspace, impl, dtype)\n\n    if dtype is None:\n        dtype = ds_type.default_dtype()\n\n    weighting = kwargs.pop('weighting', None)\n    exponent = kwargs.pop('exponent', 2.0)\n    if weighting is None and is_numeric_dtype(dtype):\n        if exponent == float('inf') or partition.ndim == 0:\n            weighting = 1.0\n        else:\n            weighting = partition.cell_volume\n\n    tspace = ds_type(partition.shape, dtype, exponent=exponent,\n                     weighting=weighting)\n    return DiscreteLp(fspace, partition, tspace, **kwargs)", "response": "Return a uniformly discretized L^p function space from a given uniform partition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a uniformly discretized L^p function space.", "response": "def uniform_discr_fromspace(fspace, shape, dtype=None, impl='numpy', **kwargs):\n    \"\"\"Return a uniformly discretized L^p function space.\n\n    Parameters\n    ----------\n    fspace : `FunctionSpace`\n        Continuous function space. Its domain must be an `IntervalProd`.\n    shape : int or sequence of ints\n        Number of samples per axis.\n    dtype : optional\n        Data type for the discretized space, must be understood by the\n        `numpy.dtype` constructor. The default for ``None`` depends on the\n        ``impl`` backend, usually it is ``'float64'`` or ``'float32'``.\n    impl : string, optional\n        Implementation of the data storage arrays\n    kwargs :\n        Additional keyword parameters, see `uniform_discr` for details.\n\n    Returns\n    -------\n    discr : `DiscreteLp`\n        The uniformly discretized function space\n\n    Examples\n    --------\n    >>> intv = odl.IntervalProd(0, 1)\n    >>> space = odl.FunctionSpace(intv)\n    >>> uniform_discr_fromspace(space, 10)\n    uniform_discr(0.0, 1.0, 10)\n\n    See Also\n    --------\n    uniform_discr : implicit uniform Lp discretization\n    uniform_discr_frompartition : uniform Lp discretization using a given\n        uniform partition of a function domain\n    uniform_discr_fromintv : uniform discretization from an existing\n        interval product\n    odl.discr.partition.uniform_partition :\n        partition of the function domain\n    \"\"\"\n    if not isinstance(fspace, FunctionSpace):\n        raise TypeError('`fspace` {!r} is not a `FunctionSpace` instance'\n                        ''.format(fspace))\n    if not isinstance(fspace.domain, IntervalProd):\n        raise TypeError('domain {!r} of the function space is not an '\n                        '`IntervalProd` instance'.format(fspace.domain))\n\n    # Set data type. If given, check consistency with fspace's field and\n    # out_dtype. If not given, take the latter.\n    if dtype is None:\n        dtype = fspace.out_dtype\n    else:\n        dtype, dtype_in = np.dtype(dtype), dtype\n        if not np.can_cast(fspace.scalar_out_dtype, dtype, casting='safe'):\n            raise ValueError('cannot safely cast from output data {} type of '\n                             'the function space to given data type {}'\n                             ''.format(fspace.out, dtype_in))\n\n    if fspace.field == RealNumbers() and not is_real_dtype(dtype):\n        raise ValueError('cannot discretize real space {} with '\n                         'non-real data type {}'\n                         ''.format(fspace, dtype))\n    elif (fspace.field == ComplexNumbers() and\n          not is_complex_floating_dtype(dtype)):\n        raise ValueError('cannot discretize complex space {} with '\n                         'non-complex-floating data type {}'\n                         ''.format(fspace, dtype))\n\n    nodes_on_bdry = kwargs.pop('nodes_on_bdry', False)\n    partition = uniform_partition_fromintv(fspace.domain, shape,\n                                           nodes_on_bdry)\n\n    return uniform_discr_frompartition(partition, dtype, impl, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a uniformly discretized L^p function space from an interval - product function domain.", "response": "def uniform_discr_fromintv(intv_prod, shape, dtype=None, impl='numpy',\n                           **kwargs):\n    \"\"\"Return a uniformly discretized L^p function space.\n\n    Parameters\n    ----------\n    intv_prod : `IntervalProd`\n        Function domain of the uniformly discretized space.\n    shape : int or sequence of ints\n        Number of samples per axis.\n    dtype : optional\n        Data type for the discretized space, must be understood by the\n        `numpy.dtype` constructor. The default for ``None`` depends on the\n        ``impl`` backend, usually it is ``'float64'`` or ``'float32'``.\n    impl : str, optional\n        Implementation of the data storage arrays.\n    kwargs :\n        Additional keyword parameters, see `uniform_discr` for details.\n\n    Returns\n    -------\n    discr : `DiscreteLp`\n        The uniformly discretized function space\n\n    Examples\n    --------\n    >>> intv = IntervalProd(0, 1)\n    >>> uniform_discr_fromintv(intv, 10)\n    uniform_discr(0.0, 1.0, 10)\n\n    See Also\n    --------\n    uniform_discr : implicit uniform Lp discretization\n    uniform_discr_frompartition : uniform Lp discretization using a given\n        uniform partition of a function domain\n    uniform_discr_fromspace : uniform discretization from an existing\n        function space\n    \"\"\"\n    if dtype is None:\n        dtype = tensor_space_impl(str(impl).lower()).default_dtype()\n\n    fspace = FunctionSpace(intv_prod, out_dtype=dtype)\n    return uniform_discr_fromspace(fspace, shape, dtype, impl, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uniform_discr(min_pt, max_pt, shape, dtype=None, impl='numpy', **kwargs):\n    intv_prod = IntervalProd(min_pt, max_pt)\n    return uniform_discr_fromintv(intv_prod, shape, dtype, impl, **kwargs)", "response": "Return a uniformly discretized L^p function space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discr_sequence_space(shape, dtype=None, impl='numpy', **kwargs):\n    shape = np.atleast_1d(shape)\n    return uniform_discr([0] * len(shape), shape - 1, shape, dtype, impl,\n                         nodes_on_bdry=True, **kwargs)", "response": "Return an object mimicing the sequence space l^p with stride 1."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uniform_discr_fromdiscr(discr, min_pt=None, max_pt=None,\n                            shape=None, cell_sides=None, **kwargs):\n    \"\"\"Return a discretization based on an existing one.\n\n    The parameters that are explicitly given are used to create the\n    new discretization, and the missing information is taken from\n    the template space. See Notes for the exact functionality.\n\n    Parameters\n    ----------\n    discr : `DiscreteLp`\n        Uniformly discretized space used as a template.\n    min_pt, max_pt: float or sequence of floats, optional\n        Desired minimum/maximum corners of the new space domain.\n    shape : int or sequence of ints, optional\n        Desired number of samples per axis of the new space.\n    cell_sides : float or sequence of floats, optional\n        Desired cell side lenghts of the new space's partition.\n    nodes_on_bdry : bool or sequence, optional\n        If a sequence is provided, it determines per axis whether to\n        place the last grid point on the boundary (``True``) or shift it\n        by half a cell size into the interior (``False``). In each axis,\n        an entry may consist in a single bool or a 2-tuple of\n        bool. In the latter case, the first tuple entry decides for\n        the left, the second for the right boundary. The length of the\n        sequence must be ``discr.ndim``.\n\n        A single boolean is interpreted as a global choice for all\n        boundaries.\n\n        Default: ``False``.\n\n    kwargs :\n        Additional keyword parameters passed to the `DiscreteLp`\n        initializer.\n\n    Notes\n    -----\n    The parameters ``min_pt``, ``max_pt``, ``shape`` and\n    ``cell_sides`` can be combined in the following ways (applies in\n    each axis individually):\n\n    **0 arguments:**\n        Return a copy of ``discr``\n\n    **1 argument:**\n        [min,max]_pt -> keep sampling but translate domain so it\n        starts/ends at ``[min,max]_pt``\n\n        shape/cell_sides -> keep domain but change sampling.\n        See `uniform_partition` for restrictions.\n\n    **2 arguments:**\n        min_pt + max_pt -> translate and resample with the same\n        number of samples\n\n        [min,max]_pt + shape/cell_sides -> translate and resample\n\n        shape + cell_sides -> error due to ambiguity (keep\n        ``min_pt`` or ``max_pt``?)\n\n    **3+ arguments:**\n        The underlying partition is uniquely determined by the new\n        parameters. See `uniform_partition`.\n\n    See Also\n    --------\n    uniform_discr : implicit uniform Lp discretization\n    odl.discr.partition.uniform_partition :\n        underlying domain partitioning scheme\n\n    Examples\n    --------\n    >>> discr = odl.uniform_discr([0, 0], [1, 2], (10, 5))\n    >>> discr.cell_sides\n    array([ 0.1,  0.4])\n\n    If no additional argument is given, a copy of ``discr`` is\n    returned:\n\n    >>> odl.uniform_discr_fromdiscr(discr) == discr\n    True\n    >>> odl.uniform_discr_fromdiscr(discr) is discr\n    False\n\n    Giving ``min_pt`` or ``max_pt`` results in a\n    translation, while for the other two options, the domain\n    is kept but re-partitioned:\n\n    >>> odl.uniform_discr_fromdiscr(discr, min_pt=[1, 1])\n    uniform_discr([ 1.,  1.], [ 2.,  3.], (10, 5))\n    >>> odl.uniform_discr_fromdiscr(discr, max_pt=[0, 0])\n    uniform_discr([-1., -2.], [ 0.,  0.], (10, 5))\n    >>> odl.uniform_discr_fromdiscr(discr, cell_sides=[1, 1])\n    uniform_discr([ 0.,  0.], [ 1.,  2.], (1, 2))\n    >>> odl.uniform_discr_fromdiscr(discr, shape=[5, 5])\n    uniform_discr([ 0.,  0.], [ 1.,  2.], (5, 5))\n    >>> odl.uniform_discr_fromdiscr(discr, shape=[5, 5]).cell_sides\n    array([ 0.2,  0.4])\n\n    The cases with 2 or more additional arguments and the syntax\n    for specifying quantities per axis is illustrated in the following:\n\n    # axis 0: translate to match max_pt = 3\n    # axis 1: recompute max_pt using the original shape with the\n    # new min_pt and cell_sides\n    >>> new_discr = odl.uniform_discr_fromdiscr(discr, min_pt=[None, 1],\n    ...                                         max_pt=[3, None],\n    ...                                         cell_sides=[None, 0.25])\n    >>> new_discr\n    uniform_discr([ 2.,  1.], [ 3.  ,  2.25], (10, 5))\n    >>> new_discr.cell_sides\n    array([ 0.1 ,  0.25])\n\n    # axis 0: recompute min_pt from old cell_sides and new\n    # max_pt and shape\n    # axis 1: use new min_pt, shape and cell_sides only\n    >>> new_discr = odl.uniform_discr_fromdiscr(discr, min_pt=[None, 1],\n    ...                                         max_pt=[3, None],\n    ...                                         shape=[5, 5],\n    ...                                         cell_sides=[None, 0.25])\n    >>> new_discr\n    uniform_discr([ 2.5,  1. ], [ 3.  ,  2.25], (5, 5))\n    >>> new_discr.cell_sides\n    array([ 0.1 ,  0.25])\n    \"\"\"\n    if not isinstance(discr, DiscreteLp):\n        raise TypeError('`discr` {!r} is not a DiscreteLp instance'\n                        ''.format(discr))\n    if not discr.is_uniform:\n        raise ValueError('`discr` {} is not uniformly discretized'\n                         ''.format(discr))\n\n    # Normalize partition parameters\n    min_pt = normalized_scalar_param_list(min_pt, discr.ndim,\n                                          param_conv=float, keep_none=True)\n    max_pt = normalized_scalar_param_list(max_pt, discr.ndim,\n                                          param_conv=float, keep_none=True)\n    shape = normalized_scalar_param_list(shape, discr.ndim,\n                                         param_conv=safe_int_conv,\n                                         keep_none=True)\n    cell_sides = normalized_scalar_param_list(cell_sides, discr.ndim,\n                                              param_conv=float, keep_none=True)\n\n    nodes_on_bdry = kwargs.pop('nodes_on_bdry', False)\n    nodes_on_bdry = normalized_nodes_on_bdry(nodes_on_bdry, discr.ndim)\n\n    new_min_pt = []\n    new_max_pt = []\n    new_shape = []\n    new_csides = []\n    for i, (xmin, xmax, n, s, old_xmin, old_xmax, old_n, old_s) in enumerate(\n            zip(min_pt, max_pt, shape, cell_sides,\n                discr.min_pt, discr.max_pt, discr.shape,\n                discr.cell_sides)):\n        num_params = sum(p is not None for p in (xmin, xmax, n, s))\n\n        if num_params == 0:\n            new_params = [old_xmin, old_xmax, old_n, None]\n\n        elif num_params == 1:\n            if xmin is not None:\n                new_params = [xmin, old_xmax + (xmin - old_xmin), old_n, None]\n            elif xmax is not None:\n                new_params = [old_xmin + (xmax - old_xmax), xmax, old_n, None]\n            elif n is not None:\n                new_params = [old_xmin, old_xmax, n, None]\n            else:\n                new_params = [old_xmin, old_xmax, None, s]\n\n        elif num_params == 2:\n            if xmin is not None and xmax is not None:\n                new_params = [xmin, xmax, old_n, None]\n            elif xmin is not None and n is not None:\n                new_params = [xmin, None, n, old_s]\n            elif xmin is not None and s is not None:\n                new_params = [xmin, None, old_n, s]\n            elif xmax is not None and n is not None:\n                new_params = [None, xmax, n, old_s]\n            elif xmax is not None and s is not None:\n                new_params = [None, xmax, old_n, s]\n            else:\n                raise ValueError('in axis {}: cannot use `shape` and '\n                                 '`cell_size` only due to ambiguous values '\n                                 'for `min_pt` and `max_pt`.'.format(i))\n\n        else:\n            new_params = [xmin, xmax, n, s]\n\n        new_min_pt.append(new_params[0])\n        new_max_pt.append(new_params[1])\n        new_shape.append(new_params[2])\n        new_csides.append(new_params[3])\n\n    new_part = uniform_partition(min_pt=new_min_pt, max_pt=new_max_pt,\n                                 shape=new_shape,\n                                 cell_sides=new_csides,\n                                 nodes_on_bdry=nodes_on_bdry)\n\n    return uniform_discr_frompartition(new_part, exponent=discr.exponent,\n                                       interp=discr.interp, impl=discr.impl,\n                                       **kwargs)", "response": "Return a new discretization based on an existing discretization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of lists of scaling functions for the boundary.", "response": "def _scaling_func_list(bdry_fracs, exponent):\n    \"\"\"Return a list of lists of scaling functions for the boundary.\"\"\"\n    def scaling(factor):\n        def scaling_func(x):\n            return x * factor\n        return scaling_func\n\n    func_list = []\n    for frac_l, frac_r in bdry_fracs:\n        func_list_entry = []\n        if np.isclose(frac_l, 1.0):\n            func_list_entry.append(None)\n        else:\n            func_list_entry.append(scaling(frac_l ** (1 / exponent)))\n\n        if np.isclose(frac_r, 1.0):\n            func_list_entry.append(None)\n        else:\n            func_list_entry.append(scaling(frac_r ** (1 / exponent)))\n\n        func_list.append(func_list_entry)\n    return func_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interp(self):\n        if self.ndim == 0:\n            return 'nearest'\n        elif all(interp == self.interp_byaxis[0]\n                 for interp in self.interp_byaxis):\n            return self.interp_byaxis[0]\n        else:\n            return self.interp_byaxis", "response": "Interpolation type of this discretization."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tangent_bundle(self):\n        if self.ndim == 0:\n            return ProductSpace(field=self.field)\n        else:\n            return ProductSpace(self, self.ndim)", "response": "The tangent bundle associated with domain using partition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrue if the weighting is the same for all space points.", "response": "def is_uniformly_weighted(self):\n        \"\"\"``True`` if the weighting is the same for all space points.\"\"\"\n        try:\n            is_uniformly_weighted = self.__is_uniformly_weighted\n        except AttributeError:\n            bdry_fracs = self.partition.boundary_cell_fractions\n            is_uniformly_weighted = (\n                np.allclose(bdry_fracs, 1.0) or\n                self.exponent == float('inf') or\n                not getattr(self.tspace, 'is_weighted', False))\n\n            self.__is_uniformly_weighted = is_uniformly_weighted\n\n        return is_uniformly_weighted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef element(self, inp=None, order=None, **kwargs):\n        if inp is None:\n            return self.element_type(self, self.tspace.element(order=order))\n        elif inp in self and order is None:\n            return inp\n        elif inp in self.tspace and order is None:\n            return self.element_type(self, inp)\n        elif callable(inp):\n            vectorized = kwargs.pop('vectorized', True)\n            # fspace element -> discretize\n            inp_elem = self.fspace.element(inp, vectorized=vectorized)\n            sampled = self.sampling(inp_elem, **kwargs)\n            return self.element_type(\n                self, self.tspace.element(sampled, order=order))\n        else:\n            # Sequence-type input\n            return self.element_type(\n                self, self.tspace.element(inp, order=order))", "response": "Create an element from an input or from scratch."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _astype(self, dtype):\n        fspace = self.fspace.astype(dtype)\n        tspace = self.tspace.astype(dtype)\n        return type(self)(\n            fspace, self.partition, tspace, interp=self.interp,\n            axis_labels=self.axis_labels)", "response": "Internal helper for casting to a new object of the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _inner(self, x, y):\n        if self.is_uniform and not self.is_uniformly_weighted:\n            # TODO: implement without copying x\n            bdry_fracs = self.partition.boundary_cell_fractions\n            func_list = _scaling_func_list(bdry_fracs, exponent=1.0)\n            x_arr = apply_on_boundary(x, func=func_list, only_once=False)\n            return super(DiscreteLp, self)._inner(self.element(x_arr), y)\n        else:\n            return super(DiscreteLp, self)._inner(x, y)", "response": "Return the inner product of two sets of elements."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dist(self, x, y):\n        if self.is_uniform and not self.is_uniformly_weighted:\n            bdry_fracs = self.partition.boundary_cell_fractions\n            func_list = _scaling_func_list(bdry_fracs, exponent=self.exponent)\n            arrs = [apply_on_boundary(vec, func=func_list, only_once=False)\n                    for vec in (x, y)]\n\n            return super(DiscreteLp, self)._dist(\n                self.element(arrs[0]), self.element(arrs[1]))\n        else:\n            return super(DiscreteLp, self)._dist(x, y)", "response": "Return the distance between two elements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new DiscreteLp object for indexing along input axes.", "response": "def byaxis_in(self):\n        \"\"\"Object to index along input (domain) dimensions.\n\n        Examples\n        --------\n        Indexing with integers or slices:\n\n        >>> space = odl.uniform_discr([0, 0, 0], [1, 2, 3], (5, 10, 15))\n        >>> space.byaxis_in[0]\n        uniform_discr(0.0, 1.0, 5)\n        >>> space.byaxis_in[1]\n        uniform_discr(0.0, 2.0, 10)\n        >>> space.byaxis_in[1:]\n        uniform_discr([ 0.,  0.], [ 2.,  3.], (10, 15))\n\n        Lists can be used to stack spaces arbitrarily:\n\n        >>> space.byaxis_in[[2, 1, 2]]\n        uniform_discr([ 0.,  0.,  0.], [ 3.,  2.,  3.], (15, 10, 15))\n        \"\"\"\n        space = self\n\n        class DiscreteLpByaxisIn(object):\n\n            \"\"\"Helper class for indexing by domain axes.\"\"\"\n\n            def __getitem__(self, indices):\n                \"\"\"Return ``self[indices]``.\n\n                Parameters\n                ----------\n                indices : index expression\n                    Object used to index the space domain.\n\n                Returns\n                -------\n                space : `DiscreteLp`\n                    The resulting space with indexed domain and otherwise\n                    same properties (except possibly weighting).\n                \"\"\"\n                fspace = space.fspace.byaxis_in[indices]\n                part = space.partition.byaxis[indices]\n\n                if isinstance(space.weighting, ConstWeighting):\n                    # Need to manually construct `tspace` since it doesn't\n                    # know where its weighting factor comes from\n                    try:\n                        iter(indices)\n                    except TypeError:\n                        newshape = space.shape[indices]\n                    else:\n                        newshape = tuple(space.shape[int(i)] for i in indices)\n\n                    weighting = part.cell_volume\n                    tspace = type(space.tspace)(\n                        newshape, space.dtype,\n                        exponent=space.exponent, weighting=weighting)\n                else:\n                    # Other weighting schemes are handled correctly by\n                    # the tensor space\n                    tspace = space.tspace.byaxis[indices]\n\n                try:\n                    iter(indices)\n                except TypeError:\n                    interp = space.interp_byaxis[indices]\n                    labels = space.axis_labels[indices]\n                else:\n                    interp = tuple(space.interp_byaxis[int(i)]\n                                   for i in indices)\n                    labels = tuple(space.axis_labels[int(i)]\n                                   for i in indices)\n\n                return DiscreteLp(fspace, part, tspace, interp,\n                                  axis_labels=labels)\n\n            def __repr__(self):\n                \"\"\"Return ``repr(self)``.\"\"\"\n                return repr(space) + '.byaxis_in'\n\n        return DiscreteLpByaxisIn()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imag(self, newimag):\n        if self.space.is_real:\n            raise ValueError('cannot set imaginary part in real spaces')\n        self.tensor.imag = newimag", "response": "Set the imaginary part of this element to newimag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef conj(self, out=None):\n        if out is None:\n            return self.space.element(self.tensor.conj())\n        else:\n            self.tensor.conj(out=out.tensor)\n            return out", "response": "Complex conjugate of this element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show(self, title=None, method='', coords=None, indices=None,\n             force_show=False, fig=None, **kwargs):\n        \"\"\"Display the function graphically.\n\n        Parameters\n        ----------\n        title : string, optional\n            Set the title of the figure\n\n        method : string, optional\n            1d methods:\n\n            - ``'plot'`` : graph plot (default for 1d data)\n            - ``'scatter'`` : scattered 2d points (2nd axis <-> value)\n\n            2d methods:\n\n            - ``'imshow'`` : image plot with coloring according to value,\n              including a colorbar (default for 2d data).\n            - ``'scatter'`` : cloud of scattered 3d points\n              (3rd axis <-> value)\n\n        coords : `array-like`, optional\n            Display a slice of the array instead of the full array.\n            The values are shown accordinging to the given values,\n            where ``None`` means all values along that dimension. For\n            example, ``[None, None, 0.5]`` shows all values in the first\n            two dimensions, with the third coordinate equal to 0.5.\n            If a sequence is provided, it specifies the minimum and maximum\n            point to be shown, i.e. ``[None, [0, 1]]`` shows all of the\n            first axis and values between 0 and 1 in the second.\n            This option is mutually exclusive with ``indices``.\n\n        indices : int, slice, Ellipsis or sequence, optional\n            Display a slice of the array instead of the full array.\n            If a sequence is given, the i-th entry indexes the i-th axis,\n            with the following behavior for the different types of entries:\n\n                - ``int``: take entries with this index along axis ``i``,\n                  removing this axis from the result\n                - ``slice``: take a subset along axis ``i``, keeping it\n                  intact\n                - ``None``: equivalent to ``slice(None)``\n                - ``Ellipsis`` (``...``): equivalent to the number of\n                  ``None`` entries required to fill up the sequence to\n                  correct length.\n\n            The typical use case is to show a slice for a fixed index in\n            a specific axis, which can be done most easily by setting, e.g.,\n            ``indices=[None, 50, None]`` to take the 2d slice parallel to\n            the x-z coordinate plane at index ``y = 50``.\n\n            A single ``int`` or ``slice`` object indexes the first\n            axis, i.e., is treated as ``(int_or_slice, Ellipsis)``.\n            For the default ``None``, the array is kepty as-is for data\n            that has at most 2 dimensions. For higher-dimensional\n            data, the 2d slice in the first two axes at the middle\n            position along the remaining axes is shown\n            (semantically ``[:, :, shape[2:] // 2]``).\n            This option is mutually exclusive with ``coords``.\n\n        force_show : bool, optional\n            Whether the plot should be forced to be shown now or deferred until\n            later. Note that some backends always displays the plot, regardless\n            of this value.\n\n        fig : `matplotlib.figure.Figure`, optional\n            The figure to show in. Expected to be of same \"style\", as\n            the figure given by this function. The most common use case\n            is that ``fig`` is the return value of an earlier call to\n            this function.\n\n        kwargs : {'figsize', 'saveto', 'clim', ...}, optional\n            Extra keyword arguments passed on to the display method.\n            See the Matplotlib functions for documentation of extra\n            options.\n\n        Returns\n        -------\n        fig : `matplotlib.figure.Figure`\n            The resulting figure. It is also shown to the user.\n\n        See Also\n        --------\n        odl.util.graphics.show_discrete_data : Underlying implementation\n        \"\"\"\n        from odl.util.graphics import show_discrete_data\n\n        if 'interp' not in kwargs and not isinstance(self.space.interp, tuple):\n            # Otherwise different interp per axis\n            kwargs['interp'] = self.space.interp\n\n        if self.ndim == 0:\n            raise ValueError('nothing to show for 0-dimensional vector')\n\n        if coords is not None:\n            if indices is not None:\n                raise ValueError('cannot provide both coords and indices')\n\n            partition = self.space.partition\n            shape = self.shape\n            indices = []\n            for axis, (n, coord) in enumerate(zip(shape, coords)):\n                try:\n                    coord_minp, coord_maxp = coord\n                except TypeError:\n                    coord_minp = coord_maxp = coord\n\n                subpart = partition.byaxis[axis]\n\n                # Validate input\n                if coord_minp is not None:\n                    coord_minp = subpart.set.element(coord_minp)\n                if coord_maxp is not None:\n                    coord_maxp = subpart.set.element(coord_maxp)\n\n                if len(subpart) == 0:  # trivial cases\n                    indices.append(0)\n                elif coord_minp is not None and coord_minp == coord_maxp:\n                    indices.append(subpart.index(coord_minp))\n                else:\n                    if coord_minp is None:\n                        min_ind = 0\n                    else:\n                        min_ind = np.floor(subpart.index(coord_minp,\n                                                         floating=True))\n\n                    if coord_maxp is None:\n                        max_ind = len(subpart)\n                    else:\n                        max_ind = np.ceil(subpart.index(coord_maxp,\n                                                        floating=True))\n\n                    indices.append(slice(int(min_ind), int(max_ind)))\n\n        # Default to showing x-y slice \"in the middle\"\n        if indices is None and self.ndim >= 3:\n            indices = ((slice(None),) * 2 +\n                       tuple(n // 2 for n in self.space.shape[2:]))\n\n        # Normalize indices\n        if isinstance(indices, (Integral, slice)):\n            indices = (indices,)\n        elif indices is None or indices == Ellipsis:\n            indices = (slice(None),) * self.ndim\n\n        # Single index or slice indexes the first axis, rest untouched\n        if len(indices) == 1:\n            indices = tuple(indices) + (Ellipsis,)\n\n        # Convert `Ellipsis` objects\n        if indices.count(Ellipsis) > 1:\n            raise ValueError('cannot use more than 1 `Ellipsis` (`...`)')\n        elif Ellipsis in indices:\n            # Replace Ellipsis with the correct number of `slice(None)`\n            pos = indices.index(Ellipsis)\n            indices = (tuple(indices[:pos]) +\n                       (slice(None),) * (self.ndim - len(indices) + 1) +\n                       tuple(indices[pos + 1:]))\n\n        # Now indices should be exactly of length `ndim`\n        if len(indices) < self.ndim:\n            raise ValueError('too few axes ({} < {})'.format(len(indices),\n                                                             self.ndim))\n        if len(indices) > self.ndim:\n            raise ValueError('too many axes ({} > {})'.format(len(indices),\n                                                              self.ndim))\n\n        # Map `None` to `slice(None)` in indices for syntax like `coords`\n        indices = tuple(slice(None) if idx is None else idx\n                        for idx in indices)\n\n        squeezed_axes = [axis for axis in range(self.ndim)\n                         if not isinstance(indices[axis], Integral)]\n        axis_labels = [self.space.axis_labels[axis] for axis in squeezed_axes]\n\n        # Squeeze grid and values according to the index expression\n        part = self.space.partition[indices].squeeze()\n        values = self.asarray()[indices].squeeze()\n\n        return show_discrete_data(values, part, title=title, method=method,\n                                  force_show=force_show, fig=fig,\n                                  axis_labels=axis_labels, **kwargs)", "response": "Display the function graphically."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget operator norms if needed.", "response": "def _operator_norms(L):\n    \"\"\"Get operator norms if needed.\n\n    Parameters\n    ----------\n    L : sequence of `Operator` or float\n        The operators or the norms of the operators that are used in the\n        `douglas_rachford_pd` method. For `Operator` entries, the norm\n        is computed with ``Operator.norm(estimate=True)``.\n    \"\"\"\n    L_norms = []\n    for Li in L:\n        if np.isscalar(Li):\n            L_norms.append(float(Li))\n        elif isinstance(Li, Operator):\n            L_norms.append(Li.norm(estimate=True))\n        else:\n            raise TypeError('invalid entry {!r} in `L`'.format(Li))\n    return L_norms"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parallel_beam_geometry(space, num_angles=None, det_shape=None):\n    # Find maximum distance from rotation axis\n    corners = space.domain.corners()[:, :2]\n    rho = np.max(np.linalg.norm(corners, axis=1))\n\n    # Find default values according to Nyquist criterion.\n\n    # We assume that the function is bandlimited by a wave along the x or y\n    # axis. The highest frequency we can measure is then a standing wave with\n    # period of twice the inter-node distance.\n    min_side = min(space.partition.cell_sides[:2])\n    omega = np.pi / min_side\n    num_px_horiz = 2 * int(np.ceil(rho * omega / np.pi)) + 1\n\n    if space.ndim == 2:\n        det_min_pt = -rho\n        det_max_pt = rho\n        if det_shape is None:\n            det_shape = num_px_horiz\n    elif space.ndim == 3:\n        num_px_vert = space.shape[2]\n        min_h = space.domain.min_pt[2]\n        max_h = space.domain.max_pt[2]\n        det_min_pt = [-rho, min_h]\n        det_max_pt = [rho, max_h]\n        if det_shape is None:\n            det_shape = [num_px_horiz, num_px_vert]\n\n    if num_angles is None:\n        num_angles = int(np.ceil(omega * rho))\n\n    angle_partition = uniform_partition(0, np.pi, num_angles)\n    det_partition = uniform_partition(det_min_pt, det_max_pt, det_shape)\n\n    if space.ndim == 2:\n        return Parallel2dGeometry(angle_partition, det_partition)\n    elif space.ndim == 3:\n        return Parallel3dAxisGeometry(angle_partition, det_partition)\n    else:\n        raise ValueError('``space.ndim`` must be 2 or 3.')", "response": "r Create default parallel beam geometry from a space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the position of the detector ref. point at angle.", "response": "def det_refpoint(self, angle):\n        \"\"\"Return the position(s) of the detector ref. point at ``angle``.\n\n        The reference point is given by a rotation of the initial\n        position by ``angle``.\n\n        For an angle (or a vector of angles) ``phi``, the detector position\n        is given by ::\n\n            det_ref(phi) = translation +\n                           rotation_matrix(phi) * (det_pos_init - translation)\n\n        where ``det_pos_init`` is the detector reference point at initial\n        state.\n\n        This default implementation assumes in the case of 2 or 3 motion\n        parameters that they are to be interpreted as Euler angles.\n        Subclasses with a deviating intended interpretation should override\n        this method.\n\n        Parameters\n        ----------\n        angle : `array-like` or sequence\n            One or several (Euler) angles in radians at which to\n            evaluate. If ``motion_params.ndim >= 2``, a sequence of that\n            length must be provided.\n\n        Returns\n        -------\n        refpt : `numpy.ndarray`\n            Vector(s) pointing from the origin to the detector reference\n            point at ``angle``.\n            If ``angle`` is a single parameter, the returned array has\n            shape ``(ndim,)``, otherwise\n\n            - ``angle.shape + (ndim,)`` if `motion_params` is 1D,\n            - ``broadcast(*angle).shape + (ndim,)`` if `motion_params` is 2D\n              or 3D (Euler angles).\n\n        See Also\n        --------\n        rotation_matrix\n\n        Examples\n        --------\n        For 2d and default arguments, the detector starts at ``e_y`` and\n        rotates to ``-e_x`` at 90 degrees:\n\n        >>> apart = odl.uniform_partition(0, np.pi, 10)\n        >>> dpart = odl.uniform_partition(-1, 1, 20)\n        >>> geom = Parallel2dGeometry(apart, dpart)\n        >>> geom.det_refpoint(0)\n        array([ 0.,  1.])\n        >>> np.allclose(geom.det_refpoint(np.pi / 2), [-1, 0])\n        True\n\n        The method is vectorized, i.e., it can be called with multiple\n        angles at once (or n-dimensional arrays of parameters):\n\n        >>> points = geom.det_refpoint([0, np.pi])\n        >>> np.allclose(points[0], [0, 1])\n        True\n        >>> np.allclose(points[1], [0, -1])\n        True\n        >>> geom.det_refpoint(np.zeros((4, 5))).shape\n        (4, 5, 2)\n\n        In 3d with single rotation axis ``e_z``, we have the same situation,\n        except that the vectors have a third component equal to 0:\n\n        >>> apart = odl.uniform_partition(0, np.pi, 10)\n        >>> dpart = odl.uniform_partition([-1, -1], [1, 1], (20, 20))\n        >>> geom = Parallel3dAxisGeometry(apart, dpart)\n        >>> geom.det_refpoint(0)\n        array([ 0.,  1.,  0.])\n        >>> np.allclose(geom.det_refpoint(np.pi / 2), [-1, 0, 0])\n        True\n        \"\"\"\n        if self.motion_params.ndim == 1:\n            squeeze_out = (np.shape(angle) == ())\n            angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n            rot_matrix = self.rotation_matrix(angle)\n            extra_dims = angle.ndim\n        elif self.motion_params.ndim in (2, 3):\n            squeeze_out = (np.broadcast(*angle).shape == ())\n            angle = tuple(np.array(a, dtype=float, copy=False, ndmin=1)\n                          for a in angle)\n            rot_matrix = self.rotation_matrix(angle)\n            extra_dims = len(np.broadcast(*angle).shape)\n        else:\n            raise NotImplementedError(\n                'no default implementation available for `det_refpoint` '\n                'with `motion_params.ndim == {}`'\n                ''.format(self.motion_params.ndim))\n\n        rot_part = rot_matrix.dot(self.det_pos_init - self.translation)\n\n        # Broadcast along extra dimensions\n        pt_slc = (None,) * extra_dims + (slice(None),)\n        refpoint = self.translation[pt_slc] + rot_part\n        if squeeze_out:\n            refpoint = refpoint.squeeze()\n\n        return refpoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef det_to_src(self, angle, dparam):\n        # Always call the downstream methods with vectorized arguments\n        # to be able to reliably manipulate the final axes of the result\n        if self.motion_params.ndim == 1:\n            squeeze_angle = (np.shape(angle) == ())\n            angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n            matrix = self.rotation_matrix(angle)  # shape (m, ndim, ndim)\n        else:\n            squeeze_angle = (np.broadcast(*angle).shape == ())\n            angle = tuple(np.array(a, dtype=float, copy=False, ndmin=1)\n                          for a in angle)\n            matrix = self.rotation_matrix(angle)  # shape (m, ndim, ndim)\n\n        if self.det_params.ndim == 1:\n            squeeze_dparam = (np.shape(dparam) == ())\n            dparam = np.array(dparam, dtype=float, copy=False, ndmin=1)\n        else:\n            squeeze_dparam = (np.broadcast(*dparam).shape == ())\n            dparam = tuple(np.array(p, dtype=float, copy=False, ndmin=1)\n                           for p in dparam)\n\n        normal = self.detector.surface_normal(dparam)  # shape (d, ndim)\n\n        # Perform matrix-vector multiplication along the last axis of both\n        # `matrix` and `normal` while \"zipping\" all axes that do not\n        # participate in the matrix-vector product. In other words, the axes\n        # are labelled\n        # [0, 1, ..., r-1, r, r+1] for `matrix` and\n        # [0, 1, ..., r-1, r+1] for `normal`, and the output axes are set to\n        # [0, 1, ..., r-1, r]. This automatically supports broadcasting\n        # along the axes 0, ..., r-1.\n        matrix_axes = list(range(matrix.ndim))\n        normal_axes = list(range(matrix.ndim - 2)) + [matrix_axes[-1]]\n        out_axes = list(range(matrix.ndim - 1))\n        det_to_src = np.einsum(matrix, matrix_axes, normal, normal_axes,\n                               out_axes)\n        if squeeze_angle and squeeze_dparam:\n            det_to_src = det_to_src.squeeze()\n\n        return det_to_src", "response": "This method computes the direction vector from a detector location to the source."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an instance of Parallel2dGeometry from a matrix.", "response": "def frommatrix(cls, apart, dpart, init_matrix, **kwargs):\n        \"\"\"Create an instance of `Parallel2dGeometry` using a matrix.\n\n        This alternative constructor uses a matrix to rotate and\n        translate the default configuration. It is most useful when\n        the transformation to be applied is already given as a matrix.\n\n        Parameters\n        ----------\n        apart : 1-dim. `RectPartition`\n            Partition of the angle interval.\n        dpart : 1-dim. `RectPartition`\n            Partition of the detector parameter interval.\n        init_matrix : `array_like`, shape ``(2, 2)`` or ``(2, 3)``, optional\n            Transformation matrix whose left ``(2, 2)`` block is multiplied\n            with the default ``det_pos_init`` and ``det_axis_init`` to\n            determine the new vectors. If present, the third column acts\n            as a translation after the initial transformation.\n            The resulting ``det_axis_init`` will be normalized.\n        kwargs :\n            Further keyword arguments passed to the class constructor.\n\n        Returns\n        -------\n        geometry : `Parallel2dGeometry`\n\n        Examples\n        --------\n        Mirror the second unit vector, creating a left-handed system:\n\n        >>> apart = odl.uniform_partition(0, np.pi, 10)\n        >>> dpart = odl.uniform_partition(-1, 1, 20)\n        >>> matrix = np.array([[1, 0],\n        ...                    [0, -1]])\n        >>> geom = Parallel2dGeometry.frommatrix(apart, dpart, matrix)\n        >>> e_x, e_y = np.eye(2)  # standard unit vectors\n        >>> np.allclose(geom.det_pos_init, -e_y)\n        True\n        >>> np.allclose(geom.det_axis_init, e_x)\n        True\n        >>> np.allclose(geom.translation, (0, 0))\n        True\n\n        Adding a translation with a third matrix column:\n\n        >>> matrix = np.array([[1, 0, 1],\n        ...                    [0, -1, 1]])\n        >>> geom = Parallel2dGeometry.frommatrix(apart, dpart, matrix)\n        >>> np.allclose(geom.translation, (1, 1))\n        True\n        >>> np.allclose(geom.det_pos_init, -e_y + (1, 1))\n        True\n        \"\"\"\n        # Get transformation and translation parts from `init_matrix`\n        init_matrix = np.asarray(init_matrix, dtype=float)\n        if init_matrix.shape not in ((2, 2), (2, 3)):\n            raise ValueError('`matrix` must have shape (2, 2) or (2, 3), '\n                             'got array with shape {}'\n                             ''.format(init_matrix.shape))\n        trafo_matrix = init_matrix[:, :2]\n        translation = init_matrix[:, 2:].squeeze()\n\n        # Transform the default vectors\n        default_det_pos_init = cls._default_config['det_pos_init']\n        default_det_axis_init = cls._default_config['det_axis_init']\n        vecs_to_transform = [default_det_axis_init]\n        transformed_vecs = transform_system(\n            default_det_pos_init, None, vecs_to_transform, matrix=trafo_matrix)\n\n        # Use the standard constructor with these vectors\n        det_pos, det_axis = transformed_vecs\n        if translation.size != 0:\n            kwargs['translation'] = translation\n\n        return cls(apart, dpart, det_pos,\n                   det_axis_init=det_axis, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef det_axes(self, angles):\n        # Transpose to take dot along axis 1\n        axes = self.rotation_matrix(angles).dot(self.det_axes_init.T)\n        # `axes` has shape (a, 3, 2), need to roll the last dimensions\n        # to the second to last place\n        return np.rollaxis(axes, -1, -2)", "response": "Return the detector axes tuple at angles."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the rotation matrix to the system state at angles.", "response": "def rotation_matrix(self, angles):\n        \"\"\"Return the rotation matrix to the system state at ``angles``.\n\n        Parameters\n        ----------\n        angles : `array-like` or sequence\n            Euler angles in radians describing the rotation of the detector.\n            The length of the provided argument (along the first axis in\n            case of an array) must be equal to the number of Euler angles\n            in this geometry.\n\n        Returns\n        -------\n        rot : `numpy.ndarray`\n            Rotation matrix (or matrices) mapping vectors at the\n            initial state to the ones in the state defined by ``angles``.\n            The rotation is extrinsic, i.e., defined in the \"world\"\n            coordinate system.\n            If ``angles`` is a single pair (or triplet) of Euler angles,\n            an array of shape ``(3, 3)`` representing a single matrix is\n            returned. Otherwise, the shape of the returned array is\n            ``broadcast(*angles).shape + (3, 3)``.\n        \"\"\"\n        squeeze_out = (np.broadcast(*angles).shape == ())\n        angles_in = angles\n        angles = tuple(np.array(angle, dtype=float, copy=False, ndmin=1)\n                       for angle in angles)\n        if (self.check_bounds and\n                not is_inside_bounds(angles, self.motion_params)):\n            raise ValueError('`angles` {} not in the valid range '\n                             '{}'.format(angles_in, self.motion_params))\n\n        matrix = euler_matrix(*angles)\n        if squeeze_out:\n            matrix = matrix.squeeze()\n\n        return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef frommatrix(cls, apart, dpart, init_matrix, **kwargs):\n        # Get transformation and translation parts from `init_matrix`\n        init_matrix = np.asarray(init_matrix, dtype=float)\n        if init_matrix.shape not in ((3, 3), (3, 4)):\n            raise ValueError('`matrix` must have shape (3, 3) or (3, 4), '\n                             'got array with shape {}'\n                             ''.format(init_matrix.shape))\n        trafo_matrix = init_matrix[:, :3]\n        translation = init_matrix[:, 3:].squeeze()\n\n        # Transform the default vectors\n        default_axis = cls._default_config['axis']\n        default_det_pos_init = cls._default_config['det_pos_init']\n        default_det_axes_init = cls._default_config['det_axes_init']\n        vecs_to_transform = (default_det_pos_init,) + default_det_axes_init\n        transformed_vecs = transform_system(\n            default_axis, None, vecs_to_transform, matrix=trafo_matrix)\n\n        # Use the standard constructor with these vectors\n        axis, det_pos, det_axis_0, det_axis_1 = transformed_vecs\n        if translation.size != 0:\n            kwargs['translation'] = translation\n\n        return cls(apart, dpart, axis,\n                   det_pos_init=det_pos,\n                   det_axes_init=[det_axis_0, det_axis_1],\n                   **kwargs)", "response": "Create an instance of Parallel3dAxisGeometry from a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn ufunc wrapper for implementation - agnostic ufunc classes.", "response": "def wrap_ufunc_base(name, n_in, n_out, doc):\n    \"\"\"Return ufunc wrapper for implementation-agnostic ufunc classes.\"\"\"\n    ufunc = getattr(np, name)\n    if n_in == 1:\n        if n_out == 1:\n            def wrapper(self, out=None, **kwargs):\n                if out is None or isinstance(out, (type(self.elem),\n                                                   type(self.elem.data))):\n                    out = (out,)\n\n                return self.elem.__array_ufunc__(\n                    ufunc, '__call__', self.elem, out=out, **kwargs)\n\n        elif n_out == 2:\n            def wrapper(self, out=None, **kwargs):\n                if out is None:\n                    out = (None, None)\n\n                return self.elem.__array_ufunc__(\n                    ufunc, '__call__', self.elem, out=out, **kwargs)\n\n        else:\n            raise NotImplementedError\n\n    elif n_in == 2:\n        if n_out == 1:\n            def wrapper(self, x2, out=None, **kwargs):\n                return self.elem.__array_ufunc__(\n                    ufunc, '__call__', self.elem, x2, out=(out,), **kwargs)\n\n        else:\n            raise NotImplementedError\n    else:\n        raise NotImplementedError\n\n    wrapper.__name__ = wrapper.__qualname__ = name\n    wrapper.__doc__ = doc\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_ufunc_productspace(name, n_in, n_out, doc):\n    if n_in == 1:\n        if n_out == 1:\n            def wrapper(self, out=None, **kwargs):\n                if out is None:\n                    result = [getattr(x.ufuncs, name)(**kwargs)\n                              for x in self.elem]\n                    return self.elem.space.element(result)\n                else:\n                    for x, out_x in zip(self.elem, out):\n                        getattr(x.ufuncs, name)(out=out_x, **kwargs)\n                    return out\n\n        elif n_out == 2:\n            def wrapper(self, out1=None, out2=None, **kwargs):\n                if out1 is None:\n                    out1 = self.elem.space.element()\n                if out2 is None:\n                    out2 = self.elem.space.element()\n                for x, out1_x, out2_x in zip(self.elem, out1, out2):\n                    getattr(x.ufuncs, name)(out1=out1_x, out2=out2_x, **kwargs)\n                return out1, out2\n\n        else:\n            raise NotImplementedError\n\n    elif n_in == 2:\n        if n_out == 1:\n            def wrapper(self, x2, out=None, **kwargs):\n                if x2 in self.elem.space:\n                    if out is None:\n                        result = [getattr(x.ufuncs, name)(x2p, **kwargs)\n                                  for x, x2p in zip(self.elem, x2)]\n                        return self.elem.space.element(result)\n                    else:\n                        for x, x2p, outp in zip(self.elem, x2, out):\n                            getattr(x.ufuncs, name)(x2p, out=outp, **kwargs)\n                        return out\n                else:\n                    if out is None:\n                        result = [getattr(x.ufuncs, name)(x2, **kwargs)\n                                  for x in self.elem]\n                        return self.elem.space.element(result)\n                    else:\n                        for x, outp in zip(self.elem, out):\n                            getattr(x.ufuncs, name)(x2, out=outp, **kwargs)\n                        return out\n\n        else:\n            raise NotImplementedError\n    else:\n        raise NotImplementedError\n\n    wrapper.__name__ = wrapper.__qualname__ = name\n    wrapper.__doc__ = doc\n    return wrapper", "response": "Return ufunc wrapper for ProductSpaceUfuncs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sum(self, axis=None, dtype=None, out=None, keepdims=False):\n        return self.elem.__array_ufunc__(\n            np.add, 'reduce', self.elem,\n            axis=axis, dtype=dtype, out=(out,), keepdims=keepdims)", "response": "Return the sum of self."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prod(self, axis=None, dtype=None, out=None, keepdims=False):\n        return self.elem.__array_ufunc__(\n            np.multiply, 'reduce', self.elem,\n            axis=axis, dtype=dtype, out=(out,), keepdims=keepdims)", "response": "Return the product of the also - set internal key elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the minimum of self.", "response": "def min(self, axis=None, dtype=None, out=None, keepdims=False):\n        \"\"\"Return the minimum of ``self``.\n\n        See Also\n        --------\n        numpy.amin\n        max\n        \"\"\"\n        return self.elem.__array_ufunc__(\n            np.minimum, 'reduce', self.elem,\n            axis=axis, dtype=dtype, out=(out,), keepdims=keepdims)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the maximum of self.", "response": "def max(self, axis=None, dtype=None, out=None, keepdims=False):\n        \"\"\"Return the maximum of ``self``.\n\n        See Also\n        --------\n        numpy.amax\n        min\n        \"\"\"\n        return self.elem.__array_ufunc__(\n            np.maximum, 'reduce', self.elem,\n            axis=axis, dtype=dtype, out=(out,), keepdims=keepdims)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the sum of self.", "response": "def sum(self):\n        \"\"\"Return the sum of ``self``.\n\n        See Also\n        --------\n        numpy.sum\n        prod\n        \"\"\"\n        results = [x.ufuncs.sum() for x in self.elem]\n        return np.sum(results)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the product of self.", "response": "def prod(self):\n        \"\"\"Return the product of ``self``.\n\n        See Also\n        --------\n        numpy.prod\n        sum\n        \"\"\"\n        results = [x.ufuncs.prod() for x in self.elem]\n        return np.prod(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef min(self):\n        results = [x.ufuncs.min() for x in self.elem]\n        return np.min(results)", "response": "Return the minimum of self."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef max(self):\n        results = [x.ufuncs.max() for x in self.elem]\n        return np.max(results)", "response": "Return the maximum of self. See Also\n        numpy. amax\n        min\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conjugate_gradient(op, x, rhs, niter, callback=None):\n    # TODO: add a book reference\n    # TODO: update doc\n\n    if op.domain != op.range:\n        raise ValueError('operator needs to be self-adjoint')\n\n    if x not in op.domain:\n        raise TypeError('`x` {!r} is not in the domain of `op` {!r}'\n                        ''.format(x, op.domain))\n\n    r = op(x)\n    r.lincomb(1, rhs, -1, r)       # r = rhs - A x\n    p = r.copy()\n    d = op.domain.element()  # Extra storage for storing A x\n\n    sqnorm_r_old = r.norm() ** 2  # Only recalculate norm after update\n\n    if sqnorm_r_old == 0:  # Return if no step forward\n        return\n\n    for _ in range(niter):\n        op(p, out=d)  # d = A p\n\n        inner_p_d = p.inner(d)\n\n        if inner_p_d == 0.0:  # Return if step is 0\n            return\n\n        alpha = sqnorm_r_old / inner_p_d\n\n        x.lincomb(1, x, alpha, p)            # x = x + alpha*p\n        r.lincomb(1, r, -alpha, d)           # r = r - alpha*d\n\n        sqnorm_r_new = r.norm() ** 2\n\n        beta = sqnorm_r_new / sqnorm_r_old\n        sqnorm_r_old = sqnorm_r_new\n\n        p.lincomb(1, r, beta, p)                       # p = s + b * p\n\n        if callback is not None:\n            callback(x)", "response": "This method solves the inverse problem of the self - adjoint operators."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef conjugate_gradient_normal(op, x, rhs, niter=1, callback=None):\n    # TODO: add a book reference\n    # TODO: update doc\n\n    if x not in op.domain:\n        raise TypeError('`x` {!r} is not in the domain of `op` {!r}'\n                        ''.format(x, op.domain))\n\n    d = op(x)\n    d.lincomb(1, rhs, -1, d)               # d = rhs - A x\n    p = op.derivative(x).adjoint(d)\n    s = p.copy()\n    q = op.range.element()\n    sqnorm_s_old = s.norm() ** 2  # Only recalculate norm after update\n\n    for _ in range(niter):\n        op(p, out=q)                       # q = A p\n        sqnorm_q = q.norm() ** 2\n        if sqnorm_q == 0.0:  # Return if residual is 0\n            return\n\n        a = sqnorm_s_old / sqnorm_q\n        x.lincomb(1, x, a, p)               # x = x + a*p\n        d.lincomb(1, d, -a, q)              # d = d - a*Ap\n        op.derivative(p).adjoint(d, out=s)  # s = A^T d\n\n        sqnorm_s_new = s.norm() ** 2\n        b = sqnorm_s_new / sqnorm_s_old\n        sqnorm_s_old = sqnorm_s_new\n\n        p.lincomb(1, s, b, p)               # p = s + b * p\n\n        if callback is not None:\n            callback(x)", "response": "Optimized implementation of CG for the normal equation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noptimizes implementation of a Gauss-Newton method. This method solves the inverse problem (of the first kind):: A(x) = y for a (Frechet-) differentiable `Operator` ``A`` using a Gauss-Newton iteration. It uses a minimum amount of memory copies by applying re-usable temporaries and in-place evaluation. A variant of the method applied to a specific problem is described in a `Wikipedia article <https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm>`_. Parameters ---------- op : `Operator` Operator in the inverse problem. If not linear, it must have an implementation of `Operator.derivative`, which in turn must implement `Operator.adjoint`, i.e. the call ``op.derivative(x).adjoint`` must be valid. x : ``op.domain`` element Element to which the result is written. Its initial value is used as starting point of the iteration, and its values are updated in each iteration step. rhs : ``op.range`` element Right-hand side of the equation defining the inverse problem niter : int Maximum number of iterations. zero_seq : iterable, optional Zero sequence whose values are used for the regularization of the linearized problem in each Newton step. callback : callable, optional Object executing code per iteration, e.g. plotting each iterate.", "response": "def gauss_newton(op, x, rhs, niter, zero_seq=exp_zero_seq(2.0),\n                 callback=None):\n    \"\"\"Optimized implementation of a Gauss-Newton method.\n\n    This method solves the inverse problem (of the first kind)::\n\n        A(x) = y\n\n    for a (Frechet-) differentiable `Operator` ``A`` using a\n    Gauss-Newton iteration.\n\n    It uses a minimum amount of memory copies by applying re-usable\n    temporaries and in-place evaluation.\n\n    A variant of the method applied to a specific problem is described\n    in a\n    `Wikipedia article\n    <https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm>`_.\n\n    Parameters\n    ----------\n    op : `Operator`\n        Operator in the inverse problem. If not linear, it must have\n        an implementation of `Operator.derivative`, which\n        in turn must implement `Operator.adjoint`, i.e.\n        the call ``op.derivative(x).adjoint`` must be valid.\n    x : ``op.domain`` element\n        Element to which the result is written. Its initial value is\n        used as starting point of the iteration, and its values are\n        updated in each iteration step.\n    rhs : ``op.range`` element\n        Right-hand side of the equation defining the inverse problem\n    niter : int\n        Maximum number of iterations.\n    zero_seq : iterable, optional\n        Zero sequence whose values are used for the regularization of\n        the linearized problem in each Newton step.\n    callback : callable, optional\n        Object executing code per iteration, e.g. plotting each iterate.\n    \"\"\"\n    if x not in op.domain:\n        raise TypeError('`x` {!r} is not in the domain of `op` {!r}'\n                        ''.format(x, op.domain))\n\n    x0 = x.copy()\n    id_op = IdentityOperator(op.domain)\n    dx = op.domain.zero()\n\n    tmp_dom = op.domain.element()\n    u = op.domain.element()\n    tmp_ran = op.range.element()\n    v = op.range.element()\n\n    for _ in range(niter):\n        tm = next(zero_seq)\n        deriv = op.derivative(x)\n        deriv_adjoint = deriv.adjoint\n\n        # v = rhs - op(x) - deriv(x0-x)\n        # u = deriv.T(v)\n        op(x, out=tmp_ran)              # eval  op(x)\n        v.lincomb(1, rhs, -1, tmp_ran)  # assign  v = rhs - op(x)\n        tmp_dom.lincomb(1, x0, -1, x)   # assign temp  tmp_dom = x0 - x\n        deriv(tmp_dom, out=tmp_ran)     # eval  deriv(x0-x)\n        v -= tmp_ran                    # assign  v = rhs-op(x)-deriv(x0-x)\n        deriv_adjoint(v, out=u)         # eval/assign  u = deriv.T(v)\n\n        # Solve equation Tikhonov regularized system\n        # (deriv.T o deriv + tm * id_op)^-1 u = dx\n        tikh_op = OperatorSum(OperatorComp(deriv.adjoint, deriv),\n                              tm * id_op, tmp_dom)\n\n        # TODO: allow user to select other method\n        conjugate_gradient(tikh_op, dx, u, 3)\n\n        # Update x\n        x.lincomb(1, x0, 1, dx)  # x = x0 + dx\n\n        if callback is not None:\n            callback(x)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kaczmarz(ops, x, rhs, niter, omega=1, projection=None, random=False,\n             callback=None, callback_loop='outer'):\n    r\"\"\"Optimized implementation of Kaczmarz's method.\n\n    Solves the inverse problem given by the set of equations::\n\n        A_n(x) = rhs_n\n\n    This is also known as the Landweber-Kaczmarz's method, since the method\n    coincides with the Landweber method for a single operator.\n\n    Parameters\n    ----------\n    ops : sequence of `Operator`'s\n        Operators in the inverse problem. ``op[i].derivative(x).adjoint`` must\n        be well-defined for ``x`` in the operator domain and for all ``i``.\n    x : ``op.domain`` element\n        Element to which the result is written. Its initial value is\n        used as starting point of the iteration, and its values are\n        updated in each iteration step.\n    rhs : sequence of ``ops[i].range`` elements\n        Right-hand side of the equation defining the inverse problem.\n    niter : int\n        Number of iterations.\n    omega : positive float or sequence of positive floats, optional\n        Relaxation parameter in the iteration. If a single float is given the\n        same step is used for all operators, otherwise separate steps are used.\n    projection : callable, optional\n        Function that can be used to modify the iterates in each iteration,\n        for example enforcing positivity. The function should take one\n        argument and modify it in-place.\n    random : bool, optional\n        If `True`, the order of the operators is randomized in each iteration.\n    callback : callable, optional\n        Object executing code per iteration, e.g. plotting each iterate.\n    callback_loop : {'inner', 'outer'}\n        Whether the callback should be called in the inner or outer loop.\n\n\n    Notes\n    -----\n    This method calculates an approximate least-squares solution of\n    the inverse problem of the first kind\n\n    .. math::\n        \\mathcal{A}_i (x) = y_i \\quad 1 \\leq i \\leq n,\n\n    for a given :math:`y_n \\in \\mathcal{Y}_n`, i.e. an approximate\n    solution :math:`x^*` to\n\n    .. math::\n        \\min_{x\\in \\mathcal{X}}\n        \\sum_{i=1}^n \\| \\mathcal{A}_i(x) - y_i \\|_{\\mathcal{Y}_i}^2\n\n    for a (Frechet-) differentiable operator\n    :math:`\\mathcal{A}: \\mathcal{X} \\to \\mathcal{Y}` between Hilbert\n    spaces :math:`\\mathcal{X}` and :math:`\\mathcal{Y}`. The method\n    starts from an initial guess :math:`x_0` and uses the\n    iteration\n\n    .. math::\n        x_{k+1} = x_k - \\omega_{[k]} \\ \\partial \\mathcal{A}_{[k]}(x_k)^*\n                                 (\\mathcal{A}_{[k]}(x_k) - y_{[k]}),\n\n    where :math:`\\partial \\mathcal{A}_{[k]}(x_k)` is the Frechet derivative\n    of :math:`\\mathcal{A}_{[k]}` at :math:`x_k`, :math:`\\omega_{[k]}` is a\n    relaxation parameter and :math:`[k] := k \\text{ mod } n`.\n\n    For linear problems, a choice\n    :math:`0 < \\omega_i < 2/\\lVert \\mathcal{A}_{i}^2\\rVert` guarantees\n    convergence, where :math:`\\|\\mathcal{A}_{i}\\|` stands for the\n    operator norm of :math:`\\mathcal{A}_{i}`.\n\n    This implementation uses a minimum amount of memory copies by\n    applying re-usable temporaries and in-place evaluation.\n\n    The method is also described in a\n    `Wikipedia article\n    <https://en.wikipedia.org/wiki/Kaczmarz_method>`_. and in Natterer, F.\n    Mathematical Methods in Image Reconstruction, section 5.3.2.\n\n    See Also\n    --------\n    landweber\n    \"\"\"\n    domain = ops[0].domain\n    if any(domain != opi.domain for opi in ops):\n        raise ValueError('domains of `ops` are not all equal')\n\n    if x not in domain:\n        raise TypeError('`x` {!r} is not in the domain of `ops` {!r}'\n                        ''.format(x, domain))\n\n    if len(ops) != len(rhs):\n        raise ValueError('`number of `ops` {} does not match number of '\n                         '`rhs` {}'.format(len(ops), len(rhs)))\n\n    omega = normalized_scalar_param_list(omega, len(ops), param_conv=float)\n\n    # Reusable elements in the range, one per type of space\n    ranges = [opi.range for opi in ops]\n    unique_ranges = set(ranges)\n    tmp_rans = {ran: ran.element() for ran in unique_ranges}\n\n    # Single reusable element in the domain\n    tmp_dom = domain.element()\n\n    # Iteratively find solution\n    for _ in range(niter):\n        if random:\n            rng = np.random.permutation(range(len(ops)))\n        else:\n            rng = range(len(ops))\n\n        for i in rng:\n            # Find residual\n            tmp_ran = tmp_rans[ops[i].range]\n            ops[i](x, out=tmp_ran)\n            tmp_ran -= rhs[i]\n\n            # Update x\n            ops[i].derivative(x).adjoint(tmp_ran, out=tmp_dom)\n            x.lincomb(1, x, -omega[i], tmp_dom)\n\n            if projection is not None:\n                projection(x)\n\n            if callback is not None and callback_loop == 'inner':\n                callback(x)\n        if callback is not None and callback_loop == 'outer':\n            callback(x)", "response": "r Returns a new set of kaczmarz equations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting the correct corresponding tensor space.", "response": "def tspace_type(space, impl, dtype=None):\n    \"\"\"Select the correct corresponding tensor space.\n\n    Parameters\n    ----------\n    space : `LinearSpace`\n        Template space from which to infer an adequate tensor space. If\n        it has a ``field`` attribute, ``dtype`` must be consistent with it.\n    impl : string\n        Implementation backend for the tensor space.\n    dtype : optional\n        Data type which the space is supposed to use. If ``None`` is\n        given, the space type is purely determined from ``space`` and\n        ``impl``. Otherwise, it must be compatible with the\n        field of ``space``.\n\n    Returns\n    -------\n    stype : type\n        Space type selected after the space's field, the backend and\n        the data type.\n    \"\"\"\n    field_type = type(getattr(space, 'field', None))\n\n    if dtype is None:\n        pass\n    elif is_real_floating_dtype(dtype):\n        if field_type is None or field_type == ComplexNumbers:\n            raise TypeError('real floating data type {!r} requires space '\n                            'field to be of type RealNumbers, got {}'\n                            ''.format(dtype, field_type))\n    elif is_complex_floating_dtype(dtype):\n        if field_type is None or field_type == RealNumbers:\n            raise TypeError('complex floating data type {!r} requires space '\n                            'field to be of type ComplexNumbers, got {!r}'\n                            ''.format(dtype, field_type))\n    elif is_numeric_dtype(dtype):\n        if field_type == ComplexNumbers:\n            raise TypeError('non-floating data type {!r} requires space field '\n                            'to be of type RealNumbers, got {!r}'\n                            .format(dtype, field_type))\n\n    try:\n        return tensor_space_impl(impl)\n    except ValueError:\n        raise NotImplementedError('no corresponding tensor space available '\n                                  'for space {!r} and implementation {!r}'\n                                  ''.format(space, impl))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element(self, inp=None, order=None, **kwargs):\n        if inp is None:\n            return self.element_type(self, self.tspace.element(order=order))\n        elif inp in self and order is None:\n            return inp\n        elif callable(inp):\n            sampled = self.sampling(inp, **kwargs)\n            return self.element_type(self,\n                                     self.tspace.element(sampled, order=order))\n        else:\n            return self.element_type(self,\n                                     self.tspace.element(inp, order=order))", "response": "Create an element from inp or from scratch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _divide(self, x1, x2, out):\n        self.tspace._divide(x1.tensor, x2.tensor, out.tensor)", "response": "Raw pointwise multiplication of two elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef examples(self):\n        for name, elem in self.fspace.examples:\n            yield (name, self.element(elem))", "response": "Return example functions in the space."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef astype(self, dtype):\n        return self.space.astype(dtype).element(self.tensor.astype(dtype))", "response": "Return a copy of this element with new dtype."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sampling(self, ufunc, **kwargs):\n        self.space.sampling(ufunc, out=self.tensor, **kwargs)", "response": "Sample a continuous function and assign to this element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes a list of sampling points to an ndim - long list of linear index arrays.", "response": "def _normalize_sampling_points(sampling_points, ndim):\n    \"\"\"Normalize points to an ndim-long list of linear index arrays.\n\n    This helper converts sampling indices for `SamplingOperator` from\n    integers or array-like objects to a list of length ``ndim``, where\n    each entry is a `numpy.ndarray` with ``dtype=int``.\n    The function also checks if all arrays have equal lengths, and that\n    they fulfill ``array.ndim=1`` (or ``size=0`` for if ``ndim == 0``).\n\n    The result of this normalization is intended to be used for indexing\n    an ``ndim``-dimensional array at ``sampling_points`` via NumPy fancy\n    indexing, i.e., ``result = ndim_array[sampling_points]``.\n    \"\"\"\n    sampling_points_in = sampling_points\n    if ndim == 0:\n        sampling_points = [np.array(sampling_points, dtype=int, copy=False)]\n        if sampling_points[0].size != 0:\n            raise ValueError('`sampling_points` must be empty for '\n                             '0-dim. `domain`')\n    elif ndim == 1:\n        if isinstance(sampling_points, Integral):\n            sampling_points = (sampling_points,)\n        sampling_points = np.array(sampling_points, dtype=int, copy=False,\n                                   ndmin=1)\n\n        # Handle possible list of length one\n        if sampling_points.ndim == 2 and sampling_points.shape[0] == 1:\n            sampling_points = sampling_points[0]\n\n        sampling_points = [sampling_points]\n        if sampling_points[0].ndim > 1:\n            raise ValueError('expected 1D index (array), got {}'\n                             ''.format(sampling_points_in))\n    else:\n        try:\n            iter(sampling_points)\n        except TypeError:\n            raise TypeError('`sampling_points` must be a sequence '\n                            'for domain with ndim > 1')\n        else:\n            if np.ndim(sampling_points) == 1:\n                sampling_points = [np.array(p, dtype=int)\n                                   for p in sampling_points]\n            else:\n                sampling_points = [\n                    np.array(pts, dtype=int, copy=False, ndmin=1)\n                    for pts in sampling_points]\n                if any(pts.ndim != 1 for pts in sampling_points):\n                    raise ValueError(\n                        'index arrays in `sampling_points` must be 1D, '\n                        'got {!r}'.format(sampling_points_in))\n\n    return sampling_points"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_compatible_space(space, base_space):\n    if isinstance(base_space, ProductSpace):\n        return False\n\n    if isinstance(space, ProductSpace):\n        if not space.is_power_space:\n            return False\n        elif len(space) == 0:\n            return False\n        else:\n            return is_compatible_space(space[0], base_space)\n    else:\n        if hasattr(space, 'astype') and hasattr(base_space, 'dtype'):\n            # TODO: maybe only the shape should play a role?\n            comp_space = space.astype(base_space.dtype)\n        else:\n            comp_space = space\n\n        return comp_space == base_space", "response": "Check compatibility of a space with a base space."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements self f and out.", "response": "def _call(self, f, out):\n        \"\"\"Implement ``self(f, out)``.\"\"\"\n        if self.exponent == 1.0:\n            self._call_vecfield_1(f, out)\n        elif self.exponent == float('inf'):\n            self._call_vecfield_inf(f, out)\n        else:\n            self._call_vecfield_p(f, out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimplementing self for exponent 1.", "response": "def _call_vecfield_1(self, vf, out):\n        \"\"\"Implement ``self(vf, out)`` for exponent 1.\"\"\"\n        vf[0].ufuncs.absolute(out=out)\n        if self.is_weighted:\n            out *= self.weights[0]\n\n        if len(self.domain) == 1:\n            return\n\n        tmp = self.range.element()\n        for fi, wi in zip(vf[1:], self.weights[1:]):\n            fi.ufuncs.absolute(out=tmp)\n            if self.is_weighted:\n                tmp *= wi\n            out += tmp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements self for exponent inf.", "response": "def _call_vecfield_inf(self, vf, out):\n        \"\"\"Implement ``self(vf, out)`` for exponent ``inf``.\"\"\"\n        vf[0].ufuncs.absolute(out=out)\n        if self.is_weighted:\n            out *= self.weights[0]\n\n        if len(self.domain) == 1:\n            return\n\n        tmp = self.range.element()\n        for vfi, wi in zip(vf[1:], self.weights[1:]):\n            vfi.ufuncs.absolute(out=tmp)\n            if self.is_weighted:\n                tmp *= wi\n            out.ufuncs.maximum(tmp, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement self for exponent 1 < p < inf.", "response": "def _call_vecfield_p(self, vf, out):\n        \"\"\"Implement ``self(vf, out)`` for exponent 1 < p < ``inf``.\"\"\"\n        # Optimization for 1 component - just absolute value (maybe weighted)\n        if len(self.domain) == 1:\n            vf[0].ufuncs.absolute(out=out)\n            if self.is_weighted:\n                out *= self.weights[0] ** (1 / self.exponent)\n            return\n\n        # Initialize out, avoiding one copy\n        self._abs_pow_ufunc(vf[0], out=out, p=self.exponent)\n        if self.is_weighted:\n            out *= self.weights[0]\n\n        tmp = self.range.element()\n        for fi, wi in zip(vf[1:], self.weights[1:]):\n            self._abs_pow_ufunc(fi, out=tmp, p=self.exponent)\n            if self.is_weighted:\n                tmp *= wi\n            out += tmp\n\n        self._abs_pow_ufunc(out, out=out, p=(1 / self.exponent))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _abs_pow_ufunc(self, fi, out, p):\n        # Optimization for very common cases\n        if p == 0.5:\n            fi.ufuncs.absolute(out=out)\n            out.ufuncs.sqrt(out=out)\n        elif p == 2.0 and self.base_space.field == RealNumbers():\n            fi.multiply(fi, out=out)\n        else:\n            fi.ufuncs.absolute(out=out)\n            out.ufuncs.power(p, out=out)", "response": "Compute |F_i x |^p point - wise and write to out."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef derivative(self, vf):\n        if self.domain.field == ComplexNumbers():\n            raise NotImplementedError('operator not Frechet-differentiable '\n                                      'on a complex space')\n\n        if self.exponent == float('inf'):\n            raise NotImplementedError('operator not Frechet-differentiable '\n                                      'for exponent = inf')\n\n        vf = self.domain.element(vf)\n        vf_pwnorm_fac = self(vf)\n        if self.exponent != 2:  # optimize away most common case.\n            vf_pwnorm_fac **= (self.exponent - 1)\n\n        inner_vf = vf.copy()\n\n        for gi in inner_vf:\n            gi *= gi.ufuncs.absolute().ufuncs.power(self.exponent - 2)\n            if self.exponent >= 2:\n                # Any component that is zero is not divided with\n                nz = (vf_pwnorm_fac.asarray() != 0)\n                gi[nz] /= vf_pwnorm_fac[nz]\n            else:\n                # For exponents < 2 there will be a singularity if any\n                # component is zero. This results in inf or nan. See the\n                # documentation for further details.\n                gi /= vf_pwnorm_fac\n\n        return PointwiseInner(self.domain, inner_vf, weighting=self.weights)", "response": "Returns the derivative of the point - wise norm operator at the given vector field."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimplements self ( vf out ).", "response": "def _call(self, vf, out):\n        \"\"\"Implement ``self(vf, out)``.\"\"\"\n        if self.domain.field == ComplexNumbers():\n            vf[0].multiply(self._vecfield[0].conj(), out=out)\n        else:\n            vf[0].multiply(self._vecfield[0], out=out)\n\n        if self.is_weighted:\n            out *= self.weights[0]\n\n        if len(self.domain) == 1:\n            return\n\n        tmp = self.range.element()\n        for vfi, gi, wi in zip(vf[1:], self.vecfield[1:],\n                               self.weights[1:]):\n\n            if self.domain.field == ComplexNumbers():\n                vfi.multiply(gi.conj(), out=tmp)\n            else:\n                vfi.multiply(gi, out=tmp)\n\n            if self.is_weighted:\n                tmp *= wi\n            out += tmp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adjoint(self):\n        return PointwiseInnerAdjoint(\n            sspace=self.base_space, vecfield=self.vecfield,\n            vfspace=self.domain, weighting=self.weights)", "response": "Adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjoint(self):\n        return PointwiseInner(vfspace=self.range, vecfield=self.vecfield,\n                              weighting=self.weights)", "response": "Adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adjoint(self):\n        return MatrixOperator(self.matrix.conj().T,\n                              domain=self.range, range=self.domain,\n                              axis=self.axis)", "response": "Returns an adjoint matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inverse(self):\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        if scipy.sparse.isspmatrix(self.matrix):\n            dense_matrix = self.matrix.toarray()\n        else:\n            dense_matrix = self.matrix\n\n        return MatrixOperator(np.linalg.inv(dense_matrix),\n                              domain=self.range, range=self.domain,\n                              axis=self.axis)", "response": "Inverse operator represented by the inverse matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the dot product of the internal state matrix and the internal state of the internal state.", "response": "def _call(self, x, out=None):\n        \"\"\"Return ``self(x[, out])``.\"\"\"\n        # Lazy import to improve `import odl` time\n        import scipy.sparse\n\n        if out is None:\n            if scipy.sparse.isspmatrix(self.matrix):\n                out = self.matrix.dot(x)\n            else:\n                dot = np.tensordot(self.matrix, x, axes=(1, self.axis))\n                # New axis ends up as first, need to swap it to its place\n                out = moveaxis(dot, 0, self.axis)\n        else:\n            if scipy.sparse.isspmatrix(self.matrix):\n                # Unfortunately, there is no native in-place dot product for\n                # sparse matrices\n                out[:] = self.matrix.dot(x)\n            elif (parse_version(np.__version__) < parse_version('1.13.0') and\n                  x is out and\n                  self.range.ndim == 1):\n                # Workaround for bug in Numpy < 1.13 with aliased in and\n                # out in np.dot\n                out[:] = self.matrix.dot(x)\n            elif self.range.ndim == 1:\n                with writable_array(out) as out_arr:\n                    self.matrix.dot(x, out=out_arr)\n            else:\n                # Could use einsum to have out, but it's damn slow\n                # TODO: investigate speed issue\n                dot = np.tensordot(self.matrix, x, axes=(1, self.axis))\n                # New axis ends up as first, need to move it to its place\n                out[:] = moveaxis(dot, 0, self.axis)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn values at indices possibly weighted.", "response": "def _call(self, x):\n        \"\"\"Return values at indices, possibly weighted.\"\"\"\n        out = x.asarray().ravel()[self._indices_flat]\n\n        if self.variant == 'point_eval':\n            weights = 1.0\n        elif self.variant == 'integrate':\n            weights = getattr(self.domain, 'cell_volume', 1.0)\n        else:\n            raise RuntimeError('bad variant {!r}'.format(self.variant))\n\n        if weights != 1.0:\n            out *= weights\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef adjoint(self):\n        if self.variant == 'point_eval':\n            variant = 'dirac'\n        elif self.variant == 'integrate':\n            variant = 'char_fun'\n        else:\n            raise RuntimeError('bad variant {!r}'.format(self.variant))\n\n        return WeightedSumSamplingOperator(self.domain, self.sampling_points,\n                                           variant)", "response": "Adjoint of the sampling operator a WeightedSumSamplingOperator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call(self, x):\n        y = np.bincount(self._indices_flat, weights=x,\n                        minlength=self.range.size)\n\n        out = y.reshape(self.range.shape)\n\n        if self.variant == 'dirac':\n            weights = getattr(self.range, 'cell_volume', 1.0)\n        elif self.variant == 'char_fun':\n            weights = 1.0\n        else:\n            raise RuntimeError('The variant \"{!r}\" is not yet supported'\n                               ''.format(self.variant))\n\n        if weights != 1.0:\n            out /= weights\n\n        return out", "response": "Sum all values if indices are given multiple times."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adjoint(self):\n        if self.variant == 'dirac':\n            variant = 'point_eval'\n        elif self.variant == 'char_fun':\n            variant = 'integrate'\n        else:\n            raise RuntimeError('The variant \"{!r}\" is not yet supported'\n                               ''.format(self.variant))\n\n        return SamplingOperator(self.range, self.sampling_points, variant)", "response": "Adjoint of this operator and a SamplingOperator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a minimal MRC2014 header from the given parameters.", "response": "def mrc_header_from_params(shape, dtype, kind, **kwargs):\n    \"\"\"Create a minimal MRC2014 header from the given parameters.\n\n    Parameters\n    ----------\n    shape : 3-sequence of ints\n        3D shape of the stored data. The values are used as\n        ``'nx', 'ny', 'nz'`` header entries, in this order. Note that\n        this is different from the actual data storage shape for\n        non-trivial ``axis_order``.\n    dtype : {'int8', 'int16', 'float32', 'uint16'}\n        Data type specifier as understood by `numpy.dtype`. It is\n        translated to a ``'mode'`` header entry. See `this page\n        <http://www.ccpem.ac.uk/mrc_format/mrc2014.php>`_ for valid\n        modes.\n    kind : {'volume', 'projections'}\n        Interpretation of the 3D data, either as single 3D volume or as\n        a stack of 2D projections. The value is used for the ``'ispg'``\n        header entry.\n    extent : 3-sequence of floats, optional\n        Size of the 3D volume in meters. The values are used for\n        the ``'cella'`` header entry.\n        Default: ``shape``, resulting in ``(1, 1, 1)`` unit cells\n    axis_order : permutation of ``(0, 1, 2)`` optional\n        Order of the data axes as they should appear in the stored file.\n        The values are used for the ``'mapc', 'mapr', 'maps'`` header\n        entries.\n        Default: ``(0, 1, 2)``\n    dmin, dmax : float, optional\n        Minimum and maximum values of the data, used for header entries\n        ``'dmin'`` and ``'dmax'``, resp.\n        Default: 1.0, 0.0. These values indicate according to [Che+2015]\n        that the values are considered as undetermined.\n    dmean, rms : float, optional\n        Mean and variance of the data, used for header entries ``'dmean'``\n        and ``'rms'``, resp.\n        Default: ``min(dmin, dmax) - 1, -1.0``. These values indicate\n        according to [Che+2015] that the values are considered as\n        undetermined.\n    mrc_version : 2-tuple of int, optional\n        Version identifier for the MRC file, used for the ``'nversion'``\n        header entry.\n        Default: ``(2014, 0)``\n    text_labels : sequence of strings, optional\n        Maximal 10 strings with 80 characters each, used for the\n        ``'nlabl'`` and ``'label'`` header entries.\n        Default: ``[]``\n\n    Returns\n    -------\n    header : `OrderedDict`\n        Header stored in an ordered dictionary, where each entry has the\n        following form::\n\n            'name': {'value': value_as_array,\n                     'offset': offset_in_bytes\n                     'description': description_string}\n\n        All ``'value'``'s are `numpy.ndarray`'s with at least one\n        dimension.\n\n    References\n    ----------\n    [Che+2015] Cheng, A et al. *MRC2014: Extensions to the MRC format header\n    for electron cryo-microscopy and tomography*. Journal of Structural\n    Biology, 129 (2015), pp 146--150.\n    \"\"\"\n    # Positional args\n    shape = [int(n) for n in shape]\n    kind, kind_in = str(kind).lower(), kind\n    if kind not in ('volume', 'projections'):\n        raise ValueError(\"`kind '{}' not understood\".format(kind_in))\n\n    # Keyword args\n    extent = kwargs.pop('extent', shape)\n    axis_order = kwargs.pop('axis_order', (0, 1, 2))\n    if tuple(axis_order) not in permutations((0, 1, 2)):\n        raise ValueError('`axis_order` must be a permutation of (0, 1, 2), '\n                         'got {}'.format(axis_order))\n    dmin = kwargs.pop('dmin', 1.0)\n    dmax = kwargs.pop('dmax', 0.0)\n    dmean = kwargs.pop('dmean', min(dmin, dmax) - 1.0)\n    rms = kwargs.pop('rms', -1.0)\n    mrc_version = kwargs.pop('mrc_version', (2014, 0))\n    if len(mrc_version) != 2:\n        raise ValueError('`mrc_version` must be a sequence of length 2, got '\n                         '{}'.format(mrc_version))\n\n    # Text labels: fill each label up with whitespace to 80 characters.\n    # Create the remaining labels as 80 * '\\x00'\n    text_labels_in = kwargs.pop('text_labels', [])\n    nlabl = len(text_labels_in)\n    if nlabl > 10:\n        raise ValueError('expexted maximum of 10 labels, got {} labels'\n                         ''.format(nlabl))\n    text_labels = [str(label).ljust(80) for label in text_labels_in]\n    if any(len(label) > 80 for label in text_labels):\n        raise ValueError('labels cannot have more than 80 characters each')\n\n    # Convert to header-friendly form. Names are required to match\n    # exactly the header field names, and all of them must exist,\n    # so that `eval` below succeeds for all fields.\n    nx, ny, nz = [np.array(n, dtype='int32').reshape([1]) for n in shape]\n    mode = np.array(NPY_DTYPE_TO_MRC_MODE[np.dtype(dtype)],\n                    dtype='int32').reshape([1])\n    mx, my, mz = nx, ny, nz\n    cella = np.array(extent).reshape([3]).astype('float32')\n    mapc, mapr, maps = [np.array(m, dtype='int32').reshape([1]) + 1\n                        for m in axis_order]\n    dmin, dmax, dmean, rms = [np.array(x, dtype='float32').reshape([1])\n                              for x in (dmin, dmax, dmean, rms)]\n    ispg = 1 if kind == 'volume' else 0\n    ispg = np.array(ispg, dtype='int32', ndmin=1)\n    nsymbt = np.array([0], dtype='int32')\n    exttype = np.fromstring('    ', dtype='S1')\n    nversion = np.array(10 * mrc_version[0] + mrc_version[1],\n                        dtype='int32').reshape([1])\n    origin = np.zeros(3, dtype='int32')\n    map = np.fromstring('MAP ', dtype='S1')\n    # TODO: no idea how to properly choose the machine stamp\n    machst = np.fromiter(b'DD  ', dtype='S1')\n    nlabl = np.array(nlabl, dtype='int32').reshape([1])\n    label = np.zeros((10, 80), dtype='S1')  # ensure correct size\n    for i, label_i in enumerate(text_labels):\n        label[i] = np.fromstring(label_i, dtype='S1')\n\n    # Make the header\n    # We use again the specification to set the values\n    header_fields = header_fields_from_table(\n        MRC_2014_SPEC_TABLE, MRC_SPEC_KEYS, MRC_DTYPE_TO_NPY_DTYPE)\n\n    header = OrderedDict()\n    for field in header_fields:\n        header[field['name']] = {'offset': field['offset'],\n                                 'value': eval(field['name'])}\n\n    return header"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntotal size of the file s header including extended header in bytes.", "response": "def header_size(self):\n        \"\"\"Total size of `file`'s header (including extended) in bytes.\n\n        The size of the header is determined from `header`. If this is not\n        possible (i.e., before the header has been read), 0 is returned.\n\n        If the header contains an ``'nsymbt'`` entry (size of the extra\n        header in bytes), its value is added to the regular header size.\n        \"\"\"\n        standard_header_size = MRC_HEADER_SIZE\n\n        try:\n            extra_header_size = int(self.header['nsymbt']['value'])\n        except KeyError:\n            extra_header_size = 0\n\n        return standard_header_size + extra_header_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_shape(self):\n        if not self.header:\n            return -1\n        try:\n            nx = self.header['nx']['value']\n            ny = self.header['ny']['value']\n            nz = self.header['nz']['value']\n        except KeyError:\n            return -1\n        else:\n            return tuple(int(n) for n in (nx, ny, nz))", "response": "Shape tuple of the whole data block as determined from header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshape tuple of the data stored in the file.", "response": "def data_storage_shape(self):\n        \"\"\"Shape tuple of the data as stored in the file.\n\n        If no header is available (i.e., before it has been initialized),\n        or any of the header entries ``'nx', 'ny', 'nz'`` is missing,\n        -1 is returned, which makes reshaping a no-op.\n        Otherwise, the returned shape is a permutation of `data_shape`,\n        i.e., ``(nx, ny, nz)``, according to `data_axis_order` in the\n        following way::\n\n            data_shape[i] == data_storage_shape[data_axis_order[i]]\n\n        See Also\n        --------\n        data_shape\n        data_axis_order\n        \"\"\"\n        if self.data_shape == -1:\n            return -1\n        else:\n            return tuple(self.data_shape[ax]\n                         for ax in np.argsort(self.data_axis_order))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef data_dtype(self):\n        if not self.header:\n            return self._init_data_dtype\n        try:\n            mode = int(self.header['mode']['value'])\n        except KeyError:\n            return self._init_data_dtype\n        else:\n            try:\n                return MRC_MODE_TO_NPY_DTYPE[mode]\n            except KeyError:\n                raise ValueError('data mode {} not supported'.format(mode))", "response": "Return the data type of the data block as determined from the header entry mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data_axis_order(self):\n        if not self.header:\n            return (0, 1, 2)\n        try:\n            mapc = self.header['mapc']['value']\n            mapr = self.header['mapr']['value']\n            maps = self.header['maps']['value']\n        except KeyError:\n            return (0, 1, 2)\n        else:\n            axis_order = tuple(int(m) - 1 for m in [mapc, mapr, maps])\n            if (sorted(axis_order) != [0, 1, 2]):\n                # Ignore invalid entries in the header, e.g. 0, 0, 0.\n                # Some MRC files out there are like that.\n                warnings.warn('invalid axis mapping {}, using (0, 1, 2)'\n                              ''.format(tuple(m + 1 for m in axis_order)),\n                              RuntimeWarning)\n                axis_order = (0, 1, 2)\n            return axis_order", "response": "Returns the permutation of the axes of the data in the file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cell_sides_angstrom(self):\n        return np.asarray(\n            self.header['cella']['value'], dtype=float) / self.data_shape", "response": "Array of sizes of a unit cell in Angstroms."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef labels(self):\n        label_array = self.header['label']['value']\n        labels = tuple(''.join(row.astype(str)) for row in label_array)\n\n        try:\n            nlabels = int(self.header['nlabl']['value'])\n        except KeyError:\n            nlabels = len(labels)\n\n        # Check if there are nontrivial labels after the number given in\n        # the header. If yes, ignore the 'nlabl' information and return\n        # all labels.\n        if any(label.strip() for label in labels[nlabels:]):\n            return labels\n        else:\n            return labels[:nlabels]", "response": "Return the 10 - tuple of text labels from header."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the extended header according to extended_header_type.", "response": "def read_extended_header(self, groupby='field', force_type=''):\n        \"\"\"Read the extended header according to `extended_header_type`.\n\n        Currently, only the FEI extended header format is supported.\n        See `print_fei_ext_header_spec` or `this homepage`_ for the format\n        specification.\n\n        The extended header usually has one header section per\n        image (slice), in case of the FEI header 128 bytes each, with\n        a total of 1024 sections.\n\n        Parameters\n        ----------\n        groupby : {'field', 'section'}, optional\n            How to group the values in the extended header sections.\n\n            ``'field'`` : make an array per section field, e.g.::\n\n                'defocus': [dval1, dval2, ..., dval1024],\n                'exp_time': [tval1, tval2, ..., tval1024],\n                ...\n\n            ``'section'`` : make a dictionary for each section, e.g.::\n\n                {'defocus': dval1, 'exp_time': tval1},\n                {'defocus': dval2, 'exp_time': tval2},\n                ...\n\n            If the number of images is smaller than 1024, the last values are\n            all set to zero.\n\n        force_type : string, optional\n            If given, this value overrides the `extended_header_type`\n            from `header`.\n\n            Currently supported: ``'FEI1'``\n\n        Returns\n        -------\n        ext_header: `OrderedDict` or tuple\n            For ``groupby == 'field'``, a dictionary with the field names\n            as keys, like in the example.\n            For ``groupby == 'section'``, a tuple of dictionaries as\n            shown above.\n            The returned data structures store no offsets, in contrast\n            to the regular header.\n\n        See Also\n        --------\n\n        References\n        ----------\n        .. _this homepage:\n           http://www.2dx.unibas.ch/documentation/mrc-software/fei-\\\nextended-mrc-format-not-used-by-2dx\n        \"\"\"\n        ext_header_type = str(force_type).upper() or self.extended_header_type\n        if ext_header_type != 'FEI1':\n            raise ValueError(\"extended header type '{}' not supported\"\n                             \"\".format(self.extended_header_type))\n\n        groupby, groupby_in = str(groupby).lower(), groupby\n\n        ext_header_len = int(self.header['nsymbt']['value'])\n        if ext_header_len % MRC_FEI_SECTION_SIZE:\n            raise ValueError('extended header length {} from header is '\n                             'not divisible by extended header section size '\n                             '{}'.format(ext_header_len, MRC_FEI_SECTION_SIZE))\n\n        num_sections = ext_header_len // MRC_FEI_SECTION_SIZE\n        if num_sections != MRC_FEI_NUM_SECTIONS:\n            raise ValueError('calculated number of sections ({}) not equal to '\n                             'expected number of sections ({})'\n                             ''.format(num_sections, MRC_FEI_NUM_SECTIONS))\n\n        section_fields = header_fields_from_table(\n            MRC_FEI_EXT_HEADER_SECTION, keys=MRC_SPEC_KEYS,\n            dtype_map=MRC_DTYPE_TO_NPY_DTYPE)\n\n        # Make a list for each field and append the values for that\n        # field. Then create an array from that list and store it\n        # under the field name.\n        ext_header = OrderedDict()\n        for field in section_fields:\n            value_list = []\n            field_offset = field['offset']\n            field_dtype = field['dtype']\n            field_dshape = field['dshape']\n\n            # Compute some parameters\n            num_items = int(np.prod(field_dshape))\n            size_bytes = num_items * field_dtype.itemsize\n            fmt = '{}{}'.format(num_items, field_dtype.char)\n\n            for section in range(num_sections):\n                # Get the bytestring from the right position in the file,\n                # unpack it and append the value to the list.\n                start = section * MRC_FEI_SECTION_SIZE + field_offset\n                self.file.seek(start)\n                packed_value = self.file.read(size_bytes)\n                value_list.append(struct.unpack(fmt, packed_value))\n\n            ext_header[field['name']] = np.array(value_list, dtype=field_dtype)\n\n        if groupby == 'field':\n            return ext_header\n        elif groupby == 'section':\n            # Transpose the data and return as tuple.\n            return tuple({key: ext_header[key][i] for key in ext_header}\n                         for i in range(num_sections))\n        else:\n            raise ValueError(\"`groupby` '{}' not understood\"\n                             \"\".format(groupby_in))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the data from the MRC file and return it as Numpy array.", "response": "def read_data(self, dstart=None, dend=None, swap_axes=True):\n        \"\"\"Read the data from `file` and return it as Numpy array.\n\n        Parameters\n        ----------\n        dstart : int, optional\n            Offset in bytes of the data field. By default, it is equal\n            to ``header_size``. Backwards indexing with negative values\n            is also supported.\n            Use a value larger than the header size to extract a data subset.\n        dend : int, optional\n            End position in bytes until which data is read (exclusive).\n            Backwards indexing with negative values is also supported.\n            Use a value different from the file size to extract a data subset.\n        swap_axes : bool, optional\n            If ``True``, use `data_axis_order` to swap the axes in the\n            returned array. In that case, the shape of the array may no\n            longer agree with `data_storage_shape`.\n\n        Returns\n        -------\n        data : `numpy.ndarray`\n            The data read from `file`.\n        \"\"\"\n        data = super(FileReaderMRC, self).read_data(dstart, dend)\n        data = data.reshape(self.data_shape, order='F')\n        if swap_axes:\n            data = np.transpose(data, axes=self.data_axis_order)\n            assert data.shape == self.data_shape\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_data(self, data, dstart=None, swap_axes=True):\n        if dstart is None:\n            shape = self.data_shape\n            dstart = int(self.header_size)\n        elif dstart < 0:\n            raise ValueError('`dstart` must be non-negative, got {}'\n                             ''.format(dstart))\n        else:\n            shape = -1\n            dstart = int(dstart)\n\n        if dstart < self.header_size:\n            raise ValueError('invalid `dstart`, resulting in absolute '\n                             '`dstart` < `header_size` ({} < {})'\n                             ''.format(dstart, self.header_size))\n\n        data = np.asarray(data, dtype=self.data_dtype).reshape(shape)\n        if swap_axes:\n            # Need to argsort here since `data_axis_order` tells\n            # \"which axis comes from where\", which is the inverse of what the\n            # `transpose` function needs.\n            data = np.transpose(data, axes=np.argsort(self.data_axis_order))\n            assert data.shape == self.data_storage_shape\n\n        data = data.reshape(-1, order='F')\n        self.file.seek(dstart)\n        data.tofile(self.file)", "response": "Write data to the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreverts the effect of indentation.", "response": "def dedent(string, indent_str='   ', max_levels=None):\n    \"\"\"Revert the effect of indentation.\n\n    Examples\n    --------\n    Remove a simple one-level indentation:\n\n    >>> text = '''<->This is line 1.\n    ... <->Next line.\n    ... <->And another one.'''\n    >>> print(text)\n    <->This is line 1.\n    <->Next line.\n    <->And another one.\n    >>> print(dedent(text, '<->'))\n    This is line 1.\n    Next line.\n    And another one.\n\n    Multiple levels of indentation:\n\n    >>> text = '''<->Level 1.\n    ... <-><->Level 2.\n    ... <-><-><->Level 3.'''\n    >>> print(text)\n    <->Level 1.\n    <-><->Level 2.\n    <-><-><->Level 3.\n    >>> print(dedent(text, '<->'))\n    Level 1.\n    <->Level 2.\n    <-><->Level 3.\n\n    >>> text = '''<-><->Level 2.\n    ... <-><-><->Level 3.'''\n    >>> print(text)\n    <-><->Level 2.\n    <-><-><->Level 3.\n    >>> print(dedent(text, '<->'))\n    Level 2.\n    <->Level 3.\n    >>> print(dedent(text, '<->', max_levels=1))\n    <->Level 2.\n    <-><->Level 3.\n    \"\"\"\n    if len(indent_str) == 0:\n        return string\n\n    lines = string.splitlines()\n\n    # Determine common (minumum) number of indentation levels, capped at\n    # `max_levels` if given\n    def num_indents(line):\n        max_num = int(np.ceil(len(line) / len(indent_str)))\n\n        for i in range(max_num):\n            if line.startswith(indent_str):\n                line = line[len(indent_str):]\n            else:\n                break\n\n        return i\n\n    num_levels = num_indents(min(lines, key=num_indents))\n    if max_levels is not None:\n        num_levels = min(num_levels, max_levels)\n\n    # Dedent\n    dedent_len = num_levels * len(indent_str)\n    return '\\n'.join(line[dedent_len:] for line in lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dtype_repr(dtype):\n    dtype = np.dtype(dtype)\n    if dtype == np.dtype(int):\n        return \"'int'\"\n    elif dtype == np.dtype(float):\n        return \"'float'\"\n    elif dtype == np.dtype(complex):\n        return \"'complex'\"\n    elif dtype.shape:\n        return \"('{}', {})\".format(dtype.base, dtype.shape)\n    else:\n        return \"'{}'\".format(dtype)", "response": "Stringify dtype for repr with default for int and float."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if dtype is a numeric type.", "response": "def is_numeric_dtype(dtype):\n    \"\"\"Return ``True`` if ``dtype`` is a numeric type.\"\"\"\n    dtype = np.dtype(dtype)\n    return np.issubsctype(getattr(dtype, 'base', None), np.number)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_int_dtype(dtype):\n    dtype = np.dtype(dtype)\n    return np.issubsctype(getattr(dtype, 'base', None), np.integer)", "response": "Return True if dtype is an integer type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if dtype is a real floating point type.", "response": "def is_real_floating_dtype(dtype):\n    \"\"\"Return ``True`` if ``dtype`` is a real floating point type.\"\"\"\n    dtype = np.dtype(dtype)\n    return np.issubsctype(getattr(dtype, 'base', None), np.floating)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if dtype is a complex floating point type.", "response": "def is_complex_floating_dtype(dtype):\n    \"\"\"Return ``True`` if ``dtype`` is a complex floating point type.\"\"\"\n    dtype = np.dtype(dtype)\n    return np.issubsctype(getattr(dtype, 'base', None), np.complexfloating)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef real_dtype(dtype, default=None):\n    dtype, dtype_in = np.dtype(dtype), dtype\n\n    if is_real_floating_dtype(dtype):\n        return dtype\n\n    try:\n        real_base_dtype = TYPE_MAP_C2R[dtype.base]\n    except KeyError:\n        if default is not None:\n            return default\n        else:\n            raise ValueError('no real counterpart exists for `dtype` {}'\n                             ''.format(dtype_repr(dtype_in)))\n    else:\n        return np.dtype((real_base_dtype, dtype.shape))", "response": "Return the real counterpart of the given data type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef complex_dtype(dtype, default=None):\n    dtype, dtype_in = np.dtype(dtype), dtype\n\n    if is_complex_floating_dtype(dtype):\n        return dtype\n\n    try:\n        complex_base_dtype = TYPE_MAP_R2C[dtype.base]\n    except KeyError:\n        if default is not None:\n            return default\n        else:\n            raise ValueError('no complex counterpart exists for `dtype` {}'\n                             ''.format(dtype_repr(dtype_in)))\n    else:\n        return np.dtype((complex_base_dtype, dtype.shape))", "response": "Return a sequence of complex counterparts of the given data type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preload_first_arg(instance, mode):\n\n    def decorator(call):\n\n        @wraps(call)\n        def oop_wrapper(x, **kwargs):\n            return call(instance, x, **kwargs)\n\n        @wraps(call)\n        def ip_wrapper(x, out, **kwargs):\n            return call(instance, x, out, **kwargs)\n\n        if mode == 'out-of-place':\n            return oop_wrapper\n        elif mode == 'in-place':\n            return ip_wrapper\n        else:\n            raise ValueError('bad mode {!r}'.format(mode))\n\n    return decorator", "response": "Decorator to preload the first argument of a call method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a stringified version of the given arguments.", "response": "def signature_string(posargs, optargs, sep=', ', mod='!r'):\n    \"\"\"Return a stringified signature from given arguments.\n\n    Parameters\n    ----------\n    posargs : sequence\n        Positional argument values, always included in the returned string.\n        They appear in the string as (roughly)::\n\n            sep.join(str(arg) for arg in posargs)\n\n    optargs : sequence of 3-tuples\n        Optional arguments with names and defaults, given in the form::\n\n            [(name1, value1, default1), (name2, value2, default2), ...]\n\n        Only those parameters that are different from the given default\n        are included as ``name=value`` keyword pairs.\n\n        **Note:** The comparison is done by using ``if value == default:``,\n        which is not valid for, e.g., NumPy arrays.\n\n    sep : string or sequence of strings, optional\n        Separator(s) for the argument strings. A provided single string is\n        used for all joining operations.\n        A given sequence must have 3 entries ``pos_sep, opt_sep, part_sep``.\n        The ``pos_sep`` and ``opt_sep`` strings are used for joining the\n        respective sequences of argument strings, and ``part_sep`` joins\n        these two joined strings.\n    mod : string or callable or sequence, optional\n        Format modifier(s) for the argument strings.\n        In its most general form, ``mod`` is a sequence of 2 sequences\n        ``pos_mod, opt_mod`` with ``len(pos_mod) == len(posargs)`` and\n        ``len(opt_mod) == len(optargs)``. Each entry ``m`` in those sequences\n        can be eiter a string, resulting in the following stringification\n        of ``arg``::\n\n            arg_fmt = {{{}}}.format(m)\n            arg_str = arg_fmt.format(arg)\n\n        For a callable ``to_str``, the stringification is simply\n        ``arg_str = to_str(arg)``.\n\n        The entries ``pos_mod, opt_mod`` of ``mod`` can also be strings\n        or callables instead of sequences, in which case the modifier\n        applies to all corresponding arguments.\n\n        Finally, if ``mod`` is a string or callable, it is applied to\n        all arguments.\n\n        The default behavior is to apply the \"{!r}\" (``repr``) conversion.\n        For floating point scalars, the number of digits printed is\n        determined by the ``precision`` value in NumPy's printing options,\n        which can be temporarily modified with `npy_printoptions`.\n\n    Returns\n    -------\n    signature : string\n        Stringification of a signature, typically used in the form::\n\n            '{}({})'.format(self.__class__.__name__, signature)\n\n    Examples\n    --------\n    Usage with non-trivial entries in both sequences, with a typical\n    use case:\n\n    >>> posargs = [1, 'hello', None]\n    >>> optargs = [('dtype', 'float32', 'float64')]\n    >>> signature_string(posargs, optargs)\n    \"1, 'hello', None, dtype='float32'\"\n    >>> '{}({})'.format('MyClass', signature_string(posargs, optargs))\n    \"MyClass(1, 'hello', None, dtype='float32')\"\n\n    Empty sequences and optargs values equal to default are omitted:\n\n    >>> posargs = ['hello']\n    >>> optargs = [('size', 1, 1)]\n    >>> signature_string(posargs, optargs)\n    \"'hello'\"\n    >>> posargs = []\n    >>> optargs = [('size', 2, 1)]\n    >>> signature_string(posargs, optargs)\n    'size=2'\n    >>> posargs = []\n    >>> optargs = [('size', 1, 1)]\n    >>> signature_string(posargs, optargs)\n    ''\n\n    Using a different separator, globally or per argument \"category\":\n\n    >>> posargs = [1, 'hello', None]\n    >>> optargs = [('dtype', 'float32', 'float64'),\n    ...            ('order', 'F', 'C')]\n    >>> signature_string(posargs, optargs)\n    \"1, 'hello', None, dtype='float32', order='F'\"\n    >>> signature_string(posargs, optargs, sep=(',', ',', ', '))\n    \"1,'hello',None, dtype='float32',order='F'\"\n\n    Using format modifiers:\n\n    >>> posargs = ['hello', 2.345]\n    >>> optargs = [('extent', 1.442, 1.0), ('spacing', 0.0151, 1.0)]\n    >>> signature_string(posargs, optargs)\n    \"'hello', 2.345, extent=1.442, spacing=0.0151\"\n    >>> # Print only two significant digits for all arguments.\n    >>> # NOTE: this also affects the string!\n    >>> mod = ':.2'\n    >>> signature_string(posargs, optargs, mod=mod)\n    'he, 2.3, extent=1.4, spacing=0.015'\n    >>> mod = [['', ''], [':.3', ':.2']]  # one modifier per argument\n    >>> signature_string(posargs, optargs, mod=mod)\n    \"'hello', 2.345, extent=1.44, spacing=0.015\"\n\n    Using callables for stringification:\n\n    >>> posargs = ['arg1', np.ones(3)]\n    >>> optargs = []\n    >>> signature_string(posargs, optargs, mod=[['', array_str], []])\n    \"'arg1', [ 1., 1., 1.]\"\n\n    The number of printed digits in floating point numbers can be changed\n    with `npy_printoptions`:\n\n    >>> posargs = ['hello', 0.123456789012345]\n    >>> optargs = [('extent', 1.234567890123456, 1.0)]\n    >>> signature_string(posargs, optargs)  # default is 8 digits\n    \"'hello', 0.12345679, extent=1.2345679\"\n    >>> with npy_printoptions(precision=2):\n    ...     sig_str = signature_string(posargs, optargs)\n    >>> sig_str\n    \"'hello', 0.12, extent=1.2\"\n    \"\"\"\n    # Define the separators for the two possible cases\n    if is_string(sep):\n        pos_sep = opt_sep = part_sep = sep\n    else:\n        pos_sep, opt_sep, part_sep = sep\n\n    # Get the stringified parts\n    posargs_conv, optargs_conv = signature_string_parts(posargs, optargs, mod)\n\n    # Join the arguments using the separators\n    parts = []\n    if posargs_conv:\n        parts.append(pos_sep.join(argstr for argstr in posargs_conv))\n    if optargs_conv:\n        parts.append(opt_sep.join(optargs_conv))\n\n    return part_sep.join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of stringified arguments as tuples.", "response": "def signature_string_parts(posargs, optargs, mod='!r'):\n    \"\"\"Return stringified arguments as tuples.\n\n    Parameters\n    ----------\n    posargs : sequence\n        Positional argument values, always included in the returned string\n        tuple.\n    optargs : sequence of 3-tuples\n        Optional arguments with names and defaults, given in the form::\n\n            [(name1, value1, default1), (name2, value2, default2), ...]\n\n        Only those parameters that are different from the given default\n        are included as ``name=value`` keyword pairs.\n\n        **Note:** The comparison is done by using ``if value == default:``,\n        which is not valid for, e.g., NumPy arrays.\n\n    mod : string or callable or sequence, optional\n        Format modifier(s) for the argument strings.\n        In its most general form, ``mod`` is a sequence of 2 sequences\n        ``pos_mod, opt_mod`` with ``len(pos_mod) == len(posargs)`` and\n        ``len(opt_mod) == len(optargs)``. Each entry ``m`` in those sequences\n        can be a string, resulting in the following stringification\n        of ``arg``::\n\n            arg_fmt = {{{}}}.format(m)\n            arg_str = arg_fmt.format(arg)\n\n        For a callable ``to_str``, the stringification is simply\n        ``arg_str = to_str(arg)``.\n\n        The entries ``pos_mod, opt_mod`` of ``mod`` can also be strings\n        or callables instead of sequences, in which case the modifier\n        applies to all corresponding arguments.\n\n        Finally, if ``mod`` is a string or callable, it is applied to\n        all arguments.\n\n        The default behavior is to apply the \"{!r}\" (``repr``) conversion.\n        For floating point scalars, the number of digits printed is\n        determined by the ``precision`` value in NumPy's printing options,\n        which can be temporarily modified with `npy_printoptions`.\n\n    Returns\n    -------\n    pos_strings : tuple of str\n        The stringified positional arguments.\n    opt_strings : tuple of str\n        The stringified optional arguments, not including the ones\n        equal to their respective defaults.\n    \"\"\"\n    # Convert modifiers to 2-sequence of sequence of strings\n    if is_string(mod) or callable(mod):\n        pos_mod = opt_mod = mod\n    else:\n        pos_mod, opt_mod = mod\n\n    mods = []\n    for m, args in zip((pos_mod, opt_mod), (posargs, optargs)):\n        if is_string(m) or callable(m):\n            mods.append([m] * len(args))\n        else:\n            if len(m) == 1:\n                mods.append(m * len(args))\n            elif len(m) == len(args):\n                mods.append(m)\n            else:\n                raise ValueError('sequence length mismatch: '\n                                 'len({}) != len({})'.format(m, args))\n\n    pos_mod, opt_mod = mods\n    precision = np.get_printoptions()['precision']\n\n    # Stringify values, treating strings specially\n    posargs_conv = []\n    for arg, modifier in zip(posargs, pos_mod):\n        if callable(modifier):\n            posargs_conv.append(modifier(arg))\n        elif is_string(arg):\n            # Preserve single quotes for strings by default\n            if modifier:\n                fmt = '{{{}}}'.format(modifier)\n            else:\n                fmt = \"'{}'\"\n            posargs_conv.append(fmt.format(arg))\n        elif np.isscalar(arg) and str(arg) in ('inf', 'nan'):\n            # Make sure the string quotes are added\n            posargs_conv.append(\"'{}'\".format(arg))\n        elif (np.isscalar(arg) and\n              np.array(arg).real.astype('int64') != arg and\n              modifier in ('', '!s', '!r')):\n            # Floating point value, use Numpy print option 'precision'\n            fmt = '{{:.{}}}'.format(precision)\n            posargs_conv.append(fmt.format(arg))\n        else:\n            # All non-string types are passed through a format conversion\n            fmt = '{{{}}}'.format(modifier)\n            posargs_conv.append(fmt.format(arg))\n\n    # Build 'key=value' strings for values that are not equal to default\n    optargs_conv = []\n    for (name, value, default), modifier in zip(optargs, opt_mod):\n        if value == default:\n            # Don't include\n            continue\n\n        # See above on str and repr\n        if callable(modifier):\n            optargs_conv.append('{}={}'.format(name, modifier(value)))\n        elif is_string(value):\n            if modifier:\n                fmt = '{{{}}}'.format(modifier)\n            else:\n                fmt = \"'{}'\"\n            value_str = fmt.format(value)\n            optargs_conv.append('{}={}'.format(name, value_str))\n        elif np.isscalar(value) and str(value) in ('inf', 'nan'):\n            # Make sure the string quotes are added\n            optargs_conv.append(\"{}='{}'\".format(name, value))\n        elif (np.isscalar(value) and\n              np.array(value).real.astype('int64') != value and\n              modifier in ('', '!s', '!r')):\n            fmt = '{{:.{}}}'.format(precision)\n            value_str = fmt.format(value)\n            optargs_conv.append('{}={}'.format(name, value_str))\n        else:\n            fmt = '{{{}}}'.format(modifier)\n            value_str = fmt.format(value)\n            optargs_conv.append('{}={}'.format(name, value_str))\n\n    return tuple(posargs_conv), tuple(optargs_conv)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn separators that keep joined strings within the line width.", "response": "def _separators(strings, linewidth):\n    \"\"\"Return separators that keep joined strings within the line width.\"\"\"\n    if len(strings) <= 1:\n        return ()\n\n    indent_len = 4\n    separators = []\n    cur_line_len = indent_len + len(strings[0]) + 1\n    if cur_line_len + 2 <= linewidth and '\\n' not in strings[0]:\n        # Next string might fit on same line\n        separators.append(', ')\n        cur_line_len += 1  # for the extra space\n    else:\n        # Use linebreak if string contains newline or doesn't fit\n        separators.append(',\\n')\n        cur_line_len = indent_len\n\n    for i, s in enumerate(strings[1:-1]):\n        cur_line_len += len(s) + 1\n\n        if '\\n' in s:\n            # Use linebreak before and after if string contains newline\n            separators[i] = ',\\n'\n            cur_line_len = indent_len\n            separators.append(',\\n')\n\n        elif cur_line_len + 2 <= linewidth:\n            # This string fits, next one might also fit on same line\n            separators.append(', ')\n            cur_line_len += 1  # for the extra space\n\n        elif cur_line_len <= linewidth:\n            # This string fits, but next one won't\n            separators.append(',\\n')\n            cur_line_len = indent_len\n\n        else:\n            # This string doesn't fit but has no newlines in it\n            separators[i] = ',\\n'\n            cur_line_len = indent_len + len(s) + 1\n\n            # Need to determine again what should come next\n            if cur_line_len + 2 <= linewidth:\n                # Next string might fit on same line\n                separators.append(', ')\n            else:\n                separators.append(',\\n')\n\n    cur_line_len += len(strings[-1])\n    if cur_line_len + 1 > linewidth or '\\n' in strings[-1]:\n        # This string and a comma don't fit on this line\n        separators[-1] = ',\\n'\n\n    return tuple(separators)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repr_string(outer_string, inner_strings, allow_mixed_seps=True):\n    linewidth = np.get_printoptions()['linewidth']\n    pos_strings, opt_strings = inner_strings\n    # Length of the positional and optional argument parts of the signature,\n    # including separators `', '`\n    pos_sig_len = (sum(len(pstr) for pstr in pos_strings) +\n                   2 * max((len(pos_strings) - 1), 0))\n    opt_sig_len = (sum(len(pstr) for pstr in opt_strings) +\n                   2 * max((len(opt_strings) - 1), 0))\n\n    # Length of the one-line string, including 2 for the parentheses and\n    # 2 for the joining ', '\n    repr_len = len(outer_string) + 2 + pos_sig_len + 2 + opt_sig_len\n\n    if repr_len <= linewidth and not any('\\n' in s\n                                         for s in pos_strings + opt_strings):\n        # Everything fits on one line\n        fmt = '{}({})'\n        pos_str = ', '.join(pos_strings)\n        opt_str = ', '.join(opt_strings)\n        parts_sep = ', '\n    else:\n        # Need to split lines in some way\n        fmt = '{}(\\n{}\\n)'\n\n        if not allow_mixed_seps:\n            pos_separators = [',\\n'] * (len(pos_strings) - 1)\n        else:\n            pos_separators = _separators(pos_strings, linewidth)\n        if len(pos_strings) == 0:\n            pos_str = ''\n        else:\n            pos_str = pos_strings[0]\n            for s, sep in zip(pos_strings[1:], pos_separators):\n                pos_str = sep.join([pos_str, s])\n\n        if not allow_mixed_seps:\n            opt_separators = [',\\n'] * (len(opt_strings) - 1)\n        else:\n            opt_separators = _separators(opt_strings, linewidth)\n        if len(opt_strings) == 0:\n            opt_str = ''\n        else:\n            opt_str = opt_strings[0]\n            for s, sep in zip(opt_strings[1:], opt_separators):\n                opt_str = sep.join([opt_str, s])\n\n        # Check if we can put both parts on one line. This requires their\n        # concatenation including 4 for indentation and 2 for ', ' to\n        # be less than the line width. And they should contain no newline.\n        if pos_str and opt_str:\n            inner_len = 4 + len(pos_str) + 2 + len(opt_str)\n        elif (pos_str and not opt_str) or (opt_str and not pos_str):\n            inner_len = 4 + len(pos_str) + len(opt_str)\n        else:\n            inner_len = 0\n\n        if (not allow_mixed_seps or\n                any('\\n' in s for s in [pos_str, opt_str]) or\n                inner_len > linewidth):\n            parts_sep = ',\\n'\n            pos_str = indent(pos_str)\n            opt_str = indent(opt_str)\n        else:\n            parts_sep = ', '\n            pos_str = indent(pos_str)\n            # Don't indent `opt_str`\n\n    parts = [s for s in [pos_str, opt_str] if s.strip()]  # ignore empty\n    inner_string = parts_sep.join(parts)\n    return fmt.format(outer_string, inner_string)", "response": "r Return a pretty string for a base class or function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attribute_repr_string(inst_str, attr_str):\n    linewidth = np.get_printoptions()['linewidth']\n    if (len(inst_str) + 1 + len(attr_str) <= linewidth or\n            '(' not in inst_str):\n        # Instance string + dot + attribute string fit in one line or\n        # no parentheses -> keep instance string as-is and append attr string\n        parts = [inst_str, attr_str]\n    else:\n        # TODO(kohr-h): use `maxsplit=1` kwarg, not supported in Py 2\n        left, rest = inst_str.split('(', 1)\n        right, middle = rest[::-1].split(')', 1)\n        middle, right = middle[::-1], right[::-1]\n\n        if middle.startswith('\\n') and middle.endswith('\\n'):\n            # Already on multiple lines\n            new_inst_str = inst_str\n        else:\n            init_parts = [left]\n            if middle:\n                init_parts.append(indent(middle))\n            new_inst_str = '(\\n'.join(init_parts) + '\\n)' + right\n        parts = [new_inst_str, attr_str]\n\n    return '.'.join(parts)", "response": "Return a repr string for an attribute that respects line width."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef method_repr_string(inst_str, meth_str, arg_strs=None,\n                       allow_mixed_seps=True):\n    r\"\"\"Return a repr string for a method that respects line width.\n\n    This function is useful to generate a ``repr`` string for a derived\n    class that is created through a method, for instance ::\n\n        functional.translated(x)\n\n    as a better way of representing ::\n\n        FunctionalTranslation(functional, x)\n\n    Parameters\n    ----------\n    inst_str : str\n        Stringification of a class instance.\n    meth_str : str\n        Name of the method (not including the ``'.'``).\n    arg_strs : sequence of str, optional\n        Stringification of the arguments to the method.\n    allow_mixed_seps : bool, optional\n        If ``False`` and the argument strings do not fit on one line, use\n        ``',\\n'`` to separate all strings.\n        By default, a mixture of ``', '`` and ``',\\n'`` is used to fit\n        as much on one line as possible.\n\n        In case some of the ``arg_strs`` span multiple lines, it is\n        usually advisable to set ``allow_mixed_seps`` to ``False`` since\n        the result tends to be more readable that way.\n\n    Returns\n    -------\n    meth_repr_str : str\n        Concatenation of all strings in a way that the line width\n        is respected.\n\n    Examples\n    --------\n    >>> inst_str = 'MyClass'\n    >>> meth_str = 'empty'\n    >>> arg_strs = []\n    >>> print(method_repr_string(inst_str, meth_str, arg_strs))\n    MyClass.empty()\n    >>> inst_str = 'MyClass'\n    >>> meth_str = 'fromfile'\n    >>> arg_strs = [\"'tmpfile.txt'\"]\n    >>> print(method_repr_string(inst_str, meth_str, arg_strs))\n    MyClass.fromfile('tmpfile.txt')\n    >>> inst_str = \"MyClass('init string')\"\n    >>> meth_str = 'method'\n    >>> arg_strs = ['2.0']\n    >>> print(method_repr_string(inst_str, meth_str, arg_strs))\n    MyClass('init string').method(2.0)\n    >>> long_inst_str = (\n    ...     \"MyClass('long string that will definitely trigger a line break')\"\n    ... )\n    >>> meth_str = 'method'\n    >>> long_arg1 = \"'long argument string that should come on the next line'\"\n    >>> arg2 = 'param1=1'\n    >>> arg3 = 'param2=2.0'\n    >>> arg_strs = [long_arg1, arg2, arg3]\n    >>> print(method_repr_string(long_inst_str, meth_str, arg_strs))\n    MyClass(\n        'long string that will definitely trigger a line break'\n    ).method(\n        'long argument string that should come on the next line',\n        param1=1, param2=2.0\n    )\n    >>> print(method_repr_string(long_inst_str, meth_str, arg_strs,\n    ...                          allow_mixed_seps=False))\n    MyClass(\n        'long string that will definitely trigger a line break'\n    ).method(\n        'long argument string that should come on the next line',\n        param1=1,\n        param2=2.0\n    )\n    \"\"\"\n    linewidth = np.get_printoptions()['linewidth']\n\n    # Part up to the method name\n    if (len(inst_str) + 1 + len(meth_str) + 1 <= linewidth or\n            '(' not in inst_str):\n        init_parts = [inst_str, meth_str]\n        # Length of the line to the end of the method name\n        meth_line_start_len = len(inst_str) + 1 + len(meth_str)\n    else:\n        # TODO(kohr-h): use `maxsplit=1` kwarg, not supported in Py 2\n        left, rest = inst_str.split('(', 1)\n        right, middle = rest[::-1].split(')', 1)\n        middle, right = middle[::-1], right[::-1]\n        if middle.startswith('\\n') and middle.endswith('\\n'):\n            # Already on multiple lines\n            new_inst_str = inst_str\n        else:\n            new_inst_str = '(\\n'.join([left, indent(middle)]) + '\\n)' + right\n\n        # Length of the line to the end of the method name, consisting of\n        # ')' + '.' + <method name>\n        meth_line_start_len = 1 + 1 + len(meth_str)\n        init_parts = [new_inst_str, meth_str]\n\n    # Method call part\n    arg_str_oneline = ', '.join(arg_strs)\n    if meth_line_start_len + 1 + len(arg_str_oneline) + 1 <= linewidth:\n        meth_call_str = '(' + arg_str_oneline + ')'\n    elif not arg_str_oneline:\n        meth_call_str = '(\\n)'\n    else:\n        if allow_mixed_seps:\n            arg_seps = _separators(arg_strs, linewidth - 4)  # indented\n        else:\n            arg_seps = [',\\n'] * (len(arg_strs) - 1)\n\n        full_arg_str = ''\n        for arg_str, sep in zip_longest(arg_strs, arg_seps, fillvalue=''):\n            full_arg_str += arg_str + sep\n\n        meth_call_str = '(\\n' + indent(full_arg_str) + '\\n)'\n\n    return '.'.join(init_parts) + meth_call_str", "response": "r Return a repr string for a method that respects line width."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pkg_supports(feature, pkg_version, pkg_feat_dict):\n    from pkg_resources import parse_requirements\n\n    feature = str(feature)\n    pkg_version = str(pkg_version)\n    supp_versions = pkg_feat_dict.get(feature, None)\n    if supp_versions is None:\n        return False\n\n    # Make sequence from single string\n    if is_string(supp_versions):\n        supp_versions = [supp_versions]\n\n    # Make valid package requirements\n    ver_specs = ['pkg' + supp_ver for supp_ver in supp_versions]\n    # Each parse_requirements list contains only one entry since we specify\n    # only one package\n    ver_reqs = [list(parse_requirements(ver_spec))[0]\n                for ver_spec in ver_specs]\n\n    # If one of the requirements in the list is met, return True\n    for req in ver_reqs:\n        if req.specifier.contains(pkg_version, prereleases=True):\n            return True\n\n    # No match\n    return False", "response": "Return True if a package supports feature."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the unique values in a sequence.", "response": "def unique(seq):\n    \"\"\"Return the unique values in a sequence.\n\n    Parameters\n    ----------\n    seq : sequence\n        Sequence with (possibly duplicate) elements.\n\n    Returns\n    -------\n    unique : list\n        Unique elements of ``seq``.\n        Order is guaranteed to be the same as in seq.\n\n    Examples\n    --------\n    Determine unique elements in list\n\n    >>> unique([1, 2, 3, 3])\n    [1, 2, 3]\n\n    >>> unique((1, 'str', 'str'))\n    [1, 'str']\n\n    The utility also works with unhashable types:\n\n    >>> unique((1, [1], [1]))\n    [1, [1]]\n    \"\"\"\n    # First check if all elements are hashable, if so O(n) can be done\n    try:\n        return list(OrderedDict.fromkeys(seq))\n    except TypeError:\n        # Unhashable, resort to O(n^2)\n        unique_values = []\n        for i in seq:\n            if i not in unique_values:\n                unique_values.append(i)\n        return unique_values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a vector from an array - like object.", "response": "def vector(array, dtype=None, order=None, impl='numpy'):\n    \"\"\"Create a vector from an array-like object.\n\n    Parameters\n    ----------\n    array : `array-like`\n        Array from which to create the vector. Scalars become\n        one-dimensional vectors.\n    dtype : optional\n        Set the data type of the vector manually with this option.\n        By default, the space type is inferred from the input data.\n    order : {None, 'C', 'F'}, optional\n        Axis ordering of the data storage. For the default ``None``,\n        no contiguousness is enforced, avoiding a copy if possible.\n    impl : str, optional\n        Impmlementation back-end for the space. See\n        `odl.space.entry_points.tensor_space_impl_names` for available\n        options.\n\n    Returns\n    -------\n    vector : `Tensor`\n        Vector created from the input array. Its concrete type depends\n        on the provided arguments.\n\n    Notes\n    -----\n    This is a convenience function and not intended for use in\n    speed-critical algorithms.\n\n    Examples\n    --------\n    Create one-dimensional vectors:\n\n    >>> odl.vector([1, 2, 3])  # No automatic cast to float\n    tensor_space(3, dtype=int).element([1, 2, 3])\n    >>> odl.vector([1, 2, 3], dtype=float)\n    rn(3).element([ 1.,  2.,  3.])\n    >>> odl.vector([1, 2 - 1j, 3])\n    cn(3).element([ 1.+0.j,  2.-1.j,  3.+0.j])\n\n    Non-scalar types are also supported:\n\n    >>> odl.vector([True, True, False])\n    tensor_space(3, dtype=bool).element([ True,  True, False])\n\n    The function also supports multi-dimensional input:\n\n    >>> odl.vector([[1, 2, 3],\n    ...             [4, 5, 6]])\n    tensor_space((2, 3), dtype=int).element(\n        [[1, 2, 3],\n         [4, 5, 6]]\n    )\n    \"\"\"\n    # Sanitize input\n    arr = np.array(array, copy=False, order=order, ndmin=1)\n    if arr.dtype is object:\n        raise ValueError('invalid input data resulting in `dtype==object`')\n\n    # Set dtype\n    if dtype is not None:\n        space_dtype = dtype\n    else:\n        space_dtype = arr.dtype\n\n    space = tensor_space(arr.shape, dtype=space_dtype, impl=impl)\n    return space.element(arr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tensor_space(shape, dtype=None, impl='numpy', **kwargs):\n    tspace_cls = tensor_space_impl(impl)\n\n    if dtype is None:\n        dtype = tspace_cls.default_dtype()\n\n    # Use args by keyword since the constructor may take other arguments\n    # by position\n    return tspace_cls(shape=shape, dtype=dtype, **kwargs)", "response": "Return a tensor space with arbitrary scalar data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a space of complex tensors with arbitrary scalar data type.", "response": "def cn(shape, dtype=None, impl='numpy', **kwargs):\n    \"\"\"Return a space of complex tensors.\n\n    Parameters\n    ----------\n    shape : positive int or sequence of positive ints\n        Number of entries per axis for elements in this space. A\n        single integer results in a space with 1 axis.\n    dtype : optional\n        Data type of each element. Can be provided in any way the\n        `numpy.dtype` function understands, e.g. as built-in type or\n        as a string. Only complex floating-point data types are allowed.\n        For ``None``, the `TensorSpace.default_dtype` of the\n        created space is used in the form\n        ``default_dtype(ComplexNumbers())``.\n    impl : str, optional\n        Impmlementation back-end for the space. See\n        `odl.space.entry_points.tensor_space_impl_names` for available\n        options.\n    kwargs :\n        Extra keyword arguments passed to the space constructor.\n\n    Returns\n    -------\n    cn : `TensorSpace`\n\n    Examples\n    --------\n    Space of complex 3-tuples with ``complex64`` entries:\n\n    >>> odl.cn(3, dtype='complex64')\n    cn(3, dtype='complex64')\n\n    Complex 2x3 tensors with ``complex64`` entries:\n\n    >>> odl.cn((2, 3), dtype='complex64')\n    cn((2, 3), dtype='complex64')\n\n    The default data type depends on the implementation. For\n    ``impl='numpy'``, it is ``'complex128'``:\n\n    >>> space = odl.cn((2, 3))\n    >>> space\n    cn((2, 3))\n    >>> space.dtype\n    dtype('complex128')\n\n    See Also\n    --------\n    tensor_space : Space of tensors with arbitrary scalar data type.\n    rn : Real tensor space.\n    \"\"\"\n    cn_cls = tensor_space_impl(impl)\n\n    if dtype is None:\n        dtype = cn_cls.default_dtype(ComplexNumbers())\n\n    # Use args by keyword since the constructor may take other arguments\n    # by position\n    cn = cn_cls(shape=shape, dtype=dtype, **kwargs)\n    if not cn.is_complex:\n        raise ValueError('data type {!r} not a complex floating-point type.'\n                         ''.format(dtype))\n    return cn"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rn(shape, dtype=None, impl='numpy', **kwargs):\n    rn_cls = tensor_space_impl(impl)\n\n    if dtype is None:\n        dtype = rn_cls.default_dtype(RealNumbers())\n\n    # Use args by keyword since the constructor may take other arguments\n    # by position\n    rn = rn_cls(shape=shape, dtype=dtype, **kwargs)\n    if not rn.is_real:\n        raise ValueError('data type {!r} not a real floating-point type.'\n                         ''.format(dtype))\n    return rn", "response": "Return a space of real 3 - tuples with arbitrary scalar data type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scales(self):\n        if self.impl == 'pywt':\n            if self.__variant == 'forward':\n                discr_space = self.domain\n                wavelet_space = self.range\n            else:\n                discr_space = self.range\n                wavelet_space = self.domain\n\n            shapes = pywt.wavedecn_shapes(discr_space.shape, self.pywt_wavelet,\n                                          mode=self.pywt_pad_mode,\n                                          level=self.nlevels, axes=self.axes)\n            coeff_list = [np.full(shapes[0], 0)]\n            for i in range(1, 1 + len(shapes[1:])):\n                coeff_list.append({k: np.full(shapes[i][k], i)\n                                   for k in shapes[i].keys()})\n            coeffs = pywt.ravel_coeffs(coeff_list, axes=self.axes)[0]\n            return wavelet_space.element(coeffs)\n        else:\n            raise RuntimeError(\"bad `impl` '{}'\".format(self.impl))", "response": "Get the scales of each coefficient."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns wavelet transform of x.", "response": "def _call(self, x):\n        \"\"\"Return wavelet transform of ``x``.\"\"\"\n        if self.impl == 'pywt':\n            coeffs = pywt.wavedecn(\n                x, wavelet=self.pywt_wavelet, level=self.nlevels,\n                mode=self.pywt_pad_mode, axes=self.axes)\n            return pywt.ravel_coeffs(coeffs, axes=self.axes)[0]\n        else:\n            raise RuntimeError(\"bad `impl` '{}'\".format(self.impl))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninverse wavelet transform. returns inverse", "response": "def inverse(self):\n        \"\"\"Inverse wavelet transform.\n\n        Returns\n        -------\n        inverse : `WaveletTransformInverse`\n\n        See Also\n        --------\n        adjoint\n        \"\"\"\n        return WaveletTransformInverse(\n            range=self.domain, wavelet=self.pywt_wavelet, nlevels=self.nlevels,\n            pad_mode=self.pad_mode, pad_const=self.pad_const, impl=self.impl,\n            axes=self.axes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the inverse wavelet transform of coeffs.", "response": "def _call(self, coeffs):\n        \"\"\"Return the inverse wavelet transform of ``coeffs``.\"\"\"\n        if self.impl == 'pywt':\n            coeffs = pywt.unravel_coeffs(coeffs,\n                                         coeff_slices=self._coeff_slices,\n                                         coeff_shapes=self._coeff_shapes,\n                                         output_format='wavedecn')\n            recon = pywt.waverecn(\n                coeffs, wavelet=self.pywt_wavelet, mode=self.pywt_pad_mode,\n                axes=self.axes)\n            recon_shape = self.range.shape\n            if recon.shape != recon_shape:\n                # If the original shape was odd along any transformed axes it\n                # will have been rounded up to the next even size after the\n                # reconstruction. The extra sample should be discarded.\n                # The underlying reason is decimation by two in reconstruction\n                # must keep ceil(N/2) samples in each band for perfect\n                # reconstruction. Reconstruction then upsamples by two.\n                # When N is odd, (2 * np.ceil(N/2)) != N.\n                recon_slc = []\n                for i, (n_recon, n_intended) in enumerate(zip(recon.shape,\n                                                              recon_shape)):\n                    if n_recon == n_intended + 1:\n                        # Upsampling added one entry too much in this axis,\n                        # drop last one\n                        recon_slc.append(slice(-1))\n                    elif n_recon == n_intended:\n                        recon_slc.append(slice(None))\n                    else:\n                        raise ValueError(\n                            'in axis {}: expected size {} or {} in '\n                            '`recon_shape`, got {}'\n                            ''.format(i, n_recon - 1, n_recon,\n                                      n_intended))\n                recon = recon[tuple(recon_slc)]\n            return recon\n        else:\n            raise RuntimeError(\"bad `impl` '{}'\".format(self.impl))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pdhg(x, f, g, A, tau, sigma, niter, **kwargs):\n\n    def fun_select(k):\n        return [0]\n\n    f = odl.solvers.SeparableSum(f)\n    A = odl.BroadcastOperator(A, 1)\n\n    # Dual variable\n    y = kwargs.pop('y', None)\n    if y is None:\n        y_new = None\n    else:\n        y_new = A.range.element([y])\n\n    spdhg_generic(x, f, g, A, tau, [sigma], niter, fun_select, y=y_new,\n                  **kwargs)\n\n    if y is not None:\n        y.assign(y_new[0])", "response": "This method computes a saddle point with PDHG."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spdhg(x, f, g, A, tau, sigma, niter, **kwargs):\n\n    # Probabilities\n    prob = kwargs.pop('prob', None)\n    if prob is None:\n        prob = [1 / len(A)] * len(A)\n\n    # Selection function\n    fun_select = kwargs.pop('fun_select', None)\n    if fun_select is None:\n        def fun_select(x):\n            return [int(np.random.choice(len(A), 1, p=prob))]\n\n    # Dual variable\n    y = kwargs.pop('y', None)\n\n    extra = [1 / p for p in prob]\n\n    spdhg_generic(x, f, g, A, tau, sigma, niter, fun_select=fun_select, y=y,\n                  extra=extra, **kwargs)", "response": "r Returns a saddle point with a stochastic PDHG."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef da_spdhg(x, f, g, A, tau, sigma_tilde, niter, mu, **kwargs):\n    # Callback object\n    callback = kwargs.pop('callback', None)\n    if callback is not None and not callable(callback):\n        raise TypeError('`callback` {} is not callable'\n                        ''.format(callback))\n\n    # Probabilities\n    prob = kwargs.pop('prob', None)\n    if prob is None:\n        prob = [1 / len(A)] * len(A)\n\n    # Selection function\n    fun_select = kwargs.pop('fun_select', None)\n    if fun_select is None:\n        def fun_select(x):\n            return [int(np.random.choice(len(A), 1, p=prob))]\n\n    # Dual variable\n    y = kwargs.pop('y', None)\n    if y is None:\n        y = A.range.zero()\n\n    # Adjoint of dual variable\n    z = kwargs.pop('z', None)\n    if z is None and y.norm() == 0:\n        z = A.domain.zero()\n\n    # Extrapolation\n    extra = kwargs.pop('extra', None)\n    if extra is None:\n        extra = [1 / p for p in prob]\n\n    # Initialize variables\n    z_relax = z.copy()\n    dz = A.domain.element()\n    y_old = A.range.element()\n\n    # Save proximal operators\n    prox_dual = [fi.convex_conj.proximal for fi in f]\n    prox_primal = g.proximal\n\n    # run the iterations\n    for k in range(niter):\n\n        # select block\n        selected = fun_select(k)\n\n        # update extrapolation parameter theta\n        theta = float(1 / np.sqrt(1 + 2 * sigma_tilde))\n\n        # update primal variable\n        # tmp = x - tau * z_relax; z_relax used as tmp variable\n        z_relax.lincomb(1, x, -tau, z_relax)\n        # x = prox(tmp)\n        prox_primal(tau)(z_relax, out=x)\n\n        # update dual variable and z, z_relax\n        z_relax.assign(z)\n        for i in selected:\n\n            # compute the step sizes sigma_i based on sigma_tilde\n            sigma_i = sigma_tilde / (\n                mu[i] * (prob[i] - 2 * (1 - prob[i]) * sigma_tilde))\n\n            # save old yi\n            y_old[i].assign(y[i])\n\n            # tmp = Ai(x)\n            A[i](x, out=y[i])\n\n            # tmp = y_old + sigma_i * Ai(x)\n            y[i].lincomb(1, y_old[i], sigma_i, y[i])\n\n            # yi++ = fi*.prox_sigmai(yi)\n            prox_dual[i](sigma_i)(y[i], out=y[i])\n\n            # update adjoint of dual variable\n            y_old[i].lincomb(-1, y_old[i], 1, y[i])\n            A[i].adjoint(y_old[i], out=dz)\n            z += dz\n\n            # compute extrapolation\n            z_relax.lincomb(1, z_relax, 1 + theta * extra[i], dz)\n\n        # update the step sizes tau and sigma_tilde for acceleration\n        sigma_tilde *= theta\n        tau /= theta\n\n        if callback is not None:\n            callback([x, y])", "response": "r Returns a saddle point with a PDHG and dual acceleration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the norm of x.", "response": "def _norm(self, x):\n        \"\"\"Return the norm of ``x``.\n\n        This method is intended to be private. Public callers should\n        resort to `norm` which is type-checked.\n        \"\"\"\n        return float(np.sqrt(self.inner(x, x).real))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zero(self):\n        tmp = self.element()\n        self.lincomb(0, tmp, 0, tmp, tmp)\n        return tmp", "response": "Return the zero element of this space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimplement ``out[:] = a * x1 + b * x2``. This function implements ``out[:] = a * x1`` or, if ``b`` and ``x2`` are given, ``out = a * x1 + b * x2``. Parameters ---------- a : `field` element Scalar to multiply ``x1`` with. x1 : `LinearSpaceElement` First space element in the linear combination. b : `field` element, optional Scalar to multiply ``x2`` with. Required if ``x2`` is provided. x2 : `LinearSpaceElement`, optional Second space element in the linear combination. out : `LinearSpaceElement`, optional Element to which the result is written. Returns ------- out : `LinearSpaceElement` Result of the linear combination. If ``out`` was provided, the returned object is a reference to it. Notes ----- The elements ``out``, ``x1`` and ``x2`` may be aligned, thus a call ``space.lincomb(2, x, 3.14, x, out=x)`` is (mathematically) equivalent to ``x = x * (2 + 3.14)``.", "response": "def lincomb(self, a, x1, b=None, x2=None, out=None):\n        \"\"\"Implement ``out[:] = a * x1 + b * x2``.\n\n        This function implements\n\n            ``out[:] = a * x1``\n\n        or, if ``b`` and ``x2`` are given,\n\n            ``out = a * x1 + b * x2``.\n\n        Parameters\n        ----------\n        a : `field` element\n            Scalar to multiply ``x1`` with.\n        x1 : `LinearSpaceElement`\n            First space element in the linear combination.\n        b : `field` element, optional\n            Scalar to multiply ``x2`` with. Required if ``x2`` is\n            provided.\n        x2 : `LinearSpaceElement`, optional\n            Second space element in the linear combination.\n        out : `LinearSpaceElement`, optional\n            Element to which the result is written.\n\n        Returns\n        -------\n        out : `LinearSpaceElement`\n            Result of the linear combination. If ``out`` was provided,\n            the returned object is a reference to it.\n\n        Notes\n        -----\n        The elements ``out``, ``x1`` and ``x2`` may be aligned, thus a call\n\n            ``space.lincomb(2, x, 3.14, x, out=x)``\n\n        is (mathematically) equivalent to\n\n            ``x = x * (2 + 3.14)``.\n        \"\"\"\n        if out is None:\n            out = self.element()\n        elif out not in self:\n            raise LinearSpaceTypeError('`out` {!r} is not an element of {!r}'\n                                       ''.format(out, self))\n        if self.field is not None and a not in self.field:\n            raise LinearSpaceTypeError('`a` {!r} not an element of the field '\n                                       '{!r} of {!r}'\n                                       ''.format(a, self.field, self))\n        if x1 not in self:\n            raise LinearSpaceTypeError('`x1` {!r} is not an element of {!r}'\n                                       ''.format(x1, self))\n\n        if b is None:  # Single element\n            if x2 is not None:\n                raise ValueError('`x2` provided but not `b`')\n            self._lincomb(a, x1, 0, x1, out)\n            return out\n\n        else:  # Two elements\n            if self.field is not None and b not in self.field:\n                raise LinearSpaceTypeError('`b` {!r} not an element of the '\n                                           'field {!r} of {!r}'\n                                           ''.format(b, self.field, self))\n            if x2 not in self:\n                raise LinearSpaceTypeError('`x2` {!r} is not an element of '\n                                           '{!r}'.format(x2, self))\n\n            self._lincomb(a, x1, b, x2, out)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the distance between two elements of the log file.", "response": "def dist(self, x1, x2):\n        \"\"\"Return the distance between ``x1`` and ``x2``.\n\n        Parameters\n        ----------\n        x1, x2 : `LinearSpaceElement`\n            Elements whose distance to compute.\n\n        Returns\n        -------\n        dist : float\n            Distance between ``x1`` and ``x2``.\n        \"\"\"\n        if x1 not in self:\n            raise LinearSpaceTypeError('`x1` {!r} is not an element of '\n                                       '{!r}'.format(x1, self))\n        if x2 not in self:\n            raise LinearSpaceTypeError('`x2` {!r} is not an element of '\n                                       '{!r}'.format(x2, self))\n        return float(self._dist(x1, x2))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef norm(self, x):\n        if x not in self:\n            raise LinearSpaceTypeError('`x` {!r} is not an element of '\n                                       '{!r}'.format(x, self))\n        return float(self._norm(x))", "response": "Return the norm of x."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inner(self, x1, x2):\n        if x1 not in self:\n            raise LinearSpaceTypeError('`x1` {!r} is not an element of '\n                                       '{!r}'.format(x1, self))\n        if x2 not in self:\n            raise LinearSpaceTypeError('`x2` {!r} is not an element of '\n                                       '{!r}'.format(x2, self))\n        inner = self._inner(x1, x2)\n        if self.field is None:\n            return inner\n        else:\n            return self.field.element(self._inner(x1, x2))", "response": "Return the inner product of x1 and x2."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the pointwise product of x1 and x2.", "response": "def multiply(self, x1, x2, out=None):\n        \"\"\"Return the pointwise product of ``x1`` and ``x2``.\n\n        Parameters\n        ----------\n        x1, x2 : `LinearSpaceElement`\n            Multiplicands in the product.\n        out : `LinearSpaceElement`, optional\n            Element to which the result is written.\n\n        Returns\n        -------\n        out : `LinearSpaceElement`\n            Product of the elements. If ``out`` was provided, the\n            returned object is a reference to it.\n        \"\"\"\n        if out is None:\n            out = self.element()\n\n        if out not in self:\n            raise LinearSpaceTypeError('`out` {!r} is not an element of '\n                                       '{!r}'.format(out, self))\n        if x1 not in self:\n            raise LinearSpaceTypeError('`x1` {!r} is not an element of '\n                                       '{!r}'.format(x1, self))\n        if x2 not in self:\n            raise LinearSpaceTypeError('`x2` {!r} is not an element of '\n                                       '{!r}'.format(x2, self))\n        self._multiply(x1, x2, out)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef divide(self, x1, x2, out=None):\n        if out is None:\n            out = self.element()\n\n        if out not in self:\n            raise LinearSpaceTypeError('`out` {!r} is not an element of '\n                                       '{!r}'.format(out, self))\n        if x1 not in self:\n            raise LinearSpaceTypeError('`x1` {!r} is not an element of '\n                                       '{!r}'.format(x1, self))\n        if x2 not in self:\n            raise LinearSpaceTypeError('`x2` {!r} is not an element of '\n                                       '{!r}'.format(x2, self))\n        self._divide(x1, x2, out)\n        return out", "response": "Returns the pointwise quotient of x1 and x2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimplement linear combination of two elements.", "response": "def lincomb(self, a, x1, b=None, x2=None):\n        \"\"\"Implement ``self[:] = a * x1 + b * x2``.\n\n        Parameters\n        ----------\n        a : element of ``space.field``\n            Scalar to multiply ``x1`` with.\n        x1 : `LinearSpaceElement`\n            First space element in the linear combination.\n        b : element of ``space.field``, optional\n            Scalar to multiply ``x2`` with. Required if ``x2`` is\n            provided.\n        x2 : `LinearSpaceElement`, optional\n            Second space element in the linear combination.\n\n        See Also\n        --------\n        LinearSpace.lincomb\n        \"\"\"\n        return self.space.lincomb(a, x1, b, x2, out=self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmultiplying two sets of items.", "response": "def multiply(self, other, out=None):\n        \"\"\"Return ``out = self * other``.\n\n        If ``out`` is provided, the result is written to it.\n\n        See Also\n        --------\n        LinearSpace.multiply\n        \"\"\"\n        return self.space.multiply(self, other, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the divide of two sets of time items.", "response": "def divide(self, other, out=None):\n        \"\"\"Return ``out = self / other``.\n\n        If ``out`` is provided, the result is written to it.\n\n        See Also\n        --------\n        LinearSpace.divide\n        \"\"\"\n        return self.space.divide(self, other, out=out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pywt_wavelet(wavelet):\n    if isinstance(wavelet, pywt.Wavelet):\n        return wavelet\n    else:\n        return pywt.Wavelet(wavelet)", "response": "Convert wavelet to a pywt. Wavelet instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts ODL - style padding mode to pywt - style padding mode.", "response": "def pywt_pad_mode(pad_mode, pad_const=0):\n    \"\"\"Convert ODL-style padding mode to pywt-style padding mode.\n\n    Parameters\n    ----------\n    pad_mode : str\n        The ODL padding mode to use at the boundaries.\n    pad_const : float, optional\n        Value to use outside the signal boundaries when ``pad_mode`` is\n        'constant'. Only a value of 0. is supported by PyWavelets\n\n    Returns\n    -------\n    pad_mode_pywt : str\n        The corresponding name of the requested padding mode in PyWavelets.\n        See `signal extension modes`_.\n\n    References\n    ----------\n    .. _signal extension modes:\n       https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html\n    \"\"\"\n    pad_mode = str(pad_mode).lower()\n    if pad_mode == 'constant' and pad_const != 0.0:\n        raise ValueError('constant padding with constant != 0 not supported '\n                         'for `pywt` back-end')\n    try:\n        return PAD_MODES_ODL2PYWT[pad_mode]\n    except KeyError:\n        raise ValueError(\"`pad_mode` '{}' not understood\".format(pad_mode))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns slices and shapes for raveled wavelet coefficients.", "response": "def precompute_raveled_slices(coeff_shapes, axes=None):\n    \"\"\"Return slices and shapes for raveled multilevel wavelet coefficients.\n\n    The output is equivalent to the ``coeff_slices`` output of\n    `pywt.ravel_coeffs`, but this function does not require computing a\n    wavelet transform first.\n\n    Parameters\n    ----------\n    coeff_shapes : array-like\n        A list of multilevel wavelet coefficient shapes as returned by\n        `pywt.wavedecn_shapes`.\n    axes : sequence of ints, optional\n        Axes over which the DWT that created ``coeffs`` was performed. The\n        default value of None corresponds to all axes.\n\n    Returns\n    -------\n    coeff_slices : list\n        List of slices corresponding to each coefficient. As a 2D example,\n        ``coeff_arr[coeff_slices[1]['dd']]`` would extract the first level\n        detail coefficients from ``coeff_arr``.\n\n    Examples\n    --------\n    >>> import pywt\n    >>> data_shape = (64, 64)\n    >>> coeff_shapes = pywt.wavedecn_shapes(data_shape, wavelet='db2', level=3,\n    ...                                     mode='periodization')\n    >>> coeff_slices = precompute_raveled_slices(coeff_shapes)\n    >>> print(coeff_slices[0])  # approximation coefficients\n    slice(None, 64, None)\n    >>> d1_coeffs = coeff_slices[-1]  # first level detail coefficients\n    >>> (d1_coeffs['ad'], d1_coeffs['da'], d1_coeffs['dd'])\n    (slice(1024, 2048, None), slice(2048, 3072, None), slice(3072, 4096, None))\n    \"\"\"\n    # initialize with the approximation coefficients.\n    a_shape = coeff_shapes[0]\n    a_size = np.prod(a_shape)\n\n    if len(coeff_shapes) == 1:\n        # only a single approximation coefficient array was found\n        return [slice(a_size), ]\n\n    a_slice = slice(a_size)\n\n    # initialize list of coefficient slices\n    coeff_slices = []\n    coeff_slices.append(a_slice)\n\n    # loop over the detail cofficients, embedding them in coeff_arr\n    details_list = coeff_shapes[1:]\n    offset = a_size\n    for shape_dict in details_list:\n        # new dictionaries for detail coefficient slices and shapes\n        coeff_slices.append({})\n        keys = sorted(shape_dict.keys())\n        for key in keys:\n            shape = shape_dict[key]\n            size = np.prod(shape)\n            sl = slice(offset, offset + size)\n            offset += size\n            coeff_slices[-1][key] = sl\n    return coeff_slices"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef combine_proximals(*factory_list):\n    def diag_op_factory(sigma):\n        \"\"\"Diagonal matrix of operators.\n\n        Parameters\n        ----------\n        sigma : positive float or sequence of positive floats\n            Step size parameter(s), if a sequence, the length must match\n            the length of the ``factory_list``.\n\n        Returns\n        -------\n        diag_op : `DiagonalOperator`\n        \"\"\"\n        if np.isscalar(sigma):\n            sigma = [sigma] * len(factory_list)\n\n        return DiagonalOperator(\n            *[factory(sigmai)\n              for sigmai, factory in zip(sigma, factory_list)])\n\n    return diag_op_factory", "response": "r Combine proximal operators into a diagonal product space operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef proximal_convex_conj(prox_factory):\n    def convex_conj_prox_factory(sigma):\n        \"\"\"Create proximal for the dual with a given sigma.\n\n        Parameters\n        ----------\n        sigma : positive float or array-like\n            Step size parameter. Can be a pointwise positive space element or\n            a sequence of positive floats if `prox_factory` supports that.\n\n        Returns\n        -------\n        proximal : `Operator`\n            The proximal operator of ``s * F^*`` where ``s`` is the step size\n        \"\"\"\n\n        # Get the underlying space. At the same time, check if the given\n        # prox_factory accepts stepsize objects of the type given by sigma.\n        space = prox_factory(sigma).domain\n\n        mult_inner = MultiplyOperator(1.0 / sigma, domain=space, range=space)\n        mult_outer = MultiplyOperator(sigma, domain=space, range=space)\n        result = (IdentityOperator(space) -\n                  mult_outer * prox_factory(1.0 / sigma) * mult_inner)\n        return result\n\n    return convex_conj_prox_factory", "response": "r Calculates the proximal of the dual using the Moreau decomposition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef proximal_quadratic_perturbation(prox_factory, a, u=None):\n    a = float(a)\n    if a < 0:\n        raise ValueError('scaling parameter muts be non-negative, got {}'\n                         ''.format(a))\n\n    if u is not None and not isinstance(u, LinearSpaceElement):\n        raise TypeError('`u` must be `None` or a `LinearSpaceElement` '\n                        'instance, got {!r}.'.format(u))\n\n    def quadratic_perturbation_prox_factory(sigma):\n        r\"\"\"Create proximal for the quadratic perturbation with a given sigma.\n\n        Parameters\n        ----------\n        sigma : positive float\n            Step size parameter\n\n        Returns\n        -------\n        proximal : `Operator`\n            The proximal operator of ``sigma * (F(x) + a * \\|x\\|^2 + <u,x>)``,\n            where ``sigma`` is the step size\n        \"\"\"\n        if np.isscalar(sigma):\n            sigma = float(sigma)\n        else:\n            sigma = np.asarray(sigma)\n\n        const = 1.0 / np.sqrt(sigma * 2.0 * a + 1)\n        prox = proximal_arg_scaling(prox_factory, const)(sigma)\n        if u is not None:\n            return (MultiplyOperator(const, domain=u.space, range=u.space) *\n                    prox *\n                    (MultiplyOperator(const, domain=u.space, range=u.space) -\n                     sigma * const * u))\n        else:\n            space = prox.domain\n            return (MultiplyOperator(const, domain=space, range=space) *\n                    prox * MultiplyOperator(const, domain=space, range=space))\n\n    return quadratic_perturbation_prox_factory", "response": "r Returns the proximal of function F a and u."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef proximal_convex_conj_l2_squared(space, lam=1, g=None):\n    lam = float(lam)\n\n    if g is not None and g not in space:\n        raise TypeError('{!r} is not an element of {!r}'.format(g, space))\n\n    class ProximalConvexConjL2Squared(Operator):\n\n        \"\"\"Proximal operator of the convex conj of the squared l2-norm/dist.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float or pointwise positive space.element\n                Step size parameter. If scalar, it contains a global stepsize,\n                otherwise the space.element defines a stepsize for each point.\n            \"\"\"\n            super(ProximalConvexConjL2Squared, self).__init__(\n                domain=space, range=space, linear=g is None)\n            if np.isscalar(sigma):\n                self.sigma = float(sigma)\n            else:\n                self.sigma = space.element(sigma)\n\n        def _call(self, x, out):\n            \"\"\"Apply the operator to ``x`` and store the result in ``out``\"\"\"\n            # (x - sig*g) / (1 + sig/(2 lam))\n            sig = self.sigma\n            if np.isscalar(sig):\n                if g is None:\n                    out.lincomb(1 / (1 + 0.5 * sig / lam), x)\n                else:\n                    out.lincomb(1 / (1 + 0.5 * sig / lam), x,\n                                -sig / (1 + 0.5 * sig / lam), g)\n            elif sig in space:\n                if g is None:\n                    x.divide(1 + 0.5 / lam * sig, out=out)\n                else:\n                    if x is out:\n                        # Can't write to `out` since old `x` is still needed\n                        tmp = sig.multiply(g)\n                        out.lincomb(1, x, -1, tmp)\n                    else:\n                        sig.multiply(g, out=out)\n                        out.lincomb(1, x, -1, out)\n                    out.divide(1 + 0.5 / lam * sig, out=out)\n            else:\n                raise RuntimeError(\n                    '`sigma` is neither a scalar nor a space element.'\n                )\n\n    return ProximalConvexConjL2Squared", "response": "r Returns a proximal function that is used to initialize the convex conjugate of the squared l2 - distencing of the functional F."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef proximal_l2_squared(space, lam=1, g=None):\n    class ProximalL2Squared(Operator):\n\n        \"\"\"Proximal operator of the squared l2-norm/dist.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float or pointwise positive space.element\n                Step size parameter. If scalar, it contains a global stepsize,\n                otherwise the space.element defines a stepsize for each point.\n            \"\"\"\n            super(ProximalL2Squared, self).__init__(\n                domain=space, range=space, linear=g is None)\n            if np.isscalar(sigma):\n                self.sigma = float(sigma)\n            else:\n                self.sigma = space.element(sigma)\n\n        def _call(self, x, out):\n            \"\"\"Apply the operator to ``x`` and store the result in ``out``\"\"\"\n            # (x + 2*sig*lam*g) / (1 + 2*sig*lam))\n            sig = self.sigma\n            if np.isscalar(sig):\n                if g is None:\n                    out.lincomb(1 / (1 + 2 * sig * lam), x)\n                else:\n                    out.lincomb(1 / (1 + 2 * sig * lam), x,\n                                2 * sig * lam / (1 + 2 * sig * lam), g)\n            else:   # sig in space\n                if g is None:\n                    x.divide(1 + 2 * sig * lam, out=out)\n                else:\n                    if x is out:\n                        # Can't write to `out` since old `x` is still needed\n                        tmp = sig.multiply(2 * lam * g)\n                        out.lincomb(1, x, 1, tmp)\n                    else:\n                        sig.multiply(2 * lam * g, out=out)\n                        out.lincomb(1, x, 1, out)\n                    out.divide(1 + 2 * sig * lam, out=out)\n\n    return ProximalL2Squared", "response": "r Returns a proximal function that creates a new instance of the class ProximalL2Squared operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef proximal_convex_conj_l1_l2(space, lam=1, g=None):\n    # Fix for rounding errors\n    dtype = getattr(space, 'dtype', float)\n    eps = np.finfo(dtype).resolution * 10\n    lam = float(lam * (1 - eps))\n\n    if g is not None and g not in space:\n        raise TypeError('{!r} is not an element of {!r}'.format(g, space))\n\n    class ProximalConvexConjL1L2(Operator):\n\n        \"\"\"Proximal operator of the convex conj of the l1-norm/distance.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float\n                Step size parameter\n            \"\"\"\n            super(ProximalConvexConjL1L2, self).__init__(\n                domain=space, range=space, linear=False)\n            self.sigma = float(sigma)\n\n        def _call(self, x, out):\n            \"\"\"Return ``self(x, out=out)``.\"\"\"\n            # lam * (x - sig * g) / max(lam, |x - sig * g|)\n\n            # diff = x - sig * g\n            if g is not None:\n                diff = self.domain.element()\n                diff.lincomb(1, x, -self.sigma, g)\n            else:\n                diff = x\n\n            # denom = max( |x-sig*g|_2, lam ) / lam  (|.|_2 pointwise)\n            pwnorm = PointwiseNorm(self.domain, exponent=2)\n            denom = pwnorm(diff)\n            denom.ufuncs.maximum(lam, out=denom)\n            denom /= lam\n\n            # Pointwise division\n            for out_i, diff_i in zip(out, diff):\n                diff_i.divide(denom, out=out_i)\n\n    return ProximalConvexConjL1L2", "response": "r Returns a proximal operator factory of the convex conjugate of the functional F1 - L2 norm distance convex conjugate of the functional F1 - L2 norm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef proximal_l1(space, lam=1, g=None):\n    lam = float(lam)\n\n    if g is not None and g not in space:\n        raise TypeError('{!r} is not an element of {!r}'.format(g, space))\n\n    class ProximalL1(Operator):\n\n        \"\"\"Proximal operator of the L1 norm/distance.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float or pointwise positive space.element\n                Step size parameter. If scalar, it contains a global stepsize,\n                otherwise the space.element defines a stepsize for each point.\n            \"\"\"\n            super(ProximalL1, self).__init__(\n                domain=space, range=space, linear=False)\n            if np.isscalar(sigma):\n                self.sigma = float(sigma)\n            else:\n                self.sigma = space.element(sigma)\n\n        def _call(self, x, out):\n            \"\"\"Return ``self(x, out=out)``.\"\"\"\n            # diff = x - g\n            if g is not None:\n                diff = x - g\n            else:\n                if x is out:\n                    # Handle aliased `x` and `out` (original `x` needed later)\n                    diff = x.copy()\n                else:\n                    diff = x\n\n            # We write the operator as\n            # x - (x - g) / max(|x - g| / sig*lam, 1)\n            denom = diff.ufuncs.absolute()\n            denom /= self.sigma * lam\n            denom.ufuncs.maximum(1, out=denom)\n\n            # out = (x - g) / denom\n            diff.ufuncs.divide(denom, out=out)\n\n            # out = x - ...\n            out.lincomb(1, x, -1, out)\n\n    return ProximalL1", "response": "r A proximal function that returns the L1 norm and distance of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef proximal_linfty(space):\n    class ProximalLInfty(Operator):\n\n        \"\"\"Proximal operator of the linf-norm.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float\n                Step size parameter\n            \"\"\"\n            super(ProximalLInfty, self).__init__(\n                domain=space, range=space, linear=False)\n            self.sigma = float(sigma)\n\n        def _call(self, x, out):\n            \"\"\"Return ``self(x)``.\"\"\"\n\n            radius = 1\n\n            if x is out:\n                x = x.copy()\n\n            proj_l1(x, radius, out)\n            out.lincomb(-1, out, 1, x)\n\n    return ProximalLInfty", "response": "r A function that creates a proximal operator of the l_infty - norm."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef proximal_convex_conj_linfty(space):\n\n    class ProximalConvexConjLinfty(Operator):\n\n        \"\"\"Proximal operator of the Linfty norm/distance convex conjugate.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float or pointwise positive space.element\n                Step size parameter. If scalar, it contains a global stepsize,\n                otherwise the space.element defines a stepsize for each point.\n            \"\"\"\n            super(ProximalConvexConjLinfty, self).__init__(\n                domain=space, range=space, linear=False)\n\n        def _call(self, x, out):\n            \"\"\"Return ``self(x, out=out)``.\"\"\"\n            proj_l1(x, radius=1, out=out)\n\n    return ProximalConvexConjLinfty", "response": "r A class that returns a proximal operator of the convex conjugate of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef proximal_huber(space, gamma):\n\n    gamma = float(gamma)\n\n    class ProximalHuber(Operator):\n\n        \"\"\"Proximal operator of Huber norm.\"\"\"\n\n        def __init__(self, sigma):\n            \"\"\"Initialize a new instance.\n\n            Parameters\n            ----------\n            sigma : positive float\n            \"\"\"\n            self.sigma = float(sigma)\n            super(ProximalHuber, self).__init__(domain=space, range=space,\n                                                linear=False)\n\n        def _call(self, x, out):\n            \"\"\"Return ``self(x, out=out)``.\"\"\"\n            if isinstance(self.domain, ProductSpace):\n                norm = PointwiseNorm(self.domain, 2)(x)\n            else:\n                norm = x.ufuncs.absolute()\n\n            mask = norm.ufuncs.less_equal(gamma + self.sigma)\n            out[mask] = gamma / (gamma + self.sigma) * x[mask]\n\n            mask.ufuncs.logical_not(out=mask)\n            sign_x = x.ufuncs.sign()\n            out[mask] = x[mask] - self.sigma * sign_x[mask]\n\n            return out\n\n    return ProximalHuber", "response": "Proximal functional of the Huber norm functional."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mri_knee_data_8_channel():\n    # TODO: Store data in some ODL controlled url\n    url = 'https://zenodo.org/record/800529/files/3_rawdata_knee_8ch.mat'\n    dct = get_data('3_rawdata_knee_8ch.mat', subset=DATA_SUBSET, url=url)\n\n    # Change axes to match ODL definitions\n    data = flip(np.swapaxes(dct['rawdata'], 0, -1) * 9e3, 2)\n\n    return data", "response": "Raw data for 8 channel MRI of a healthy volunteer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts image to ODL object.", "response": "def convert_to_odl(image):\n    \"\"\"Convert image to ODL object.\"\"\"\n\n    shape = image.shape\n\n    if len(shape) == 2:\n        space = odl.uniform_discr([0, 0], shape, shape)\n    elif len(shape) == 3:\n        d = shape[2]\n        shape = shape[:2]\n        image = np.transpose(image, (2, 0, 1))\n        space = odl.uniform_discr([0, 0], shape, shape) ** d\n\n    image = space.element(image)\n\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef element(self, inp=None):\n        if inp is None:\n            return self.mid_pt\n        elif inp in self:\n            if self.ndim == 1:\n                return float(inp)\n            else:\n                return np.asarray(inp)\n        else:\n            raise TypeError('`inp` {!r} is not a valid element of {!r}'\n                            ''.format(inp, self))", "response": "Return an element of this interval product."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef approx_equals(self, other, atol):\n        if other is self:\n            return True\n        elif not isinstance(other, IntervalProd):\n            return False\n\n        return (np.allclose(self.min_pt, other.min_pt, atol=atol, rtol=0.0) and\n                np.allclose(self.max_pt, other.max_pt, atol=atol, rtol=0.0))", "response": "Return True if self is equal to other set up to atol."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef approx_contains(self, point, atol):\n        try:\n            # Duck-typed check of type\n            point = np.array(point, dtype=np.float, copy=False, ndmin=1)\n        except (ValueError, TypeError):\n            return False\n\n        if point.size == 0:\n            return True\n        elif point.shape != (self.ndim,):\n            return False\n\n        return self.dist(point, exponent=np.inf) <= atol", "response": "Return True if point is almost contained in this set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if this set contains other.", "response": "def contains_set(self, other, atol=0.0):\n        \"\"\"Return ``True`` if ``other`` is (almost) contained in this set.\n\n        Parameters\n        ----------\n        other : `Set`\n            Set to be tested.\n        atol : float, optional\n            Maximum allowed distance in maximum norm from ``other``\n            to ``self``.\n\n        Raises\n        ------\n        AttributeError\n            if ``other`` does not have both ``min`` and ``max`` methods.\n\n        Examples\n        --------\n        >>> min_pt1, max_pt1 = [-1, 0, 2], [-0.5, 0, 3]\n        >>> rbox1 = IntervalProd(min_pt1, max_pt1)\n        >>> min_pt2, max_pt2 = [-0.6, 0, 2.1], [-0.5, 0, 2.5]\n        >>> rbox2 = IntervalProd(min_pt2, max_pt2)\n        >>> rbox1.contains_set(rbox2)\n        True\n        >>> rbox2.contains_set(rbox1)\n        False\n        \"\"\"\n        if self is other:\n            return True\n\n        try:\n            return (self.approx_contains(other.min(), atol) and\n                    self.approx_contains(other.max(), atol))\n        except AttributeError:\n            raise AttributeError('cannot test {!r} without `min` and `max` '\n                                 'methods'.format(other))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if all points defined by other are contained in this interval product.", "response": "def contains_all(self, other, atol=0.0):\n        \"\"\"Return ``True`` if all points defined by ``other`` are contained.\n\n        Parameters\n        ----------\n        other :\n            Collection of points to be tested. Can be given as a single\n            point, a ``(d, N)`` array-like where ``d`` is the\n            number of dimensions, or a length-``d`` `meshgrid` tuple.\n        atol : float, optional\n            The maximum allowed distance in 'inf'-norm between the\n            other set and this interval product.\n\n        Returns\n        -------\n        contains : bool\n            ``True`` if all points are contained, ``False`` otherwise.\n\n        Examples\n        --------\n        >>> min_pt, max_pt = [-1, 0, 2], [-0.5, 0, 3]\n        >>> rbox = IntervalProd(min_pt, max_pt)\n\n        Arrays are expected in ``(ndim, npoints)`` shape:\n\n        >>> arr = np.array([[-1, 0, 2],   # defining one point at a time\n        ...                 [-0.5, 0, 2]])\n        >>> rbox.contains_all(arr.T)\n        True\n\n        Implicit meshgrids defined by coordinate vectors:\n\n        >>> from odl.discr.grid import sparse_meshgrid\n        >>> vec1 = (-1, -0.9, -0.7)\n        >>> vec2 = (0, 0, 0)\n        >>> vec3 = (2.5, 2.75, 3)\n        >>> mg = sparse_meshgrid(vec1, vec2, vec3)\n        >>> rbox.contains_all(mg)\n        True\n\n        Works also with an arbitrary iterable:\n\n        >>> rbox.contains_all([[-1, -0.5], # define points by axis\n        ...                    [0, 0],\n        ...                    [2, 2]])\n        True\n\n        Grids are also accepted as input:\n\n        >>> agrid = odl.uniform_grid(rbox.min_pt, rbox.max_pt, [3, 1, 3])\n        >>> rbox.contains_all(agrid)\n        True\n        \"\"\"\n        atol = float(atol)\n\n        # First try optimized methods\n        if other in self:\n            return True\n        if hasattr(other, 'meshgrid'):\n            return self.contains_all(other.meshgrid, atol=atol)\n        elif is_valid_input_meshgrid(other, self.ndim):\n            vecs = tuple(vec.squeeze() for vec in other)\n            mins = np.fromiter((np.min(vec) for vec in vecs), dtype=float)\n            maxs = np.fromiter((np.max(vec) for vec in vecs), dtype=float)\n            return (np.all(mins >= self.min_pt - atol) and\n                    np.all(maxs <= self.max_pt + atol))\n\n        # Convert to array and check each element\n        other = np.asarray(other)\n        if is_valid_input_array(other, self.ndim):\n            if self.ndim == 1:\n                mins = np.min(other)\n                maxs = np.max(other)\n            else:\n                mins = np.min(other, axis=1)\n                maxs = np.max(other, axis=1)\n            return np.all(mins >= self.min_pt) and np.all(maxs <= self.max_pt)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef measure(self, ndim=None):\n        if self.true_ndim == 0:\n            return 0.0\n\n        if ndim is None:\n            return self.measure(ndim=self.true_ndim)\n        elif ndim < self.true_ndim:\n            return np.inf\n        elif ndim > self.true_ndim:\n            return 0.0\n        else:\n            return np.prod(self.extent[self.nondegen_byaxis])", "response": "Return the Lebesgue measure of this interval product."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dist(self, point, exponent=2.0):\n        point = np.atleast_1d(point)\n        if len(point) != self.ndim:\n            raise ValueError('`point` must have length {}, got {}'\n                             ''.format(self.ndim, len(point)))\n\n        if np.any(np.isnan(point)):\n            return float('inf')\n\n        i_larger = np.where(point > self.max_pt)\n        i_smaller = np.where(point < self.min_pt)\n\n        # Access [0] since np.where returns a tuple.\n        if len(i_larger[0]) == 0 and len(i_smaller[0]) == 0:\n            return 0.0\n        else:\n            proj = np.concatenate((point[i_larger], point[i_smaller]))\n            border = np.concatenate((self.max_pt[i_larger],\n                                     self.min_pt[i_smaller]))\n            return np.linalg.norm(proj - border, ord=exponent)", "response": "Return the distance of point to this set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef squeeze(self):\n        b_new = self.min_pt[self.nondegen_byaxis]\n        e_new = self.max_pt[self.nondegen_byaxis]\n        return IntervalProd(b_new, e_new)", "response": "Remove the degenerate dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts a set of interval products before index.", "response": "def insert(self, index, *intvs):\n        \"\"\"Return a copy with ``intvs`` inserted before ``index``.\n\n        The given interval products are inserted (as a block) into ``self``,\n        yielding a new interval product whose number of dimensions is the\n        sum of the numbers of dimensions of all involved interval products.\n        Note that no changes are made in-place.\n\n        Parameters\n        ----------\n        index : int\n            Index of the dimension before which ``other`` is to\n            be inserted. Must fulfill ``-ndim <= index <= ndim``.\n            Negative indices count backwards from ``self.ndim``.\n        intv1, ..., intvN : `IntervalProd`\n            Interval products to be inserted into ``self``.\n\n        Returns\n        -------\n        newintvp : `IntervalProd`\n            The enlarged interval product.\n\n        Examples\n        --------\n        >>> intv = IntervalProd([-1, 2], [-0.5, 3])\n        >>> intv2 = IntervalProd(0, 1)\n        >>> intv.insert(0, intv2)\n        IntervalProd([ 0., -1.,  2.], [ 1. , -0.5,  3. ])\n        >>> intv.insert(-1, intv2)\n        IntervalProd([-1.,  0.,  2.], [-0.5,  1. ,  3. ])\n        >>> intv.insert(1, intv2, intv2)\n        IntervalProd([-1.,  0.,  0.,  2.], [-0.5,  1. ,  1. ,  3. ])\n        \"\"\"\n        index, index_in = safe_int_conv(index), index\n\n        if not -self.ndim <= index <= self.ndim:\n            raise IndexError('index {0} outside the valid range -{1} ... {1}'\n                             ''.format(index_in, self.ndim))\n        if index < 0:\n            index += self.ndim\n\n        if len(intvs) == 0:\n            # Copy of `self`\n            return IntervalProd(self.min_pt, self.max_pt)\n\n        elif len(intvs) == 1:\n            # Insert single interval product\n            intv = intvs[0]\n            if not isinstance(intv, IntervalProd):\n                raise TypeError('{!r} is not a `IntervalProd` instance'\n                                ''.format(intv))\n            new_min_pt = np.empty(self.ndim + intv.ndim)\n            new_max_pt = np.empty(self.ndim + intv.ndim)\n\n            new_min_pt[: index] = self.min_pt[: index]\n            new_max_pt[: index] = self.max_pt[: index]\n            new_min_pt[index: index + intv.ndim] = intv.min_pt\n            new_max_pt[index: index + intv.ndim] = intv.max_pt\n            if index < self.ndim:  # Avoid IndexError\n                new_min_pt[index + intv.ndim:] = self.min_pt[index:]\n                new_max_pt[index + intv.ndim:] = self.max_pt[index:]\n\n            return IntervalProd(new_min_pt, new_max_pt)\n\n        else:\n            # Recursively insert one, then rest into the result\n            return self.insert(index, intvs[0]).insert(\n                index + intvs[0].ndim, *(intvs[1:]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef corners(self, order='C'):\n        from odl.discr.grid import RectGrid\n\n        minmax_vecs = [0] * self.ndim\n        for axis in np.where(~self.nondegen_byaxis)[0]:\n            minmax_vecs[axis] = self.min_pt[axis]\n        for axis in np.where(self.nondegen_byaxis)[0]:\n            minmax_vecs[axis] = (self.min_pt[axis], self.max_pt[axis])\n\n        minmax_grid = RectGrid(*minmax_vecs)\n        return minmax_grid.points(order=order)", "response": "Return the corners of the current set of undegenerate elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning self ( x out = None", "response": "def _call(self, x, out=None):\n        \"\"\"Return ``self(x[, out])``.\"\"\"\n        if self.domain.is_real:\n            return self._call_real(x, out)\n\n        elif self.domain.is_complex:\n            result_parts = [\n                self._call_real(x.real, getattr(out, 'real', None)),\n                self._call_real(x.imag, getattr(out, 'imag', None))]\n\n            if out is None:\n                out = self.range.element()\n                out.real = result_parts[0]\n                out.imag = result_parts[1]\n\n            return out\n\n        else:\n            raise RuntimeError('bad domain {!r}'.format(self.domain))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adjoint(self):\n        if self._adjoint is not None:\n            return self._adjoint\n\n        kwargs = self._extra_kwargs.copy()\n        kwargs['range'] = self.domain\n        self._adjoint = RayTransform(self.range, self.geometry,\n                                     impl=self.impl,\n                                     use_cache=self.use_cache,\n                                     **kwargs)\n        return self._adjoint", "response": "Adjoint of this operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef poisson_log_likelihood(x, data):\n    if np.any(np.less(x, 0)):\n        raise ValueError('`x` must be non-negative')\n\n    return np.sum(data * np.log(x + 1e-8) - x)", "response": "Calculates the poisson log - likelihood of data given noise parametrized by x."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the volume scaling factor for differing adjoint definitions.", "response": "def astra_cuda_bp_scaling_factor(proj_space, reco_space, geometry):\n    \"\"\"Volume scaling accounting for differing adjoint definitions.\n\n    ASTRA defines the adjoint operator in terms of a fully discrete\n    setting (transposed \"projection matrix\") without any relation to\n    physical dimensions, which makes a re-scaling necessary to\n    translate it to spaces with physical dimensions.\n\n    Behavior of ASTRA changes slightly between versions, so we keep\n    track of it and adapt the scaling accordingly.\n    \"\"\"\n    # Angular integration weighting factor\n    # angle interval weight by approximate cell volume\n    angle_extent = geometry.motion_partition.extent\n    num_angles = geometry.motion_partition.shape\n    # TODO: this gives the wrong factor for Parallel3dEulerGeometry with\n    # 2 angles\n    scaling_factor = (angle_extent / num_angles).prod()\n\n    # Correct in case of non-weighted spaces\n    proj_extent = float(proj_space.partition.extent.prod())\n    proj_size = float(proj_space.partition.size)\n    proj_weighting = proj_extent / proj_size\n\n    scaling_factor *= (proj_space.weighting.const /\n                       proj_weighting)\n    scaling_factor /= (reco_space.weighting.const /\n                       reco_space.cell_volume)\n\n    if parse_version(ASTRA_VERSION) < parse_version('1.8rc1'):\n        if isinstance(geometry, Parallel2dGeometry):\n            # Scales with 1 / cell_volume\n            scaling_factor *= float(reco_space.cell_volume)\n        elif (isinstance(geometry, FanBeamGeometry)\n              and geometry.det_curvature_radius is None):\n            # Scales with 1 / cell_volume\n            scaling_factor *= float(reco_space.cell_volume)\n            # Additional magnification correction\n            src_radius = geometry.src_radius\n            det_radius = geometry.det_radius\n            scaling_factor *= ((src_radius + det_radius) / src_radius)\n        elif isinstance(geometry, Parallel3dAxisGeometry):\n            # Scales with voxel stride\n            # In 1.7, only cubic voxels are supported\n            voxel_stride = reco_space.cell_sides[0]\n            scaling_factor /= float(voxel_stride)\n        elif isinstance(geometry, ConeFlatGeometry):\n            # Scales with 1 / cell_volume\n            # In 1.7, only cubic voxels are supported\n            voxel_stride = reco_space.cell_sides[0]\n            scaling_factor /= float(voxel_stride)\n            # Magnification correction\n            src_radius = geometry.src_radius\n            det_radius = geometry.det_radius\n            scaling_factor *= ((src_radius + det_radius) / src_radius) ** 2\n    # Check if the development version of astra is used\n    if parse_version(ASTRA_VERSION) == parse_version('1.9.0dev'):\n        if isinstance(geometry, Parallel2dGeometry):\n            # Scales with 1 / cell_volume\n            scaling_factor *= float(reco_space.cell_volume)\n        elif (isinstance(geometry, FanBeamGeometry)\n              and geometry.det_curvature_radius is None):\n            # Scales with 1 / cell_volume\n            scaling_factor *= float(reco_space.cell_volume)\n            # Magnification correction\n            src_radius = geometry.src_radius\n            det_radius = geometry.det_radius\n            scaling_factor *= ((src_radius + det_radius) / src_radius)\n        elif isinstance(geometry, Parallel3dAxisGeometry):\n            # Scales with cell volume\n            # currently only square voxels are supported\n            scaling_factor /= reco_space.cell_volume\n        elif isinstance(geometry, ConeFlatGeometry):\n            # Scales with cell volume\n            scaling_factor /= reco_space.cell_volume\n            # Magnification correction (scaling = 1 / magnification ** 2)\n            src_radius = geometry.src_radius\n            det_radius = geometry.det_radius\n            scaling_factor *= ((src_radius + det_radius) / src_radius) ** 2\n\n            # Correction for scaled 1/r^2 factor in ASTRA's density weighting.\n            # This compensates for scaled voxels and pixels, as well as a\n            # missing factor src_radius ** 2 in the ASTRA BP with\n            # density weighting.\n            det_px_area = geometry.det_partition.cell_volume\n            scaling_factor *= (src_radius ** 2 * det_px_area ** 2)\n    else:\n        if isinstance(geometry, Parallel2dGeometry):\n            # Scales with 1 / cell_volume\n            scaling_factor *= float(reco_space.cell_volume)\n        elif (isinstance(geometry, FanBeamGeometry)\n              and geometry.det_curvature_radius is None):\n            # Scales with 1 / cell_volume\n            scaling_factor *= float(reco_space.cell_volume)\n            # Magnification correction\n            src_radius = geometry.src_radius\n            det_radius = geometry.det_radius\n            scaling_factor *= ((src_radius + det_radius) / src_radius)\n        elif isinstance(geometry, Parallel3dAxisGeometry):\n            # Scales with cell volume\n            # currently only square voxels are supported\n            scaling_factor /= reco_space.cell_volume\n        elif isinstance(geometry, ConeFlatGeometry):\n            # Scales with cell volume\n            scaling_factor /= reco_space.cell_volume\n            # Magnification correction (scaling = 1 / magnification ** 2)\n            src_radius = geometry.src_radius\n            det_radius = geometry.det_radius\n            scaling_factor *= ((src_radius + det_radius) / src_radius) ** 2\n\n            # Correction for scaled 1/r^2 factor in ASTRA's density weighting.\n            # This compensates for scaled voxels and pixels, as well as a\n            # missing factor src_radius ** 2 in the ASTRA BP with\n            # density weighting.\n            det_px_area = geometry.det_partition.cell_volume\n            scaling_factor *= (src_radius ** 2 * det_px_area ** 2 /\n                               reco_space.cell_volume ** 2)\n\n        # TODO: add case with new ASTRA release\n\n    return scaling_factor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call_forward(self, vol_data, out=None):\n        with self._mutex:\n            assert vol_data in self.reco_space\n            if out is not None:\n                assert out in self.proj_space\n            else:\n                out = self.proj_space.element()\n\n            # Copy data to GPU memory\n            if self.geometry.ndim == 2:\n                astra.data2d.store(self.vol_id, vol_data.asarray())\n            elif self.geometry.ndim == 3:\n                astra.data3d.store(self.vol_id, vol_data.asarray())\n            else:\n                raise RuntimeError('unknown ndim')\n\n            # Run algorithm\n            astra.algorithm.run(self.algo_id)\n\n            # Copy result to host\n            if self.geometry.ndim == 2:\n                out[:] = self.out_array\n            elif self.geometry.ndim == 3:\n                out[:] = np.swapaxes(self.out_array, 0, 1).reshape(\n                    self.proj_space.shape)\n\n            # Fix scaling to weight by pixel size\n            if isinstance(self.geometry, Parallel2dGeometry):\n                # parallel2d scales with pixel stride\n                out *= 1 / float(self.geometry.det_partition.cell_volume)\n\n            return out", "response": "Run an ASTRA forward projection on the given data using the GPU."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_ids(self):\n        # Create input and output arrays\n        if self.geometry.motion_partition.ndim == 1:\n            motion_shape = self.geometry.motion_partition.shape\n        else:\n            # Need to flatten 2- or 3-dimensional angles into one axis\n            motion_shape = (np.prod(self.geometry.motion_partition.shape),)\n\n        proj_shape = motion_shape + self.geometry.det_partition.shape\n        proj_ndim = len(proj_shape)\n\n        if proj_ndim == 2:\n            astra_proj_shape = proj_shape\n            astra_vol_shape = self.reco_space.shape\n        elif proj_ndim == 3:\n            # The `u` and `v` axes of the projection data are swapped,\n            # see explanation in `astra_*_3d_geom_to_vec`.\n            astra_proj_shape = (proj_shape[1], proj_shape[0], proj_shape[2])\n            astra_vol_shape = self.reco_space.shape\n\n        self.in_array = np.empty(astra_vol_shape,\n                                 dtype='float32', order='C')\n        self.out_array = np.empty(astra_proj_shape,\n                                  dtype='float32', order='C')\n\n        # Create ASTRA data structures\n        vol_geom = astra_volume_geometry(self.reco_space)\n        proj_geom = astra_projection_geometry(self.geometry)\n        self.vol_id = astra_data(vol_geom,\n                                 datatype='volume',\n                                 ndim=self.reco_space.ndim,\n                                 data=self.in_array,\n                                 allow_copy=False)\n\n        self.proj_id = astra_projector('nearest', vol_geom, proj_geom,\n                                       ndim=proj_ndim, impl='cuda')\n\n        self.sino_id = astra_data(proj_geom,\n                                  datatype='projection',\n                                  ndim=proj_ndim,\n                                  data=self.out_array,\n                                  allow_copy=False)\n\n        # Create algorithm\n        self.algo_id = astra_algorithm(\n            'forward', proj_ndim, self.vol_id, self.sino_id,\n            proj_id=self.proj_id, impl='cuda')", "response": "Create the internal arrays and objects for the internal structures."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call_backward(self, proj_data, out=None):\n        with self._mutex:\n            assert proj_data in self.proj_space\n            if out is not None:\n                assert out in self.reco_space\n            else:\n                out = self.reco_space.element()\n\n            # Copy data to GPU memory\n            if self.geometry.ndim == 2:\n                astra.data2d.store(self.sino_id, proj_data.asarray())\n            elif self.geometry.ndim == 3:\n                shape = (-1,) + self.geometry.det_partition.shape\n                reshaped_proj_data = proj_data.asarray().reshape(shape)\n                swapped_proj_data = np.ascontiguousarray(\n                    np.swapaxes(reshaped_proj_data, 0, 1))\n                astra.data3d.store(self.sino_id, swapped_proj_data)\n\n            # Run algorithm\n            astra.algorithm.run(self.algo_id)\n\n            # Copy result to CPU memory\n            out[:] = self.out_array\n\n            # Fix scaling to weight by pixel/voxel size\n            out *= astra_cuda_bp_scaling_factor(\n                self.proj_space, self.reco_space, self.geometry)\n\n            return out", "response": "Run an ASTRA back - projection on the given data using the GPU."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the minimum matching signature for given dtypes.", "response": "def find_min_signature(ufunc, dtypes_in):\n    \"\"\"Determine the minimum matching ufunc signature for given dtypes.\n\n    Parameters\n    ----------\n    ufunc : str or numpy.ufunc\n        Ufunc whose signatures are to be considered.\n    dtypes_in :\n        Sequence of objects specifying input dtypes. Its length must match\n        the number of inputs of ``ufunc``, and its entries must be understood\n        by `numpy.dtype`.\n\n    Returns\n    -------\n    signature : str\n        Minimum matching ufunc signature, see, e.g., ``np.add.types``\n        for examples.\n\n    Raises\n    ------\n    TypeError\n        If no valid signature is found.\n    \"\"\"\n    if not isinstance(ufunc, np.ufunc):\n        ufunc = getattr(np, str(ufunc))\n\n    dtypes_in = [np.dtype(dt_in) for dt_in in dtypes_in]\n    tcs_in = [dt.base.char for dt in dtypes_in]\n\n    if len(tcs_in) != ufunc.nin:\n        raise ValueError('expected {} input dtype(s) for {}, got {}'\n                         ''.format(ufunc.nin, ufunc, len(tcs_in)))\n\n    valid_sigs = []\n    for sig in ufunc.types:\n        sig_tcs_in, sig_tcs_out = sig.split('->')\n        if all(np.dtype(tc_in) <= np.dtype(sig_tc_in) and\n               sig_tc_in in SUPP_TYPECODES\n               for tc_in, sig_tc_in in zip(tcs_in, sig_tcs_in)):\n            valid_sigs.append(sig)\n\n    if not valid_sigs:\n        raise TypeError('no valid signature found for {} and input dtypes {}'\n                        ''.format(ufunc, tuple(dt.name for dt in dtypes_in)))\n\n    def in_dtypes(sig):\n        \"\"\"Comparison key function for input dtypes of a signature.\"\"\"\n        sig_tcs_in = sig.split('->')[0]\n        return tuple(np.dtype(tc) for tc in sig_tcs_in)\n\n    return min(valid_sigs, key=in_dtypes)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the result dtype of ufunc with inputs of given dtypes.", "response": "def dtypes_out(ufunc, dtypes_in):\n    \"\"\"Return the result dtype(s) of ``ufunc`` with inputs of given dtypes.\"\"\"\n    sig = find_min_signature(ufunc, dtypes_in)\n    tcs_out = sig.split('->')[1]\n    return tuple(np.dtype(tc) for tc in tcs_out)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating gradient function for some ufuncs.", "response": "def gradient_factory(name):\n    \"\"\"Create gradient `Functional` for some ufuncs.\"\"\"\n\n    if name == 'sin':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return cos(self.domain)\n    elif name == 'cos':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return -sin(self.domain)\n    elif name == 'tan':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return 1 + square(self.domain) * self\n    elif name == 'sqrt':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return FunctionalQuotient(ConstantFunctional(self.domain, 0.5),\n                                      self)\n    elif name == 'square':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return ScalingFunctional(self.domain, 2.0)\n    elif name == 'log':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return reciprocal(self.domain)\n    elif name == 'exp':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return self\n    elif name == 'reciprocal':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return FunctionalQuotient(ConstantFunctional(self.domain, -1.0),\n                                      square(self.domain))\n    elif name == 'sinh':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return cosh(self.domain)\n    elif name == 'cosh':\n        def gradient(self):\n            \"\"\"Return the gradient operator.\"\"\"\n            return sinh(self.domain)\n    else:\n        # Fallback to default\n        gradient = Functional.gradient\n\n    return gradient"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef derivative_factory(name):\n\n    if name == 'sin':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            return MultiplyOperator(cos(self.domain)(point))\n    elif name == 'cos':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            point = self.domain.element(point)\n            return MultiplyOperator(-sin(self.domain)(point))\n    elif name == 'tan':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            return MultiplyOperator(1 + self(point) ** 2)\n    elif name == 'sqrt':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            return MultiplyOperator(0.5 / self(point))\n    elif name == 'square':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            point = self.domain.element(point)\n            return MultiplyOperator(2.0 * point)\n    elif name == 'log':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            point = self.domain.element(point)\n            return MultiplyOperator(1.0 / point)\n    elif name == 'exp':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            return MultiplyOperator(self(point))\n    elif name == 'reciprocal':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            point = self.domain.element(point)\n            return MultiplyOperator(-self(point) ** 2)\n    elif name == 'sinh':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            point = self.domain.element(point)\n            return MultiplyOperator(cosh(self.domain)(point))\n    elif name == 'cosh':\n        def derivative(self, point):\n            \"\"\"Return the derivative operator.\"\"\"\n            return MultiplyOperator(sinh(self.domain)(point))\n    else:\n        # Fallback to default\n        derivative = Operator.derivative\n\n    return derivative", "response": "Create derivative function for some ufuncs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ufunc_class_factory(name, nargin, nargout, docstring):\n\n    assert 0 <= nargin <= 2\n\n    def __init__(self, space):\n        \"\"\"Initialize an instance.\n\n        Parameters\n        ----------\n        space : `TensorSpace`\n            The domain of the operator.\n        \"\"\"\n        if not isinstance(space, LinearSpace):\n            raise TypeError('`space` {!r} not a `LinearSpace`'.format(space))\n\n        if nargin == 1:\n            domain = space0 = space\n            dtypes = [space.dtype]\n        elif nargin == len(space) == 2 and isinstance(space, ProductSpace):\n            domain = space\n            space0 = space[0]\n            dtypes = [space[0].dtype, space[1].dtype]\n        else:\n            domain = ProductSpace(space, nargin)\n            space0 = space\n            dtypes = [space.dtype, space.dtype]\n\n        dts_out = dtypes_out(name, dtypes)\n\n        if nargout == 1:\n            range = space0.astype(dts_out[0])\n        else:\n            range = ProductSpace(space0.astype(dts_out[0]),\n                                 space0.astype(dts_out[1]))\n\n        linear = name in LINEAR_UFUNCS\n        Operator.__init__(self, domain=domain, range=range, linear=linear)\n\n    def _call(self, x, out=None):\n        \"\"\"Return ``self(x)``.\"\"\"\n        # TODO: use `__array_ufunc__` when implemented on `ProductSpace`,\n        # or try both\n        if out is None:\n            if nargin == 1:\n                return getattr(x.ufuncs, name)()\n            else:\n                return getattr(x[0].ufuncs, name)(*x[1:])\n        else:\n            if nargin == 1:\n                return getattr(x.ufuncs, name)(out=out)\n            else:\n                return getattr(x[0].ufuncs, name)(*x[1:], out=out)\n\n    def __repr__(self):\n        \"\"\"Return ``repr(self)``.\"\"\"\n        return '{}({!r})'.format(name, self.domain)\n\n    # Create example (also functions as doctest)\n    if 'shift' in name or 'bitwise' in name or name == 'invert':\n        dtype = int\n    else:\n        dtype = float\n\n    space = tensor_space(3, dtype=dtype)\n    if nargin == 1:\n        vec = space.element([-1, 1, 2])\n        arg = '{}'.format(vec)\n        with np.errstate(all='ignore'):\n            result = getattr(vec.ufuncs, name)()\n    else:\n        vec = space.element([-1, 1, 2])\n        vec2 = space.element([3, 4, 5])\n        arg = '[{}, {}]'.format(vec, vec2)\n        with np.errstate(all='ignore'):\n            result = getattr(vec.ufuncs, name)(vec2)\n\n    if nargout == 2:\n        result_space = ProductSpace(vec.space, 2)\n        result = repr(result_space.element(result))\n\n    examples_docstring = RAW_EXAMPLES_DOCSTRING.format(space=space, name=name,\n                                                       arg=arg, result=result)\n    full_docstring = docstring + examples_docstring\n\n    attributes = {\"__init__\": __init__,\n                  \"_call\": _call,\n                  \"derivative\": derivative_factory(name),\n                  \"__repr__\": __repr__,\n                  \"__doc__\": full_docstring}\n\n    full_name = name + '_op'\n\n    return type(full_name, (Operator,), attributes)", "response": "Create a class from a given specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a ufunc functional from a given specification.", "response": "def ufunc_functional_factory(name, nargin, nargout, docstring):\n    \"\"\"Create a ufunc `Functional` from a given specification.\"\"\"\n\n    assert 0 <= nargin <= 2\n\n    def __init__(self, field):\n        \"\"\"Initialize an instance.\n\n        Parameters\n        ----------\n        field : `Field`\n            The domain of the functional.\n        \"\"\"\n        if not isinstance(field, Field):\n            raise TypeError('`field` {!r} not a `Field`'.format(space))\n\n        if _is_integer_only_ufunc(name):\n            raise ValueError(\"ufunc '{}' only defined with integral dtype\"\n                             \"\".format(name))\n\n        linear = name in LINEAR_UFUNCS\n        Functional.__init__(self, space=field, linear=linear)\n\n    def _call(self, x):\n        \"\"\"Return ``self(x)``.\"\"\"\n        if nargin == 1:\n            return getattr(np, name)(x)\n        else:\n            return getattr(np, name)(*x)\n\n    def __repr__(self):\n        \"\"\"Return ``repr(self)``.\"\"\"\n        return '{}({!r})'.format(name, self.domain)\n\n    # Create example (also functions as doctest)\n\n    if nargin != 1:\n        raise NotImplementedError('Currently not suppored')\n\n    if nargout != 1:\n        raise NotImplementedError('Currently not suppored')\n\n    space = RealNumbers()\n    val = 1.0\n    arg = '{}'.format(val)\n    with np.errstate(all='ignore'):\n        result = np.float64(getattr(np, name)(val))\n\n    examples_docstring = RAW_EXAMPLES_DOCSTRING.format(space=space, name=name,\n                                                       arg=arg, result=result)\n    full_docstring = docstring + examples_docstring\n\n    attributes = {\"__init__\": __init__,\n                  \"_call\": _call,\n                  \"gradient\": property(gradient_factory(name)),\n                  \"__repr__\": __repr__,\n                  \"__doc__\": full_docstring}\n\n    full_name = name + '_op'\n\n    return type(full_name, (Functional,), attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pdhg(x, f, g, L, niter, tau=None, sigma=None, **kwargs):\n    # Forward operator\n    if not isinstance(L, Operator):\n        raise TypeError('`op` {!r} is not an `Operator` instance'\n                        ''.format(L))\n\n    # Starting point\n    if x not in L.domain:\n        raise TypeError('`x` {!r} is not in the domain of `op` {!r}'\n                        ''.format(x, L.domain))\n\n    # Spaces\n    if f.domain != L.domain:\n        raise TypeError('`f.domain` {!r} must equal `op.domain` {!r}'\n                        ''.format(f.domain, L.domain))\n\n    # Step size parameters\n    tau, sigma = pdhg_stepsize(L, tau, sigma)\n\n    # Number of iterations\n    if not isinstance(niter, int) or niter < 0:\n        raise ValueError('`niter` {} not understood'\n                         ''.format(niter))\n\n    # Relaxation parameter\n    theta = kwargs.pop('theta', 1)\n    theta, theta_in = float(theta), theta\n    if not 0 <= theta <= 1:\n        raise ValueError('`theta` {} not in [0, 1]'\n                         ''.format(theta_in))\n\n    # Acceleration parameters\n    gamma_primal = kwargs.pop('gamma_primal', None)\n    if gamma_primal is not None:\n        gamma_primal, gamma_primal_in = float(gamma_primal), gamma_primal\n        if gamma_primal < 0:\n            raise ValueError('`gamma_primal` must be non-negative, got {}'\n                             ''.format(gamma_primal_in))\n\n    gamma_dual = kwargs.pop('gamma_dual', None)\n    if gamma_dual is not None:\n        gamma_dual, gamma_dual_in = float(gamma_dual), gamma_dual\n        if gamma_dual < 0:\n            raise ValueError('`gamma_dual` must be non-negative, got {}'\n                             ''.format(gamma_dual_in))\n\n    if gamma_primal is not None and gamma_dual is not None:\n        raise ValueError('Only one acceleration parameter can be used')\n\n    # Callback object\n    callback = kwargs.pop('callback', None)\n    if callback is not None and not callable(callback):\n        raise TypeError('`callback` {} is not callable'\n                        ''.format(callback))\n\n    # Initialize the relaxation variable\n    x_relax = kwargs.pop('x_relax', None)\n    if x_relax is None:\n        x_relax = x.copy()\n    elif x_relax not in L.domain:\n        raise TypeError('`x_relax` {} is not in the domain of '\n                        '`L` {}'.format(x_relax.space, L.domain))\n\n    # Initialize the dual variable\n    y = kwargs.pop('y', None)\n    if y is None:\n        y = L.range.zero()\n    elif y not in L.range:\n        raise TypeError('`y` {} is not in the range of `L` '\n                        '{}'.format(y.space, L.range))\n\n    # Get the proximals\n    proximal_primal = f.proximal\n    proximal_dual = g.convex_conj.proximal\n    proximal_constant = (gamma_primal is None) and (gamma_dual is None)\n    if proximal_constant:\n        # Pre-compute proximals for efficiency\n        proximal_dual_sigma = proximal_dual(sigma)\n        proximal_primal_tau = proximal_primal(tau)\n\n    # Temporary copy to store previous iterate\n    x_old = x.space.element()\n\n    # Temporaries\n    dual_tmp = L.range.element()\n    primal_tmp = L.domain.element()\n\n    for _ in range(niter):\n        # Copy required for relaxation\n        x_old.assign(x)\n\n        # Gradient ascent in the dual variable y\n        # Compute dual_tmp = y + sigma * L(x_relax)\n        L(x_relax, out=dual_tmp)\n        dual_tmp.lincomb(1, y, sigma, dual_tmp)\n\n        # Apply the dual proximal\n        if not proximal_constant:\n            proximal_dual_sigma = proximal_dual(sigma)\n        proximal_dual_sigma(dual_tmp, out=y)\n\n        # Gradient descent in the primal variable x\n        # Compute primal_tmp = x + (- tau) * L.derivative(x).adjoint(y)\n        L.derivative(x).adjoint(y, out=primal_tmp)\n        primal_tmp.lincomb(1, x, -tau, primal_tmp)\n\n        # Apply the primal proximal\n        if not proximal_constant:\n            proximal_primal_tau = proximal_primal(tau)\n        proximal_primal_tau(primal_tmp, out=x)\n\n        # Acceleration\n        if gamma_primal is not None:\n            theta = float(1 / np.sqrt(1 + 2 * gamma_primal * tau))\n            tau *= theta\n            sigma /= theta\n\n        if gamma_dual is not None:\n            theta = float(1 / np.sqrt(1 + 2 * gamma_dual * sigma))\n            tau /= theta\n            sigma *= theta\n\n        # Over-relaxation in the primal variable x\n        x_relax.lincomb(1 + theta, x, -theta, x_old)\n\n        if callback is not None:\n            callback(x)", "response": "r Returns a primal - dual hybrid - gradient algorithm for convex optimization problems with known saddle - point structure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pdhg_stepsize(L, tau=None, sigma=None):\n    if tau is not None and sigma is not None:\n        return float(tau), float(sigma)\n\n    L_norm = L.norm(estimate=True) if isinstance(L, Operator) else float(L)\n    if tau is None and sigma is None:\n        tau = sigma = np.sqrt(0.9) / L_norm\n        return tau, sigma\n    elif tau is None:\n        tau = 0.9 / (sigma * L_norm ** 2)\n        return tau, float(sigma)\n    else:  # sigma is None\n        sigma = 0.9 / (tau * L_norm ** 2)\n        return float(tau), sigma", "response": "r Default step sizes for the PDHG method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_image_sep2d(image, fh, fv, impl='numpy', padding=None):\n    # TODO: generalize for nD\n    impl, impl_in = str(impl).lower(), impl\n    if impl not in ('numpy', 'pyfftw'):\n        raise ValueError('`impl` {!r} not understood'\n                         ''.format(impl_in))\n\n    image = np.asarray(image)\n    if image.ndim != 2:\n        raise ValueError('`image` must be 2-dimensional, got image with '\n                         'ndim={}'.format(image.ndim))\n    if image.size == 0:\n        raise ValueError('`image` cannot have size 0')\n    if not np.issubsctype(image.dtype, np.floating):\n        image = image.astype(float)\n\n    fh = np.asarray(fh).astype(image.dtype)\n    if fh.ndim != 1:\n        raise ValueError('`fh` must be one-dimensional')\n    elif fh.size == 0:\n        raise ValueError('`fh` cannot have size 0')\n    elif fh.size > image.shape[0]:\n        raise ValueError('`fh` can be at most `image.shape[0]`, got '\n                         '{} > {}'.format(fh.size, image.shape[0]))\n\n    fv = np.asarray(fv).astype(image.dtype)\n    if fv.ndim != 1:\n        raise ValueError('`fv` must be one-dimensional')\n    elif fv.size == 0:\n        raise ValueError('`fv` cannot have size 0')\n    elif fv.size > image.shape[0]:\n        raise ValueError('`fv` can be at most `image.shape[1]`, got '\n                         '{} > {}'.format(fv.size, image.shape[1]))\n\n    # Pad image with zeros\n    if padding is None:\n        padding = min(max(len(fh), len(fv)) - 1, 64)\n\n    if padding != 0:\n        image_padded = np.pad(image, padding, mode='constant')\n    else:\n        image_padded = image.copy() if impl == 'pyfftw' else image\n\n    # Prepare filters for the convolution\n    def prepare_for_fft(filt, n_new):\n        \"\"\"Return padded and shifted filter ready for FFT.\n\n        The filter is padded with zeros to the new size, and then shifted\n        such that such that the middle element of old filter, i.e., the\n        one at index ``(len(filt) - 1) // 2`` ends up at index 0.\n        \"\"\"\n        mid = (len(filt) - 1) // 2\n        padded = np.zeros(n_new, dtype=filt.dtype)\n        padded[:len(filt) - mid] = filt[mid:]\n        padded[len(padded) - mid:] = filt[:mid]\n        return padded\n\n    fh = prepare_for_fft(fh, image_padded.shape[0])\n    fv = prepare_for_fft(fv, image_padded.shape[1])\n\n    # Perform the multiplication in Fourier space and apply inverse FFT\n    if impl == 'numpy':\n        image_ft = np.fft.rfftn(image_padded)\n        fh_ft = np.fft.fft(fh)\n        fv_ft = np.fft.rfft(fv)\n\n        image_ft *= fh_ft[:, None]\n        image_ft *= fv_ft[None, :]\n        # Important to specify the shape since `irfftn` cannot know the\n        # original shape\n        conv = np.fft.irfftn(image_ft, s=image_padded.shape)\n        if conv.dtype != image.dtype:\n            conv = conv.astype(image.dtype)\n\n    elif impl == 'pyfftw':\n        if not PYFFTW_AVAILABLE:\n            raise ValueError(\n                '`pyfftw` package is not available; you need to install it '\n                'to use the pyfftw backend')\n\n        import pyfftw\n        import multiprocessing\n\n        # Generate output arrays, for half-complex transform of image and\n        # vertical filter, and full FT of the horizontal filter\n        out_img_shape = (image_padded.shape[0], image_padded.shape[1] // 2 + 1)\n        out_img_dtype = np.result_type(image_padded, 1j)\n        out_img = np.empty(out_img_shape, out_img_dtype)\n\n        out_fh_shape = out_img_shape[0]\n        out_fh_dtype = np.result_type(fh, 1j)\n        fh_c = fh.astype(out_fh_dtype)  # need to make this a C2C trafo\n        out_fh = np.empty(out_fh_shape, out_fh_dtype)\n\n        out_fv_shape = out_img_shape[1]\n        out_fv_dtype = np.result_type(fv, 1j)\n        out_fv = np.empty(out_fv_shape, out_fv_dtype)\n\n        # Perform the forward transforms of image and filters. We use\n        # the `FFTW_ESTIMATE` flag to not allow the planner to destroy\n        # the input.\n        plan = pyfftw.FFTW(image_padded, out_img, axes=(0, 1),\n                           direction='FFTW_FORWARD',\n                           flags=['FFTW_ESTIMATE'],\n                           threads=multiprocessing.cpu_count())\n        plan(image_padded, out_img)\n\n        plan = pyfftw.FFTW(fh_c, out_fh, axes=(0,),\n                           direction='FFTW_FORWARD',\n                           flags=['FFTW_ESTIMATE'],\n                           threads=multiprocessing.cpu_count())\n        plan(fh_c, out_fh)\n\n        plan = pyfftw.FFTW(fv, out_fv, axes=(0,),\n                           direction='FFTW_FORWARD',\n                           flags=['FFTW_ESTIMATE'],\n                           threads=multiprocessing.cpu_count())\n        plan(fv, out_fv)\n\n        # Fourier space multiplication\n        out_img *= out_fh[:, None]\n        out_img *= out_fv[None, :]\n\n        # Inverse trafo\n        conv = image_padded  # Overwrite\n        plan = pyfftw.FFTW(out_img.copy(), conv, axes=(0, 1),\n                           direction='FFTW_BACKWARD',\n                           flags=['FFTW_ESTIMATE'],\n                           threads=multiprocessing.cpu_count())\n        plan(out_img, conv)\n\n    else:\n        raise ValueError('unsupported `impl` {!r}'.format(impl_in))\n\n    if padding:\n        return conv[padding:-padding, padding:-padding]\n    else:\n        return conv", "response": "Filter an image with a separable filter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef haarpsi_weight_map(img1, img2, axis):\n    # TODO: generalize for nD\n    impl = 'pyfftw' if PYFFTW_AVAILABLE else 'numpy'\n\n    # Haar wavelet filters for level 3\n    dec_lo_lvl3 = np.repeat([np.sqrt(2), np.sqrt(2)], 4)\n    dec_hi_lvl3 = np.repeat([-np.sqrt(2), np.sqrt(2)], 4)\n\n    if axis == 0:\n        fh_lvl3 = dec_hi_lvl3\n        fv_lvl3 = dec_lo_lvl3\n    elif axis == 1:\n        fh_lvl3 = dec_lo_lvl3\n        fv_lvl3 = dec_hi_lvl3\n    else:\n        raise ValueError('`axis` out of the valid range 0 -> 1')\n\n    # Filter with level 3 wavelet filter\n    img1_lvl3 = filter_image_sep2d(img1, fh_lvl3, fv_lvl3, impl=impl)\n    img2_lvl3 = filter_image_sep2d(img2, fh_lvl3, fv_lvl3, impl=impl)\n\n    # Return the pointwise maximum of the filtered images\n    np.abs(img1_lvl3, out=img1_lvl3)\n    np.abs(img2_lvl3, out=img2_lvl3)\n\n    return np.maximum(img1_lvl3, img2_lvl3)", "response": "r Weights a set of images along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsums image values over concentric annuli.", "response": "def spherical_sum(image, binning_factor=1.0):\n    \"\"\"Sum image values over concentric annuli.\n\n    Parameters\n    ----------\n    image : `DiscreteLp` element\n        Input data whose radial sum should be computed.\n    binning_factor : positive float, optional\n        Reduce the number of output bins by this factor. Increasing this\n        number can help reducing fluctuations due to the variance of points\n        that fall in a particular annulus.\n        A binning factor of ``1`` corresponds to a bin size equal to\n        image pixel size for images with square pixels, otherwise ::\n\n            max(norm2(c)) / norm2(shape)\n\n        where the maximum is taken over all corners of the image domain.\n\n    Returns\n    -------\n    spherical_sum : 1D `DiscreteLp` element\n        The spherical sum of ``image``. Its space is one-dimensional with\n        domain ``[0, rmax]``, where ``rmax`` is the radius of the smallest\n        ball containing ``image.space.domain``. Its shape is ``(N,)`` with ::\n\n            N = int(sqrt(sum(n ** 2 for n in image.shape)) / binning_factor)\n    \"\"\"\n    r = np.sqrt(sum(xi ** 2 for xi in image.space.meshgrid))\n    rmax = max(np.linalg.norm(c) for c in image.space.domain.corners())\n    n_bins = int(np.sqrt(sum(n ** 2 for n in image.shape)) / binning_factor)\n    rad_sum, _ = np.histogram(r, weights=image, bins=n_bins, range=(0, rmax))\n\n    out_spc = uniform_discr(min_pt=0, max_pt=rmax, shape=n_bins,\n                            impl=image.space.impl, dtype=image.space.dtype,\n                            interp=\"linear\", axis_labels=[\"$r$\"])\n\n    return out_spc.element(rad_sum)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simple_functional(space, fcall=None, grad=None, prox=None, grad_lip=np.nan,\n                      convex_conj_fcall=None, convex_conj_grad=None,\n                      convex_conj_prox=None, convex_conj_grad_lip=np.nan,\n                      linear=False):\n    \"\"\"Simplified interface to create a functional with specific properties.\n\n    Users may specify as many properties as-is needed by the application.\n\n    Parameters\n    ----------\n    space : `LinearSpace`\n        Space that the functional should act on.\n    fcall : callable, optional\n        Function to evaluate when calling the functional.\n    grad : callable or `Operator`, optional\n        Gradient operator of the functional.\n    prox : `proximal factory`, optional\n        Proximal factory for the functional.\n    grad_lip : float, optional\n        lipschitz constant of the functional.\n    convex_conj_fcall : callable, optional\n        Function to evaluate when calling the convex conjugate functional.\n    convex_conj_grad : callable or `Operator`, optional\n        Gradient operator of the convex conjugate functional\n    convex_conj_prox : `proximal factory`, optional\n        Proximal factory for the convex conjugate functional.\n    convex_conj_grad_lip : float, optional\n        lipschitz constant of the convex conjugate functional.\n    linear : bool, optional\n        True if the operator is linear.\n\n    Examples\n    --------\n    Create squared sum functional on rn:\n\n    >>> def f(x):\n    ...     return sum(xi**2 for xi in x)\n    >>> def dfdx(x):\n    ...     return 2 * x\n    >>> space = odl.rn(3)\n    >>> func = simple_functional(space, f, grad=dfdx)\n    >>> func.domain\n    rn(3)\n    >>> func.range\n    RealNumbers()\n    >>> func([1, 2, 3])\n    14.0\n    >>> func.gradient([1, 2, 3])\n    rn(3).element([ 2.,  4.,  6.])\n    \"\"\"\n    if grad is not None and not isinstance(grad, Operator):\n        grad_in = grad\n\n        class SimpleFunctionalGradient(Operator):\n\n            \"\"\"Gradient of a `SimpleFunctional`.\"\"\"\n\n            def _call(self, x):\n                \"\"\"Return ``self(x)``.\"\"\"\n                return grad_in(x)\n\n        grad = SimpleFunctionalGradient(space, space, linear=False)\n\n    if (convex_conj_grad is not None and\n            not isinstance(convex_conj_grad, Operator)):\n        convex_conj_grad_in = convex_conj_grad\n\n        class SimpleFunctionalConvexConjGradient(Operator):\n\n            \"\"\"Gradient of the convex conj of a  `SimpleFunctional`.\"\"\"\n\n            def _call(self, x):\n                \"\"\"Return ``self(x)``.\"\"\"\n                return convex_conj_grad_in(x)\n\n        convex_conj_grad = SimpleFunctionalConvexConjGradient(\n            space, space, linear=False)\n\n    class SimpleFunctional(Functional):\n\n        \"\"\"A simplified functional for examples.\"\"\"\n\n        def __init__(self):\n            \"\"\"Initialize an instance.\"\"\"\n            super(SimpleFunctional, self).__init__(\n                space, linear=linear, grad_lipschitz=grad_lip)\n\n        def _call(self, x):\n            \"\"\"Return ``self(x)``.\"\"\"\n            if fcall is None:\n                raise NotImplementedError('call not implemented')\n            else:\n                return fcall(x)\n\n        @property\n        def proximal(self):\n            \"\"\"Return the proximal of the operator.\"\"\"\n            if prox is None:\n                raise NotImplementedError('proximal not implemented')\n            else:\n                return prox\n\n        @property\n        def gradient(self):\n            \"\"\"Return the gradient of the operator.\"\"\"\n            if grad is None:\n                raise NotImplementedError('gradient not implemented')\n            else:\n                return grad\n\n        @property\n        def convex_conj(self):\n            return simple_functional(space, fcall=convex_conj_fcall,\n                                     grad=convex_conj_grad,\n                                     prox=convex_conj_prox,\n                                     grad_lip=convex_conj_grad_lip,\n                                     convex_conj_fcall=fcall,\n                                     convex_conj_grad=grad,\n                                     convex_conj_prox=prox,\n                                     convex_conj_grad_lip=grad_lip,\n                                     linear=linear)\n\n    return SimpleFunctional()", "response": "Simplified interface to create a functional with specific properties."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convex_conj(self):\n        if self.scalar <= 0:\n            raise ValueError('scaling with nonpositive values have no convex '\n                             'conjugate. Current value: {}.'\n                             ''.format(self.scalar))\n\n        return self.scalar * self.functional.convex_conj * (1.0 / self.scalar)", "response": "Convex conjugate functional of the scaled functional."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the gradient of the compositon.", "response": "def gradient(self):\n        \"\"\"Gradient of the compositon according to the chain rule.\"\"\"\n        func = self.left\n        op = self.right\n\n        class FunctionalCompositionGradient(Operator):\n\n            \"\"\"Gradient of the compositon according to the chain rule.\"\"\"\n\n            def __init__(self):\n                \"\"\"Initialize a new instance.\"\"\"\n                super(FunctionalCompositionGradient, self).__init__(\n                    op.domain, op.domain, linear=False)\n\n            def _call(self, x):\n                \"\"\"Apply the gradient operator to the given point.\"\"\"\n                return op.derivative(x).adjoint(func.gradient(op(x)))\n\n            def derivative(self, x):\n                \"\"\"The derivative in point ``x``.\n\n                This is only defined\n                \"\"\"\n                if not op.is_linear:\n                    raise NotImplementedError('derivative only implemented '\n                                              'for linear opertors.')\n                else:\n                    return (op.adjoint * func.gradient * op).derivative(x)\n\n        return FunctionalCompositionGradient()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the functional to the given point.", "response": "def _call(self, x):\n        \"\"\"Apply the functional to the given point.\"\"\"\n        return (self.functional(x) +\n                self.quadratic_coeff * x.inner(x) +\n                x.inner(self.linear_term) + self.constant)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the convex conjugate functional of the functional.", "response": "def convex_conj(self):\n        r\"\"\"Convex conjugate functional of the functional.\n\n        Notes\n        -----\n        Given a functional :math:`f`, the convex conjugate of a linearly\n        perturbed version :math:`f(x) + <y, x>` is given by a translation of\n        the convex conjugate of :math:`f`:\n\n        .. math::\n            (f + \\langle y, \\cdot \\rangle)^* (x^*) = f^*(x^* - y).\n\n        For reference on the identity used, see `[KP2015]`_. Moreover, the\n        convex conjugate of :math:`f + c` is by definition\n\n        .. math::\n            (f + c)^* (x^*) = f^*(x^*) - c.\n\n\n        References\n        ----------\n        [KP2015] Komodakis, N, and Pesquet, J-C. *Playing with Duality: An\n        overview of recent primal-dual approaches for solving large-scale\n        optimization problems*. IEEE Signal Processing Magazine, 32.6 (2015),\n        pp 31--54.\n\n        .. _[KP2015]:  https://arxiv.org/abs/1406.5429\n        \"\"\"\n        if self.quadratic_coeff == 0:\n            cconj = self.functional.convex_conj.translated(self.linear_term)\n            if self.constant != 0:\n                cconj = cconj - self.constant\n            return cconj\n        else:\n            return super(FunctionalQuadraticPerturb, self).convex_conj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gradient(self):\n        func = self\n\n        class FunctionalProductGradient(Operator):\n\n            \"\"\"Functional representing the gradient of ``f(.) * g(.)``.\"\"\"\n\n            def _call(self, x):\n                return (func.right(x) * func.left.gradient(x) +\n                        func.left(x) * func.right.gradient(x))\n\n        return FunctionalProductGradient(self.domain, self.domain,\n                                         linear=False)", "response": "r Gradient operator of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gradient(self):\n        try:\n            op_to_return = self.functional.gradient\n        except NotImplementedError:\n            raise NotImplementedError(\n                '`self.functional.gradient` is not implemented for '\n                '`self.functional` {}'.format(self.functional))\n\n        op_to_return = op_to_return - ConstantOperator(self.subgrad)\n        return op_to_return", "response": "Gradient operator of the functional."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef estimate_noise_std(img, average=True):\n    import scipy.signal\n    import functools\n    img = np.asarray(img, dtype='float')\n\n    M = functools.reduce(np.add.outer, [[-1, 2, -1]] * img.ndim)\n\n    convolved = scipy.signal.fftconvolve(img, M, mode='valid')\n    if average:\n        conv_var = np.sum(convolved ** 2) / convolved.size\n    else:\n        conv_var = convolved ** 2\n\n        # Pad in order to retain shape\n        conv_var = np.pad(conv_var, pad_width=1, mode='edge')\n\n    scale = np.sum(np.square(M))\n    sigma = np.sqrt(conv_var / scale)\n\n    return sigma", "response": "Estimate standard deviation of noise in an image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a default helical geometry from a given space.", "response": "def helical_geometry(space, src_radius, det_radius, num_turns,\n                     n_pi=1, num_angles=None, det_shape=None):\n    \"\"\"Create a default helical geometry from ``space``.\n\n    This function is intended for simple test cases where users do not\n    need the full flexibility of the geometries, but simply wants a\n    geometry that works.\n\n    The geometry returned by this function has equidistant angles\n    that lie (strictly) between 0 and ``2 * pi * num_turns``.\n    The detector is centered around 0, and its size is chosen such that\n    the whole ``space`` is covered with lines.\n\n    The number of angles and detector elements is chosen such that\n    the resulting sinogram is fully sampled according to the\n    Nyquist criterion, which in general results in a very large number of\n    samples. In particular, a ``space`` that is not centered at the origin\n    can result in very large detectors since the latter is always\n    origin-centered.\n\n    Parameters\n    ----------\n    space : `DiscreteLp`\n        Reconstruction space, the space of the volumetric data to be\n        projected. Must be 3-dimensional.\n    src_radius : nonnegative float\n        Radius of the source circle. Must be larger than the radius of\n        the smallest vertical cylinder containing ``space.domain``,\n        i.e., the source must be outside the volume for all rotations.\n    det_radius : nonnegative float\n        Radius of the detector circle.\n    num_turns : positive float\n        Total number of helical turns.\n    num_angles : int, optional\n        Number of angles.\n        Default: Enough to fully sample the data, see Notes.\n    n_pi : odd int, optional\n        Total number of half rotations to include in the window. Values larger\n        than 1 should be used if the pitch is much smaller than the detector\n        height.\n    det_shape : int or sequence of ints, optional\n        Number of detector pixels.\n        Default: Enough to fully sample the data, see Notes.\n\n    Returns\n    -------\n    geometry : `ConeFlatGeometry`\n        Projection geometry with equidistant angles and zero-centered\n        detector as determined by sampling criteria.\n\n    Examples\n    --------\n    Create a helical beam geometry from space:\n\n    >>> space = odl.uniform_discr([-1, -1, -1], [1, 1, 1], (20, 20, 20))\n    >>> geometry = helical_geometry(space, src_radius=5, det_radius=5,\n    ...                             num_turns=3)\n    >>> geometry.angles.size\n    234\n    >>> geometry.detector.shape\n    (57, 9)\n\n    Notes\n    -----\n    In the \"fan beam direction\", the sampling exactly follows the\n    two-dimensional case see `cone_beam_geometry` for a description.\n\n    In the \"axial direction\", e.g. along the [0, 0, 1] axis, the geometry is\n    sampled according to two criteria. First, the bounds of the detector\n    are chosen to satisfy the tuy condition.\n    See `[TSS1998]`_ for a full description.\n\n    Second, the sampling rate is selected according to the nyquist criterion\n    to give a full sampling. This is done by sampling such that the pixel\n    size is half of the size of the projection of the smallest voxel onto the\n    detector.\n\n    References\n    ----------\n    [TSS1998] Tam, K C, Samarasekera, S and Sauer, F.\n    *Exact cone beam CT with a spiral scan*.\n    Physics in Medicine & Biology 4 (1998), p 1015.\n\n    .. _[TSS1998]: https://dx.doi.org/10.1088/0031-9155/43/4/028\n    \"\"\"\n    # Find maximum distance from rotation axis\n    corners = space.domain.corners()[:, :2]\n    rho = np.max(np.linalg.norm(corners, axis=1))\n\n    offset_along_axis = space.partition.min_pt[2]\n    pitch = space.partition.extent[2] / num_turns\n\n    # Find default values according to Nyquist criterion.\n\n    # We assume that the function is bandlimited by a wave along the x or y\n    # axis. The highest frequency we can measure is then a standing wave with\n    # period of twice the inter-node distance.\n    min_side = min(space.partition.cell_sides[:2])\n    omega = np.pi / min_side\n\n    # Compute minimum width of the detector to cover the object. The relation\n    # used here is (w/2)/(rs+rd) = rho/rs since both are equal to tan(alpha),\n    # where alpha is the half fan angle.\n    rs = float(src_radius)\n    if (rs <= rho):\n        raise ValueError('source too close to the object, resulting in '\n                         'infinite detector for full coverage')\n    rd = float(det_radius)\n    r = rs + rd\n    w = 2 * rho * (rs + rd) / rs\n\n    # Compute minimum number of pixels given the constraint on the\n    # sampling interval and the computed width\n    rb = np.hypot(r, w / 2)  # length of the boundary ray to the flat detector\n    num_px_horiz = 2 * int(np.ceil(w * omega * r / (2 * np.pi * rb))) + 1\n\n    # Compute lower and upper bound needed to fully sample the object.\n    # In particular, since in a helical geometry several turns are used,\n    # this is selected so that the field of view of two opposing projections,\n    # separated by theta = 180 deg, overlap, but as little as possible.\n    # See `tam_danielson_window` for more information.\n    h_axis = (pitch / (2 * np.pi) *\n              (1 + (-rho / src_radius) ** 2) *\n              (n_pi * np.pi / 2.0 - np.arctan(-rho / src_radius)))\n    h = 2 * h_axis * (rs + rd) / rs\n\n    # Compute number of pixels\n    min_mag = r / rs\n    dh = 0.5 * space.partition.cell_sides[2] * min_mag\n    num_px_vert = int(np.ceil(h / dh))\n\n    det_min_pt = [-w / 2, -h / 2]\n    det_max_pt = [w / 2, h / 2]\n    if det_shape is None:\n        det_shape = [num_px_horiz, num_px_vert]\n\n    max_angle = 2 * np.pi * num_turns\n\n    if num_angles is None:\n        num_angles = int(np.ceil(max_angle * omega * rho / np.pi\n                                 * r / (r + rho)))\n\n    angle_partition = uniform_partition(0, max_angle, num_angles)\n    det_partition = uniform_partition(det_min_pt, det_max_pt, det_shape)\n\n    return ConeFlatGeometry(angle_partition, det_partition,\n                            src_radius, det_radius,\n                            offset_along_axis=offset_along_axis,\n                            pitch=pitch)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an instance of FanBeamGeometry from a matrix.", "response": "def frommatrix(cls, apart, dpart, src_radius, det_radius, init_matrix,\n                   det_curvature_radius=None, **kwargs):\n        \"\"\"Create an instance of `FanBeamGeometry` using a matrix.\n\n        This alternative constructor uses a matrix to rotate and\n        translate the default configuration. It is most useful when\n        the transformation to be applied is already given as a matrix.\n\n        Parameters\n        ----------\n        apart : 1-dim. `RectPartition`\n            Partition of the angle interval.\n        dpart : 1-dim. `RectPartition`\n            Partition of the detector parameter interval.\n        src_radius : nonnegative float\n            Radius of the source circle.\n        det_radius : nonnegative float\n            Radius of the detector circle. Must be nonzero if ``src_radius``\n            is zero.\n        init_matrix : `array_like`, shape ``(2, 2)`` or ``(2, 3)``, optional\n            Transformation matrix whose left ``(2, 2)`` block is multiplied\n            with the default ``det_pos_init`` and ``det_axis_init`` to\n            determine the new vectors. If present, the third column acts\n            as a translation after the initial transformation.\n            The resulting ``det_axis_init`` will be normalized.\n        det_curvature_radius : nonnegative float, optional\n            Radius of the detector curvature.\n            If ``None``, flat detector is used, otherwise must be positive.\n        kwargs :\n            Further keyword arguments passed to the class constructor.\n\n        Returns\n        -------\n        geometry : `FanBeamGeometry`\n\n        Examples\n        --------\n        Mirror the second unit vector, creating a left-handed system:\n\n        >>> apart = odl.uniform_partition(0, np.pi, 10)\n        >>> dpart = odl.uniform_partition(-1, 1, 20)\n        >>> matrix = np.array([[1, 0],\n        ...                    [0, -1]])\n        >>> geom = FanBeamGeometry.frommatrix(\n        ...     apart, dpart, src_radius=1, det_radius=5, init_matrix=matrix)\n        >>> geom.det_refpoint(0)\n        array([ 0., -5.])\n        >>> geom.det_axis_init\n        array([ 1.,  0.])\n        >>> geom.translation\n        array([ 0.,  0.])\n\n        Adding a translation with a third matrix column:\n\n        >>> matrix = np.array([[1, 0, 1],\n        ...                    [0, -1, 1]])\n        >>> geom = FanBeamGeometry.frommatrix(\n        ...     apart, dpart, src_radius=1, det_radius=5, init_matrix=matrix)\n        >>> geom.translation\n        array([ 1.,  1.])\n        >>> geom.det_refpoint(0)  # (0, -5) + (1, 1)\n        array([ 1., -4.])\n        \"\"\"\n        # Get transformation and translation parts from `init_matrix`\n        init_matrix = np.asarray(init_matrix, dtype=float)\n        if init_matrix.shape not in ((2, 2), (2, 3)):\n            raise ValueError('`matrix` must have shape (2, 2) or (2, 3), '\n                             'got array with shape {}'\n                             ''.format(init_matrix.shape))\n        trafo_matrix = init_matrix[:, :2]\n        translation = init_matrix[:, 2:].squeeze()\n\n        # Transform the default vectors\n        default_src_to_det_init = cls._default_config['src_to_det_init']\n        default_det_axis_init = cls._default_config['det_axis_init']\n        vecs_to_transform = [default_det_axis_init]\n        transformed_vecs = transform_system(\n            default_src_to_det_init, None, vecs_to_transform,\n            matrix=trafo_matrix)\n\n        # Use the standard constructor with these vectors\n        src_to_det, det_axis = transformed_vecs\n        if translation.size != 0:\n            kwargs['translation'] = translation\n\n        return cls(apart, dpart, src_radius, det_radius, det_curvature_radius,\n                   src_to_det, det_axis_init=det_axis, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef src_position(self, angle):\n        squeeze_out = (np.shape(angle) == ())\n        angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n\n        # Initial vector from the rotation center to the source. It can be\n        # computed this way since source and detector are at maximum distance,\n        # i.e. the connecting line passes the origin.\n        center_to_src_init = -self.src_radius * self.src_to_det_init\n        pos_vec = (self.translation[None, :]\n                   + self.rotation_matrix(angle).dot(center_to_src_init))\n        if squeeze_out:\n            pos_vec = pos_vec.squeeze()\n\n        return pos_vec", "response": "Return the source position at an angle."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the detector reference point position at an angle.", "response": "def det_refpoint(self, angle):\n        \"\"\"Return the detector reference point position at ``angle``.\n\n        For an angle ``phi``, the detector position is given by ::\n\n            det_ref(phi) = translation +\n                           rot_matrix(phi) * (det_rad * src_to_det_init)\n\n        where ``src_to_det_init`` is the initial unit vector pointing\n        from source to detector.\n\n        Parameters\n        ----------\n        angle : float or `array-like`\n            Angle(s) in radians describing the counter-clockwise\n            rotation of source and detector.\n\n        Returns\n        -------\n        point : `numpy.ndarray`\n            Vector(s) pointing from the origin to the detector reference\n            point. If ``angle`` is a single parameter, the returned array\n            has shape ``(2,)``, otherwise ``angle.shape + (2,)``.\n\n        See Also\n        --------\n        src_position\n\n        Examples\n        --------\n        With default arguments, the detector starts at ``det_rad * e_y``\n        and rotates to ``det_rad * (-e_x)`` at 90 degrees:\n\n        >>> apart = odl.uniform_partition(0, 2 * np.pi, 10)\n        >>> dpart = odl.uniform_partition(-1, 1, 20)\n        >>> geom = FanBeamGeometry(apart, dpart, src_radius=2, det_radius=5)\n        >>> geom.det_refpoint(0)\n        array([ 0.,  5.])\n        >>> np.allclose(geom.det_refpoint(np.pi / 2), [-5, 0])\n        True\n\n        The method is vectorized, i.e., it can be called with multiple\n        angles at once:\n\n        >>> points = geom.det_refpoint([0, np.pi / 2])\n        >>> np.allclose(points[0], [0, 5])\n        True\n        >>> np.allclose(points[1], [-5, 0])\n        True\n        \"\"\"\n        squeeze_out = (np.shape(angle) == ())\n        angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n\n        # Initial vector from the rotation center to the detector. It can be\n        # computed this way since source and detector are at maximum distance,\n        # i.e. the connecting line passes the origin.\n        center_to_det_init = self.det_radius * self.src_to_det_init\n        refpt = (self.translation[None, :]\n                 + self.rotation_matrix(angle).dot(center_to_det_init))\n        if squeeze_out:\n            refpt = refpt.squeeze()\n\n        return refpt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef frommatrix(cls, apart, dpart, src_radius, det_radius, init_matrix,\n                   pitch=0, **kwargs):\n        \"\"\"Create an instance of `ConeFlatGeometry` using a matrix.\n\n        This alternative constructor uses a matrix to rotate and\n        translate the default configuration. It is most useful when\n        the transformation to be applied is already given as a matrix.\n\n        Parameters\n        ----------\n        apart : 1-dim. `RectPartition`\n            Partition of the parameter interval.\n        dpart : 2-dim. `RectPartition`\n            Partition of the detector parameter set.\n        src_radius : nonnegative float\n            Radius of the source circle.\n        det_radius : nonnegative float\n            Radius of the detector circle. Must be nonzero if ``src_radius``\n            is zero.\n        init_matrix : `array_like`, shape ``(3, 3)`` or ``(3, 4)``, optional\n            Transformation matrix whose left ``(3, 3)`` block is multiplied\n            with the default ``det_pos_init`` and ``det_axes_init`` to\n            determine the new vectors. If present, the fourth column acts\n            as a translation after the initial transformation.\n            The resulting ``det_axes_init`` will be normalized.\n        pitch : float, optional\n            Constant distance along the rotation axis that a point on the\n            helix traverses when increasing the angle parameter by\n            ``2 * pi``. The default case ``pitch=0`` results in a circular\n            cone beam geometry.\n        kwargs :\n            Further keyword arguments passed to the class constructor.\n\n        Returns\n        -------\n        geometry : `ConeFlatGeometry`\n\n        Examples\n        --------\n        Map unit vectors ``e_y -> e_z`` and ``e_z -> -e_y``, keeping the\n        right-handedness:\n\n        >>> apart = odl.uniform_partition(0, 2 * np.pi, 10)\n        >>> dpart = odl.uniform_partition([-1, -1], [1, 1], (20, 20))\n        >>> matrix = np.array([[1, 0, 0],\n        ...                    [0, 0, -1],\n        ...                    [0, 1, 0]])\n        >>> geom = ConeFlatGeometry.frommatrix(\n        ...     apart, dpart, src_radius=5, det_radius=10, pitch=2,\n        ...     init_matrix=matrix)\n        >>> geom.axis\n        array([ 0., -1.,  0.])\n        >>> geom.src_to_det_init\n        array([ 0.,  0.,  1.])\n        >>> geom.det_axes_init\n        array([[ 1.,  0.,  0.],\n               [ 0., -1.,  0.]])\n\n        Adding a translation with a fourth matrix column:\n\n        >>> matrix = np.array([[0, 0, -1, 0],\n        ...                    [0, 1, 0, 1],\n        ...                    [1, 0, 0, 1]])\n        >>> geom = ConeFlatGeometry.frommatrix(\n        ...     apart, dpart, src_radius=5, det_radius=10, pitch=2,\n        ...     init_matrix=matrix)\n        >>> geom.translation\n        array([ 0.,  1.,  1.])\n        >>> geom.det_refpoint(0)  # (0, 10, 0) + (0, 1, 1)\n        array([  0.,  11.,   1.])\n        \"\"\"\n        for key in ('axis', 'src_to_det_init', 'det_axes_init', 'translation'):\n            if key in kwargs:\n                raise TypeError('got unknown keyword argument {!r}'\n                                ''.format(key))\n\n        # Get transformation and translation parts from `init_matrix`\n        init_matrix = np.asarray(init_matrix, dtype=float)\n        if init_matrix.shape not in ((3, 3), (3, 4)):\n            raise ValueError('`matrix` must have shape (3, 3) or (3, 4), '\n                             'got array with shape {}'\n                             ''.format(init_matrix.shape))\n        trafo_matrix = init_matrix[:, :3]\n        translation = init_matrix[:, 3:].squeeze()\n\n        # Transform the default vectors\n        default_axis = cls._default_config['axis']\n        default_src_to_det_init = cls._default_config['src_to_det_init']\n        default_det_axes_init = cls._default_config['det_axes_init']\n        vecs_to_transform = (default_src_to_det_init,) + default_det_axes_init\n        transformed_vecs = transform_system(\n            default_axis, None, vecs_to_transform, matrix=trafo_matrix)\n\n        # Use the standard constructor with these vectors\n        axis, src_to_det, det_axis_0, det_axis_1 = transformed_vecs\n        if translation.size == 0:\n            pass\n        else:\n            kwargs['translation'] = translation\n\n        return cls(apart, dpart, src_radius, det_radius, pitch, axis,\n                   src_to_det_init=src_to_det,\n                   det_axes_init=[det_axis_0, det_axis_1],\n                   **kwargs)", "response": "Create an instance of the alternative class from a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef det_refpoint(self, angle):\n        squeeze_out = (np.shape(angle) == ())\n        angle = np.array(angle, dtype=float, copy=False, ndmin=1)\n        rot_matrix = self.rotation_matrix(angle)\n        extra_dims = angle.ndim\n\n        # Initial vector from center of rotation to detector.\n        # It can be computed this way since source and detector are at\n        # maximum distance, i.e. the connecting line passes the center.\n        center_to_det_init = self.det_radius * self.src_to_det_init\n        # `circle_component` has shape (a, ndim)\n        circle_component = rot_matrix.dot(center_to_det_init)\n\n        # Increment along the rotation axis according to pitch and\n        # offset_along_axis\n        # `shift_along_axis` has shape angles.shape\n        shift_along_axis = (self.offset_along_axis\n                            + self.pitch * angle / (2 * np.pi))\n        # Create outer product of `shift_along_axis` and `axis`, resulting\n        # in shape (a, ndim)\n        pitch_component = np.multiply.outer(shift_along_axis, self.axis)\n\n        # Broadcast translation along extra dimensions\n        transl_slc = (None,) * extra_dims + (slice(None),)\n        refpt = (self.translation[transl_slc]\n                 + circle_component\n                 + pitch_component)\n        if squeeze_out:\n            refpt = refpt.squeeze()\n\n        return refpt", "response": "Return the detector reference point position at an angle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef derivative(self, displacement):\n        # To implement the complex case we need to be able to embed the real\n        # vector field space into the range of the gradient. Issue #59.\n        if not self.range.is_real:\n            raise NotImplementedError('derivative not implemented for complex '\n                                      'spaces.')\n\n        displacement = self.domain.element(displacement)\n\n        # TODO: allow users to select what method to use here.\n        grad = Gradient(domain=self.range, method='central',\n                        pad_mode='symmetric')\n        grad_templ = grad(self.template)\n        def_grad = self.domain.element(\n            [linear_deform(gf, displacement) for gf in grad_templ])\n\n        return PointwiseInner(self.domain, def_grad)", "response": "Derivative of the operator at displacement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating 3d cylinders from ellipses.", "response": "def cylinders_from_ellipses(ellipses):\n    \"\"\"Create 3d cylinders from ellipses.\"\"\"\n    ellipses = np.asarray(ellipses)\n    ellipsoids = np.zeros((ellipses.shape[0], 10))\n    ellipsoids[:, [0, 1, 2, 4, 5, 7]] = ellipses\n    ellipsoids[:, 3] = 100000.0\n\n    return ellipsoids"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns elapsed crawl time as a float in seconds.", "response": "def elapsed(self):\n        '''\n        Returns elapsed crawl time as a float in seconds.\n\n        This metric includes all the time that a site was in active rotation,\n        including any time it spent waiting for its turn to be brozzled.\n\n        In contrast `Site.active_brozzling_time` only counts time when a\n        brozzler worker claimed the site and was actively brozzling it.\n        '''\n        dt = 0\n        for ss in self.starts_and_stops[:-1]:\n            dt += (ss['stop'] - ss['start']).total_seconds()\n        ss = self.starts_and_stops[-1]\n        if ss['stop']:\n            dt += (ss['stop'] - ss['start']).total_seconds()\n        else: # crawl is active\n            dt += (doublethink.utcnow() - ss['start']).total_seconds()\n        return dt"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef accept_reject_or_neither(self, url, parent_page=None):\n        '''\n        Returns `True` (accepted), `False` (rejected), or `None` (no decision).\n\n        `None` usually means rejected, unless `max_hops_off` comes into play.\n        '''\n        if not isinstance(url, urlcanon.ParsedUrl):\n            url = urlcanon.semantic(url)\n\n        if not url.scheme in (b'http', b'https'):\n            # XXX doesn't belong here maybe (where? worker ignores unknown\n            # schemes?)\n            return False\n\n        try_parent_urls = []\n        if parent_page:\n            try_parent_urls.append(urlcanon.semantic(parent_page.url))\n            if parent_page.redirect_url:\n                try_parent_urls.append(\n                        urlcanon.semantic(parent_page.redirect_url))\n\n        # enforce max_hops\n        if (parent_page and \"max_hops\" in self.scope\n                and parent_page.hops_from_seed >= self.scope[\"max_hops\"]):\n            return False\n\n        # enforce reject rules\n        if \"blocks\" in self.scope:\n            for block_rule in self.scope[\"blocks\"]:\n                rule = urlcanon.MatchRule(**block_rule)\n                if try_parent_urls:\n                    for parent_url in try_parent_urls:\n                        if rule.applies(url, parent_url):\n                           return False\n                else:\n                    if rule.applies(url):\n                        return False\n\n        # honor accept rules\n        for accept_rule in self.scope[\"accepts\"]:\n            rule = urlcanon.MatchRule(**accept_rule)\n            if try_parent_urls:\n                for parent_url in try_parent_urls:\n                    if rule.applies(url, parent_url):\n                       return True\n            else:\n                if rule.applies(url):\n                    return True\n\n        # no decision if we reach here\n        return None", "response": "Returns True if the given URL is accepted False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises brozzler. ReachedTimeLimit if appropriate.", "response": "def enforce_time_limit(self, site):\n        '''\n        Raises `brozzler.ReachedTimeLimit` if appropriate.\n        '''\n        if (site.time_limit and site.time_limit > 0\n                and site.elapsed() > site.time_limit):\n            self.logger.debug(\n                    \"site FINISHED_TIME_LIMIT! time_limit=%s \"\n                    \"elapsed=%s %s\", site.time_limit, site.elapsed(), site)\n            raise brozzler.ReachedTimeLimit"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises brozzler. CrawlStopped if stop has been requested.", "response": "def honor_stop_request(self, site):\n        \"\"\"Raises brozzler.CrawlStopped if stop has been requested.\"\"\"\n        site.refresh()\n        if (site.stop_requested\n                and site.stop_requested <= doublethink.utcnow()):\n            self.logger.info(\"stop requested for site %s\", site.id)\n            raise brozzler.CrawlStopped\n\n        if site.job_id:\n            job = brozzler.Job.load(self.rr, site.job_id)\n            if (job and job.stop_requested\n                    and job.stop_requested <= doublethink.utcnow()):\n                self.logger.info(\"stop requested for job %s\", site.job_id)\n                raise brozzler.CrawlStopped"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if job is finished False otherwise.", "response": "def _maybe_finish_job(self, job_id):\n        \"\"\"Returns True if job is finished.\"\"\"\n        job = brozzler.Job.load(self.rr, job_id)\n        if not job:\n            return False\n        if job.status.startswith(\"FINISH\"):\n            self.logger.warn(\"%s is already %s\", job, job.status)\n            return True\n\n        results = self.rr.table(\"sites\").get_all(job_id, index=\"job_id\").run()\n        n = 0\n        for result in results:\n            site = brozzler.Site(self.rr, result)\n            if not site.status.startswith(\"FINISH\"):\n                results.close()\n                return False\n            n += 1\n\n        self.logger.info(\n                \"all %s sites finished, job %s is FINISHED!\", n, job.id)\n        job.finish()\n        job.save()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _scope_and_enforce_robots(self, site, parent_page, outlinks):\n        '''\n        Returns tuple (\n            dict of {page_id: Page} of fresh `brozzler.Page` representing in\n                scope links accepted by robots policy,\n            set of in scope urls (canonicalized) blocked by robots policy,\n            set of out-of-scope urls (canonicalized)).\n        '''\n        pages = {}  # {page_id: Page, ...}\n        blocked = set()\n        out_of_scope = set()\n        for url in outlinks or []:\n            url_for_scoping = urlcanon.semantic(url)\n            url_for_crawling = urlcanon.whatwg(url)\n            decision = site.accept_reject_or_neither(\n                    url_for_scoping, parent_page=parent_page)\n            if decision is True:\n                hops_off = 0\n            elif decision is None:\n                decision = parent_page.hops_off < site.scope.get(\n                        'max_hops_off', 0)\n                hops_off = parent_page.hops_off + 1\n            if decision is True:\n                if brozzler.is_permitted_by_robots(site, str(url_for_crawling)):\n                    fresh_page = self._build_fresh_page(\n                            site, parent_page, url, hops_off)\n                    if fresh_page.id in pages:\n                        self._merge_page(pages[fresh_page.id], fresh_page)\n                    else:\n                        pages[fresh_page.id] = fresh_page\n                else:\n                    blocked.add(str(url_for_crawling))\n            else:\n                out_of_scope.add(str(url_for_crawling))\n        return pages, blocked, out_of_scope", "response": "Returns tuple of inscope blocked and out - of - scope urls."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an iterator over all pages that have been brozzled at least once for the given site.", "response": "def site_pages(self, site_id, brozzled=None):\n        '''\n        Args:\n            site_id (str or int):\n            brozzled (bool): if true, results include only pages that have\n                been brozzled at least once; if false, only pages that have\n                not been brozzled; and if None (the default), all pages\n        Returns:\n            iterator of brozzler.Page\n        '''\n        results = self.rr.table(\"pages\").between(\n                [site_id, 1 if brozzled is True else 0,\n                    r.minval, r.minval],\n                [site_id, 0 if brozzled is False else r.maxval,\n                    r.maxval, r.maxval],\n                index=\"priority_by_site\").run()\n        for result in results:\n            yield brozzler.Page(self.rr, result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef behaviors(behaviors_dir=None):\n    import os, yaml, string\n    global _behaviors\n    if _behaviors is None:\n        d = behaviors_dir or os.path.dirname(__file__)\n        behaviors_yaml = os.path.join(d, 'behaviors.yaml')\n        with open(behaviors_yaml) as fin:\n            _behaviors = yaml.safe_load(fin)\n    return _behaviors", "response": "Return list of JS behaviors loaded from YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef behavior_script(url, template_parameters=None, behaviors_dir=None):\n    '''\n    Returns the javascript behavior string populated with template_parameters.\n    '''\n    import re, logging, json\n    for behavior in behaviors(behaviors_dir=behaviors_dir):\n        if re.match(behavior['url_regex'], url):\n            parameters = dict()\n            if 'default_parameters' in behavior:\n                parameters.update(behavior['default_parameters'])\n            if template_parameters:\n                parameters.update(template_parameters)\n            template = jinja2_environment(behaviors_dir).get_template(\n                    behavior['behavior_js_template'])\n            script = template.render(parameters)\n            logging.info(\n                    'using template=%r populated with parameters=%r for %r',\n                    behavior['behavior_js_template'], json.dumps(parameters), url)\n            return script\n    return None", "response": "Returns the javascript behavior string populated with template_parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a ThreadExceptionGate for thread.", "response": "def thread_exception_gate(thread=None):\n    '''\n    Returns a `ThreadExceptionGate` for `thread` (current thread by default).\n\n    `ThreadExceptionGate` is a context manager which allows exceptions to be\n    raised from threads other than the current one, by way of `thread_raise`.\n\n    Example:\n\n        try:\n            with thread_exception_gate():\n                # do something\n        except:\n            # handle exception....\n\n    If `thread_raise` is called on a thread that is not currently inside the\n    `ThreadExceptionGate` context (pep340 \"runtime environment\"), the exception\n    is queued, and raised immediately if and when the thread enters the\n    context. Only one exception will be queued this way at a time, others are\n    discarded.\n    '''\n    if not thread:\n        thread = threading.current_thread()\n\n    with _thread_exception_gates_lock:\n        if not thread in _thread_exception_gates:\n            _thread_exception_gates[thread] = ThreadExceptionGate(thread)\n\n    return _thread_exception_gates[thread]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise an exception in the thread.", "response": "def thread_raise(thread, exctype):\n    '''\n    Raises or queues the exception `exctype` for the thread `thread`.\n\n    See the documentation on the function `thread_exception_gate()` for more\n    information.\n\n    Adapted from http://tomerfiliba.com/recipes/Thread2/ which explains:\n    \"The exception will be raised only when executing python bytecode. If your\n    thread calls a native/built-in blocking function, the exception will be\n    raised only when execution returns to the python code.\"\n\n    Raises:\n        TypeError if `exctype` is not a class\n        ValueError, SystemError in case of unexpected problems\n    '''\n    import ctypes, inspect, threading, logging\n\n    if not inspect.isclass(exctype):\n        raise TypeError(\n                'cannot raise %s, only exception types can be raised (not '\n                'instances)' % exctype)\n\n    gate = thread_exception_gate(thread)\n    with gate.lock:\n        if gate.ok_to_raise.is_set() and thread.is_alive():\n            gate.ok_to_raise.clear()\n            logging.info('raising %s in thread %s', exctype, thread)\n            res = ctypes.pythonapi.PyThreadState_SetAsyncExc(\n                    ctypes.c_long(thread.ident), ctypes.py_object(exctype))\n            if res == 0:\n                raise ValueError(\n                        'invalid thread id? thread.ident=%s' % thread.ident)\n            elif res != 1:\n                # if it returns a number greater than one, you're in trouble,\n                # and you should call it again with exc=NULL to revert the effect\n                ctypes.pythonapi.PyThreadState_SetAsyncExc(thread.ident, 0)\n                raise SystemError('PyThreadState_SetAsyncExc failed')\n        else:\n            logging.info('queueing %s for thread %s', exctype, thread)\n            gate.queue_exception(exctype)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sleep(duration):\n    '''\n    Sleeps for duration seconds in increments of 0.5 seconds.\n\n    Use this so that the sleep can be interrupted by thread_raise().\n    '''\n    import time\n    start = time.time()\n    while True:\n        elapsed = time.time() - start\n        if elapsed >= duration:\n            break\n        time.sleep(min(duration - elapsed, 0.5))", "response": "Sleeps for duration seconds in increments of 0. 5 seconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of up to n browsers.", "response": "def acquire_multi(self, n=1):\n        '''\n        Returns a list of up to `n` browsers.\n\n        Raises:\n            NoBrowsersAvailable if none available\n        '''\n        browsers = []\n        with self._lock:\n            if len(self._in_use) >= self.size:\n                raise NoBrowsersAvailable\n            while len(self._in_use) < self.size and len(browsers) < n:\n                browser = self._fresh_browser()\n                browsers.append(browser)\n                self._in_use.add(browser)\n        return browsers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nacquiring an available instance of a specific language.", "response": "def acquire(self):\n        '''\n        Returns an available instance.\n\n        Returns:\n            browser from pool, if available\n\n        Raises:\n            NoBrowsersAvailable if none available\n        '''\n        with self._lock:\n            if len(self._in_use) >= self.size:\n                raise NoBrowsersAvailable\n            browser = self._fresh_browser()\n            self._in_use.add(browser)\n            return browser"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when an error occurs in the websocket receiver thread.", "response": "def _on_error(self, websock, e):\n        '''\n        Raises BrowsingException in the thread that created this instance.\n        '''\n        if isinstance(e, (\n            websocket.WebSocketConnectionClosedException,\n            ConnectionResetError)):\n            self.logger.error('websocket closed, did chrome die?')\n        else:\n            self.logger.error(\n                    'exception from websocket receiver thread',\n                    exc_info=1)\n        brozzler.thread_raise(self.calling_thread, BrowsingException)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nspin until callback returns truthy.", "response": "def _wait_for(self, callback, timeout=None):\n        '''\n        Spins until callback() returns truthy.\n        '''\n        start = time.time()\n        while True:\n            if callback():\n                return\n            elapsed = time.time() - start\n            if timeout and elapsed > timeout:\n                raise BrowsingTimeout(\n                        'timed out after %.1fs waiting for: %s' % (\n                            elapsed, callback))\n            brozzler.sleep(self._wait_interval)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart chrome if it s not running.", "response": "def start(self, **kwargs):\n        '''\n        Starts chrome if it's not running.\n\n        Args:\n            **kwargs: arguments for self.chrome.start(...)\n        '''\n        if not self.is_running():\n            self.websock_url = self.chrome.start(**kwargs)\n            self.websock = websocket.WebSocketApp(self.websock_url)\n            self.websock_thread = WebsockReceiverThread(\n                    self.websock, name='WebsockThread:%s' % self.chrome.port)\n            self.websock_thread.start()\n\n            self._wait_for(lambda: self.websock_thread.is_open, timeout=30)\n\n            # tell browser to send us messages we're interested in\n            self.send_to_chrome(method='Network.enable')\n            self.send_to_chrome(method='Page.enable')\n            self.send_to_chrome(method='Console.enable')\n            self.send_to_chrome(method='Runtime.enable')\n            self.send_to_chrome(method='ServiceWorker.enable')\n            self.send_to_chrome(method='ServiceWorker.setForceUpdateOnPageLoad')\n\n            # disable google analytics\n            self.send_to_chrome(\n                method='Network.setBlockedURLs',\n                params={'urls': ['*google-analytics.com/analytics.js',\n                                 '*google-analytics.com/ga.js']})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        '''\n        Stops chrome if it's running.\n        '''\n        try:\n            if (self.websock and self.websock.sock\n                    and self.websock.sock.connected):\n                self.logger.info('shutting down websocket connection')\n                try:\n                    self.websock.close()\n                except BaseException as e:\n                    self.logger.error(\n                            'exception closing websocket %s - %s',\n                            self.websock, e)\n\n            self.chrome.stop()\n\n            if self.websock_thread and (\n                    self.websock_thread != threading.current_thread()):\n                self.websock_thread.join(timeout=30)\n                if self.websock_thread.is_alive():\n                    self.logger.error(\n                            '%s still alive 30 seconds after closing %s, will '\n                            'forcefully nudge it again', self.websock_thread,\n                            self.websock)\n                    self.websock.keep_running = False\n                    self.websock_thread.join(timeout=30)\n                    if self.websock_thread.is_alive():\n                        self.logger.critical(\n                                '%s still alive 60 seconds after closing %s',\n                                    self.websock_thread, self.websock)\n\n            self.websock_url = None\n        except:\n            self.logger.error('problem stopping', exc_info=True)", "response": "Stops chrome if it s running."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef browse_page(\n            self, page_url, extra_headers=None,\n            user_agent=None, behavior_parameters=None, behaviors_dir=None,\n            on_request=None, on_response=None,\n            on_service_worker_version_updated=None, on_screenshot=None,\n            username=None, password=None, hashtags=None,\n            skip_extract_outlinks=False, skip_visit_hashtags=False,\n            skip_youtube_dl=False, page_timeout=300, behavior_timeout=900):\n        '''\n        Browses page in browser.\n\n        Browser should already be running, i.e. start() should have been\n        called. Opens the page_url in the browser, runs behaviors, takes a\n        screenshot, extracts outlinks.\n\n        Args:\n            page_url: url of the page to browse\n            extra_headers: dict of extra http headers to configure the browser\n                to send with every request (default None)\n            user_agent: user agent string, replaces browser default if\n                supplied (default None)\n            behavior_parameters: dict of parameters for populating the\n                javascript behavior template (default None)\n            behaviors_dir: Directory containing behaviors.yaml and JS templates\n                (default None loads Brozzler default JS behaviors)\n            on_request: callback to invoke on every Network.requestWillBeSent\n                event, takes one argument, the json-decoded message (default\n                None)\n            on_response: callback to invoke on every Network.responseReceived\n                event, takes one argument, the json-decoded message (default\n                None)\n            on_service_worker_version_updated: callback to invoke on every\n                ServiceWorker.workerVersionUpdated event, takes one argument,\n                the json-decoded message (default None)\n            on_screenshot: callback to invoke when screenshot is obtained,\n                takes one argument, the the raw jpeg bytes (default None)\n                # XXX takes two arguments, the url of the page at the time the\n                # screenshot was taken, and the raw jpeg bytes (default None)\n            username: username string to use to try logging in if a login form\n                is found in the page (default None)\n            password: password string to use to try logging in if a login form\n                is found in the page (default None)\n            ... (there are more)\n\n        Returns:\n            A tuple (final_page_url, outlinks).\n            final_page_url: the url in the location bar at the end of the\n                browse_page cycle, which could be different from the original\n                page url if the page redirects, javascript has changed the url\n                in the location bar, etc\n            outlinks: a list of navigational links extracted from the page\n\n        Raises:\n            brozzler.ProxyError: in case of proxy connection error\n            BrowsingException: if browsing the page fails in some other way\n        '''\n        if not self.is_running():\n            raise BrowsingException('browser has not been started')\n        if self.is_browsing:\n            raise BrowsingException('browser is already busy browsing a page')\n        self.is_browsing = True\n        if on_request:\n            self.websock_thread.on_request = on_request\n        if on_response:\n            self.websock_thread.on_response = on_response\n        if on_service_worker_version_updated:\n            self.websock_thread.on_service_worker_version_updated = \\\n                    on_service_worker_version_updated\n        try:\n            with brozzler.thread_accept_exceptions():\n                self.configure_browser(\n                        extra_headers=extra_headers,\n                        user_agent=user_agent)\n                self.navigate_to_page(page_url, timeout=page_timeout)\n                if password:\n                    self.try_login(username, password, timeout=page_timeout)\n                    # if login redirected us, return to page_url\n                    if page_url != self.url().split('#')[0]:\n                        self.logger.debug(\n                            'login navigated away from %s; returning!',\n                            page_url)\n                        self.navigate_to_page(page_url, timeout=page_timeout)\n                if on_screenshot:\n                    self._try_screenshot(on_screenshot)\n                behavior_script = brozzler.behavior_script(\n                        page_url, behavior_parameters,\n                        behaviors_dir=behaviors_dir)\n                self.run_behavior(behavior_script, timeout=behavior_timeout)\n                if skip_extract_outlinks:\n                    outlinks = []\n                else:\n                    outlinks = self.extract_outlinks()\n                if not skip_visit_hashtags:\n                    self.visit_hashtags(self.url(), hashtags, outlinks)\n                final_page_url = self.url()\n                return final_page_url, outlinks\n        except brozzler.ReachedLimit:\n            # websock_thread has stashed the ReachedLimit exception with\n            # more information, raise that one\n            raise self.websock_thread.reached_limit\n        except websocket.WebSocketConnectionClosedException as e:\n            self.logger.error('websocket closed, did chrome die?')\n            raise BrowsingException(e)\n        finally:\n            self.is_browsing = False\n            self.websock_thread.on_request = None\n            self.websock_thread.on_response = None", "response": "Browses a page in the browser and returns a dictionary of all the information needed to browse it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning value of document. URL from the browser.", "response": "def url(self, timeout=30):\n        '''\n        Returns value of document.URL from the browser.\n        '''\n        self.websock_thread.expect_result(self._command_id.peek())\n        msg_id = self.send_to_chrome(\n                method='Runtime.evaluate',\n                params={'expression': 'document.URL'})\n        self._wait_for(\n                lambda: self.websock_thread.received_result(msg_id),\n                timeout=timeout)\n        message = self.websock_thread.pop_result(msg_id)\n        return message['result']['result']['value']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef brozzle_page(argv=None):\n    '''\n    Command line utility entry point for brozzling a single page. Opens url in\n    a browser, running some javascript behaviors, and prints outlinks.\n    '''\n    argv = argv or sys.argv\n    arg_parser = argparse.ArgumentParser(\n            prog=os.path.basename(argv[0]),\n            description='brozzle-page - brozzle a single page',\n            formatter_class=BetterArgumentDefaultsHelpFormatter)\n    arg_parser.add_argument('url', metavar='URL', help='page url')\n    arg_parser.add_argument(\n            '-e', '--chrome-exe', dest='chrome_exe',\n            default=suggest_default_chrome_exe(),\n            help='executable to use to invoke chrome')\n    arg_parser.add_argument(\n            '--behavior-parameters', dest='behavior_parameters',\n            default=None, help=(\n                'json blob of parameters to populate the javascript behavior '\n                'template, e.g. {\"parameter_username\":\"x\",'\n                '\"parameter_password\":\"y\"}'))\n    arg_parser.add_argument(\n            '--username', dest='username', default=None,\n            help='use this username to try to log in if a login form is found')\n    arg_parser.add_argument(\n            '--password', dest='password', default=None,\n            help='use this password to try to log in if a login form is found')\n    arg_parser.add_argument(\n            '--proxy', dest='proxy', default=None, help='http proxy')\n    arg_parser.add_argument(\n            '--skip-extract-outlinks', dest='skip_extract_outlinks',\n            action='store_true')\n    arg_parser.add_argument(\n            '--skip-visit-hashtags', dest='skip_visit_hashtags',\n            action='store_true')\n    arg_parser.add_argument(\n            '--skip-youtube-dl', dest='skip_youtube_dl', action='store_true')\n    add_common_options(arg_parser, argv)\n\n    args = arg_parser.parse_args(args=argv[1:])\n    configure_logging(args)\n    brozzler.chrome.check_version(args.chrome_exe)\n\n    behavior_parameters = {}\n    if args.behavior_parameters:\n        behavior_parameters = json.loads(args.behavior_parameters)\n    site = brozzler.Site(None, {\n        'id': -1, 'seed': args.url, 'behavior_parameters': behavior_parameters,\n        'username': args.username, 'password': args.password})\n    page = brozzler.Page(None, {'url': args.url, 'site_id': site.id})\n    worker = brozzler.BrozzlerWorker(frontier=None, proxy=args.proxy,\n        skip_extract_outlinks=args.skip_extract_outlinks,\n        skip_visit_hashtags=args.skip_visit_hashtags,\n        skip_youtube_dl=args.skip_youtube_dl)\n\n    def on_screenshot(screenshot_png):\n        OK_CHARS = (string.ascii_letters + string.digits)\n        filename = '/tmp/{}-{:%Y%m%d%H%M%S}.png'.format(\n                ''.join(ch if ch in OK_CHARS else '_' for ch in args.url),\n                datetime.datetime.now())\n        # logging.info('len(screenshot_png)=%s', len(screenshot_png))\n        with open(filename, 'wb') as f:\n            f.write(screenshot_png)\n        logging.info('wrote screenshot to %s', filename)\n\n    browser = brozzler.Browser(chrome_exe=args.chrome_exe)\n    try:\n        browser.start(proxy=args.proxy)\n        outlinks = worker.brozzle_page(\n                browser, site, page, on_screenshot=on_screenshot,\n                enable_youtube_dl=not args.skip_youtube_dl)\n        logging.info('outlinks: \\n\\t%s', '\\n\\t'.join(sorted(outlinks)))\n    except brozzler.ReachedLimit as e:\n        logging.error('reached limit %s', e)\n    except brozzler.PageInterstitialShown as e:\n        logging.error('page interstitial shown %s', e)\n    finally:\n        browser.stop()", "response": "A command line utility entry point for brozzling a single page."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef brozzler_new_job(argv=None):\n    '''\n    Command line utility entry point for queuing a new brozzler job. Takes a\n    yaml brozzler job configuration file, creates job, sites, and pages objects\n    in rethinkdb, which brozzler-workers will look at and start crawling.\n    '''\n    argv = argv or sys.argv\n    arg_parser = argparse.ArgumentParser(\n            prog=os.path.basename(argv[0]),\n            description='brozzler-new-job - queue new job with brozzler',\n            formatter_class=BetterArgumentDefaultsHelpFormatter)\n    arg_parser.add_argument(\n            'job_conf_file', metavar='JOB_CONF_FILE',\n            help='brozzler job configuration file in yaml')\n    add_rethinkdb_options(arg_parser)\n    add_common_options(arg_parser, argv)\n\n    args = arg_parser.parse_args(args=argv[1:])\n    configure_logging(args)\n\n    rr = rethinker(args)\n    frontier = brozzler.RethinkDbFrontier(rr)\n    try:\n        brozzler.new_job_file(frontier, args.job_conf_file)\n    except brozzler.InvalidJobConf as e:\n        print('brozzler-new-job: invalid job file:', args.job_conf_file, file=sys.stderr)\n        print('  ' + yaml.dump(e.errors).rstrip().replace('\\n', '\\n  '), file=sys.stderr)\n        sys.exit(1)", "response": "A command line utility entry point for queuing a new brozzler job. Takes a\n    yaml file creates job sites and pages objects\n    in rethinkdb which will look at and start crawling it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef brozzler_new_site(argv=None):\n    '''\n    Command line utility entry point for queuing a new brozzler site.\n    Takes a seed url and creates a site and page object in rethinkdb, which\n    brozzler-workers will look at and start crawling.\n    '''\n    argv = argv or sys.argv\n    arg_parser = argparse.ArgumentParser(\n            prog=os.path.basename(argv[0]),\n            description='brozzler-new-site - register site to brozzle',\n            formatter_class=BetterArgumentDefaultsHelpFormatter)\n    arg_parser.add_argument('seed', metavar='SEED', help='seed url')\n    add_rethinkdb_options(arg_parser)\n    arg_parser.add_argument(\n            '--time-limit', dest='time_limit', default=None,\n            help='time limit in seconds for this site')\n    arg_parser.add_argument(\n            '--ignore-robots', dest='ignore_robots', action='store_true',\n            help='ignore robots.txt for this site')\n    arg_parser.add_argument(\n            '--warcprox-meta', dest='warcprox_meta',\n            help=(\n                'Warcprox-Meta http request header to send with each request; '\n                'must be a json blob, ignored unless warcprox features are '\n                'enabled'))\n    arg_parser.add_argument(\n            '--behavior-parameters', dest='behavior_parameters',\n            default=None, help=(\n                'json blob of parameters to populate the javascript behavior '\n                'template, e.g. {\"parameter_username\":\"x\",'\n                '\"parameter_password\":\"y\"}'))\n    arg_parser.add_argument(\n            '--username', dest='username', default=None,\n            help='use this username to try to log in if a login form is found')\n    arg_parser.add_argument(\n            '--password', dest='password', default=None,\n            help='use this password to try to log in if a login form is found')\n    add_common_options(arg_parser, argv)\n\n    args = arg_parser.parse_args(args=argv[1:])\n    configure_logging(args)\n\n    rr = rethinker(args)\n    site = brozzler.Site(rr, {\n        'seed': args.seed,\n        'time_limit': int(args.time_limit) if args.time_limit else None,\n        'ignore_robots': args.ignore_robots,\n        'warcprox_meta': json.loads(\n            args.warcprox_meta) if args.warcprox_meta else None,\n        'behavior_parameters': json.loads(\n            args.behavior_parameters) if args.behavior_parameters else None,\n        'username': args.username,\n        'password': args.password})\n\n    frontier = brozzler.RethinkDbFrontier(rr)\n    brozzler.new_site(frontier, site)", "response": "Command line utility entry point for queuing a new brozzler site."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef brozzler_ensure_tables(argv=None):\n    '''\n    Creates rethinkdb tables if they don't already exist. Brozzler\n    (brozzler-worker, brozzler-new-job, etc) normally creates the tables it\n    needs on demand at startup, but if multiple instances are starting up at\n    the same time, you can end up with duplicate broken tables. So it's a good\n    idea to use this utility at an early step when spinning up a cluster.\n    '''\n    argv = argv or sys.argv\n    arg_parser = argparse.ArgumentParser(\n            prog=os.path.basename(argv[0]),\n            formatter_class=BetterArgumentDefaultsHelpFormatter)\n    add_rethinkdb_options(arg_parser)\n    add_common_options(arg_parser, argv)\n\n    args = arg_parser.parse_args(args=argv[1:])\n    configure_logging(args)\n\n    rr = rethinker(args)\n\n    # services table\n    doublethink.ServiceRegistry(rr)\n\n    # sites, pages, jobs tables\n    brozzler.frontier.RethinkDbFrontier(rr)", "response": "Creates rethinkdb tables if they don t already exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds warcprox. Options object for the given command line arguments.", "response": "def _warcprox_opts(self, args):\n        '''\n        Takes args as produced by the argument parser built by\n        _build_arg_parser and builds warcprox arguments object suitable to pass\n        to warcprox.main.init_controller. Copies some arguments, renames some,\n        populates some with defaults appropriate for brozzler-easy, etc.\n        '''\n        warcprox_opts = warcprox.Options()\n        warcprox_opts.address = 'localhost'\n        # let the OS choose an available port; discover it later using\n        # sock.getsockname()[1]\n        warcprox_opts.port = 0\n        warcprox_opts.cacert = args.cacert\n        warcprox_opts.certs_dir = args.certs_dir\n        warcprox_opts.directory = args.warcs_dir\n        warcprox_opts.gzip = True\n        warcprox_opts.prefix = 'brozzler'\n        warcprox_opts.size = 1000 * 1000* 1000\n        warcprox_opts.rollover_idle_time = 3 * 60\n        warcprox_opts.digest_algorithm = 'sha1'\n        warcprox_opts.base32 = True\n        warcprox_opts.stats_db_file = None\n        warcprox_opts.playback_port = None\n        warcprox_opts.playback_index_db_file = None\n        warcprox_opts.rethinkdb_big_table_url = (\n                'rethinkdb://%s/%s/captures' % (\n                    args.rethinkdb_servers, args.rethinkdb_db))\n        warcprox_opts.queue_size = 500\n        warcprox_opts.max_threads = None\n        warcprox_opts.profile = False\n        warcprox_opts.onion_tor_socks_proxy = args.onion_tor_socks_proxy\n        return warcprox_opts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the first occurrence of a user - agent token matching the supplied full user - agent.", "response": "def _reppy_rules_getitem(self, agent):\n    '''\n    Find the user-agent token matching the supplied full user-agent, using\n    a case-insensitive substring search.\n    '''\n    lc_agent = agent.lower()\n    for s in self.agents:\n        if s in lc_agent:\n            return self.agents[s]\n    return self.agents.get('*')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if url is permitted by robots. txt.", "response": "def is_permitted_by_robots(site, url, proxy=None):\n    '''\n    Checks if `url` is permitted by robots.txt.\n\n    Treats any kind of error fetching robots.txt as \"allow all\". See\n    http://builds.archive.org/javadoc/heritrix-3.x-snapshot/org/archive/modules/net/CrawlServer.html#updateRobots(org.archive.modules.CrawlURI)\n    for some background on that policy.\n\n    Returns:\n        bool: `True` if `site.ignore_robots` is set, or if `url` is permitted\n            by robots.txt, `False` otherwise\n\n    Raises:\n        brozzler.ReachedLimit: if warcprox responded with 420 Reached Limit\n        requests.exceptions.ProxyError: if the proxy is down\n    '''\n    if site.ignore_robots:\n        return True\n\n    try:\n        result = _robots_cache(site, proxy).allowed(\n                url, site.user_agent or \"brozzler\")\n        return result\n    except Exception as e:\n        if isinstance(e, reppy.exceptions.ServerError) and isinstance(\n                e.args[0], brozzler.ReachedLimit):\n            raise e.args[0]\n        elif hasattr(e, 'args') and isinstance(\n                e.args[0], requests.exceptions.ProxyError):\n            # reppy has wrapped an exception that we want to bubble up\n            raise brozzler.ProxyError(e)\n        else:\n            logging.warn(\n                    \"returning true (permitted) after problem fetching \"\n                    \"robots.txt for %r: %r\", url, e)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef final_bounces(fetches, url):\n    redirects = {}\n    for fetch in fetches:\n         # XXX check http status 301,302,303,307? check for \"uri\" header\n         # as well as \"location\"? see urllib.request.HTTPRedirectHandler\n         if 'location' in fetch['response_headers']:\n             redirects[fetch['url']] = fetch\n\n    final_url = url\n    while final_url in redirects:\n        fetch = redirects.pop(final_url)\n        final_url = urllib.parse.urljoin(\n                fetch['url'], fetch['response_headers']['location'])\n\n    final_bounces = []\n    for fetch in fetches:\n        if fetch['url'] == final_url:\n            final_bounces.append(fetch)\n\n    return final_bounces", "response": "Resolves redirect chains in fetches and returns a list of fetches containing the final bounces of the given url."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a brozzler_dl. YoutubeDL instance for brozzling.", "response": "def _build_youtube_dl(worker, destdir, site):\n    '''\n    Builds a `youtube_dl.YoutubeDL` for brozzling `site` with `worker`.\n\n    The `YoutubeDL` instance does a few special brozzler-specific things:\n\n    - keeps track of urls fetched using a `YoutubeDLSpy`\n    - periodically updates `site.last_claimed` in rethinkdb\n    - if brozzling through warcprox and downloading segmented videos (e.g.\n      HLS), pushes the stitched-up video created by youtube-dl to warcprox\n      using a WARCPROX_WRITE_RECORD request\n    - some logging\n\n    Args:\n        worker (brozzler.BrozzlerWorker): the calling brozzler worker\n        destdir (str): where to save downloaded videos\n        site (brozzler.Site): the site we are brozzling\n\n    Returns:\n        a `youtube_dl.YoutubeDL` instance\n    '''\n\n    class _YoutubeDL(youtube_dl.YoutubeDL):\n        logger = logging.getLogger(__module__ + \".\" + __qualname__)\n\n        def urlopen(self, req):\n            try:\n                url = req.full_url\n            except AttributeError:\n                url = req\n            self.logger.debug('fetching %r', url)\n            return super().urlopen(req)\n\n        def add_default_extra_info(self, ie_result, ie, url):\n            # hook in some logging\n            super().add_default_extra_info(ie_result, ie, url)\n            if ie_result.get('_type') == 'playlist':\n                self.logger.info(\n                        'extractor %r found playlist in %s', ie.IE_NAME, url)\n                if ie.IE_NAME == 'youtube:playlist':\n                    # At this point ie_result['entries'] is an iterator that\n                    # will fetch more metadata from youtube to list all the\n                    # videos. We unroll that iterator here partly because\n                    # otherwise `process_ie_result()` will clobber it, and we\n                    # use it later to extract the watch pages as outlinks.\n                    ie_result['entries_no_dl'] = list(ie_result['entries'])\n                    ie_result['entries'] = []\n                    self.logger.info(\n                            'not downoading %s videos from this youtube '\n                            'playlist because we expect to capture them from '\n                            'individual watch pages',\n                            len(ie_result['entries_no_dl']))\n            else:\n                self.logger.info(\n                        'extractor %r found a video in %s', ie.IE_NAME, url)\n\n        def _push_stitched_up_vid_to_warcprox(self, site, info_dict, ctx):\n            # XXX Don't know how to get the right content-type. Youtube-dl\n            # doesn't supply it. Sometimes (with --hls-prefer-native)\n            # youtube-dl produces a stitched-up video that /usr/bin/file fails\n            # to identify (says \"application/octet-stream\"). `ffprobe` doesn't\n            # give us a mimetype.\n            if info_dict.get('ext') == 'mp4':\n                mimetype = 'video/mp4'\n            else:\n                try:\n                    import magic\n                    mimetype = magic.from_file(ctx['filename'], mime=True)\n                except ImportError as e:\n                    mimetype = 'video/%s' % info_dict['ext']\n                    self.logger.warn(\n                            'guessing mimetype %s because %r', mimetype, e)\n\n            url = 'youtube-dl:%05d:%s' % (\n                    info_dict.get('playlist_index') or 1,\n                    info_dict['webpage_url'])\n            size = os.path.getsize(ctx['filename'])\n            self.logger.info(\n                    'pushing %r video stitched-up as %s (%s bytes) to '\n                    'warcprox at %s with url %s', info_dict['format'],\n                    mimetype, size, worker._proxy_for(site), url)\n            with open(ctx['filename'], 'rb') as f:\n                # include content-length header to avoid chunked\n                # transfer, which warcprox currently rejects\n                extra_headers = dict(site.extra_headers())\n                extra_headers['content-length'] = size\n                request, response = worker._warcprox_write_record(\n                        warcprox_address=worker._proxy_for(site), url=url,\n                        warc_type='resource', content_type=mimetype, payload=f,\n                        extra_headers=extra_headers)\n                # consulted by _remember_videos()\n                self.stitch_ups.append({\n                    'url': url,\n                    'response_code': response.code,\n                    'content-type': mimetype,\n                    'content-length': size,\n                })\n\n        def process_info(self, info_dict):\n            '''\n            See comment above on `_finish_frag_download()`\n            '''\n            def ffd_callback(ffd_self, ctx):\n                if worker._using_warcprox(site):\n                    self._push_stitched_up_vid_to_warcprox(site, info_dict, ctx)\n            try:\n                thread_local.finish_frag_download_callback = ffd_callback\n                return super().process_info(info_dict)\n            finally:\n                delattr(thread_local, 'finish_frag_download_callback')\n\n    def maybe_heartbeat_site_last_claimed(*args, **kwargs):\n        # in case youtube-dl takes a long time, heartbeat site.last_claimed\n        # to prevent another brozzler-worker from claiming the site\n        try:\n            if site.rr and doublethink.utcnow() - site.last_claimed > datetime.timedelta(minutes=worker.SITE_SESSION_MINUTES):\n                worker.logger.debug(\n                        'heartbeating site.last_claimed to prevent another '\n                        'brozzler-worker claiming this site id=%r', site.id)\n                site.last_claimed = doublethink.utcnow()\n                site.save()\n        except:\n            worker.logger.debug(\n                    'problem heartbeating site.last_claimed site id=%r',\n                    site.id, exc_info=True)\n\n    ydl_opts = {\n        \"outtmpl\": \"{}/ydl%(autonumber)s.out\".format(destdir),\n        \"retries\": 1,\n        \"nocheckcertificate\": True,\n        \"hls_prefer_native\": True,\n        \"noprogress\": True,\n        \"nopart\": True,\n        \"no_color\": True,\n        \"progress_hooks\": [maybe_heartbeat_site_last_claimed],\n\n         # https://github.com/rg3/youtube-dl/blob/master/README.md#format-selection\n         # \"best: Select the best quality format represented by a single\n         # file with video and audio.\"\n        \"format\": \"best/bestvideo+bestaudio\",\n\n        ### we do our own logging\n        # \"logger\": logging.getLogger(\"youtube_dl\"),\n        \"verbose\": False,\n        \"quiet\": True,\n    }\n    if worker._proxy_for(site):\n        ydl_opts[\"proxy\"] = \"http://{}\".format(worker._proxy_for(site))\n    ydl = _YoutubeDL(ydl_opts)\n    if site.extra_headers():\n        ydl._opener.add_handler(ExtraHeaderAdder(site.extra_headers()))\n    ydl.fetch_spy = YoutubeDLSpy()\n    ydl.stitch_ups = []\n    ydl._opener.add_handler(ydl.fetch_spy)\n    return ydl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstoring info about videos captured by youtube - dl in page. videos.", "response": "def _remember_videos(page, fetches, stitch_ups=None):\n    '''\n    Saves info about videos captured by youtube-dl in `page.videos`.\n    '''\n    if not 'videos' in page:\n        page.videos = []\n    for fetch in fetches or []:\n        content_type = fetch['response_headers'].get_content_type()\n        if (content_type.startswith('video/')\n                # skip manifests of DASH segmented video -\n                # see https://github.com/internetarchive/brozzler/pull/70\n                and content_type != 'video/vnd.mpeg.dash.mpd'\n                and fetch['method'] == 'GET'\n                and fetch['response_code'] in (200, 206)):\n            video = {\n                'blame': 'youtube-dl',\n                'url': fetch['url'],\n                'response_code': fetch['response_code'],\n                'content-type': content_type,\n            }\n            if 'content-length' in fetch['response_headers']:\n                video['content-length'] = int(\n                        fetch['response_headers']['content-length'])\n            if 'content-range' in fetch['response_headers']:\n                video['content-range'] = fetch[\n                        'response_headers']['content-range']\n            logging.debug('embedded video %s', video)\n            page.videos.append(video)\n    for stitch_up in stitch_ups or []:\n        if stitch_up['content-type'].startswith('video/'):\n            video = {\n                'blame': 'youtube-dl',\n                'url': stitch_up['url'],\n                'response_code': stitch_up['response_code'],\n                'content-type': stitch_up['content-type'],\n                'content-length': stitch_up['content-length'],\n            }\n            logging.debug('embedded video %s', video)\n            page.videos.append(video)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_youtube_dl(worker, site, page):\n    '''\n    Runs youtube-dl configured for `worker` and `site` to download videos from\n    `page`.\n\n    Args:\n        worker (brozzler.BrozzlerWorker): the calling brozzler worker\n        site (brozzler.Site): the site we are brozzling\n        page (brozzler.Page): the page we are brozzling\n\n    Returns:\n        tuple with two entries:\n            `list` of `dict`: with info about urls fetched:\n                [{\n                    'url': ...,\n                    'method': ...,\n                    'response_code': ...,\n                    'response_headers': ...,\n                }, ...]\n            `list` of `str`: outlink urls\n    '''\n    with tempfile.TemporaryDirectory(prefix='brzl-ydl-') as tempdir:\n        ydl = _build_youtube_dl(worker, tempdir, site)\n        ie_result = _try_youtube_dl(worker, ydl, site, page)\n        outlinks = set()\n        if ie_result and ie_result.get('extractor') == 'youtube:playlist':\n            # youtube watch pages as outlinks\n            outlinks = {'https://www.youtube.com/watch?v=%s' % e['id']\n                        for e in ie_result.get('entries_no_dl', [])}\n        # any outlinks for other cases?\n        return ydl.fetch_spy.fetches, outlinks", "response": "Runs youtube - dl on the given page and returns a tuple with two entries of url and outlink urls."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmonkeys - patch pywb. warc. pathresolvers. PrefixResolver to include warcs still being written to.", "response": "def support_in_progress_warcs():\n    '''\n    Monkey-patch pywb.warc.pathresolvers.PrefixResolver to include warcs still\n    being written to (warcs having \".open\" suffix). This way if a cdx entry\n    references foo.warc.gz, pywb will try both foo.warc.gz and\n    foo.warc.gz.open.\n    '''\n    _orig_prefix_resolver_call = pywb.warc.pathresolvers.PrefixResolver.__call__\n    def _prefix_resolver_call(self, filename, cdx=None):\n        raw_results = _orig_prefix_resolver_call(self, filename, cdx)\n        results = []\n        for warc_path in raw_results:\n            results.append(warc_path)\n            results.append('%s.open' % warc_path)\n        return results\n    pywb.warc.pathresolvers.PrefixResolver.__call__ = _prefix_resolver_call"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pages(site_id):\n    start = int(flask.request.args.get(\"start\", 0))\n    end = int(flask.request.args.get(\"end\", start + 90))\n    reql = rr.table(\"pages\").between(\n            [site_id, 1, r.minval], [site_id, r.maxval, r.maxval],\n            index=\"least_hops\").order_by(index=\"least_hops\")[start:end]\n    logging.debug(\"querying rethinkdb: %s\", reql)\n    pages_ = reql.run()\n    return flask.jsonify(pages=list(pages_))", "response": "Get a list of pages already crawled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if chrome_exe is a supported browser version.", "response": "def check_version(chrome_exe):\n    '''\n    Raises SystemExit if `chrome_exe` is not a supported browser version.\n\n    Must run in the main thread to have the desired effect.\n    '''\n    # mac$ /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --version\n    # Google Chrome 64.0.3282.140 \n    # mac$ /Applications/Google\\ Chrome\\ Canary.app/Contents/MacOS/Google\\ Chrome\\ Canary --version\n    # Google Chrome 66.0.3341.0 canary\n    # linux$ chromium-browser --version\n    # Using PPAPI flash.\n    #  --ppapi-flash-path=/usr/lib/adobe-flashplugin/libpepflashplayer.so --ppapi-flash-version=\n    # Chromium 61.0.3163.100 Built on Ubuntu , running on Ubuntu 16.04\n    cmd = [chrome_exe, '--version']\n    out = subprocess.check_output(cmd, timeout=60)\n    m = re.search(br'(Chromium|Google Chrome) ([\\d.]+)', out)\n    if not m:\n        sys.exit(\n                'unable to parse browser version from output of '\n                '%r: %r' % (subprocess.list2cmdline(cmd), out))\n    version_str = m.group(2).decode()\n    major_version = int(version_str.split('.')[0])\n    if major_version < 64:\n        sys.exit('brozzler requires chrome/chromium version 64 or '\n                 'later but %s reports version %s' % (\n                     chrome_exe, version_str))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart the Chromium process.", "response": "def start(self, proxy=None, cookie_db=None, disk_cache_dir=None,\n              disk_cache_size=None):\n        '''\n        Starts chrome/chromium process.\n\n        Args:\n            proxy: http proxy 'host:port' (default None)\n            cookie_db: raw bytes of chrome/chromium sqlite3 cookies database,\n                which, if supplied, will be written to\n                {chrome_user_data_dir}/Default/Cookies before running the\n                browser (default None)\n            disk_cache_dir: use directory for disk cache. The default location\n                is inside `self._home_tmpdir` (default None).\n            disk_cache_size: Forces the maximum disk space to be used by the disk\n                cache, in bytes. (default None)\n        Returns:\n            websocket url to chrome window with about:blank loaded\n        '''\n        # these can raise exceptions\n        self._home_tmpdir = tempfile.TemporaryDirectory()\n        self._chrome_user_data_dir = os.path.join(\n            self._home_tmpdir.name, 'chrome-user-data')\n        if cookie_db:\n            self._init_cookie_db(cookie_db)\n        self._shutdown.clear()\n\n        new_env = os.environ.copy()\n        new_env['HOME'] = self._home_tmpdir.name\n        chrome_args = [\n                self.chrome_exe,\n                '--remote-debugging-port=%s' % self.port,\n                '--use-mock-keychain', # mac thing\n                '--user-data-dir=%s' % self._chrome_user_data_dir,\n                '--disable-background-networking',\n                '--disable-renderer-backgrounding', '--disable-hang-monitor',\n                '--disable-background-timer-throttling', '--mute-audio',\n                '--disable-web-sockets',\n                '--window-size=1100,900', '--no-default-browser-check',\n                '--disable-first-run-ui', '--no-first-run',\n                '--homepage=about:blank', '--disable-direct-npapi-requests',\n                '--disable-web-security', '--disable-notifications',\n                '--disable-extensions', '--disable-save-password-bubble']\n\n        if disk_cache_dir:\n            chrome_args.append('--disk-cache-dir=%s' % disk_cache_dir)\n        if disk_cache_size:\n            chrome_args.append('--disk-cache-size=%s' % disk_cache_size)\n        if self.ignore_cert_errors:\n            chrome_args.append('--ignore-certificate-errors')\n        if proxy:\n            chrome_args.append('--proxy-server=%s' % proxy)\n        chrome_args.append('about:blank')\n        self.logger.info('running: %r', subprocess.list2cmdline(chrome_args))\n        # start_new_session - new process group so we can kill the whole group\n        self.chrome_process = subprocess.Popen(\n                chrome_args, env=new_env, start_new_session=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=0)\n        self._out_reader_thread = threading.Thread(\n                target=self._read_stderr_stdout,\n                name='ChromeOutReaderThread:%s' % self.port, daemon=True)\n        self._out_reader_thread.start()\n        self.logger.info('chrome running, pid %s' % self.chrome_process.pid)\n\n        return self._websocket_url()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending service registry heartbeat if due'''", "response": "def _service_heartbeat_if_due(self):\n        '''Sends service registry heartbeat if due'''\n        due = False\n        if self._service_registry:\n            if not hasattr(self, \"status_info\"):\n                due = True\n            else:\n                d = doublethink.utcnow() - self.status_info[\"last_heartbeat\"]\n                due = d.total_seconds() > self.HEARTBEAT_INTERVAL\n\n        if due:\n            self._service_heartbeat()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _start_browsing_some_sites(self):\n        '''\n        Starts browsing some sites.\n\n        Raises:\n            NoBrowsersAvailable if none available\n        '''\n        # acquire_multi() raises NoBrowsersAvailable if none available\n        browsers = self._browser_pool.acquire_multi(\n                (self._browser_pool.num_available() + 1) // 2)\n        try:\n            sites = self._frontier.claim_sites(len(browsers))\n        except:\n            self._browser_pool.release_all(browsers)\n            raise\n\n        for i in range(len(browsers)):\n            if i < len(sites):\n                th = threading.Thread(\n                        target=self._brozzle_site_thread_target,\n                        args=(browsers[i], sites[i]),\n                        name=\"BrozzlingThread:%s\" % browsers[i].chrome.port,\n                        daemon=True)\n                with self._browsing_threads_lock:\n                    self._browsing_threads.add(th)\n                th.start()\n            else:\n                self._browser_pool.release(browsers[i])", "response": "Starts browsing some sites."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _createtoken(self, type_, value, flags=None):\n        '''create a token with position information'''\n        pos = None\n        assert len(self._positions) >= 2, (type_, value)\n        p2 = self._positions.pop()\n        p1 = self._positions.pop()\n        pos = [p1, p2]\n        return token(type_, value, pos, flags)", "response": "create a token with position information"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_inputunit(p):\n    '''inputunit : simple_list simple_list_terminator\n                 | NEWLINE\n                 | error NEWLINE\n                 | EOF'''\n    # XXX\n    if p.lexer._parserstate & flags.parser.CMDSUBST:\n        p.lexer._parserstate.add(flags.parser.EOFTOKEN)\n\n    if isinstance(p[1], ast.node):\n        p[0] = p[1]\n        # accept right here in case the input contains more lines that are\n        # not part of the current command\n        p.accept()", "response": "inputunit is a simple list of simple_list terminator terminator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_word_list(p):\n    '''word_list : WORD\n                 | word_list WORD'''\n    parserobj = p.context\n    if len(p) == 2:\n        p[0] = [_expandword(parserobj, p.slice[1])]\n    else:\n        p[0] = p[1]\n        p[0].append(_expandword(parserobj, p.slice[2]))", "response": "word_list : word_list | word_list WORD"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_redirection_heredoc(p):\n    '''redirection : LESS_LESS WORD\n                   | NUMBER LESS_LESS WORD\n                   | REDIR_WORD LESS_LESS WORD\n                   | LESS_LESS_MINUS WORD\n                   | NUMBER LESS_LESS_MINUS WORD\n                   | REDIR_WORD LESS_LESS_MINUS WORD'''\n    parserobj = p.context\n    assert isinstance(parserobj, _parser)\n\n    output = ast.node(kind='word', word=p[len(p)-1], parts=[],\n                      pos=p.lexspan(len(p)-1))\n    if len(p) == 3:\n        p[0] = ast.node(kind='redirect', input=None, type=p[1], heredoc=None,\n                        output=output, pos=(p.lexpos(1), p.endlexpos(2)))\n    else:\n        p[0] = ast.node(kind='redirect', input=p[1], type=p[2], heredoc=None,\n                        output=output, pos=(p.lexpos(1), p.endlexpos(3)))\n\n    if p.slice[len(p)-2].ttype == tokenizer.tokentype.LESS_LESS:\n        parserobj.redirstack.append((p[0], False))\n    else:\n        parserobj.redirstack.append((p[0], True))", "response": "redirection is a list of nodes that are not part of a heredoc."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a redirection from the top level to the bottom of the tree", "response": "def p_redirection(p):\n    '''redirection : GREATER WORD\n                   | LESS WORD\n                   | NUMBER GREATER WORD\n                   | NUMBER LESS WORD\n                   | REDIR_WORD GREATER WORD\n                   | REDIR_WORD LESS WORD\n                   | GREATER_GREATER WORD\n                   | NUMBER GREATER_GREATER WORD\n                   | REDIR_WORD GREATER_GREATER WORD\n                   | GREATER_BAR WORD\n                   | NUMBER GREATER_BAR WORD\n                   | REDIR_WORD GREATER_BAR WORD\n                   | LESS_GREATER WORD\n                   | NUMBER LESS_GREATER WORD\n                   | REDIR_WORD LESS_GREATER WORD\n                   | LESS_LESS_LESS WORD\n                   | NUMBER LESS_LESS_LESS WORD\n                   | REDIR_WORD LESS_LESS_LESS WORD\n                   | LESS_AND NUMBER\n                   | NUMBER LESS_AND NUMBER\n                   | REDIR_WORD LESS_AND NUMBER\n                   | GREATER_AND NUMBER\n                   | NUMBER GREATER_AND NUMBER\n                   | REDIR_WORD GREATER_AND NUMBER\n                   | LESS_AND WORD\n                   | NUMBER LESS_AND WORD\n                   | REDIR_WORD LESS_AND WORD\n                   | GREATER_AND WORD\n                   | NUMBER GREATER_AND WORD\n                   | REDIR_WORD GREATER_AND WORD\n                   | GREATER_AND DASH\n                   | NUMBER GREATER_AND DASH\n                   | REDIR_WORD GREATER_AND DASH\n                   | LESS_AND DASH\n                   | NUMBER LESS_AND DASH\n                   | REDIR_WORD LESS_AND DASH\n                   | AND_GREATER WORD\n                   | AND_GREATER_GREATER WORD'''\n    parserobj = p.context\n    if len(p) == 3:\n        output = p[2]\n        if p.slice[2].ttype == tokenizer.tokentype.WORD:\n            output = _expandword(parserobj, p.slice[2])\n        p[0] = ast.node(kind='redirect', input=None, type=p[1], heredoc=None,\n                        output=output, pos=(p.lexpos(1), p.endlexpos(2)))\n    else:\n        output = p[3]\n        if p.slice[3].ttype == tokenizer.tokentype.WORD:\n            output = _expandword(parserobj, p.slice[3])\n        p[0] = ast.node(kind='redirect', input=p[1], type=p[2], heredoc=None,\n                        output=output, pos=(p.lexpos(1), p.endlexpos(3)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_simple_command_element(p):\n    '''simple_command_element : WORD\n                              | ASSIGNMENT_WORD\n                              | redirection'''\n    if isinstance(p[1], ast.node):\n        p[0] = [p[1]]\n        return\n\n    parserobj = p.context\n    p[0] = [_expandword(parserobj, p.slice[1])]\n\n    # change the word node to an assignment if necessary\n    if p.slice[1].ttype == tokenizer.tokentype.ASSIGNMENT_WORD:\n        p[0][0].kind = 'assignment'", "response": "Simple command element parser."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_redirection_list(p):\n    '''redirection_list : redirection\n                        | redirection_list redirection'''\n    if len(p) == 2:\n        p[0] = [p[1]]\n    else:\n        p[0] = p[1]\n        p[0].append(p[2])", "response": "redirection_list is a list of redirections."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncommand : simple_command | shell_command | shell_command redirection_list | function_def | coproc", "response": "def p_command(p):\n    '''command : simple_command\n               | shell_command\n               | shell_command redirection_list\n               | function_def\n               | coproc'''\n    if isinstance(p[1], ast.node):\n        p[0] = p[1]\n        if len(p) == 3:\n            assert p[0].kind == 'compound'\n            p[0].redirects.extend(p[2])\n            assert p[0].pos[0] < p[0].redirects[-1].pos[1]\n            p[0].pos = (p[0].pos[0], p[0].redirects[-1].pos[1])\n    else:\n        p[0] = ast.node(kind='command', parts=p[1], pos=_partsspan(p[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_shell_command(p):\n    '''shell_command : for_command\n                     | case_command\n                     | WHILE compound_list DO compound_list DONE\n                     | UNTIL compound_list DO compound_list DONE\n                     | select_command\n                     | if_command\n                     | subshell\n                     | group_command\n                     | arith_command\n                     | cond_command\n                     | arith_for_command'''\n    if len(p) == 2:\n        p[0] = p[1]\n    else:\n        # while or until\n        assert p[2].kind == 'list'\n\n        parts = _makeparts(p)\n        kind = parts[0].word\n        assert kind in ('while', 'until')\n        p[0] = ast.node(kind='compound',\n                        redirects=[],\n                        list=[ast.node(kind=kind, parts=parts, pos=_partsspan(parts))],\n                        pos=_partsspan(parts))\n\n    assert p[0].kind == 'compound'", "response": "shell_command : for_command\n                     | case_command\n                     | WHILE compound_list DO compound_list DONE\n                     | UNTIL compound_list DO compound_list DONE\n                     | select_command\n                     | if_command\n                     | subshell\n                     | group_command\n                     | arith_command\n                     | cond_command\n                     | arith_for_command"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_for_command(p):\n    '''for_command : FOR WORD newline_list DO compound_list DONE\n                   | FOR WORD newline_list LEFT_CURLY compound_list RIGHT_CURLY\n                   | FOR WORD SEMICOLON newline_list DO compound_list DONE\n                   | FOR WORD SEMICOLON newline_list LEFT_CURLY compound_list RIGHT_CURLY\n                   | FOR WORD newline_list IN word_list list_terminator newline_list DO compound_list DONE\n                   | FOR WORD newline_list IN word_list list_terminator newline_list LEFT_CURLY compound_list RIGHT_CURLY\n                   | FOR WORD newline_list IN list_terminator newline_list DO compound_list DONE\n                   | FOR WORD newline_list IN list_terminator newline_list LEFT_CURLY compound_list RIGHT_CURLY'''\n    parts = _makeparts(p)\n    # find the operatornode that we might have there due to\n    # list_terminator/newline_list and convert it to a reservedword so its\n    # considered as part of the for loop\n    for i, part in enumerate(parts):\n        if part.kind == 'operator' and part.op == ';':\n            parts[i] = ast.node(kind='reservedword', word=';', pos=part.pos)\n            break # there could be only one in there...\n\n    p[0] = ast.node(kind='compound',\n                    redirects=[],\n                    list=[ast.node(kind='for', parts=parts, pos=_partsspan(parts))],\n                    pos=_partsspan(parts))", "response": "converts a command to a for statement"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a compound command to the node list.", "response": "def p_if_command(p):\n    '''if_command : IF compound_list THEN compound_list FI\n                  | IF compound_list THEN compound_list ELSE compound_list FI\n                  | IF compound_list THEN compound_list elif_clause FI'''\n    # we currently don't distinguish the various lists that make up the\n    # command, because it's not needed later on. if there will be a need\n    # we can always add different nodes for elif/else.\n    parts = _makeparts(p)\n    p[0] = ast.node(kind='compound',\n                    redirects=[],\n                    list=[ast.node(kind='if', parts=parts, pos=_partsspan(parts))],\n                    pos=_partsspan(parts))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_group_command(p):\n    '''group_command : LEFT_CURLY compound_list RIGHT_CURLY'''\n    lcurly = ast.node(kind='reservedword', word=p[1], pos=p.lexspan(1))\n    rcurly = ast.node(kind='reservedword', word=p[3], pos=p.lexspan(3))\n    parts = [lcurly, p[2], rcurly]\n    p[0] = ast.node(kind='compound', list=parts, redirects=[],\n                    pos=_partsspan(parts))", "response": "group_command : LEFT_CURLY compound_list RIGHT_CURLY"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_list0(p):\n    '''list0 : list1 NEWLINE newline_list\n             | list1 AMPERSAND newline_list\n             | list1 SEMICOLON newline_list'''\n    parts = p[1]\n    if len(parts) > 1 or p.slice[2].ttype != tokenizer.tokentype.NEWLINE:\n        parts.append(ast.node(kind='operator', op=p[2], pos=p.lexspan(2)))\n        p[0] = ast.node(kind='list', parts=parts, pos=_partsspan(parts))\n    else:\n        p[0] = parts[0]", "response": "parse a list0 token"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a list terminator", "response": "def p_list_terminator(p):\n    '''list_terminator : NEWLINE\n                       | SEMICOLON\n                       | EOF'''\n    if p[1] == ';':\n        p[0] = ast.node(kind='operator', op=';', pos=p.lexspan(1))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_simple_list(p):\n    '''simple_list : simple_list1\n                   | simple_list1 AMPERSAND\n                   | simple_list1 SEMICOLON'''\n    tok = p.lexer\n    heredoc.gatherheredocuments(tok)\n\n    if len(p) == 3 or len(p[1]) > 1:\n        parts = p[1]\n        if len(p) == 3:\n            parts.append(ast.node(kind='operator', op=p[2], pos=p.lexspan(2)))\n        p[0] = ast.node(kind='list', parts=parts, pos=_partsspan(parts))\n    else:\n        assert len(p[1]) == 1\n        p[0] = p[1][0]\n\n    if (len(p) == 2 and p.lexer._parserstate & flags.parser.CMDSUBST and\n            p.lexer._current_token.nopos() == p.lexer._shell_eof_token):\n        # accept the input\n        p.accept()", "response": "simple_list : simple_list1\n                   | simple_list1 AMPERSAND\n                   | simple_list1 SEMICOLON"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_simple_list1(p):\n    '''simple_list1 : simple_list1 AND_AND newline_list simple_list1\n                    | simple_list1 OR_OR newline_list simple_list1\n                    | simple_list1 AMPERSAND simple_list1\n                    | simple_list1 SEMICOLON simple_list1\n                    | pipeline_command'''\n    if len(p) == 2:\n        p[0] = [p[1]]\n    else:\n        p[0] = p[1]\n        p[0].append(ast.node(kind='operator', op=p[2], pos=p.lexspan(2)))\n        p[0].extend(p[len(p) - 1])", "response": "simple_list1 : simple_list1 AND_AND newline_list simple_list1\n                    | simple_list1 OR_OR newline_list simple_list1\n                    | simple_list1 AMPERSAND simple_list1\n                    | simple_list1 SEMICOLON simple_list1\n                    | pipeline_command"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_pipeline_command(p):\n    '''pipeline_command : pipeline\n                        | BANG pipeline_command\n                        | timespec pipeline_command\n                        | timespec list_terminator\n                        | BANG list_terminator'''\n    if len(p) == 2:\n        if len(p[1]) == 1:\n            p[0] = p[1][0]\n        else:\n            p[0] = ast.node(kind='pipeline', parts=p[1],\n                            pos=(p[1][0].pos[0], p[1][-1].pos[1]))\n    else:\n        # XXX timespec\n        node = ast.node(kind='reservedword', word='!', pos=p.lexspan(1))\n        if p[2].kind == 'pipeline':\n            p[0] = p[2]\n            p[0].parts.insert(0, node)\n            p[0].pos = (p[0].parts[0].pos[0], p[0].parts[-1].pos[1])\n        else:\n            p[0] = ast.node(kind='pipeline', parts=[node, p[2]],\n                            pos=(node.pos[0], p[2].pos[1]))", "response": "A pipeline command is a list of two or more nodes. Each node is a node with the name of the last node in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parsesingle(s, strictmode=True, expansionlimit=None, convertpos=False):\n    '''like parse, but only consumes a single top level node, e.g. parsing\n    'a\\nb' will only return a node for 'a', leaving b unparsed'''\n    p = _parser(s, strictmode=strictmode, expansionlimit=expansionlimit)\n    tree = p.parse()\n    if convertpos:\n        ast.posconverter(s).visit(tree)\n    return tree", "response": "like parse but only consumes a single top level node e. g. parse\n    a \\ nb will only return a node for a \\ nb"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the input string returning a list of nodes where the first node is a simple command pipeline and the second is a simple pipeline and the rest are simple commands and pipeline.", "response": "def parse(s, strictmode=True, expansionlimit=None, convertpos=False):\n    '''parse the input string, returning a list of nodes\n\n    top level node kinds are:\n\n    - command - a simple command\n    - pipeline - a series of simple commands\n    - list - a series of one or more pipelines\n    - compound - contains constructs for { list; }, (list), if, for..\n\n    leafs are word nodes (which in turn can also contain any of the\n    aforementioned nodes due to command substitutions).\n\n    when strictmode is set to False, we will:\n    - skip reading a heredoc if we're at the end of the input\n\n    expansionlimit is used to limit the amount of recursive parsing done due to\n    command substitutions found during word expansion.\n    '''\n    p = _parser(s, strictmode=strictmode, expansionlimit=expansionlimit)\n    parts = [p.parse()]\n\n    class endfinder(ast.nodevisitor):\n        def __init__(self):\n            self.end = -1\n        def visitheredoc(self, node, value):\n            self.end = node.pos[1]\n\n    # find the 'real' end incase we have a heredoc in there\n    ef = _endfinder()\n    ef.visit(parts[-1])\n    index = max(parts[-1].pos[1], ef.end) + 1\n    while index < len(s):\n        part = _parser(s[index:], strictmode=strictmode).parse()\n\n        if not isinstance(part, ast.node):\n            break\n\n        ast.posshifter(index).visit(part)\n        parts.append(part)\n        ef = _endfinder()\n        ef.visit(parts[-1])\n        index = max(parts[-1].pos[1], ef.end) + 1\n\n    if convertpos:\n        for tree in parts:\n            ast.posconverter(s).visit(tree)\n\n    return parts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a wrapped function that rescues rate limit exceptions, sleeping the current thread until rate limit resets. :param function func: The function to decorate. :return: Decorated function. :rtype: function", "response": "def sleep_and_retry(func):\n    '''\n    Return a wrapped function that rescues rate limit exceptions, sleeping the\n    current thread until rate limit resets.\n\n    :param function func: The function to decorate.\n    :return: Decorated function.\n    :rtype: function\n    '''\n    @wraps(func)\n    def wrapper(*args, **kargs):\n        '''\n        Call the rate limited function. If the function raises a rate limit\n        exception sleep for the remaing time period and retry the function.\n\n        :param args: non-keyword variable length argument list to the decorated function.\n        :param kargs: keyworded variable length argument list to the decorated function.\n        '''\n        while True:\n            try:\n                return func(*args, **kargs)\n            except RateLimitException as exception:\n                time.sleep(exception.period_remaining)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the remaining period for the current rate limit window.", "response": "def __period_remaining(self):\n        '''\n        Return the period remaining for the current rate limit window.\n\n        :return: The remaing period.\n        :rtype: float\n        '''\n        elapsed = self.clock() - self.last_reset\n        return self.period - elapsed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter the lines from comments and non code lines.", "response": "def filter_lines_from_comments(lines):\n    \"\"\" Filter the lines from comments and non code lines. \"\"\"\n    for line_nb, raw_line in enumerate(lines):\n        clean_line = remove_comments_from_line(raw_line)\n        if clean_line == '':\n            continue\n        yield line_nb, clean_line, raw_line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nraise exception if we try to add a relation or a column with no current table.", "response": "def _check_no_current_table(new_obj, current_table):\n    \"\"\" Raises exception if we try to add a relation or a column\n    with no current table. \"\"\"\n    if current_table is None:\n        msg = 'Cannot add {} before adding table'\n        if isinstance(new_obj, Relation):\n            raise NoCurrentTableException(msg.format('relation'))\n        if isinstance(new_obj, Column):\n            raise NoCurrentTableException(msg.format('column'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_models(new_obj, current_table, tables, relations):\n    _update_check_inputs(current_table, tables, relations)\n    _check_no_current_table(new_obj, current_table)\n\n    if isinstance(new_obj, Table):\n        tables_names = [t.name for t in tables]\n        _check_not_creating_duplicates(new_obj.name, tables_names, 'table', DuplicateTableException)\n        return new_obj, tables + [new_obj], relations\n\n    if isinstance(new_obj, Relation):\n        tables_names = [t.name for t in tables]\n        _check_colname_in_lst(new_obj.right_col, tables_names)\n        _check_colname_in_lst(new_obj.left_col, tables_names)\n        return current_table, tables, relations + [new_obj]\n\n    if isinstance(new_obj, Column):\n        columns_names = [c.name for c in current_table.columns]\n        _check_not_creating_duplicates(new_obj.name, columns_names, 'column', DuplicateColumnException)\n        current_table.columns.append(new_obj)\n        return current_table, tables, relations\n\n    msg = \"new_obj cannot be of type {}\"\n    raise ValueError(msg.format(new_obj.__class__.__name__))", "response": "Update the state of the parsing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef markdown_file_to_intermediary(filename):\n    with open(filename) as f:\n        lines = f.readlines()\n    return line_iterator_to_intermediary(lines)", "response": "Parse a file and return to intermediary syntax."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef line_iterator_to_intermediary(line_iterator):\n    current_table = None\n    tables = []\n    relations = []\n    errors = []\n    for line_nb, line, raw_line in filter_lines_from_comments(line_iterator):\n        try:\n            new_obj = parse_line(line)\n            current_table, tables, relations = update_models(new_obj, current_table, tables, relations)\n        except ParsingException as e:\n            e.line_nb = line_nb\n            e.line = raw_line\n            errors.append(e)\n    if len(errors) != 0:\n        msg = 'ERAlchemy couldn\\'t complete the generation due the {} following errors'.format(len(errors))\n        raise ParsingException(msg + '\\n\\n'.join(e.traceback for e in errors))\n    return tables, relations", "response": "Parse an iterator of str to the intermediary syntax"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_args(args):\n    check_args_has_attributes(args)\n    if args.v:\n        non_version_attrs = [v for k, v in args.__dict__.items() if k != 'v']\n        print('non_version_attrs', non_version_attrs)\n        if len([v for v in non_version_attrs if v is not None]) != 0:\n            fail('Cannot show the version number with another command.')\n        return\n    if args.i is None:\n        fail('Cannot draw ER diagram of no database.')\n    if args.o is None:\n        fail('Cannot draw ER diagram with no output file.')", "response": "Checks that the args are coherent."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform an SQLAlchemy ForeignKey object to it s intermediary representation.", "response": "def relation_to_intermediary(fk):\n    \"\"\"Transform an SQLAlchemy ForeignKey object to it's intermediary representation. \"\"\"\n    return Relation(\n        right_col=format_name(fk.parent.table.fullname),\n        left_col=format_name(fk._column_tokens[1]),\n        right_cardinality='?',\n        left_cardinality='*',\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef column_to_intermediary(col, type_formatter=format_type):\n    return Column(\n        name=col.name,\n        type=type_formatter(col.type),\n        is_key=col.primary_key,\n    )", "response": "Transform an SQLAlchemy Column object to it s intermediary representation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform an SQLAlchemy Table object to it s intermediary representation.", "response": "def table_to_intermediary(table):\n    \"\"\"Transform an SQLAlchemy Table object to it's intermediary representation. \"\"\"\n    return Table(\n        name=table.fullname,\n        columns=[column_to_intermediary(col) for col in table.c._data.values()]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms SQLAlchemy metadata to the intermediary representation.", "response": "def metadata_to_intermediary(metadata):\n    \"\"\" Transforms SQLAlchemy metadata to the intermediary representation. \"\"\"\n    tables = [table_to_intermediary(table) for table in metadata.tables.values()]\n    relationships = [relation_to_intermediary(fk) for table in metadata.tables.values() for fk in table.foreign_keys]\n    return tables, relationships"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the name of the scalar relationship.", "response": "def name_for_scalar_relationship(base, local_cls, referred_cls, constraint):\n    \"\"\" Overriding naming schemes. \"\"\"\n    name = referred_cls.__name__.lower() + \"_ref\"\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef database_to_intermediary(database_uri, schema=None):\n    from sqlalchemy.ext.automap import automap_base\n    from sqlalchemy import create_engine\n\n    Base = automap_base()\n    engine = create_engine(database_uri)\n    if schema is not None:\n        Base.metadata.schema = schema\n\n    # reflect the tables\n    Base.prepare(engine, reflect=True, name_for_scalar_relationship=name_for_scalar_relationship)\n    return declarative_to_intermediary(Base)", "response": "Introspect from the database to create the intermediary representation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the args and return the type of update", "response": "def parse_args():\n    \"\"\" Parse the args, returns if the type of update:\n    Major, minor, fix\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-M', action='store_true')\n    parser.add_argument('-m', action='store_true')\n    parser.add_argument('-f', action='store_true')\n    args = parser.parse_args()\n    major, minor, fix = args.M, args.m, args.f\n    if major + minor + fix != 1:\n        fail('Please select one and only one action.')\n    return major, minor, fix"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli():\n    parser = get_argparser()\n\n    args = parser.parse_args()\n    check_args(args)\n    if args.v:\n        print('ERAlchemy version {}.'.format(__version__))\n        exit(0)\n    render_er(\n        args.i,\n        args.o,\n        include_tables=args.include_tables,\n        include_columns=args.include_columns,\n        exclude_tables=args.exclude_tables,\n        exclude_columns=args.exclude_columns,\n        schema=args.s\n    )", "response": "Entry point for the application script"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the intermediary representation to markdown.", "response": "def intermediary_to_markdown(tables, relationships, output):\n    \"\"\" Saves the intermediary representation to markdown. \"\"\"\n    er_markup = _intermediary_to_markdown(tables, relationships)\n    with open(output, \"w\") as file_out:\n        file_out.write(er_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the intermediary representation of the current node to dot format.", "response": "def intermediary_to_dot(tables, relationships, output):\n    \"\"\" Save the intermediary representation to dot format. \"\"\"\n    dot_file = _intermediary_to_dot(tables, relationships)\n    with open(output, \"w\") as file_out:\n        file_out.write(dot_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform and saves the intermediary representation to a file.", "response": "def intermediary_to_schema(tables, relationships, output):\n    \"\"\" Transforms and save the intermediary representation to the file chosen. \"\"\"\n    dot_file = _intermediary_to_dot(tables, relationships)\n    graph = AGraph()\n    graph = graph.from_string(dot_file)\n    extension = output.split('.')[-1]\n    graph.draw(path=output, prog='dot', format=extension)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _intermediary_to_markdown(tables, relationships):\n    t = '\\n'.join(t.to_markdown() for t in tables)\n    r = '\\n'.join(r.to_markdown() for r in relationships)\n    return '{}\\n{}'.format(t, r)", "response": "Returns the er markup source in a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _intermediary_to_dot(tables, relationships):\n    t = '\\n'.join(t.to_dot() for t in tables)\n    r = '\\n'.join(r.to_dot() for r in relationships)\n    return '{}\\n{}\\n{}\\n}}'.format(GRAPH_BEGINNING, t, r)", "response": "Returns the dot source representing the database in a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndispatches the filename_or_input to the different function to produce the intermediary syntax.", "response": "def all_to_intermediary(filename_or_input, schema=None):\n    \"\"\" Dispatch the filename_or_input to the different function to produce the intermediary syntax.\n    All the supported classes names are in `swich_input_class_to_method`.\n    The input can also be a list of strings in markdown format or a filename finishing by '.er' containing markdown\n    format.\n    \"\"\"\n    # Try to convert from the name of the class\n    input_class_name = filename_or_input.__class__.__name__\n    try:\n        this_to_intermediary = switch_input_class_to_method[input_class_name]\n        tables, relationships = this_to_intermediary(filename_or_input)\n        return tables, relationships\n    except KeyError:\n        pass\n\n    # try to read markdown file.\n    if isinstance(filename_or_input, basestring):\n        if filename_or_input.split('.')[-1] == 'er':\n            return markdown_file_to_intermediary(filename_or_input)\n\n    # try to read a markdown in a string\n    if not isinstance(filename_or_input, basestring):\n        if all(isinstance(e, basestring) for e in filename_or_input):\n            return line_iterator_to_intermediary(filename_or_input)\n\n    # try to read DB URI.\n    try:\n        make_url(filename_or_input)\n        return database_to_intermediary(filename_or_input, schema=schema)\n    except ArgumentError:\n        pass\n\n    msg = 'Cannot process filename_or_input {}'.format(input_class_name)\n    raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_output_mode(output, mode):\n    if mode != 'auto':\n        try:\n            return switch_output_mode_auto[mode]\n        except KeyError:\n            raise ValueError('Mode \"{}\" is not supported.')\n\n    extension = output.split('.')[-1]\n    try:\n        return switch_output_mode[extension]\n    except KeyError:\n        return intermediary_to_schema", "response": "Returns a function that will transform the intermediary\n    representation to the output name and the mode returns a function that will transform the intermediary\n    representation to the output name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering the tables and relationships for a single resource.", "response": "def filter_resources(tables, relationships,\n                     include_tables=None, include_columns=None,\n                     exclude_tables=None, exclude_columns=None):\n    \"\"\"\n    Include the following:\n        1. Tables and relationships with tables present in the include_tables (lst of str, tables names)\n        2. Columns (of whichever table) present in the include_columns (lst of str, columns names)\n    Exclude the following:\n        1. Tables and relationships with tables present in the exclude_tables (lst of str, tables names)\n        2. Columns (of whichever table) present in the exclude_columns (lst of str, columns names)\n    Disclosure note:\n        All relationships are taken into consideration before ignoring columns.\n        In other words, if one excludes primary or foreign keys, it will still keep the relations display amongst tables\n    \"\"\"\n    _tables = copy.deepcopy(tables)\n    _relationships = copy.deepcopy(relationships)\n\n    include_tables = include_tables or [t.name for t in _tables]\n    include_columns = include_columns or [c.name for t in _tables for c in t.columns]\n    exclude_tables = exclude_tables or list()\n    exclude_columns = exclude_columns or list()\n\n    _tables = [t for t in _tables if t.name not in exclude_tables and t.name in include_tables]\n    _relationships = [r for r in _relationships\n                      if r.right_col not in exclude_tables\n                      and r.left_col not in exclude_tables\n                      and r.right_col in include_tables\n                      and r.left_col in include_tables]\n\n    for t in _tables:\n        t.columns = [c for c in t.columns if c.name not in exclude_columns and c.name in include_columns]\n\n    return _tables, _relationships"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming the metadata into a graph.", "response": "def render_er(input, output, mode='auto', include_tables=None, include_columns=None,\n              exclude_tables=None, exclude_columns=None, schema=None):\n    \"\"\"\n    Transform the metadata into a representation.\n    :param input: Possible inputs are instances of:\n        MetaData: SQLAlchemy Metadata\n        DeclarativeMeta: SQLAlchemy declarative Base\n    :param output: name of the file to output the\n    :param mode: str in list:\n        'er': writes to a file the markup to generate an ER style diagram.\n        'graph': writes the image of the ER diagram.\n        'dot': write to file the diagram in dot format.\n        'auto': choose from the filename:\n            '*.er': writes to a file the markup to generate an ER style diagram.\n            '.dot': returns the graph in the dot syntax.\n            else: return a graph to the format graph\n    :param include_tables: lst of str, table names to include, None means include all\n    :param include_columns: lst of str, column names to include, None means include all\n    :param exclude_tables: lst of str, table names to exclude, None means exclude nothing\n    :param exclude_columns: lst of str, field names to exclude, None means exclude nothing\n    :param schema: name of the schema\n    \"\"\"\n    try:\n        tables, relationships = all_to_intermediary(input, schema=schema)\n        tables, relationships = filter_resources(tables, relationships,\n                                                 include_tables=include_tables, include_columns=include_columns,\n                                                 exclude_tables=exclude_tables, exclude_columns=exclude_columns)\n        intermediary_to_output = get_output_mode(output, mode)\n        intermediary_to_output(tables, relationships, output)\n    except ImportError as e:\n        module_name = e.message.split()[-1]\n        print('Please install {0} using \"pip install {0}\".'.format(module_name))\n    except ParsingException as e:\n        sys.stderr.write(e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines the OS and platform and set the copy and paste functions accordingly.", "response": "def determine_clipboard():\n    '''\n    Determine the OS/platform and set the copy() and paste() functions\n    accordingly.\n    '''\n\n    global Foundation, AppKit, gtk, qtpy, PyQt4, PyQt5\n\n    # Setup for the CYGWIN platform:\n    if 'cygwin' in platform.system().lower(): # Cygwin has a variety of values returned by platform.system(), such as 'CYGWIN_NT-6.1'\n        # FIXME: pyperclip currently does not support Cygwin,\n        # see https://github.com/asweigart/pyperclip/issues/55\n        if os.path.exists('/dev/clipboard'):\n            warnings.warn('Pyperclip\\'s support for Cygwin is not perfect, see https://github.com/asweigart/pyperclip/issues/55')\n            return init_dev_clipboard_clipboard()\n\n    # Setup for the WINDOWS platform:\n    elif os.name == 'nt' or platform.system() == 'Windows':\n        return init_windows_clipboard()\n\n    if platform.system() == 'Linux':\n        with open('/proc/version', 'r') as f:\n            if \"Microsoft\" in f.read():\n                return init_wsl_clipboard()\n\n    # Setup for the MAC OS X platform:\n    if os.name == 'mac' or platform.system() == 'Darwin':\n        try:\n            import Foundation  # check if pyobjc is installed\n            import AppKit\n        except ImportError:\n            return init_osx_pbcopy_clipboard()\n        else:\n            return init_osx_pyobjc_clipboard()\n\n    # Setup for the LINUX platform:\n    if HAS_DISPLAY:\n        try:\n            import gtk  # check if gtk is installed\n        except ImportError:\n            pass # We want to fail fast for all non-ImportError exceptions.\n        else:\n            return init_gtk_clipboard()\n\n        if _executable_exists(\"xsel\"):\n            return init_xsel_clipboard()\n        if _executable_exists(\"xclip\"):\n            return init_xclip_clipboard()\n        if _executable_exists(\"klipper\") and _executable_exists(\"qdbus\"):\n            return init_klipper_clipboard()\n\n        try:\n            # qtpy is a small abstraction layer that lets you write applications using a single api call to either PyQt or PySide.\n            # https://pypi.python.org/pypi/QtPy\n            import qtpy  # check if qtpy is installed\n        except ImportError:\n            # If qtpy isn't installed, fall back on importing PyQt4.\n            try:\n                import PyQt5  # check if PyQt5 is installed\n            except ImportError:\n                try:\n                    import PyQt4  # check if PyQt4 is installed\n                except ImportError:\n                    pass # We want to fail fast for all non-ImportError exceptions.\n                else:\n                    return init_qt_clipboard()\n            else:\n                return init_qt_clipboard()\n        else:\n            return init_qt_clipboard()\n\n\n    return init_no_clipboard()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_clipboard(clipboard):\n    '''\n    Explicitly sets the clipboard mechanism. The \"clipboard mechanism\" is how\n    the copy() and paste() functions interact with the operating system to\n    implement the copy/paste feature. The clipboard parameter must be one of:\n        - pbcopy\n        - pbobjc (default on Mac OS X)\n        - gtk\n        - qt\n        - xclip\n        - xsel\n        - klipper\n        - windows (default on Windows)\n        - no (this is what is set when no clipboard mechanism can be found)\n    '''\n    global copy, paste\n\n    clipboard_types = {'pbcopy': init_osx_pbcopy_clipboard,\n                       'pyobjc': init_osx_pyobjc_clipboard,\n                       'gtk': init_gtk_clipboard,\n                       'qt': init_qt_clipboard, # TODO - split this into 'qtpy', 'pyqt4', and 'pyqt5'\n                       'xclip': init_xclip_clipboard,\n                       'xsel': init_xsel_clipboard,\n                       'klipper': init_klipper_clipboard,\n                       'windows': init_windows_clipboard,\n                       'no': init_no_clipboard}\n\n    if clipboard not in clipboard_types:\n        raise ValueError('Argument must be one of %s' % (', '.join([repr(_) for _ in clipboard_types.keys()])))\n\n    # Sets pyperclip's copy() and paste() functions:\n    copy, paste = clipboard_types[clipboard]()", "response": "Explicitly sets the clipboard mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_data(data: dict) -> dict:\n    new_data = {}\n    for key, value in data.items():\n        # Verify that only explicitly passed args get passed on\n        if not isinstance(value, bool) and not value:\n            continue\n\n        # Multiple choice command are passed as tuples, convert to list to match schema\n        if isinstance(value, tuple):\n            value = list(value)\n        new_data[key] = value\n    return new_data", "response": "Removes all empty values and converts tuples into lists"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef params_factory(schema: dict, add_message: bool) -> list:\n\n    # Immediately create message as an argument\n    params = []\n    if add_message:\n        params.append(click.Argument([\"message\"], required=False))\n\n    for property, prpty_schema in schema.items():\n        multiple = False\n        choices = None\n\n        if any(char in property for char in [\"@\"]):\n            continue\n        if prpty_schema.get(\"type\") in COMPLEX_TYPES:\n            continue\n        if prpty_schema.get(\"duplicate\"):\n            continue\n        if property == \"message\":\n            continue\n\n        elif not prpty_schema.get(\"oneOf\"):\n            click_type, description, choices = json_schema_to_click_type(prpty_schema)\n        else:\n            click_type, multiple, description = handle_oneof(prpty_schema[\"oneOf\"])\n            # Not all oneOf schema can be handled by click\n            if not click_type:\n                continue\n\n        # Convert bool values into flags\n        if click_type == click.BOOL:\n            param_decls = [get_flag_param_decals_from_bool(property)]\n            click_type = None\n        else:\n            param_decls = [get_param_decals_from_name(property)]\n\n        if description:\n            description = description.capitalize()\n\n            if multiple:\n                if not description.endswith(\".\"):\n                    description += \".\"\n                description += \" Multiple usages of this option are allowed\"\n        # Construct the base command options\n        option = partial(\n            click.Option, param_decls=param_decls, help=description, multiple=multiple\n        )\n\n        if choices:\n            option = option(type=choices)\n        elif click_type:\n            option = option(type=click_type)\n        else:\n            option = option()\n        params.append(option)\n    return params", "response": "Generates a list of click. Command objects based on a JSON schema."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef schema_to_command(\n    p, name: str, callback: callable, add_message: bool\n) -> click.Command:\n    \"\"\"\n    Generates a ``notify`` :class:`click.Command` for :class:`~notifiers.core.Provider`\n\n    :param p: Relevant Provider\n    :param name: Command name\n    :return: A ``notify`` :class:`click.Command`\n    \"\"\"\n    params = params_factory(p.schema[\"properties\"], add_message=add_message)\n    help = p.__doc__\n    cmd = click.Command(name=name, callback=callback, params=params, help=help)\n    return cmd", "response": "Generates a click. Command for a given Provider."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an instantiated instance of the given provider name.", "response": "def get_notifier(provider_name: str, strict: bool = False) -> Provider:\n    \"\"\"\n    Convenience method to return an instantiated :class:`~notifiers.core.Provider` object according to it ``name``\n\n    :param provider_name: The ``name`` of the requested :class:`~notifiers.core.Provider`\n    :param strict: Raises a :class:`ValueError` if the given provider string was not found\n    :return: :class:`Provider` or None\n    :raises ValueError: In case ``strict`` is True and provider not found\n    \"\"\"\n    if provider_name in _all_providers:\n        log.debug(\"found a match for '%s', returning\", provider_name)\n        return _all_providers[provider_name]()\n    elif strict:\n        raise NoSuchNotifierError(name=provider_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notify(provider_name: str, **kwargs) -> Response:\n    return get_notifier(provider_name=provider_name, strict=True).notify(**kwargs)", "response": "Quickly sends a notification to the specified provider."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raise_on_errors(self):\n        if self.errors:\n            raise NotificationError(\n                provider=self.provider,\n                data=self.data,\n                errors=self.errors,\n                response=self.response,\n            )", "response": "Raises an exception if response hold errors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef schema(self) -> dict:\n        if not self._merged_schema:\n            log.debug(\"merging required dict into schema for %s\", self.name)\n            self._merged_schema = self._schema.copy()\n            self._merged_schema.update(self._required)\n        return self._merged_schema", "response": "A property method that will return the constructed provider schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a Response object for the given data and response.", "response": "def create_response(\n        self, data: dict = None, response: requests.Response = None, errors: list = None\n    ) -> Response:\n        \"\"\"\n        Helper function to generate a :class:`~notifiers.core.Response` object\n\n        :param data: The data that was used to send the notification\n        :param response: :class:`requests.Response` if exist\n        :param errors: List of errors if relevant\n        \"\"\"\n        status = FAILURE_STATUS if errors else SUCCESS_STATUS\n        return Response(\n            status=status,\n            provider=self.name,\n            data=data,\n            response=response,\n            errors=errors,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _merge_defaults(self, data: dict) -> dict:\n        log.debug(\"merging defaults %s into data %s\", self.defaults, data)\n        return merge_dicts(data, self.defaults)", "response": "Helper method that merges default values into provided data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_environs(self, prefix: str = None) -> dict:\n        if not prefix:\n            log.debug(\"using default environ prefix\")\n            prefix = DEFAULT_ENVIRON_PREFIX\n        return dict_from_environs(prefix, self.name, list(self.arguments.keys()))", "response": "Fetches set environment variables if such exist via the : func:`~notifiers. utils. dict_from_environs`"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the provider schema for syntax issues. Raises SchemaError if not relevant.", "response": "def _validate_schema(self):\n        \"\"\"\n        Validates provider schema for syntax issues. Raises :class:`~notifiers.exceptions.SchemaError` if relevant\n\n        :raises: :class:`~notifiers.exceptions.SchemaError`\n        \"\"\"\n        try:\n            log.debug(\"validating provider schema\")\n            self.validator.check_schema(self.schema)\n        except jsonschema.SchemaError as e:\n            raise SchemaError(\n                schema_error=e.message, provider=self.name, data=self.schema\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates data against provider schema. Raises BadArguments if validation fails.", "response": "def _validate_data(self, data: dict):\n        \"\"\"\n        Validates data against provider schema. Raises :class:`~notifiers.exceptions.BadArguments` if relevant\n\n        :param data: Data to validate\n        :raises: :class:`~notifiers.exceptions.BadArguments`\n        \"\"\"\n        log.debug(\"validating provided data\")\n        e = best_match(self.validator.iter_errors(data))\n        if e:\n            custom_error_key = f\"error_{e.validator}\"\n            msg = (\n                e.schema[custom_error_key]\n                if e.schema.get(custom_error_key)\n                else e.message\n            )\n            raise BadArguments(validation_error=msg, provider=self.name, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a notification to the provider.", "response": "def notify(self, raise_on_errors: bool = False, **kwargs) -> Response:\n        \"\"\"\n        The main method to send notifications. Prepares the data via the\n        :meth:`~notifiers.core.SchemaResource._prepare_data` method and then sends the notification\n        via the :meth:`~notifiers.core.Provider._send_notification` method\n\n        :param kwargs: Notification data\n        :param raise_on_errors: Should the :meth:`~notifiers.core.Response.raise_on_errors` be invoked immediately\n        :return: A :class:`~notifiers.core.Response` object\n        :raises: :class:`~notifiers.exceptions.NotificationError` if ``raise_on_errors`` is set to True and response\n         contained errors\n        \"\"\"\n        data = self._process_data(**kwargs)\n        rsp = self._send_notification(data)\n        if raise_on_errors:\n            rsp.raise_on_errors()\n        return rsp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating RFC 2822 format", "response": "def is_rfc2822(instance: str):\n    \"\"\"Validates RFC2822 format\"\"\"\n    if not isinstance(instance, str):\n        return True\n    return email.utils.parsedate(instance) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_port(instance: int):\n    if not isinstance(instance, (int, str)):\n        return True\n    return int(instance) in range(65535)", "response": "Validates data is a valid port"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating data is a timestamp", "response": "def is_timestamp(instance):\n    \"\"\"Validates data is a timestamp\"\"\"\n    if not isinstance(instance, (int, str)):\n        return True\n    return datetime.fromtimestamp(int(instance))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _notify(p, **data):\n    message = data.get(\"message\")\n    if not message and not sys.stdin.isatty():\n        message = click.get_text_stream(\"stdin\").read()\n    data[\"message\"] = message\n\n    data = clean_data(data)\n\n    ctx = click.get_current_context()\n    if ctx.obj.get(\"env_prefix\"):\n        data[\"env_prefix\"] = ctx.obj[\"env_prefix\"]\n\n    rsp = p.notify(**data)\n    rsp.raise_on_errors()\n    click.secho(f\"Succesfully sent a notification to {p.name}!\", fg=\"green\")", "response": "The callback func that will be hooked to the notify command"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resource(resource, pretty: bool = None, **data):\n    data = clean_data(data)\n\n    ctx = click.get_current_context()\n    if ctx.obj.get(\"env_prefix\"):\n        data[\"env_prefix\"] = ctx.obj[\"env_prefix\"]\n\n    rsp = resource(**data)\n    dump = partial(json.dumps, indent=4) if pretty else partial(json.dumps)\n    click.echo(dump(rsp))", "response": "The callback func that will be hooked to the generic resource commands"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _resources(p):\n    if p.resources:\n        click.echo(\",\".join(p.resources))\n    else:\n        click.echo(f\"Provider '{p.name}' does not have resource helpers\")", "response": "Callback func to display provider resources"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef one_or_more(\n    schema: dict, unique_items: bool = True, min: int = 1, max: int = None\n) -> dict:\n    \"\"\"\n    Helper function to construct a schema that validates items matching\n    `schema` or an array containing items matching `schema`.\n\n    :param schema: The schema to use\n    :param unique_items: Flag if array items should be unique\n    :param min: Correlates to ``minLength`` attribute of JSON Schema array\n    :param max: Correlates to ``maxLength`` attribute of JSON Schema array\n    \"\"\"\n    multi_schema = {\n        \"type\": \"array\",\n        \"items\": schema,\n        \"minItems\": min,\n        \"uniqueItems\": unique_items,\n    }\n    if max:\n        multi_schema[\"maxItems\"] = max\n    return {\"oneOf\": [multi_schema, schema]}", "response": "Helper function to construct a schema that validates items matching schema or an array containing items matching schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text_to_bool(value: str) -> bool:\n    try:\n        return bool(strtobool(value))\n    except (ValueError, AttributeError):\n        return value is not None", "response": "Tries to convert a text value to a bool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_dicts(target_dict: dict, merge_dict: dict) -> dict:\n    log.debug(\"merging dict %s into %s\", merge_dict, target_dict)\n    for key, value in merge_dict.items():\n        if key not in target_dict:\n            target_dict[key] = value\n    return target_dict", "response": "Merges the target dict into the former dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of environment variables correlating to the arguments list main name and prefix like so.", "response": "def dict_from_environs(prefix: str, name: str, args: list) -> dict:\n    \"\"\"\n    Return a dict of environment variables correlating to the arguments list, main name and prefix like so:\n    [prefix]_[name]_[arg]\n\n    :param prefix: The environ prefix to use\n    :param name: Main part\n    :param args: List of args to iterate over\n    :return: A dict of found environ values\n    \"\"\"\n    environs = {}\n    log.debug(\"starting to collect environs using prefix: '%s'\", prefix)\n    for arg in args:\n        environ = f\"{prefix}{name}_{arg}\".upper()\n        if os.environ.get(environ):\n            environs[arg] = os.environ[environ]\n    return environs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a snake case param to CamelCase", "response": "def snake_to_camel_case(value: str) -> str:\n    \"\"\"\n    Convert a snake case param to CamelCase\n\n    :param value: The value to convert\n    :return: A CamelCase value\n    \"\"\"\n    log.debug(\"trying to convert %s to camel case\", value)\n    return \"\".join(word.capitalize() for word in value.split(\"_\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef valid_file(path: str) -> bool:\n    path = Path(path).expanduser()\n    log.debug(\"checking if %s is a valid file\", path)\n    return path.exists() and path.is_file()", "response": "Verifies that a string path actually exists and is a file in the\n    directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_providers(self, provider, kwargs):\n        self.provider = notifiers.get_notifier(provider, strict=True)\n        if kwargs.get(\"fallback\"):\n            self.fallback = notifiers.get_notifier(kwargs.pop(\"fallback\"), strict=True)\n            self.fallback_defaults = kwargs.pop(\"fallback_defaults\", {})", "response": "Initializes main and fallback providers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride the base class method that does the actual logging. Handler. emit method that takes the msg attribute from the log record and sends it to the provider.", "response": "def emit(self, record):\n        \"\"\"\n        Override the :meth:`~logging.Handler.emit` method that takes the ``msg`` attribute from the log record passed\n\n        :param record: :class:`logging.LogRecord`\n        \"\"\"\n        data = copy.deepcopy(self.defaults)\n        data[\"message\"] = self.format(record)\n        try:\n            self.provider.notify(raise_on_errors=True, **data)\n        except Exception:\n            self.handleError(record)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles any errors raised during the emit method.", "response": "def handleError(self, record):\n        \"\"\"\n        Handles any errors raised during the :meth:`emit` method. Will only try to pass exceptions to fallback notifier\n        (if defined) in case the exception is a sub-class of :exc:`~notifiers.exceptions.NotifierException`\n\n        :param record: :class:`logging.LogRecord`\n        \"\"\"\n        if logging.raiseExceptions:\n            t, v, tb = sys.exc_info()\n            if issubclass(t, NotifierException) and self.fallback:\n                msg = f\"Could not log msg to provider '{self.provider.name}'!\\n{v}\"\n                self.fallback_defaults[\"message\"] = msg\n                self.fallback.notify(**self.fallback_defaults)\n            else:\n                super().handleError(record)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(url: str, *args, **kwargs) -> tuple:\n    return RequestsHelper.request(url, \"get\", *args, **kwargs)", "response": "Send a GET request. Returns a dict or requests. Response <Response >"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a POST request. Returns a dict or requests. Response <Response >", "response": "def post(url: str, *args, **kwargs) -> tuple:\n    \"\"\"Send a POST request. Returns a dict or :class:`requests.Response <Response>`\"\"\"\n    return RequestsHelper.request(url, \"post\", *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of files ready to be uploaded to a request.", "response": "def file_list_for_request(\n    list_of_paths: list, key_name: str, mimetype: str = None\n) -> list:\n    \"\"\"\n    Convenience function to construct a list of files for multiple files upload by :mod:`requests`\n\n    :param list_of_paths: Lists of strings to include in files. Should be pre validated for correctness\n    :param key_name: The key name to use for the file list in the request\n    :param mimetype: If specified, will be included in the requests\n    :return: List of open files ready to be used in a request\n    \"\"\"\n    if mimetype:\n        return [\n            (key_name, (file, open(file, mode=\"rb\"), mimetype))\n            for file in list_of_paths\n        ]\n    return [(key_name, (file, open(file, mode=\"rb\"))) for file in list_of_paths]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef provider_group_factory():\n    for provider in all_providers():\n        p = get_notifier(provider)\n        provider_name = p.name\n        help = f\"Options for '{provider_name}'\"\n        group = click.Group(name=provider_name, help=help)\n\n        # Notify command\n        notify = partial(_notify, p=p)\n        group.add_command(schema_to_command(p, \"notify\", notify, add_message=True))\n\n        # Resources command\n        resources_callback = partial(_resources, p=p)\n        resources_cmd = click.Command(\n            \"resources\",\n            callback=resources_callback,\n            help=\"Show provider resources list\",\n        )\n        group.add_command(resources_cmd)\n\n        pretty_opt = click.Option(\n            [\"--pretty/--not-pretty\"], help=\"Output a pretty version of the JSON\"\n        )\n\n        # Add any provider resources\n        for resource in p.resources:\n            rsc = getattr(p, resource)\n            rsrc_callback = partial(_resource, rsc)\n            rsrc_command = schema_to_command(\n                rsc, resource, rsrc_callback, add_message=False\n            )\n            rsrc_command.params.append(pretty_opt)\n            group.add_command(rsrc_command)\n\n        for name, description in CORE_COMMANDS.items():\n            callback = func_factory(p, name)\n            params = [pretty_opt]\n            command = click.Command(\n                name,\n                callback=callback,\n                help=description.format(provider_name),\n                params=params,\n            )\n            group.add_command(command)\n\n        notifiers_cli.add_command(group)", "response": "Dynamically generates the provider groups for all providers and adds all basic commands to it"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(\n            self, method, endpoint=None, headers=None, use_auth=True,\n            _url=None, _kwargs=None, **kwargs):\n        \"\"\"\n        Make a request to the Canvas API and return the response.\n\n        :param method: The HTTP method for the request.\n        :type method: str\n        :param endpoint: The endpoint to call.\n        :type endpoint: str\n        :param headers: Optional HTTP headers to be sent with the request.\n        :type headers: dict\n        :param use_auth: Optional flag to remove the authentication\n            header from the request.\n        :type use_auth: bool\n        :param _url: Optional argument to send a request to a URL\n            outside of the Canvas API. If this is selected and an\n            endpoint is provided, the endpoint will be ignored and\n            only the _url argument will be used.\n        :type _url: str\n        :param _kwargs: A list of 2-tuples representing processed\n            keyword arguments to be sent to Canvas as params or data.\n        :type _kwargs: `list`\n        :rtype: str\n        \"\"\"\n        full_url = _url if _url else \"{}{}\".format(self.base_url, endpoint)\n\n        if not headers:\n            headers = {}\n\n        if use_auth:\n            auth_header = {'Authorization': 'Bearer {}'.format(self.access_token)}\n            headers.update(auth_header)\n\n        # Convert kwargs into list of 2-tuples and combine with _kwargs.\n        _kwargs = _kwargs or []\n        _kwargs.extend(kwargs.items())\n\n        # Do any final argument processing before sending to request method.\n        for i, kwarg in enumerate(_kwargs):\n            kw, arg = kwarg\n\n            # Convert boolean objects to a lowercase string.\n            if isinstance(arg, bool):\n                _kwargs[i] = (kw, str(arg).lower())\n\n            # Convert any datetime objects into ISO 8601 formatted strings.\n            elif isinstance(arg, datetime):\n                _kwargs[i] = (kw, arg.isoformat())\n\n        # Determine the appropriate request method.\n        if method == 'GET':\n            req_method = self._get_request\n        elif method == 'POST':\n            req_method = self._post_request\n        elif method == 'DELETE':\n            req_method = self._delete_request\n        elif method == 'PUT':\n            req_method = self._put_request\n\n        # Call the request method\n        response = req_method(full_url, headers, _kwargs)\n\n        # Add response to internal cache\n        if len(self._cache) > 4:\n            self._cache.pop()\n\n        self._cache.insert(0, response)\n\n        # Raise for status codes\n        if response.status_code == 400:\n            raise BadRequest(response.text)\n        elif response.status_code == 401:\n            if 'WWW-Authenticate' in response.headers:\n                raise InvalidAccessToken(response.json())\n            else:\n                raise Unauthorized(response.json())\n        elif response.status_code == 403:\n            raise Forbidden(response.text)\n        elif response.status_code == 404:\n            raise ResourceDoesNotExist('Not Found')\n        elif response.status_code == 409:\n            raise Conflict(response.text)\n        elif response.status_code == 500:\n            raise CanvasException(\"API encountered an error processing your request\")\n\n        return response", "response": "Makes a request to the Canvas API and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nissue a GET request to the specified endpoint with the data provided.", "response": "def _get_request(self, url, headers, params=None):\n        \"\"\"\n        Issue a GET request to the specified endpoint with the data provided.\n\n        :param url: str\n        :pararm headers: dict\n        :param params: dict\n        \"\"\"\n        return self._session.get(url, headers=headers, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _post_request(self, url, headers, data=None):\n\n        # Grab file from data.\n        files = None\n        for field, value in data:\n            if field == 'file':\n                if isinstance(value, dict):\n                    files = value\n                else:\n                    files = {'file': value}\n                break\n\n        # Remove file entry from data.\n        data[:] = [tup for tup in data if tup[0] != 'file']\n\n        return self._session.post(url, headers=headers, data=data, files=files)", "response": "Issue a POST request to the specified endpoint with the data provided."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _delete_request(self, url, headers, data=None):\n        return self._session.delete(url, headers=headers, data=data)", "response": "Issue a DELETE request to the specified endpoint with the data provided."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nissue a PUT request to the specified endpoint with the data provided.", "response": "def _put_request(self, url, headers, data=None):\n        \"\"\"\n        Issue a PUT request to the specified endpoint with the data provided.\n\n        :param url: str\n        :pararm headers: dict\n        :param data: dict\n        \"\"\"\n        return self._session.put(url, headers=headers, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the upload process.", "response": "def start(self):\n        \"\"\"\n        Kick off uploading process. Handles open/closing file if a path\n        is passed.\n\n        :calls: request_upload_token\n        :returns: True if the file uploaded successfully, False \\\n            otherwise, and the JSON response from the API.\n        :rtype: tuple\n        \"\"\"\n        if self._using_filename:\n            with open(self.file, 'rb') as file:\n                return self.request_upload_token(file)\n        else:\n            return self.request_upload_token(self.file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest an upload token.", "response": "def request_upload_token(self, file):\n        \"\"\"\n        Request an upload token.\n\n        :param file: A file handler pointing to the file to upload.\n        :returns: True if the file uploaded successfully, False otherwise, \\\n            and the JSON response from the API.\n        :rtype: tuple\n        \"\"\"\n        self.kwargs['name'] = os.path.basename(file.name)\n        self.kwargs['size'] = os.fstat(file.fileno()).st_size\n\n        response = self._requester.request(\n            'POST',\n            self.url,\n            _kwargs=combine_kwargs(**self.kwargs)\n        )\n\n        return self.upload(response, file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload the file to the specified key.", "response": "def upload(self, response, file):\n        \"\"\"\n        Upload the file.\n\n        :param response: The response from the upload request.\n        :type response: dict\n        :param file: A file handler pointing to the file to upload.\n        :returns: True if the file uploaded successfully, False otherwise, \\\n            and the JSON response from the API.\n        :rtype: tuple\n        \"\"\"\n        response = response.json()\n        if not response.get('upload_url'):\n            raise ValueError('Bad API response. No upload_url.')\n\n        if not response.get('upload_params'):\n            raise ValueError('Bad API response. No upload_params.')\n\n        kwargs = response.get('upload_params')\n\n        response = self._requester.request(\n            'POST',\n            use_auth=False,\n            _url=response.get('upload_url'),\n            file=file,\n            _kwargs=combine_kwargs(**kwargs)\n        )\n\n        # remove `while(1);` that may appear at the top of a response\n        response_json = json.loads(response.text.lstrip('while(1);'))\n\n        return ('url' in response_json, response_json)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads this object with attributes.", "response": "def set_attributes(self, attributes):\n        \"\"\"\n        Load this object with attributes.\n\n        This method attempts to detect special types based on the field's content\n        and will create an additional attribute of that type.\n\n        Consider a JSON response with the following fields::\n\n            {\n                \"name\": \"New course name\",\n                \"course_code\": \"COURSE-001\",\n                \"start_at\": \"2012-05-05T00:00:00Z\",\n                \"end_at\": \"2012-08-05T23:59:59Z\",\n                \"sis_course_id\": \"12345\"\n            }\n\n        The `start_at` and `end_at` fields match a date in ISO8601 format,\n        so two additional datetime attributes are created, `start_at_date`\n        and `end_at_date`.\n\n        :param attributes: The JSON object to build this object with.\n        :type attributes: dict\n        \"\"\"\n        self.attributes = attributes\n\n        for attribute, value in attributes.items():\n            self.__setattr__(attribute, value)\n\n            # datetime field\n            if DATE_PATTERN.match(text_type(value)):\n                naive = datetime.strptime(value, '%Y-%m-%dT%H:%M:%SZ')\n                aware = naive.replace(tzinfo=pytz.utc)\n                self.__setattr__(attribute + '_date', aware)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_account(self, **kwargs):\n        response = self.__requester.request(\n            'POST',\n            'accounts',\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Account(self.__requester, response.json())", "response": "Create a new root account."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns information on an individual account.", "response": "def get_account(self, account, use_sis_id=False, **kwargs):\n        \"\"\"\n        Retrieve information on an individual account.\n\n        :calls: `GET /api/v1/accounts/:id \\\n        <https://canvas.instructure.com/doc/api/accounts.html#method.accounts.show>`_\n\n        :param account: The object or ID of the account to retrieve.\n        :type account: int, str or :class:`canvasapi.account.Account`\n        :param use_sis_id: Whether or not account_id is an sis ID.\n            Defaults to `False`.\n        :type use_sis_id: bool\n\n        :rtype: :class:`canvasapi.account.Account`\n        \"\"\"\n        if use_sis_id:\n            account_id = account\n            uri_str = 'accounts/sis_account_id:{}'\n        else:\n            account_id = obj_or_id(account, \"account\", (Account,))\n            uri_str = 'accounts/{}'\n\n        response = self.__requester.request(\n            'GET',\n            uri_str.format(account_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Account(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of accounts that the current user can view or manage.", "response": "def get_accounts(self, **kwargs):\n        \"\"\"\n        List accounts that the current user can view or manage.\n\n        Typically, students and teachers will get an empty list in\n        response. Only account admins can view the accounts that they\n        are in.\n\n        :calls: `GET /api/v1/accounts \\\n        <https://canvas.instructure.com/doc/api/accounts.html#method.accounts.index>`_\n\n        :rtype: :class:`canvasapi.paginated_list.PaginatedList` of\n            :class:`canvasapi.account.Account`\n        \"\"\"\n        return PaginatedList(\n            Account,\n            self.__requester,\n            'GET',\n            'accounts',\n            _kwargs=combine_kwargs(**kwargs)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_course(self, course, use_sis_id=False, **kwargs):\n        if use_sis_id:\n            course_id = course\n            uri_str = 'courses/sis_course_id:{}'\n        else:\n            course_id = obj_or_id(course, \"course\", (Course,))\n            uri_str = 'courses/{}'\n\n        response = self.__requester.request(\n            'GET',\n            uri_str.format(course_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Course(self.__requester, response.json())", "response": "Returns a Course object for the specified object or ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a user by their ID.", "response": "def get_user(self, user, id_type=None):\n        \"\"\"\n        Retrieve a user by their ID. `id_type` denotes which endpoint to try as there are\n        several different IDs that can pull the same user record from Canvas.\n\n        Refer to API documentation's\n        `User <https://canvas.instructure.com/doc/api/users.html#User>`_\n        example to see the ID types a user can be retrieved with.\n\n        :calls: `GET /api/v1/users/:id \\\n        <https://canvas.instructure.com/doc/api/users.html#method.users.api_show>`_\n\n        :param user: The user's object or ID.\n        :type user: :class:`canvasapi.user.User` or int\n        :param id_type: The ID type.\n        :type id_type: str\n\n        :rtype: :class:`canvasapi.user.User`\n        \"\"\"\n        if id_type:\n            uri = 'users/{}:{}'.format(id_type, user)\n        elif user == 'self':\n            uri = 'users/self'\n        else:\n            user_id = obj_or_id(user, \"user\", (User,))\n            uri = 'users/{}'.format(user_id)\n\n        response = self.__requester.request(\n            'GET',\n            uri\n        )\n        return User(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of active courses for the current user.", "response": "def get_courses(self, **kwargs):\n        \"\"\"\n        Return a list of active courses for the current user.\n\n        :calls: `GET /api/v1/courses \\\n        <https://canvas.instructure.com/doc/api/courses.html#method.courses.index>`_\n\n        :rtype: :class:`canvasapi.paginated_list.PaginatedList` of\n            :class:`canvasapi.course.Course`\n        \"\"\"\n        return PaginatedList(\n            Course,\n            self.__requester,\n            'GET',\n            'courses',\n            _kwargs=combine_kwargs(**kwargs)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_section(self, section, use_sis_id=False, **kwargs):\n        if use_sis_id:\n            section_id = section\n            uri_str = 'sections/sis_section_id:{}'\n        else:\n            section_id = obj_or_id(section, \"section\", (Section,))\n            uri_str = 'sections/{}'\n\n        response = self.__requester.request(\n            'GET',\n            uri_str.format(section_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Section(self.__requester, response.json())", "response": "Get details about a specific section."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_course_nickname(self, course, nickname):\n        from canvasapi.course import CourseNickname\n\n        course_id = obj_or_id(course, \"course\", (Course,))\n\n        response = self.__requester.request(\n            'PUT',\n            'users/self/course_nicknames/{}'.format(course_id),\n            nickname=nickname\n        )\n        return CourseNickname(self.__requester, response.json())", "response": "Set a nickname for the given course."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_accounts(self, **kwargs):\n        response = self.__requester.request(\n            'GET',\n            'accounts/search',\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return response.json()", "response": "Returns a list of up to 5 matching account domains. Partial matches are supported."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_group(self, **kwargs):\n        response = self.__requester.request(\n            'POST',\n            'groups',\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Group(self.__requester, response.json())", "response": "Creates a group with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_group(self, group, use_sis_id=False, **kwargs):\n\n        if use_sis_id:\n            group_id = group\n            uri_str = 'groups/sis_group_id:{}'\n        else:\n            group_id = obj_or_id(group, \"group\", (Group,))\n            uri_str = 'groups/{}'\n\n        response = self.__requester.request(\n            'GET',\n            uri_str.format(group_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Group(self.__requester, response.json())", "response": "Returns the data for a single group."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a single group category.", "response": "def get_group_category(self, category):\n        \"\"\"\n        Get a single group category.\n\n        :calls: `GET /api/v1/group_categories/:group_category_id \\\n        <https://canvas.instructure.com/doc/api/group_categories.html#method.group_categories.show>`_\n\n        :param category: The object or ID of the category.\n        :type category: :class:`canvasapi.group.GroupCategory` or int\n\n        :rtype: :class:`canvasapi.group.GroupCategory`\n        \"\"\"\n        category_id = obj_or_id(category, \"category\", (GroupCategory,))\n\n        response = self.__requester.request(\n            'GET',\n            'group_categories/{}'.format(category_id)\n        )\n        return GroupCategory(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_conversation(self, recipients, body, **kwargs):\n        from canvasapi.conversation import Conversation\n\n        kwargs['recipients'] = recipients\n        kwargs['body'] = body\n\n        response = self.__requester.request(\n            'POST',\n            'conversations',\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return [Conversation(self.__requester, convo) for convo in response.json()]", "response": "Creates a new conversation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_conversation(self, conversation, **kwargs):\n        from canvasapi.conversation import Conversation\n\n        conversation_id = obj_or_id(conversation, \"conversation\", (Conversation,))\n\n        response = self.__requester.request(\n            'GET',\n            'conversations/{}'.format(conversation_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Conversation(self.__requester, response.json())", "response": "Returns a single Conversation object with the specified ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_conversations(self, **kwargs):\n        from canvasapi.conversation import Conversation\n\n        return PaginatedList(\n            Conversation,\n            self.__requester,\n            'GET',\n            'conversations',\n            _kwargs=combine_kwargs(**kwargs)\n        )", "response": "Returns a list of conversations for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new Calendar Event.", "response": "def create_calendar_event(self, calendar_event, **kwargs):\n        \"\"\"\n        Create a new Calendar Event.\n\n        :calls: `POST /api/v1/calendar_events \\\n        <https://canvas.instructure.com/doc/api/calendar_events.html#method.calendar_events_api.create>`_\n\n        :param calendar_event: The attributes of the calendar event.\n        :type calendar_event: `dict`\n        :rtype: :class:`canvasapi.calendar_event.CalendarEvent`\n        \"\"\"\n        from canvasapi.calendar_event import CalendarEvent\n\n        if isinstance(calendar_event, dict) and 'context_code' in calendar_event:\n            kwargs['calendar_event'] = calendar_event\n        else:\n            raise RequiredFieldMissing(\n                \"Dictionary with key 'context_codes' is required.\"\n            )\n\n        response = self.__requester.request(\n            'POST',\n            'calendar_events',\n            _kwargs=combine_kwargs(**kwargs)\n        )\n\n        return CalendarEvent(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_calendar_events(self, **kwargs):\n        from canvasapi.calendar_event import CalendarEvent\n\n        return PaginatedList(\n            CalendarEvent,\n            self.__requester,\n            'GET',\n            'calendar_events',\n            _kwargs=combine_kwargs(**kwargs)\n        )", "response": "Returns a list of calendar events for the specified locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a single Calendar Event by id", "response": "def get_calendar_event(self, calendar_event):\n        \"\"\"\n        Return single Calendar Event by id\n\n        :calls: `GET /api/v1/calendar_events/:id \\\n        <https://canvas.instructure.com/doc/api/calendar_events.html#method.calendar_events_api.show>`_\n\n        :param calendar_event: The object or ID of the calendar event.\n        :type calendar_event: :class:`canvasapi.calendar_event.CalendarEvent` or int\n\n        :rtype: :class:`canvasapi.calendar_event.CalendarEvent`\n        \"\"\"\n        from canvasapi.calendar_event import CalendarEvent\n\n        calendar_event_id = obj_or_id(calendar_event, \"calendar_event\", (CalendarEvent,))\n\n        response = self.__requester.request(\n            'GET',\n            'calendar_events/{}'.format(calendar_event_id)\n        )\n        return CalendarEvent(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reserve_time_slot(self, calendar_event, participant_id=None, **kwargs):\n        from canvasapi.calendar_event import CalendarEvent\n\n        calendar_event_id = obj_or_id(calendar_event, \"calendar_event\", (CalendarEvent,))\n\n        if participant_id:\n            uri = 'calendar_events/{}/reservations/{}'.format(\n                calendar_event_id, participant_id\n            )\n        else:\n            uri = 'calendar_events/{}/reservations'.format(calendar_event_id)\n\n        response = self.__requester.request(\n            'POST',\n            uri,\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return CalendarEvent(self.__requester, response.json())", "response": "Reserve a single Calendar Event in the specified time slot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_appointment_groups(self, **kwargs):\n        from canvasapi.appointment_group import AppointmentGroup\n\n        return PaginatedList(\n            AppointmentGroup,\n            self.__requester,\n            'GET',\n            'appointment_groups',\n            _kwargs=combine_kwargs(**kwargs)\n        )", "response": "Returns a list of all appointment groups in the specified locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_appointment_group(self, appointment_group):\n        from canvasapi.appointment_group import AppointmentGroup\n\n        appointment_group_id = obj_or_id(\n            appointment_group, \"appointment_group\", (AppointmentGroup,)\n        )\n\n        response = self.__requester.request(\n            'GET',\n            'appointment_groups/{}'.format(appointment_group_id)\n        )\n        return AppointmentGroup(self.__requester, response.json())", "response": "Returns a single Appointment Group by ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_appointment_group(self, appointment_group, **kwargs):\n        from canvasapi.appointment_group import AppointmentGroup\n\n        if (\n                isinstance(appointment_group, dict) and\n                'context_codes' in appointment_group and\n                'title' in appointment_group\n        ):\n            kwargs['appointment_group'] = appointment_group\n\n        elif (\n            isinstance(appointment_group, dict) and\n            'context_codes' not in appointment_group\n        ):\n            raise RequiredFieldMissing(\n                \"Dictionary with key 'context_codes' is missing.\"\n            )\n\n        elif isinstance(appointment_group, dict) and 'title' not in appointment_group:\n            raise RequiredFieldMissing(\"Dictionary with key 'title' is missing.\")\n\n        response = self.__requester.request(\n            'POST',\n            'appointment_groups',\n            _kwargs=combine_kwargs(**kwargs)\n        )\n\n        return AppointmentGroup(self.__requester, response.json())", "response": "Creates a new Appointment Group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_user_participants(self, appointment_group, **kwargs):\n        warnings.warn(\n            \"`list_user_participants` is being deprecated and will be removed in a future version.\"\n            \" Use `get_user_participants` instead\",\n            DeprecationWarning\n        )\n\n        return self.get_user_participants(appointment_group, **kwargs)", "response": "This method returns a paginated list of user participants in this appointment group."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the user participants in this appointment group.", "response": "def get_user_participants(self, appointment_group, **kwargs):\n        \"\"\"\n        List user participants in this appointment group.\n\n        :calls: `GET /api/v1/appointment_groups/:id/users \\\n        <https://canvas.instructure.com/doc/api/appointment_groups.html#method.appointment_groups.users>`_\n\n        :param appointment_group: The object or ID of the appointment group.\n        :type appointment_group: :class:`canvasapi.appointment_group.AppointmentGroup` or int\n\n        :rtype: :class:`canvasapi.paginated_list.PaginatedList` of :class:`canvasapi.user.User`\n        \"\"\"\n        from canvasapi.appointment_group import AppointmentGroup\n        from canvasapi.user import User\n\n        appointment_group_id = obj_or_id(\n            appointment_group, \"appointment_group\", (AppointmentGroup,)\n        )\n\n        return PaginatedList(\n            User,\n            self.__requester,\n            'GET',\n            'appointment_groups/{}/users'.format(appointment_group_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_group_participants(self, appointment_group, **kwargs):\n        warnings.warn(\n            \"`list_group_participants` is being deprecated and will be removed \"\n            \"in a future version. Use `get_group_participants` instead\",\n            DeprecationWarning\n        )\n\n        return self.get_group_participants(appointment_group, **kwargs)", "response": "This method returns a paginated list of participants in this appointment group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_group_participants(self, appointment_group, **kwargs):\n        from canvasapi.appointment_group import AppointmentGroup\n        from canvasapi.group import Group\n\n        appointment_group_id = obj_or_id(\n            appointment_group, \"appointment_group\", (AppointmentGroup,)\n        )\n\n        return PaginatedList(\n            Group,\n            self.__requester,\n            'GET',\n            'appointment_groups/{}/groups'.format(appointment_group_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )", "response": "Returns a list of all participants in this appointment group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the standard attachment json object for a file.", "response": "def get_file(self, file, **kwargs):\n        \"\"\"\n        Return the standard attachment json object for a file.\n\n        :calls: `GET /api/v1/files/:id \\\n        <https://canvas.instructure.com/doc/api/files.html#method.files.api_show>`_\n\n        :param file: The object or ID of the file to retrieve.\n        :type file: :class:`canvasapi.file.File` or int\n\n        :rtype: :class:`canvasapi.file.File`\n        \"\"\"\n        file_id = obj_or_id(file, \"file\", (File,))\n\n        response = self.__requester.request(\n            'GET',\n            'files/{}'.format(file_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return File(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the details for a folder.", "response": "def get_folder(self, folder):\n        \"\"\"\n        Return the details for a folder\n\n        :calls: `GET /api/v1/folders/:id \\\n        <https://canvas.instructure.com/doc/api/files.html#method.folders.show>`_\n\n        :param folder: The object or ID of the folder to retrieve.\n        :type folder: :class:`canvasapi.folder.Folder` or int\n\n        :rtype: :class:`canvasapi.folder.Folder`\n        \"\"\"\n        folder_id = obj_or_id(folder, \"folder\", (Folder,))\n\n        response = self.__requester.request(\n            'GET',\n            'folders/{}'.format(folder_id)\n        )\n        return Folder(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_outcome(self, outcome):\n        from canvasapi.outcome import Outcome\n\n        outcome_id = obj_or_id(outcome, \"outcome\", (Outcome,))\n        response = self.__requester.request(\n            'GET',\n            'outcomes/{}'.format(outcome_id)\n        )\n        return Outcome(self.__requester, response.json())", "response": "Returns the details of the outcome with the given id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the root outcome group for the current context.", "response": "def get_root_outcome_group(self):\n        \"\"\"\n        Redirect to root outcome group for context\n\n        :calls: `GET /api/v1/global/root_outcome_group \\\n        <https://canvas.instructure.com/doc/api/outcome_groups.html#method.outcome_groups_api.redirect>`_\n\n        :returns: The OutcomeGroup of the context.\n        :rtype: :class:`canvasapi.outcome.OutcomeGroup`\n        \"\"\"\n        from canvasapi.outcome import OutcomeGroup\n\n        response = self.__requester.request(\n            'GET',\n            'global/root_outcome_group'\n        )\n        return OutcomeGroup(self.__requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_outcome_group(self, group):\n        from canvasapi.outcome import OutcomeGroup\n\n        outcome_group_id = obj_or_id(group, \"group\", (OutcomeGroup,))\n\n        response = self.__requester.request(\n            'GET',\n            'global/outcome_groups/{}'.format(outcome_group_id)\n        )\n\n        return OutcomeGroup(self.__requester, response.json())", "response": "Returns the details of the given outcome group."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_progress(self, progress, **kwargs):\n\n        from canvasapi.progress import Progress\n\n        progress_id = obj_or_id(progress, \"progress\", (Progress,))\n\n        response = self.__requester.request(\n            'GET',\n            'progress/{}'.format(progress_id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return Progress(self.__requester, response.json())", "response": "Returns a specific progress."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all discussion topics in the specified locale.", "response": "def get_announcements(self, **kwargs):\n        \"\"\"\n        List announcements.\n\n        :calls: `GET /api/v1/announcements \\\n        <https://canvas.instructure.com/doc/api/announcements.html#method.announcements_api.index>`_\n\n        :rtype: :class:`canvasapi.paginated_list.PaginatedList` of\n                :class:`canvasapi.discussion_topic.DiscussionTopic`\n        \"\"\"\n        from canvasapi.discussion_topic import DiscussionTopic\n        return PaginatedList(\n            DiscussionTopic,\n            self.__requester,\n            'GET',\n            'announcements',\n            _kwargs=combine_kwargs(**kwargs)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if the given value is a multivalued sequence of tokens or tokens.", "response": "def is_multivalued(value):\n    \"\"\"\n    Determine whether the given value should be treated as a sequence\n    of multiple values when used as a request parameter.\n\n    In general anything that is iterable is multivalued.  For example,\n    `list` and `tuple` instances are multivalued.  Generators are\n    multivalued, as are the iterable objects returned by `zip`,\n    `itertools.chain`, etc.  However, a simple `int` is single-valued.\n    `str` and `bytes` are special cases: although these are iterable,\n    we treat each as a single value rather than as a sequence of\n    isolated characters or bytes.\n    \"\"\"\n\n    # special cases: iterable, but not multivalued\n    if isinstance(value, (string_types, binary_type)):\n        return False\n\n    # general rule: multivalued if iterable\n    return isinstance(value, Iterable)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nflatten a series of keyword arguments from complex combinations of dictionaries and lists into a list of tuples representing the keys and values of the second object.", "response": "def combine_kwargs(**kwargs):\n    \"\"\"\n    Flatten a series of keyword arguments from complex combinations of\n    dictionaries and lists into a list of tuples representing\n    properly-formatted parameters to pass to the Requester object.\n\n    :param kwargs: A dictionary containing keyword arguments to be\n        flattened into properly-formatted parameters.\n    :type kwargs: dict\n\n    :returns: A list of tuples that represent flattened kwargs. The\n        first element is a string representing the key. The second\n        element is the value.\n    :rtype: `list` of `tuple`\n    \"\"\"\n    combined_kwargs = []\n\n    # Loop through all kwargs provided\n    for kw, arg in kwargs.items():\n        if isinstance(arg, dict):\n            for k, v in arg.items():\n                for tup in flatten_kwarg(k, v):\n                    combined_kwargs.append(('{}{}'.format(kw, tup[0]), tup[1]))\n        elif is_multivalued(arg):\n            for i in arg:\n                for tup in flatten_kwarg('', i):\n                    combined_kwargs.append(('{}{}'.format(kw, tup[0]), tup[1]))\n        else:\n            combined_kwargs.append((text_type(kw), arg))\n\n    return combined_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns either an int or an int.", "response": "def obj_or_id(parameter, param_name, object_types):\n    \"\"\"\n    Accepts either an int (or long or str representation of an integer)\n    or an object. If it is an int, return it. If it is an object and\n    the object is of correct type, return the object's id. Otherwise,\n    throw an exception.\n\n    :param parameter: int, str, long, or object\n    :param param_name: str\n    :param object_types: tuple\n    :rtype: int\n    \"\"\"\n    from canvasapi.user import User\n\n    try:\n        return int(parameter)\n    except (ValueError, TypeError):\n        # Special case where 'self' is a valid ID of a User object\n        if User in object_types and parameter == 'self':\n            return parameter\n\n        for obj_type in object_types:\n            if isinstance(parameter, obj_type):\n                try:\n                    return int(parameter.id)\n                except Exception:\n                    break\n\n        obj_type_list = \",\".join([obj_type.__name__ for obj_type in object_types])\n        message = 'Parameter {} must be of type {} or int.'.format(param_name, obj_type_list)\n        raise TypeError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_institution_url(base_url):\n    base_url = base_url.rstrip('/')\n    index = base_url.find('/api/v1')\n\n    if index != -1:\n        return base_url[0:index]\n\n    return base_url", "response": "Clean up a given base URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening a file and return the handler if a path is given.", "response": "def file_or_path(file):\n    \"\"\"\n    Open a file and return the handler if a path is given.\n    If a file handler is given, return it directly.\n\n    :param file: A file handler or path to a file.\n\n    :returns: A tuple with the open file handler and whether it was a path.\n    :rtype: (file, bool)\n    \"\"\"\n\n    is_path = False\n    if isinstance(file, string_types):\n        if not os.path.exists(file):\n            raise IOError('File at path ' + file + ' does not exist.')\n        file = open(file, 'rb')\n        is_path = True\n\n    return file, is_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes this calendar event.", "response": "def delete(self, **kwargs):\n        \"\"\"\n        Delete this calendar event.\n\n        :calls: `DELETE /api/v1/calendar_events/:id \\\n        <https://canvas.instructure.com/doc/api/calendar_events.html#method.calendar_events_api.destroy>`_\n\n        :rtype: :class:`canvasapi.calendar_event.CalendarEvent`\n        \"\"\"\n        response = self._requester.request(\n            'DELETE',\n            'calendar_events/{}'.format(self.id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n        return CalendarEvent(self._requester, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit(self, **kwargs):\n        response = self._requester.request(\n            'PUT',\n            'calendar_events/{}'.format(self.id),\n            _kwargs=combine_kwargs(**kwargs)\n        )\n\n        if 'title' in response.json():\n            super(CalendarEvent, self).set_attributes(response.json())\n\n        return CalendarEvent(self._requester, response.json())", "response": "Edit this calendar event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping a keras layer with residual normalization and dropout.", "response": "def _wrap_layer(name, input_layer, build_func, dropout_rate=0.0, trainable=True):\n    \"\"\"Wrap layers with residual, normalization and dropout.\n\n    :param name: Prefix of names for internal layers.\n    :param input_layer: Input layer.\n    :param build_func: A callable that takes the input tensor and generates the output tensor.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    \"\"\"\n    build_output = build_func(input_layer)\n    if dropout_rate > 0.0:\n        dropout_layer = keras.layers.Dropout(\n            rate=dropout_rate,\n            name='%s-Dropout' % name,\n        )(build_output)\n    else:\n        dropout_layer = build_output\n    if isinstance(input_layer, list):\n        input_layer = input_layer[0]\n    add_layer = keras.layers.Add(name='%s-Add' % name)([input_layer, dropout_layer])\n    normal_layer = LayerNormalization(\n        trainable=trainable,\n        name='%s-Norm' % name,\n    )(add_layer)\n    return normal_layer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attention_builder(name, head_num, activation, history_only, trainable=True):\n    def _attention_builder(x):\n        return MultiHeadAttention(\n            head_num=head_num,\n            activation=activation,\n            history_only=history_only,\n            trainable=trainable,\n            name=name,\n        )(x)\n    return _attention_builder", "response": "Get multi - head self - attention builder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef feed_forward_builder(name, hidden_dim, activation, trainable=True):\n    def _feed_forward_builder(x):\n        return FeedForward(\n            units=hidden_dim,\n            activation=activation,\n            trainable=trainable,\n            name=name,\n        )(x)\n    return _feed_forward_builder", "response": "Returns a function that creates a FeedForward layer builder."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn encoder component for the internal layers.", "response": "def get_encoder_component(name,\n                          input_layer,\n                          head_num,\n                          hidden_dim,\n                          attention_activation=None,\n                          feed_forward_activation='relu',\n                          dropout_rate=0.0,\n                          trainable=True):\n    \"\"\"Multi-head self-attention and feed-forward layer.\n\n    :param name: Prefix of names for internal layers.\n    :param input_layer: Input layer.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    \"\"\"\n    attention_name = '%s-MultiHeadSelfAttention' % name\n    feed_forward_name = '%s-FeedForward' % name\n    attention_layer = _wrap_layer(\n        name=attention_name,\n        input_layer=input_layer,\n        build_func=attention_builder(\n            name=attention_name,\n            head_num=head_num,\n            activation=attention_activation,\n            history_only=False,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    feed_forward_layer = _wrap_layer(\n        name=feed_forward_name,\n        input_layer=attention_layer,\n        build_func=feed_forward_builder(\n            name=feed_forward_name,\n            hidden_dim=hidden_dim,\n            activation=feed_forward_activation,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    return feed_forward_layer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_decoder_component(name,\n                          input_layer,\n                          encoded_layer,\n                          head_num,\n                          hidden_dim,\n                          attention_activation=None,\n                          feed_forward_activation='relu',\n                          dropout_rate=0.0,\n                          trainable=True):\n    \"\"\"Multi-head self-attention, multi-head query attention and feed-forward layer.\n\n    :param name: Prefix of names for internal layers.\n    :param input_layer: Input layer.\n    :param encoded_layer: Encoded layer from encoder.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    \"\"\"\n    self_attention_name = '%s-MultiHeadSelfAttention' % name\n    query_attention_name = '%s-MultiHeadQueryAttention' % name\n    feed_forward_name = '%s-FeedForward' % name\n    self_attention_layer = _wrap_layer(\n        name=self_attention_name,\n        input_layer=input_layer,\n        build_func=attention_builder(\n            name=self_attention_name,\n            head_num=head_num,\n            activation=attention_activation,\n            history_only=True,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    query_attention_layer = _wrap_layer(\n        name=query_attention_name,\n        input_layer=[self_attention_layer, encoded_layer, encoded_layer],\n        build_func=attention_builder(\n            name=query_attention_name,\n            head_num=head_num,\n            activation=attention_activation,\n            history_only=False,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    feed_forward_layer = _wrap_layer(\n        name=feed_forward_name,\n        input_layer=query_attention_layer,\n        build_func=feed_forward_builder(\n            name=feed_forward_name,\n            hidden_dim=hidden_dim,\n            activation=feed_forward_activation,\n            trainable=trainable,\n        ),\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    return feed_forward_layer", "response": "Returns a decoder component for the given encoder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_encoders(encoder_num,\n                 input_layer,\n                 head_num,\n                 hidden_dim,\n                 attention_activation=None,\n                 feed_forward_activation='relu',\n                 dropout_rate=0.0,\n                 trainable=True):\n    \"\"\"Get encoders.\n\n    :param encoder_num: Number of encoder components.\n    :param input_layer: Input layer.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    \"\"\"\n    last_layer = input_layer\n    for i in range(encoder_num):\n        last_layer = get_encoder_component(\n            name='Encoder-%d' % (i + 1),\n            input_layer=last_layer,\n            head_num=head_num,\n            hidden_dim=hidden_dim,\n            attention_activation=attention_activation,\n            feed_forward_activation=feed_forward_activation,\n            dropout_rate=dropout_rate,\n            trainable=trainable,\n        )\n    return last_layer", "response": "Get encoders.\n\n    :param encoder_num: Number of encoder components.\n    :param input_layer: Input layer.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_decoders(decoder_num,\n                 input_layer,\n                 encoded_layer,\n                 head_num,\n                 hidden_dim,\n                 attention_activation=None,\n                 feed_forward_activation='relu',\n                 dropout_rate=0.0,\n                 trainable=True):\n    \"\"\"Get decoders.\n\n    :param decoder_num: Number of decoder components.\n    :param input_layer: Input layer.\n    :param encoded_layer: Encoded layer from encoder.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param trainable: Whether the layers are trainable.\n    :return: Output layer.\n    \"\"\"\n    last_layer = input_layer\n    for i in range(decoder_num):\n        last_layer = get_decoder_component(\n            name='Decoder-%d' % (i + 1),\n            input_layer=last_layer,\n            encoded_layer=encoded_layer,\n            head_num=head_num,\n            hidden_dim=hidden_dim,\n            attention_activation=attention_activation,\n            feed_forward_activation=feed_forward_activation,\n            dropout_rate=dropout_rate,\n            trainable=trainable,\n        )\n    return last_layer", "response": "Get decoders from the input layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets full Keras model.", "response": "def get_model(token_num,\n              embed_dim,\n              encoder_num,\n              decoder_num,\n              head_num,\n              hidden_dim,\n              attention_activation=None,\n              feed_forward_activation='relu',\n              dropout_rate=0.0,\n              use_same_embed=True,\n              embed_weights=None,\n              embed_trainable=None,\n              trainable=True):\n    \"\"\"Get full model without compilation.\n\n    :param token_num: Number of distinct tokens.\n    :param embed_dim: Dimension of token embedding.\n    :param encoder_num: Number of encoder components.\n    :param decoder_num: Number of decoder components.\n    :param head_num: Number of heads in multi-head self-attention.\n    :param hidden_dim: Hidden dimension of feed forward layer.\n    :param attention_activation: Activation for multi-head self-attention.\n    :param feed_forward_activation: Activation for feed-forward layer.\n    :param dropout_rate: Dropout rate.\n    :param use_same_embed: Whether to use the same token embedding layer. `token_num`, `embed_weights` and\n                           `embed_trainable` should be lists of two elements if it is False.\n    :param embed_weights: Initial weights of token embedding.\n    :param embed_trainable: Whether the token embedding is trainable. It will automatically set to False if the given\n                            value is None when embedding weights has been provided.\n    :param trainable: Whether the layers are trainable.\n    :return: Keras model.\n    \"\"\"\n    if not isinstance(token_num, list):\n        token_num = [token_num, token_num]\n    encoder_token_num, decoder_token_num = token_num\n\n    if not isinstance(embed_weights, list):\n        embed_weights = [embed_weights, embed_weights]\n    encoder_embed_weights, decoder_embed_weights = embed_weights\n    if encoder_embed_weights is not None:\n        encoder_embed_weights = [encoder_embed_weights]\n    if decoder_embed_weights is not None:\n        decoder_embed_weights = [decoder_embed_weights]\n\n    if not isinstance(embed_trainable, list):\n        embed_trainable = [embed_trainable, embed_trainable]\n    encoder_embed_trainable, decoder_embed_trainable = embed_trainable\n    if encoder_embed_trainable is None:\n        encoder_embed_trainable = encoder_embed_weights is None\n    if decoder_embed_trainable is None:\n        decoder_embed_trainable = decoder_embed_weights is None\n\n    if use_same_embed:\n        encoder_embed_layer = decoder_embed_layer = EmbeddingRet(\n            input_dim=encoder_token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            weights=encoder_embed_weights,\n            trainable=encoder_embed_trainable,\n            name='Token-Embedding',\n        )\n    else:\n        encoder_embed_layer = EmbeddingRet(\n            input_dim=encoder_token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            weights=encoder_embed_weights,\n            trainable=encoder_embed_trainable,\n            name='Encoder-Token-Embedding',\n        )\n        decoder_embed_layer = EmbeddingRet(\n            input_dim=decoder_token_num,\n            output_dim=embed_dim,\n            mask_zero=True,\n            weights=decoder_embed_weights,\n            trainable=decoder_embed_trainable,\n            name='Decoder-Token-Embedding',\n        )\n    encoder_input = keras.layers.Input(shape=(None,), name='Encoder-Input')\n    encoder_embed = TrigPosEmbedding(\n        mode=TrigPosEmbedding.MODE_ADD,\n        name='Encoder-Embedding',\n    )(encoder_embed_layer(encoder_input)[0])\n    encoded_layer = get_encoders(\n        encoder_num=encoder_num,\n        input_layer=encoder_embed,\n        head_num=head_num,\n        hidden_dim=hidden_dim,\n        attention_activation=attention_activation,\n        feed_forward_activation=feed_forward_activation,\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    decoder_input = keras.layers.Input(shape=(None,), name='Decoder-Input')\n    decoder_embed, decoder_embed_weights = decoder_embed_layer(decoder_input)\n    decoder_embed = TrigPosEmbedding(\n        mode=TrigPosEmbedding.MODE_ADD,\n        name='Decoder-Embedding',\n    )(decoder_embed)\n    decoded_layer = get_decoders(\n        decoder_num=decoder_num,\n        input_layer=decoder_embed,\n        encoded_layer=encoded_layer,\n        head_num=head_num,\n        hidden_dim=hidden_dim,\n        attention_activation=attention_activation,\n        feed_forward_activation=feed_forward_activation,\n        dropout_rate=dropout_rate,\n        trainable=trainable,\n    )\n    dense_layer = EmbeddingSim(\n        trainable=trainable,\n        name='Output',\n    )([decoded_layer, decoder_embed_weights])\n    return keras.models.Model(inputs=[encoder_input, decoder_input], outputs=dense_layer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode(model, tokens, start_token, end_token, pad_token, max_len=10000, max_repeat=10, max_repeat_block=10):\n    is_single = not isinstance(tokens[0], list)\n    if is_single:\n        tokens = [tokens]\n    batch_size = len(tokens)\n    decoder_inputs = [[start_token] for _ in range(batch_size)]\n    outputs = [None for _ in range(batch_size)]\n    output_len = 1\n    while len(list(filter(lambda x: x is None, outputs))) > 0:\n        output_len += 1\n        batch_inputs, batch_outputs = [], []\n        max_input_len = 0\n        index_map = {}\n        for i in range(batch_size):\n            if outputs[i] is None:\n                index_map[len(batch_inputs)] = i\n                batch_inputs.append(tokens[i][:])\n                batch_outputs.append(decoder_inputs[i])\n                max_input_len = max(max_input_len, len(tokens[i]))\n        for i in range(len(batch_inputs)):\n            batch_inputs[i] += [pad_token] * (max_input_len - len(batch_inputs[i]))\n        predicts = model.predict([np.asarray(batch_inputs), np.asarray(batch_outputs)])\n        for i in range(len(predicts)):\n            last_token = np.argmax(predicts[i][-1])\n            decoder_inputs[index_map[i]].append(last_token)\n            if last_token == end_token or\\\n                    (max_len is not None and output_len >= max_len) or\\\n                    _get_max_suffix_repeat_times(decoder_inputs, max_repeat * max_repeat_block) >= max_repeat:\n                outputs[index_map[i]] = decoder_inputs[index_map[i]]\n    if is_single:\n        outputs = outputs[0]\n    return outputs", "response": "Decode with the given model and input tokens."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gelu(x):\n    return 0.5 * x * (1.0 + K.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * K.pow(x, 3))))", "response": "An approximation of gelu."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dict2schema(dct):\n    attrs = dct.copy()\n    if MARSHMALLOW_VERSION_INFO[0] < 3:\n\n        class Meta(object):\n            strict = True\n\n        attrs[\"Meta\"] = Meta\n    return type(str(\"\"), (ma.Schema,), attrs)", "response": "Generate a marshmallow. Schema class given a dictionary of\n    Fields <marshmallow. fields. Field >."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_env(path=None, recurse=True, stream=None, verbose=False, override=False):\n        # By default, start search from the same file this function is called\n        if path is None:\n            frame = inspect.currentframe().f_back\n            caller_dir = os.path.dirname(frame.f_code.co_filename)\n            start = os.path.join(os.path.abspath(caller_dir))\n        else:\n            start = path\n        if recurse:\n            for dirname in _walk_to_root(start):\n                check_path = os.path.join(dirname, \".env\")\n                if os.path.exists(check_path):\n                    return load_dotenv(\n                        check_path, stream=stream, verbose=verbose, override=override\n                    )\n        else:\n            if path is None:\n                start = os.path.join(start, \".env\")\n            return load_dotenv(start, stream=stream, verbose=verbose, override=override)", "response": "Read a. env file into os. environ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a new parser method with the name name. func must be a function that takes a value for an environment variable. Returns None if the method is already registered.", "response": "def add_parser(self, name, func):\n        \"\"\"Register a new parser method with the name ``name``. ``func`` must\n        receive the input value for an environment variable.\n        \"\"\"\n        self.__parser_map__[name] = _func2method(func, method_name=name)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a new parser method with name given a marshmallow Field.", "response": "def add_parser_from_field(self, name, field_cls):\n        \"\"\"Register a new parser method with name ``name``, given a marshmallow ``Field``.\"\"\"\n        self.__parser_map__[name] = _field2method(field_cls, method_name=name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps parsed environment variables to a dictionary of simple data types.", "response": "def dump(self):\n        \"\"\"Dump parsed environment variables to a dictionary of simple data types (numbers\n        and strings).\n        \"\"\"\n        schema = _dict2schema(self._fields)()\n        dump_result = schema.dump(self._values)\n        return dump_result.data if MARSHMALLOW_VERSION_INFO[0] < 3 else dump_result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_from_environ(self, key, default):\n        env_key = self._get_key(key)\n        value = os.environ.get(env_key, default)\n        if hasattr(value, \"strip\"):\n            match = _PROXIED_PATTERN.match(value)\n            if match:  # Proxied variable\n                proxied_key = match.groups()[0]\n                return key, self._get_from_environ(proxied_key, default)[1], proxied_key\n        return env_key, value, None", "response": "Access a value from os. environ. Handles proxed variables e. g. SMTP_LOGIN = > SMTP_LOGIN."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next(self, data=None):\r\n        '''\r\n        consume `data` (if given, or calls `stream.read()` if `stream` was given\r\n        in the constructor) and yield a list of `NMEASentence` objects parsed\r\n        from the stream (may be empty)\r\n        '''\r\n        if data is None:\r\n            if self.stream:\r\n                data = self.stream.readline()\r\n            else:\r\n                return\r\n\r\n        lines = (self.buffer + data).split('\\n')\r\n        self.buffer = lines.pop()\r\n\r\n        for line in lines:\r\n            try:\r\n                msg = nmea.NMEASentence.parse(line)\r\n                yield msg\r\n            except nmea.ParseError as e:\r\n                if self.errors == 'raise':\r\n                    raise e\r\n                if self.errors == 'yield':\r\n                    yield e\r\n                if self.errors == 'ignore':\r\n                    pass", "response": "Yields a list of NMEASentence objects parsed from the stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a string representing a NMEA 0183 sentence and returns a new object of the same type as the input string.", "response": "def parse(line, check=False):\r\n        '''\r\n        parse(line)\r\n\r\n        Parses a string representing a NMEA 0183 sentence, and returns a\r\n        NMEASentence object\r\n\r\n        Raises ValueError if the string could not be parsed, or if the checksum\r\n        did not match.\r\n        '''\r\n        match = NMEASentence.sentence_re.match(line)\r\n        if not match:\r\n            raise ParseError('could not parse data', line)\r\n\r\n        # pylint: disable=bad-whitespace\r\n        nmea_str        = match.group('nmea_str')\r\n        data_str        = match.group('data')\r\n        checksum        = match.group('checksum')\r\n        sentence_type   = match.group('sentence_type').upper()\r\n        data            = data_str.split(',')\r\n\r\n        if checksum:\r\n            cs1 = int(checksum, 16)\r\n            cs2 = NMEASentence.checksum(nmea_str)\r\n            if cs1 != cs2:\r\n                raise ChecksumError(\r\n                    'checksum does not match: %02X != %02X' % (cs1, cs2), data)\r\n        elif check:\r\n            raise ChecksumError(\r\n                'strict checking requested but checksum missing', data)\r\n\r\n        talker_match = NMEASentence.talker_re.match(sentence_type)\r\n        if talker_match:\r\n            talker = talker_match.group('talker')\r\n            sentence = talker_match.group('sentence')\r\n            cls = TalkerSentence.sentence_types.get(sentence)\r\n\r\n            if not cls:\r\n                # TODO instantiate base type instead of fail\r\n                raise SentenceTypeError(\r\n                    'Unknown sentence type %s' % sentence_type, line)\r\n            return cls(talker, sentence, data)\r\n\r\n        query_match = NMEASentence.query_re.match(sentence_type)\r\n        if query_match and not data_str:\r\n            talker = query_match.group('talker')\r\n            listener = query_match.group('listener')\r\n            sentence = query_match.group('sentence')\r\n            return QuerySentence(talker, listener, sentence)\r\n\r\n        proprietary_match = NMEASentence.proprietary_re.match(sentence_type)\r\n        if proprietary_match:\r\n            manufacturer = proprietary_match.group('manufacturer')\r\n            cls = ProprietarySentence.sentence_types.get(manufacturer, ProprietarySentence)\r\n            return cls(manufacturer, data)\r\n\r\n        raise ParseError(\r\n            'could not parse sentence type: %r' % sentence_type, line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(self, fp, mode='r'):\n        self._file = open(fp, mode=mode)\n        return self._file", "response": "Open the NMEAFile.\n        file and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the next NMEASentence in the file object", "response": "def readline(self):\n        \"\"\"\n        Return the next NMEASentence in the file object\n        :return: NMEASentence\n        \"\"\"\n        data = self._file.readline()\n        s = self.parse(data)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a timestamp given in hhmmss [. ss ] ASCII text format to a datetime. time object", "response": "def timestamp(s):\r\n    '''\r\n    Converts a timestamp given in \"hhmmss[.ss]\" ASCII text format to a\r\n    datetime.time object\r\n    '''\r\n    ms_s = s[6:]\r\n    ms = ms_s and int(float(ms_s) * 1000000) or 0\r\n\r\n    t = datetime.time(\r\n        hour=int(s[0:2]),\r\n        minute=int(s[2:4]),\r\n        second=int(s[4:6]),\r\n        microsecond=ms)\r\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a geographic co -ordinate given in degrees / minutes dddmm. mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm to a signed format", "response": "def dm_to_sd(dm):\r\n    '''\r\n    Converts a geographic co-ordinate given in \"degrees/minutes\" dddmm.mmmm\r\n    format (eg, \"12319.943281\" = 123 degrees, 19.943281 minutes) to a signed\r\n    decimal (python float) format\r\n    '''\r\n    # '12319.943281'\r\n    if not dm or dm == '0':\r\n        return 0.\r\n    d, m = re.match(r'^(\\d+)(\\d\\d\\.\\d+)$', dm).groups()\r\n    return float(d) + float(m) / 60"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef longitude(self):\r\n        '''Longitude in signed degrees (python float)'''\r\n        sd = dm_to_sd(self.lon)\r\n        if self.lon_dir == 'E':\r\n            return +sd\r\n        elif self.lon_dir == 'W':\r\n            return -sd\r\n        else:\r\n            return 0.", "response": "Longitude in signed degrees ( python float )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the template instance node.", "response": "def template_instance(self):\n        '''\n        parse the template instance node.\n        this is used to compute the location of the template definition structure.\n\n        Returns:\n          TemplateInstanceNode: the template instance.\n        '''\n        ofs = self.offset()\n        if self.unpack_byte(0x0) & 0x0F == 0xF:\n            ofs += 4\n        return TemplateInstanceNode(self._buf, ofs, self._chunk, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the template referenced by this root node.", "response": "def template(self):\n        '''\n        parse the template referenced by this root node.\n        note, this template structure is not guaranteed to be located within the root node's boundaries.\n\n        Returns:\n          TemplateNode: the template.\n        '''\n        instance = self.template_instance()\n        offset = self._chunk.offset() + instance.template_offset()\n        node = TemplateNode(self._buf, offset, self._chunk, instance)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the offset aligned to the nearest greater than given alignment", "response": "def align(offset, alignment):\n    \"\"\"\n    Return the offset aligned to the nearest greater given alignment\n    Arguments:\n    - `offset`: An integer\n    - `alignment`: An integer\n    \"\"\"\n    if offset % alignment == 0:\n        return offset\n    return offset + (alignment - (offset % alignment))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new object of the correct type based on the dosdate and dostime.", "response": "def dosdate(dosdate, dostime):\n    \"\"\"\n    `dosdate`: 2 bytes, little endian.\n    `dostime`: 2 bytes, little endian.\n    returns: datetime.datetime or datetime.datetime.min on error\n    \"\"\"\n    try:\n        t  = ord(dosdate[1]) << 8\n        t |= ord(dosdate[0])\n        day   = t & 0b0000000000011111\n        month = (t & 0b0000000111100000) >> 5\n        year  = (t & 0b1111111000000000) >> 9\n        year += 1980\n\n        t  = ord(dostime[1]) << 8\n        t |= ord(dostime[0])\n        sec     = t & 0b0000000000011111\n        sec    *= 2\n        minute  = (t & 0b0000011111100000) >> 5\n        hour    = (t & 0b1111100000000000) >> 11\n\n        return datetime(year, month, day, hour, minute, sec)\n    except:\n        return datetime.min"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeclares a field of the current object.", "response": "def declare_field(self, type, name, offset=None, length=None):\n        \"\"\"\n        Declaratively add fields to this block.\n        This method will dynamically add corresponding\n          offset and unpacker methods to this block.\n        Arguments:\n        - `type`: A string. Should be one of the unpack_* types.\n        - `name`: A string.\n        - `offset`: A number.\n        - `length`: (Optional) A number. For (w)strings, length in chars.\n        \"\"\"\n        if offset is None:\n            offset = self._implicit_offset\n\n        if length is None:\n            def no_length_handler():\n                f = getattr(self, \"unpack_\" + type)\n                return f(offset)\n            setattr(self, name, no_length_handler)\n        else:\n\n            def explicit_length_handler():\n                f = getattr(self, \"unpack_\" + type)\n                return f(offset, length)\n            setattr(self, name, explicit_length_handler)\n\n        setattr(self, \"_off_\" + name, offset)\n        if type == \"byte\":\n            self._implicit_offset = offset + 1\n        elif type == \"int8\":\n            self._implicit_offset = offset + 1\n        elif type == \"word\":\n            self._implicit_offset = offset + 2\n        elif type == \"word_be\":\n            self._implicit_offset = offset + 2\n        elif type == \"int16\":\n            self._implicit_offset = offset + 2\n        elif type == \"dword\":\n            self._implicit_offset = offset + 4\n        elif type == \"dword_be\":\n            self._implicit_offset = offset + 4\n        elif type == \"int32\":\n            self._implicit_offset = offset + 4\n        elif type == \"qword\":\n            self._implicit_offset = offset + 8\n        elif type == \"int64\":\n            self._implicit_offset = offset + 8\n        elif type == \"float\":\n            self._implicit_offset = offset + 4\n        elif type == \"double\":\n            self._implicit_offset = offset + 8\n        elif type == \"dosdate\":\n            self._implicit_offset = offset + 4\n        elif type == \"filetime\":\n            self._implicit_offset = offset + 8\n        elif type == \"systemtime\":\n            self._implicit_offset = offset + 8\n        elif type == \"guid\":\n            self._implicit_offset = offset + 16\n        elif type == \"binary\":\n            self._implicit_offset = offset + length\n        elif type == \"string\" and length is not None:\n            self._implicit_offset = offset + length\n        elif type == \"wstring\" and length is not None:\n            self._implicit_offset = offset + (2 * length)\n        elif \"string\" in type and length is None:\n            raise ParseException(\"Implicit offset not supported \"\n                                 \"for dynamic length strings\")\n        else:\n            raise ParseException(\"Implicit offset not supported \"\n                                 \"for type: {}\".format(type))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a little - endian unsigned byte from the relative offset.", "response": "def unpack_byte(self, offset):\n        \"\"\"\n        Returns a little-endian unsigned byte from the relative offset.\n        Arguments:\n        - `offset`: The relative offset from the start of the block.\n        Throws:\n        - `OverrunBufferException`\n        \"\"\"\n        o = self._offset + offset\n        try:\n            return struct.unpack_from(\"<B\", self._buf, o)[0]\n        except struct.error:\n            raise OverrunBufferException(o, len(self._buf))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npacking a little - endian WORD into the internal buffer.", "response": "def pack_word(self, offset, word):\n        \"\"\"\n        Applies the little-endian WORD (2 bytes) to the relative offset.\n        Arguments:\n        - `offset`: The relative offset from the start of the block.\n        - `word`: The data to apply.\n        \"\"\"\n        o = self._offset + offset\n        return struct.pack_into(\"<H\", self._buf, o, word)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpack_binary(self, offset, length=False):\n        if not length:\n            return bytes(\"\".encode(\"ascii\"))\n        o = self._offset + offset\n        try:\n            return bytes(struct.unpack_from(\"<{}s\".format(length), self._buf, o)[0])\n        except struct.error:\n            raise OverrunBufferException(o, len(self._buf))", "response": "Returns the raw binary data from the relative offset with the given length."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack a string from the relative offset with the given length.", "response": "def unpack_wstring(self, offset, length):\n        \"\"\"\n        Returns a string from the relative offset with the given length,\n        where each character is a wchar (2 bytes)\n        Arguments:\n        - `offset`: The relative offset from the start of the block.\n        - `length`: The length of the string.\n        Throws:\n        - `UnicodeDecodeError`\n        \"\"\"\n        start = self._offset + offset\n        end = self._offset + offset + 2 * length\n        try:\n            return bytes(self._buf[start:end]).decode(\"utf16\")\n        except AttributeError:  # already a 'str' ?\n            return bytes(self._buf[start:end]).decode('utf16')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpack_dosdate(self, offset):\n        try:\n            o = self._offset + offset\n            return dosdate(self._buf[o:o + 2], self._buf[o + 2:o + 4])\n        except struct.error:\n            raise OverrunBufferException(o, len(self._buf))", "response": "Unpacks the next two bytes of the buffer starting at the given offset and returns a datetime."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunpacking a QWORD Windows SYSTEMTIME timestamp into a datetime object.", "response": "def unpack_systemtime(self, offset):\n        \"\"\"\n        Returns a datetime from the QWORD Windows SYSTEMTIME timestamp\n          starting at the relative offset.\n          See http://msdn.microsoft.com/en-us/library/ms724950%28VS.85%29.aspx\n        Arguments:\n        - `offset`: The relative offset from the start of the block.\n        Throws:\n        - `OverrunBufferException`\n        \"\"\"\n        o = self._offset + offset\n        try:\n            parts = struct.unpack_from(\"<HHHHHHHH\", self._buf, o)\n        except struct.error:\n            raise OverrunBufferException(o, len(self._buf))\n        return datetime(parts[0], parts[1],\n                        parts[3],  # skip part 2 (day of week)\n                        parts[4], parts[5],\n                        parts[6], parts[7])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunpacking a GUID from the beginning of the buffer starting at the relative offset.", "response": "def unpack_guid(self, offset):\n        \"\"\"\n        Returns a string containing a GUID starting at the relative offset.\n        Arguments:\n        - `offset`: The relative offset from the start of the block.\n        Throws:\n        - `OverrunBufferException`\n        \"\"\"\n        o = self._offset + offset\n\n        try:\n            _bin = bytes(self._buf[o:o + 16])\n        except IndexError:\n            raise OverrunBufferException(o, len(self._buf))\n\n        # Yeah, this is ugly\n        h = [six.indexbytes(_bin, i) for i in range(len(_bin))]\n        return \"\"\"{:02x}{:02x}{:02x}{:02x}-{:02x}{:02x}-{:02x}{:02x}-{:02x}{:02x}-{:02x}{:02x}{:02x}{:02x}{:02x}{:02x}\"\"\".format(\n            h[3], h[2], h[1], h[0],\n            h[5], h[4],\n            h[7], h[6],\n            h[8], h[9],\n            h[10], h[11], h[12], h[13], h[14], h[15])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _format_node_name(self, record, node, extra=None):\n        line = \"\"\n        if extra is not None:\n            line = \"%s(offset=%s, %s)\" % (node.__class__.__name__, hex(node.offset() - record.offset()), extra)\n        else:\n            line = \"%s(offset=%s)\" % (node.__class__.__name__, hex(node.offset() - record.offset()))\n\n        if isinstance(node, e_nodes.VariantTypeNode):\n            line += \" --> %s\" % (node.string())\n        if isinstance(node, e_nodes.OpenStartElementNode):\n            line += \" --> %s\" % (node.tag_name())\n        if isinstance(node, e_nodes.AttributeNode):\n            line += \" --> %s\" % (node.attribute_name().string())\n        return line", "response": "format the node name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string describing the root of the BXmlRecord.", "response": "def describe_root(record, root, indent=0, suppress_values=False):\n    \"\"\"\n    Args:\n      record (Evtx.Record):\n      indent (int):\n    \"\"\"\n    def format_node(n, extra=None, indent=0):\n        \"\"\"\n        Depends on closure over `record` and `suppress_values`.\n\n        Args:\n          n (Evtx.Nodes.BXmlNode):\n          extra (str):\n\n        Returns:\n          str:\n        \"\"\"\n        ret = \"\"\n        indent_s = '  ' * indent\n        name = n.__class__.__name__\n        offset = n.offset() - record.offset()\n        if extra is not None:\n            ret = \"%s%s(offset=%s, %s)\" % (indent_s, name, hex(offset), extra)\n        else:\n            ret = \"%s%s(offset=%s)\" % (indent_s, name, hex(offset))\n\n        if not suppress_values and isinstance(n, VariantTypeNode):\n            ret += \" --> %s\" % (n.string())\n            if isinstance(n, BXmlTypeNode):\n                ret += \"\\n\"\n                ret += describe_root(record, n._root, indent=indent + 1)\n\n        return ret\n\n    def rec(node, indent=0):\n        \"\"\"\n        Args:\n          node (Evtx.Nodes.BXmlNode):\n          indent (int):\n\n        Returns:\n          str:\n        \"\"\"\n        ret = \"\"\n        if isinstance(node, TemplateInstanceNode):\n            if node.is_resident_template():\n                extra = \"resident=True, length=%s\" % (hex(node.template().data_length()))\n                ret += \"%s\\n\" % (format_node(node, extra=extra, indent=indent))\n                ret += rec(node.template(), indent=indent + 1)\n            else:\n                ret += \"%s\\n\" % (format_node(node, extra=\"resident=False\", indent=indent))\n        else:\n            ret += \"%s\\n\" % (format_node(node, indent=indent))\n\n        for child in node.children():\n            ret += rec(child, indent=indent + 1)\n\n        if isinstance(node, RootNode):\n            ofs = node.tag_and_children_length()\n            indent_s = '  ' * (indent + 1)\n            offset = node.offset() - record.offset() + ofs\n            ret += \"%sSubstitutions(offset=%s)\\n\" % (indent_s, hex(offset))\n            for sub in node.substitutions():\n                ret += \"%s\\n\" % (format_node(sub, indent=indent + 2))\n\n        return ret\n\n    ret = \"\"\n    ret += rec(root, indent=indent)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef escape_attr(s):\n    '''\n    escape the given string such that it can be placed in an XML attribute, like:\n\n        <foo bar='$value'>\n\n    Args:\n      s (str): the string to escape.\n\n    Returns:\n      str: the escaped string.\n    '''\n    esc = xml.sax.saxutils.quoteattr(s)\n    esc = esc.encode('ascii', 'xmlcharrefreplace').decode('ascii')\n    esc = RESTRICTED_CHARS.sub('', esc)\n    return esc", "response": "escape the given string such that it can be placed in an XML attribute like : foo bar = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef escape_value(s):\n    '''\n    escape the given string such that it can be placed in an XML value location, like:\n\n        <foo>\n          $value\n        </foo>\n\n    Args:\n      s (str): the string to escape.\n\n    Returns:\n      str: the escaped string.\n    '''\n    esc = xml.sax.saxutils.escape(s)\n    esc = esc.encode('ascii', 'xmlcharrefreplace').decode('ascii')\n    esc = RESTRICTED_CHARS.sub('', esc)\n    return esc", "response": "Escape the given string such that it can be placed in an XML value location."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_root_node_with_subs(root_node, subs):\n    def rec(node, acc):\n        if isinstance(node, e_nodes.EndOfStreamNode):\n            pass  # intended\n        elif isinstance(node, e_nodes.OpenStartElementNode):\n            acc.append(\"<\")\n            acc.append(node.tag_name())\n            for child in node.children():\n                if isinstance(child, e_nodes.AttributeNode):\n                    acc.append(\" \")\n                    acc.append(validate_name(child.attribute_name().string()))\n                    acc.append(\"=\\\"\")\n                    # TODO: should use xml.sax.saxutils.quoteattr here\n                    # but to do so, we'd need to ensure we're not double-quoting this value.\n                    rec(child.attribute_value(), acc)\n                    acc.append(\"\\\"\")\n            acc.append(\">\")\n            for child in node.children():\n                rec(child, acc)\n            acc.append(\"</\")\n            acc.append(validate_name(node.tag_name()))\n            acc.append(\">\\n\")\n        elif isinstance(node, e_nodes.CloseStartElementNode):\n            pass  # intended\n        elif isinstance(node, e_nodes.CloseEmptyElementNode):\n            pass  # intended\n        elif isinstance(node, e_nodes.CloseElementNode):\n            pass  # intended\n        elif isinstance(node, e_nodes.ValueNode):\n            acc.append(escape_value(node.children()[0].string()))\n        elif isinstance(node, e_nodes.AttributeNode):\n            pass  # intended\n        elif isinstance(node, e_nodes.CDataSectionNode):\n            acc.append(\"<![CDATA[\")\n            # TODO: is this correct escaping???\n            acc.append(escape_value(node.cdata()))\n            acc.append(\"]]>\")\n        elif isinstance(node, e_nodes.EntityReferenceNode):\n            acc.append(escape_value(node.entity_reference()))\n        elif isinstance(node, e_nodes.ProcessingInstructionTargetNode):\n            acc.append(escape_value(node.processing_instruction_target()))\n        elif isinstance(node, e_nodes.ProcessingInstructionDataNode):\n            acc.append(escape_value(node.string()))\n        elif isinstance(node, e_nodes.TemplateInstanceNode):\n            raise UnexpectedElementException(\"TemplateInstanceNode\")\n        elif isinstance(node, e_nodes.NormalSubstitutionNode):\n            sub = subs[node.index()]\n\n            if isinstance(sub, e_nodes.BXmlTypeNode):\n                sub = render_root_node(sub.root())\n            else:\n                sub = escape_value(sub.string())\n\n            acc.append(sub)\n        elif isinstance(node, e_nodes.ConditionalSubstitutionNode):\n            sub = subs[node.index()]\n\n            if isinstance(sub, e_nodes.BXmlTypeNode):\n                sub = render_root_node(sub.root())\n            else:\n                sub = escape_value(sub.string())\n\n            acc.append(sub)\n        elif isinstance(node, e_nodes.StreamStartNode):\n            pass  # intended\n\n    acc = []\n    for c in root_node.template().children():\n        rec(c, acc)\n    return \"\".join(acc)", "response": "Render the given root node with the given substitutions into XML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating XML representations of the records in an EVTX chunk.", "response": "def evtx_chunk_xml_view(chunk):\n    \"\"\"\n    Generate XML representations of the records in an EVTX chunk.\n\n    Does not include the XML <?xml... header.\n    Records are ordered by chunk.records()\n\n    Args:\n      chunk (Evtx.Chunk): the chunk to render.\n\n    Yields:\n      tuple[str, Evtx.Record]: the rendered XML document and the raw record.\n    \"\"\"\n    for record in chunk.records():\n        record_str = evtx_record_xml_view(record)\n        yield record_str, record"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evtx_file_xml_view(file_header):\n    for chunk in file_header.chunks():\n        for record in chunk.records():\n            record_str = evtx_record_xml_view(record)\n            yield record_str, record", "response": "Generates XML representations of the records in an EVTX file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_contexted(func):\n        @wraps(func)\n        def wrapped(self, *args, **kwargs):\n            if self._buf is None:\n                raise TypeError(\"An Evtx object must be used with\"\n                                \" a context (see the `with` statement).\")\n            else:\n                return func(self, *args, **kwargs)\n        return wrapped", "response": "Decorator that ensures that an instance of the\n ArcGIS object is used within a context statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chunks(self, include_inactive=False):\n        if include_inactive:\n            chunk_count = sys.maxsize\n        else:\n            chunk_count = self.chunk_count()\n\n        i = 0\n        ofs = self._offset + self.header_chunk_size()\n        while ofs + 0x10000 <= len(self._buf) and i < chunk_count:\n            yield ChunkHeader(self._buf, ofs)\n            ofs += 0x10000\n            i += 1", "response": "A generator that yields the chunks of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_record(self, record_num):\n        for chunk in self.chunks():\n            first_record = chunk.log_first_record_number()\n            last_record = chunk.log_last_record_number()\n            if not (first_record <= record_num <= last_record):\n                continue\n            for record in chunk.records():\n                if record.record_num() == record_num:\n                    return record\n        return None", "response": "Get a Record by record number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_xml(self):\n        if self._xml is not None:\n            return\n        matcher = \"\\[(?:Normal|Conditional) Substitution\\(index=(\\d+), type=\\d+\\)\\]\"\n        self._xml = re.sub(matcher, \"{\\\\1:}\",\n                           self._template_node.template_format().replace(\"{\", \"{{\").replace(\"}\", \"}}\"))", "response": "Load the XML from the template node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the raw data block which makes up this record as a bytestring.", "response": "def data(self):\n        \"\"\"\n        Return the raw data block which makes up this record as a bytestring.\n\n        @rtype str\n        @return A string that is a copy of the buffer that makes\n          up this record.\n        \"\"\"\n        return self._buf[self.offset():self.offset() + self.size()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lxml(self):\n        '''\n        render the record into a lxml document.\n        this is useful for querying data from the record using xpath, etc.\n\n        note: lxml must be installed.\n\n        Returns:\n          lxml.etree.ElementTree: the rendered and parsed xml document.\n\n        Raises:\n          ImportError: if lxml is not installed.\n        '''\n        import lxml.etree\n        return lxml.etree.fromstring((e_views.XML_HEADER + self.xml()).encode('utf-8'))", "response": "render the record into a lxml document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post(self):\n        self.reqparse.add_argument('username', type=str, required=True)\n        self.reqparse.add_argument('authSystem', type=str, required=True)\n        self.reqparse.add_argument('password', type=str, required=False, default=None)\n        self.reqparse.add_argument('roles', type=str, action='append', default=[])\n        args = self.reqparse.parse_args()\n        auditlog(event='user.create', actor=session['user'].username, data=args)\n\n        user = db.User.find_one(\n            User.username == args['username'],\n            User.auth_system == args['authSystem']\n        )\n        roles = []\n        if user:\n            return self.make_response('User already exists', HTTP.BAD_REQUEST)\n\n        if args['authSystem'] not in current_app.available_auth_systems:\n            return self.make_response(\n                'The {} auth system does not allow local edits'.format(args['authSystem']),\n                HTTP.BAD_REQUEST\n            )\n\n        if current_app.available_auth_systems[args['authSystem']].readonly:\n            return self.make_response(\n                'You cannot create users for the {} auth system as it is handled externally'.format(args['authSystem']),\n                HTTP.BAD_REQUEST\n            )\n\n        for roleName in args['roles']:\n            role = db.Role.find_one(Role.name == roleName)\n\n            if not role:\n                return self.make_response('No such role {}'.format(roleName), HTTP.BAD_REQUEST)\n\n            if roleName == ROLE_ADMIN and ROLE_ADMIN not in session['user'].roles:\n                self.log.error('User {} tried to grant admin privileges to {}'.format(\n                    session['user'].username,\n                    args['username']\n                ))\n\n                return self.make_response('You do not have permission to grant admin privileges', HTTP.FORBIDDEN)\n\n            roles.append(role)\n\n        authSys = current_app.available_auth_systems[args['authSystem']]\n        password = args['password'] or generate_password()\n\n        user = User()\n        user.username = args['username']\n        user.password = hash_password(password)\n        user.auth_system = authSys.name\n        db.session.add(user)\n        db.session.commit()\n        db.session.refresh(user)\n        User.add_role(user, roles)\n\n        return self.make_response({\n            'message': 'User {}/{} has been created'.format(user.auth_system, user.username),\n            'user': user,\n            'password': password if not args['password'] else None\n        })", "response": "Create a new user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef options(self):\n        roles = db.Role.all()\n\n        return self.make_response({\n            'roles': roles,\n            'authSystems': list(current_app.available_auth_systems.keys()),\n            'activeAuthSystem': current_app.active_auth_system.name\n        })", "response": "Returns metadata information required for User Creation"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a specific user", "response": "def get(self, user_id):\n        \"\"\"Returns a specific user\"\"\"\n        user = db.User.find_one(User.user_id == user_id)\n        roles = db.Role.all()\n\n        if not user:\n            return self.make_response('Unable to find the user requested, might have been removed', HTTP.NOT_FOUND)\n\n        return self.make_response({\n            'user': user.to_json(),\n            'roles': roles\n        }, HTTP.OK)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a user object", "response": "def put(self, user_id):\n        \"\"\"Update a user object\"\"\"\n        self.reqparse.add_argument('roles', type=str, action='append')\n        args = self.reqparse.parse_args()\n        auditlog(event='user.create', actor=session['user'].username, data=args)\n\n        user = db.User.find_one(User.user_id == user_id)\n        roles = db.Role.find(Role.name.in_(args['roles']))\n        if not user:\n            return self.make_response('No such user found: {}'.format(user_id), HTTP.NOT_FOUND)\n\n        if user.username == 'admin' and user.auth_system == 'builtin':\n            return self.make_response('You cannot modify the built-in admin user', HTTP.FORBIDDEN)\n\n        user.roles = []\n        for role in roles:\n            if role in args['roles']:\n                user.roles.append(role)\n\n        db.session.add(user)\n        db.session.commit()\n\n        return self.make_response({'message': 'User roles updated'}, HTTP.OK)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the cache of all DNS entries and perform checks on them", "response": "def run(self, *args, **kwargs):\n        \"\"\"Update the cache of all DNS entries and perform checks\n\n        Args:\n            *args: Optional list of arguments\n            **kwargs: Optional list of keyword arguments\n\n        Returns:\n            None\n        \"\"\"\n        try:\n            zones = list(DNSZone.get_all().values())\n            buckets = {k.lower(): v for k, v in S3Bucket.get_all().items()}\n            dists = list(CloudFrontDist.get_all().values())\n            ec2_public_ips = [x.public_ip for x in EC2Instance.get_all().values() if x.public_ip]\n            beanstalks = {x.cname.lower(): x for x in BeanStalk.get_all().values()}\n\n            existing_issues = DomainHijackIssue.get_all()\n            issues = []\n\n            # List of different types of domain audits\n            auditors = [\n                ElasticBeanstalkAudit(beanstalks),\n                S3Audit(buckets),\n                S3WithoutEndpointAudit(buckets),\n                EC2PublicDns(ec2_public_ips),\n            ]\n\n            # region Build list of active issues\n            for zone in zones:\n                for record in zone.records:\n                    for auditor in auditors:\n                        if auditor.match(record):\n                            issues.extend(auditor.audit(record, zone))\n\n            for dist in dists:\n                for org in dist.origins:\n                    if org['type'] == 's3':\n                        bucket = self.return_resource_name(org['source'], 's3')\n\n                        if bucket not in buckets:\n                            key = '{} ({})'.format(bucket, dist.type)\n                            issues.append({\n                                'key': key,\n                                'value': 'S3Bucket {} doesnt exist on any known account. Referenced by {} on {}'.format(\n                                    bucket,\n                                    dist.domain_name,\n                                    dist.account,\n                                )\n                            })\n            # endregion\n\n            # region Process new, old, fixed issue lists\n            old_issues = {}\n            new_issues = {}\n            fixed_issues = []\n\n            for data in issues:\n                issue_id = get_resource_id('dhi', ['{}={}'.format(k, v) for k, v in data.items()])\n\n                if issue_id in existing_issues:\n                    issue = existing_issues[issue_id]\n\n                    if issue.update({'state': 'EXISTING', 'end': None}):\n                        db.session.add(issue.issue)\n\n                    old_issues[issue_id] = issue\n\n                else:\n                    properties = {\n                        'issue_hash': issue_id,\n                        'state': 'NEW',\n                        'start': datetime.now(),\n                        'end': None,\n                        'source': data['key'],\n                        'description': data['value']\n                    }\n                    new_issues[issue_id] = DomainHijackIssue.create(issue_id, properties=properties)\n            db.session.commit()\n\n            for issue in list(existing_issues.values()):\n                if issue.id not in new_issues and issue.id not in old_issues:\n                    fixed_issues.append(issue.to_json())\n                    db.session.delete(issue.issue)\n            # endregion\n\n            # Only alert if its been more than a day since the last alert\n            alert_cutoff = datetime.now() - timedelta(hours=self.alert_frequency)\n            old_alerts = []\n            for issue_id, issue in old_issues.items():\n                if issue.last_alert and issue.last_alert < alert_cutoff:\n                    if issue.update({'last_alert': datetime.now()}):\n                        db.session.add(issue.issue)\n\n                    old_alerts.append(issue)\n\n            db.session.commit()\n\n            self.notify(\n                [x.to_json() for x in new_issues.values()],\n                [x.to_json() for x in old_alerts],\n                fixed_issues\n            )\n        finally:\n            db.session.rollback()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend notifications for any issues that are currently open or has just been closed.", "response": "def notify(self, new_issues, existing_issues, fixed_issues):\n        \"\"\"Send notifications (email, slack, etc.) for any issues that are currently open or has just been closed\n\n        Args:\n            new_issues (`list` of :obj:`DomainHijackIssue`): List of newly discovered issues\n            existing_issues (`list` of :obj:`DomainHijackIssue`): List of existing open issues\n            fixed_issues (`list` of `dict`): List of fixed issues\n\n        Returns:\n            None\n        \"\"\"\n        if len(new_issues + existing_issues + fixed_issues) > 0:\n            maxlen = max(len(x['properties']['source']) for x in (new_issues + existing_issues + fixed_issues)) + 2\n            text_tmpl = get_template('domain_hijacking.txt')\n            html_tmpl = get_template('domain_hijacking.html')\n            issues_text = text_tmpl.render(\n                new_issues=new_issues,\n                existing_issues=existing_issues,\n                fixed_issues=fixed_issues,\n                maxlen=maxlen\n            )\n            issues_html = html_tmpl.render(\n                new_issues=new_issues,\n                existing_issues=existing_issues,\n                fixed_issues=fixed_issues,\n                maxlen=maxlen\n            )\n\n            try:\n                send_notification(\n                    subsystem=self.name,\n                    recipients=[NotificationContact('email', addr) for addr in self.recipients],\n                    subject=self.subject,\n                    body_html=issues_html,\n                    body_text=issues_text\n                )\n            except Exception as ex:\n                self.log.exception('Failed sending notification email: {}'.format(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the trailing AWS domain from a DNS record to return the resource name", "response": "def return_resource_name(self, record, resource_type):\n        \"\"\" Removes the trailing AWS domain from a DNS record\n            to return the resource name\n\n            e.g bucketname.s3.amazonaws.com will return bucketname\n\n        Args:\n            record (str): DNS record\n            resource_type: AWS Resource type (i.e. S3 Bucket, Elastic Beanstalk, etc..)\n\n        \"\"\"\n        try:\n            if resource_type == 's3':\n                regex = re.compile('.*(\\.(?:s3-|s3){1}(?:.*)?\\.amazonaws\\.com)')\n                bucket_name = record.replace(regex.match(record).group(1), '')\n                return bucket_name\n\n        except Exception as e:\n            self.log.error('Unable to parse DNS record {} for resource type {}/{}'.format(record, resource_type, e))\n            return record"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_json(self, is_admin=False):\n        if is_admin:\n            return {\n                'accountId': self.account_id,\n                'accountName': self.account_name,\n                'accountType': self.account_type,\n                'contacts': self.contacts,\n                'enabled': True if self.enabled == 1 else False,\n                'requiredRoles': self.required_roles,\n                'properties': {to_camelcase(prop.name): prop.value for prop in self.account.properties}\n            }\n        else:\n            return {\n                'accountId': self.account_id,\n                'accountName': self.account_name,\n                'contacts': self.contacts\n            }", "response": "Returns a dict representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, **kwargs):\n        updated = False\n\n        for prop in self.class_properties:\n            key = prop['key']\n            kwarg_key = to_camelcase(key)\n            if kwarg_key in kwargs:\n                if prop['required'] and not kwargs[kwarg_key]:\n                    raise InquisitorError('Missing required property {}'.format(prop['name']))\n\n                updated |= self.set_property(key, kwargs[kwarg_key])\n\n        return updated", "response": "Updates the object information based on live data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(account):\n        account = Account.get(account)\n        if not account:\n            return None\n\n        acct_type = AccountType.get(account.account_type_id).account_type\n        account_class = get_plugin_by_name(PLUGIN_NAMESPACES['accounts'], acct_type)\n\n        return account_class(account)", "response": "Returns the class object identified by account_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all(cls, include_disabled=True):\n        if cls == BaseAccount:\n            raise InquisitorError('get_all on BaseAccount is not supported')\n\n        account_type_id = db.AccountType.find_one(account_type=cls.account_type).account_type_id\n        qry = db.Account.order_by(desc(Account.enabled), Account.account_type_id, Account.account_name)\n\n        if not include_disabled:\n            qry = qry.filter(Account.enabled == 1)\n\n        accounts = qry.find(Account.account_type_id == account_type_id)\n\n        return {res.account_id: cls(res) for res in accounts}", "response": "Returns a list of all accounts of a given type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for accounts based on the provided filters", "response": "def search(*, include_disabled=True, account_ids=None, account_type_id=None, properties=None, return_query=False):\n        \"\"\"Search for accounts based on the provided filters\n\n        Args:\n            include_disabled (`bool`): Include disabled accounts (default: True)\n            account_ids: (`list` of `int`): List of account IDs\n            account_type_id (`int`): Account Type ID to limit results to\n            properties (`dict`): A `dict` containing property name and value pairs. Values can be either a str or a list\n            of strings, in which case a boolean OR search is performed on the values\n            return_query (`bool`): Returns the query object prior to adding the limit and offset functions. Allows for\n            sub-classes to amend the search feature with extra conditions. The calling function must handle pagination\n            on its own\n\n        Returns:\n            `list` of `Account`, `sqlalchemy.orm.Query`\n        \"\"\"\n        qry = db.Account.order_by(desc(Account.enabled), Account.account_type_id, Account.account_name)\n\n        if not include_disabled:\n            qry = qry.filter(Account.enabled == 1)\n\n        if account_ids:\n            if type(account_ids) not in (list, tuple):\n                account_ids = [account_ids]\n\n            qry = qry.filter(Account.account_id.in_(account_ids))\n\n        if account_type_id:\n            qry = qry.filter(Account.account_type_id == account_type_id)\n\n        if properties:\n            for prop_name, value in properties.items():\n                alias = aliased(AccountProperty)\n                qry = qry.join(alias, Account.account_id == alias.account_id)\n                if type(value) == list:\n                    where_clause = []\n                    for item in value:\n                        where_clause.append(alias.value == item)\n\n                    qry = qry.filter(\n                        and_(\n                            alias.name == prop_name,\n                            or_(*where_clause)\n                        ).self_group()\n                    )\n                else:\n                    qry = qry.filter(\n                        and_(\n                            alias.name == prop_name,\n                            alias.value == value\n                        ).self_group()\n                    )\n\n        if return_query:\n            return qry\n\n        total = qry.count()\n        return total, list(map(BaseAccount.get_typed_account, qry.all()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_scheduler(self):\n        try:\n            # Schedule periodic scheduling of jobs\n            self.scheduler.add_job(\n                self.schedule_jobs,\n                trigger='interval',\n                name='schedule_jobs',\n                minutes=15,\n                start_date=datetime.now() + timedelta(seconds=1)\n            )\n\n            self.scheduler.add_job(\n                self.process_status_queue,\n                trigger='interval',\n                name='process_status_queue',\n                seconds=30,\n                start_date=datetime.now() + timedelta(seconds=5),\n                max_instances=1\n            )\n\n            self.scheduler.start()\n\n        except KeyboardInterrupt:\n            self.scheduler.shutdown()", "response": "This method starts two scheduled jobs and processes the status queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_current_jobs(self):\n        jobs = {}\n        for job in self.scheduler.get_jobs():\n            if job.name not in ('schedule_jobs', 'process_status_queue'):\n                jobs[job.name] = job\n\n        return jobs", "response": "Return a list of the currently scheduled jobs in APScheduler\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nschedule or remove jobs as needed.", "response": "def schedule_jobs(self):\n        \"\"\"Schedule or remove jobs as needed.\n\n        Checks to see if there are any jobs that needs to be scheduled, after refreshing the database configuration\n        as well as the list of collectors and auditors.\n\n        Returns:\n            `None`\n        \"\"\"\n        self.dbconfig.reload_data()\n        self.collectors = {}\n        self.auditors = []\n        self.load_plugins()\n\n        _, accounts = BaseAccount.search(include_disabled=False)\n        current_jobs = self.list_current_jobs()\n        new_jobs = []\n        batch_id = str(uuid4())\n\n        batch = SchedulerBatch()\n        batch.batch_id = batch_id\n        batch.status = SchedulerStatus.PENDING\n        db.session.add(batch)\n        db.session.commit()\n\n        start = datetime.now() + timedelta(seconds=1)\n        job_delay = dbconfig.get('job_delay', self.ns, 0.5)\n\n        # region Global collectors (non-aws)\n        if CollectorType.GLOBAL in self.collectors:\n            for worker in self.collectors[CollectorType.GLOBAL]:\n                job_name = get_hash(worker)\n\n                if job_name in current_jobs:\n                    continue\n\n                self.scheduler.add_job(\n                    self.send_worker_queue_message,\n                    trigger='interval',\n                    name=job_name,\n                    minutes=worker.interval,\n                    start_date=start,\n                    kwargs={\n                        'batch_id': batch_id,\n                        'job_name': job_name,\n                        'entry_point': worker.entry_point,\n                        'worker_args': {}\n                    }\n                )\n                start += timedelta(seconds=job_delay)\n        # endregion\n\n        # region AWS collectors\n        aws_accounts = list(filter(lambda x: x.account_type == AWSAccount.account_type, accounts))\n        if CollectorType.AWS_ACCOUNT in self.collectors:\n            for worker in self.collectors[CollectorType.AWS_ACCOUNT]:\n                for account in aws_accounts:\n                    job_name = get_hash((account.account_name, worker))\n                    if job_name in current_jobs:\n                        continue\n\n                    new_jobs.append(job_name)\n\n                    self.scheduler.add_job(\n                        self.send_worker_queue_message,\n                        trigger='interval',\n                        name=job_name,\n                        minutes=worker.interval,\n                        start_date=start,\n                        kwargs={\n                            'batch_id': batch_id,\n                            'job_name': job_name,\n                            'entry_point': worker.entry_point,\n                            'worker_args': {\n                                'account': account.account_name\n                            }\n                        }\n                    )\n                    start += timedelta(seconds=job_delay)\n\n        if CollectorType.AWS_REGION in self.collectors:\n            for worker in self.collectors[CollectorType.AWS_REGION]:\n                for region in AWS_REGIONS:\n                    for account in aws_accounts:\n                        job_name = get_hash((account.account_name, region, worker))\n\n                        if job_name in current_jobs:\n                            continue\n\n                        new_jobs.append(job_name)\n\n                        self.scheduler.add_job(\n                            self.send_worker_queue_message,\n                            trigger='interval',\n                            name=job_name,\n                            minutes=worker.interval,\n                            start_date=start,\n                            kwargs={\n                                'batch_id': batch_id,\n                                'job_name': job_name,\n                                'entry_point': worker.entry_point,\n                                'worker_args': {\n                                    'account': account.account_name,\n                                    'region': region\n                                }\n                            }\n                        )\n                        start += timedelta(seconds=job_delay)\n        # endregion\n\n        # region Auditors\n        if app_config.log_level == 'DEBUG':\n            audit_start = start + timedelta(seconds=5)\n        else:\n            audit_start = start + timedelta(minutes=5)\n\n        for worker in self.auditors:\n            job_name = get_hash((worker,))\n            if job_name in current_jobs:\n                continue\n\n            new_jobs.append(job_name)\n\n            self.scheduler.add_job(\n                self.send_worker_queue_message,\n                trigger='interval',\n                name=job_name,\n                minutes=worker.interval,\n                start_date=audit_start,\n                kwargs={\n                    'batch_id': batch_id,\n                    'job_name': job_name,\n                    'entry_point': worker.entry_point,\n                    'worker_args': {}\n                }\n            )\n            audit_start += timedelta(seconds=job_delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a message to the worker_queue for a worker to execute the requests.", "response": "def send_worker_queue_message(self, *, batch_id, job_name, entry_point, worker_args, retry_count=0):\n        \"\"\"Send a message to the `worker_queue` for a worker to execute the requests job\n\n        Args:\n            batch_id (`str`): Unique ID of the batch the job belongs to\n            job_name (`str`): Non-unique ID of the job. This is used to ensure that the same job is only scheduled\n            a single time per batch\n            entry_point (`dict`): A dictionary providing the entry point information for the worker to load the class\n            worker_args (`dict`): A dictionary with the arguments required by the worker class (if any, can be an\n            empty dictionary)\n            retry_count (`int`): The number of times this one job has been attempted to be executed. If a job fails to\n            execute after 3 retries it will be marked as failed\n\n        Returns:\n            `None`\n        \"\"\"\n        try:\n            job_id = str(uuid4())\n            self.job_queue.send_message(\n                MessageBody=json.dumps({\n                    'batch_id': batch_id,\n                    'job_id': job_id,\n                    'job_name': job_name,\n                    'entry_point': entry_point,\n                    'worker_args': worker_args,\n                }),\n                MessageDeduplicationId=job_id,\n                MessageGroupId=batch_id,\n                MessageAttributes={\n                    'RetryCount': {\n                        'StringValue': str(retry_count),\n                        'DataType': 'Number'\n\n                    }\n                }\n            )\n\n            if retry_count == 0:\n                job = SchedulerJob()\n                job.job_id = job_id\n                job.batch_id = batch_id\n                job.status = SchedulerStatus.PENDING\n                job.data = worker_args\n\n                db.session.add(job)\n                db.session.commit()\n        except:\n            self.log.exception('Error when processing worker task')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a message from the `worker_queue` and process the request. This function will read a single message from the `worker_queue` and load the specified `EntryPoint` and execute the worker with the provided arguments. Upon completion (failure or otherwise) a message is sent to the `status_queue` information the scheduler about the return status (success/failure) of the worker Returns: `None`", "response": "def execute_worker(self):\n        \"\"\"Retrieve a message from the `worker_queue` and process the request.\n\n        This function will read a single message from the `worker_queue` and load the specified `EntryPoint`\n        and execute the worker with the provided arguments. Upon completion (failure or otherwise) a message is sent\n        to the `status_queue` information the scheduler about the return status (success/failure) of the worker\n\n        Returns:\n            `None`\n        \"\"\"\n        try:\n            try:\n                messages = self.job_queue.receive_messages(\n                    MaxNumberOfMessages=1,\n                    MessageAttributeNames=('RetryCount',)\n                )\n\n            except ClientError:\n                self.log.exception('Failed fetching messages from SQS queue')\n                return\n\n            if not messages:\n                self.log.debug('No pending jobs')\n                return\n\n            for message in messages:\n                try:\n                    retry_count = int(message.message_attributes['RetryCount']['StringValue'])\n\n                    data = json.loads(message.body)\n                    try:\n                        # SQS FIFO queues will not allow another thread to get any new messages until the messages\n                        # in-flight are returned to the queue or deleted, so we remove the message from the queue as\n                        # soon as we've loaded the data\n                        self.send_status_message(data['job_id'], SchedulerStatus.STARTED)\n                        message.delete()\n\n                        cls = self.get_class_from_ep(data['entry_point'])\n                        worker = cls(**data['worker_args'])\n                        if hasattr(worker, 'type'):\n                            if worker.type == CollectorType.GLOBAL:\n                                self.log.info('RUN_INFO: {} starting at {}, next run will be at approximately {}'.format(data['entry_point']['module_name'], datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), (datetime.now() + timedelta(minutes=worker.interval)).strftime(\"%Y-%m-%d %H:%M:%S\")))\n                            elif worker.type == CollectorType.AWS_REGION:\n                                self.log.info('RUN_INFO: {} starting at {} for account {} / region {}, next run will be at approximately {}'.format(data['entry_point']['module_name'],\tdatetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), data['worker_args']['account'], data['worker_args']['region'], (datetime.now() + timedelta(minutes=worker.interval)).strftime(\"%Y-%m-%d %H:%M:%S\")))\n                            elif worker.type == CollectorType.AWS_ACCOUNT:\n                                self.log.info('RUN_INFO: {} starting at {} for account {} next run will be at approximately {}'.format(data['entry_point']['module_name'], datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), data['worker_args']['account'], (datetime.now() + timedelta(minutes=worker.interval)).strftime(\"%Y-%m-%d %H:%M:%S\")))\n                        else:\n                            self.log.info('RUN_INFO: {} starting at {} next run will be at approximately {}'.format(data['entry_point']['module_name'], datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), (datetime.now() + timedelta(minutes=worker.interval)).strftime(\"%Y-%m-%d %H:%M:%S\")))\n                        worker.run()\n\n                        self.send_status_message(data['job_id'], SchedulerStatus.COMPLETED)\n                    except InquisitorError:\n                        # If the job failed for some reason, reschedule it unless it has already been retried 3 times\n                        if retry_count >= 3:\n                            self.send_status_message(data['job_id'], SchedulerStatus.FAILED)\n                        else:\n                            self.send_worker_queue_message(\n                                batch_id=data['batch_id'],\n                                job_name=data['job_name'],\n                                entry_point=data['entry_point'],\n                                worker_args=data['worker_args'],\n                                retry_count=retry_count + 1\n                            )\n                except:\n                    self.log.exception('Failed processing scheduler job: {}'.format(message.body))\n\n        except KeyboardInterrupt:\n            self.log.info('Shutting down worker thread')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a status message to the status_queue.", "response": "def send_status_message(self, object_id, status):\n        \"\"\"Send a message to the `status_queue` to update a job's status.\n\n        Returns `True` if the message was sent, else `False`\n\n        Args:\n            object_id (`str`): ID of the job that was executed\n            status (:obj:`SchedulerStatus`): Status of the job\n\n        Returns:\n            `bool`\n        \"\"\"\n        try:\n            body = json.dumps({\n                'id': object_id,\n                'status': status\n            })\n\n            self.status_queue.send_message(\n                MessageBody=body,\n                MessageGroupId='job_status',\n                MessageDeduplicationId=get_hash((object_id, status))\n            )\n            return True\n        except Exception as ex:\n            print(ex)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses all messages in the status_queue and check for any jobs that need to be updated status", "response": "def process_status_queue(self):\n        \"\"\"Process all messages in the `status_queue` and check for any batches that needs to change status\n\n        Returns:\n            `None`\n        \"\"\"\n        self.log.debug('Start processing status queue')\n        while True:\n            messages = self.status_queue.receive_messages(MaxNumberOfMessages=10)\n\n            if not messages:\n                break\n\n            for message in messages:\n                data = json.loads(message.body)\n                job = SchedulerJob.get(data['id'])\n                try:\n                    if job and job.update_status(data['status']):\n                        db.session.commit()\n                except SchedulerError as ex:\n                    if hasattr(ex, 'message') and ex.message == 'Attempting to update already completed job':\n                        pass\n\n                message.delete()\n\n        # Close any batch that is now complete\n        open_batches = db.SchedulerBatch.find(SchedulerBatch.status < SchedulerStatus.COMPLETED)\n        for batch in open_batches:\n            open_jobs = list(filter(lambda x: x.status < SchedulerStatus.COMPLETED, batch.jobs))\n            if not open_jobs:\n                open_batches.remove(batch)\n                batch.update_status(SchedulerStatus.COMPLETED)\n                self.log.debug('Closed completed batch {}'.format(batch.batch_id))\n            else:\n                started_jobs = list(filter(lambda x: x.status > SchedulerStatus.PENDING, open_jobs))\n                if batch.status == SchedulerStatus.PENDING and len(started_jobs) > 0:\n                    batch.update_status(SchedulerStatus.STARTED)\n                    self.log.debug('Started batch manually {}'.format(batch.batch_id))\n\n        # Check for stale batches / jobs\n        for batch in open_batches:\n            if batch.started < datetime.now() - timedelta(hours=2):\n                self.log.warning('Closing a stale scheduler batch: {}'.format(batch.batch_id))\n                for job in batch.jobs:\n                    if job.status < SchedulerStatus.COMPLETED:\n                        job.update_status(SchedulerStatus.ABORTED)\n                batch.update_status(SchedulerStatus.ABORTED)\n        db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, *args, **kwargs):\n        accounts = list(AWSAccount.get_all(include_disabled=False).values())\n        self.manage_policies(accounts)", "response": "Iterate through all AWS accounts and apply roles and policies from Github\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_policies(self, account, account_policies, aws_policies):\n        self.log.debug('Fetching policies for {}'.format(account.account_name))\n        sess = get_aws_session(account)\n        iam = sess.client('iam')\n        added = {}\n\n        for policyName, account_policy in account_policies.items():\n            # policies pulled from github a likely bytes and need to be converted\n            if isinstance(account_policy, bytes):\n                account_policy = account_policy.decode('utf-8')\n\n            # Using re.sub instead of format since format breaks on the curly braces of json\n            gitpol = json.loads(\n                re.sub(\n                    r'{AD_Group}',\n                    account.ad_group_base or account.account_name,\n                    account_policy\n                )\n            )\n\n            if policyName in aws_policies:\n                pol = aws_policies[policyName]\n                awspol = iam.get_policy_version(\n                    PolicyArn=pol['Arn'],\n                    VersionId=pol['DefaultVersionId']\n                )['PolicyVersion']['Document']\n\n                if awspol != gitpol:\n                    self.log.warn('IAM Policy {} on {} does not match Git policy documents, updating'.format(\n                        policyName,\n                        account.account_name\n                    ))\n\n                    self.create_policy(account, iam, json.dumps(gitpol, indent=4), policyName, arn=pol['Arn'])\n                else:\n                    self.log.debug('IAM Policy {} on {} is up to date'.format(\n                        policyName,\n                        account.account_name\n                    ))\n            else:\n                self.log.warn('IAM Policy {} is missing on {}'.format(policyName, account.account_name))\n                response = self.create_policy(account, iam, json.dumps(gitpol), policyName)\n                added[policyName] = response['Policy']\n\n        return added", "response": "Iterate through the policies of a specific account and create or update the policies if they do not match the Git policy documents from Git."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate through the roles of a specific account and create or update the roles if they are missing or does not match the roles from Git.", "response": "def check_roles(self, account, aws_policies, aws_roles):\n        \"\"\"Iterate through the roles of a specific account and create or update the roles if they're missing or\n        does not match the roles from Git.\n\n        Args:\n            account (:obj:`Account`): The account to check roles on\n            aws_policies (:obj:`dict` of `str`: `dict`): A dictionary containing all the policies for the specific\n            account\n            aws_roles (:obj:`dict` of `str`: `dict`): A dictionary containing all the roles for the specific account\n\n        Returns:\n            `None`\n        \"\"\"\n        self.log.debug('Checking roles for {}'.format(account.account_name))\n        max_session_duration = self.dbconfig.get('role_timeout_in_hours', self.ns, 8) * 60 * 60\n        sess = get_aws_session(account)\n        iam = sess.client('iam')\n\n        # Build a list of default role policies and extra account specific role policies\n        account_roles = copy.deepcopy(self.cfg_roles)\n        if account.account_name in self.git_policies:\n            for role in self.git_policies[account.account_name]:\n                if role in account_roles:\n                    account_roles[role]['policies'] += list(self.git_policies[account.account_name][role].keys())\n\n        for role_name, data in list(account_roles.items()):\n            if role_name not in aws_roles:\n                iam.create_role(\n                    Path='/',\n                    RoleName=role_name,\n                    AssumeRolePolicyDocument=json.dumps(data['trust'], indent=4),\n                    MaxSessionDuration=max_session_duration\n                )\n                self.log.info('Created role {}/{}'.format(account.account_name, role_name))\n            else:\n                try:\n                    if aws_roles[role_name]['MaxSessionDuration'] != max_session_duration:\n                        iam.update_role(\n                            RoleName=aws_roles[role_name]['RoleName'],\n                            MaxSessionDuration=max_session_duration\n                        )\n                        self.log.info('Adjusted MaxSessionDuration for role {} in account {} to {} seconds'.format(\n                            role_name,\n                            account.account_name,\n                            max_session_duration\n                        ))\n                except ClientError:\n                    self.log.exception('Unable to adjust MaxSessionDuration for role {} in account {}'.format(\n                        role_name,\n                        account.account_name\n                    ))\n\n            aws_role_policies = [x['PolicyName'] for x in iam.list_attached_role_policies(\n                RoleName=role_name)['AttachedPolicies']\n            ]\n            aws_role_inline_policies = iam.list_role_policies(RoleName=role_name)['PolicyNames']\n            cfg_role_policies = data['policies']\n\n            missing_policies = list(set(cfg_role_policies) - set(aws_role_policies))\n            extra_policies = list(set(aws_role_policies) - set(cfg_role_policies))\n\n            if aws_role_inline_policies:\n                self.log.info('IAM Role {} on {} has the following inline policies: {}'.format(\n                    role_name,\n                    account.account_name,\n                    ', '.join(aws_role_inline_policies)\n                ))\n\n                if self.dbconfig.get('delete_inline_policies', self.ns, False) and self.manage_roles:\n                    for policy in aws_role_inline_policies:\n                        iam.delete_role_policy(RoleName=role_name, PolicyName=policy)\n                        auditlog(\n                            event='iam.check_roles.delete_inline_role_policy',\n                            actor=self.ns,\n                            data={\n                                'account': account.account_name,\n                                'roleName': role_name,\n                                'policy': policy\n                            }\n                        )\n\n            if missing_policies:\n                self.log.info('IAM Role {} on {} is missing the following policies: {}'.format(\n                    role_name,\n                    account.account_name,\n                    ', '.join(missing_policies)\n                ))\n                if self.manage_roles:\n                    for policy in missing_policies:\n                        iam.attach_role_policy(RoleName=role_name, PolicyArn=aws_policies[policy]['Arn'])\n                        auditlog(\n                            event='iam.check_roles.attach_role_policy',\n                            actor=self.ns,\n                            data={\n                                'account': account.account_name,\n                                'roleName': role_name,\n                                'policyArn': aws_policies[policy]['Arn']\n                            }\n                        )\n\n            if extra_policies:\n                self.log.info('IAM Role {} on {} has the following extra policies applied: {}'.format(\n                    role_name,\n                    account.account_name,\n                    ', '.join(extra_policies)\n                ))\n\n                for policy in extra_policies:\n                    if policy in aws_policies:\n                        polArn = aws_policies[policy]['Arn']\n                    elif policy in self.aws_managed_policies:\n                        polArn = self.aws_managed_policies[policy]['Arn']\n                    else:\n                        polArn = None\n                        self.log.info('IAM Role {} on {} has an unknown policy attached: {}'.format(\n                            role_name,\n                            account.account_name,\n                            policy\n                        ))\n\n                    if self.manage_roles and polArn:\n                        iam.detach_role_policy(RoleName=role_name, PolicyArn=polArn)\n                        auditlog(\n                            event='iam.check_roles.detach_role_policy',\n                            actor=self.ns,\n                            data={\n                                'account': account.account_name,\n                                'roleName': role_name,\n                                'policyArn': polArn\n                            }\n                        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_policies_from_git(self):\n        fldr = mkdtemp()\n        try:\n            url = 'https://{token}:x-oauth-basic@{server}/{repo}'.format(**{\n                'token': self.dbconfig.get('git_auth_token', self.ns),\n                'server': self.dbconfig.get('git_server', self.ns),\n                'repo': self.dbconfig.get('git_repo', self.ns)\n            })\n\n            policies = {'GLOBAL': {}}\n            if self.dbconfig.get('git_no_ssl_verify', self.ns, False):\n                os.environ['GIT_SSL_NO_VERIFY'] = '1'\n\n            repo = Repo.clone_from(url, fldr)\n            for obj in repo.head.commit.tree:\n                name, ext = os.path.splitext(obj.name)\n\n                # Read the standard policies\n                if ext == '.json':\n                    policies['GLOBAL'][name] = obj.data_stream.read()\n\n                # Read any account role specific policies\n                if name == 'roles' and obj.type == 'tree':\n                    for account in [x for x in obj.trees]:\n                        for role in [x for x in account.trees]:\n                            role_policies = {policy.name.replace('.json', ''): policy.data_stream.read() for policy in\n                                             role.blobs if\n                                             policy.name.endswith('.json')}\n\n                            if account.name in policies:\n                                if role.name in policies[account.name]:\n                                    policies[account.name][role.name] += role_policies\n                                else:\n                                    policies[account.name][role.name] = role_policies\n                            else:\n                                policies[account.name] = {\n                                    role.name: role_policies\n                                }\n\n            return policies\n        finally:\n            if os.path.exists(fldr) and os.path.isdir(fldr):\n                shutil.rmtree(fldr)", "response": "Retrieve all the roles and policies from the Git repo. Returns a dictionary containing all the roles and policies that are in the Git repo."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_policies_from_aws(client, scope='Local'):\n        done = False\n        marker = None\n        policies = []\n\n        while not done:\n            if marker:\n                response = client.list_policies(Marker=marker, Scope=scope)\n            else:\n                response = client.list_policies(Scope=scope)\n\n            policies += response['Policies']\n\n            if response['IsTruncated']:\n                marker = response['Marker']\n            else:\n                done = True\n\n        return policies", "response": "Returns a list of all the policies currently applied to an AWS Account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all the roles for an account.", "response": "def get_roles(client):\n        \"\"\"Returns a list of all the roles for an account. Returns a list containing all the roles for the account.\n\n        Args:\n            client (:obj:`boto3.session.Session`): A boto3 Session object\n\n        Returns:\n            :obj:`list` of `dict`\n        \"\"\"\n        done = False\n        marker = None\n        roles = []\n\n        while not done:\n            if marker:\n                response = client.list_roles(Marker=marker)\n            else:\n                response = client.list_roles()\n\n            roles += response['Roles']\n\n            if response['IsTruncated']:\n                marker = response['Marker']\n            else:\n                done = True\n\n        return roles"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new IAM policy.", "response": "def create_policy(self, account, client, document, name, arn=None):\n        \"\"\"Create a new IAM policy.\n\n        If the policy already exists, a new version will be added and if needed the oldest policy version not in use\n        will be removed. Returns a dictionary containing the policy or version information\n\n        Args:\n            account (:obj:`Account`): Account to create the policy on\n            client (:obj:`boto3.client`): A boto3 client object\n            document (`str`): Policy document\n            name (`str`): Name of the policy to create / update\n            arn (`str`): Optional ARN for the policy to update\n\n        Returns:\n            `dict`\n        \"\"\"\n        if not arn and not name:\n            raise ValueError('create_policy must be called with either arn or name in the argument list')\n\n        if arn:\n            response = client.list_policy_versions(PolicyArn=arn)\n\n            # If we're at the max of the 5 possible versions, remove the oldest version that is not\n            # the currently active policy\n            if len(response['Versions']) >= 5:\n                version = [x for x in sorted(\n                    response['Versions'],\n                    key=lambda k: k['CreateDate']\n                ) if not x['IsDefaultVersion']][0]\n\n                self.log.info('Deleting oldest IAM Policy version {}/{}'.format(arn, version['VersionId']))\n                client.delete_policy_version(PolicyArn=arn, VersionId=version['VersionId'])\n                auditlog(\n                    event='iam.check_roles.delete_policy_version',\n                    actor=self.ns,\n                    data={\n                        'account': account.account_name,\n                        'policyName': name,\n                        'policyArn': arn,\n                        'versionId': version['VersionId']\n                    }\n                )\n\n            res = client.create_policy_version(\n                PolicyArn=arn,\n                PolicyDocument=document,\n                SetAsDefault=True\n            )\n        else:\n            res = client.create_policy(\n                PolicyName=name,\n                PolicyDocument=document\n            )\n\n        auditlog(\n            event='iam.check_roles.create_policy',\n            actor=self.ns,\n            data={\n                'account': account.account_name,\n                'policyName': name,\n                'policyArn': arn\n            }\n        )\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a message to a subsystem.", "response": "def notify(self, subsystem, recipient, subject, body_html, body_text):\n        \"\"\"You can send messages either to channels and private groups by using the following formats\n\n        #channel-name\n        @username-direct-message\n\n        Args:\n            subsystem (`str`): Name of the subsystem originating the notification\n            recipient (`str`): Recipient\n            subject (`str`): Subject / title of the notification, not used for this notifier\n            body_html (`str)`: HTML formatted version of the message, not used for this notifier\n            body_text (`str`): Text formatted version of the message\n\n        Returns:\n            `None`\n        \"\"\"\n        if not re.match(self.validation, recipient, re.I):\n            raise ValueError('Invalid recipient provided')\n\n        if recipient.startswith('#'):\n            target_type = 'channel'\n\n        elif recipient.find('@') != -1:\n            target_type = 'user'\n\n        else:\n            self.log.error('Unknown contact type for Slack: {}'.format(recipient))\n            return\n\n        try:\n            self._send_message(\n                target_type=target_type,\n                target=recipient,\n                message=body_text,\n                title=subject\n            )\n        except SlackError as ex:\n            self.log.error('Failed sending message to {}: {}'.format(recipient, ex))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_message(contacts, message):\n        if type(contacts) == str:\n            contacts = [contacts]\n\n        recipients = list(set(contacts))\n\n        send_notification(\n            subsystem='UNKNOWN',\n            recipients=[NotificationContact('slack', x) for x in recipients],\n            subject=None,\n            body_html=message,\n            body_text=message\n        )", "response": "Sends a message to a list of contacts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the object with live data.", "response": "def update(self, data):\n        '''Updates object information with live data (if live data has\n        different values to stored object information). Changes will be\n        automatically applied, but not persisted in the database. Call\n        `db.session.add(elb)` manually to commit the changes to the DB.\n\n        Args:\n            # data (:obj:) AWS API Resource object fetched from AWS API\n            data (:dict:) Dict representing ELB data retrieved from ELB client\n\n        Returns:\n            True if there were any changes to the object, False otherwise\n        '''\n\n        updated = self.set_property('lb_name', data['LoadBalancerName'])\n        updated |= self.set_property('dns_name', data['DNSName'])\n        if 'CanonicalHostedZoneName' not in data:\n            data['CanonicalHostedZoneName'] = None\n        updated |= self.set_property(\n            'canonical_hosted_zone_name',\n            data['CanonicalHostedZoneName']\n        )\n        # Apparently you can get an ELB that doesn't have a parent VPC\n        if 'VPCId' in data:\n            updated |= self.set_property('vpc_id', data['VPCId'])\n        else:\n            updated |= self.set_property('vpc_id', 'None')\n\n        # Instances\n        # ELBs list instances as [{'InstanceId': <instance_id>}, ...] Sigh.\n        instances = [instance['InstanceId'] for instance in data['Instances']]\n        if sorted(instances) != sorted(self.get_property('instances')):\n            self.set_property('instances', instances)\n            updated = True\n\n        # Tags (not currently in use, but for future reference)\n        if 'Tags' not in data:\n            data['Tags'] = {}\n        tags = {x['Key']: x['Value'] for x in data['Tags'] or {}}\n        existing_tags = {x.key: x for x in self.tags}\n        # Check for updated or removed tags\n        for key in list(existing_tags.keys()):\n            if key not in tags:\n                updated |= self.delete_tag(key)\n\n        # Metrics\n        if 'Metrics' not in data:\n            data['Metrics'] = {}\n        updated |= self.set_property('metrics', data['Metrics'])\n\n        return updated"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _register_default_option(nsobj, opt):\n    item = ConfigItem.get(nsobj.namespace_prefix, opt.name)\n    if not item:\n        logger.info('Adding {} ({}) = {} to {}'.format(\n            opt.name,\n            opt.type,\n            opt.default_value,\n            nsobj.namespace_prefix\n        ))\n        item = ConfigItem()\n        item.namespace_prefix = nsobj.namespace_prefix\n        item.key = opt.name\n        item.value = opt.default_value\n        item.type = opt.type\n        item.description = opt.description\n        nsobj.config_items.append(item)\n    else:\n        if item.description != opt.description:\n            logger.info('Updating description of {} / {}'.format(item.namespace_prefix, item.key))\n            item.description = opt.description\n            db.session.add(item)", "response": "Register default ConfigOption value if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport all templates from disk into database and adds them to the database.", "response": "def _import_templates(force=False):\n    \"\"\"Import templates from disk into database\n\n    Reads all templates from disk and adds them to the database. By default, any template that has been modified by\n    the user will not be updated. This can however be changed by setting `force` to `True`, which causes all templates\n    to be imported regardless of status\n\n    Args:\n        force (`bool`): Force overwrite any templates with local changes made. Default: `False`\n\n    Returns:\n        `None`\n    \"\"\"\n    tmplpath = os.path.join(resource_filename('cloud_inquisitor', 'data'), 'templates')\n    disk_templates = {f: os.path.join(root, f) for root, directory, files in os.walk(tmplpath) for f in files}\n    db_templates = {tmpl.template_name: tmpl for tmpl in db.Template.find()}\n\n    for name, template_file in disk_templates.items():\n        with open(template_file, 'r') as f:\n            body = f.read()\n        disk_hash = get_hash(body)\n\n        if name not in db_templates:\n            template = Template()\n            template.template_name = name\n            template.template = body\n\n            db.session.add(template)\n            auditlog(\n                event='template.import',\n                actor='init',\n                data={\n                    'template_name': name,\n                    'template': body\n                }\n            )\n            logger.info('Imported template {}'.format(name))\n        else:\n            template = db_templates[name]\n            db_hash = get_hash(template.template)\n\n            if db_hash != disk_hash:\n                if force or not db_templates[name].is_modified:\n                    template.template = body\n\n                    db.session.add(template)\n                    auditlog(\n                        event='template.update',\n                        actor='init',\n                        data={\n                            'template_name': name,\n                            'template_diff': diff(template.template, body)\n                        }\n                    )\n                    logger.info('Updated template {}'.format(name))\n                else:\n                    logger.warning(\n                        'Updated template available for {}. Will not import as it would'\n                        ' overwrite user edited content and force is not enabled'.format(name)\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize():\n    global __initialized\n\n    if __initialized:\n        return\n\n    # Setup all the default base settings\n    try:\n        for data in DEFAULT_CONFIG_OPTIONS:\n            nsobj = _get_config_namespace(data['prefix'], data['name'], sort_order=data['sort_order'])\n            for opt in data['options']:\n                _register_default_option(nsobj, opt)\n            db.session.add(nsobj)\n\n        # Iterate over all of our plugins and setup their defaults\n        for ns, info in CINQ_PLUGINS.items():\n            if info['name'] == 'commands':\n                continue\n\n            for entry_point in info['plugins']:\n                _cls = entry_point.load()\n                if hasattr(_cls, 'ns'):\n                    ns_name = '{}: {}'.format(info['name'].capitalize(), _cls.name)\n                    if not isinstance(_cls.options, abstractproperty):\n                        nsobj = _get_config_namespace(_cls.ns, ns_name)\n                        if _cls.options:\n                            for opt in _cls.options:\n                                _register_default_option(nsobj, opt)\n\n                        db.session.add(nsobj)\n\n        # Create the default roles if they are missing and import any missing or updated templates,\n        # if they havent been modified by the user\n        _add_default_roles()\n        _import_templates()\n\n        db.session.commit()\n        dbconfig.reload_data()\n        __initialized = True\n    except ProgrammingError as ex:\n        if str(ex).find('1146') != -1:\n            logging.getLogger('cloud_inquisitor').error(\n                'Missing required tables, please make sure you run `cloud-inquisitor db upgrade`'\n            )", "response": "Initialize the application configuration adding any missing default configuration or roles"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef before_request():\n    if not request.path.startswith('/saml') and not request.path.startswith('/auth'):\n        # Validate the session has the items we need\n        if 'accounts' not in session:\n            logger.debug('Missing \\'accounts\\' from session object, sending user to login page')\n            return BaseView.make_unauth_response()\n\n        # Require the CSRF token to be present if we are performing a change action (add, delete or modify objects)\n        # but exclude the SAML endpoints from the CSRF check\n        if request.method in ('POST', 'PUT', 'DELETE',):\n            if session['csrf_token'] != request.headers.get('X-Csrf-Token'):\n                logger.info('CSRF Token is missing or incorrect, sending user to login page')\n                abort(403)", "response": "Checks to ensure that the session is valid and validates the users CSRF token is present"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef after_request(response):\n    response.headers.add('Access-Control-Allow-Origin', '*')\n    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')\n    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE')\n    return response", "response": "Modifies the response object prior to sending it to the client. Used to add CORS headers to the request\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a given authentication system with the framework. Returns True if the auth_system is registered otherwise False.", "response": "def register_auth_system(self, auth_system):\n        \"\"\"Register a given authentication system with the framework. Returns `True` if the `auth_system` is registered\n        as the active auth system, else `False`\n\n        Args:\n            auth_system (:obj:`BaseAuthPlugin`): A subclass of the `BaseAuthPlugin` class to register\n\n        Returns:\n            `bool`\n        \"\"\"\n        auth_system_settings = dbconfig.get('auth_system')\n\n        if auth_system.name not in auth_system_settings['available']:\n            auth_system_settings['available'].append(auth_system.name)\n            dbconfig.set('default', 'auth_system', DBCChoice(auth_system_settings))\n\n        if auth_system.name == auth_system_settings['enabled'][0]:\n            self.active_auth_system = auth_system\n            auth_system().bootstrap()\n            logger.debug('Registered {} as the active auth system'.format(auth_system.name))\n            return True\n\n        else:\n            logger.debug('Not trying to load the {} auth system as it is disabled by config'.format(auth_system.name))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_menu_item(self, items):\n        for itm in items:\n            if itm.group in self.menu_items:\n                # Only add the menu item if we don't already have it registered\n                if itm not in self.menu_items[itm.group]['items']:\n                    self.menu_items[itm.group]['items'].append(itm)\n            else:\n                logger.warning('Tried registering menu item to unknown group {}'.format(itm.group))", "response": "Registers a views menu items into the metadata for the application. Skips if the item is already present\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating all entry points for resource types and registers a resource_type_id to class mapping", "response": "def __register_types(self):\n        \"\"\"Iterates all entry points for resource types and registers a `resource_type_id` to class mapping\n\n        Returns:\n            `None`\n        \"\"\"\n        try:\n            for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.types']['plugins']:\n                cls = entry_point.load()\n                self.types[ResourceType.get(cls.resource_type).resource_type_id] = cls\n                logger.debug('Registered resource type {}'.format(cls.__name__))\n        except SQLAlchemyError as ex:\n            logger.warning('Failed loading type information: {}'.format(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all notifiers that can be used to provide metadata for the frontend", "response": "def __register_notifiers(self):\n        \"\"\"Lists all notifiers to be able to provide metadata for the frontend\n\n        Returns:\n            `list` of `dict`\n        \"\"\"\n        notifiers = {}\n        for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.notifiers']['plugins']:\n            cls = entry_point.load()\n            notifiers[cls.notifier_type] = cls.validation\n\n        return notifiers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_views(self, app):\n        self.add_resource(LoginRedirectView, '/auth/login')\n        self.add_resource(LogoutRedirectView, '/auth/logout')\n\n        for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.auth']['plugins']:\n            cls = entry_point.load()\n            app.available_auth_systems[cls.name] = cls\n\n            if app.register_auth_system(cls):\n                for vcls in cls.views:\n                    self.add_resource(vcls, *vcls.URLS)\n                    logger.debug('Registered auth system view {} for paths: {}'.format(\n                        cls.__name__,\n                        ', '.join(vcls.URLS)\n                    ))\n\n        if not app.active_auth_system:\n            logger.error('No auth systems active, please enable an auth system and then start the system again')\n            sys.exit(-1)\n\n        for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.views']['plugins']:\n            view = entry_point.load()\n            self.add_resource(view, *view.URLS)\n            app.register_menu_item(view.MENU_ITEMS)\n\n            logger.debug('Registered view {} for paths: {}'.format(view.__name__, ', '.join(view.URLS)))", "response": "Iterates all entry points for views and dynamically load and register the routes with Flask"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_axfr_records(self, server, domains):\n        zones = []\n        for zoneName in domains:\n            try:\n                zone = {\n                    'zone_id': get_resource_id('axfrz', zoneName),\n                    'name': zoneName,\n                    'source': 'AXFR',\n                    'comment': None,\n                    'tags': {},\n                    'records': []\n                }\n\n                z = dns_zone.from_xfr(query.xfr(server, zoneName))\n                rdata_fields = ('name', 'ttl', 'rdata')\n                for rr in [dict(zip(rdata_fields, x)) for x in z.iterate_rdatas()]:\n                    record_name = rr['name'].derelativize(z.origin).to_text()\n                    zone['records'].append(\n                    {\n                        'id': get_resource_id('axfrr', record_name, ['{}={}'.format(k, str(v)) for k, v in rr.items()]),\n                        'zone_id': zone['zone_id'],\n                        'name': record_name,\n                        'value': sorted([rr['rdata'].to_text()]),\n                        'type': type_to_text(rr['rdata'].rdtype)\n                    })\n\n                if len(zone['records']) > 0:\n                    zones.append(zone)\n\n            except Exception as ex:\n                self.log.exception('Failed fetching DNS zone information for {}: {}'.format(zoneName, ex))\n                raise\n\n        return zones", "response": "Returns a list of dicts containing the zones and their records obtained from the DNS server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cloudflare_records(self, *, account):\n        zones = []\n\n        for zobj in self.__cloudflare_list_zones(account=account):\n            try:\n                self.log.debug('Processing DNS zone CloudFlare/{}'.format(zobj['name']))\n                zone = {\n                    'zone_id': get_resource_id('cfz', zobj['name']),\n                    'name': zobj['name'],\n                    'source': 'CloudFlare',\n                    'comment': None,\n                    'tags': {},\n                    'records': []\n                }\n\n                for record in self.__cloudflare_list_zone_records(account=account, zoneID=zobj['id']):\n                    zone['records'].append({\n                        'id': get_resource_id('cfr', zobj['id'], ['{}={}'.format(k, v) for k, v in record.items()]),\n                        'zone_id': zone['zone_id'],\n                        'name': record['name'],\n                        'value': record['value'],\n                        'type': record['type']\n                    })\n\n                if len(zone['records']) > 0:\n                    zones.append(zone)\n            except CloudFlareError:\n                self.log.exception('Failed getting records for CloudFlare zone {}'.format(zobj['name']))\n\n        return zones", "response": "Returns a list of dicts containing the zones and their records obtained from the CloudFlare API"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __cloudflare_request(self, *, account, path, args=None):\n        if not args:\n            args = {}\n\n        if not self.cloudflare_initialized[account.account_id]:\n            self.cloudflare_session[account.account_id] = requests.Session()\n            self.cloudflare_session[account.account_id].headers.update({\n                'X-Auth-Email': account.email,\n                'X-Auth-Key': account.api_key,\n                'Content-Type': 'application/json'\n            })\n            self.cloudflare_initialized[account.account_id] = True\n\n        if 'per_page' not in args:\n            args['per_page'] = 100\n\n        response = self.cloudflare_session[account.account_id].get(account.endpoint + path, params=args)\n        if response.status_code != 200:\n            raise CloudFlareError('Request failed: {}'.format(response.text))\n\n        return response.json()", "response": "Helper function to interact with the CloudFlare API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __cloudflare_list_zone_records(self, *, account, zoneID, **kwargs):\n        done = False\n        records = {}\n        page = 1\n\n        while not done:\n            kwargs['page'] = page\n            response = self.__cloudflare_request(\n                account=account,\n                path='/zones/{}/dns_records'.format(zoneID),\n                args=kwargs\n            )\n            info = response['result_info']\n\n            # Check if we have received all records, and if not iterate over the result set\n            if 'total_pages' not in info or page >= info['total_pages']:\n                done = True\n            else:\n                page += 1\n\n            for record in response['result']:\n                if record['name'] in records:\n                    records[record['name']]['value'] = sorted(records[record['name']]['value'] + [record['content']])\n                else:\n                    records[record['name']] = {\n                        'name': record['name'],\n                        'value': sorted([record['content']]),\n                        'type': record['type']\n                    }\n\n        return list(records.values())", "response": "Helper function to list all records on a CloudFlare DNS Zone. Returns a dict containing the records and their information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, *args, **kwargs):\n        accounts = list(AWSAccount.get_all(include_disabled=False).values())\n\n        # S3 Bucket config\n        s3_acl = get_template('cloudtrail_s3_bucket_policy.json')\n        s3_bucket_name = self.dbconfig.get('bucket_name', self.ns)\n        s3_bucket_region = self.dbconfig.get('bucket_region', self.ns, 'us-west-2')\n        s3_bucket_account = AWSAccount.get(self.dbconfig.get('bucket_account', self.ns))\n        CloudTrail.create_s3_bucket(s3_bucket_name, s3_bucket_region, s3_bucket_account, s3_acl)\n\n        self.validate_sqs_policy(accounts)\n\n        for account in accounts:\n            ct = CloudTrail(account, s3_bucket_name, s3_bucket_region, self.log)\n            ct.run()", "response": "Entry point for the scheduler\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that the SQS policy allows all the accounts to write to the queue", "response": "def validate_sqs_policy(self, accounts):\n        \"\"\"Given a list of accounts, ensures that the SQS policy allows all the accounts to write to the queue\n\n        Args:\n            accounts (`list` of :obj:`Account`): List of accounts\n\n        Returns:\n            `None`\n        \"\"\"\n        sqs_queue_name = self.dbconfig.get('sqs_queue_name', self.ns)\n        sqs_queue_region = self.dbconfig.get('sqs_queue_region', self.ns)\n        sqs_account = AWSAccount.get(self.dbconfig.get('sqs_queue_account', self.ns))\n        session = get_aws_session(sqs_account)\n\n        sqs = session.client('sqs', region_name=sqs_queue_region)\n        sqs_queue_url = sqs.get_queue_url(QueueName=sqs_queue_name, QueueOwnerAWSAccountId=sqs_account.account_number)\n        sqs_attribs = sqs.get_queue_attributes(QueueUrl=sqs_queue_url['QueueUrl'], AttributeNames=['Policy'])\n\n        policy = json.loads(sqs_attribs['Attributes']['Policy'])\n\n        for account in accounts:\n            arn = 'arn:aws:sns:*:{}:{}'.format(account.account_number, sqs_queue_name)\n            if arn not in policy['Statement'][0]['Condition']['ForAnyValue:ArnEquals']['aws:SourceArn']:\n                self.log.warning('SQS policy is missing condition for ARN {}'.format(arn))\n                policy['Statement'][0]['Condition']['ForAnyValue:ArnEquals']['aws:SourceArn'].append(arn)\n\n        sqs.set_queue_attributes(QueueUrl=sqs_queue_url['QueueUrl'], Attributes={'Policy': json.dumps(policy)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        for aws_region in AWS_REGIONS:\n            self.log.debug('Checking trails for {}/{}'.format(\n                self.account.account_name,\n                aws_region\n            ))\n            ct = self.session.client('cloudtrail', region_name=aws_region)\n            trails = ct.describe_trails()\n\n            if len(trails['trailList']) == 0:\n                if aws_region == self.global_ct_region:\n                    self.create_cloudtrail(aws_region)\n            else:\n                for trail in trails['trailList']:\n                    if trail['Name'] in ('Default', self.trail_name):\n                        if not trail['IsMultiRegionTrail']:\n                            if trail['Name'] == self.trail_name and self.global_ct_region == aws_region:\n                                ct.update_trail(\n                                    Name=trail['Name'],\n                                    IncludeGlobalServiceEvents=True,\n                                    IsMultiRegionTrail=True\n                                )\n                                auditlog(\n                                    event='cloudtrail.update_trail',\n                                    actor=self.ns,\n                                    data={\n                                        'trailName': trail['Name'],\n                                        'account': self.account.account_name,\n                                        'region': aws_region,\n                                        'changes': [\n                                            {\n                                                'setting': 'IsMultiRegionTrail',\n                                                'oldValue': False,\n                                                'newValue': True\n                                            }\n                                        ]\n                                    }\n                                )\n                            else:\n                                ct.delete_trail(name=trail['Name'])\n                                auditlog(\n                                    event='cloudtrail.delete_trail',\n                                    actor=self.ns,\n                                    data={\n                                        'trailName': trail['Name'],\n                                        'account': self.account.account_name,\n                                        'region': aws_region,\n                                        'reason': 'Incorrect region, name or not multi-regional'\n                                    }\n                                )\n                        else:\n                            if trail['HomeRegion'] == aws_region:\n                                if self.global_ct_region != aws_region or trail['Name'] == 'Default':\n                                    ct.delete_trail(Name=trail['Name'])\n                                    auditlog(\n                                        event='cloudtrail.delete_trail',\n                                        actor=self.ns,\n                                        data={\n                                            'trailName': trail['Name'],\n                                            'account': self.account.account_name,\n                                            'region': aws_region,\n                                            'reason': 'Incorrect name or region for multi-region trail'\n                                        }\n                                    )\n\n            trails = ct.describe_trails()\n            for trail in trails['trailList']:\n                if trail['Name'] == self.trail_name and trail['HomeRegion'] == aws_region:\n                    self.validate_trail_settings(ct, aws_region, trail)", "response": "Configures and enables a CloudTrail trail and logging on a single AWS Account."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_trail_settings(self, ct, aws_region, trail):\n        self.log.debug('Validating trail {}/{}/{}'.format(\n            self.account.account_name,\n            aws_region,\n            trail['Name']\n        ))\n        status = ct.get_trail_status(Name=trail['Name'])\n        if not status['IsLogging']:\n            self.log.warning('Logging is disabled for {}/{}/{}'.format(\n                self.account.account_name,\n                aws_region,\n                trail['Name']\n            ))\n            self.start_logging(aws_region, trail['Name'])\n\n        if 'SnsTopicName' not in trail or not trail['SnsTopicName']:\n            self.log.warning('SNS Notifications not enabled for {}/{}/{}'.format(\n                self.account.account_name,\n                aws_region,\n                trail['Name']\n            ))\n            self.create_sns_topic(aws_region)\n            self.enable_sns_notification(aws_region, trail['Name'])\n\n        if not self.validate_sns_topic_subscription(aws_region):\n            self.log.warning(\n                'SNS Notification configured but not subscribed for {}/{}/{}'.format(\n                    self.account.account_name,\n                    aws_region,\n                    trail['Name']\n                )\n            )\n            self.subscribe_sns_topic_to_sqs(aws_region)\n\n        if trail['S3BucketName'] != self.bucket_name:\n            self.log.warning('CloudTrail is logging to an incorrect bucket for {}/{}/{}'.format(\n                self.account.account_name,\n                trail['S3BucketName'],\n                trail['Name']\n            ))\n            self.set_s3_bucket(aws_region, trail['Name'], self.bucket_name)\n\n        if not trail.get('S3KeyPrefix') or trail['S3KeyPrefix'] != self.account.account_name:\n            self.log.warning('Missing or incorrect S3KeyPrefix for {}/{}/{}'.format(\n                self.account.account_name,\n                aws_region,\n                trail['Name']\n            ))\n            self.set_s3_prefix(aws_region, trail['Name'])", "response": "Validates the global settings for the given global trail."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an SNS topic if needed. Returns the ARN if the created SNS topic is needed.", "response": "def create_sns_topic(self, region):\n        \"\"\"Creates an SNS topic if needed. Returns the ARN if the created SNS topic\n\n        Args:\n            region (str): Region name\n\n        Returns:\n            `str`\n        \"\"\"\n        sns = self.session.client('sns', region_name=region)\n\n        self.log.info('Creating SNS topic for {}/{}'.format(self.account, region))\n        # Create the topic\n        res = sns.create_topic(Name=self.topic_name)\n        arn = res['TopicArn']\n\n        # Allow CloudTrail to publish messages with a policy update\n        tmpl = get_template('cloudtrail_sns_policy.json')\n        policy = tmpl.render(region=region, account_id=self.account.account_number, topic_name=self.topic_name)\n        sns.set_topic_attributes(TopicArn=arn, AttributeName='Policy', AttributeValue=policy)\n\n        auditlog(\n            event='cloudtrail.create_sns_topic',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n\n        return arn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the SNS topic subscription to the SNS topic. Returns True if subscribed or False if not subscribed or False if not subscribed or not missing", "response": "def validate_sns_topic_subscription(self, region):\n        \"\"\"Validates SQS subscription to the SNS topic. Returns `True` if subscribed or `False` if not subscribed\n        or topic is missing\n\n        Args:\n            region (str): Name of AWS Region\n\n        Returns:\n            `bool`\n        \"\"\"\n        sns = self.session.client('sns', region_name=region)\n        arn = 'arn:aws:sns:{}:{}:{}'.format(region, self.account.account_number, self.topic_name)\n        try:\n            data = sns.list_subscriptions_by_topic(TopicArn=arn)\n        except ClientError as ex:\n            self.log.error('Failed to list subscriptions by topic in {} ({}): {}'.format(\n                self.account.account_name,\n                region,\n                ex\n            ))\n            return False\n\n        for sub in data['Subscriptions']:\n            if sub['Endpoint'] == self.sqs_queue:\n                if sub['SubscriptionArn'] == 'PendingConfirmation':\n                    self.log.warning('Subscription pending confirmation for {} in {}'.format(\n                        self.account.account_name,\n                        region\n                    ))\n                    return False\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subscribe_sns_topic_to_sqs(self, region):\n        sns = self.session.resource('sns', region_name=region)\n        topic = sns.Topic('arn:aws:sns:{}:{}:{}'.format(region, self.account.account_number, self.topic_name))\n\n        topic.subscribe(Protocol='sqs', Endpoint=self.sqs_queue)\n\n        auditlog(\n            event='cloudtrail.subscribe_sns_topic_to_sqs',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n\n        return topic.attributes['TopicArn']", "response": "Subscribe to the SNS topic. Returns the ARN of the SNS Topic subscribed\n                   Returns the ARN of the SNS Topic subscribed\n                   Returns the ARN of the SNS Topic subscribed\n                  "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new CloudTrail Trail in the specified region.", "response": "def create_cloudtrail(self, region):\n        \"\"\"Creates a new CloudTrail Trail\n\n        Args:\n            region (str): Name of the AWS region\n\n        Returns:\n            `None`\n        \"\"\"\n        ct = self.session.client('cloudtrail', region_name=region)\n\n        # Creating the sns topic for the trail prior to creation\n        self.create_sns_topic(region)\n\n        ct.create_trail(\n            Name=self.trail_name,\n            S3BucketName=self.bucket_name,\n            S3KeyPrefix=self.account.account_name,\n            IsMultiRegionTrail=True,\n            IncludeGlobalServiceEvents=True,\n            SnsTopicName=self.topic_name\n        )\n        self.subscribe_sns_topic_to_sqs(region)\n\n        auditlog(\n            event='cloudtrail.create_cloudtrail',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n        self.log.info('Created CloudTrail for {} in {} ({})'.format(self.account, region, self.bucket_name))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenabling SNS notifications for a CloudTrail Trail.", "response": "def enable_sns_notification(self, region, trailName):\n        \"\"\"Enable SNS notifications for a Trail\n\n        Args:\n            region (`str`): Name of the AWS region\n            trailName (`str`): Name of the CloudTrail Trail\n\n        Returns:\n            `None`\n        \"\"\"\n        ct = self.session.client('cloudtrail', region_name=region)\n        ct.update_trail(Name=trailName, SnsTopicName=self.topic_name)\n\n        auditlog(\n            event='cloudtrail.enable_sns_notification',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n        self.log.info('Enabled SNS notifications for trail {} in {}/{}'.format(\n            trailName,\n            self.account.account_name,\n            region\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning on logging for a CloudTrail Trail", "response": "def start_logging(self, region, name):\n        \"\"\"Turn on logging for a CloudTrail Trail\n\n        Args:\n            region (`str`): Name of the AWS region\n            name (`str`): Name of the CloudTrail Trail\n\n        Returns:\n            `None`\n        \"\"\"\n        ct = self.session.client('cloudtrail', region_name=region)\n        ct.start_logging(Name=name)\n\n        auditlog(\n            event='cloudtrail.start_logging',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n        self.log.info('Enabled logging for {} ({})'.format(name, region))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the S3 prefix for a CloudTrail Trail object.", "response": "def set_s3_prefix(self, region, name):\n        \"\"\"Sets the S3 prefix for a CloudTrail Trail\n\n        Args:\n            region (`str`): Name of the AWS region\n            name (`str`): Name of the CloudTrail Trail\n\n        Returns:\n            `None`\n        \"\"\"\n        ct = self.session.client('cloudtrail', region_name=region)\n        ct.update_trail(Name=name, S3KeyPrefix=self.account.account_name)\n\n        auditlog(\n            event='cloudtrail.set_s3_prefix',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n        self.log.info('Updated S3KeyPrefix to {0} for {0}/{1}'.format(\n            self.account.account_name,\n            region\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the S3 bucket location for the log files to deliver to the CloudTrail Trail bucket.", "response": "def set_s3_bucket(self, region, name, bucketName):\n        \"\"\"Sets the S3 bucket location for logfile delivery\n\n        Args:\n            region (`str`): Name of the AWS region\n            name (`str`): Name of the CloudTrail Trail\n            bucketName (`str`): Name of the S3 bucket to deliver log files to\n\n        Returns:\n            `None`\n        \"\"\"\n        ct = self.session.client('cloudtrail', region_name=region)\n        ct.update_trail(Name=name, S3BucketName=bucketName)\n\n        auditlog(\n            event='cloudtrail.set_s3_bucket',\n            actor=self.ns,\n            data={\n                'account': self.account.account_name,\n                'region': region\n            }\n        )\n        self.log.info('Updated S3BucketName to {} for {} in {}/{}'.format(\n            bucketName,\n            name,\n            self.account.account_name,\n            region\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_s3_bucket(cls, bucket_name, bucket_region, bucket_account, template):\n        s3 = get_aws_session(bucket_account).client('s3', region_name=bucket_region)\n\n        # Check to see if the bucket already exists and if we have access to it\n        try:\n            s3.head_bucket(Bucket=bucket_name)\n        except ClientError as ex:\n            status_code = ex.response['ResponseMetadata']['HTTPStatusCode']\n\n            # Bucket exists and we do not have access\n            if status_code == 403:\n                raise Exception('Bucket {} already exists but we do not have access to it and so cannot continue'.format(\n                    bucket_name\n                ))\n\n            # Bucket does not exist, lets create one\n            elif status_code == 404:\n                try:\n                    s3.create_bucket(\n                        Bucket=bucket_name,\n                        CreateBucketConfiguration={\n                            'LocationConstraint': bucket_region\n                        }\n                    )\n\n                    auditlog(\n                        event='cloudtrail.create_s3_bucket',\n                        actor=cls.ns,\n                        data={\n                            'account': bucket_account.account_name,\n                            'bucket_region': bucket_region,\n                            'bucket_name': bucket_name\n                        }\n                    )\n                except Exception:\n                    raise Exception('An error occured while trying to create the bucket, cannot continue')\n\n        try:\n            bucket_acl = template.render(\n                bucket_name=bucket_name,\n                account_id=bucket_account.account_number\n            )\n            s3.put_bucket_policy(Bucket=bucket_name, Policy=bucket_acl)\n\n        except Exception as ex:\n            raise Warning('An error occurred while setting bucket policy: {}'.format(ex))", "response": "Creates the S3 bucket on the specified account and adds the bucket policy to the specified bucket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        # Loop through all accounts that are marked as enabled\n        accounts = list(AWSAccount.get_all(include_disabled=False).values())\n        for account in accounts:\n            self.log.debug('Updating VPC Flow Logs for {}'.format(account))\n\n            self.session = get_aws_session(account)\n            role_arn = self.confirm_iam_role(account)\n            # region specific\n            for aws_region in AWS_REGIONS:\n                try:\n                    vpc_list = VPC.get_all(account, aws_region).values()\n                    need_vpc_flow_logs = [x for x in vpc_list if x.vpc_flow_logs_status != 'ACTIVE']\n\n                    for vpc in need_vpc_flow_logs:\n                        if self.confirm_cw_log(account, aws_region, vpc.id):\n                            self.create_vpc_flow_logs(account, aws_region, vpc.id, role_arn)\n                        else:\n                            self.log.info('Failed to confirm log group for {}/{}'.format(\n                                account,\n                                aws_region\n                            ))\n\n                except Exception:\n                    self.log.exception('Failed processing VPCs for {}/{}.'.format(\n                        account,\n                        aws_region\n                    ))\n\n            db.session.commit()", "response": "Main entry point for the auditor worker."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the ARN of the IAM Role on the provided account as a string.", "response": "def confirm_iam_role(self, account):\n        \"\"\"Return the ARN of the IAM Role on the provided account as a string. Returns an `IAMRole` object from boto3\n\n        Args:\n            account (:obj:`Account`): Account where to locate the role\n\n        Returns:\n            :obj:`IAMRole`\n        \"\"\"\n        try:\n            iam = self.session.client('iam')\n            rolearn = iam.get_role(RoleName=self.role_name)['Role']['Arn']\n            return rolearn\n\n        except ClientError as e:\n            if e.response['Error']['Code'] == 'NoSuchEntity':\n                self.create_iam_role(account)\n            else:\n                raise\n\n        except Exception as e:\n            self.log.exception('Failed validating IAM role for VPC Flow Log Auditing for {}'.format(e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new IAM role. Returns the ARN of the newly created role.", "response": "def create_iam_role(self, account):\n        \"\"\"Create a new IAM role. Returns the ARN of the newly created role\n\n        Args:\n            account (:obj:`Account`): Account where to create the IAM role\n\n        Returns:\n            `str`\n        \"\"\"\n        try:\n            iam = self.session.client('iam')\n            trust = get_template('vpc_flow_logs_iam_role_trust.json').render()\n            policy = get_template('vpc_flow_logs_role_policy.json').render()\n\n            newrole = iam.create_role(\n                Path='/',\n                RoleName=self.role_name,\n                AssumeRolePolicyDocument=trust\n            )['Role']['Arn']\n\n            # Attach an inline policy to the role to avoid conflicts or hitting the Managed Policy Limit\n            iam.put_role_policy(\n                RoleName=self.role_name,\n                PolicyName='VpcFlowPolicy',\n                PolicyDocument=policy\n            )\n\n            self.log.debug('Created VPC Flow Logs role & policy for {}'.format(account.account_name))\n            auditlog(\n                event='vpc_flow_logs.create_iam_role',\n                actor=self.ns,\n                data={\n                    'account': account.account_name,\n                    'roleName': self.role_name,\n                    'trustRelationship': trust,\n                    'inlinePolicy': policy\n                }\n            )\n            return newrole\n\n        except Exception:\n            self.log.exception('Failed creating the VPC Flow Logs role for {}.'.format(account))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new VPC Flow log group for a given VPC.", "response": "def create_vpc_flow_logs(self, account, region, vpc_id, iam_role_arn):\n        \"\"\"Create a new VPC Flow log\n\n        Args:\n            account (:obj:`Account`): Account to create the flow in\n            region (`str`): Region to create the flow in\n            vpc_id (`str`): ID of the VPC to create the flow for\n            iam_role_arn (`str`): ARN of the IAM role used to post logs to the log group\n\n        Returns:\n            `None`\n        \"\"\"\n        try:\n            flow = self.session.client('ec2', region)\n            flow.create_flow_logs(\n                ResourceIds=[vpc_id],\n                ResourceType='VPC',\n                TrafficType='ALL',\n                LogGroupName=vpc_id,\n                DeliverLogsPermissionArn=iam_role_arn\n            )\n            fvpc = VPC.get(vpc_id)\n            fvpc.set_property('vpc_flow_logs_status', 'ACTIVE')\n\n            self.log.info('Enabled VPC Logging {}/{}/{}'.format(account, region, vpc_id))\n            auditlog(\n                event='vpc_flow_logs.create_vpc_flow',\n                actor=self.ns,\n                data={\n                    'account': account.account_name,\n                    'region': region,\n                    'vpcId': vpc_id,\n                    'arn': iam_role_arn\n                }\n            )\n        except Exception:\n            self.log.exception('Failed creating VPC Flow Logs for {}/{}/{}.'.format(\n                account,\n                region,\n                vpc_id\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_contacts(self, issue):\n        # If the resources has been deleted, just return an empty list, to trigger issue deletion without notification\n        if not issue.resource:\n            return []\n\n        account_contacts = issue.resource.account.contacts\n        try:\n            resource_owners = issue.resource.get_owner_emails()\n            # Double check get_owner_emails for it's return value\n            if type(resource_owners) is list:\n                for resource_owner in resource_owners:\n                    account_contacts.append({'type': 'email', 'value': resource_owner})\n        except AttributeError:\n            pass\n        return account_contacts", "response": "Returns a list of contacts for an issue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of actions to executed", "response": "def get_actions(self, issues):\n        \"\"\"Returns a list of actions to executed\n\n        Args:\n            issues (`list` of :obj:`RequiredTagsIssue`): List of issues\n\n        Returns:\n            `list` of `dict`\n        \"\"\"\n        actions = []\n        try:\n            for issue in issues:\n                action_item = self.determine_action(issue)\n                if action_item['action'] != AuditActions.IGNORE:\n                    action_item['owners'] = self.get_contacts(issue)\n                    actions.append(action_item)\n        finally:\n            db.session.rollback()\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if we need to trigger an alert in the schedule.", "response": "def determine_alert(self, action_schedule, issue_creation_time, last_alert):\n        \"\"\"Determine if we need to trigger an alert\n\n        Args:\n            action_schedule (`list`): A list contains the alert schedule\n            issue_creation_time (`int`): Time we create the issue\n            last_alert (`str`): Time we sent the last alert\n\n        Returns:\n            (`None` or `str`)\n            None if no alert should be sent. Otherwise return the alert we should send\n        \"\"\"\n        issue_age = time.time() - issue_creation_time\n        alert_schedule_lookup = {pytimeparse.parse(action_time): action_time for action_time in action_schedule}\n        alert_schedule = sorted(alert_schedule_lookup.keys())\n        last_alert_time = pytimeparse.parse(last_alert)\n\n        for alert_time in alert_schedule:\n            if last_alert_time < alert_time <= issue_age and last_alert_time != alert_time:\n                return alert_schedule_lookup[alert_time]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the action we should take for the issue", "response": "def determine_action(self, issue):\n        \"\"\"Determine the action we should take for the issue\n\n        Args:\n            issue: Issue to determine action for\n\n        Returns:\n             `dict`\n        \"\"\"\n        resource_type = self.resource_types[issue.resource.resource_type_id]\n        issue_alert_schedule = self.alert_schedule[resource_type] if \\\n            resource_type in self.alert_schedule \\\n            else self.alert_schedule['*']\n\n        action_item = {\n            'action': None,\n            'action_description': None,\n            'last_alert': issue.last_alert,\n            'issue': issue,\n            'resource': self.resource_classes[self.resource_types[issue.resource.resource_type_id]](issue.resource),\n            'owners': [],\n            'stop_after': issue_alert_schedule['stop'],\n            'remove_after': issue_alert_schedule['remove'],\n            'notes': issue.notes,\n            'missing_tags': issue.missing_tags\n        }\n\n        time_elapsed = time.time() - issue.created\n        stop_schedule = pytimeparse.parse(issue_alert_schedule['stop'])\n        remove_schedule = pytimeparse.parse(issue_alert_schedule['remove'])\n\n        if self.collect_only:\n            action_item['action'] = AuditActions.IGNORE\n        elif remove_schedule and time_elapsed >= remove_schedule:\n            action_item['action'] = AuditActions.REMOVE\n            action_item['action_description'] = 'Resource removed'\n            action_item['last_alert'] = remove_schedule\n            if issue.update({'last_alert': remove_schedule}):\n                db.session.add(issue.issue)\n\n        elif stop_schedule and time_elapsed >= stop_schedule:\n            action_item['action'] = AuditActions.STOP\n            action_item['action_description'] = 'Resource stopped'\n            action_item['last_alert'] = stop_schedule\n            if issue.update({'last_alert': stop_schedule}):\n                db.session.add(issue.issue)\n\n        else:\n            alert_selection = self.determine_alert(\n                issue_alert_schedule['alert'],\n                issue.get_property('created').value,\n                issue.get_property('last_alert').value\n            )\n            if alert_selection:\n                action_item['action'] = AuditActions.ALERT\n                action_item['action_description'] = '{} alert'.format(alert_selection)\n                action_item['last_alert'] = alert_selection\n                if issue.update({'last_alert': alert_selection}):\n                    db.session.add(issue.issue)\n            else:\n                action_item['action'] = AuditActions.IGNORE\n\n        db.session.commit()\n        return action_item"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the actions we want to take and returns a list of notifications that can be sent to the server.", "response": "def process_actions(self, actions):\n        \"\"\"Process the actions we want to take\n\n        Args:\n            actions (`list`): List of actions we want to take\n\n        Returns:\n            `list` of notifications\n        \"\"\"\n        notices = {}\n        notification_contacts = {}\n        for action in actions:\n            resource = action['resource']\n            action_status = ActionStatus.SUCCEED\n\n            try:\n                if action['action'] == AuditActions.REMOVE:\n                    action_status = self.process_action(\n                        resource,\n                        AuditActions.REMOVE\n                    )\n                    if action_status == ActionStatus.SUCCEED:\n                        db.session.delete(action['issue'].issue)\n\n                elif action['action'] == AuditActions.STOP:\n                    action_status = self.process_action(\n                        resource,\n                        AuditActions.STOP\n                    )\n                    if action_status == ActionStatus.SUCCEED:\n                        action['issue'].update({\n                            'missing_tags': action['missing_tags'],\n                            'notes': action['notes'],\n                            'last_alert': action['last_alert'],\n                            'state': action['action']\n                        })\n\n                elif action['action'] == AuditActions.FIXED:\n                    db.session.delete(action['issue'].issue)\n\n                elif action['action'] == AuditActions.ALERT:\n                    action['issue'].update({\n                        'missing_tags': action['missing_tags'],\n                        'notes': action['notes'],\n                        'last_alert': action['last_alert'],\n                        'state': action['action']\n                    })\n\n                db.session.commit()\n\n                if action_status == ActionStatus.SUCCEED:\n                    for owner in [\n                        dict(t) for t in {tuple(d.items()) for d in (action['owners'] + self.permanent_emails)}\n                    ]:\n                        if owner['value'] not in notification_contacts:\n                            contact = NotificationContact(type=owner['type'], value=owner['value'])\n                            notification_contacts[owner['value']] = contact\n                            notices[contact] = {\n                                'fixed': [],\n                                'not_fixed': []\n                            }\n                        else:\n                            contact = notification_contacts[owner['value']]\n\n                        if action['action'] == AuditActions.FIXED:\n                            notices[contact]['fixed'].append(action)\n                        else:\n                            notices[contact]['not_fixed'].append(action)\n            except Exception as ex:\n                self.log.exception('Unexpected error while processing resource {}/{}/{}/{}'.format(\n                    action['resource'].account.account_name,\n                    action['resource'].id,\n                    action['resource'],\n                    ex\n                ))\n\n        return notices"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether a tag value is valid for a given tag.", "response": "def validate_tag(self, key, value):\n        \"\"\"Check whether a tag value is valid\n\n        Args:\n            key: A tag key\n            value: A tag value\n\n        Returns:\n            `(True or False)`\n            A boolean indicating whether or not the value is valid\n        \"\"\"\n        if key == 'owner':\n            return validate_email(value, self.partial_owner_match)\n        elif key == self.gdpr_tag:\n            return value in self.gdpr_tag_values\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether a resource is compliance with the required tags. Returns a tuple containing the list of missing tags and the list of notes that are not present in the resource.", "response": "def check_required_tags_compliance(self, resource):\n        \"\"\"Check whether a resource is compliance\n\n        Args:\n            resource: A single resource\n\n        Returns:\n            `(list, list)`\n            A tuple contains missing tags (if there were any) and notes\n        \"\"\"\n\n        missing_tags = []\n        notes = []\n        resource_tags = {tag.key.lower(): tag.value for tag in resource.tags}\n\n        # Do not audit this resource if it is not in the Account scope\n        if resource.resource_type in self.alert_schedule:\n            target_accounts = self.alert_schedule[resource.resource_type]['scope']\n        else:\n            target_accounts = self.alert_schedule['*']['scope']\n        if not (resource.account.account_name in target_accounts or '*' in target_accounts):\n            return missing_tags, notes\n\n        # Do not audit this resource if the ignore tag was set\n        if self.audit_ignore_tag.lower() in resource_tags:\n            return missing_tags, notes\n\n        required_tags = list(self.required_tags)\n\n        # Add GDPR tag to required tags if the account must be GDPR compliant\n        if self.gdpr_enabled and resource.account.account_name in self.gdpr_accounts:\n            required_tags.append(self.gdpr_tag)\n\n        '''\n        # Do not audit this resource if it is still in grace period\n        if (datetime.utcnow() - resource.resource_creation_date).total_seconds() // 3600 < self.grace_period:\n            return missing_tags, notes\n        '''\n\n        # Check if the resource is missing required tags or has invalid tag values\n        for key in [tag.lower() for tag in required_tags]:\n            if key not in resource_tags:\n                missing_tags.append(key)\n            elif not self.validate_tag(key, resource_tags[key]):\n                missing_tags.append(key)\n                notes.append('{} tag is not valid'.format(key))\n\n        return missing_tags, notes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notify(self, notices):\n        tmpl_html = get_template('required_tags_notice.html')\n        tmpl_text = get_template('required_tags_notice.txt')\n        for recipient, data in list(notices.items()):\n            body_html = tmpl_html.render(data=data)\n            body_text = tmpl_text.render(data=data)\n\n            send_notification(\n                subsystem=self.ns,\n                recipients=[recipient],\n                subject=self.email_subject,\n                body_html=body_html,\n                body_text=body_text\n            )", "response": "Send notifications to the recipients provided by the caller."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_one(cls, enforcement_id):\n\n        qry = db.Enforcements.filter(enforcement_id == Enforcements.enforcement_id)\n        return qry", "response": "Return the properties of any enforcement action"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all Enforcements for a given account.", "response": "def get_all(cls, account_id=None, location=None):\n        \"\"\" Return all Enforcements\n\n        args:\n            `account_id` : Unique Account Identifier\n            `location` : Region associated with the Resource\n\n        returns:\n            list of enforcement objects\n\n        \"\"\"\n        qry = db.Enforcements.filter()\n\n        if account_id:\n            qry = qry.filter(account_id == Enforcements.account_id)\n\n        if location:\n            qry = qry.join(Resource, Resource.location == location)\n\n        return qry"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(cls, account_id, resource_id, action, timestamp, metrics):\n\n        enforcement = Enforcements()\n        enforcement.account_id = account_id\n        enforcement.resource_id = resource_id\n        enforcement.action = action\n        enforcement.timestamp = timestamp\n        enforcement.metrics = metrics\n\n        try:\n            db.session.add(enforcement)\n\n        except SQLAlchemyError as e:\n            logging.error('Could not add enforcement entry to database. {}'.format(e))", "response": "Create an enforcement entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the issue type object for the given issue type. If no object is found a new one will be created in the database and returned.", "response": "def get(cls, issue_type):\n        \"\"\"Returns the IssueType object for `issue_type`. If no existing object was found, a new type will\n        be created in the database and returned\n\n        Args:\n            issue_type (str,int,IssueType): Issue type name, id or class\n\n        Returns:\n            :obj:`IssueType`\n        \"\"\"\n        if isinstance(issue_type, str):\n            obj = getattr(db, cls.__name__).find_one(cls.issue_type == issue_type)\n\n        elif isinstance(issue_type, int):\n            obj = getattr(db, cls.__name__).find_one(cls.issue_type_id == issue_type)\n\n        elif isinstance(issue_type, cls):\n            return issue_type\n\n        else:\n            obj = None\n\n        if not obj:\n            obj = cls()\n            obj.issue_type = issue_type\n\n            db.session.add(obj)\n            db.session.commit()\n            db.session.refresh(obj)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(issue_id, issue_type_id):\n        return db.Issue.find_one(\n            Issue.issue_id == issue_id,\n            Issue.issue_type_id == issue_type_id\n        )", "response": "Return issue by ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_data(self):\n        existing_issues = EBSVolumeAuditIssue.get_all()\n\n        volumes = self.get_unattached_volumes()\n        new_issues = self.process_new_issues(volumes, existing_issues)\n        fixed_issues = self.process_fixed_issues(volumes, existing_issues)\n\n        # region Process the data to be returned\n        output = defaultdict(list)\n        for acct, data in new_issues.items():\n            output[acct] += data\n        # endregion\n\n        # region Update the database with the changes pending\n        for issues in new_issues.values():\n            for issue in issues:\n                db.session.add(issue.issue)\n\n        for issue in fixed_issues:\n            db.session.delete(issue.issue)\n\n        db.session.commit()\n        # endregion\n\n        return output", "response": "Update the database with the current state and return a dict containing the new / updated and fixed\n        issues respectively keyed by the account object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a list of all volumes missing tags and not ignored. Returns a dict keyed by the issue_id with the value volume as the value", "response": "def get_unattached_volumes(self):\n        \"\"\"Build a list of all volumes missing tags and not ignored. Returns a `dict` keyed by the issue_id with the\n        volume as the value\n\n        Returns:\n            :obj:`dict` of `str`: `EBSVolume`\n        \"\"\"\n        volumes = {}\n        ignored_tags = dbconfig.get('ignore_tags', self.ns)\n        for volume in EBSVolume.get_all().values():\n            issue_id = get_resource_id('evai', volume.id)\n\n            if len(volume.attachments) == 0:\n                if len(list(filter(set(ignored_tags).__contains__, [tag.key for tag in volume.tags]))):\n                    continue\n\n                volumes[issue_id] = volume\n\n        return volumes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_new_issues(self, volumes, existing_issues):\n        new_issues = {}\n        for issue_id, volume in volumes.items():\n            state = EBSIssueState.DETECTED.value\n\n            if issue_id in existing_issues:\n                issue = existing_issues[issue_id]\n\n                data = {\n                    'state': state,\n                    'notes': issue.notes,\n                    'last_notice': issue.last_notice\n                }\n                if issue.update(data):\n                    new_issues.setdefault(issue.volume.account, []).append(issue)\n                    self.log.debug('Updated EBSVolumeAuditIssue {}'.format(\n                        issue_id\n                    ))\n\n            else:\n                properties = {\n                    'volume_id': volume.id,\n                    'account_id': volume.account_id,\n                    'location': volume.location,\n                    'state': state,\n                    'last_change': datetime.now(),\n                    'last_notice': None,\n                    'notes': []\n                }\n\n                issue = EBSVolumeAuditIssue.create(issue_id, properties=properties)\n                new_issues.setdefault(issue.volume.account, []).append(issue)\n\n        return new_issues", "response": "Takes a dict of existing volumes missing tags and a dict of existing issues and finds any new or updated EBSVolumeAuditIssue objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_fixed_issues(self, volumes, existing_issues):\n        fixed_issues = []\n        for issue_id, issue in list(existing_issues.items()):\n            if issue_id not in volumes:\n                fixed_issues.append(issue)\n\n        return fixed_issues", "response": "This method takes a list of volumes and existing issues and returns a list of fixed issues to be deleted"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends notifications to the users via the provided methods .", "response": "def notify(self, notices):\n        \"\"\"Send notifications to the users via. the provided methods\n\n        Args:\n            notices (:obj:`dict` of `str`: `dict`): List of the notifications to send\n\n        Returns:\n            `None`\n        \"\"\"\n        issues_html = get_template('unattached_ebs_volume.html')\n        issues_text = get_template('unattached_ebs_volume.txt')\n\n        for recipient, issues in list(notices.items()):\n            if issues:\n                message_html = issues_html.render(issues=issues)\n                message_text = issues_text.render(issues=issues)\n\n                send_notification(\n                    subsystem=self.name,\n                    recipients=[recipient],\n                    subject=self.subject,\n                    body_html=message_html,\n                    body_text=message_text\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_local_aws_session():\n    if not all((app_config.aws_api.access_key, app_config.aws_api.secret_key)):\n        return boto3.session.Session()\n    else:\n        # If we are not running on an EC2 instance, assume the instance role\n        # first, then assume the remote role\n        session_args = [app_config.aws_api.access_key, app_config.aws_api.secret_key]\n        if app_config.aws_api.session_token:\n            session_args.append(app_config.aws_api.session_token)\n\n        return boto3.session.Session(*session_args)", "response": "Returns a session for the local instance not for a remote account"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to create a boto3 Session based on the account passed in.", "response": "def get_aws_session(account):\n    \"\"\"Function to return a boto3 Session based on the account passed in the first argument.\n\n    Args:\n        account (:obj:`Account`): Account to create the session object for\n\n    Returns:\n        :obj:`boto3:boto3.session.Session`\n    \"\"\"\n    from cloud_inquisitor.config import dbconfig\n    from cloud_inquisitor.plugins.types.accounts import AWSAccount\n\n    if not isinstance(account, AWSAccount):\n        raise InquisitorError('Non AWSAccount passed to get_aws_session, got {}'.format(account.__class__.__name__))\n\n    # If no keys are on supplied for the account, use sts.assume_role instead\n    session = get_local_aws_session()\n    if session.get_credentials().method in ['iam-role', 'env', 'explicit']:\n        sts = session.client('sts')\n    else:\n        # If we are not running on an EC2 instance, assume the instance role\n        # first, then assume the remote role\n        temp_sts = session.client('sts')\n\n        audit_sts_role = temp_sts.assume_role(\n            RoleArn=app_config.aws_api.instance_role_arn,\n            RoleSessionName='inquisitor'\n        )\n        sts = boto3.session.Session(\n            audit_sts_role['Credentials']['AccessKeyId'],\n            audit_sts_role['Credentials']['SecretAccessKey'],\n            audit_sts_role['Credentials']['SessionToken']\n        ).client('sts')\n\n    role = sts.assume_role(\n        RoleArn='arn:aws:iam::{}:role/{}'.format(\n            account.account_number,\n            dbconfig.get('role_name', default='cinq_role')\n        ),\n        RoleSessionName='inquisitor'\n    )\n\n    sess = boto3.session.Session(\n        role['Credentials']['AccessKeyId'],\n        role['Credentials']['SecretAccessKey'],\n        role['Credentials']['SessionToken']\n    )\n\n    return sess"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a list of AWS regions from the AWS static data.", "response": "def get_aws_regions(*, force=False):\n    \"\"\"Load a list of AWS regions from the AWS static data.\n\n    Args:\n        force (`bool`): Force fetch list of regions even if we already have a cached version\n\n    Returns:\n        :obj:`list` of `str`\n    \"\"\"\n    from cloud_inquisitor.config import dbconfig\n    global __regions\n\n    if force or not __regions:\n        logger.debug('Loading list of AWS regions from static data')\n        data = requests.get('https://ip-ranges.amazonaws.com/ip-ranges.json').json()\n        rgx = re.compile(dbconfig.get('ignored_aws_regions_regexp', default='(^cn-|GLOBAL|-gov)'), re.I)\n        __regions = sorted(list({x['region'] for x in data['prefixes'] if not rgx.search(x['region'])}))\n\n    return __regions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning migrations in online mode.", "response": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    engine = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix='sqlalchemy.',\n        poolclass=pool.NullPool\n    )\n\n    connection = engine.connect()\n    context.configure(\n        connection=connection,\n        target_metadata=target_metadata,\n        compare_type=True\n    )\n\n    try:\n        with context.begin_transaction():\n            context.run_migrations()\n    finally:\n        connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post(self):\n        self.reqparse.add_argument('accountName', type=str, required=True)\n        self.reqparse.add_argument('accountType', type=str, required=True)\n        self.reqparse.add_argument('contacts', type=dict, required=True, action='append')\n        self.reqparse.add_argument('enabled', type=int, required=True, choices=(0, 1))\n        self.reqparse.add_argument('requiredGroups', type=str, action='append', default=())\n        self.reqparse.add_argument('properties', type=dict, required=True)\n        args = self.reqparse.parse_args()\n\n        account_class = get_plugin_by_name(PLUGIN_NAMESPACES['accounts'], args['accountType'])\n        if not account_class:\n            raise InquisitorError('Invalid account type: {}'.format(args['accountType']))\n\n        validate_contacts(args['contacts'])\n\n        for key in ('accountName', 'accountType', 'contacts', 'enabled'):\n            value = args[key]\n            if type(value) == str:\n                value = value.strip()\n\n            if type(value) in (int, tuple, list, str):\n                if not value:\n                    raise Exception('{} cannot be empty'.format(key.replace('_', ' ').title()))\n            else:\n                raise ValueError('Invalid type: {} for value {} for argument {}'.format(type(value), value, key))\n\n        class_properties = {from_camelcase(key): value for key, value in args['properties'].items()}\n        for prop in account_class.class_properties:\n            if prop['key'] not in class_properties:\n                raise InquisitorError('Missing required property {}'.format(prop))\n\n        acct = account_class.create(\n            account_name=args['accountName'],\n            contacts=args['contacts'],\n            enabled=args['enabled'],\n            required_roles=args['requiredGroups'],\n            properties=class_properties,\n            auto_commit=False\n        )\n        db.session.commit()\n\n        # Add the newly created account to the session so we can see it right away\n        session['accounts'].append(acct.account_id)\n        auditlog(event='account.create', actor=session['user'].username, data=args)\n\n        return self.make_response({'message': 'Account created', 'accountId': acct.account_id}, HTTP.CREATED)", "response": "Create a new account"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching a single account", "response": "def get(self, accountId):\n        \"\"\"Fetch a single account\"\"\"\n        account = BaseAccount.get(accountId)\n        if account:\n            return self.make_response({\n                'message': None,\n                'account': account.to_json(is_admin=True)\n            })\n        else:\n            return self.make_response({\n                'message': 'Unable to find account',\n                'account': None\n            }, HTTP.NOT_FOUND)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_s3buckets(self):\n        self.log.debug('Updating S3Buckets for {}'.format(self.account.account_name))\n        s3 = self.session.resource('s3')\n        s3c = self.session.client('s3')\n\n        try:\n            existing_buckets = S3Bucket.get_all(self.account)\n            buckets = {bucket.name: bucket for bucket in s3.buckets.all()}\n            for data in buckets.values():\n                # This section ensures that we handle non-existent or non-accessible sub-resources\n                try:\n                    bucket_region = s3c.get_bucket_location(Bucket=data.name)['LocationConstraint']\n                    if not bucket_region:\n                        bucket_region = 'us-east-1'\n\n                except ClientError as e:\n                    self.log.info('Could not get bucket location..bucket possibly removed / {}'.format(e))\n                    bucket_region = 'unavailable'\n\n                try:\n                    bucket_policy = data.Policy().policy\n\n                except ClientError as e:\n                    if e.response['Error']['Code'] == 'NoSuchBucketPolicy':\n                        bucket_policy = None\n                    else:\n                        self.log.info('There was a problem collecting bucket policy for bucket {} on account {}, {}'\n                                      .format(data.name, self.account, e.response))\n                        bucket_policy = 'cinq cannot poll'\n\n                try:\n                    website_enabled = 'Enabled' if data.Website().index_document else 'Disabled'\n\n                except ClientError as e:\n                    if e.response['Error']['Code'] == 'NoSuchWebsiteConfiguration':\n                        website_enabled = 'Disabled'\n                    else:\n                        self.log.info('There was a problem collecting website config for bucket {} on account {}'\n                                      .format(data.name, self.account))\n                        website_enabled = 'cinq cannot poll'\n\n                try:\n                    tags = {t['Key']: t['Value'] for t in data.Tagging().tag_set}\n\n                except ClientError:\n                    tags = {}\n\n                try:\n                    bucket_size = self._get_bucket_statistics(data.name, bucket_region, 'StandardStorage',\n                                                              'BucketSizeBytes', 3)\n\n                    bucket_obj_count = self._get_bucket_statistics(data.name, bucket_region, 'AllStorageTypes',\n                                                                   'NumberOfObjects', 3)\n\n                    metrics = {'size': bucket_size, 'object_count': bucket_obj_count}\n\n                except Exception as e:\n                    self.log.info('Could not retrieve bucket statistics / {}'.format(e))\n                    metrics = {'found': False}\n\n                properties = {\n                    'bucket_policy': bucket_policy,\n                    'creation_date': data.creation_date,\n                    'location': bucket_region,\n                    'website_enabled': website_enabled,\n                    'metrics': metrics,\n                    'tags': tags\n                }\n\n                if data.name in existing_buckets:\n                    bucket = existing_buckets[data.name]\n                    if bucket.update(data, properties):\n                        self.log.debug('Change detected for S3Bucket {}/{}'.format(\n                            self.account.account_name,\n                            bucket.id\n                        ))\n                        bucket.save()\n                else:\n                    # If a bucket has no tags, a boto3 error is thrown. We treat this as an empty tag set\n\n                    S3Bucket.create(\n                        data.name,\n                        account_id=self.account.account_id,\n                        properties=properties,\n                        location=bucket_region,\n                        tags=tags\n                    )\n                    self.log.debug('Added new S3Bucket {}/{}'.format(\n                        self.account.account_name,\n                        data.name\n                    ))\n            db.session.commit()\n\n            bk = set(list(buckets.keys()))\n            ebk = set(list(existing_buckets.keys()))\n\n            try:\n                for resource_id in ebk - bk:\n                    db.session.delete(existing_buckets[resource_id].resource)\n                    self.log.debug('Deleted S3Bucket {}/{}'.format(\n                        self.account.account_name,\n                        resource_id\n                    ))\n                db.session.commit()\n\n            except Exception as e:\n                self.log.error(\n                    'Could not update the current S3Bucket list for account {}/{}'.format(self.account.account_name, e))\n                db.session.rollback()\n\n        finally:\n            del s3, s3c", "response": "Updates the list of S3 Buckets for the account and returns the new list of S3 Buckets."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_cloudfront(self):\n        self.log.debug('Updating CloudFront distributions for {}'.format(self.account.account_name))\n        cfr = self.session.client('cloudfront')\n\n        try:\n            existing_dists = CloudFrontDist.get_all(self.account, None)\n            dists = []\n\n            # region Fetch information from API\n            # region Web distributions\n            done = False\n            marker = None\n            while not done:\n                if marker:\n                    response = cfr.list_distributions(Marker=marker)\n                else:\n                    response = cfr.list_distributions()\n\n                dl = response['DistributionList']\n                if dl['IsTruncated']:\n                    marker = dl['NextMarker']\n                else:\n                    done = True\n\n                if 'Items' in dl:\n                    for dist in dl['Items']:\n                        origins = []\n                        for origin in dist['Origins']['Items']:\n                            if 'S3OriginConfig' in origin:\n                                origins.append(\n                                    {\n                                        'type': 's3',\n                                        'source': origin['DomainName']\n                                    }\n                                )\n                            elif 'CustomOriginConfig' in origin:\n                                origins.append(\n                                    {\n                                        'type': 'custom-http',\n                                        'source': origin['DomainName']\n                                    }\n                                )\n\n                        data = {\n                            'arn': dist['ARN'],\n                            'name': dist['DomainName'],\n                            'origins': origins,\n                            'enabled': dist['Enabled'],\n                            'type': 'web',\n                            'tags': self.__get_distribution_tags(cfr, dist['ARN'])\n                        }\n                        dists.append(data)\n            # endregion\n\n            # region Streaming distributions\n            done = False\n            marker = None\n            while not done:\n                if marker:\n                    response = cfr.list_streaming_distributions(Marker=marker)\n                else:\n                    response = cfr.list_streaming_distributions()\n\n                dl = response['StreamingDistributionList']\n                if dl['IsTruncated']:\n                    marker = dl['NextMarker']\n                else:\n                    done = True\n\n                if 'Items' in dl:\n                    dists += [\n                        {\n                            'arn': x['ARN'],\n                            'name': x['DomainName'],\n                            'origins': [{'type': 's3', 'source': x['S3Origin']['DomainName']}],\n                            'enabled': x['Enabled'],\n                            'type': 'rtmp',\n                            'tags': self.__get_distribution_tags(cfr, x['ARN'])\n                        } for x in dl['Items']\n                    ]\n            # endregion\n            # endregion\n\n            for data in dists:\n                if data['arn'] in existing_dists:\n                    dist = existing_dists[data['arn']]\n                    if dist.update(data):\n                        self.log.debug('Updated CloudFrontDist {}/{}'.format(\n                            self.account.account_name,\n                            data['name']\n                        ))\n                        dist.save()\n\n                else:\n                    properties = {\n                        'domain_name': data['name'],\n                        'origins': data['origins'],\n                        'enabled': data['enabled'],\n                        'type': data['type']\n                    }\n\n                    CloudFrontDist.create(\n                        data['arn'],\n                        account_id=self.account.account_id,\n                        properties=properties,\n                        tags=data['tags']\n                    )\n\n                    self.log.debug('Added new CloudFrontDist {}/{}'.format(\n                        self.account.account_name,\n                        data['name']\n                    ))\n            db.session.commit()\n\n            dk = set(x['arn'] for x in dists)\n            edk = set(existing_dists.keys())\n\n            try:\n                for resource_id in edk - dk:\n                    db.session.delete(existing_dists[resource_id].resource)\n                    self.log.debug('Deleted CloudFrontDist {}/{}'.format(\n                        resource_id,\n                        self.account.account_name\n                    ))\n                db.session.commit()\n            except:\n                db.session.rollback()\n        finally:\n            del cfr", "response": "Updates the list of CloudFront Distributions for the account with the information from API."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the list of Route53 DNS Zones and their records for the account.", "response": "def update_route53(self):\n        \"\"\"Update list of Route53 DNS Zones and their records for the account\n\n        Returns:\n            `None`\n        \"\"\"\n        self.log.debug('Updating Route53 information for {}'.format(self.account))\n\n        # region Update zones\n        existing_zones = DNSZone.get_all(self.account)\n        zones = self.__fetch_route53_zones()\n        for resource_id, data in zones.items():\n            if resource_id in existing_zones:\n                zone = DNSZone.get(resource_id)\n                if zone.update(data):\n                    self.log.debug('Change detected for Route53 zone {}/{}'.format(\n                        self.account,\n                        zone.name\n                    ))\n                    zone.save()\n            else:\n                tags = data.pop('tags')\n                DNSZone.create(\n                    resource_id,\n                    account_id=self.account.account_id,\n                    properties=data,\n                    tags=tags\n                )\n\n                self.log.debug('Added Route53 zone {}/{}'.format(\n                    self.account,\n                    data['name']\n                ))\n\n        db.session.commit()\n\n        zk = set(zones.keys())\n        ezk = set(existing_zones.keys())\n\n        for resource_id in ezk - zk:\n            zone = existing_zones[resource_id]\n\n            db.session.delete(zone.resource)\n            self.log.debug('Deleted Route53 zone {}/{}'.format(\n                self.account.account_name,\n                zone.name.value\n            ))\n        db.session.commit()\n        # endregion\n\n        # region Update resource records\n        try:\n            for zone_id, zone in DNSZone.get_all(self.account).items():\n                existing_records = {rec.id: rec for rec in zone.records}\n                records = self.__fetch_route53_zone_records(zone.get_property('zone_id').value)\n\n                for data in records:\n                    if data['id'] in existing_records:\n                        record = existing_records[data['id']]\n                        if record.update(data):\n                            self.log.debug('Changed detected for DNSRecord {}/{}/{}'.format(\n                                self.account,\n                                zone.name,\n                                data['name']\n                            ))\n                            record.save()\n                    else:\n                        record = DNSRecord.create(\n                            data['id'],\n                            account_id=self.account.account_id,\n                            properties={k: v for k, v in data.items() if k != 'id'},\n                            tags={}\n                        )\n                        self.log.debug('Added new DNSRecord {}/{}/{}'.format(\n                            self.account,\n                            zone.name,\n                            data['name']\n                        ))\n                        zone.add_record(record)\n                db.session.commit()\n\n                rk = set(x['id'] for x in records)\n                erk = set(existing_records.keys())\n\n                for resource_id in erk - rk:\n                    record = existing_records[resource_id]\n                    zone.delete_record(record)\n                    self.log.debug('Deleted Route53 record {}/{}/{}'.format(\n                        self.account.account_name,\n                        zone_id,\n                        record.name\n                    ))\n                db.session.commit()\n        except:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __get_distribution_tags(self, client, arn):\n        return {\n            t['Key']: t['Value'] for t in client.list_tags_for_resource(\n            Resource=arn\n        )['Tags']['Items']\n        }", "response": "Returns a dict containing the tags for a CloudFront distribution with the given ARN"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __fetch_route53_zones(self):\n        done = False\n        marker = None\n        zones = {}\n        route53 = self.session.client('route53')\n\n        try:\n            while not done:\n                if marker:\n                    response = route53.list_hosted_zones(Marker=marker)\n                else:\n                    response = route53.list_hosted_zones()\n\n                if response['IsTruncated']:\n                    marker = response['NextMarker']\n                else:\n                    done = True\n\n                for zone_data in response['HostedZones']:\n                    zones[get_resource_id('r53z', zone_data['Id'])] = {\n                        'name': zone_data['Name'].rstrip('.'),\n                        'source': 'AWS/{}'.format(self.account),\n                        'comment': zone_data['Config']['Comment'] if 'Comment' in zone_data['Config'] else None,\n                        'zone_id': zone_data['Id'],\n                        'private_zone': zone_data['Config']['PrivateZone'],\n                        'tags': self.__fetch_route53_zone_tags(zone_data['Id'])\n                    }\n\n            return zones\n        finally:\n            del route53", "response": "Returns a list of all DNS zones hosted in Route53"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __fetch_route53_zone_records(self, zone_id):\n        route53 = self.session.client('route53')\n\n        done = False\n        nextName = nextType = None\n        records = {}\n\n        try:\n            while not done:\n                if nextName and nextType:\n                    response = route53.list_resource_record_sets(\n                        HostedZoneId=zone_id,\n                        StartRecordName=nextName,\n                        StartRecordType=nextType\n                    )\n                else:\n                    response = route53.list_resource_record_sets(HostedZoneId=zone_id)\n\n                if response['IsTruncated']:\n                    nextName = response['NextRecordName']\n                    nextType = response['NextRecordType']\n                else:\n                    done = True\n\n                if 'ResourceRecordSets' in response:\n                    for record in response['ResourceRecordSets']:\n                        # Cannot make this a list, due to a race-condition in the AWS api that might return the same\n                        # record more than once, so we use a dict instead to ensure that if we get duplicate records\n                        # we simply just overwrite the one already there with the same info.\n                        record_id = self._get_resource_hash(zone_id, record)\n                        if 'AliasTarget' in record:\n                            value = record['AliasTarget']['DNSName']\n                            records[record_id] = {\n                                'id': record_id,\n                                'name': record['Name'].rstrip('.'),\n                                'type': 'ALIAS',\n                                'ttl': 0,\n                                'value': [value]\n                            }\n                        else:\n                            value = [y['Value'] for y in record['ResourceRecords']]\n                            records[record_id] = {\n                                'id': record_id,\n                                'name': record['Name'].rstrip('.'),\n                                'type': record['Type'],\n                                'ttl': record['TTL'],\n                                'value': value\n                            }\n\n            return list(records.values())\n        finally:\n            del route53", "response": "Fetch all resource records for a specific Route53 zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __fetch_route53_zone_tags(self, zone_id):\n        route53 = self.session.client('route53')\n\n        try:\n            return {\n                tag['Key']: tag['Value'] for tag in\n                route53.list_tags_for_resource(\n                    ResourceType='hostedzone',\n                    ResourceId=zone_id.split('/')[-1]\n                )['ResourceTagSet']['Tags']\n            }\n        finally:\n            del route53", "response": "Returns a dict with the tags for the hosted zone."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the last ten digits of the sha256 hash of the combined arguments. Useful for generating unique tags.", "response": "def _get_resource_hash(zone_name, record):\n        \"\"\"Returns the last ten digits of the sha256 hash of the combined arguments. Useful for generating unique\n        resource IDs\n\n        Args:\n            zone_name (`str`): The name of the DNS Zone the record belongs to\n            record (`dict`): A record dict to generate the hash from\n\n        Returns:\n            `str`\n        \"\"\"\n        record_data = defaultdict(int, record)\n        if type(record_data['GeoLocation']) == dict:\n            record_data['GeoLocation'] = \":\".join([\"{}={}\".format(k, v) for k, v in record_data['GeoLocation'].items()])\n\n        args = [\n            zone_name,\n            record_data['Name'],\n            record_data['Type'],\n            record_data['Weight'],\n            record_data['Region'],\n            record_data['GeoLocation'],\n            record_data['Failover'],\n            record_data['HealthCheckId'],\n            record_data['TrafficPolicyInstanceId']\n        ]\n\n        return get_resource_id('r53r', args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns datapoints from cloudwatch for the specified bucket and the given statistic.", "response": "def _get_bucket_statistics(self, bucket_name, bucket_region, storage_type, statistic, days):\n        \"\"\" Returns datapoints from cloudwatch for bucket statistics.\n\n        Args:\n            bucket_name `(str)`: The name of the bucket\n            statistic `(str)`: The statistic you want to fetch from\n            days `(int)`: Sample period for the statistic\n\n        \"\"\"\n\n        cw = self.session.client('cloudwatch', region_name=bucket_region)\n\n        # gather cw stats\n\n        try:\n            obj_stats = cw.get_metric_statistics(\n                Namespace='AWS/S3',\n                MetricName=statistic,\n                Dimensions=[\n                    {\n                        'Name': 'StorageType',\n                        'Value': storage_type\n                    },\n                    {\n                        'Name': 'BucketName',\n                        'Value': bucket_name\n                    }\n                ],\n                Period=86400,\n                StartTime=datetime.utcnow() - timedelta(days=days),\n                EndTime=datetime.utcnow(),\n                Statistics=[\n                    'Average'\n                ]\n            )\n            stat_value = obj_stats['Datapoints'][0]['Average'] if obj_stats['Datapoints'] else 'NO_DATA'\n\n            return stat_value\n\n        except Exception as e:\n            self.log.error(\n                'Could not get bucket statistic for account {} / bucket {} / {}'.format(self.account.account_name,\n                                                                                        bucket_name, e))\n\n        finally:\n            del cw"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the ResourceType object for the given resource type. If no object with the given name exists a new type will be created in the database and returned.", "response": "def get(cls, resource_type):\n        \"\"\"Returns the ResourceType object for `resource_type`. If no existing object was found, a new type will\n        be created in the database and returned\n\n        Args:\n            resource_type (str): Resource type name\n\n        Returns:\n            :obj:`ResourceType`\n        \"\"\"\n        if isinstance(resource_type, str):\n            obj = getattr(db, cls.__name__).find_one(cls.resource_type == resource_type)\n\n        elif isinstance(resource_type, int):\n            obj = getattr(db, cls.__name__).find_one(cls.resource_type_id == resource_type)\n\n        elif isinstance(resource_type, cls):\n            return resource_type\n\n        else:\n            obj = None\n\n        if not obj:\n            obj = cls()\n            obj.resource_type = resource_type\n            db.session.add(obj)\n            db.session.commit()\n            db.session.refresh(obj)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the list of EC2 Instances for the account / region.", "response": "def update_instances(self):\n        \"\"\"Update list of EC2 Instances for the account / region\n\n        Returns:\n            `None`\n        \"\"\"\n        self.log.debug('Updating EC2Instances for {}/{}'.format(self.account.account_name, self.region))\n        ec2 = self.session.resource('ec2', region_name=self.region)\n\n        try:\n            existing_instances = EC2Instance.get_all(self.account, self.region)\n            instances = {}\n            api_instances = {x.id: x for x in ec2.instances.all()}\n\n            try:\n                for instance_id, data in api_instances.items():\n                    if data.instance_id in existing_instances:\n                        instance = existing_instances[instance_id]\n\n                        if data.state['Name'] not in ('terminated', 'shutting-down'):\n                            instances[instance_id] = instance\n\n                            # Add object to transaction if it changed\n                            if instance.update(data):\n                                self.log.debug('Updating info for instance {} in {}/{}'.format(\n                                    instance.resource.resource_id,\n                                    self.account.account_name,\n                                    self.region\n                                ))\n                                db.session.add(instance.resource)\n                    else:\n                        # New instance, if its not in state=terminated\n                        if data.state['Name'] in ('terminated', 'shutting-down'):\n                            continue\n\n                        tags = {tag['Key']: tag['Value'] for tag in data.tags or {}}\n                        properties = {\n                            'launch_date': to_utc_date(data.launch_time).isoformat(),\n                            'state': data.state['Name'],\n                            'instance_type': data.instance_type,\n                            'public_ip': getattr(data, 'public_ip_address', None),\n                            'public_dns': getattr(data, 'public_dns_address', None),\n                            'created': isoformat(datetime.now())\n                        }\n\n                        instance = EC2Instance.create(\n                            data.instance_id,\n                            account_id=self.account.account_id,\n                            location=self.region,\n                            properties=properties,\n                            tags=tags\n                        )\n\n                        instances[instance.resource.resource_id] = instance\n                        self.log.debug('Added new EC2Instance {}/{}/{}'.format(\n                            self.account.account_name,\n                            self.region,\n                            instance.resource.resource_id\n                        ))\n\n                # Check for deleted instances\n                ik = set(list(instances.keys()))\n                eik = set(list(existing_instances.keys()))\n\n                for instanceID in eik - ik:\n                    db.session.delete(existing_instances[instanceID].resource)\n                    self.log.debug('Deleted EC2Instance {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        instanceID\n                    ))\n\n                db.session.commit()\n            except:\n                db.session.rollback()\n                raise\n        finally:\n            del ec2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_amis(self):\n        self.log.debug('Updating AMIs for {}/{}'.format(self.account.account_name, self.region))\n        ec2 = self.session.resource('ec2', region_name=self.region)\n\n        try:\n            existing_images = AMI.get_all(self.account, self.region)\n            images = {x.id: x for x in ec2.images.filter(Owners=['self'])}\n\n            for data in list(images.values()):\n                if data.id in existing_images:\n                    ami = existing_images[data.id]\n                    if ami.update(data):\n                        self.log.debug('Changed detected for AMI {}/{}/{}'.format(\n                            self.account.account_name,\n                            self.region,\n                            ami.resource.resource_id\n                        ))\n                else:\n                    properties = {\n                        'architecture': data.architecture,\n                        'creation_date': parse_date(data.creation_date or '1970-01-01 00:00:00'),\n                        'description': data.description,\n                        'name': data.name,\n                        'platform': data.platform or 'Linux',\n                        'state': data.state,\n                    }\n                    tags = {tag['Key']: tag['Value'] for tag in data.tags or {}}\n\n                    AMI.create(\n                        data.id,\n                        account_id=self.account.account_id,\n                        location=self.region,\n                        properties=properties,\n                        tags=tags\n                    )\n\n                    self.log.debug('Added new AMI {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        data.id\n                    ))\n            db.session.commit()\n\n            # Check for deleted instances\n            ik = set(list(images.keys()))\n            eik = set(list(existing_images.keys()))\n\n            try:\n                for image_id in eik - ik:\n                    db.session.delete(existing_images[image_id].resource)\n                    self.log.debug('Deleted AMI {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        image_id,\n                    ))\n\n                db.session.commit()\n            except:\n                db.session.rollback()\n        finally:\n            del ec2", "response": "Updates the list of AMIs for the account / region."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_volumes(self):\n        self.log.debug('Updating EBSVolumes for {}/{}'.format(self.account.account_name, self.region))\n        ec2 = self.session.resource('ec2', region_name=self.region)\n\n        try:\n            existing_volumes = EBSVolume.get_all(self.account, self.region)\n            volumes = {x.id: x for x in ec2.volumes.all()}\n\n            for data in list(volumes.values()):\n                if data.id in existing_volumes:\n                    vol = existing_volumes[data.id]\n                    if vol.update(data):\n                        self.log.debug('Changed detected for EBSVolume {}/{}/{}'.format(\n                            self.account.account_name,\n                            self.region,\n                            vol.resource.resource_id\n                        ))\n\n                else:\n                    properties = {\n                        'create_time': data.create_time,\n                        'encrypted': data.encrypted,\n                        'iops': data.iops or 0,\n                        'kms_key_id': data.kms_key_id,\n                        'size': data.size,\n                        'state': data.state,\n                        'snapshot_id': data.snapshot_id,\n                        'volume_type': data.volume_type,\n                        'attachments': sorted([x['InstanceId'] for x in data.attachments])\n                    }\n                    tags = {t['Key']: t['Value'] for t in data.tags or {}}\n                    vol = EBSVolume.create(\n                        data.id,\n                        account_id=self.account.account_id,\n                        location=self.region,\n                        properties=properties,\n                        tags=tags\n                    )\n\n                    self.log.debug('Added new EBSVolume {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        vol.resource.resource_id\n                    ))\n            db.session.commit()\n\n            vk = set(list(volumes.keys()))\n            evk = set(list(existing_volumes.keys()))\n            try:\n                for volumeID in evk - vk:\n                    db.session.delete(existing_volumes[volumeID].resource)\n                    self.log.debug('Deleted EBSVolume {}/{}/{}'.format(\n                        volumeID,\n                        self.account.account_name,\n                        self.region\n                    ))\n\n                db.session.commit()\n            except:\n                self.log.exception('Failed removing deleted volumes')\n                db.session.rollback()\n        finally:\n            del ec2", "response": "Updates the list of EBS Volumes for the account / region."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_snapshots(self):\n        self.log.debug('Updating EBSSnapshots for {}/{}'.format(self.account.account_name, self.region))\n        ec2 = self.session.resource('ec2', region_name=self.region)\n\n        try:\n            existing_snapshots = EBSSnapshot.get_all(self.account, self.region)\n            snapshots = {x.id: x for x in ec2.snapshots.filter(OwnerIds=[self.account.account_number])}\n\n            for data in list(snapshots.values()):\n                if data.id in existing_snapshots:\n                    snapshot = existing_snapshots[data.id]\n                    if snapshot.update(data):\n                        self.log.debug('Change detected for EBSSnapshot {}/{}/{}'.format(\n                            self.account.account_name,\n                            self.region,\n                            snapshot.resource.resource_id\n                        ))\n\n                else:\n                    properties = {\n                        'create_time': data.start_time,\n                        'encrypted': data.encrypted,\n                        'kms_key_id': data.kms_key_id,\n                        'state': data.state,\n                        'state_message': data.state_message,\n                        'volume_id': data.volume_id,\n                        'volume_size': data.volume_size,\n                    }\n                    tags = {t['Key']: t['Value'] for t in data.tags or {}}\n\n                    snapshot = EBSSnapshot.create(\n                        data.id,\n                        account_id=self.account.account_id,\n                        location=self.region,\n                        properties=properties,\n                        tags=tags\n                    )\n\n                    self.log.debug('Added new EBSSnapshot {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        snapshot.resource.resource_id\n                    ))\n\n            db.session.commit()\n\n            vk = set(list(snapshots.keys()))\n            evk = set(list(existing_snapshots.keys()))\n            try:\n                for snapshotID in evk - vk:\n                    db.session.delete(existing_snapshots[snapshotID].resource)\n                    self.log.debug('Deleted EBSSnapshot {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        snapshotID\n                    ))\n\n                db.session.commit()\n            except:\n                self.log.exception('Failed removing deleted snapshots')\n                db.session.rollback()\n        finally:\n            del ec2", "response": "Update the list of EBS Snapshots for the account / region."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the list of ElasticBeanstalk environments for the account / region.", "response": "def update_beanstalks(self):\n        \"\"\"Update list of Elastic BeanStalks for the account / region\n\n        Returns:\n            `None`\n        \"\"\"\n        self.log.debug('Updating ElasticBeanStalk environments for {}/{}'.format(\n            self.account.account_name,\n            self.region\n        ))\n        ebclient = self.session.client('elasticbeanstalk', region_name=self.region)\n\n        try:\n            existing_beanstalks = BeanStalk.get_all(self.account, self.region)\n            beanstalks = {}\n            # region Fetch elastic beanstalks\n            for env in ebclient.describe_environments()['Environments']:\n                # Only get information for HTTP (non-worker) Beanstalks\n                if env['Tier']['Type'] == 'Standard':\n                    if 'CNAME' in env:\n                        beanstalks[env['EnvironmentId']] = {\n                            'id': env['EnvironmentId'],\n                            'environment_name': env['EnvironmentName'],\n                            'application_name': env['ApplicationName'],\n                            'cname': env['CNAME']\n                        }\n                    else:\n                        self.log.warning('Found a BeanStalk that does not have a CNAME: {} in {}/{}'.format(\n                            env['EnvironmentName'],\n                            self.account,\n                            self.region\n                        ))\n                else:\n                    self.log.debug('Skipping worker tier ElasticBeanstalk environment {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        env['EnvironmentName']\n                    ))\n            # endregion\n\n            try:\n                for data in beanstalks.values():\n                    if data['id'] in existing_beanstalks:\n                        beanstalk = existing_beanstalks[data['id']]\n                        if beanstalk.update(data):\n                            self.log.debug('Change detected for ElasticBeanStalk {}/{}/{}'.format(\n                                self.account.account_name,\n                                self.region,\n                                data['id']\n                            ))\n                    else:\n                        bid = data.pop('id')\n                        tags = {}\n                        BeanStalk.create(\n                            bid,\n                            account_id=self.account.account_id,\n                            location=self.region,\n                            properties=data,\n                            tags=tags\n                        )\n\n                        self.log.debug('Added new ElasticBeanStalk {}/{}/{}'.format(\n                            self.account.account_name,\n                            self.region,\n                            bid\n                        ))\n                db.session.commit()\n\n                bk = set(beanstalks.keys())\n                ebk = set(existing_beanstalks.keys())\n\n                for resource_id in ebk - bk:\n                    db.session.delete(existing_beanstalks[resource_id].resource)\n                    self.log.debug('Deleted ElasticBeanStalk {}/{}/{}'.format(\n                        self.account.account_name,\n                        self.region,\n                        resource_id\n                    ))\n                db.session.commit()\n            except:\n                db.session.rollback()\n\n            return beanstalks\n        finally:\n            del ebclient"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the list of VPCs for the account / region.", "response": "def update_vpcs(self):\n        \"\"\"Update list of VPCs for the account / region\n\n        Returns:\n            `None`\n        \"\"\"\n        self.log.debug('Updating VPCs for {}/{}'.format(\n            self.account.account_name,\n            self.region\n        ))\n\n        existing_vpcs = VPC.get_all(self.account, self.region)\n        try:\n            ec2 = self.session.resource('ec2', region_name=self.region)\n            ec2_client = self.session.client('ec2', region_name=self.region)\n            vpcs = {x.id: x for x in ec2.vpcs.all()}\n\n            for data in vpcs.values():\n                flow_logs = ec2_client.describe_flow_logs(\n                    Filters=[\n                        {\n                            'Name': 'resource-id',\n                            'Values': [data.vpc_id]\n                        }\n                    ]\n                ).get('FlowLogs')\n\n                tags = {t['Key']: t['Value'] for t in data.tags or {}}\n                properties = {\n                    'vpc_id': data.vpc_id,\n                    'cidr_v4': data.cidr_block,\n                    'is_default': data.is_default,\n                    'state': data.state,\n                    'vpc_flow_logs_status': flow_logs[0]['FlowLogStatus'] if flow_logs else 'UNDEFINED',\n                    'vpc_flow_logs_log_group': flow_logs[0]['LogGroupName'] if flow_logs else 'UNDEFINED',\n                    'tags': tags\n                }\n                if data.id in existing_vpcs:\n                    vpc = existing_vpcs[data.vpc_id]\n                    if vpc.update(data, properties):\n                        self.log.debug('Change detected for VPC {}/{}/{} '.format(data.vpc_id, self.region, properties))\n                else:\n                    VPC.create(\n                        data.id,\n                        account_id=self.account.account_id,\n                        location=self.region,\n                        properties=properties,\n                        tags=tags\n                    )\n            db.session.commit()\n\n            # Removal of VPCs\n            vk = set(vpcs.keys())\n            evk = set(existing_vpcs.keys())\n\n            for resource_id in evk - vk:\n                db.session.delete(existing_vpcs[resource_id].resource)\n                self.log.debug('Removed VPCs {}/{}/{}'.format(\n                    self.account.account_name,\n                    self.region,\n                    resource_id\n                ))\n            db.session.commit()\n\n        except Exception:\n            self.log.exception('There was a problem during VPC collection for {}/{}'.format(\n                self.account.account_name,\n                self.region\n            ))\n            db.session.rollback()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_elbs(self):\n        self.log.debug('Updating ELBs for {}/{}'.format(\n            self.account.account_name,\n            self.region\n        ))\n\n        # ELBs known to CINQ\n        elbs_from_db = ELB.get_all(self.account, self.region)\n        try:\n\n            # ELBs known to AWS\n            elb_client = self.session.client('elb', region_name=self.region)\n            load_balancer_instances = elb_client.describe_load_balancers()['LoadBalancerDescriptions']\n            elbs_from_api = {}\n            for load_balancer in load_balancer_instances:\n                key = '{}::{}'.format(self.region, load_balancer['LoadBalancerName'])\n                elbs_from_api[key] = load_balancer\n\n            # Process ELBs known to AWS\n            for elb_identifier in elbs_from_api:\n                data = elbs_from_api[elb_identifier]\n                # ELB already in DB?\n                if elb_identifier in elbs_from_db:\n                    elb = elbs_from_db[elb_identifier]\n                    if elb.update(data):\n                        self.log.info(\n                            'Updating info for ELB {} in {}/{}'.format(\n                                elb.resource.resource_id,\n                                self.account.account_name,\n                                self.region\n                            )\n                        )\n                        db.session.add(elb.resource)\n                else:\n                    # Not previously seen this ELB, so add it\n                    if 'Tags' in data:\n                        try:\n                            tags = {tag['Key']: tag['Value'] for tag in data['Tags']}\n                        except AttributeError:\n                            tags = {}\n                    else:\n                        tags = {}\n\n                    vpc_data = (data['VPCId'] if ('VPCId' in data and data['VPCId']) else 'no vpc')\n\n                    properties = {\n                        'lb_name': data['LoadBalancerName'],\n                        'dns_name': data['DNSName'],\n                        'instances': ' '.join(\n                            [instance['InstanceId'] for instance in data['Instances']]\n                        ),\n                        'num_instances': len(\n                            [instance['InstanceId'] for instance in data['Instances']]\n                        ),\n                        'vpc_id': vpc_data,\n                        'state': 'not_reported'\n                    }\n                    if 'CanonicalHostedZoneName' in data:\n                        properties['canonical_hosted_zone_name'] = data['CanonicalHostedZoneName']\n                    else:\n                        properties['canonical_hosted_zone_name'] = None\n\n                    # LoadBalancerName doesn't have to be unique across all regions\n                    # Use region::LoadBalancerName as resource_id\n                    resource_id = '{}::{}'.format(self.region, data['LoadBalancerName'])\n\n                    # All done, create\n                    elb = ELB.create(\n                        resource_id,\n                        account_id=self.account.account_id,\n                        location=self.region,\n                        properties=properties,\n                        tags=tags\n                    )\n\n                    # elbs[elb.resource.resource_id] = elb\n                    self.log.info(\n                        'Added new ELB {}/{}/{}'.format(\n                            self.account.account_name,\n                            self.region,\n                            elb.resource.resource_id\n                        )\n                    )\n\n            # Delete no longer existing ELBs\n            elb_keys_from_db = set(list(elbs_from_db.keys()))\n            self.log.debug('elb_keys_from_db =  %s', elb_keys_from_db)\n            elb_keys_from_api = set(list(elbs_from_api.keys()))\n            self.log.debug('elb_keys_from_api = %s', elb_keys_from_api)\n\n            for elb_identifier in elb_keys_from_db - elb_keys_from_api:\n                db.session.delete(elbs_from_db[elb_identifier].resource)\n                self.log.info('Deleted ELB {}/{}/{}'.format(\n                    self.account.account_name,\n                    self.region,\n                    elb_identifier\n                )\n                )\n            db.session.commit()\n\n\n        except:\n            self.log.exception('There was a problem during ELB collection for {}/{}'.format(\n                self.account.account_name,\n                self.region\n            ))\n            db.session.rollback()", "response": "Update list of ELBs for the account / region"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_rds_databases(self):\n        self.log.info('Updating RDS Databases for {} / {}'.format(\n            self.account, self.region\n        ))\n        # All RDS resources are polled via a Lambda collector in a central account\n        rds_collector_account = AWSAccount.get(self.rds_collector_account)\n        rds_session = get_aws_session(rds_collector_account)\n        # Existing RDS resources come from database\n        existing_rds_dbs = RDSInstance.get_all(self.account, self.region)\n\n        try:\n            # Special session pinned to a single account for Lambda invocation so we\n            # don't have to manage lambdas in every account & region\n            lambda_client = rds_session.client('lambda', region_name=self.rds_collector_region)\n\n            # The AWS Config Lambda will collect all the non-compliant resources for all regions\n            # within the account\n            input_payload = json.dumps({\"account_id\": self.account.account_number,\n                                        \"region\": self.region,\n                                        \"role\": self.rds_role,\n                                        \"config_rule_name\": self.rds_config_rule_name\n                                        }).encode('utf-8')\n            response = lambda_client.invoke(FunctionName=self.rds_function_name, InvocationType='RequestResponse',\n                                            Payload=input_payload\n                                            )\n            response_payload = json.loads(response['Payload'].read().decode('utf-8'))\n            if response_payload['success']:\n                rds_dbs = response_payload['data']\n                if rds_dbs:\n                    for db_instance in rds_dbs:\n                        tags = {t['Key']: t['Value'] for t in db_instance['tags'] or {}}\n                        properties = {\n                            'tags': tags,\n                            'metrics': None,\n                            'engine': db_instance['engine'],\n                            'creation_date': db_instance['creation_date']\n                        }\n                        if db_instance['resource_name'] in existing_rds_dbs:\n                            rds = existing_rds_dbs[db_instance['resource_name']]\n                            if rds.update(db_instance, properties):\n                                self.log.debug('Change detected for RDS instance {}/{} '\n                                               .format(db_instance['resource_name'], properties))\n                        else:\n                            RDSInstance.create(\n                                db_instance['resource_name'],\n                                account_id=self.account.account_id,\n                                location=db_instance['region'],\n                                properties=properties,\n                                tags=tags\n                            )\n                    # Removal of RDS instances\n                    rk = set()\n                    erk = set()\n                    for database in rds_dbs:\n                        rk.add(database['resource_name'])\n                    for existing in existing_rds_dbs.keys():\n                        erk.add(existing)\n\n                    for resource_id in erk - rk:\n                        db.session.delete(existing_rds_dbs[resource_id].resource)\n                        self.log.debug('Removed RDS instances {}/{}'.format(\n                            self.account.account_name,\n                            resource_id\n                        ))\n                    db.session.commit()\n\n            else:\n                self.log.error('RDS Lambda Execution Failed / {} / {} / {}'.\n                                format(self.account.account_name, self.region, response_payload))\n\n        except Exception as e:\n            self.log.exception('There was a problem during RDS collection for {}/{}/{}'.format(\n                self.account.account_name, self.region, e\n            ))\n            db.session.rollback()", "response": "Updates the list of RDS Databases for the account and region."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an account by ID and type", "response": "def get(account_id, account_type_id=None):\n        \"\"\"Return account by ID and type\n\n        Args:\n            account_id (`int`, `str`): Unique Account identifier\n            account_type_id (str): Type of account to get\n\n        Returns:\n            :obj:`Account`: Returns an Account object if found, else None\n        \"\"\"\n        if type(account_id) == str:\n            args = {'account_name': account_id}\n        else:\n            args = {'account_id': account_id}\n\n        if account_type_id:\n            args['account_type_id'] = account_type_id\n\n        return db.Account.find_one(**args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef user_has_access(self, user):\n        if ROLE_ADMIN in user.roles:\n            return True\n\n        # Non-admin users should only see active accounts\n        if self.enabled:\n            if not self.required_roles:\n                return True\n\n            for role in self.required_roles:\n                if role in user.roles:\n                    return True\n\n        return False", "response": "Check if a user has access to view information for the account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefresh the list of available collectors and auditors", "response": "def load_plugins(self):\n        \"\"\"Refresh the list of available collectors and auditors\n\n        Returns:\n            `None`\n        \"\"\"\n        for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.collectors']['plugins']:\n            cls = entry_point.load()\n            if cls.enabled():\n                self.log.debug('Collector loaded: {} in module {}'.format(cls.__name__, cls.__module__))\n                self.collectors.setdefault(cls.type, []).append(Worker(\n                    cls.name,\n                    cls.interval,\n                    {\n                        'name': entry_point.name,\n                        'module_name': entry_point.module_name,\n                        'attrs': entry_point.attrs\n                    }\n                ))\n            else:\n                self.log.debug('Collector disabled: {} in module {}'.format(cls.__name__, cls.__module__))\n\n        for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.auditors']['plugins']:\n            cls = entry_point.load()\n            if cls.enabled():\n                self.log.debug('Auditor loaded: {} in module {}'.format(cls.__name__, cls.__module__))\n                self.auditors.append(Worker(\n                    cls.name,\n                    cls.interval,\n                    {\n                        'name': entry_point.name,\n                        'module_name': entry_point.module_name,\n                        'attrs': entry_point.attrs\n                    }\n                ))\n            else:\n                self.log.debug('Auditor disabled: {} in module {}'.format(cls.__name__, cls.__module__))\n\n        collector_count = sum(len(x) for x in self.collectors.values())\n        auditor_count = len(self.auditors)\n\n        if collector_count + auditor_count == 0:\n            raise Exception('No auditors or collectors loaded, aborting scheduler')\n\n        self.log.info('Scheduler loaded {} collectors and {} auditors'.format(collector_count, auditor_count))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_scheduler_plugins(self):\n        if not self.scheduler_plugins:\n            for entry_point in CINQ_PLUGINS['cloud_inquisitor.plugins.schedulers']['plugins']:\n                cls = entry_point.load()\n                self.scheduler_plugins[cls.__name__] = cls\n                if cls.__name__ == self.active_scheduler:\n                    self.log.debug('Scheduler loaded: {} in module {}'.format(cls.__name__, cls.__module__))\n                else:\n                    self.log.debug('Scheduler disabled: {} in module {}'.format(cls.__name__, cls.__module__))", "response": "Refresh the list of available schedulers\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the scheduler. Returns: `None`", "response": "def run(self, **kwargs):\n        \"\"\"Execute the scheduler.\n\n        Returns:\n            `None`\n        \"\"\"\n        if not super().run(**kwargs):\n            return\n\n        if kwargs['list']:\n            self.log.info('--- List of Scheduler Modules ---')\n            for name, scheduler in list(self.scheduler_plugins.items()):\n                if self.active_scheduler == name:\n                    self.log.info('{} (active)'.format(name))\n                else:\n                    self.log.info(name)\n            self.log.info('--- End list of Scheduler Modules ---')\n            return\n\n        scheduler = self.scheduler_plugins[self.active_scheduler]()\n        scheduler.execute_scheduler()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the worker thread.", "response": "def run(self, **kwargs):\n        \"\"\"Execute the worker thread.\n\n        Returns:\n            `None`\n        \"\"\"\n        super().run(**kwargs)\n        scheduler = self.scheduler_plugins[self.active_scheduler]()\n\n        if not kwargs['no_daemon']:\n            self.log.info('Starting {} worker with {} threads checking for new messages every {} seconds'.format(\n                scheduler.name,\n                kwargs['threads'],\n                kwargs['delay']\n            ))\n\n            for i in range(kwargs['threads']):\n                thd = threading.Thread(\n                    target=self.execute_worker_thread,\n                    args=(scheduler.execute_worker, kwargs['delay'])\n                )\n                thd.start()\n        else:\n            self.log.info('Starting {} worker for a single non-daemon execution'.format(\n                scheduler.name\n            ))\n            scheduler.execute_worker()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new template", "response": "def post(self):\n        \"\"\"Create a new template\"\"\"\n        self.reqparse.add_argument('templateName', type=str, required=True)\n        self.reqparse.add_argument('template', type=str, required=True)\n        args = self.reqparse.parse_args()\n\n        template = db.Template.find_one(template_name=args['templateName'])\n        if template:\n            return self.make_response('Template already exists, update the existing template instead', HTTP.CONFLICT)\n\n        template = Template()\n        template.template_name = args['templateName']\n        template.template = args['template']\n\n        db.session.add(template)\n        db.session.commit()\n        auditlog(event='template.create', actor=session['user'].username, data=args)\n\n        return self.make_response('Template {} has been created'.format(template.template_name), HTTP.CREATED)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put(self):\n        try:\n            _import_templates(force=True)\n            return self.make_response('Imported templates')\n        except:\n            self.log.exception('Failed importing templates')\n            return self.make_response('Failed importing templates', HTTP.SERVER_ERROR)", "response": "Re - import all templates overwriting any local changes made"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, template_name):\n        template = db.Template.find_one(template_name=template_name)\n\n        if not template:\n            return self.make_response('No such template found', HTTP.NOT_FOUND)\n\n        return self.make_response({'template': template})", "response": "Get a specific template"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_action(resource, action, action_issuer='unknown'):\n    from cinq_collector_aws import AWSRegionCollector\n\n    func_action = action_mapper[resource.resource_type][action]\n    extra_info = {}\n    action_status = ActionStatus.UNKNOWN\n\n    if func_action:\n        if action_mapper[resource.resource_type]['service_name'] == 'lambda':\n            client = get_aws_session(\n                AWSAccount.get(dbconfig.get('rds_collector_account', AWSRegionCollector.ns, ''))\n            ).client(\n                'lambda',\n                dbconfig.get('rds_collector_region', AWSRegionCollector.ns, '')\n            )\n        else:\n            client = get_aws_session(AWSAccount(resource.account)).client(\n                action_mapper[resource.resource_type]['service_name'],\n                region_name=resource.location\n            )\n        try:\n            logger.info(f'Trying to {action} resource {resource.id} for account {resource.account.account_name} / region {resource.location}')\n            action_status, extra_info = func_action(client, resource)\n            Enforcement.create(resource.account.account_id, resource.id, action, datetime.now(), extra_info)\n        except Exception as ex:\n            action_status = ActionStatus.FAILED\n            logger.exception('Failed to apply action {} to {}: {}'.format(action, resource.id, ex))\n        finally:\n            auditlog(\n                event='{}.{}.{}.{}'.format(action_issuer, resource.resource_type, action, action_status),\n                actor=action_issuer,\n                data={\n                    'resource_id': resource.id,\n                    'account_name': resource.account.account_name,\n                    'location': resource.location,\n                    'info': extra_info\n                }\n            )\n            return action_status\n    else:\n        logger.error('Failed to apply action {} to {}: Not supported'.format(action, resource.id))\n        return ActionStatus.FAILED", "response": "Process an action for a resource and return the result of the action"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop_ec2_instance(client, resource):\n    instance = EC2Instance.get(resource.id)\n    if instance.state in ('stopped', 'terminated'):\n        return ActionStatus.IGNORED, {}\n\n    client.stop_instances(InstanceIds=[resource.id])\n    return ActionStatus.SUCCEED, {'instance_type': resource.instance_type, 'public_ip': resource.public_ip}", "response": "Stop an EC2 Instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef terminate_ec2_instance(client, resource):\n    # TODO: Implement disabling of TerminationProtection\n    instance = EC2Instance.get(resource.id)\n    if instance.state == 'terminated':\n        return ActionStatus.IGNORED, {}\n    client.terminate_instances(InstanceIds=[resource.id])\n    return ActionStatus.SUCCEED, {'instance_type': resource.instance_type, 'public_ip': resource.public_ip}", "response": "Terminate an EC2 Instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_s3_bucket(client, resource):\n\n    bucket_policy = {\n        'Version': '2012-10-17',\n        'Id': 'PutObjPolicy',\n        'Statement': [\n            {\n                'Sid': 'cinqDenyObjectUploads',\n                'Effect': 'Deny',\n                'Principal': '*',\n                'Action': ['s3:PutObject', 's3:GetObject'],\n                'Resource': 'arn:aws:s3:::{}/*'.format(resource.id)\n            }\n        ]\n    }\n\n    s3_removal_lifecycle_policy = {\n        'Rules': [\n            {'Status': 'Enabled',\n             'NoncurrentVersionExpiration': {u'NoncurrentDays': 1},\n             'Filter': {u'Prefix': ''},\n             'Expiration': {\n                 u'Date': datetime.utcnow().replace(\n                     hour=0, minute=0, second=0, microsecond=0\n                 ) + timedelta(days=dbconfig.get('lifecycle_expiration_days', NS_AUDITOR_REQUIRED_TAGS, 3))\n             },\n             'AbortIncompleteMultipartUpload': {u'DaysAfterInitiation': 3},\n             'ID': 'cloudInquisitor'}\n        ]\n    }\n\n    policy_exists = s3_removal_policy_exists(client, resource)\n    lifecycle_policy_exists = s3_removal_lifecycle_policy_exists(client, resource)\n    if policy_exists and lifecycle_policy_exists:\n        return ActionStatus.IGNORED, {}\n\n    if not policy_exists:\n        client.put_bucket_policy(Bucket=resource.id, Policy=json.dumps(bucket_policy))\n        logger.info('Added policy to prevent putObject in s3 bucket {} in {}'.format(\n            resource.id,\n            resource.account.account_name\n        ))\n\n    if not lifecycle_policy_exists:\n        # Grab S3 Metrics before lifecycle policies start removing objects\n\n        client.put_bucket_lifecycle_configuration(\n            Bucket=resource.id,\n            LifecycleConfiguration=s3_removal_lifecycle_policy\n        )\n        logger.info('Added policy to delete bucket contents in s3 bucket {} in {}'.format(\n            resource.id,\n            resource.account.account_name\n        ))\n\n    return ActionStatus.SUCCEED, resource.metrics()", "response": "Stop an S3 bucket"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes an S3 bucket", "response": "def delete_s3_bucket(client, resource):\n    \"\"\"Delete an S3 bucket\n\n    This function will try to delete an S3 bucket\n\n    Args:\n        client (:obj:`boto3.session.Session.client`): A boto3 client object\n        resource (:obj:`Resource`): The resource object to terminate\n\n    Returns:\n        `ActionStatus`\n    \"\"\"\n\n    if dbconfig.get('enable_delete_s3_buckets', NS_AUDITOR_REQUIRED_TAGS, False):\n        client.delete_bucket(Bucket=resource.id)\n    return ActionStatus.SUCCEED, resource.metrics()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the class object identified by resource_id.", "response": "def get(cls, resource_id):\n        \"\"\"Returns the class object identified by `resource_id`\n\n        Args:\n            resource_id (str): Unique EC2 Instance ID to load from database\n\n        Returns:\n            EC2 Instance object if found, else None\n        \"\"\"\n        res = Resource.get(resource_id)\n        return cls(res) if res else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new resource object with the properties and tags provided.", "response": "def create(cls, resource_id, *, account_id, properties=None, tags=None, location=None,\n               auto_add=True, auto_commit=False):\n        \"\"\"Creates a new Resource object with the properties and tags provided\n\n        Args:\n            resource_id (str): Unique identifier for the resource object\n            account_id (int): Account ID which owns the resource\n            properties (dict): Dictionary of properties for the resource object.\n            tags (dict): Key / value dictionary of tags. Values must be `str` types\n            location (str): Location of the resource, if applicable\n            auto_add (bool): Automatically add the new resource to the DB session. Default: True\n            auto_commit (bool): Automatically commit the change to the database. Default: False\n        \"\"\"\n        if cls.get(resource_id):\n            raise ResourceException('Resource {} already exists'.format(resource_id))\n\n        res = Resource()\n        res.resource_id = resource_id\n        res.account_id = account_id\n        res.location = location\n        res.resource_type_id = ResourceType.get(cls.resource_type).resource_type_id\n\n        if properties:\n            for name, value in properties.items():\n                prop = ResourceProperty()\n                prop.resource_id = res.resource_id\n                prop.name = name\n                prop.value = value.isoformat() if type(value) == datetime else value\n                res.properties.append(prop)\n                db.session.add(prop)\n\n        if tags:\n            for key, value in tags.items():\n                if type(value) != str:\n                    raise ValueError('Invalid object type for tag value: {}'.format(key))\n\n                tag = Tag()\n                tag.resource_id = resource_id\n                tag.key = key\n                tag.value = value\n                res.tags.append(tag)\n                db.session.add(tag)\n\n        if auto_add:\n            db.session.add(res)\n\n            if auto_commit:\n                db.session.commit()\n\n            return cls.get(res.resource_id)\n        else:\n            return cls(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all(cls, account=None, location=None, include_disabled=False):\n        qry = db.Resource.filter(\n            Resource.resource_type_id == ResourceType.get(cls.resource_type).resource_type_id\n        )\n\n        if account:\n            qry = qry.filter(Resource.account_id == account.account_id)\n\n        if not include_disabled:\n            qry = qry.join(Account, Resource.account_id == Account.account_id).filter(Account.enabled == 1)\n\n        if location:\n            qry = qry.filter(Resource.location == location)\n\n        return {res.resource_id: cls(res) for res in qry.all()}", "response": "Returns a list of all resources for a given account location and resource type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(cls, *, limit=100, page=1, accounts=None, locations=None, resources=None,\n               properties=None, include_disabled=False, return_query=False):\n        \"\"\"Search for resources based on the provided filters. If `return_query` a sub-class of `sqlalchemy.orm.Query`\n        is returned instead of the resource list.\n\n        Args:\n            limit (`int`): Number of results to return. Default: 100\n            page (`int`): Pagination offset for results. Default: 1\n            accounts (`list` of `int`): A list of account id's to limit the returned resources to\n            locations (`list` of `str`): A list of locations as strings to limit the search for\n            resources ('list' of `str`): A list of resource_ids\n            properties (`dict`): A `dict` containing property name and value pairs. Values can be either a str or a list\n            of strings, in which case a boolean OR search is performed on the values\n            include_disabled (`bool`): Include resources from disabled accounts. Default: False\n            return_query (`bool`): Returns the query object prior to adding the limit and offset functions. Allows for\n            sub-classes to amend the search feature with extra conditions. The calling function must handle pagination\n            on its own\n\n        Returns:\n            `list` of `Resource`, `sqlalchemy.orm.Query`\n        \"\"\"\n        qry = db.Resource.order_by(Resource.resource_id).filter(\n            Resource.resource_type_id == ResourceType.get(cls.resource_type).resource_type_id\n        )\n\n        if not include_disabled:\n            qry = qry.join(Account, Resource.account_id == Account.account_id).filter(Account.enabled == 1)\n\n        if session:\n            qry = qry.filter(Resource.account_id.in_(session['accounts']))\n\n        if accounts:\n            qry = qry.filter(Resource.account_id.in_([Account.get(acct).account_id for acct in accounts]))\n\n        if locations:\n            qry = qry.filter(Resource.location.in_(locations))\n\n        if resources:\n            qry = qry.filter(Resource.resource_id.in_(resources))\n\n        if properties:\n            for prop_name, value in properties.items():\n                alias = aliased(ResourceProperty)\n\n                qry = qry.join(alias, Resource.resource_id == alias.resource_id)\n\n                if type(value) == list:\n                    where_clause = []\n                    for item in value:\n                        where_clause.append(alias.value == item)\n\n                    qry = qry.filter(\n                        and_(\n                            alias.name == prop_name,\n                            or_(*where_clause)\n                        ).self_group()\n                    )\n                else:\n                    qry = qry.filter(\n                        and_(\n                            alias.name == prop_name,\n                            alias.value == value\n                        ).self_group()\n                    )\n\n        if return_query:\n            return qry\n\n        total = qry.count()\n        qry = qry.limit(limit)\n        qry = qry.offset((page - 1) * limit if page > 1 else 0)\n\n        return total, [cls(x) for x in qry.all()]", "response": "Search for resources based on the provided filters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of email addresses associated with the instance based on tags", "response": "def get_owner_emails(self, partial_owner_match=True):\n        \"\"\"Return a list of email addresses associated with the instance, based on tags\n\n        Returns:\n            List of email addresses if any, else None\n        \"\"\"\n        for tag in self.tags:\n            if tag.key.lower() == 'owner':\n                rgx = re.compile(RGX_EMAIL_VALIDATION_PATTERN, re.I)\n                if partial_owner_match:\n                    match = rgx.findall(tag.value)\n                    if match:\n                        return [NotificationContact('email', email) for email in match]\n                else:\n                    match = rgx.match(tag.value)\n                    if match:\n                        return [NotificationContact('email', email) for email in match.groups()]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a named property for a resource if available. Will raise an AttributeError if the property does not exist. Will raise an AttributeError if the property does not exist. Will raise an AttributeError if the property does not exist.", "response": "def get_property(self, name):\n        \"\"\"Return a named property for a resource, if available. Will raise an `AttributeError` if the property\n        does not exist\n\n        Args:\n            name (str): Name of the property to return\n\n        Returns:\n            `ResourceProperty`\n        \"\"\"\n        for prop in self.resource.properties:\n            if prop.name == name:\n                return prop\n\n        raise AttributeError(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_property(self, name, value, update_session=True):\n        if type(value) == datetime:\n            value = value.isoformat()\n        else:\n            value = value\n\n        try:\n            prop = self.get_property(name)\n            if prop.value == value:\n                return False\n\n            prop.value = value\n\n        except AttributeError:\n            prop = ResourceProperty()\n            prop.resource_id = self.id\n            prop.name = name\n            prop.value = value\n\n        if update_session:\n            db.session.add(prop)\n\n        return True", "response": "Create or update the value of a property. Returns True if the property was created or updated False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tag by key if found", "response": "def get_tag(self, key, *, case_sensitive=True):\n        \"\"\"Return a tag by key, if found\n\n        Args:\n            key (str): Name/key of the tag to locate\n            case_sensitive (bool): Should tag keys be treated case-sensitive (default: true)\n\n        Returns:\n            `Tag`,`None`\n        \"\"\"\n        key = key if case_sensitive else key.lower()\n        for tag in self.resource.tags:\n            if not case_sensitive:\n                if tag.key.lower() == key:\n                    return tag\n            elif key == tag.key:\n                return tag\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate or update the value of the tag with key to value. Returns True if the tag was created or updated False otherwise.", "response": "def set_tag(self, key, value, update_session=True):\n        \"\"\"Create or set the value of the tag with `key` to `value`. Returns `True` if the tag was created or updated or\n        `False` if there were no changes to be made.\n\n        Args:\n            key (str): Key of the tag\n            value (str): Value of the tag\n            update_session (bool): Automatically add the change to the SQLAlchemy session. Default: True\n\n        Returns:\n            `bool`\n        \"\"\"\n        existing_tags = {x.key: x for x in self.tags}\n        if key in existing_tags:\n            tag = existing_tags[key]\n\n            if tag.value == value:\n                return False\n\n            tag.value = value\n        else:\n            tag = Tag()\n            tag.resource_id = self.id\n            tag.key = key\n            tag.value = value\n            self.tags.append(tag)\n\n        if update_session:\n            db.session.add(tag)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a tag from a resource based on the tag key. Returns True if the tag was removed False otherwise.", "response": "def delete_tag(self, key, update_session=True):\n        \"\"\"Removes a tag from a resource based on the tag key. Returns `True` if the tag was removed or `False` if the\n        tag didn't exist\n\n        Args:\n            key (str): Key of the tag to delete\n            update_session (bool): Automatically add the change to the SQLAlchemy session. Default: True\n\n        Returns:\n\n        \"\"\"\n        existing_tags = {x.key: x for x in self.tags}\n        if key in existing_tags:\n            if update_session:\n                db.session.delete(existing_tags[key])\n\n            self.tags.remove(existing_tags[key])\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the resource to the database.", "response": "def save(self, *, auto_commit=False):\n        \"\"\"Save the resource to the database\n\n        Args:\n            auto_commit (bool): Automatically commit the transaction. Default: `False`\n\n        Returns:\n            `None`\n        \"\"\"\n        try:\n            db.session.add(self.resource)\n            if auto_commit:\n                db.session.commit()\n        except SQLAlchemyError as ex:\n            self.log.exception('Failed updating resource: {}'.format(ex))\n            db.session.rollback()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, *, auto_commit=False):\n        try:\n            db.session.delete(self.resource)\n            if auto_commit:\n                db.session.commit()\n        except SQLAlchemyError:\n            self.log.exception('Failed deleting resource: {}'.format(self.id))\n            db.session.rollback()", "response": "Removes a resource from the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dict representation of the resource including all properties and tags", "response": "def to_json(self):\n        \"\"\"Return a `dict` representation of the resource, including all properties and tags\n\n        Returns:\n            `dict`\n        \"\"\"\n        return {\n            'resourceType': self.resource.resource_type_id,\n            'resourceId': self.id,\n            'accountId': self.resource.account_id,\n            'account': self.account,\n            'location': self.resource.location,\n            'properties': {to_camelcase(prop.name): prop.value for prop in self.resource.properties},\n            'tags': [{'key': t.key, 'value': t.value} for t in self.resource.tags]\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of the volumes attached to the instance", "response": "def volumes(self):\n        \"\"\"Returns a list of the volumes attached to the instance\n\n        Returns:\n            `list` of `EBSVolume`\n        \"\"\"\n        return [\n            EBSVolume(res) for res in db.Resource.join(\n                ResourceProperty, Resource.resource_id == ResourceProperty.resource_id\n            ).filter(\n                Resource.resource_type_id == ResourceType.get('aws_ebs_volume').resource_type_id,\n                ResourceProperty.name == 'attachments',\n                func.JSON_CONTAINS(ResourceProperty.value, func.JSON_QUOTE(self.id))\n            ).all()\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, data):\n        # If the instance was terminated, remove it\n        if data.state['Name'] == 'terminated':\n            self.delete(auto_commit=False)\n            return True\n\n        updated = self.set_property('launch_date', to_utc_date(data.launch_time).isoformat())\n        updated |= self.set_property('state', data.state['Name'])\n        updated |= self.set_property('instance_type', data.instance_type)\n        updated |= self.set_property('public_ip', data.public_ip_address or None)\n        updated |= self.set_property('public_dns', data.public_dns_name or None)\n\n        tags = {x['Key']: x['Value'] for x in data.tags or {}}\n        existing_tags = {x.key: x for x in self.tags}\n\n        # Check for new tags\n        for key, value in list(tags.items()):\n            updated |= self.set_tag(key, value)\n\n        # Check for updated or removed tags\n        for key in list(existing_tags.keys()):\n            if key not in tags:\n                updated |= self.delete_tag(key)\n\n        return updated", "response": "Updates the object s properties based on live data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the name of an instance if existant else return the instance id", "response": "def get_name_or_instance_id(self, with_id=False):\n        \"\"\"Returns the name of an instance if existant, else return the instance id\n\n        Args:\n            with_id (bool): Include the instance ID even if the name is found (default: False)\n\n        Returns:\n            Name and/or instance ID of the instance object\n        \"\"\"\n        name = self.get_tag('Name', case_sensitive=False)\n        if name and len(name.value.strip()) > 0:\n            return '{0} ({1})'.format(name.value, self.id) if with_id else name.value\n\n        return self.id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_by_age(cls, *, limit=100, page=1, accounts=None, locations=None, age=720,\n                      properties=None, include_disabled=False):\n        \"\"\"Search for resources based on the provided filters\n\n        Args:\n            limit (`int`): Number of results to return. Default: 100\n            page (`int`): Pagination offset for results. Default: 1\n            accounts (`list` of `int`): A list of account id's to limit the returned resources to\n            locations (`list` of `str`): A list of locations as strings to limit the search for\n            age (`int`): Age of instances older than `age` days to return\n            properties (`dict`): A `dict` containing property name and value pairs. Values can be either a str or a list\n            of strings, in which case a boolean OR search is performed on the values\n            include_disabled (`bool`): Include resources from disabled accounts. Default: False\n\n        Returns:\n            `list` of `Resource`\n        \"\"\"\n        qry = cls.search(\n            limit=limit,\n            page=page,\n            accounts=accounts,\n            locations=locations,\n            properties=properties,\n            include_disabled=include_disabled,\n            return_query=True\n        )\n\n        age_alias = aliased(ResourceProperty)\n        qry = (\n            qry.join(age_alias, Resource.resource_id == age_alias.resource_id)\n                .filter(\n                age_alias.name == 'launch_date',\n                cast(func.JSON_UNQUOTE(age_alias.value), DATETIME) < datetime.now() - timedelta(days=age)\n            )\n        )\n\n        total = qry.count()\n        qry = qry.limit(limit)\n        qry = qry.offset((page - 1) * limit if page > 1 else 0)\n\n        return total, [cls(x) for x in qry.all()]", "response": "Search for resources based on the provided filters"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_json(self, with_volumes=True):\n        data = super().to_json()\n        if with_volumes:\n            data['volumes'] = [\n                {\n                    'volumeId': vol.id,\n                    'volumeType': vol.volume_type,\n                    'size': vol.size\n                } for vol in self.volumes\n            ]\n\n        return data", "response": "Augment the base to_json function adding information about volumes\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, data):\n        updated = self.set_property('description', data.description)\n        updated |= self.set_property('state', data.state)\n\n        tags = {x['Key']: x['Value'] for x in data.tags or {}}\n        existing_tags = {x.key: x for x in self.tags}\n\n        # Check for new tags\n        for key, value in list(tags.items()):\n            updated |= self.set_tag(key, value)\n\n        # Check for updated or removed tags\n        for key in list(existing_tags.keys()):\n            if key not in tags:\n                updated |= self.delete_tag(key)\n\n        return updated", "response": "Updates the object s properties based on live data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_record(self, record):\n        self.children.remove(record.resource)\n        record.delete()", "response": "Removes a DNSRecord from the set of children."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self):\n        namespaces = db.ConfigNamespace.order_by(\n            ConfigNamespace.sort_order,\n            ConfigNamespace.name\n        ).all()\n\n        return self.make_response({\n            'message': None,\n            'namespaces': namespaces\n        }, HTTP.OK)", "response": "List existing config namespaces and their items"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self):\n        self.reqparse.add_argument('namespacePrefix', type=str, required=True)\n        self.reqparse.add_argument('description', type=str, required=True)\n        self.reqparse.add_argument('key', type=str, required=True)\n        self.reqparse.add_argument('value', required=True)\n        self.reqparse.add_argument('type', type=str, required=True)\n        args = self.reqparse.parse_args()\n\n        if not self.dbconfig.namespace_exists(args['namespacePrefix']):\n            return self.make_response('The namespace doesnt exist', HTTP.NOT_FOUND)\n\n        if self.dbconfig.key_exists(args['namespacePrefix'], args['key']):\n            return self.make_response('This config item already exists', HTTP.CONFLICT)\n\n        self.dbconfig.set(args['namespacePrefix'], args['key'], _to_dbc_class(args), description=args['description'])\n        auditlog(event='configItem.create', actor=session['user'].username, data=args)\n\n        return self.make_response('Config item added', HTTP.CREATED)", "response": "Create a new config item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, namespace, key):\n        cfg = self.dbconfig.get(key, namespace, as_object=True)\n        return self.make_response({\n            'message': None,\n            'config': cfg\n        })", "response": "Get a specific configuration item"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a single configuration item", "response": "def put(self, namespace, key):\n        \"\"\"Update a single configuration item\"\"\"\n        args = request.json\n\n        if not self.dbconfig.key_exists(namespace, key):\n            return self.make_response('No such config entry: {}/{}'.format(namespace, key), HTTP.BAD_REQUEST)\n\n        if (args['type'] == 'choice' and\n                not args['value']['min_items'] <= len(args['value']['enabled']) <= args['value']['max_items']):\n            return self.make_response(\n                'You should select {} {}item{}'.format(\n                    args['value']['min_items'],\n                    '' if args['value']['min_items'] == args['value']['max_items'] else 'to {} '.format(\n                        args['value']['max_items']\n                    ),\n                    's' if args['value']['max_items'] > 1 else ''\n                ),\n                HTTP.BAD_REQUEST\n            )\n\n        if args['type'] == 'choice' and not set(args['value']['enabled']).issubset(args['value']['available']):\n            return self.make_response('Invalid item', HTTP.BAD_REQUEST)\n\n        item = db.ConfigItem.find_one(\n            ConfigItem.namespace_prefix == namespace, ConfigItem.key == key\n        )\n\n        if item.value != args['value']:\n            item.value = args['value']\n\n        if item.type != args['type']:\n            item.type = args['type']\n\n        if item.description != args['description']:\n            item.description = args['description']\n\n        self.dbconfig.set(namespace, key, _to_dbc_class(args))\n        auditlog(event='configItem.update', actor=session['user'].username, data=args)\n\n        return self.make_response('Config entry updated')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a specific configuration item", "response": "def delete(self, namespace, key):\n        \"\"\"Delete a specific configuration item\"\"\"\n        if not self.dbconfig.key_exists(namespace, key):\n            return self.make_response('No such config entry exists: {}/{}'.format(namespace, key), HTTP.BAD_REQUEST)\n\n        self.dbconfig.delete(namespace, key)\n        auditlog(event='configItem.delete', actor=session['user'].username, data={'namespace': namespace, 'key': key})\n        return self.make_response('Config entry deleted')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a specific configuration namespace", "response": "def get(self, namespacePrefix):\n        \"\"\"Get a specific configuration namespace\"\"\"\n        ns = db.ConfigNamespace.find_one(ConfigNamespace.namespace_prefix == namespacePrefix)\n        if not ns:\n            return self.make_response('No such namespace: {}'.format(namespacePrefix), HTTP.NOT_FOUND)\n\n        return self.make_response({\n            'message': None,\n            'namespace': ns\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, namespacePrefix):\n        self.reqparse.add_argument('name', type=str, required=True)\n        self.reqparse.add_argument('sortOrder', type=int, required=True)\n        args = self.reqparse.parse_args()\n\n        ns = db.ConfigNamespace.find_one(ConfigNamespace.namespace_prefix == namespacePrefix)\n        if not ns:\n            return self.make_response('No such namespace: {}'.format(namespacePrefix), HTTP.NOT_FOUND)\n\n        ns.name = args['name']\n        ns.sort_order = args['sortOrder']\n        db.session.add(ns)\n        db.session.commit()\n\n        self.dbconfig.reload_data()\n        auditlog(event='configNamespace.update', actor=session['user'].username, data=args)\n\n        return self.make_response('Namespace updated')", "response": "Update a specific configuration namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a specific configuration namespace", "response": "def delete(self, namespacePrefix):\n        \"\"\"Delete a specific configuration namespace\"\"\"\n        ns = db.ConfigNamespace.find_one(ConfigNamespace.namespace_prefix == namespacePrefix)\n        if not ns:\n            return self.make_response('No such namespace: {}'.format(namespacePrefix), HTTP.NOT_FOUND)\n\n        db.session.delete(ns)\n        db.session.commit()\n\n        self.dbconfig.reload_data()\n        auditlog(\n            event='configNamespace.delete',\n            actor=session['user'].username,\n            data={'namespacePrefix': namespacePrefix}\n        )\n        return self.make_response('Namespace deleted')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post(self):\n        self.reqparse.add_argument('namespacePrefix', type=str, required=True)\n        self.reqparse.add_argument('name', type=str, required=True)\n        self.reqparse.add_argument('sortOrder', type=int, required=True)\n        args = self.reqparse.parse_args()\n\n        if self.dbconfig.namespace_exists(args['namespacePrefix']):\n            return self.make_response('Namespace {} already exists'.format(args['namespacePrefix']), HTTP.CONFLICT)\n\n        ns = ConfigNamespace()\n\n        ns.namespace_prefix = args['namespacePrefix']\n        ns.name = args['name']\n        ns.sort_order = args['sortOrder']\n\n        db.session.add(ns)\n        db.session.commit()\n\n        self.dbconfig.reload_data()\n        auditlog(event='configNamespace.create', actor=session['user'].username, data=args)\n\n        return self.make_response('Namespace created', HTTP.CREATED)", "response": "Create a new configuration namespace"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_syslog_format(event_type):\n    syslog_format_template = get_template('syslog_format.json')\n    fmt = syslog_format_template.render(\n        event_type=event_type,\n        host=dbconfig.get('instance_name', default='local')\n    )\n\n    # Load and redump string, to get rid of any extraneous whitespaces\n    return json.dumps(json.loads(fmt))", "response": "Take an event type argument and return a python logging format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_logging():\n    config = json.load(open(os.path.join(config_path, 'logging.json')))\n\n    # If syslogging is disabled, set the pipeline handler to NullHandler\n    if dbconfig.get('enable_syslog_forwarding', NS_LOG, False):\n        try:\n            config['formatters']['syslog'] = {\n                'format': _get_syslog_format('cloud-inquisitor-logs')\n            }\n\n            config['handlers']['syslog'] = {\n                'class': 'cloud_inquisitor.log.SyslogPipelineHandler',\n                'formatter': 'syslog',\n                'filters': ['standard']\n            }\n\n            config['loggers']['cloud_inquisitor']['handlers'].append('syslog')\n\n            # Configure the audit log handler\n            audit_handler = SyslogPipelineHandler()\n            audit_handler.setFormatter(logging.Formatter(_get_syslog_format('cloud-inquisitor-audit')))\n            audit_handler.setLevel(logging.DEBUG)\n\n            _AUDIT_LOGGER.addHandler(audit_handler)\n            _AUDIT_LOGGER.propagate = False\n        except Exception as ex:\n            print('An error occured while configuring the syslogger: {}'.format(ex))\n\n    logging.config.dictConfig(config)", "response": "Utility function to setup the logging system based on the logging. json configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating and insert a new audit log entry.", "response": "def auditlog(*, event, actor, data, level=logging.INFO):\n    \"\"\"Generate and insert a new event\n\n    Args:\n        event (`str`): Action performed\n        actor (`str`): Actor (user or subsystem) triggering the event\n        data (`dict`): Any extra data necessary for describing the event\n        level (`str` or `int`): Log level for the message. Uses standard python logging level names / numbers\n\n    Returns:\n        `None`\n    \"\"\"\n    try:\n        entry = AuditLog()\n        entry.event = event\n        entry.actor = actor\n        entry.data = data\n\n        db.session.add(entry)\n        db.session.commit()\n\n        _AUDIT_LOGGER.log(\n            logging.getLevelName(level) if type(level) == str else level,\n            {\n                'event': event,\n                'actor': actor,\n                'data': data,\n            }\n        )\n\n    except Exception:\n        logging.getLogger(__name__).exception('Failed adding audit log event')\n        db.session.rollback()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npersist a record into the database.", "response": "def emit(self, record):\n        \"\"\"Persist a record into the database\n\n        Args:\n            record (`logging.Record`): The logging.Record object to store\n\n        Returns:\n            `None`\n        \"\"\"\n        # Skip records less than min_level\n        if record.levelno < logging.getLevelName(self.min_level):\n            return\n\n        evt = LogEvent()\n        evt.level = record.levelname\n        evt.levelno = record.levelno\n        evt.timestamp = datetime.fromtimestamp(record.created)\n        evt.message = record.message\n        evt.filename = record.filename\n        evt.lineno = record.lineno\n        evt.module = record.module\n        evt.funcname = record.funcName\n        evt.pathname = record.pathname\n        evt.process_id = record.process\n\n        # Only log stacktraces if its the level is ERROR or higher\n        if record.levelno >= 40:\n            evt.stacktrace = traceback.format_exc()\n\n        try:\n            db.session.add(evt)\n            db.session.commit()\n        except Exception:\n            db.session.rollback()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport the object to a JSON friendly dict.", "response": "def to_json(self, include_body=False):\n        \"\"\"Exports the object to a JSON friendly dict\n\n        Args:\n            include_body (bool): Include the body of the message in the output\n\n        Returns:\n             Dict representation of object type\n        \"\"\"\n\n        message = {\n            'emailId': self.email_id,\n            'timestamp': isoformat(self.timestamp),\n            'subsystem': self.subsystem,\n            'subject': self.subject,\n            'sender': self.sender,\n            'recipients': self.recipients,\n            'uuid': self.uuid,\n            'messageHtml': None,\n            'messageText': None\n        }\n\n        if include_body:\n            message['messageHtml'] = self.message_html\n            message['messageText'] = self.message_text\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching an item by namespace and key", "response": "def get(cls, ns, key):\n        \"\"\"Fetch an item by namespace and key\n\n        Args:\n            ns (str): Namespace prefix\n            key (str): Item key\n\n        Returns:\n            :obj:`Configitem`: Returns config item object if found, else `None`\n        \"\"\"\n        return getattr(db, cls.__name__).find_one(\n            ConfigItem.namespace_prefix == ns,\n            ConfigItem.key == key\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_json(cls, data):\n        role = cls()\n\n        role.role_id = data['roleId']\n        role.name = data['name']\n        role.color = data['color']\n\n        return role", "response": "Return object based on JSON / dict input\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps roles for user in database", "response": "def add_role(user, roles):\n        \"\"\"Map roles for user in database\n\n        Args:\n            user (User): User to add roles to\n            roles ([Role]): List of roles to add\n\n        Returns:\n            None\n        \"\"\"\n        def _add_role(role):\n            user_role = UserRole()\n            user_role.user_id = user.user_id\n            user_role.role_id = role.role_id\n            db.session.add(user_role)\n            db.session.commit()\n        [_add_role(role) for role in roles]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_json(cls, data):\n        user = cls()\n\n        user.user_id = data['userId']\n        user.username = data['username']\n        user.auth_system = data['authSystem']\n        user.roles = data['roles']\n\n        return user", "response": "Return object based on JSON / dict input\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_json(self):\n        return {\n            'userId': self.user_id,\n            'username': self.username,\n            'roles': self.roles,\n            'authSystem': self.auth_system\n        }", "response": "Exports the object to a JSON friendly dict representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate and insert a new event in the log file", "response": "def log(cls, event=None, actor=None, data=None):\n        \"\"\"Generate and insert a new event\n\n        Args:\n            event (str): Action performed\n            actor (str): Actor (user or subsystem) triggering the event\n            data (dict): Any extra data necessary for describing the event\n\n        Returns:\n            `None`\n        \"\"\"\n        from cloud_inquisitor.log import auditlog\n\n        auditlog(event=event, actor=actor, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreload the configuration from the database", "response": "def reload_data(self):\n        \"\"\"Reloads the configuration from the database\n\n        Returns:\n            `None`\n        \"\"\"\n        # We must force a rollback here to ensure that we are working on a fresh session, without any cache\n        db.session.rollback()\n\n        self.__data = {}\n        try:\n            for ns in db.ConfigNamespace.all():\n                self.__data[ns.namespace_prefix] = {x.key: x.value for x in ns.config_items}\n\n        except SQLAlchemyError as ex:\n            if str(ex).find('1146') != -1:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking a namespace for the existence of a specific key in the innermost instance", "response": "def key_exists(self, namespace, key):\n        \"\"\"Checks a namespace for the existence of a specific key\n\n        Args:\n            namespace (str): Namespace to check in\n            key (str): Name of the key to check for\n\n        Returns:\n            `True` if key exists in the namespace, else `False`\n        \"\"\"\n\n        return namespace in self.__data and key in self.__data[namespace]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value of a key or namespace pair", "response": "def get(self, key, namespace='default', default=None, as_object=False):\n        \"\"\"Return the value of a key/namespace pair\n\n        Args:\n            key (str): Key to return\n            namespace (str): Namespace of the key\n            default (:obj:`Any`): Optional default value to return, if key was not found\n            as_object (bool): If `True` returns the object as a :py:obj:`ConfigItem` object instead of its primitive\n            type\n\n        Returns:\n            Requested value if found, else default value or `None`\n        \"\"\"\n\n        if namespace in self.__data and key in self.__data[namespace]:\n            if as_object:\n                return db.ConfigItem.find_one(\n                    ConfigItem.namespace_prefix == namespace,\n                    ConfigItem.key == key\n                )\n\n            return self.__data[namespace][key]\n        else:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, namespace, key, value, description=None):\n\n        if isinstance(value, DBCChoice):\n            vtype = 'choice'\n\n        elif isinstance(value, DBCString):\n            vtype = 'string'\n\n        elif isinstance(value, DBCFloat):\n            vtype = 'float'\n\n        elif isinstance(value, DBCInt):\n            vtype = 'int'\n\n        elif isinstance(value, DBCArray):\n            vtype = 'array'\n\n        elif isinstance(value, DBCJSON):\n            vtype = 'json'\n\n        elif isinstance(value, bool):\n            vtype = 'bool'\n\n        else:\n            raise ValueError('Invalid config item type: {}'.format(type(value)))\n\n        if namespace in self.__data and key in self.__data[namespace]:\n            itm = db.ConfigItem.find_one(\n                ConfigItem.namespace_prefix == namespace,\n                ConfigItem.key == key\n            )\n\n            if not itm:\n                raise KeyError(key)\n\n            itm.value = value\n            itm.type = vtype\n            if description:\n                itm.description = description\n        else:\n            itm = ConfigItem()\n            itm.key = key\n            itm.value = value\n            itm.type = vtype\n            itm.description = description\n            itm.namespace_prefix = namespace\n\n        db.session.add(itm)\n        db.session.commit()\n\n        if namespace in self.__data:\n            self.__data[namespace][key] = value\n        else:\n            self.__data[namespace] = {key: value}", "response": "Set a configuration item in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a configuration item from the database", "response": "def delete(self, namespace, key):\n        \"\"\"Remove a configuration item from the database\n\n        Args:\n            namespace (`str`): Namespace of the config item\n            key (`str`): Key to delete\n\n        Returns:\n            `None`\n        \"\"\"\n        if self.key_exists(namespace, key):\n            obj = db.ConfigItem.find_one(\n                ConfigItem.namespace_prefix == namespace,\n                ConfigItem.key == key\n            )\n\n            del self.__data[namespace][key]\n\n            db.session.delete(obj)\n            db.session.commit()\n        else:\n            raise KeyError('{}/{}'.format(namespace, key))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new role", "response": "def post(self):\n        \"\"\"Create a new role\"\"\"\n        self.reqparse.add_argument('name', type=str, required=True)\n        self.reqparse.add_argument('color', type=str, required=True)\n        args = self.reqparse.parse_args()\n\n        role = Role()\n        role.name = args['name']\n        role.color = args['color']\n\n        db.session.add(role)\n        db.session.commit()\n        auditlog(event='role.create', actor=session['user'].username, data=args)\n\n        return self.make_response('Role {} has been created'.format(role.role_id), HTTP.CREATED)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a specific role information", "response": "def get(self, roleId):\n        \"\"\"Get a specific role information\"\"\"\n        role = db.Role.find_one(Role.role_id == roleId)\n\n        if not role:\n            return self.make_response('No such role found', HTTP.NOT_FOUND)\n\n        return self.make_response({'role': role})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, roleId):\n        role = db.Role.find_one(Role.role_id == roleId)\n        if not role:\n            return self.make_response('No such role found', HTTP.NOT_FOUND)\n\n        if role.name in ('User', 'Admin'):\n            return self.make_response('Cannot delete the built-in roles', HTTP.BAD_REQUEST)\n\n        db.session.delete(role)\n        db.session.commit()\n        auditlog(event='role.delete', actor=session['user'].username, data={'roleId': roleId})\n\n        return self.make_response({\n            'message': 'Role has been deleted',\n            'roleId': roleId\n        })", "response": "Delete a user role"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_email(subsystem, sender, recipients, subject, html_body=None, text_body=None, message_uuid=None):\n    if type(recipients) == str:\n        recipients = [recipients]\n\n    recipients = list(set(recipients))\n\n    send_notification(\n        subsystem=subsystem,\n        recipients=[NotificationContact('email', x) for x in recipients],\n        subject=subject,\n        body_html=html_body,\n        body_text=text_body\n    )", "response": "Sends an email to a list of recipients using the system configured email method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notify(self, subsystem, recipient, subject, body_html, body_text):\n        if not re.match(RGX_EMAIL_VALIDATION_PATTERN, recipient, re.I):\n            raise ValueError('Invalid recipient provided')\n\n        email = Email()\n        email.timestamp = datetime.now()\n        email.subsystem = subsystem\n        email.sender = self.sender\n        email.recipients = recipient\n        email.subject = subject\n        email.uuid = uuid.uuid4()\n        email.message_html = body_html\n        email.message_text = body_text\n\n        method = dbconfig.get('method', NS_EMAIL, 'ses')\n        try:\n            if method == 'ses':\n                self.__send_ses_email([recipient], subject, body_html, body_text)\n\n            elif method == 'smtp':\n                self.__send_smtp_email([recipient], subject, body_html, body_text)\n\n            else:\n                raise ValueError('Invalid email method: {}'.format(method))\n\n            db.session.add(email)\n            db.session.commit()\n        except Exception as ex:\n            raise EmailSendError(ex)", "response": "Method to send a notification to the specified subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __send_ses_email(self, recipients, subject, body_html, body_text):\n        source_arn = dbconfig.get('source_arn', NS_EMAIL)\n        return_arn = dbconfig.get('return_path_arn', NS_EMAIL)\n\n        session = get_local_aws_session()\n        ses = session.client('ses', region_name=dbconfig.get('ses_region', NS_EMAIL, 'us-west-2'))\n\n        body = {}\n        if body_html:\n            body['Html'] = {\n                'Data': body_html\n            }\n        if body_text:\n            body['Text'] = {\n                'Data': body_text\n            }\n\n        ses_options = {\n            'Source': self.sender,\n            'Destination': {\n                'ToAddresses': recipients\n            },\n            'Message': {\n                'Subject': {\n                    'Data': subject\n                },\n                'Body': body\n            }\n        }\n\n        # Set SES options if needed\n        if source_arn and return_arn:\n            ses_options.update({\n                'SourceArn': source_arn,\n                'ReturnPathArn': return_arn\n            })\n\n        ses.send_email(**ses_options)", "response": "Send an email using SES"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __send_smtp_email(self, recipients, subject, html_body, text_body):\n        smtp = smtplib.SMTP(\n            dbconfig.get('smtp_server', NS_EMAIL, 'localhost'),\n            dbconfig.get('smtp_port', NS_EMAIL, 25)\n        )\n        source_arn = dbconfig.get('source_arn', NS_EMAIL)\n        return_arn = dbconfig.get('return_path_arn', NS_EMAIL)\n        from_arn = dbconfig.get('from_arn', NS_EMAIL)\n        msg = MIMEMultipart('alternative')\n\n        # Set SES options if needed\n        if source_arn and from_arn and return_arn:\n            msg['X-SES-SOURCE-ARN'] = source_arn\n            msg['X-SES-FROM-ARN'] = from_arn\n            msg['X-SES-RETURN-PATH-ARN'] = return_arn\n\n        msg['Subject'] = subject\n        msg['To'] = ','.join(recipients)\n        msg['From'] = self.sender\n\n        # Check body types to avoid exceptions\n        if html_body:\n            html_part = MIMEText(html_body, 'html')\n            msg.attach(html_part)\n        if text_body:\n            text_part = MIMEText(text_body, 'plain')\n            msg.attach(text_part)\n\n        # TLS if needed\n        if dbconfig.get('smtp_tls', NS_EMAIL, False):\n            smtp.starttls()\n\n        # Login if needed\n        username = dbconfig.get('smtp_username', NS_EMAIL)\n        password = dbconfig.get('smtp_password', NS_EMAIL)\n        if username and password:\n            smtp.login(username, password)\n\n        smtp.sendmail(self.sender, recipients, msg.as_string())\n        smtp.quit()", "response": "Send an email using SMTP"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndefault object encoder function", "response": "def default(self, obj):\n        \"\"\"Default object encoder function\n\n        Args:\n            obj (:obj:`Any`): Object to be serialized\n\n        Returns:\n            JSON string\n        \"\"\"\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n\n        if issubclass(obj.__class__, Enum.__class__):\n            return obj.value\n\n        to_json = getattr(obj, 'to_json', None)\n        if to_json:\n            out = obj.to_json()\n            if issubclass(obj.__class__, Model):\n                out.update({'__type': obj.__class__.__name__})\n\n            return out\n\n        return JSONEncoder.default(self, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef object_hook(obj):\n        try:\n            if '__type' in obj:\n                obj_type = obj['__type']\n                cls = getattr(cloud_inquisitor.schema, obj_type)\n                if hasattr(cls, 'from_json'):\n                    return cls.from_json(obj)\n\n            key, value = next(iter(obj.items()))\n            if key == ' t':\n                return tuple(value)\n            elif key == ' u':\n                return uuid.UUID(value)\n            elif key == ' b':\n                return b64decode(value)\n            elif key == ' m':\n                return Markup(value)\n            elif key == ' d':\n                return parse_date(value)\n\n            return obj\n        except Exception:\n            log.exception('Error during data deserialization')", "response": "Checks to see if the __type - hinting field is available in the object being de - serialized and if not returns the object otherwise returns a regular python object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deprecated(msg):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            logging.getLogger(__name__).warning(msg)\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Mark a function or method as deprecated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating a value for truthiness", "response": "def is_truthy(value, default=False):\n    \"\"\"Evaluate a value for truthiness\n\n    >>> is_truthy('Yes')\n    True\n    >>> is_truthy('False')\n    False\n    >>> is_truthy(1)\n    True\n\n    Args:\n        value (Any): Value to evaluate\n        default (bool): Optional default value, if the input does not match the true or false values\n\n    Returns:\n        True if a truthy value is passed, else False\n    \"\"\"\n\n    if value is None:\n        return False\n\n    if isinstance(value, bool):\n        return value\n\n    if isinstance(value, int):\n        return value > 0\n\n    trues = ('1', 'true', 'y', 'yes', 'ok')\n    falses = ('', '0', 'false', 'n', 'none', 'no')\n\n    if value.lower().strip() in falses:\n        return False\n\n    elif value.lower().strip() in trues:\n        return True\n\n    else:\n        if default:\n            return default\n        else:\n            raise ValueError('Invalid argument given to truthy: {0}'.format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_email(email, partial_match=False):\n    rgx = re.compile(RGX_EMAIL_VALIDATION_PATTERN, re.I)\n    if partial_match:\n        return rgx.search(email) is not None\n    else:\n        return rgx.match(email) is not None", "response": "Perform email address validation returning True if the value contains an email address otherwise False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_template(template):\n    from cloud_inquisitor.database import db\n\n    tmpl = db.Template.find_one(template_name=template)\n    if not tmpl:\n        raise InquisitorError('No such template found: {}'.format(template))\n\n    tmplenv = Environment(loader=BaseLoader, autoescape=True)\n    tmplenv.filters['json_loads'] = json.loads\n    tmplenv.filters['slack_quote_join'] = lambda data: ', '.join('`{}`'.format(x) for x in data)\n\n    return tmplenv.from_string(tmpl.template)", "response": "Return a Jinja2 template by filename"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_bucket_info(domain):\n    match = RGX_BUCKET.match(domain)\n    if match:\n        data = match.groupdict()\n        return data['bucket'], data['region'] or 'us-east-1'", "response": "Parse a domain name to gather the bucket name and region for an S3 bucket. Returns a tuple containing bucket name and region if a valid domain name else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a datetime object from local to UTC format", "response": "def to_utc_date(date):\n    \"\"\"Convert a datetime object from local to UTC format\n\n    >>> import datetime\n    >>> d = datetime.datetime(2017, 8, 15, 18, 24, 31)\n    >>> to_utc_date(d)\n    datetime.datetime(2017, 8, 16, 1, 24, 31)\n\n    Args:\n        date (`datetime`): Input datetime object\n\n    Returns:\n        `datetime`\n    \"\"\"\n    return datetime.utcfromtimestamp(float(date.strftime('%s'))).replace(tzinfo=None) if date else None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a cryptographically secure random string to use for passwords", "response": "def generate_password(length=32):\n    \"\"\"Generate a cryptographically secure random string to use for passwords\n\n    Args:\n        length (int): Length of password, defaults to 32 characters\n\n    Returns:\n        Randomly generated string\n    \"\"\"\n    return ''.join(random.SystemRandom().choice(string.ascii_letters + '!@#$+.,') for _ in range(length))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a new JWT token for a user", "response": "def generate_jwt_token(user, authsys, **kwargs):\n    \"\"\"Generate a new JWT token, with optional extra information. Any data provided in `**kwargs`\n    will be added into the token object for auth specific usage\n\n    Args:\n        user (:obj:`User`): User object to generate token for\n        authsys (str): The auth system for which the token was generated\n        **kwargs (dict): Any optional items to add to the token\n\n    Returns:\n        Encoded JWT token\n    \"\"\"\n    # Local import to prevent app startup failures\n    from cloud_inquisitor.config import dbconfig\n\n    token = {\n        'auth_system': authsys,\n        'exp': time.time() + dbconfig.get('session_expire_time'),\n        'roles': [role.name for role in user.roles]\n    }\n\n    if kwargs:\n        token.update(**kwargs)\n\n    enc = jwt.encode(token, get_jwt_key_data(), algorithm='HS512')\n    return enc.decode()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the data for the JWT private key used for encrypting the user login token as a string object", "response": "def get_jwt_key_data():\n    \"\"\"Returns the data for the JWT private key used for encrypting the user login token as a string object\n\n    Returns:\n        `str`\n    \"\"\"\n    global __jwt_data\n\n    if __jwt_data:\n        return __jwt_data\n\n    from cloud_inquisitor import config_path\n    from cloud_inquisitor.config import dbconfig\n\n    jwt_key_file = dbconfig.get('jwt_key_file_path', default='ssl/private.key')\n    if not os.path.isabs(jwt_key_file):\n        jwt_key_file = os.path.join(config_path, jwt_key_file)\n\n    with open(os.path.join(jwt_key_file), 'r') as f:\n        __jwt_data = f.read()\n\n    return __jwt_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the user has access to the required_roles.", "response": "def has_access(user, required_roles, match_all=True):\n    \"\"\"Check if the user meets the role requirements. If mode is set to AND, all the provided roles must apply\n\n    Args:\n        user (:obj:`User`): User object\n        required_roles (`list` of `str`): List of roles that the user must have applied\n        match_all (`bool`): If true, all the required_roles must be applied to the user, else any one match will\n         return `True`\n\n    Returns:\n        `bool`\n    \"\"\"\n    # Admins have access to everything\n    if ROLE_ADMIN in user.roles:\n        return True\n\n    if isinstance(required_roles, str):\n        if required_roles in user.roles:\n            return True\n\n        return False\n\n    # If we received a list of roles to match against\n    if match_all:\n        for role in required_roles:\n            if role not in user.roles:\n                return False\n\n        return True\n\n    else:\n        for role in required_roles:\n            if role in user.roles:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge an arbitrary number of lists into a single list and dedupe it", "response": "def merge_lists(*args):\n    \"\"\"Merge an arbitrary number of lists into a single list and dedupe it\n\n    Args:\n        *args: Two or more lists\n\n    Returns:\n        A deduped merged list of all the provided lists as a single list\n    \"\"\"\n\n    out = {}\n    for contacts in filter(None, args):\n        for contact in contacts:\n            out[contact.value] = contact\n\n    return list(out.values())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a unique ID based on the SHA256 hash of the provided data.", "response": "def get_resource_id(prefix, *data):\n    \"\"\"Returns a unique ID based on the SHA256 hash of the provided data. The input data is flattened and sorted to\n    ensure identical hashes are generated regardless of the order of the input. Values must be of types `str`, `int` or\n    `float`, any other input type will raise a `ValueError`\n\n    >>> get_resource_id('ec2', 'lots', 'of', 'data')\n    'ec2-1d21940125214123'\n    >>> get_resource_id('ecs', 'foo', ['more', 'data', 'here', 2, 3])\n    'ecs-e536b036ea6fd463'\n    >>> get_resource_id('ecs', ['more'], 'data', 'here', [[2], 3], 'foo')\n    'ecs-e536b036ea6fd463'\n\n    Args:\n        prefix (`str`): Key prefix\n        *data (`str`, `int`, `float`, `list`, `tuple`): Data used to generate a unique ID\n\n    Returns:\n        `str`\n    \"\"\"\n    parts = flatten(data)\n    for part in parts:\n        if type(part) not in (str, int, float):\n            raise ValueError('Supported data types: int, float, list, tuple, str. Got: {}'.format(type(part)))\n\n    return '{}-{}'.format(\n        prefix,\n        get_hash('-'.join(sorted(map(str, parts))))[-16:]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_date(date_string, ignoretz=True):\n    try:\n        return parser.parse(date_string, ignoretz=ignoretz)\n    except TypeError:\n        return None", "response": "Parse a string as a date."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_user_data_configuration():\n    from cloud_inquisitor import get_local_aws_session, app_config\n\n    kms_region = app_config.kms_region\n    session = get_local_aws_session()\n\n    if session.get_credentials().method == 'iam-role':\n        kms = session.client('kms', region_name=kms_region)\n    else:\n        sts = session.client('sts')\n        audit_role = sts.assume_role(RoleArn=app_config.aws_api.instance_role_arn, RoleSessionName='cloud_inquisitor')\n        kms = boto3.session.Session(\n            audit_role['Credentials']['AccessKeyId'],\n            audit_role['Credentials']['SecretAccessKey'],\n            audit_role['Credentials']['SessionToken'],\n        ).client('kms', region_name=kms_region)\n\n    user_data_url = app_config.user_data_url\n    res = requests.get(user_data_url)\n\n    if res.status_code == 200:\n        data = kms.decrypt(CiphertextBlob=b64decode(res.content))\n        kms_config = json.loads(zlib.decompress(data['Plaintext']).decode('utf-8'))\n\n        app_config.database_uri = kms_config['db_uri']\n    else:\n        raise RuntimeError('Failed loading user-data, cannot continue: {}: {}'.format(res.status_code, res.content))", "response": "Retrieve and update the application configuration with information from the user - data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to read the application configuration file and returns the folder where the configuration file was loaded from and the Munch containing the configuration file.", "response": "def read_config():\n    \"\"\"Attempts to read the application configuration file and will raise a `FileNotFoundError` if the\n    configuration file is not found. Returns the folder where the configuration file was loaded from, and\n    a `Munch` (dict-like object) containing the configuration\n\n    Configuration file paths searched, in order:\n        * ~/.cinq/config.json'\n        * ./config.json\n        * /usr/local/etc/cloud-inquisitor/config.json\n\n    Returns:\n        `str`, `dict`\n    \"\"\"\n    def __recursive_update(old, new):\n        out = deepcopy(old)\n        for k, v in new.items():\n            if issubclass(type(v), dict):\n                if k in old:\n                    out[k] = __recursive_update(old[k], v)\n                else:\n                    out[k] = v\n            else:\n                out[k] = v\n\n        return out\n\n    for fpath in CONFIG_FILE_PATHS:\n        if os.path.exists(fpath):\n            data = munch.munchify(json.load(open(fpath, 'r')))\n\n            # Our code expects a munch, so ensure that any regular dicts are converted\n            return os.path.dirname(fpath), munch.munchify(__recursive_update(DEFAULT_CONFIG, data))\n\n    raise FileNotFoundError('Configuration file not found')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a flattened version of a list.", "response": "def flatten(data):\n    \"\"\"Returns a flattened version of a list.\n\n    Courtesy of https://stackoverflow.com/a/12472564\n\n    Args:\n        data (`tuple` or `list`): Input data\n\n    Returns:\n        `list`\n    \"\"\"\n    if not data:\n        return data\n\n    if type(data[0]) in (list, tuple):\n        return list(flatten(data[0])) + list(flatten(data[1:]))\n\n    return list(data[:1]) + list(flatten(data[1:]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_notification(*, subsystem, recipients, subject, body_html, body_text):\n    from cloud_inquisitor import CINQ_PLUGINS\n\n    if not body_html and not body_text:\n        raise ValueError('body_html or body_text must be provided')\n\n    # Make sure that we don't have any duplicate recipients\n    recipients = list(set(recipients))\n\n    notifiers = map(lambda plugin: plugin.load(), CINQ_PLUGINS['cloud_inquisitor.plugins.notifiers']['plugins'])\n\n    for cls in filter(lambda x: x.enabled(), notifiers):\n        for recipient in recipients:\n            if isinstance(recipient, NotificationContact):\n                if recipient.type == cls.notifier_type:\n                    try:\n                        notifier = cls()\n                        notifier.notify(subsystem, recipient.value, subject, body_html, body_text)\n                    except Exception:\n                        log.exception('Failed sending notification for {}/{}'.format(\n                            recipient.type,\n                            recipient.value\n                        ))\n            else:\n                log.warning('Unexpected recipient {}'.format(recipient))", "response": "Method to send a notification to the specified recipients."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the difference between two strings", "response": "def diff(a, b):\n    \"\"\"Return the difference between two strings\n\n    Will return a human-readable difference between two strings. See\n    https://docs.python.org/3/library/difflib.html#difflib.Differ for more information about the output format\n\n    Args:\n        a (str): Original string\n        b (str): New string\n\n    Returns:\n        `str`\n    \"\"\"\n    return ''.join(\n        Differ().compare(\n            a.splitlines(keepends=True),\n            b.splitlines(keepends=True)\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(bucket_name, version, force, verbose):\n    if verbose:\n        log.setLevel('DEBUG')\n\n    if not version:\n        version = setuptools_scm.get_version()\n\n    release = \"dev\" if \"dev\" in version else \"release\"\n    tarball = TARBALL_FORMAT.format(version)\n    tarball_path = os.path.join(tempfile.gettempdir(), tarball)\n    s3_key = os.path.join(release, tarball)\n\n    try:\n        run('npm i')\n        run('./node_modules/.bin/gulp build.prod')\n\n    except ExecutionError:\n        log.exception('Failed executing command')\n        return\n\n    log.debug('Creating archive')\n    tar = tarfile.open(tarball_path, \"w:gz\")\n    for root, dirnames, filenames in os.walk('dist'):\n        for f in filenames:\n            tar.add(os.path.join(root, f), recursive=False, filter=strip_path)\n    tar.close()\n\n    log.debug('Uploading {} to s3://{}/{}'.format(tarball, bucket_name, s3_key))\n    try:\n        bucket = get_bucket_resource(bucket_name)\n\n        if s3_file_exists(bucket, s3_key) and not force:\n            log.error('File already exists in S3, use --force to overwrite')\n            return\n\n        bucket.upload_file(tarball_path, os.path.join(release, tarball))\n    except ClientError:\n        log.exception('AWS API failure')", "response": "Builds and uploads a new tarball to S3"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the class object identified by issue_id", "response": "def get(cls, issue_id):\n        \"\"\"Returns the class object identified by `issue_id`\n\n        Args:\n            issue_id (str): Unique EC2 Instance ID to load from database\n\n        Returns:\n            EC2 Instance object if found, else None\n        \"\"\"\n        res = Issue.get(issue_id, IssueType.get(cls.issue_type).issue_type_id)\n        return cls(res) if res else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(cls, issue_id, *, properties=None, auto_commit=False):\n        if cls.get(issue_id):\n            raise IssueException('Issue {} already exists'.format(issue_id))\n\n        res = Issue()\n        res.issue_id = issue_id\n        res.issue_type_id = IssueType.get(cls.issue_type).issue_type_id\n\n        if properties:\n            for name, value in properties.items():\n                prop = IssueProperty()\n                prop.issue_id = res.issue_id\n                prop.name = name\n                prop.value = value.isoformat() if type(value) == datetime else value\n                res.properties.append(prop)\n                db.session.add(prop)\n\n        db.session.add(res)\n        if auto_commit:\n            db.session.commit()\n\n        return cls.get(res.issue_id)", "response": "Creates a new issue object with the properties and tags provided."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all(cls):\n        issues = db.Issue.find(\n            Issue.issue_type_id == IssueType.get(cls.issue_type).issue_type_id\n        )\n\n        return {res.issue_id: cls(res) for res in issues}", "response": "Returns a list of all issues of a given type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(cls, *, limit=100, page=1, properties=None, return_query=False):\n        qry = db.Issue.order_by(Issue.issue_id).filter(\n            Issue.issue_type_id == IssueType.get(cls.issue_type).issue_type_id\n        )\n\n        if properties:\n            for prop_name, value in properties.items():\n                alias = aliased(IssueProperty)\n                qry = qry.join(alias, Issue.issue_id == alias.issue_id)\n                if type(value) == list:\n                    where_clause = []\n                    for item in value:\n                        where_clause.append(alias.value == item)\n\n                    qry = qry.filter(\n                        and_(\n                            alias.name == prop_name,\n                            or_(*where_clause)\n                        ).self_group()\n                    )\n                else:\n                    qry = qry.filter(\n                        and_(\n                            alias.name == prop_name,\n                            alias.value == value\n                        ).self_group()\n                    )\n\n        if return_query:\n            return qry\n\n        total = qry.count()\n        qry = qry.limit(limit)\n        qry = qry.offset((page - 1) * limit if page > 1 else 0)\n\n        return total, [cls(x) for x in qry.all()]", "response": "Search for issues based on the provided filters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the object s properties based on live data.", "response": "def update(self, data):\n        \"\"\"Updates the object information based on live data, if there were any changes made. Any changes will be\n        automatically applied to the object, but will not be automatically persisted. You must manually call\n        `db.session.add(instance)` on the object.\n\n        Args:\n            data (:obj:): AWS API Resource object fetched from AWS API\n\n        Returns:\n            `bool`\n        \"\"\"\n        updated = False\n        if 'missing_tags' in data:\n            updated |= self.set_property('missing_tags', data['missing_tags'])\n\n        if 'notes' in data:\n            updated |= self.set_property('notes', data['notes'])\n\n        if 'state' in data:\n            updated |= self.set_property('state', data['state'])\n\n        if 'last_alert' in data:\n            updated |= self.set_property('last_alert', data['last_alert'])\n\n        if updated:\n            now = datetime.now()\n            self.set_property('last_change', now)\n\n        return updated"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a human - readable value of the state of the current state of the elastic elastic", "response": "def state_name(self):\n        \"\"\"Get a human-readable value of the state\n\n        Returns:\n            str: Name of the current state\n        \"\"\"\n        if self.state == 1:\n            return 'New Issue'\n\n        elif self.state == 2:\n            return 'Shutdown in 1 week'\n\n        elif self.state == 3:\n            return 'Shutdown in 1 day'\n\n        elif self.state == 4:\n            return 'Pending Shutdown'\n\n        elif self.state == 5:\n            return 'Stopped, delete in 12 weeks'\n\n        elif self.state == 6:\n            return 'Instance deleted'\n\n        else:\n            raise ValueError('Invalid state: {}'.format(self.state))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the object s information based on live data.", "response": "def update(self, data):\n        \"\"\"Updates the object information based on live data, if there were any changes made. Any changes will be\n        automatically applied to the object, but will not be automatically persisted. You must manually call\n        `db.session.add(instance)` on the object.\n\n        Args:\n            data (:obj:): AWS API Resource object fetched from AWS API\n\n        Returns:\n            `bool`\n        \"\"\"\n        # If the instance was terminated, remove it\n        updated = False\n\n        if 'state' in data:\n            updated = self.set_property('state', data['state'])\n\n        if 'end' in data:\n            updated |= self.set_property('end', data['end'])\n\n        if 'last_alert' in data:\n            updated |= self.set_property('last_alert', data['last_alert'])\n\n        return updated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the object information based on live data.", "response": "def update(self, data):\n        \"\"\"Updates the object information based on live data, if there were any changes made. Any changes will be\n        automatically applied to the object, but will not be automatically persisted. You must manually call\n        `db.session.add(instance)` on the object.\n\n        Args:\n            data (:obj:): AWS API Resource object fetched from AWS API\n\n        Returns:\n            `bool`\n        \"\"\"\n        # If the instance was terminated, remove it\n        updated = self.set_property('state', data['state'])\n        updated |= self.set_property('notes', sorted(data['notes'] or []))\n        updated |= self.set_property('last_notice', data['last_notice'])\n\n        if updated:\n            self.set_property('last_change', datetime.now())\n\n        return updated"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying a single ID3 header to another ID3 header.", "response": "def copy(src, dst, merge, write_v1=True, excluded_tags=None, verbose=False):\n    \"\"\"Returns 0 on success\"\"\"\n\n    if excluded_tags is None:\n        excluded_tags = []\n\n    try:\n        id3 = mutagen.id3.ID3(src, translate=False)\n    except mutagen.id3.ID3NoHeaderError:\n        print_(u\"No ID3 header found in \", src, file=sys.stderr)\n        return 1\n    except Exception as err:\n        print_(str(err), file=sys.stderr)\n        return 1\n\n    if verbose:\n        print_(u\"File\", src, u\"contains:\", file=sys.stderr)\n        print_(id3.pprint(), file=sys.stderr)\n\n    for tag in excluded_tags:\n        id3.delall(tag)\n\n    if merge:\n        try:\n            target = mutagen.id3.ID3(dst, translate=False)\n        except mutagen.id3.ID3NoHeaderError:\n            # no need to merge\n            pass\n        except Exception as err:\n            print_(str(err), file=sys.stderr)\n            return 1\n        else:\n            for frame in id3.values():\n                target.add(frame)\n\n            id3 = target\n\n    # if the source is 2.3 save it as 2.3\n    if id3.version < (2, 4, 0):\n        id3.update_to_v23()\n        v2_version = 3\n    else:\n        id3.update_to_v24()\n        v2_version = 4\n\n    try:\n        id3.save(dst, v1=(2 if write_v1 else 0), v2_version=v2_version)\n    except Exception as err:\n        print_(u\"Error saving\", dst, u\":\\n%s\" % text_type(err),\n               file=sys.stderr)\n        return 1\n    else:\n        if verbose:\n            print_(u\"Successfully saved\", dst, file=sys.stderr)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the next limit bytes from fileobj until the MSB is zero.", "response": "def _parse_sv8_int(fileobj, limit=9):\n    \"\"\"Reads (max limit) bytes from fileobj until the MSB is zero.\n    All 7 LSB will be merged to a big endian uint.\n\n    Raises ValueError in case not MSB is zero, or EOFError in\n    case the file ended before limit is reached.\n\n    Returns (parsed number, number of bytes read)\n    \"\"\"\n\n    num = 0\n    for i in xrange(limit):\n        c = fileobj.read(1)\n        if len(c) != 1:\n            raise EOFError\n        c = bytearray(c)\n        num = (num << 7) | (c[0] & 0x7F)\n        if not c[0] & 0x80:\n            return num, i + 1\n    if limit > 0:\n        raise ValueError\n    return 0, 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a single object from the file.", "response": "def delete(filething):\n    \"\"\" delete(filething)\n\n    Arguments:\n        filething (filething)\n    Raises:\n        mutagen.MutagenError\n\n    Remove tags from a file.\n    \"\"\"\n\n    t = OggFLAC(filething)\n    filething.fileobj.seek(0)\n    t.delete(filething)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _inject(self, fileobj, padding_func):\n\n        # Ogg FLAC has no convenient data marker like Vorbis, but the\n        # second packet - and second page - must be the comment data.\n        fileobj.seek(0)\n        page = OggPage(fileobj)\n        while not page.packets[0].startswith(b\"\\x7FFLAC\"):\n            page = OggPage(fileobj)\n\n        first_page = page\n        while not (page.sequence == 1 and page.serial == first_page.serial):\n            page = OggPage(fileobj)\n\n        old_pages = [page]\n        while not (old_pages[-1].complete or len(old_pages[-1].packets) > 1):\n            page = OggPage(fileobj)\n            if page.serial == first_page.serial:\n                old_pages.append(page)\n\n        packets = OggPage.to_packets(old_pages, strict=False)\n\n        # Set the new comment block.\n        data = self.write(framing=False)\n        data = packets[0][:1] + struct.pack(\">I\", len(data))[-3:] + data\n        packets[0] = data\n\n        new_pages = OggPage.from_packets(packets, old_pages[0].sequence)\n        OggPage.replace(fileobj, old_pages, new_pages)", "response": "Write tag data into the FLAC Vorbis comment packet or page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the tags from a file.", "response": "def delete(filething, delete_v1=True, delete_v2=True):\n    \"\"\"Remove tags from a file.\n\n    Args:\n        delete_v1 (bool): delete any ID3v1 tag\n        delete_v2 (bool): delete any ID3v2 tag\n\n    Raises:\n        mutagen.MutagenError: In case deleting failed\n    \"\"\"\n\n    f = filething.fileobj\n\n    if delete_v1:\n        tag, offset = find_id3v1(f)\n        if tag is not None:\n            f.seek(offset, 2)\n            f.truncate()\n\n    # technically an insize=0 tag is invalid, but we delete it anyway\n    # (primarily because we used to write it)\n    if delete_v2:\n        f.seek(0, 0)\n        idata = f.read(10)\n        try:\n            id3, vmaj, vrev, flags, insize = struct.unpack('>3sBBB4s', idata)\n        except struct.error:\n            pass\n        else:\n            insize = BitPaddedInt(insize)\n            if id3 == b'ID3' and insize >= 0:\n                delete_bytes(f, insize + 10, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a tag from a file object.", "response": "def load(self, filething, known_frames=None, translate=True, v2_version=4,\n             load_v1=True):\n        \"\"\"Load tags from a filename.\n\n        Args:\n            filename (filething): filename or file object to load tag data from\n            known_frames (Dict[`mutagen.text`, `Frame`]): dict mapping frame\n                IDs to Frame objects\n            translate (bool): Update all tags to ID3v2.3/4 internally. If you\n                intend to save, this must be true or you have to\n                call update_to_v23() / update_to_v24() manually.\n            v2_version (int): if update_to_v23 or update_to_v24 get called\n                (3 or 4)\n            load_v1 (bool): Load tags from ID3v1 header if present. If both\n                ID3v1 and ID3v2 headers are present, combine the tags from\n                the two, with ID3v2 having precedence.\n\n                .. versionadded:: 1.42\n\n        Example of loading a custom frame::\n\n            my_frames = dict(mutagen.id3.Frames)\n            class XMYF(Frame): ...\n            my_frames[\"XMYF\"] = XMYF\n            mutagen.id3.ID3(filename, known_frames=my_frames)\n        \"\"\"\n\n        fileobj = filething.fileobj\n\n        if v2_version not in (3, 4):\n            raise ValueError(\"Only 3 and 4 possible for v2_version\")\n\n        self.unknown_frames = []\n        self._header = None\n        self._padding = 0\n\n        self._pre_load_header(fileobj)\n\n        try:\n            self._header = ID3Header(fileobj)\n        except (ID3NoHeaderError, ID3UnsupportedVersionError):\n            if not load_v1:\n                raise\n\n            frames, offset = find_id3v1(fileobj, v2_version, known_frames)\n            if frames is None:\n                raise\n\n            self.version = ID3Header._V11\n            for v in frames.values():\n                if len(self.getall(v.HashKey)) == 0:\n                    self.add(v)\n        else:\n            # XXX: attach to the header object so we have it in spec parsing..\n            if known_frames is not None:\n                self._header._known_frames = known_frames\n\n            data = read_full(fileobj, self.size - 10)\n            remaining_data = self._read(self._header, data)\n            self._padding = len(remaining_data)\n\n            if load_v1:\n                v1v2_ver = 4 if self.version[1] == 4 else 3\n                frames, offset = find_id3v1(fileobj, v1v2_ver, known_frames)\n                if frames:\n                    for v in frames.values():\n                        if len(self.getall(v.HashKey)) == 0:\n                            self.add(v)\n\n        if translate:\n            if v2_version == 3:\n                self.update_to_v23()\n            else:\n                self.update_to_v24()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, filething=None, v1=1, v2_version=4, v23_sep='/',\n             padding=None):\n        \"\"\"save(filething=None, v1=1, v2_version=4, v23_sep='/', padding=None)\n\n        Save changes to a file.\n\n        Args:\n            filething (filething):\n                Filename to save the tag to. If no filename is given,\n                the one most recently loaded is used.\n            v1 (ID3v1SaveOptions):\n                if 0, ID3v1 tags will be removed.\n                if 1, ID3v1 tags will be updated but not added.\n                if 2, ID3v1 tags will be created and/or updated\n            v2 (int):\n                version of ID3v2 tags (3 or 4).\n            v23_sep (text):\n                the separator used to join multiple text values\n                if v2_version == 3. Defaults to '/' but if it's None\n                will be the ID3v2v2.4 null separator.\n            padding (:obj:`mutagen.PaddingFunction`)\n\n        Raises:\n            mutagen.MutagenError\n\n        By default Mutagen saves ID3v2.4 tags. If you want to save ID3v2.3\n        tags, you must call method update_to_v23 before saving the file.\n\n        The lack of a way to update only an ID3v1 tag is intentional.\n        \"\"\"\n\n        f = filething.fileobj\n\n        try:\n            header = ID3Header(filething.fileobj)\n        except ID3NoHeaderError:\n            old_size = 0\n        else:\n            old_size = header.size\n\n        data = self._prepare_data(\n            f, 0, old_size, v2_version, v23_sep, padding)\n        new_size = len(data)\n\n        if (old_size < new_size):\n            insert_bytes(f, new_size - old_size, old_size)\n        elif (old_size > new_size):\n            delete_bytes(f, old_size - new_size, new_size)\n        f.seek(0)\n        f.write(data)\n\n        self.__save_v1(f, v1)", "response": "Save the contents of the ID3v2. 3 - tag to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the tags from a file.", "response": "def delete(self, filething=None, delete_v1=True, delete_v2=True):\n        \"\"\"delete(filething=None, delete_v1=True, delete_v2=True)\n\n        Remove tags from a file.\n\n        Args:\n            filething (filething): A filename or `None` to use the one used\n                when loading.\n            delete_v1 (bool): delete any ID3v1 tag\n            delete_v2 (bool): delete any ID3v2 tag\n\n        If no filename is given, the one most recently loaded is used.\n        \"\"\"\n\n        delete(filething, delete_v1, delete_v2)\n        self.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tags(self, ID3=None):\n\n        if ID3 is None:\n            ID3 = self.ID3\n        if self.tags is None:\n            self.ID3 = ID3\n            self.tags = ID3()\n        else:\n            raise error(\"an ID3 tag already exists\")", "response": "Add an empty ID3 tag to the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RegisterKey(cls, key,\n                    getter=None, setter=None, deleter=None, lister=None):\n        \"\"\"Register a new key mapping.\n\n        A key mapping is four functions, a getter, setter, deleter,\n        and lister. The key may be either a string or a glob pattern.\n\n        The getter, deleted, and lister receive an MP4Tags instance\n        and the requested key name. The setter also receives the\n        desired value, which will be a list of strings.\n\n        The getter, setter, and deleter are used to implement __getitem__,\n        __setitem__, and __delitem__.\n\n        The lister is used to implement keys(). It should return a\n        list of keys that are actually in the MP4 instance, provided\n        by its associated getter.\n        \"\"\"\n        key = key.lower()\n        if getter is not None:\n            cls.Get[key] = getter\n        if setter is not None:\n            cls.Set[key] = setter\n        if deleter is not None:\n            cls.Delete[key] = deleter\n        if lister is not None:\n            cls.List[key] = lister", "response": "Register a new key mapping."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RegisterTextKey(cls, key, atomid):\n        def getter(tags, key):\n            return tags[atomid]\n\n        def setter(tags, key, value):\n            tags[atomid] = value\n\n        def deleter(tags, key):\n            del(tags[atomid])\n\n        cls.RegisterKey(key, getter, setter, deleter)", "response": "Register a text key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a scalar integer key.", "response": "def RegisterIntKey(cls, key, atomid, min_value=0, max_value=(2 ** 16) - 1):\n        \"\"\"Register a scalar integer key.\n        \"\"\"\n\n        def getter(tags, key):\n            return list(map(text_type, tags[atomid]))\n\n        def setter(tags, key, value):\n            clamp = lambda x: int(min(max(min_value, x), max_value))\n            tags[atomid] = [clamp(v) for v in map(int, value)]\n\n        def deleter(tags, key):\n            del(tags[atomid])\n\n        cls.RegisterKey(key, getter, setter, deleter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RegisterFreeformKey(cls, key, name, mean=\"com.apple.iTunes\"):\n        atomid = \"----:\" + mean + \":\" + name\n\n        def getter(tags, key):\n            return [s.decode(\"utf-8\", \"replace\") for s in tags[atomid]]\n\n        def setter(tags, key, value):\n            encoded = []\n            for v in value:\n                if not isinstance(v, text_type):\n                    if PY3:\n                        raise TypeError(\"%r not str\" % v)\n                    v = v.decode(\"utf-8\")\n                encoded.append(v.encode(\"utf-8\"))\n            tags[atomid] = encoded\n\n        def deleter(tags, key):\n            del(tags[atomid])\n\n        cls.RegisterKey(key, getter, setter, deleter)", "response": "Register a freeform key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint tag key = value pairs.", "response": "def pprint(self):\n        \"\"\"Print tag key=value pairs.\"\"\"\n        strings = []\n        for key in sorted(self.keys()):\n            values = self[key]\n            for value in values:\n                strings.append(\"%s=%s\" % (key, value))\n        return \"\\n\".join(strings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_stream(cls, fileobj, max_bytes):\n\n        r = BitReader(fileobj)\n        stream = cls(r)\n        if stream.sync(max_bytes):\n            stream.offset = (r.get_position() - 12) // 8\n            return stream", "response": "Returns a possibly valid _ADTSStream or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sync(self, max_bytes):\n\n        # at least 2 bytes for the sync\n        max_bytes = max(max_bytes, 2)\n\n        r = self._r\n        r.align()\n        while max_bytes > 0:\n            try:\n                b = r.bytes(1)\n                if b == b\"\\xff\":\n                    if r.bits(4) == 0xf:\n                        return True\n                    r.align()\n                    max_bytes -= 2\n                else:\n                    max_bytes -= 1\n            except BitReaderError:\n                return False\n        return False", "response": "Find the next sync.\n        Returns True if found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the number of channels in the current frame.", "response": "def channels(self):\n        \"\"\"0 means unknown\"\"\"\n\n        assert self.parsed_frames, \"no frame parsed yet\"\n\n        b_index = self._fixed_header_key[6]\n        if b_index == 7:\n            return 8\n        elif b_index > 7:\n            return 0\n        else:\n            return b_index"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef frequency(self):\n\n        assert self.parsed_frames, \"no frame parsed yet\"\n\n        f_index = self._fixed_header_key[4]\n        try:\n            return _FREQS[f_index]\n        except IndexError:\n            return 0", "response": "Return the frequency of the current user s user s user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a single object from the file.", "response": "def delete(filething):\n    \"\"\" delete(filething)\n\n    Arguments:\n        filething (filething)\n    Raises:\n        mutagen.MutagenError\n\n    Remove tags from a file.\n    \"\"\"\n\n    t = OggSpeex(filething)\n    filething.fileobj.seek(0)\n    t.delete(filething)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(filething):\n\n    dsf_file = DSFFile(filething.fileobj)\n\n    if dsf_file.dsd_chunk.offset_metdata_chunk != 0:\n        id3_location = dsf_file.dsd_chunk.offset_metdata_chunk\n        dsf_file.dsd_chunk.offset_metdata_chunk = 0\n        dsf_file.dsd_chunk.write()\n\n        filething.fileobj.seek(id3_location)\n        filething.fileobj.truncate()", "response": "Delete the tags from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filething=None, v2_version=4, v23_sep='/', padding=None):\n\n        fileobj = filething.fileobj\n        fileobj.seek(0)\n\n        dsd_header = DSDChunk(fileobj)\n        if dsd_header.offset_metdata_chunk == 0:\n            # create a new ID3 chunk at the end of the file\n            fileobj.seek(0, 2)\n\n            # store reference to ID3 location\n            dsd_header.offset_metdata_chunk = fileobj.tell()\n            dsd_header.write()\n\n        try:\n            data = self._prepare_data(\n                fileobj, dsd_header.offset_metdata_chunk, self.size,\n                v2_version, v23_sep, padding)\n        except ID3Error as e:\n            reraise(error, e, sys.exc_info()[2])\n\n        fileobj.seek(dsd_header.offset_metdata_chunk)\n        fileobj.write(data)\n        fileobj.truncate()\n\n        # Update total file size\n        dsd_header.total_size = fileobj.tell()\n        dsd_header.write()", "response": "Save the ID3v2 data to the DSF file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning if all data could be read and the atom payload", "response": "def read(self, fileobj):\n        \"\"\"Return if all data could be read and the atom payload\"\"\"\n\n        fileobj.seek(self._dataoffset, 0)\n        data = fileobj.read(self.datalength)\n        return len(data) == self.datalength, data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(name, data):\n        # this raises OverflowError if Py_ssize_t can't handle the atom data\n        size = len(data) + 8\n        if size <= 0xFFFFFFFF:\n            return struct.pack(\">I4s\", size, name) + data\n        else:\n            return struct.pack(\">I4sQ\", 1, name, size + 8) + data", "response": "Render raw atom data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path(self, *names):\n\n        path = [self]\n        for name in names:\n            path.append(path[-1][name, ])\n        return path[1:]", "response": "Look up and return the complete path of an atom."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mkstemp(suffix=None, prefix=None, dir=None, text=False):\n\n    suffix = fsnative() if suffix is None else path2fsn(suffix)\n    prefix = gettempprefix() if prefix is None else path2fsn(prefix)\n    dir = gettempdir() if dir is None else path2fsn(dir)\n\n    return tempfile.mkstemp(suffix, prefix, dir, text)", "response": "Create a temporary file and return its path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a temporary file in a directory.", "response": "def mkdtemp(suffix=None, prefix=None, dir=None):\n    \"\"\"\n    Args:\n        suffix (`pathlike` or `None`): suffix or `None` to use the default\n        prefix (`pathlike` or `None`): prefix or `None` to use the default\n        dir (`pathlike` or `None`): temp dir or `None` to use the default\n    Returns:\n        `fsnative`: A path to a directory\n    Raises:\n        EnvironmentError\n\n    Like :func:`python3:tempfile.mkstemp` but always returns a `fsnative` path.\n    \"\"\"\n\n    suffix = fsnative() if suffix is None else path2fsn(suffix)\n    prefix = gettempprefix() if prefix is None else path2fsn(prefix)\n    dir = gettempdir() if dir is None else path2fsn(dir)\n\n    return tempfile.mkdtemp(suffix, prefix, dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an ASFValue object of a specific kind.", "response": "def ASFValue(value, kind, **kwargs):\n    \"\"\"Create a tag value of a specific kind.\n\n    ::\n\n        ASFValue(u\"My Value\", UNICODE)\n\n    :rtype: ASFBaseAttribute\n    :raises TypeError: in case a wrong type was passed\n    :raises ValueError: in case the value can't be be represented as ASFValue.\n    \"\"\"\n\n    try:\n        attr_type = ASFBaseAttribute._get_type(kind)\n    except KeyError:\n        raise ValueError(\"Unknown value type %r\" % kind)\n    else:\n        return attr_type(value=value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields a series of repaired text values for decoding", "response": "def iter_text_fixups(data, encoding):\n    \"\"\"Yields a series of repaired text values for decoding\"\"\"\n\n    yield data\n    if encoding == Encoding.UTF16BE:\n        # wrong termination\n        yield data + b\"\\x00\"\n    elif encoding == Encoding.UTF16:\n        # wrong termination\n        yield data + b\"\\x00\"\n        # utf-16 is missing BOM, content is usually utf-16-le\n        yield codecs.BOM_UTF16_LE + data\n        # both cases combined\n        yield codecs.BOM_UTF16_LE + data + b\"\\x00\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a sequence of File objects for the given file.", "response": "def File(filething, options=None, easy=False):\n    \"\"\"File(filething, options=None, easy=False)\n\n    Guess the type of the file and try to open it.\n\n    The file type is decided by several things, such as the first 128\n    bytes (which usually contains a file type identifier), the\n    filename extension, and the presence of existing tags.\n\n    If no appropriate type could be found, None is returned.\n\n    Args:\n        filething (filething)\n        options: Sequence of :class:`FileType` implementations,\n            defaults to all included ones.\n        easy (bool):  If the easy wrappers should be returnd if available.\n            For example :class:`EasyMP3 <mp3.EasyMP3>` instead of\n            :class:`MP3 <mp3.MP3>`.\n\n    Returns:\n        FileType: A FileType instance for the detected type or `None` in case\n            the type couln't be determined.\n\n    Raises:\n        MutagenError: in case the detected type fails to load the file.\n    \"\"\"\n\n    if options is None:\n        from mutagen.asf import ASF\n        from mutagen.apev2 import APEv2File\n        from mutagen.flac import FLAC\n        if easy:\n            from mutagen.easyid3 import EasyID3FileType as ID3FileType\n        else:\n            from mutagen.id3 import ID3FileType\n        if easy:\n            from mutagen.mp3 import EasyMP3 as MP3\n        else:\n            from mutagen.mp3 import MP3\n        from mutagen.oggflac import OggFLAC\n        from mutagen.oggspeex import OggSpeex\n        from mutagen.oggtheora import OggTheora\n        from mutagen.oggvorbis import OggVorbis\n        from mutagen.oggopus import OggOpus\n        if easy:\n            from mutagen.trueaudio import EasyTrueAudio as TrueAudio\n        else:\n            from mutagen.trueaudio import TrueAudio\n        from mutagen.wavpack import WavPack\n        if easy:\n            from mutagen.easymp4 import EasyMP4 as MP4\n        else:\n            from mutagen.mp4 import MP4\n        from mutagen.musepack import Musepack\n        from mutagen.monkeysaudio import MonkeysAudio\n        from mutagen.optimfrog import OptimFROG\n        from mutagen.aiff import AIFF\n        from mutagen.aac import AAC\n        from mutagen.smf import SMF\n        from mutagen.dsf import DSF\n        options = [MP3, TrueAudio, OggTheora, OggSpeex, OggVorbis, OggFLAC,\n                   FLAC, AIFF, APEv2File, MP4, ID3FileType, WavPack,\n                   Musepack, MonkeysAudio, OptimFROG, ASF, OggOpus, AAC,\n                   SMF, DSF]\n\n    if not options:\n        return None\n\n    fileobj = filething.fileobj\n\n    try:\n        header = fileobj.read(128)\n    except IOError:\n        header = b\"\"\n\n    # Sort by name after score. Otherwise import order affects\n    # Kind sort order, which affects treatment of things with\n    # equals scores.\n    results = [(Kind.score(filething.name, fileobj, header), Kind.__name__)\n               for Kind in options]\n\n    results = list(izip(results, options))\n    results.sort()\n    (score, name), Kind = results[-1]\n    if score > 0:\n        try:\n            fileobj.seek(0, 0)\n        except IOError:\n            pass\n        return Kind(fileobj, filename=filething.filename)\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pprint(self):\n\n        stream = \"%s (%s)\" % (self.info.pprint(), self.mime[0])\n        try:\n            tags = self.tags.pprint()\n        except AttributeError:\n            return stream\n        else:\n            return stream + ((tags and \"\\n\" + tags) or \"\")", "response": "Prints the information and comment of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef intround(value):\n\n    return int(decimal.Decimal.from_float(\n        value).to_integral_value(decimal.ROUND_HALF_EVEN))", "response": "Given a float returns a rounded int. Should give the same result on Py2 and Py3\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying that the passed fileobj is a file like object which we can use.", "response": "def verify_fileobj(fileobj, writable=False):\n    \"\"\"Verifies that the passed fileobj is a file like object which\n    we can use.\n\n    Args:\n        writable (bool): verify that the file object is writable as well\n\n    Raises:\n        ValueError: In case the object is not a file object that is readable\n            (or writable if required) or is not opened in bytes mode.\n    \"\"\"\n\n    try:\n        data = fileobj.read(0)\n    except Exception:\n        if not hasattr(fileobj, \"read\"):\n            raise ValueError(\"%r not a valid file object\" % fileobj)\n        raise ValueError(\"Can't read from file object %r\" % fileobj)\n\n    if not isinstance(data, bytes):\n        raise ValueError(\n            \"file object %r not opened in binary mode\" % fileobj)\n\n    if writable:\n        try:\n            fileobj.write(b\"\")\n        except Exception:\n            if not hasattr(fileobj, \"write\"):\n                raise ValueError(\"%r not a valid file object\" % fileobj)\n            raise ValueError(\"Can't write to file object %r\" % fileobj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fileobj_name(fileobj):\n\n    value = getattr(fileobj, \"name\", u\"\")\n    if not isinstance(value, (text_type, bytes)):\n        value = text_type(value)\n    return value", "response": "Returns a potential filename for a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadfile(method=True, writable=False, create=False):\n\n    def convert_file_args(args, kwargs):\n        filething = args[0] if args else None\n        filename = kwargs.pop(\"filename\", None)\n        fileobj = kwargs.pop(\"fileobj\", None)\n        return filething, filename, fileobj, args[1:], kwargs\n\n    def wrap(func):\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            filething, filename, fileobj, args, kwargs = \\\n                convert_file_args(args, kwargs)\n            with _openfile(self, filething, filename, fileobj,\n                           writable, create) as h:\n                return func(self, h, *args, **kwargs)\n\n        @wraps(func)\n        def wrapper_func(*args, **kwargs):\n            filething, filename, fileobj, args, kwargs = \\\n                convert_file_args(args, kwargs)\n            with _openfile(None, filething, filename, fileobj,\n                           writable, create) as h:\n                return func(h, *args, **kwargs)\n\n        return wrapper if method else wrapper_func\n\n    return wrap", "response": "A decorator for functions taking a FileThing instance as a first argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_error(exc_src, exc_dest):\n\n    def wrap(func):\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except exc_dest:\n                raise\n            except exc_src as err:\n                reraise(exc_dest, err, sys.exc_info()[2])\n\n        return wrapper\n\n    return wrap", "response": "A decorator for reraising exceptions with a different type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _openfile(instance, filething, filename, fileobj, writable, create):\n\n    assert not create or writable\n\n    # to allow stacked context managers, just pass the result through\n    if isinstance(filething, FileThing):\n        filename = filething.filename\n        fileobj = filething.fileobj\n        filething = None\n\n    if filething is not None:\n        if is_fileobj(filething):\n            fileobj = filething\n        elif hasattr(filething, \"__fspath__\"):\n            filename = filething.__fspath__()\n            if not isinstance(filename, (bytes, text_type)):\n                raise TypeError(\"expected __fspath__() to return a filename\")\n        else:\n            filename = filething\n\n    if instance is not None:\n        # XXX: take \"not writable\" as loading the file..\n        if not writable:\n            instance.filename = filename\n        elif filename is None:\n            filename = getattr(instance, \"filename\", None)\n\n    if fileobj is not None:\n        verify_fileobj(fileobj, writable=writable)\n        yield FileThing(fileobj, filename, filename or fileobj_name(fileobj))\n    elif filename is not None:\n        verify_filename(filename)\n\n        inmemory_fileobj = False\n        try:\n            fileobj = open(filename, \"rb+\" if writable else \"rb\")\n        except IOError as e:\n            if writable and e.errno == errno.EOPNOTSUPP:\n                # Some file systems (gvfs over fuse) don't support opening\n                # files read/write. To make things still work read the whole\n                # file into an in-memory file like object and write it back\n                # later.\n                # https://github.com/quodlibet/mutagen/issues/300\n                try:\n                    with open(filename, \"rb\") as fileobj:\n                        fileobj = BytesIO(fileobj.read())\n                except IOError as e2:\n                    raise MutagenError(e2)\n                inmemory_fileobj = True\n            elif create and e.errno == errno.ENOENT:\n                assert writable\n                try:\n                    fileobj = open(filename, \"wb+\")\n                except IOError as e2:\n                    raise MutagenError(e2)\n            else:\n                raise MutagenError(e)\n\n        with fileobj as fileobj:\n            yield FileThing(fileobj, filename, filename)\n\n            if inmemory_fileobj:\n                assert writable\n                data = fileobj.getvalue()\n                try:\n                    with open(filename, \"wb\") as fileobj:\n                        fileobj.write(data)\n                except IOError as e:\n                    raise MutagenError(e)\n    else:\n        raise TypeError(\"Missing filename or fileobj argument\")", "response": "Open a file and return a FileThing object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hashable(cls):\n\n    # py2\n    assert \"__hash__\" in cls.__dict__\n    # py3\n    assert cls.__dict__[\"__hash__\"] is not None\n    assert \"__eq__\" in cls.__dict__\n\n    cls.__ne__ = lambda self, other: not self.__eq__(other)\n\n    return cls", "response": "Makes sure the class is hashable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enum(cls):\n\n    assert cls.__bases__ == (object,)\n\n    d = dict(cls.__dict__)\n    new_type = type(cls.__name__, (int,), d)\n    new_type.__module__ = cls.__module__\n\n    map_ = {}\n    for key, value in iteritems(d):\n        if key.upper() == key and isinstance(value, integer_types):\n            value_instance = new_type(value)\n            setattr(new_type, key, value_instance)\n            map_[value] = key\n\n    def str_(self):\n        if self in map_:\n            return \"%s.%s\" % (type(self).__name__, map_[self])\n        return \"%d\" % int(self)\n\n    def repr_(self):\n        if self in map_:\n            return \"<%s.%s: %d>\" % (type(self).__name__, map_[self], int(self))\n        return \"%d\" % int(self)\n\n    setattr(new_type, \"__repr__\", repr_)\n    setattr(new_type, \"__str__\", str_)\n\n    return new_type", "response": "A decorator for creating an int enum class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd struct pack and unpack functions to the class", "response": "def _fill_cdata(cls):\n    \"\"\"Add struct pack/unpack functions\"\"\"\n\n    funcs = {}\n    for key, name in [(\"b\", \"char\"), (\"h\", \"short\"),\n                      (\"i\", \"int\"), (\"q\", \"longlong\")]:\n        for echar, esuffix in [(\"<\", \"le\"), (\">\", \"be\")]:\n            esuffix = \"_\" + esuffix\n            for unsigned in [True, False]:\n                s = struct.Struct(echar + (key.upper() if unsigned else key))\n                get_wrapper = lambda f: lambda *a, **k: f(*a, **k)[0]\n                unpack = get_wrapper(s.unpack)\n                unpack_from = get_wrapper(s.unpack_from)\n\n                def get_unpack_from(s):\n                    def unpack_from(data, offset=0):\n                        return s.unpack_from(data, offset)[0], offset + s.size\n                    return unpack_from\n\n                unpack_from = get_unpack_from(s)\n                pack = s.pack\n\n                prefix = \"u\" if unsigned else \"\"\n                if s.size == 1:\n                    esuffix = \"\"\n                bits = str(s.size * 8)\n\n                if unsigned:\n                    max_ = 2 ** (s.size * 8) - 1\n                    min_ = 0\n                else:\n                    max_ = 2 ** (s.size * 8 - 1) - 1\n                    min_ = - 2 ** (s.size * 8 - 1)\n\n                funcs[\"%s%s_min\" % (prefix, name)] = min_\n                funcs[\"%s%s_max\" % (prefix, name)] = max_\n                funcs[\"%sint%s_min\" % (prefix, bits)] = min_\n                funcs[\"%sint%s_max\" % (prefix, bits)] = max_\n\n                funcs[\"%s%s%s\" % (prefix, name, esuffix)] = unpack\n                funcs[\"%sint%s%s\" % (prefix, bits, esuffix)] = unpack\n                funcs[\"%s%s%s_from\" % (prefix, name, esuffix)] = unpack_from\n                funcs[\"%sint%s%s_from\" % (prefix, bits, esuffix)] = unpack_from\n                funcs[\"to_%s%s%s\" % (prefix, name, esuffix)] = pack\n                funcs[\"to_%sint%s%s\" % (prefix, bits, esuffix)] = pack\n\n    for key, func in iteritems(funcs):\n        setattr(cls, key, staticmethod(func))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the size of the file.", "response": "def get_size(fileobj):\n    \"\"\"Returns the size of the file.\n    The position when passed in will be preserved if no error occurs.\n\n    Args:\n        fileobj (fileobj)\n    Returns:\n        int: The size of the file\n    Raises:\n        IOError\n    \"\"\"\n\n    old_pos = fileobj.tell()\n    try:\n        fileobj.seek(0, 2)\n        return fileobj.tell()\n    finally:\n        fileobj.seek(old_pos, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlikes fileobj. read but raises IOError if not enough data is returned.", "response": "def read_full(fileobj, size):\n    \"\"\"Like fileobj.read but raises IOError if not all requested data is\n    returned.\n\n    If you want to distinguish IOError and the EOS case, better handle\n    the error yourself instead of using this.\n\n    Args:\n        fileobj (fileobj)\n        size (int): amount of bytes to read\n    Raises:\n        IOError: In case read fails or not enough data is read\n    \"\"\"\n\n    if size < 0:\n        raise ValueError(\"size must not be negative\")\n\n    data = fileobj.read(size)\n    if len(data) != size:\n        raise IOError\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlikes fileobj. seek - 2 but will not try to go beyond the start", "response": "def seek_end(fileobj, offset):\n    \"\"\"Like fileobj.seek(-offset, 2), but will not try to go beyond the start\n\n    Needed since file objects from BytesIO will not raise IOError and\n    file objects from open() will raise IOError if going to a negative offset.\n    To make things easier for custom implementations, instead of allowing\n    both behaviors, we just don't do it.\n\n    Args:\n        fileobj (fileobj)\n        offset (int): how many bytes away from the end backwards to seek to\n\n    Raises:\n        IOError\n    \"\"\"\n\n    if offset < 0:\n        raise ValueError\n\n    if get_size(fileobj) < offset:\n        fileobj.seek(0, 0)\n    else:\n        fileobj.seek(-offset, 2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize_file(fobj, diff, BUFFER_SIZE=2 ** 16):\n\n    fobj.seek(0, 2)\n    filesize = fobj.tell()\n\n    if diff < 0:\n        if filesize + diff < 0:\n            raise ValueError\n        # truncate flushes internally\n        fobj.truncate(filesize + diff)\n    elif diff > 0:\n        try:\n            while diff:\n                addsize = min(BUFFER_SIZE, diff)\n                fobj.write(b\"\\x00\" * addsize)\n                diff -= addsize\n            fobj.flush()\n        except IOError as e:\n            if e.errno == errno.ENOSPC:\n                # To reduce the chance of corrupt files in case of missing\n                # space try to revert the file expansion back. Of course\n                # in reality every in-file-write can also fail due to COW etc.\n                # Note: IOError gets also raised in flush() due to buffering\n                fobj.truncate(filesize)\n            raise", "response": "Resize a file by diff."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fallback_move(fobj, dest, src, count, BUFFER_SIZE=2 ** 16):\n\n    if dest < 0 or src < 0 or count < 0:\n        raise ValueError\n\n    fobj.seek(0, 2)\n    filesize = fobj.tell()\n\n    if max(dest, src) + count > filesize:\n        raise ValueError(\"area outside of file\")\n\n    if src > dest:\n        moved = 0\n        while count - moved:\n            this_move = min(BUFFER_SIZE, count - moved)\n            fobj.seek(src + moved)\n            buf = fobj.read(this_move)\n            fobj.seek(dest + moved)\n            fobj.write(buf)\n            moved += this_move\n        fobj.flush()\n    else:\n        while count:\n            this_move = min(BUFFER_SIZE, count)\n            fobj.seek(src + count - this_move)\n            buf = fobj.read(this_move)\n            fobj.seek(count + dest - this_move)\n            fobj.write(buf)\n            count -= this_move\n        fobj.flush()", "response": "Moves data around using read () and write()."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_bytes(fobj, size, offset, BUFFER_SIZE=2 ** 16):\n\n    if size < 0 or offset < 0:\n        raise ValueError\n\n    fobj.seek(0, 2)\n    filesize = fobj.tell()\n    movesize = filesize - offset\n\n    if movesize < 0:\n        raise ValueError\n\n    resize_file(fobj, size, BUFFER_SIZE)\n\n    if mmap is not None:\n        try:\n            mmap_move(fobj, offset + size, offset, movesize)\n        except mmap.error:\n            fallback_move(fobj, offset + size, offset, movesize, BUFFER_SIZE)\n    else:\n        fallback_move(fobj, offset + size, offset, movesize, BUFFER_SIZE)", "response": "Insert size bytes of empty space starting at offset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike dict. get but works as the keys() are all filename patterns.", "response": "def dict_match(d, key, default=None):\n    \"\"\"Like __getitem__ but works as if the keys() are all filename patterns.\n    Returns the value of any dict key that matches the passed key.\n\n    Args:\n        d (dict): A dict with filename patterns as keys\n        key (str): A key potentially matching any of the keys\n        default (object): The object to return if no pattern matched the\n            passed in key\n    Returns:\n        object: The dict value where the dict key matched the passed in key.\n            Or default if there was no match.\n    \"\"\"\n\n    if key in d and \"[\" not in key:\n        return d[key]\n    else:\n        for pattern, value in iteritems(d):\n            if fnmatchcase(key, pattern):\n                return value\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_endian(text, encoding, errors=\"strict\", le=True):\n\n    encoding = codecs.lookup(encoding).name\n\n    if encoding == \"utf-16\":\n        if le:\n            return codecs.BOM_UTF16_LE + text.encode(\"utf-16-le\", errors)\n        else:\n            return codecs.BOM_UTF16_BE + text.encode(\"utf-16-be\", errors)\n    elif encoding == \"utf-32\":\n        if le:\n            return codecs.BOM_UTF32_LE + text.encode(\"utf-32-le\", errors)\n        else:\n            return codecs.BOM_UTF32_BE + text.encode(\"utf-32-be\", errors)\n    else:\n        return text.encode(encoding, errors)", "response": "Like text. encode but always returns little endian unicode bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode the data until the first NULL terminator and all data after it.", "response": "def decode_terminated(data, encoding, strict=True):\n    \"\"\"Returns the decoded data until the first NULL terminator\n    and all data after it.\n\n    Args:\n        data (bytes): data to decode\n        encoding (str): The codec to use\n        strict (bool): If True will raise ValueError in case no NULL is found\n            but the available data decoded successfully.\n    Returns:\n        Tuple[`text`, `bytes`]: A tuple containing the decoded text and the\n            remaining data after the found NULL termination.\n\n    Raises:\n        UnicodeError: In case the data can't be decoded.\n        LookupError:In case the encoding is not found.\n        ValueError: In case the data isn't null terminated (even if it is\n            encoded correctly) except if strict is False, then the decoded\n            string will be returned anyway.\n    \"\"\"\n\n    codec_info = codecs.lookup(encoding)\n\n    # normalize encoding name so we can compare by name\n    encoding = codec_info.name\n\n    # fast path\n    if encoding in (\"utf-8\", \"iso8859-1\"):\n        index = data.find(b\"\\x00\")\n        if index == -1:\n            # make sure we raise UnicodeError first, like in the slow path\n            res = data.decode(encoding), b\"\"\n            if strict:\n                raise ValueError(\"not null terminated\")\n            else:\n                return res\n        return data[:index].decode(encoding), data[index + 1:]\n\n    # slow path\n    decoder = codec_info.incrementaldecoder()\n    r = []\n    for i, b in enumerate(iterbytes(data)):\n        c = decoder.decode(b)\n        if c == u\"\\x00\":\n            return u\"\".join(r), data[i + 1:]\n        r.append(c)\n    else:\n        # make sure the decoder is finished\n        r.append(decoder.decode(b\"\", True))\n        if strict:\n            raise ValueError(\"not null terminated\")\n        return u\"\".join(r), b\"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads count bits and returns an uint MSB read first.", "response": "def bits(self, count):\n        \"\"\"Reads `count` bits and returns an uint, MSB read first.\n\n        May raise BitReaderError if not enough data could be read or\n        IOError by the underlying file object.\n        \"\"\"\n\n        if count < 0:\n            raise ValueError\n\n        if count > self._bits:\n            n_bytes = (count - self._bits + 7) // 8\n            data = self._fileobj.read(n_bytes)\n            if len(data) != n_bytes:\n                raise BitReaderError(\"not enough data\")\n            for b in bytearray(data):\n                self._buffer = (self._buffer << 8) | b\n            self._bits += n_bytes * 8\n\n        self._bits -= count\n        value = self._buffer >> self._bits\n        self._buffer &= (1 << self._bits) - 1\n        assert self._bits < 8\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bytes(self, count):\n\n        if count < 0:\n            raise ValueError\n\n        # fast path\n        if self._bits == 0:\n            data = self._fileobj.read(count)\n            if len(data) != count:\n                raise BitReaderError(\"not enough data\")\n            return data\n\n        return bytes(bytearray(self.bits(8) for _ in xrange(count)))", "response": "Returns a bytearray of length count. Works unaligned."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nskips `count` bits. Might raise BitReaderError if there wasn't enough data to skip, but might also fail on the next bits() instead.", "response": "def skip(self, count):\n        \"\"\"Skip `count` bits.\n\n        Might raise BitReaderError if there wasn't enough data to skip,\n        but might also fail on the next bits() instead.\n        \"\"\"\n\n        if count < 0:\n            raise ValueError\n\n        if count <= self._bits:\n            self.bits(count)\n        else:\n            count -= self.align()\n            n_bytes = count // 8\n            self._fileobj.seek(n_bytes, 1)\n            count -= n_bytes * 8\n            self.bits(count)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef align(self):\n\n        bits = self._bits\n        self._buffer = 0\n        self._bits = 0\n        return bits", "response": "Align to the next byte returns the amount of bits skipped"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unicode argv under Windows and standard sys. argv otherwise", "response": "def _get_win_argv():\n    \"\"\"Returns a unicode argv under Windows and standard sys.argv otherwise\n\n    Returns:\n        List[`fsnative`]\n    \"\"\"\n\n    assert is_win\n\n    argc = ctypes.c_int()\n    try:\n        argv = winapi.CommandLineToArgvW(\n            winapi.GetCommandLineW(), ctypes.byref(argc))\n    except WindowsError:\n        return []\n\n    if not argv:\n        return []\n\n    res = argv[max(0, argc.value - len(sys.argv)):argc.value]\n\n    winapi.LocalFree(argv)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the user dir or None", "response": "def _get_userdir(user=None):\n    \"\"\"Returns the user dir or None\"\"\"\n\n    if user is not None and not isinstance(user, fsnative):\n        raise TypeError\n\n    if is_win:\n        if \"HOME\" in environ:\n            path = environ[\"HOME\"]\n        elif \"USERPROFILE\" in environ:\n            path = environ[\"USERPROFILE\"]\n        elif \"HOMEPATH\" in environ and \"HOMEDRIVE\" in environ:\n            path = os.path.join(environ[\"HOMEDRIVE\"], environ[\"HOMEPATH\"])\n        else:\n            return\n\n        if user is None:\n            return path\n        else:\n            return os.path.join(os.path.dirname(path), user)\n    else:\n        import pwd\n\n        if user is None:\n            if \"HOME\" in environ:\n                return environ[\"HOME\"]\n            else:\n                try:\n                    return path2fsn(pwd.getpwuid(os.getuid()).pw_dir)\n                except KeyError:\n                    return\n        else:\n            try:\n                return path2fsn(pwd.getpwnam(user).pw_dir)\n            except KeyError:\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpands user ~ in a path.", "response": "def expanduser(path):\n    \"\"\"\n    Args:\n        path (pathlike): A path to expand\n    Returns:\n        `fsnative`\n\n    Like :func:`python:os.path.expanduser` but supports unicode home\n    directories under Windows + Python 2 and always returns a `fsnative`.\n    \"\"\"\n\n    path = path2fsn(path)\n\n    if path == \"~\":\n        return _get_userdir()\n    elif path.startswith(\"~\" + sep) or (\n            altsep is not None and path.startswith(\"~\" + altsep)):\n        userdir = _get_userdir()\n        if userdir is None:\n            return path\n        return userdir + path[1:]\n    elif path.startswith(\"~\"):\n        sep_index = path.find(sep)\n        if altsep is not None:\n            alt_index = path.find(altsep)\n            if alt_index != -1 and alt_index < sep_index:\n                sep_index = alt_index\n\n        if sep_index == -1:\n            user = path[1:]\n            rest = \"\"\n        else:\n            user = path[1:sep_index]\n            rest = path[sep_index:]\n\n        userdir = _get_userdir(user)\n        if userdir is not None:\n            return userdir + rest\n        else:\n            return path\n    else:\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpands environment variables in a path.", "response": "def expandvars(path):\n    \"\"\"\n    Args:\n        path (pathlike): A path to expand\n    Returns:\n        `fsnative`\n\n    Like :func:`python:os.path.expandvars` but supports unicode under Windows\n    + Python 2 and always returns a `fsnative`.\n    \"\"\"\n\n    path = path2fsn(path)\n\n    def repl_func(match):\n        return environ.get(match.group(1), match.group(0))\n\n    path = re.compile(r\"\\$(\\w+)\", flags=re.UNICODE).sub(repl_func, path)\n    if os.name == \"nt\":\n        path = re.sub(r\"%([^%]+)%\", repl_func, path)\n    return re.sub(r\"\\$\\{([^\\}]+)\\}\", repl_func, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_(*objects, **kwargs):\n\n    sep = kwargs.get(\"sep\")\n    sep = sep if sep is not None else \" \"\n    end = kwargs.get(\"end\")\n    end = end if end is not None else \"\\n\"\n    file = kwargs.get(\"file\")\n    file = file if file is not None else sys.stdout\n    flush = bool(kwargs.get(\"flush\", False))\n\n    if is_win:\n        _print_windows(objects, sep, end, file, flush)\n    else:\n        _print_unix(objects, sep, end, file, flush)", "response": "Print a list of objects to the screen."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _print_unix(objects, sep, end, file, flush):\n\n    encoding = _encoding\n\n    if isinstance(sep, text_type):\n        sep = sep.encode(encoding, \"replace\")\n    if not isinstance(sep, bytes):\n        raise TypeError\n\n    if isinstance(end, text_type):\n        end = end.encode(encoding, \"replace\")\n    if not isinstance(end, bytes):\n        raise TypeError\n\n    if end == b\"\\n\":\n        end = os.linesep\n        if PY3:\n            end = end.encode(\"ascii\")\n\n    parts = []\n    for obj in objects:\n        if not isinstance(obj, text_type) and not isinstance(obj, bytes):\n            obj = text_type(obj)\n        if isinstance(obj, text_type):\n            if PY2:\n                obj = obj.encode(encoding, \"replace\")\n            else:\n                try:\n                    obj = obj.encode(encoding, \"surrogateescape\")\n                except UnicodeEncodeError:\n                    obj = obj.encode(encoding, \"replace\")\n        assert isinstance(obj, bytes)\n        parts.append(obj)\n\n    data = sep.join(parts) + end\n    assert isinstance(data, bytes)\n\n    file = getattr(file, \"buffer\", file)\n\n    try:\n        file.write(data)\n    except TypeError:\n        if PY3:\n            # For StringIO, first try with surrogates\n            surr_data = data.decode(encoding, \"surrogateescape\")\n            try:\n                file.write(surr_data)\n            except (TypeError, ValueError):\n                file.write(data.decode(encoding, \"replace\"))\n        else:\n            # for file like objects with don't support bytes\n            file.write(data.decode(encoding, \"replace\"))\n\n    if flush:\n        file.flush()", "response": "A print_() implementation which writes bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _print_windows(objects, sep, end, file, flush):\n\n    h = winapi.INVALID_HANDLE_VALUE\n\n    try:\n        fileno = file.fileno()\n    except (EnvironmentError, AttributeError):\n        pass\n    else:\n        if fileno == 1:\n            h = winapi.GetStdHandle(winapi.STD_OUTPUT_HANDLE)\n        elif fileno == 2:\n            h = winapi.GetStdHandle(winapi.STD_ERROR_HANDLE)\n\n    encoding = _encoding\n\n    parts = []\n    for obj in objects:\n        if isinstance(obj, bytes):\n            obj = obj.decode(encoding, \"replace\")\n        if not isinstance(obj, text_type):\n            obj = text_type(obj)\n        parts.append(obj)\n\n    if isinstance(sep, bytes):\n        sep = sep.decode(encoding, \"replace\")\n    if not isinstance(sep, text_type):\n        raise TypeError\n\n    if isinstance(end, bytes):\n        end = end.decode(encoding, \"replace\")\n    if not isinstance(end, text_type):\n        raise TypeError\n\n    if end == u\"\\n\":\n        end = os.linesep\n\n    text = sep.join(parts) + end\n    assert isinstance(text, text_type)\n\n    is_console = True\n    if h == winapi.INVALID_HANDLE_VALUE:\n        is_console = False\n    else:\n        # get the default value\n        info = winapi.CONSOLE_SCREEN_BUFFER_INFO()\n        if not winapi.GetConsoleScreenBufferInfo(h, ctypes.byref(info)):\n            is_console = False\n\n    if is_console:\n        # make sure we flush before we apply any console attributes\n        file.flush()\n\n        # try to force a utf-8 code page, use the output CP if that fails\n        cp = winapi.GetConsoleOutputCP()\n        try:\n            encoding = \"utf-8\"\n            if winapi.SetConsoleOutputCP(65001) == 0:\n                encoding = None\n\n            for is_ansi, part in ansi_split(text):\n                if is_ansi:\n                    ansi_state.apply(h, part)\n                else:\n                    if encoding is not None:\n                        data = part.encode(encoding, _surrogatepass)\n                    else:\n                        data = _encode_codepage(cp, part)\n                    os.write(fileno, data)\n        finally:\n            # reset the code page to what we had before\n            winapi.SetConsoleOutputCP(cp)\n    else:\n        # try writing bytes first, so in case of Python 2 StringIO we get\n        # the same type on all platforms\n        try:\n            file.write(text.encode(\"utf-8\", _surrogatepass))\n        except (TypeError, ValueError):\n            file.write(text)\n\n        if flush:\n            file.flush()", "response": "The windows implementation of print_."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _readline_windows():\n\n    try:\n        fileno = sys.stdin.fileno()\n    except (EnvironmentError, AttributeError):\n        fileno = -1\n\n    # In case stdin is replaced, read from that\n    if fileno != 0:\n        return _readline_windows_fallback()\n\n    h = winapi.GetStdHandle(winapi.STD_INPUT_HANDLE)\n    if h == winapi.INVALID_HANDLE_VALUE:\n        return _readline_windows_fallback()\n\n    buf_size = 1024\n    buf = ctypes.create_string_buffer(buf_size * ctypes.sizeof(winapi.WCHAR))\n    read = winapi.DWORD()\n\n    text = u\"\"\n    while True:\n        if winapi.ReadConsoleW(\n                h, buf, buf_size, ctypes.byref(read), None) == 0:\n            if not text:\n                return _readline_windows_fallback()\n            raise ctypes.WinError()\n        data = buf[:read.value * ctypes.sizeof(winapi.WCHAR)]\n        text += data.decode(\"utf-16-le\", _surrogatepass)\n        if text.endswith(u\"\\r\\n\"):\n            return text[:-2]", "response": "Reads a new entry point from the standard input and returns the new entry point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding data using the given codepage.", "response": "def _decode_codepage(codepage, data):\n    \"\"\"\n    Args:\n        codepage (int)\n        data (bytes)\n    Returns:\n        `text`\n\n    Decodes data using the given codepage. If some data can't be decoded\n    using the codepage it will not fail.\n    \"\"\"\n\n    assert isinstance(data, bytes)\n\n    if not data:\n        return u\"\"\n\n    # get the required buffer length first\n    length = winapi.MultiByteToWideChar(codepage, 0, data, len(data), None, 0)\n    if length == 0:\n        raise ctypes.WinError()\n\n    # now decode\n    buf = ctypes.create_unicode_buffer(length)\n    length = winapi.MultiByteToWideChar(\n        codepage, 0, data, len(data), buf, length)\n    if length == 0:\n        raise ctypes.WinError()\n\n    return buf[:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencode text using a given codepage.", "response": "def _encode_codepage(codepage, text):\n    \"\"\"\n    Args:\n        codepage (int)\n        text (text)\n    Returns:\n        `bytes`\n\n    Encode text using the given code page. Will not fail if a char\n    can't be encoded using that codepage.\n    \"\"\"\n\n    assert isinstance(text, text_type)\n\n    if not text:\n        return b\"\"\n\n    size = (len(text.encode(\"utf-16-le\", _surrogatepass)) //\n            ctypes.sizeof(winapi.WCHAR))\n\n    # get the required buffer size\n    length = winapi.WideCharToMultiByte(\n        codepage, 0, text, size, None, 0, None, None)\n    if length == 0:\n        raise ctypes.WinError()\n\n    # decode to the buffer\n    buf = ctypes.create_string_buffer(length)\n    length = winapi.WideCharToMultiByte(\n        codepage, 0, text, size, buf, length, None, None)\n    if length == 0:\n        raise ctypes.WinError()\n    return buf[:length]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a file name for a given file handle.", "response": "def _get_file_name_for_handle(handle):\n    \"\"\"(Windows only) Returns a file name for a file handle.\n\n    Args:\n        handle (winapi.HANDLE)\n    Returns:\n       `text` or `None` if no file name could be retrieved.\n    \"\"\"\n\n    assert is_win\n    assert handle != winapi.INVALID_HANDLE_VALUE\n\n    size = winapi.FILE_NAME_INFO.FileName.offset + \\\n        winapi.MAX_PATH * ctypes.sizeof(winapi.WCHAR)\n    buf = ctypes.create_string_buffer(size)\n\n    if winapi.GetFileInformationByHandleEx is None:\n        # Windows XP\n        return None\n\n    status = winapi.GetFileInformationByHandleEx(\n        handle, winapi.FileNameInfo, buf, size)\n    if status == 0:\n        return None\n\n    name_info = ctypes.cast(\n        buf, ctypes.POINTER(winapi.FILE_NAME_INFO)).contents\n    offset = winapi.FILE_NAME_INFO.FileName.offset\n    data = buf[offset:offset + name_info.FileNameLength]\n    return bytes2fsn(data, \"utf-16-le\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the output device is capable of interpreting ANSI escape codes when print_ is used.", "response": "def supports_ansi_escape_codes(fd):\n    \"\"\"Returns whether the output device is capable of interpreting ANSI escape\n    codes when :func:`print_` is used.\n\n    Args:\n        fd (int): file descriptor (e.g. ``sys.stdout.fileno()``)\n    Returns:\n        `bool`\n    \"\"\"\n\n    if os.isatty(fd):\n        return True\n\n    if not is_win:\n        return False\n\n    # Check for cygwin/msys terminal\n    handle = winapi._get_osfhandle(fd)\n    if handle == winapi.INVALID_HANDLE_VALUE:\n        return False\n\n    if winapi.GetFileType(handle) != winapi.FILE_TYPE_PIPE:\n        return False\n\n    file_name = _get_file_name_for_handle(handle)\n    match = re.match(\n        \"^\\\\\\\\(cygwin|msys)-[a-z0-9]+-pty[0-9]+-(from|to)-master$\", file_name)\n    return match is not None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string encoding of the page header and data.", "response": "def write(self):\n        \"\"\"Return a string encoding of the page header and data.\n\n        A ValueError is raised if the data is too big to fit in a\n        single page.\n        \"\"\"\n\n        data = [\n            struct.pack(\"<4sBBqIIi\", b\"OggS\", self.version, self.__type_flags,\n                        self.position, self.serial, self.sequence, 0)\n        ]\n\n        lacing_data = []\n        for datum in self.packets:\n            quot, rem = divmod(len(datum), 255)\n            lacing_data.append(b\"\\xff\" * quot + chr_(rem))\n        lacing_data = b\"\".join(lacing_data)\n        if not self.complete and lacing_data.endswith(b\"\\x00\"):\n            lacing_data = lacing_data[:-1]\n        data.append(chr_(len(lacing_data)))\n        data.append(lacing_data)\n        data.extend(self.packets)\n        data = b\"\".join(data)\n\n        # Python's CRC is swapped relative to Ogg's needs.\n        # crc32 returns uint prior to py2.6 on some platforms, so force uint\n        crc = (~zlib.crc32(data.translate(cdata.bitswap), -1)) & 0xffffffff\n        # Although we're using to_uint_be, this actually makes the CRC\n        # a proper le integer, since Python's CRC is byteswapped.\n        crc = cdata.to_uint_be(crc).translate(cdata.bitswap)\n        data = data[:22] + crc + data[26:]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef size(self):\n\n        size = 27  # Initial header size\n        for datum in self.packets:\n            quot, rem = divmod(len(datum), 255)\n            size += quot + 1\n        if not self.complete and rem == 0:\n            # Packet contains a multiple of 255 bytes and is not\n            # terminated, so we don't have a \\x00 at the end.\n            size -= 1\n        size += sum(map(len, self.packets))\n        return size", "response": "Total size of the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrenumber all pages belonging to a specified logical stream.", "response": "def renumber(fileobj, serial, start):\n        \"\"\"Renumber pages belonging to a specified logical stream.\n\n        fileobj must be opened with mode r+b or w+b.\n\n        Starting at page number 'start', renumber all pages belonging\n        to logical stream 'serial'. Other pages will be ignored.\n\n        fileobj must point to the start of a valid Ogg page; any\n        occuring after it and part of the specified logical stream\n        will be numbered. No adjustment will be made to the data in\n        the pages nor the granule position; only the page number, and\n        so also the CRC.\n\n        If an error occurs (e.g. non-Ogg data is found), fileobj will\n        be left pointing to the place in the stream the error occured,\n        but the invalid data will be left intact (since this function\n        does not change the total file size).\n        \"\"\"\n\n        number = start\n        while True:\n            try:\n                page = OggPage(fileobj)\n            except EOFError:\n                break\n            else:\n                if page.serial != serial:\n                    # Wrong stream, skip this page.\n                    continue\n                # Changing the number can't change the page size,\n                # so seeking back based on the current size is safe.\n                fileobj.seek(-page.size, 1)\n            page.sequence = number\n            fileobj.write(page.write())\n            fileobj.seek(page.offset + page.size, 0)\n            number += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_packets(pages, strict=False):\n\n        serial = pages[0].serial\n        sequence = pages[0].sequence\n        packets = []\n\n        if strict:\n            if pages[0].continued:\n                raise ValueError(\"first packet is continued\")\n            if not pages[-1].complete:\n                raise ValueError(\"last packet does not complete\")\n        elif pages and pages[0].continued:\n            packets.append([b\"\"])\n\n        for page in pages:\n            if serial != page.serial:\n                raise ValueError(\"invalid serial number in %r\" % page)\n            elif sequence != page.sequence:\n                raise ValueError(\"bad sequence number in %r\" % page)\n            else:\n                sequence += 1\n\n            if page.continued:\n                packets[-1].append(page.packets[0])\n            else:\n                packets.append([page.packets[0]])\n            packets.extend([p] for p in page.packets[1:])\n\n        return [b\"\".join(p) for p in packets]", "response": "Construct a list of packet data from a list of Ogg pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlikes from_packets but tries to preserve the layout of the pages.", "response": "def _from_packets_try_preserve(cls, packets, old_pages):\n        \"\"\"Like from_packets but in case the size and number of the packets\n        is the same as in the given pages the layout of the pages will\n        be copied (the page size and number will match).\n\n        If the packets don't match this behaves like::\n\n            OggPage.from_packets(packets, sequence=old_pages[0].sequence)\n        \"\"\"\n\n        old_packets = cls.to_packets(old_pages)\n\n        if [len(p) for p in packets] != [len(p) for p in old_packets]:\n            # doesn't match, fall back\n            return cls.from_packets(packets, old_pages[0].sequence)\n\n        new_data = b\"\".join(packets)\n        new_pages = []\n        for old in old_pages:\n            new = OggPage()\n            new.sequence = old.sequence\n            new.complete = old.complete\n            new.continued = old.continued\n            new.position = old.position\n            for p in old.packets:\n                data, new_data = new_data[:len(p)], new_data[len(p):]\n                new.packets.append(data)\n            new_pages.append(new)\n        assert not new_data\n\n        return new_pages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct a list of Ogg pages from a list of packet data.", "response": "def from_packets(packets, sequence=0, default_size=4096,\n                     wiggle_room=2048):\n        \"\"\"Construct a list of Ogg pages from a list of packet data.\n\n        The algorithm will generate pages of approximately\n        default_size in size (rounded down to the nearest multiple of\n        255). However, it will also allow pages to increase to\n        approximately default_size + wiggle_room if allowing the\n        wiggle room would finish a packet (only one packet will be\n        finished in this way per page; if the next packet would fit\n        into the wiggle room, it still starts on a new page).\n\n        This method reduces packet fragmentation when packet sizes are\n        slightly larger than the default page size, while still\n        ensuring most pages are of the average size.\n\n        Pages are numbered started at 'sequence'; other information is\n        uninitialized.\n        \"\"\"\n\n        chunk_size = (default_size // 255) * 255\n\n        pages = []\n\n        page = OggPage()\n        page.sequence = sequence\n\n        for packet in packets:\n            page.packets.append(b\"\")\n            while packet:\n                data, packet = packet[:chunk_size], packet[chunk_size:]\n                if page.size < default_size and len(page.packets) < 255:\n                    page.packets[-1] += data\n                else:\n                    # If we've put any packet data into this page yet,\n                    # we need to mark it incomplete. However, we can\n                    # also have just started this packet on an already\n                    # full page, in which case, just start the new\n                    # page with this packet.\n                    if page.packets[-1]:\n                        page.complete = False\n                        if len(page.packets) == 1:\n                            page.position = -1\n                    else:\n                        page.packets.pop(-1)\n                    pages.append(page)\n                    page = OggPage()\n                    page.continued = not pages[-1].complete\n                    page.sequence = pages[-1].sequence + 1\n                    page.packets.append(data)\n\n                if len(packet) < wiggle_room:\n                    page.packets[-1] += packet\n                    packet = b\"\"\n\n        if page.packets:\n            pages.append(page)\n\n        return pages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace old_pages with new_pages within fileobj.", "response": "def replace(cls, fileobj, old_pages, new_pages):\n        \"\"\"Replace old_pages with new_pages within fileobj.\n\n        old_pages must have come from reading fileobj originally.\n        new_pages are assumed to have the 'same' data as old_pages,\n        and so the serial and sequence numbers will be copied, as will\n        the flags for the first and last pages.\n\n        fileobj will be resized and pages renumbered as necessary. As\n        such, it must be opened r+b or w+b.\n        \"\"\"\n\n        if not len(old_pages) or not len(new_pages):\n            raise ValueError(\"empty pages list not allowed\")\n\n        # Number the new pages starting from the first old page.\n        first = old_pages[0].sequence\n        for page, seq in izip(new_pages,\n                              xrange(first, first + len(new_pages))):\n            page.sequence = seq\n            page.serial = old_pages[0].serial\n\n        new_pages[0].first = old_pages[0].first\n        new_pages[0].last = old_pages[0].last\n        new_pages[0].continued = old_pages[0].continued\n\n        new_pages[-1].first = old_pages[-1].first\n        new_pages[-1].last = old_pages[-1].last\n        new_pages[-1].complete = old_pages[-1].complete\n        if not new_pages[-1].complete and len(new_pages[-1].packets) == 1:\n            new_pages[-1].position = -1\n\n        new_data = [cls.write(p) for p in new_pages]\n\n        # Add dummy data or merge the remaining data together so multiple\n        # new pages replace an old one\n        pages_diff = len(old_pages) - len(new_data)\n        if pages_diff > 0:\n            new_data.extend([b\"\"] * pages_diff)\n        elif pages_diff < 0:\n            new_data[pages_diff - 1:] = [b\"\".join(new_data[pages_diff - 1:])]\n\n        # Replace pages one by one. If the sizes match no resize happens.\n        offset_adjust = 0\n        new_data_end = None\n        assert len(old_pages) == len(new_data)\n        for old_page, data in izip(old_pages, new_data):\n            offset = old_page.offset + offset_adjust\n            data_size = len(data)\n            resize_bytes(fileobj, old_page.size, data_size, offset)\n            fileobj.seek(offset, 0)\n            fileobj.write(data)\n            new_data_end = offset + data_size\n            offset_adjust += (data_size - old_page.size)\n\n        # Finally, if there's any discrepency in length, we need to\n        # renumber the pages for the logical stream.\n        if len(old_pages) != len(new_pages):\n            fileobj.seek(new_data_end, 0)\n            serial = new_pages[-1].serial\n            sequence = new_pages[-1].sequence + 1\n            cls.renumber(fileobj, serial, sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the last page of the stream with the given serial number.", "response": "def find_last(fileobj, serial, finishing=False):\n        \"\"\"Find the last page of the stream 'serial'.\n\n        If the file is not multiplexed this function is fast. If it is,\n        it must read the whole the stream.\n\n        This finds the last page in the actual file object, or the last\n        page in the stream (with eos set), whichever comes first.\n\n        If finishing is True it returns the last page which contains a packet\n        finishing on it. If there exist pages but none with finishing packets\n        returns None.\n\n        Returns None in case no page with the serial exists.\n        Raises error in case this isn't a valid ogg stream.\n        Raises IOError.\n        \"\"\"\n\n        # For non-muxed streams, look at the last page.\n        seek_end(fileobj, 256 * 256)\n\n        data = fileobj.read()\n        try:\n            index = data.rindex(b\"OggS\")\n        except ValueError:\n            raise error(\"unable to find final Ogg header\")\n        bytesobj = cBytesIO(data[index:])\n\n        def is_valid(page):\n            return not finishing or page.position != -1\n\n        best_page = None\n        try:\n            page = OggPage(bytesobj)\n        except error:\n            pass\n        else:\n            if page.serial == serial and is_valid(page):\n                if page.last:\n                    return page\n                else:\n                    best_page = page\n            else:\n                best_page = None\n\n        # The stream is muxed, so use the slow way.\n        fileobj.seek(0)\n        try:\n            page = OggPage(fileobj)\n            while True:\n                if page.serial == serial:\n                    if is_valid(page):\n                        best_page = page\n                    if page.last:\n                        break\n                page = OggPage(fileobj)\n            return best_page\n        except error:\n            return best_page\n        except EOFError:\n            return best_page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(self, filething):\n\n        fileobj = filething.fileobj\n\n        try:\n            self.info = self._Info(fileobj)\n            self.tags = self._Tags(fileobj, self.info)\n            self.info._post_tags(fileobj)\n        except (error, IOError) as e:\n            reraise(self._Error, e, sys.exc_info()[2])\n        except EOFError:\n            raise self._Error(\"no appropriate stream found\")", "response": "Load information from a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, filething=None):\n\n        fileobj = filething.fileobj\n\n        self.tags.clear()\n        # TODO: we should delegate the deletion to the subclass and not through\n        # _inject.\n        try:\n            try:\n                self.tags._inject(fileobj, lambda x: 0)\n            except error as e:\n                reraise(self._Error, e, sys.exc_info()[2])\n            except EOFError:\n                raise self._Error(\"no appropriate stream found\")\n        except IOError as e:\n            reraise(self._Error, e, sys.exc_info()[2])", "response": "Delete a file from the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a tag to a file.", "response": "def save(self, filething=None, padding=None):\n        \"\"\"save(filething=None, padding=None)\n\n        Save a tag to a file.\n\n        If no filename is given, the one most recently loaded is used.\n\n        Args:\n            filething (filething)\n            padding (:obj:`mutagen.PaddingFunction`)\n        Raises:\n            mutagen.MutagenError\n        \"\"\"\n\n        try:\n            self.tags._inject(filething.fileobj, padding)\n        except (IOError, error) as e:\n            reraise(self._Error, e, sys.exc_info()[2])\n        except EOFError:\n            raise self._Error(\"no appropriate stream found\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a GUID to the serialized bytes representation", "response": "def guid2bytes(s):\n    \"\"\"Converts a GUID to the serialized bytes representation\"\"\"\n\n    assert isinstance(s, str)\n    assert len(s) == 36\n\n    p = struct.pack\n    return b\"\".join([\n        p(\"<IHH\", int(s[:8], 16), int(s[9:13], 16), int(s[14:18], 16)),\n        p(\">H\", int(s[19:23], 16)),\n        p(\">Q\", int(s[24:], 16))[2:],\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bytes2guid(s):\n\n    assert isinstance(s, bytes)\n\n    u = struct.unpack\n    v = []\n    v.extend(u(\"<IHH\", s[:8]))\n    v.extend(u(\">HQ\", s[8:10] + b\"\\x00\\x00\" + s[10:]))\n    return \"%08X-%04X-%04X-%04X-%012X\" % tuple(v)", "response": "Converts a serialized GUID to a text GUID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a single object from the file.", "response": "def delete(filething):\n    \"\"\" delete(filething)\n\n    Arguments:\n        filething (filething)\n    Raises:\n        mutagen.MutagenError\n\n    Remove tags from a file.\n    \"\"\"\n\n    t = OggOpus(filething)\n    filething.fileobj.seek(0)\n    t.delete(filething)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_full_atom(data):\n\n    if len(data) < 4:\n        raise ValueError(\"not enough data\")\n\n    version = ord(data[0:1])\n    flags = cdata.uint_be(b\"\\x00\" + data[1:4])\n    return version, flags, data[4:]", "response": "Parse a full atom from the data buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a single object from the file.", "response": "def delete(filething):\n    \"\"\" delete(filething)\n\n    Arguments:\n        filething (filething)\n    Raises:\n        mutagen.MutagenError\n\n    Remove tags from a file.\n    \"\"\"\n\n    t = MP4(filething)\n    filething.fileobj.seek(0)\n    t.delete(filething)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the offset table in the specified atom.", "response": "def __update_offset_table(self, fileobj, fmt, atom, delta, offset):\n        \"\"\"Update offset table in the specified atom.\"\"\"\n        if atom.offset > offset:\n            atom.offset += delta\n        fileobj.seek(atom.offset + 12)\n        data = fileobj.read(atom.length - 12)\n        fmt = fmt % cdata.uint_be(data[:4])\n        offsets = struct.unpack(fmt, data[4:])\n        offsets = [o + (0, delta)[offset < o] for o in offsets]\n        fileobj.seek(atom.offset + 16)\n        fileobj.write(struct.pack(fmt, *offsets))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __update_offsets(self, fileobj, atoms, delta, offset):\n        if delta == 0:\n            return\n        moov = atoms[b\"moov\"]\n        for atom in moov.findall(b'stco', True):\n            self.__update_offset_table(fileobj, \">%dI\", atom, delta, offset)\n        for atom in moov.findall(b'co64', True):\n            self.__update_offset_table(fileobj, \">%dQ\", atom, delta, offset)\n        try:\n            for atom in atoms[b\"moof\"].findall(b'tfhd', True):\n                self.__update_tfhd(fileobj, atom, delta, offset)\n        except KeyError:\n            pass", "response": "Update offset tables in all stco and co64 atoms."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, filename):\n\n        self._failed_atoms.clear()\n        self.clear()\n        self.save(filename, padding=lambda x: 0)", "response": "Remove the metadata from the given filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a single STSD atom and return the corresponding object.", "response": "def _parse_stsd(self, atom, fileobj):\n        \"\"\"Sets channels, bits_per_sample, sample_rate and optionally bitrate.\n\n        Can raise MP4StreamInfoError.\n        \"\"\"\n\n        assert atom.name == b\"stsd\"\n\n        ok, data = atom.read(fileobj)\n        if not ok:\n            raise MP4StreamInfoError(\"Invalid stsd\")\n\n        try:\n            version, flags, data = parse_full_atom(data)\n        except ValueError as e:\n            raise MP4StreamInfoError(e)\n\n        if version != 0:\n            raise MP4StreamInfoError(\"Unsupported stsd version\")\n\n        try:\n            num_entries, offset = cdata.uint32_be_from(data, 0)\n        except cdata.error as e:\n            raise MP4StreamInfoError(e)\n\n        if num_entries == 0:\n            return\n\n        # look at the first entry if there is one\n        entry_fileobj = cBytesIO(data[offset:])\n        try:\n            entry_atom = Atom(entry_fileobj)\n        except AtomError as e:\n            raise MP4StreamInfoError(e)\n\n        try:\n            entry = AudioSampleEntry(entry_atom, entry_fileobj)\n        except ASEntryError as e:\n            raise MP4StreamInfoError(e)\n        else:\n            self.channels = entry.channels\n            self.bits_per_sample = entry.sample_size\n            self.sample_rate = entry.sample_rate\n            self.bitrate = entry.bitrate\n            self.codec = entry.codec\n            self.codec_description = entry.codec_description"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, *args, **kwargs):\n\n        super(MP4, self).save(*args, **kwargs)", "response": "Save the current object to the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GASpecificConfig(r, info):\n\n    assert isinstance(info, DecoderSpecificInfo)\n\n    r.skip(1)  # frameLengthFlag\n    dependsOnCoreCoder = r.bits(1)\n    if dependsOnCoreCoder:\n        r.skip(14)\n    extensionFlag = r.bits(1)\n    if not info.channelConfiguration:\n        pce = ProgramConfigElement(r)\n        info.pce_channels = pce.channels\n    if info.audioObjectType == 6 or info.audioObjectType == 20:\n        r.skip(3)\n    if extensionFlag:\n        if info.audioObjectType == 22:\n            r.skip(5 + 11)\n        if info.audioObjectType in (17, 19, 20, 23):\n            r.skip(1 + 1 + 1)\n        extensionFlag3 = r.bits(1)\n        if extensionFlag3 != 0:\n            raise NotImplementedError(\"extensionFlag3 set\")", "response": "Reads GASpecificConfig which is needed to get the data after that base64 encoded version of the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_desc_length_file(cls, fileobj):\n\n        value = 0\n        for i in xrange(4):\n            try:\n                b = cdata.uint8(fileobj.read(1))\n            except cdata.error as e:\n                raise ValueError(e)\n            value = (value << 7) | (b & 0x7f)\n            if not b >> 7:\n                break\n        else:\n            raise ValueError(\"invalid descriptor length\")\n\n        return value", "response": "Parse the descriptor length file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a parsed instance of the called type.", "response": "def parse(cls, fileobj):\n        \"\"\"Returns a parsed instance of the called type.\n        The file position is right after the descriptor after this returns.\n\n        Raises DescriptorError\n        \"\"\"\n\n        try:\n            length = cls._parse_desc_length_file(fileobj)\n        except ValueError as e:\n            raise DescriptorError(e)\n        pos = fileobj.tell()\n        instance = cls(fileobj, length)\n        left = length - (fileobj.tell() - pos)\n        if left < 0:\n            raise DescriptorError(\"descriptor parsing read too much data\")\n        fileobj.seek(left, 1)\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstrings representation of the object type indicator as defined in RFC 3339 section 2. 1. 1.", "response": "def codec_param(self):\n        \"\"\"string\"\"\"\n\n        param = u\".%X\" % self.objectTypeIndication\n        info = self.decSpecificInfo\n        if info is not None:\n            param += u\".%d\" % info.audioObjectType\n        return param"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef codec_desc(self):\n\n        info = self.decSpecificInfo\n        desc = None\n        if info is not None:\n            desc = info.description\n        return desc", "response": "Returns the codec description of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef description(self):\n\n        name = None\n        try:\n            name = self._TYPE_NAMES[self.audioObjectType]\n        except IndexError:\n            pass\n        if name is None:\n            return\n        if self.sbrPresentFlag == 1:\n            name += \"+SBR\"\n        if self.psPresentFlag == 1:\n            name += \"+PS\"\n        return text_type(name)", "response": "returns the name of the audio object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the sample rate of the object in the AOT", "response": "def sample_rate(self):\n        \"\"\"0 means unknown\"\"\"\n\n        if self.sbrPresentFlag == 1:\n            return self.extensionSamplingFrequency\n        elif self.sbrPresentFlag == 0:\n            return self.samplingFrequency\n        else:\n            # these are all types that support SBR\n            aot_can_sbr = (1, 2, 3, 4, 6, 17, 19, 20, 22)\n            if self.audioObjectType not in aot_can_sbr:\n                return self.samplingFrequency\n            # there shouldn't be SBR for > 48KHz\n            if self.samplingFrequency > 24000:\n                return self.samplingFrequency\n            # either samplingFrequency or samplingFrequency * 2\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef channels(self):\n\n        # from ProgramConfigElement()\n        if hasattr(self, \"pce_channels\"):\n            return self.pce_channels\n\n        conf = getattr(\n            self, \"extensionChannelConfiguration\", self.channelConfiguration)\n\n        if conf == 1:\n            if self.psPresentFlag == -1:\n                return 0\n            elif self.psPresentFlag == 1:\n                return 2\n            else:\n                return 1\n        elif conf == 7:\n            return 8\n        elif conf > 7:\n            return 0\n        else:\n            return conf", "response": "get the number of channels in the current user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_audio_object_type(self, r):\n\n        audioObjectType = r.bits(5)\n        if audioObjectType == 31:\n            audioObjectTypeExt = r.bits(6)\n            audioObjectType = 32 + audioObjectTypeExt\n        return audioObjectType", "response": "Returns the audio object type from the given bit stream."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_sampling_freq(self, r):\n\n        samplingFrequencyIndex = r.bits(4)\n        if samplingFrequencyIndex == 0xf:\n            samplingFrequency = r.bits(24)\n        else:\n            try:\n                samplingFrequency = self._FREQS[samplingFrequencyIndex]\n            except IndexError:\n                samplingFrequency = 0\n        return samplingFrequency", "response": "Returns the sampling frequency from the bit stream r."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse(self, r, length):\n\n        def bits_left():\n            return length * 8 - r.get_position()\n\n        self.audioObjectType = self._get_audio_object_type(r)\n        self.samplingFrequency = self._get_sampling_freq(r)\n        self.channelConfiguration = r.bits(4)\n\n        self.sbrPresentFlag = -1\n        self.psPresentFlag = -1\n        if self.audioObjectType in (5, 29):\n            self.extensionAudioObjectType = 5\n            self.sbrPresentFlag = 1\n            if self.audioObjectType == 29:\n                self.psPresentFlag = 1\n            self.extensionSamplingFrequency = self._get_sampling_freq(r)\n            self.audioObjectType = self._get_audio_object_type(r)\n            if self.audioObjectType == 22:\n                self.extensionChannelConfiguration = r.bits(4)\n        else:\n            self.extensionAudioObjectType = 0\n\n        if self.audioObjectType in (1, 2, 3, 4, 6, 7, 17, 19, 20, 21, 22, 23):\n            try:\n                GASpecificConfig(r, self)\n            except NotImplementedError:\n                # unsupported, (warn?)\n                return\n        else:\n            # unsupported\n            return\n\n        if self.audioObjectType in (\n                17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 39):\n            epConfig = r.bits(2)\n            if epConfig in (2, 3):\n                # unsupported\n                return\n\n        if self.extensionAudioObjectType != 5 and bits_left() >= 16:\n            syncExtensionType = r.bits(11)\n            if syncExtensionType == 0x2b7:\n                self.extensionAudioObjectType = self._get_audio_object_type(r)\n\n                if self.extensionAudioObjectType == 5:\n                    self.sbrPresentFlag = r.bits(1)\n                    if self.sbrPresentFlag == 1:\n                        self.extensionSamplingFrequency = \\\n                            self._get_sampling_freq(r)\n                        if bits_left() >= 12:\n                            syncExtensionType = r.bits(11)\n                            if syncExtensionType == 0x548:\n                                self.psPresentFlag = r.bits(1)\n\n                if self.extensionAudioObjectType == 22:\n                    self.sbrPresentFlag = r.bits(1)\n                    if self.sbrPresentFlag == 1:\n                        self.extensionSamplingFrequency = \\\n                            self._get_sampling_freq(r)\n                    self.extensionChannelConfiguration = r.bits(4)", "response": "Parses the ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO - 1462 ISO."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_track(chunk):\n\n    TEMPO, MIDI = range(2)\n\n    # Deviations: The running status should be reset on non midi events, but\n    # some files contain meta events inbetween.\n    # TODO: Offset and time signature are not considered.\n\n    tempos = []\n    events = []\n\n    chunk = bytearray(chunk)\n    deltasum = 0\n    status = 0\n    off = 0\n    while off < len(chunk):\n        delta, off = _var_int(chunk, off)\n        deltasum += delta\n        event_type = chunk[off]\n        off += 1\n        if event_type == 0xFF:\n            meta_type = chunk[off]\n            off += 1\n            num, off = _var_int(chunk, off)\n            # TODO: support offset/time signature\n            if meta_type == 0x51:\n                data = chunk[off:off + num]\n                if len(data) != 3:\n                    raise SMFError\n                tempo = struct.unpack(\">I\", b\"\\x00\" + bytes(data))[0]\n                tempos.append((deltasum, TEMPO, tempo))\n            off += num\n        elif event_type in (0xF0, 0xF7):\n            val, off = _var_int(chunk, off)\n            off += val\n        else:\n            if event_type < 0x80:\n                # if < 0x80 take the type from the previous midi event\n                off += 1\n                event_type = status\n            elif event_type < 0xF0:\n                off += 2\n                status = event_type\n            else:\n                raise SMFError(\"invalid event\")\n\n            if event_type >> 4 in (0xD, 0xC):\n                off -= 1\n\n            events.append((deltasum, MIDI, delta))\n\n    return events, tempos", "response": "Reads a list of events and tempo change events from a chunk of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_midi_length(fileobj):\n\n    TEMPO, MIDI = range(2)\n\n    def read_chunk(fileobj):\n        info = fileobj.read(8)\n        if len(info) != 8:\n            raise SMFError(\"truncated\")\n        chunklen = struct.unpack(\">I\", info[4:])[0]\n        data = fileobj.read(chunklen)\n        if len(data) != chunklen:\n            raise SMFError(\"truncated\")\n        return info[:4], data\n\n    identifier, chunk = read_chunk(fileobj)\n    if identifier != b\"MThd\":\n        raise SMFError(\"Not a MIDI file\")\n\n    if len(chunk) != 6:\n        raise SMFError(\"truncated\")\n\n    format_, ntracks, tickdiv = struct.unpack(\">HHH\", chunk)\n    if format_ > 1:\n        raise SMFError(\"Not supported format %d\" % format_)\n\n    if tickdiv >> 15:\n        # fps = (-(tickdiv >> 8)) & 0xFF\n        # subres = tickdiv & 0xFF\n        # never saw one of those\n        raise SMFError(\"Not supported timing interval\")\n\n    # get a list of events and tempo changes for each track\n    tracks = []\n    first_tempos = None\n    for tracknum in xrange(ntracks):\n        identifier, chunk = read_chunk(fileobj)\n        if identifier != b\"MTrk\":\n            continue\n        events, tempos = _read_track(chunk)\n\n        # In case of format == 1, copy the first tempo list to all tracks\n        first_tempos = first_tempos or tempos\n        if format_ == 1:\n            tempos = list(first_tempos)\n        events += tempos\n        events.sort()\n        tracks.append(events)\n\n    # calculate the duration of each track\n    durations = []\n    for events in tracks:\n        tempo = 500000\n        parts = []\n        deltasum = 0\n        for (dummy, type_, data) in events:\n            if type_ == TEMPO:\n                parts.append((deltasum, tempo))\n                tempo = data\n                deltasum = 0\n            else:\n                deltasum += data\n        parts.append((deltasum, tempo))\n\n        duration = 0\n        for (deltasum, tempo) in parts:\n            quarter, tpq = deltasum / float(tickdiv), tempo\n            duration += (quarter * tpq)\n        duration /= 10 ** 6\n\n        durations.append(duration)\n\n    # return the longest one\n    return max(durations)", "response": "Reads the duration in seconds from the MIDI file. Can raise all kind of errors..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize a codec name.", "response": "def _normalize_codec(codec, _cache={}):\n    \"\"\"Raises LookupError\"\"\"\n\n    try:\n        return _cache[codec]\n    except KeyError:\n        _cache[codec] = codecs.lookup(codec).name\n        return _cache[codec]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _swap_bytes(data):\n\n    a, b = data[1::2], data[::2]\n    data = bytearray().join(bytearray(x) for x in zip(a, b))\n    if len(b) > len(a):\n        data += b[-1:]\n    return bytes(data)", "response": "swaps bytes for 16 bit leaves remaining trailing bytes alone"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn if a codec fails correctly when passing in surrogates with a surrogatepass or surrogateescape error handler.", "response": "def _codec_fails_on_encode_surrogates(codec, _cache={}):\n    \"\"\"Returns if a codec fails correctly when passing in surrogates with\n    a surrogatepass/surrogateescape error handler. Some codecs were broken\n    in Python <3.4\n    \"\"\"\n\n    try:\n        return _cache[codec]\n    except KeyError:\n        try:\n            u\"\\uD800\\uDC01\".encode(codec)\n        except UnicodeEncodeError:\n            _cache[codec] = True\n        else:\n            _cache[codec] = False\n        return _cache[codec]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _codec_can_decode_with_surrogatepass(codec, _cache={}):\n\n    try:\n        return _cache[codec]\n    except KeyError:\n        try:\n            u\"\\ud83d\".encode(\n                codec, _surrogatepass).decode(codec, _surrogatepass)\n        except UnicodeDecodeError:\n            _cache[codec] = False\n        else:\n            _cache[codec] = True\n        return _cache[codec]", "response": "Returns True if a codec supports the surrogatepass error handler when decoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decode_surrogatepass(data, codec):\n\n    try:\n        return data.decode(codec, _surrogatepass)\n    except UnicodeDecodeError:\n        if not _codec_can_decode_with_surrogatepass(codec):\n            if _normalize_codec(codec) == \"utf-16-be\":\n                data = _swap_bytes(data)\n                codec = \"utf-16-le\"\n            if _normalize_codec(codec) == \"utf-16-le\":\n                buffer_ = ctypes.create_string_buffer(data + b\"\\x00\\x00\")\n                value = ctypes.wstring_at(buffer_, len(data) // 2)\n                if value.encode(\"utf-16-le\", _surrogatepass) != data:\n                    raise\n                return value\n            else:\n                raise\n        else:\n            raise", "response": "Like data. decode but makes utf - 16 - le work\n    on Python < 3. 4 + Windows\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _winpath2bytes_py3(text, codec):\n\n    # merge surrogate codepoints\n    if _normalize_codec(codec).startswith(\"utf-16\"):\n        # fast path, utf-16 merges anyway\n        return text.encode(codec, _surrogatepass)\n    return _decode_surrogatepass(\n        text.encode(\"utf-16-le\", _surrogatepass),\n        \"utf-16-le\").encode(codec, _surrogatepass)", "response": "Fallback implementation for text including surrogates in Python 3."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize an fsnative path.", "response": "def fsn2norm(path):\n    \"\"\"\n    Args:\n        path (fsnative): The path to normalize\n    Returns:\n        `fsnative`\n\n    Normalizes an fsnative path.\n\n    The same underlying path can have multiple representations as fsnative\n    (due to surrogate pairs and variable length encodings). When concatenating\n    fsnative the result might be different than concatenating the serialized\n    form and then deserializing it.\n\n    This returns the normalized form i.e. the form which os.listdir() would\n    return. This is useful when you alter fsnative but require that the same\n    underlying path always maps to the same fsnative value.\n\n    All functions like :func:`bytes2fsn`, :func:`fsnative`, :func:`text2fsn`\n    and :func:`path2fsn` always return a normalized path, independent of their\n    input.\n    \"\"\"\n\n    native = _fsn2native(path)\n\n    if is_win:\n        return _decode_surrogatepass(\n            native.encode(\"utf-16-le\", _surrogatepass),\n            \"utf-16-le\")\n    elif PY3:\n        return bytes2fsn(native, None)\n    else:\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _typecheck_fsnative(path):\n\n    if not isinstance(path, fsnative_type):\n        return False\n\n    if PY3 or is_win:\n        if u\"\\x00\" in path:\n            return False\n\n        if is_unix:\n            try:\n                path.encode(_encoding, \"surrogateescape\")\n            except UnicodeEncodeError:\n                return False\n    elif b\"\\x00\" in path:\n        return False\n\n    return True", "response": "Checks if the path is a fsnative file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fsn2native(path):\n\n    if not isinstance(path, fsnative_type):\n        raise TypeError(\"path needs to be %s, not %s\" % (\n            fsnative_type.__name__, type(path).__name__))\n\n    if is_unix:\n        if PY3:\n            try:\n                path = path.encode(_encoding, \"surrogateescape\")\n            except UnicodeEncodeError:\n                # This look more like ValueError, but raising only one error\n                # makes things simpler... also one could say str + surrogates\n                # is its own type\n                raise TypeError(\n                    \"path contained Unicode code points not valid in\"\n                    \"the current path encoding. To create a valid \"\n                    \"path from Unicode use text2fsn()\")\n\n        if b\"\\x00\" in path:\n            raise TypeError(\"fsnative can't contain nulls\")\n    else:\n        if u\"\\x00\" in path:\n            raise TypeError(\"fsnative can't contain nulls\")\n\n    return path", "response": "Convert a path from the filesystem native format to the native format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_encoding():\n\n    encoding = sys.getfilesystemencoding()\n    if encoding is None:\n        if is_darwin:\n            encoding = \"utf-8\"\n        elif is_win:\n            encoding = \"mbcs\"\n        else:\n            encoding = \"ascii\"\n    encoding = _normalize_codec(encoding)\n    return encoding", "response": "The encoding used for paths argv stdout and stdin"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a path like object to a fsnative object.", "response": "def path2fsn(path):\n    \"\"\"\n    Args:\n        path (pathlike): The path to convert\n    Returns:\n        `fsnative`\n    Raises:\n        TypeError: In case the type can't be converted to a `fsnative`\n        ValueError: In case conversion fails\n\n    Returns a `fsnative` path for a `pathlike`.\n    \"\"\"\n\n    # allow mbcs str on py2+win and bytes on py3\n    if PY2:\n        if is_win:\n            if isinstance(path, bytes):\n                path = path.decode(_encoding)\n        else:\n            if isinstance(path, text_type):\n                path = path.encode(_encoding)\n        if \"\\x00\" in path:\n            raise ValueError(\"embedded null\")\n    else:\n        path = getattr(os, \"fspath\", lambda x: x)(path)\n        if isinstance(path, bytes):\n            if b\"\\x00\" in path:\n                raise ValueError(\"embedded null\")\n            path = path.decode(_encoding, \"surrogateescape\")\n        elif is_unix and isinstance(path, str):\n            # make sure we can encode it and this is not just some random\n            # unicode string\n            data = path.encode(_encoding, \"surrogateescape\")\n            if b\"\\x00\" in data:\n                raise ValueError(\"embedded null\")\n            path = fsn2norm(path)\n        else:\n            if u\"\\x00\" in path:\n                raise ValueError(\"embedded null\")\n            path = fsn2norm(path)\n\n    if not isinstance(path, fsnative_type):\n        raise TypeError(\"path needs to be %s\", fsnative_type.__name__)\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fsn2text(path, strict=False):\n\n    path = _fsn2native(path)\n\n    errors = \"strict\" if strict else \"replace\"\n\n    if is_win:\n        return path.encode(\"utf-16-le\", _surrogatepass).decode(\"utf-16-le\",\n                                                               errors)\n    else:\n        return path.decode(_encoding, errors)", "response": "Converts a fsnative path to text."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a path to bytes.", "response": "def fsn2bytes(path, encoding=\"utf-8\"):\n    \"\"\"\n    Args:\n        path (fsnative): The path to convert\n        encoding (`str`): encoding used for Windows\n    Returns:\n        `bytes`\n    Raises:\n        TypeError: If no `fsnative` path is passed\n        ValueError: If encoding fails or the encoding is invalid\n\n    Converts a `fsnative` path to `bytes`.\n\n    The passed *encoding* is only used on platforms where paths are not\n    associated with an encoding (Windows for example).\n\n    For Windows paths, lone surrogates will be encoded like normal code points\n    and surrogate pairs will be merged before encoding. In case of ``utf-8``\n    or ``utf-16-le`` this is equal to the `WTF-8 and WTF-16 encoding\n    <https://simonsapin.github.io/wtf-8/>`__.\n    \"\"\"\n\n    path = _fsn2native(path)\n\n    if is_win:\n        if encoding is None:\n            raise ValueError(\"invalid encoding %r\" % encoding)\n\n        try:\n            return _winpath2bytes(path, encoding)\n        except LookupError:\n            raise ValueError(\"invalid encoding %r\" % encoding)\n    else:\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a bytes path to a fsnative path.", "response": "def bytes2fsn(data, encoding=\"utf-8\"):\n    \"\"\"\n    Args:\n        data (bytes): The data to convert\n        encoding (`str`): encoding used for Windows\n    Returns:\n        `fsnative`\n    Raises:\n        TypeError: If no `bytes` path is passed\n        ValueError: If decoding fails or the encoding is invalid\n\n    Turns `bytes` to a `fsnative` path.\n\n    The passed *encoding* is only used on platforms where paths are not\n    associated with an encoding (Windows for example).\n\n    For Windows paths ``WTF-8`` is accepted if ``utf-8`` is used and\n    ``WTF-16`` accepted if ``utf-16-le`` is used.\n    \"\"\"\n\n    if not isinstance(data, bytes):\n        raise TypeError(\"data needs to be bytes\")\n\n    if is_win:\n        if encoding is None:\n            raise ValueError(\"invalid encoding %r\" % encoding)\n        try:\n            path = _decode_surrogatepass(data, encoding)\n        except LookupError:\n            raise ValueError(\"invalid encoding %r\" % encoding)\n        if u\"\\x00\" in path:\n            raise ValueError(\"contains nulls\")\n        return path\n    else:\n        if b\"\\x00\" in data:\n            raise ValueError(\"contains nulls\")\n        if PY2:\n            return data\n        else:\n            return data.decode(_encoding, \"surrogateescape\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uri2fsn(uri):\n\n    if PY2:\n        if isinstance(uri, text_type):\n            uri = uri.encode(\"utf-8\")\n        if not isinstance(uri, bytes):\n            raise TypeError(\"uri needs to be ascii str or unicode\")\n    else:\n        if not isinstance(uri, str):\n            raise TypeError(\"uri needs to be str\")\n\n    parsed = urlparse(uri)\n    scheme = parsed.scheme\n    netloc = parsed.netloc\n    path = parsed.path\n\n    if scheme != \"file\":\n        raise ValueError(\"Not a file URI: %r\" % uri)\n\n    if not path:\n        raise ValueError(\"Invalid file URI: %r\" % uri)\n\n    uri = urlunparse(parsed)[7:]\n\n    if is_win:\n        try:\n            drive, rest = uri.split(\":\", 1)\n        except ValueError:\n            path = \"\"\n            rest = uri.replace(\"/\", \"\\\\\")\n        else:\n            path = drive[-1] + \":\"\n            rest = rest.replace(\"/\", \"\\\\\")\n        if PY2:\n            path += unquote(rest)\n        else:\n            path += unquote(rest, encoding=\"utf-8\", errors=\"surrogatepass\")\n        if netloc:\n            path = \"\\\\\\\\\" + path\n        if PY2:\n            path = path.decode(\"utf-8\")\n        if u\"\\x00\" in path:\n            raise ValueError(\"embedded null\")\n        return path\n    else:\n        if PY2:\n            path = unquote(uri)\n        else:\n            path = unquote(uri, encoding=_encoding, errors=\"surrogateescape\")\n        if \"\\x00\" in path:\n            raise ValueError(\"embedded null\")\n        return path", "response": "Converts a file URI to a filesystem - native path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fsn2uri(path):\n\n    path = _fsn2native(path)\n\n    def _quote_path(path):\n        # RFC 2396\n        path = quote(path, \"/:@&=+$,\")\n        if PY2:\n            path = path.decode(\"ascii\")\n        return path\n\n    if is_win:\n        buf = ctypes.create_unicode_buffer(winapi.INTERNET_MAX_URL_LENGTH)\n        length = winapi.DWORD(winapi.INTERNET_MAX_URL_LENGTH)\n        flags = 0\n        try:\n            winapi.UrlCreateFromPathW(path, buf, ctypes.byref(length), flags)\n        except WindowsError as e:\n            raise ValueError(e)\n        uri = buf[:length.value]\n\n        # For some reason UrlCreateFromPathW escapes some chars outside of\n        # ASCII and some not. Unquote and re-quote with utf-8.\n        if PY3:\n            # latin-1 maps code points directly to bytes, which is what we want\n            uri = unquote(uri, \"latin-1\")\n        else:\n            # Python 2 does what we want by default\n            uri = unquote(uri)\n\n        return _quote_path(uri.encode(\"utf-8\", _surrogatepass))\n\n    else:\n        return u\"file://\" + _quote_path(path)", "response": "Converts a path to an ASCII only URI."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove tags from a file.", "response": "def delete(filething):\n    \"\"\"Remove tags from a file.\n\n    Args:\n        filething (filething)\n    Raises:\n        mutagen.MutagenError\n    \"\"\"\n\n    f = FLAC(filething)\n    filething.fileobj.seek(0)\n    f.delete(filething)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the content of the block + header. Raises error.", "response": "def _writeblock(cls, block, is_last=False):\n        \"\"\"Returns the block content + header.\n\n        Raises error.\n        \"\"\"\n\n        data = bytearray()\n        code = (block.code | 128) if is_last else block.code\n        datum = block.write()\n        size = len(datum)\n        if size > cls._MAX_SIZE:\n            if block._distrust_size and block._invalid_overflow_size != -1:\n                # The original size of this block was (1) wrong and (2)\n                # the real size doesn't allow us to save the file\n                # according to the spec (too big for 24 bit uint). Instead\n                # simply write back the original wrong size.. at least\n                # we don't make the file more \"broken\" as it is.\n                size = block._invalid_overflow_size\n            else:\n                raise error(\"block is too long to write\")\n        assert not size > cls._MAX_SIZE\n        length = struct.pack(\">I\", size)[-3:]\n        data.append(code)\n        data += length\n        data += datum\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders metadata blocks as a byte string.", "response": "def _writeblocks(cls, blocks, available, cont_size, padding_func):\n        \"\"\"Render metadata block as a byte string.\"\"\"\n\n        # write everything except padding\n        data = bytearray()\n        for block in blocks:\n            if isinstance(block, Padding):\n                continue\n            data += cls._writeblock(block)\n        blockssize = len(data)\n\n        # take the padding overhead into account. we always add one\n        # to make things simple.\n        padding_block = Padding()\n        blockssize += len(cls._writeblock(padding_block))\n\n        # finally add a padding block\n        info = PaddingInfo(available - blockssize, cont_size)\n        padding_block.length = min(info._get_padding(padding_func),\n                                   cls._MAX_SIZE)\n        data += cls._writeblock(padding_block, is_last=True)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_tags(self):\n        if self.tags is None:\n            self.tags = VCFLACDict()\n            self.metadata_blocks.append(self.tags)\n        else:\n            raise FLACVorbisError(\"a Vorbis comment already exists\")", "response": "Add a Vorbis comment block to the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, filething=None):\n\n        if self.tags is not None:\n            temp_blocks = [\n                b for b in self.metadata_blocks if b.code != VCFLACDict.code]\n            self._save(filething, temp_blocks, False, padding=lambda x: 0)\n            self.metadata_blocks[:] = [\n                b for b in self.metadata_blocks\n                if b.code != VCFLACDict.code or b is self.tags]\n            self.tags.clear()", "response": "Remove Vorbis comments from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads file information from a filename.", "response": "def load(self, filething):\n        \"\"\"Load file information from a filename.\"\"\"\n\n        fileobj = filething.fileobj\n\n        self.metadata_blocks = []\n        self.tags = None\n        self.cuesheet = None\n        self.seektable = None\n\n        fileobj = StrictFileObject(fileobj)\n        self.__check_header(fileobj, filething.name)\n        while self.__read_metadata_block(fileobj):\n            pass\n\n        try:\n            self.metadata_blocks[0].length\n        except (AttributeError, IndexError):\n            raise FLACNoHeaderError(\"Stream info block not found\")\n\n        if self.info.length:\n            start = fileobj.tell()\n            fileobj.seek(0, 2)\n            self.info.bitrate = int(\n                float(fileobj.tell() - start) * 8 / self.info.length)\n        else:\n            self.info.bitrate = 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_pictures(self):\n\n        blocks = [b for b in self.metadata_blocks if b.code != Picture.code]\n        self.metadata_blocks = blocks", "response": "Delete all pictures from the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting of embedded pictures", "response": "def pictures(self):\n        \"\"\"list[Picture]: List of embedded pictures\"\"\"\n\n        return [b for b in self.metadata_blocks if b.code == Picture.code]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the metadata blocks to a file.", "response": "def save(self, filething=None, deleteid3=False, padding=None):\n        \"\"\"Save metadata blocks to a file.\n\n        Args:\n            filething (filething)\n            deleteid3 (bool): delete id3 tags while at it\n            padding (:obj:`mutagen.PaddingFunction`)\n\n        If no filename is given, the one most recently loaded is used.\n        \"\"\"\n\n        self._save(filething, self.metadata_blocks, deleteid3, padding)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake item from argv and returns ascii native str Raises ValueError.", "response": "def frame_from_fsnative(arg):\n    \"\"\"Takes item from argv and returns ascii native str\n    or raises ValueError.\n    \"\"\"\n\n    assert isinstance(arg, fsnative)\n\n    text = fsn2text(arg, strict=True)\n    if PY2:\n        return text.encode(\"ascii\")\n    else:\n        return text.encode(\"ascii\").decode(\"ascii\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake an item from argv and returns a text_type value without surrogate escapes.", "response": "def value_from_fsnative(arg, escape):\n    \"\"\"Takes an item from argv and returns a text_type value without\n    surrogate escapes or raises ValueError.\n    \"\"\"\n\n    assert isinstance(arg, fsnative)\n\n    if escape:\n        bytes_ = fsn2bytes(arg)\n        if PY2:\n            bytes_ = bytes_.decode(\"string_escape\")\n        else:\n            # With py3.7 this has started to warn for invalid escapes, but we\n            # don't control the input so ignore it.\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                bytes_ = codecs.escape_decode(bytes_)[0]\n        arg = bytes2fsn(bytes_)\n\n    text = fsn2text(arg, strict=True)\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nskipping the next ID3 from the file - like object fileobj.", "response": "def skip_id3(fileobj):\n    \"\"\"Might raise IOError\"\"\"\n\n    # WMP writes multiple id3s, so skip as many as we find\n    while True:\n        idata = fileobj.read(10)\n        try:\n            id3, insize = struct.unpack('>3sxxx4s', idata)\n        except struct.error:\n            id3, insize = b'', 0\n        insize = BitPaddedInt(insize)\n        if id3 == b'ID3' and insize > 0:\n            fileobj.seek(insize, 1)\n        else:\n            fileobj.seek(-len(idata), 1)\n            break"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over a fileobj and yields on each mpeg sync.", "response": "def iter_sync(fileobj, max_read):\n    \"\"\"Iterate over a fileobj and yields on each mpeg sync.\n\n    When yielding the fileobj offset is right before the sync and can be\n    changed between iterations without affecting the iteration process.\n\n    Might raise IOError.\n    \"\"\"\n\n    read = 0\n    size = 2\n    last_byte = b\"\"\n    is_second = lambda b: ord(b) & 0xe0 == 0xe0\n\n    while read < max_read:\n        data_offset = fileobj.tell()\n        new_data = fileobj.read(min(max_read - read, size))\n        if not new_data:\n            return\n        read += len(new_data)\n\n        if last_byte == b\"\\xff\" and is_second(new_data[0:1]):\n            fileobj.seek(data_offset - 1, 0)\n            yield\n\n        size *= 2\n        last_byte = new_data[-1:]\n\n        find_offset = 0\n        while True:\n            index = new_data.find(b\"\\xff\", find_offset)\n            # if not found or the last byte -> read more\n            if index == -1 or index == len(new_data) - 1:\n                break\n\n            if is_second(new_data[index + 1:index + 2]):\n                fileobj.seek(data_offset + index, 0)\n                yield\n            find_offset = index + 1\n\n        fileobj.seek(data_offset + len(new_data), 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_vbr_header(self, fileobj, frame_offset, frame_size,\n                          frame_length):\n        \"\"\"Does not raise\"\"\"\n\n        # Xing\n        xing_offset = XingHeader.get_offset(self)\n        fileobj.seek(frame_offset + xing_offset, 0)\n        try:\n            xing = XingHeader(fileobj)\n        except XingHeaderError:\n            pass\n        else:\n            lame = xing.lame_header\n            self.sketchy = False\n            self.bitrate_mode = _guess_xing_bitrate_mode(xing)\n            self.encoder_settings = xing.get_encoder_settings()\n            if xing.frames != -1:\n                samples = frame_size * xing.frames\n                if xing.bytes != -1 and samples > 0:\n                    # the first frame is only included in xing.bytes but\n                    # not in xing.frames, skip it.\n                    audio_bytes = max(0, xing.bytes - frame_length)\n                    self.bitrate = intround((\n                        audio_bytes * 8 * self.sample_rate) / float(samples))\n                if lame is not None:\n                    samples -= lame.encoder_delay_start\n                    samples -= lame.encoder_padding_end\n                if samples < 0:\n                    # older lame versions wrote bogus delay/padding for short\n                    # files with low bitrate\n                    samples = 0\n                self.length = float(samples) / self.sample_rate\n            if xing.lame_version_desc:\n                self.encoder_info = u\"LAME %s\" % xing.lame_version_desc\n            if lame is not None:\n                self.track_gain = lame.track_gain_adjustment\n                self.track_peak = lame.track_peak\n                self.album_gain = lame.album_gain_adjustment\n            return\n\n        # VBRI\n        vbri_offset = VBRIHeader.get_offset(self)\n        fileobj.seek(frame_offset + vbri_offset, 0)\n        try:\n            vbri = VBRIHeader(fileobj)\n        except VBRIHeaderError:\n            pass\n        else:\n            self.bitrate_mode = BitrateMode.VBR\n            self.encoder_info = u\"FhG\"\n            self.sketchy = False\n            self.length = float(frame_size * vbri.frames) / self.sample_rate\n            if self.length:\n                self.bitrate = int((vbri.bytes * 8) / self.length)", "response": "Parses the VBR header and sets the appropriate attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef RegisterTextKey(cls, key, frameid):\n        def getter(id3, key):\n            return list(id3[frameid])\n\n        def setter(id3, key, value):\n            try:\n                frame = id3[frameid]\n            except KeyError:\n                id3.add(mutagen.id3.Frames[frameid](encoding=3, text=value))\n            else:\n                frame.encoding = 3\n                frame.text = value\n\n        def deleter(id3, key):\n            del(id3[frameid])\n\n        cls.RegisterKey(key, getter, setter, deleter)", "response": "Register a text key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RegisterTXXXKey(cls, key, desc):\n        frameid = \"TXXX:\" + desc\n\n        def getter(id3, key):\n            return list(id3[frameid])\n\n        def setter(id3, key, value):\n            enc = 0\n            # Store 8859-1 if we can, per MusicBrainz spec.\n            for v in value:\n                if v and max(v) > u'\\x7f':\n                    enc = 3\n                    break\n\n            id3.add(mutagen.id3.TXXX(encoding=enc, text=value, desc=desc))\n\n        def deleter(id3, key):\n            del(id3[frameid])\n\n        cls.RegisterKey(key, getter, setter, deleter)", "response": "Register a user - defined text frame key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the current ID3 object to a file.", "response": "def save(self, filething=None, v1=1, v2_version=4, v23_sep='/',\n             padding=None):\n        \"\"\"save(filething=None, v1=1, v2_version=4, v23_sep='/', padding=None)\n\n        Save changes to a file.\n        See :meth:`mutagen.id3.ID3.save` for more info.\n        \"\"\"\n\n        if v2_version == 3:\n            # EasyID3 only works with v2.4 frames, so update_to_v23() would\n            # break things. We have to save a shallow copy of all tags\n            # and restore it after saving. Due to CHAP/CTOC copying has\n            # to be done recursively implemented in ID3Tags.\n            backup = self.__id3._copy()\n            try:\n                self.__id3.update_to_v23()\n                self.__id3.save(\n                    filething, v1=v1, v2_version=v2_version, v23_sep=v23_sep,\n                    padding=padding)\n            finally:\n                self.__id3._restore(backup)\n        else:\n            self.__id3.save(filething, v1=v1, v2_version=v2_version,\n                            v23_sep=v23_sep, padding=padding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(filething):\n\n    try:\n        t = APEv2(filething)\n    except APENoHeaderError:\n        return\n    filething.fileobj.seek(0)\n    t.delete(filething)", "response": "Delete a tag from a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a _APEValue subclass or raises ValueError", "response": "def _get_value_type(kind):\n    \"\"\"Returns a _APEValue subclass or raises ValueError\"\"\"\n\n    if kind == TEXT:\n        return APETextValue\n    elif kind == BINARY:\n        return APEBinaryValue\n    elif kind == EXTERNAL:\n        return APEExtValue\n    raise ValueError(\"unknown kind %r\" % kind)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef APEValue(value, kind):\n\n    try:\n        type_ = _get_value_type(kind)\n    except ValueError:\n        raise ValueError(\"kind must be TEXT, BINARY, or EXTERNAL\")\n    else:\n        return type_(value)", "response": "APEv2 tag value factory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns tag key = value pairs in a human - readable format.", "response": "def pprint(self):\n        \"\"\"Return tag key=value pairs in a human-readable format.\"\"\"\n\n        items = sorted(self.items())\n        return u\"\\n\".join(u\"%s=%s\" % (k, v.pprint()) for k, v in items)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, filething):\n\n        data = _APEv2Data(filething.fileobj)\n\n        if data.tag:\n            self.clear()\n            self.__parse_tag(data.tag, data.items)\n        else:\n            raise APENoHeaderError(\"No APE tag found\")", "response": "Load tags from a file object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the tag and stores the data in the object.", "response": "def __parse_tag(self, tag, count):\n        \"\"\"Raises IOError and APEBadItemError\"\"\"\n\n        fileobj = cBytesIO(tag)\n\n        for i in xrange(count):\n            tag_data = fileobj.read(8)\n            # someone writes wrong item counts\n            if not tag_data:\n                break\n            if len(tag_data) != 8:\n                raise error\n            size = cdata.uint32_le(tag_data[:4])\n            flags = cdata.uint32_le(tag_data[4:8])\n\n            # Bits 1 and 2 bits are flags, 0-3\n            # Bit 0 is read/write flag, ignored\n            kind = (flags & 6) >> 1\n            if kind == 3:\n                raise APEBadItemError(\"value type must be 0, 1, or 2\")\n\n            key = value = fileobj.read(1)\n            if not key:\n                raise APEBadItemError\n            while key[-1:] != b'\\x00' and value:\n                value = fileobj.read(1)\n                if not value:\n                    raise APEBadItemError\n                key += value\n            if key[-1:] == b\"\\x00\":\n                key = key[:-1]\n\n            if PY3:\n                try:\n                    key = key.decode(\"ascii\")\n                except UnicodeError as err:\n                    reraise(APEBadItemError, err, sys.exc_info()[2])\n            value = fileobj.read(size)\n            if len(value) != size:\n                raise APEBadItemError\n\n            value = _get_value_type(kind)._new(value)\n\n            self[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, filething=None):\n\n        fileobj = filething.fileobj\n\n        data = _APEv2Data(fileobj)\n\n        if data.is_at_start:\n            delete_bytes(fileobj, data.end - data.start, data.start)\n        elif data.start is not None:\n            fileobj.seek(data.start)\n            # Delete an ID3v1 tag if present, too.\n            fileobj.truncate()\n        fileobj.seek(0, 2)\n\n        tags = []\n        for key, value in self.items():\n            # Packed format for an item:\n            # 4B: Value length\n            # 4B: Value type\n            # Key name\n            # 1B: Null\n            # Key value\n            value_data = value._write()\n            if not isinstance(key, bytes):\n                key = key.encode(\"utf-8\")\n            tag_data = bytearray()\n            tag_data += struct.pack(\"<2I\", len(value_data), value.kind << 1)\n            tag_data += key + b\"\\0\" + value_data\n            tags.append(bytes(tag_data))\n\n        # \"APE tags items should be sorted ascending by size... This is\n        # not a MUST, but STRONGLY recommended. Actually the items should\n        # be sorted by importance/byte, but this is not feasible.\"\n        tags.sort(key=lambda tag: (len(tag), tag))\n        num_tags = len(tags)\n        tags = b\"\".join(tags)\n\n        header = bytearray(b\"APETAGEX\")\n        # version, tag size, item count, flags\n        header += struct.pack(\"<4I\", 2000, len(tags) + 32, num_tags,\n                              HAS_HEADER | IS_HEADER)\n        header += b\"\\0\" * 8\n        fileobj.write(header)\n\n        fileobj.write(tags)\n\n        footer = bytearray(b\"APETAGEX\")\n        footer += struct.pack(\"<4I\", 2000, len(tags) + 32, num_tags,\n                              HAS_HEADER)\n        footer += b\"\\0\" * 8\n\n        fileobj.write(footer)", "response": "Save the current state of the APE tags to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, filething=None):\n\n        fileobj = filething.fileobj\n        data = _APEv2Data(fileobj)\n        if data.start is not None and data.size is not None:\n            delete_bytes(fileobj, data.end - data.start, data.start)\n        self.clear()", "response": "Remove tags from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ansi_split(text, _re=re.compile(u\"(\\x1b\\\\[(\\\\d*;?)*\\\\S)\")):\n\n    for part in _re.split(text):\n        if part:\n            yield (bool(_re.match(part)), part)", "response": "Yields a list of boolean values for ANSI text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pprint(self):\n\n        s = u\"ASF (%s) %d bps, %s Hz, %d channels, %.2f seconds\" % (\n            self.codec_type or self.codec_name or u\"???\", self.bitrate,\n            self.sample_rate, self.channels, self.length)\n        return s", "response": "Returns a string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_dict(self):\n\n        d = {}\n        for key, value in self:\n            d.setdefault(key, []).append(value)\n        return d", "response": "Return a copy of the comment data in a real dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, filething):\n\n        fileobj = filething.fileobj\n\n        self.info = ASFInfo()\n        self.tags = ASFTags()\n\n        self._tags = {}\n        self._header = HeaderObject.parse_full(self, fileobj)\n\n        for guid in [ContentDescriptionObject.GUID,\n                     ExtendedContentDescriptionObject.GUID,\n                     MetadataObject.GUID,\n                     MetadataLibraryObject.GUID]:\n            self.tags.extend(self._tags.pop(guid, []))\n\n        assert not self._tags", "response": "Load an ASF from a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, filething=None, padding=None):\n\n        # Move attributes to the right objects\n        self.to_content_description = {}\n        self.to_extended_content_description = {}\n        self.to_metadata = {}\n        self.to_metadata_library = []\n        for name, value in self.tags:\n            library_only = (value.data_size() > 0xFFFF or value.TYPE == GUID)\n            can_cont_desc = value.TYPE == UNICODE\n\n            if library_only or value.language is not None:\n                self.to_metadata_library.append((name, value))\n            elif value.stream is not None:\n                if name not in self.to_metadata:\n                    self.to_metadata[name] = value\n                else:\n                    self.to_metadata_library.append((name, value))\n            elif name in ContentDescriptionObject.NAMES:\n                if name not in self.to_content_description and can_cont_desc:\n                    self.to_content_description[name] = value\n                else:\n                    self.to_metadata_library.append((name, value))\n            else:\n                if name not in self.to_extended_content_description:\n                    self.to_extended_content_description[name] = value\n                else:\n                    self.to_metadata_library.append((name, value))\n\n        # Add missing objects\n        header = self._header\n        if header.get_child(ContentDescriptionObject.GUID) is None:\n            header.objects.append(ContentDescriptionObject())\n        if header.get_child(ExtendedContentDescriptionObject.GUID) is None:\n            header.objects.append(ExtendedContentDescriptionObject())\n        header_ext = header.get_child(HeaderExtensionObject.GUID)\n        if header_ext is None:\n            header_ext = HeaderExtensionObject()\n            header.objects.append(header_ext)\n        if header_ext.get_child(MetadataObject.GUID) is None:\n            header_ext.objects.append(MetadataObject())\n        if header_ext.get_child(MetadataLibraryObject.GUID) is None:\n            header_ext.objects.append(MetadataLibraryObject())\n\n        fileobj = filething.fileobj\n        # Render to file\n        old_size = header.parse_size(fileobj)[0]\n        data = header.render_full(self, fileobj, old_size, padding)\n        size = len(data)\n        resize_bytes(fileobj, old_size, size, 0)\n        fileobj.seek(0)\n        fileobj.write(data)", "response": "Save the current state of the object to the loaded file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a file from the cache.", "response": "def delete(self, filething=None):\n        \"\"\"delete(filething=None)\n\n        Args:\n            filething (filething)\n        Raises:\n            mutagen.MutagenError\n        \"\"\"\n\n        self.tags.clear()\n        self.save(filething, padding=lambda x: 0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _upgrade_frame(self):\n\n        # turn 2.2 into 2.3/2.4 tags\n        if len(type(self).__name__) == 3:\n            base = type(self).__base__\n            if base is Frame:\n                return\n            return base(self)\n        else:\n            return self", "response": "Returns either this instance or a new instance if this is a v2. 2 instance and an upgrade path is viable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_v23_frame(self, **kwargs):\n\n        new_kwargs = {}\n        for checker in self._framespec:\n            name = checker.name\n            value = getattr(self, name)\n            new_kwargs[name] = checker._validate23(self, value, **kwargs)\n\n        for checker in self._optionalspec:\n            name = checker.name\n            if hasattr(self, name):\n                value = getattr(self, name)\n                new_kwargs[name] = checker._validate23(self, value, **kwargs)\n\n        return type(self)(**new_kwargs)", "response": "Returns a copy of the current object which is suitable for writing into a v2. 3 tag."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _readData(self, id3, data):\n\n        for reader in self._framespec:\n            if len(data) or reader.handle_nodata:\n                try:\n                    value, data = reader.read(id3, self, data)\n                except SpecError as e:\n                    raise ID3JunkFrameError(e)\n            else:\n                raise ID3JunkFrameError(\"no data left\")\n            self._setattr(reader.name, value)\n\n        for reader in self._optionalspec:\n            if len(data) or reader.handle_nodata:\n                try:\n                    value, data = reader.read(id3, self, data)\n                except SpecError as e:\n                    raise ID3JunkFrameError(e)\n            else:\n                break\n            self._setattr(reader.name, value)\n\n        return data", "response": "Raises ID3JunkFrameError ; Returns leftover data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the data for the current ID3Save.", "response": "def _writeData(self, config=None):\n        \"\"\"Raises error\"\"\"\n\n        if config is None:\n            config = ID3SaveConfig()\n\n        if config.v2_version == 3:\n            frame = self._get_v23_frame(sep=config.v23_separator)\n        else:\n            frame = self\n\n        data = []\n        for writer in self._framespec:\n            try:\n                data.append(\n                    writer.write(config, frame, getattr(frame, writer.name)))\n            except SpecError as e:\n                raise error(e)\n\n        for writer in self._optionalspec:\n            try:\n                data.append(\n                    writer.write(config, frame, getattr(frame, writer.name)))\n            except AttributeError:\n                break\n            except SpecError as e:\n                raise error(e)\n\n        return b''.join(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fromData(cls, header, tflags, data):\n\n        if header.version >= header._V24:\n            if tflags & (Frame.FLAG24_COMPRESS | Frame.FLAG24_DATALEN):\n                # The data length int is syncsafe in 2.4 (but not 2.3).\n                # However, we don't actually need the data length int,\n                # except to work around a QL 0.12 bug, and in that case\n                # all we need are the raw bytes.\n                datalen_bytes = data[:4]\n                data = data[4:]\n            if tflags & Frame.FLAG24_UNSYNCH or header.f_unsynch:\n                try:\n                    data = unsynch.decode(data)\n                except ValueError:\n                    # Some things write synch-unsafe data with either the frame\n                    # or global unsynch flag set. Try to load them as is.\n                    # https://github.com/quodlibet/mutagen/issues/210\n                    # https://github.com/quodlibet/mutagen/issues/223\n                    pass\n            if tflags & Frame.FLAG24_ENCRYPT:\n                raise ID3EncryptionUnsupportedError\n            if tflags & Frame.FLAG24_COMPRESS:\n                try:\n                    data = zlib.decompress(data)\n                except zlib.error:\n                    # the initial mutagen that went out with QL 0.12 did not\n                    # write the 4 bytes of uncompressed size. Compensate.\n                    data = datalen_bytes + data\n                    try:\n                        data = zlib.decompress(data)\n                    except zlib.error as err:\n                        raise ID3JunkFrameError(\n                            'zlib: %s: %r' % (err, data))\n\n        elif header.version >= header._V23:\n            if tflags & Frame.FLAG23_COMPRESS:\n                usize, = unpack('>L', data[:4])\n                data = data[4:]\n            if tflags & Frame.FLAG23_ENCRYPT:\n                raise ID3EncryptionUnsupportedError\n            if tflags & Frame.FLAG23_COMPRESS:\n                try:\n                    data = zlib.decompress(data)\n                except zlib.error as err:\n                    raise ID3JunkFrameError('zlib: %s: %r' % (err, data))\n\n        frame = cls()\n        frame._readData(header, data)\n        return frame", "response": "Construct a new ID3 frame from raw string data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a guess about the encoder settings used.", "response": "def guess_settings(self, major, minor):\n        \"\"\"Gives a guess about the encoder settings used. Returns an empty\n        string if unknown.\n\n        The guess is mostly correct in case the file was encoded with\n        the default options (-V --preset --alt-preset --abr -b etc) and no\n        other fancy options.\n\n        Args:\n            major (int)\n            minor (int)\n        Returns:\n            text\n        \"\"\"\n\n        version = major, minor\n\n        if self.vbr_method == 2:\n            if version in ((3, 90), (3, 91), (3, 92)) and self.encoding_flags:\n                if self.bitrate < 255:\n                    return u\"--alt-preset %d\" % self.bitrate\n                else:\n                    return u\"--alt-preset %d+\" % self.bitrate\n            if self.preset_used != 0:\n                return u\"--preset %d\" % self.preset_used\n            elif self.bitrate < 255:\n                return u\"--abr %d\" % self.bitrate\n            else:\n                return u\"--abr %d+\" % self.bitrate\n        elif self.vbr_method == 1:\n            if self.preset_used == 0:\n                if self.bitrate < 255:\n                    return u\"-b %d\" % self.bitrate\n                else:\n                    return u\"-b 255+\"\n            elif self.preset_used == 1003:\n                return u\"--preset insane\"\n            return u\"-b %d\" % self.preset_used\n        elif version in ((3, 90), (3, 91), (3, 92)):\n            preset_key = (self.vbr_quality, self.quality, self.vbr_method,\n                          self.lowpass_filter, self.ath_type)\n            if preset_key == (1, 2, 4, 19500, 3):\n                return u\"--preset r3mix\"\n            if preset_key == (2, 2, 3, 19000, 4):\n                return u\"--alt-preset standard\"\n            if preset_key == (2, 2, 3, 19500, 2):\n                return u\"--alt-preset extreme\"\n\n            if self.vbr_method == 3:\n                return u\"-V %s\" % self.vbr_quality\n            elif self.vbr_method in (4, 5):\n                return u\"-V %s --vbr-new\" % self.vbr_quality\n        elif version in ((3, 93), (3, 94), (3, 95), (3, 96), (3, 97)):\n            if self.preset_used == 1001:\n                return u\"--preset standard\"\n            elif self.preset_used == 1002:\n                return u\"--preset extreme\"\n            elif self.preset_used == 1004:\n                return u\"--preset fast standard\"\n            elif self.preset_used == 1005:\n                return u\"--preset fast extreme\"\n            elif self.preset_used == 1006:\n                return u\"--preset medium\"\n            elif self.preset_used == 1007:\n                return u\"--preset fast medium\"\n\n            if self.vbr_method == 3:\n                return u\"-V %s\" % self.vbr_quality\n            elif self.vbr_method in (4, 5):\n                return u\"-V %s --vbr-new\" % self.vbr_quality\n        elif version == (3, 98):\n            if self.vbr_method == 3:\n                return u\"-V %s --vbr-old\" % self.vbr_quality\n            elif self.vbr_method in (4, 5):\n                return u\"-V %s\" % self.vbr_quality\n        elif version >= (3, 99):\n            if self.vbr_method == 3:\n                return u\"-V %s --vbr-old\" % self.vbr_quality\n            elif self.vbr_method in (4, 5):\n                p = self.vbr_quality\n                adjust_key = (p, self.bitrate, self.lowpass_filter)\n                # https://sourceforge.net/p/lame/bugs/455/\n                p = {\n                    (5, 32, 0): 7,\n                    (5, 8, 0): 8,\n                    (6, 8, 0): 9,\n                }.get(adjust_key, p)\n                return u\"-V %s\" % p\n\n        return u\"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the LAME version string and return a tuple of major minor flag and False if a LAMEHeader follows.", "response": "def parse_version(cls, fileobj):\n        \"\"\"Returns a version string and True if a LAMEHeader follows.\n        The passed file object will be positioned right before the\n        lame header if True.\n\n        Raises LAMEError if there is no lame version info.\n        \"\"\"\n\n        # http://wiki.hydrogenaud.io/index.php?title=LAME_version_string\n\n        data = fileobj.read(20)\n        if len(data) != 20:\n            raise LAMEError(\"Not a lame header\")\n        if not data.startswith((b\"LAME\", b\"L3.99\")):\n            raise LAMEError(\"Not a lame header\")\n\n        data = data.lstrip(b\"EMAL\")\n        major, data = data[0:1], data[1:].lstrip(b\".\")\n        minor = b\"\"\n        for c in iterbytes(data):\n            if not c.isdigit():\n                break\n            minor += c\n        data = data[len(minor):]\n\n        try:\n            major = int(major.decode(\"ascii\"))\n            minor = int(minor.decode(\"ascii\"))\n        except ValueError:\n            raise LAMEError\n\n        # the extended header was added sometimes in the 3.90 cycle\n        # e.g. \"LAME3.90 (alpha)\" should still stop here.\n        # (I have seen such a file)\n        if (major, minor) < (3, 90) or (\n                (major, minor) == (3, 90) and data[-11:-10] == b\"(\"):\n            flag = data.strip(b\"\\x00\").rstrip().decode(\"ascii\")\n            return (major, minor), u\"%d.%d%s\" % (major, minor, flag), False\n\n        if len(data) < 11:\n            raise LAMEError(\"Invalid version: too long\")\n\n        flag = data[:-11].rstrip(b\"\\x00\")\n\n        flag_string = u\"\"\n        patch = u\"\"\n        if flag == b\"a\":\n            flag_string = u\" (alpha)\"\n        elif flag == b\"b\":\n            flag_string = u\" (beta)\"\n        elif flag == b\"r\":\n            patch = u\".1+\"\n        elif flag == b\" \":\n            if (major, minor) > (3, 96):\n                patch = u\".0\"\n            else:\n                patch = u\".0+\"\n        elif flag == b\"\" or flag == b\".\":\n            patch = u\".0+\"\n        else:\n            flag_string = u\" (?)\"\n\n        # extended header, seek back to 9 bytes for the caller\n        fileobj.seek(-11, 1)\n\n        return (major, minor), \\\n            u\"%d.%d%s%s\" % (major, minor, patch, flag_string), True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_encoder_settings(self):\n\n        if self.lame_header is None:\n            return u\"\"\n        return self.lame_header.guess_settings(*self.lame_version)", "response": "Returns the guessed encoder settings"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_offset(cls, info):\n\n        assert info.layer == 3\n\n        if info.version == 1:\n            if info.mode != 3:\n                return 36\n            else:\n                return 21\n        else:\n            if info.mode != 3:\n                return 21\n            else:\n                return 13", "response": "Calculate the offset to the Xing header from the start of the base of the base of the base of the base of the base of the base of the base of the base of the base of the base of the base of the base of the MPEG header."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_windows_env_var(key):\n\n    if not isinstance(key, text_type):\n        raise TypeError(\"%r not of type %r\" % (key, text_type))\n\n    buf = ctypes.create_unicode_buffer(32767)\n\n    stored = winapi.GetEnvironmentVariableW(key, buf, 32767)\n    if stored == 0:\n        raise ctypes.WinError()\n    return buf[:stored]", "response": "Get an env var."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_windows_env_var(key, value):\n\n    if not isinstance(key, text_type):\n        raise TypeError(\"%r not of type %r\" % (key, text_type))\n\n    if not isinstance(value, text_type):\n        raise TypeError(\"%r not of type %r\" % (value, text_type))\n\n    status = winapi.SetEnvironmentVariableW(key, value)\n    if status == 0:\n        raise ctypes.WinError()", "response": "Set an env var."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting an env var.", "response": "def del_windows_env_var(key):\n    \"\"\"Delete an env var.\n\n    Raises:\n        WindowsError\n    \"\"\"\n\n    if not isinstance(key, text_type):\n        raise TypeError(\"%r not of type %r\" % (key, text_type))\n\n    status = winapi.SetEnvironmentVariableW(key, None)\n    if status == 0:\n        raise ctypes.WinError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_windows_environ():\n\n    res = winapi.GetEnvironmentStringsW()\n    if not res:\n        raise ctypes.WinError()\n\n    res = ctypes.cast(res, ctypes.POINTER(ctypes.c_wchar))\n\n    done = []\n    current = u\"\"\n    i = 0\n    while 1:\n        c = res[i]\n        i += 1\n        if c == u\"\\x00\":\n            if not current:\n                break\n            done.append(current)\n            current = u\"\"\n            continue\n        current += c\n\n    dict_ = {}\n    for entry in done:\n        try:\n            key, value = entry.split(u\"=\", 1)\n        except ValueError:\n            continue\n        key = _norm_key(key)\n        dict_[key] = value\n\n    status = winapi.FreeEnvironmentStringsW(res)\n    if status == 0:\n        raise ctypes.WinError()\n\n    return dict_", "response": "Reads the Windows environment and returns a unicode dict of the keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlikes os. getenv but returns unicode under Windows + Python 2", "response": "def getenv(key, value=None):\n    \"\"\"Like `os.getenv` but returns unicode under Windows + Python 2\n\n    Args:\n        key (pathlike): The env var to get\n        value (object): The value to return if the env var does not exist\n    Returns:\n        `fsnative` or `object`:\n            The env var or the passed value if it doesn't exist\n    \"\"\"\n\n    key = path2fsn(key)\n    if is_win and PY2:\n        return environ.get(key, value)\n    return os.getenv(key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unsetenv(key):\n\n    key = path2fsn(key)\n    if is_win:\n        # python 3 has no unsetenv under Windows -> use our ctypes one as well\n        try:\n            del_windows_env_var(key)\n        except WindowsError:\n            pass\n    else:\n        os.unsetenv(key)", "response": "Like os. unsetenv but takes unicode under Windows + Python 2\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef putenv(key, value):\n\n    key = path2fsn(key)\n    value = path2fsn(value)\n\n    if is_win and PY2:\n        try:\n            set_windows_env_var(key, value)\n        except WindowsError:\n            # py3 + win fails here\n            raise ValueError\n    else:\n        try:\n            os.putenv(key, value)\n        except OSError:\n            # win + py3 raise here for invalid keys which is probably a bug.\n            # ValueError seems better\n            raise ValueError", "response": "Like os. putenv but takes unicode under Windows + Python 2\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new _WavPackHeader instance from a file - like object.", "response": "def from_fileobj(cls, fileobj):\n        \"\"\"A new _WavPackHeader or raises WavPackHeaderError\"\"\"\n\n        header = fileobj.read(32)\n        if len(header) != 32 or not header.startswith(b\"wvpk\"):\n            raise WavPackHeaderError(\"not a WavPack header: %r\" % header)\n\n        block_size = cdata.uint_le(header[4:8])\n        version = cdata.ushort_le(header[8:10])\n        track_no = ord(header[10:11])\n        index_no = ord(header[11:12])\n        samples = cdata.uint_le(header[12:16])\n        if samples == 2 ** 32 - 1:\n            samples = -1\n        block_index = cdata.uint_le(header[16:20])\n        block_samples = cdata.uint_le(header[20:24])\n        flags = cdata.uint_le(header[24:28])\n        crc = cdata.uint_le(header[28:32])\n\n        return _WavPackHeader(block_size, version, track_no, index_no,\n                              samples, block_index, block_samples, flags, crc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the frames from the data buffer and returns a list of objects.", "response": "def read_frames(id3, data, frames):\n    \"\"\"Does not error out\"\"\"\n\n    assert id3.version >= ID3Header._V22\n\n    result = []\n    unsupported_frames = []\n\n    if id3.version < ID3Header._V24 and id3.f_unsynch:\n        try:\n            data = unsynch.decode(data)\n        except ValueError:\n            pass\n\n    if id3.version >= ID3Header._V23:\n        if id3.version < ID3Header._V24:\n            bpi = int\n        else:\n            bpi = determine_bpi(data, frames)\n\n        while data:\n            header = data[:10]\n            try:\n                name, size, flags = struct.unpack('>4sLH', header)\n            except struct.error:\n                break  # not enough header\n            if name.strip(b'\\x00') == b'':\n                break\n\n            size = bpi(size)\n            framedata = data[10:10 + size]\n            data = data[10 + size:]\n            if size == 0:\n                continue  # drop empty frames\n\n            if PY3:\n                try:\n                    name = name.decode('ascii')\n                except UnicodeDecodeError:\n                    continue\n\n            try:\n                # someone writes 2.3 frames with 2.2 names\n                if name[-1] == \"\\x00\":\n                    tag = Frames_2_2[name[:-1]]\n                    name = tag.__base__.__name__\n\n                tag = frames[name]\n            except KeyError:\n                if is_valid_frame_id(name):\n                    unsupported_frames.append(header + framedata)\n            else:\n                try:\n                    result.append(tag._fromData(id3, flags, framedata))\n                except NotImplementedError:\n                    unsupported_frames.append(header + framedata)\n                except ID3JunkFrameError:\n                    pass\n    elif id3.version >= ID3Header._V22:\n        while data:\n            header = data[0:6]\n            try:\n                name, size = struct.unpack('>3s3s', header)\n            except struct.error:\n                break  # not enough header\n            size, = struct.unpack('>L', b'\\x00' + size)\n            if name.strip(b'\\x00') == b'':\n                break\n\n            framedata = data[6:6 + size]\n            data = data[6 + size:]\n            if size == 0:\n                continue  # drop empty frames\n\n            if PY3:\n                try:\n                    name = name.decode('ascii')\n                except UnicodeDecodeError:\n                    continue\n\n            try:\n                tag = frames[name]\n            except KeyError:\n                if is_valid_frame_id(name):\n                    unsupported_frames.append(header + framedata)\n            else:\n                try:\n                    result.append(\n                        tag._fromData(id3, 0, framedata))\n                except (ID3EncryptionUnsupportedError,\n                        NotImplementedError):\n                    unsupported_frames.append(header + framedata)\n                except ID3JunkFrameError:\n                    pass\n\n    return result, unsupported_frames, data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setall(self, key, values):\n\n        self.delall(key)\n        for tag in values:\n            self[tag.HashKey] = tag", "response": "Delete frames of the given type and add frames in values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add(self, frame, strict):\n\n        if not isinstance(frame, Frame):\n            raise TypeError(\"%r not a Frame instance\" % frame)\n\n        orig_frame = frame\n        frame = frame._upgrade_frame()\n        if frame is None:\n            if not strict:\n                return\n            raise TypeError(\n                \"Can't upgrade %r frame\" % type(orig_frame).__name__)\n\n        hash_key = frame.HashKey\n        if strict or hash_key not in self:\n            self[hash_key] = frame\n            return\n\n        # Try to merge frames, or change the new one. Since changing\n        # the new one can lead to new conflicts, try until everything is\n        # either merged or added.\n        while True:\n            old_frame = self[hash_key]\n            new_frame = old_frame._merge_frame(frame)\n            new_hash = new_frame.HashKey\n            if new_hash == hash_key:\n                self[hash_key] = new_frame\n                break\n            else:\n                assert new_frame is frame\n                if new_hash not in self:\n                    self[new_hash] = new_frame\n                    break\n                hash_key = new_hash", "response": "Add a frame to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __update_common(self):\n\n        if \"TCON\" in self:\n            # Get rid of \"(xx)Foobr\" format.\n            self[\"TCON\"].genres = self[\"TCON\"].genres\n\n        mimes = {\"PNG\": \"image/png\", \"JPG\": \"image/jpeg\"}\n        for pic in self.getall(\"APIC\"):\n            if pic.mime in mimes:\n                newpic = APIC(\n                    encoding=pic.encoding, mime=mimes[pic.mime],\n                    type=pic.type, desc=pic.desc, data=pic.data)\n                self.add(newpic)", "response": "Updates done by both v23 and v24 update"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_to_v24(self):\n\n        self.__update_common()\n\n        # TDAT, TYER, and TIME have been turned into TDRC.\n        try:\n            date = text_type(self.get(\"TYER\", \"\"))\n            if date.strip(u\"\\x00\"):\n                self.pop(\"TYER\")\n                dat = text_type(self.get(\"TDAT\", \"\"))\n                if dat.strip(\"\\x00\"):\n                    self.pop(\"TDAT\")\n                    date = \"%s-%s-%s\" % (date, dat[2:], dat[:2])\n                    time = text_type(self.get(\"TIME\", \"\"))\n                    if time.strip(\"\\x00\"):\n                        self.pop(\"TIME\")\n                        date += \"T%s:%s:00\" % (time[:2], time[2:])\n                if \"TDRC\" not in self:\n                    self.add(TDRC(encoding=0, text=date))\n        except UnicodeDecodeError:\n            # Old ID3 tags have *lots* of Unicode problems, so if TYER\n            # is bad, just chuck the frames.\n            pass\n\n        # TORY can be the first part of a TDOR.\n        if \"TORY\" in self:\n            f = self.pop(\"TORY\")\n            if \"TDOR\" not in self:\n                try:\n                    self.add(TDOR(encoding=0, text=str(f)))\n                except UnicodeDecodeError:\n                    pass\n\n        # IPLS is now TIPL.\n        if \"IPLS\" in self:\n            f = self.pop(\"IPLS\")\n            if \"TIPL\" not in self:\n                self.add(TIPL(encoding=f.encoding, people=f.people))\n\n        # These can't be trivially translated to any ID3v2.4 tags, or\n        # should have been removed already.\n        for key in [\"RVAD\", \"EQUA\", \"TRDA\", \"TSIZ\", \"TDAT\", \"TIME\"]:\n            if key in self:\n                del(self[key])\n\n        # Recurse into chapters\n        for f in self.getall(\"CHAP\"):\n            f.sub_frames.update_to_v24()\n        for f in self.getall(\"CTOC\"):\n            f.sub_frames.update_to_v24()", "response": "Convert old ID3v2 tags into ID3v2. 4 tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _copy(self):\n\n        items = self.items()\n        subs = {}\n        for f in (self.getall(\"CHAP\") + self.getall(\"CTOC\")):\n            subs[f.HashKey] = f.sub_frames._copy()\n        return (items, subs)", "response": "Creates a shallow copy of all tags"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _restore(self, value):\n\n        items, subs = value\n        self.clear()\n        for key, value in items:\n            self[key] = value\n            if key in subs:\n                value.sub_frames._restore(subs[key])", "response": "Restores the state copied with _copy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a single tag from a file.", "response": "def delete(filething):\n    \"\"\" delete(filething)\n\n    Arguments:\n        filething (filething)\n    Raises:\n        mutagen.MutagenError\n\n    Remove tags from a file.\n    \"\"\"\n\n    t = OggTheora(filething)\n    filething.fileobj.seek(0)\n    t.delete(filething)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nliking unicode. split but allows for the separator to be escaped", "response": "def split_escape(string, sep, maxsplit=None, escape_char=\"\\\\\"):\n    \"\"\"Like unicode/str/bytes.split but allows for the separator to be escaped\n\n    If passed unicode/str/bytes will only return list of unicode/str/bytes.\n    \"\"\"\n\n    assert len(sep) == 1\n    assert len(escape_char) == 1\n\n    if isinstance(string, bytes):\n        if isinstance(escape_char, text_type):\n            escape_char = escape_char.encode(\"ascii\")\n        iter_ = iterbytes\n    else:\n        iter_ = iter\n\n    if maxsplit is None:\n        maxsplit = len(string)\n\n    empty = string[:0]\n    result = []\n    current = empty\n    escaped = False\n    for char in iter_(string):\n        if escaped:\n            if char != escape_char and char != sep:\n                current += escape_char\n            current += char\n            escaped = False\n        else:\n            if char == escape_char:\n                escaped = True\n            elif char == sep and len(result) < maxsplit:\n                result.append(current)\n                current = empty\n            else:\n                current += char\n    result.append(current)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef block(self):\n\n        self._nosig = True\n        yield\n        self._nosig = False\n        if self._interrupted:\n            raise SystemExit(\"Aborted...\")", "response": "Context manager context manager context manager will be blocked and exit the program if interrupted."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid_key(key):\n\n    if PY3 and isinstance(key, bytes):\n        raise TypeError(\"needs to be str not bytes\")\n\n    for c in key:\n        if c < \" \" or c > \"}\" or c == \"=\":\n            return False\n    else:\n        return bool(key)", "response": "Return True if a string is a valid Vorbis comment key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a Vorbis comment from a file - like object.", "response": "def load(self, fileobj, errors='replace', framing=True):\n        \"\"\"Parse a Vorbis comment from a file-like object.\n\n        Arguments:\n            errors (str): 'strict', 'replace', or 'ignore'.\n                This affects Unicode decoding and how other malformed content\n                is interpreted.\n            framing (bool): if true, fail if a framing bit is not present\n\n        Framing bits are required by the Vorbis comment specification,\n        but are not used in FLAC Vorbis comment blocks.\n        \"\"\"\n\n        try:\n            vendor_length = cdata.uint_le(fileobj.read(4))\n            self.vendor = fileobj.read(vendor_length).decode('utf-8', errors)\n            count = cdata.uint_le(fileobj.read(4))\n            for i in xrange(count):\n                length = cdata.uint_le(fileobj.read(4))\n                try:\n                    string = fileobj.read(length).decode('utf-8', errors)\n                except (OverflowError, MemoryError):\n                    raise error(\"cannot read %d bytes, too large\" % length)\n                try:\n                    tag, value = string.split('=', 1)\n                except ValueError as err:\n                    if errors == \"ignore\":\n                        continue\n                    elif errors == \"replace\":\n                        tag, value = u\"unknown%d\" % i, string\n                    else:\n                        reraise(VorbisEncodingError, err, sys.exc_info()[2])\n                try:\n                    tag = tag.encode('ascii', errors)\n                except UnicodeEncodeError:\n                    raise VorbisEncodingError(\"invalid tag name %r\" % tag)\n                else:\n                    # string keys in py3k\n                    if PY3:\n                        tag = tag.decode(\"ascii\")\n                    if is_valid_key(tag):\n                        self.append((tag, value))\n\n            if framing and not bytearray(fileobj.read(1))[0] & 0x01:\n                raise VorbisUnsetFrameError(\"framing bit was unset\")\n        except (cdata.error, TypeError):\n            raise error(\"file is not a valid Vorbis comment\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self):\n\n        if not isinstance(self.vendor, text_type):\n            if PY3:\n                raise ValueError(\"vendor needs to be str\")\n\n            try:\n                self.vendor.decode('utf-8')\n            except UnicodeDecodeError:\n                raise ValueError\n\n        for key, value in self:\n            try:\n                if not is_valid_key(key):\n                    raise ValueError(\"%r is not a valid key\" % key)\n            except TypeError:\n                raise ValueError(\"%r is not a valid key\" % key)\n\n            if not isinstance(value, text_type):\n                if PY3:\n                    err = \"%r needs to be str for key %r\" % (value, key)\n                    raise ValueError(err)\n\n                try:\n                    value.decode(\"utf-8\")\n                except Exception:\n                    err = \"%r is not a valid value for key %r\" % (value, key)\n                    raise ValueError(err)\n\n        return True", "response": "Validate the keys and values of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_id3v1(fileobj, v2_version=4, known_frames=None):\n\n    if v2_version not in (3, 4):\n        raise ValueError(\"Only 3 and 4 possible for v2_version\")\n\n    # id3v1 is always at the end (after apev2)\n\n    extra_read = b\"APETAGEX\".index(b\"TAG\")\n\n    old_pos = fileobj.tell()\n    try:\n        fileobj.seek(-128 - extra_read, 2)\n    except IOError as e:\n        if e.errno == errno.EINVAL:\n            # If the file is too small, might be ok since we wrote too small\n            # tags at some point. let's see how the parsing goes..\n            fileobj.seek(0, 0)\n        else:\n            raise\n\n    data = fileobj.read(128 + extra_read)\n    fileobj.seek(old_pos, 0)\n    try:\n        idx = data.index(b\"TAG\")\n    except ValueError:\n        return (None, 0)\n    else:\n        # FIXME: make use of the apev2 parser here\n        # if TAG is part of APETAGEX assume this is an APEv2 tag\n        try:\n            ape_idx = data.index(b\"APETAGEX\")\n        except ValueError:\n            pass\n        else:\n            if idx == ape_idx + extra_read:\n                return (None, 0)\n\n        tag = ParseID3v1(data[idx:], v2_version, known_frames)\n        if tag is None:\n            return (None, 0)\n\n        offset = idx - len(data)\n        return (tag, offset)", "response": "Find the ID3v1 tag in the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ParseID3v1(data, v2_version=4, known_frames=None):\n\n    if v2_version not in (3, 4):\n        raise ValueError(\"Only 3 and 4 possible for v2_version\")\n\n    try:\n        data = data[data.index(b\"TAG\"):]\n    except ValueError:\n        return None\n    if 128 < len(data) or len(data) < 124:\n        return None\n\n    # Issue #69 - Previous versions of Mutagen, when encountering\n    # out-of-spec TDRC and TYER frames of less than four characters,\n    # wrote only the characters available - e.g. \"1\" or \"\" - into the\n    # year field. To parse those, reduce the size of the year field.\n    # Amazingly, \"0s\" works as a struct format string.\n    unpack_fmt = \"3s30s30s30s%ds29sBB\" % (len(data) - 124)\n\n    try:\n        tag, title, artist, album, year, comment, track, genre = unpack(\n            unpack_fmt, data)\n    except StructError:\n        return None\n\n    if tag != b\"TAG\":\n        return None\n\n    def fix(data):\n        return data.split(b\"\\x00\")[0].strip().decode('latin1')\n\n    title, artist, album, year, comment = map(\n        fix, [title, artist, album, year, comment])\n\n    frame_class = {\n        \"TIT2\": TIT2,\n        \"TPE1\": TPE1,\n        \"TALB\": TALB,\n        \"TYER\": TYER,\n        \"TDRC\": TDRC,\n        \"COMM\": COMM,\n        \"TRCK\": TRCK,\n        \"TCON\": TCON,\n    }\n    for key in frame_class:\n        if known_frames is not None:\n            if key in known_frames:\n                frame_class[key] = known_frames[key]\n            else:\n                frame_class[key] = None\n\n    frames = {}\n    if title and frame_class[\"TIT2\"]:\n        frames[\"TIT2\"] = frame_class[\"TIT2\"](encoding=0, text=title)\n    if artist and frame_class[\"TPE1\"]:\n        frames[\"TPE1\"] = frame_class[\"TPE1\"](encoding=0, text=[artist])\n    if album and frame_class[\"TALB\"]:\n        frames[\"TALB\"] = frame_class[\"TALB\"](encoding=0, text=album)\n    if year:\n        if v2_version == 3 and frame_class[\"TYER\"]:\n            frames[\"TYER\"] = frame_class[\"TYER\"](encoding=0, text=year)\n        elif frame_class[\"TDRC\"]:\n            frames[\"TDRC\"] = frame_class[\"TDRC\"](encoding=0, text=year)\n    if comment and frame_class[\"COMM\"]:\n        frames[\"COMM\"] = frame_class[\"COMM\"](\n            encoding=0, lang=\"eng\", desc=\"ID3v1 Comment\", text=comment)\n\n    # Don't read a track number if it looks like the comment was\n    # padded with spaces instead of nulls (thanks, WinAmp).\n    if (track and frame_class[\"TRCK\"] and\n            ((track != 32) or (data[-3] == b'\\x00'[0]))):\n        frames[\"TRCK\"] = TRCK(encoding=0, text=str(track))\n    if genre != 255 and frame_class[\"TCON\"]:\n        frames[\"TCON\"] = TCON(encoding=0, text=str(genre))\n    return frames", "response": "Parses an ID3v1 tag returning a list of ID3v2 frames or None."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking an ID3v1. 1 tag string from a dict of ID3v2. 4 frames.", "response": "def MakeID3v1(id3):\n    \"\"\"Return an ID3v1.1 tag string from a dict of ID3v2.4 frames.\"\"\"\n\n    v1 = {}\n\n    for v2id, name in {\"TIT2\": \"title\", \"TPE1\": \"artist\",\n                       \"TALB\": \"album\"}.items():\n        if v2id in id3:\n            text = id3[v2id].text[0].encode('latin1', 'replace')[:30]\n        else:\n            text = b\"\"\n        v1[name] = text + (b\"\\x00\" * (30 - len(text)))\n\n    if \"COMM\" in id3:\n        cmnt = id3[\"COMM\"].text[0].encode('latin1', 'replace')[:28]\n    else:\n        cmnt = b\"\"\n    v1[\"comment\"] = cmnt + (b\"\\x00\" * (29 - len(cmnt)))\n\n    if \"TRCK\" in id3:\n        try:\n            v1[\"track\"] = chr_(+id3[\"TRCK\"])\n        except ValueError:\n            v1[\"track\"] = b\"\\x00\"\n    else:\n        v1[\"track\"] = b\"\\x00\"\n\n    if \"TCON\" in id3:\n        try:\n            genre = id3[\"TCON\"].genres[0]\n        except IndexError:\n            pass\n        else:\n            if genre in TCON.GENRES:\n                v1[\"genre\"] = chr_(TCON.GENRES.index(genre))\n    if \"genre\" not in v1:\n        v1[\"genre\"] = b\"\\xff\"\n\n    if \"TDRC\" in id3:\n        year = text_type(id3[\"TDRC\"]).encode('ascii')\n    elif \"TYER\" in id3:\n        year = text_type(id3[\"TYER\"]).encode('ascii')\n    else:\n        year = b\"\"\n    v1[\"year\"] = (year + b\"\\x00\\x00\\x00\\x00\")[:4]\n\n    return (\n        b\"TAG\" +\n        v1[\"title\"] +\n        v1[\"artist\"] +\n        v1[\"album\"] +\n        v1[\"year\"] +\n        v1[\"comment\"] +\n        v1[\"track\"] +\n        v1[\"genre\"]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(filething):\n\n    t = OggVorbis(filething)\n    filething.fileobj.seek(0)\n    t.delete(filething)", "response": "Delete a single object from the file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nposting tags to the file.", "response": "def _post_tags(self, fileobj):\n        \"\"\"Raises ogg.error\"\"\"\n\n        page = OggPage.find_last(fileobj, self.serial, finishing=True)\n        if page is None:\n            raise OggVorbisHeaderError\n        self.length = page.position / float(self.sample_rate)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _inject(self, fileobj, padding_func):\n\n        # Find the old pages in the file; we'll need to remove them,\n        # plus grab any stray setup packet data out of them.\n        fileobj.seek(0)\n        page = OggPage(fileobj)\n        while not page.packets[0].startswith(b\"\\x03vorbis\"):\n            page = OggPage(fileobj)\n\n        old_pages = [page]\n        while not (old_pages[-1].complete or len(old_pages[-1].packets) > 1):\n            page = OggPage(fileobj)\n            if page.serial == old_pages[0].serial:\n                old_pages.append(page)\n\n        packets = OggPage.to_packets(old_pages, strict=False)\n\n        content_size = get_size(fileobj) - len(packets[0])  # approx\n        vcomment_data = b\"\\x03vorbis\" + self.write()\n        padding_left = len(packets[0]) - len(vcomment_data)\n\n        info = PaddingInfo(padding_left, content_size)\n        new_padding = info._get_padding(padding_func)\n\n        # Set the new comment packet.\n        packets[0] = vcomment_data + b\"\\x00\" * new_padding\n\n        new_pages = OggPage._from_packets_try_preserve(packets, old_pages)\n        OggPage.replace(fileobj, old_pages, new_pages)", "response": "Write tag data into the Vorbis comment packet or page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data):\n\n        if len(data) > self.data_size:\n            raise ValueError\n\n        self.__fileobj.seek(self.data_offset)\n        self.__fileobj.write(data)", "response": "Write the chunk data to the file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resize(self, new_data_size):\n\n        resize_bytes(\n            self.__fileobj, self.data_size, new_data_size, self.data_offset)\n        self._update_size(new_data_size)", "response": "Resize the file and update the chunk sizes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert_chunk(self, id_):\n\n        assert_valid_chunk_id(id_)\n\n        self.__fileobj.seek(self.__next_offset)\n        self.__fileobj.write(pack('>4si', id_.ljust(4).encode('ascii'), 0))\n        self.__fileobj.seek(self.__next_offset)\n        chunk = IFFChunk(self.__fileobj, self[u'FORM'])\n        self[u'FORM']._update_size(self[u'FORM'].data_size + chunk.size)\n\n        self.__chunks[id_] = chunk\n        self.__next_offset = chunk.offset + chunk.size", "response": "Insert a new chunk at the end of the IFF file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the ID3v2 data to the AIFF file.", "response": "def save(self, filething=None, v2_version=4, v23_sep='/', padding=None):\n        \"\"\"Save ID3v2 data to the AIFF file\"\"\"\n\n        fileobj = filething.fileobj\n\n        iff_file = IFFFile(fileobj)\n\n        if u'ID3' not in iff_file:\n            iff_file.insert_chunk(u'ID3')\n\n        chunk = iff_file[u'ID3']\n\n        try:\n            data = self._prepare_data(\n                fileobj, chunk.data_offset, chunk.data_size, v2_version,\n                v23_sep, padding)\n        except ID3Error as e:\n            reraise(error, e, sys.exc_info()[2])\n\n        new_size = len(data)\n        new_size += new_size % 2  # pad byte\n        assert new_size % 2 == 0\n        chunk.resize(new_size)\n        data += (new_size - len(data)) * b'\\x00'\n        assert new_size == len(data)\n        chunk.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload stream and tag information from a file.", "response": "def load(self, filething, **kwargs):\n        \"\"\"Load stream and tag information from a file.\"\"\"\n\n        fileobj = filething.fileobj\n\n        try:\n            self.tags = _IFFID3(fileobj, **kwargs)\n        except ID3NoHeaderError:\n            self.tags = None\n        except ID3Error as e:\n            raise error(e)\n        else:\n            self.tags.filename = self.filename\n\n        fileobj.seek(0, 0)\n        self.info = AIFFInfo(fileobj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_valid_image(self, raw_data):\n        '''\n        Wand library makes sure when opening any image that is fine, when\n        the image is corrupted raises an exception.\n        '''\n\n        try:\n            Image(blob=raw_data)\n            return True\n        except (exceptions.CorruptImageError, exceptions.MissingDelegateError):\n            return False", "response": "Check if the image is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a geometry string syntax and returns a tuple containing x y and ratio", "response": "def parse_geometry(geometry, ratio=None):\n    \"\"\"\n    Parses a geometry string syntax and returns a (width, height) tuple\n    \"\"\"\n    m = geometry_pat.match(geometry)\n\n    def syntax_error():\n        return ThumbnailParseError('Geometry does not have the correct '\n                                   'syntax: %s' % geometry)\n\n    if not m:\n        raise syntax_error()\n    x = m.group('x')\n    y = m.group('y')\n    if x is None and y is None:\n        raise syntax_error()\n    if x is not None:\n        x = int(x)\n    if y is not None:\n        y = int(y)\n        # calculate x or y proportionally if not set but we need the image ratio\n    # for this\n    if ratio is not None:\n        ratio = float(ratio)\n        if x is None:\n            x = toint(y * ratio)\n        elif y is None:\n            y = toint(x / ratio)\n    return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_crop(crop, xy_image, xy_window):\n\n    x_alias_percent = {\n        'left': '0%',\n        'center': '50%',\n        'right': '100%',\n    }\n    y_alias_percent = {\n        'top': '0%',\n        'center': '50%',\n        'bottom': '100%',\n    }\n    xy_crop = crop.split(' ')\n\n    if len(xy_crop) == 1:\n        if crop in x_alias_percent:\n            x_crop = x_alias_percent[crop]\n            y_crop = '50%'\n        elif crop in y_alias_percent:\n            y_crop = y_alias_percent[crop]\n            x_crop = '50%'\n        else:\n            x_crop, y_crop = crop, crop\n    elif len(xy_crop) == 2:\n        x_crop, y_crop = xy_crop\n        x_crop = x_alias_percent.get(x_crop, x_crop)\n        y_crop = y_alias_percent.get(y_crop, y_crop)\n    else:\n        raise ThumbnailParseError('Unrecognized crop option: %s' % crop)\n\n    def get_offset(crop, epsilon):\n        m = bgpos_pat.match(crop)\n        if not m:\n            raise ThumbnailParseError('Unrecognized crop option: %s' % crop)\n        value = int(m.group('value'))  # we only take ints in the regexp\n        unit = m.group('unit')\n        if unit == '%':\n            value = epsilon * value / 100.0\n\n        # return \u2208 [0, epsilon]\n        return int(max(0, min(value, epsilon)))\n\n    offset_x = get_offset(x_crop, xy_image[0] - xy_window[0])\n    offset_y = get_offset(y_crop, xy_image[1] - xy_window[1])\n    return offset_x, offset_y", "response": "Parses the crop option and returns x y offsets for cropping."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_cropbox(cropbox):\n    if isinstance(cropbox, six.text_type):\n        return tuple([int(x.strip()) for x in cropbox.split(',')])\n    else:\n        return tuple(cropbox)", "response": "Parses a cropbox string into x y x2 y2 tuple for cropping."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the image to the thumbnail file", "response": "def write(self, image, options, thumbnail):\n        \"\"\"\n        Writes the thumbnail image\n        \"\"\"\n        if options['format'] == 'JPEG' and options.get(\n                'progressive', settings.THUMBNAIL_PROGRESSIVE):\n            image['options']['interlace'] = 'line'\n\n        image['options']['quality'] = options['quality']\n\n        args = settings.THUMBNAIL_CONVERT.split(' ')\n        args.append(image['source'] + '[0]')\n\n        for k in image['options']:\n            v = image['options'][k]\n            args.append('-%s' % k)\n            if v is not None:\n                args.append('%s' % v)\n\n        flatten = \"on\"\n        if 'flatten' in options:\n            flatten = options['flatten']\n\n        if settings.THUMBNAIL_FLATTEN and not flatten == \"off\":\n            args.append('-flatten')\n\n        suffix = '.%s' % EXTENSIONS[options['format']]\n\n        with NamedTemporaryFile(suffix=suffix, mode='rb') as fp:\n            args.append(fp.name)\n            args = map(smart_str, args)\n            p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            returncode = p.wait()\n            out, err = p.communicate()\n\n            if returncode:\n                raise EngineError(\n                    \"The command %r exited with a non-zero exit code and printed this to stderr: %s\"\n                    % (args, err)\n                )\n            elif err:\n                logger.error(\"Captured stderr: %s\", err)\n\n            thumbnail.write(fp.read())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the backend image objects from an ImageFile instance", "response": "def get_image(self, source):\n        \"\"\"\n        Returns the backend image objects from a ImageFile instance\n        \"\"\"\n        with NamedTemporaryFile(mode='wb', delete=False) as fp:\n            fp.write(source.read())\n        return {'source': fp.name, 'options': OrderedDict(), 'size': None}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the image is valid.", "response": "def is_valid_image(self, raw_data):\n        \"\"\"\n        This is not very good for imagemagick because it will say anything is\n        valid that it can use as input.\n        \"\"\"\n        with NamedTemporaryFile(mode='wb') as fp:\n            fp.write(raw_data)\n            fp.flush()\n            args = settings.THUMBNAIL_IDENTIFY.split(' ')\n            args.append(fp.name + '[0]')\n            p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            retcode = p.wait()\n        return retcode == 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncropping the image to a set of x y coordinates", "response": "def _cropbox(self, image, x, y, x2, y2):\n        \"\"\"\n        Crops the image to a set of x,y coordinates (x,y) is top left, (x2,y2) is bottom left\n        \"\"\"\n        image['options']['crop'] = '%sx%s+%s+%s' % (x2 - x, y2 - y, x, y)\n        image['size'] = (x2 - x, y2 - y)  # update image size\n        return image"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo the resizing of the image", "response": "def _scale(self, image, width, height):\n        \"\"\"\n        Does the resizing of the image\n        \"\"\"\n        image['options']['scale'] = '%sx%s!' % (width, height)\n        image['size'] = (width, height)  # update image size\n        return image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute a unique key from arguments given.", "response": "def tokey(*args):\n    \"\"\"\n    Computes a unique key from arguments given.\n    \"\"\"\n    salt = '||'.join([force_text(arg) for arg in args])\n    hash_ = hashlib.md5(encode(salt))\n    return hash_.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_module_class(class_path):\n    mod_name, cls_name = class_path.rsplit('.', 1)\n\n    try:\n        mod = import_module(mod_name)\n    except ImportError as e:\n        raise ImproperlyConfigured(('Error importing module %s: \"%s\"' % (mod_name, e)))\n\n    return getattr(mod, cls_name)", "response": "Imports and returns module class from path. to. module. Class argument\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef safe_filter(error_output=''):\n\n    def inner(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            try:\n                return f(*args, **kwargs)\n            except Exception as err:\n                if sorl_settings.THUMBNAIL_DEBUG:\n                    raise\n                logger.error('Thumbnail filter failed: %s' % str(err),\n                             exc_info=sys.exc_info())\n                return error_output\n\n        return wrapper\n\n    return inner", "response": "A safe filter decorator only raising errors when THUMBNAIL_DEBUG is\n    True otherwise returning error_output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolution(file_, resolution_string):\n    if sorl_settings.THUMBNAIL_DUMMY:\n        dummy_source = sorl_settings.THUMBNAIL_DUMMY_SOURCE\n        source = dummy_source.replace('%(width)s', '(?P<width>[0-9]+)')\n        source = source.replace('%(height)s', '(?P<height>[0-9]+)')\n        source = re.compile(source)\n        try:\n            resolution = decimal.Decimal(resolution_string.strip('x'))\n            info = source.match(file_).groupdict()\n            info = {dimension: int(int(size) * resolution) for (dimension, size) in info.items()}\n            return dummy_source % info\n        except (AttributeError, TypeError, KeyError):\n            # If we can't manipulate the dummy we shouldn't change it at all\n            return file_\n\n    filename, extension = os.path.splitext(file_)\n    return '%s@%s%s' % (filename, resolution_string, extension)", "response": "A filter to return the URL for the provided resolution of the thumbnail."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef margin(file_, geometry_string):\n\n    if not file_ or (sorl_settings.THUMBNAIL_DUMMY or isinstance(file_, DummyImageFile)):\n        return 'auto'\n\n    margin = [0, 0, 0, 0]\n\n    image_file = default.kvstore.get_or_set(ImageFile(file_))\n\n    x, y = parse_geometry(geometry_string, image_file.ratio)\n    ex = x - image_file.x\n    margin[3] = ex / 2\n    margin[1] = ex / 2\n\n    if ex % 2:\n        margin[1] += 1\n\n    ey = y - image_file.y\n    margin[0] = ey / 2\n    margin[2] = ey / 2\n\n    if ey % 2:\n        margin[2] += 1\n\n    return ' '.join(['%dpx' % n for n in margin])", "response": "Returns the calculated margin for an image and geometry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef text_filter(regex_base, value):\n    regex = regex_base % {\n        're_cap': r'[a-zA-Z0-9\\.\\,:;/_ \\(\\)\\-\\!\\?\"]+',\n        're_img': r'[a-zA-Z0-9\\.:/_\\-\\% ]+'\n    }\n    images = re.findall(regex, value)\n\n    for i in images:\n        image = i[1]\n        if image.startswith(settings.MEDIA_URL):\n            image = image[len(settings.MEDIA_URL):]\n\n        im = get_thumbnail(image, str(sorl_settings.THUMBNAIL_FILTER_WIDTH))\n        value = value.replace(i[1], im.url)\n\n    return value", "response": "Helper method to regex replace images with captions in different markups"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_file(self, instance, sender, **kwargs):\n        file_ = getattr(instance, self.attname)\n\n        # If no other object of this type references the file, and it's not the\n        # default value for future objects, delete it from the backend.\n        query = Q(**{self.name: file_.name}) & ~Q(pk=instance.pk)\n        qs = sender._default_manager.filter(query)\n\n        if (file_ and file_.name != self.default and not qs):\n            default.backend.delete(file_)\n        elif file_:\n            # Otherwise, just close the file, so it doesn't tie up resources.\n            file_.close()", "response": "Removes the file from the backend if it is not the default value for future objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_python(self, data):\n        f = super(ImageFormField, self).to_python(data)\n        if f is None:\n            return None\n\n        # We need to get a file raw data to validate it.\n        if hasattr(data, 'temporary_file_path'):\n            with open(data.temporary_file_path(), 'rb') as fp:\n                raw_data = fp.read()\n        elif hasattr(data, 'read'):\n            raw_data = data.read()\n        else:\n            raw_data = data['content']\n\n        if not default.engine.is_valid_image(raw_data):\n            raise forms.ValidationError(self.default_error_messages['invalid_image'])\n        if hasattr(f, 'seek') and callable(f.seek):\n            f.seek(0)\n\n        return f", "response": "Check that the file - upload field data contains a valid image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, image, options, thumbnail):\n\n        args = settings.THUMBNAIL_VIPSTHUMBNAIL.split(' ')\n        args.append(image['source'])\n\n        for k in image['options']:\n            v = image['options'][k]\n            args.append('--%s' % k)\n            if v is not None:\n                args.append('%s' % v)\n\n        suffix = '.%s' % EXTENSIONS[options['format']]\n\n        write_options = []\n        if options['format'] == 'JPEG' and options.get(\n                'progressive', settings.THUMBNAIL_PROGRESSIVE):\n            write_options.append(\"interlace\")\n\n        if options['quality']:\n            if options['format'] == 'JPEG':\n                write_options.append(\"Q=%d\" % options['quality'])\n\n        with NamedTemporaryFile(suffix=suffix, mode='rb') as fp:\n            # older vipsthumbails used -o, this was renamed to -f in 8.0, use\n            # -o here for commpatibility\n            args.append(\"-o\")\n            args.append(fp.name + \"[%s]\" % \",\".join(write_options))\n\n            args = map(smart_str, args)\n            p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            p.wait()\n            out, err = p.communicate()\n\n            if err:\n                raise Exception(err)\n\n            thumbnail.write(fp.read())", "response": "Writes the image to the thumbnail image"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the width and height of an image as a tuple", "response": "def get_image_size(self, image):\n        \"\"\"\n        Returns the image width and height as a tuple\n        \"\"\"\n        if image['size'] is None:\n            args = settings.THUMBNAIL_VIPSHEADER.split(' ')\n            args.append(image['source'])\n            p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            p.wait()\n            m = size_re.match(str(p.stdout.read()))\n            image['size'] = int(m.group('x')), int(m.group('y'))\n        return image['size']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an ImageFile instance for the given file with geometry and options given.", "response": "def get_thumbnail(self, file_, geometry_string, **options):\n        \"\"\"\n        Returns thumbnail as an ImageFile instance for file with geometry and\n        options given. First it will try to get it from the key value store,\n        secondly it will create it.\n        \"\"\"\n        logger.debug('Getting thumbnail for file [%s] at [%s]', file_, geometry_string)\n\n        if file_:\n            source = ImageFile(file_)\n        else:\n            raise ValueError('falsey file_ argument in get_thumbnail()')\n\n        # preserve image filetype\n        if settings.THUMBNAIL_PRESERVE_FORMAT:\n            options.setdefault('format', self._get_format(source))\n\n        for key, value in self.default_options.items():\n            options.setdefault(key, value)\n\n        # For the future I think it is better to add options only if they\n        # differ from the default settings as below. This will ensure the same\n        # filenames being generated for new options at default.\n        for key, attr in self.extra_options:\n            value = getattr(settings, attr)\n            if value != getattr(default_settings, attr):\n                options.setdefault(key, value)\n\n        name = self._get_thumbnail_filename(source, geometry_string, options)\n        thumbnail = ImageFile(name, default.storage)\n        cached = default.kvstore.get(thumbnail)\n\n        if cached:\n            return cached\n\n        # We have to check exists() because the Storage backend does not\n        # overwrite in some implementations.\n        if settings.THUMBNAIL_FORCE_OVERWRITE or not thumbnail.exists():\n            try:\n                source_image = default.engine.get_image(source)\n            except IOError as e:\n                logger.exception(e)\n                if settings.THUMBNAIL_DUMMY:\n                    return DummyImageFile(geometry_string)\n                else:\n                    # if S3Storage says file doesn't exist remotely, don't try to\n                    # create it and exit early.\n                    # Will return working empty image type; 404'd image\n                    logger.warning(\n                        'Remote file [%s] at [%s] does not exist',\n                        file_, geometry_string,\n                    )\n                    return thumbnail\n\n            # We might as well set the size since we have the image in memory\n            image_info = default.engine.get_image_info(source_image)\n            options['image_info'] = image_info\n            size = default.engine.get_image_size(source_image)\n            source.set_size(size)\n\n            try:\n                self._create_thumbnail(source_image, geometry_string, options,\n                                       thumbnail)\n                self._create_alternative_resolutions(source_image, geometry_string,\n                                                     options, thumbnail.name)\n            finally:\n                default.engine.cleanup(source_image)\n\n        # If the thumbnail exists we don't create it, the other option is\n        # to delete and write but this could lead to race conditions so I\n        # will just leave that out for now.\n        default.kvstore.get_or_set(source)\n        default.kvstore.set(thumbnail, source)\n        return thumbnail"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, file_, delete_file=True):\n        image_file = ImageFile(file_)\n        if delete_file:\n            image_file.delete()\n        default.kvstore.delete(image_file)", "response": "Deletes the file_ references in Key Value store and optionally the file_\n        it self."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the thumbnail file", "response": "def _create_thumbnail(self, source_image, geometry_string, options,\n                          thumbnail):\n        \"\"\"\n        Creates the thumbnail by using default.engine\n        \"\"\"\n        logger.debug('Creating thumbnail file [%s] at [%s] with [%s]',\n                     thumbnail.name, geometry_string, options)\n        ratio = default.engine.get_image_ratio(source_image, options)\n        geometry = parse_geometry(geometry_string, ratio)\n        image = default.engine.create(source_image, geometry, options)\n        default.engine.write(image, options, thumbnail)\n        # It's much cheaper to set the size here\n        size = default.engine.get_image_size(image)\n        thumbnail.set_size(size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the alternative resolution images.", "response": "def _create_alternative_resolutions(self, source_image, geometry_string,\n                                        options, name):\n        \"\"\"\n        Creates the thumbnail by using default.engine with multiple output\n        sizes.  Appends @<ratio>x to the file name.\n        \"\"\"\n        ratio = default.engine.get_image_ratio(source_image, options)\n        geometry = parse_geometry(geometry_string, ratio)\n        file_name, dot_file_ext = os.path.splitext(name)\n\n        for resolution in settings.THUMBNAIL_ALTERNATIVE_RESOLUTIONS:\n            resolution_geometry = (int(geometry[0] * resolution), int(geometry[1] * resolution))\n            resolution_options = options.copy()\n            if 'crop' in options and isinstance(options['crop'], string_types):\n                crop = options['crop'].split(\" \")\n                for i in range(len(crop)):\n                    s = re.match(r\"(\\d+)px\", crop[i])\n                    if s:\n                        crop[i] = \"%spx\" % int(int(s.group(1)) * resolution)\n                resolution_options['crop'] = \" \".join(crop)\n\n            image = default.engine.create(source_image, resolution_geometry, options)\n            thumbnail_name = '%(file_name)s%(suffix)s%(file_ext)s' % {\n                'file_name': file_name,\n                'suffix': '@%sx' % resolution,\n                'file_ext': dot_file_ext\n            }\n            thumbnail = ImageFile(thumbnail_name, default.storage)\n            default.engine.write(image, resolution_options, thumbnail)\n            size = default.engine.get_image_size(image)\n            thumbnail.set_size(size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the destination filename.", "response": "def _get_thumbnail_filename(self, source, geometry_string, options):\n        \"\"\"\n        Computes the destination filename.\n        \"\"\"\n        key = tokey(source.key, geometry_string, serialize(options))\n        # make some subdirs\n        path = '%s/%s/%s' % (key[:2], key[2:4], key)\n        return '%s%s.%s' % (settings.THUMBNAIL_PREFIX, path, EXTENSIONS[options['format']])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndraws a round corner", "response": "def round_corner(radius, fill):\n    \"\"\"Draw a round corner\"\"\"\n    corner = Image.new('L', (radius, radius), 0)  # (0, 0, 0, 0))\n    draw = ImageDraw.Draw(corner)\n    draw.pieslice((0, 0, radius * 2, radius * 2), 180, 270, fill=fill)\n    return corner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw a rounded rectangle", "response": "def round_rectangle(size, radius, fill):\n    \"\"\"Draw a rounded rectangle\"\"\"\n    width, height = size\n    rectangle = Image.new('L', size, 255)  # fill\n    corner = round_corner(radius, 255)  # fill\n    rectangle.paste(corner, (0, 0))\n    rectangle.paste(corner.rotate(90),\n                    (0, height - radius))  # Rotate the corner and paste it\n    rectangle.paste(corner.rotate(180), (width - radius, height - radius))\n    rectangle.paste(corner.rotate(270), (width - radius, 0))\n    return rectangle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the entropy of an image", "response": "def _get_image_entropy(self, image):\n        \"\"\"calculate the entropy of an image\"\"\"\n        hist = image.histogram()\n        hist_size = sum(hist)\n        hist = [float(h) / hist_size for h in hist]\n        return -sum([p * math.log(p, 2) for p in hist if p != 0])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, image, geometry, options):\n        image = self.cropbox(image, geometry, options)\n        image = self.orientation(image, geometry, options)\n        image = self.colorspace(image, geometry, options)\n        image = self.remove_border(image, options)\n        image = self.scale(image, geometry, options)\n        image = self.crop(image, geometry, options)\n        image = self.rounded(image, geometry, options)\n        image = self.blur(image, geometry, options)\n        image = self.padding(image, geometry, options)\n        return image", "response": "Create a new image engine instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the image s orientation.", "response": "def orientation(self, image, geometry, options):\n        \"\"\"\n        Wrapper for ``_orientation``\n        \"\"\"\n        if options.get('orientation', settings.THUMBNAIL_ORIENTATION):\n            return self._orientation(image)\n        self.reoriented = True\n        return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a colorspace object for the image.", "response": "def colorspace(self, image, geometry, options):\n        \"\"\"\n        Wrapper for ``_colorspace``\n        \"\"\"\n        colorspace = options['colorspace']\n        return self._colorspace(image, colorspace)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crop(self, image, geometry, options):\n        crop = options['crop']\n        x_image, y_image = self.get_image_size(image)\n\n        if not crop or crop == 'noop':\n            return image\n        elif crop == 'smart':\n            # Smart cropping is suitably different from regular cropping\n            # to warrent it's own function\n            return self._entropy_crop(image, geometry[0], geometry[1], x_image, y_image)\n\n        # Handle any other crop option with the backend crop function.\n        geometry = (min(x_image, geometry[0]), min(y_image, geometry[1]))\n        x_offset, y_offset = parse_crop(crop, (x_image, y_image), geometry)\n        return self._crop(image, geometry[0], geometry[1], x_offset, y_offset)", "response": "Wrapper for _crop method that handles cropping of the image."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the image ratio based on the image size and cropbox options.", "response": "def get_image_ratio(self, image, options):\n        \"\"\"\n        Calculates the image ratio. If cropbox option is used, the ratio\n        may have changed.\n        \"\"\"\n        cropbox = options['cropbox']\n\n        if cropbox:\n            x, y, x2, y2 = parse_cropbox(cropbox)\n            x = x2 - x\n            y = y2 - y\n        else:\n            x, y = self.get_image_size(image)\n\n        return float(x) / y"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self, delete_thumbnails=False):\n        prefix = settings.THUMBNAIL_KEY_PREFIX\n        for key in self._find_keys_raw(prefix):\n            self.cache.delete(key)\n        KVStoreModel.objects.filter(key__startswith=prefix).delete()\n        if delete_thumbnails:\n            self.delete_all_thumbnail_files()", "response": "Clears all the entries in the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, image_file, source=None):\n        image_file.set_size()  # make sure its got a size\n        self._set(image_file.key, image_file)\n        if source is not None:\n            if not self.get(source):\n                # make sure the source is in kvstore\n                raise ThumbnailError('Cannot add thumbnails for source: `%s` '\n                                     'that is not in kvstore.' % source.name)\n\n            # Update the list of thumbnails for source.\n            thumbnails = self._get(source.key, identity='thumbnails') or []\n            thumbnails = set(thumbnails)\n            thumbnails.add(image_file.key)\n\n            self._set(source.key, list(thumbnails), identity='thumbnails')", "response": "Updates the store for the image_file. Makes sure the image_file has a size set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the image_file and all of its related references.", "response": "def delete(self, image_file, delete_thumbnails=True):\n        \"\"\"\n        Deletes the reference to the ``image_file`` and deletes the references\n        to thumbnails as well as thumbnail files if ``delete_thumbnails`` is\n        `True``. Does not delete the ``image_file`` is self.\n        \"\"\"\n        if delete_thumbnails:\n            self.delete_thumbnails(image_file)\n        self._delete(image_file.key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete references to thumbnails as well as thumbnails image_files.", "response": "def delete_thumbnails(self, image_file):\n        \"\"\"\n        Deletes references to thumbnails as well as thumbnail ``image_files``.\n        \"\"\"\n        thumbnail_keys = self._get(image_file.key, identity='thumbnails')\n        if thumbnail_keys:\n            # Delete all thumbnail keys from store and delete the\n            # thumbnail ImageFiles.\n\n            for key in thumbnail_keys:\n                thumbnail = self._get(key)\n                if thumbnail:\n                    self.delete(thumbnail, False)\n                    thumbnail.delete()  # delete the actual file\n\n            # Delete the thumbnails key from store\n            self._delete(image_file.key, identity='thumbnails')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclean up the key value store.", "response": "def cleanup(self):\n        \"\"\"\n        Cleans up the key value store. In detail:\n        1. Deletes all key store references for image_files that do not exist\n           and all key references for its thumbnails *and* their image_files.\n        2. Deletes or updates all invalid thumbnail keys\n        \"\"\"\n        for key in self._find_keys(identity='image'):\n            image_file = self._get(key)\n\n            if image_file and not image_file.exists():\n                self.delete(image_file)\n\n        for key in self._find_keys(identity='thumbnails'):\n            # We do not need to check for file existence in here since we\n            # already did that above for all image references\n            image_file = self._get(key)\n\n            if image_file:\n                # if there is an image_file then we check all of its thumbnails\n                # for existence\n                thumbnail_keys = self._get(key, identity='thumbnails') or []\n                thumbnail_keys_set = set(thumbnail_keys)\n\n                for thumbnail_key in thumbnail_keys:\n                    if not self._get(thumbnail_key):\n                        thumbnail_keys_set.remove(thumbnail_key)\n\n                thumbnail_keys = list(thumbnail_keys_set)\n\n                if thumbnail_keys:\n                    self._set(key, thumbnail_keys, identity='thumbnails')\n                    continue\n\n            # if there is no image_file then this thumbnails key is just\n            # hangin' loose, If the thumbnail_keys ended up empty there is no\n            # reason for keeping it either\n            self._delete(key, identity='thumbnails')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclearing the key value store for all keys with THUMBNAIL_KEY_PREFIX.", "response": "def clear(self):\n        \"\"\"\n        Brutely clears the key value store for keys with THUMBNAIL_KEY_PREFIX\n        prefix. Use this in emergency situations. Normally you would probably\n        want to use the ``cleanup`` method instead.\n        \"\"\"\n        all_keys = self._find_keys_raw(settings.THUMBNAIL_KEY_PREFIX)\n        if all_keys:\n            self._delete_raw(*all_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a key from the cache.", "response": "def _get(self, key, identity='image'):\n        \"\"\"\n        Deserializing, prefix wrapper for _get_raw\n        \"\"\"\n        value = self._get_raw(add_prefix(key, identity))\n\n        if not value:\n            return None\n\n        if identity == 'image':\n            return deserialize_image_file(value)\n\n        return deserialize(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set(self, key, value, identity='image'):\n        if identity == 'image':\n            s = serialize_image_file(value)\n        else:\n            s = serialize(value)\n        self._set_raw(add_prefix(key, identity), s)", "response": "Internal method to set the value of a key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind and returns all keys for identity", "response": "def _find_keys(self, identity='image'):\n        \"\"\"\n        Finds and returns all keys for identity,\n        \"\"\"\n        prefix = add_prefix('', identity)\n        raw_keys = self._find_keys_raw(prefix) or []\n        for raw_key in raw_keys:\n            yield del_prefix(raw_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_attachment(self, recipient_id, attachment_type, attachment_path,\n                        notification_type=NotificationType.regular):\n        \"\"\"Send an attachment to the specified recipient using local path.\n        Input:\n            recipient_id: recipient id to send to\n            attachment_type: type of attachment (image, video, audio, file)\n            attachment_path: Path of attachment\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        payload = {\n            'recipient': {\n                {\n                    'id': recipient_id\n                }\n            },\n            'notification_type': notification_type,\n            'message': {\n                {\n                    'attachment': {\n                        'type': attachment_type,\n                        'payload': {}\n                    }\n                }\n            },\n            'filedata': (os.path.basename(attachment_path), open(attachment_path, 'rb'))\n        }\n        multipart_data = MultipartEncoder(payload)\n        multipart_header = {\n            'Content-Type': multipart_data.content_type\n        }\n        return requests.post(self.graph_url, data=multipart_data,\n                             params=self.auth_args, headers=multipart_header).json()", "response": "Send an attachment to the specified recipient using local path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend an attachment to the specified recipient using URL.", "response": "def send_attachment_url(self, recipient_id, attachment_type, attachment_url,\n                            notification_type=NotificationType.regular):\n        \"\"\"Send an attachment to the specified recipient using URL.\n        Input:\n            recipient_id: recipient id to send to\n            attachment_type: type of attachment (image, video, audio, file)\n            attachment_url: URL of attachment\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_message(recipient_id, {\n            'attachment': {\n                'type': attachment_type,\n                'payload': {\n                    'url': attachment_url\n                }\n            }\n        }, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_text_message(self, recipient_id, message, notification_type=NotificationType.regular):\n        return self.send_message(recipient_id, {\n            'text': message\n        }, notification_type)", "response": "Send a message to the specified recipient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_generic_message(self, recipient_id, elements, notification_type=NotificationType.regular):\n        return self.send_message(recipient_id, {\n            \"attachment\": {\n                \"type\": \"template\",\n                \"payload\": {\n                    \"template_type\": \"generic\",\n                    \"elements\": elements\n                }\n            }\n        }, notification_type)", "response": "Send generic message to the specified recipient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a text message to the specified recipient.", "response": "def send_button_message(self, recipient_id, text, buttons, notification_type=NotificationType.regular):\n        \"\"\"Send text messages to the specified recipient.\n        https://developers.facebook.com/docs/messenger-platform/send-api-reference/button-template\n        Input:\n            recipient_id: recipient id to send to\n            text: text of message to send\n            buttons: buttons to send\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_message(recipient_id, {\n            \"attachment\": {\n                \"type\": \"template\",\n                \"payload\": {\n                    \"template_type\": \"button\",\n                    \"text\": text,\n                    \"buttons\": buttons\n                }\n            }\n        }, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend typing indicators or send read receipts to the specified recipient.", "response": "def send_action(self, recipient_id, action, notification_type=NotificationType.regular):\n        \"\"\"Send typing indicators or send read receipts to the specified recipient.\n        https://developers.facebook.com/docs/messenger-platform/send-api-reference/sender-actions\n\n        Input:\n            recipient_id: recipient id to send to\n            action: action type (mark_seen, typing_on, typing_off)\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_recipient(recipient_id, {\n            'sender_action': action\n        }, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_image(self, recipient_id, image_path, notification_type=NotificationType.regular):\n        return self.send_attachment(recipient_id, \"image\", image_path, notification_type)", "response": "Send an image to the specified recipient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending an image to a recipient using URL.", "response": "def send_image_url(self, recipient_id, image_url, notification_type=NotificationType.regular):\n        \"\"\"Send an image to specified recipient using URL.\n        Image must be PNG or JPEG or GIF (more might be supported).\n        https://developers.facebook.com/docs/messenger-platform/send-api-reference/image-attachment\n        Input:\n            recipient_id: recipient id to send to\n            image_url: url of image to be sent\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_attachment_url(recipient_id, \"image\", image_url, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_audio(self, recipient_id, audio_path, notification_type=NotificationType.regular):\n        return self.send_attachment(recipient_id, \"audio\", audio_path, notification_type)", "response": "Send audio to the specified recipient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_audio_url(self, recipient_id, audio_url, notification_type=NotificationType.regular):\n        return self.send_attachment_url(recipient_id, \"audio\", audio_url, notification_type)", "response": "Send audio to specified recipient using URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend video to the specified recipient.", "response": "def send_video(self, recipient_id, video_path, notification_type=NotificationType.regular):\n        \"\"\"Send video to the specified recipient.\n        Video should be MP4 or MOV, but supports more (https://www.facebook.com/help/218673814818907).\n        https://developers.facebook.com/docs/messenger-platform/send-api-reference/video-attachment\n        Input:\n            recipient_id: recipient id to send to\n            video_path: path to video to be sent\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_attachment(recipient_id, \"video\", video_path, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_video_url(self, recipient_id, video_url, notification_type=NotificationType.regular):\n        return self.send_attachment_url(recipient_id, \"video\", video_url, notification_type)", "response": "Send video to specified recipient using URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a file to the specified recipient.", "response": "def send_file(self, recipient_id, file_path, notification_type=NotificationType.regular):\n        \"\"\"Send file to the specified recipient.\n        https://developers.facebook.com/docs/messenger-platform/send-api-reference/file-attachment\n        Input:\n            recipient_id: recipient id to send to\n            file_path: path to file to be sent\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_attachment(recipient_id, \"file\", file_path, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a file to the specified recipient.", "response": "def send_file_url(self, recipient_id, file_url, notification_type=NotificationType.regular):\n        \"\"\"Send file to the specified recipient.\n        https://developers.facebook.com/docs/messenger-platform/send-api-reference/file-attachment\n        Input:\n            recipient_id: recipient id to send to\n            file_url: url of file to be sent\n        Output:\n            Response from API as <dict>\n        \"\"\"\n        return self.send_attachment_url(recipient_id, \"file\", file_url, notification_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_user_info(self, recipient_id, fields=None):\n        params = {}\n        if fields is not None and isinstance(fields, (list, tuple)):\n            params['fields'] = \",\".join(fields)\n\n        params.update(self.auth_args)\n\n        request_endpoint = '{0}/{1}'.format(self.graph_url, recipient_id)\n        response = requests.get(request_endpoint, params=params)\n        if response.status_code == 200:\n            return response.json()\n\n        return None", "response": "Get information about the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fastdtw(x, y, radius=1, dist=None):\n    ''' return the approximate distance between 2 time series with O(N)\n        time and memory complexity\n\n        Parameters\n        ----------\n        x : array_like\n            input array 1\n        y : array_like\n            input array 2\n        radius : int\n            size of neighborhood when expanding the path. A higher value will\n            increase the accuracy of the calculation but also increase time\n            and memory consumption. A radius equal to the size of x and y will\n            yield an exact dynamic time warping calculation.\n        dist : function or int\n            The method for calculating the distance between x[i] and y[j]. If\n            dist is an int of value p > 0, then the p-norm will be used. If\n            dist is a function then dist(x[i], y[j]) will be used. If dist is\n            None then abs(x[i] - y[j]) will be used.\n\n        Returns\n        -------\n        distance : float\n            the approximate distance between the 2 time series\n        path : list\n            list of indexes for the inputs x and y\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import fastdtw\n        >>> x = np.array([1, 2, 3, 4, 5], dtype='float')\n        >>> y = np.array([2, 3, 4], dtype='float')\n        >>> fastdtw.fastdtw(x, y)\n        (2.0, [(0, 0), (1, 0), (2, 1), (3, 2), (4, 2)])\n    '''\n    x, y, dist = __prep_inputs(x, y, dist)\n    return __fastdtw(x, y, radius, dist)", "response": "fastdtw returns the approximate distance between two time series x and y with O ( N ) time and memory complexity"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dtw(x, y, dist=None):\n    ''' return the distance between 2 time series without approximation\n\n        Parameters\n        ----------\n        x : array_like\n            input array 1\n        y : array_like\n            input array 2\n        dist : function or int\n            The method for calculating the distance between x[i] and y[j]. If\n            dist is an int of value p > 0, then the p-norm will be used. If\n            dist is a function then dist(x[i], y[j]) will be used. If dist is\n            None then abs(x[i] - y[j]) will be used.\n\n        Returns\n        -------\n        distance : float\n            the approximate distance between the 2 time series\n        path : list\n            list of indexes for the inputs x and y\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import fastdtw\n        >>> x = np.array([1, 2, 3, 4, 5], dtype='float')\n        >>> y = np.array([2, 3, 4], dtype='float')\n        >>> fastdtw.dtw(x, y)\n        (2.0, [(0, 0), (1, 0), (2, 1), (3, 2), (4, 2)])\n    '''\n    x, y, dist = __prep_inputs(x, y, dist)\n    return __dtw(x, y, None, dist)", "response": "return the distance between 2 time series x and y with approximation dist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_next_url(request, redirect_field_name):\n    next_url = request.GET.get(redirect_field_name)\n    if next_url:\n        kwargs = {\n            'url': next_url,\n            'require_https': import_from_settings(\n                'OIDC_REDIRECT_REQUIRE_HTTPS', request.is_secure())\n        }\n\n        hosts = list(import_from_settings('OIDC_REDIRECT_ALLOWED_HOSTS', []))\n        hosts.append(request.get_host())\n        kwargs['allowed_hosts'] = hosts\n\n        is_safe = is_safe_url(**kwargs)\n        if is_safe:\n            return next_url\n    return None", "response": "Retrieves the next url from the request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, request):\n\n        nonce = request.session.get('oidc_nonce')\n        if nonce:\n            # Make sure that nonce is not used twice\n            del request.session['oidc_nonce']\n\n        if request.GET.get('error'):\n            # Ouch! Something important failed.\n            # Make sure the user doesn't get to continue to be logged in\n            # otherwise the refresh middleware will force the user to\n            # redirect to authorize again if the session refresh has\n            # expired.\n            if is_authenticated(request.user):\n                auth.logout(request)\n            assert not is_authenticated(request.user)\n        elif 'code' in request.GET and 'state' in request.GET:\n            kwargs = {\n                'request': request,\n                'nonce': nonce,\n            }\n\n            if 'oidc_state' not in request.session:\n                return self.login_failure()\n\n            if request.GET['state'] != request.session['oidc_state']:\n                msg = 'Session `oidc_state` does not match the OIDC callback state'\n                raise SuspiciousOperation(msg)\n\n            self.user = auth.authenticate(**kwargs)\n\n            if self.user and self.user.is_active:\n                return self.login_success()\n        return self.login_failure()", "response": "Callback handler for OIDC authorization code flow"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, request):\n        state = get_random_string(self.get_settings('OIDC_STATE_SIZE', 32))\n        redirect_field_name = self.get_settings('OIDC_REDIRECT_FIELD_NAME', 'next')\n        reverse_url = self.get_settings('OIDC_AUTHENTICATION_CALLBACK_URL',\n                                        'oidc_authentication_callback')\n\n        params = {\n            'response_type': 'code',\n            'scope': self.get_settings('OIDC_RP_SCOPES', 'openid email'),\n            'client_id': self.OIDC_RP_CLIENT_ID,\n            'redirect_uri': absolutify(\n                request,\n                reverse(reverse_url)\n            ),\n            'state': state,\n        }\n\n        params.update(self.get_extra_params(request))\n\n        if self.get_settings('OIDC_USE_NONCE', True):\n            nonce = get_random_string(self.get_settings('OIDC_NONCE_SIZE', 32))\n            params.update({\n                'nonce': nonce\n            })\n            request.session['oidc_nonce'] = nonce\n\n        request.session['oidc_state'] = state\n        request.session['oidc_login_next'] = get_next_url(request, redirect_field_name)\n\n        query = urlencode(params)\n        redirect_url = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, query=query)\n        return HttpResponseRedirect(redirect_url)", "response": "This method is called by OIDC to get the current OIDC client authentication state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs out the user.", "response": "def post(self, request):\n        \"\"\"Log out the user.\"\"\"\n        logout_url = self.redirect_url\n\n        if is_authenticated(request.user):\n            # Check if a method exists to build the URL to log out the user\n            # from the OP.\n            logout_from_op = self.get_settings('OIDC_OP_LOGOUT_URL_METHOD', '')\n            if logout_from_op:\n                logout_url = import_string(logout_from_op)(request)\n\n            # Log out the Django user if they were logged in.\n            auth.logout(request)\n\n        return HttpResponseRedirect(logout_url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_oidc_backend():\n\n    # allow the user to force which back backend to use. this is mostly\n    # convenient if you want to use OIDC with DRF but don't want to configure\n    # OIDC for the \"normal\" Django auth.\n    backend_setting = import_from_settings('OIDC_DRF_AUTH_BACKEND', None)\n    if backend_setting:\n        backend = import_string(backend_setting)()\n        if not isinstance(backend, OIDCAuthenticationBackend):\n            msg = 'Class configured in OIDC_DRF_AUTH_BACKEND ' \\\n                  'does not extend OIDCAuthenticationBackend!'\n            raise ImproperlyConfigured(msg)\n        return backend\n\n    # if the backend setting is not set, look through the list of configured\n    # backends for one that is an OIDCAuthenticationBackend.\n    backends = [b for b in get_backends() if isinstance(b, OIDCAuthenticationBackend)]\n\n    if not backends:\n        msg = 'No backends extending OIDCAuthenticationBackend found - ' \\\n              'add one to AUTHENTICATION_BACKENDS or set OIDC_DRF_AUTH_BACKEND!'\n        raise ImproperlyConfigured(msg)\n    if len(backends) > 1:\n        raise ImproperlyConfigured('More than one OIDCAuthenticationBackend found!')\n    return backends[0]", "response": "Get the Django auth backend that uses OIDC."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthenticates the request and return a tuple of user and token.", "response": "def authenticate(self, request):\n        \"\"\"\n        Authenticate the request and return a tuple of (user, token) or None\n        if there was no authentication attempt.\n        \"\"\"\n        access_token = self.get_access_token(request)\n\n        if not access_token:\n            return None\n\n        try:\n            user = self.backend.get_or_create_user(access_token, None, None)\n        except HTTPError as exc:\n            resp = exc.response\n\n            # if the oidc provider returns 401, it means the token is invalid.\n            # in that case, we want to return the upstream error message (which\n            # we can get from the www-authentication header) in the response.\n            if resp.status_code == 401 and 'www-authenticate' in resp.headers:\n                data = parse_www_authenticate_header(resp.headers['www-authenticate'])\n                raise exceptions.AuthenticationFailed(data['error_description'])\n\n            # for all other http errors, just re-raise the exception.\n            raise\n        except SuspiciousOperation as exc:\n            LOGGER.info('Login failed: %s', exc)\n            raise exceptions.AuthenticationFailed('Login failed')\n\n        if not user:\n            msg = 'Login failed: No user found for the given access token.'\n            raise exceptions.AuthenticationFailed(msg)\n\n        return user, access_token"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_access_token(self, request):\n        header = authentication.get_authorization_header(request)\n        if not header:\n            return None\n        header = header.decode(authentication.HTTP_HEADER_ENCODING)\n\n        auth = header.split()\n\n        if auth[0].lower() != 'bearer':\n            return None\n\n        if len(auth) == 1:\n            msg = 'Invalid \"bearer\" header: No credentials provided.'\n            raise exceptions.AuthenticationFailed(msg)\n        elif len(auth) > 2:\n            msg = 'Invalid \"bearer\" header: Credentials string should not contain spaces.'\n            raise exceptions.AuthenticationFailed(msg)\n\n        return auth[1]", "response": "Get the access token based on a request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an attribute from the django settings.", "response": "def import_from_settings(attr, *args):\n    \"\"\"\n    Load an attribute from the django settings.\n\n    :raises:\n        ImproperlyConfigured\n    \"\"\"\n    try:\n        if args:\n            return getattr(settings, attr, args[0])\n        return getattr(settings, attr)\n    except AttributeError:\n        raise ImproperlyConfigured('Setting {0} not found'.format(attr))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default_username_algo(email):\n    # bluntly stolen from django-browserid\n    # store the username as a base64 encoded sha224 of the email address\n    # this protects against data leakage because usernames are often\n    # treated as public identifiers (so we can't use the email address).\n    username = base64.urlsafe_b64encode(\n        hashlib.sha1(force_bytes(email)).digest()\n    ).rstrip(b'=')\n\n    return smart_text(username)", "response": "Generate a username for the Django user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_users_by_claims(self, claims):\n        email = claims.get('email')\n        if not email:\n            return self.UserModel.objects.none()\n        return self.UserModel.objects.filter(email__iexact=email)", "response": "Return all users matching the specified email."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify the provided claims to decide if authentication should be allowed.", "response": "def verify_claims(self, claims):\n        \"\"\"Verify the provided claims to decide if authentication should be allowed.\"\"\"\n\n        # Verify claims required by default configuration\n        scopes = self.get_settings('OIDC_RP_SCOPES', 'openid email')\n        if 'email' in scopes.split():\n            return 'email' in claims\n\n        LOGGER.warning('Custom OIDC_RP_SCOPES defined. '\n                       'You need to override `verify_claims` for custom claims verification.')\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_user(self, claims):\n        email = claims.get('email')\n        username = self.get_username(claims)\n        return self.UserModel.objects.create_user(username, email)", "response": "Return object for a newly created user account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate username based on claims.", "response": "def get_username(self, claims):\n        \"\"\"Generate username based on claims.\"\"\"\n        # bluntly stolen from django-browserid\n        # https://github.com/mozilla/django-browserid/blob/master/django_browserid/auth.py\n        username_algo = self.get_settings('OIDC_USERNAME_ALGO', None)\n\n        if username_algo:\n            if isinstance(username_algo, six.string_types):\n                username_algo = import_string(username_algo)\n            return username_algo(claims.get('email'))\n\n        return default_username_algo(claims.get('email'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verify_jws(self, payload, key):\n        jws = JWS.from_compact(payload)\n\n        try:\n            alg = jws.signature.combined.alg.name\n        except KeyError:\n            msg = 'No alg value found in header'\n            raise SuspiciousOperation(msg)\n\n        if alg != self.OIDC_RP_SIGN_ALGO:\n            msg = \"The provider algorithm {!r} does not match the client's \" \\\n                  \"OIDC_RP_SIGN_ALGO.\".format(alg)\n            raise SuspiciousOperation(msg)\n\n        if isinstance(key, six.string_types):\n            # Use smart_bytes here since the key string comes from settings.\n            jwk = JWK.load(smart_bytes(key))\n        else:\n            # The key is a json returned from the IDP JWKS endpoint.\n            jwk = JWK.from_json(key)\n\n        if not jws.verify(jwk):\n            msg = 'JWS token verification failed.'\n            raise SuspiciousOperation(msg)\n\n        return jws.payload", "response": "Verify the given JWS payload with the given key and return the payload."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef retrieve_matching_jwk(self, token):\n        response_jwks = requests.get(\n            self.OIDC_OP_JWKS_ENDPOINT,\n            verify=self.get_settings('OIDC_VERIFY_SSL', True)\n        )\n        response_jwks.raise_for_status()\n        jwks = response_jwks.json()\n\n        # Compute the current header from the given token to find a match\n        jws = JWS.from_compact(token)\n        json_header = jws.signature.protected\n        header = Header.json_loads(json_header)\n\n        key = None\n        for jwk in jwks['keys']:\n            if jwk['kid'] != smart_text(header.kid):\n                continue\n            if 'alg' in jwk and jwk['alg'] != smart_text(header.alg):\n                raise SuspiciousOperation('alg values do not match.')\n            key = jwk\n        if key is None:\n            raise SuspiciousOperation('Could not find a valid JWKS.')\n        return key", "response": "Retrieve the signing key by exploring the JWKS endpoint of the OP."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_payload_data(self, token, key):\n        if self.get_settings('OIDC_ALLOW_UNSECURED_JWT', False):\n            header, payload_data, signature = token.split(b'.')\n            header = json.loads(smart_text(b64decode(header)))\n\n            # If config allows unsecured JWTs check the header and return the decoded payload\n            if 'alg' in header and header['alg'] == 'none':\n                return b64decode(payload_data)\n\n        # By default fallback to verify JWT signatures\n        return self._verify_jws(token, key)", "response": "Helper method to get the payload of the JWT token."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the token signature.", "response": "def verify_token(self, token, **kwargs):\n        \"\"\"Validate the token signature.\"\"\"\n        nonce = kwargs.get('nonce')\n\n        token = force_bytes(token)\n        if self.OIDC_RP_SIGN_ALGO.startswith('RS'):\n            if self.OIDC_RP_IDP_SIGN_KEY is not None:\n                key = self.OIDC_RP_IDP_SIGN_KEY\n            else:\n                key = self.retrieve_matching_jwk(token)\n        else:\n            key = self.OIDC_RP_CLIENT_SECRET\n\n        payload_data = self.get_payload_data(token, key)\n\n        # The 'token' will always be a byte string since it's\n        # the result of base64.urlsafe_b64decode().\n        # The payload is always the result of base64.urlsafe_b64decode().\n        # In Python 3 and 2, that's always a byte string.\n        # In Python3.6, the json.loads() function can accept a byte string\n        # as it will automagically decode it to a unicode string before\n        # deserializing https://bugs.python.org/issue17909\n        payload = json.loads(payload_data.decode('utf-8'))\n        token_nonce = payload.get('nonce')\n\n        if self.get_settings('OIDC_USE_NONCE', True) and nonce != token_nonce:\n            msg = 'JWT Nonce verification failed.'\n            raise SuspiciousOperation(msg)\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning token object as a dictionary.", "response": "def get_token(self, payload):\n        \"\"\"Return token object as a dictionary.\"\"\"\n\n        auth = None\n        if self.get_settings('OIDC_TOKEN_USE_BASIC_AUTH', False):\n            # When Basic auth is defined, create the Auth Header and remove secret from payload.\n            user = payload.get('client_id')\n            pw = payload.get('client_secret')\n\n            auth = HTTPBasicAuth(user, pw)\n            del payload['client_secret']\n\n        response = requests.post(\n            self.OIDC_OP_TOKEN_ENDPOINT,\n            data=payload,\n            auth=auth,\n            verify=self.get_settings('OIDC_VERIFY_SSL', True))\n        response.raise_for_status()\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_userinfo(self, access_token, id_token, payload):\n\n        user_response = requests.get(\n            self.OIDC_OP_USER_ENDPOINT,\n            headers={\n                'Authorization': 'Bearer {0}'.format(access_token)\n            },\n            verify=self.get_settings('OIDC_VERIFY_SSL', True))\n        user_response.raise_for_status()\n        return user_response.json()", "response": "Return user details dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nauthenticates a user based on the OIDC code flow.", "response": "def authenticate(self, request, **kwargs):\n        \"\"\"Authenticates a user based on the OIDC code flow.\"\"\"\n\n        self.request = request\n        if not self.request:\n            return None\n\n        state = self.request.GET.get('state')\n        code = self.request.GET.get('code')\n        nonce = kwargs.pop('nonce', None)\n\n        if not code or not state:\n            return None\n\n        reverse_url = self.get_settings('OIDC_AUTHENTICATION_CALLBACK_URL',\n                                        'oidc_authentication_callback')\n\n        token_payload = {\n            'client_id': self.OIDC_RP_CLIENT_ID,\n            'client_secret': self.OIDC_RP_CLIENT_SECRET,\n            'grant_type': 'authorization_code',\n            'code': code,\n            'redirect_uri': absolutify(\n                self.request,\n                reverse(reverse_url)\n            ),\n        }\n\n        # Get the token\n        token_info = self.get_token(token_payload)\n        id_token = token_info.get('id_token')\n        access_token = token_info.get('access_token')\n\n        # Validate the token\n        payload = self.verify_token(id_token, nonce=nonce)\n\n        if payload:\n            self.store_tokens(access_token, id_token)\n            try:\n                return self.get_or_create_user(access_token, id_token, payload)\n            except SuspiciousOperation as exc:\n                LOGGER.warning('failed to get or create user: %s', exc)\n                return None\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a User instance if 1 user is found. Creates a user if not found.", "response": "def get_or_create_user(self, access_token, id_token, payload):\n        \"\"\"Returns a User instance if 1 user is found. Creates a user if not found\n        and configured to do so. Returns nothing if multiple users are matched.\"\"\"\n\n        user_info = self.get_userinfo(access_token, id_token, payload)\n\n        email = user_info.get('email')\n\n        claims_verified = self.verify_claims(user_info)\n        if not claims_verified:\n            msg = 'Claims verification failed'\n            raise SuspiciousOperation(msg)\n\n        # email based filtering\n        users = self.filter_users_by_claims(user_info)\n\n        if len(users) == 1:\n            return self.update_user(users[0], user_info)\n        elif len(users) > 1:\n            # In the rare case that two user accounts have the same email address,\n            # bail. Randomly selecting one seems really wrong.\n            msg = 'Multiple users returned'\n            raise SuspiciousOperation(msg)\n        elif self.get_settings('OIDC_CREATE_USER', True):\n            user = self.create_user(user_info)\n            return user\n        else:\n            LOGGER.debug('Login failed: No user with email %s found, and '\n                         'OIDC_CREATE_USER is False', email)\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating and return a set of url paths to exempt from SessionRefresh", "response": "def exempt_urls(self):\n        \"\"\"Generate and return a set of url paths to exempt from SessionRefresh\n\n        This takes the value of ``settings.OIDC_EXEMPT_URLS`` and appends three\n        urls that mozilla-django-oidc uses. These values can be view names or\n        absolute url paths.\n\n        :returns: list of url paths (for example \"/oidc/callback/\")\n\n        \"\"\"\n        exempt_urls = list(self.get_settings('OIDC_EXEMPT_URLS', []))\n        exempt_urls.extend([\n            'oidc_authentication_init',\n            'oidc_authentication_callback',\n            'oidc_logout',\n        ])\n\n        return set([\n            url if url.startswith('/') else reverse(url)\n            for url in exempt_urls\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a request and returns whether it triggers a refresh examination of the OIDC resource.", "response": "def is_refreshable_url(self, request):\n        \"\"\"Takes a request and returns whether it triggers a refresh examination\n\n        :arg HttpRequest request:\n\n        :returns: boolean\n\n        \"\"\"\n        # Do not attempt to refresh the session if the OIDC backend is not used\n        backend_session = request.session.get(BACKEND_SESSION_KEY)\n        is_oidc_enabled = True\n        if backend_session:\n            auth_backend = import_string(backend_session)\n            is_oidc_enabled = issubclass(auth_backend, OIDCAuthenticationBackend)\n\n        return (\n            request.method == 'GET' and\n            is_authenticated(request.user) and\n            is_oidc_enabled and\n            request.path not in self.exempt_urls\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubmits a reCAPTCHA request for verification. Returns RecaptchaResponse for the request", "response": "def submit(recaptcha_response, private_key, remoteip):\n    \"\"\"\n    Submits a reCAPTCHA request for verification. Returns RecaptchaResponse\n    for the request\n\n    recaptcha_response -- The value of reCAPTCHA response from the form\n    private_key -- your reCAPTCHA private key\n    remoteip -- the user's ip address\n    \"\"\"\n    params = urlencode({\n        \"secret\": private_key,\n        \"response\": recaptcha_response,\n        \"remoteip\": remoteip,\n    })\n\n    if not PY2:\n        params = params.encode(\"utf-8\")\n\n    response = recaptcha_request(params)\n    data = json.loads(response.read().decode(\"utf-8\"))\n    response.close()\n    return RecaptchaResponse(\n        is_valid=data[\"success\"],\n        error_codes=data.get(\"error-codes\")\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread and returns a buffer reversely from current file - pointer position.", "response": "def _read(self):\n        \"\"\"\n        Reads and returns a buffer reversely from current file-pointer position.\n\n        :rtype : str\n        \"\"\"\n        filepos = self._fp.tell()\n        if filepos < 1:\n            return \"\"\n        destpos = max(filepos - self._chunk_size, 0)\n        self._fp.seek(destpos)\n        buf = self._fp.read(filepos - destpos)\n        self._fp.seek(destpos)\n        return buf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find(self):\n        lastbuf = \"\"\n        while 0 < self._fp.tell():\n            buf = self._read()\n            bufpos = (buf + lastbuf).rfind(self._needle)\n            if bufpos > -1:\n                filepos = self._fp.tell() + bufpos\n                self._fp.seek(filepos)\n                return filepos\n\n            # for it to work when the needle is split between chunks.\n            lastbuf = buf[:len(self._needle)]\n\n        return -1", "response": "Returns the position of the first occurence of needle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, text):\n        key = hash(text)\n        searcher = self._searchers.get(key)\n        if not searcher:\n            searcher = ReverseFileSearcher(self.filename, text)\n            self._searchers[key] = searcher\n\n        position = searcher.find()\n        if position < 0:\n            # reset the searcher to start from the tail again.\n            searcher.reset()\n            return -1, -1, ''\n\n        # try to get some content from before and after the result's position\n        read_before = self.buffer_size / 2\n        offset = max(position - read_before, 0)\n        bufferpos = position if offset == 0 else read_before\n        self.fp.seek(offset)\n        return position, bufferpos, self.read()", "response": "Search the log file for a text in the current position and return the absolute position the position of the text in the result buffer and the contents of the actual file contents."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_interface_addresses():\n\n    addresses = []\n    ifaces = netifaces.interfaces()\n    for iface in ifaces:\n        addrs = netifaces.ifaddresses(iface)\n        families = addrs.keys()\n\n        # put IPv4 to the end so it lists as the main iface address\n        if netifaces.AF_INET in families:\n            families.remove(netifaces.AF_INET)\n            families.append(netifaces.AF_INET)\n\n        for family in families:\n            for addr in addrs[family]:\n                address = {\n                    'name': iface,\n                    'family': family,\n                    'ip': addr['addr'],\n                }\n                addresses.append(address)\n\n    return addresses", "response": "Get addresses of available network interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_net_io_counters(self):\n        counters = psutil.net_io_counters(pernic=self.pernic)\n\n        res = {}\n        for name, io in counters.iteritems():\n            res[name] = io._asdict()\n            res[name].update({'tx_per_sec': 0, 'rx_per_sec': 0})\n\n        return res", "response": "Fetch io counters from psutil and transform it to\n        dicts with the additional attributes defaulted\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and returns a new URL with the given parameters.", "response": "def build(\n        cls,\n        *,\n        scheme=\"\",\n        user=\"\",\n        password=None,\n        host=\"\",\n        port=None,\n        path=\"\",\n        query=None,\n        query_string=\"\",\n        fragment=\"\",\n        encoded=False\n    ):\n        \"\"\"Creates and returns a new URL\"\"\"\n\n        if not host and scheme:\n            raise ValueError('Can\\'t build URL with \"scheme\" but without \"host\".')\n        if port and not host:\n            raise ValueError('Can\\'t build URL with \"port\" but without \"host\".')\n        if query and query_string:\n            raise ValueError('Only one of \"query\" or \"query_string\" should be passed')\n        if path is None or query_string is None or fragment is None:\n            raise TypeError('NoneType is illegal for \"path\", \"query_string\" and '\n                            '\"fragment\" args, use string values instead.')\n\n        if not user and not password and not host and not port:\n            netloc = \"\"\n        else:\n            netloc = cls._make_netloc(user, password, host, port, encode=not encoded)\n        if not encoded:\n            path = cls._PATH_QUOTER(path)\n            if netloc:\n                path = cls._normalize_path(path)\n\n            cls._validate_authority_uri_abs_path(host=host, path=path)\n            query_string = cls._QUERY_QUOTER(query_string)\n            fragment = cls._FRAGMENT_QUOTER(fragment)\n\n        url = cls(\n            SplitResult(scheme, netloc, path, query_string, fragment), encoded=True\n        )\n\n        if query:\n            return url.with_query(query)\n        else:\n            return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_default_port(self):\n        if self.port is None:\n            return False\n        default = DEFAULT_PORTS.get(self.scheme)\n        if default is None:\n            return False\n        return self.port == default", "response": "A check for default port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef origin(self):\n        # TODO: add a keyword-only option for keeping user/pass maybe?\n        if not self.is_absolute():\n            raise ValueError(\"URL should be absolute\")\n        if not self._val.scheme:\n            raise ValueError(\"URL should have scheme\")\n        v = self._val\n        netloc = self._make_netloc(None, None, v.hostname, v.port, encode=False)\n        val = v._replace(netloc=netloc, path=\"\", query=\"\", fragment=\"\")\n        return URL(val, encoded=True)", "response": "Return an URL with scheme host and port parts only."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relative(self):\n        if not self.is_absolute():\n            raise ValueError(\"URL should be absolute\")\n        val = self._val._replace(scheme=\"\", netloc=\"\")\n        return URL(val, encoded=True)", "response": "Return a relative part of the URL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef host(self):\n        raw = self.raw_host\n        if raw is None:\n            return None\n        if \"%\" in raw:\n            # Hack for scoped IPv6 addresses like\n            # fe80::2%\u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430\n            # presence of '%' sign means only IPv6 address, so idna is useless.\n            return raw\n\n        try:\n            return idna.decode(raw.encode(\"ascii\"))\n        except UnicodeError:  # e.g. '::1'\n            return raw.encode(\"ascii\").decode(\"idna\")", "response": "Decoded host part of URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nport part of URL with scheme - based fallback.", "response": "def port(self):\n        \"\"\"Port part of URL, with scheme-based fallback.\n\n        None for relative URLs or URLs without explicit port and\n        scheme without default port substitution.\n\n        \"\"\"\n        return self._val.port or DEFAULT_PORTS.get(self._val.scheme)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding path of URL.", "response": "def raw_path(self):\n        \"\"\"Encoded path of URL.\n\n        / for absolute URLs without path part.\n\n        \"\"\"\n        ret = self._val.path\n        if not ret and self.is_absolute():\n            ret = \"/\"\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self):\n        ret = MultiDict(parse_qsl(self.raw_query_string, keep_blank_values=True))\n        return MultiDictProxy(ret)", "response": "A MultiDictProxy representing parsed query parameters in decoded\n        representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path_qs(self):\n        if not self.query_string:\n            return self.path\n        return \"{}?{}\".format(self.path, self.query_string)", "response": "Decoded path of URL with query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencode path of URL with query.", "response": "def raw_path_qs(self):\n        \"\"\"Encoded path of URL with query.\"\"\"\n        if not self.raw_query_string:\n            return self.raw_path\n        return \"{}?{}\".format(self.raw_path, self.raw_query_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef raw_parts(self):\n        path = self._val.path\n        if self.is_absolute():\n            if not path:\n                parts = [\"/\"]\n            else:\n                parts = [\"/\"] + path[1:].split(\"/\")\n        else:\n            if path.startswith(\"/\"):\n                parts = [\"/\"] + path[1:].split(\"/\")\n            else:\n                parts = path.split(\"/\")\n        return tuple(parts)", "response": "A tuple containing encoded path * parts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parent(self):\n        path = self.raw_path\n        if not path or path == \"/\":\n            if self.raw_fragment or self.raw_query_string:\n                return URL(self._val._replace(query=\"\", fragment=\"\"), encoded=True)\n            return self\n        parts = path.split(\"/\")\n        val = self._val._replace(path=\"/\".join(parts[:-1]), query=\"\", fragment=\"\")\n        return URL(val, encoded=True)", "response": "A new URL with last part of path removed and cleaned up query and fragment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_authority_uri_abs_path(host, path):\n        if len(host) > 0 and len(path) > 0 and not path.startswith(\"/\"):\n            raise ValueError(\n                \"Path in a URL with authority \" \"should start with a slash ('/') if set\"\n            )", "response": "Ensure that path in URL with authority is absolute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef with_scheme(self, scheme):\n        # N.B. doesn't cleanup query/fragment\n        if not isinstance(scheme, str):\n            raise TypeError(\"Invalid scheme type\")\n        if not self.is_absolute():\n            raise ValueError(\"scheme replacement is not allowed \" \"for relative URLs\")\n        return URL(self._val._replace(scheme=scheme.lower()), encoded=True)", "response": "Return a new URL with scheme replaced."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef with_user(self, user):\n        # N.B. doesn't cleanup query/fragment\n        val = self._val\n        if user is None:\n            password = None\n        elif isinstance(user, str):\n            user = self._QUOTER(user)\n            password = val.password\n        else:\n            raise TypeError(\"Invalid user type\")\n        if not self.is_absolute():\n            raise ValueError(\"user replacement is not allowed \" \"for relative URLs\")\n        return URL(\n            self._val._replace(\n                netloc=self._make_netloc(\n                    user, password, val.hostname, val.port, encode=False\n                )\n            ),\n            encoded=True,\n        )", "response": "Return a new URL with user replaced."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new URL with host replaced.", "response": "def with_host(self, host):\n        \"\"\"Return a new URL with host replaced.\n\n        Autoencode host if needed.\n\n        Changing host for relative URLs is not allowed, use .join()\n        instead.\n\n        \"\"\"\n        # N.B. doesn't cleanup query/fragment\n        if not isinstance(host, str):\n            raise TypeError(\"Invalid host type\")\n        if not self.is_absolute():\n            raise ValueError(\"host replacement is not allowed \" \"for relative URLs\")\n        if not host:\n            raise ValueError(\"host removing is not allowed\")\n        host = self._encode_host(host)\n        val = self._val\n        return URL(\n            self._val._replace(\n                netloc=self._make_netloc(\n                    val.username, val.password, host, val.port, encode=False\n                )\n            ),\n            encoded=True,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef with_port(self, port):\n        # N.B. doesn't cleanup query/fragment\n        if port is not None and not isinstance(port, int):\n            raise TypeError(\"port should be int or None, got {}\".format(type(port)))\n        if not self.is_absolute():\n            raise ValueError(\"port replacement is not allowed \" \"for relative URLs\")\n        val = self._val\n        return URL(\n            self._val._replace(\n                netloc=self._make_netloc(\n                    val.username, val.password, val.hostname, port, encode=False\n                )\n            ),\n            encoded=True,\n        )", "response": "Return a new URL with port replaced."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef with_path(self, path, *, encoded=False):\n        if not encoded:\n            path = self._PATH_QUOTER(path)\n            if self.is_absolute():\n                path = self._normalize_path(path)\n        if len(path) > 0 and path[0] != \"/\":\n            path = \"/\" + path\n        return URL(self._val._replace(path=path, query=\"\", fragment=\"\"), encoded=True)", "response": "Return a new URL with path replaced."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new URL with query part replaced.", "response": "def with_query(self, *args, **kwargs):\n        \"\"\"Return a new URL with query part replaced.\n\n        Accepts any Mapping (e.g. dict, multidict.MultiDict instances)\n        or str, autoencode the argument if needed.\n\n        A sequence of (key, value) pairs is supported as well.\n\n        It also can take an arbitrary number of keyword arguments.\n\n        Clear query if None is passed.\n\n        \"\"\"\n        # N.B. doesn't cleanup query/fragment\n\n        new_query = self._get_str_query(*args, **kwargs)\n        return URL(\n            self._val._replace(path=self._val.path, query=new_query), encoded=True\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_query(self, *args, **kwargs):\n        s = self._get_str_query(*args, **kwargs)\n        new_query = MultiDict(parse_qsl(s, keep_blank_values=True))\n        query = MultiDict(self.query)\n        query.update(new_query)\n\n        return URL(self._val._replace(query=self._get_str_query(query)), encoded=True)", "response": "Return a new URL with query part updated."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef with_fragment(self, fragment):\n        # N.B. doesn't cleanup query/fragment\n        if fragment is None:\n            fragment = \"\"\n        elif not isinstance(fragment, str):\n            raise TypeError(\"Invalid fragment type\")\n        return URL(\n            self._val._replace(fragment=self._FRAGMENT_QUOTER(fragment)), encoded=True\n        )", "response": "Return a new URL with fragment replaced."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef with_name(self, name):\n        # N.B. DOES cleanup query/fragment\n        if not isinstance(name, str):\n            raise TypeError(\"Invalid name type\")\n        if \"/\" in name:\n            raise ValueError(\"Slash in name is not allowed\")\n        name = self._PATH_QUOTER(name)\n        if name in (\".\", \"..\"):\n            raise ValueError(\". and .. values are forbidden\")\n        parts = list(self.raw_parts)\n        if self.is_absolute():\n            if len(parts) == 1:\n                parts.append(name)\n            else:\n                parts[-1] = name\n            parts[0] = \"\"  # replace leading '/'\n        else:\n            parts[-1] = name\n            if parts[0] == \"/\":\n                parts[0] = \"\"  # replace leading '/'\n        return URL(\n            self._val._replace(path=\"/\".join(parts), query=\"\", fragment=\"\"),\n            encoded=True,\n        )", "response": "Return a new URL with name replaced."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef join(self, url):\n        # See docs for urllib.parse.urljoin\n        if not isinstance(url, URL):\n            raise TypeError(\"url should be URL\")\n        return URL(urljoin(str(self), str(url)), encoded=True)", "response": "Join a base URL with another URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef human_repr(self):\n\n        return urlunsplit(\n            SplitResult(\n                self.scheme,\n                self._make_netloc(\n                    self.user, self.password, self.host, self._val.port, encode=False\n                ),\n                self.path,\n                self.query_string,\n                self.fragment,\n            )\n        )", "response": "Return decoded human readable string for URL representation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprompt the user for a value if the user has entered a value.", "response": "def oldconfig(node):\n    \"\"\"\n    Prompts the user for a value if node.item is a visible symbol/choice with\n    no user value.\n    \"\"\"\n    # See main()\n    global conf_changed\n\n    # Only symbols and choices can be configured\n    if not isinstance(node.item, (Symbol, Choice)):\n        return\n\n    # Skip symbols and choices that aren't visible\n    if not node.item.visibility:\n        return\n\n    # Skip symbols and choices that don't have a prompt (at this location)\n    if not node.prompt:\n        return\n\n    if isinstance(node.item, Symbol):\n        sym = node.item\n\n        # Skip symbols that already have a user value\n        if sym.user_value is not None:\n            return\n\n        # Skip symbols that can only have a single value, due to selects\n        if len(sym.assignable) == 1:\n            return\n\n        # Skip symbols in choices in y mode. We ask once for the entire choice\n        # instead.\n        if sym.choice and sym.choice.tri_value == 2:\n            return\n\n        # Loop until the user enters a valid value or enters a blank string\n        # (for the default value)\n        while True:\n            val = input(\"{} ({}) [{}] \".format(\n                node.prompt[0], _name_and_loc_str(sym),\n                _default_value_str(sym)))\n\n            if val == \"?\":\n                _print_help(node)\n                continue\n\n            # Substitute a blank string with the default value the symbol\n            # would get\n            if not val:\n                val = sym.str_value\n\n            # Automatically add a \"0x\" prefix for hex symbols, like the\n            # menuconfig interface does. This isn't done when loading .config\n            # files, hence why set_value() doesn't do it automatically.\n            if sym.type == HEX and not val.startswith((\"0x\", \"0X\")):\n                val = \"0x\" + val\n\n            old_str_val = sym.str_value\n\n            # Kconfiglib itself will print a warning here if the value\n            # is invalid, so we don't need to bother\n            if sym.set_value(val):\n                # Valid value input. We're done with this node.\n\n                if sym.str_value != old_str_val:\n                    conf_changed = True\n\n                return\n\n    else:\n        choice = node.item\n\n        # Skip choices that already have a visible user selection...\n        if choice.user_selection and choice.user_selection.visibility == 2:\n            # ...unless there are new visible symbols in the choice. (We know\n            # they have y (2) visibility in that case, because m-visible\n            # symbols get demoted to n-visibility in y-mode choices, and the\n            # user-selected symbol had visibility y.)\n            for sym in choice.syms:\n                if sym is not choice.user_selection and sym.visibility and \\\n                   sym.user_value is None:\n                    # New visible symbols in the choice\n                    break\n            else:\n                # No new visible symbols in the choice\n                return\n\n        # Get a list of available selections. The mode of the choice limits\n        # the visibility of the choice value symbols, so this will indirectly\n        # skip choices in n and m mode.\n        options = [sym for sym in choice.syms if sym.visibility == 2]\n\n        if not options:\n            # No y-visible choice value symbols\n            return\n\n        # Loop until the user enters a valid selection or a blank string (for\n        # the default selection)\n        while True:\n            print(\"{} ({})\".format(node.prompt[0], _name_and_loc_str(choice)))\n\n            for i, sym in enumerate(options, 1):\n                print(\"{} {}. {} ({})\".format(\n                    \">\" if sym is choice.selection else \" \",\n                    i,\n                    # Assume people don't define choice symbols with multiple\n                    # prompts. That generates a warning anyway.\n                    sym.nodes[0].prompt[0],\n                    sym.name))\n\n            sel_index = input(\"choice[1-{}]: \".format(len(options)))\n\n            if sel_index == \"?\":\n                _print_help(node)\n                continue\n\n            # Pick the default selection if the string is blank\n            if not sel_index:\n                choice.selection.set_value(2)\n                break\n\n            try:\n                sel_index = int(sel_index)\n            except ValueError:\n                print(\"Bad index\", file=sys.stderr)\n                continue\n\n            if not 1 <= sel_index <= len(options):\n                print(\"Bad index\", file=sys.stderr)\n                continue\n\n            # Valid selection\n\n            if options[sel_index - 1].tri_value != 2:\n                conf_changed = True\n\n            options[sel_index - 1].set_value(2)\n            break\n\n        # Give all of the non-selected visible choice symbols the user value n.\n        # This makes it so that the choice is no longer considered new once we\n        # do additional passes, if the reason that it was considered new was\n        # that it had new visible choice symbols.\n        #\n        # Only giving visible choice symbols the user value n means we will\n        # prompt for the choice again if later user selections make more new\n        # choice symbols visible, which is correct.\n        for sym in choice.syms:\n            if sym is not choice.user_selection and sym.visibility:\n                sym.set_value(0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_arch_srcarch_pairs():\n    for srcarch in os.listdir(\"arch\"):\n        # Each subdirectory of arch/ containing a Kconfig file corresponds to\n        # an architecture\n        if os.path.exists(os.path.join(\"arch\", srcarch, \"Kconfig\")):\n            yield (srcarch, srcarch)\n\n    # Some architectures define additional ARCH settings with ARCH != SRCARCH\n    # (search for \"Additional ARCH settings for\" in the top-level Makefile)\n\n    yield (\"i386\", \"x86\")\n    yield (\"x86_64\", \"x86\")\n\n    yield (\"sparc32\", \"sparc\")\n    yield (\"sparc64\", \"sparc\")\n\n    yield (\"sh64\", \"sh\")\n\n    yield (\"um\", \"um\")", "response": "Yields all valid ARCH and SRCARCH tuples for the kernel corresponding to\n    different architectures. SRCARCH holds the arch directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields all the architectures in the kernel", "response": "def all_arch_srcarch_kconfigs():\n    \"\"\"\n    Generates Kconfig instances for all the architectures in the kernel\n    \"\"\"\n\n    os.environ[\"srctree\"] = \".\"\n    os.environ[\"HOSTCC\"] = \"gcc\"\n    os.environ[\"HOSTCXX\"] = \"g++\"\n    os.environ[\"CC\"] = \"gcc\"\n    os.environ[\"LD\"] = \"ld\"\n\n    for arch, srcarch in all_arch_srcarch_pairs():\n        print(\"  Processing \" + arch)\n\n        os.environ[\"ARCH\"] = arch\n        os.environ[\"SRCARCH\"] = srcarch\n\n        # um (User Mode Linux) uses a different base Kconfig file\n        yield Kconfig(\"Kconfig\" if arch != \"um\" else \"arch/x86/um/Kconfig\",\n                      warn=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch the configuration interface returning after the user exits.", "response": "def menuconfig(kconf):\n    \"\"\"\n    Launches the configuration interface, returning after the user exits.\n\n    kconf:\n      Kconfig instance to be configured\n    \"\"\"\n    global _kconf\n    global _conf_filename\n    global _conf_changed\n    global _minconf_filename\n    global _show_all\n\n    _kconf = kconf\n\n    # Load existing configuration and set _conf_changed True if it is outdated\n    _conf_changed = _load_config()\n\n    # Filename to save configuration to\n    _conf_filename = standard_config_filename()\n\n    # Filename to save minimal configuration to\n    _minconf_filename = \"defconfig\"\n\n    # Any visible items in the top menu?\n    _show_all = False\n    if not _shown_nodes(kconf.top_node):\n        # Nothing visible. Start in show-all mode and try again.\n        _show_all = True\n        if not _shown_nodes(kconf.top_node):\n            # Give up. The implementation relies on always having a selected\n            # node.\n            print(\"Empty configuration -- nothing to configure.\\n\"\n                  \"Check that environment variables are set properly.\")\n            return\n\n    # Disable warnings. They get mangled in curses mode, and we deal with\n    # errors ourselves.\n    kconf.disable_warnings()\n\n    # Make curses use the locale settings specified in the environment\n    locale.setlocale(locale.LC_ALL, \"\")\n\n    # Try to fix Unicode issues on systems with bad defaults\n    if _CONVERT_C_LC_CTYPE_TO_UTF8:\n        _convert_c_lc_ctype_to_utf8()\n\n    # Get rid of the delay between pressing ESC and jumping to the parent menu,\n    # unless the user has set ESCDELAY (see ncurses(3)). This makes the UI much\n    # smoother to work with.\n    #\n    # Note: This is strictly pretty iffy, since escape codes for e.g. cursor\n    # keys start with ESC, but I've never seen it cause problems in practice\n    # (probably because it's unlikely that the escape code for a key would get\n    # split up across read()s, at least with a terminal emulator). Please\n    # report if you run into issues. Some suitable small default value could be\n    # used here instead in that case. Maybe it's silly to not put in the\n    # smallest imperceptible delay here already, though I don't like guessing.\n    #\n    # (From a quick glance at the ncurses source code, ESCDELAY might only be\n    # relevant for mouse events there, so maybe escapes are assumed to arrive\n    # in one piece already...)\n    os.environ.setdefault(\"ESCDELAY\", \"0\")\n\n    # Enter curses mode. _menuconfig() returns a string to print on exit, after\n    # curses has been de-initialized.\n    print(curses.wrapper(_menuconfig))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value part of a menu entry.", "response": "def value_str(sc):\n    \"\"\"\n    Returns the value part (\"[*]\", \"<M>\", \"(foo)\" etc.) of a menu entry.\n\n    sc: Symbol or Choice.\n    \"\"\"\n    if sc.type in (STRING, INT, HEX):\n        return \"({})\".format(sc.str_value)\n\n    # BOOL or TRISTATE\n\n    # The choice mode is an upper bound on the visibility of choice symbols, so\n    # we can check the choice symbols' own visibility to see if the choice is\n    # in y mode\n    if isinstance(sc, Symbol) and sc.choice and sc.visibility == 2:\n        # For choices in y mode, print '-->' next to the selected symbol\n        return \"-->\" if sc.choice.selection is sc else \"   \"\n\n    tri_val_str = (\" \", \"M\", \"*\")[sc.tri_value]\n\n    if len(sc.assignable) == 1:\n        # Pinned to a single value\n        return \"-{}-\".format(tri_val_str)\n\n    if sc.type == BOOL:\n        return \"[{}]\".format(tri_val_str)\n\n    if sc.type == TRISTATE:\n        if sc.assignable == (1, 2):\n            # m and y available\n            return \"{\" + tri_val_str + \"}\"  # Gets a bit confusing with .format()\n        return \"<{}>\".format(tri_val_str)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef node_str(node):\n    if not node.prompt:\n        return \"\"\n\n    # Even for menu nodes for symbols and choices, it's wrong to check\n    # Symbol.visibility / Choice.visibility here. The reason is that a symbol\n    # (and a choice, in theory) can be defined in multiple locations, giving it\n    # multiple menu nodes, which do not necessarily all have the same prompt\n    # visibility. Symbol.visibility / Choice.visibility is calculated as the OR\n    # of the visibility of all the prompts.\n    prompt, prompt_cond = node.prompt\n    if not expr_value(prompt_cond):\n        return \"\"\n\n    if node.item == MENU:\n        return \"    \" + prompt\n\n    if node.item == COMMENT:\n        return \"    *** {} ***\".format(prompt)\n\n    # Symbol or Choice\n\n    sc = node.item\n\n    if sc.type == UNKNOWN:\n        # Skip symbols defined without a type (these are obscure and generate\n        # a warning)\n        return \"\"\n\n    # Add help text\n    if WITH_HELP_DESC:\n        prompt += ' - ' + str(node.help).replace('\\n', ' ').replace('\\r', '')\n\n    # {:3} sets the field width to three. Gives nice alignment for empty string\n    # values.\n    res = \"{:3} {}\".format(value_str(sc), prompt)\n\n    # Don't print the name for unnamed choices (the normal kind)\n    if sc.name is not None:\n        res += \" ({})\".format(sc.name)\n\n    return res", "response": "Returns a string representation of a menu node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_menuconfig_nodes(node, indent):\n    while node:\n        string = node_str(node)\n        if string:\n            indent_print(string, indent)\n\n        if node.list:\n            print_menuconfig_nodes(node.list, indent + 8)\n\n        node = node.next", "response": "Prints a tree with all the menu entries rooted at node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_menuconfig(kconf):\n    # Print the expanded mainmenu text at the top. This is the same as\n    # kconf.top_node.prompt[0], but with variable references expanded.\n    print(\"\\n======== {} ========\\n\".format(kconf.mainmenu_text))\n\n    print_menuconfig_nodes(kconf.top_node.list, 0)\n    print(\"\")", "response": "Prints the mainmenu text at the top of the menu."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the expression expr to a tristate value.", "response": "def expr_value(expr):\n    \"\"\"\n    Evaluates the expression 'expr' to a tristate value. Returns 0 (n), 1 (m),\n    or 2 (y).\n\n    'expr' must be an already-parsed expression from a Symbol, Choice, or\n    MenuNode property. To evaluate an expression represented as a string, use\n    Kconfig.eval_string().\n\n    Passing subexpressions of expressions to this function works as expected.\n    \"\"\"\n    if expr.__class__ is not tuple:\n        return expr.tri_value\n\n    if expr[0] is AND:\n        v1 = expr_value(expr[1])\n        # Short-circuit the n case as an optimization (~5% faster\n        # allnoconfig.py and allyesconfig.py, as of writing)\n        return 0 if not v1 else min(v1, expr_value(expr[2]))\n\n    if expr[0] is OR:\n        v1 = expr_value(expr[1])\n        # Short-circuit the y case as an optimization\n        return 2 if v1 == 2 else max(v1, expr_value(expr[2]))\n\n    if expr[0] is NOT:\n        return 2 - expr_value(expr[1])\n\n    # Relation\n    #\n    # Implements <, <=, >, >= comparisons as well. These were added to\n    # kconfig in 31847b67 (kconfig: allow use of relations other than\n    # (in)equality).\n\n    rel, v1, v2 = expr\n\n    # If both operands are strings...\n    if v1.orig_type is STRING and v2.orig_type is STRING:\n        # ...then compare them lexicographically\n        comp = _strcmp(v1.str_value, v2.str_value)\n    else:\n        # Otherwise, try to compare them as numbers\n        try:\n            comp = _sym_to_num(v1) - _sym_to_num(v2)\n        except ValueError:\n            # Fall back on a lexicographic comparison if the operands don't\n            # parse as numbers\n            comp = _strcmp(v1.str_value, v2.str_value)\n\n    if rel is EQUAL:      return 2*(comp == 0)\n    if rel is UNEQUAL:    return 2*(comp != 0)\n    if rel is LESS:       return 2*(comp < 0)\n    if rel is LESS_EQUAL: return 2*(comp <= 0)\n    if rel is GREATER:    return 2*(comp > 0)\n    return 2*(comp >= 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the string representation of the expression expr as in a Kconfig file.", "response": "def expr_str(expr, sc_expr_str_fn=standard_sc_expr_str):\n    \"\"\"\n    Returns the string representation of the expression 'expr', as in a Kconfig\n    file.\n\n    Passing subexpressions of expressions to this function works as expected.\n\n    sc_expr_str_fn (default: standard_sc_expr_str):\n      This function is called for every symbol/choice (hence \"sc\") appearing in\n      the expression, with the symbol/choice as the argument. It is expected to\n      return a string to be used for the symbol/choice.\n\n      This can be used e.g. to turn symbols/choices into links when generating\n      documentation, or for printing the value of each symbol/choice after it.\n\n      Note that quoted values are represented as constants symbols\n      (Symbol.is_constant == True).\n    \"\"\"\n    if expr.__class__ is not tuple:\n        return sc_expr_str_fn(expr)\n\n    if expr[0] is AND:\n        return \"{} && {}\".format(_parenthesize(expr[1], OR, sc_expr_str_fn),\n                                 _parenthesize(expr[2], OR, sc_expr_str_fn))\n\n    if expr[0] is OR:\n        # This turns A && B || C && D into \"(A && B) || (C && D)\", which is\n        # redundant, but more readable\n        return \"{} || {}\".format(_parenthesize(expr[1], AND, sc_expr_str_fn),\n                                 _parenthesize(expr[2], AND, sc_expr_str_fn))\n\n    if expr[0] is NOT:\n        if expr[1].__class__ is tuple:\n            return \"!({})\".format(expr_str(expr[1], sc_expr_str_fn))\n        return \"!\" + sc_expr_str_fn(expr[1])  # Symbol\n\n    # Relation\n    #\n    # Relation operands are always symbols (quoted strings are constant\n    # symbols)\n    return \"{} {} {}\".format(sc_expr_str_fn(expr[1]), _REL_TO_STR[expr[0]],\n                             sc_expr_str_fn(expr[2]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a set of all items that appear in the expression expr.", "response": "def expr_items(expr):\n    \"\"\"\n    Returns a set() of all items (symbols and choices) that appear in the\n    expression 'expr'.\n    \"\"\"\n\n    res = set()\n\n    def rec(subexpr):\n        if subexpr.__class__ is tuple:\n            # AND, OR, NOT, or relation\n\n            rec(subexpr[1])\n\n            # NOTs only have a single operand\n            if subexpr[0] is not NOT:\n                rec(subexpr[2])\n\n        else:\n            # Symbol or choice\n            res.add(subexpr)\n\n    rec(expr)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_expr(expr, op):\n    res = []\n\n    def rec(subexpr):\n        if subexpr.__class__ is tuple and subexpr[0] is op:\n            rec(subexpr[1])\n            rec(subexpr[2])\n        else:\n            res.append(subexpr)\n\n    rec(expr)\n    return res", "response": "Splits an expression into a list of top - level AND or OR operands."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef standard_kconfig():\n    if len(sys.argv) > 2:\n        sys.exit(\"usage: {} [Kconfig]\".format(sys.argv[0]))\n\n    # Only show backtraces for unexpected exceptions\n    try:\n        return Kconfig(\"Kconfig\" if len(sys.argv) < 2 else sys.argv[1])\n    except (IOError, KconfigError) as e:\n        # Some long exception messages have extra newlines for better\n        # formatting when reported as an unhandled exception. Strip them here.\n        sys.exit(str(e).strip())", "response": "A helper for tools. Loads the top - level Kconfig specified as the first\n    command - line argument or Kconfig if there are no command - line arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload all configuration files.", "response": "def load_allconfig(kconf, filename):\n    \"\"\"\n    Helper for all*config. Loads (merges) the configuration file specified by\n    KCONFIG_ALLCONFIG, if any. See Documentation/kbuild/kconfig.txt in the\n    Linux kernel.\n\n    Disables warnings for duplicated assignments within configuration files for\n    the duration of the call (disable_override_warnings() +\n    disable_redun_warnings()), and enables them at the end. The\n    KCONFIG_ALLCONFIG configuration file is expected to override symbols.\n\n    Exits with sys.exit() (which raises a SystemExit exception) and prints an\n    error to stderr if KCONFIG_ALLCONFIG is set but the configuration file\n    can't be opened.\n\n    kconf:\n      Kconfig instance to load the configuration in.\n\n    filename:\n      Command-specific configuration filename - \"allyes.config\",\n      \"allno.config\", etc.\n    \"\"\"\n    def std_msg(e):\n        # \"Upcasts\" a _KconfigIOError to an IOError, removing the custom\n        # __str__() message. The standard message is better here.\n        return IOError(e.errno, e.strerror, e.filename)\n\n    kconf.disable_override_warnings()\n    kconf.disable_redun_warnings()\n\n    allconfig = os.environ.get(\"KCONFIG_ALLCONFIG\")\n    if allconfig is not None:\n        if allconfig in (\"\", \"1\"):\n            try:\n                kconf.load_config(filename, False)\n            except IOError as e1:\n                try:\n                    kconf.load_config(\"all.config\", False)\n                except IOError as e2:\n                    sys.exit(\"error: KCONFIG_ALLCONFIG is set, but neither {} \"\n                             \"nor all.config could be opened: {}, {}\"\n                             .format(filename, std_msg(e1), std_msg(e2)))\n        else:\n            try:\n                kconf.load_config(allconfig, False)\n            except IOError as e:\n                sys.exit(\"error: KCONFIG_ALLCONFIG is set to '{}', which \"\n                         \"could not be opened: {}\"\n                         .format(allconfig, std_msg(e)))\n\n    # API wart: It would be nice if there was a way to query and/or push/pop\n    # warning settings\n    kconf.enable_override_warnings()\n    kconf.enable_redun_warnings()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef defconfig_filename(self):\n        if self.defconfig_list:\n            for filename, cond in self.defconfig_list.defaults:\n                if expr_value(cond):\n                    try:\n                        with self._open_config(filename.str_value) as f:\n                            return f.name\n                    except IOError:\n                        continue\n\n        return None", "response": "Returns the name of the default config file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the values from a file in the configuration file format.", "response": "def load_config(self, filename=None, replace=True, verbose=True):\n        \"\"\"\n        Loads symbol values from a file in the .config format. Equivalent to\n        calling Symbol.set_value() to set each of the values.\n\n        \"# CONFIG_FOO is not set\" within a .config file sets the user value of\n        FOO to n. The C tools work the same way.\n\n        For each symbol, the Symbol.user_value attribute holds the value the\n        symbol was assigned in the .config file (if any). The user value might\n        differ from Symbol.str/tri_value if there are unsatisfied dependencies.\n\n        Calling this function also updates the Kconfig.missing_syms attribute\n        with a list of all assignments to undefined symbols within the\n        configuration file. Kconfig.missing_syms is cleared if 'replace' is\n        True, and appended to otherwise. See the documentation for\n        Kconfig.missing_syms as well.\n\n        Raises (possibly a subclass of) IOError on IO errors ('errno',\n        'strerror', and 'filename' are available). Note that IOError can be\n        caught as OSError on Python 3.\n\n        filename (default: None):\n          Path to load configuration from (a string). Respects $srctree if set\n          (see the class documentation).\n\n          If 'filename' is None (the default), the configuration file to load\n          (if any) is calculated automatically, giving the behavior you'd\n          usually want:\n\n            1. If the KCONFIG_CONFIG environment variable is set, it gives the\n               path to the configuration file to load. Otherwise, \".config\" is\n               used. See standard_config_filename().\n\n            2. If the path from (1.) doesn't exist, the configuration file\n               given by kconf.defconfig_filename is loaded instead, which is\n               derived from the 'option defconfig_list' symbol.\n\n            3. If (1.) and (2.) fail to find a configuration file to load, no\n               configuration file is loaded, and symbols retain their current\n               values (e.g., their default values). This is not an error.\n\n           See the return value as well.\n\n        replace (default: True):\n          If True, all existing user values will be cleared before loading the\n          .config. Pass False to merge configurations.\n\n        verbose (default: True):\n          If True and filename is None (automatically infer configuration\n          file), a message will be printed to stdout telling which file got\n          loaded (or that no file got loaded). This is meant to reduce\n          boilerplate in tools.\n\n        Returns True if an existing configuration was loaded (that didn't come\n        from the 'option defconfig_list' symbol), and False otherwise. This is\n        mostly useful in conjunction with filename=None, as True will always be\n        returned otherwise.\n        \"\"\"\n        loaded_existing = True\n        if filename is None:\n            filename = standard_config_filename()\n            if exists(filename):\n                if verbose:\n                    print(\"Using existing configuration '{}' as base\"\n                          .format(filename))\n            else:\n                filename = self.defconfig_filename\n                if filename is None:\n                    if verbose:\n                        print(\"Using default symbol values as base\")\n                    return False\n\n                if verbose:\n                    print(\"Using default configuration found in '{}' as \"\n                          \"base\".format(filename))\n\n                loaded_existing = False\n\n        # Disable the warning about assigning to symbols without prompts. This\n        # is normal and expected within a .config file.\n        self._warn_for_no_prompt = False\n\n        # This stub only exists to make sure _warn_for_no_prompt gets reenabled\n        try:\n            self._load_config(filename, replace)\n        except UnicodeDecodeError as e:\n            _decoding_error(e, filename)\n        finally:\n            self._warn_for_no_prompt = True\n\n        return loaded_existing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite out a minimal configuration file.", "response": "def write_min_config(self, filename,\n                         header=\"# Generated by Kconfiglib (https://github.com/ulfalizer/Kconfiglib)\\n\"):\n        \"\"\"\n        Writes out a \"minimal\" configuration file, omitting symbols whose value\n        matches their default value. The format matches the one produced by\n        'make savedefconfig'.\n\n        The resulting configuration file is incomplete, but a complete\n        configuration can be derived from it by loading it. Minimal\n        configuration files can serve as a more manageable configuration format\n        compared to a \"full\" .config file, especially when configurations files\n        are merged or edited by hand.\n\n        filename:\n          Self-explanatory.\n\n        header (default: \"# Generated by Kconfiglib (https://github.com/ulfalizer/Kconfiglib)\\n\"):\n          Text that will be inserted verbatim at the beginning of the file. You\n          would usually want each line to start with '#' to make it a comment,\n          and include a final terminating newline.\n        \"\"\"\n        with self._open(filename, \"w\") as f:\n            f.write(header)\n\n            for sym in self.unique_defined_syms:\n                # Skip symbols that cannot be changed. Only check\n                # non-choice symbols, as selects don't affect choice\n                # symbols.\n                if not sym.choice and \\\n                   sym.visibility <= expr_value(sym.rev_dep):\n                    continue\n\n                # Skip symbols whose value matches their default\n                if sym.str_value == sym._str_default():\n                    continue\n\n                # Skip symbols that would be selected by default in a\n                # choice, unless the choice is optional or the symbol type\n                # isn't bool (it might be possible to set the choice mode\n                # to n or the symbol to m in those cases).\n                if sym.choice and \\\n                   not sym.choice.is_optional and \\\n                   sym.choice._get_selection_from_defaults() is sym and \\\n                   sym.orig_type is BOOL and \\\n                   sym.tri_value == 2:\n                    continue\n\n                f.write(sym.config_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sync_deps(self, path):\n        if not exists(path):\n            os.mkdir(path, 0o755)\n\n        # Load old values from auto.conf, if any\n        self._load_old_vals(path)\n\n        for sym in self.unique_defined_syms:\n            # Note: _write_to_conf is determined when the value is\n            # calculated. This is a hidden function call due to\n            # property magic.\n            val = sym.str_value\n\n            # Note: n tristate values do not get written to auto.conf and\n            # autoconf.h, making a missing symbol logically equivalent to n\n\n            if sym._write_to_conf:\n                if sym._old_val is None and \\\n                   sym.orig_type in _BOOL_TRISTATE and \\\n                   val == \"n\":\n                    # No old value (the symbol was missing or n), new value n.\n                    # No change.\n                    continue\n\n                if val == sym._old_val:\n                    # New value matches old. No change.\n                    continue\n\n            elif sym._old_val is None:\n                # The symbol wouldn't appear in autoconf.h (because\n                # _write_to_conf is false), and it wouldn't have appeared in\n                # autoconf.h previously either (because it didn't appear in\n                # auto.conf). No change.\n                continue\n\n            # 'sym' has a new value. Flag it.\n            _touch_dep_file(path, sym.name)\n\n        # Remember the current values as the \"new old\" values.\n        #\n        # This call could go anywhere after the call to _load_old_vals(), but\n        # putting it last means _sync_deps() can be safely rerun if it fails\n        # before this point.\n        self._write_old_vals(path)", "response": "This function creates or updates a directory structure that can be used to avoid rebuilding the configuration files that depend on the current configuration symbols."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator over all MenuNodes in the Kconfig tree.", "response": "def node_iter(self, unique_syms=False):\n        \"\"\"\n        Returns a generator for iterating through all MenuNode's in the Kconfig\n        tree. The iteration is done in Kconfig definition order (each node is\n        visited before its children, and the children of a node are visited\n        before the next node).\n\n        The Kconfig.top_node menu node is skipped. It contains an implicit menu\n        that holds the top-level items.\n\n        As an example, the following code will produce a list equal to\n        Kconfig.defined_syms:\n\n          defined_syms = [node.item for node in kconf.node_iter()\n                          if isinstance(node.item, Symbol)]\n\n        unique_syms (default: False):\n          If True, only the first MenuNode will be included for symbols defined\n          in multiple locations.\n\n          Using kconf.node_iter(True) in the example above would give a list\n          equal to unique_defined_syms.\n        \"\"\"\n        if unique_syms:\n            for sym in self.unique_defined_syms:\n                sym._visited = False\n\n        node = self.top_node\n        while 1:\n            # Jump to the next node with an iterative tree walk\n            if node.list:\n                node = node.list\n            elif node.next:\n                node = node.next\n            else:\n                while node.parent:\n                    node = node.parent\n                    if node.next:\n                        node = node.next\n                        break\n                else:\n                    # No more nodes\n                    return\n\n            if unique_syms and node.item.__class__ is Symbol:\n                if node.item._visited:\n                    continue\n                node.item._visited = True\n\n            yield node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eval_string(self, s):\n        # The parser is optimized to be fast when parsing Kconfig files (where\n        # an expression can never appear at the beginning of a line). We have\n        # to monkey-patch things a bit here to reuse it.\n\n        self._filename = None\n\n        # Don't include the \"if \" from below to avoid giving confusing error\n        # messages\n        self._line = s\n        self._tokens = self._tokenize(\"if \" + s)\n        self._tokens_i = 1  # Skip the 'if' token\n\n        return expr_value(self._expect_expr_and_eol())", "response": "Evaluate a string containing a tristate value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset the user values of all symbols and choices.", "response": "def unset_values(self):\n        \"\"\"\n        Resets the user values of all symbols, as if Kconfig.load_config() or\n        Symbol.set_value() had never been called.\n        \"\"\"\n        self._warn_for_no_prompt = False\n        try:\n            # set_value() already rejects undefined symbols, and they don't\n            # need to be invalidated (because their value never changes), so we\n            # can just iterate over defined symbols\n            for sym in self.unique_defined_syms:\n                sym.unset_value()\n\n            for choice in self.unique_choices:\n                choice.unset_value()\n        finally:\n            self._warn_for_no_prompt = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the type of the object.", "response": "def type(self):\n        \"\"\"\n        See the class documentation.\n        \"\"\"\n        if self.orig_type is TRISTATE and \\\n           ((self.choice and self.choice.tri_value == 2) or\n            not self.kconfig.modules.tri_value):\n\n            return BOOL\n\n        return self.orig_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef str_value(self):\n        if self._cached_str_val is not None:\n            return self._cached_str_val\n\n        if self.orig_type in _BOOL_TRISTATE:\n            # Also calculates the visibility, so invalidation safe\n            self._cached_str_val = TRI_TO_STR[self.tri_value]\n            return self._cached_str_val\n\n        # As a quirk of Kconfig, undefined symbols get their name as their\n        # string value. This is why things like \"FOO = bar\" work for seeing if\n        # FOO has the value \"bar\".\n        if not self.orig_type:  # UNKNOWN\n            self._cached_str_val = self.name\n            return self.name\n\n        val = \"\"\n        # Warning: See Symbol._rec_invalidate(), and note that this is a hidden\n        # function call (property magic)\n        vis = self.visibility\n\n        self._write_to_conf = (vis != 0)\n\n        if self.orig_type in _INT_HEX:\n            # The C implementation checks the user value against the range in a\n            # separate code path (post-processing after loading a .config).\n            # Checking all values here instead makes more sense for us. It\n            # requires that we check for a range first.\n\n            base = _TYPE_TO_BASE[self.orig_type]\n\n            # Check if a range is in effect\n            for low_expr, high_expr, cond in self.ranges:\n                if expr_value(cond):\n                    has_active_range = True\n\n                    # The zeros are from the C implementation running strtoll()\n                    # on empty strings\n                    low = int(low_expr.str_value, base) if \\\n                      _is_base_n(low_expr.str_value, base) else 0\n                    high = int(high_expr.str_value, base) if \\\n                      _is_base_n(high_expr.str_value, base) else 0\n\n                    break\n            else:\n                has_active_range = False\n\n            # Defaults are used if the symbol is invisible, lacks a user value,\n            # or has an out-of-range user value\n            use_defaults = True\n\n            if vis and self.user_value:\n                user_val = int(self.user_value, base)\n                if has_active_range and not low <= user_val <= high:\n                    num2str = str if base == 10 else hex\n                    self.kconfig._warn(\n                        \"user value {} on the {} symbol {} ignored due to \"\n                        \"being outside the active range ([{}, {}]) -- falling \"\n                        \"back on defaults\"\n                        .format(num2str(user_val), TYPE_TO_STR[self.orig_type],\n                                _name_and_loc(self),\n                                num2str(low), num2str(high)))\n                else:\n                    # If the user value is well-formed and satisfies range\n                    # contraints, it is stored in exactly the same form as\n                    # specified in the assignment (with or without \"0x\", etc.)\n                    val = self.user_value\n                    use_defaults = False\n\n            if use_defaults:\n                # No user value or invalid user value. Look at defaults.\n\n                # Used to implement the warning below\n                has_default = False\n\n                for sym, cond in self.defaults:\n                    if expr_value(cond):\n                        has_default = self._write_to_conf = True\n\n                        val = sym.str_value\n\n                        if _is_base_n(val, base):\n                            val_num = int(val, base)\n                        else:\n                            val_num = 0  # strtoll() on empty string\n\n                        break\n                else:\n                    val_num = 0  # strtoll() on empty string\n\n                # This clamping procedure runs even if there's no default\n                if has_active_range:\n                    clamp = None\n                    if val_num < low:\n                        clamp = low\n                    elif val_num > high:\n                        clamp = high\n\n                    if clamp is not None:\n                        # The value is rewritten to a standard form if it is\n                        # clamped\n                        val = str(clamp) \\\n                              if self.orig_type is INT else \\\n                              hex(clamp)\n\n                        if has_default:\n                            num2str = str if base == 10 else hex\n                            self.kconfig._warn(\n                                \"default value {} on {} clamped to {} due to \"\n                                \"being outside the active range ([{}, {}])\"\n                                .format(val_num, _name_and_loc(self),\n                                        num2str(clamp), num2str(low),\n                                        num2str(high)))\n\n        elif self.orig_type is STRING:\n            if vis and self.user_value is not None:\n                # If the symbol is visible and has a user value, use that\n                val = self.user_value\n            else:\n                # Otherwise, look at defaults\n                for sym, cond in self.defaults:\n                    if expr_value(cond):\n                        val = sym.str_value\n                        self._write_to_conf = True\n                        break\n\n        # env_var corresponds to SYMBOL_AUTO in the C implementation, and is\n        # also set on the defconfig_list symbol there. Test for the\n        # defconfig_list symbol explicitly instead here, to avoid a nonsensical\n        # env_var setting and the defconfig_list symbol being printed\n        # incorrectly. This code is pretty cold anyway.\n        if self.env_var is not None or self is self.kconfig.defconfig_list:\n            self._write_to_conf = False\n\n        self._cached_str_val = val\n        return val", "response": "Returns the string value of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of the current logical context entry.", "response": "def tri_value(self):\n        \"\"\"\n        See the class documentation.\n        \"\"\"\n        if self._cached_tri_val is not None:\n            return self._cached_tri_val\n\n        if self.orig_type not in _BOOL_TRISTATE:\n            if self.orig_type:  # != UNKNOWN\n                # Would take some work to give the location here\n                self.kconfig._warn(\n                    \"The {} symbol {} is being evaluated in a logical context \"\n                    \"somewhere. It will always evaluate to n.\"\n                    .format(TYPE_TO_STR[self.orig_type], _name_and_loc(self)))\n\n            self._cached_tri_val = 0\n            return 0\n\n        # Warning: See Symbol._rec_invalidate(), and note that this is a hidden\n        # function call (property magic)\n        vis = self.visibility\n        self._write_to_conf = (vis != 0)\n\n        val = 0\n\n        if not self.choice:\n            # Non-choice symbol\n\n            if vis and self.user_value is not None:\n                # If the symbol is visible and has a user value, use that\n                val = min(self.user_value, vis)\n\n            else:\n                # Otherwise, look at defaults and weak reverse dependencies\n                # (implies)\n\n                for default, cond in self.defaults:\n                    dep_val = expr_value(cond)\n                    if dep_val:\n                        val = min(expr_value(default), dep_val)\n                        if val:\n                            self._write_to_conf = True\n                        break\n\n                # Weak reverse dependencies are only considered if our\n                # direct dependencies are met\n                dep_val = expr_value(self.weak_rev_dep)\n                if dep_val and expr_value(self.direct_dep):\n                    val = max(dep_val, val)\n                    self._write_to_conf = True\n\n            # Reverse (select-related) dependencies take precedence\n            dep_val = expr_value(self.rev_dep)\n            if dep_val:\n                if expr_value(self.direct_dep) < dep_val:\n                    self._warn_select_unsatisfied_deps()\n\n                val = max(dep_val, val)\n                self._write_to_conf = True\n\n            # m is promoted to y for (1) bool symbols and (2) symbols with a\n            # weak_rev_dep (from imply) of y\n            if val == 1 and \\\n               (self.type is BOOL or expr_value(self.weak_rev_dep) == 2):\n                val = 2\n\n        elif vis == 2:\n            # Visible choice symbol in y-mode choice. The choice mode limits\n            # the visibility of choice symbols, so it's sufficient to just\n            # check the visibility of the choice symbols themselves.\n            val = 2 if self.choice.selection is self else 0\n\n        elif vis and self.user_value:\n            # Visible choice symbol in m-mode choice, with set non-0 user value\n            val = 1\n\n        self._cached_tri_val = val\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the object is assignable to the other object.", "response": "def assignable(self):\n        \"\"\"\n        See the class documentation.\n        \"\"\"\n        if self._cached_assignable is None:\n            self._cached_assignable = self._assignable()\n\n        return self._cached_assignable"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the visibility of the object.", "response": "def visibility(self):\n        \"\"\"\n        See the class documentation.\n        \"\"\"\n        if self._cached_vis is None:\n            self._cached_vis = _visibility(self)\n\n        return self._cached_vis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef config_string(self):\n        # Note: _write_to_conf is determined when the value is calculated. This\n        # is a hidden function call due to property magic.\n        val = self.str_value\n        if not self._write_to_conf:\n            return \"\"\n\n        if self.orig_type in _BOOL_TRISTATE:\n            return \"{}{}={}\\n\" \\\n                   .format(self.kconfig.config_prefix, self.name, val) \\\n                   if val != \"n\" else \\\n                   \"# {}{} is not set\\n\" \\\n                   .format(self.kconfig.config_prefix, self.name)\n\n        if self.orig_type in _INT_HEX:\n            return \"{}{}={}\\n\" \\\n                   .format(self.kconfig.config_prefix, self.name, val)\n\n        # sym.orig_type is STRING\n        return '{}{}=\"{}\"\\n' \\\n               .format(self.kconfig.config_prefix, self.name, escape(val))", "response": "Return the config string for the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the user value of the symbol.", "response": "def set_value(self, value):\n        \"\"\"\n        Sets the user value of the symbol.\n\n        Equal in effect to assigning the value to the symbol within a .config\n        file. For bool and tristate symbols, use the 'assignable' attribute to\n        check which values can currently be assigned. Setting values outside\n        'assignable' will cause Symbol.user_value to differ from\n        Symbol.str/tri_value (be truncated down or up).\n\n        Setting a choice symbol to 2 (y) sets Choice.user_selection to the\n        choice symbol in addition to setting Symbol.user_value.\n        Choice.user_selection is considered when the choice is in y mode (the\n        \"normal\" mode).\n\n        Other symbols that depend (possibly indirectly) on this symbol are\n        automatically recalculated to reflect the assigned value.\n\n        value:\n          The user value to give to the symbol. For bool and tristate symbols,\n          n/m/y can be specified either as 0/1/2 (the usual format for tristate\n          values in Kconfiglib) or as one of the strings \"n\"/\"m\"/\"y\". For other\n          symbol types, pass a string.\n\n          Values that are invalid for the type (such as \"foo\" or 1 (m) for a\n          BOOL or \"0x123\" for an INT) are ignored and won't be stored in\n          Symbol.user_value. Kconfiglib will print a warning by default for\n          invalid assignments, and set_value() will return False.\n\n        Returns True if the value is valid for the type of the symbol, and\n        False otherwise. This only looks at the form of the value. For BOOL and\n        TRISTATE symbols, check the Symbol.assignable attribute to see what\n        values are currently in range and would actually be reflected in the\n        value of the symbol. For other symbol types, check whether the\n        visibility is non-n.\n        \"\"\"\n        # If the new user value matches the old, nothing changes, and we can\n        # save some work.\n        #\n        # This optimization is skipped for choice symbols: Setting a choice\n        # symbol's user value to y might change the state of the choice, so it\n        # wouldn't be safe (symbol user values always match the values set in a\n        # .config file or via set_value(), and are never implicitly updated).\n        if value == self.user_value and not self.choice:\n            self._was_set = True\n            return True\n\n        # Check if the value is valid for our type\n        if not (self.orig_type is BOOL     and value in (2, 0, \"y\", \"n\")         or\n                self.orig_type is TRISTATE and value in (2, 1, 0, \"y\", \"m\", \"n\") or\n                (value.__class__ is str    and\n                 (self.orig_type is STRING                        or\n                  self.orig_type is INT and _is_base_n(value, 10) or\n                  self.orig_type is HEX and _is_base_n(value, 16)\n                                        and int(value, 16) >= 0))):\n\n            # Display tristate values as n, m, y in the warning\n            self.kconfig._warn(\n                \"the value {} is invalid for {}, which has type {} -- \"\n                \"assignment ignored\"\n                .format(TRI_TO_STR[value] if value in (0, 1, 2) else\n                            \"'{}'\".format(value),\n                        _name_and_loc(self), TYPE_TO_STR[self.orig_type]))\n\n            return False\n\n        if self.orig_type in _BOOL_TRISTATE and value in (\"y\", \"m\", \"n\"):\n            value = STR_TO_TRI[value]\n\n        self.user_value = value\n        self._was_set = True\n\n        if self.choice and value == 2:\n            # Setting a choice symbol to y makes it the user selection of the\n            # choice. Like for symbol user values, the user selection is not\n            # guaranteed to match the actual selection of the choice, as\n            # dependencies come into play.\n            self.choice.user_selection = self\n            self.choice._was_set = True\n            self.choice._rec_invalidate()\n        else:\n            self._rec_invalidate_if_has_prompt()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef custom_str(self, sc_expr_str_fn):\n        return \"\\n\\n\".join(node.custom_str(sc_expr_str_fn)\n                           for node in self.nodes)", "response": "Returns a string representation of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of the key - value tuple for the current class entry.", "response": "def tri_value(self):\n        \"\"\"\n        See the class documentation.\n        \"\"\"\n        # This emulates a reverse dependency of 'm && visibility' for\n        # non-optional choices, which is how the C implementation does it\n\n        val = 0 if self.is_optional else 1\n\n        if self.user_value is not None:\n            val = max(val, self.user_value)\n\n        # Warning: See Symbol._rec_invalidate(), and note that this is a hidden\n        # function call (property magic)\n        val = min(val, self.visibility)\n\n        # Promote m to y for boolean choices\n        return 2 if val == 1 and self.type is BOOL else val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the current selection.", "response": "def selection(self):\n        \"\"\"\n        See the class documentation.\n        \"\"\"\n        if self._cached_selection is _NO_CACHED_SELECTION:\n            self._cached_selection = self._selection()\n\n        return self._cached_selection"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_value(self, value):\n        if value == self.user_value:\n            # We know the value must be valid if it was successfully set\n            # previously\n            self._was_set = True\n            return True\n\n        if not ((self.orig_type is BOOL     and value in (2, 0, \"y\", \"n\")        ) or\n                (self.orig_type is TRISTATE and value in (2, 1, 0, \"y\", \"m\", \"n\"))):\n\n            # Display tristate values as n, m, y in the warning\n            self.kconfig._warn(\n                \"the value {} is invalid for {}, which has type {} -- \"\n                \"assignment ignored\"\n                .format(TRI_TO_STR[value] if value in (0, 1, 2) else\n                            \"'{}'\".format(value),\n                        _name_and_loc(self),\n                        TYPE_TO_STR[self.orig_type]))\n\n            return False\n\n        if value in (\"y\", \"m\", \"n\"):\n            value = STR_TO_TRI[value]\n\n        self.user_value = value\n        self._was_set = True\n        self._rec_invalidate()\n\n        return True", "response": "Sets the value of the current value of the current choice."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unset_value(self):\n        if self.user_value is not None or self.user_selection:\n            self.user_value = self.user_selection = None\n            self._rec_invalidate()", "response": "Resets the user value and user selection of the Choice."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef referenced(self):\n        # self.dep is included to catch dependencies from a lone 'depends on'\n        # when there are no properties to propagate it to\n        res = expr_items(self.dep)\n\n        if self.prompt:\n            res |= expr_items(self.prompt[1])\n\n        if self.item is MENU:\n            res |= expr_items(self.visibility)\n\n        for value, cond in self.defaults:\n            res |= expr_items(value)\n            res |= expr_items(cond)\n\n        for value, cond in self.selects:\n            res.add(value)\n            res |= expr_items(cond)\n\n        for value, cond in self.implies:\n            res.add(value)\n            res |= expr_items(cond)\n\n        for low, high, cond in self.ranges:\n            res.add(low)\n            res.add(high)\n            res |= expr_items(cond)\n\n        return res", "response": "Return a list of all the keys that are referenced by this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef custom_str(self, sc_expr_str_fn):\n        return self._menu_comment_node_str(sc_expr_str_fn) \\\n               if self.item in _MENU_COMMENT else \\\n               self._sym_choice_node_str(sc_expr_str_fn)", "response": "Returns a string representation of the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string representation of a node in the order they appear in the menu.", "response": "def node_str(node):\n    \"\"\"\n    Returns the complete menu entry text for a menu node, or \"\" for invisible\n    menu nodes. Invisible menu nodes are those that lack a prompt or that do\n    not have a satisfied prompt condition.\n\n    Example return value: \"[*] Bool symbol (BOOL)\"\n\n    The symbol name is printed in parentheses to the right of the prompt. This\n    is so that symbols can easily be referred to in the configuration\n    interface.\n    \"\"\"\n    if not node.prompt:\n        return \"\"\n\n    # Even for menu nodes for symbols and choices, it's wrong to check\n    # Symbol.visibility / Choice.visibility here. The reason is that a symbol\n    # (and a choice, in theory) can be defined in multiple locations, giving it\n    # multiple menu nodes, which do not necessarily all have the same prompt\n    # visibility. Symbol.visibility / Choice.visibility is calculated as the OR\n    # of the visibility of all the prompts.\n    prompt, prompt_cond = node.prompt\n    if not expr_value(prompt_cond):\n        return \"\"\n\n    if node.item == MENU:\n        return \"    \" + prompt\n\n    if node.item == COMMENT:\n        return \"    *** {} ***\".format(prompt)\n\n    # Symbol or Choice\n\n    sc = node.item\n\n    if sc.type == UNKNOWN:\n        # Skip symbols defined without a type (these are obscure and generate\n        # a warning)\n        return \"\"\n\n    # {:3} sets the field width to three. Gives nice alignment for empty string\n    # values.\n    res = \"{:3} {}\".format(value_str(sc), prompt)\n\n    # Don't print the name for unnamed choices (the normal kind)\n    if sc.name is not None:\n        res += \" ({})\".format(sc.name)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprompt the user for a value for the symbol or choice sc. For bool or tristate symbols and choices provides a list of all the assignable values. For hex symbols and choices provides a list of all the assignable values.", "response": "def get_value_from_user(sc):\n    \"\"\"\n    Prompts the user for a value for the symbol or choice 'sc'. For\n    bool/tristate symbols and choices, provides a list of all the assignable\n    values.\n    \"\"\"\n    if not sc.visibility:\n        print(sc.name + \" is not currently visible\")\n        return False\n\n    prompt = \"Value for {}\".format(sc.name)\n    if sc.type in (BOOL, TRISTATE):\n        prompt += \" (available: {})\" \\\n                  .format(\", \".join(TRI_TO_STR[val] for val in sc.assignable))\n    prompt += \": \"\n\n    val = input(prompt)\n\n    # Automatically add a \"0x\" prefix for hex symbols, like the menuconfig\n    # interface does. This isn't done when loading .config files, hence why\n    # set_value() doesn't do it automatically.\n    if sc.type == HEX and not val.startswith((\"0x\", \"0X\")):\n        val = \"0x\" + val\n\n    # Let Kconfiglib itself print a warning here if the value is invalid. We\n    # could also disable warnings temporarily with\n    # kconf.disable_warnings() / kconf.enable_warnings() and print our own\n    # warning.\n    return sc.set_value(val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef die(msg, errlvl=1, prefix=\"Error: \"):\n    stderr(\"%s%s\\n\" % (prefix, msg))\n    sys.exit(errlvl)", "response": "Convenience function to write short message to stderr and quit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef type_name(value):\n    return type(value).__name__ if isinstance(value, EncapsulatedNode) else \\\n           \"struct\" if isinstance(value, dict) else \\\n           \"sequence\" if isinstance(value, (tuple, list)) else \\\n           type(value).__name__", "response": "Returns pseudo - YAML type name of given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do(stream, action, key, default=None, dump=yaml_dump,\n       loader=ShyamlSafeLoader):\n    \"\"\"Return string representations of target value in stream YAML\n\n    The key is used for traversal of the YAML structure to target\n    the value that will be dumped.\n\n    :param stream:  file like input yaml content\n    :param action:  string identifying one of the possible supported actions\n    :param key:     string dotted expression to traverse yaml input\n    :param default: optional default value in case of missing end value when\n                    traversing input yaml.  (default is ``None``)\n    :param dump:    callable that will be given python objet to dump in yaml\n                    (default is ``yaml_dump``)\n    :param loader:  PyYAML's *Loader subclass to parse YAML\n                    (default is ShyamlSafeLoader)\n    :return:        generator of string representation of target value per\n                    YAML docs in the given stream.\n\n    :raises ActionTypeError: when there's a type mismatch between the\n        action selected and the type of the targetted value.\n        (ie: action 'key-values' on non-struct)\n    :raises InvalidAction: when selected action is not a recognised valid\n        action identifier.\n    :raises InvalidPath: upon inexistent content when traversing YAML\n        input following the key specification.\n\n    \"\"\"\n    at_least_one_content = False\n    for content in yaml.load_all(stream, Loader=loader):\n        at_least_one_content = True\n        value = traverse(content, key, default=default)\n        yield act(action, value, dump=dump)\n\n    ## In case of empty stream, we consider that it is equivalent\n    ## to one document having the ``null`` value.\n    if at_least_one_content is False:\n        value = traverse(None, key, default=default)\n        yield act(action, value, dump=dump)", "response": "A generator that yields string representations of target value in stream YAML content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode(s):\n    if not isinstance(s, text_type):\n        return s\n\n    r = []\n    _in = []\n\n    def extend_result_if_chars_buffered():\n        if _in:\n            r.extend(['&', modified_utf7(''.join(_in)), '-'])\n            del _in[:]\n\n    for c in s:\n        if ord(c) in PRINTABLE:\n            extend_result_if_chars_buffered()\n            r.append(c)\n        elif c == '&':\n            extend_result_if_chars_buffered()\n            r.append('&-')\n        else:\n            _in.append(c)\n\n    extend_result_if_chars_buffered()\n\n    return ''.join(r)", "response": "Encode a folder name using IMAP modified UTF - 7 encoding."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode(s):\n    if isinstance(s, binary_type):\n        s = s.decode('latin-1')\n    if not isinstance(s, text_type):\n        return s\n\n    r = []\n    _in = []\n    for c in s:\n        if c == '&' and not _in:\n            _in.append('&')\n        elif c == '-' and _in:\n            if len(_in) == 1:\n                r.append('&')\n            else:\n                r.append(modified_deutf7(''.join(_in[1:])))\n            _in = []\n        elif _in:\n            _in.append(c)\n        else:\n            r.append(c)\n    if _in:\n        r.append(modified_deutf7(''.join(_in[1:])))\n\n    return ''.join(r)", "response": "Decode a folder name from IMAP modified UTF - 7 encoding to unicode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform a series of automated data cleaning transformations on the provided data set Parameters ---------- input_dataframe: pandas.DataFrame Data set to clean drop_nans: bool Drop all rows that have a NaN in any column (default: False) copy: bool Make a copy of the data set (default: False) encoder: category_encoders transformer The a valid category_encoders transformer which is passed an inferred cols list. Default (None: LabelEncoder) encoder_kwargs: category_encoders The a valid sklearn transformer to encode categorical features. Default (None) ignore_update_check: bool Do not check for the latest version of datacleaner Returns ---------- output_dataframe: pandas.DataFrame Cleaned data set", "response": "def autoclean(input_dataframe, drop_nans=False, copy=False, encoder=None,\n              encoder_kwargs=None, ignore_update_check=False):\n    \"\"\"Performs a series of automated data cleaning transformations on the provided data set\n\n    Parameters\n    ----------\n    input_dataframe: pandas.DataFrame\n        Data set to clean\n    drop_nans: bool\n        Drop all rows that have a NaN in any column (default: False)\n    copy: bool\n        Make a copy of the data set (default: False)\n    encoder: category_encoders transformer\n        The a valid category_encoders transformer which is passed an inferred cols list. Default (None: LabelEncoder)\n    encoder_kwargs: category_encoders\n        The a valid sklearn transformer to encode categorical features. Default (None)\n    ignore_update_check: bool\n        Do not check for the latest version of datacleaner\n\n    Returns\n    ----------\n    output_dataframe: pandas.DataFrame\n        Cleaned data set\n\n    \"\"\"\n    global update_checked\n    if ignore_update_check:\n        update_checked = True\n\n    if not update_checked:\n        update_check('datacleaner', __version__)\n        update_checked = True\n\n    if copy:\n        input_dataframe = input_dataframe.copy()\n\n    if drop_nans:\n        input_dataframe.dropna(inplace=True)\n\n    if encoder_kwargs is None:\n        encoder_kwargs = {}\n\n    for column in input_dataframe.columns.values:\n        # Replace NaNs with the median or mode of the column depending on the column type\n        try:\n            input_dataframe[column].fillna(input_dataframe[column].median(), inplace=True)\n        except TypeError:\n            most_frequent = input_dataframe[column].mode()\n            # If the mode can't be computed, use the nearest valid value\n            # See https://github.com/rhiever/datacleaner/issues/8\n            if len(most_frequent) > 0:\n                input_dataframe[column].fillna(input_dataframe[column].mode()[0], inplace=True)\n            else:\n                input_dataframe[column].fillna(method='bfill', inplace=True)\n                input_dataframe[column].fillna(method='ffill', inplace=True)\n\n\n        # Encode all strings with numerical equivalents\n        if str(input_dataframe[column].values.dtype) == 'object':\n            if encoder is not None:\n                column_encoder = encoder(**encoder_kwargs).fit(input_dataframe[column].values)\n            else:\n                column_encoder = LabelEncoder().fit(input_dataframe[column].values)\n\n            input_dataframe[column] = column_encoder.transform(input_dataframe[column].values)\n\n    return input_dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autoclean_cv(training_dataframe, testing_dataframe, drop_nans=False, copy=False,\n                 encoder=None, encoder_kwargs=None, ignore_update_check=False):\n    \"\"\"Performs a series of automated data cleaning transformations on the provided training and testing data sets\n\n    Unlike `autoclean()`, this function takes cross-validation into account by learning the data transformations\n    from only the training set, then applying those transformations to both the training and testing set.\n    By doing so, this function will prevent information leak from the training set into the testing set.\n\n    Parameters\n    ----------\n    training_dataframe: pandas.DataFrame\n        Training data set\n    testing_dataframe: pandas.DataFrame\n        Testing data set\n    drop_nans: bool\n        Drop all rows that have a NaN in any column (default: False)\n    copy: bool\n        Make a copy of the data set (default: False)\n    encoder: category_encoders transformer\n        The a valid category_encoders transformer which is passed an inferred cols list. Default (None: LabelEncoder)\n    encoder_kwargs: category_encoders\n        The a valid sklearn transformer to encode categorical features. Default (None)\n    ignore_update_check: bool\n        Do not check for the latest version of datacleaner\n\n    Returns\n    ----------\n    output_training_dataframe: pandas.DataFrame\n        Cleaned training data set\n    output_testing_dataframe: pandas.DataFrame\n        Cleaned testing data set\n\n    \"\"\"\n    global update_checked\n    if ignore_update_check:\n        update_checked = True\n\n    if not update_checked:\n        update_check('datacleaner', __version__)\n        update_checked = True\n\n    if set(training_dataframe.columns.values) != set(testing_dataframe.columns.values):\n        raise ValueError('The training and testing DataFrames do not have the same columns. '\n                         'Make sure that you are providing the same columns.')\n\n    if copy:\n        training_dataframe = training_dataframe.copy()\n        testing_dataframe = testing_dataframe.copy()\n    \n    if drop_nans:\n        training_dataframe.dropna(inplace=True)\n        testing_dataframe.dropna(inplace=True)\n\n    if encoder_kwargs is None:\n        encoder_kwargs = {}\n\n    for column in training_dataframe.columns.values:\n        # Replace NaNs with the median or mode of the column depending on the column type\n        try:\n            column_median = training_dataframe[column].median()\n            training_dataframe[column].fillna(column_median, inplace=True)\n            testing_dataframe[column].fillna(column_median, inplace=True)\n        except TypeError:\n            column_mode = training_dataframe[column].mode()[0]\n            training_dataframe[column].fillna(column_mode, inplace=True)\n            testing_dataframe[column].fillna(column_mode, inplace=True)\n\n        # Encode all strings with numerical equivalents\n        if str(training_dataframe[column].values.dtype) == 'object':\n            if encoder is not None:\n                column_encoder = encoder(**encoder_kwargs).fit(training_dataframe[column].values)\n            else:\n                column_encoder = LabelEncoder().fit(training_dataframe[column].values)\n\n            training_dataframe[column] = column_encoder.transform(training_dataframe[column].values)\n            testing_dataframe[column] = column_encoder.transform(testing_dataframe[column].values)\n\n    return training_dataframe, testing_dataframe", "response": "This function performs a series of automated data cleaning transformations on the provided training and testing data sets."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_foreign_keys(cls):\n        foreign_keys = {}\n        for field in cls._meta.fields:\n            if (\n                field.get_internal_type() == 'ForeignKey' and\n                field.name != 'parent'\n            ):\n                if django.VERSION >= (1, 9):\n                    foreign_keys[field.name] = field.remote_field.model\n                else:\n                    foreign_keys[field.name] = field.rel.to\n        return foreign_keys", "response": "Get foreign keys and models they refer to so we can pre - process the data for load_bulk\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the foreign keys that are not already loaded", "response": "def _process_foreign_keys(cls, foreign_keys, node_data):\n        \"\"\"For each foreign key try to load the actual object so load_bulk\n        doesn't fail trying to load an int where django expects a\n        model instance\n        \"\"\"\n        for key in foreign_keys.keys():\n            if key in node_data:\n                node_data[key] = foreign_keys[key].objects.get(\n                    pk=node_data[key])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the previous node s sibling or None if no previous node s sibling was found.", "response": "def get_prev_sibling(self):\n        \"\"\"\n        :returns:\n\n            The previous node's sibling, or None if it was the leftmost\n            sibling.\n        \"\"\"\n        siblings = self.get_siblings()\n        ids = [obj.pk for obj in siblings]\n        if self.pk in ids:\n            idx = ids.index(self.pk)\n            if idx > 0:\n                return siblings[idx - 1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the next node s sibling or None if there is no next node s sibling.", "response": "def get_next_sibling(self):\n        \"\"\"\n        :returns:\n\n            The next node's sibling, or None if it was the rightmost\n            sibling.\n        \"\"\"\n        siblings = self.get_siblings()\n        ids = [obj.pk for obj in siblings]\n        if self.pk in ids:\n            idx = ids.index(self.pk)\n            if idx < len(siblings) - 1:\n                return siblings[idx + 1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the node is a sibling of another node given as an argument.", "response": "def is_sibling_of(self, node):\n        \"\"\"\n        :returns: ``True`` if the node is a sibling of another node given as an\n            argument, else, returns ``False``\n\n        :param node:\n\n            The node that will be checked as a sibling\n        \"\"\"\n        return self.get_siblings().filter(pk=node.pk).exists()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the node is a child of another node given as an argument.", "response": "def is_child_of(self, node):\n        \"\"\"\n        :returns: ``True`` if the node is a child of another node given as an\n            argument, else, returns ``False``\n\n        :param node:\n\n            The node that will be checked as a parent\n        \"\"\"\n        return node.get_children().filter(pk=self.pk).exists()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a node and all its descendants.", "response": "def delete(self):\n        \"\"\"Removes a node and all it's descendants.\"\"\"\n        self.__class__.objects.filter(pk=self.pk).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a queryset of the nodes that must be moved to the right.", "response": "def get_sorted_pos_queryset(self, siblings, newobj):\n        \"\"\"\n        :returns: A queryset of the nodes that must be moved\n        to the right. Called only for Node models with :attr:`node_order_by`\n\n        This function is based on _insertion_target_filters from django-mptt\n        (BSD licensed) by Jonathan Buchanan:\n        https://github.com/django-mptt/django-mptt/blob/0.3.0/mptt/signals.py\n        \"\"\"\n\n        fields, filters = [], []\n        for field in self.node_order_by:\n            value = getattr(newobj, field)\n            filters.append(\n                Q(\n                    *[Q(**{f: v}) for f, v in fields] +\n                     [Q(**{'%s__gt' % field: value})]\n                )\n            )\n            fields.append((field, value))\n        return siblings.filter(reduce(operator.or_, filters))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_annotated_list_qs(cls, qs):\n        result, info = [], {}\n        start_depth, prev_depth = (None, None)\n        for node in qs:\n            depth = node.get_depth()\n            if start_depth is None:\n                start_depth = depth\n            open = (depth and (prev_depth is None or depth > prev_depth))\n            if prev_depth is not None and depth < prev_depth:\n                info['close'] = list(range(0, prev_depth - depth))\n            info = {'open': open, 'close': [], 'level': depth - start_depth}\n            result.append((node, info,))\n            prev_depth = depth\n        if start_depth and start_depth > 0:\n            info['close'] = list(range(0, prev_depth - start_depth + 1))\n        return result", "response": "Gets an annotated list from a queryset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_annotated_list(cls, parent=None, max_depth=None):\n\n        result, info = [], {}\n        start_depth, prev_depth = (None, None)\n        qs = cls.get_tree(parent)\n        if max_depth:\n            qs = qs.filter(depth__lte=max_depth)\n        return cls.get_annotated_list_qs(qs)", "response": "Returns a list of all the annotated nodes in a tree branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a model with a valid _meta. local_fields ( serializable ).", "response": "def _get_serializable_model(cls):\n        \"\"\"\n        Returns a model with a valid _meta.local_fields (serializable).\n\n        Basically, this means the original model, not a proxied model.\n\n        (this is a workaround for a bug in django)\n        \"\"\"\n        current_class = cls\n        while current_class._meta.proxy:\n            current_class = current_class._meta.proxy_for_model\n        return current_class"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the list of items for the given result.", "response": "def items_for_result(cl, result, form):\n    \"\"\"\n    Generates the actual list of data.\n\n    @jjdelc:\n    This has been shamelessly copied from original\n    django.contrib.admin.templatetags.admin_list.items_for_result\n    in order to alter the dispay for the first element\n    \"\"\"\n    first = True\n    pk = cl.lookup_opts.pk.attname\n    for field_name in cl.list_display:\n        result_repr, row_class = get_result_and_row_class(cl, field_name,\n                                                          result)\n        # If list_display_links not defined, add the link tag to the\n        # first field\n        if (first and not cl.list_display_links) or \\\n           field_name in cl.list_display_links:\n            table_tag = {True: 'th', False: 'td'}[first]\n            # This spacer indents the nodes based on their depth\n            spacer = get_spacer(first, result)\n            # This shows a collapse or expand link for nodes with childs\n            collapse = get_collapse(result)\n            # Add a <td/> before the first col to show the drag handler\n            drag_handler = get_drag_handler(first)\n            first = False\n            url = cl.url_for_result(result)\n            # Convert the pk to something that can be used in Javascript.\n            # Problem cases are long ints (23L) and non-ASCII strings.\n            if cl.to_field:\n                attr = str(cl.to_field)\n            else:\n                attr = pk\n            value = result.serializable_value(attr)\n            result_id = \"'%s'\" % force_str(value)\n            onclickstr = (\n                ' onclick=\"opener.dismissRelatedLookupPopup(window, %s);'\n                ' return false;\"')\n            yield mark_safe(\n                u('%s<%s%s>%s %s <a href=\"%s\"%s>%s</a></%s>') % (\n                    drag_handler, table_tag, row_class, spacer, collapse, url,\n                    (cl.is_popup and onclickstr % result_id or ''),\n                    conditional_escape(result_repr), table_tag))\n        else:\n            # By default the fields come from ModelAdmin.list_editable, but if\n            # we pull the fields out of the form instead of list_editable\n            # custom admins can provide fields on a per request basis\n            if (\n                    form and\n                    field_name in form.fields and\n                    not (\n                        field_name == cl.model._meta.pk.name and\n                        form[cl.model._meta.pk.name].is_hidden\n                    )\n            ):\n                bf = form[field_name]\n                result_repr = mark_safe(force_str(bf.errors) + force_str(bf))\n            yield format_html(u('<td{0}>{1}</td>'), row_class, result_repr)\n    if form and not form[cl.model._meta.pk.name].is_hidden:\n        yield format_html(u('<td>{0}</td>'),\n                          force_str(form[cl.model._meta.pk.name]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_empty_dict(GET_dict):\n    empty = True\n    for k, v in GET_dict.items():\n        # Don't disable on p(age) or 'all' GET param\n        if v and k != 'p' and k != 'all':\n            empty = False\n    return empty", "response": "Returns True if the GET querstring contains on values but it can contain empty keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef result_tree(context, cl, request):\n\n    # Here I'm adding an extra col on pos 2 for the drag handlers\n    headers = list(result_headers(cl))\n    headers.insert(1 if needs_checkboxes(context) else 0, {\n        'text': '+',\n        'sortable': True,\n        'url': request.path,\n        'tooltip': _('Return to ordered tree'),\n        'class_attrib': mark_safe(' class=\"oder-grabber\"')\n    })\n    return {\n        'filtered': not check_empty_dict(request.GET),\n        'result_hidden_fields': list(result_hidden_fields(cl)),\n        'result_headers': headers,\n        'results': list(results(cl)),\n    }", "response": "Returns a tree with the result_hidden_fields filtered by GET params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_static_url():\n    path = getattr(settings, 'STATIC_URL', None)\n    if not path:\n        path = getattr(settings, 'MEDIA_URL', None)\n    if not path:\n        path = '/'\n    return path", "response": "Return a base static url always ending with a slash"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef treebeard_js():\n    path = get_static_url()\n    js_file = urljoin(path, 'treebeard/treebeard-admin.js')\n    jquery_ui = urljoin(path, 'treebeard/jquery-ui-1.8.5.custom.min.js')\n\n    # Jquery UI is needed to call disableSelection() on drag and drop so\n    # text selections arent marked while dragging a table row\n    # http://www.lokkju.com/blog/archives/143\n    TEMPLATE = (\n        '<script type=\"text/javascript\" src=\"{}\"></script>'\n        '<script type=\"text/javascript\" src=\"{}\"></script>'\n        '<script>'\n            '(function($){{jQuery = $.noConflict(true);}})(django.jQuery);'\n        '</script>'\n        '<script type=\"text/javascript\" src=\"{}\"></script>')\n    return format_html(\n        TEMPLATE, \"jsi18n\", mark_safe(js_file), mark_safe(jquery_ui))", "response": "Return the proper js tag to include a custom. js file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a url to move nodes to this admin", "response": "def get_urls(self):\n        \"\"\"\n        Adds a url to move nodes to this admin\n        \"\"\"\n        urls = super(TreeAdmin, self).get_urls()\n\n        if django.VERSION < (1, 10):\n            from django.views.i18n import javascript_catalog\n            jsi18n_url = url(r'^jsi18n/$', javascript_catalog, {'packages': ('treebeard',)})\n        else:\n            from django.views.i18n import JavaScriptCatalog\n\n            jsi18n_url = url(r'^jsi18n/$',\n                JavaScriptCatalog.as_view(packages=['treebeard']),\n                name='javascript-catalog'\n            )\n\n        new_urls = [\n            url('^move/$', self.admin_site.admin_view(self.move_node), ),\n            jsi18n_url,\n        ]\n        return new_urls + urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clean_cleaned_data(self):\n        reference_node_id = 0\n\n        if '_ref_node_id' in self.cleaned_data:\n            reference_node_id = self.cleaned_data['_ref_node_id']\n            del self.cleaned_data['_ref_node_id']\n\n        position_type = self.cleaned_data['_position']\n        del self.cleaned_data['_position']\n\n        return position_type, reference_node_id", "response": "delete auxilary fields not belonging to node model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_subtree(cls, for_node, node, options):\n        if cls.is_loop_safe(for_node, node):\n            options.append(\n                (node.pk,\n                 mark_safe(cls.mk_indent(node.get_depth()) + escape(node))))\n            for subnode in node.get_children():\n                cls.add_subtree(for_node, subnode, options)", "response": "Recursively build options tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a tree - like list of choices", "response": "def mk_dropdown_tree(cls, model, for_node=None):\n        \"\"\" Creates a tree-like list of choices \"\"\"\n\n        options = [(0, _('-- root --'))]\n        for node in model.get_root_nodes():\n            cls.add_subtree(for_node, node, options)\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, removed_ranges=None):\n        model = get_result_class(self.model)\n        if removed_ranges is not None:\n            # we already know the children, let's call the default django\n            # delete method and let it handle the removal of the user's\n            # foreign keys...\n            super(NS_NodeQuerySet, self).delete()\n            cursor = model._get_database_cursor('write')\n\n            # Now closing the gap (Celko's trees book, page 62)\n            # We do this for every gap that was left in the tree when the nodes\n            # were removed.  If many nodes were removed, we're going to update\n            # the same nodes over and over again. This would be probably\n            # cheaper precalculating the gapsize per intervals, or just do a\n            # complete reordering of the tree (uses COUNT)...\n            for tree_id, drop_lft, drop_rgt in sorted(removed_ranges,\n                                                      reverse=True):\n                sql, params = model._get_close_gap_sql(drop_lft, drop_rgt,\n                                                            tree_id)\n                cursor.execute(sql, params)\n        else:\n            # we'll have to manually run through all the nodes that are going\n            # to be deleted and remove nodes from the list if an ancestor is\n            # already getting removed, since that would be redundant\n            removed = {}\n            for node in self.order_by('tree_id', 'lft'):\n                found = False\n                for rid, rnode in removed.items():\n                    if node.is_descendant_of(rnode):\n                        found = True\n                        break\n                if not found:\n                    removed[node.pk] = node\n\n            # ok, got the minimal list of nodes to remove...\n            # we must also remove their descendants\n            toremove = []\n            ranges = []\n            for id, node in removed.items():\n                toremove.append(Q(lft__range=(node.lft, node.rgt)) &\n                                Q(tree_id=node.tree_id))\n                ranges.append((node.tree_id, node.lft, node.rgt))\n            if toremove:\n                model.objects.filter(\n                    reduce(operator.or_,\n                           toremove)\n                ).delete(removed_ranges=ranges)", "response": "Custom delete method for the user s a\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_root(cls, **kwargs):\n\n        # do we have a root node already?\n        last_root = cls.get_last_root_node()\n\n        if last_root and last_root.node_order_by:\n            # there are root nodes and node_order_by has been set\n            # delegate sorted insertion to add_sibling\n            return last_root.add_sibling('sorted-sibling', **kwargs)\n\n        if last_root:\n            # adding the new root node as the last one\n            newtree_id = last_root.tree_id + 1\n        else:\n            # adding the first root node\n            newtree_id = 1\n\n        if len(kwargs) == 1 and 'instance' in kwargs:\n            # adding the passed (unsaved) instance to the tree\n            newobj = kwargs['instance']\n            if newobj.pk:\n                raise NodeAlreadySaved(\"Attempted to add a tree node that is \"\\\n                    \"already in the database\")\n        else:\n            # creating the new object\n            newobj = get_result_class(cls)(**kwargs)\n\n        newobj.depth = 1\n        newobj.tree_id = newtree_id\n        newobj.lft = 1\n        newobj.rgt = 2\n        # saving the instance before returning it\n        newobj.save()\n        return newobj", "response": "Adds a root node to the tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_child(self, **kwargs):\n        if not self.is_leaf():\n            # there are child nodes, delegate insertion to add_sibling\n            if self.node_order_by:\n                pos = 'sorted-sibling'\n            else:\n                pos = 'last-sibling'\n            last_child = self.get_last_child()\n            last_child._cached_parent_obj = self\n            return last_child.add_sibling(pos, **kwargs)\n\n        # we're adding the first child of this node\n        sql, params = self.__class__._move_right(self.tree_id,\n                                                 self.rgt, False, 2)\n\n        if len(kwargs) == 1 and 'instance' in kwargs:\n            # adding the passed (unsaved) instance to the tree\n            newobj = kwargs['instance']\n            if newobj.pk:\n                raise NodeAlreadySaved(\"Attempted to add a tree node that is \"\\\n                    \"already in the database\")\n        else:\n            # creating a new object\n            newobj = get_result_class(self.__class__)(**kwargs)\n\n        newobj.tree_id = self.tree_id\n        newobj.depth = self.depth + 1\n        newobj.lft = self.lft + 1\n        newobj.rgt = self.lft + 2\n\n        # this is just to update the cache\n        self.rgt += 2\n\n        newobj._cached_parent_obj = self\n\n        cursor = self._get_database_cursor('write')\n        cursor.execute(sql, params)\n\n        # saving the instance before returning it\n        newobj.save()\n\n        return newobj", "response": "Adds a child to the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new node as a sibling to the current node object.", "response": "def add_sibling(self, pos=None, **kwargs):\n        \"\"\"Adds a new node as a sibling to the current node object.\"\"\"\n\n        pos = self._prepare_pos_var_for_add_sibling(pos)\n\n        if len(kwargs) == 1 and 'instance' in kwargs:\n            # adding the passed (unsaved) instance to the tree\n            newobj = kwargs['instance']\n            if newobj.pk:\n                raise NodeAlreadySaved(\"Attempted to add a tree node that is \"\\\n                    \"already in the database\")\n        else:\n            # creating a new object\n            newobj = get_result_class(self.__class__)(**kwargs)\n\n        newobj.depth = self.depth\n\n        sql = None\n        target = self\n\n        if target.is_root():\n            newobj.lft = 1\n            newobj.rgt = 2\n            if pos == 'sorted-sibling':\n                siblings = list(target.get_sorted_pos_queryset(\n                    target.get_siblings(), newobj))\n                if siblings:\n                    pos = 'left'\n                    target = siblings[0]\n                else:\n                    pos = 'last-sibling'\n\n            last_root = target.__class__.get_last_root_node()\n            if (\n                    (pos == 'last-sibling') or\n                    (pos == 'right' and target == last_root)\n            ):\n                newobj.tree_id = last_root.tree_id + 1\n            else:\n                newpos = {'first-sibling': 1,\n                          'left': target.tree_id,\n                          'right': target.tree_id + 1}[pos]\n                sql, params = target.__class__._move_tree_right(newpos)\n\n                newobj.tree_id = newpos\n        else:\n            newobj.tree_id = target.tree_id\n\n            if pos == 'sorted-sibling':\n                siblings = list(target.get_sorted_pos_queryset(\n                    target.get_siblings(), newobj))\n                if siblings:\n                    pos = 'left'\n                    target = siblings[0]\n                else:\n                    pos = 'last-sibling'\n\n            if pos in ('left', 'right', 'first-sibling'):\n                siblings = list(target.get_siblings())\n\n                if pos == 'right':\n                    if target == siblings[-1]:\n                        pos = 'last-sibling'\n                    else:\n                        pos = 'left'\n                        found = False\n                        for node in siblings:\n                            if found:\n                                target = node\n                                break\n                            elif node == target:\n                                found = True\n                if pos == 'left':\n                    if target == siblings[0]:\n                        pos = 'first-sibling'\n                if pos == 'first-sibling':\n                    target = siblings[0]\n\n            move_right = self.__class__._move_right\n\n            if pos == 'last-sibling':\n                newpos = target.get_parent().rgt\n                sql, params = move_right(target.tree_id, newpos, False, 2)\n            elif pos == 'first-sibling':\n                newpos = target.lft\n                sql, params = move_right(target.tree_id, newpos - 1, False, 2)\n            elif pos == 'left':\n                newpos = target.lft\n                sql, params = move_right(target.tree_id, newpos, True, 2)\n\n            newobj.lft = newpos\n            newobj.rgt = newpos + 1\n\n        # saving the instance before returning it\n        if sql:\n            cursor = self._get_database_cursor('write')\n            cursor.execute(sql, params)\n        newobj.save()\n\n\n        return newobj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move(self, target, pos=None):\n\n        pos = self._prepare_pos_var_for_move(pos)\n        cls = get_result_class(self.__class__)\n\n        parent = None\n\n        if pos in ('first-child', 'last-child', 'sorted-child'):\n            # moving to a child\n            if target.is_leaf():\n                parent = target\n                pos = 'last-child'\n            else:\n                target = target.get_last_child()\n                pos = {'first-child': 'first-sibling',\n                       'last-child': 'last-sibling',\n                       'sorted-child': 'sorted-sibling'}[pos]\n\n        if target.is_descendant_of(self):\n            raise InvalidMoveToDescendant(\n                _(\"Can't move node to a descendant.\"))\n\n        if self == target and (\n            (pos == 'left') or\n            (pos in ('right', 'last-sibling') and\n             target == target.get_last_sibling()) or\n            (pos == 'first-sibling' and\n             target == target.get_first_sibling())):\n            # special cases, not actually moving the node so no need to UPDATE\n            return\n\n        if pos == 'sorted-sibling':\n            siblings = list(target.get_sorted_pos_queryset(\n                target.get_siblings(), self))\n            if siblings:\n                pos = 'left'\n                target = siblings[0]\n            else:\n                pos = 'last-sibling'\n        if pos in ('left', 'right', 'first-sibling'):\n            siblings = list(target.get_siblings())\n\n            if pos == 'right':\n                if target == siblings[-1]:\n                    pos = 'last-sibling'\n                else:\n                    pos = 'left'\n                    found = False\n                    for node in siblings:\n                        if found:\n                            target = node\n                            break\n                        elif node == target:\n                            found = True\n            if pos == 'left':\n                if target == siblings[0]:\n                    pos = 'first-sibling'\n            if pos == 'first-sibling':\n                target = siblings[0]\n\n        # ok let's move this\n        cursor = self._get_database_cursor('write')\n        move_right = cls._move_right\n        gap = self.rgt - self.lft + 1\n        sql = None\n        target_tree = target.tree_id\n\n        # first make a hole\n        if pos == 'last-child':\n            newpos = parent.rgt\n            sql, params = move_right(target.tree_id, newpos, False, gap)\n        elif target.is_root():\n            newpos = 1\n            if pos == 'last-sibling':\n                target_tree = target.get_siblings().reverse()[0].tree_id + 1\n            elif pos == 'first-sibling':\n                target_tree = 1\n                sql, params = cls._move_tree_right(1)\n            elif pos == 'left':\n                sql, params = cls._move_tree_right(target.tree_id)\n        else:\n            if pos == 'last-sibling':\n                newpos = target.get_parent().rgt\n                sql, params = move_right(target.tree_id, newpos, False, gap)\n            elif pos == 'first-sibling':\n                newpos = target.lft\n                sql, params = move_right(target.tree_id,\n                                         newpos - 1, False, gap)\n            elif pos == 'left':\n                newpos = target.lft\n                sql, params = move_right(target.tree_id, newpos, True, gap)\n\n        if sql:\n            cursor.execute(sql, params)\n\n        # we reload 'self' because lft/rgt may have changed\n\n        fromobj = cls.objects.get(pk=self.pk)\n\n        depthdiff = target.depth - fromobj.depth\n        if parent:\n            depthdiff += 1\n\n        # move the tree to the hole\n        sql = \"UPDATE %(table)s \"\\\n              \" SET tree_id = %(target_tree)d, \"\\\n              \"     lft = lft + %(jump)d , \"\\\n              \"     rgt = rgt + %(jump)d , \"\\\n              \"     depth = depth + %(depthdiff)d \"\\\n              \" WHERE tree_id = %(from_tree)d AND \"\\\n              \"     lft BETWEEN %(fromlft)d AND %(fromrgt)d\" % {\n                  'table': connection.ops.quote_name(cls._meta.db_table),\n                  'from_tree': fromobj.tree_id,\n                  'target_tree': target_tree,\n                  'jump': newpos - fromobj.lft,\n                  'depthdiff': depthdiff,\n                  'fromlft': fromobj.lft,\n                  'fromrgt': fromobj.rgt}\n        cursor.execute(sql, [])\n\n        # close the gap\n        sql, params = cls._get_close_gap_sql(fromobj.lft,\n                                             fromobj.rgt, fromobj.tree_id)\n        cursor.execute(sql, params)", "response": "Moves the current node and all its descendants to a new position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_bulk(cls, bulk_data, parent=None, keep_ids=False):\n\n        cls = get_result_class(cls)\n\n        # tree, iterative preorder\n        added = []\n        if parent:\n            parent_id = parent.pk\n        else:\n            parent_id = None\n        # stack of nodes to analize\n        stack = [(parent_id, node) for node in bulk_data[::-1]]\n        foreign_keys = cls.get_foreign_keys()\n        while stack:\n            parent_id, node_struct = stack.pop()\n            # shallow copy of the data strucure so it doesn't persist...\n            node_data = node_struct['data'].copy()\n            cls._process_foreign_keys(foreign_keys, node_data)\n            if keep_ids:\n                node_data['id'] = node_struct['id']\n            if parent_id:\n                parent = cls.objects.get(pk=parent_id)\n                node_obj = parent.add_child(**node_data)\n            else:\n                node_obj = cls.add_root(**node_data)\n            added.append(node_obj.pk)\n            if 'children' in node_struct:\n                # extending the stack with the current node as the parent of\n                # the new nodes\n                stack.extend([\n                    (node_obj.pk, node)\n                    for node in node_struct['children'][::-1]\n                ])\n        return added", "response": "Loads a list / dictionary structure to the tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_root(self):\n        if self.lft == 1:\n            return self\n        return get_result_class(self.__class__).objects.get(\n            tree_id=self.tree_id, lft=1)", "response": "returns the root node for the current node object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_siblings(self):\n        if self.lft == 1:\n            return self.get_root_nodes()\n        return self.get_parent(True).get_children()", "response": "Returns a queryset of all the node s siblings including the node itself."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump a tree branch to a python data structure.", "response": "def dump_bulk(cls, parent=None, keep_ids=True):\n        \"\"\"Dumps a tree branch to a python data structure.\"\"\"\n        qset = cls._get_serializable_model().get_tree(parent)\n        ret, lnk = [], {}\n        for pyobj in qset:\n            serobj = serializers.serialize('python', [pyobj])[0]\n            # django's serializer stores the attributes in 'fields'\n            fields = serobj['fields']\n            depth = fields['depth']\n            # this will be useless in load_bulk\n            del fields['lft']\n            del fields['rgt']\n            del fields['depth']\n            del fields['tree_id']\n            if 'id' in fields:\n                # this happens immediately after a load_bulk\n                del fields['id']\n\n            newobj = {'data': fields}\n            if keep_ids:\n                newobj['id'] = serobj['pk']\n\n            if (not parent and depth == 1) or\\\n               (parent and depth == parent.depth):\n                ret.append(newobj)\n            else:\n                parentobj = pyobj.get_parent()\n                parentser = lnk[parentobj.pk]\n                if 'children' not in parentser:\n                    parentser['children'] = []\n                parentser['children'].append(newobj)\n            lnk[pyobj.pk] = newobj\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a queryset of all tree entries for the given class and parent.", "response": "def get_tree(cls, parent=None):\n        \"\"\"\n        :returns:\n\n            A *queryset* of nodes ordered as DFS, including the parent.\n            If no parent is given, all trees are returned.\n        \"\"\"\n        cls = get_result_class(cls)\n\n        if parent is None:\n            # return the entire tree\n            return cls.objects.all()\n        if parent.is_leaf():\n            return cls.objects.filter(pk=parent.pk)\n        return cls.objects.filter(\n            tree_id=parent.tree_id,\n            lft__range=(parent.lft, parent.rgt - 1))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a queryset of all the node s descendants as DFS", "response": "def get_descendants(self):\n        \"\"\"\n        :returns: A queryset of all the node's descendants as DFS, doesn't\n            include the node itself\n        \"\"\"\n        if self.is_leaf():\n            return get_result_class(self.__class__).objects.none()\n        return self.__class__.get_tree(self).exclude(pk=self.pk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a queryset containing the current node s ancestors starting by the root node and descending to the parent node.", "response": "def get_ancestors(self):\n        \"\"\"\n        :returns: A queryset containing the current node object's ancestors,\n            starting by the root node and descending to the parent.\n        \"\"\"\n        if self.is_root():\n            return get_result_class(self.__class__).objects.none()\n        return get_result_class(self.__class__).objects.filter(\n            tree_id=self.tree_id,\n            lft__lt=self.lft,\n            rgt__gt=self.rgt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the node is a descendant of another node.", "response": "def is_descendant_of(self, node):\n        \"\"\"\n        :returns: ``True`` if the node if a descendant of another node given\n            as an argument, else, returns ``False``\n        \"\"\"\n        return (\n            self.tree_id == node.tree_id and\n            self.lft > node.lft and\n            self.rgt < node.rgt\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_parent(self, update=False):\n        if self.is_root():\n            return\n        try:\n            if update:\n                del self._cached_parent_obj\n            else:\n                return self._cached_parent_obj\n        except AttributeError:\n            pass\n        # parent = our most direct ancestor\n        self._cached_parent_obj = self.get_ancestors().reverse()[0]\n        return self._cached_parent_obj", "response": "Gets the parent node of the current node object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the class that should be used for the given model class.", "response": "def get_result_class(cls):\n    \"\"\"\n    For the given model class, determine what class we should use for the\n    nodes returned by its tree methods (such as get_children).\n\n    Usually this will be trivially the same as the initial model class,\n    but there are special cases when model inheritance is in use:\n\n    * If the model extends another via multi-table inheritance, we need to\n      use whichever ancestor originally implemented the tree behaviour (i.e.\n      the one which defines the 'path' field). We can't use the\n      subclass, because it's not guaranteed that the other nodes reachable\n      from the current one will be instances of the same subclass.\n\n    * If the model is a proxy model, the returned nodes should also use\n      the proxy class.\n    \"\"\"\n    base_class = cls._meta.get_field('path').model\n    if cls._meta.proxy_for_model == base_class:\n        return cls\n    else:\n        return base_class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self):\n        # we'll have to manually run through all the nodes that are going\n        # to be deleted and remove nodes from the list if an ancestor is\n        # already getting removed, since that would be redundant\n        removed = {}\n        for node in self.order_by('depth', 'path'):\n            found = False\n            for depth in range(1, int(len(node.path) / node.steplen)):\n                path = node._get_basepath(node.path, depth)\n                if path in removed:\n                    # we are already removing a parent of this node\n                    # skip\n                    found = True\n                    break\n            if not found:\n                removed[node.path] = node\n\n        # ok, got the minimal list of nodes to remove...\n        # we must also remove their children\n        # and update every parent node's numchild attribute\n        # LOTS OF FUN HERE!\n        parents = {}\n        toremove = []\n        for path, node in removed.items():\n            parentpath = node._get_basepath(node.path, node.depth - 1)\n            if parentpath:\n                if parentpath not in parents:\n                    parents[parentpath] = node.get_parent(True)\n                parent = parents[parentpath]\n                if parent and parent.numchild > 0:\n                    parent.numchild -= 1\n                    parent.save()\n            if node.is_leaf():\n                toremove.append(Q(path=node.path))\n            else:\n                toremove.append(Q(path__startswith=node.path))\n\n        # Django will handle this as a SELECT and then a DELETE of\n        # ids, and will deal with removing related objects\n        if toremove:\n            qset = get_result_class(self.model).objects.filter(reduce(operator.or_, toremove))\n            super(MP_NodeQuerySet, qset).delete()", "response": "Custom delete method for handling delete - related objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the sql needed the numchild value of a node", "response": "def get_sql_update_numchild(self, path, incdec='inc'):\n        \"\"\":returns: The sql needed the numchild value of a node\"\"\"\n        sql = \"UPDATE %s SET numchild=numchild%s1\"\\\n              \" WHERE path=%%s\" % (\n                  connection.ops.quote_name(\n                      get_result_class(self.node_cls)._meta.db_table),\n                  {'inc': '+', 'dec': '-'}[incdec])\n        vals = [path]\n        return sql, vals"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reorder_nodes_before_add_or_move(self, pos, newpos, newdepth, target,\n                                         siblings, oldpath=None,\n                                         movebranch=False):\n        \"\"\"\n        Handles the reordering of nodes and branches when adding/moving\n        nodes.\n\n        :returns: A tuple containing the old path and the new path.\n        \"\"\"\n        if (\n                (pos == 'last-sibling') or\n                (pos == 'right' and target == target.get_last_sibling())\n        ):\n            # easy, the last node\n            last = target.get_last_sibling()\n            newpath = last._inc_path()\n            if movebranch:\n                self.stmts.append(\n                    self.get_sql_newpath_in_branches(oldpath, newpath))\n        else:\n            # do the UPDATE dance\n\n            if newpos is None:\n                siblings = target.get_siblings()\n                siblings = {'left': siblings.filter(path__gte=target.path),\n                            'right': siblings.filter(path__gt=target.path),\n                            'first-sibling': siblings}[pos]\n                basenum = target._get_lastpos_in_path()\n                newpos = {'first-sibling': 1,\n                          'left': basenum,\n                          'right': basenum + 1}[pos]\n\n            newpath = self.node_cls._get_path(target.path, newdepth, newpos)\n\n            # If the move is amongst siblings and is to the left and there\n            # are siblings to the right of its new position then to be on\n            # the safe side we temporarily dump it on the end of the list\n            tempnewpath = None\n            if movebranch and len(oldpath) == len(newpath):\n                parentoldpath = self.node_cls._get_basepath(\n                    oldpath,\n                    int(len(oldpath) / self.node_cls.steplen) - 1\n                )\n                parentnewpath = self.node_cls._get_basepath(\n                    newpath, newdepth - 1)\n                if (\n                    parentoldpath == parentnewpath and\n                    siblings and\n                    newpath < oldpath\n                ):\n                    last = target.get_last_sibling()\n                    basenum = last._get_lastpos_in_path()\n                    tempnewpath = self.node_cls._get_path(\n                        newpath, newdepth, basenum + 2)\n                    self.stmts.append(\n                        self.get_sql_newpath_in_branches(\n                            oldpath, tempnewpath))\n\n            # Optimisation to only move siblings which need moving\n            # (i.e. if we've got holes, allow them to compress)\n            movesiblings = []\n            priorpath = newpath\n            for node in siblings:\n                # If the path of the node is already greater than the path\n                # of the previous node it doesn't need shifting\n                if node.path > priorpath:\n                    break\n                # It does need shifting, so add to the list\n                movesiblings.append(node)\n                # Calculate the path that it would be moved to, as that's\n                # the next \"priorpath\"\n                priorpath = node._inc_path()\n            movesiblings.reverse()\n\n            for node in movesiblings:\n                # moving the siblings (and their branches) at the right of the\n                # related position one step to the right\n                sql, vals = self.get_sql_newpath_in_branches(\n                    node.path, node._inc_path())\n                self.stmts.append((sql, vals))\n\n                if movebranch:\n                    if oldpath.startswith(node.path):\n                        # if moving to a parent, update oldpath since we just\n                        # increased the path of the entire branch\n                        oldpath = vals[0] + oldpath[len(vals[0]):]\n                    if target.path.startswith(node.path):\n                        # and if we moved the target, update the object\n                        # django made for us, since the update won't do it\n                        # maybe useful in loops\n                        target.path = vals[0] + target.path[len(vals[0]):]\n            if movebranch:\n                # node to move\n                if tempnewpath:\n                    self.stmts.append(\n                        self.get_sql_newpath_in_branches(\n                            tempnewpath, newpath))\n                else:\n                    self.stmts.append(\n                        self.get_sql_newpath_in_branches(\n                            oldpath, newpath))\n        return oldpath, newpath", "response": "Handles the reordering of nodes and branches when adding or moving a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the sql needed to move a branch to another position.", "response": "def get_sql_newpath_in_branches(self, oldpath, newpath):\n        \"\"\"\n        :returns: The sql needed to move a branch to another position.\n\n        .. note::\n\n           The generated sql will only update the depth values if needed.\n\n        \"\"\"\n\n        vendor = self.node_cls.get_database_vendor('write')\n        sql1 = \"UPDATE %s SET\" % (\n            connection.ops.quote_name(\n                get_result_class(self.node_cls)._meta.db_table), )\n\n        # <3 \"standard\" sql\n        if vendor == 'sqlite':\n            # I know that the third argument in SUBSTR (LENGTH(path)) is\n            # awful, but sqlite fails without it:\n            # OperationalError: wrong number of arguments to function substr()\n            # even when the documentation says that 2 arguments are valid:\n            # http://www.sqlite.org/lang_corefunc.html\n            sqlpath = \"%s||SUBSTR(path, %s, LENGTH(path))\"\n        elif vendor == 'mysql':\n            # hooray for mysql ignoring standards in their default\n            # configuration!\n            # to make || work as it should, enable ansi mode\n            # http://dev.mysql.com/doc/refman/5.0/en/ansi-mode.html\n            sqlpath = \"CONCAT(%s, SUBSTR(path, %s))\"\n        else:\n            sqlpath = sql_concat(\"%s\", sql_substr(\"path\", \"%s\", vendor=vendor), vendor=vendor)\n\n        sql2 = [\"path=%s\" % (sqlpath, )]\n        vals = [newpath, len(oldpath) + 1]\n        if len(oldpath) != len(newpath) and vendor != 'mysql':\n            # when using mysql, this won't update the depth and it has to be\n            # done in another query\n            # doesn't even work with sql_mode='ANSI,TRADITIONAL'\n            # TODO: FIND OUT WHY?!?? right now I'm just blaming mysql\n            sql2.append((\"depth=\" + sql_length(\"%s\", vendor=vendor) + \"/%%s\") % (sqlpath, ))\n            vals.extend([newpath, len(oldpath) + 1, self.node_cls.steplen])\n        sql3 = \"WHERE path LIKE %s\"\n        vals.extend([oldpath + '%'])\n        sql = '%s %s %s' % (sql1, ', '.join(sql2), sql3)\n        return sql, vals"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the list of sql statements needed after moving nodes.", "response": "def sanity_updates_after_move(self, oldpath, newpath):\n        \"\"\"\n        Updates the list of sql statements needed after moving nodes.\n\n        1. :attr:`depth` updates *ONLY* needed by mysql databases (*sigh*)\n        2. update the number of children of parent nodes\n        \"\"\"\n        if (\n                self.node_cls.get_database_vendor('write') == 'mysql' and\n                len(oldpath) != len(newpath)\n        ):\n            # no words can describe how dumb mysql is\n            # we must update the depth of the branch in a different query\n            self.stmts.append(\n                self.get_mysql_update_depth_in_branch(newpath))\n\n        oldparentpath = self.node_cls._get_parent_path_from_path(oldpath)\n        newparentpath = self.node_cls._get_parent_path_from_path(newpath)\n        if (\n                (not oldparentpath and newparentpath) or\n                (oldparentpath and not newparentpath) or\n                (oldparentpath != newparentpath)\n        ):\n            # node changed parent, updating count\n            if oldparentpath:\n                self.stmts.append(\n                    self.get_sql_update_numchild(oldparentpath, 'dec'))\n            if newparentpath:\n                self.stmts.append(\n                    self.get_sql_update_numchild(newparentpath, 'inc'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_move_to_child_vars(self):\n        newdepth = self.target.depth\n        newpos = None\n        siblings = []\n        if self.pos in ('first-child', 'last-child', 'sorted-child'):\n            # moving to a child\n            parent = self.target\n            newdepth += 1\n            if self.target.is_leaf():\n                # moving as a target's first child\n                newpos = 1\n                self.pos = 'first-sibling'\n                siblings = get_result_class(self.node_cls).objects.none()\n            else:\n                self.target = self.target.get_last_child()\n                self.pos = {\n                    'first-child': 'first-sibling',\n                    'last-child': 'last-sibling',\n                    'sorted-child': 'sorted-sibling'}[self.pos]\n\n            # this is not for save(), since if needed, will be handled with a\n            # custom UPDATE, this is only here to update django's object,\n            # should be useful in loops\n            parent.numchild += 1\n\n        return newdepth, siblings, newpos", "response": "Update preliminar vars in : meth : move when moving to a child"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mysql_update_depth_in_branch(self, path):\n        vendor = self.node_cls.get_database_vendor('write')\n        sql = (\"UPDATE %s SET depth=\" + sql_length(\"path\", vendor=vendor) + \"/%%s WHERE path LIKE %%s\") % (\n            connection.ops.quote_name(\n                get_result_class(self.node_cls)._meta.db_table), )\n        vals = [self.node_cls.steplen, path + '%']\n        return sql, vals", "response": "Returns the sql needed to update the depth of all the nodes in a\n                  branch."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_bulk(cls, parent=None, keep_ids=True):\n\n        cls = get_result_class(cls)\n\n        # Because of fix_tree, this method assumes that the depth\n        # and numchild properties in the nodes can be incorrect,\n        # so no helper methods are used\n        qset = cls._get_serializable_model().objects.all()\n        if parent:\n            qset = qset.filter(path__startswith=parent.path)\n        ret, lnk = [], {}\n        for pyobj in serializers.serialize('python', qset):\n            # django's serializer stores the attributes in 'fields'\n            fields = pyobj['fields']\n            path = fields['path']\n            depth = int(len(path) / cls.steplen)\n            # this will be useless in load_bulk\n            del fields['depth']\n            del fields['path']\n            del fields['numchild']\n            if 'id' in fields:\n                # this happens immediately after a load_bulk\n                del fields['id']\n\n            newobj = {'data': fields}\n            if keep_ids:\n                newobj['id'] = pyobj['pk']\n\n            if (not parent and depth == 1) or\\\n               (parent and len(path) == len(parent.path)):\n                ret.append(newobj)\n            else:\n                parentpath = cls._get_basepath(path, depth - 1)\n                parentobj = lnk[parentpath]\n                if 'children' not in parentobj:\n                    parentobj['children'] = []\n                parentobj['children'].append(newobj)\n            lnk[path] = newobj\n        return ret", "response": "Dumps a tree branch to a python data structure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_problems(cls):\n        cls = get_result_class(cls)\n        vendor = cls.get_database_vendor('write')\n\n        evil_chars, bad_steplen, orphans = [], [], []\n        wrong_depth, wrong_numchild = [], []\n        for node in cls.objects.all():\n            found_error = False\n            for char in node.path:\n                if char not in cls.alphabet:\n                    evil_chars.append(node.pk)\n                    found_error = True\n                    break\n            if found_error:\n                continue\n            if len(node.path) % cls.steplen:\n                bad_steplen.append(node.pk)\n                continue\n            try:\n                node.get_parent(True)\n            except cls.DoesNotExist:\n                orphans.append(node.pk)\n                continue\n\n            if node.depth != int(len(node.path) / cls.steplen):\n                wrong_depth.append(node.pk)\n                continue\n\n            real_numchild = cls.objects.filter(\n                path__range=cls._get_children_path_interval(node.path)\n            ).extra(\n                where=[(sql_length(\"path\", vendor=vendor) + '/%d=%d') % (cls.steplen, node.depth + 1)]\n            ).count()\n            if real_numchild != node.numchild:\n                wrong_numchild.append(node.pk)\n                continue\n\n        return evil_chars, bad_steplen, orphans, wrong_depth, wrong_numchild", "response": "This method checks for problems in the tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfix the depth field of the tree.", "response": "def fix_tree(cls, destructive=False):\n        \"\"\"\n        Solves some problems that can appear when transactions are not used and\n        a piece of code breaks, leaving the tree in an inconsistent state.\n\n        The problems this method solves are:\n\n           1. Nodes with an incorrect ``depth`` or ``numchild`` values due to\n              incorrect code and lack of database transactions.\n           2. \"Holes\" in the tree. This is normal if you move/delete nodes a\n              lot. Holes in a tree don't affect performance,\n           3. Incorrect ordering of nodes when ``node_order_by`` is enabled.\n              Ordering is enforced on *node insertion*, so if an attribute in\n              ``node_order_by`` is modified after the node is inserted, the\n              tree ordering will be inconsistent.\n\n        :param destructive:\n\n            A boolean value. If True, a more agressive fix_tree method will be\n            attempted. If False (the default), it will use a safe (and fast!)\n            fix approach, but it will only solve the ``depth`` and\n            ``numchild`` nodes, it won't fix the tree holes or broken path\n            ordering.\n\n            .. warning::\n\n               Currently what the ``destructive`` method does is:\n\n               1. Backup the tree with :meth:`dump_data`\n               2. Remove all nodes in the tree.\n               3. Restore the tree with :meth:`load_data`\n\n               So, even when the primary keys of your nodes will be preserved,\n               this method isn't foreign-key friendly. That needs complex\n               in-place tree reordering, not available at the moment (hint:\n               patches are welcome).\n        \"\"\"\n        cls = get_result_class(cls)\n        vendor = cls.get_database_vendor('write')\n\n        if destructive:\n            dump = cls.dump_bulk(None, True)\n            cls.objects.all().delete()\n            cls.load_bulk(dump, None, True)\n        else:\n            cursor = cls._get_database_cursor('write')\n\n            # fix the depth field\n            # we need the WHERE to speed up postgres\n            sql = (\n                \"UPDATE %s \"\n                \"SET depth=\" + sql_length(\"path\", vendor=vendor) + \"/%%s \"\n                \"WHERE depth!=\" + sql_length(\"path\", vendor=vendor) + \"/%%s\"\n            ) % (connection.ops.quote_name(cls._meta.db_table), )\n            vals = [cls.steplen, cls.steplen]\n            cursor.execute(sql, vals)\n\n            # fix the numchild field\n            vals = ['_' * cls.steplen]\n            # the cake and sql portability are a lie\n            if cls.get_database_vendor('read') == 'mysql':\n                sql = (\n                    \"SELECT tbn1.path, tbn1.numchild, (\"\n                    \"SELECT COUNT(1) \"\n                    \"FROM %(table)s AS tbn2 \"\n                    \"WHERE tbn2.path LIKE \" +\n                    sql_concat(\"tbn1.path\", \"%%s\", vendor=vendor) + \") AS real_numchild \"\n                    \"FROM %(table)s AS tbn1 \"\n                    \"HAVING tbn1.numchild != real_numchild\"\n                ) % {'table': connection.ops.quote_name(cls._meta.db_table)}\n            else:\n                subquery = \"(SELECT COUNT(1) FROM %(table)s AS tbn2\"\\\n                           \" WHERE tbn2.path LIKE \" + sql_concat(\"tbn1.path\", \"%%s\", vendor=vendor) + \")\"\n                sql = (\"SELECT tbn1.path, tbn1.numchild, \" + subquery +\n                       \" FROM %(table)s AS tbn1 WHERE tbn1.numchild != \" +\n                       subquery)\n                sql = sql % {\n                    'table': connection.ops.quote_name(cls._meta.db_table)}\n                # we include the subquery twice\n                vals *= 2\n            cursor.execute(sql, vals)\n            sql = \"UPDATE %(table)s \"\\\n                  \"SET numchild=%%s \"\\\n                  \"WHERE path=%%s\" % {\n                      'table': connection.ops.quote_name(cls._meta.db_table)}\n            for node_data in cursor.fetchall():\n                vals = [node_data[2], node_data[0]]\n                cursor.execute(sql, vals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_tree(cls, parent=None):\n        cls = get_result_class(cls)\n\n        if parent is None:\n            # return the entire tree\n            return cls.objects.all()\n        if parent.is_leaf():\n            return cls.objects.filter(pk=parent.pk)\n        return cls.objects.filter(\n            path__startswith=parent.path,\n            depth__gte=parent.depth\n        ).order_by(\n            'path'\n        )", "response": "Returns a queryset of all the nodes in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of all the descendants of a class and their count.", "response": "def get_descendants_group_count(cls, parent=None):\n        \"\"\"\n        Helper for a very common case: get a group of siblings and the number\n        of *descendants* in every sibling.\n        \"\"\"\n\n        #~\n        # disclaimer: this is the FOURTH implementation I wrote for this\n        # function. I really tried to make it return a queryset, but doing so\n        # with a *single* query isn't trivial with Django's ORM.\n\n        # ok, I DID manage to make Django's ORM return a queryset here,\n        # defining two querysets, passing one subquery in the tables parameters\n        # of .extra() of the second queryset, using the undocumented order_by\n        # feature, and using a HORRIBLE hack to avoid django quoting the\n        # subquery as a table, BUT (and there is always a but) the hack didn't\n        # survive turning the QuerySet into a ValuesQuerySet, so I just used\n        # good old SQL.\n        # NOTE: in case there is interest, the hack to avoid django quoting the\n        # subquery as a table, was adding the subquery to the alias cache of\n        # the queryset's query object:\n        #\n        #     qset.query.quote_cache[subquery] = subquery\n        #\n        # If there is a better way to do this in an UNMODIFIED django 1.0, let\n        # me know.\n        #~\n\n        cls = get_result_class(cls)\n        vendor = cls.get_database_vendor('write')\n\n        if parent:\n            depth = parent.depth + 1\n            params = cls._get_children_path_interval(parent.path)\n            extrand = 'AND path BETWEEN %s AND %s'\n        else:\n            depth = 1\n            params = []\n            extrand = ''\n\n        subpath = sql_substr(\"path\", \"1\", \"%(subpathlen)s\", vendor=vendor)\n\n        sql = (\n            'SELECT * FROM %(table)s AS t1 INNER JOIN '\n            ' (SELECT '\n            '   ' + subpath + ' AS subpath, '\n            '   COUNT(1)-1 AS count '\n            '   FROM %(table)s '\n            '   WHERE depth >= %(depth)s %(extrand)s'\n            '   GROUP BY '+ subpath + ') AS t2 '\n            ' ON t1.path=t2.subpath '\n            ' ORDER BY t1.path'\n        ) % {\n            'table': connection.ops.quote_name(cls._meta.db_table),\n            'subpathlen': depth * cls.steplen,\n            'depth': depth,\n                'extrand': extrand}\n        cursor = cls._get_database_cursor('write')\n        cursor.execute(sql, params)\n\n        ret = []\n        field_names = [field[0] for field in cursor.description]\n        for node_data in cursor.fetchall():\n            node = cls(**dict(zip(field_names, node_data[:-2])))\n            node.descendants_count = node_data[-1]\n            ret.append(node)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_siblings(self):\n        qset = get_result_class(self.__class__).objects.filter(\n            depth=self.depth\n        ).order_by(\n            'path'\n        )\n        if self.depth > 1:\n            # making sure the non-root nodes share a parent\n            parentpath = self._get_basepath(self.path, self.depth - 1)\n            qset = qset.filter(\n                path__range=self._get_children_path_interval(parentpath))\n        return qset", "response": "Returns a queryset of all the node s siblings including the node itself."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_children(self):\n        if self.is_leaf():\n            return get_result_class(self.__class__).objects.none()\n        return get_result_class(self.__class__).objects.filter(\n            depth=self.depth + 1,\n            path__range=self._get_children_path_interval(self.path)\n        ).order_by(\n            'path'\n        )", "response": "Returns a queryset of all the node s children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a queryset of all the node s descendants as DFS", "response": "def get_descendants(self):\n        \"\"\"\n        :returns: A queryset of all the node's descendants as DFS, doesn't\n            include the node itself\n        \"\"\"\n        return self.__class__.get_tree(self).exclude(pk=self.pk)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the previous node s sibling or None if it was the leftmost sibling.", "response": "def get_prev_sibling(self):\n        \"\"\"\n        :returns: The previous node's sibling, or None if it was the leftmost\n            sibling.\n        \"\"\"\n        try:\n            return self.get_siblings().filter(path__lt=self.path).reverse()[0]\n        except IndexError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the node is a sibling of another node.", "response": "def is_sibling_of(self, node):\n        \"\"\"\n        :returns: ``True`` if the node is a sibling of another node given as an\n            argument, else, returns ``False``\n        \"\"\"\n        aux = self.depth == node.depth\n        # Check non-root nodes share a parent only if they have the same depth\n        if aux and self.depth > 1:\n            # making sure the non-root nodes share a parent\n            parentpath = self._get_basepath(self.path, self.depth - 1)\n            return aux and node.path.startswith(parentpath)\n        return aux"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if this node is a child of another node.", "response": "def is_child_of(self, node):\n        \"\"\"\n        :returns: ``True`` is the node if a child of another node given as an\n            argument, else, returns ``False``\n        \"\"\"\n        return (self.path.startswith(node.path) and\n                self.depth == node.depth + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the node is a descendant of another node.", "response": "def is_descendant_of(self, node):\n        \"\"\"\n        :returns: ``True`` if the node is a descendant of another node given\n            as an argument, else, returns ``False``\n        \"\"\"\n        return self.path.startswith(node.path) and self.depth > node.depth"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_root(self):\n        return get_result_class(self.__class__).objects.get(\n            path=self.path[0:self.steplen])", "response": "returns the root node for the current node object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ancestors(self):\n        if self.is_root():\n            return get_result_class(self.__class__).objects.none()\n\n        paths = [\n            self.path[0:pos]\n            for pos in range(0, len(self.path), self.steplen)[1:]\n        ]\n        return get_result_class(self.__class__).objects.filter(\n            path__in=paths).order_by('depth')", "response": "Returns a queryset containing the current node s ancestors ordered by depth."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_parent(self, update=False):\n        depth = int(len(self.path) / self.steplen)\n        if depth <= 1:\n            return\n        try:\n            if update:\n                del self._cached_parent_obj\n            else:\n                return self._cached_parent_obj\n        except AttributeError:\n            pass\n        parentpath = self._get_basepath(self.path, depth - 1)\n        self._cached_parent_obj = get_result_class(\n            self.__class__).objects.get(path=parentpath)\n        return self._cached_parent_obj", "response": "Gets the parent node of the current node object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_path(cls, path, depth, newstep):\n        parentpath = cls._get_basepath(path, depth - 1)\n        key = cls._int2str(newstep)\n        return '{0}{1}{2}'.format(\n            parentpath,\n            cls.alphabet[0] * (cls.steplen - len(key)),\n            key\n        )", "response": "Builds a path given some values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _inc_path(self):\n        newpos = self._str2int(self.path[-self.steplen:]) + 1\n        key = self._int2str(newpos)\n        if len(key) > self.steplen:\n            raise PathOverflow(_(\"Path Overflow from: '%s'\" % (self.path, )))\n        return '{0}{1}{2}'.format(\n            self.path[:-self.steplen],\n            self.alphabet[0] * (self.steplen - len(key)),\n            key\n        )", "response": "Returns the path of the next sibling of a given node path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an interval of all possible children paths for a node.", "response": "def _get_children_path_interval(cls, path):\n        \"\"\":returns: An interval of all possible children paths for a node.\"\"\"\n        return (path + cls.alphabet[0] * cls.steplen,\n                path + cls.alphabet[-1] * cls.steplen)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef int2str(num, radix=10, alphabet=BASE85):\n    return NumConv(radix, alphabet).int2str(num)", "response": "helper function for quick base conversions from integers to strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef str2int(num, radix=10, alphabet=BASE85):\n    return NumConv(radix, alphabet).str2int(num)", "response": "helper function for quick base conversions from strings to integers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef int2str(self, num):\n        if int(num) != num:\n            raise TypeError('number must be an integer')\n        if num < 0:\n            raise ValueError('number must be positive')\n        radix, alphabet = self.radix, self.alphabet\n        if radix in (8, 10, 16) and \\\n                alphabet[:radix].lower() == BASE85[:radix].lower():\n            return ({8: '%o', 10: '%d', 16: '%x'}[radix] % num).upper()\n        ret = ''\n        while True:\n            ret = alphabet[num % radix] + ret\n            if num < radix:\n                break\n            num //= radix\n        return ret", "response": "Converts an integer to a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef str2int(self, num):\n        radix, alphabet = self.radix, self.alphabet\n        if radix <= 36 and alphabet[:radix].lower() == BASE85[:radix].lower():\n            return int(num, radix)\n        ret = 0\n        lalphabet = alphabet[:radix]\n        for char in num:\n            if char not in lalphabet:\n                raise ValueError(\"invalid literal for radix2int() with radix \"\n                                 \"%d: '%s'\" % (radix, num))\n            ret = ret * radix + self.cached_map[char]\n        return ret", "response": "Converts a string into an integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_queryset(self):\n        if self.model.node_order_by:\n            order_by = ['parent'] + list(self.model.node_order_by)\n        else:\n            order_by = ['parent', 'sib_order']\n        return super(AL_NodeManager, self).get_queryset().order_by(*order_by)", "response": "Sets the custom queryset as the default."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_root(cls, **kwargs):\n\n        if len(kwargs) == 1 and 'instance' in kwargs:\n            # adding the passed (unsaved) instance to the tree\n            newobj = kwargs['instance']\n            if newobj.pk:\n                raise NodeAlreadySaved(\"Attempted to add a tree node that is \"\\\n                    \"already in the database\")\n        else:\n            newobj = cls(**kwargs)\n\n        newobj._cached_depth = 1\n        if not cls.node_order_by:\n            try:\n                max = get_result_class(cls).objects.filter(\n                    parent__isnull=True).order_by(\n                    'sib_order').reverse()[0].sib_order\n            except IndexError:\n                max = 0\n            newobj.sib_order = max + 1\n        newobj.save()\n        return newobj", "response": "Adds a root node to the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_depth(self, update=False):\n\n        if self.parent_id is None:\n            return 1\n\n        try:\n            if update:\n                del self._cached_depth\n            else:\n                return self._cached_depth\n        except AttributeError:\n            pass\n\n        depth = 0\n        node = self\n        while node:\n            node = node.parent\n            depth += 1\n        self._cached_depth = depth\n        return depth", "response": "Gets the depth of the node in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the parent node of the current node object", "response": "def get_parent(self, update=False):\n        \"\"\":returns: the parent node of the current node object.\"\"\"\n        if self._meta.proxy_for_model:\n            # the current node is a proxy model; the returned parent\n            # should be the same proxy model, so we need to explicitly\n            # fetch it as an instance of that model rather than simply\n            # following the 'parent' relation\n            if self.parent_id is None:\n                return None\n            else:\n                return self.__class__.objects.get(pk=self.parent_id)\n        else:\n            return self.parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ancestors(self):\n        ancestors = []\n        if self._meta.proxy_for_model:\n            # the current node is a proxy model; our result set\n            # should use the same proxy model, so we need to\n            # explicitly fetch instances of that model\n            # when following the 'parent' relation\n            cls = self.__class__\n            node = self\n            while node.parent_id:\n                node = cls.objects.get(pk=node.parent_id)\n                ancestors.insert(0, node)\n        else:\n            node = self.parent\n            while node:\n                ancestors.insert(0, node)\n                node = node.parent\n        return ancestors", "response": "Returns a list containing the current node s ancestors starting by the root node and descending to the parent node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the node is a descendant of another node.", "response": "def is_descendant_of(self, node):\n        \"\"\"\n        :returns: ``True`` if the node if a descendant of another node given\n            as an argument, else, returns ``False``\n        \"\"\"\n        return self.pk in [obj.pk for obj in node.get_descendants()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_bulk(cls, parent=None, keep_ids=True):\n\n        serializable_cls = cls._get_serializable_model()\n        if (\n                parent and serializable_cls != cls and\n                parent.__class__ != serializable_cls\n        ):\n            parent = serializable_cls.objects.get(pk=parent.pk)\n\n        # a list of nodes: not really a queryset, but it works\n        objs = serializable_cls.get_tree(parent)\n\n        ret, lnk = [], {}\n        for node, pyobj in zip(objs, serializers.serialize('python', objs)):\n            depth = node.get_depth()\n            # django's serializer stores the attributes in 'fields'\n            fields = pyobj['fields']\n            del fields['parent']\n\n            # non-sorted trees have this\n            if 'sib_order' in fields:\n                del fields['sib_order']\n\n            if 'id' in fields:\n                del fields['id']\n\n            newobj = {'data': fields}\n            if keep_ids:\n                newobj['id'] = pyobj['pk']\n\n            if (not parent and depth == 1) or\\\n               (parent and depth == parent.get_depth()):\n                ret.append(newobj)\n            else:\n                parentobj = lnk[node.parent_id]\n                if 'children' not in parentobj:\n                    parentobj['children'] = []\n                parentobj['children'].append(newobj)\n            lnk[node.pk] = newobj\n        return ret", "response": "Dumps a tree branch to a python data structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_child(self, **kwargs):\n        cls = get_result_class(self.__class__)\n\n        if len(kwargs) == 1 and 'instance' in kwargs:\n            # adding the passed (unsaved) instance to the tree\n            newobj = kwargs['instance']\n            if newobj.pk:\n                raise NodeAlreadySaved(\"Attempted to add a tree node that is \"\\\n                    \"already in the database\")\n        else:\n            newobj = cls(**kwargs)\n\n        try:\n            newobj._cached_depth = self._cached_depth + 1\n        except AttributeError:\n            pass\n        if not cls.node_order_by:\n            try:\n                max = cls.objects.filter(parent=self).reverse(\n                )[0].sib_order\n            except IndexError:\n                max = 0\n            newobj.sib_order = max + 1\n        newobj.parent = self\n        newobj.save()\n        return newobj", "response": "Adds a child to the node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tree(cls, parent=None):\n        if parent:\n            depth = parent.get_depth() + 1\n            results = [parent]\n        else:\n            depth = 1\n            results = []\n        cls._get_tree_recursively(results, parent, depth)\n        return results", "response": "Returns a list of nodes ordered as DFS including the parent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a queryset of all the node s siblings including the nodeMeMe.", "response": "def get_siblings(self):\n        \"\"\"\n        :returns: A queryset of all the node's siblings, including the node\n            itself.\n        \"\"\"\n        if self.parent:\n            return get_result_class(self.__class__).objects.filter(\n                parent=self.parent)\n        return self.__class__.get_root_nodes()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_sibling(self, pos=None, **kwargs):\n        pos = self._prepare_pos_var_for_add_sibling(pos)\n\n        if len(kwargs) == 1 and 'instance' in kwargs:\n            # adding the passed (unsaved) instance to the tree\n            newobj = kwargs['instance']\n            if newobj.pk:\n                raise NodeAlreadySaved(\"Attempted to add a tree node that is \"\\\n                    \"already in the database\")\n        else:\n            # creating a new object\n            newobj = get_result_class(self.__class__)(**kwargs)\n\n        if not self.node_order_by:\n            newobj.sib_order = self.__class__._get_new_sibling_order(pos,\n                                                                     self)\n        newobj.parent_id = self.parent_id\n        newobj.save()\n        return newobj", "response": "Adds a new node as a sibling to the current node object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move(self, target, pos=None):\n\n        pos = self._prepare_pos_var_for_move(pos)\n\n        sib_order = None\n        parent = None\n\n        if pos in ('first-child', 'last-child', 'sorted-child'):\n            # moving to a child\n            if not target.is_leaf():\n                target = target.get_last_child()\n                pos = {'first-child': 'first-sibling',\n                       'last-child': 'last-sibling',\n                       'sorted-child': 'sorted-sibling'}[pos]\n            else:\n                parent = target\n                if pos == 'sorted-child':\n                    pos = 'sorted-sibling'\n                else:\n                    pos = 'first-sibling'\n                    sib_order = 1\n\n        if target.is_descendant_of(self):\n            raise InvalidMoveToDescendant(\n                _(\"Can't move node to a descendant.\"))\n\n        if self == target and (\n            (pos == 'left') or\n            (pos in ('right', 'last-sibling') and\n             target == target.get_last_sibling()) or\n            (pos == 'first-sibling' and\n             target == target.get_first_sibling())):\n            # special cases, not actually moving the node so no need to UPDATE\n            return\n\n        if pos == 'sorted-sibling':\n            if parent:\n                self.parent = parent\n            else:\n                self.parent = target.parent\n        else:\n            if sib_order:\n                self.sib_order = sib_order\n            else:\n                self.sib_order = self.__class__._get_new_sibling_order(pos,\n                                                                       target)\n            if parent:\n                self.parent = parent\n            else:\n                self.parent = target.parent\n\n        self.save()", "response": "Moves the current node and all its descendants to a new position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a contribute_to_class method that can be used to create a Contributagenat in order to create a Contributagenatat.", "response": "def make_contrib(superclass, func=None):\n    \"\"\"\n    Returns a suitable contribute_to_class() method for the Field subclass.\n\n    If 'func' is passed in, it is the existing contribute_to_class() method on\n    the subclass and it is called before anything else. It is assumed in this\n    case that the existing contribute_to_class() calls all the necessary\n    superclass methods.\n    \"\"\"\n    def contribute_to_class(self, cls, name):\n        if func:\n            func(self, cls, name)\n        else:\n            super(superclass, self).contribute_to_class(cls, name)\n        setattr(cls, self.name, Creator(self))\n\n    return contribute_to_class"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pre_init(self, value, obj):\n\n        try:\n            if obj._state.adding:\n                # Make sure the primary key actually exists on the object before\n                # checking if it's empty. This is a special case for South datamigrations\n                # see: https://github.com/bradjasper/django-jsonfield/issues/52\n                if getattr(obj, \"pk\", None) is not None:\n                    if isinstance(value, six.string_types):\n                        try:\n                            return json.loads(value, **self.load_kwargs)\n                        except ValueError:\n                            raise ValidationError(_(\"Enter valid JSON\"))\n\n        except AttributeError:\n            # south fake meta class doesn't create proper attributes\n            # see this:\n            # https://github.com/bradjasper/django-jsonfield/issues/52\n            pass\n\n        return value", "response": "Convert a string value to JSON only if it needs to be deserialized."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_prep_value(self, value):\n        if self.null and value is None:\n            return None\n        return json.dumps(value, **self.dump_kwargs)", "response": "Convert a JSON object to a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts string to model class.", "response": "def get_model(method):\n    \"\"\"Convert string to model class.\"\"\"\n\n    @wraps(method)\n    def wrapper(migrator, model, *args, **kwargs):\n        if isinstance(model, str):\n            return method(migrator, migrator.orm[model], *args, **kwargs)\n        return method(migrator, model, *args, **kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize migrator by db.", "response": "def from_database(cls, database):\n        \"\"\"Initialize migrator by db.\"\"\"\n        if isinstance(database, PostgresqlDatabase):\n            return PostgresqlMigrator(database)\n        if isinstance(database, SqliteDatabase):\n            return SqliteMigrator(database)\n        if isinstance(database, MySQLDatabase):\n            return MySQLMigrator(database)\n        return super(SchemaMigrator, cls).from_database(database)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef alter_add_column(self, table, column_name, field, **kwargs):\n        name = field.name\n        op = super(SchemaMigrator, self).alter_add_column(table, column_name, field, **kwargs)\n        if isinstance(field, pw.ForeignKeyField):\n            field.name = name\n        return op", "response": "Fix fieldname for ForeignKeys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_table(self, model):\n        self.orm[model._meta.table_name] = model\n        model._meta.database = self.database\n        self.ops.append(model.create_table)\n        return model", "response": "Create model and table in database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndropping the table from the database.", "response": "def drop_table(self, model, cascade=True):\n        \"\"\"Drop model and table from database.\n\n        >> migrator.drop_table(model, cascade=True)\n        \"\"\"\n        del self.orm[model._meta.table_name]\n        self.ops.append(self.migrator.drop_table(model, cascade))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef change_columns(self, model, **fields):\n        for name, field in fields.items():\n            old_field = model._meta.fields.get(name, field)\n            old_column_name = old_field and old_field.column_name\n\n            model._meta.add_field(name, field)\n\n            if isinstance(old_field, pw.ForeignKeyField):\n                self.ops.append(self.migrator.drop_foreign_key_constraint(\n                    model._meta.table_name, old_column_name))\n\n            if old_column_name != field.column_name:\n                self.ops.append(\n                    self.migrator.rename_column(\n                        model._meta.table_name, old_column_name, field.column_name))\n\n            if isinstance(field, pw.ForeignKeyField):\n                on_delete = field.on_delete if field.on_delete else 'RESTRICT'\n                on_update = field.on_update if field.on_update else 'RESTRICT'\n                self.ops.append(self.migrator.add_foreign_key_constraint(\n                    model._meta.table_name, field.column_name,\n                    field.rel_model._meta.table_name, field.rel_field.name,\n                    on_delete, on_update))\n                continue\n\n            self.ops.append(self.migrator.change_column(\n                model._meta.table_name, field.column_name, field))\n\n            if field.unique == old_field.unique:\n                continue\n\n            if field.unique:\n                index = (field.column_name,), field.unique\n                self.ops.append(self.migrator.add_index(model._meta.table_name, *index))\n                model._meta.indexes.append(index)\n            else:\n                index = (field.column_name,), old_field.unique\n                self.ops.append(self.migrator.drop_index(model._meta.table_name, *index))\n                model._meta.indexes.remove(index)\n\n        return model", "response": "Change columns of a model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving columns from model.", "response": "def drop_columns(self, model, *names, **kwargs):\n        \"\"\"Remove fields from model.\"\"\"\n        fields = [field for field in model._meta.fields.values() if field.name in names]\n        cascade = kwargs.pop('cascade', True)\n        for field in fields:\n            self.__del_field__(model, field)\n            if field.unique:\n                index_name = make_index_name(model._meta.table_name, [field.column_name])\n                self.ops.append(self.migrator.drop_index(model._meta.table_name, index_name))\n            self.ops.append(\n                self.migrator.drop_column(\n                    model._meta.table_name, field.column_name, cascade=cascade))\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrenaming field in model.", "response": "def rename_column(self, model, old_name, new_name):\n        \"\"\"Rename field in model.\"\"\"\n        field = model._meta.fields[old_name]\n        if isinstance(field, pw.ForeignKeyField):\n            old_name = field.column_name\n        self.__del_field__(model, field)\n        field.name = field.column_name = new_name\n        model._meta.add_field(new_name, field)\n        if isinstance(field, pw.ForeignKeyField):\n            field.column_name = new_name = field.column_name + '_id'\n        self.ops.append(self.migrator.rename_column(model._meta.table_name, old_name, new_name))\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rename_table(self, model, new_name):\n        del self.orm[model._meta.table_name]\n        model._meta.table_name = new_name\n        self.orm[model._meta.table_name] = model\n        self.ops.append(self.migrator.rename_table(model._meta.table_name, new_name))\n        return model", "response": "Rename table in database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd not null to the table.", "response": "def add_not_null(self, model, *names):\n        \"\"\"Add not null.\"\"\"\n        for name in names:\n            field = model._meta.fields[name]\n            field.null = False\n            self.ops.append(self.migrator.add_not_null(model._meta.table_name, field.column_name))\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_default(self, model, name, default):\n        field = model._meta.fields[name]\n        model._meta.defaults[field] = field.default = default\n        self.ops.append(self.migrator.apply_default(model._meta.table_name, name, field))\n        return model", "response": "Add default to the given model."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges migrations into one.", "response": "def merge(database=None, directory=None, verbose=None):\n    \"\"\"Merge migrations into one.\"\"\"\n    router = get_router(directory, database, verbose)\n    router.merge()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading models from given module.", "response": "def load_models(module):\n    \"\"\"Load models from given module.\"\"\"\n    modules = _import_submodules(module)\n    return {m for module in modules for m in filter(\n        _check_model, (getattr(module, name) for name in dir(module))\n    )}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks object if it s a peewee model and unique.", "response": "def _check_model(obj, models=None):\n    \"\"\"Checks object if it's a peewee model and unique.\"\"\"\n    return isinstance(obj, type) and issubclass(obj, pw.Model) and hasattr(obj, '_meta')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_migrations(migrator, models, reverse=False):\n    source = migrator.orm.values()\n    if reverse:\n        source, models = models, source\n\n    migrations = diff_many(models, source, migrator, reverse=reverse)\n    if not migrations:\n        return False\n\n    migrations = NEWLINE + NEWLINE.join('\\n\\n'.join(migrations).split('\\n'))\n    return CLEAN_RE.sub('\\n', migrations)", "response": "Compile migrations for given models."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes and cache MigrationHistory model.", "response": "def model(self):\n        \"\"\"Initialize and cache MigrationHistory model.\"\"\"\n        MigrateHistory._meta.database = self.database\n        MigrateHistory._meta.table_name = self.migrate_table\n        MigrateHistory._meta.schema = self.schema\n        MigrateHistory.create_table(True)\n        return MigrateHistory"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans migrations in database.", "response": "def done(self):\n        \"\"\"Scan migrations in database.\"\"\"\n        return [mm.name for mm in self.model.select().order_by(self.model.id)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate difference between fs and db.", "response": "def diff(self):\n        \"\"\"Calculate difference between fs and db.\"\"\"\n        done = set(self.done)\n        return [name for name in self.todo if name not in done]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates migrator and setup it with fake migrations.", "response": "def migrator(self):\n        \"\"\"Create migrator and setup it with fake migrations.\"\"\"\n        migrator = Migrator(self.database)\n        for name in self.done:\n            self.run_one(name, migrator)\n        return migrator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, name='auto', auto=False):\n        migrate = rollback = ''\n        if auto:\n            # Need to append the CURDIR to the path for import to work.\n            sys.path.append(CURDIR)\n            try:\n                modules = [auto]\n                if isinstance(auto, bool):\n                    modules = [m for _, m, ispkg in pkgutil.iter_modules([CURDIR]) if ispkg]\n\n                models = [m for module in modules for m in load_models(module)]\n\n            except ImportError:\n                return self.logger.error(\"Can't import models module: %s\", auto)\n\n            if self.ignore:\n                models = [m for m in models if m._meta.name not in self.ignore]\n\n            for migration in self.diff:\n                self.run_one(migration, self.migrator, fake=True)\n\n            migrate = compile_migrations(self.migrator, models)\n            if not migrate:\n                return self.logger.warn('No changes found.')\n\n            rollback = compile_migrations(self.migrator, models, reverse=True)\n\n        self.logger.info('Creating migration \"%s\"', name)\n        name = self.compile(name, migrate, rollback)\n        self.logger.info('Migration has been created as \"%s\"', name)\n        return name", "response": "Create a migration.\n        :param auto: Python module path to scan for models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(self, name='initial'):\n        migrator = Migrator(self.database)\n        migrate = compile_migrations(migrator, self.migrator.orm.values())\n        if not migrate:\n            return self.logger.error(\"Can't merge migrations\")\n\n        self.clear()\n\n        self.logger.info('Merge migrations into \"%s\"', name)\n        rollback = compile_migrations(self.migrator, [])\n        name = self.compile(name, migrate, rollback, 0)\n\n        migrator = Migrator(self.database)\n        self.run_one(name, migrator, fake=True, force=True)\n        self.logger.info('Migrations has been merged into \"%s\"', name)", "response": "Merge migrations into one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_one(self, name, migrator, fake=True, downgrade=False, force=False):\n        try:\n            migrate, rollback = self.read(name)\n            if fake:\n                with mock.patch('peewee.Model.select'):\n                    with mock.patch('peewee.Query._execute'):\n                        migrate(migrator, self.database, fake=fake)\n\n                if force:\n                    self.model.create(name=name)\n                    self.logger.info('Done %s', name)\n\n                migrator.clean()\n                return migrator\n\n            with self.database.transaction():\n                if not downgrade:\n                    self.logger.info('Migrate \"%s\"', name)\n                    migrate(migrator, self.database, fake=fake)\n                    migrator.run()\n                    self.model.create(name=name)\n                else:\n                    self.logger.info('Rolling back %s', name)\n                    rollback(migrator, self.database, fake=fake)\n                    migrator.run()\n                    self.model.delete().where(self.model.name == name).execute()\n\n                self.logger.info('Done %s', name)\n\n        except Exception:\n            self.database.rollback()\n            operation = 'Migration' if not downgrade else 'Rollback'\n            self.logger.exception('%s failed: %s', operation, name)\n            raise", "response": "Run a migration with given name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef todo(self):\n        if not os.path.exists(self.migrate_dir):\n            self.logger.warn('Migration directory: %s does not exist.', self.migrate_dir)\n            os.makedirs(self.migrate_dir)\n        return sorted(f[:-3] for f in os.listdir(self.migrate_dir) if self.filemask.match(f))", "response": "Scan migrations in file system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, name):\n        call_params = dict()\n        if os.name == 'nt' and sys.version_info >= (3, 0):\n            # if system is windows - force utf-8 encoding\n            call_params['encoding'] = 'utf-8'\n        with open(os.path.join(self.migrate_dir, name + '.py'), **call_params) as f:\n            code = f.read()\n            scope = {}\n            exec_in(code, scope)\n            return scope.get('migrate', VOID), scope.get('rollback', VOID)", "response": "Read migration from file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving migrations from fs.", "response": "def clear(self):\n        \"\"\"Remove migrations from fs.\"\"\"\n        super(Router, self).clear()\n        for name in self.todo:\n            filename = os.path.join(self.migrate_dir, name + '.py')\n            os.remove(filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diff_one(model1, model2, **kwargs):\n    changes = []\n\n    fields1 = model1._meta.fields\n    fields2 = model2._meta.fields\n\n    # Add fields\n    names1 = set(fields1) - set(fields2)\n    if names1:\n        fields = [fields1[name] for name in names1]\n        changes.append(create_fields(model1, *fields, **kwargs))\n\n    # Drop fields\n    names2 = set(fields2) - set(fields1)\n    if names2:\n        changes.append(drop_fields(model1, *names2))\n\n    # Change fields\n    fields_ = []\n    nulls_ = []\n    indexes_ = []\n    for name in set(fields1) - names1 - names2:\n        field1, field2 = fields1[name], fields2[name]\n        diff = compare_fields(field1, field2)\n        null = diff.pop('null', None)\n        index = diff.pop('index', None)\n\n        if diff:\n            fields_.append(field1)\n\n        if null is not None:\n            nulls_.append((name, null))\n\n        if index is not None:\n            indexes_.append((name, index[0], index[1]))\n\n    if fields_:\n        changes.append(change_fields(model1, *fields_, **kwargs))\n\n    for name, null in nulls_:\n        changes.append(change_not_null(model1, name, null))\n\n    for name, index, unique in indexes_:\n        if index is True or unique is True:\n            if fields2[name].unique or fields2[name].index:\n                changes.append(drop_index(model1, name))\n            changes.append(add_index(model1, name, unique))\n        else:\n            changes.append(drop_index(model1, name))\n\n    return changes", "response": "Find difference between two peewee models."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef diff_many(models1, models2, migrator=None, reverse=False):\n    models1 = pw.sort_models(models1)\n    models2 = pw.sort_models(models2)\n\n    if reverse:\n        models1 = reversed(models1)\n        models2 = reversed(models2)\n\n    models1 = OrderedDict([(m._meta.name, m) for m in models1])\n    models2 = OrderedDict([(m._meta.name, m) for m in models2])\n\n    changes = []\n\n    for name, model1 in models1.items():\n        if name not in models2:\n            continue\n        changes += diff_one(model1, models2[name], migrator=migrator)\n\n    # Add models\n    for name in [m for m in models1 if m not in models2]:\n        changes.append(create_model(models1[name], migrator=migrator))\n\n    # Remove models\n    for name in [m for m in models2 if m not in models1]:\n        changes.append(remove_model(models2[name]))\n\n    return changes", "response": "Calculate changes for migrations from models1 to models2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef watch(path: Union[Path, str], **kwargs):\n    loop = asyncio.new_event_loop()\n    try:\n        _awatch = awatch(path, loop=loop, **kwargs)\n        while True:\n            try:\n                yield loop.run_until_complete(_awatch.__anext__())\n            except StopAsyncIteration:\n                break\n    except KeyboardInterrupt:\n        logger.debug('KeyboardInterrupt, exiting')\n    finally:\n        loop.close()", "response": "Watch a directory and yield a set of changes whenever files change in that directory or its subdirectories."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a function in a subprocess using multiprocessing. Process.", "response": "def run_process(path: Union[Path, str], target: Callable, *,\n                args: Tuple=(),\n                kwargs: Dict[str, Any]=None,\n                callback: Callable[[Set[Tuple[Change, str]]], None]=None,\n                watcher_cls: Type[AllWatcher]=PythonWatcher,\n                debounce=400,\n                min_sleep=100):\n    \"\"\"\n    Run a function in a subprocess using multiprocessing.Process, restart it whenever files change in path.\n    \"\"\"\n\n    process = _start_process(target=target, args=args, kwargs=kwargs)\n    reloads = 0\n\n    for changes in watch(path, watcher_cls=watcher_cls, debounce=debounce, min_sleep=min_sleep):\n        callback and callback(changes)\n        _stop_process(process)\n        process = _start_process(target=target, args=args, kwargs=kwargs)\n        reloads += 1\n    return reloads"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def arun_process(path: Union[Path, str], target: Callable, *,\n                       args: Tuple[Any]=(),\n                       kwargs: Dict[str, Any]=None,\n                       callback: Callable[[Set[Tuple[Change, str]]], Awaitable]=None,\n                       watcher_cls: Type[AllWatcher]=PythonWatcher,\n                       debounce=400,\n                       min_sleep=100):\n    \"\"\"\n    Run a function in a subprocess using multiprocessing.Process, restart it whenever files change in path.\n    \"\"\"\n    watcher = awatch(path, watcher_cls=watcher_cls, debounce=debounce, min_sleep=min_sleep)\n    start_process = partial(_start_process, target=target, args=args, kwargs=kwargs)\n    process = await watcher.run_in_executor(start_process)\n    reloads = 0\n\n    async for changes in watcher:\n        callback and await callback(changes)\n        await watcher.run_in_executor(_stop_process, process)\n        process = await watcher.run_in_executor(start_process)\n        reloads += 1\n    return reloads", "response": "A function that runs a function in a subprocess using multiprocessing. Process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_event(event):\n    op_name = event.EventType.DESCRIPTOR.values_by_number[event.type].name\n    if op_name == 'PUT':\n        cls = PutEvent\n    elif op_name == 'DELETE':\n        cls = DeleteEvent\n    else:\n        raise Exception('Invalid op_name')\n\n    return cls(event)", "response": "Wrap a raw gRPC event in a friendlier containing class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nacquire the lock. :params timeout: Maximum time to wait before returning. `None` means forever, any other value equal or greater than 0 is the number of seconds. :returns: True if the lock has been acquired, False otherwise.", "response": "def acquire(self, timeout=10):\n        \"\"\"Acquire the lock.\n\n        :params timeout: Maximum time to wait before returning. `None` means\n                         forever, any other value equal or greater than 0 is\n                         the number of seconds.\n        :returns: True if the lock has been acquired, False otherwise.\n\n        \"\"\"\n        stop = (\n            tenacity.stop_never\n            if timeout is None else tenacity.stop_after_delay(timeout)\n        )\n\n        def wait(previous_attempt_number, delay_since_first_attempt):\n            if timeout is None:\n                remaining_timeout = None\n            else:\n                remaining_timeout = max(timeout - delay_since_first_attempt, 0)\n            # TODO(jd): Wait for a DELETE event to happen: that'd mean the lock\n            # has been released, rather than retrying on PUT events too\n            try:\n                self.etcd_client.watch_once(self.key, remaining_timeout)\n            except exceptions.WatchTimedOut:\n                pass\n            return 0\n\n        @tenacity.retry(retry=tenacity.retry_never,\n                        stop=stop,\n                        wait=wait)\n        def _acquire():\n            # TODO: save the created revision so we can check it later to make\n            # sure we still have the lock\n\n            self.lease = self.etcd_client.lease(self.ttl)\n\n            success, _ = self.etcd_client.transaction(\n                compare=[\n                    self.etcd_client.transactions.create(self.key) == 0\n                ],\n                success=[\n                    self.etcd_client.transactions.put(self.key, self.uuid,\n                                                      lease=self.lease)\n                ],\n                failure=[\n                    self.etcd_client.transactions.get(self.key)\n                ]\n            )\n            if success is True:\n                return True\n            self.lease = None\n            raise tenacity.TryAgain\n\n        try:\n            return _acquire()\n        except tenacity.RetryError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if this lock is currently acquired.", "response": "def is_acquired(self):\n        \"\"\"Check if this lock is currently acquired.\"\"\"\n        uuid, _ = self.etcd_client.get(self.key)\n\n        if uuid is None:\n            return False\n\n        return uuid == self.uuid"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lease_to_id(lease):\n    lease_id = 0\n    if hasattr(lease, 'id'):\n        lease_id = lease.id\n    else:\n        try:\n            lease_id = int(lease)\n        except TypeError:\n            pass\n    return lease_id", "response": "Figure out if the argument is a Lease object and the lease ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef client(host='localhost', port=2379,\n           ca_cert=None, cert_key=None, cert_cert=None, timeout=None,\n           user=None, password=None, grpc_options=None):\n    \"\"\"Return an instance of an Etcd3Client.\"\"\"\n    return Etcd3Client(host=host,\n                       port=port,\n                       ca_cert=ca_cert,\n                       cert_key=cert_key,\n                       cert_cert=cert_cert,\n                       timeout=timeout,\n                       user=user,\n                       password=password,\n                       grpc_options=grpc_options)", "response": "Return an instance of an Etcd3Client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the value of a key from etcd.", "response": "def get_response(self, key, serializable=False):\n        \"\"\"Get the value of a key from etcd.\"\"\"\n        range_request = self._build_get_range_request(\n            key,\n            serializable=serializable\n        )\n\n        return self.kvstub.Range(\n            range_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, key, **kwargs):\n        range_response = self.get_response(key, **kwargs)\n        if range_response.count < 1:\n            return None, None\n        else:\n            kv = range_response.kvs.pop()\n            return kv.value, KVMetadata(kv, range_response.header)", "response": "Get the value of a key from etcd."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_prefix_response(self, key_prefix, sort_order=None,\n                            sort_target='key', keys_only=False):\n        \"\"\"Get a range of keys with a prefix.\"\"\"\n        range_request = self._build_get_range_request(\n            key=key_prefix,\n            range_end=utils.increment_last_byte(utils.to_bytes(key_prefix)),\n            sort_order=sort_order,\n            sort_target=sort_target,\n            keys_only=keys_only,\n        )\n\n        return self.kvstub.Range(\n            range_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )", "response": "Get a range of keys with a prefix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a range of keys with a prefix.", "response": "def get_prefix(self, key_prefix, **kwargs):\n        \"\"\"\n        Get a range of keys with a prefix.\n\n        :param key_prefix: first key in range\n        :param keys_only: if True, retrieve only the keys, not the values\n\n        :returns: sequence of (value, metadata) tuples\n        \"\"\"\n        range_response = self.get_prefix_response(key_prefix, **kwargs)\n        for kv in range_response.kvs:\n            yield (kv.value, KVMetadata(kv, range_response.header))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a range of keys.", "response": "def get_range_response(self, range_start, range_end, sort_order=None,\n                           sort_target='key', **kwargs):\n        \"\"\"Get a range of keys.\"\"\"\n        range_request = self._build_get_range_request(\n            key=range_start,\n            range_end=range_end,\n            sort_order=sort_order,\n            sort_target=sort_target,\n            **kwargs\n        )\n\n        return self.kvstub.Range(\n            range_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a range of keys.", "response": "def get_range(self, range_start, range_end, **kwargs):\n        \"\"\"\n        Get a range of keys.\n\n        :param range_start: first key in range\n        :param range_end: last key in range\n        :returns: sequence of (value, metadata) tuples\n        \"\"\"\n        range_response = self.get_range_response(range_start, range_end,\n                                                 **kwargs)\n        for kv in range_response.kvs:\n            yield (kv.value, KVMetadata(kv, range_response.header))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_response(self, sort_order=None, sort_target='key',\n                         keys_only=False):\n        \"\"\"Get all keys currently stored in etcd.\"\"\"\n        range_request = self._build_get_range_request(\n            key=b'\\0',\n            range_end=b'\\0',\n            sort_order=sort_order,\n            sort_target=sort_target,\n            keys_only=keys_only,\n        )\n\n        return self.kvstub.Range(\n            range_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )", "response": "Get all keys currently stored in etcd."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all keys currently stored in etcd.", "response": "def get_all(self, **kwargs):\n        \"\"\"\n        Get all keys currently stored in etcd.\n\n        :param keys_only: if True, retrieve only the keys, not the values\n        :returns: sequence of (value, metadata) tuples\n        \"\"\"\n        range_response = self.get_all_response(**kwargs)\n        for kv in range_response.kvs:\n            yield (kv.value, KVMetadata(kv, range_response.header))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, key, value, lease=None, prev_kv=False):\n        put_request = self._build_put_request(key, value, lease=lease,\n                                              prev_kv=prev_kv)\n        return self.kvstub.Put(\n            put_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )", "response": "Saves a value to etcd."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a single key in etcd.", "response": "def delete(self, key, prev_kv=False, return_response=False):\n        \"\"\"\n        Delete a single key in etcd.\n\n        :param key: key in etcd to delete\n        :param prev_kv: return the deleted key-value pair\n        :type prev_kv: bool\n        :param return_response: return the full response\n        :type return_response: bool\n        :returns: True if the key has been deleted when\n                  ``return_response`` is False and a response containing\n                  a header, the number of deleted keys and prev_kvs when\n                  ``return_response`` is True\n        \"\"\"\n        delete_request = self._build_delete_request(key, prev_kv=prev_kv)\n        delete_response = self.kvstub.DeleteRange(\n            delete_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n        if return_response:\n            return delete_response\n        return delete_response.deleted >= 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_prefix(self, prefix):\n        delete_request = self._build_delete_request(\n            prefix,\n            range_end=utils.increment_last_byte(utils.to_bytes(prefix))\n        )\n        return self.kvstub.DeleteRange(\n            delete_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )", "response": "Delete a range of keys with a prefix in etcd."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef status(self):\n        status_request = etcdrpc.StatusRequest()\n        status_response = self.maintenancestub.Status(\n            status_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n\n        for m in self.members:\n            if m.id == status_response.leader:\n                leader = m\n                break\n        else:\n            # raise exception?\n            leader = None\n\n        return Status(status_response.version,\n                      status_response.dbSize,\n                      leader,\n                      status_response.raftIndex,\n                      status_response.raftTerm)", "response": "Get the status of the responding member."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_watch_callback(self, *args, **kwargs):\n        try:\n            return self.watcher.add_callback(*args, **kwargs)\n        except queue.Empty:\n            raise exceptions.WatchTimedOut()", "response": "Adds a callback to be called when a key or range of keys is added."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwatching a key. Example usage: .. code-block:: python events_iterator, cancel = etcd.watch('/doot/key') for event in events_iterator: print(event) :param key: key to watch :returns: tuple of ``events_iterator`` and ``cancel``. Use ``events_iterator`` to get the events of key changes and ``cancel`` to cancel the watch request", "response": "def watch(self, key, **kwargs):\n        \"\"\"\n        Watch a key.\n\n        Example usage:\n\n        .. code-block:: python\n            events_iterator, cancel = etcd.watch('/doot/key')\n            for event in events_iterator:\n                print(event)\n\n        :param key: key to watch\n\n        :returns: tuple of ``events_iterator`` and ``cancel``.\n                  Use ``events_iterator`` to get the events of key changes\n                  and ``cancel`` to cancel the watch request\n        \"\"\"\n        event_queue = queue.Queue()\n\n        def callback(event):\n            event_queue.put(event)\n\n        watch_id = self.add_watch_callback(key, callback, **kwargs)\n        canceled = threading.Event()\n\n        def cancel():\n            canceled.set()\n            event_queue.put(None)\n            self.cancel_watch(watch_id)\n\n        @_handle_errors\n        def iterator():\n            while not canceled.is_set():\n                event = event_queue.get()\n                if event is None:\n                    canceled.set()\n                if isinstance(event, Exception):\n                    canceled.set()\n                    raise event\n                if not canceled.is_set():\n                    yield event\n\n        return iterator(), cancel"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef watch_prefix(self, key_prefix, **kwargs):\n        kwargs['range_end'] = \\\n            utils.increment_last_byte(utils.to_bytes(key_prefix))\n        return self.watch(key_prefix, **kwargs)", "response": "Watches a range of keys with a prefix."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef watch_once(self, key, timeout=None, **kwargs):\n        event_queue = queue.Queue()\n\n        def callback(event):\n            event_queue.put(event)\n\n        watch_id = self.add_watch_callback(key, callback, **kwargs)\n\n        try:\n            return event_queue.get(timeout=timeout)\n        except queue.Empty:\n            raise exceptions.WatchTimedOut()\n        finally:\n            self.cancel_watch(watch_id)", "response": "Watch a key and stops after the first event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef watch_prefix_once(self, key_prefix, timeout=None, **kwargs):\n        kwargs['range_end'] = \\\n            utils.increment_last_byte(utils.to_bytes(key_prefix))\n        return self.watch_once(key_prefix, timeout=timeout, **kwargs)", "response": "Watches a range of keys with a prefix and stops after the first event."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ops_to_requests(self, ops):\n        request_ops = []\n        for op in ops:\n            if isinstance(op, transactions.Put):\n                request = self._build_put_request(op.key, op.value,\n                                                  op.lease, op.prev_kv)\n                request_op = etcdrpc.RequestOp(request_put=request)\n                request_ops.append(request_op)\n\n            elif isinstance(op, transactions.Get):\n                request = self._build_get_range_request(op.key, op.range_end)\n                request_op = etcdrpc.RequestOp(request_range=request)\n                request_ops.append(request_op)\n\n            elif isinstance(op, transactions.Delete):\n                request = self._build_delete_request(op.key, op.range_end,\n                                                     op.prev_kv)\n                request_op = etcdrpc.RequestOp(request_delete_range=request)\n                request_ops.append(request_op)\n\n            elif isinstance(op, transactions.Txn):\n                compare = [c.build_message() for c in op.compare]\n                success_ops = self._ops_to_requests(op.success)\n                failure_ops = self._ops_to_requests(op.failure)\n                request = etcdrpc.TxnRequest(compare=compare,\n                                             success=success_ops,\n                                             failure=failure_ops)\n                request_op = etcdrpc.RequestOp(request_txn=request)\n                request_ops.append(request_op)\n\n            else:\n                raise Exception(\n                    'Unknown request class {}'.format(op.__class__))\n        return request_ops", "response": "Converts an iterable of etcd3. transactions. Put Get Delete and Txn objects into a list of grpc requests."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a transaction. Example usage: .. code-block:: python etcd.transaction( compare=[ etcd.transactions.value('/doot/testing') == 'doot', etcd.transactions.version('/doot/testing') > 0, ], success=[ etcd.transactions.put('/doot/testing', 'success'), ], failure=[ etcd.transactions.put('/doot/testing', 'failure'), ] ) :param compare: A list of comparisons to make :param success: A list of operations to perform if all the comparisons are true :param failure: A list of operations to perform if any of the comparisons are false :return: A tuple of (operation status, responses)", "response": "def transaction(self, compare, success=None, failure=None):\n        \"\"\"\n        Perform a transaction.\n\n        Example usage:\n\n        .. code-block:: python\n\n            etcd.transaction(\n                compare=[\n                    etcd.transactions.value('/doot/testing') == 'doot',\n                    etcd.transactions.version('/doot/testing') > 0,\n                ],\n                success=[\n                    etcd.transactions.put('/doot/testing', 'success'),\n                ],\n                failure=[\n                    etcd.transactions.put('/doot/testing', 'failure'),\n                ]\n            )\n\n        :param compare: A list of comparisons to make\n        :param success: A list of operations to perform if all the comparisons\n                        are true\n        :param failure: A list of operations to perform if any of the\n                        comparisons are false\n        :return: A tuple of (operation status, responses)\n        \"\"\"\n        compare = [c.build_message() for c in compare]\n\n        success_ops = self._ops_to_requests(success)\n        failure_ops = self._ops_to_requests(failure)\n\n        transaction_request = etcdrpc.TxnRequest(compare=compare,\n                                                 success=success_ops,\n                                                 failure=failure_ops)\n        txn_response = self.kvstub.Txn(\n            transaction_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n\n        responses = []\n        for response in txn_response.responses:\n            response_type = response.WhichOneof('response')\n            if response_type in ['response_put', 'response_delete_range',\n                                 'response_txn']:\n                responses.append(response)\n\n            elif response_type == 'response_range':\n                range_kvs = []\n                for kv in response.response_range.kvs:\n                    range_kvs.append((kv.value,\n                                      KVMetadata(kv, txn_response.header)))\n\n                responses.append(range_kvs)\n\n        return txn_response.succeeded, responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new lease.", "response": "def lease(self, ttl, lease_id=None):\n        \"\"\"\n        Create a new lease.\n\n        All keys attached to this lease will be expired and deleted if the\n        lease expires. A lease can be sent keep alive messages to refresh the\n        ttl.\n\n        :param ttl: Requested time to live\n        :param lease_id: Requested ID for the lease\n\n        :returns: new lease\n        :rtype: :class:`.Lease`\n        \"\"\"\n        lease_grant_request = etcdrpc.LeaseGrantRequest(TTL=ttl, ID=lease_id)\n        lease_grant_response = self.leasestub.LeaseGrant(\n            lease_grant_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n        return leases.Lease(lease_id=lease_grant_response.ID,\n                            ttl=lease_grant_response.TTL,\n                            etcd_client=self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrevoke a lease. :param lease_id: ID of the lease to revoke.", "response": "def revoke_lease(self, lease_id):\n        \"\"\"\n        Revoke a lease.\n\n        :param lease_id: ID of the lease to revoke.\n        \"\"\"\n        lease_revoke_request = etcdrpc.LeaseRevokeRequest(ID=lease_id)\n        self.leasestub.LeaseRevoke(\n            lease_revoke_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new lock.", "response": "def lock(self, name, ttl=60):\n        \"\"\"\n        Create a new lock.\n\n        :param name: name of the lock\n        :type name: string or bytes\n        :param ttl: length of time for the lock to live for in seconds. The\n                    lock will be released after this time elapses, unless\n                    refreshed\n        :type ttl: int\n        :returns: new lock\n        :rtype: :class:`.Lock`\n        \"\"\"\n        return locks.Lock(name, ttl=ttl, etcd_client=self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a member into the cluster.", "response": "def add_member(self, urls):\n        \"\"\"\n        Add a member into the cluster.\n\n        :returns: new member\n        :rtype: :class:`.Member`\n        \"\"\"\n        member_add_request = etcdrpc.MemberAddRequest(peerURLs=urls)\n\n        member_add_response = self.clusterstub.MemberAdd(\n            member_add_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n\n        member = member_add_response.member\n        return etcd3.members.Member(member.ID,\n                                    member.name,\n                                    member.peerURLs,\n                                    member.clientURLs,\n                                    etcd_client=self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove an existing member from the cluster.", "response": "def remove_member(self, member_id):\n        \"\"\"\n        Remove an existing member from the cluster.\n\n        :param member_id: ID of the member to remove\n        \"\"\"\n        member_rm_request = etcdrpc.MemberRemoveRequest(ID=member_id)\n        self.clusterstub.MemberRemove(\n            member_rm_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the configuration of an existing member in the cluster.", "response": "def update_member(self, member_id, peer_urls):\n        \"\"\"\n        Update the configuration of an existing member in the cluster.\n\n        :param member_id: ID of the member to update\n        :param peer_urls: new list of peer urls the member will use to\n                          communicate with the cluster\n        \"\"\"\n        member_update_request = etcdrpc.MemberUpdateRequest(ID=member_id,\n                                                            peerURLs=peer_urls)\n        self.clusterstub.MemberUpdate(\n            member_update_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a generator that yields all members associated with the cluster.", "response": "def members(self):\n        \"\"\"\n        List of all members associated with the cluster.\n\n        :type: sequence of :class:`.Member`\n\n        \"\"\"\n        member_list_request = etcdrpc.MemberListRequest()\n        member_list_response = self.clusterstub.MemberList(\n            member_list_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n\n        for member in member_list_response.members:\n            yield etcd3.members.Member(member.ID,\n                                       member.name,\n                                       member.peerURLs,\n                                       member.clientURLs,\n                                       etcd_client=self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compact(self, revision, physical=False):\n        compact_request = etcdrpc.CompactionRequest(revision=revision,\n                                                    physical=physical)\n        self.kvstub.Compact(\n            compact_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )", "response": "Compact the event history up to a given revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef defragment(self):\n        defrag_request = etcdrpc.DefragmentRequest()\n        self.maintenancestub.Defragment(\n            defrag_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )", "response": "Defragment a member s backend database to recover storage space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the hash of the local KV state.", "response": "def hash(self):\n        \"\"\"\n        Return the hash of the local KV state.\n\n        :returns: kv state hash\n        :rtype: int\n        \"\"\"\n        hash_request = etcdrpc.HashRequest()\n        return self.maintenancestub.Hash(hash_request).hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an alarm. If no member id is given, the alarm is activated for all the members of the cluster. Only the `no space` alarm can be raised. :param member_id: The cluster member id to create an alarm to. If 0, the alarm is created for all the members of the cluster. :returns: list of :class:`.Alarm`", "response": "def create_alarm(self, member_id=0):\n        \"\"\"Create an alarm.\n\n        If no member id is given, the alarm is activated for all the\n        members of the cluster. Only the `no space` alarm can be raised.\n\n        :param member_id: The cluster member id to create an alarm to.\n                          If 0, the alarm is created for all the members\n                          of the cluster.\n        :returns: list of :class:`.Alarm`\n        \"\"\"\n        alarm_request = self._build_alarm_request('activate',\n                                                  member_id,\n                                                  'no space')\n        alarm_response = self.maintenancestub.Alarm(\n            alarm_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n\n        return [Alarm(alarm.alarm, alarm.memberID)\n                for alarm in alarm_response.alarms]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a snapshot of the database.", "response": "def snapshot(self, file_obj):\n        \"\"\"Take a snapshot of the database.\n\n        :param file_obj: A file-like object to write the database contents in.\n        \"\"\"\n        snapshot_request = etcdrpc.SnapshotRequest()\n        snapshot_response = self.maintenancestub.Snapshot(\n            snapshot_request,\n            self.timeout,\n            credentials=self.call_credentials,\n            metadata=self.metadata\n        )\n\n        for response in snapshot_response:\n            file_obj.write(response.blob)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_pixels(X):\n        if len(X.shape) != 4:\n            raise ValueError('Array of input images has to be a 4-dimensional array of shape'\n                             '[n_images, n_pixels_y, n_pixels_x, n_bands]')\n\n        new_shape = (X.shape[0] * X.shape[1] * X.shape[2], X.shape[3],)\n        pixels = X.reshape(new_shape)\n        return pixels", "response": "Extract pixels from array X"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_predict(self, X):\n\n        pixels = self.extract_pixels(X)\n\n        predictions = self.classifier.predict(pixels)\n\n        return predictions.reshape(X.shape[0], X.shape[1], X.shape[2])", "response": "Predicts class label for the entire image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npredicting class probabilities for the entire image.", "response": "def image_predict_proba(self, X):\n        \"\"\"\n        Predicts class probabilities for the entire image.\n\n        :param X: Array of images to be classified.\n        :type X: numpy array, shape = [n_images, n_pixels_y, n_pixels_x, n_bands]\n\n        :return: classification probability map\n        :rtype: numpy array, [n_samples, n_pixels_y, n_pixels_x]\n        \"\"\"\n\n        pixels = self.extract_pixels(X)\n\n        probabilities = self.classifier.predict_proba(pixels)\n\n        return probabilities.reshape(X.shape[0], X.shape[1], X.shape[2], probabilities.shape[1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the cloud detection on the input images and returns a numpy array of cloud probability maps.", "response": "def get_cloud_probability_maps(self, X):\n        \"\"\"\n        Runs the cloud detection on the input images (dimension n_images x n x m x 10\n        or n_images x n x m x 13) and returns an array of cloud probability maps (dimension\n        n_images x n x m). Pixel values close to 0 indicate clear-sky-like pixels, while\n        values close to 1 indicate pixels covered with clouds.\n\n        :param X: input Sentinel-2 image obtained with Sentinel-Hub's WMS/WCS request\n                  (see https://github.com/sentinel-hub/sentinelhub-py)\n        :type X: numpy array (shape n_images x n x m x 10 or n x m x 13)\n        :return: cloud probability map\n        :rtype: numpy array (shape n_images x n x m)\n        \"\"\"\n        band_num = X.shape[-1]\n        exp_bands = 13 if self.all_bands else len(self.BAND_IDXS)\n        if band_num != exp_bands:\n            raise ValueError(\"Parameter 'all_bands' is set to {}. Therefore expected band data with {} bands, \"\n                             \"got {} bands\".format(self.all_bands, exp_bands, band_num))\n\n        if self.all_bands:\n            X = X[..., self.BAND_IDXS]\n\n        return self.classifier.image_predict_proba(X)[..., 1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the cloud detection on the input images and returns the raster cloud mask.", "response": "def get_cloud_masks(self, X):\n        \"\"\"\n        Runs the cloud detection on the input images (dimension n_images x n x m x 10\n        or n_images x n x m x 13) and returns the raster cloud mask (dimension n_images x n x m).\n        Pixel values equal to 0 indicate pixels classified as clear-sky, while values\n        equal to 1 indicate pixels classified as clouds.\n\n        :param X: input Sentinel-2 image obtained with Sentinel-Hub's WMS/WCS request\n                  (see https://github.com/sentinel-hub/sentinelhub-py)\n        :type X: numpy array (shape n_images x n x m x 10 or n x m x 13)\n        :return: raster cloud mask\n        :rtype: numpy array (shape n_images x n x m)\n        \"\"\"\n\n        cloud_probs = self.get_cloud_probability_maps(X)\n\n        return self.get_mask_from_prob(cloud_probs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns raster cloud mask by applying morphological operations to input cloud probabilities.", "response": "def get_mask_from_prob(self, cloud_probs, threshold=None):\n        \"\"\"\n        Returns cloud mask by applying morphological operations -- convolution and dilation --\n        to input cloud probabilities.\n\n        :param cloud_probs: cloud probability map\n        :type cloud_probs: numpy array of cloud probabilities (shape n_images x n x m)\n        :param threshold: A float from [0,1] specifying threshold\n        :type threshold: float\n        :return: raster cloud mask\n        :rtype: numpy array (shape n_images x n x m)\n        \"\"\"\n        threshold = self.threshold if threshold is None else threshold\n\n        if self.average_over:\n            cloud_masks = np.asarray([convolve(cloud_prob, self.conv_filter) > threshold\n                                      for cloud_prob in cloud_probs], dtype=np.int8)\n        else:\n            cloud_masks = (cloud_probs > threshold).astype(np.int8)\n\n        if self.dilation_size:\n            cloud_masks = np.asarray([dilation(cloud_mask, self.dilation_filter) for cloud_mask in cloud_masks],\n                                     dtype=np.int8)\n\n        return cloud_masks"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads band data and valid mask. Sets self. bands self. valid_data self. valid_data", "response": "def _set_band_and_valid_mask(self):\n        \"\"\" Downloads band data and valid mask. Sets parameters self.bands, self.valid_data\n        \"\"\"\n        data = np.asarray(self.ogc_request.get_data())\n        self.bands = data[..., :-1]\n        self.valid_data = (data[..., -1] == 1.0).astype(np.bool)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting probability maps of areas for each available date.", "response": "def get_probability_masks(self, non_valid_value=0):\n        \"\"\"\n        Get probability maps of areas for each available date. The pixels without valid data are assigned\n        non_valid_value.\n\n        :param non_valid_value: Value to be assigned to non valid data pixels\n        :type non_valid_value: float\n        :return: Probability map of shape `(times, height, width)` and `dtype=numpy.float64`\n        :rtype: numpy.ndarray\n        \"\"\"\n        if self.probability_masks is None:\n            self.get_data()\n            self.probability_masks = self.cloud_detector.get_cloud_probability_maps(self.bands)\n\n        self.probability_masks[~self.valid_data] = non_valid_value\n        return self.probability_masks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the binary cloud mask of the image with the given probability.", "response": "def get_cloud_masks(self, threshold=None, non_valid_value=False):\n        \"\"\" The binary cloud mask is computed on the fly. Be cautious. The pixels without valid data are assigned\n        non_valid_value.\n\n        :param threshold: A float from [0,1] specifying threshold\n        :type threshold: float\n        :param non_valid_value: Value which will be assigned to pixels without valid data\n        :type non_valid_value: int in range `[-254, 255]`\n        :return: Binary cloud masks of shape `(times, height, width)` and `dtype=numpy.int8`\n        :rtype: numpy.ndarray\n        \"\"\"\n        self.get_probability_masks()\n\n        cloud_masks = self.cloud_detector.get_mask_from_prob(self.probability_masks, threshold)\n        cloud_masks[~self.valid_data] = non_valid_value\n\n        return cloud_masks"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an authentication request.", "response": "def create_authn_request(self, destination, vorg=\"\", scoping=None,\n            binding=saml2.BINDING_HTTP_POST,\n            nameid_format=None,\n            service_url_binding=None, message_id=0,\n            consent=None, extensions=None, sign=None,\n            allow_create=None, sign_prepare=False, sign_alg=None,\n            digest_alg=None, **kwargs):\n        \"\"\" Creates an authentication request.\n\n        :param destination: Where the request should be sent.\n        :param vorg: The virtual organization the service belongs to.\n        :param scoping: The scope of the request\n        :param binding: The protocol to use for the Response !!\n        :param nameid_format: Format of the NameID\n        :param service_url_binding: Where the reply should be sent dependent\n            on reply binding.\n        :param message_id: The identifier for this request\n        :param consent: Whether the principal have given her consent\n        :param extensions: Possible extensions\n        :param sign: Whether the request should be signed or not.\n        :param sign_prepare: Whether the signature should be prepared or not.\n        :param allow_create: If the identity provider is allowed, in the course\n            of fulfilling the request, to create a new identifier to represent\n            the principal.\n        :param kwargs: Extra key word arguments\n        :return: either a tuple of request ID and <samlp:AuthnRequest> instance\n                 or a tuple of request ID and str when sign is set to True\n        \"\"\"\n        client_crt = None\n        if \"client_crt\" in kwargs:\n            client_crt = kwargs[\"client_crt\"]\n\n        args = {}\n\n        if self.config.getattr('hide_assertion_consumer_service', 'sp'):\n            args[\"assertion_consumer_service_url\"] = None\n            binding = None\n        else:\n            try:\n                args[\"assertion_consumer_service_url\"] = kwargs[\n                    \"assertion_consumer_service_urls\"][0]\n                del kwargs[\"assertion_consumer_service_urls\"]\n            except KeyError:\n                try:\n                    args[\"assertion_consumer_service_url\"] = kwargs[\n                        \"assertion_consumer_service_url\"]\n                    del kwargs[\"assertion_consumer_service_url\"]\n                except KeyError:\n                    try:\n                        args[\"assertion_consumer_service_index\"] = str(\n                            kwargs[\"assertion_consumer_service_index\"])\n                        del kwargs[\"assertion_consumer_service_index\"]\n                    except KeyError:\n                        if service_url_binding is None:\n                            service_urls = self.service_urls(binding)\n                        else:\n                            service_urls = self.service_urls(service_url_binding)\n                        args[\"assertion_consumer_service_url\"] = service_urls[0]\n\n        try:\n            args[\"provider_name\"] = kwargs[\"provider_name\"]\n        except KeyError:\n            if binding == BINDING_PAOS:\n                pass\n            else:\n                args[\"provider_name\"] = self._my_name()\n\n        # Allow argument values either as class instances or as dictionaries\n        # all of these have cardinality 0..1\n        _msg = AuthnRequest()\n        for param in [\"scoping\", \"requested_authn_context\", \"conditions\",\n                      \"subject\"]:\n            try:\n                _item = kwargs[param]\n            except KeyError:\n                pass\n            else:\n                del kwargs[param]\n                # either class instance or argument dictionary\n                if isinstance(_item, _msg.child_class(param)):\n                    args[param] = _item\n                elif isinstance(_item, dict):\n                    args[param] = RequestedAuthnContext(**_item)\n                else:\n                    raise ValueError(\"%s or wrong type expected %s\" % (_item,\n                                                                       param))\n\n        try:\n            args[\"name_id_policy\"] = kwargs[\"name_id_policy\"]\n            del kwargs[\"name_id_policy\"]\n        except KeyError:\n            if allow_create is None:\n                allow_create = self.config.getattr(\"name_id_format_allow_create\", \"sp\")\n                if allow_create is None:\n                    allow_create = \"false\"\n                else:\n                    if allow_create is True:\n                        allow_create = \"true\"\n                    else:\n                        allow_create = \"false\"\n\n            if nameid_format == \"\":\n                name_id_policy = None\n            else:\n                if nameid_format is None:\n                    nameid_format = self.config.getattr(\"name_id_format\", \"sp\")\n\n                    # If no nameid_format has been set in the configuration\n                    # or passed in then transient is the default.\n                    if nameid_format is None:\n                        nameid_format = NAMEID_FORMAT_TRANSIENT\n\n                    # If a list has been configured or passed in choose the\n                    # first since NameIDPolicy can only have one format specified.\n                    elif isinstance(nameid_format, list):\n                        nameid_format = nameid_format[0]\n\n                    # Allow a deployer to signal that no format should be specified\n                    # in the NameIDPolicy by passing in or configuring the string 'None'.\n                    elif nameid_format == 'None':\n                        nameid_format = None\n\n                name_id_policy = samlp.NameIDPolicy(allow_create=allow_create,\n                                                    format=nameid_format)\n\n            if name_id_policy and vorg:\n                try:\n                    name_id_policy.sp_name_qualifier = vorg\n                    name_id_policy.format = saml.NAMEID_FORMAT_PERSISTENT\n                except KeyError:\n                    pass\n            args[\"name_id_policy\"] = name_id_policy\n\n        try:\n            nsprefix = kwargs[\"nsprefix\"]\n        except KeyError:\n            nsprefix = None\n\n        try:\n            force_authn = kwargs['force_authn']\n        except KeyError:\n            force_authn = self.config.getattr('force_authn', 'sp')\n        finally:\n            if force_authn:\n                args['force_authn'] = 'true'\n\n        conf_sp_type = self.config.getattr('sp_type', 'sp')\n        conf_sp_type_in_md = self.config.getattr('sp_type_in_metadata', 'sp')\n        if conf_sp_type and conf_sp_type_in_md is False:\n            if not extensions:\n                extensions = Extensions()\n            item = sp_type.SPType(text=conf_sp_type)\n            extensions.add_extension_element(item)\n\n        requested_attrs = self.config.getattr('requested_attributes', 'sp')\n        if requested_attrs:\n            if not extensions:\n                extensions = Extensions()\n\n            attributemapsmods = []\n            for modname in attributemaps.__all__:\n                attributemapsmods.append(getattr(attributemaps, modname))\n\n            items = []\n            for attr in requested_attrs:\n                friendly_name = attr.get('friendly_name')\n                name = attr.get('name')\n                name_format = attr.get('name_format')\n                is_required = str(attr.get('required', False)).lower()\n\n                if not name and not friendly_name:\n                    raise ValueError(\n                        \"Missing required attribute: '{}' or '{}'\".format(\n                            'name', 'friendly_name'))\n\n                if not name:\n                    for mod in attributemapsmods:\n                        try:\n                            name = mod.MAP['to'][friendly_name]\n                        except KeyError:\n                            continue\n                        else:\n                            if not name_format:\n                                name_format = mod.MAP['identifier']\n                            break\n\n                if not friendly_name:\n                    for mod in attributemapsmods:\n                        try:\n                            friendly_name = mod.MAP['fro'][name]\n                        except KeyError:\n                            continue\n                        else:\n                            if not name_format:\n                                name_format = mod.MAP['identifier']\n                            break\n\n                items.append(requested_attributes.RequestedAttribute(\n                    is_required=is_required,\n                    name_format=name_format,\n                    friendly_name=friendly_name,\n                    name=name))\n\n            item = requested_attributes.RequestedAttributes(\n                extension_elements=items)\n            extensions.add_extension_element(item)\n\n        if kwargs:\n            _args, extensions = self._filter_args(AuthnRequest(), extensions,\n                                                  **kwargs)\n            args.update(_args)\n\n        try:\n            del args[\"id\"]\n        except KeyError:\n            pass\n\n        if sign is None:\n            sign = self.authn_requests_signed\n\n        if (sign and self.sec.cert_handler.generate_cert()) or \\\n                        client_crt is not None:\n            with self.lock:\n                self.sec.cert_handler.update_cert(True, client_crt)\n                if client_crt is not None:\n                    sign_prepare = True\n                return self._message(AuthnRequest, destination, message_id,\n                                     consent, extensions, sign, sign_prepare,\n                                     protocol_binding=binding,\n                                     scoping=scoping, nsprefix=nsprefix,\n                                     sign_alg=sign_alg, digest_alg=digest_alg,\n                                     **args)\n        return self._message(AuthnRequest, destination, message_id, consent,\n                             extensions, sign, sign_prepare,\n                             protocol_binding=binding,\n                             scoping=scoping, nsprefix=nsprefix,\n                             sign_alg=sign_alg, digest_alg=digest_alg, **args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_attribute_query(self, destination, name_id=None,\n            attribute=None, message_id=0, consent=None,\n            extensions=None, sign=False, sign_prepare=False, sign_alg=None,\n            digest_alg=None,\n            **kwargs):\n        \"\"\" Constructs an AttributeQuery\n\n        :param destination: To whom the query should be sent\n        :param name_id: The identifier of the subject\n        :param attribute: A dictionary of attributes and values that is\n            asked for. The key are one of 4 variants:\n            3-tuple of name_format,name and friendly_name,\n            2-tuple of name_format and name,\n            1-tuple with name or\n            just the name as a string.\n        :param sp_name_qualifier: The unique identifier of the\n            service provider or affiliation of providers for whom the\n            identifier was generated.\n        :param name_qualifier: The unique identifier of the identity\n            provider that generated the identifier.\n        :param format: The format of the name ID\n        :param message_id: The identifier of the session\n        :param consent: Whether the principal have given her consent\n        :param extensions: Possible extensions\n        :param sign: Whether the query should be signed or not.\n        :param sign_prepare: Whether the Signature element should be added.\n        :return: Tuple of request ID and an AttributeQuery instance\n        \"\"\"\n\n        if name_id is None:\n            if \"subject_id\" in kwargs:\n                name_id = saml.NameID(text=kwargs[\"subject_id\"])\n                for key in [\"sp_name_qualifier\", \"name_qualifier\",\n                            \"format\"]:\n                    try:\n                        setattr(name_id, key, kwargs[key])\n                    except KeyError:\n                        pass\n            else:\n                raise AttributeError(\"Missing required parameter\")\n        elif isinstance(name_id, six.string_types):\n            name_id = saml.NameID(text=name_id)\n            for key in [\"sp_name_qualifier\", \"name_qualifier\", \"format\"]:\n                try:\n                    setattr(name_id, key, kwargs[key])\n                except KeyError:\n                    pass\n\n        subject = saml.Subject(name_id=name_id)\n\n        if attribute:\n            attribute = do_attributes(attribute)\n\n        try:\n            nsprefix = kwargs[\"nsprefix\"]\n        except KeyError:\n            nsprefix = None\n\n        return self._message(AttributeQuery, destination, message_id, consent,\n                             extensions, sign, sign_prepare, subject=subject,\n                             attribute=attribute, nsprefix=nsprefix,\n                             sign_alg=sign_alg, digest_alg=digest_alg)", "response": "Creates an AttributeQuery instance for the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_authz_decision_query(self, destination, action,\n            evidence=None, resource=None, subject=None,\n            message_id=0, consent=None, extensions=None,\n            sign=None, sign_alg=None, digest_alg=None, **kwargs):\n        \"\"\" Creates an authz decision query.\n\n        :param destination: The IdP endpoint\n        :param action: The action you want to perform (has to be at least one)\n        :param evidence: Why you should be able to perform the action\n        :param resource: The resource you want to perform the action on\n        :param subject: Who wants to do the thing\n        :param message_id: Message identifier\n        :param consent: If the principal gave her consent to this request\n        :param extensions: Possible request extensions\n        :param sign: Whether the request should be signed or not.\n        :return: AuthzDecisionQuery instance\n        \"\"\"\n\n        return self._message(AuthzDecisionQuery, destination, message_id,\n                             consent, extensions, sign, action=action,\n                             evidence=evidence, resource=resource,\n                             subject=subject, sign_alg=sign_alg,\n                             digest_alg=digest_alg, **kwargs)", "response": "Creates an authz decision query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an authz decision query based on an Assertion instance.", "response": "def create_authz_decision_query_using_assertion(self, destination,\n            assertion, action=None,\n            resource=None,\n            subject=None, message_id=0,\n            consent=None,\n            extensions=None,\n            sign=False, nsprefix=None):\n        \"\"\" Makes an authz decision query based on a previously received\n        Assertion.\n\n        :param destination: The IdP endpoint to send the request to\n        :param assertion: An Assertion instance\n        :param action: The action you want to perform (has to be at least one)\n        :param resource: The resource you want to perform the action on\n        :param subject: Who wants to do the thing\n        :param message_id: Message identifier\n        :param consent: If the principal gave her consent to this request\n        :param extensions: Possible request extensions\n        :param sign: Whether the request should be signed or not.\n        :return: AuthzDecisionQuery instance\n        \"\"\"\n\n        if action:\n            if isinstance(action, six.string_types):\n                _action = [saml.Action(text=action)]\n            else:\n                _action = [saml.Action(text=a) for a in action]\n        else:\n            _action = None\n\n        return self.create_authz_decision_query(\n                destination, _action, saml.Evidence(assertion=assertion),\n                resource, subject, message_id=message_id, consent=consent,\n                extensions=extensions, sign=sign, nsprefix=nsprefix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndealing with an AuthnRequestResponse.", "response": "def parse_authn_request_response(self, xmlstr, binding, outstanding=None,\n                                     outstanding_certs=None, conv_info=None):\n        \"\"\" Deal with an AuthnResponse\n\n        :param xmlstr: The reply as a xml string\n        :param binding: Which binding that was used for the transport\n        :param outstanding: A dictionary with session IDs as keys and\n            the original web request from the user before redirection\n            as values.\n        :param outstanding_certs:\n        :param conv_info: Information about the conversation.\n        :return: An response.AuthnResponse or None\n        \"\"\"\n\n        if not getattr(self.config, 'entityid', None):\n            raise SAMLError(\"Missing entity_id specification\")\n\n        if not xmlstr:\n            return None\n\n        kwargs = {\n            \"outstanding_queries\": outstanding,\n            \"outstanding_certs\": outstanding_certs,\n            \"allow_unsolicited\": self.allow_unsolicited,\n            \"want_assertions_signed\": self.want_assertions_signed,\n            \"want_assertions_or_response_signed\": self.want_assertions_or_response_signed,\n            \"want_response_signed\": self.want_response_signed,\n            \"return_addrs\": self.service_urls(binding=binding),\n            \"entity_id\": self.config.entityid,\n            \"attribute_converters\": self.config.attribute_converters,\n            \"allow_unknown_attributes\":\n                self.config.allow_unknown_attributes,\n            'conv_info': conv_info\n        }\n\n        try:\n            resp = self._parse_response(xmlstr, AuthnResponse,\n                                        \"assertion_consumer_service\",\n                                        binding, **kwargs)\n        except StatusError as err:\n            logger.error(\"SAML status error: %s\", err)\n            raise\n        except UnravelError:\n            return None\n        except Exception as err:\n            logger.error(\"XML parse error: %s\", err)\n            raise\n\n        if not isinstance(resp, AuthnResponse):\n            logger.error(\"Response type not supported: %s\",\n                         saml2.class_name(resp))\n            return None\n\n        if (resp.assertion and len(resp.response.encrypted_assertion) == 0 and\n                resp.assertion.subject.name_id):\n            self.users.add_information_about_person(resp.session_info())\n            logger.info(\"--- ADDED person info ----\")\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the response from an authorization decision query", "response": "def parse_authz_decision_query_response(self, response,\n            binding=BINDING_SOAP):\n        \"\"\" Verify that the response is OK\n        \"\"\"\n        kwargs = {\"entity_id\": self.config.entityid,\n                  \"attribute_converters\": self.config.attribute_converters}\n\n        return self._parse_response(response, AuthzResponse, \"\", binding,\n                                    **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the response from the AuthnQueryRequest", "response": "def parse_authn_query_response(self, response, binding=BINDING_SOAP):\n        \"\"\" Verify that the response is OK\n        \"\"\"\n        kwargs = {\"entity_id\": self.config.entityid,\n                  \"attribute_converters\": self.config.attribute_converters}\n\n        return self._parse_response(response, AuthnQueryResponse, \"\", binding,\n                                    **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the AssertionIDResponse from the server", "response": "def parse_assertion_id_request_response(self, response, binding):\n        \"\"\" Verify that the response is OK\n        \"\"\"\n        kwargs = {\"entity_id\": self.config.entityid,\n                  \"attribute_converters\": self.config.attribute_converters}\n\n        res = self._parse_response(response, AssertionIDResponse, \"\", binding,\n                                   **kwargs)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an authentication request for the specified entity.", "response": "def create_ecp_authn_request(self, entityid=None, relay_state=\"\",\n            sign=False, **kwargs):\n        \"\"\" Makes an authentication request.\n\n        :param entityid: The entity ID of the IdP to send the request to\n        :param relay_state: A token that can be used by the SP to know\n            where to continue the conversation with the client\n        :param sign: Whether the request should be signed or not.\n        :return: SOAP message with the AuthnRequest\n        \"\"\"\n\n        # ----------------------------------------\n        # <paos:Request>\n        # ----------------------------------------\n        my_url = self.service_urls(BINDING_PAOS)[0]\n\n        # must_understand and act according to the standard\n        #\n        paos_request = paos.Request(must_understand=\"1\", actor=ACTOR,\n                                    response_consumer_url=my_url,\n                                    service=ECP_SERVICE)\n\n        # ----------------------------------------\n        # <ecp:RelayState>\n        # ----------------------------------------\n\n        relay_state = ecp.RelayState(actor=ACTOR, must_understand=\"1\",\n                                     text=relay_state)\n\n        # ----------------------------------------\n        # <samlp:AuthnRequest>\n        # ----------------------------------------\n\n        try:\n            authn_req = kwargs[\"authn_req\"]\n            try:\n                req_id = authn_req.id\n            except AttributeError:\n                req_id = 0  # Unknown but since it's SOAP it doesn't matter\n        except KeyError:\n            try:\n                _binding = kwargs[\"binding\"]\n            except KeyError:\n                _binding = BINDING_SOAP\n                kwargs[\"binding\"] = _binding\n\n            logger.debug(\"entityid: %s, binding: %s\", entityid, _binding)\n\n            # The IDP publishes support for ECP by using the SOAP binding on\n            # SingleSignOnService\n            _, location = self.pick_binding(\"single_sign_on_service\",\n                                            [_binding], entity_id=entityid)\n            req_id, authn_req = self.create_authn_request(\n                    location, service_url_binding=BINDING_PAOS, **kwargs)\n\n        # ----------------------------------------\n        # The SOAP envelope\n        # ----------------------------------------\n\n        soap_envelope = make_soap_enveloped_saml_thingy(authn_req,\n                                                        [paos_request,\n                                                         relay_state])\n\n        return req_id, \"%s\" % soap_envelope"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the HTTP request URL needed to send the user to the discovery service.", "response": "def create_discovery_service_request(url, entity_id, **kwargs):\n        \"\"\"\n        Created the HTTP redirect URL needed to send the user to the\n        discovery service.\n\n        :param url: The URL of the discovery service\n        :param entity_id: The unique identifier of the service provider\n        :param return: The discovery service MUST redirect the user agent\n            to this location in response to this request\n        :param policy: A parameter name used to indicate the desired behavior\n            controlling the processing of the discovery service\n        :param returnIDParam: A parameter name used to return the unique\n            identifier of the selected identity provider to the original\n            requester.\n        :param isPassive: A boolean value True/False that controls\n            whether the discovery service is allowed to visibly interact with\n            the user agent.\n        :return: A URL\n        \"\"\"\n\n        args = {\"entityID\": entity_id}\n        for key in [\"policy\", \"returnIDParam\"]:\n            try:\n                args[key] = kwargs[key]\n            except KeyError:\n                pass\n\n        try:\n            args[\"return\"] = kwargs[\"return_url\"]\n        except KeyError:\n            try:\n                args[\"return\"] = kwargs[\"return\"]\n            except KeyError:\n                pass\n\n        if \"isPassive\" in kwargs:\n            if kwargs[\"isPassive\"]:\n                args[\"isPassive\"] = \"true\"\n            else:\n                args[\"isPassive\"] = \"false\"\n\n        params = urlencode(args)\n        return \"%s?%s\" % (url, params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_discovery_service_response(url=\"\", query=\"\",\n            returnIDParam=\"entityID\"):\n        \"\"\"\n        Deal with the response url from a Discovery Service\n\n        :param url: the url the user was redirected back to or\n        :param query: just the query part of the URL.\n        :param returnIDParam: This is where the identifier of the IdP is\n            place if it was specified in the query. Default is 'entityID'\n        :return: The IdP identifier or \"\" if none was given\n        \"\"\"\n\n        if url:\n            part = urlparse(url)\n            qsd = parse_qs(part[4])\n        elif query:\n            qsd = parse_qs(query)\n        else:\n            qsd = {}\n\n        try:\n            return qsd[returnIDParam][0]\n        except KeyError:\n            return \"\"", "response": "Deal with the response url from a Discovery Service and return the IdP identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _filter_values(vals, vlist=None, must=False):\n\n    if not vlist:  # No value specified equals any value\n        return vals\n\n    if isinstance(vlist, six.string_types):\n        vlist = [vlist]\n\n    res = []\n\n    for val in vlist:\n        if val in vals:\n            res.append(val)\n\n    if must:\n        if res:\n            return res\n        else:\n            raise MissingValue(\"Required attribute value missing\")\n    else:\n        return res", "response": "Removes values from vals that do not appear in vlist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering the attribute value assertion as a dictionary of RequestedAttribute instances.", "response": "def filter_on_attributes(ava, required=None, optional=None, acs=None,\n                         fail_on_unfulfilled_requirements=True):\n    \"\"\" Filter\n\n    :param ava: An attribute value assertion as a dictionary\n    :param required: list of RequestedAttribute instances defined to be\n        required\n    :param optional: list of RequestedAttribute instances defined to be\n        optional\n    :param fail_on_unfulfilled_requirements: If required attributes\n        are missing fail or fail not depending on this parameter.\n    :return: The modified attribute value assertion\n    \"\"\"\n\n    def _match_attr_name(attr, ava):\n        local_name = None\n\n        for a in ['name_format', 'friendly_name']:\n            _val = attr.get(a)\n            if _val:\n                if a == 'name_format':\n                    local_name = get_local_name(acs, attr['name'], _val)\n                else:\n                    local_name = _val\n                break\n\n        if local_name:\n            _fn = _match(local_name, ava)\n        else:\n            _fn = None\n\n        if not _fn:  # In the unlikely case that someone has provided us with\n            #  URIs as attribute names\n            _fn = _match(attr[\"name\"], ava)\n\n        return _fn\n\n\n    def _apply_attr_value_restrictions(attr, res, must=False):\n        try:\n            values = [av[\"text\"] for av in attr[\"attribute_value\"]]\n        except KeyError:\n            values = []\n\n        try:\n            res[_fn].extend(_filter_values(ava[_fn], values))\n        except KeyError:\n            res[_fn] = _filter_values(ava[_fn], values)\n\n        return _filter_values(ava[_fn], values, must)\n\n    res = {}\n    if required is None:\n        required = []\n\n    for attr in required:\n        _fn = _match_attr_name(attr, ava)\n\n        if _fn:\n            _apply_attr_value_restrictions(attr, res, True)\n        elif fail_on_unfulfilled_requirements:\n            desc = \"Required attribute missing: '%s'\" % (attr[\"name\"])\n            raise MissingValue(desc)\n\n    if optional is None:\n        optional = []\n\n    for attr in optional:\n        _fn = _match_attr_name(attr, ava)\n        if _fn:\n            _apply_attr_value_restrictions(attr, res, False)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter out all attributes that are not required on demand.", "response": "def filter_on_demands(ava, required=None, optional=None):\n    \"\"\" Never return more than is needed. Filters out everything\n    the server is prepared to return but the receiver doesn't ask for\n\n    :param ava: Attribute value assertion as a dictionary\n    :param required: Required attributes\n    :param optional: Optional attributes\n    :return: The possibly reduced assertion\n    \"\"\"\n\n    # Is all what's required there:\n    if required is None:\n        required = {}\n\n    lava = dict([(k.lower(), k) for k in ava.keys()])\n\n    for attr, vals in required.items():\n        attr = attr.lower()\n        if attr in lava:\n            if vals:\n                for val in vals:\n                    if val not in ava[lava[attr]]:\n                        raise MissingValue(\n                            \"Required attribute value missing: %s,%s\" % (attr,\n                                                                         val))\n        else:\n            raise MissingValue(\"Required attribute missing: %s\" % (attr,))\n\n    if optional is None:\n        optional = {}\n\n    oka = [k.lower() for k in required.keys()]\n    oka.extend([k.lower() for k in optional.keys()])\n\n    # OK, so I can imaging releasing values that are not absolutely necessary\n    # but not attributes that are not asked for.\n    for attr in lava.keys():\n        if attr not in oka:\n            del ava[lava[attr]]\n\n    return ava"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter out attributes and values from wire representation.", "response": "def filter_on_wire_representation(ava, acs, required=None, optional=None):\n    \"\"\"\n    :param ava: A dictionary with attributes and values\n    :param acs: List of tuples (Attribute Converter name,\n        Attribute Converter instance)\n    :param required: A list of saml.Attributes\n    :param optional: A list of saml.Attributes\n    :return: Dictionary of expected/wanted attributes and values\n    \"\"\"\n    acsdic = dict([(ac.name_format, ac) for ac in acs])\n\n    if required is None:\n        required = []\n    if optional is None:\n        optional = []\n\n    res = {}\n    for attr, val in ava.items():\n        done = False\n        for req in required:\n            try:\n                _name = acsdic[req.name_format]._to[attr]\n                if _name == req.name:\n                    res[attr] = val\n                    done = True\n            except KeyError:\n                pass\n        if done:\n            continue\n        for opt in optional:\n            try:\n                _name = acsdic[opt.name_format]._to[attr]\n                if _name == opt.name:\n                    res[attr] = val\n                    break\n            except KeyError:\n                pass\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_attribute_value_assertions(ava, attribute_restrictions=None):\n    if not attribute_restrictions:\n        return ava\n\n    for attr, vals in list(ava.items()):\n        _attr = attr.lower()\n        try:\n            _rests = attribute_restrictions[_attr]\n        except KeyError:\n            del ava[attr]\n        else:\n            if _rests is None:\n                continue\n            if isinstance(vals, six.string_types):\n                vals = [vals]\n            rvals = []\n            for restr in _rests:\n                for val in vals:\n                    if restr.match(val):\n                        rvals.append(val)\n\n            if rvals:\n                ava[attr] = list(set(rvals))\n            else:\n                del ava[attr]\n    return ava", "response": "Filter the attribute value assertions based on the rules defined in attribute_restrictions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _authn_context_class_ref(authn_class, authn_auth=None):\n    cntx_class = factory(saml.AuthnContextClassRef, text=authn_class)\n    if authn_auth:\n        return factory(saml.AuthnContext,\n                       authn_context_class_ref=cntx_class,\n                       authenticating_authority=factory(\n                           saml.AuthenticatingAuthority, text=authn_auth))\n    else:\n        return factory(saml.AuthnContext,\n                       authn_context_class_ref=cntx_class)", "response": "Construct an AuthnContext instance with a authn context class reference"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _authn_context_decl(decl, authn_auth=None):\n    return factory(saml.AuthnContext,\n                   authn_context_decl=decl,\n                   authenticating_authority=factory(\n                       saml.AuthenticatingAuthority, text=authn_auth))", "response": "Construct an AuthnContext instance with a authn context declaration"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing an AuthnContext instance with a authn context declaration reference", "response": "def _authn_context_decl_ref(decl_ref, authn_auth=None):\n    \"\"\"\n    Construct the authn context with a authn context declaration reference\n    :param decl_ref: The authn context declaration reference\n    :param authn_auth: Authenticating Authority\n    :return: An AuthnContext instance\n    \"\"\"\n    return factory(saml.AuthnContext,\n                   authn_context_decl_ref=decl_ref,\n                   authenticating_authority=factory(\n                       saml.AuthenticatingAuthority, text=authn_auth))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authn_statement(authn_class=None, authn_auth=None,\n                    authn_decl=None, authn_decl_ref=None, authn_instant=\"\",\n                    subject_locality=\"\", session_not_on_or_after=None):\n    \"\"\"\n    Construct the AuthnStatement\n    :param authn_class: Authentication Context Class reference\n    :param authn_auth: Authenticating Authority\n    :param authn_decl: Authentication Context Declaration\n    :param authn_decl_ref: Authentication Context Declaration reference\n    :param authn_instant: When the Authentication was performed.\n        Assumed to be seconds since the Epoch.\n    :param subject_locality: Specifies the DNS domain name and IP address\n        for the system from which the assertion subject was apparently\n        authenticated.\n    :return: An AuthnContext instance\n    \"\"\"\n    if authn_instant:\n        _instant = instant(time_stamp=authn_instant)\n    else:\n        _instant = instant()\n\n    if authn_class:\n        res = factory(\n            saml.AuthnStatement,\n            authn_instant=_instant,\n            session_index=sid(),\n            session_not_on_or_after=session_not_on_or_after,\n            authn_context=_authn_context_class_ref(\n                authn_class, authn_auth))\n    elif authn_decl:\n        res = factory(\n            saml.AuthnStatement,\n            authn_instant=_instant,\n            session_index=sid(),\n            session_not_on_or_after=session_not_on_or_after,\n            authn_context=_authn_context_decl(authn_decl, authn_auth))\n    elif authn_decl_ref:\n        res = factory(\n            saml.AuthnStatement,\n            authn_instant=_instant,\n            session_index=sid(),\n            session_not_on_or_after=session_not_on_or_after,\n            authn_context=_authn_context_decl_ref(authn_decl_ref,\n                                                  authn_auth))\n    else:\n        res = factory(\n            saml.AuthnStatement,\n            authn_instant=_instant,\n            session_index=sid(),\n            session_not_on_or_after=session_not_on_or_after)\n\n    if subject_locality:\n        res.subject_locality = saml.SubjectLocality(text=subject_locality)\n\n    return res", "response": "Constructs an AuthnStatement object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter(self, ava, sp_entity_id, mdstore, required=None, optional=None):\n\n        _ava = None\n\n        if not self.acs:  # acs MUST have a value, fall back to default.\n            self.acs = ac_factory()\n\n        _rest = self.get_entity_categories(sp_entity_id, mdstore, required)\n        if _rest:\n            _ava = filter_attribute_value_assertions(ava.copy(), _rest)\n        elif required or optional:\n            logger.debug(\"required: %s, optional: %s\", required, optional)\n            _ava = filter_on_attributes(\n                ava.copy(), required, optional, self.acs,\n                self.get_fail_on_missing_requested(sp_entity_id))\n\n        _rest = self.get_attribute_restrictions(sp_entity_id)\n        if _rest:\n            if _ava is None:\n                _ava = ava.copy()\n            _ava = filter_attribute_value_assertions(_ava, _rest)\n        elif _ava is None:\n            _ava = ava.copy()\n\n        if _ava is None:\n            return {}\n        else:\n            return _ava", "response": "Filter the attributes of an attribute and attribute value dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a saml. Conditions instance for the given SP entity ID.", "response": "def conditions(self, sp_entity_id):\n        \"\"\" Return a saml.Condition instance\n\n        :param sp_entity_id: The SP entity ID\n        :return: A saml.Condition instance\n        \"\"\"\n        return factory(saml.Conditions,\n                       not_before=instant(),\n                       # How long might depend on who's getting it\n                       not_on_or_after=self.not_on_or_after(sp_entity_id),\n                       audience_restriction=[factory(\n                           saml.AudienceRestriction,\n                           audience=[factory(saml.Audience,\n                                             text=sp_entity_id)])])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct an Assertion instance based on the attributes of the Assertion.", "response": "def construct(self, sp_entity_id, attrconvs, policy, issuer, farg,\n                  authn_class=None, authn_auth=None, authn_decl=None,\n                  encrypt=None, sec_context=None, authn_decl_ref=None,\n                  authn_instant=\"\", subject_locality=\"\", authn_statem=None,\n                  name_id=None, session_not_on_or_after=None):\n        \"\"\" Construct the Assertion\n\n        :param sp_entity_id: The entityid of the SP\n        :param in_response_to: An identifier of the message, this message is\n            a response to\n        :param name_id: An NameID instance\n        :param attrconvs: AttributeConverters\n        :param policy: The policy that should be adhered to when replying\n        :param issuer: Who is issuing the statement\n        :param authn_class: The authentication class\n        :param authn_auth: The authentication instance\n        :param authn_decl: An Authentication Context declaration\n        :param encrypt: Whether to encrypt parts or all of the Assertion\n        :param sec_context: The security context used when encrypting\n        :param authn_decl_ref: An Authentication Context declaration reference\n        :param authn_instant: When the Authentication was performed\n        :param subject_locality: Specifies the DNS domain name and IP address\n            for the system from which the assertion subject was apparently\n            authenticated.\n        :param authn_statem: A AuthnStatement instance\n        :return: An Assertion instance\n        \"\"\"\n\n        if policy:\n            _name_format = policy.get_name_form(sp_entity_id)\n        else:\n            _name_format = NAME_FORMAT_URI\n\n        attr_statement = saml.AttributeStatement(attribute=from_local(\n            attrconvs, self, _name_format))\n\n        if encrypt == \"attributes\":\n            for attr in attr_statement.attribute:\n                enc = sec_context.encrypt(text=\"%s\" % attr)\n\n                encd = xmlenc.encrypted_data_from_string(enc)\n                encattr = saml.EncryptedAttribute(encrypted_data=encd)\n                attr_statement.encrypted_attribute.append(encattr)\n\n            attr_statement.attribute = []\n\n        # start using now and for some time\n        conds = policy.conditions(sp_entity_id)\n\n        if authn_statem:\n            _authn_statement = authn_statem\n        elif authn_auth or authn_class or authn_decl or authn_decl_ref:\n            _authn_statement = authn_statement(authn_class, authn_auth,\n                                               authn_decl, authn_decl_ref,\n                                               authn_instant,\n                                               subject_locality,\n                                               session_not_on_or_after=session_not_on_or_after)\n        else:\n            _authn_statement = None\n\n        subject = do_subject(policy, sp_entity_id, name_id,\n                             **farg['subject'])\n\n        _ass = assertion_factory(issuer=issuer, conditions=conds,\n                                 subject=subject)\n\n        if _authn_statement:\n            _ass.authn_statement = [_authn_statement]\n\n        if not attr_statement.empty():\n            _ass.attribute_statement = [attr_statement]\n\n        return _ass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_policy(self, sp_entity_id, policy, metadata=None):\n\n        policy.acs = self.acs\n        ava = policy.restrict(self, sp_entity_id, metadata)\n\n        for key, val in list(self.items()):\n            if key in ava:\n                self[key] = ava[key]\n            else:\n                del self[key]\n\n        return ava", "response": "Applies the policy to the assertion I m representing\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ecp_auth_request(cls, entityid=None, relay_state=\"\", sign=False):\n\n    eelist = []\n\n    # ----------------------------------------\n    # <paos:Request>\n    # ----------------------------------------\n    my_url = cls.service_urls(BINDING_PAOS)[0]\n\n    # must_understand and actor according to the standard\n    #\n    paos_request = paos.Request(must_understand=\"1\", actor=ACTOR,\n                                response_consumer_url=my_url,\n                                service=SERVICE)\n\n    eelist.append(element_to_extension_element(paos_request))\n\n    # ----------------------------------------\n    # <samlp:AuthnRequest>\n    # ----------------------------------------\n\n    logger.info(\"entityid: %s, binding: %s\" % (entityid, BINDING_SOAP))\n\n    location = cls._sso_location(entityid, binding=BINDING_SOAP)\n    req_id, authn_req = cls.create_authn_request(\n        location, binding=BINDING_PAOS, service_url_binding=BINDING_PAOS)\n\n    body = soapenv.Body()\n    body.extension_elements = [element_to_extension_element(authn_req)]\n\n    # ----------------------------------------\n    # <ecp:Request>\n    # ----------------------------------------\n\n#        idp = samlp.IDPEntry(\n#            provider_id = \"https://idp.example.org/entity\",\n#            name = \"Example identity provider\",\n#            loc = \"https://idp.example.org/saml2/sso\",\n#            )\n#\n#        idp_list = samlp.IDPList(idp_entry= [idp])\n\n    idp_list = None\n    ecp_request = ecp.Request(\n        actor=ACTOR,\n        must_understand=\"1\",\n        provider_name=None,\n        issuer=saml.Issuer(text=authn_req.issuer.text),\n        idp_list=idp_list)\n\n    eelist.append(element_to_extension_element(ecp_request))\n\n    # ----------------------------------------\n    # <ecp:RelayState>\n    # ----------------------------------------\n\n    relay_state = ecp.RelayState(actor=ACTOR, must_understand=\"1\",\n                                 text=relay_state)\n\n    eelist.append(element_to_extension_element(relay_state))\n\n    header = soapenv.Header()\n    header.extension_elements = eelist\n\n    # ----------------------------------------\n    # The SOAP envelope\n    # ----------------------------------------\n\n    soap_envelope = soapenv.Envelope(header=header, body=body)\n\n    return req_id, \"%s\" % soap_envelope", "response": "Makes an authentication request to the IdP."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_static(environ, start_response, path):\n    try:\n        data = open(path, \"rb\").read()\n        if path.endswith(\".ico\"):\n            resp = Response(data, headers=[(\"Content-Type\", \"image/x-icon\")])\n        elif path.endswith(\".html\"):\n            resp = Response(data, headers=[(\"Content-Type\", \"text/html\")])\n        elif path.endswith(\".txt\"):\n            resp = Response(data, headers=[(\"Content-Type\", \"text/plain\")])\n        elif path.endswith(\".css\"):\n            resp = Response(data, headers=[(\"Content-Type\", \"text/css\")])\n        elif path.endswith(\".js\"):\n            resp = Response(data, headers=[(\"Content-Type\", \"text/javascript\")])\n        elif path.endswith(\".png\"):\n            resp = Response(data, headers=[(\"Content-Type\", \"image/png\")])\n        else:\n            resp = Response(data)\n    except IOError:\n        resp = NotFound()\n    return resp(environ, start_response)", "response": "Handles a static file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the SOAP data for this session.", "response": "def soap(self):\n        \"\"\"\n        Single log out using HTTP_SOAP binding\n        \"\"\"\n        logger.debug(\"- SOAP -\")\n        _dict = self.unpack_soap()\n        logger.debug(\"_dict: %s\", _dict)\n        return self.operation(_dict, BINDING_SOAP)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do(self, response, binding, relay_state=\"\", mtype=\"response\"):\n        # tmp_outstanding_queries = dict(self.outstanding_queries)\n        if not response:\n            logger.info(\"Missing Response\")\n            resp = Unauthorized(\"Unknown user\")\n            return resp(self.environ, self.start_response)\n\n        try:\n            conv_info = {\n                \"remote_addr\": self.environ[\"REMOTE_ADDR\"],\n                \"request_uri\": self.environ[\"REQUEST_URI\"],\n                \"entity_id\": self.sp.config.entityid,\n                \"endpoints\": self.sp.config.getattr(\"endpoints\", \"sp\"),\n            }\n\n            self.response = self.sp.parse_authn_request_response(\n                response,\n                binding,\n                self.outstanding_queries,\n                self.cache.outstanding_certs,\n                conv_info=conv_info,\n            )\n        except UnknownPrincipal as excp:\n            logger.error(\"UnknownPrincipal: %s\", excp)\n            resp = ServiceError(\"UnknownPrincipal: %s\" % (excp,))\n            return resp(self.environ, self.start_response)\n        except UnsupportedBinding as excp:\n            logger.error(\"UnsupportedBinding: %s\", excp)\n            resp = ServiceError(\"UnsupportedBinding: %s\" % (excp,))\n            return resp(self.environ, self.start_response)\n        except VerificationError as err:\n            resp = ServiceError(\"Verification error: %s\" % (err,))\n            return resp(self.environ, self.start_response)\n        except SignatureError as err:\n            resp = ServiceError(\"Signature error: %s\" % (err,))\n            return resp(self.environ, self.start_response)\n        except Exception as err:\n            resp = ServiceError(\"Other error: %s\" % (err,))\n            return resp(self.environ, self.start_response)\n\n        logger.info(\"AVA: %s\", self.response.ava)\n\n        user = User(self.response.name_id, self.response.ava, self.response)\n        cookie = self.cache.set_cookie(user)\n\n        resp = Redirect(\"/\", headers=[cookie])\n        return resp(self.environ, self.start_response)", "response": "This method is called by the SAML2 server when the response is received from the SAML server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pick_idp(self, came_from):\n\n        _cli = self.sp\n\n        logger.debug(\"[_pick_idp] %s\", self.environ)\n        if \"HTTP_PAOS\" in self.environ:\n            if self.environ[\"HTTP_PAOS\"] == PAOS_HEADER_INFO:\n                if MIME_PAOS in self.environ[\"HTTP_ACCEPT\"]:\n                    # Where should I redirect the user to\n                    # entityid -> the IdP to use\n                    # relay_state -> when back from authentication\n\n                    logger.debug(\"- ECP client detected -\")\n\n                    _rstate = rndstr()\n                    self.cache.relay_state[_rstate] = geturl(self.environ)\n                    _entityid = _cli.config.ecp_endpoint(self.environ[\"REMOTE_ADDR\"])\n\n                    if not _entityid:\n                        return -1, ServiceError(\"No IdP to talk to\")\n                    logger.debug(\"IdP to talk to: %s\", _entityid)\n                    return ecp.ecp_auth_request(_cli, _entityid, _rstate)\n                else:\n                    return -1, ServiceError(\"Faulty Accept header\")\n            else:\n                return -1, ServiceError(\"unknown ECP version\")\n\n        # Find all IdPs\n        idps = self.sp.metadata.with_descriptor(\"idpsso\")\n\n        idp_entity_id = None\n\n        kaka = self.environ.get(\"HTTP_COOKIE\", \"\")\n        if kaka:\n            try:\n                (idp_entity_id, _) = parse_cookie(\"ve_disco\", \"SEED_SAW\", kaka)\n            except ValueError:\n                pass\n            except TypeError:\n                pass\n\n        # Any specific IdP specified in a query part\n        query = self.environ.get(\"QUERY_STRING\")\n        if not idp_entity_id and query:\n            try:\n                _idp_entity_id = dict(parse_qs(query))[self.idp_query_param][0]\n                if _idp_entity_id in idps:\n                    idp_entity_id = _idp_entity_id\n            except KeyError:\n                logger.debug(\"No IdP entity ID in query: %s\", query)\n                pass\n\n        if not idp_entity_id:\n\n            if self.wayf:\n                if query:\n                    try:\n                        wayf_selected = dict(parse_qs(query))[\"wayf_selected\"][0]\n                    except KeyError:\n                        return self._wayf_redirect(came_from)\n                    idp_entity_id = wayf_selected\n                else:\n                    return self._wayf_redirect(came_from)\n            elif self.discosrv:\n                if query:\n                    idp_entity_id = _cli.parse_discovery_service_response(\n                        query=self.environ.get(\"QUERY_STRING\")\n                    )\n                if not idp_entity_id:\n                    sid_ = sid()\n                    self.cache.outstanding_queries[sid_] = came_from\n                    logger.debug(\"Redirect to Discovery Service function\")\n                    eid = _cli.config.entityid\n                    ret = _cli.config.getattr(\"endpoints\", \"sp\")[\"discovery_response\"][\n                        0\n                    ][0]\n                    ret += \"?sid=%s\" % sid_\n                    loc = _cli.create_discovery_service_request(\n                        self.discosrv, eid, **{\"return\": ret}\n                    )\n                    return -1, SeeOther(loc)\n            elif len(idps) == 1:\n                # idps is a dictionary\n                idp_entity_id = list(idps.keys())[0]\n            elif not len(idps):\n                return -1, ServiceError(\"Misconfiguration\")\n            else:\n                return -1, NotImplemented(\"No WAYF or DS present!\")\n\n        logger.info(\"Chosen IdP: '%s'\", idp_entity_id)\n        return 0, idp_entity_id", "response": "Picks an IdP from the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef valid_any_uri(item):\n    try:\n        part = urlparse(item)\n    except Exception:\n        raise NotValid(\"AnyURI\")\n\n    if part[0] == \"urn\" and part[1] == \"\":  # A urn\n        return True\n    # elif part[1] == \"localhost\" or part[1] == \"127.0.0.1\":\n    #     raise NotValid(\"AnyURI\")\n\n    return True", "response": "valid_any_uri - Check if the given item is a valid Any URI"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valid_string(val):\n    for char in val:\n        try:\n            char = ord(char)\n        except TypeError:\n            raise NotValid(\"string\")\n        if char == 0x09 or char == 0x0A or char == 0x0D:\n            continue\n        elif 0x20 <= char <= 0xD7FF:\n            continue\n        elif 0xE000 <= char <= 0xFFFD:\n            continue\n        elif 0x10000 <= char <= 0x10FFFF:\n            continue\n        else:\n            raise NotValid(\"string\")\n    return True", "response": "Expects unicode\n    Char ::= #x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD] |\n                    [#x10000-#x10FFFF]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef valid_anytype(val):\n    for validator in VALIDATOR.values():\n        if validator == valid_anytype:  # To hinder recursion\n            continue\n        try:\n            if validator(val):\n                return True\n        except NotValid:\n            pass\n\n    if isinstance(val, type):\n        return True\n\n    raise NotValid(\"AnyType\")", "response": "Checks if the value is valid for any type of item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_value_type(value, spec):\n    if \"maxlen\" in spec:\n        return len(value) <= int(spec[\"maxlen\"])\n\n    if spec[\"base\"] == \"string\":\n        if \"enumeration\" in spec:\n            if value not in spec[\"enumeration\"]:\n                raise NotValid(\"value not in enumeration\")\n        else:\n            return valid_string(value)\n    elif spec[\"base\"] == \"list\":  # comma separated list of values\n        for val in [v.strip() for v in value.split(\",\")]:\n            valid(spec[\"member\"], val)\n    else:\n        return valid(spec[\"base\"], value)\n\n    return True", "response": "Validate that value is of type spec."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_maps(dirspec):\n    mapd = {}\n    if dirspec not in sys.path:\n        sys.path.insert(0, dirspec)\n\n    for fil in os.listdir(dirspec):\n        if fil.endswith(\".py\"):\n            mod = import_module(fil[:-3])\n            for key, item in mod.__dict__.items():\n                if key.startswith(\"__\"):\n                    continue\n                if isinstance(item, dict) and \"to\" in item and \"fro\" in item:\n                    mapd[item[\"identifier\"]] = item\n\n    return mapd", "response": "load the attribute maps\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ac_factory(path=\"\"):\n    acs = []\n\n    if path:\n        if path not in sys.path:\n            sys.path.insert(0, path)\n\n        for fil in os.listdir(path):\n            if fil.endswith(\".py\"):\n                mod = import_module(fil[:-3])\n                for key, item in mod.__dict__.items():\n                    if key.startswith(\"__\"):\n                        continue\n                    if isinstance(item,\n                                  dict) and \"to\" in item and \"fro\" in item:\n                        atco = AttributeConverter(item[\"identifier\"])\n                        atco.from_dict(item)\n                        acs.append(atco)\n    else:\n        from saml2 import attributemaps\n\n        for typ in attributemaps.__all__:\n            mod = import_module(\".%s\" % typ, \"saml2.attributemaps\")\n            for key, item in mod.__dict__.items():\n                if key.startswith(\"__\"):\n                    continue\n                if isinstance(item, dict) and \"to\" in item and \"fro\" in item:\n                    atco = AttributeConverter(item[\"identifier\"])\n                    atco.from_dict(item)\n                    acs.append(atco)\n\n    return acs", "response": "A factory function that creates an attribute converter for the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing the attribute names in a attribute value assertion with the corresponding name from a local name format.", "response": "def to_local(acs, statement, allow_unknown_attributes=False):\n    \"\"\" Replaces the attribute names in a attribute value assertion with the\n    equivalent name from a local name format.\n\n    :param acs: List of Attribute Converters\n    :param statement: The Attribute Statement\n    :param allow_unknown_attributes: If unknown attributes are allowed\n    :return: A key,values dictionary\n    \"\"\"\n    return list_to_local(acs, statement.attribute, allow_unknown_attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_to_local(acs, attrlist, allow_unknown_attributes=False):\n    if not acs:\n        acs = [AttributeConverter()]\n        acsd = {\"\": acs}\n    else:\n        acsd = dict([(a.name_format, a) for a in acs])\n\n    ava = {}\n    for attr in attrlist:\n        try:\n            _func = acsd[attr.name_format].ava_from\n        except KeyError:\n            if attr.name_format == NAME_FORMAT_UNSPECIFIED or \\\n                    allow_unknown_attributes:\n                _func = acs[0].lcd_ava_from\n            else:\n                logger.info(\"Unsupported attribute name format: %s\",\n                    attr.name_format)\n                continue\n\n        try:\n            key, val = _func(attr)\n        except KeyError:\n            if allow_unknown_attributes:\n                key, val = acs[0].lcd_ava_from(attr)\n            else:\n                logger.info(\"Unknown attribute name: %s\", attr)\n                continue\n        except AttributeError:\n            continue\n\n        try:\n            ava[key].extend(val)\n        except KeyError:\n            ava[key] = val\n\n    return ava", "response": "Replaces the attribute names in a attribute value assertion with the equivalent name from a local name format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_local_name(acs, attr, name_format):\n    for aconv in acs:\n        #print(ac.format, name_format)\n        if aconv.name_format == name_format:\n            #print(\"Found a name_form converter\")\n            return aconv.to_format(attr)\n    return attr", "response": "Convert an attribute name from local name to specified name - format"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the given attribute instance to the local name.", "response": "def to_local_name(acs, attr):\n    \"\"\"\n    :param acs: List of AttributeConverter instances\n    :param attr: an Attribute instance\n    :return: The local attribute name\n    \"\"\"\n    for aconv in acs:\n        lattr = aconv.from_format(attr)\n        if lattr:\n            return lattr\n\n    return attr.friendly_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef d_to_local_name(acs, attr):\n    for aconv in acs:\n        lattr = aconv.d_from_format(attr)\n        if lattr:\n            return lattr\n\n    # if everything else fails this might be good enough\n    try:\n        return attr[\"friendly_name\"]\n    except KeyError:\n        raise ConverterError(\"Could not find local name for %s\" % attr)", "response": "Convert the attribute dictionary to the local name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadjust the internal state of the object to match the one in the original image.", "response": "def adjust(self):\n        \"\"\" If one of the transformations is not defined it is expected to\n        be the mirror image of the other.\n        \"\"\"\n\n        if self._fro is None and self._to is not None:\n            self._fro = dict(\n                [(value.lower(), key) for key, value in self._to.items()])\n        if self._to is None and self._fro is not None:\n            self._to = dict(\n                [(value.lower(), key) for key, value in self._fro.items()])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dict(self, mapdict):\n\n        self.name_format = mapdict[\"identifier\"]\n        try:\n            self._fro = dict(\n                [(k.lower(), v) for k, v in mapdict[\"fro\"].items()])\n        except KeyError:\n            pass\n        try:\n            self._to = dict([(k.lower(), v) for k, v in mapdict[\"to\"].items()])\n        except KeyError:\n            pass\n\n        if self._fro is None and self._to is None:\n            raise ConverterError(\"Missing specifications\")\n\n        if self._fro is None or self._to is None:\n            self.adjust()", "response": "Import the attribute map from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lcd_ava_from(self, attribute):\n        name = attribute.name.strip()\n        values = [\n            (value.text or '').strip()\n            for value in attribute.attribute_value]\n        return name, values", "response": "This function returns the name and values of the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the attributes and values from the attribute statement.", "response": "def fro(self, statement):\n        \"\"\" Get the attributes and the attribute values.\n\n        :param statement: The AttributeStatement.\n        :return: A dictionary containing attributes and values\n        \"\"\"\n\n        if not self.name_format:\n            return self.fail_safe_fro(statement)\n\n        result = {}\n        for attribute in statement.attribute:\n            if attribute.name_format and self.name_format and \\\n                    attribute.name_format != self.name_format:\n                continue\n\n            try:\n                (key, val) = self.ava_from(attribute)\n            except (KeyError, AttributeError):\n                pass\n            else:\n                result[key] = val\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_format(self, attr):\n        try:\n            _attr = self._to[attr]\n        except KeyError:\n            try:\n                _attr = self._to[attr.lower()]\n            except:\n                _attr = ''\n\n        if _attr:\n            return factory(saml.Attribute,\n                           name=_attr,\n                           name_format=self.name_format,\n                           friendly_name=attr)\n        else:\n            return factory(saml.Attribute, name=attr)", "response": "Creates an Attribute instance with name name_format and friendly_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds out the local name of an attribute from the name format", "response": "def from_format(self, attr):\n        \"\"\" Find out the local name of an attribute\n\n        :param attr: An saml.Attribute instance\n        :return: The local attribute name or \"\" if no mapping could be made\n        \"\"\"\n        if attr.name_format:\n            if self.name_format == attr.name_format:\n                try:\n                    return self._fro[attr.name.lower()]\n                except KeyError:\n                    pass\n        else:  # don't know the name format so try all I have\n            try:\n                return self._fro[attr.name.lower()]\n            except KeyError:\n                pass\n\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds out the local name of an attribute in the specified format.", "response": "def d_from_format(self, attr):\n        \"\"\" Find out the local name of an attribute\n\n        :param attr: An Attribute dictionary\n        :return: The local attribute name or \"\" if no mapping could be made\n        \"\"\"\n        if attr[\"name_format\"]:\n            if self.name_format == attr[\"name_format\"]:\n                try:\n                    return self._fro[attr[\"name\"].lower()]\n                except KeyError:\n                    pass\n        else:  # don't know the name format so try all I have\n            try:\n                return self._fro[attr[\"name\"].lower()]\n            except KeyError:\n                pass\n\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_(self, attrvals):\n        attributes = []\n        for key, value in attrvals.items():\n            name = self._to.get(key.lower())\n            if name:\n                if name == \"urn:oid:1.3.6.1.4.1.5923.1.1.1.10\":\n                    # special case for eduPersonTargetedID\n                    attr_value = []\n                    for v in value:\n                        extension_element = ExtensionElement(\"NameID\", NAMESPACE,\n                                                             attributes={'Format': NAMEID_FORMAT_PERSISTENT}, text=v)\n                        attrval = saml.AttributeValue(extension_elements=[extension_element])\n                        attr_value.append(attrval)\n                else:\n                    attr_value = do_ava(value)\n                attributes.append(factory(saml.Attribute,\n                                          name=name,\n                                          name_format=self.name_format,\n                                          friendly_name=key,\n                                          attribute_value=attr_value))\n            else:\n                attributes.append(factory(saml.Attribute,\n                                          name=key,\n                                          attribute_value=do_ava(value)))\n\n        return attributes", "response": "Create a list of Attribute instances."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a list of Attribute instances.", "response": "def to_(self, attrvals):\n        \"\"\" Create a list of Attribute instances.\n\n        :param attrvals: A dictionary of attributes and values\n        :return: A list of Attribute instances\n        \"\"\"\n        attributes = []\n        for key, value in attrvals.items():\n            key = key.lower()\n            attributes.append(factory(saml.Attribute,\n                                      name=key,\n                                      name_format=self.name_format,\n                                      attribute_value=do_ava(value)))\n\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads the metadata file from the remote location and store it into the local location.", "response": "def fetch_metadata(url, path, maxage=600):\n    \"\"\"\n    :param url:  metadata remote location\n    :param path: metdata file name\n    :param maxage: if max age of existing metadata file (s) is exceeded,\n     the file will be fetched from the remote location\n    \"\"\"\n    fetch = False\n    if not os.path.isfile(path):\n        fetch = True\n        logger.debug(\"metadata file %s not found\", path)\n    elif (os.path.getmtime(path) + maxage) < time.time():\n        fetch = True\n        logger.debug(\"metadata file %s from %s is more than %s s old\",\n                     path,\n                     strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(os.path.getmtime(path))),\n                     maxage)\n    else:\n        logger.debug(\"metadata file %s is less than %s s old\", path, maxage)\n    if fetch:\n        f=urllib.URLopener()\n        try:\n            f.retrieve(url, path)\n            logger.debug(\"downloaded metadata from %s into %s\", url, path)\n        except:\n            logger.debug(\"downloaded metadata from %s failed: %s\",\n                         url, sys.exc_info()[0])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning one of the classifiersdav xmlpost or browser depending on the imperative logic below.", "response": "def my_request_classifier(environ):\n    \"\"\" Returns one of the classifiers 'dav', 'xmlpost', or 'browser',\n    depending on the imperative logic below\"\"\"\n    request_method = REQUEST_METHOD(environ)\n    if request_method in _DAV_METHODS:\n        return \"dav\"\n    useragent = USER_AGENT(environ)\n    if useragent:\n        for agent in _DAV_USERAGENTS:\n            if useragent.find(agent) != -1:\n                return \"dav\"\n    if request_method == \"POST\":\n        if CONTENT_TYPE(environ) == \"text/xml\":\n            return \"xmlpost\"\n        elif CONTENT_TYPE(environ) == \"application/soap+xml\":\n            return \"soap\"\n    return \"browser\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _localized_name(val, klass):\n    try:\n        (text, lang) = val\n        return klass(text=text, lang=lang)\n    except ValueError:\n        return klass(text=val, lang=\"en\")", "response": "Return the name of the given language."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the organization information for the given organization.", "response": "def do_organization_info(ava):\n    \"\"\"\n    Description of an organization in the configuration is\n    a dictionary of keys and values, where the values might be tuples::\n\n        \"organization\": {\n            \"name\": (\"AB Exempel\", \"se\"),\n            \"display_name\": (\"AB Exempel\", \"se\"),\n            \"url\": \"http://www.example.org\"\n        }\n\n    \"\"\"\n\n    if ava is None:\n        return None\n\n    org = md.Organization()\n    for dkey, (ckey, klass) in ORG_ATTR_TRANSL.items():\n        if ckey not in ava:\n            continue\n        if isinstance(ava[ckey], six.string_types):\n            setattr(org, dkey, [_localized_name(ava[ckey], klass)])\n        elif isinstance(ava[ckey], list):\n            setattr(org, dkey,\n                    [_localized_name(n, klass) for n in ava[ckey]])\n        else:\n            setattr(org, dkey, [_localized_name(ava[ckey], klass)])\n    return org"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a ContactPerson instance from configuration information.", "response": "def do_contact_person_info(ava):\n    \"\"\"Create a ContactPerson instance from configuration information.\"\"\"\n    cper = md.ContactPerson()\n    cper.loadd(ava)\n    if not cper.contact_type:\n        cper.contact_type = \"technical\"\n    return cper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a Policy Decision Point descriptor.", "response": "def do_pdp_descriptor(conf, cert=None, enc_cert=None):\n    \"\"\" Create a Policy Decision Point descriptor \"\"\"\n    pdp = md.PDPDescriptor()\n\n    pdp.protocol_support_enumeration = samlp.NAMESPACE\n\n    endps = conf.getattr(\"endpoints\", \"pdp\")\n\n    if endps:\n        for (endpoint, instlist) in do_endpoints(endps,\n                                                 ENDPOINTS[\"pdp\"]).items():\n            setattr(pdp, endpoint, instlist)\n\n    _do_nameid_format(pdp, conf, \"pdp\")\n\n    if cert:\n        pdp.key_descriptor = do_key_descriptor(cert, enc_cert,\n                                               use=conf.metadata_key_usage)\n\n    return pdp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a base URL which may contain a query string plus extra parameters.", "response": "def create_return_url(base, query, **kwargs):\n    \"\"\"\n    Add a query string plus extra parameters to a base URL which may contain\n    a query part already.\n\n    :param base: redirect_uri may contain a query part, no fragment allowed.\n    :param query: Old query part as a string\n    :param kwargs: extra query parameters\n    :return:\n    \"\"\"\n    part = urlsplit(base)\n    if part.fragment:\n        raise ValueError(\"Base URL contained parts it shouldn't\")\n\n    for key, values in parse_qs(query).items():\n        if key in kwargs:\n            if isinstance(kwargs[key], six.string_types):\n                kwargs[key] = [kwargs[key]]\n            kwargs[key].extend(values)\n        else:\n            kwargs[key] = values\n\n    if part.query:\n        for key, values in parse_qs(part.query).items():\n            if key in kwargs:\n                if isinstance(kwargs[key], six.string_types):\n                    kwargs[key] = [kwargs[key]]\n                kwargs[key].extend(values)\n            else:\n                kwargs[key] = values\n\n        _pre = base.split(\"?\")[0]\n    else:\n        _pre = base\n\n    logger.debug(\"kwargs: %s\" % kwargs)\n\n    return \"%s?%s\" % (_pre, url_encode_params(kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify(self, request, **kwargs):\n\n        #logger.debug(\"verify(%s)\" % request)\n        if isinstance(request, six.string_types):\n            _dict = parse_qs(request)\n        elif isinstance(request, dict):\n            _dict = request\n        else:\n            raise ValueError(\"Wrong type of input\")\n\n        # verify username and password\n        try:\n            self._verify(_dict[\"password\"][0], _dict[\"login\"][0])\n            timestamp = str(int(time.mktime(time.gmtime())))\n            msg = \"::\".join([_dict[\"login\"][0], timestamp])\n            info = self.symmetric.encrypt(msg.encode())\n            self.active[info] = timestamp\n            cookie = make_cookie(self.cookie_name, info, self.srv.seed)\n            return_to = create_return_url(self.return_to, _dict[\"query\"][0],\n                                          **{self.query_param: \"true\"})\n            resp = Redirect(return_to, headers=[cookie])\n        except (ValueError, KeyError):\n            resp = Unauthorized(\"Unknown user or wrong password\")\n\n        return resp", "response": "Verify that the username and password was correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_artifact(entity_id, message_handle, endpoint_index=0):\n    if not isinstance(entity_id, six.binary_type):\n        entity_id = entity_id.encode('utf-8')\n    sourceid = sha1(entity_id)\n\n    if not isinstance(message_handle, six.binary_type):\n        message_handle = message_handle.encode('utf-8')\n    ter = b\"\".join((ARTIFACT_TYPECODE,\n                    (\"%.2x\" % endpoint_index).encode('ascii'),\n                    sourceid.digest(),\n                    message_handle))\n    return base64.b64encode(ter).decode('ascii')", "response": "Creates an artifact from the given entity id and message handle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an Issuer instance", "response": "def _issuer(self, entityid=None):\n        \"\"\" Return an Issuer instance \"\"\"\n        if entityid:\n            if isinstance(entityid, Issuer):\n                return entityid\n            else:\n                return Issuer(text=entityid, format=NAMEID_FORMAT_ENTITY)\n        else:\n            return Issuer(text=self.config.entityid,\n                          format=NAMEID_FORMAT_ENTITY)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_binding(self, binding, msg_str, destination=\"\", relay_state=\"\",\n                      response=False, sign=False, **kwargs):\n        \"\"\"\n        Construct the necessary HTTP arguments dependent on Binding\n\n        :param binding: Which binding to use\n        :param msg_str: The return message as a string (XML) if the message is\n            to be signed it MUST contain the signature element.\n        :param destination: Where to send the message\n        :param relay_state: Relay_state if provided\n        :param response: Which type of message this is\n        :param kwargs: response type specific arguments\n        :return: A dictionary\n        \"\"\"\n        # unless if BINDING_HTTP_ARTIFACT\n        if response:\n            typ = \"SAMLResponse\"\n        else:\n            typ = \"SAMLRequest\"\n\n        if binding == BINDING_HTTP_POST:\n            logger.info(\"HTTP POST\")\n            # if self.entity_type == 'sp':\n            #     info = self.use_http_post(msg_str, destination, relay_state,\n            #                               typ)\n            #     info[\"url\"] = destination\n            #     info[\"method\"] = \"POST\"\n            # else:\n            info = self.use_http_form_post(msg_str, destination,\n                                           relay_state, typ)\n            info[\"url\"] = destination\n            info[\"method\"] = \"POST\"\n        elif binding == BINDING_HTTP_REDIRECT:\n            logger.info(\"HTTP REDIRECT\")\n            sigalg = kwargs.get(\"sigalg\")\n            if sign and sigalg:\n                signer = self.sec.sec_backend.get_signer(sigalg)\n            else:\n                signer = None\n            info = self.use_http_get(msg_str, destination, relay_state, typ,\n                                     signer=signer, **kwargs)\n            info[\"url\"] = str(destination)\n            info[\"method\"] = \"GET\"\n        elif binding == BINDING_SOAP or binding == BINDING_PAOS:\n            info = self.use_soap(msg_str, destination, sign=sign, **kwargs)\n        elif binding == BINDING_URI:\n            info = self.use_http_uri(msg_str, typ, destination)\n        elif binding == BINDING_HTTP_ARTIFACT:\n            if response:\n                info = self.use_http_artifact(msg_str, destination, relay_state)\n                info[\"method\"] = \"GET\"\n                info[\"status\"] = 302\n            else:\n                info = self.use_http_artifact(msg_str, destination, relay_state)\n        else:\n            raise SAMLError(\"Unknown binding type: %s\" % binding)\n\n        return info", "response": "Applies the HTTP and HTTP arguments depending on the binding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunravel the text from the server into the original version of the user s identity.", "response": "def unravel(txt, binding, msgtype=\"response\"):\n        \"\"\"\n        Will unpack the received text. Depending on the context the original\n         response may have been transformed before transmission.\n        :param txt:\n        :param binding:\n        :param msgtype:\n        :return:\n        \"\"\"\n        # logger.debug(\"unravel '%s'\", txt)\n        if binding not in [BINDING_HTTP_REDIRECT, BINDING_HTTP_POST,\n                           BINDING_SOAP, BINDING_URI, BINDING_HTTP_ARTIFACT,\n                           None]:\n            raise UnknownBinding(\"Don't know how to handle '%s'\" % binding)\n        else:\n            try:\n                if binding == BINDING_HTTP_REDIRECT:\n                    xmlstr = decode_base64_and_inflate(txt)\n                elif binding == BINDING_HTTP_POST:\n                    xmlstr = base64.b64decode(txt)\n                elif binding == BINDING_SOAP:\n                    func = getattr(soap,\n                                   \"parse_soap_enveloped_saml_%s\" % msgtype)\n                    xmlstr = func(txt)\n                elif binding == BINDING_HTTP_ARTIFACT:\n                    xmlstr = base64.b64decode(txt)\n                else:\n                    xmlstr = txt\n            except Exception:\n                raise UnravelError(\"Unravelling binding '%s' failed\" % binding)\n\n        return xmlstr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_info(self, msg, **kwargs):\n\n        args, extensions = self._filter_args(msg, **kwargs)\n        for key, val in args.items():\n            setattr(msg, key, val)\n\n        if extensions:\n            if msg.extension_elements:\n                msg.extension_elements.extend(extensions)\n            else:\n                msg.extension_elements = extensions", "response": "Add information to a SAML message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies if a certificate in the metadata contains any encryption certificates.", "response": "def has_encrypt_cert_in_metadata(self, sp_entity_id):\n        \"\"\" Verifies if the metadata contains encryption certificates.\n\n        :param sp_entity_id: Entity ID for the calling service provider.\n        :return: True if encrypt cert exists in metadata, otherwise False.\n        \"\"\"\n        if sp_entity_id is not None:\n            _certs = self.metadata.certs(sp_entity_id, \"any\", \"encryption\")\n            if len(_certs) > 0:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencrypt the assertion with the specified certificate.", "response": "def _encrypt_assertion(self, encrypt_cert, sp_entity_id, response,\n                           node_xpath=None):\n        \"\"\" Encryption of assertions.\n\n        :param encrypt_cert: Certificate to be used for encryption.\n        :param sp_entity_id: Entity ID for the calling service provider.\n        :param response: A samlp.Response\n        :param node_xpath: Unquie path to the element to be encrypted.\n        :return: A new samlp.Resonse with the designated assertion encrypted.\n        \"\"\"\n        _certs = []\n\n        if encrypt_cert:\n            _certs.append(encrypt_cert)\n        elif sp_entity_id is not None:\n            _certs = self.metadata.certs(sp_entity_id, \"any\", \"encryption\")\n        exception = None\n        for _cert in _certs:\n            try:\n                begin_cert = \"-----BEGIN CERTIFICATE-----\\n\"\n                end_cert = \"\\n-----END CERTIFICATE-----\\n\"\n                if begin_cert not in _cert:\n                    _cert = \"%s%s\" % (begin_cert, _cert)\n                if end_cert not in _cert:\n                    _cert = \"%s%s\" % (_cert, end_cert)\n                _, cert_file = make_temp(_cert.encode('ascii'), decode=False)\n                response = self.sec.encrypt_assertion(response, cert_file,\n                                                      pre_encryption_part(),\n                                                      node_xpath=node_xpath)\n                return response\n            except Exception as ex:\n                exception = ex\n                pass\n        if exception:\n            raise exception\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _response(self, in_response_to, consumer_url=None, status=None,\n                  issuer=None, sign=False, to_sign=None, sp_entity_id=None,\n                  encrypt_assertion=False,\n                  encrypt_assertion_self_contained=False,\n                  encrypted_advice_attributes=False,\n                  encrypt_cert_advice=None, encrypt_cert_assertion=None,\n                  sign_assertion=None, pefim=False, sign_alg=None,\n                  digest_alg=None, **kwargs):\n        \"\"\" Create a Response.\n            Encryption:\n                encrypt_assertion must be true for encryption to be\n                performed. If encrypted_advice_attributes also is\n                true, then will the function try to encrypt the assertion in\n                the the advice element of the main\n                assertion. Only one assertion element is allowed in the\n                advice element, if multiple assertions exists\n                in the advice element the main assertion will be encrypted\n                instead, since it's no point to encrypt\n                If encrypted_advice_attributes is\n                false the main assertion will be encrypted. Since the same key\n\n        :param in_response_to: The session identifier of the request\n        :param consumer_url: The URL which should receive the response\n        :param status: An instance of samlp.Status\n        :param issuer: The issuer of the response\n        :param sign: Whether the response should be signed or not\n        :param to_sign: If there are other parts to sign\n        :param sp_entity_id: Entity ID for the calling service provider.\n        :param encrypt_assertion: True if assertions should be encrypted.\n        :param encrypt_assertion_self_contained: True if all encrypted\n        assertions should have alla namespaces selfcontained.\n        :param encrypted_advice_attributes: True if assertions in the advice\n        element should be encrypted.\n        :param encrypt_cert_advice: Certificate to be used for encryption of\n        assertions in the advice element.\n        :param encrypt_cert_assertion: Certificate to be used for encryption\n        of assertions.\n        :param sign_assertion: True if assertions should be signed.\n        :param pefim: True if a response according to the PEFIM profile\n        should be created.\n        :param kwargs: Extra key word arguments\n        :return: A Response instance\n        \"\"\"\n\n        if not status:\n            status = success_status_factory()\n\n        _issuer = self._issuer(issuer)\n\n        response = response_factory(issuer=_issuer,\n                                    in_response_to=in_response_to,\n                                    status=status, sign_alg=sign_alg,\n                                    digest_alg=digest_alg)\n\n        if consumer_url:\n            response.destination = consumer_url\n\n        self._add_info(response, **kwargs)\n\n        if not sign and to_sign and not encrypt_assertion:\n            return signed_instance_factory(response, self.sec, to_sign)\n\n        has_encrypt_cert = self.has_encrypt_cert_in_metadata(sp_entity_id)\n        if not has_encrypt_cert and encrypt_cert_advice is None:\n            encrypted_advice_attributes = False\n        if not has_encrypt_cert and encrypt_cert_assertion is None:\n            encrypt_assertion = False\n\n        if encrypt_assertion or (\n                        encrypted_advice_attributes and\n                            response.assertion.advice is\n                    not None and\n                        len(response.assertion.advice.assertion) == 1):\n            if sign:\n                response.signature = pre_signature_part(response.id,\n                                                        self.sec.my_cert, 1,\n                                                        sign_alg=sign_alg,\n                                                        digest_alg=digest_alg)\n                sign_class = [(class_name(response), response.id)]\n            else:\n                sign_class = []\n\n            if encrypted_advice_attributes and response.assertion.advice is \\\n                    not None \\\n                    and len(response.assertion.advice.assertion) > 0:\n                _assertions = response.assertion\n                if not isinstance(_assertions, list):\n                    _assertions = [_assertions]\n                for _assertion in _assertions:\n                    _assertion.advice.encrypted_assertion = []\n                    _assertion.advice.encrypted_assertion.append(\n                        EncryptedAssertion())\n                    _advice_assertions = copy.deepcopy(\n                        _assertion.advice.assertion)\n                    _assertion.advice.assertion = []\n                    if not isinstance(_advice_assertions, list):\n                        _advice_assertions = [_advice_assertions]\n                    for tmp_assertion in _advice_assertions:\n                        to_sign_advice = []\n                        if sign_assertion and not pefim:\n                            tmp_assertion.signature = pre_signature_part(\n                                tmp_assertion.id, self.sec.my_cert, 1,\n                                sign_alg=sign_alg, digest_alg=digest_alg)\n                            to_sign_advice.append(\n                                (class_name(tmp_assertion), tmp_assertion.id))\n\n                        # tmp_assertion = response.assertion.advice.assertion[0]\n                        _assertion.advice.encrypted_assertion[\n                            0].add_extension_element(tmp_assertion)\n                        if encrypt_assertion_self_contained:\n                            advice_tag = \\\n                                response.assertion.advice._to_element_tree().tag\n                            assertion_tag = tmp_assertion._to_element_tree().tag\n                            response = \\\n                                response.get_xml_string_with_self_contained_assertion_within_advice_encrypted_assertion(\n                                    assertion_tag, advice_tag)\n                        node_xpath = ''.join(\n                            [\"/*[local-name()=\\\"%s\\\"]\" % v for v in\n                             [\"Response\", \"Assertion\", \"Advice\",\n                              \"EncryptedAssertion\", \"Assertion\"]])\n\n                        if to_sign_advice:\n                            response = signed_instance_factory(response,\n                                                               self.sec,\n                                                               to_sign_advice)\n                        response = self._encrypt_assertion(\n                            encrypt_cert_advice, sp_entity_id, response,\n                            node_xpath=node_xpath)\n                        response = response_from_string(response)\n\n            if encrypt_assertion:\n                to_sign_assertion = []\n                if sign_assertion is not None and sign_assertion:\n                    _assertions = response.assertion\n                    if not isinstance(_assertions, list):\n                        _assertions = [_assertions]\n                    for _assertion in _assertions:\n                        _assertion.signature = pre_signature_part(\n                            _assertion.id, self.sec.my_cert, 1,\n                            sign_alg=sign_alg, digest_alg=digest_alg)\n                        to_sign_assertion.append(\n                            (class_name(_assertion), _assertion.id))\n                if encrypt_assertion_self_contained:\n                    try:\n                        assertion_tag = response.assertion._to_element_tree(\n\n                        ).tag\n                    except:\n                        assertion_tag = response.assertion[\n                            0]._to_element_tree().tag\n                    response = pre_encrypt_assertion(response)\n                    response = \\\n                        response.get_xml_string_with_self_contained_assertion_within_encrypted_assertion(\n                            assertion_tag)\n                else:\n                    response = pre_encrypt_assertion(response)\n                if to_sign_assertion:\n                    response = signed_instance_factory(response, self.sec,\n                                                       to_sign_assertion)\n                response = self._encrypt_assertion(encrypt_cert_assertion,\n                                                   sp_entity_id, response)\n            else:\n                if to_sign:\n                    response = signed_instance_factory(response, self.sec,\n                                                       to_sign)\n            if sign:\n                return signed_instance_factory(response, self.sec, sign_class)\n            else:\n                return response\n\n        if sign:\n            return self.sign(response, to_sign=to_sign, sign_alg=sign_alg,\n                             digest_alg=digest_alg)\n        else:\n            return response", "response": "Create a Response object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a StatusResponse object.", "response": "def _status_response(self, response_class, issuer, status, sign=False,\n                         sign_alg=None, digest_alg=None,\n                         **kwargs):\n        \"\"\" Create a StatusResponse.\n\n        :param response_class: Which subclass of StatusResponse that should be\n            used\n        :param issuer: The issuer of the response message\n        :param status: The return status of the response operation\n        :param sign: Whether the response should be signed or not\n        :param kwargs: Extra arguments to the response class\n        :return: Class instance or string representation of the instance\n        \"\"\"\n\n        mid = sid()\n\n        for key in [\"binding\"]:\n            try:\n                del kwargs[key]\n            except KeyError:\n                pass\n\n        if not status:\n            status = success_status_factory()\n\n        response = response_class(issuer=issuer, id=mid, version=VERSION,\n                                  issue_instant=instant(),\n                                  status=status, **kwargs)\n\n        if sign:\n            return self.sign(response, mid, sign_alg=sign_alg,\n                             digest_alg=digest_alg)\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_request(self, enc_request, request_cls, service, binding):\n\n        _log_info = logger.info\n        _log_debug = logger.debug\n\n        # The addresses I should receive messages like this on\n        receiver_addresses = self.config.endpoint(service, binding,\n                                                  self.entity_type)\n        if not receiver_addresses and self.entity_type == \"idp\":\n            for typ in [\"aa\", \"aq\", \"pdp\"]:\n                receiver_addresses = self.config.endpoint(service, binding, typ)\n                if receiver_addresses:\n                    break\n\n        _log_debug(\"receiver addresses: %s\", receiver_addresses)\n        _log_debug(\"Binding: %s\", binding)\n\n        try:\n            timeslack = self.config.accepted_time_diff\n            if not timeslack:\n                timeslack = 0\n        except AttributeError:\n            timeslack = 0\n\n        _request = request_cls(self.sec, receiver_addresses,\n                               self.config.attribute_converters,\n                               timeslack=timeslack)\n\n        xmlstr = self.unravel(enc_request, binding, request_cls.msgtype)\n        must = self.config.getattr(\"want_authn_requests_signed\", \"idp\")\n        only_valid_cert = self.config.getattr(\n            \"want_authn_requests_only_with_valid_cert\", \"idp\")\n        if only_valid_cert is None:\n            only_valid_cert = False\n        if only_valid_cert:\n            must = True\n        _request = _request.loads(xmlstr, binding, origdoc=enc_request,\n                                  must=must, only_valid_cert=only_valid_cert)\n\n        _log_debug(\"Loaded request\")\n\n        if _request:\n            _request = _request.verify()\n            _log_debug(\"Verified request\")\n\n        if not _request:\n            return None\n        else:\n            return _request", "response": "Parse a request in its transport format and return a new request instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a response object for an error.", "response": "def create_error_response(self, in_response_to, destination, info,\n                              sign=False, issuer=None, sign_alg=None,\n                              digest_alg=None, **kwargs):\n        \"\"\" Create a error response.\n\n        :param in_response_to: The identifier of the message this is a response\n            to.\n        :param destination: The intended recipient of this message\n        :param info: Either an Exception instance or a 2-tuple consisting of\n            error code and descriptive text\n        :param sign: Whether the response should be signed or not\n        :param issuer: The issuer of the response\n        :param kwargs: To capture key,value pairs I don't care about\n        :return: A response instance\n        \"\"\"\n        status = error_status_factory(info)\n\n        return self._response(in_response_to, destination, status, issuer,\n                              sign, sign_alg=sign_alg, digest_alg=digest_alg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a LogoutRequest object for the IdP.", "response": "def create_logout_request(self, destination, issuer_entity_id,\n                              subject_id=None, name_id=None,\n                              reason=None, expire=None, message_id=0,\n                              consent=None, extensions=None, sign=False,\n                              session_indexes=None, sign_alg=None,\n                              digest_alg=None):\n        \"\"\" Constructs a LogoutRequest\n\n        :param destination: Destination of the request\n        :param issuer_entity_id: The entity ID of the IdP the request is\n            target at.\n        :param subject_id: The identifier of the subject\n        :param name_id: A NameID instance identifying the subject\n        :param reason: An indication of the reason for the logout, in the\n            form of a URI reference.\n        :param expire: The time at which the request expires,\n            after which the recipient may discard the message.\n        :param message_id: Request identifier\n        :param consent: Whether the principal have given her consent\n        :param extensions: Possible extensions\n        :param sign: Whether the query should be signed or not.\n        :param session_indexes: SessionIndex instances or just values\n        :return: A LogoutRequest instance\n        \"\"\"\n\n        if subject_id:\n            if self.entity_type == \"idp\":\n                name_id = NameID(text=self.users.get_entityid(subject_id,\n                                                              issuer_entity_id,\n                                                              False))\n            else:\n                name_id = NameID(text=subject_id)\n\n        if not name_id:\n            raise SAMLError(\"Missing subject identification\")\n\n        args = {}\n        if session_indexes:\n            sis = []\n            for si in session_indexes:\n                if isinstance(si, SessionIndex):\n                    sis.append(si)\n                else:\n                    sis.append(SessionIndex(text=si))\n            args[\"session_index\"] = sis\n\n        return self._message(LogoutRequest, destination, message_id,\n                             consent, extensions, sign, name_id=name_id,\n                             reason=reason, not_on_or_after=expire,\n                             issuer=self._issuer(), sign_alg=sign_alg,\n                             digest_alg=digest_alg, **args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a LogoutResponse. :param request: The request this is a response to :param bindings: Which bindings that can be used for the response If None the preferred bindings are gathered from the configuration :param status: The return status of the response operation If None the operation is regarded as a Success. :param issuer: The issuer of the message :return: HTTP args", "response": "def create_logout_response(self, request, bindings=None, status=None,\n                               sign=False, issuer=None, sign_alg=None,\n                               digest_alg=None):\n        \"\"\" Create a LogoutResponse.\n\n        :param request: The request this is a response to\n        :param bindings: Which bindings that can be used for the response\n            If None the preferred bindings are gathered from the configuration\n        :param status: The return status of the response operation\n            If None the operation is regarded as a Success.\n        :param issuer: The issuer of the message\n        :return: HTTP args\n        \"\"\"\n\n        rinfo = self.response_args(request, bindings)\n\n        if not issuer:\n            issuer = self._issuer()\n\n        response = self._status_response(samlp.LogoutResponse, issuer, status,\n                                         sign, sign_alg=sign_alg,\n                                         digest_alg=digest_alg, **rinfo)\n\n        logger.info(\"Response: %s\", response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a ArtifactResolve request", "response": "def create_artifact_resolve(self, artifact, destination, sessid,\n                                consent=None, extensions=None, sign=False,\n                                sign_alg=None, digest_alg=None):\n        \"\"\"\n        Create a ArtifactResolve request\n\n        :param artifact:\n        :param destination:\n        :param sessid: session id\n        :param consent:\n        :param extensions:\n        :param sign:\n        :return: The request message\n        \"\"\"\n\n        artifact = Artifact(text=artifact)\n\n        return self._message(ArtifactResolve, destination, sessid,\n                             consent, extensions, sign, artifact=artifact,\n                             sign_alg=sign_alg, digest_alg=digest_alg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an ArtifactResponse object", "response": "def create_artifact_response(self, request, artifact, bindings=None,\n                                 status=None, sign=False, issuer=None,\n                                 sign_alg=None, digest_alg=None):\n        \"\"\"\n        Create an ArtifactResponse\n        :return:\n        \"\"\"\n\n        rinfo = self.response_args(request, bindings)\n        response = self._status_response(ArtifactResponse, issuer, status,\n                                         sign=sign, sign_alg=sign_alg,\n                                         digest_alg=digest_alg, **rinfo)\n\n        msg = element_to_extension_element(self.artifact[artifact])\n        response.extension_elements = [msg]\n\n        logger.info(\"Response: %s\", response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_manage_name_id_request(self, xmlstr, binding=BINDING_SOAP):\n\n        return self._parse_request(xmlstr, saml_request.ManageNameIDRequest,\n                                   \"manage_name_id_service\", binding)", "response": "Deal with a ManageNameIDRequest."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a SAML Response and returns a Response object.", "response": "def _parse_response(self, xmlstr, response_cls, service, binding,\n                        outstanding_certs=None, **kwargs):\n        \"\"\" Deal with a Response\n\n        :param xmlstr: The response as a xml string\n        :param response_cls: What type of response it is\n        :param binding: What type of binding this message came through.\n        :param outstanding_certs: Certificates that belongs to me that the\n                IdP may have used to encrypt a response/assertion/..\n        :param kwargs: Extra key word arguments\n        :return: None if the reply doesn't contain a valid SAML Response,\n            otherwise the response.\n        \"\"\"\n\n        if self.config.accepted_time_diff:\n            kwargs[\"timeslack\"] = self.config.accepted_time_diff\n\n        if \"asynchop\" not in kwargs:\n            if binding in [BINDING_SOAP, BINDING_PAOS]:\n                kwargs[\"asynchop\"] = False\n            else:\n                kwargs[\"asynchop\"] = True\n\n        response = None\n        if not xmlstr:\n            return response\n\n        if \"return_addrs\" not in kwargs:\n            bindings = {\n                BINDING_SOAP,\n                BINDING_HTTP_REDIRECT,\n                BINDING_HTTP_POST,\n            }\n            if binding in bindings:\n                # expected return address\n                kwargs[\"return_addrs\"] = self.config.endpoint(\n                        service,\n                        binding=binding,\n                        context=self.entity_type)\n\n        try:\n            response = response_cls(self.sec, **kwargs)\n        except Exception as exc:\n            logger.info(\"%s\", exc)\n            raise\n\n        xmlstr = self.unravel(xmlstr, binding, response_cls.msgtype)\n        if not xmlstr:  # Not a valid reponse\n            return None\n\n        try:\n            response_is_signed = False\n            # Record the response signature requirement.\n            require_response_signature = response.require_response_signature\n            # Force the requirement that the response be signed in order to\n            # force signature checking to happen so that we can know whether\n            # or not the response is signed. The attribute on the response class\n            # is reset to the recorded value in the finally clause below.\n            response.require_response_signature = True\n            response = response.loads(xmlstr, False, origxml=xmlstr)\n        except SigverError as err:\n            if require_response_signature:\n                logger.error(\"Signature Error: %s\", err)\n                raise\n            else:\n                # The response is not signed but a signature is not required\n                # so reset the attribute on the response class to the recorded\n                # value and attempt to consume the unpacked XML again.\n                response.require_response_signature = require_response_signature\n                response = response.loads(xmlstr, False, origxml=xmlstr)\n        except UnsolicitedResponse:\n            logger.error(\"Unsolicited response\")\n            raise\n        except Exception as err:\n            if \"not well-formed\" in \"%s\" % err:\n                logger.error(\"Not well-formed XML\")\n            raise\n        else:\n            response_is_signed = True\n        finally:\n            response.require_response_signature = require_response_signature\n\n        logger.debug(\"XMLSTR: %s\", xmlstr)\n\n        if not response:\n            return response\n\n        keys = None\n        if outstanding_certs:\n            try:\n                cert = outstanding_certs[response.in_response_to]\n            except KeyError:\n                keys = None\n            else:\n                if not isinstance(cert, list):\n                    cert = [cert]\n                keys = []\n                for _cert in cert:\n                    keys.append(_cert[\"key\"])\n\n        try:\n            assertions_are_signed = False\n            # Record the assertions signature requirement.\n            require_signature = response.require_signature\n            # Force the requirement that the assertions be signed in order to\n            # force signature checking to happen so that we can know whether\n            # or not the assertions are signed. The attribute on the response class\n            # is reset to the recorded value in the finally clause below.\n            response.require_signature = True\n            # Verify that the assertion is syntactically correct and the\n            # signature on the assertion is correct if present.\n            response = response.verify(keys)\n        except SignatureError as err:\n            if require_signature:\n                logger.error(\"Signature Error: %s\", err)\n                raise\n            else:\n                response.require_signature = require_signature\n                response = response.verify(keys)\n        else:\n            assertions_are_signed = True\n        finally:\n            response.require_signature = require_signature\n\n        # If so configured enforce that either the response is signed\n        # or the assertions within it are signed.\n        if response.require_signature_or_response_signature:\n            if not response_is_signed and not assertions_are_signed:\n                msg = \"Neither the response nor the assertions are signed\"\n                logger.error(msg)\n                raise SigverError(msg)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_logout_request(self, xmlstr, binding=BINDING_SOAP):\n\n        return self._parse_request(xmlstr, saml_request.LogoutRequest,\n                                   \"single_logout_service\", binding)", "response": "Deal with a LogoutRequest object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef artifact2destination(self, artifact, descriptor):\n\n        _art = base64.b64decode(artifact)\n\n        assert _art[:2] == ARTIFACT_TYPECODE\n\n        try:\n            endpoint_index = str(int(_art[2:4]))\n        except ValueError:\n            endpoint_index = str(int(hexlify(_art[2:4])))\n        entity = self.sourceid[_art[4:24]]\n\n        destination = None\n        for desc in entity[\"%s_descriptor\" % descriptor]:\n            for srv in desc[\"artifact_resolution_service\"]:\n                if srv[\"index\"] == endpoint_index:\n                    destination = srv[\"location\"]\n                    break\n\n        return destination", "response": "Translate an artifact into a receiver location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare all necessary preparations for an authentication request.", "response": "def prepare_for_authenticate(\n            self, entityid=None, relay_state=\"\",\n            binding=saml2.BINDING_HTTP_REDIRECT, vorg=\"\", nameid_format=None,\n            scoping=None, consent=None, extensions=None, sign=None,\n            response_binding=saml2.BINDING_HTTP_POST, **kwargs):\n        \"\"\" Makes all necessary preparations for an authentication request.\n\n        :param entityid: The entity ID of the IdP to send the request to\n        :param relay_state: To where the user should be returned after\n            successfull log in.\n        :param binding: Which binding to use for sending the request\n        :param vorg: The entity_id of the virtual organization I'm a member of\n        :param nameid_format:\n        :param scoping: For which IdPs this query are aimed.\n        :param consent: Whether the principal have given her consent\n        :param extensions: Possible extensions\n        :param sign: Whether the request should be signed or not.\n        :param response_binding: Which binding to use for receiving the response\n        :param kwargs: Extra key word arguments\n        :return: session id and AuthnRequest info\n        \"\"\"\n\n        reqid, negotiated_binding, info = \\\n            self.prepare_for_negotiated_authenticate(\n                entityid=entityid,\n                relay_state=relay_state,\n                binding=binding,\n                vorg=vorg,\n                nameid_format=nameid_format,\n                scoping=scoping,\n                consent=consent,\n                extensions=extensions,\n                sign=sign,\n                response_binding=response_binding,\n                **kwargs)\n\n        assert negotiated_binding == binding\n\n        return reqid, info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare_for_negotiated_authenticate(\n            self, entityid=None, relay_state=\"\", binding=None, vorg=\"\",\n            nameid_format=None, scoping=None, consent=None, extensions=None,\n            sign=None, response_binding=saml2.BINDING_HTTP_POST, **kwargs):\n        \"\"\" Makes all necessary preparations for an authentication request\n        that negotiates which binding to use for authentication.\n\n        :param entityid: The entity ID of the IdP to send the request to\n        :param relay_state: To where the user should be returned after\n            successfull log in.\n        :param binding: Which binding to use for sending the request\n        :param vorg: The entity_id of the virtual organization I'm a member of\n        :param nameid_format:\n        :param scoping: For which IdPs this query are aimed.\n        :param consent: Whether the principal have given her consent\n        :param extensions: Possible extensions\n        :param sign: Whether the request should be signed or not.\n        :param response_binding: Which binding to use for receiving the response\n        :param kwargs: Extra key word arguments\n        :return: session id and AuthnRequest info\n        \"\"\"\n\n        expected_binding = binding\n\n        for binding in [BINDING_HTTP_REDIRECT, BINDING_HTTP_POST]:\n            if expected_binding and binding != expected_binding:\n                continue\n\n            destination = self._sso_location(entityid, binding)\n            logger.info(\"destination to provider: %s\", destination)\n\n            reqid, request = self.create_authn_request(\n                destination, vorg, scoping, response_binding, nameid_format,\n                consent=consent, extensions=extensions, sign=sign,\n                **kwargs)\n\n            _req_str = str(request)\n\n            logger.info(\"AuthNReq: %s\", _req_str)\n\n            try:\n                args = {'sigalg': kwargs[\"sigalg\"]}\n            except KeyError:\n                args = {}\n\n            http_info = self.apply_binding(binding, _req_str, destination,\n                                           relay_state, sign=sign, **args)\n\n            return reqid, binding, http_info\n        else:\n            raise SignOnError(\n                \"No supported bindings available for authentication\")", "response": "Prepares the authentication request for negotiated authentication."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef global_logout(self, name_id, reason=\"\", expire=None, sign=None,\n                      sign_alg=None, digest_alg=None):\n        \"\"\" More or less a layer of indirection :-/\n        Bootstrapping the whole thing by finding all the IdPs that should\n        be notified.\n\n        :param name_id: The identifier of the subject that wants to be\n            logged out.\n        :param reason: Why the subject wants to log out\n        :param expire: The latest the log out should happen.\n            If this time has passed don't bother.\n        :param sign: Whether the request should be signed or not.\n            This also depends on what binding is used.\n        :return: Depends on which binding is used:\n            If the HTTP redirect binding then a HTTP redirect,\n            if SOAP binding has been used the just the result of that\n            conversation.\n        \"\"\"\n\n        if isinstance(name_id, six.string_types):\n            name_id = decode(name_id)\n\n        logger.info(\"logout request for: %s\", name_id)\n\n        # find out which IdPs/AAs I should notify\n        entity_ids = self.users.issuers_of_info(name_id)\n        return self.do_logout(name_id, entity_ids, reason, expire, sign,\n                              sign_alg=sign_alg, digest_alg=digest_alg)", "response": "This function is used to do a logout request for a global user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a user is logged in the cache", "response": "def is_logged_in(self, name_id):\n        \"\"\" Check if user is in the cache\n\n        :param name_id: The identifier of the subject\n        \"\"\"\n        identity = self.users.get_identity(name_id)[0]\n        return bool(identity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a Logout response", "response": "def handle_logout_response(self, response, sign_alg=None, digest_alg=None):\n        \"\"\" handles a Logout response\n\n        :param response: A response.Response instance\n        :return: 4-tuple of (session_id of the last sent logout request,\n            response message, response headers and message)\n        \"\"\"\n\n        logger.info(\"state: %s\", self.state)\n        status = self.state[response.in_response_to]\n        logger.info(\"status: %s\", status)\n        issuer = response.issuer()\n        logger.info(\"issuer: %s\", issuer)\n        del self.state[response.in_response_to]\n        if status[\"entity_ids\"] == [issuer]:  # done\n            self.local_logout(decode(status[\"name_id\"]))\n            return 0, \"200 Ok\", [(\"Content-type\", \"text/html\")], []\n        else:\n            status[\"entity_ids\"].remove(issuer)\n            if \"sign_alg\" in status:\n                sign_alg = status[\"sign_alg\"]\n            return self.do_logout(decode(status[\"name_id\"]),\n                                  status[\"entity_ids\"],\n                                  status[\"reason\"], status[\"not_on_or_after\"],\n                                  status[\"sign\"], sign_alg=sign_alg,\n                                  digest_alg=digest_alg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo a attribute request to an attribute authority, this is by default done over SOAP. :param entityid: To whom the query should be sent :param subject_id: The identifier of the subject :param attribute: A dictionary of attributes and values that is asked for :param sp_name_qualifier: The unique identifier of the service provider or affiliation of providers for whom the identifier was generated. :param name_qualifier: The unique identifier of the identity provider that generated the identifier. :param nameid_format: The format of the name ID :param real_id: The identifier which is the key to this entity in the identity database :param binding: Which binding to use :param nsprefix: Namespace prefixes preferred before those automatically produced. :return: The attributes returned if BINDING_SOAP was used. HTTP args if BINDING_HTT_POST was used.", "response": "def do_attribute_query(self, entityid, subject_id,\n                           attribute=None, sp_name_qualifier=None,\n                           name_qualifier=None, nameid_format=None,\n                           real_id=None, consent=None, extensions=None,\n                           sign=False, binding=BINDING_SOAP, nsprefix=None):\n        \"\"\" Does a attribute request to an attribute authority, this is\n        by default done over SOAP.\n\n        :param entityid: To whom the query should be sent\n        :param subject_id: The identifier of the subject\n        :param attribute: A dictionary of attributes and values that is\n            asked for\n        :param sp_name_qualifier: The unique identifier of the\n            service provider or affiliation of providers for whom the\n            identifier was generated.\n        :param name_qualifier: The unique identifier of the identity\n            provider that generated the identifier.\n        :param nameid_format: The format of the name ID\n        :param real_id: The identifier which is the key to this entity in the\n            identity database\n        :param binding: Which binding to use\n        :param nsprefix: Namespace prefixes preferred before those automatically\n            produced.\n        :return: The attributes returned if BINDING_SOAP was used.\n            HTTP args if BINDING_HTT_POST was used.\n        \"\"\"\n\n        if real_id:\n            response_args = {\"real_id\": real_id}\n        else:\n            response_args = {}\n\n        if not binding:\n            binding, destination = self.pick_binding(\"attribute_service\",\n                                                     None,\n                                                     \"attribute_authority\",\n                                                     entity_id=entityid)\n        else:\n            srvs = self.metadata.attribute_service(entityid, binding)\n            if srvs is []:\n                raise SAMLError(\"No attribute service support at entity\")\n\n            destination = destinations(srvs)[0]\n\n        if binding == BINDING_SOAP:\n            return self._use_soap(destination, \"attribute_query\",\n                                  consent=consent, extensions=extensions,\n                                  sign=sign, subject_id=subject_id,\n                                  attribute=attribute,\n                                  sp_name_qualifier=sp_name_qualifier,\n                                  name_qualifier=name_qualifier,\n                                  format=nameid_format,\n                                  response_args=response_args)\n        elif binding == BINDING_HTTP_POST:\n            mid = sid()\n            query = self.create_attribute_query(destination, subject_id,\n                                                attribute, mid, consent,\n                                                extensions, sign, nsprefix)\n            self.state[query.id] = {\"entity_id\": entityid,\n                                    \"operation\": \"AttributeQuery\",\n                                    \"subject_id\": subject_id,\n                                    \"sign\": sign}\n            relay_state = self._relay_state(query.id)\n            return self.apply_binding(binding, \"%s\" % query, destination,\n                                      relay_state, sign=sign)\n        else:\n            raise SAMLError(\"Unsupported binding\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_logout_request(self, request, name_id, binding, sign=False,\n                              sign_alg=None, relay_state=\"\"):\n        \"\"\"\n        Deal with a LogoutRequest\n\n        :param request: The request as text string\n        :param name_id: The id of the current user\n        :param binding: Which binding the message came in over\n        :param sign: Whether the response will be signed or not\n        :return: Keyword arguments which can be used to send the response\n            what's returned follow different patterns for different bindings.\n            If the binding is BINDIND_SOAP, what is returned looks like this::\n\n                {\n                    \"data\": <the SOAP enveloped response>\n                    \"url\": \"\",\n                    'headers': [('content-type', 'application/soap+xml')]\n                    'method': \"POST\n                }\n        \"\"\"\n        logger.info(\"logout request: %s\", request)\n\n        _req = self._parse_request(request, LogoutRequest,\n                                   \"single_logout_service\", binding)\n\n        if _req.message.name_id == name_id:\n            try:\n                if self.local_logout(name_id):\n                    status = success_status_factory()\n                else:\n                    status = status_message_factory(\"Server error\",\n                                                    STATUS_REQUEST_DENIED)\n            except KeyError:\n                status = status_message_factory(\"Server error\",\n                                                STATUS_REQUEST_DENIED)\n        else:\n            status = status_message_factory(\"Wrong user\",\n                                            STATUS_UNKNOWN_PRINCIPAL)\n\n        if binding == BINDING_SOAP:\n            response_bindings = [BINDING_SOAP]\n        elif binding == BINDING_HTTP_POST or BINDING_HTTP_REDIRECT:\n            response_bindings = [BINDING_HTTP_POST, BINDING_HTTP_REDIRECT]\n        else:\n            response_bindings = self.config.preferred_binding[\n                \"single_logout_service\"]\n\n        response = self.create_logout_response(_req.message, response_bindings,\n                                               status, sign, sign_alg=sign_alg)\n        rinfo = self.response_args(_req.message, response_bindings)\n\n        return self.apply_binding(rinfo[\"binding\"], response,\n                                  rinfo[\"destination\"], relay_state,\n                                  response=True, sign=sign)", "response": "This function handles a LogoutRequest and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a UTC time in a while", "response": "def time_in_a_while(days=0, seconds=0, microseconds=0, milliseconds=0,\n                    minutes=0, hours=0, weeks=0):\n    \"\"\"\n    format of timedelta:\n        timedelta([days[, seconds[, microseconds[, milliseconds[,\n                    minutes[, hours[, weeks]]]]]]])\n    :return: UTC time\n    \"\"\"\n    delta = timedelta(days, seconds, microseconds, milliseconds,\n                      minutes, hours, weeks)\n    return datetime.utcnow() + delta"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrues if point datetime specification is before now.", "response": "def before(point):\n    \"\"\" True if point datetime specification is before now.\n\n    NOTE: If point is specified it is supposed to be in local time.\n    Not UTC/GMT !! This is because that is what gmtime() expects.\n    \"\"\"\n    if not point:\n        return True\n\n    if isinstance(point, six.string_types):\n        point = str_to_time(point)\n    elif isinstance(point, int):\n        point = time.gmtime(point)\n\n    return time.gmtime() <= point"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrues if after is later or equal to that", "response": "def later_than(after, before):\n    \"\"\" True if then is later or equal to that \"\"\"\n    if isinstance(after, six.string_types):\n        after = str_to_time(after)\n    elif isinstance(after, int):\n        after = time.gmtime(after)\n\n    if isinstance(before, six.string_types):\n        before = str_to_time(before)\n    elif isinstance(before, int):\n        before = time.gmtime(before)\n\n    if before is None:\n        return True\n    if after is None:\n        return False\n    return after >= before"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extend(self, name_id, issuer, vo_members):\n        result = []\n        for member in vo_members:\n            for ass in self.metadata.attribute_consuming_service(member):\n                for attr_serv in ass.attribute_service:\n                    logger.info(\n                        \"Send attribute request to %s\", attr_serv.location)\n                    if attr_serv.binding != BINDING_SOAP:\n                        continue\n                    # attribute query assumes SOAP binding\n                    session_info = self.saml2client.attribute_query(\n                        name_id, attr_serv.location, issuer_id=issuer,\n)\n                    if session_info:\n                        result.append(session_info)\n        return result", "response": "This method is used to extend the list of attributes of a given subject."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef phase2(self, authn_request, rc_url, idp_entity_id, headers=None,\n               sign=False, **kwargs):\n        \"\"\"\n        Doing the second phase of the ECP conversation, the conversation\n        with the IdP happens.\n\n        :param authn_request: The AuthenticationRequest\n        :param rc_url: The assertion consumer service url of the SP\n        :param idp_entity_id: The EntityID of the IdP\n        :param headers: Possible extra headers\n        :param sign: If the message should be signed\n        :return: The response from the IdP\n        \"\"\"\n\n        _, destination = self.pick_binding(\"single_sign_on_service\",\n                                           [BINDING_SOAP], \"idpsso\",\n                                           entity_id=idp_entity_id)\n\n        ht_args = self.apply_binding(BINDING_SOAP, authn_request, destination,\n                                     sign=sign)\n\n        if headers:\n            ht_args[\"headers\"].extend(headers)\n\n        logger.debug(\"[P2] Sending request: %s\", ht_args[\"data\"])\n\n        # POST the request to the IdP\n        response = self.send(**ht_args)\n\n        logger.debug(\"[P2] Got IdP response: %s\", response)\n\n        if response.status_code != 200:\n            raise SAMLError(\n                \"Request to IdP failed (%s): %s\" % (response.status_code,\n                                                    response.text))\n\n        # SAMLP response in a SOAP envelope body, ecp response in headers\n        respdict = self.parse_soap_message(response.text)\n\n        if respdict is None:\n            raise SAMLError(\"Unexpected reply from the IdP\")\n\n        logger.debug(\"[P2] IdP response dict: %s\", respdict)\n\n        idp_response = respdict[\"body\"]\n        assert idp_response.c_tag == \"Response\"\n\n        logger.debug(\"[P2] IdP AUTHN response: %s\", idp_response)\n\n        _ecp_response = None\n        for item in respdict[\"header\"]:\n            if item.c_tag == \"Response\" and item.c_namespace == ecp.NAMESPACE:\n                _ecp_response = item\n\n        _acs_url = _ecp_response.assertion_consumer_service_url\n        if rc_url != _acs_url:\n            error = (\"response_consumer_url '%s' does not match\" % rc_url,\n                     \"assertion_consumer_service_url '%s\" % _acs_url)\n            # Send an error message to the SP\n            _ = self.send(rc_url, \"POST\", data=soap.soap_fault(error))\n            # Raise an exception so the user knows something went wrong\n            raise SAMLError(error)\n\n        return idp_response", "response": "This method is called by the second phase of the ECP conversation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef operation(self, url, idp_entity_id, op, **opargs):\n        sp_url = self._sp\n\n        # ********************************************\n        # Phase 1 - First conversation with the SP\n        # ********************************************\n        # headers needed to indicate to the SP that I'm ECP enabled\n\n        opargs[\"headers\"] = self.add_paos_headers(opargs[\"headers\"])\n        response = self.send(sp_url, op, **opargs)\n        logger.debug(\"[Op] SP response: %s\" % response)\n        print(response.text)\n\n        if response.status_code != 200:\n            raise SAMLError(\n                \"Request to SP failed: %s\" % response.text)\n\n        # The response might be a AuthnRequest instance in a SOAP envelope\n        # body. If so it's the start of the ECP conversation\n        # Two SOAP header blocks; paos:Request and ecp:Request\n        # may also contain a ecp:RelayState SOAP header block\n        # If channel-binding was part of the PAOS header any number of\n        # <cb:ChannelBindings> header blocks may also be present\n        # if 'holder-of-key' option then one or more <ecp:SubjectConfirmation>\n        # header blocks may also be present\n        try:\n            respdict = self.parse_soap_message(response.text)\n            self.ecp_conversation(respdict, idp_entity_id)\n\n            # should by now be authenticated so this should go smoothly\n            response = self.send(url, op, **opargs)\n        except (soap.XmlParseError, AssertionError, KeyError):\n            raise\n\n        if response.status_code >= 400:\n            raise SAMLError(\"Error performing operation: %s\" % (\n                response.text,))\n\n        return response", "response": "This method is used by someone that wants to authenticate using SAML ECP. It is used by someone that wants to authenticate using SAML ECP."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the identity information that has been received and are still valid about the subject.", "response": "def get_identity(self, subject_id, entities=None,\n                     check_not_on_or_after=True):\n        \"\"\" Get all the identity information that has been received and\n        are still valid about the subject.\n\n        :param subject_id: The identifier of the subject\n        :param entities: The identifiers of the entities whoes assertions are\n            interesting. If the list is empty all entities are interesting.\n        :return: A 2-tuple consisting of the identity information (a\n            dictionary of attributes and values) and the list of entities\n            whoes information has timed out.\n        \"\"\"\n        res = {}\n        oldees = []\n        if not entities:\n            for item in self._cache.find({\"subject_id\": subject_id}):\n                try:\n                    info = self._get_info(item, check_not_on_or_after)\n                except ToOld:\n                    oldees.append(item[\"entity_id\"])\n                    continue\n\n                for key, vals in info[\"ava\"].items():\n                    try:\n                        tmp = set(res[key]).union(set(vals))\n                        res[key] = list(tmp)\n                    except KeyError:\n                        res[key] = vals\n        else:\n            for entity_id in entities:\n                try:\n                    info = self.get(subject_id, entity_id,\n                                    check_not_on_or_after)\n                except ToOld:\n                    oldees.append(entity_id)\n                    continue\n\n                for key, vals in info[\"ava\"].items():\n                    try:\n                        tmp = set(res[key]).union(set(vals))\n                        res[key] = list(tmp)\n                    except KeyError:\n                        res[key] = vals\n\n        return res, oldees"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the session information about a subject gotten from aracagetoken IdP / AA.", "response": "def _get_info(self, item, check_not_on_or_after=True):\n        \"\"\" Get session information about a subject gotten from a\n        specified IdP/AA.\n\n        :param item: Information stored\n        :return: The session information as a dictionary\n        \"\"\"\n        timestamp = item[\"timestamp\"]\n\n        if check_not_on_or_after and not time_util.not_on_or_after(timestamp):\n            raise ToOld()\n\n        try:\n            return item[\"info\"]\n        except KeyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring session information in the cache.", "response": "def set(self, subject_id, entity_id, info, timestamp=0):\n        \"\"\" Stores session information in the cache. Assumes that the subject_id\n        is unique within the context of the Service Provider.\n\n        :param subject_id: The subject identifier\n        :param entity_id: The identifier of the entity_id/receiver of an\n            assertion\n        :param info: The session info, the assertion is part of this\n        :param timestamp: A time after which the assertion is not valid.\n        \"\"\"\n\n        if isinstance(timestamp, datetime) or isinstance(timestamp,\n                                                         time.struct_time):\n            timestamp = time.strftime(TIME_FORMAT, timestamp)\n\n        doc = {\"subject_id\": subject_id,\n               \"entity_id\": entity_id,\n               \"info\": info,\n               \"timestamp\": timestamp}\n\n        _ = self._cache.insert(doc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all the entities of assertions for a subject.", "response": "def entities(self, subject_id):\n        \"\"\" Returns all the entities of assertions for a subject, disregarding\n        whether the assertion still is valid or not.\n\n        :param subject_id: The identifier of the subject\n        :return: A possibly empty list of entity identifiers\n        \"\"\"\n        try:\n            return [i[\"entity_id\"] for i in self._cache.find({\"subject_id\":\n                    subject_id})]\n        except ValueError:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the assertion is still active False otherwise.", "response": "def active(self, subject_id, entity_id):\n        \"\"\" Returns the status of assertions from a specific entity_id.\n\n        :param subject_id: The ID of the subject\n        :param entity_id: The entity ID of the entity_id of the assertion\n        :return: True or False depending on if the assertion is still\n            valid or not.\n        \"\"\"\n\n        item = self._cache.find_one({\"subject_id\": subject_id,\n                                     \"entity_id\": entity_id})\n        try:\n            return time_util.not_on_or_after(item[\"timestamp\"])\n        except ToOld:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subjects(self):\n\n        subj = [i[\"subject_id\"] for i in self._cache.find()]\n\n        return list(set(subj))", "response": "Return all the subject identifiers that are in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collect(self, top, sup, argv=None, parent=\"\"):\n        \n        try:\n            argv_copy = sd_copy(argv)\n            return [self.repr(top, sup, argv_copy, parent=parent)], []\n        except AttributeError as exc:\n            print(\"#!!!!\", exc)\n            return [], []", "response": "collects the information from this object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects the properties of this object", "response": "def collect(self, top, sup, argv=None, parent=\"\"):\n        \"\"\" means this element is part of a larger object, hence a property of \n        that object \"\"\"\n        \n        try:\n            #objekt = PyGroup(\"\", root=top)\n            (namespace, tag) = _namespace_and_tag(self, self.ref, top)\n    \n            try:\n                if self.xmlns_map[namespace] == top.target_namespace:\n                    cti = get_type_def(tag, top.parts)\n                    try:\n                        return cti.py_class.properties\n                    except ValueError:\n                        return cti.collect(top, sup) \n                else:\n                    raise Exception(\n                        \"Reference to group in other XSD file, not supported\")\n            except KeyError:\n                raise Exception(\"Missing namespace definition\")            \n        except AttributeError as exc:\n            print(\"#!!!!\", exc)\n            return [], []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_identity(self, name_id, entities=None,\n                     check_not_on_or_after=True):\n        \"\"\" Get all the identity information that has been received and\n        are still valid about the subject.\n\n        :param name_id: The subject identifier, a NameID instance\n        :param entities: The identifiers of the entities whoes assertions are\n            interesting. If the list is empty all entities are interesting.\n        :return: A 2-tuple consisting of the identity information (a\n            dictionary of attributes and values) and the list of entities\n            whoes information has timed out.\n        \"\"\"\n        if not entities:\n            try:\n                cni = code(name_id)\n                entities = self._db[cni].keys()\n            except KeyError:\n                return {}, []\n\n        res = {}\n        oldees = []\n        for entity_id in entities:\n            try:\n                info = self.get(name_id, entity_id, check_not_on_or_after)\n            except ToOld:\n                oldees.append(entity_id)\n                continue\n\n            if not info:\n                oldees.append(entity_id)\n                continue\n\n            for key, vals in info[\"ava\"].items():\n                try:\n                    tmp = set(res[key]).union(set(vals))\n                    res[key] = list(tmp)\n                except KeyError:\n                    res[key] = vals\n        return res, oldees", "response": "Get all the identity information that has been received and are still valid about the subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the session information about a subject.", "response": "def get(self, name_id, entity_id, check_not_on_or_after=True):\n        \"\"\" Get session information about a subject gotten from a\n        specified IdP/AA.\n\n        :param name_id: The subject identifier, a NameID instance\n        :param entity_id: The identifier of the entity_id\n        :param check_not_on_or_after: if True it will check if this\n             subject is still valid or if it is too old. Otherwise it\n             will not check this. True by default.\n        :return: The session information\n        \"\"\"\n        cni = code(name_id)\n        (timestamp, info) = self._db[cni][entity_id]\n        info = info.copy()\n        if check_not_on_or_after and time_util.after(timestamp):\n            raise ToOld(\"past %s\" % str(timestamp))\n\n        if 'name_id' in info and isinstance(info['name_id'], six.string_types):\n            info['name_id'] = decode(info['name_id'])\n        return info or None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set(self, name_id, entity_id, info, not_on_or_after=0):\n        info = dict(info)\n        if 'name_id' in info and not isinstance(info['name_id'], six.string_types):\n            # make friendly to (JSON) serialization\n            info['name_id'] = code(name_id)\n\n        cni = code(name_id)\n        if cni not in self._db:\n            self._db[cni] = {}\n\n        self._db[cni][entity_id] = (not_on_or_after, info)\n        if self._sync:\n            try:\n                self._db.sync()\n            except AttributeError:\n                pass", "response": "Stores the session info for the specified NameID and entity_id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef entities(self, name_id):\n        cni = code(name_id)\n        return list(self._db[cni].keys())", "response": "Returns all the entities of assertions for a subject disregarding\n        whether the assertion still is valid or not."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the status of a specific assertion from a specific entity_id.", "response": "def active(self, name_id, entity_id):\n        \"\"\" Returns the status of assertions from a specific entity_id.\n\n        :param name_id: The ID of the subject\n        :param entity_id: The entity ID of the entity_id of the assertion\n        :return: True or False depending on if the assertion is still\n            valid or not.\n        \"\"\"\n        try:\n            cni = code(name_id)\n            (timestamp, info) = self._db[cni][entity_id]\n        except KeyError:\n            return False\n\n        if not info:\n            return False\n        else:\n            return time_util.not_on_or_after(timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an instance of the target class from a string.", "response": "def create_class_from_xml_string(target_class, xml_string):\n    \"\"\"Creates an instance of the target class from a string.\n\n    :param target_class: The class which will be instantiated and populated\n        with the contents of the XML. This class must have a c_tag and a\n        c_namespace class variable.\n    :param xml_string: A string which contains valid XML. The root element\n        of the XML string should match the tag and namespace of the desired\n        class.\n\n    :return: An instance of the target class with members assigned according to\n        the contents of the XML - or None if the root XML tag and namespace did\n        not match those of the target class.\n    \"\"\"\n    if not isinstance(xml_string, six.binary_type):\n        xml_string = xml_string.encode('utf-8')\n    tree = defusedxml.ElementTree.fromstring(xml_string)\n    return create_class_from_element_tree(target_class, tree)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new class from an element tree.", "response": "def create_class_from_element_tree(target_class, tree, namespace=None,\n                                   tag=None):\n    \"\"\"Instantiates the class and populates members according to the tree.\n\n    Note: Only use this function with classes that have c_namespace and c_tag\n    class members.\n\n    :param target_class: The class which will be instantiated and populated\n        with the contents of the XML.\n    :param tree: An element tree whose contents will be converted into\n        members of the new target_class instance.\n    :param namespace: The namespace which the XML tree's root node must\n        match. If omitted, the namespace defaults to the c_namespace of the\n        target class.\n    :param tag: The tag which the XML tree's root node must match. If\n        omitted, the tag defaults to the c_tag class member of the target\n        class.\n\n    :return: An instance of the target class - or None if the tag and namespace\n        of the XML tree's root node did not match the desired namespace and tag.\n    \"\"\"\n    if namespace is None:\n        namespace = target_class.c_namespace\n    if tag is None:\n        tag = target_class.c_tag\n    if tree.tag == '{%s}%s' % (namespace, tag):\n        target = target_class()\n        target.harvest_element_tree(tree)\n        return target\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a value class instance with a specified value.", "response": "def make_vals(val, klass, klass_inst=None, prop=None, part=False,\n              base64encode=False):\n    \"\"\"\n    Creates a class instance with a specified value, the specified\n    class instance may be a value on a property in a defined class instance.\n\n    :param val: The value\n    :param klass: The value class\n    :param klass_inst: The class instance which has a property on which\n        what this function returns is a value.\n    :param prop: The property which the value should be assigned to.\n    :param part: If the value is one of a possible list of values it should be\n        handled slightly different compared to if it isn't.\n    :return: Value class instance\n    \"\"\"\n    cinst = None\n\n    # print(\"make_vals(%s, %s)\" % (val, klass))\n\n    if isinstance(val, dict):\n        cinst = klass().loadd(val, base64encode=base64encode)\n    else:\n        try:\n            cinst = klass().set_text(val)\n        except ValueError:\n            if not part:\n                cis = [make_vals(sval, klass, klass_inst, prop, True,\n                                 base64encode) for sval in val]\n                setattr(klass_inst, prop, cis)\n            else:\n                raise\n\n    if part:\n        return cinst\n    else:\n        if cinst:\n            cis = [cinst]\n            setattr(klass_inst, prop, cis)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an element into an extension element instance", "response": "def element_to_extension_element(element):\n    \"\"\"\n    Convert an element into a extension element\n\n    :param element: The element instance\n    :return: An extension element instance\n    \"\"\"\n\n    exel = ExtensionElement(element.c_tag, element.c_namespace,\n                            text=element.text)\n\n    exel.attributes.update(element.extension_attributes)\n    exel.children.extend(element.extension_elements)\n\n    for xml_attribute, (member_name, typ, req) in \\\n            iter(element.c_attributes.items()):\n        member_value = getattr(element, member_name)\n        if member_value is not None:\n            exel.attributes[xml_attribute] = member_value\n\n    exel.children.extend([element_to_extension_element(c) for c in\n                          element.children_with_values()])\n\n    return exel"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extension_element_to_element(extension_element, translation_functions,\n                                 namespace=None):\n    \"\"\" Convert an extension element to a normal element.\n    In order to do this you need to have an idea of what type of\n    element it is. Or rather which module it belongs to.\n\n    :param extension_element: The extension element\n    :param translation_functions: A dictionary with class identifiers\n        as keys and string-to-element translations functions as values\n    :param namespace: The namespace of the translation functions.\n    :return: An element instance or None\n    \"\"\"\n\n    try:\n        element_namespace = extension_element.namespace\n    except AttributeError:\n        element_namespace = extension_element.c_namespace\n    if element_namespace == namespace:\n        try:\n            try:\n                ets = translation_functions[extension_element.tag]\n            except AttributeError:\n                ets = translation_functions[extension_element.c_tag]\n            return ets(extension_element.to_string())\n        except KeyError:\n            pass\n\n    return None", "response": "Convert an extension element to a normal element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a list of elements each one matching one of the extension elements and the given schemas.", "response": "def extension_elements_to_elements(extension_elements, schemas):\n    \"\"\" Create a list of elements each one matching one of the\n    given extension elements. This is of course dependent on the access\n    to schemas that describe the extension elements.\n\n    :param extension_elements: The list of extension elements\n    :param schemas: Imported Python modules that represent the different\n        known schemas used for the extension elements\n    :return: A list of elements, representing the set of extension elements\n        that was possible to match against a Class in the given schemas.\n        The elements returned are the native representation of the elements\n        according to the schemas.\n    \"\"\"\n    res = []\n\n    if isinstance(schemas, list):\n        pass\n    elif isinstance(schemas, dict):\n        schemas = list(schemas.values())\n    else:\n        return res\n\n    for extension_element in extension_elements:\n        for schema in schemas:\n            inst = extension_element_to_element(extension_element,\n                                                schema.ELEMENT_FROM_STRING,\n                                                schema.NAMESPACE)\n            if inst:\n                res.append(inst)\n                break\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch child nodes for objects with the desired tag and namespace.", "response": "def find_children(self, tag=None, namespace=None):\n        \"\"\"Searches child nodes for objects with the desired tag/namespace.\n\n        Returns a list of extension elements within this object whose tag\n        and/or namespace match those passed in. To find all children in\n        a particular namespace, specify the namespace but not the tag name.\n        If you specify only the tag, the result list may contain extension\n        elements in multiple namespaces.\n\n        :param tag: str (optional) The desired tag\n        :param namespace: str (optional) The desired namespace\n\n        :return: A list of elements whose tag and/or namespace match the\n            parameters values\n        \"\"\"\n\n        results = []\n\n        if tag and namespace:\n            for element in self.children:\n                if element.tag == tag and element.namespace == namespace:\n                    results.append(element)\n        elif tag and not namespace:\n            for element in self.children:\n                if element.tag == tag:\n                    results.append(element)\n        elif namespace and not tag:\n            for element in self.children:\n                if element.namespace == namespace:\n                    results.append(element)\n        else:\n            for element in self.children:\n                results.append(element)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadd(self, ava):\n\n        if \"attributes\" in ava:\n            for key, val in ava[\"attributes\"].items():\n                self.attributes[key] = val\n\n        try:\n            self.tag = ava[\"tag\"]\n        except KeyError:\n            if not self.tag:\n                raise KeyError(\"ExtensionElement must have a tag\")\n\n        try:\n            self.namespace = ava[\"namespace\"]\n        except KeyError:\n            if not self.namespace:\n                raise KeyError(\"ExtensionElement must belong to a namespace\")\n\n        try:\n            self.text = ava[\"text\"]\n        except KeyError:\n            pass\n\n        if \"children\" in ava:\n            for item in ava[\"children\"]:\n                self.children.append(ExtensionElement(item[\"tag\"]).loadd(item))\n\n        return self", "response": "Load the attributes and children of an extension element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch extension elements within this object with the desired name and namespace.", "response": "def find_extensions(self, tag=None, namespace=None):\n        \"\"\"Searches extension elements for child nodes with the desired name.\n\n        Returns a list of extension elements within this object whose tag\n        and/or namespace match those passed in. To find all extensions in\n        a particular namespace, specify the namespace but not the tag name.\n        If you specify only the tag, the result list may contain extension\n        elements in multiple namespaces.\n\n        :param tag: str (optional) The desired tag\n        :param namespace: str (optional) The desired namespace\n\n        :Return: A list of elements whose tag and/or namespace match the\n            parameters values\n        \"\"\"\n\n        results = []\n\n        if tag and namespace:\n            for element in self.extension_elements:\n                if element.tag == tag and element.namespace == namespace:\n                    results.append(element)\n        elif tag and not namespace:\n            for element in self.extension_elements:\n                if element.tag == tag:\n                    results.append(element)\n        elif namespace and not tag:\n            for element in self.extension_elements:\n                if element.namespace == namespace:\n                    results.append(element)\n        else:\n            for element in self.extension_elements:\n                results.append(element)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of native elements of the given schema that have the given tag and belongs to the element given schema as elements of that schema.", "response": "def extensions_as_elements(self, tag, schema):\n        \"\"\" Return extensions that has the given tag and belongs to the\n        given schema as native elements of that schema.\n\n        :param tag: The tag of the element\n        :param schema: Which schema the element should originate from\n        :return: a list of native elements\n        \"\"\"\n        result = []\n        for ext in self.find_extensions(tag, schema.NAMESPACE):\n            ets = schema.ELEMENT_FROM_STRING[tag]\n            result.append(ets(ext.to_string()))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_prefix(self, nspair):\n        for prefix, uri in nspair.items():\n            try:\n                ElementTree.register_namespace(prefix, uri)\n            except AttributeError:\n                # Backwards compatibility with ET < 1.3\n                ElementTree._namespace_map[uri] = prefix\n            except ValueError:\n                pass", "response": "Register with ElementTree a set of namespaces that are used when constructing the text representation of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a encrypted assertion only containing self contained namespaces.", "response": "def get_xml_string_with_self_contained_assertion_within_encrypted_assertion(\n            self, assertion_tag):\n        \"\"\" Makes a encrypted assertion only containing self contained\n        namespaces.\n\n        :param assertion_tag: Tag for the assertion to be transformed.\n        :return: A new samlp.Resonse in string representation.\n        \"\"\"\n        prefix_map = self.get_prefix_map(\n            [self.encrypted_assertion._to_element_tree().find(assertion_tag)])\n\n        tree = self._to_element_tree()\n\n        self.set_prefixes(\n            tree.find(\n                self.encrypted_assertion._to_element_tree().tag).find(\n                assertion_tag), prefix_map)\n\n        return ElementTree.tostring(tree, encoding=\"UTF-8\").decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_string(self, nspair=None):\n        if not nspair and self.c_ns_prefix:\n            nspair = self.c_ns_prefix\n\n        if nspair:\n            self.register_prefix(nspair)\n\n        return ElementTree.tostring(self._to_element_tree(), encoding=\"UTF-8\")", "response": "Converts the Saml object to a string containing XML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all the keys that represent possible attributes and children.", "response": "def keys(self):\n        \"\"\" Return all the keys that represent possible attributes and\n        children.\n\n        :return: list of keys\n        \"\"\"\n        keys = ['text']\n        keys.extend([n for (n, t, r) in self.c_attributes.values()])\n        keys.extend([v[0] for v in self.c_children.values()])\n        return keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all children that have values", "response": "def children_with_values(self):\n        \"\"\" Returns all children that has values\n\n        :return: Possibly empty list of children.\n        \"\"\"\n        childs = []\n        for attribute in self._get_all_c_children_with_order():\n            member = getattr(self, attribute)\n            if member is None or member == []:\n                pass\n            elif isinstance(member, list):\n                for instance in member:\n                    childs.append(instance)\n            else:\n                childs.append(member)\n        return childs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the text property of the instance.", "response": "def set_text(self, val, base64encode=False):\n        \"\"\" Sets the text property of this instance.\n\n        :param val: The value of the text property\n        :param base64encode: Whether the value should be base64encoded\n        :return: The instance\n        \"\"\"\n\n        # print(\"set_text: %s\" % (val,))\n        if isinstance(val, bool):\n            if val:\n                setattr(self, \"text\", \"true\")\n            else:\n                setattr(self, \"text\", \"false\")\n        elif isinstance(val, int):\n            setattr(self, \"text\", \"%d\" % val)\n        elif isinstance(val, six.string_types):\n            setattr(self, \"text\", val)\n        elif val is None:\n            pass\n        else:\n            raise ValueError(\"Type shouldn't be '%s'\" % (val,))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the attributes children extension elements and extension attributes of this element instance depending on what is in the given dictionary.", "response": "def loadd(self, ava, base64encode=False):\n        \"\"\"\n        Sets attributes, children, extension elements and extension\n        attributes of this element instance depending on what is in\n        the given dictionary. If there are already values on properties\n        those will be overwritten. If the keys in the dictionary does\n        not correspond to known attributes/children/.. they are ignored.\n\n        :param ava: The dictionary\n        :param base64encode: Whether the values on attributes or texts on\n            children shoule be base64encoded.\n        :return: The instance\n        \"\"\"\n\n        for prop, _typ, _req in self.c_attributes.values():\n            if prop in ava:\n                value = ava[prop]\n                if isinstance(value, (bool, int)):\n                    setattr(self, prop, str(value))\n                else:\n                    setattr(self, prop, value)\n\n        if \"text\" in ava:\n            self.set_text(ava[\"text\"], base64encode)\n\n        for prop, klassdef in self.c_children.values():\n            # print(\"## %s, %s\" % (prop, klassdef))\n            if prop in ava:\n                # print(\"### %s\" % ava[prop])\n                # means there can be a list of values\n                if isinstance(klassdef, list):\n                    make_vals(ava[prop], klassdef[0], self, prop,\n                              base64encode=base64encode)\n                else:\n                    cis = make_vals(ava[prop], klassdef, self, prop, True,\n                                    base64encode)\n                    setattr(self, prop, cis)\n\n        if \"extension_elements\" in ava:\n            for item in ava[\"extension_elements\"]:\n                self.extension_elements.append(ExtensionElement(\n                    item[\"tag\"]).loadd(item))\n\n        if \"extension_attributes\" in ava:\n            for key, val in ava[\"extension_attributes\"].items():\n                self.extension_attributes[key] = val\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the class a child element should be an instance of.", "response": "def child_class(self, child):\n        \"\"\" Return the class a child element should be an instance of\n\n        :param child: The name of the child element\n        :return: The class\n        \"\"\"\n        for prop, klassdef in self.c_children.values():\n            if child == prop:\n                if isinstance(klassdef, list):\n                    return klassdef[0]\n                else:\n                    return klassdef\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef child_cardinality(self, child):\n        for prop, klassdef in self.c_children.values():\n            if child == prop:\n                if isinstance(klassdef, list):\n                    try:\n                        _min = self.c_cardinality[\"min\"]\n                    except KeyError:\n                        _min = 1\n                    try:\n                        _max = self.c_cardinality[\"max\"]\n                    except KeyError:\n                        _max = \"unbounded\"\n\n                    return _min, _max\n                else:\n                    return 1, 1\n        return None", "response": "Return the cardinality of a child element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_identity(self, subject_id, entities=None):\n        if not entities:\n            entities = self.entities(subject_id)\n            if not entities:\n                return {}, []\n\n        res = {}\n        oldees = []\n        for (entity_id, item) in self._cache.get_multi(entities,\n                                                    subject_id+'_').items():\n            try:\n                info = self.get_info(item)\n            except ToOld:\n                oldees.append(entity_id)\n                continue\n            for key, vals in info[\"ava\"].items():\n                try:\n                    tmp = set(res[key]).union(set(vals))\n                    res[key] = list(tmp)\n                except KeyError:\n                    res[key] = vals\n        return res, oldees", "response": "Get all the identity information that has been received and are still valid about the subject."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the session information about a subject gotten from IdP / AA.", "response": "def get_info(self, item, check_not_on_or_after=True):\n        \"\"\" Get session information about a subject gotten from a\n        specified IdP/AA.\n\n        :param item: Information stored\n        :return: The session information as a dictionary\n        \"\"\"\n        try:\n            (timestamp, info) = item\n        except ValueError:\n            raise ToOld()\n\n        if check_not_on_or_after and not time_util.not_on_or_after(timestamp):\n            raise ToOld()\n\n        return info or None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, subject_id, entity_id, info, timestamp=0):\n        entities = self._cache.get(subject_id)\n        if not entities:\n            entities = []\n            subjects = self._cache.get(\"subjects\")\n            if not subjects:\n                subjects = []\n            if subject_id not in subjects:\n                subjects.append(subject_id)\n                if not self._cache.set(\"subjects\", subjects):\n                    raise CacheError(\"set failed\")\n\n        if entity_id not in entities:\n            entities.append(entity_id)\n            if not self._cache.set(subject_id, entities):\n                raise CacheError(\"set failed\")\n\n        # Should use memcache's expire\n        if not self._cache.set(_key(subject_id, entity_id), (timestamp, info)):\n            raise CacheError(\"set failed\")", "response": "Stores the session info for the given subject and entity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset(self, subject_id, entity_id):\n        if not self._cache.set(_key(subject_id, entity_id), {}, 0):\n            raise CacheError(\"reset failed\")", "response": "Reset the cache for a specific subject and entity."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef entities(self, subject_id):\n        res = self._cache.get(subject_id)\n        if not res:\n            raise KeyError(\"No such subject\")\n        else:\n            return res", "response": "Returns all the entities of assertions for a subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the assertion is active False otherwise.", "response": "def active(self, subject_id, entity_id):\n        \"\"\" Returns the status of assertions from a specific entity_id.\n\n        :param subject_id: The ID of the subject\n        :param entity_id: The entity ID of the entity_id of the assertion\n        :return: True or False depending on if the assertion is still\n            valid or not.\n        \"\"\"\n        try:\n            (timestamp, info) = self._cache.get(_key(subject_id, entity_id))\n        except ValueError:\n            return False\n        except TypeError:\n            return False\n\n        # if not info:\n        #     return False\n\n        try:\n            return time_util.not_on_or_after(timestamp)\n        except ToOld:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd information about a person to the cache", "response": "def add_information_about_person(self, session_info):\n        \"\"\"If there already are information from this source in the cache\n        this function will overwrite that information\"\"\"\n\n        session_info = dict(session_info)\n        name_id = session_info[\"name_id\"]\n        issuer = session_info.pop(\"issuer\")\n        self.cache.set(name_id, issuer, session_info,\n                       session_info[\"not_on_or_after\"])\n        return name_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new authentication method to the database.", "response": "def add(self, spec, method, level=0, authn_authority=\"\", reference=None):\n        \"\"\"\n        Adds a new authentication method.\n        Assumes not more than one authentication method per AuthnContext\n        specification.\n\n        :param spec: What the authentication endpoint offers in the form\n            of an AuthnContext\n        :param method: A identifier of the authentication method.\n        :param level: security level, positive integers, 0 is lowest\n        :param reference: Desired unique reference to this `spec'\n        :return:\n        \"\"\"\n\n        if spec.authn_context_class_ref:\n            key = spec.authn_context_class_ref.text\n            _info = {\n                \"class_ref\": key,\n                \"method\": method,\n                \"level\": level,\n                \"authn_auth\": authn_authority\n            }\n        elif spec.authn_context_decl:\n            key = spec.authn_context_decl.c_namespace\n            _info = {\n                \"method\": method,\n                \"decl\": spec.authn_context_decl,\n                \"level\": level,\n                \"authn_auth\": authn_authority\n            }\n        else:\n            raise NotImplementedError()\n\n        self.next += 1\n        _ref = reference\n        if _ref is None:\n            _ref = str(self.next)\n\n        assert _ref not in self.db[\"info\"]\n        self.db[\"info\"][_ref] = _info\n        try:\n            self.db[\"key\"][key].append(_ref)\n        except KeyError:\n            self.db[\"key\"][key] = [_ref]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pick(self, req_authn_context=None):\n\n        if req_authn_context is None:\n            return self._pick_by_class_ref(UNSPECIFIED, \"minimum\")\n        if req_authn_context.authn_context_class_ref:\n            if req_authn_context.comparison:\n                _cmp = req_authn_context.comparison\n            else:\n                _cmp = \"exact\"\n            if _cmp == 'exact':\n                res = []\n                for cls_ref in req_authn_context.authn_context_class_ref:\n                    res += (self._pick_by_class_ref(cls_ref.text, _cmp))\n                return res\n            else:\n                return self._pick_by_class_ref(\n                    req_authn_context.authn_context_class_ref[0].text, _cmp)\n        elif req_authn_context.authn_context_decl_ref:\n            if req_authn_context.comparison:\n                _cmp = req_authn_context.comparison\n            else:\n                _cmp = \"exact\"\n            return self._pick_by_class_ref(\n                req_authn_context.authn_context_decl_ref, _cmp)", "response": "Given a requested authentication context find zero or more places where the user could be sent next."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading RSA PEM certificate.", "response": "def load_pem_private_key(data, password):\n    \"\"\"Load RSA PEM certificate.\"\"\"\n    key = _serialization.load_pem_private_key(\n        data, password, _backends.default_backend())\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef key_sign(rsakey, message, digest):\n    padding = _asymmetric.padding.PKCS1v15()\n    signature = rsakey.sign(message, padding, digest)\n    return signature", "response": "Sign the given message with the RSA key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies the given signature with the RSA key.", "response": "def key_verify(rsakey, signature, message, digest):\n    \"\"\"Verify the given signature with the RSA key.\"\"\"\n    padding = _asymmetric.padding.PKCS1v15()\n    if isinstance(rsakey, _asymmetric.rsa.RSAPrivateKey):\n        rsakey = rsakey.public_key()\n\n    try:\n        rsakey.verify(signature, message, padding, digest)\n    except Exception as e:\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef application(environ, start_response):\n    path = environ.get('PATH_INFO', '').lstrip('/')\n    logger.info(\"<application> PATH: %s\", path)\n\n    if path == \"metadata\":\n        return metadata(environ, start_response)\n\n    user = environ.get(\"REMOTE_USER\", \"\")\n    if not user:\n        user = environ.get(\"repoze.who.identity\", \"\")\n        logger.info(\"repoze.who.identity: '%s'\", user)\n    else:\n        logger.info(\"REMOTE_USER: '%s'\", user)\n    #logger.info(logging.Logger.manager.loggerDict)\n    for regex, callback in urls:\n        if user:\n            match = re.search(regex, path)\n            if match is not None:\n                try:\n                    environ['myapp.url_args'] = match.groups()[0]\n                except IndexError:\n                    environ['myapp.url_args'] = path\n                return callback(environ, start_response, user)\n        else:\n            return not_authn(environ, start_response)\n\n    return not_found(environ, start_response)", "response": "This function is the main WSGI application that handles the request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a value to a basic dictionary format", "response": "def _eval(val, onts, mdb_safe):\n    \"\"\"\n    Convert a value to a basic dict format\n    :param val: The value\n    :param onts: Schemas to be used in the conversion\n    :return: The basic dictionary\n    \"\"\"\n    if isinstance(val, six.string_types):\n        val = val.strip()\n        if not val:\n            return None\n        else:\n            return val\n    elif isinstance(val, dict) or isinstance(val, SamlBase):\n        return to_dict(val, onts, mdb_safe)\n    elif isinstance(val, list):\n        lv = []\n        for v in val:\n            if isinstance(v, dict) or isinstance(v, SamlBase):\n                lv.append(to_dict(v, onts, mdb_safe))\n            else:\n                lv.append(v)\n        return lv\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a pysaml2 metadata instance into a basic dictionary containing the contents of the pysaml2 message class instance.", "response": "def to_dict(_dict, onts, mdb_safe=False):\n    \"\"\"\n    Convert a pysaml2 SAML2 message class instance into a basic dictionary\n    format.\n    The export interface.\n\n    :param _dict: The pysaml2 metadata instance\n    :param onts: List of schemas to use for the conversion\n    :return: The converted information\n    \"\"\"\n    res = {}\n    if isinstance(_dict, SamlBase):\n        res[\"__class__\"] = \"%s&%s\" % (_dict.c_namespace, _dict.c_tag)\n        for key in _dict.keyswv():\n            if key in IMP_SKIP:\n                continue\n            val = getattr(_dict, key)\n            if key == \"extension_elements\":\n                _eel = extension_elements_to_elements(val, onts)\n                _val = [_eval(_v, onts, mdb_safe) for _v in _eel]\n            elif key == \"extension_attributes\":\n                if mdb_safe:\n                    _val = dict([(k.replace(\".\", \"__\"), v) for k, v in\n                                 val.items()])\n                    #_val = {k.replace(\".\", \"__\"): v for k, v in val.items()}\n                else:\n                    _val = val\n            else:\n                _val = _eval(val, onts, mdb_safe)\n\n            if _val:\n                if mdb_safe:\n                    key = key.replace(\".\", \"__\")\n                res[key] = _val\n    else:\n        for key, val in _dict.items():\n            _val = _eval(val, onts, mdb_safe)\n            if _val:\n                if mdb_safe and \".\" in key:\n                    key = key.replace(\".\", \"__\")\n                res[key] = _val\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _kwa(val, onts, mdb_safe=False):\n    if not mdb_safe:\n        return dict([(k, from_dict(v, onts)) for k, v in val.items()\n                     if k not in EXP_SKIP])\n    else:\n        _skip = [\"_id\"]\n        _skip.extend(EXP_SKIP)\n        return dict([(k.replace(\"__\", \".\"), from_dict(v, onts)) for k, v in\n                     val.items() if k not in _skip])", "response": "Convert a dictionary with key word argument to a dictionary with schema namespase."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(val, onts, mdb_safe=False):\n    if isinstance(val, dict):\n        if \"__class__\" in val:\n            ns, typ = val[\"__class__\"].split(\"&\")\n            cls = getattr(onts[ns], typ)\n            if cls is md.Extensions:\n                lv = []\n                for key, ditems in val.items():\n                    if key in EXP_SKIP:\n                        continue\n                    for item in ditems:\n                        ns, typ = item[\"__class__\"].split(\"&\")\n                        cls = getattr(onts[ns], typ)\n                        kwargs = _kwa(item, onts, mdb_safe)\n                        inst = cls(**kwargs)\n                        lv.append(element_to_extension_element(inst))\n                return lv\n            else:\n                kwargs = _kwa(val, onts, mdb_safe)\n                inst = cls(**kwargs)\n            return inst\n        else:\n            res = {}\n            for key, v in val.items():\n                if mdb_safe:\n                    key = key.replace(\"__\", \".\")\n                res[key] = from_dict(v, onts)\n            return res\n    elif isinstance(val, six.string_types):\n        return val\n    elif isinstance(val, list):\n        return [from_dict(v, onts) for v in val]\n    else:\n        return val", "response": "Converts a dictionary into a pysaml2 object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef application(environ, start_response):\n\n    path = environ.get(\"PATH_INFO\", \"\").lstrip(\"/\")\n\n    if path == \"metadata\":\n        return metadata(environ, start_response)\n\n    kaka = environ.get(\"HTTP_COOKIE\", None)\n    logger.info(\"<application> PATH: %s\", path)\n\n    if kaka:\n        logger.info(\"= KAKA =\")\n        user, authn_ref = info_from_cookie(kaka)\n        if authn_ref:\n            environ[\"idp.authn\"] = AUTHN_BROKER[authn_ref]\n    else:\n        try:\n            query = parse_qs(environ[\"QUERY_STRING\"])\n            logger.debug(\"QUERY: %s\", query)\n            user = IDP.cache.uid2user[query[\"id\"][0]]\n        except KeyError:\n            user = None\n\n    url_patterns = AUTHN_URLS\n    if not user:\n        logger.info(\"-- No USER --\")\n        # insert NON_AUTHN_URLS first in case there is no user\n        url_patterns = NON_AUTHN_URLS + url_patterns\n\n    for regex, callback in url_patterns:\n        match = re.search(regex, path)\n        if match is not None:\n            try:\n                environ[\"myapp.url_args\"] = match.groups()[0]\n            except IndexError:\n                environ[\"myapp.url_args\"] = path\n\n            logger.debug(\"Callback: %s\", callback)\n            if isinstance(callback, tuple):\n                cls = callback[0](environ, start_response, user)\n                func = getattr(cls, callback[1])\n\n                return func()\n            return callback(environ, start_response, user)\n\n    if re.search(r\"static/.*\", path) is not None:\n        return staticfile(environ, start_response)\n    return not_found(environ, start_response)", "response": "The main WSGI application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying the SAML request.", "response": "def verify_request(self, query, binding):\n        \"\"\"\n        :param query: The SAML query, transport encoded\n        :param binding: Which binding the query came in over\n        \"\"\"\n        resp_args = {}\n        if not query:\n            logger.info(\"Missing QUERY\")\n            resp = Unauthorized(\"Unknown user\")\n            return resp_args, resp(self.environ, self.start_response)\n\n        if not self.req_info:\n            self.req_info = IDP.parse_authn_request(query, binding)\n\n        logger.info(\"parsed OK\")\n        _authn_req = self.req_info.message\n        logger.debug(\"%s\", _authn_req)\n\n        try:\n            self.binding_out, self.destination = IDP.pick_binding(\n                \"assertion_consumer_service\",\n                bindings=self.response_bindings,\n                entity_id=_authn_req.issuer.text,\n                request=_authn_req,\n            )\n        except Exception as err:\n            logger.error(\"Couldn't find receiver endpoint: %s\", err)\n            raise\n\n        logger.debug(\"Binding: %s, destination: %s\", self.binding_out, self.destination)\n\n        resp_args = {}\n        try:\n            resp_args = IDP.response_args(_authn_req)\n            _resp = None\n        except UnknownPrincipal as excp:\n            _resp = IDP.create_error_response(_authn_req.id, self.destination, excp)\n        except UnsupportedBinding as excp:\n            _resp = IDP.create_error_response(_authn_req.id, self.destination, excp)\n\n        return resp_args, _resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays the login form", "response": "def do_authentication(environ, start_response, authn_context, key,\n                      redirect_uri):\n    \"\"\"\n    Display the login form\n    \"\"\"\n    logger.debug(\"Do authentication\")\n    auth_info = AUTHN_BROKER.pick(authn_context)\n\n    if len(auth_info):\n        method, reference = auth_info[0]\n        logger.debug(\"Authn chosen: %s (ref=%s)\", method, reference)\n        return method(environ, start_response, reference, key, redirect_uri)\n    else:\n        resp = Unauthorized(\"No usable authentication method\")\n        return resp(environ, start_response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay the login form", "response": "def username_password_authn(environ, start_response, reference, key,\n                            redirect_uri):\n    \"\"\"\n    Display the login form\n    \"\"\"\n    logger.info(\"The login page\")\n    headers = []\n\n    resp = Response(mako_template=\"login.mako\", template_lookup=LOOKUP,\n                    headers=headers)\n\n    argv = {\n        \"action\": \"/verify\",\n        \"login\": \"\",\n        \"password\": \"\",\n        \"key\": key,\n        \"authn_reference\": reference,\n        \"redirect_uri\": redirect_uri\n    }\n    logger.info(\"do_authentication argv: %s\", argv)\n    return resp(environ, start_response, **argv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(self):\n        logger.info(\"--- In SSO POST ---\")\n        saml_msg = self.unpack_either()\n        self.req_info = IDP.parse_authn_request(\n            saml_msg[\"SAMLRequest\"], BINDING_HTTP_POST)\n        _req = self.req_info.message\n        if self.user:\n            if _req.force_authn:\n                saml_msg[\"req_info\"] = self.req_info\n                key = self._store_request(saml_msg)\n                return self.not_authn(key, _req.requested_authn_context)\n            else:\n                return self.operation(saml_msg, BINDING_HTTP_POST)\n        else:\n            saml_msg[\"req_info\"] = self.req_info\n            key = self._store_request(saml_msg)\n            return self.not_authn(key, _req.requested_authn_context)", "response": "This method handles the HTTP - Post endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef code(item):\n    _res = []\n    i = 0\n    for attr in ATTR:\n        val = getattr(item, attr)\n        if val:\n            _res.append(\"%d=%s\" % (i, quote(val)))\n        i += 1\n    return \",\".join(_res)", "response": "Converts a NameID class instance into a quoted string of comma separated\n    attribute value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef code_binary(item):\n    code_str = code(item)\n    if isinstance(code_str, six.string_types):\n        return code_str.encode('utf-8')\n    return code_str", "response": "Return a binary code suitable for hashing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode(txt):\n    _nid = NameID()\n    for part in txt.split(\",\"):\n        if part.find(\"=\") != -1:\n            i, val = part.split(\"=\")\n            try:\n                setattr(_nid, ATTR[int(i)], unquote(val))\n            except:\n                pass\n    return _nid", "response": "Turns a coded string by code() into a NameID class instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a NameID to userID mapping", "response": "def remove_remote(self, name_id):\n        \"\"\"\n        Remove a NameID to userID mapping\n\n        :param name_id: NameID instance\n        \"\"\"\n        _cn = code(name_id)\n        _id = self.db[name_id.text]\n        try:\n            vals = self.db[_id].split(\" \")\n            vals.remove(_cn)\n            self.db[_id] = \" \".join(vals)\n        except KeyError:\n            pass\n\n        del self.db[name_id.text]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_nameid(self, userid, **kwargs):\n        res = []\n        try:\n            _vals = self.db[userid]\n        except KeyError:\n            logger.debug(\"failed to find userid %s in IdentDB\", userid)\n            return res\n\n        for val in _vals.split(\" \"):\n            nid = decode(val)\n            if kwargs:\n                for key, _val in kwargs.items():\n                    if getattr(nid, key, None) != _val:\n                        break\n                else:\n                    res.append(nid)\n            else:\n                res.append(nid)\n\n        return res", "response": "Find a set of NameID s that match the search criteria."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef construct_nameid(self, userid, local_policy=None,\n                         sp_name_qualifier=None, name_id_policy=None,\n                         name_qualifier=\"\"):\n        \"\"\" Returns a name_id for the object. How the name_id is\n        constructed depends on the context.\n\n        :param local_policy: The policy the server is configured to follow\n        :param userid: The local permanent identifier of the object\n        :param sp_name_qualifier: The 'user'/-s of the name_id\n        :param name_id_policy: The policy the server on the other side wants\n            us to follow.\n        :param name_qualifier: A domain qualifier\n        :return: NameID instance precursor\n        \"\"\"\n\n        args = self.nim_args(local_policy, sp_name_qualifier, name_id_policy)\n        if name_qualifier:\n            args[\"name_qualifier\"] = name_qualifier\n        else:\n            args[\"name_qualifier\"] = self.name_qualifier\n\n        return self.get_nameid(userid, **args)", "response": "Constructs a NameID instance for the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the local ID of a persistent ID.", "response": "def find_local_id(self, name_id):\n        \"\"\"\n        Only find persistent IDs\n\n        :param name_id:\n        :return:\n        \"\"\"\n\n        try:\n            return self.db[name_id.text]\n        except KeyError:\n            logger.debug(\"name: %s\", name_id.text)\n            #logger.debug(\"id sub keys: %s\", self.subkeys())\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a manage name id request from the SP.", "response": "def handle_manage_name_id_request(self, name_id, new_id=None,\n                                      new_encrypted_id=\"\", terminate=\"\"):\n        \"\"\"\n        Requests from the SP is about the SPProvidedID attribute.\n        So this is about adding,replacing and removing said attribute.\n\n        :param name_id: NameID instance\n        :param new_id: NewID instance\n        :param new_encrypted_id: NewEncryptedID instance\n        :param terminate: Terminate instance\n        :return: The modified name_id\n        \"\"\"\n        _id = self.find_local_id(name_id)\n\n        orig_name_id = copy.copy(name_id)\n\n        if new_id:\n            name_id.sp_provided_id = new_id.text\n        elif new_encrypted_id:\n            # TODO\n            pass\n        elif terminate:\n            name_id.sp_provided_id = None\n        else:\n            #NOOP\n            return name_id\n\n        self.remove_remote(orig_name_id)\n        self.store(_id, name_id)\n        return name_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_config(self, stype=\"idp\"):\n        if stype == \"aa\":\n            return\n\n        # subject information is stored in a database\n        # default database is in memory which is OK in some setups\n        dbspec = self.config.getattr(\"subject_data\", \"idp\")\n        idb = None\n        typ = \"\"\n        if not dbspec:\n            idb = {}\n        elif isinstance(dbspec, six.string_types):\n            idb = _shelve_compat(dbspec, writeback=True, protocol=2)\n        else:  # database spec is a a 2-tuple (type, address)\n            # print(>> sys.stderr, \"DBSPEC: %s\" % (dbspec,))\n            (typ, addr) = dbspec\n            if typ == \"shelve\":\n                idb = _shelve_compat(addr, writeback=True, protocol=2)\n            elif typ == \"memcached\":\n                import memcache\n                idb = memcache.Client(addr)\n            elif typ == \"dict\":  # in-memory dictionary\n                idb = {}\n            elif typ == \"mongodb\":\n                from saml2.mongo_store import IdentMDB\n                self.ident = IdentMDB(database=addr, collection=\"ident\")\n            elif typ == \"identdb\":\n                mod, clas = addr.rsplit('.', 1)\n                mod = importlib.import_module(mod)\n                self.ident = getattr(mod, clas)()\n\n        if typ == \"mongodb\" or typ == \"identdb\":\n            pass\n        elif idb is not None:\n            self.ident = IdentDB(idb)\n        elif dbspec:\n            raise Exception(\"Couldn't open identity database: %s\" %\n                            (dbspec,))\n\n        try:\n            _domain = self.config.getattr(\"domain\", \"idp\")\n            if _domain:\n                self.ident.domain = _domain\n\n            self.ident.name_qualifier = self.config.entityid\n\n            dbspec = self.config.getattr(\"edu_person_targeted_id\", \"idp\")\n            if not dbspec:\n                pass\n            else:\n                typ = dbspec[0]\n                addr = dbspec[1]\n                secret = dbspec[2]\n                if typ == \"shelve\":\n                    self.eptid = EptidShelve(secret, addr)\n                elif typ == \"mongodb\":\n                    from saml2.mongo_store import EptidMDB\n                    self.eptid = EptidMDB(secret, database=addr,\n                                          collection=\"eptid\")\n                else:\n                    self.eptid = Eptid(secret)\n        except Exception:\n            self.ident.close()\n            raise", "response": "Initializes the server configuration with the given type of server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse an authentication request and return the corresponding AuthnRequest instance.", "response": "def parse_authn_request(self, enc_request, binding=BINDING_HTTP_REDIRECT):\n        \"\"\"Parse a Authentication Request\n\n        :param enc_request: The request in its transport format\n        :param binding: Which binding that was used to transport the message\n            to this entity.\n        :return: A request instance\n        \"\"\"\n\n        return self._parse_request(enc_request, AuthnRequest,\n                                   \"single_sign_on_service\", binding)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct and return the Assertion :param authn: Authentication information :param sp_entity_id: :param in_response_to: The ID of the request this is an answer to :param consumer_url: The recipient of the assertion :param name_id: The NameID of the subject :param policy: Assertion policies :param _issuer: Issuer of the statement :param authn_statement: An AuthnStatement instance :param identity: Identity information about the Subject :param best_effort: Even if not the SPs demands can be met send a response. :param sign_response: Sign the response, only applicable if ErrorResponse :param kwargs: Extra keyword arguments :return: An Assertion instance", "response": "def setup_assertion(self, authn, sp_entity_id, in_response_to, consumer_url,\n                        name_id, policy, _issuer, authn_statement, identity,\n                        best_effort, sign_response, farg=None,\n                        session_not_on_or_after=None, **kwargs):\n        \"\"\"\n        Construct and return the Assertion\n\n        :param authn: Authentication information\n        :param sp_entity_id:\n        :param in_response_to: The ID of the request this is an answer to\n        :param consumer_url: The recipient of the assertion\n        :param name_id: The NameID of the subject\n        :param policy: Assertion policies\n        :param _issuer: Issuer of the statement\n        :param authn_statement: An AuthnStatement instance\n        :param identity: Identity information about the Subject\n        :param best_effort: Even if not the SPs demands can be met send a\n            response.\n        :param sign_response: Sign the response, only applicable if\n            ErrorResponse\n        :param kwargs: Extra keyword arguments\n        :return: An Assertion instance\n        \"\"\"\n\n        ast = Assertion(identity)\n        ast.acs = self.config.getattr(\"attribute_converters\", \"idp\")\n        if policy is None:\n            policy = Policy()\n        try:\n            ast.apply_policy(sp_entity_id, policy, self.metadata)\n        except MissingValue as exc:\n            if not best_effort:\n                return self.create_error_response(in_response_to, consumer_url,\n                                                  exc, sign_response)\n\n        farg = self.update_farg(in_response_to, consumer_url, farg)\n\n        if authn:  # expected to be a dictionary\n            # Would like to use dict comprehension but ...\n            authn_args = dict(\n                [(AUTHN_DICT_MAP[k], v) for k, v in authn.items() if\n                 k in AUTHN_DICT_MAP])\n            authn_args.update(kwargs)\n\n            assertion = ast.construct(\n                sp_entity_id, self.config.attribute_converters, policy,\n                issuer=_issuer, farg=farg['assertion'], name_id=name_id,\n                session_not_on_or_after=session_not_on_or_after,\n                **authn_args)\n\n        elif authn_statement:  # Got a complete AuthnStatement\n            assertion = ast.construct(\n                sp_entity_id, self.config.attribute_converters, policy,\n                issuer=_issuer, authn_statem=authn_statement,\n                farg=farg['assertion'], name_id=name_id,\n                **kwargs)\n        else:\n            assertion = ast.construct(\n                sp_entity_id, self.config.attribute_converters, policy,\n                issuer=_issuer, farg=farg['assertion'], name_id=name_id,\n                session_not_on_or_after=session_not_on_or_after,\n                **kwargs)\n        return assertion"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a response. A layer of indirection. :param in_response_to: The session identifier of the request :param consumer_url: The URL which should receive the response :param sp_entity_id: The entity identifier of the SP :param identity: A dictionary with attributes and values that are expected to be the bases for the assertion in the response. :param name_id: The identifier of the subject :param status: The status of the response :param authn: A dictionary containing information about the authn context. :param issuer: The issuer of the response :param policy: :param sign_assertion: Whether the assertion should be signed or not :param sign_response: Whether the response should be signed or not :param best_effort: Even if not the SPs demands can be met send a response. :param encrypt_assertion: True if assertions should be encrypted. :param encrypt_assertion_self_contained: True if all encrypted assertions should have alla namespaces selfcontained. :param encrypted_advice_attributes: True if assertions in the advice element should be encrypted. :param encrypt_cert_advice: Certificate to be used for encryption of assertions in the advice element. :param encrypt_cert_assertion: Certificate to be used for encryption of assertions. :param authn_statement: Authentication statement. :param sign_assertion: True if assertions should be signed. :param pefim: True if a response according to the PEFIM profile should be created. :param farg: Argument to pass on to the assertion constructor :return: A response instance", "response": "def _authn_response(self, in_response_to, consumer_url,\n                        sp_entity_id, identity=None, name_id=None,\n                        status=None, authn=None, issuer=None, policy=None,\n                        sign_assertion=False, sign_response=False,\n                        best_effort=False, encrypt_assertion=False,\n                        encrypt_cert_advice=None, encrypt_cert_assertion=None,\n                        authn_statement=None,\n                        encrypt_assertion_self_contained=False,\n                        encrypted_advice_attributes=False,\n                        pefim=False, sign_alg=None, digest_alg=None,\n                        farg=None, session_not_on_or_after=None):\n        \"\"\" Create a response. A layer of indirection.\n\n        :param in_response_to: The session identifier of the request\n        :param consumer_url: The URL which should receive the response\n        :param sp_entity_id: The entity identifier of the SP\n        :param identity: A dictionary with attributes and values that are\n            expected to be the bases for the assertion in the response.\n        :param name_id: The identifier of the subject\n        :param status: The status of the response\n        :param authn: A dictionary containing information about the\n            authn context.\n        :param issuer: The issuer of the response\n        :param policy:\n        :param sign_assertion: Whether the assertion should be signed or not\n        :param sign_response: Whether the response should be signed or not\n        :param best_effort: Even if not the SPs demands can be met send a\n            response.\n        :param encrypt_assertion: True if assertions should be encrypted.\n        :param encrypt_assertion_self_contained: True if all encrypted\n        assertions should have alla namespaces\n        selfcontained.\n        :param encrypted_advice_attributes: True if assertions in the advice\n        element should be encrypted.\n        :param encrypt_cert_advice: Certificate to be used for encryption of\n        assertions in the advice element.\n        :param encrypt_cert_assertion: Certificate to be used for encryption\n        of assertions.\n        :param authn_statement: Authentication statement.\n        :param sign_assertion: True if assertions should be signed.\n        :param pefim: True if a response according to the PEFIM profile\n        should be created.\n        :param farg: Argument to pass on to the assertion constructor\n        :return: A response instance\n        \"\"\"\n\n        if farg is None:\n            assertion_args = {}\n\n        args = {}\n        # if identity:\n        _issuer = self._issuer(issuer)\n\n        # if encrypt_assertion and show_nameid:\n        #    tmp_name_id = name_id\n        #    name_id = None\n        #    name_id = None\n        #    tmp_authn = authn\n        #    authn = None\n        #    tmp_authn_statement = authn_statement\n        #    authn_statement = None\n\n        if pefim:\n            encrypted_advice_attributes = True\n            encrypt_assertion_self_contained = True\n            assertion_attributes = self.setup_assertion(\n                None, sp_entity_id, None, None, None, policy, None, None,\n                identity, best_effort, sign_response, farg=farg)\n            assertion = self.setup_assertion(\n                authn, sp_entity_id, in_response_to, consumer_url, name_id,\n                policy, _issuer, authn_statement, [], True, sign_response,\n                farg=farg, session_not_on_or_after=session_not_on_or_after)\n            assertion.advice = saml.Advice()\n\n            # assertion.advice.assertion_id_ref.append(saml.AssertionIDRef())\n            # assertion.advice.assertion_uri_ref.append(saml.AssertionURIRef())\n            assertion.advice.assertion.append(assertion_attributes)\n        else:\n            assertion = self.setup_assertion(\n                authn, sp_entity_id, in_response_to, consumer_url, name_id,\n                policy, _issuer, authn_statement, identity, True,\n                sign_response, farg=farg,\n                session_not_on_or_after=session_not_on_or_after)\n\n        to_sign = []\n        if not encrypt_assertion:\n            if sign_assertion:\n                assertion.signature = pre_signature_part(assertion.id,\n                                                         self.sec.my_cert, 2,\n                                                         sign_alg=sign_alg,\n                                                         digest_alg=digest_alg)\n                to_sign.append((class_name(assertion), assertion.id))\n\n        args[\"assertion\"] = assertion\n\n        if (self.support_AssertionIDRequest() or self.support_AuthnQuery()):\n            self.session_db.store_assertion(assertion, to_sign)\n\n        return self._response(\n            in_response_to, consumer_url, status, issuer, sign_response,\n            to_sign, sp_entity_id=sp_entity_id,\n            encrypt_assertion=encrypt_assertion,\n            encrypt_cert_advice=encrypt_cert_advice,\n            encrypt_cert_assertion=encrypt_cert_assertion,\n            encrypt_assertion_self_contained=encrypt_assertion_self_contained,\n            encrypted_advice_attributes=encrypted_advice_attributes,\n            sign_assertion=sign_assertion,\n            pefim=pefim, sign_alg=sign_alg, digest_alg=digest_alg, **args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an attribute assertion response.", "response": "def create_attribute_response(self, identity, in_response_to, destination,\n                                  sp_entity_id, userid=\"\", name_id=None,\n                                  status=None, issuer=None,\n                                  sign_assertion=False, sign_response=False,\n                                  attributes=None, sign_alg=None,\n                                  digest_alg=None, farg=None, **kwargs):\n        \"\"\" Create an attribute assertion response.\n\n        :param identity: A dictionary with attributes and values that are\n            expected to be the bases for the assertion in the response.\n        :param in_response_to: The session identifier of the request\n        :param destination: The URL which should receive the response\n        :param sp_entity_id: The entity identifier of the SP\n        :param userid: A identifier of the user\n        :param name_id: The identifier of the subject\n        :param status: The status of the response\n        :param issuer: The issuer of the response\n        :param sign_assertion: Whether the assertion should be signed or not\n        :param sign_response: Whether the whole response should be signed\n        :param attributes:\n        :param kwargs: To catch extra keyword arguments\n        :return: A response instance\n        \"\"\"\n\n        policy = self.config.getattr(\"policy\", \"aa\")\n\n        if not name_id and userid:\n            try:\n                name_id = self.ident.construct_nameid(userid, policy,\n                                                      sp_entity_id)\n                logger.warning(\"Unspecified NameID format\")\n            except Exception:\n                pass\n\n        to_sign = []\n\n        if identity:\n            farg = self.update_farg(in_response_to, sp_entity_id, farg=farg)\n\n            _issuer = self._issuer(issuer)\n            ast = Assertion(identity)\n            if policy:\n                ast.apply_policy(sp_entity_id, policy, self.metadata)\n            else:\n                policy = Policy()\n\n            if attributes:\n                restr = restriction_from_attribute_spec(attributes)\n                ast = filter_attribute_value_assertions(ast)\n\n            assertion = ast.construct(\n                sp_entity_id, self.config.attribute_converters, policy,\n                issuer=_issuer, name_id=name_id,\n                farg=farg['assertion'])\n\n            if sign_assertion:\n                assertion.signature = pre_signature_part(assertion.id,\n                                                         self.sec.my_cert, 1,\n                                                         sign_alg=sign_alg,\n                                                         digest_alg=digest_alg)\n                # Just the assertion or the response and the assertion ?\n                to_sign = [(class_name(assertion), assertion.id)]\n                kwargs['sign_assertion'] = True\n\n            kwargs[\"assertion\"] = assertion\n\n        if sp_entity_id:\n            kwargs['sp_entity_id'] = sp_entity_id\n\n        return self._response(in_response_to, destination, status, issuer,\n                              sign_response, to_sign, sign_alg=sign_alg,\n                              digest_alg=digest_alg, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing an AuthenticationResponse object based on the given parameters.", "response": "def create_authn_response(self, identity, in_response_to, destination,\n                              sp_entity_id, name_id_policy=None, userid=None,\n                              name_id=None, authn=None, issuer=None,\n                              sign_response=None, sign_assertion=None,\n                              encrypt_cert_advice=None,\n                              encrypt_cert_assertion=None,\n                              encrypt_assertion=None,\n                              encrypt_assertion_self_contained=True,\n                              encrypted_advice_attributes=False, pefim=False,\n                              sign_alg=None, digest_alg=None,\n                              session_not_on_or_after=None,\n                              **kwargs):\n        \"\"\" Constructs an AuthenticationResponse\n\n        :param identity: Information about an user\n        :param in_response_to: The identifier of the authentication request\n            this response is an answer to.\n        :param destination: Where the response should be sent\n        :param sp_entity_id: The entity identifier of the Service Provider\n        :param name_id_policy: How the NameID should be constructed\n        :param userid: The subject identifier\n        :param name_id: The identifier of the subject. A saml.NameID instance.\n        :param authn: Dictionary with information about the authentication\n            context\n        :param issuer: Issuer of the response\n        :param sign_assertion: Whether the assertion should be signed or not.\n        :param sign_response: Whether the response should be signed or not.\n        :param encrypt_assertion: True if assertions should be encrypted.\n        :param encrypt_assertion_self_contained: True if all encrypted\n        assertions should have alla namespaces\n        selfcontained.\n        :param encrypted_advice_attributes: True if assertions in the advice\n        element should be encrypted.\n        :param encrypt_cert_advice: Certificate to be used for encryption of\n        assertions in the advice element.\n        :param encrypt_cert_assertion: Certificate to be used for encryption\n        of assertions.\n        :param sign_assertion: True if assertions should be signed.\n        :param pefim: True if a response according to the PEFIM profile\n        should be created.\n        :return: A response instance\n        \"\"\"\n\n        try:\n            args = self.gather_authn_response_args(\n                sp_entity_id, name_id_policy=name_id_policy, userid=userid,\n                name_id=name_id, sign_response=sign_response,\n                sign_assertion=sign_assertion,\n                encrypt_cert_advice=encrypt_cert_advice,\n                encrypt_cert_assertion=encrypt_cert_assertion,\n                encrypt_assertion=encrypt_assertion,\n                encrypt_assertion_self_contained\n                =encrypt_assertion_self_contained,\n                encrypted_advice_attributes=encrypted_advice_attributes,\n                pefim=pefim, **kwargs)\n        except IOError as exc:\n            response = self.create_error_response(in_response_to,\n                                                  destination,\n                                                  sp_entity_id,\n                                                  exc, name_id)\n            return (\"%s\" % response).split(\"\\n\")\n\n        try:\n            _authn = authn\n            if (sign_assertion or sign_response) and \\\n                    self.sec.cert_handler.generate_cert():\n                with self.lock:\n                    self.sec.cert_handler.update_cert(True)\n                    return self._authn_response(\n                        in_response_to, destination, sp_entity_id, identity,\n                        authn=_authn, issuer=issuer, pefim=pefim,\n                        sign_alg=sign_alg, digest_alg=digest_alg,\n                        session_not_on_or_after=session_not_on_or_after, **args)\n            return self._authn_response(\n                in_response_to, destination, sp_entity_id, identity,\n                authn=_authn, issuer=issuer, pefim=pefim, sign_alg=sign_alg,\n                digest_alg=digest_alg,\n                session_not_on_or_after=session_not_on_or_after, **args)\n\n        except MissingValue as exc:\n            return self.create_error_response(in_response_to, destination,\n                                              sp_entity_id, exc, name_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates NameIDMappingResponse protocol for mapping a principal s name identifier into a different name identifier for the same principal.", "response": "def create_name_id_mapping_response(self, name_id=None, encrypted_id=None,\n                                        in_response_to=None,\n                                        issuer=None, sign_response=False,\n                                        status=None, sign_alg=None,\n                                        digest_alg=None, **kwargs):\n        \"\"\"\n        protocol for mapping a principal's name identifier into a\n        different name identifier for the same principal.\n        Done over soap.\n\n        :param name_id:\n        :param encrypted_id:\n        :param in_response_to:\n        :param issuer:\n        :param sign_response:\n        :param status:\n        :return:\n        \"\"\"\n        # Done over SOAP\n\n        ms_args = self.message_args()\n\n        _resp = NameIDMappingResponse(name_id, encrypted_id,\n                                      in_response_to=in_response_to, **ms_args)\n\n        if sign_response:\n            return self.sign(_resp, sign_alg=sign_alg, digest_alg=digest_alg)\n        else:\n            logger.info(\"Message: %s\", _resp)\n            return _resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_authn_query_response(self, subject, session_index=None,\n                                    requested_context=None, in_response_to=None,\n                                    issuer=None, sign_response=False,\n                                    status=None, sign_alg=None, digest_alg=None,\n                                    **kwargs):\n        \"\"\"\n        A successful <Response> will contain one or more assertions containing\n        authentication statements.\n\n        :return:\n        \"\"\"\n\n        margs = self.message_args()\n        asserts = []\n        for statement in self.session_db.get_authn_statements(\n                subject.name_id, session_index, requested_context):\n            asserts.append(saml.Assertion(authn_statement=statement,\n                                          subject=subject, **margs))\n\n        if asserts:\n            args = {\"assertion\": asserts}\n        else:\n            args = {}\n\n        return self._response(in_response_to, \"\", status, issuer,\n                              sign_response, to_sign=[], sign_alg=sign_alg,\n                              digest_alg=digest_alg, **args)", "response": "Create a SAML Response object containing one or more AuthnStatement s."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all authentication statements that belong to a user identified by a NameID instance.", "response": "def clean_out_user(self, name_id):\n        \"\"\"\n        Remove all authentication statements that belongs to a user identified\n        by a NameID instance\n\n        :param name_id: NameID instance\n        :return: The local identifier for the user\n        \"\"\"\n\n        lid = self.ident.find_local_id(name_id)\n        logger.info(\"Clean out %s\", lid)\n\n        # remove the authentications\n        try:\n            for _nid in [decode(x) for x in self.ident.db[lid].split(\" \")]:\n                try:\n                    self.session_db.remove_authn_statements(_nid)\n                except KeyError:\n                    pass\n        except KeyError:\n            pass\n\n        return lid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mdb_get_database(uri, **kwargs):\n    if not \"tz_aware\" in kwargs:\n        # default, but not forced\n        kwargs[\"tz_aware\"] = True\n\n    connection_factory = MongoClient\n    _parsed_uri = {}\n\n    try:\n        _parsed_uri = pymongo.uri_parser.parse_uri(uri)\n    except pymongo.errors.InvalidURI:\n        # assume URI to be just the database name\n        db_name = uri\n        _conn = MongoClient()\n        pass\n    else:\n        if \"replicaset\" in _parsed_uri[\"options\"]:\n            connection_factory = MongoReplicaSetClient\n        db_name = _parsed_uri.get(\"database\", \"pysaml2\")\n        _conn = connection_factory(uri, **kwargs)\n\n    _db = _conn[db_name]\n\n    if \"username\" in _parsed_uri:\n        _db.authenticate(\n            _parsed_uri.get(\"username\", None),\n            _parsed_uri.get(\"password\", None)\n        )\n\n    return _db", "response": "Helper - function to connect to MongoDB and return a pymongo database object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate or extend an argument tree tdict from a list of items in a path.", "response": "def add_path(tdict, path):\n    \"\"\"\n    Create or extend an argument tree `tdict` from `path`.\n\n    :param tdict: a dictionary representing a argument tree\n    :param path: a path list\n    :return: a dictionary\n\n    Convert a list of items in a 'path' into a nested dict, where the\n    second to last item becomes the key for the final item. The remaining\n    items in the path become keys in the nested dict around that final pair\n    of items.\n\n    For example, for input values of:\n        tdict={}\n        path = ['assertion', 'subject', 'subject_confirmation',\n                'method', 'urn:oasis:names:tc:SAML:2.0:cm:bearer']\n\n        Returns an output value of:\n           {'assertion': {'subject': {'subject_confirmation':\n                         {'method': 'urn:oasis:names:tc:SAML:2.0:cm:bearer'}}}}\n\n    Another example, this time with a non-empty tdict input:\n\n        tdict={'method': 'urn:oasis:names:tc:SAML:2.0:cm:bearer'},\n        path=['subject_confirmation_data', 'in_response_to', '_012345']\n\n        Returns an output value of:\n            {'subject_confirmation_data': {'in_response_to': '_012345'},\n             'method': 'urn:oasis:names:tc:SAML:2.0:cm:bearer'}\n    \"\"\"\n    t = tdict\n    for step in path[:-2]:\n        try:\n            t = t[step]\n        except KeyError:\n            t[step] = {}\n            t = t[step]\n    t[path[-2]] = path[-1]\n\n    return tdict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a syntactically valid email address.", "response": "def valid_email(emailaddress, domains=GENERIC_DOMAINS):\n    \"\"\"Checks for a syntactically valid email address.\"\"\"\n\n    # Email address must be at least 6 characters in total.\n    # Assuming noone may have addresses of the type a@com\n    if len(emailaddress) < 6:\n        return False  # Address too short.\n\n    # Split up email address into parts.\n    try:\n        localpart, domainname = emailaddress.rsplit('@', 1)\n        host, toplevel = domainname.rsplit('.', 1)\n    except ValueError:\n        return False  # Address does not have enough parts.\n\n    # Check for Country code or Generic Domain.\n    if len(toplevel) != 2 and toplevel not in domains:\n        return False  # Not a domain name.\n\n    for i in '-_.%+.':\n        localpart = localpart.replace(i, \"\")\n    for i in '-_.':\n        host = host.replace(i, \"\")\n\n    if localpart.isalnum() and host.isalnum():\n        return True  # Email address is fine.\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeflates and base64 encodes a string", "response": "def deflate_and_base64_encode(string_val):\n    \"\"\"\n    Deflates and the base64 encodes a string\n\n    :param string_val: The string to deflate and encode\n    :return: The deflated and encoded string\n    \"\"\"\n    if not isinstance(string_val, six.binary_type):\n        string_val = string_val.encode('utf-8')\n    return base64.b64encode(zlib.compress(string_val)[2:-4])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rndbytes(size=16, alphabet=\"\"):\n    x = rndstr(size, alphabet)\n    if isinstance(x, six.string_types):\n        return x.encode('utf-8')\n    return x", "response": "Returns a random binary string of size size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the attribute map files.", "response": "def parse_attribute_map(filenames):\n    \"\"\"\n    Expects a file with each line being composed of the oid for the attribute\n    exactly one space, a user friendly name of the attribute and then\n    the type specification of the name.\n\n    :param filenames: List of filenames on mapfiles.\n    :return: A 2-tuple, one dictionary with the oid as keys and the friendly\n        names as values, the other one the other way around.\n    \"\"\"\n    forward = {}\n    backward = {}\n    for filename in filenames:\n        with open(filename) as fp:\n            for line in fp:\n                (name, friendly_name, name_format) = line.strip().split()\n                forward[(name, name_format)] = friendly_name\n                backward[friendly_name] = (name, name_format)\n\n    return forward, backward"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef signature(secret, parts):\n    if not isinstance(secret, six.binary_type):\n        secret = secret.encode('utf-8')\n    newparts = []\n    for part in parts:\n        if not isinstance(part, six.binary_type):\n            part = part.encode('utf-8')\n        newparts.append(part)\n    parts = newparts\n    if sys.version_info >= (2, 5):\n        csum = hmac.new(secret, digestmod=hashlib.sha1)\n    else:\n        csum = hmac.new(secret, digestmod=sha)\n\n    for part in parts:\n        csum.update(part)\n\n    return csum.hexdigest()", "response": "Generates a signature for the given secret and list of parts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn any entity that matches the specification", "response": "def any(self, typ, service, binding=None):\n        \"\"\"\n        Return any entity that matches the specification\n\n        :param typ: Type of entity\n        :param service:\n        :param binding:\n        :return:\n        \"\"\"\n        res = {}\n        for ent in self.keys():\n            bind = self.service(ent, typ, service, binding)\n            if bind:\n                res[ent] = bind\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget me all the bindings that are registered for a service entity", "response": "def bindings(self, entity_id, typ, service):\n        \"\"\"\n        Get me all the bindings that are registered for a service entity\n\n        :param entity_id:\n        :param service:\n        :return:\n        \"\"\"\n        return self.service(entity_id, typ, service)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns any entities with the specified descriptor.", "response": "def with_descriptor(self, descriptor):\n        '''\n        Returns any entities with the specified descriptor\n        '''\n        res = {}\n        desc = \"%s_descriptor\" % descriptor\n        for eid, ent in self.items():\n            if desc in ent:\n                res[eid] = ent\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of certificates for the given Entity", "response": "def certs(self, entity_id, descriptor, use=\"signing\"):\n        '''\n        Returns certificates for the given Entity\n        '''\n        ent = self[entity_id]\n\n        def extract_certs(srvs):\n            res = []\n            for srv in srvs:\n                if \"key_descriptor\" in srv:\n                    for key in srv[\"key_descriptor\"]:\n                        if \"use\" in key and key[\"use\"] == use:\n                            for dat in key[\"key_info\"][\"x509_data\"]:\n                                cert = repack_cert(\n                                    dat[\"x509_certificate\"][\"text\"])\n                                if cert not in res:\n                                    res.append(cert)\n                        elif not \"use\" in key:\n                            for dat in key[\"key_info\"][\"x509_data\"]:\n                                cert = repack_cert(\n                                    dat[\"x509_certificate\"][\"text\"])\n                                if cert not in res:\n                                    res.append(cert)\n\n            return res\n\n        if descriptor == \"any\":\n            res = []\n            for descr in [\"spsso\", \"idpsso\", \"role\", \"authn_authority\",\n                          \"attribute_authority\", \"pdp\"]:\n                try:\n                    srvs = ent[\"%s_descriptor\" % descr]\n                except KeyError:\n                    continue\n\n                res.extend(extract_certs(srvs))\n        else:\n            srvs = ent[\"%s_descriptor\" % descriptor]\n            res = extract_certs(srvs)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets me all services with a specified entity ID and type that supports the specified version of binding.", "response": "def service(self, entity_id, typ, service, binding=None):\n        \"\"\" Get me all services with a specified\n        entity ID and type, that supports the specified version of binding.\n\n        :param entity_id: The EntityId\n        :param typ: Type of service (idp, attribute_authority, ...)\n        :param service: which service that is sought for\n        :param binding: A binding identifier\n        :return: list of service descriptions.\n            Or if no binding was specified a list of 2-tuples (binding, srv)\n        \"\"\"\n        try:\n            srvs = []\n            for t in self[entity_id][typ]:\n                try:\n                    srvs.extend(t[service])\n                except KeyError:\n                    pass\n        except KeyError:\n            return None\n\n        if not srvs:\n            return srvs\n\n        if binding:\n            res = []\n            for srv in srvs:\n                if srv[\"binding\"] == binding:\n                    res.append(srv)\n        else:\n            res = {}\n            for srv in srvs:\n                try:\n                    res[srv[\"binding\"]].append(srv)\n                except KeyError:\n                    res[srv[\"binding\"]] = [srv]\n        logger.debug(\"service => %s\", res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attribute_requirement(self, entity_id, index=None):\n        res = {\"required\": [], \"optional\": []}\n\n        try:\n            for sp in self[entity_id][\"spsso_descriptor\"]:\n                _res = attribute_requirement(sp, index)\n                res[\"required\"].extend(_res[\"required\"])\n                res[\"optional\"].extend(_res[\"optional\"])\n        except KeyError:\n            return None\n\n        return res", "response": "Returns what attributes the SP requires and which are optional if any such demands are registered in the Metadata."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting metadata by HTTP GET.", "response": "def load(self, *args, **kwargs):\n        \"\"\" Imports metadata by the use of HTTP GET.\n        If the fingerprint is known the file will be checked for\n        compliance before it is imported.\n        \"\"\"\n        response = self.http.send(self.url)\n        if response.status_code == 200:\n            _txt = response.content\n            return self.parse_and_check_signature(_txt)\n        else:\n            logger.info(\"Response status: %s\", response.status_code)\n            raise SourceNotFound(self.url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef entity_categories(self, entity_id):\n        attributes = self.entity_attributes(entity_id)\n        return attributes.get(ENTITY_CATEGORY, [])", "response": "Get a list of entity categories for an entity id."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of entity category support for an entity id.", "response": "def supported_entity_categories(self, entity_id):\n        \"\"\"\n        Get a list of entity category support for an entity id.\n\n        :param entity_id: Entity id\n        :return: Entity category support\n\n        :type entity_id: string\n        :rtype: [string]\n        \"\"\"\n        attributes = self.entity_attributes(entity_id)\n        return attributes.get(ENTITY_CATEGORY_SUPPORT, [])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef entity_attributes(self, entity_id):\n        res = {}\n        try:\n            ext = self.__getitem__(entity_id)[\"extensions\"]\n        except KeyError:\n            return res\n        for elem in ext[\"extension_elements\"]:\n            if elem[\"__class__\"] == ENTITYATTRIBUTES:\n                for attr in elem[\"attribute\"]:\n                    if attr[\"name\"] not in res:\n                        res[attr[\"name\"]] = []\n                    res[attr[\"name\"]] += [v[\"text\"] for v in attr[\n                        \"attribute_value\"]]\n        return res", "response": "Get all entity attributes for an entry in the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dumps(self, format=\"local\"):\n        if format == \"local\":\n            res = EntitiesDescriptor()\n            for _md in self.metadata.values():\n                try:\n                    res.entity_descriptor.extend(\n                        _md.entities_descr.entity_descriptor)\n                except AttributeError:\n                    res.entity_descriptor.append(_md.entity_descr)\n\n            return \"%s\" % res\n        elif format == \"md\":\n            return json.dumps(self.items(), indent=2)", "response": "Dumps the content in the specified format or the pysaml2 metadata format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef http_form_post_message(message, location, relay_state=\"\",\n                           typ=\"SAMLRequest\", **kwargs):\n    \"\"\"The HTTP POST binding defines a mechanism by which SAML protocol\n    messages may be transmitted within the base64-encoded content of a\n    HTML form control.\n\n    :param message: The message\n    :param location: Where the form should be posted to\n    :param relay_state: for preserving and conveying state information\n    :return: A tuple containing header information and a HTML message.\n    \"\"\"\n    if not isinstance(message, six.string_types):\n        message = str(message)\n    if not isinstance(message, six.binary_type):\n        message = message.encode('utf-8')\n\n    if typ == \"SAMLRequest\" or typ == \"SAMLResponse\":\n        _msg = base64.b64encode(message)\n    else:\n        _msg = message\n    _msg = _msg.decode('ascii')\n\n    saml_response_input = HTML_INPUT_ELEMENT_SPEC.format(\n            name=cgi.escape(typ),\n            val=cgi.escape(_msg),\n            type='hidden')\n\n    relay_state_input = \"\"\n    if relay_state:\n        relay_state_input = HTML_INPUT_ELEMENT_SPEC.format(\n                name='RelayState',\n                val=cgi.escape(relay_state),\n                type='hidden')\n\n    response = HTML_FORM_SPEC.format(\n        saml_response_input=saml_response_input,\n        relay_state_input=relay_state_input,\n        action=location)\n\n    return {\"headers\": [(\"Content-type\", \"text/html\")], \"data\": response}", "response": "This function is used to create an HTTP POST request for a new HTTP page."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a SOAP envelope containing a SAML thingy.", "response": "def make_soap_enveloped_saml_thingy(thingy, header_parts=None):\n    \"\"\" Returns a soap envelope containing a SAML request\n    as a text string.\n\n    :param thingy: The SAML thingy\n    :return: The SOAP envelope as a string\n    \"\"\"\n    envelope = ElementTree.Element('')\n    envelope.tag = '{%s}Envelope' % NAMESPACE\n\n    if header_parts:\n        header = ElementTree.Element('')\n        header.tag = '{%s}Header' % NAMESPACE\n        envelope.append(header)\n        for part in header_parts:\n            # This doesn't work if the headers are signed\n            part.become_child_element_of(header)\n\n    body = ElementTree.Element('')\n    body.tag = '{%s}Body' % NAMESPACE\n    envelope.append(body)\n\n    if isinstance(thingy, six.string_types):\n        # remove the first XML version/encoding line\n        if thingy[0:5].lower() == '<?xml':\n            logger.debug(\"thingy0: %s\", thingy)\n            _part = thingy.split(\"\\n\")\n            thingy = \"\".join(_part[1:])\n        thingy = thingy.replace(PREFIX, \"\")\n        logger.debug(\"thingy: %s\", thingy)\n        _child = ElementTree.Element('')\n        _child.tag = '{%s}FuddleMuddle' % DUMMY_NAMESPACE\n        body.append(_child)\n        _str = ElementTree.tostring(envelope, encoding=\"UTF-8\")\n        if isinstance(_str, six.binary_type):\n            _str = _str.decode('utf-8')\n        logger.debug(\"SOAP precursor: %s\", _str)\n        # find an remove the namespace definition\n        i = _str.find(DUMMY_NAMESPACE)\n        j = _str.rfind(\"xmlns:\", 0, i)\n        cut1 = _str[j:i + len(DUMMY_NAMESPACE) + 1]\n        _str = _str.replace(cut1, \"\")\n        first = _str.find(\"<%s:FuddleMuddle\" % (cut1[6:9],))\n        last = _str.find(\">\", first + 14)\n        cut2 = _str[first:last + 1]\n        return _str.replace(cut2, thingy)\n    else:\n        thingy.become_child_element_of(body)\n        return ElementTree.tostring(envelope, encoding=\"UTF-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a SOAP enveloped SAML thing and returns header parts and body as saml. samlbase instances.", "response": "def parse_soap_enveloped_saml(text, body_class, header_class=None):\n    \"\"\"Parses a SOAP enveloped SAML thing and returns header parts and body\n\n    :param text: The SOAP object as XML\n    :return: header parts and body as saml.samlbase instances\n    \"\"\"\n    envelope = defusedxml.ElementTree.fromstring(text)\n    assert envelope.tag == '{%s}Envelope' % NAMESPACE\n\n    # print(len(envelope))\n    body = None\n    header = {}\n    for part in envelope:\n        # print(\">\",part.tag)\n        if part.tag == '{%s}Body' % NAMESPACE:\n            for sub in part:\n                try:\n                    body = saml2.create_class_from_element_tree(\n                            body_class, sub)\n                except Exception:\n                    raise Exception(\n                        \"Wrong body type (%s) in SOAP envelope\" % sub.tag)\n        elif part.tag == '{%s}Header' % NAMESPACE:\n            if not header_class:\n                raise Exception(\"Header where I didn't expect one\")\n            # print(\"--- HEADER ---\")\n            for sub in part:\n                # print(\">>\",sub.tag)\n                for klass in header_class:\n                    # print(\"?{%s}%s\" % (klass.c_namespace,klass.c_tag))\n                    if sub.tag == \"{%s}%s\" % (klass.c_namespace, klass.c_tag):\n                        header[sub.tag] = \\\n                            saml2.create_class_from_element_tree(klass, sub)\n                        break\n\n    return body, header"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, cnf, metadata_construction=False):\n        _uc = self.unicode_convert\n        for arg in COMMON_ARGS:\n            if arg == \"virtual_organization\":\n                if \"virtual_organization\" in cnf:\n                    for key, val in cnf[\"virtual_organization\"].items():\n                        self.vorg[key] = VirtualOrg(None, key, val)\n                continue\n            elif arg == \"extension_schemas\":\n                # List of filename of modules representing the schemas\n                if \"extension_schemas\" in cnf:\n                    for mod_file in cnf[\"extension_schemas\"]:\n                        _mod = self._load(mod_file)\n                        self.extension_schema[_mod.NAMESPACE] = _mod\n\n            try:\n                setattr(self, arg, _uc(cnf[arg]))\n            except KeyError:\n                pass\n            except TypeError:  # Something that can't be a string\n                setattr(self, arg, cnf[arg])\n\n        if \"service\" in cnf:\n            for typ in [\"aa\", \"idp\", \"sp\", \"pdp\", \"aq\"]:\n                try:\n                    self.load_special(\n                        cnf[\"service\"][typ], typ,\n                        metadata_construction=metadata_construction)\n                    self.serves.append(typ)\n                except KeyError:\n                    pass\n\n        if \"extensions\" in cnf:\n            self.do_extensions(cnf[\"extensions\"])\n\n        self.load_complex(cnf, metadata_construction=metadata_construction)\n        self.context = self.def_context\n\n        return self", "response": "This method loads the configuration and returns the Configuration instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_metadata(self, metadata_conf):\n\n        acs = self.attribute_converters\n\n        if acs is None:\n            raise ConfigurationError(\n                \"Missing attribute converter specification\")\n\n        try:\n            ca_certs = self.ca_certs\n        except:\n            ca_certs = None\n        try:\n            disable_validation = self.disable_ssl_certificate_validation\n        except:\n            disable_validation = False\n\n        mds = MetadataStore(acs, self, ca_certs,\n            disable_ssl_certificate_validation=disable_validation)\n\n        mds.imp(metadata_conf)\n\n        return mds", "response": "Loads the metadata into an internal structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef endpoint(self, service, binding=None, context=None):\n        spec = []\n        unspec = []\n        endps = self.getattr(\"endpoints\", context)\n        if endps and service in endps:\n            for endpspec in endps[service]:\n                try:\n                    endp, bind = endpspec\n                    if binding is None or bind == binding:\n                        spec.append(endp)\n                except ValueError:\n                    unspec.append(endpspec)\n\n        if spec:\n            return spec\n        else:\n            return unspec", "response": "Goes through the list of endpoint specifications for the given type of service and returns a list of endpoints that match the given restrictions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef service_per_endpoint(self, context=None):\n        endps = self.getattr(\"endpoints\", context)\n        res = {}\n        for service, specs in endps.items():\n            for endp, binding in specs:\n                res[endp] = (service, binding)\n        return res", "response": "List all endpoint urls that are behind the endpoint\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ecp_endpoint(self, ipaddress):\n        _ecp = self.getattr(\"ecp\")\n        if _ecp:\n            for key, eid in _ecp.items():\n                if re.match(key, ipaddress):\n                    return eid\n\n        return None", "response": "Returns the entity ID of the ECP client which the user should talk to"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef members_to_ask(self, name_id):\n\n        vo_members = self._affiliation_members()\n        for member in self.member:\n            if member not in vo_members:\n                vo_members.append(member)\n\n        # Remove the ones I have cached data from about this subject\n        vo_members = [m for m in vo_members if not self.sp.users.cache.active(\n            name_id, m)]\n        logger.info(\"VO members (not cached): %s\", vo_members)\n        return vo_members", "response": "Find the members that I haven t already already"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs the URL that the user used when the process where interupted is for single - sign - on processing.", "response": "def construct_came_from(environ):\n    \"\"\" The URL that the user used when the process where interupted\n    for single-sign-on processing. \"\"\"\n\n    came_from = environ.get(\"PATH_INFO\")\n    qstr = environ.get(\"QUERY_STRING\", \"\")\n    if qstr:\n        came_from += \"?\" + qstr\n    return came_from"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef for_me(conditions, myself):\n\n    if not conditions.audience_restriction:  # No audience restriction\n        return True\n\n    for restriction in conditions.audience_restriction:\n        if not restriction.audience:\n            continue\n        for audience in restriction.audience:\n            if audience.text.strip() == myself:\n                return True\n            else:\n                # print(\"Not for me: %s != %s\" % (audience.text.strip(),\n                # myself))\n                pass\n\n    return False", "response": "Returns True if the user is in the list of audiences that are in the list of intended audiences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef issue_instant_ok(self):\n        upper = time_util.shift_time(time_util.time_in_a_while(days=1),\n                                     self.timeslack).timetuple()\n        lower = time_util.shift_time(time_util.time_a_while_ago(days=1),\n                                     -self.timeslack).timetuple()\n        # print(\"issue_instant: %s\" % self.response.issue_instant)\n        # print(\"%s < x < %s\" % (lower, upper))\n        issued_at = str_to_time(self.response.issue_instant)\n        return lower < issued_at < upper", "response": "Check that the response was issued at a reasonable time"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt_attributes(self, attribute_statement):\n        #        _node_name = [\n        #            \"urn:oasis:names:tc:SAML:2.0:assertion:EncryptedData\",\n        #            \"urn:oasis:names:tc:SAML:2.0:assertion:EncryptedAttribute\"]\n\n        for encattr in attribute_statement.encrypted_attribute:\n            if not encattr.encrypted_key:\n                _decr = self.sec.decrypt(encattr.encrypted_data)\n                _attr = attribute_from_string(_decr)\n                attribute_statement.attribute.append(_attr)\n            else:\n                _decr = self.sec.decrypt(encattr)\n                enc_attr = encrypted_attribute_from_string(_decr)\n                attrlist = enc_attr.extensions_as_elements(\"Attribute\", saml)\n                attribute_statement.attribute.extend(attrlist)", "response": "Decrypts possible encrypted attributes and adds the decrypts to the attribute list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_identity(self):\n        ava = {}\n        for _assertion in self.assertions:\n            if _assertion.advice:\n                if _assertion.advice.assertion:\n                    for tmp_assertion in _assertion.advice.assertion:\n                        if tmp_assertion.attribute_statement:\n                            assert len(tmp_assertion.attribute_statement) == 1\n                            ava.update(self.read_attribute_statement(\n                                tmp_assertion.attribute_statement[0]))\n            if _assertion.attribute_statement:\n                logger.debug(\"Assertion contains %s attribute statement(s)\",\n                             (len(self.assertion.attribute_statement)))\n                for _attr_statem in _assertion.attribute_statement:\n                    logger.debug(\"Attribute Statement: %s\" % (_attr_statem,))\n                    ava.update(self.read_attribute_statement(_attr_statem))\n            if not ava:\n                logger.debug(\"Assertion contains no attribute statements\")\n        return ava", "response": "Get identity of the assertion."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the Subject object from the assertion.", "response": "def get_subject(self):\n        \"\"\" The assertion must contain a Subject\n        \"\"\"\n        assert self.assertion.subject\n        subject = self.assertion.subject\n        subjconf = []\n\n        if not self.verify_attesting_entity(subject.subject_confirmation):\n            raise VerificationError(\"No valid attesting address\")\n\n        for subject_confirmation in subject.subject_confirmation:\n            _data = subject_confirmation.subject_confirmation_data\n\n            if subject_confirmation.method == SCM_BEARER:\n                if not self._bearer_confirmed(_data):\n                    continue\n            elif subject_confirmation.method == SCM_HOLDER_OF_KEY:\n                if not self._holder_of_key_confirmed(_data):\n                    continue\n            elif subject_confirmation.method == SCM_SENDER_VOUCHES:\n                pass\n            else:\n                raise ValueError(\"Unknown subject confirmation method: %s\" % (\n                    subject_confirmation.method,))\n\n            _recip = _data.recipient\n            if not _recip or not self.verify_recipient(_recip):\n                raise VerificationError(\"No valid recipient\")\n\n            subjconf.append(subject_confirmation)\n\n        if not subjconf:\n            raise VerificationError(\"No valid subject confirmation\")\n\n        subject.subject_confirmation = subjconf\n\n        # The subject may contain a name_id\n\n        if subject.name_id:\n            self.name_id = subject.name_id\n        elif subject.encrypted_id:\n            # decrypt encrypted ID\n            _name_id_str = self.sec.decrypt(\n                subject.encrypted_id.encrypted_data.to_string())\n            _name_id = saml.name_id_from_string(_name_id_str)\n            self.name_id = _name_id\n\n        logger.info(\"Subject NameID: %s\", self.name_id)\n        return self.name_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the assertion and return True or False depending on if the assertion is sane or not", "response": "def _assertion(self, assertion, verified=False):\n        \"\"\"\n        Check the assertion\n        :param assertion:\n        :return: True/False depending on if the assertion is sane or not\n        \"\"\"\n\n        if not hasattr(assertion, 'signature') or not assertion.signature:\n            logger.debug(\"unsigned\")\n            if self.require_signature:\n                raise SignatureError(\"Signature missing for assertion\")\n        else:\n            logger.debug(\"signed\")\n            if not verified and self.do_not_verify is False:\n                try:\n                    self.sec.check_signature(assertion, class_name(assertion),\n                                             self.xmlstr)\n                except Exception as exc:\n                    logger.error(\"correctly_signed_response: %s\", exc)\n                    raise\n\n        self.assertion = assertion\n        logger.debug(\"assertion context: %s\", self.context)\n        logger.debug(\"assertion keys: %s\", assertion.keyswv())\n        logger.debug(\"outstanding_queries: %s\", self.outstanding_queries)\n\n        # if self.context == \"AuthnReq\" or self.context == \"AttrQuery\":\n        if self.context == \"AuthnReq\":\n            self.authn_statement_ok()\n        # elif self.context == \"AttrQuery\":\n        #            self.authn_statement_ok(True)\n\n        if not self.condition_ok():\n            raise VerificationError(\"Condition not OK\")\n\n        logger.debug(\"--- Getting Identity ---\")\n\n        # if self.context == \"AuthnReq\" or self.context == \"AttrQuery\":\n        #    self.ava = self.get_identity()\n        #    logger.debug(\"--- AVA: %s\", self.ava)\n\n        try:\n            self.get_subject()\n            if self.asynchop:\n                if self.allow_unsolicited:\n                    pass\n                elif self.came_from is None:\n                    raise VerificationError(\"Came from\")\n            return True\n        except Exception:\n            logger.exception(\"get subject\")\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decrypt_assertions(self, encrypted_assertions, decr_txt, issuer=None,\n            verified=False):\n        \"\"\" Moves the decrypted assertion from the encrypted assertion to a\n        list.\n\n        :param encrypted_assertions: A list of encrypted assertions.\n        :param decr_txt: The string representation containing the decrypted\n        data. Used when verifying signatures.\n        :param issuer: The issuer of the response.\n        :param verified: If True do not verify signatures, otherwise verify\n        the signature if it exists.\n        :return: A list of decrypted assertions.\n        \"\"\"\n        res = []\n        for encrypted_assertion in encrypted_assertions:\n            if encrypted_assertion.extension_elements:\n                assertions = extension_elements_to_elements(\n                    encrypted_assertion.extension_elements, [saml, samlp])\n                for assertion in assertions:\n                    if assertion.signature and not verified:\n                        if not self.sec.check_signature(\n                                assertion, origdoc=decr_txt,\n                                node_name=class_name(assertion), issuer=issuer):\n                            logger.error(\"Failed to verify signature on '%s'\",\n                                         assertion)\n                            raise SignatureError()\n                    res.append(assertion)\n        return res", "response": "Takes the list of encrypted assertions and decrypts them and returns a list of decrypted assertions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a list of assertions contains encrypted data in the COOKIE element.", "response": "def find_encrypt_data_assertion_list(self, _assertions):\n        \"\"\" Verifies if a list of assertions contains encrypted data in the\n        advice element.\n\n        :param _assertions: A list of assertions.\n        :return: True encrypted data exists otherwise false.\n        \"\"\"\n        for _assertion in _assertions:\n            if _assertion.advice:\n                if _assertion.advice.encrypted_assertion:\n                    res = self.find_encrypt_data_assertion(\n                        _assertion.advice.encrypted_assertion)\n                    if res:\n                        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying if a response contains encrypted assertions with a specific ID and encrypted data.", "response": "def find_encrypt_data(self, resp):\n        \"\"\" Verifies if a saml response contains encrypted assertions with\n        encrypted data.\n\n        :param resp: A saml response.\n        :return: True encrypted data exists otherwise false.\n        \"\"\"\n        if resp.encrypted_assertion:\n            res = self.find_encrypt_data_assertion(resp.encrypted_assertion)\n            if res:\n                return True\n        if resp.assertion:\n            for tmp_assertion in resp.assertion:\n                if tmp_assertion.advice:\n                    if tmp_assertion.advice.encrypted_assertion:\n                        res = self.find_encrypt_data_assertion(\n                            tmp_assertion.advice.encrypted_assertion)\n                        if res:\n                            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the assertion for a SAML response.", "response": "def parse_assertion(self, keys=None):\n        \"\"\" Parse the assertions for a saml response.\n\n        :param keys: A string representing a RSA key or a list of strings\n        containing RSA keys.\n        :return: True if the assertions are parsed otherwise False.\n        \"\"\"\n        if self.context == \"AuthnQuery\":\n            # can contain one or more assertions\n            pass\n        else:\n            # This is a saml2int limitation\n            try:\n                assert (\n                    len(self.response.assertion) == 1\n                    or len(self.response.encrypted_assertion) == 1\n                    or self.assertion is not None\n                )\n            except AssertionError:\n                raise Exception(\"No assertion part\")\n\n        if self.response.assertion:\n            logger.debug(\"***Unencrypted assertion***\")\n            for assertion in self.response.assertion:\n                if not self._assertion(assertion, False):\n                    return False\n\n        if self.find_encrypt_data(self.response):\n            logger.debug(\"***Encrypted assertion/-s***\")\n            _enc_assertions = []\n            resp = self.response\n            decr_text = str(self.response)\n\n            decr_text_old = None\n            while self.find_encrypt_data(resp) and decr_text_old != decr_text:\n                decr_text_old = decr_text\n                try:\n                    decr_text = self.sec.decrypt_keys(decr_text, keys)\n                except DecryptError as e:\n                    continue\n                else:\n                    resp = samlp.response_from_string(decr_text)\n                    # check and prepare for comparison between str and unicode\n                    if type(decr_text_old) != type(decr_text):\n                        if isinstance(decr_text_old, six.binary_type):\n                            decr_text_old = decr_text_old.decode(\"utf-8\")\n                        else:\n                            decr_text_old = decr_text_old.encode(\"utf-8\")\n\n            _enc_assertions = self.decrypt_assertions(\n                resp.encrypted_assertion, decr_text\n            )\n\n            decr_text_old = None\n            while (\n                self.find_encrypt_data(resp)\n                or self.find_encrypt_data_assertion_list(_enc_assertions)\n            ) and decr_text_old != decr_text:\n                decr_text_old = decr_text\n                try:\n                    decr_text = self.sec.decrypt_keys(decr_text, keys)\n                except DecryptError as e:\n                    continue\n                else:\n                    resp = samlp.response_from_string(decr_text)\n                    _enc_assertions = self.decrypt_assertions(\n                        resp.encrypted_assertion, decr_text, verified=True\n                    )\n                    # check and prepare for comparison between str and unicode\n                    if type(decr_text_old) != type(decr_text):\n                        if isinstance(decr_text_old, six.binary_type):\n                            decr_text_old = decr_text_old.decode(\"utf-8\")\n                        else:\n                            decr_text_old = decr_text_old.encode(\"utf-8\")\n\n            all_assertions = _enc_assertions\n            if resp.assertion:\n                all_assertions = all_assertions + resp.assertion\n\n            if len(all_assertions) > 0:\n                for tmp_ass in all_assertions:\n                    if tmp_ass.advice and tmp_ass.advice.encrypted_assertion:\n\n                        advice_res = self.decrypt_assertions(\n                            tmp_ass.advice.encrypted_assertion,\n                            decr_text,\n                            tmp_ass.issuer)\n                        if tmp_ass.advice.assertion:\n                            tmp_ass.advice.assertion.extend(advice_res)\n                        else:\n                            tmp_ass.advice.assertion = advice_res\n                        if len(advice_res) > 0:\n                            tmp_ass.advice.encrypted_assertion = []\n\n            self.response.assertion = resp.assertion\n            for assertion in _enc_assertions:\n                if not self._assertion(assertion, True):\n                    return False\n                else:\n                    self.assertions.append(assertion)\n\n            self.xmlstr = decr_text\n            if len(_enc_assertions) > 0:\n                self.response.encrypted_assertion = []\n\n        if self.response.assertion:\n            for assertion in self.response.assertion:\n                self.assertions.append(assertion)\n\n        if self.assertions and len(self.assertions) > 0:\n            self.assertion = self.assertions[0]\n\n        if self.context == \"AuthnReq\" or self.context == \"AttrQuery\":\n            self.ava = self.get_identity()\n            logger.debug(\"--- AVA: %s\", self.ava)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify(self, keys=None):\n\n        try:\n            res = self._verify()\n        except AssertionError as err:\n            logger.error(\"Verification error on the response: %s\", err)\n            raise\n        else:\n            if res is None:\n                return None\n\n        if not isinstance(self.response, samlp.Response):\n            return self\n\n        if self.parse_assertion(keys):\n            return self\n        else:\n            logger.error(\"Could not parse the assertion\")\n            return None", "response": "Verify that the assertion is syntactically correct and the key file is correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a predefined set of information gleened from the response.", "response": "def session_info(self):\n        \"\"\" Returns a predefined set of information gleened from the\n        response.\n        :returns: Dictionary with information\n        \"\"\"\n        if self.session_not_on_or_after > 0:\n            nooa = self.session_not_on_or_after\n        else:\n            nooa = self.not_on_or_after\n\n        if self.context == \"AuthzQuery\":\n            return {\"name_id\": self.name_id, \"came_from\": self.came_from,\n                    \"issuer\": self.issuer(), \"not_on_or_after\": nooa,\n                    \"authz_decision_info\": self.authz_decision_info()}\n        else:\n            authn_statement = self.assertion.authn_statement[0]\n            return {\"ava\": self.ava, \"name_id\": self.name_id,\n                    \"came_from\": self.came_from, \"issuer\": self.issuer(),\n                    \"not_on_or_after\": nooa, \"authn_info\": self.authn_info(),\n                    \"session_index\": authn_statement.session_index}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that the recipient is the recipient of the ancipline.", "response": "def verify_recipient(self, recipient):\n        \"\"\"\n        Verify that I'm the recipient of the assertion\n\n        :param recipient: A URI specifying the entity or location to which an\n            attesting entity can present the assertion.\n        :return: True/False\n        \"\"\"\n        if not self.conv_info:\n            return True\n\n        _info = self.conv_info\n\n        try:\n            if recipient == _info['entity_id']:\n                return True\n        except KeyError:\n            pass\n\n        try:\n            if recipient in self.return_addrs:\n                return True\n        except KeyError:\n            pass\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if some part of the document signed?", "response": "def signed(item):\n    \"\"\"\n    Is any part of the document signed ?\n\n    :param item: A Samlbase instance\n    :return: True if some part of it is signed\n    \"\"\"\n    if SIG in item.c_children.keys() and item.signature:\n        return True\n    else:\n        for prop in item.c_child_order:\n            child = getattr(item, prop, None)\n            if isinstance(child, list):\n                for chi in child:\n                    if signed(chi):\n                        return True\n            elif child and signed(child):\n                return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to find the xmlsec1 binary.", "response": "def get_xmlsec_binary(paths=None):\n    \"\"\"\n    Tries to find the xmlsec1 binary.\n\n    :param paths: Non-system path paths which should be searched when\n        looking for xmlsec1\n    :return: full name of the xmlsec1 binary found. If no binaries are\n        found then an exception is raised.\n    \"\"\"\n    if os.name == 'posix':\n        bin_name = ['xmlsec1']\n    elif os.name == 'nt':\n        bin_name = ['xmlsec.exe', 'xmlsec1.exe']\n    else:  # Default !?\n        bin_name = ['xmlsec1']\n\n    if paths:\n        for bname in bin_name:\n            for path in paths:\n                fil = os.path.join(path, bname)\n                try:\n                    if os.lstat(fil):\n                        return fil\n                except OSError:\n                    pass\n\n    for path in os.environ['PATH'].split(os.pathsep):\n        for bname in bin_name:\n            fil = os.path.join(path, bname)\n            try:\n                if os.lstat(fil):\n                    return fil\n            except OSError:\n                pass\n\n    raise SigverError('Cannot find {binary}'.format(binary=bin_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_xmlsec_cryptobackend(path=None, search_paths=None):\n    if path is None:\n        path = get_xmlsec_binary(paths=search_paths)\n    return CryptoBackendXmlSec1(path)", "response": "Initialize a CryptoBackendXmlSec1 crypto backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_vals(val, klass, seccont, klass_inst=None, prop=None, part=False,\n               base64encode=False, elements_to_sign=None):\n    \"\"\"\n    Creates a class instance with a specified value, the specified\n    class instance may be a value on a property in a defined class instance.\n\n    :param val: The value\n    :param klass: The value class\n    :param klass_inst: The class instance which has a property on which\n        what this function returns is a value.\n    :param prop: The property which the value should be assigned to.\n    :param part: If the value is one of a possible list of values it should be\n        handled slightly different compared to if it isn't.\n    :return: Value class instance\n    \"\"\"\n    cinst = None\n\n    if isinstance(val, dict):\n        cinst = _instance(klass, val, seccont, base64encode=base64encode,\n                          elements_to_sign=elements_to_sign)\n    else:\n        try:\n            cinst = klass().set_text(val)\n        except ValueError:\n            if not part:\n                cis = [\n                    _make_vals(\n                        sval,\n                        klass,\n                        seccont,\n                        klass_inst,\n                        prop,\n                        True,\n                        base64encode,\n                        elements_to_sign)\n                    for sval in val\n                ]\n                setattr(klass_inst, prop, cis)\n            else:\n                raise\n\n    if part:\n        return cinst\n    else:\n        if cinst:\n            cis = [cinst]\n            setattr(klass_inst, prop, cis)", "response": "Creates a value class instance with a specified value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_temp(string, suffix='', decode=True, delete=True):\n    ntf = NamedTemporaryFile(suffix=suffix, delete=delete)\n    # Python3 tempfile requires byte-like object\n    if not isinstance(string, six.binary_type):\n        string = string.encode('utf-8')\n\n    if decode:\n        ntf.write(base64.b64decode(string))\n    else:\n        ntf.write(string)\n    ntf.seek(0)\n    return ntf, ntf.name", "response": "This function creates a temporary file and returns the file pointer and filename of the temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that a key is active that is present time is before not_before and before not_after.", "response": "def active_cert(key):\n    \"\"\"\n    Verifies that a key is active that is present time is after not_before\n    and before not_after.\n\n    :param key: The Key\n    :return: True if the key is active else False\n    \"\"\"\n    try:\n        cert_str = pem_format(key)\n        cert = crypto.load_certificate(crypto.FILETYPE_PEM, cert_str)\n        assert cert.has_expired() == 0\n        assert not OpenSSLWrapper().certificate_not_valid_yet(cert)\n        return True\n    except AssertionError:\n        return False\n    except AttributeError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cert_from_key_info(key_info, ignore_age=False):\n    res = []\n    for x509_data in key_info.x509_data:\n        x509_certificate = x509_data.x509_certificate\n        cert = x509_certificate.text.strip()\n        cert = '\\n'.join(split_len(''.join([s.strip() for s in\n                                            cert.split()]), 64))\n        if ignore_age or active_cert(cert):\n            res.append(cert)\n        else:\n            logger.info('Inactive cert')\n    return res", "response": "Get all X509 certs from a KeyInfo instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind certificates that are part of an instance", "response": "def cert_from_instance(instance):\n    \"\"\" Find certificates that are part of an instance\n\n    :param instance: An instance\n    :return: possible empty list of certificates\n    \"\"\"\n    if instance.signature:\n        if instance.signature.key_info:\n            return cert_from_key_info(instance.signature.key_info,\n                                      ignore_age=True)\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_xmlsec_output(output):\n    for line in output.splitlines():\n        if line == 'OK':\n            return True\n        elif line == 'FAIL':\n            raise XmlsecError(output)\n    raise XmlsecError(output)", "response": "Parse the output from xmlsec to find out if the command was successfull or not."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_cert_from_file(cert_file, cert_type):\n\n    if not cert_file:\n        return ''\n\n    if cert_type == 'pem':\n        _a = read_file(cert_file, 'rb').decode()\n        _b = _a.replace('\\r\\n', '\\n')\n        lines = _b.split('\\n')\n\n        for pattern in (\n                '-----BEGIN CERTIFICATE-----',\n                '-----BEGIN PUBLIC KEY-----'):\n            if pattern in lines:\n                lines = lines[lines.index(pattern) + 1:]\n                break\n        else:\n            raise CertificateError('Strange beginning of PEM file')\n\n        for pattern in (\n                '-----END CERTIFICATE-----',\n                '-----END PUBLIC KEY-----'):\n            if pattern in lines:\n                lines = lines[:lines.index(pattern)]\n                break\n        else:\n            raise CertificateError('Strange end of PEM file')\n        return make_str(''.join(lines).encode())\n\n    if cert_type in ['der', 'cer', 'crt']:\n        data = read_file(cert_file, 'rb')\n        _cert = base64.b64encode(data)\n        return make_str(_cert)", "response": "Reads a certificate from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a security context based on the configuration.", "response": "def security_context(conf):\n    \"\"\" Creates a security context based on the configuration\n\n    :param conf: The configuration, this is a Config instance\n    :return: A SecurityContext instance\n    \"\"\"\n    if not conf:\n        return None\n\n    try:\n        metadata = conf.metadata\n    except AttributeError:\n        metadata = None\n\n    try:\n        id_attr = conf.id_attr_name\n    except AttributeError:\n        id_attr = None\n\n    sec_backend = None\n\n    if conf.crypto_backend == 'xmlsec1':\n        xmlsec_binary = conf.xmlsec_binary\n\n        if not xmlsec_binary:\n            try:\n                _path = conf.xmlsec_path\n            except AttributeError:\n                _path = []\n            xmlsec_binary = get_xmlsec_binary(_path)\n\n        # verify that xmlsec is where it's supposed to be\n        if not os.path.exists(xmlsec_binary):\n            # if not os.access(, os.F_OK):\n            err_msg = 'xmlsec binary not found: {binary}'\n            err_msg = err_msg.format(binary=xmlsec_binary)\n            raise SigverError(err_msg)\n\n        crypto = _get_xmlsec_cryptobackend(xmlsec_binary)\n\n        _file_name = conf.getattr('key_file', '')\n        if _file_name:\n            try:\n                rsa_key = import_rsa_key_from_file(_file_name)\n            except Exception as err:\n                logger.error('Cannot import key from {file}: {err_msg}'.format(\n                    file=_file_name, err_msg=err))\n                raise\n            else:\n                sec_backend = RSACrypto(rsa_key)\n    elif conf.crypto_backend == 'XMLSecurity':\n        # new and somewhat untested pyXMLSecurity crypto backend.\n        crypto = CryptoBackendXMLSecurity()\n    else:\n        err_msg = 'Unknown crypto_backend {backend}'\n        err_msg = err_msg.format(backend=conf.crypto_backend)\n        raise SigverError(err_msg)\n\n    enc_key_files = []\n    if conf.encryption_keypairs is not None:\n        for _encryption_keypair in conf.encryption_keypairs:\n            if 'key_file' in _encryption_keypair:\n                enc_key_files.append(_encryption_keypair['key_file'])\n\n    return SecurityContext(\n            crypto,\n            conf.key_file,\n            cert_file=conf.cert_file,\n            metadata=metadata,\n            only_use_keys_in_metadata=conf.only_use_keys_in_metadata,\n            cert_handler_extra_class=conf.cert_handler_extra_class,\n            generate_cert_info=conf.generate_cert_info,\n            tmp_cert_file=conf.tmp_cert_file,\n            tmp_key_file=conf.tmp_key_file,\n            validate_certificate=conf.validate_certificate,\n            enc_key_files=enc_key_files,\n            encryption_keypairs=conf.encryption_keypairs,\n            sec_backend=sec_backend,\n            id_attr=id_attr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves the assertion to within an encrypted_assertion", "response": "def pre_encrypt_assertion(response):\n    \"\"\"\n    Move the assertion to within a encrypted_assertion\n    :param response: The response with one assertion\n    :return: The response but now with the assertion within an\n        encrypted_assertion.\n    \"\"\"\n    assertion = response.assertion\n    response.assertion = None\n    response.encrypted_assertion = EncryptedAssertion()\n    if assertion is not None:\n        if isinstance(assertion, list):\n            response.encrypted_assertion.add_extension_elements(assertion)\n        else:\n            response.encrypted_assertion.add_extension_element(assertion)\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encrypt_assertion(self, statement, enc_key, template, key_type='des-192', node_xpath=None, node_id=None):\n        if six.PY2:\n            _str = unicode\n        else:\n            _str = str\n\n        if isinstance(statement, SamlBase):\n            statement = pre_encrypt_assertion(statement)\n\n        _, fil = make_temp(\n            _str(statement), decode=False, delete=self._xmlsec_delete_tmpfiles\n        )\n        _, tmpl = make_temp(_str(template), decode=False)\n\n        if not node_xpath:\n            node_xpath = ASSERT_XPATH\n\n        com_list = [\n            self.xmlsec,\n            '--encrypt',\n            '--pubkey-cert-pem', enc_key,\n            '--session-key', key_type,\n            '--xml-data', fil,\n            '--node-xpath', node_xpath,\n        ]\n\n        if node_id:\n            com_list.extend(['--node-id', node_id])\n\n        try:\n            (_stdout, _stderr, output) = self._run_xmlsec(com_list, [tmpl])\n        except XmlsecError as e:\n            six.raise_from(EncryptError(com_list), e)\n\n        return output.decode('utf-8')", "response": "Encrypt an assertion with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsigning an XML statement.", "response": "def sign_statement(self, statement, node_name, key_file, node_id, id_attr):\n        \"\"\"\n        Sign an XML statement.\n\n        :param statement: The statement to be signed\n        :param node_name: string like 'urn:oasis:names:...:Assertion'\n        :param key_file: The file where the key can be found\n        :param node_id:\n        :param id_attr: The attribute name for the identifier, normally one of\n            'id','Id' or 'ID'\n        :return: The signed statement\n        \"\"\"\n        if isinstance(statement, SamlBase):\n            statement = str(statement)\n\n        _, fil = make_temp(\n            statement,\n            suffix='.xml',\n            decode=False,\n            delete=self._xmlsec_delete_tmpfiles,\n        )\n\n        com_list = [\n            self.xmlsec,\n            '--sign',\n            '--privkey-pem', key_file,\n            '--id-attr:{id_attr_name}'.format(id_attr_name=id_attr),\n            node_name,\n        ]\n\n        if node_id:\n            com_list.extend(['--node-id', node_id])\n\n        try:\n            (stdout, stderr, output) = self._run_xmlsec(com_list, [fil])\n        except XmlsecError as e:\n            raise SignatureError(com_list)\n\n        # this does not work if --store-signatures is used\n        if output:\n            return output.decode(\"utf-8\")\n        if stdout:\n            return stdout.decode(\"utf-8\")\n        raise SignatureError(stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_signature(self, signedtext, cert_file, cert_type, node_name, node_id, id_attr):\n        if not isinstance(signedtext, six.binary_type):\n            signedtext = signedtext.encode('utf-8')\n\n        _, fil = make_temp(\n            signedtext,\n            suffix='.xml',\n            decode=False,\n            delete=self._xmlsec_delete_tmpfiles,\n        )\n\n        com_list = [\n            self.xmlsec,\n            '--verify',\n            '--enabled-reference-uris', 'empty,same-doc',\n            '--pubkey-cert-{type}'.format(type=cert_type), cert_file,\n            '--id-attr:{id_attr_name}'.format(id_attr_name=id_attr),\n            node_name,\n        ]\n\n        if node_id:\n            com_list.extend(['--node-id', node_id])\n\n        try:\n            (_stdout, stderr, _output) = self._run_xmlsec(com_list, [fil])\n        except XmlsecError as e:\n            six.raise_from(SignatureError(com_list), e)\n\n        return parse_xmlsec_output(stderr)", "response": "Validate the signature on the XML document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _run_xmlsec(self, com_list, extra_args):\n        with NamedTemporaryFile(suffix='.xml', delete=self._xmlsec_delete_tmpfiles) as ntf:\n            com_list.extend(['--output', ntf.name])\n            com_list += extra_args\n\n            logger.debug('xmlsec command: %s', ' '.join(com_list))\n\n            pof = Popen(com_list, stderr=PIPE, stdout=PIPE)\n            p_out, p_err = pof.communicate()\n            p_out = p_out.decode()\n            p_err = p_err.decode()\n\n            if pof.returncode != 0:\n                errmsg = \"returncode={code}\\nerror={err}\\noutput={out}\".format(\n                    code=pof.returncode, err=p_err, out=p_out\n                )\n                logger.error(errmsg)\n                raise XmlsecError(errmsg)\n\n            ntf.seek(0)\n            return p_out, p_err, ntf.read()", "response": "This method is used to invoke xmlsec and parse the output of xmlsec."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sign_statement(self, statement, node_name, key_file, node_id, id_attr):\n        import xmlsec\n        import lxml.etree\n\n        xml = xmlsec.parse_xml(statement)\n        signed = xmlsec.sign(xml, key_file)\n        signed_str = lxml.etree.tostring(signed, xml_declaration=False, encoding=\"UTF-8\")\n        if not isinstance(signed_str, six.string_types):\n            signed_str = signed_str.decode(\"utf-8\")\n        return signed_str", "response": "Sign an XML statement."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_signature(self, signedtext, cert_file, cert_type, node_name, node_id, id_attr):\n        if cert_type != 'pem':\n            raise Unsupported('Only PEM certs supported here')\n\n        import xmlsec\n        xml = xmlsec.parse_xml(signedtext)\n\n        try:\n            return xmlsec.verify(xml, cert_file)\n        except xmlsec.XMLSigException:\n            return False", "response": "Validate the signature on XML document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encrypt(self, text, recv_key='', template='', key_type=''):\n        if not key_type:\n            key_type = self.encrypt_key_type\n        if not template:\n            template = self.template\n\n        return self.crypto.encrypt(text, recv_key, template, key_type)", "response": "Encrypt the text with the specified key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts an assertion with a key and a template", "response": "def encrypt_assertion(self, statement, enc_key, template, key_type='des-192', node_xpath=None):\n        \"\"\"\n        Will encrypt an assertion\n\n        :param statement: A XML document that contains the assertion to encrypt\n        :param enc_key: File name of a file containing the encryption key\n        :param template: A template for the encryption part to be added.\n        :param key_type: The type of session key to use.\n        :return: The encrypted text\n        \"\"\"\n        return self.crypto.encrypt_assertion(\n                statement, enc_key, template, key_type, node_xpath)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrypt_keys(self, enctext, keys=None, id_attr=''):\n        key_files = []\n\n        if not isinstance(keys, list):\n            keys = [keys]\n\n        keys = [key for key in keys if key]\n        for key in keys:\n            if not isinstance(key, six.binary_type):\n                key = key.encode(\"ascii\")\n            _, key_file = make_temp(key, decode=False, delete=False)\n            key_files.append(key_file)\n\n        try:\n            dectext = self.decrypt(enctext, key_file=key_files, id_attr=id_attr)\n        except DecryptError as e:\n            raise\n        else:\n            return dectext\n        finally:\n            for key_file in key_files:\n                os.unlink(key_file)", "response": "Decrypt an encrypted text by using a private key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying the signature of a XML document.", "response": "def verify_signature(self, signedtext, cert_file=None, cert_type='pem', node_name=NODE_NAME, node_id=None, id_attr=''):\n        \"\"\" Verifies the signature of a XML document.\n\n        :param signedtext: The XML document as a string\n        :param cert_file: The public key that was used to sign the document\n        :param cert_type: The file type of the certificate\n        :param node_name: The name of the class that is signed\n        :param node_id: The identifier of the node\n        :param id_attr: The attribute name for the identifier, normally one of\n            'id','Id' or 'ID'\n        :return: Boolean True if the signature was correct otherwise False.\n        \"\"\"\n        # This is only for testing purposes, otherwise when would you receive\n        # stuff that is signed with your key !?\n        if not cert_file:\n            cert_file = self.cert_file\n            cert_type = self.cert_type\n\n        if not id_attr:\n            id_attr = self.id_attr\n\n        return self.crypto.validate_signature(\n                signedtext,\n                cert_file=cert_file,\n                cert_type=cert_type,\n                node_name=node_name,\n                node_id=node_id,\n                id_attr=id_attr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a request is correctly signed.", "response": "def correctly_signed_message(self, decoded_xml, msgtype, must=False, origdoc=None, only_valid_cert=False):\n        \"\"\"Check if a request is correctly signed, if we have metadata for\n        the entity that sent the info use that, if not use the key that are in\n        the message if any.\n\n        :param decoded_xml: The SAML message as an XML infoset (a string)\n        :param msgtype: SAML protocol message type\n        :param must: Whether there must be a signature\n        :param origdoc:\n        :return:\n        \"\"\"\n\n        attr = '{type}_from_string'.format(type=msgtype)\n        _func = getattr(saml, attr, None)\n        _func = getattr(samlp, attr, _func)\n\n        msg = _func(decoded_xml)\n        if not msg:\n            raise TypeError('Not a {type}'.format(type=msgtype))\n\n        if not msg.signature:\n            if must:\n                err_msg = 'Required signature missing on {type}'\n                err_msg = err_msg.format(type=msgtype)\n                raise SignatureError(err_msg)\n            else:\n                return msg\n\n        return self._check_signature(\n                decoded_xml,\n                msg,\n                class_name(msg),\n                origdoc,\n                must=must,\n                only_valid_cert=only_valid_cert)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a response is correctly signed.", "response": "def correctly_signed_response(self, decoded_xml, must=False, origdoc=None, only_valid_cert=False, require_response_signature=False, **kwargs):\n        \"\"\" Check if a instance is correctly signed, if we have metadata for\n        the IdP that sent the info use that, if not use the key that are in\n        the message if any.\n\n        :param decoded_xml: The SAML message as a XML string\n        :param must: Whether there must be a signature\n        :param origdoc:\n        :param only_valid_cert:\n        :param require_response_signature:\n        :return: None if the signature can not be verified otherwise an instance\n        \"\"\"\n\n        response = samlp.any_response_from_string(decoded_xml)\n        if not response:\n            raise TypeError('Not a Response')\n\n        if response.signature:\n            if 'do_not_verify' in kwargs:\n                pass\n            else:\n                self._check_signature(decoded_xml, response,\n                                      class_name(response), origdoc)\n        elif require_response_signature:\n            raise SignatureError('Signature missing for response')\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sign_statement(self, statement, node_name, key=None, key_file=None, node_id=None, id_attr=''):\n        if not id_attr:\n            id_attr = self.id_attr\n\n        if not key_file and key:\n            _, key_file = make_temp(str(key).encode(), '.pem')\n\n        if not key and not key_file:\n            key_file = self.key_file\n\n        return self.crypto.sign_statement(\n                statement,\n                node_name,\n                key_file,\n                node_id,\n                id_attr)", "response": "Sign a SAML statement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsigning an Assertion using XMLSEC.", "response": "def sign_assertion_using_xmlsec(self, statement, **kwargs):\n        \"\"\" Deprecated function. See sign_assertion(). \"\"\"\n        return self.sign_statement(\n                statement, class_name(saml.Assertion()), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sign_assertion(self, statement, **kwargs):\n        return self.sign_statement(\n                statement, class_name(saml.Assertion()), **kwargs)", "response": "Sign a SAML assertion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sign_attribute_query(self, statement, **kwargs):\n        return self.sign_statement(\n                statement, class_name(samlp.AttributeQuery()), **kwargs)", "response": "Sign a SAML attribute query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multiple_signatures(self, statement, to_sign, key=None, key_file=None, sign_alg=None, digest_alg=None):\n        for (item, sid, id_attr) in to_sign:\n            if not sid:\n                if not item.id:\n                    sid = item.id = sid()\n                else:\n                    sid = item.id\n\n            if not item.signature:\n                item.signature = pre_signature_part(\n                        sid,\n                        self.cert_file,\n                        sign_alg=sign_alg,\n                        digest_alg=digest_alg)\n\n            statement = self.sign_statement(\n                    statement,\n                    class_name(item),\n                    key=key,\n                    key_file=key_file,\n                    node_id=sid,\n                    id_attr=id_attr)\n\n        return statement", "response": "Signs multiple parts of a statement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a SOAP enveloped SAML thing and returns the thing as a string.", "response": "def parse_soap_enveloped_saml_thingy(text, expected_tags):\n    \"\"\"Parses a SOAP enveloped SAML thing and returns the thing as\n    a string.\n\n    :param text: The SOAP object as XML string\n    :param expected_tags: What the tag of the SAML thingy is expected to be.\n    :return: SAML thingy as a string\n    \"\"\"\n    envelope = defusedxml.ElementTree.fromstring(text)\n\n    # Make sure it's a SOAP message\n    assert envelope.tag == '{%s}Envelope' % soapenv.NAMESPACE\n\n    assert len(envelope) >= 1\n    body = None\n    for part in envelope:\n        if part.tag == '{%s}Body' % soapenv.NAMESPACE:\n            assert len(part) == 1\n            body = part\n            break\n\n    if body is None:\n        return \"\"\n\n    saml_part = body[0]\n    if saml_part.tag in expected_tags:\n        return ElementTree.tostring(saml_part, encoding=\"UTF-8\")\n    else:\n        raise WrongMessageType(\"Was '%s' expected one of %s\" % (saml_part.tag,\n                                                                expected_tags))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a SOAP enveloped header and body SAML thing and returns the XML as a dictionary class instance.", "response": "def class_instances_from_soap_enveloped_saml_thingies(text, modules):\n    \"\"\"Parses a SOAP enveloped header and body SAML thing and returns the\n    thing as a dictionary class instance.\n\n    :param text: The SOAP object as XML\n    :param modules: modules representing xsd schemas\n    :return: The body and headers as class instances\n    \"\"\"\n    try:\n        envelope = defusedxml.ElementTree.fromstring(text)\n    except Exception as exc:\n        raise XmlParseError(\"%s\" % exc)\n\n    assert envelope.tag == '{%s}Envelope' % soapenv.NAMESPACE\n    assert len(envelope) >= 1\n    env = {\"header\": [], \"body\": None}\n\n    for part in envelope:\n        if part.tag == '{%s}Body' % soapenv.NAMESPACE:\n            assert len(part) == 1\n            env[\"body\"] = instanciate_class(part[0], modules)\n        elif part.tag == \"{%s}Header\" % soapenv.NAMESPACE:\n            for item in part:\n                env[\"header\"].append(instanciate_class(item, modules))\n\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a SOAP envelope containing a SAML thingy as a text string.", "response": "def make_soap_enveloped_saml_thingy(thingy, headers=None):\n    \"\"\" Returns a soap envelope containing a SAML request\n    as a text string.\n\n    :param thingy: The SAML thingy\n    :return: The SOAP envelope as a string\n    \"\"\"\n    soap_envelope = soapenv.Envelope()\n\n    if headers:\n        _header = soapenv.Header()\n        _header.add_extension_elements(headers)\n        soap_envelope.header = _header\n\n    soap_envelope.body = soapenv.Body()\n    soap_envelope.body.add_extension_element(thingy)\n\n    return \"%s\" % soap_envelope"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a SOAP Fault message", "response": "def soap_fault(message=None, actor=None, code=None, detail=None):\n    \"\"\" Create a SOAP Fault message\n\n    :param message: Human readable error message\n    :param actor: Who discovered the error\n    :param code: Error code\n    :param detail: More specific error message\n    :return: A SOAP Fault message as a string\n    \"\"\"\n    _string = _actor = _code = _detail = None\n\n    if message:\n        _string = soapenv.Fault_faultstring(text=message)\n    if actor:\n        _actor = soapenv.Fault_faultactor(text=actor)\n    if code:\n        _code = soapenv.Fault_faultcode(text=code)\n    if detail:\n        _detail = soapenv.Fault_detail(text=detail)\n\n    fault = soapenv.Fault(\n        faultcode=_code,\n        faultstring=_string,\n        faultactor=_actor,\n        detail=_detail,\n    )\n\n    return \"%s\" % fault"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _deprecation_notice(cls):\n        _deprecation_msg = (\n            '{name} {type} is deprecated. '\n            'It will be removed in the next version. '\n            'Use saml2.cryptography.symmetric instead.'\n        ).format(name=cls.__name__, type=type(cls).__name__)\n        _warnings.warn(_deprecation_msg, DeprecationWarning)", "response": "Warn about deprecation of this class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_cipher(self, alg='aes_128_cbc'):\n        self.__class__._deprecation_notice()\n        typ, bits, cmode = alg.lower().split('_')\n        bits = int(bits)\n        iv = _os.urandom(self.AES_BLOCK_SIZE)\n\n        if len(iv) != self.AES_BLOCK_SIZE:\n            raise Exception('Wrong iv size: {}'.format(len(iv)))\n\n        if bits not in _ciphers.algorithms.AES.key_sizes:\n            raise Exception('Unsupported key length: {}'.format(bits))\n\n        if len(self.key) != bits / 8:\n            raise Exception('Wrong Key length: {}'.format(len(self.key)))\n\n        try:\n            mode = self.POSTFIX_MODE[cmode]\n        except KeyError:\n            raise Exception('Unsupported chaining mode: {}'.format(cmode))\n\n        cipher = _ciphers.Cipher(\n                _ciphers.algorithms.AES(self.key),\n                mode(iv),\n                backend=_backends.default_backend())\n\n        return cipher, iv", "response": "Builds a new instance of a Cipher class based on the current key and the algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encrypt(self, msg, alg='aes_128_cbc', padding='PKCS#7', b64enc=True,\n                block_size=AES_BLOCK_SIZE):\n        \"\"\"\n        :param key: The encryption key\n        :param msg: Message to be encrypted\n        :param padding: Which padding that should be used\n        :param b64enc: Whether the result should be base64encoded\n        :param block_size: If PKCS#7 padding which block size to use\n        :return: The encrypted message\n        \"\"\"\n        self.__class__._deprecation_notice()\n        if padding == 'PKCS#7':\n            _block_size = block_size\n        elif padding == 'PKCS#5':\n            _block_size = 8\n        else:\n            _block_size = 0\n\n        if _block_size:\n            plen = _block_size - (len(msg) % _block_size)\n            c = chr(plen).encode()\n            msg += c * plen\n\n        cipher, iv = self.build_cipher(alg)\n        encryptor = cipher.encryptor()\n        cmsg = iv + encryptor.update(msg) + encryptor.finalize()\n\n        if b64enc:\n            enc_msg = _base64.b64encode(cmsg)\n        else:\n            enc_msg = cmsg\n\n        return enc_msg", "response": "Encrypt a message with the key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decrypt(self, msg, alg='aes_128_cbc', padding='PKCS#7', b64dec=True):\n        self.__class__._deprecation_notice()\n        data = _base64.b64decode(msg) if b64dec else msg\n\n        cipher, iv = self.build_cipher(alg=alg)\n        decryptor = cipher.decryptor()\n        res = decryptor.update(data)[self.AES_BLOCK_SIZE:]\n        res += decryptor.finalize()\n        if padding in ['PKCS#5', 'PKCS#7']:\n            idx = bytearray(res)[-1]\n            res = res[:-idx]\n        return res", "response": "Decrypts the message with the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_certificate(self, cert_info, request=False, valid_from=0,\n                           valid_to=315360000, sn=1, key_length=1024,\n                           hash_alg=\"sha256\", write_to_file=False, cert_dir=\"\",\n                           cipher_passphrase=None):\n        \"\"\"\n        Can create certificate requests, to be signed later by another\n        certificate with the method\n        create_cert_signed_certificate. If request is True.\n\n        Can also create self signed root certificates if request is False.\n        This is default behaviour.\n\n        :param cert_info:         Contains information about the certificate.\n                                  Is a dictionary that must contain the keys:\n                                  cn                = Common name. This part\n                                  must match the host being authenticated\n                                  country_code      = Two letter description\n                                  of the country.\n                                  state             = State\n                                  city              = City\n                                  organization      = Organization, can be a\n                                  company name.\n                                  organization_unit = A unit at the\n                                  organization, can be a department.\n                                  Example:\n                                                    cert_info_ca = {\n                                                        \"cn\": \"company.com\",\n                                                        \"country_code\": \"se\",\n                                                        \"state\": \"AC\",\n                                                        \"city\": \"Dorotea\",\n                                                        \"organization\":\n                                                        \"Company\",\n                                                        \"organization_unit\":\n                                                        \"Sales\"\n                                                    }\n        :param request:           True if this is a request for certificate,\n                                  that should be signed.\n                                  False if this is a self signed certificate,\n                                  root certificate.\n        :param valid_from:        When the certificate starts to be valid.\n                                  Amount of seconds from when the\n                                  certificate is generated.\n        :param valid_to:          How long the certificate will be valid from\n                                  when it is generated.\n                                  The value is in seconds. Default is\n                                  315360000 seconds, a.k.a 10 years.\n        :param sn:                Serial number for the certificate. Default\n                                  is 1.\n        :param key_length:        Length of the key to be generated. Defaults\n                                  to 1024.\n        :param hash_alg:          Hash algorithm to use for the key. Default\n                                  is sha256.\n        :param write_to_file:     True if you want to write the certificate\n                                  to a file. The method will then return\n                                  a tuple with path to certificate file and\n                                  path to key file.\n                                  False if you want to get the result as\n                                  strings. The method will then return a tuple\n                                  with the certificate string and the key as\n                                  string.\n                                  WILL OVERWRITE ALL EXISTING FILES WITHOUT\n                                  ASKING!\n        :param cert_dir:          Where to save the files if write_to_file is\n                                  true.\n        :param cipher_passphrase  A dictionary with cipher and passphrase.\n        Example::\n                {\"cipher\": \"blowfish\", \"passphrase\": \"qwerty\"}\n\n        :return:                  string representation of certificate,\n                                  string representation of private key\n                                  if write_to_file parameter is False otherwise\n                                  path to certificate file, path to private\n                                  key file\n        \"\"\"\n        cn = cert_info[\"cn\"]\n\n        c_f = None\n        k_f = None\n\n        if write_to_file:\n            cert_file = \"%s.crt\" % cn\n            key_file = \"%s.key\" % cn\n            try:\n                remove(cert_file)\n            except:\n                pass\n            try:\n                remove(key_file)\n            except:\n                pass\n            c_f = join(cert_dir, cert_file)\n            k_f = join(cert_dir, key_file)\n\n\n        # create a key pair\n        k = crypto.PKey()\n        k.generate_key(crypto.TYPE_RSA, key_length)\n\n        # create a self-signed cert\n        cert = crypto.X509()\n\n        if request:\n            cert = crypto.X509Req()\n\n        if (len(cert_info[\"country_code\"]) != 2):\n            raise WrongInput(\"Country code must be two letters!\")\n        cert.get_subject().C = cert_info[\"country_code\"]\n        cert.get_subject().ST = cert_info[\"state\"]\n        cert.get_subject().L = cert_info[\"city\"]\n        cert.get_subject().O = cert_info[\"organization\"]\n        cert.get_subject().OU = cert_info[\"organization_unit\"]\n        cert.get_subject().CN = cn\n        if not request:\n            cert.set_serial_number(sn)\n            cert.gmtime_adj_notBefore(valid_from)  #Valid before present time\n            cert.gmtime_adj_notAfter(valid_to)  #3 650 days\n            cert.set_issuer(cert.get_subject())\n        cert.set_pubkey(k)\n        cert.sign(k, hash_alg)\n\n        try:\n            if request:\n                tmp_cert = crypto.dump_certificate_request(crypto.FILETYPE_PEM,\n                                                           cert)\n            else:\n                tmp_cert = crypto.dump_certificate(crypto.FILETYPE_PEM, cert)\n            tmp_key = None\n            if cipher_passphrase is not None:\n                passphrase = cipher_passphrase[\"passphrase\"]\n                if isinstance(cipher_passphrase[\"passphrase\"],\n                              six.string_types):\n                    passphrase = passphrase.encode('utf-8')\n                tmp_key = crypto.dump_privatekey(crypto.FILETYPE_PEM, k,\n                                                 cipher_passphrase[\"cipher\"],\n                                                 passphrase)\n            else:\n                tmp_key = crypto.dump_privatekey(crypto.FILETYPE_PEM, k)\n            if write_to_file:\n                with open(c_f, 'wt') as fc:\n                    fc.write(tmp_cert.decode('utf-8'))\n                with open(k_f, 'wt') as fk:\n                    fk.write(tmp_key.decode('utf-8'))\n                return c_f, k_f\n            return tmp_cert, tmp_key\n        except Exception as ex:\n            raise CertificateError(\"Certificate cannot be generated.\", ex)", "response": "This method creates a certificate in the local directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_cert_signed_certificate(self, sign_cert_str, sign_key_str,\n                                       request_cert_str, hash_alg=\"sha256\",\n                                       valid_from=0, valid_to=315360000, sn=1,\n                                       passphrase=None):\n\n        \"\"\"\n        Will sign a certificate request with a give certificate.\n        :param sign_cert_str:     This certificate will be used to sign with.\n                                  Must be a string representation of\n                                  the certificate. If you only have a file\n                                  use the method read_str_from_file to\n                                  get a string representation.\n        :param sign_key_str:        This is the key for the ca_cert_str\n                                  represented as a string.\n                                  If you only have a file use the method\n                                  read_str_from_file to get a string\n                                  representation.\n        :param request_cert_str:  This is the prepared certificate to be\n                                  signed. Must be a string representation of\n                                  the requested certificate. If you only have\n                                  a file use the method read_str_from_file\n                                  to get a string representation.\n        :param hash_alg:          Hash algorithm to use for the key. Default\n                                  is sha256.\n        :param valid_from:        When the certificate starts to be valid.\n                                  Amount of seconds from when the\n                                  certificate is generated.\n        :param valid_to:          How long the certificate will be valid from\n                                  when it is generated.\n                                  The value is in seconds. Default is\n                                  315360000 seconds, a.k.a 10 years.\n        :param sn:                Serial number for the certificate. Default\n                                  is 1.\n        :param passphrase:        Password for the private key in sign_key_str.\n        :return:                  String representation of the signed\n                                  certificate.\n        \"\"\"\n        ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM, sign_cert_str)\n        ca_key = None\n        if passphrase is not None:\n            ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, sign_key_str,\n                                            passphrase)\n        else:\n            ca_key = crypto.load_privatekey(crypto.FILETYPE_PEM, sign_key_str)\n        req_cert = crypto.load_certificate_request(crypto.FILETYPE_PEM,\n                                                   request_cert_str)\n\n        cert = crypto.X509()\n        cert.set_subject(req_cert.get_subject())\n        cert.set_serial_number(sn)\n        cert.gmtime_adj_notBefore(valid_from)\n        cert.gmtime_adj_notAfter(valid_to)\n        cert.set_issuer(ca_cert.get_subject())\n        cert.set_pubkey(req_cert.get_pubkey())\n        cert.sign(ca_key, hash_alg)\n\n        cert_dump = crypto.dump_certificate(crypto.FILETYPE_PEM, cert)\n        if isinstance(cert_dump, six.string_types):\n            return cert_dump\n        return cert_dump.decode('utf-8')", "response": "Create a certificate signed with a give certificate."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify if a certificate is valid and signed by a given certificate.", "response": "def verify(self, signing_cert_str, cert_str):\n        \"\"\"\n        Verifies if a certificate is valid and signed by a given certificate.\n\n        :param signing_cert_str: This certificate will be used to verify the\n                                  signature. Must be a string representation\n                                 of the certificate. If you only have a file\n                                 use the method read_str_from_file to\n                                 get a string representation.\n        :param cert_str:         This certificate will be verified if it is\n                                  correct. Must be a string representation\n                                 of the certificate. If you only have a file\n                                 use the method read_str_from_file to\n                                 get a string representation.\n        :return:                 Valid, Message\n                                 Valid = True if the certificate is valid,\n                                 otherwise false.\n                                 Message = Why the validation failed.\n        \"\"\"\n        try:\n            ca_cert = crypto.load_certificate(crypto.FILETYPE_PEM,\n                                              signing_cert_str)\n            cert = crypto.load_certificate(crypto.FILETYPE_PEM, cert_str)\n\n            if self.certificate_not_valid_yet(ca_cert):\n                return False, \"CA certificate is not valid yet.\"\n\n            if ca_cert.has_expired() == 1:\n                return False, \"CA certificate is expired.\"\n\n            if cert.has_expired() == 1:\n                return False, \"The signed certificate is expired.\"\n\n            if self.certificate_not_valid_yet(cert):\n                return False, \"The signed certificate is not valid yet.\"\n\n            if ca_cert.get_subject().CN == cert.get_subject().CN:\n                return False, (\"CN may not be equal for CA certificate and the \"\n                               \"signed certificate.\")\n\n            cert_algorithm = cert.get_signature_algorithm()\n            if six.PY3:\n                cert_algorithm = cert_algorithm.decode('ascii')\n                cert_str = cert_str.encode('ascii')\n\n            cert_crypto = saml2.cryptography.pki.load_pem_x509_certificate(\n                    cert_str)\n\n            try:\n                crypto.verify(ca_cert, cert_crypto.signature,\n                              cert_crypto.tbs_certificate_bytes,\n                              cert_algorithm)\n                return True, \"Signed certificate is valid and correctly signed by CA certificate.\"\n            except crypto.Error as e:\n                return False, \"Certificate is incorrectly signed.\"\n        except Exception as e:\n            return False, \"Certificate is not valid for an unknown reason. %s\" % str(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _since_epoch(cdate):\n\n    if len(cdate) < 29:  # somethings broken\n        if len(cdate) < 5:\n            return utc_now()\n\n    cdate = cdate[5:] # assume short weekday, i.e. do not support obsolete RFC 1036 date format\n    t = -1\n    for time_format in TIME_FORMAT :\n        try:\n            t = time.strptime(cdate, time_format)   # e.g. 18-Apr-2014 12:30:51 GMT\n        except ValueError:\n            pass\n        else:\n            break\n\n    if t == -1:\n        raise (Exception,\n               'ValueError: Date \"{0}\" does not match any of: {1}'.format(\n                   cdate,TIME_FORMAT))\n\n    return calendar.timegm(t)", "response": "returns UTC time of the next year since the epoch"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary of cookies that are matching the path and are still valid.", "response": "def cookies(self, url):\n        \"\"\"\n        Return cookies that are matching the path and are still valid\n\n        :param url:\n        :return:\n        \"\"\"\n        part = urlparse(url)\n\n        #if part.port:\n        #    _domain = \"%s:%s\" % (part.hostname, part.port)\n        #else:\n        _domain = part.hostname\n\n        cookie_dict = {}\n        now = utc_now()\n        for _, a in list(self.cookiejar._cookies.items()):\n            for _, b in a.items():\n                for cookie in list(b.values()):\n                    # print(cookie)\n                    if cookie.expires and cookie.expires <= now:\n                        continue\n                    if not re.search(\"%s$\" % cookie.domain, _domain):\n                        continue\n                    if not re.match(cookie.path, part.path):\n                        continue\n\n                    cookie_dict[cookie.name] = cookie.value\n\n        return cookie_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a cookie based on a set - cookie header line.", "response": "def set_cookie(self, kaka, request):\n        \"\"\"Returns a http_cookiejar.Cookie based on a set-cookie header line\"\"\"\n\n        if not kaka:\n            return\n\n        part = urlparse(request.url)\n        _domain = part.hostname\n        logger.debug(\"%s: '%s'\", _domain, kaka)\n\n        for cookie_name, morsel in kaka.items():\n            std_attr = ATTRS.copy()\n            std_attr[\"name\"] = cookie_name\n            _tmp = morsel.coded_value\n            if _tmp.startswith('\"') and _tmp.endswith('\"'):\n                std_attr[\"value\"] = _tmp[1:-1]\n            else:\n                std_attr[\"value\"] = _tmp\n\n            std_attr[\"version\"] = 0\n            # copy attributes that have values\n            for attr in morsel.keys():\n                if attr in ATTRS:\n                    if morsel[attr]:\n                        if attr == \"expires\":\n                            std_attr[attr] = _since_epoch(morsel[attr])\n                        elif attr == \"path\":\n                            if morsel[attr].endswith(\",\"):\n                                std_attr[attr] = morsel[attr][:-1]\n                            else:\n                                std_attr[attr] = morsel[attr]\n                        else:\n                            std_attr[attr] = morsel[attr]\n                elif attr == \"max-age\":\n                    if morsel[\"max-age\"]:\n                        std_attr[\"expires\"] = time.time() + int(morsel[\"max-age\"])\n\n            for att, item in PAIRS.items():\n                if std_attr[att]:\n                    std_attr[item] = True\n\n            if std_attr[\"domain\"]:\n                if std_attr[\"domain\"].startswith(\".\"):\n                    std_attr[\"domain_initial_dot\"] = True\n            else:\n                std_attr[\"domain\"] = _domain\n                std_attr[\"domain_specified\"] = True\n\n            if morsel[\"max-age\"] is 0:\n                try:\n                    self.cookiejar.clear(domain=std_attr[\"domain\"],\n                                         path=std_attr[\"path\"],\n                                         name=std_attr[\"name\"])\n                except ValueError:\n                    pass\n            elif std_attr[\"expires\"] and std_attr[\"expires\"] < utc_now():\n                try:\n                    self.cookiejar.clear(domain=std_attr[\"domain\"],\n                                         path=std_attr[\"path\"],\n                                         name=std_attr[\"name\"])\n                except ValueError:\n                    pass\n            else:\n                new_cookie = http_cookiejar.Cookie(**std_attr)\n                self.cookiejar.set_cookie(new_cookie)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef use_http_post(message, destination, relay_state,\n                           typ=\"SAMLRequest\"):\n        \"\"\"\n        Return a urlencoded message that should be POSTed to the recipient.\n\n        :param message: The response\n        :param destination: Where the response should be sent\n        :param relay_state: The relay_state received in the request\n        :param typ: Whether a Request, Response or Artifact\n        :return: dictionary\n        \"\"\"\n        if not isinstance(message, six.string_types):\n            message = \"%s\" % (message,)\n\n        return http_post_message(message, relay_state, typ)", "response": "Use HTTP POST to the recipient."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a form that will automagically execute and POST the message to the recipient.", "response": "def use_http_form_post(message, destination, relay_state,\n                           typ=\"SAMLRequest\"):\n        \"\"\"\n        Return a form that will automagically execute and POST the message\n        to the recipient.\n\n        :param message:\n        :param destination:\n        :param relay_state:\n        :param typ: Whether a Request, Response or Artifact\n        :return: dictionary\n        \"\"\"\n        if not isinstance(message, six.string_types):\n            message = \"%s\" % (message,)\n\n        return http_form_post_message(message, destination, relay_state, typ)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing the necessary information for using SOAP+POST :param request: :param destination: :param soap_headers: :param sign: :return: dictionary", "response": "def use_soap(self, request, destination=\"\", soap_headers=None, sign=False,\n                 **kwargs):\n        \"\"\"\n        Construct the necessary information for using SOAP+POST\n\n        :param request:\n        :param destination:\n        :param soap_headers:\n        :param sign:\n        :return: dictionary\n        \"\"\"\n        headers = [(\"content-type\", \"application/soap+xml\")]\n\n        soap_message = make_soap_enveloped_saml_thingy(request, soap_headers)\n\n        logger.debug(\"SOAP message: %s\", soap_message)\n\n        if sign and self.sec:\n            _signed = self.sec.sign_statement(soap_message,\n                                              class_name=class_name(request),\n                                              node_id=request.id)\n            soap_message = _signed\n\n        return {\"url\": destination, \"method\": \"POST\",\n                \"data\": soap_message, \"headers\": headers}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_using_soap(self, request, destination, headers=None, sign=False):\n\n        # _response = self.server.post(soap_message, headers, path=path)\n        try:\n            args = self.use_soap(request, destination, headers, sign)\n            args[\"headers\"] = dict(args[\"headers\"])\n            response = self.send(**args)\n        except Exception as exc:\n            logger.info(\"HTTPClient exception: %s\", exc)\n            raise\n\n        if response.status_code == 200:\n            logger.info(\"SOAP response: %s\", response.text)\n            return response\n        else:\n            raise HTTPError(\"%d:%s\" % (response.status_code, response.content))", "response": "Send a message using SOAP + POST"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a message using HTTP - Redirect", "response": "def use_http_get(message, destination, relay_state,\n                     typ=\"SAMLRequest\", sigalg=\"\", signer=None, **kwargs):\n        \"\"\"\n        Send a message using GET, this is the HTTP-Redirect case so\n        no direct response is expected to this request.\n\n        :param message:\n        :param destination:\n        :param relay_state:\n        :param typ: Whether a Request, Response or Artifact\n        :param sigalg: Which algorithm the signature function will use to sign\n            the message\n        :param signer: A signing function that can be used to sign the message\n        :return: dictionary\n        \"\"\"\n        if not isinstance(message, six.string_types):\n            message = \"%s\" % (message,)\n\n        return http_redirect_message(message, destination, relay_state, typ,\n                                     sigalg, signer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract strings in form data and returns a dict.", "response": "def extract(environ, empty=False, err=False):\n    \"\"\"Extracts strings in form data and returns a dict.\n\n    :param environ: WSGI environ\n    :param empty: Stops on empty fields (default: Fault)\n    :param err: Stops on errors in fields (default: Fault)\n    \"\"\"\n    formdata = cgi.parse(environ['wsgi.input'], environ, empty, err)\n    # Remove single entries from lists\n    for key, value in iter(formdata.items()):\n        if len(value) == 1:\n            formdata[key] = value[0]\n    return formdata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geturl(environ, query=True, path=True, use_server_name=False):\n    url = [environ['wsgi.url_scheme'] + '://']\n    if use_server_name:\n        url.append(environ['SERVER_NAME'])\n        if environ['wsgi.url_scheme'] == 'https':\n            if environ['SERVER_PORT'] != '443':\n                url.append(':' + environ['SERVER_PORT'])\n        else:\n            if environ['SERVER_PORT'] != '80':\n                url.append(':' + environ['SERVER_PORT'])\n    else:\n        url.append(environ['HTTP_HOST'])\n    if path:\n        url.append(getpath(environ))\n    if query and environ.get('QUERY_STRING'):\n        url.append('?' + environ['QUERY_STRING'])\n    return ''.join(url)", "response": "Rebuilds a request URL from the given WSGI environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cookie_signature(seed, *parts):\n    sha1 = hmac.new(seed, digestmod=hashlib.sha1)\n    for part in parts:\n        if part:\n            sha1.update(part)\n    return sha1.hexdigest()", "response": "Generates a cookie signature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_cookie(name, load, seed, expire=0, domain=\"\", path=\"\",\n                timestamp=\"\"):\n    \"\"\"\n    Create and return a cookie\n\n    :param name: Cookie name\n    :param load: Cookie load\n    :param seed: A seed for the HMAC function\n    :param expire: Number of minutes before this cookie goes stale\n    :param domain: The domain of the cookie\n    :param path: The path specification for the cookie\n    :return: A tuple to be added to headers\n    \"\"\"\n    cookie = SimpleCookie()\n    if not timestamp:\n        timestamp = str(int(time.mktime(time.gmtime())))\n    signature = cookie_signature(seed, load, timestamp)\n    cookie[name] = \"|\".join([load, timestamp, signature])\n    if path:\n        cookie[name][\"path\"] = path\n    if domain:\n        cookie[name][\"domain\"] = domain\n    if expire:\n        cookie[name][\"expires\"] = _expiration(expire,\n                                              \"%a, %d-%b-%Y %H:%M:%S GMT\")\n\n    return tuple(cookie.output().split(\": \", 1))", "response": "Create and return a cookie tuple"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_cookie(name, seed, kaka):\n    if not kaka:\n        return None\n\n    cookie_obj = SimpleCookie(kaka)\n    morsel = cookie_obj.get(name)\n\n    if morsel:\n        parts = morsel.value.split(\"|\")\n        if len(parts) != 3:\n            return None\n            # verify the cookie signature\n        sig = cookie_signature(seed, parts[0], parts[1])\n        if sig != parts[2]:\n            raise SAMLError(\"Invalid cookie signature\")\n\n        try:\n            return parts[0].strip(), parts[1]\n        except KeyError:\n            return None\n    else:\n        return None", "response": "Parses and verifies a cookie value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_basic_auth(self, username, password, realm):\n    self._passmgr.add_password(realm, self._base_url, username, password)\n    return self", "response": "Set up basic auth for the client\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a HTTP request.", "response": "def execute(self, http_method, path, params=None, data=None, headers=None):\n    \"\"\"\n    Submit an HTTP request.\n    @param http_method: GET, POST, PUT, DELETE\n    @param path: The path of the resource.\n    @param params: Key-value parameter data.\n    @param data: The data to attach to the body of the request.\n    @param headers: The headers to set for this request.\n\n    @return: The result of urllib2.urlopen()\n    \"\"\"\n    # Prepare URL and params\n    url = self._make_url(path, params)\n    if http_method in (\"GET\", \"DELETE\"):\n      if data is not None:\n        self.logger.warn(\n            \"GET method does not pass any data. Path '%s'\" % (path,))\n        data = None\n\n    # Setup the request\n    request = urllib2.Request(url, data)\n    # Hack/workaround because urllib2 only does GET and POST\n    request.get_method = lambda: http_method\n\n    headers = self._get_headers(headers)\n    for k, v in headers.items():\n      request.add_header(k, v)\n\n    # Call it\n    self.logger.debug(\"%s %s\" % (http_method, url))\n    try:\n      return self._opener.open(request)\n    except urllib2.HTTPError, ex:\n      raise self._exc_class(ex)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying CM time series data store.", "response": "def query_timeseries(resource_root, query, from_time=None, to_time=None,\n    desired_rollup=None, must_use_desired_rollup=None, by_post=False):\n  \"\"\"\n  Query for time series data from the CM time series data store.\n  @param query: Query string.\n  @param from_time: Start of the period to query (optional).\n  @type from_time: datetime.datetime Note the that datetime must either be time\n                   zone aware or specified in the server time zone. See the\n                   python datetime documentation for more details about python's\n                   time zone handling.\n  @param to_time: End of the period to query (default = now).\n                  This may be an ISO format string, or a datetime object.\n  @type to_time: datetime.datetime Note the that datetime must either be time\n                 zone aware or specified in the server time zone. See the\n                 python datetime documentation for more details about python's\n                 time zone handling.\n  @param desired_rollup: The aggregate rollup to get data for. This can be\n                         RAW, TEN_MINUTELY, HOURLY, SIX_HOURLY, DAILY, or\n                         WEEKLY. Note that rollup desired is only a hint unless\n                         must_use_desired_rollup is set to true.\n  @param must_use_desired_rollup: Indicates that the monitoring server should\n                                  return the data at the rollup desired.\n  @param by_post: If true, an HTTP POST request will be made to server. This\n                  allows longer query string to be accepted compared to HTTP\n                  GET request.\n  @return: List of ApiTimeSeriesResponse\n  \"\"\"\n  data = None\n  params = {}\n  request_method = resource_root.get\n  if by_post:\n    request = ApiTimeSeriesRequest(resource_root,\n                                   query=query)\n    data = request\n    request_method = resource_root.post\n  elif query:\n    params['query'] = query\n\n  if from_time:\n    params['from'] = from_time.isoformat()\n  if to_time:\n    params['to'] = to_time.isoformat()\n  if desired_rollup:\n    params['desiredRollup'] = desired_rollup\n  if must_use_desired_rollup:\n    params['mustUseDesiredRollup'] = must_use_desired_rollup\n  return call(request_method, TIME_SERIES_PATH,\n      ApiTimeSeriesResponse, True, params=params, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a parcel by name.", "response": "def get_parcel(resource_root, product, version, cluster_name=\"default\"):\n  \"\"\"\n  Lookup a parcel by name\n  @param resource_root: The root Resource object.\n  @param product: Parcel product name\n  @param version: Parcel version\n  @param cluster_name: Cluster name\n  @return: An ApiService object\n  \"\"\"\n  return _get_parcel(resource_root, PARCEL_PATH % (cluster_name, product, version))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all parcels in a cluster.", "response": "def get_all_parcels(resource_root, cluster_name=\"default\", view=None):\n  \"\"\"\n  Get all parcels\n  @param resource_root: The root Resource object.\n  @param cluster_name: Cluster name\n  @return: A list of ApiParcel objects.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.get, PARCELS_PATH % (cluster_name,),\n      ApiParcel, True, params=view and dict(view=view) or None, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_bulk_config_update(hostnames):\n  api = ApiResource(CM_HOST, username=CM_USER, password=CM_PASSWD)\n  hosts = collect_hosts(api, hostnames)\n\n  # Set config\n  for h in hosts:\n    configure_roles_on_host(api, h)", "response": "Update the configs of all the datanodes tasktrackers and regionservers on the given hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collect_hosts(api, wanted_hostnames):\n  all_hosts = api.get_all_hosts(view='full')\n  all_hostnames = set([ h.hostname for h in all_hosts])\n  wanted_hostnames = set(wanted_hostnames)\n\n  unknown_hosts = wanted_hostnames.difference(all_hostnames)\n  if len(unknown_hosts) != 0:\n    msg = \"The following hosts are not found in Cloudera Manager. \"\\\n          \"Please check for typos:\\n%s\" % ('\\n'.join(unknown_hosts))\n    LOG.error(msg)\n    raise RuntimeError(msg)\n\n  return [ h for h in all_hosts if h.hostname in wanted_hostnames ]", "response": "Collect hosts that are in the set of wanted_hostnames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring all the roles on a host.", "response": "def configure_roles_on_host(api, host):\n  \"\"\"\n  Go through all the roles on this host, and configure them if they\n  match the role types that we care about.\n  \"\"\"\n  for role_ref in host.roleRefs:\n    # Mgmt service/role has no cluster name. Skip over those.\n    if role_ref.get('clusterName') is None:\n      continue\n\n    # Get the role and inspect the role type\n    role = api.get_cluster(role_ref['clusterName'])\\\n              .get_service(role_ref['serviceName'])\\\n              .get_role(role_ref['roleName'])\n    LOG.debug(\"Evaluating %s (%s)\" % (role.name, host.hostname))\n\n    config = None\n    if role.type == 'DATANODE':\n      config = DATANODE_CONF\n    elif role.type == 'TASKTRACKER':\n      config = TASKTRACKER_CONF\n    elif role.type == 'REGIONSERVER':\n      config = REGIONSERVER_CONF\n    else:\n      continue\n\n    # Set the config\n    LOG.info(\"Configuring %s (%s)\" % (role.name, host.hostname))\n    role.update_config(config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_host_file(path):\n  res = []\n  for l in file(path).xreadlines():\n    hostname = l.strip()\n    if hostname:\n      res.append(hostname)\n  return res", "response": "Reads the host file. Return a list of hostnames."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_commands(self, view=None):\n    return self._get(\"commands\", ApiCommand, True,\n        params = view and dict(view=view) or None)", "response": "Retrieve a list of running global commands."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninstall or update the Cloudera Manager license.", "response": "def update_license(self, license_text):\n    \"\"\"\n    Install or update the Cloudera Manager license.\n\n    @param license_text: the license in text form\n    \"\"\"\n    content = (\n        '--MULTI_BOUNDARY',\n        'Content-Disposition: form-data; name=\"license\"',\n        '',\n        license_text,\n        '--MULTI_BOUNDARY--',\n        '')\n    resp = self._get_resource_root().post('cm/license',\n        data=\"\\r\\n\".join(content),\n        contenttype='multipart/form-data; boundary=MULTI_BOUNDARY')\n    return ApiLicense.from_json_dict(resp, self._get_resource_root())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports the KDC Account Manager credentials needed by Cloudera Manager to create kerberos principals needed by Cloudera Manager.", "response": "def import_admin_credentials(self, username, password):\n    \"\"\"\n    Imports the KDC Account Manager credentials needed by Cloudera\n    Manager to create kerberos principals needed by CDH services.\n\n    @param username Username of the Account Manager. Full name including the Kerberos\n           realm must be specified.\n    @param password Password for the Account Manager.\n\n    @return: Information about the submitted command.\n\n    @since API v7\n    \"\"\"\n    return self._cmd('importAdminCredentials', params=dict(username=username, password=password))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collect_diagnostic_data(self, start_datetime, end_datetime, includeInfoLog=False):\n    args = {\n        'startTime': start_datetime.isoformat(),\n        'endTime': end_datetime.isoformat(),\n        'includeInfoLog': includeInfoLog,\n    }\n    # This method is deprecated as of CM API version 3 which was introduced\n    # in CM 4.5.\n    return self._cmd('collectDiagnosticData', data=args, api_version=2)", "response": "This method is deprecated as of CM 4. 5."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collect_diagnostic_data_45(self, end_datetime, bundle_size_bytes, cluster_name=None,\n                                 roles=None, collect_metrics=False, start_datetime=None):\n    \"\"\"\n    Issue the command to collect diagnostic data.\n    If start_datetime is specified, diagnostic data is collected for the entire period between\n    start_datetime and end_datetime provided that bundle size is less than or equal to\n    bundle_size_bytes. Diagnostics data collection fails if the bundle size is greater than\n    bundle_size_bytes.\n\n    If start_datetime is not specified, diagnostic data is collected starting from end_datetime\n    and collecting backwards upto a maximum of bundle_size_bytes.\n\n    @param end_datetime: The end of the collection period. Type datetime.\n    @param bundle_size_bytes: The target size for the support bundle in bytes\n    @param cluster_name: The cluster to collect or None for all clusters\n    @param roles: Role ids of roles to restrict log and metric collection to. Valid since v10.\n    @param collect_metrics: Whether to collect metrics for viewing as charts. Valid since v13.\n    @param start_datetime: The start of the collection period. Type datetime. Valid since v13.\n    \"\"\"\n    args = {\n        'endTime': end_datetime.isoformat(),\n        'bundleSizeBytes': bundle_size_bytes,\n        'clusterName': cluster_name\n    }\n    if self._get_resource_root().version >= 10:\n      args['roles'] = roles\n    if self._get_resource_root().version >= 13:\n      args['enableMonitorMetricsCollection'] = collect_metrics\n      if start_datetime is not None:\n          args['startTime'] = start_datetime.isoformat()\n    return self._cmd('collectDiagnosticData', data=args)", "response": "Issue the command to collect diagnostic data for a given bundle size."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new peer for replication.", "response": "def create_peer(self, name, url, username, password, peer_type=\"REPLICATION\"):\n    \"\"\"\n    Create a new peer for replication.\n\n    @param name: The name of the peer.\n    @param url: The url of the peer.\n    @param username: The admin username to use to setup the remote side of the peer connection.\n    @param password: The password of the admin user.\n    @param peer_type: Added in v11. The type of the peer. Defaults to 'REPLICATION'.\n    @return: The newly created peer.\n    @since: API v3\n    \"\"\"\n    if self._get_resource_root().version < 11:\n      peer_type = None\n    peer = ApiCmPeer(self._get_resource_root(),\n        name=name,\n        url=url,\n        username=username,\n        password=password,\n        type=peer_type)\n    return self._post(\"peers\", ApiCmPeer, data=peer, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the type param for the peer type.", "response": "def _get_peer_type_param(self, peer_type):\n    \"\"\"\n    Checks if the resource_root's API version is >= 11 and construct type param.\n    \"\"\"\n    params = None\n    if self._get_resource_root().version >= 11:\n      params = {\n        'type':   peer_type,\n      }\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_peer(self, name, peer_type=\"REPLICATION\"):\n    params = self._get_peer_type_param(peer_type)\n    return self._delete(\"peers/\" + name, ApiCmPeer, params=params, api_version=3)", "response": "Delete a replication peer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates a replication peer.", "response": "def update_peer(self,\n      current_name,\n      new_name, new_url, username, password, peer_type=\"REPLICATION\"):\n    \"\"\"\n    Update a replication peer.\n\n    @param current_name: The name of the peer to updated.\n    @param new_name: The new name for the peer.\n    @param new_url: The new url for the peer.\n    @param username: The admin username to use to setup the remote side of the peer connection.\n    @param password: The password of the admin user.\n    @param peer_type: Added in v11. The type of the peer. Defaults to 'REPLICATION'.\n    @return: The updated peer.\n    @since: API v3\n    \"\"\"\n    if self._get_resource_root().version < 11:\n      peer_type = None\n    peer = ApiCmPeer(self._get_resource_root(),\n        name=new_name,\n        url=new_url,\n        username=username,\n        password=password,\n        type=peer_type)\n    return self._put(\"peers/\" + current_name, ApiCmPeer, data=peer, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a replication peer by name.", "response": "def get_peer(self, name, peer_type=\"REPLICATION\"):\n    \"\"\"\n    Retrieve a replication peer by name.\n\n    @param name: The name of the peer.\n    @param peer_type: Added in v11. The type of the peer. Defaults to 'REPLICATION'.\n    @return: The peer.\n    @since: API v3\n    \"\"\"\n    params = self._get_peer_type_param(peer_type)\n    return self._get(\"peers/\" + name, ApiCmPeer, params=params, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls Cloudera Manager Agent on a set of hosts.", "response": "def host_install(self, user_name, host_names, ssh_port=None, password=None,\n          private_key=None, passphrase=None, parallel_install_count=None,\n          cm_repo_url=None, gpg_key_custom_url=None,\n          java_install_strategy=None, unlimited_jce=None):\n    \"\"\"\n    Install Cloudera Manager Agent on a set of hosts.\n\n    @param user_name: The username used to authenticate with the hosts. Root access\n                      to your hosts is required to install Cloudera packages. The\n                      installer will connect to your hosts via SSH and log in either\n                      directly as root or as another user with password-less sudo\n                      privileges to become root.\n    @param host_names: List of names of hosts to configure for use with\n                       Cloudera Manager. A host may be specified by a\n                       hostname(FQDN) or an IP address.\n    @param ssh_port: SSH port. If unset, defaults to 22.\n    @param password: The password used to authenticate with the hosts. Specify\n                     either this or a private key. For password-less login, use\n                     an empty string as password.\n    @param private_key: The private key to authenticate with the hosts. Specify\n                        either this or a password.\n    @param passphrase: The passphrase associated with the private key used to\n                       authenticate with the hosts (optional).\n    @param parallel_install_count: Number of simultaneous installations.\n                                   Defaults to 10. Running a large number of\n                                   installations at once can consume large amounts\n                                   of network bandwidth and other system resources.\n    @param cm_repo_url: The Cloudera Manager repository URL to use (optional).\n                        Example for SLES, Redhat or other RPM based distributions:\n                        http://archive-primary.cloudera.com/cm5/redhat/6/x86_64/cm/5/\n                        Example for Ubuntu or other Debian based distributions:\n                        \"deb http://archive.cloudera.com/cm5/ubuntu/lucid/amd64/cm/ lucid-cm5 contrib\"\n    @param gpg_key_custom_url: The Cloudera Manager public GPG key (optional).\n                               Example for SLES, Redhat or other RPM based distributions:\n                               http://archive-primary.cloudera.com/cm5/redhat/6/x86_64/cm/RPM-GPG-KEY-cloudera\n                               Example for Ubuntu or other Debian based distributions:\n                               http://archive.cloudera.com/debian/archive.key\n    @param java_install_strategy: Added in v8: Strategy to use for JDK installation. Valid values are 1.\n                                  AUTO (default): Cloudera Manager will install the JDK versions that are\n                                  required when the \"AUTO\" option is selected. Cloudera Manager may\n                                  overwrite any of the existing JDK installations. 2. NONE: Cloudera\n                                  Manager will not install any JDK when \"NONE\" option is selected. It\n                                  should be used if an existing JDK installation has to be used.\n    @param unlimited_jce: Added in v8: Flag for unlimited strength JCE policy files installation If\n                          unset, defaults to false\n    @return: Information about the submitted command.\n    @since: API v6\n    \"\"\"\n    host_install_args = {}\n    if user_name:\n     host_install_args['userName'] = user_name\n    if host_names:\n      host_install_args['hostNames'] = host_names\n    if ssh_port:\n     host_install_args['sshPort'] = ssh_port\n    if password:\n     host_install_args['password'] = password\n    if private_key:\n     host_install_args['privateKey'] = private_key\n    if passphrase:\n     host_install_args['passphrase'] = passphrase\n    if parallel_install_count:\n     host_install_args['parallelInstallCount'] = parallel_install_count\n    if cm_repo_url:\n     host_install_args['cmRepoUrl'] = cm_repo_url\n    if gpg_key_custom_url:\n     host_install_args['gpgKeyCustomUrl'] = gpg_key_custom_url\n    if java_install_strategy is not None:\n     host_install_args['javaInstallStrategy'] = java_install_strategy\n    if unlimited_jce:\n     host_install_args['unlimitedJCE'] = unlimited_jce\n    return self._cmd('hostInstall', data=host_install_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a cluster according to the provided template", "response": "def import_cluster_template(self, api_cluster_template, add_repositories=False):\n    \"\"\"\n    Create a cluster according to the provided template\n\n    @param api_cluster_template: cluster template to import\n    @param add_repositories: if true the parcels repositories in the cluster template will be added.\n    @return: Command handing cluster import\n    @since: API v12\n    \"\"\"\n    return self._post(\"importClusterTemplate\", ApiCommand, False, api_cluster_template, params=dict(addRepositories=add_repositories), api_version=12)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_get_aliases(name):\n  metric_schemas = MetricSchemas()\n  aliases = metric_schemas.get_aliases(name)\n  for alias in aliases:\n    do_print(alias)", "response": "Get aliases for given metric name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_supported_types(resource_root, category_name):\n  return call(resource_root.get,\n      EXTERNAL_ACCOUNT_FETCH_PATH % (\"supportedTypes\", category_name,),\n      ApiExternalAccountType, True)", "response": "Get all supported types in a category."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an external account", "response": "def create_external_account(resource_root, name, display_name, type_name,\n                            account_configs=None):\n  \"\"\"\n  Create an external account\n  @param resource_root: The root Resource object.\n  @param name: Immutable external account name\n  @param display_name: Display name\n  @param type_name: Account type\n  @param account_configs: Optional account configuration (ApiList of ApiConfig objects)\n  @return: An ApiExternalAccount object matching the newly created account\n  \"\"\"\n  account = ApiExternalAccount(resource_root,\n                               name=name,\n                               displayName=display_name,\n                               typeName=type_name,\n                               accountConfigs=account_configs)\n  return call(resource_root.post,\n      EXTERNAL_ACCOUNT_PATH % (\"create\",),\n      ApiExternalAccount, False, data=account)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_external_account(resource_root, name, view=None):\n  return call(resource_root.get,\n      EXTERNAL_ACCOUNT_FETCH_PATH % (\"account\", name,),\n      ApiExternalAccount, False, params=view and dict(view=view) or None)", "response": "Get an external account by name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_external_account_by_display_name(resource_root,\n                                         display_name, view=None):\n  \"\"\"\n  Lookup an external account by display name\n  @param resource_root: The root Resource object.\n  @param display_name: Account display name\n  @param view: View\n  @return: An ApiExternalAccount object\n  \"\"\"\n  return call(resource_root.get,\n      EXTERNAL_ACCOUNT_FETCH_PATH % (\"accountByDisplayName\", display_name,),\n      ApiExternalAccount, False, params=view and dict(view=view) or None)", "response": "Lookup an external account by display name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all external accounts of a particular type.", "response": "def get_all_external_accounts(resource_root, type_name, view=None):\n  \"\"\"\n  Lookup all external accounts of a particular type, by type name.\n  @param resource_root: The root Resource object.\n  @param type_name: Type name\n  @param view: View\n  @return: An ApiList of ApiExternalAccount objects matching the specified type\n  \"\"\"\n  return call(resource_root.get,\n      EXTERNAL_ACCOUNT_FETCH_PATH % (\"type\", type_name,),\n      ApiExternalAccount, True, params=view and dict(view=view) or None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_external_account(resource_root, account):\n  return call(resource_root.put,\n      EXTERNAL_ACCOUNT_PATH % (\"update\",),\n      ApiExternalAccount, False, data=account)", "response": "Update an external account in a resource tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete an external account by name", "response": "def delete_external_account(resource_root, name):\n  \"\"\"\n  Delete an external account by name\n  @param resource_root: The root Resource object.\n  @param name: Account name\n  @return: The deleted ApiExternalAccount object\n  \"\"\"\n  return call(resource_root.delete,\n      EXTERNAL_ACCOUNT_FETCH_PATH % (\"delete\", name,),\n      ApiExternalAccount, False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a command on the external account specified by name.", "response": "def external_account_cmd_by_name(self, command_name):\n    \"\"\"\n    Executes a command on the external account specified\n    by name.\n\n    @param command_name: The name of the command.\n    @return: Reference to the submitted command.\n    @since: API v16\n    \"\"\"\n    return self._cmd(command_name, data=self.name, api_version=16)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the list of dashboards.", "response": "def create_dashboards(resource_root, dashboard_list):\n  \"\"\"\n  Creates the list of dashboards. If any of the dashboards already exist\n  this whole command will fail and no dashboards will be created.\n  @since: API v6\n  @return: The list of dashboards created.\n  \"\"\"\n  return call(resource_root.post, DASHBOARDS_PATH, ApiDashboard, \\\n      ret_is_list=True, data=dashboard_list)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a cluster with the specified name and version.", "response": "def create_cluster(resource_root, name, version=None, fullVersion=None):\n  \"\"\"\n  Create a cluster\n  @param resource_root: The root Resource object.\n  @param name: Cluster name\n  @param version: Cluster CDH major version (eg: \"CDH4\")\n                  - The CDH minor version will be assumed to be the\n                    latest released version for CDH4, or 5.0 for CDH5.\n  @param fullVersion: Cluster's full CDH version. (eg: \"5.1.1\")\n                        - If specified, 'version' will be ignored.\n                        - Since: v6\n  @return: An ApiCluster object\n  \"\"\"\n  if version is None and fullVersion is None:\n    raise Exception(\"Either 'version' or 'fullVersion' must be specified\")\n  if fullVersion is not None:\n    api_version = 6\n    version = None\n  else:\n    api_version = 1\n\n  apicluster = ApiCluster(resource_root, name, version, fullVersion)\n  return call(resource_root.post, CLUSTERS_PATH, ApiCluster, True,\n              data=[apicluster], api_version=api_version)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_clusters(resource_root, view=None):\n  return call(resource_root.get, CLUSTERS_PATH, ApiCluster, True,\n      params=view and dict(view=view) or None)", "response": "Get all clusters in a resource_root"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_service_types(self):\n    resp = self._get_resource_root().get(self._path() + '/serviceTypes')\n    return resp[ApiList.LIST_KEY]", "response": "Get all service types supported by this cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rename(self, newname):\n    dic = self.to_json_dict()\n    if self._get_resource_root().version < 6:\n      dic['name'] = newname\n    else:\n      dic['displayName'] = newname\n    return self._put_cluster(dic)", "response": "Rename a cluster.\n\n    @param newname: New cluster name\n    @return: An ApiCluster object\n    @since: API v2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a service. @param name: Service name @param service_type: Service type @return: An ApiService object", "response": "def create_service(self, name, service_type):\n    \"\"\"\n    Create a service.\n\n    @param name: Service name\n    @param service_type: Service type\n    @return: An ApiService object\n    \"\"\"\n    return services.create_service(self._get_resource_root(), name,\n        service_type, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a service by name.", "response": "def delete_service(self, name):\n    \"\"\"\n    Delete a service by name.\n\n    @param name: Service name\n    @return: The deleted ApiService object\n    \"\"\"\n    return services.delete_service(self._get_resource_root(), name, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_services(self, view = None):\n    return services.get_all_services(self._get_resource_root(), self.name, view)", "response": "Get all services in this cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_parcel(self, product, version):\n    return parcels.get_parcel(self._get_resource_root(), product, version, self.name)", "response": "Lookup a parcel by product and version."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_parcels(self, view = None):\n    return parcels.get_all_parcels(self._get_resource_root(), self.name, view)", "response": "Get all parcels in this cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a host to the cluster.", "response": "def add_hosts(self, hostIds):\n    \"\"\"\n    Adds a host to the cluster.\n\n    @param hostIds: List of IDs of hosts to add to cluster.\n    @return: A list of ApiHostRef objects of the new\n             hosts that were added to the cluster\n    @since: API v3\n    \"\"\"\n    hostRefList = [ApiHostRef(self._get_resource_root(), x) for x in hostIds]\n    return self._post(\"hosts\", ApiHostRef, True, data=hostRefList,\n        api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef restart(self, restart_only_stale_services=None,\n    redeploy_client_configuration=None,\n    restart_service_names=None):\n    \"\"\"\n    Restart all services in the cluster.\n    Services are restarted in the appropriate order given their dependencies.\n\n    @param restart_only_stale_services: Only restart services that have stale\n                                        configuration and their dependent\n                                        services. Default is False.\n    @param redeploy_client_configuration: Re-deploy client configuration for\n                                          all services in the cluster. Default\n                                          is False.\n    @param restart_service_names: Only restart services that are specified and their dependent services.\n                                  Available since API v11.\n    @since API v6\n\n    @return: Reference to the submitted command.\n    \"\"\"\n    if self._get_resource_root().version < 6:\n      return self._cmd('restart')\n    else:\n      args = dict()\n      args['restartOnlyStaleServices'] = restart_only_stale_services\n      args['redeployClientConfiguration'] = redeploy_client_configuration\n      if self._get_resource_root().version >= 11:\n        args['restartServiceNames'] = restart_service_names\n      return self._cmd('restart', data=args, api_version=6)", "response": "Restart all services in the specified language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enter_maintenance_mode(self):\n    cmd = self._cmd('enterMaintenanceMode')\n    if cmd.success:\n      self._update(get_cluster(self._get_resource_root(), self.name))\n    return cmd", "response": "Put the cluster in maintenance mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a host template by name.", "response": "def get_host_template(self, name):\n    \"\"\"\n    Retrieves a host templates by name.\n    @param name: Host template name.\n    @return: An ApiHostTemplate object.\n    \"\"\"\n    return host_templates.get_host_template(self._get_resource_root(), name, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a host template.", "response": "def create_host_template(self, name):\n    \"\"\"\n    Creates a host template.\n    @param name: Name of the host template to create.\n    @return: An ApiHostTemplate object.\n    \"\"\"\n    return host_templates.create_host_template(self._get_resource_root(), name, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a host template.", "response": "def delete_host_template(self, name):\n    \"\"\"\n    Deletes a host template.\n    @param name: Name of the host template to delete.\n    @return: An ApiHostTemplate object.\n    \"\"\"\n    return host_templates.delete_host_template(self._get_resource_root(), name, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rolling_restart(self, slave_batch_size=None,\n                      slave_fail_count_threshold=None,\n                      sleep_seconds=None,\n                      stale_configs_only=None,\n                      unupgraded_only=None,\n                      roles_to_include=None,\n                      restart_service_names=None):\n    \"\"\"\n    Command to do a \"best-effort\" rolling restart of the given cluster,\n    i.e. it does plain restart of services that cannot be rolling restarted,\n    followed by first rolling restarting non-slaves and then rolling restarting\n    the slave roles of services that can be rolling restarted. The slave restarts\n    are done host-by-host.\n    @param slave_batch_size: Number of hosts with slave roles to restart at a time\n           Must be greater than 0. Default is 1.\n    @param slave_fail_count_threshold: The threshold for number of slave host batches that\n           are allowed to fail to restart before the entire command is considered failed.\n           Must be >= 0. Default is 0.\n    @param sleep_seconds: Number of seconds to sleep between restarts of slave host batches.\n           Must be >=0. Default is 0.\n    @param stale_configs_only: Restart roles with stale configs only. Default is false.\n    @param unupgraded_only: Restart roles that haven't been upgraded yet. Default is false.\n    @param roles_to_include: Role types to restart. Default is slave roles only.\n    @param restart_service_names: List of specific services to restart.\n    @return: Reference to the submitted command.\n    @since: API v4\n    \"\"\"\n    args = dict()\n    if slave_batch_size:\n      args['slaveBatchSize'] = slave_batch_size\n    if slave_fail_count_threshold:\n      args['slaveFailCountThreshold'] = slave_fail_count_threshold\n    if sleep_seconds:\n      args['sleepSeconds'] = sleep_seconds\n    if stale_configs_only:\n      args['staleConfigsOnly'] = stale_configs_only\n    if unupgraded_only:\n      args['unUpgradedOnly'] = unupgraded_only\n    if roles_to_include:\n      args['rolesToInclude'] = roles_to_include\n    if restart_service_names:\n      args['restartServiceNames'] = restart_service_names\n\n    return self._cmd('rollingRestart', data=args, api_version=4)", "response": "This method is used to submit a rolling restart command to the slave cluster."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rolling_upgrade(self, upgrade_from_cdh_version,\n                      upgrade_to_cdh_version,\n                      upgrade_service_names,\n                      slave_batch_size=None,\n                      slave_fail_count_threshold=None,\n                      sleep_seconds=None):\n    \"\"\"\n    Command to do a rolling upgrade of services in the given cluster\n\n    This command does not handle any services that don't support rolling\n    upgrades. The command will throw an error and not start if upgrade of\n    any such service is requested.\n\n    This command does not upgrade the full CDH Cluster. You should normally\n    use the upgradeCDH Command for upgrading the cluster. This is primarily\n    helpful if you need to need to recover from an upgrade failure or for\n    advanced users to script an alternative to the upgradeCdhCommand.\n\n    This command expects the binaries to be available on hosts and activated.\n    It does not change any binaries on the hosts.\n\n    @param upgrade_from_cdh_version: Current CDH Version of the services.\n           Example versions are: \"5.1.0\", \"5.2.2\" or \"5.4.0\"\n    @param upgrade_to_cdh_version: Target CDH Version for the services.\n           The CDH version should already be present and activated on the nodes.\n           Example versions are: \"5.1.0\", \"5.2.2\" or \"5.4.0\"\n    @param upgrade_service_names: List of specific services to be upgraded and restarted.\n    @param slave_batch_size: Number of hosts with slave roles to restart at a time\n           Must be greater than 0. Default is 1.\n    @param slave_fail_count_threshold: The threshold for number of slave host batches that\n           are allowed to fail to restart before the entire command is considered failed.\n           Must be >= 0. Default is 0.\n    @param sleep_seconds: Number of seconds to sleep between restarts of slave host batches.\n           Must be >=0. Default is 0.\n\n    @return: Reference to the submitted command.\n    @since: API v10\n    \"\"\"\n    args = dict()\n    args['upgradeFromCdhVersion'] = upgrade_from_cdh_version\n    args['upgradeToCdhVersion'] = upgrade_to_cdh_version\n    args['upgradeServiceNames'] = upgrade_service_names\n\n    if slave_batch_size:\n      args['slaveBatchSize'] = slave_batch_size\n    if slave_fail_count_threshold:\n      args['slaveFailCountThreshold'] = slave_fail_count_threshold\n    if sleep_seconds:\n      args['sleepSeconds'] = sleep_seconds\n\n    return self._cmd('rollingUpgrade', data=args, api_version=10)", "response": "This method is used to submit a rolling upgrade of services in a given cluster. It is intended to be used by the upgradeCDH command. It is intended to be used by the upgradeCDH command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upgrade_cdh(self, deploy_client_config=True, start_all_services=True,\n      cdh_parcel_version=None, cdh_package_version=None,\n      rolling_restart=False, slave_batch_size=None, sleep_seconds=None,\n      slave_fail_count_threshold=None):\n    \"\"\"\n    Perform CDH upgrade to the next major version. In v9+, also supports\n    minor CDH 5 upgrades (5.a.b to 5.x.y where x > a) and supports maintenance\n    release changes (a.b.x to a.b.y).\n\n    If using packages, CDH packages on all hosts of the cluster must be\n    manually upgraded before this command is issued.\n\n    The command will upgrade the services and their configuration to the\n    requested version. All running services will be stopped before proceeding,\n    unless rolling restart is requested and is available.\n\n    @param deploy_client_config: Whether to deploy client configurations\n           after the upgrade. Default is True. Has no effect in v9+;\n           client configurations are always deployed.\n    @param start_all_services: Whether to start all services after the upgrade.\n           Default is True. Has no effect in v9+; services are always\n           restarted.\n    @param cdh_parcel_version: If upgrading to parcels, the full version of an\n           already distributed parcel for the next CDH version. Default\n           is None. Example versions are: '5.0.0-1.cdh5.0.0.p0.11' or\n           '5.0.2-1.cdh5.0.2.p0.32'.\n    @param cdh_package_version: If upgrading to packages, the full version of an\n           already installed package for the next CDH version. Default\n           is None. Example versions are: '5.2.0' or '4.5.0'. Only available\n           since v9.\n    @param rolling_restart: If you'd like to do a rolling restart, set this to\n           True. Default is False. Only available since v9.\n    @param slave_batch_size: Controls the rolling restart slave batch size.\n           Only applicable when rolling_restart is True.\n    @param sleep_seconds: Controls how many seconds to sleep betweein rolling\n           restart batches. Only applicable when rolling_restart is True.\n    @param slave_fail_count_threshold: Controls how many slave restart failures\n           are tolerated in a rolling restart. Only applicable when\n           rolling_restart is True.\n    @return: Reference to the submitted command.\n    @since: API v6 for major upgrades only, v9 for maintenance and CDH 5 minor\n            releases.\n    \"\"\"\n    args = dict()\n    args['deployClientConfig'] = deploy_client_config\n    args['startAllServices'] = start_all_services\n    if cdh_parcel_version:\n      args['cdhParcelVersion'] = cdh_parcel_version\n    if cdh_package_version:\n      args['cdhPackageVersion'] = cdh_package_version\n    if rolling_restart:\n      args['rollingRestartArgs'] = {\n          'slaveBatchSize' : slave_batch_size,\n          'sleepSeconds' : sleep_seconds,\n          'slaveFailCountThreshold' : slave_fail_count_threshold\n        }\n    return self._cmd('upgradeCdh', data=args, api_version=6)", "response": "This method is used to upgrade a CDH version to the next major version."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncommands to configure the cluster to use Kerberos for authentication. This command will configure all relevant services on a cluster for Kerberos usage. This command will trigger a GenerateCredentials command to create Kerberos keytabs for all roles in the cluster. @param datanode_transceiver_port: The HDFS DataNode transceiver port to use. This will be applied to all DataNode role configuration groups. If not specified, this will default to 1004. @param datanode_web_port: The HDFS DataNode web port to use. This will be applied to all DataNode role configuration groups. If not specified, this will default to 1006. @return: Reference to the submitted command. @since: API v11", "response": "def configure_for_kerberos(self, datanode_transceiver_port=None,\n    datanode_web_port=None):\n    \"\"\"\n    Command to configure the cluster to use Kerberos for authentication.\n\n    This command will configure all relevant services on a cluster for\n    Kerberos usage.  This command will trigger a GenerateCredentials command\n    to create Kerberos keytabs for all roles in the cluster.\n\n    @param datanode_transceiver_port: The HDFS DataNode transceiver port to use.\n           This will be applied to all DataNode role configuration groups. If\n           not specified, this will default to 1004.\n    @param datanode_web_port: The HDFS DataNode web port to use.  This will be\n           applied to all DataNode role configuration groups. If not specified,\n           this will default to 1006.\n    @return: Reference to the submitted command.\n    @since: API v11\n    \"\"\"\n    args = dict()\n    if datanode_transceiver_port:\n        args['datanodeTransceiverPort'] = datanode_transceiver_port\n    if datanode_web_port:\n        args['datanodeWebPort'] = datanode_web_port\n    return self._cmd('configureForKerberos', data=args, api_version=11)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the cluster template for the given cluster.", "response": "def export(self, export_auto_config=False):\n    \"\"\"\n    Export the cluster template for the given cluster. ccluster must have host\n    templates defined. It cluster does not have host templates defined it will\n    export host templates based on roles assignment.\n\n    @param export_auto_config: Also export auto configured configs\n    @return: Return cluster template\n    @since: API v12\n    \"\"\"\n\n    return self._get(\"export\", ApiClusterTemplate, False,\n                     params=dict(exportAutoConfig=export_auto_config), api_version=12)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist available DFS services in a cluster.", "response": "def list_dfs_services(self, view=None):\n    \"\"\"\n    List available DFS (distributed file system) services in a cluster.\n    @param view: View to materialize\n    @return: List of available distributed file system services in the cluster.\n    @since: API v12\n    \"\"\"\n    if view:\n      return self._get_resource_root().get(\"%s/%s?view=%s\" % (self._path(), 'dfsServices', view))\n    else:\n      return self._get_resource_root().get(\"%s/%s\" % (self._path(), 'dfsServices'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_api_version(resource_root, min_version):\n  if resource_root.version < min_version:\n    raise Exception(\"API version %s is required but %s is in use.\"\n        % (min_version, resource_root.version))", "response": "Checks if the resource_root s API version is at least the given minimum version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef config_to_api_list(dic):\n  config = [ ]\n  for k, v in dic.iteritems():\n    config.append({ 'name' : k, 'value': v })\n  return { ApiList.LIST_KEY : config }", "response": "Converts a python dictionary into a list containing the proper\n ApiConfig encoding for configuration data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_to_config(dic, full = False):\n  config = { }\n  for entry in dic['items']:\n    k = entry['name']\n    if full:\n      config[k] = ApiConfig.from_json_dict(entry, None)\n    else:\n      config[k] = entry.get('value')\n  return config", "response": "Converts a JSON - decoded config dictionary to a python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_json(self, value, preserve_ro):\n    if hasattr(value, 'to_json_dict'):\n      return value.to_json_dict(preserve_ro)\n    elif isinstance(value, dict) and self._atype == ApiConfig:\n      return config_to_api_list(value)\n    elif isinstance(value, datetime.datetime):\n      return value.strftime(self.DATE_FMT)\n    elif isinstance(value, list) or isinstance(value, tuple):\n      if self._is_api_list:\n        return ApiList(value).to_json_dict()\n      else:\n        return [ self.to_json(x, preserve_ro) for x in value ]\n    else:\n      return value", "response": "Converts the given value to JSON encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_json(self, resource_root, data):\n    if data is None:\n      return None\n\n    if self._atype == datetime.datetime:\n      return datetime.datetime.strptime(data, self.DATE_FMT)\n    elif self._atype == ApiConfig:\n      # ApiConfig is special. We want a python dictionary for summary views,\n      # but an ApiList for full views. Try to detect each case from the JSON\n      # data.\n      if not data['items']:\n        return { }\n      first = data['items'][0]\n      return json_to_config(data, len(first) == 2)\n    elif self._is_api_list:\n      return ApiList.from_json_dict(data, resource_root, self._atype)\n    elif isinstance(data, list):\n      return [ self.from_json(resource_root, x) for x in data ]\n    elif hasattr(self._atype, 'from_json_dict'):\n      return self._atype.from_json_dict(data, resource_root)\n    else:\n      return data", "response": "Parses the given JSON value into an appropriate python object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(obj, resource_root, attrs=None):\n    # This works around http://bugs.python.org/issue2646\n    # We use unicode strings as keys in kwargs.\n    str_attrs = { }\n    if attrs:\n      for k, v in attrs.iteritems():\n        if k not in ('self', 'resource_root'):\n          str_attrs[k] = v\n    BaseApiObject.__init__(obj, resource_root, **str_attrs)", "response": "This is a hack around the real constructor to avoid issues with the self argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting all the attributes in the dictionary. Optionally allows setting read - only attributes and skipping JSON deserialization of values.", "response": "def _set_attrs(self, attrs, allow_ro=False, from_json=True):\n    \"\"\"\n    Sets all the attributes in the dictionary. Optionally, allows setting\n    read-only attributes (e.g. when deserializing from JSON) and skipping\n    JSON deserialization of values.\n    \"\"\"\n    for k, v in attrs.iteritems():\n      attr = self._check_attr(k, allow_ro)\n      if attr and from_json:\n        v = attr.from_json(self._get_resource_root(), v)\n      object.__setattr__(self, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy state from api_obj to self.", "response": "def _update(self, api_obj):\n    \"\"\"Copy state from api_obj to this object.\"\"\"\n    if not isinstance(self, api_obj.__class__):\n      raise ValueError(\n          \"Class %s does not derive from %s; cannot update attributes.\" %\n          (self.__class__, api_obj.__class__))\n\n    for name in self._get_attributes().keys():\n      try:\n        val = getattr(api_obj, name)\n        setattr(self, name, val)\n      except AttributeError, ignored:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise an exception if the version of the api is less than the given version.", "response": "def _require_min_api_version(self, version):\n    \"\"\"\n    Raise an exception if the version of the api is less than the given version.\n\n    @param version: The minimum required version.\n    \"\"\"\n    actual_version = self._get_resource_root().version\n    version = max(version, self._api_version())\n    if actual_version < version:\n      raise Exception(\"API version %s is required but %s is in use.\"\n          % (version, actual_version))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a command on the resource.", "response": "def _cmd(self, command, data=None, params=None, api_version=1):\n    \"\"\"\n    Invokes a command on the resource. Commands are expected to be under the\n    \"commands/\" sub-resource.\n    \"\"\"\n    return self._post(\"commands/\" + command, ApiCommand,\n        data=data, params=params, api_version=api_version)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve an ApiConfig list from the given relative path.", "response": "def _get_config(self, rel_path, view, api_version=1):\n    \"\"\"\n    Retrieves an ApiConfig list from the given relative path.\n    \"\"\"\n    self._require_min_api_version(api_version)\n    params = view and dict(view=view) or None\n    resp = self._get_resource_root().get(self._path() + '/' + rel_path,\n        params=params)\n    return json_to_config(resp, view == 'full')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the updated data about the command from the server.", "response": "def fetch(self):\n    \"\"\"\n    Retrieve updated data about the command from the server.\n\n    @return: A new ApiCommand object.\n    \"\"\"\n    if self.id == ApiCommand.SYNCHRONOUS_COMMAND_ID:\n      return self\n\n    resp = self._get_resource_root().get(self._path())\n    return ApiCommand.from_json_dict(resp, self._get_resource_root())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait(self, timeout=None):\n    if self.id == ApiCommand.SYNCHRONOUS_COMMAND_ID:\n      return self\n\n    SLEEP_SEC = 5\n\n    if timeout is None:\n      deadline = None\n    else:\n      deadline = time.time() + timeout\n\n    while True:\n      cmd = self.fetch()\n      if not cmd.active:\n        return cmd\n\n      if deadline is not None:\n        now = time.time()\n        if deadline < now:\n          return cmd\n        else:\n          time.sleep(min(SLEEP_SEC, deadline - now))\n      else:\n        time.sleep(SLEEP_SEC)", "response": "Wait for the command to finish."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abort(self):\n    if self.id == ApiCommand.SYNCHRONOUS_COMMAND_ID:\n      return self\n\n    path = self._path() + '/abort'\n    resp = self._get_resource_root().post(path)\n    return ApiCommand.from_json_dict(resp, self._get_resource_root())", "response": "Abort a running command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retry(self):\n    path = self._path() + '/retry'\n    resp = self._get_resource_root().post(path)\n    return ApiCommand.from_json_dict(resp, self._get_resource_root())", "response": "Retry a failed or aborted command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_role_config_groups(resource_root, service_name, apigroup_list,\n    cluster_name=\"default\"):\n  \"\"\"\n  Create role config groups.\n  @param resource_root: The root Resource object.\n  @param service_name: Service name.\n  @param apigroup_list: List of role config groups to create.\n  @param cluster_name: Cluster name.\n  @return: New ApiRoleConfigGroup object.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.post,\n      _get_role_config_groups_path(cluster_name, service_name),\n      ApiRoleConfigGroup, True, data=apigroup_list, api_version=3)", "response": "Create role config groups."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_role_config_group(resource_root, service_name, name, display_name,\n    role_type, cluster_name=\"default\"):\n  \"\"\"\n  Create a role config group.\n  @param resource_root: The root Resource object.\n  @param service_name: Service name.\n  @param name: The name of the new group.\n  @param display_name: The display name of the new group.\n  @param role_type: The role type of the new group.\n  @param cluster_name: Cluster name.\n  @return: List of created role config groups.\n  \"\"\"\n  apigroup = ApiRoleConfigGroup(resource_root, name, display_name, role_type)\n  return create_role_config_groups(resource_root, service_name, [apigroup],\n      cluster_name)[0]", "response": "Create a role config group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a role config group by name.", "response": "def get_role_config_group(resource_root, service_name, name,\n    cluster_name=\"default\"):\n  \"\"\"\n  Find a role config group by name.\n  @param resource_root: The root Resource object.\n  @param service_name: Service name.\n  @param name: Role config group name.\n  @param cluster_name: Cluster name.\n  @return: An ApiRoleConfigGroup object.\n  \"\"\"\n  return _get_role_config_group(resource_root, _get_role_config_group_path(\n      cluster_name, service_name, name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_role_config_groups(resource_root, service_name,\n    cluster_name=\"default\"):\n  \"\"\"\n  Get all role config groups in the specified service.\n  @param resource_root: The root Resource object.\n  @param service_name: Service name.\n  @param cluster_name: Cluster name.\n  @return: A list of ApiRoleConfigGroup objects.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.get,\n      _get_role_config_groups_path(cluster_name, service_name),\n      ApiRoleConfigGroup, True, api_version=3)", "response": "Get all role config groups in the specified service."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a role config group by name.", "response": "def update_role_config_group(resource_root, service_name, name, apigroup,\n    cluster_name=\"default\"):\n  \"\"\"\n  Update a role config group by name.\n  @param resource_root: The root Resource object.\n  @param service_name: Service name.\n  @param name: Role config group name.\n  @param apigroup: The updated role config group.\n  @param cluster_name: Cluster name.\n  @return: The updated ApiRoleConfigGroup object.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.put,\n      _get_role_config_group_path(cluster_name, service_name, name),\n      ApiRoleConfigGroup, data=apigroup, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_role_config_group(resource_root, service_name, name,\n    cluster_name=\"default\"):\n  \"\"\"\n  Delete a role config group by name.\n  @param resource_root: The root Resource object.\n  @param service_name: Service name.\n  @param name: Role config group name.\n  @param cluster_name: Cluster name.\n  @return: The deleted ApiRoleConfigGroup object.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.delete,\n      _get_role_config_group_path(cluster_name, service_name, name),\n      ApiRoleConfigGroup, api_version=3)", "response": "Delete a role config group by name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_roles(resource_root, service_name, name, role_names,\n    cluster_name=\"default\"):\n  \"\"\"\n  Moves roles to the specified role config group.\n\n  The roles can be moved from any role config group belonging\n  to the same service. The role type of the destination group\n  must match the role type of the roles.\n\n  @param name: The name of the group the roles will be moved to.\n  @param role_names: The names of the roles to move.\n  @return: List of roles which have been moved successfully.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.put,\n      _get_role_config_group_path(cluster_name, service_name, name) + '/roles',\n      ApiRole, True, data=role_names, api_version=3)", "response": "Moves roles to the specified role config group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_roles_to_base_role_config_group(resource_root, service_name,\n     role_names, cluster_name=\"default\"):\n  \"\"\"\n  Moves roles to the base role config group.\n\n  The roles can be moved from any role config group belonging to the same\n  service. The role type of the roles may vary. Each role will be moved to\n  its corresponding base group depending on its role type.\n\n  @param role_names: The names of the roles to move.\n  @return: List of roles which have been moved successfully.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.put,\n      _get_role_config_groups_path(cluster_name, service_name) + '/roles',\n      ApiRole, True, data=role_names, api_version=3)", "response": "Moves roles to the base role config group."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the group s configuration.", "response": "def update_config(self, config):\n    \"\"\"\n    Update the group's configuration.\n\n    @param config: Dictionary with configuration to update.\n    @return: Dictionary with updated configuration.\n    \"\"\"\n    path = self._path() + '/config'\n    resp = self._get_resource_root().put(path, data = config_to_json(config))\n    return json_to_config(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving roles to this config group.", "response": "def move_roles(self, roles):\n    \"\"\"\n    Moves roles to this role config group.\n\n    The roles can be moved from any role config group belonging\n    to the same service. The role type of the destination group\n    must match the role type of the roles.\n\n    @param roles: The names of the roles to move.\n    @return: List of roles which have been moved successfully.\n    \"\"\"\n    return move_roles(self._get_resource_root(), self.serviceRef.serviceName,\n        self.name, roles, self.serviceRef.clusterName)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a role in the cluster.", "response": "def create_role(resource_root,\n                service_name,\n                role_type,\n                role_name,\n                host_id,\n                cluster_name=\"default\"):\n  \"\"\"\n  Create a role\n  @param resource_root: The root Resource object.\n  @param service_name: Service name\n  @param role_type: Role type\n  @param role_name: Role name\n  @param cluster_name: Cluster name\n  @return: An ApiRole object\n  \"\"\"\n  apirole = ApiRole(resource_root, role_name, role_type,\n                    ApiHostRef(resource_root, host_id))\n  return call(resource_root.post,\n      _get_roles_path(cluster_name, service_name),\n      ApiRole, True, data=[apirole])[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a role by name.", "response": "def get_role(resource_root, service_name, name, cluster_name=\"default\"):\n  \"\"\"\n  Lookup a role by name\n  @param resource_root: The root Resource object.\n  @param service_name: Service name\n  @param name: Role name\n  @param cluster_name: Cluster name\n  @return: An ApiRole object\n  \"\"\"\n  return _get_role(resource_root, _get_role_path(cluster_name, service_name, name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_roles(resource_root, service_name, cluster_name=\"default\", view=None):\n  return call(resource_root.get,\n      _get_roles_path(cluster_name, service_name),\n      ApiRole, True, params=view and dict(view=view) or None)", "response": "Get all roles in a cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all roles of a certain type in a service.", "response": "def get_roles_by_type(resource_root, service_name, role_type,\n                      cluster_name=\"default\", view=None):\n  \"\"\"\n  Get all roles of a certain type in a service\n  @param resource_root: The root Resource object.\n  @param service_name: Service name\n  @param role_type: Role type\n  @param cluster_name: Cluster name\n  @return: A list of ApiRole objects.\n  \"\"\"\n  roles = get_all_roles(resource_root, service_name, cluster_name, view)\n  return [ r for r in roles if r.type == role_type ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a role by name", "response": "def delete_role(resource_root, service_name, name, cluster_name=\"default\"):\n  \"\"\"\n  Delete a role by name\n  @param resource_root: The root Resource object.\n  @param service_name: Service name\n  @param name: Role name\n  @param cluster_name: Cluster name\n  @return: The deleted ApiRole object\n  \"\"\"\n  return call(resource_root.delete,\n      _get_role_path(cluster_name, service_name, name), ApiRole)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the metrics for this role.", "response": "def get_metrics(self, from_time=None, to_time=None, metrics=None, view=None):\n    \"\"\"\n    This endpoint is not supported as of v6. Use the timeseries API\n    instead. To get all metrics for a role with the timeseries API use\n    the query:\n\n    'select * where roleName = $ROLE_NAME'.\n\n    To get specific metrics for a role use a comma-separated list of\n    the metric names as follows:\n\n    'select $METRIC_NAME1, $METRIC_NAME2 where roleName = $ROLE_NAME'.\n\n    For more information see http://tiny.cloudera.com/tsquery_doc\n    @param from_time: A datetime; start of the period to query (optional).\n    @param to_time: A datetime; end of the period to query (default = now).\n    @param metrics: List of metrics to query (default = all).\n    @param view: View to materialize ('full' or 'summary')\n    @return: List of metrics and their readings.\n    \"\"\"\n    return self._get_resource_root().get_metrics(self._path() + '/metrics',\n        from_time, to_time, metrics, view)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_users(resource_root, view=None):\n  return call(resource_root.get, USERS_PATH, ApiUser, True,\n      params=view and dict(view=view) or None)", "response": "Get all users.\n\n  @param resource_root: The root Resource object\n  @param view: View to materialize ('full' or 'summary').\n  @return: A list of ApiUser objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a user. @param resource_root: The root Resource object @param username: Username @param password: Password @param roles: List of roles for the user. This should be [] or ['ROLE_USER'] for a regular user, ['ROLE_ADMIN'] for an admin, or ['ROLE_LIMITED'] for a limited admin. @return: An ApiUser object", "response": "def create_user(resource_root, username, password, roles):\n  \"\"\"\n  Create a user.\n\n  @param resource_root: The root Resource object\n  @param username: Username\n  @param password: Password\n  @param roles: List of roles for the user. This should be [] or ['ROLE_USER']\n                for a regular user, ['ROLE_ADMIN'] for an admin, or\n                ['ROLE_LIMITED'] for a limited admin.\n  @return: An ApiUser object\n  \"\"\"\n  apiuser = ApiUser(resource_root, username, password=password, roles=roles)\n  return call(resource_root.post, USERS_PATH, ApiUser, True,\n      data=[apiuser])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_user(resource_root, user):\n  return call(resource_root.put,\n      '%s/%s' % (USERS_PATH, user.name), ApiUser, data=user)", "response": "Updates a user s details with those provided."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grant_admin_role(self):\n    apiuser = ApiUser(self._get_resource_root(), self.name, roles=['ROLE_ADMIN'])\n    return self._put('', ApiUser, data=apiuser)", "response": "Grant admin access to a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a batch request with one or more elements.", "response": "def do_batch(resource_root, elements):\n  \"\"\"\n  Execute a batch request with one or more elements. If any element fails,\n  the entire request is rolled back and subsequent elements are ignored.\n\n  @param elements: A list of ApiBatchRequestElements\n  @return: an ApiBatchResponseList\n  @since: API v6\n  \"\"\"\n  return call(resource_root.post, BATCH_PATH, ApiBatchResponseList,\n      data=elements, api_version=6)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a row to the table Taxonomy", "response": "def add_row(self, row):\n\n        \"\"\"Add a row to the table\n\n        Arguments:\n\n        row - row of data, should be a list with as many elements as the table\n        has fields\"\"\"\n\n        if self._field_names and len(row) != len(self._field_names):\n            raise Exception(\"Row has incorrect number of values, (actual) %d!=%d (expected)\" %(len(row),len(self._field_names)))\n        self._rows.append(list(row))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string representation of the current state of the table.", "response": "def get_string(self, **kwargs):\n\n        \"\"\"Return string representation of table in current state.\n\n        Arguments:\n\n        start - index of first data row to include in output\n        end - index of last data row to include in output PLUS ONE (list slice style)\n        fields - names of fields (columns) to include\n        header - print a header showing field names (True or False)\n        border - print a border around the table (True or False)\n        hrules - controls printing of horizontal rules after rows.  Allowed values: FRAME, ALL, NONE\n\tint_format - controls formatting of integer data\n\tfloat_format - controls formatting of floating point data\n        padding_width - number of spaces on either side of column data (only used if left and right paddings are None)\n        left_padding_width - number of spaces on left hand side of column data\n        right_padding_width - number of spaces on right hand side of column data\n        vertical_char - single character string used to draw vertical lines\n        horizontal_char - single character string used to draw horizontal lines\n        junction_char - single character string used to draw line junctions\n        sortby - name of field to sort rows by\n        sort_key - sorting key function, applied to data points before sorting\n        reversesort - True or False to sort in descending or ascending order\"\"\"\n\n        options = self._get_options(kwargs)\n\n        bits = []\n\n        # Don't think too hard about an empty table\n        if self.rowcount == 0:\n            return \"\"\n\n        rows = self._get_rows(options)\n        self._compute_widths(rows, options)\n\n        # Build rows\n        # (for now, this is done before building headers etc. because rowbits.append\n        # contains width-adjusting voodoo which has to be done first.  This is ugly\n        # and Wrong and will change soon)\n        rowbits = []\n        for row in rows:\n            rowbits.append(self._stringify_row(row, options))\n\n\n        # Add header or top of border\n        if options[\"header\"]:\n            bits.append(self._stringify_header(options))\n        elif options[\"border\"] and options[\"hrules\"] != NONE:\n            bits.append(self._hrule)\n\n        # Add rows\n        bits.extend(rowbits)\n\n        # Add bottom of border\n        if options[\"border\"] and not options[\"hrules\"]:\n            bits.append(self._hrule)\n        \n        string = \"\\n\".join(bits)\n        self._nonunicode = string\n        return _unicode(string)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a service in the cluster.", "response": "def create_service(resource_root, name, service_type,\n                   cluster_name=\"default\"):\n  \"\"\"\n  Create a service\n  @param resource_root: The root Resource object.\n  @param name: Service name\n  @param service_type: Service type\n  @param cluster_name: Cluster name\n  @return: An ApiService object\n  \"\"\"\n  apiservice = ApiService(resource_root, name, service_type)\n  return call(resource_root.post,\n      SERVICES_PATH % (cluster_name,),\n      ApiService, True, data=[apiservice])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all services in a cluster.", "response": "def get_all_services(resource_root, cluster_name=\"default\", view=None):\n  \"\"\"\n  Get all services\n  @param resource_root: The root Resource object.\n  @param cluster_name: Cluster name\n  @return: A list of ApiService objects.\n  \"\"\"\n  return call(resource_root.get,\n      SERVICES_PATH % (cluster_name,),\n      ApiService, True, params=view and dict(view=view) or None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a service by name", "response": "def delete_service(resource_root, name, cluster_name=\"default\"):\n  \"\"\"\n  Delete a service by name\n  @param resource_root: The root Resource object.\n  @param name: Service name\n  @param cluster_name: Cluster name\n  @return: The deleted ApiService object\n  \"\"\"\n  return call(resource_root.delete,\n      \"%s/%s\" % (SERVICES_PATH % (cluster_name,), name),\n      ApiService)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_svc_config(self, json_dic, view = None):\n    svc_config = json_to_config(json_dic, view == 'full')\n    rt_configs = { }\n    if json_dic.has_key(ROLETYPES_CFG_KEY):\n      for rt_config in json_dic[ROLETYPES_CFG_KEY]:\n        rt_configs[rt_config['roleType']] = \\\n            json_to_config(rt_config, view == 'full')\n\n    return (svc_config, rt_configs)", "response": "Parse a json - decoded ApiServiceConfig dictionary into a 2 - tuple."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a directory to the watching list.", "response": "def add_watched_directory(self, dir_path):\n    \"\"\"\n    Adds a directory to the watching list.\n\n    @param dir_path: The path of the directory to be added to the watching list\n    @return: The added directory, or null if failed\n    @since: API v14\n    \"\"\"\n    req = ApiWatchedDir(self._get_resource_root(), path=dir_path)\n    return self._post(\"watcheddir\", ApiWatchedDir, data=req, api_version=14)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of queries that satisfy the filter @type start_time: datetime.datetime. Note that the datetime must either be time zone aware or specified in the server time zone. See the python datetime documentation for more details about python's time zone handling. @param start_time: Queries must have ended after this time @type end_time: datetime.datetime. Note that the datetime must either be time zone aware or specified in the server time zone. See the python datetime documentation for more details about python's time zone handling. @param end_time: Queries must have started before this time @param filter_str: A filter to apply to the queries. For example: 'user = root and queryDuration > 5s' @param limit: The maximum number of results to return @param offset: The offset into the return list @since: API v4", "response": "def get_impala_queries(self, start_time, end_time, filter_str=\"\", limit=100,\n     offset=0):\n    \"\"\"\n    Returns a list of queries that satisfy the filter\n\n    @type start_time: datetime.datetime. Note that the datetime must either be\n                      time zone aware or specified in the server time zone. See\n                      the python datetime documentation for more details about\n                      python's time zone handling.\n    @param start_time: Queries must have ended after this time\n    @type end_time: datetime.datetime. Note that the datetime must either be\n                    time zone aware or specified in the server time zone. See\n                    the python datetime documentation for more details about\n                    python's time zone handling.\n    @param end_time: Queries must have started before this time\n    @param filter_str: A filter to apply to the queries. For example:\n                       'user = root and queryDuration > 5s'\n    @param limit: The maximum number of results to return\n    @param offset: The offset into the return list\n    @since: API v4\n    \"\"\"\n    params = {\n      'from':   start_time.isoformat(),\n      'to':     end_time.isoformat(),\n      'filter': filter_str,\n      'limit':  limit,\n      'offset': offset,\n    }\n    return self._get(\"impalaQueries\", ApiImpalaQueryResponse,\n        params=params, api_version=4)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_query_details(self, query_id, format='text'):\n    return self._get(\"impalaQueries/\" + query_id, ApiImpalaQueryDetailsResponse,\n        params=dict(format=format), api_version=4)", "response": "Get the query details"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling Llama - based resource management for Impala.", "response": "def enable_llama_rm(self, llama1_host_id, llama1_role_name=None,\n                      llama2_host_id=None, llama2_role_name=None,\n                      zk_service_name=None, skip_restart=False):\n    \"\"\"\n    Enable Llama-based resource management for Impala.\n\n    This command only applies to CDH 5.1+ Impala services.\n\n    This command configures YARN and Impala for Llama resource management,\n    and then creates one or two Llama roles, as specified by the parameters.\n    When two Llama roles are created, they are configured as an active-standby\n    pair. Auto-failover from active to standby Llama will be enabled using\n    ZooKeeper.\n\n    If optional role name(s) are specified, the new Llama role(s) will be\n    named accordingly; otherwise, role name(s) will be automatically generated.\n\n    By default, YARN, Impala, and any dependent services will be restarted,\n    and client configuration will be re-deployed across the cluster. These\n    default actions may be suppressed.\n\n    In order to enable Llama resource management, a YARN service must be\n    present in the cluster, and Cgroup-based resource management must be\n    enabled for all hosts with NodeManager roles. If these preconditions\n    are not met, the command will fail.\n\n    @param llama1_host_id: id of the host where the first Llama role will\n                           be created.\n    @param llama1_role_name: Name of the first Llama role. If omitted, a\n                             name will be generated automatically.\n    @param llama2_host_id: id of the host where the second Llama role will\n                           be created. If omitted, only one Llama role will\n                           be created (i.e., high availability will not be\n                           enabled).\n    @param llama2_role_name: Name of the second Llama role. If omitted, a\n                             name will be generated automatically.\n    @param zk_service_name: Name of the ZooKeeper service to use for\n                            auto-failover. Only relevant when enabling\n                            Llama RM in HA mode (i.e., when creating two\n                            Llama roles). If Impala's ZooKeeper dependency\n                            is already set, then that ZooKeeper service will\n                            be used for auto-failover, and this parameter\n                            may be omitted.\n    @param skip_restart: true to skip the restart of Yarn, Impala, and\n                         their dependent services, and to skip deployment\n                         of client configuration. Default is False (i.e.,\n                         by default dependent services are restarted and\n                         client configuration is deployed).\n    @return: Reference to the submitted command.\n    @since: API v8\n    \"\"\"\n    args = dict(\n      llama1HostId = llama1_host_id,\n      llama1RoleName = llama1_role_name,\n      llama2HostId = llama2_host_id,\n      llama2RoleName = llama2_role_name,\n      zkServiceName = zk_service_name,\n      skipRestart = skip_restart\n    )\n    return self._cmd('impalaEnableLlamaRm', data=args, api_version=8)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable high availability for an Impala Llama ApplicationMaster.", "response": "def enable_llama_ha(self, new_llama_host_id, zk_service_name=None,\n                      new_llama_role_name=None):\n    \"\"\"\n    Enable high availability for an Impala Llama ApplicationMaster.\n\n    This command only applies to CDH 5.1+ Impala services.\n\n    @param new_llama_host_id: id of the host where the second Llama role\n                              will be added.\n    @param zk_service_name: Name of the ZooKeeper service to use for\n                            auto-failover. If Impala's ZooKeeper dependency\n                            is already set, then that ZooKeeper service will\n                            be used for auto-failover, and this parameter\n                            may be omitted.\n    @param new_llama_role_name: Name of the new Llama role. If omitted, a\n                                name will be generated automatically.\n    @return: Reference to the submitted command.\n    @since: API v8\n    \"\"\"\n    args = dict(\n      newLlamaHostId = new_llama_host_id,\n      zkServiceName = zk_service_name,\n      newLlamaRoleName = new_llama_role_name\n    )\n    return self._cmd('impalaEnableLlamaHa', data=args, api_version=8)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of YARN applications that satisfy the filter @type start_time: datetime.datetime. Note that the datetime must either be time zone aware or specified in the server time zone. See the python datetime documentation for more details about python's time zone handling. @param start_time: Applications must have ended after this time @type end_time: datetime.datetime. Note that the datetime must either be time zone aware or specified in the server time zone. See the python datetime documentation for more details about python's time zone handling. @param filter_str: A filter to apply to the applications. For example: 'user = root and applicationDuration > 5s' @param limit: The maximum number of results to return @param offset: The offset into the return list @since: API v6", "response": "def get_yarn_applications(self, start_time, end_time, filter_str=\"\", limit=100,\n      offset=0):\n    \"\"\"\n    Returns a list of YARN applications that satisfy the filter\n    @type start_time: datetime.datetime. Note that the datetime must either be\n                      time zone aware or specified in the server time zone. See\n                      the python datetime documentation for more details about\n                      python's time zone handling.\n    @param start_time: Applications must have ended after this time\n    @type end_time: datetime.datetime. Note that the datetime must either be\n                    time zone aware or specified in the server time zone. See\n                    the python datetime documentation for more details about\n                    python's time zone handling.\n    @param filter_str: A filter to apply to the applications. For example:\n                       'user = root and applicationDuration > 5s'\n    @param limit: The maximum number of results to return\n    @param offset: The offset into the return list\n    @since: API v6\n    \"\"\"\n    params = {\n      'from':   start_time.isoformat(),\n      'to':     end_time.isoformat(),\n      'filter': filter_str,\n      'limit':  limit,\n      'offset': offset\n    }\n    return self._get(\"yarnApplications\", ApiYarnApplicationResponse,\n        params=params, api_version=6)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef collect_yarn_application_diagnostics(self, *application_ids):\n    args = dict(applicationIds = application_ids)\n    return self._cmd('yarnApplicationDiagnosticsCollection', api_version=8, data=args)", "response": "This method returns the Diagnostics data for the Yarn applications."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the Diagnostics data for Yarn applications.", "response": "def create_yarn_application_diagnostics_bundle(self, application_ids, ticket_number=None, comments=None):\n    \"\"\"\n    Collects the Diagnostics data for Yarn applications.\n\n    @param application_ids: An array of strings containing the ids of the\n                            yarn applications.\n    @param ticket_number: If applicable, the support ticket number of the issue\n                          being experienced on the cluster.\n    @param comments: Additional comments\n    @return: Reference to the submitted command.\n    @since: API v10\n    \"\"\"\n    args = dict(applicationIds = application_ids,\n                ticketNumber = ticket_number,\n                comments = comments)\n\n    return self._cmd('yarnApplicationDiagnosticsCollection', api_version=10, data=args)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config(self, view = None):\n    path = self._path() + '/config'\n    resp = self._get_resource_root().get(path,\n        params = view and dict(view=view) or None)\n    return self._parse_svc_config(resp, view)", "response": "Retrieves the service s configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_config(self, svc_config, **rt_configs):\n    path = self._path() + '/config'\n\n    if svc_config:\n      data = config_to_api_list(svc_config)\n    else:\n      data = { }\n    if rt_configs:\n      rt_list = [ ]\n      for rt, cfg in rt_configs.iteritems():\n        rt_data = config_to_api_list(cfg)\n        rt_data['roleType'] = rt\n        rt_list.append(rt_data)\n      data[ROLETYPES_CFG_KEY] = rt_list\n\n    resp = self._get_resource_root().put(path, data = json.dumps(data))\n    return self._parse_svc_config(resp)", "response": "Update the service s configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_role(self, role_name, role_type, host_id):\n    return roles.create_role(self._get_resource_root(), self.name, role_type,\n        role_name, host_id, self._get_cluster_name())", "response": "Create a role.\n\n    @param role_name: Role name\n    @param role_type: Role type\n    @param host_id: ID of the host to assign the role to\n    @return: An ApiRole object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a role by name.", "response": "def delete_role(self, name):\n    \"\"\"\n    Delete a role by name.\n\n    @param name: Role name\n    @return: The deleted ApiRole object\n    \"\"\"\n    return roles.delete_role(self._get_resource_root(), self.name, name,\n        self._get_cluster_name())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_role(self, name):\n    return roles.get_role(self._get_resource_root(), self.name, name,\n        self._get_cluster_name())", "response": "Lookup a role by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_roles(self, view = None):\n    return roles.get_all_roles(self._get_resource_root(), self.name,\n        self._get_cluster_name(), view)", "response": "Get all roles in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all roles of a certain type in a service.", "response": "def get_roles_by_type(self, role_type, view = None):\n    \"\"\"\n    Get all roles of a certain type in a service.\n\n    @param role_type: Role type\n    @param view: View to materialize ('full' or 'summary')\n    @return: A list of ApiRole objects.\n    \"\"\"\n    return roles.get_roles_by_type(self._get_resource_root(), self.name,\n        role_type, self._get_cluster_name(), view)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of role types in a service.", "response": "def get_role_types(self):\n    \"\"\"\n    Get a list of role types in a service.\n\n    @return: A list of role types (strings)\n    \"\"\"\n    resp = self._get_resource_root().get(self._path() + '/roleTypes')\n    return resp[ApiList.LIST_KEY]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of role configuration groups in the service.", "response": "def get_all_role_config_groups(self):\n    \"\"\"\n    Get a list of role configuration groups in the service.\n\n    @return: A list of ApiRoleConfigGroup objects.\n    @since: API v3\n    \"\"\"\n    return role_config_groups.get_all_role_config_groups(\n        self._get_resource_root(), self.name, self._get_cluster_name())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a role config group in the service by name.", "response": "def get_role_config_group(self, name):\n    \"\"\"\n    Get a role configuration group in the service by name.\n\n    @param name: The name of the role config group.\n    @return: An ApiRoleConfigGroup object.\n    @since: API v3\n    \"\"\"\n    return role_config_groups.get_role_config_group(\n        self._get_resource_root(), self.name, name, self._get_cluster_name())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a role config group.", "response": "def create_role_config_group(self, name, display_name, role_type):\n    \"\"\"\n    Create a role config group.\n\n    @param name: The name of the new group.\n    @param display_name: The display name of the new group.\n    @param role_type: The role type of the new group.\n    @return: New ApiRoleConfigGroup object.\n    @since: API v3\n    \"\"\"\n    return role_config_groups.create_role_config_group(\n        self._get_resource_root(), self.name, name, display_name, role_type,\n        self._get_cluster_name())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_role_config_group(self, name, apigroup):\n    return role_config_groups.update_role_config_group(\n        self._get_resource_root(), self.name, name, apigroup,\n        self._get_cluster_name())", "response": "Update a role config group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_role_config_group(self, name):\n    return role_config_groups.delete_role_config_group(\n        self._get_resource_root(), self.name, name, self._get_cluster_name())", "response": "Delete a role config group by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling high availability for an HDFS NameNode.", "response": "def disable_hdfs_ha(self, active_name, secondary_name,\n      start_dependent_services=True, deploy_client_configs=True,\n                      disable_quorum_storage=False):\n    \"\"\"\n    Disable high availability for an HDFS NameNode.\n    This command is no longer supported with API v6 onwards. Use disable_nn_ha instead.\n\n    @param active_name: Name of the NameNode to keep.\n    @param secondary_name: Name of (existing) SecondaryNameNode to link to\n                           remaining NameNode.\n    @param start_dependent_services: whether to re-start dependent services.\n    @param deploy_client_configs: whether to re-deploy client configurations.\n    @param disable_quorum_storage: whether to disable Quorum-based Storage. Available since API v2.\n                                   Quorum-based Storage will be disabled for all\n                                   nameservices that have Quorum-based Storage\n                                   enabled.\n    @return: Reference to the submitted command.\n    \"\"\"\n    args = dict(\n      activeName = active_name,\n      secondaryName = secondary_name,\n      startDependentServices = start_dependent_services,\n      deployClientConfigs = deploy_client_configs,\n    )\n\n    version = self._get_resource_root().version\n    if version < 2:\n      if disable_quorum_storage:\n        raise AttributeError(\"Quorum-based Storage requires at least API version 2 available in Cloudera Manager 4.1.\")\n    else:\n      args['disableQuorumStorage'] = disable_quorum_storage\n\n    return self._cmd('hdfsDisableHa', data=args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_hdfs_auto_failover(self, nameservice, active_fc_name,\n      standby_fc_name, zk_service):\n    \"\"\"\n    Enable auto-failover for an HDFS nameservice.\n    This command is no longer supported with API v6 onwards. Use enable_nn_ha instead.\n\n    @param nameservice: Nameservice for which to enable auto-failover.\n    @param active_fc_name: Name of failover controller to create for active node.\n    @param standby_fc_name: Name of failover controller to create for stand-by node.\n    @param zk_service: ZooKeeper service to use.\n    @return: Reference to the submitted command.\n    \"\"\"\n    version = self._get_resource_root().version\n\n    args = dict(\n      nameservice = nameservice,\n      activeFCName = active_fc_name,\n      standByFCName = standby_fc_name,\n      zooKeeperService = dict(\n        clusterName = zk_service.clusterRef.clusterName,\n        serviceName = zk_service.name,\n        ),\n      )\n    return self._cmd('hdfsEnableAutoFailover', data=args)", "response": "Enable auto - failover for an HDFS nameservice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_hdfs_ha(self, active_name, active_shared_path, standby_name,\n      standby_shared_path, nameservice, start_dependent_services=True,\n      deploy_client_configs=True, enable_quorum_storage=False):\n    \"\"\"\n    Enable high availability for an HDFS NameNode.\n    This command is no longer supported with API v6 onwards. Use enable_nn_ha instead.\n\n    @param active_name: name of active NameNode.\n    @param active_shared_path: shared edits path for active NameNode.\n                               Ignored if Quorum-based Storage is being enabled.\n    @param standby_name: name of stand-by NameNode.\n    @param standby_shared_path: shared edits path for stand-by NameNode.\n                                Ignored if Quourm Journal is being enabled.\n    @param nameservice: nameservice for the HA pair.\n    @param start_dependent_services: whether to re-start dependent services.\n    @param deploy_client_configs: whether to re-deploy client configurations.\n    @param enable_quorum_storage: whether to enable Quorum-based Storage. Available since API v2.\n                                  Quorum-based Storage will be enabled for all\n                                  nameservices except those configured with NFS High\n                                  Availability.\n    @return: Reference to the submitted command.\n    \"\"\"\n    version = self._get_resource_root().version\n\n    args = dict(\n      activeName = active_name,\n      standByName = standby_name,\n      nameservice = nameservice,\n      startDependentServices = start_dependent_services,\n      deployClientConfigs = deploy_client_configs,\n    )\n\n    if enable_quorum_storage:\n      if version < 2:\n        raise AttributeError(\"Quorum-based Storage is not supported prior to Cloudera Manager 4.1.\")\n      else:\n        args['enableQuorumStorage'] = enable_quorum_storage\n    else:\n      if active_shared_path is None or standby_shared_path is None:\n        raise AttributeError(\"Active and standby shared paths must be specified if not enabling Quorum-based Storage\")\n      args['activeSharedEditsPath'] = active_shared_path\n      args['standBySharedEditsPath'] = standby_shared_path\n\n    return self._cmd('hdfsEnableHa', data=args)", "response": "Enable high availability for an HDFS NameNode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enable_nn_ha(self, active_name, standby_host_id, nameservice, jns,\n      standby_name_dir_list=None, qj_name=None, standby_name=None,\n      active_fc_name=None, standby_fc_name=None, zk_service_name=None,\n      force_init_znode=True, clear_existing_standby_name_dirs=True, clear_existing_jn_edits_dir=True):\n    \"\"\"\n    Enable High Availability (HA) with Auto-Failover for an HDFS NameNode.\n    @param active_name: Name of Active NameNode.\n    @param standby_host_id: ID of host where Standby NameNode will be created.\n    @param nameservice: Nameservice to be used while enabling HA.\n                        Optional if Active NameNode already has this config set.\n    @param jns: List of Journal Nodes to be created during the command.\n                Each element of the list must be a dict containing the following keys:\n                  - B{jnHostId}: ID of the host where the new JournalNode will be created.\n                  - B{jnName}: Name of the JournalNode role (optional)\n                  - B{jnEditsDir}: Edits dir of the JournalNode. Can be omitted if the config\n                    is already set at RCG level.\n    @param standby_name_dir_list: List of directories for the new Standby NameNode.\n                                  If not provided then it will use same dirs as Active NameNode.\n    @param qj_name: Name of the journal located on each JournalNodes' filesystem.\n                    This can be optionally provided if the config hasn't been already set for the Active NameNode.\n                    If this isn't provided and Active NameNode doesn't also have the config,\n                    then nameservice is used by default.\n    @param standby_name: Name of the Standby NameNode role to be created (Optional).\n    @param active_fc_name: Name of the Active Failover Controller role to be created (Optional).\n    @param standby_fc_name: Name of the Standby Failover Controller role to be created (Optional).\n    @param zk_service_name: Name of the ZooKeeper service to use for auto-failover.\n                            If HDFS service already depends on a ZooKeeper service then that ZooKeeper\n                            service will be used for auto-failover and in that case this parameter\n                            can either be omitted or should be the same ZooKeeper service.\n    @param force_init_znode: Indicates if the ZNode should be force initialized if it is\n                             already present. Useful while re-enabling High Availability. (Default: TRUE)\n    @param clear_existing_standby_name_dirs: Indicates if the existing name directories for Standby NameNode\n                                             should be cleared during the workflow.\n                                             Useful while re-enabling High Availability. (Default: TRUE)\n    @param clear_existing_jn_edits_dir: Indicates if the existing edits directories for the JournalNodes\n                                        for the specified nameservice should be cleared during the workflow.\n                                        Useful while re-enabling High Availability. (Default: TRUE)\n    @return: Reference to the submitted command.\n    @since: API v6\n    \"\"\"\n    args = dict (\n      activeNnName = active_name,\n      standbyNnName = standby_name,\n      standbyNnHostId = standby_host_id,\n      standbyNameDirList = standby_name_dir_list,\n      nameservice = nameservice,\n      qjName = qj_name,\n      activeFcName = active_fc_name,\n      standbyFcName = standby_fc_name,\n      zkServiceName = zk_service_name,\n      forceInitZNode = force_init_znode,\n      clearExistingStandbyNameDirs = clear_existing_standby_name_dirs,\n      clearExistingJnEditsDir = clear_existing_jn_edits_dir,\n      jns = jns\n    )\n    return self._cmd('hdfsEnableNnHa', data=args, api_version=6)", "response": "Enable High Availability with Auto - Failover for an HDFS NameNode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disable_nn_ha(self, active_name, snn_host_id, snn_check_point_dir_list,\n      snn_name=None):\n    \"\"\"\n    Disable high availability with automatic failover for an HDFS NameNode.\n\n    @param active_name: Name of the NamdeNode role that is going to be active after\n                        High Availability is disabled.\n    @param snn_host_id: Id of the host where the new SecondaryNameNode will be created.\n    @param snn_check_point_dir_list : List of directories used for checkpointing\n                                      by the new SecondaryNameNode.\n    @param snn_name: Name of the new SecondaryNameNode role (Optional).\n    @return: Reference to the submitted command.\n    @since: API v6\n    \"\"\"\n    args = dict(\n      activeNnName = active_name,\n      snnHostId = snn_host_id,\n      snnCheckpointDirList = snn_check_point_dir_list,\n      snnName = snn_name\n    )\n    return self._cmd('hdfsDisableNnHa', data=args, api_version=6)", "response": "Disable high availability with automatic failover for an HDFS NameNode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable_jt_ha(self, new_jt_host_id, force_init_znode=True, zk_service_name=None,\n      new_jt_name=None, fc1_name=None, fc2_name=None):\n    \"\"\"\n    Enable high availability for a MR JobTracker.\n\n    @param zk_service_name: Name of the ZooKeeper service to use for auto-failover.\n           If MapReduce service depends on a ZooKeeper service then that ZooKeeper\n           service will be used for auto-failover and in that case this parameter\n           can be omitted.\n    @param new_jt_host_id: id of the host where the second JobTracker\n                        will be added.\n    @param force_init_znode: Initialize the ZNode used for auto-failover even if\n                             it already exists. This can happen if JobTracker HA\n                             was enabled before and then disabled. Disable operation\n                             doesn't delete this ZNode. Defaults to true.\n    @param new_jt_name: Name of the second JobTracker role to be created.\n    @param fc1_name: Name of the Failover Controller role that is co-located with\n                     the existing JobTracker.\n    @param fc2_name: Name of the Failover Controller role that is co-located with\n                     the new JobTracker.\n    @return: Reference to the submitted command.\n    @since: API v5\n    \"\"\"\n    args = dict(\n      newJtHostId = new_jt_host_id,\n      forceInitZNode = force_init_znode,\n      zkServiceName = zk_service_name,\n      newJtRoleName = new_jt_name,\n      fc1RoleName = fc1_name,\n      fc2RoleName = fc2_name\n    )\n    return self._cmd('enableJtHa', data=args)", "response": "Enable high availability for a JobTracker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling high availability for a MR JobTracker active - standby pair.", "response": "def disable_jt_ha(self, active_name):\n    \"\"\"\n    Disable high availability for a MR JobTracker active-standby pair.\n\n    @param active_name: name of the JobTracker that will be active after\n                        the disable operation. The other JobTracker and\n                        Failover Controllers will be removed.\n    @return: Reference to the submitted command.\n    \"\"\"\n    args = dict(\n      activeName = active_name,\n    )\n    return self._cmd('disableJtHa', data=args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables high availability for a YARN ResourceManager.", "response": "def enable_rm_ha(self, new_rm_host_id, zk_service_name=None):\n    \"\"\"\n    Enable high availability for a YARN ResourceManager.\n\n    @param new_rm_host_id: id of the host where the second ResourceManager\n                           will be added.\n    @param zk_service_name: Name of the ZooKeeper service to use for auto-failover.\n           If YARN service depends on a ZooKeeper service then that ZooKeeper\n           service will be used for auto-failover and in that case this parameter\n           can be omitted.\n    @return: Reference to the submitted command.\n    @since: API v6\n    \"\"\"\n    args = dict(\n      newRmHostId = new_rm_host_id,\n      zkServiceName = zk_service_name\n    )\n    return self._cmd('enableRmHa', data=args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisable high availability for a YARN ResourceManager active - standby pair.", "response": "def disable_rm_ha(self, active_name):\n    \"\"\"\n    Disable high availability for a YARN ResourceManager active-standby pair.\n\n    @param active_name: name of the ResourceManager that will be active after\n                        the disable operation. The other ResourceManager\n                        will be removed.\n    @return: Reference to the submitted command.\n    @since: API v6\n    \"\"\"\n    args = dict(\n      activeName = active_name\n    )\n    return self._cmd('disableRmHa', data=args)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_oozie_ha(self, new_oozie_server_host_ids, new_oozie_server_role_names=None,\n    zk_service_name=None, load_balancer_host_port=None):\n    \"\"\"\n    Enable high availability for Oozie.\n\n    @param new_oozie_server_host_ids: List of IDs of the hosts on which new Oozie Servers\n                                      will be added.\n    @param new_oozie_server_role_names: List of names of the new Oozie Servers. This is an\n                                        optional argument, but if provided, it should\n                                        match the length of host IDs provided.\n    @param zk_service_name: Name of the ZooKeeper service that will be used for Oozie HA.\n                            This is an optional parameter if the Oozie to ZooKeeper\n                            dependency is already set.\n    @param load_balancer_host_port: Address and port of the load balancer used for Oozie HA.\n                                    This is an optional parameter if this config is already set.\n    @return: Reference to the submitted command.\n    @since: API v6\n    \"\"\"\n    args = dict(\n      newOozieServerHostIds = new_oozie_server_host_ids,\n      newOozieServerRoleNames = new_oozie_server_role_names,\n      zkServiceName = zk_service_name,\n      loadBalancerHostPort = load_balancer_host_port\n    )\n    return self._cmd('oozieEnableHa', data=args, api_version=6)", "response": "Enable high availability for Oozie."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disable_oozie_ha(self, active_name):\n    args = dict(\n      activeName = active_name\n    )\n    return self._cmd('oozieDisableHa', data=args, api_version=6)", "response": "Disable high availability for the specified Oozie Server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitiate a failover of an HDFS NameNode HA pair.", "response": "def failover_hdfs(self, active_name, standby_name, force=False):\n    \"\"\"\n    Initiate a failover of an HDFS NameNode HA pair.\n\n    This will make the given stand-by NameNode active, and vice-versa.\n\n    @param active_name: name of currently active NameNode.\n    @param standby_name: name of NameNode currently in stand-by.\n    @param force: whether to force failover.\n    @return: Reference to the submitted command.\n    \"\"\"\n    params = { \"force\" : \"true\" and force or \"false\" }\n    args = { ApiList.LIST_KEY : [ active_name, standby_name ] }\n    return self._cmd('hdfsFailover', data=[ active_name, standby_name ],\n        params = { \"force\" : \"true\" and force or \"false\" })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef roll_edits_hdfs(self, nameservice=None):\n    args = dict()\n    if nameservice:\n      args['nameservice'] = nameservice\n\n    return self._cmd('hdfsRollEdits', data=args)", "response": "Roll the edits of an HDFS NameNode or Nameservice."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsynchronizing the Hue server s database.", "response": "def sync_hue_db(self, *servers):\n    \"\"\"\n    Synchronize the Hue server's database.\n\n    @param servers: Name of Hue Server roles to synchronize. Not required starting with API v10.\n    @return: List of submitted commands.\n    \"\"\"\n\n    actual_version = self._get_resource_root().version\n    if actual_version < 10:\n      return self._role_cmd('hueSyncDb', servers)\n\n    return self._cmd('hueSyncDb', api_version=10)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nputs the service in maintenance mode.", "response": "def enter_maintenance_mode(self):\n    \"\"\"\n    Put the service in maintenance mode.\n\n    @return: Reference to the completed command.\n    @since: API v2\n    \"\"\"\n    cmd = self._cmd('enterMaintenanceMode')\n    if cmd.success:\n      self._update(_get_service(self._get_resource_root(), self._path()))\n    return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrolling restart the roles of a service. The sequence is: 1. Restart all the non-slave roles 2. If slaves are present restart them in batches of size specified 3. Perform any post-command needed after rolling restart @param slave_batch_size: Number of slave roles to restart at a time Must be greater than 0. Default is 1. For HDFS, this number should be less than the replication factor (default 3) to ensure data availability during rolling restart. @param slave_fail_count_threshold: The threshold for number of slave batches that are allowed to fail to restart before the entire command is considered failed. Must be >= 0. Default is 0. @param sleep_seconds: Number of seconds to sleep between restarts of slave role batches. Must be >=0. Default is 0. @param stale_configs_only: Restart roles with stale configs only. Default is false. @param unupgraded_only: Restart roles that haven't been upgraded yet. Default is false. @param restart_role_types: Role types to restart. If not specified, all startable roles are restarted. @param restart_role_names: List of specific roles to restart. If none are specified, then all roles of specified role types are restarted. @return: Reference to the submitted command. @since: API v3", "response": "def rolling_restart(self, slave_batch_size=None,\n                      slave_fail_count_threshold=None,\n                      sleep_seconds=None,\n                      stale_configs_only=None,\n                      unupgraded_only=None,\n                      restart_role_types=None,\n                      restart_role_names=None):\n    \"\"\"\n    Rolling restart the roles of a service. The sequence is:\n      1. Restart all the non-slave roles\n      2. If slaves are present restart them in batches of size specified\n      3. Perform any post-command needed after rolling restart\n\n    @param slave_batch_size: Number of slave roles to restart at a time\n           Must be greater than 0. Default is 1.\n           For HDFS, this number should be less than the replication factor (default 3)\n           to ensure data availability during rolling restart.\n    @param slave_fail_count_threshold: The threshold for number of slave batches that\n           are allowed to fail to restart before the entire command is considered failed.\n           Must be >= 0. Default is 0.\n    @param sleep_seconds: Number of seconds to sleep between restarts of slave role batches.\n            Must be >=0. Default is 0.\n    @param stale_configs_only: Restart roles with stale configs only. Default is false.\n    @param unupgraded_only: Restart roles that haven't been upgraded yet. Default is false.\n    @param restart_role_types: Role types to restart. If not specified, all startable roles are restarted.\n    @param restart_role_names: List of specific roles to restart.\n            If none are specified, then all roles of specified role types are restarted.\n    @return: Reference to the submitted command.\n    @since: API v3\n    \"\"\"\n    args = dict()\n    if slave_batch_size:\n      args['slaveBatchSize'] = slave_batch_size\n    if slave_fail_count_threshold:\n      args['slaveFailCountThreshold'] = slave_fail_count_threshold\n    if sleep_seconds:\n      args['sleepSeconds'] = sleep_seconds\n    if stale_configs_only:\n      args['staleConfigsOnly'] = stale_configs_only\n    if unupgraded_only:\n      args['unUpgradedOnly'] = unupgraded_only\n    if restart_role_types:\n      args['restartRoleTypes'] = restart_role_types\n    if restart_role_names:\n      args['restartRoleNames'] = restart_role_names\n\n    return self._cmd('rollingRestart', data=args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new replication schedule for this service.", "response": "def create_replication_schedule(self,\n      start_time, end_time, interval_unit, interval, paused, arguments,\n      alert_on_start=False, alert_on_success=False, alert_on_fail=False,\n      alert_on_abort=False):\n    \"\"\"\n    Create a new replication schedule for this service.\n\n    The replication argument type varies per service type. The following types\n    are recognized:\n      - HDFS: ApiHdfsReplicationArguments\n      - Hive: ApiHiveReplicationArguments\n\n    @type  start_time: datetime.datetime\n    @param start_time: The time at which the schedule becomes active and first executes.\n    @type  end_time: datetime.datetime\n    @param end_time: The time at which the schedule will expire.\n    @type  interval_unit: str\n    @param interval_unit: The unit of time the `interval` represents. Ex. MINUTE, HOUR,\n                          DAY. See the server documentation for a full list of values.\n    @type  interval: int\n    @param interval: The number of time units to wait until triggering the next replication.\n    @type  paused: bool\n    @param paused: Should the schedule be paused? Useful for on-demand replication.\n    @param arguments: service type-specific arguments for the replication job.\n    @param alert_on_start: whether to generate alerts when the job is started.\n    @param alert_on_success: whether to generate alerts when the job succeeds.\n    @param alert_on_fail: whether to generate alerts when the job fails.\n    @param alert_on_abort: whether to generate alerts when the job is aborted.\n    @return: The newly created schedule.\n    @since: API v3\n    \"\"\"\n    schedule = ApiReplicationSchedule(self._get_resource_root(),\n      startTime=start_time, endTime=end_time, intervalUnit=interval_unit, interval=interval,\n      paused=paused, alertOnStart=alert_on_start, alertOnSuccess=alert_on_success,\n      alertOnFail=alert_on_fail, alertOnAbort=alert_on_abort)\n\n    if self.type == 'HDFS':\n      if isinstance(arguments, ApiHdfsCloudReplicationArguments):\n        schedule.hdfsCloudArguments = arguments\n      elif isinstance(arguments, ApiHdfsReplicationArguments):\n        schedule.hdfsArguments = arguments\n      else:\n        raise TypeError, 'Unexpected type for HDFS replication argument.'\n    elif self.type == 'HIVE':\n      if not isinstance(arguments, ApiHiveReplicationArguments):\n        raise TypeError, 'Unexpected type for Hive replication argument.'\n      schedule.hiveArguments = arguments\n    else:\n      raise TypeError, 'Replication is not supported for service type ' + self.type\n\n    return self._post(\"replications\", ApiReplicationSchedule, True, [schedule],\n        api_version=3)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a replication schedule.", "response": "def update_replication_schedule(self, schedule_id, schedule):\n    \"\"\"\n    Update a replication schedule.\n\n    @param schedule_id: The id of the schedule to update.\n    @param schedule: The modified schedule.\n    @return: The updated replication schedule.\n    @since: API v3\n    \"\"\"\n    return self._put(\"replications/%s\" % schedule_id, ApiReplicationSchedule,\n        data=schedule, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_replication_command_history(self, schedule_id, limit=20, offset=0,\n                                      view=None):\n    \"\"\"\n    Retrieve a list of commands for a replication schedule.\n\n    @param schedule_id: The id of the replication schedule.\n    @param limit: Maximum number of commands to retrieve.\n    @param offset: Index of first command to retrieve.\n    @param view: View to materialize. Valid values are 'full', 'summary', 'export', 'export_redacted'.\n    @return: List of commands executed for a replication schedule.\n    @since: API v4\n    \"\"\"\n    params = {\n      'limit':  limit,\n      'offset': offset,\n    }\n    if view:\n      params['view'] = view\n\n    return self._get(\"replications/%s/history\" % schedule_id,\n                     ApiReplicationCommand, True, params=params, api_version=4)", "response": "Retrieve a list of commands executed for a replication schedule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrigger replication immediately. Start and end dates on the schedule will be ignored. @param schedule_id: The id of the schedule to trigger. @param dry_run: Whether to execute a dry run. @return: The command corresponding to the replication job. @since: API v3", "response": "def trigger_replication_schedule(self, schedule_id, dry_run=False):\n    \"\"\"\n    Trigger replication immediately. Start and end dates on the schedule will be\n    ignored.\n\n    @param schedule_id: The id of the schedule to trigger.\n    @param dry_run: Whether to execute a dry run.\n    @return: The command corresponding to the replication job.\n    @since: API v3\n    \"\"\"\n    return self._post(\"replications/%s/run\" % schedule_id, ApiCommand,\n        params=dict(dryRun=dry_run),\n        api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_snapshot_policies(self, view=None):\n    return self._get(\"snapshots/policies\", ApiSnapshotPolicy, True,\n        params=view and dict(view=view) or None, api_version=6)", "response": "Retrieve a list of snapshot policies."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a single snapshot policy.", "response": "def get_snapshot_policy(self, name, view=None):\n    \"\"\"\n    Retrieve a single snapshot policy.\n\n    @param name: The name of the snapshot policy to retrieve.\n    @param view: View to materialize. Valid values are 'full', 'summary', 'export', 'export_redacted'.\n    @return: The requested snapshot policy.\n    @since: API v6\n    \"\"\"\n    return self._get(\"snapshots/policies/%s\" % name, ApiSnapshotPolicy,\n        params=view and dict(view=view) or None, api_version=6)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_snapshot_policy(self, name, policy):\n    return self._put(\"snapshots/policies/%s\" % name, ApiSnapshotPolicy, data=policy,\n        api_version=6)", "response": "Update a snapshot policy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a list of commands triggered by a snapshot policy.", "response": "def get_snapshot_command_history(self, name, limit=20, offset=0, view=None):\n    \"\"\"\n    Retrieve a list of commands triggered by a snapshot policy.\n\n    @param name: The name of the snapshot policy.\n    @param limit: Maximum number of commands to retrieve.\n    @param offset: Index of first command to retrieve.\n    @param view: View to materialize. Valid values are 'full', 'summary', 'export', 'export_redacted'.\n    @return: List of commands triggered by a snapshot policy.\n    @since: API v6\n    \"\"\"\n    params = {\n      'limit':  limit,\n      'offset': offset,\n    }\n    if view:\n      params['view'] = view\n\n    return self._get(\"snapshots/policies/%s/history\" % name, ApiSnapshotCommand, True,\n        params=params, api_version=6)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_config(self, config):\n    if self.config is None:\n      self.config = { }\n    self.config.update(config_to_api_list(config))", "response": "Sets the service configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_role_type_info(self, role_type, config):\n    rt_config = config_to_api_list(config)\n    rt_config['roleType'] = role_type\n\n    if self.config is None:\n      self.config = { }\n    if not self.config.has_key(ROLETYPES_CFG_KEY):\n      self.config[ROLETYPES_CFG_KEY] = [ ]\n    self.config[ROLETYPES_CFG_KEY].append(rt_config)", "response": "Add a role type setup info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_role_info(self, role_name, role_type, host_id, config=None):\n    if self.roles is None:\n      self.roles = [ ]\n    api_config_list = config is not None and config_to_api_list(config) or None\n    self.roles.append({\n        'name' : role_name,\n        'type' : role_type,\n        'hostRef' : { 'hostId' : host_id },\n        'config' : api_config_list })", "response": "Add a role info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_host(resource_root, host_id, name, ipaddr, rack_id=None):\n  apihost = ApiHost(resource_root, host_id, name, ipaddr, rack_id)\n  return call(resource_root.post, HOSTS_PATH, ApiHost, True, data=[apihost])[0]", "response": "Create a host object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all hosts @param resource_root: The root Resource object. @return: A list of ApiHost objects.", "response": "def get_all_hosts(resource_root, view=None):\n  \"\"\"\n  Get all hosts\n  @param resource_root: The root Resource object.\n  @return: A list of ApiHost objects.\n  \"\"\"\n  return call(resource_root.get, HOSTS_PATH, ApiHost, True,\n          params=view and dict(view=view) or None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the metrics for a given host.", "response": "def get_metrics(self, from_time=None, to_time=None, metrics=None,\n      ifs=[], storageIds=[], view=None):\n    \"\"\"\n    This endpoint is not supported as of v6. Use the timeseries API\n    instead. To get all metrics for a host with the timeseries API use\n    the query:\n\n    'select * where hostId = $HOST_ID'.\n\n    To get specific metrics for a host use a comma-separated list of\n    the metric names as follows:\n\n    'select $METRIC_NAME1, $METRIC_NAME2 where hostId = $HOST_ID'.\n\n    For more information see http://tiny.cloudera.com/tsquery_doc\n    @param from_time: A datetime; start of the period to query (optional).\n    @param to_time: A datetime; end of the period to query (default = now).\n    @param metrics: List of metrics to query (default = all).\n    @param ifs: network interfaces to query. Default all, use None to disable.\n    @param storageIds: storage IDs to query. Default all, use None to disable.\n    @param view: View to materialize ('full' or 'summary')\n    @return: List of metrics and their readings.\n    \"\"\"\n    params = { }\n    if ifs:\n      params['ifs'] = ifs\n    elif ifs is None:\n      params['queryNw'] = 'false'\n    if storageIds:\n      params['storageIds'] = storageIds\n    elif storageIds is None:\n      params['queryStorage'] = 'false'\n    return self._get_resource_root().get_metrics(self._path() + '/metrics',\n        from_time, to_time, metrics, view, params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nput the host in maintenance mode.", "response": "def enter_maintenance_mode(self):\n    \"\"\"\n    Put the host in maintenance mode.\n\n    @return: Reference to the completed command.\n    @since: API v2\n    \"\"\"\n    cmd = self._cmd('enterMaintenanceMode')\n    if cmd.success:\n      self._update(get_host(self._get_resource_root(), self.hostId))\n    return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmigrating roles from this host to a different host. Currently, this command applies only to HDFS NameNode, JournalNode, and Failover Controller roles. In order to migrate these roles: - HDFS High Availability must be enabled, using quorum-based storage. - HDFS must not be configured to use a federated nameservice. I{B{Migrating a NameNode role requires cluster downtime.}} HDFS, along with all of its dependent services, will be stopped at the beginning of the migration process, and restarted at its conclusion. If the active NameNode is selected for migration, a manual failover will be performed before the role is migrated. The role will remain in standby mode after the migration is complete. When migrating a NameNode role, the co-located Failover Controller role must be migrated as well. The Failover Controller role name must be included in the list of role names to migrate specified in the arguments to this command (it will not be included implicitly). This command does not allow a Failover Controller role to be moved by itself, although it is possible to move a JournalNode independently. @param role_names_to_migrate: list of role names to migrate. @param destination_host_id: the id of the host to which the roles should be migrated. @param clear_stale_role_data: true to delete existing stale role data, if any. For example, when migrating a NameNode, if the destination host has stale data in the NameNode data directories (possibly because a NameNode role was previously located there), this stale data will be deleted before migrating the role. @return: Reference to the submitted command. @since: API v10", "response": "def migrate_roles(self, role_names_to_migrate, destination_host_id,\n      clear_stale_role_data):\n    \"\"\"\n    Migrate roles from this host to a different host.\n\n    Currently, this command applies only to HDFS NameNode, JournalNode,\n    and Failover Controller roles. In order to migrate these roles:\n\n      - HDFS High Availability must be enabled, using quorum-based storage.\n      - HDFS must not be configured to use a federated nameservice.\n\n    I{B{Migrating a NameNode role requires cluster downtime.}} HDFS, along\n    with all of its dependent services, will be stopped at the beginning\n    of the migration process, and restarted at its conclusion.\n\n    If the active NameNode is selected for migration, a manual failover\n    will be performed before the role is migrated. The role will remain in\n    standby mode after the migration is complete.\n\n    When migrating a NameNode role, the co-located Failover Controller\n    role must be migrated as well. The Failover Controller role name must\n    be included in the list of role names to migrate specified in the\n    arguments to this command (it will not be included implicitly). This\n    command does not allow a Failover Controller role to be moved by itself,\n    although it is possible to move a JournalNode independently.\n\n    @param role_names_to_migrate: list of role names to migrate.\n    @param destination_host_id: the id of the host to which the roles\n                                should be migrated.\n    @param clear_stale_role_data: true to delete existing stale role data,\n                                  if any. For example, when migrating a\n                                  NameNode, if the destination host has\n                                  stale data in the NameNode data\n                                  directories (possibly because a NameNode\n                                  role was previously located there), this\n                                  stale data will be deleted before migrating\n                                  the role.\n    @return: Reference to the submitted command.\n    @since: API v10\n    \"\"\"\n    args = dict(\n      roleNamesToMigrate = role_names_to_migrate,\n      destinationHostId = destination_host_id,\n      clearStaleRoleData = clear_stale_role_data)\n    return self._cmd('migrateRoles', data=args, api_version=10)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_args():\n  ''' Parse the script arguments\n  '''\n  parser = optparse.OptionParser()\n\n  parser.add_option(\"-v\", \"--verbose\", action=\"store_true\")\n\n  mode_group = optparse.OptionGroup(parser, \"Program Mode\")\n  mode_group.add_option(\"-u\", \"--update-status\", action=\"store_const\",\n                        dest=\"mode\", const=\"update_status\")\n  mode_group.add_option(\"-g\", \"--generate-cfg\", action=\"store_const\",\n                        dest=\"mode\", const=\"generate_cfg\")\n  parser.add_option_group(mode_group)\n  parser.set_defaults(mode=\"update_status\")\n\n  general_options = optparse.OptionGroup(parser, \"CM API Configuration\")\n  general_options.add_option(\"-H\", \"--host\", metavar=\"HOST\",\n                             help=\"CM API hostname\")\n  general_options.add_option(\"-p\", \"--port\", help=\"CM API port\", default=None)\n  general_options.add_option(\"-P\", \"--passfile\", metavar=\"FILE\",\n                             help=\"File containing CM API username and password, \"\n                                  \"colon-delimited on a single line.  E.g. \"\n                                  \"\\\"user:pass\\\"\")\n  general_options.add_option(\"--use-tls\", action=\"store_true\",\n                             help=\"Use TLS\", default=False)\n  parser.add_option_group(general_options)\n\n  polling_options = optparse.OptionGroup(parser, \"Status Update Options\")\n  polling_options.add_option(\"-c\", \"--cmd-file\", metavar=\"FILE\",\n                             help=\"Path to the file that Nagios checks for \"\n                                  \"external command requests.\")\n  polling_options.add_option(\"-n\", \"--use-send-nsca\", action=\"store_true\",\n                             default=False,\n                             help=\"Use send_nsca to report status via a nsca \"\n                                  \"daemon. When using this option, the \"\n                                  \"send_nsca program must be available and the \"\n                                  \"nsca daemon host and port must be provided.\"\n                                  \"Default is false.\")\n  polling_options.add_option(\"--send-nsca-path\", metavar=\"PATH\",\n                             default=\"/usr/sbin/send_nsca\",\n                             help=\"Path to send_nsca, default is \"\n                                  \"/usr/sbin/send_nsca\")\n  polling_options.add_option(\"--nsca-host\", metavar=\"HOST\",\n                             default=\"localhost\",\n                             help=\"When using send_nsca, the hostname of NSCA \"\n                                  \"server, default is localhost.\")\n  polling_options.add_option(\"--nsca-port\", metavar=\"PORT\", default=None,\n                             help=\"When using send_nsca, the port on which the \"\n                                  \"server is running, default is 5667.\")\n  polling_options.add_option(\"--send-nsca-config\", metavar=\"FILE\", default=None,\n                             help=\"Config file passed to send_nsca -c. Default\"\n                                  \" is to not specify the config parameter.\")\n  parser.add_option_group(polling_options)\n\n\n  generate_options = optparse.OptionGroup(parser, \"Generate Config Options\")\n  generate_options.add_option(\"--cfg-dir\", metavar=\"DIR\", default=getcwd(),\n                              help=\"Directory for generated Nagios cfg files.\")\n  parser.add_option_group(generate_options)\n\n  (options, args) = parser.parse_args()\n\n  ''' Parse the 'passfile' - it must contain the username and password,\n      colon-delimited on a single line. E.g.:\n      $ cat ~/protected/cm_pass\n      admin:admin\n  '''\n  required = [\"host\", \"passfile\"]\n\n  if options.mode == \"update_status\":\n    if not options.use_send_nsca:\n      required.append(\"cmd_file\")\n\n  for required_opt in required:\n    if getattr(options, required_opt) is None:\n      parser.error(\"Please specify the required argument: --%s\" %\n                   (required_opt.replace('_','-'),))\n\n  return (options, args)", "response": "Parses the command line arguments and returns a dictionary of options and values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a mapping between Nagios host information and virtual hosts", "response": "def get_host_map(root):\n  ''' Gets a mapping between CM hostId and Nagios host information\n\n      The key is the CM hostId\n      The value is an object containing the Nagios hostname and host address\n  '''\n  hosts_map = {}\n  for host in root.get_all_hosts():\n    hosts_map[host.hostId] = {\"hostname\": NAGIOS_HOSTNAME_FORMAT % (host.hostname,),\n                              \"address\": host.ipAddress}\n\n  ''' Also define \"virtual hosts\" for the CM clusters- they will be the hosts\n      to which CM services are mapped\n  '''\n  for cluster in root.get_all_clusters():\n    hosts_map[cluster.name] = {\"hostname\": cluster.name,\n                               \"address\": quote(cluster.name)}\n  hosts_map[CM_DUMMY_HOST] = {\"hostname\": CM_DUMMY_HOST,\n                              \"address\": CM_DUMMY_HOST}\n  return hosts_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a string representing the status of the Api Subject.", "response": "def get_status(api_subject):\n  ''' Gets a string representing the status of the Api subject (role or service)\n      based on the health summary and health checks.\n  '''\n  summary = api_subject.healthSummary\n  if summary is None:\n    return None\n  # status string always starts with \"<nagios code>: <summary>\"\n  status = \"%s: %s\" % (NAGIOS_CODE_MESSAGES[CM_STATE_CODES[summary]], summary)\n  if summary != \"GOOD\" and summary != \"DISABLED\":\n    # if the summary is CONCERNING or BAD, then append the health checks\n    for health_check in api_subject.healthChecks:\n      if health_check['summary'] != \"GOOD\" and health_check['summary'] != \"DISABLED\":\n        status = (\"%s, %s=%s\" % (status, health_check['name'], health_check['summary']))\n  return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_services(root, hosts_map, view=None):\n  ''' Gets a list of objects representing the Nagios services.\n\n      Each object contains the Nagios hostname, service name, service display\n      name, and service health summary.\n  '''\n  services_list = []\n  mgmt_service = root.get_cloudera_manager().get_service()\n  services_list.append({\"hostname\": CM_DUMMY_HOST,\n                        \"name\": mgmt_service.name,\n                        \"display_name\": \"CM Managed Service: %s\" % (mgmt_service.name,),\n                        \"status\": get_status(mgmt_service),\n                        \"url\": mgmt_service.serviceUrl,\n                        \"health_summary\": mgmt_service.healthSummary})\n  for cm_role in root.get_cloudera_manager().get_service().get_all_roles(view):\n    services_list.append({\"hostname\": hosts_map[cm_role.hostRef.hostId][\"hostname\"],\n                          \"name\": cm_role.name,\n                          \"display_name\": \"CM Management Service: %s\" % (cm_role.name,),\n                          \"status\": get_status(cm_role),\n                          \"url\": cm_role.roleUrl,\n                          \"health_summary\": cm_role.healthSummary})\n  for cm_host in root.get_all_hosts(view):\n    services_list.append({\"hostname\": hosts_map[cm_host.hostId][\"hostname\"],\n                          \"name\": \"cm-host-%s\" % (cm_host.hostname,),\n                          \"display_name\": \"CM Managed Host: %s\" % (cm_host.hostname,),\n                          \"status\": get_status(cm_host),\n                          \"url\": cm_host.hostUrl,\n                          \"health_summary\": cm_host.healthSummary})\n  for cluster in root.get_all_clusters(view):\n    for service in cluster.get_all_services(view):\n      services_list.append({\"hostname\": cluster.name,\n                            \"name\": service.name,\n                            \"display_name\": \"CM Managed Service: %s\" % (service.name,),\n                            \"status\": get_status(service),\n                            \"url\": service.serviceUrl,\n                            \"health_summary\": service.healthSummary})\n      for role in service.get_all_roles(view):\n        services_list.append({\"hostname\": hosts_map[role.hostRef.hostId][\"hostname\"],\n                              \"name\": role.name,\n                              \"display_name\": \"%s:%s\" % (cluster.name, role.name,),\n                              \"status\": get_status(role),\n                              \"url\": role.roleUrl,\n                              \"health_summary\": role.healthSummary})\n  return services_list", "response": "Gets a list of objects representing the Nagios services."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsubmits the status lines in the status_file to Nagios external cmd file.", "response": "def submit_status_external_cmd(cmd_file, status_file):\n  ''' Submits the status lines in the status_file to Nagios' external cmd file.\n  '''\n  try:\n    with open(cmd_file, 'a') as cmd_file:\n      cmd_file.write(status_file.read())\n  except IOError:\n    exit(\"Fatal error: Unable to write to Nagios external command file '%s'.\\n\"\n         \"Make sure that the file exists and is writable.\" % (cmd_file,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninvokes an API method.", "response": "def invoke(self, method, relpath=None, params=None, data=None, headers=None):\n    \"\"\"\n    Invoke an API method.\n    @return: Raw body or JSON dictionary (if response content type is JSON).\n    \"\"\"\n    path = self._join_uri(relpath)\n    resp = self._client.execute(method,\n                                path,\n                                params=params,\n                                data=data,\n                                headers=headers)\n    try:\n      body = resp.read()\n    except Exception, ex:\n      raise Exception(\"Command '%s %s' failed: %s\" %\n                      (method, path, ex))\n\n    self._client.logger.debug(\n        \"%s Got response: %s%s\" %\n        (method, body[:32], len(body) > 32 and \"...\" or \"\"))\n\n    # Is the response application/json?\n    if len(body) != 0 and \\\n          resp.info().getmaintype() == \"application\" and \\\n          resp.info().getsubtype() == \"json\":\n      try:\n        json_dict = json.loads(body)\n        return json_dict\n      except Exception, ex:\n        self._client.logger.exception('JSON decode error: %s' % (body,))\n        raise ex\n    else:\n      return body"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninvoke the GET method on a resource.", "response": "def get(self, relpath=None, params=None):\n    \"\"\"\n    Invoke the GET method on a resource.\n    @param relpath: Optional. A relative path to this resource's path.\n    @param params: Key-value data.\n\n    @return: A dictionary of the JSON result.\n    \"\"\"\n    for retry in xrange(self.retries + 1):\n      if retry:\n        time.sleep(self.retry_sleep)\n      try:\n        return self.invoke(\"GET\", relpath, params)\n      except (socket.error, urllib2.URLError) as e:\n        if \"timed out\" in str(e).lower():\n          log_message = \"Timeout issuing GET request for %s.\" \\\n              % (self._join_uri(relpath), )\n          if retry < self.retries:\n            log_message += \" Will retry.\"\n          else:\n            log_message += \" No retries left.\"\n          LOG.warn(log_message, exc_info=True)\n        else:\n          raise\n    else:\n      raise e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninvoking the POST method on a resource.", "response": "def post(self, relpath=None, params=None, data=None, contenttype=None):\n    \"\"\"\n    Invoke the POST method on a resource.\n    @param relpath: Optional. A relative path to this resource's path.\n    @param params: Key-value data.\n    @param data: Optional. Body of the request.\n    @param contenttype: Optional.\n\n    @return: A dictionary of the JSON result.\n    \"\"\"\n    return self.invoke(\"POST\", relpath, params, data,\n                       self._make_headers(contenttype))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, relpath=None, params=None, data=None, contenttype=None):\n    return self.invoke(\"PUT\", relpath, params, data,\n                       self._make_headers(contenttype))", "response": "Invoke the PUT method on a resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_host_template(resource_root, name, cluster_name):\n  apitemplate = ApiHostTemplate(resource_root, name, [])\n  return call(resource_root.post,\n      HOST_TEMPLATES_PATH % (cluster_name,),\n      ApiHostTemplate, True, data=[apitemplate], api_version=3)[0]", "response": "Create a host template."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a host template by name in the specified cluster.", "response": "def get_host_template(resource_root, name, cluster_name):\n  \"\"\"\n  Lookup a host template by name in the specified cluster.\n  @param resource_root: The root Resource object.\n  @param name: Host template name.\n  @param cluster_name: Cluster name.\n  @return: An ApiHostTemplate object.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.get,\n      HOST_TEMPLATE_PATH % (cluster_name, name),\n      ApiHostTemplate, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all host templates in a cluster.", "response": "def get_all_host_templates(resource_root, cluster_name=\"default\"):\n  \"\"\"\n  Get all host templates in a cluster.\n  @param cluster_name: Cluster name.\n  @return: ApiList of ApiHostTemplate objects for all host templates in a cluster.\n  @since: API v3\n  \"\"\"\n  return call(resource_root.get,\n      HOST_TEMPLATES_PATH % (cluster_name,),\n      ApiHostTemplate, True, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_host_template(resource_root, name, cluster_name):\n  return call(resource_root.delete,\n      HOST_TEMPLATE_PATH % (cluster_name, name),\n      ApiHostTemplate, api_version=3)", "response": "Delete a host template identified by name in the specified cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_host_template(resource_root, name, cluster_name, api_host_template):\n  return call(resource_root.put,\n      HOST_TEMPLATE_PATH % (cluster_name, name),\n      ApiHostTemplate, data=api_host_template, api_version=3)", "response": "Updates a host template identified by name in the specified cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying a host template identified by name on the specified hosts and optionally start them.", "response": "def apply_host_template(resource_root, name, cluster_name, host_ids, start_roles):\n  \"\"\"\n  Apply a host template identified by name on the specified hosts and\n  optionally start them.\n  @param resource_root: The root Resource object.\n  @param name: Host template name.\n  @param cluster_name: Cluster name.\n  @param host_ids: List of host ids.\n  @param start_roles: Whether to start the created roles or not.\n  @return: An ApiCommand object.\n  @since: API v3\n  \"\"\"\n  host_refs = []\n  for host_id in host_ids:\n    host_refs.append(ApiHostRef(resource_root, host_id))\n\n  params = {\"startRoles\" : start_roles}\n  return call(resource_root.post,\n      APPLY_HOST_TEMPLATE_PATH % (cluster_name, name),\n      ApiCommand, data=host_refs, params=params, api_version=3)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename(self, new_name):\n    update = copy.copy(self)\n    update.name = new_name\n    return self._do_update(update)", "response": "Rename a host template."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the role config groups in a host template.", "response": "def set_role_config_groups(self, role_config_group_refs):\n    \"\"\"\n    Updates the role config groups in a host template.\n    @param role_config_group_refs: List of role config group refs.\n    @return: An ApiHostTemplate object.\n    \"\"\"\n    update = copy.copy(self)\n    update.roleConfigGroupRefs = role_config_group_refs\n    return self._do_update(update)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_host_template(self, host_ids, start_roles):\n    return apply_host_template(self._get_resource_root(), self.name, self.clusterRef.clusterName, host_ids, start_roles)", "response": "Applies a host template identified by name on the specified hosts and optionally start them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_supported_categories():\n  categories = get_supported_categories(api)\n  category_names = [category.name for category in categories]\n  print (\"Supported account categories by name: {0}\".format(\n    COMMA_WITH_SPACE.join(map(str, category_names))))", "response": "Prints a list of supported external account category names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a list of supported external account types for the given category_name.", "response": "def list_supported_types(category_name):\n  \"\"\"\n  Prints a list of supported external account type names for the given\n  category_name. For example, \"AWS_ACCESS_KEY_AUTH\" is a supported external\n  account type name for external account category \"AWS\".\n  \"\"\"\n  types = get_supported_types(api, category_name)\n  type_names = [type.name for type in types]\n  print (\"Supported account types by name for '{0}': [{1}]\".format(\n    category_name, COMMA_WITH_SPACE.join(map(str, type_names))))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a list of available credential names for the given type_name.", "response": "def list_credentials_by_name(type_name):\n  \"\"\"\n  Prints a list of available credential names for the given type_name.\n  \"\"\"\n  accounts = get_all_external_accounts(api, type_name)\n  account_names = [account.name for account in accounts]\n  print (\"List of credential names for '{0}': [{1}]\".format(\n    type_name, COMMA_WITH_SPACE.join(map(str, account_names))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call_s3guard_prune(credential_name):\n  account = get_external_account(api, credential_name)\n  # Invoke the prune command for the account by its name\n  cmd = account.external_account_cmd_by_name('S3GuardPrune')\n  print (\"Issued '{0}' command with id '{1}'\".format(cmd.name, cmd.id))\n  print (\"Waiting for command {0} to finish...\".format(cmd.id))\n  cmd = cmd.wait()\n  print (\"Command succeeded: {0}\".format(cmd.success))", "response": "Runs S3Guard prune command on the external account associated with the given credential_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize_api(args):\n  global api\n  api = ApiResource(server_host=args.hostname, server_port=args.port,\n                    username=args.username, password=args.password,\n                    version=args.api_version, use_tls=args.use_tls)", "response": "Initializes the global API instance using the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the API version.", "response": "def validate_api_compatibility(args):\n  \"\"\"\n  Validates the API version.\n  @param args: arguments provided to the script.\n  \"\"\"\n  if args.api_version and args.api_version < MINIMUM_SUPPORTED_API_VERSION:\n    print(\"ERROR: Given API version: {0}. Minimum supported API version: {1}\"\n          .format(args.api_version, MINIMUM_SUPPORTED_API_VERSION))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_login_credentials(args):\n  if not args.username:\n    args.username = raw_input(\"Enter Username: \")\n  if not args.password:\n    args.password = getpass.getpass(\"Enter Password: \")", "response": "Gets the login credentials from the user if not specified while invoking\n    the script."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the root resource.", "response": "def get_root_resource(server_host, server_port=None,\n                      username=\"admin\", password=\"admin\",\n                      use_tls=False, version=API_CURRENT_VERSION):\n  \"\"\"\n  See ApiResource.\n  \"\"\"\n  return ApiResource(server_host, server_port, username, password, use_tls,\n      version)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_cluster(self, name, version=None, fullVersion=None):\n    return clusters.create_cluster(self, name, version, fullVersion)", "response": "Create a new cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a host. @param host_id: The host id. @param name: Host name @param ipaddr: IP address @param rack_id: Rack id. Default None. @return: An ApiHost object", "response": "def create_host(self, host_id, name, ipaddr, rack_id = None):\n    \"\"\"\n    Create a host.\n\n    @param host_id:  The host id.\n    @param name:     Host name\n    @param ipaddr:   IP address\n    @param rack_id:  Rack id. Default None.\n    @return: An ApiHost object\n    \"\"\"\n    return hosts.create_host(self, host_id, name, ipaddr, rack_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_user(self, username, password, roles):\n    return users.create_user(self, username, password, roles)", "response": "Create a user.\n\n    @param username: Username\n    @param password: Password\n    @param roles: List of roles for the user. This should be [] for a\n                  regular user, or ['ROLE_ADMIN'] for an admin.\n    @return: An ApiUser object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_metrics(self, path, from_time, to_time, metrics, view, params=None):\n    if not params:\n      params = { }\n    if from_time:\n      params['from'] = from_time.isoformat()\n    if to_time:\n      params['to'] = to_time.isoformat()\n    if metrics:\n      params['metrics'] = metrics\n    if view:\n      params['view'] = view\n    resp = self.get(path, params=params)\n    return types.ApiList.from_json_dict(resp, self, types.ApiMetric)", "response": "Generic function for querying metrics."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_timeseries(self, query, from_time=None, to_time=None, by_post=False):\n    return timeseries.query_timeseries(self, query, from_time, to_time, by_post=by_post)", "response": "Query time series.\n    @param query: Query string.\n    @param from_time: Start of the period to query (optional).\n    @param to_time: End of the period to query (default = now).\n    @return: A list of ApiTimeSeriesResponse."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an external account object", "response": "def create_external_account(self, name, display_name, type_name,\n                              account_configs=None):\n    \"\"\"\n    Create an external account\n    @param name: Immutable external account name\n    @param display_name: Display name\n    @param type_name: Account type\n    @param account_configs: Optional account configuration\n    @return: An ApiExternalAccount object\n    \"\"\"\n    return external_accounts.create_external_account(\n      self, name, display_name, type_name, account_configs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhaving the server echo our message back?", "response": "def echo(root_resource, message):\n  \"\"\"Have the server echo our message back.\"\"\"\n  params = dict(message=message)\n  return root_resource.get(ECHO_PATH, params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef echo_error(root_resource, message):\n  params = dict(message=message)\n  return root_resource.get(ECHO_ERROR_PATH, params)", "response": "Generate an error message."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all services on the cluster", "response": "def do_status(self, service):\n        \"\"\"\n        List all services on the cluster\n        Usage:\n            > status\n        \"\"\"\n        if service:\n            self.do_show(\"services\", single=service)\n        else:\n            self.do_show(\"services\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows the general system information of a specific cluster and services.", "response": "def do_show(self, option, single=None):\n        \"\"\"\n        General System Information\n        Usage:\n            > show clusters     list of clusters this CM manages\n            > show hosts        list of all hosts CM manages\n            > show services     list of all services on this cluster\n                                including their health.\n        \"\"\"\n        headers = []\n        rows = []\n        align = None\n        # show clusters\n        if option == \"clusters\":\n            \"Display list of clusters on system\"\n            headers = [\"CLUSTER NAME\"]\n            clusters = api.get_all_clusters()\n            for cluster in clusters:\n                rows.append([cluster.name])\n\n        # show hosts\n        if option == \"hosts\":\n            \"Display a list of hosts avaiable on the system\"\n            headers = [\"HOSTNAME\", \"IP ADDRESS\", \"RACK\"]\n            align = [\"HOSTNAME\", \"IP ADDRESS\", \"RACK\"]\n            for host in api.get_all_hosts():\n                rows.append([host.hostname, host.ipAddress, host.rackId])\n\n        # show services\n        if option == \"services\":\n            \"Show list of services on the cluster\"\n            headers = [\"NAME\", \"SERVICE\", \"STATUS\", \"HEALTH\", \"CONFIG\"]\n            align = [\"NAME\", \"SERVICE\"]\n\n            # Check if the user has selected a cluster\n            if not self.has_cluster():\n                print(\"Error: Please select a cluster first\")\n                return None\n\n            if not single:\n                for s in api.get_cluster(self.cluster).get_all_services():\n                    if s.configStale:\n                        config = \"STALE\"\n                    else:\n                        config = \"UP TO DATE\"\n                    rows.append([s.name, s.type, s.serviceState, s.healthSummary, config])\n            else:\n                s = api.get_cluster(self.cluster).get_service(single)\n                if s.configStale:\n                    config = \"STALE\"\n                else:\n                    config = \"UP TO DATE\"\n                rows.append([s.name, s.type, s.serviceState, s.healthSummary, config])\n\n        self.generate_output(headers, rows, align=align)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef service_action(self, service, action):\n        \"Perform given action on service for the selected cluster\"\n        try:\n            service = api.get_cluster(self.cluster).get_service(service)\n        except ApiException:\n            print(\"Service not found\")\n            return None\n\n        if action == \"start\":\n            service.start()\n        if action == \"restart\":\n            service.restart()\n        if action == \"stop\":\n            service.stop()\n\n        return True", "response": "Perform given action on service for the selected cluster"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_start_service(self, service):\n        if not self.has_cluster():\n            return None\n\n        if self.service_action(service=service, action=\"start\"):\n            print(\"%s is being started\" % (service))\n        else:\n            print(\"Error starting service\")\n            return None", "response": "Start a service\n        Usage:\n            > start_service <service>"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrestart a service Usage: > restart_service <service>", "response": "def do_restart_service(self, service):\n        \"\"\"\n        Restart a service\n        Usage:\n            > restart_service <service>\n        \"\"\"\n        if not self.has_cluster():\n            return None\n\n        if self.service_action(service=service, action=\"restart\"):\n            print(\"%s is being restarted\" % (service))\n        else:\n            print(\"Error restarting service\")\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping a service Usage: > stop_service <service>", "response": "def do_stop_service(self, service):\n        \"\"\"\n        Stop a service\n        Usage:\n            > stop_service <service>\n        \"\"\"\n        if not self.has_cluster():\n            return None\n\n        if self.service_action(service=service, action=\"stop\"):\n            print(\"%s is being stopped\" % (service))\n        else:\n            print(\"Error stopping service\")\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_roles(self, service):\n        if not self.has_cluster():\n            return None\n\n        if not service:\n            return None\n\n        if service == \"all\":\n            if not self.CACHED_SERVICES:\n                self.services_autocomplete('', service, 0, 0)\n\n            for s in self.CACHED_SERVICES:\n                print(\"= \" + s.upper() + \" =\")\n                self.do_roles(s)\n            return None\n        try:\n            service = api.get_cluster(self.cluster).get_service(service)\n            headers = [\"ROLE TYPE\", \"HOST\", \"ROLE NAME\", \"STATE\", \"HEALTH\", \"CONFIG\"]\n            align = [\"ROLE TYPE\", \"ROLE NAME\", \"HOST\"]\n            rows = []\n            for roletype in service.get_role_types():\n                for role in service.get_roles_by_type(roletype):\n                    if role.configStale:\n                        config = \"STALE\"\n                    else:\n                        config = \"UP TO DATE\"\n                    rows.append([role.type, role.hostRef.hostId, role.name, role.roleState, role.healthSummary, config])\n            self.generate_output(headers, rows, align=align)\n        except ApiException:\n            print(\"Service not found\")", "response": "Display role information for a service"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning full list of roles", "response": "def roles_autocomplete(self, text, line, start_index, end_index):\n        \"Return full list of roles\"\n        if '-' not in line:\n            # Append a dash to each service, makes for faster autocompletion of\n            # roles\n            return [s + '-' for s in self.services_autocomplete(text, line, start_index, end_index)]\n        else:\n            key, role = line.split()[1].split('-', 1)\n            if key not in self.CACHED_ROLES:\n                service = api.get_cluster(self.cluster).get_service(key)\n                roles = []\n                for t in service.get_role_types():\n                    for r in service.get_roles_by_type(t):\n                        roles.append(r.name)\n\n                self.CACHED_ROLES[key] = roles\n\n            if not role:\n                return self.CACHED_ROLES[key]\n            else:\n                return [r for r in self.CACHED_ROLES[key] if r.startswith(line.split()[1])]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_start_role(self, role):\n        if not role:\n            return None\n\n        if not self.has_cluster():\n            return None\n\n        if '-' not in role:\n            print(\"Please enter a valid role name\")\n            return None\n\n        try:\n            service = api.get_cluster(self.cluster).get_service(role.split('-')[0])\n            service.start_roles(role)\n            print(\"Starting Role\")\n        except ApiException:\n            print(\"Error: Role or Service Not Found\")", "response": "Start a role\n        Usage:\n            > start_role <role>     Restarts this role"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrestarting a role Usage: > restart_role <role> Restarts this role", "response": "def do_restart_role(self, role):\n        \"\"\"\n        Restart a role\n        Usage:\n            > restart_role <role>   Restarts this role\n        \"\"\"\n        if not role:\n            return None\n\n        if not self.has_cluster():\n            return None\n\n        if '-' not in role:\n            print(\"Please enter a valid role name\")\n            return None\n\n        try:\n            service = api.get_cluster(self.cluster).get_service(role.split('-')[0])\n            service.restart_roles(role)\n            print(\"Restarting Role\")\n        except ApiException:\n            print(\"Error: Role or Service Not Found\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_stop_role(self, role):\n        if not role:\n            return None\n\n        if not self.has_cluster():\n            return None\n\n        if '-' not in role:\n            print(\"Please enter a valid role name\")\n            return None\n\n        try:\n            service = api.get_cluster(self.cluster).get_service(role.split('-')[0])\n            service.stop_roles(role)\n            print(\"Stopping Role\")\n        except ApiException:\n            print(\"Error: Role or Service Not Found\")", "response": "Stop a role\n        Usage:\n            > stop_role <role>  Stops this role"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_start_cluster(self, cluster):\n        try:\n            cluster = api.get_cluster(cluster)\n            cluster.start()\n            print(\"Starting Cluster\")\n        except ApiException:\n            print(\"Cluster not found\")\n            return None", "response": "Start the cluster\n        Usage:\n            > start_cluster <cluster>"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_version(self, cluster=None):\n        if not cluster:\n            if not self.has_cluster():\n                return None\n            else:\n                cluster = api.get_cluster(self.cluster)\n        else:\n            try:\n                cluster = api.get_cluster(cluster)\n            except ApiException:\n                print(\"Error: Cluster not found\")\n                return None\n\n        print(\"Version: %s\" % (cluster.version))", "response": "Get the version of the CDH"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_events(resource_root, query_str=None):\n  params = None\n  if query_str:\n    params = dict(query=query_str)\n  return call(resource_root.get, EVENTS_PATH, ApiEventQueryResult,\n      params=params)", "response": "Search for events.\n  @param query_str: Query string.\n  @return: A list of ApiEvent."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an injector with a callable config or raise an exception when already configured.", "response": "def configure(config=None, bind_in_runtime=True):\n    \"\"\"Create an injector with a callable config or raise an exception when already configured.\"\"\"\n    global _INJECTOR\n\n    with _INJECTOR_LOCK:\n        if _INJECTOR:\n            raise InjectorException('Injector is already configured')\n\n        _INJECTOR = Injector(config, bind_in_runtime=bind_in_runtime)\n        logger.debug('Created and configured an injector, config=%s', config)\n        return _INJECTOR"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure_once(config=None, bind_in_runtime=True):\n    with _INJECTOR_LOCK:\n        if _INJECTOR:\n            return _INJECTOR\n\n        return configure(config, bind_in_runtime=bind_in_runtime)", "response": "Create an injector with a callable config if not present otherwise do nothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclears an existing injector and create another one with a callable config.", "response": "def clear_and_configure(config=None, bind_in_runtime=True):\n    \"\"\"Clear an existing injector and create another one with a callable config.\"\"\"\n    with _INJECTOR_LOCK:\n        clear()\n        return configure(config, bind_in_runtime=bind_in_runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef autoparams(*selected_args):\n    def autoparams_decorator(func):\n        if sys.version_info[:2] < (3, 5):\n            raise InjectorException('autoparams are supported from Python 3.5 onwards')\n\n        full_args_spec = inspect.getfullargspec(func)\n        annotations_items = full_args_spec.annotations.items()\n        all_arg_names = frozenset(full_args_spec.args + full_args_spec.kwonlyargs)\n        args_to_check = frozenset(selected_args) or all_arg_names\n        args_annotated_types = {\n            arg_name: annotated_type for arg_name, annotated_type in annotations_items\n            if arg_name in args_to_check\n        }\n        return _ParametersInjection(**args_annotated_types)(func)\n\n    return autoparams_decorator", "response": "Returns a decorator that will injects args into a function using type annotations Python < 3. 5 only."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind(self, cls, instance):\n        self._check_class(cls)\n        self._bindings[cls] = lambda: instance\n        logger.debug('Bound %s to an instance %s', cls, instance)\n        return self", "response": "Bind a class to an instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbinding a class to a callable singleton constructor.", "response": "def bind_to_constructor(self, cls, constructor):\n        \"\"\"Bind a class to a callable singleton constructor.\"\"\"\n        self._check_class(cls)\n        if constructor is None:\n            raise InjectorException('Constructor cannot be None, key=%s' % cls)\n\n        self._bindings[cls] = _ConstructorBinding(constructor)\n        logger.debug('Bound %s to a constructor %s', cls, constructor)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbind a class to a callable instance provider executed for each injection.", "response": "def bind_to_provider(self, cls, provider):\n        \"\"\"Bind a class to a callable instance provider executed for each injection.\"\"\"\n        self._check_class(cls)\n        if provider is None:\n            raise InjectorException('Provider cannot be None, key=%s' % cls)\n\n        self._bindings[cls] = provider\n        logger.debug('Bound %s to a provider %s', cls, provider)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_instance(self, cls):\n        binding = self._bindings.get(cls)\n        if binding:\n            return binding()\n\n        # Try to create a runtime binding.\n        with _BINDING_LOCK:\n            binding = self._bindings.get(cls)\n            if binding:\n                return binding()\n\n            if not self._bind_in_runtime:\n                raise InjectorException('No binding was found for key=%s' % cls)\n\n            if not callable(cls):\n                raise InjectorException(\n                    'Cannot create a runtime binding, the key is not callable, key=%s' % cls)\n\n            instance = cls()\n            self._bindings[cls] = lambda: instance\n\n            logger.debug('Created a runtime binding for key=%s, instance=%s', cls, instance)\n            return instance", "response": "Return an instance for a class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_csv(\n    filename: Union[PathLike, Iterator[str]],\n    delimiter: Optional[str]=',',\n    first_column_names: Optional[bool]=None,\n    dtype: str='float32',\n) -> AnnData:\n    \"\"\"Read ``.csv`` file.\n\n    Same as :func:`~anndata.read_text` but with default delimiter ``','``.\n\n    Parameters\n    ----------\n    filename\n        Data file.\n    delimiter\n        Delimiter that separates data within text file. If ``None``, will split at\n        arbitrary number of white spaces, which is different from enforcing\n        splitting at single white space ``' '``.\n    first_column_names\n        Assume the first column stores row names.\n    dtype\n        Numpy data type.\n    \"\"\"\n    return read_text(filename, delimiter, first_column_names, dtype)", "response": "Read ``.csv`` file.\n\n    Same as :func:`~anndata.read_text` but with default delimiter ``','``.\n\n    Parameters\n    ----------\n    filename\n        Data file.\n    delimiter\n        Delimiter that separates data within text file. If ``None``, will split at\n        arbitrary number of white spaces, which is different from enforcing\n        splitting at single white space ``' '``.\n    first_column_names\n        Assume the first column stores row names.\n    dtype\n        Numpy data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_excel(\n    filename: PathLike,\n    sheet: Union[str, int],\n    dtype: str='float32',\n) -> AnnData:\n    \"\"\"Read ``.xlsx`` (Excel) file.\n\n    Assumes that the first columns stores the row names and the first row the\n    column names.\n\n    Parameters\n    ----------\n    filename\n        File name to read from.\n    sheet\n        Name of sheet in Excel file.\n    \"\"\"\n    # rely on pandas for reading an excel file\n    from pandas import read_excel\n    df = read_excel(fspath(filename), sheet)\n    X = df.values[:, 1:]\n    row = {'row_names': df.iloc[:, 0].values.astype(str)}\n    col = {'col_names': np.array(df.columns[1:], dtype=str)}\n    return AnnData(X, row, col, dtype=dtype)", "response": "Read an Excel file and return a new AnnData object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a gzipped condensed count matrix from umi_tools.", "response": "def read_umi_tools(filename: PathLike, dtype: str='float32') -> AnnData:\n    \"\"\"Read a gzipped condensed count matrix from umi_tools.\n\n    Parameters\n    ----------\n    filename\n        File name to read from.\n    \"\"\"\n    # import pandas for conversion of a dict of dicts into a matrix\n    # import gzip to read a gzipped file :-)\n    import gzip\n    from pandas import DataFrame\n\n    dod = {}  # this will contain basically everything\n    fh = gzip.open(fspath(filename))\n    header = fh.readline()  # read the first line\n\n    for line in fh:\n        t = line.decode('ascii').split('\\t')  # gzip read bytes, hence the decoding\n        try:\n            dod[t[1]].update({t[0]:int(t[2])})\n        except KeyError:\n            dod[t[1]] = {t[0]:int(t[2])}\n\n    df = DataFrame.from_dict(dod, orient='index')  # build the matrix\n    df.fillna(value=0., inplace=True)  # many NaN, replace with zeros\n    return AnnData(np.array(df), {'obs_names': df.index}, {'var_names': df.columns}, dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads an HDF5 file and return a new object.", "response": "def read_hdf(filename: PathLike, key: str) -> AnnData:\n    \"\"\"Read ``.h5`` (hdf5) file.\n\n    Note: Also looks for fields ``row_names`` and ``col_names``.\n\n    Parameters\n    ----------\n    filename\n        Filename of data file.\n    key\n        Name of dataset in the file.\n    \"\"\"\n    with h5py.File(filename, 'r') as f:\n        # the following is necessary in Python 3, because only\n        # a view and not a list is returned\n        keys = [k for k in f.keys()]\n        if key == '':\n            raise ValueError((\n                'The file {} stores the following sheets:\\n{}\\n'\n                'Call read/read_hdf5 with one of them.'\n            ).format(filename, keys))\n        # read array\n        X = f[key][()]\n        # try to find row and column names\n        rows_cols = [{}, {}]\n        for iname, name in enumerate(['row_names', 'col_names']):\n            if name in keys:\n                rows_cols[iname][name] = f[name][()]\n    adata = AnnData(X, rows_cols[0], rows_cols[1], dtype=X.dtype.name)\n    return adata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_loom(filename: PathLike, sparse: bool = True, cleanup: bool = False, X_name: str = 'spliced',\n              obs_names: str = 'CellID', var_names: str = 'Gene', dtype: str='float32', **kwargs) -> AnnData:\n    \"\"\"Read ``.loom``-formatted hdf5 file.\n\n    This reads the whole file into memory.\n\n    Beware that you have to explicitly state when you want to read the file as\n    sparse data.\n\n    Parameters\n    ----------\n    filename\n        The filename.\n    sparse\n        Whether to read the data matrix as sparse.\n    cleanup:\n        Whether to remove all obs/var keys that do not store more than one unique value.\n    X_name:\n        Loompy key where the data matrix is stored.\n    obs_names:\n        Loompy key where the observation/cell names are stored.\n    var_names:\n        Loompy key where the variable/gene names are stored.\n    **kwargs:\n        Arguments to loompy.connect\n    \"\"\"\n    filename = fspath(filename)  # allow passing pathlib.Path objects\n    from loompy import connect\n    with connect(filename, 'r', **kwargs) as lc:\n\n        if X_name not in lc.layers.keys(): X_name = ''\n        X = lc.layers[X_name].sparse().T.tocsr() if sparse else lc.layers[X_name][()].T\n\n        layers = OrderedDict()\n        if X_name != '': layers['matrix'] = lc.layers[''].sparse().T.tocsr() if sparse else lc.layers[''][()].T\n        for key in lc.layers.keys():\n            if key != '': layers[key] = lc.layers[key].sparse().T.tocsr() if sparse else lc.layers[key][()].T\n\n        obs = dict(lc.col_attrs)\n        if obs_names in obs.keys(): obs['obs_names'] = obs.pop(obs_names)\n        obsm_attrs = [k for k, v in obs.items() if v.ndim > 1 and v.shape[1] > 1]\n\n        obsm = {}\n        for key in obsm_attrs:\n            obsm[key] = obs.pop(key)\n\n        var = dict(lc.row_attrs)\n        if var_names in var.keys(): var['var_names'] = var.pop(var_names)\n        varm_attrs = [k for k, v in var.items() if v.ndim > 1 and v.shape[1] > 1]\n\n        varm = {}\n        for key in varm_attrs:\n            varm[key] = var.pop(key)\n\n        if cleanup:\n            for key in list(obs.keys()):\n                if len(set(obs[key])) == 1:\n                    del obs[key]\n            for key in list(var.keys()):\n                if len(set(var[key])) == 1:\n                    del var[key]\n\n        adata = AnnData(\n            X,\n            obs=obs,  # not ideal: make the generator a dict...\n            var=var,\n            layers=layers,\n            obsm=obsm if obsm else None,\n            varm=varm if varm else None,\n            dtype=dtype)\n    return adata", "response": "Read a. loom - formatted hdf5 file into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_mtx(filename: PathLike, dtype: str='float32') -> AnnData:\n    from scipy.io import mmread\n    # could be rewritten accounting for dtype to be more performant\n    X = mmread(fspath(filename)).astype(dtype)\n    from scipy.sparse import csr_matrix\n    X = csr_matrix(X)\n    return AnnData(X, dtype=dtype)", "response": "Read a. mtx file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_text(\n    filename: Union[PathLike, Iterator[str]],\n    delimiter: Optional[str]=None,\n    first_column_names: Optional[bool]=None,\n    dtype: str='float32',\n) -> AnnData:\n    \"\"\"Read ``.txt``, ``.tab``, ``.data`` (text) file.\n\n    Same as :func:`~anndata.read_csv` but with default delimiter ``None``.\n\n    Parameters\n    ----------\n    filename\n        Data file, filename or stream.\n    delimiter\n        Delimiter that separates data within text file. If ``None``, will split at\n        arbitrary number of white spaces, which is different from enforcing\n        splitting at single white space ``' '``.\n    first_column_names\n        Assume the first column stores row names.\n    dtype\n        Numpy data type.\n    \"\"\"\n    if not isinstance(filename, (PathLike, str, bytes)):\n        return _read_text(filename, delimiter, first_column_names, dtype)\n\n    filename = Path(filename)\n    if filename.suffix == '.gz':\n        with gzip.open(str(filename), mode='rt') as f:\n            return _read_text(f, delimiter, first_column_names, dtype)\n    elif filename.suffix == '.bz2':\n        with bz2.open(str(filename), mode='rt') as f:\n            return _read_text(f, delimiter, first_column_names, dtype)\n    else:\n        with filename.open() as f:\n            return _read_text(f, delimiter, first_column_names, dtype)", "response": "Read ``.txt``, ``.tab``, ``.data`` (text) file.\n\n    Same as :func:`~anndata.read_csv` but with default delimiter ``None``.\n\n    Parameters\n    ----------\n    filename\n        Data file, filename or stream.\n    delimiter\n        Delimiter that separates data within text file. If ``None``, will split at\n        arbitrary number of white spaces, which is different from enforcing\n        splitting at single white space ``' '``.\n    first_column_names\n        Assume the first column stores row names.\n    dtype\n        Numpy data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields all nonempty lines from file_like.", "response": "def iter_lines(file_like: Iterable[str]) -> Generator[str, None, None]:\n    \"\"\" Helper for iterating only nonempty lines without line breaks\"\"\"\n    for line in file_like:\n        line = line.rstrip('\\r\\n')\n        if line:\n            yield line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading from a hierarchical Zarr array store.", "response": "def read_zarr(store):\n    \"\"\"Read from a hierarchical Zarr array store.\n\n    Parameters\n    ----------\n    store\n        The filename, a :class:`~typing.MutableMapping`, or a Zarr storage class.\n    \"\"\"\n    if isinstance(store, Path):\n        store = str(store)\n    import zarr\n    f = zarr.open(store, mode='r')\n    d = {}\n    for key in f.keys():\n        _read_key_value_from_zarr(f, d, key)\n    return AnnData(*AnnData._args_from_dict(d))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads h5ad - formatted hdf5 file.", "response": "def read_h5ad(filename, backed: Optional[str] = None, chunk_size: int = 6000):\n    \"\"\"Read ``.h5ad``-formatted hdf5 file.\n\n    Parameters\n    ----------\n    filename\n        File name of data file.\n    backed : {``None``, ``'r'``, ``'r+'``}\n        If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\n        of fully loading it into memory (`memory` mode). If you want to modify\n        backed attributes of the AnnData object, you need to choose ``'r+'``.\n    chunk_size\n        Used only when loading sparse dataset that is stored as dense.\n        Loading iterates through chunks of the dataset of this row size\n        until it reads the whole dataset.\n        Higher size means higher memory consumption and higher loading speed.\n    \"\"\"\n    if isinstance(backed, bool):\n        # We pass `None`s through to h5py.File, and its default is \u201ca\u201d\n        # (=\u201cr+\u201d, but create the file if it doesn\u2019t exist)\n        backed = 'r+' if backed else None\n        warnings.warn(\n            \"In a future version, read_h5ad will no longer explicitly support \"\n            \"boolean arguments. Specify the read mode, or leave `backed=None`.\",\n            DeprecationWarning,\n        )\n    if backed:\n        # open in backed-mode\n        return AnnData(filename=filename, filemode=backed)\n    else:\n        # load everything into memory\n        constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size)\n        X = constructor_args[0]\n        dtype = None\n        if X is not None:\n            dtype = X.dtype.name  # maintain dtype, since 0.7\n        return AnnData(*_read_args_from_h5ad(filename=filename, chunk_size=chunk_size), dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the parameters for initializing AnnData.", "response": "def _read_args_from_h5ad(\n    adata: AnnData = None,\n    filename: Optional[PathLike] = None,\n    mode: Optional[str] = None,\n    chunk_size: int = 6000\n):\n    \"\"\"Return a tuple with the parameters for initializing AnnData.\n\n    Parameters\n    ----------\n    filename\n        Defaults to the objects filename if ``None``.\n    \"\"\"\n    if filename is None and (adata is None or adata.filename is None):\n        raise ValueError('Need either a filename or an AnnData object with file backing')\n\n    # we need to be able to call the function without reference to self when\n    # not reading in backed mode\n    backed = mode is not None\n    if filename is None and not backed:\n        filename = adata.filename\n\n    d = {}\n    if backed:\n        f = adata.file._file\n    else:\n        f = h5py.File(filename, 'r')\n    for key in f.keys():\n        if backed and key in AnnData._BACKED_ATTRS:\n            d[key] = None\n        else:\n            _read_key_value_from_h5(f, d, key, chunk_size=chunk_size)\n    # backwards compat: save X with the correct name\n    if 'X' not in d:\n        if backed == 'r+':\n            for key in AnnData._H5_ALIASES['X']:\n                if key in d:\n                    del f[key]\n                    f.create_dataset('X', data=d[key])\n                    break\n    # backwards compat: store sparse matrices properly\n    csr_keys = [key.replace('_csr_data', '')\n                for key in d if '_csr_data' in key]\n    for key in csr_keys:\n        d = load_sparse_csr(d, key=key)\n    if not backed:\n        f.close()\n    return AnnData._args_from_dict(d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_csvs(dirname: PathLike, adata: AnnData, skip_data: bool = True, sep: str = ','):\n    dirname = Path(dirname)\n    if dirname.suffix == '.csv':\n        dirname = dirname.with_suffix('')\n    logger.info(\"writing '.csv' files to %s\", dirname)\n    if not dirname.is_dir():\n        dirname.mkdir(parents=True, exist_ok=True)\n    dir_uns = dirname / 'uns'\n    if not dir_uns.is_dir():\n        dir_uns.mkdir(parents=True, exist_ok=True)\n    d = dict(\n        obs=adata._obs,\n        var=adata._var,\n        obsm=adata._obsm.to_df(),\n        varm=adata._varm.to_df(),\n    )\n    if not skip_data:\n        d['X'] = pd.DataFrame(\n            adata._X.toarray() if issparse(adata._X) else adata._X)\n    d_write = {**d, **adata._uns}\n    not_yet_raised_sparse_warning = True\n    for key, value in d_write.items():\n        if issparse(value):\n            if not_yet_raised_sparse_warning:\n                warnings.warn('Omitting to write sparse annotation.')\n                not_yet_raised_sparse_warning = False\n            continue\n        filename = dirname\n        if key not in {'X', 'var', 'obs', 'obsm', 'varm'}:\n            filename = dir_uns\n        filename /= '{}.csv'.format(key)\n        df = value\n        if not isinstance(value, pd.DataFrame):\n            value = np.array(value)\n            if np.ndim(value) == 0:\n                value = value[None]\n            try:\n                df = pd.DataFrame(value)\n            except Exception as e:\n                warnings.warn('Omitting to write {!r}.'.format(key), type(e))\n                continue\n        df.to_csv(\n            filename, sep=sep,\n            header=key in {'obs', 'var', 'obsm', 'varm'},\n            index=key in {'obs', 'var'},\n        )", "response": "Writes the. csv files of the current object to the specified directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all the indices for the chunks in a zarr array even empty ones.", "response": "def _get_chunk_indices(za):\n    # TODO: does zarr provide code for this?\n    \"\"\"\n    Return all the indices (coordinates) for the chunks in a zarr array, even empty ones.\n    \"\"\"\n    return [(i, j) for i in range(int(math.ceil(float(za.shape[0])/za.chunks[0])))\n            for j in range(int(math.ceil(float(za.shape[1])/za.chunks[1])))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes the index unique by appending 1 2 etc.", "response": "def make_index_unique(index: pd.Index, join: str = '-'):\n    \"\"\"Makes the index unique by appending '1', '2', etc.\n\n    The first occurance of a non-unique value is ignored.\n\n    Parameters\n    ----------\n    join\n         The connecting string between name and integer.\n\n    Examples\n    --------\n    >>> adata1 = sc.AnnData(np.ones((3, 2)), {'obs_names': ['a', 'b', 'c']})\n    >>> adata2 = sc.AnnData(np.zeros((3, 2)), {'obs_names': ['d', 'b', 'b']})\n    >>> adata = adata1.concatenate(adata2)\n    >>> adata.obs_names\n    Index(['a', 'b', 'c', 'd', 'b', 'b'], dtype='object')\n    >>> adata.obs_names_make_unique()\n    >>> adata.obs_names\n    Index(['a', 'b', 'c', 'd', 'b-1', 'b-2'], dtype='object')\n    \"\"\"\n    if index.is_unique:\n        return index\n    from collections import defaultdict\n    values = index.values\n    indices_dup = index.duplicated(keep='first')\n    values_dup = values[indices_dup]\n    counter = defaultdict(lambda: 0)\n    for i, v in enumerate(values_dup):\n        counter[v] += 1\n        values_dup[i] += join + str(counter[v])\n    values[indices_dup] = values_dup\n    index = pd.Index(values)\n    return index"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_corresponding_multicol_key(key, keys_multicol):\n    for mk in keys_multicol:\n        if key.startswith(mk) and 'of' in key:\n            return mk\n    return None", "response": "Find the corresponding multicolumn key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate single - column keys from multicolumn key.", "response": "def _gen_keys_from_multicol_key(key_multicol, n_keys):\n    \"\"\"Generates single-column keys from multicolumn key.\"\"\"\n    keys = [('{}{:03}of{:03}')\n            .format(key_multicol, i+1, n_keys) for i in range(n_keys)]\n    return keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that X is 2D.", "response": "def _check_2d_shape(X):\n    \"\"\"Check shape of array or sparse matrix.\n\n    Assure that X is always 2D: Unlike numpy we always deal with 2D arrays.\n    \"\"\"\n    if X.dtype.names is None and len(X.shape) != 2:\n        raise ValueError('X needs to be 2-dimensional, not '\n                         '{}-dimensional.'.format(len(X.shape)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_df(self) -> pd.DataFrame:\n        df = pd.DataFrame(index=RangeIndex(0, self.shape[0], name=None))\n        for key in self.keys():\n            value = self[key]\n            for icolumn, column in enumerate(value.T):\n                df['{}{}'.format(key, icolumn+1)] = column\n        return df", "response": "Convert to pandas dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _to_memory_mode(self):\n        self._adata.__X = self._adata.X[()]\n        self._file.close()\n        self._file = None\n        self._filename = None", "response": "Close the backing file forget filename change to memory mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstate of backing file.", "response": "def isopen(self) -> bool:\n        \"\"\"State of backing file.\"\"\"\n        if self._file is None:\n            return False\n        # try accessing the id attribute to see if the file is open\n        return bool(self._file.id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef X(self) -> Optional[Union[np.ndarray, sparse.spmatrix, ArrayView]]:\n        if self.isbacked:\n            if not self.file.isopen: self.file.open()\n            X = self.file['X']\n            if self.isview:\n                X = X[self._oidx, self._vidx]\n            return X\n        else:\n            if self.n_obs == 1 and self.n_vars == 1:\n                return self._X[0, 0]\n            elif self.n_obs == 1 or self.n_vars == 1:\n                X = self._X\n                if issparse(self._X): X = self._X.toarray()\n                return X.flatten()\n            else:\n                return self._X", "response": "Data matrix of shape n_obs n_vars."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rename_categories(self, key: str, categories: Sequence[Any]):\n        if isinstance(categories, Mapping):\n            raise ValueError('Only list-like `categories` is supported.')\n        if key in self.obs:\n            old_categories = self.obs[key].cat.categories.tolist()\n            self.obs[key].cat.rename_categories(categories, inplace=True)\n        elif key in self.var:\n            old_categories = self.var[key].cat.categories.tolist()\n            self.var[key].cat.rename_categories(categories, inplace=True)\n        else:\n            raise ValueError('{} is neither in `.obs` nor in `.var`.'\n                             .format(key))\n        # this is not a good solution\n        # but depends on the scanpy conventions for storing the categorical key\n        # as `groupby` in the `params` slot\n        for k1, v1 in self.uns.items():\n            if isinstance(v1, Mapping):\n                if 'params' in v1 and 'groupby' in v1['params']:\n                    if v1['params']['groupby'] == key:\n                        for k2, v2 in v1.items():\n                            # picks out the recarrays that are named according to the old\n                            # categories\n                            if isinstance(v2, np.ndarray) and v2.dtype.names is not None:\n                                if list(v2.dtype.names) == old_categories:\n                                    self.uns[k1][k2].dtype.names = categories\n                                else:\n                                    logger.warning(\n                                        'Omitting {}/{} as old categories do not match.'\n                                        .format(k1, k2))", "response": "Rename the categories of an observation or variable annotation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming string annotations to categoricals.", "response": "def strings_to_categoricals(self, df: Optional[pd.DataFrame] = None):\n        \"\"\"Transform string annotations to categoricals.\n\n        Only affects string annotations that lead to less categories than the\n        total number of observations.\n\n        Params\n        ------\n        df\n            If ``df`` is ``None``, modifies both :attr:`obs` and :attr:`.var`,\n            otherwise modifies ``df`` inplace.\n\n        Notes\n        -----\n        Turns the view of an :class:`~anndata.AnnData` into an actual\n        :class:`~anndata.AnnData`.\n        \"\"\"\n        dont_modify = False  # only necessary for backed views\n        if df is None:\n            dfs = [self.obs, self.var]\n            if self.isview:\n                if not self.isbacked:\n                    self._init_as_actual(self.copy())\n                else:\n                    dont_modify = True\n        else:\n            dfs = [df]\n        for df in dfs:\n            string_cols = [\n                key for key in df.columns\n                if is_string_dtype(df[key])\n                and not is_categorical(df[key])\n            ]\n            for key in string_cols:\n                # make sure we only have strings (could be that there are\n                # np.nans (float), -666, '-666', for instance)\n                c = df[key].astype('U')\n                # make a categorical\n                c = pd.Categorical(c, categories=natsorted(np.unique(c)))\n                if len(c.categories) < len(c):\n                    if dont_modify:\n                        raise RuntimeError(\n                            'Please call `.strings_to_categoricals()` on full AnnData, not on this view. '\n                            'You might encounter this error message while copying or writing to disk.'\n                        )\n                    df[key] = c\n                    logger.info('... storing {!r} as categorical'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _inplace_subset_obs(self, index):\n        adata_subset = self[index].copy()\n        self._init_as_actual(adata_subset, dtype=self._X.dtype)", "response": "Inplace subsetting along variables dimension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransposing the entire object.", "response": "def transpose(self) -> 'AnnData':\n        \"\"\"Transpose whole object.\n\n        Data matrix is transposed, observations and variables are interchanged.\n        \"\"\"\n        if not self.isbacked: X = self._X\n        else: X = self.file['X']\n        if self.isview:\n            raise ValueError(\n                'You\\'re trying to transpose a view of an `AnnData`, which is currently not implemented. '\n                'Call `.copy()` before transposing.')\n        layers = {k:(v.T.tocsr() if sparse.isspmatrix_csr(v) else v.T) for (k, v) in self.layers.items(copy=False)}\n        if sparse.isspmatrix_csr(X):\n            return AnnData(X.T.tocsr(), self._var, self._obs, self._uns,\n                           self._varm.flipped(), self._obsm.flipped(),\n                           filename=self.filename, layers=layers, dtype=self.X.dtype.name)\n        return AnnData(X.T, self._var, self._obs, self._uns,\n                       self._varm.flipped(), self._obsm.flipped(),\n                       filename=self.filename, layers=layers, dtype=self.X.dtype.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate shallow : class : ~pandas. DataFrame.", "response": "def to_df(self) -> pd.DataFrame:\n        \"\"\"Generate shallow :class:`~pandas.DataFrame`.\n\n        The data matrix :attr:`X` is returned as\n        :class:`~pandas.DataFrame`, where :attr:`obs_names` initializes the\n        index, and :attr:`var_names` the columns.\n\n        * No annotations are maintained in the returned object.\n        * The data matrix is densified in case it is sparse.\n        \"\"\"\n        if issparse(self._X):\n            X = self._X.toarray()\n        else:\n            X = self._X\n        return pd.DataFrame(X, index=self.obs_names, columns=self.var_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self, filename: Optional[PathLike] = None) -> 'AnnData':\n        if not self.isbacked:\n            return AnnData(self._X.copy() if self._X is not None else None,\n                           self._obs.copy(),\n                           self._var.copy(),\n                           # deepcopy on DictView does not work and is unnecessary\n                           # as uns was copied already before\n                           self._uns.copy() if isinstance(self._uns, DictView) else deepcopy(self._uns),\n                           self._obsm.copy(), self._varm.copy(),\n                           raw=None if self._raw is None else self._raw.copy(),\n                           layers=self.layers.as_dict(),\n                           dtype=self._X.dtype.name if self._X is not None else 'float32')\n        else:\n            if filename is None:\n                raise ValueError(\n                    'To copy an AnnData object in backed mode, '\n                    'pass a filename: `.copy(filename=\\'myfilename.h5ad\\')`.')\n            if self.isview:\n                self.write(filename)\n            else:\n                from shutil import copyfile\n                copyfile(self.filename, filename)\n            return AnnData(filename=filename)", "response": "Copy an AnnData object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconcatenate the given set of anndata matrices into a single object.", "response": "def concatenate(\n        self, *adatas: 'AnnData',\n        join: str = 'inner',\n        batch_key: str = 'batch',\n        batch_categories: Sequence[Any] = None,\n        index_unique: Optional[str] = '-'\n    ) -> 'AnnData':\n        \"\"\"Concatenate along the observations axis.\n\n        The :attr:`uns`, :attr:`varm` and :attr:`obsm` attributes are ignored.\n\n        Currently, this works only in ``'memory'`` mode.\n\n        Parameters\n        ----------\n        adatas\n            AnnData matrices to concatenate with. Each matrix is referred to as\n            a \u201cbatch\u201d.\n        join\n            Use intersection (``'inner'``) or union (``'outer'``) of variables.\n        batch_key\n            Add the batch annotation to :attr:`obs` using this key.\n        batch_categories\n            Use these as categories for the batch annotation. By default, use increasing numbers.\n        index_unique\n            Make the index unique by joining the existing index names with the\n            batch category, using ``index_unique='-'``, for instance. Provide\n            ``None`` to keep existing indices.\n\n        Returns\n        -------\n        :class:`~anndata.AnnData`\n            The concatenated :class:`~anndata.AnnData`, where ``adata.obs[batch_key]``\n            stores a categorical variable labeling the batch.\n\n        Notes\n        -----\n\n        .. warning::\n\n           If you use ``join='outer'`` this fills 0s for sparse data when\n           variables are absent in a batch. Use this with care. Dense data is\n           filled with ``NaN``. See the examples.\n\n        Examples\n        --------\n        Joining on intersection of variables.\n\n        >>> adata1 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),\n        >>>                  {'obs_names': ['s1', 's2'],\n        >>>                   'anno1': ['c1', 'c2']},\n        >>>                  {'var_names': ['a', 'b', 'c'],\n        >>>                   'annoA': [0, 1, 2]})\n        >>> adata2 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),\n        >>>                  {'obs_names': ['s3', 's4'],\n        >>>                   'anno1': ['c3', 'c4']},\n        >>>                  {'var_names': ['d', 'c', 'b'],\n        >>>                   'annoA': [0, 1, 2]})\n        >>> adata3 = AnnData(np.array([[1, 2, 3], [4, 5, 6]]),\n        >>>                  {'obs_names': ['s1', 's2'],\n        >>>                   'anno2': ['d3', 'd4']},\n        >>>                  {'var_names': ['d', 'c', 'b'],\n        >>>                   'annoA': [0, 2, 3],\n        >>>                   'annoB': [0, 1, 2]})\n        >>>\n        >>> adata = adata1.concatenate(adata2, adata3)\n        >>> adata\n        AnnData object with n_obs \u00d7 n_vars = 6 \u00d7 2\n            obs_keys = ['anno1', 'anno2', 'batch']\n            var_keys = ['annoA-0', 'annoA-1', 'annoB-2', 'annoA-2']\n        >>> adata.X\n        array([[2., 3.],\n               [5., 6.],\n               [3., 2.],\n               [6., 5.],\n               [3., 2.],\n               [6., 5.]], dtype=float32)\n        >>> adata.obs\n             anno1 anno2 batch\n        s1-0    c1   NaN     0\n        s2-0    c2   NaN     0\n        s3-1    c3   NaN     1\n        s4-1    c4   NaN     1\n        s1-2   NaN    d3     2\n        s2-2   NaN    d4     2\n        >>> adata.var.T\n                 b  c\n        annoA-0  1  2\n        annoA-1  2  1\n        annoB-2  2  1\n        annoA-2  3  2\n\n        Joining on the union of variables.\n\n        >>> adata = adata1.concatenate(adata2, adata3, join='outer')\n        >>> adata\n        AnnData object with n_obs \u00d7 n_vars = 6 \u00d7 4\n            obs_keys = ['anno1', 'anno2', 'batch']\n            var_keys = ['annoA-0', 'annoA-1', 'annoB-2', 'annoA-2']\n        >>> adata.var.T\n        index      a    b    c    d\n        annoA-0  0.0  1.0  2.0  NaN\n        annoA-1  NaN  2.0  1.0  0.0\n        annoB-2  NaN  2.0  1.0  0.0\n        annoA-2  NaN  3.0  2.0  0.0\n        >>> adata.var_names\n        Index(['a', 'b', 'c', 'd'], dtype='object')\n        >>> adata.X\n        array([[ 1.,  2.,  3., nan],\n               [ 4.,  5.,  6., nan],\n               [nan,  3.,  2.,  1.],\n               [nan,  6.,  5.,  4.],\n               [nan,  3.,  2.,  1.],\n               [nan,  6.,  5.,  4.]], dtype=float32)\n        >>> adata.X.sum(axis=0)\n        array([nan, 25., 23., nan], dtype=float32)\n        >>> import pandas as pd\n        >>> Xdf = pd.DataFrame(adata.X, columns=adata.var_names)\n        index    a    b    c    d\n        0      1.0  2.0  3.0  NaN\n        1      4.0  5.0  6.0  NaN\n        2      NaN  3.0  2.0  1.0\n        3      NaN  6.0  5.0  4.0\n        4      NaN  3.0  2.0  1.0\n        5      NaN  6.0  5.0  4.0\n        >>> Xdf.sum()\n        index\n        a     5.0\n        b    25.0\n        c    23.0\n        d    10.0\n        dtype: float32\n        >>> from numpy import ma\n        >>> adata.X = ma.masked_invalid(adata.X)\n        >>> adata.X\n        masked_array(\n          data=[[1.0, 2.0, 3.0, --],\n                [4.0, 5.0, 6.0, --],\n                [--, 3.0, 2.0, 1.0],\n                [--, 6.0, 5.0, 4.0],\n                [--, 3.0, 2.0, 1.0],\n                [--, 6.0, 5.0, 4.0]],\n          mask=[[False, False, False,  True],\n                [False, False, False,  True],\n                [ True, False, False, False],\n                [ True, False, False, False],\n                [ True, False, False, False],\n                [ True, False, False, False]],\n          fill_value=1e+20,\n          dtype=float32)\n        >>> adata.X.sum(axis=0).data\n        array([ 5., 25., 23., 10.], dtype=float32)\n\n        The masked array is not saved but has to be reinstantiated after saving.\n\n        >>> adata.write('./test.h5ad')\n        >>> from anndata import read_h5ad\n        >>> adata = read_h5ad('./test.h5ad')\n        >>> adata.X\n        array([[ 1.,  2.,  3., nan],\n               [ 4.,  5.,  6., nan],\n               [nan,  3.,  2.,  1.],\n               [nan,  6.,  5.,  4.],\n               [nan,  3.,  2.,  1.],\n               [nan,  6.,  5.,  4.]], dtype=float32)\n\n        For sparse data, everything behaves similarly, except that for ``join='outer'``, zeros are added.\n\n        >>> from scipy.sparse import csr_matrix\n        >>> adata1 = AnnData(csr_matrix([[0, 2, 3], [0, 5, 6]]),\n        >>>                  {'obs_names': ['s1', 's2'],\n        >>>                   'anno1': ['c1', 'c2']},\n        >>>                  {'var_names': ['a', 'b', 'c']})\n        >>> adata2 = AnnData(csr_matrix([[0, 2, 3], [0, 5, 6]]),\n        >>>                  {'obs_names': ['s3', 's4'],\n        >>>                   'anno1': ['c3', 'c4']},\n        >>>                  {'var_names': ['d', 'c', 'b']})\n        >>> adata3 = AnnData(csr_matrix([[1, 2, 0], [0, 5, 6]]),\n        >>>                  {'obs_names': ['s5', 's6'],\n        >>>                   'anno2': ['d3', 'd4']},\n        >>>                  {'var_names': ['d', 'c', 'b']})\n        >>>\n        >>> adata = adata1.concatenate(adata2, adata3, join='outer')\n        >>> adata.var_names\n        Index(['a', 'b', 'c', 'd'], dtype='object')\n        >>> adata.X.toarray()\n        array([[0., 2., 3., 0.],\n               [0., 5., 6., 0.],\n               [0., 3., 2., 0.],\n               [0., 6., 5., 0.],\n               [0., 0., 2., 1.],\n               [0., 6., 5., 0.]], dtype=float32)\n        \"\"\"\n        if self.isbacked:\n            raise ValueError(\n                'Currently, concatenate does only work in \\'memory\\' mode.')\n\n        if len(adatas) == 0:\n            return self\n        elif len(adatas) == 1 and not isinstance(adatas[0], AnnData):\n            adatas = adatas[0]  # backwards compatibility\n        all_adatas = (self,) + tuple(adatas)\n\n        # for controlled behavior, make all variable names unique\n        printed_info = False\n        for i, ad in enumerate(all_adatas):\n            if not ad.var_names.is_unique:\n                ad.var_names = utils.make_index_unique(ad.var_names)\n                if not printed_info:\n                    logger.info(\n                        'Making variable names unique for controlled concatenation.')\n                    printed_info = True\n\n        # define variable names of joint AnnData\n        mergers = dict(inner=set.intersection, outer=set.union)\n        var_names_reduce = reduce(mergers[join], (set(ad.var_names) for ad in all_adatas))\n        # restore order of initial var_names, append non-sortable names at the end\n        # see how this was done in the repo at commit state\n        # 40a24f\n        var_names = []\n        for v in all_adatas[0].var_names:\n            if v in var_names_reduce:\n                var_names.append(v)\n                var_names_reduce.remove(v)  # update the set\n        var_names = pd.Index(var_names + list(var_names_reduce))\n\n        if batch_categories is None:\n            categories = [str(i) for i, _ in enumerate(all_adatas)]\n        elif len(batch_categories) == len(all_adatas):\n            categories = batch_categories\n        else:\n            raise ValueError('Provide as many `batch_categories` as `adatas`.')\n\n        out_shape = (sum(a.n_obs for a in all_adatas), len(var_names))\n\n        any_sparse = any(issparse(a.X) for a in all_adatas)\n        if join == 'outer':\n            if any_sparse:  # not sure whether the lil_matrix is really the best option\n                X = sparse.lil_matrix(out_shape, dtype=self.X.dtype)\n            else:\n                X = np.empty(out_shape, dtype=self.X.dtype)\n                X[:] = np.nan\n        else:\n            Xs = []\n\n        # create layers dict that contains layers shared among all AnnDatas\n        layers = OrderedDict()\n        shared_layers = [key for key in all_adatas[0].layers.keys()\n                         if all([key in ad.layers.keys() for ad in all_adatas])]\n        for key in shared_layers:\n            layers[key] = []\n\n        # check whether tries to do 'outer' join and layers is non_empty.\n        if join == 'outer' and len(shared_layers) > 0:\n            logger.info(\n                'layers concatenation is not yet available for \\'outer\\' intersection and will be ignored.')\n\n        # check whether layers are not consistently set in all AnnData objects.\n        n_layers = np.array([len(ad.layers.keys()) for ad in all_adatas])\n        if join == 'inner' and not all(len(shared_layers) == n_layers):\n            logger.info(\n                'layers are inconsistent - only layers that are shared among all AnnData objects are included.')\n\n        var = pd.DataFrame(index=var_names)\n\n        obs_i = 0  # start of next adata\u2019s observations in X\n        out_obss = []\n        for i, ad in enumerate(all_adatas):\n            if join == 'outer':\n                # only those names that are actually present in the current AnnData\n                vars_intersect = [v for v in var_names if v in ad.var_names]\n            else:\n                vars_intersect = var_names\n\n            # X\n            if join == 'outer':\n                # this is pretty slow, I guess sparse matrices shouldn't be\n                # constructed like that\n                X[obs_i:obs_i+ad.n_obs,\n                  var_names.isin(vars_intersect)] = ad[:, vars_intersect].X\n            else:\n                Xs.append(ad[:, vars_intersect].X)\n            obs_i += ad.n_obs\n\n            # layers\n            if join == 'inner':\n                for key in shared_layers:\n                    layers[key].append(ad[:, vars_intersect].layers[key])\n\n            # obs\n            obs = ad.obs.copy()\n            obs[batch_key] = pd.Categorical(ad.n_obs * [categories[i]], categories)\n            if (is_string_dtype(all_adatas[0].obs.index) and not\n                is_string_dtype(ad.obs.index)):\n                obs.index = obs.index.astype(str)\n            if index_unique is not None:\n                if not is_string_dtype(ad.obs.index):\n                    obs.index = obs.index.astype(str)\n                obs.index = obs.index.values + index_unique + categories[i]\n            out_obss.append(obs)\n\n            # var\n            for c in ad.var.columns:\n                new_c = c + (index_unique if index_unique is not None else '-') + categories[i]\n                var.loc[vars_intersect, new_c] = ad.var.loc[vars_intersect, c]\n\n        if join == 'inner':\n            if any_sparse:\n                from scipy.sparse import vstack\n                X = vstack(Xs)\n            else:\n                X = np.concatenate(Xs)\n\n            for key in shared_layers:\n                if any(issparse(a.layers[key]) for a in all_adatas):\n                    layers[key] = vstack(layers[key])\n                else:\n                    layers[key] = np.concatenate(layers[key])\n\n        obs = pd.concat(out_obss, sort=True)\n\n        if any_sparse:\n            sparse_format = all_adatas[0].X.getformat()\n            X = X.asformat(sparse_format)\n\n        new_adata = AnnData(X, obs, var, layers=layers) if join == 'inner' else AnnData(X, obs, var)\n        if not obs.index.is_unique:\n            logger.info(\n                'Or pass `index_unique!=None` to `.concatenate`.')\n        return new_adata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the object to a. h5ad file.", "response": "def write_h5ad(\n        self,\n        filename: Optional[PathLike] = None,\n        compression: Optional[str] = None,\n        compression_opts: Union[int, Any] = None,\n        force_dense: Optional[bool] = None\n    ):\n        \"\"\"Write ``.h5ad``-formatted hdf5 file.\n\n        .. note::\n\n            Setting compression to ``'gzip'`` can save disk space but\n            will slow down writing and subsequent reading. Prior to\n            v0.6.16, this was the default for parameter\n            ``compression``.\n\n        Generally, if you have sparse data that are stored as a dense\n        matrix, you can dramatically improve performance and reduce\n        disk space by converting to a :class:`~scipy.sparse.csr_matrix`::\n\n            from scipy.sparse import csr_matrix\n            adata.X = csr_matrix(adata.X)\n\n        Parameters\n        ----------\n        filename\n            Filename of data file. Defaults to backing file.\n        compression : ``None``,  {``'gzip'``, ``'lzf'``} (default: ``None``)\n            See the h5py :ref:`dataset_compression`.\n        compression_opts\n            See the h5py :ref:`dataset_compression`.\n        force_dense\n            Write sparse data as a dense matrix. Defaults to ``True`` if object is\n            backed, otherwise to ``False``.\n        \"\"\"\n        from .readwrite.write import _write_h5ad\n\n        if filename is None and not self.isbacked:\n            raise ValueError('Provide a filename!')\n        if filename is None:\n            filename = self.filename\n        if force_dense is None:\n            force_dense = self.isbacked\n\n        _write_h5ad(filename, self, compression=compression,\n                    compression_opts=compression_opts, force_dense=force_dense)\n\n        if self.isbacked:\n            self.file.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_csvs(self, dirname: PathLike, skip_data: bool = True, sep: str = ','):\n        from .readwrite.write import write_csvs\n        write_csvs(dirname, self, skip_data=skip_data, sep=sep)", "response": "Write the data matrix to. csv files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite ``.loom``-formatted hdf5 file. Parameters ---------- filename The filename.", "response": "def write_loom(self, filename: PathLike, write_obsm_varm: bool = False):\n        \"\"\"Write ``.loom``-formatted hdf5 file.\n\n        Parameters\n        ----------\n        filename\n            The filename.\n        \"\"\"\n        from .readwrite.write import write_loom\n        write_loom(filename, self, write_obsm_varm = write_obsm_varm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_zarr(\n        self,\n        store: Union[MutableMapping, PathLike],\n        chunks: Union[bool, int, Tuple[int, ...]],\n    ):\n        \"\"\"Write a hierarchical Zarr array store.\n\n        Parameters\n        ----------\n        store\n            The filename, a :class:`~typing.MutableMapping`, or a Zarr storage class.\n        chunks\n            Chunk shape.\n        \"\"\"\n        from .readwrite.write import write_zarr\n        write_zarr(store, self, chunks=chunks)", "response": "Writes a hierarchical Zarr array store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterator over the rows of the data matrix X.", "response": "def chunked_X(self, chunk_size: Optional[int] = None):\n        \"\"\"Return an iterator over the rows of the data matrix :attr:`X`.\n\n        Parameters\n        ----------\n        chunk_size\n            Row size of a single chunk.\n        \"\"\"\n        if chunk_size is None:\n            # Should be some adaptive code\n            chunk_size = 6000\n        start = 0\n        n = self.n_obs\n        for _ in range(int(n // chunk_size)):\n            end = start + chunk_size\n            yield (self.X[start:end], start, end)\n            start = end\n        if start < n:\n            yield (self.X[start:n], start, n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunk_X(\n        self,\n        select: Union[int, List[int], Tuple[int, ...], np.ndarray] = 1000,\n        replace: bool = True,\n    ):\n        \"\"\"Return a chunk of the data matrix :attr:`X` with random or specified indices.\n\n        Parameters\n        ----------\n        select\n            If select is an integer, a random chunk of row size = select will be returned.\n            If select is a list, tuple or numpy array of integers, then a chunk\n            with these indices will be returned.\n\n        replace\n            If select is an integer then ``replace=True`` specifies random sampling of indices\n            with replacement, ``replace=False`` - without replacement.\n        \"\"\"\n        if isinstance(select, int):\n            select = select if select < self.n_obs else self.n_obs\n            choice = np.random.choice(self.n_obs, select, replace)\n        elif isinstance(select, (np.ndarray, list, tuple)):\n            choice = np.asarray(select)\n        else:\n            raise ValueError('select should be int or array')\n\n        reverse = None\n        if self.isbacked:\n            # h5py can only slice with a sorted list of unique index values\n            # so random batch with indices [2, 2, 5, 3, 8, 10, 8] will fail\n            # this fixes the problem\n            indices, reverse = np.unique(choice, return_inverse=True)\n            selection = self.X[indices.tolist()]\n        else:\n            selection = self.X[choice]\n\n        selection = selection.toarray() if issparse(selection) else selection\n        return selection if reverse is None else selection[reverse]", "response": "Return a random chunk of the data matrix with random or specified indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _args_from_dict(ddata: Mapping[str, Any]):\n        d_true_keys = {}\n        # backwards compat\n        uns_is_not_key = False\n        valid_keys = []\n        for keys in AnnData._H5_ALIASES.values():\n            valid_keys += keys\n        valid_keys += ['raw.X', 'raw.var', 'raw.varm', 'raw.cat']\n        for key in ddata.keys():\n            # if there is another key then the prdedefined\n            # then we are reading the old format\n            if key not in valid_keys:\n                uns_is_not_key = True\n\n        for true_key, keys in AnnData._H5_ALIASES.items():\n            for key in keys:\n                if key in ddata:\n                    d_true_keys[true_key] = ddata[key]\n                    if uns_is_not_key: del ddata[key]\n                    break\n            else:\n                d_true_keys[true_key] = None\n\n        # transform recarray to dataframe\n        for true_key, keys in AnnData._H5_ALIASES_NAMES.items():\n            if d_true_keys[true_key] is not None:\n                for key in keys:\n                    if key in d_true_keys[true_key].dtype.names:\n                        d_true_keys[true_key] = pd.DataFrame.from_records(\n                            d_true_keys[true_key], index=key)\n                        break\n                d_true_keys[true_key].index = d_true_keys[true_key].index.astype('U')\n                # transform to unicode string\n                # TODO: this is quite a hack\n                for c in d_true_keys[true_key].columns:\n                    if is_string_dtype(d_true_keys[true_key][c]):\n                        d_true_keys[true_key][c] = pd.Index(\n                            d_true_keys[true_key][c]).astype('U').values\n\n        # these are the category fields\n        k_to_delete = []\n        items = (\n            ddata.items() if uns_is_not_key\n            else ddata['uns'].items() if 'uns' in ddata else []\n        )\n        for k, v in items:\n            if k.endswith('_categories'):\n                k_stripped = k.replace('_categories', '')\n                if isinstance(v, (str, int)):  # fix categories with a single category\n                    v = [v]\n                for ann in ['obs', 'var']:\n                    if k_stripped in d_true_keys[ann]:\n                        d_true_keys[ann][k_stripped] = pd.Categorical.from_codes(\n                            codes=d_true_keys[ann][k_stripped].values,\n                            categories=v,\n                        )\n                k_to_delete.append(k)\n\n        for k in k_to_delete:\n            if uns_is_not_key:\n                del ddata[k]\n            else:\n                del ddata['uns'][k]\n\n        # assign the variables\n        X = d_true_keys['X']\n        obs = d_true_keys['obs']\n        obsm = d_true_keys['obsm']\n        var = d_true_keys['var']\n        varm = d_true_keys['varm']\n        layers = d_true_keys['layers']\n\n        raw = None\n        if 'raw.X' in ddata:\n            raw = {}\n            raw['X'] = ddata['raw.X']\n            del ddata['raw.X']\n            # get the dataframe\n            raw['var'] = pd.DataFrame.from_records(\n                ddata['raw.var'], index='index')\n            del ddata['raw.var']\n            raw['var'].index = raw['var'].index.astype('U')\n            # transform to unicode string\n            for c in raw['var'].columns:\n                if is_string_dtype(raw['var'][c]):\n                    raw['var'][c] = pd.Index(raw['var'][c]).astype('U').values\n            # these are the category fields\n            if 'raw.cat' in ddata:  # old h5ad didn't have that field\n                for k, v in ddata['raw.cat'].items():\n                    if k.endswith('_categories'):\n                        k_stripped = k.replace('_categories', '')\n                        if isinstance(v, (str, int)):  # fix categories with a single category\n                            v = [v]\n                        raw['var'][k_stripped] = pd.Categorical.from_codes(\n                            codes=raw['var'][k_stripped].values,\n                            categories=v)\n                del ddata['raw.cat']\n        if 'raw.varm' in ddata:\n            raw['varm'] = ddata['raw.varm']\n            del ddata['raw.varm']\n        elif raw is not None:\n            raw['varm'] = None\n\n        # the remaining fields are the unstructured annotation\n        uns = (\n            ddata if uns_is_not_key\n            else ddata['uns'] if 'uns' in ddata\n            else {}\n        )\n\n        return X, obs, var, uns, obsm, varm, layers, raw", "response": "Converts a dictionary of values into a dictionary of arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset value at each i j to x", "response": "def _set_many(self, i, j, x):\n    \"\"\"Sets value at each (i, j) to x\n\n    Here (i,j) index major and minor respectively, and must not contain\n    duplicate entries.\n    \"\"\"\n    i, j, M, N = self._prepare_indices(i, j)\n\n    n_samples = len(x)\n    offsets = np.empty(n_samples, dtype=self.indices.dtype)\n    ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,\n                                          n_samples, i, j, offsets)\n    if ret == 1:\n        # rinse and repeat\n        self.sum_duplicates()\n        _sparsetools.csr_sample_offsets(M, N, self.indptr,\n                                        self.indices, n_samples, i, j,\n                                        offsets)\n\n    if -1 not in offsets:\n        # make a list for interaction with h5py\n        offsets = list(offsets)\n        # only affects existing non-zero cells\n        self.data[offsets] = x\n        return\n\n    else:\n        # raise ValueError(\n        #     'Currently, you cannot change the sparsity structure of a SparseDataset.')\n        # replace where possible\n        mask = offsets > -1\n        self.data[offsets[mask]] = x[mask]\n        # only insertions remain\n        mask = ~mask\n        i = i[mask]\n        i[i < 0] += M\n        j = j[mask]\n        j[j < 0] += N\n        self._insert_many(i, j, x[mask])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _zero_many(self, i, j):\n    i, j, M, N = self._prepare_indices(i, j)\n\n    n_samples = len(i)\n    offsets = np.empty(n_samples, dtype=self.indices.dtype)\n    ret = _sparsetools.csr_sample_offsets(M, N, self.indptr, self.indices,\n                                          n_samples, i, j, offsets)\n    if ret == 1:\n        # rinse and repeat\n        self.sum_duplicates()\n        _sparsetools.csr_sample_offsets(M, N, self.indptr,\n                                        self.indices, n_samples, i, j,\n                                        offsets)\n\n    # only assign zeros to the existing sparsity structure\n    self.data[list(offsets[offsets > -1])] = 0", "response": "Sets value at each i j to zero preserving sparsity structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding parse functions for public grammar rules", "response": "def _expose_rule_functions(self, expose_all_rules=False):\n        \"\"\"add parse functions for public grammar rules\n\n        Defines a function for each public grammar rule, based on\n        introspecting the grammar. For example, the `c_interval` rule\n        is exposed as a method `parse_c_interval` and used like this::\n\n          Parser.parse_c_interval('26+2_57-3') -> Interval(...)\n\n        \"\"\"\n\n        def make_parse_rule_function(rule_name):\n            \"builds a wrapper function that parses a string with the specified rule\"\n\n            def rule_fxn(s):\n                try:\n                    return self._grammar(s).__getattr__(rule_name)()\n                except ometa.runtime.ParseError as exc:\n                    raise HGVSParseError(\"{s}: char {exc.position}: {reason}\".format(\n                        s=s, exc=exc, reason=exc.formatReason()))\n\n            rule_fxn.__doc__ = \"parse string s using `%s' rule\" % rule_name\n            return rule_fxn\n\n        exposed_rule_re = re.compile(r\"hgvs_(variant|position)|(c|g|m|n|p|r)\"\n                                     r\"_(edit|hgvs_position|interval|pos|posedit|variant)\")\n        exposed_rules = [\n            m.replace(\"rule_\", \"\") for m in dir(self._grammar._grammarClass)\n            if m.startswith(\"rule_\")\n        ]\n        if not expose_all_rules:\n            exposed_rules = [\n                rule_name for rule_name in exposed_rules if exposed_rule_re.match(rule_name)\n            ]\n        for rule_name in exposed_rules:\n            att_name = \"parse_\" + rule_name\n            rule_fxn = make_parse_rule_function(rule_name)\n            self.__setattr__(att_name, rule_fxn)\n        self._logger.debug(\"Exposed {n} rules ({rules})\".format(\n            n=len(exposed_rules), rules=\", \".join(exposed_rules)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef variant_context_w_alignment(am, var, margin=20, tx_ac=None):\n    from uta_align.align.algorithms import align, cigar_alignment\n\n    fh = full_house(am, var, tx_ac=tx_ac)\n    tm = am._fetch_AlignmentMapper(fh['n'].ac, fh['g'].ac, am.alt_aln_method)\n    strand = tm.strand\n    span_g = _ival_to_span(fh['g'].posedit.pos)\n    span_g = (span_g[0] - margin, span_g[1] + margin)\n    ival_g = Interval(SimplePosition(span_g[0]), SimplePosition(span_g[1]))\n    ival_n = tm.g_to_n(ival_g)\n    assert ival_n.start.offset == 0 and ival_n.end.offset == 0, \"limited to coding variants\"\n    span_n = _ival_to_span(ival_n)\n    ival_c = tm.g_to_c(ival_g)\n    span_c = _ival_to_span(ival_c)\n    seq_gt = am.hdp.get_seq(fh['g'].ac, span_g[0] - 1, span_g[1])\n    seq_gb = complement(seq_gt)\n    seq_n = am.hdp.get_seq(fh['n'].ac, span_n[0] - 1, span_n[1])\n    if strand == 1:\n        a = align(bytes(seq_gt), bytes(seq_n), b'global', extended_cigar=True)\n    else:\n        seq_n = ''.join(reversed(seq_n))\n        a = align(bytes(seq_gb), bytes(seq_n), b'global', extended_cigar=True)\n\n    aseq_gt, _ = cigar_alignment(seq_gt, a.query, a.cigar, hide_match=False)\n    aseq_gb, aseq_n = cigar_alignment(seq_gb, a.query, a.cigar, hide_match=False)\n    aln_str = _reformat_aln_str(cigar_alignment(a.ref, a.query, a.cigar, hide_match=True)[1])\n    s_dir = '>' if strand == 1 else '<'\n\n    lines = [\n        [\n            1,\n            0,\n            seq_line_fmt(\n                var=fh['c'],\n                span=span_c if strand == 1 else list(reversed(span_c)),\n                content='',\n                dir=s_dir),\n        ],\n        [\n            2,\n            0,\n            seq_line_fmt(\n                var=fh['n'],\n                span=span_n if strand == 1 else list(reversed(span_n)),\n                content=aseq_n,\n                dir=s_dir),\n        ],\n        [\n            3,\n            0,\n            _line_fmt.format(pre='', content=aln_str, post=a.cigar.to_string(), comment=''),\n        ],\n        [\n            4,\n            1,\n            seq_line_fmt(var=fh['g'], span=span_g, content=aseq_gt, dir='>'),\n        ],\n        [\n            4,\n            2,\n            seq_line_fmt(var=fh['g'], span=span_g, content=aseq_gb, dir='<'),\n        ],\n        [\n            5,\n            0,\n            pointer_line(var=fh['g'], span=span_g),\n        ],\n    ]\n    if strand == -1:\n        lines.sort(key=lambda e: (-e[0], e[1]))\n    return '\\n'.join(r[2] for r in lines)", "response": "This module is experimental. It requires the uta_align package from pypi."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_sequence(seq, start=None, end=None, group_size=3):\n\n    width = 100\n    loc_width = 9\n    sep = \" \"\n    body_sep = \" : \"\n\n    start = start or 0\n    end = end or len(seq)\n\n    bw = width - loc_width - len(body_sep)\n    assert group_size <= bw, \"group size must be less than available line width\"\n    gpl = int((bw + len(sep)) / (group_size + len(sep)))    # groups per line\n    gpl = int(gpl / 5) * 5 if gpl > 20 else gpl\n    rpl = group_size * gpl\n    line_fmt = \"{{l:>{lw}s}}{body_sep}{{body}}\".format(lw=loc_width, body_sep=body_sep)\n    ge_fmt = \"{{ge:>{gs}}}\".format(gs=group_size)\n\n    blocks = []\n    for ls in range(start, end, rpl):\n        le = ls + rpl\n\n        groups = [\n            ge_fmt.format(ge=str(gs + group_size)[-group_size + 1:])\n            for gs in range(ls, le, group_size)\n        ]\n        blocks += [line_fmt.format(l=\"\", body=sep.join(groups)) + \"\\n\"]\n\n        groups = [seq[gs:min(gs + group_size, end)] for gs in range(ls, le, group_size)]\n        blocks += [line_fmt.format(l=str(ls + 1), body=sep.join(groups)) + \"\\n\"]\n\n        blocks += [\"\\n\"]\n\n    return blocks", "response": "format a sequence into a list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _stage_from_version(version):\n    if version:\n        m = re.match(r\"^(?P<xyz>\\d+\\.\\d+\\.\\d+)(?P<extra>.*)\", version)\n        if m:\n            return \"stg\" if m.group(\"extra\") else \"prd\"\n    return \"dev\"", "response": "Return the stage name for the given version string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_ncbi_db_url():\n\n    if \"NCBI_DB_URL\" in os.environ:\n        return os.environ[\"NCBI_DB_URL\"]\n\n    if \"_NCBI_URL_KEY\" in os.environ:\n        url_key = os.environ[\"_NCBI_URL_KEY\"]\n    else:\n        sdlc = _stage_from_version(hgvs.__version__)\n        url_key = \"public_{sdlc}\".format(sdlc=sdlc)\n    return hgvs.global_config['NCBI'][url_key]", "response": "returns NCBI DB URL based on environment variables and code version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(db_url=None,\n            pooling=hgvs.global_config.uta.pooling,\n            application_name=None,\n            mode=None,\n            cache=None):\n    \"\"\"Connect to a uta/ncbi database instance.\n\n    :param db_url: URL for database connection\n    :type db_url: string\n    :param pooling: whether to use connection pooling (postgresql only)\n    :type pooling: bool\n    :param application_name: log application name in connection (useful for debugging; PostgreSQL only)\n    :type application_name: str\n\n    When called with an explicit db_url argument, that db_url is used for connecting.\n\n    When called without an explicit argument, the function default is\n    determined by the environment variable UTA_DB_URL if it exists, or\n    hgvs.datainterface.uta.public_db_url otherwise.\n\n    >>> hdp = connect()\n    >>> hdp.schema_version()\n    '1.1'\n\n    The format of the db_url is driver://user:pass@host/database (the same\n    as that used by SQLAlchemy).  Examples:\n\n    A remote public postgresql database:\n        postgresql://anonymous:anonymous@uta.biocommons.org/uta'\n\n    A local postgresql database:\n        postgresql://localhost/uta\n\n    A local SQLite database:\n      sqlite:////tmp/uta-0.0.6.db\n\n    For postgresql db_urls, pooling=True causes connect to use a\n    psycopg2.pool.ThreadedConnectionPool.\n    \"\"\"\n\n    _logger.debug('connecting to ' + str(db_url) + '...')\n\n    if db_url is None:\n        db_url = _get_ncbi_db_url()\n\n    url = _parse_url(db_url)\n    if url.scheme == 'postgresql':\n        conn = NCBI_postgresql(\n            url=url, pooling=pooling, application_name=application_name, mode=mode, cache=cache)\n    else:\n        # fell through connection scheme cases\n        raise RuntimeError(\"{url.scheme} in {url} is not currently supported\".format(url=url))\n    _logger.info('connected to ' + str(db_url) + '...')\n    return conn", "response": "Connect to a uta database instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_cursor(self, n_retries=1):\n\n        n_tries_rem = n_retries + 1\n        while n_tries_rem > 0:\n            try:\n\n                conn = self._pool.getconn() if self.pooling else self._conn\n\n                # autocommit=True obviates closing explicitly\n                conn.autocommit = True\n\n                cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)\n                cur.execute(\"set search_path = {self.url.schema};\".format(self=self))\n\n                yield cur\n\n                # contextmanager executes these when context exits\n                cur.close()\n                if self.pooling:\n                    self._pool.putconn(conn)\n\n                break\n\n            except psycopg2.OperationalError:\n\n                _logger.warning(\n                    \"Lost connection to {url}; attempting reconnect\".format(url=self.url))\n                if self.pooling:\n                    self._pool.closeall()\n                self._connect()\n                _logger.warning(\"Reconnected to {url}\".format(url=self.url))\n\n            n_tries_rem -= 1\n\n        else:\n\n            # N.B. Probably never reached\n            raise HGVSError(\"Permanently lost connection to {url} ({n} retries)\".format(\n                url=self.url, n=n_retries))", "response": "Returns a context manager for obtained from a single or pooled connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef project_interval_forward(self, c_interval):\n        return self.dst_tm.g_to_c(self.src_tm.c_to_g(c_interval))", "response": "project c_interval on the source transcript to the\n        destination transcript"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprojecting c_interval on the destination transcript to the source transcript", "response": "def project_interval_backward(self, c_interval):\n        \"\"\"\n        project c_interval on the destination transcript to the\n        source transcript\n\n        :param c_interval: an :class:`hgvs.interval.Interval` object on the destination transcript\n        :returns: c_interval: an :class:`hgvs.interval.Interval` object on the source transcript\n        \"\"\"\n        return self.src_tm.g_to_c(self.dst_tm.c_to_g(c_interval))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef project_variant_forward(self, c_variant):\n        if c_variant.ac != self.src_tm.tx_ac:\n            raise RuntimeError(\"variant accession does not match that used to initialize \" +\n                               __name__)\n        new_c_variant = copy.deepcopy(c_variant)\n        new_c_variant.ac = self.dst_tm.tx_ac\n        new_c_variant.posedit.pos = self.project_interval_forward(c_variant.posedit.pos)\n        return new_c_variant", "response": "project a sequencevariant onto the destination transcript"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef project_variant_backward(self, c_variant):\n        if c_variant.ac != self.dst_tm.tx_ac:\n            raise RuntimeError(\"variant accession does not match that used to initialize \" +\n                               __name__)\n        new_c_variant = copy.deepcopy(c_variant)\n        new_c_variant.ac = self.src_tm.tx_ac\n        new_c_variant.posedit.pos = self.project_interval_backward(c_variant.posedit.pos)\n        return new_c_variant", "response": "project a sequencevariant object on the source transcript onto the destination transcript"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a parsed g. variant return a n. variant on the specified transcript using the specified alignment method.", "response": "def g_to_n(self, var_g, tx_ac, alt_aln_method=hgvs.global_config.mapping.alt_aln_method):\n        \"\"\"Given a parsed g. variant, return a n. variant on the specified\n        transcript using the specified alignment method (default is\n        \"splign\" from NCBI).\n\n        :param hgvs.sequencevariant.SequenceVariant var_g: a variant object\n        :param str tx_ac: a transcript accession (e.g., NM_012345.6 or ENST012345678)\n        :param str alt_aln_method: the alignment method; valid values depend on data source\n        :returns: variant object (:class:`hgvs.sequencevariant.SequenceVariant`) using transcript (n.) coordinates\n        :raises HGVSInvalidVariantError: if var_g is not of type \"g\"\n\n        \"\"\"\n\n        if not (var_g.type == \"g\"):\n            raise HGVSInvalidVariantError(\"Expected a g. variant; got \" + str(var_g))\n        if self._validator:\n            self._validator.validate(var_g)\n        var_g.fill_ref(self.hdp)\n        tm = self._fetch_AlignmentMapper(\n            tx_ac=tx_ac, alt_ac=var_g.ac, alt_aln_method=alt_aln_method)\n        pos_n = tm.g_to_n(var_g.posedit.pos)\n        if not pos_n.uncertain:\n            edit_n = self._convert_edit_check_strand(tm.strand, var_g.posedit.edit)\n            if edit_n.type == 'ins' and pos_n.start.offset == 0 and pos_n.end.offset == 0 and pos_n.end - pos_n.start > 1:\n                pos_n.start.base += 1\n                pos_n.end.base -= 1\n                edit_n.ref = ''\n        else:\n            # variant at alignment gap\n            pos_g = tm.n_to_g(pos_n)\n            edit_n = hgvs.edit.NARefAlt(\n                ref='', alt=self._get_altered_sequence(tm.strand, pos_g, var_g))\n        pos_n.uncertain = var_g.posedit.pos.uncertain\n        var_n = hgvs.sequencevariant.SequenceVariant(\n            ac=tx_ac, type=\"n\", posedit=hgvs.posedit.PosEdit(pos_n, edit_n))\n        if self.replace_reference:\n            self._replace_reference(var_n)\n        if self.add_gene_symbol:\n            self._update_gene_symbol(var_n, var_g.gene)\n        return var_n"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a parsed g. variant return a c. variant on the specified transcript using the specified alignment method.", "response": "def g_to_c(self, var_g, tx_ac, alt_aln_method=hgvs.global_config.mapping.alt_aln_method):\n        \"\"\"Given a parsed g. variant, return a c. variant on the specified\n        transcript using the specified alignment method (default is\n        \"splign\" from NCBI).\n\n        :param hgvs.sequencevariant.SequenceVariant var_g: a variant object\n        :param str tx_ac: a transcript accession (e.g., NM_012345.6 or ENST012345678)\n        :param str alt_aln_method: the alignment method; valid values depend on data source\n        :returns: variant object (:class:`hgvs.sequencevariant.SequenceVariant`) using CDS coordinates\n        :raises HGVSInvalidVariantError: if var_g is not of type \"g\"\n\n        \"\"\"\n\n        if not (var_g.type == \"g\"):\n            raise HGVSInvalidVariantError(\"Expected a g. variant; got \" + str(var_g))\n        if self._validator:\n            self._validator.validate(var_g)\n        var_g.fill_ref(self.hdp)\n        tm = self._fetch_AlignmentMapper(\n            tx_ac=tx_ac, alt_ac=var_g.ac, alt_aln_method=alt_aln_method)\n        pos_c = tm.g_to_c(var_g.posedit.pos)\n        if not pos_c.uncertain:\n            edit_c = self._convert_edit_check_strand(tm.strand, var_g.posedit.edit)\n            if edit_c.type == 'ins' and pos_c.start.offset == 0 and pos_c.end.offset == 0 and pos_c.end - pos_c.start > 1:\n                pos_c.start.base += 1\n                pos_c.end.base -= 1\n                edit_c.ref = ''\n        else:\n            # variant at alignment gap\n            pos_g = tm.c_to_g(pos_c)\n            edit_c = hgvs.edit.NARefAlt(\n                ref='', alt=self._get_altered_sequence(tm.strand, pos_g, var_g))\n        pos_c.uncertain = var_g.posedit.pos.uncertain\n        var_c = hgvs.sequencevariant.SequenceVariant(\n            ac=tx_ac, type=\"c\", posedit=hgvs.posedit.PosEdit(pos_c, edit_c))\n        if self.replace_reference:\n            self._replace_reference(var_c)\n        if self.add_gene_symbol:\n            self._update_gene_symbol(var_c, var_g.gene)\n        return var_c"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef c_to_g(self, var_c, alt_ac, alt_aln_method=hgvs.global_config.mapping.alt_aln_method):\n\n        if not (var_c.type == \"c\"):\n            raise HGVSInvalidVariantError(\"Expected a cDNA (c.); got \" + str(var_c))\n        if self._validator:\n            self._validator.validate(var_c)\n        var_c.fill_ref(self.hdp)\n        tm = self._fetch_AlignmentMapper(\n            tx_ac=var_c.ac, alt_ac=alt_ac, alt_aln_method=alt_aln_method)\n        pos_g = tm.c_to_g(var_c.posedit.pos)\n        if not pos_g.uncertain:\n            edit_g = self._convert_edit_check_strand(tm.strand, var_c.posedit.edit)\n            if edit_g.type == 'ins' and pos_g.end - pos_g.start > 1:\n                pos_g.start.base += 1\n                pos_g.end.base -= 1\n                edit_g.ref = ''\n        else:\n            # variant at alignment gap\n            var_n = copy.deepcopy(var_c)\n            var_n.posedit.pos = tm.c_to_n(var_c.posedit.pos)\n            var_n.type = 'n'\n            pos_n = tm.g_to_n(pos_g)\n            edit_g = hgvs.edit.NARefAlt(\n                ref='', alt=self._get_altered_sequence(tm.strand, pos_n, var_n))\n        pos_g.uncertain = var_c.posedit.pos.uncertain\n        var_g = hgvs.sequencevariant.SequenceVariant(\n            ac=alt_ac, type=\"g\", posedit=hgvs.posedit.PosEdit(pos_g, edit_g))\n        if self.replace_reference:\n            self._replace_reference(var_g)\n        # intentional: no gene symbol\n        return var_g", "response": "Given a parsed c. variant return a g. variant on the specified species."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a parsed c. variant return a n. variant on the specified transcript using the specified alignment method.", "response": "def c_to_n(self, var_c):\n        \"\"\"Given a parsed c. variant, return a n. variant on the specified\n        transcript using the specified alignment method (default is\n        \"transcript\" indicating a self alignment).\n\n        :param hgvs.sequencevariant.SequenceVariant var_c: a variant object\n        :returns: variant object (:class:`hgvs.sequencevariant.SequenceVariant`)\n        :raises HGVSInvalidVariantError: if var_c is not of type \"c\"\n\n        \"\"\"\n\n        if not (var_c.type == \"c\"):\n            raise HGVSInvalidVariantError(\"Expected a cDNA (c.); got \" + str(var_c))\n        if self._validator:\n            self._validator.validate(var_c)\n        var_c.fill_ref(self.hdp)\n        tm = self._fetch_AlignmentMapper(\n            tx_ac=var_c.ac, alt_ac=var_c.ac, alt_aln_method=\"transcript\")\n        pos_n = tm.c_to_n(var_c.posedit.pos)\n        if (isinstance(var_c.posedit.edit, hgvs.edit.NARefAlt)\n                or isinstance(var_c.posedit.edit, hgvs.edit.Dup)\n                or isinstance(var_c.posedit.edit, hgvs.edit.Inv)):\n            edit_n = copy.deepcopy(var_c.posedit.edit)\n        else:\n            raise HGVSUnsupportedOperationError(\n                \"Only NARefAlt/Dup/Inv types are currently implemented\")\n        var_n = hgvs.sequencevariant.SequenceVariant(\n            ac=var_c.ac, type=\"n\", posedit=hgvs.posedit.PosEdit(pos_n, edit_n))\n        if self.replace_reference:\n            self._replace_reference(var_n)\n        if self.add_gene_symbol:\n            self._update_gene_symbol(var_n, var_c.gene)\n        return var_n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a parsed n. variant return a c. variant on the specified transcript using the specified alignment method.", "response": "def n_to_c(self, var_n):\n        \"\"\"Given a parsed n. variant, return a c. variant on the specified\n        transcript using the specified alignment method (default is\n        \"transcript\" indicating a self alignment).\n\n        :param hgvs.sequencevariant.SequenceVariant var_n: a variant object\n        :returns: variant object (:class:`hgvs.sequencevariant.SequenceVariant`)\n        :raises HGVSInvalidVariantError: if var_n is not of type \"n\"\n\n        \"\"\"\n\n        if not (var_n.type == \"n\"):\n            raise HGVSInvalidVariantError(\"Expected n. variant; got \" + str(var_n))\n        if self._validator:\n            self._validator.validate(var_n)\n        var_n.fill_ref(self.hdp)\n        tm = self._fetch_AlignmentMapper(\n            tx_ac=var_n.ac, alt_ac=var_n.ac, alt_aln_method=\"transcript\")\n        pos_c = tm.n_to_c(var_n.posedit.pos)\n        if (isinstance(var_n.posedit.edit, hgvs.edit.NARefAlt)\n                or isinstance(var_n.posedit.edit, hgvs.edit.Dup)\n                or isinstance(var_n.posedit.edit, hgvs.edit.Inv)):\n            edit_c = copy.deepcopy(var_n.posedit.edit)\n        else:\n            raise HGVSUnsupportedOperationError(\n                \"Only NARefAlt/Dup/Inv types are currently implemented\")\n        var_c = hgvs.sequencevariant.SequenceVariant(\n            ac=var_n.ac, type=\"c\", posedit=hgvs.posedit.PosEdit(pos_c, edit_c))\n        if self.replace_reference:\n            self._replace_reference(var_c)\n        if self.add_gene_symbol:\n            self._update_gene_symbol(var_c, var_n.gene)\n        return var_c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a c. SequenceVariant to a p. SequenceVariant on the specified protein accession.", "response": "def c_to_p(self, var_c, pro_ac=None):\n        \"\"\"\n        Converts a c. SequenceVariant to a p. SequenceVariant on the specified protein accession\n        Author: Rudy Rico\n\n        :param SequenceVariant var_c: hgvsc tag\n        :param str pro_ac: protein accession\n        :rtype: hgvs.sequencevariant.SequenceVariant\n\n        \"\"\"\n\n        if not (var_c.type == \"c\"):\n            raise HGVSInvalidVariantError(\"Expected a cDNA (c.) variant; got \" + str(var_c))\n        if self._validator:\n            self._validator.validate(var_c)\n        reference_data = RefTranscriptData(self.hdp, var_c.ac, pro_ac)\n        builder = altseqbuilder.AltSeqBuilder(var_c, reference_data)\n\n        # TODO: handle case where you get 2+ alt sequences back;\n        # currently get list of 1 element loop structure implemented\n        # to handle this, but doesn't really do anything currently.\n        all_alt_data = builder.build_altseq()\n\n        var_ps = []\n        for alt_data in all_alt_data:\n            builder = altseq_to_hgvsp.AltSeqToHgvsp(reference_data, alt_data)\n            var_p = builder.build_hgvsp()\n            var_ps.append(var_p)\n\n        var_p = var_ps[0]\n\n        if self.add_gene_symbol:\n            self._update_gene_symbol(var_p, var_c.gene)\n\n        return var_p"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches reference sequence for a variant and update it if necessary", "response": "def _replace_reference(self, var):\n        \"\"\"fetch reference sequence for variant and update (in-place) if necessary\"\"\"\n\n        if var.type not in \"cgmnr\":\n            raise HGVSUnsupportedOperationError(\"Can only update references for type c, g, m, n, r\")\n\n        if var.posedit.edit.type == \"ins\":\n            # insertions have no reference sequence (zero-width), so return as-is\n            return var\n        if var.posedit.edit.type == \"con\":\n            # conversions have no reference sequence (zero-width), so return as-is\n            return var\n\n        pos = var.posedit.pos\n        if ((isinstance(pos.start, hgvs.location.BaseOffsetPosition) and pos.start.offset != 0)\n                or (isinstance(pos.end, hgvs.location.BaseOffsetPosition) and pos.end.offset != 0)):\n            _logger.info(\"Can't update reference sequence for intronic variant {}\".format(var))\n            return var\n\n        # For c. variants, we need coords on underlying sequences\n        if var.type == \"c\":\n            tm = self._fetch_AlignmentMapper(\n                tx_ac=var.ac, alt_ac=var.ac, alt_aln_method=\"transcript\")\n            pos = tm.c_to_n(var.posedit.pos)\n        else:\n            pos = var.posedit.pos\n        seq = self.hdp.get_seq(var.ac, pos.start.base - 1, pos.end.base)\n\n        edit = var.posedit.edit\n        if edit.ref != seq:\n            _logger.debug(\"Replaced reference sequence in {var} with {seq}\".format(\n                var=var, seq=seq))\n            edit.ref = seq\n\n        return var"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch an alignment mapper for the given transcript accession.", "response": "def _fetch_AlignmentMapper(self, tx_ac, alt_ac, alt_aln_method):\n        \"\"\"\n        Get a new AlignmentMapper for the given transcript accession (ac),\n        possibly caching the result.\n        \"\"\"\n        return hgvs.alignmentmapper.AlignmentMapper(\n            self.hdp, tx_ac=tx_ac, alt_ac=alt_ac, alt_aln_method=alt_aln_method)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _convert_edit_check_strand(strand, edit_in):\n        if isinstance(edit_in, hgvs.edit.NARefAlt):\n            if strand == 1:\n                edit_out = copy.deepcopy(edit_in)\n            else:\n                try:\n                    # if smells like an int, do nothing\n                    # TODO: should use ref_n, right?\n                    int(edit_in.ref)\n                    ref = edit_in.ref\n                except (ValueError, TypeError):\n                    ref = reverse_complement(edit_in.ref)\n                edit_out = hgvs.edit.NARefAlt(\n                    ref=ref,\n                    alt=reverse_complement(edit_in.alt),\n                )\n        elif isinstance(edit_in, hgvs.edit.Dup):\n            if strand == 1:\n                edit_out = copy.deepcopy(edit_in)\n            else:\n                edit_out = hgvs.edit.Dup(ref=reverse_complement(edit_in.ref))\n        elif isinstance(edit_in, hgvs.edit.Inv):\n            if strand == 1:\n                edit_out = copy.deepcopy(edit_in)\n            else:\n                try:\n                    int(edit_in.ref)\n                    ref = edit_in.ref\n                except (ValueError, TypeError):\n                    ref = reverse_complement(edit_in.ref)\n                edit_out = hgvs.edit.Inv(ref=ref)\n        else:\n            raise NotImplementedError(\"Only NARefAlt/Dup/Inv types are currently implemented\")\n        return edit_out", "response": "Convert an edit from one type to another based on the stand and type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef t_to_p(self, var_t):\n        if var_t.type == \"n\":\n            return \"non-coding\"\n        if var_t.type == \"c\":\n            return self.c_to_p(var_t)\n        raise HGVSInvalidVariantError(\"Expected a coding (c.) or non-coding (n.) variant; got \" +\n                                      str(var_t))", "response": "Return a protein variant or non - coding for non - coding variants."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of transcripts accessions for given variant", "response": "def relevant_transcripts(self, var_g):\n        \"\"\"return list of transcripts accessions (strings) for given variant,\n        selected by genomic overlap\"\"\"\n        tx = self.hdp.get_tx_for_region(var_g.ac, self.alt_aln_method, var_g.posedit.pos.start.base,\n                                        var_g.posedit.pos.end.base)\n        return [e[\"tx_ac\"] for e in tx]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _alt_ac_for_tx_ac(self, tx_ac):\n        alt_acs = [\n            e[\"alt_ac\"] for e in self.hdp.get_tx_mapping_options(tx_ac) if\n            e[\"alt_aln_method\"] == self.alt_aln_method and e[\"alt_ac\"] in self._assembly_accessions\n        ]\n\n        if not alt_acs:\n            raise HGVSDataNotAvailableError(\"No alignments for {tx_ac} in {an} using {am}\".format(\n                tx_ac=tx_ac, an=self.assembly_name, am=self.alt_aln_method))\n\n        # TODO: conditional is unnecessary; remove\n        if len(alt_acs) > 1:\n            names = set(self._assembly_map[ac] for ac in alt_acs)\n            if names != set(\"XY\"):\n                alts = \", \".join(\n                    [\"{ac} ({n})\".format(ac=ac, n=self._assembly_map[ac]) for ac in alt_acs])\n                raise HGVSError(\"Multiple chromosomal alignments for {tx_ac} in {an}\"\n                                \" using {am} (non-pseudoautosomal region) [{alts}]\".format(\n                                    tx_ac=tx_ac,\n                                    an=self.assembly_name,\n                                    am=self.alt_aln_method,\n                                    alts=alts))\n\n            # assume PAR\n            if self.in_par_assume is None:\n                raise HGVSError(\"Multiple chromosomal alignments for {tx_ac} in {an}\"\n                                \" using {am} (likely pseudoautosomal region)\".format(\n                                    tx_ac=tx_ac, an=self.assembly_name, am=self.alt_aln_method))\n\n            alt_acs = [ac for ac in alt_acs if self._assembly_map[ac] == self.in_par_assume]\n            if len(alt_acs) != 1:\n                raise HGVSError(\"Multiple chromosomal alignments for {tx_ac} in {an}\"\n                                \" using {am}; in_par_assume={ipa} selected {n} of them\".format(\n                                    tx_ac=tx_ac,\n                                    an=self.assembly_name,\n                                    am=self.alt_aln_method,\n                                    ipa=self.in_par_assume,\n                                    n=len(alt_acs)))\n\n        assert len(alt_acs) == 1, \"Should have exactly one alignment at this point\"\n        return alt_acs[0]", "response": "return the chromosomal accession for given transcript accession"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fetch_AlignmentMapper(self, tx_ac, alt_ac=None, alt_aln_method=None):\n\n        if alt_ac is None:\n            alt_ac = self._alt_ac_for_tx_ac(tx_ac)\n        if alt_aln_method is None:\n            alt_aln_method = self.alt_aln_method\n        return super(AssemblyMapper, self)._fetch_AlignmentMapper(tx_ac, alt_ac, alt_aln_method)", "response": "convenience version of VariantMapper. _fetch_AlignmentMapper that derives alt_ac from transcript assembly and alt_aln_method\n        used to instantiate the AssemblyMapper instance that is derived from alt_ac_for_tx_ac and alt_aln_method\n       ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes the variant if requested and ignore HGVSUnsupportedOperationError", "response": "def _maybe_normalize(self, var):\n        \"\"\"normalize variant if requested, and ignore HGVSUnsupportedOperationError\n        This is better than checking whether the variant is intronic because\n        future UTAs will support LRG, which will enable checking intronic variants.\n        \"\"\"\n        if self.normalize:\n            try:\n                return self._norm.normalize(var)\n            except HGVSUnsupportedOperationError as e:\n                _logger.warning(str(e) + \"; returning unnormalized variant\")\n                # fall through to return unnormalized variant\n        return var"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hgvs_to_vcf(self, var_g):\n\n        if var_g.type != \"g\":\n            raise RuntimeError(\"Expected g. variant, got {var_g}\".format(var_g=var_g))\n\n        vleft = self.hn.normalize(var_g)\n\n        (start_i, end_i) = _as_interbase(vleft.posedit)\n\n        chr = self.ac_to_chr_name_map[vleft.ac]\n\n        typ = vleft.posedit.edit.type\n\n        if typ == \"dup\":\n            start_i -= 1\n            alt = self.hdp.seqfetcher.fetch_seq(vleft.ac, start_i, end_i)\n            ref = alt[0]\n            end_i = start_i\n            return (chr, start_i + 1, ref, alt, typ)\n\n        if vleft.posedit.edit.ref == vleft.posedit.edit.alt:\n            return None\n\n        alt = vleft.posedit.edit.alt or \"\"\n\n        if end_i - start_i == 1 and vleft.posedit.length_change == 0:\n            # SNVs aren't left anchored\n            ref = vleft.posedit.edit.ref\n\n        else:\n            # everything else is left-anchored\n            start_i -= 1\n            ref = self.hdp.seqfetcher.fetch_seq(vleft.ac, start_i, end_i)\n            alt = ref[0] + alt\n\n        return (chr, start_i + 1, ref, alt, typ)", "response": "converts a single hgvs allele to a single VCF"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_cigar(self, cigar):\n        ces = [m.groupdict() for m in cigar_re.finditer(cigar)]\n        ref_pos = [None] * len(ces)\n        tgt_pos = [None] * len(ces)\n        cigar_op = [None] * len(ces)\n        ref_cur = tgt_cur = 0\n        for i, ce in enumerate(ces):\n            ref_pos[i] = ref_cur\n            tgt_pos[i] = tgt_cur\n            cigar_op[i] = ce[\"op\"]\n            step = int(ce[\"len\"])\n            if ce[\"op\"] in \"=MINX\":\n                ref_cur += step\n            if ce[\"op\"] in \"=MDX\":\n                tgt_cur += step\n        ref_pos.append(ref_cur)\n        tgt_pos.append(tgt_cur)\n        return ref_pos, tgt_pos, cigar_op", "response": "Parse a CIGAR string and return the start positions of the ref and tgt segments and a list of CIGAR operators."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _map(self, from_pos, to_pos, pos, base):\n        pos_i = -1\n        while pos_i < len(self.cigar_op) and pos >= from_pos[pos_i + 1]:\n            pos_i += 1\n\n        if pos_i == -1 or pos_i == len(self.cigar_op):\n            raise HGVSInvalidIntervalError(\"Position is beyond the bounds of transcript record\")\n\n        if self.cigar_op[pos_i] in \"=MX\":\n            mapped_pos = to_pos[pos_i] + (pos - from_pos[pos_i])\n            mapped_pos_offset = 0\n        elif self.cigar_op[pos_i] in \"DI\":\n            if base == \"start\":\n                mapped_pos = to_pos[pos_i] - 1\n            elif base == \"end\":\n                mapped_pos = to_pos[pos_i]\n            mapped_pos_offset = 0\n        elif self.cigar_op[pos_i] == \"N\":\n            if pos - from_pos[pos_i] + 1 <= from_pos[pos_i + 1] - pos:\n                mapped_pos = to_pos[pos_i] - 1\n                mapped_pos_offset = pos - from_pos[pos_i] + 1\n            else:\n                mapped_pos = to_pos[pos_i]\n                mapped_pos_offset = -(from_pos[pos_i + 1] - pos)\n\n        return mapped_pos, mapped_pos_offset, self.cigar_op[pos_i]", "response": "Map position between aligned sequences."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef g_to_n(self, g_interval):\n\n        grs, gre = g_interval.start.base - 1 - self.gc_offset, g_interval.end.base - 1 - self.gc_offset\n        # frs, fre = (f)orward (r)na (s)tart & (e)nd; forward w.r.t. genome\n        frs, frs_offset, frs_cigar = self._map(\n            from_pos=self.ref_pos, to_pos=self.tgt_pos, pos=grs, base=\"start\")\n        fre, fre_offset, fre_cigar = self._map(\n            from_pos=self.ref_pos, to_pos=self.tgt_pos, pos=gre, base=\"end\")\n\n        if self.strand == -1:\n            frs, fre = self.tgt_len - fre - 1, self.tgt_len - frs - 1\n            frs_offset, fre_offset = -fre_offset, -frs_offset\n\n        # The returned interval would be uncertain when locating at alignment gaps\n        return hgvs.location.BaseOffsetInterval(\n            start=hgvs.location.BaseOffsetPosition(\n                base=frs + 1, offset=frs_offset, datum=Datum.SEQ_START),\n            end=hgvs.location.BaseOffsetPosition(\n                base=fre + 1, offset=fre_offset, datum=Datum.SEQ_START),\n            uncertain=frs_cigar in 'DI' or fre_cigar in 'DI')", "response": "convert a genomic interval to a transcript cDNA interval"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef n_to_g(self, n_interval):\n\n        frs, fre = n_interval.start.base - 1, n_interval.end.base - 1\n        start_offset, end_offset = n_interval.start.offset, n_interval.end.offset\n\n        if self.strand == -1:\n            fre, frs = self.tgt_len - frs - 1, self.tgt_len - fre - 1\n            start_offset, end_offset = -end_offset, -start_offset\n\n        # returns the genomic range start (grs) and end (gre)\n        grs, _, grs_cigar = self._map(\n            from_pos=self.tgt_pos, to_pos=self.ref_pos, pos=frs, base=\"start\")\n        gre, _, gre_cigar = self._map(\n            from_pos=self.tgt_pos, to_pos=self.ref_pos, pos=fre, base=\"end\")\n        grs, gre = grs + self.gc_offset + 1, gre + self.gc_offset + 1\n        gs, ge = grs + start_offset, gre + end_offset\n\n        # The returned interval would be uncertain when locating at alignment gaps\n        return hgvs.location.Interval(\n            start=hgvs.location.SimplePosition(gs, uncertain=n_interval.start.uncertain),\n            end=hgvs.location.SimplePosition(ge, uncertain=n_interval.end.uncertain),\n            uncertain=grs_cigar in 'DI' or gre_cigar in 'DI')", "response": "convert a transcript n. interval to a genomic interval"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef c_to_n(self, c_interval):\n\n        if self.cds_start_i is None:    # cds_start_i defined iff cds_end_i defined; see assertion above\n            raise HGVSUsageError(\n                \"CDS is undefined for {self.tx_ac}; cannot map from c. coordinate (non-coding transcript?)\"\n                .format(self=self))\n\n        # start\n        if c_interval.start.datum == Datum.CDS_START and c_interval.start.base < 0:\n            r_start = c_interval.start.base + self.cds_start_i + 1\n        elif c_interval.start.datum == Datum.CDS_START and c_interval.start.base > 0:\n            r_start = c_interval.start.base + self.cds_start_i\n        elif c_interval.start.datum == Datum.CDS_END:\n            r_start = c_interval.start.base + self.cds_end_i\n        # end\n        if c_interval.end.datum == Datum.CDS_START and c_interval.end.base < 0:\n            r_end = c_interval.end.base + self.cds_start_i + 1\n        elif c_interval.end.datum == Datum.CDS_START and c_interval.end.base > 0:\n            r_end = c_interval.end.base + self.cds_start_i\n        elif c_interval.end.datum == Datum.CDS_END:\n            r_end = c_interval.end.base + self.cds_end_i\n\n        if r_start <= 0 or r_end > self.tgt_len:\n            raise HGVSInvalidIntervalError(\n                \"The given coordinate is outside the bounds of the reference sequence.\")\n\n        n_interval = hgvs.location.BaseOffsetInterval(\n            start=hgvs.location.BaseOffsetPosition(\n                base=r_start, offset=c_interval.start.offset, datum=Datum.SEQ_START),\n            end=hgvs.location.BaseOffsetPosition(\n                base=r_end, offset=c_interval.end.offset, datum=Datum.SEQ_START),\n            uncertain=c_interval.uncertain)\n        return n_interval", "response": "convert a transcript CDS interval to a transcript cDNA interval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a single CIGAR string representing an alignment of the input transcript sequence to a reference sequence including introns.", "response": "def build_tx_cigar(exons, strand):\n    \"\"\"builds a single CIGAR string representing an alignment of the\n    transcript sequence to a reference sequence, including introns.\n    The input exons are expected to be in transcript order, and the\n    resulting CIGAR is also in transcript order. \n\n    >>> build_tx_cigar([], 1) is None\n    True\n    \"\"\"\n    cigarelem_re = re.compile(r\"\\d+[=DIMNX]\")\n\n    def _reverse_cigar(c):\n        return ''.join(reversed(cigarelem_re.findall(c)))\n\n    if len(exons) == 0:\n        return None\n\n    # flip orientation of all CIGARs if on - strand\n    if strand == -1:\n        cigars = [_reverse_cigar(e[\"cigar\"]) for e in exons]\n    else:\n        cigars = [e[\"cigar\"] for e in exons]\n\n    tx_cigar = [cigars[0]]    # exon 1\n    for i in range(1, len(cigars)):    # and intron + exon pairs thereafter\n        intron = str(exons[i][\"alt_start_i\"] - exons[i - 1][\"alt_end_i\"]) + \"N\"\n        tx_cigar += [intron, cigars[i]]\n\n    tx_cigar_str = \"\".join(tx_cigar)\n\n    return tx_cigar_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding an hgvs tag from the output amino acid sequences.", "response": "def build_hgvsp(self):\n        \"\"\"Compare two amino acid sequences; generate an hgvs tag from the output\n\n        :return list of variants in sequence order\n        :rtype list of dict\n        \"\"\"\n\n        variants = []\n\n        if not self._is_ambiguous and len(self._alt_seq) > 0:\n\n            do_delins = True\n            if self._ref_seq == self._alt_seq:\n                # Silent p. variant\n                start = self._alt_data.variant_start_aa\n                if start - 1 < len(self._ref_seq):\n                    deletion = self._ref_seq[start - 1]\n                    insertion = deletion\n                else:\n                    start = \"\"\n                    deletion = \"\"\n                    insertion = \"\"\n                    self._is_frameshift = False\n                variants.append({\"start\": start, \"ins\": insertion, \"del\": deletion})\n                do_delins = False\n            elif self._is_substitution:\n                if len(self._ref_seq) == len(self._alt_seq):\n                    diff_pos = [(i, self._ref_seq[i], self._alt_seq[i])\n                                for i in range(len(self._ref_seq))\n                                if self._ref_seq[i] != self._alt_seq[i]]\n                    if len(diff_pos) == 1:\n                        (start, deletion, insertion) = diff_pos[0]\n                        variants.append({\"start\": start + 1, \"ins\": insertion, \"del\": deletion})\n                        do_delins = False\n\n            if do_delins:\n                if self._alt_data.is_frameshift:\n                    start = self._alt_data.variant_start_aa - 1\n                    while self._ref_seq[start] == self._alt_seq[start]:\n                        start += 1\n                    insertion = list(self._alt_seq[start:])\n                    deletion = list(self._ref_seq[start:])\n                    variants.append({\"start\": start + 1, \"ins\": insertion, \"del\": deletion})\n\n                else:    # non-frameshifting delins or dup\n                    # get size diff from diff in ref/alt lengths\n                    start = self._alt_data.variant_start_aa - 1\n                    delta = len(self._alt_seq) - len(self._ref_seq)\n                    while self._ref_seq[start] == self._alt_seq[start]:\n                        start += 1\n                    offset = start + abs(delta)\n\n                    if delta > 0:    # net insertion\n                        insertion = list(self._alt_seq[start:offset])\n                        deletion = []\n                        ref_sub = self._ref_seq[start:]\n                        alt_sub = self._alt_seq[offset:]\n                    elif delta < 0:    # net deletion\n                        insertion = []\n                        deletion = list(self._ref_seq[start:offset])\n                        ref_sub = self._ref_seq[offset:]\n                        alt_sub = self._alt_seq[start:]\n                    else:\n                        insertion = []\n                        deletion = []\n                        ref_sub = self._ref_seq[start:]\n                        alt_sub = self._alt_seq[start:]\n\n                    # from start, get del/ins out to last difference\n                    diff_indices = [i for i in range(len(ref_sub)) if ref_sub[i] != alt_sub[i]]\n                    if not diff_indices and not deletion and insertion[0] == '*':\n                        diff_indices.append(0)\n                    if diff_indices:\n                        max_diff = diff_indices[-1] + 1\n                        insertion.extend(list(alt_sub[:max_diff]))\n                        deletion.extend(list(ref_sub[:max_diff]))\n\n                    variants.append({\"start\": start + 1, \"ins\": insertion, \"del\": deletion})\n\n            if DBG:\n                print(variants)\n\n        if self._is_ambiguous:\n            var_ps = [\n                self._create_variant(\n                    None,\n                    None,\n                    '',\n                    '',\n                    acc=self._protein_accession,\n                    is_ambiguous=self._is_ambiguous)\n            ]\n        elif len(self._alt_seq) == 0:\n            var_ps = [\n                self._create_variant(\n                    None,\n                    None,\n                    '',\n                    '',\n                    acc=self._protein_accession,\n                    is_ambiguous=self._is_ambiguous,\n                    is_no_protein=True)\n            ]\n        else:\n            var_ps = [\n                self._convert_to_sequence_variants(x, self._protein_accession) for x in variants\n            ]\n\n        if len(var_ps) > 1:\n            raise HGVSError(\"Got multiple AA variants - not supported\")\n        return var_ps[0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a single AA variant to an hgvs representation.", "response": "def _convert_to_sequence_variants(self, variant, acc):\n        \"\"\"Convert AA variant to an hgvs representation\n\n        :param variant: contains start, del, and ins\n        :type variant: dict\n        :param acc: protein accession\n        :type acc: str\n        :return hgvs string\n        :rtype str\n        \"\"\"\n        start = variant['start']\n        insertion = ''.join(variant['ins'])\n        deletion = ''.join(variant['del'])\n\n        # defaults\n        is_dup = False    # assume not dup\n        fsext_len = None    # fs or ext length\n        is_sub = False\n        is_ext = False\n\n        if start == 1:    # initial methionine is modified\n            aa_start = aa_end = AAPosition(base=start, aa=deletion)\n            ref = ''\n            alt = ''\n            self._is_init_met = True\n            self._is_ambiguous = True    # side-effect\n\n        if insertion and insertion.find(\"*\") == 0:    # stop codon at variant position\n            aa_start = aa_end = AAPosition(base=start, aa=deletion[0])\n            ref = ''\n            alt = '*'\n            is_sub = True\n\n        elif start == len(self._ref_seq):    # extension\n            if self._alt_seq[-1] == '*':\n                fsext_len = len(insertion) - len(deletion)    # don't include the former stop codon\n            else:\n                fsext_len = '?'\n            subst_at_stop_codon = insertion[0]\n\n            aa_start = aa_end = AAPosition(base=start, aa='*')\n            ref = ''\n            alt = subst_at_stop_codon\n            is_ext = True\n\n        elif self._is_frameshift:    # frameshift\n            aa_start = aa_end = AAPosition(base=start, aa=deletion[0])\n            ref = ''\n\n            try:\n                fsext_len = str(\n                    insertion.index(\"*\") + 1)    # start w/ 1st change; ends w/ * (inclusive)\n            except ValueError:\n                fsext_len = \"?\"\n\n            alt = insertion[0]\n\n        else:    # no frameshift - sub/delins/dup\n            if insertion == deletion:    # silent\n                aa_start = aa_end = AAPosition(base=start, aa=deletion)\n                ref = alt = ''\n\n            elif len(insertion) == len(deletion) == 1:    # substitution\n                aa_start = aa_end = AAPosition(base=start, aa=deletion)\n                ref = ''\n                alt = insertion\n                is_sub = True\n\n            elif len(deletion) > 0:    # delins OR deletion OR stop codon at variant position\n                ref = deletion\n                end = start + len(deletion) - 1\n                if len(insertion) > 0:    # delins\n                    aa_start = AAPosition(base=start, aa=deletion[0])\n                    if end > start:\n                        aa_end = AAPosition(base=end, aa=deletion[-1])\n                    else:\n                        aa_end = aa_start\n                    alt = insertion\n\n                else:    # deletion OR stop codon at variant position\n                    if len(deletion) + start == len(\n                            self._ref_seq):    # stop codon at variant position\n                        aa_start = AAPosition(base=start, aa=deletion[0])\n                        aa_end = AAPosition(base=start, aa=deletion[0])\n                        ref = ''\n                        alt = '*'\n                        is_sub = True\n                    else:    # deletion\n                        aa_start = AAPosition(base=start, aa=deletion[0])\n                        if end > start:\n                            aa_end = AAPosition(base=end, aa=deletion[-1])\n                        else:\n                            aa_end = aa_start\n                        alt = None\n\n            elif len(deletion) == 0:    # insertion OR duplication OR extension\n\n                is_dup, dup_start = self._check_if_ins_is_dup(start, insertion)\n\n                if is_dup:    # duplication\n                    dup_end = dup_start + len(insertion) - 1\n                    aa_start = AAPosition(base=dup_start, aa=insertion[0])\n                    aa_end = AAPosition(base=dup_end, aa=insertion[-1])\n                    ref = alt = None\n\n                else:    # insertion\n                    start -= 1\n                    end = start + 1\n\n                    aa_start = AAPosition(base=start, aa=self._ref_seq[start - 1])\n                    aa_end = AAPosition(base=end, aa=self._ref_seq[end - 1])\n                    ref = None\n                    alt = insertion\n\n            else:    # should never get here\n                raise ValueError(\"unexpected variant: {}\".format(variant))\n\n        var_p = self._create_variant(\n            aa_start,\n            aa_end,\n            ref,\n            alt,\n            fsext_len=fsext_len,\n            is_dup=is_dup,\n            acc=acc,\n            is_ambiguous=self._is_ambiguous,\n            is_sub=is_sub,\n            is_ext=is_ext,\n            is_init_met=self._is_init_met\n        )\n\n        return var_p"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a SequenceVariant object based on the parameters.", "response": "def _create_variant(self,\n                        start,\n                        end,\n                        ref,\n                        alt,\n                        fsext_len=None,\n                        is_dup=False,\n                        acc=None,\n                        is_ambiguous=False,\n                        is_sub=False,\n                        is_ext=False,\n                        is_no_protein=False,\n                        is_init_met=False):\n        \"\"\"Creates a SequenceVariant object\"\"\"\n\n        if is_init_met:\n            posedit = AARefAlt(ref=ref, alt=alt, init_met=True)\n        elif is_ambiguous:\n            posedit = None\n        else:\n            interval = Interval(start=start, end=end)\n            # Note - order matters\n            if is_no_protein:\n                edit = '0'\n            elif is_sub:\n                edit = AASub(ref=ref, alt=alt)\n            elif is_ext:\n                edit = AAExt(ref=ref, alt=alt, aaterm='*', length=fsext_len)\n            elif self._is_frameshift:\n                edit = AAFs(ref=ref, alt=alt, length=fsext_len)\n            elif is_dup:\n                edit = Dup()\n            elif ref == alt == '':\n                edit = AARefAlt(ref='', alt='')\n            else:\n                edit = AARefAlt(ref=ref, alt=alt)\n            posedit = PosEdit(\n                pos=interval,\n                edit=edit,\n                uncertain=hgvs.global_config.mapping.inferred_p_is_uncertain)\n        var_p = hgvs.sequencevariant.SequenceVariant(acc, 'p', posedit)\n        return var_p"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a continuous interbase and discontinuous HGVS coordinates to a single HGVS coordinate.", "response": "def _ci_to_hgvs_coord(s, e):\n    \"\"\" Convert continuous interbase (right-open) coordinates (..,-2,-1,0,1,..) to\n    discontinuous HGVS coordinates (..,-2,-1,1,2,..)\n    \"\"\"\n\n    def _ci_to_hgvs(c):\n        return c + 1 if c >= 0 else c\n\n    return (None if s is None else _ci_to_hgvs(s), None if e is None else _ci_to_hgvs(e) - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _hgvs_coord_to_ci(s, e):\n\n    def _hgvs_to_ci(c):\n        assert c != 0, \"received CDS coordinate 0; expected ..,-2,-1,1,1,...\"\n        return c - 1 if c > 0 else c\n\n    return (None if s is None else _hgvs_to_ci(s), None if e is None else _hgvs_to_ci(e) + 1)", "response": "convert start end interval in inclusive discontinuous HGVS coordinates to continuous interbase"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef g_to_n(self, g_interval):\n\n        # This code is extremely convoluted. To begin with, it\n        # confuses interbase intervals for a *single* hgvs position\n        # with intervals of *two* hgvs positions.  This is the origin\n        # of bug #205 (now closed). Although the bug is itself fixed,\n        # the mappers really need an overhaul. See #208.\n\n        def _hgvs_offset(g_position, grs, gre, strand):\n            \"\"\" Calculates the HGVS coordinate offset from a given genomic position\"\"\"\n            if g_position == grs or g_position == gre:\n                return 0\n            mid = (grs + gre) / 2\n            if g_position < mid or (g_position == mid and strand == 1):\n                offset = g_position - grs\n            else:\n                offset = g_position - gre\n            return offset\n\n        def map_g_to_n_pos(pos):\n            g_ci = _hgvs_coord_to_ci(pos, pos)\n            # frs, fre = (f)orward (r)na (s)tart & (e)nd; forward w.r.t. genome\n            frs, fre = self.im.map_ref_to_tgt(\n                g_ci[0] - self.gc_offset, g_ci[1] - self.gc_offset, max_extent=False)\n            if self.strand == -1:\n                frs, fre = self.tgt_len - fre, self.tgt_len - frs\n            # get BaseOffsetPosition information for n.\n            if self.strand == 1:\n                grs, gre = self.im.map_tgt_to_ref(frs, fre, max_extent=False)\n            elif self.strand == -1:\n                grs, gre = self.im.map_tgt_to_ref((self.tgt_len - fre), (self.tgt_len - frs),\n                                                  max_extent=False)\n            grs, gre = grs + self.gc_offset, gre + self.gc_offset\n            # 0-width interval indicates an intron.  Need to calculate offsets but we\"re are in ci coordinates\n            # requires adding 1 strategically to get the HGVS position\n            # (shift coordinates to 3' end of the ref nucleotide)\n\n            if frs == fre:\n                start_offset = _hgvs_offset(g_ci[0] + 1, grs, gre + 1, self.strand)\n                end_offset = _hgvs_offset(g_ci[1], grs, gre + 1, self.strand)\n            else:\n                start_offset = _hgvs_offset(g_ci[0], grs, gre, self.strand)\n                end_offset = _hgvs_offset(g_ci[1], grs, gre, self.strand)\n            if self.strand == -1:\n                start_offset, end_offset = self.strand * end_offset, self.strand * start_offset\n            if start_offset > 0:\n                frs -= 1\n            if end_offset < 0:\n                fre += 1\n            start_base = _ci_to_hgvs_coord(frs, fre)[0]\n            end_base = _ci_to_hgvs_coord(frs, fre)[1]\n            return start_base, start_offset, end_base, end_offset\n\n        start_bo = map_g_to_n_pos(g_interval.start.base)[0:2]\n        end_bo = start_bo if g_interval.start.base == g_interval.end.base else map_g_to_n_pos(\n            g_interval.end.base)[2:4]\n        if self.strand == -1:\n            start_bo, end_bo = end_bo, start_bo\n\n        return hgvs.location.BaseOffsetInterval(\n            start=hgvs.location.BaseOffsetPosition(\n                base=start_bo[0], offset=start_bo[1], datum=Datum.SEQ_START),\n            end=hgvs.location.BaseOffsetPosition(\n                base=end_bo[0], offset=end_bo[1], datum=Datum.SEQ_START),\n            uncertain=g_interval.uncertain)", "response": "convert a genomic interval to a transcript cDNA interval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a transcript cDNA interval to a genomic interval", "response": "def n_to_g(self, n_interval):\n        \"\"\"convert a transcript cDNA (n.) interval to a genomic (g.) interval\"\"\"\n\n        assert self.strand in [1, -1], \"strand = \" + str(self.strand) + \"; must be 1 or -1\"\n\n        if self.strand == 1:\n            frs, fre = _hgvs_coord_to_ci(n_interval.start.base, n_interval.end.base)\n            start_offset, end_offset = n_interval.start.offset, n_interval.end.offset\n        elif self.strand == -1:\n            frs, fre = _hgvs_coord_to_ci(n_interval.start.base, n_interval.end.base)\n            fre, frs = self.tgt_len - frs, self.tgt_len - fre\n            start_offset, end_offset = self.strand * n_interval.end.offset, self.strand * n_interval.start.offset\n\n        # returns the genomic range start (grs) and end (gre)\n        grs, gre = self.im.map_tgt_to_ref(frs, fre, max_extent=False)\n        grs, gre = grs + self.gc_offset, gre + self.gc_offset\n        gs, ge = grs + start_offset, gre + end_offset\n        return hgvs.location.Interval(\n            start=hgvs.location.SimplePosition(\n                _ci_to_hgvs_coord(gs, ge)[0], uncertain=n_interval.start.uncertain),\n            end=hgvs.location.SimplePosition(\n                _ci_to_hgvs_coord(gs, ge)[1], uncertain=n_interval.end.uncertain),\n            uncertain=n_interval.uncertain)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a n. interval to a transcript CDS ( n. interval", "response": "def n_to_c(self, n_interval):\n        \"\"\"convert a transcript cDNA (n.) interval to a transcript CDS (c.) interval\"\"\"\n\n        if self.cds_start_i is None:    # cds_start_i defined iff cds_end_i defined; see assertion above\n            raise HGVSUsageError(\n                \"CDS is undefined for {self.tx_ac}; cannot map to c. coordinate (non-coding transcript?)\"\n                .format(self=self))\n        if n_interval.start.base <= 0 or n_interval.end.base > self.tgt_len:\n            raise HGVSError(\"The given coordinate is outside the bounds of the reference sequence.\")\n\n        # start\n        if n_interval.start.base <= self.cds_start_i:\n            cs = n_interval.start.base - (self.cds_start_i + 1)\n            cs_datum = Datum.CDS_START\n        elif n_interval.start.base > self.cds_start_i and n_interval.start.base <= self.cds_end_i:\n            cs = n_interval.start.base - self.cds_start_i\n            cs_datum = Datum.CDS_START\n        else:\n            cs = n_interval.start.base - self.cds_end_i\n            cs_datum = Datum.CDS_END\n        # end\n        if n_interval.end.base <= self.cds_start_i:\n            ce = n_interval.end.base - (self.cds_start_i + 1)\n            ce_datum = Datum.CDS_START\n        elif n_interval.end.base > self.cds_start_i and n_interval.end.base <= self.cds_end_i:\n            ce = n_interval.end.base - self.cds_start_i\n            ce_datum = Datum.CDS_START\n        else:\n            ce = n_interval.end.base - self.cds_end_i\n            ce_datum = Datum.CDS_END\n\n        c_interval = hgvs.location.BaseOffsetInterval(\n            start=hgvs.location.BaseOffsetPosition(\n                base=cs, offset=n_interval.start.offset, datum=cs_datum),\n            end=hgvs.location.BaseOffsetPosition(\n                base=ce, offset=n_interval.end.offset, datum=ce_datum),\n            uncertain=n_interval.uncertain)\n        return c_interval"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef c_to_n(self, c_interval):\n\n        if self.cds_start_i is None:    # cds_start_i defined iff cds_end_i defined; see assertion above\n            raise HGVSUsageError(\n                \"CDS is undefined for {self.tx_ac}; cannot map from c. coordinate (non-coding transcript?)\"\n                .format(self=self))\n\n        # start\n        if c_interval.start.datum == Datum.CDS_START and c_interval.start.base < 0:\n            rs = c_interval.start.base + self.cds_start_i + 1\n        elif c_interval.start.datum == Datum.CDS_START and c_interval.start.base > 0:\n            rs = c_interval.start.base + self.cds_start_i\n        elif c_interval.start.datum == Datum.CDS_END:\n            rs = c_interval.start.base + self.cds_end_i\n        # end\n        if c_interval.end.datum == Datum.CDS_START and c_interval.end.base < 0:\n            re = c_interval.end.base + self.cds_start_i + 1\n        elif c_interval.end.datum == Datum.CDS_START and c_interval.end.base > 0:\n            re = c_interval.end.base + self.cds_start_i\n        elif c_interval.end.datum == Datum.CDS_END:\n            re = c_interval.end.base + self.cds_end_i\n\n        if rs <= 0 or re > self.tgt_len:\n            raise HGVSError(\"The given coordinate is outside the bounds of the reference sequence.\")\n\n        n_interval = hgvs.location.BaseOffsetInterval(\n            start=hgvs.location.BaseOffsetPosition(\n                base=rs, offset=c_interval.start.offset, datum=Datum.SEQ_START),\n            end=hgvs.location.BaseOffsetPosition(\n                base=re, offset=c_interval.end.offset, datum=Datum.SEQ_START),\n            uncertain=c_interval.uncertain)\n        return n_interval", "response": "convert a transcript CDS ( c.) interval to a transcript cDNA ( n.) interval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(db_url=None,\n            pooling=hgvs.global_config.uta.pooling,\n            application_name=None,\n            mode=None,\n            cache=None):\n    \"\"\"Connect to a UTA database instance and return a UTA interface instance.\n\n    :param db_url: URL for database connection\n    :type db_url: string\n    :param pooling: whether to use connection pooling (postgresql only)\n    :type pooling: bool\n    :param application_name: log application name in connection (useful for debugging; PostgreSQL only)\n    :type application_name: str\n\n    When called with an explicit db_url argument, that db_url is used for connecting.\n\n    When called without an explicit argument, the function default is\n    determined by the environment variable UTA_DB_URL if it exists, or\n    hgvs.datainterface.uta.public_db_url otherwise.\n\n    >>> hdp = connect()\n    >>> hdp.schema_version()\n    '1.1'\n\n    The format of the db_url is driver://user:pass@host/database/schema (the same\n    as that used by SQLAlchemy).  Examples:\n\n    A remote public postgresql database:\n        postgresql://anonymous:anonymous@uta.biocommons.org/uta/uta_20170707'\n\n    A local postgresql database:\n        postgresql://localhost/uta_dev/uta_20170707\n\n    For postgresql db_urls, pooling=True causes connect to use a\n    psycopg2.pool.ThreadedConnectionPool.\n    \"\"\"\n\n    _logger.debug('connecting to ' + str(db_url) + '...')\n\n    if db_url is None:\n        db_url = _get_uta_db_url()\n\n    url = _parse_url(db_url)\n    if url.scheme == 'sqlite':\n        conn = UTA_sqlite(url, mode, cache)\n    elif url.scheme == 'postgresql':\n        conn = UTA_postgresql(\n            url=url, pooling=pooling, application_name=application_name, mode=mode, cache=cache)\n    else:\n        # fell through connection scheme cases\n        raise RuntimeError(\"{url.scheme} in {url} is not currently supported\".format(url=url))\n    _logger.info('connected to ' + str(db_url) + '...')\n    return conn", "response": "Connect to a UTA database instance and return a UTA interface instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of protein accessions for a given sequence.", "response": "def get_acs_for_protein_seq(self, seq):\n        \"\"\"\n        returns a list of protein accessions for a given sequence.  The\n        list is guaranteed to contain at least one element with the\n        MD5-based accession (MD5_01234abc...def56789) at the end of the\n        list.\n        \"\"\"\n        md5 = seq_md5(seq)\n        return [r['ac'] for r in self._fetchall(self._queries['acs_for_protein_md5'], [md5])\n                ] + ['MD5_' + md5]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets transcript exon info for supplied transcript accession.", "response": "def get_tx_exons(self, tx_ac, alt_ac, alt_aln_method):\n        \"\"\"\n        return transcript exon info for supplied accession (tx_ac, alt_ac, alt_aln_method), or None if not found\n\n        :param tx_ac: transcript accession with version (e.g., 'NM_000051.3')\n        :type tx_ac: str\n\n        :param alt_ac: specific genomic sequence (e.g., NC_000011.4)\n        :type alt_ac: str\n\n        :param alt_aln_method: sequence alignment method (e.g., splign, blat)\n        :type alt_aln_method: str\n\n        # tx_exons = db.get_tx_exons('NM_199425.2', 'NC_000020.10', 'splign')\n        # len(tx_exons)\n        3\n\n        tx_exons have the following attributes::\n\n            {\n                'tes_exon_set_id' : 98390\n                'aes_exon_set_id' : 298679\n                'tx_ac'           : 'NM_199425.2'\n                'alt_ac'          : 'NC_000020.10'\n                'alt_strand'      : -1\n                'alt_aln_method'  : 'splign'\n                'ord'             : 2\n                'tx_exon_id'      : 936834\n                'alt_exon_id'     : 2999028\n                'tx_start_i'      : 786\n                'tx_end_i'        : 1196\n                'alt_start_i'     : 25059178\n                'alt_end_i'       : 25059588\n                'cigar'           : '410='\n            }\n\n        For example:\n\n        # tx_exons[0]['tx_ac']\n        'NM_199425.2'\n\n        \"\"\"\n        rows = self._fetchall(self._queries['tx_exons'], [tx_ac, alt_ac, alt_aln_method])\n        if len(rows) == 0:\n            raise HGVSDataNotAvailableError(\n                \"No tx_exons for (tx_ac={tx_ac},alt_ac={alt_ac},alt_aln_method={alt_aln_method})\".\n                format(tx_ac=tx_ac, alt_ac=alt_ac, alt_aln_method=alt_aln_method))\n\n        # TODO: Check that end == transcript sequence length (but length N/A in current hdp)\n        ex0 = 0 if (rows[0][\"alt_strand\"] == 1) else -1\n        if rows[ex0][\"tx_start_i\"] != 0:\n            raise HGVSDataNotAvailableError(\n                \"Alignment is incomplete; cannot use transcript for mapping\"\n                \"(tx_ac={tx_ac},alt_ac={alt_ac},alt_aln_method={alt_aln_method})\".format(\n                    tx_ac=tx_ac, alt_ac=alt_ac, alt_aln_method=alt_aln_method))\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_tx_for_region(self, alt_ac, alt_aln_method, start_i, end_i):\n        return self._fetchall(self._queries['tx_for_region'],\n                              [alt_ac, alt_aln_method, start_i, end_i])", "response": "get all transcripts that overlap given region"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tx_identity_info(self, tx_ac):\n        rows = self._fetchall(self._queries['tx_identity_info'], [tx_ac])\n        if len(rows) == 0:\n            raise HGVSDataNotAvailableError(\n                \"No transcript definition for (tx_ac={tx_ac})\".format(tx_ac=tx_ac))\n        return rows[0]", "response": "returns features associated with a single transcript."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a single transcript info for supplied accession", "response": "def get_tx_info(self, tx_ac, alt_ac, alt_aln_method):\n        \"\"\"return a single transcript info for supplied accession (tx_ac, alt_ac, alt_aln_method), or None if not found\n\n        :param tx_ac: transcript accession with version (e.g., 'NM_000051.3')\n        :type tx_ac: str\n\n        :param alt_ac: specific genomic sequence (e.g., NC_000011.4)\n        :type alt_ac: str\n\n        :param alt_aln_method: sequence alignment method (e.g., splign, blat)\n        :type alt_aln_method: str\n\n        # database output\n        -[ RECORD 1 ]--+------------\n        hgnc           | ATM\n        cds_start_i    | 385\n        cds_end_i      | 9556\n        tx_ac          | NM_000051.3\n        alt_ac         | AC_000143.1\n        alt_aln_method | splign\n\n        \"\"\"\n        rows = self._fetchall(self._queries['tx_info'], [tx_ac, alt_ac, alt_aln_method])\n        if len(rows) == 0:\n            raise HGVSDataNotAvailableError(\n                \"No tx_info for (tx_ac={tx_ac},alt_ac={alt_ac},alt_aln_method={alt_aln_method})\".\n                format(tx_ac=tx_ac, alt_ac=alt_ac, alt_aln_method=alt_aln_method))\n        elif len(rows) == 1:\n            return rows[0]\n        else:\n            raise HGVSError(\"Multiple ({n}) replies for tx_info(tx_ac=\"\n                            \"{tx_ac},alt_ac={alt_ac},alt_aln_method={alt_aln_method})\".format(\n                                n=len(rows),\n                                tx_ac=tx_ac,\n                                alt_ac=alt_ac,\n                                alt_aln_method=alt_aln_method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tx_mapping_options(self, tx_ac):\n        rows = self._fetchall(self._queries['tx_mapping_options'], [tx_ac])\n        return rows", "response": "Return all possible mapping options for a given transcript accession."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of transcripts that are similar to the given transcript with relevant similarity criteria.", "response": "def get_similar_transcripts(self, tx_ac):\n        \"\"\"Return a list of transcripts that are similar to the given\n        transcript, with relevant similarity criteria.\n\n        >> sim_tx = hdp.get_similar_transcripts('NM_001285829.1')\n        >> dict(sim_tx[0])\n        { 'cds_eq': False,\n        'cds_es_fp_eq': False,\n        'es_fp_eq': True,\n        'tx_ac1': 'NM_001285829.1',\n        'tx_ac2': 'ENST00000498907' }\n\n        where:\n\n        * cds_eq means that the CDS sequences are identical\n        * es_fp_eq means that the full exon structures are identical\n          (i.e., incl. UTR)\n        * cds_es_fp_eq means that the cds-clipped portions of the exon\n          structures are identical (i.e., ecluding. UTR)\n        * Hint: \"es\" = \"exon set\", \"fp\" = \"fingerprint\", \"eq\" = \"equal\"\n\n        \"exon structure\" refers to the start and end coordinates on a\n        specified reference sequence. Thus, having the same exon\n        structure means that the transcripts are defined on the same\n        reference sequence and have the same exon spans on that\n        sequence.\n\n        \"\"\"\n\n        rows = self._fetchall(self._queries['tx_similar'], [tx_ac])\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the protein accession for a given transcript_ac.", "response": "def get_pro_ac_for_tx_ac(self, tx_ac):\n        \"\"\"Return the (single) associated protein accession for a given transcript\n        accession, or None if not found.\"\"\"\n\n        rows = self._fetchall(self._queries['tx_to_pro'], [tx_ac])\n        try:\n            return rows[0]['pro_ac']\n        except IndexError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a cache key from optionally typed positional and keyword arguments", "response": "def _make_key(func,\n              args,\n              kwds,\n              typed,\n              kwd_mark=(object(), ),\n              fasttypes={int, str, frozenset, type(None)},\n              sorted=sorted,\n              tuple=tuple,\n              type=type,\n              len=len):\n    'Make a cache key from optionally typed positional and keyword arguments'\n    key = args\n    key += kwd_mark\n    key += ('__func__', func)\n    if kwds:\n        sorted_items = sorted(kwds.items())\n        for item in sorted_items:\n            key += item\n    if typed:\n        key += tuple(type(v) for v in args)\n        if kwds:\n            key += tuple(type(v) for k, v in sorted_items)\n    elif len(key) == 1 and type(key[0]) in fasttypes:\n        return key[0]\n    return _HashedSeq(key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize(self, var):\n        assert isinstance(var, hgvs.sequencevariant.SequenceVariant\n                          ), \"variant must be a parsed HGVS sequence variant object\"\n\n        if self.validator:\n            self.validator.validate(var)\n\n        init_met = False\n        if var.posedit is not None and isinstance(var.posedit, hgvs.edit.AARefAlt):\n            init_met = var.posedit.init_met\n\n        if var.posedit is None or var.posedit.uncertain or init_met or var.posedit.pos is None:\n            return var\n\n        type = var.type\n\n        if type == \"p\":\n            raise HGVSUnsupportedOperationError(\n                \"Unsupported normalization of protein level variants: {0}\".format(var))\n        if var.posedit.edit.type == \"con\":\n            raise HGVSUnsupportedOperationError(\n                \"Unsupported normalization of conversion variants: {0}\", format(var))\n\n        var.fill_ref(self.hdp)\n\n        if var.posedit.edit.type == \"identity\":\n            var_norm = copy.deepcopy(var)\n            return var_norm\n\n        # For c. variants normalization, first convert to n. variant\n        # and perform normalization at the n. level, then convert the\n        # normalized n. variant back to c. variant.\n        if type == \"c\":\n            var = self.hm.c_to_n(var)\n\n        if var.type in \"nr\":\n            if var.posedit.pos.start.offset != 0 or var.posedit.pos.end.offset != 0:\n                raise HGVSUnsupportedOperationError(\n                    \"Normalization of intronic variants is not supported\")\n\n        # g, m, n, r sequences all use sequence start as the datum\n        # That\"s an essential assumption herein\n        # (this is why we may have converted from c to n above)\n        assert var.type in \"gmnr\", \"Internal Error: variant must be of type g, m, n, r\"\n\n        bound_s, bound_e = self._get_boundary(var)\n        boundary = (bound_s, bound_e)\n        start, end, (ref, alt) = self._normalize_alleles(var, boundary)\n\n        ref_len = len(ref)\n        alt_len = len(alt)\n\n        # Generate normalized variant\n        if alt_len == ref_len:\n            ref_start = start\n            ref_end = end - 1\n            # inversion\n            if ref_len > 1 and ref == reverse_complement(alt):\n                edit = hgvs.edit.Inv(ref=ref)\n            # ident\n            elif ref_len == 0 and alt_len == 0:\n                ref_start = ref_end\n                edit = hgvs.edit.NARefAlt(ref=ref, alt=alt)\n            # substitution or delins\n            else:\n                edit = hgvs.edit.NARefAlt(ref=ref, alt=alt)\n        if alt_len < ref_len:\n            # del or delins\n            ref_start = start\n            ref_end = end - 1\n            edit = hgvs.edit.NARefAlt(ref=ref, alt=None if alt_len == 0 else alt)\n        elif alt_len > ref_len:\n            # ins or dup\n            if ref_len == 0:\n                if self.shuffle_direction == 3:\n                    adj_seq = self._fetch_bounded_seq(var, start - alt_len - 1, end - 1, 0,\n                                                      boundary)\n                else:\n                    adj_seq = self._fetch_bounded_seq(var, start - 1, start + alt_len - 1, 0,\n                                                      boundary)\n                # ins\n                if alt != adj_seq:\n                    ref_start = start - 1\n                    ref_end = end\n                    edit = hgvs.edit.NARefAlt(ref=None, alt=alt)\n                # dup\n                else:\n                    if self.shuffle_direction == 3:\n                        ref_start = start - alt_len\n                        ref_end = end - 1\n                        edit = hgvs.edit.Dup(ref=alt)\n                    else:\n                        ref_start = start\n                        ref_end = start + alt_len - 1\n                        edit = hgvs.edit.Dup(ref=alt)\n            # delins\n            else:\n                ref_start = start\n                ref_end = end - 1\n                edit = hgvs.edit.NARefAlt(ref=ref, alt=alt)\n\n        # ensure the start is not 0\n        if ref_start == 0:\n            ref = self._fetch_bounded_seq(var, 0, 1, 0, boundary)\n            alt = alt + ref\n            edit = hgvs.edit.NARefAlt(ref=ref, alt=alt)\n            ref_start = 1\n            ref_end = 1\n\n        # ensure the end is not outside of reference sequence\n        tgt_len = self._get_tgt_length(var)\n        if ref_end == tgt_len + 1:\n            ref = self._fetch_bounded_seq(var, tgt_len - 1, tgt_len, 0, boundary)\n            alt = ref + alt\n            edit = hgvs.edit.NARefAlt(ref=ref, alt=alt)\n            ref_start = tgt_len\n            ref_end = tgt_len\n\n        var_norm = copy.deepcopy(var)\n        var_norm.posedit.edit = edit\n        var_norm.posedit.pos.start.base = ref_start\n        var_norm.posedit.pos.end.base = ref_end\n\n        if type == \"c\":\n            var_norm = self.hm.n_to_c(var_norm)\n\n        return var_norm", "response": "Perform normalization of a single variant in the HGVS database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the position of exon - intron boundary for current variant", "response": "def _get_boundary(self, var):\n        \"\"\"Get the position of exon-intron boundary for current variant\n        \"\"\"\n        if var.type == \"r\" or var.type == \"n\":\n            if self.cross_boundaries:\n                return 0, float(\"inf\")\n            else:\n                # Get genomic sequence access number for this transcript\n                map_info = self.hdp.get_tx_mapping_options(var.ac)\n                if not map_info:\n                    raise HGVSDataNotAvailableError(\n                        \"No mapping info available for {ac}\".format(ac=var.ac))\n                map_info = [\n                    item for item in map_info if item[\"alt_aln_method\"] == self.alt_aln_method\n                ]\n                alt_ac = map_info[0][\"alt_ac\"]\n\n                # Get tx info\n                tx_info = self.hdp.get_tx_info(var.ac, alt_ac, self.alt_aln_method)\n                cds_start = tx_info[\"cds_start_i\"]\n                cds_end = tx_info[\"cds_end_i\"]\n\n                # Get exon info\n                exon_info = self.hdp.get_tx_exons(var.ac, alt_ac, self.alt_aln_method)\n                exon_starts = [exon[\"tx_start_i\"] for exon in exon_info]\n                exon_ends = [exon[\"tx_end_i\"] for exon in exon_info]\n                exon_starts.sort()\n                exon_ends.sort()\n                exon_starts.append(exon_ends[-1])\n                exon_ends.append(float(\"inf\"))\n\n                # Find the end pos of the exon where the var locates\n                left = 0\n                right = float(\"inf\")\n\n                # TODO: #242: implement methods to find tx regions\n                for i, _ in enumerate(exon_starts):\n                    if (var.posedit.pos.start.base - 1 >= exon_starts[i]\n                            and var.posedit.pos.start.base - 1 < exon_ends[i]):\n                        break\n\n                for j, _ in enumerate(exon_starts):\n                    if (var.posedit.pos.end.base - 1 >= exon_starts[j]\n                            and var.posedit.pos.end.base - 1 < exon_ends[j]):\n                        break\n\n                if i != j:\n                    raise HGVSUnsupportedOperationError(\n                        \"Unsupported normalization of variants spanning the exon-intron boundary ({var})\"\n                        .format(var=var))\n\n                left = exon_starts[i]\n                right = exon_ends[i]\n\n                if cds_start is None:\n                    pass\n                elif var.posedit.pos.end.base - 1 < cds_start:\n                    right = min(right, cds_start)\n                elif var.posedit.pos.start.base - 1 >= cds_start:\n                    left = max(left, cds_start)\n                else:\n                    raise HGVSUnsupportedOperationError(\n                        \"Unsupported normalization of variants spanning the UTR-exon boundary ({var})\"\n                        .format(var=var))\n\n                if cds_end is None:\n                    pass\n                elif var.posedit.pos.start.base - 1 >= cds_end:\n                    left = max(left, cds_end)\n                elif var.posedit.pos.end.base - 1 < cds_end:\n                    right = min(right, cds_end)\n                else:\n                    raise HGVSUnsupportedOperationError(\n                        \"Unsupported normalization of variants spanning the exon-UTR boundary ({var})\"\n                        .format(var=var))\n\n                return left, right\n        else:\n            # For variant type of g and m etc.\n            return 0, float(\"inf\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_tgt_length(self, var):\n        if var.type == \"g\" or var.type == \"m\":\n            return float(\"inf\")\n        else:\n            # Get genomic sequence access number for this transcript\n            identity_info = self.hdp.get_tx_identity_info(var.ac)\n            if not identity_info:\n                raise HGVSDataNotAvailableError(\n                    \"No identity info available for {ac}\".format(ac=var.ac))\n            tgt_len = sum(identity_info[\"lengths\"])\n            return tgt_len", "response": "Get the total length of the whole reference sequence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch a bounded sequence from hgvs data provider.", "response": "def _fetch_bounded_seq(self, var, start, end, window_size, boundary):\n        \"\"\"Fetch reference sequence from hgvs data provider.\n\n        The start position is 0 and the interval is half open\n        \"\"\"\n        var_len = end - start - window_size\n\n        start = start if start >= boundary[0] else boundary[0]\n        end = end if end <= boundary[1] else boundary[1]\n        if start >= end:\n            return \"\"\n\n        seq = self.hdp.get_seq(var.ac, start, end)\n\n        if len(seq) < end - start and len(seq) < var_len:\n            raise HGVSInvalidVariantError(\n                \"Variant span is outside sequence bounds ({var})\".format(var=var))\n\n        return seq"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_ref_alt(self, var, boundary):\n\n        # Get reference allele\n        if var.posedit.edit.type == \"ins\" or var.posedit.edit.type == \"dup\":\n            ref = \"\"\n        else:\n            # For NARefAlt and Inv\n            if var.posedit.edit.ref_s is None or var.posedit.edit.ref == \"\":\n                ref = self._fetch_bounded_seq(var, var.posedit.pos.start.base - 1,\n                                              var.posedit.pos.end.base, 0, boundary)\n            else:\n                ref = var.posedit.edit.ref\n\n        # Get alternative allele\n        if var.posedit.edit.type == \"sub\" or var.posedit.edit.type == \"delins\" or var.posedit.edit.type == \"ins\":\n            alt = var.posedit.edit.alt\n        elif var.posedit.edit.type == \"del\":\n            alt = \"\"\n        elif var.posedit.edit.type == \"dup\":\n            alt = var.posedit.edit.ref or self._fetch_bounded_seq(\n                var, var.posedit.pos.start.base - 1, var.posedit.pos.end.base, 0, boundary)\n        elif var.posedit.edit.type == \"inv\":\n            alt = reverse_complement(ref)\n        elif var.posedit.edit.type == \"identity\":\n            alt = ref\n\n        return ref, alt", "response": "Get the reference and alternative allele of the variant."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing the variant until it could not be shuffled", "response": "def _normalize_alleles(self, var, boundary):\n        \"\"\"Normalize the variant until it could not be shuffled\n        \"\"\"\n\n        ref, alt = self._get_ref_alt(var, boundary)\n        win_size = hgvs.global_config.normalizer.window_size\n\n        if self.shuffle_direction == 3:\n            if var.posedit.edit.type == \"ins\":\n                base = var.posedit.pos.start.base\n                start = 1\n                stop = 1\n            elif var.posedit.edit.type == \"dup\":\n                base = var.posedit.pos.end.base\n                start = 1\n                stop = 1\n            else:\n                base = var.posedit.pos.start.base\n                start = 0\n                stop = var.posedit.pos.end.base - base + 1\n\n            while True:\n                ref_seq = self._fetch_bounded_seq(var, base - 1, base + stop - 1 + win_size,\n                                                  win_size, boundary)\n                if ref_seq == \"\":\n                    break\n                orig_start, orig_stop = start, stop\n                start, stop, (ref, alt) = normalize_alleles(ref_seq, start, stop, (ref, alt),\n                                                            len(ref_seq), win_size, False)\n                if stop < len(ref_seq) or start == orig_start:\n                    break\n                # if stop at the end of the window, try to extend the shuffling to the right\n                base += start - orig_start\n                stop -= start - orig_start\n                start = orig_start\n\n        elif self.shuffle_direction == 5:\n            if var.posedit.edit.type == \"ins\":\n                base = max(var.posedit.pos.start.base - win_size, 1)\n                start = var.posedit.pos.end.base - base\n                stop = var.posedit.pos.end.base - base\n            elif var.posedit.edit.type == \"dup\":\n                base = max(var.posedit.pos.start.base - win_size, 1)\n                start = var.posedit.pos.end.base - base + 1\n                stop = var.posedit.pos.end.base - base + 1\n            else:\n                base = max(var.posedit.pos.start.base - win_size, 1)\n                start = var.posedit.pos.start.base - base\n                stop = var.posedit.pos.end.base - base + 1\n\n            while True:\n                if base < boundary[0] + 1:\n                    start -= boundary[0] + 1 - base\n                    stop -= boundary[0] + 1 - base\n                    base = boundary[0] + 1\n                ref_seq = self._fetch_bounded_seq(var, base - 1, base + stop - 1, start, boundary)\n                if ref_seq == \"\":\n                    break\n                orig_start, orig_stop = start, stop\n                start, stop, (ref, alt) = normalize_alleles(ref_seq, start, stop, (ref, alt), 0,\n                                                            win_size, True)\n                if start > 0 or stop == orig_stop:\n                    break\n                # if stop at the end of the window, try to extend the shuffling to the left\n                base -= orig_stop - stop\n                start += orig_stop - stop\n                stop = orig_stop\n\n        return base + start, base + stop, (ref, alt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trim_common_suffixes(strs, min_len=0):\n\n    if len(strs) < 2:\n        return 0, strs\n\n    rev_strs = [s[::-1] for s in strs]\n\n    trimmed, rev_strs = trim_common_prefixes(rev_strs, min_len)\n\n    if trimmed:\n        strs = [s[::-1] for s in rev_strs]\n\n    return trimmed, strs", "response": "trim common suffixes\n\n    >>> trim_common_suffixes('A', 1)\n    (0, 'A')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_alleles_left(ref, start, stop, alleles, bound, ref_step, shuffle=True):\n\n    normalized_alleles = namedtuple('shuffled_alleles', 'start stop alleles')\n\n    if len(alleles) < 2:\n        return normalized_alleles(start, stop, alleles)\n\n    # STEP 1: Trim common suffix\n    trimmed, alleles = trim_common_suffixes(alleles)\n    stop -= trimmed\n\n    # STEP 2: Trim common prefix\n    trimmed, alleles = trim_common_prefixes(alleles)\n    start += trimmed\n\n    # assert bound <= start,'start={:d}, left bound={:d}'.format(start, bound)\n\n    # STEP 3: While a null allele exists, left shuffle by prepending alleles\n    #         with reference and trimming common suffixes\n    while shuffle and '' in alleles and start > bound:\n        step = min(ref_step, start - bound)\n\n        r = ref[start - step:start].upper()\n        new_alleles = [r + a for a in alleles]\n\n        trimmed, new_alleles = trim_common_suffixes(new_alleles)\n\n        if not trimmed:\n            break\n\n        start -= trimmed\n        stop -= trimmed\n\n        if trimmed == step:\n            alleles = new_alleles\n        else:\n            left = step - trimmed\n            alleles = [a[left:] for a in new_alleles]\n            break\n\n    return normalized_alleles(start, stop, tuple(alleles))", "response": "Normalize loci by removing extraneous reference padding and trimming common suffixes and common prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the given type of accession is correct for the given sequence number.", "response": "def validate_type_ac_pair(type, ac):\n    \"\"\"validate that accession is correct for variant type AND that\n    accession is fully specified.\n\n    \"\"\"\n\n    assert type in valid_pairs, \"Unknown variant type \" + type\n    if valid_pairs[type].match(ac):\n        return (ValidationLevel.VALID,\n                \"Accession ({ac}) is compatible with variant type {type}\".format(ac=ac, type=type))\n    elif invalid_pairs[type].match(ac):\n        return (ValidationLevel.ERROR,\n                \"Accession ({ac}) is not compatible with variant type {type}\".format(\n                    ac=ac, type=type))\n    else:\n        return (ValidationLevel.WARNING,\n                \"Accession ({ac}) is not known to be compatible with variant type {type}\".format(\n                    ac=ac, type=type))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a list of dictionaries for each allele in the variant and a sequence", "response": "def build_altseq(self):\n        \"\"\"given a variant and a sequence, incorporate the variant and return the new sequence\n\n        Data structure returned is analogous to the data structure used to return the variant sequence,\n        but with an additional parameter denoting the start of a frameshift that should affect all bases\n        downstream.\n\n        :returns variant sequence data\n        :rtype list of dictionaries\n        \"\"\"\n        NOT_CDS = \"not_cds_variant\"\n        WHOLE_GENE_DELETED = \"whole_gene_deleted\"\n\n        type_map = {\n            NARefAlt: self._incorporate_delins,\n            Dup: self._incorporate_dup,\n            Inv: self._incorporate_inv,\n            Repeat: self._incorporate_repeat,\n            NOT_CDS: self._create_alt_equals_ref_noncds,\n            WHOLE_GENE_DELETED: self._create_no_protein\n        }\n\n        # should loop over each allele rather than assume only 1 variant; return a list for now\n        alt_data = []\n\n        variant_location = self._get_variant_region()\n\n        if variant_location == self.EXON:\n            edit_type = type(self._var_c.posedit.edit)\n        elif variant_location == self.INTRON:\n            edit_type = NOT_CDS\n        elif variant_location == self.T_UTR:\n            edit_type = NOT_CDS\n        elif variant_location == self.F_UTR:\n            # TODO: handle case where variant introduces a Met (new start)\n            edit_type = NOT_CDS\n        elif variant_location == self.WHOLE_GENE:\n            if self._var_c.posedit.edit.type == \"del\":\n                edit_type = WHOLE_GENE_DELETED\n            elif self._var_c.posedit.edit.type == \"dup\":\n                _logger.warning(\n                    \"Whole-gene duplication; consequence assumed to not affect protein product\")\n                edit_type = NOT_CDS\n            elif self._var_c.posedit.edit.type == \"inv\":\n                _logger.warning(\n                    \"Whole-gene inversion; consequence assumed to not affect protein product\")\n                edit_type = NOT_CDS\n            else:\n                edit_type = NOT_CDS\n        else:    # should never get here\n            raise ValueError(\"value_location = {}\".format(variant_location))\n\n        try:\n            this_alt_data = type_map[edit_type]()\n        except KeyError:\n            raise NotImplementedError(\"c to p translation unsupported for {} type {}\".format(\n                self._var_c, edit_type))\n\n        # get the start of the \"terminal\" frameshift (i.e. one never \"cancelled out\")\n        this_alt_data = self._get_frameshift_start(this_alt_data)\n        alt_data.append(this_alt_data)\n        if DBG:\n            print(this_alt_data.transcript_sequence)\n\n        return alt_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_variant_region(self):\n        if self._var_c.posedit.pos.start.datum == Datum.CDS_END and self._var_c.posedit.pos.end.datum == Datum.CDS_END:\n            result = self.T_UTR\n        elif self._var_c.posedit.pos.start.base < 0 and self._var_c.posedit.pos.end.base < 0:\n            result = self.F_UTR\n        elif self._var_c.posedit.pos.start.base < 0 and self._var_c.posedit.pos.end.datum == Datum.CDS_END:\n            result = self.WHOLE_GENE\n        elif self._var_c.posedit.pos.start.offset != 0 or self._var_c.posedit.pos.end.offset != 0:\n            # leave out anything intronic for now\n            result = self.INTRON\n        else:    # anything else that contains an exon\n            result = self.EXON\n        return result", "response": "Return the region of the variant in the transcript."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nincorporate delins into the sequence", "response": "def _incorporate_delins(self):\n        \"\"\"Incorporate delins\"\"\"\n        seq, cds_start, cds_stop, start, end = self._setup_incorporate()\n\n        ref = self._var_c.posedit.edit.ref\n        alt = self._var_c.posedit.edit.alt\n        ref_length = end - start if ref is not None else 0    # can't just get from ref since ref isn't always known\n        alt_length = len(\n            self._var_c.posedit.edit.alt) if self._var_c.posedit.edit.alt is not None else 0\n        net_base_change = alt_length - ref_length\n        cds_stop += net_base_change\n\n        # incorporate the variant into the sequence (depending on the type)\n        is_substitution = False\n        if ref is not None and alt is not None:    # delins or SNP\n            seq[start:end] = list(alt)\n            if len(ref) == 1 and len(alt) == 1:\n                is_substitution = True\n        elif ref is not None:    # deletion\n            del seq[start:end]\n        else:    # insertion\n            seq[start + 1:start + 1] = list(alt)    # insertion in list before python list index\n\n        if DBG:\n            print(\"net base change: {}\".format(net_base_change))\n        is_frameshift = net_base_change % 3 != 0\n        # use max of mod 3 value and 1 (in event that indel starts in the 5'utr range)\n        variant_start_aa = max(int(math.ceil((self._var_c.posedit.pos.start.base) / 3.0)), 1)\n\n        alt_data = AltTranscriptData(\n            seq,\n            cds_start,\n            cds_stop,\n            is_frameshift,\n            variant_start_aa,\n            self._transcript_data.protein_accession,\n            is_substitution=is_substitution,\n            is_ambiguous=self._ref_has_multiple_stops)\n        return alt_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nincorporating dup into sequence", "response": "def _incorporate_dup(self):\n        \"\"\"Incorporate dup into sequence\"\"\"\n        seq, cds_start, cds_stop, start, end = self._setup_incorporate()\n\n        dup_seq = seq[start:end]\n        seq[end:end] = dup_seq\n\n        is_frameshift = len(dup_seq) % 3 != 0\n        variant_start_aa = int(math.ceil((self._var_c.posedit.pos.end.base + 1) / 3.0))\n\n        alt_data = AltTranscriptData(\n            seq,\n            cds_start,\n            cds_stop,\n            is_frameshift,\n            variant_start_aa,\n            self._transcript_data.protein_accession,\n            is_ambiguous=self._ref_has_multiple_stops)\n        return alt_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nincorporates inv into sequence", "response": "def _incorporate_inv(self):\n        \"\"\"Incorporate inv into sequence\"\"\"\n        seq, cds_start, cds_stop, start, end = self._setup_incorporate()\n\n        seq[start:end] = list(reverse_complement(''.join(seq[start:end])))\n\n        is_frameshift = False\n        variant_start_aa = max(int(math.ceil((self._var_c.posedit.pos.start.base) / 3.0)), 1)\n\n        alt_data = AltTranscriptData(\n            seq,\n            cds_start,\n            cds_stop,\n            is_frameshift,\n            variant_start_aa,\n            self._transcript_data.protein_accession,\n            is_ambiguous=self._ref_has_multiple_stops)\n        return alt_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _setup_incorporate(self):\n        seq = list(self._transcript_data.transcript_sequence)\n\n        # get initial start/end points; will modify these based on the variant length\n        cds_start = self._transcript_data.cds_start\n        cds_stop = self._transcript_data.cds_stop\n\n        start_end = []\n        for pos in (self._var_c.posedit.pos.start, self._var_c.posedit.pos.end):\n            # list is zero-based; seq pos is 1-based\n            if pos.datum == Datum.CDS_START:\n                if pos.base < 0:    # 5' UTR\n                    result = cds_start - 1\n                else:    # cds/intron\n                    if pos.offset <= 0:\n                        result = (cds_start - 1) + pos.base - 1\n                    else:\n                        result = (cds_start - 1) + pos.base\n            elif pos.datum == Datum.CDS_END:    # 3' UTR\n                result = cds_stop + pos.base - 1\n            else:\n                raise NotImplementedError(\"Unsupported/unexpected location\")\n            start_end.append(result)\n\n        # unpack; increment end by 1 (0-based exclusive)\n        (start, end) = start_end\n        end += 1\n\n        if DBG:\n            print(\"len seq:{} cds_start:{} cds_stop:{} start:{} end:{}\".format(\n                len(seq), cds_start, cds_stop, start, end))\n        return seq, cds_start, cds_stop, start, end", "response": "Helper to setup incorporate functions\n        is a helper method that returns the transcript sequence cds start cds stop start and end indices in the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_alt_equals_ref_noncds(self):\n        alt_data = AltTranscriptData(\n            list(self._transcript_data.transcript_sequence),\n            self._transcript_data.cds_start,\n            self._transcript_data.cds_stop,\n            False,\n            None,\n            self._transcript_data.protein_accession,\n            is_ambiguous=True)\n        return alt_data", "response": "Create an alt seq that matches the reference non - citation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a no - protein result.", "response": "def _create_no_protein(self):\n        \"\"\"Create a no-protein result\"\"\"\n        alt_data = AltTranscriptData([],\n                                     None,\n                                     None,\n                                     False,\n                                     None,\n                                     self._transcript_data.protein_accession,\n                                     is_ambiguous=False)\n        return alt_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the start position of the first frameshift in the sequence", "response": "def _get_frameshift_start(self, variant_data):\n        \"\"\"Get starting position (AA ref index) of the last frameshift\n        which affects the rest of the sequence, i.e. not offset by subsequent frameshifts\n        :param variant_data: info on each variant\n        :type variant_data: attrs\n        :return variant data with additional field for AA index (1-based) of the frameshift start\n        :rtype attrs\n        \"\"\"\n\n        if DBG:\n            print(\"is_frameshift:{}\".format(variant_data.is_frameshift))\n            print(\"variant_start_aa:{}\".format(variant_data.variant_start_aa))\n        if variant_data.is_frameshift:\n            variant_data.frameshift_start = variant_data.variant_start_aa\n        return variant_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cigar_to_intervalpairs(cigar):\n\n    cigar_elem_re = re.compile(r\"(?P<len>\\d+)(?P<op>[=DIMNX])\")\n    ces = [\n        CIGARElement(op=md[\"op\"], len=int(md[\"len\"]))\n        for md in [m.groupdict() for m in cigar_elem_re.finditer(cigar)]\n    ]\n    ips = [None] * len(ces)\n    ref_pos = tgt_pos = 0\n    for i, ce in enumerate(ces):\n        ips[i] = IntervalPair(\n            Interval(ref_pos, ref_pos + ce.ref_len), Interval(tgt_pos, tgt_pos + ce.tgt_len))\n        ref_pos += ce.ref_len\n        tgt_pos += ce.tgt_len\n    return ips", "response": "Given a CIGAR string return a list of ( Interval Pair ) tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing a metadata dict for an IA S3 and Metadata API requests.", "response": "def prepare_metadata(metadata, source_metadata=None, append=False, append_list=False):\n    \"\"\"Prepare a metadata dict for an\n    :class:`S3PreparedRequest <S3PreparedRequest>` or\n    :class:`MetadataPreparedRequest <MetadataPreparedRequest>` object.\n\n    :type metadata: dict\n    :param metadata: The metadata dict to be prepared.\n\n    :type source_metadata: dict\n    :param source_metadata: (optional) The source metadata for the item\n                            being modified.\n\n    :rtype: dict\n    :returns: A filtered metadata dict to be used for generating IA\n              S3 and Metadata API requests.\n\n    \"\"\"\n    # Make a deepcopy of source_metadata if it exists. A deepcopy is\n    # necessary to avoid modifying the original dict.\n    source_metadata = {} if not source_metadata else copy.deepcopy(source_metadata)\n    prepared_metadata = {}\n\n    # Functions for dealing with metadata keys containing indexes.\n    def get_index(key):\n        match = re.search(r'(?<=\\[)\\d+(?=\\])', key)\n        if match is not None:\n            return int(match.group())\n\n    def rm_index(key):\n        return key.split('[')[0]\n\n    # Create indexed_keys counter dict. i.e.: {'subject': 3} -- subject\n    # (with the index removed) appears 3 times in the metadata dict.\n    indexed_keys = {}\n    for key in metadata:\n        # Convert number values to strings!\n        if isinstance(metadata[key], (six.integer_types, float, complex)):\n            metadata[key] = str(metadata[key])\n        if get_index(key) is None:\n            continue\n        count = len([x for x in metadata if rm_index(x) == rm_index(key)])\n        indexed_keys[rm_index(key)] = count\n\n    # Initialize the values for all indexed_keys.\n    for key in indexed_keys:\n        # Increment the counter so we know how many values the final\n        # value in prepared_metadata should have.\n        indexed_keys[key] += len(source_metadata.get(key, []))\n        # Intialize the value in the prepared_metadata dict.\n        prepared_metadata[key] = source_metadata.get(key, [])\n        if not isinstance(prepared_metadata[key], list):\n            prepared_metadata[key] = [prepared_metadata[key]]\n        # Fill the value of the prepared_metadata key with None values\n        # so all indexed items can be indexed in order.\n        while len(prepared_metadata[key]) < indexed_keys[key]:\n            prepared_metadata[key].append(None)\n\n    # Index all items which contain an index.\n    for key in metadata:\n        # Insert values from indexed keys into prepared_metadata dict.\n        if (rm_index(key) in indexed_keys):\n            try:\n                prepared_metadata[rm_index(key)][get_index(key)] = metadata[key]\n            except IndexError:\n                prepared_metadata[rm_index(key)].append(metadata[key])\n        # If append is True, append value to source_metadata value.\n        elif append_list and source_metadata.get(key):\n            if not isinstance(metadata[key], list):\n                metadata[key] = [metadata[key]]\n            for v in metadata[key]:\n                if not isinstance(source_metadata[key], list):\n                    if v in [source_metadata[key]]:\n                        continue\n                else:\n                    if v in source_metadata[key]:\n                        continue\n                if not isinstance(source_metadata[key], list):\n                    prepared_metadata[key] = [source_metadata[key]]\n                else:\n                    prepared_metadata[key] = source_metadata[key]\n                prepared_metadata[key].append(v)\n        elif append and source_metadata.get(key):\n            prepared_metadata[key] = '{0} {1}'.format(\n                source_metadata[key], metadata[key])\n        else:\n            prepared_metadata[key] = metadata[key]\n\n    # Remove values from metadata if value is REMOVE_TAG.\n    _done = []\n    for key in indexed_keys:\n        # Filter None values from items with arrays as values\n        prepared_metadata[key] = [v for v in prepared_metadata[key] if v]\n        # Only filter the given indexed key if it has not already been\n        # filtered.\n        if key not in _done:\n            indexes = []\n            for k in metadata:\n                if not get_index(k):\n                    continue\n                elif not rm_index(k) == key:\n                    continue\n                elif not metadata[k] == 'REMOVE_TAG':\n                    continue\n                else:\n                    indexes.append(get_index(k))\n            # Delete indexed values in reverse to not throw off the\n            # subsequent indexes.\n            for i in sorted(indexes, reverse=True):\n                del prepared_metadata[key][i]\n            _done.append(key)\n\n    return prepared_metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the HTTP headers for the current object.", "response": "def prepare_headers(self, headers, metadata, queue_derive=True):\n        \"\"\"Convert a dictionary of metadata into S3 compatible HTTP\n        headers, and append headers to ``headers``.\n\n        :type metadata: dict\n        :param metadata: Metadata to be converted into S3 HTTP Headers\n                         and appended to ``headers``.\n\n        :type headers: dict\n        :param headers: (optional) S3 compatible HTTP headers.\n\n        \"\"\"\n        if not metadata.get('scanner'):\n            scanner = 'Internet Archive Python library {0}'.format(__version__)\n            metadata['scanner'] = scanner\n        prepared_metadata = prepare_metadata(metadata)\n\n        headers['x-archive-auto-make-bucket'] = '1'\n        if queue_derive is False:\n            headers['x-archive-queue-derive'] = '0'\n        else:\n            headers['x-archive-queue-derive'] = '1'\n\n        for meta_key, meta_value in prepared_metadata.items():\n            # Encode arrays into JSON strings because Archive.org does not\n            # yet support complex metadata structures in\n            # <identifier>_meta.xml.\n            if isinstance(meta_value, dict):\n                meta_value = json.dumps(meta_value)\n            # Convert the metadata value into a list if it is not already\n            # iterable.\n            if (isinstance(meta_value, six.string_types) or\n                    not hasattr(meta_value, '__iter__')):\n                meta_value = [meta_value]\n            # Convert metadata items into HTTP headers and add to\n            # ``headers`` dict.\n            for i, value in enumerate(meta_value):\n                if not value:\n                    continue\n                header_key = 'x-archive-meta{0:02d}-{1}'.format(i, meta_key)\n                if (isinstance(value, six.string_types) and needs_quote(value)):\n                    if six.PY2 and isinstance(value, six.text_type):\n                        value = value.encode('utf-8')\n                    value = 'uri({0})'.format(urllib.parse.quote(value))\n                # because rfc822 http headers disallow _ in names, IA-S3 will\n                # translate two hyphens in a row (--) into an underscore (_).\n                header_key = header_key.replace('_', '--')\n                headers[header_key] = value\n        super(S3PreparedRequest, self).prepare_headers(headers)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    args = docopt(__doc__, version=__version__, options_first=True)\n\n    # Validate args.\n    s = Schema({\n        six.text_type: bool,\n        '--config-file': Or(None, str),\n        '<args>': list,\n        '<command>': Or(str, lambda _: 'help'),\n    })\n    try:\n        args = s.validate(args)\n    except SchemaError as exc:\n        print('{0}\\n{1}'.format(str(exc), printable_usage(__doc__)), file=sys.stderr)\n        sys.exit(1)\n\n    # Get subcommand.\n    cmd = args['<command>']\n    if cmd in cmd_aliases:\n        cmd = cmd_aliases[cmd]\n\n    if (cmd == 'help') or (not cmd):\n        if not args['<args>']:\n            sys.exit(print(__doc__.strip(), file=sys.stderr))\n        else:\n            ia_module = load_ia_module(args['<args>'][0])\n            sys.exit(print(ia_module.__doc__.strip(), file=sys.stderr))\n\n    if cmd != 'configure' and args['--config-file']:\n        if not os.path.isfile(args['--config-file']):\n            print('--config-file should be a readable file.\\n{0}'.format(\n                printable_usage(__doc__)), file=sys.stderr)\n            sys.exit(1)\n\n    argv = [cmd] + args['<args>']\n\n    config = dict()\n    if args['--log']:\n        config['logging'] = {'level': 'INFO'}\n    elif args['--debug']:\n        config['logging'] = {'level': 'DEBUG'}\n\n    if args['--insecure']:\n        config['general'] = dict(secure=False)\n\n    session = get_session(config_file=args['--config-file'],\n                          config=config,\n                          debug=args['--debug'])\n\n    ia_module = load_ia_module(cmd)\n    try:\n        sys.exit(ia_module.main(argv, session))\n    except IOError as e:\n        # Handle Broken Pipe errors.\n        if e.errno == errno.EPIPE:\n            sys.stderr.close()\n            sys.stdout.close()\n            sys.exit(0)\n        else:\n            raise", "response": "This is the main function for the ia - wrapper."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload the file into the current working directory.", "response": "def download(self, file_path=None, verbose=None, silent=None, ignore_existing=None,\n                 checksum=None, destdir=None, retries=None, ignore_errors=None,\n                 fileobj=None, return_responses=None, no_change_timestamp=None,\n                 params=None):\n        \"\"\"Download the file into the current working directory.\n\n        :type file_path: str\n        :param file_path: Download file to the given file_path.\n\n        :type verbose: bool\n        :param verbose: (optional) Turn on verbose output.\n\n        :type silent: bool\n        :param silent: (optional) Suppress all output.\n\n        :type ignore_existing: bool\n        :param ignore_existing: Overwrite local files if they already\n                                exist.\n\n        :type checksum: bool\n        :param checksum: (optional) Skip downloading file based on checksum.\n\n        :type destdir: str\n        :param destdir: (optional) The directory to download files to.\n\n        :type retries: int\n        :param retries: (optional) The number of times to retry on failed\n                        requests.\n\n        :type ignore_errors: bool\n        :param ignore_errors: (optional) Don't fail if a single file fails to\n                              download, continue to download other files.\n\n        :type fileobj: file-like object\n        :param fileobj: (optional) Write data to the given file-like object\n                         (e.g. sys.stdout).\n\n        :type return_responses: bool\n        :param return_responses: (optional) Rather than downloading files to disk, return\n                                 a list of response objects.\n\n        :type no_change_timestamp: bool\n        :param no_change_timestamp: (optional) If True, leave the time stamp as the\n                                    current time instead of changing it to that given in\n                                    the original archive.\n\n        :type params: dict\n        :param params: (optional) URL parameters to send with\n                       download request (e.g. `cnt=0`).\n\n        :rtype: bool\n        :returns: True if file was successfully downloaded.\n        \"\"\"\n        verbose = False if verbose is None else verbose\n        ignore_existing = False if ignore_existing is None else ignore_existing\n        checksum = False if checksum is None else checksum\n        retries = 2 if not retries else retries\n        ignore_errors = False if not ignore_errors else ignore_errors\n        return_responses = False if not return_responses else return_responses\n        no_change_timestamp = False if not no_change_timestamp else no_change_timestamp\n        params = None if not params else params\n\n        if (fileobj and silent is None) or silent is not False:\n            silent = True\n        else:\n            silent = False\n\n        self.item.session.mount_http_adapter(max_retries=retries)\n        file_path = self.name if not file_path else file_path\n\n        if destdir:\n            if not os.path.exists(destdir) and return_responses is not True:\n                os.mkdir(destdir)\n            if os.path.isfile(destdir):\n                raise IOError('{} is not a directory!'.format(destdir))\n            file_path = os.path.join(destdir, file_path)\n\n        if not return_responses and os.path.exists(file_path.encode('utf-8')):\n            if ignore_existing:\n                msg = 'skipping {0}, file already exists.'.format(file_path)\n                log.info(msg)\n                if verbose:\n                    print(' ' + msg)\n                elif silent is False:\n                    print('.', end='')\n                    sys.stdout.flush()\n                return\n            elif checksum:\n                with open(file_path, 'rb') as fp:\n                    md5_sum = utils.get_md5(fp)\n\n                if md5_sum == self.md5:\n                    msg = ('skipping {0}, '\n                           'file already exists based on checksum.'.format(file_path))\n                    log.info(msg)\n                    if verbose:\n                        print(' ' + msg)\n                    elif silent is False:\n                        print('.', end='')\n                        sys.stdout.flush()\n                    return\n            else:\n                st = os.stat(file_path.encode('utf-8'))\n                if (st.st_mtime == self.mtime) and (st.st_size == self.size) \\\n                        or self.name.endswith('_files.xml') and st.st_size != 0:\n                    msg = ('skipping {0}, file already exists '\n                           'based on length and date.'.format(file_path))\n                    log.info(msg)\n                    if verbose:\n                        print(' ' + msg)\n                    elif silent is False:\n                        print('.', end='')\n                        sys.stdout.flush()\n                    return\n\n        parent_dir = os.path.dirname(file_path)\n        if parent_dir != '' \\\n                and not os.path.exists(parent_dir) \\\n                and return_responses is not True:\n            os.makedirs(parent_dir)\n\n        try:\n            response = self.item.session.get(self.url,\n                                             stream=True,\n                                             timeout=12,\n                                             auth=self.auth,\n                                             params=params)\n            response.raise_for_status()\n            if return_responses:\n                return response\n\n            chunk_size = 2048\n            if not fileobj:\n                fileobj = open(file_path.encode('utf-8'), 'wb')\n\n            with fileobj:\n                for chunk in response.iter_content(chunk_size=chunk_size):\n                    if chunk:\n                        fileobj.write(chunk)\n                        fileobj.flush()\n        except (RetryError, HTTPError, ConnectTimeout,\n                ConnectionError, socket.error, ReadTimeout) as exc:\n            msg = ('error downloading file {0}, '\n                   'exception raised: {1}'.format(file_path, exc))\n            log.error(msg)\n            if os.path.exists(file_path):\n                os.remove(file_path)\n            if verbose:\n                print(' ' + msg)\n            elif silent is False:\n                print('e', end='')\n                sys.stdout.flush()\n            if ignore_errors is True:\n                return False\n            else:\n                raise exc\n\n        # Set mtime with mtime from files.xml.\n        if not no_change_timestamp:\n            # If we want to set the timestamp to that of the original archive...\n            try:\n                os.utime(file_path.encode('utf-8'), (0, self.mtime))\n            except OSError:\n                # Probably file-like object, e.g. sys.stdout.\n                pass\n\n        msg = 'downloaded {0}/{1} to {2}'.format(self.identifier,\n                                                 self.name,\n                                                 file_path)\n        log.info(msg)\n        if verbose:\n            print(' ' + msg)\n        elif silent is False:\n            print('d', end='')\n            sys.stdout.flush()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a file from the Archive.", "response": "def delete(self, cascade_delete=None, access_key=None, secret_key=None, verbose=None,\n               debug=None, retries=None, headers=None):\n        \"\"\"Delete a file from the Archive. Note: Some files -- such as\n        <itemname>_meta.xml -- cannot be deleted.\n\n        :type cascade_delete: bool\n        :param cascade_delete: (optional) Also deletes files derived from the file, and\n                               files the file was derived from.\n\n        :type access_key: str\n        :param access_key: (optional) IA-S3 access_key to use when making the given\n                           request.\n\n        :type secret_key: str\n        :param secret_key: (optional) IA-S3 secret_key to use when making the given\n                           request.\n\n        :type verbose: bool\n        :param verbose: (optional) Print actions to stdout.\n\n        :type debug: bool\n        :param debug: (optional) Set to True to print headers to stdout and exit exit\n                      without sending the delete request.\n\n        \"\"\"\n        cascade_delete = '0' if not cascade_delete else '1'\n        access_key = self.item.session.access_key if not access_key else access_key\n        secret_key = self.item.session.secret_key if not secret_key else secret_key\n        debug = False if not debug else debug\n        verbose = False if not verbose else verbose\n        max_retries = 2 if retries is None else retries\n        headers = dict() if headers is None else headers\n\n        if 'x-archive-cascade-delete' not in headers:\n            headers['x-archive-cascade-delete'] = cascade_delete\n\n        url = '{0}//s3.us.archive.org/{1}/{2}'.format(self.item.session.protocol,\n                                                      self.identifier,\n                                                      self.name)\n        self.item.session.mount_http_adapter(max_retries=max_retries,\n                                             status_forcelist=[503],\n                                             host='s3.us.archive.org')\n        request = iarequest.S3Request(\n            method='DELETE',\n            url=url,\n            headers=headers,\n            access_key=access_key,\n            secret_key=secret_key\n        )\n        if debug:\n            return request\n        else:\n            if verbose:\n                msg = ' deleting: {0}'.format(self.name)\n                if cascade_delete:\n                    msg += ' and all derivative files.'\n                print(msg, file=sys.stderr)\n            prepared_request = self.item.session.prepare_request(request)\n\n            try:\n                resp = self.item.session.send(prepared_request)\n                resp.raise_for_status()\n            except (RetryError, HTTPError, ConnectTimeout,\n                    ConnectionError, socket.error, ReadTimeout) as exc:\n                error_msg = 'Error deleting {0}, {1}'.format(url, exc)\n                log.error(error_msg)\n                raise\n            else:\n                return resp\n            finally:\n                # The retry adapter is mounted to the session object.\n                # Make sure to remove it after delete, so it isn't\n                # mounted if and when the session object is used for an\n                # upload. This is important because we use custom retry\n                # handling for IA-S3 uploads.\n                url_prefix = '{0}//s3.us.archive.org'.format(self.item.session.protocol)\n                del self.item.session.adapters[url_prefix]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps function for Python 2 and 3 compatability", "response": "def map2x(func, *iterables):\n    \"\"\"map() function for Python 2/3 compatability\"\"\"\n    zipped = zip_longest(*iterables)\n    if func is None:\n        return zipped\n    return starmap(func, zipped)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef suppress_keyboard_interrupt_message():\n    old_excepthook = sys.excepthook\n\n    def new_hook(type, value, traceback):\n        if type != KeyboardInterrupt:\n            old_excepthook(type, value, traceback)\n        else:\n            sys.exit(130)\n\n    sys.excepthook = new_hook", "response": "Register a new excepthook to suppress KeyboardInterrupt exception messages and exit with status code 130."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_directory(directory):\n    for path, dir, files in os.walk(directory):\n        for f in files:\n            filepath = os.path.join(path, f)\n            key = os.path.relpath(filepath, directory)\n            yield (filepath, key)", "response": "Given a directory yield all files and s3 keys as a two - tuple"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a filepath or list of filepaths return the total number of files.", "response": "def recursive_file_count(files, item=None, checksum=False):\n    \"\"\"Given a filepath or list of filepaths, return the total number of files.\"\"\"\n    if not isinstance(files, (list, set)):\n        files = [files]\n    total_files = 0\n    if checksum is True:\n        md5s = [f.get('md5') for f in item.files]\n    else:\n        md5s = list()\n    if isinstance(files, dict):\n        # make sure to use local filenames.\n        _files = files.values()\n    else:\n        if isinstance(files[0], tuple):\n            _files = dict(files).values()\n        else:\n            _files = files\n    for f in _files:\n        try:\n            is_dir = os.path.isdir(f)\n        except TypeError:\n            try:\n                f = f[0]\n                is_dir = os.path.isdir(f)\n            except (AttributeError, TypeError):\n                is_dir = False\n        if is_dir:\n            for x, _ in iter_directory(f):\n                lmd5 = get_md5(open(x, 'rb'))\n                if lmd5 in md5s:\n                    continue\n                else:\n                    total_files += 1\n        else:\n            try:\n                lmd5 = get_md5(open(f, 'rb'))\n            except TypeError:\n                # Support file-like objects.\n                lmd5 = get_md5(f)\n            if lmd5 in md5s:\n                continue\n            else:\n                total_files += 1\n    return total_files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend message to exception while preserving attributes.", "response": "def reraise_modify(caught_exc, append_msg, prepend=False):\n    \"\"\"Append message to exception while preserving attributes.\n\n    Preserves exception class, and exception traceback.\n\n    Note:\n        This function needs to be called inside an except because\n        `sys.exc_info()` requires the exception context.\n\n    Args:\n        caught_exc(Exception): The caught exception object\n        append_msg(str): The message to append to the caught exception\n        prepend(bool): If True prepend the message to args instead of appending\n\n    Returns:\n        None\n\n    Side Effects:\n        Re-raises the exception with the preserved data / trace but\n        modified message\n    \"\"\"\n    ExceptClass = type(caught_exc)\n    # Keep old traceback\n    traceback = sys.exc_info()[2]\n    if not caught_exc.args:\n        # If no args, create our own tuple\n        arg_list = [append_msg]\n    else:\n        # Take the last arg\n        # If it is a string\n        # append your message.\n        # Otherwise append it to the\n        # arg list(Not as pretty)\n        arg_list = list(caught_exc.args[:-1])\n        last_arg = caught_exc.args[-1]\n        if isinstance(last_arg, str):\n            if prepend:\n                arg_list.append(append_msg + last_arg)\n            else:\n                arg_list.append(last_arg + append_msg)\n        else:\n            arg_list += [last_arg, append_msg]\n    caught_exc.args = tuple(arg_list)\n    six.reraise(ExceptClass,\n                caught_exc,\n                traceback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_items_from_dict(d, to_delete):\n    if not isinstance(to_delete, list):\n        to_delete = [to_delete]\n    if isinstance(d, dict):\n        for single_to_delete in set(to_delete):\n            if single_to_delete in d.values():\n                for k, v in d.copy().items():\n                    if v == single_to_delete:\n                        del d[k]\n        for k, v in d.items():\n            delete_items_from_dict(v, to_delete)\n    elif isinstance(d, list):\n        for i in d:\n            delete_items_from_dict(i, to_delete)\n    return remove_none(d)", "response": "Recursively deletes items from a dict and returns a list of None."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new session object.", "response": "def get_session(config=None, config_file=None, debug=None, http_adapter_kwargs=None):\n    \"\"\"Return a new :class:`ArchiveSession` object. The :class:`ArchiveSession`\n    object is the main interface to the ``internetarchive`` lib. It allows you to\n    persist certain parameters across tasks.\n\n    :type config: dict\n    :param config: (optional) A dictionary used to configure your session.\n\n    :type config_file: str\n    :param config_file: (optional) A path to a config file used to configure your session.\n\n    :type http_adapter_kwargs: dict\n    :param http_adapter_kwargs: (optional) Keyword arguments that\n                                :py:class:`requests.adapters.HTTPAdapter` takes.\n\n    :returns: :class:`ArchiveSession` object.\n\n    Usage:\n\n        >>> from internetarchive import get_session\n        >>> config = dict(s3=dict(access='foo', secret='bar'))\n        >>> s = get_session(config)\n        >>> s.access_key\n        'foo'\n\n    From the session object, you can access all of the functionality of the\n    ``internetarchive`` lib:\n\n        >>> item = s.get_item('nasa')\n        >>> item.download()\n        nasa: ddddddd - success\n        >>> s.get_tasks(task_ids=31643513)[0].server\n        'ia311234'\n    \"\"\"\n    return session.ArchiveSession(config, config_file, debug, http_adapter_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an item from the archive.", "response": "def get_item(identifier,\n             config=None,\n             config_file=None,\n             archive_session=None,\n             debug=None,\n             http_adapter_kwargs=None,\n             request_kwargs=None):\n    \"\"\"Get an :class:`Item` object.\n\n    :type identifier: str\n    :param identifier: The globally unique Archive.org item identifier.\n\n    :type config: dict\n    :param config: (optional) A dictionary used to configure your session.\n\n    :type config_file: str\n    :param config_file: (optional) A path to a config file used to configure your session.\n\n    :type archive_session: :class:`ArchiveSession`\n    :param archive_session: (optional) An :class:`ArchiveSession` object can be provided\n                            via the ``archive_session`` parameter.\n\n    :type http_adapter_kwargs: dict\n    :param http_adapter_kwargs: (optional) Keyword arguments that\n                                :py:class:`requests.adapters.HTTPAdapter` takes.\n\n    :type request_kwargs: dict\n    :param request_kwargs: (optional) Keyword arguments that\n                           :py:class:`requests.Request` takes.\n\n    Usage:\n        >>> from internetarchive import get_item\n        >>> item = get_item('nasa')\n        >>> item.item_size\n        121084\n    \"\"\"\n    if not archive_session:\n        archive_session = get_session(config, config_file, debug, http_adapter_kwargs)\n    return archive_session.get_item(identifier, request_kwargs=request_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget files from an item.", "response": "def get_files(identifier,\n              files=None,\n              formats=None,\n              glob_pattern=None,\n              on_the_fly=None,\n              **get_item_kwargs):\n    \"\"\"Get :class:`File` objects from an item.\n\n    :type identifier: str\n    :param identifier: The globally unique Archive.org identifier for a given item.\n\n    :param files: iterable\n    :param files: (optional) Only return files matching the given filenames.\n\n    :param formats: iterable\n    :param formats: (optional) Only return files matching the given formats.\n\n    :type glob_pattern: str\n    :param glob_pattern: (optional) Only return files matching the given glob pattern.\n\n    :type on_the_fly: bool\n    :param on_the_fly: (optional) Include on-the-fly files (i.e. derivative EPUB,\n                       MOBI, DAISY files).\n\n    :param \\*\\*get_item_kwargs: (optional) Arguments that ``get_item()`` takes.\n\n    Usage:\n        >>> from internetarchive import get_files\n        >>> fnames = [f.name for f in get_files('nasa', glob_pattern='*xml')]\n        >>> print(fnames)\n        ['nasa_reviews.xml', 'nasa_meta.xml', 'nasa_files.xml']\n    \"\"\"\n    item = get_item(identifier, **get_item_kwargs)\n    return item.get_files(files, formats, glob_pattern, on_the_fly)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies the metadata of an existing item on Archive. org.", "response": "def modify_metadata(identifier, metadata,\n                    target=None,\n                    append=None,\n                    append_list=None,\n                    priority=None,\n                    access_key=None,\n                    secret_key=None,\n                    debug=None,\n                    request_kwargs=None,\n                    **get_item_kwargs):\n    \"\"\"Modify the metadata of an existing item on Archive.org.\n\n    :type identifier: str\n    :param identifier: The globally unique Archive.org identifier for a given item.\n\n    :type metadata: dict\n    :param metadata: Metadata used to update the item.\n\n    :type target: str\n    :param target: (optional) The metadata target to update. Defaults to `metadata`.\n\n    :type append: bool\n    :param append: (optional) set to True to append metadata values to current values\n                   rather than replacing. Defaults to ``False``.\n\n    :type append_list: bool\n    :param append_list: (optional) Append values to an existing multi-value\n                        metadata field. No duplicate values will be added.\n\n    :type priority: int\n    :param priority: (optional) Set task priority.\n\n    :type access_key: str\n    :param access_key: (optional) IA-S3 access_key to use when making the given request.\n\n    :type secret_key: str\n    :param secret_key: (optional) IA-S3 secret_key to use when making the given request.\n\n    :type debug: bool\n    :param debug: (optional) set to True to return a :class:`requests.Request <Request>`\n                  object instead of sending request. Defaults to ``False``.\n\n    :param \\*\\*get_item_kwargs: (optional) Arguments that ``get_item`` takes.\n\n    :returns: :class:`requests.Response` object or :class:`requests.Request` object if\n              debug is ``True``.\n    \"\"\"\n    item = get_item(identifier, **get_item_kwargs)\n    return item.modify_metadata(metadata,\n                                target=target,\n                                append=append,\n                                append_list=append_list,\n                                priority=priority,\n                                access_key=access_key,\n                                secret_key=secret_key,\n                                debug=debug,\n                                request_kwargs=request_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload(identifier, files,\n           metadata=None,\n           headers=None,\n           access_key=None,\n           secret_key=None,\n           queue_derive=None,\n           verbose=None,\n           verify=None,\n           checksum=None,\n           delete=None,\n           retries=None,\n           retries_sleep=None,\n           debug=None,\n           request_kwargs=None,\n           **get_item_kwargs):\n    \"\"\"Upload files to an item. The item will be created if it does not exist.\n\n    :type identifier: str\n    :param identifier: The globally unique Archive.org identifier for a given item.\n\n    :param files: The filepaths or file-like objects to upload. This value can be an\n                  iterable or a single file-like object or string.\n\n    :type metadata: dict\n    :param metadata: (optional) Metadata used to create a new item. If the item already\n                     exists, the metadata will not be updated -- use ``modify_metadata``.\n\n    :type headers: dict\n    :param headers: (optional) Add additional HTTP headers to the request.\n\n    :type access_key: str\n    :param access_key: (optional) IA-S3 access_key to use when making the given request.\n\n    :type secret_key: str\n    :param secret_key: (optional) IA-S3 secret_key to use when making the given request.\n\n    :type queue_derive: bool\n    :param queue_derive: (optional) Set to False to prevent an item from being derived\n                         after upload.\n\n    :type verbose: bool\n    :param verbose: (optional) Display upload progress.\n\n    :type verify: bool\n    :param verify: (optional) Verify local MD5 checksum matches the MD5 checksum of the\n                   file received by IAS3.\n\n    :type checksum: bool\n    :param checksum: (optional) Skip uploading files based on checksum.\n\n    :type delete: bool\n    :param delete: (optional) Delete local file after the upload has been successfully\n                   verified.\n\n    :type retries: int\n    :param retries: (optional) Number of times to retry the given request if S3 returns a\n                    503 SlowDown error.\n\n    :type retries_sleep: int\n    :param retries_sleep: (optional) Amount of time to sleep between ``retries``.\n\n    :type debug: bool\n    :param debug: (optional) Set to True to print headers to stdout, and exit without\n                  sending the upload request.\n\n    :param \\*\\*kwargs: Optional arguments that ``get_item`` takes.\n\n    :returns: A list of :py:class:`requests.Response` objects.\n    \"\"\"\n    item = get_item(identifier, **get_item_kwargs)\n    return item.upload(files,\n                       metadata=metadata,\n                       headers=headers,\n                       access_key=access_key,\n                       secret_key=secret_key,\n                       queue_derive=queue_derive,\n                       verbose=verbose,\n                       verify=verify,\n                       checksum=checksum,\n                       delete=delete,\n                       retries=retries,\n                       retries_sleep=retries_sleep,\n                       debug=debug,\n                       request_kwargs=request_kwargs)", "response": "Uploads files to an item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(identifier,\n             files=None,\n             formats=None,\n             glob_pattern=None,\n             dry_run=None,\n             verbose=None,\n             silent=None,\n             ignore_existing=None,\n             checksum=None,\n             destdir=None,\n             no_directory=None,\n             retries=None,\n             item_index=None,\n             ignore_errors=None,\n             on_the_fly=None,\n             return_responses=None,\n             **get_item_kwargs):\n    \"\"\"Download files from an item.\n\n    :type identifier: str\n    :param identifier: The globally unique Archive.org identifier for a given item.\n\n    :param files: (optional) Only return files matching the given file names.\n\n    :param formats: (optional) Only return files matching the given formats.\n\n    :type glob_pattern: str\n    :param glob_pattern: (optional) Only return files matching the given glob pattern.\n\n    :type dry_run: bool\n    :param dry_run: (optional) Print URLs to files to stdout rather than downloading\n                    them.\n\n    :type verbose: bool\n    :param verbose: (optional) Turn on verbose output.\n\n    :type silent: bool\n    :param silent: (optional) Suppress all output.\n\n    :type ignore_existing: bool\n    :param ignore_existing: (optional) Skip files that already exist\n                            locally.\n\n    :type checksum: bool\n    :param checksum: (optional) Skip downloading file based on checksum.\n\n    :type destdir: str\n    :param destdir: (optional) The directory to download files to.\n\n    :type no_directory: bool\n    :param no_directory: (optional) Download files to current working\n                         directory rather than creating an item directory.\n\n    :type retries: int\n    :param retries: (optional) The number of times to retry on failed\n                    requests.\n\n    :type item_index: int\n    :param item_index: (optional) The index of the item for displaying\n                       progress in bulk downloads.\n\n    :type ignore_errors: bool\n    :param ignore_errors: (optional) Don't fail if a single file fails to\n                          download, continue to download other files.\n\n    :type on_the_fly: bool\n    :param on_the_fly: (optional) Download on-the-fly files (i.e. derivative EPUB,\n                       MOBI, DAISY files).\n\n    :type return_responses: bool\n    :param return_responses: (optional) Rather than downloading files to disk, return\n                             a list of response objects.\n\n    :param \\*\\*kwargs: Optional arguments that ``get_item`` takes.\n\n    :rtype: bool\n    :returns: True if all files were downloaded successfully.\n    \"\"\"\n    item = get_item(identifier, **get_item_kwargs)\n    r = item.download(files=files,\n                      formats=formats,\n                      glob_pattern=glob_pattern,\n                      dry_run=dry_run,\n                      verbose=verbose,\n                      silent=silent,\n                      ignore_existing=ignore_existing,\n                      checksum=checksum,\n                      destdir=destdir,\n                      no_directory=no_directory,\n                      retries=retries,\n                      item_index=item_index,\n                      ignore_errors=ignore_errors,\n                      on_the_fly=on_the_fly,\n                      return_responses=return_responses)\n    return r", "response": "Download files from an archive. org item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting files from an item.", "response": "def delete(identifier,\n           files=None,\n           formats=None,\n           glob_pattern=None,\n           cascade_delete=None,\n           access_key=None,\n           secret_key=None,\n           verbose=None,\n           debug=None, **kwargs):\n    \"\"\"Delete files from an item. Note: Some system files, such as <itemname>_meta.xml,\n    cannot be deleted.\n\n    :type identifier: str\n    :param identifier: The globally unique Archive.org identifier for a given item.\n\n    :param files: (optional) Only return files matching the given filenames.\n\n    :param formats: (optional) Only return files matching the given formats.\n\n    :type glob_pattern: str\n    :param glob_pattern: (optional) Only return files matching the given glob pattern.\n\n    :type cascade_delete: bool\n    :param cascade_delete: (optional) Also deletes files derived from the file, and files\n                           the filewas derived from.\n\n    :type access_key: str\n    :param access_key: (optional) IA-S3 access_key to use when making the given request.\n\n    :type secret_key: str\n    :param secret_key: (optional) IA-S3 secret_key to use when making the given request.\n\n    :type verbose: bool\n    :param verbose: Print actions to stdout.\n\n    :type debug: bool\n    :param debug: (optional) Set to True to print headers to stdout and exit exit without\n                  sending the delete request.\n    \"\"\"\n    files = get_files(identifier, files, formats, glob_pattern, **kwargs)\n\n    responses = []\n    for f in files:\n        r = f.delete(cascade_delete=cascade_delete,\n                     access_key=access_key,\n                     secret_key=secret_key,\n                     verbose=verbose,\n                     debug=debug)\n        responses.append(r)\n    return responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets tasks from the Internet archive.", "response": "def get_tasks(identifier=None,\n              task_id=None,\n              task_type=None,\n              params=None,\n              config=None,\n              config_file=None,\n              verbose=None,\n              archive_session=None,\n              http_adapter_kwargs=None,\n              request_kwargs=None):\n    \"\"\"Get tasks from the Archive.org catalog. ``internetarchive`` must be configured\n    with your logged-in-* cookies to use this function. If no arguments are provided,\n    all queued tasks for the user will be returned.\n\n    :type identifier: str\n    :param identifier: (optional) The Archive.org identifier for which to retrieve tasks\n                       for.\n\n    :type task_id: int or str\n    :param task_is: (optional) The task_id to retrieve from the Archive.org catalog.\n\n    :type task_type: str\n    :param task_type: (optional) The type of tasks to retrieve from the Archive.org\n                      catalog. The types can be either \"red\" for failed tasks, \"blue\" for\n                      running tasks, \"green\" for pending tasks, \"brown\" for paused tasks,\n                      or \"purple\" for completed tasks.\n\n    :type params: dict\n    :param params: (optional) The URL parameters to send with each request sent to the\n                   Archive.org catalog API.\n\n    :type config: dict\n    :param secure: (optional) Configuration options for session.\n\n    :type verbose: bool\n    :param verbose: (optional) Set to ``True`` to retrieve verbose information for each\n                    catalog task returned. verbose is set to ``True`` by default.\n\n    :returns: A set of :class:`CatalogTask` objects.\n    \"\"\"\n    if not archive_session:\n        archive_session = get_session(config, config_file, http_adapter_kwargs)\n    return archive_session.get_tasks(identifier=identifier,\n                                     task_id=task_id,\n                                     params=params,\n                                     config=config,\n                                     verbose=verbose,\n                                     request_kwargs=request_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for items on the archive. org.", "response": "def search_items(query,\n                 fields=None,\n                 sorts=None,\n                 params=None,\n                 archive_session=None,\n                 config=None,\n                 config_file=None,\n                 http_adapter_kwargs=None,\n                 request_kwargs=None,\n                 max_retries=None):\n    \"\"\"Search for items on Archive.org.\n\n    :type query: str\n    :param query: The Archive.org search query to yield results for. Refer to\n                  https://archive.org/advancedsearch.php#raw for help formatting your\n                  query.\n\n    :type fields: list\n    :param fields: (optional) The metadata fields to return in the search results.\n\n    :type params: dict\n    :param params: (optional) The URL parameters to send with each request sent to the\n                   Archive.org Advancedsearch Api.\n\n    :type config: dict\n    :param secure: (optional) Configuration options for session.\n\n    :type config_file: str\n    :param config_file: (optional) A path to a config file used to configure your session.\n\n    :type http_adapter_kwargs: dict\n    :param http_adapter_kwargs: (optional) Keyword arguments that\n                                :py:class:`requests.adapters.HTTPAdapter` takes.\n\n    :type request_kwargs: dict\n    :param request_kwargs: (optional) Keyword arguments that\n                           :py:class:`requests.Request` takes.\n\n    :type max_retries: int, object\n    :param max_retries: The number of times to retry a failed request.\n                        This can also be an `urllib3.Retry` object.\n                        If you need more control (e.g. `status_forcelist`), use a\n                        `ArchiveSession` object, and mount your own adapter after the\n                        session object has been initialized. For example::\n\n                        >>> s = get_session()\n                        >>> s.mount_http_adapter()\n                        >>> search_results = s.search_items('nasa')\n\n                        See :meth:`ArchiveSession.mount_http_adapter`\n                        for more details.\n\n    :returns: A :class:`Search` object, yielding search results.\n    \"\"\"\n    if not archive_session:\n        archive_session = get_session(config, config_file, http_adapter_kwargs)\n    return archive_session.search_items(query,\n                                        fields=fields,\n                                        sorts=sorts,\n                                        params=params,\n                                        request_kwargs=request_kwargs,\n                                        max_retries=max_retries)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configure(username=None, password=None, config_file=None):\n    username = input('Email address: ') if not username else username\n    password = getpass('Password: ') if not password else password\n    config_file_path = config_module.write_config_file(username, password, config_file)\n    return config_file_path", "response": "Configure an internetarchive user with your Archive. org credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_info(access_key, secret_key):\n    u = 'https://s3.us.archive.org'\n    p = dict(check_auth=1)\n    r = requests.get(u, params=p, auth=auth.S3Auth(access_key, secret_key))\n    r.raise_for_status()\n    j = r.json()\n    if j.get('error'):\n        raise AuthenticationError(j.get('error'))\n    else:\n        return j", "response": "Returns details about an Archive. org user given an IA - S3 key pair."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading files from an item.", "response": "def download(self,\n                 files=None,\n                 formats=None,\n                 glob_pattern=None,\n                 dry_run=None,\n                 verbose=None,\n                 silent=None,\n                 ignore_existing=None,\n                 checksum=None,\n                 destdir=None,\n                 no_directory=None,\n                 retries=None,\n                 item_index=None,\n                 ignore_errors=None,\n                 on_the_fly=None,\n                 return_responses=None,\n                 no_change_timestamp=None,\n                 params=None):\n        \"\"\"Download files from an item.\n\n        :param files: (optional) Only download files matching given file names.\n\n        :type formats: str\n        :param formats: (optional) Only download files matching the given\n                        Formats.\n\n        :type glob_pattern: str\n        :param glob_pattern: (optional) Only download files matching the given\n                             glob pattern.\n\n        :type dry_run: bool\n        :param dry_run: (optional) Output download URLs to stdout, don't\n                        download anything.\n\n        :type verbose: bool\n        :param verbose: (optional) Turn on verbose output.\n\n        :type silent: bool\n        :param silent: (optional) Suppress all output.\n\n        :type ignore_existing: bool\n        :param ignore_existing: (optional) Skip files that already exist\n                                locally.\n\n        :type checksum: bool\n        :param checksum: (optional) Skip downloading file based on checksum.\n\n        :type destdir: str\n        :param destdir: (optional) The directory to download files to.\n\n        :type no_directory: bool\n        :param no_directory: (optional) Download files to current working\n                             directory rather than creating an item directory.\n\n        :type retries: int\n        :param retries: (optional) The number of times to retry on failed\n                        requests.\n\n        :type item_index: int\n        :param item_index: (optional) The index of the item for displaying\n                           progress in bulk downloads.\n\n        :type ignore_errors: bool\n        :param ignore_errors: (optional) Don't fail if a single file fails to\n                              download, continue to download other files.\n\n        :type on_the_fly: bool\n        :param on_the_fly: (optional) Download on-the-fly files (i.e. derivative EPUB,\n                           MOBI, DAISY files).\n\n        :type return_responses: bool\n        :param return_responses: (optional) Rather than downloading files to disk, return\n                                 a list of response objects.\n\n        :type no_change_timestamp: bool\n        :param no_change_timestamp: (optional) If True, leave the time stamp as the\n                                    current time instead of changing it to that given in\n                                    the original archive.\n\n        :type params: dict\n        :param params: (optional) URL parameters to send with\n                       download request (e.g. `cnt=0`).\n\n        :rtype: bool\n        :returns: True if if all files have been downloaded successfully.\n        \"\"\"\n        dry_run = False if dry_run is None else dry_run\n        verbose = False if verbose is None else verbose\n        silent = False if silent is None else silent\n        ignore_existing = False if ignore_existing is None else ignore_existing\n        ignore_errors = False if not ignore_errors else ignore_errors\n        checksum = False if checksum is None else checksum\n        no_directory = False if no_directory is None else no_directory\n        return_responses = False if not return_responses else True\n        no_change_timestamp = False if not no_change_timestamp else no_change_timestamp\n        params = None if not params else params\n\n        if not dry_run:\n            if item_index and verbose is True:\n                print('{0} ({1}):'.format(self.identifier, item_index))\n            elif item_index and silent is False:\n                print('{0} ({1}): '.format(self.identifier, item_index), end='')\n            elif item_index is None and verbose is True:\n                print('{0}:'.format(self.identifier))\n            elif item_index is None and silent is False:\n                print(self.identifier, end=': ')\n            sys.stdout.flush()\n\n        if self.is_dark is True:\n            msg = 'skipping {0}, item is dark'.format(self.identifier)\n            log.warning(msg)\n            if verbose:\n                print(' ' + msg)\n            elif silent is False:\n                print(msg)\n            return\n        elif self.metadata == {}:\n            msg = 'skipping {0}, item does not exist.'.format(self.identifier)\n            log.warning(msg)\n            if verbose:\n                print(' ' + msg)\n            elif silent is False:\n                print(msg)\n            return\n\n        if files:\n            files = self.get_files(files, on_the_fly=on_the_fly)\n        else:\n            files = self.get_files(on_the_fly=on_the_fly)\n        if formats:\n            files = self.get_files(formats=formats, on_the_fly=on_the_fly)\n        if glob_pattern:\n            files = self.get_files(glob_pattern=glob_pattern, on_the_fly=on_the_fly)\n\n        if not files:\n            msg = 'skipping {0}, no matching files found.'.format(self.identifier)\n            log.info(msg)\n            if verbose:\n                print(' ' + msg)\n            elif silent is False:\n                print(msg, end='')\n\n        errors = list()\n        responses = list()\n        for f in files:\n            if no_directory:\n                path = f.name\n            else:\n                path = os.path.join(self.identifier, f.name)\n            if dry_run:\n                print(f.url)\n                continue\n            r = f.download(path, verbose, silent, ignore_existing, checksum, destdir,\n                           retries, ignore_errors, None, return_responses,\n                           no_change_timestamp, params)\n            if return_responses:\n                responses.append(r)\n            if r is False:\n                errors.append(f.name)\n        if silent is False and verbose is False and dry_run is False:\n            if errors:\n                print(' - errors')\n            else:\n                print(' - success')\n        if return_responses:\n            return responses\n        else:\n            return errors"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef modify_metadata(self, metadata,\n                        target=None,\n                        append=None,\n                        append_list=None,\n                        priority=None,\n                        access_key=None,\n                        secret_key=None,\n                        debug=None,\n                        request_kwargs=None):\n        \"\"\"Modify the metadata of an existing item on Archive.org.\n\n        Note: The Metadata Write API does not yet comply with the\n        latest Json-Patch standard. It currently complies with `version 02\n        <https://tools.ietf.org/html/draft-ietf-appsawg-json-patch-02>`__.\n\n        :type metadata: dict\n        :param metadata: Metadata used to update the item.\n\n        :type target: str\n        :param target: (optional) Set the metadata target to update.\n\n        :type priority: int\n        :param priority: (optional) Set task priority.\n\n        :type append: bool\n        :param append: (optional) Append value to an existing multi-value\n                       metadata field.\n\n        :type append_list: bool\n        :param append_list: (optional) Append values to an existing multi-value\n                            metadata field. No duplicate values will be added.\n\n        Usage::\n\n            >>> import internetarchive\n            >>> item = internetarchive.Item('mapi_test_item1')\n            >>> md = dict(new_key='new_value', foo=['bar', 'bar2'])\n            >>> item.modify_metadata(md)\n\n        :rtype: dict\n        :returns: A dictionary containing the status_code and response\n                  returned from the Metadata API.\n        \"\"\"\n        append = False if append is None else append\n        access_key = self.session.access_key if not access_key else access_key\n        secret_key = self.session.secret_key if not secret_key else secret_key\n        debug = False if debug is None else debug\n        request_kwargs = {} if not request_kwargs else request_kwargs\n\n        url = '{protocol}//archive.org/metadata/{identifier}'.format(\n            protocol=self.session.protocol,\n            identifier=self.identifier)\n        # TODO: currently files and metadata targets do not support dict's,\n        # but they might someday?? refactor this check.\n        source_metadata = self.item_metadata\n        request = MetadataRequest(\n            method='POST',\n            url=url,\n            metadata=metadata,\n            headers=self.session.headers,\n            source_metadata=source_metadata,\n            target=target,\n            priority=priority,\n            access_key=access_key,\n            secret_key=secret_key,\n            append=append,\n            append_list=append_list)\n        # Must use Session.prepare_request to make sure session settings\n        # are used on request!\n        prepared_request = request.prepare()\n        if debug:\n            return prepared_request\n        resp = self.session.send(prepared_request, **request_kwargs)\n        # Re-initialize the Item object with the updated metadata.\n        self.refresh()\n        return resp", "response": "Modify the metadata of an existing item on Archive. org."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload a single file to an item.", "response": "def upload_file(self, body,\n                    key=None,\n                    metadata=None,\n                    headers=None,\n                    access_key=None,\n                    secret_key=None,\n                    queue_derive=None,\n                    verbose=None,\n                    verify=None,\n                    checksum=None,\n                    delete=None,\n                    retries=None,\n                    retries_sleep=None,\n                    debug=None,\n                    request_kwargs=None):\n        \"\"\"Upload a single file to an item. The item will be created\n        if it does not exist.\n\n        :type body: Filepath or file-like object.\n        :param body: File or data to be uploaded.\n\n        :type key: str\n        :param key: (optional) Remote filename.\n\n        :type metadata: dict\n        :param metadata: (optional) Metadata used to create a new item.\n\n        :type headers: dict\n        :param headers: (optional) Add additional IA-S3 headers to request.\n\n        :type queue_derive: bool\n        :param queue_derive: (optional) Set to False to prevent an item from\n                             being derived after upload.\n\n        :type verify: bool\n        :param verify: (optional) Verify local MD5 checksum matches the MD5\n                       checksum of the file received by IAS3.\n\n        :type checksum: bool\n        :param checksum: (optional) Skip based on checksum.\n\n        :type delete: bool\n        :param delete: (optional) Delete local file after the upload has been\n                       successfully verified.\n\n        :type retries: int\n        :param retries: (optional) Number of times to retry the given request\n                        if S3 returns a 503 SlowDown error.\n\n        :type retries_sleep: int\n        :param retries_sleep: (optional) Amount of time to sleep between\n                              ``retries``.\n\n        :type verbose: bool\n        :param verbose: (optional) Print progress to stdout.\n\n        :type debug: bool\n        :param debug: (optional) Set to True to print headers to stdout, and\n                      exit without sending the upload request.\n\n        Usage::\n\n            >>> import internetarchive\n            >>> item = internetarchive.Item('identifier')\n            >>> item.upload_file('/path/to/image.jpg',\n            ...                  key='photos/image1.jpg')\n            True\n        \"\"\"\n        # Set defaults.\n        headers = {} if headers is None else headers\n        metadata = {} if metadata is None else metadata\n        access_key = self.session.access_key if access_key is None else access_key\n        secret_key = self.session.secret_key if secret_key is None else secret_key\n        queue_derive = True if queue_derive is None else queue_derive\n        verbose = False if verbose is None else verbose\n        verify = True if verify is None else verify\n        delete = False if delete is None else delete\n        # Set checksum after delete.\n        checksum = True if delete else checksum\n        retries = 0 if retries is None else retries\n        retries_sleep = 30 if retries_sleep is None else retries_sleep\n        debug = False if debug is None else debug\n        request_kwargs = {} if request_kwargs is None else request_kwargs\n        if 'timeout' not in request_kwargs:\n            request_kwargs['timeout'] = 120\n        md5_sum = None\n\n        if not hasattr(body, 'read'):\n            filename = body\n            body = open(body, 'rb')\n        else:\n            if key:\n                filename = key\n            else:\n                filename = body.name\n\n        size = get_file_size(body)\n\n        # Support for uploading empty files.\n        if size == 0:\n            headers['Content-Length'] = '0'\n\n        if not headers.get('x-archive-size-hint'):\n            headers['x-archive-size-hint'] = str(size)\n\n        # Build IA-S3 URL.\n        key = norm_filepath(filename).split('/')[-1] if key is None else key\n        base_url = '{0.session.protocol}//s3.us.archive.org/{0.identifier}'.format(self)\n        url = '{0}/{1}'.format(\n            base_url, urllib.parse.quote(norm_filepath(key).lstrip('/').encode('utf-8')))\n\n        # Skip based on checksum.\n        if checksum:\n            md5_sum = get_md5(body)\n            ia_file = self.get_file(key)\n            if (not self.tasks) and (ia_file) and (ia_file.md5 == md5_sum):\n                log.info('{f} already exists: {u}'.format(f=key, u=url))\n                if verbose:\n                    print(' {f} already exists, skipping.'.format(f=key))\n                if delete:\n                    log.info(\n                        '{f} successfully uploaded to '\n                        'https://archive.org/download/{i}/{f} '\n                        'and verified, deleting '\n                        'local copy'.format(i=self.identifier,\n                                            f=key))\n                    body.close()\n                    os.remove(filename)\n                # Return an empty response object if checksums match.\n                # TODO: Is there a better way to handle this?\n                body.close()\n                return Response()\n\n        # require the Content-MD5 header when delete is True.\n        if verify or delete:\n            if not md5_sum:\n                md5_sum = get_md5(body)\n            headers['Content-MD5'] = md5_sum\n\n        def _build_request():\n            body.seek(0, os.SEEK_SET)\n            if verbose:\n                try:\n                    # hack to raise exception so we get some output for\n                    # empty files.\n                    if size == 0:\n                        raise Exception\n\n                    chunk_size = 1048576\n                    expected_size = size / chunk_size + 1\n                    chunks = chunk_generator(body, chunk_size)\n                    progress_generator = progress.bar(\n                        chunks,\n                        expected_size=expected_size,\n                        label=' uploading {f}: '.format(f=key))\n                    data = IterableToFileAdapter(progress_generator, size)\n                except:\n                    print(' uploading {f}'.format(f=key))\n                    data = body\n            else:\n                data = body\n\n            headers.update(self.session.headers)\n            request = S3Request(method='PUT',\n                                url=url,\n                                headers=headers,\n                                data=data,\n                                metadata=metadata,\n                                access_key=access_key,\n                                secret_key=secret_key,\n                                queue_derive=queue_derive)\n            return request\n\n        if debug:\n            prepared_request = self.session.prepare_request(_build_request())\n            body.close()\n            return prepared_request\n        else:\n            try:\n                error_msg = ('s3 is overloaded, sleeping for '\n                             '{0} seconds and retrying. '\n                             '{1} retries left.'.format(retries_sleep, retries))\n                while True:\n                    if retries > 0:\n                        if self.session.s3_is_overloaded(access_key):\n                            sleep(retries_sleep)\n                            log.info(error_msg)\n                            if verbose:\n                                print(' warning: {0}'.format(error_msg), file=sys.stderr)\n                            retries -= 1\n                            continue\n                    request = _build_request()\n                    prepared_request = request.prepare()\n\n                    # chunked transfer-encoding is NOT supported by IA-S3.\n                    # It should NEVER be set. Requests adds it in certain\n                    # scenarios (e.g. if content-length is 0). Stop it.\n                    if prepared_request.headers.get('transfer-encoding') == 'chunked':\n                        del prepared_request.headers['transfer-encoding']\n\n                    response = self.session.send(prepared_request,\n                                                 stream=True,\n                                                 **request_kwargs)\n                    if (response.status_code == 503) and (retries > 0):\n                        log.info(error_msg)\n                        if verbose:\n                            print(' warning: {0}'.format(error_msg), file=sys.stderr)\n                        sleep(retries_sleep)\n                        retries -= 1\n                        continue\n                    else:\n                        if response.status_code == 503:\n                            log.info('maximum retries exceeded, upload failed.')\n                        break\n                response.raise_for_status()\n                log.info(u'uploaded {f} to {u}'.format(f=key, u=url))\n                if delete and response.status_code == 200:\n                    log.info(\n                        '{f} successfully uploaded to '\n                        'https://archive.org/download/{i}/{f} and verified, deleting '\n                        'local copy'.format(i=self.identifier, f=key))\n                    body.close()\n                    os.remove(filename)\n                body.close()\n                return response\n            except HTTPError as exc:\n                body.close()\n                msg = get_s3_xml_text(exc.response.content)\n                error_msg = (' error uploading {0} to {1}, '\n                             '{2}'.format(key, self.identifier, msg))\n                log.error(error_msg)\n                if verbose:\n                    print(' error uploading {0}: {1}'.format(key, msg), file=sys.stderr)\n                # Raise HTTPError with error message.\n                raise type(exc)(error_msg, response=exc.response, request=exc.request)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload(self, files,\n               metadata=None,\n               headers=None,\n               access_key=None,\n               secret_key=None,\n               queue_derive=None,\n               verbose=None,\n               verify=None,\n               checksum=None,\n               delete=None,\n               retries=None,\n               retries_sleep=None,\n               debug=None,\n               request_kwargs=None):\n        \"\"\"Upload files to an item. The item will be created if it\n        does not exist.\n\n        :type files: str, file, list, tuple, dict\n        :param files: The filepaths or file-like objects to upload.\n\n        :param \\*\\*kwargs: Optional arguments that :func:`Item.upload_file()` takes.\n\n        Usage::\n\n            >>> import internetarchive\n            >>> item = internetarchive.Item('identifier')\n            >>> md = dict(mediatype='image', creator='Jake Johnson')\n            >>> item.upload('/path/to/image.jpg', metadata=md, queue_derive=False)\n            [<Response [200]>]\n\n        Uploading multiple files::\n\n            >>> r = item.upload(['file1.txt', 'file2.txt'])\n            >>> r = item.upload([fileobj, fileobj2])\n            >>> r = item.upload(('file1.txt', 'file2.txt'))\n\n        Uploading file objects:\n\n            >>> import io\n            >>> f = io.BytesIO(b\"some initial binary data: \\\\x00\\\\x01\")\n            >>> r = item.upload({'remote-name.txt': f})\n            >>> f = io.BytesIO(b\"some more binary data: \\\\x00\\\\x01\")\n            >>> f.name = 'remote-name.txt'\n            >>> r = item.upload(f)\n\n            *Note: file objects must either have a name attribute, or be uploaded in a\n            dict where the key is the remote-name*\n\n        Setting the remote filename with a dict::\n\n            >>> r = item.upload({'remote-name.txt': '/path/to/local/file.txt'})\n\n        :rtype: list\n        :returns: A list of :class:`requests.Response` objects.\n        \"\"\"\n        queue_derive = True if queue_derive is None else queue_derive\n        remote_dir_name = None\n        if isinstance(files, dict):\n            files = list(files.items())\n        if not isinstance(files, (list, tuple)):\n            files = [files]\n\n        responses = []\n        file_index = 0\n        if checksum:\n            total_files = recursive_file_count(files, item=self, checksum=True)\n        else:\n            total_files = recursive_file_count(files, item=self, checksum=False)\n        for f in files:\n            if (isinstance(f, string_types) and is_dir(f)) \\\n                    or (isinstance(f, tuple) and is_dir(f[-1])):\n                if isinstance(f, tuple):\n                    remote_dir_name = f[0].strip('/')\n                    f = f[-1]\n                for filepath, key in iter_directory(f):\n                    file_index += 1\n                    # Set derive header if queue_derive is True,\n                    # and this is the last request being made.\n                    if queue_derive is True and file_index >= total_files:\n                        _queue_derive = True\n                    else:\n                        _queue_derive = False\n                    if not f.endswith('/'):\n                        if remote_dir_name:\n                            key = '{0}{1}/{2}'.format(remote_dir_name, f, key)\n                        else:\n                            key = '{0}/{1}'.format(f, key)\n                    elif remote_dir_name:\n                        key = '{0}/{1}'.format(remote_dir_name, key)\n                    key = norm_filepath(key)\n                    resp = self.upload_file(filepath,\n                                            key=key,\n                                            metadata=metadata,\n                                            headers=headers,\n                                            access_key=access_key,\n                                            secret_key=secret_key,\n                                            queue_derive=_queue_derive,\n                                            verbose=verbose,\n                                            verify=verify,\n                                            checksum=checksum,\n                                            delete=delete,\n                                            retries=retries,\n                                            retries_sleep=retries_sleep,\n                                            debug=debug,\n                                            request_kwargs=request_kwargs)\n                    responses.append(resp)\n            else:\n                file_index += 1\n                # Set derive header if queue_derive is True,\n                # and this is the last request being made.\n                # if queue_derive is True and file_index >= len(files):\n                if queue_derive is True and file_index >= total_files:\n                    _queue_derive = True\n                else:\n                    _queue_derive = False\n\n                if not isinstance(f, (list, tuple)):\n                    key, body = (None, f)\n                else:\n                    key, body = f\n                if key and not isinstance(key, string_types):\n                    key = str(key)\n                resp = self.upload_file(body,\n                                        key=key,\n                                        metadata=metadata,\n                                        headers=headers,\n                                        access_key=access_key,\n                                        secret_key=secret_key,\n                                        queue_derive=_queue_derive,\n                                        verbose=verbose,\n                                        verify=verify,\n                                        checksum=checksum,\n                                        delete=delete,\n                                        retries=retries,\n                                        retries_sleep=retries_sleep,\n                                        debug=debug,\n                                        request_kwargs=request_kwargs)\n                responses.append(resp)\n        return responses", "response": "Uploads files to an item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the task log as a string.", "response": "def task_log(self):\n        \"\"\"Get task log.\n\n        :rtype: str\n        :returns: The task log as a string.\n\n        \"\"\"\n        if self.task_id is None:\n            raise ValueError('task_id is None')\n        return self.get_task_log(self.task_id, self.session, self.request_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_task_log(task_id, session, request_kwargs=None):\n        request_kwargs = request_kwargs if request_kwargs else dict()\n        url = '{0}//catalogd.archive.org/log/{1}'.format(session.protocol, task_id)\n        p = dict(full=1)\n        r = session.get(url, params=p, **request_kwargs)\n        r.raise_for_status()\n        return r.content.decode('utf-8')", "response": "Static method for getting a task log given a task_id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_user_agent_string(self):\n        uname = platform.uname()\n        try:\n            lang = locale.getlocale()[0][:2]\n        except:\n            lang = ''\n        py_version = '{0}.{1}.{2}'.format(*sys.version_info)\n        return 'internetarchive/{0} ({1} {2}; N; {3}; {4}) Python/{5}'.format(\n            __version__, uname[0], uname[-1], lang, self.access_key, py_version)", "response": "Generate a User - Agent string to be sent with every request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rebuild_auth(self, prepared_request, response):\n        u = urlparse(prepared_request.url)\n        if u.netloc.endswith('archive.org'):\n            return\n        super(ArchiveSession, self).rebuild_auth(prepared_request, response)", "response": "Rebuild auth for archive. org URLs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmounting an HTTP adapter to the archive. org.", "response": "def mount_http_adapter(self, protocol=None, max_retries=None,\n                           status_forcelist=None, host=None):\n        \"\"\"Mount an HTTP adapter to the\n        :class:`ArchiveSession <ArchiveSession>` object.\n\n        :type protocol: str\n        :param protocol: HTTP protocol to mount your adapter to (e.g. 'https://').\n\n        :type max_retries: int, object\n        :param max_retries: The number of times to retry a failed request.\n                            This can also be an `urllib3.Retry` object.\n\n        :type status_forcelist: list\n        :param status_forcelist: A list of status codes (as int's) to retry on.\n\n        :type host: str\n        :param host: The host to mount your adapter to.\n        \"\"\"\n        protocol = protocol if protocol else self.protocol\n        host = host if host else 'archive.org'\n        if max_retries is None:\n            max_retries = self.http_adapter_kwargs.get('max_retries', 3)\n\n        if not status_forcelist:\n            status_forcelist = [500, 501, 502, 503, 504]\n        if max_retries and isinstance(max_retries, (int, float)):\n            max_retries = Retry(total=max_retries,\n                                connect=max_retries,\n                                read=max_retries,\n                                redirect=False,\n                                method_whitelist=Retry.DEFAULT_METHOD_WHITELIST,\n                                status_forcelist=status_forcelist,\n                                backoff_factor=1)\n        self.http_adapter_kwargs['max_retries'] = max_retries\n        max_retries_adapter = HTTPAdapter(**self.http_adapter_kwargs)\n        # Don't mount on s3.us.archive.org, only archive.org!\n        # IA-S3 requires a more complicated retry workflow.\n        self.mount('{0}//{1}'.format(protocol, host), max_retries_adapter)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_item(self, identifier, item_metadata=None, request_kwargs=None):\n        request_kwargs = {} if not request_kwargs else request_kwargs\n        if not item_metadata:\n            logger.debug('no metadata provided for \"{0}\", '\n                         'retrieving now.'.format(identifier))\n            item_metadata = self.get_metadata(identifier, request_kwargs)\n        mediatype = item_metadata.get('metadata', {}).get('mediatype')\n        try:\n            item_class = self.ITEM_MEDIATYPE_TABLE.get(mediatype, Item)\n        except TypeError:\n            item_class = Item\n        return item_class(self, identifier, item_metadata)", "response": "A method for creating an Item or Collection object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an item s metadata from the Metadata API.", "response": "def get_metadata(self, identifier, request_kwargs=None):\n        \"\"\"Get an item's metadata from the `Metadata API\n        <http://blog.archive.org/2013/07/04/metadata-api/>`__\n\n        :type identifier: str\n        :param identifier: Globally unique Archive.org identifier.\n\n        :rtype: dict\n        :returns: Metadat API response.\n        \"\"\"\n        request_kwargs = {} if not request_kwargs else request_kwargs\n        url = '{0}//archive.org/metadata/{1}'.format(self.protocol, identifier)\n        if 'timeout' not in request_kwargs:\n            request_kwargs['timeout'] = 12\n        try:\n            resp = self.get(url, **request_kwargs)\n            resp.raise_for_status()\n        except Exception as exc:\n            error_msg = 'Error retrieving metadata from {0}, {1}'.format(url, exc)\n            logger.error(error_msg)\n            raise type(exc)(error_msg)\n        return resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_items(self, query,\n                     fields=None,\n                     sorts=None,\n                     params=None,\n                     request_kwargs=None,\n                     max_retries=None):\n        \"\"\"Search for items on Archive.org.\n\n        :type query: str\n        :param query: The Archive.org search query to yield results for. Refer to\n                      https://archive.org/advancedsearch.php#raw for help formatting your\n                      query.\n\n        :type fields: bool\n        :param fields: (optional) The metadata fields to return in the search results.\n\n        :type params: dict\n        :param params: (optional) The URL parameters to send with each request sent to the\n                       Archive.org Advancedsearch Api.\n\n        :returns: A :class:`Search` object, yielding search results.\n        \"\"\"\n        request_kwargs = {} if not request_kwargs else request_kwargs\n        return Search(self, query,\n                      fields=fields,\n                      sorts=sorts,\n                      params=params,\n                      request_kwargs=request_kwargs,\n                      max_retries=max_retries)", "response": "Search for items on Archive. org."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tasks(self,\n                  identifier=None,\n                  task_id=None,\n                  task_type=None,\n                  params=None,\n                  config=None,\n                  verbose=None,\n                  request_kwargs=None):\n        \"\"\"Get tasks from the Archive.org catalog. ``internetarchive`` must be configured\n        with your logged-in-* cookies to use this function. If no arguments are provided,\n        all queued tasks for the user will be returned.\n\n        :type identifier: str\n        :param identifier: (optional) The Archive.org identifier for which to retrieve\n                           tasks for.\n\n        :type task_id: int or str\n        :param task_id: (optional) The task_id to retrieve from the Archive.org catalog.\n\n        :type task_type: str\n        :param task_type: (optional) The type of tasks to retrieve from the Archive.org\n                          catalog. The types can be either \"red\" for failed tasks, \"blue\"\n                          for running tasks, \"green\" for pending tasks, \"brown\" for paused\n                          tasks, or \"purple\" for completed tasks.\n\n        :type params: dict\n        :param params: (optional) The URL parameters to send with each request sent to the\n                       Archive.org catalog API.\n\n        :type config: dict\n        :param secure: (optional) Configuration options for session.\n\n        :type verbose: bool\n        :param verbose: (optional) Set to ``True`` to retrieve verbose information for\n                        each catalog task returned. verbose is set to ``True`` by default.\n\n        :returns: A set of :class:`CatalogTask` objects.\n        \"\"\"\n        request_kwargs = {} if not request_kwargs else request_kwargs\n        _catalog = Catalog(self,\n                           identifier=identifier,\n                           task_id=task_id,\n                           params=params,\n                           config=config,\n                           verbose=verbose,\n                           request_kwargs=request_kwargs)\n        if task_type:\n            return eval('_catalog.{0}_rows'.format(task_type.lower()))\n        else:\n            return _catalog.tasks", "response": "Get all queued tasks from the Internet archive."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef email_to(self):\n        for field in self.form_fields:\n            if field.is_a(fields.EMAIL):\n                return self.cleaned_data[field.slug]\n        return None", "response": "Return the value entered for the first field of type EmailField."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the given field has been posted to the form.", "response": "def posted_data(self, field):\n        \"\"\"\n        Wrapper for self.cleaned_data that returns True on\n        field_id_export fields when the form hasn't been posted to,\n        to facilitate show/export URLs that export all entries without\n        a form submission.\n        \"\"\"\n        try:\n            return self.cleaned_data[field]\n        except (AttributeError, KeyError):\n            return field.endswith(\"_export\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unique_slug(manager, slug_field, slug):\n    max_length = manager.model._meta.get_field(slug_field).max_length\n    slug = slug[:max_length]\n    i = 0\n    while True:\n        if i > 0:\n            if i > 1:\n                slug = slug.rsplit(\"-\", 1)[0]\n            # We need to keep the slug length under the slug fields max length. We need to\n            # account for the length that is added by adding a random integer and `-`.\n            slug = \"%s-%s\" % (slug[:max_length - len(str(i)) - 1], i)\n        if not manager.filter(**{slug_field: slug}):\n            break\n        i += 1\n    return slug", "response": "Ensure slug is unique for the given manager appending a digit\nWorkItem if it isn t."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a Python dotted path to a variable in a module returns the variable in that module.", "response": "def import_attr(path):\n    \"\"\"\n    Given a a Python dotted path to a variable in a module,\n    imports the module and returns the variable in it.\n    \"\"\"\n    module_path, attr_name = path.rsplit(\".\", 1)\n    return getattr(import_module(module_path), attr_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef form_sent(request, slug, template=\"forms/form_sent.html\"):\n    published = Form.objects.published(for_user=request.user)\n    context = {\"form\": get_object_or_404(published, slug=slug)}\n    return render_to_response(template, context, RequestContext(request))", "response": "Show the response message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nannotates the queryset with the entries count for use in the admin list view.", "response": "def get_queryset(self, request):\n        \"\"\"\n        Annotate the queryset with the entries count for use in the\n        admin list view.\n        \"\"\"\n        qs = super(FormAdmin, self).get_queryset(request)\n        return qs.annotate(total_entries=Count(\"entries\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the entries view to urls.", "response": "def get_urls(self):\n        \"\"\"\n        Add the entries view to urls.\n        \"\"\"\n        urls = super(FormAdmin, self).get_urls()\n        extra_urls = [\n            re_path(\"^(?P<form_id>\\d+)/entries/$\",\n                self.admin_site.admin_view(self.entries_view),\n                name=\"form_entries\"),\n            re_path(\"^(?P<form_id>\\d+)/entries/show/$\",\n                self.admin_site.admin_view(self.entries_view),\n                {\"show\": True}, name=\"form_entries_show\"),\n            re_path(\"^(?P<form_id>\\d+)/entries/export/$\",\n                self.admin_site.admin_view(self.entries_view),\n                {\"export\": True}, name=\"form_entries_export\"),\n            re_path(\"^file/(?P<field_entry_id>\\d+)/$\",\n                self.admin_site.admin_view(self.file_view),\n                name=\"form_file\"),\n        ]\n        return extra_urls + urls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef entries_view(self, request, form_id, show=False, export=False,\n                     export_xls=False):\n        \"\"\"\n        Displays the form entries in a HTML table with option to\n        export as CSV file.\n        \"\"\"\n        if request.POST.get(\"back\"):\n            bits = (self.model._meta.app_label, self.model.__name__.lower())\n            change_url = reverse(\"admin:%s_%s_change\" % bits, args=(form_id,))\n            return HttpResponseRedirect(change_url)\n        form = get_object_or_404(self.model, id=form_id)\n        post = request.POST or None\n        args = form, request, self.formentry_model, self.fieldentry_model, post\n        entries_form = EntriesForm(*args)\n        delete = \"%s.delete_formentry\" % self.formentry_model._meta.app_label\n        can_delete_entries = request.user.has_perm(delete)\n        submitted = entries_form.is_valid() or show or export or export_xls\n        export = export or request.POST.get(\"export\")\n        export_xls = export_xls or request.POST.get(\"export_xls\")\n        if submitted:\n            if export:\n                response = HttpResponse(content_type=\"text/csv\")\n                fname = \"%s-%s.csv\" % (form.slug, slugify(now().ctime()))\n                attachment = \"attachment; filename=%s\" % fname\n                response[\"Content-Disposition\"] = attachment\n                queue = StringIO()\n                try:\n                    csv = writer(queue, delimiter=CSV_DELIMITER)\n                    writerow = csv.writerow\n                except TypeError:\n                    queue = BytesIO()\n                    delimiter = bytes(CSV_DELIMITER, encoding=\"utf-8\")\n                    csv = writer(queue, delimiter=delimiter)\n                    writerow = lambda row: csv.writerow([c.encode(\"utf-8\")\n                        if hasattr(c, \"encode\") else c for c in row])\n                writerow(entries_form.columns())\n                for row in entries_form.rows(csv=True):\n                    writerow(row)\n                data = queue.getvalue()\n                response.write(data)\n                return response\n            elif XLWT_INSTALLED and export_xls:\n                response = HttpResponse(content_type=\"application/vnd.ms-excel\")\n                fname = \"%s-%s.xls\" % (form.slug, slugify(now().ctime()))\n                attachment = \"attachment; filename=%s\" % fname\n                response[\"Content-Disposition\"] = attachment\n                queue = BytesIO()\n                workbook = xlwt.Workbook(encoding='utf8')\n                sheet = workbook.add_sheet(form.title[:31])\n                for c, col in enumerate(entries_form.columns()):\n                    sheet.write(0, c, col)\n                for r, row in enumerate(entries_form.rows(csv=True)):\n                    for c, item in enumerate(row):\n                        if isinstance(item, datetime):\n                            item = item.replace(tzinfo=None)\n                            sheet.write(r + 2, c, item, XLWT_DATETIME_STYLE)\n                        else:\n                            sheet.write(r + 2, c, item)\n                workbook.save(queue)\n                data = queue.getvalue()\n                response.write(data)\n                return response\n            elif request.POST.get(\"delete\") and can_delete_entries:\n                selected = request.POST.getlist(\"selected\")\n                if selected:\n                    try:\n                        from django.contrib.messages import info\n                    except ImportError:\n                        def info(request, message, fail_silently=True):\n                            request.user.message_set.create(message=message)\n                    entries = self.formentry_model.objects.filter(id__in=selected)\n                    count = entries.count()\n                    if count > 0:\n                        entries.delete()\n                        message = ungettext(\"1 entry deleted\",\n                                            \"%(count)s entries deleted\", count)\n                        info(request, message % {\"count\": count})\n        template = \"admin/forms/entries.html\"\n        context = {\"title\": _(\"View Entries\"), \"entries_form\": entries_form,\n                   \"opts\": self.model._meta, \"original\": form,\n                   \"can_delete_entries\": can_delete_entries,\n                   \"submitted\": submitted,\n                   \"xlwt_installed\": XLWT_INSTALLED}\n        return render(request, template, context)", "response": "Displays the form entries in a HTML table with option toto\n        export as CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_view(self, request, field_entry_id):\n        model = self.fieldentry_model\n        field_entry = get_object_or_404(model, id=field_entry_id)\n        path = join(fs.location, field_entry.value)\n        response = HttpResponse(content_type=guess_type(path)[0])\n        f = open(path, \"r+b\")\n        response[\"Content-Disposition\"] = \"attachment; filename=%s\" % f.name\n        response.write(f.read())\n        f.close()\n        return response", "response": "Output the file for the requested field entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering a built - form.", "response": "def render_built_form(parser, token):\n    \"\"\"\n    render_build_form takes one argument in one of the following formats:\n\n    {% render_build_form form_instance %}\n    {% render_build_form form=form_instance %}\n    {% render_build_form id=form_instance.id %}\n    {% render_build_form slug=form_instance.slug %}\n\n    \"\"\"\n    try:\n        _, arg = token.split_contents()\n        if \"=\" not in arg:\n            arg = \"form=\" + arg\n        name, value = arg.split(\"=\", 1)\n        if name not in (\"form\", \"id\", \"slug\"):\n            raise ValueError\n    except ValueError:\n        e = ()\n        raise template.TemplateSyntaxError(render_built_form.__doc__)\n    return BuiltFormNode(name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get(self, url):\n        req = requests.get(RequestHandler.BASE_URL + url, headers=self.headers)\n        status_code = req.status_code\n        if status_code == requests.codes.ok:\n            return req\n        elif status_code == requests.codes.bad:\n            raise APIErrorException('Invalid request. Check parameters.')\n        elif status_code == requests.codes.forbidden:\n            raise APIErrorException('This resource is restricted')\n        elif status_code == requests.codes.not_found:\n            raise APIErrorException('This resource does not exist. Check parameters')\n        elif status_code == requests.codes.too_many_requests:\n            raise APIErrorException('You have exceeded your allowed requests per minute/day')", "response": "Handles api. football - data. org requests"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_live_scores(self, use_12_hour_format):\n        req = requests.get(RequestHandler.LIVE_URL)\n        if req.status_code == requests.codes.ok:\n            scores_data = []\n            scores = req.json()\n            if len(scores[\"games\"]) == 0:\n                click.secho(\"No live action currently\", fg=\"red\", bold=True)\n                return\n\n            for score in scores['games']:\n                # match football-data api structure\n                d = {}\n                d['homeTeam'] = {'name': score['homeTeamName']}\n                d['awayTeam'] = {'name': score['awayTeamName']}\n                d['score'] = {'fullTime': {'homeTeam': score['goalsHomeTeam'],\n                                           'awayTeam': score['goalsAwayTeam']}}\n                d['league'] = score['league']\n                d['time'] = score['time']\n                scores_data.append(d)\n            self.writer.live_scores(scores_data)\n        else:\n            click.secho(\"There was problem getting live scores\", fg=\"red\", bold=True)", "response": "Gets the live scores of the current user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_team_scores(self, team, time, show_upcoming, use_12_hour_format):\n        team_id = self.team_names.get(team, None)\n        time_frame = 'n' if show_upcoming else 'p'\n        if team_id:\n            try:\n                req = self._get('teams/{team_id}/matches?timeFrame={time_frame}{time}'.format(\n                            team_id=team_id, time_frame=time_frame, time=time))\n                team_scores = req.json()\n                if len(team_scores[\"matches\"]) == 0:\n                    click.secho(\"No action during past week. Change the time \"\n                                \"parameter to get more fixtures.\", fg=\"red\", bold=True)\n                else:\n                    self.writer.team_scores(team_scores, time, show_upcoming, use_12_hour_format)\n            except APIErrorException as e:\n                click.secho(e.args[0],\n                            fg=\"red\", bold=True)\n        else:\n            click.secho(\"Team code is not correct.\",\n                        fg=\"red\", bold=True)", "response": "Queries the API and gets the particular team scores"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the API and gets the standings for a particular league", "response": "def get_standings(self, league):\n        \"\"\"Queries the API and gets the standings for a particular league\"\"\"\n        league_id = self.league_ids[league]\n        try:\n            req = self._get('competitions/{id}/standings'.format(\n                        id=league_id))\n            self.writer.standings(req.json(), league)\n        except APIErrorException:\n            # Click handles incorrect League codes so this will only come up\n            # if that league does not have standings available. ie. Champions League\n            click.secho(\"No standings availble for {league}.\".format(league=league),\n                        fg=\"red\", bold=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_league_scores(self, league, time, show_upcoming, use_12_hour_format):\n\n        \"\"\"\n        Queries the API and fetches the scores for fixtures\n        based upon the league and time parameter\n        \"\"\"\n        time_frame = 'n' if show_upcoming else 'p'\n        if league:\n            try:\n                league_id = self.league_ids[league]\n                req = self._get('competitions/{id}/matches?timeFrame={time_frame}{time}'.format(\n                     id=league_id, time_frame=time_frame, time=str(time)))\n                fixtures_results = req.json()\n                # no fixtures in the past week. display a help message and return\n                if len(fixtures_results[\"matches\"]) == 0:\n                    click.secho(\"No {league} matches in the past week.\".format(league=league),\n                                fg=\"red\", bold=True)\n                    return\n                self.writer.league_scores(fixtures_results,\n                                          time, show_upcoming,\n                                          use_12_hour_format)\n            except APIErrorException:\n                click.secho(\"No data for the given league.\", fg=\"red\", bold=True)\n        else:\n            # When no league specified. Print all available in time frame.\n            try:\n                req = self._get('matches?timeFrame={time_frame}{time}'.format(\n                     time_frame=time_frame, time=str(time)))\n                fixtures_results = req.json()\n                self.writer.league_scores(fixtures_results,\n                                          time,\n                                          show_upcoming,\n                                          use_12_hour_format)\n            except APIErrorException:\n                click.secho(\"No data available.\", fg=\"red\", bold=True)", "response": "Queries the API and fetches the scores for fixtures based upon the league and time parameter\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the API and fetches the players for a particular team", "response": "def get_team_players(self, team):\n        \"\"\"\n        Queries the API and fetches the players\n        for a particular team\n        \"\"\"\n        team_id = self.team_names.get(team, None)\n        try:\n            req = self._get('teams/{}/'.format(team_id))\n            team_players = req.json()['squad']\n            if not team_players:\n                click.secho(\"No players found for this team\", fg=\"red\", bold=True)\n            else:\n                self.writer.team_players(team_players)\n        except APIErrorException:\n            click.secho(\"No data for the team. Please check the team code.\",\n                        fg=\"red\", bold=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_json(file):\n    here = os.path.dirname(os.path.abspath(__file__))\n    with open(os.path.join(here, file)) as jfile:\n        data = json.load(jfile)\n    return data", "response": "Load JSON file at app start"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninput API key and validate", "response": "def get_input_key():\n    \"\"\"Input API key and validate\"\"\"\n    click.secho(\"No API key found!\", fg=\"yellow\", bold=True)\n    click.secho(\"Please visit {} and get an API token.\".format(RequestHandler.BASE_URL),\n                fg=\"yellow\",\n                bold=True)\n    while True:\n        confkey = click.prompt(click.style(\"Enter API key\",\n                                           fg=\"yellow\", bold=True))\n        if len(confkey) == 32:  # 32 chars\n            try:\n                int(confkey, 16)  # hexadecimal\n            except ValueError:\n                click.secho(\"Invalid API key\", fg=\"red\", bold=True)\n            else:\n                break\n        else:\n            click.secho(\"Invalid API key\", fg=\"red\", bold=True)\n    return confkey"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads API key from config file write if needed", "response": "def load_config_key():\n    \"\"\"Load API key from config file, write if needed\"\"\"\n    global api_token\n    try:\n        api_token = os.environ['SOCCER_CLI_API_TOKEN']\n    except KeyError:\n        home = os.path.expanduser(\"~\")\n        config = os.path.join(home, \".soccer-cli.ini\")\n        if not os.path.exists(config):\n            with open(config, \"w\") as cfile:\n                key = get_input_key()\n                cfile.write(key)\n        else:\n            with open(config, \"r\") as cfile:\n                key = cfile.read()\n        if key:\n            api_token = key\n        else:\n            os.remove(config)  # remove 0-byte file\n            click.secho('No API Token detected. '\n                        'Please visit {0} and get an API Token, '\n                        'which will be used by Soccer CLI '\n                        'to get access to the data.'\n                        .format(RequestHandler.BASE_URL), fg=\"red\", bold=True)\n            sys.exit(1)\n    return api_token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_team_id(code):\n    for team in TEAM_DATA:\n        if team[\"code\"] == code:\n            click.secho(team[\"name\"], fg=\"green\")\n            break\n    else:\n        click.secho(\"No team found for this code\", fg=\"red\", bold=True)", "response": "Take in team ID read in JSON file to map ID to name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_team_codes():\n    # Sort teams by league, then alphabetical by code\n    cleanlist = sorted(TEAM_DATA, key=lambda k: (k[\"league\"][\"name\"], k[\"code\"]))\n    # Get league names\n    leaguenames = sorted(list(set([team[\"league\"][\"name\"] for team in cleanlist])))\n    for league in leaguenames:\n        teams = [team for team in cleanlist if team[\"league\"][\"name\"] == league]\n        click.secho(league, fg=\"green\", bold=True)\n        for team in teams:\n            if team[\"code\"] != \"null\":\n                click.secho(u\"{0}: {1}\".format(team[\"code\"], team[\"name\"]), fg=\"yellow\")\n        click.secho(\"\")", "response": "List team names in alphabetical order of team ID per league."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(league, time, standings, team, live, use12hour, players,\n         output_format, output_file, upcoming, lookup, listcodes, apikey):\n    \"\"\"\n    A CLI for live and past football scores from various football leagues.\n\n    League codes:\n\n    \\b\n    - WC: World Cup\n    - EC: European Championship\n    - CL: Champions League\n    - PL: English Premier League\n    - ELC: English Championship\n    - FL1: French Ligue 1\n    - BL: German Bundesliga\n    - SA: Serie A\n    - DED: Eredivisie\n    - PPL: Primeira Liga\n    - PD: Primera Division\n    - BSA: Brazil Serie A\n    \"\"\"\n    headers = {'X-Auth-Token': apikey}\n\n    try:\n        if output_format == 'stdout' and output_file:\n            raise IncorrectParametersException('Printing output to stdout and '\n                                               'saving to a file are mutually exclusive')\n        writer = get_writer(output_format, output_file)\n        rh = RequestHandler(headers, LEAGUE_IDS, TEAM_NAMES, writer)\n\n        if listcodes:\n            list_team_codes()\n            return\n\n        if live:\n            rh.get_live_scores(use12hour)\n            return\n\n        if standings:\n            if not league:\n                raise IncorrectParametersException('Please specify a league. '\n                                                   'Example --standings --league=PL')\n            if league == 'CL':\n                raise IncorrectParametersException('Standings for CL - '\n                                                   'Champions League not supported')\n            rh.get_standings(league)\n            return\n\n        if team:\n            if lookup:\n                map_team_id(team)\n                return\n            if players:\n                rh.get_team_players(team)\n                return\n            else:\n                rh.get_team_scores(team, time, upcoming, use12hour)\n                return\n\n        rh.get_league_scores(league, time, upcoming, use12hour)\n    except IncorrectParametersException as e:\n        click.secho(str(e), fg=\"red\", bold=True)", "response": "A function that returns the score of a specific league and a list of team scores."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef live_scores(self, live_scores):\n        scores = sorted(live_scores, key=lambda x: x[\"league\"])\n        for league, games in groupby(scores, key=lambda x: x[\"league\"]):\n            self.league_header(league)\n            for game in games:\n                self.scores(self.parse_result(game), add_new_line=False)\n                click.secho('   %s' % Stdout.utc_to_local(game[\"time\"],\n                                                          use_12_hour_format=False),\n                            fg=self.colors.TIME)\n                click.echo()", "response": "Prints the live scores in a pretty format"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the teams scores in a pretty format", "response": "def team_scores(self, team_scores, time, show_datetime, use_12_hour_format):\n        \"\"\"Prints the teams scores in a pretty format\"\"\"\n        for score in team_scores[\"matches\"]:\n            if score[\"status\"] == \"FINISHED\":\n                click.secho(\"%s\\t\" % score[\"utcDate\"].split('T')[0],\n                            fg=self.colors.TIME, nl=False)\n                self.scores(self.parse_result(score))\n            elif show_datetime:\n                self.scores(self.parse_result(score), add_new_line=False)\n                click.secho('   %s' % Stdout.utc_to_local(score[\"utcDate\"],\n                                                          use_12_hour_format,\n                                                          show_datetime),\n                            fg=self.colors.TIME)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the team players in a pretty format", "response": "def team_players(self, team):\n        \"\"\"Prints the team players in a pretty format\"\"\"\n        players = sorted(team, key=lambda d: d['shirtNumber'])\n        click.secho(\"%-4s %-25s    %-20s    %-20s    %-15s\" %\n                    (\"N.\",  \"NAME\", \"POSITION\", \"NATIONALITY\", \"BIRTHDAY\"),\n                    bold=True,\n                    fg=self.colors.MISC)\n        fmt = (u\"{shirtNumber:<4} {name:<28} {position:<23} {nationality:<23}\"\n               u\" {dateOfBirth:<18}\")\n        for player in players:\n            click.secho(fmt.format(**player), bold=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef standings(self, league_table, league):\n        click.secho(\"%-6s  %-30s    %-10s    %-10s    %-10s\" %\n                    (\"POS\", \"CLUB\", \"PLAYED\", \"GOAL DIFF\", \"POINTS\"))\n        for team in league_table[\"standings\"][0][\"table\"]:\n            if team[\"goalDifference\"] >= 0:\n                team[\"goalDifference\"] = ' ' + str(team[\"goalDifference\"])\n\n            # Define the upper and lower bounds for Champions League,\n            # Europa League and Relegation places.\n            # This is so we can highlight them appropriately.\n            cl_upper, cl_lower = LEAGUE_PROPERTIES[league]['cl']\n            el_upper, el_lower = LEAGUE_PROPERTIES[league]['el']\n            rl_upper, rl_lower = LEAGUE_PROPERTIES[league]['rl']\n            team['teamName'] = team['team']['name']\n            team_str = (u\"{position:<7} {teamName:<33} {playedGames:<12}\"\n                        u\" {goalDifference:<14} {points}\").format(**team)\n            if cl_upper <= team[\"position\"] <= cl_lower:\n                click.secho(team_str, bold=True, fg=self.colors.CL_POSITION)\n            elif el_upper <= team[\"position\"] <= el_lower:\n                click.secho(team_str, fg=self.colors.EL_POSITION)\n            elif rl_upper <= team[\"position\"] <= rl_lower:\n                click.secho(team_str, fg=self.colors.RL_POSITION)\n            else:\n                click.secho(team_str, fg=self.colors.POSITION)", "response": "Prints the standings of the league in a pretty way"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef league_scores(self, total_data, time, show_datetime,\n                      use_12_hour_format):\n        \"\"\"Prints the data in a pretty format\"\"\"\n        for match in total_data['matches']:\n            self.scores(self.parse_result(match), add_new_line=not show_datetime)\n            if show_datetime:\n                click.secho('   %s' % Stdout.utc_to_local(match[\"utcDate\"],\n                                                          use_12_hour_format,\n                                                          show_datetime),\n                            fg=self.colors.TIME)\n            click.echo()", "response": "Prints the data in a pretty format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint the league header", "response": "def league_header(self, league):\n        \"\"\"Prints the league header\"\"\"\n        league_name = \" {0} \".format(league)\n        click.secho(\"{:=^62}\".format(league_name), fg=self.colors.MISC)\n        click.echo()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint out the scores in a pretty format", "response": "def scores(self, result, add_new_line=True):\n        \"\"\"Prints out the scores in a pretty format\"\"\"\n        if result.goalsHomeTeam > result.goalsAwayTeam:\n            homeColor, awayColor = (self.colors.WIN, self.colors.LOSE)\n        elif result.goalsHomeTeam < result.goalsAwayTeam:\n            homeColor, awayColor = (self.colors.LOSE, self.colors.WIN)\n        else:\n            homeColor = awayColor = self.colors.TIE\n\n        click.secho('%-25s %2s' % (result.homeTeam, result.goalsHomeTeam),\n                    fg=homeColor, nl=False)\n        click.secho(\"  vs \", nl=False)\n        click.secho('%2s %s' % (result.goalsAwayTeam,\n                                result.awayTeam.rjust(25)), fg=awayColor,\n                    nl=add_new_line)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the results and returns a Result namedtuple", "response": "def parse_result(self, data):\n        \"\"\"Parses the results and returns a Result namedtuple\"\"\"\n        def valid_score(score):\n            return \"\" if score is None else score\n\n        return self.Result(\n            data[\"homeTeam\"][\"name\"],\n            valid_score(data[\"score\"][\"fullTime\"][\"homeTeam\"]),\n            data[\"awayTeam\"][\"name\"],\n            valid_score(data[\"score\"][\"fullTime\"][\"awayTeam\"]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the API UTC time string to the local user time.", "response": "def utc_to_local(time_str, use_12_hour_format, show_datetime=False):\n        \"\"\"Converts the API UTC time string to the local user time.\"\"\"\n        if not (time_str.endswith(\" UTC\") or time_str.endswith(\"Z\")):\n            return time_str\n\n        today_utc = datetime.datetime.utcnow()\n        utc_local_diff = today_utc - datetime.datetime.now()\n\n        if time_str.endswith(\" UTC\"):\n            time_str, _ = time_str.split(\" UTC\")\n            utc_time = datetime.datetime.strptime(time_str, '%I:%M %p')\n            utc_datetime = datetime.datetime(today_utc.year,\n                                             today_utc.month,\n                                             today_utc.day,\n                                             utc_time.hour,\n                                             utc_time.minute)\n        else:\n            utc_datetime = datetime.datetime.strptime(time_str,\n                                                      '%Y-%m-%dT%H:%M:%SZ')\n\n        local_time = utc_datetime - utc_local_diff\n\n        if use_12_hour_format:\n            date_format = '%I:%M %p' if not show_datetime else '%a %d, %I:%M %p'\n        else:\n            date_format = '%H:%M' if not show_datetime else '%a %d, %H:%M'\n\n        return datetime.datetime.strftime(local_time, date_format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore output of live scores to a CSV file", "response": "def live_scores(self, live_scores):\n        \"\"\"Store output of live scores to a CSV file\"\"\"\n        headers = ['League', 'Home Team Name', 'Home Team Goals',\n                   'Away Team Goals', 'Away Team Name']\n        result = [headers]\n        result.extend([game['league'], game['homeTeamName'],\n                       game['goalsHomeTeam'], game['goalsAwayTeam'],\n                       game['awayTeamName']] for game in live_scores['games'])\n        self.generate_output(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef team_scores(self, team_scores, time):\n        headers = ['Date', 'Home Team Name', 'Home Team Goals',\n                   'Away Team Goals', 'Away Team Name']\n        result = [headers]\n        result.extend([score[\"utcDate\"].split('T')[0],\n                       score['homeTeam']['name'],\n                       score['score']['fullTime']['homeTeam'],\n                       score['score']['fullTime']['awayTeam'],\n                       score['awayTeam']['name']]\n                      for score in team_scores['matches']\n                      if score['status'] == 'FINISHED')\n        self.generate_output(result)", "response": "Store output of team scores to a CSV file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores output of team players to a CSV file", "response": "def team_players(self, team):\n        \"\"\"Store output of team players to a CSV file\"\"\"\n        headers = ['Jersey Number', 'Name', 'Position', 'Nationality',\n                   'Date of Birth']\n        result = [headers]\n\n        result.extend([player['shirtNumber'],\n                       player['name'],\n                       player['position'],\n                       player['nationality'],\n                       player['dateOfBirth']]\n                      for player in team)\n        self.generate_output(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef standings(self, league_table, league):\n        headers = ['Position', 'Team Name', 'Games Played', 'Goal For',\n                   'Goals Against', 'Goal Difference', 'Points']\n        result = [headers]\n        result.extend([team['position'],\n                       team['team']['name'],\n                       team['playedGames'],\n                       team['goalsFor'],\n                       team['goalsAgainst'],\n                       team['goalDifference'],\n                       team['points']]\n                       for team in league_table['standings'][0]['table'])\n        self.generate_output(result)", "response": "Store output of league standings to a CSV file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef league_scores(self, total_data, time, show_upcoming, use_12_hour_format):\n        headers = ['League', 'Home Team Name', 'Home Team Goals',\n                   'Away Team Goals', 'Away Team Name']\n        result = [headers]\n        league = total_data['competition']['name']\n        result.extend([league,\n                       score['homeTeam']['name'],\n                       score['score']['fullTime']['homeTeam'],\n                       score['score']['fullTime']['awayTeam'],\n                        score['awayTeam']['name']]\n                       for score in total_data['matches'])\n        self.generate_output(result)", "response": "Store output of fixtures based on league and time"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef team_scores(self, team_scores, time):\n        data = []\n        for score in team_scores['matches']:\n            if score['status'] == 'FINISHED':\n                item = {'date': score[\"utcDate\"].split('T')[0],\n                        'homeTeamName': score['homeTeam']['name'],\n                        'goalsHomeTeam': score['score']['fullTime']['homeTeam'],\n                        'goalsAwayTeam': score['score']['fullTime']['awayTeam'],\n                        'awayTeamName': score['awayTeam']['name']}\n                data.append(item)\n        self.generate_output({'team_scores': data})", "response": "Store output of team scores to a JSON file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef standings(self, league_table, league):\n        data = []\n        for team in league_table['standings'][0]['table']:\n            item = {'position': team['position'],\n                    'teamName': team['team'],\n                    'playedGames': team['playedGames'],\n                    'goalsFor': team['goalsFor'],\n                    'goalsAgainst': team['goalsAgainst'],\n                    'goalDifference': team['goalDifference'],\n                    'points': team['points']}\n            data.append(item)\n        self.generate_output({'standings': data})", "response": "Store output of league standings to a JSON file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef team_players(self, team):\n        keys = 'shirtNumber name position nationality dateOfBirth'.split()\n        data = [{key: player[key] for key in keys} for player in team]\n        self.generate_output({'players': data})", "response": "Store output of team players to a JSON file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef league_scores(self, total_data, time):\n        data = []\n        for league, score in self.supported_leagues(total_data):\n            item = {'league': league, 'homeTeamName': score['homeTeamName'],\n                    'goalsHomeTeam': score['result']['goalsHomeTeam'],\n                    'goalsAwayTeam': score['result']['goalsAwayTeam'],\n                    'awayTeamName': score['awayTeamName']}\n            data.append(item)\n        self.generate_output({'league_scores': data, 'time': time})", "response": "Store output of fixtures based on league and time to a JSON file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a callback that can be used to visualize the evolution of the current plot.", "response": "def visual_callback_2d(background, fig=None):\n    \"\"\"\n    Returns a callback than can be passed as the argument `iter_callback`\n    of `morphological_geodesic_active_contour` and\n    `morphological_chan_vese` for visualizing the evolution\n    of the levelsets. Only works for 2D images.\n    \n    Parameters\n    ----------\n    background : (M, N) array\n        Image to be plotted as the background of the visual evolution.\n    fig : matplotlib.figure.Figure\n        Figure where results will be drawn. If not given, a new figure\n        will be created.\n    \n    Returns\n    -------\n    callback : Python function\n        A function that receives a levelset and updates the current plot\n        accordingly. This can be passed as the `iter_callback` argument of\n        `morphological_geodesic_active_contour` and\n        `morphological_chan_vese`.\n    \n    \"\"\"\n    \n    # Prepare the visual environment.\n    if fig is None:\n        fig = plt.figure()\n    fig.clf()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax1.imshow(background, cmap=plt.cm.gray)\n\n    ax2 = fig.add_subplot(1, 2, 2)\n    ax_u = ax2.imshow(np.zeros_like(background), vmin=0, vmax=1)\n    plt.pause(0.001)\n\n    def callback(levelset):\n        \n        if ax1.collections:\n            del ax1.collections[0]\n        ax1.contour(levelset, [0.5], colors='r')\n        ax_u.set_data(levelset)\n        fig.canvas.draw()\n        plt.pause(0.001)\n\n    return callback"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that returns a function that updates the current plot of the evolution of the current levelset.", "response": "def visual_callback_3d(fig=None, plot_each=1):\n    \"\"\"\n    Returns a callback than can be passed as the argument `iter_callback`\n    of `morphological_geodesic_active_contour` and\n    `morphological_chan_vese` for visualizing the evolution\n    of the levelsets. Only works for 3D images.\n    \n    Parameters\n    ----------\n    fig : matplotlib.figure.Figure\n        Figure where results will be drawn. If not given, a new figure\n        will be created.\n    plot_each : positive integer\n        The plot will be updated once every `plot_each` calls to the callback\n        function.\n    \n    Returns\n    -------\n    callback : Python function\n        A function that receives a levelset and updates the current plot\n        accordingly. This can be passed as the `iter_callback` argument of\n        `morphological_geodesic_active_contour` and\n        `morphological_chan_vese`.\n    \n    \"\"\"\n    \n    from mpl_toolkits.mplot3d import Axes3D\n    # PyMCubes package is required for `visual_callback_3d`\n    try:\n        import mcubes\n    except ImportError:\n        raise ImportError(\"PyMCubes is required for 3D `visual_callback_3d`\")\n    \n    # Prepare the visual environment.\n    if fig is None:\n        fig = plt.figure()\n    fig.clf()\n    ax = fig.add_subplot(111, projection='3d')\n    plt.pause(0.001)\n    \n    counter = [-1]\n\n    def callback(levelset):\n\n        counter[0] += 1\n        if (counter[0] % plot_each) != 0:\n            return\n\n        if ax.collections:\n            del ax.collections[0]\n\n        coords, triangles = mcubes.marching_cubes(levelset, 0.5)\n        ax.plot_trisurf(coords[:, 0], coords[:, 1], coords[:, 2],\n                        triangles=triangles)\n        plt.pause(0.1)\n\n    return callback"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef example_camera():\n    \n    logging.info('Running: example_camera (MorphACWE)...')\n\n    # Load the image.\n    img = imread(PATH_IMG_CAMERA)/255.0\n\n    # Callback for visual plotting\n    callback = visual_callback_2d(img)\n\n    # Morphological Chan-Vese (or ACWE)\n    ms.morphological_chan_vese(img, 35,\n                               smoothing=3, lambda1=1, lambda2=1,\n                               iter_callback=callback)", "response": "Example with Morphological Chan - Vese or ACWE initialization."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gborders(img, alpha=1.0, sigma=1.0):\n    # The norm of the gradient.\n    gradnorm = gaussian_gradient_magnitude(img, sigma, mode='constant')\n    return 1.0/np.sqrt(1.0 + alpha*gradnorm)", "response": "Stopping criterion for image borders."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evolve_visual3d(msnake, fig=None, levelset=None, num_iters=20,\n                    animate_ui=True, animate_delay=250):\n    \"\"\"\n    Visual evolution of a three-dimensional morphological snake.\n    \n    Parameters\n    ----------\n    msnake : MorphGAC or MorphACWE instance\n        The morphological snake solver.\n    fig: object, optional\n        Handles to actual figure.\n    levelset : array-like, optional\n        If given, the levelset of the solver is initialized to this. If not\n        given, the evolution will use the levelset already set in msnake.\n    num_iters : int, optional\n        The number of iterations.\n    animate_ui : bool, optional\n        Show the animation interface\n    animate_delay : int, optional\n        The number of delay between frames.\n    \"\"\"\n    from mayavi import mlab\n\n    if levelset is not None:\n        msnake.levelset = levelset\n\n    if fig is None:\n        fig = mlab.gcf()\n    mlab.clf()\n    src = mlab.pipeline.scalar_field(msnake.data)\n    mlab.pipeline.image_plane_widget(src, plane_orientation='x_axes', colormap='gray')\n    cnt = mlab.contour3d(msnake.levelset, contours=[0.5])\n    \n    @mlab.animate(ui=animate_ui, delay=animate_delay)\n    def anim():\n        for i in range(num_iters):\n            msnake.step()\n            cnt.mlab_source.scalars = msnake.levelset\n            print(\"Iteration %i/%i...\" % (i + 1, num_iters))\n            yield\n    \n    anim()\n    mlab.show()\n    \n    # Return the last levelset.\n    return msnake.levelset", "response": "Visual evolution of a 3D morphological snake."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a single step of the morphological Chan - Vese evolution.", "response": "def step(self):\n        \"\"\"Perform a single step of the morphological Chan-Vese evolution.\"\"\"\n        # Assign attributes to local variables for convenience.\n        u = self._u\n        \n        if u is None:\n            raise ValueError(\"the levelset function is not set \"\n                             \"(use set_levelset)\")\n        \n        data = self.data\n        \n        # Determine c0 and c1.\n        inside = (u > 0)\n        outside = (u <= 0)\n        c0 = data[outside].sum() / float(outside.sum())\n        c1 = data[inside].sum() / float(inside.sum())\n        \n        # Image attachment.\n        dres = np.array(np.gradient(u))\n        abs_dres = np.abs(dres).sum(0)\n        #aux = abs_dres * (c0 - c1) * (c0 + c1 - 2*data)\n        aux = abs_dres * (self.lambda1*(data - c1) ** 2 -\n                          self.lambda2*(data - c0) ** 2)\n        \n        res = np.copy(u)\n        res[aux < 0] = 1\n        res[aux > 0] = 0\n        \n        # Smoothing.\n        for i in range(self.smoothing):\n            res = curvop(res)\n        \n        self._u = res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_mask(self):\n        self._threshold_mask = self._data > self._theta\n        self._threshold_mask_v = self._data > self._theta/np.abs(self._v)", "response": "Update the mask for speed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a single step of the morphological snake evolution.", "response": "def step(self):\n        \"\"\"Perform a single step of the morphological snake evolution.\"\"\"\n        # Assign attributes to local variables for convenience.\n        u = self._u\n        gI = self._data\n        dgI = self._ddata\n        theta = self._theta\n        v = self._v\n        \n        if u is None:\n            raise ValueError(\"the levelset is not set (use set_levelset)\")\n        \n        res = np.copy(u)\n        \n        # Balloon.\n        if v > 0:\n            aux = binary_dilation(u, self.structure)\n        elif v < 0:\n            aux = binary_erosion(u, self.structure)\n        if v!= 0:\n            res[self._threshold_mask_v] = aux[self._threshold_mask_v]\n        \n        # Image attachment.\n        aux = np.zeros_like(res)\n        dres = np.gradient(res)\n        for el1, el2 in zip(dgI, dres):\n            aux += el1*el2\n        res[aux > 0] = 1\n        res[aux < 0] = 0\n        \n        # Smoothing.\n        for i in range(self.smoothing):\n            res = curvop(res)\n        \n        self._u = res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inf_sup(u):\n\n    if np.ndim(u) == 2:\n        P = _P2\n    elif np.ndim(u) == 3:\n        P = _P3\n    else:\n        raise ValueError(\"u has an invalid number of dimensions \"\n                         \"(should be 2 or 3)\")\n\n    dilations = []\n    for P_i in P:\n        dilations.append(ndi.binary_dilation(u, P_i))\n\n    return np.array(dilations, dtype=np.int8).min(0)", "response": "IS operator. Returns the inf superset of u."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_input(image, init_level_set):\n    if not image.ndim in [2, 3]:\n        raise ValueError(\"`image` must be a 2 or 3-dimensional array.\")\n\n    if len(image.shape) != len(init_level_set.shape):\n        raise ValueError(\"The dimensions of the initial level set do not \"\n                         \"match the dimensions of the image.\")", "response": "Check that the input image and init_level_set match."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a circle level set with binary values.", "response": "def circle_level_set(image_shape, center=None, radius=None):\n    \"\"\"Create a circle level set with binary values.\n\n    Parameters\n    ----------\n    image_shape : tuple of positive integers\n        Shape of the image\n    center : tuple of positive integers, optional\n        Coordinates of the center of the circle given in (row, column). If not\n        given, it defaults to the center of the image.\n    radius : float, optional\n        Radius of the circle. If not given, it is set to the 75% of the\n        smallest image dimension.\n\n    Returns\n    -------\n    out : array with shape `image_shape`\n        Binary level set of the circle with the given `radius` and `center`.\n\n    See also\n    --------\n    checkerboard_level_set\n    \"\"\"\n\n    if center is None:\n        center = tuple(i // 2 for i in image_shape)\n\n    if radius is None:\n        radius = min(image_shape) * 3.0 / 8.0\n\n    grid = np.mgrid[[slice(i) for i in image_shape]]\n    grid = (grid.T - center).T\n    phi = radius - np.sqrt(np.sum((grid)**2, 0))\n    res = np.int8(phi > 0)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a checkerboard level set with binary values.", "response": "def checkerboard_level_set(image_shape, square_size=5):\n    \"\"\"Create a checkerboard level set with binary values.\n\n    Parameters\n    ----------\n    image_shape : tuple of positive integers\n        Shape of the image.\n    square_size : int, optional\n        Size of the squares of the checkerboard. It defaults to 5.\n\n    Returns\n    -------\n    out : array with shape `image_shape`\n        Binary level set of the checkerboard.\n\n    See also\n    --------\n    circle_level_set\n    \"\"\"\n\n    grid = np.ogrid[[slice(i) for i in image_shape]]\n    grid = [(grid_i // square_size) & 1 for grid_i in grid]\n\n    checkerboard = np.bitwise_xor.reduce(grid, axis=0)\n    res = np.int8(checkerboard)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inverse_gaussian_gradient(image, alpha=100.0, sigma=5.0):\n    gradnorm = ndi.gaussian_gradient_magnitude(image, sigma, mode='nearest')\n    return 1.0 / np.sqrt(1.0 + alpha * gradnorm)", "response": "Inverse of gradient magnitude."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef morphological_geodesic_active_contour(gimage, iterations,\n                                          init_level_set='circle', smoothing=1,\n                                          threshold='auto', balloon=0,\n                                          iter_callback=lambda x: None):\n    \"\"\"Morphological Geodesic Active Contours (MorphGAC).\n\n    Geodesic active contours implemented with morphological operators. It can\n    be used to segment objects with visible but noisy, cluttered, broken\n    borders.\n\n    Parameters\n    ----------\n    gimage : (M, N) or (L, M, N) array\n        Preprocessed image or volume to be segmented. This is very rarely the\n        original image. Instead, this is usually a preprocessed version of the\n        original image that enhances and highlights the borders (or other\n        structures) of the object to segment.\n        `morphological_geodesic_active_contour` will try to stop the contour\n        evolution in areas where `gimage` is small. See\n        `morphsnakes.inverse_gaussian_gradient` as an example function to\n        perform this preprocessing. Note that the quality of\n        `morphological_geodesic_active_contour` might greatly depend on this\n        preprocessing.\n    iterations : uint\n        Number of iterations to run.\n    init_level_set : str, (M, N) array, or (L, M, N) array\n        Initial level set. If an array is given, it will be binarized and used\n        as the initial level set. If a string is given, it defines the method\n        to generate a reasonable initial level set with the shape of the\n        `image`. Accepted values are 'checkerboard' and 'circle'. See the\n        documentation of `checkerboard_level_set` and `circle_level_set`\n        respectively for details about how these level sets are created.\n    smoothing : uint, optional\n        Number of times the smoothing operator is applied per iteration.\n        Reasonable values are around 1-4. Larger values lead to smoother\n        segmentations.\n    threshold : float, optional\n        Areas of the image with a value smaller than this threshold will be\n        considered borders. The evolution of the contour will stop in this\n        areas.\n    balloon : float, optional\n        Balloon force to guide the contour in non-informative areas of the\n        image, i.e., areas where the gradient of the image is too small to push\n        the contour towards a border. A negative value will shrink the contour,\n        while a positive value will expand the contour in these areas. Setting\n        this to zero will disable the balloon force.\n    iter_callback : function, optional\n        If given, this function is called once per iteration with the current\n        level set as the only argument. This is useful for debugging or for\n        plotting intermediate results during the evolution.\n\n    Returns\n    -------\n    out : (M, N) or (L, M, N) array\n        Final segmentation (i.e., the final level set)\n\n    See also\n    --------\n    inverse_gaussian_gradient, circle_level_set, checkerboard_level_set\n\n    Notes\n    -----\n\n    This is a version of the Geodesic Active Contours (GAC) algorithm that uses\n    morphological operators instead of solving partial differential equations\n    (PDEs) for the evolution of the contour. The set of morphological operators\n    used in this algorithm are proved to be infinitesimally equivalent to the\n    GAC PDEs (see [1]_). However, morphological operators are do not suffer\n    from the numerical stability issues typically found in PDEs (e.g., it is\n    not necessary to find the right time step for the evolution), and are\n    computationally faster.\n\n    The algorithm and its theoretical derivation are described in [1]_.\n\n    References\n    ----------\n    .. [1] A Morphological Approach to Curvature-based Evolution of Curves and\n           Surfaces, Pablo M\u00e1rquez-Neila, Luis Baumela, Luis \u00c1lvarez. In IEEE\n           Transactions on Pattern Analysis and Machine Intelligence (PAMI),\n           2014, DOI 10.1109/TPAMI.2013.106\n    \"\"\"\n\n    image = gimage\n    init_level_set = _init_level_set(init_level_set, image.shape)\n\n    _check_input(image, init_level_set)\n\n    if threshold == 'auto':\n        threshold = np.percentile(image, 40)\n\n    structure = np.ones((3,) * len(image.shape), dtype=np.int8)\n    dimage = np.gradient(image)\n    # threshold_mask = image > threshold\n    if balloon != 0:\n        threshold_mask_balloon = image > threshold / np.abs(balloon)\n\n    u = np.int8(init_level_set > 0)\n\n    iter_callback(u)\n\n    for _ in range(iterations):\n\n        # Balloon\n        if balloon > 0:\n            aux = ndi.binary_dilation(u, structure)\n        elif balloon < 0:\n            aux = ndi.binary_erosion(u, structure)\n        if balloon != 0:\n            u[threshold_mask_balloon] = aux[threshold_mask_balloon]\n\n        # Image attachment\n        aux = np.zeros_like(image)\n        du = np.gradient(u)\n        for el1, el2 in zip(dimage, du):\n            aux += el1 * el2\n        u[aux > 0] = 1\n        u[aux < 0] = 0\n\n        # Smoothing\n        for _ in range(smoothing):\n            u = _curvop(u)\n\n        iter_callback(u)\n\n    return u", "response": "This function generates a tree of morphological active contours for a given image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_handler(self, *args, **options):\n        handler = super(Command, self).get_handler(*args, **options)\n        insecure_serving = options.get('insecure_serving', False)\n        if self.should_use_static_handler(options):\n            return StaticFilesHandler(handler)\n        return handler", "response": "Returns the handler wrapping the default handler if static files should be served. Otherwise just returns the default handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt(self, password, kdf=None, iterations=None):\n        '''\n        Generate a string with the encrypted key, as in\n        :meth:`~eth_account.account.Account.encrypt`, but without a private key argument.\n        '''\n        return self._publicapi.encrypt(self.privateKey, password, kdf=kdf, iterations=iterations)", "response": "Generate a string with the encrypted key as in\n        but without a private key argument."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef defunct_hash_message(\n        primitive=None,\n        *,\n        hexstr=None,\n        text=None,\n        signature_version=b'E',\n        version_specific_data=None):\n    '''\n    Convert the provided message into a message hash, to be signed.\n    This provides the same prefix and hashing approach as\n    :meth:`w3.eth.sign() <web3.eth.Eth.sign>`.\n    Currently you can only specify the ``signature_version`` as following.\n\n    * **Version** ``0x45`` (version ``E``):  ``b'\\\\x19Ethereum Signed Message:\\\\n'``\n      concatenated with the number of bytes in the message.\n\n        .. note:: This is the defualt version followed, if the signature_version is not specified.\n\n    * **Version** ``0x00`` (version ``0``): Sign data with intended validator (EIP 191).\n      Here the version_specific_data would be a hexstr which is the 20 bytes account address\n      of the intended validator.\n\n    For version ``0x45`` (version ``E``), Awkwardly, the number of bytes in the message is\n    encoded in decimal ascii. So if the message is 'abcde', then the length is encoded as the ascii\n    character '5'. This is one of the reasons that this message format is not preferred.\n    There is ambiguity when the message '00' is encoded, for example.\n    Only use this method with version ``E`` if you must have compatibility with\n    :meth:`w3.eth.sign() <web3.eth.Eth.sign>`.\n\n    Supply exactly one of the three arguments:\n    bytes, a hex string, or a unicode string.\n\n    :param primitive: the binary message to be signed\n    :type primitive: bytes or int\n    :param str hexstr: the message encoded as hex\n    :param str text: the message as a series of unicode characters (a normal Py3 str)\n    :param bytes signature_version: a byte indicating which kind of prefix is to be added (EIP 191)\n    :param version_specific_data: the data which is related to the prefix (EIP 191)\n    :returns: The hash of the message, after adding the prefix\n    :rtype: ~hexbytes.main.HexBytes\n\n    .. code-block:: python\n\n        >>> from eth_account.messages import defunct_hash_message\n\n        >>> msg = \"I\u2665SF\"\n        >>> defunct_hash_message(text=msg)\n        HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750')\n\n        # these four also produce the same hash:\n        >>> defunct_hash_message(w3.toBytes(text=msg))\n        HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750')\n\n        >>> defunct_hash_message(bytes(msg, encoding='utf-8'))\n        HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750')\n\n        >>> Web3.toHex(text=msg)\n        '0x49e299a55346'\n        >>> defunct_hash_message(hexstr='0x49e299a55346')\n        HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750')\n\n        >>> defunct_hash_message(0x49e299a55346)\n        HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750')\n    '''\n    message_bytes = to_bytes(primitive, hexstr=hexstr, text=text)\n    recovery_hasher = compose(\n        HexBytes,\n        keccak,\n        signature_wrapper(\n            signature_version=signature_version,\n            version_specific_data=version_specific_data,\n        )\n    )\n    return recovery_hasher(message_bytes)", "response": "This function returns the message hash for the given binary message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new private key and returns it as a : class : ~eth_account. local. LocalAccount.", "response": "def create(self, extra_entropy=''):\n        '''\n        Creates a new private key, and returns it as a :class:`~eth_account.local.LocalAccount`.\n\n        :param extra_entropy: Add extra randomness to whatever randomness your OS can provide\n        :type extra_entropy: str or bytes or int\n        :returns: an object with private key and convenience methods\n\n        .. code-block:: python\n\n            >>> from eth_account import Account\n            >>> acct = Account.create('KEYSMASH FJAFJKLDSKF7JKFDJ 1530')\n            >>> acct.address\n            '0x5ce9454909639D2D17A3F753ce7d93fa0b9aB12E'\n            >>> acct.privateKey\n            b\"\\\\xb2\\\\}\\\\xb3\\\\x1f\\\\xee\\\\xd9\\\\x12''\\\\xbf\\\\t9\\\\xdcv\\\\x9a\\\\x96VK-\\\\xe4\\\\xc4rm\\\\x03[6\\\\xec\\\\xf1\\\\xe5\\\\xb3d\"\n\n            # These methods are also available: signHash(), signTransaction(), encrypt()\n            # They correspond to the same-named methods in Account.*\n            # but without the private key argument\n        '''\n        extra_key_bytes = text_if_str(to_bytes, extra_entropy)\n        key_bytes = keccak(os.urandom(32) + extra_key_bytes)\n        return self.privateKeyToAccount(key_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt(keyfile_json, password):\n        '''\n        Decrypts a private key that was encrypted using an Ethereum client or\n        :meth:`~Account.encrypt`.\n\n        :param keyfile_json: The encrypted key\n        :type keyfile_json: dict or str\n        :param str password: The password that was used to encrypt the key\n        :returns: the raw private key\n        :rtype: ~hexbytes.main.HexBytes\n\n        .. code-block:: python\n\n            >>> encrypted = {\n             'address': '5ce9454909639d2d17a3f753ce7d93fa0b9ab12e',\n             'crypto': {'cipher': 'aes-128-ctr',\n              'cipherparams': {'iv': '78f214584844e0b241b433d7c3bb8d5f'},\n              'ciphertext': 'd6dbb56e4f54ba6db2e8dc14df17cb7352fdce03681dd3f90ce4b6c1d5af2c4f',\n              'kdf': 'pbkdf2',\n              'kdfparams': {'c': 1000000,\n               'dklen': 32,\n               'prf': 'hmac-sha256',\n               'salt': '45cf943b4de2c05c2c440ef96af914a2'},\n              'mac': 'f5e1af09df5ded25c96fcf075ada313fb6f79735a914adc8cb02e8ddee7813c3'},\n             'id': 'b812f3f9-78cc-462a-9e89-74418aa27cb0',\n             'version': 3}\n\n            >>> import getpass\n            >>> Account.decrypt(encrypted, getpass.getpass())\n            HexBytes('0xb25c7db31feed9122727bf0939dc769a96564b2de4c4726d035b36ecf1e5b364')\n\n        '''\n        if isinstance(keyfile_json, str):\n            keyfile = json.loads(keyfile_json)\n        elif is_dict(keyfile_json):\n            keyfile = keyfile_json\n        else:\n            raise TypeError(\"The keyfile should be supplied as a JSON string, or a dictionary.\")\n        password_bytes = text_if_str(to_bytes, password)\n        return HexBytes(decode_keyfile_json(keyfile, password_bytes))", "response": "Decrypts a private key that was encrypted using an Ethereum client or a user - supplied password."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a dictionary with an encrypted version of your private key. To import this keyfile into Ethereum clients like geth and parity: encode this dictionary with :func:`json.dumps` and save it to disk where your client keeps key files. :param private_key: The raw private key :type private_key: hex str, bytes, int or :class:`eth_keys.datatypes.PrivateKey` :param str password: The password which you will need to unlock the account in your client :param str kdf: The key derivation function to use when encrypting your private key :param int iterations: The work factor for the key derivation function :returns: The data to use in your encrypted file :rtype: dict .. code-block:: python >>> import getpass >>> encrypted = Account.encrypt( 0xb25c7db31feed9122727bf0939dc769a96564b2de4c4726d035b36ecf1e5b364, getpass.getpass() ) { 'address': '5ce9454909639d2d17a3f753ce7d93fa0b9ab12e', 'crypto': { 'cipher': 'aes-128-ctr', 'cipherparams': { 'iv': '0b7845a5c3597d3d378bde9b7c7319b7' }, 'ciphertext': 'a494f1feb3c854e99c1ff01e6aaa17d43c0752009073503b908457dc8de5d2a5', # noqa: E501 'kdf': 'scrypt', 'kdfparams': { 'dklen': 32, 'n': 262144, 'p': 8, 'r': 1, 'salt': '13c4a48123affaa29189e9097726c698' }, 'mac': 'f4cfb027eb0af9bd7a320b4374a3fa7bef02cfbafe0ec5d1fd7ad129401de0b1' }, 'id': 'a60e0578-0e5b-4a75-b991-d55ec6451a6f', 'version': 3 } >>> with open('my-keyfile', 'w') as f: f.write(json.dumps(encrypted))", "response": "def encrypt(cls, private_key, password, kdf=None, iterations=None):\n        '''\n        Creates a dictionary with an encrypted version of your private key.\n        To import this keyfile into Ethereum clients like geth and parity:\n        encode this dictionary with :func:`json.dumps` and save it to disk where your\n        client keeps key files.\n\n        :param private_key: The raw private key\n        :type private_key: hex str, bytes, int or :class:`eth_keys.datatypes.PrivateKey`\n        :param str password: The password which you will need to unlock the account in your client\n        :param str kdf: The key derivation function to use when encrypting your private key\n        :param int iterations: The work factor for the key derivation function\n        :returns: The data to use in your encrypted file\n        :rtype: dict\n\n        .. code-block:: python\n\n            >>> import getpass\n            >>> encrypted = Account.encrypt(\n                0xb25c7db31feed9122727bf0939dc769a96564b2de4c4726d035b36ecf1e5b364,\n                getpass.getpass()\n            )\n\n            {\n                'address': '5ce9454909639d2d17a3f753ce7d93fa0b9ab12e',\n                'crypto': {\n                    'cipher': 'aes-128-ctr',\n                    'cipherparams': {\n                        'iv': '0b7845a5c3597d3d378bde9b7c7319b7'\n                    },\n                    'ciphertext': 'a494f1feb3c854e99c1ff01e6aaa17d43c0752009073503b908457dc8de5d2a5',  # noqa: E501\n                    'kdf': 'scrypt',\n                    'kdfparams': {\n                        'dklen': 32,\n                        'n': 262144,\n                        'p': 8,\n                        'r': 1,\n                        'salt': '13c4a48123affaa29189e9097726c698'\n                    },\n                    'mac': 'f4cfb027eb0af9bd7a320b4374a3fa7bef02cfbafe0ec5d1fd7ad129401de0b1'\n                },\n                'id': 'a60e0578-0e5b-4a75-b991-d55ec6451a6f',\n                'version': 3\n            }\n\n             >>> with open('my-keyfile', 'w') as f:\n                 f.write(json.dumps(encrypted))\n        '''\n        if isinstance(private_key, keys.PrivateKey):\n            key_bytes = private_key.to_bytes()\n        else:\n            key_bytes = HexBytes(private_key)\n\n        if kdf is None:\n            kdf = cls.default_kdf\n\n        password_bytes = text_if_str(to_bytes, password)\n        assert len(key_bytes) == 32\n\n        return create_keyfile_json(key_bytes, password_bytes, kdf=kdf, iterations=iterations)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a convenient object for working with the given private key.", "response": "def privateKeyToAccount(self, private_key):\n        '''\n        Returns a convenient object for working with the given private key.\n\n        :param private_key: The raw private key\n        :type private_key: hex str, bytes, int or :class:`eth_keys.datatypes.PrivateKey`\n        :return: object with methods for signing and encrypting\n        :rtype: LocalAccount\n\n        .. code-block:: python\n\n            >>> acct = Account.privateKeyToAccount(\n              0xb25c7db31feed9122727bf0939dc769a96564b2de4c4726d035b36ecf1e5b364)\n            >>> acct.address\n            '0x5ce9454909639D2D17A3F753ce7d93fa0b9aB12E'\n            >>> acct.privateKey\n            b\"\\\\xb2\\\\}\\\\xb3\\\\x1f\\\\xee\\\\xd9\\\\x12''\\\\xbf\\\\t9\\\\xdcv\\\\x9a\\\\x96VK-\\\\xe4\\\\xc4rm\\\\x03[6\\\\xec\\\\xf1\\\\xe5\\\\xb3d\"\n\n            # These methods are also available: signHash(), signTransaction(), encrypt()\n            # They correspond to the same-named methods in Account.*\n            # but without the private key argument\n        '''\n        key = self._parsePrivateKey(private_key)\n        return LocalAccount(key, self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the address of the account that signed the message with the given hash. You must specify exactly one of: vrs or signature :param message_hash: the hash of the message that you want to verify :type message_hash: hex str or bytes or int :param vrs: the three pieces generated by an elliptic curve signature :type vrs: tuple(v, r, s), each element is hex str, bytes or int :param signature: signature bytes concatenated as r+s+v :type signature: hex str or bytes or int :returns: address of signer, hex-encoded & checksummed :rtype: str .. code-block:: python >>> msg = \"I\u2665SF\" >>> msghash = '0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750' >>> vrs = ( 28, '0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb3', '0x3e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce') >>> Account.recoverHash(msghash, vrs=vrs) '0x5ce9454909639D2D17A3F753ce7d93fa0b9aB12E' # All of these recover calls are equivalent: # variations on msghash >>> msghash = b\"\\\\x14v\\\\xab\\\\xb7E\\\\xd4#\\\\xbf\\\\t'?\\\\x1a\\\\xfd\\\\x88}\\\\x95\\\\x11\\\\x81\\\\xd2Z\\\\xdcf\\\\xc4\\\\x83JpI\\\\x19\\\\x11\\\\xb7\\\\xf7P\" # noqa: E501 >>> Account.recoverHash(msghash, vrs=vrs) >>> msghash = 0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750 >>> Account.recoverHash(msghash, vrs=vrs) # variations on vrs >>> vrs = ( '0x1c', '0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb3', '0x3e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce') >>> Account.recoverHash(msghash, vrs=vrs) >>> vrs = ( b'\\\\x1c', b'\\\\xe6\\\\xca\\\\x9b\\\\xbaX\\\\xc8\\\\x86\\\\x11\\\\xfa\\\\xd6jl\\\\xe8\\\\xf9\\\\x96\\\\x90\\\\x81\\\\x95Y8\\\\x07\\\\xc4\\\\xb3\\\\x8b\\\\xd5(\\\\xd2\\\\xcf\\\\xf0\\\\x9dN\\\\xb3', # noqa: E501 b'>[\\\\xfb\\\\xbfM>9\\\\xb1\\\\xa2\\\\xfd\\\\x81jv\\\\x80\\\\xc1\\\\x9e\\\\xbe\\\\xba\\\\xf3\\\\xa1A\\\\xb29\\\\x93J\\\\xd4<\\\\xb3?\\\\xce\\\\xc8\\\\xce') # noqa: E501 >>> Account.recoverHash(msghash, vrs=vrs) >>> vrs = ( 0x1c, 0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb3, 0x3e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce) >>> Account.recoverHash(msghash, vrs=vrs) # variations on signature >>> signature = '0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb33e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce1c' # noqa: E501 >>> Account.recoverHash(msghash, signature=signature) >>> signature = b'\\\\xe6\\\\xca\\\\x9b\\\\xbaX\\\\xc8\\\\x86\\\\x11\\\\xfa\\\\xd6jl\\\\xe8\\\\xf9\\\\x96\\\\x90\\\\x81\\\\x95Y8\\\\x07\\\\xc4\\\\xb3\\\\x8b\\\\xd5(\\\\xd2\\\\xcf\\\\xf0\\\\x9dN\\\\xb3>[\\\\xfb\\\\xbfM>9\\\\xb1\\\\xa2\\\\xfd\\\\x81jv\\\\x80\\\\xc1\\\\x9e\\\\xbe\\\\xba\\\\xf3\\\\xa1A\\\\xb29\\\\x93J\\\\xd4<\\\\xb3?\\\\xce\\\\xc8\\\\xce\\\\x1c' # noqa: E501 >>> Account.recoverHash(msghash, signature=signature) >>> signature = 0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb33e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce1c # noqa: E501 >>> Account.recoverHash(msghash, signature=signature)", "response": "def recoverHash(self, message_hash, vrs=None, signature=None):\n        '''\n        Get the address of the account that signed the message with the given hash.\n        You must specify exactly one of: vrs or signature\n\n        :param message_hash: the hash of the message that you want to verify\n        :type message_hash: hex str or bytes or int\n        :param vrs: the three pieces generated by an elliptic curve signature\n        :type vrs: tuple(v, r, s), each element is hex str, bytes or int\n        :param signature: signature bytes concatenated as r+s+v\n        :type signature: hex str or bytes or int\n        :returns: address of signer, hex-encoded & checksummed\n        :rtype: str\n\n        .. code-block:: python\n\n            >>> msg = \"I\u2665SF\"\n            >>> msghash = '0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750'\n            >>> vrs = (\n                  28,\n                  '0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb3',\n                  '0x3e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce')\n            >>> Account.recoverHash(msghash, vrs=vrs)\n            '0x5ce9454909639D2D17A3F753ce7d93fa0b9aB12E'\n\n            # All of these recover calls are equivalent:\n\n            # variations on msghash\n            >>> msghash = b\"\\\\x14v\\\\xab\\\\xb7E\\\\xd4#\\\\xbf\\\\t'?\\\\x1a\\\\xfd\\\\x88}\\\\x95\\\\x11\\\\x81\\\\xd2Z\\\\xdcf\\\\xc4\\\\x83JpI\\\\x19\\\\x11\\\\xb7\\\\xf7P\"  # noqa: E501\n            >>> Account.recoverHash(msghash, vrs=vrs)\n            >>> msghash = 0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750\n            >>> Account.recoverHash(msghash, vrs=vrs)\n\n            # variations on vrs\n            >>> vrs = (\n                  '0x1c',\n                  '0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb3',\n                  '0x3e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce')\n            >>> Account.recoverHash(msghash, vrs=vrs)\n            >>> vrs = (\n                  b'\\\\x1c',\n                  b'\\\\xe6\\\\xca\\\\x9b\\\\xbaX\\\\xc8\\\\x86\\\\x11\\\\xfa\\\\xd6jl\\\\xe8\\\\xf9\\\\x96\\\\x90\\\\x81\\\\x95Y8\\\\x07\\\\xc4\\\\xb3\\\\x8b\\\\xd5(\\\\xd2\\\\xcf\\\\xf0\\\\x9dN\\\\xb3',  # noqa: E501\n                  b'>[\\\\xfb\\\\xbfM>9\\\\xb1\\\\xa2\\\\xfd\\\\x81jv\\\\x80\\\\xc1\\\\x9e\\\\xbe\\\\xba\\\\xf3\\\\xa1A\\\\xb29\\\\x93J\\\\xd4<\\\\xb3?\\\\xce\\\\xc8\\\\xce')  # noqa: E501\n            >>> Account.recoverHash(msghash, vrs=vrs)\n            >>> vrs = (\n                  0x1c,\n                  0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb3,\n                  0x3e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce)\n            >>> Account.recoverHash(msghash, vrs=vrs)\n\n            # variations on signature\n            >>> signature = '0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb33e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce1c'  # noqa: E501\n            >>> Account.recoverHash(msghash, signature=signature)\n            >>> signature = b'\\\\xe6\\\\xca\\\\x9b\\\\xbaX\\\\xc8\\\\x86\\\\x11\\\\xfa\\\\xd6jl\\\\xe8\\\\xf9\\\\x96\\\\x90\\\\x81\\\\x95Y8\\\\x07\\\\xc4\\\\xb3\\\\x8b\\\\xd5(\\\\xd2\\\\xcf\\\\xf0\\\\x9dN\\\\xb3>[\\\\xfb\\\\xbfM>9\\\\xb1\\\\xa2\\\\xfd\\\\x81jv\\\\x80\\\\xc1\\\\x9e\\\\xbe\\\\xba\\\\xf3\\\\xa1A\\\\xb29\\\\x93J\\\\xd4<\\\\xb3?\\\\xce\\\\xc8\\\\xce\\\\x1c'  # noqa: E501\n            >>> Account.recoverHash(msghash, signature=signature)\n            >>> signature = 0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb33e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce1c  # noqa: E501\n            >>> Account.recoverHash(msghash, signature=signature)\n        '''\n        hash_bytes = HexBytes(message_hash)\n        if len(hash_bytes) != 32:\n            raise ValueError(\"The message hash must be exactly 32-bytes\")\n        if vrs is not None:\n            v, r, s = map(hexstr_if_str(to_int), vrs)\n            v_standard = to_standard_v(v)\n            signature_obj = self._keys.Signature(vrs=(v_standard, r, s))\n        elif signature is not None:\n            signature_bytes = HexBytes(signature)\n            signature_bytes_standard = to_standard_signature_bytes(signature_bytes)\n            signature_obj = self._keys.Signature(signature_bytes=signature_bytes_standard)\n        else:\n            raise TypeError(\"You must supply the vrs tuple or the signature bytes\")\n        pubkey = signature_obj.recover_public_key_from_msg_hash(hash_bytes)\n        return pubkey.to_checksum_address()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the address of the account that signed this transaction. :param serialized_transaction: the complete signed transaction :type serialized_transaction: hex str, bytes or int :returns: address of signer, hex-encoded & checksummed :rtype: str .. code-block:: python >>> raw_transaction = '0xf86a8086d55698372431831e848094f0109fc8df283027b6285cc889f5aa624eac1f55843b9aca008025a009ebb6ca057a0535d6186462bc0b465b561c94a295bdb0621fc19208ab149a9ca0440ffd775ce91a833ab410777204d5341a6f9fa91216a6f3ee2c051fea6a0428', # noqa: E501 >>> Account.recoverTransaction(raw_transaction) '0x2c7536E3605D9C16a7a3D7b1898e529396a65c23'", "response": "def recoverTransaction(self, serialized_transaction):\n        '''\n        Get the address of the account that signed this transaction.\n\n        :param serialized_transaction: the complete signed transaction\n        :type serialized_transaction: hex str, bytes or int\n        :returns: address of signer, hex-encoded & checksummed\n        :rtype: str\n\n        .. code-block:: python\n\n            >>> raw_transaction = '0xf86a8086d55698372431831e848094f0109fc8df283027b6285cc889f5aa624eac1f55843b9aca008025a009ebb6ca057a0535d6186462bc0b465b561c94a295bdb0621fc19208ab149a9ca0440ffd775ce91a833ab410777204d5341a6f9fa91216a6f3ee2c051fea6a0428',  # noqa: E501\n            >>> Account.recoverTransaction(raw_transaction)\n            '0x2c7536E3605D9C16a7a3D7b1898e529396a65c23'\n        '''\n        txn_bytes = HexBytes(serialized_transaction)\n        txn = Transaction.from_bytes(txn_bytes)\n        msg_hash = hash_of_signed_transaction(txn)\n        return self.recoverHash(msg_hash, vrs=vrs_from(txn))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef signHash(self, message_hash, private_key):\n        '''\n        Sign the hash provided.\n\n        .. WARNING:: *Never* sign a hash that you didn't generate,\n            it can be an arbitrary transaction. For example, it might\n            send all of your account's ether to an attacker.\n\n        If you would like compatibility with\n        :meth:`w3.eth.sign() <web3.eth.Eth.sign>`\n        you can use :meth:`~eth_account.messages.defunct_hash_message`.\n\n        Several other message standards are proposed, but none have a clear\n        consensus. You'll need to manually comply with any of those message standards manually.\n\n        :param message_hash: the 32-byte message hash to be signed\n        :type message_hash: hex str, bytes or int\n        :param private_key: the key to sign the message with\n        :type private_key: hex str, bytes, int or :class:`eth_keys.datatypes.PrivateKey`\n        :returns: Various details about the signature - most\n          importantly the fields: v, r, and s\n        :rtype: ~eth_account.datastructures.AttributeDict\n\n        .. code-block:: python\n\n            >>> msg = \"I\u2665SF\"\n            >>> from eth_account.messages import defunct_hash_message\n            >>> msghash = defunct_hash_message(text=msg)\n            HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750')\n            >>> key = \"0xb25c7db31feed9122727bf0939dc769a96564b2de4c4726d035b36ecf1e5b364\"\n            >>> Account.signHash(msghash, key)\n            {'messageHash': HexBytes('0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750'),  # noqa: E501\n             'r': 104389933075820307925104709181714897380569894203213074526835978196648170704563,\n             's': 28205917190874851400050446352651915501321657673772411533993420917949420456142,\n             'signature': HexBytes('0xe6ca9bba58c88611fad66a6ce8f996908195593807c4b38bd528d2cff09d4eb33e5bfbbf4d3e39b1a2fd816a7680c19ebebaf3a141b239934ad43cb33fcec8ce1c'),  # noqa: E501\n             'v': 28}\n\n            # these are equivalent:\n            >>> Account.signHash(\n                0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750,\n                key\n            )\n            >>> Account.signHash(\n                \"0x1476abb745d423bf09273f1afd887d951181d25adc66c4834a70491911b7f750\",\n                key\n            )\n        '''\n        msg_hash_bytes = HexBytes(message_hash)\n        if len(msg_hash_bytes) != 32:\n            raise ValueError(\"The message hash must be exactly 32-bytes\")\n\n        key = self._parsePrivateKey(private_key)\n\n        (v, r, s, eth_signature_bytes) = sign_message_hash(key, msg_hash_bytes)\n        return AttributeDict({\n            'messageHash': msg_hash_bytes,\n            'r': r,\n            's': s,\n            'v': v,\n            'signature': HexBytes(eth_signature_bytes),\n        })", "response": "Signs the message with the given message hash and returns the signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsigns a transaction using a local private key.", "response": "def signTransaction(self, transaction_dict, private_key):\n        '''\n        Sign a transaction using a local private key. Produces signature details\n        and the hex-encoded transaction suitable for broadcast using\n        :meth:`w3.eth.sendRawTransaction() <web3.eth.Eth.sendRawTransaction>`.\n\n        Create the transaction dict for a contract method with\n        `my_contract.functions.my_function().buildTransaction()\n        <http://web3py.readthedocs.io/en/latest/contracts.html#methods>`_\n\n        :param dict transaction_dict: the transaction with keys:\n          nonce, chainId, to, data, value, gas, and gasPrice.\n        :param private_key: the private key to sign the data with\n        :type private_key: hex str, bytes, int or :class:`eth_keys.datatypes.PrivateKey`\n        :returns: Various details about the signature - most\n          importantly the fields: v, r, and s\n        :rtype: AttributeDict\n\n        .. code-block:: python\n\n            >>> transaction = {\n                    # Note that the address must be in checksum format or native bytes:\n                    'to': '0xF0109fC8DF283027b6285cc889F5aA624EaC1F55',\n                    'value': 1000000000,\n                    'gas': 2000000,\n                    'gasPrice': 234567897654321,\n                    'nonce': 0,\n                    'chainId': 1\n                }\n            >>> key = '0x4c0883a69102937d6231471b5dbb6204fe5129617082792ae468d01a3f362318'\n            >>> signed = Account.signTransaction(transaction, key)\n            {'hash': HexBytes('0x6893a6ee8df79b0f5d64a180cd1ef35d030f3e296a5361cf04d02ce720d32ec5'),\n             'r': 4487286261793418179817841024889747115779324305375823110249149479905075174044,\n             'rawTransaction': HexBytes('0xf86a8086d55698372431831e848094f0109fc8df283027b6285cc889f5aa624eac1f55843b9aca008025a009ebb6ca057a0535d6186462bc0b465b561c94a295bdb0621fc19208ab149a9ca0440ffd775ce91a833ab410777204d5341a6f9fa91216a6f3ee2c051fea6a0428'),  # noqa: E501\n             's': 30785525769477805655994251009256770582792548537338581640010273753578382951464,\n             'v': 37}\n            >>> w3.eth.sendRawTransaction(signed.rawTransaction)\n        '''\n        if not isinstance(transaction_dict, Mapping):\n            raise TypeError(\"transaction_dict must be dict-like, got %r\" % transaction_dict)\n\n        account = self.privateKeyToAccount(private_key)\n\n        # allow from field, *only* if it matches the private key\n        if 'from' in transaction_dict:\n            if transaction_dict['from'] == account.address:\n                sanitized_transaction = dissoc(transaction_dict, 'from')\n            else:\n                raise TypeError(\"from field must match key's %s, but it was %s\" % (\n                    account.address,\n                    transaction_dict['from'],\n                ))\n        else:\n            sanitized_transaction = transaction_dict\n\n        # sign transaction\n        (\n            v,\n            r,\n            s,\n            rlp_encoded,\n        ) = sign_transaction_dict(account._key_obj, sanitized_transaction)\n\n        transaction_hash = keccak(rlp_encoded)\n\n        return AttributeDict({\n            'rawTransaction': HexBytes(rlp_encoded),\n            'hash': HexBytes(transaction_hash),\n            'r': r,\n            's': s,\n            'v': v,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parsePrivateKey(self, key):\n        '''\n        Generate a :class:`eth_keys.datatypes.PrivateKey` from the provided key. If the\n        key is already of type :class:`eth_keys.datatypes.PrivateKey`, return the key.\n\n        :param key: the private key from which a :class:`eth_keys.datatypes.PrivateKey`\n                    will be generated\n        :type key: hex str, bytes, int or :class:`eth_keys.datatypes.PrivateKey`\n        :returns: the provided key represented as a :class:`eth_keys.datatypes.PrivateKey`\n        '''\n        if isinstance(key, self._keys.PrivateKey):\n            return key\n\n        try:\n            return self._keys.PrivateKey(HexBytes(key))\n        except ValidationError as original_exception:\n            raise ValueError(\n                \"The private key must be exactly 32 bytes long, instead of \"\n                \"%d bytes.\" % len(key)\n            ) from original_exception", "response": "Parse a private key from the provided key and return the key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming DFS to get all the dependencies of the primary_type", "response": "def get_dependencies(primary_type, types):\n    \"\"\"\n    Perform DFS to get all the dependencies of the primary_type\n    \"\"\"\n    deps = set()\n    struct_names_yet_to_be_expanded = [primary_type]\n\n    while len(struct_names_yet_to_be_expanded) > 0:\n        struct_name = struct_names_yet_to_be_expanded.pop()\n\n        deps.add(struct_name)\n        fields = types[struct_name]\n        for field in fields:\n            if field[\"type\"] not in types:\n                # We don't need to expand types that are not user defined (customized)\n                continue\n            elif field[\"type\"] in deps:\n                # skip types that we have already encountered\n                continue\n            else:\n                # Custom Struct Type\n                struct_names_yet_to_be_expanded.append(field[\"type\"])\n\n    # Don't need to make a struct as dependency of itself\n    deps.remove(primary_type)\n\n    return tuple(deps)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode_type(primary_type, types):\n    # Getting the dependencies and sorting them alphabetically as per EIP712\n    deps = get_dependencies(primary_type, types)\n    sorted_deps = (primary_type,) + tuple(sorted(deps))\n\n    result = ''.join(\n        [\n            encode_struct(struct_name, types[struct_name])\n            for struct_name in sorted_deps\n        ]\n    )\n    return result", "response": "Encodes a type into a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid_abi_type(type_name):\n    valid_abi_types = {\"address\", \"bool\", \"bytes\", \"int\", \"string\", \"uint\"}\n    is_bytesN = type_name.startswith(\"bytes\") and 1 <= int(type_name[5:]) <= 32\n    is_intN = (\n        type_name.startswith(\"int\") and\n        8 <= int(type_name[3:]) <= 256 and\n        int(type_name[3:]) % 8 == 0\n    )\n    is_uintN = (\n        type_name.startswith(\"uint\") and\n        8 <= int(type_name[4:]) <= 256 and\n        int(type_name[4:]) % 8 == 0\n    )\n\n    if type_name in valid_abi_types:\n        return True\n    elif is_bytesN:\n        # bytes1 to bytes32\n        return True\n    elif is_intN:\n        # int8 to int256\n        return True\n    elif is_uintN:\n        # uint8 to uint256\n        return True\n\n    return False", "response": "This function is used to make sure that the type_name is a valid ABI Type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields 2 - length tuples of depth and dimension of each element at that depth", "response": "def get_depths_and_dimensions(data, depth):\n    \"\"\"\n    Yields 2-length tuples of depth and dimension of each element at that depth\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        # Not checking for Iterable instance, because even Dictionaries and strings\n        # are considered as iterables, but that's not what we want the condition to be.\n        return ()\n\n    yield depth, len(data)\n\n    for item in data:\n        # iterating over all 1 dimension less sub-data items\n        yield from get_depths_and_dimensions(item, depth + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive an array type data item check that it is an array and return the dimensions as a tuple.", "response": "def get_array_dimensions(data):\n    \"\"\"\n    Given an array type data item, check that it is an array and\n    return the dimensions as a tuple.\n    Ex: get_array_dimensions([[1, 2, 3], [4, 5, 6]]) returns (2, 3)\n    \"\"\"\n    depths_and_dimensions = get_depths_and_dimensions(data, 0)\n    # re-form as a dictionary with `depth` as key, and all of the dimensions found at that depth.\n    grouped_by_depth = {\n        depth: tuple(dimension for depth, dimension in group)\n        for depth, group in groupby(depths_and_dimensions, itemgetter(0))\n    }\n\n    # validate that there is only one dimension for any given depth.\n    invalid_depths_dimensions = tuple(\n        (depth, dimensions)\n        for depth, dimensions in grouped_by_depth.items()\n        if len(set(dimensions)) != 1\n    )\n    if invalid_depths_dimensions:\n        raise ValidationError(\n            '\\n'.join(\n                [\n                    \"Depth {0} of array data has more than one dimensions: {1}\".\n                    format(depth, dimensions)\n                    for depth, dimensions in invalid_depths_dimensions\n                ]\n            )\n        )\n\n    dimensions = tuple(\n        toolz.first(set(dimensions))\n        for depth, dimensions in sorted(grouped_by_depth.items())\n    )\n\n    return dimensions"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregenerates the hash of the signed transaction object.", "response": "def hash_of_signed_transaction(txn_obj):\n    '''\n    Regenerate the hash of the signed transaction object.\n\n    1. Infer the chain ID from the signature\n    2. Strip out signature from transaction\n    3. Annotate the transaction with that ID, if available\n    4. Take the hash of the serialized, unsigned, chain-aware transaction\n\n    Chain ID inference and annotation is according to EIP-155\n    See details at https://github.com/ethereum/EIPs/blob/master/EIPS/eip-155.md\n\n    :return: the hash of the provided transaction, to be signed\n    '''\n    (chain_id, _v) = extract_chain_id(txn_obj.v)\n    unsigned_parts = strip_signature(txn_obj)\n    if chain_id is None:\n        signable_transaction = UnsignedTransaction(*unsigned_parts)\n    else:\n        extended_transaction = unsigned_parts + [chain_id, 0, 0]\n        signable_transaction = ChainAwareUnsignedTransaction(*extended_transaction)\n    return signable_transaction.hash()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting chain ID according to EIP - 151.", "response": "def extract_chain_id(raw_v):\n    '''\n    Extracts chain ID, according to EIP-155\n    @return (chain_id, v)\n    '''\n    above_id_offset = raw_v - CHAIN_ID_OFFSET\n    if above_id_offset < 0:\n        if raw_v in {0, 1}:\n            return (None, raw_v + V_OFFSET)\n        elif raw_v in {27, 28}:\n            return (None, raw_v)\n        else:\n            raise ValueError(\"v %r is invalid, must be one of: 0, 1, 27, 28, 35+\")\n    else:\n        (chain_id, v_bit) = divmod(above_id_offset, 2)\n        return (chain_id, v_bit + V_OFFSET)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying a nice table with occurrences and action buttons.", "response": "def daily_table(context, day, start=8, end=20, increment=30):\n    \"\"\"\n      Display a nice table with occurrences and action buttons.\n      Arguments:\n      start - hour at which the day starts\n      end - hour at which the day ends\n      increment - size of a time slot (in minutes)\n    \"\"\"\n    user = context['request'].user\n    addable = CHECK_EVENT_PERM_FUNC(None, user)\n    if 'calendar' in context:\n        addable = addable and CHECK_CALENDAR_PERM_FUNC(context['calendar'], user)\n    context['addable'] = addable\n    day_part = day.get_time_slot(day.start + datetime.timedelta(hours=start), day.start + datetime.timedelta(hours=end))\n    # get slots to display on the left\n    slots = _cook_slots(day_part, increment)\n    context['slots'] = slots\n    return context"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the list of time slots to be displayed on the left hand side", "response": "def _cook_slots(period, increment):\n    \"\"\"\n        Prepare slots to be displayed on the left hand side\n        calculate dimensions (in px) for each slot.\n        Arguments:\n        period - time period for the whole series\n        increment - slot size in minutes\n    \"\"\"\n    tdiff = datetime.timedelta(minutes=increment)\n    num = int((period.end - period.start).total_seconds()) // int(tdiff.total_seconds())\n    s = period.start\n    slots = []\n    for i in range(num):\n        sl = period.get_time_slot(s, s + tdiff)\n        slots.append(sl)\n        s = s + tdiff\n    return slots"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_occurrence(event_id, occurrence_id=None, year=None, month=None,\n                   day=None, hour=None, minute=None, second=None,\n                   tzinfo=None):\n    \"\"\"\n    Because occurrences don't have to be persisted, there must be two ways to\n    retrieve them. both need an event, but if its persisted the occurrence can\n    be retrieved with an id. If it is not persisted it takes a date to\n    retrieve it.  This function returns an event and occurrence regardless of\n    which method is used.\n    \"\"\"\n    if(occurrence_id):\n        occurrence = get_object_or_404(Occurrence, id=occurrence_id)\n        event = occurrence.event\n    elif None not in (year, month, day, hour, minute, second):\n        event = get_object_or_404(Event, id=event_id)\n        date = timezone.make_aware(datetime.datetime(int(year), int(month),\n                                   int(day), int(hour), int(minute),\n                                   int(second)), tzinfo)\n        occurrence = event.get_occurrence(date)\n        if occurrence is None:\n            raise Http404\n    else:\n        raise Http404\n    return event, occurrence", "response": "This function returns an event and occurrence object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the url to redirect to after the event is deleted", "response": "def get_success_url(self):\n        \"\"\"\n        After the event is deleted there are three options for redirect, tried in\n        this order:\n        # Try to find a 'next' GET variable\n        # If the key word argument redirect is set\n        # Lastly redirect to the event detail of the recently create event\n        \"\"\"\n        url_val = 'fullcalendar' if USE_FULLCALENDAR else 'day_calendar'\n        next_url = self.kwargs.get('next') or reverse(url_val, args=[self.object.calendar.slug])\n        next_url = get_next_url(self.request, next_url)\n        return next_url"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_calendar_for_object(self, obj, distinction=''):\n        calendar_list = self.get_calendars_for_object(obj, distinction)\n        if len(calendar_list) == 0:\n            raise Calendar.DoesNotExist(\"Calendar does not exist.\")\n        elif len(calendar_list) > 1:\n            raise AssertionError(\"More than one calendars were found.\")\n        else:\n            return calendar_list[0]", "response": "This function returns the calendar for the given object. It should only return one calendar for the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_or_create_calendar_for_object(self, obj, distinction='', name=None):\n        try:\n            return self.get_calendar_for_object(obj, distinction)\n        except Calendar.DoesNotExist:\n            if name is None:\n                calendar = self.model(name=str(obj))\n            else:\n                calendar = self.model(name=name)\n            calendar.slug = slugify(calendar.name)\n            calendar.save()\n            calendar.create_relation(obj, distinction)\n            return calendar", "response": "Get or create a Calendar for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_calendars_for_object(self, obj, distinction=''):\n        ct = ContentType.objects.get_for_model(obj)\n        if distinction:\n            dist_q = Q(calendarrelation__distinction=distinction)\n        else:\n            dist_q = Q()\n        return self.filter(dist_q, calendarrelation__content_type=ct, calendarrelation__object_id=obj.id)", "response": "This function allows you to get calendars for a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_relation(self, calendar, content_object, distinction='', inheritable=True):\n        return CalendarRelation.objects.create(\n            calendar=calendar,\n            distinction=distinction,\n            content_object=content_object)", "response": "Creates a relation between a calendar and a content object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncoerce a dictionary into a tuple that represents a date.", "response": "def coerce_date_dict(date_dict):\n    \"\"\"\n    given a dictionary (presumed to be from request.GET) it returns a tuple\n    that represents a date. It will return from year down to seconds until one\n    is not found.  ie if year, month, and seconds are in the dictionary, only\n    year and month will be returned, the rest will be returned as min. If none\n    of the parts are found return an empty tuple.\n    \"\"\"\n    keys = ['year', 'month', 'day', 'hour', 'minute', 'second']\n    ret_val = {\n        'year': 1,\n        'month': 1,\n        'day': 1,\n        'hour': 0,\n        'minute': 0,\n        'second': 0}\n    modified = False\n    for key in keys:\n        try:\n            ret_val[key] = int(date_dict[key])\n            modified = True\n        except KeyError:\n            break\n    return modified and ret_val or {}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef occurrences_after(self, after=None):\n        from schedule.models import Occurrence\n\n        if after is None:\n            after = timezone.now()\n        occ_replacer = OccurrenceReplacer(\n            Occurrence.objects.filter(event__in=self.events))\n        generators = [event._occurrences_after_generator(after) for event in self.events]\n        occurrences = []\n\n        for generator in generators:\n            try:\n                heapq.heappush(occurrences, (next(generator), generator))\n            except StopIteration:\n                pass\n\n        while occurrences:\n            generator = occurrences[0][1]\n\n            try:\n                next_occurrence = heapq.heapreplace(occurrences, (next(generator), generator))[0]\n            except StopIteration:\n                next_occurrence = heapq.heappop(occurrences)[0]\n            yield occ_replacer.get_occurrence(next_occurrence)", "response": "This function returns a generator that yields the most recent occurrence after the given date."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of persisted occurrences which are now in the period", "response": "def get_additional_occurrences(self, start, end):\n        \"\"\"\n        Return persisted occurrences which are now in the period\n        \"\"\"\n        return [occ for _, occ in list(self.lookup.items()) if (occ.start < end and occ.end >= start and not occ.cancelled)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_events_for_object(self, content_object, distinction='', inherit=True):\n        '''\n        returns a queryset full of events, that relate to the object through, the\n        distinction\n\n        If inherit is false it will not consider the calendars that the events\n        belong to. If inherit is true it will inherit all of the relations and\n        distinctions that any calendar that it belongs to has, as long as the\n        relation has inheritable set to True.  (See Calendar)\n\n        >>> event = Event.objects.get(title='Test1')\n        >>> user = User.objects.get(username = 'alice')\n        >>> EventRelation.objects.get_events_for_object(user, 'owner', inherit=False)\n        [<Event: Test1: Tuesday, Jan. 1, 2008-Friday, Jan. 11, 2008>]\n\n        If a distinction is not declared it will not vet the relations based on\n        distinction.\n        >>> EventRelation.objects.get_events_for_object(user, inherit=False)\n        [<Event: Test1: Tuesday, Jan. 1, 2008-Friday, Jan. 11, 2008>, <Event: Test2: Tuesday, Jan. 1, 2008-Friday, Jan. 11, 2008>]\n\n        Now if there is a Calendar\n        >>> calendar = Calendar(name = 'MyProject')\n        >>> calendar.save()\n\n        And an event that belongs to that calendar\n        >>> event = Event.objects.get(title='Test2')\n        >>> calendar.events.add(event)\n\n        If we relate this calendar to some object with inheritable set to true,\n        that relation will be inherited\n        >>> user = User.objects.get(username='bob')\n        >>> cr = calendar.create_relation(user, 'viewer', True)\n        >>> EventRelation.objects.get_events_for_object(user, 'viewer')\n        [<Event: Test1: Tuesday, Jan. 1, 2008-Friday, Jan. 11, 2008>, <Event: Test2: Tuesday, Jan. 1, 2008-Friday, Jan. 11, 2008>]\n        '''\n        ct = ContentType.objects.get_for_model(type(content_object))\n        if distinction:\n            dist_q = Q(eventrelation__distinction=distinction)\n            cal_dist_q = Q(calendar__calendarrelation__distinction=distinction)\n        else:\n            dist_q = Q()\n            cal_dist_q = Q()\n        if inherit:\n            inherit_q = Q(\n                cal_dist_q,\n                calendar__calendarrelation__content_type=ct,\n                calendar__calendarrelation__object_id=content_object.id,\n                calendar__calendarrelation__inheritable=True,\n            )\n        else:\n            inherit_q = Q()\n        event_q = Q(dist_q, eventrelation__content_type=ct, eventrelation__object_id=content_object.id)\n        return Event.objects.filter(inherit_q | event_q)", "response": "Returns a queryset of events that relate to the object through the specified distinction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_relation(self, event, content_object, distinction=''):\n        return EventRelation.objects.create(\n            event=event,\n            distinction=distinction,\n            content_object=content_object)", "response": "Creates a relation between event and content_object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npopulates a small db with some example entries.", "response": "def init_db():\n    \"\"\"\n    Populate a small db with some example entries.\n    \"\"\"\n    db.drop_all()\n    db.create_all()\n\n    # Create sample Post\n    title = \"de Finibus Bonorum et Malorum - Part I\"\n    text = \"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor \\\n                incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud \\\n                exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure \\\n                dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. \\\n                Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt \\\n                mollit anim id est laborum.\"\n\n    post = Post(title=title, text=text)\n    db.session.add(post)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a upload failed response for CKEditor > = 4. 5.", "response": "def upload_fail(message=None):\n    \"\"\"Return a upload failed response, for CKEditor >= 4.5.\n    For example::\n\n        from flask import send_from_directory\n        from flask_ckeditor import upload_success, upload_fail\n        \n        app.config['CKEDITOR_FILE_UPLOADER'] = 'upload'  # this value can be endpoint or url\n\n\n        @app.route('/files/<path:filename>')\n        def uploaded_files(filename):\n            path = '/the/uploaded/directory'\n            return send_from_directory(path, filename)\n\n        @app.route('/upload', methods=['POST'])\n        def upload():\n            f = request.files.get('upload')\n            if extension not in ['jpg', 'gif', 'png', 'jpeg']:\n                return upload_fail(message='Image only!')  # <--\n            f.save(os.path.join('/the/uploaded/directory', f.filename))\n            url = url_for('uploaded_files', filename=f.filename)\n            return upload_success(url=url)\n\n    :param message: error message.\n\n    .. versionadded:: 0.4.0\n    \"\"\"\n    if message is None:\n        message = current_app.config['CKEDITOR_UPLOAD_ERROR_MESSAGE']\n    return jsonify(uploaded=0, error={'message': message})"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads CKEditor resource from CDN or local.", "response": "def load(custom_url=None, pkg_type=None, serve_local=None, version='4.9.2'):\n        \"\"\"Load CKEditor resource from CDN or local.\n\n        :param custom_url: The custom resource url to use, build your CKEditor\n            on `CKEditor builder <https://ckeditor.com/cke4/builder>`_.\n        :param pkg_type: The type of CKEditor package, one of ``basic``,\n            ``standard`` and ``full``. Default to ``standard``. It's a\n            mirror argument to overwrite ``CKEDITOR_PKG_TYPE``.\n        :param serve_local: Mirror argument to overwrite ``CKEDITOR_SERVE_LOCAL``.\n        :param version: The version of CKEditor.\n        \"\"\"\n        pkg_type = pkg_type or current_app.config['CKEDITOR_PKG_TYPE']\n\n        if pkg_type not in ['basic', 'standard', 'full']:\n            warnings.warn('The provided pkg_type string was invalid, '\n                          'it should be one of basic/standard/full.')\n            pkg_type = 'standard'\n\n        if serve_local or current_app.config['CKEDITOR_SERVE_LOCAL']:\n            url = url_for('ckeditor.static', filename='%s/ckeditor.js' % pkg_type)\n        else:\n            url = '//cdn.ckeditor.com/%s/%s/ckeditor.js' % (version, pkg_type)\n\n        if custom_url:\n            url = custom_url\n        return Markup('<script src=\"%s\"></script>' % url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_code_theme():\n        theme = current_app.config['CKEDITOR_CODE_THEME']\n        js_url = url_for('ckeditor.static',\n                         filename='basic/plugins/codesnippet/lib/highlight/highlight.pack.js')\n        css_url = url_for('ckeditor.static',\n                          filename='basic/plugins/codesnippet/lib/highlight/styles/%s.css' % theme)\n        return Markup('''<link href=\"%s\" rel=\"stylesheet\">\\n<script src=\"%s\"></script>\\n\n            <script>hljs.initHighlightingOnLoad();</script>''' % (css_url, js_url))", "response": "Highlight the code snippets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uploader(func):\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            func_num = request.args.get('CKEditorFuncNum')\n            # ckeditor = request.args.get('CKEditor')\n            # language code used for error message, not used yet.\n            # lang_code = request.args.get('langCode')\n            # the error message to display when upload failed.\n            message = current_app.config['CKEDITOR_UPLOAD_ERROR_MESSAGE']\n            url = func(*args, **kwargs)\n            return Markup('''<script type=\"text/javascript\">\n        window.parent.CKEDITOR.tools.callFunction(%s, \"%s\", \"%s\");</script>''' % (func_num, url, message))\n\n        return wrapper", "response": "Decorator for file uploader view function that handles file upload."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect the available wlan interfaces.", "response": "def interfaces(self):\n        \"\"\"Collect the available wlan interfaces.\"\"\"\n\n        self._ifaces = []\n        wifi_ctrl = wifiutil.WifiUtil()\n\n        for interface in wifi_ctrl.interfaces():\n            iface = Interface(interface)\n            self._ifaces.append(iface)\n            self._logger.info(\"Get interface: %s\", iface.name())\n\n        if not self._ifaces:\n            self._logger.error(\"Can't get wifi interface\")\n\n        return self._ifaces"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the AP list after scanning.", "response": "def scan_results(self, obj):\n        \"\"\"Get the AP list after scanning.\"\"\"\n\n        avail_network_list = pointer(WLAN_AVAILABLE_NETWORK_LIST())\n        self._wlan_get_available_network_list(self._handle,\n            byref(obj['guid']), byref(avail_network_list))\n        networks = cast(avail_network_list.contents.Network,\n                     POINTER(WLAN_AVAILABLE_NETWORK))\n\n        self._logger.debug(\"Scan found %d networks.\",\n            avail_network_list.contents.dwNumberOfItems)\n\n        network_list = []\n        for i in range(avail_network_list.contents.dwNumberOfItems):\n\n            if networks[i].dot11BssType == 1 and networks[i].bNetworkConnectable :\n\n                ssid = ''\n                for j in range(networks[i].dot11Ssid.uSSIDLength):\n\n                    if networks[i].dot11Ssid.ucSSID != b'':\n                        ssid += \"%c\" % networks[i].dot11Ssid.ucSSID[j]\n\n                bss_list = pointer(WLAN_BSS_LIST())\n                self._wlan_get_network_bss_list(self._handle,\n                    byref(obj['guid']), byref(bss_list), networks[i].dot11Ssid, networks[i].bSecurityEnabled)\n                bsses = cast(bss_list.contents.wlanBssEntries,\n                             POINTER(WLAN_BSS_ENTRY))\n\n                if networks[i].bSecurityEnabled:\n                    akm = self._get_akm(networks[i].dot11DefaultCipherAlgorithm)\n                    auth_alg = self._get_auth_alg(networks[i].dot11DefaultAuthAlgorithm)\n                else:\n                    akm = [AKM_TYPE_NONE]\n                    auth_alg = [AUTH_ALG_OPEN]\n\n                for j in range(bss_list.contents.dwNumberOfItems):\n                    network = Profile()\n\n                    network.ssid = ssid\n\n                    network.bssid = ''\n                    for k in range(6):\n                        network.bssid += \"%02x:\" % bsses[j].dot11Bssid[k]\n\n                    network.signal = bsses[j].lRssi\n                    network.freq = bsses[j].ulChCenterFrequency\n                    network.auth = auth_alg\n                    network.akm = akm\n                    network_list.append(network)\n\n        return network_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to the specified AP.", "response": "def connect(self, obj, params):\n        \"\"\"Connect to the specified AP.\"\"\"\n\n        connect_params = WLAN_CONNECTION_PARAMETERS()\n        connect_params.wlanConnectionMode = 0  # Profile\n        connect_params.dot11BssType = 1  # infra\n        profile_name = create_unicode_buffer(params.ssid)\n\n        connect_params.strProfile = profile_name.value\n        ret = self._wlan_connect(\n            self._handle, obj['guid'], byref(connect_params))\n        self._logger.debug('connect result: %d', ret)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an AP profile for connecting to afterward.", "response": "def add_network_profile(self, obj, params):\n        \"\"\"Add an AP profile for connecting to afterward.\"\"\"\n\n        reason_code = DWORD()\n\n        params.process_akm()\n        profile_data = {}\n        profile_data['ssid'] = params.ssid\n\n        if AKM_TYPE_NONE in params.akm:\n            profile_data['auth'] = auth_value_to_str_dict[params.auth]\n            profile_data['encrypt'] = \"none\"\n        else:\n            profile_data['auth'] = akm_value_to_str_dict[params.akm[-1]]\n            profile_data['encrypt'] = cipher_value_to_str_dict[params.cipher]\n\n        profile_data['key'] = params.key\n\n        profile_data['protected'] = 'false'\n        profile_data['profile_name'] = params.ssid\n\n        xml = \"\"\"<?xml version=\"1.0\"?>\n        <WLANProfile xmlns=\"http://www.microsoft.com/networking/WLAN/profile/v1\">\n            <name>{profile_name}</name>\n            <SSIDConfig>\n                <SSID>\n                    <name>{ssid}</name>\n                </SSID>\n            </SSIDConfig>\n            <connectionType>ESS</connectionType>\n            <connectionMode>manual</connectionMode>\n            <MSM>\n                <security>\n                    <authEncryption>\n                        <authentication>{auth}</authentication>\n                        <encryption>{encrypt}</encryption>\n                        <useOneX>false</useOneX>\n                    </authEncryption>\n        \"\"\"\n\n        if AKM_TYPE_NONE not in params.akm:\n            xml += \"\"\"<sharedKey>\n                        <keyType>passPhrase</keyType>\n                        <protected>{protected}</protected>\n                        <keyMaterial>{key}</keyMaterial>\n                    </sharedKey>\"\"\"\n\n        xml += \"\"\"\n                </security>\n            </MSM>\"\"\"\n\n        xml += \"\"\"<MacRandomization xmlns=\"http://www.microsoft.com/networking/WLAN/profile/v3\">\n                <enableRandomization>false</enableRandomization>\n            </MacRandomization>\n        </WLANProfile>\n        \"\"\"\n\n        xml = xml.format(**profile_data)\n\n        status = self._wlan_set_profile(self._handle, obj['guid'], xml,\n                                        True, byref(reason_code))\n        if status != ERROR_SUCCESS:\n            self._logger.debug(\"Status %d: Add profile failed\", status)\n\n        buf_size = DWORD(64)\n        buf = create_unicode_buffer(64)\n        self._wlan_reason_code_to_str(reason_code, buf_size, buf)\n        \n        return params"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget AP profile names.", "response": "def network_profile_name_list(self, obj):\n        \"\"\"Get AP profile names.\"\"\"\n\n        profile_list = pointer(WLAN_PROFILE_INFO_LIST())\n        self._wlan_get_profile_list(self._handle,\n                                    byref(obj['guid']),\n                                    byref(profile_list))\n        profiles = cast(profile_list.contents.ProfileInfo,\n                        POINTER(WLAN_PROFILE_INFO))\n\n        profile_name_list = []\n        for i in range(profile_list.contents.dwNumberOfItems):\n            profile_name = ''\n            for j in range(len(profiles[i].strProfileName)):\n                profile_name += profiles[i].strProfileName[j]\n            profile_name_list.append(profile_name)\n\n        return profile_name_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the specified AP profile.", "response": "def remove_network_profile(self, obj, params):\n        \"\"\"Remove the specified AP profile.\"\"\"\n\n        self._logger.debug(\"delete profile: %s\", params.ssid)\n        str_buf = create_unicode_buffer(params.ssid)\n        ret = self._wlan_delete_profile(self._handle, obj['guid'], str_buf)\n        self._logger.debug(\"delete result %d\", ret)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all the AP profiles.", "response": "def remove_all_network_profiles(self, obj):\n        \"\"\"Remove all the AP profiles.\"\"\"\n\n        profile_name_list = self.network_profile_name_list(obj)\n\n        for profile_name in profile_name_list:\n            self._logger.debug(\"delete profile: %s\", profile_name)\n            str_buf = create_unicode_buffer(profile_name)\n            ret = self._wlan_delete_profile(self._handle, obj['guid'], str_buf)\n            self._logger.debug(\"delete result %d\", ret)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the wifi interface status.", "response": "def status(self, obj):\n        \"\"\"Get the wifi interface status.\"\"\"\n\n        data_size = DWORD()\n        data = PDWORD()\n        opcode_value_type = DWORD()\n        self._wlan_query_interface(self._handle, obj['guid'], 6,\n                                   byref(data_size), byref(data),\n                                   byref(opcode_value_type))\n\n        return status_dict[data.contents.value]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the wifi interface lists.", "response": "def interfaces(self):\n        \"\"\"Get the wifi interface lists.\"\"\"\n\n        ifaces = []\n\n        if self._wlan_open_handle(CLIENT_VERSION,\n                                  byref(self._nego_version),\n                                  byref(self._handle)) \\\n           is not ERROR_SUCCESS:\n            self._logger.error(\"Open handle failed!\")\n\n        if self._wlan_enum_interfaces(self._handle, byref(self._ifaces)) \\\n           is not ERROR_SUCCESS:\n            self._logger.error(\"Enum interface failed!\")\n\n        interfaces = cast(self._ifaces.contents.InterfaceInfo,\n                     POINTER(WLAN_INTERFACE_INFO))\n        for i in range(0, self._ifaces.contents.dwNumberOfItems):\n            iface = {}\n            iface['guid'] = interfaces[i].InterfaceGuid\n            iface['name'] = interfaces[i].strInterfaceDescription\n            ifaces.append(iface)\n\n        return ifaces"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the AP list after scanning.", "response": "def scan_results(self, obj):\n        \"\"\"Get the AP list after scanning.\"\"\"\n\n        bsses = []\n        bsses_summary = self._send_cmd_to_wpas(obj['name'], 'SCAN_RESULTS', True)\n        bsses_summary = bsses_summary[:-1].split('\\n')\n        if len(bsses_summary) == 1:\n            return bsses\n\n        for l in bsses_summary[1:]:\n            values = l.split('\\t')\n            bss = Profile()\n            bss.bssid = values[0]\n            bss.freq = int(values[1])\n            bss.signal = int(values[2])\n            bss.ssid = values[4]\n            bss.akm = []\n            if 'WPA-PSK' in values[3]:\n                bss.akm.append(AKM_TYPE_WPAPSK)\n            if 'WPA2-PSK' in values[3]:\n                bss.akm.append(AKM_TYPE_WPA2PSK)\n            if 'WPA-EAP' in values[3]:\n                bss.akm.append(AKM_TYPE_WPA)\n            if 'WPA2-EAP' in values[3]:\n                bss.akm.append(AKM_TYPE_WPA2)\n\n            bss.auth = AUTH_ALG_OPEN\n\n            bsses.append(bss)\n\n        return bsses"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the specified AP.", "response": "def connect(self, obj, network):\n        \"\"\"Connect to the specified AP.\"\"\"\n\n        network_summary = self._send_cmd_to_wpas(\n            obj['name'],\n            'LIST_NETWORKS',\n            True)\n        network_summary = network_summary[:-1].split('\\n')\n        if len(network_summary) == 1:\n            return networks\n\n        for l in network_summary[1:]:\n            values = l.split('\\t')\n            if values[1] == network.ssid:\n                network_summary = self._send_cmd_to_wpas(\n                    obj['name'],\n                    'SELECT_NETWORK {}'.format(values[0]),\n                    True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_network_profile(self, obj, params):\n\n        network_id = self._send_cmd_to_wpas(obj['name'], 'ADD_NETWORK', True)\n        network_id = network_id.strip()\n\n        params.process_akm()\n\n        self._send_cmd_to_wpas(\n                obj['name'],\n                'SET_NETWORK {} ssid \\\"{}\\\"'.format(network_id, params.ssid))\n\n        key_mgmt = ''\n        if params.akm[-1] in [AKM_TYPE_WPAPSK, AKM_TYPE_WPA2PSK]:\n            key_mgmt = 'WPA-PSK'\n        elif params.akm[-1] in [AKM_TYPE_WPA, AKM_TYPE_WPA2]:\n            key_mgmt = 'WPA-EAP'\n        else:\n            key_mgmt = 'NONE'\n\n        if key_mgmt:\n            self._send_cmd_to_wpas(\n                    obj['name'],\n                    'SET_NETWORK {} key_mgmt {}'.format(\n                        network_id,\n                        key_mgmt))\n\n        proto = ''\n        if params.akm[-1] in [AKM_TYPE_WPAPSK, AKM_TYPE_WPA]:\n            proto = 'WPA'\n        elif params.akm[-1] in [AKM_TYPE_WPA2PSK, AKM_TYPE_WPA2]:\n            proto = 'RSN'\n\n        if proto:\n            self._send_cmd_to_wpas(\n                    obj['name'],\n                    'SET_NETWORK {} proto {}'.format(\n                        network_id,\n                        proto))\n\n        if params.akm[-1] in [AKM_TYPE_WPAPSK, AKM_TYPE_WPA2PSK]:\n            self._send_cmd_to_wpas(\n                    obj['name'],\n                    'SET_NETWORK {} psk \\\"{}\\\"'.format(network_id, params.key))\n\n        return params", "response": "Add an AP profile for connecting to afterward."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the specified AP profiles", "response": "def remove_network_profile(self, obj, params):\n        \"\"\"Remove the specified AP profiles\"\"\"\n\n        network_id = -1\n        profiles = self.network_profiles(obj)\n\n        for profile in profiles:\n            if profile == params:\n                network_id = profile.id\n\n        if network_id != -1:\n            self._send_cmd_to_wpas(obj['name'],\n                'REMOVE_NETWORK {}'.format(network_id))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef status(self, obj):\n\n        reply = self._send_cmd_to_wpas(obj['name'], 'STATUS', True)\n        result = reply.split('\\n')\n\n        status = ''\n        for l in result:\n            if l.startswith('wpa_state='):\n                status = l[10:]\n                return status_dict[status.lower()]", "response": "Get the wifi interface status."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the wifi interface lists.", "response": "def interfaces(self):\n        \"\"\"Get the wifi interface lists.\"\"\"\n        \n        ifaces = []\n        for f in sorted(os.listdir(CTRL_IFACE_DIR)):\n            sock_file = '/'.join([CTRL_IFACE_DIR, f])\n            mode = os.stat(sock_file).st_mode\n            if stat.S_ISSOCK(mode):\n                iface = {}\n                iface['name'] = f\n                ifaces.append(iface)\n                self._connect_to_wpa_s(f)\n\n        return ifaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntriggers the wifi interface to scan.", "response": "def scan(self):\n        \"\"\"Trigger the wifi interface to scan.\"\"\"\n\n        self._logger.info(\"iface '%s' scans\", self.name())\n\n        self._wifi_ctrl.scan(self._raw_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan_results(self):\n        \n        bsses = self._wifi_ctrl.scan_results(self._raw_obj)\n\n        if self._logger.isEnabledFor(logging.INFO):\n            for bss in bsses:\n                self._logger.info(\"Find bss:\")\n                self._logger.info(\"\\tbssid: %s\", bss.bssid)\n                self._logger.info(\"\\tssid: %s\", bss.ssid)\n                self._logger.info(\"\\tfreq: %d\", bss.freq)\n                self._logger.info(\"\\tauth: %s\", bss.auth)\n                self._logger.info(\"\\takm: %s\", bss.akm)\n                self._logger.info(\"\\tsignal: %d\", bss.signal)\n\n        return bsses", "response": "Return the scan result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef network_profiles(self):\n\n        profiles = self._wifi_ctrl.network_profiles(self._raw_obj)\n\n        if self._logger.isEnabledFor(logging.INFO):\n            for profile in profiles:\n                self._logger.info(\"Get profile:\")\n                self._logger.info(\"\\tssid: %s\", profile.ssid)\n                self._logger.info(\"\\tauth: %s\", profile.auth)\n                self._logger.info(\"\\takm: %s\", profile.akm)\n                self._logger.info(\"\\tcipher: %s\", profile.cipher)\n\n        return profiles", "response": "Get all the AP profiles."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, params):\n\n        self._logger.info(\"iface '%s' connects to AP: '%s'\",\n                          self.name(), params.ssid)\n\n        self._wifi_ctrl.connect(self._raw_obj, params)", "response": "Connect to the specified AP."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disconnect(self):\n\n        self._logger.info(\"iface '%s' disconnects\", self.name())\n\n        self._wifi_ctrl.disconnect(self._raw_obj)", "response": "Disconnect from the specified AP."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up a graphviz graph context.", "response": "def graph(self, **kw):\n        \"\"\"Set up a graphviz graph context.\n        \"\"\"\n        self.name = kw.get('name', 'G')\n        self.fillcolor = kw.get('fillcolor', '#ffffff')\n        self.fontcolor = kw.get('fontcolor', '#000000')\n        self.rankdir = kw.get('rankdir', 'BT' if self.reverse else 'TB')\n        if kw.get('concentrate', True):\n            self.concentrate = 'concentrate = true;'\n        else:\n            self.concentrate = ''\n        self.dedent(\"\"\"\n            digraph {self.name} {{\n                {self.concentrate}\n                rankdir = {self.rankdir};\n                node [style=filled,fillcolor=\"{self.fillcolor}\",fontcolor=\"{self.fontcolor}\",fontname=Helvetica,fontsize=10];\n\n        \"\"\".format(self=self))\n        yield\n        self.writeln('}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef text(self):\n        if self.out:\n            self.out.close()  # pragma: nocover\n        return self.fp.getvalue()", "response": "Get the value of the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites txt to file and output stream.", "response": "def write(self, txt):\n        \"\"\"Write ``txt`` to file and output stream (StringIO).\n        \"\"\"\n        self.fp.write(to_unicode(txt))\n        if self.out:\n            self.out.write(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_attributes(self, attrs):\n        if attrs:\n            self.write(\n                ' [' + ','.join('%s=\"%s\"' % kv for kv in attrs.items()) + ']'\n            )\n        else:  # pragma: nocover\n            pass", "response": "Write comma separated attribute values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a rule to the log file.", "response": "def write_rule(self, a, b, **attrs):\n        if self.reverse:\n            a, b = b, a\n        \"a -> b [a1=x,a2=y];\"\n        with self.rule():\n            self.write('%s -> %s' % (self._nodename(a), self._nodename(b)))\n            self._delattr(attrs, 'weight', 1)\n            self._delattr(attrs, 'minlen', 1)\n            self.write_attributes(attrs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a node to the file", "response": "def write_node(self, a, **attrs):\n        \"a [a1=x,a2=y];\"\n        with self.rule():\n            nodename = self._nodename(a)\n            self.write(nodename)\n            self._delattr(attrs, 'label', nodename)\n            self._delattr(attrs, 'fillcolor', self.fillcolor)\n            self._delattr(attrs, 'fontcolor', self.fontcolor)\n            self.write_attributes(attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_noise(self):\n        noise = self.args['noise_level']\n        if not (self.in_degree and self.out_degree):\n            return self.degree > noise\n        return False", "response": "Is this module just noise?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef label(self):\n        if len(self.name) > 14 and '.' in self.name:\n            return '\\\\.\\\\n'.join(self.name.split('.'))  # pragma: nocover\n        return self.name", "response": "Convert a module name to a formatted node label. This is a default node label. This is a default node label."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the proximity of the dependency from a to b.", "response": "def proximity_metric(self, a, b):\n        \"\"\"Return the weight of the dependency from a to b. Higher weights\n           usually have shorter straighter edges. Return 1 if it has normal\n           weight. A value of 4 is usually good for ensuring that a related\n           pair of modules are drawn next to each other.\n\n           Returns an int between 1 (unknown, default), and 4 (very related).\n        \"\"\"\n        # if self._is_pylib(a) and self._is_pylib(b):\n        #     return 1\n\n        res = 1\n        for ap, bp, n in zip(a.path_parts, b.path_parts, list(range(4))):\n            res += ap == bp\n            if n >= 3:\n                break\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns non - zero if references to this module are strange and the inversion of the inversion of the inversion of the inversion of the inversion of the inversion of the inversion.", "response": "def dissimilarity_metric(self, a, b):\n        \"\"\"Return non-zero if references to this module are strange, and\n           should be drawn extra-long. The value defines the length, in\n           rank. This is also good for putting some vertical space between\n           seperate subsystems.\n\n           Returns an int between 1 (default) and 4 (highly unrelated).\n        \"\"\"\n        # if self._is_pylib(a) and self._is_pylib(b):\n        #     return 1\n\n        res = 4\n        for an, bn, n in zip_longest(a.name_parts, b.name_parts, list(range(4))):\n            res -= an == bn\n            if n >= 3:\n                break\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntraverse depth - first adding imported_by.", "response": "def connect_generations(self):\n        \"\"\"Traverse depth-first adding imported_by.\n        \"\"\"\n        # for src in list(self.sources.values()):\n        for src in self.sources.values():\n            for _child in src.imports:\n                if _child in self.sources:\n                    child = self.sources[_child]\n                    child.imported_by.add(src.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exclude_bacon(self, limit):\n        for src in list(self.sources.values()):\n            if src.bacon > limit:\n                src.excluded = True\n                # print \"Excluding bacon:\", src.name\n                self._add_skip(src.name)", "response": "Exclude modules that are more than limit hops away from __main__."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_excluded(self):\n        # import yaml\n        # print yaml.dump({k:v.__json__() for k,v in self.sources.items()}, default_flow_style=False)\n        sources = list(self.sources.values())\n        for src in sources:\n            if src.excluded:\n                del self.sources[src.name]\n            src.imports = [m for m in src.imports if not self._exclude(m)]\n            src.imported_by = [m for m in src.imported_by if not self._exclude(m)]", "response": "Remove all sources marked as excluded."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_bytes(s):  # pragma: nocover\n    if isinstance(s, bytes):\n        return s\n    if isinstance(s, str) or is_unicode(s):\n        return s.encode(\"utf-8\")\n    try:\n        return unicode(s).encode(\"utf-8\")\n    except NameError:\n        return str(s).encode(\"utf-8\")", "response": "Convert an item into bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare a command line for execution by Popen.", "response": "def cmd2args(cmd):\n    \"\"\"Prepare a command line for execution by Popen.\n    \"\"\"\n    if isinstance(cmd, str):\n        return cmd if win32 else shlex.split(cmd)\n    return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pipe(cmd, txt):\n    return Popen(\n        cmd2args(cmd),\n        stdout=subprocess.PIPE,\n        stdin=subprocess.PIPE,\n        shell=win32\n    ).communicate(txt)[0]", "response": "Pipe txt into the command cmd and return the output."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dot(src, **kw):\n    cmd = \"dot -T%s\" % kw.pop('T', 'svg')\n    for k, v in list(kw.items()):\n        if v is True:\n            cmd += \" -%s\" % k\n        else:\n            cmd += \" -%s%s\" % (k, v)\n\n    return pipe(cmd, to_bytes(src))", "response": "Execute the dot command to create an svg output."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_graphviz_dot(src, fmt):\n    try:\n        svg = dot(src, T=fmt)\n    except OSError as e:  # pragma: nocover\n        if e.errno == 2:\n            cli.error(\"\"\"\n               cannot find 'dot'\n\n               pydeps calls dot (from graphviz) to create svg diagrams,\n               please make sure that the dot executable is available\n               on your path.\n            \"\"\")\n        raise\n    return svg", "response": "Call dot command and provide helpful error message if we can t find it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to display the svg file on this platform.", "response": "def display_svg(kw, fname):  # pragma: nocover\n    \"\"\"Try to display the svg file on this platform.\n    \"\"\"\n    if kw['display'] is None:\n        cli.verbose(\"Displaying:\", fname)\n        if sys.platform == 'win32':\n            os.startfile(fname)\n        else:\n            opener = \"open\" if sys.platform == \"darwin\" else \"xdg-open\"\n            subprocess.call([opener, fname])\n    else:\n        cli.verbose(kw['display'] + \" \" + fname)\n        os.system(kw['display'] + \" \" + fname)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pystdlib():\r\n    curver = '.'.join(str(x) for x in sys.version_info[:2])\r\n    return (set(stdlib_list.stdlib_list(curver)) | {\r\n        '_LWPCookieJar', '_MozillaCookieJar', '_abcoll', 'email._parseaddr',\r\n        'email.base64mime', 'email.feedparser', 'email.quoprimime',\r\n        'encodings', 'genericpath', 'ntpath', 'nturl2path', 'os2emxpath',\r\n        'posixpath', 'sre_compile', 'sre_parse', 'unittest.case',\r\n        'unittest.loader', 'unittest.main', 'unittest.result',\r\n        'unittest.runner', 'unittest.signals', 'unittest.suite',\r\n        'unittest.util', '_threading_local', 'sre_constants', 'strop',\r\n        'repr', 'opcode', 'nt', 'encodings.aliases',\r\n        '_bisect', '_codecs', '_collections', '_functools', '_hashlib',\r\n        '_heapq', '_io', '_locale', '_LWPCookieJar', '_md5',\r\n        '_MozillaCookieJar', '_random', '_sha', '_sha256', '_sha512',\r\n        '_socket', '_sre', '_ssl', '_struct', '_subprocess',\r\n        '_threading_local', '_warnings', '_weakref', '_weakrefset',\r\n        '_winreg'\r\n    }) - {'__main__'}", "response": "Returns a set of all module - names in the Python standard library."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a report of the found modules with their paths as well as modules that are missing or may also be missing.", "response": "def report(self):  # pragma: nocover\n        \"\"\"Print a report to stdout, listing the found modules with their\n        paths, as well as modules that are missing, or seem to be missing.\n        \"\"\"\n        print()\n        print(\"  %-25s %s\" % (\"Name\", \"File\"))\n        print(\"  %-25s %s\" % (\"----\", \"----\"))\n        # Print modules found\n        keys = list(self.modules.keys())\n        keys.sort()\n        for key in keys:\n            m = self.modules[key]\n            if m.__path__:\n                print(\"P\", end=' ')\n            else:\n                print(\"m\", end=' ')\n            print(\"%-25s\" % key, m.__file__ or \"\")\n\n        # Print missing modules\n        missing, maybe = self.any_missing_maybe()\n        if missing:\n            print()\n            print(\"Missing modules:\")\n            for name in missing:\n                mods = list(self.badmodules[name].keys())\n                mods.sort()\n                print(\"?\", name, \"imported from\", ', '.join(mods))\n        # Print modules that may be missing, but then again, maybe not...\n        if maybe:\n            print()\n            print(\"Submodules thay appear to be missing, but could also be\", end=' ')\n            print(\"global names in the parent package:\")\n            for name in maybe:\n                mods = list(self.badmodules[name].keys())\n                mods.sort()\n                print(\"?\", name, \"imported from\", ', '.join(mods))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef any_missing_maybe(self):  # pragma: nocover\n        missing = []\n        maybe = []\n        for name in self.badmodules:\n            if name in self.excludes:\n                continue\n            i = name.rfind(\".\")\n            if i < 0:\n                missing.append(name)\n                continue\n            subname = name[i + 1:]\n            pkgname = name[:i]\n            pkg = self.modules.get(pkgname)\n            if pkg is not None:\n                if pkgname in self.badmodules[name]:\n                    # The package tried to import this module itself and\n                    # failed. It's definitely missing.\n                    missing.append(name)\n                elif subname in pkg.globalnames:\n                    # It's a global in the package: definitely not missing.\n                    pass\n                elif pkg.starimports:\n                    # It could be missing, but the package did an \"import *\"\n                    # from a non-Python module, so we simply can't be sure.\n                    maybe.append(name)\n                else:\n                    # It's not a global in the package, the package didn't\n                    # do funny star imports, it's very likely to be missing.\n                    # The symbol could be inserted into the package from the\n                    # outside, but since that's not good style we simply list\n                    # it missing.\n                    missing.append(name)\n            else:\n                missing.append(name)\n        missing.sort()\n        maybe.sort()\n        return missing, maybe", "response": "Return two lists one with modules that are certainly missing and one with modules that are not present in the package and one with modules that are not present in the package."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlikes range but with floats.", "response": "def frange(start, end, step):\n    \"\"\"Like range(), but with floats.\n    \"\"\"\n    val = start\n    while val < end:\n        yield val\n        val += step"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef name2rgb(hue):\n    r, g, b = colorsys.hsv_to_rgb(hue / 360.0, .8, .7)\n    return tuple(int(x * 256) for x in [r, g, b])", "response": "Originally used to calculate color based on module name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef colordiff(rgb1, rgb2):\n    (r, g, b) = rgb1\n    (r2, g2, b2) = rgb2\n    return (\n        max(r, r2) - min(r, r2) +\n        max(g, g2) - min(g, g2) +\n        max(b, b2) - min(b, b2)\n    )", "response": "Compute the colordiff between two rgb values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef foreground(background, *options):\n    def absdiff(a, b):\n        return brightnessdiff(a, b)\n        # return 3 * brightnessdiff(a, b) + colordiff(a, b)\n    diffs = [(absdiff(background, color), color) for color in options]\n    diffs.sort(reverse=True)\n    return diffs[0][1]", "response": "Find the best foreground color based on options."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint an error message and exit.", "response": "def error(*args, **kwargs):  # pragma: nocover\n    \"\"\"Print an error message and exit.\n    \"\"\"\n    kwargs['file'] = sys.stderr\n    print(\"\\n\\tERROR:\", *args, **kwargs)\n    sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitial parser that can set values for the rest of the parsing process.", "response": "def base_argparser(argv=()):\n    \"\"\"Initial parser that can set values for the rest of the parsing process.\n    \"\"\"\n    global verbose\n    verbose = _not_verbose\n\n    _p = argparse.ArgumentParser(add_help=False)\n    _p.add_argument('--debug', action='store_true', help=\"turn on all the show and verbose options (mainly for debugging pydeps itself)\")\n    _p.add_argument('--config', help=\"specify config file\", metavar=\"FILE\")\n    _p.add_argument('--no-config', help=\"disable processing of config files\", action='store_true')\n    _p.add_argument('--version', action='store_true', help='print pydeps version')\n    _p.add_argument('-L', '--log', help=textwrap.dedent('''\n        set log-level to one of CRITICAL, ERROR, WARNING, INFO, DEBUG, NOTSET.\n    '''))\n    _args, argv = _p.parse_known_args(argv)\n\n    if _args.log:\n        loglevels = \"CRITICAL DEBUG ERROR FATAL INFO WARN\"\n        if _args.log not in loglevels:  # pragma: nocover\n            error('legal values for the -L parameter are:', loglevels)\n        loglevel = getattr(logging, _args.log)\n    else:\n        loglevel = None\n\n    logging.basicConfig(\n        level=loglevel,\n        format='%(filename)s:%(lineno)d: %(levelname)s: %(message)s'\n    )\n\n    if _args.version:  # pragma: nocover\n        print(\"pydeps v\" + __version__)\n        sys.exit(0)\n\n    return _p, _args, argv"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse command line arguments and return a dict.", "response": "def parse_args(argv=()):\n    \"\"\"Parse command line arguments, and return a dict.\n    \"\"\"\n    _p, _args, argv = base_argparser(argv)\n\n    config_files = []\n\n    if not _args.no_config:  # process config files\n        # extra config file specified with --config <fname> has highest precedence\n        if _args.config:\n            config_files.append(_args.config)\n\n        # .pydeps file specified in current directory is next\n        local_pydeps = os.path.join(os.getcwd(), '.pydeps')\n        if os.path.exists(local_pydeps):\n            config_files.append(local_pydeps)\n\n        # finally the .pydeps file in the the user's homedir\n        home = os.environ['USERPROFILE' if sys.platform == 'win32' else 'HOME']\n        home_pydeps = os.path.join(home, '.pydeps')\n        if os.path.exists(home_pydeps):\n            config_files.append(home_pydeps)\n        \n    args = Arguments(config_files, debug=True, parents=[_p])\n    args.add('fname', kind=\"FNAME:input\", help='filename')\n    args.add('-v', '--verbose', default=0, action='count', help=\"be more verbose (-vv, -vvv for more verbosity)\")\n    args.add('-o', default=None, kind=\"FNAME:output\", dest='output', metavar=\"file\", help=\"write output to 'file'\")\n    args.add('-T', default='svg', dest='format', help=\"output format (svg|png)\")\n    args.add('--display', kind=\"FNAME:exe\", default=None, help=\"program to use to display the graph (png or svg file depending on the T parameter)\", metavar=\"PROGRAM\")\n    args.add('--noshow', action='store_true', help=\"don't call external program to display graph\")\n    args.add('--show-deps', action='store_true', help=\"show output of dependency analysis\")\n    args.add('--show-raw-deps', action='store_true', help=\"show output of dependency analysis before removing skips\")\n    args.add('--show-dot', action='store_true', help=\"show output of dot conversion\")\n    args.add('--nodot', action='store_true', help=\"skip dot conversion\")\n    args.add('--no-output', action='store_true', help=\"don't create .svg/.png file, implies --no-show (-t/-o will be ignored)\")\n    args.add('--show-cycles', action='store_true', help=\"show only import cycles\")\n    args.add('--debug-mf', default=0, type=int, metavar=\"INT\", help=\"set the ModuleFinder.debug flag to this value\")\n    args.add('--noise-level', default=200, type=int, metavar=\"INT\", help=\"exclude sources or sinks with degree greater than noise-level\")\n    args.add('--max-bacon', default=2, type=int, metavar=\"INT\", help=\"exclude nodes that are more than n hops away (default=2, 0 -> infinite)\")\n    args.add('--pylib', action='store_true', help=\"include python std lib modules\")\n    args.add('--pylib-all', action='store_true', help=\"include python all std lib modules (incl. C modules)\")\n    args.add('--include-missing', action='store_true', help=\"include modules that are not installed (or can't be found on sys.path)\")\n    args.add('-x', '--exclude', default=[], nargs=\"+\", metavar=\"FNAME\", help=\"input files to skip\")\n    args.add('--externals', action='store_true', help='create list of direct external dependencies')\n    args.add('--reverse', action='store_true', help=\"draw arrows to (instead of from) imported modules\")\n\n    _args = args.parse_args(argv)\n\n    if _args.externals:\n        return dict(\n            T='svg', config=None, debug=False, display=None, exclude=[], externals=True,\n            fname=_args.fname, format='svg', max_bacon=10, no_config=False, nodot=False,\n            noise_level=200, noshow=True, output=None, pylib=False, pylib_all=False,\n            show=False, show_cycles=False, show_deps=False, show_dot=False,\n            show_raw_deps=False, verbose=0, include_missing=True, reverse=False,\n        )\n\n    _args.show = True\n\n    if _args.no_output:\n        _args.noshow = True\n    if _args.noshow:\n        _args.show = False\n    if _args.nodot and _args.show_cycles:\n        error(\"Can't use --nodot and --show-cycles together\")  # pragma: nocover\n    if _args.nodot:\n        _args.show_dot = False\n    if _args.max_bacon == 0:\n        _args.max_bacon = sys.maxsize\n\n    _args.format = getattr(_args, 'T', getattr(_args, 'format', None))\n\n    verbose = _mkverbose(max(_args.verbose, int(_args.debug)))\n    verbose(2, _args, '\\n')\n    if _args.debug:  # pragma: nocover\n        _args.verbose = 1\n        _args.show = True\n        _args.show_deps = True\n        _args.show_dot = True\n\n    return vars(_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dep2req(name, imported_by):\r\n    lst = [item for item in sorted(imported_by) if not item.startswith(name)]\r\n    res = '%-15s # from: ' % name\r\n    imps = ', '.join(lst)\r\n    if len(imps) < WIDTH - 24:\r\n        return res + imps\r\n    return res + imps[:WIDTH - 24 - 3] + '...'", "response": "Convert dependency to requirement.\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pydeps2reqs(deps):\r\n    reqs = defaultdict(set)\r\n    for k, v in list(deps.items()):\r\n        # not a built-in\r\n        p = v['path']\r\n        if p and not p.startswith(sys.real_prefix):\r\n            if p.startswith(sys.prefix) and 'site-packages' in p:\r\n                if not p.endswith('.pyd'):\r\n                    if '/win32/' in p.replace('\\\\', '/'):\r\n                        reqs['win32'] |= set(v['imported_by'])\r\n                    else:\r\n                        name = k.split('.', 1)[0]\r\n                        if name not in skiplist:\r\n                            reqs[name] |= set(v['imported_by'])\r\n\r\n    if '_dummy' in reqs:\r\n        del reqs['_dummy']\r\n    return '\\n'.join(dep2req(name, reqs[name]) for name in sorted(reqs))", "response": "Convert a deps instance into a requirements.\r\nDeferred"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the dependency graph to dot source code.", "response": "def depgraph_to_dotsrc(dep_graph, show_cycles, nodot, reverse):\n    \"\"\"Convert the dependency graph (DepGraph class) to dot source code.\n    \"\"\"\n    if show_cycles:\n        dotsrc = cycles2dot(dep_graph, reverse=reverse)\n    elif not nodot:\n        dotsrc = dep2dot(dep_graph, reverse=reverse)\n    else:\n        dotsrc = None\n    return dotsrc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef externals(trgt, **kwargs):\n    kw = dict(\n        T='svg', config=None, debug=False, display=None, exclude=[], externals=True,\n        format='svg', max_bacon=2**65, no_config=True, nodot=False,\n        noise_level=2**65, noshow=True, output=None, pylib=True, pylib_all=True,\n        show=False, show_cycles=False, show_deps=False, show_dot=False,\n        show_raw_deps=False, verbose=0, include_missing=True,\n    )\n    kw.update(kwargs)\n    depgraph = py2depgraph.py2dep(trgt, **kw)\n    pkgname = trgt.fname\n    log.info(\"DEPGRAPH: %s\", depgraph)\n    pkgname = os.path.splitext(pkgname)[0]\n\n    res = {}\n    ext = set()\n\n    for k, src in list(depgraph.sources.items()):\n        if k.startswith('_'):\n            continue\n        if not k.startswith(pkgname):\n            continue\n        if src.imports:\n            imps = [imp for imp in src.imports if not imp.startswith(pkgname)]\n            if imps:\n                for imp in imps:\n                    ext.add(imp.split('.')[0])\n                res[k] = imps\n    # return res  # debug\n    return list(sorted(ext))", "response": "Return a list of direct external dependencies of pkgname."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _path_parts(self, pth):\n        res = re.split(r\"[\\\\/]\", pth)\n        if res and os.path.splitdrive(res[0]) == (res[0], ''):\n            res[0] += os.path.sep\n        return res", "response": "Return a list of all directories in the path pth."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a module name is legal.", "response": "def legal_module_name(self, name):\n        \"\"\"Legal module names are dotted strings where each part\n           is a valid Python identifier.\n           (and not a keyword, and support unicode identifiers in\n           Python3, ..)\n        \"\"\"\n        if name in self._legal_mnames:\n            return self._legal_mnames[name]\n\n        for part in name.split('.'):\n            try:\n                exec(\"%s = 42\" % part, {}, {})\n            except:  # pragma: nocover\n                self._legal_mnames[name] = False\n                return False\n        self._legal_mnames[name] = True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate dependencies for pattern and return a DepGraph.", "response": "def py2dep(target, **kw):\n    \"\"\"\"Calculate dependencies for ``pattern`` and return a DepGraph.\n    \"\"\"\n    log.info(\"py2dep(%r)\", target)\n    dummy = DummyModule(target, **kw)\n\n    kw['dummyname'] = dummy.fname\n    syspath = sys.path[:]\n    syspath.insert(0, target.syspath_dir)\n\n    # remove exclude so we don't pass it twice to modulefinder\n    exclude = ['migrations'] + kw.pop('exclude', [])\n    log.debug(\"Exclude: %r\", exclude)\n    log.debug(\"KW: %r\", kw)\n    if 'fname' in kw:\n        del kw['fname']\n\n    mf = MyModuleFinder(\n        syspath,                # module search path for this module finder\n        excludes=exclude,       # folders to exclude\n        **kw\n    )\n    mf.debug = max(mf.debug, kw.get('debug_mf', 0))\n    log.debug(\"CURDIR: %s\", os.getcwd())\n    log.debug(\"FNAME: %r, CONTENT:\\n%s\\n\", dummy.fname, dummy.text())\n    mf.run_script(dummy.fname)\n\n    log.info(\"mf._depgraph:\\n%s\", json.dumps(dict(mf._depgraph), indent=4))\n    log.info(\"mf.badmodules:\\n%s\", json.dumps(mf.badmodules, indent=4))\n\n    if kw.get('include_missing'):\n        for k, vdict in list(mf.badmodules.items()):\n            if k not in mf._depgraph:\n                mf._depgraph[k] = {}\n            for v in vdict:\n                if v not in mf._depgraph['__main__']:\n                    mf._depgraph['__main__'][v] = None\n                if v in mf._depgraph:\n                    mf._depgraph[v][k] = None\n                else:\n                    mf._depgraph[v] = {k:None}\n\n    log.info(\"mf._depgraph:\\n%s\", json.dumps(dict(mf._depgraph), indent=4))\n\n    kw['exclude'] = exclude\n\n    if kw.get('pylib'):\n        mf_depgraph = mf._depgraph\n        for k, v in list(mf._depgraph.items()):\n            log.debug('depgraph item: %r %r', k, v)\n        # mf_modules = {k: os.syspath.abspath(v.__file__)\n        #               for k, v in mf.modules.items()}\n    else:\n        pylib = pystdlib()\n        mf_depgraph = {}\n        for k, v in list(mf._depgraph.items()):\n            log.debug('depgraph item: %r %r', k, v)\n            if k in pylib:\n                continue\n            vals = {vk: vv for vk, vv in list(v.items()) if vk not in pylib}\n            mf_depgraph[k] = vals\n\n        # mf_modules = {k: os.syspath.abspath(v.__file__)\n        #               for k, v in mf.modules.items()\n        #               if k not in pylib}\n\n    try:\n        import yaml\n        log.info(\"mf_depgraph:\\n%s\",\n                 yaml.dump(dict(mf_depgraph), default_flow_style=False))\n        # log.error(\"mf._types:\\n%s\", yaml.dump(mf._types, default_flow_style=False))\n        # log.debug(\"mf_modules:\\n%s\", yaml.dump(mf_modules, default_flow_style=False))\n    except ImportError:\n        log.info(\"mf_depgraph:\\n%s\", json.dumps(dict(mf_depgraph), indent=4))\n\n    return depgraph.DepGraph(mf_depgraph, mf._types, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cursor(self):\n        self._assert_valid()\n        c = Cursor(self.impl.cursor())\n        self.cursors.add(c)\n        return c", "response": "Create a new Cursor instance associated with this Connection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n        for c in self.cursors:\n            c.close()\n        self.cursors = []\n        self.impl = None", "response": "Closes the connection and all associated cursors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_options(read_buffer_size=None,\n                 parameter_sets_to_buffer=None,\n                 varchar_max_character_limit=None,\n                 prefer_unicode=None,\n                 use_async_io=None,\n                 autocommit=None,\n                 large_decimals_as_64_bit_types=None,\n                 limit_varchar_results_to_max=None,\n                 force_extra_capacity_for_unicode=None,\n                 fetch_wchar_as_char=None):\n    \"\"\"\n    Create options that control how turbodbc interacts with a database. These\n    options affect performance for the most part, but some options may require adjustment\n    so that all features work correctly with certain databases.\n\n    If a parameter is set to `None`, this means the default value is used.\n\n    :param read_buffer_size: Affects performance. Controls the size of batches fetched from the\n     database when reading result sets. Can be either an instance of ``turbodbc.Megabytes`` (recommended)\n     or ``turbodbc.Rows``.\n    :param parameter_sets_to_buffer: Affects performance. Number of parameter sets (rows) which shall be\n     transferred to the server in a single batch when ``executemany()`` is called. Must be an integer.\n    :param varchar_max_character_limit: Affects behavior/performance. If a result set contains fields\n     of type ``VARCHAR(max)`` or ``NVARCHAR(max)`` or the equivalent type of your database, buffers\n     will be allocated to hold the specified number of characters. This may lead to truncation. The\n     default value is ``65535`` characters. Please note that large values reduce the risk of\n     truncation, but may affect the number of rows in a batch of result sets (see ``read_buffer_size``).\n     Please note that this option only relates to retrieving results, not sending parameters to the\n     database.\n    :param use_async_io: Affects performance. Set this option to ``True`` if you want to use asynchronous\n     I/O, i.e., while Python is busy converting database results to Python objects, new result sets are\n     fetched from the database in the background.\n    :param prefer_unicode: May affect functionality and performance. Some databases do not support\n     strings encoded with UTF-8, leading to UTF-8 characters being misinterpreted, misrepresented, or\n     downright rejected. Set this option to ``True`` if you want to transfer character data using the\n     UCS-2/UCS-16 encoding that use (multiple) two-byte instead of (multiple) one-byte characters.\n    :param autocommit: Affects behavior. If set to ``True``, all queries and commands executed\n     with ``cursor.execute()`` or ``cursor.executemany()`` will be succeeded by an implicit ``COMMIT``\n     operation, persisting any changes made to the database. If not set or set to ``False``,\n     users has to take care of calling ``cursor.commit()`` themselves.\n    :param large_decimals_as_64_bit_types: Affects behavior. If set to ``True``, ``DECIMAL(x, y)``\n     results with ``x > 18`` will be rendered as 64 bit integers (``y == 0``) or 64 bit floating\n     point numbers (``y > 0``), respectively. Use this option if your decimal data types are larger\n     than the data they actually hold. Using this data type can lead to overflow errors and loss\n     of precision. If not set or set to ``False``, large decimals are rendered as strings.\n    :param limit_varchar_results_to_max: Affects behavior/performance. If set to ``True``,\n     any text-like fields such as ``VARCHAR(n)`` and ``NVARCHAR(n)`` will be limited to a maximum\n     size of ``varchar_max_character_limit`` characters. This may lead to values being truncated,\n     but reduces the amount of memory required to allocate string buffers, leading to larger, more\n     efficient batches. If not set or set to ``False``, strings can exceed ``varchar_max_character_limit``\n     in size if the database reports them this way. For fields such as ``TEXT``, some databases\n     report a size of 2 billion characters.\n     Please note that this option only relates to retrieving results, not sending parameters to the\n     database.\n    :param force_extra_capacity_for_unicode Affects behavior/performance. Some ODBC drivers report the\n     length of the ``VARCHAR``/``NVARCHAR`` field rather than the number of code points for which space is required\n     to be allocated, resulting in string truncations. Set this option to ``True`` to increase the memory\n     allocated for ``VARCHAR`` and ``NVARCHAR`` fields and prevent string truncations.\n     Please note that this option only relates to retrieving results, not sending parameters to the\n     database.\n    :param fetch_wchar_as_char Affects behavior. Some ODBC drivers retrieve single byte encoded strings\n     into ``NVARCHAR`` fields of result sets, which are decoded incorrectly by turbodbc default settings,\n     resulting in corrupt strings. Set this option to ``True`` to have turbodbc treat ``NVARCHAR`` types\n     as narrow character types when decoding the fields in result sets.\n     Please note that this option only relates to retrieving results, not sending parameters to the\n     database.\n    :return: An option struct that is suitable to pass to the ``turbodbc_options`` parameter of\n     ``turbodbc.connect()``\n    \"\"\"\n    options = Options()\n\n    if not read_buffer_size is None:\n        options.read_buffer_size = read_buffer_size\n\n    if not parameter_sets_to_buffer is None:\n        options.parameter_sets_to_buffer = parameter_sets_to_buffer\n\n    if not varchar_max_character_limit is None:\n        options.varchar_max_character_limit = varchar_max_character_limit\n\n    if not prefer_unicode is None:\n        options.prefer_unicode = prefer_unicode\n\n    if not use_async_io is None:\n        options.use_async_io = use_async_io\n\n    if not autocommit is None:\n        options.autocommit = autocommit\n\n    if not large_decimals_as_64_bit_types is None:\n        options.large_decimals_as_64_bit_types = large_decimals_as_64_bit_types\n\n    if not limit_varchar_results_to_max is None:\n        options.limit_varchar_results_to_max = limit_varchar_results_to_max\n\n    if not force_extra_capacity_for_unicode is None:\n        options.force_extra_capacity_for_unicode = force_extra_capacity_for_unicode\n\n    if not fetch_wchar_as_char is None:\n        options.fetch_wchar_as_char = fetch_wchar_as_char\n\n    return options", "response": "Create options for the turbodbc database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_distutils_build_directory():\n    pattern = \"lib.{platform}-{major}.{minor}\"\n    return os.path.join('build', pattern.format(platform=sysconfig.get_platform(),\n                                                major=sys.version_info[0],\n                                                minor=sys.version_info[1]))", "response": "Returns the distutils build directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_extension_modules():\n    extension_modules = []\n\n    \"\"\"\n    Extension module which is actually a plain C++ library without Python bindings\n    \"\"\"\n    turbodbc_sources = _get_source_files('cpp_odbc') + _get_source_files('turbodbc')\n    turbodbc_library = Extension('libturbodbc',\n                                 sources=turbodbc_sources,\n                                 include_dirs=include_dirs,\n                                 extra_compile_args=extra_compile_args,\n                                 extra_link_args=base_library_link_args,\n                                 libraries=[odbclib],\n                                 library_dirs=library_dirs)\n    if sys.platform == \"win32\":\n        turbodbc_libs = []\n    else:\n        turbodbc_libs = [_get_turbodbc_libname()]\n        extension_modules.append(turbodbc_library)\n\n    \"\"\"\n    An extension module which contains the main Python bindings for turbodbc\n    \"\"\"\n    turbodbc_python_sources = _get_source_files('turbodbc_python')\n    if sys.platform == \"win32\":\n        turbodbc_python_sources = turbodbc_sources + turbodbc_python_sources\n    turbodbc_python = Extension('turbodbc_intern',\n                                sources=turbodbc_python_sources,\n                                include_dirs=include_dirs,\n                                extra_compile_args=extra_compile_args + hidden_visibility_args,\n                                libraries=[odbclib] + turbodbc_libs,\n                                extra_link_args=python_module_link_args,\n                                library_dirs=library_dirs)\n    extension_modules.append(turbodbc_python)\n\n    \"\"\"\n    An extension module which contains Python bindings which require numpy support\n    to work. Not included in the standard Python bindings so this can stay optional.\n    \"\"\"\n    if _has_numpy_headers():\n        import numpy\n        turbodbc_numpy_sources = _get_source_files('turbodbc_numpy')\n        if sys.platform == \"win32\":\n            turbodbc_numpy_sources = turbodbc_sources + turbodbc_numpy_sources\n        turbodbc_numpy = Extension('turbodbc_numpy_support',\n                                   sources=turbodbc_numpy_sources,\n                                   include_dirs=include_dirs + [numpy.get_include()],\n                                   extra_compile_args=extra_compile_args + hidden_visibility_args,\n                                   libraries=[odbclib] + turbodbc_libs,\n                                   extra_link_args=python_module_link_args,\n                                   library_dirs=library_dirs)\n        extension_modules.append(turbodbc_numpy)\n\n    \"\"\"\n    An extension module which contains Python bindings which require Apache Arrow\n    support to work. Not included in the standard Python bindings so this can\n    stay optional.\n    \"\"\"\n    if _has_arrow_headers():\n        import pyarrow\n        pyarrow_location = os.path.dirname(pyarrow.__file__)\n        # For now, assume that we build against bundled pyarrow releases.\n        pyarrow_include_dir = os.path.join(pyarrow_location, 'include')\n        turbodbc_arrow_sources = _get_source_files('turbodbc_arrow')\n        pyarrow_module_link_args = list(python_module_link_args)\n        if sys.platform == \"win32\":\n            turbodbc_arrow_sources = turbodbc_sources + turbodbc_arrow_sources\n        elif sys.platform == \"darwin\":\n            pyarrow_module_link_args.append('-Wl,-rpath,@loader_path/pyarrow')\n        else:\n            pyarrow_module_link_args.append(\"-Wl,-rpath,$ORIGIN/pyarrow\")\n        turbodbc_arrow = Extension('turbodbc_arrow_support',\n                                   sources=turbodbc_arrow_sources,\n                                   include_dirs=include_dirs + [pyarrow_include_dir],\n                                   extra_compile_args=extra_compile_args + hidden_visibility_args,\n                                   libraries=[odbclib, 'arrow', 'arrow_python'] + turbodbc_libs,\n                                   extra_link_args=pyarrow_module_link_args,\n                                   library_dirs=library_dirs + [pyarrow_location])\n        extension_modules.append(turbodbc_arrow)\n\n    return extension_modules", "response": "Returns a list of extension modules that can be used to compile the C ++ library with Python bindings."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a connection to the database identified by the dsn or the connection_string.", "response": "def connect(dsn=None, turbodbc_options=None, connection_string=None, **kwargs):\n    \"\"\"\n    Create a connection with the database identified by the ``dsn`` or the ``connection_string``.\n\n    :param dsn: Data source name as given in the (unix) odbc.ini file\n           or (Windows) ODBC Data Source Administrator tool.\n    :param turbodbc_options: Options that control how turbodbc interacts with the database.\n           Create such a struct with `turbodbc.make_options()` or leave this blank to take the defaults.\n    :param connection_string: Preformatted ODBC connection string.\n           Specifying this and dsn or kwargs at the same time raises ParameterError.\n    :param \\**kwargs: You may specify additional options as you please. These options will go into\n           the connection string that identifies the database. Valid options depend on the specific database you\n           would like to connect with (e.g. `user` and `password`, or `uid` and `pwd`)\n    :return: A connection to your database\n    \"\"\"\n    if turbodbc_options is None:\n        turbodbc_options = make_options()\n\n    if connection_string is not None and (dsn is not None or len(kwargs) > 0):\n        raise ParameterError(\"Both connection_string and dsn or kwargs specified\")\n\n    if connection_string is None:\n        connection_string = _make_connection_string(dsn, **kwargs)\n\n    connection = Connection(intern_connect(connection_string,\n                                           turbodbc_options))\n\n    return connection"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef description(self):\n        if self.result_set:\n            info = self.result_set.get_column_info()\n            return [(c.name, c.type_code(), None, None, None, None, c.supports_null_values) for c in info]\n        else:\n            return None", "response": "Retrieve a description of the columns in the current result set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute an SQL command or query.", "response": "def execute(self, sql, parameters=None):\n        \"\"\"\n        Execute an SQL command or query\n\n        :param sql: A (unicode) string that contains the SQL command or query. If you would like to\n               use parameters, please use a question mark ``?`` at the location where the\n               parameter shall be inserted.\n        :param parameters: An iterable of parameter values. The number of values must match\n               the number of parameters in the SQL string.\n        :return: The ``Cursor`` object to allow chaining of operations.\n        \"\"\"\n        self.rowcount = -1\n        self._assert_valid()\n        self.impl.prepare(sql)\n        if parameters:\n            buffer = make_parameter_set(self.impl)\n            buffer.add_set(parameters)\n            buffer.flush()\n        return self._execute()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting an SQL command or query with multiple parameter sets that are passed in a column - wise fashion as opposed to the row - wise parameters in executemany.", "response": "def executemanycolumns(self, sql, columns):\n        \"\"\"\n        Execute an SQL command or query with multiple parameter sets that are passed in\n        a column-wise fashion as opposed to the row-wise parameters in ``executemany()``.\n        This function is a turbodbc-specific extension to PEP-249.\n\n        :param sql: A (unicode) string that contains the SQL command or query. If you would like to\n               use parameters, please use a question mark ``?`` at the location where the\n               parameter shall be inserted.\n        :param columns: An iterable of NumPy MaskedArrays. The Arrays represent the columnar\n               parameter data,\n        :return: The ``Cursor`` object to allow chaining of operations.\n        \"\"\"\n        self.rowcount = -1\n        self._assert_valid()\n\n        self.impl.prepare(sql)\n\n        if _has_arrow_support():\n            import pyarrow as pa\n            if isinstance(columns, pa.Table):\n                from turbodbc_arrow_support import set_arrow_parameters\n\n                for column in columns.itercolumns():\n                    if column.data.num_chunks != 1:\n                        raise NotImplementedError(\"Chunked Arrays are not yet supported\")\n\n                set_arrow_parameters(self.impl, columns)\n                return self._execute()\n\n        # Workaround to give users a better error message without a need\n        # to import pyarrow\n        if columns.__class__.__module__.startswith('pyarrow'):\n            raise Error(_NO_ARROW_SUPPORT_MSG)\n\n        if not _has_numpy_support():\n            raise Error(_NO_NUMPY_SUPPORT_MSG)\n\n        _assert_numpy_column_preconditions(columns)\n\n\n        from numpy.ma import MaskedArray\n        from turbodbc_numpy_support import set_numpy_parameters\n        split_arrays = []\n        for column in columns:\n            if isinstance(column, MaskedArray):\n                split_arrays.append((column.data, column.mask, str(column.dtype)))\n            else:\n                split_arrays.append((column, False, str(column.dtype)))\n        set_numpy_parameters(self.impl, split_arrays)\n\n        return self._execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetchone(self):\n        self._assert_valid_result_set()\n        result = self.result_set.fetch_row()\n        if len(result) == 0:\n            return None\n        else:\n            return result", "response": "Returns a single row of a result set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetchmany(self, size=None):\n        if size is None:\n            size = self.arraysize\n        if (size <= 0):\n            raise InterfaceError(\"Invalid arraysize {} for fetchmany()\".format(size))\n\n        return [row for row in islice(self, size)]", "response": "Fetches a batch of rows from the active result set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetchallnumpy(self):\n        from numpy.ma import concatenate\n        batches = list(self._numpy_batch_generator())\n        column_names = [description[0] for description in self.description]\n        return OrderedDict(zip(column_names, [concatenate(column) for column in zip(*batches)]))", "response": "Fetch all rows in the active result set generated with execute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetchnumpybatches(self):\n        batchgen = self._numpy_batch_generator()\n        column_names = [description[0] for description in self.description]\n        for next_batch in batchgen:\n            yield OrderedDict(zip(column_names, next_batch))", "response": "Returns an iterator over all rows in the active result set generated with execute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetcharrowbatches(self, strings_as_dictionary=False, adaptive_integers=False):\n        self._assert_valid_result_set()\n        if _has_arrow_support():\n            from turbodbc_arrow_support import make_arrow_result_set\n            rs = make_arrow_result_set(\n                self.impl.get_result_set(),\n                strings_as_dictionary,\n                adaptive_integers)\n            first_run = True\n            while True:\n                table = rs.fetch_next_batch()\n                is_empty_batch = (len(table) == 0)\n                if is_empty_batch and not first_run:\n                    return # Let us return a typed result set at least once\n                first_run = False\n                yield table\n        else:\n            raise Error(_NO_ARROW_SUPPORT_MSG)", "response": "Returns an iterable of tables from the active result set generated by execute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching all rows in the active result set generated by execute.", "response": "def fetchallarrow(self, strings_as_dictionary=False, adaptive_integers=False):\n        \"\"\"\n        Fetches all rows in the active result set generated with ``execute()`` or\n        ``executemany()``.\n\n        :param strings_as_dictionary: If true, fetch string columns as\n                 dictionary[string] instead of a plain string column.\n\n        :param adaptive_integers: If true, instead of the integer type returned\n                by the database (driver), this produce integer columns with the\n                smallest possible integer type in which all values can be\n                stored. Be aware that here the type depends on the resulting\n                data.\n\n        :return: ``pyarrow.Table``\n        \"\"\"\n        self._assert_valid_result_set()\n        if _has_arrow_support():\n            from turbodbc_arrow_support import make_arrow_result_set\n            return make_arrow_result_set(\n                    self.impl.get_result_set(),\n                    strings_as_dictionary,\n                    adaptive_integers).fetch_all()\n        else:\n            raise Error(_NO_ARROW_SUPPORT_MSG)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to a new pipe in message mode.", "response": "def connect_to_pipe(pipe_name):\n    \"\"\"\n    Connect to a new pipe in message mode.\n    \"\"\"\n    pipe_handle = windll.kernel32.CreateFileW(\n        pipe_name,\n        DWORD(GENERIC_READ | GENERIC_WRITE | FILE_WRITE_ATTRIBUTES),\n        DWORD(0),  # No sharing.\n        None,  # Default security attributes.\n        DWORD(OPEN_EXISTING),  # dwCreationDisposition.\n        FILE_FLAG_OVERLAPPED,  # dwFlagsAndAttributes.\n        None  # hTemplateFile,\n    )\n    if pipe_handle == INVALID_HANDLE_VALUE:\n        raise Exception('Invalid handle. Connecting to pipe %r failed.' % pipe_name)\n\n    # Turn pipe into message mode.\n    dwMode = DWORD(PIPE_READMODE_MESSAGE)\n    windll.kernel32.SetNamedPipeHandleState(\n        pipe_handle,\n        byref(dwMode),\n        None,\n        None)\n\n    return pipe_handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a message from a pipe.", "response": "def read_message_from_pipe(pipe_handle):\n    \"\"\"\n    (coroutine)\n    Read message from this pipe. Return text.\n    \"\"\"\n    data = yield From(read_message_bytes_from_pipe(pipe_handle))\n    assert isinstance(data, bytes)\n    raise Return(data.decode('utf-8', 'ignore'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_message_bytes_from_pipe(pipe_handle):\n    overlapped = OVERLAPPED()\n    overlapped.hEvent = create_event()\n\n    try:\n        buff = create_string_buffer(BUFSIZE + 1)\n        c_read = DWORD()\n\n        success = windll.kernel32.ReadFile(\n            pipe_handle,\n            buff,\n            DWORD(BUFSIZE),\n            byref(c_read),\n            byref(overlapped))\n\n        if success:\n            buff[c_read.value] = b'\\0'\n            raise Return(buff.value)\n\n        error_code = windll.kernel32.GetLastError()\n\n        if error_code == ERROR_IO_PENDING:\n            yield From(wait_for_event(overlapped.hEvent))\n\n            success = windll.kernel32.GetOverlappedResult(\n                pipe_handle,\n                byref(overlapped),\n                byref(c_read),\n                BOOL(False))\n\n            if success:\n                buff[c_read.value] = b'\\0'\n                raise Return(buff.value)\n\n            else:\n                error_code = windll.kernel32.GetLastError()\n                if error_code == ERROR_BROKEN_PIPE:\n                    raise BrokenPipeError\n\n                elif error_code == ERROR_MORE_DATA:\n                    more_data = yield From(read_message_bytes_from_pipe(pipe_handle))\n                    raise Return(buff.value + more_data)\n                else:\n                    raise Exception(\n                        'reading overlapped IO failed. error_code=%r' % error_code)\n\n        elif error_code == ERROR_BROKEN_PIPE:\n            raise BrokenPipeError\n\n        elif error_code == ERROR_MORE_DATA:\n            more_data = yield From(read_message_bytes_from_pipe(pipe_handle))\n            raise Return(buff.value + more_data)\n\n        else:\n            raise Exception('Reading pipe failed, error_code=%s' % error_code)\n    finally:\n        windll.kernel32.CloseHandle(overlapped.hEvent)", "response": "Reads a message from a pipe and returns bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_event(event):\n    f = Future()\n    def ready():\n        get_event_loop().remove_win32_handle(event)\n        f.set_result(None)\n    get_event_loop().add_win32_handle(event, ready)\n    return f", "response": "Wraps a win32 event into a Future and wait for it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading messages from the Win32 pipe server and handle them.", "response": "def _start_reader(self):\n        \"\"\"\n        Read messages from the Win32 pipe server and handle them.\n        \"\"\"\n        while True:\n            message = yield From(self.pipe.read_message())\n            self._process(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process(self, data_buffer):\n        packet = json.loads(data_buffer)\n\n        if packet['cmd'] == 'out':\n            # Call os.write manually. In Python2.6, sys.stdout.write doesn't use UTF-8.\n            original_mode = DWORD(0)\n            windll.kernel32.GetConsoleMode(self._hconsole, byref(original_mode))\n\n            windll.kernel32.SetConsoleMode(self._hconsole, DWORD(\n                ENABLE_PROCESSED_INPUT | ENABLE_VIRTUAL_TERMINAL_PROCESSING))\n\n            try:\n                os.write(sys.stdout.fileno(), packet['data'].encode('utf-8'))\n            finally:\n                windll.kernel32.SetConsoleMode(self._hconsole, original_mode)\n\n        elif packet['cmd'] == 'suspend':\n            # Suspend client process to background.\n            pass\n\n        elif packet['cmd'] == 'mode':\n            pass", "response": "Process incoming packet from server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreports terminal size to server.", "response": "def _send_size(self):\n        \" Report terminal size to server. \"\n        output = Win32Output(sys.stdout)\n        rows, cols = output.get_size()\n\n        self._send_packet({\n            'cmd': 'size',\n            'data': [rows, cols]\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting number at position.", "response": "def _draw_number(screen, x_offset, y_offset, number, style='class:clock',\n                 transparent=False):\n    \" Write number at position. \"\n    fg = Char(' ', 'class:clock')\n    bg = Char(' ', '')\n\n    for y, row in enumerate(_numbers[number]):\n        screen_row = screen.data_buffer[y + y_offset]\n        for x, n in enumerate(row):\n            if n == '#':\n                screen_row[x + x_offset] = fg\n            elif not transparent:\n                screen_row[x + x_offset] = bg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_split(pymux, window, split):\n    assert isinstance(split, (arrangement.HSplit, arrangement.VSplit))\n    is_vsplit = isinstance(split, arrangement.VSplit)\n\n    def get_average_weight():\n        \"\"\" Calculate average weight of the children. Return 1 if none of\n        the children has a weight specified yet. \"\"\"\n        weights = 0\n        count = 0\n\n        for i in split:\n            if i in split.weights:\n                weights += split.weights[i]\n                count += 1\n\n        if weights:\n            return max(1, weights // count)\n        else:\n            return 1\n\n    def report_write_position_callback(item, write_position):\n        \"\"\"\n        When the layout is rendered, store the actial dimensions as\n        weights in the arrangement.VSplit/HSplit classes.\n\n        This is required because when a pane is resized with an increase of +1,\n        we want to be sure that this corresponds exactly with one row or\n        column. So, that updating weights corresponds exactly 1/1 to updating\n        the size of the panes.\n        \"\"\"\n        if is_vsplit:\n            split.weights[item] = write_position.width\n        else:\n            split.weights[item] = write_position.height\n\n    def get_size(item):\n        return D(weight=split.weights.get(item) or average_weight)\n\n    content = []\n    average_weight = get_average_weight()\n\n    for i, item in enumerate(split):\n        # Create function for calculating dimensions for child.\n        width = height = None\n        if is_vsplit:\n            width = partial(get_size, item)\n        else:\n            height = partial(get_size, item)\n\n        # Create child.\n        if isinstance(item, (arrangement.VSplit, arrangement.HSplit)):\n            child = _create_split(pymux, window, item)\n        elif isinstance(item, arrangement.Pane):\n            child = _create_container_for_process(pymux, window, item)\n        else:\n            raise TypeError('Got %r' % (item,))\n\n        # Wrap child in `SizedBox` to enforce dimensions and sync back.\n        content.append(SizedBox(\n            child, width=width, height=height,\n            report_write_position_callback=partial(report_write_position_callback, item)))\n\n    # Create prompt_toolkit Container.\n    if is_vsplit:\n        return_cls = VSplit\n        padding_char = _border_vertical\n    else:\n        return_cls = HSplit\n        padding_char = _border_horizontal\n\n    return return_cls(content,\n            padding=1,\n            padding_char=padding_char)", "response": "Create a prompt_toolkit Container instance for the given pymux split."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Container for a process.", "response": "def _create_container_for_process(pymux, window, arrangement_pane, zoom=False):\n    \"\"\"\n    Create a `Container` with a titlebar for a process.\n    \"\"\"\n    @Condition\n    def clock_is_visible():\n        return arrangement_pane.clock_mode\n\n    @Condition\n    def pane_numbers_are_visible():\n        return pymux.display_pane_numbers\n\n    terminal_is_focused = has_focus(arrangement_pane.terminal)\n\n    def get_terminal_style():\n        if terminal_is_focused():\n            result = 'class:terminal.focused'\n        else:\n            result = 'class:terminal'\n        return result\n\n    def get_titlebar_text_fragments():\n        result = []\n\n        if zoom:\n            result.append(('class:titlebar-zoom', ' Z '))\n\n        if arrangement_pane.process.is_terminated:\n            result.append(('class:terminated', ' Terminated '))\n\n        # Scroll buffer info.\n        if arrangement_pane.display_scroll_buffer:\n            result.append(('class:copymode', ' %s ' % arrangement_pane.scroll_buffer_title))\n\n            # Cursor position.\n            document = arrangement_pane.scroll_buffer.document\n            result.append(('class:copymode.position', ' %i,%i ' % (\n                document.cursor_position_row, document.cursor_position_col)))\n\n        if arrangement_pane.name:\n            result.append(('class:name', ' %s ' % arrangement_pane.name))\n            result.append(('', ' '))\n\n        return result + [\n            ('', format_pymux_string(pymux, ' #T ', pane=arrangement_pane))  # XXX: Make configurable.\n        ]\n\n    def get_pane_index():\n        try:\n            w = pymux.arrangement.get_active_window()\n            index = w.get_pane_index(arrangement_pane)\n        except ValueError:\n            index = '/'\n\n        return '%3s ' % index\n\n    def on_click():\n        \" Click handler for the clock. When clicked, select this pane. \"\n        arrangement_pane.clock_mode = False\n        pymux.arrangement.get_active_window().active_pane = arrangement_pane\n        pymux.invalidate()\n\n\n    return HighlightBordersIfActive(\n        window,\n        arrangement_pane,\n        get_terminal_style,\n        FloatContainer(\n            HSplit([\n                # The terminal.\n                TracePaneWritePosition(\n                    pymux, arrangement_pane,\n                    content=arrangement_pane.terminal),\n            ]),\n\n            #\n            floats=[\n                # The title bar.\n                Float(content=\n                    ConditionalContainer(\n                        content=VSplit([\n                                Window(\n                                    height=1,\n                                    content=FormattedTextControl(\n                                        get_titlebar_text_fragments)),\n                                Window(\n                                    height=1,\n                                    width=4,\n                                    content=FormattedTextControl(get_pane_index),\n                                    style='class:paneindex')\n                            ], style='class:titlebar'),\n                        filter=Condition(lambda: pymux.enable_pane_status)),\n                    left=0, right=0, top=-1, height=1, z_index=Z_INDEX.WINDOW_TITLE_BAR),\n\n                # The clock.\n                Float(\n                    content=ConditionalContainer(BigClock(on_click),\n                      filter=clock_is_visible)),\n\n                # Pane number.\n                Float(content=ConditionalContainer(\n                      content=PaneNumber(pymux, arrangement_pane),\n                      filter=pane_numbers_are_visible)),\n            ]\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef focus_left(pymux):\n    \" Move focus to the left. \"\n    _move_focus(pymux,\n                lambda wp: wp.xpos - 2,  # 2 in order to skip over the border.\n                lambda wp: wp.ypos)", "response": "Move focus to the left."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove focus to the right.", "response": "def focus_right(pymux):\n    \" Move focus to the right. \"\n    _move_focus(pymux,\n                lambda wp: wp.xpos + wp.width + 1,\n                lambda wp: wp.ypos)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _move_focus(pymux, get_x, get_y):\n    \" Move focus of the active window. \"\n    window = pymux.arrangement.get_active_window()\n\n    try:\n        write_pos = pymux.get_client_state().layout_manager.pane_write_positions[window.active_pane]\n    except KeyError:\n        pass\n    else:\n        x = get_x(write_pos)\n        y = get_y(write_pos)\n\n        # Look for the pane at this position.\n        for pane, wp in pymux.get_client_state().layout_manager.pane_write_positions.items():\n            if (wp.xpos <= x < wp.xpos + wp.width and\n                    wp.ypos <= y < wp.ypos + wp.height):\n                window.active_pane = pane\n                return", "response": "Move focus of the active window."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_to_screen(self, screen, mouse_handlers, write_position,\n                        parent_style, erase_bg, z_index):\n        \" Fill the whole area of write_position with dots. \"\n        default_char = Char(' ', 'class:background')\n        dot = Char('.', 'class:background')\n\n        ypos = write_position.ypos\n        xpos = write_position.xpos\n\n        for y in range(ypos, ypos + write_position.height):\n            row = screen.data_buffer[y]\n\n            for x in range(xpos, xpos + write_position.width):\n                row[x] = dot if (x + y) % 3 == 0 else default_char", "response": "Fill the whole area of write_position with dots."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef display_popup(self, title, content):\n        assert isinstance(title, six.text_type)\n        assert isinstance(content, six.text_type)\n\n        self.popup_dialog.title = title\n        self._popup_textarea.text = content\n        self.client_state.display_popup = True\n        get_app().layout.focus(self._popup_textarea)", "response": "Display a pop - up dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_select_window_handler(self, window):\n        \" Return a mouse handler that selects the given window when clicking. \"\n        def handler(mouse_event):\n            if mouse_event.event_type == MouseEventType.MOUSE_DOWN:\n                self.pymux.arrangement.set_active_window(window)\n                self.pymux.invalidate()\n            else:\n                return NotImplemented  # Event not handled here.\n        return handler", "response": "Return a mouse handler that selects the given window when clicking."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the main prompt_toolkit layout.", "response": "def _create_layout(self):\n        \"\"\"\n        Generate the main prompt_toolkit layout.\n        \"\"\"\n        waits_for_confirmation = WaitsForConfirmation(self.pymux)\n\n        return FloatContainer(\n            content=HSplit([\n                # The main window.\n                FloatContainer(\n                    Background(),\n                    floats=[\n                        Float(width=lambda: self.pymux.get_window_size().columns,\n                              height=lambda: self.pymux.get_window_size().rows,\n                              content=DynamicBody(self.pymux))\n                    ]),\n                # Status bar.\n                ConditionalContainer(\n                    content=VSplit([\n                        # Left.\n                        Window(\n                            height=1,\n                            width=(lambda: D(max=self.pymux.status_left_length)),\n                            dont_extend_width=True,\n                            content=FormattedTextControl(self._get_status_left_tokens)),\n                        # List of windows in the middle.\n                        Window(\n                            height=1,\n                            char=' ',\n                            align=self._get_align,\n                            content=FormattedTextControl(self._get_status_tokens)),\n                        # Right.\n                        Window(\n                            height=1,\n                            width=(lambda: D(max=self.pymux.status_right_length)),\n                            dont_extend_width=True,\n                            align=WindowAlign.RIGHT,\n                            content=FormattedTextControl(self._get_status_right_tokens))\n                    ], z_index=Z_INDEX.STATUS_BAR, style='class:statusbar'),\n                    filter=Condition(lambda: self.pymux.enable_status),\n                )\n            ]),\n            floats=[\n                Float(bottom=1, left=0, z_index=Z_INDEX.MESSAGE_TOOLBAR,\n                      content=MessageToolbar(self.client_state)),\n                Float(left=0, right=0, bottom=0, content=HSplit([\n                    # Wait for confirmation toolbar.\n                    ConditionalContainer(\n                        content=Window(\n                            height=1,\n                            content=ConfirmationToolbar(self.pymux, self.client_state),\n                            z_index=Z_INDEX.COMMAND_LINE,\n                        ),\n                        filter=waits_for_confirmation,\n                    ),\n                    # ':' prompt toolbar.\n                    ConditionalContainer(\n                        content=Window(\n                            height=D(min=1),  # Can be more if the command is multiline.\n                            style='class:commandline',\n                            dont_extend_height=True,\n                            content=BufferControl(\n                                buffer=self.client_state.command_buffer,\n                                preview_search=True,\n                                input_processors=[\n                                    AppendAutoSuggestion(),\n                                    BeforeInput(':', style='class:commandline-prompt'),\n                                    ShowArg(),\n                                    HighlightSelectionProcessor(),\n                                ]),\n                            z_index=Z_INDEX.COMMAND_LINE,\n                        ),\n                        filter=has_focus(self.client_state.command_buffer),\n                    ),\n                    # Other command-prompt commands toolbar.\n                    ConditionalContainer(\n                        content=Window(\n                            height=1,\n                            style='class:commandline',\n                            content=BufferControl(\n                                buffer=self.client_state.prompt_buffer,\n                                input_processors=[\n                                    BeforeInput(self._before_prompt_command_tokens),\n                                    AppendAutoSuggestion(),\n                                    HighlightSelectionProcessor(),\n                                ]),\n                            z_index=Z_INDEX.COMMAND_LINE,\n                        ),\n                        filter=has_focus(self.client_state.prompt_buffer),\n                    ),\n                ])),\n                # Keys pop-up.\n                Float(\n                    content=ConditionalContainer(\n                        content=self.popup_dialog,\n                        filter=Condition(lambda: self.client_state.display_popup),\n                    ),\n                    left=3, right=3, top=5, bottom=5,\n                    z_index=Z_INDEX.POPUP,\n                ),\n                Float(xcursor=True, ycursor=True, content=CompletionsMenu(max_height=12)),\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_body(self):\n        \" Return the Container object for the current CLI. \"\n        new_hash = self.pymux.arrangement.invalidation_hash()\n\n        # Return existing layout if nothing has changed to the arrangement.\n        app = get_app()\n\n        if app in self._bodies_for_app:\n            existing_hash, container = self._bodies_for_app[app]\n            if existing_hash == new_hash:\n                return container\n\n        # The layout changed. Build a new layout when the arrangement changed.\n        new_layout = self._build_layout()\n        self._bodies_for_app[app] = (new_hash, new_layout)\n        return new_layout", "response": "Return the Container object for the current CLI."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrebuilding a new Container object and return that.", "response": "def _build_layout(self):\n        \" Rebuild a new Container object and return that. \"\n        logger.info('Rebuilding layout.')\n\n        if not self.pymux.arrangement.windows:\n            # No Pymux windows in the arrangement.\n            return Window()\n\n        active_window = self.pymux.arrangement.get_active_window()\n\n        # When zoomed, only show the current pane, otherwise show all of them.\n        if active_window.zoom:\n            return to_container(_create_container_for_process(\n                self.pymux, active_window, active_window.active_pane, zoom=True))\n        else:\n            window = self.pymux.arrangement.get_active_window()\n            return HSplit([\n                # Some spacing for the top status bar.\n                ConditionalContainer(\n                    content=Window(height=1),\n                    filter=Condition(lambda: self.pymux.enable_pane_status)),\n                # The actual content.\n                _create_split(self.pymux, window, window.root)\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bind_and_listen_on_socket(socket_name, accept_callback):\n    if is_windows():\n        from .win32_server import bind_and_listen_on_win32_socket\n        return bind_and_listen_on_win32_socket(socket_name, accept_callback)\n    else:\n        from .posix import bind_and_listen_on_posix_socket\n        return bind_and_listen_on_posix_socket(socket_name, accept_callback)", "response": "Bind and listen on a socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_clients():\n    p = '%s/pymux.sock.%s.*' % (tempfile.gettempdir(), getpass.getuser())\n    for path in glob.glob(p):\n        try:\n            yield PosixClient(path)\n        except socket.error:\n            pass", "response": "List all the server that are running."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attach(self, detach_other_clients=False, color_depth=ColorDepth.DEPTH_8_BIT):\n        assert isinstance(detach_other_clients, bool)\n\n        self._send_size()\n        self._send_packet({\n            'cmd': 'start-gui',\n            'detach-others': detach_other_clients,\n            'color-depth': color_depth,\n            'term': os.environ.get('TERM', ''),\n            'data': ''\n        })\n\n        with raw_mode(sys.stdin.fileno()):\n            data_buffer = b''\n\n            stdin_fd = sys.stdin.fileno()\n            socket_fd = self.socket.fileno()\n            current_timeout = INPUT_TIMEOUT  # Timeout, used to flush escape sequences.\n\n            try:\n                def winch_handler(signum, frame):\n                    self._send_size()\n\n                signal.signal(signal.SIGWINCH, winch_handler)\n                while True:\n                    r = select_fds([stdin_fd, socket_fd], current_timeout)\n\n                    if socket_fd in r:\n                        # Received packet from server.\n                        data = self.socket.recv(1024)\n\n                        if data == b'':\n                            # End of file. Connection closed.\n                            # Reset terminal\n                            o = Vt100_Output.from_pty(sys.stdout)\n                            o.quit_alternate_screen()\n                            o.disable_mouse_support()\n                            o.disable_bracketed_paste()\n                            o.reset_attributes()\n                            o.flush()\n                            return\n                        else:\n                            data_buffer += data\n\n                            while b'\\0' in data_buffer:\n                                pos = data_buffer.index(b'\\0')\n                                self._process(data_buffer[:pos])\n                                data_buffer = data_buffer[pos + 1:]\n\n                    elif stdin_fd in r:\n                        # Got user input.\n                        self._process_stdin()\n                        current_timeout = INPUT_TIMEOUT\n\n                    else:\n                        # Timeout. (Tell the server to flush the vt100 Escape.)\n                        self._send_packet({'cmd': 'flush-input'})\n                        current_timeout = None\n            finally:\n                signal.signal(signal.SIGWINCH, signal.SIG_IGN)", "response": "Attaches the client to the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing incoming packet from server.", "response": "def _process(self, data_buffer):\n        \"\"\"\n        Handle incoming packet from server.\n        \"\"\"\n        packet = json.loads(data_buffer.decode('utf-8'))\n\n        if packet['cmd'] == 'out':\n            # Call os.write manually. In Python2.6, sys.stdout.write doesn't use UTF-8.\n            os.write(sys.stdout.fileno(), packet['data'].encode('utf-8'))\n\n        elif packet['cmd'] == 'suspend':\n            # Suspend client process to background.\n            if hasattr(signal, 'SIGTSTP'):\n                os.kill(os.getpid(), signal.SIGTSTP)\n\n        elif packet['cmd'] == 'mode':\n            # Set terminal to raw/cooked.\n            action = packet['data']\n\n            if action == 'raw':\n                cm = raw_mode(sys.stdin.fileno())\n                cm.__enter__()\n                self._mode_context_managers.append(cm)\n\n            elif action == 'cooked':\n                cm = cooked_mode(sys.stdin.fileno())\n                cm.__enter__()\n                self._mode_context_managers.append(cm)\n\n            elif action == 'restore' and self._mode_context_managers:\n                cm = self._mode_context_managers.pop()\n                cm.__exit__()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_stdin(self):\n        with nonblocking(sys.stdin.fileno()):\n            data = self._stdin_reader.read()\n\n        # Send input in chunks of 4k.\n        step = 4056\n        for i in range(0, len(data), step):\n            self._send_packet({\n                'cmd': 'in',\n                'data': data[i:i + step],\n            })", "response": "Read and send data from stdin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreport terminal size to server.", "response": "def _send_size(self):\n        \" Report terminal size to server. \"\n        rows, cols = _get_size(sys.stdout.fileno())\n        self._send_packet({\n            'cmd': 'size',\n            'data': [rows, cols]\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_command(self, buffer):\n        \" When text is accepted in the command line. \"\n        text = buffer.text\n\n        # First leave command mode. We want to make sure that the working\n        # pane is focused again before executing the command handers.\n        self.pymux.leave_command_mode(append_to_history=True)\n\n        # Execute command.\n        self.pymux.handle_command(text)", "response": "When text is accepted in the command line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an application instance for this instance.", "response": "def _create_app(self):\n        \"\"\"\n        Create `Application` instance for this .\n        \"\"\"\n        pymux = self.pymux\n\n        def on_focus_changed():\n            \"\"\" When the focus changes to a read/write buffer, make sure to go\n            to insert mode. This happens when the ViState was set to NAVIGATION\n            in the copy buffer. \"\"\"\n            vi_state = app.vi_state\n\n            if app.current_buffer.read_only():\n                vi_state.input_mode = InputMode.NAVIGATION\n            else:\n                vi_state.input_mode = InputMode.INSERT\n\n        app = Application(\n            output=self.output,\n            input=self.input,\n            color_depth=self.color_depth,\n\n            layout=Layout(container=self.layout_manager.layout),\n            key_bindings=pymux.key_bindings_manager.key_bindings,\n            mouse_support=Condition(lambda: pymux.enable_mouse_support),\n            full_screen=True,\n            style=self.pymux.style,\n            style_transformation=ConditionalStyleTransformation(\n                SwapLightAndDarkStyleTransformation(),\n                Condition(lambda: self.pymux.swap_dark_and_light),\n            ),\n            on_invalidate=(lambda _: pymux.invalidate()))\n\n        # Synchronize the Vi state with the CLI object.\n        # (This is stored in the current class, but expected to be in the\n        # CommandLineInterface.)\n        def sync_vi_state(_):\n            VI = EditingMode.VI\n            EMACS = EditingMode.EMACS\n\n            if self.confirm_text or self.prompt_command or self.command_mode:\n                app.editing_mode = VI if pymux.status_keys_vi_mode else EMACS\n            else:\n                app.editing_mode = VI if pymux.mode_keys_vi_mode else EMACS\n\n        app.key_processor.before_key_press += sync_vi_state\n        app.key_processor.after_key_press += sync_vi_state\n        app.key_processor.after_key_press += self.sync_focus\n\n        # Set render postpone time. (.1 instead of 0).\n        # This small change ensures that if for a split second a process\n        # outputs a lot of information, we don't give the highest priority to\n        # rendering output. (Nobody reads that fast in real-time.)\n        app.max_render_postpone_time = .1  # Second.\n\n        # Hide message when a key has been pressed.\n        def key_pressed(_):\n            self.message = None\n        app.key_processor.before_key_press += key_pressed\n\n        # The following code needs to run with the application active.\n        # Especially, `create_window` needs to know what the current\n        # application is, in order to focus the new pane.\n        with set_app(app):\n            # Redraw all CLIs. (Adding a new client could mean that the others\n            # change size, so everything has to be redrawn.)\n            pymux.invalidate()\n\n            pymux.startup()\n\n        return app"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync_focus(self, *_):\n        # Pop-up displayed?\n        if self.display_popup:\n            self.app.layout.focus(self.layout_manager.popup_dialog)\n            return\n\n        # Confirm.\n        if self.confirm_text:\n            return\n\n        # Custom prompt.\n        if self.prompt_command:\n            return # Focus prompt\n\n        # Command mode.\n        if self.command_mode:\n            return # Focus command\n\n        # No windows left, return. We will quit soon.\n        if not self.pymux.arrangement.windows:\n            return\n\n        pane = self.pymux.arrangement.get_active_pane()\n        self.app.layout.focus(pane.terminal)", "response": "Syncs the focused window from the pymux arrangement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the background thread that auto refreshes all clients according to self. status_interval.", "response": "def _start_auto_refresh_thread(self):\n        \"\"\"\n        Start the background thread that auto refreshes all clients according to\n        `self.status_interval`.\n        \"\"\"\n        def run():\n            while True:\n                time.sleep(self.status_interval)\n                self.invalidate()\n\n        t = threading.Thread(target=run)\n        t.daemon = True\n        t.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_client_state(self):\n        \" Return the active ClientState instance. \"\n        app = get_app()\n        for client_state in self._client_states.values():\n            if client_state.app == app:\n                return client_state\n\n        raise ValueError('Client state for app %r not found' % (app, ))", "response": "Return the active ClientState instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the active Connection instance.", "response": "def get_connection(self):\n        \" Return the active Connection instance. \"\n        app = get_app()\n        for connection, client_state in self._client_states.items():\n            if client_state.app == app:\n                return connection\n\n        raise ValueError('Connection for app %r not found' % (app, ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_title(self):\n        w = self.arrangement.get_active_window()\n\n        if w and w.active_process:\n            title = w.active_process.screen.title\n        else:\n            title = ''\n\n        if title:\n            return '%s - Pymux' % (title, )\n        else:\n            return 'Pymux'", "response": "Returns the title of the active process or the empty string if the active process is not in the titlebar."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the size of the window that is used for the DynamicBody.", "response": "def get_window_size(self):\n        \"\"\"\n        Get the size to be used for the DynamicBody.\n        This will be the smallest size of all clients.\n        \"\"\"\n        def active_window_for_app(app):\n            with set_app(app):\n                return self.arrangement.get_active_window()\n\n        active_window = self.arrangement.get_active_window()\n\n        # Get sizes for connections watching the same window.\n        apps = [client_state.app for client_state in self._client_states.values()\n                if active_window_for_app(client_state.app) == active_window]\n        sizes = [app.output.get_size() for app in apps]\n\n        rows = [s.rows for s in sizes]\n        columns = [s.columns for s in sizes]\n\n        if rows and columns:\n            return Size(rows=min(rows) - (1 if self.enable_status else 0),\n                        columns=min(columns))\n        else:\n            return Size(rows=20, columns=80)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new pane.", "response": "def _create_pane(self, window=None, command=None, start_directory=None):\n        \"\"\"\n        Create a new :class:`pymux.arrangement.Pane` instance. (Don't put it in\n        a window yet.)\n\n        :param window: If a window is given, take the CWD of the current\n            process of that window as the start path for this pane.\n        :param command: If given, run this command instead of `self.default_shell`.\n        :param start_directory: If given, use this as the CWD.\n        \"\"\"\n        assert window is None or isinstance(window, Window)\n        assert command is None or isinstance(command, six.text_type)\n        assert start_directory is None or isinstance(start_directory, six.text_type)\n\n        def done_callback():\n            \" When the process finishes. \"\n            if not self.remain_on_exit:\n                # Remove pane from layout.\n                self.arrangement.remove_pane(pane)\n\n                # No panes left? -> Quit.\n                if not self.arrangement.has_panes:\n                    self.stop()\n\n                # Make sure the right pane is focused for each client.\n                for client_state in self._client_states.values():\n                    client_state.sync_focus()\n\n            self.invalidate()\n\n        def bell():\n            \" Sound bell on all clients. \"\n            if self.enable_bell:\n                for c in self.apps:\n                    c.output.bell()\n\n        # Start directory.\n        if start_directory:\n            path = start_directory\n        elif window and window.active_process:\n            # When the path of the active process is known,\n            # start the new process at the same location.\n            path = window.active_process.get_cwd()\n        else:\n            path = None\n\n        def before_exec():\n            \" Called in the process fork (in the child process). \"\n            # Go to this directory.\n            try:\n                os.chdir(path or self.original_cwd)\n            except OSError:\n                pass  # No such file or directory.\n\n            # Set terminal variable. (We emulate xterm.)\n            os.environ['TERM'] = self.default_terminal\n\n            # Make sure to set the PYMUX environment variable.\n            if self.socket_name:\n                os.environ['PYMUX'] = '%s,%i' % (\n                    self.socket_name, pane.pane_id)\n\n        if command:\n            command = command.split()\n        else:\n            command = [self.default_shell]\n\n        # Create new pane and terminal.\n        terminal = Terminal(done_callback=done_callback, bell_func=bell,\n                            before_exec_func=before_exec)\n        pane = Pane(terminal)\n\n        # Keep track of panes. This is a WeakKeyDictionary, we only add, but\n        # don't remove.\n        self.panes_by_id[pane.pane_id] = pane\n\n        logger.info('Created process %r.', command)\n\n        return pane"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvalidate the UI for all clients.", "response": "def invalidate(self):\n        \" Invalidate the UI for all clients. \"\n        logger.info('Invalidating %s applications', len(self.apps))\n\n        for app in self.apps:\n            app.invalidate()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new window in the arrangement.", "response": "def create_window(self, command=None, start_directory=None, name=None):\n        \"\"\"\n        Create a new :class:`pymux.arrangement.Window` in the arrangement.\n        \"\"\"\n        assert command is None or isinstance(command, six.text_type)\n        assert start_directory is None or isinstance(start_directory, six.text_type)\n\n        pane = self._create_pane(None, command, start_directory=start_directory)\n\n        self.arrangement.create_window(pane, name=name)\n        pane.focus()\n        self.invalidate()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_process(self, command=None, vsplit=False, start_directory=None):\n        assert command is None or isinstance(command, six.text_type)\n        assert start_directory is None or isinstance(start_directory, six.text_type)\n\n        window = self.arrangement.get_active_window()\n\n        pane = self._create_pane(window, command, start_directory=start_directory)\n        window.add_pane(pane, vsplit=vsplit)\n        pane.focus()\n        self.invalidate()", "response": "Add a new process to the current window."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nkill the given pane and remove it from the arrangement.", "response": "def kill_pane(self, pane):\n        \"\"\"\n        Kill the given pane, and remove it from the arrangement.\n        \"\"\"\n        assert isinstance(pane, Pane)\n\n        # Send kill signal.\n        if not pane.process.is_terminated:\n            pane.process.kill()\n\n        # Remove from layout.\n        self.arrangement.remove_pane(pane)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nleaving the command mode.", "response": "def leave_command_mode(self, append_to_history=False):\n        \"\"\"\n        Leave the command/prompt mode.\n        \"\"\"\n        client_state = self.get_client_state()\n\n        client_state.command_buffer.reset(append_to_history=append_to_history)\n        client_state.prompt_buffer.reset(append_to_history=True)\n\n        client_state.prompt_command = ''\n        client_state.confirm_command = ''\n\n        client_state.app.layout.focus_previous()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetaches the client that belongs to this CLI.", "response": "def detach_client(self, app):\n        \"\"\"\n        Detach the client that belongs to this CLI.\n        \"\"\"\n        connection = self.get_connection()\n        if connection:\n            connection.detach_and_close()\n\n        # Redraw all clients -> Maybe their size has to change.\n        self.invalidate()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlisten for clients on a Unix socket.", "response": "def listen_on_socket(self, socket_name=None):\n        \"\"\"\n        Listen for clients on a Unix socket.\n        Returns the socket name.\n        \"\"\"\n        def connection_cb(pipe_connection):\n            # We have to create a new `context`, because this will be the scope for\n            # a new prompt_toolkit.Application to become active.\n            with context():\n                connection = ServerConnection(self, pipe_connection)\n\n            self.connections.append(connection)\n\n        self.socket_name = bind_and_listen_on_socket(socket_name, connection_cb)\n\n        # Set session_name according to socket name.\n#        if '.' in self.socket_name:\n#            self.session_name = self.socket_name.rpartition('.')[-1]\n\n        logger.info('Listening on %r.' % self.socket_name)\n        return self.socket_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_standalone(self, color_depth):\n        self._runs_standalone = True\n        self._start_auto_refresh_thread()\n\n        client_state = self.add_client(\n            input=create_input(),\n            output=create_output(stdout=sys.stdout),\n            color_depth=color_depth,\n            connection=None)\n\n        client_state.app.run()", "response": "Run pymux standalone, rather than using a client/server architecture.\n        This is mainly useful for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind_and_listen_on_posix_socket(socket_name, accept_callback):\n    assert socket_name is None or isinstance(socket_name, six.text_type)\n    assert callable(accept_callback)\n\n    # Py2 uses 0027 and Py3 uses 0o027, but both know\n    # how to create the right value from the string '0027'.\n    old_umask = os.umask(int('0027', 8))\n\n    # Bind socket.\n    socket_name, socket = _bind_posix_socket(socket_name)\n\n    _ = os.umask(old_umask)\n\n    # Listen on socket.\n    socket.listen(0)\n\n    def _accept_cb():\n        connection, client_address = socket.accept()\n        # Note: We don't have to put this socket in non blocking mode.\n        #       This can cause crashes when sending big packets on OS X.\n\n        posix_connection = PosixSocketConnection(connection)\n\n        accept_callback(posix_connection)\n\n    get_event_loop().add_reader(socket.fileno(), _accept_cb)\n\n    logger.info('Listening on %r.' % socket_name)\n    return socket_name", "response": "Bind and listen on a POSIX socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbind a posix socket to the internal list and return it.", "response": "def _bind_posix_socket(socket_name=None):\n    \"\"\"\n    Find a socket to listen on and return it.\n\n    Returns (socket_name, sock_obj)\n    \"\"\"\n    assert socket_name is None or isinstance(socket_name, six.text_type)\n\n    s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n\n    if socket_name:\n        s.bind(socket_name)\n        return socket_name, s\n    else:\n        i = 0\n        while True:\n            try:\n                socket_name = '%s/pymux.sock.%s.%i' % (\n                    tempfile.gettempdir(), getpass.getuser(), i)\n                s.bind(socket_name)\n                return socket_name, s\n            except (OSError, socket.error):\n                i += 1\n\n                # When 100 times failed, cancel server\n                if i == 100:\n                    logger.warning('100 times failed to listen on posix socket. '\n                                   'Please clean up old sockets.')\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_chunk_from_socket(socket):\n    fd = socket.fileno()\n    f = Future()\n\n    def read_callback():\n        get_event_loop().remove_reader(fd)\n\n        # Read next chunk.\n        try:\n            data = socket.recv(1024)\n        except OSError as e:\n            # On OSX, when we try to create a new window by typing \"pymux\n            # new-window\" in a centain pane, very often we get the following\n            # error: \"OSError: [Errno 9] Bad file descriptor.\"\n            # This doesn't seem very harmful, and we can just try again.\n            logger.warning('Got OSError while reading data from client: %s. '\n                           'Trying again.', e)\n            f.set_result('')\n            return\n\n        if data:\n            f.set_result(data)\n        else:\n            f.set_exception(BrokenPipeError)\n\n    get_event_loop().add_reader(fd, read_callback)\n\n    return f", "response": "Read a chunk from a socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the prefix key binding.", "response": "def _load_prefix_binding(self):\n        \"\"\"\n        Load the prefix key binding.\n        \"\"\"\n        pymux = self.pymux\n\n        # Remove previous binding.\n        if self._prefix_binding:\n            self.custom_key_bindings.remove_binding(self._prefix_binding)\n\n        # Create new Python binding.\n        @self.custom_key_bindings.add(*self._prefix, filter=\n            ~(HasPrefix(pymux) | has_focus(COMMAND) | has_focus(PROMPT) |\n              WaitsForConfirmation(pymux)))\n        def enter_prefix_handler(event):\n            \" Enter prefix mode. \"\n            pymux.get_client_state().has_prefix = True\n\n        self._prefix_binding = enter_prefix_handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a new prefix key.", "response": "def prefix(self, keys):\n        \"\"\"\n        Set a new prefix key.\n        \"\"\"\n        assert isinstance(keys, tuple)\n\n        self._prefix = keys\n        self._load_prefix_binding()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the built - in key bindings and filters.", "response": "def _load_builtins(self):\n        \"\"\"\n        Fill the Registry with the hard coded key bindings.\n        \"\"\"\n        pymux = self.pymux\n        kb = KeyBindings()\n\n        # Create filters.\n        has_prefix = HasPrefix(pymux)\n        waits_for_confirmation = WaitsForConfirmation(pymux)\n        prompt_or_command_focus = has_focus(COMMAND) | has_focus(PROMPT)\n        display_pane_numbers = Condition(lambda: pymux.display_pane_numbers)\n        in_scroll_buffer_not_searching = InScrollBufferNotSearching(pymux)\n\n        @kb.add(Keys.Any, filter=has_prefix)\n        def _(event):\n            \" Ignore unknown Ctrl-B prefixed key sequences. \"\n            pymux.get_client_state().has_prefix = False\n\n        @kb.add('c-c', filter=prompt_or_command_focus & ~has_prefix)\n        @kb.add('c-g', filter=prompt_or_command_focus & ~has_prefix)\n#        @kb.add('backspace', filter=has_focus(COMMAND) & ~has_prefix &\n#                              Condition(lambda: cli.buffers[COMMAND].text == ''))\n        def _(event):\n            \" Leave command mode. \"\n            pymux.leave_command_mode(append_to_history=False)\n\n        @kb.add('y', filter=waits_for_confirmation)\n        @kb.add('Y', filter=waits_for_confirmation)\n        def _(event):\n            \"\"\"\n            Confirm command.\n            \"\"\"\n            client_state = pymux.get_client_state()\n\n            command = client_state.confirm_command\n            client_state.confirm_command = None\n            client_state.confirm_text = None\n\n            pymux.handle_command(command)\n\n        @kb.add('n', filter=waits_for_confirmation)\n        @kb.add('N', filter=waits_for_confirmation)\n        @kb.add('c-c' , filter=waits_for_confirmation)\n        def _(event):\n            \"\"\"\n            Cancel command.\n            \"\"\"\n            client_state = pymux.get_client_state()\n            client_state.confirm_command = None\n            client_state.confirm_text = None\n\n        @kb.add('c-c', filter=in_scroll_buffer_not_searching)\n        @kb.add('enter', filter=in_scroll_buffer_not_searching)\n        @kb.add('q', filter=in_scroll_buffer_not_searching)\n        def _(event):\n            \" Exit scroll buffer. \"\n            pane = pymux.arrangement.get_active_pane()\n            pane.exit_scroll_buffer()\n\n        @kb.add(' ', filter=in_scroll_buffer_not_searching)\n        def _(event):\n            \" Enter selection mode when pressing space in copy mode. \"\n            event.current_buffer.start_selection(selection_type=SelectionType.CHARACTERS)\n\n        @kb.add('enter', filter=in_scroll_buffer_not_searching & has_selection)\n        def _(event):\n            \" Copy selection when pressing Enter. \"\n            clipboard_data = event.current_buffer.copy_selection()\n            event.app.clipboard.set_data(clipboard_data)\n\n        @kb.add('v', filter=in_scroll_buffer_not_searching & has_selection)\n        def _(event):\n            \" Toggle between selection types. \"\n            types = [SelectionType.LINES, SelectionType.BLOCK, SelectionType.CHARACTERS]\n            selection_state = event.current_buffer.selection_state\n\n            try:\n                index = types.index(selection_state.type)\n            except ValueError:  # Not in list.\n                index = 0\n\n            selection_state.type = types[(index + 1) % len(types)]\n\n        @Condition\n        def popup_displayed():\n            return self.pymux.get_client_state().display_popup\n\n        @kb.add('q', filter=popup_displayed, eager=True)\n        def _(event):\n            \" Quit pop-up dialog. \"\n            self.pymux.get_client_state().display_popup = False\n\n        @kb.add(Keys.Any, eager=True, filter=display_pane_numbers)\n        def _(event):\n            \" When the pane numbers are shown. Any key press should hide them. \"\n            pymux.display_pane_numbers = False\n\n        @Condition\n        def clock_displayed():\n            \" \"\n            pane = pymux.arrangement.get_active_pane()\n            return pane.clock_mode\n\n        @kb.add(Keys.Any, eager=True, filter=clock_displayed)\n        def _(event):\n            \" When the clock is displayed. Any key press should hide it. \"\n            pane = pymux.arrangement.get_active_pane()\n            pane.clock_mode = False\n\n        return kb"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_custom_binding(self, key_name, command, arguments, needs_prefix=False):\n        assert isinstance(key_name, six.text_type)\n        assert isinstance(command, six.text_type)\n        assert isinstance(arguments, list)\n\n        # Unbind previous key.\n        self.remove_custom_binding(key_name, needs_prefix=needs_prefix)\n\n        # Translate the pymux key name into a prompt_toolkit key sequence.\n        # (Can raise ValueError.)\n        keys_sequence = pymux_key_to_prompt_toolkit_key_sequence(key_name)\n\n        # Create handler and add to Registry.\n        if needs_prefix:\n            filter = HasPrefix(self.pymux)\n        else:\n            filter = ~HasPrefix(self.pymux)\n\n        filter = filter & ~(WaitsForConfirmation(self.pymux) |\n                            has_focus(COMMAND) | has_focus(PROMPT))\n\n        def key_handler(event):\n            \" The actual key handler. \"\n            call_command_handler(command, self.pymux, arguments)\n            self.pymux.get_client_state().has_prefix = False\n\n        self.custom_key_bindings.add(*keys_sequence, filter=filter)(key_handler)\n\n        # Store key in `custom_bindings` in order to be able to call\n        # \"unbind-key\" later on.\n        k = (needs_prefix, key_name)\n        self.custom_bindings[k] = CustomBinding(key_handler, command, arguments)", "response": "Adds a custom binding for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove custom key binding for a key.", "response": "def remove_custom_binding(self, key_name, needs_prefix=False):\n        \"\"\"\n        Remove custom key binding for a key.\n\n        :param key_name: Pymux key name, for instance \"C-A\".\n        \"\"\"\n        k = (needs_prefix, key_name)\n\n        if k in self.custom_bindings:\n            self.custom_key_bindings.remove(self.custom_bindings[k].handler)\n            del self.custom_bindings[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbinds and listen on a Windows socket.", "response": "def bind_and_listen_on_win32_socket(socket_name, accept_callback):\n    \"\"\"\n    :param accept_callback: Called with `Win32PipeConnection` when a new\n        connection is established.\n    \"\"\"\n    assert callable(accept_callback)\n    socket_name = r'\\\\.\\pipe\\pymux.sock.jonathan.42'\n\n    pipes = [PipeInstance(socket_name, pipe_connection_cb=accept_callback)\n             for i in range(INSTANCES)]\n\n    for p in pipes:\n        # Start pipe.\n        ensure_future(p.handle_pipe())\n\n    return socket_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self):\n        if self.done_f.done():\n            raise BrokenPipeError\n\n        try:\n            result = yield From(read_message_from_pipe(self.pipe_instance.pipe_handle))\n            raise Return(result)\n        except BrokenPipeError:\n            self.done_f.set_result(None)\n            raise", "response": "Read a single message from the pipe."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a single message into the pipe.", "response": "def write(self, message):\n        \"\"\"\n        (coroutine)\n        Write a single message into the pipe.\n        \"\"\"\n        if self.done_f.done():\n            raise BrokenPipeError\n\n        try:\n            yield From(write_message_to_pipe(self.pipe_instance.pipe_handle, message))\n        except BrokenPipeError:\n            self.done_f.set_result(None)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _connect_client(self):\n        overlapped = OVERLAPPED()\n        overlapped.hEvent = create_event()\n\n        while True:\n            success = windll.kernel32.ConnectNamedPipe(\n                self.pipe_handle,\n                byref(overlapped))\n\n            if success:\n                return\n\n            last_error = windll.kernel32.GetLastError()\n            if last_error == ERROR_IO_PENDING:\n                yield From(wait_for_event(overlapped.hEvent))\n\n                # XXX: Call GetOverlappedResult.\n                return  # Connection succeeded.\n\n            else:\n                raise Exception('connect failed with error code' + str(last_error))", "response": "Connect to the pipe and wait for a client to connect."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pymux_key_to_prompt_toolkit_key_sequence(key):\n    # Make the c- and m- prefixes case insensitive.\n    if key.lower().startswith('m-c-'):\n        key = 'M-C-' + key[4:]\n    elif key.lower().startswith('c-'):\n        key = 'C-' + key[2:]\n    elif key.lower().startswith('m-'):\n        key = 'M-' + key[2:]\n\n    # Lookup key.\n    try:\n        return PYMUX_TO_PROMPT_TOOLKIT_KEYS[key]\n    except KeyError:\n        if len(key) == 1:\n            return (key, )\n        else:\n            raise ValueError('Unknown key: %r' % (key, ))", "response": "Turn a pymux description of a key into a prompt - toolkit key sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a prompt toolkit key into a Vt100 key sequence.", "response": "def prompt_toolkit_key_to_vt100_key(key, application_mode=False):\n    \"\"\"\n    Turn a prompt toolkit key. (E.g Keys.ControlB) into a Vt100 key sequence.\n    (E.g. \\x1b[A.)\n    \"\"\"\n    application_mode_keys = {\n        Keys.Up: '\\x1bOA',\n        Keys.Left: '\\x1bOD',\n        Keys.Right: '\\x1bOC',\n        Keys.Down: '\\x1bOB',\n    }\n\n    if key == Keys.ControlJ:\n        # Required for redis-cli. This can be removed when prompt_toolkit stops\n        # replacing \\r by \\n.\n        return '\\r'\n\n    if key == '\\n':\n        return '\\r'\n\n    elif application_mode and key in application_mode_keys:\n        return application_mode_keys.get(key)\n    else:\n        return _PROMPT_TOOLKIT_KEY_TO_VT100.get(key, key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(cls, text):\n        OUTSIDE, IN_DOUBLE, IN_SINGLE = 0, 1, 2\n\n        iterator = enumerate(text)\n        state = OUTSIDE\n        parts = []\n        current_part = ''\n        part_start_pos = 0\n\n        for i, c in iterator:  # XXX: correctly handle empty strings.\n            if state == OUTSIDE:\n                if c.isspace():\n                    # New part.\n                    if current_part:\n                        parts.append(current_part)\n                    part_start_pos = i + 1\n                    current_part = ''\n                elif c == '\"':\n                    state = IN_DOUBLE\n                elif c == \"'\":\n                    state = IN_SINGLE\n                else:\n                    current_part += c\n\n            elif state == IN_SINGLE:\n                if c == \"'\":\n                    state = OUTSIDE\n                elif c == \"\\\\\":\n                    next(iterator)\n                    current_part += c\n                else:\n                    current_part += c\n\n            elif state == IN_DOUBLE:\n                if c == '\"':\n                    state = OUTSIDE\n                elif c == \"\\\\\":\n                    next(iterator)\n                    current_part += c\n                else:\n                    current_part += c\n\n        parts.append(current_part)\n        return parts, part_start_pos", "response": "Parse the given text and return a list of parts and start_pos of the last part."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the value of the attribute in the given pymux.", "response": "def set_value(self, pymux, value):\n        \"\"\"\n        Take a string, and return an integer. Raise SetOptionError when the\n        given text does not parse to a positive integer.\n        \"\"\"\n        try:\n            value = int(value)\n            if value < 0:\n                raise ValueError\n        except ValueError:\n            raise SetOptionError('Expecting an integer.')\n        else:\n            setattr(pymux, self.attribute_name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute command. :param arguments: List of options.", "response": "def call_command_handler(command, pymux, arguments):\n    \"\"\"\n    Execute command.\n\n    :param arguments: List of options.\n    \"\"\"\n    assert isinstance(arguments, list)\n\n    # Resolve aliases.\n    command = ALIASES.get(command, command)\n\n    try:\n        handler = COMMANDS_TO_HANDLERS[command]\n    except KeyError:\n        pymux.show_message('Invalid command: %s' % (command,))\n    else:\n        try:\n            handler(pymux, arguments)\n        except CommandException as e:\n            pymux.show_message(e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmd(name, options=''):\n    # Validate options.\n    if options:\n        try:\n            docopt.docopt('Usage:\\n    %s %s' % (name, options, ), [])\n        except SystemExit:\n            pass\n\n    def decorator(func):\n        def command_wrapper(pymux, arguments):\n            # Hack to make the 'bind-key' option work.\n            # (bind-key expects a variable number of arguments.)\n            if name == 'bind-key' and '--' not in arguments:\n                # Insert a double dash after the first non-option.\n                for i, p in enumerate(arguments):\n                    if not p.startswith('-'):\n                        arguments.insert(i + 1, '--')\n                        break\n\n            # Parse options.\n            try:\n                # Python 2 workaround: pass bytes to docopt.\n                # From the following, only the bytes version returns the right\n                # output in Python 2:\n                #   docopt.docopt('Usage:\\n  app <params>...', [b'a', b'b'])\n                #   docopt.docopt('Usage:\\n  app <params>...', [u'a', u'b'])\n                # https://github.com/docopt/docopt/issues/30\n                # (Not sure how reliable this is...)\n                if six.PY2:\n                    arguments = [a.encode('utf-8') for a in arguments]\n\n                received_options = docopt.docopt(\n                    'Usage:\\n    %s %s' % (name, options),\n                    arguments,\n                    help=False)  # Don't interpret the '-h' option as help.\n\n                # Make sure that all the received options from docopt are\n                # unicode objects. (Docopt returns 'str' for Python2.)\n                for k, v in received_options.items():\n                    if isinstance(v, six.binary_type):\n                        received_options[k] = v.decode('utf-8')\n            except SystemExit:\n                raise CommandException('Usage: %s %s' % (name, options))\n\n            # Call handler.\n            func(pymux, received_options)\n\n            # Invalidate all clients, not just the current CLI.\n            pymux.invalidate()\n\n        COMMANDS_TO_HANDLERS[name] = command_wrapper\n        COMMANDS_TO_HELP[name] = options\n\n        # Get list of option flags.\n        flags = re.findall(r'-[a-zA-Z0-9]\\b', options)\n        COMMANDS_TO_OPTION_FLAGS[name] = flags\n\n        return func\n    return decorator", "response": "Decorator for all commands."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_window(pymux, variables):\n    window_id = variables['<target-window>']\n\n    def invalid_window():\n        raise CommandException('Invalid window: %s' % window_id)\n\n    if window_id.startswith(':'):\n        try:\n            number = int(window_id[1:])\n        except ValueError:\n            invalid_window()\n        else:\n            w = pymux.arrangement.get_window_by_index(number)\n            if w:\n                pymux.arrangement.set_active_window(w)\n            else:\n                invalid_window()\n    else:\n        invalid_window()", "response": "Select a window. Eg. select - window - t 3"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving a window to a new index.", "response": "def move_window(pymux, variables):\n    \"\"\"\n    Move window to a new index.\n    \"\"\"\n    dst_window = variables['<dst-window>']\n    try:\n        new_index = int(dst_window)\n    except ValueError:\n        raise CommandException('Invalid window index: %r' % (dst_window, ))\n\n    # Check first whether the index was not yet taken.\n    if pymux.arrangement.get_window_by_index(new_index):\n        raise CommandException(\"Can't move window: index in use.\")\n\n    # Save index.\n    w = pymux.arrangement.get_active_window()\n    pymux.arrangement.move_window(w, new_index)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nkilling all panes in the current window.", "response": "def kill_window(pymux, variables):\n    \" Kill all panes in the current window. \"\n    for pane in pymux.arrangement.get_active_window().panes:\n        pymux.kill_pane(pane)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngoes to previous active window.", "response": "def _(pymux, variables):\n    \" Go to previous active window. \"\n    w = pymux.arrangement.get_previous_active_window()\n\n    if w:\n        pymux.arrangement.set_active_window(w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_window(pymux, variables):\n    executable = variables['<executable>']\n    start_directory = variables['<start-directory>']\n\n    # The tmux definition of horizontal is the opposite of prompt_toolkit.\n    pymux.add_process(executable, vsplit=variables['-h'],\n                      start_directory=start_directory)", "response": "Split horizontally or vertically or both."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resize_pane(pymux, variables):\n    try:\n        left = int(variables['<left>'] or 0)\n        right = int(variables['<right>'] or 0)\n        up = int(variables['<up>'] or 0)\n        down = int(variables['<down>'] or 0)\n    except ValueError:\n        raise CommandException('Expecting an integer.')\n\n    w = pymux.arrangement.get_active_window()\n\n    if w:\n        w.change_size_for_active_pane(up=up, right=right, down=down, left=left)\n\n        # Zoom in/out.\n        if variables['-Z']:\n            w.zoom = not w.zoom", "response": "Resize the active pane."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending prefix to active pane.", "response": "def send_prefix(pymux, variables):\n    \"\"\"\n    Send prefix to active pane.\n    \"\"\"\n    process = pymux.arrangement.get_active_pane().process\n\n    for k in pymux.key_bindings_manager.prefix:\n        vt100_data = prompt_toolkit_key_to_vt100_key(k)\n        process.write_input(vt100_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbind a key sequence.", "response": "def bind_key(pymux, variables):\n    \"\"\"\n    Bind a key sequence.\n    -n: Not necessary to use the prefix.\n    \"\"\"\n    key = variables['<key>']\n    command = variables['<command>']\n    arguments = variables['<arguments>']\n    needs_prefix = not variables['-n']\n\n    try:\n        pymux.key_bindings_manager.add_custom_binding(\n            key, command, arguments, needs_prefix=needs_prefix)\n    except ValueError:\n        raise CommandException('Invalid key: %r' % (key, ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_keys(pymux, variables):\n    pane = pymux.arrangement.get_active_pane()\n\n    if pane.display_scroll_buffer:\n        raise CommandException('Cannot send keys. Pane is in copy mode.')\n\n    for key in variables['<keys>']:\n        # Translate key from pymux key to prompt_toolkit key.\n        try:\n            keys_sequence = pymux_key_to_prompt_toolkit_key_sequence(key)\n        except ValueError:\n            raise CommandException('Invalid key: %r' % (key, ))\n\n        # Translate prompt_toolkit key to VT100 key.\n        for k in keys_sequence:\n            pane.process.write_key(k)", "response": "Send keys to the active process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npaste clipboard content into buffer.", "response": "def paste_buffer(pymux, variables):\n    \"\"\"\n    Paste clipboard content into buffer.\n    \"\"\"\n    pane = pymux.arrangement.get_active_pane()\n    pane.process.write_input(get_app().clipboard.get_data().text, paste=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef source_file(pymux, variables):\n    filename = os.path.expanduser(variables['<filename>'])\n    try:\n        with open(filename, 'rb') as f:\n            for line in f:\n                line = line.decode('utf-8')\n                handle_command(pymux, line)\n    except IOError as e:\n        raise CommandException('IOError: %s' % (e, ))", "response": "Reads the source file and processes the command."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay all configured key bindings.", "response": "def list_keys(pymux, variables):\n    \"\"\"\n    Display all configured key bindings.\n    \"\"\"\n    # Create help string.\n    result = []\n\n    for k, custom_binding in pymux.key_bindings_manager.custom_bindings.items():\n        needs_prefix, key = k\n\n        result.append('bind-key %3s %-10s %s %s' % (\n            ('-n' if needs_prefix else ''), key, custom_binding.command,\n            ' '.join(map(wrap_argument, custom_binding.arguments))))\n\n    # Display help in pane.\n    result = '\\n'.join(sorted(result))\n    pymux.get_client_state().layout_manager.display_popup('list-keys', result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays a list of all the panes.", "response": "def list_panes(pymux, variables):\n    \"\"\"\n    Display a list of all the panes.\n    \"\"\"\n    w = pymux.arrangement.get_active_window()\n    active_pane = w.active_pane\n\n    result = []\n\n    for i, p in enumerate(w.panes):\n        process = p.process\n\n        result.append('%i: [%sx%s] [history %s/%s] %s' % (\n            i, process.sx, process.sy,\n            min(pymux.history_limit, process.screen.line_offset + process.sy),\n            pymux.history_limit,\n            ('(active)' if p == active_pane else '')))\n\n    # Display help in pane.\n    result = '\\n'.join(sorted(result))\n    pymux.get_client_state().layout_manager.display_popup('list-keys', result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays the clipboard content.", "response": "def show_buffer(pymux, variables):\n    \"\"\"\n    Display the clipboard content.\n    \"\"\"\n    text = get_app().clipboard.get_data().text\n    pymux.get_client_state().layout_manager.display_popup('show-buffer', text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_pymux_string(pymux, string, window=None, pane=None):\n    arrangement = pymux.arrangement\n\n    if window is None:\n        window = arrangement.get_active_window()\n\n    if pane is None:\n        pane = window.active_pane\n\n    def id_of_pane():\n        return '%s' % (pane.pane_id, )\n\n    def index_of_pane():\n        try:\n            return '%s' % (window.get_pane_index(pane), )\n        except ValueError:\n            return '/'\n\n    def index_of_window():\n        return '%s' % (window.index, )\n\n    def name_of_window():\n        return window.name or '(noname)'\n\n    def window_flags():\n        z = 'Z' if window.zoom else ''\n\n        if window == arrangement.get_active_window():\n            return '*' + z\n        elif window == arrangement.get_previous_active_window():\n            return '-' + z\n        else:\n            return z + ' '\n\n    def name_of_session():\n        return pymux.session_name\n\n    def title_of_pane():\n        return pane.process.screen.title\n\n    def hostname():\n        return socket.gethostname()\n\n    def literal():\n        return '#'\n\n    format_table = {\n        '#D': id_of_pane,\n        '#F': window_flags,\n        '#I': index_of_window,\n        '#P': index_of_pane,\n        '#S': name_of_session,\n        '#T': title_of_pane,\n        '#W': name_of_window,\n        '#h': hostname,\n        '##': literal,\n    }\n\n    # Date/time formatting.\n    if '%' in string:\n        try:\n            if six.PY2:\n                string = datetime.datetime.now().strftime(\n                    string.encode('utf-8')).decode('utf-8')\n            else:\n                string = datetime.datetime.now().strftime(string)\n        except ValueError:  # strftime format ends with raw %\n            string = '<ValueError>'\n\n    # Apply '#' formatting.\n    for symbol, f in format_table.items():\n        if symbol in string:\n            string = string.replace(symbol, f())\n\n    return string", "response": "Format a string according to the pymux style."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef name(self):\n        # Name, explicitely set for the pane.\n        if self.chosen_name:\n            return self.chosen_name\n        else:\n            # Name from the process running inside the pane.\n            name = self.process.get_name()\n            if name:\n                return os.path.basename(name)\n\n        return ''", "response": "Return the name of the current window."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a hash that can be used to determine when the layout has to be rebuild.", "response": "def invalidation_hash(self):\n        \"\"\"\n        Return a hash (string) that can be used to determine when the layout\n        has to be rebuild.\n        \"\"\"\n#        if not self.root:\n#            return '<empty-window>'\n\n        def _hash_for_split(split):\n            result = []\n            for item in split:\n                if isinstance(item, (VSplit, HSplit)):\n                    result.append(_hash_for_split(item))\n                elif isinstance(item, Pane):\n                    result.append('p%s' % item.pane_id)\n\n            if isinstance(split, HSplit):\n                return 'HSplit(%s)' % (','.join(result))\n            else:\n                return 'VSplit(%s)' % (','.join(result))\n\n        return '<window_id=%s,zoom=%s,children=%s>' % (\n            self.window_id, self.zoom, _hash_for_split(self.root))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef name(self):\n        # Name, explicitely set for the window.\n        if self.chosen_name:\n            return self.chosen_name\n        else:\n            pane = self.active_pane\n            if pane:\n                return pane.name\n\n        return ''", "response": "Return the name of the current window."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_pane(self, pane, vsplit=False):\n        assert isinstance(pane, Pane)\n        assert isinstance(vsplit, bool)\n\n        split_cls = VSplit if vsplit else HSplit\n\n        if self.active_pane is None:\n            self.root.append(pane)\n        else:\n            parent = self._get_parent(self.active_pane)\n            same_direction = isinstance(parent, split_cls)\n\n            index = parent.index(self.active_pane)\n\n            if same_direction:\n                parent.insert(index + 1, pane)\n            else:\n                new_split = split_cls([self.active_pane, pane])\n                parent[index] = new_split\n\n                # Give the newly created split the same weight as the original\n                # pane that was at this position.\n                parent.weights[new_split] = parent.weights[self.active_pane]\n\n        self.active_pane = pane\n        self.zoom = False", "response": "Add a new pane to the Window."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_pane(self, pane):\n        assert isinstance(pane, Pane)\n\n        if pane in self.panes:\n            # When this pane was focused, switch to previous active or next in order.\n            if pane == self.active_pane:\n                if self.previous_active_pane:\n                    self.active_pane = self.previous_active_pane\n                else:\n                    self.focus_next()\n\n            # Remove from the parent. When the parent becomes empty, remove the\n            # parent itself recursively.\n            p = self._get_parent(pane)\n            p.remove(pane)\n\n            while len(p) == 0 and p != self.root:\n                p2 = self._get_parent(p)\n                p2.remove(p)\n                p = p2\n\n            # When the parent has only one item left, collapse into its parent.\n            while len(p) == 1 and p != self.root:\n                p2 = self._get_parent(p)\n                p2.weights[p[0]] = p2.weights[p]  # Keep dimensions.\n                i = p2.index(p)\n                p2[i] = p[0]\n                p = p2", "response": "Removes a pane from this Window."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef panes(self):\n        \" List with all panes from this Window. \"\n        result = []\n\n        for s in self.splits:\n            for item in s:\n                if isinstance(item, Pane):\n                    result.append(item)\n\n        return result", "response": "List with all panes from this Window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef splits(self):\n        \" Return a list with all HSplit/VSplit instances. \"\n        result = []\n\n        def collect(split):\n            result.append(split)\n\n            for item in split:\n                if isinstance(item, (HSplit, VSplit)):\n                    collect(item)\n\n        collect(self.root)\n        return result", "response": "Return a list with all HSplit / VSplit instances."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef focus_next(self, count=1):\n        \" Focus the next pane. \"\n        panes = self.panes\n        if panes:\n            self.active_pane = panes[(panes.index(self.active_pane) + count) % len(panes)]\n        else:\n            self.active_pane = None", "response": "Focus the next pane."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rotate(self, count=1, with_pane_before_only=False, with_pane_after_only=False):\n        # Create (split, index, pane, weight) tuples.\n        items = []\n        current_pane_index = None\n\n        for s in self.splits:\n            for index, item in enumerate(s):\n                if isinstance(item, Pane):\n                    items.append((s, index, item, s.weights[item]))\n                    if item == self.active_pane:\n                        current_pane_index = len(items) - 1\n\n        # Only before after? Reduce list of panes.\n        if with_pane_before_only:\n            items = items[current_pane_index - 1:current_pane_index + 1]\n\n        elif with_pane_after_only:\n            items = items[current_pane_index:current_pane_index + 2]\n\n        # Rotate positions.\n        for i, triple in enumerate(items):\n            split, index, pane, weight = triple\n\n            new_item = items[(i + count) % len(items)][2]\n\n            split[index] = new_item\n            split.weights[new_item] = weight", "response": "Rotate panes.\n        When `with_pane_before_only` or `with_pane_after_only` is True, only rotate\n        with the pane before/after the active pane."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_layout(self, layout_type):\n        assert layout_type in LayoutTypes._ALL\n\n        # When there is only one pane, always choose EVEN_HORIZONTAL,\n        # Otherwise, we create VSplit/HSplit instances with an empty list of\n        # children.\n        if len(self.panes) == 1:\n            layout_type = LayoutTypes.EVEN_HORIZONTAL\n\n        # even-horizontal.\n        if layout_type == LayoutTypes.EVEN_HORIZONTAL:\n            self.root = HSplit(self.panes)\n\n        # even-vertical.\n        elif layout_type == LayoutTypes.EVEN_VERTICAL:\n            self.root = VSplit(self.panes)\n\n        # main-horizontal.\n        elif layout_type == LayoutTypes.MAIN_HORIZONTAL:\n            self.root = HSplit([\n                self.active_pane,\n                VSplit([p for p in self.panes if p != self.active_pane])\n            ])\n\n        # main-vertical.\n        elif layout_type == LayoutTypes.MAIN_VERTICAL:\n            self.root = VSplit([\n                self.active_pane,\n                HSplit([p for p in self.panes if p != self.active_pane])\n            ])\n\n        # tiled.\n        elif layout_type == LayoutTypes.TILED:\n            panes = self.panes\n            column_count = math.ceil(len(panes) ** .5)\n\n            rows = HSplit()\n            current_row = VSplit()\n\n            for p in panes:\n                current_row.append(p)\n\n                if len(current_row) >= column_count:\n                    rows.append(current_row)\n                    current_row = VSplit()\n            if current_row:\n                rows.append(current_row)\n\n            self.root = rows\n\n        self.previous_selected_layout = layout_type", "response": "Selects one of the predefined layouts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nselect next layout. (Cycle through predefined layouts.)", "response": "def select_next_layout(self, count=1):\n        \"\"\"\n        Select next layout. (Cycle through predefined layouts.)\n        \"\"\"\n        # List of all layouts. (When we have just two panes, only toggle\n        # between horizontal/vertical.)\n        if len(self.panes) == 2:\n            all_layouts = [LayoutTypes.EVEN_HORIZONTAL, LayoutTypes.EVEN_VERTICAL]\n        else:\n            all_layouts = LayoutTypes._ALL\n\n        # Get index of current layout.\n        layout = self.previous_selected_layout or LayoutTypes._ALL[-1]\n        try:\n            index = all_layouts.index(layout)\n        except ValueError:\n            index = 0\n\n        # Switch to new layout.\n        new_layout = all_layouts[(index + count) % len(all_layouts)]\n        self.select_layout(new_layout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nincrease the size of the current pane in any of the four directions.", "response": "def change_size_for_active_pane(self, up=0, right=0, down=0, left=0):\n        \"\"\"\n        Increase the size of the current pane in any of the four directions.\n        \"\"\"\n        child = self.active_pane\n        self.change_size_for_pane(child, up=up, right=right, down=down, left=left)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges the size of the pane.", "response": "def change_size_for_pane(self, pane, up=0, right=0, down=0, left=0):\n        \"\"\"\n        Increase the size of the current pane in any of the four directions.\n        Positive values indicate an increase, negative values a decrease.\n        \"\"\"\n        assert isinstance(pane, Pane)\n\n        def find_split_and_child(split_cls, is_before):\n            \" Find the split for which we will have to update the weights. \"\n            child = pane\n            split = self._get_parent(child)\n\n            def found():\n                return isinstance(split, split_cls) and (\n                    not is_before or split.index(child) > 0) and (\n                        is_before or split.index(child) < len(split) - 1)\n\n            while split and not found():\n                child = split\n                split = self._get_parent(child)\n\n            return split, child  # split can be None!\n\n        def handle_side(split_cls, is_before, amount, trying_other_side=False):\n            \" Increase weights on one side. (top/left/right/bottom). \"\n            if amount:\n                split, child = find_split_and_child(split_cls, is_before)\n\n                if split:\n                    # Find neighbour.\n                    neighbour_index = split.index(child) + (-1 if is_before else 1)\n                    neighbour_child = split[neighbour_index]\n\n                    # Increase/decrease weights.\n                    split.weights[child] += amount\n                    split.weights[neighbour_child] -= amount\n\n                    # Ensure that all weights are at least one.\n                    for k, value in split.weights.items():\n                        if value < 1:\n                            split.weights[k] = 1\n\n                else:\n                    # When no split has been found where we can move in this\n                    # direction, try to move the other side instead using a\n                    # negative amount. This happens when we run \"resize-pane -R 4\"\n                    # inside the pane that is completely on the right. In that\n                    # case it's logical to move the left border to the right\n                    # instead.\n                    if not trying_other_side:\n                        handle_side(split_cls, not is_before, -amount,\n                                    trying_other_side=True)\n\n        handle_side(VSplit, True, left)\n        handle_side(VSplit, False, right)\n        handle_side(HSplit, True, up)\n        handle_side(HSplit, False, down)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the index of the given pane. ValueError if not found.", "response": "def get_pane_index(self, pane):\n        \" Return the index of the given pane. ValueError if not found. \"\n        assert isinstance(pane, Pane)\n        return self.panes.index(pane)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_active_window(self):\n        app = get_app()\n\n        try:\n            return self._active_window_for_cli[app]\n        except KeyError:\n            self._active_window_for_cli[app] = self._last_active_window or self.windows[0]\n            return self.windows[0]", "response": "Returns the active window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_active_window_from_pane_id(self, pane_id):\n        assert isinstance(pane_id, int)\n\n        for w in self.windows:\n            for p in w.panes:\n                if p.pane_id == pane_id:\n                    self.set_active_window(w)", "response": "Set the active Window from a pane ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the Window with this index or None if not found.", "response": "def get_window_by_index(self, index):\n        \" Return the Window with this index or None if not found. \"\n        for w in self.windows:\n            if w.index == index:\n                return w"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new window that contains just this pane.", "response": "def create_window(self, pane, name=None, set_active=True):\n        \"\"\"\n        Create a new window that contains just this pane.\n\n        :param pane: The :class:`.Pane` instance to put in the new window.\n        :param name: If given, name for the new window.\n        :param set_active: When True, focus the new window.\n        \"\"\"\n        assert isinstance(pane, Pane)\n        assert name is None or isinstance(name, six.text_type)\n\n        # Take the first available index.\n        taken_indexes = [w.index for w in self.windows]\n\n        index = self.base_index\n        while index in taken_indexes:\n            index += 1\n\n        # Create new window and add it.\n        w = Window(index)\n        w.add_pane(pane)\n        self.windows.append(w)\n\n        # Sort windows by index.\n        self.windows = sorted(self.windows, key=lambda w: w.index)\n\n        app = get_app(return_none=True)\n\n        if app is not None and set_active:\n            self.set_active_window(w)\n\n        if name is not None:\n            w.chosen_name = name\n\n        assert w.active_pane == pane\n        assert w._get_parent(pane)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_window(self, window, new_index):\n        assert isinstance(window, Window)\n        assert isinstance(new_index, int)\n\n        window.index = new_index\n\n        # Sort windows by index.\n        self.windows = sorted(self.windows, key=lambda w: w.index)", "response": "Move a window to a new index."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a Pane from all windows.", "response": "def remove_pane(self, pane):\n        \"\"\"\n        Remove a :class:`.Pane`. (Look in all windows.)\n        \"\"\"\n        assert isinstance(pane, Pane)\n\n        for w in self.windows:\n            w.remove_pane(pane)\n\n            # No panes left in this window?\n            if not w.has_panes:\n                # Focus next.\n                for app, active_w in self._active_window_for_cli.items():\n                    if w == active_w:\n                        with set_app(app):\n                            self.focus_next_window()\n\n                self.windows.remove(w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef break_pane(self, set_active=True):\n        w = self.get_active_window()\n\n        if len(w.panes) > 1:\n            pane = w.active_pane\n            self.get_active_window().remove_pane(pane)\n            self.create_window(pane, set_active=set_active)", "response": "Break the pane in the current window."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrotating the panes in the active window.", "response": "def rotate_window(self, count=1):\n        \" Rotate the panes in the active window. \"\n        w = self.get_active_window()\n        w.rotate(count=count)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process(self, data):\n        try:\n            packet = json.loads(data)\n        except ValueError:\n            # So far, this never happened. But it would be good to have some\n            # protection.\n            logger.warning('Received invalid JSON from client. Ignoring.')\n            return\n\n        # Handle commands.\n        if packet['cmd'] == 'run-command':\n            self._run_command(packet)\n\n        # Handle stdin.\n        elif packet['cmd'] == 'in':\n            self._pipeinput.send_text(packet['data'])\n\n#        elif packet['cmd'] == 'flush-input':\n#            self._inputstream.flush()  # Flush escape key.  # XXX: I think we no longer need this.\n\n        # Set size. (The client reports the size.)\n        elif packet['cmd'] == 'size':\n            data = packet['data']\n            self.size = Size(rows=data[0], columns=data[1])\n            self.pymux.invalidate()\n\n        # Start GUI. (Create CommandLineInterface front-end for pymux.)\n        elif packet['cmd'] == 'start-gui':\n            detach_other_clients = bool(packet['detach-others'])\n            color_depth = packet['color-depth']\n            term = packet['term']\n\n            if detach_other_clients:\n                for c in self.pymux.connections:\n                    c.detach_and_close()\n\n            print('Create app...')\n            self._create_app(color_depth=color_depth, term=term)", "response": "Process packet received from client."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends packet to client.", "response": "def _send_packet(self, data):\n        \"\"\"\n        Send packet to client.\n        \"\"\"\n        if self._closed:\n            return\n\n        data = json.dumps(data)\n\n        def send():\n            try:\n                yield From(self.pipe_connection.write(data))\n            except BrokenPipeError:\n                self.detach_and_close()\n        ensure_future(send())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _run_command(self, packet):\n        create_temp_cli = self.client_states is None\n\n        if create_temp_cli:\n            # If this client doesn't have a CLI. Create a Fake CLI where the\n            # window containing this pane, is the active one. (The CLI instance\n            # will be removed before the render function is called, so it doesn't\n            # hurt too much and makes the code easier.)\n            pane_id = int(packet['pane_id'])\n            self._create_app()\n            with set_app(self.client_state.app):\n                self.pymux.arrangement.set_active_window_from_pane_id(pane_id)\n\n        with set_app(self.client_state.app):\n            try:\n                self.pymux.handle_command(packet['data'])\n            finally:\n                self._close_connection()", "response": "Execute a run command from the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_app(self, color_depth, term='xterm'):\n        output = Vt100_Output(_SocketStdout(self._send_packet),\n                              lambda: self.size,\n                              term=term,\n                              write_binary=False)\n\n        self.client_state = self.pymux.add_client(\n            input=self._pipeinput, output=output, connection=self, color_depth=color_depth)\n\n        print('Start running app...')\n        future = self.client_state.app.run_async()\n        print('Start running app got future...', future)\n\n        @future.add_done_callback\n        def done(_):\n            print('APP DONE.........')\n            print(future.result())\n            self._close_connection()", "response": "Create CommandLineInterface for this client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_context_manager(self, mode):\n        \" Create a context manager that sends 'mode' commands to the client. \"\n        class mode_context_manager(object):\n            def __enter__(*a):\n                self.send_packet({'cmd': 'mode', 'data': mode})\n\n            def __exit__(*a):\n                self.send_packet({'cmd': 'mode', 'data': 'restore'})\n\n        return mode_context_manager()", "response": "Create a context manager that sends mode commands to the client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap command argument in quotes and escape when this contains special characters.", "response": "def wrap_argument(text):\n    \"\"\"\n    Wrap command argument in quotes and escape when this contains special characters.\n    \"\"\"\n    if not any(x in text for x in [' ', '\"', \"'\", '\\\\']):\n        return text\n    else:\n        return '\"%s\"' % (text.replace('\\\\', r'\\\\').replace('\"', r'\\\"'), )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_default_shell():\n    if is_windows():\n        return 'cmd.exe'\n    else:\n        import pwd\n        import getpass\n\n        if 'SHELL' in os.environ:\n            return os.environ['SHELL']\n        else:\n            username = getpass.getuser()\n            shell = pwd.getpwnam(username).pw_shell\n            return shell", "response": "Returns the path to the default shell for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _confirm_or_prompt_or_command(pymux):\n    \" True when we are waiting for a command, prompt or confirmation. \"\n    client_state = pymux.get_client_state()\n    if client_state.confirm_text or client_state.prompt_command or client_state.command_mode:\n        return True", "response": "True when we are waiting for a command prompt or confirmation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mutate(self):\n        '''\n        Mutate to next state\n\n        :return: True if mutated, False if not\n        '''\n        self._get_ready()\n        if self._is_last_index():\n            return False\n        self._current_index += 1\n        self._mutate()\n        return True", "response": "Mutate the current state of the current set of items."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sequence_str(self):\n        '''\n        :return: string representation of the sequence\n        '''\n        sequence = self.get_sequence()\n        return '->'.join(e.dst.name for e in sequence)", "response": "Returns a string representation of the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary of information regarding the stages in the fuzzing session", "response": "def get_stages(self):\n        '''\n        :return: dictionary of information regarding the stages in the fuzzing session\n\n        .. note::\n\n            structure: { current: ['stage1', 'stage2', 'stage3'], 'stages': {'source1': ['dest1', 'dest2'], 'source2': ['dest1', 'dest3']}}\n        '''\n        sequence = self.get_sequence()\n        return {\n            'current': [e.dst.get_name() for e in sequence],\n            'stages': {e.src.get_name(): [e.dst.get_name()] for e in sequence}\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget kitty stats as a dictionary", "response": "def get_stats(self):\n        '''\n        Get kitty stats as a dictionary\n        '''\n        resp = requests.get('%s/api/stats.json' % self.url)\n        assert(resp.status_code == 200)\n        return resp.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_reports(self, report_ids):\n        '''\n        Get reports by list of ids\n        :param report_ids: list of reports ids\n        :return dictionary of id/report (json string)\n        '''\n        res = {}\n        for rid in report_ids:\n            print('Fetching report %d' % rid)\n            resp = requests.get('%s/api/report?report_id=%d' % (self.url, rid))\n            if resp.status_code != 200:\n                print('[!] failed to fetch report %d' % rid)\n            else:\n                res[rid] = resp.text\n        return res", "response": "Get reports by list of ids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _next_mutation(self):\n        '''\n        :return: True if mutated, False otherwise\n        '''\n        if self._keep_running():\n            current_idx = self.model.current_index()\n            self.session_info.current_index = current_idx\n            next_idx = self._test_list.current()\n            if next_idx is None:\n                return False\n            skip = next_idx - current_idx - 1\n            if skip > 0:\n                self.model.skip(skip)\n            self._test_list.next()\n            resp = self.model.mutate()\n            return resp\n        return False", "response": "Returns True if the next mutation is needed False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_options(self, option_line):\n        '''\n        Handle options from command line, in docopt style.\n        This allows passing arguments to the fuzzer from the command line\n        without the need to re-write it in each runner.\n\n        :param option_line: string with the command line options to be parsed.\n        '''\n        if option_line is not None:\n            usage = '''\n            These are the options to the kitty fuzzer object, not the options to the runner.\n\n            Usage:\n                fuzzer [options] [-v ...]\n\n            Options:\n                -d --delay <delay>              delay between tests in secodes, float number\n                -f --session <session-file>     session file name to use\n                -n --no-env-test                don't perform environment test before the fuzzing session\n                -r --retest <session-file>      retest failed/error tests from a session file\n                -t --test-list <test-list>      a comma delimited test list string of the form \"-10,12,15-20,30-\"\n                -v --verbose                    be more verbose in the log\n\n            Removed options:\n                end, start - use --test-list instead\n            '''\n            options = docopt.docopt(usage, shlex.split(option_line))\n\n            # ranges\n            if options['--retest']:\n                retest_file = options['--retest']\n                try:\n                    test_list_str = self._get_test_list_from_session_file(retest_file)\n                except Exception as ex:\n                    raise KittyException('Failed to open session file (%s) for retesting: %s' % (retest_file, ex))\n            else:\n                test_list_str = options['--test-list']\n            self._set_test_ranges(None, None, test_list_str)\n\n            # session file\n            session_file = options['--session']\n            if session_file is not None:\n                self.set_session_file(session_file)\n\n            # delay between tests\n            delay = options['--delay']\n            if delay is not None:\n                self.set_delay_between_tests(float(delay))\n\n            # environment test\n            skip_env_test = options['--no-env-test']\n            if skip_env_test:\n                self.set_skip_env_test(True)\n\n            # verbosity\n            verbosity = options['--verbose']\n            self.set_verbosity(verbosity)", "response": "Handles options from command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the model of the object.", "response": "def set_model(self, model):\n        '''\n        Set the model to fuzz\n\n        :type model: :class:`~kitty.model.high_level.base.BaseModel` or a subclass\n        :param model: Model object to fuzz\n        '''\n        self.model = model\n        if self.model:\n            self.model.set_notification_handler(self)\n            self.handle_stage_changed(model)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_target(self, target):\n        '''\n        :param target: target object\n        '''\n        self.target = target\n        if target:\n            self.target.set_fuzzer(self)\n        return self", "response": "Sets the target object for fuzzing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_range(self, start_index=0, end_index=None):\n        '''\n        Set range of tests to run\n\n        .. deprecated::\n            use :func:`~kitty.fuzzers.base.BaseFuzzer.set_test_list`\n\n        :param start_index: index to start at (default=0)\n        :param end_index: index to end at(default=None)\n        '''\n        if end_index is not None:\n            end_index += 1\n        self._test_list = StartEndList(start_index, end_index)\n        self.session_info.start_index = start_index\n        self.session_info.current_index = 0\n        self.session_info.end_index = end_index\n        self.session_info.test_list_str = self._test_list.as_test_list_str()\n        return self", "response": "Set the range of tests to run at start_index and end_index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the fuzzing session.", "response": "def start(self):\n        '''\n        Start the fuzzing session\n\n        If fuzzer already running, it will return immediatly\n        '''\n        if self._started:\n            self.logger.warning('called while fuzzer is running. ignoring.')\n            return\n        self._started = True\n        assert(self.model)\n        assert(self.user_interface)\n        assert(self.target)\n\n        if self._load_session():\n            self._check_session_validity()\n            self._set_test_ranges(\n                self.session_info.start_index,\n                self.session_info.end_index,\n                self.session_info.test_list_str\n            )\n        else:\n            self.session_info.kitty_version = _get_current_version()\n            # TODO: write hash for high level\n            self.session_info.data_model_hash = self.model.hash()\n        # if self.session_info.end_index is None:\n        #     self.session_info.end_index = self.model.last_index()\n        if self._test_list is None:\n            self._test_list = StartEndList(0, self.model.num_mutations())\n        else:\n            self._test_list.set_last(self.model.last_index())\n\n        list_count = self._test_list.get_count()\n        self._test_list.skip(list_count - 1)\n        self.session_info.end_index = self._test_list.current()\n        self._test_list.reset()\n        self._store_session()\n        self._test_list.skip(self.session_info.current_index)\n        self.session_info.test_list_str = self._test_list.as_test_list_str()\n\n        self._set_signal_handler()\n        self.user_interface.set_data_provider(self.dataman)\n        self.user_interface.set_continue_event(self._continue_event)\n        self.user_interface.start()\n\n        self.session_info.start_time = time.time()\n        try:\n            self._start_message()\n            self.target.setup()\n            start_from = self.session_info.current_index\n            if self._skip_env_test:\n                self.logger.info('Skipping environment test')\n            else:\n                self.logger.info('Performing environment test')\n                self._test_environment()\n            self._in_environment_test = False\n            self._test_list.reset()\n            self._test_list.skip(start_from)\n            self.session_info.current_index = start_from\n            self.model.skip(self._test_list.current())\n            self._start()\n            return True\n        except Exception as e:\n            self.logger.error('Error occurred while fuzzing: %s', repr(e))\n            self.logger.error(traceback.format_exc())\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a stage change in the data model", "response": "def handle_stage_changed(self, model):\n        '''\n        handle a stage change in the data model\n\n        :param model: the data model that was changed\n        '''\n        stages = model.get_stages()\n        if self.dataman:\n            self.dataman.set('stages', stages)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the fuzzing session", "response": "def stop(self):\n        '''\n        stop the fuzzing session\n        '''\n        assert(self.model)\n        assert(self.user_interface)\n        assert(self.target)\n        self.user_interface.stop()\n        self.target.teardown()\n        self.dataman.submit_task(None)\n        self._un_set_signal_handler()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _keep_running(self):\n        '''\n        Should we still fuzz??\n        '''\n        if self.config.max_failures:\n            if self.session_info.failure_count >= self.config.max_failures:\n                return False\n        return self._test_list.current() is not None", "response": "Return True if we should keep running."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_logger(cls):\n        '''\n        :return: the class logger\n        '''\n        if KittyObject._logger is None:\n            logger = logging.getLogger('kitty')\n            logger.setLevel(logging.INFO)\n            consolehandler = logging.StreamHandler()\n            console_format = logging.Formatter('[%(levelname)-8s][%(module)s.%(funcName)s] %(message)s')\n            consolehandler.setFormatter(console_format)\n            logger.addHandler(consolehandler)\n            if not os.path.exists('./kittylogs'):\n                os.mkdir('./kittylogs')\n            filehandler = logging.FileHandler(KittyObject.log_file_name)\n            file_format = logging.Formatter('[%(asctime)s] [%(levelname)s] [%(module)s.%(funcName)s] -> %(message)s')\n            filehandler.setFormatter(file_format)\n            logger.addHandler(filehandler)\n            KittyObject._logger = logger\n        return KittyObject._logger", "response": "returns the class logger\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset verbosity of logger .", "response": "def set_verbosity(cls, verbosity):\n        '''\n        Set verbosity of logger\n\n        :param verbosity: verbosity level. currently, we only support 1 (logging.DEBUG)\n        '''\n        if verbosity > 0:\n            # currently, we only toggle between INFO, DEBUG\n            logger = KittyObject.get_logger()\n            levels = [logging.DEBUG]\n            verbosity = min(verbosity, len(levels)) - 1\n            logger.setLevel(levels[verbosity])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef not_implemented(self, func_name):\n        '''\n        log access to unimplemented method and raise error\n\n        :param func_name: name of unimplemented function.\n        :raise: NotImplementedError detailing the function the is not implemented.\n        '''\n        msg = '%s is not overridden by %s' % (func_name, type(self).__name__)\n        self.logger.error(msg)\n        raise NotImplementedError(msg)", "response": "log access to unimplemented method and raise error\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef synced(func):\n    '''\n    Decorator for functions that should be called synchronously from another thread\n\n    :param func: function to call\n    '''\n\n    def wrapper(self, *args, **kwargs):\n        '''\n        Actual wrapper for the synchronous function\n        '''\n        task = DataManagerTask(func, *args, **kwargs)\n        self.submit_task(task)\n        return task.get_results()\n    return wrapper", "response": "Decorator for functions that should be called synchronously from another thread\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the task with the given dataman", "response": "def execute(self, dataman):\n        '''\n        run the task\n\n        :type dataman: :class:`~kitty.data.data_manager.DataManager`\n        :param dataman: the executing data manager\n        '''\n        self._event.clear()\n        try:\n            self._result = self._task(dataman, *self._args)\n        #\n        # We are going to re-throw this exception from get_results,\n        # so we are doing such a general eception handling at the point.\n        # however, we do want to print it here as well\n        #\n        except Exception as ex:  # pylint: disable=W0703\n            self._exception = ex\n            KittyObject.get_logger().error(traceback.format_exc())\n        self._event.set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_results(self):\n        '''\n        :return: result from running the task\n        '''\n        self._event.wait()\n        if self._exception is not None:\n            #\n            # Well... rethrownig the exception caught in execute\n            # but on the caller thread\n            #\n            raise self._exception  # pylint: disable=E0702\n        return self._result", "response": "Returns the result from running the task\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        '''\n        thread function\n        '''\n        self._stopped_event.clear()\n        self.open()\n        while True:\n            task = self._queue.get()\n            if task is None:\n                break\n            task.execute(self)\n        self.close()\n        self._stopped_event.set()", "response": "thread function that runs the thread"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening the database and create the tables", "response": "def open(self):\n        '''\n        open the database\n        '''\n        self._connection = sqlite3.connect(self._dbname)\n        self._cursor = self._connection.cursor()\n        self._session_info = SessionInfoTable(self._connection, self._cursor)\n        self._reports = ReportsTable(self._connection, self._cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting arbitrary data by key in volatile memory", "response": "def set(self, key, data):\n        '''\n        set arbitrary data by key in volatile memory\n\n        :param key: key of the data\n        :param data: data to be stored\n        '''\n        if isinstance(data, dict):\n            self._volatile_data[key] = {k: v for (k, v) in data.items()}\n        else:\n            self._volatile_data[key] = data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the current table if not exists", "response": "def _create_table(self):\n        '''\n        create the current table if not exists\n        '''\n        self._cursor.execute('''\n            CREATE TABLE IF NOT EXISTS %(name)s ( %(fields)s )\n        ''' % {\n            'name': self._name,\n            'fields': ','.join('%s %s' % (k, v) for (k, v) in self._fields)\n        })\n        self._connection.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select(self, to_select, where=None, sql_params=None):\n        '''\n        select db entries\n\n        :param to_select: string of fields to select\n        :param where: where clause (default: None)\n        :param sql_params: params for the where clause\n        '''\n        if sql_params is None:\n            sql_params = []\n        query = '''\n        SELECT %s FROM %s\n        ''' % (to_select, self._name)\n        if where:\n            query = '%s WHERE %s' % (query, where)\n        return self._cursor.execute(query, tuple(sql_params))", "response": "select db entries from the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef row_to_dict(self, row):\n        '''\n        translate a row of the current table to dictionary\n\n        :param row: a row of the current table (selected with \\\\*)\n        :return: dictionary of all fields\n        '''\n        res = {}\n        for i in range(len(self._fields)):\n            res[self._fields[i][0]] = row[i]\n        return res", "response": "translate a row of the current table to dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, field_dict, where_clause=None):\n        '''\n        update db entry\n\n        :param field_dict: dictionary of fields and values\n        :param where_clause: where clause for the update\n        '''\n        query = '''\n        UPDATE %s SET %s\n        ''' % (\n            self._name,\n            ','.join('%s=:%s' % (k, k) for k in field_dict)\n        )\n        if where_clause:\n            query += ' WHERE %s' % (where_clause)\n        self._cursor.execute(query, field_dict)\n        self._connection.commit()", "response": "update the entry with the given fields and values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting new db entry", "response": "def insert(self, fields, values):\n        '''\n        insert new db entry\n\n        :param fields: list of fields to insert\n        :param values: list of values to insert\n        :return: row id of the new row\n        '''\n        if fields:\n            _fields = ' (%s) ' % ','.join(fields)\n        else:\n            _fields = ''\n        _values = ','.join('?' * len(values))\n        query = '''\n        INSERT INTO %s %s VALUES (%s)\n        ''' % (self._name, _fields, _values)\n        self._cursor.execute(query, tuple(values))\n        self._connection.commit()\n        return self._cursor.lastrowid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store(self, report, test_id):\n        '''\n        :param report: the report to store\n        :param test_id: the id of the test reported\n        :return: report id\n        '''\n        report_d = report.to_dict()\n        content = self._serialize_dict(report_d)\n        report_id = self.insert(\n            ['test_id', 'content', 'status', 'reason'],\n            [test_id, content, report.get_status(), report.get('reason')],\n        )\n        return report_id", "response": "Stores the report in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets report by the test id", "response": "def get(self, test_id):\n        '''\n        get report by the test id\n\n        :param test_id: test id\n        :return: Report object\n        '''\n        self.select('*', 'test_id=?', [test_id])\n        row = self._cursor.fetchone()\n        if not row:\n            raise KeyError('No report with test id %s in the DB' % test_id)\n\n        values = self.row_to_dict(row)\n        content = self._deserialize_dict(values['content'])\n        return Report.from_dict(content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of test reports in the database.", "response": "def get_report_list(self):\n        '''\n        :return: ids of test reports\n        '''\n        self.select('test_id, status, reason')\n        res = []\n        for row in self._cursor.fetchall():\n            res.append((row[0], row[1], row[2]))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _serialize_dict(cls, data):\n        '''\n        serializes a dictionary\n\n        :param data: data to serialize\n        '''\n        return b64encode(zlib.compress(cPickle.dumps(data, protocol=2))).decode()", "response": "Serialize a dictionary into base64 encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _deserialize_dict(cls, data):\n        '''\n        deserializes a dictionary\n\n        :param data: data to deserialize\n        '''\n        return cPickle.loads(zlib.decompress(b64decode(data.encode())))", "response": "Deserialize a dictionary into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the current session info from the cursor.", "response": "def read_info(self):\n        '''\n        :rtype: :class:`~kitty.data.data_manager.SessionInfo`\n        :return: current session info\n        '''\n        self.select('*')\n        row = self._cursor.fetchone()\n        if not row:\n            return None\n        info_d = self.row_to_dict(row)\n        return SessionInfo.from_dict(info_d)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_session_info(self, info):\n        '''\n        :type info: :class:`~kitty.data.data_manager.SessionInfo`\n        :param info: info to set\n        '''\n        if not self.info:\n            self.info = SessionInfo()\n            info_d = self.info.as_dict()\n            ks = []\n            vs = []\n            for k, v in info_d.items():\n                ks.append(k)\n                vs.append(v)\n            self.insert(ks, vs)\n        changed = self.info.copy(info)\n        if changed:\n            self.update(self.info.as_dict())", "response": "Set the info of the current object to the given info object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy the current object to the new one.", "response": "def copy(self, orig):\n        '''\n        :param orig: SessionInfo object to copy\n        :return: True if changed, false otherwise\n        '''\n        changed = False\n        for attr in SessionInfo.fields:\n            oattr = getattr(orig, attr)\n            if getattr(self, attr) != oattr:\n                setattr(self, attr, oattr)\n                changed = True\n        return changed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dict(cls, info_d):\n        '''\n        :param info_d: the info dictionary\n        :rtype: :class:`~kitty.data.data_manager.SessionInfo`\n        :return: object that corresponds to the info dictionary\n        '''\n        info = SessionInfo()\n        for k, v in info_d.items():\n            setattr(info, k, v)\n        return info", "response": "Creates a new SessionInfo object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_model_info(self):\n        '''\n        :return: dictionary of information about this model\n        '''\n        info = {}\n        info['model_name'] = self.name\n        info['stages'] = '->'.join([repr(s) for s in self._stages])\n        info['sequence'] = {\n            'index': self._current_index\n        }\n        return info", "response": "Returns a dictionary of information about this model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _run_sequence(self, sequence):\n        '''\n        Run a single sequence\n        '''\n        self._check_pause()\n        self._pre_test()\n        session_data = self.target.get_session_data()\n        self._test_info()\n        resp = None\n        for edge in sequence:\n            if edge.callback:\n                edge.callback(self, edge, resp)\n            session_data = self.target.get_session_data()\n            node = edge.dst\n            node.set_session_data(session_data)\n            resp = self._transmit(node)\n        return self._post_test()", "response": "Run a single sequence"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransmits node data to target.", "response": "def _transmit(self, node):\n        '''\n        Transmit node data to target.\n\n        :type node:  Template\n        :param node: node to transmit\n        :return: response if there is any\n        '''\n        payload = node.render().tobytes()\n        self._last_payload = payload\n        try:\n            return self.target.transmit(payload)\n        except Exception as e:\n            self.logger.error('Error in transmit: %s', e)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_string(data, encoding='hex'):\n    '''\n    Encode string\n\n    :param data: string to encode\n    :param encoding: encoding to use (default: 'hex')\n    :return: encoded string\n    '''\n    if six.PY2:\n        return data.encode(encoding)\n    else:\n        if isinstance(data, str):\n            data = bytes(data, 'utf-8')\n        return codecs.encode(data, encoding).decode('ascii')", "response": "Encode string to be used in the sequence of objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes string using codecs", "response": "def decode_string(data, encoding='hex'):\n    '''\n    Decode string\n\n    :param data: string to decode\n    :param encoding: encoding to use (default: 'hex')\n    :return: decoded string\n    '''\n    if six.PY2:\n        return data.decode(encoding)\n    else:\n        return codecs.decode(data.encode('ascii'), encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencodes data into a list dict string bool or int", "response": "def encode_data(data):\n    '''\n    Encode data - list, dict, string, bool or int (and nested)\n\n    :param data: data to encode\n    :return: encoded object of the same type\n    '''\n    if isinstance(data, (six.string_types, bytes)):\n        return encode_string(data)\n    elif isinstance(data, (six.integer_types, bool, float)):\n        return data\n    elif data is None:\n        return data\n    elif isinstance(data, list):\n        return [encode_data(x) for x in data]\n    elif isinstance(data, dict):\n        return {k: encode_data(v) for k, v in data.items()}\n    else:\n        raise ValueError('Cannot encode data of type %s' % type(data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a function that performs rpc call", "response": "def _generate_rpc_method(self, method):\n        '''\n        Generate a function that performs rpc call\n\n        :param method: method name\n        :return: rpc function\n        '''\n        def _(**kwargs):\n            '''\n            always use named arguments\n            '''\n            msg_id = self.get_unique_msg_id()\n            params = encode_data(kwargs)\n            payload = {\n                'method': method,\n                'params': params,\n                'jsonrpc': '2.0',\n                'id': msg_id\n            }\n            response = requests.post(self.url, data=json.dumps(payload), headers=self.headers).json()\n            if ('error' in response):\n                if response['error']['code'] == JSONRPC_NO_RESULT:\n                    return None\n                raise Exception('Got error from RPC server when called \"%s\" error: %s' % (method, response['error']))\n            if 'result' in response:\n                result = decode_data(response['result'])\n                return result\n        return _"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_request(self):\n        '''\n        Parse the request\n        '''\n        self.req_method = 'unknown'\n        self.req_params = {}\n        self.req_rpc_version = '2.0'\n        self.req_id = 0\n        self.data = self.rfile.read(int(self.headers.get('content-length')))\n        data_dict = json.loads(self.data)\n        self.req_method = data_dict['method']\n        self.req_params = decode_data(data_dict['params'])\n        self.req_rpc_version = data_dict['jsonrpc']\n        self.req_id = data_dict['id']", "response": "Parse the request object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a result to the RPC client", "response": "def send_result(self, additional_dict):\n        '''\n        Send a result to the RPC client\n\n        :param additional_dict: the dictionary with the response\n        '''\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"application/json\")\n        response = {\n            'jsonrpc': self.req_rpc_version,\n            'id': self.req_id,\n        }\n        response.update(additional_dict)\n        jresponse = json.dumps(response)\n        self.send_header(\"Content-length\", len(jresponse))\n        self.end_headers()\n        self.wfile.write(jresponse.encode())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n        '''\n        Serving loop\n        '''\n        print('Waiting for a client to connect to url http://%s:%d/' % (self.host, self.port))\n        self.state = RpcServer._STATE_RUN\n        while self.state == RpcServer._STATE_RUN:\n            self.server.handle_request()\n        self.server.server_close()\n        self.state = RpcServer._STATE_IDLE", "response": "Start serving loop for the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an instance of some BitField class.", "response": "def BitField(value, length, signed=False, min_value=None, max_value=None, encoder=ENC_INT_DEFAULT, fuzzable=True, name=None, full_range=False):\n    '''\n    Returns an instance of some BitField class\n    .. note::\n\n        Since BitField is frequently used in binary format, multiple aliases were created for it. See aliases.py for more details.\n    '''\n    if not full_range:\n        return _LibraryBitField(value, length, signed, min_value, max_value, encoder, fuzzable, name)\n    return _FullRangeBitField(value, length, signed, min_value, max_value, encoder, fuzzable, name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_current_value(self, value):\n        '''\n        Sets the current value of the field\n\n        :param value: value to set\n        :return: rendered value\n        '''\n        self._current_value = value\n        self._current_rendered = self._encode_value(self._current_value)\n        return self._current_rendered", "response": "Sets the current value of the field\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nskipping up to count cases", "response": "def skip(self, count):\n        '''\n        Skip up to [count] cases, default behavior is to just mutate [count] times\n\n        :count: number of cases to skip\n        :rtype: int\n        :return: number of cases skipped\n        '''\n        skipped = 0\n        for _ in range(count):\n            if self.mutate():\n                skipped += 1\n            else:\n                break\n        return skipped"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmutating the field returning True if the field is mutated otherwise False.", "response": "def mutate(self):\n        '''\n        Mutate the field\n\n        :rtype: boolean\n        :return: True if field the mutated\n        '''\n        self._initialize()\n        if self._exhausted():\n            return False\n        self._current_index += 1\n        self._mutate()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders the current value of the field", "response": "def render(self, ctx=None):\n        '''\n        Render the current value of the field\n\n        :rtype: Bits\n        :return: rendered value\n        '''\n        self._initialize()\n        if not self.is_default():\n            self._current_rendered = self._encode_value(self._current_value)\n        return self._current_rendered"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the field to its default state.", "response": "def reset(self):\n        '''\n        Reset the field to its default state\n        '''\n        self._current_index = -1\n        self._current_value = self._default_value\n        self._current_rendered = self._default_rendered\n        self.offset = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the field information of the current object as a dictionary", "response": "def get_info(self):\n        '''\n        :rtype: dictionary\n        :return: field information\n        '''\n        info = {\n            'name': self.name if self.name else '<no name>',\n            'path': self.name if self.name else '<no name>',\n            'field_type': type(self).__name__,\n            'value': {\n                'raw': repr(self._current_value),\n                'rendered': {\n                    'base64': b64encode(self._current_rendered.tobytes()).decode(),\n                    'length_in_bits': len(self._current_rendered),\n                    'length_in_bytes': len(self._current_rendered.tobytes()),\n                }\n            },\n            'mutation': {\n                'total_number': self._num_mutations,\n                'current_index': self._current_index,\n                'mutating': self._mutating(),\n                'fuzzable': self._fuzzable,\n            },\n        }\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_field(self, field):\n        '''\n        Resolve a field from name\n\n        :param field: name of the field to resolve\n        :rtype: BaseField\n        :return: the resolved field\n        :raises: KittyException if field could not be resolved\n        '''\n        if isinstance(field, BaseField):\n            return field\n        name = field\n        if name.startswith('/'):\n            return self.resolve_absolute_name(name)\n        resolved_field = self.scan_for_field(name)\n        if not resolved_field:\n            container = self.enclosing\n            if container:\n                resolved_field = container.resolve_field(name)\n        if not resolved_field:\n            raise KittyException('Could not resolve field by name (%s)' % name)\n        return resolved_field", "response": "Resolve a field from name\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve a field from an absolute name.", "response": "def resolve_absolute_name(self, name):\n        '''\n        Resolve a field from an absolute name.\n        An absolute name is just like unix absolute path,\n        starts with '/' and each name component is separated by '/'.\n\n        :param name: absolute name, e.g. \"/container/subcontainer/field\"\n        :return: field with this absolute name\n        :raises: KittyException if field could not be resolved\n        '''\n        current = self\n        while current.enclosing:\n            current = current.enclosing\n        if name != '/':\n            components = name.split('/')[1:]\n            for component in components:\n                current = current.get_field_by_name(component)\n        return current"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hash(self):\n        '''\n        :rtype: int\n        :return: hash of the field\n        '''\n        if self._hash is None:\n            self._initialize()\n            self._hash = khash(type(self).__name__, self._default_value, self._fuzzable)\n        return self._hash", "response": "returns the hash of the field\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef skip(self, count):\n        '''\n        skip up to [count] cases\n\n        :param count: number of cases to skip\n        :rtype: int\n        :return: number of cases skipped\n        '''\n        self._initialize()\n        skipped = 0\n        if not self._exhausted():\n            skipped = min(count, self._last_index() - self._current_index)\n            self._current_index += skipped\n        return skipped", "response": "skip up to count cases"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_command_injection_strings_unix(self, lib):\n        '''\n        .. note::\n\n            The following mutations will probably not be detected\n            unless there's a monitor that checks if the file /tmp/KITTY\n            was created in the post test\n        '''\n        lib.append(('|touch /tmp/KITTY', 'command injection - pipe'))\n        lib.append((';touch /tmp/KITTY;', 'command injection - additional command'))\n        lib.append((';ls>/tmp/KITTY', 'command injection - additional command'))\n        lib.append(('\";ls>/tmp/KITTY;ls>/dev/null\"', 'command injection - escape double qoutes'))\n        lib.append(('\\';ls>/tmp/KITTY;ls>\\'/dev/null\\'', 'command injection - escape qoutes'))\n        lib.append(('`ls>/tmp/KITTY`', 'command injection - backtick'))\n        lib.append((' `ls>/tmp/KITTY`', 'command injection - backtick with space'))", "response": "Add command injection strings to the given library."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_sql_injection_strings(self, lib):\n        '''\n        .. note::\n\n            The following mutations will probably not be detected\n            unless some entity will check the response from the target\n            on the validity of the DB.\n        '''\n        entries = [\n            (\"' or 1=1 --\", 'mssql - bypass check'),\n            (\"\\'; desc users; --\", 'mysql - mssql - get desc users'),\n            (\"' or username is not NULL or username = '\", 'mysql - mssql - bypass check'),\n            (\"1 union all select 1,2,3,4,5,6,name from sysobjects where xtype = 'u' --\", 'mysql - mssql - get sysobjects'),\n            (\"` or `1`=`1\", 'oracle - bypass check'),\n            (\"' or '1'='1\", 'oracle - bypass check'),\n        ]\n        for (s, desc) in entries:\n            lib.append((s, 'sqli - %s' % desc))", "response": "Add sql injection strings to the lib list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding path traversal strings to lib.", "response": "def _add_path_traversal_strings(self, lib):\n        '''\n        .. note::\n\n            The following mutations will probably not be detected\n            unless there's a monitor that checks if the file /tmp/KITTY\n            was created in the post test\n        '''\n        entries = [\n            (('/etc/passwd', 'absolute - /etc/passwd')),\n            (('./../../../../../../../../../../../../../../etc/passwd', 'relative - /etc/passwd')),\n            (('../../../../../../../../../../../../../../etc/passwd', 'relative - /etc/passwd')),\n            (('/proc/cpuinfo', 'absolute path - /proc/cpuinfo')),\n            (('./../../../../../../../../../../../../../../proc/cpuinfo', 'relative - /proc/cpuinfo')),\n            (('../../../../../../../../../../../../../../proc/cpuinfo', 'relative - /proc/cpuinfo')),\n            (('~/.profile', 'absolute - home')),\n            (('$HOME/.profile', 'environment - home')),\n            (('/../../../../../../../../../../../../boot.ini', 'relative - boot.ini')),\n        ]\n        for (s, desc) in entries:\n            lib.append((s, 'path traversal - %s' % desc))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the hash of the field", "response": "def hash(self):\n        '''\n        :rtype: int\n        :return: hash of the field\n        '''\n        hashed = super(String, self).hash()\n        return khash(hashed, self._max_size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_class_lib(self):\n        '''\n        If the range is from a to b, we try a few numbers around the arrows\n        a                                           b\n        +-------------------------------------------+\n        ^          ^          ^          ^          ^\n        '''\n        lib = []\n        num_sections = 4\n        for i in range(3):\n            lib.append(((lambda x, i=i: x._min_value + i), 'off by %d from max value' % i))\n            lib.append(((lambda x, i=i: x._max_value - i), 'off by -%d from min value' % i))\n            for s in range(1, num_sections):\n                lib.append(\n                    (\n                        (lambda x, i=i, s=s: x._max_value - (x._max_min_diff // num_sections) * s + i),\n                        'off by %d from section %d' % (i, s)\n                    )\n                )\n                lib.append(\n                    (\n                        (lambda x, i=i, s=s: x._max_value - (x._max_min_diff // num_sections) * s - i),\n                        'off by %d from section %d' % (i, s)\n                    )\n                )\n        # off-by-N\n        for i in range(1, 3):\n            lib.append(((lambda x, i=i: x._default_value + i), 'off by %d from value' % i))\n            lib.append(((lambda x, i=i: x._default_value - i), 'off by %d from value' % -i))\n        self._add_ints_from_file('./kitty_integers.txt')\n        return lib", "response": "Get the class lib for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hash(self):\n        '''\n        :rtype: int\n        :return: hash of the field\n        '''\n        hashed = super(_LibraryBitField, self).hash()\n        return khash(hashed, self._length, self._signed, self._min_value, self._max_value)", "response": "Returns the hash of the field\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hash(self):\n        '''\n        :rtype: int\n        :return: hash of the field\n        '''\n        hashed = super(Group, self).hash()\n        return khash(hashed, frozenset(self._values))", "response": "Returns the hash of the field\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hash(self):\n        '''\n        :rtype: int\n        :return: hash of the field\n        '''\n        hashed = super(Dynamic, self).hash()\n        return khash(hashed, self._key, self._length)", "response": "Returns the hash of the field\n       "}
