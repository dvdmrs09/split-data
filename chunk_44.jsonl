{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_next_objective(self):\n        try:\n            next_object = next(self)\n        except StopIteration:\n            raise IllegalState('no more elements available in this list')\n        except Exception:  # Need to specify exceptions here!\n            raise OperationFailed()\n        else:\n            return next_object", "response": "Gets the next Objective in this list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_objective(self):\n        # Note that this makes the generic objectives call to Handcar\n        # without specifying the objectiveBank:\n        url_str = (self._base_url + '/objectives/' +\n                   self._my_map['objectiveId'])\n        return Objective(self._load_json(url_str))", "response": "Gets the related objective."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_asset_ids(self):\n        if not self.is_asset_based_activity():\n            raise IllegalState()\n        else:\n            ids = []\n            for i in self._my_map['assetIds']:\n                ids.append(Id(i))\n            return IdList(ids)", "response": "Gets the Ids of any assets associated with this activity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_assets(self):\n        # This includes a kludge to get the objectiveBankId directly from\n        # this Activity's Objective's private _my_map :o\n        from ..repository.objects import AssetList\n        if not self.is_asset_based_activity():\n            raise IllegalState()\n        url_str = (self._base_url + '/objectivebanks/' +\n                   self.get_objective()._my_map['objectiveBankId'] +\n                   '/assets/bulk?id=' + '&id='.join(self._my_map['assetIds']))\n        return AssetList(self._load_json(url_str))", "response": "Gets any assets associated with this activity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_assessment_ids(self):\n        if not self.is_assessment_based_activity():\n            raise IllegalState()\n        else:\n            return [Id(a) for a in self._my_map['assessmentIds']]", "response": "Gets the Ids of any assessments associated with this activity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the assets. arg: assetIds (osid.id.Id): the asset Ids raise: INVALID_ARGUMENT - assetIds is invalid raise: NullArgument - assetIds is null raise: NoAccess - metadata.is_read_only() is true compliance: mandatory - This method must be implemented.", "response": "def set_assets(self, asset_ids=None):\n        \"\"\"Sets the assets.\n\n        arg:    assetIds (osid.id.Id): the asset Ids\n        raise:  INVALID_ARGUMENT - assetIds is invalid\n        raise:  NullArgument - assetIds is null\n        raise:  NoAccess - metadata.is_read_only() is true\n        compliance: mandatory - This method must be implemented.\n\n        \"\"\"\n        if asset_ids is None:\n            raise NullArgument()\n        metadata = Metadata(**settings.METADATA['asset_ids'])\n        if metadata.is_read_only():\n            raise NoAccess()\n        if self._is_valid_input(asset_ids, metadata, array=True):\n            for asset_id in asset_ids:\n                self._my_map['assetIds'].append(str(asset_id))\n        else:\n            raise InvalidArgument"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_courses(self, course_ids=None):\n        if course_ids is None:\n            raise NullArgument()\n        metadata = Metadata(**settings.METADATA['course_ids'])\n        if metadata.is_read_only():\n            raise NoAccess()\n        if self._is_valid_input(course_ids, metadata, array=True):\n            for course_id in course_ids:\n                self._my_map['courseIds'].append(str(course_id))\n        else:\n            raise InvalidArgument", "response": "Sets the courses.\n\n        arg:    courseIds (osid.id.Id): the course Ids\n        raise:  INVALID_ARGUMENT - courseIds is invalid\n        raise:  NullArgument - courseIds is null\n        raise:  NoAccess - metadata.is_read_only() is true\n        compliance: mandatory - This method must be implemented."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_assessments(self, assessment_ids=None):\n        if assessment_ids is None:\n            raise NullArgument()\n        metadata = Metadata(**settings.METADATA['assessment_ids'])\n        if metadata.is_read_only():\n            raise NoAccess()\n        if self._is_valid_input(assessment_ids, metadata, array=True):\n            for assessment_id in assessment_ids:\n                self._my_map['assessmentIds'].append(str(assessment_id))\n        else:\n            raise InvalidArgument", "response": "Sets the assessments.\n\n        arg:    assessmentIds (osid.id.Id): the assessment Ids\n        raise:  INVALID_ARGUMENT - assessmentIds is invalid\n        raise:  NullArgument - assessmentIds is null\n        raise:  NoAccess - metadata.is_read_only() is true\n        compliance: mandatory - This method must be implemented."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_next_activity(self):\n        try:\n            next_object = next(self)\n        except StopIteration:\n            raise IllegalState('no more elements available in this list')\n        except Exception:  # Need to specify exceptions here!\n            raise OperationFailed()\n        else:\n            return next_object", "response": "Gets the next Activity in this list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the next ObjectiveBank in this list.", "response": "def get_next_objective_bank(self):\n        \"\"\"Gets the next ObjectiveBank in this list.\n\n        return: (osid.learning.ObjectiveBank) - the next ObjectiveBank\n                in this list. The has_next() method should be used to\n                test that a next ObjectiveBank is available before\n                calling this method.\n        raise:  IllegalState - no more elements available in this list\n        raise:  OperationFailed - unable to complete request\n        compliance: mandatory - This method must be implemented.\n\n        \"\"\"\n        try:\n            next_object = next(self)\n        except StopIteration:\n            raise IllegalState('no more elements available in this list')\n        except Exception:  # Need to specify exceptions here!\n            raise OperationFailed()\n        else:\n            return next_object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_next_objective_banks(self, n=None):\n        if n > self.available():\n            # !!! This is not quite as specified (see method docs) !!!\n            raise IllegalState('not enough elements available in this list')\n        else:\n            next_list = []\n            x = 0\n            while x < n:\n                try:\n                    next_list.append(next(self))\n                except Exception:  # Need to specify exceptions here!\n                    raise OperationFailed()\n                x = x + 1\n            return next_list", "response": "Gets the next set of ObjectiveBank elements in this list which are less than or equal to the return from available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_report(self):\n    ostr = ''\n    ostr += \"Nodes: \"+str(len(self.__nodes.keys()))+\"\\n\"\n    ostr += \"Edges: \"+str(len(self.__edges.keys()))+\"\\n\"\n    return ostr", "response": "describe the graph\n\n    :returns: report\n    :rtype: string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_node_edges(self,node,type=\"both\"):\n    if type == \"both\":\n      return [self.__edges[x] for x in self.__edges if node.id in self.__edges[x].get_node_ids()]\n    elif type == \"outgoing\":\n      return [self.__edges[x] for x in self.__edges if node.id == self.__edges[x].get_node_ids()[0]]\n    elif type == \"incoming\":\n      return [self.__edges[x] for x in self.__edges if node.id == self.__edges[x].get_node_ids()[1]]\n    sys.stderr.write(\"ERROR: type is not a type \"+type+\"\\n\")\n    sys.exit()", "response": "given a node return the edges attached by default get both incoming and outgoing edges"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_children(self,node):\n    if self.find_cycle() or self.__directionless:\n      sys.stderr.write(\"ERROR: do cannot find a branch when there are cycles in the graph\\n\")\n      sys.exit()\n    v = self.__get_children(node.id)\n    return [self.__nodes[i] for i in v]", "response": "Find all the children of a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_roots(self):\n    if self.__directionless:\n      sys.stderr.write(\"ERROR: can't get roots of an undirected graph\\n\")\n      sys.exit()\n    outputids = self.__nodes.keys()\n    #print outputids\n    rootset  = set(outputids) -  set(self.__child_to_parent.keys())\n    return [self.__nodes[x] for x in rootset]", "response": "get the roots of a directed graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a root node and its children and make them into graphs", "response": "def root_and_children_to_graph(self,root):\n     \"\"\"Take a root node and its children and make them into graphs\"\"\"\n     g = Graph()\n     g.add_node(root)\n     edges = []\n     edges += self.get_node_edges(root,\"outgoing\")\n     for c in self.get_children(root):\n           g.add_node(c)\n           edges += self.get_node_edges(c,\"outgoing\")\n     for e in edges: g.add_edge(e)\n     return g"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate whether the particular model is created properly.", "response": "def validate(self):\n        \"\"\"\n        Validates whether the particular model is created properly\n        \"\"\"\n        if self.stoichiometry_matrix.cols != self.propensities.rows:\n            raise ValueError('There must be a column in stoichiometry matrix '\n                             'for each row in propensities matrix. '\n                             'S ({0.rows}x{0.cols}): {0!r} , '\n                             'propensities ({1.rows}x{1.cols}): {1!r}'.format(self.stoichiometry_matrix,\n                                                                              self.propensities))\n\n        if self.stoichiometry_matrix.rows != len(self.species):\n            raise ValueError('There must be a row in stoichiometry matrix for each variable. '\n                             'S ({0.rows}x{0.cols}): {0!r}, variables: {1!r}'.format(self.stoichiometry_matrix,\n                                                                                     self.species))\n\n        seen_free_symbols = set()\n        parameters = set(self.parameters)\n        species = set(self.species)\n\n        # Check if there are any parameters in both lists\n        intersection = parameters & species\n        if intersection:\n            raise ValueError(\"Some symbols are in both parameters and species lists\")\n\n        both = parameters | species\n        for row in self.propensities:\n            free_symbols = row.free_symbols\n            # Do not check the seen symbols twice\n            free_symbols = free_symbols - seen_free_symbols\n            for symbol in free_symbols:\n                if symbol not in both:\n                    raise ValueError('Propensity {0!r} '\n                                     'contains a free symbol {1!r} '\n                                     'that is not in listed in parameters or species lists '\n                                     'Parameters: {2!r}; '\n                                     'Species: {3!r}'.format(row, symbol,\n                                                             self.parameters,\n                                                             self.species))\n\n            seen_free_symbols.update(free_symbols)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_id(self):\n        return Id(\n            identifier=str(self._my_map['_id']),\n            namespace=self._namespace,\n            authority=self._authority)", "response": "Gets the Id associated with this OSID object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_record(self, record_type):\n        if not self.has_record_type(record_type):\n            raise errors.Unsupported()\n        if str(record_type) not in self._records:\n            raise errors.Unimplemented()\n        return self._records[str(record_type)]", "response": "Get the record string type value given the record_type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noverriding this method in inheriting objects to perform special clearing operations.", "response": "def _delete(self):\n        \"\"\"Override this method in inheriting objects to perform special clearing operations.\"\"\"\n        try:\n            for record in self._records:\n                try:\n                    self._records[record]._delete()\n                except AttributeError:\n                    pass\n        except AttributeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the most appropriate provider manager depending on config.", "response": "def _get_provider_manager(self, osid, local=False):\n        \"\"\"Gets the most appropriate provider manager depending on config.\"\"\"\n        return get_provider_manager(osid,\n                                    runtime=self._runtime,\n                                    proxy=getattr(self, '_proxy', None),\n                                    local=local)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the record types available in this object.", "response": "def get_record_types(self):\n        \"\"\"Gets the record types available in this object.\n\n        A record ``Type`` explicitly indicates the specification of an\n        interface to the record. A record may or may not inherit other\n        record interfaces through interface inheritance in which case\n        support of a record type may not be explicit in the returned\n        list. Interoperability with the typed interface to this object\n        should be performed through ``hasRecordType()``.\n\n        return: (osid.type.TypeList) - the record types available\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        from ..type.objects import TypeList\n        type_list = []\n        for type_idstr in self._supported_record_type_ids:\n            type_list.append(Type(**self._record_type_data_sets[Id(type_idstr).get_identifier()]))\n        return TypeList(type_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_effective(self):\n        now = DateTime.utcnow()\n        return self.get_start_date() <= now and self.get_end_date() >= now", "response": "Tests if the current date is within the start end dates inclusive."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the start date of the entry.", "response": "def get_start_date(self):\n        \"\"\"Gets the start date.\n\n        return: (osid.calendaring.DateTime) - the start date\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        sdate = self._my_map['startDate']\n        return DateTime(\n            sdate.year,\n            sdate.month,\n            sdate.day,\n            sdate.hour,\n            sdate.minute,\n            sdate.second,\n            sdate.microsecond)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the Id of the provider.", "response": "def get_provider_id(self):\n        \"\"\"Gets the ``Id`` of the provider.\n\n        return: (osid.id.Id) - the provider ``Id``\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        if 'providerId' not in self._my_map or not self._my_map['providerId']:\n            raise errors.IllegalState('this sourceable object has no provider set')\n        return Id(self._my_map['providerId'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the provider resource.", "response": "def get_provider(self):\n        \"\"\"Gets the ``Resource`` representing the provider.\n\n        return: (osid.resource.Resource) - the provider\n        raise:  OperationFailed - unable to complete request\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        if 'providerId' not in self._my_map or not self._my_map['providerId']:\n            raise errors.IllegalState('this sourceable object has no provider set')\n        mgr = self._get_provider_manager('RESOURCE')\n        lookup_session = mgr.get_resource_lookup_session()  # What about the Proxy?\n        lookup_session.use_federated_bin_view()\n        return lookup_session.get_resource(self.get_provider_id())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the branding asset Ids.", "response": "def get_branding_ids(self):\n        \"\"\"Gets the branding asset ``Ids``.\n\n        return: (osid.id.IdList) - a list of asset ``Ids``\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        from ..id.objects import IdList\n        if 'brandingIds' not in self._my_map:\n            return IdList([])\n        id_list = []\n        for idstr in self._my_map['brandingIds']:\n            id_list.append(Id(idstr))\n        return IdList(id_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_license(self):\n        if 'license' in self._my_map:\n            license_text = self._my_map['license']\n            return DisplayText(display_text_map=license_text)\n        return DisplayText(text='',\n                           language_type=types.Language().get_type_data('DEFAULT'),\n                           format_type=types.Format().get_type_data('DEFAULT'),\n                           script_type=types.Script().get_type_data('DEFAULT'))", "response": "Gets the terms of usage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nslicing the mapping by the position in the sequence start - > end", "response": "def slice_sequence(self,start,end,directionless=False):\n     \"\"\"Slice the mapping by the position in the sequence\n\n       \tFirst coordinate is 0-indexed start\n       \tSecond coordinate is 1-indexed finish\n\n     \"\"\"\n     if end > self.length: end = self.length\n     if start < 0: start = 0\n     if not directionless and self.direction == '-': \n        newend = self.length-start\n        newstart = self.length-end\n        end = newend\n        start = newstart\n     #find the sequence length\n     l = self.length\n     indexstart = start\n     indexend = end\n     ns = []\n     tot = 0\n     for r in self._rngs:\n        tot += r.length\n        n = r.copy()\n        if indexstart > r.length:\n           indexstart-=r.length\n           continue\n        n.start = n.start+indexstart\n        if tot > end:\n           diff = tot-end\n           n.end -= diff\n           tot = end\n        indexstart = 0\n        ns.append(n)\n        if tot == end: break\n     if len(ns)==0: return None\n     return Transcript(ns,self._options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the range from the leftmost exon to the rightmost exon", "response": "def range(self):\n    \"\"\"Get the range from the leftmost exon to the rightmost\n\n    :return: total range\n    :rtype: GenomicRange\n    \"\"\"\n    return GenomicRange(self._rngs[0].chr,self._rngs[0].start,self._rngs[-1].end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the strand of the sequence", "response": "def set_strand(self,dir):\n    \"\"\"Set the strand (direction)\n\n    :param dir: direction + or -\n    :type dir: char\n    \"\"\"\n    self._options = self._options._replace(direction = dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of junctions", "response": "def junctions(self):\n    \"\"\"Can be inferred from the exons, this is not implemented yet\"\"\"\n    if len(self.exons) < 2: return []\n    junctions = []\n    for i in range(1,len(self.exons)):\n      junctions.append(Junction(self.exons[i-1],self.exons[i]))\n    return junctions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the GenePredict format string representation of the mapping", "response": "def get_gpd_line(self,transcript_name=None,gene_name=None,direction=None):\n    \"\"\"Get the genpred format string representation of the mapping\"\"\"\n    return transcript_to_gpd_line(self,transcript_name=transcript_name,gene_name=gene_name,direction=direction)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_gene_name(self,name):\n    self._options = self._options._replace(gene_name = name)", "response": "assign a gene name to the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning a transcript name", "response": "def set_transcript_name(self,name):\n    \"\"\"assign a transcript name\n\n    :param name: name\n    :type name: string\n    \"\"\"\n    self._options = self._options._replace(name = name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a report on how much the exons overlap with the given transcript.", "response": "def exon_overlap(self,tx,multi_minover=10,multi_endfrac=0,multi_midfrac=0.8,single_minover=50,single_frac=0.5,multi_consec=True):\n    \"\"\"Get a report on how mucht the exons overlap\n\n    :param tx:\n    :param multi_minover: multi-exons need to overlap by at lest this much to be considered overlapped (default 10)\n    :param multi_endfrac: multi-exons need an end fraction coverage of at least this by default (default 0)\n    :param multi_midfrac: multi-exons need (default 0.8) mutual coverage for internal exons\n    :parma single_minover: single-exons need at least this much shared overlap (default 50)\n    :param single_frac: at least this fraction of single exons must overlap (default 0.5)\n    :parma multi_consec: exons need to have multiexon consecutive mapping to consider it a match (default True)\n    :type tx:\n    :type multi_minover: int\n    :type multi_endfrac: float\n    :type multi_midfrac: float\n    :type single_minover: int\n    :type single_frac: float\n    :type multi_consec: bool\n    :return: ExonOverlap report\n    :rtype: Transcript.ExonOverlap\n    \"\"\"\n    return ExonOverlap(self,tx,multi_minover,multi_endfrac,multi_midfrac,single_minover,single_frac,multi_consec=multi_consec)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of consecutive exons that overlap with self1.", "response": "def consecutive_exon_count(self1):\n      \"\"\"Best number of consecutive exons that overlap\n\n      :return: matched consecutive exon count\n      :rtype: int\n      \"\"\"\n      best = 1\n      consec = 1\n      for i in range(0,len(self1.dif1)):\n        if self1.dif1[i] == 1 and self1.dif2[i] == 1:\n          consec += 1\n        else: \n          consec = 1\n        if consec > best:\n          best = consec\n      return best"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns value if the two objects are a subset of the two objects.", "response": "def is_subset(self1):\n      \"\"\" Return value if tx_obj2 is a complete subset of tx_obj1 or \n          tx_obj1 is a complete subset of tx_obj2\n\n          Values are:\n\n          * Return 1: Full overlap (mutual subests) \n          * Return 2: two is a subset of one\n          * Return 3: one is a subset of two\n          * Return False if neither is a subset of the other\n\n      :return: subset value\n      :rtype: int\n      \"\"\"\n      if len(self1.overs) == 0: return False\n      if len(self1.dif1) > 0: # make sure they are consecutive if more than one\n        if max(self1.dif1) != 1 or max(self1.dif2) != 1: return False\n      onecov = self1.start1 and self1.end1\n      twocov = self1.start2 and self1.end2\n      if onecov and twocov:\n        return 1\n      elif twocov: return 2\n      elif onecov: return 3\n      return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrue if they are a full overlap", "response": "def is_full_overlap(self1):\n      \"\"\"true if they are a full overlap\n\n      :return: is full overlap\n      :rtype: bool\n      \"\"\"\n      if len(self1.overs) == 0: return False\n      if len(self1.dif1) > 0:\n        if max(self1.dif1) != 1 or max(self1.dif2) != 1: return False\n      if self1.start1 and self1.end1 and self1.start2 and self1.end2:\n        return True\n      return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_overlap(self1):\n      overs = []\n      if not self1.tx_obj1.range.overlaps(self1.tx_obj2.range): return # if they dont overlap wont find anything\n      for i in range(0,len(self1.tx_obj1.exons)):\n        for j in range(0,len(self1.tx_obj2.exons)):\n          osize = self1.tx_obj1.exons[i].range.overlap_size(self1.tx_obj2.exons[j].range)\n          ofrac = 0\n          if osize > 0:\n            ofrac = min(float(osize)/float(self1.tx_obj1.exons[i].range.length)\\\n                       ,float(osize)/float(self1.tx_obj2.exons[j].range.length))\n\n          if self1.tx_obj1.get_exon_count() == 1 or self1.tx_obj2.get_exon_count() == 1:\n            # use single exon rules\n            if osize >= self1.single_minover and ofrac >= self1.single_frac:\n              #print 'single exon match'\n              overs.append([i,j])\n          else: # for multi exons\n            if i == 0 or j == 0 or i == len(self1.tx_obj1.exons)-1 or j == len(self1.tx_obj2.exons)-1:\n              #its on an end\n              if osize >= self1.multi_minover and ofrac >= self1.multi_endfrac:\n                #print 'end exon match'\n                overs.append([i,j])\n            #else its a middle\n            elif osize >= self1.multi_minover and ofrac >= self1.multi_midfrac:\n              #print 'mid exon match'\n              overs.append([i,j])\n      #print overs\n      self1.overs = overs", "response": "Calculate the overlap between two junctions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning value if the two objects are a subset of the two objects.", "response": "def is_subset(self):\n      \"\"\"Return value if tx_obj2 is a complete subset of tx_obj1 or tx_obj1 is a complete subset of tx_obj2\n\n      values:\n\n      * Return 1: Full overlap (mutual subests) \n      * Return 2: two is a subset of one\n      * Return 3: one is a subset of two\n      * Return False if neither is a subset of the other\n      \"\"\"\n      if len(self.overs) == 0: return False\n      if len(self.dif1) > 0: # make sure they are consecutive if more than one\n        if len([x for x in self.dif1 if x != 1]) != 0: return False\n        if len([x for x in self.dif2 if x != 1]) != 0: return False\n      #look closely at what we are doing here\n      onecov = self.start1 and self.end1\n      twocov = self.start2 and self.end2\n      if onecov and twocov:\n        if self.tx_obj1.get_exon_count() != self.tx_obj2.get_exon_count():\n           raise ValueError('how can be same with different exons'+\"\\n\"+str(self.overs)+\"\\n\"+str(self.dif1)+\"\\n\"+str(self.dif2)+\"\\n\"+str(len(self.j1))+\"\\n\"+str(len(self.j2))+\"\\n\"+str(self.tx_obj1.get_exon_count())+\"\\n\"+str(self.tx_obj2.get_exon_count()))\n        return 1\n      elif twocov: return 2\n      elif onecov: return 3\n      return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_overlap(self):\n      overs = []\n      if not self.tx_obj1.range.overlaps(self.tx_obj2.range): return [] # if they dont overlap wont find anything\n      for i in range(0,len(self.j1)):\n        for j in range(0,len(self.j2)):\n          if self.j1[i].overlaps(self.j2[j],tolerance=self.tolerance):\n            overs.append([i,j])\n      return overs", "response": "Create the array that describes how junctions overlap"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string representation of the junction .", "response": "def get_string(self):\n    \"\"\"A string representation of the junction\n\n    :return: string represnetation\n    :rtype: string\n    \"\"\"\n    return self.left.chr+':'+str(self.left.end)+'-'+self.right.chr+':'+str(self.right.start)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntest equality with another junction", "response": "def equals(self,junc):\n    \"\"\"test equality with another junction\"\"\"\n    if self.left.equals(junc.left): return False\n    if self.right.equals(junc.right): return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsee if junction overlaps with tolerance", "response": "def overlaps(self,junc,tolerance=0):\n    \"\"\"see if junction overlaps with tolerance\"\"\"\n    if not self.left.overlaps(junc.left,padding=tolerance): return False\n    if not self.right.overlaps(junc.right,padding=tolerance): return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmp(self,junc,tolerance=0):\n    if self.overlaps(junc,tolerance):\n      return 0 #equal\n    if self.left.chr == junc.right.chr:\n      if self.left.start > junc.right.start:\n        return -1 #comes before\n    if self.right.chr == junc.left.chr:\n      if self.right.start < junc.right.start:\n        return 1 #comes after\n    return 2", "response": "compare two nodes in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_sequence(self,chr=None,start=None,end=None,dir=None,rng=None):\n    if rng: \n      chr = rng.chr\n      start = rng.start\n      end = rng.end\n      dir = rng.direction\n    if not start: start = 1\n    if not end: end = self.fai[chr]['length']\n    if not dir: dir = '+'\n    if dir == '-':\n      return sequence.Sequence.rc(self._seqs[chr][start-1:end])\n    return self._seqs[chr][start-1:end]", "response": "get a sequence by chr start and end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the OsidSession associated with the relationship query service.", "response": "def get_relationship_query_session(self):\n        \"\"\"Gets the ``OsidSession`` associated with the relationship query service.\n\n        return: (osid.relationship.RelationshipQuerySession) - a\n                ``RelationshipQuerySession``\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - ``supports_relationship_query()`` is\n                ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_relationship_query()`` is ``true``.*\n\n        \"\"\"\n        if not self.supports_relationship_query():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.RelationshipQuerySession(runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_relationship_query_session_for_family(self, family_id):\n        if not self.supports_relationship_query():\n            raise errors.Unimplemented()\n        ##\n        # Also include check to see if the catalog Id is found otherwise raise errors.NotFound\n        ##\n        # pylint: disable=no-member\n        return sessions.RelationshipQuerySession(family_id, runtime=self._runtime)", "response": "Gets the OsidSession associated with the relationship query service for the given family."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_relationship_admin_session(self):\n        if not self.supports_relationship_admin():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.RelationshipAdminSession(runtime=self._runtime)", "response": "Gets the OsidSession associated with the relationship administration service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the OsidSession associated with the relationship administration service for the given family.", "response": "def get_relationship_admin_session_for_family(self, family_id):\n        \"\"\"Gets the ``OsidSession`` associated with the relationship administration service for the given family.\n\n        arg:    family_id (osid.id.Id): the ``Id`` of the ``Family``\n        return: (osid.relationship.RelationshipAdminSession) - a\n                ``RelationshipAdminSession``\n        raise:  NotFound - no family found by the given ``Id``\n        raise:  NullArgument - ``family_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - ``supports_relationship_admin()`` or\n                ``supports_visible_federation()`` is ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_relationship_admin()`` and\n        ``supports_visible_federation()`` are ``true``*\n\n        \"\"\"\n        if not self.supports_relationship_admin():\n            raise errors.Unimplemented()\n        ##\n        # Also include check to see if the catalog Id is found otherwise raise errors.NotFound\n        ##\n        # pylint: disable=no-member\n        return sessions.RelationshipAdminSession(family_id, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the OsidSession associated with the relationship lookup service.", "response": "def get_relationship_lookup_session(self, proxy):\n        \"\"\"Gets the ``OsidSession`` associated with the relationship lookup service.\n\n        arg:    proxy (osid.proxy.Proxy): a proxy\n        return: (osid.relationship.RelationshipLookupSession) - a\n                ``RelationshipLookupSession``\n        raise:  NullArgument - ``proxy`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - ``supports_relationship_lookup()`` is\n                ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_relationship_lookup()`` is ``true``.*\n\n        \"\"\"\n        if not self.supports_relationship_lookup():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.RelationshipLookupSession(proxy=proxy, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_relationship_lookup_session_for_family(self, family_id, proxy):\n        if not self.supports_relationship_lookup():\n            raise errors.Unimplemented()\n        ##\n        # Also include check to see if the catalog Id is found otherwise raise errors.NotFound\n        ##\n        # pylint: disable=no-member\n        return sessions.RelationshipLookupSession(family_id, proxy, self._runtime)", "response": "Gets the OsidSession associated with the relationship lookup service for the given family."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_family_lookup_session(self, proxy):\n        if not self.supports_family_lookup():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.FamilyLookupSession(proxy=proxy, runtime=self._runtime)", "response": "Gets the OsidSession associated with the family lookup service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_family_admin_session(self, proxy):\n        if not self.supports_family_admin():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.FamilyAdminSession(proxy=proxy, runtime=self._runtime)", "response": "Gets the OsidSession associated with the family administrative service."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the OsidSession associated with the family hierarchy service.", "response": "def get_family_hierarchy_session(self, proxy):\n        \"\"\"Gets the ``OsidSession`` associated with the family hierarchy service.\n\n        arg:    proxy (osid.proxy.Proxy): a proxy\n        return: (osid.relationship.FamilyHierarchySession) - a\n                ``FamilyHierarchySession`` for families\n        raise:  NullArgument - ``proxy`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - ``supports_family_hierarchy()`` is\n                ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_family_hierarchy()`` is ``true``.*\n\n        \"\"\"\n        if not self.supports_family_hierarchy():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.FamilyHierarchySession(proxy=proxy, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the OsidSession associated with the family hierarchy design service.", "response": "def get_family_hierarchy_design_session(self, proxy):\n        \"\"\"Gets the ``OsidSession`` associated with the family hierarchy design service.\n\n        arg:    proxy (osid.proxy.Proxy): a proxy\n        return: (osid.relationship.FamilyHierarchyDesignSession) - a\n                ``HierarchyDesignSession`` for families\n        raise:  NullArgument - ``proxy`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - ``supports_family_hierarchy_design()``\n                is ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_family_hierarchy_design()`` is ``true``.*\n\n        \"\"\"\n        if not self.supports_family_hierarchy_design():\n            raise errors.Unimplemented()\n        # pylint: disable=no-member\n        return sessions.FamilyHierarchyDesignSession(proxy=proxy, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_authz_session(self):\n        from ..utilities import BOOTSTRAP_VAULT_TYPE\n        try:\n            vaults = self._get_vault_lookup_session().get_vaults_by_genus_type(BOOTSTRAP_VAULT_TYPE)\n        except Unimplemented:\n            return self._get_authz_manager().get_authorization_session()\n        if vaults.available():\n            vault = vaults.next()\n            return self._get_authz_manager().get_authorization_session_for_vault(vault.get_id())\n        else:\n            return self._get_authz_manager().get_authorization_session()", "response": "Gets the AuthorizationSession for the default typed Vault\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the AuthorizationLookupSession for the override typed Vault", "response": "def _get_override_lookup_session(self):\n        \"\"\"Gets the AuthorizationLookupSession for the override typed Vault\n\n        Assumes only one\n\n        \"\"\"\n        from ..utilities import OVERRIDE_VAULT_TYPE\n        try:\n            override_vaults = self._get_vault_lookup_session().get_vaults_by_genus_type(OVERRIDE_VAULT_TYPE)\n        except Unimplemented:\n            return None\n        if override_vaults.available():\n            vault = override_vaults.next()\n        else:\n            return None\n        session = self._get_authz_manager().get_authorization_lookup_session_for_vault(vault.get_id())\n        session.use_isolated_vault_view()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fetch_headers(self):\n    self._header_text, self._n_ref = self._read_top_header()\n    self._ref_lengths, self._ref_names = self._read_reference_information()\n    self._header = SAMHeader(self._header_text)", "response": "Fetch the header text and set self. _header"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_block(self):\n    b = self._fh.read(4) # get block size bytes\n    #print self._fh.tell()\n    if not b: raise StopIteration\n    block_size = struct.unpack('<i',b)[0]\n    return self._fh.read(block_size)", "response": "Just read a single block from the current location in _fh"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_reference_information(self):\n    ref_lengths = {}\n    ref_names = []\n    for n in range(self._n_ref):\n      l_name = struct.unpack('<i',self._fh.read(4))[0]\n      name = self._fh.read(l_name).rstrip('\\0')\n      l_ref = struct.unpack('<i',self._fh.read(4))[0]\n      ref_lengths[name] = l_ref\n      ref_names.append(name)\n    return ref_lengths, ref_names", "response": "Reads the reference names and lengths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the top header text and number of reference seqs", "response": "def _read_top_header(self):\n    \"\"\"Read the header text and number of reference seqs\"\"\"\n    magic = self._fh.read(4)\n    l_text = struct.unpack('<i',self._fh.read(4))[0]\n    header_text = self._fh.read(l_text).rstrip('\\0')\n    n_ref = struct.unpack('<i',self._fh.read(4))[0]\n    return header_text, n_ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches a single entry by the coordinate location", "response": "def fetch_by_coord(self,coord):\n    \"\"\"get a single entry by the coordinate location [blockStart, innerStart]\n\n    .. warning:: creates a new instance of a BAMFile object when maybe the one we had would have worked\n    \"\"\"\n    #print coord\n    #print self.path\n    #b2 = BAMFile(self.path,blockStart=coord[0],innerStart=coord[1],index_obj=self.index,reference=self._reference)\n    b2 = BAMFile(self.path,BAMFile.Options(blockStart=coord[0],innerStart=coord[1],reference=self.reference))\n    #for bam in b2: print type(bam)\n    #print 'hi'\n    bam = b2.read_entry()\n    b2.close()\n    b2 = None\n    return bam"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_starting_at_coord(self,coord):\n    #b2 = BAMFile(self.path,blockStart=coord[0],innerStart=coord[1],index_obj=self.index,reference=self._reference)\n    \"\"\"starting at a certain coordinate was supposed to make output\n\n    .. warning:: creates a new instance of a BAMFile object when maybe the one we had would have worked\n    \"\"\"\n    b2 = BAMFile(self.path,BAMFile.Options(blockStart=coord[0],innerStart=coord[1],reference=self.reference))\n    return b2", "response": "fetch the starting position of a BAM file at a certain coordinate"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_agents(self):\n        if self.retrieved:\n            raise errors.IllegalState('List has already been retrieved.')\n        self.retrieved = True\n        return objects.AgentList(self._results, runtime=self._runtime)", "response": "Gets the agent list resulting from the search."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_flag(exception_message):\n    import re\n    match = re.match('.* failed with flag (-\\d+)', exception_message)\n    try:\n        return int(match.group(1))\n    except Exception:\n        return None", "response": "Parses the exception message from the solver exception.\n    e. g. Dopri5 failed with flag - 3"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef simulate(self, timepoints):\n        solver = self._solver\n        last_timepoint = timepoints[-1]\n        try:\n            simulated_timepoints, simulated_values = solver.simulate(last_timepoint, ncp_list=timepoints)\n\n        except (Exception, self._solver_exception_class) as e:\n            # The exceptions thrown by solvers are usually hiding the real cause, try to see if it is\n            # our right_hand_side_as_function that is broken first\n            try:\n                self._problem.right_hand_side_as_function(self._initial_conditions, self._parameters)\n            except:\n                # If it is broken, throw that exception instead\n                raise\n            else:\n                # If it is not, handle the original exception\n                self._handle_solver_exception(e)\n\n        trajectories =  self._results_to_trajectories(simulated_timepoints, simulated_values)\n\n        return trajectories", "response": "Simulate the initial solver for the specified timepoints and return a list of trajectories."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _results_to_trajectories(self, simulated_timepoints, simulated_values):\n\n        descriptions = self._problem.left_hand_side_descriptors\n\n        return _wrap_results_to_trajectories(simulated_timepoints, simulated_values, descriptions)", "response": "Convert the results into a list of trajectories"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a synchronous version of Blackbird interface of the specified url.", "response": "def get_blackbird(url, use_serial=True):\n    \"\"\"\n    Return synchronous version of Blackbird interface\n    :param port_url: serial port, i.e. '/dev/ttyUSB0'\n    :return: synchronous implementation of Blackbird interface\n    \"\"\"\n    lock = RLock()\n    print(serial)\n\n    def synchronized(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            with lock:\n                return func(*args, **kwargs)\n        return wrapper\n\n    class BlackbirdSync(Blackbird):\n        def __init__(self, url):\n            \"\"\"\n            Initialize the client.\n            \"\"\"\n            if use_serial:\n                self._port = serial.serial_for_url(url, do_not_open=True)\n                self._port.baudrate = 9600\n                self._port.stopbits = serial.STOPBITS_ONE\n                self._port.bytesize = serial.EIGHTBITS\n                self._port.parity = serial.PARITY_NONE\n                self._port.timeout = TIMEOUT\n                self._port.write_timeout = TIMEOUT\n                self._port.open()\n\n            else:\n                self.host = url\n                self.port = PORT\n                self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self.socket.settimeout(TIMEOUT)\n                self.socket.connect((self.host, self.port))\n\n                # Clear login message\n                self.socket.recv(SOCKET_RECV)\n\n        def _process_request(self, request: bytes, skip=0):\n            \"\"\"\n            Send data to socket\n            :param request: request that is sent to the blackbird\n            :param skip: number of bytes to skip for end of transmission decoding\n            :return: ascii string returned by blackbird\n            \"\"\"\n            _LOGGER.debug('Sending \"%s\"', request)\n\n            if use_serial:\n                # clear\n                self._port.reset_output_buffer()\n                self._port.reset_input_buffer()\n                # send\n                self._port.write(request)\n                self._port.flush()\n                # receive\n                result = bytearray()\n                while True:\n                    c = self._port.read(1)\n                    if c is None:\n                        break\n                    if not c:\n                        raise serial.SerialTimeoutException(\n                            'Connection timed out! Last received bytes {}'.format([hex(a) for a in result]))\n                    result += c\n                    if len(result) > skip and result [-LEN_EOL:] == EOL:\n                        break\n                ret = bytes(result)\n                _LOGGER.debug('Received \"%s\"', ret)\n                return ret.decode('ascii')\n\n            else:\n                self.socket.send(request)\n\n                response = ''\n\n                while True:\n\n                    data = self.socket.recv(SOCKET_RECV)\n                    response += data.decode('ascii')\n                    \n                    if EOL in data and len(response) > skip:\n                        break\n\n                return response\n\n        @synchronized\n        def zone_status(self, zone: int):\n            # Returns status of a zone\n            return ZoneStatus.from_string(zone, self._process_request(_format_zone_status_request(zone), skip=20))\n\n        @synchronized\n        def set_zone_power(self, zone: int, power: bool):\n            # Set zone power\n            self._process_request(_format_set_zone_power(zone, power))\n\n        @synchronized\n        def set_zone_source(self, zone: int, source: int):\n            # Set zone source\n            self._process_request(_format_set_zone_source(zone, source))\n\n        @synchronized\n        def set_all_zone_source(self, source: int):\n            # Set all zones to one source\n            self._process_request(_format_set_all_zone_source(source))\n\n        @synchronized\n        def lock_front_buttons(self):\n            # Lock front panel buttons\n            self._process_request(_format_lock_front_buttons())\n\n        @synchronized\n        def unlock_front_buttons(self):\n            # Unlock front panel buttons\n            self._process_request(_format_unlock_front_buttons())\n\n        @synchronized\n        def lock_status(self):\n            # Report system locking status\n            return LockStatus.from_string(self._process_request(_format_lock_status()))\n\n    return BlackbirdSync(url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning asynchronous version of Blackbird interface.", "response": "def get_async_blackbird(port_url, loop):\n    \"\"\"\n    Return asynchronous version of Blackbird interface\n    :param port_url: serial port, i.e. '/dev/ttyUSB0'\n    :return: asynchronous implementation of Blackbird interface\n    \"\"\"\n\n    lock = asyncio.Lock()\n\n    def locked_coro(coro):\n        @asyncio.coroutine\n        @wraps(coro)\n        def wrapper(*args, **kwargs):\n            with (yield from lock):\n                return (yield from coro(*args, **kwargs))\n        return wrapper\n\n    class BlackbirdAsync(Blackbird):\n        def __init__(self, blackbird_protocol):\n            self._protocol = blackbird_protocol\n\n        @locked_coro\n        @asyncio.coroutine\n        def zone_status(self, zone: int):\n            string = yield from self._protocol.send(_format_zone_status_request(zone), skip=15)\n            return ZoneStatus.from_string(zone, string)\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_zone_power(self, zone: int, power: bool):\n            yield from self._protocol.send(_format_set_zone_power(zone, power))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_zone_source(self, zone: int, source: int):\n            yield from self._protocol.send(_format_set_zone_source(zone, source))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_all_zone_source(self, source: int):\n            yield from self._protocol.send(_format_set_all_zone_source(source))\n\n        @locked_coro\n        @asyncio.coroutine\n        def lock_front_buttons(self):\n            yield from self._protocol.send(_format_lock_front_buttons())\n\n        @locked_coro\n        @asyncio.coroutine\n        def unlock_front_buttons(self):\n            yield from self._protocol.send(_format_unlock_front_buttons())\n\n        @locked_coro\n        @asyncio.coroutine\n        def lock_status(self):\n            string = yield from self._protocol.send(_format_lock_status())\n            return LockStatus.from_string(string)\n\n    class BlackbirdProtocol(asyncio.Protocol):\n        def __init__(self, loop):\n            super().__init__()\n            self._loop = loop\n            self._lock = asyncio.Lock()\n            self._transport = None\n            self._connected = asyncio.Event(loop=loop)\n            self.q = asyncio.Queue(loop=loop)\n\n        def connection_made(self, transport):\n            self._transport = transport\n            self._connected.set()\n            _LOGGER.debug('port opened %s', self._transport)\n\n        def data_received(self, data):\n            asyncio.ensure_future(self.q.put(data), loop=self._loop)\n\n        @asyncio.coroutine\n        def send(self, request: bytes, skip=0):\n            yield from self._connected.wait()\n            result = bytearray()\n            # Only one transaction at a time\n            with (yield from self._lock):\n                self._transport.serial.reset_output_buffer()\n                self._transport.serial.reset_input_buffer()\n                while not self.q.empty():\n                    self.q.get_nowait()\n                self._transport.write(request)\n                try:\n                    while True:\n                        result += yield from asyncio.wait_for(self.q.get(), TIMEOUT, loop=self._loop)\n                        if len(result) > skip and result[-LEN_EOL:] == EOL:\n                            ret = bytes(result)\n                            _LOGGER.debug('Received \"%s\"', ret)\n                            return ret.decode('ascii')\n                except asyncio.TimeoutError:\n                    _LOGGER.error(\"Timeout during receiving response for command '%s', received='%s'\", request, result)\n                    raise\n\n    _, protocol = yield from create_serial_connection(loop, functools.partial(BlackbirdProtocol, loop), port_url, baudrate=9600)\n\n    return BlackbirdAsync(protocol)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the underlying log view to match current view", "response": "def _set_log_view(self, session):\n        \"\"\"Sets the underlying log view to match current view\"\"\"\n        if self._log_view == COMPARATIVE:\n            try:\n                session.use_comparative_log_view()\n            except AttributeError:\n                pass\n        else:\n            try:\n                session.use_plenary_log_view()\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef use_comparative_log_view(self):\n        self._log_view = COMPARATIVE\n        # self._get_provider_session('log_entry_log_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_comparative_log_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider LogEntryLogSession. use_comparative_log_view"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npassing through to provider LogEntryLogSession. use_plenary_log_view", "response": "def use_plenary_log_view(self):\n        \"\"\"Pass through to provider LogEntryLogSession.use_plenary_log_view\"\"\"\n        self._log_view = PLENARY\n        # self._get_provider_session('log_entry_log_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_plenary_log_view()\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npass through to provider LogLookupSession. get_logs_by_provider", "response": "def get_logs_by_provider(self, *args, **kwargs):\n        \"\"\"Pass through to provider LogLookupSession.get_logs_by_provider\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.BinLookupSession.get_bins_by_provider\n        catalogs = self._get_provider_session('log_lookup_session').get_logs_by_provider(*args, **kwargs)\n        cat_list = []\n        for cat in catalogs:\n            cat_list.append(Log(self._provider_manager, cat, self._runtime, self._proxy))\n        return LogList(cat_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_logs(self):\n        # Implemented from kitosid template for -\n        # osid.resource.BinLookupSession.get_bins_template\n        catalogs = self._get_provider_session('log_lookup_session').get_logs()\n        cat_list = []\n        for cat in catalogs:\n            cat_list.append(Log(self._provider_manager, cat, self._runtime, self._proxy))\n        return LogList(cat_list)", "response": "Pass through to provider LogLookupSession. get_logs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npass through to provider LogAdminSession. get_log_form_for_update", "response": "def get_log_form(self, *args, **kwargs):\n        \"\"\"Pass through to provider LogAdminSession.get_log_form_for_update\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.BinAdminSession.get_bin_form_for_update_template\n        # This method might be a bit sketchy. Time will tell.\n        if isinstance(args[-1], list) or 'log_record_types' in kwargs:\n            return self.get_log_form_for_create(*args, **kwargs)\n        else:\n            return self.get_log_form_for_update(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npass through to provider LogAdminSession. update_log", "response": "def update_log(self, *args, **kwargs):\n        \"\"\"Pass through to provider LogAdminSession.update_log\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.BinAdminSession.update_bin\n        # OSID spec does not require returning updated catalog\n        return Log(\n            self._provider_manager,\n            self._get_provider_session('log_admin_session').update_log(*args, **kwargs),\n            self._runtime,\n            self._proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_log(self, log_form, *args, **kwargs):\n        # Implemented from kitosid template for -\n        # osid.resource.BinAdminSession.update_bin\n        if log_form.is_for_update():\n            return self.update_log(log_form, *args, **kwargs)\n        else:\n            return self.create_log(log_form, *args, **kwargs)", "response": "Pass through to provider LogAdminSession. update_log"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_log_view(self, session):\n        if self._log_view == FEDERATED:\n            try:\n                session.use_federated_log_view()\n            except AttributeError:\n                pass\n        else:\n            try:\n                session.use_isolated_log_view()\n            except AttributeError:\n                pass", "response": "Sets the underlying log view to match current view"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef use_comparative_log_entry_view(self):\n        self._object_views['log_entry'] = COMPARATIVE\n        # self._get_provider_session('log_entry_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_comparative_log_entry_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider LogEntryLookupSession. use_comparative_log_entry_view"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef use_plenary_log_entry_view(self):\n        self._object_views['log_entry'] = PLENARY\n        # self._get_provider_session('log_entry_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_plenary_log_entry_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider LogEntryLookupSession. use_plenary_log_entry_view"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef use_federated_log_view(self):\n        self._log_view = FEDERATED\n        # self._get_provider_session('log_entry_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_federated_log_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider LogEntryLookupSession. use_federated_log_view"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef use_isolated_log_view(self):\n        self._log_view = ISOLATED\n        # self._get_provider_session('log_entry_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_isolated_log_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider LogEntryLookupSession. use_isolated_log_view"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_log_entry_form(self, *args, **kwargs):\n        # Implemented from kitosid template for -\n        # osid.resource.ResourceAdminSession.get_resource_form_for_update\n        # This method might be a bit sketchy. Time will tell.\n        if isinstance(args[-1], list) or 'log_entry_record_types' in kwargs:\n            return self.get_log_entry_form_for_create(*args, **kwargs)\n        else:\n            return self.get_log_entry_form_for_update(*args, **kwargs)", "response": "Pass through to provider LogEntryAdminSession. get_log_entry_form_for_update"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npasses through to provider LogEntryAdminSession. update_log_entry", "response": "def save_log_entry(self, log_entry_form, *args, **kwargs):\n        \"\"\"Pass through to provider LogEntryAdminSession.update_log_entry\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.ResourceAdminSession.update_resource\n        if log_entry_form.is_for_update():\n            return self.update_log_entry(log_entry_form, *args, **kwargs)\n        else:\n            return self.create_log_entry(log_entry_form, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_next_logs(self, n):\n        # Implemented from kitosid template for -\n        # osid.resource.ResourceList.get_next_resources\n        if n > self.available():\n            # !!! This is not quite as specified (see method docs) !!!\n            raise IllegalState('not enough elements available in this list')\n        else:\n            next_list = []\n            i = 0\n            while i < n:\n                try:\n                    next_list.append(next(self))\n                except StopIteration:\n                    break\n                i += 1\n            return next_list", "response": "gets next n objects from list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init(self, base_user):\n        self._base_user = base_user\n\n        # Modify this for multiple services support when the time comes\n        base_list = endpoints.myanimelist(base_user)\n\n        for anime in base_list:\n            id = anime[\"id\"]\n            score = anime[\"score\"]\n\n            self._base_scores[id] = [score]\n\n        return self", "response": "Initialize the object with the base user s list and store it in self. _base_user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef comparison(self, username):\n        # Check if there's actually a base user to compare scores with.\n        if not self._base_user or not self._base_scores:\n            raise Exception(\"No base user has been specified. Call the `init` \"\n                            \"function to retrieve a base users' scores\")\n\n        # Create a local, deep-copy of the scores for modification\n        scores = copy.deepcopy(self._base_scores)\n\n        user_list = endpoints.myanimelist(username)\n\n        for anime in user_list:\n            id = anime[\"id\"]\n            score = anime[\"score\"]\n\n            if id in scores:\n                scores[id].append(score)\n\n        # Force to list so no errors when deleting keys.\n        for key in list(scores.keys()):\n            if not len(scores[key]) == 2:\n                del scores[key]\n\n        return scores", "response": "Get a comparison of scores between the base user and username."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calculate_affinity(self, username):\n        scores = self.comparison(username)\n\n        # Handle cases where the shared scores are <= 10 so\n        # affinity can not be accurately calculated.\n        if len(scores) <= 10:\n            raise NoAffinityError(\"Shared rated anime count between \"\n                                  \"`{}` and `{}` is less than eleven\"\n                                  .format(self._base_user, username))\n\n        # Sort multiple rows of scores into two arrays for calculations.\n        # E.G. [1,2], [3,4], [5,6] to [1,3,5], [2,4,6]\n        values = scores.values()\n        scores1, scores2 = list(zip(*values))\n\n        pearson = calcs.pearson(scores1, scores2)\n        pearson *= 100\n\n        if self._round is not False:\n            pearson = round(pearson, self._round)\n\n        return models.Affinity(affinity=pearson, shared=len(scores))", "response": "Calculates the affinity between the base user and the given username."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a value into a bool but handle truthy strings eg yes true ok y", "response": "def to_bool(value):\n    # type: (Any) -> bool\n    \"\"\"\n    Convert a value into a bool but handle \"truthy\" strings eg, yes, true, ok, y\n    \"\"\"\n    if isinstance(value, _compat.string_types):\n        return value.upper() in ('Y', 'YES', 'T', 'TRUE', '1', 'OK')\n    return bool(value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_filter_update(base, updates):\n    # type: (dict, dict) -> None\n    \"\"\"\n    Update dict with None values filtered out.\n    \"\"\"\n    base.update((k, v) for k, v in updates.items() if v is not None)", "response": "Update dict with None values filtered out."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_filter(*args, **kwargs):\n    result = {}\n    for arg in itertools.chain(args, (kwargs,)):\n        dict_filter_update(result, arg)\n    return result", "response": "Merge all values into a single dict with all None values removed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_by_priority(iterable, reverse=False, default_priority=10):\n    return sorted(iterable, reverse=reverse, key=lambda o: getattr(o, 'priority', default_priority))", "response": "Return a list or objects sorted by a priority value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npopulate the change set with addCharm and deploy changes.", "response": "def handle_services(changeset):\n    \"\"\"Populate the change set with addCharm and deploy changes.\"\"\"\n    charms = {}\n    for service_name, service in sorted(changeset.bundle['services'].items()):\n        # Add the addCharm record if one hasn't been added yet.\n        if service['charm'] not in charms:\n            record_id = 'addCharm-{}'.format(changeset.next_action())\n            changeset.send({\n                'id': record_id,\n                'method': 'addCharm',\n                'args': [service['charm']],\n                'requires': [],\n            })\n            charms[service['charm']] = record_id\n\n        # Add the deploy record for this service.\n        record_id = 'deploy-{}'.format(changeset.next_action())\n        changeset.send({\n            'id': record_id,\n            'method': 'deploy',\n            'args': [\n                '${}'.format(charms[service['charm']]),\n                service_name,\n                service.get('options', {}),\n                service.get('constraints', ''),\n                service.get('storage', {}),\n            ],\n            'requires': [charms[service['charm']]],\n        })\n        changeset.services_added[service_name] = record_id\n\n        # Expose this service if required.\n        if service.get('expose'):\n            changeset.send({\n                'id': 'expose-{}'.format(changeset.next_action()),\n                'method': 'expose',\n                'args': ['${}'.format(record_id)],\n                'requires': [record_id],\n            })\n\n        # Set the annotations for this service.\n        if 'annotations' in service:\n            changeset.send({\n                'id': 'setAnnotations-{}'.format(changeset.next_action()),\n                'method': 'setAnnotations',\n                'args': [\n                    '${}'.format(record_id),\n                    'service',\n                    service['annotations'],\n                ],\n                'requires': [record_id],\n            })\n\n    return handle_machines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_machines(changeset):\n    machines = sorted(changeset.bundle.get('machines', {}).items())\n    for machine_name, machine in machines:\n        if machine is None:\n            # We allow the machine value to be unset in the YAML.\n            machine = {}\n        record_id = 'addMachines-{}'.format(changeset.next_action())\n        changeset.send({\n            'id': record_id,\n            'method': 'addMachines',\n            'args': [\n                {\n                    'series': machine.get('series', ''),\n                    'constraints': machine.get('constraints', ''),\n                },\n            ],\n            'requires': [],\n        })\n        changeset.machines_added[str(machine_name)] = record_id\n        if 'annotations' in machine:\n            changeset.send({\n                'id': 'setAnnotations-{}'.format(changeset.next_action()),\n                'method': 'setAnnotations',\n                'args': [\n                    '${}'.format(record_id),\n                    'machine',\n                    machine['annotations'],\n                ],\n                'requires': [record_id],\n            })\n    return handle_relations", "response": "Populate the change set with addMachines changes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npopulate the change set with addRelation changes.", "response": "def handle_relations(changeset):\n    \"\"\"Populate the change set with addRelation changes.\"\"\"\n    for relation in changeset.bundle.get('relations', []):\n        relations = [models.Relation(*i.split(':')) if ':' in i\n                     else models.Relation(i, '') for i in relation]\n        changeset.send({\n            'id': 'addRelation-{}'.format(changeset.next_action()),\n            'method': 'addRelation',\n            'args': [\n                '${}'.format(\n                    changeset.services_added[rel.name]) +\n                (':{}'.format(rel.interface) if rel.interface else '')\n                for rel in relations\n            ],\n            'requires': [changeset.services_added[rel.name] for\n                         rel in relations],\n        })\n    return handle_units"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npopulate the change set with addUnit changes.", "response": "def handle_units(changeset):\n    \"\"\"Populate the change set with addUnit changes.\"\"\"\n    units, records = {}, {}\n    for service_name, service in sorted(changeset.bundle['services'].items()):\n        for i in range(service.get('num_units', 0)):\n            record_id = 'addUnit-{}'.format(changeset.next_action())\n            unit_name = '{}/{}'.format(service_name, i)\n            records[record_id] = {\n                'id': record_id,\n                'method': 'addUnit',\n                'args': [\n                    '${}'.format(changeset.services_added[service_name]),\n                    None,\n                ],\n                'requires': [changeset.services_added[service_name]],\n            }\n            units[unit_name] = {\n                'record': record_id,\n                'service': service_name,\n                'unit': i,\n            }\n    _handle_units_placement(changeset, units, records)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_units_placement(changeset, units, records):\n    for service_name, service in sorted(changeset.bundle['services'].items()):\n        num_units = service.get('num_units')\n        if num_units is None:\n            # This is a subordinate service.\n            continue\n        placement_directives = service.get('to', [])\n        if not isinstance(placement_directives, (list, tuple)):\n            placement_directives = [placement_directives]\n        if placement_directives and not changeset.is_legacy_bundle():\n            placement_directives += (\n                placement_directives[-1:] *\n                (num_units - len(placement_directives)))\n        placed_in_services = {}\n        for i in range(num_units):\n            unit = units['{}/{}'.format(service_name, i)]\n            record = records[unit['record']]\n            if i < len(placement_directives):\n                record = _handle_unit_placement(\n                    changeset, units, unit, record, placement_directives[i],\n                    placed_in_services)\n            changeset.send(record)", "response": "Handle placement directives for units."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _next_unit_in_service(service, placed_in_services):\n    current = placed_in_services.get(service)\n    number = 0 if current is None else current + 1\n    placed_in_services[service] = number\n    return number", "response": "Return the next unit in a service."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(bundle, handler=handle_services):\n    changeset = ChangeSet(bundle)\n    while True:\n        handler = handler(changeset)\n        for change in changeset.recv():\n            yield change\n        if handler is None:\n            break", "response": "Parse a bundle and yield all changes required to deploy it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_or_create(self, db_name):\n        if not db_name in self:\n            res = self.resource.put(db_name)\n            if not res[0] == 201:\n                raise RuntimeError(\n                    'Failed to create database \"{}\"'.format(db_name)\n                )\n        return self[db_name]", "response": "Gets the database named db_name or creates it if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replicate(self, doc_id, source, target, continuous=False):\n        if doc_id in self[\"_replicator\"]:\n            return\n        data = {\n            \"_id\": doc_id,\n            \"source\": source,\n            \"target\": target,\n            \"continuous\": continuous\n        }\n        self[\"_replicator\"][doc_id] = data", "response": "Starts a replication from the source database to the target database by writing a document with the id doc_id to the _relicator record."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a user in the CouchDB instance with the username and password password.", "response": "def create_user(self, username, password):\n        \"\"\"\n        Creates a user in the CouchDB instance with the username `username` and\n        password `password`\n        \"\"\"\n        user_id = \"org.couchdb.user:\" + username\n        res = self[\"_users\"].resource.put(\n            user_id, body=json.dumps({\n                \"_id\": user_id,\n                \"name\": username,\n                \"roles\": [],\n                \"type\": \"user\",\n                \"password\": password,\n                \"farms\": []\n            })\n        )\n        if res[0] == 409:\n            raise RuntimeError(\n                'The username \"{}\" is already taken'.format(username)\n            )\n        elif res[0] != 201:\n            raise RuntimeError(\n                \"Failed to create user ({}): {}\".format(\n                    res.status_code, res.content\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog in to the CouchDB instance with the credentials username and password", "response": "def log_in(self, username, password):\n        \"\"\"\n        Logs in to the CouchDB instance with the credentials `username` and\n        `password`\n        \"\"\"\n        self.resource.credentials = (username, password)\n        return self.resource.get_json(\"_session\")[2]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_user_info(self):\n        try:\n            user_id = \"org.couchdb.user:\"+self.resource.credentials[0]\n        except TypeError:\n            raise RuntimeError(\n                \"Please log in before trying to access your user's info\"\n            )\n        status, _, body = self[\"_users\"].resource.get_json(user_id)\n        if status != 200:\n            raise RuntimeError(\n                \"Failed to get user info\"\n            )\n        return body", "response": "Returns the user s info on the server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush the design documents stored in design_path to the server", "response": "def push_design_documents(self, design_path):\n        \"\"\"\n        Push the design documents stored in `design_path` to the server\n        \"\"\"\n        for db_name in os.listdir(design_path):\n            if db_name.startswith(\"__\") or db_name.startswith(\".\"):\n                continue\n            db_path = os.path.join(design_path, db_name)\n            doc = self._folder_to_dict(db_path)\n            doc_id = \"_design/openag\"\n            doc[\"_id\"] = doc_id\n            db = self[db_name]\n            if doc_id in db:\n                old_doc = db[doc_id]\n                doc[\"_rev\"] = old_doc[\"_rev\"]\n                if doc == old_doc:\n                    continue\n            db[doc_id] = doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets an asset search session for the given repository.", "response": "def get_asset_search_session_for_repository(self, repository_id=None):\n        \"\"\"Gets an asset search session for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        return: (osid.repository.AssetSearchSession) - an\n                AssetSearchSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_search() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_search() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_search():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        try:\n            session = sessions.AssetSearchSession(repository_id,\n                                                  proxy=self._proxy,\n                                                  runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an asset administration session for creating updating and deleting assets.", "response": "def get_asset_admin_session(self, *args, **kwargs):\n        \"\"\"Gets an asset administration session for creating, updating and\n        deleting assets.\n\n        return: (osid.repository.AssetAdminSession) - an\n                AssetAdminSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_admin() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_admin() is true.\n\n        \"\"\"\n        if not self.supports_asset_admin():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.AssetAdminSession(proxy=self._proxy,\n                                                 runtime=self._runtime, **kwargs)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an asset administration session for the given repository.", "response": "def get_asset_admin_session_for_repository(self, repository_id=None, *args, **kwargs):\n        \"\"\"Gets an asset administration session for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        return: (osid.repository.AssetAdminSession) - an\n                AssetAdminSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_admin() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_admin() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_admin():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        try:\n            session = sessions.AssetAdminSession(repository_id,\n                                                 proxy=self._proxy,\n                                                 runtime=self._runtime, **kwargs)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the session for retrieving temporal coverage of an asset.", "response": "def get_asset_temporal_session(self):\n        \"\"\"Gets the session for retrieving temporal coverage of an asset.\n\n        return: (osid.repository.AssetTemporalSession) - an\n                AssetTemporalSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_temporal() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_temporal() is true.\n\n        \"\"\"\n        if not self.supports_asset_temporal():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.AssetTemporalSession(proxy=self._proxy,\n                                                    runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_asset_temporal_session_for_repository(self, repository_id=None):\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_temporal():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        try:\n            session = sessions.AssetTemporalSession(repository_id,\n                                                    proxy=self._proxy,\n                                                    runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session", "response": "Gets the session for retrieving temporal coverage of an asset in a repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the session for assigning temporal coverage to an asset.", "response": "def get_asset_temporal_assignment_session(self):\n        \"\"\"Gets the session for assigning temporal coverage to an asset.\n\n        return: (osid.repository.AssetTemporalAssignmentSession) - an\n                AssetTemporalAssignmentSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_temporal_assignment() is\n                false\n        compliance: optional - This method must be implemented if\n                    supports_asset_temporal_assignment() is true.\n\n        \"\"\"\n        if not self.supports_asset_temporal_assignment():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.AssetTemporalAssignmentSession(proxy=self._proxy,\n                                                              runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the session for retrieving asset compositions.", "response": "def get_asset_composition_session(self):\n        \"\"\"Gets the session for retrieving asset compositions.\n\n        return: (osid.repository.AssetCompositionSession) - an\n                AssetCompositionSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_composition() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_composition() is true.\n\n        \"\"\"\n        if not self.supports_asset_composition():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.AssetCompositionSession(proxy=self._proxy,\n                                                       runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the session for creating asset compositions.", "response": "def get_asset_composition_design_session(self):\n        \"\"\"Gets the session for creating asset compositions.\n\n        return: (osid.repository.AssetCompositionDesignSession) - an\n                AssetCompositionDesignSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_composition_design() is\n                false\n        compliance: optional - This method must be implemented if\n                    supports_asset_composition_design() is true.\n\n        \"\"\"\n        if not self.supports_asset_composition_design():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        try:\n            session = sessions.AssetCompositionDesignSession(proxy=self._proxy,\n                                                             runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_composition_lookup_session(self):\n        if not self.supports_composition_lookup():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.CompositionLookupSession(proxy=self._proxy,\n                                                        runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets the OsidSession associated with the composition lookup session."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_composition_admin_session(self):\n        if not self.supports_composition_admin():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.CompositionAdminSession(proxy=self._proxy,\n                                                       runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets a composition administration session for creating updating\n        and deleting compositions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_composition_admin_session_for_repository(self, repository_id=None):\n        if repository_id is None:\n            raise NullArgument()\n        if not self.supports_composition_admin() or not self.supports_visible_federation():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.CompositionSearchSession(repository_id,\n                                                        proxy=self._proxy,\n                                                        runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets a composiiton administrative session for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_repository_query_session(self):\n        if not self.supports_repository_query():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.RepositoryQuerySession(proxy=self._proxy,\n                                                      runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets the repository query session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the repository search session.", "response": "def get_repository_search_session(self):\n        \"\"\"Gets the repository search session.\n\n        return: (osid.repository.RepositorySearchSession) - a\n                RepositorySearchSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_repository_search() is false\n        compliance: optional - This method must be implemented if\n                    supports_repository_search() is true.\n\n        \"\"\"\n        if not self.supports_repository_search():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.RepositorySearchSession(proxy=self._proxy,\n                                                       runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_repository_admin_session(self):\n        if not self.supports_repository_admin():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        try:\n            session = sessions.RepositoryAdminSession(proxy=self._proxy,\n                                                      runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets the repository administrative session for creating updating and deleting repositories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the OsidSession associated with the asset lookup service.", "response": "def get_asset_lookup_session(self, proxy, *args, **kwargs):\n        \"\"\"Gets the OsidSession associated with the asset lookup service.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetLookupSession) - the new\n                AssetLookupSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_lookup() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_lookup() is true.\n\n        \"\"\"\n        if not self.supports_asset_lookup():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetLookupSession(proxy=proxy, runtime=self._runtime, **kwargs)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the OsidSession associated with the asset lookup service for the given repository.", "response": "def get_asset_lookup_session_for_repository(self, repository_id, proxy, *args, **kwargs):\n        \"\"\"Gets the OsidSession associated with the asset lookup service\n        for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetLookupSession) - the new\n                AssetLookupSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_lookup() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_lookup() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_lookup():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetLookupSession(repository_id, proxy, runtime=self._runtime, **kwargs)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_asset_query_session(self, proxy):\n        if not self.supports_asset_query():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetQuerySession(proxy=proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets an asset query session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an asset query session for the given repository.", "response": "def get_asset_query_session_for_repository(self, repository_id, proxy):\n        \"\"\"Gets an asset query session for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetQuerySession) - an\n                AssetQuerySession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_query() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_query() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_query():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetQuerySession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an asset search session.", "response": "def get_asset_search_session(self, proxy):\n        \"\"\"Gets an asset search session.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetSearchSession) - an\n                AssetSearchSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_search() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_search() is true.\n\n        \"\"\"\n        if not self.supports_asset_search():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetSearchSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the notification session for notifications pertaining to an asset changes.", "response": "def get_asset_notification_session(self, asset_receiver, proxy):\n        \"\"\"Gets the notification session for notifications pertaining to\n        asset changes.\n\n        arg:    asset_receiver (osid.repository.AssetReceiver): the\n                notification callback\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetNotificationSession) - an\n                AssetNotificationSession\n        raise:  NullArgument - asset_receiver is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_notification() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_notification() is true.\n\n        \"\"\"\n        if asset_receiver is None:\n            raise NullArgument()\n        if not self.supports_asset_notification():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetNotificationSession(asset_receiver, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_asset_notification_session_for_repository(self, asset_receiver, repository_id, proxy):\n        if not repository_id or not asset_receiver:\n            raise NullArgument()\n        if not self.supports_asset_lookup():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetAdminSession(asset_receiver, repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session", "response": "Gets the asset notification session for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_asset_repository_session(self, proxy):\n        if not self.supports_asset_repository():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetRespositorySession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets the session for retrieving asset to repository mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the session for assigning asset to repository mappings.", "response": "def get_asset_repository_assignment_session(self, proxy):\n        \"\"\"Gets the session for assigning asset to repository mappings.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetRepositoryAssignmentSession) - an\n                AssetRepositoryAsignmentSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_repository_assignment()\n                is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_repository_assignment() is true.\n\n        \"\"\"\n        if not self.supports_asset_repository_assignment():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetRespositoryAssignmentSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an asset smart repository session for the given repository.", "response": "def get_asset_smart_repository_session(self, repository_id, proxy):\n        \"\"\"Gets an asset smart repository session for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetSmartRepositorySession) - an\n                AssetSmartRepositorySession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_smart_repository()  false\n        compliance: optional - This method must be implemented if\n                    supports_asset_smart_repository() is true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_smart_repository():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetSmartRepositorySession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_asset_temporal_assignment_session_for_repository(self, repository_id, proxy):\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_temporal_assignment():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetTemporalAssignmentSession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session", "response": "Gets the session for assigning temporal coverage of an asset for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the session for retrieving spatial coverage of an asset.", "response": "def get_asset_spatial_session(self, proxy):\n        \"\"\"Gets the session for retrieving spatial coverage of an asset.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetSpatialSession) - an\n                AssetSpatialSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_spatial_assets() is false\n        compliance: optional - This method must be implemented if\n                    supports_spatial_assets() is true.\n\n        \"\"\"\n        if not self.supports_spatial_asset():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetSpatialSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the session for retrieving spatial coverage of an asset for the given repository.", "response": "def get_asset_spatial_session_for_repository(self, repository_id, proxy):\n        \"\"\"Gets the session for retrieving spatial coverage of an asset for\n        the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetSpatialSession) - an\n                AssetSpatialSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_spatial() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_spatial() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_spatial() or not self.supports_visible_federation():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetSpatialSession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the session for assigning spatial coverage to an asset.", "response": "def get_asset_spatial_assignment_session(self, proxy):\n        \"\"\"Gets the session for assigning spatial coverage to an asset.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetSpatialAssignmentSession) - an\n                AssetSpatialAssignmentSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_spatial_assignment() is\n                false\n        compliance: optional - This method must be implemented if\n                    supports_asset_spatial_assignment() is true.\n\n        \"\"\"\n        if not self.supports_asset_spatial_assignment():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetSpatialAssignmentSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the session for assigning spatial coverage of an asset for the given repository.", "response": "def get_asset_spatial_assignment_session_for_repository(self, repository_id, proxy):\n        \"\"\"Gets the session for assigning spatial coverage of an asset for\n        the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetSpatialAssignmentSession) - an\n                AssetSpatialAssignmentSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_asset_spatial_assignment() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_asset_spatial_assignment() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if not repository_id:\n            raise NullArgument()\n        if not self.supports_asset_spatial_assignment() or not self.supports_visible_federation():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise OperationFailed('import error')\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.AssetSpatialAssignmentSession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise OperationFailed('attribute error')\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the OsidSession associated with the composition lookup service for the given repository.", "response": "def get_composition_lookup_session_for_repository(self, repository_id, proxy):\n        \"\"\"Gets the OsidSession associated with the composition lookup\n        service for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionLookupSession) - the new\n                CompositionLookupSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_lookup() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_composition_lookup() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if repository_id is None:\n            raise NullArgument()\n        if not self.supports_composition_lookup():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionLookupSession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a composition query session.", "response": "def get_composition_query_session(self, proxy):\n        \"\"\"Gets a composition query session.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionQuerySession) - a\n                CompositionQuerySession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_query() is false\n        compliance: optional - This method must be implemented if\n                    supports_composition_query() is true.\n\n        \"\"\"\n        if not self.supports_composition_query():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionQuerySession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a composition query session for the given repository.", "response": "def get_composition_query_session_for_repository(self, repository_id, proxy):\n        \"\"\"Gets a composition query session for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionQuerySession) - a\n                CompositionQuerySession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_query() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_composition_query() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if repository_id is None:\n            raise NullArgument()\n        if not self.supports_composition_query():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionQuerySession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_composition_search_session(self, proxy):\n        if not self.supports_composition_search():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionSearchSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets a composition search session."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a composition search session for the given repository.", "response": "def get_composition_search_session_for_repository(self, repository_id, proxy):\n        \"\"\"Gets a composition search session for the given repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionSearchSession) - a\n                CompositionSearchSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_search() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_composition_search() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if repository_id is None:\n            raise NullArgument()\n        if not self.supports_composition_search() or not self.supports_visible_federation():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionSearchSession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the composition notification session for the given repository.", "response": "def get_composition_notification_session_for_repository(self, composition_receiver, repository_id, proxy):\n        \"\"\"Gets the composition notification session for the given\n        repository.\n\n        arg:    composition_receiver\n                (osid.repository.CompositionReceiver): the notification\n                callback\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionNotificationSession) - a\n                CompositionNotificationSession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - composition_receiver or repository_id is\n                null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_notification() or\n                supports_visible_federation() is false\n        compliance: optional - This method must be implemented if\n                    supports_composition_notfication() and\n                    supports_visible_federation() are true.\n\n        \"\"\"\n        if composition_receiver is None or repository_id is None:\n            raise NullArgument()\n        if not self.supports_composition_notification():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionNotificationSession(composition_receiver,\n                                                              repository_id,\n                                                              proxy,\n                                                              runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the session for retrieving composition to repository mappings.", "response": "def get_composition_repository_session(self, proxy):\n        \"\"\"Gets the session for retrieving composition to repository\n        mappings.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionRepositorySession) - a\n                CompositionRepositorySession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_repository() is\n                false\n        compliance: optional - This method must be implemented if\n                    supports_composition_repository() is true.\n\n        \"\"\"\n        if not self.supports_composition_repository():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionRepositorySession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the session for assigning composition to repository mappings.", "response": "def get_composition_repository_assignment_session(self, proxy):\n        \"\"\"Gets the session for assigning composition to repository\n        mappings.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionRepositoryAssignmentSession)\n                - a CompositionRepositoryAssignmentSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented -\n                supports_composition_repository_assignment() is false\n        compliance: optional - This method must be implemented if\n                    supports_composition_repository_assignment() is\n                    true.\n\n        \"\"\"\n        if not self.supports_composition_repository_assignment():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionRepositoryAssignmentSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a composition smart repository session for the given repository.", "response": "def get_composition_smart_repository_session(self, repository_id, proxy):\n        \"\"\"Gets a composition smart repository session for the given\n        repository.\n\n        arg:    repository_id (osid.id.Id): the Id of the repository\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionSmartRepositorySession) - a\n                CompositionSmartRepositorySession\n        raise:  NotFound - repository_id not found\n        raise:  NullArgument - repository_id is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_composition_smart_repository()\n                false\n        compliance: optional - This method must be implemented if\n                    supports_composition_smart_repository() is true.\n\n        \"\"\"\n        if repository_id is None:\n            raise NullArgument()\n        if not self.supports_composition_smart_repository():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.CompositionSmartRepositorySession(repository_id, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the repository lookup session.", "response": "def get_repository_lookup_session(self, proxy, *args, **kwargs):\n        \"\"\"Gets the repository lookup session.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.RepositoryLookupSession) - a\n                RepositoryLookupSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_repository_lookup() is false\n        compliance: optional - This method must be implemented if\n                    supports_repository_lookup() is true.\n\n        \"\"\"\n        if not self.supports_repository_lookup():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.RepositoryLookupSession(proxy, runtime=self._runtime, **kwargs)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the notification session for subscribing to changes to a specific a repository.", "response": "def get_repository_notification_session(self, repository_receiver, proxy):\n        \"\"\"Gets the notification session for subscribing to changes to a\n        repository.\n\n        arg:    repository_receiver\n                (osid.repository.RepositoryReceiver): the notification\n                callback\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.RepositoryNotificationSession) - a\n                RepositoryNotificationSession\n        raise:  NullArgument - repository_receiver is null\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_repository_notification() is\n                false\n        compliance: optional - This method must be implemented if\n                    supports_repository_notification() is true.\n\n        \"\"\"\n        if repository_receiver is None:\n            raise NullArgument()\n        if not self.supports_repository_notification():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.RepositoryNotificationSession(repository_receiver, proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_repository_hierarchy_session(self, proxy):\n        if not self.supports_repository_hierarchy():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.RepositoryHierarchySession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session", "response": "Gets the repository hierarchy traversal session."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the repository hierarchy design session.", "response": "def get_repository_hierarchy_design_session(self, proxy):\n        \"\"\"Gets the repository hierarchy design session.\n\n        arg     proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.RepositoryHierarchyDesignSession) - a\n                RepostoryHierarchyDesignSession\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - supports_repository_hierarchy_design()\n                is false\n        compliance: optional - This method must be implemented if\n                    supports_repository_hierarchy_design() is true.\n\n        \"\"\"\n        if not self.supports_repository_hierarchy_design():\n            raise Unimplemented()\n        try:\n            from . import sessions\n        except ImportError:\n            raise  # OperationFailed()\n        proxy = self._convert_proxy(proxy)\n        try:\n            session = sessions.RepositoryHierarchyDesignSession(proxy, runtime=self._runtime)\n        except AttributeError:\n            raise  # OperationFailed()\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the OsidSession associated with the asset content lookup service for the given repository.", "response": "def get_asset_content_lookup_session_for_repository(self, repository_id=None):\n        \"\"\"Gets the ``OsidSession`` associated with the asset content lookup service for\n        the given repository.\n\n        arg:    repository_id (osid.id.Id): the ``Id`` of the repository\n        return: (osid.repository.AssetLookupSession) - the new\n                ``AssetLookupSession``\n        raise:  NotFound - ``repository_id`` not found\n        raise:  NullArgument - ``repository_id`` is ``null``\n        raise:  OperationFailed - ``unable to complete request``\n        raise:  Unimplemented - ``supports_asset_lookup()`` or\n                ``supports_visible_federation()`` is ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_asset_lookup()`` and\n        ``supports_visible_federation()`` are ``true``.*\n\n        \"\"\"\n        return AssetContentLookupSession(\n            self._provider_manager.get_asset_content_lookup_session_for_repository(repository_id),\n            self._config_map)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_asset_query_session_for_repository(self, repository_id=None):\n        return AssetQuerySession(\n            self._provider_manager.get_asset_query_session_for_repository(repository_id),\n            self._config_map)", "response": "Gets an asset query session for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the OsidSession associated with the asset lookup service.", "response": "def get_asset_lookup_session(self, proxy=None):\n        \"\"\"Gets the ``OsidSession`` associated with the asset lookup service.\n\n        arg:    proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetLookupSession) - an\n                ``AssetLookupSession``\n        raise:  NullArgument - ``proxy`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  Unimplemented - ``supports_asset_lookup()`` is ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_asset_lookup()`` is ``true``.*\n\n        \"\"\"\n        return AssetLookupSession(self._provider_manager.get_asset_lookup_session(proxy),\n                                  self._config_map)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_asset_lookup_session_for_repository(self, repository_id=None, proxy=None):\n        return AssetLookupSession(\n            self._provider_manager.get_asset_lookup_session_for_repository(repository_id,\n                                                                           proxy),\n            self._config_map)", "response": "Gets the OsidSession associated with the asset lookup service for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_asset_content_lookup_session(self, proxy=None):\n        return AssetContentLookupSession(self._provider_manager.get_asset_content_lookup_session(proxy),\n                                         self._config_map)", "response": "Gets the OsidSession associated with the asset content lookup service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_asset_query_session(self, proxy=None):\n        return AssetQuerySession(\n            self._provider_manager.get_asset_query_session(proxy),\n            self._config_map)", "response": "Gets the OsidSession associated with the asset query service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_asset_admin_session(self, proxy=None):\n        asset_lookup_session = self._provider_manager.get_asset_lookup_session(proxy)\n        return AssetAdminSession(\n            self._provider_manager.get_asset_admin_session(proxy),\n            self._config_map,\n            asset_lookup_session)", "response": "Gets an asset administration session for creating updating and deleting assets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_asset_admin_session_for_repository(self, repository_id=None, proxy=None):\n        asset_lookup_session = self._provider_manager.get_asset_lookup_session_for_repository(\n            repository_id, proxy)\n        return AssetAdminSession(\n            self._provider_manager.get_asset_admin_session_for_repository(repository_id,\n                                                                          proxy),\n            self._config_map,\n            asset_lookup_session)", "response": "Gets an asset administration session for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the asset notification session for the given repository.", "response": "def get_asset_notification_session_for_repository(self,\n                                                      asset_receiver=None,\n                                                      repository_id=None,\n                                                      proxy=None):\n        \"\"\"Gets the asset notification session for the given repository.\n\n        arg:    asset_receiver (osid.repository.AssetReceiver): the\n                notification callback\n        arg:    repository_id (osid.id.Id): the ``Id`` of the repository\n        arg:    proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.AssetNotificationSession) - an\n                ``AssetNotificationSession``\n        raise:  NotFound - ``repository_id`` not found\n        raise:  NullArgument - ``asset_receiver, repository_id`` or\n                ``proxy`` is ``null``\n        raise:  OperationFailed - ``unable to complete request``\n        raise:  Unimplemented - ``supports_asset_notification()`` or\n                ``supports_visible_federation()`` is ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_asset_notfication()`` and\n        ``supports_visible_federation()`` are ``true``.*\n\n        \"\"\"\n        # Implemented from awsosid template for -\n        # osid.resource.ResourceManager.get_resource_lookup_session_for_bin_template\n        return self._provider_manager.get_asset_notification_session_for_repository(\n            asset_receiver,\n            repository_id,\n            proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_composition_notification_session_for_repository(self,\n                                                            composition_receiver=None,\n                                                            repository_id=None,\n                                                            proxy=None):\n        \"\"\"Gets the composition notification session for the given repository.\n\n        arg:    composition_receiver\n                (osid.repository.CompositionReceiver): the notification\n                callback\n        arg:    repository_id (osid.id.Id): the ``Id`` of the repository\n        arg:    proxy (osid.proxy.Proxy): a proxy\n        return: (osid.repository.CompositionNotificationSession) - a\n                ``CompositionNotificationSession``\n        raise:  NotFound - ``repository_id`` not found\n        raise:  NullArgument - ``composition_receiver, repository_id``\n                or ``proxy`` is ``null``\n        raise:  OperationFailed - ``unable to complete request``\n        raise:  Unimplemented - ``supports_composition_notification()``\n                or ``supports_visible_federation()`` is ``false``\n        *compliance: optional -- This method must be implemented if\n        ``supports_composition_notfication()`` and\n        ``supports_visible_federation()`` are ``true``.*\n\n        \"\"\"\n        # Implemented from awsosid template for -\n        # osid.resource.ResourceManager.get_resource_lookup_session_for_bin_template\n        return self._provider_manager.get_composition_notification_session_for_repository(\n            composition_receiver,\n            proxy)", "response": "Gets the composition notification session for the given repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate(self):\n      self._calculated = True\n      for name in self.transcripts:\n         self.transcripts[name]['RPK'] = (float(self.transcripts[name]['count'])/float(self.transcripts[name]['length']))/float(1000)\n      tot = 0.0\n      for name in self.transcripts:\n         tot += self.transcripts[name]['RPK']\n      tot = tot/float(1000000)\n      for name in self.transcripts:\n         self.transcripts[name]['TPM'] = self.transcripts[name]['RPK']/tot\n      \"\"\"do the FPKM calculation\"\"\"\n      tot = 0\n      for name in self.transcripts: tot += self.transcripts[name]['count']\n      tot = float(tot)/float(1000000)\n      for name in self.transcripts:\n         if tot > 0:\n            rpm = float(self.transcripts[name]['count'])/float(tot)\n            self.transcripts[name]['FPKM'] = 1000*rpm/self.transcripts[name]['length']", "response": "calculate TPM and FPKM"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tuple_roll(self, count=0):\n        '''One or more die rolls.\n        :param count: [0] Return list of ``count`` rolls\n        :return: (face, value) of roll or list of same\n        '''\n        if count:\n            return [self._faces[random.randint(1, self._sides) - 1] for i in range(count)]\n        else:\n            return self._faces[random.randint(1, self._sides) - 1]", "response": "One or more die rolls.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _init_map(self):\n        self.my_osid_object_form._my_map['rerandomize'] = \\\n            self._rerandomize_metadata['default_object_values'][0]\n        super(edXMultiChoiceQuestionFormRecord, self)._init_map()", "response": "Initialize the map for the record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the metadata for the object", "response": "def _init_metadata(self):\n        \"\"\"stub\"\"\"\n        self._rerandomize_metadata = {\n            'element_id': Id(self.my_osid_object_form._authority,\n                             self.my_osid_object_form._namespace,\n                             'rerandomize'),\n            'element_label': 'Randomize',\n            'instructions': 'How to rerandomize the parameters',\n            'required': False,\n            'read_only': False,\n            'linked': False,\n            'array': False,\n            'default_object_values': ['never'],\n            'syntax': 'STRING',\n            'minimum_string_length': None,\n            'maximum_string_length': None,\n            'string_set': []\n        }\n        super(edXMultiChoiceQuestionFormRecord, self)._init_metadata()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a rerandomize to the archive", "response": "def add_rerandomize(self, rerandomize):\n        \"\"\"stub\"\"\"\n        if not self.my_osid_object_form._is_valid_string(\n                rerandomize, self.get_rerandomize_metadata()):\n            raise InvalidArgument('rerandomize')\n        self.my_osid_object_form._my_map['rerandomize'] = rerandomize"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the objective list resulting from the search.", "response": "def get_objectives(self):\n        \"\"\"Gets the objective list resulting from the search.\n\n        return: (osid.learning.ObjectiveList) - the objective list\n        raise:  IllegalState - list already retrieved\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        if self.retrieved:\n            raise errors.IllegalState('List has already been retrieved.')\n        self.retrieved = True\n        return objects.ObjectiveList(self._results, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the activity list resulting from the search.", "response": "def get_activities(self):\n        \"\"\"Gets the activity list resulting from the search.\n\n        return: (osid.learning.ActivityList) - the activity list\n        raise:  IllegalState - list already retrieved\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        if self.retrieved:\n            raise errors.IllegalState('List has already been retrieved.')\n        self.retrieved = True\n        return objects.ActivityList(self._results, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_proficiencies(self):\n        if self.retrieved:\n            raise errors.IllegalState('List has already been retrieved.')\n        self.retrieved = True\n        return objects.ProficiencyList(self._results, runtime=self._runtime)", "response": "Gets the proficiency list resulting from a search."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the objective bank list resulting from the search.", "response": "def get_objective_banks(self):\n        \"\"\"Gets the objective bank list resulting from the search.\n\n        return: (osid.learning.ObjectiveBankList) - the objective bank\n                list\n        raise:  IllegalState - list already retrieved\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        if self.retrieved:\n            raise errors.IllegalState('List has already been retrieved.')\n        self.retrieved = True\n        return objects.ObjectiveBankList(self._results, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_bin_view(self, session):\n        if self._bin_view == COMPARATIVE:\n            try:\n                session.use_comparative_bin_view()\n            except AttributeError:\n                pass\n        else:\n            try:\n                session.use_plenary_bin_view()\n            except AttributeError:\n                pass", "response": "Sets the underlying bin view to match current view"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize(self, runtime):\n        from .primitives import Id\n        if self._runtime is not None:\n            raise IllegalState('Manager has already been initialized')\n        self._runtime = runtime\n        config = runtime.get_configuration()\n        parameter_id = Id('parameter:resourceProviderImpl@dlkit_service')\n        provider_impl = config.get_value_by_parameter(parameter_id).get_string_value()\n        if self._proxy is None:\n            # need to add version argument\n            self._provider_manager = runtime.get_manager('RESOURCE', provider_impl)\n        else:\n            # need to add version argument\n            self._provider_manager = runtime.get_proxy_manager('RESOURCE', provider_impl)", "response": "Initialize the OSID Manager."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npassing through to provider ResourceBinSession. use_comparative_bin_view", "response": "def use_comparative_bin_view(self):\n        \"\"\"Pass through to provider ResourceBinSession.use_comparative_bin_view\"\"\"\n        self._bin_view = COMPARATIVE\n        # self._get_provider_session('resource_bin_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_comparative_bin_view()\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npass through to provider ResourceBinSession. use_plenary_bin_view", "response": "def use_plenary_bin_view(self):\n        \"\"\"Pass through to provider ResourceBinSession.use_plenary_bin_view\"\"\"\n        self._bin_view = PLENARY\n        # self._get_provider_session('resource_bin_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_plenary_bin_view()\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bins_by_resource(self, *args, **kwargs):\n        # Implemented from kitosid template for -\n        # osid.resource.ResourceBinSession.get_bins_by_resource\n        catalogs = self._get_provider_session('resource_bin_session').get_bins_by_resource(*args, **kwargs)\n        cat_list = []\n        for cat in catalogs:\n            cat_list.append(Bin(self._provider_manager, cat, self._runtime, self._proxy))\n        return BinList(cat_list)", "response": "Pass through to provider ResourceBinSession. get_bins_by_resource"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bin(self, *args, **kwargs):\n        # Implemented from kitosid template for -\n        # osid.resource.BinLookupSession.get_bin\n        return Bin(\n            self._provider_manager,\n            self._get_provider_session('bin_lookup_session').get_bin(*args, **kwargs),\n            self._runtime,\n            self._proxy)", "response": "Pass through to provider BinLookupSession. get_bin"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npass through to provider BinLookupSession. get_bins", "response": "def get_bins(self):\n        \"\"\"Pass through to provider BinLookupSession.get_bins\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.BinLookupSession.get_bins_template\n        catalogs = self._get_provider_session('bin_lookup_session').get_bins()\n        cat_list = []\n        for cat in catalogs:\n            cat_list.append(Bin(self._provider_manager, cat, self._runtime, self._proxy))\n        return BinList(cat_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npasses through to provider BinAdminSession. get_bin_form_for_update", "response": "def get_bin_form(self, *args, **kwargs):\n        \"\"\"Pass through to provider BinAdminSession.get_bin_form_for_update\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.BinAdminSession.get_bin_form_for_update_template\n        # This method might be a bit sketchy. Time will tell.\n        if isinstance(args[-1], list) or 'bin_record_types' in kwargs:\n            return self.get_bin_form_for_create(*args, **kwargs)\n        else:\n            return self.get_bin_form_for_update(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_bin(self, bin_form, *args, **kwargs):\n        # Implemented from kitosid template for -\n        # osid.resource.BinAdminSession.update_bin\n        if bin_form.is_for_update():\n            return self.update_bin(bin_form, *args, **kwargs)\n        else:\n            return self.create_bin(bin_form, *args, **kwargs)", "response": "Pass through to provider BinAdminSession. update_bin"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_bin_view(self, session):\n        if self._bin_view == FEDERATED:\n            try:\n                session.use_federated_bin_view()\n            except AttributeError:\n                pass\n        else:\n            try:\n                session.use_isolated_bin_view()\n            except AttributeError:\n                pass", "response": "Sets the underlying bin view to match current view"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef use_comparative_resource_view(self):\n        self._object_views['resource'] = COMPARATIVE\n        # self._get_provider_session('resource_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_comparative_resource_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider ResourceLookupSession. use_comparative_resource_view"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npasses through to provider ResourceLookupSession. use_plenary_resource_view", "response": "def use_plenary_resource_view(self):\n        \"\"\"Pass through to provider ResourceLookupSession.use_plenary_resource_view\"\"\"\n        self._object_views['resource'] = PLENARY\n        # self._get_provider_session('resource_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_plenary_resource_view()\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npass through to provider ResourceLookupSession. use_federated_bin_view", "response": "def use_federated_bin_view(self):\n        \"\"\"Pass through to provider ResourceLookupSession.use_federated_bin_view\"\"\"\n        self._bin_view = FEDERATED\n        # self._get_provider_session('resource_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_federated_bin_view()\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef use_isolated_bin_view(self):\n        self._bin_view = ISOLATED\n        # self._get_provider_session('resource_lookup_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_isolated_bin_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider ResourceLookupSession. use_isolated_bin_view"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npassing through to provider ResourceAdminSession. get_resource_form_for_update", "response": "def get_resource_form(self, *args, **kwargs):\n        \"\"\"Pass through to provider ResourceAdminSession.get_resource_form_for_update\"\"\"\n        # Implemented from kitosid template for -\n        # osid.resource.ResourceAdminSession.get_resource_form_for_update\n        # This method might be a bit sketchy. Time will tell.\n        if isinstance(args[-1], list) or 'resource_record_types' in kwargs:\n            return self.get_resource_form_for_create(*args, **kwargs)\n        else:\n            return self.get_resource_form_for_update(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_resource(self, resource_form, *args, **kwargs):\n        # Implemented from kitosid template for -\n        # osid.resource.ResourceAdminSession.update_resource\n        if resource_form.is_for_update():\n            return self.update_resource(resource_form, *args, **kwargs)\n        else:\n            return self.create_resource(resource_form, *args, **kwargs)", "response": "Pass through to provider ResourceAdminSession. update_resource"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef use_comparative_agent_view(self):\n        self._object_views['agent'] = COMPARATIVE\n        # self._get_provider_session('resource_agent_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_comparative_agent_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider ResourceAgentSession. use_comparative_agent_view"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef use_plenary_agent_view(self):\n        self._object_views['agent'] = PLENARY\n        # self._get_provider_session('resource_agent_session') # To make sure the session is tracked\n        for session in self._get_provider_sessions():\n            try:\n                session.use_plenary_agent_view()\n            except AttributeError:\n                pass", "response": "Pass through to provider ResourceAgentSession. use_plenary_agent_view"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disk_usage(path, human=False):\n    command = ['du', '-s', path]\n    if human:\n        command.append('-h')\n\n    return subprocess.check_output(command).split()[0].decode('utf-8')", "response": "disk usage in bytes or human readable format"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _join(segments):\n    new = []\n    start = segments[0][0]\n    end = segments[0][1]\n    for i in range(len(segments)-1):\n        if segments[i+1][0] != segments[i][1]:\n            new.append((start, end))\n            start = segments[i+1][0]\n        end = segments[i+1][1]\n    new.append((start, end))\n    return new", "response": "simply list by joining adjacent segments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter messages for desired products and levels.", "response": "def _filter_messages(messages, products=None, levels=None):\n    \"\"\"filter messages for desired products and levels.\"\"\"\n    if products is None:\n        products = []\n    if levels is None:\n        levels = []\n    segments = []\n    bounds = len(messages)\n    for i, message in enumerate(messages):\n        if (message[3] in products or len(products) == 0) and \\\n                (message[4] in levels or len(levels) == 0):\n            start = int(message[1])\n            if i == (bounds - 1):\n                end = None\n            else:\n                end = int(messages[i+1][1])\n            segments.append((start, end))\n    return _join(segments)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _download_segments(filename, url, segments):\n    gribfile = open(filename, 'w')\n    for start, end in segments:\n        req = urllib2.Request(url)\n        req.add_header('User-Agent',\n                       'caelum/0.1 +https://github.com/nrcharles/caelum')\n        if end:\n            req.headers['Range'] = 'bytes=%s-%s' % (start, end)\n        else:\n            req.headers['Range'] = 'bytes=%s' % (start)\n        opener = urllib2.build_opener()\n        gribfile.write(opener.open(req).read())\n    gribfile.close()", "response": "download segments into a single file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(timestamp, dataset, path=None, products=None,\n             levels=None, offset=0):\n    \"\"\"save GFS grib file to DATA_PATH.\n\n    Args:\n        dataset(function): naming convention function.  eg. pgrb2\n        timestamp(datetime): ???\n        path(str): if None defaults to DATA_PATH\n        products(list): TMP, etc. if None downloads all.\n        layers(list): surface, etc. if None downloads all.\n        offset(int): should be multiple of 3\n    \"\"\"\n    if path is None:\n        path = DATA_PATH\n    closest = timestamp.hour//6*6\n    filename = dataset(closest, offset)\n    gfs_timestamp = '%s%02d' % (timestamp.strftime('%Y%m%d'), closest)\n\n    url = baseurl(gfs_timestamp, filename)\n    index = url + '.idx'\n    messages = message_index(index)\n    segments = _filter_messages(messages, products, levels)\n    dl_path = path + '/%s/' % gfs_timestamp\n    _verify_path(dl_path)\n    _download_segments(path + filename, url, segments)", "response": "Download a GFS grib file from the given dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef message_index(index_url):\n    idx = csv.reader(urllib2.urlopen(index_url), delimiter=':')\n    messages = []\n    for line in idx:\n        messages.append(line)\n    return messages", "response": "get message index of components for urllib2.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extend_is_dir(value, minimum=None, maximum=None):\n\n    if isinstance(value, list):\n        return [is_dir(member)\n                for member in validate.is_list(value, minimum, maximum)]\n\n    else:\n        return is_dir(value)", "response": "u Extends is_dir function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_log(value):\n\n    if value.lower() == 'syslog':\n        return 'syslog'\n\n    value = os.path.expanduser(value)\n    value = os.path.expandvars(value)\n    value = os.path.abspath(value)\n\n    log_file = 'blackbird.log'\n\n    if os.path.exists(value):\n\n        if os.path.isdir(value):\n\n            if os.access(value, os.W_OK):\n                return os.path.join(value, log_file)\n\n            else:\n                err_message = ('{path}: Permission denied.'\n                               ''.format(path=value)\n                               )\n                raise validate.VdtValueError(err_message)\n\n        else:\n\n            if os.access(value, os.W_OK):\n                return value\n\n            else:\n                err_message = ('{path}: Permission denied.'\n                               ''.format(path=value)\n                               )\n                raise validate.VdtValueError(err_message)\n\n    else:\n        directory = os.path.split(value)[0]\n\n        if os.path.isdir(directory):\n\n            if os.access(directory, os.W_OK):\n                return value\n\n            else:\n                err_message = ('{directory}: Permission denied.'\n                               ''.format(directory=directory)\n                               )\n                raise validate.VdtValueError(err_message)\n\n        else:\n\n            if os.path.exists(directory):\n                err_message = ('{directory} is file.'\n                               ''.format(directory=directory)\n                               )\n                raise validate.VdtTypeError(err_message)\n\n            else:\n                err_message = ('{directory}: No such file or directory.'\n                               ''.format(directory=directory)\n                               )\n                raise validate.VdtValueError(err_message)", "response": "This function checks whether a log file path exists and if it does not exist and if it does create it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether username or uid as argument exists.", "response": "def is_user(value, min=None, max=None):\n    \"\"\"\n    Check whether username or uid as argument exists.\n    if this function recieved username, convert uid and exec validation.\n    \"\"\"\n\n    if type(value) == str:\n        try:\n            entry = pwd.getpwnam(value)\n            value = entry.pw_uid\n        except KeyError:\n            err_message = ('{0}: No such user.'.format(value))\n            raise validate.VdtValueError(err_message)\n\n        return value\n\n    elif type(value) == int:\n        try:\n            pwd.getpwuid(value)\n        except KeyError:\n            err_message = ('{0}: No such user.'.format(value))\n            raise validate.VdtValueError(err_message)\n\n        return value\n\n    else:\n        err_message = ('Please, use str or int to \"user\" parameter.')\n        raise validate.VdtTypeError(err_message)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_group(value):\n\n    if type(value) == str:\n        try:\n            entry = grp.getgrnam(value)\n            value = entry.gr_gid\n        except KeyError:\n            err_message = ('{0}: No such group.'.format(value))\n            raise validate.VdtValueError(err_message)\n\n        return value\n\n    elif type(value) == int:\n        try:\n            grp.getgrgid(value)\n        except KeyError:\n            err_message = ('{0}: No such group.'.format(value))\n            raise validate.VdtValueError(err_message)\n\n        return value\n\n    else:\n        err_message = ('Please, use str or int to \"user\" parameter.')\n        raise validate.VdtTypeError(err_message)", "response": "Check whether groupname or gid as argument exists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_global_include_abs_path(self, path):\n        if not os.path.isabs(path):\n            path = os.path.abspath(path)\n\n        if os.path.isdir(path) or path.endswith('/'):\n            path = os.path.join(path, '*')\n\n        return path", "response": "Get a value after converting to absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_global_include(self, path):\n        if not path.endswith('/'):\n            path = os.path.dirname(path)\n\n        if os.path.exists(path):\n            if not os.access(path, os.R_OK):\n                raise blackbird.utils.error.BlackbirdError(\n                    message=(\n                        '{0}: Permission denied.'\n                        ''.format(path)\n                    )\n                )\n\n        else:\n            raise blackbird.utils.error.BlackbirdError(\n                message=(\n                    '{0}: No such file or directory.'\n                    ''.format(path)\n                )\n            )\n\n        return True", "response": "This method checks if given path passes global include validation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _merge_includes(self):\n        raw_include_path = self.get_global_include()\n        if raw_include_path:\n            abs_include_path = self._get_global_include_abs_path(\n                raw_include_path\n            )\n            self._validate_global_include(abs_include_path)\n            self.set_global_include(abs_include_path)\n\n            for infile in glob.glob(abs_include_path):\n                self.config.merge(\n                    self._configobj_factory(infile=infile)\n                )", "response": "Merge include files into the current config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, observers):\n\n        if isinstance(observers, list) or isinstance(observers, tuple):\n\n            for observer in observers:\n                # check whether inhelitance \"base.Observer\"\n                if isinstance(observer, base.Observer):\n                    self._observers.append(observer)\n\n                else:\n                    raise InhelitanceError(base.Observer.__name__)\n\n        elif isinstance(observers, base.Observer):\n            self._observers.append(observers)", "response": "Registers observers as an argument to self. observers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unregister(self, observers):\n\n        if isinstance(observers, list) or isinstance(observers, tuple):\n            for observer in observers:\n                try:\n                    index = self._observers.index(observer)\n                    self._observers.remove(self._observers[index])\n                except ValueError:\n                    # logging\n                    print('{observer} not in list...'.format(observer))\n\n        elif isinstance(observers, base.Observer):\n            try:\n                index = self._observers.index(observers)\n                self._observers.remove(self._observers[index])\n            except ValueError:\n                # logging\n                print('{observer} not in list...'.format(observers))\n\n        else:\n            err_message = ('ConfigReader.register support'\n                           'ListType, TupleType and {observer} Object.'\n                           ''.format(base.Observer.__name__)\n                           )\n\n            raise ValueError(err_message)", "response": "u Unregister observers from the Subject."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnotify about a new job", "response": "def notify(self, name, job):\n        \"\"\"\n        Concrete method of Subject.notify().\n        Notify to change the status of Subject for observer.\n        This method call Observer.update().\n        In this program, ConfigReader.notify() call JobObserver.update().\n        For exmaple, register threads.redis.ConcreateJob to JobObserver.jobs.\n        \"\"\"\n        for observer in self._observers:\n            observer.update(name, job)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_default_module_dir(self):\n        default_module_dir = os.path.join(\n            os.path.abspath(os.path.curdir),\n            'plugins'\n        )\n        module_dir_params = {\n            'module_dir': [default_module_dir]\n        }\n\n        if 'module_dir' in self.config['global']:\n            module_dir_params['module_dir'].append(\n                self.config['global']['module_dir']\n            )\n        self.config['global'].update(\n            module_dir_params\n        )", "response": "Adds default module_dir to the global config parameter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef global_validate(self):\n\n        raw_spec = (\n            \"[global]\",\n            \"user = user(default=bbd)\",\n            \"group = group(default=bbd)\",\n            \"log_file = log(default=/var/log/blackbird/blackbird.log)\",\n            \"log_level = log_level(default='info')\",\n            \"log_format = log_format(default='ltsv')\",\n            \"max_queue_length = integer(default=32767)\",\n            \"lld_interval = integer(default=600)\",\n            \"interval = integer(default=60)\"\n        )\n\n        functions = {\n            'user': is_user,\n            'group': is_group,\n            'dir': extend_is_dir,\n            'log': is_log,\n            'log_level': is_log_level,\n            'log_format': is_log_format\n        }\n\n        validator = validate.Validator(functions=functions)\n        spec = self._configobj_factory(infile=raw_spec,\n                                       _inspec=True\n                                       )\n        self.config.configspec = spec\n        result = self.config.validate(validator, preserve_errors=True)\n        self._parse_result(result)\n\n        self.config['global'].configspec = None", "response": "Validate only global section."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all modules under the self. _module_dirs directories.", "response": "def _get_modules(self):\n        \"\"\"\n        Get modules under the self.config['global']['module_dirs'] directories.\n        Plugin modules has the two classes of \"ConcreteJob\" and \"Validator\".\n        Further, \"Validator.module\" property is used to\n        deciding which one to use plugin module.\n\n        This method returns a dictionary as following:\n        modules = {\n            'redis': <module 'MODULE_NAME' from 'REAL_FILE_NAME'>,\n            'memcached': <module 'MODULE_NAME' from 'REAL_FILE_NAME'>\n            ...\n        }\n\n        At here,\n        collect all plugin modules under the self._module_dirs directories.\n        Plugins that were collected by this method is used\n        in ConfigReader._register_jobs() and ConfigReader._get_raw_specs().\n        \"\"\"\n\n        not_import = set()\n        not_import.add('base')\n        modules = {}\n\n        for path in self.config['global']['module_dir']:\n            sys.path.insert(0, path)\n            iter_modules = pkgutil.iter_modules([path])\n\n            for module_info in iter_modules:\n                module_name = module_info[1]\n\n                if module_name in not_import:\n                    continue\n\n                if helpers.helper_import(module_name, 'Validator'):\n                    module = helpers.helper_import(module_name)\n                    modules[module.__name__] = module\n\n            sys.path.remove(path)\n\n        return modules"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_raw_specs(self, config):\n\n        # spec_name is hard-corded\n        raw_specs = {}\n        spec_name = 'Validator'\n        modules = self._get_modules()\n\n        for section, options in config.items():\n\n            if section == 'global':\n                continue\n\n            try:\n                name = options['module']\n            except KeyError:\n                raise ConfigMissingValue(section, 'module')\n\n            try:\n                spec = getattr(modules[name], spec_name)().spec\n                raw_specs[name] = spec\n            except KeyError:\n                raise NotSupportedError(name)\n\n        return raw_specs", "response": "This method extracts only the Validate. spec from modules that were collected by ConfigReader. _get_modules and appends it to the raw_specs dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_specs(self):\n\n        raw_specs = self._get_raw_specs(self.config)\n        spec = self._configobj_factory(infile=None,\n                                       _inspec=True\n                                       )\n\n        for section, options in self.config.items():\n\n            if section == 'global':\n                continue\n\n            if 'module' in options:\n                module = options['module']\n            else:\n                raise ConfigMissingValue(section, 'module')\n\n            spec.merge(self._configspec_factory(section=section,\n                                                module=module,\n                                                infile=raw_specs[module]\n                                                )\n                       )\n\n        return spec", "response": "Create configspec instances based on the config."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _configspec_factory(self, section, module, infile):\n\n        configspec = self._configobj_factory(\n            infile=infile,\n            _inspec=True\n        )\n\n        # Override the name of section in spec file\n        # by given module as argument.\n        configspec.rename(module, section)\n\n        return configspec", "response": "This method creates a new conf. cfg. cfg instance and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self):\n\n        spec = self._create_specs()\n\n        # support in future\n        functions = {}\n\n        validator = validate.Validator(functions=functions)\n\n        self.config.configspec = spec\n        result = self.config.validate(validator, preserve_errors=True)\n\n        if self._parse_result(result):\n            return True", "response": "validate whether value in config file is correct."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse the valid input file to get the header information.", "response": "def main(args):\n  of = sys.stdout\n  if args.output and args.output[-4:] == '.bam':\n    cmd = 'samtools view -Sb - -o '+args.output\n    pof = Popen(cmd.split(),stdin=PIPE)\n    of = pof.stdin\n  elif args.output:\n    of = open(args.output,'w')\n  \"\"\"Use the valid input file to get the header information.\"\"\"\n\n  header = None\n  if args.HQ:\n    cmd = 'samtools view -H '+args.HQ\n    sys.stderr.write(cmd+\"\\n\")\n    header = Popen(cmd.split(),stdout=PIPE).communicate()[0]\n    of.write(header)\n  if (not header) and args.HQCorrected:\n    cmd = 'samtools view -H '+args.HQCorrected\n    sys.stderr.write(cmd+\"\\n\")\n    header = Popen(cmd.split(),stdout=PIPE).communicate()[0]\n    of.write(header)\n  if (not header) and args.AQ:\n    cmd = 'samtools view -H '+args.AQ\n    sys.stderr.write(cmd+\"\\n\")\n    header = Popen(cmd.split(),stdout=PIPE).communicate()[0]\n    of.write(header)\n  if (not header) and args.AQCorrected:\n    cmd = 'samtools view -H '+args.AQCorrected\n    sys.stderr.write(cmd+\"\\n\")\n    header = Popen(cmd.split(),stdout=PIPE).communicate()[0]\n    of.write(header)\n  if (not header) and args.subreads:\n    cmd = 'samtools view -H '+args.subreads\n    sys.stderr.write(cmd+\"\\n\")\n    header = Popen(cmd.split(),stdout=PIPE).communicate()[0]\n    of.write(header)\n  if (not header) and args.subreadsCorrected:\n    cmd = 'samtools view -H '+args.subreadsCorrected\n    sys.stderr.write(cmd+\"\\n\")\n    header = Popen(cmd.split(),stdout=PIPE).communicate()[0]\n    of.write(header)\n\n  _nameprog = re.compile('^(\\S+)')\n  negative_filter = set() # remove these\n  \"\"\" Next read throught he alignments THAT ALIGNED in order of priority\"\"\"\n  negative_filter = get_best_set(negative_filter,'-F 4',of,args,True)\n  \"\"\"After traversing all the aligned reads we can do it all over again\n     this time with the unaligned portion of reads\"\"\"\n\n  \"\"\" Finally go through the reads that did NOT ALIGN to get anything left\"\"\"\n  get_best_set(negative_filter,'-f 4',of,args,False)\n  if args.output and args.output[-4:] == '.bam':\n    pof.communicate()\n  else:\n    of.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _do_subread_set(flag,input_file,of,negative_filter,aligned):\n    best = {}\n    cmd = 'samtools view '+flag+' '+input_file\n    sys.stderr.write(cmd+\"\\n\")\n    p = Popen(cmd.split(),stdout=PIPE)\n    z = 0\n    for line in p.stdout:\n      z += 1\n      if z%10000==0: sys.stderr.write(str(z) + \" subread alignment paths scanned for alignment length\\r\")\n      pbname = PacBioReadName(_nameprog.match(line).group(1))\n      mol = pbname.get_molecule()\n      if mol in negative_filter: continue\n      name = pbname.name()\n      sam = SAM(line)\n      c = 0 # aligned base count if we are aligned, subread length if we are not aligned\n      if aligned:\n        c = sam.get_aligned_bases_count()\n      else:\n        c = sam.get_query_length()\n      if mol not in best:\n        best[mol] = [name,c]\n      if c > best[mol][1]: best[mol] = [name,c]\n    p.communicate()\n    sys.stderr.write(\"\\n\")\n    sys.stderr.write(\"Finished analyzing subread lengths\\nWriting aligned subreads\\n\")\n    \"\"\"After getting all the best alignment counts we can traverse again\n       to keep the best\"\"\"\n    cmd = 'samtools view '+flag+' '+input_file\n    sys.stderr.write(cmd+\"\\n\")\n    z = 0\n    p = Popen(cmd.split(),stdout=PIPE)\n    for line in p.stdout:\n      z += 1\n      if z%10000==0: sys.stderr.write(str(z) + \" subreads alignment paths scanned during selected for best\\r\")\n      pbname = PacBioReadName(_nameprog.match(line).group(1))\n      mol = pbname.get_molecule()\n      name = pbname.name()\n      if mol in negative_filter: continue\n      if not best[mol][0] == name: continue\n      of.write(line)\n    p.communicate()\n    for mol in best: negative_filter.add(mol)\n    sys.stderr.write(\"\\n\")\n    sys.stderr.write(\"molecules written: \"+str(len(negative_filter))+\"\\n\")\n    return negative_filter", "response": "This function will traverse the samtools view command and return the best alignment counts for the subreads that are not in the list of subreads that are in the list of negative_filter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _traverse_unobserved(stream,negative_filter,of):\n  observed = set()\n  for line in stream:\n    name = PacBioReadName(_nameprog.match(line).group(1))\n    if name.get_molecule() not in negative_filter: of.write(line)\n    observed.add(name.get_molecule())\n  return negative_filter|observed", "response": "Traverse a stream and print out anything not in observed set"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the custom tasks and record the associated image with each task", "response": "def find_tasks(self, overrides):\n        \"\"\"Find the custom tasks and record the associated image with each task\"\"\"\n        tasks = self.default_tasks()\n        configuration = self.collector.configuration\n\n        for image in list(configuration[\"images\"].keys()):\n            path = configuration.path([\"images\", image, \"tasks\"], joined=\"images.{0}.tasks\".format(image))\n            nxt = configuration.get(path, {})\n            tasks.update(nxt)\n\n        if overrides:\n            tasks.update(overrides)\n\n        self.tasks = tasks\n        return tasks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a string into a datetime object", "response": "def strptime(string, timezone=0):\n    \"\"\"necessary because of 24:00 end of day labeling\"\"\"\n    year = int(string[0:4])\n    month = int(string[5:7])\n    day = int(string[8:10])\n    hour = int(string[-5:-3])\n    minute = int(string[-2:])\n    ts = datetime.datetime(year, month, day) + \\\n        datetime.timedelta(hours=hour, minutes=minute) - \\\n        datetime.timedelta(hours=timezone)\n    return ts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates report for a USAF base", "response": "def report(usaf):\n    \"\"\"generate report for usaf base\"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    station_info = geo.station_info(usaf)\n    y = {}\n    for i in range(1991, 2011):\n        monthData = monthly(usaf, i)\n        t = sum(monthData)\n        y[i] = t\n        print t\n    tmy3tot = tmy3.total(usaf)\n    average = sum([v for k, v in y.items()])/20.\n    s = sorted(y.items(), key=lambda t: t[1])\n    o = sorted(y.items(), key=lambda t: t[0])\n    twohigh = s[-1][1] + s[-2][1]\n    twolow = s[0][1] + s[1][1]\n    mintol = 1-twolow/2./average\n    plustol = twohigh/2./average-1\n    txt = \"\"\n    txt += \"%s\\n\" % station_info['Site Name']\n    txt += 'TMY3/hist: %s/' % int(round(tmy3tot))\n    txt += '%s\\n' % int(round(average))\n    txt += \"high/low av: %s/\" % int(round(twohigh/2.))\n    txt += \"%s\\n\" % int(round(twolow/2.))\n    txt += \"+%s/-%s%% \" % (round(plustol*100, 0), round(mintol*100, 0))\n    txt += \"(-%s%% of TMY3)\" % round((1-twolow/2./tmy3tot)*100, 0)\n    print txt\n    x = np.array([k for k, v in o])\n    y = np.array([v for k, v in o])\n\n    rx = x[1:]\n    ry = [(v + y[i+1])/2 for i, v in enumerate(y[:-1])]\n    fit = pylab.polyfit(x, y, 3)\n    fit_fn = pylab.poly1d(fit)\n    f = interp1d(x, y, kind='cubic')\n    f2 = interp1d(rx, ry, kind='cubic')\n    xnew = np.linspace(min(x), max(x), 200)\n    x2 = np.linspace(min(rx), max(rx), 200)\n    # ax.plot(x,y)\n    ax.plot(xnew, f(xnew), label=\"Annual GHI\")\n    ax.plot(xnew, fit_fn(xnew), label='trendline')\n    ax.plot(x2, f2(x2), label='2 Year Ave')\n    ax.plot([min(x), max(x)], [tmy3tot, tmy3tot], linestyle='--')\n    leg = plt.legend(title=txt, loc=4, fancybox=True)\n    leg.get_frame().set_alpha(0.5)\n    # fig.text(min(x),min(y)-min(y)*.1,txt)\n    # fig.text(.1,.1,txt)\n    plt.tight_layout()\n    fig.savefig('%s_annual_GHI.pdf' % (usaf), format='pdf')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_proxy(self, input):\n        from ..authentication_process.objects import Authentication\n        agent_id = input.user.username\n        host = settings.HOST\n        url_path = ('/handcar/services/authentication/agentkeys/' + agent_id +\n                    '?proxyname=' + settings.APP_KEYS[host.lower()])\n        authentication = Authentication(agent_id, self._get_request(url_path))\n\n        return rules.Proxy(authentication=authentication)", "response": "Gets a proxy.\n\n        :param input: a proxy condition\n        :type input: ``osid.proxy.ProxyCondition``\n        :return: a proxy\n        :rtype: ``osid.proxy.Proxy``\n        :raise: ``NullArgument`` -- ``input`` is ``null``\n        :raise: ``OperationFailed`` -- unable to complete request\n        :raise: ``PermissionDenied`` -- authorization failure\n        :raise: ``Unsupported`` -- ``input`` is not of this service\n\n        *compliance: mandatory -- This method is must be implemented.*"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_file(abspath, text):\n    try:\n        with open(abspath, \"wb\") as f:\n            f.write(text.encode(\"utf-8\"))\n        print(\"Made: %s\" % abspath)\n    except:  # pragma: no cover\n        pass", "response": "Make a file with utf - 8 text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _calculate_hash(self, filename, **kwargs):\n        with open(filename, 'rb') as f:\n            file_hash = hashlib.md5(f.read()).hexdigest()\n\n        if kwargs:\n            data = str(\n                [urepr(kwargs[k]) for k in sorted(kwargs)] + [file_hash])\n        else:\n            data = file_hash\n\n        address_piece_with_metadata = str(\n            bin_to_b58check(bin_hash160(data.encode()),\n                            magicbyte=self._magicbyte)\n        )\n        address_piece = str(bin_to_b58check(bin_hash160(file_hash.encode()),\n                                            magicbyte=self._magicbyte))\n        return address_piece, address_piece_with_metadata", "response": "Calculates the hash of the file and the hash of the file + metadata\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match_created_date(self, start, end, match):\n        self._match_minimum_date_time('createdDate', start, match)\n        self._match_maximum_date_time('createdDate', end, match)", "response": "Match assets that are created between the specified time period."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_published_date(self, start, end, match):\n        self._match_minimum_date_time('publishedDate', start, match)\n        self._match_maximum_date_time('publishedDate', end, match)", "response": "Match assets that are published between the specified time period."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef throttled_login(request):\n    \"Displays the login form and handles the login action.\"\n    # if the user is already logged-in, simply redirect them to the entry page\n    if request.user.is_authenticated():\n        return HttpResponseRedirect(settings.LOGIN_REDIRECT_URL)\n\n    login_allowed = request.session.get('login_allowed', True)\n\n    if request.method == 'POST':\n        # If the session has already been flagged to not allow login attempts,\n        # then simply redirect back to the login page.\n        if not login_allowed:\n            return HttpResponseRedirect(settings.LOGIN_URL)\n\n        login_allowed = throttle_login(request)\n\n    if login_allowed:\n        response = login(request, authentication_form=EmailAuthenticationForm)\n        # GHETTO: we know if the response is a redirect, the login\n        # was successful, thus we can clear the throttled login counter\n        if isinstance(response, HttpResponseRedirect):\n            clear_throttled_login(request)\n        return response\n\n    return render_to_response('registration/login.html', {\n        'login_not_allowed': not login_allowed\n    }, context_instance=RequestContext(request))", "response": "Displays the login form and handles the login action."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the Comment specified by its Id.", "response": "def get_comment(self, comment_id):\n        \"\"\"Gets the ``Comment`` specified by its ``Id``.\n\n        arg:    comment_id (osid.id.Id): the ``Id`` of the ``Comment``\n                to retrieve\n        return: (osid.commenting.Comment) - the returned ``Comment``\n        raise:  NotFound - no ``Comment`` found with the given ``Id``\n        raise:  NullArgument - ``comment_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceLookupSession.get_resource\n        # NOTE: This implementation currently ignores plenary view\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        result = collection.find_one(\n            dict({'_id': ObjectId(self._get_id(comment_id, 'commenting').get_identifier())},\n                 **self._view_filter()))\n        return objects.Comment(osid_object_map=result, runtime=self._runtime, proxy=self._proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a CommentList corresponding to the given IdList.", "response": "def get_comments_by_ids(self, comment_ids):\n        \"\"\"Gets a ``CommentList`` corresponding to the given ``IdList``.\n\n        arg:    comment_ids (osid.id.IdList): the list of ``Ids`` to\n                retrieve\n        return: (osid.commenting.CommentList) - the returned ``Comment\n                list``\n        raise:  NotFound - an ``Id was`` not found\n        raise:  NullArgument - ``comment_ids`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceLookupSession.get_resources_by_ids\n        # NOTE: This implementation currently ignores plenary view\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        object_id_list = []\n        for i in comment_ids:\n            object_id_list.append(ObjectId(self._get_id(i, 'commenting').get_identifier()))\n        result = collection.find(\n            dict({'_id': {'$in': object_id_list}},\n                 **self._view_filter()))\n        result = list(result)\n        sorted_result = []\n        for object_id in object_id_list:\n            for object_map in result:\n                if object_map['_id'] == object_id:\n                    sorted_result.append(object_map)\n                    break\n        return objects.CommentList(sorted_result, runtime=self._runtime, proxy=self._proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a CommentList corresponding to the given comment genus Type which does not include comments of genus types derived from the specified Type.", "response": "def get_comments_by_genus_type(self, comment_genus_type):\n        \"\"\"Gets a ``CommentList`` corresponding to the given comment genus ``Type`` which does not include comments of genus types derived from the specified ``Type``.\n\n        arg:    comment_genus_type (osid.type.Type): a comment genus\n                type\n        return: (osid.commenting.CommentList) - the returned ``Comment``\n                list\n        raise:  NullArgument - ``comment_genus_type`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceLookupSession.get_resources_by_genus_type\n        # NOTE: This implementation currently ignores plenary view\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        result = collection.find(\n            dict({'genusTypeId': str(comment_genus_type)},\n                 **self._view_filter())).sort('_id', DESCENDING)\n        return objects.CommentList(result, runtime=self._runtime, proxy=self._proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of all comments effective during the entire given date range inclusive but not confined to the date range.", "response": "def get_comments_on_date(self, from_, to):\n        \"\"\"Gets a ``CommentList`` effective during the entire given date range inclusive but not confined to the date range.\n\n        arg:    from (osid.calendaring.DateTime): starting date\n        arg:    to (osid.calendaring.DateTime): ending date\n        return: (osid.commenting.CommentList) - the returned ``Comment``\n                list\n        raise:  InvalidArgument - ``from`` is greater than ``to``\n        raise:  NullArgument - ``from`` or ``to`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.relationship.RelationshipLookupSession.get_relationships_on_date\n        comment_list = []\n        for comment in self.get_comments():\n            if overlap(from_, to, comment.start_date, comment.end_date):\n                comment_list.append(comment)\n        return objects.CommentList(comment_list, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_comments_for_commentor_on_date(self, resource_id, from_, to):\n        # Implemented from template for\n        # osid.relationship.RelationshipLookupSession.get_relationships_for_destination_on_date\n        comment_list = []\n        for comment in self.get_comments_for_commentor():\n            if overlap(from_, to, comment.start_date, comment.end_date):\n                comment_list.append(comment)\n        return objects.CommentList(comment_list, runtime=self._runtime)", "response": "Gets a list of all comments corresponding to a resource Id and effective during the entire given date range inclusive but not confined to the date range."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of all comments corresponding to a reference Id and effective during the entire given date range inclusive but not confined to the date range.", "response": "def get_comments_for_reference_on_date(self, reference_id, from_, to):\n        \"\"\"Gets a list of all comments corresponding to a reference ``Id`` and effective during the entire given date range inclusive but not confined to the date range.\n\n        arg:    reference_id (osid.id.Id): a reference ``Id``\n        arg:    from (osid.calendaring.DateTime): from date\n        arg:    to (osid.calendaring.DateTime): to date\n        return: (osid.commenting.CommentList) - the returned\n                ``CommentList``\n        raise:  InvalidArgument - ``to`` is less than ``from``\n        raise:  NullArgument - ``reference_id, from,`` or ``to`` is\n                ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.relationship.RelationshipLookupSession.get_relationships_for_source_on_date\n        comment_list = []\n        for comment in self.get_comments_for_reference(reference_id):\n            if overlap(from_, to, comment.start_date, comment.end_date):\n                comment_list.append(comment)\n        return objects.CommentList(comment_list, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_comments_by_genus_type_for_reference_on_date(self, reference_id, comment_genus_type, from_, to):\n        # Implemented from template for\n        # osid.relationship.RelationshipLookupSession.get_relationships_by_genus_type_for_source_on_date\n        comment_list = []\n        for comment in self.get_comments_by_genus_type_for_reference():\n            if overlap(from_, to, comment.start_date, comment.end_date):\n                comment_list.append(comment)\n        return objects.CommentList(comment_list, runtime=self._runtime)", "response": "Gets a list of all comments of the given genus type corresponding to a reference Id and effective during the entire given date range inclusive but not confined to the date range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of comments corresponding to a resource and reference Id.", "response": "def get_comments_for_commentor_and_reference(self, resource_id, reference_id):\n        \"\"\"Gets a list of comments corresponding to a resource and reference ``Id``.\n\n        arg:    resource_id (osid.id.Id): the ``Id`` of the resource\n        arg:    reference_id (osid.id.Id): the ``Id`` of the reference\n        return: (osid.commenting.CommentList) - the returned\n                ``CommentList``\n        raise:  NullArgument - ``resource_id`` or ``reference_id`` is\n                ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.relationship.RelationshipLookupSession.get_relationships_for_peers\n        # NOTE: This implementation currently ignores plenary and effective views\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        result = collection.find(\n            dict({'referenceId': str(resource_id),\n                  'commentorId': str(reference_id)},\n                 **self._view_filter())).sort('_id', ASCENDING)\n        return objects.CommentList(result, runtime=self._runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_comments(self):\n        # Implemented from template for\n        # osid.resource.ResourceLookupSession.get_resources\n        # NOTE: This implementation currently ignores plenary view\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        result = collection.find(self._view_filter()).sort('_id', DESCENDING)\n        return objects.CommentList(result, runtime=self._runtime, proxy=self._proxy)", "response": "Gets all comments in the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_comments_by_query(self, comment_query):\n        # Implemented from template for\n        # osid.resource.ResourceQuerySession.get_resources_by_query\n        and_list = list()\n        or_list = list()\n        for term in comment_query._query_terms:\n            if '$in' in comment_query._query_terms[term] and '$nin' in comment_query._query_terms[term]:\n                and_list.append(\n                    {'$or': [{term: {'$in': comment_query._query_terms[term]['$in']}},\n                             {term: {'$nin': comment_query._query_terms[term]['$nin']}}]})\n            else:\n                and_list.append({term: comment_query._query_terms[term]})\n        for term in comment_query._keyword_terms:\n            or_list.append({term: comment_query._keyword_terms[term]})\n        if or_list:\n            and_list.append({'$or': or_list})\n        view_filter = self._view_filter()\n        if view_filter:\n            and_list.append(view_filter)\n        if and_list:\n            query_terms = {'$and': and_list}\n            collection = JSONClientValidated('commenting',\n                                             collection='Comment',\n                                             runtime=self._runtime)\n            result = collection.find(query_terms).sort('_id', DESCENDING)\n        else:\n            result = []\n        return objects.CommentList(result, runtime=self._runtime, proxy=self._proxy)", "response": "Gets a list of comments matching the given search."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the comment form for creating new comments.", "response": "def get_comment_form_for_create(self, reference_id, comment_record_types):\n        \"\"\"Gets the comment form for creating new comments.\n\n        A new form should be requested for each create transaction.\n\n        arg:    reference_id (osid.id.Id): the ``Id`` for the reference\n                object\n        arg:    comment_record_types (osid.type.Type[]): array of\n                comment record types\n        return: (osid.commenting.CommentForm) - the comment form\n        raise:  NullArgument - ``reference_id or comment_record_types``\n                is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        raise:  Unsupported - unable to get form for requested record\n                types\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.relationship.CommentAdminSession.get_comment_form_for_create_template\n        # These really need to be in module imports:\n        if not isinstance(reference_id, ABCId):\n            raise errors.InvalidArgument('argument is not a valid OSID Id')\n        for arg in comment_record_types:\n            if not isinstance(arg, ABCType):\n                raise errors.InvalidArgument('one or more argument array elements is not a valid OSID Type')\n        if comment_record_types == []:\n            # WHY are we passing book_id = self._catalog_id below, seems redundant:\n            # Probably don't need to send effective_agent_id, since the form can get that from proxy.\n            obj_form = objects.CommentForm(\n                book_id=self._catalog_id,\n                reference_id=reference_id,\n                effective_agent_id=str(self.get_effective_agent_id()),\n                catalog_id=self._catalog_id,\n                runtime=self._runtime,\n                proxy=self._proxy)\n        else:\n            obj_form = objects.CommentForm(\n                book_id=self._catalog_id,\n                record_types=comment_record_types,\n                reference_id=reference_id,\n                effective_agent_id=self.get_effective_agent_id(),\n                catalog_id=self._catalog_id,\n                runtime=self._runtime,\n                proxy=self._proxy)\n        obj_form._for_update = False\n        self._forms[obj_form.get_id().get_identifier()] = not CREATED\n        return obj_form"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_comment(self, comment_form):\n        # Implemented from template for\n        # osid.resource.ResourceAdminSession.create_resource_template\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        if not isinstance(comment_form, ABCCommentForm):\n            raise errors.InvalidArgument('argument type is not an CommentForm')\n        if comment_form.is_for_update():\n            raise errors.InvalidArgument('the CommentForm is for update only, not create')\n        try:\n            if self._forms[comment_form.get_id().get_identifier()] == CREATED:\n                raise errors.IllegalState('comment_form already used in a create transaction')\n        except KeyError:\n            raise errors.Unsupported('comment_form did not originate from this session')\n        if not comment_form.is_valid():\n            raise errors.InvalidArgument('one or more of the form elements is invalid')\n        insert_result = collection.insert_one(comment_form._my_map)\n\n        self._forms[comment_form.get_id().get_identifier()] = CREATED\n        result = objects.Comment(\n            osid_object_map=collection.find_one({'_id': insert_result.inserted_id}),\n            runtime=self._runtime,\n            proxy=self._proxy)\n\n        return result", "response": "Creates a new Comment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_comment(self, comment_form):\n        # Implemented from template for\n        # osid.resource.ResourceAdminSession.update_resource_template\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        if not isinstance(comment_form, ABCCommentForm):\n            raise errors.InvalidArgument('argument type is not an CommentForm')\n        if not comment_form.is_for_update():\n            raise errors.InvalidArgument('the CommentForm is for update only, not create')\n        try:\n            if self._forms[comment_form.get_id().get_identifier()] == UPDATED:\n                raise errors.IllegalState('comment_form already used in an update transaction')\n        except KeyError:\n            raise errors.Unsupported('comment_form did not originate from this session')\n        if not comment_form.is_valid():\n            raise errors.InvalidArgument('one or more of the form elements is invalid')\n        collection.save(comment_form._my_map)\n\n        self._forms[comment_form.get_id().get_identifier()] = UPDATED\n\n        # Note: this is out of spec. The OSIDs don't require an object to be returned:\n        return objects.Comment(\n            osid_object_map=comment_form._my_map,\n            runtime=self._runtime,\n            proxy=self._proxy)", "response": "Updates an existing comment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_comment(self, comment_id):\n        # Implemented from template for\n        # osid.resource.ResourceAdminSession.delete_resource_template\n        collection = JSONClientValidated('commenting',\n                                         collection='Comment',\n                                         runtime=self._runtime)\n        if not isinstance(comment_id, ABCId):\n            raise errors.InvalidArgument('the argument is not a valid OSID Id')\n        comment_map = collection.find_one(\n            dict({'_id': ObjectId(comment_id.get_identifier())},\n                 **self._view_filter()))\n\n        objects.Comment(osid_object_map=comment_map, runtime=self._runtime, proxy=self._proxy)._delete()\n        collection.delete_one({'_id': ObjectId(comment_id.get_identifier())})", "response": "Deletes a ``Comment``.\n\n        arg:    comment_id (osid.id.Id): the ``Id`` of the ``Comment``\n                to remove\n        raise:  NotFound - ``comment_id`` not found\n        raise:  NullArgument - ``comment_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an Id to a Comment for the purpose of creating compatibility.", "response": "def alias_comment(self, comment_id, alias_id):\n        \"\"\"Adds an ``Id`` to a ``Comment`` for the purpose of creating compatibility.\n\n        The primary ``Id`` of the ``Comment`` is determined by the\n        provider. The new ``Id`` performs as an alias to the primary\n        ``Id``. If the alias is a pointer to another comment, it is\n        reassigned to the given comment ``Id``.\n\n        arg:    comment_id (osid.id.Id): the ``Id`` of a ``Comment``\n        arg:    alias_id (osid.id.Id): the alias ``Id``\n        raise:  AlreadyExists - ``alias_id`` is already assigned\n        raise:  NotFound - ``comment_id`` not found\n        raise:  NullArgument - ``comment_id`` or ``alias_id`` is\n                ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceAdminSession.alias_resources_template\n        self._alias_id(primary_id=comment_id, equivalent_id=alias_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_comment_ids_by_book(self, book_id):\n        # Implemented from template for\n        # osid.resource.ResourceBinSession.get_resource_ids_by_bin\n        id_list = []\n        for comment in self.get_comments_by_book(book_id):\n            id_list.append(comment.get_id())\n        return IdList(id_list)", "response": "Gets the list of Comment Ids associated with a Book."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_comments_by_book(self, book_id):\n        # Implemented from template for\n        # osid.resource.ResourceBinSession.get_resources_by_bin\n        mgr = self._get_provider_manager('COMMENTING', local=True)\n        lookup_session = mgr.get_comment_lookup_session_for_book(book_id, proxy=self._proxy)\n        lookup_session.use_isolated_book_view()\n        return lookup_session.get_comments()", "response": "Gets the list of Comments associated with a Book."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of Comment Ids corresponding to a list of Book objects.", "response": "def get_comment_ids_by_books(self, book_ids):\n        \"\"\"Gets the list of ``Comment Ids`` corresponding to a list of ``Book`` objects.\n\n        arg:    book_ids (osid.id.IdList): list of book ``Ids``\n        return: (osid.id.IdList) - list of comment ``Ids``\n        raise:  NullArgument - ``book_ids`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceBinSession.get_resource_ids_by_bins\n        id_list = []\n        for comment in self.get_comments_by_books(book_ids):\n            id_list.append(comment.get_id())\n        return IdList(id_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_comments_by_books(self, book_ids):\n        # Implemented from template for\n        # osid.resource.ResourceBinSession.get_resources_by_bins\n        comment_list = []\n        for book_id in book_ids:\n            comment_list += list(\n                self.get_comments_by_book(book_id))\n        return objects.CommentList(comment_list)", "response": "Gets the list of Comments corresponding to a list of Books."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of Book Ids mapped to a Comment.", "response": "def get_book_ids_by_comment(self, comment_id):\n        \"\"\"Gets the list of ``Book``  ``Ids`` mapped to a ``Comment``.\n\n        arg:    comment_id (osid.id.Id): ``Id`` of a ``Comment``\n        return: (osid.id.IdList) - list of book ``Ids``\n        raise:  NotFound - ``comment_id`` is not found\n        raise:  NullArgument - ``comment_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceBinSession.get_bin_ids_by_resource\n        mgr = self._get_provider_manager('COMMENTING', local=True)\n        lookup_session = mgr.get_comment_lookup_session(proxy=self._proxy)\n        lookup_session.use_federated_book_view()\n        comment = lookup_session.get_comment(comment_id)\n        id_list = []\n        for idstr in comment._my_map['assignedBookIds']:\n            id_list.append(Id(idstr))\n        return IdList(id_list)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of Books mapped to a Comment.", "response": "def get_books_by_comment(self, comment_id):\n        \"\"\"Gets the list of ``Book`` objects mapped to a ``Comment``.\n\n        arg:    comment_id (osid.id.Id): ``Id`` of a ``Comment``\n        return: (osid.commenting.BookList) - list of books\n        raise:  NotFound - ``comment_id`` is not found\n        raise:  NullArgument - ``comment_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceBinSession.get_bins_by_resource\n        mgr = self._get_provider_manager('COMMENTING', local=True)\n        lookup_session = mgr.get_book_lookup_session(proxy=self._proxy)\n        return lookup_session.get_books_by_ids(\n            self.get_book_ids_by_comment(comment_id))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of books including and under the given book node in which any comment can be assigned.", "response": "def get_assignable_book_ids(self, book_id):\n        \"\"\"Gets a list of books including and under the given book node in which any comment can be assigned.\n\n        arg:    book_id (osid.id.Id): the ``Id`` of the ``Book``\n        return: (osid.id.IdList) - list of assignable book ``Ids``\n        raise:  NullArgument - ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceBinAssignmentSession.get_assignable_bin_ids\n        # This will likely be overridden by an authorization adapter\n        mgr = self._get_provider_manager('COMMENTING', local=True)\n        lookup_session = mgr.get_book_lookup_session(proxy=self._proxy)\n        books = lookup_session.get_books()\n        id_list = []\n        for book in books:\n            id_list.append(book.get_id())\n        return IdList(id_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_comment_to_book(self, comment_id, book_id):\n        # Implemented from template for\n        # osid.resource.ResourceBinAssignmentSession.assign_resource_to_bin\n        mgr = self._get_provider_manager('COMMENTING', local=True)\n        lookup_session = mgr.get_book_lookup_session(proxy=self._proxy)\n        lookup_session.get_book(book_id)  # to raise NotFound\n        self._assign_object_to_catalog(comment_id, book_id)", "response": "Adds an existing Comment to a Book."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unassign_comment_from_book(self, comment_id, book_id):\n        # Implemented from template for\n        # osid.resource.ResourceBinAssignmentSession.unassign_resource_from_bin\n        mgr = self._get_provider_manager('COMMENTING', local=True)\n        lookup_session = mgr.get_book_lookup_session(proxy=self._proxy)\n        lookup_session.get_book(book_id)  # to raise NotFound\n        self._unassign_object_from_catalog(comment_id, book_id)", "response": "Removes a Comment from a Book."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving a Credit from one Book to another.", "response": "def reassign_comment_to_book(self, comment_id, from_book_id, to_book_id):\n        \"\"\"Moves a ``Credit`` from one ``Book`` to another.\n\n        Mappings to other ``Books`` are unaffected.\n\n        arg:    comment_id (osid.id.Id): the ``Id`` of the ``Comment``\n        arg:    from_book_id (osid.id.Id): the ``Id`` of the current\n                ``Book``\n        arg:    to_book_id (osid.id.Id): the ``Id`` of the destination\n                ``Book``\n        raise:  NotFound - ``comment_id, from_book_id,`` or\n                ``to_book_id`` not found or ``comment`` not mapped to\n                ``from_book_id``\n        raise:  NullArgument - ``comment_id, book_id_id,`` or\n                ``to_book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.ResourceBinAssignmentSession.reassign_resource_to_bin\n        self.assign_comment_to_book(comment_id, to_book_id)\n        try:\n            self.unassign_comment_from_book(comment_id, from_book_id)\n        except:  # something went wrong, roll back assignment to to_book_id\n            self.unassign_comment_from_book(comment_id, to_book_id)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef can_create_book_with_record_types(self, book_record_types):\n        # Implemented from template for\n        # osid.resource.BinAdminSession.can_create_bin_with_record_types\n        # NOTE: It is expected that real authentication hints will be\n        # handled in a service adapter above the pay grade of this impl.\n        if self._catalog_session is not None:\n            return self._catalog_session.can_create_catalog_with_record_types(catalog_record_types=book_record_types)\n        return True", "response": "Tests if this user can create a single Book using the desired record types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_book(self, book_form):\n        # Implemented from template for\n        # osid.resource.BinAdminSession.update_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.update_catalog(catalog_form=book_form)\n        collection = JSONClientValidated('commenting',\n                                         collection='Book',\n                                         runtime=self._runtime)\n        if not isinstance(book_form, ABCBookForm):\n            raise errors.InvalidArgument('argument type is not an BookForm')\n        if not book_form.is_for_update():\n            raise errors.InvalidArgument('the BookForm is for update only, not create')\n        try:\n            if self._forms[book_form.get_id().get_identifier()] == UPDATED:\n                raise errors.IllegalState('book_form already used in an update transaction')\n        except KeyError:\n            raise errors.Unsupported('book_form did not originate from this session')\n        if not book_form.is_valid():\n            raise errors.InvalidArgument('one or more of the form elements is invalid')\n        collection.save(book_form._my_map)  # save is deprecated - change to replace_one\n\n        self._forms[book_form.get_id().get_identifier()] = UPDATED\n\n        # Note: this is out of spec. The OSIDs don't require an object to be returned\n        return objects.Book(osid_object_map=book_form._my_map, runtime=self._runtime, proxy=self._proxy)", "response": "Updates an existing book."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef alias_book(self, book_id, alias_id):\n        # Implemented from template for\n        # osid.resource.BinLookupSession.alias_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.alias_catalog(catalog_id=book_id, alias_id=alias_id)\n        self._alias_id(primary_id=book_id, equivalent_id=alias_id)", "response": "Adds an Id to a Book for the purpose of creating compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_root_books(self):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.get_root_bins\n        if self._catalog_session is not None:\n            return self._catalog_session.get_root_catalogs()\n        return BookLookupSession(\n            self._proxy,\n            self._runtime).get_books_by_ids(list(self.get_root_book_ids()))", "response": "Gets the root books in the book hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_parent_books(self, book_id):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.has_parent_bins\n        if self._catalog_session is not None:\n            return self._catalog_session.has_parent_catalogs(catalog_id=book_id)\n        return self._hierarchy_session.has_parents(id_=book_id)", "response": "Tests if the Book has any parents."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting if an Id is a direct parent of book.", "response": "def is_parent_of_book(self, id_, book_id):\n        \"\"\"Tests if an ``Id`` is a direct parent of book.\n\n        arg:    id (osid.id.Id): an ``Id``\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        return: (boolean) - ``true`` if this ``id`` is a parent of\n                ``book_id,`` f ``alse`` otherwise\n        raise:  NotFound - ``book_id`` is not found\n        raise:  NullArgument - ``id`` or ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n        *implementation notes*: If ``id`` not found return ``false``.\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.is_parent_of_bin\n        if self._catalog_session is not None:\n            return self._catalog_session.is_parent_of_catalog(id_=id_, catalog_id=book_id)\n        return self._hierarchy_session.is_parent(id_=book_id, parent_id=id_)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the parent Ids of the given book.", "response": "def get_parent_book_ids(self, book_id):\n        \"\"\"Gets the parent ``Ids`` of the given book.\n\n        arg:    book_id (osid.id.Id): a book ``Id``\n        return: (osid.id.IdList) - the parent ``Ids`` of the book\n        raise:  NotFound - ``book_id`` is not found\n        raise:  NullArgument - ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.get_parent_bin_ids\n        if self._catalog_session is not None:\n            return self._catalog_session.get_parent_catalog_ids(catalog_id=book_id)\n        return self._hierarchy_session.get_parents(id_=book_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_parent_books(self, book_id):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.get_parent_bins\n        if self._catalog_session is not None:\n            return self._catalog_session.get_parent_catalogs(catalog_id=book_id)\n        return BookLookupSession(\n            self._proxy,\n            self._runtime).get_books_by_ids(\n                list(self.get_parent_book_ids(book_id)))", "response": "Gets the parent books of the given id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if an Id is an ancestor of a book.", "response": "def is_ancestor_of_book(self, id_, book_id):\n        \"\"\"Tests if an ``Id`` is an ancestor of a book.\n\n        arg:    id (osid.id.Id): an ``Id``\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        return: (boolean) - ``tru`` e if this ``id`` is an ancestor of\n                ``book_id,``  ``false`` otherwise\n        raise:  NotFound - ``book_id`` is not found\n        raise:  NullArgument - ``id`` or ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n        *implementation notes*: If ``id`` not found return ``false``.\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.is_ancestor_of_bin\n        if self._catalog_session is not None:\n            return self._catalog_session.is_ancestor_of_catalog(id_=id_, catalog_id=book_id)\n        return self._hierarchy_session.is_ancestor(id_=id_, ancestor_id=book_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_child_books(self, book_id):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.has_child_bins\n        if self._catalog_session is not None:\n            return self._catalog_session.has_child_catalogs(catalog_id=book_id)\n        return self._hierarchy_session.has_children(id_=book_id)", "response": "Tests if a book has any children."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntests if a book is a direct child of another.", "response": "def is_child_of_book(self, id_, book_id):\n        \"\"\"Tests if a book is a direct child of another.\n\n        arg:    id (osid.id.Id): an ``Id``\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        return: (boolean) - ``true`` if the ``id`` is a child of\n                ``book_id,``  ``false`` otherwise\n        raise:  NotFound - ``book_id`` is not found\n        raise:  NullArgument - ``id`` or ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n        *implementation notes*: If ``id`` not found return ``false``.\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.is_child_of_bin\n        if self._catalog_session is not None:\n            return self._catalog_session.is_child_of_catalog(id_=id_, catalog_id=book_id)\n        return self._hierarchy_session.is_child(id_=book_id, child_id=id_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_child_book_ids(self, book_id):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.get_child_bin_ids\n        if self._catalog_session is not None:\n            return self._catalog_session.get_child_catalog_ids(catalog_id=book_id)\n        return self._hierarchy_session.get_children(id_=book_id)", "response": "Gets the child Ids of the given book."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_child_books(self, book_id):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.get_child_bins\n        if self._catalog_session is not None:\n            return self._catalog_session.get_child_catalogs(catalog_id=book_id)\n        return BookLookupSession(\n            self._proxy,\n            self._runtime).get_books_by_ids(\n                list(self.get_child_book_ids(book_id)))", "response": "Gets the child books of the given id."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntests if an Id is a descendant of a book.", "response": "def is_descendant_of_book(self, id_, book_id):\n        \"\"\"Tests if an ``Id`` is a descendant of a book.\n\n        arg:    id (osid.id.Id): an ``Id``\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        return: (boolean) - ``true`` if the ``id`` is a descendant of\n                the ``book_id,``  ``false`` otherwise\n        raise:  NotFound - ``book_id`` is not found\n        raise:  NullArgument - ``id`` or ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n        *implementation notes*: If ``id`` is not found return ``false``.\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.is_descendant_of_bin\n        if self._catalog_session is not None:\n            return self._catalog_session.is_descendant_of_catalog(id_=id_, catalog_id=book_id)\n        return self._hierarchy_session.is_descendant(id_=id_, descendant_id=book_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_book_nodes(self, book_id, ancestor_levels, descendant_levels, include_siblings):\n        # Implemented from template for\n        # osid.resource.BinHierarchySession.get_bin_nodes\n        return objects.BookNode(self.get_book_node_ids(\n            book_id=book_id,\n            ancestor_levels=ancestor_levels,\n            descendant_levels=descendant_levels,\n            include_siblings=include_siblings)._my_map, runtime=self._runtime, proxy=self._proxy)", "response": "Gets a portion of the hierarchy for the given book."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a root book.", "response": "def add_root_book(self, book_id):\n        \"\"\"Adds a root book.\n\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        raise:  AlreadyExists - ``book_id`` is already in hierarchy\n        raise:  NotFound - ``book_id`` is not found\n        raise:  NullArgument - ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchyDesignSession.add_root_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.add_root_catalog(catalog_id=book_id)\n        return self._hierarchy_session.add_root(id_=book_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_root_book(self, book_id):\n        # Implemented from template for\n        # osid.resource.BinHierarchyDesignSession.remove_root_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.remove_root_catalog(catalog_id=book_id)\n        return self._hierarchy_session.remove_root(id_=book_id)", "response": "Removes a root book."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a child to a book.", "response": "def add_child_book(self, book_id, child_id):\n        \"\"\"Adds a child to a book.\n\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        arg:    child_id (osid.id.Id): the ``Id`` of the new child\n        raise:  AlreadyExists - ``book_id`` is already a parent of\n                ``child_id``\n        raise:  NotFound - ``book_id`` or ``child_id`` not found\n        raise:  NullArgument - ``book_id`` or ``child_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchyDesignSession.add_child_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.add_child_catalog(catalog_id=book_id, child_id=child_id)\n        return self._hierarchy_session.add_child(id_=book_id, child_id=child_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a child from a book.", "response": "def remove_child_book(self, book_id, child_id):\n        \"\"\"Removes a child from a book.\n\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        arg:    child_id (osid.id.Id): the ``Id`` of the new child\n        raise:  NotFound - ``book_id`` not a parent of ``child_id``\n        raise:  NullArgument - ``book_id`` or ``child_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchyDesignSession.remove_child_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.remove_child_catalog(catalog_id=book_id, child_id=child_id)\n        return self._hierarchy_session.remove_child(id_=book_id, child_id=child_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all children from a book.", "response": "def remove_child_books(self, book_id):\n        \"\"\"Removes all children from a book.\n\n        arg:    book_id (osid.id.Id): the ``Id`` of a book\n        raise:  NotFound - ``book_id`` not found\n        raise:  NullArgument - ``book_id`` is ``null``\n        raise:  OperationFailed - unable to complete request\n        raise:  PermissionDenied - authorization failure\n        *compliance: mandatory -- This method must be implemented.*\n\n        \"\"\"\n        # Implemented from template for\n        # osid.resource.BinHierarchyDesignSession.remove_child_bin_template\n        if self._catalog_session is not None:\n            return self._catalog_session.remove_child_catalogs(catalog_id=book_id)\n        return self._hierarchy_session.remove_children(id_=book_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_value_by_parameter(self, parameter_id=None):\n        pass\n        if parameter_id is None:\n            raise NullArgument\n        try:\n            parameter_key = parameter_id.get_identifier() + '.' + parameter_id.get_identifier_namespace()\n            parameter_map = self._catalog._config_map['parameters'][parameter_key]\n        except KeyError:\n            try:\n                parameter_key = parameter_id.get_identifier()\n                parameter_map = self._catalog._config_map['parameters'][parameter_key]\n            except KeyError:\n                raise NotFound(str(parameter_id))\n        if len(parameter_map['values']) == 0:\n            raise NotFound()\n        lowest_priority_value_map = None\n        for value_map in parameter_map['values']:\n            if lowest_priority_value_map is None or lowest_priority_value_map['priority'] < value_map['priority']:\n                lowest_priority_value_map = value_map\n        return Value(lowest_priority_value_map, Parameter(parameter_map))", "response": "Gets a Value object for the given parameter Id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_config():\n    env = getenv('FLASH_CONFIG')\n    if env:\n        logger.info('loading configuration from environment')\n        data = json.loads(env)\n    else:\n        data = _parse_file()\n    data['project_name'] = data.get('project_name', 'unnamed')\n    data['services'] = define_services(data.get('services', []))\n    data['style'] = data.get('style', 'default')\n    if data.get('project_end'):\n        data['project_end'] = repr(data['project_end'])\n    return data", "response": "Parse the configuration and create required services."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_file():\n    file_name = path.join(\n        path.abspath(path.dirname(path.dirname(__file__))), 'config.json'\n    )\n    logger.info('loading configuration from file: %r', file_name)\n    try:\n        data = _read_file(file_name)\n    except FileNotFoundError:\n        logger.error('no configuration available, set FLASH_CONFIG or '\n                     'provide config.json')\n        exit()\n    for service in data.get('services', []):\n        for key, val in service.items():\n            if isinstance(val, str) and re.match(r'^\\$[A-Z_]+$', val):\n                env_val = getenv(val[1:])\n                if env_val is None:\n                    logger.warning('environment variable %r not found', val[1:])\n                service[key] = env_val or val\n    return data", "response": "Parse the config from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the file content and load it as JSON.", "response": "def _read_file(file_name):\n    \"\"\"Read the file content and load it as JSON.\n\n    Arguments:\n      file_name (:py:class:`str`): The filename.\n\n    Returns:\n      :py:class:`dict`: The loaded JSON data.\n\n    Raises:\n      :py:class:`FileNotFoundError`: If the file is not found.\n\n    \"\"\"\n    with open(file_name) as config_file:\n        data = json.load(config_file)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_message(self, checker):\n        solution = ' (%s)' % checker.solution if self.with_solutions else ''\n        return '{} {}{}'.format(checker.code,\n                                checker.msg,\n                                solution)", "response": "Builds the checker s error message to report"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves every available experiment.", "response": "def all_experiments(self):\n        \"\"\"\n        Retrieve every available experiment.\n\n        Returns a list of ``cleaver.experiment.Experiment``s\n        \"\"\"\n        try:\n            return [\n                self.experiment_factory(e)\n                for e in model.Experiment.query.all()\n            ]\n        finally:\n            self.Session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_experiment(self, name, variants):\n        try:\n            return self.experiment_factory(model.Experiment.get_by(name=name))\n        finally:\n            self.Session.close()", "response": "Retrieve an experiment by its name and variants."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npersist an experiment and its variants.", "response": "def save_experiment(self, name, variants):\n        \"\"\"\n        Persist an experiment and its variants (unless they already exist).\n\n        :param name a unique string name for the experiment\n        :param variants a list of strings, each with a unique variant name\n        \"\"\"\n        try:\n            model.Experiment(\n                name=name,\n                started_on=datetime.utcnow(),\n                variants=[\n                    model.Variant(name=v, order=i)\n                    for i, v in enumerate(variants)\n                ]\n            )\n            self.Session.commit()\n        finally:\n            self.Session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the variant for a specific user and experiment.", "response": "def get_variant(self, identity, experiment_name):\n        \"\"\"\n        Retrieve the variant for a specific user and experiment (if it exists).\n\n        :param identity a unique user identifier\n        :param experiment_name the string name of the experiment\n\n        Returns a ``String`` or `None`\n        \"\"\"\n        try:\n            match = model.Participant.query.join(\n                model.Experiment\n            ).filter(and_(\n                model.Participant.identity == identity,\n                model.Experiment.name == experiment_name\n            )).first()\n            return match.variant.name if match else None\n        finally:\n            self.Session.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the variant for a specific user.", "response": "def set_variant(self, identity, experiment_name, variant_name):\n        \"\"\"\n        Set the variant for a specific user.\n\n        :param identity a unique user identifier\n        :param experiment_name the string name of the experiment\n        :param variant_name the string name of the variant\n        \"\"\"\n        try:\n            experiment = model.Experiment.get_by(name=experiment_name)\n            variant = model.Variant.get_by(name=variant_name)\n            if experiment and variant and model.Participant.query.filter(and_(\n                model.Participant.identity == identity,\n                model.Participant.experiment_id == experiment.id,\n                model.Participant.variant_id == variant.id\n            )).count() == 0:\n                model.Participant(\n                    identity=identity,\n                    experiment=experiment,\n                    variant=variant\n                )\n                self.Session.commit()\n        finally:\n            self.Session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parametersAsIndex( self, ps ):\n        k = \"\"\n        for p in sorted(ps.keys()):       # normalise the parameters\n            v = ps[p]\n            k = k + \"{p}=[[{v}]];\".format(p = p, v = v)\n        return k", "response": "Private method to turn a parameter dict into a string suitable for keying a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addResult( self, result, jobids = None ):\n\n        # deal with the dufferent ways of presenting results to be added\n        if isinstance(result, list):\n            # a list, recursively add\n            for res in result:\n                self.addResult(res)\n        else:\n            if isinstance(result, dict):\n                if isinstance(result[Experiment.RESULTS], list):\n                    # a result with embedded results, unwrap and and add them\n                    for res in result[Experiment.RESULTS]:\n                        self.addResult(res)\n                else:\n                    # a single results dict with a single set of experimental results\n                    k = self._parametersAsIndex(result[Experiment.PARAMETERS])\n            \n                    # retrieve or create the result list\n                    if k in self._results.keys():\n                        rs = self._results[k]\n                    else:\n                        rs = []\n                        self._results[k] = rs\n\n                    # store the result\n                    rs.insert(0, result)\n            else:\n                raise Exception(\"Can't deal with results like this: {r}\".format(r = result)) \n                    \n        # if there is are job ids provided, cancel the corresponding pending jobs\n        if jobids is not None:\n            if not isinstance(jobids, list):\n                jobids = [ jobids ]\n            for jobid in jobids:\n                if jobid in self._pending.keys():\n                    # grab the results list for which this is a pending job\n                    k = self._pending[jobid]\n                    if k in self._results.keys():\n                        # delete job id from current results\n                        rs = self._results[k]\n                        j = rs.index(jobid)\n                        del rs[j]\n                    \n                        # ...and from the set of pending results\n                        del self._pending[jobid]\n                    else:\n                        # we've screwed-up the internal data structures\n                        raise RuntimeError('Internal structure error for {j} -> {ps}'.format(j = jobid,\n                                                                                             ps = k))\n                else:\n                    # we've screwed-up the internal data structures\n                    raise RuntimeError('Internal structure error for {j}'.format(j = jobid))", "response": "Add a result to the result set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a pending result that we expect to get results for.", "response": "def addPendingResult( self, ps, jobid ):\n        \"\"\"Add a \"pending\" result that we expect to get results for.\n\n        :param ps: the parameters for the result\n        :param jobid: an identifier for the pending result\"\"\"\n        k = self._parametersAsIndex(ps)\n\n        # retrieve or create the result list\n        if k in self._results.keys():\n            rs = self._results[k]\n        else:\n            rs = []\n            self._results[k] = rs\n\n        # append the pending result's jobid\n        rs.insert(0, jobid)\n\n        # map job id to parameters to which it refers\n        self._pending[jobid] = k"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncanceling a particular pending result.", "response": "def cancelPendingResult( self, jobid ):\n        \"\"\"Cancel a particular pending result. Note that this only affects the\n        notebook's record, not any job running in a lab.\n\n        :param jobid: job id for pending result\"\"\"\n        if jobid in self._pending.keys():\n            k = self._pending[jobid]\n            del self._pending[jobid]\n            if k in self._results.keys():\n                rs = self._results[k]\n                j = rs.index(jobid)\n                del rs[j]\n            else:\n                # we've screwed-up the internal data structures\n                raise RuntimeError('Internal structure error for {j} -> {ps}'.format(j = jobid,\n                                                                                     ps = k))\n        else:\n            # no such job\n            # sd: should this just fail silently?\n            raise KeyError('No pending result with id {j}'.format(j = jobid))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves a list of all pending results associated with the given parameters.", "response": "def pendingResultsFor( self, ps ):\n        \"\"\"Retrieve a list of all pending results associated with the given parameters.\n\n        :param ps: the parameters\n        :returns: a list of pending result job ids, which may be empty\"\"\"\n        k = self._parametersAsIndex(ps)\n        if k in self._results.keys():\n            # filter out pending job ids, which can be anything except dicts\n            return [ j for j in self._results[k] if not isinstance(j, dict) ]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncancels all pending results for the given parameters.", "response": "def cancelPendingResultsFor( self, ps ):\n        \"\"\"Cancel all pending results for the given parameters. Note that\n        this only affects the notebook's record, not any job running in a lab.\n\n        :param ps: the parameters\"\"\"\n        k = self._parametersAsIndex(ps)\n\n        if k in self._results.keys():\n            # remove from results\n            rs = self._results[k]\n            js = [ j for j in rs if not isinstance(j, dict) ]\n            self._results[k] = [ rc for rc in rs if isinstance(rc, dict) ]\n\n            # ...and from pending jobs list\n            for j in js:\n                del self._pending[j]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncanceling all pending results.", "response": "def cancelAllPendingResults( self ):\n        \"\"\"Cancel all pending results. Note that this only affects the\n        notebook's record, not any job running in a lab.\"\"\"\n        for k in self._results.keys():\n            rs = self._results[k]\n            self._results[k] = [ j for j in rs if isinstance(j, dict) ]\n        self._pending = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a list of all results associated with the given parameters.", "response": "def resultsFor( self, ps ):\n        \"\"\"Retrieve a list of all results associated with the given parameters.\n\n        :param ps: the parameters\n        :returns: a list of results, which may be empty\"\"\"\n        k = self._parametersAsIndex(ps)\n        if k in self._results.keys():\n            # filter out pending job ids, which can be anything except dicts\n            return [ res for res in self._results[k] if isinstance(res, dict) ]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all the results currently available. This is a convenience method for getting the results from the job store.", "response": "def results( self ):\n        \"\"\"Return a list of all the results currently available. This\n        excludes pending results. Results are returned as a single flat\n        list, so any repetition structure is lost.\n\n        :returns: a list of results\"\"\"\n        rs = []\n        for k in self._results.keys():\n            # filter out pending job ids, which can be anything except dicts\n            ars = [ res for res in self._results[k] if isinstance(res, dict) ]\n            rs.extend(ars)\n        return rs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dataframe( self, only_successful = True ):\n\n        def extract( r ):\n            if r[Experiment.METADATA][Experiment.STATUS]:\n                # experiment was a success, include it\n                rd = r[Experiment.METADATA].copy()\n                rd.update(r[Experiment.PARAMETERS])\n                rd.update(r[Experiment.RESULTS])\n            else:\n                # experiment returned an exception\n                if not only_successful:\n                    # ...but we want it anyway\n                    rd = r[Experiment.METADATA].copy()\n                    rd.update(r[Experiment.PARAMETERS])\n            \n                    # ...and there are no results to add\n                else:\n                    rd = None\n            return rd\n\n        records = [ r for r in map(extract, self.results()) if r is not None ]\n        return DataFrame.from_records(records)", "response": "Return the results as a pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the distutils metadata object.", "response": "def distutils_autosemver_case(\n    metadata, with_release_notes=False, with_authors=True, with_changelog=True,\n    bugtracker_url=None,\n):\n    \"\"\"\n    :param metadata: distutils metadata object.\n    :param with_release_notes: if true, will create the release notes.\n    :type with_release_notes: bool\n    :param with_authors: if true, will create the authors file.\n    :type with_authors: bool\n    :param with_changelog: if true, will create the release notes file.\n    :type with_changelog: bool\n    :param bugtracker_url: URL for the bugtracker of the project.\n    :type bugtracker_url: str\n    :returns metadata: the updated distutils metadata.\n    \"\"\"\n    metadata.version = pkg_version()\n    if with_authors:\n        create_authors()\n\n    if with_release_notes:\n        create_releasenotes()\n\n    if with_changelog:\n        create_changelog()\n\n    metadata._autosmever = True\n\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distutils_old_autosemver_case(metadata, attr, value):\n    metadata = distutils_default_case(metadata, attr, value)\n    create_changelog(bugtracker_url=getattr(metadata, 'bugtracker_url', ''))\n    return metadata", "response": "DEPRECATED - use distutils_default_case"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the given stream and add the entries to the object.", "response": "def parse(self, stream):\n        \"\"\"\n        Parse the given stream\n        \"\"\"\n        lines = re.sub(\"[\\r\\n]+\", \"\\n\", stream.read()).split(\"\\n\")\n        for line in lines:\n            self.parseline(line)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield the items in a stream of bytes or text.", "response": "async def stream_as_text(stream):\n    \"\"\"\n    Given a stream of bytes or text, if any of the items in the stream\n    are bytes convert them to text.\n    This function can be removed once we return text streams\n    instead of byte streams.\n    \"\"\"\n    async for data in stream:\n        if not isinstance(data, six.text_type):\n            data = data.decode('utf-8', 'replace')\n        yield data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun PyLint on the code and produce a report suitable for the Jenkins plugin violations.", "response": "def pylint_jenkins():\n    \"\"\"Run PyLint on the code and produce a report suitable for the\n    Jenkins plugin 'violations'.\n\n    Note that there is a bug in the Violations plugin which means that\n    absolute paths to source (produced by PyLint) are not read. The sed command\n    removes the workspace part of the path making everything good again. This\n    requires the environment variable WORKSPACE from Jenkins\"\"\"\n    cmd = '{0} formic -f parseable'.format(PYLINT_EXE).split(' ')\n    return dovetail.call(cmd, stdout=BUILD_PYLINT)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish Formic to PyPi", "response": "def publish():\n    \"\"\"Publishes Formic to PyPi (don't run unless you are the maintainer)\"\"\"\n    print(\"To be ready for release, remember:\")\n    print(\"      1) Update the version number (and associated test)\")\n    print(\"      2) Update the ChangeLog.rst (and other documentation)\")\n    print(\n        \"         ChangeLog should have an line (title) consisting of the version number\"\n    )\n    print(\"      3) Tag Mercurial with 'Release <version>'\")\n    print(\"      4) Push updates to BitBucket\")\n    print(\"      5) Set the RELEASE environment variable\")\n    print(\"           $ export RELEASE=formic\")\n\n    cmd = [\n        'bash', '-c',\n        'yolk -M formic | grep \"^version: \" | sed \"s/^version: \\\\(.*\\\\)$/\\\\1/\"'\n    ]\n    published_version = subprocess.check_output(cmd).strip()\n    our_version = open(os.path.join(\"formic\", \"VERSION.txt\"), \"r\").read()\n\n    # sanity test on version\n    if \"\\n\" in published_version or\\\n       len(published_version) < 3 or len(published_version) > 10:\n        raise Exception(\n            \"Published version number seems weird: \" + published_version)\n\n    print(\"Published version:\", published_version)\n    print(\"Current version:  \", our_version)\n\n    if our_version == published_version:\n        raise Exception(\n            \"You are attempting to republish version \" + our_version)\n\n    # sanity: check ChangeLog starts with our version\n    changelog = open(\"CHANGELOG.rst\", \"r\")\n    found = False\n    for line in changelog.readlines():\n        if line.strip() == our_version:\n            print(\"ChangeLog has an entry\")\n            found = True\n            break\n    changelog.close()\n    if not found:\n        raise Exception(\n            \"The ChangeLog does not appear to include comments on this release\"\n        )\n\n    # Sanity check: is there a release tag\n    tags = subprocess.check_output(\"hg tags\".split())\n    found = False\n    looking_for = \"Release \" + our_version\n    for line in tags.split(\"\\n\"):\n        match = re.match(r\"^(.*)\\s+[0-9]+:[0-9a-f]+$\", line)\n        if match:\n            tag = match.group(1).strip()\n            if tag == looking_for:\n                print(\"Found tag\", tag)\n                found = True\n                break\n\n    if not found:\n        raise Exception(\n            \"Mercurial does not have the release tag: \" + looking_for)\n\n    status = subprocess.check_output([\"hg\", \"status\"])\n    for line in status.split(\"\\n\"):\n        if len(line) > 0:\n            raise Exception(\"Uncommitted changes present\")\n\n    try:\n        v = os.environ[\"RELEASE\"]\n        if v != \"formic\":\n            raise KeyError()\n    except KeyError:\n        print(\"$RELEASE environment variable is not set\")\n        raise\n\n    subprocess.check_call(\"python setup.py bdist_egg upload\".split())\n    subprocess.check_call(\"python setup.py sdist upload\".split())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef launch_modules_with_names(modules_with_names, module_args={}, kill_before_launch=True):\n    '''launch module.main functions in another process'''\n    processes = []\n    if kill_before_launch:\n        for module_name, name in modules_with_names:\n            kill_module(name)\n    for module_name, name in modules_with_names:\n        m = importlib.import_module(module_name)\n        args = {}\n        if module_name in module_args:\n            args = module_args[module_name]\n        p1 = Process(target=m.main, args=args)\n        p1.daemon = True\n        p1.start()\n        processes.append(p1)\n        with open(get_launched_module_pid_file(name), 'w') as f:\n            f.write('{}'.format(p1.pid))\n    return processes", "response": "launch modules with names in another process"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self, **kwds):\n        albums = self._client.get(\"/albums/list.json\", **kwds)[\"result\"]\n        albums = self._result_to_list(albums)\n        return [Album(self._client, album) for album in albums]", "response": "This endpoint returns a list of Album objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the cover photo of an album.", "response": "def cover_update(self, album, photo, **kwds):\n        \"\"\"\n        Endpoint: /album/<album_id>/cover/<photo_id>/update.json\n\n        Update the cover photo of an album.\n        Returns the updated album object.\n        \"\"\"\n        result = self._client.post(\"/album/%s/cover/%s/update.json\" %\n                                   (self._extract_id(album),\n                                    self._extract_id(photo)),\n                                   **kwds)[\"result\"]\n\n        # API currently doesn't return the updated album\n        # (frontend issue #1369)\n        if isinstance(result, bool): # pragma: no cover\n            result = self._client.get(\"/album/%s/view.json\" %\n                                      self._extract_id(album))[\"result\"]\n\n        return Album(self._client, result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, name, **kwds):\n        result = self._client.post(\"/album/create.json\",\n                                   name=name, **kwds)[\"result\"]\n        return Album(self._client, result)", "response": "Create a new album and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, album, objects, object_type=None, **kwds):\n        return self._add_remove(\"add\", album, objects, object_type,\n                                **kwds)", "response": "Add objects to an album."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, album, objects, object_type=None, **kwds):\n        return self._add_remove(\"remove\", album, objects, object_type,\n                                **kwds)", "response": "Remove objects from an album."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_remove(self, action, album, objects, object_type=None,\n                    **kwds):\n        \"\"\"Common code for the add and remove endpoints.\"\"\"\n        # Ensure we have an iterable of objects\n        if not isinstance(objects, collections.Iterable):\n            objects = [objects]\n\n        # Extract the type of the objects\n        if object_type is None:\n            object_type = objects[0].get_type()\n\n        for i, obj in enumerate(objects):\n            if isinstance(obj, TroveboxObject):\n                # Ensure all objects are the same type\n                if obj.get_type() != object_type:\n                    raise ValueError(\"Not all objects are of type '%s'\"\n                                     % object_type)\n                # Extract the ids of the objects\n                objects[i] = obj.id\n\n        result = self._client.post(\"/album/%s/%s/%s.json\" %\n                                   (self._extract_id(album),\n                                    object_type, action),\n                                   ids=objects, **kwds)[\"result\"]\n\n        # API currently doesn't return the updated album\n        # (frontend issue #1369)\n        if isinstance(result, bool): # pragma: no cover\n            result = self._client.get(\"/album/%s/view.json\" %\n                                      self._extract_id(album))[\"result\"]\n        return Album(self._client, result)", "response": "Common code for the add and remove endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, album, **kwds):\n        result = self._client.post(\"/album/%s/update.json\" %\n                                   self._extract_id(album),\n                                   **kwds)[\"result\"]\n\n        # APIv1 doesn't return the updated album (frontend issue #937)\n        if isinstance(result, bool): # pragma: no cover\n            result = self._client.get(\"/album/%s/view.json\" %\n                                      self._extract_id(album))[\"result\"]\n\n        return Album(self._client, result)", "response": "Update an album with the specified parameters. Returns the updated Album object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef view(self, album, **kwds):\n        result = self._client.get(\"/album/%s/view.json\" %\n                                  self._extract_id(album),\n                                  **kwds)[\"result\"]\n        return Album(self._client, result)", "response": "This endpoint returns the full object representation of the album."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures theme destination folder and clone git specified repo in it.", "response": "def clone(self, folder, git_repository):\n        \"\"\"Ensures theme destination folder and clone git specified repo in it.\n\n        :param git_repository: git url of the theme folder\n        :param folder: path of the git managed theme folder\n        \"\"\"\n        os.makedirs(folder)\n        git.Git().clone(git_repository, folder)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_git_repository(self, folder, git_repository):\n\n        # load repo object from path\n        repo = git.Repo(folder)\n\n        # keep local_head_name for to reset folder remote head later\n        local_head_name = repo.head.ref.name\n\n        # test if git repository url has changed\n        remote = repo.remote('origin')\n        if remote.url == git_repository:\n            return\n\n        # remove/add new remote repository origin\n        remote.remove(repo, 'origin')\n        origin = remote.add(repo, 'origin', git_repository)\n\n        # fetch available branches\n        origin.fetch()\n\n        # get remote head according previously store local head name\n        remote_head = getattr(origin.refs, local_head_name)\n        # reset repository tracking branch according deduced remote head\n        repo.create_head(local_head_name, remote_head)\\\n            .set_tracking_branch(remote_head)", "response": "Updates git remote for the managed theme folder if has changed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate or updates the theme folder according given git repository.", "response": "def update(self, folder, git_repository):\n        \"\"\"Creates or updates theme folder according given git repository.\n\n        :param git_repository: git url of the theme folder\n        :param folder: path of the git managed theme folder\n        \"\"\"\n        # git clone\n        try:\n            self.clone(folder, git_repository)\n        # git update if folder already exist\n        except OSError:\n            self.update_git_repository(folder, git_repository)\n            self.pull(folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_sex_problems(file_name):\n    if file_name is None:\n        return frozenset()\n\n    problems = None\n    with open(file_name, 'r') as input_file:\n        header_index = dict([\n            (col_name, i) for i, col_name in\n            enumerate(input_file.readline().rstrip(\"\\r\\n\").split(\"\\t\"))\n        ])\n        if \"IID\" not in header_index:\n            msg = \"{}: no column named IID\".format(file_name)\n            raise ProgramError(msg)\n\n        problems = frozenset([\n            i.rstrip(\"\\r\\n\").split(\"\\t\")[header_index[\"IID\"]]\n            for i in input_file.readlines()\n        ])\n    return problems", "response": "Reads the sex problem file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode_chr(chromosome):\n    if chromosome == \"X\":\n        return 23\n    if chromosome == \"Y\":\n        return 24\n    if chromosome == \"XY\":\n        return 25\n    if chromosome == \"MT\":\n        return 26\n    try:\n        new_chromosome = int(chromosome)\n        if new_chromosome < 0 or new_chromosome > 26:\n            msg = \"{}: invalid chromosome\".format(chromosome)\n            raise ProgramError(msg)\n        return new_chromosome\n    except ValueError:\n        msg = \"{}: invalid chromosome\".format(chromosome)\n        raise ProgramError(msg)", "response": "Encodes chromosomes.\n\n    :param chromosome: the chromosome to encode.\n\n    :type chromosome: str\n\n    :returns: the encoded chromosome as :py:class:`int`.\n\n    It changes ``X``, ``Y``, ``XY`` and ``MT`` to ``23``, ``24``, ``25`` and\n    ``26``, respectively. It changes everything else as :py:class:`int`.\n\n    If :py:class:`ValueError` is raised, then :py:class:`ProgramError` is\n    also raised. If a chromosome as a value below 1 or above 26, a\n    :py:class:`ProgramError` is raised.\n\n    .. testsetup::\n\n        from pyGenClean.SexCheck.gender_plot import encode_chr\n\n    .. doctest::\n\n        >>> [encode_chr(str(i)) for i in range(0, 11)]\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n        >>> [encode_chr(str(i)) for i in range(11, 21)]\n        [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n        >>> [encode_chr(str(i)) for i in range(21, 27)]\n        [21, 22, 23, 24, 25, 26]\n        >>> [encode_chr(i) for i in [\"X\", \"Y\", \"XY\", \"MT\"]]\n        [23, 24, 25, 26]\n        >>> encode_chr(\"27\")\n        Traceback (most recent call last):\n            ...\n        ProgramError: 27: invalid chromosome\n        >>> encode_chr(\"XX\")\n        Traceback (most recent call last):\n            ...\n        ProgramError: XX: invalid chromosome"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_bim(file_name):\n    marker_names_chr = None\n    with open(file_name, 'r') as input_file:\n        marker_names_chr = dict([\n            (i[1], encode_chr(i[0]))\n            for i in [\n                j.rstrip(\"\\r\\n\").split(\"\\t\") for j in input_file.readlines()\n            ] if encode_chr(i[0]) in {23, 24}\n        ])\n    return marker_names_chr", "response": "Reads the BIM file to gather marker names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_fam(file_name):\n    sample_names_gender = None\n    with open(file_name, 'r') as input_file:\n        sample_names_gender = dict([\n            (i[1], encode_gender(i[4])) for i in [\n                j.rstrip(\"\\r\\n\").split(\" \") for j in input_file.readlines()\n            ]\n        ])\n    return sample_names_gender", "response": "Reads the FAM file to gather sample names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_gender(data, options):\n    if data is None:\n        # there is a problem...\n        msg = (\"no data: specify either '--bfile' and '--intensities', or \"\n               \"'--summarized-intensities'\")\n        raise ProgramError(msg)\n\n    import matplotlib as mpl\n    if options.format != \"X11\" and mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    if options.format != \"X11\":\n        plt.ioff()\n\n    # The figure and axes\n    fig = plt.figure()\n    fig.subplots_adjust(top=0.84)\n    ax = fig.add_subplot(111)\n\n    # Changing the spines\n    ax.xaxis.set_ticks_position(\"bottom\")\n    ax.yaxis.set_ticks_position(\"left\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n\n    # Setting the title\n    ax.set_xlabel(options.xlabel)\n    ax.set_ylabel(options.ylabel)\n\n    # For the legend\n    plot_object = []\n    labels = []\n\n    # Plotting the OK males\n    males = np.logical_and(data[\"gender\"] == \"Male\", data[\"status\"] == \"OK\")\n    tmp, = ax.plot(data[\"chr23\"][males], data[\"chr24\"][males], \"o\", ms=5,\n                   mec=\"#0099CC\", mfc=\"#0099CC\")\n    plot_object.append(tmp)\n    labels.append(\"OK Males (n={})\".format(sum(males)))\n    if options.summarized_intensities is None:\n        print_data_to_file(data[males], \"{}.ok_males.txt\".format(options.out))\n\n    # Plotting the OK females\n    females = np.logical_and(data[\"gender\"] == \"Female\",\n                             data[\"status\"] == \"OK\")\n    tmp, = ax.plot(data[\"chr23\"][females], data[\"chr24\"][females], \"o\", ms=5,\n                   mec=\"#CC0000\", mfc=\"#CC0000\")\n    plot_object.append(tmp)\n    labels.append(\"OK Females (n={})\".format(sum(females)))\n    if options.summarized_intensities is None:\n        print_data_to_file(data[females],\n                           \"{}.ok_females.txt\".format(options.out))\n\n    # Plotting the OK unknowns\n    unknowns = np.logical_and(data[\"gender\"] == \"Unknown\",\n                              data[\"status\"] == \"OK\")\n    tmp, = ax.plot(data[\"chr23\"][unknowns], data[\"chr24\"][unknowns], \"o\", ms=5,\n                   mec=\"#555555\", mfc=\"#555555\")\n    plot_object.append(tmp)\n    labels.append(\"OK Unknowns (n={})\".format(sum(unknowns)))\n    if options.summarized_intensities is None:\n        print_data_to_file(data[unknowns],\n                           \"{}.ok_unknowns.txt\".format(options.out))\n\n    # Plotting the Problem males\n    males = np.logical_and(data[\"gender\"] == \"Male\",\n                           data[\"status\"] == \"Problem\")\n    tmp, = ax.plot(data[\"chr23\"][males], data[\"chr24\"][males], \"^\", ms=6,\n                   mec=\"#000000\", mfc=\"#669900\")\n    plot_object.append(tmp)\n    labels.append(\"Problematic Males (n={})\".format(sum(males)))\n    if options.summarized_intensities is None:\n        print_data_to_file(data[males],\n                           \"{}.problematic_males.txt\".format(options.out))\n\n    # Plotting the Problem females\n    females = np.logical_and(data[\"gender\"] == \"Female\",\n                             data[\"status\"] == \"Problem\")\n    tmp, = ax.plot(data[\"chr23\"][females], data[\"chr24\"][females], \"v\", ms=6,\n                   mec=\"#000000\", mfc=\"#9933CC\")\n    plot_object.append(tmp)\n    labels.append(\"Problematic Females (n={})\".format(sum(females)))\n    if options.summarized_intensities is None:\n        print_data_to_file(data[females],\n                           \"{}.problematic_females.txt\".format(options.out))\n\n    # Plotting the Problem unknowns\n    unknowns = np.logical_and(data[\"gender\"] == \"Unknown\",\n                              data[\"status\"] == \"Problem\")\n    tmp, = ax.plot(data[\"chr23\"][unknowns], data[\"chr24\"][unknowns], \">\", ms=6,\n                   mec=\"#000000\", mfc=\"#555555\")\n    plot_object.append(tmp)\n    labels.append(\"Problematic Unknown (n={})\".format(sum(unknowns)))\n    if options.summarized_intensities is None:\n        print_data_to_file(data[unknowns],\n                           \"{}.problematic_unknowns.txt\".format(options.out))\n\n    # the legend\n    prop = mpl.font_manager.FontProperties(size=10)\n    leg = ax.legend(plot_object, labels, loc=8, numpoints=1, fancybox=True,\n                    prop=prop, ncol=2, bbox_to_anchor=(0., 1.02, 1., .102),\n                    borderaxespad=0.)\n\n    # Setting the limit\n    xlim = ax.get_xlim()\n    ax.set_xlim((xlim[0]-0.01, xlim[1]+0.01))\n    ylim = ax.get_ylim()\n    ax.set_ylim((ylim[0]-0.01, ylim[1]+0.01))\n\n    if options.format == \"X11\":\n        plt.show()\n    else:\n        file_name = \"{}.{}\".format(options.out, options.format)\n        try:\n            plt.savefig(file_name)\n        except IOError:\n            msg = \"{}: can't write file\".format(file_name)\n            raise ProgramError(msg)", "response": "Plots the gender of the current sample."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_data_to_file(data, file_name):\n    try:\n        with open(file_name, 'w') as output_file:\n            print >>output_file, \"\\t\".join(data.dtype.names)\n            for row in data:\n                print >>output_file, \"\\t\".join(map(str, row))\n    except IOError:\n        msg = \"{}: can't write file\".format(file_name)\n        raise ProgramError(msg)", "response": "Prints data to file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_summarized_intensities(prefix):\n    data = []\n    for suffix in {\".ok_females.txt\", \".ok_males.txt\", \".ok_unknowns.txt\",\n                   \".problematic_females.txt\", \".problematic_males.txt\",\n                   \".problematic_unknowns.txt\"}:\n        with open(prefix + suffix, 'r') as input_file:\n            header_index = None\n            for line_nb, line in enumerate(input_file):\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n                if line_nb == 0:\n                    # This is the header\n                    header_index = dict([\n                        (col_name, i) for i, col_name in enumerate(row)\n                    ])\n                    for col_name in {\"sampleID\", \"chr23\", \"chr24\", \"gender\",\n                                     \"status\"}:\n                        if col_name not in header_index:\n                            msg = \"{}: no column named {}\".format(\n                                prefix+suffix,\n                                col_name,\n                            )\n                            raise ProgramError(msg)\n\n                else:\n                    sampleID = row[header_index[\"sampleID\"]]\n                    chr23 = row[header_index[\"chr23\"]]\n                    chr24 = row[header_index[\"chr24\"]]\n                    gender = row[header_index[\"gender\"]]\n                    status = row[header_index[\"status\"]]\n\n                    try:\n                        chr23 = float(chr23)\n                        chr24 = float(chr24)\n                    except ValueError:\n                        msg = (\"{} and {}: bad summarized intensities for \"\n                               \"sample {}\".format(chr23, chr24, sampleID))\n                        raise ProgramError(msg)\n\n                    data.append((sampleID, chr23, chr24, gender, status))\n\n    # Creating the data structure\n    data = np.array(\n        data,\n        dtype=[(\"sampleID\", \"a{}\".format(max([len(i[0]) for i in data]))),\n               (\"chr23\", float), (\"chr24\", float),\n               (\"gender\", \"a{}\".format(max([len(i[3]) for i in data]))),\n               (\"status\", \"a{}\".format(max([len(i[4]) for i in data])))],\n    )\n    return data", "response": "Reads the summarized intensities from 6 files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the intensities from a file.", "response": "def read_intensities(file_name, needed_markers_chr, needed_samples_gender,\n                     sex_problems):\n    \"\"\"Reads the intensities from a file.\n\n    :param file_name: the name of the input file.\n    :param needed_markers_chr: the markers that are needed.\n    :param needed_samples_gender: the gender of all the samples.\n    :param sex_problems: the sample with sex problem.\n\n    :type file_name: str\n    :type needed_markers_chr: dict\n    :type needed_samples_gender: dict\n    :type sex_problems: frozenset\n\n    :returns: a :py:class`numpy.recarray` containing the following columns (for\n              each of the samples): ``sampleID``, ``chr23``, ``chr24``,\n              ``gender`` and ``status``.\n\n    Reads the normalized intensities from a final report. The file must contain\n    the following columns: ``SNP Name``, ``Sample ID``, ``X``, ``Y`` and\n    ``Chr``. It then keeps only the required markers (those that are on\n    sexual chromosomes (``23`` or ``24``), encoding `NaN` intensities to zero.\n\n    The final data set contains the following information for each sample:\n\n    * ``sampleID``: the sample ID.\n    * ``chr23``: the summarized intensities for chromosome 23.\n    * ``chr24``: the summarized intensities for chromosome 24.\n    * ``gender``: the gender of the sample (``Male`` or ``Female``).\n    * ``status``: the status of the sample (``OK`` or ``Problem``).\n\n    The summarized intensities for a chromosome (:math:`S_{chr}`) is computed\n    using this formula (where :math:`I_{chr}` is the set of all marker\n    intensities on chromosome :math:`chr`):\n\n    .. math::\n        S_{chr} = \\\\frac{\\\\sum{I_{chr}}}{||I_{chr}||}\n\n    \"\"\"\n    input_file = None\n    if file_name.endswith(\".gz\"):\n        input_file = gzip.open(file_name, 'rb')\n    else:\n        input_file = open(file_name, 'r')\n\n    # The intensities\n    intensities = {}\n\n    header_index = None\n    for line_nb, line in enumerate(input_file):\n        row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n        if line_nb == 0:\n            # This is the header\n            header_index = dict([\n                (col_name, i) for i, col_name in enumerate(row)\n            ])\n            # Check the column names\n            for col_name in {\"SNP Name\", \"Sample ID\", \"X\", \"Y\", \"Chr\"}:\n                if col_name not in header_index:\n                    msg = \"{}: no column named {}\".format(file_name, col_name)\n                    raise ProgramError(msg)\n        else:\n            # This is the data\n            # Check if we want this sample and this marker\n            sampleID = row[header_index[\"Sample ID\"]]\n            markerID = row[header_index[\"SNP Name\"]]\n            chromosome = encode_chr(row[header_index[\"Chr\"]])\n            if chromosome not in {23, 24}:\n                # Not good chromsoome\n                continue\n            if sampleID not in needed_samples_gender:\n                # Sample not needed\n                continue\n            if markerID not in needed_markers_chr:\n                # Marker not needed\n                continue\n\n            if sampleID not in intensities:\n                # First time we see this sample\n                intensities[sampleID] = [0, 0, 0, 0]\n\n            # We get the intensities\n            allele_a = row[header_index[\"X\"]]\n            allele_b = row[header_index[\"Y\"]]\n\n            # Check for NaN\n            if allele_a == \"NaN\" or allele_b == \"NaN\":\n                continue\n            try:\n                allele_a = float(allele_a)\n                allele_b = float(allele_b)\n            except ValueError:\n                msg = \"{}: {} and {}: wrong intensities\".format(file_name,\n                                                                allele_a,\n                                                                allele_b)\n                raise ProgramError(msg)\n\n            if chromosome == 23:\n                # Chromosome 23\n                intensities[sampleID][0] += allele_a + allele_b\n                intensities[sampleID][1] += 1\n            else:\n                # Chromosome 24\n                intensities[sampleID][2] += allele_a + allele_b\n                intensities[sampleID][3] += 1\n\n    # Closing the input file\n    input_file.close()\n\n    # Creating the data structure\n    data = []\n    for sampleID in intensities.iterkeys():\n        sum_chr_23, nb_chr_23, sum_chr_24, nb_chr_24 = intensities[sampleID]\n        status = \"OK\"\n        if sampleID in sex_problems:\n            status = \"Problem\"\n        try:\n            data.append((sampleID, sum_chr_23 / nb_chr_23, sum_chr_24 /\n                         nb_chr_24, needed_samples_gender[sampleID], status))\n        except ZeroDivisionError:\n            msg = \"0 marker on chr23 or chr24\"\n            raise ProgramError(msg)\n\n    data = np.array(\n        data,\n        dtype=[(\"sampleID\", \"a{}\".format(max([len(i[0]) for i in data]))),\n               (\"chr23\", float),\n               (\"chr24\", float),\n               (\"gender\", \"a{}\".format(max([len(i[3]) for i in data]))),\n               (\"status\", \"a{}\".format(max([len(i[4]) for i in data])))],\n    )\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkArgs(args):\n    # Checking if there are input files\n    if args.summarized_intensities is None:\n        if args.bfile is None and args.intensities is None:\n            msg = (\"need to specify either '--bfile' and '--intensities', or \"\n                   \"'--summarized-intensities'\")\n            raise ProgramError(msg)\n\n        # Checking the fam file bim\n        for suffix in {\".bim\", \".fam\"}:\n            if not os.path.isfile(args.bfile + suffix):\n                msg = \"{}: no such file\".format(args.bfile + suffix)\n                raise ProgramError(msg)\n\n        # Checking the intensity file\n        if not os.path.isfile(args.intensities):\n            msg = \"{}: no such file\".format(args.intensities)\n            raise ProgramError(msg)\n    else:\n        if args.bfile is not None or args.intensities is not None:\n            msg = (\"need to specify either '--bfile' and '--intensities', or \"\n                   \"'--summarized-intensities'\")\n            raise ProgramError(msg)\n\n        for suffix in {\".ok_females.txt\", \".ok_males.txt\", \".ok_unknowns.txt\",\n                       \".problematic_females.txt\", \".problematic_males.txt\",\n                       \".problematic_unknowns.txt\"}:\n            if not os.path.isfile(args.summarized_intensities + suffix):\n                msg = \"{}: no such file\".format(args.summarized_intensities +\n                                                suffix)\n                raise ProgramError(msg)\n\n    # Checking the sex problem file\n    if args.sex_problems is not None:\n        if not os.path.isfile(args.sex_problems):\n            msg = \"{}: no such file\".format(args.sex_problems)\n            raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef safe_main():\n    try:\n        main()\n    except KeyboardInterrupt:\n        logger.info(\"Cancelled by user\")\n        sys.exit(0)\n    except ProgramError as e:\n        logger.error(e.message)\n        parser.error(e.message)", "response": "A safe version of the main function that catches ProgramError and exits."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a QuerySet with the given arguments and keyword arguments.", "response": "def filter(self, *args, **kwargs):\n\t\t\"\"\"If id or pk was specified as a kwargs, return even if it's deleteted.\"\"\"\n\t\tif 'pk' in kwargs or 'id' in kwargs:\n\t\t\treturn self.all_with_deleted().filter(*args, **kwargs)\n\t\treturn self.get_query_set().filter(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the popcorn JSON and builds a sane data model out of it", "response": "def preprocess(self, data):\n        \"\"\"\n        Processes popcorn JSON and builds a sane data model out of it\n        @param data : The popcorn editor project json blob\n        \"\"\"\n\n        print 'Beginning pre-process...'\n        for url, video in data['media'][0]['clipData'].iteritems():\n            print 'Downloading {0} from {1}.'.format(video['title'], url)\n\n            # Removes all white spaces and non alphanumeric chars from title\n            video['title'] = re.sub(\n                '[^\\w\\.]',\n                '',\n                video['title']\n            ) + '.webm'\n\n            urllib.urlretrieve(url, video['title'])\n            self.base_videos.append(video['title'])\n            print 'video downloaded as %s!' % video['title']\n        print 'All videos downloaded.'\n\n        events = [event for track in data['media'][0]['tracks']\n                  for event in track['trackEvents']]\n\n        for event in events:\n            if event['type'] == 'skip' or event['type'] == 'loopPlugin':\n                edit = TrackEdit(event['type'], event['popcornOptions'])\n\n                self.track_edits.append(edit)\n\n            if event['type'] == 'text' or event['type'] == 'image':\n                item = TrackItem(event['type'], event['popcornOptions'])\n\n                item.options['start_stamp'] = \\\n                    item.options['start']\n                item.options['end_stamp'] = \\\n                    item.options['end']\n                item.options['x_px'] = percent_to_px(\n                    item.options['left'],\n                    self.size[0]\n                )\n                item.options['y_px'] = percent_to_px(\n                    item.options['top'],\n                    self.size[1]\n                )\n\n                self.track_items.append(item)\n\n            if event['type'] == 'sequencer':\n                video = TrackVideo(\n                    event['type'],\n                    event['popcornOptions']['source'][0],\n                    event['popcornOptions']\n                )\n                self.track_videos.append(video)\n\n        self.parse_duration()\n\n        cfilter = r'color=c={0}:s={1}x{2}:d={3};aevalsrc=0:d={4}'.format(\n            self.background_color,\n            self.size[0],\n            self.size[1],\n            self.duration,\n            self.duration,\n        )\n        call(['ffmpeg', '-filter_complex', cfilter, '-y',\n              self.current_video.name])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_duration(self):\n        for edit in self.track_edits:\n            if edit.edit_type == 'loopPlugin':\n                self.duration += (\n                    (edit.options['end'] -\n                     edit.options['start']) *\n                    float(edit.options['loop'])\n                )", "response": "Parses the duration of the events that have been created by loop and skip events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap long lines to a maximum length of 80.", "response": "def wrap_lines(content, length=80):\n    \"\"\"Wraps long lines to a maximum length of 80.\n\n    :param content: the content to wrap.\n    :param legnth: the maximum length to wrap the content.\n\n    :type content: str\n    :type length: int\n\n    :returns: a string containing the wrapped content.\n    :rtype: str\n\n    \"\"\"\n    return \"\\n\".join(textwrap.wrap(content, length, break_long_words=False))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting a number in the scientific notation for LaTeX.", "response": "def format_numbers(number, prefix=\"\"):\n    \"\"\"Formats number in the scientific notation for LaTeX.\n\n    :param number: the number to format.\n    :param prefix: a prefix to add before the number (e.g. \"p < \").\n\n    :type number: str\n    :type prefix: str\n\n    :returns: a string containing the scientific notation of the number.\n    :rtype: str\n\n    \"\"\"\n    # Matching\n    r = re.match(r\"^([-+]?\\d*\\.\\d+|\\d+)e([-+]?\\d+)$\", number)\n\n    # Nothing matched\n    if not r:\n        if prefix != \"\":\n            return \"$\" + prefix + number + \"$\"\n        else:\n            return number\n\n    # Getting the coefficient and the exponent\n    coefficient = r.group(1)\n    exponent = int(r.group(2))\n\n    return \"$\" + prefix + coefficient + r\"\\times 10^{\" + str(exponent) + \"}$\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sanitize_fig_name(name):\n    name, extension = os.path.splitext(name)\n    return \"{\" + name + \"}\" + extension", "response": "Sanitize the name of a figure file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsanitizes TeX text. :param original_text: the text to sanitize for LaTeX. :type original_text: str :returns: the sanitize text. Text is sanitized by following these steps: 1. Replaces ``\\\\` by ``\\\\textbackslash`` 2. Escapes certain characters (such as ``$``, ``%``, ``_``, ``}``, ``{``, ``&`` and ``#``) by adding a backslash (*e.g.* from ``&`` to ``\\\\&``). 3. Replaces special characters such as ``~`` by the LaTeX equivalent (*e.g.* from ``~`` to ``$\\\\sim$``).", "response": "def sanitize_tex(original_text):\n    \"\"\"Sanitize TeX text.\n\n    :param original_text: the text to sanitize for LaTeX.\n\n    :type original_text: str\n\n    :returns: the sanitize text.\n\n    Text is sanitized by following these steps:\n\n    1. Replaces ``\\\\` by ``\\\\textbackslash``\n    2. Escapes certain characters (such as ``$``, ``%``, ``_``, ``}``, ``{``,\n       ``&`` and ``#``) by adding a backslash (*e.g.* from ``&`` to ``\\\\&``).\n    3. Replaces special characters such as ``~`` by the LaTeX equivalent\n       (*e.g.* from ``~`` to ``$\\\\sim$``).\n\n    \"\"\"\n    # The backslashes\n    sanitized_tex = original_text.replace(\"\\\\\", r\"\\textbackslash \")\n\n    # Escaping\n    sanitized_tex = re.sub(r\"([{}])\".format(\"\".join(_escaped_char)),\n                           r\"\\\\\\g<1>\", sanitized_tex)\n\n    # Replacing\n    for character, mod in _char_mod.items():\n        sanitized_tex = sanitized_tex.replace(character, mod)\n\n    return sanitized_tex"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef contextMenuEvent(self, event):\n        menu = QtWidgets.QPlainTextEdit.createStandardContextMenu(self)\n        mg = self.getGlobalsMenu()\n\n        a0 = menu.actions()[0]\n        menu.insertMenu(a0, mg)\n        menu.insertSeparator(a0)\n\n        menu.addSeparator()\n        a = QtWidgets.QAction('Show line numbers', menu)\n        l = self.codeEditor.lineNumbers\n        a.setCheckable(True)\n        a.setChecked(l.isVisible())\n        a.triggered.connect(lambda checked: l.show() if checked else l.hide())\n        menu.addAction(a)\n\n        menu.addSeparator()\n        a = QtWidgets.QAction('Save to file', menu)\n        a.triggered.connect(self.saveToFile)\n        menu.addAction(a)\n\n        menu.exec_(event.globalPos())", "response": "Add context menu action"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the current text to file", "response": "def saveToFile(self):\n        \"\"\"\n        Save the current text to file\n        \"\"\"\n        filename = self.codeEditor.dialog.getSaveFileName()\n        if filename and filename != '.':\n            with open(filename, 'w') as f:\n                f.write(self.toPlainText())\n            print('saved script under %s' % filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _updateNumbers(self, linenumers):\n        b = self.blockCount()\n        c = b - linenumers\n        if c > 0:\n            # remove lines numbers\n            for _ in range(c):\n                # remove last line:\n                self.setFocus()\n                storeCursorPos = self.textCursor()\n                self.moveCursor(\n                    QtGui.QTextCursor.End,\n                    QtGui.QTextCursor.MoveAnchor)\n                self.moveCursor(\n                    QtGui.QTextCursor.StartOfLine,\n                    QtGui.QTextCursor.MoveAnchor)\n                self.moveCursor(\n                    QtGui.QTextCursor.End,\n                    QtGui.QTextCursor.KeepAnchor)\n                self.textCursor().removeSelectedText()\n                self.textCursor().deletePreviousChar()\n                self.setTextCursor(storeCursorPos)\n        elif c < 0:\n            # add line numbers\n            for i in range(-c):\n                self.appendPlainText(str(b + i + 1))", "response": "Update the text cursor with the number of the line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish(self, payload):\n        '''Publish payload to the topic\n\n        .. note:: If you publishes just after creating Publisher instance, it will causes\n           lost of message. You have to add sleep if you just want to publish once.\n\n           >>> pub = jps.Publisher('topic')\n           >>> time.sleep(0.1)\n           >>> pub.publish('{data}')\n\n        :param payload: data to be published. This is ok if the data is not json.\n        '''\n        if self._serializer is not None:\n            payload = self._serializer(payload)\n        if self._topic == '*':\n            # special case for publish everything\n            msg = payload\n        else:\n            msg = '{topic} {data}'.format(topic=self._topic, data=payload)\n        self._socket.send(cast_bytes(msg))", "response": "Publish a payload to the topic\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(self, input):\n        demod = self.demod.main(input)\n        match = self.match.main(demod)\n\n        return match", "response": "Main method for demodulator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self, hostname, family, hostaddr):\n        self.client_ip = hostaddr[0]\n        self.client_port = hostaddr[1]\n        self.time_start = time.time()\n        logger.debug('<{}> Connect from {}[{}]:{}'.format(\n            self.id, hostname, self.client_ip, self.client_port))\n        return Milter.CONTINUE", "response": "Connect to a new instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef envrcpt(self, rcpt, *params):\n        if rcpt.startswith('<'):\n            rcpt = rcpt[1:]\n        if rcpt.endswith('>'):\n            rcpt = rcpt[:-1]\n        if self.recipient_delimiter_re:\n            rcpt = self.recipient_delimiter_re.sub('', rcpt)\n        if rcpt not in self.recipients:\n            self.recipients.append(rcpt)\n            logger.debug('<{}> Received RCPT {}'.format(self.id, rcpt))\n        return Milter.CONTINUE", "response": "Process an environment variable rcpt."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore all message headers optionally clean them up.", "response": "def header(self, name, value):\n        \"\"\"\n        Store all message headers, optionally clean them up.\n\n        This simply stores all message headers so we can send them to DSPAM.\n        Additionally, headers that have the same prefix as the ones we're\n        about to add are deleted.\n\n        \"\"\"\n        self.message += \"{}: {}\\r\\n\".format(name, value)\n        logger.debug('<{}> Received {} header'.format(self.id, name))\n        if name.lower().startswith(self.header_prefix.lower()):\n            self.remove_headers.append(name)\n            logger.debug('<{}> Going to remove {} header'.format(\n                self.id, name))\n        return Milter.CONTINUE"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eom(self):\n        for header in self.remove_headers:\n            self.chgheader(header, 1, '')\n            logger.info('<{}> Removing existing {} header'.format(\n                self.id, header))\n\n        queue_id = self.getsymval('i')\n        logger.debug(\n            '<{}> Sending message with MTA queue id {} to DSPAM'.format(\n                self.id, queue_id))\n\n        try:\n            if not self.dspam:\n                self.dspam = DspamClient()\n                self.dspam.connect()\n                self.dspam.lhlo()\n                if not self.dspam.dlmtp:\n                    logger.warning(\n                        '<{}> Connection to DSPAM is established, but DLMTP '\n                        'seems unavailable'.format(self.id))\n            else:\n                self.dspam.rset()\n        except DspamClientError as err:\n            logger.error(\n                '<{}> An error ocurred while connecting to DSPAM: {}'.format(\n                    self.id, err))\n            return Milter.TEMPFAIL\n\n        try:\n            self.dspam.mailfrom(client_args='--process --deliver=summary')\n            if self.static_user:\n                self.dspam.rcptto((self.static_user,))\n            else:\n                self.dspam.rcptto(self.recipients)\n            self.dspam.data(self.message)\n        except DspamClientError as err:\n            logger.error(\n                '<{}> An error ocurred while talking to DSPAM: {}'.format(\n                    self.id, err))\n            return Milter.TEMPFAIL\n\n        # Clear caches\n        self.message = ''\n        self.recipients = []\n\n        # With multiple recipients, if different verdicts were returned, always\n        #   use the 'lowest' verdict as final, so mail is not lost unexpected.\n        final_verdict = None\n        for rcpt in self.dspam.results:\n            results = self.dspam.results[rcpt]\n            logger.info(\n                '<{0}> DSPAM returned results for message with queue id {1} '\n                'and RCPT {2}: {3}'.format(\n                    self.id, queue_id, rcpt,\n                    ' '.join('{}={}'.format(k, v) for k, v in results.iteritems())))\n            verdict = self.compute_verdict(results)\n            if final_verdict is None or verdict < final_verdict:\n                final_verdict = verdict\n                final_results = results\n\n        if final_verdict == self.VERDICT_REJECT:\n            logger.info(\n                '<{0}> Rejecting message with queue id {1} based on DSPAM '\n                'results: user={2[user]} class={2[class]} '\n                'confidence={2[confidence]}'.format(\n                    self.id, queue_id, final_results))\n            self.setreply('550', '5.7.1', 'Message is {0[class]}'.format(\n                final_results))\n            return Milter.REJECT\n        elif final_verdict == self.VERDICT_QUARANTINE:\n            logger.info(\n                '<{0}> Quarantining message with queue id {1} based on DSPAM '\n                'results: user={2[user]} class={2[class]} '\n                'confidence={2[confidence]}'.format(\n                    self.id, queue_id, final_results))\n            self.add_dspam_headers(final_results)\n            self.quarantine('Message is {0[class]} according to DSPAM'.format(\n                final_results))\n            return Milter.ACCEPT\n        else:\n            logger.info(\n                '<{0}> Accepting message with queue id {1} based on DSPAM '\n                'results: user={2[user]} class={2[class]} '\n                'confidence={2[confidence]}'.format(\n                    self.id, queue_id, final_results))\n            self.add_dspam_headers(final_results)\n            return Milter.ACCEPT", "response": "Sends the message to DSPAM for classification and returns a Milter.TEMPFAIL if the message is not sent to the DSPAM."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the verdict for a specific resource based on the results dictionary.", "response": "def compute_verdict(self, results):\n        \"\"\"\n        Match results to the configured reject, quarantine and accept classes,\n        and return a verdict based on that.\n\n        The verdict classes are matched in the order: reject_classes,\n        quarantine_classes, accept_classes. This means that you can configure\n        different verdicts for different confidence results, for instance:\n        reject_classes= Spam:0.99       # Reject obvious spam\n        quarantine_classes = Spam:0.7   # Quarantine spam with confidence\n                                        #   between 0.7 and 0.99\n        accept_classes = Spam           # Accept low confidence spam (good\n                                        #   for FP and retraining)\n\n        Args:\n        results -- A results dictionary from DspamClient.\n\n        \"\"\"\n        if results['class'] in self.reject_classes:\n            threshold = self.reject_classes[results['class']]\n            if float(results['confidence']) >= threshold:\n                logger.debug(\n                    '<{0}> Suggesting to reject the message based on DSPAM '\n                    'results: user={1[user]}, class={1[class]}, '\n                    'confidence={1[confidence]}'.format(self.id, results))\n                return self.VERDICT_REJECT\n\n        if results['class'] in self.quarantine_classes:\n            threshold = self.quarantine_classes[results['class']]\n            if float(results['confidence']) >= threshold:\n                logger.debug(\n                    '<{0}> Suggesting to quarantine the message based on '\n                    'DSPAM results: user={1[user]}, class={1[class]}, '\n                    'confidence={1[confidence]}'.format(self.id, results))\n                return self.VERDICT_QUARANTINE\n\n        if results['class'] in self.accept_classes:\n            threshold = self.accept_classes[results['class']]\n            if float(results['confidence']) >= threshold:\n                logger.debug(\n                    '<{0}> Suggesting to accept the message based on DSPAM '\n                    'results: user={1[user]}, class={1[class]}, '\n                    'confidence={1[confidence]}'.format(self.id, results))\n                return self.VERDICT_ACCEPT\n\n        logger.debug(\n            '<{0}> Suggesting to accept the message, no verdict class matched '\n            'DSPAM results: user={1[user]}, class={1[class]}, '\n            'confidence={1[confidence]}'.format(self.id, results))\n        return self.VERDICT_ACCEPT"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat DSPAM headers with passed results and add them to the message.", "response": "def add_dspam_headers(self, results):\n        \"\"\"\n        Format DSPAM headers with passed results, and add them to the message.\n\n        Args:\n        results -- A results dictionary from DspamClient.\n        \"\"\"\n        for header in self.headers:\n            hname = self.header_prefix + header\n            if header.lower() in results:\n                hvalue = results[header.lower()]\n                logger.debug(\n                    '<{}> Adding header {}: {}'.format(self.id, hname, hvalue))\n                self.addheader(hname, hvalue)\n            elif header == 'Processed':\n                # X-DSPAM-Processed: Wed Dec 12 02:19:23 2012\n                hvalue = datetime.datetime.now().strftime(\n                    '%a %b %d %H:%M:%S %Y')\n                logger.debug(\n                    '<{}> Adding header {}: {}'.format(self.id, hname, hvalue))\n                self.addheader(hname, hvalue)\n            else:\n                logger.warning(\n                    '<{}> Not adding header {}, no data available in '\n                    'DSPAM results'.format(self.id, hname))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing and configure the object with the configuration from the given file.", "response": "def configure(self, config_file):\n        \"\"\"\n        Parse configuration, and setup objects to use it.\n\n        \"\"\"\n        cfg = configparser.RawConfigParser()\n        try:\n            cfg.readfp(open(config_file))\n        except IOError as err:\n            logger.critical(\n                'Error while reading config file {}: {}'.format(\n                    config_file, err.strerror))\n            sys.exit(1)\n        logger.info('Parsed config file ' + config_file)\n\n        # Extract user-defined log level from configuration\n        if cfg.has_option('milter', 'loglevel'):\n            loglevel = cfg.get('milter', 'loglevel')\n            loglevel_numeric = getattr(logging, loglevel.upper(), None)\n            if not isinstance(loglevel_numeric, int):\n                logger.critical(\n                    'Config contains unsupported loglevel: ' + loglevel)\n                exit(1)\n            rl = logging.getLogger()\n            rl.setLevel(loglevel_numeric)\n            logger.debug(\n                'Config option applied: milter->loglevel: {}'.format(loglevel))\n\n        # Apply all config options to their respective classes\n        section_class_map = {\n            'milter': self,\n            'dspam': DspamClient,\n            'classification': DspamMilter,\n        }\n        for section in cfg.sections():\n            try:\n                class_ = section_class_map[section]\n            except KeyError:\n                logger.warning('Config contains unknown section: ' + section)\n                continue\n            logger.debug('Handling config section: ' + section)\n\n            dict_options = [\n                'headers',\n                'reject_classes',\n                'quarantine_classes',\n                'accept_classes'\n            ]\n            for option in cfg.options(section):\n                # Kludge: static_user needs to be set on the milter,\n                #   not on the client\n                if section == 'dspam' and option == 'static_user':\n                    value = cfg.get('dspam', 'static_user')\n                    DspamMilter.static_user = value\n                    logger.debug(\n                        'Config option applied: dspam->static_user: {}'.format(\n                            value))\n                    continue\n\n                if not hasattr(class_, option):\n                    logger.warning(\n                        'Config contains unknown option: {}->{}'.format(\n                            section, option))\n                    continue\n\n                value = cfg.get(section, option)\n                if option in dict_options:\n                    value = utils.config_str2dict(value)\n                elif value.lower() in ['false', 'no']:\n                    value = False\n                elif value.lower() in ['true', 'yes']:\n                    value = True\n\n                setattr(class_, option, value)\n                logger.debug(\n                    'Config option applied: {}->{}: {}'.format(\n                        section, option, value))\n        logger.debug('Configuration completed')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of instances from your account.", "response": "def list_instances(\n        deployment_name='',\n        cloud_name='EC2 us-east-1',\n        view='tiny',\n        ):\n    \"\"\"\n    Returns a list of instances from your account.\n\n    :param str deployment_name: If provided, only lists servers in the\n        specified deployment.\n\n    :param str cloud_name: The friendly name for a RightScale-supported cloud.\n        E.g. ``EC2 us-east-1``, ``us-west-2``, etc...\n\n    :param str view: The level of detail to request of RightScale.  Valid\n        values are ``default``, ``extended``, ``full``, ``full_inputs_2_0``,\n        ``tiny``.  Defaults to ``tiny``.\n\n    \"\"\"\n    api = get_api()\n    cloud = find_by_name(api.clouds, cloud_name)\n    filters = ['state==operational']\n    if deployment_name:\n        deploy = find_by_name(api.deployments, deployment_name)\n        filters.append('deployment_href==' + deploy.href)\n    params = {'filter[]': filters, 'view': view}\n    return cloud.instances.index(params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_script_on_server(\n        script_name,\n        server_name,\n        inputs=None,\n        timeout_s=10,\n        output=sys.stdout\n        ):\n    \"\"\"\n    Runs a RightScript and polls for status.\n\n    Sample usage::\n\n        from rightscale import run_script_on_server\n        run_script_on_server(\n                'my cool bob lol script',\n                'some server',\n                inputs={'BOB': 'blah blah', 'LOL': 'fubar'},\n                )\n\n    Sample output::\n\n        status: Querying tags\n        status: Querying tags\n        status: Preparing execution\n        status: RightScript: 'my cool bob lol script'\n        status: completed: my cool bob lol script\n\n    Defaults to printing status message to stdout, but will accept any object\n    that implements ``write()`` passed in to :attr:`output`.\n    \"\"\"\n    api = get_api()\n    script = find_by_name(api.right_scripts, script_name)\n    server = find_by_name(api.servers, server_name)\n    path = server.links['current_instance'] + '/run_executable'\n\n    data = {\n            'right_script_href': script.href,\n            }\n    if inputs:\n        for k, v in inputs.items():\n            data['inputs[%s]' % k] = 'text:' + v\n    response = api.client.post(path, data=data)\n    status_path = response.headers['location']\n    for i in range(timeout_s):\n        status = api.client.get(status_path).json()\n        summary = status.get('summary', '')\n        output.write('status: %s\\n' % summary)\n        if summary.startswith('completed'):\n            return\n        time.sleep(1)\n    output.write('Done waiting. Poll %s for status.\\n' % status_path)", "response": "Runs a RightScript on a server and waits for status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for resources in the hierarchy by path.", "response": "def get_by_path(path, first=False):\n    \"\"\"\n    Search for resources using colon-separated path notation.\n\n    E.g.::\n\n        path = 'deployments:production:servers:haproxy'\n        haproxies = get_by_path(path)\n\n    :param bool first: Always use the first returned match for all intermediate\n        searches along the path.  If this is ``False`` and an intermediate\n        search returns multiple hits, an exception is raised.\n\n    \"\"\"\n    api = get_api()\n\n    cur_res = api\n    parts = path.split(':')\n    for part in parts:\n        res = getattr(cur_res, part, None)\n        if not res:\n            # probably the name of the res to find\n            res = find_by_name(cur_res, part)\n        cur_res = res\n\n    index = getattr(cur_res, 'index', None)\n    if index:\n        return index()\n    return cur_res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Rizk(mp, dp, rhog, D):\n    r'''Calculates saltation velocity of the gas for pneumatic conveying,\n    according to [1]_ as described in [2]_ and many others.\n\n    .. math::\n        \\mu=\\left(\\frac{1}{10^{1440d_p+1.96}}\\right)\\left(Fr_s\\right)^{1100d_p+2.5}\n\n        Fr_s = \\frac{V_{salt}}{\\sqrt{gD}}\n\n        \\mu = \\frac{m_p}{\\frac{\\pi}{4}D^2V \\rho_f}\n\n    Parameters\n    ----------\n    mp : float\n        Solid mass flow rate, [kg/s]\n    dp : float\n        Particle diameter, [m]\n    rhog : float\n        Gas density, [kg/m^3]\n    D : float\n        Diameter of pipe, [m]\n\n    Returns\n    -------\n        V : float\n            Saltation velocity of gas, [m/s]\n\n    Notes\n    -----\n    Model is rearanged to be explicit in terms of saltation velocity\n    internally.\n\n    Examples\n    --------\n    Example is from [3]_.\n\n    >>> Rizk(mp=0.25, dp=100E-6, rhog=1.2, D=.078)\n    9.8833092829357\n\n    References\n    ----------\n    .. [1] Rizk, F. \"Pneumatic conveying at optimal operation conditions and a\n       solution of Bath's equation.\" Proceedings of Pneumotransport 3,\n       paper D4. BHRA Fluid Engineering, Cranfield, England (1973)\n    .. [2] Klinzing, G. E., F. Rizk, R. Marcus, and L. S. Leung. Pneumatic\n       Conveying of Solids: A Theoretical and Practical Approach.\n       Springer, 2013.\n    .. [3] Rhodes, Martin J. Introduction to Particle Technology. Wiley, 2013.\n    '''\n    alpha = 1440*dp + 1.96\n    beta = 1100*dp + 2.5\n    term1 = 1./10**alpha\n    Frs_sorta = 1/(g*D)**0.5\n    expression1 = term1*Frs_sorta**beta\n    expression2 = mp/rhog/(pi/4*D**2)\n    V = (expression2/expression1)**(1./(1 + beta))\n    return V", "response": "r Returns a base class that calculates the saltation velocity of the given gas for the given mass flow rate and gas diameter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Matsumoto_1977(mp, rhop, dp, rhog, D, Vterminal=1):\n    r'''Calculates saltation velocity of the gas for pneumatic conveying,\n    according to [1]_ and reproduced in [2]_, [3]_, and [4]_.\n\n    First equation is used if third equation yeilds d* higher than dp.\n    Otherwise, use equation 2.\n\n    .. math::\n        \\mu = 5560\\left(\\frac{d_p}{D}\\right)^{1.43}\\left(\\frac{Fr_s}{10}\\right)^4\n\n        \\mu = 0.373 \\left(\\frac{\\rho_p}{\\rho_f}\\right)^{1.06}\\left(\\frac{Fr_p}\n        {10}\\right)^{-3.7}\\left(\\frac{Fr_s}{10}\\right)^{3.61}\n\n        \\frac{d_p^*}{D} = 1.39\\left(\\frac{\\rho_p}{\\rho_f}\\right)^{-0.74}\n\n        Fr_s = \\frac{V_{salt}}{\\sqrt{gD}}\n\n        Fr_p = \\frac{V_{terminal}}{\\sqrt{gd_p}}\n\n        \\mu = \\frac{m_p}{\\frac{\\pi}{4}D^2V \\rho_f}\n\n    Parameters\n    ----------\n    mp : float\n        Solid mass flow rate, [kg/s]\n    rhop : float\n        Particle density, [kg/m^3]\n    dp : float\n        Particle diameter, [m]\n    rhog : float\n        Gas density, [kg/m^3]\n    D : float\n        Diameter of pipe, [m]\n    Vterminal : float\n        Terminal velocity of particle settling in gas, [m/s]\n\n    Returns\n    -------\n        V : float\n            Saltation velocity of gas, [m/s]\n\n    Notes\n    -----\n    Model is rearanged to be explicit in terms of saltation velocity\n    internally.\n\n    Examples\n    --------\n    Example is only a self-test.\n\n    Course routine, terminal velocity input is from example in [2].\n\n    >>> Matsumoto_1977(mp=1., rhop=1000., dp=1E-3, rhog=1.2, D=0.1, Vterminal=5.24)\n    16.64284834446686\n\n    References\n    ----------\n    .. [1] Matsumoto, Shigeru, Makoto Kikuta, and Siro Maeda. \"Effect of\n       Particle Size on the Minimum Transport Velocity for Horizontal Pneumatic\n       Conveying of Solids.\" Journal of Chemical Engineering of Japan 10,\n       no. 4 (1977): 273-79. doi:10.1252/jcej.10.273.\n    .. [2] Klinzing, G. E., F. Rizk, R. Marcus, and L. S. Leung. Pneumatic\n       Conveying of Solids: A Theoretical and Practical Approach.\n       Springer, 2013.\n    .. [3] Gomes, L. M., and A. L. Amarante Mesquita. \"On the Prediction of\n       Pickup and Saltation Velocities in Pneumatic Conveying.\" Brazilian\n       Journal of Chemical Engineering 31, no. 1 (March 2014): 35-46.\n       doi:10.1590/S0104-66322014000100005\n    .. [4] Rabinovich, Evgeny, and Haim Kalman. \"Threshold Velocities of\n       Particle-Fluid Flows in Horizontal Pipes and Ducts: Literature Review.\"\n       Reviews in Chemical Engineering 27, no. 5-6 (January 1, 2011).\n       doi:10.1515/REVCE.2011.011.\n    '''\n    limit = 1.39*D*(rhop/rhog)**-0.74\n    A = pi/4*D**2\n    if limit < dp:\n        # Corase routine\n        Frp = Vterminal/(g*dp)**0.5\n        Frs_sorta = 1./(g*D)**0.5\n        expression1 = 0.373*(rhop/rhog)**1.06*(Frp/10.)**-3.7*(Frs_sorta/10.)**3.61\n        expression2 = mp/rhog/A\n        V = (expression2/expression1)**(1/4.61)\n    else:\n        Frs_sorta = 1./(g*D)**0.5\n        expression1 = 5560*(dp/D)**1.43*(Frs_sorta/10.)**4\n        expression2 = mp/rhog/A\n        V = (expression2/expression1)**(0.2)\n    return V", "response": "r Calculates the saltation velocity of the pneumatic conveying of a given mass flow rate with the given particle density dp and D."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Weber(mp, rhop, dp, rhog, D, Vterminal=4):\n    r'''Calculates saltation velocity of the gas for pneumatic conveying,\n    according to [1]_ as described in [2]_, [3]_, [4]_, and [5]_.\n\n    If Vterminal is under 3 m/s, use equation 1; otherwise, equation 2.\n\n    .. math::\n        Fr_s = \\left(7 + \\frac{8}{3}V_{terminal}\\right)\\mu^{0.25}\n        \\left(\\frac{d_p}{D}\\right)^{0.1}\n\n        Fr_s = 15\\mu^{0.25}\\left(\\frac{d_p}{D}\\right)^{0.1}\n\n        Fr_s = \\frac{V_{salt}}{\\sqrt{gD}}\n\n        \\mu = \\frac{m_p}{\\frac{\\pi}{4}D^2V \\rho_f}\n\n    Parameters\n    ----------\n    mp : float\n        Solid mass flow rate, [kg/s]\n    rhop : float\n        Particle density, [kg/m^3]\n    dp : float\n        Particle diameter, [m]\n    rhog : float\n        Gas density, [kg/m^3]\n    D : float\n        Diameter of pipe, [m]\n    Vterminal : float\n        Terminal velocity of particle settling in gas, [m/s]\n\n    Returns\n    -------\n        V : float\n            Saltation velocity of gas, [m/s]\n\n    Notes\n    -----\n    Model is rearanged to be explicit in terms of saltation velocity\n    internally.\n\n    Examples\n    --------\n    Examples are only a self-test.\n\n    >>> Weber(mp=1, rhop=1000., dp=1E-3, rhog=1.2, D=0.1, Vterminal=4)\n    15.227445436331474\n\n    References\n    ----------\n    .. [1] Weber, M. 1981. Principles of hydraulic and pneumatic conveying in\n       pipes. Bulk Solids Handling 1: 57-63.\n    .. [2] Rabinovich, Evgeny, and Haim Kalman. \"Threshold Velocities of\n       Particle-Fluid Flows in Horizontal Pipes and Ducts: Literature Review.\"\n       Reviews in Chemical Engineering 27, no. 5-6 (January 1, 2011).\n       doi:10.1515/REVCE.2011.011.\n    .. [3] Setia, G., S. S. Mallick, R. Pan, and P. W. Wypych. \"Modeling\n       Minimum Transport Boundary for Fluidized Dense-Phase Pneumatic Conveying\n       Systems.\" Powder Technology 277 (June 2015): 244-51.\n       doi:10.1016/j.powtec.2015.02.050.\n    .. [4] Bansal, A., S. S. Mallick, and P. W. Wypych. \"Investigating\n       Straight-Pipe Pneumatic Conveying Characteristics for Fluidized\n       Dense-Phase Pneumatic Conveying.\" Particulate Science and Technology\n       31, no. 4 (July 4, 2013): 348-56. doi:10.1080/02726351.2012.732677.\n    .. [5] Gomes, L. M., and A. L. Amarante Mesquita. \"On the Prediction of\n       Pickup and Saltation Velocities in Pneumatic Conveying.\" Brazilian\n       Journal of Chemical Engineering 31, no. 1 (March 2014): 35-46.\n       doi:10.1590/S0104-66322014000100005\n    '''\n    if Vterminal <= 3:\n        term1 = (7 + 8/3.*Vterminal)*(dp/D)**0.1\n    else:\n        term1 = 15.*(dp/D)**0.1\n    term2 = 1./(g*D)**0.5\n    term3 = mp/rhog/(pi/4*D**2)\n    V = (term1/term2*term3**0.25)**(1/1.25)\n    return V", "response": "r Returns a new object with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Geldart_Ling(mp, rhog, D, mug):\n    r'''Calculates saltation velocity of the gas for pneumatic conveying,\n    according to [1]_ as described in [2]_ and [3]_.\n\n    if Gs/D < 47000, use equation 1, otherwise use equation 2.\n\n    .. math::\n        V_{salt} = 1.5G_s^{0.465}D^{-0.01} \\mu^{0.055}\\rho_f^{-0.42}\n\n        V_{salt} = 8.7G_s^{0.302}D^{0.153} \\mu^{0.055}\\rho_f^{-0.42}\n\n        Fr_s = 15\\mu^{0.25}\\left(\\frac{d_p}{D}\\right)^{0.1}\n\n        Fr_s = \\frac{V_{salt}}{\\sqrt{gD}}\n\n        \\mu = \\frac{m_p}{\\frac{\\pi}{4}D^2V \\rho_f}\n\n        G_s = \\frac{m_p}{A}\n\n    Parameters\n    ----------\n    mp : float\n        Solid mass flow rate, [kg/s]\n    rhog : float\n        Gas density, [kg/m^3]\n    D : float\n        Diameter of pipe, [m]\n    mug : float\n        Gas viscosity, [Pa*S]\n\n    Returns\n    -------\n        V : float\n            Saltation velocity of gas, [m/s]\n\n    Notes\n    -----\n    Model is rearanged to be explicit in terms of saltation velocity\n    internally.\n\n    Examples\n    --------\n    >>> Geldart_Ling(1., 1.2, 0.1, 2E-5)\n    7.467495862402707\n\n    References\n    ----------\n    .. [1] Weber, M. 1981. Principles of hydraulic and pneumatic conveying in\n       pipes. Bulk Solids Handling 1: 57-63.\n    .. [2] Rabinovich, Evgeny, and Haim Kalman. \"Threshold Velocities of\n       Particle-Fluid Flows in Horizontal Pipes and Ducts: Literature Review.\"\n       Reviews in Chemical Engineering 27, no. 5-6 (January 1, 2011).\n       doi:10.1515/REVCE.2011.011.\n    .. [3] Gomes, L. M., and A. L. Amarante Mesquita. \"On the Prediction of\n       Pickup and Saltation Velocities in Pneumatic Conveying.\" Brazilian\n       Journal of Chemical Engineering 31, no. 1 (March 2014): 35-46.\n       doi:10.1590/S0104-66322014000100005\n    '''\n    Gs = mp/(pi/4*D**2)\n    if Gs/D <= 47000:\n        V = 1.5*Gs**0.465*D**-0.01*mug**0.055*rhog**-0.42\n    else:\n        V = 8.7*Gs**0.302*D**0.153*mug**0.055*rhog**-0.42\n    return V", "response": "r Geldart - Ling function for the base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_lines(x, fsamps, ax=None, downsample=100, **kwargs):\n    if ax is None:\n        ax = matplotlib.pyplot.gca()\n    if downsample < len(fsamps.T):\n        indices = numpy.random.choice(len(fsamps.T), downsample, replace=False)\n    else:\n        indices = numpy.arange(len(fsamps.T))\n    color = kwargs.pop('color', 'k')\n    alpha = kwargs.pop('alpha', 0.1)\n    for y in fsamps.T[indices]:\n        ax.plot(x, y, color=color, alpha=alpha, **kwargs)", "response": "Plots the function samples at each x as a set of line plots."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd content from source docs and user.", "response": "def add_content(self, more_content):\n        \"\"\"Add content from source docs and user.\"\"\"\n        sourcename = self.get_sourcename()\n\n        if self.object.docs:\n            self.add_line('', sourcename)\n            for line in self.object.docs.splitlines():\n                self.add_line(line, sourcename)\n\n        # add additional content (e.g. from document), if present\n        if more_content:\n            self.add_line('', sourcename)\n            for line, src in zip(more_content.data, more_content.items):\n                self.add_line(line, src[0], src[1])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate reST for member documentation.", "response": "def document_members(self, all_members=False):\n        # type: (bool) -> None\n        \"\"\"Generate reST for member documentation.\n\n        If *all_members* is True, do all members, else those given by\n        *self.options.members*.\n        \"\"\"\n        sourcename = self.get_sourcename()\n\n        want_all = all_members or self.options.members is ALL\n\n        if not want_all and not self.options.members:\n            return\n\n        expressions = [\n            SolidityObject.file == self.object.file,\n            SolidityObject.contract_name == self.object.name\n        ]\n\n        if not want_all:\n            members_inset = set()\n            should_include_fallback = False\n            should_include_constructor = False\n\n            for member in self.options.members:\n                if member == '<fallback>':\n                    should_include_fallback = True\n                elif member == 'constructor':\n                    should_include_constructor = True\n                elif member:\n                    members_inset.add(member)\n\n            expr = SolidityObject.name.in_(members_inset)\n            if should_include_fallback:\n                expr |= (SolidityObject.objtype == 'function') & (SolidityObject.name.is_null(True))\n            if should_include_constructor:\n                expr |= (SolidityObject.objtype == 'constructor') & (SolidityObject.name.is_null(True))\n\n            expressions.append(expr)\n\n        if self.options.exclude_members:\n            should_exclude_fallback = False\n            should_exclude_constructor = False\n\n            if '<fallback>' in self.options.exclude_members:\n                self.options.exclude_members.remove('<fallback>')\n                should_exclude_fallback = True\n            if 'constructor' in self.options.exclude_members:\n                self.options.exclude_members.remove('constructor')\n                should_exclude_constructor = True\n\n            expr = SolidityObject.name.not_in(self.options.exclude_members)\n\n            subexpr = SolidityObject.name.is_null(True)\n            if should_exclude_fallback:\n                subexpr &= (SolidityObject.objtype != 'function')\n            if should_exclude_constructor:\n                subexpr &= (SolidityObject.objtype != 'constructor')\n            expr |= subexpr\n\n            expressions.append(expr)\n\n        for member in SolidityObject.select().where(*expressions):\n            self.add_line('', sourcename)\n            full_mname = '{file}:{contract}{name}{paramtypes}'.format(\n                file=member.file,\n                contract='' if member.contract_name is None\n                else member.contract_name + '.',\n                name=member.name or '',\n                paramtypes='' if member.paramtypes is None\n                else '(' + member.paramtypes + ')',\n            )\n            documenter = all_solidity_documenters[member.objtype](\n                self.directive, full_mname, self.indent)\n            documenter.generate(all_members=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self, more_content=None, all_members=False):\n        # type: (Any, str, bool, bool) -> None\n        \"\"\"Generate reST for the object given by *self.name*, and possibly for\n        its members.\n\n        If *more_content* is given, include that content.\n        If *all_members* is True, document all members.\n        \"\"\"\n        directive = getattr(self, 'directivetype', self.objtype)\n\n        # parse components out of name\n        (file, _, namepath) = self.name.rpartition(':')\n        (contract_name, _, fullname) = namepath.partition('.')\n        (name, _, paramtypes) = fullname.partition('(')\n\n        # normalize components\n        name = name.strip() or None\n\n        if directive in ('contract', 'interface', 'library') and name is None:\n            name = contract_name\n            contract_name = None\n\n        paramtypes = ','.join(ptype.strip() for ptype in paramtypes.split(','))\n        paramtypes = re.sub(r'\\s+', ' ', paramtypes)\n        if paramtypes.endswith(')'):\n            paramtypes = paramtypes[:-1]\n\n        # build query\n        expressions = [\n            SolidityObject.objtype == directive,\n            SolidityObject.name == name,\n        ]\n\n        if file:\n            expressions.append(SolidityObject.file == file)\n        if contract_name:\n            expressions.append(SolidityObject.contract_name == contract_name)\n        if paramtypes:\n            expressions.append(SolidityObject.paramtypes == paramtypes)\n\n        # get associated object\n        query = SolidityObject.select().where(*expressions)\n        sol_objects = tuple(query)\n        if len(sol_objects) == 0:\n            logger.warning('{} {} could not be found via query:\\n{}'.format(\n                directive, self.name, ',\\n'.join(\n                    '  ' + str(expr.lhs.column_name) +\n                    str(expr.op) + ('' if expr.rhs is None else expr.rhs)\n                    for expr in expressions\n                )))\n            return\n        elif len(sol_objects) > 1:\n            logger.warning('multiple candidates for {} {} found:\\n{}'.format(\n                directive, self.name,\n                '\\n'.join('  ' + obj.signature for obj in sol_objects)))\n\n        self.object = sol_objects[0]\n\n        # begin rendering output\n        sourcename = self.get_sourcename()\n\n        # make sure that the result starts with an empty line.  This is\n        # necessary for some situations where another directive preprocesses\n        # reST and no starting newline is present\n        self.add_line('', sourcename)\n\n        # generate the directive header and options, if applicable\n        self.add_directive_header()\n\n        # make sure content is indented\n        # TODO: consider adding a source unit directive\n        self.indent += self.content_indent\n\n        # add all content (from docstrings, attribute docs etc.)\n        self.add_content(more_content)\n\n        # document members, if possible\n        if directive in ('contract', 'interface', 'library'):\n            self.add_line('', sourcename)\n            self.document_members(all_members)", "response": "Generate a reST for the object given by self. name and possibly for the object s members."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addParameter( self, k, r ):\n\n        if isinstance(r, six.string_types) or not isinstance(r, collections.Iterable):\n            # range is a single value (where a string constitutes a single value), make it a list\n            r = [ r ]\n        else:\n            if isinstance(r, collections.Iterable):\n                # range is an iterable, make into a list\n                r = list(r)\n\n        self._parameters[k] = r", "response": "Add a parameter to the experiment s parameter space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _crossProduct( self, ls ):\n        p = ls[0]\n        ds = []\n        if len(ls) == 1:\n            # last parameter, convert range to a dict\n            for i in self._parameters[p]:\n                dp = dict()\n                dp[p] = i\n                ds.append(dp)\n        else:\n            # for other parameters, create a dict combining each value in\n            # the range to a copy of the dict of other parameters\n            ps = self._crossProduct(ls[1:])\n            for i in self._parameters[p]:\n                for d in ps:\n                    dp = d.copy()\n                    dp[p] = i\n                    ds.append(dp)\n\n        # return the complete parameter space\n        return ds", "response": "Internal method to generate the cross product of all parameter names and values for the experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parameterSpace( self ):\n        ps = self.parameters()\n        if len(ps) == 0:\n            return []\n        else:\n            return self._crossProduct(ps)", "response": "Returns the parameter space of the experiment as a list of dicts with each dict mapping each parameter name to a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns an experiment over all the points in the parameter space.", "response": "def runExperiment( self, e ):\n        \"\"\"Run an experiment over all the points in the parameter space.\n        The results will be stored in the notebook.\n\n        :param e: the experiment\"\"\"\n\n        # create the parameter space\n        ps = self.parameterSpace()\n\n        # run the experiment at each point\n        nb = self.notebook()\n        for p in ps:\n            #print \"Running {p}\".format(p = p)\n            res = e.set(p).run()\n            nb.addResult(res)\n\n        # commit the results\n        nb.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        if self.start == 0 and self.stop == 0:\n            evaluated_data = np.empty(0, dtype=np.int64)\n        else:\n            evaluated_data = super(Index, self).evaluate(verbose, decode, passes, num_threads, apply_experimental)\n\n        return Index(evaluated_data, self.dtype, self.name)", "response": "Evaluates by creating an Index containing evaluated data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getsetting(setting, default):\n\n    setting = _DJANGO_SETTING_PREFIX + setting\n\n    try:\n        return getattr(settings, setting)\n    except:\n        return default", "response": "Get the value of a setting from the Django s settings module if not set fallback to default"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _setsetting(setting, default):\n    value = _getsetting(setting, default)\n    setattr(_self, setting, value)", "response": "Dynamically sets the variable named in setting to the value of default."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns Plink with the mind option.", "response": "def runPlink(options):\n    \"\"\"Run Plink with the ``mind`` option.\n\n    :param options: the options.\n\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # The plink command\n    plinkCommand = [\n        \"plink\",\n        \"--noweb\",\n        \"--bfile\" if options.is_bfile else \"--tfile\",\n        options.ifile,\n        \"--mind\",\n        str(options.mind),\n        \"--make-bed\",\n        \"--out\",\n        options.out,\n    ]\n\n    output = None\n    try:\n        output = subprocess.check_output(plinkCommand,\n                                         stderr=subprocess.STDOUT, shell=False)\n    except subprocess.CalledProcessError:\n        msg = \"plink: couldn't run plink\"\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the arguments and options for validity.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: a object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Check if we have the tped and the tfam files\n    required_file_extensions = {\".tfam\", \".tped\"}\n    if args.is_bfile:\n        required_file_extensions = {\".bed\", \".bim\", \".fam\"}\n    for fileName in [args.ifile + i for i in required_file_extensions]:\n        if not os.path.isfile(fileName):\n            msg = \"{}: no such file\".format(fileName)\n            raise ProgramError(msg)\n\n    # Check the mind option (between 0 and 1, inclusive)\n    if (args.mind < 0) or (args.mind > 1):\n        msg = \"mind=%f: must be between 0 and 1 (inclusive)\" % args.mind\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a cache key for the specified hashable arguments.", "response": "def hash_key(*args, **kwargs):\n    \"\"\"Return a cache key for the specified hashable arguments.\"\"\"\n\n    if kwargs:\n        return cachetools.keys._HashedTuple(args + _kwargs_mark + tuple(itertools.chain(sorted(kwargs.items()))))\n    else:\n        return cachetools.keys._HashedTuple(args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef typed_hash_key(*args, **kwargs):\n\n    key = hash_key(*args, **kwargs)\n    key += tuple(type(v) for v in args)\n    key += tuple(type(v) for _, v in sorted(kwargs.items()))\n    return key", "response": "Return a typed cache key for the specified hashable arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attribute_dependend_key(key_function, *dependencies):\n\n    def dependend_key_function(self, *args, **kwargs):\n        key = hash_key(*args, **kwargs)\n        \n        if len(dependencies) > 0:\n            dependecies_dict = {}\n            for dependency in dependencies:\n                value = eval(dependency)\n                dependecies_dict[dependency] = value\n            \n            key = key + cachetools.keys._HashedTuple(_dependency_mark + tuple(itertools.chain(sorted(dependecies_dict.items()))))\n\n        return key\n    \n    return dependend_key_function", "response": "Return a cache key for the specified hashable arguments with additional dependent arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AssertRC(self, rc=0):\n        assert self.rc == rc, \"Command `%s` failed. $? expected: %d, $? given: %d\" % (self.command, rc, self.rc)", "response": "Assert used for testing on certain RC values\n        is not None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef command(cls, command, stdin=None, shell=False):\n        if not shell and isinstance(command, str):\n            command = cls.shlex.split(command)\n        collate_original = None\n        try:\n            collate_original = cls.os.environ['LC_ALL']\n        except KeyError:\n            pass\n        cls.os.environ['LC_ALL'] = \"C\"  # Because of my czech locale, YUCK! :)\n        try:\n            process = cls.subprocess.Popen(command,\n                                           stdout=cls.subprocess.PIPE,\n                                           stderr=cls.subprocess.PIPE,\n                                           stdin=cls.subprocess.PIPE,\n                                           shell=shell)\n            (stdout, stderr) = process.communicate(stdin)\n        finally:\n            if collate_original:\n                cls.os.environ['LC_ALL'] = collate_original\n            else:\n                del cls.os.environ['LC_ALL']\n        return cls(stdout, stderr, stdin, process.returncode, command)", "response": "Runs specified command and returns a new instance of this class with the output."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef evaluate(self, verbose=False, decode=True, passes=None, num_threads=1,\n                 apply_experimental_transforms=True):\n        \"\"\"Evaluate the stored expression.\n\n        Parameters\n        ----------\n        verbose : bool, optional\n            Whether to print output for each Weld compilation step.\n        decode : bool, optional\n            Whether to decode the result\n        passes : list, optional\n            Which Weld optimization passes to apply\n        num_threads : int, optional\n            On how many threads to run Weld\n        apply_experimental_transforms : bool\n            Whether to apply the experimental Weld transforms.\n\n        Returns\n        -------\n        numpy.ndarray\n            Output of the evaluated expression.\n\n        \"\"\"\n        if isinstance(self.weld_expr, WeldObject):\n            old_context = dict(self.weld_expr.context)\n\n            for key in self.weld_expr.context.keys():\n                if LazyResult._cache.contains(key):\n                    self.weld_expr.context[key] = LazyResult._cache.get(key)\n\n            evaluated = self.weld_expr.evaluate(to_weld_vec(self.weld_type,\n                                                            self.ndim),\n                                                verbose,\n                                                decode,\n                                                passes,\n                                                num_threads,\n                                                apply_experimental_transforms)\n\n            self.weld_expr.context = old_context\n\n            return evaluated\n        else:\n            return self.weld_expr", "response": "Evaluate the stored expression."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert from NumPy dtype to Weld type.", "response": "def numpy_to_weld_type(np_dtype):\n    \"\"\"Convert from NumPy dtype to Weld type.\n\n    Note that support for strings is intended to be only for\n    Python 2 str and Python 3 bytes. No unicode.\n\n    Parameters\n    ----------\n    np_dtype : numpy.dtype or str\n        NumPy dtype.\n\n    Returns\n    -------\n    WeldType\n        Corresponding WeldType.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from baloo.weld import numpy_to_weld_type\n    >>> str(numpy_to_weld_type(np.dtype(np.int64)))\n    'i64'\n    >>> str(numpy_to_weld_type('?'))\n    'bool'\n\n    \"\"\"\n    if not isinstance(np_dtype, (str, bytes, np.dtype, type)):\n        raise TypeError('Can only convert np.dtype or str')\n\n    if isinstance(np_dtype, (str, bytes, type)):\n        np_dtype = np.dtype(np_dtype)\n\n    return _numpy_to_weld_type_mapping[np_dtype.char]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a development server for WSGI Application.", "response": "def run(filepath, wsgiapp, host, port, reload, interval,\n        static, static_root, static_dirs, lineprof, lineprof_file, validate):\n    \"\"\"\n    Runs a development server for WSGI Application.\n\n    Usage:\n\n        $ wsgicli run hello.py app -h 0.0.0.0 -p 5000 --reload\n\n        $ wsgicli run hello.py app --static --static-root /static/ --static-dirs ./static/\n    \"\"\"\n    insert_import_path_to_sys_modules(filepath)\n    module = SourceFileLoader('module', filepath).load_module()\n    app = getattr(module, wsgiapp)\n\n    if static:\n        from wsgi_static_middleware import StaticMiddleware\n        app = StaticMiddleware(app, static_root=static_root, static_dirs=static_dirs)\n\n    if validate:\n        from wsgiref.validate import validator\n        app = validator(app)\n\n    if lineprof:\n        # Caution: wsgi-lineprof is still pre-alpha. Except breaking API Changes.\n        from wsgi_lineprof.middleware import LineProfilerMiddleware\n        from wsgi_lineprof.filters import FilenameFilter, TotalTimeSorter\n\n        if lineprof_file:\n            # Now wsgi-lineprof is now supported only 1 file checking.\n            lineprof_file = lineprof_file[0]\n        else:\n            lineprof_file = os.path.basename(filepath)\n        filters = [FilenameFilter(lineprof_file), TotalTimeSorter()]\n        app = LineProfilerMiddleware(app, filters=filters)\n\n    if reload:\n        run_live_reloading_server(interval, app=app, host=host, port=port)\n    else:\n        run_server(app=app, host=host, port=port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert_import_path_to_sys_modules(import_path):\n    abspath = os.path.abspath(import_path)\n    if os.path.isdir(abspath):\n        sys.path.insert(0, abspath)\n    else:\n        sys.path.insert(0, os.path.dirname(abspath))", "response": "Insert import path into sys. path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shell(filepath, wsgiapp, interpreter, models):\n    model_base_classes = get_model_base_classes()\n    imported_objects = {}\n\n    if models and model_base_classes:\n        insert_import_path_to_sys_modules(filepath)\n\n        for module in find_modules_from_path(filepath):\n            for name in dir(module):\n                if name.startswith('_'):\n                    continue\n                obj = getattr(module, name)\n                if isinstance(obj, model_base_classes):\n                    key = name.split('.')[-1] if '.' in name else name\n                    if key in imported_objects:\n                        continue\n                    imported_objects[key] = obj\n\n    module = SourceFileLoader('module', filepath).load_module()\n    imported_objects['app'] = getattr(module, wsgiapp)\n\n    for key in imported_objects.keys():\n        click.secho(\"import {}\".format(key), fg='green')\n    run_python(interpreter, imported_objects)", "response": "Runs a python shell."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the given key to all elements in the set.", "response": "def kadd(self, key, value):\n        \"\"\"Adds the given key/value to all elements.\n        Single values for a key are stored directly, as key:value, multiple\n        values for the same key are stored as key,set(values).\n        \"\"\"\n        for item in self:\n            try:\n                # Use the key as a set\n                item[key].add(value)\n            except KeyError:\n                # This happens if the key is not present\n                item[key] = value\n            except AttributeError:\n                # This happens if the key is present but is not a set\n                item[key] = set([item[key], value])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing the given key with value for each element in the archive.", "response": "def kreplace(self, key, value):\n        \"\"\"Replaces the given key/value for each element.\n        If the key is not present silently passes.\n        \"\"\"\n        for item in self:\n            if key in item:\n                item[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the given key value from all elements in the set.", "response": "def kremove(self, key, value=None):\n        \"\"\"Removes the given key/value from all elements.\n        If value is not specified, the whole key is removed.\n        If value is not None and the key is present but with a\n        different value, or if the key is not present, silently passes.\n        \"\"\"\n        for item in self:\n            if value is None:\n                # Just pop the key if present,\n                # otherwise return None\n                # (shortcut to ignore the exception)\n                item.pop(key, None)\n            else:\n                try:\n                    # Use the key as a set\n                    item[key].remove(value)\n                    # If the set contains a single element\n                    # just store the latter\n                    if len(item[key]) == 1:\n                        item[key] = item[key].pop()\n                except KeyError:\n                    # This happens when the item\n                    # does not contain the key\n                    pass\n                except AttributeError:\n                    # This happens when the key is not a set\n                    # and shall be removed only if values match\n                    if item[key] == value:\n                        item.pop(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a DictRegister which contains only the elements that match the given specifications.", "response": "def dfilter(self, **kwds):\n        \"\"\"Returns a DictRegister which contains only the\n        elements that match the given specifications.\n        \"\"\"\n        starting_list = self[:]\n        filtered_list = []\n        for key, value in six.iteritems(kwds):\n            for item in starting_list:\n                if self._match(item, key, value):\n                    filtered_list.append(item)\n            starting_list = filtered_list\n            filtered_list = []\n        return DictRegister(starting_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dpop(self, **kwds):\n        item = self.dget(**kwds)\n        self.remove(item)\n        return item", "response": "Pops and returns the first element that matches the\n        given specification. Returns IndexError if no elements are found."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving from the object any element that matches the given specification.", "response": "def dremove(self, **kwds):\n        \"\"\"Removes from the object any element that matches the\n        given specification.\n        \"\"\"\n        filtered_dr = self.dfilter(**kwds)\n        for item in filtered_dr:\n            self.remove(item)\n        return filtered_dr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the object without any element that matches the given specification.", "response": "def dremove_copy(self, **kwds):\n        \"\"\"Returns a copy of the object without any element that\n        matches the given specification.\n        \"\"\"\n        copy_dr = DictRegister(self)\n        copy_dr.dremove(**kwds)\n        return copy_dr"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_media_with_naming (output_dir, media_url, uuid, size):\n    try:\n        response = requests.get(media_url, stream=True)\n        response.raise_for_status()\n    except (requests.exceptions.HTTPError, requests.exceptions.ConnectionError) as e:\n        print('*** HTTP ERROR: {0}'.format(e))\n        return False\n\n    ### iDigBio returns 200 OK and displays an SVG status image when a derivative\n    ### is not present.  Check for \"Content-Type: image/svg+xml\" header to notice this condition.\n    if response.headers['Content-Type'] == 'image/svg+xml':\n        print(\"*** WARNING - No media at '{0}'\".format(media_url))\n        return False\n\n    # Output filenames will be of the form: {mediarecord_uuid}_{SIZE}.jpg\n    local_filepath = os.path.join(output_dir,  uuid + '_' + SIZE + '.jpg')\n\n    try:\n        with open(local_filepath, 'wb') as out_file:\n            shutil.copyfileobj(response.raw, out_file)\n        return True\n    except:\n        return False", "response": "Download a media file to a directory and name it based on the input parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(args=sys.argv[1:]):\n    usage = \"%prog --help\"\n    parser = OptionParser(usage, add_help_option=False)\n    parser.add_option('-c', '--config', help=\"Configuration file to use\",\n                      action='store', type='string', dest='config_file')\n    parser.add_option('-h', '-H', '--host',\n                      help=(\"Hostname of the Trovebox server \"\n                            \"(overrides config_file)\"),\n                      action='store', type='string', dest='host')\n    parser.add_option('-X', help=\"Method to use (GET or POST)\",\n                      action='store', type='choice', dest='method',\n                      choices=('GET', 'POST'), default=\"GET\")\n    parser.add_option('-F', help=\"Endpoint field\",\n                      action='append', type='string', dest='fields')\n    parser.add_option('-e', help=\"Endpoint to call\",\n                      action='store', type='string', dest='endpoint',\n                      default='/photos/list.json')\n    parser.add_option('-p', help=\"Pretty print the json\",\n                      action=\"store_true\", dest=\"pretty\", default=False)\n    parser.add_option('-v', help=\"Verbose output\",\n                      action=\"store_true\", dest=\"verbose\", default=False)\n    parser.add_option('--version', help=\"Display the current version\",\n                      action=\"store_true\")\n    parser.add_option('--help', help='show this help message',\n                      action=\"store_true\")\n\n    options, args = parser.parse_args(args)\n\n    if options.help:\n        parser.print_help()\n        return\n\n    if options.version:\n        print(trovebox.__version__)\n        return\n\n    if args:\n        parser.error(\"Unknown argument: %s\" % args)\n\n    params = {}\n    if options.fields:\n        for field in options.fields:\n            (key, value) = field.split('=')\n            params[key] = value\n\n    # Host option overrides config file settings\n    if options.host:\n        client = trovebox.Trovebox(host=options.host)\n    else:\n        try:\n            client = trovebox.Trovebox(config_file=options.config_file)\n        except IOError as error:\n            print(error)\n            print(CONFIG_ERROR)\n            print(error)\n            sys.exit(1)\n\n    if options.method == \"GET\":\n        result = client.get(options.endpoint, process_response=False,\n                            **params)\n    else:\n        params, files = extract_files(params)\n        result = client.post(options.endpoint, process_response=False,\n                             files=files, **params)\n        for file_ in files:\n            files[file_].close()\n\n    if options.verbose:\n        print(\"==========\\nMethod: %s\\nHost: %s\\nEndpoint: %s\" %\n              (options.method, client.host, options.endpoint))\n        if params:\n            print(\"Fields:\")\n            for key, value in params.items():\n                print(\"  %s=%s\" % (key, value))\n        print(\"==========\\n\")\n\n    if options.pretty:\n        print(json.dumps(json.loads(result), sort_keys=True,\n                         indent=4, separators=(',',':')))\n    else:\n        print(result)", "response": "The main function of the command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_files(params):\n    files = {}\n    updated_params = {}\n    for name in params:\n        if name == \"photo\" and params[name].startswith(\"@\"):\n            filename = params[name][1:]\n\n            # Python2 uses encoded commandline parameters.\n            # Decode to Unicode if necessary.\n            if isinstance(filename, bytes):\n                filename = filename.decode(sys.getfilesystemencoding())\n\n            files[name] = open(os.path.expanduser(filename), 'rb')\n        else:\n            updated_params[name] = params[name]\n\n    return updated_params, files", "response": "Extracts the files from the photo parameter and returns the updated parameters and files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates a webfont settings and optionally fill missing csspart_path option.", "response": "def extend_webfont_settings(webfont_settings):\n    \"\"\"\n    Validate a webfont settings and optionally fill missing ``csspart_path``\n    option.\n\n    Args:\n        webfont_settings (dict): Webfont settings (an item value from\n            ``settings.ICOMOON_WEBFONTS``).\n\n    Returns:\n        dict: Webfont settings\n    \"\"\"\n    if not webfont_settings.get('fontdir_path', False):\n        raise IcomoonSettingsError((\"Webfont settings miss the required key \"\n                                    \"item 'fontdir_path'\"))\n\n    if not webfont_settings.get('csspart_path', False):\n        webfont_settings['csspart_path'] = None\n\n    return webfont_settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(url, lamson_host, lamson_port, lamson_debug):\n    try:\n        worker = LamsonWorker(url=url,\n                              lamson_host=lamson_host,\n                              lamson_port=lamson_port,\n                              lamson_debug=lamson_debug)\n        worker.connect()\n        worker.run_forever()\n    except KeyboardInterrupt:\n        worker.close()", "response": "Main function for Lamson worker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef received_new(self, msg):\n        logger.info(\"Receiving msg, delivering to Lamson...\")\n        logger.debug(\"Relaying msg to lamson: From: %s, To: %s\",\n                     msg['From'], msg['To'])\n        self._relay.deliver(msg)", "response": "Called when a new message arrives."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(**vkargs):\n    depr('Use route wildcard filters instead.')\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kargs):\n            for key, value in vkargs.items():\n                if key not in kargs:\n                    abort(403, 'Missing parameter: %s' % key)\n                try:\n                    kargs[key] = value(kargs[key])\n                except ValueError:\n                    abort(403, 'Wrong parameter format for: %s' % key)\n            return func(*args, **kargs)\n        return wrapper\n    return decorator", "response": "Decorator that validates keyword arguments by user defined callables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmounting an application (:class:`Bottle` or plain WSGI) to a specific URL prefix. Example:: root_app.mount('/admin/', admin_app) :param prefix: path prefix or `mount-point`. If it ends in a slash, that slash is mandatory. :param app: an instance of :class:`Bottle` or a WSGI application. All other parameters are passed to the underlying :meth:`route` call.", "response": "def mount(self, prefix, app, **options):\n        ''' Mount an application (:class:`Bottle` or plain WSGI) to a specific\n            URL prefix. Example::\n\n                root_app.mount('/admin/', admin_app)\n\n            :param prefix: path prefix or `mount-point`. If it ends in a slash,\n                that slash is mandatory.\n            :param app: an instance of :class:`Bottle` or a WSGI application.\n\n            All other parameters are passed to the underlying :meth:`route` call.\n        '''\n        if isinstance(app, basestring):\n            prefix, app = app, prefix\n            depr('Parameter order of Bottle.mount() changed.') # 0.10\n\n        parts = [p for p in prefix.split('/') if p]\n        if not parts: raise ValueError('Empty path prefix.')\n        path_depth = len(parts)\n        options.setdefault('skip', True)\n        options.setdefault('method', 'ANY')\n\n        @self.route('/%s/:#.*#' % '/'.join(parts), **options)\n        def mountpoint():\n            try:\n                request.path_shift(path_depth)\n                rs = BaseResponse([], 200)\n                def start_response(status, header):\n                    rs.status = status\n                    for name, value in header: rs.add_header(name, value)\n                    return rs.body.append\n                rs.body = itertools.chain(rs.body, app(request.environ, start_response))\n                return HTTPResponse(rs.body, rs.status_code, rs.headers)\n            finally:\n                request.path_shift(-path_depth)\n\n        if not prefix.endswith('/'):\n            self.route('/' + '/'.join(parts), callback=mountpoint, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a FormsDict containing all the form values parsed from an url - encoded POST or PUT request body.", "response": "def forms(self):\n        \"\"\" Form values parsed from an `url-encoded` or `multipart/form-data`\n            encoded POST or PUT request body. The result is retuned as a\n            :class:`FormsDict`. All keys and values are strings. File uploads\n            are stored separately in :attr:`files`. \"\"\"\n        forms = FormsDict()\n        for name, item in self.POST.allitems():\n            if not hasattr(item, 'filename'):\n                forms[name] = item\n        return forms"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a FormsDict containing the file uploads parsed from a URL - encoded POST or PUT request body.", "response": "def files(self):\n        \"\"\" File uploads parsed from an `url-encoded` or `multipart/form-data`\n            encoded POST or PUT request body. The values are instances of\n            :class:`cgi.FieldStorage`. The most important attributes are:\n\n            filename\n                The filename, if specified; otherwise None; this is the client\n                side filename, *not* the file name on which it is stored (that's\n                a temporary file you don't deal with)\n            file\n                The file(-like) object from which you can read the data.\n            value\n                The value as a *string*; for file uploads, this transparently\n                reads the file every time you request the value. Do not do this\n                on big files.\n        \"\"\"\n        files = FormsDict()\n        for name, item in self.POST.allitems():\n            if hasattr(item, 'filename'):\n                files[name] = item\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields the headers that are not allowed with the current response status code.", "response": "def iter_headers(self):\n        ''' Yield (header, value) tuples, skipping headers that are not\n            allowed with the current response status code. '''\n        headers = self._headers.items()\n        bad_headers = self.bad_headers.get(self._status_code)\n        if bad_headers:\n            headers = [h for h in headers if h[0] not in bad_headers]\n        for name, values in headers:\n            for value in values:\n                yield name, value\n        if self._cookies:\n            for c in self._cookies.values():\n                yield 'Set-Cookie', c.OutputString()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_path(self, path, base=None, index=None, create=False):\n        ''' Add a new path to the list of search paths. Return False if it does\n            not exist.\n\n            :param path: The new search path. Relative paths are turned into an\n                absolute and normalized form. If the path looks like a file (not\n                ending in `/`), the filename is stripped off.\n            :param base: Path used to absolutize relative search paths.\n                Defaults to `:attr:base` which defaults to ``./``.\n            :param index: Position within the list of search paths. Defaults to\n                last index (appends to the list).\n            :param create: Create non-existent search paths. Off by default.\n\n            The `base` parameter makes it easy to reference files installed\n            along with a python module or package::\n            \n                res.add_path('./resources/', __file__)\n        '''\n        base = os.path.abspath(os.path.dirname(base or self.base))\n        path = os.path.abspath(os.path.join(base, os.path.dirname(path)))\n        path += os.sep\n        if path in self.path:\n            self.path.remove(path)\n        if create and not os.path.isdir(path):\n            os.mkdirs(path)\n        if index is None:\n            self.path.append(path)\n        else:\n            self.path.insert(index, path)\n        self.cache.clear()", "response": "Adds a new path to the list of search paths. Return False if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npublishes a json message to all the infrastructure.", "response": "def publish(self, json_msg):\n        '''\n        json_msg = '{\"topic1\": 1.0, \"topic2\": {\"x\": 0.1}}'\n        '''\n        pyobj = json.loads(json_msg)\n        for topic, value in pyobj.items():\n            msg = '{topic} {data}'.format(topic=topic, data=json.dumps(value))\n            self._pub.publish(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a file handler to the root logging.", "response": "def add_file_handler_to_root(log_fn):\n    \"\"\"Adds a file handler to the root logging.\n\n    :param log_fn: the name of the log file.\n\n    :type log_fn: str\n\n    \"\"\"\n    file_handler = logging.FileHandler(log_fn, mode=\"w\")\n    file_handler.setFormatter(logging.Formatter(\n        fmt=\"[%(asctime)s %(name)s %(levelname)s] %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n    ))\n    logging.root.addHandler(file_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering exconsole hooks and commands", "response": "def register(reg_signal=signal.SIGQUIT, reg_unhandled=True, commands=[]):\n    \"\"\"\n    Registers exconsole hooks\n\n    :param reg_signal: if not None, register signal handler (default: ``signal.SIGQUIT``)\n    :param reg_unhandled: if ``True``, register unhandled exception hook (``sys.excepthook``)\n    :param commands: list of custom commands/objects: (<local name>, <help string>, <function or object>)\n    \"\"\"\n    if reg_signal:\n        signal.signal(reg_signal, handle_quit)\n    if reg_unhandled:\n        sys.excepthook = handle_exception\n    launch.commands = commands"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlaunch an emergency console.", "response": "def launch(exception=None, extraceback=None, signalnum=None, frame=None):\n    \"\"\"\n    Launches an emergency console\n\n    :param exception: unhandled exception value\n    :param extraceback: unhandled exception traceback\n    :param signalnum: interrupting signal number\n    :param frame: interrupting signal frame\n    \"\"\"\n\n    print('\\n')\n    print('Activating emergency console')\n    print('----------------------------')\n\n    print('Caused by:')\n    if signalnum:\n        signals = dict((k, v) for v, k in signal.__dict__.iteritems() if v.startswith('SIG'))\n        print('Signal', signals.get(signalnum, 'unknown'))\n    elif exception:\n        print(exception.__class__.__name__)\n        print(exception)\n    else:\n        print('manual invocation')\n\n    stack = []\n    locals = {}\n    active_frame = 0\n    if frame:\n        current_frame = frame\n        while current_frame:\n            stack.insert(0, current_frame)\n            current_frame = current_frame.f_back\n    if extraceback:\n        current_tb = extraceback\n        while current_tb:\n            stack.append(current_tb.tb_frame)\n            current_tb = current_tb.tb_next\n\n    import readline\n    import code\n\n    def _cmd_stack():\n        index = 0\n        print('\\nStack frames:')\n        for frame in stack:\n            s = '> ' if (active_frame == index) else '  '\n            s += '[%s] ' % str(index).rjust(3)\n            lines, current_line = inspect.getsourcelines(frame)\n            s += '%s:%i' % (inspect.getfile(frame), frame.f_lineno)\n            s += '\\n' + ' ' * 10\n            if frame.f_lineno - current_line < len(lines):\n                s += lines[frame.f_lineno - current_line].strip('\\n')\n            print(s)\n            index += 1\n\n    def _cmd_help():\n        print((\n            \"Exconsole interactive emergency console\\n\"\n            \"Builtin commands:\\n\"\n            \" - _help()    this help\\n\"\n            \" - _s()       display stack\\n\"\n            \" - _f(index)  change current stack frame\\n\"\n            \" - _pdb()     launch PDB debugger\\n\"\n            \" - _exc       exception object\\n\"\n            \" - Ctrl-D     leave console\\n\"\n        ))\n        print('\\n'.join(' - %s\\t%s' % x[:2] for x in launch.commands))\n\n    def _cmd_pdb():\n        pdb.pm()\n\n    def _cmd_frame(index):\n        if not isinstance(index, int):\n            print('index must be int')\n            return\n        if index < 0 or index >= len(stack):\n            print('index out of bounds')\n            return\n        frame = stack[index] \n        locals.clear()\n        locals.update(frame.f_locals)\n        locals.update({\n            '_help': _cmd_help,\n            '_s': _cmd_stack,\n            '_f': _cmd_frame,\n            '_pdb': _cmd_pdb,\n            '_exc': exception,\n        })\n        for command in launch.commands:\n            locals[command[0]] = command[2]\n\n        print('On frame %i' % index)\n        print('Source:')\n\n        lines, current_line = inspect.getsourcelines(frame)\n        print(''.join(\n            '    ' +\n            ('>>' if lines.index(line) == frame.f_lineno - current_line else '  ') +\n            ' ' + line\n            for line in lines\n        ))\n\n    active_frame = len(stack) - 1\n    _cmd_stack()\n    _cmd_frame(len(stack) - 1)\n\n    shell = code.InteractiveConsole(locals)\n\n    print('Press Ctrl-D to leave console')\n    print('Type \"_help()\" for built-in commands')\n\n    shell.interact(banner='')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds new variables or change values to be used for particular parameter names that will not be jointly varied.", "response": "def add_params(self, p):\n        \"\"\"Add new variables or change values to be used for particular\n        parameter names that will not be jointly varied.\"\"\"\n        new_params = p.copy()\n        for key,val in new_params.items():\n            if not isinstance(val, collections.Iterable):\n                new_params[key] = [new_params[key]]\n            #_check_comb_param(key, val)\n        self.comb_params.update(new_params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an RGB color scheme based on predefined presets or specify your own band names to use.", "response": "def GetRGB(self, scheme='infrared', names=None):\n        \"\"\"Get an RGB color scheme based on predefined presets or specify your\n        own band names to use. A given set of names always overrides a scheme.\n\n        Note:\n            Available schemes are defined in ``RGB_SCHEMES`` and include:\n\n            - ``true``\n            - ``infrared``\n            - ``false_a``\n            - ``false_b``\n            - ``false_c``\n\n        \"\"\"\n        if names is not None:\n            if not isinstance(names, (list, tuple)) or len(names) != 3:\n                raise RuntimeError('RGB band names improperly defined.')\n        else:\n            lookup = self.RGB_SCHEMES[scheme]\n            names = lookup[self.global_metadata.satellite]\n\n        # Now check that all bands are available:\n        for nm in names:\n            if nm not in self.bands.keys():\n                raise RuntimeError('Band (%s) unavailable.' % nm)\n\n        # Get the RGB bands\n        r = self.bands[names[0]].data\n        g = self.bands[names[1]].data\n        b = self.bands[names[2]].data\n        # Note that the bands dhould already be masked from read.\n        # If casted then there are np.nans present\n        r = ((r - np.nanmin(r)) * (1/(np.nanmax(r) - np.nanmin(r)) * 255)).astype('uint8')\n        g = ((g - np.nanmin(g)) * (1/(np.nanmax(g) - np.nanmin(g)) * 255)).astype('uint8')\n        b = ((b - np.nanmin(b)) * (1/(np.nanmax(b) - np.nanmin(b)) * 255)).astype('uint8')\n        return np.dstack([r, g, b])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets and stores an OAUTH token from Rightscale.", "response": "def login(self):\n        \"\"\"\n        Gets and stores an OAUTH token from Rightscale.\n        \"\"\"\n        log.debug('Logging into RightScale...')\n        login_data = {\n            'grant_type': 'refresh_token',\n            'refresh_token': self.refresh_token,\n            }\n        response = self._request('post', self.oauth_path, data=login_data)\n\n        raw_token = response.json()\n        auth_token = \"Bearer %s\" % raw_token['access_token']\n        self.s.headers['Authorization'] = auth_token\n\n        # Generate an expiration time for our token of 60-seconds before the\n        # standard time returned by RightScale. This will be used in the\n        # self.client property to validate that our token is still usable on\n        # every API call.\n        log.debug('Auth Token expires in %s(s)' % raw_token['expires_in'])\n        self.auth_expires_at = time.time() + int(raw_token['expires_in']) - 60"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request(self, method, path='/', url=None, ignore_codes=[], **kwargs):\n        # On every call, check if we're both logged in, and if the token is\n        # expiring. If it is, we'll re-login with the information passed into\n        # us at instantiation.\n        if time.time() > self.auth_expires_at:\n            self.login()\n\n        # Now make the actual API call\n        return self._request(method, path, url, ignore_codes, **kwargs)", "response": "Wrapper for the requests. request method that verifies if we re logged into the oauth expiration date and then calls the actual API call."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a HTTP request.", "response": "def _request(self, method, path='/', url=None, ignore_codes=[], **kwargs):\n        \"\"\"\n        Performs HTTP request.\n\n        :param str method: An HTTP method (e.g. 'get', 'post', 'PUT', etc...)\n\n        :param str path: A path component of the target URL.  This will be\n            appended to the value of ``self.endpoint``.  If both :attr:`path`\n            and :attr:`url` are specified, the value in :attr:`url` is used and\n            the :attr:`path` is ignored.\n\n        :param str url: The target URL (e.g.  ``http://server.tld/somepath/``).\n            If both :attr:`path` and :attr:`url` are specified, the value in\n            :attr:`url` is used and the :attr:`path` is ignored.\n\n        :param ignore_codes: List of HTTP error codes (e.g.  404, 500) that\n            should be ignored.  If an HTTP error occurs and it is *not* in\n            :attr:`ignore_codes`, then an exception is raised.\n        :type ignore_codes: list of int\n\n        :param kwargs: Any other kwargs to pass to :meth:`requests.request()`.\n\n        Returns a :class:`requests.Response` object.\n        \"\"\"\n        _url = url if url else (self.endpoint + path)\n        r = self.s.request(method, _url, **kwargs)\n        if not r.ok and r.status_code not in ignore_codes:\n            r.raise_for_status()\n        return HTTPResponse(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(epub_path):\n\n    try:\n        subprocess.check_call([c.JAVA, '-jar', c.EPUBCHECK, epub_path])\n        return True\n    except subprocess.CalledProcessError:\n        return False", "response": "Minimal validation.\n\n    :return bool: True if valid else False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rename_next_state_fluent(name: str) -> str:\n    '''Returns next state fluent canonical name.\n\n    Args:\n        name (str): The current state fluent name.\n\n    Returns:\n        str: The next state fluent name.\n    '''\n    i = name.index('/')\n    functor = name[:i-1]\n    arity = name[i+1:]\n    return \"{}/{}\".format(functor, arity)", "response": "Returns next state fluent canonical name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rename_state_fluent(name: str) -> str:\n    '''Returns current state fluent canonical name.\n\n    Args:\n        name (str): The next state fluent name.\n\n    Returns:\n        str: The current state fluent name.\n    '''\n    i = name.index('/')\n    functor = name[:i]\n    arity = name[i+1:]\n    return \"{}'/{}\".format(functor, arity)", "response": "Returns the current state fluent canonical name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_related_samples(file_name, out_prefix, no_status):\n    # What we need to save\n    status = {}\n    samples_sets = []\n    open_function = open\n    if file_name.endswith(\".gz\"):\n        open_function = gzip.open\n    with open_function(file_name, 'rb') as input_file:\n        header_index = dict([\n            (col_name, i) for i, col_name in\n            enumerate(input_file.readline().rstrip(\"\\r\\n\").split(\"\\t\"))\n        ])\n        for col_name in {\"FID1\", \"IID1\", \"FID2\", \"IID2\"}:\n            if col_name not in header_index:\n                msg = \"{}: no column named {}\".format(file_name, col_name)\n                raise ProgramError(msg)\n        if not no_status:\n            if \"status\" not in header_index:\n                msg = \"{}: no column named status\".format(file_name)\n                raise ProgramError(msg)\n\n        for line in input_file:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            sample_1 = (row[header_index[\"FID1\"]], row[header_index[\"IID1\"]])\n            sample_2 = (row[header_index[\"FID2\"]], row[header_index[\"IID2\"]])\n            tmp_set = {sample_1, sample_2}\n            match = False\n            for i in xrange(len(samples_sets)):\n                if len(tmp_set & samples_sets[i]) > 0:\n                    # We have a match\n                    samples_sets[i] |= tmp_set\n                    match = True\n            if not match:\n                # We did not find a match, so we add\n                samples_sets.append(tmp_set)\n\n            # Check for the status\n            the_status = \"None\"\n            if not no_status:\n                the_status = row[header_index[\"status\"]]\n            status[(sample_1, sample_2)] = the_status\n\n    # Doing a final check\n    final_samples_set = []\n    removed = set()\n    for i in xrange(len(samples_sets)):\n        if i in removed:\n            # We removed this group\n            continue\n        group = samples_sets[i]\n        j = i + 1\n        while j < len(samples_sets):\n            if j in removed:\n                j += 1\n                continue\n            if len(group & samples_sets[j]) > 0:\n                # We have a match, we start from the beginning\n                group |= samples_sets[j]\n                removed.add(j)\n                j = i + 1\n                continue\n            j += 1\n\n        final_samples_set.append(group)\n\n    # Printing the output file\n    output_file = None\n    try:\n        output_file = open(out_prefix + \".merged_related_individuals\", 'w')\n        to_print = [\"index\", \"FID1\", \"IID1\", \"FID2\", \"IID2\"]\n        if not no_status:\n            to_print.append(\"status\")\n        print >>output_file, \"\\t\".join(to_print)\n    except IOError:\n        msg = \"{}: can't write file\".format(out_prefix +\n                                            \".merged_related_individuals\")\n        raise ProgramError(msg)\n\n    # Iterating on the groups\n    chosen_samples = set()\n    remaining_samples = set()\n    for i, group in enumerate(final_samples_set):\n        index = str(i+1)\n        for sample_1, sample_2 in status.iterkeys():\n            if (sample_1 in group) and (sample_2 in group):\n                to_print = [index, sample_1[0], sample_1[1], sample_2[0],\n                            sample_2[1]]\n                if not no_status:\n                    to_print.append(status[(sample_1, sample_2)])\n                print >>output_file, \"\\t\".join(to_print)\n\n        # Choose a random sample from the group\n        chosen = random.choice(list(group))\n        chosen_samples.add(chosen)\n        remaining_samples |= group - {chosen}\n\n    # Printing the files\n    try:\n        filename = out_prefix + \".chosen_related_individuals\"\n        with open(filename, \"w\") as chosen_file:\n            for sample_id in chosen_samples:\n                print >>chosen_file, \"\\t\".join(sample_id)\n\n        filename = out_prefix + \".discarded_related_individuals\"\n        with open(filename, \"w\") as discarded_file:\n            for sample_id in remaining_samples:\n                print >>discarded_file, \"\\t\".join(sample_id)\n    except IOError:\n        msg = \"{}: can't write files\".format(out_prefix + \".*\")\n        raise ProgramError(msg)\n\n    # Closing the output file\n    output_file.close()", "response": "Merge related samples into a single cannonical tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the arguments and options.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: a an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    if not os.path.isfile(args.ibs_related):\n        msg = \"{}: no such file\".format(args.ibs_related)\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the admin url for the given model and admin url name.", "response": "def admin_url(model, url, object_id=None):\n    \"\"\"\n    Returns the URL for the given model and admin url name.\n    \"\"\"\n    opts = model._meta\n    url = \"admin:%s_%s_%s\" % (opts.app_label, opts.object_name.lower(), url)\n    args = ()\n    if object_id is not None:\n        args = (object_id,)\n    return reverse(url, args=args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle redirect back to the admin when a save is clicked.", "response": "def handle_save(self, request, response):\n        \"\"\"\n        Handles redirect back to the dashboard when save is clicked\n        (eg not save and continue editing), by checking for a redirect\n        response, which only occurs if the form is valid.\n        \"\"\"\n        form_valid = isinstance(response, HttpResponseRedirect)\n        if request.POST.get(\"_save\") and form_valid:\n            return redirect(\"admin:index\")\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nredirecting to the change view if the singleton instance exists.", "response": "def add_view(self, *args, **kwargs):\n        \"\"\"\n        Redirect to the change view if the singleton instance exists.\n        \"\"\"\n        try:\n            singleton = self.model.objects.get()\n        except (self.model.DoesNotExist, self.model.MultipleObjectsReturned):\n            kwargs.setdefault(\"extra_context\", {})\n            kwargs[\"extra_context\"][\"singleton\"] = True\n            response = super(SingletonAdmin, self).add_view(*args, **kwargs)\n            return self.handle_save(args[0], response)\n        return redirect(admin_url(self.model, \"change\", singleton.id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nredirect to the add view if no records exist.", "response": "def changelist_view(self, *args, **kwargs):\n        \"\"\"\n        Redirect to the add view if no records exist or the change\n        view if the singleton instance exists.\n        \"\"\"\n        try:\n            singleton = self.model.objects.get()\n        except self.model.MultipleObjectsReturned:\n            return super(SingletonAdmin, self).changelist_view(*args, **kwargs)\n        except self.model.DoesNotExist:\n            return redirect(admin_url(self.model, \"add\"))\n        return redirect(admin_url(self.model, \"change\", singleton.id))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride change_view to add singleton instance to the extra_context.", "response": "def change_view(self, *args, **kwargs):\n        \"\"\"\n        If only the singleton instance exists, pass ``True`` for\n        ``singleton`` into the template which will use CSS to hide\n        the \"save and add another\" button.\n        \"\"\"\n        kwargs.setdefault(\"extra_context\", {})\n        kwargs[\"extra_context\"][\"singleton\"] = self.model.objects.count() == 1\n        response = super(SingletonAdmin, self).change_view(*args, **kwargs)\n        return self.handle_save(args[0], response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish the data to the topic", "response": "def pub(topic_name, json_msg, repeat_rate=None, host=jps.env.get_master_host(), pub_port=jps.DEFAULT_PUB_PORT):\n    '''publishes the data to the topic\n\n    :param topic_name: name of the topic\n    :param json_msg: data to be published\n    :param repeat_rate: if None, publishes once. if not None, it is used as [Hz].\n    '''\n    pub = jps.Publisher(topic_name, host=host, pub_port=pub_port)\n    time.sleep(0.1)\n    if repeat_rate is None:\n        pub.publish(json_msg)\n    else:\n        try:\n            while True:\n                pub.publish(json_msg)\n                time.sleep(1.0 / repeat_rate)\n        except KeyboardInterrupt:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef echo(topic_name, num_print=None, out=sys.stdout, host=jps.env.get_master_host(), sub_port=jps.DEFAULT_SUB_PORT):\n    '''print the data for the given topic forever\n    '''\n    class PrintWithCount(object):\n\n        def __init__(self, out):\n            self._printed = 0\n            self._out = out\n\n        def print_and_increment(self, msg):\n            self._out.write('{}\\n'.format(msg))\n            self._printed += 1\n\n        def get_count(self):\n            return self._printed\n\n    counter = PrintWithCount(out)\n    sub = jps.Subscriber(\n        topic_name, counter.print_and_increment, host=host, sub_port=sub_port)\n    try:\n        while num_print is None or counter.get_count() < num_print:\n            sub.spin_once()\n            time.sleep(0.0001)\n    except KeyboardInterrupt:\n        pass", "response": "print the data for the given topic forever"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing the name list of the topics and print it", "response": "def show_list(timeout_in_sec, out=sys.stdout, host=jps.env.get_master_host(), sub_port=jps.DEFAULT_SUB_PORT):\n    '''get the name list of the topics, and print it\n    '''\n    class TopicNameStore(object):\n\n        def __init__(self):\n            self._topic_names = set()\n\n        def callback(self, msg, topic):\n            self._topic_names.add(topic)\n\n        def get_topic_names(self):\n            names = list(self._topic_names)\n            names.sort()\n            return names\n\n    store = TopicNameStore()\n    sub = jps.Subscriber('*', store.callback, host=host, sub_port=sub_port)\n    sleep_sec = 0.01\n    for i in range(int(timeout_in_sec / sleep_sec)):\n        sub.spin_once(sleep_sec)\n        time.sleep(0.001)  # for context switch\n    for name in store.get_topic_names():\n        out.write('{}\\n'.format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef record(file_path, topic_names=[], host=jps.env.get_master_host(), sub_port=jps.DEFAULT_SUB_PORT):\n    '''record the topic data to the file\n    '''\n    class TopicRecorder(object):\n\n        def __init__(self, file_path, topic_names):\n            self._topic_names = topic_names\n            self._file_path = file_path\n            self._output = open(self._file_path, 'w')\n            signal.signal(signal.SIGINT, self._handle_signal)\n            signal.signal(signal.SIGTERM, self._handle_signal)\n            header = {}\n            header['topic_names'] = topic_names\n            header['start_date'] = str(datetime.datetime.today())\n            header_string = json.dumps({'header': header})\n            tail_removed_header = header_string[0:-1]\n            self._output.write(tail_removed_header + ',\\n')\n            self._output.write(' \"data\": [\\n')\n            self._has_no_data = True\n\n        def callback(self, msg, topic):\n            if self._output.closed:\n                return\n            raw_msg = '{topic} {msg}'.format(topic=topic, msg=msg)\n            if not self._topic_names or topic in self._topic_names:\n                if not self._has_no_data:\n                    self._output.write(',\\n')\n                else:\n                    self._has_no_data = False\n                self._output.write(json.dumps([time.time(), raw_msg]))\n\n        def close(self):\n            if not self._output.closed:\n                self._output.write('\\n]}')\n                self._output.close()\n\n        def _handle_signal(self, signum, frame):\n            self.close()\n            sys.exit(0)\n\n    writer = TopicRecorder(file_path, topic_names)\n    sub = jps.Subscriber('*', writer.callback, host=host, sub_port=sub_port)\n    sub.spin()\n    writer.close()", "response": "record the topic data to the file_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplaying the recorded data by record", "response": "def play(file_path, host=jps.env.get_master_host(), pub_port=jps.DEFAULT_PUB_PORT):\n    '''replay the recorded data by record()\n    '''\n    pub = jps.Publisher('*', host=host, pub_port=pub_port)\n    time.sleep(0.2)\n    last_time = None\n    print('start publishing file {}'.format(file_path))\n    with open(file_path, 'r') as f:\n        # super hack to remove header\n        f.readline()\n        f.readline()\n        for line in f:\n            if line.startswith(']}'):\n                break\n            publish_time, raw_msg = json.loads(line.rstrip(',\\n'))\n            if last_time is not None:\n                time.sleep(publish_time - last_time)\n            pub.publish(raw_msg.rstrip())\n            last_time = publish_time\n    print('fnished')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncommands line tool for jps", "response": "def topic_command():\n    '''command line tool for jps\n    '''\n    parser = argparse.ArgumentParser(description='json pub/sub tool')\n    pub_common_parser = jps.ArgumentParser(subscriber=False, add_help=False)\n    sub_common_parser = jps.ArgumentParser(publisher=False, add_help=False)\n    command_parsers = parser.add_subparsers(dest='command', help='command')\n\n    pub_parser = command_parsers.add_parser(\n        'pub', help='publish topic from command line', parents=[pub_common_parser])\n    pub_parser.add_argument('topic_name', type=str, help='name of topic')\n    pub_parser.add_argument(\n        'data', type=str, help='json string data to be published')\n    pub_parser.add_argument('--repeat', '-r', help='repeat in hz', type=float)\n\n    echo_parser = command_parsers.add_parser(\n        'echo', help='show topic data', parents=[sub_common_parser])\n    echo_parser.add_argument('topic_name', type=str, help='name of topic')\n    echo_parser.add_argument(\n        '--num', '-n', help='print N times and exit', type=int,\n        default=None)\n\n    list_parser = command_parsers.add_parser(\n        'list', help='show topic list', parents=[sub_common_parser])\n    list_parser.add_argument(\n        '--timeout', '-t', help='timeout in sec', type=float,\n        default=1.0)\n\n    record_parser = command_parsers.add_parser(\n        'record', help='record topic data', parents=[sub_common_parser])\n    record_parser.add_argument('topic_names', nargs='*',\n                               help='topic names to be recorded', type=str)\n    record_parser.add_argument(\n        '--file', '-f', help='output file name (default: record.json)',\n        type=str, default='record.json')\n\n    play_parser = command_parsers.add_parser(\n        'play', help='play recorded topic data', parents=[pub_common_parser])\n    play_parser.add_argument('file', type=str, help='input file name')\n\n    args = parser.parse_args()\n\n    if args.command == 'pub':\n        pub(args.topic_name, args.data, repeat_rate=args.repeat,\n            host=args.host, pub_port=args.publisher_port)\n    elif args.command == 'echo':\n        echo(args.topic_name, args.num,\n             host=args.host, sub_port=args.subscriber_port)\n    elif args.command == 'list':\n        show_list(args.timeout, host=args.host, sub_port=args.subscriber_port)\n    elif args.command == 'record':\n        record(args.file, args.topic_names,\n               host=args.host, sub_port=args.subscriber_port)\n    elif args.command == 'play':\n        play(args.file, host=args.host, pub_port=args.publisher_port)\n    else:\n        parser.print_help()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef str_to_class(class_name):\n    mod_str, cls_str = class_name.rsplit('.', 1)\n    mod = __import__(mod_str, globals(), locals(), [''])\n    cls = getattr(mod, cls_str)\n    return cls", "response": "Returns a class based on class name    \n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hierarchy_uploader(root):\n    # Workaround to avoid Django 1.7 makemigrations wierd behaviour:\n    # More details: https://code.djangoproject.com/ticket/22436\n    import sys\n    if len(sys.argv) > 1 and sys.argv[1] in ('makemigrations', 'migrate'):\n        # Hide ourselves from Django migrations\n        return None\n\n    from pymisc.utils.files import get_hierarchy_path\n    def upload_to(instance, filename):\n        file_name, file_ext = os.path.splitext(filename)\n        return get_hierarchy_path(str(instance.id), file_ext, root, prefix_path_length=settings.PREFIX_PATH_LENGTH)\n    return upload_to", "response": "Returns uploader that uses get_hierarch_path to store files\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_config_from_setup(app):\n    # for now, assume project root is one level up\n    root = os.path.join(app.confdir, '..')\n    setup_script = os.path.join(root, 'setup.py')\n    fields = ['--name', '--version', '--url', '--author']\n    dist_info_cmd = [sys.executable, setup_script] + fields\n    output = subprocess.check_output(\n        dist_info_cmd,\n        cwd=root,\n        universal_newlines=True,\n    )\n    outputs = output.strip().split('\\n')\n    project, version, url, author = outputs\n    app.config.project = project\n    app.config.version = app.config.release = version\n    app.config.package_url = url\n    app.config.author = app.config.copyright = author", "response": "Load app. config from setup. py"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a field representing the object s own URL.", "response": "def build_url_field(self, field_name, model_class):\n        \"\"\"\n        Create a field representing the object's own URL.\n        \"\"\"\n        field_class = self.serializer_url_field\n        field_kwargs = rest_framework.serializers.get_url_kwargs(model_class)\n        field_kwargs.update({\"parent_lookup_field\": self.get_parent_lookup_field()})\n        return field_class, field_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_parent_lookup_field(self):\n        if hasattr(self.Meta, \"parent_lookup_field\"):\n            return getattr(self.Meta, \"parent_lookup_field\")\n        elif hasattr(self.Meta, \"parent_model\"):\n            model = getattr(self.Meta, \"parent_model\")\n        else:\n            parent_models = filter(\n                lambda field: isinstance(field, db_models.ForeignKey),\n                self.Meta.model._meta.fields\n            )\n            assert len(parent_models) > 0, self.default_error_messages['no_parent']\n            assert len(parent_models) == 1, self.default_error_messages['multiple_parents']\n            model = parent_models[0].related_model\n\n        return '%(model_name)s__pk' % {\n            'app_label': model._meta.app_label,\n            'model_name': model._meta.object_name.lower()\n        }", "response": "Return tha parent_lookup_field for the NestedHyperlinkedModelSerializer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object(self, view_name, view_args, view_kwargs):\n        lookup_value = view_kwargs.get(self.lookup_url_kwarg)\n        parent_lookup_value = view_kwargs.get(self.parent_lookup_field)\n        lookup_kwargs = {\n            self.lookup_field: lookup_value,\n        }\n        # Try to lookup parent attr\n        if parent_lookup_value:\n            lookup_kwargs.update({self.parent_lookup_field: parent_lookup_value})\n        return self.get_queryset().get(**lookup_kwargs)", "response": "Get the object corresponding to a matched URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_url(self, obj, view_name, request, format):\n        # Unsaved objects will not yet have a valid URL.\n        if obj.pk is None:\n            return None\n\n        lookup_value = getattr(obj, self.lookup_field)\n        lookup_kwargs = {\n            self.lookup_field: lookup_value,\n        }\n\n        # Try to lookup parent attr\n        parent_lookup_value = None\n        for attr in self.parent_lookup_field.split(\"__\"):\n            if not hasattr(obj, attr):\n                break\n            parent_lookup_value = getattr(parent_lookup_value or obj, attr)\n        if parent_lookup_value:\n            lookup_kwargs.update({self.parent_lookup_field: parent_lookup_value})\n\n        return self.reverse(view_name, kwargs=lookup_kwargs, request=request, format=format)", "response": "Given an object return the URL that hyperlinks to the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_table(self, drop=False, with_test_data=False):\n        db = self.get_sql_hook(self.sql_conn_id)\n        table = self.table_name\n        if drop:\n            sql = \"DROP TABLE IF EXISTS {table};\".format(**locals())\n            logging.info(\"Executing SQL: \\n\" + sql)\n            db.run(sql)\n        sql = \"\"\"CREATE TABLE IF NOT EXISTS honeypot_logs (\n                log_filepath VARCHAR(255) ,\n                dag_id VARCHAR(255),\n                task_id VARCHAR(255),\n                job_num INT,\n                execution_date DATETIME,\n                duration DOUBLE,\n                input_date DATETIME,\n                num_mappers INT,\n                num_reducers INT,\n                cpu_time LONG,\n                hdfs_reads LONG,\n                hdfs_writes LONG,\n                owner VARCHAR(255));\"\"\".format(**locals())\n        logging.info(\"Executing SQL: \\n\" + sql)\n        db.run(sql)\n        if with_test_data:\n            self.create_test_data()", "response": "Creates the honeypot_log table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a list of filenames into a directory tree structure.", "response": "def list_to_tree(cls, files):\n        \"\"\"Converts a list of filenames into a directory tree structure.\"\"\"\n\n        def attach(branch, trunk):\n            \"\"\"Insert a branch of directories on its trunk.\"\"\"\n            parts = branch.split('/', 1)\n            if len(parts) == 1:  # branch is a file\n                trunk[FILE_MARKER].append(parts[0])\n            else:\n                node, others = parts\n                if node not in trunk:\n                    trunk[node] = defaultdict(dict, ((FILE_MARKER, []), ))\n                attach(others, trunk[node])\n\n        tree = defaultdict(dict, ((FILE_MARKER, []), ))\n        for line in files:\n            attach(line, tree)\n        return tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwalks a tree returned by os. walk returning a list of tuples as if from os. walk", "response": "def tree_walk(cls, directory, tree):\n        \"\"\"Walks a tree returned by `cls.list_to_tree` returning a list of\n        3-tuples as if from os.walk().\"\"\"\n        results = []\n        dirs = [d for d in tree if d != FILE_MARKER]\n        files = tree[FILE_MARKER]\n        results.append((directory, dirs, files))\n        for d in dirs:\n            subdir = os.path.join(directory, d)\n            subtree = tree[d]\n            results.extend(cls.tree_walk(subdir, subtree))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_token_for_user(user: get_user_model()) -> bytes:\n        token = urandom(48)\n        AuthToken.objects.create(\n            hashed_token=AuthToken._hash_token(token),\n            user=user)\n        return token", "response": "Create a random auth token for user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a copy of the object as a string.", "response": "def str(self):\n        \"\"\"Get Access to string functions.\n\n        Returns\n        -------\n        StringMethods\n\n        Examples\n        --------\n        >>> sr = bl.Series([b' aB ', b'GoOsfrABA'])\n        >>> print(sr.str.lower().evaluate())\n        <BLANKLINE>\n        ---  ---------\n          0   ab\n          1  goosfraba\n\n        \"\"\"\n        if self.dtype.char != 'S':\n            raise AttributeError('Can only use .str when data is of type np.bytes_')\n\n        from .strings import StringMethods\n\n        return StringMethods(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates by creating a Series containing evaluated data and index.", "response": "def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        \"\"\"Evaluates by creating a Series containing evaluated data and index.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        Series\n            Series with evaluated data and index.\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(3)) > 0\n        >>> weld_code = sr.values  # accessing values now returns the weld code as a string\n        >>> sr = sr.evaluate()\n        >>> sr.values  # now it is evaluated to raw data\n        array([False,  True,  True])\n\n        \"\"\"\n        # TODO: work on masking (branch masking) ~ evaluate the mask first and use on both index and data;\n        # TODO right now the filter gets computed twice, once for index and once for the data\n        evaluated_data = super(Series, self).evaluate(verbose, decode, passes, num_threads, apply_experimental)\n        evaluated_index = self.index.evaluate(verbose, decode, passes, num_threads, apply_experimental)\n\n        return Series(evaluated_data, evaluated_index, self.dtype, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning Series with the last n values.", "response": "def tail(self, n=5):\n        \"\"\"Return Series with the last n values.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        Series\n            Series containing the last n values.\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(3))\n        >>> print(sr.tail(2).evaluate())\n        <BLANKLINE>\n        ---  --\n          1   1\n          2   2\n\n        \"\"\"\n        if self._length is not None:\n            length = self._length\n        else:\n            length = self._lazy_len().weld_expr\n\n        return _series_tail(self, self.index.tail(n), length, n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef agg(self, aggregations):\n        check_type(aggregations, list)\n\n        new_index = Index(np.array(aggregations, dtype=np.bytes_), np.dtype(np.bytes_))\n\n        return _series_agg(self, aggregations, new_index)", "response": "Multiple aggregations optimized.\n\n        Parameters\n        ----------\n        aggregations : list of str\n            Which aggregations to perform.\n\n        Returns\n        -------\n        Series\n            Series with resulting aggregations."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns unique values in the Series.", "response": "def unique(self):\n        \"\"\"Return unique values in the Series.\n\n        Note that because it is hash-based, the result will NOT be in the same order (unlike pandas).\n\n        Returns\n        -------\n        LazyArrayResult\n            Unique values in random order.\n\n        \"\"\"\n        return LazyArrayResult(weld_unique(self.values,\n                                           self.weld_type),\n                               self.weld_type)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fillna(self, value):\n        if not is_scalar(value):\n            raise TypeError('Value to replace with is not a valid scalar')\n\n        return Series(weld_replace(self.weld_expr,\n                                   self.weld_type,\n                                   default_missing_data_literal(self.weld_type),\n                                   value),\n                      self.index,\n                      self.dtype,\n                      self.name)", "response": "Returns a new Series with missing values replaced with value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply an element - wise UDF to the Series.", "response": "def apply(self, func, mapping=None, new_dtype=None, **kwargs):\n        \"\"\"Apply an element-wise UDF to the Series.\n\n        There are currently 6 options for using a UDF. First 4 are lazy,\n        other 2 are eager and require the use of the raw decorator:\n\n        - One of the predefined functions in baloo.functions.\n        - Implementing a function which encodes the result. kwargs are automatically passed to it.\n        - Pure Weld code and mapping.\n        - Weld code and mapping along with a dynamically linked C++ lib containing the UDF.\n        - Using a NumPy function, which however is EAGER and hence requires self.values to be raw. Additionally, NumPy\n            does not support kwargs in (all) functions so must use raw decorator to strip away weld_type.\n        - Implementing an eager function with the same precondition as above. Use the raw decorator to check this.\n\n        Parameters\n        ----------\n        func : function or str\n            Weld code as a str to encode or function from baloo.functions.\n        mapping : dict, optional\n            Additional mappings in the weld_template to replace on execution.\n            self is added by default to reference to this Series.\n        new_dtype : numpy.dtype, optional\n            Specify the new dtype of the result Series.\n            If None, it assumes it's the same dtype as before the apply.\n\n        Returns\n        -------\n        Series\n            With UDF result.\n\n        Examples\n        --------\n        >>> import baloo as bl\n        >>> sr = bl.Series([1, 2, 3])\n        >>> weld_template = 'map({self}, |e| e + {scalar})'\n        >>> mapping = {'scalar': '2L'}\n        >>> print(sr.apply(weld_template, mapping).evaluate())\n        <BLANKLINE>\n        ---  --\n          0   3\n          1   4\n          2   5\n        >>> weld_template2 = 'map({self}, |e| e + 3L)'\n        >>> print(sr.apply(weld_template2).evaluate())\n        <BLANKLINE>\n        ---  --\n          0   4\n          1   5\n          2   6\n        >>> print(bl.Series([1., 4., 100.]).apply(bl.sqrt).evaluate())  # lazy predefined function\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2  10\n        >>> sr = bl.Series([4, 2, 3, 1])\n        >>> print(sr.apply(bl.sort, kind='q').evaluate())  # eager wrapper over np.sort (which uses raw decorator)\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2   3\n          3   4\n        >>> print(sr.apply(bl.raw(np.sort, kind='q')).evaluate())  # np.sort directly\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2   3\n          3   4\n        >>> print(sr.apply(bl.raw(lambda x: np.sort(x, kind='q'))).evaluate())  # lambda also works, with x = np.array\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2   3\n          3   4\n\n        # check tests/core/cudf/* and tests/core/test_series.test_cudf for C UDF example\n\n        \"\"\"\n        if callable(func):\n            return Series(func(self.values,\n                               weld_type=self.weld_type,\n                               **kwargs),\n                          self.index,\n                          self.dtype,\n                          self.name)\n        elif isinstance(func, str):\n            check_type(mapping, dict)\n            check_dtype(new_dtype)\n\n            default_mapping = {'self': self.values}\n            if mapping is None:\n                mapping = default_mapping\n            else:\n                mapping.update(default_mapping)\n\n            if new_dtype is None:\n                new_dtype = self.dtype\n\n            return Series(weld_udf(func,\n                                   mapping),\n                          self.index,\n                          new_dtype,\n                          self.name)\n        else:\n            raise TypeError('Expected function or str defining a weld_template')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a Series from pandas Series.", "response": "def from_pandas(cls, series):\n        \"\"\"Create baloo Series from pandas Series.\n\n        Parameters\n        ----------\n        series : pandas.series.Series\n\n        Returns\n        -------\n        Series\n\n        \"\"\"\n        from pandas import Index as PandasIndex, MultiIndex as PandasMultiIndex\n\n        if isinstance(series.index, PandasIndex):\n            baloo_index = Index.from_pandas(series.index)\n        elif isinstance(series.index, PandasMultiIndex):\n            baloo_index = MultiIndex.from_pandas(series.index)\n        else:\n            raise TypeError('Cannot convert pandas index of type={} to baloo'.format(type(series.index)))\n\n        return _series_from_pandas(series, baloo_index)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diagnostics(self, **kwds):\n        # Don't process the result automatically, since this raises an exception\n        # on failure, which doesn't provide the cause of the failure\n        self._client.get(\"/system/diagnostics.json\", process_response=False,\n                         **kwds)\n        return self._client.last_response.json()[\"result\"]", "response": "Returns a dictionary containing the results of the diagnostic tests on the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread an allele file.", "response": "def read_source_alleles(file_name):\n    \"\"\"Reads an allele file.\"\"\"\n    alleles = {}\n    open_function = open\n    if file_name.endswith(\".gz\"):\n        open_function = gzip.open\n    with open_function(file_name, 'rb') as input_file:\n        for line in input_file:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            marker_name = row[0]\n            allele1, allele2 = row[1].split(\" \")\n            alleles[marker_name] = {allele1, allele2}\n\n    return alleles"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_statistics(out_dir, gold_prefix, source_prefix, same_samples,\n                       use_sge, final_out_prefix):\n    \"\"\"Compute the statistics.\"\"\"\n    # Now, creating a temporary directory\n    if not os.path.isdir(out_dir):\n        try:\n            os.mkdir(out_dir)\n        except OSError:\n            msg = \"{}: file exists\".format(out_dir)\n            raise ProgramError(msg)\n\n    # The out prefix\n    out_prefix = os.path.join(out_dir, \"tmp\")\n\n    # Subsetting the files\n    logger.info(\"  - Subsetting the files\")\n    for k, (gold_sample, source_sample) in enumerate(same_samples):\n        # Preparing the files\n        try:\n            filename = out_prefix + \"_{}_gold.samples\".format(k)\n            with open(filename, 'w') as output_file:\n                print >>output_file, \"\\t\".join(gold_sample)\n\n            filename = out_prefix + \"_{}_source.samples\".format(k)\n            with open(filename, \"w\") as output_file:\n                print >>output_file, \"\\t\".join(source_sample)\n\n        except IOError:\n            msg = \"can't write in dir {}\".format(out_dir)\n            raise ProgramError(msg)\n\n    # Preparing the files\n    nb = len(same_samples)\n    keepSamples(\n        [gold_prefix]*nb + [source_prefix]*nb,\n        [out_prefix + \"_{}_gold.samples\".format(i) for i in range(nb)] +\n        [out_prefix + \"_{}_source.samples\".format(i) for i in range(nb)],\n        [out_prefix + \"_{}_gold\".format(i) for i in range(nb)] +\n        [out_prefix + \"_{}_source\".format(i) for i in range(nb)],\n        use_sge,\n        transpose=True,\n    )\n\n    # Creating reports\n    # The diff file\n    diff_file = None\n    try:\n        diff_file = open(final_out_prefix + \".diff\", 'w')\n    except IOError:\n        msg = \"{}: can't write file\".format(final_out_prefix + \".diff\")\n        raise ProgramError(msg)\n    # The diff file header\n    print >>diff_file, \"\\t\".join([\"name\", \"famID_source\", \"indID_source\",\n                                  \"famID_gold\", \"indID_gold\", \"geno_source\",\n                                  \"geno_gold\"])\n\n    # The concordance file\n    concordance_file = None\n    try:\n        concordance_file = open(final_out_prefix + \".concordance\", \"w\")\n    except IOError:\n        msg = \"{}: can't write file\".format(final_out_prefix + \".concordance\")\n        raise ProgramError(msg)\n    # The concordance file header\n    print >>concordance_file, \"\\t\".join([\"famID_source\", \"indID_source\",\n                                         \"famID_gold\", \"indID_gold\",\n                                         \"nb_geno\", \"nb_diff\",\n                                         \"concordance\"])\n\n    for k in range(nb):\n        # The samples\n        gold_sample, source_sample = same_samples[k]\n\n        # Reading the source freq file\n        source_genotypes = {}\n        filename = out_prefix + \"_{}_source.tped\".format(k)\n        try:\n            with open(filename, 'r') as input_file:\n                for line in input_file:\n                    row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                    marker_name = row[1]\n                    geno = row[4]\n                    if geno != \"0 0\":\n                        geno = set(geno.split(\" \"))\n                        source_genotypes[marker_name] = geno\n        except IOError:\n            msg = \"{}: no such file\".format(filename)\n            raise ProgramError(msg)\n\n        # Reading the gold freq file\n        gold_genotypes = {}\n        filename = out_prefix + \"_{}_gold.tped\".format(k)\n        try:\n            with open(filename, 'r') as input_file:\n                for line in input_file:\n                    row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                    marker_name = row[1]\n                    geno = row[4]\n                    if geno != \"0 0\":\n                        geno = set(geno.split(\" \"))\n                        gold_genotypes[marker_name] = geno\n        except IOError:\n            msg = \"{}: no such file\".format(filename)\n            raise ProgramError(msg)\n\n        # The genotyped markers in both, with their number\n        genotyped_markers = source_genotypes.viewkeys() & \\\n            gold_genotypes.viewkeys()\n        nb_genotyped = len(genotyped_markers)\n\n        # Finding the number of differences, and creating the diff file\n        nb_diff = 0\n        for marker_name in genotyped_markers:\n            # Getting the genotypes\n            source_geno = source_genotypes[marker_name]\n            gold_geno = gold_genotypes[marker_name]\n\n            # Comparing the genotypes\n            if source_geno != gold_geno:\n                nb_diff += 1\n\n                source_geno_print = list(source_geno - {\"0\"})\n                source_geno_print.sort()\n                if len(source_geno_print) == 1:\n                    source_geno_print.append(source_geno_print[0])\n                gold_geno_print = list(gold_geno - {\"0\"})\n                gold_geno_print.sort()\n                if len(gold_geno_print) == 1:\n                    gold_geno_print.append(gold_geno_print[0])\n                # We print in the diff file\n                print >>diff_file, \"\\t\".join([marker_name,\n                                              \"\\t\".join(source_sample),\n                                              \"\\t\".join(gold_sample),\n                                              \"/\".join(source_geno_print),\n                                              \"/\".join(gold_geno_print)])\n\n        # Creating the concordance file\n        concordance = 0.0\n        if nb_genotyped != 0:\n            concordance = (nb_genotyped - nb_diff) / float(nb_genotyped)\n        print >>concordance_file, \"\\t\".join([\"\\t\".join(source_sample),\n                                             \"\\t\".join(gold_sample),\n                                             str(nb_genotyped), str(nb_diff),\n                                             str(concordance)])\n\n    # Closing the output files\n    diff_file.close()\n    concordance_file.close()\n\n    # Deleating the temporary directory\n    try:\n        shutil.rmtree(out_dir)\n    except IOError:\n        print >>sys.stderr, \"   - Can't delete {}\".format(out_dir)", "response": "Compute the statistics for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_fam_for_samples(required_samples, source, gold):\n    # Checking the source panel\n    source_samples = set()\n    with open(source, 'r') as input_file:\n        for line in input_file:\n            sample = tuple(line.rstrip(\"\\r\\n\").split(\" \")[:2])\n            if sample in required_samples:\n                source_samples.add(sample)\n\n    # Checking the gold standard\n    gold_samples = set()\n    with open(gold, 'r') as input_file:\n        for line in input_file:\n            sample = tuple(line.rstrip(\"\\r\\n\").split(\" \")[:2])\n            if sample in required_samples:\n                gold_samples.add(sample)\n\n    # Checking if we got everything\n    logger.info(\"  - Found {} samples in source panel\".format(\n        len(source_samples),\n    ))\n    logger.info(\"  - Found {} samples in gold standard\".format(\n        len(gold_samples),\n    ))\n\n    if len(required_samples - (source_samples | gold_samples)) != 0:\n        return False\n    else:\n        return True", "response": "Check fam files for required_samples."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_same_samples_file(filename, out_prefix):\n    # The same samples\n    same_samples = []\n\n    # Creating the extraction files\n    gold_file = None\n    try:\n        gold_file = open(out_prefix + \".gold_samples2keep\", 'w')\n    except IOError:\n        msg = \"{}: can't create file\".format(out_prefix + \".gold_samples2keep\")\n        raise ProgramError(msg)\n\n    source_file = None\n    try:\n        source_file = open(out_prefix + \".source_panel_samples2keep\", 'w')\n    except IOError:\n        msg = (\"{}: can't create \"\n               \"file\".format(out_prefix + \".source_panel_samples2keep\"))\n        raise ProgramError(msg)\n\n    with open(filename, 'r') as input_file:\n        for line in input_file:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n            # Getting the samples\n            gold_sample = tuple(row[:2])\n            source_sample = tuple(row[2:])\n            same_samples.append((gold_sample, source_sample))\n\n            # Printing files\n            print >>gold_file, \"\\t\".join(gold_sample)\n            print >>source_file, \"\\t\".join(source_sample)\n\n    # Closing the files\n    gold_file.close()\n    source_file.close()\n\n    return same_samples", "response": "Reads a file containing same samples."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flipSNPs(inPrefix, outPrefix, flipFileName):\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", inPrefix, \"--flip\",\n                    flipFileName, \"--make-bed\", \"--out\", outPrefix]\n    runCommand(plinkCommand)", "response": "Flip SNPs using Plink."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexclude some SNPs and keep some samples using Plink.", "response": "def exclude_SNPs_samples(inPrefix, outPrefix, exclusionSNP=None,\n                         keepSample=None, transpose=False):\n    \"\"\"Exclude some SNPs and keep some samples using Plink.\"\"\"\n    if (exclusionSNP is None) and (keepSample is None):\n        msg = \"Something wront with development... work on that source code...\"\n        raise ProgramError(msg)\n\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", inPrefix, \"--out\",\n                    outPrefix]\n    if exclusionSNP is not None:\n        # We want to exclude SNP\n        plinkCommand.extend([\"--exclude\", exclusionSNP])\n    if keepSample is not None:\n        # We want to keep samples\n        plinkCommand.extend([\"--keep\", keepSample])\n    if transpose:\n        # We want a transpose ped file\n        plinkCommand.extend([\"--recode\", \"--transpose\", \"--tab\"])\n    else:\n        # We want a binary file\n        plinkCommand.append(\"--make-bed\")\n    runCommand(plinkCommand)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the name of the SNPs using Plink.", "response": "def renameSNPs(inPrefix, updateFileName, outPrefix):\n    \"\"\"Updates the name of the SNPs using Plink.\"\"\"\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", inPrefix, \"--update-map\",\n                    updateFileName, \"--update-name\", \"--make-bed\", \"--out\",\n                    outPrefix]\n    runCommand(plinkCommand)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding flipped SNPs and flip them in the data1.", "response": "def findFlippedSNPs(goldFrqFile1, sourceAlleles, outPrefix):\n    \"\"\"Find flipped SNPs and flip them in the data1.\"\"\"\n    goldAlleles = {}\n    with open(goldFrqFile1, \"r\") as inputFile:\n        headerIndex = None\n        for i, line in enumerate(inputFile):\n            row = createRowFromPlinkSpacedOutput(line)\n\n            if i == 0:\n                # This is the header\n                headerIndex = dict([\n                    (row[j], j) for j in xrange(len(row))\n                ])\n\n                # Checking the columns\n                for columnName in [\"SNP\", \"A1\", \"A2\"]:\n                    if columnName not in headerIndex:\n                        msg = \"%(fileName)s: no column named \" \\\n                                \"%(columnName)s\" % locals()\n                        raise ProgramError(msg)\n            else:\n                snpName = row[headerIndex[\"SNP\"]]\n                allele1 = row[headerIndex[\"A1\"]]\n                allele2 = row[headerIndex[\"A2\"]]\n\n                alleles = set([allele1, allele2])\n                if \"0\" in alleles:\n                    alleles.remove(\"0\")\n\n                goldAlleles[snpName] = alleles\n\n    # Finding the SNPs to flip\n    toFlipOutputFile = None\n    try:\n        toFlipOutputFile = open(outPrefix + \".snp_to_flip_in_reference\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.snp_to_flip_in_reference: can't write \" \\\n              \"file\" % locals()\n        raise ProgramError(msg)\n\n    toRemoveOutputFile = None\n    try:\n        toRemoveOutputFile = open(outPrefix + \".snp_to_remove\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.snp_to_remove: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    toRemoveOutputFileExplanation = None\n    try:\n        toRemoveOutputFileExplanation = open(\n            outPrefix + \".snp_to_remove.explanation\",\n            \"w\",\n        )\n        print >>toRemoveOutputFileExplanation, \"\\t\".join([\"Name\", \"Reason\",\n                                                          \"Alleles 1\",\n                                                          \"Alleles 2\"])\n    except IOError:\n        msg = \"%(outPrefix)s.snp_to_remove: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    for snpName in goldAlleles.iterkeys():\n        alleles1 = goldAlleles[snpName]\n        alleles2 = sourceAlleles[snpName]\n\n        if (len(alleles1) == 2) and (len(alleles2) == 2):\n            # Both are heterozygous\n            if (({\"A\", \"T\"} == alleles1 and {\"A\", \"T\"} == alleles2) or\n                    ({\"C\", \"G\"} == alleles1 and {\"C\", \"G\"} == alleles2)):\n                # We can't flip those..., so we remove them\n                print >>toRemoveOutputFile, snpName\n                print >>toRemoveOutputFileExplanation, \"\\t\".join([\n                    snpName,\n                    \"Undetermined\",\n                    \"\".join(alleles1),\n                    \"\".join(alleles2),\n                ])\n            else:\n                if alleles1 != alleles2:\n                    # Let's try the flip one\n                    if flipGenotype(alleles1) == alleles2:\n                        # We need to flip it\n                        print >>toFlipOutputFile, snpName\n                    else:\n                        # Those SNP are discordant...\n                        print >>toRemoveOutputFile, snpName\n                        print >>toRemoveOutputFileExplanation, \"\\t\".join([\n                            snpName,\n                            \"Invalid\",\n                            \"\".join(alleles1),\n                            \"\".join(alleles2),\n                        ])\n        else:\n            # We want to remove this SNP, because there is at least one\n            # homozygous individual\n            print >>toRemoveOutputFile, snpName\n            tmp_allele1 = \"\".join(alleles1)\n            if len(alleles1) == 1:\n                tmp_allele1 += tmp_allele1\n            tmp_allele2 = \"\".join(alleles1)\n            if len(alleles1) == 1:\n                tmp_allele2 += tmp_allele2\n            print >>toRemoveOutputFileExplanation, \"\\t\".join([snpName,\n                                                              \"Homozygous\",\n                                                              tmp_allele1,\n                                                              tmp_allele2])\n\n    # Closing output files\n    toFlipOutputFile.close()\n    toRemoveOutputFile.close()\n    toRemoveOutputFileExplanation.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the overlapping SNPs in 4 different data sets.", "response": "def findOverlappingSNPsWithGoldStandard(prefix, gold_prefixe, out_prefix,\n                                        use_marker_names=False):\n    \"\"\"Find the overlapping SNPs in 4 different data sets.\"\"\"\n    # Reading the main file\n    sourceSnpToExtract = {}\n    if use_marker_names:\n        sourceSnpToExtract = set()\n    duplicates = set()\n    try:\n        with open(prefix + \".bim\", \"r\") as inputFile:\n            for line in inputFile:\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                chromosome = row[0]\n                position = row[3]\n                snpName = row[1]\n\n                if use_marker_names:\n                    sourceSnpToExtract.add(snpName)\n                else:\n                    if (chromosome, position) not in sourceSnpToExtract:\n                        sourceSnpToExtract[(chromosome, position)] = snpName\n                    else:\n                        # It's a duplicate\n                        duplicates.add((chromosome, position))\n    except IOError:\n        msg = \"%s.bim: no such file\" % prefix\n        raise ProgramError(msg)\n\n    # Removing duplicates from the list\n    if not use_marker_names:\n        logger.info(\"  - There are {} duplicated markers \"\n                    \"in {};\".format(len(duplicates), prefix + \".bim\"))\n        logger.info(\"  - removing them for simplicity...\")\n        for snpID in duplicates:\n            del sourceSnpToExtract[snpID]\n\n    # Reading the Gold standard files\n    goldSnpToExtract = {}\n    if use_marker_names:\n        goldSnpToExtract = set()\n    with open(gold_prefixe + \".bim\", \"r\") as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            chromosome = row[0]\n            position = row[3]\n            snpName = row[1]\n\n            if use_marker_names:\n                if snpName in sourceSnpToExtract:\n                    goldSnpToExtract.add(snpName)\n            else:\n                if (chromosome, position) in sourceSnpToExtract:\n                    # We want this SNP\n                    goldSnpToExtract[(chromosome, position)] = snpName\n\n    # Printing the names of the SNPs to extract\n    goldOutputFile = None\n    try:\n        goldOutputFile = open(out_prefix + \".gold_snp_to_extract\", \"w\")\n    except IOError:\n        msg = \"%(out_prefix)s.goldSnpToExtract: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    sourceOutputFile = None\n    try:\n        sourceOutputFile = open(out_prefix + \".source_snp_to_extract\", \"w\")\n    except IOError:\n        msg = \"%(out_prefix)s.sourceSnpToExtract: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    changeNameOutputFile = None\n    try:\n        changeNameOutputFile = open(out_prefix + \".update_names\", \"w\")\n    except IOError:\n        msg = \"%(out_prefix)s.updateNames: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    # Writing the file\n    if use_marker_names:\n        for snpName in goldSnpToExtract:\n            print >>sourceOutputFile, snpName\n            print >>goldOutputFile, snpName\n    else:\n        for snpID in goldSnpToExtract.iterkeys():\n            print >>sourceOutputFile, sourceSnpToExtract[snpID]\n            print >>goldOutputFile, goldSnpToExtract[snpID]\n            print >>changeNameOutputFile, \"\\t\".join([\n                goldSnpToExtract[snpID],\n                sourceSnpToExtract[snpID],\n            ])\n\n    # Closing the output file\n    goldOutputFile.close()\n    sourceOutputFile.close()\n    changeNameOutputFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting a list of SNPs using Plink.", "response": "def extractSNPs(prefixes, snpToExtractFileNames, outPrefixes, runSGE):\n    \"\"\"Extract a list of SNPs using Plink.\"\"\"\n    s = None\n    jobIDs = []\n    jobTemplates = []\n    if runSGE:\n        # Add the environment variable for DRMAA package\n        if \"DRMAA_LIBRARY_PATH\" not in os.environ:\n            t = \"/shares/data/sge/lib/lx24-amd64/libdrmaa.so.1.0\"\n            os.environ[\"DRMAA_LIBRARY_PATH\"] = t\n\n        # Import the python drmaa library\n        try:\n            import drmaa\n        except ImportError:\n            raise ProgramError(\"drmaa is not install, install drmaa\")\n\n        # Initializing a session\n        s = drmaa.Session()\n        s.initialize()\n\n    for k, prefix in enumerate(prefixes):\n        plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", prefix, \"--extract\",\n                        snpToExtractFileNames[k], \"--make-bed\", \"--out\",\n                        outPrefixes[k]]\n\n        if runSGE:\n            # We run using SGE\n            # Creating the job template\n            jt = s.createJobTemplate()\n            jt.remoteCommand = plinkCommand[0]\n            jt.workingDirectory = os.getcwd()\n            jt.jobEnvironment = os.environ\n            jt.args = plinkCommand[1:]\n            jt.jobName = \"_plink_extract_snps\"\n\n            # Running the job\n            jobID = s.runJob(jt)\n\n            # Storing the job template and the job ID\n            jobTemplates.append(jt)\n            jobIDs.append(jobID)\n\n        else:\n            # We run normal\n            runCommand(plinkCommand)\n\n    if runSGE:\n        # We wait for all the jobs to be over\n        hadProblems = []\n        for jobID in jobIDs:\n            retVal = s.wait(jobID, drmaa.Session.TIMEOUT_WAIT_FOREVER)\n            hadProblems.append(retVal.exitStatus == 0)\n\n        # The jobs should be finished, so we clean everything\n        # Deleating the job template, and exiting the session\n        for jt in jobTemplates:\n            s.deleteJobTemplate(jt)\n\n        # Closing the connection\n        s.exit()\n\n        for hadProblem in hadProblems:\n            if not hadProblem:\n                msg = \"Some SGE jobs had errors...\"\n                raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef checkArgs(args):\n    # Check if we have the binary files\n    for prefix in [args.bfile, args.gold_bfile]:\n        if prefix is None:\n            msg = \"no input file\"\n            raise ProgramError(msg)\n        for fileName in [prefix + i for i in [\".bed\", \".bim\", \".fam\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\".format(fileName)\n                raise ProgramError(msg)\n\n    # Check for the same sample file\n    if not os.path.isfile(args.same_samples):\n        msg = \"{}: no such file\".format(args.same_samples)\n        raise ProgramError(msg)\n\n    # Check we have either a manifest or a allele file\n    if (args.source_manifest is None) and (args.source_alleles is None):\n        msg = (\"need an allele file (either an Illumina manifest \"\n               \"[--source-manifest] or a file containing alleles for each \"\n               \"marker [--source-alleles]\")\n        raise ProgramError(msg)\n    if ((args.source_manifest is not None) and\n            (args.source_alleles is not None)):\n        msg = (\"use either --source-manifest or --source-alleles, not both\")\n        raise ProgramError(msg)\n    # Check for the manifests\n    if args.source_manifest is not None:\n        if not os.path.isfile(args.source_manifest):\n            msg = \"{}: no such file\".format(args.source_manifest)\n            raise ProgramError(msg)\n    if args.source_alleles is not None:\n        if not os.path.isfile(args.source_alleles):\n            msg = \"{}: no such file\".format(args.source_alleles)\n            raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options of the\n                 program."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading data and metadata from binary format.", "response": "def _read_binary(self):\n        \"\"\"Reads data and metadata from binary format.\"\"\"\n        # NOTE: binary files store binned data using Fortran-like ordering.\n        # Dimensions are iterated like z, y, x (so x changes fastest)\n\n        header_path = self.path + 'header'\n        with open(header_path) as f_header:\n            self._read_header(f_header.read())\n\n        data = np.fromfile(self.path)\n\n        # separate data by statistic\n        data = data.reshape((len(self.statistics), -1), order='F')\n        data = {stat: data[i] for i, stat in enumerate(self.statistics)}\n\n        # reshape data according to binning\n        data_shape = [dim.n_bins for dim in self.dimensions]\n        data = {k: v.reshape(data_shape, order='F') for k, v in data.items()}\n\n        self.data = data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads data and metadata from ASCII format.", "response": "def _read_ascii(self):\n        \"\"\"Reads data and metadata from ASCII format.\"\"\"\n        # NOTE: ascii files store binned data using C-like ordering.\n        # Dimensions are iterated like x, y, z (so z changes fastest)\n\n        header_str = ''\n        with open(self.path) as f:\n            for line in f:\n                if line.startswith('#'):\n                    header_str += line\n        self._read_header(header_str)\n\n        data = np.loadtxt(self.path, delimiter=',', unpack=True, ndmin=1)\n\n        # separate data by statistic (neglecting bin columns when necessary)\n        n_dim = len(self.dimensions)\n        data = {stat: data[n_dim+i] for i, stat in enumerate(self.statistics)}\n\n        # reshape data according to binning\n        data_shape = [dim.n_bins for dim in self.dimensions]\n        data = {k: v.reshape(data_shape) for k, v in data.items()}\n\n        self.data = data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_header(self, header_str):\n\n        # regular expressions\n        re_float = '[-+]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?'\n        re_uint = '\\d+'\n        re_binning = '{d} in (?P<nbins>' + re_uint + ') bin[ s] '\n        re_binning += 'of (?P<binwidth>' + re_float + ') {unit}'\n\n        # map of dimensions and units\n        dim_units = {\n            'X': 'cm',\n            'Y': 'cm',\n            'Z': 'cm',\n            'R': 'cm',\n            'Phi': 'deg',\n            'Theta': 'deg',\n        }\n\n        # retrieve binning info\n        self.dimensions = []\n        for line in header_str.splitlines():\n\n            for dim, unit in dim_units.items():\n                re_tmp = re_binning.format(d=dim, unit=unit)\n                regex = re.compile(re_tmp)\n                match = regex.search(line)\n\n                if match:\n                    N = int(match.group('nbins'))\n                    width = float(match.group('binwidth'))\n                    dimension = BinnedDimension(dim, unit, N, width)\n                    self.dimensions.append(dimension)\n\n        # retrieve scored quantity info\n        re_score_unit = '# (?P<quant>.+) \\( (?P<unit>.+) \\) : (?P<stats>.+)'\n        re_score_unitless = '# (?P<quant>.+) : (?P<stats>.+)'\n        regex_unit = re.compile(re_score_unit)\n        regex_unitless = re.compile(re_score_unitless)\n\n        for line in header_str.splitlines():\n\n            match = regex_unit.search(line)\n            if match:\n                self.quantity = match.group('quant')\n                self.unit = match.group('unit')\n                self.statistics = match.group('stats').split()\n                break\n\n            match = regex_unitless.search(line)\n            if match:\n                self.quantity = match.group('quant')\n                self.unit = None\n                self.statistics = match.group('stats').split()\n                break", "response": "Reads the metadata from the header string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    logger.info(\"Options used:\")\n    for key, value in vars(args).iteritems():\n        logger.info(\"  --{} {}\".format(key.replace(\"_\", \"-\"), value))\n\n    # Reads the bim file to see if chromosome 23 is there\n    hasSexProblems = None\n    if not checkBim(\"{}.bim\".format(args.bfile), args.nbChr23, \"23\"):\n        logger.info(\"There are not enough markers on chromosome 23: \"\n                    \"STOPPING NOW!\")\n    else:\n        # Run plink \"check-sex\"\n        logger.info(\"Running Plink for sex check\")\n        runPlinkSexCheck(args)\n\n        # Reading plink \"check-sex\" output file\n        logger.info(\"Reading Plink's sex check output to find sex problems\")\n        hasSexProblems = readCheckSexFile(args.out + \".sexcheck\",\n                                          args.out + \".list_problem_sex\",\n                                          args.out + \".list_problem_sex_ids\",\n                                          args.femaleF, args.maleF)\n\n    if hasSexProblems is not None and hasSexProblems:\n        # Run plink to recode chr 23 in a ped format\n        logger.info(\"Creating recoded file for chr23 using Plink\")\n        createPedChr23UsingPlink(args)\n\n        # Compute the hetero percentage\n        logger.info(\"Computing the heterozygous percentage\")\n        computeHeteroPercentage(args.out + \".chr23_recodeA.raw\")\n\n        # Run plink to get chr 24\n        if checkBim(\"{}.bim\".format(args.bfile), 1, \"24\"):\n            logger.info(\"Creating recoded file for chr24 using Plink\")\n            createPedChr24UsingPlink(args)\n\n            # Compute the number of no call\n            logger.info(\"Computing the number of no calls\")\n            computeNoCall(args.out + \".chr24_recodeA.raw\")\n        else:\n            logger.info(\"Not enough markers on chr24\")\n\n        # If required, let's plot the gender plot\n        if args.gender_plot:\n            logger.info(\"Creating the gender plot\")\n            createGenderPlot(args.bfile, args.sex_chr_intensities,\n                             args.out + \".list_problem_sex\",\n                             args.gender_plot_format, args.out)\n\n        # If required, let's plot the LRR and BAF plot\n        if args.lrr_baf:\n            logger.info(\"Creating the LRR and BAF plot\")\n            createLrrBafPlot(\n                raw_dir=args.lrr_baf_raw_dir,\n                problematic_samples=args.out + \".list_problem_sex_ids\",\n                format=args.lrr_baf_format,\n                dpi=args.lrr_baf_dpi,\n                out_prefix=args.out,\n            )", "response": "The main function of the module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createGenderPlot(bfile, intensities, problematic_samples, format,\n                     out_prefix):\n    \"\"\"Creates the gender plot.\n\n    :param bfile: the prefix of the input binary file.\n    :param intensities: the file containing the intensities.\n    :param problematic_samples: the file containing the problematic samples.\n    :param format: the format of the output plot.\n    :param out_prefix: the prefix of the output file.\n\n    :type bfile: str\n    :type intensities: str\n    :type problematic_samples: str\n    :type format: str\n    :type out_prefix: str\n\n    Creates the gender plot of the samples using the\n    :py:mod:`pyGenClean.SexCheck.gender_plot` module.\n\n    \"\"\"\n    gender_plot_options = [\"--bfile\", bfile, \"--intensities\", intensities,\n                           \"--sex-problems\", problematic_samples, \"--format\",\n                           format, \"--out\", out_prefix]\n    try:\n        gender_plot.main(gender_plot_options)\n    except gender_plot.ProgramError as e:\n        msg = \"gender plot: {}\".format(e)\n        raise ProgramError(msg)", "response": "Creates the gender plot of the specified samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef createLrrBafPlot(raw_dir, problematic_samples, format, dpi, out_prefix):\n    # First, we create an output directory\n    dir_name = out_prefix + \".LRR_BAF\"\n    if not os.path.isdir(dir_name):\n        os.mkdir(dir_name)\n\n    # The options\n    baf_lrr_plot_options = [\"--problematic-samples\", problematic_samples,\n                            \"--raw-dir\", raw_dir, \"--format\", format,\n                            \"--dpi\", str(dpi),\n                            \"--out\", os.path.join(dir_name, \"baf_lrr\")]\n    try:\n        baf_lrr_plot.main(baf_lrr_plot_options)\n    except baf_lrr_plot.ProgramError as e:\n        msg = \"BAF LRR plot: {}\".format(e)\n        raise ProgramError(msg)", "response": "Creates the LRR and BAF plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the BIM file for chrN markers.", "response": "def checkBim(fileName, minNumber, chromosome):\n    \"\"\"Checks the BIM file for chrN markers.\n\n    :param fileName:\n    :param minNumber:\n    :param chromosome:\n\n    :type fileName: str\n    :type minNumber: int\n    :type chromosome: str\n\n    :returns: ``True`` if there are at least ``minNumber`` markers on\n              chromosome ``chromosome``, ``False`` otherwise.\n\n    \"\"\"\n    nbMarkers = 0\n    with open(fileName, 'r') as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            if row[0] == chromosome:\n                nbMarkers += 1\n    if nbMarkers < minNumber:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the file and computes the number of no call.", "response": "def computeNoCall(fileName):\n    \"\"\"Computes the number of no call.\n\n    :param fileName: the name of the file\n\n    :type fileName: str\n\n    Reads the ``ped`` file created by Plink using the ``recodeA`` options (see\n    :py:func:`createPedChr24UsingPlink`) and computes the number and percentage\n    of no calls on the chromosome ``24``.\n    \"\"\"\n    outputFile = None\n    try:\n        outputFile = open(fileName + \".noCall\", \"w\")\n    except IOError:\n        msg = \"%s: can't write file\" % fileName + \".noCall\"\n        raise ProgramError(msg)\n    print >>outputFile, \"\\t\".join([\"PED\", \"ID\", \"SEX\", \"nbGeno\", \"nbNoCall\"])\n\n    try:\n        toPrint = []\n        with open(fileName, \"r\") as inputFile:\n            for i, line in enumerate(inputFile):\n                row = line.rstrip(\"\\r\\n\").split(\" \")\n                if i != 0:\n                    # This is data\n                    genotypes = np.array(row[6:])\n\n                    nbMarker = len(genotypes)\n                    nbNA = len(np.where(genotypes == \"NA\")[0])\n\n                    toPrint.append((row[0], row[1], row[4], str(nbMarker),\n                                    str(nbNA)))\n\n        toPrint.sort(reverse=True, key=lambda values: int(values[4]))\n\n        for row in toPrint:\n            print >>outputFile, \"\\t\".join(row)\n\n    except IOError:\n        msg = \"%(fileName)s: no such file\" % locals()\n        raise ProgramError(msg)\n\n    # Closing the output file\n    outputFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef computeHeteroPercentage(fileName):\n    outputFile = None\n    try:\n        outputFile = open(fileName + \".hetero\", \"w\")\n    except IOError:\n        msg = \"%s: can't write file\" % fileName + \".hetero\"\n        raise ProgramError(msg)\n    print >>outputFile, \"\\t\".join([\"PED\", \"ID\", \"SEX\", \"HETERO\"])\n\n    try:\n        toPrint = []\n        with open(fileName, \"r\") as inputFile:\n            for i, line in enumerate(inputFile):\n                row = line.rstrip(\"\\r\\n\").split(\" \")\n                if i != 0:\n                    # This is data\n                    genotypes = np.array(row[6:])\n                    genotypes = genotypes[np.where(genotypes != \"NA\")]\n\n                    nbMarker = len(genotypes)\n                    nbHetero = len(np.where(genotypes == \"1\")[0])\n                    percentHetero = -9999\n                    if nbMarker != 0:\n                        percentHetero = nbHetero / float(nbMarker)\n\n                    toPrint.append((row[0], row[1], row[4], percentHetero))\n\n        # Sorting the data\n        toPrint.sort(reverse=True, key=lambda values: values[3])\n\n        # Printing the data\n        for row in toPrint:\n            value = list(row)\n            if value[3] == -9999:\n                value[3] = \"ALL_NA\"\n            else:\n                value[3] = str(value[3])\n            print >>outputFile, \"\\t\".join(value)\n\n    except IOError:\n        msg = \"%(fileName)s: no such file\" % locals()\n        raise ProgramError(msg)\n\n    # Closing the output file\n    outputFile.close()", "response": "Computes the heterozygosity percentage of the input file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readCheckSexFile(fileName, allProblemsFileName, idsFileName, femaleF,\n                     maleF):\n    \"\"\"Reads the Plink check-sex output file.\n\n    :param fileName: the name of the input file.\n    :param allProblemsFileName: the name of the output file that will contain\n                                all the problems.\n    :param idsFileName: the name of the output file what will contain samples\n                        with sex problems.\n    :param femaleF: the F threshold for females.\n    :param maleF: the F threshold for males.\n\n    :type fileName: str\n    :type allProblemsFileName: str\n    :type idsFileName: str\n    :type femaleF: float\n    :type maleF: float\n\n    :returns: ``True`` if there are sex problems, ``False`` otherwise.\n\n    Reads sex check file provided by :py:func:`runPlinkSexCheck` (Plink) and\n    extract the samples that have sex problems.\n\n    \"\"\"\n    allProblemsFile = None\n    try:\n        allProblemsFile = open(allProblemsFileName, 'w')\n    except IOError:\n        msg = \"%(allProblemsFileName)s: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    idsFile = None\n    try:\n        idsFile = open(idsFileName, 'w')\n    except IOError:\n        msg = \"%(idsFileName)s: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    try:\n        with open(fileName, 'r') as inputFile:\n            headerIndex = None\n            nbProblems = 0\n            nbTotalProblems = 0\n            nbSexUnknown = 0\n            nbFemaleThreshold = 0\n            nbMaleThreshold = 0\n            for line in inputFile:\n                row = createRowFromPlinkSpacedOutput(line)\n\n                if headerIndex is None:\n                    # This is the header\n                    headerIndex = dict([\n                        (row[i], i) for i in xrange(len(row))\n                    ])\n                    for columnName in [\"STATUS\", \"PEDSEX\", \"SNPSEX\", \"F\",\n                                       \"FID\", \"IID\"]:\n                        if columnName not in headerIndex:\n                            msg = \"%(fileName)s: no column named \" \\\n                                  \"%(columnName)s\" % locals()\n                            raise ProgramError(msg)\n                    print >>allProblemsFile, \"\\t\".join(row)\n                    continue\n\n                # We have data\n                status = row[headerIndex[\"STATUS\"]]\n\n                if status == \"PROBLEM\":\n                    # We have a sex problem\n                    nbTotalProblems += 1\n                    pedsex = row[headerIndex[\"PEDSEX\"]]\n\n                    if pedsex == \"0\":\n                        # The individual was \"0\", so we skip\n                        nbSexUnknown += 1\n                        continue\n\n                    snpsex = row[headerIndex[\"SNPSEX\"]]\n                    if snpsex == \"0\":\n                        # The new sex is unknown\n                        f = None\n                        try:\n                            f = float(row[headerIndex[\"F\"]])\n                        except ValueError:\n                            msg = \"F=%s: not a float\" % row[headerIndex[\"F\"]]\n                            raise ProgramError(msg)\n\n                        if pedsex == \"2\":\n                            # We have a female\n                            if f < femaleF:\n                                nbFemaleThreshold += 1\n                                continue\n\n                        if pedsex == \"1\":\n                            # We have a male\n                            if f > maleF:\n                                nbMaleThreshold += 1\n                                continue\n\n                    print >>allProblemsFile, \"\\t\".join(row)\n\n                    famID = row[headerIndex[\"FID\"]]\n                    indID = row[headerIndex[\"IID\"]]\n                    print >>idsFile, \"\\t\".join([famID, indID])\n\n                    nbProblems += 1\n\n            logger.info(\"Sex Check Summary\")\n            logger.info(\"  - {:,d} total problems\".format(nbTotalProblems))\n            logger.info(\"  - {:,d} pedsex unknown\".format(nbSexUnknown))\n            logger.info(\"  - {:,d} female F < {}\".format(nbFemaleThreshold,\n                                                         femaleF))\n            logger.info(\"  - {:,d} male F > {}\".format(nbMaleThreshold, maleF))\n            logger.info(\"  - {:,d} problems kept\".format(nbProblems))\n\n    except IOError:\n        msg = \"%(fileName)s: no such file\"\n\n    # Closing the output files\n    idsFile.close()\n    allProblemsFile.close()\n\n    if nbProblems == 0:\n        # There are no sex problems to investigate\n        logger.info(\"There are no sex problem to investigate...\")\n        logger.info(\"  - Nothing else to do...\")\n        return False\n    return True", "response": "Reads the Plink check - sex output file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createPedChr23UsingPlink(options):\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", options.bfile, \"--chr\",\n                    \"23\", \"--recodeA\", \"--keep\",\n                    options.out + \".list_problem_sex_ids\", \"--out\",\n                    options.out + \".chr23_recodeA\"]\n    runCommand(plinkCommand)", "response": "Run Plink to create a ped file of markers on the chromosome 23."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createPedChr24UsingPlink(options):\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", options.bfile, \"--chr\",\n                    \"24\", \"--recodeA\", \"--keep\",\n                    options.out + \".list_problem_sex_ids\", \"--out\",\n                    options.out + \".chr24_recodeA\"]\n    runCommand(plinkCommand)", "response": "Run Plink to create a ped file of markers on the chromosome 24."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkArgs(args):\n    # Check if we have the tped and the tfam files\n    for fileName in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Ceck the number of markers on chromosome 23\n    if args.nbChr23 < 0:\n        msg = (\"{}: number of markers on chr 23 must be \"\n               \"positive\".format(args.nbChr23))\n        raise ProgramError(msg)\n\n    # If we ask for LRR and BAF, we need a directory\n    if args.lrr_baf:\n        if not os.path.isdir(args.lrr_baf_raw_dir):\n            msg = \"{}: no such directory\".format(args.lrr_baf_raw_dir)\n            raise ProgramError(msg)\n        if args.lrr_baf_dpi < 10:\n            msg = \"{}: DPI too low\".format(args.dpi)\n            raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options for the\n ArcGIS program."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes the cluster use Dill as pickler for transferring results.", "response": "def use_dill( self ):\n        \"\"\"Make the cluster use Dill as pickler for transferring results. This isn't\n        generally needed, but is sometimes useful for particularly complex experiments\n        such as those involving closures. (Or, to put it another way, if you find yourself\n        tempted to use this method, consider re-structuring your experiment code.)\"\"\"\n        self.open()\n        with self.sync_imports(quiet = True):\n            import dill\n        self._client.direct_view().use_dill()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sync_imports( self, quiet = False ):\n        self.open()\n        return self._client[:].sync_imports(quiet = quiet)", "response": "Returns a context manager to control imports onto all the engines\n        in the underlying cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _mixup( self, ps ):\n        for i in range(len(ps) - 1, 0, -1):\n            j = int(numpy.random.random() * i)\n            temp = ps[i]\n            ps[i] = ps[j]\n            ps[j] = temp\n        return ps", "response": "Private method to mix up a list of values in - place using a Fisher - Yates shuffle method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the experiment across the parameter space in parallel using all the engines in the cluster. This method returns immediately. The experiments are run asynchronously, with the points in the parameter space being explored randomly so that intermediate retrievals of results are more representative of the overall result. Put another way, for a lot of experiments the results available will converge towards a final answer, so we can plot them and see the answer emerge. :param e: the experiment", "response": "def runExperiment( self, e ):\n        \"\"\"Run the experiment across the parameter space in parallel using\n        all the engines in the cluster. This method returns immediately.\n\n        The experiments are run asynchronously, with the points in the parameter\n        space being explored randomly so that intermediate retrievals of results\n        are more representative of the overall result. Put another way, for a lot\n        of experiments the results available will converge towards a final\n        answer, so we can plot them and see the answer emerge.\n\n        :param e: the experiment\"\"\"\n\n        # create the parameter space\n        space = self.parameterSpace()\n\n        # only proceed if there's work to do\n        if len(space) > 0:\n            nb = self.notebook()\n            \n            # randomise the order of the parameter space so that we evaluate across\n            # the space as we go along to try to make intermediate (incomplete) result\n            # sets more representative of the overall result set\n            ps = self._mixup(space)\n\n            try:\n                # connect to the cluster\n                self.open()\n\n                # submit an experiment at each point in the parameter space to the cluster\n                view = self._client.load_balanced_view()\n                jobs = []\n                for p in ps:\n                    jobs.extend((view.apply_async((lambda p: e.set(p).run()), p)).msg_ids)\n\n                    # there seems to be a race condition in submitting jobs,\n                    # whereby jobs get dropped if they're submitted too quickly\n                    time.sleep(0.01)\n                \n                # record the mesage ids of all the jobs as submitted but not yet completed\n                psjs = zip(ps, jobs)\n                for (p, j) in psjs:\n                    nb.addPendingResult(p, j)\n            finally:\n                # commit our pending results in the notebook\n                nb.commit()\n                self.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates our results within any pending results that have completed since we last retrieved results from the cluster.", "response": "def updateResults( self ):\n        \"\"\"Update our results within any pending results that have completed since we\n        last retrieved results from the cluster.\n\n        :returns: the number of pending results completed at this call\"\"\"\n\n        # we do all the tests for pending results against the notebook directly,\n        # as the corresponding methods on self call this method themselves\n        nb = self.notebook()\n\n        # look for pending results if we're waiting for any\n        n = 0\n        if nb.numberOfPendingResults() > 0:\n            # we have results to get\n            self.open()\n            for j in set(nb.pendingResults()):\n                # query the status of a job\n                status = self._client.result_status(j, status_only = False)\n                    \n                # add all completed jobs to the notebook\n                if j in status['completed']:\n                    r = status[j]\n                        \n                    # update the result in the notebook, cancelling\n                    # the pending result as well\n                    # values come back from Client.result_status() in\n                    # varying degrees of list-nesting, which LabNotebook.addResult()\n                    # handles itself\n                    nb.addResult(r, j)\n\n                    # commit changes to the notebook\n                    nb.commit()\n\n                    # purge the completed job from the cluster\n                    self._client.purge_hub_results(j)\n                         \n                    # record that we retrieved the results for the given job\n                    n = n + 1\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait( self, timeout = -1 ):\n\n        # we can't use ipyparallel.Client.wait() for this, because that\n        # method only works for cases where the Client object is the one that\n        # submitted the jobs to the cluster hub -- and therefore has the\n        # necessary data structures to perform synchronisation. This isn't the\n        # case for us, as one of the main goals of epyc is to support disconnected\n        # operation, which implies a different Client object retrieving results\n        # than the one that submitted the jobs in the first place. This is\n        # unfortunate, but understandable given the typical use cases for\n        # Client objects.\n        #\n        # Instead. we have to code around a little busily. The ClusterLab.WaitingTime\n        # global sets the latency for waiting, and we repeatedly wait for this amount\n        # of time before updating the results. The latency value essentially controls\n        # how busy this process is: given that most simulations are expected to\n        # be long, a latency in the tens of seconds feels about right as a default\n        if self.numberOfPendingResults() > 0:\n            # we've got pending results, wait for them\n            timeWaited = 0\n            while (timeout < 0) or (timeWaited < timeout):\n                if self.numberOfPendingResults() == 0:\n                    # no pending jobs left, we're complete\n                    return True\n                else:\n                    # not done yet, calculate the waiting period\n                    if timeout == -1:\n                        # wait for the default waiting period\n                        dt = self.WaitingTime\n                    else:\n                        # wait for the default waiting period or until the end of the timeout.\n                        # whichever comes first\n                        if (timeout - timeWaited) < self.WaitingTime:\n                            dt = timeout - timeWaited\n                        else:\n                            dt = self.WaitingTime\n                            \n                    # sleep for a while\n                    time.sleep(dt)\n                    timeWaited = timeWaited + dt\n\n            # if we get here, the timeout expired, so do a final check\n            # and then exit\n            return (self.numberOfPendingResults() == 0)\n\n        else:\n            # no results, so we got them all\n            return True", "response": "Wait for all pending results to be finished."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cancelPendingResultsFor( self, params ):\n        \n        # grab the result job ids\n        jobs = self.pendingResultsFor(params)\n        \n        if len(jobs) > 0:\n            # abort in the cluster\n            self._abortJobs(jobs)\n            \n            # cancel in the notebook                  \n            self.notebook().cancelPendingResultsFor(params)", "response": "Cancel any pending results for the given parameters in the parameter space."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cancelAllPendingResults( self ):\n\n        # grab all the pending job ids\n        jobs = self.pendingResults()\n        \n        if len(jobs) > 0:\n            # abort in the cluster\n            self._abortJobs(jobs)\n            \n            # cancel in the notebook                  \n            self.notebook().cancelAllPendingResults()", "response": "Cancel all pending results."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsort rows in this table preserving a record of how that sort is done in TableFu. options. sorted_by", "response": "def sort(self, column_name=None, reverse=False):\n        \"\"\"\n        Sort rows in this table, preserving a record of how that\n        sorting is done in TableFu.options['sorted_by']\n        \"\"\"\n        if not column_name and self.options.has_key('sorted_by'):\n            column_name = self.options['sorted_by'].keys()[0]\n        if column_name not in self.default_columns:\n            raise ValueError(\"%s isn't a column in this table\" % column_name)\n        index = self.default_columns.index(column_name)\n        self.table.sort(key = lambda row: row[index], reverse=reverse)\n        self.options['sorted_by'] = {column_name: {'reverse': reverse}}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new TableFu instance with only the rows where the values match exactly * query.", "response": "def filter(self, func=None, **query):\n        \"\"\"\n        Tables can be filtered in one of two ways:\n         - Simple keyword arguments return rows where values match *exactly*\n         - Pass in a function and return rows where that function evaluates to True\n        \n        In either case, a new TableFu instance is returned\n        \"\"\"\n        if callable(func):\n            result = filter(func, self)\n            result.insert(0, self.default_columns)\n            return TableFu(result, **self.options)\n        else:\n            result = self\n            for column, value in query.items():\n                result = result.filter(lambda r: r[column] == value)\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a list of TableFu instances with rows matching the given column.", "response": "def facet_by(self, column):\n        \"\"\"\n        Faceting creates new TableFu instances with rows matching\n        each possible value.\n        \"\"\"\n        faceted_spreadsheets = {}\n        for row in self.rows:\n            if row[column]:\n                col = row[column].value\n                if faceted_spreadsheets.has_key(col):\n                    faceted_spreadsheets[col].append(row.cells)\n                else:\n                    faceted_spreadsheets[col] = []\n                    faceted_spreadsheets[col].append(row.cells)\n\n        # create a new TableFu instance for each facet\n        tables = []\n        for k, v in faceted_spreadsheets.items():\n            v.insert(0, self.default_columns)\n            table = TableFu(v)\n            table.faceted_on = k\n            table.formatting = self.formatting\n            table.options = self.options\n            tables.append(table)\n\n        tables.sort(key=lambda t: t.faceted_on)\n        return tables"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map(self, func, *columns):\n        if not columns:\n            return map(func, self.rows)\n        else:\n            values = (self.values(column) for column in columns)\n            result = [map(func, v) for v in values]\n            if len(columns) == 1:\n                return result[0]\n            else:\n                return result", "response": "Map a function to rows or columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef csv(self, **kwargs):\n        out = StringIO()\n        writer = csv.DictWriter(out, self.columns, **kwargs)\n        writer.writerow(dict(zip(self.columns, self.columns)))\n        writer.writerows(dict(row.items()) for row in self.rows)\n        \n        return out", "response": "Export this table as a CSV"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new TableFu instance from a file or path", "response": "def from_file(fn, **options):\n        \"\"\"\n        Creates a new TableFu instance from a file or path\n        \"\"\"\n        if hasattr(fn, 'read'):\n            return TableFu(fn, **options)\n        with open(fn) as f:\n            return TableFu(f, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_url(url, **options):\n        resp = urllib2.urlopen(url)\n        return TableFu(resp, **options)", "response": "Download the contents of a given URL and loads it into a TableFu instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, column_name, default=None):\n        if column_name in self.table.default_columns:\n            index = self.table.default_columns.index(column_name)\n            return Datum(self.cells[index], self.row_num, column_name, self.table)\n        return default", "response": "Return the Datum for the given column_name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the scree plot.", "response": "def create_scree_plot(data, o_filename, options):\n    \"\"\"Creates the scree plot.\n\n    :param data: the eigenvalues.\n    :param o_filename: the name of the output files.\n    :param options: the options.\n\n    :type data: numpy.ndarray\n    :type o_filename: str\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # Importing plt\n    mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    plt.ioff()\n\n    # Computing the cumulative sum\n    cumul_data = np.cumsum(data)\n\n    # Creating the figure and axes\n    fig, axes = plt.subplots(2, 1, figsize=(8, 16))\n\n    # The title of the figure\n    fig.suptitle(options.scree_plot_title, fontsize=16, weight=\"bold\")\n\n    fig.subplots_adjust(hspace=0.27, top=0.93, bottom=0.06)\n\n    # Modifying the spines\n    for axe in axes:\n        axe.xaxis.set_ticks_position(\"bottom\")\n        axe.yaxis.set_ticks_position(\"left\")\n        axe.spines[\"top\"].set_visible(False)\n        axe.spines[\"right\"].set_visible(False)\n        axe.spines[\"left\"].set_position((\"outward\", 9))\n        axe.spines[\"bottom\"].set_position((\"outward\", 9))\n\n    # First, plotting the eigenvalues\n    axes[0].set_title(\"Scree Plot\", weight=\"bold\")\n    axes[0].set_xlabel(\"Component\")\n    axes[0].set_ylabel(\"Eigenvalue\")\n    axes[0].plot(np.arange(len(data)) + 1, data, marker=\"o\", c=\"#0099CC\",\n                 mec=\"#0099CC\", ls=\"-\", lw=2, clip_on=False)\n\n    # Then, plotting the annotation\n    for i in range(len(data)):\n        axes[0].annotate(np.round(data[i], 3),\n                         xy=(np.arange(len(data))[i] + 1, data[i]),\n                         xytext=(1, 10), textcoords=\"offset points\",\n                         ha=\"left\", va=\"bottom\",\n                         bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"#FFFFFF\"))\n\n    # Next plot the cumulative values\n    axes[1].set_title((\"Cumulative explained variance \"\n                       \"(max={:.3f})\".format(np.sum(data))), weight=\"bold\")\n    axes[1].set_xlabel(\"Component\")\n    axes[1].set_ylabel(\"Cumulative explained variance\")\n    axes[1].axhline(np.sum(data) * 0.8, ls=\"--\", lw=\"2\", c=\"#999999\")\n    axes[1].plot(np.arange(len(data)) + 1, cumul_data, marker=\"o\", c=\"#CC0000\",\n                 mec=\"#CC0000\", mfc=\"#CC0000\", ls=\"-\", lw=2, clip_on=False)\n\n    # Then, plotting the annotation\n    for i in range(len(data)):\n        axes[1].annotate(np.round(cumul_data[i], 3),\n                         xy=(np.arange(len(data))[i] + 1, cumul_data[i]),\n                         xytext=(1, -10), textcoords=\"offset points\",\n                         ha=\"left\", va=\"top\",\n                         bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"#FFFFFF\"))\n\n    # Saving the file\n    plt.savefig(o_filename, dpi=300)\n    plt.close(fig)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the eigenvalues from EIGENSOFT results.", "response": "def read_eigenvalues(i_filename):\n    \"\"\"Reads the eigenvalues from EIGENSOFT results.\n\n    :param i_filename: the name of the input file.\n\n    :type i_filename: str\n\n    :returns: a :py:class:`numpy.ndarray` array containing the eigenvalues.\n\n    \"\"\"\n    # The data is the first line of the result file (should begin with\n    # \"#eigvals\"\n    data = None\n    with open(i_filename, \"r\") as i_file:\n        data = re.split(\n            r\"\\s+\",\n            re.sub(r\"(^\\s+)|(\\s+$)\", \"\", i_file.readline()),\n        )\n        if not data[0].startswith(\"#eigvals\"):\n            m = \"{}: not a evec file\".format(i_filename)\n            raise ProgramError(m)\n        data = np.array(data[1:], dtype=float)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the arguments and options.", "response": "def check_args(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options and arguments of the program.\n\n    :type args: :py:class:`argparse.Namespace`\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exits with error code 1.\n\n    \"\"\"\n    # Checking that the input file exists\n    if not os.path.isfile(args.evec):\n        m = \"{}: no such file\".format(args.evec)\n        raise ProgramError(m)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the command line options and arguments.", "response": "def parse_args(argString=None):\n    \"\"\"Parses the command line options and arguments.\n\n    :returns: A :py:class:`argparse.Namespace` object created by the\n              :py:mod:`argparse` module. It contains the values of the\n              different options.\n\n    ====================== ====== ================================\n            Options         Type            Description\n    ====================== ====== ================================\n    ``--evec``             string The EVEC file from EIGENSOFT\n    ``--scree-plot-title`` string The main title of the scree plot\n    ``--out``              string The name of the output file\n    ====================== ====== ================================\n\n    .. note::\n        No option check is done here (except for the one automatically done by\n        :py:mod:`argparse`). Those need to be done elsewhere (see\n        :py:func:`checkArgs`).\n\n    \"\"\"\n    args = None\n    if argString is None:\n        args = parser.parse_args()\n    else:\n        args = parser.parse_args(argString)\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites json data to file", "response": "def dump_json(token_dict, dump_path):\n    \"\"\"write json data to file\n    \"\"\"\n    if sys.version > '3':\n        with open(dump_path, 'w', encoding='utf-8') as output_file:\n            json.dump(token_dict, output_file, indent=4)\n    else:\n        with open(dump_path, 'w') as output_file:\n            json.dump(token_dict, output_file, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse():\n        parser = argparse.ArgumentParser(\n            description='BabelFy Entity Tagger',\n            formatter_class=argparse.RawTextHelpFormatter\n            )\n        group = parser.add_mutually_exclusive_group()\n        group.add_argument(\n            '-t',\n            '--text',\n            help='text to be annotated by BabelFy API',\n            metavar='',\n            )\n        group.add_argument(\n            '-tf',\n            '--text-file',\n            help='path to the file containing the input text',\n            metavar='',\n            )\n        parser.add_argument(\n            '-key',\n            '--api-key',\n            help='BabelFy API key',\n            metavar='',\n            required=False,\n            )\n        parser.add_argument(\n            '-e',\n            '--entities',\n            help='get entity data',\n            required=False,\n            action='store_true',\n            )\n        parser.add_argument(\n            '-ae',\n            '--all-entities',\n            help='get entity and non-entity data',\n            required=False,\n            action='store_true',\n            )\n        parser.add_argument(\n            '-m',\n            '--merged-entities',\n            help='get merged entities only',\n            required=False,\n            action='store_true',\n            )\n        parser.add_argument(\n            '-am',\n            '--all-merged-entities',\n            help='get all merged entities',\n            required=False,\n            action='store_true',\n            )\n        parser.add_argument(\n            '-p',\n            '--print',\n            help='dump all babelfy data to stdout',\n            required=False,\n            action='store_true',\n            )\n        parser.add_argument(\n            '-ex',\n            '--export',\n            help='filename of the output file',\n            required=False,\n            metavar='',\n            )\n\n        return vars(parser.parse_args())", "response": "parse command line arguments and return dict of keys and values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(self, x):\n        self.acc[0] = x * self.TAPS[-1]\n        for i in range(1, len(self.acc)):\n            self.acc[i] = self.acc[i - 1] + x * self.TAPS[len(self.TAPS) - 1 - i]\n\n        self.out = self.acc[-1]\n        return self.out", "response": "This function is used to generate the FIR structure for the given time period."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pg_version(using=None):\n    connection = get_connection(using)\n    cursor = connection.cursor()\n\n    cursor.execute('SHOW server_version')\n    row = cursor.fetchone()\n\n    return tuple([int(i) for i in row[0].split('.')])", "response": "Returns tuple with PostgreSQL version of a specific connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields a batch of tuples for each article in the given queryset.", "response": "def batch_qs(qs, batch_size=1000):\n    \"\"\"\n    Returns a (start, end, total, queryset) tuple for each batch in the given\n    queryset.\n\n    Usage:\n        # Make sure to order your queryset\n        article_qs = Article.objects.order_by('id')\n        for start, end, total, qs in batch_qs(article_qs):\n            print \"Now processing %s - %s of %s\" % (start + 1, end, total)\n            for article in qs:\n                print article.body\n    \"\"\"\n    total = qs.count()\n    for start in range(0, total, batch_size):\n        end = min(start + batch_size, total)\n        yield (start, end, total, qs[start:end])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self, **kwds):\n        tags = self._client.get(\"/tags/list.json\", **kwds)[\"result\"]\n        tags = self._result_to_list(tags)\n        return [Tag(self._client, tag) for tag in tags]", "response": "Endpoint : / tags. json\n        Returns a list of Tag objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, tag, **kwds):\n        return self._client.post(\"/tag/create.json\", tag=tag, **kwds)[\"result\"]", "response": "This method creates a new tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, tag, **kwds):\n        result = self._client.post(\"/tag/%s/update.json\" %\n                                   self._quote_url(self._extract_id(tag)),\n                                   **kwds)[\"result\"]\n        return Tag(self._client, result)", "response": "This method updates a tag with the specified parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrecords an event for identity with any properties.", "response": "def record(self, action, props=None, path=KISSmetrics.RECORD_PATH,\n               resp=False):\n        \"\"\"Record event for identity with any properties.\n\n        :param action: event performed\n        :param props: any additional data to include\n        :type props: dict\n        :param resp: indicate whether to return response\n        :type resp: boolean\n\n        :returns: an HTTP response for request if `resp=True`\n        :rtype: `urllib3.response.HTTPResponse`\n\n        :raises: Exception if either `identity` or `key` not set\n\n        \"\"\"\n        self.check_id_key()\n        timestamp = None\n        if not props:\n            props = {}\n        response = self.client.record(person=self.identity, event=action,\n                                      properties=props, timestamp=timestamp,\n                                      path=path)\n        if resp:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, data, path=KISSmetrics.SET_PATH, resp=False):\n        self.check_id_key()\n        timestamp = None\n        response = self.client.set(person=self.identity, properties=data,\n                                   timestamp=timestamp, path=path)\n        if resp:\n            return response", "response": "Set a properties provided in data for identity."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps name to alias_to", "response": "def alias(self, name, alias_to, path=KISSmetrics.ALIAS_PATH, resp=False):\n        \"\"\"Map `name` to `alias_to`; actions done by one resolve to other.\n\n        :param name: consider as same individual as ``alias_to``\n        :param alias_to: consider an alias of ``name``\n        :param path: endpoint path; defaults to ``KISSmetrics.ALIAS_PATH``\n        :param resp: indicate whether to return response\n        :type resp: boolean\n\n        :returns: an HTTP response for request if `resp=True`\n        :rtype: `urllib3.response.HTTPResponse`\n\n        :raises: Exception if either `identity` or `key` not set\n\n        \"\"\"\n        self.check_init()\n        response = self.client.alias(person=name, identity=alias_to, path=path)\n        if resp:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the probability mass function for a set of samples and a set of y.", "response": "def PMF(samples, y):\n    \"\"\" Compute the probability mass function.\n\n        The set of samples defines a probability density P(y),\n        which is computed using a kernel density estimator.\n\n        From :math:`P(y)` we define:\n\n        :math:`\\mathrm{pmf}(p) = \\int_{P(y)<p} P(y) dy`\n\n        This is the cumulative distribution function expressed as a\n        function of the probability\n\n        We aim to compute :math:`M(y)`, which indicates the amount of\n        probability contained outside the iso-probability contour\n        passing through :math:`y`::\n\n\n             ^ P(y)                   ...\n             |                     | .   .\n             |                     |       .\n            p|- - - - - - - - - - .+- - - - . - - - - - - - - - - -\n             |                   .#|        #.\n             |                  .##|        ##.\n             |                  .##|        ##.\n             |                 .###|        ###.     M(p)\n             |                 .###|        ###.     is the\n             |                 .###|        ###.     shaded area\n             |                .####|        ####.\n             |                .####|        ####.\n             |              ..#####|        #####..\n             |          ....#######|        #######....\n             |         .###########|        ###########.\n             +---------------------+-------------------------------> y\n                                  t\n\n             ^ M(p)                        ^ M(y)\n             |                             |\n            1|                +++         1|         +\n             |               +             |        + +\n             |       ++++++++              |       +   +\n             |     ++                      |     ++     ++\n             |   ++                        |   ++         ++\n             |+++                          |+++             +++\n             +---------------------> p     +---------------------> y\n            0\n\n        Parameters\n        ----------\n        samples: array-like\n            Array of samples from a probability density P(y).\n\n        y: array-like (optional)\n            Array to evaluate the PDF at\n\n        Returns\n        -------\n        1D numpy.array:\n            PMF evaluated at each y value\n\n    \"\"\"\n    # Remove any nans from the samples\n    samples = numpy.array(samples)\n    samples = samples[~numpy.isnan(samples)]\n    try:\n        # Compute the kernel density estimate\n        kernel = scipy.stats.gaussian_kde(samples)\n\n        # Add two more samples definitely outside the range and sort them\n        mn = min(samples) - 10*numpy.sqrt(kernel.covariance[0, 0])\n        mx = max(samples) + 10*numpy.sqrt(kernel.covariance[0, 0])\n        y_ = numpy.linspace(mn, mx, len(y)*10)\n\n        # Compute the probabilities at each of the extended samples\n        ps_ = kernel(y_)\n\n        # Compute the masses\n        ms = []\n        for yi in y:\n            # compute the probability at this y value\n            p = kernel(yi)\n            if p <= max(ps_)*1e-5:\n                m = 0.\n            else:\n                # Find out which samples have greater probability than P(y)\n                bools = ps_ > p\n\n                # Compute indices where to start and stop the integration\n                stops = numpy.where(numpy.logical_and(~bools[:-1], bools[1:]))\n                starts = numpy.where(numpy.logical_and(bools[:-1], ~bools[1:]))\n\n                # Compute locations\n                starts = [scipy.optimize.brentq(lambda u: kernel(u)-p,\n                                                y_[i], y_[i+1])\n                          for i in starts[0]]\n                starts = [-numpy.inf] + starts\n                stops = [scipy.optimize.brentq(lambda u: kernel(u)-p,\n                                               y_[i], y_[i+1])\n                         for i in stops[0]]\n                stops = stops + [numpy.inf]\n\n                # Sum up the masses\n                m = sum(kernel.integrate_box_1d(a, b)\n                        for a, b in zip(starts, stops))\n            ms.append(m)\n        return numpy.array(ms)\n\n    except numpy.linalg.LinAlgError:\n        return numpy.zeros_like(y)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_pmf(fsamps, y, **kwargs):\n    parallel = kwargs.pop('parallel', False)\n    cache = kwargs.pop('cache', '')\n    tqdm_kwargs = kwargs.pop('tqdm_kwargs', {})\n    if kwargs:\n        raise TypeError('Unexpected **kwargs: %r' % kwargs)\n\n    if cache:\n        cache = Cache(cache + '_masses')\n        try:\n            return cache.check(fsamps, y)\n        except CacheException as e:\n            print(e)\n\n    masses = parallel_apply(PMF, fsamps, postcurry=(y,), parallel=parallel,\n                            tqdm_kwargs=tqdm_kwargs)\n    masses = numpy.array(masses).transpose().copy()\n\n    if cache:\n        cache.save(fsamps, y, masses)\n\n    return masses", "response": "Compute the PMF at each x for each y."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weld_range(start, stop, step):\n    if isinstance(stop, WeldObject):\n        obj_id, weld_obj = create_weld_object(stop)\n        stop = obj_id\n    else:\n        weld_obj = create_empty_weld_object()\n\n    weld_template = \"\"\"result(\n    for(\n        rangeiter({start}L, {stop}, {step}L),\n        appender[i64],\n        |b: appender[i64], i: i64, e: i64| \n            merge(b, e)\n    )\n)\"\"\"\n\n    stop = '{}L'.format(stop) if isinstance(stop, int) else stop\n\n    weld_obj.weld_code = weld_template.format(start=start,\n                                              stop=stop,\n                                              step=step)\n\n    return weld_obj", "response": "Create a vector for the range parameters above."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weld_compare(array, scalar, operation, weld_type):\n    obj_id, weld_obj = create_weld_object(array)\n\n    if not isinstance(scalar, str):\n        scalar = to_weld_literal(scalar, weld_type)\n\n    cast = '{type}({scalar})'.format(type=weld_type, scalar=scalar)\n    # actually checking WeldVec(WeldChar)\n    if isinstance(weld_type, WeldVec):\n        cast = get_weld_obj_id(weld_obj, scalar)\n\n    # TODO: there should be no casting! requires Weld fix\n    weld_template = \"\"\"map(\n    {array},\n    |a: {type}| \n        a {operation} {cast}\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              operation=operation,\n                                              type=weld_type,\n                                              cast=cast)\n\n    return weld_obj", "response": "Applies comparison operation between each element in the array with scalar."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new array only with the elements with a corresponding True in bool_array.", "response": "def weld_filter(array, weld_type, bool_array):\n    \"\"\"Returns a new array only with the elements with a corresponding True in bool_array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    weld_type : WeldType\n        Type of the elements in the input array.\n    bool_array : numpy.ndarray or WeldObject\n        Array of bool with True for elements in array desired in the result array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n    bool_obj_id = get_weld_obj_id(weld_obj, bool_array)\n\n    weld_template = \"\"\"result(\n    for(\n        zip({array}, {bool_array}),\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: {{{type}, bool}}| \n            if (e.$1, \n                merge(b, e.$0), \n                b)\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              bool_array=bool_obj_id,\n                                              type=weld_type)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weld_slice(array, weld_type, slice_, default_start=0, default_stop=0, default_step=1):\n    from ..core.utils import replace_slice_defaults\n\n    slice_ = replace_slice_defaults(slice_, default_start, default_stop, default_step)\n    obj_id, weld_obj = create_weld_object(array)\n\n    if slice_.step == 1:\n        weld_template = \"\"\"slice(\n    {array},\n    {slice_start},\n    {slice_stop}\n)\"\"\"\n    else:\n        weld_template = \"\"\"result(\n    for(\n        iter({array}, {slice_start}, {slice_stop}, {slice_step}),\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: {type}| \n            merge(b, n)\n    )  \n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              slice_start='{}L'.format(slice_.start),\n                                              slice_stop='{}L'.format(slice_.stop - slice_.start),\n                                              slice_step='{}L'.format(slice_.step))\n\n    return weld_obj", "response": "Returns a new array according to the given slice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weld_tail(array, length, n):\n    obj_id, weld_obj = create_weld_object(array)\n    if isinstance(length, WeldObject):\n        length = get_weld_obj_id(weld_obj, length)\n        slice_start = '{} - {}L'.format(length, n)\n        slice_stop = '{}'.format(length)\n    else:\n        slice_start = '{}L - {}L'.format(length, n)\n        slice_stop = '{}L'.format(length)\n\n    weld_template = \"\"\"slice(\n    {array},\n    {slice_start},\n    {slice_stop}\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              slice_start=slice_start,\n                                              slice_stop=slice_stop)\n\n    return weld_obj", "response": "Return the last n elements in the array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply operation to each pair of elements in the arrays.", "response": "def weld_array_op(array1, array2, result_type, operation):\n    \"\"\"Applies operation to each pair of elements in the arrays.\n\n    Their lengths and types are assumed to be the same.\n\n    Parameters\n    ----------\n    array1 : numpy.ndarray or WeldObject\n        Input array.\n    array2 : numpy.ndarray or WeldObject\n        Second input array.\n    result_type : WeldType\n        Weld type of the result. Expected to be the same as both input arrays.\n    operation : {'+', '-', '*', '/', '&&', '||', 'pow'}\n        Which operation to apply. Note bitwise operations (not included) seem to be bugged at the LLVM level.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id1, weld_obj = create_weld_object(array1)\n    obj_id2 = get_weld_obj_id(weld_obj, array2)\n\n    if operation == 'pow':\n        action = 'pow(e.$0, e.$1)'\n    else:\n        action = 'e.$0 {operation} e.$1'.format(operation=operation)\n\n    weld_template = \"\"\"result(\n    for(zip({array1}, {array2}), \n        appender[{type}], \n        |b: appender[{type}], i: i64, e: {{{type}, {type}}}| \n            merge(b, {action})\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array1=obj_id1,\n                                              array2=obj_id2,\n                                              type=result_type,\n                                              action=action)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninverting a bool array.", "response": "def weld_invert(array):\n    \"\"\"Inverts a bool array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"result(\n    for({array},\n        appender[bool],\n        |b: appender[bool], i: i64, e: bool|\n            if(e, merge(b, false), merge(b, true))\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weld_iloc_int(array, index):\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = 'lookup({array}, {index}L)'\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              index=index)\n\n    return weld_obj", "response": "Retrieves the value at index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the values at indices.", "response": "def weld_iloc_indices(array, weld_type, indices):\n    \"\"\"Retrieve the values at indices.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n    weld_type : WeldType\n        The WeldType of the array data.\n    indices : numpy.ndarray or WeldObject\n        The indices to lookup.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    weld_obj = create_empty_weld_object()\n    weld_obj_id_array = get_weld_obj_id(weld_obj, array)\n    weld_obj_id_indices = get_weld_obj_id(weld_obj, indices)\n\n    weld_template = \"\"\"result(\n    for({indices},\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: i64|\n            merge(b, lookup({array}, e))\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=weld_obj_id_array,\n                                              indices=weld_obj_id_indices,\n                                              type=weld_type)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the values at indices.", "response": "def weld_iloc_indices_with_missing(array, weld_type, indices):\n    \"\"\"Retrieve the values at indices. Indices greater than array length get replaced with\n    a corresponding-type missing value literal.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n    weld_type : WeldType\n        The WeldType of the array data.\n    indices : numpy.ndarray or WeldObject\n        The indices to lookup.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    weld_obj = create_empty_weld_object()\n    weld_obj_id_array = get_weld_obj_id(weld_obj, array)\n    weld_obj_id_indices = get_weld_obj_id(weld_obj, indices)\n\n    missing_literal = default_missing_data_literal(weld_type)\n    if weld_type == WeldVec(WeldChar()):\n        missing_literal = get_weld_obj_id(weld_obj, missing_literal)\n\n    weld_template = \"\"\"let len_array = len({array});\nresult(\n    for({indices},\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: i64|\n            if(e >= len_array,\n                merge(b, {missing}),\n                merge(b, lookup({array}, e))\n            )\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=weld_obj_id_array,\n                                              indices=weld_obj_id_indices,\n                                              type=weld_type,\n                                              missing=missing_literal)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weld_element_wise_op(array, weld_type, scalar, operation):\n    obj_id, weld_obj = create_weld_object(array)\n\n    scalar = to_weld_literal(scalar, weld_type)\n\n    if operation == 'pow':\n        action = 'pow(e, {scalar})'.format(scalar=scalar)\n    else:\n        action = 'e {operation} {scalar}'.format(scalar=scalar,\n                                                 operation=operation)\n\n    weld_template = \"\"\"result(\n    for({array}, \n        appender[{type}], \n        |b: appender[{type}], i: i64, e: {type}| \n            merge(b, {action})\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              action=action)\n\n    return weld_obj", "response": "Applies operation to each element in the array with scalar."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsorts the arrays in the same order.", "response": "def weld_sort(arrays, weld_types, readable_text, ascending=True):\n    \"\"\"Sort the arrays.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Arrays to put in a struct.\n    weld_types : list of WeldType\n        The Weld types of the arrays in the same order.\n    readable_text : str\n        Explanatory string to add in the Weld placeholder.\n    ascending : bool, optional\n\n    Returns\n    -------\n    list of WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    weld_obj_sort = _weld_sort(arrays, weld_types, ascending)\n    weld_obj_struct = weld_vec_of_struct_to_struct_of_vec(weld_obj_sort, weld_types)\n    weld_obj_indices = weld_select_from_struct(weld_obj_struct, 0)\n\n    intermediate_result = LazyArrayResult(weld_obj_indices, WeldLong())\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, readable_text)\n\n    fake_weld_input = Cache.create_fake_array_input(dependency_name, readable_text + '_indices')\n    obj_id, weld_obj = create_weld_object(fake_weld_input)\n    weld_obj.weld_code = '{}'.format(obj_id)\n    Cache.cache_fake_input(obj_id, fake_weld_input)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weld_unique(array, weld_type):\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"map(\n    tovec(\n        result(\n            for(\n                map(\n                    {array},\n                    |e| \n                        {{e, 0si}}\n                ),\n                dictmerger[{type}, i16, +],\n                |b: dictmerger[{type}, i16, +], i: i64, e: {{{type}, i16}}| \n                    merge(b, e)\n            )\n        )\n    ),\n    |e| \n        e.$0\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type)\n\n    return weld_obj", "response": "Returns the unique elements of the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weld_drop_duplicates(arrays, weld_types, subset_indices, keep):\n    weld_obj_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n\n    obj_id, weld_obj = create_weld_object(weld_obj_struct)\n\n    all_indices = list(range(len(arrays)))\n    value_indices = list(filter(lambda x: x not in subset_indices, all_indices))\n    key_weld_types = [weld_types[i] for i in subset_indices]\n    value_weld_types = [weld_types[i] for i in value_indices]\n\n    key_types = struct_of('{e}', key_weld_types)\n    value_types = struct_of('{e}', value_weld_types)\n    all_types = struct_of('{e}', weld_types)\n    key_merges = struct_of('e.${e}', subset_indices)\n    value_merges = struct_of('e.${e}', value_indices)\n\n    # flattening the struct of struct\n    results = []\n    key_i = 0\n    value_i = 0\n    for i in all_indices:\n        if i in subset_indices:\n            results.append('e.${}.${}'.format(0, key_i))\n            key_i += 1\n        else:\n            results.append('e.${}.${}'.format(1, value_i))\n            value_i += 1\n    res = '{{{}}}'.format(', '.join(results))\n\n    weld_template = \"\"\"map(\n    tovec(\n        result(\n            for(\n                map(\n                    {arrays},\n                    |e: {all_types}| \n                        {{{key_merges}, {value_merges}}}\n                ),\n                dictmerger[{key_types}, {value_types}, {keep}],\n                |b: dictmerger[{key_types}, {value_types}, {keep}], i: i64, e: {{{key_types}, {value_types}}}| \n                    merge(b, e)\n            )\n        )\n    ),\n    |e: {{{key_types}, {value_types}}}| \n        {res}\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(arrays=obj_id,\n                                              all_types=all_types,\n                                              key_types=key_types,\n                                              value_types=value_types,\n                                              key_merges=key_merges,\n                                              value_merges=value_merges,\n                                              keep=keep,\n                                              res=res)\n\n    weld_struct_of_vec = weld_vec_of_struct_to_struct_of_vec(weld_obj, weld_types)\n\n    intermediate_result = LazyStructOfVecResult(weld_struct_of_vec, weld_types)\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, 'drop_dupl')\n\n    weld_objects = extract_placeholder_weld_objects(dependency_name, len(arrays), 'drop_dupl')\n\n    return weld_objects", "response": "Returns the unique elements of the input arrays."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace this value with to value.", "response": "def weld_replace(array, weld_type, this, to):\n    \"\"\"Replaces 'this' values to 'to' value.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of the data in the array.\n    this : {int, float, str, bool, bytes}\n        Scalar to replace.\n    to : {int, float, str, bool, bytes}\n        Scalar to replace with.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    if not isinstance(this, str):\n        this = to_weld_literal(this, weld_type)\n    to = to_weld_literal(to, weld_type)\n\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"map({array},\n    |e: {type}|\n        if(e == {this},\n            {to},\n            e\n        )    \n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              this=this,\n                                              to=to)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates WeldObject to encode Weld_template code given mapping.", "response": "def weld_udf(weld_template, mapping):\n    \"\"\"Create WeldObject to encode weld_template code given mapping.\n\n    Parameters\n    ----------\n    weld_template : str\n        Weld code to encode.\n    mapping : dict\n        Which substitutions to make in the weld_template.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    weld_obj = create_empty_weld_object()\n\n    for k, v in mapping.items():\n        if isinstance(v, (np.ndarray, WeldObject)):\n            obj_id = get_weld_obj_id(weld_obj, v)\n            mapping.update({k: obj_id})\n\n    weld_obj.weld_code = weld_template.format(**mapping)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef option_parser():\n    usage = '''\n             $ ./crawler -d5 <url>\n                Here in this case it goes till depth of 5 and url is target URL to\n                start crawling.\n            '''\n    version = \"2.0.0\"\n\n    parser = optparse.OptionParser(usage=usage, version=version)\n\n    parser.add_option(\"-l\", \"--links\", action=\"store_true\",\n                      default=False, dest=\"links\", help=\"links for target url\")\n\n    parser.add_option(\"-d\", \"--depth\", action=\"store\", type=\"int\",\n                      default=30, dest=\"depth\", help=\"Maximum depth traverse\")\n    opts, args = parser.parse_args()\n\n    if len(args) < 1:\n        parser.print_help()\n        raise SystemExit(1)\n\n    return opts, args", "response": "Option Parser to give various options."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets Links from the Linkfetcher class.", "response": "async def getlinks(url):\n    \"\"\"Get Links from the Linkfetcher class.\"\"\"\n    page = Linkfetcher(url)\n    await page.linkfetch()\n    for i, url in enumerate(page):\n        return (i, url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_mapping():\n    global _STATIC_MAPPING\n\n    if _STATIC_MAPPING is None:\n        manifest_path = getattr(settings,\n            'DJANGO_GULP_REV_PATH',\n            os.path.join(getattr(settings, 'STATIC_ROOT', ''), 'rev-manifest.json'))\n        \n        try:\n            with open(manifest_path) as manifest_file:\n                _STATIC_MAPPING = json.load(manifest_file)\n        except IOError:\n            return None\n\n    return _STATIC_MAPPING", "response": "Returns the static mapping for the current language of the current language of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef production_url(path, original):\n    mapping = _get_mapping()\n    if mapping:\n        if path in mapping:\n            return original.replace(path, mapping[path])\n        return original\n    else:\n        return dev_url(original)", "response": "Returns a production URL for a given path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef static_rev(path):\n    static_path = StaticNode.handle_simple(path)\n\n    if is_debug():\n        return dev_url(static_path)\n\n    return production_url(path, static_path)", "response": "Gets a joined path with the STATIC_URL setting and applies revisioning\n    depending on DEBUG setting."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the object table for each RDDL type.", "response": "def _build_object_table(self):\n        '''Builds the object table for each RDDL type.'''\n        types = self.domain.types\n        objects = dict(self.non_fluents.objects)\n        self.object_table = dict()\n        for name, value in self.domain.types:\n            if value == 'object':\n                objs = objects[name]\n                idx = { obj: i for i, obj in enumerate(objs) }\n                self.object_table[name] = {\n                    'size': len(objs),\n                    'idx': idx,\n                    'objects': objs\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_fluent_table(self):\n        '''Builds the fluent table for each RDDL pvariable.'''\n        self.fluent_table = collections.OrderedDict()\n\n        for name, size in zip(self.domain.non_fluent_ordering, self.non_fluent_size):\n            non_fluent = self.domain.non_fluents[name]\n            self.fluent_table[name] = (non_fluent, size)\n\n        for name, size in zip(self.domain.state_fluent_ordering, self.state_size):\n            fluent = self.domain.state_fluents[name]\n            self.fluent_table[name] = (fluent, size)\n\n        for name, size in zip(self.domain.action_fluent_ordering, self.action_size):\n            fluent = self.domain.action_fluents[name]\n            self.fluent_table[name] = (fluent, size)\n\n        for name, size in zip(self.domain.interm_fluent_ordering, self.interm_size):\n            fluent = self.domain.intermediate_fluents[name]\n            self.fluent_table[name] = (fluent, size)", "response": "Builds the fluent table for each RDDL pvariable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef non_fluent_variables(self) -> FluentParamsList:\n        '''Returns the instantiated non-fluents in canonical order.\n\n        Returns:\n            Sequence[Tuple[str, List[str]]]: A tuple of pairs of fluent name\n            and a list of instantiated fluents represented as strings.\n        '''\n        fluents = self.domain.non_fluents\n        ordering = self.domain.non_fluent_ordering\n        return self._fluent_params(fluents, ordering)", "response": "Returns the instantiated non - fluents in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state_fluent_variables(self) -> FluentParamsList:\n        '''Returns the instantiated state fluents in canonical order.\n\n        Returns:\n            Sequence[Tuple[str, List[str]]]: A tuple of pairs of fluent name\n            and a list of instantiated fluents represented as strings.\n        '''\n        fluents = self.domain.state_fluents\n        ordering = self.domain.state_fluent_ordering\n        return self._fluent_params(fluents, ordering)", "response": "Returns the instantiated state fluents in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the instantiated intermediate fluents in canonical order.", "response": "def interm_fluent_variables(self) -> FluentParamsList:\n        '''Returns the instantiated intermediate fluents in canonical order.\n\n        Returns:\n            Sequence[Tuple[str, List[str]]]: A tuple of pairs of fluent name\n            and a list of instantiated fluents represented as strings.\n        '''\n        fluents = self.domain.intermediate_fluents\n        ordering = self.domain.interm_fluent_ordering\n        return self._fluent_params(fluents, ordering)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef action_fluent_variables(self) -> FluentParamsList:\n        '''Returns the instantiated action fluents in canonical order.\n\n        Returns:\n            Sequence[Tuple[str, List[str]]]: A tuple of pairs of fluent name\n            and a list of instantiated fluents represented as strings.\n        '''\n        fluents = self.domain.action_fluents\n        ordering = self.domain.action_fluent_ordering\n        return self._fluent_params(fluents, ordering)", "response": "Returns the instantiated action fluents in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef non_fluent_size(self) -> Sequence[Sequence[int]]:\n        '''The size of each non-fluent in canonical order.\n\n        Returns:\n            Sequence[Sequence[int]]: A tuple of tuple of integers\n            representing the shape and size of each non-fluent.\n        '''\n        fluents = self.domain.non_fluents\n        ordering = self.domain.non_fluent_ordering\n        return self._fluent_size(fluents, ordering)", "response": "The size of each non - fluent in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef action_size(self) -> Sequence[Sequence[int]]:\n        '''The size of each action fluent in canonical order.\n\n        Returns:\n            Sequence[Sequence[int]]: A tuple of tuple of integers\n            representing the shape and size of each fluent.\n        '''\n        fluents = self.domain.action_fluents\n        ordering = self.domain.action_fluent_ordering\n        return self._fluent_size(fluents, ordering)", "response": "The size of each action fluent in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef state_range_type(self) -> Sequence[str]:\n        '''The range type of each state fluent in canonical order.\n\n        Returns:\n            Sequence[str]: A tuple of range types representing\n            the range of each fluent.\n        '''\n        fluents = self.domain.state_fluents\n        ordering = self.domain.state_fluent_ordering\n        return self._fluent_range_type(fluents, ordering)", "response": "Returns the canonical range type of each state fluent in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef action_range_type(self) -> Sequence[str]:\n        '''The range type of each action fluent in canonical order.\n\n        Returns:\n            Sequence[str]: A tuple of range types representing\n            the range of each fluent.\n        '''\n        fluents = self.domain.action_fluents\n        ordering = self.domain.action_fluent_ordering\n        return self._fluent_range_type(fluents, ordering)", "response": "Returns the canonical order of the action fluents in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the canonical range type of each intermediate fluent in canonical order.", "response": "def interm_range_type(self) -> Sequence[str]:\n        '''The range type of each intermediate fluent in canonical order.\n\n        Returns:\n            Sequence[str]: A tuple of range types representing\n            the range of each fluent.\n        '''\n        fluents = self.domain.intermediate_fluents\n        ordering = self.domain.interm_fluent_ordering\n        return self._fluent_range_type(fluents, ordering)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the range types of fluents following the given ordering.", "response": "def _fluent_range_type(cls, fluents, ordering) -> Sequence[str]:\n        '''Returns the range types of `fluents` following the given `ordering`.\n\n        Returns:\n            Sequence[str]: A tuple of range types representing\n            the range of each fluent.\n        '''\n        range_types = []\n        for name in ordering:\n            fluent = fluents[name]\n            range_type = fluent.range\n            range_types.append(range_type)\n        return tuple(range_types)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the instantiated fluents for the given ordering.", "response": "def _fluent_params(self, fluents, ordering) -> FluentParamsList:\n        '''Returns the instantiated `fluents` for the given `ordering`.\n\n        For each fluent in `fluents`, it instantiates each parameter\n        type w.r.t. the contents of the object table.\n\n        Returns:\n            Sequence[Tuple[str, List[str]]]: A tuple of pairs of fluent name\n            and a list of instantiated fluents represented as strings.\n        '''\n        variables = []\n        for fluent_id in ordering:\n            fluent = fluents[fluent_id]\n            param_types = fluent.param_types\n            objects = ()\n            names = []\n            if param_types is None:\n                names = [fluent.name]\n            else:\n                objects = tuple(self.object_table[ptype]['objects'] for ptype in param_types)\n                for values in itertools.product(*objects):\n                    values = ','.join(values)\n                    var_name = '{}({})'.format(fluent.name, values)\n                    names.append(var_name)\n            variables.append((fluent_id, names))\n        return tuple(variables)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the sizes of fluents following the given ordering.", "response": "def _fluent_size(self, fluents, ordering) -> Sequence[Sequence[int]]:\n        '''Returns the sizes of `fluents` following the given `ordering`.\n\n        Returns:\n            Sequence[Sequence[int]]: A tuple of tuple of integers\n            representing the shape and size of each fluent.\n        '''\n        shapes = []\n        for name in ordering:\n            fluent = fluents[name]\n            shape = self._param_types_to_shape(fluent.param_types)\n            shapes.append(shape)\n        return tuple(shapes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _param_types_to_shape(self, param_types: Optional[str]) -> Sequence[int]:\n        '''Returns the fluent shape given its `param_types`.'''\n        param_types = [] if param_types is None else param_types\n        shape = tuple(self.object_table[ptype]['size'] for ptype in param_types)\n        return shape", "response": "Returns the fluent shape given its param_types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(self, c):\n        conj = self.conjugate.main(c)\n        mult = self.complex_mult.main(c, conj)\n        angle = self.angle.main(mult)\n\n        self.y = self.GAIN_SFIX * angle\n        return self.y", "response": "Main method for the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind a Pointcut ctx which is a class or instance related to input function or method.", "response": "def find_ctx(elt):\n    \"\"\"Find a Pointcut ctx which is a class/instance related to input\n    function/method.\n\n    :param elt: elt from where find a ctx.\n    :return: elt ctx. None if no ctx available or if elt is a None method.\n    \"\"\"\n\n    result = None\n\n    if ismethod(elt):\n\n        result = elt.__self__\n\n        if result is None and PY2:\n            result = elt.im_class\n\n    elif isclass(elt):\n        result = elt\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets base ctx. :param ctx: initial ctx. :return: base ctx.", "response": "def base_ctx(ctx):\n    \"\"\"Get base ctx.\n\n    :param ctx: initial ctx.\n    :return: base ctx.\"\"\"\n\n    result = None\n\n    if isclass(ctx):\n        result = getattr(ctx, '__base__', None)\n        if result is None:\n            mro = getmro(ctx)\n            if len(mro) > 1:\n                result = mro[1]\n    else:\n        result = ctx.__class__\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef super_method(name, ctx):\n\n    result = None, None\n\n    # get class ctx\n    if isclass(ctx):\n        _ctx = ctx\n        first_mro = 1\n    else:\n        _ctx = ctx.__class__\n        first_mro = 0\n    # get class hierachy\n    mro = getmro(_ctx)\n    for cls in mro[first_mro:]:\n        if hasattr(cls, name):\n            result = getattr(cls, name), cls\n            break\n\n    return result", "response": "Get super ctx method and super ctx where name matches with input name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies interception on target and return the final target.", "response": "def _apply_interception(\n        target, interception_fn, ctx=None, _globals=None\n):\n    \"\"\"Apply interception on input target and return the final target.\n\n    :param Callable target: target on applying the interception_fn.\n    :param function interception_fn: interception function to apply on\n        target\n    :param ctx: target ctx (instance or class) if not None.\n\n    :return: both interception and intercepted\n        - if target is a builtin function,\n            the result is a (wrapper function, builtin).\n        - if target is a function, interception is target where\n            code is intercepted code, and interception is a new function where\n            code is target code.\n    :rtype: tuple(callable, function, ctx)\n    :raises: TypeError if target is not a routine.\n    \"\"\"\n\n    if not callable(target):\n        raise TypeError('target {0} is not callable.'.format(target))\n\n    intercepted = target\n    interception = interception_fn\n\n    # try to get the right ctx\n    if ctx is None:\n        ctx = find_ctx(elt=target)\n\n    # if target is a builtin\n    if isbuiltin(target) or getmodule(target) is builtins:\n        # update builtin function reference in module with wrapper\n        module = getmodule(target)\n        found = False  # check for found function\n\n        if module is not None:\n            # update all references by value\n            for name, _ in getmembers(\n                    module, lambda member: member is target):\n                setattr(module, name, interception_fn)\n                found = True\n\n            if not found:  # raise Exception if not found\n                raise JoinpointError(\n                    \"Impossible to weave on not modifiable function {0}. \\\n                    Must be contained in module {1}\".format(target, module)\n                )\n\n    elif ctx is None:\n        # update code with interception code\n        target_fn = _get_function(target)\n        # switch interception and intercepted\n        interception, intercepted = target, interception_fn\n        # switch of code between target_fn and\n        # interception_fn\n        target_fn.__code__, interception_fn.__code__ = \\\n            interception_fn.__code__, target_fn.__code__\n\n    else:\n        # get target name\n        if isclass(target):  # if target is a class, get constructor name\n            target_name = _get_function(target).__name__\n        else:  # else get target name\n            target_name = target.__name__\n        # get the right intercepted\n        intercepted = getattr(ctx, target_name)\n        # in case of method\n        if ismethod(intercepted):  # in creating eventually a new method\n            args = [interception, ctx]\n            if PY2:  # if py2, specify the ctx class\n                # and unbound method type\n                if intercepted.__self__ is None:\n                    args = [interception, None, ctx]\n                else:\n                    args.append(ctx.__class__)\n            # instantiate a new method\n            interception = MethodType(*args)\n        # get the right intercepted function\n        if is_intercepted(intercepted):\n            intercepted, _ = get_intercepted(intercepted)\n        else:\n            intercepted = _get_function(intercepted)\n        # set in ctx the new method\n        setattr(ctx, target_name, interception)\n\n    # add intercepted into interception_fn globals and attributes\n    interception_fn = _get_function(interception)\n    # set intercepted\n    setattr(interception_fn, _INTERCEPTED, intercepted)\n    # set intercepted ctx\n    if ctx is not None:\n        setattr(interception_fn, _INTERCEPTED_CTX, ctx)\n\n    interception_fn.__globals__[_INTERCEPTED] = intercepted\n    interception_fn.__globals__[_INTERCEPTION] = interception\n\n    if _globals is not None:\n        interception_fn.__globals__.update(_globals)\n\n    return interception, intercepted, ctx"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _unapply_interception(target, ctx=None):\n\n    # try to get the right ctx\n    if ctx is None:\n        ctx = find_ctx(elt=target)\n\n    # get previous target\n    intercepted, old_ctx = get_intercepted(target)\n\n    # if ctx is None and old_ctx is not None, update ctx with old_ctx\n    if ctx is None and old_ctx is not None:\n        ctx = old_ctx\n\n    if intercepted is None:\n        raise JoinpointError('{0} must be intercepted'.format(target))\n\n    # flag to deleting of joinpoint_function\n    del_joinpoint_function = False\n\n    # if old target is a not modifiable resource\n    if isbuiltin(intercepted):\n        module = getmodule(intercepted)\n        found = False\n\n        # update references to target to not modifiable element in module\n        for name, member in getmembers(module):\n            if member is target:\n                setattr(module, name, intercepted)\n                found = True\n\n        # if no reference found, raise an Exception\n        if not found:\n            raise JoinpointError(\n                \"Impossible to unapply interception on not modifiable element \\\n                {0}. Must be contained in module {1}\".format(target, module)\n            )\n\n    elif ctx is None:\n        # get joinpoint function\n        joinpoint_function = _get_function(target)\n        # update old code on target\n        joinpoint_function.__code__ = intercepted.__code__\n        # ensure to delete joinpoint_function\n        del_joinpoint_function = True\n\n    else:\n        # flag for joinpoint recovering\n        recover = False\n        # get interception name in order to update/delete interception from ctx\n        intercepted_name = intercepted.__name__\n        # should we change of target or is it inherited ?\n        if isclass(ctx):\n            base_interception, _ = super_method(name=intercepted_name, ctx=ctx)\n        else:\n            base_interception = getattr(ctx.__class__, intercepted_name, None)\n        # if base interception does not exist\n        if base_interception is None:  # recover intercepted\n            recover = True\n\n        else:\n            # get joinpoint_function\n            joinpoint_function = _get_function(target)\n            # get base function\n            if is_intercepted(base_interception):\n                base_intercepted, _ = get_intercepted(base_interception)\n            else:\n                base_intercepted = _get_function(base_interception)\n            # is interception inherited ?\n            if base_intercepted is joinpoint_function:\n                pass  # do nothing\n            # is intercepted inherited\n            elif base_intercepted is intercepted:\n                # del interception\n                delattr(ctx, intercepted_name)\n                del_joinpoint_function = True\n            else:  # base function is something else\n                recover = True\n\n        if recover:  # if recover is required\n            # new content to put in ctx\n            new_content = intercepted\n            if ismethod(target):  # in creating eventually a new method\n                args = [new_content, ctx]\n                if PY2:  # if py2, specify the ctx class\n                    # and unbound method type\n                    if target.__self__ is None:\n                        args = [new_content, None, ctx]\n                    else:  # or instance method\n                        args.append(ctx.__class__)\n                # instantiate a new method\n                new_content = MethodType(*args)\n            # update ctx with intercepted\n            setattr(ctx, intercepted_name, new_content)\n            joinpoint_function = _get_function(target)\n            del_joinpoint_function = True\n\n    if del_joinpoint_function:\n        # delete _INTERCEPTED and _INTERCEPTED_CTX from joinpoint_function\n        if hasattr(joinpoint_function, _INTERCEPTED):\n            delattr(joinpoint_function, _INTERCEPTED)\n            if hasattr(joinpoint_function, _INTERCEPTED_CTX):\n                delattr(joinpoint_function, _INTERCEPTED_CTX)\n        del joinpoint_function", "response": "Unapply interception on target in cleaning it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_intercepted(target):\n\n    result = False\n\n    # get interception function from input target\n    function = _get_function(target)\n\n    result = hasattr(function, _INTERCEPTED)\n\n    return result", "response": "Check if target is intercepted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_intercepted(target):\n\n    function = _get_function(target)\n\n    intercepted = getattr(function, _INTERCEPTED, None)\n    ctx = getattr(function, _INTERCEPTED_CTX, None)\n\n    return intercepted, ctx", "response": "Get intercepted function and ctx from input target."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_function(target):\n\n    result = None\n\n    # raise TypeError if target is not callable\n    if not callable(target):\n        raise TypeError('target {0} must be callable'.format(target))\n\n    # in case of class, final target is its constructor\n    if isclass(target):\n        constructor = getattr(\n            target, '__init__',  # try to find __init__\n            getattr(target, '__new__', None)\n        )  # try to find __new__ | target\n        # if no constructor exists\n        if constructor is None:\n            # create one\n            def __init__(self):\n                pass\n            if PY2:\n                target.__init__ = MethodType(__init__, None, target)\n            else:\n                target.__init__ = __init__\n            constructor = target.__init__\n        # if constructor is a method, return function method\n        if ismethod(constructor):\n            result = constructor.__func__\n        # else return constructor\n        else:\n            result = constructor\n\n    elif ismethod(target):  # if target is a method, return function method\n        result = target.__func__\n\n    # return target if target is function or builtin\n    elif isfunction(target) or isbuiltin(target) or isroutine(target):\n        result = target\n\n    else:  # otherwise, return __call__ method\n        __call__ = getattr(target, '__call__')\n\n        if ismethod(__call__):  # if __call__ is a method, return its function\n            result = __call__.__func__\n        else:  # otherwise return __call__\n            result = __call__\n\n    return result", "response": "Get target function.\n\n    :param callable target: target from where get function.\n\n    :return: depending on target type::\n\n        - class: constructor.\n        - method: method function.\n        - function: function.\n        - else: __call__ method.\n\n    :raises: TypeError if target is not callable or is a class without a\n        constructor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_target(self, target, ctx=None):\n\n        if target is not None:\n            # check if target is already intercepted\n            if is_intercepted(target):\n                # set self interception last target reference\n                self._interception = target\n                # and targets, ctx\n                self.target, self.ctx = get_intercepted(target)\n            else:\n                # if not, update target reference with new interception\n                self.apply_pointcut(target, ctx=ctx)", "response": "Set target to use."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the joinpoint in initializing target its arguments and advices.", "response": "def start(\n            self, target=None, args=None, kwargs=None, advices=None,\n            exec_ctx=None, ctx=None\n    ):\n        \"\"\" Start to proceed this Joinpoint in initializing target, its\n        arguments and advices. Call self.proceed at the end.\n\n        :param callable target: new target to use in proceeding. self.target by\n            default.\n        :param tuple args: new target args to use in proceeding. self.args by\n            default.\n        :param dict kwargs: new target kwargs to use in proceeding. self.kwargs\n            by default.\n        :param list advices: advices to use in proceeding. self advices by\n            default.\n        :param dict exec_ctx: execution context.\n        :param target_ctx: target ctx to use in proceeding.\n        :return: self.proceed()\n        \"\"\"\n\n        # init target and _interception if not None as set_target method do\n        if target is not None:\n            self.set_target(target=target, ctx=ctx)\n\n        # init args if not None\n        if args is not None:\n            self.args = args\n\n        # init kwargs if not None\n        if kwargs is not None:\n            self.kwargs = kwargs\n\n        # get advices to process\n        if advices is None:\n            if self._advices is not None:\n                advices = self._advices\n            else:\n                advices = self.get_advices(self._interception)\n\n        # initialize self._advices_iterator\n        self._advices_iterator = iter(advices)\n\n        # initialize execution context\n        self.exec_ctx = self._exec_ctx.copy()\n\n        if exec_ctx is not None:\n            self.exec_ctx.update(exec_ctx)\n\n        result = self.proceed()\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproceeding this Joinpoint in calling all advices with this joinpoint as the only one parameter and call at the end of the target.", "response": "def proceed(self):\n        \"\"\"Proceed this Joinpoint in calling all advices with this joinpoint\n        as the only one parameter, and call at the end the target.\n        \"\"\"\n\n        try:\n            # get next advice\n            advice = next(self._advices_iterator)\n\n        except StopIteration:  # if no advice can be applied\n            # call target\n            result = self.target(*self.args, **self.kwargs)\n\n        else:\n            # if has next, apply advice on self\n            result = advice(self)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply pointcut on input target and returns final interception.", "response": "def apply_pointcut(self, target, function=None, ctx=None):\n        \"\"\"Apply pointcut on input target and returns final interception.\n\n        The poincut respects all meta properties such as:\n        - function signature,\n        - module path,\n        - file path,\n        - __dict__ reference.\n        \"\"\"\n\n        try:\n            __file__ = getfile(target)\n        except TypeError:\n            __file__ = '<string>'\n\n        if function is None:\n            function = _get_function(target)\n\n        # flag which indicates that the function is not a pure python function\n        # and has to be wrapped\n        wrap_function = not hasattr(function, '__code__')\n\n        try:\n            # get params from target\n            args, varargs, kwargs, _ = getargspec(function)\n        except TypeError:\n            # in case of error, wrap the function\n            wrap_function = True\n\n        if wrap_function:\n            # if function is not pure python, create a generic one\n            # with assignments\n            assigned = []\n            for wrapper_assignment in WRAPPER_ASSIGNMENTS:\n                if hasattr(function, wrapper_assignment):\n                    assigned.append(wrapper_assignment)\n            # and updates\n            updated = []\n            for wrapper_update in WRAPPER_UPDATES:\n                if hasattr(function, wrapper_update):\n                    updated.append(wrapper_update)\n\n            @wraps(function, assigned=assigned, updated=updated)\n            def wrapper(*args, **kwargs):\n                \"\"\"Default wrapper.\"\"\"\n\n            function = wrapper\n\n            # get params from target wrapper\n            args, varargs, kwargs, _ = getargspec(function)\n\n        # get params from target\n        name = function.__name__\n\n        # if target has not name, use 'function'\n        if name == Joinpoint.__LAMBDA_NAME__:\n            name = Joinpoint.__INTERCEPTION__\n\n        # get join method for reducing concatenation time execution\n        join = \"\".join\n\n        # default indentation\n        indent = '    '\n\n        newcodestr = \"def {0}(\".format(name)\n        if args:\n            newcodestr = join((newcodestr, \"{0}\".format(args[0])))\n        for arg in args[1:]:\n            newcodestr = join((newcodestr, \", {0}\".format(arg)))\n\n        if varargs is not None:\n            if args:\n                newcodestr = join((newcodestr, \", \"))\n            newcodestr = join((newcodestr, \"*{0}\".format(varargs)))\n\n        if kwargs is not None:\n            if args or varargs is not None:\n                newcodestr = join((newcodestr, \", \"))\n            newcodestr = join((newcodestr, \"**{0}\".format(kwargs)))\n\n        newcodestr = join((newcodestr, \"):\\n\"))\n\n        # unique id which will be used for advicesexecutor and kwargs\n        generated_id = repr(time()).replace('.', '_')\n\n        # if kwargs is None\n        if kwargs is None and args:\n            kwargs = \"kwargs_{0}\".format(generated_id)  # generate a name\n            # initialize a new dict with args\n            newcodestr = join(\n                (newcodestr, \"{0}{1} = {{\\n\".format(indent, kwargs)))\n            for arg in args:\n                newcodestr = join(\n                    (newcodestr, \"{0}{0}'{1}': {1},\\n\".format(indent, arg))\n                )\n            newcodestr = join((newcodestr, \"{0}}}\\n\".format(indent)))\n\n        else:\n            # fill args in kwargs\n            for arg in args:\n                newcodestr = join(\n                    (newcodestr, \"{0}{1}['{2}'] = {2}\\n\".format(\n                        indent, kwargs, arg))\n                )\n\n        # advicesexecutor name\n        joinpoint = \"joinpoint_{0}\".format(generated_id)\n\n        if varargs:\n            newcodestr = join(\n                (newcodestr, \"{0}{1}.args = {2}\\n\".format(\n                    indent, joinpoint, varargs))\n            )\n\n        # set kwargs in advicesexecutor\n        if kwargs is not None:\n            newcodestr = join(\n                (newcodestr, \"{0}{1}.kwargs = {2}\\n\".format(\n                    indent, joinpoint, kwargs))\n            )\n\n        # return advicesexecutor proceed result\n        start = \"start_{0}\".format(generated_id)\n        newcodestr = join(\n            (newcodestr, \"{0}return {1}()\\n\".format(indent, start))\n        )\n        # compile newcodestr\n        code = compile(newcodestr, __file__, 'single')\n\n        _globals = {}\n\n        # define the code with the new function\n        exec(code, _globals)\n\n        # get new code\n        newco = _globals[name].__code__\n\n        # get new consts list\n        newconsts = list(newco.co_consts)\n\n        if PY3:\n            newcode = list(newco.co_code)\n        else:\n            newcode = map(ord, newco.co_code)\n\n        consts_values = {joinpoint: self, start: self.start}\n\n        # change LOAD_GLOBAL to LOAD_CONST\n        index = 0\n        newcodelen = len(newcode)\n        while index < newcodelen:\n            if newcode[index] == LOAD_GLOBAL:\n                oparg = newcode[index + 1] + (newcode[index + 2] << 8)\n                name = newco.co_names[oparg]\n                if name in consts_values:\n                    const_value = consts_values[name]\n                    if const_value in newconsts:\n                        pos = newconsts.index(const_value)\n                    else:\n                        pos = len(newconsts)\n                        newconsts.append(consts_values[name])\n                    newcode[index] = LOAD_CONST\n                    newcode[index + 1] = pos & 0xFF\n                    newcode[index + 2] = pos >> 8\n                    if name == start:\n                        break  # stop when start is encountered\n            index += 1\n\n        # get code string\n        codestr = bytes(newcode) if PY3 else join(map(chr, newcode))\n\n        # get vargs\n        vargs = [\n            newco.co_argcount, newco.co_nlocals, newco.co_stacksize,\n            newco.co_flags, codestr, tuple(newconsts), newco.co_names,\n            newco.co_varnames, newco.co_filename, newco.co_name,\n            newco.co_firstlineno, newco.co_lnotab,\n            getattr(function.__code__, 'co_freevars', ()),\n            newco.co_cellvars\n        ]\n        if PY3:\n            vargs.insert(1, newco.co_kwonlyargcount)\n\n        # instanciate a new code object\n        codeobj = type(newco)(*vargs)\n        # instanciate a new function\n        if function is None or isbuiltin(function):\n            interception_fn = FunctionType(codeobj, {})\n\n        else:\n            interception_fn = type(function)(\n                codeobj,\n                {} if function.__globals__ is None else function.__globals__,\n                function.__name__,\n                function.__defaults__,\n                function.__closure__\n            )\n\n        # set wrapping assignments\n        for wrapper_assignment in WRAPPER_ASSIGNMENTS:\n            try:\n                value = getattr(function, wrapper_assignment)\n            except AttributeError:\n                pass\n            else:\n                setattr(interception_fn, wrapper_assignment, value)\n        # update wrapping updating\n        for wrapper_update in WRAPPER_UPDATES:\n            try:\n                value = getattr(function, wrapper_update)\n            except AttributeError:\n                pass\n            else:\n                getattr(interception_fn, wrapper_update).update(value)\n\n        # set interception, target function and ctx\n        self._interception, self.target, self.ctx = _apply_interception(\n            target=target, interception_fn=interception_fn, ctx=ctx\n        )\n\n        return self._interception"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a String and return the data", "response": "def read(f):\n    \"\"\"\n    Parse a String and return the data\n\n    :param f: The file to read\n    :type f: file/str\n    :returns: A dictionary object containing the parsed data from f\n    :raises: SyntaxError - An error occured reading the data.\n    \"\"\"\n    try:\n      return PyVDF.reads(f.read())\n    except AttributeError:\n      pass\n\n    try:\n      with open(f, 'r') as filec:\n        data = PyVDF.reads(filec.read())\n        filec.close()\n        return data\n    except IOError as e:\n      print(\"Could not open '\" + f + \"' for reading.\")\n      print(\"Ignore this if you are creating a new file.\")\n\n    return PyVDF.__UseDict()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reads(s):\n    _dict = PyVDF.__UseDict\n    _len = len\n    _whitespace = frozenset('\\t ')\n    _newline = frozenset('\\n\\r')\n\n    _quote_match = PyVDF.__RE_Token_Quoted.match\n    _unquote_match = PyVDF.__RE_Token_UnQuoted.match\n    _max_length = PyVDF.__MaxTokenLength\n\n    ci = 0\n    line = 0\n    grabKey = 1\n\n    data = _dict()\n    tree = data\n\n    keys = deque()\n    keyApp = keys.append\n    keyPop = keys.pop\n\n    try:\n      while 1:\n\n        while s[ci] in _whitespace:\n          ci += 1\n\n        char = s[ci]\n\n        if char == '\"':\n          ci += 1\n          string = _quote_match(s[ci:ci + _max_length]).group()[:-1]\n          ci += _len(string)\n\n          if grabKey:\n            k = string\n            grabKey = 0\n          else:\n            tree[k] = string\n            grabKey = 1\n\n        elif char == '\\n':\n          line += 1\n\n        # elif char == '\\r':\n        #   if s[ci + 1] == '\\n':\n        #     ci += 1\n        #   line += 1\n\n        elif char == '{':\n          if grabKey:\n            raise Exception(PyVDF.__ERR_BlockNoKey.format(line, k))\n          else:\n            keyApp(k)\n            tree[k] = _dict()\n            tree = tree[k]\n            grabKey = 1\n\n        elif char == '}':\n          if grabKey:\n            keyPop()\n            tree = data\n            for key in keys:\n              tree = tree[key]\n          else:\n            raise Exception(PyVDF.__ERR_CompanionBrace.format(line, k))\n\n        elif char == '/' and s[ci + 1] == '/':\n          ci += 1\n          line += 1\n          while 1:\n            ci += 1\n            if s[ci] in _newline:\n              break\n\n        elif char == '[':\n          while 1:\n            ci += 1\n            if s[ci] == ']':\n              break\n\n        else:\n          string = _unquote_match(s[ci:ci + _max_length]).group()\n          ci += _len(string)\n\n          if grabKey:\n            k = string\n            grabKey = 0\n          else:\n            tree[k] = string\n            grabKey = 1\n          continue\n\n        ci += 1\n\n    except IndexError:\n      if _len(keys) == 0:\n        return data\n      raise Exception(PyVDF.__ERR_EODArray)\n    except AttributeError:\n      raise Exception(PyVDF.__ERR_BadToken.format(line, _max_length))", "response": "Parse a string and return the data in a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef formatData(data):\n    condensed = PyVDF.__CondensedOutput\n    indentation = PyVDF.__OutputIndentation\n    spacing = PyVDF.__OutputSpacing\n    def loop(array, tab=''):\n      string = ''\n      for k, v in array.items():\n        string += '{}\"{}\"'.format(tab,k)\n        if isinstance(v, dict):\n          string += '{}{{\\n{}{}}}\\n'.format(\n            '' if condensed else '\\n' + tab,\n            loop(v, tab + indentation),\n            tab)\n        else:\n            string += '{}\"{}\"\\n'.format(spacing, v)\n      return string\n    return loop(data)", "response": "Formats a dictionary object to look like a VDF file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a dictionary object to a file in the order they appear.", "response": "def writeData(f, data):\n    \"\"\"\n    Write a dictionary object to a file\n\n    :param f: The file to write to\n    :type f: file/string\n    :param data: The data to write to the file\n    :type data: dict\n    \"\"\"\n    if not isinstance(data, dict):\n      raise Exception(PyVDF.__ERR_NotDict.format(repr(data)))\n    data = PyVDF.formatData(data)\n    try:\n      f.write(data)\n    except AttributeError:\n      pass\n\n    try:\n      filec = open(f, 'w')\n      filec.write(data)\n      filec.close()\n    except IOError as e:\n      print(\"Could not open '\" + f + \"' for writing.\")\n      print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a value in the key - value list", "response": "def find(self, path):\n    \"\"\"\n    Find a value\n\n    :param path: The Key path to search for\n    :type path: :py:obj:`str`\n    :returns: The found value or an empty string if not found.\n    \"\"\"\n    p = [re.sub('[\\[\\]]', '', w) for w in PyVDF.__RE_Path_Seperator.findall(path)]\n    array = self.getData()\n    for c in p:\n      try:\n        array = array[c]\n      except KeyError:\n        return ''\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit(self, path, value):\n    _dict = PyVDF.__UseDict\n    p = [re.sub('[\\[\\]]', '', w) for w in PyVDF.__RE_Path_Seperator.findall(path)]\n    array = self.getData()\n    a = array\n    for c in p[:-1]:\n      try:\n        if not isinstance(a[c], dict):\n          a[c] = _dict()\n      except KeyError:\n        a[c] = _dict()\n      a = a[c]\n    if value == None:\n      a.pop(p[-1], None)\n    else:\n      a[p[-1]] = value\n    self.__data = array", "response": "Edit a key value in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the files in the specified project", "response": "def _runtime(self, project, base):\n        ''' first runtimes all project type files, like `project/type.vim`, then the specific project file, like\n        `project/type/name.vim`.\n        '''\n        def run(path_suf):\n            path = '{}/{}'.format(base, path_suf)\n            err = 'error sourcing {}.vim: {{}}'.format(path)\n            return (\n                self.vim.runtime(path)\n                .cata(L(err.format)(_) >> List, lambda a: List())\n            )\n        return (\n            project.all_types.flat_map(run) +\n            (project.tpe.map(_ + '/' + project.name).map(run) | List()) +\n            run('all/*')\n        ).map(Error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_line(what, indent='', cols=79):\n    if len(indent) > cols:\n        raise ValueError(\"The indent can't be longer than cols.\")\n\n    if cols < 2:\n        raise ValueError(\n            \"The cols can't be smaller than 2 (a char plus a possible '-')\"\n        )\n\n    what = indent + what.lstrip()\n\n    if len(what) <= cols:\n        what, new_line = '', what\n    else:\n        try:\n            closest_space = what[:cols].rindex(' ')\n        except ValueError:\n            closest_space = -1\n\n        if closest_space > len(indent):\n            what, new_line = (\n                what[closest_space:],\n                what[:closest_space],\n            )\n        elif what[cols] == ' ':\n            what, new_line = (\n                what[cols:],\n                what[:cols],\n            )\n        else:\n            what, new_line = what[cols - 1:], what[:cols - 1] + '-'\n\n    return what.lstrip(), new_line.rstrip()", "response": "Split a text into a single line of the n - word language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_to_cols(what, indent='', cols=79):\n    lines = []\n    while what:\n        what, next_line = split_line(\n            what=what,\n            cols=cols,\n            indent=indent,\n        )\n        lines.append(next_line)\n\n    return '\\n'.join(lines)", "response": "Wrap the given text to the columns prepending the indent to each line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compress(self, data_list):\n        if data_list:\n            # Calculate the hash of the supplied values\n            hashed = self.widget.hash_answer(answer=data_list[0], timestamp=data_list[1])\n            # Current time\n            timestamp = time.time()\n\n            if float(data_list[1]) < timestamp - DURATION:\n                raise ValidationError(\"Captcha expired, please try again\", code='invalid')\n            elif hashed != data_list[2]:\n                raise ValidationError(\"Incorrect answer\", code='invalid')\n\n            # Return the supplied answer\n            return data_list[0]\n        else:\n            return None", "response": "Validates the captcha answer and returns the result\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(self, options=None, **kwds):\n        option_string = self._build_option_string(options)\n        photos = self._client.get(\"/photos%s/list.json\" % option_string,\n                                  **kwds)[\"result\"]\n        photos = self._result_to_list(photos)\n        return [Photo(self._client, photo) for photo in photos]", "response": "The list API endpoint provides a list of photos."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsharing a user with a set of photos.", "response": "def share(self, options=None, **kwds):\n        \"\"\"\n        Endpoint: /photos[/<options>/share.json\n\n        Not currently implemented.\n        \"\"\"\n        option_string = self._build_option_string(options)\n        return self._client.post(\"/photos%s/share.json\" % option_string,\n                                 **kwds)[\"result\"]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, photos, **kwds):\n        ids = [self._extract_id(photo) for photo in photos]\n        return self._client.post(\"/photos/update.json\", ids=ids,\n                                 **kwds)[\"result\"]", "response": "This endpoint updates a list of photos with the specified parameters. Returns True if successful Raises TroveboxError if not successful"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the source files of a photo.", "response": "def delete_source(self, photo, **kwds):\n        \"\"\"\n        Endpoint: /photo/<id>/source/delete.json\n\n        Delete the source files of a photo.\n        Returns True if successful.\n        Raises a TroveboxError if not.\n        \"\"\"\n        return self._client.post(\"/photo/%s/source/delete.json\" %\n                                 self._extract_id(photo),\n                                 **kwds)[\"result\"]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_from_url(self, photo, url, **kwds):\n        result = self._client.post(\"/photo/%s/replace.json\" %\n                                   self._extract_id(photo),\n                                   photo=url,\n                                   **kwds)[\"result\"]\n        return Photo(self._client, result)", "response": "Replace a photo from a URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef view(self, photo, options=None, **kwds):\n        option_string = self._build_option_string(options)\n        result = self._client.get(\"/photo/%s%s/view.json\" %\n                                  (self._extract_id(photo), option_string),\n                                  **kwds)[\"result\"]\n        return Photo(self._client, result)", "response": "This method returns a Photo object with all properties of a photo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload a photo to the specified user s site.", "response": "def upload(self, photo_file, **kwds):\n        \"\"\"\n        Endpoint: /photo/upload.json\n\n        Uploads the specified photo filename.\n        \"\"\"\n        with open(photo_file, 'rb') as in_file:\n            result = self._client.post(\"/photo/upload.json\",\n                                       files={'photo': in_file},\n                                       **kwds)[\"result\"]\n        return Photo(self._client, result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_encoded(self, photo_file, **kwds):\n        with open(photo_file, \"rb\") as in_file:\n            encoded_photo = base64.b64encode(in_file.read())\n        result = self._client.post(\"/photo/upload.json\", photo=encoded_photo,\n                                   **kwds)[\"result\"]\n        return Photo(self._client, result)", "response": "Upload a photo encoded to the base64 - encoded base64 - encoded base64 - encoded photo."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports a photo from the specified URL", "response": "def upload_from_url(self, url, **kwds):\n        \"\"\"\n        Endpoint: /photo/upload.json\n\n        Import a photo from the specified URL\n        \"\"\"\n        result = self._client.post(\"/photo/upload.json\", photo=url,\n                                   **kwds)[\"result\"]\n        return Photo(self._client, result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_previous(self, photo, options=None, **kwds):\n        option_string = self._build_option_string(options)\n        result = self._client.get(\"/photo/%s/nextprevious%s.json\" %\n                                  (self._extract_id(photo), option_string),\n                                  **kwds)[\"result\"]\n        value = {}\n        if \"next\" in result:\n            # Workaround for APIv1\n            if not isinstance(result[\"next\"], list): # pragma: no cover\n                result[\"next\"] = [result[\"next\"]]\n\n            value[\"next\"] = []\n            for photo in result[\"next\"]:\n                value[\"next\"].append(Photo(self._client, photo))\n\n        if \"previous\" in result:\n            # Workaround for APIv1\n            if not isinstance(result[\"previous\"], list): # pragma: no cover\n                result[\"previous\"] = [result[\"previous\"]]\n\n            value[\"previous\"] = []\n            for photo in result[\"previous\"]:\n                value[\"previous\"].append(Photo(self._client, photo))\n\n        return value", "response": "Returns the next and previous photo lists\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new photo with the specified transformations.", "response": "def transform(self, photo, **kwds):\n        \"\"\"\n        Endpoint: /photo/<id>/transform.json\n\n        Performs the specified transformations.\n          eg. transform(photo, rotate=90)\n        Returns the transformed photo.\n        \"\"\"\n        result = self._client.post(\"/photo/%s/transform.json\" %\n                                   self._extract_id(photo),\n                                   **kwds)[\"result\"]\n\n        # APIv1 doesn't return the transformed photo (frontend issue #955)\n        if isinstance(result, bool): # pragma: no cover\n            result = self._client.get(\"/photo/%s/view.json\" %\n                                      self._extract_id(photo))[\"result\"]\n\n        return Photo(self._client, result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_query(key, person, event=None, timestamp=None,\n                 identity=None, properties=None):\n    \"\"\"Build and encode query string.\n\n    :param key: API key for product, found on the\n                \"KISSmetrics Settings\".\n    :param person: individual performing `event`\n    :param event: event name that was performed\n    :param timestamp: when `event` was performed; optional for\n                      back-dating\n    :param identity: individual to alias to `person`\n    :param properties: any additional data to include\n    :type properties: dict\n\n    :returns: URL encoded string representing query string\n    :rtype: str\n\n    .. note::\n\n        When a ``timestamp`` is provided, the ``TIME_FLAG_KEY`` will\n        be set to ``1`` and included.\n\n    \"\"\"\n    if properties is None:\n        properties = {}\n\n    query_dict = {KEY_KEY: key, PERSON_KEY: person}\n    if timestamp:\n        query_dict[TIME_FLAG_KEY] = 1\n        query_dict[TIME_KEY] = int(timestamp)\n    if event:\n        query_dict[EVENT_NAME_KEY] = event\n    if identity:\n        query_dict[ALIAS_KEY] = identity\n    query_dict.update(properties)\n    return urlencode(query_dict)", "response": "Builds and encode a query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(self, *args):\n        data = self.load()\n\n        if len(data)-1 != len(args):\n            raise ValueError(\"Wrong number of arguments passed to Cache.check\")\n\n        try:\n            for x, x_check in zip(data, args):\n                if isinstance(x, list):\n                    if len(x) != len(x_check):\n                        raise CacheException\n                    for x_i, x_check_i in zip(x, x_check):\n                        if x_i.shape != x_check_i.shape:\n                            raise CacheException\n                        elif not numpy.allclose(x_i, x_check_i,\n                                                equal_nan=True):\n                            raise CacheException\n                elif x.shape != x_check.shape:\n                    raise CacheException\n                elif not numpy.allclose(x, x_check, equal_nan=True):\n                    raise CacheException\n\n        except CacheException:\n            raise CacheChanged(self.file_root)\n\n        print(CacheOK(self.file_root))\n        return data[-1]", "response": "Check that the arguments have not changed since the last call."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload cache from file using pickle.", "response": "def load(self):\n        \"\"\" Load cache from file using pickle. \"\"\"\n        try:\n            with open(self.file_root + '.pkl', \"rb\") as f:\n                return pickle.load(f)\n        except IOError:\n            raise CacheMissing(self.file_root)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, *args):\n        with open(self.file_root + '.pkl', \"wb\") as f:\n            pickle.dump(args, f, protocol=pickle.HIGHEST_PROTOCOL)", "response": "Save the cache to file using pickle."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tree(self):\n        from cmdtree.tree import CmdTree\n        if self._tree is None:\n            self._tree = CmdTree()\n        return self._tree", "response": "returns a CmdTree object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_fields(self, json_dict):\n        for key, value in json_dict.items():\n            if not key.startswith(\"_\"):\n                setattr(self, key, value)", "response": "Set this object s attributes specified in json_dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing the fields of this object with the values in json_dict.", "response": "def _replace_fields(self, json_dict):\n        \"\"\"\n        Delete this object's attributes, and replace with\n        those in json_dict.\n        \"\"\"\n        for key in self._json_dict.keys():\n            if not key.startswith(\"_\"):\n                delattr(self, key)\n        self._json_dict = json_dict\n        self._set_fields(json_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _delete_fields(self):\n        for key in self._json_dict.keys():\n            if not key.startswith(\"_\"):\n                delattr(self, key)\n        self._json_dict = {}\n        self.id = None\n        self.name = None", "response": "Delete this object s attributes including name and id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(cls, subclass):\n        if not isinstance(cls, type):\n            raise TypeError(\"Can only register classes\")\n        if issubclass(subclass, cls):\n            return  # Already a subclass\n        # Subtle: test for cycles *after* testing for \"already a subclass\";\n        # this means we allow X.register(X) and interpret it as a no-op.\n        if issubclass(cls, subclass):\n            # This would create a cycle, which is bad for the algorithm below\n            raise RuntimeError(\"Refusing to create an inheritance cycle\")\n        cls._abc_registry.add(subclass)\n        ABCMeta._abc_invalidation_counter += 1", "response": "Register a virtual subclass of an ABC."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_state_from_api(self):\n        if self.last_api_call is not None:\n            difference = (datetime.datetime.now() - self.last_api_call).seconds\n        else:\n            # This is the first run, so we need to get the lastest state.\n            difference = 301\n        if difference >= 300:\n            url = BASE_URL + \"/rest/item\"\n            payload = {'usertoken': self.token}\n            arequest = requests.get(url, params=payload)\n            status = str(arequest.status_code)\n            if status == '401':\n                _LOGGER.info(\"Token expired? Trying to get a new one.\")\n                self.authenticate(True)\n                arequest = requests.get(url, params=payload)\n                status = arequest.status_code\n            elif status == '404':\n                _LOGGER.error(\"No devices associated with this account.\")\n            elif status != '200':\n                _LOGGER.error(\"API error not updating state. \" + status)\n            else:\n                self.state = arequest.json()\n            self.last_api_call = datetime.datetime.now()\n            _LOGGER.info(\"Pulled latest state from API.\")", "response": "Pull and update the state of the current state from the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nauthenticate with the API and return an authentication token.", "response": "def authenticate(self, reauth=False):\n        \"\"\"\n        Authenticate with the API and return an authentication token.\n        \"\"\"\n        auth_url = BASE_URL + \"/rest/user\"\n        payload = {'email': self.email, 'password': self.password}\n        arequest = requests.get(auth_url, params=payload)\n        status = arequest.status_code\n        if status != 200:\n            if reauth:\n                _LOGGER.error(\"Reauthentication request failed. \" + status)\n            else:\n                _LOGGER.error(\"Authentication request failed, please check credintials. \" + status)\n        self.token = arequest.json().get('usertoken')\n        if reauth:\n            _LOGGER.info(\"Reauthentication was successful, token updated.\")\n        else:\n            _LOGGER.info(\"Authentication was successful, token set.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_trackrs(self):\n        trackrs = []\n        for trackr in self.state:\n            trackrs.append(trackrDevice(trackr, self))\n        return trackrs", "response": "Returns a list of all Trackr objects from the trackrApiInterface state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the python version exists if!= 2. 7.", "response": "def check_python_version():\n    \"\"\"Checks the python version, exists if != 2.7.\"\"\"\n    python_major, python_minor = sys.version_info[:2]\n\n    if python_major != 2 or python_minor != 7:\n        sys.stderr.write(\"pyGenClean requires python 2.7\")\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_media(self,**kwargs):\n        return self.__search_base(apifn=self.__api.search_media, **kwargs)", "response": "Search IDigbio record format using Media Query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a new course.", "response": "def register_course (self, course_id):\n        \"\"\" \u5c65\u4fee\u7533\u8acb\u3059\u308b \"\"\"\n\n        # \u4f55\u30e2\u30b8\u30e5\u30fc\u30eb\u958b\u8b1b\u304b\u53d6\u5f97\n        kdb = twins.kdb.Kdb()\n        first_module = kdb.get_course_info(course_id)[\"modules\"][:2]\n        if not first_module.startswith(\"\u6625\") and \\\n           not first_module.startswith(\"\u79cb\"):\n            raise RequestError()\n        module_code, gakkiKbnCode = {\n                                      \"\u6625A\": (1, \"A\"),\n                                      \"\u6625B\": (2, \"A\"),\n                                      \"\u6625C\": (3, \"A\"),\n                                      \"\u79cbA\": (4, \"B\"),\n                                      \"\u79cbB\": (5, \"B\"),\n                                      \"\u79cbC\": (6, \"B\")\n                                    }.get(first_module)\n\n        self.req(\"RSW0001000-flow\")\n        self.get({\n                   \"_eventId\":   \"search\",\n                   \"moduleCode\": module_code,\n                   \"gakkiKbnCode\": gakkiKbnCode\n                })\n        self.post({\n                    \"_eventId\": \"input\",\n                    \"yobi\":     \"1\",\n                    \"jigen\":    \"1\"\n                 }, True)\n        r = self.post({\n                        \"_eventId\": \"insert\",\n                        \"nendo\": get_nendo(),\n                        \"jikanwariShozokuCode\": \"\",\n                        \"jikanwariCode\": course_id,\n                        \"dummy\": \"\"\n                     }, True)\n\n        errmsg = pq(r.text)(\".error\").text()\n        if errmsg != \"\":\n            raise RequestError()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_registered_credits (self):\n\n        self.req(\"RSW0001000-flow\")\n        r = self.get({\n                       \"_eventId\":     \"search\",\n                       \"moduleCode\":   1,\n                       \"gakkiKbnCode\": \"A\"\n                   })\n        html = r.text\n\n        # XXX\n        for l in html.split(\"\\n\"):\n            if \"\u5358\u4f4d</td>\" in l:\n                return float(l.strip().replace('<td align=\"center\">', \"\").\n                                       replace(\"\u5358\u4f4d</td>\", \"\"))\n\n        return 0.", "response": "Get the number of credits that are registered in the current page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of all courses that are registered.", "response": "def get_registered_courses (self):\n        \"\"\" \u5c65\u4fee\u767b\u9332\u6e08\u307f\u6388\u696d\u3092\u53d6\u5f97 \"\"\"\n        kdb = twins.kdb.Kdb()\n        _reged = []\n        for x in ((1, \"A\"), (2, \"A\"), (3, \"A\"), (4, \"B\"), (5, \"B\"), (6, \"B\")):\n            self.req(\"RSW0001000-flow\")\n            self.get({\n                       \"_eventId\":     \"search\",\n                       \"moduleCode\":   x[0],\n                       \"gakkiKbnCode\": x[1]\n                    })\n            self.post({\"_eventId\": \"output\"}, True)\n            r = self.post({\n                            \"_eventId\":         \"output\",\n                            \"outputType\":       \"csv\",\n                            \"fileEncoding\":     \"UTF8\",\n                            \"logicalDeleteFlg\": 0\n                          }, True)\n\n            _reged += list(csv.reader(r.text.strip().split(\"\\n\")))\n\n        if _reged == []:\n            return []\n\n        already_appeared = []\n        reged = []\n        for c in [kdb.get_course_info(c[0]) for c in _reged]:\n            # \u91cd\u8907\u3092\u9664\u53bb\n            if c is None or c[\"id\"] in already_appeared:\n                continue\n            reged.append(c)\n            already_appeared.append(c[\"id\"])\n        return reged"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of all aachievements.", "response": "def get_achievements_summary (self):\n        \"\"\" \u5c65\u4fee\u6210\u7e3e\u8981\u7d04\u306e\u53d6\u5f97 (\u7d2f\u8a08)\"\"\"\n        r = self.req(\"SIW0001200-flow\")\n\n        # XXX\n        ret = {}\n        k = \"\"\n        for d in pq(r.text)(\"td\"):\n            if d.text is None:\n                continue\n            if k != \"\":\n                # \u5168\u89d2\u82f1\u5b57\u30c0\u30e1\u30bc\u30c3\u30bf\u30a4\n                if k == \"\uff27\uff30\uff21\":\n                    k = \"GPA\"\n                ret[k] = d.text.strip()\n                k = \"\"\n                continue\n            k = d.text.strip()\n            if k == \"\u5c65\u4fee\u5358\u4f4d\u6570\" or k == \"\u4fee\u5f97\u5358\u4f4d\u6570\" or k == \"\uff27\uff30\uff21\":\n                continue\n            else:\n                k = \"\"\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        evaluated_data = [v.evaluate(verbose, decode, passes, num_threads, apply_experimental) for v in self.values]\n\n        return MultiIndex(evaluated_data, self.names)", "response": "Evaluates by creating a MultiIndex containing evaluated data and index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tail(self, n=5):\n        # not computing slice here to use with __getitem__ because we'd need to use len which is eager\n        return MultiIndex([v.tail(n) for v in self.values], self.names)", "response": "Return a new MultiIndex with the last n values in each column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new MultiIndex with no rows containing null values according to Baloo s convention.", "response": "def dropna(self):\n        \"\"\"Returns MultiIndex without any rows containing null values according to Baloo's convention.\n\n        Returns\n        -------\n        MultiIndex\n            MultiIndex with no null values.\n\n        \"\"\"\n        not_nas = [v.notna() for v in self.values]\n        and_filter = reduce(lambda x, y: x & y, not_nas)\n\n        return self[and_filter]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_pandas(cls, index):\n        from pandas import MultiIndex as PandasMultiIndex\n        check_type(index, PandasMultiIndex)\n\n        baloo_level_values = [Index.from_pandas(index.get_level_values(level))\n                              for level in range(len(index.levels))]\n\n        return MultiIndex(baloo_level_values, list(index.names))", "response": "Create baloo MultiIndex from pandas MultiIndex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_pandas(self):\n        if not all(ind.is_raw() for ind in self.values):\n            raise ValueError('Cannot convert to pandas MultiIndex if not evaluated.')\n\n        from pandas import MultiIndex as PandasMultiIndex\n\n        arrays = [ind.values for ind in self.values]\n\n        return PandasMultiIndex.from_arrays(arrays, names=self.names)", "response": "Convert to pandas MultiIndex.\n\n        Returns PandasMultiIndex.\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a population file and returns a dictionary containing the population of each sample.", "response": "def readPopulations(inputFileName, requiredPopulation):\n    \"\"\"Reads a population file.\n\n    :param inputFileName: the name of the population file.\n    :param requiredPopulation: the required population.\n\n    :type inputFileName: str\n    :type requiredPopulation: list\n\n    :returns: a :py:class:`dict` containing the population of each samples.\n\n    \"\"\"\n    populations = {}\n    requiredPopulation = set(requiredPopulation)\n    with open(inputFileName, \"r\") as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n            # Getting the informations\n            famID = row[0]\n            indID = row[1]\n            pop = row[2]\n\n            # Check if we already saw this sample\n            if (famID, indID) in populations:\n                if pop != populations[(famID, indID)]:\n                    msg = (\"{} {}: sample has multiple population ({} and \"\n                           \"{})\".format(famID, indID, pop,\n                                        populations[(famID, indID)]))\n                    raise ProgramError(msg)\n\n            # Save the population if we need it\n            if pop in requiredPopulation:\n                # We need this population\n                populations[(famID, indID)] = pop\n\n    popMissing = requiredPopulation - set(populations.values())\n    if len(popMissing) != 0:\n        msg = \"Population that were asked for doesn't exists in \" \\\n              \"population file: %s\" % str(popMissing)\n        raise ProgramError(msg)\n\n    return populations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plotMDS(data, theOrders, theLabels, theColors, theAlphas, theSizes,\n            theMarkers, options):\n    \"\"\"Plot the MDS data.\n\n    :param data: the data to plot (MDS values).\n    :param theOrders: the order of the populations to plot.\n    :param theLabels: the names of the populations to plot.\n    :param theColors: the colors of the populations to plot.\n    :param theAlphas: the alpha value for the populations to plot.\n    :param theSizes: the sizes of the markers for each population to plot.\n    :param theMarkers: the type of marker for each population to plot.\n    :param options: the options.\n\n    :type data: list of numpy.array\n    :type theOrders: list\n    :type theLabels: list\n    :type theColors: list\n    :type theAlphas: list\n    :type theSizes: list\n    :type theMarkers: list\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # Do the import\n    import matplotlib as mpl\n    if options.format != \"X11\" and mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    if options.format != \"X11\":\n        plt.ioff()\n\n    fig = plt.figure()\n    try:\n        fig.subplots_adjust(right=options.adjust_right,\n                            left=options.adjust_left,\n                            bottom=options.adjust_bottom,\n                            top=options.adjust_top)\n    except ValueError as e:\n        raise ProgramError(e)\n    ax = fig.add_subplot(111)\n\n    # Setting the axis\n    ax.xaxis.set_ticks_position(\"bottom\")\n    ax.yaxis.set_ticks_position(\"left\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"bottom\"].set_position((\"outward\", 9))\n    ax.spines[\"left\"].set_position((\"outward\", 9))\n\n    # The plot\n    plotObject = []\n    labels = []\n    for i, index in enumerate(theOrders):\n        try:\n            tmp, = ax.plot(data[0][i], data[1][i], theMarkers[i],\n                           color=theColors[i], mec=theColors[i],\n                           markersize=theSizes[i], alpha=theAlphas[i])\n        except ValueError as e:\n            msg = \"Problem with markers: %(e)s\" % locals()\n            raise ProgramError(msg)\n        plotObject.append(tmp)\n        labels.append(index)\n\n    # The legend\n    prop = mpl.font_manager.FontProperties(size=options.legend_size)\n    leg = ax.legend(plotObject, labels, loc=options.legend_position,\n                    numpoints=1, fancybox=True, prop=prop,\n                    ncol=options.legend_ncol)\n    leg.get_frame().set_alpha(0.5)\n\n    # The title and XY labels\n    ax.set_title(options.title, fontsize=options.title_fontsize, weight=\"bold\")\n    ax.set_xlabel(options.xlabel, fontsize=options.label_fontsize)\n    ax.set_ylabel(options.ylabel, fontsize=options.label_fontsize)\n\n    # Changing the size of the tick labels\n    for tick in ax.yaxis.get_major_ticks() + ax.xaxis.get_major_ticks():\n        tick.label.set_fontsize(options.axis_fontsize)\n\n    if options.format == \"X11\":\n        # Show the plot\n        plt.show()\n    else:\n        fileName = options.out + \".\" + options.format\n        try:\n            plt.savefig(fileName, dpi=300)\n        except IOError:\n            msg = \"%(fileName)s: can't write file\" % locals()\n            raise ProgramError(msg)\n        except ValueError as e:\n            colorError = False\n            for errorMsg in str(e).split(\"\\n\"):\n                if errorMsg.startswith(\"to_rgb\"):\n                    colorError = True\n            if colorError:\n                msg = \"problem with the population colors\"\n                raise ProgramError(msg)\n            else:\n                print str(e)", "response": "Plot the MDS data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkArgs(args):\n    # Check in input file\n    if not os.path.isfile(args.file):\n        msg = \"%s: no such file\" % args.file\n        raise ProgramError(msg)\n\n    # Check the population file\n    if args.population_file is None:\n        msg = \"population-file: no population file\"\n        raise ProgramError(msg)\n    elif not os.path.isfile(args.population_file):\n        msg = \"%s: no such file\" % args.population_file\n        raise ProgramError(msg)\n\n    # Split the order\n    args.population_order = args.population_order.split(\",\")\n    nbPop = len(args.population_order)\n\n    # Format the legend position\n    args.legend_position = args.legend_position.replace(\"-\", \" \")\n\n    # Format the color\n    colors = []\n    for color in args.population_colors.split(\",\"):\n        colors.append(\"#\" + color)\n    args.population_colors = colors\n    if len(args.population_colors) < nbPop:\n        msg = \"not enough colors for the required populations\"\n        raise ProgramError(msg)\n\n    # Format the point size\n    sizes = []\n    for size in args.population_sizes.split(\",\"):\n        try:\n            sizes.append(int(size))\n        except ValueError:\n            msg = \"%(size)s: not a valid size\" % locals()\n            raise ProgramError(msg)\n    args.population_sizes = sizes\n    if len(args.population_sizes) < nbPop:\n        msg = \"not enough sizes for the required populations\"\n        raise ProgramError(msg)\n\n    # Format the point marker\n    args.population_markers = args.population_markers.split(\",\")\n\n    # Format the alpha values\n    alphas = []\n    for alpha in args.population_alpha.split(\",\"):\n        try:\n            alphas.append(float(alpha))\n        except ValueError:\n            msg = \"%(alpha)s: not a valid alpha value\" % locals()\n            raise ProgramError(msg)\n    args.population_alpha = alphas\n\n    # Check the legend alpha value\n    if (args.legend_alpha < 0) or (args.legend_alpha > 1):\n        msg = \"%s: alpha for legend must be between \" \\\n              \"0 and 1\" % str(args.legend_alpha)\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options for validity."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parallel_apply(f, array, **kwargs):\n\n    precurry = tuple(kwargs.pop('precurry', ()))\n    postcurry = tuple(kwargs.pop('postcurry', ()))\n    parallel = kwargs.pop('parallel', False)\n    tqdm_kwargs = kwargs.pop('tqdm_kwargs', {})\n    if kwargs:\n        raise TypeError('Unexpected **kwargs: %r' % kwargs)\n    try:\n        # If running in a jupyter notebook then use tqdm_notebook.\n        progress = tqdm_notebook if get_ipython().has_trait('kernel') else tqdm\n    except (NameError, AssertionError):\n        # Otherwise use regular tqdm progress bar\n        progress = tqdm\n    if not parallel:\n        return [f(*(precurry + (x,) + postcurry)) for x in\n                progress(array, **tqdm_kwargs)]\n    elif parallel is True:\n        parallel = cpu_count()\n    elif isinstance(parallel, int):\n        if parallel < 0:\n            parallel = cpu_count()\n        else:\n            parallel = parallel\n    else:\n        raise ValueError(\"parallel keyword must be an integer or bool\")\n\n    if parallel and not PARALLEL:\n        warnings.warn(\"You need to install the package joblib\"\n                      \"if you want to use parallelisation\")\n\n    return Parallel(n_jobs=parallel)(delayed(f)(*(precurry + (x,) + postcurry))\n                                     for x in progress(array, **tqdm_kwargs))", "response": "Apply a function to an array with openmp parallelisation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling callback for all data forever ( until \\ C - c is reached", "response": "def spin(self, use_thread=False):\n        '''call callback for all data forever (until \\C-c)\n\n        :param use_thread: use thread for spin (do not block)\n        '''\n        if use_thread:\n            if self._thread is not None:\n                raise 'spin called twice'\n            self._thread = threading.Thread(target=self._spin_internal)\n            self._thread.setDaemon(True)\n            self._thread.start()\n        else:\n            self._spin_internal()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of all of the properties of the object.", "response": "def vars_(object=None):\n    \"\"\"\n    Clean all of the property starts with \"_\" then\n    return result of vars(object).\n    \"\"\"\n    filtered_vars = {}\n    vars_dict = vars(object)\n    for key, value in six.iteritems(vars_dict):\n        if key.startswith(\"_\"):\n            continue\n        filtered_vars[_normalize_arg_name(key)] = value\n    return filtered_vars"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_cmd(self, name, help=None, func=None):\n        if self.subparsers is None:\n            self.subparsers = self.add_subparsers(\n                title=\"sub-commands\",\n                help=help or 'sub-commands',\n            )\n\n        parser = self.subparsers.add_parser(\n            name,\n            help=help,\n        )\n        if func is not None:\n            parser.set_defaults(_func=func)\n        return parser", "response": "Adds a new command parser to the parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, **kwds):\n        result = self._client.photo.delete(self, **kwds)\n        self._delete_fields()\n        return result", "response": "Delete this photo. Returns True if successful Raises a TroveboxError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace(self, photo_file, **kwds):\n        result = self._client.photo.replace(self, photo_file, **kwds)\n        self._replace_fields(result.get_fields())", "response": "This method allows you to replace a photo in the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef view(self, options=None, **kwds):\n        result = self._client.photo.view(self, options, **kwds)\n        self._replace_fields(result.get_fields())", "response": "This method is used to view all properties of a specific photo."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef next_previous(self, options=None, **kwds):\n        return self._client.photo.next_previous(self, options, **kwds)", "response": "The next_previous method is used to retrieve the next and previous photo lists for this photo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, **kwds):\n        result = self._client.photo.transform(self, **kwds)\n        self._replace_fields(result.get_fields())", "response": "This method performs the specified transformations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _copy_body_to_tempfile(cls, environ):\n        try:\n            length = int(environ.get('CONTENT_LENGTH', 0))\n        except ValueError:\n            length = 0\n\n        try:\n            fileobj = tempfile.SpooledTemporaryFile(1024*1024)\n        except AttributeError:  # pragma: nocover\n            fileobj = tempfile.TemporaryFile()  # py25 fallback\n        if length:\n            remaining = length\n            while remaining > 0:\n                data = environ['wsgi.input'].read(min(remaining, 65536))\n                if not data:\n                    raise IOError(\n                        \"Client disconnected (%s more bytes were expected)\"\n                        % remaining\n                    )\n                fileobj.write(data)\n                remaining -= len(data)\n\n        fileobj.seek(0)\n        environ['wsgi.input'] = fileobj\n        return fileobj, length", "response": "Copy wsgi. input to a tempfile so it can be reused."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading ~. rightscalerc and returns API endpoint and refresh token.", "response": "def get_rc_creds():\n    \"\"\"\n    Reads ~/.rightscalerc and returns API endpoint and refresh token.\n\n    Always returns a tuple of strings even if the file is empty - in which\n    case, returns ``('', '')``.\n    \"\"\"\n    config = get_config()\n    try:\n        return (\n                config.get(CFG_SECTION_OAUTH, CFG_OPTION_ENDPOINT),\n                config.get(CFG_SECTION_OAUTH, CFG_OPTION_REF_TOKEN),\n                )\n    except:\n        return ('', '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_by_name(collection, name, exact=True):\n    params = {'filter[]': ['name==%s' % name]}\n    found = collection.index(params=params)\n    if not exact and len(found) > 0:\n        return found\n    for f in found:\n        if f.soul['name'] == name:\n            return f", "response": "Searches collection by name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kmer_lca_records(seqs_path,\n                     one_codex_api_key: 'One Codex API key' = None,\n                     fastq: 'input is fastq; disable autodetection' = False,\n                     progress: 'show progress bar (sent to stderr)' = False):\n    '''\n    Parallel lowest common ancestor sequence classification of fasta/q using the One Codex API.\n    Returns Biopython SeqRecords with tictax annotations as the `description` attribute.\n    LCAs are assigned using an LCA index of 31mers from the One Codex database.\n    '''\n    records = parse_seqs(seqs_path, fastq)\n    one_codex_api_key = one_codex_api_key if one_codex_api_key else config()['one_codex_api_key']\n    print('Classifying sequences\u2026', file=sys.stderr)\n    records = asyncio.get_event_loop().run_until_complete(oc_classify(records,\n                                                                      one_codex_api_key,\n                                                                      progress,\n                                                                      False))\n    return records", "response": "Parses a file and classifies the sequences using the One Codex API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef annotate_diamond(records, diamond_path):\n    '''\n    Retrieve scientific names and lineages for taxon IDs in Diamond output\n    Returns taxonomically annotated SeqRecords with modified description attributes\n    '''\n    contigs_metadata = {}\n    with open(diamond_path) as diamond_tax_fh:\n        for line in diamond_tax_fh:\n            contig, taxid, evalue = line.strip().split('\\t')\n            contigs_metadata[contig] = dict(taxid=int(taxid), evalue=float(evalue))\n\n    ncbi = ete3.NCBITaxa()\n    taxids = {m['taxid'] for m in contigs_metadata.values()} # set of taxids\n    taxids_lineages = ncbi.get_lineage_translator(taxids)  # dict of taxid lists\n    taxids_with_children = {x for v in taxids_lineages.values() for x in v}  # flatten to set\n    taxids_names = ncbi.get_taxid_translator(taxids_with_children)\n    taxids_ranks = ncbi.get_rank(taxids_with_children)\n\n    for contig, md in contigs_metadata.items():\n        md['sciname'] = taxids_names.get(md['taxid'])\n        md['rank'] = taxids_ranks.get(md['taxid'], '')\n        md['lineage_fmt'] = (':'.join([taxids_names.get(t, '')\n                                       for t in taxids_lineages.get(md['taxid'], [])])\n                                       if md['taxid'] else None)\n\n    for r in records:\n        md = contigs_metadata[r.id]\n        r.description = f\"{md['taxid']}|{md['rank']}|{md['sciname']}|{md['lineage_fmt']}\"\n    return records", "response": "Annotate SeqRecords with modified description attributes for taxon IDs in Diamond output\n    Returns taxonomically annotated SeqRecords with modified description attributes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering out SeqRecords that have a specific taxon ID in the tictax annotated FASTA file.", "response": "def filter_taxa(records, taxids, unclassified=False, discard=False):\n    '''\n    Selectively include or discard specified taxon IDs from tictax annotated FASTA/Qs\n    Filters all children of specified taxon IDs\n    Returns subset of input SeqRecords\n    Taxon IDs of 1 and 2 are considered unclassified \n    '''\n    taxids = set(taxids)\n    kept_records = []\n    ncbi = ete3.NCBITaxa()\n    unclassified_taxids = {0,1}\n    for r in records:\n        taxid, rank, sciname, lineage = r.description.strip().partition(' ')[2].split('|')\n        taxid = int(taxid)\n        lineage = set(ncbi.get_lineage(taxid) or [0])  # lineage defined twice?\n        intersection = lineage & taxids\n        if taxid in unclassified_taxids and unclassified:\n            kept_records.append(r)\n        elif intersection and not discard:\n            kept_records.append(r)\n        elif not intersection and discard and taxid not in unclassified_taxids:\n            kept_records.append(r)\n\n    return kept_records"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matrix(records, scafstats_path):\n    '''\n    Generate taxonomic count matrix from BBMap scafstats output to tictax classified contigs\n    '''\n    ncbi = ete3.NCBITaxa()\n    \n    # # Single file version \n    # contigs_lineages = {r.id: r.description.strip().partition(' ')[2].split('|')[2] for r in records}\n    # df = pd.read_csv(scafstats_path, sep='\\t').set_index('#name')\n    # contigs_counts = pd.Series(df.assignedReads.values, index=df.index).to_dict()\n    # lineages_counts = defaultdict(int)\n    \n    # for contig, lineage in contigs_lineages.items():\n    #     lineages_counts[lineage] += contigs_counts.get(contig, 0)\n\n    # lineages_counts_sorted = dict(reversed(sorted(lineages_counts.items(), key=lambda x: x[1])))\n    # print(pd.DataFrame(lineages_counts_sorted, index=[scafstats_path]).transpose().to_csv())\n\n    scafstats_paths = {fn.replace('.scafstats', ''): f'{scafstats_path}/{fn}'\n                       for fn in os.listdir(scafstats_path)\n                       if fn.endswith('.scafstats')}\n    contigs_lineages = {r.id: r.description.strip().partition(' ')[2].split('|')[3] for r in records}\n    samples = []\n    \n    for scafstat, path in scafstats_paths.items():\n        raw_df = pd.read_csv(path, sep='\\t').set_index('#name')\n        contigs_counts = pd.Series(raw_df.assignedReads.values, index=raw_df.index).to_dict()\n        lineages_counts = defaultdict(int)\n        for contig, lineage in contigs_lineages.items():\n            lineages_counts[lineage] += contigs_counts.get(contig, 0)\n        counts_df = pd.DataFrame(lineages_counts, index=[scafstat]).transpose()\n        samples.append(counts_df)\n\n    return pd.concat(samples, axis=1, sort=False).rename_axis('lineage')", "response": "Generate taxonomic count matrix from BBMap scafstats output to tictax classified contigs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do( self, params ):\n        N = self.repetitions()\n        e = self.experiment()\n        results = []\n        for i in range(N):\n            res = e.run()\n\n            # make sure we have a list to traverse\n            if not isinstance(res, list):\n                res = [ res ]\n\n            # add repetition metadata to each result\n            for r in res:\n                r[Experiment.METADATA][self.I] = i \n                r[Experiment.METADATA][self.REPETITIONS] = N\n\n            # add the results to ours\n            results.extend(res)\n        return results", "response": "This method performs the number of repetitions we want."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_slide(filename: Path, pptx_template: Path, master_slide_idx: int, slide_layout_idx: int, font_size: int,\n                dst_dir: Path, font_name: str, slide_txt_alignment: str = \"left\") -> Path:\n    \"\"\"Builds a powerpoint presentation using data read from a yaml file\n\n    :param filename: path to the yaml file \n    :param pptx_template: path to powerpoint template\n    :param master_slide_idx: slide master index\n    :param slide_layout_idx: slide layout index\n    :param font_size: size of the font\n    :param dst_dir: directory where the generated pptx should get dumped\n    :param font_name: name of the font\n    :param slide_txt_alignment: alignment of text in slides\n    :return path to the generated pptx\n    \"\"\"\n\n    prs = pptx.Presentation(pptx_template)\n\n    # setting text box size and position\n    slide_height = pptx.util.Length(prs.slide_height)\n    slide_width = pptx.util.Length(prs.slide_width)\n\n    # Emu is English metric unit\n    tb_pos = {\n        \"left\": pptx.util.Emu(400000),\n        \"top\": pptx.util.Emu(400000),\n        \"width\": pptx.util.Emu(slide_width - (400000 * 2)),\n        \"height\": pptx.util.Emu(slide_height - (400000 * 2))\n    }\n\n    slide_layout = prs.slide_masters[master_slide_idx].slide_layouts[slide_layout_idx]\n\n    with filename.open() as f:\n\n        yml_data = yaml.load(f)\n\n        lyrics = yml_data.get('lyrics')\n\n        hard_font_size = yml_data.get(\"font_size\")\n        if hard_font_size:\n            msg = f\"NOTE: Setting the font size to {hard_font_size} for {filename}\"\n            click.echo(click.style(msg, fg=\"blue\"))\n            font_size = hard_font_size\n\n        for content in lyrics:\n            slide = prs.slides.add_slide(slide_layout)\n\n            txbox = slide.shapes.add_textbox(**tb_pos)\n\n            tf = txbox.text_frame\n\n            # this is to keep text frame in the middle of the screen from top to bottom of the screen\n            tf.vertical_anchor = pptx.enum.text.MSO_ANCHOR.MIDDLE\n\n            # this is supposed to work as per the documentation but it's not working\n            # 09/12/2018\n            # tf.fit_text(font_family=font_name, max_size=font_size)\n\n            p = tf.add_paragraph()\n\n            if slide_txt_alignment == \"left\":\n                p.alignment = pptx.enum.text.PP_ALIGN.LEFT\n            elif slide_txt_alignment == \"middle\":\n                p.alignment = pptx.enum.text.PP_ALIGN.CENTER\n            else:\n                p.alignment = pptx.enum.text.PP_ALIGN.RIGHT\n\n            p.font.name = font_name\n            p.font.size = pptx.util.Pt(font_size)\n\n            p.text = content.get(\"english\")\n\n    dst_dir.mkdir(parents=True, exist_ok=True)\n    dst_file = filename.with_suffix(\".pptx\")\n    dst_path = Path(dst_dir, dst_file.name)\n\n    if dst_path.exists():\n        dst_path.unlink()\n\n    prs.save(str(dst_path))\n\n    return dst_path", "response": "Builds a powerpoint presentation from a file containing a single slide."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a path to a master slide. If argument is a directory returns a randomly chosen file in the directory and returns the argument itself. If argument is a file returns a randomly chosen file in the directory and returns the argument itself.", "response": "def pick_master_slide(master_slides_path: Path) -> Path:\n    \"\"\"Returns path to a master slide. If argument is a directory,\n    returns a randomly chosen file in the directory and if argument\n    is a file, returns the argument itself\n\n    :return: path to chosen master slide\n    \"\"\"\n\n    if master_slides_path.is_file():\n        return master_slides_path\n\n    master_slides = [\n        f.name for f in master_slides_path.iterdir()\n        if f.suffix == '.pptx'\n        if not f.name.startswith(\"archived\")\n    ]\n\n    if master_slides:\n        return Path(master_slides_path, random.choice(master_slides))\n\n    raise ValueError(f\"Unable to find any valid pptx template file in {master_slides_path}\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_yaml_file(schema: dict, yaml_file: Path):\n\n    with yaml_file.open() as f:\n        data = yaml.load(f)\n\n    jsonschema.validate(data, schema)", "response": "Validates the yaml file against the defined schema"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(yaml_paths, pptx_template_path, font_size, master_slide_idx, slide_layout_idx, dst_dir, font_name,\n        slide_txt_alignment, validate):\n    \"\"\"\n    A powerpoint builder\n\n    https://github.com/sukujgrg/pptx-builder-from-yaml\n\n    \"\"\"\n\n    dst_dir = Path(dst_dir)\n\n    pptx_template_path = Path(pptx_template_path)\n    pptx_template = pick_master_slide(pptx_template_path)\n\n    yamlfiles = []\n    for yaml_path in yaml_paths:\n        yaml_path = Path(yaml_path)\n        if yaml_path.is_dir():\n            yamlfiles.extend([yml for yml in yaml_path.iterdir()])\n        else:\n            yamlfiles.append(yaml_path)\n\n    if validate:\n        exit_fail = False\n        for yamlfile in yamlfiles:\n            try:\n                validate_yaml_file(SCHEMA_FOR_YAML, Path(yamlfile))\n                msg = f\"VALIDATE: Validation of {yamlfile} passed\"\n                click.echo(click.style(msg, fg=\"blue\"))\n            except jsonschema.exceptions.ValidationError as err:\n                msg = f\"ERR: {yamlfile} {str(err.message)} {err.path}\"\n                click.echo(click.style(msg, fg=\"red\"), nl=True)\n                exit_fail = True\n            except Exception:\n                raise\n        if exit_fail:\n            sys.exit(1)\n\n    for yamlfile in yamlfiles:\n        try:\n            r = build_slide(\n                    Path(yamlfile),\n                    pptx_template,\n                    master_slide_idx,\n                    slide_layout_idx,\n                    font_size,\n                    dst_dir,\n                    font_name,\n                    slide_txt_alignment\n                )\n            msg = f\"PPTX: {r}\"\n            click.echo(click.style(msg, fg=\"green\"))\n        except Exception:\n            raise", "response": "A helper function for building a powerpoint from a list of YAML files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exec_rule(self, rule):\n        print(\"running Rule: {0}\".format(rule.__name__))\n        ant = rule()\n        ant.start()", "response": ":rule : the Ant class of rule, which must have a start() function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addText(self, text):\n        # move to the end of the doc\n        self.moveCursor(QtGui.QTextCursor.End)\n        # insert the text\n        self.setTextColor(self._currentColor)\n        self.textCursor().insertText(text)", "response": "append text in the chosen color"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates context menu for the current locale", "response": "def contextMenuEvent(self, event):\n        \"\"\"\n        Add menu action:\n        * 'Show line numbers'\n        * 'Save to file'\n        \"\"\"\n        menu = QtWidgets.QTextEdit.createStandardContextMenu(self)\n\n        # create max.lines spin box:\n        w = QtWidgets.QWidget()\n        l = QtWidgets.QHBoxLayout()\n        w.setLayout(l)\n        e = QtWidgets.QSpinBox()\n        e.setRange(1, 1e6)\n        e.setValue(self.MAXLINES)\n        e.valueChanged.connect(self.document().setMaximumBlockCount)\n        l.addWidget(QtWidgets.QLabel('Max. lines'))\n        l.addWidget(e)\n\n        # add spinbox to menu:\n        a = QtWidgets.QWidgetAction(self)\n        a.setDefaultWidget(w)\n        menu.addAction(a)\n\n        menu.exec_(event.globalPos())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_form(model, only=None, meta=None):\n    fields = OrderedDict()\n    if meta:\n        fields['Meta'] = meta\n\n    for name, column in model.__dict__['columns'].items():\n        if only:\n            if not name in only:\n                continue\n        if not isinstance(column, Column):\n            continue\n        fields[name] = TYPE_MAP[column.type.__class__](\n            name, render_kw={'placeholder': name}\n        )\n    form = type(\n        'Add{}Form'.format(model.name.capitalize()),\n        (Form,),\n        fields\n    )\n    return form", "response": "Generate WTForm based on SQLAlchemy table\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the final TPED and TFAM files.", "response": "def createFinalTPEDandTFAM(tped, toReadPrefix, prefix, snpToRemove):\n    \"\"\"Creates the final TPED and TFAM.\n\n    :param tped: a representation of the ``tped`` of duplicated markers.\n    :param toReadPrefix: the prefix of the unique files.\n    :param prefix: the prefix of the output files.\n    :param snpToRemove: the markers to remove.\n\n    :type tped: numpy.array\n    :type toReadPrefix: str\n    :type prefix: str\n    :type snpToRemove: set\n\n    Starts by copying the unique markers' ``tfam`` file to\n    ``prefix.final.tfam``. Then, it copies the unique markers' ``tped`` file,\n    in which the chosen markers will be appended.\n\n    The final data set will include the unique markers, the chosen markers\n    which were completed, and the problematic duplicated markers (for further\n    analysis). The markers that were used to complete the chosen ones are not\n    present in the final data set.\n\n    \"\"\"\n    # First, copying the tfam\n    try:\n        shutil.copy(toReadPrefix + \".tfam\", prefix + \".final.tfam\")\n    except IOError:\n        msg = \"%(toReadPrefix)s.tfam: can't copy file to \" \\\n              \"%(prefix)s.final.tfam\" % locals()\n        raise ProgramError(msg)\n\n    # Next, copy the tped, and append at the end\n    try:\n        shutil.copy(toReadPrefix + \".tped\", prefix + \".final.tped\")\n    except IOError:\n        msg = \"%(toReadPrefix)s.tped: can't copy fil to \" \\\n              \"%(prefix)s.final.tped\" % locals()\n        raise ProgramError(msg)\n    tpedFile = None\n    try:\n        tpedFile = open(prefix + \".final.tped\", \"a\")\n    except IOError:\n        msg = \"%(prefix)s.final.tped: can't append to file\" % locals()\n        raise ProgramError(msg)\n    for i, row in enumerate(tped):\n        if i not in snpToRemove:\n            print >>tpedFile, \"\\t\".join(row)\n    tpedFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncomplete a TPED for duplicated SNPs. :param tped: a representation of the ``tped`` of duplicated markers. :param tfam: a representation of the ``tfam``. :param snps: the position of duplicated markers in the ``tped``. :param prefix: the prefix of the output files. :param chosenSNPs: the markers that were chosen for completion (including problems). :param completion: the completion of each of the duplicated markers. :param concordance: the pairwise concordance of the duplicated markers. :param snpsToComplete: the markers that will be completed (excluding problems). :param tfamFileName: the name of the original ``tfam`` file. :param completionT: the completion threshold. :param concordanceT: the concordance threshold. :type tped: numpy.array :type tfam: list :type snps: dict :type prefix: str :type chosenSNPs: dict :type completion: numpy.array :type concordance: dict :type snpsToComplete: set :type tfamFileName: str :type completionT: float :type concordanceT: float :returns: a tuple containing the new ``tped`` after completion (:py:class:`numpy.array` as the first element, and the index of the markers that will need to be rid of (:py:class:`set`) as the last element. It creates three different files: * ``prefix.zeroed_out``: contains information about markers and samples where the genotyped was zeroed out. * ``prefix.not_good_enough``: contains information about markers that were not good enough to help in completing the chosen markers (because of concordance or completion). * ``prefix.removed_duplicates``: the list of markers that where used for completing the chosen one, hence they will be removed from the final data set. Cycling through every genotypes of every samples of every duplicated markers, checks if the genotypes are all the same. If the chosen one was not called, but the other ones were, then we complete the chosen one with the genotypes for the others (assuming that they are all the same). If there is a difference between the genotypes, it is zeroed out for the chosen marker.", "response": "def createAndCleanTPED(tped, tfam, snps, prefix, chosenSNPs, completion,\n                       concordance, snpsToComplete, tfamFileName, completionT,\n                       concordanceT):\n    \"\"\"Complete a TPED for duplicated SNPs.\n\n    :param tped: a representation of the ``tped`` of duplicated markers.\n    :param tfam: a representation of the ``tfam``.\n    :param snps: the position of duplicated markers in the ``tped``.\n    :param prefix: the prefix of the output files.\n    :param chosenSNPs: the markers that were chosen for completion (including\n                       problems).\n    :param completion: the completion of each of the duplicated markers.\n    :param concordance: the pairwise concordance of the duplicated markers.\n    :param snpsToComplete: the markers that will be completed (excluding\n                           problems).\n    :param tfamFileName: the name of the original ``tfam`` file.\n    :param completionT: the completion threshold.\n    :param concordanceT: the concordance threshold.\n\n    :type tped: numpy.array\n    :type tfam: list\n    :type snps: dict\n    :type prefix: str\n    :type chosenSNPs: dict\n    :type completion: numpy.array\n    :type concordance: dict\n    :type snpsToComplete: set\n    :type tfamFileName: str\n    :type completionT: float\n    :type concordanceT: float\n\n    :returns: a tuple containing the new ``tped`` after completion\n              (:py:class:`numpy.array` as the first element, and the index of\n              the markers that will need to be rid of (:py:class:`set`) as the\n              last element.\n\n    It creates three different files:\n\n    * ``prefix.zeroed_out``: contains information about markers and samples\n                             where the genotyped was zeroed out.\n    * ``prefix.not_good_enough``: contains information about markers that were\n                                  not good enough to help in completing the\n                                  chosen markers (because of concordance or\n                                  completion).\n    * ``prefix.removed_duplicates``: the list of markers that where used for\n                                     completing the chosen one, hence they will\n                                     be removed from the final data\n                                     set.\n\n    Cycling through every genotypes of every samples of every duplicated\n    markers, checks if the genotypes are all the same. If the chosen one was\n    not called, but the other ones were, then we complete the chosen one with\n    the genotypes for the others (assuming that they are all the same). If\n    there is a difference between the genotypes, it is zeroed out for the\n    chosen marker.\n\n    \"\"\"\n    zeroedOutFile = None\n    try:\n        zeroedOutFile = open(prefix + \".zeroed_out\", \"w\")\n    except IOError:\n        msg = \"%(prefix).zeroed_out: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>zeroedOutFile, \"\\t\".join([\"famID\", \"indID\", \"snpID\"])\n\n    notGoodEnoughFile = None\n    try:\n        notGoodEnoughFile = open(prefix + \".not_good_enough\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.not_good_enough: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>notGoodEnoughFile, \"\\t\".join([\"name\", \"reason\"])\n\n    removedFile = None\n    try:\n        removedFile = open(prefix + \".removed_duplicates\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.removed_duplicates: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    notGoodEnoughSnps = set()\n\n    # Split the tped in 'snpInfo' and 'genotypes'\n    snpInfo = tped[:, :4]\n    genotypes = tped[:, 4:]\n\n    # The sed of index we want to get rid of at the end\n    getRidOfIndex = set()\n\n    for snpID, indexes in snps.iteritems():\n        if snpID not in snpsToComplete:\n            # We don't want to complete this SNP, so we continue to next SNP\n            continue\n\n        # Getting the completion\n        completionToRemove = set(\n            np.where(completion[indexes] < completionT)[0]\n        )\n        for k in completionToRemove:\n            notGoodEnoughSnps.add((snpInfo[indexes][k, 1], \"completion\"))\n\n        # Getting the concordance\n        concordanceToRemove = set(\n            np.where(concordance[snpID] < concordanceT)[0]\n        )\n        for k in concordanceToRemove:\n            notGoodEnoughSnps.add((snpInfo[indexes][k, 1], \"concordance\"))\n\n        # These will be the indexes to remove\n        indexesToRemove = set()\n        for index in completionToRemove | concordanceToRemove:\n            indexesToRemove.add(indexes[index])\n\n        # These are the indexes to keep\n        indexesToKeep = []\n        for index in indexes:\n            if index not in indexesToRemove:\n                indexesToKeep.append(index)\n\n        # Getting the chosen SNP\n        chosenOne = chosenSNPs[snpID]\n        if chosenOne not in set(indexesToKeep):\n            # The chosen SNP is not a good SNP, so we go to next SNP\n            logger.warning(\"  - {} chosen but not good enough\".format(\n                snpInfo[chosenOne, 1],\n            ))\n            continue\n\n        # Now cycling through the genotypes\n        nbSamples = genotypes.shape[1]\n        for sampleIndex in xrange(nbSamples):\n            # We need to remove the no call and keep the unique genotypes\n            curGenotypes = genotypes[indexesToKeep, sampleIndex]\n            cleanedCurGenotypes = curGenotypes[\n                np.where(curGenotypes != \"0 0\")\n            ]\n            uniqueCleanedCurGenotypes = np.unique(cleanedCurGenotypes)\n\n            # Checking the number of unique genotypes\n            toComplete = False\n            if len(uniqueCleanedCurGenotypes) > 1:\n                # There are more than one unique genotype (except 0 0)\n                # len = 0 means all were 0 0\n                # len = 1 means they are all the same\n                # len > 1 means discordance (might need to flip)\n                # Just need to check the order of the alleles\n                possibleAlleles = [\n                    set() for k in xrange(len(uniqueCleanedCurGenotypes))\n                ]\n                for k, geno in enumerate(uniqueCleanedCurGenotypes):\n                    possibleAlleles[k] |= set(geno.split(\" \"))\n                allEqual = True\n                for k in xrange(len(possibleAlleles)):\n                    for l in xrange(k+1, len(possibleAlleles)):\n                        if possibleAlleles[k] != possibleAlleles[l]:\n                            allEqual = False\n\n                if not allEqual:\n                    # The genotypes are not all equal, we set the chosen\n                    # genotype to null (0 0)\n                    tped[chosenOne, sampleIndex+4] = \"0 0\"\n                    print >>zeroedOutFile, \"\\t\".join([tfam[sampleIndex, 0],\n                                                      tfam[sampleIndex, 1],\n                                                      snpInfo[chosenOne, 1]])\n                elif genotypes[chosenOne, sampleIndex] == \"0 0\":\n                    toComplete = True\n            elif ((len(uniqueCleanedCurGenotypes) == 1) and\n                    (genotypes[chosenOne, sampleIndex] == \"0 0\")):\n                toComplete = True\n\n            if toComplete:\n                # We complete the current individual\n                tped[chosenOne, sampleIndex+4] = uniqueCleanedCurGenotypes[0]\n\n        # We keep only the chose one\n        for index in indexes:\n            if index != chosenOne:\n                getRidOfIndex.add(index)\n                print >>removedFile, snpInfo[index, 1]\n\n    # Writing the not good enough file\n    for item in notGoodEnoughSnps:\n        print >>notGoodEnoughFile, \"\\t\".join(item)\n\n    # Closing the output files\n    zeroedOutFile.close()\n    notGoodEnoughFile.close()\n\n    # Printing the chosen file\n    try:\n        shutil.copy(tfamFileName, prefix + \".chosen_snps.tfam\")\n    except IOError:\n        msg = \"%(tfamFileName)s: can't copy file to \" \\\n              \"%(prefix)s.chosen_snps.tfam\" % locals()\n        raise ProgramError(msg)\n    chosenFile = None\n    try:\n        chosenFile = open(prefix + \".chosen_snps.tped\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.chosen_snps.tped: can't write file\" % locals()\n        raise ProgramError(msg)\n    for chosenOne in chosenSNPs.itervalues():\n        snpID = (tped[chosenOne, 0], tped[chosenOne, 3])\n        if snpID in snpsToComplete:\n            print >>chosenFile, \"\\t\".join(tped[chosenOne])\n    chosenFile.close()\n\n    return tped, getRidOfIndex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchoosing the best duplicates according to the completion and concordance. :param tped: a representation of the ``tped`` of duplicated markers. :param snps: the position of the duplicated markers in the ``tped``. :param trueCompletion: the completion of each markers. :param trueConcordance: the pairwise concordance of each markers. :param prefix: the prefix of the output files. :type tped: numpy.array :type snps: dict :type trueCompletion: numpy.array :type trueConcordance: dict :type prefix: str :returns: a tuple containing the chosen indexes (:py:class:`dict`) as the first element, the completion (:py:class:`numpy.array`) as the second element, and the concordance (:py:class:`dict`) as last element. It creates two output files: ``prefix.chosen_snps.info`` and ``prefix.not_chosen_snps.info``. The first one contains the markers that were chosen for completion, and the second one, the markers that weren't. It starts by computing the completion of each markers (dividing the number of calls divided by the total number of genotypes). Then, for each of the duplicated markers, we choose the best one according to completion and concordance (see explanation in :py:func:`DupSamples.duplicated_samples.chooseBestDuplicates` for more details).", "response": "def chooseBestSnps(tped, snps, trueCompletion, trueConcordance, prefix):\n    \"\"\"Choose the best duplicates according to the completion and concordance.\n\n    :param tped: a representation of the ``tped`` of duplicated markers.\n    :param snps: the position of the duplicated markers in the ``tped``.\n    :param trueCompletion: the completion of each markers.\n    :param trueConcordance: the pairwise concordance of each markers.\n    :param prefix: the prefix of the output files.\n\n    :type tped: numpy.array\n    :type snps: dict\n    :type trueCompletion: numpy.array\n    :type trueConcordance: dict\n    :type prefix: str\n\n    :returns: a tuple containing the chosen indexes (:py:class:`dict`) as the\n              first element, the completion (:py:class:`numpy.array`) as the\n              second element, and the concordance (:py:class:`dict`) as last\n              element.\n\n    It creates two output files: ``prefix.chosen_snps.info`` and\n    ``prefix.not_chosen_snps.info``. The first one contains the markers that\n    were chosen for completion, and the second one, the markers that weren't.\n\n    It starts by computing the completion of each markers (dividing the number\n    of calls divided by the total number of genotypes). Then, for each of the\n    duplicated markers, we choose the best one according to completion and\n    concordance (see explanation in\n    :py:func:`DupSamples.duplicated_samples.chooseBestDuplicates` for more\n    details).\n\n    \"\"\"\n    # The output files\n    chosenFile = None\n    try:\n        chosenFile = open(prefix + \".chosen_snps.info\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.chosen_snps.info: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    excludedFile = None\n    try:\n        excludedFile = open(prefix + \".not_chosen_snps.info\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.not_chosen_snps.info: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    # Computing the completion\n    completion = np.true_divide(trueCompletion[0], trueCompletion[1])\n\n    # For each duplicated SNPs\n    chosenIndexes = {}\n    snpConcordance = {}\n    for snp, indexes in snps.iteritems():\n        # Getting the completion for those duplicated SNPs\n        currCompletion = completion[indexes]\n\n        # Sorting those completion\n        sortedCompletionInsexes = np.argsort(currCompletion)\n\n        # Getting the concordance\n        concordance = np.true_divide(trueConcordance[snp][0],\n                                     trueConcordance[snp][1])\n\n        currConcordance = [[] for i in xrange(len(indexes))]\n        for i in xrange(len(indexes)):\n            indexToKeep = list(set(range(len(indexes))) - set([i]))\n            currConcordance[i] = np.mean(concordance[i, indexToKeep])\n        currConcordance = np.array(currConcordance)\n        if snp not in snpConcordance:\n            snpConcordance[snp] = currConcordance\n\n        # Sorting the concordance\n        sortedConcordanceIndexes = np.argsort(currConcordance)\n\n        # Trying to find the best duplicate to keep\n        nbToCheck = 1\n        chosenIndex = None\n        while nbToCheck <= len(indexes):\n            # Getting the `nbToCheck` best value (higher to lower)\n            completionValue = currCompletion[\n                sortedCompletionInsexes[nbToCheck*-1]\n            ]\n            concordanceValue = currConcordance[\n                sortedConcordanceIndexes[nbToCheck*-1]\n            ]\n\n            # Getting the indexes to consider\n            completionToConsider = set(\n                np.where(currCompletion >= completionValue)[0]\n            )\n            concordanceToConsider = set(\n                np.where(currConcordance >= concordanceValue)[0]\n            )\n\n            # Getting the intersection of the indexes\n            toConsider = concordanceToConsider & completionToConsider\n            if len(toConsider) >= 1:\n                chosenIndex = random.choice(list(toConsider))\n                break\n            nbToCheck += 1\n\n        if chosenIndex is None:\n            msg = \"Could not choose the best snp ID\"\n            raise ProgramError(msg)\n\n        # Printing the chosen SNPs\n        print >>chosenFile, tped[indexes[chosenIndex], 1]\n\n        # Printing the excluded SNPs\n        for i, index in enumerate(indexes):\n            if i != chosenIndex:\n                print >>excludedFile, tped[index, 1]\n\n        chosenIndexes[snp] = indexes[chosenIndex]\n\n    # Closing the output files\n    chosenFile.close()\n    excludedFile.close()\n\n    return chosenIndexes, completion, snpConcordance"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the frequency of the SNPs in a single file.", "response": "def computeFrequency(prefix, outPrefix):\n    \"\"\"Computes the frequency of the SNPs using Plink.\n\n    :param prefix: the prefix of the input files.\n    :param outPrefix: the prefix of the output files.\n\n    :type prefix: str\n    :type outPrefix: str\n\n    :returns: a :py:class:`dict` containing the frequency of each marker.\n\n    Start by computing the frequency of all markers using Plink. Then, it reads\n    the output file, and saves the frequency and allele information.\n\n    \"\"\"\n    # The plink command\n    plinkCommand = [\"plink\", \"--noweb\", \"--tfile\", prefix, \"--freq\", \"--out\",\n                    outPrefix + \".duplicated_snps\"]\n    runCommand(plinkCommand)\n\n    # Reading the frequency file\n    snpFreq = {}\n    try:\n        with open(outPrefix + \".duplicated_snps.frq\", \"r\") as inputFile:\n            headerIndex = None\n            for i, line in enumerate(inputFile):\n                row = createRowFromPlinkSpacedOutput(line)\n                if i == 0:\n                    # This is the header\n                    headerIndex = dict([\n                        (row[j], j) for j in xrange(len(row))\n                    ])\n\n                    # Checking the column titles\n                    for columnTitle in [\"SNP\", \"MAF\", \"A1\", \"A2\"]:\n                        if columnTitle not in headerIndex:\n                            msg = \"%(outPrefix)s.duplicated_snps.frq: no \" \\\n                                  \"column called %(columnTitle)s\" % locals()\n                            raise ProgramError(msg)\n                else:\n                    # This is data\n                    snpName = row[headerIndex[\"SNP\"]]\n                    maf = row[headerIndex[\"MAF\"]]\n                    a1 = row[headerIndex[\"A1\"]]\n                    a2 = row[headerIndex[\"A2\"]]\n                    try:\n                        if maf == \"NA\":\n                            maf = 0.0\n                        else:\n                            maf = float(maf)\n                    except ValueError:\n                        msg = \"%(outPrefix)s.duplicated_snps.frq: %(maf)s: \" \\\n                              \"not a valid MAF\" % locals()\n                        raise ProgramError(msg)\n                    snpFreq[snpName] = (maf, (a1, a2))\n    except IOError:\n        msg = \"%(outPrefix)s.duplicated_snps.freq: no such file\" % locals()\n        raise ProgramError(msg)\n\n    return snpFreq"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef printDuplicatedTPEDandTFAM(tped, tfamFileName, outPrefix):\n    # Copying the tfam file\n    try:\n        shutil.copy(tfamFileName, outPrefix + \".duplicated_snps.tfam\")\n    except IOError:\n        msg = \"%(tfamFileName)s: can't copy file to \" \\\n              \"%(outPrefix)s.duplicated_snps.tfam\" % locals()\n        raise ProgramError(msg)\n\n    # Writing the tped\n    tpedFile = None\n    try:\n        tpedFile = open(outPrefix + \".duplicated_snps.tped\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.duplicated_snps.tped: can't write \" \\\n              \"file\" % locals()\n        raise ProgramError(msg)\n    for row in tped:\n        print >>tpedFile, \"\\t\".join(row)\n    tpedFile.close()", "response": "Print the duplicated SNPs TPED and TFAM."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the concordance. :param concordance: the concordance. :param prefix: the prefix if the output files. :param tped: a representation of the ``tped`` of duplicated markers. :param snps: the position of the duplicated markers in the ``tped``. :type concordance: dict :type prefix: str :type tped: numpy.array :type snps: dict Prints the concordance in a file, in the format of a matrix. For each duplicated markers, the first line (starting with the `#` signs) contains the name of all the markers in the duplicated markers set. Then a :math:`N \\\\times N` matrix is printed to file (where :math:`N` is the number of markers in the duplicated marker list), containing the pairwise concordance.", "response": "def printConcordance(concordance, prefix, tped, snps):\n    \"\"\"Print the concordance.\n\n    :param concordance: the concordance.\n    :param prefix: the prefix if the output files.\n    :param tped: a representation of the ``tped`` of duplicated markers.\n    :param snps: the position of the duplicated markers in the ``tped``.\n\n    :type concordance: dict\n    :type prefix: str\n    :type tped: numpy.array\n    :type snps: dict\n\n    Prints the concordance in a file, in the format of a matrix. For each\n    duplicated markers, the first line (starting with the `#` signs) contains\n    the name of all the markers in the duplicated markers set. Then a :math:`N\n    \\\\times N` matrix is printed to file (where :math:`N` is the number of\n    markers in the duplicated marker list), containing the pairwise\n    concordance.\n\n    \"\"\"\n    outFile = None\n    try:\n        outFile = open(prefix + \".concordance\", \"w\")\n    except IOError:\n        msg = \"%s: can't write file\" % prefix + \".concordance\"\n        raise ProgramError(msg)\n\n    for snpID in concordance.iterkeys():\n        print >>outFile, \"#\" + \"\\t\".join(\n            list(snpID) + list(tped[snps[snpID], 1])\n        )\n\n        # Doing the division\n        true_concordance = np.true_divide(concordance[snpID][0],\n                                          concordance[snpID][1])\n\n        output = StringIO.StringIO()\n        np.savetxt(output, true_concordance, delimiter=\"\\t\", fmt=\"%.8f\")\n        print >>outFile, output.getvalue().rstrip(\"\\r\\n\")\n\n    outFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef printProblems(completion, concordance, tped, snps, frequencies, prefix,\n                  diffFreq):\n    \"\"\"Print the statistics.\n\n    :param completion: the completion of each duplicated markers.\n    :param concordance: the pairwise concordance between duplicated markers.\n    :param tped: a representation of the ``tped`` of duplicated markers.\n    :param snps: the positions of the duplicated markers in the ``tped``\n    :param frequencies: the frequency of each of the duplicated markers.\n    :param prefix: the prefix of the output files.\n    :param diffFreq: the frequency difference threshold.\n\n    :type completion: numpy.array\n    :type concordance: dict\n    :type tped: numpy.array\n    :type snps: dict\n    :type frequencies: dict\n    :type prefix: str\n    :type diffFreq: float\n\n    :returns: a :py:class:`set` containing duplicated markers to complete.\n\n    Creates a summary file (``prefix.summary``) containing information about\n    duplicated markers: chromosome, position, name, alleles, status, completion\n    percentage, completion number and mean concordance.\n\n    The frequency and the minor allele are used to be certain that two\n    duplicated markers are exactly the same marker (and not a tri-allelic one,\n    for example).\n\n    For each duplicated markers:\n\n    1. Constructs the set of available alleles for the first marker.\n    2. Constructs the set of available alleles for the second marker.\n    3. If the two sets are different, but the number of alleles is the same, we\n       try to flip one of the marker. If the two sets are the same, but the\n       number of alleles is 1, we set the status to ``homo_flip``. If the\n       markers are heterozygous, we set the status to ``flip``.\n    4. If there is a difference in the number of alleles (one is homozygous,\n       the other, heterozygous), and that there is on allele in common, we set\n       the status to ``homo_hetero``. If there are no allele in common, we try\n       to flip one. If the new sets have one allele in common, we set the\n       status to ``homo_hetero_flip``.\n    5. If the sets of available alleles are the same (without flip), we check\n       the frequency and the minor alleles. If the minor allele is different,\n       we set the status to ``diff_minor_allele``. If the difference in\n       frequencies is higher than a threshold, we set the status to\n       ``diff_frequency``.\n    6. If all of the above fail, we set the status to ``problem``.\n\n    Problems are written in the ``prefix.problems`` file, and contains the\n    following columns: chromosome, position, name and status. This file\n    contains all the markers with a status, as explained above.\n\n    \"\"\"\n\n    completionPercentage = np.true_divide(completion[0], completion[1])\n\n    outSummary = None\n    try:\n        outSummary = open(prefix + \".summary\", \"w\")\n    except IOError:\n        msg = \"%s: can't write file\" % prefix + \".summary\"\n        raise ProgramError\n\n    # Prints the header of the summary file\n    print >>outSummary, \"\\t\".join([\"chr\", \"pos\", \"name\", \"alleles\", \"status\",\n                                   \"% completion\", \"completion\",\n                                   \"mean concordance\"])\n\n    # The data structure containing the problems\n    problems = {}\n    for snpID, indexes in snps.iteritems():\n        for i, index in enumerate(indexes):\n            # The SNP information (chromosome and position)\n            toPrint = list(snpID)\n\n            # The name of the SNP\n            snpName = tped[index, 1]\n            toPrint.append(snpName)\n\n            # The frequency of the SNP\n            snpFreq, mafAlleles = frequencies[snpName]\n\n            # A list of the other SNP name with problems\n            otherSnpNameWithProblem = set()\n\n            # The alleles\n            alleles = set()\n            otherAlleles = set()\n            status = []\n            for genotype in np.unique(tped[index, 4:]):\n                alleles |= set(genotype.split(\" \"))\n            if \"0\" in alleles:\n                alleles.remove(\"0\")\n            for j in xrange(i+1, len(indexes)):\n                otherIndex = indexes[j]\n                otherSnpName = tped[otherIndex, 1]\n\n                # The frequency of the other SNP\n                otherSnpFreq, otherMafAlleles = frequencies[otherSnpName]\n\n                # Checking the alleles\n                for genotype in np.unique(tped[otherIndex, 4:]):\n                    otherAlleles |= set(genotype.split(\" \"))\n                if \"0\" in otherAlleles:\n                    otherAlleles.remove(\"0\")\n                if alleles != otherAlleles:\n                    if len(alleles) == len(otherAlleles):\n                        # Same number of alleles\n                        # Try the flipped ones\n                        otherAlleles = flipGenotype(otherAlleles)\n                        if alleles == otherAlleles:\n                            if len(alleles) == 1:\n                                status.append(\"homo_flip\")\n                                otherSnpNameWithProblem.add(otherSnpName)\n                            else:\n                                status.append(\"flip\")\n                                otherSnpNameWithProblem.add(otherSnpName)\n                        else:\n                            status.append(\"problem\")\n                            otherSnpNameWithProblem.add(otherSnpName)\n                    else:\n                        # Different number of alleles\n                        if len(alleles & otherAlleles) == 1:\n                            status.append(\"homo_hetero\")\n                            otherSnpNameWithProblem.add(otherSnpName)\n                        else:\n                            # Try the flipped one\n                            otherAlleles = flipGenotype(otherAlleles)\n                            if len(alleles & otherAlleles) == 1:\n                                status.append(\"homo_hetero_flip\")\n                                otherSnpNameWithProblem.add(otherSnpName)\n                            else:\n                                status.append(\"problem\")\n                                otherSnpNameWithProblem.add(otherSnpName)\n                else:\n                    # The alleles are the same, so we check the frequency\n                    if mafAlleles[0] != otherMafAlleles[0]:\n                        # They don't have the same minor allele\n                        status.append(\"diff_minor_allele\")\n                        otherSnpNameWithProblem.add(otherSnpName)\n                    elif math.fabs(snpFreq - otherSnpFreq) > diffFreq:\n                        # They don't have same frequency\n                        status.append(\"diff_frequency\")\n                        otherSnpNameWithProblem.add(otherSnpName)\n\n            alleles = list(alleles)\n            alleles.sort()\n            if len(alleles) == 1:\n                alleles.append(alleles[0])\n            toPrint.append(\" \".join(alleles))\n            toPrint.append(\";\".join(status))\n\n            # The completion\n            toPrint.append(\"%.8f\" % completionPercentage[index])\n            toPrint.append(\"%d/%d\" % (completion[0][index],\n                                      completion[1][index]))\n\n            # The concordance\n            indexToKeep = list(set(range(len(indexes))) - set([i]))\n            currConcordance = np.true_divide(\n                concordance[snpID][0][i, indexToKeep],\n                concordance[snpID][1][i, indexToKeep],\n            )\n            currConcordance = np.mean(currConcordance)\n            toPrint.append(\"%.8f\" % currConcordance)\n            print >>outSummary, \"\\t\".join(toPrint)\n\n            # Now updating the problems data structure\n            if len(status) != len(otherSnpNameWithProblem):\n                msg = \"There is a problem with the problematic SNPs\"\n                raise ProgramError(msg)\n\n            if len(status) > 0:\n                if snpID not in problems:\n                    tmp = {\"snpNames\": {snpName}, \"problems\": set()}\n                    problems[snpID] = tmp\n\n                # We have problems\n                problems[snpID][\"snpNames\"] |= otherSnpNameWithProblem\n                problems[snpID][\"problems\"] |= set(status)\n\n    outSummary.close()\n\n    outProblems = None\n    try:\n        outProblems = open(prefix + \".problems\", \"w\")\n    except IOError:\n        msg = \"%s: can't write file\" % prefix + \".problems\"\n        raise ProgramError\n\n    # Printing the header of the problem file...\n    print >>outProblems, \"\\t\".join([\"chr\", \"pos\", \"name\", \"status\"])\n    for snpID in problems.iterkeys():\n        toPrint = list(snpID)\n        toPrint.append(\";\".join(list(problems[snpID][\"snpNames\"])))\n        toPrint.append(\";\".join(list(problems[snpID][\"problems\"])))\n        print >>outProblems, \"\\t\".join(toPrint)\n\n    outProblems.close()\n\n    # Returning the SNPs to complete\n    return set(snps.keys()) - set(problems.keys())", "response": "Print the statistics of the duplicated markers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the completion and concordance of each SNP in the duplicated markers.", "response": "def computeStatistics(tped, tfam, snps):\n    \"\"\"Computes the completion and concordance of each SNPs.\n\n    :param tped: a representation of the ``tped``.\n    :param tfam: a representation of the ``tfam``\n    :param snps: the position of the duplicated markers in the ``tped``.\n\n    :type tped: numpy.array\n    :type tfam: list\n    :type snps: dict\n\n    :returns: a tuple containing the completion of duplicated markers\n              (:py:class:`numpy.array`) as first element, and the concordance\n              (:py:class:`dict`) of duplicated markers, as last element.\n\n    A marker's completion is compute using this formula (where :math:`G_i` is\n    the set of genotypes for the marker :math:`i`):\n\n    .. math::\n        Completion_i = \\\\frac{||g \\\\in G_i \\\\textrm{ where } g \\\\neq 0||}\n                             {||G_i||}\n\n    The pairwise concordance between duplicated markers is compute as follow\n    (where :math:`G_i` and :math:`G_j` are the sets of genotypes for markers\n    :math:`i` and :math:`j`, respectively):\n\n    .. math::\n        Concordance_{i,j} = \\\\frac{\n            ||g \\\\in G_i \\\\cup G_j \\\\textrm{ where } g_i = g_j \\\\neq 0||\n        }{\n            ||g \\\\in G_i \\\\cup G_j \\\\textrm{ where } g \\\\neq 0||\n        }\n\n    Hence, we only computes the numerators and denominators of the completion\n    and concordance, for future reference.\n\n    .. note::\n        When the genotypes are not comparable, the function tries to flip one\n        of the genotype to see if it becomes comparable.\n\n    \"\"\"\n    # The completion data type\n    completion = np.array([[0 for i in xrange(len(tped))],\n                           [0 for i in xrange(len(tped))]])\n\n    # The concordance data type\n    concordance = {}\n    for snpID in snps.keys():\n        nbDup = len(snps[snpID])\n        concordance[snpID] = [\n            np.asmatrix(np.zeros((nbDup, nbDup), dtype=int)),\n            np.asmatrix(np.zeros((nbDup, nbDup), dtype=int))\n        ]\n\n    # The women and the no sex\n    menIndex = np.where(tfam[:, 4] == \"1\")\n    womenIndex = np.where(tfam[:, 4] == \"2\")\n    noSexIndex = np.where(tfam[:, 4] == \"0\")\n\n    for snpID, indexes in snps.iteritems():\n        nbDup = len(indexes)\n        currGenotypes = tped[indexes, 4:]\n        chromosome, position = snpID\n\n#         if chromosome == \"24\":\n#             # Remove the heterozygous men\n#             menToRemove = getIndexOfHeteroMen(currGenotypes, menIndex)\n#             # Remove the women and the no sex\n#             currGenotypes = np.delete(currGenotypes,\n#                                        np.hstack((womenIndex, noSexIndex,\n#                                                    menToRemove)), 1)\n#         elif chromosome == \"23\":\n#             # Remove the heterozygous men\n#             menToRemove = getIndexOfHeteroMen(currGenotypes, menIndex)\n#             # Remove the no sex\n#             currGenotypes = np.delete(currGenotypes,\n#                                        np.hstack((noSexIndex, menToRemove)),\n#                                        1)\n\n        for i in xrange(nbDup):\n            # Compute completion here\n            completion[0][indexes[i]] = len(\n                np.where(currGenotypes[i] != \"0 0\")[0]\n            )\n            completion[1][indexes[i]] = len(currGenotypes[i])\n            for j in xrange(i+1, nbDup):\n                # Compute concordance here\n                # Removing samples with at least one null genotype\n                nullGenotypeIndexes = np.where(\n                    np.any(currGenotypes[[i, j]] == \"0 0\", 0)\n                )\n                subGenotypes = np.delete(\n                    currGenotypes,\n                    nullGenotypeIndexes,\n                    1,\n                )\n\n                # Finding the errors in the subseted genotypes\n                errorIndexes = np.where(subGenotypes[i] != subGenotypes[j])[0]\n                nbDiff = len(errorIndexes)\n\n                for k in errorIndexes:\n                    # Getting the genotypes\n                    genotype1 = set(subGenotypes[i, k].split(\" \"))\n                    genotype2 = set(subGenotypes[j, k].split(\" \"))\n\n                    # Checking for flips\n                    if len(genotype1) == len(genotype2):\n                        # Both have the same number of different alleles,\n                        # so they might be flipped\n                        genotype2 = flipGenotype(genotype2)\n                        if genotype1 == genotype2:\n                            # The genotypes are equivalent after the flip\n                            nbDiff -= 1\n\n                # Updating the concordance\n                nbTot = len(subGenotypes[i])\n                concordance[snpID][0][i, j] = nbTot - nbDiff\n                concordance[snpID][0][j, i] = nbTot - nbDiff\n                if nbTot == 0:\n                    # We will have a division by 0...\n                    nbTot = 1\n                concordance[snpID][1][i, j] = nbTot\n                concordance[snpID][1][j, i] = nbTot\n\n    for snpID in concordance.iterkeys():\n        for i in range(len(concordance[snpID][0])):\n            concordance[snpID][0][i, i] = 1\n            concordance[snpID][1][i, i] = 1\n\n    return completion, concordance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getIndexOfHeteroMen(genotypes, menIndex):\n    toRemove = set()\n    for i in menIndex[0]:\n        for genotype in [set(j.split(\" \")) for j in genotypes[:, i]]:\n            if len(genotype) != 1:\n                # We have an heterozygous\n                toRemove.add(i)\n\n    toRemove = list(toRemove)\n    toRemove.sort()\n\n    return (np.array(toRemove, dtype=int),)", "response": "Get the indexes of heterozygous genotypes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nflipping a genotype. :param genotype: the genotype to flip. :type genotype: set :returns: the new flipped genotype (as a :py:class:`set`) .. testsetup:: from pyGenClean.DupSNPs.duplicated_snps import flipGenotype .. doctest:: >>> flipGenotype({\"A\", \"T\"}) set(['A', 'T']) >>> flipGenotype({\"C\", \"T\"}) set(['A', 'G']) >>> flipGenotype({\"T\", \"G\"}) set(['A', 'C']) >>> flipGenotype({\"0\", \"0\"}) Traceback (most recent call last): ... ProgramError: 0: unkown allele >>> flipGenotype({\"A\", \"N\"}) Traceback (most recent call last): ... ProgramError: N: unkown allele", "response": "def flipGenotype(genotype):\n    \"\"\"Flips a genotype.\n\n    :param genotype: the genotype to flip.\n\n    :type genotype: set\n\n    :returns: the new flipped genotype (as a :py:class:`set`)\n\n    .. testsetup::\n\n        from pyGenClean.DupSNPs.duplicated_snps import flipGenotype\n\n    .. doctest::\n\n        >>> flipGenotype({\"A\", \"T\"})\n        set(['A', 'T'])\n        >>> flipGenotype({\"C\", \"T\"})\n        set(['A', 'G'])\n        >>> flipGenotype({\"T\", \"G\"})\n        set(['A', 'C'])\n        >>> flipGenotype({\"0\", \"0\"})\n        Traceback (most recent call last):\n            ...\n        ProgramError: 0: unkown allele\n        >>> flipGenotype({\"A\", \"N\"})\n        Traceback (most recent call last):\n            ...\n        ProgramError: N: unkown allele\n\n    \"\"\"\n    newGenotype = set()\n    for allele in genotype:\n        if allele == \"A\":\n            newGenotype.add(\"T\")\n        elif allele == \"C\":\n            newGenotype.add(\"G\")\n        elif allele == \"T\":\n            newGenotype.add(\"A\")\n        elif allele == \"G\":\n            newGenotype.add(\"C\")\n        else:\n            msg = \"%(allele)s: unknown allele\" % locals()\n            raise ProgramError(msg)\n\n    return newGenotype"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the TPED file. :param uniqueSNPs: the unique markers. :param mapF: a representation of the ``map`` file. :param fileName: the name of the ``tped`` file. :param tfam: the name of the ``tfam`` file. :param prefix: the prefix of all the files. :type uniqueSNPs: dict :type mapF: list :type fileName: str :type tfam: str :type prefix: str :returns: a tuple with the representation of the ``tped`` file (:py:class:`numpy.array`) as first element, and the updated position of the duplicated markers in the ``tped`` representation. Copies the ``tfam`` file into ``prefix.unique_snps.tfam``. While reading the ``tped`` file, creates a new one (``prefix.unique_snps.tped``) containing only unique markers.", "response": "def processTPED(uniqueSNPs, mapF, fileName, tfam, prefix):\n    \"\"\"Process the TPED file.\n\n    :param uniqueSNPs: the unique markers.\n    :param mapF: a representation of the ``map`` file.\n    :param fileName: the name of the ``tped`` file.\n    :param tfam: the name of the ``tfam`` file.\n    :param prefix: the prefix of all the files.\n\n    :type uniqueSNPs: dict\n    :type mapF: list\n    :type fileName: str\n    :type tfam: str\n    :type prefix: str\n\n    :returns: a tuple with the representation of the ``tped`` file\n              (:py:class:`numpy.array`) as first element, and the updated\n              position of the duplicated markers in the ``tped``\n              representation.\n\n    Copies the ``tfam`` file into ``prefix.unique_snps.tfam``. While reading\n    the ``tped`` file, creates a new one (``prefix.unique_snps.tped``)\n    containing only unique markers.\n\n    \"\"\"\n    # Copying the tfam file\n    try:\n        shutil.copy(tfam, prefix + \".unique_snps.tfam\")\n    except IOError:\n        msg = \"%s: can't write file\" % prefix + \".unique_snps.tfam\"\n        raise ProgramError(msg)\n\n    tped = []\n    updatedSNPs = defaultdict(list)\n    outputFile = None\n    try:\n        outputFile = open(prefix + \".unique_snps.tped\", \"w\")\n    except IOError:\n        msg = \"%s: can't write to file\" % prefix + \".unique_snps.tped\"\n        raise ProgramError(msg)\n    nbSNP = 0\n    with open(fileName, 'r') as inputFile:\n        for line in inputFile:\n            nbSNP += 1\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            snpInfo = row[:4]\n            genotype = [i.upper() for i in row[4:]]\n\n            chromosome = snpInfo[0]\n            position = snpInfo[3]\n\n            if (chromosome, position) in uniqueSNPs:\n                # Printing the new TPED file (unique SNPs only)\n                print >>outputFile, \"\\t\".join(snpInfo + genotype)\n            else:\n                # Saving the TPED file (duplicated samples only)\n                currPos = len(tped)\n                tped.append(tuple(snpInfo + genotype))\n                updatedSNPs[(chromosome, position)].append(currPos)\n    outputFile.close()\n\n    if len(mapF) != nbSNP:\n        msg = \"%(fileName)s: no the same number of SNPs than MAP \" \\\n              \"file\" % locals()\n        raise ProgramError(msg)\n\n    tped = np.array(tped)\n\n    return tped, updatedSNPs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the unique markers in a MAP file.", "response": "def findUniques(mapF):\n    \"\"\"Finds the unique markers in a MAP.\n\n    :param mapF: representation of a ``map`` file.\n\n    :type mapF: list\n\n    :returns: a :py:class:`dict` containing unique markers (according to their\n              genomic localisation).\n\n    \"\"\"\n    uSNPs = {}\n    dSNPs = defaultdict(list)\n    for i, row in enumerate(mapF):\n        chromosome = row[0]\n        position = row[3]\n        snpID = (chromosome, position)\n        if snpID not in uSNPs:\n            # This is the first time we see this sample\n            uSNPs[snpID] = i\n        else:\n            # We have seen this sample at least once...\n            if snpID not in dSNPs:\n                # This is the second time we see this sample...\n                dSNPs[snpID].extend([uSNPs[snpID], i])\n            else:\n                # We have seen this sample multiple times\n                dSNPs[snpID].append(i)\n\n    # Removing the duplicates from the unique samples\n    for snpID in dSNPs.iterkeys():\n        if snpID in uSNPs:\n            del uSNPs[snpID]\n\n    return uSNPs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readTFAM(fileName):\n    # Saving the TFAM file\n    tfam = None\n    with open(fileName, 'r') as inputFile:\n        tfam = [\n            tuple(i.rstrip(\"\\r\\n\").split(\"\\t\")) for i in inputFile.readlines()\n        ]\n\n    tfam = np.array(tfam)\n\n    return tfam", "response": "Reads the TFAM file and returns a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the MAP file and saves it as a file containing the unique markers.", "response": "def readMAP(fileName, prefix):\n    \"\"\"Reads the MAP file.\n\n    :param fileName: the name of the ``map`` file.\n\n    :type fileName: str\n\n    :returns: a list of tuples, representing the ``map`` file.\n\n    While reading the ``map`` file, it saves a file\n    (``prefix.duplicated_marker_names``) containing the name of the unique\n    duplicated markers.\n\n    \"\"\"\n    # Saving the MAP file\n    mapF = None\n    with open(fileName, 'r') as inputFile:\n        mapF = [\n            tuple(i.rstrip(\"\\r\\n\").split(\"\\t\")) for i in inputFile.readlines()\n        ]\n\n    # Test for uniqueness of names\n    marker_names = np.array([i[1] for i in mapF])\n    nb_with_same_name = len(marker_names) - len(np.unique(marker_names))\n    if nb_with_same_name > 0:\n        logger.info(\"  - {} markers with same name\".format(nb_with_same_name))\n        u, indices = np.unique(marker_names, return_index=True)\n        duplicated_indices = np.setdiff1d(np.arange(len(marker_names)),\n                                          indices)\n        duplicated_indices = np.in1d(marker_names,\n                                     marker_names[duplicated_indices])\n        marker_chr_pos = np.array([(i[0], i[3]) for i in mapF],\n                                  dtype=[(\"chr\", int),\n                                         (\"pos\", int)])[duplicated_indices]\n        marker_names = marker_names[duplicated_indices]\n        try:\n            duplicated_marker_names = open(prefix + \".duplicated_marker_names\",\n                                           \"w\")\n        except IOError:\n            msg = \"{}.duplicated_marker_names: can't write file\".format(prefix)\n            raise ProgramError(msg)\n        for i in xrange(len(marker_names)):\n            print >>duplicated_marker_names, \"\\t\".join([marker_names[i]] +\n                                                       map(str,\n                                                           marker_chr_pos[i]))\n        duplicated_marker_names.close()\n\n    return mapF"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the arguments and options of the ArcGIS program.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Checking the input files\n    for suffix in [\".tped\", \".tfam\", \".map\"]:\n        fileName = args.tfile + suffix\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Checking the concordance threshold\n    if ((args.snp_concordance_threshold < 0) or\n            (args.snp_concordance_threshold > 1)):\n        msg = \"snp-concordance-threshold: must be between 0 and 1 \" \\\n              \"(not %f)\" % args.snp_concordance_threshold\n        raise ProgramError(msg)\n\n    # Checking the completion threshold\n    if ((args.snp_completion_threshold < 0) or\n            (args.snp_completion_threshold > 1)):\n        msg = \"snp-completion-threshold: must be between 0 and 1 \" \\\n              \"(not %f)\" % args.snp_completion_threshold\n        raise ProgramError(msg)\n\n    # Checking the difference in frequency\n    if (args.frequency_difference < 0) or (args.frequency_difference > 1):\n        msg = (\"{}: maximal frequency difference: value must be between 0 and \"\n               \"1 (inclusively)\".format())\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findMenu(self, title):\n        # See also http://www.riverbankcomputing.co.uk/static/Docs/PyQt4/pyqt4ref.html#differences-between-pyqt-and-qt\n        #title = QApplication.translate(mikro.classname(self.window), title)\n        for menu in self.iter_menus():\n            if menu.title() == title:\n                return menu\n            for innerMenu in self.iter_inner_menus(menu):\n                if innerMenu.title() == title:\n                    return innerMenu", "response": "find a menu with a given title"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert a menu before another menu in the menubar.", "response": "def insertMenuBefore(self, before_menu, new_menu):\n        \"\"\"\n        Insert a menu after another menu in the menubar\n\n        @type: before_menu QMenu instance or title string of menu\n        @param before_menu: menu which should be after the newly inserted menu\n        @rtype: QAction instance\n        @return: action for inserted menu\n        \"\"\"\n        if isinstance(before_menu, string_types):\n            before_menu = self.findMenu(before_menu)\n        before_action = self.actionForMenu(before_menu)\n        # I have no clue why QMenuBar::insertMenu only allows\n        # to insert before another menu and not after a menu...\n        new_action = self.insertMenu(before_action, new_menu)\n        return new_action"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a widget that should be placed in the second tree column.", "response": "def makeWidget(self):\n        \"\"\"\n        Return a single widget that should be placed in the second tree column.\n        The widget must be given three attributes:\n\n        ==========  ============================================================\n        sigChanged  a signal that is emitted when the widget's value is changed\n        value       a function that returns the value\n        setValue    a function that sets the value\n        ==========  ============================================================\n\n        This is a good function to override in subclasses.\n        \"\"\"\n        opts = self.param.opts\n        t = opts['type']\n        if t == 'int':\n            defs = {\n                'value': 0, 'min': None, 'max': None, 'int': True,\n                'step': 1.0, 'minStep': 1.0, 'dec': False,\n                'siPrefix': False, 'suffix': ''\n            }\n            defs.update(opts)\n            if 'limits' in opts:\n                defs['bounds'] = opts['limits']\n            w = SpinBox()\n            w.setOpts(**defs)\n            w.sigChanged = w.sigValueChanged\n            w.sigChanging = w.sigValueChanging\n        elif t == 'float':\n            defs = {\n                'value': 0, 'min': None, 'max': None,\n                'step': 1.0, 'dec': False,\n                'siPrefix': False, 'suffix': ''\n            }\n            defs.update(opts)\n            if 'limits' in opts:\n                defs['bounds'] = opts['limits']\n            w = SpinBox()\n            w.setOpts(**defs)\n            w.sigChanged = w.sigValueChanged\n            w.sigChanging = w.sigValueChanging\n        elif t == 'bool':\n            w = QtWidgets.QCheckBox()\n            w.sigChanged = w.toggled\n            w.value = w.isChecked\n            w.setValue = w.setChecked\n            w.setEnabled(not opts.get('readonly', False))\n            self.hideWidget = False\n        elif t == 'str':\n            w = QtWidgets.QLineEdit()\n            w.sigChanged = w.editingFinished\n            w.value = lambda: asUnicode(w.text())\n            w.setValue = lambda v: w.setText(asUnicode(v))\n            w.sigChanging = w.textChanged\n        elif t == 'color':\n            w = ColorButton()\n            w.sigChanged = w.sigColorChanged\n            w.sigChanging = w.sigColorChanging\n            w.value = w.color\n            w.setValue = w.setColor\n            self.hideWidget = False\n            w.setFlat(True)\n            w.setEnabled(not opts.get('readonly', False))\n        elif t == 'colormap':\n            # from pyqtgraph_karl.widgets.GradientWidget import GradientWidget\n            # ## need this here to avoid import loop\n            w = GradientWidget(orientation='bottom')\n            w.sigChanged = w.sigGradientChangeFinished\n            w.sigChanging = w.sigGradientChanged\n            w.value = w.colorMap\n            w.setValue = w.setColorMap\n            self.hideWidget = False\n        else:\n            raise Exception(\"Unknown type '%s'\" % asUnicode(t))\n        return w"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef updateDisplayLabel(self, value=None):\n        if value is None:\n            value = self.param.value()\n        opts = self.param.opts\n        if isinstance(self.widget, QtWidgets.QAbstractSpinBox):\n            text = asUnicode(self.widget.lineEdit().text())\n        elif isinstance(self.widget, QtWidgets.QComboBox):\n            text = self.widget.currentText()\n        else:\n            text = asUnicode(value)\n        self.displayLabel.setText(text)", "response": "Update the display label to reflect the value of the parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef widgetValueChanging(self, *args):\n        # This is a bit sketchy: assume the last argument of each signal is\n        # the value..\n        self.param.sigValueChanging.emit(self.param, args[-1])", "response": "Called when the widget s value is changing but not finalized."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef selected(self, sel):\n        ParameterItem.selected(self, sel)\n\n        if self.widget is None:\n            return\n        if sel and self.param.writable():\n            self.showEditor()\n        elif self.hideWidget:\n            self.hideEditor()", "response": "Called when this item has been selected"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef limitsChanged(self, param, limits):\n        ParameterItem.limitsChanged(self, param, limits)\n\n        t = self.param.opts['type']\n        if t == 'int' or t == 'float':\n            self.widget.setOpts(bounds=limits)\n        else:\n            return", "response": "Called when the parameter s limits have changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef treeWidgetChanged(self):\n        ParameterItem.treeWidgetChanged(self)\n\n        # add all widgets for this item into the tree\n        if self.widget is not None:\n            tree = self.treeWidget()\n            if tree is None:\n                return\n            tree.setItemWidget(self, 1, self.layoutWidget)\n            self.displayLabel.hide()\n            self.selected(False)", "response": "Called when this item is added or removed from a tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef optsChanged(self, param, opts):\n        # print \"opts changed:\", opts\n        ParameterItem.optsChanged(self, param, opts)\n        w = self.widget\n        if 'readonly' in opts:\n            self.updateDefaultBtn()\n            if isinstance(w, (QtWidgets.QCheckBox, ColorButton)):\n                w.setEnabled(not opts['readonly'])\n\n        # If widget is a SpinBox, pass options straight through\n        if isinstance(self.widget, SpinBox):\n            if 'units' in opts and 'suffix' not in opts:\n                opts['suffix'] = opts['units']\n            w.setOpts(**opts)\n            self.updateDisplayLabel()", "response": "Called when any options are changed that are not\n        name value default or limits."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when the add new combo is changed", "response": "def addChanged(self):\n        \"\"\"Called when \"add new\" combo is changed\n        The parameter MUST have an 'addNew' method defined.\n        \"\"\"\n        if self.addWidget.currentIndex() == 0:\n            return\n        typ = asUnicode(self.addWidget.currentText())\n        self.param.addNew(typ)\n        self.addWidget.setCurrentIndex(0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zotero_inline_tags(parser, token):\n    \n    args = token.split_contents()\n    length = len(args)\n    if length == 2:\n        rendered_node = RenderedAllNode(args[1])\n    elif length == 3 and args[2].lower() == u'all':\n        rendered_node = RenderedAllNode(args[1])\n    elif length == 3 and args[2].lower() == u'media':\n        rendered_node = RenderedMediaNode(args[1])\n    elif length == 3 and args[2].lower() == u'formset':\n        rendered_node = RenderedFormsetNode(args[1])\n    else:\n        raise t.TemplateSyntaxError('Incorrect arguments in %s.' % args[0])\n    \n    return rendered_node", "response": "Render an inline formset of tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_format(fn, format_bytes=50, verbose=False, *args, **kwargs):\n    assert format_bytes > 0\n    assert verbose in [True, False]\n    \n    with open(fn, 'rb') as f:\n        rough_header = f.read(format_bytes)\n        \n        if re.match(r'.*AmiraMesh.*', rough_header):\n            file_format = \"AmiraMesh\"\n        elif re.match(r'.*HyperSurface.*', rough_header):\n            file_format = \"HyperSurface\"\n        else:\n            file_format = \"Undefined\"\n    \n    if verbose:\n        print >> sys.stderr,  \"{} file detected...\".format(file_format)\n    \n    return file_format", "response": "Detects the format of an Amira file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_header(fn, file_format, header_bytes=20000, verbose=False, *args, **kwargs):\n    assert header_bytes > 0\n    assert file_format in ['AmiraMesh', 'HyperSurface']\n    \n    with open(fn, 'rb') as f:\n        rough_header = f.read(header_bytes)\n        \n        if file_format == \"AmiraMesh\":\n            if verbose:\n                print >> sys.stderr, \"Using pattern: (?P<data>.*)\\\\n@1\"\n            m = re.search(r'(?P<data>.*)\\n@1', rough_header, flags=re.S)\n        elif file_format == \"HyperSurface\":\n            if verbose:\n                print >> sys.stderr, \"Using pattern: (?P<data>.*)\\\\nVertices [0-9]*\\\\n\"\n            m = re.search(r'(?P<data>.*)\\nVertices [0-9]*\\n', rough_header, flags=re.S)\n        elif file_format == \"Undefined\":\n            raise ValueError(\"Unable to parse undefined file\")\n\n    # select the data\n    data = m.group('data')\n#     print data\n#     print\n    \n    return data", "response": "Returns the header as per the file_format"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the data using the grammar specified in this module and return a list of structured metadata", "response": "def parse_header(data, verbose=False, *args, **kwargs):\n    \"\"\"Parse the data using the grammar specified in this module\n    \n    :param str data: delimited data to be parsed for metadata\n    :return list parsed_data: structured metadata \n    \"\"\"\n    # the parser\n    if verbose:\n        print >> sys.stderr, \"Creating parser object...\"\n    parser = Parser(amira_header_grammar)\n    \n    # the processor\n    if verbose:\n        print >> sys.stderr, \"Defining dispatch processor...\"\n    amira_processor = AmiraDispatchProcessor()\n    \n    # parsing\n    if verbose:\n        print >> sys.stderr, \"Parsing data...\"\n    success, parsed_data, next_item = parser.parse(data, production='amira', processor=amira_processor)\n    \n    if success:\n        if verbose:\n            print >> sys.stderr, \"Successfully parsed data...\"\n        return parsed_data\n    else:\n        raise TypeError(\"Parse: {}\\nNext: {}\\n\".format(parsed_data, next_item))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction to get the parsed data from a file name and return a list of structured metadata structures.", "response": "def get_parsed_data(fn, *args, **kwargs):\n    \"\"\"All above functions as a single function\n    \n    :param str fn: file name\n    :return list parsed_data: structured metadata\n    \"\"\"\n    file_format = detect_format(fn, *args, **kwargs)\n    data = get_header(fn, file_format, *args, **kwargs)\n    parsed_data = parse_header(data, *args, **kwargs)\n    return parsed_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_parser():\n\n    parser = ArgumentParser(\n        prog='epubcheck',\n        description=\"EpubCheck v%s - Validate your ebooks\" % __version__\n    )\n\n    # Arguments\n    parser.add_argument(\n        'path',\n        nargs='?',\n        default=getcwd(),\n        help=\"Path to EPUB-file or folder for batch validation. \"\n             \"The current directory will be processed if this argument \"\n             \"is not specified.\"\n    )\n\n    # Options\n    parser.add_argument(\n        '-x', '--xls', nargs='?', type=FileType(mode='wb'),\n        const='epubcheck_report.xls',\n        help='Create a detailed Excel report.'\n    )\n\n    parser.add_argument(\n        '-c', '--csv', nargs='?', type=FileType(mode='wb'),\n        const='epubcheck_report.csv',\n        help='Create a CSV report.'\n    )\n\n    parser.add_argument(\n        '-r', '--recursive', action='store_true',\n        help='Recurse into subfolders.'\n    )\n\n    return parser", "response": "Create a commandline parser for epubcheck"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv=None):\n\n    parser = create_parser()\n    args = parser.parse_args() if argv is None else parser.parse_args(argv)\n\n    if not os.path.exists(args.path):\n        sys.exit(0)\n\n    all_valid = True\n    single = os.path.isfile(args.path)\n    files = [args.path] if single else iter_files(\n        args.path, exts=('epub', ), recursive=args.recursive\n    )\n\n    pool = ThreadPool()\n    results = pool.imap_unordered(EpubCheck, files)\n\n    metas = tablib.Dataset(headers=Checker._fields + Meta._fields)\n    messages = tablib.Dataset(headers=Message._fields)\n\n    for result in results:\n        metas.append(result.checker + result.meta.flatten())\n        if not result.valid:\n            all_valid = False\n        for message in result.messages:\n            messages.append(message)\n            if message.level == 'ERROR':\n                print(message.short, file=sys.stderr)\n            else:\n                print(message.short)\n\n    if args.csv:\n        args.csv.write(messages.export('csv', delimiter=b';'))\n\n    if args.xls:\n        databook = tablib.Databook((metas, messages))\n        args.xls.write(databook.xls)\n\n    if all_valid:\n        return 0\n    else:\n        return 1", "response": "Command line app main function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef A_cylinder(D, L):\n    r'''Returns the surface area of a cylinder.\n\n    .. math::\n        A = \\pi D L + 2\\cdot \\frac{\\pi D^2}{4}\n\n    Parameters\n    ----------\n    D : float\n        Diameter of the cylinder, [m]\n    L : float\n        Length of the cylinder, [m]\n\n    Returns\n    -------\n    A : float\n        Surface area [m]\n\n    Examples\n    --------\n    >>> A_cylinder(0.01, .1)\n    0.0032986722862692833\n    '''\n    cap = pi*D**2/4*2\n    side = pi*D*L\n    A = cap + side\n    return A", "response": "r Returns the surface area of a cylinder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef V_multiple_hole_cylinder(Do, L, holes):\n    r'''Returns the solid volume of a cylinder with multiple cylindrical holes.\n    Calculation will naively return a negative value or other impossible\n    result if the number of cylinders added is physically impossible.\n\n    .. math::\n        V = \\frac{\\pi D_o^2}{4}L - L\\frac{\\pi D_i^2}{4}\n\n    Parameters\n    ----------\n    Do : float\n        Diameter of the exterior of the cylinder, [m]\n    L : float\n        Length of the cylinder, [m]\n    holes : list\n        List of tuples containing (diameter, count) pairs of descriptions for\n        each of the holes sizes.\n\n    Returns\n    -------\n    V : float\n        Volume [m^3]\n\n    Examples\n    --------\n    >>> V_multiple_hole_cylinder(0.01, 0.1, [(0.005, 1)])\n    5.890486225480862e-06\n    '''\n    V = pi*Do**2/4*L\n    for Di, n in holes:\n        V -= pi*Di**2/4*L*n\n    return V", "response": "r Returns the solid volume of a cylinder with multiple cylindrical holes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef urlencode_no_plus(query, doseq=0):\n\n    if hasattr(query,\"items\"):\n        # mapping objects\n        query = query.items()\n    else:\n        # it's a bother at times that strings and string-like objects are\n        # sequences...\n        try:\n            # non-sequence items should not work with len()\n            # non-empty strings will fail this\n            if len(query) and not isinstance(query[0], tuple):\n                raise TypeError\n            # zero-length sequences of all types will get here and succeed,\n            # but that's a minor nit - since the original implementation\n            # allowed empty dicts that type of behavior probably should be\n            # preserved for consistency\n        except TypeError:\n            ty,va,tb = sys.exc_info()\n            raise TypeError, \"not a valid non-string sequence or mapping object\", tb\n\n    l = []\n    if not doseq:\n        # preserve old behavior\n        for k, v in query:\n            k = urllib.quote(str(k))\n            v = urllib.quote(str(v))\n            l.append(k + '=' + v)\n    else:\n        for k, v in query:\n            k = urllib.quote(str(k))\n            if isinstance(v, str):\n                v = urllib.quote(v)\n                l.append(k + '=' + v)\n            elif _is_unicode(v):\n                # is there a reasonable way to convert to ASCII?\n                # encode generates a string, but \"replace\" or \"ignore\"\n                # lose information and \"strict\" can raise UnicodeError\n                v = urllib.quote(v.encode(\"ASCII\",\"replace\"))\n                l.append(k + '=' + v)\n            else:\n                try:\n                    # is this a sufficient test for sequence-ness?\n                    len(v)\n                except TypeError:\n                    # not a sequence\n                    v = urllib.quote(str(v))\n                    l.append(k + '=' + v)\n                else:\n                    # loop over the sequence\n                    for elt in v:\n                        l.append(k + '=' + urllib.quote(str(elt)))\n    return '&'.join(l)", "response": "Encode a sequence of two - element tuples or dictionary into a URL query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pmxbot_excuse(self, rest):\n        \"Provide a convenient excuse\"\n        args = rest.split(' ')[:2]\n        parser = argparse.ArgumentParser()\n        parser.add_argument('word', nargs=\"?\")\n        parser.add_argument('index', type=int, nargs=\"?\")\n        args = parser.parse_args(args)\n        if not args.word:\n            return self.get()\n        return self.find(args.word, args.index)", "response": "Provide a convenient excuse"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_with_scipy(file, data_name):\n    import scipy.io\n\n    \"\"\"\n    Loads data from a netcdf file.\n\n    Parameters\n    ----------\n    file : string or file-like\n        The name of the netcdf file to open.\n    data_name : string\n        The name of the data to extract from the netcdf file.\n\n    Returns\n    -------\n    data : ndarray\n        The desired data from the netcdf file as ndarray with nan for missing values.\n    \"\"\"\n\n    logger.debug('Loading data {} of netcdf file {} with scipy.io.'.format(data_name, file))\n\n    f = scipy.io.netcdf.netcdf_file(file, 'r')\n    data_netcdf = f.variables[data_name]\n    data = np.array(data_netcdf.data, copy = True)\n    data[data == data_netcdf.missing_value] = np.nan\n    f.close()\n\n    return data", "response": "Loads data from a netcdf file with scipy. io."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cholesky(A, ordering_method='default', return_type=RETURN_P_L, use_long=False):\n    '''\n    P A P' = L L'\n    '''\n    logger.debug('Calculating cholesky decomposition for matrix {!r} with ordering method {}, return type {} and use_long {}.'.format(A, ordering_method, return_type, use_long))\n\n    ## check input\n    return_types = (RETURN_L, RETURN_L_D, RETURN_P_L, RETURN_P_L_D)\n    if ordering_method not in CHOLMOD_ORDERING_METHODS:\n        raise ValueError('Unknown ordering method {}. Only values in {} are supported.'.format(ordering_method, CHOLMOD_ORDERING_METHODS))\n    if return_type not in return_types:\n        raise ValueError('Unknown return type {}. Only values in {} are supported.'.format(return_type, return_types))\n        if ordering_method != 'natural' and return_type in (RETURN_L, RETURN_L_D):\n            raise ValueError('Return type {} is only supported for \"natural\" ordering method.'.format(return_type))\n\n    #TODO symmetry check\n    A = util.math.sparse.check.sorted_squared_csc(A)\n\n    ## calculate cholesky decomposition\n    try:\n        try:\n            f = sksparse.cholmod.cholesky(A, ordering_method=ordering_method, use_long=use_long)\n        except sksparse.cholmod.CholmodTooLargeError as e:\n            if not use_long:\n                warnings.warn('Problem to large for int, switching to long.')\n                return cholesky(A, ordering_method=ordering_method, return_type=return_type, use_long=True)\n            else:\n                raise\n    except sksparse.cholmod.CholmodNotPositiveDefiniteError as e:\n        raise util.math.matrix.NoPositiveDefiniteMatrixError(A, 'Row/column {} makes matrix not positive definite.'.format(e.column))\n    del A\n\n    ## calculate permutation matrix\n    p = f.P()\n    n = len(p)\n    if return_type in (RETURN_P_L, RETURN_P_L_D):\n        P = scipy.sparse.dok_matrix((n,n), dtype=np.int8)\n        for i in range(n):\n            P[i,p[i]] = 1\n        P = P.tocsr()\n        P.astype(np.int8)\n\n    ## return P, L\n    if return_type in (RETURN_L, RETURN_P_L):\n        L = f.L().tocsr()\n        if return_type == RETURN_L:\n            assert np.all(p == np.arange(n))\n            logger.debug('Returning lower triangular matrix {!r}.'.format(L))\n            return (L,)\n        else:\n            logger.debug('Returning permutation matrix {!r} and lower triangular matrix {!r}.'.format(P, L))\n            return (P, L)\n\n    ## return P, L, D\n    if return_type in (RETURN_L_D, RETURN_P_L_D):\n        L, D = f.L_D()\n        # Do not use f.L_D() -> higher memory consumption\n        # LD = f.LD()\n        if return_type == RETURN_L_D:\n            logger.debug('Returning lower triangular matrix {!r} and diagonal matrix {!r}.'.format(P, L, D))\n            return (L, D)\n        else:\n            logger.debug('Returning permutation matrix {!r}, lower triangular matrix {!r} and diagonal matrix {!r}.'.format(P, L, D))\n            return (P, L, D)", "response": "Calculates the Cholesky decomposition of a matrix A."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _connect_database(config):\n    settings = config.registry.settings\n\n    mongo_uri = \"mongodb://localhost:27017\"\n    mongodb_name = \"test\"\n\n    if settings.get(\"mongo_url\"):\n        mongo_uri = settings[\"mongo_url\"]\n\n    if settings.get(\"mongodb_name\"):\n        mongodb_name = settings[\"mongodb_name\"]\n\n    return mongoengine.connect(mongodb_name, host=mongo_uri)", "response": "Create a connection with Mongodb"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the DynamicContent instance for the given identifier.", "response": "def get_content(identifier, default=None):\n    '''\n    Returns the DynamicContent instance for the given identifier.\n\n    If no object is found, a new one will be created.\n\n    :param identifier: String representing the unique identifier of a\n      ``DynamicContent`` object.\n    :param default: String that should be used in case that no matching\n      ``DynamicContent`` object exists.\n\n    '''\n    if default is None:\n        default = ''\n\n    try:\n        return models.DynamicContent.objects.get(identifier=identifier)\n    except models.DynamicContent.DoesNotExist:\n        return models.DynamicContent.objects.create(\n            identifier=identifier, content=default)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a value to a jsonable type.", "response": "def to_json(value):\n    \"\"\"\n    Converts a value to a jsonable type.\n    \"\"\"\n    if type(value) in JSON_TYPES:\n        return value\n    elif hasattr(value, \"to_json\"):\n        return value.to_json()\n    elif isinstance(value, list) or isinstance(value, set) or \\\n            isinstance(value, deque) or isinstance(value, tuple):\n        return [to_json(v) for v in value]\n    elif isinstance(value, dict):\n        return {str(k): to_json(v) for k, v in value.items()}\n    else:\n        raise TypeError(\"{0} is not json serializable.\".format(type(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the pid of the lock.", "response": "def lock_pid(self):\n        \"\"\"\n        Get the pid of the lock.\n        \"\"\"\n        \n        if os.path.exists(self.lock_filename):\n            return int(open(self.lock_filename).read())\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_locked_by_me(self):\n        \n        ## get pid of lock\n        lock_pid = self.lock_pid()\n\n        ## not locked\n        if lock_pid is None:\n            logger.debug('Lock {} is not aquired.'.format(self.lock_filename))\n            return False\n        \n        ## locked by me\n        if self.pid == lock_pid:\n            logger.debug('Lock {} is aquired by me (pid: {}).'.format(self.lock_filename, self.pid))\n            return True\n\n        ## locked by alive process\n        try:\n            os.kill(lock_pid, 0)\n            logger.debug('Lock {} is aquired by another (alive) process (pid: {}).'.format(self.lock_filename, lock_pid))\n        \n        ## locked by dead process\n        except OSError:\n            logger.debug('Lock {} is aquired by a dead process (pid: {}).'.format(self.lock_filename, lock_pid))\n            try:\n                lock_fd = os.open(self.lock_filename, os.O_RDWR)\n            except FileNotFoundError:\n                logger.debug('The lock is now removed by another process.')\n            else:\n                try:\n                    fcntl.lockf(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)\n                except BlockingIOError:\n                    logger.debug('The lock will be removed by another process.')\n                else:\n                    if self.lock_pid() == lock_pid:\n                        os.remove(self.lock_filename)\n                        fcntl.lockf(lock_fd, fcntl.LOCK_UN)\n                        logger.debug('The lock is removed by me.')\n                    else:\n                        logger.debug('The lock is substituted by another lock.')\n                os.close(lock_fd)\n        return False", "response": "Check if the lock exists and is aquired by me."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to get the lock once.", "response": "def acquire_try_once(self):\n        \"\"\"\n        Try to aquire the lock once.\n        \"\"\"\n        \n        if self.is_locked_by_me():\n            return True\n        else:\n            try:\n                self.fd = os.open(self.lock_filename, os.O_CREAT | os.O_RDWR | os.O_EXCL)\n            except FileExistsError:\n                logger.debug('I tried to get the lock {}, but another process was faster.'.format(self.lock_filename))\n                return False\n            else:\n                os.write(self.fd, str(self.pid).encode('utf-8'))\n                logger.debug('I got the lock {}.'.format(self.lock_filename))\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef acquire(self):\n        \n        if self.timeout is not None:\n            sleep_intervals = int(self.timeout / self.sleep_time)\n        else:\n            sleep_intervals = float('inf')\n        \n        while not self.acquire_try_once() and sleep_intervals > 0:\n            time.sleep(self.sleep_time)\n            sleep_intervals -= 1\n        \n        if not self.is_locked_by_me():\n            raise util.io.filelock.general.FileLockTimeoutError(self.lock_filename, self.timeout)", "response": "Try to acquire the lock."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_scree_plot(in_filename, out_filename, plot_title):\n    # Constructing the arguments\n    scree_plot_args = (\"--evec\", in_filename, \"--out\", out_filename,\n                       \"--scree-plot-title\", plot_title)\n    try:\n        # Executing the main method\n        PlotEigenvalues.main(argString=scree_plot_args)\n\n    except PlotEigenvalues.ProgramError as e:\n        msg = \"PlotEigenvalues: {}\".format(e)\n        raise ProgramError(msg)", "response": "Creates a scree plot using smartpca results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_eigenvalues(in_prefix, out_prefix):\n    # First, we create the parameter file\n    with open(out_prefix + \".parameters\", \"w\") as o_file:\n        print >>o_file, \"genotypename:    \" + in_prefix + \".bed\"\n        print >>o_file, \"snpname:         \" + in_prefix + \".bim\"\n        print >>o_file, \"indivname:       \" + in_prefix + \".fam\"\n        print >>o_file, \"evecoutname:     \" + out_prefix + \".evec.txt\"\n        print >>o_file, \"evaloutname:     \" + out_prefix + \".eval.txt\"\n        print >>o_file, \"numoutlieriter:  0\"\n        print >>o_file, \"altnormstyle:    NO\"\n\n    # Executing smartpca\n    command = [\"smartpca\", \"-p\", out_prefix + \".parameters\"]\n    runCommand(command)", "response": "Compute the Eigenvalues using smartpca."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_the_outliers(mds_file_name, population_file_name, ref_pop_name,\n                      multiplier, out_prefix):\n    \"\"\"Finds the outliers of a given population.\n\n    :param mds_file_name: the name of the ``mds`` file.\n    :param population_file_name: the name of the population file.\n    :param ref_pop_name: the name of the reference population for which to find\n                         outliers from.\n    :param multiplier: the multiplier of the cluster standard deviation to\n                       modify the strictness of the outlier removal procedure.\n    :param out_prefix: the prefix of the output file.\n\n    :type mds_file_name: str\n    :type population_file_name: str\n    :type ref_pop_name: str\n    :type multiplier: float\n    :type out_prefix: str\n\n    Uses the :py:mod:`pyGenClean.Ethnicity.find_outliers` modules to find\n    outliers. It requires the ``mds`` file created by :py:func:`createMDSFile`\n    and the population file created by :py:func:`createPopulationFile`.\n\n    \"\"\"\n    options = [\"--mds\", mds_file_name, \"--population-file\",\n               population_file_name, \"--outliers-of\", ref_pop_name,\n               \"--multiplier\", str(multiplier), \"--out\", out_prefix]\n\n    try:\n        find_outliers.main(options)\n    except find_outliers.ProgramError as e:\n        msg = \"find_outliers: {}\".format(e)\n        raise ProgramError(msg)", "response": "This function finds the outliers of a given population."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a population file from the input files and labels.", "response": "def createPopulationFile(inputFiles, labels, outputFileName):\n    \"\"\"Creates a population file.\n\n    :param inputFiles: the list of input files.\n    :param labels: the list of labels (corresponding to the input files).\n    :param outputFileName: the name of the output file.\n\n    :type inputFiles: list\n    :type labels: list\n    :type outputFileName: str\n\n    The ``inputFiles`` is in reality a list of ``tfam`` files composed of\n    samples. For each of those ``tfam`` files, there is a label associated with\n    it (representing the name of the population).\n\n    The output file consists of one row per sample, with the following three\n    columns: the family ID, the individual ID and the population of each\n    sample.\n\n    \"\"\"\n    outputFile = None\n    try:\n        outputFile = open(outputFileName, 'w')\n    except IOError:\n        msg = \"%(outputFileName)s: can't write file\"\n        raise ProgramError(msg)\n\n    for i in xrange(len(inputFiles)):\n        # For each file\n        fileName = inputFiles[i]\n        label = labels[i]\n\n        try:\n            with open(fileName, 'r') as inputFile:\n                for line in inputFile:\n                    row = line.rstrip(\"\\r\\n\").split(\" \")\n\n                    # Getting the informations\n                    famID = row[0]\n                    indID = row[1]\n\n                    # Printing to file\n                    print >>outputFile, \"\\t\".join([famID, indID, label])\n        except IOError:\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Closing the output file\n    outputFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the MDS value.", "response": "def plotMDS(inputFileName, outPrefix, populationFileName, options):\n    \"\"\"Plots the MDS value.\n\n    :param inputFileName: the name of the ``mds`` file.\n    :param outPrefix: the prefix of the output files.\n    :param populationFileName: the name of the population file.\n    :param options: the options\n\n    :type inputFileName: str\n    :type outPrefix: str\n    :type populationFileName: str\n    :type options: argparse.Namespace\n\n    Plots the ``mds`` value according to the ``inputFileName`` file (``mds``)\n    and the ``populationFileName`` (the population file).\n\n    \"\"\"\n    # The options\n    plotMDS_options = Dummy()\n    plotMDS_options.file = inputFileName\n    plotMDS_options.out = outPrefix\n    plotMDS_options.format = options.format\n    plotMDS_options.title = options.title\n    plotMDS_options.xlabel = options.xlabel\n    plotMDS_options.ylabel = options.ylabel\n    plotMDS_options.population_file = populationFileName\n\n    try:\n        # Checking the options\n        PlotMDS.checkArgs(plotMDS_options)\n\n        # Reading the population file\n        populations = PlotMDS.readPopulations(plotMDS_options.population_file)\n\n        # Getting the data\n        data, labels = PlotMDS.extractData(plotMDS_options.file, populations)\n        order = [labels.index(\"CEU\"), labels.index(\"YRI\"),\n                 labels.index(\"JPT-CHB\"), labels.index(\"SOURCE\")]\n        if \"HIGHLIGHT\" in labels:\n            order.append(labels.index(\"HIGHLIGHT\"))\n        color = [(0.215686275, 0.000494118, 0.721568627),\n                 (0.301960784, 0.68627451, 0.290196078),\n                 (0.596078431, 0.305882353, 0.639215686),\n                 (0.894117647, 0.101960784, 0.109803922),\n                 (0.596078431, 0.305882353, 0.639215686)]\n        sizes = [12, 12, 12, 8, 12]\n        markers = [\".\", \".\", \".\", \"+\", \"D\"]\n\n        # Plotting the data\n        PlotMDS.plotMDS(data, order, labels, color, sizes, markers,\n                        plotMDS_options)\n\n    except PlotMDS.ProgramError as e:\n        msg = \"PlotMDS: %s\" % e\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a MDS file using Plink.", "response": "def createMDSFile(nb_components, inPrefix, outPrefix, genomeFileName):\n    \"\"\"Creates a MDS file using Plink.\n\n    :param nb_components: the number of component.\n    :param inPrefix: the prefix of the input file.\n    :param outPrefix: the prefix of the output file.\n    :param genomeFileName: the name of the ``genome`` file.\n\n    :type nb_components: int\n    :type inPrefix: str\n    :type outPrefix: str\n    :type genomeFileName: str\n\n    Using Plink, computes the MDS values for each individual using the\n    ``inPrefix``, ``genomeFileName`` and the number of components. The results\n    are save using the ``outPrefix`` prefix.\n\n    \"\"\"\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", inPrefix, \"--read-genome\",\n                    genomeFileName, \"--cluster\", \"--mds-plot\",\n                    str(nb_components), \"--out\", outPrefix]\n    runCommand(plinkCommand)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the relatedness step of the data clean up.", "response": "def runRelatedness(inputPrefix, outPrefix, options):\n    \"\"\"Run the relatedness step of the data clean up.\n\n    :param inputPrefix: the prefix of the input file.\n    :param outPrefix: the prefix of the output file.\n    :param options: the options\n\n    :type inputPrefix: str\n    :type outPrefix: str\n    :type options: argparse.Namespace\n\n    :returns: the prefix of the new bfile.\n\n    Runs :py:mod:`pyGenClean.RelatedSamples.find_related_samples` using the\n    ``inputPrefix`` files and ``options`` options, and saves the results using\n    the ``outPrefix`` prefix.\n\n    \"\"\"\n    # The options\n    new_options = [\"--bfile\", inputPrefix, \"--genome-only\",\n                   \"--min-nb-snp\", str(options.min_nb_snp),\n                   \"--maf\", options.maf,\n                   \"--out\", \"{}.ibs\".format(outPrefix)]\n    new_options += [\"--indep-pairwise\"] + options.indep_pairwise\n    if options.sge:\n        new_options.append(\"--sge\")\n        new_options += [\"--line-per-file-for-sge\",\n                        str(options.line_per_file_for_sge)]\n        if options.ibs_sge_walltime is not None:\n            new_options += [\"--sge-walltime\", options.ibs_sge_walltime]\n        if options.ibs_sge_nodes is not None:\n            new_options += [\"--sge-nodes\"] + map(str, options.ibs_sge_nodes)\n\n    # Checking the input file\n    if not allFileExists([inputPrefix + i for i in [\".bed\", \".bim\", \".fam\"]]):\n        msg = \"{}: not a valid binary prefix\".format(inputPrefix)\n        raise ProgramError(msg)\n\n    newBfile = None\n    try:\n        newBfile = Relatedness.main(new_options)\n    except Relatedness.ProgramError as e:\n        msg = \"compute genome: {}\".format(e)\n        raise ProgramError(msg)\n\n    return newBfile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that all files in the list of files exists.", "response": "def allFileExists(fileList):\n    \"\"\"Check that all file exists.\n\n    :param fileList: the list of file to check.\n\n    :type fileList: list\n\n    Check if all the files in ``fileList`` exists.\n\n    \"\"\"\n    allExists = True\n    for fileName in fileList:\n        allExists = allExists and os.path.isfile(fileName)\n    return allExists"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexcluding some SNPs from inPrefix and save them to outPrefix.", "response": "def excludeSNPs(inPrefix, outPrefix, exclusionFileName):\n    \"\"\"Exclude some SNPs using Plink.\n\n    :param inPrefix: the prefix of the input file.\n    :param outPrefix: the prefix of the output file.\n    :param exclusionFileName: the name of the file containing the markers to be\n                              excluded.\n\n    :type inPrefix: str\n    :type outPrefix: str\n    :type exclusionFileName: str\n\n    Using Plink, exclude a list of markers from ``inPrefix``, and saves the\n    results in ``outPrefix``. The list of markers are in ``exclusionFileName``.\n\n    \"\"\"\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", inPrefix, \"--exclude\",\n                    exclusionFileName, \"--make-bed\", \"--out\", outPrefix]\n    runCommand(plinkCommand)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind flipped SNPs and flip them in the data set.", "response": "def findFlippedSNPs(frqFile1, frqFile2, outPrefix):\n    \"\"\"Find flipped SNPs and flip them in the data.\n\n    :param frqFile1: the name of the first frequency file.\n    :param frqFile2: the name of the second frequency file.\n    :param outPrefix: the prefix of the output files.\n\n    :type frqFile1: str\n    :type frqFile2: str\n    :type outPrefix: str\n\n    By reading two frequency files (``frqFile1`` and ``frqFile2``), it finds a\n    list of markers that need to be flipped so that the first file becomes\n    comparable with the second one. Also finds marker that need to be removed.\n\n    A marker needs to be flipped in one of the two data set if the two markers\n    are not comparable (same minor allele), but become comparable if we flip\n    one of them.\n\n    A marker will be removed if it is all homozygous in at least one data set.\n    It will also be removed if it's impossible to determine the phase of the\n    marker (*e.g.* if the two alleles are ``A`` and ``T`` or ``C`` and ``G``).\n\n    \"\"\"\n    allelesFiles = [{}, {}]\n    files = [frqFile1, frqFile2]\n    for k, fileName in enumerate(files):\n        try:\n            with open(fileName, \"r\") as inputFile:\n                headerIndex = None\n                for i, line in enumerate(inputFile):\n                    row = createRowFromPlinkSpacedOutput(line)\n\n                    if i == 0:\n                        # This is the header\n                        headerIndex = dict([\n                            (row[j], j) for j in xrange(len(row))\n                        ])\n\n                        # Checking the columns\n                        for columnName in [\"SNP\", \"A1\", \"A2\"]:\n                            if columnName not in headerIndex:\n                                msg = \"%(fileName)s: no column named \" \\\n                                      \"%(columnName)s\" % locals()\n                                raise ProgramError(msg)\n                    else:\n                        snpName = row[headerIndex[\"SNP\"]]\n                        allele1 = row[headerIndex[\"A1\"]]\n                        allele2 = row[headerIndex[\"A2\"]]\n\n                        alleles = set([allele1, allele2])\n                        if \"0\" in alleles:\n                            alleles.remove(\"0\")\n\n                        allelesFiles[k][snpName] = alleles\n        except IOError:\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    allelesFile1, allelesFile2 = allelesFiles\n\n    # Finding the SNPs to flip\n    toFlipOutputFile = None\n    try:\n        toFlipOutputFile = open(outPrefix + \".snp_to_flip_in_reference\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.snp_to_flip_in_reference: can't write \" \\\n              \"file\" % locals()\n        raise ProgramError(msg)\n\n    toRemoveOutputFile = None\n    try:\n        toRemoveOutputFile = open(outPrefix + \".snp_to_remove\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.snp_to_remove: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    for snpName in allelesFile1.iterkeys():\n        alleles1 = allelesFile1[snpName]\n        alleles2 = allelesFile2[snpName]\n\n        if (len(alleles1) == 2) and (len(alleles2) == 2):\n            # Both are heterozygous\n            if ({\"A\", \"T\"} == alleles1) or ({\"C\", \"G\"} == alleles1) or \\\n                    ({\"A\", \"T\"} == alleles2) or ({\"C\", \"G\"} == alleles2):\n                # We can't flip those..., so we remove them\n                print >>toRemoveOutputFile, snpName\n            else:\n                if alleles1 != alleles2:\n                    # Let's try the flip one\n                    if flipGenotype(alleles1) == alleles2:\n                        # We need to flip it\n                        print >>toFlipOutputFile, snpName\n                    else:\n                        # Those SNP are discordant...\n                        print >>toRemoveOutputFile, snpName\n        else:\n            # We want to remove this SNP, because there is at least one\n            # homozygous individual\n            print >>toRemoveOutputFile, snpName\n\n    # Closing output files\n    toFlipOutputFile.close()\n    toRemoveOutputFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncombines Plink binary files.", "response": "def combinePlinkBinaryFiles(prefixes, outPrefix):\n    \"\"\"Combine Plink binary files.\n\n    :param prefixes: a list of the prefix of the files that need to be\n                     combined.\n    :param outPrefix: the prefix of the output file (the combined file).\n\n    :type prefixes: list\n    :type outPrefix: str\n\n    It uses Plink to merge a list of binary files (which is a list of prefixes\n    (strings)), and create the final data set which as ``outPrefix`` as the\n    prefix.\n\n    \"\"\"\n    # The first file is the bfile, the others are the ones to merge\n    outputFile = None\n    try:\n        outputFile = open(outPrefix + \".files_to_merge\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.filesToMerge: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    for prefix in prefixes[1:]:\n        print >>outputFile, \" \".join([\n            prefix + i for i in [\".bed\", \".bim\", \".fam\"]\n        ])\n\n    # Closing the output files\n    outputFile.close()\n\n    # Runing plink\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", prefixes[0],\n                    \"--merge-list\", outPrefix + \".files_to_merge\",\n                    \"--make-bed\", \"--out\", outPrefix]\n    runCommand(plinkCommand)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the overlapping SNPs in 4 different data sets. :param prefix: the prefix of all the files. :param referencePrefixes: the prefix of the reference population files. :param referencePopulations: the name of the reference population (same order as ``referencePrefixes``) :param outPrefix: the prefix of the output files. :type prefix: str :type referencePrefixes: list :type referencePopulations: list :type outPrefix: str It starts by reading the ``bim`` file of the source data set (``prefix.bim``). It finds all the markers (excluding the duplicated ones). Then it reads all of the reference population ``bim`` files (``referencePrefixes.bim``) and find all the markers that were found in the source data set. It creates three output files: * ``outPrefix.ref_snp_to_extract``: the name of the markers that needs to be extracted from the three reference panels. * ``outPrefix.source_snp_to_extract``: the name of the markers that needs to be extracted from the source panel. * ``outPrefix.update_names``: a file (readable by Plink) that will help in changing the names of the selected markers in the reference panels, so that they become comparable with the source panel.", "response": "def findOverlappingSNPsWithReference(prefix, referencePrefixes,\n                                     referencePopulations, outPrefix):\n    \"\"\"Find the overlapping SNPs in 4 different data sets.\n\n    :param prefix: the prefix of all the files.\n    :param referencePrefixes: the prefix of the reference population files.\n    :param referencePopulations: the name of the reference population (same\n                                 order as ``referencePrefixes``)\n    :param outPrefix: the prefix of the output files.\n\n    :type prefix: str\n    :type referencePrefixes: list\n    :type referencePopulations: list\n    :type outPrefix: str\n\n    It starts by reading the ``bim`` file of the source data set\n    (``prefix.bim``). It finds all the markers (excluding the duplicated ones).\n    Then it reads all of the reference population ``bim`` files\n    (``referencePrefixes.bim``) and find all the markers that were found in the\n    source data set.\n\n    It creates three output files:\n\n    * ``outPrefix.ref_snp_to_extract``: the name of the markers that needs to\n      be extracted from the three reference panels.\n    * ``outPrefix.source_snp_to_extract``: the name of the markers that needs\n      to be extracted from the source panel.\n    * ``outPrefix.update_names``: a file (readable by Plink) that will help in\n      changing the names of the selected markers in the reference panels, so\n      that they become comparable with the source panel.\n\n    \"\"\"\n    # Reading the main file\n    sourceSnpToExtract = {}\n    duplicates = set()\n    try:\n        with open(prefix + \".bim\", \"r\") as inputFile:\n            for line in inputFile:\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                chromosome = row[0]\n                position = row[3]\n                snpName = row[1]\n\n                if (chromosome, position) not in sourceSnpToExtract:\n                    sourceSnpToExtract[(chromosome, position)] = snpName\n                else:\n                    # It's a duplicate\n                    duplicates.add((chromosome, position))\n    except IOError:\n        msg = \"%s.bim: no such file\" % prefix\n        raise ProgramError(msg)\n\n    # Removing duplicates from the list\n    for snpID in duplicates:\n        del sourceSnpToExtract[snpID]\n\n    # Reading each of the reference markers\n    refSnpToExtract = defaultdict(dict)\n    refSnp = defaultdict(set)\n    for refPop, refPrefix in izip(referencePopulations, referencePrefixes):\n        try:\n            with open(refPrefix + \".bim\", \"r\") as inputFile:\n                for line in inputFile:\n                    row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                    chromosome = row[0]\n                    position = row[3]\n                    snpName = row[1]\n\n                    key = (chromosome, position)\n                    if key in sourceSnpToExtract:\n                        # We want this SNP\n                        refSnpToExtract[refPop][key] = snpName\n                        refSnp[refPop].add(key)\n                logger.info(\"  - {:,d} overlaps with {}\".format(\n                    len(refSnp[refPop]),\n                    refPrefix,\n                ))\n\n        except IOError:\n            msg = \"%(refPrefix)s.bim: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Creating the intersect of the reference SNP\n    refSnpIntersect = refSnp[referencePopulations[0]]\n    for refPop in referencePopulations[1:]:\n        refSnpIntersect &= refSnp[refPop]\n    logger.info(\"  - {:,d} in common between reference \"\n                \"panels\".format(len(refSnpIntersect)))\n\n    # Printing the names of the SNPs to extract in the reference\n    refOutputFiles = {}\n    try:\n        for refPop in referencePopulations:\n            refOutputFiles[refPop] = open(\n                outPrefix + \".{}_snp_to_extract\".format(refPop),\n                mode=\"w\",\n            )\n    except IOError:\n        msg = \"{}.POP_snp_to_extract: can't write file\".format(outPrefix)\n        raise ProgramError(msg)\n\n    sourceOutputFile = None\n    try:\n        sourceOutputFile = open(outPrefix + \".source_snp_to_extract\", \"w\")\n    except IOError:\n        msg = \"{}.source_snp_to_extract: can't write file\".format(outPrefix)\n        raise ProgramError(msg)\n\n    changeNameOutputFiles = {}\n    try:\n        for refPop in referencePopulations:\n            changeNameOutputFiles[refPop] = open(\n                outPrefix + \".{}_update_names\".format(refPop),\n                mode=\"w\",\n            )\n    except IOError:\n        msg = \"%(outPrefix)s.updateNames: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    # Writing the file containing the SNPs to extract in the source\n    for snpID in refSnpIntersect:\n        print >>sourceOutputFile, sourceSnpToExtract[snpID]\n        for refPop in referencePopulations:\n            print >>refOutputFiles[refPop], refSnpToExtract[refPop][snpID]\n            print >>changeNameOutputFiles[refPop], \"\\t\".join([\n                refSnpToExtract[refPop][snpID],\n                sourceSnpToExtract[snpID],\n            ])\n\n    # Closing the output file\n    sourceOutputFile.close()\n    for refOutputFile in refOutputFiles.itervalues():\n        refOutputFile.close()\n    for changeNameOutputFile in changeNameOutputFiles.itervalues():\n        changeNameOutputFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting a list of SNPs using Plink. :param snpToExtractFileNames: the name of the files which contains the markers to extract from the original data set. :param referencePrefixes: a list containing the three reference population prefixes (the original data sets). :param popNames: a list containing the three reference population names. :param outPrefix: the prefix of the output file. :param runSGE: Whether using SGE or not. :param options: the options. :type snpToExtractFileNames: list :type referencePrefixes: list :type popNames: list :type outPrefix: str :type runSGE: boolean :type options: argparse.Namespace Using Plink, extract a set of markers from a list of prefixes.", "response": "def extractSNPs(snpToExtractFileNames, referencePrefixes, popNames, outPrefix,\n                runSGE, options):\n    \"\"\"Extract a list of SNPs using Plink.\n\n    :param snpToExtractFileNames: the name of the files which contains the\n                                  markers to extract from the original data\n                                  set.\n    :param referencePrefixes: a list containing the three reference population\n                              prefixes (the original data sets).\n    :param popNames: a list containing the three reference population names.\n    :param outPrefix: the prefix of the output file.\n    :param runSGE: Whether using SGE or not.\n    :param options: the options.\n\n    :type snpToExtractFileNames: list\n    :type referencePrefixes: list\n    :type popNames: list\n    :type outPrefix: str\n    :type runSGE: boolean\n    :type options: argparse.Namespace\n\n    Using Plink, extract a set of markers from a list of prefixes.\n\n    \"\"\"\n    s = None\n    jobIDs = []\n    jobTemplates = []\n    if runSGE:\n        # Add the environment variable for DRMAA package\n        if \"DRMAA_LIBRARY_PATH\" not in os.environ:\n            msg = \"could not load drmaa: set DRMAA_LIBRARY_PATH\"\n            raise ProgramError(msg)\n\n        # Import the python drmaa library\n        try:\n            import drmaa\n        except ImportError:\n            raise ProgramError(\"drmaa is not install, install drmaa\")\n\n        # Initializing a session\n        s = drmaa.Session()\n        s.initialize()\n\n    zipped = izip(popNames, referencePrefixes, snpToExtractFileNames)\n    for popName, refPrefix, snpToExtractFileName in zipped:\n        plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", refPrefix, \"--extract\",\n                        snpToExtractFileName, \"--make-bed\", \"--out\",\n                        outPrefix + \".\" + popName]\n\n        if runSGE:\n            # We run using SGE\n            # Creating the job template\n            jt = s.createJobTemplate()\n            jt.remoteCommand = plinkCommand[0]\n            jt.workingDirectory = os.getcwd()\n            jt.jobEnvironment = os.environ\n            jt.args = plinkCommand[1:]\n            jt.jobName = \"_plink_extract_snps\"\n\n            # Cluster specifics\n            if options.sge_walltime is not None:\n                jt.hardWallclockTimeLimit = options.sge_walltime\n            if options.sge_nodes is not None:\n                native_spec = \"-l nodes={}:ppn={}\".format(options.sge_nodes[0],\n                                                          options.sge_nodes[1])\n                jt.nativeSpecification = native_spec\n\n            # Running the job\n            jobID = s.runJob(jt)\n\n            # Storing the job template and the job ID\n            jobTemplates.append(jt)\n            jobIDs.append(jobID)\n\n        else:\n            # We run normal\n            runCommand(plinkCommand)\n\n    if runSGE:\n        # We wait for all the jobs to be over\n        hadProblems = []\n        for jobID in jobIDs:\n            retVal = s.wait(jobID, drmaa.Session.TIMEOUT_WAIT_FOREVER)\n            hadProblems.append(retVal.exitStatus == 0)\n\n        # The jobs should be finished, so we clean everything\n        # Deleting the job template, and exiting the session\n        for jt in jobTemplates:\n            s.deleteJobTemplate(jt)\n\n        # Closing the connection\n        s.exit()\n\n        for hadProblem in hadProblems:\n            if not hadProblem:\n                msg = \"Some SGE jobs had errors...\"\n                raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a command. :param command: the command to run. :type command: list Tries to run a command. If it fails, raise a :py:class:`ProgramError`. This function uses the :py:mod:`subprocess` module. .. warning:: The variable ``command`` should be a list of strings (no other type).", "response": "def runCommand(command):\n    \"\"\"Run a command.\n\n    :param command: the command to run.\n\n    :type command: list\n\n    Tries to run a command. If it fails, raise a :py:class:`ProgramError`. This\n    function uses the :py:mod:`subprocess` module.\n\n    .. warning::\n        The variable ``command`` should be a list of strings (no other type).\n\n    \"\"\"\n    output = None\n    try:\n        output = subprocess.check_output(\n            command,\n            stderr=subprocess.STDOUT,\n            shell=False,\n        )\n    except subprocess.CalledProcessError:\n        msg = \"couldn't run command\\n\" + \" \".join(command)\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkArgs(args):\n    # Check if we have the tped and the tfam files\n    prefixes_to_check = [args.bfile]\n    if not args.skip_ref_pops:\n        for pop in (\"ceu\", \"yri\", \"jpt_chb\"):\n            if vars(args)[\"{}_bfile\".format(pop)] is None:\n                raise ProgramError(\"argument --{}-bfile is \"\n                                   \"required\".format(pop.replace(\"_\", \"-\")))\n        prefixes_to_check += [\n            args.ceu_bfile,\n            args.yri_bfile,\n            args.jpt_chb_bfile,\n        ]\n    for prefix in prefixes_to_check:\n        if prefix is None:\n            msg = \"no input file\"\n            raise ProgramError(msg)\n        for fileName in [prefix + i for i in [\".bed\", \".bim\", \".fam\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"%(fileName)s: no such file\" % locals()\n                raise ProgramError(msg)\n\n    # Check the indep-pairwise option\n    # The two first must be int, the last one float\n    try:\n        for i in xrange(2):\n            tmp = int(args.indep_pairwise[i])\n        tmp = float(args.indep_pairwise[2])\n    except ValueError:\n        msg = \"indep-pairwise: need INT INT FLOAT\"\n        raise ProgramError(msg)\n\n    # Check the maf value\n    tmpMAF = None\n    try:\n        tmpMAF = float(args.maf)\n    except ValueError:\n        msg = \"maf: must be a float, not %s\" % args.maf\n        raise ProgramError(msg)\n    if (tmpMAF > 0.5) or (tmpMAF < 0.0):\n        msg = \"maf: must be between 0.0 and 0.5, not %s\" % args.maf\n        raise ProgramError(msg)\n\n    # Check the number of line per file\n    if args.line_per_file_for_sge < 1:\n        msg = \"line-per-file-for-sge: must be above 0, not \" \\\n              \"%d\" % args.line_per_file_for_sge\n        raise ProgramError(msg)\n\n    # Check the number of component to compute\n    if args.nb_components < 2 or args.nb_components > 10:\n        msg = (\"nb-components: must be between 2 and 10 (inclusive), \"\n               \"not {}\".format(args.nb_components))\n        raise ProgramError(msg)\n\n    # Check the minimum number of SNPs\n    if args.min_nb_snp < 1:\n        msg = \"min-nb-snp: must be above 1\"\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options of the program."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts favicon url from BeautifulSoup object", "response": "def extract_favicon(bs4):\n    \"\"\"Extracting favicon url from BeautifulSoup object\n\n    :param bs4: `BeautifulSoup`\n    :return: `list` List of favicon urls\n    \"\"\"\n\n    favicon = []\n\n    selectors = [\n        'link[rel=\"icon\"]',\n        'link[rel=\"Icon\"]',\n        'link[rel=\"ICON\"]',\n        'link[rel^=\"shortcut\"]',\n        'link[rel^=\"Shortcut\"]',\n        'link[rel^=\"SHORTCUT\"]'\n    ]\n\n    for selector in selectors:\n\n        icons = bs4.select(selector)\n\n        if icons:\n\n            for icon in icons:\n\n                if icon.has_attr('href'):\n\n                    favicon.append(icon['href'])\n\n    return favicon"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_metas(bs4):\n\n    meta_tags = []\n\n    metas = bs4.select('meta')\n\n    for meta in metas:\n\n        meta_content = {}\n\n        meta_attrs = [\n            'charset',\n            'name',\n            'content',\n            'property',\n            'http-equiv',\n            'itemprop'\n        ]\n\n        for attr in meta_attrs:\n            if meta.has_attr(attr):\n                meta_content.update({attr: meta[attr]})\n\n        meta_tags.append(meta_content)\n\n    return meta_tags", "response": "Extracting meta tags from BeautifulSoup object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_invalid_url(url):\n    regex_valid_url = re.compile(\n        r'^(?:http|ftp)s?://' # http:// or https://\n        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n        r'localhost|' #localhost...\n        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n        r'(?::\\d+)?' # optional port\n        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n\n    return url if regex_valid_url.match(url) else 'http://{}'.format(url)", "response": "Convert invalid url with adding extra http://' schema into it\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract links from BeautifulSoup object", "response": "def extract_links(bs4):\n    \"\"\"Extracting links from BeautifulSoup object\n\n    :param bs4: `BeautifulSoup`\n    :return: `list` List of links\n    \"\"\"\n\n    unique_links = list(set([anchor['href'] for anchor in bs4.select('a[href]') if anchor.has_attr('href')]))\n\n    # remove irrelevant link\n    unique_links = [link for link in unique_links if link != '#']\n\n    # convert invalid link with adding 'http' schema\n    return [convert_invalid_url(link) for link in unique_links]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_original_links(base_url, bs4):\n    valid_url = convert_invalid_url(base_url)\n\n    url = urlparse(valid_url)\n\n    base_url = '{}://{}'.format(url.scheme, url.netloc)\n\n    base_url_with_www = '{}://www.{}'.format(url.scheme, url.netloc)\n\n    links = extract_links(bs4)\n\n    result_links = [anchor for anchor in links if anchor.startswith(base_url)]\n\n    result_links_www = [anchor for anchor in links if anchor.startswith(base_url_with_www)]\n\n    return list(set(result_links + result_links_www))", "response": "Extracting links that contains specific url from BeautifulSoup object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract css links from BeautifulSoup object", "response": "def extract_css_links(bs4):\n    \"\"\"Extracting css links from BeautifulSoup object\n\n    :param bs4: `BeautifulSoup`\n    :return: `list` List of links\n    \"\"\"\n\n    links = extract_links(bs4)\n\n    real_css = [anchor for anchor in links if anchor.endswith(('.css', '.CSS'))]\n\n    css_link_tags = [anchor['href'] for anchor in bs4.select('link[type=\"text/css\"]')\n                     if anchor.has_attr('href')]\n\n    return list(set(real_css+css_link_tags))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_js_links(bs4):\n\n    links = extract_links(bs4)\n\n    real_js = [anchor for anchor in links if anchor.endswith(('.js', '.JS'))]\n\n    js_tags = [anchor['src'] for anchor in bs4.select('script[type=\"text/javascript\"]')\n               if anchor.has_attr('src')]\n\n    return list(set(real_js+js_tags))", "response": "Extracting js links from BeautifulSoup object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_images(bs4, lazy_image_attribute=None):\n\n    # get images form 'img' tags\n    if lazy_image_attribute:\n\n        images = [image[lazy_image_attribute] for image in bs4.select('img') if image.has_attr(lazy_image_attribute)]\n\n    else:\n\n        images = [image['src'] for image in bs4.select('img') if image.has_attr('src')]\n\n    # get images from detected links\n    image_links = [link for link in extract_links(bs4) if link.endswith(('.jpg', '.JPG', '.png', '.PNG', '.gif', '.GIF'))]\n\n    # get images from meta content\n    image_metas = [meta['content'] for meta in extract_metas(bs4)\n                   if 'content' in meta\n                   if meta['content'].endswith(('.jpg', '.JPG', '.png', '.PNG', '.gif', '.GIF'))]\n\n    return list(set(images + image_links + image_metas))", "response": "Extract images from a bs4 element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting canonical url from BeautifulSoup object", "response": "def extract_canonical(bs4):\n    \"\"\"Extracting canonical url\n\n    :param bs4:\n    :return:\n    \"\"\"\n\n    link_rel = bs4.select('link[rel=\"canonical\"]')\n\n    if link_rel.__len__() > 0:\n\n        if link_rel[0].has_attr('href'):\n\n            return link_rel[0]['href']\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning html result that executed by given css selector", "response": "def html(self, selector):\n        \"\"\"Return html result that executed by given css selector\n\n        :param selector: `str` css selector\n        :return: `list` or `None`\n        \"\"\"\n\n        result = self.__bs4.select(selector)\n\n        return [str(r) for r in result] \\\n            if result.__len__() > 1 else \\\n            str(result[0]) if result.__len__() > 0 else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns text result that executed by given css selector", "response": "def text(self, selector):\n        \"\"\"Return text result that executed by given css selector\n\n        :param selector: `str` css selector\n        :return: `list` or `None`\n        \"\"\"\n\n        result = self.__bs4.select(selector)\n\n        return [r.get_text() for r in result] \\\n            if result.__len__() > 1 else \\\n            result[0].get_text() if result.__len__() > 0 else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef conversion_rate(self):\n        participants = self.participant_count\n        if participants == 0:\n            return 0.0\n        return self.experiment.conversions_for(self.name) / float(participants)", "response": "Returns a > 0 float representing a percentage of conversion rates for this variant."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef z_score(self):\n        control = VariantStat(self.experiment.control, self.experiment)\n\n        alternative = self\n\n        if control.name == alternative.name:\n            return 'N/A'\n\n        conv_c = control.conversion_rate\n        conv_a = alternative.conversion_rate\n\n        num_c = control.participant_count\n        num_a = alternative.participant_count\n\n        if conv_c == 0 or conv_a == 0:\n            return 0\n\n        numerator = conv_a - conv_c\n\n        frac_c = (conv_c * (1 - conv_c)) / float(num_c)\n        frac_a = (conv_a * (1 - conv_a)) / float(num_a)\n\n        if frac_c + frac_a == 0:\n            # square root of 0 is 0, so no need to calculate\n            return 0\n        elif frac_c + frac_a < 0:\n            # can't take a square root of a negative number,\n            # so return 'Invalid'\n            return 'Invalid'\n\n        return numerator / math.sqrt((frac_c + frac_a))", "response": "Calculate the Z - Score between this alternative and the project control."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef confidence_level(self):\n        z = self.z_score\n        if isinstance(z, string_types):\n            return z\n\n        z = abs(round(z, 3))\n\n        if z == 0.0:\n            return \"No Change\"\n        elif z < 1.65:\n            return \"No Confidence\"\n        elif z < 2.33:\n            return \"95% Confidence\"\n        elif z < 3.08:\n            return \"99% Confidence\"\n        return \"99.9% Confidence\"", "response": "Returns a human - readable string that describes the confidence of the current variant."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        evaluated_data = super(Index, self).evaluate(verbose, decode, passes, num_threads, apply_experimental)\n\n        return Index(evaluated_data, self.dtype, self.name)", "response": "Evaluates by creating an Index containing evaluated data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tail(self, n=5):\n        if self.empty:\n            return self\n        else:\n            if self._length is not None:\n                length = self._length\n            else:\n                length = self._lazy_len().weld_expr\n\n            # not computing slice here to use with __getitem__ because we'd need to use len which is eager\n            return Index(weld_tail(self.weld_expr, length, n),\n                         self.dtype,\n                         self.name)", "response": "Return Index with the last n values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new Index with missing values replaced with value.", "response": "def fillna(self, value):\n        \"\"\"Returns Index with missing values replaced with value.\n\n        Parameters\n        ----------\n        value : {int, float, bytes, bool}\n            Scalar value to replace missing values with.\n\n        Returns\n        -------\n        Index\n            With missing values replaced.\n\n        \"\"\"\n        if not is_scalar(value):\n            raise TypeError('Value to replace with is not a valid scalar')\n\n        return Index(weld_replace(self.weld_expr,\n                                  self.weld_type,\n                                  default_missing_data_literal(self.weld_type),\n                                  value),\n                     self.dtype,\n                     self.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_pandas(cls, index):\n        from pandas import Index as PandasIndex\n        check_type(index, PandasIndex)\n\n        return Index(index.values,\n                     index.dtype,\n                     index.name)", "response": "Create baloo Index from pandas Index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_pandas(self):\n        if not self.is_raw():\n            raise ValueError('Cannot convert to pandas Index if not evaluated.')\n\n        from pandas import Index as PandasIndex\n\n        return PandasIndex(self.values,\n                           self.dtype,\n                           name=self.name)", "response": "Convert to pandas Index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plink_version():\n    # Running the command\n    tmp_fn = None\n    with tempfile.NamedTemporaryFile(delete=False) as tmpfile:\n        tmp_fn = tmpfile.name + \"_pyGenClean\"\n\n    # The command to run\n    command = [\"plink\", \"--noweb\", \"--out\", tmp_fn]\n\n    output = None\n    try:\n        proc = Popen(command, stdout=PIPE, stderr=PIPE)\n        output = proc.communicate()[0].decode()\n    except OSError:\n        raise ProgramError(\"plink: command not found\")\n\n    # Deleting the output file automatically created by Plink\n    if os.path.isfile(tmp_fn + \".log\"):\n        os.remove(tmp_fn + \".log\")\n\n    # Finding the version\n    version = re.search(r\"\\|\\s+PLINK!\\s+\\|\\s+(\\S+)\\s+\\|\", output)\n    if version is None:\n        version = \"unknown\"\n    else:\n        version = version.group(1)\n\n    return version", "response": "Gets the Plink version from the binary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _normalise_weights(logZ, weights, ntrim=None):\n    logZ -= logZ.max()\n\n    Zs = numpy.exp(logZ)\n\n    weights = [w/w.sum()*Z for w, Z in zip(weights, Zs)]\n\n    wmax = max([w.max() for w in weights])\n\n    weights = [w/wmax for w in weights]\n\n    ntot = sum([w.sum() for w in weights])\n\n    if ntrim is not None and ntrim < ntot:\n        weights = [w*ntrim/ntot for w in weights]\n\n    return logZ, weights", "response": "This function takes a list of log - evidences and re - normalises the weights for trimming\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _equally_weight_samples(samples, weights):\n    if len(weights) != len(samples):\n        raise ValueError(\"len(weights) = %i != len(samples) = %i\" %\n                         (len(weights), len(samples)))\n\n    if numpy.logical_or(weights < 0, weights > 1).any():\n        raise ValueError(\"weights must have probability between 0 and 1\")\n\n    weights = numpy.array(weights)\n    samples = numpy.array(samples)\n\n    state = numpy.random.get_state()\n\n    numpy.random.seed(1)\n    n = len(weights)\n    choices = numpy.random.rand(n) < weights\n\n    new_samples = samples[choices]\n\n    numpy.random.set_state(state)\n\n    return new_samples.copy()", "response": "Convert samples to be equally weighted."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending data from your server to your users devices.", "response": "def notification_push(dev_type, to, message=None, **kwargs):\n    \"\"\"\n    Send data from your server to your users' devices.\n    \"\"\"\n    key = {\n        'ANDROID': settings.GCM_ANDROID_APIKEY,\n        'IOS': settings.GCM_IOS_APIKEY\n    }\n\n    if not key[dev_type]:\n        raise ImproperlyConfigured(\n            \"You haven't set the 'GCM_{}_APIKEY' setting yet.\".format(dev_type))\n\n    payload = {\n        'ANDROID': {'to': to,\n                    'data': {'message': message}},\n        'IOS': {\n            'to': to,\n            'notification': {\n                'body': message,\n            },\n        }\n    }\n\n    payload[dev_type].update(**kwargs)\n\n    payload = json.dumps(payload[dev_type])\n\n    headers = {'Authorization': 'key={}'.format(key[dev_type]), 'Content-Type': 'application/json'}\n\n    response = requests.post(url='https://gcm-http.googleapis.com/gcm/send',\n                             data=payload,\n                             headers=headers\n                             )\n\n    if response.status_code == 200:\n\n        response = response.json()\n\n        if response['success']:\n            return {'success': 'Message send successfully'}\n        elif response['canonical_ids']:\n            return {'canonical_id': response.get('results')[0].get('registration_id')}\n        elif response['failure']:\n            return {'error': response.get('results')[0].get('error')}\n\n    elif 400 <= response.status_code < 500:\n        return {'error': '%s Client Error: %s' % (response.status_code, response.reason)}\n\n    elif 500 <= response.status_code < 600:\n        return {'error': '%s Server Error: %s' % (response.status_code, response.reason)}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the device model that is active in this project.", "response": "def get_device_model():\n    \"\"\"\n    Returns the Device model that is active in this project.\n    \"\"\"\n    try:\n        return apps.get_model(settings.GCM_DEVICE_MODEL)\n    except ValueError:\n        raise ImproperlyConfigured(\"GCM_DEVICE_MODEL must be of the form 'app_label.model_name'\")\n    except LookupError:\n        raise ImproperlyConfigured(\n            \"GCM_DEVICE_MODEL refers to model '%s' that has not been installed\" % settings.GCM_DEVICE_MODEL\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_json(self, json: Map) -> Maybe[Project]:\n        ''' Try to instantiate a Project from the given json object.\n        Convert the **type** key to **tpe** and its value to\n        Maybe.\n        Make sure **root** is a directory, fall back to resolution\n        by **tpe/name**.\n        Reinsert the root dir into the json dict, filter out all keys\n        that aren't contained in Project's fields.\n        Try to instantiate.\n        '''\n        root = json.get('root')\\\n            .map(mkpath)\\\n            .or_else(\n                json.get_all('type', 'name')\n                .flat_map2(self.resolver.type_name))\n        valid_fields = root\\\n            .map(lambda a: json ** Map(root=a, tpe=json.get('type')))\\\n            .map(lambda a: a.at(*Project._pclass_fields))\n        return Try(lambda: valid_fields.map(lambda kw: Project(**kw))) | Empty()", "response": "Try to instantiate a Project from the given json object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_template(template_name=None):\n\n    def decorator(view_func):\n        def _wrapped_view(request, *args, **kwargs):\n            result = view_func(request, *args, **kwargs)\n            if isinstance(result, dict):\n                return TemplateResponse(request, result.pop('TEMPLATE', template_name), result)\n            return result \n        return wraps(view_func, assigned=available_attrs(view_func))(_wrapped_view)\n    return decorator", "response": "Decorator for simple call to template"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nintroduce in Django 1.3 (django.dispatch.receiver) A decorator for connecting receivers to signals. Used by passing in the signal and keyword arguments to connect:: @receiver(post_save, sender=MyModel) def signal_receiver(sender, **kwargs): do_stuff()", "response": "def receiver(signal, **kwargs):\n    \"\"\"\n    Introduced in Django 1.3 (django.dispatch.receiver)\n    \n    A decorator for connecting receivers to signals. Used by passing in the\n    signal and keyword arguments to connect::\n\n    @receiver(post_save, sender=MyModel)\n    def signal_receiver(sender, **kwargs):\n        do_stuff()\n    \"\"\"\n    def _decorator(func):\n        signal.connect(func, **kwargs)\n        return func\n    return _decorator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    # Getting and checking the options\n    args = parse_args()\n    check_args(args)\n\n    # The directory name\n    dirname = \"data_clean_up.\"\n    dirname += datetime.datetime.today().strftime(\"%Y-%m-%d_%H.%M.%S\")\n    while os.path.isdir(dirname):\n        time.sleep(1)\n        dirname = \"data_clean_up.\"\n        dirname += datetime.datetime.today().strftime(\"%Y-%m-%d_%H.%M.%S\")\n\n    # Creating the output directory\n    os.mkdir(dirname)\n\n    # Configuring the root logger\n    add_file_handler_to_root(os.path.join(dirname, \"pyGenClean.log\"))\n\n    logger.info(\"pyGenClean version {}\".format(__version__))\n    plink_version = get_plink_version()\n    logger.info(\"Using Plink version {}\".format(plink_version))\n\n    # Reading the configuration file\n    logger.info(\"Reading configuration file [ {} ]\".format(args.conf))\n    order, conf = read_config_file(args.conf)\n\n    # Executing the data clean up\n    current_in = None\n    current_in_type = None\n    suffixes = None\n    if args.tfile is not None:\n        current_in = args.tfile\n        current_in_type = \"tfile\"\n        suffixes = (\".tped\", \".tfam\")\n    elif args.bfile is not None:\n        current_in = args.bfile\n        current_in_type = \"bfile\"\n        suffixes = (\".bed\", \".bim\", \".fam\")\n    else:\n        current_in = args.file\n        current_in_type = \"file\"\n        suffixes = (\".ped\", \".map\")\n\n    # Creating the excluded files\n    try:\n        with open(os.path.join(dirname, \"excluded_markers.txt\"), \"w\") as o_f:\n            pass\n        with open(os.path.join(dirname, \"excluded_samples.txt\"), \"w\") as o_f:\n            pass\n        with open(os.path.join(dirname, \"initial_files.txt\"), \"w\") as o_file:\n            for s in suffixes:\n                print >>o_file, current_in + s\n\n    except IOError:\n        msg = \"{}: cannot write summary\".format(dirname)\n        raise ProgramError(msg)\n\n    # Counting the number of markers and samples in the datafile\n    logger.info(\"Counting initial number of samples and markers\")\n    nb_markers, nb_samples = count_markers_samples(current_in,\n                                                   current_in_type)\n    logger.info(\"  - {:,d} samples\".format(nb_samples))\n    logger.info(\"  - {:,d} markers\".format(nb_markers))\n\n    # Creating the result summary file containing the initial numbers\n    try:\n        with open(os.path.join(dirname, \"results_summary.txt\"), \"w\") as o_file:\n            print >>o_file, \"# initial\"\n            print >>o_file, (\"Initial number of markers\\t\"\n                             \"{:,d}\".format(nb_markers))\n            print >>o_file, (\"Initial number of samples\\t\"\n                             \"{:,d}\".format(nb_samples))\n            print >>o_file, \"---\"\n    except IOError:\n        msg = \"{}: cannot write summary\".format(dirname)\n        raise ProgramError(msg)\n\n    latex_summaries = []\n    steps = []\n    descriptions = []\n    long_descriptions = []\n    graphic_paths = set()\n    for number in order:\n        # Getting the script name and its options\n        script_name, options = conf[number]\n\n        # Getting the output prefix\n        output_prefix = os.path.join(dirname,\n                                     \"{}_{}\".format(number, script_name))\n\n        # Getting the function to use\n        function_to_use = available_functions[script_name]\n\n        # Executing the function\n        logger.info(\"Running {} {}\".format(number, script_name))\n        logger.info(\"  - Using {} as prefix for input \"\n                    \"files\".format(current_in))\n        logger.info(\"  - Results will be in [ {} ]\".format(output_prefix))\n\n        # Executing the function\n        step_results = function_to_use(\n            in_prefix=current_in,\n            in_type=current_in_type,\n            out_prefix=output_prefix,\n            base_dir=dirname,\n            options=options,\n        )\n\n        # Updating the input files and input file types\n        current_in = step_results.next_file\n        current_in_type = step_results.next_file_type\n\n        # Saving what's necessary for the LaTeX report\n        latex_summaries.append(step_results.latex_summary)\n        steps.append(script_name)\n        descriptions.append(step_results.description)\n        long_descriptions.append(step_results.long_description)\n        if step_results.graph_path is not None:\n            graphic_paths.update(step_results.graph_path)\n\n    # Counting the final number of samples and markers\n    logger.info(\"Counting final number of samples and markers\")\n    nb_markers, nb_samples = count_markers_samples(current_in,\n                                                   current_in_type)\n    logger.info(\"  - {:,d} samples\".format(nb_samples))\n    logger.info(\"  - {:,d} markers\".format(nb_markers))\n\n    # Getting the final suffixes\n    suffixes = None\n    if current_in_type == \"tfile\":\n        suffixes = ((\".tped\", nb_markers), (\".tfam\", nb_samples))\n    elif current_in_type == \"bfile\":\n        suffixes = ((\".bed\", None), (\".bim\", nb_markers), (\".fam\", nb_samples))\n    else:\n        suffixes = ((\".ped\", nb_samples), (\".map\", nb_markers))\n\n    with open(os.path.join(dirname, \"final_files.txt\"), \"w\") as o_file:\n        for s, nb in suffixes:\n            if nb:\n                print >>o_file, current_in + s + \"\\t{:,d}\".format(nb)\n            else:\n                print >>o_file, current_in + s\n\n    # Generating the graphics paths file\n    graphic_paths_fn = None\n    if len(graphic_paths) > 0:\n        try:\n            graphic_paths_fn = os.path.join(dirname, \"graphic_paths.txt\")\n            with open(graphic_paths_fn, \"w\") as o_file:\n                for path in sorted(graphic_paths):\n                    print >>o_file, path\n        except IOError:\n            msg = \"{}: cannot write summary\".format(dirname)\n            raise ProgramError(msg)\n\n    # We create the automatic report\n    logger.info(\"Generating automatic report\")\n    report_name = os.path.join(dirname, \"automatic_report.tex\")\n    auto_report.create_report(\n        dirname,\n        report_name,\n        project_name=args.report_number,\n        steps=steps,\n        descriptions=descriptions,\n        graphic_paths_fn=graphic_paths_fn,\n        long_descriptions=long_descriptions,\n        summaries=latex_summaries,\n        background=args.report_background,\n        summary_fn=os.path.join(dirname, \"results_summary.txt\"),\n        report_title=args.report_title,\n        report_author=args.report_author,\n        initial_files=os.path.join(dirname, \"initial_files.txt\"),\n        final_files=os.path.join(dirname, \"final_files.txt\"),\n        final_nb_markers=\"{:,d}\".format(nb_markers),\n        final_nb_samples=\"{:,d}\".format(nb_samples),\n        plink_version=plink_version,\n    )", "response": "This function is the main function of the data clean up script. It is responsible for checking if the required files exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_duplicated_samples(in_prefix, in_type, out_prefix, base_dir, options):\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need tfile\n    required_type = \"tfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"dup_samples\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        duplicated_samples.main(options)\n    except duplicated_samples.ProgramError as e:\n        msg = \"duplicated_samples: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Reading the number of duplicated samples\n    duplicated_count = defaultdict(int)\n    if os.path.isfile(script_prefix + \".duplicated_samples.tfam\"):\n        with open(script_prefix + \".duplicated_samples.tfam\", \"r\") as i_file:\n            duplicated_count = Counter([\n                tuple(createRowFromPlinkSpacedOutput(line)[:2])\n                for line in i_file\n            ])\n\n    # Counting the number of zeroed out genotypes per duplicated sample\n    zeroed_out = defaultdict(int)\n    if os.path.isfile(script_prefix + \".zeroed_out\"):\n        with open(script_prefix + \".zeroed_out\", \"r\") as i_file:\n            zeroed_out = Counter([\n                tuple(line.rstrip(\"\\r\\n\").split(\"\\t\")[:2])\n                for line in i_file.read().splitlines()[1:]\n            ])\n    nb_zeroed_out = sum(zeroed_out.values())\n\n    # Checking the not good enough samples\n    not_good_enough = set()\n    if os.path.isfile(script_prefix + \".not_good_enough\"):\n        with open(script_prefix + \".not_good_enough\", \"r\") as i_file:\n            not_good_enough = {\n                tuple(line.rstrip(\"\\r\\n\").split(\"\\t\")[:4])\n                for line in i_file.read().splitlines()[1:]\n            }\n\n    # Checking which samples were chosen\n    chosen_sample = set()\n    if os.path.isfile(script_prefix + \".chosen_samples.info\"):\n        with open(script_prefix + \".chosen_samples.info\", \"r\") as i_file:\n            chosen_sample = {\n                tuple(line.rstrip(\"\\r\\n\").split(\"\\t\"))\n                for line in i_file.read().splitlines()[1:]\n            }\n\n    # Finding if some 'not_good_enough' samples were chosen\n    not_good_still = {s[2:] for s in chosen_sample & not_good_enough}\n\n    # We create a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                duplicated_samples.pretty_name\n            )\n            text = (\n                \"A total of {:,d} duplicated sample{} {} found.\".format(\n                    len(duplicated_count),\n                    \"s\" if len(duplicated_count) > 1 else \"\",\n                    \"were\" if len(duplicated_count) > 1 else \"was\",\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n            if len(duplicated_count) > 0:\n                text = (\n                    \"While merging duplicates, a total of {:,d} genotype{} {} \"\n                    \"zeroed out. A total of {:,d} sample{} {} found to be not \"\n                    \"good enough for duplicate completion.\".format(\n                        nb_zeroed_out,\n                        \"s\" if nb_zeroed_out > 1 else \"\",\n                        \"were\" if nb_zeroed_out > 1 else \"was\",\n                        len(not_good_enough),\n                        \"s\" if len(not_good_enough) > 1 else \"\",\n                        \"were\" if len(not_good_enough) > 1 else \"was\",\n                    )\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                table_label = re.sub(\n                    r\"[/\\\\]\",\n                    \"_\",\n                    script_prefix,\n                ) + \"_dup_samples\"\n                text = (\n                    r\"Table~\\ref{\" + table_label + \"} summarizes the number \"\n                    \"of each duplicated sample with some characteristics.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                if len(not_good_still) > 0:\n                    text = latex_template.textbf(\n                        \"There {} {:,d} sample{} that {} not good due to low \"\n                        \"completion or concordance, but {} still selected as \"\n                        \"the best duplicate (see Table~{}).\".format(\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            len(not_good_still),\n                            \"s\" if len(not_good_still) > 1 else \"\",\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            r\"~\\ref{\" + table_label + \"}\",\n                        )\n                    )\n                    print >>o_file, latex_template.wrap_lines(text)\n\n                # Getting the template\n                longtable_template = latex_template.jinja2_env.get_template(\n                    \"longtable_template.tex\",\n                )\n\n                # The table caption\n                table_caption = (\n                    \"Summary of the {:,d} duplicated sample{}. The number of \"\n                    \"duplicates and the total number of zeroed out genotypes \"\n                    \"are shown.\".format(\n                        len(duplicated_count),\n                        \"s\" if len(duplicated_count) > 1 else \"\",\n                    )\n                )\n\n                if len(not_good_still) > 0:\n                    table_caption += (\n                        \" A total of {:,d} sample{} (highlighted) {} not good \"\n                        \"enough for completion, but {} chosen as the best \"\n                        \"duplicate, and {} still in the final \"\n                        \"dataset).\".format(\n                            len(not_good_still),\n                            \"s\" if len(not_good_still) > 1 else \"\",\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            \"are\" if len(not_good_still) > 1 else \"is\",\n                        )\n                    )\n\n                duplicated_samples_list = duplicated_count.most_common()\n                print >>o_file, longtable_template.render(\n                    table_caption=table_caption,\n                    table_label=table_label,\n                    nb_col=4,\n                    col_alignments=\"llrr\",\n                    text_size=\"scriptsize\",\n                    header_data=[(\"FID\", 1), (\"IID\", 1), (\"Nb Duplicate\", 1),\n                                 (\"Nb Zeroed\", 1)],\n                    tabular_data=[\n                        [latex_template.sanitize_tex(fid),\n                         latex_template.sanitize_tex(iid),\n                         \"{:,d}\".format(nb),\n                         \"{:,d}\".format(zeroed_out[(fid, iid)])]\n                        for (fid, iid), nb in duplicated_samples_list\n                    ],\n                    highlighted=[\n                        (fid, iid) in not_good_still\n                        for fid, iid in [i[0] for i in duplicated_samples_list]\n                    ],\n                )\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        counter = Counter(duplicated_count.values()).most_common()\n        if counter:\n            print >>o_file, \"Number of replicated samples\"\n        else:\n            print >>o_file, \"Number of replicated samples\\t0\"\n        for rep_type, rep_count in counter:\n            print >>o_file, \"  - x{}\\t{:,d}\\t\\t-{:,d}\".format(\n                rep_type,\n                rep_count,\n                (rep_count * rep_type) - rep_count,\n            )\n        print >>o_file, (\"Poorly chosen replicated \"\n                         \"samples\\t{:,d}\".format(len(not_good_still)))\n        print >>o_file, \"---\"\n\n    # We know this step does produce a new data set (tfile), so we return it\n    return _StepResult(\n        next_file=os.path.join(out_prefix, \"dup_samples.final\"),\n        next_file_type=\"tfile\",\n        latex_summary=latex_file,\n        description=duplicated_samples.desc,\n        long_description=duplicated_samples.long_desc,\n        graph_path=None,\n    )", "response": "Runs step1 of duplicated samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_duplicated_snps(in_prefix, in_type, out_prefix, base_dir, options):\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need a tfile\n    required_type = \"tfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # This step require a map file (we now have a tfile)\n    if not os.path.isfile(in_prefix + \".map\"):\n        outputFile = None\n        try:\n            outputFile = open(in_prefix + \".map\", \"w\")\n        except IOError:\n            msg = \"{}: can't write file\".format(in_prefix + \".map\")\n            raise ProgramError(msg)\n        try:\n            with open(in_prefix + \".tped\", 'r') as inputFile:\n                for line in inputFile:\n                    row = createRowFromPlinkSpacedOutput(line)\n                    print >>outputFile, \"\\t\".join(row[:4])\n        except IOError:\n            msg = \"{}: no such file\".format(in_prefix + \".tped\")\n            raise ProgramError(msg)\n        outputFile.close()\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"dup_snps\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        duplicated_snps.main(options)\n    except duplicated_snps.ProgramError as e:\n        msg = \"duplicated_snps: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Reading the number of duplicated markers\n    duplicated_count = defaultdict(int)\n    if os.path.isfile(script_prefix + \".duplicated_snps.tped\"):\n        with open(script_prefix + \".duplicated_snps.tped\", \"r\") as i_file:\n            duplicated_count = Counter(\n                (i[0], i[3]) for i in [\n                    tuple(createRowFromPlinkSpacedOutput(line)[:4])\n                    for line in i_file\n                ]\n            )\n\n    # Counting the number of zeroed out genotypes per duplicated markers\n    zeroed_out = defaultdict(int)\n    if os.path.isfile(script_prefix + \".zeroed_out\"):\n        with open(script_prefix + \".zeroed_out\", \"r\") as i_file:\n            zeroed_out = Counter([\n                tuple(line.rstrip(\"\\r\\n\").split(\"\\t\")[:2])\n                for line in i_file.read().splitlines()[1:]\n            ])\n    nb_zeroed_out = sum(zeroed_out.values())\n\n    # Checking the not good enough markers\n    not_good_enough = set()\n    if os.path.isfile(script_prefix + \".not_good_enough\"):\n        with open(script_prefix + \".not_good_enough\", \"r\") as i_file:\n            not_good_enough = {\n                line.rstrip(\"\\r\\n\").split(\"\\t\")[0]\n                for line in i_file.read().splitlines()[1:]\n            }\n\n    # Checking which markers were chosen\n    chosen_markers = set()\n    if os.path.isfile(script_prefix + \".chosen_snps.info\"):\n        with open(script_prefix + \".chosen_snps.info\", \"r\") as i_file:\n            chosen_markers = set(i_file.read().splitlines())\n\n    # Finding if some 'not_good_enough' samples were chosen\n    not_good_still = chosen_markers & not_good_enough\n\n    # Adding the 'not chosen markers' to the list of excluded markers\n    removed_markers = set()\n    o_filename = os.path.join(base_dir, \"excluded_markers.txt\")\n    if os.path.isfile(script_prefix + \".removed_duplicates\"):\n        with open(script_prefix + \".removed_duplicates\", \"r\") as i_file:\n            removed_markers = set(i_file.read().splitlines())\n            with open(o_filename, \"a\") as o_file:\n                for marker_id in removed_markers:\n                    print >>o_file, marker_id + \"\\t\" + \"removed duplicate\"\n\n    # Writing the summary results\n    total_remaining = 0\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        rep_counter = Counter(duplicated_count.values()).most_common()\n        if rep_counter:\n            print >>o_file, \"Number of replicated markers\"\n        else:\n            print >>o_file, \"Number of replicated markers\\t0\"\n        total_nb_removed_rep = 0\n        for rep_type, rep_count in rep_counter:\n            nb_removed_rep = (rep_count * rep_type) - rep_count\n            print >>o_file, \"  - x{}\\t{:,d}\\t-{:,d}\".format(\n                rep_type,\n                rep_count,\n                nb_removed_rep,\n            )\n            total_nb_removed_rep += nb_removed_rep\n        total_remaining = total_nb_removed_rep - len(removed_markers)\n        print >>o_file, (\n            \"Number of replicated markers kept\\t{nb:,d}\\t+{nb:,d}\".format(\n                nb=total_remaining,\n            )\n        )\n        print >>o_file, (\"Poorly chosen replicated markers\\t\"\n                         \"{nb:,d}\".format(nb=len(not_good_still)))\n        print >>o_file, (\"Final number of excluded markers\\t\"\n                         \"{nb:,d}\".format(nb=len(removed_markers)))\n        print >>o_file, \"---\"\n\n    # We create a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                duplicated_snps.pretty_name\n            )\n\n            text = (\n                \"A total of {:,d} duplicated marker{} {} found.\".format(\n                    len(duplicated_count),\n                    \"s\" if len(duplicated_count) > 1 else \"\",\n                    \"were\" if len(duplicated_count) > 1 else \"was\",\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n            if len(duplicated_count) > 0:\n                text = (\n                    \"While merging duplicates, a total of {:,d} genotype{} {} \"\n                    \"zeroed out. A total of {:,d} marker{} {} found to be not \"\n                    \"good enough for duplicate completion.\".format(\n                        nb_zeroed_out,\n                        \"s\" if nb_zeroed_out > 1 else \"\",\n                        \"were\" if nb_zeroed_out > 1 else \"was\",\n                        len(not_good_enough),\n                        \"s\" if len(not_good_enough) > 1 else \"\",\n                        \"were\" if len(not_good_enough) > 1 else \"was\",\n                    )\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                text = (\n                    \"A total of {:,d} marker{} {} excluded while creating the \"\n                    \"final dataset.\".format(\n                        len(removed_markers),\n                        \"s\" if len(removed_markers) > 1 else \"\",\n                        \"were\" if len(removed_markers) > 1 else \"was\",\n                    )\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                if total_remaining > 0:\n                    text = latex_template.textbf(\n                        \"In total, {:,d} maker{} {} not merged for different \"\n                        \"reasons (low completion rate, discordant allele, \"\n                        \"discordant MAF, etc) and {} still present in the \"\n                        \"dataset.\".format(\n                            total_remaining,\n                            \"s\" if total_remaining > 1 else \"\",\n                            \"were\" if total_remaining > 1 else \"was\",\n                            \"are\" if total_remaining > 1 else \"is\",\n                        )\n                    )\n                    print >>o_file, latex_template.wrap_lines(text)\n\n                if len(not_good_still) > 0:\n                    start = \"A total of\"\n                    end = \" and {} still present in the final dataset.\".format(\n                        \"are\" if len(not_good_still) > 1 else \"is\",\n                    )\n                    if total_remaining > 0:\n                        start = \"Out of these,\"\n                        end = \".\"\n                    text = latex_template.textbf(\n                        start + \" {:,d} marker{} {} not good enough for \"\n                        \"completion, but {} still selected as the best \"\n                        \"duplicate{}\".format(\n                            len(not_good_still),\n                            \"s\" if len(not_good_still) > 1 else \"\",\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            \"were\" if len(not_good_still) > 1 else \"was\",\n                            end,\n                        )\n                    )\n                    print >>o_file, latex_template.wrap_lines(text)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # We know this step does produce a new data set (tfile), so we return it\n    return _StepResult(\n        next_file=os.path.join(out_prefix, \"dup_snps.final\"),\n        next_file_type=\"tfile\",\n        latex_summary=latex_file,\n        description=duplicated_snps.desc,\n        long_description=duplicated_snps.long_desc,\n        graph_path=None,\n    )", "response": "Runs step1 of the duplicated snps."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_noCall_hetero_snps(in_prefix, in_type, out_prefix, base_dir, options):\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need a tfile\n    required_type = \"tfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"clean_noCall_hetero\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        noCall_hetero_snps.main(options)\n    except noCall_hetero_snps.ProgramError as e:\n        msg = \"noCall_hetero_snps: {}\".format(e)\n        raise ProgramError(msg)\n\n    # We want to save in a file the markers and samples that were removed\n    # There are two files to look at, which contains only one row, the name of\n    # the markers:\n    #     - prefix.allFailed\n    #     - prefix.allHetero\n    nb_all_failed = 0\n    nb_all_hetero = 0\n    o_filename = os.path.join(base_dir, \"excluded_markers.txt\")\n    with open(o_filename, \"a\") as o_file:\n        # The first file\n        i_filename = script_prefix + \".allFailed\"\n        if os.path.isfile(i_filename):\n            with open(i_filename, \"r\") as i_file:\n                for line in i_file:\n                    nb_all_failed += 1\n                    print >>o_file, line.rstrip(\"\\r\\n\") + \"\\tall failed\"\n\n        # The second file\n        i_filename = os.path.join(script_prefix + \".allHetero\")\n        if os.path.isfile(i_filename):\n            with open(i_filename, \"r\") as i_file:\n                for line in i_file:\n                    nb_all_hetero += 1\n                    print >>o_file, line.rstrip(\"\\r\\n\") + \"\\tall hetero\"\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                noCall_hetero_snps.pretty_name,\n            )\n            text = (\n                \"After scrutiny, {:,d} marker{} {} excluded from the \"\n                \"dataset because of a call rate of 0. Also, {:,d} marker{} \"\n                \"{} excluded from the dataset because all samples were \"\n                \"heterozygous (excluding the mitochondrial \"\n                \"chromosome)\".format(nb_all_failed,\n                                     \"s\" if nb_all_failed > 1 else \"\",\n                                     \"were\" if nb_all_failed > 1 else \"was\",\n                                     nb_all_hetero,\n                                     \"s\" if nb_all_hetero > 1 else \"\",\n                                     \"were\" if nb_all_hetero > 1 else \"was\")\n            )\n            print >>o_file, latex_template.wrap_lines(text, 80)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of completely failed markers\\t\"\n                         \"{nb:,d}\\t-{nb:,d}\".format(nb=nb_all_failed))\n        print >>o_file, \"---\"\n        print >>o_file, (\"Number of all heterozygous markers\\t\"\n                         \"{nb:,d}\\t-{nb:,d}\".format(nb=nb_all_hetero))\n        print >>o_file, \"---\"\n\n    # We know this step does produce a new data set (tfile), so we return it\n    # along with the report name\n    return _StepResult(\n        next_file=os.path.join(out_prefix, \"clean_noCall_hetero\"),\n        next_file_type=\"tfile\",\n        latex_summary=latex_file,\n        description=noCall_hetero_snps.desc,\n        long_description=noCall_hetero_snps.long_desc,\n        graph_path=None,\n    )", "response": "Runs step 3 ( clean no call and hetero."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_sample_missingness(in_prefix, in_type, out_prefix, base_dir, options):\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We are looking at what we have\n    required_type = \"tfile\"\n    if in_type == \"bfile\":\n        required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"clean_mind\")\n    options += [\"--ifile\", in_prefix,\n                \"--out\", script_prefix]\n    if required_type == \"bfile\":\n        options.append(\"--is-bfile\")\n\n    # We run the script\n    try:\n        sample_missingness.main(options)\n    except sample_missingness.ProgramError as e:\n        msg = \"sample_missingness: {}\".format(e)\n        raise ProgramError(msg)\n\n    # We want to modify the description, so that it contains the option used\n    desc = sample_missingness.desc\n    mind_value = sample_missingness.parser.get_default(\"mind\")\n    if \"--mind\" in options:\n        # Since we already run the script, we know that the mind option is a\n        # valid float\n        mind_value = options[options.index(\"--mind\") + 1]\n    if desc.endswith(\".\"):\n        desc = desc[:-1] + r\" (${}={}$).\".format(latex_template.texttt(\"mind\"),\n                                                 mind_value)\n    long_description = sample_missingness.long_desc.format(\n        success_rate=\"{:.1f}\".format((1-float(mind_value)) * 100),\n    )\n\n    # We want to save in a file the samples that were removed\n    # There is one file to look at, which contains only one row, the name of\n    # the samples:\n    #     - prefix.irem (file will exists only if samples were removed)\n    nb_samples = 0\n    o_filename = os.path.join(base_dir, \"excluded_samples.txt\")\n    i_filename = script_prefix + \".irem\"\n    if os.path.isfile(i_filename):\n        # True, so sample were removed\n        with open(i_filename, \"r\") as i_file, open(o_filename, \"a\") as o_file:\n            for line in i_file:\n                nb_samples += 1\n                print >>o_file, line.rstrip(\"\\r\\n\") + \"\\tmind {}\".format(\n                    mind_value,\n                )\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                sample_missingness.pretty_name,\n            )\n            text = (\"Using a {} threshold of {} ({} keeping only samples with \"\n                    r\"a missing rate $\\leq {}$), {:,d} sample{} {} excluded \"\n                    \"from the dataset.\".format(\n                        latex_template.texttt(\"mind\"),\n                        mind_value,\n                        latex_template.textit(\"i.e.\"),\n                        mind_value,\n                        nb_samples,\n                        \"s\" if nb_samples > 1 else \"\",\n                        \"were\" if nb_samples > 1 else \"was\",\n                    ))\n            print >>o_file, latex_template.wrap_lines(text)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of samples with missing rate higher \"\n                         \"than {t}\\t{nb:,d}\\t\\t-{nb:,d}\".format(\n                            t=mind_value,\n                            nb=nb_samples,\n                         ))\n        print >>o_file, \"---\"\n\n    # We know this step does produce a new data set (bfile), so we return it\n    return _StepResult(\n        next_file=os.path.join(out_prefix, \"clean_mind\"),\n        next_file_type=\"bfile\",\n        latex_summary=latex_file,\n        description=desc,\n        long_description=long_description,\n        graph_path=None,\n    )", "response": "Runs step4 (clean mind).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the\n    :py:mod:`pyGenClean.SampleMissingness.sample_missingness` module. The\n    required file type for this module is either a ``bfile`` or a ``tfile``,\n    hence the need to use the :py:func:`check_input_files` to check if the file\n    input file type is the good one, or to create it if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the contamination check for samples.", "response": "def run_contamination(in_prefix, in_type, out_prefix, base_dir, options):\n    \"\"\"Runs the contamination check for samples.\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need a bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"contamination\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        contamination.main(options)\n    except contamination.ProgramError as e:\n        msg = \"contamination: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Counting the number of markers used for contamination\n    nb_autosomal = 0\n    with open(script_prefix + \".to_extract\", \"r\") as i_file:\n        nb_autosomal = len(i_file.read().splitlines())\n\n    # Reading the \"contamination\" file\n    nb_tested_samples = 0\n    contaminated_table = []\n    nb_contaminated_samples = 0\n    with open(script_prefix + \".bafRegress\", \"r\") as i_file:\n        header = None\n        for i, line in enumerate(i_file):\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            if i == 0:\n                contaminated_table.append((\"sample\", \"estimate$^1$\",\n                                           \"stderr$^1$\", \"tval\", \"pval\",\n                                           \"callrate\", \"Nhom$^2$\"))\n                header = {name: i for i, name in enumerate(row)}\n\n                for name in (\"sample\", \"estimate\", \"stderr\", \"tval\", \"pval\",\n                             \"callrate\", \"Nhom\"):\n                    if name not in header:\n                        raise ProgramError(\"{}: missing column {}\".format(\n                            script_prefix + \".bafRegress\",\n                            name,\n                        ))\n                continue\n\n            # One more sample\n            nb_tested_samples += 1\n\n            # Reading the data\n            estimate = float(row[header[\"estimate\"]])\n            if estimate > 0.01:\n                # This might be a contaminated samples\n                contaminated_table.append((\n                    latex_template.sanitize_tex(row[header[\"sample\"]]),\n                    \"{:.4f}\".format(float(row[header[\"estimate\"]])),\n                    \"{:.4f}\".format(float(row[header[\"stderr\"]])),\n                    \"{:.4f}\".format(float(row[header[\"tval\"]])),\n                    latex_template.format_numbers(\"{:.3e}\".format(\n                        float(row[header[\"pval\"]]),\n                    )),\n                    \"{:.4f}\".format(float(row[header[\"callrate\"]])),\n                    \"{:,d}\".format(int(row[header[\"Nhom\"]])),\n                ))\n                nb_contaminated_samples += 1\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                contamination.pretty_name,\n            )\n            text = (\"A total of {:,d} sample{} {} analyzed for contamination \"\n                    r\"using \\textit{bafRegress}\\cite{bafRegress}. The \"\n                    \"analysis was performed using {:,d} autosomal marker{}. \"\n                    \"Using a threshold of 0.01, {:,d} sample{} {} estimated \"\n                    \"to be contaminated.\".format(\n                        nb_tested_samples,\n                        \"s\" if nb_tested_samples > 1 else \"\",\n                        \"were\" if nb_tested_samples > 1 else \"was\",\n                        nb_autosomal,\n                        \"s\" if nb_autosomal > 1 else \"\",\n                        nb_contaminated_samples,\n                        \"s\" if nb_contaminated_samples > 1 else \"\",\n                        \"were\" if nb_contaminated_samples > 1 else \"was\",\n                        bafRegress=\"{bafRegress}\",\n                    ))\n            print >>o_file, latex_template.wrap_lines(text)\n\n            if nb_contaminated_samples > 0:\n                label = re.sub(r\"[/\\\\]\", \"_\", script_prefix)\n                text = (\n                    r\"Table~\\ref{\" + label + \"} list all the samples that \"\n                    r\"were estimated to be contaminated (\\textit{i.e.} with \"\n                    r\"an estimate $>0.01$).\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                # Getting the template\n                longtable_template = latex_template.jinja2_env.get_template(\n                    \"longtable_template.tex\",\n                )\n\n                # Rendering\n                print >>o_file, longtable_template.render(\n                    table_caption=r\"List of all possible contaminated samples \"\n                                  r\"(\\textit{i.e.} with an estimate computed \"\n                                  r\"by \\textit{bafRegress} $>0.01$).\",\n                    table_label=label,\n                    nb_col=len(contaminated_table[1]),\n                    col_alignments=\"lrrrrrr\",\n                    text_size=\"scriptsize\",\n                    header_data=zip(contaminated_table[0],\n                                    [1 for i in contaminated_table[0]]),\n                    tabular_data=sorted(\n                        contaminated_table[1:],\n                        key=lambda item: item[0],\n                    ),\n                    footnotes=[\n                        \"$^1$Contamination estimate (with standard error)\",\n                        \"$^2$Number of homozygous genotypes used in the model\",\n                    ],\n                )\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of possibly contaminated \"\n                         \"samples\\t{:,d}\".format(nb_contaminated_samples))\n        print >>o_file, \"---\"\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=contamination.desc,\n        long_description=contamination.long_desc,\n        graph_path=None,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_sex_check(in_prefix, in_type, out_prefix, base_dir, options):\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need a bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"sexcheck\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        sex_check.main(options)\n    except sex_check.ProgramError as e:\n        msg = \"sex_check {}\".format(e)\n        raise ProgramError(msg)\n\n    # Reading the hetero file on X\n    hetero = {}\n    if os.path.isfile(script_prefix + \".chr23_recodeA.raw.hetero\"):\n        with open(script_prefix + \".chr23_recodeA.raw.hetero\", \"r\") as i_file:\n            header = {\n                name: i for i, name in\n                enumerate(createRowFromPlinkSpacedOutput(i_file.readline()))\n            }\n            for required_col in (\"PED\", \"ID\", \"HETERO\"):\n                if required_col not in header:\n                    msg = \"{}: no column named {}\".format(\n                        script_prefix + \".chr23_recodeA.raw.hetero\",\n                        required_col,\n                    )\n                    raise ProgramError(msg)\n\n            # Reading the data\n            for line in i_file:\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                famid = row[header[\"PED\"]]\n                indid = row[header[\"ID\"]]\n\n                # Formatting the hetero value\n                het = None\n                try:\n                    het = \"{:.4f}\".format(float(row[header[\"HETERO\"]]))\n                except:\n                    het = \"N/A\"\n\n                hetero[(famid, indid)] = het\n\n    # Reading the number of no call on Y\n    nb_no_call = {}\n    if os.path.isfile(script_prefix + \".chr24_recodeA.raw.noCall\"):\n        with open(script_prefix + \".chr24_recodeA.raw.noCall\", \"r\") as i_file:\n            header = {\n                name: i for i, name in\n                enumerate(createRowFromPlinkSpacedOutput(i_file.readline()))\n            }\n            for required_col in (\"PED\", \"ID\", \"nbGeno\", \"nbNoCall\"):\n                if required_col not in header:\n                    msg = \"{}: no column named {}\".format(\n                        script_prefix + \".chr24_recodeA.raw.noCall\",\n                        required_col,\n                    )\n                    raise ProgramError(msg)\n\n            # Reading the data\n            for line in i_file:\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                famid = row[header[\"PED\"]]\n                indid = row[header[\"ID\"]]\n\n                # Getting the statistics\n                nb_geno = row[header[\"nbGeno\"]]\n                nb_nocall = row[header[\"nbNoCall\"]]\n\n                percent = None\n                try:\n                    percent = \"{:.4f}\".format(\n                        float(nb_nocall) / float(nb_geno),\n                    )\n                except:\n                    percent = \"N/A\"\n                nb_no_call[(famid, indid)] = percent\n\n    # Reading the problem file to gather statistics. Note that dataset without\n    # problem will only have the header line (and no data)\n    nb_problems = 0\n    table = []\n    nb_no_genetic = 0\n    nb_discordant = 0\n    with open(script_prefix + \".list_problem_sex\", \"r\") as i_file:\n        # Reading the header\n        header = i_file.readline().rstrip(\"\\r\\n\").split(\"\\t\")\n        table.append(header)\n        header = {name: i for i, name in enumerate(header)}\n        for required_col in (\"FID\", \"IID\", \"SNPSEX\"):\n            if required_col not in header:\n                msg = \"{}: no column named {}\".format(\n                    script_prefix + \".list_problem_sex\",\n                    required_col,\n                )\n                raise ProgramError(msg)\n\n        # Adding the missing column name\n        table[-1].append(\"HET\")\n        table[-1].append(r\"\\%NOCALL\")\n\n        # Reading the rest of the data\n        for line in i_file:\n            nb_problems += 1\n\n            # Creating the row\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n            # Counting\n            if row[header[\"SNPSEX\"]] == \"0\":\n                nb_no_genetic += 1\n            else:\n                nb_discordant += 1\n\n            table.append([\n                latex_template.sanitize_tex(row[header[name]])\n                for name in (\"FID\", \"IID\", \"PEDSEX\", \"SNPSEX\", \"STATUS\", \"F\")\n            ])\n            table[-1].append(\n                hetero.get((row[header[\"FID\"]], row[header[\"IID\"]]), \"N/A\"),\n            )\n            table[-1].append(\n                nb_no_call.get((row[header[\"FID\"]], row[header[\"IID\"]]), \"N/A\")\n            )\n\n    # Getting the value for the maleF option\n    male_f = sex_check.parser.get_default(\"maleF\")\n    if \"--maleF\" in options:\n        male_f = options[options.index(\"--maleF\") + 1]\n\n    # Getting the value for the femaleF option\n    female_f = sex_check.parser.get_default(\"femaleF\")\n    if \"--femaleF\" in options:\n        female_f = options[options.index(\"--femaleF\") + 1]\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    graphics_paths = set()\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(sex_check.pretty_name)\n            text = (\n                \"Using $F$ thresholds of {male_f} and {female_f} for males \"\n                \"and females respectively, {nb_problems:,d} sample{plural} \"\n                \"had gender problem according to Plink.\".format(\n                    male_f=male_f,\n                    female_f=female_f,\n                    nb_problems=nb_problems,\n                    plural=\"s\" if nb_problems > 1 else \"\",\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n            # The float template\n            float_template = latex_template.jinja2_env.get_template(\n                \"float_template.tex\",\n            )\n\n            if nb_problems > 0:\n                # The label and text for the table\n                table_label = re.sub(\n                    r\"[/\\\\]\",\n                    \"_\",\n                    script_prefix,\n                ) + \"_problems\"\n                text = (\n                    r\"Table~\\ref{\" + table_label + \"} summarizes the gender \"\n                    \"problems encountered during the analysis.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                # Getting the template\n                longtable_template = latex_template.jinja2_env.get_template(\n                    \"longtable_template.tex\",\n                )\n\n                # Rendering\n                print >>o_file, longtable_template.render(\n                    table_caption=\"Summarization of the gender problems \"\n                                  \"encountered during Plink's analysis. \"\n                                  \"HET is the heterozygosity rate on the X \"\n                                  r\"chromosome. \\%NOCALL is the percentage of \"\n                                  \"no calls on the Y chromosome.\",\n                    table_label=table_label,\n                    nb_col=len(table[1]),\n                    col_alignments=\"llrrlrrrr\",\n                    text_size=\"scriptsize\",\n                    header_data=zip(table[0], [1 for i in table[0]]),\n                    tabular_data=sorted(table[1:], key=lambda item: item[1]),\n                )\n\n            # Getting the templates\n            graphic_template = latex_template.jinja2_env.get_template(\n                \"graphics_template.tex\",\n            )\n\n            # If there is a figure, we add it here\n            if os.path.isfile(script_prefix + \".png\"):\n                # Adding the figure\n                figure_label = re.sub(r\"[/\\\\]\", \"_\", script_prefix)\n                text = (\n                    r\"Figure~\\ref{\" + figure_label + r\"} shows the $\\bar{y}$ \"\n                    r\"intensities versus the $\\bar{x}$ intensities for each \"\n                    \"samples. Problematic samples are shown using triangles.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                # Getting the paths\n                graphics_path, path = os.path.split(script_prefix + \".png\")\n                graphics_path = os.path.relpath(graphics_path, base_dir)\n\n                print >>o_file, float_template.render(\n                    float_type=\"figure\",\n                    float_placement=\"H\",\n                    float_caption=\"Gender check using Plink. Mean $x$ and $y$ \"\n                                  \"intensities are shown for each sample. \"\n                                  \"Males are shown in blue, and females in \"\n                                  \"red. Triangles show problematic samples \"\n                                  \"(green for males, mauve for females). \"\n                                  \"Unknown gender are shown in gray.\",\n                    float_label=figure_label,\n                    float_content=graphic_template.render(\n                        width=r\"0.8\\textwidth\",\n                        path=latex_template.sanitize_fig_name(path),\n                    ),\n                )\n                # Adding the path where the graphic is\n                graphics_paths.add(graphics_path)\n\n            # If there is a 'sexcheck.LRR_BAF' directory, then there are LRR\n            # and BAF plots.\n            if os.path.isdir(script_prefix + \".LRR_BAF\"):\n                figures = glob(\n                    os.path.join(script_prefix + \".LRR_BAF\", \"*.png\"),\n                )\n\n                if len(figures) > 0:\n                    # Getting the sample IDs\n                    sample_ids = [\n                        re.search(\n                            \"^baf_lrr_(\\S+)_lrr_baf.png$\",\n                            os.path.basename(figure),\n                        ) for figure in figures\n                    ]\n                    sample_ids = [\n                        \"unknown sample\" if not sample else sample.group(1)\n                        for sample in sample_ids\n                    ]\n\n                    # Sorting according to sample IDs\n                    sorted_indexes = sorted(range(len(figures)),\n                                            key=figures.__getitem__)\n                    figures = [figures[i] for i in sorted_indexes]\n                    sample_ids = [sample_ids[i] for i in sorted_indexes]\n\n                    # Getting the labels\n                    labels = [\n                        re.sub(\n                            r\"[/\\\\]\",\n                            \"_\",\n                            script_prefix + \"_baf_lrr_\" +\n                            os.path.splitext(sample)[0],\n                        ) for sample in sample_ids\n                    ]\n\n                    fig_1 = labels[0]\n                    fig_2 = \"\"\n                    if len(figures) > 1:\n                        fig_2 = labels[-1]\n                    text = (\n                        \"Figure\" + (\"s\" if len(figures) > 1 else \"\") +\n                        r\"~\\ref{\" + fig_1 + \"} \" +\n                        (r\"to \\ref{\" + fig_2 + \"} \" if fig_2 else \"\") +\n                        \"show\" + (\" \" if len(figures) > 1 else \"s \") + \"the \"\n                        \"log R ratio and the B allele frequency versus the \"\n                        \"position on chromosome X and Y for the problematic \"\n                        \"sample{}.\".format(\"s\" if len(figures) > 1 else \"\")\n                    )\n                    print >>o_file, latex_template.wrap_lines(text)\n\n                    zipped = zip(figures, sample_ids, labels)\n                    for figure, sample_id, label in zipped:\n                        sample_id = latex_template.sanitize_tex(sample_id)\n\n                        # Getting the paths\n                        graphics_path, path = os.path.split(figure)\n                        graphics_path = os.path.relpath(graphics_path,\n                                                        base_dir)\n\n                        caption = (\n                            \"Plots showing the log R ratio and the B allele \"\n                            \"frequency for chromosome X and Y (on the left \"\n                            \"and right, respectively) for sample \"\n                            \"{}.\".format(sample_id)\n                        )\n                        print >>o_file, float_template.render(\n                            float_type=\"figure\",\n                            float_placement=\"H\",\n                            float_caption=caption,\n                            float_label=label,\n                            float_content=graphic_template.render(\n                                width=r\"\\textwidth\",\n                                path=latex_template.sanitize_fig_name(path),\n                            ),\n                        )\n                # Adding the path where the graphic is\n                graphics_paths.add(graphics_path)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, \"Number of samples with gender problem\"\n        print >>o_file, \"  - no genetic gender\\t{:,d}\".format(nb_no_genetic)\n        print >>o_file, \"  - discordant gender\\t{:,d}\".format(nb_discordant)\n        print >>o_file, \"---\"\n\n    # We know this step does not produce a new data set, so we return the\n    # original one\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=sex_check.desc,\n        long_description=sex_check.long_desc,\n        graph_path=graphics_paths,\n    )", "response": "Runs step6 (sexcheck).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the :py:mod:`pyGenClean.SexCheck.sex_check` module. The\n    required file type for this module is ``bfile``, hence the need to use the\n    :py:func:`check_input_files` to check if the file input file type is the\n    good one, or to create it if needed.\n\n    .. note::\n        The :py:mod:`pyGenClean.SexCheck.sex_check` module doesn't return\n        usable output files. Hence, this function returns the input file prefix\n        and its type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the plate bias module.", "response": "def run_plate_bias(in_prefix, in_type, out_prefix, base_dir, options):\n    \"\"\"Runs step7 (plate bias).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the :py:mod:`pyGenClean.PlateBias.plate_bias` module.\n    The required file type for this module is ``bfile``, hence the need to use\n    the :py:func:`check_input_files` to check if the file input file type is\n    the good one, or to create it if needed.\n\n    .. note::\n        The :py:mod:`pyGenClean.PlateBias.plate_bias` module doesn't return\n        usable output files. Hence, this function returns the input file prefix\n        and its type.\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"plate_bias\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        plate_bias.main(options)\n    except plate_bias.ProgramError as e:\n        msg = \"plate_bias: {}\".format(e)\n        raise ProgramError(msg)\n\n    # The name of the summary file\n    filename = script_prefix + \".significant_SNPs.summary\"\n    if not os.path.isfile(filename):\n        raise ProgramError(\"{}: no such file\".format(filename))\n\n    # Getting the number of each plate\n    plate_counter = None\n    with open(filename, \"r\") as i_file:\n        header = {\n            name: i for i, name in\n            enumerate(i_file.readline().rstrip(\"\\r\\n\").split(\"\\t\"))\n        }\n        if \"plate\" not in header:\n            msg = \"{}: missing column plate\".format(filename)\n            raise ProgramError(msg)\n\n        # Counting the number of markers for each plate\n        plate_counter = Counter(\n            line.rstrip(\"\\r\\n\").split(\"\\t\")[header[\"plate\"]] for line in i_file\n        )\n\n    # Creating the table\n    table = [[\"plate name\", \"number of markers\"]]\n    for plate_name, number in plate_counter.most_common():\n        table.append([\n            latex_template.sanitize_tex(plate_name),\n            \"{:,d}\".format(number),\n        ])\n\n    # The number of unique markers\n    filename = script_prefix + \".significant_SNPs.txt\"\n    nb_markers = None\n    with open(filename, \"r\") as i_file:\n        nb_markers = len({line.rstrip(\"\\r\\n\") for line in i_file})\n\n    # Getting the p value threshold\n    p_threshold = str(plate_bias.parser.get_default(\"pfilter\"))\n    if \"--pfilter\" in options:\n        p_threshold = str(options[options.index(\"--pfilter\") + 1])\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(plate_bias.pretty_name)\n            text = (\n                \"After performing the plate bias analysis using Plink, a \"\n                \"total of {:,d} unique marker{} had a significant result \"\n                \"({} a value less than {}).\".format(\n                    nb_markers,\n                    \"s\" if nb_markers > 1 else \"\",\n                    r\"\\textit{i.e.}\",\n                    latex_template.format_numbers(p_threshold),\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n            if nb_markers > 0:\n                table_label = re.sub(\n                    r\"[/\\\\]\",\n                    \"_\",\n                    script_prefix,\n                ) + \"_plate_bias\"\n                text = (\n                    r\"Table~\\ref{\" + table_label + \"} summarizes the plate \"\n                    \"bias results.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                # Getting the template\n                longtable_template = latex_template.jinja2_env.get_template(\n                    \"longtable_template.tex\",\n                )\n\n                # The table caption\n                table_caption = (\n                    \"Summary of the plate bias analysis performed by Plink. \"\n                    \"For each plate, the number of significant marker{} is \"\n                    \"shown (threshold of {}). The plates are sorted according \"\n                    \"to the total number of significant results.\".format(\n                        \"s\" if nb_markers > 1 else \"\",\n                        latex_template.format_numbers(p_threshold),\n                    )\n                )\n                print >>o_file, longtable_template.render(\n                    table_caption=table_caption,\n                    table_label=table_label,\n                    nb_col=len(table[1]),\n                    col_alignments=\"lr\",\n                    text_size=\"normalsize\",\n                    header_data=zip(table[0], [1 for i in table[0]]),\n                    tabular_data=table[1:],\n                )\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of markers with plate bias (p<{})\\t\"\n                         \"{:,d}\".format(p_threshold, nb_markers))\n        print >>o_file, \"---\"\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=plate_bias.desc,\n        long_description=plate_bias.long_desc,\n        graph_path=None,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_remove_heterozygous_haploid(in_prefix, in_type, out_prefix, base_dir,\n                                    options):\n    \"\"\"Runs step8 (remove heterozygous haploid).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the\n    :py:mod:`pyGenClean.HeteroHap.remove_heterozygous_haploid` module. The\n    required file type for this module is ``bfile``, hence the need to use the\n    :py:func:`check_input_files` to check if the file input file type is the\n    good one, or to create it if needed.\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"without_hh_genotypes\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        remove_heterozygous_haploid.main(options)\n    except remove_heterozygous_haploid.ProgramError as e:\n        msg = \"remove_heterozygous_haploid: {}\".format(e)\n        raise ProgramError(msg)\n\n    # We get the number of genotypes that were set to missing\n    nb_hh_missing = None\n    with open(script_prefix + \".log\", \"r\") as i_file:\n        nb_hh_missing = re.search(\n            r\"(\\d+) heterozygous haploid genotypes; set to missing\",\n            i_file.read(),\n        )\n    if nb_hh_missing:\n        nb_hh_missing = int(nb_hh_missing.group(1))\n    else:\n        nb_hh_missing = 0\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                remove_heterozygous_haploid.pretty_name\n            )\n            text = (\n                \"After Plink's heterozygous haploid analysis, a total of \"\n                \"{:,d} genotype{} were set to missing.\".format(\n                    nb_hh_missing,\n                    \"s\" if nb_hh_missing > 1 else \"\",\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of heterozygous haploid genotypes set to \"\n                         \"missing\\t{:,d}\".format(nb_hh_missing))\n        print >>o_file, \"---\"\n\n    # We know this step produces an new data set (bfile), so we return it\n    return _StepResult(\n        next_file=os.path.join(out_prefix, \"without_hh_genotypes\"),\n        next_file_type=\"bfile\",\n        latex_summary=latex_file,\n        description=remove_heterozygous_haploid.desc,\n        long_description=remove_heterozygous_haploid.long_desc,\n        graph_path=None,\n    )", "response": "Runs step8 ( remove haploid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning step 9 of find related samples.", "response": "def run_find_related_samples(in_prefix, in_type, out_prefix, base_dir,\n                             options):\n    \"\"\"Runs step9 (find related samples).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the\n    :py:mod:`pyGenClean.RelatedSamples.find_related_samples` module. The\n    required file type for this module is ``bfile``, hence the need to use the\n    :py:func:`check_input_files` to check if the file input file type is the\n    good one, or to create it if needed.\n\n    .. note::\n        The :py:mod:`pyGenClean.RelatedSamples.find_related_samples` module\n        doesn't return usable output files. Hence, this function returns the\n        input file prefix and its type.\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"ibs\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # The IBS2 ratio\n    ibs2_ratio = find_related_samples._ibs2_ratio_default\n    if \"--ibs2-ratio\" in options:\n        ibs2_ratio = options[options.index(\"--ibs2-ratio\") + 1]\n\n    # The indep pairwiase\n    r2_value = find_related_samples._indep_pairwise_r2_default\n    if \"--indep-pairwise\" in options:\n        r2_value = options[options.index(\"--indep-pairwise\") + 3]\n\n    # We run the script\n    try:\n        find_related_samples.main(options)\n    except find_related_samples.ProgramError as e:\n        msg = \"find_related_samples: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Reading the file containing all samples that are related\n    #   - ibs.related_individuals\n    related_samples = set()\n    with open(script_prefix + \".related_individuals\", \"r\") as i_file:\n        header = {\n            name: i for i, name in\n            enumerate(createRowFromPlinkSpacedOutput(i_file.readline()))\n        }\n        for required_col in [\"FID1\", \"IID1\", \"FID2\", \"IID2\"]:\n            if required_col not in header:\n                msg = \"{}: missing column {}\".format(\n                    script_prefix + \".related_individuals\",\n                    required_col,\n                )\n                raise ProgramError(msg)\n\n        # Reading the rest of the data\n        for line in i_file:\n            row = createRowFromPlinkSpacedOutput(line)\n            related_samples.add((row[header[\"FID1\"]], row[header[\"IID1\"]]))\n            related_samples.add((row[header[\"FID2\"]], row[header[\"IID2\"]]))\n\n    # Reading file containing samples that should be discarded\n    #   - ibs.discarded_related_individuals\n    discarded_samples = None\n    with open(script_prefix + \".discarded_related_individuals\", \"r\") as i_file:\n        discarded_samples = {\n            tuple(i.rstrip(\"\\r\\n\").split(\"\\t\")) for i in i_file\n        }\n\n    # Counting the number of markers used for computing IBS values\n    nb_markers_ibs = 0\n    with open(script_prefix + \".pruned_data.bim\", \"r\") as i_file:\n        for line in i_file:\n            nb_markers_ibs += 1\n\n    # Reading the merged related individuals file\n    table = []\n    with open(script_prefix + \".merged_related_individuals\", \"r\") as i_file:\n        for line in i_file:\n            table.append([\n                latex_template.sanitize_tex(item)\n                for item in line.rstrip(\"\\r\\n\").split(\"\\t\")\n            ])\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    graphics_paths = set()\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                find_related_samples.pretty_name,\n            )\n            text = (\n                \"According to Plink relatedness analysis (using {:,d} \"\n                \"marker{}), {:,d} unique sample{} {} related to at least one \"\n                \"other sample. A total of {:,d} sample{} {} randomly selected \"\n                \"for downstream exclusion from the dataset.\".format(\n                    nb_markers_ibs,\n                    \"s\" if nb_markers_ibs > 1 else \"\",\n                    len(related_samples),\n                    \"s\" if len(related_samples) > 1 else \"\",\n                    \"were\" if len(related_samples) > 1 else \"was\",\n                    len(discarded_samples),\n                    \"s\" if len(discarded_samples) > 1 else \"\",\n                    \"were\" if len(discarded_samples) > 1 else \"was\",\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n            # Adding the first figure (if present)\n            fig_1 = script_prefix + \".related_individuals_z1.png\"\n            fig_1_label = re.sub(r\"[/\\\\]\", \"_\", script_prefix) + \"_z1\"\n            if os.path.isfile(fig_1):\n                text = (\n                    r\"Figure~\\ref{\" + fig_1_label + \"} shows $Z_1$ versus \"\n                    r\"$IBS2_{ratio}^\\ast$ for all related samples found by \"\n                    r\"Plink.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n            # Adding the second figure (if present)\n            fig_2 = script_prefix + \".related_individuals_z2.png\"\n            fig_2_label = re.sub(r\"[/\\\\]\", \"_\", script_prefix) + \"_z2\"\n            if os.path.isfile(fig_2):\n                text = (\n                    r\"Figure~\\ref{\" + fig_2_label + \"} shows $Z_2$ versus \"\n                    r\"$IBS2_{ratio}^\\ast$ for all related samples found by \"\n                    r\"Plink.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n            if len(table) > 1:\n                # There is data, so we add\n                table_label = re.sub(r\"[/\\\\]\", \"_\", script_prefix) + \"_related\"\n                text = (\n                    r\"Table~\\ref{\" + table_label + \"} lists the related \"\n                    \"sample pairs with estimated relationship.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n            # Getting the required template\n            float_template = latex_template.jinja2_env.get_template(\n                \"float_template.tex\",\n            )\n            graphic_template = latex_template.jinja2_env.get_template(\n                \"graphics_template.tex\",\n            )\n\n            figures = (fig_1, fig_2)\n            labels = (fig_1_label, fig_2_label)\n            graph_types = (\"$Z_1$\", \"$Z_2$\")\n            for fig, label, graph_type in zip(figures, labels, graph_types):\n                if os.path.isfile(fig):\n                    # Getting the paths\n                    graphics_path, path = os.path.split(fig)\n                    graphics_path = os.path.relpath(graphics_path, base_dir)\n\n                    # Printing\n                    caption = (\n                        graph_type + r\" versus $IBS2_{ratio}^\\ast$ for all \"\n                        \"related samples found by Plink in the IBS analysis.\"\n                    )\n                    print >>o_file, float_template.render(\n                        float_type=\"figure\",\n                        float_placement=\"H\",\n                        float_caption=caption,\n                        float_label=label,\n                        float_content=graphic_template.render(\n                            width=r\"0.8\\textwidth\",\n                            path=latex_template.sanitize_fig_name(path),\n                        ),\n                    )\n                    # Adding the path where the graphic is\n                    graphics_paths.add(graphics_path)\n\n            # Adding the table\n            if len(table) > 1:\n                # Getting the template\n                longtable_template = latex_template.jinja2_env.get_template(\n                    \"longtable_template.tex\",\n                )\n\n                # The table caption\n                table_caption = (\n                    \"List of all related samples with estimated relationship. \"\n                    \"Sample pairs are grouped according to their estimated \"\n                    \"family (the index column).\"\n                )\n                print >>o_file, longtable_template.render(\n                    table_caption=table_caption,\n                    table_label=table_label,\n                    nb_col=len(table[1]),\n                    col_alignments=\"rlllll\",\n                    text_size=\"scriptsize\",\n                    header_data=zip(table[0], [1 for i in table[0]]),\n                    tabular_data=table[1:],\n                )\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of markers used for IBS analysis\\t\"\n                         \"{:,d}\".format(nb_markers_ibs))\n        print >>o_file, (\"Number of unique related samples\\t\"\n                         \"{:,d}\".format(len(related_samples)))\n        print >>o_file, \"---\"\n\n    # The long description\n    long_description = find_related_samples.long_desc.format(\n        ratio=\"{ratio}\",\n        ratio_value=ibs2_ratio,\n        r_squared=r2_value,\n    )\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=find_related_samples.desc,\n        long_description=long_description,\n        graph_path=graphics_paths,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_check_ethnicity(in_prefix, in_type, out_prefix, base_dir, options):\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"ethnicity\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        check_ethnicity.main(options)\n    except check_ethnicity.ProgramError as e:\n        msg = \"check_ethnicity: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Getting the multiplier value\n    multiplier = check_ethnicity.parser.get_default(\"multiplier\")\n    if \"--multiplier\" in options:\n        multiplier = options[options.index(\"--multiplier\") + 1]\n\n    # Getting the population of which the outliers were computed from\n    outliers_of = check_ethnicity.parser.get_default(\"outliers_of\")\n    if \"--outliers-of\" in options:\n        outliers_of = options[options.index(\"--outliers-of\") + 1]\n\n    # Was the reference populations required?\n    skip_ref_pops = \"--skip-ref-pops\" in options\n\n    # Computing the number of outliers\n    outliers = None\n    if not skip_ref_pops:\n        with open(script_prefix + \".outliers\", \"r\") as i_file:\n            outliers = {\n                tuple(line.rstrip(\"\\r\\n\").split(\"\\t\")) for line in i_file\n            }\n\n    # Computing the number of markers used\n    nb_markers_mds = 0\n    with open(script_prefix + \".ibs.pruned_data.bim\", \"r\") as i_file:\n        for line in i_file:\n            nb_markers_mds += 1\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    graphics_paths = set()\n    try:\n        # TODO: IF THIS CHANGE, code in find_outliers needs to change to...\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                check_ethnicity.pretty_name,\n            )\n            text = None\n            if skip_ref_pops:\n                text = (\n                    \"Principal components analysis was performed using {:,d} \"\n                    \"marker{} on the study dataset only.\".format(\n                        nb_markers_mds,\n                        \"s\" if nb_markers_mds > 1 else \"\",\n                    )\n                )\n\n            else:\n                text = (\n                    \"Using {:,d} marker{} and a multiplier of {}, there was a \"\n                    \"total of {:,d} outlier{} of the {} population.\".format(\n                        nb_markers_mds,\n                        \"s\" if nb_markers_mds > 1 else \"\",\n                        multiplier,\n                        len(outliers),\n                        \"s\" if len(outliers) > 1 else \"\",\n                        outliers_of,\n                    )\n                )\n            print >>o_file, latex_template.wrap_lines(text)\n\n            # Adding the figure if it exists\n            fig = script_prefix + \".outliers.png\"\n            if os.path.isfile(fig):\n                # Getting the paths\n                graphics_path, path = os.path.split(fig)\n                graphics_path = os.path.relpath(graphics_path, base_dir)\n\n                # Getting the required template\n                float_template = latex_template.jinja2_env.get_template(\n                    \"float_template.tex\",\n                )\n                graphic_template = latex_template.jinja2_env.get_template(\n                    \"graphics_template.tex\",\n                )\n\n                # The label\n                label = re.sub(r\"[/\\\\]\", \"_\", script_prefix) + \"_outliers\"\n\n                text = (\n                    r\"Figure~\\ref{\" + label + \"} shows the first two \"\n                    \"principal components of the MDS analysis, where outliers \"\n                    \"of the \" + outliers_of + \" population are shown in grey.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                # Printing\n                caption = (\n                    \"MDS plots showing the first two principal components of \"\n                    \"the source dataset with the reference panels. The \"\n                    \"outliers of the {} population are shown in grey, while \"\n                    \"samples of the source dataset that resemble the {} \"\n                    \"population are shown in orange. A multiplier of {} was \"\n                    \"used to find the {:,d} outlier{}.\".format(\n                        outliers_of,\n                        outliers_of,\n                        multiplier,\n                        len(outliers),\n                        \"s\" if len(outliers) > 1 else \"\",\n                    )\n                )\n                print >>o_file, float_template.render(\n                    float_type=\"figure\",\n                    float_placement=\"H\",\n                    float_caption=latex_template.wrap_lines(caption),\n                    float_label=label,\n                    float_content=graphic_template.render(\n                        width=r\"0.8\\textwidth\",\n                        path=latex_template.sanitize_fig_name(path),\n                    ),\n                )\n                # Adding the path where the graphic is\n                graphics_paths.add(graphics_path)\n\n            # Adding the screeplot if it exists\n            fig = script_prefix + \".smartpca.scree_plot.png\"\n            if os.path.isfile(fig):\n                # Getting the paths\n                graphics_path, path = os.path.split(fig)\n                graphics_path = os.path.relpath(graphics_path, base_dir)\n\n                # Getting the required template\n                float_template = latex_template.jinja2_env.get_template(\n                    \"float_template.tex\",\n                )\n                graphic_template = latex_template.jinja2_env.get_template(\n                    \"graphics_template.tex\",\n                )\n\n                # The label\n                label = re.sub(r\"[/\\\\]\", \"_\", script_prefix) + \"_screeplot\"\n\n                text = (\n                    r\"Figure~\\ref{\" + label + \"} shows the scree plot for the \"\n                    \"principal components of the MDS analysis.\"\n                )\n                print >>o_file, latex_template.wrap_lines(text)\n\n                # Printing\n                caption = (\n                    \"Scree plot for the principal components of the MDS \"\n                    \"analysis.\"\n                )\n                print >>o_file, float_template.render(\n                    float_type=\"figure\",\n                    float_placement=\"H\",\n                    float_caption=caption,\n                    float_label=label,\n                    float_content=graphic_template.render(\n                        height=r\"0.95\\textheight\",\n                        path=latex_template.sanitize_fig_name(path),\n                    ),\n                )\n                # Adding the path where the graphic is\n                graphics_paths.add(graphics_path)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of markers used for MDS analysis\\t\"\n                         \"{:,d}\".format(nb_markers_mds))\n        if not skip_ref_pops:\n            print >>o_file, (\"Number of {} outliers\\t\"\n                             \"{:,d}\".format(outliers_of, len(outliers)))\n        print >>o_file, \"---\"\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=check_ethnicity.desc,\n        long_description=check_ethnicity.long_desc,\n        graph_path=graphics_paths,\n    )", "response": "Runs step 10 of check ethnicity."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the flag_maf_zero module.", "response": "def run_flag_maf_zero(in_prefix, in_type, out_prefix, base_dir, options):\n    \"\"\"Runs step11 (flag MAF zero).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the :py:mod:`pyGenClean.FlagMAF.flag_maf_zero` module.\n    The required file type for this module is ``bfile``, hence the need to use\n    the :py:func:`check_input_files` to check if the file input file type is\n    the good one, or to create it if needed.\n\n    .. note::\n        The :py:mod:`pyGenClean.FlagMAF.flag_maf_zero` module doesn't return\n        usable output files. Hence, this function returns the input file prefix\n        and its type.\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"flag_maf_0\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        flag_maf_zero.main(options)\n    except flag_maf_zero.ProgramError as e:\n        msg = \"flag_maf_zero: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Reading the file to compute the number of flagged markers\n    nb_flagged = None\n    flagged_fn = script_prefix + \".list\"\n    with open(flagged_fn, \"r\") as i_file:\n        nb_flagged = len(i_file.read().splitlines())\n\n    # We write a LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                flag_maf_zero.pretty_name\n            )\n            safe_fn = latex_template.sanitize_tex(os.path.basename(flagged_fn))\n            text = (\n                \"After computing minor allele frequencies (MAF) of all \"\n                \"markers using Plink, a total of {:,d} marker{} had a MAF \"\n                \"of zero and were flagged ({}).\".format(\n                    nb_flagged,\n                    \"s\" if nb_flagged - 1 > 1 else \"\",\n                    \"see file \" + latex_template.texttt(safe_fn) +\n                    \" for more information\"\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, (\"Number of markers flagged for MAF of 0\\t\"\n                         \"{:,d}\".format(nb_flagged))\n        print >>o_file, \"---\"\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=flag_maf_zero.desc,\n        long_description=flag_maf_zero.long_desc,\n        graph_path=None,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun step12 of flag HW.", "response": "def run_flag_hw(in_prefix, in_type, out_prefix, base_dir, options):\n    \"\"\"Runs step12 (flag HW).\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the :py:mod:`pyGenClean.FlagHW.flag_hw` module. The\n    required file type for this module is ``bfile``, hence the need to use the\n    :py:func:`check_input_files` to check if the file input file type is the\n    good one, or to create it if needed.\n\n    .. note::\n        The :py:mod:`pyGenClean.FlagHW.flag_hw` module doesn't return usable\n        output files. Hence, this function returns the input file prefix and\n        its type.\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"flag_hw\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        flag_hw.main(options)\n    except flag_hw.ProgramError as e:\n        msg = \"flag_hw: {}\".format(e)\n        raise ProgramError(msg)\n\n    # Finding the two files containing the list of flagged markers\n    filenames = glob(script_prefix + \".snp_flag_threshold_[0-9]*\")\n    thresholds = {}\n    for filename in filenames:\n        # Finding the threshold of the file\n        threshold = re.sub(\n            r\"^flag_hw.snp_flag_threshold_\",\n            \"\",\n            os.path.basename(filename),\n        )\n\n        # Counting the number of markers in the file\n        nb_markers = None\n        with open(filename, \"r\") as i_file:\n            nb_markers = len(i_file.read().splitlines())\n\n        # Saving the values\n        thresholds[threshold] = (nb_markers, filename)\n\n    # We create the LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                flag_hw.pretty_name\n            )\n\n            # Data to write\n            sorted_keys = sorted(thresholds.keys(), key=float)\n\n            text = (\n                \"Markers which failed Hardy-Weinberg equilibrium test (using \"\n                \"Plink) were flagged. A total of {:,d} marker{} failed with a \"\n                \"threshold of {}. A total of {:,d} marker{} failed with a \"\n                \"threshold of {}. For a total list, check the files {} and \"\n                \"{}, respectively.\".format(\n                    thresholds[sorted_keys[0]][0],\n                    \"s\" if thresholds[sorted_keys[0]][0] - 1 > 1 else \"\",\n                    latex_template.format_numbers(sorted_keys[0]),\n                    thresholds[sorted_keys[1]][0],\n                    \"s\" if thresholds[sorted_keys[1]][0] - 1 > 1 else \"\",\n                    latex_template.format_numbers(sorted_keys[1]),\n                    latex_template.texttt(\n                        latex_template.sanitize_tex(os.path.basename(\n                            thresholds[sorted_keys[0]][1],\n                        )),\n                    ),\n                    latex_template.texttt(\n                        latex_template.sanitize_tex(os.path.basename(\n                            thresholds[sorted_keys[1]][1],\n                        )),\n                    ),\n                )\n            )\n            print >>o_file, latex_template.wrap_lines(text)\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # Writing the summary results\n    with open(os.path.join(base_dir, \"results_summary.txt\"), \"a\") as o_file:\n        print >>o_file, \"# {}\".format(script_prefix)\n        print >>o_file, \"Number of markers flagged for HW\"\n        print >>o_file, \"  - {}\\t{:,d}\".format(\n                            sorted_keys[0],\n                            thresholds[sorted_keys[0]][0],\n                        )\n        print >>o_file, \"  - {}\\t{:,d}\".format(\n                            sorted_keys[1],\n                            thresholds[sorted_keys[1]][0],\n                        )\n        print >>o_file, \"---\"\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=flag_hw.desc,\n        long_description=flag_hw.long_desc,\n        graph_path=None,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_compare_gold_standard(in_prefix, in_type, out_prefix, base_dir,\n                              options):\n    \"\"\"Compares with a gold standard data set (compare_gold_standard.\n\n    :param in_prefix: the prefix of the input files.\n    :param in_type: the type of the input files.\n    :param out_prefix: the output prefix.\n    :param base_dir: the output directory.\n    :param options: the options needed.\n\n    :type in_prefix: str\n    :type in_type: str\n    :type out_prefix: str\n    :type base_dir: str\n    :type options: list\n\n    :returns: a tuple containing the prefix of the output files (the input\n              prefix for the next script) and the type of the output files\n              (``bfile``).\n\n    This function calls the :py:mod:`pyGenClean.Misc.compare_gold_standard`\n    module. The required file type for this module is ``bfile``, hence the need\n    to use the :py:func:`check_input_files` to check if the file input file\n    type is the good one, or to create it if needed.\n\n    .. note::\n        The :py:mod:`pyGenClean.Misc.compare_gold_standard` module doesn't\n        return usable output files. Hence, this function returns the input file\n        prefix and its type.\n\n    \"\"\"\n    # Creating the output directory\n    os.mkdir(out_prefix)\n\n    # We know we need bfile\n    required_type = \"bfile\"\n    check_input_files(in_prefix, in_type, required_type)\n\n    # We need to inject the name of the input file and the name of the output\n    # prefix\n    script_prefix = os.path.join(out_prefix, \"compare_with_gold\")\n    options += [\"--{}\".format(required_type), in_prefix,\n                \"--out\", script_prefix]\n\n    # We run the script\n    try:\n        compare_gold_standard.main(options)\n    except compare_gold_standard.ProgramError as e:\n        msg = \"compare_gold_standard: {}\".format(e)\n        raise ProgramError(msg)\n\n    # We create the LaTeX summary\n    latex_file = os.path.join(script_prefix + \".summary.tex\")\n    try:\n        with open(latex_file, \"w\") as o_file:\n            print >>o_file, latex_template.subsection(\n                compare_gold_standard.pretty_name\n            )\n\n    except IOError:\n        msg = \"{}: cannot write LaTeX summary\".format(latex_file)\n        raise ProgramError(msg)\n\n    # We know this step doesn't produce an new data set, so we return the old\n    # prefix and the old in_type\n    return _StepResult(\n        next_file=in_prefix,\n        next_file_type=required_type,\n        latex_summary=latex_file,\n        description=compare_gold_standard.desc,\n        long_description=compare_gold_standard.long_desc,\n        graph_path=None,\n    )", "response": "Compares with a gold standard data set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a command using subprocesses.", "response": "def run_command(command):\n    \"\"\"Run a command using subprocesses.\n\n    :param command: the command to run.\n\n    :type command: list\n\n    Tries to run a command. If it fails, raise a :py:class:`ProgramError`.\n\n    .. warning::\n        The variable ``command`` should be a list of strings (no other type).\n\n    \"\"\"\n    output = None\n    try:\n        output = subprocess.check_output(command, stderr=subprocess.STDOUT,\n                                         shell=False)\n    except subprocess.CalledProcessError:\n        msg = \"couldn't run command\\n{}\".format(command)\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_markers_samples(prefix, file_type):\n    # The files that will need counting\n    sample_file = None\n    marker_file = None\n\n    if file_type == \"bfile\":\n        # Binary files (.bed, .bim and .fam)\n        sample_file = prefix + \".fam\"\n        marker_file = prefix + \".bim\"\n\n    elif file_type == \"file\":\n        # Pedfile (.ped and .map)\n        sample_file = prefix + \".ped\"\n        marker_file = prefix + \".map\"\n\n    elif file_type == \"tfile\":\n        # Transposed pedfile (.tped and .tfam)\n        sample_file = prefix + \".tfam\"\n        marker_file = prefix + \".tped\"\n\n    # Counting (this may take some time)\n    nb_samples = 0\n    with open(sample_file, \"r\") as f:\n        for line in f:\n            nb_samples += 1\n\n    nb_markers = 0\n    with open(marker_file, \"r\") as f:\n        for line in f:\n            nb_markers += 1\n\n    return nb_markers, nb_samples", "response": "Counts the number of markers and samples in a single object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the input files are of the specified type.", "response": "def check_input_files(prefix, the_type, required_type):\n    \"\"\"Check that the file is of a certain file type.\n\n    :param prefix: the prefix of the input files.\n    :param the_type: the type of the input files (bfile, tfile or file).\n    :param required_type: the required type of the input files (bfile, tfile or\n                          file).\n\n    :type prefix: str\n    :type the_type: str\n    :type required_type: str\n\n    :returns: ``True`` if everything is OK.\n\n    Checks if the files are of the required type, according to their current\n    type. The available types are ``bfile`` (binary), ``tfile`` (transposed)\n    and ``file`` (normal).\n\n    \"\"\"\n    # The files required for each type\n    bfile_type = {\".bed\", \".bim\", \".fam\"}\n    tfile_type = {\".tped\", \".tfam\"}\n    file_type = {\".ped\", \".map\"}\n\n    # Check if of bfile, tfile and file\n    plink_command = [\"plink\", \"--noweb\", \"--out\", prefix]\n    if required_type == \"bfile\":\n        # We need bfile\n        plink_command += [\"--make-bed\"]\n        if the_type == \"bfile\":\n            return True\n        elif the_type == \"tfile\":\n            # We have tfile, we need to create bfile from tfile\n            plink_command += [\"--tfile\", prefix]\n        elif the_type == \"file\":\n            # We have file, we need to create bfile from file\n            plink_command += [\"--file\", prefix]\n        else:\n            msg = \"{}: no suitable input format...\".format(prefix)\n            raise ProgramError(msg)\n\n        # We create the required files\n        if os.path.isfile(prefix + \".log\"):\n            # There is a log file... we need to copy it\n            shutil.copyfile(prefix + \".log\", prefix + \".olog\")\n        logger.info(\"Converting {} from {} to {}\".format(\n            prefix,\n            the_type,\n            required_type,\n        ))\n        run_command(plink_command)\n\n        # Everything is now fine\n        return True\n\n    elif required_type == \"tfile\":\n        # We need a tfile\n        plink_command += [\"--recode\", \"--transpose\", \"--tab\"]\n        if the_type == \"tfile\":\n            return True\n        elif the_type == \"bfile\":\n            # We have bfile, we need to create tfile from bfile\n            plink_command += [\"--bfile\", prefix]\n        elif the_type == \"file\":\n            # We have file, we need to create tfile from file\n            plink_command += [\"--file\", prefix]\n        else:\n            msg = \"{}: no suitable input format...\".format(prefix)\n            raise ProgramError(msg)\n\n        # We create the required files\n        if os.path.isfile(prefix + \".log\"):\n            # There is a log file... we need to copy it\n            shutil.copyfile(prefix + \".log\", prefix + \".olog\")\n        logger.info(\"Converting {} from {} to {}\".format(\n            prefix,\n            the_type,\n            required_type,\n        ))\n        run_command(plink_command)\n\n        # Everything is now fine\n        return True\n\n    elif required_type == \"file\":\n        # We need a file\n        plink_command += [\"--recode\", \"--tab\"]\n        if the_type == \"file\":\n            return True\n        elif the_type == \"bfile\":\n            # We have bfile, we need to create file from bfile\n            plink_command += [\"--bfile\", prefix]\n        elif the_type == \"tfile\":\n            # We have tfile, we need to create file from tfile\n            plink_command += [\"--tfile\", prefix]\n        else:\n            msg = \"{}: no suitable input format...\".format(prefix)\n            raise ProgramError(msg)\n\n        # We create the required files\n        if os.path.isfile(prefix + \".log\"):\n            # There is a log file... we need to copy it\n            shutil.copyfile(prefix + \".log\", prefix + \".olog\")\n        logger.info(\"Converting {} from {} to {}\".format(\n            prefix,\n            the_type,\n            required_type,\n        ))\n        run_command(plink_command)\n\n        # Everything is now fine\n        return True\n\n    else:\n        msg = \"{}: unknown file format\".format(required_type)\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if all files exist.", "response": "def all_files_exist(file_list):\n    \"\"\"Check if all files exist.\n\n    :param file_list: the names of files to check.\n\n    :type file_list: list\n\n    :returns: ``True`` if all files exist, ``False`` otherwise.\n\n    \"\"\"\n    all_exist = True\n    for filename in file_list:\n        all_exist = all_exist and os.path.isfile(filename)\n    return all_exist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_config_file(filename):\n    # Creating the config parser\n    config = ConfigParser.RawConfigParser(allow_no_value=True)\n    config.optionxform = str\n    config.read(filename)\n\n    # Checking the section names\n    sections = None\n    try:\n        sections = sorted([int(i) for i in config.sections()])\n    except ValueError:\n        # Section not integer\n        msg = (\"{}: sections must be integers: \"\n               \"{}\".format(filename, config.sections()))\n        raise ProgramError(msg)\n    if sections != range(min(sections), max(sections)+1):\n        # Missing a section\n        msg = \"{}: maybe a section is missing: {}\".format(filename, sections)\n        raise ProgramError(msg)\n    sections = [str(i) for i in sections]\n\n    # Reading the configuration for each sections\n    configuration = {}\n    for section in sections:\n        # Getting the script variable (and check it)\n        script_name = None\n        try:\n            script_name = config.get(section, \"script\")\n        except ConfigParser.NoOptionError:\n            msg = (\"{}: section {}: no variable called 'script'\".format(\n                filename,\n                section,\n            ))\n            raise ProgramError(msg)\n        if script_name not in available_modules:\n            msg = (\"{}: section {}: script {}: invalid script name\".format(\n                filename,\n                section,\n                script_name,\n            ))\n            raise ProgramError(msg)\n\n        # Getting the variables\n        options = []\n        for variable_name, variable_value in config.items(section):\n            unwanted_options = {\"bfile\", \"tfile\", \"file\", \"out\"}\n            if script_name in {\"sample_missingness\", \"subset\"}:\n                unwanted_options |= {\"ifile\", \"is-bfile\", \"is-tfile\"}\n            if script_name == \"subset\":\n                unwanted_options.add(\"is-file\")\n            for unwanted in unwanted_options:\n                if variable_name == unwanted:\n                    msg = (\"{}: section {}: do not use {} as an option for \"\n                           \"{}\".format(filename, section, unwanted,\n                                       script_name))\n                    raise ProgramError(msg)\n            if variable_name != \"script\":\n                options.append(\"--\" + variable_name)\n                if variable_value is not None:\n                    if variable_name in {\"indep-pairwise\", \"sge-nodes\",\n                                         \"ibs-sge-nodes\"}:\n                        # This is a special option\n                        options.extend(variable_value.split(\" \"))\n                    else:\n                        options.append(variable_value)\n\n        # Saving the configuration\n        configuration[section] = (script_name, options)\n\n    return sections, configuration", "response": "Reads the configuration file and returns a tuple of sections and the map containing the configuration options and the value of the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_args(args):\n    # Checking the configuration file\n    if not os.path.isfile(args.conf):\n        msg = \"{}: no such file\".format(args.conf)\n        raise ProgramError(msg)\n\n    # Check the input files\n    if args.bfile is None and args.tfile is None and args.file is None:\n        msg = \"needs one input file prefix (--bfile, --tfile or --file)\"\n        raise ProgramError(msg)\n    if args.bfile is not None and args.tfile is None and args.file is None:\n        for fileName in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\".format(fileName)\n                raise ProgramError(msg)\n    elif args.tfile is not None and args.bfile is None and args.file is None:\n        for fileName in [args.tfile + i for i in [\".tped\", \".tfam\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\".format(fileName)\n                raise ProgramError(msg)\n    elif args.file is not None and args.bfile is None and args.tfile is None:\n        for fileName in [args.file + i for i in [\".ped\", \".map\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\". format(fileName)\n                raise ProgramError(msg)\n    else:\n        msg = \"needs only one input file prefix (--bfile, --tfile or --file)\"\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options and returns True if everything was OK."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef instance(cls, public_keys_dir):\n        '''Please avoid create multi instance'''\n        if public_keys_dir in cls._authenticators:\n            return cls._authenticators[public_keys_dir]\n        new_instance = cls(public_keys_dir)\n        cls._authenticators[public_keys_dir] = new_instance\n        return new_instance", "response": "Please avoid create multi instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_client_key(self, zmq_socket, client_secret_key_path, server_public_key_path):\n        '''must call before bind'''\n        load_and_set_key(zmq_socket, client_secret_key_path)\n        server_public, _ = zmq.auth.load_certificate(server_public_key_path)\n        zmq_socket.curve_serverkey = server_public", "response": "Load and set client key"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _register_nested_router(self, router):\n        assert issubclass(router.__class__, NestedSimpleRouter), \"You can only register NestedSimpleRouters\"\n        self.nested_routers.append(router)", "response": "Register a NestedSimpleRouter instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of urls including all NestedSimpleRouter urls", "response": "def get_urls(self):\n        \"\"\"\n        Returns a list of urls including all NestedSimpleRouter urls\n        \"\"\"\n        ret = super(SimpleRouter, self).get_urls()\n        for router in self.nested_routers:\n            ret.extend(router.get_urls())\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_weld_obj_id(weld_obj, data):\n    obj_id = weld_obj.update(data)\n    if isinstance(data, WeldObject):\n        obj_id = data.obj_id\n        weld_obj.dependencies[obj_id] = data\n\n    return obj_id", "response": "Returns the id of the object with some data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_weld_object(data):\n    weld_obj = create_empty_weld_object()\n    obj_id = get_weld_obj_id(weld_obj, data)\n\n    return obj_id, weld_obj", "response": "Helper method to create a WeldObject and update with data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_placeholder_weld_objects_at_index(dependency_name, length, readable_text, index):\n    weld_objects = []\n\n    for i in range(length):\n        fake_weld_input = Cache.create_fake_array_input(dependency_name, readable_text + '_' + str(i), eval(index))\n        obj_id, weld_obj = create_weld_object(fake_weld_input)\n        weld_obj.weld_code = '{}'.format(obj_id)\n        weld_objects.append(weld_obj)\n\n        Cache.cache_fake_input(obj_id, fake_weld_input)\n\n    return weld_objects", "response": "Helper method that creates a WeldObject for each component of dependency evaluating to a tuple of integers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_weld_literal(scalar, weld_type):\n    try:\n        if isinstance(scalar, int):\n            if isinstance(weld_type, WeldInt16):\n                return '{}si'.format(str(scalar))\n            elif isinstance(weld_type, WeldInt):\n                return str(scalar)\n            elif isinstance(weld_type, WeldLong):\n                return '{}L'.format(str(scalar))\n            elif isinstance(weld_type, WeldFloat):\n                return '{}f'.format(str(scalar))\n            elif isinstance(weld_type, WeldDouble):\n                return '{}.0'.format(str(scalar))\n            else:\n                raise TypeError()\n        elif isinstance(scalar, float):\n            if isinstance(weld_type, WeldFloat):\n                return '{}f'.format(str(scalar))\n            elif isinstance(weld_type, WeldDouble):\n                return str(scalar)\n            else:\n                raise TypeError()\n        elif isinstance(scalar, str):\n            if str(weld_type) == 'vec[i8]':\n                return str(scalar)\n            else:\n                raise TypeError()\n        elif isinstance(scalar, bool):\n            if isinstance(weld_type, WeldBit):\n                return str(scalar).lower()\n            else:\n                raise TypeError()\n        else:\n            raise TypeError()\n    except TypeError:\n        raise TypeError('Cannot convert scalar:{} to type:{}'.format(scalar, weld_type))", "response": "Converts a scalar to a Weld literal."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef weld_combine_scalars(scalars, weld_type):\n    weld_obj = create_empty_weld_object()\n    obj_ids = (get_weld_obj_id(weld_obj, scalar) for scalar in scalars)\n\n    merges = '\\n'.join(('let res = merge(res, {});'.format(obj_id) for obj_id in obj_ids))\n\n    weld_template = \"\"\"let res = appender[{type}];\n{merges}\nresult(res)\n\"\"\"\n\n    weld_obj.weld_code = weld_template.format(type=weld_type,\n                                              merges=merges)\n\n    return weld_obj", "response": "Combine column - wise aggregations into a single array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the scalar casted to the request Weld type.", "response": "def weld_cast_scalar(scalar, to_weld_type):\n    \"\"\"Returns the scalar casted to the request Weld type.\n\n    Parameters\n    ----------\n    scalar : {int, float, WeldObject}\n        Input array.\n    to_weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    if _not_possible_to_cast(scalar, to_weld_type):\n        raise TypeError('Cannot cast scalar of type={} to type={}'.format(type(scalar), to_weld_type))\n\n    weld_obj = create_empty_weld_object()\n    if isinstance(scalar, WeldObject):\n        scalar = get_weld_obj_id(weld_obj, scalar)\n\n    weld_template = '{type}({scalar})'\n\n    weld_obj.weld_code = weld_template.format(scalar=scalar,\n                                              type=to_weld_type)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncasting array to a different type.", "response": "def weld_cast_array(array, weld_type, to_weld_type):\n    \"\"\"Cast array to a different type.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    weld_type : WeldType\n        Type of each element in the input array.\n    to_weld_type : WeldType\n        Desired type.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    if not is_numeric(weld_type) or not is_numeric(to_weld_type):\n        raise TypeError('Cannot cast array of type={} to type={}'.format(weld_type, to_weld_type))\n\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"map(\n    {array},\n    |e: {type}|\n        {to}(e)\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              to=to_weld_type)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weld_arrays_to_vec_of_struct(arrays, weld_types):\n    weld_obj = create_empty_weld_object()\n    obj_ids = [get_weld_obj_id(weld_obj, array) for array in arrays]\n\n    arrays = 'zip({})'.format(', '.join(obj_ids)) if len(obj_ids) > 1 else '{}'.format(obj_ids[0])\n    input_types = struct_of('{e}', weld_types) if len(obj_ids) > 1 else '{}'.format(weld_types[0])\n    res_types = struct_of('{e}', weld_types)\n    to_merge = 'e' if len(obj_ids) > 1 else '{e}'\n\n    weld_template = \"\"\"result(\n    for({arrays},\n        appender[{res_types}],\n        |b: appender[{res_types}], i: i64, e: {input_types}|\n            merge(b, {to_merge})\n    )    \n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(arrays=arrays,\n                                              input_types=input_types,\n                                              res_types=res_types,\n                                              to_merge=to_merge)\n\n    return weld_obj", "response": "Create a vector of structs from multiple arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a struct of vectors.", "response": "def weld_vec_of_struct_to_struct_of_vec(vec_of_structs, weld_types):\n    \"\"\"Create a struct of vectors.\n\n    Parameters\n    ----------\n    vec_of_structs : WeldObject\n        Encoding a vector of structs.\n    weld_types : list of WeldType\n        The Weld types of the arrays in the same order.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(vec_of_structs)\n\n    appenders = struct_of('appender[{e}]', weld_types)\n    types = struct_of('{e}', weld_types)\n    merges = struct_of('merge(b.${i}, e.${i})', weld_types)\n    result = struct_of('result(vecs.${i})', weld_types)\n\n    weld_template = \"\"\"let vecs = for({vec_of_struct},\n    {appenders},\n    |b: {appenders}, i: i64, e: {types}|\n        {merges}\n);\n{result}\n\"\"\"\n\n    weld_obj.weld_code = weld_template.format(vec_of_struct=obj_id,\n                                              appenders=appenders,\n                                              types=types,\n                                              merges=merges,\n                                              result=result)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect a single vector from the struct of vectors.", "response": "def weld_select_from_struct(struct_of_vec, index_to_select):\n    \"\"\"Select a single vector from the struct of vectors.\n\n    Parameters\n    ----------\n    struct_of_vec : WeldObject\n        Encoding a struct of vectors.\n    index_to_select : int\n        Which vec to select from the struct.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(struct_of_vec)\n\n    weld_template = '{struct}.${index}'\n\n    weld_obj.weld_code = weld_template.format(struct=obj_id,\n                                              index=index_to_select)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weld_data_to_dict(keys, keys_weld_types, values, values_weld_types):\n    weld_obj_keys = weld_arrays_to_vec_of_struct(keys, keys_weld_types)\n\n    weld_obj = create_empty_weld_object()\n    keys_obj_id = get_weld_obj_id(weld_obj, weld_obj_keys)\n    values_obj_id = get_weld_obj_id(weld_obj, values)\n\n    keys_types = struct_of('{e}', keys_weld_types)\n    values_types = values_weld_types\n\n    weld_template = \"\"\"result(\n    for(\n        zip({keys}, {values}),\n        dictmerger[{keys_types}, {values_types}, max],\n        |b: dictmerger[{keys_types}, {values_types}, max], i: i64, e: {{{keys_types}, {values_types}}}|\n            merge(b, e)\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(keys=keys_obj_id,\n                                              values=values_obj_id,\n                                              keys_types=keys_types,\n                                              values_types=values_types)\n\n    return weld_obj", "response": "Adds the key - value pairs in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set( self, params ):\n        if self._parameters is not None:\n            self.deconfigure()\n        self.configure(params)\n        return self", "response": "Set the parameters for the experiment returning the current experiment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a properly - structured dict of results.", "response": "def report( self, params, meta, res ):\n        \"\"\"Return a properly-structured dict of results. The default returns a dict with\n        results keyed by :attr:`Experiment.RESULTS`, the data point in the parameter space\n        keyed by :attr:`Experiment.PARAMETERS`, and timing and other metadata keyed\n        by :attr:`Experiment.METADATA`. Overriding this method can be used to record extra\n        values, but be sure to call the base method as well.\n\n        :param params: the parameters we ran under\n        :param meta: the metadata for this run\n        :param res: the direct experimental results from do()\n        :returns: a :term:`results dict`\"\"\"\n        rc = dict()\n        rc[self.PARAMETERS] = params.copy()\n        rc[self.METADATA] = meta.copy()\n        rc[self.RESULTS] = res\n        return rc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run( self ):\n        \n        # perform the experiment protocol\n        params = self.parameters()\n        self._metadata = dict()\n        self._results = None\n        res = None\n        doneSetupTime = doneExperimentTime = doneTeardownTime = None\n        try:\n            # do the phases in order, recording the wallclock times at each phase\n            startTime = datetime.now()\n            self.setUp(params)\n            doneSetupTime = datetime.now()\n            res = self.do(params)\n            doneExperimentTime = datetime.now() \n            self.tearDown()\n            doneTeardownTime = datetime.now() \n            \n            # record the various timings\n            self._metadata[self.START_TIME] = startTime\n            self._metadata[self.END_TIME] = doneTeardownTime\n            self._metadata[self.ELAPSED_TIME] = (doneTeardownTime - startTime).total_seconds()\n            self._metadata[self.SETUP_TIME] = (doneSetupTime - startTime).total_seconds()\n            self._metadata[self.EXPERIMENT_TIME] = (doneExperimentTime - doneSetupTime).total_seconds()\n            self._metadata[self.TEARDOWN_TIME] = (doneTeardownTime - doneExperimentTime).total_seconds()\n            \n            # set the success flag\n            self._metadata[self.STATUS] = True\n        except Exception as e:\n            print(\"Caught exception in experiment: {e}\".format(e = e))\n\n            # grab the traceback before we do anything else\n            #_, _, tb = sys.exc_info()\n            tb = traceback.format_exc()\n            \n            # decide on the cleanup actions that need doing\n            if (doneSetupTime is not None) and (doneExperimentTime is None):\n                # we did the setup and then failed in the experiment, so\n                # we need to do the teardown\n                try:\n                    self.tearDown()\n                except:\n                    pass\n                \n            # set the failure flag and record the exception\n            # (there will be no timing information recorded)\n            self._metadata[self.STATUS] = False\n            self._metadata[self.EXCEPTION] = e\n            self._metadata[self.TRACEBACK] = tb\n                \n        # report the results\n        self._results = res\n        return self.report(params,\n                           self._metadata,\n                           res)", "response": "Runs the experiment and returns the results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef success( self ):\n        if self.STATUS in self.metadata().keys():\n            return (self.metadata())[self.STATUS]\n        else:\n            return False", "response": "Test whether the experiment has been run successfully. This will return True if the experiment has been run and the exception will be stored in the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef results( self ):\n        return self.report(self.parameters(),\n                           self.metadata(),\n                           self.experimentalResults())", "response": "Return a complete dictionary of results for this run. Only really makes sense for\n        recently - executed experimental runs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef SetProperties(has_props_cls, input_dict, include_immutable=True):\n    props = has_props_cls()\n    if not isinstance(input_dict, (dict, collections.OrderedDict)):\n        raise RuntimeError('input_dict invalid: ', input_dict)\n    for k, v in iter(input_dict.items()):\n        if (k in has_props_cls._props and (\n                include_immutable or\n                any(hasattr(has_props_cls._props[k], att) for att in ('required', 'new_name'))\n                )\n           ):\n            p = props._props.get(k)\n            if isinstance(p, properties.HasProperties):\n                props._set(k, SetProperties(p, v, include_immutable=include_immutable))\n            elif isinstance(p, properties.Instance):\n                props._set(k, SetProperties(p.instance_class, v, include_immutable=include_immutable))\n            elif isinstance(p, properties.List):\n                if not isinstance(v, list):\n                    raise RuntimeError('property value mismatch', p, v)\n                if not isinstance(v[0], properties.HasProperties):\n                    prop = p.prop.instance_class\n                    newlist = []\n                    for i in v:\n                        value = SetProperties(prop, i, include_immutable=include_immutable)\n                        newlist.append(value)\n                    props._set(k, newlist)\n                else:\n                    props._set(k, v)\n            else:\n                props._set(k, p.from_json(v))\n\n    # Return others as well\n    # others_dict = {k: v for k, v in iter(input_dict.items())\n    #                if k not in has_props_cls._props}\n    return props", "response": "A helper method to set an object s properties from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a tif file to a 2D NumPy array", "response": "def ReadTif(tifFile):\n        \"\"\"Reads a tif file to a 2D NumPy array\"\"\"\n        img = Image.open(tifFile)\n        img = np.array(img)\n        return img"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GenerateBand(self, band, meta_only=False, cast=False):\n\n        # Read the band data and add it to dictionary\n        if not meta_only:\n            fname = band.get('file_name')\n            data = self.ReadTif('%s/%s' % (os.path.dirname(self.filename), fname))\n            # band['data'] = data # TODO: data is not a properties object so do not set yet\n\n        def FixBitmap(d):\n            p = d.get('bitmap_description')\n            if p:\n                lis = p.get('bit')\n                bm = dict()\n                # Fix bitmap_description from list of dicts to one dict\n                for i in lis:\n                    key = i['num']\n                    value = i['text']\n                    bm[key] = value\n                del d['bitmap_description']\n                d['bitmap_description'] = bm\n            return d\n\n        band = SetProperties(Band, FixBitmap(self.CleanDict(band)))\n        if not meta_only:\n            if cast:\n                # cast as floats and fill bad values with nans\n                data = data.astype(np.float32)\n                data[data==band.fill_value] = -9999\n                if band.valid_range is not None:\n                    data[data<band.valid_range.min] = -9999\n                    data[data>band.valid_range.max] = -9999\n                data[data==-9999] = np.nan\n            else:\n                data = np.ma.masked_where(data==band.fill_value, data)\n                if band.valid_range is not None:\n                    data = np.ma.masked_where(data<band.valid_range.min, data)\n                    data = np.ma.masked_where(data>band.valid_range.max, data)\n            # Flip y axis if requested\n            if self.yflip:\n                data = np.flip(data, 0)\n            band.data = data\n\n        if not meta_only:\n            band.validate()\n\n        return band", "response": "Generates a Band object given a band metadata."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the ESPA XML metadata file and returns a dictionary of the relevant attributes.", "response": "def Read(self, meta_only=False, allowed=None, cast=False):\n        \"\"\"Read the ESPA XML metadata file\"\"\"\n        if allowed is not None and not isinstance(allowed, (list, tuple)):\n            raise RuntimeError('`allowed` must be a list of str names.')\n\n        meta = xmltodict.parse(\n                open(self.filename, 'r').read()\n            ).get('espa_metadata')\n\n        # Handle bands seperately\n        bands = meta.get('bands').get('band')\n        del(meta['bands'])\n\n        if not isinstance(bands, (list)):\n            bands = [bands]\n        meta = self.CleanDict(meta)\n\n        # Get spatial refernce\n        ras = SetProperties(RasterSet, meta)\n\n        if allowed is not None:\n            # Remove non-allowed arrays from bdict\n            for k in list(self.bdict.keys()):\n                if k not in allowed:\n                    del(self.bdict[k])\n\n        for i in range(len(bands)):\n            info = self.GenerateBand(bands[i], meta_only=True, cast=cast)\n            if allowed is not None and info.name not in allowed:\n                continue\n            if info.name not in self.bdict.keys() or self.bdict[info.name].data is None:\n                b = self.GenerateBand(bands[i], meta_only=meta_only, cast=cast)\n                self.bdict[b.name] = b\n            elif cast and self.bdict[info.name].data.dtype != np.float32:\n                b = self.GenerateBand(bands[i], meta_only=meta_only, cast=cast)\n                self.bdict[b.name] = b\n            elif not cast and self.bdict[info.name].data.dtype == np.float32:\n                b = self.GenerateBand(bands[i], meta_only=meta_only, cast=cast)\n                self.bdict[b.name] = b\n        ras.bands = self.bdict\n\n        if not meta_only:\n            ras.validate()\n\n        return ras"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_records(self, rq={}, limit=100, offset=0, sort=None,\n                       fields=None, fields_exclude=FIELDS_EXCLUDE_DEFAULT):\n        \"\"\"\n            rq  Search Query in iDigBio Query Format, using Record Query Fields\n            sort    field to sort on, pick from Record Query Fields\n            fields  a list of fields to return, specified using the fieldName parameter from Fields with type records\n            fields_exclude  a list of fields to exclude, specified using the fieldName parameter from Fields with type records\n            limit   max results\n            offset  skip results\n\n            Returns idigbio record format (legacy api), plus additional top level keys with parsed index terms. Returns None on error.\n        \"\"\"\n        if fields is not None and fields_exclude is FIELDS_EXCLUDE_DEFAULT:\n            fields_exclude = None\n\n        return self._api_post(\"/v2/search/records\",\n                              rq=rq, limit=limit, offset=offset, sort=sort,\n                              fields=fields, fields_exclude=fields_exclude)", "response": "Search for records in iDigBio Query Format"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for a record in iDigBio record format using Media Query and Record Query", "response": "def search_media(self, mq={}, rq={}, limit=100, offset=0, sort=None,\n                     fields=None, fields_exclude=FIELDS_EXCLUDE_DEFAULT):\n        \"\"\"\n            mq  Search Query in iDigBio Query Format, using Media Query Fields\n            rq  Search Query in iDigBio Query Format, using Record Query Fields\n            sort    field to sort on, pick from Media Query Fields\n            fields  a list of fields to return, specified using the fieldName parameter from Fields with type mediarecords\n            fields_exclude  a list of fields to exclude, specified using the fieldName parameter from Fields with type records\n            limit   max results\n            offset  skip results\n\n            Returns idigbio record format (legacy api), plus additional top level keys with parsed index terms. Returns None on error.\n        \"\"\"\n        if fields is not None and fields_exclude is FIELDS_EXCLUDE_DEFAULT:\n            fields_exclude = None\n\n        return self._api_post(\"/v2/search/media\",\n                              rq=rq, mq=mq, limit=limit, offset=offset, sort=sort,\n                              fields=fields, fields_exclude=fields_exclude)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef java_version():\n    result = subprocess.check_output(\n        [c.JAVA, '-version'], stderr=subprocess.STDOUT\n    )\n    first_line = result.splitlines()[0]\n    return first_line.decode()", "response": "Call java and return version information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the commandline help text of the current language of the object.", "response": "def epubcheck_help():\n    \"\"\"Return epubcheck.jar commandline help text.\n\n    :return unicode: helptext from epubcheck.jar\n    \"\"\"\n\n    # tc = locale.getdefaultlocale()[1]\n\n    with open(os.devnull, \"w\") as devnull:\n        p = subprocess.Popen(\n            [c.JAVA, '-Duser.language=en', '-jar', c.EPUBCHECK, '-h'],\n            stdout=subprocess.PIPE,\n            stderr=devnull,\n        )\n        result = p.communicate()[0]\n\n    return result.decode()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_sample_json():\n\n    check = EpubCheck(samples.EPUB3_VALID)\n    with open(samples.RESULT_VALID, 'wb') as jsonfile:\n        jsonfile.write(check._stdout)\n\n    check = EpubCheck(samples.EPUB3_INVALID)\n    with open(samples.RESULT_INVALID, 'wb') as jsonfile:\n        jsonfile.write(check._stdout)", "response": "Generate sample json data for testing"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_files(root, exts=None, recursive=False):\n\n    if exts is not None:\n        exts = set((x.lower() for x in exts))\n\n    def matches(e):\n        return (exts is None) or (e in exts)\n\n    if recursive is False:\n        for entry in compat.scandir(root):\n            if compat.has_scandir:\n                ext = splitext(entry.name)[-1].lstrip('.').lower()\n                if entry.is_file() and matches(ext):\n                    yield entry.path\n            else:\n                ext = splitext(entry)[-1].lstrip('.').lower()\n                if not compat.isdir(entry) and matches(ext):\n                    yield join(root, entry)\n    else:\n        for root, folders, files in compat.walk(root):\n            for f in files:\n                ext = splitext(f)[-1].lstrip('.').lower()\n                if matches(ext):\n                    yield join(root, f)", "response": "Iterate over files within a given root folder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef participate(self, identity, experiment_name, variant):\n        self.set_variant(identity, experiment_name, variant)\n        if self.is_verified_human(identity):\n            self.mark_participant(experiment_name, variant)", "response": "Set the variant for a specific user and mark a participation for the given experiment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert multi - dimensional data to WeldVec types.", "response": "def to_weld_vec(weld_type, ndim):\n    \"\"\"Convert multi-dimensional data to WeldVec types.\n\n    Parameters\n    ----------\n    weld_type : WeldType\n        WeldType of data.\n    ndim : int\n        Number of dimensions.\n\n    Returns\n    -------\n    WeldVec\n        WeldVec of 1 or more dimensions.\n\n    \"\"\"\n    for i in range(ndim):\n        weld_type = WeldVec(weld_type)\n    return weld_type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the name of the shared library depending on platform.", "response": "def to_shared_lib(name):\n    \"\"\"Return library name depending on platform.\n\n    Parameters\n    ----------\n    name : str\n        Name of library.\n\n    Returns\n    -------\n    str\n        Name of library with extension.\n\n    \"\"\"\n    if sys.platform.startswith('linux'):\n        return name + '.so'\n    elif sys.platform.startswith('darwin'):\n        return name + '.dylib'\n    elif sys.platform.startswith('win'):\n        return name + '.dll'\n    else:\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks given value s type.", "response": "def check_type(value: typing.Any, hint: typing.Optional[type]) -> bool:\n    \"\"\"Check given ``value``'s type.\n\n    :param value: given argument\n    :param hint: expected type of given ``value``.\n                 as like :mod:`typing` interprets, :const:`None` is interpreted\n                 as :class:`types.NoneType`\n    :type hint: :class:`typing.Optional`[:class:`type`]\n\n    \"\"\"\n    if hint is None:\n        hint = NoneType\n    actual_type = type(value)\n    if hint is NoneType:\n        correct = value is None\n    elif hint is typing.Any:\n        correct = True\n    elif hint is typing.Pattern or hint is typing.Match:\n        correct = isinstance(value, hint.impl_type)\n    elif isinstance(hint, typing.TypeVar):\n        # TODO: Check generic\n        correct = True\n    elif issubclass(hint, typing.Callable):\n        actual_type, correct = check_callable(value, hint)\n    elif issubclass(hint, typing.Tuple):\n        actual_type, correct = check_tuple(value, hint)\n    elif issubclass(hint, typing.Union):\n        actual_type, correct = check_union(value, hint)\n    else:\n        correct = isinstance(value, hint)\n    return actual_type, correct"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_return(callable_name: str, r: typing.Any,\n                 hints: typing.Mapping[str, type]) -> None:\n    \"\"\"Check return type, raise :class:`TypeError` if return type is not\n    expected type.\n\n    :param str callable_name: callable name of :func:`~.typechecked` checked\n    :param r: returned result\n    :param hints: assumed type of given ``r``\n\n    \"\"\"\n    correct = True\n    if 'return' not in hints:\n        return\n    _, correct = check_type(r, hints['return'])\n    if not correct:\n        raise TypeError(\n            'Incorrect return type `{}`, expected {}. for: {}'.format(\n                type(r), hints.get('return'), callable_name\n            )\n        )", "response": "Check return type of a given object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_callable(callable_: typing.Callable, hint: type) -> bool:\n    if not callable(callable_):\n        return type(callable_), False\n    if callable(callable_) and not hasattr(callable_, '__code__'):\n        return type(callable_), True\n    hints = typing.get_type_hints(callable_)\n    return_type = hints.pop('return', type(None))\n    signature = inspect.signature(callable_)\n    arg_types = tuple(\n        param.annotation\n        for _, param in signature.parameters.items()\n    )\n    correct = all({\n        any({\n            hint.__args__ is None,\n            hint.__args__ is Ellipsis,\n            hint.__args__ == arg_types,\n        }),\n        any({\n            hint.__result__ is None,\n            hint.__result__ in (typing.Any, return_type)\n        })\n    })\n    return typing.Callable[list(arg_types), return_type], correct", "response": "Check argument type & return type of given callable object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_tuple(data: typing.Tuple,\n                hint: typing.Union[type, typing.TypingMeta]) -> bool:\n    \"\"\"Check argument type & return type of :class:`typing.Tuple`. since it\n    raises check :class:`typing.Tuple` using `isinstance`, so compare in\n    diffrent way\n\n    :param data: tuple given as a argument\n    :param hint: assumed type of given ``data``\n\n    \"\"\"\n    if not isinstance(data, tuple):\n        raise TypeError(\n            'expected {}, not {}'.format(\n                typing._type_repr(hint),\n                'None' if data is None else '{}: {!r}'.format(\n                    typing._type_repr(type(data)),\n                    data\n                )\n            )\n        )\n    tuple_param = hint.__tuple_params__\n    if len(data) != len(tuple_param):\n        raise TypeError('expected tuple size is {}, not {}: '\n                        '{!r}'.format(len(tuple_param), len(data), data))\n    zipped = itertools.zip_longest(data, tuple_param)\n    for i, (v, t) in enumerate(zipped):\n        _, correct = check_type(v, t)\n        if not correct:\n            raise TypeError(\n                '{0}th item `{1}` in tuple must be {2!r}, not: {3!r}'.format(\n                    i, v, t, v\n                )\n            )\n    return hint, True", "response": "Check argument type & return type of tuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_union(data: typing.Union, hint: type) -> bool:\n    r = any(check_type(data, t)[1] for t in hint.__union_params__)\n    if not r:\n        raise TypeError(\n            'expected one of {0!r}, found: {1!r}'.format(\n                hint.__union_params__, type(data)\n            )\n        )\n    return hint, r", "response": "Check argument type & return type of a union."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_arguments(c: typing.Callable,\n                    hints: typing.Mapping[str, typing.Optional[type]],\n                    *args, **kwargs) -> None:\n    \"\"\"Check arguments type, raise :class:`TypeError` if argument type is not\n    expected type.\n\n    :param c: callable object want to check types\n    :param hints: assumed type of given ``c`` result of\n                  :func:`typing.get_type_hints`\n\n    \"\"\"\n    signature = inspect.signature(c)\n    bound = signature.bind(*args, **kwargs)\n    for argument_name, value in bound.arguments.items():\n        try:\n            type_hint = hints[argument_name]\n        except KeyError:\n            continue\n        actual_type, correct = check_type(value, type_hint)\n        if not correct:\n            raise TypeError(\n                'Incorrect type `{}`, expected `{}` for `{}`'.format(\n                    actual_type, type_hint, argument_name\n                )\n            )", "response": "Check arguments type of a given object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the command instance by path.", "response": "def get_cmd_by_path(self, existed_cmd_path):\n        \"\"\"\n        :return:\n        {\n            \"name\": cmd_name,\n            \"cmd\": Resource instance,\n            \"children\": {}\n        }\n        \"\"\"\n        parent = self.tree\n        for cmd_name in existed_cmd_path:\n            try:\n                parent = parent['children'][cmd_name]\n            except KeyError:\n                raise ValueError(\n                    \"Given key [%s] in path %s does not exist in tree.\"\n                    % (cmd_name, existed_cmd_path)\n                )\n        return parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a node to the tree.", "response": "def _add_node(self, cmd_node, cmd_path):\n        \"\"\"\n        :type cmd_path: list or tuple\n        \"\"\"\n        parent = self.tree\n        for cmd_key in cmd_path:\n            if cmd_key not in parent['children']:\n                break\n            parent = parent['children'][cmd_key]\n        parent[\"children\"][cmd_node['name']] = cmd_node\n        return cmd_node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_parent_commands(self, cmd_path, help=None):\n        existed_cmd_end_index = self.index_in_tree(cmd_path)\n        new_path, existed_path = self._get_paths(\n            cmd_path,\n            existed_cmd_end_index,\n        )\n        parent_node = self.get_cmd_by_path(existed_path)\n\n        last_one_index = 1\n        new_path_len = len(new_path)\n        _kwargs = {}\n        for cmd_name in new_path:\n            if last_one_index >= new_path_len:\n                _kwargs['help'] = help\n            sub_cmd = parent_node['cmd'].add_cmd(\n                cmd_name, **_kwargs\n            )\n            parent_node = _mk_cmd_node(cmd_name, sub_cmd)\n            self._add_node(\n                parent_node,\n                existed_path + new_path[:new_path.index(cmd_name)]\n            )\n            last_one_index += 1\n        return parent_node", "response": "Create parent command object in cmd tree then return\n            the last parent command object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the start index of which the element is not in cmd tree.", "response": "def index_in_tree(self, cmd_path):\n        \"\"\"\n        Return the start index of which the element is not in cmd tree.\n        :type cmd_path: list or tuple\n        :return: None if cmd_path already indexed in tree.\n        \"\"\"\n        current_tree = self.tree\n        for key in cmd_path:\n            if key in current_tree['children']:\n                current_tree = current_tree['children'][key]\n            else:\n                return cmd_path.index(key)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_report(outdirname, report_filename, **kwargs):\n    # Checking the required variables\n    if \"steps\" in kwargs:\n        assert \"descriptions\" in kwargs\n        assert \"long_descriptions\" in kwargs\n        assert \"steps_filename\" not in kwargs\n    else:\n        assert \"steps_filename\" in kwargs\n        assert \"descriptions\" not in kwargs\n        assert \"long_descriptions\" not in kwargs\n    assert \"summaries\" in kwargs\n    assert \"background\" in kwargs\n    assert \"project_name\" in kwargs\n    assert \"summary_fn\" in kwargs\n    assert \"report_title\" in kwargs\n    assert \"report_author\" in kwargs\n    assert \"initial_files\" in kwargs\n    assert \"final_nb_markers\" in kwargs\n    assert \"final_nb_samples\" in kwargs\n    assert \"final_files\" in kwargs\n    assert \"plink_version\" in kwargs\n    assert \"graphic_paths_fn\" in kwargs\n\n    # Formatting the background section\n    background_section = _format_background(kwargs[\"background\"])\n\n    # Writing the method steps to a separate file (for access later)\n    steps_filename = None\n    if \"steps_filename\" in kwargs:\n        steps_filename = kwargs[\"steps_filename\"]\n    else:\n        steps_filename = os.path.join(outdirname, \"steps_summary.tex\")\n        with open(steps_filename, \"w\") as o_file:\n            zipped = zip(kwargs[\"steps\"], kwargs[\"descriptions\"],\n                         kwargs[\"long_descriptions\"])\n            for step, desc, long_desc in zipped:\n                if desc.endswith(\".\"):\n                    desc = desc[:-1]\n                step = step.replace(\"_\", r\"\\_\")\n                to_print = latex.item(desc)\n                to_print += \" [{}].\".format(latex.texttt(step))\n                if long_desc is not None:\n                    to_print += \" \" + long_desc\n                print >>o_file, latex.wrap_lines(to_print) + \"\\n\"\n\n    # Adding the content of the results section\n    result_summaries = []\n    for name in kwargs[\"summaries\"]:\n        full_path = os.path.abspath(name)\n        if os.path.isfile(full_path):\n            rel_path = os.path.relpath(full_path, outdirname)\n            result_summaries.append(re.sub(r\"\\\\\", \"/\", rel_path))\n\n    # Reading the initial_files file\n    initial_files = None\n    with open(kwargs[\"initial_files\"], \"r\") as i_file:\n        initial_files = i_file.read().splitlines()\n\n    # Reading the final_files file\n    final_files = None\n    with open(kwargs[\"final_files\"], \"r\") as i_file:\n        final_files = [i.split(\"\\t\")[0] for i in i_file.read().splitlines()]\n\n    # Adding the bibliography content\n    biblio_entry = latex.bib_entry(\n        name=\"pyGenClean\",\n        authors=\"Lemieux Perreault LP, Provost S, Legault MA, Barhdadi A, \"\n                r\"Dub\\'e MP\",\n        title=\"pyGenClean: efficient tool for genetic data clean up before \"\n              \"association testing\",\n        journal=\"Bioinformatics\",\n        year=\"2013\",\n        volume=\"29\",\n        number=\"13\",\n        pages=\"1704--1705\",\n    ) + \"\\n\" * 2 + latex.bib_entry(\n        name=\"plink\",\n        authors=\"Purcell S, Neale B, Todd-Brown K, Thomas L, Ferreira MAR, \"\n                \"Bender D, Maller J, Sklar P, de Bakker PIW, Daly MJ, Sham PC\",\n        title=\"PLINK: a tool set for whole-genome association and \"\n              \"population-based linkage analyses\",\n        journal=\"American Journal of Human Genetics\",\n        year=\"2007\",\n        volume=\"81\",\n        number=\"3\",\n        pages=\"559--575\",\n    ) + \"\\n\" * 2 + latex.bib_entry(\n        name=\"bafRegress\",\n        authors=r\"Goo J, Matthew F, Kurt NH, Jane MR, Kimberly FD, \"\n                r\"Gon{\\c{c}}alo RA, Michael B, Hyun Min K\",\n        title=\"Detecting and estimating contamination of human DNA samples in \"\n              \"sequencing and array-based genotype data\",\n        journal=\"The American Journal of Human Genetics\",\n        year=\"2012\",\n        volume=\"91\",\n        number=\"5\",\n        pages=\"839--848\",\n    )\n\n    # Getting the template\n    main_template = latex.jinja2_env.get_template(\"main_document.tex\")\n\n    # Getting the data\n    today = datetime.today()\n\n    # Reading the graphics path\n    graphic_paths = []\n    if kwargs[\"graphic_paths_fn\"] is not None:\n        with open(kwargs[\"graphic_paths_fn\"], \"r\") as i_file:\n            graphic_paths = [\n                re.sub(r\"\\\\\", \"/\", path) + (\"\" if path.endswith(\"/\") else \"/\")\n                for path in i_file.read().splitlines()\n            ]\n\n    try:\n        with open(report_filename, \"w\") as i_file:\n            # Rendering the template\n            print >>i_file, main_template.render(\n                project_name=latex.sanitize_tex(kwargs[\"project_name\"]),\n                month=today.strftime(\"%B\"),\n                day=today.day,\n                year=today.year,\n                background_content=background_section,\n                result_summaries=result_summaries,\n                bibliography_content=biblio_entry,\n                pygenclean_version=pygenclean_version,\n                plink_version=kwargs[\"plink_version\"],\n                steps_filename=os.path.basename(steps_filename),\n                final_results=_create_summary_table(\n                    kwargs[\"summary_fn\"],\n                    latex.jinja2_env.get_template(\"summary_table.tex\"),\n                    nb_samples=kwargs[\"final_nb_samples\"],\n                    nb_markers=kwargs[\"final_nb_markers\"],\n                ),\n                report_title=latex.sanitize_tex(kwargs[\"report_title\"]),\n                report_author=latex.sanitize_tex(kwargs[\"report_author\"]),\n                initial_files=initial_files,\n                final_files=final_files,\n                final_nb_samples=kwargs[\"final_nb_samples\"],\n                final_nb_markers=kwargs[\"final_nb_markers\"],\n                graphic_paths=graphic_paths,\n            )\n\n    except IOError:\n        msg = \"{}: could not create report\".format(report_filename)\n        raise ProgramError(msg)", "response": "Creates a LaTeX report."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_background(background):\n    # Getting the background\n    if os.path.isfile(background):\n        with open(background, \"r\") as i_file:\n            background = i_file.read().splitlines()\n    else:\n        background = background.splitlines()\n\n    # Formatting\n    final_background = \"\"\n    for line in background:\n        if line == \"\":\n            final_background += r\"\\\\\" + \"\\n\\n\"\n            continue\n\n        final_background += latex.wrap_lines(latex.sanitize_tex(line))\n\n    return final_background", "response": "Formats the background section of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_summary_table(fn, template, nb_samples, nb_markers):\n    # The final data\n    table_data = []\n\n    # Reading the summary file\n    with open(fn, \"r\") as i_file:\n        data = None\n\n        line = i_file.readline()\n        while line != \"\":\n            if line.startswith(\"#\"):\n                # If there is data, this isn't the first line, so we save\n                if data:\n                    table_data.append(data)\n\n                # This is the 'header' of a section (hence a new section)\n                data = dict(\n                    header=line.rstrip(\"\\r\\n\").split(\" \")[1],\n                    data=[],\n                )\n\n                # Changing to next line\n                line = i_file.readline()\n                continue\n\n            # If the line starts with '---', then it's a horizontal line\n            if line.startswith(\"---\"):\n                data[\"data\"].append(dict(hline=True))\n\n                # Changing to next line\n                line = i_file.readline()\n                continue\n\n            # If the line starts with '  -', then it's a sub section\n            if line.startswith(\"  -\"):\n                tmp = line[4:].rstrip(\"\\r\\n\").split(\"\\t\")\n                if data[\"header\"].endswith(\"/subset\"):\n                    if tmp[0].startswith(\"_file_path:\"):\n                        tmp[0] = r\"\\path{\" + tmp[0][11:] + \"}\"\n                elif data[\"header\"].endswith(\"/flag_hw\"):\n                    tmp[0] = latex.format_numbers(tmp[0], prefix=\"p < \")\n                else:\n                    tmp = map(latex.sanitize_tex, tmp)\n                    if tmp[0].startswith(\"x\"):\n                        tmp[0] = latex.inline_math(r\"\\times \" + tmp[0][1:])\n\n                data[\"data\"].append(dict(\n                    hline=False,\n                    multicol=False,\n                    row_data=tmp,\n                ))\n\n                # Changing to next line\n                line = i_file.readline()\n                continue\n\n            # This is a regular line\n            data[\"data\"].append(dict(\n                hline=False,\n                multicol=True,\n                row_data=map(\n                    latex.sanitize_tex,\n                    line.rstrip(\"\\r\\n\").split(\"\\t\"),\n                ),\n            ))\n\n            # Skipping to next line\n            line = i_file.readline()\n\n    # We add the last entry\n    table_data.append(data)\n\n    # Rendering\n    return template.render(table_data=table_data, final_nb_markers=nb_markers,\n                           final_nb_samples=nb_samples)", "response": "Creates the final summary table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef weld_str_lower(array):\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"map(\n    {array},\n    |e: vec[i8]|\n        result(\n            for(e,\n                appender[i8],\n                |c: appender[i8], j: i64, f: i8|\n                    if(f > 64c && f < 91c,\n                        merge(c, f + 32c),\n                        merge(c, f))\n            )\n        )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj", "response": "Convert values to lowercase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert values to uppercase.", "response": "def weld_str_upper(array):\n    \"\"\"Convert values to uppercase.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"map(\n    {array},\n    |e: vec[i8]|\n        result(\n            for(e,\n                appender[i8],\n                |c: appender[i8], j: i64, f: i8|\n                    if(f > 96c && f < 123c,\n                        merge(c, f - 32c),\n                        merge(c, f))\n            )\n        )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weld_str_capitalize(array):\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \"\"\"map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenString > 0L,\n            let res = appender[i8];\n            let firstChar = lookup(e, 0L);\n            let res = if(firstChar > 96c && firstChar < 123c, merge(res, firstChar - 32c), merge(res, firstChar));\n            result(\n                for(slice(e, 1L, lenString - 1L),\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        if(f > 64c && f < 91c,\n                            merge(c, f + 32c),\n                            merge(c, f)\n                        )\n                )\n            ),\n            e)\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj", "response": "Capitalize first letter of the array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving character at index i.", "response": "def weld_str_get(array, i):\n    \"\"\"Retrieve character at index i.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    i : int\n        Index of character to retrieve. If greater than length of string, returns None.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n    index_literal = to_weld_literal(i, WeldLong())\n    missing_literal = default_missing_data_literal(WeldVec(WeldChar()))\n    missing_literal_id = get_weld_obj_id(weld_obj, missing_literal)\n\n    weld_template = \"\"\"map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if({i} >= lenString,\n            {missing},\n            if({i} > 0L,\n                result(merge(appender[i8], lookup(slice(e, 0L, lenString), {i}))),\n                result(merge(appender[i8], lookup(slice(e, lenString, {i}), {i})))\n            )\n        )\n)\"\"\"\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              i=index_literal,\n                                              missing=missing_literal_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef weld_str_strip(array):\n    obj_id, weld_obj = create_weld_object(array)\n\n    # +3L = +1 compensate start_i already +1'ed, +1 compensate end_i already -1'ed, +1 compensate for slice with size\n    weld_template = \"\"\"map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        let res = appender[i8];\n        let start_i = iterate(0L, |p| {{p + 1L, lookup(e, p) == 32c}});\n        let end_i = iterate(lenString - 1L, |p| {{p - 1L, lookup(e, p) == 32c && p > 0L}});\n        slice(e, start_i - 1L, end_i - start_i + 3L)\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj", "response": "Strip whitespace from start and end of elements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef weld_str_slice(array, start=None, stop=None, step=None):\n    obj_id, weld_obj = create_weld_object(array)\n    start = _prepare_slice(start, '0L')\n    stop = _prepare_slice(stop, 'lenString')\n    step = _prepare_slice(step, '1L')\n\n    weld_template = \"\"\"map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        let stop = if({stop} > lenString, lenString, {stop});\n        result(\n            for(iter(e, {start}, stop, {step}),\n                appender[i8],\n                |c: appender[i8], j: i64, f: i8| \n                    merge(c, f)\n            )\n        ) \n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              start=start,\n                                              stop=stop,\n                                              step=step)\n\n    return weld_obj", "response": "Slice each element of the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks which elements start with pattern.", "response": "def weld_str_startswith(array, pat):\n    \"\"\"Check which elements start with pattern.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To check for.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n\n    \"\"\"alternative implementation for reference\n    let res = result(\n        for(zip(slice(e, 0L, lenPat), {pat}),\n            merger[i64, +],\n            |b: merger[i64, +], i: i64, e: {{i8, i8}}|\n                if(e.$0 == e.$1, \n                    merge(b, 1L), \n                    merge(b, 0L)\n                )\n        )\n    );\n    res == lenPat\n    \"\"\"\n\n    weld_template = \"\"\"let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            false,\n            iterate({{0L, true}}, \n                |q| \n                    let found = lookup(e, q.$0) == lookup({pat}, q.$0);\n                    {{\n                        {{q.$0 + 1L, found}}, \n                        q.$0 + 1L < lenPat &&\n                        found == true\n                    }}\n            ).$1\n        )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind sub in array.", "response": "def weld_str_find(array, sub, start, end):\n    \"\"\"Return index of sub in elements if found, else -1.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    sub : str\n        To check for.\n    start : int\n        Start index for searching.\n    end : int or None\n        Stop index for searching.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n    sub_id = get_weld_obj_id(weld_obj, sub)\n\n    if end is None:\n        end = 'len(e)'\n    else:\n        end = to_weld_literal(end, WeldLong())\n\n    start = to_weld_literal(start, WeldLong())\n\n    # TODO: maybe be more friendly and fix end >= len(e) to be len(e) - 1?\n    weld_template = \"\"\"let lenSub = len({sub});\nmap({array},\n    |e: vec[i8]|\n        let start = {start};\n        let size = {end} - start;\n        let string = slice(e, start, size);\n        let lenString = len(string);\n        if(lenSub > lenString,\n            -1L,\n            # start by assuming sub is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and sub are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(string, q.$0) == lookup({sub}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenSub &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenSub < lenString &&\n                        word_check_res == false\n                    }}\n            );\n            if(words_iter_res.$1 == true,\n                words_iter_res.$0 - 1L + start,\n                -1L\n            )\n        )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              sub=sub_id,\n                                              start=start,\n                                              end=end)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces first occurrence of pat with rep.", "response": "def weld_str_replace(array, pat, rep):\n    \"\"\"Replace first occurrence of pat with rep.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To find.\n    rep : str\n        To replace with.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n    rep_id = get_weld_obj_id(weld_obj, rep)\n\n    weld_template = \"\"\"let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            e,\n            # start by assuming sub is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and sub are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(e, q.$0) == lookup({pat}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenPat &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenPat < lenString &&\n                        word_check_res == false\n                    }}\n            );\n            if(words_iter_res.$1 == true,\n                let rep_from = words_iter_res.$0 - 1L;\n                let rep_to = rep_from + lenPat;\n                let res = appender[i8];\n                let res = for(slice(e, 0L, rep_from),\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        merge(c, f)                    \n                );\n                let res = for({rep},\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        merge(c, f)                    \n                );\n                let res = for(slice(e, rep_to, lenString),\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        merge(c, f)                    \n                );\n                result(res),\n                e\n            )\n        )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id,\n                                              rep=rep_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weld_str_split(array, pat, side):\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n\n    left_side_template = \"\"\"let pat_start_index = words_iter_res.$0 - 1L;\nresult(\n    for(slice(e, 0L, pat_start_index),\n        appender[i8],\n        |c: appender[i8], j: i64, f: i8|\n            merge(c, f)   \n    )                 \n)\"\"\"\n    right_side_template = \"\"\"let start_index = words_iter_res.$0 - 1L + lenPat;\nresult(\n    for(slice(e, start_index, lenString),\n        appender[i8],\n        |c: appender[i8], j: i64, f: i8|\n            merge(c, f)   \n    )                 \n)\"\"\"\n\n    weld_template = \"\"\"let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            e,\n            # start by assuming sub is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and sub are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(e, q.$0) == lookup({pat}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenPat &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenPat < lenString &&\n                        word_check_res == false\n                    }}\n            );\n            if(words_iter_res.$1 == true,\n                {side},\n                e\n            )\n        )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id,\n                                              side=left_side_template if side == 0 else right_side_template)\n\n    return weld_obj", "response": "Splits the array into two words and returns the side."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _isPromise(obj):\n    return hasattr(obj, \"fulfill\") and \\\n        _isFunction(getattr(obj, \"fulfill\")) and \\\n        hasattr(obj, \"reject\") and \\\n        _isFunction(getattr(obj, \"reject\")) and \\\n        hasattr(obj, \"then\") and \\\n        _isFunction(getattr(obj, \"then\"))", "response": "A utility function to determine if the specified object is a promise using duck typing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dictPromise(m):\n    ret = Promise()\n\n    def handleSuccess(v, ret):\n        for p in m.values():\n            if not p.isFulfilled():\n                return\n\n        value = {}\n        for k in m:\n            value[k] = m[k].value\n        ret.fulfill(value)\n\n    for p in m.values():\n        p.addCallback(lambda v: handleSuccess(v, ret))\n        p.addErrback(lambda r: ret.reject(r))\n\n    # Check to see if all the promises are already fulfilled\n    handleSuccess(None, ret)\n\n    return ret", "response": "A function that turns a dictionary of promises for values\n    into a promise for a dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fulfill(self, value):\n\n        assert self._state==self.PENDING\n\n        self._state=self.FULFILLED;\n        self.value = value\n        for callback in self._callbacks:\n            try:\n                callback(value)\n            except Exception:\n                # Ignore errors in callbacks\n                pass\n        # We will never call these callbacks again, so allow\n        # them to be garbage collected.  This is important since\n        # they probably include closures which are binding variables\n        # that might otherwise be garbage collected.\n        self._callbacks = []", "response": "Fulfill the promise with a given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reject(self, reason):\n        assert self._state==self.PENDING\n\n        self._state=self.REJECTED;\n        self.reason = reason\n        for errback in self._errbacks:\n            try:\n                errback(reason)\n            except Exception:\n                # Ignore errors in callbacks\n                pass\n\n        # We will never call these errbacks again, so allow\n        # them to be garbage collected.  This is important since\n        # they probably include closures which are binding variables\n        # that might otherwise be garbage collected.\n        self._errbacks = []", "response": "Reject this promise for a given reason."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, timeout=None):\n        self.wait(timeout)\n        if self._state==self.FULFILLED:\n            return self.value\n        else:\n            raise ValueError(\"Calculation didn't yield a value\")", "response": "Get the value of the promise waiting if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait(self, timeout=None):\n        import threading\n\n        if self._state!=self.PENDING:\n            return\n\n        e = threading.Event()\n        self.addCallback(lambda v: e.set())\n        self.addErrback(lambda r: e.set())\n        e.wait(timeout)", "response": "A method that returns when the thread is not in the PENDING state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef samples_from_getdist_chains(params, file_root, latex=False):\n\n    import getdist\n    samples = getdist.loadMCSamples(file_root)\n    weights = samples.weights\n\n    indices = [samples.index[p] for p in params]\n    samps = samples.samples[:, indices]\n    if latex:\n        latex = [samples.parLabel(p) for p in params]\n        return samps, weights, latex\n    else:\n        return samps, weights", "response": "Extract samples and weights from getdist chains."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_session_url(session_id, type='view', **params):\n        url = 'sessions/{}/{}'.format(session_id, type)\n        url = urljoin(API_URL, url)\n        return add_to_url(url, **params)", "response": "Get the URL for a specific session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef checkArgs(args):\n    # Check if we have the tped and the tfam files\n    for fileName in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate connect and block on the listener worker.", "response": "def main(cert, key, pushtoken, url):\n    \"\"\"Create, connect, and block on the listener worker.\"\"\"\n    try:\n        worker = APNSWorker(cert=cert, key=key, pushtoken=pushtoken, url=url)\n        worker.connect()\n        worker.run_forever()\n    except KeyboardInterrupt:\n        worker.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the websocket and ensure the account is connected and ensure the INBOX is being watched and start watchingAll.", "response": "def opened(self):\n        \"\"\"Connect to the websocket, and ensure the account is connected and\n        the INBOX is being watched, and then start watchingAll.\n        \"\"\"\n        def post_setup((cmds, resps)):\n            \"\"\"Post setup callback.\"\"\"\n            logger.info(\"Setup complete, listening...\")\n\n        self.send_cmds(('connect', CONN_SPEC),\n                       ('watchMailboxes', {'account': ACCOUNT,\n                                           'list': ['INBOX']}),\n                       ('watchAll', {})).then(post_setup)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef valuedispatch(func):\n    registry = {}\n    def dispatch(value):\n        return registry.get(value, func)\n    def register(value, func=None):\n        if func is None:\n            return lambda f: register(value, f)\n        registry[value] = func\n        return func\n    def wrapper(*args, **kw):\n        return dispatch(args[0])(*args, **kw)\n    wrapper.register = register\n    wrapper.dispatch = dispatch\n    wrapper.registry = MappingProxyType(registry)\n    update_wrapper(wrapper, func)\n    return wrapper", "response": "Decorates a function to dispatch handler of the value of the first\nCTYPE argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_xref(self, env, fromdocname, builder,\n                     typ, target, node, contnode):\n        # type: (BuildEnvironment, unicode, Builder, unicode, unicode, nodes.Node, nodes.Node) -> nodes.Node  # NOQA\n        \"\"\"Resolve the pending_xref *node* with the given *typ* and *target*.\n\n        This method should return a new node, to replace the xref node,\n        containing the *contnode* which is the markup content of the\n        cross-reference.\n\n        If no resolution can be found, None can be returned; the xref node will\n        then given to the :event:`missing-reference` event, and if that yields no\n        resolution, replaced by *contnode*.\n\n        The method can also raise :exc:`sphinx.environment.NoUri` to suppress\n        the :event:`missing-reference` event being emitted.\n        \"\"\"\n        for fullname, (docname, objtype) in self.data['objects'].items():\n            if fullname.name == target:\n                return make_refnode(builder, fromdocname, docname, fullname2id(fullname), contnode, fullname.name)\n        return None", "response": "Resolve the xref node with the given typ and target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying merge - join on the arrays returning indices from each to keep in the resulting DataFrame.", "response": "def weld_merge_join(arrays_self, weld_types_self, arrays_other, weld_types_other,\n                    how, is_on_sorted, is_on_unique, readable_text):\n    \"\"\"Applies merge-join on the arrays returning indices from each to keep in the resulting\n\n    Parameters\n    ----------\n    arrays_self : list of (numpy.ndarray or WeldObject)\n        Columns from the self DataFrame on which to join.\n    weld_types_self : list of WeldType\n        Corresponding Weld types.\n    arrays_other : list of (numpy.ndarray or WeldObject)\n        Columns from the other DataFrame on which to join.\n    weld_types_other : list of WeldType\n        Corresponding Weld types.\n    how : {'inner', 'left', 'right'}\n        Which kind of join to do.\n    is_on_sorted : bool\n        If we know that the on columns are already sorted, can employ faster algorithm.\n    is_on_unique : bool\n        If we know that the values are unique, can employ faster algorithm.\n    readable_text : str\n        Explanatory string to add in the Weld placeholder.\n\n    Returns\n    -------\n    tuple of WeldObject\n        Two columns of indices from the input arrays, indices of the rows from self and other that should be\n        available in the resulting joined DataFrame.\n\n    \"\"\"\n    assert is_on_unique\n\n    weld_obj_vec_of_struct_self = weld_arrays_to_vec_of_struct(arrays_self, weld_types_self)\n    weld_obj_vec_of_struct_other = weld_arrays_to_vec_of_struct(arrays_other, weld_types_other)\n\n    weld_obj_join = _weld_merge_join(weld_obj_vec_of_struct_self,\n                                     weld_obj_vec_of_struct_other,\n                                     len(arrays_self),\n                                     how,\n                                     is_on_unique)\n\n    intermediate_result = LazyStructOfVecResult(weld_obj_join, [WeldLong(), WeldLong()])\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, readable_text)\n\n    weld_objects = extract_placeholder_weld_objects(dependency_name, 2, readable_text)\n\n    return weld_objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies merge - join on the arrays returning indices from each to keep in the resulting DataFrame.", "response": "def weld_merge_outer_join(arrays_self, weld_types_self, arrays_other, weld_types_other,\n                          how, is_on_sorted, is_on_unique, readable_text):\n    \"\"\"Applies merge-join on the arrays returning indices from each to keep in the resulting\n\n    Parameters\n    ----------\n    arrays_self : list of (numpy.ndarray or WeldObject)\n        Columns from the self DataFrame on which to join.\n    weld_types_self : list of WeldType\n        Corresponding Weld types.\n    arrays_other : list of (numpy.ndarray or WeldObject)\n        Columns from the other DataFrame on which to join.\n    weld_types_other : list of WeldType\n        Corresponding Weld types.\n    how : {'outer'}\n        Here it is not used but kept to maintain same method signature as weld_merge_join\n    is_on_sorted : bool\n        If we know that the on columns are already sorted, can employ faster algorithm.\n    is_on_unique : bool\n        If we know that the values are unique, can employ faster algorithm.\n    readable_text : str\n        Explanatory string to add in the Weld placeholder.\n\n    Returns\n    -------\n    tuple of WeldObject\n        Three objects: first 2 are indices from the input arrays, indices of the rows from self and other that should be\n        available in the resulting joined DataFrame. The last object will be a tuple containing the new index with\n        actual values, not indices to other rows.\n\n    \"\"\"\n    assert is_on_unique\n\n    weld_obj_vec_of_struct_self = weld_arrays_to_vec_of_struct(arrays_self, weld_types_self)\n    weld_obj_vec_of_struct_other = weld_arrays_to_vec_of_struct(arrays_other, weld_types_other)\n\n    weld_obj_join = _weld_merge_outer_join(weld_obj_vec_of_struct_self,\n                                           weld_obj_vec_of_struct_other,\n                                           weld_types_self,\n                                           len(arrays_self),\n                                           is_on_unique)\n\n    intermediate_result = LazyStructResult(weld_obj_join, [WeldVec(WeldLong()),\n                                                           WeldVec(WeldLong()),\n                                                           WeldStruct([WeldVec(weld_type)\n                                                                       for weld_type in weld_types_self])])\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, readable_text)\n\n    weld_objects_indexes = extract_placeholder_weld_objects(dependency_name, 2, readable_text)\n    weld_objects_new_index = extract_placeholder_weld_objects_from_index(dependency_name,\n                                                                         len(weld_types_self),\n                                                                         readable_text,\n                                                                         2)\n\n    return weld_objects_indexes + [weld_objects_new_index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weld_align(df_index_arrays, df_index_weld_types,\n               series_index_arrays, series_index_weld_types,\n               series_data, series_weld_type):\n    \"\"\"Returns the data from the Series aligned to the DataFrame index.\n\n    Parameters\n    ----------\n    df_index_arrays : list of (numpy.ndarray or WeldObject)\n        The index columns as a list.\n    df_index_weld_types : list of WeldType\n    series_index_arrays : numpy.ndarray or WeldObject\n        The index of the Series.\n    series_index_weld_types : list of WeldType\n    series_data : numpy.ndarray or WeldObject\n        The data of the Series.\n    series_weld_type : WeldType\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    weld_obj_index_df = weld_arrays_to_vec_of_struct(df_index_arrays, df_index_weld_types)\n    weld_obj_series_dict = weld_data_to_dict(series_index_arrays,\n                                             series_index_weld_types,\n                                             series_data,\n                                             series_weld_type)\n\n    weld_obj = create_empty_weld_object()\n    df_index_obj_id = get_weld_obj_id(weld_obj, weld_obj_index_df)\n    series_dict_obj_id = get_weld_obj_id(weld_obj, weld_obj_series_dict)\n\n    index_type = struct_of('{e}', df_index_weld_types)\n    missing_literal = default_missing_data_literal(series_weld_type)\n    if series_weld_type == WeldVec(WeldChar()):\n        missing_literal = get_weld_obj_id(weld_obj, missing_literal)\n\n    weld_template = \"\"\"result(\n    for({df_index},\n        appender[{data_type}],\n        |b: appender[{data_type}], i: i64, e: {index_type}|\n            if(keyexists({series_dict}, e),\n                merge(b, lookup({series_dict}, e)),\n                merge(b, {missing})\n            )\n    )\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(series_dict=series_dict_obj_id,\n                                              df_index=df_index_obj_id,\n                                              index_type=index_type,\n                                              data_type=series_weld_type,\n                                              missing=missing_literal)\n\n    return weld_obj", "response": "Aligns the data from the Series to the DataFrame index."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    # Check the number of samples\n    nb_samples = compute_nb_samples(args.tfile)\n\n    # Compute the heterozygosity rate\n    heterozygosity, samples = compute_heterozygosity(args.tfile, nb_samples)\n\n    # Save heterozygosity data\n    save_heterozygosity(heterozygosity, samples, args.out)\n\n    # Plotting the heterozygosity rate distribution\n    plot_heterozygosity(heterozygosity, args)", "response": "The main function of the module."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the heterozygosity data to a file.", "response": "def save_heterozygosity(heterozygosity, samples, out_prefix):\n    \"\"\"Saves the heterozygosity data.\n\n    :param heterozygosity: the heterozygosity data.\n    :param samples: the list of samples.\n    :param out_prefix: the prefix of the output files.\n\n    :type heterozygosity: numpy.array\n    :type samples: list of tuples of str\n    :type out_prefix: str\n\n    \"\"\"\n    # The output file\n    o_file = None\n    try:\n        o_file = open(out_prefix + \".het\", 'wb')\n    except IOError:\n        msg = \"{}.het: can't write file\".format(out_prefix)\n        raise ProgramError(msg)\n\n    # Saving the data\n    for (fid, iid), het in zip(samples, heterozygosity):\n        print >>o_file, \"\\t\".join([fid, iid, str(het)])\n\n    # Closing the file\n    o_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the number of samples in the input file.", "response": "def compute_nb_samples(in_prefix):\n    \"\"\"Check the number of samples.\n\n    :param in_prefix: the prefix of the input file.\n\n    :type in_prefix: str\n\n    :returns: the number of sample in ``prefix.fam``.\n\n    \"\"\"\n    file_name = in_prefix + \".tfam\"\n    nb = None\n    with open(file_name, 'rb') as input_file:\n        nb = len(input_file.readlines())\n    return nb"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_heterozygosity(in_prefix, nb_samples):\n    tped_name = in_prefix + \".tped\"\n    tfam_name = in_prefix + \".tfam\"\n\n    # The function we want to use\n    check_heterozygosity = np.vectorize(is_heterozygous)\n\n    # The autosomes\n    autosomes = {str(i) for i in xrange(1, 23)}\n\n    # The tfam\n    samples = None\n    with open(tfam_name, 'rb') as input_file:\n        samples = input_file.readlines()\n        samples = [tuple(i.rstrip(\"\\r\\n\").split(\"\\t\")[:2]) for i in samples]\n\n    heterozygosity = np.zeros(nb_samples, dtype=int)\n    nb_markers = np.zeros(nb_samples, dtype=int)\n    with open(tped_name, 'rb') as input_file:\n        # There is no header\n        for line in input_file:\n            row = np.array(line.rstrip(\"\\r\\n\").split(\"\\t\"))\n\n            chromosome = row[0]\n            if chromosome not in autosomes:\n                # This is not an autosome, so we skip\n                continue\n\n            # Getting the genotypes\n            genotypes = row[4:]\n\n            # Finding the heterozygous genotypes\n            heterozygosity += check_heterozygosity(genotypes)\n\n            # Adding to number of markers for each samples (excluding no calls)\n            nb_markers += genotypes != \"0 0\"\n\n    return np.true_divide(heterozygosity, nb_markers), samples", "response": "Computes the heterozygosity ratio of samples from tped and tfam files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the heterozygosity rate distribution.", "response": "def plot_heterozygosity(heterozygosity, options):\n    \"\"\"Plots the heterozygosity rate distribution.\n\n    :param heterozygosity: the heterozygosity data.\n    :param options: the options.\n\n    :type heterozygosity: numpy.array\n    :type options: argparse.Namespace\n\n    Plots a histogram or a boxplot of the heterozygosity distribution.\n\n    \"\"\"\n    # importing important stuff\n    import matplotlib as mpl\n    if options.format != \"X11\" and mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    if options.format != \"X11\":\n        plt.ioff()\n\n    # Creating the figure and ax\n    figsize = (13.5, 8)\n    if options.boxplot:\n        figsize = (13.5, 4)\n    fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    # Setting subplot properties\n    ax.xaxis.set_ticks_position(\"bottom\")\n    ax.yaxis.set_ticks_position(\"left\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"bottom\"].set_position((\"outward\", 9))\n    ax.spines[\"left\"].set_position((\"outward\", 9))\n\n    # The title and labels\n    ax.set_title((\"Heterozygosity rate distribution \"\n                  \"({:,} samples)\".format(len(heterozygosity))), weight=\"bold\")\n    ax.set_xlabel(\"Heterozygosity rate\")\n\n    # Plotting the histogram\n    if options.boxplot:\n        # Specific settings for the boxplot\n        ax.yaxis.set_ticks_position(\"none\")\n        ax.spines[\"left\"].set_visible(False)\n        ax.set_yticklabels([])\n        fig.subplots_adjust(bottom=0.18)\n\n        # The boxplot\n        ax.boxplot(heterozygosity, notch=True, vert=False)\n    else:\n        # Specific settings for the histogram\n        ax.set_ylabel(\"Proportion\")\n\n        # The histogram\n        ax.hist(\n            heterozygosity,\n            bins=options.bins,\n            color=\"#0099CC\",\n            histtype=\"stepfilled\",\n            weights=np.zeros_like(heterozygosity) + 1.0 / len(heterozygosity),\n        )\n\n        # Plotting the mean, the median and the variance\n        the_mean = np.mean(heterozygosity)\n        the_median = np.median(heterozygosity)\n        the_variance = np.power(np.std(heterozygosity), 2)\n        mean_line = ax.axvline(the_mean, color=\"#CC0000\", ls=\"--\", lw=2,\n                               clip_on=False)\n        median_line = ax.axvline(the_median, color=\"#FF8800\", ls=\"--\", lw=2,\n                                 clip_on=False)\n        variance_line = ax.axvline(the_variance, color=\"#FFFFFF\", ls=\"--\",\n                                   lw=0, clip_on=False)\n        ax.legend(\n            [mean_line, median_line, variance_line],\n            [\n                \"Mean ({:.4})\".format(the_mean),\n                \"Median ({:.4})\".format(the_median),\n                \"Variance ({:.4})\".format(the_variance),\n            ],\n            loc=\"best\",\n            prop={\"size\": 11},\n        )\n\n        # The ylim\n        if options.ymax is not None:\n            ax.set_ylim(0.0, options.ymax)\n\n    # The xlim\n    if options.xlim is not None:\n        ax.set_xlim(options.xlim)\n\n    # Saving the figure\n    if options.format == \"X11\":\n        plt.show()\n    else:\n        file_name = \"{}.{}\".format(options.out, options.format)\n        if options.boxplot:\n            file_name = \"{}_boxplot.{}\".format(options.out, options.format)\n        plt.savefig(file_name, dpi=300)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkArgs(args):\n    # Checking the input file\n    for file_name in [args.tfile + i for i in {\".tfam\", \".tped\"}]:\n        if not os.path.isfile(file_name):\n            msg = \"{}: no such file\".format(file_name)\n            raise ProgramError(msg)\n\n    # Checking the xlimit\n    if args.xlim is not None:\n        if args.xlim[0] >= args.xlim[1]:\n            msg = \"invalid xlim\"\n            raise ProgramError(msg)\n\n    # Checking the ymax\n    if args.ymax is not None:\n        if args.ymax <= 0:\n            msg = \"invalid ymax (must be above 0)\"\n            raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addEmptyTab(self, text=''):\n        tab = self.defaultTabWidget()\n        c = self.count()\n        self.addTab(tab, text)\n        self.setCurrentIndex(c)\n        if not text:\n            self.tabBar().editTab(c)\n        self.sigTabAdded.emit(tab)\n        return tab", "response": "Add a new empty tab with the given text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that the Add button is visible also when there are no tabs.", "response": "def _mkAddBtnVisible(self):\n        \"\"\"\n        Ensure that the Add button is visible also when there are no tabs\n        \"\"\"\n        if not self._btn_add_height:\n#             self._btn_add_height = self.cornerWidget().height()\n            self._btn_add_height = self._cwBtn.height()\n        if self.count() == 0:\n            \n#             self.cornerWidget().setMinimumHeight(self._btn_add_height - 8)\n            self._cwBtn.setMinimumHeight(self._btn_add_height - 8)\n            self.setMinimumHeight(self._btn_add_height)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nallowing to remove a tab directly - not only by giving its index", "response": "def removeTab(self, tab):\n        \"\"\"allows to remove a tab directly -not only by giving its index\"\"\"\n        if not isinstance(tab, int):\n            tab = self.indexOf(tab)\n        return super(FwTabWidget, self).removeTab(tab)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns text for tab", "response": "def tabText(self, tab):\n        \"\"\" allow index or tab widget instance\"\"\"\n        if not isinstance(tab, int):\n            tab = self.indexOf(tab)\n        return super(FwTabWidget, self).tabText(tab)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a message to the specified phone number", "response": "def send_message(self, number, content):\n        \"\"\"\n        Send message\n        :param str number: phone number with cc (country code)\n        :param str content: body text of the message\n        \"\"\"\n        outgoing_message = TextMessageProtocolEntity(content.encode(\"utf-8\") if sys.version_info >= (3, 0)\n                                                     else content, to=self.normalize_jid(number))\n        self.toLower(outgoing_message)\n        return outgoing_message"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends image message with optional caption", "response": "def send_image(self, number, path, caption=None):\n        \"\"\"\n        Send image message\n        :param str number: phone number with cc (country code)\n        :param str path: image file path\n        \"\"\"\n        return self._send_media_path(number, path, RequestUploadIqProtocolEntity.MEDIA_TYPE_IMAGE, caption)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_audio(self, number, path):\n        return self._send_media_path(number, path, RequestUploadIqProtocolEntity.MEDIA_TYPE_AUDIO)", "response": "Send audio message with number and path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a location message to the local cache", "response": "def send_location(self, number, name, url, latitude, longitude):\n        \"\"\"\n        Send location message\n        :param str number: phone number with cc (country code)\n        :param str name: indentifier for the location\n        :param str url: location url\n        :param str longitude: location longitude\n        :param str latitude: location latitude \n        \"\"\"\n        location_message = LocationMediaMessageProtocolEntity(latitude, longitude, name, url, encoding=\"raw\", \n                                                              to=self.normalize_jid(number))\n        self.toLower(location_message)\n        return location_message"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a vcard message to the location", "response": "def send_vcard(self, number, name, data):\n        \"\"\"\n        Send location message\n        :param str number: phone number with cc (country code)\n        :param str name: indentifier for the location\n        :param str data: vcard format i.e.\n        BEGIN:VCARD\n        VERSION:3.0\n        N:;Home;;;\n        FN:Home\n        item1.TEL:+34 911234567\n        item1.X-ABLabel:Home\n        END:VCARD\n        \"\"\"\n        vcard_message = VCardMediaMessageProtocolEntity(name, data, to=self.normalize_jid(number))\n        self.toLower(vcard_message)\n        return vcard_message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_archive(stream, filename):\n    name, ext = os.path.splitext(os.path.basename(filename))\n\n    def targz_handler(stream):\n        return TarGZAdapter(tarfile.open(fileobj=stream, mode='r:gz'))\n    cls = [zipfile.ZipFile, targz_handler]['gz' in ext]\n    archive = cls(stream)\n    return archive", "response": "Open an archive and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if the archive contains a single prefix.", "response": "def get_prefix_dir(archive):\n    \"\"\"\n    Often, all files are in a single directory. If so, they'll all have\n    the same prefix. Determine any such prefix.\n    archive is a ZipFile\n    \"\"\"\n    names = archive.namelist()\n    shortest_name = sorted(names, key=len)[0]\n    candidate_prefixes = [\n        shortest_name[:length]\n        for length in range(len(shortest_name), -1, -1)\n    ]\n    for prefix in candidate_prefixes:\n        if all(name.startswith(prefix) for name in names):\n            return prefix\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clean_metadata(self):\n        desc = self.metadata.get_long_description()\n        if not isinstance(desc, six.text_type):\n            desc = desc.decode('utf-8')\n        lines = io.StringIO(desc)\n\n        def trim_eight_spaces(line):\n            if line.startswith(' ' * 8):\n                line = line[8:]\n            return line\n        lines = itertools.chain(\n            itertools.islice(lines, 1),\n            six.moves.map(trim_eight_spaces, lines),\n        )\n        self.metadata.long_description = ''.join(lines)", "response": "Clean the metadata so that it can be loaded properly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_nendo ():\n    y, m = map(int, time.strftime(\"%Y %m\").split())\n    return y if m >= 4 else y - 1", "response": "Get the last day of year"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_files(self):\n        '''Find files in `paths` which match valid extensions'''\n        for path in self.paths:\n            for subpath, dirs, files in os.walk(path):\n                for filename in files:\n                    (name, ext) = os.path.splitext(filename)\n                    if ext in self.extensions:\n                        yield os.path.join(subpath, filename)", "response": "Find files in paths which match valid extensions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_boolean(node):\n    return any([\n        isinstance(node, ast.Name)\n        and node.id in ('True', 'False'),\n        hasattr(ast, 'NameConstant')  # Support for Python 3 NameConstant\n        and isinstance(node, getattr(ast, 'NameConstant'))  # screw you pylint!\n        and str(node.value) in ('True', 'False')\n    ])", "response": "Checks if node is True or False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the function call name", "response": "def call_name_is(siter, name):\n    \"\"\"Checks the function call name\"\"\"\n    return (\n        isinstance(siter, ast.Call)\n        and hasattr(siter.func, 'attr')\n        and siter.func.attr == name\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef target_names(targets):\n    names = []\n    for entry in targets:\n        if isinstance(entry, ast.Name):\n            names.append(entry.id)\n        elif isinstance(entry, ast.Tuple):\n            for element in entry.elts:\n                if isinstance(element, ast.Name):\n                    names.append(element.id)\n\n    return names", "response": "Retrieves the target names"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns the running process into a proper daemon according to PEP3143.", "response": "def daemonize(pidfile=None):\n    \"\"\"\n    Turn the running process into a proper daemon according to PEP3143.\n\n    Args:\n    pidfile --The pidfile to create.\n\n    \"\"\"\n\n    # Prevent core dumps\n    resource.setrlimit(resource.RLIMIT_CORE, (0, 0))\n\n    # Change working directory\n    os.chdir(\"/\")\n\n    # Change file creation mask\n    os.umask(0)\n\n    # Detach process context: do double fork\n    pid = os.fork()\n    if pid > 0:\n        os._exit(0)\n    os.setsid()\n    pid = os.fork()\n    if pid > 0:\n        os._exit(0)\n\n    # Create signal handler for SIGTERM\n    def terminate(signal, stack_frame):\n        msg = 'Terminating on signal {}'.format(signal)\n        logger.info(msg)\n        raise SystemExit(msg)\n    signal.signal(signal.SIGTERM, terminate)\n\n    # Redirect input/output streams\n    streams = [sys.stdin, sys.stdout, sys.stderr]\n    for stream in streams:\n        devnull = os.open(os.devnull, os.O_RDWR)\n        os.dup2(devnull, stream.fileno())\n\n    # Close file descriptors\n    for fd in [stream.fileno() for stream in streams]:\n        try:\n            os.close(fd)\n        except OSError as err:\n            if err.errno == errno.EBADF:\n                # File descriptor was not open\n                pass\n\n    # Create pidfile\n    if pidfile is None or pidfile.strip() == '':\n        logger.debug('Empty pidfile set')\n    else:\n        pid = os.getpid()\n        try:\n            with open(pidfile, 'w') as f:\n                f.write('{}\\n'.format(pid))\n                f.close()\n        except EnvironmentError:\n            logger.error('Failed to create pidfile at {}'.format(pidfile))\n\n        def remove_pid_file():\n            os.remove(pidfile)\n\n        atexit.register(remove_pid_file)\n\n    logger.debug('Process daemonized')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_str2dict(option_value):\n    dict = {}\n    for key in option_value.split(','):\n        if ':' in key:\n            key, value = pair.split(':')\n            value = float(value)\n        else:\n            value = 0\n        dict[key] = value\n    return dict", "response": "Parse the value of a config option and convert it to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures logging to syslog.", "response": "def log_to_syslog():\n    \"\"\"\n    Configure logging to syslog.\n\n    \"\"\"\n    # Get root logger\n    rl = logging.getLogger()\n    rl.setLevel('INFO')\n\n    # Stderr gets critical messages (mostly config/setup issues)\n    #   only when not daemonized\n    stderr = logging.StreamHandler(stream=sys.stderr)\n    stderr.setLevel(logging.CRITICAL)\n    stderr.setFormatter(logging.Formatter(\n        '%(asctime)s %(name)s: %(levelname)s %(message)s'))\n    rl.addHandler(stderr)\n\n    # All interesting data goes to syslog, using root logger's loglevel\n    syslog = SysLogHandler(address='/dev/log', facility=SysLogHandler.LOG_MAIL)\n    syslog.setFormatter(logging.Formatter(\n        '%(name)s[%(process)d]: %(levelname)s %(message)s'))\n    rl.addHandler(syslog)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate connect and block on the listener worker.", "response": "def main(sid, token, to, from_, url):\n    \"\"\"Create, connect, and block on the listener worker.\"\"\"\n    try:\n        worker = APNSWorker(sid=sid, token=token, to=to, from_=from_, url=url)\n        worker.connect()\n        worker.run_forever()\n    except KeyboardInterrupt:\n        worker.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a setuptools package requirement print a tree of dependencies as they resolve in this environment.", "response": "def check_dependencies(req, indent=1, history=None):\n    \"\"\"\n    Given a setuptools package requirement (e.g. 'gryphon==2.42' or just\n    'gryphon'), print a tree of dependencies as they resolve in this\n    environment.\n    \"\"\"\n    # keep a history to avoid infinite loops\n    if history is None:\n        history = set()\n    if req in history:\n        return\n    history.add(req)\n    d = pkg_resources.get_distribution(req)\n    extras = parse_extras(req)\n    if indent == 1:\n        print_package(req, 0)\n    for r in d.requires(extras=extras):\n        print_package(r, indent)\n        check_dependencies(r, indent + 1, history)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_dependencies(req, history=None):\n    if history is None:\n        history = set()\n    dist = pkg_resources.get_distribution(req)\n    spec = dict(\n        requirement=str(req),\n        resolved=str(dist),\n    )\n    if req not in history:\n        # traverse into children\n        history.add(req)\n        extras = parse_extras(req)\n        depends = [\n            load_dependencies(dep, history=history)\n            for dep in dist.requires(extras=extras)\n        ]\n        if depends:\n            spec.update(depends=depends)\n    return spec", "response": "Load the dependency tree as a Python object tree suitable for JSON serialization."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninvokes this command on a remote Python.", "response": "def check_dependencies_remote(args):\n    \"\"\"\n    Invoke this command on a remote Python.\n    \"\"\"\n    cmd = [args.python, '-m', 'depends', args.requirement]\n    env = dict(PYTHONPATH=os.path.dirname(__file__))\n    return subprocess.check_call(cmd, env=env)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a single line of data to the server.", "response": "def _send(self, line):\n        \"\"\"\n        Write a line of data to the server.\n\n        Args:\n        line -- A single line of data to write to the socket.\n\n        \"\"\"\n        if not line.endswith('\\r\\n'):\n            if line.endswith('\\n'):\n                logger.debug('Fixing bare LF before sending data to socket')\n                line = line[0:-1] + '\\r\\n'\n            else:\n                logger.debug(\n                    'Fixing missing CRLF before sending data to socket')\n                line = line + '\\r\\n'\n        logger.debug('Client sent: ' + line.rstrip())\n        self._socket.send(line)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read(self):\n        line = ''\n        finished = False\n        while not finished:\n            char = self._socket.recv(1)\n            if char == '':\n                return ''\n            elif char == '\\r':\n                continue\n            elif char == '\\n':\n                finished = True\n                continue\n            else:\n                line = line + char\n        logger.debug('Server sent: ' + line.rstrip())\n        return line", "response": "Read a single response line from the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the next line from the server response.", "response": "def _peek(self, chars=1):\n        \"\"\"\n        Peek at the data in the server response.\n\n        Peeking should only be done when the response can be predicted.\n        Make sure that the socket will not block by requesting too\n        much data from it while peeking.\n\n        Args:\n        chars -- the number of characters to peek.\n\n        \"\"\"\n        line = self._socket.recv(chars, socket.MSG_PEEK)\n        logger.debug('Server sent (peek): ' + line.rstrip())\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to the DSPAM server and processes the server LMTP greeting.", "response": "def connect(self):\n        \"\"\"\n        Connect to TCP or domain socket, and process the server LMTP greeting.\n\n        \"\"\"\n        # extract proto from socket setting\n        try:\n            (proto, spec) = self.socket.split(':')\n        except ValueError:\n            raise DspamClientError(\n                'Failed to parse DSPAM socket specification, '\n                'no proto found: ' + self.socket)\n\n        if proto == 'unix':\n            # connect to UNIX domain socket\n            try:\n                self._socket = socket.socket(\n                    socket.AF_UNIX, socket.SOCK_STREAM)\n                self._socket.connect(spec)\n            except socket.error as err:\n                self._socket = None\n                raise DspamClientError(\n                    'Failed to connect to DSPAM server '\n                    'at socket {}: {}'.format(spec, err))\n            logger.debug('Connected to DSPAM server at socket {}'.format(spec))\n\n        elif proto == 'inet' or proto == 'inet6':\n            # connect to TCP socket\n            try:\n                (port, host) = spec.split('@')\n                port = int(port)\n                if host == '':\n                    host = 'localhost'\n            except ValueError:\n                port = int(spec)\n                host = 'localhost'\n\n            try:\n                self._socket = socket.socket(\n                    socket.AF_INET, socket.SOCK_STREAM)\n                self._socket.connect((host, port))\n            except socket.error as err:\n                self._socket = None\n                raise DspamClientError(\n                    'Failed to connect to DSPAM server at host {} '\n                    'port {}: {}'.format(host, port, err))\n            logger.debug(\n                'Connected to DSPAM server at host {}, port {}'.format(\n                    host, port))\n        else:\n            raise DspamClientError(\n                'Failed to parse DSPAM socket specification, '\n                'unknown proto ' + proto)\n\n        resp = self._read()\n        if not resp.startswith('220'):\n            raise DspamClientError(\n                'Unexpected server response at connect: ' + resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend LHLO greeting and process the server response.", "response": "def lhlo(self):\n        \"\"\"\n        Send LMTP LHLO greeting, and process the server response.\n\n        A regular LMTP greeting is sent, and if accepted by the server, the\n        capabilities it returns are parsed.\n\n        DLMTP authentication starts here by announcing the dlmtp_ident in\n        the LHLO as our hostname. When the ident is accepted and DLMTP\n        mode is enabled (dspam.conf: ServerMode=dspam|auto), the\n        DSPAMPROCESSMODE capability is announced by the server.\n        When this capability is detected, the <DspamClient>.dlmtp flag\n        will be enabled.\n\n        \"\"\"\n        if self.dlmtp_ident is not None:\n            host = self.dlmtp_ident\n        else:\n            host = socket.getfqdn()\n        self._send('LHLO ' + host + '\\r\\n')\n\n        finished = False\n        while not finished:\n            resp = self._read()\n            if not resp.startswith('250'):\n                raise DspamClientError(\n                    'Unexpected server response at LHLO: ' + resp)\n            if resp[4:20] == 'DSPAMPROCESSMODE':\n                self.dlmtp = True\n                logger.debug('Detected DLMTP extension in LHLO response')\n            if resp[3] == ' ':\n                # difference between \"250-8BITMIME\" and \"250 SIZE\"\n                finished = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a MAIL FROM command and process the server response.", "response": "def mailfrom(self, sender=None, client_args=None):\n        \"\"\"\n        Send LMTP MAIL FROM command, and process the server response.\n\n        In DLMTP mode, the server expects the client to identify itself.\n        Because the envelope sender is of no importance to DSPAM, the client\n        is expected to send an identity and a password (dspam.conf:\n        ServerPass.<ident>=\"<password>\") in stead of the actual sender.\n\n        When you need want DSPAM to deliver the message itself and need to\n        pass the server an actual envelope sender for that, add the\n        --mail-from parameter in client_args.\n\n        When the server is setup in LMTP mode only (dspam.conf:\n        ServerMode=standard), the envelope sender is a regular envelope\n        sender, and is re-used when delivering the message after processing.\n\n        Client args\n        ===========\n        When in DLMTP mode (and with proper auth credentials), the server\n        accepts parameters specified by the client. These are in the form\n        as they are passed to the command-line 'dspam' program.\n        See man dspam(1) for details, and the process() or classify() methods\n        in this class for simple examples.\n\n        Args:\n        sender      -- The envelope sender to use in LMTP mode.\n        client_args -- DSPAM parameters to pass to the server in DLMTP mode.\n\n        \"\"\"\n        if sender and client_args:\n            raise DspamClientError('Arguments are mutually exclusive')\n\n        if client_args and not self.dlmtp:\n            raise DspamClientError(\n                'Cannot send client args, server does not support DLMTP')\n\n        command = 'MAIL FROM:'\n        if not sender:\n            if self.dlmtp_ident and self.dlmtp_pass:\n                sender = self.dlmtp_pass + '@' + self.dlmtp_ident\n            else:\n                sender = ''\n        command = command + '<' + sender + '>'\n\n        if client_args:\n            command = command + ' DSPAMPROCESSMODE=\"{}\"'.format(client_args)\n\n        self._send(command + '\\r\\n')\n        resp = self._read()\n        if not resp.startswith('250'):\n            raise DspamClientError(\n                'Unexpected server response at MAIL FROM: ' + resp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rcptto(self, recipients):\n        for rcpt in recipients:\n            self._send('RCPT TO:<{}>\\r\\n'.format(rcpt))\n            resp = self._read()\n            if not resp.startswith('250'):\n                raise DspamClientError(\n                    'Unexpected server response at RCPT TO for '\n                    'recipient {}: {}'.format(rcpt, resp))\n            self._recipients.append(rcpt)", "response": "Sends a LMTP RCPT TO command and processes the response from the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data(self, message):\n        self._send('DATA\\r\\n')\n        resp = self._read()\n        if not resp.startswith('354'):\n            raise DspamClientError(\n                'Unexpected server response at DATA: ' + resp)\n\n        # Send message payload\n        for line in message.split('\\n'):\n            if line == '.':\n                # Dot stuffing\n                line = '..'\n            self._send(line)\n\n        # Send end-of-data\n        self._send('.\\r\\n')\n\n        # Depending on server configuration, several responses are possible:\n        # * Standard LMTP response code, once for each recipient:\n        #   250 2.6.0 <bar> Message accepted for delivery\n        # * Summary response (--deliver=summary), once for each recipient:\n        #   X-DSPAM-Result: bar; result=\"Spam\"; class=\"Spam\"; \\\n        #     probability=1.0000; confidence=0.85; \\\n        #     signature=50c50c0f315636261418125\n        #   (after the last summary line, a single dot is sent)\n        # * Stdout response (--delivery=stdout), once for each recipient:\n        #   X-Daemon-Classification: INNOCENT\n        #   <complete mail body>\n        #\n        # Note that when an unknown recipient is passed in, DSPAM will simply\n        #   deliver the message (dspam.conf: (Un)TrustedDeliveryAgent,\n        #   DeliveryHost) unaltered and unfiltered. The response for unknown\n        #   recipients will still be something indicating 'accepted'.\n\n        peek = self._peek(24)\n        if peek.startswith('250'):\n            # Response is LTMP formatted\n            regex = re.compile('250 \\d\\.\\d\\.\\d <([^>]+)>')\n            finished = False\n            while not finished:\n                resp = self._read()\n                match = regex.match(resp)\n                if not match:\n                    raise DspamClientError(\n                        'Unexpected server response at END-OF-DATA: ' + resp)\n                rcpt = match.group(1)\n                self.results[rcpt] = {'accepted': True}\n                logger.debug(\n                    'Message accepted for recipient {} in LMTP mode'.format(\n                        rcpt))\n                if len(self.results) == len(self._recipients):\n                    finished = True\n\n        elif peek.startswith('X-DSPAM-Result:'):\n            # Response is in summary format\n            regex = re.compile('X-DSPAM-Result: ([^;]+); result=\"(\\w+)\"; '\n                               'class=\"(\\w+)\"; probability=([\\d\\.]+); '\n                               'confidence=([\\d\\.]+); signature=([\\w,/]+)')\n            finished = False\n            while not finished:\n                resp = self._read()\n                match = regex.match(resp)\n                if not match:\n                    raise DspamClientError(\n                        'Unexpected server response at END-OF-DATA: ' + resp)\n                rcpt = match.group(1)\n\n                # map results to their DSPAM classification result names\n                fields = ('user', 'result', 'class',\n                          'probability', 'confidence', 'signature')\n                self.results[rcpt] = dict(zip(fields, match.groups()))\n                if self.results[rcpt]['signature'] == 'N/A':\n                    del(self.results[rcpt]['signature'])\n\n                logger.debug(\n                    'Message handled for recipient {} in DLMTP summary mode, '\n                    'result is {}'.format(rcpt, match.group(2)))\n                if len(self.results) == len(self._recipients):\n                    # we received responses for all accepted recipients\n                    finished = True\n            # read final dot\n            resp = self._read()\n            if resp != '.':\n                raise DspamClientError(\n                    'Unexpected server response at END-OF-DATA: ' + resp)\n\n        elif peek.startswith('X-Daemon-Classification:'):\n            # Response is in stdout format\n            finished = False\n            message = ''\n            while not finished:\n                resp = self._read()\n                if resp.startswith('X-Daemon-Classification:'):\n                    if message != '':\n                        # A new message body starts, store the previous one\n                        rcpt = self._recipients.pop(0)\n                        self.results[rcpt] = {\n                            'result': result,\n                            'message': message\n                        }\n                        logger.debug(\n                            'Message handled for recipient {} in DLMTP '\n                            'stdout mode, result is {}, message body '\n                            'is {} chars'.format(rcpt, result, len(message)))\n                        message = ''\n                    # Remember next result\n                    result = resp[25:]\n\n                elif resp == '.':\n                    # A single dot can signal end-of-data, or might be just\n                    #   regular mail data.\n                    self._socket.setblocking(False)\n                    try:\n                        # If _peek() succeeds, we did not reach end-of-data yet\n                        #   so it was message content.\n                        peek = self._peek(1)\n                        message = message + '\\r\\n' + resp\n                    except socket.error:\n                        # reached end-of-data, store message and finish\n                        finished = True\n                        rcpt = self._recipients.pop(0)\n                        # strip final newline\n                        message = message[0:-2]\n                        self.results[rcpt] = {\n                            'result': result,\n                            'message': message\n                        }\n                        logger.debug(\n                            'Message accepted for recipient {} in DLMTP '\n                            'stdout mode, result is {}, message body '\n                            'is {} chars'.format(rcpt, result, len(message)))\n\n                    self._socket.setblocking(True)\n\n                else:\n                    # regular message data\n                    if message == '':\n                        message = resp\n                    else:\n                        message = message + '\\r\\n' + resp\n\n        else:\n            raise DspamClientError(\n                'Unexpected server response at END-OF-DATA: ' + resp)", "response": "Send a DATA command and process the server response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a RSET command and process the server response.", "response": "def rset(self):\n        \"\"\"\n        Send LMTP RSET command and process the server response.\n\n        \"\"\"\n        self._send('RSET\\r\\n')\n        resp = self._read()\n        if not resp.startswith('250'):\n            logger.warn('Unexpected server response at RSET: ' + resp)\n        self._recipients = []\n        self.results = {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quit(self):\n        self._send('QUIT\\r\\n')\n        resp = self._read()\n        if not resp.startswith('221'):\n            logger.warning('Unexpected server response at QUIT: ' + resp)\n        self._socket.close()\n        self._socket = None\n        self._recipients = []\n        self.results = {}", "response": "Send QUIT command and read the server response and disconnect the connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_resource_method(name, template):\n    def rsr_meth(self, **kwargs):\n        http_method = template['http_method']\n        extra_path = template.get('extra_path')\n        if extra_path:\n            fills = {'res_id': kwargs.pop('res_id', '')}\n            path = self.path + (extra_path % fills)\n        else:\n            path = self.path\n        response = self.client.request(http_method, path, **kwargs)\n\n        loc = response.headers.get('location', None)\n\n        if loc:\n            # If the returned code is a 201, then there should be a location\n            # header in the response that we can use to re-get the newly created\n            # resource.\n            loc = response.headers.get('location')\n            response = self.client.get(loc, **kwargs)\n\n        # At this point, we better have a valid JSON response object\n        try:\n            obj = response.json()\n        except:\n            # The response had no JSON ... not a resource object\n            return\n\n        if COLLECTION_TYPE in response.content_type:\n            ret = HookList(\n                    [Resource(r, path, response, self.client) for r in obj],\n                    response=response\n                    )\n        else:\n            ret = Resource(obj, path, response, self.client)\n        return ret\n\n    rsr_meth.__name__ = name\n    return rsr_meth", "response": "Returns a function that is suitable as a method for ResourceCollection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that will access an attribute off of an object.", "response": "def Getter(accessor, normalizer=lambda x: x):\n    \"\"\"\n    Returns a function that will access an attribute off of an object.  If that\n    attribute is callable, it will call it.  Accepts a normalizer to call on\n    the value at the end.\n    \"\"\"\n    if not callable(accessor):\n        short_description = get_pretty_name(accessor)\n        accessor = attrgetter(accessor)\n    else:\n        short_description = getattr(accessor, 'short_description', None)\n\n    def getter(obj):\n        ret = accessor(obj)\n        # handle things like get_absolute_url\n        if callable(ret):\n            ret = ret()\n        return normalizer(ret)\n\n    if short_description:\n        getter.short_description = short_description\n\n    return getter"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DisplayGetter(accessor, *args, **kwargs):\n    short_description = get_pretty_name(accessor)\n    accessor = 'get_%s_display' % accessor\n    getter = Getter(accessor, *args, **kwargs)\n    getter.short_description = short_description\n    return getter", "response": "Returns a Getter that gets the display name for a model field with choices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initial_step(self, phase, x, y):\n        self.x[0] = x\n        self.y[0] = y\n        self.phase[0] = phase\n        if self.MODE == CordicMode.ROTATION:\n            if phase > 0.5:\n                # > np.pi/2\n                self.x[0] = -x\n                self.phase[0] = phase - 1.0\n            elif phase < -0.5:\n                # < -np.pi/2\n                self.x[0] = -x\n                self.phase[0] = phase + 1.0\n\n        elif self.MODE == CordicMode.VECTORING:\n            if x < 0.0 and y > 0.0:\n                # vector in II quadrant -> initial shift by PI to IV quadrant (mirror)\n                self.x[0] = -x\n                self.y[0] = -y\n                self.phase[0] = 1.0\n                # self.phase[0] = 0.0\n            elif x < 0.0 and y < 0.0:\n                # vector in III quadrant -> initial shift by -PI to I quadrant (mirror)\n                self.x[0] = -x\n                self.y[0] = -y\n                self.phase[0] = -1.0", "response": "This method is called by the main initialization of the cordic."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(self, x, y, phase):\n        self.initial_step(phase, x, y)\n\n        # pipelined CORDIC\n        for i in range(self.ITERATIONS - 1):\n            if self.MODE == CordicMode.ROTATION:\n                direction = self.phase[i] > 0\n            elif self.MODE == CordicMode.VECTORING:\n                direction = self.y[i] < 0\n\n            if direction:\n                self.x[i + 1] = self.x[i] - (self.y[i] >> i)\n                self.y[i + 1] = self.y[i] + (self.x[i] >> i)\n                self.phase[i + 1] = self.phase[i] - self.PHASE_LUT[i]\n            else:\n                self.x[i + 1] = self.x[i] + (self.y[i] >> i)\n                self.y[i + 1] = self.y[i] - (self.x[i] >> i)\n                self.phase[i + 1] = self.phase[i] + self.PHASE_LUT[i]\n\n        return self.x[-1], self.y[-1], self.phase[-1]", "response": "Runs one step of pipelined CORDIC."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding block / unblock of keyboard shortcut", "response": "def blockSignals(self, boolean):\n        \"\"\"add block/unblock of keyboard shortcut\"\"\"\n        pgParameter.blockSignals(self, boolean)\n        try:\n            item = self.items[0]\n            if item.key:\n                item.key.blockSignals(boolean)\n        except:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replaceWith(self, param):\n        i = self.parent().children().index(self)\n        # TODO: transfer the children:\n        p = self.parent()\n        self.parent().removeChild(self)\n        p.insertChild(i, param)\n        self = param", "response": "replace this parameter with another"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deploy(self):\n        self._info(\"* Opening archive: {}\", self.archive_path)\n        if not os.path.exists(self.archive_path):\n            self._error(\"Given path does not exists: {}\", self.archive_path)\n\n        with zipfile.ZipFile(self.archive_path, 'r') as zip_archive:\n            font_dir = self.requirements['font_dir']+'/'\n            allowed_extensions = ['.'+item for item in self.requirements['extensions']]\n            members = [member for member in zip_archive.namelist()]\n\n            if settings.ICOMOON_MANIFEST_FILENAME not in members:\n                raise self._error(\"Icomoon archive must contain a JSON manifest '{}'\", settings.ICOMOON_MANIFEST_FILENAME)\n\n            if font_dir not in members:\n                raise self._error(\"Icomoon archive must contain the font directory '{}'\", font_dir)\n\n            # Scan for supported font files\n            font_files = []\n            for item in members:\n                # Dont catch the font_dir itself nor sub directories, just files with allowed extensions\n                if item.startswith(font_dir) and not item.endswith('/') and os.path.splitext(item)[-1] in allowed_extensions:\n                    font_files.append(item)\n\n            if not font_files:\n                self._error(\"Font dir does not contain any supported format: {}\", ', '.join(allowed_extensions))\n            else:\n                self._debug(\"* Finded font files in archive: {}\", ', '.join(font_files))\n\n            # Extract files from archive\n            tmp_container, css_content = self.extract(zip_archive, font_files)\n\n        # Install files\n        self.install(tmp_container, font_dir, css_content)", "response": "Deploy the webfont into the project static files"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts files to install and return a temporary directory and css content", "response": "def extract(self, zip_archive, font_files):\n        \"\"\"\n        Extract files to install\n        \"\"\"\n        # Get a temp directory\n        tmp_container = tempfile.mkdtemp(prefix='icomoon-tmp')\n        self._debug(\"* Temporary dir for extracted archive: {}\", tmp_container)\n\n        # Extract manifest to temp directory\n        zip_archive.extract(settings.ICOMOON_MANIFEST_FILENAME, tmp_container)\n        # Then the font files\n        for item in font_files:\n            zip_archive.extract(item, tmp_container)\n\n        # Get manifest for icon map\n        webfont_store = WebfontStore(settings.ICOMOON_MANIFEST_FILENAME)\n        webfont_store.get(self.webfont_name, {\n            'fontdir_path': tmp_container,\n        })\n        icons = webfont_store.get_manifests()[self.webfont_name]\n        #print json.dumps(icons, indent=4)\n\n        # Render CSS icon part\n        css_content = self.render_css(self.css_templatepath, icons)\n\n        return tmp_container, css_content"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install(self, tmp_container, font_tmpdir, css_content):\n        # Write builded css file to its destination\n        with open(self.webfont_settings['csspart_path'], 'w') as css_file:\n            css_file.write(css_content)\n\n        # Clean previous font dir\n        if os.path.exists(self.webfont_settings['fontdir_path']):\n            shutil.rmtree(self.webfont_settings['fontdir_path'])\n        font_srcdir = os.path.join(tmp_container, font_tmpdir)\n        self._debug(\"* Installing font\")\n        self._debug(\"  - From: {}\", font_srcdir)\n        self._debug(\"  - To: {}\", self.webfont_settings['fontdir_path'])\n\n        shutil.copytree(font_srcdir, self.webfont_settings['fontdir_path'])\n\n        # Copy new manifest into font dir\n        manifest_src = os.path.join(tmp_container,\n                                    settings.ICOMOON_MANIFEST_FILENAME)\n        self._debug(\"* Installing manifest\")\n        self._debug(\"  - From: {}\", manifest_src)\n        self._debug(\"  - To: {}\", self.webfont_settings['fontdir_path'])\n        shutil.copy(manifest_src, self.webfont_settings['fontdir_path'])\n\n        # Remove temp directory when all is done\n        self._debug(\"* Removing temporary dir\")\n        shutil.rmtree(tmp_container)", "response": "Install extracted files and builded css file into font dir and manifest dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_parser():\n    parser = ArgumentParser(\n        formatter_class=RawDescriptionHelpFormatter,\n        description=DESCRIPTION,\n        epilog=EPILOG,\n        add_help=False)\n\n    directory = parser.add_argument_group(\"Directory\")\n    directory.add_argument(\n        dest='directory',\n        action=\"store\",\n        default=None,\n        nargs=\"?\",\n        help=\"The directory from which to start the search \"\n        \"(defaults to current working directory)\")\n\n    globs = parser.add_argument_group(\"Globs\")\n    globs.add_argument(\n        '-i',\n        '--include',\n        action=\"store\",\n        nargs=\"*\",\n        help=\"One or more Ant-like globs in include in the search.\"\n        \"If not specified, then all files are implied\")\n    globs.add_argument(\n        '-e',\n        '--exclude',\n        action=\"store\",\n        nargs=\"*\",\n        help=\"One or more Ant-like globs in include in the search\")\n    globs.add_argument(\n        '--no-default-excludes',\n        dest=\"default_excludes\",\n        action=\"store_false\",\n        default=True,\n        help=\"Do not include the default excludes\")\n    globs.add_argument(\n        '--no-symlinks',\n        action=\"store_true\",\n        default=False,\n        help=\"Do not include symlinks\")\n    globs.add_argument(\n        '--insensitive',\n        action=\"store_true\",\n        default=False,\n        help=\"Turn off case-sensitive, default sensitive on POSIX, always insensitive on NT.\")\n\n    output = parser.add_argument_group(\"Output\")\n    output.add_argument(\n        '-r',\n        '--relative',\n        action=\"store_true\",\n        default=False,\n        help=\"Print file paths relative to directory.\")\n\n    info = parser.add_argument_group(\"Information\")\n    info.add_argument(\n        '-h',\n        '--help',\n        action='store_true',\n        default=False,\n        help=\"Prints this help and exits\")\n    info.add_argument(\n        '--usage',\n        action='store_true',\n        default=False,\n        help=\"Prints additional help on globs and exits\")\n    info.add_argument(\n        '--version',\n        action='store_true',\n        default=False,\n        help=\"Prints the version of formic and exits\")\n    info.add_argument('--license', action=\"store_true\", help=SUPPRESS)\n    return parser", "response": "Creates and returns the command line parser and an\n     instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommanding line entry point; arguments must match those defined in in :meth:`create_parser()`; returns 0 for success, else 1. Example:: command.main(\"-i\", \"**/*.py\", \"--no-default-excludes\") Runs formic printing out all .py files in the current working directory and its children to ``sys.stdout``. If *kw* is None, :func:`main()` will use ``sys.argv``.", "response": "def main(*kw):\n    \"\"\"Command line entry point; arguments must match those defined in\n    in :meth:`create_parser()`; returns 0 for success, else 1.\n\n    Example::\n\n      command.main(\"-i\", \"**/*.py\", \"--no-default-excludes\")\n\n    Runs formic printing out all .py files in the current working directory\n    and its children to ``sys.stdout``.\n\n    If *kw* is None, :func:`main()` will use ``sys.argv``.\"\"\"\n    parser = create_parser()\n\n    args = parser.parse_args(kw if kw else None)\n    if args.help:\n        parser.print_help()\n    elif args.usage:\n        print(\"\"\"Ant Globs\n=========\n\nApache Ant fileset is documented at the Apache Ant project:\n\n* http://ant.apache.org/manual/dirtasks.html#patterns\n\nExamples\n--------\n\nAnt Globs are like simple file globs (they use ? and * in the same way), but\ninclude powerful ways for selecting directories. The examples below use the\nAnt glob naming, so a leading slash represents the top of the search, *not* the\nroot of the file system.\n\n    *.py\n            Selects every matching file anywhere in the whole tree\n                Matches /foo.py and /bar/foo.py\n                but not /foo.pyc or /bar/foo.pyc/\n\n    /*.py\n            Selects every matching file in the root of the directory (but no\n            deeper).\n\n            Matches /foo.py but not /bar/foo.py\n\n    /myapp/**\n            Matches all files under /myapp and below.\n\n    /myapp/**/__init__.py\n            Matches all __init__.py files /myapp and below.\n\n    dir1/__init__.py\n            Selects every __init__.py in directory dir1. dir1\n            directory can be anywhere in the directory tree\n\n            Matches /dir1/file.py, /dir3/dir1/file.py and\n            /dir3/dir2/dir1/file.py but not /dir1/another/__init__.py.\n\n    **/dir1/__init__.py\n            Same as above.\n\n    /**/dir1/__init__.py\n            Same as above.\n\n    /myapp/**/dir1/__init__.py\n            Selects every __init__.py in dir1 in the directory tree\n            /myapp under the root.\n\n            Matches /myapp/dir1/__init__.py and /myapp/dir2/dir1/__init__.py\n            but not /myapp/file.txt and /dir1/file.txt\n\nDefault excludes\n----------------\n\nAnt FileSet (and Formic) has built-in patterns to screen out a lot of\ndevelopment 'noise', such as hidden VCS files and directories. The full list is\nat:\n\n    * https://formic.readthedocs.io/en/latest/api.html#formic.formic.get_initial_default_excludes\n\nDefault excludes can be simply switched off on both the command line and the\nAPI, for example::\n\n    $ formic -i \"*.py\" -e \"__init__.py\" \"**/*test*/\" \"test_*\" --no-default-excludes\n\"\"\")\n    elif args.version:\n        print(\"formic\", get_version())\n    elif args.license:\n        print(resource_string(__name__, \"LICENSE.txt\"))\n    else:\n        try:\n            fileset = FileSet(\n                directory=args.directory,\n                include=args.include if args.include else [\"*\"],\n                exclude=args.exclude,\n                default_excludes=args.default_excludes,\n                symlinks=not args.no_symlinks,\n                casesensitive=not args.insensitive)\n        except FormicError as exception:\n            parser.print_usage()\n            print(exception.message)\n            return 1\n\n        prefix = fileset.get_directory()\n        for directory, file_name in fileset.files():\n            if args.relative:\n                sys.stdout.write(\".\")\n            else:\n                sys.stdout.write(prefix)\n            if directory:\n                sys.stdout.write(os.path.sep)\n                sys.stdout.write(directory)\n            sys.stdout.write(os.path.sep)\n            sys.stdout.write(file_name)\n            sys.stdout.write(\"\\n\")\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_version(project_name=None, project_dir=os.curdir,\n                        repo_dir=None):\n    \"\"\"\n    Retrieves the version of the package, checking in this order of priority:\n\n    * From an environment variable named ${project_name}_VERSION (all in caps)\n      if project_name was specified.\n    * From the PKG-INFO file if inside a packaged distro.\n    * From the git history.\n\n    Args:\n        project_name(str): Name of the project to get the version for, if none\n            passed, will not use any environment variable override.\n\n    Returns:\n        str: Version for the package.\n\n    Raises:\n        RuntimeError: If the version could not be retrieved.\n    \"\"\"\n    if project_name is not None:\n        version_env_var = '%s_VERSION' % project_name.upper()\n\n        if version_env_var in os.environ and os.environ[version_env_var]:\n            return os.environ[version_env_var]\n\n    version = None\n    repo_dir = repo_dir or project_dir\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    if os.path.exists(pkg_info_file):\n        with open(pkg_info_file) as info_fd:\n            for line in info_fd.readlines():\n                if line.startswith('Version: '):\n                    version = line.split(' ', 1)[-1]\n\n    if version is None:\n        try:\n            version = api.get_current_version(repo_path=repo_dir)\n        except:\n            pass\n\n    if version is None:\n        if project_name:\n            try:\n                distribution = pkg_resources.get_distribution(project_name)\n                if distribution.has_version():\n                    version = distribution.version\n            except:\n                pass\n\n    if version is None:\n        raise RuntimeError('Failed to get package version')\n\n    # py3 compatibility step\n    if not isinstance(version, str) and isinstance(version, bytes):\n        version = api._to_str(version)\n\n    return version", "response": "Get the current version of the package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the authors list from the AUTHORS file if in a package or generates it from the git history.", "response": "def get_authors(project_dir=os.curdir):\n    \"\"\"\n    Retrieves the authors list, from the AUTHORS file (if in a package) or\n    generates it from the git history.\n\n    Returns:\n        list(str): List of authors\n\n    Raises:\n        RuntimeError: If the authors could not be retrieved\n    \"\"\"\n    authors = set()\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    authors_file = os.path.join(project_dir, 'AUTHORS')\n    if os.path.exists(pkg_info_file) and os.path.exists(authors_file):\n        with open(authors_file) as authors_fd:\n            authors = set(authors_fd.read().splitlines())\n    else:\n        authors = api.get_authors(repo_path=project_dir)\n\n    return authors"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the changelog from the CHANGELOG file if in a package or from the git history. Optionally in rpm - compatible format.", "response": "def get_changelog(project_dir=os.curdir, bugtracker_url='', rpm_format=False):\n    \"\"\"\n    Retrieves the changelog, from the CHANGELOG file (if in a package) or\n    generates it from the git history. Optionally in rpm-compatible format.\n\n    :param project_dir: Path to the git repo of the project.\n    :type project_dir: str\n    :param bugtracker_url: Url to the bug tracker for the issues.\n    :type bugtracker_url: str\n    :param rpm_format: if set to True, will make the changelog rpm-compatible\n    :returns: changelog\n    :rtype: str\n    :rises RuntimeError: If the changelog could not be retrieved\n    \"\"\"\n    changelog = ''\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    changelog_file = os.path.join(project_dir, 'CHANGELOG')\n    if os.path.exists(pkg_info_file) and os.path.exists(changelog_file):\n        with open(changelog_file) as changelog_fd:\n            changelog = changelog_fd.read()\n\n    else:\n        changelog = api.get_changelog(\n            repo_path=project_dir,\n            bugtracker_url=bugtracker_url,\n            rpm_format=rpm_format,\n        )\n\n    return changelog"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_releasenotes(project_dir=os.curdir, bugtracker_url=''):\n    releasenotes = ''\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    releasenotes_file = os.path.join(project_dir, 'RELEASE_NOTES')\n    if os.path.exists(pkg_info_file) and os.path.exists(releasenotes_file):\n        with open(releasenotes_file) as releasenotes_fd:\n            releasenotes = releasenotes_fd.read()\n\n    else:\n        releasenotes = api.get_releasenotes(\n            repo_path=project_dir,\n            bugtracker_url=bugtracker_url,\n        )\n\n    return releasenotes", "response": "Retrieves the release notes from the RELEASE_NOTES file if in a package or generates it from the git history."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_authors(project_dir=os.curdir):\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    authors_file = os.path.join(project_dir, 'AUTHORS')\n    if os.path.exists(pkg_info_file):\n        return\n\n    authors = get_authors(project_dir=project_dir)\n    with open(authors_file, 'wb') as authors_fd:\n        authors_fd.write(\n            b'\\n'.join(a.encode('utf-8') for a in authors) + b'\\n'\n        )", "response": "Creates the authors file if not in a package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_changelog(project_dir=os.curdir, bugtracker_url='',\n                     rpm_format=False):\n    \"\"\"\n    Creates the changelog file, if not in a package.\n\n    :param project_dir: Path to the git repo of the project.\n    :type project_dir: str\n    :param bugtracker_url: Url to the bug tracker for the issues.\n    :type bugtracker_url: str\n    :param rpm_format: if set to True, will make the changelog rpm-compatible.\n    :type rpm_format: bool\n    :rises RuntimeError: If the changelog could not be retrieved\n    \"\"\"\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    if os.path.exists(pkg_info_file):\n        return\n\n    with open('CHANGELOG', 'wb') as changelog_fd:\n        changelog_fd.write(\n            get_changelog(\n                project_dir=project_dir,\n                bugtracker_url=bugtracker_url,\n                rpm_format=rpm_format,\n            ).encode('utf-8')\n        )", "response": "Creates the changelog file if not in a package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_releasenotes(project_dir=os.curdir, bugtracker_url=''):\n    pkg_info_file = os.path.join(project_dir, 'PKG-INFO')\n    if os.path.exists(pkg_info_file):\n        return\n\n    with open('RELEASE_NOTES', 'wb') as releasenotes_fd:\n        releasenotes_fd.write(\n            get_releasenotes(\n                project_dir=project_dir,\n                bugtracker_url=bugtracker_url,\n            ).encode('utf-8') + b'\\n'\n        )", "response": "Creates the release notes file if not in a package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_rddl_block(self, p):\n        '''rddl_block : rddl_block domain_block\n                      | rddl_block instance_block\n                      | rddl_block nonfluent_block\n                      | empty'''\n        if p[1] is None:\n            p[0] = dict()\n        else:\n            name, block = p[2]\n            p[1][name] = block\n            p[0] = p[1]", "response": "rddl_block is a dict mapping domain name to block name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_domain_list(self, p):\n        '''domain_list : domain_list type_section\n                       | domain_list pvar_section\n                       | domain_list cpf_section\n                       | domain_list reward_section\n                       | domain_list action_precond_section\n                       | domain_list state_action_constraint_section\n                       | domain_list state_invariant_section\n                       | empty'''\n        if p[1] is None:\n            p[0] = dict()\n        else:\n            name, section = p[2]\n            p[1][name] = section\n            p[0] = p[1]", "response": "parse the domain_list section in the form of a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_type_list(self, p):\n        '''type_list : type_list type_def\n                     | empty'''\n        if p[1] is None:\n            p[0] = []\n        else:\n            p[1].append(p[2])\n            p[0] = p[1]", "response": "type_list : type_list type_def\n                     | empty"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_pvar_list(self, p):\n        '''pvar_list : pvar_list pvar_def\n                     | empty'''\n        if p[1] is None:\n            p[0] = []\n        else:\n            p[1].append(p[2])\n            p[0] = p[1]", "response": "p_pvar_list is a list of pvar_list pvar_def\n                     | empty"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_nonfluent_def(self, p):\n        '''nonfluent_def : IDENT LPAREN param_list RPAREN COLON LCURLY NON_FLUENT COMMA type_spec COMMA DEFAULT ASSIGN_EQUAL range_const RCURLY SEMI\n                         | IDENT COLON LCURLY NON_FLUENT COMMA type_spec COMMA DEFAULT ASSIGN_EQUAL range_const RCURLY SEMI'''\n        if len(p) == 16:\n            p[0] = PVariable(name=p[1], fluent_type='non-fluent', range_type=p[9], param_types=p[3], default=p[13])\n        else:\n            p[0] = PVariable(name=p[1], fluent_type='non-fluent', range_type=p[6], default=p[10])", "response": "parse the non - fluent class definition"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_intermfluent_def(self, p):\n        '''intermfluent_def : IDENT LPAREN param_list RPAREN COLON LCURLY INTERMEDIATE COMMA type_spec COMMA LEVEL ASSIGN_EQUAL range_const RCURLY SEMI\n                            | IDENT COLON LCURLY INTERMEDIATE COMMA type_spec COMMA LEVEL ASSIGN_EQUAL range_const RCURLY SEMI'''\n        if len(p) == 16:\n            p[0] = PVariable(name=p[1], fluent_type='interm-fluent', range_type=p[9], param_types=p[3], level=p[13])\n        else:\n            p[0] = PVariable(name=p[1], fluent_type='interm-fluent', range_type=p[6], level=p[10])", "response": "p_intermfluent_def is the entry point for the interm - fluent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing action - precondition section", "response": "def p_action_precond_section(self, p):\n        '''action_precond_section : ACTION_PRECONDITIONS LCURLY action_precond_list RCURLY SEMI\n                                  | ACTION_PRECONDITIONS LCURLY RCURLY SEMI'''\n        if len(p) == 6:\n            p[0] = ('preconds', p[3])\n        elif len(p) == 5:\n            p[0] = ('preconds', [])\n        self._print_verbose('action-preconditions')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_state_action_constraint_section(self, p):\n        '''state_action_constraint_section : STATE_ACTION_CONSTRAINTS LCURLY state_cons_list RCURLY SEMI\n                                           | STATE_ACTION_CONSTRAINTS LCURLY RCURLY SEMI'''\n        if len(p) == 6:\n            p[0] = ('constraints', p[3])\n        elif len(p) == 5:\n            p[0] = ('constraints', [])\n        self._print_verbose('state-action-constraints')", "response": "state_action_constraint_section is the section that contains the state action constraints"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_state_cons_list(self, p):\n        '''state_cons_list : state_cons_list state_cons_def\n                           | state_cons_def'''\n        if len(p) == 3:\n            p[1].append(p[2])\n            p[0] = p[1]\n        elif len(p) == 2:\n            p[0] = [p[1]]", "response": "state_cons_list : state_cons_list | state_cons_def\n                           | state_cons_def"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_state_invariant_section(self, p):\n        '''state_invariant_section : STATE_INVARIANTS LCURLY state_invariant_list RCURLY SEMI\n                                   | STATE_INVARIANTS LCURLY RCURLY SEMI'''\n        if len(p) == 6:\n            p[0] = ('invariants', p[3])\n        elif len(p) == 5:\n            p[0] = ('invariants', [])\n        self._print_verbose('invariants')", "response": "handle state invariant section"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_state_invariant_list(self, p):\n        '''state_invariant_list : state_invariant_list state_invariant_def\n                                | state_invariant_def'''\n        if len(p) == 3:\n            p[1].append(p[2])\n            p[0] = p[1]\n        elif len(p) == 2:\n            p[0] = [p[1]]", "response": "state_invariant_list | state_invariant_def\n                                | state_invariant_def"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_term_list(self, p):\n        '''term_list : term_list COMMA term\n                     | term\n                     | empty'''\n        if p[1] is None:\n            p[0] = []\n        elif len(p) == 4:\n            p[1].append(p[3])\n            p[0] = p[1]\n        elif len(p) == 2:\n            p[0] = [p[1]]", "response": "term_list : term_list COMMA term\n                     | term\n                     | empty"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_numerical_expr(self, p):\n        '''numerical_expr : expr PLUS expr\n                          | expr MINUS expr\n                          | expr TIMES expr\n                          | expr DIV expr\n                          | MINUS expr %prec UMINUS\n                          | PLUS expr %prec UMINUS\n                          | INTEGER\n                          | DOUBLE'''\n        if len(p) == 4:\n            p[0] = (p[2], (p[1], p[3]))\n        elif len(p) == 3:\n            p[0] = (p[1], (p[2],))\n        elif len(p) == 2:\n            p[0] = ('number', p[1])", "response": "numerical_expr : expr PLUS expr\n                          | expr MINUS expr\n                          | expr TIMES expr\n                          | expr DIV expr\n                          | MINUS expr %prec UMINUS\n                          | PLUS expr %prec UMINUS\n                          | INTEGER\n                          | DOUBLE"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_control_expr(self, p):\n        '''control_expr : IF LPAREN expr RPAREN THEN expr ELSE expr %prec IF\n                        | SWITCH LPAREN term RPAREN LCURLY case_list RCURLY'''\n        if len(p) == 9:\n            p[0] = (p[1], (p[3], p[6], p[8]))\n        elif len(p) == 8:\n            p[0] = (p[1], (p[3], *p[6]))", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m control_expr - Handles control expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_randomvar_expr(self, p):\n        '''randomvar_expr : BERNOULLI LPAREN expr RPAREN\n                          | DIRAC_DELTA LPAREN expr RPAREN\n                          | KRON_DELTA LPAREN expr RPAREN\n                          | UNIFORM LPAREN expr COMMA expr RPAREN\n                          | NORMAL LPAREN expr COMMA expr RPAREN\n                          | EXPONENTIAL LPAREN expr RPAREN\n                          | DISCRETE LPAREN IDENT COMMA lconst_case_list RPAREN\n                          | DIRICHLET LPAREN IDENT COMMA expr RPAREN\n                          | POISSON LPAREN expr RPAREN\n                          | WEIBULL LPAREN expr COMMA expr RPAREN\n                          | GAMMA   LPAREN expr COMMA expr RPAREN'''\n        if len(p) == 7:\n            if isinstance(p[5], list):\n                p[0] = ('randomvar', (p[1], (('enum_type', p[3]), *p[5])))\n            else:\n                p[0] = ('randomvar', (p[1], (p[3], p[5])))\n        elif len(p) == 5:\n            p[0] = ('randomvar', (p[1], (p[3],)))", "response": "parses the randomvar_expr into the form of a randomvar_expr"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the typed_var_list parameter", "response": "def p_typed_var_list(self, p):\n        '''typed_var_list : typed_var_list COMMA typed_var\n                          | typed_var'''\n        if len(p) == 4:\n            p[1].append(p[3])\n            p[0] = p[1]\n        elif len(p) == 2:\n            p[0] = [p[1]]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_expr_list(self, p):\n        '''expr_list : expr_list COMMA expr\n                     | expr'''\n        if len(p) == 4:\n            p[1].append(p[3])\n            p[0] = p[1]\n        elif len(p) == 2:\n            p[0] = [p[1]]", "response": "expr_list is a list of expressions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_case_def(self, p):\n        '''case_def : CASE term COLON expr\n                    | DEFAULT COLON expr'''\n        if len(p) == 5:\n            p[0] = ('case', (p[2], p[4]))\n        elif len(p) == 4:\n            p[0] = ('default', p[3])", "response": "CASE term COLON expr\n                    | DEFAULT COLON expr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse instance_list section of the next section", "response": "def p_instance_list(self, p):\n        '''instance_list : instance_list domain_section\n                         | instance_list nonfluents_section\n                         | instance_list objects_section\n                         | instance_list init_state_section\n                         | instance_list max_nondef_actions_section\n                         | instance_list horizon_spec_section\n                         | instance_list discount_section\n                         | empty'''\n        if p[1] is None:\n            p[0] = dict()\n        else:\n            name, section = p[2]\n            p[1][name] = section\n            p[0] = p[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_nonfluent_list(self, p):\n        '''nonfluent_list : nonfluent_list domain_section\n                          | nonfluent_list objects_section\n                          | nonfluent_list init_non_fluent_section\n                          | empty'''\n        if p[1] is None:\n            p[0] = dict()\n        else:\n            name, section = p[2]\n            p[1][name] = section\n            p[0] = p[1]", "response": "non - fluent list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_lconst_list(self, p):\n        '''lconst_list : lconst_list COMMA lconst\n                       | lconst'''\n        if len(p) == 4:\n            p[1].append(p[3])\n            p[0] = p[1]\n        elif len(p) == 2:\n            p[0] = [p[1]]", "response": "lconst_list : lconst_list COMMA lconst\n                       | lconst"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef selectable_delete(self) -> Expectation:\n        ''' Remove two projects\n        by selecting them via `<space>` and pressing `d`\n        '''\n        self.cmd_sync('ProAdd! tpe2/dep')\n        self._count(2)\n        self.cmd_sync('Projects')\n        self.cmd_sync('call feedkeys(\"\\\\<space>\\\\<space>d\")')\n        return self._count(0)", "response": "Remove two projects\n        by selecting them via d and pressing d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, **kwds):\n        result = self._client.tag.delete(self, **kwds)\n        self._delete_fields()\n        return result", "response": "Delete this tag. Returns True if successful."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, **kwds):\n        result = self._client.tag.update(self, **kwds)\n        self._replace_fields(result.get_fields())", "response": "Endpoint : / tag/<id > update. json\n        Updates this tag with the specified parameters. Returns the updated tag object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(count=1, length=12, chars=ALPHNUM):\n    if count == 1:\n        return ''.join(sample(chars, length))\n    \n    passwords = []\n    while count > 0:\n        passwords.append(''.join(sample(chars, length)))\n        count -= 1\n\n    return passwords", "response": "Generates a list of random passwords from the given chars and length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split(self, experiment_name, *variants):\n        # Perform some minimal type checking\n        if not isinstance(experiment_name, string_types):\n            raise RuntimeError(\n                'Invalid experiment name: %s must be a string.' %\n                experiment_name\n            )\n\n        keys, values, weights = self._parse_variants(variants)\n        b = self._backend\n\n        # Record the experiment if it doesn't exist already\n        experiment = b.get_experiment(experiment_name, keys)\n\n        # If the current visitor hasn't been verified as a human, and we've not\n        # required human verification, go ahead and mark them as a human.\n        if self.count_humans_only is False and self.human is not True:\n            b.mark_human(self.identity)\n\n        if experiment is None:\n            b.save_experiment(experiment_name, keys)\n            experiment = b.get_experiment(experiment_name, keys)\n        else:\n            if set(experiment.variants) != set(keys):\n                raise RuntimeError(\n                    'An experiment named %s already exists with different '\n                    'variants.' % experiment_name\n                )\n\n        # Retrieve the variant assigned to the current user\n        if experiment.name in self._environ.get('cleaver.override', {}):\n            variant = self._environ['cleaver.override'][experiment.name]\n        else:\n            variant = b.get_variant(self.identity, experiment.name)\n            if variant is None:\n                # ...or choose (and store) one randomly if it doesn't exist yet\n                variant = next(util.random_variant(keys, weights))\n                b.participate(self.identity, experiment.name, variant)\n\n        return dict(zip(keys, values))[variant]", "response": "This function splits the user experience amongst one or more variants."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef score(self, experiment_name):\n        if self._backend.get_variant(self.identity, experiment_name) and \\\n                self.human is True:\n            self._backend.mark_conversion(\n                experiment_name,\n                self._backend.get_variant(self.identity, experiment_name)\n            )", "response": "Used to score the current user s experiment variant as converted e. g. to be used for the current user s experiment variant as humans."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the element in the list with the given index", "response": "def find_element(list, index, index2=1):\n    \"\"\"\n        When you have list like: a = [(0, 10), (1, 20), (2, 30)] and you need to get value from tuple with first value == index\n        Usage:\n        {% find_element 1 %} will return 20\n    \"\"\"\n    for x in list:\n        if x[0] == index:\n            return x[index2]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dict(parser, token):\n    bits = token.contents.split(' ')\n    return GetDict(bits[1], bits[2], ((len(bits) > 3) and bits[3]) or '', ((len(bits) > 4) and bits[4]) or '', ((len(bits) > 5) and bits[5]) or '')", "response": "Get dict key from key element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a filter tag for Query sets.", "response": "def filter(parser, token):\n    \"\"\"\n        Filter tag for Query sets. Use with set tag =)\n        {% set filter posts status 0 drafts %}\n    \"\"\"\n    bits = token.contents.split(' ')\n    return FilterTag(bits[1], bits[2:])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve a real variable against the given context.", "response": "def _resolve_lookup(self, context):\n        \"\"\"\n        Performs resolution of a real variable (i.e. not a literal) against the\n        given context.\n\n        As indicated by the method's name, this method is an implementation\n        detail and shouldn't be called by external code. Use Variable.resolve()\n        instead.\n        \"\"\"\n        current = context\n        try: # catch-all for silent variable failures\n            for bit in self.lookups:\n                if callable(current):\n                    if getattr(current, 'alters_data', False):\n                        current = settings.TEMPLATE_STRING_IF_INVALID\n                    else:\n                        try: # method call (assuming no args required)\n                            current = current()\n                        except TypeError: # arguments *were* required\n                            # GOTCHA: This will also catch any TypeError\n                            # raised in the function itself.\n                            current = settings.TEMPLATE_STRING_IF_INVALID # invalid method call\n                try: # dictionary lookup\n                    current = current[bit]\n                except (TypeError, AttributeError, KeyError):\n                    try: # attribute lookup\n                        current = getattr(current, bit)\n                    except (TypeError, AttributeError):\n                        try: # list-index lookup\n                            current = current[int(bit)]\n                        except (IndexError, # list index out of range\n                                ValueError, # invalid literal for int()\n                                KeyError,   # current is a dict without `int(bit)` key\n                                TypeError,  # unsubscriptable object\n                                ):\n                            raise VariableDoesNotExist(\"Failed lookup for key [%s] in %r\", (bit, current)) # missing attribute\n        except Exception, e:\n            if getattr(e, 'silent_variable_failure', False):\n                current = settings.TEMPLATE_STRING_IF_INVALID\n            else:\n                raise\n\n        return current"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setWidget(self, widget, index=0, row=None,\n                  col=0, rowspan=1, colspan=1):\n        \"\"\"\n        Add new widget inside dock, remove old one if existent\n        \"\"\"\n        if row is None:\n            row = self.currentRow\n        self.currentRow = max(row + 1, self.currentRow)\n        if index > len(self.widgets) - 1:\n            # add new widget\n            self.widgets.append(widget)\n        else:  # change existing widget\n            self.layout.removeWidget(self.widgets[index])\n            self.widgets[index] = widget\n        self.layout.addWidget(widget, row, col, rowspan, colspan)\n        self.raiseOverlay()", "response": "Set a new widget inside the dock"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nround a float value off to the desired precision", "response": "def _saferound(value, decimal_places):\n    \"\"\"\n    Rounds a float value off to the desired precision\n    \"\"\"\n    try:\n        f = float(value)\n    except ValueError:\n        return ''\n    format = '%%.%df' % decimal_places\n    return format % f"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ap_state(value, failure_string=None):\n    try:\n        return statestyle.get(value).ap\n    except:\n        if failure_string:\n            return failure_string\n        else:\n            return value", "response": "Converts a state s name postal abbreviation or FIPS to A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P. style. A. P."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncapitalizes the first character of the value. Returns the failure_string keyword", "response": "def capfirst(value, failure_string='N/A'):\n    \"\"\"\n    Capitalizes the first character of the value.\n    \n    If the submitted value isn't a string, returns the `failure_string` keyword\n    argument.\n    \n    Cribbs from django's default filter set\n    \"\"\"\n    try:\n        value = value.lower()\n        return value[0].upper() + value[1:]\n    except:\n        return failure_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an integer into a string that contains the corresponding number of dollar sign symbols.", "response": "def dollar_signs(value, failure_string='N/A'):\n    \"\"\"\n    Converts an integer into the corresponding number of dollar sign symbols.\n    \n    If the submitted value isn't a string, returns the `failure_string` keyword\n    argument.\n    \n    Meant to emulate the illustration of price range on Yelp.\n    \"\"\"\n    try:\n        count = int(value)\n    except ValueError:\n        return failure_string\n    string = ''\n    for i in range(0, count):\n        string += '$'\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef image(value, width='', height=''):\n    style = \"\"\n    if width:\n        style += \"width:%s\" % width\n    if height:\n        style += \"height:%s\" % height\n    data_dict = dict(src=value, style=style)\n    return '<img src=\"%(src)s\" style=\"%(style)s\">' % data_dict", "response": "Takes a URL and returns an HTML image tag ready to be displayed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an integer to a string containing commas every three digits.", "response": "def intcomma(value):\n    \"\"\"\n    Borrowed from django.contrib.humanize\n    \n    Converts an integer to a string containing commas every three digits.\n    For example, 3000 becomes '3,000' and 45000 becomes '45,000'.\n    \"\"\"\n    orig = str(value)\n    new = re.sub(\"^(-?\\d+)(\\d{3})\", '\\g<1>,\\g<2>', orig)\n    if orig == new:\n        return new\n    else:\n        return intcomma(new)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a floating point value into a percentage value.", "response": "def percentage(value, decimal_places=1, multiply=True, failure_string='N/A'):\n    \"\"\"\n    Converts a floating point value into a percentage value.\n    \n    Number of decimal places set by the `decimal_places` kwarg. Default is one.\n    \n    By default the number is multiplied by 100. You can prevent it from doing\n    that by setting the `multiply` keyword argument to False.\n    \n    If the submitted value isn't a string, returns the `failure_string` keyword\n    argument.\n    \"\"\"\n    try:\n        value = float(value)\n    except ValueError:\n        return failure_string\n    if multiply:\n        value = value * 100\n    return _saferound(value, decimal_places) + '%'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef percent_change(value, decimal_places=1, multiply=True, failure_string='N/A'):\n    try:\n        f = float(value)\n        if multiply:\n            f = f * 100\n    except ValueError:\n       return  failure_string\n    s = _saferound(f, decimal_places)\n    if f > 0:\n        return '+' + s + '%'\n    else:\n        return s + '%'", "response": "Converts a floating point value into a percentage change value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ratio(value, decimal_places=0, failure_string='N/A'):\n    try:\n        f = float(value)\n    except ValueError:\n        return failure_string\n    return _saferound(f, decimal_places) + ':1'", "response": "Converts a floating point value a X : 1 ratio."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string into titlecase.", "response": "def title(value, failure_string='N/A'):\n    \"\"\"\n    Converts a string into titlecase.\n    \n    Lifted from Django.\n    \"\"\"\n    try:\n        value = value.lower()\n        t = re.sub(\"([a-z])'([A-Z])\", lambda m: m.group(0).lower(), value.title())\n        result = re.sub(\"\\d([A-Z])\", lambda m: m.group(0).lower(), t)\n        if not result:\n            return failure_string\n        return result\n    except:\n        return failure_string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, i):\n        check_type(i, int)\n\n        return _series_str_result(self, weld_str_get, i=i)", "response": "Extract i'th character of each element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slice(self, start=None, stop=None, step=None):\n        check_type(start, int)\n        check_type(stop, int)\n        check_type(step, int)\n\n        if step is not None and step < 0:\n            raise ValueError('Only positive steps are currently supported')\n\n        return _series_str_result(self, weld_str_slice, start=start, stop=stop, step=step)", "response": "Slice substrings from each element in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntesting if pat is included within elements.", "response": "def contains(self, pat):\n        \"\"\"Test if pat is included within elements.\n\n        Parameters\n        ----------\n        pat : str\n\n        Returns\n        -------\n        Series\n\n        \"\"\"\n        check_type(pat, str)\n\n        return _series_bool_result(self, weld_str_contains, pat=pat)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting if elements start with pat.", "response": "def startswith(self, pat):\n        \"\"\"Test if elements start with pat.\n\n        Parameters\n        ----------\n        pat : str\n\n        Returns\n        -------\n        Series\n\n        \"\"\"\n        check_type(pat, str)\n\n        return _series_bool_result(self, weld_str_startswith, pat=pat)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef endswith(self, pat):\n        check_type(pat, str)\n\n        return _series_bool_result(self, weld_str_endswith, pat=pat)", "response": "Test if elements end with pat."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if elements contain substring.", "response": "def find(self, sub, start=0, end=None):\n        \"\"\"Test if elements contain substring.\n\n        Parameters\n        ----------\n        sub : str\n        start : int, optional\n            Index to start searching from.\n        end : int, optional\n            Index to stop searching from.\n\n        Returns\n        -------\n        Series\n\n        \"\"\"\n        check_type(sub, str)\n        check_type(start, int)\n        check_type(end, int)\n\n        if end is not None and start >= end:\n            raise ValueError('End must be greater than start')\n\n        return Series(weld_str_find(self._data.values, sub, start, end),\n                      self._data.index,\n                      weld_to_numpy_dtype(WeldLong()),\n                      self._data.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces first occurrence of pat with rep in each element.", "response": "def replace(self, pat, rep):\n        \"\"\"Replace first occurrence of pat with rep in each element.\n\n        Parameters\n        ----------\n        pat : str\n        rep : str\n\n        Returns\n        -------\n        Series\n\n        \"\"\"\n        check_type(pat, str)\n        check_type(rep, str)\n\n        return _series_str_result(self, weld_str_replace, pat=pat, rep=rep)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the log entry into two sets of elements.", "response": "def split(self, pat, side='left'):\n        \"\"\"Split once each element from the left and select a side to return.\n\n        Note this is unlike pandas split in that it essentially combines the split with a select.\n\n        Parameters\n        ----------\n        pat : str\n        side : {'left', 'right'}\n            Which side of the split to select and return in each element.\n\n        Returns\n        -------\n        Series\n\n        \"\"\"\n        check_type(pat, str)\n        check_type(side, str)\n\n        # don't want this made with the object\n        _split_mapping = {\n            'left': 0,\n            'right': 1\n        }\n\n        if side not in _split_mapping:\n            raise ValueError('Can only select left or right side of split')\n\n        return _series_str_result(self, weld_str_split, pat=pat, side=_split_mapping[side])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that can be used to access the foreign field of a single object.", "response": "def foreign_field_func(field_name, short_description=None, admin_order_field=None): \n    \"\"\"\n    Allow to use ForeignKey field attributes at list_display in a simple way.\n\n    Example:\n        \n        from misc.admin import foreign_field_func as ff\n\n        class SongAdmin(admin.ModelAdmin):                                                                                                                        \n            list_display = ['name', 'time', 'artist', 'album', ff('track__num', \"Track number\"), ff('album__total_tracks')]\n    \"\"\"  \n    def accessor(obj): \n        val = obj \n        for part in field_name.split('__'): \n            val = getattr(val, part) \n        return val \n    \n    if short_description: \n        accessor.short_description = short_description \n    else: \n        accessor.__name__ = field_name \n    if admin_order_field: \n        accessor.admin_order_field = admin_order_field \n    else: \n        accessor.admin_order_field  = (field_name,) \n    \n    return accessor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef queryset(self, request):\n        query_set = self.model._default_manager.all_with_deleted()\n        ordering = self.ordering or ()\n        if ordering:\n            query_set = query_set.order_by(*ordering)\n        return query_set", "response": "Returns a Queryset of all model instances that can be edited by the \n        admin site. This is used by changelist_view."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_request (operation, expression):\n    \n    base = 'https://newton.now.sh'\n    url = '%s/%s/%s' % (base, operation, urllib.parse.quote(expression))\n    \n    with urllib.request.urlopen(url) as response:\n        return handle_response(response)", "response": "Send an HTTP GET request to the newton API"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_response (response):\n    \n    response = json.loads(response.read())\n    \n    # Was the expression valid?\n    if 'error' in response:\n        raise ValueError(response['error'])\n    else:\n        # Some of the strings returned can be parsed to integers or floats\n        try:\n            return json.loads(response['result'])\n        except (TypeError, json.decoder.JSONDecodeError):\n            # If the result is NaN, return the actual NaN float\n            if response['result'] == 'NaN':\n                return float('nan')\n            else:\n                return response['result']", "response": "Handle a response from the newton API to the newton API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexpose methods to the given module for each API endpoint", "response": "def expose_endpoints (module, *args):\n    \"\"\"\n    Expose methods to the given module for each API endpoint\n    \"\"\"\n    \n    for op in args:\n        # Capture the closure state\n        def create_method (o):\n            return lambda exp: send_request(o, exp)\n        \n        setattr(sys.modules[__name__], op, create_method(op))\n        setattr(module, op, getattr(sys.modules[__name__], op))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_config_path(config_file):\n    config_path = os.getenv('XDG_CONFIG_HOME')\n    if not config_path:\n        config_path = os.path.join(os.getenv('HOME'), \".config\")\n    if not config_file:\n        config_file = \"default\"\n    return os.path.join(config_path, \"trovebox\", config_file)", "response": "Returns the full path to the config file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_config(config_path):\n    section = \"DUMMY\"\n    defaults = {'host': 'localhost',\n                'consumerKey': '', 'consumerSecret': '',\n                'token': '', 'tokenSecret':'',\n                }\n    # Insert an section header at the start of the config file,\n    # so ConfigParser can understand it\n    buf = io.StringIO()\n    buf.write('[%s]\\n' % section)\n    with io.open(config_path, \"r\") as conf:\n        buf.write(conf.read())\n\n    buf.seek(0, os.SEEK_SET)\n    parser = ConfigParser()\n    parser.optionxform = str # Case-sensitive options\n    try:\n        parser.read_file(buf) # Python3\n    except AttributeError:\n        parser.readfp(buf) # Python2\n\n    # Trim quotes\n    config = parser.items(section)\n    config = [(item[0].replace('\"', ''), item[1].replace('\"', ''))\n              for item in config]\n    config = [(item[0].replace(\"'\", \"\"), item[1].replace(\"'\", \"\"))\n              for item in config]\n    config = dict(config)\n\n    # Apply defaults\n    for key in defaults:\n        if key not in config:\n            config[key] = defaults[key]\n\n    return config", "response": "Loads the authentication config data from the specified file path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the expression s type.", "response": "def etype(self) -> Tuple[str, str]:\n        '''Returns the expression's type.'''\n        if self._expr[0] in ['number', 'boolean']:\n            return ('constant', str(type(self._expr[1])))\n        elif self._expr[0] == 'pvar_expr':\n            return ('pvar', self._expr[1][0])\n        elif self._expr[0] == 'randomvar':\n            return ('randomvar', self._expr[1][0])\n        elif self._expr[0] in ['+', '-', '*', '/']:\n            return ('arithmetic', self._expr[0])\n        elif self._expr[0] in ['^', '&', '|', '~', '=>', '<=>']:\n            return ('boolean', self._expr[0])\n        elif self._expr[0] in ['>=', '<=', '<', '>', '==', '~=']:\n            return ('relational', self._expr[0])\n        elif self._expr[0] == 'func':\n            return ('func', self._expr[1][0])\n        elif self._expr[0] == 'sum':\n            return ('aggregation', 'sum')\n        elif self._expr[0] == 'prod':\n            return ('aggregation', 'prod')\n        elif self._expr[0] == 'avg':\n            return ('aggregation', 'avg')\n        elif self._expr[0] == 'max':\n            return ('aggregation', 'maximum')\n        elif self._expr[0] == 'min':\n            return ('aggregation', 'minimum')\n        elif self._expr[0] == 'forall':\n            return ('aggregation', 'forall')\n        elif self._expr[0] == 'exists':\n            return ('aggregation', 'exists')\n        elif self._expr[0] == 'if':\n            return ('control', 'if')\n        else:\n            return ('UNKOWN', 'UNKOWN')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the expression s arguments.", "response": "def args(self) -> Union[Value, Sequence[ExprArg]]:\n        '''Returns the expression's arguments.'''\n        if self._expr[0] in ['number', 'boolean']:\n            return self._expr[1]\n        elif self._expr[0] == 'pvar_expr':\n            return self._expr[1]\n        elif self._expr[0] == 'randomvar':\n            return self._expr[1][1]\n        elif self._expr[0] in ['+', '-', '*', '/']:\n            return self._expr[1]\n        elif self._expr[0] in ['^', '&', '|', '~', '=>', '<=>']:\n            return self._expr[1]\n        elif self._expr[0] in ['>=', '<=', '<', '>', '==', '~=']:\n            return self._expr[1]\n        elif self._expr[0] == 'func':\n            return self._expr[1][1]\n        elif self._expr[0] in ['sum', 'prod', 'avg', 'max', 'min', 'forall', 'exists']:\n            return self._expr[1]\n        elif self._expr[0] == 'if':\n            return self._expr[1]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(self) -> str:\n        '''Returns the name of pvariable.\n\n        Returns:\n            Name of pvariable.\n\n        Raises:\n            ValueError: If not a pvariable expression.\n        '''\n        if not self.is_pvariable_expression():\n            raise ValueError('Expression is not a pvariable.')\n        return self._pvar_to_name(self.args)", "response": "Returns the name of the pvariable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning string representing the expression.", "response": "def __expr_str(cls, expr, level):\n        '''Returns string representing the expression.'''\n        ident = ' ' * level * 4\n\n        if isinstance(expr, tuple):\n            return '{}{}'.format(ident, str(expr))\n\n        if expr.etype[0] in ['pvar', 'constant']:\n            return '{}Expression(etype={}, args={})'.format(ident, expr.etype, expr.args)\n\n        if not isinstance(expr, Expression):\n            return '{}{}'.format(ident, str(expr))\n\n        args = list(cls.__expr_str(arg, level + 1) for arg in expr.args)\n        args = '\\n'.join(args)\n        return '{}Expression(etype={}, args=\\n{})'.format(ident, expr.etype, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the set of fluents in the expression s scope.", "response": "def __get_scope(cls,\n            expr: Union['Expression', Tuple]) -> Set[str]:\n        '''Returns the set of fluents in the expression's scope.\n\n        Args:\n            expr: Expression object or nested tuple of Expressions.\n\n        Returns:\n            The set of fluents in the expression's scope.\n        '''\n        scope = set()\n        for i, atom in enumerate(expr):\n            if isinstance(atom, Expression):\n                scope.update(cls.__get_scope(atom._expr))\n            elif type(atom) in [tuple, list]:\n                scope.update(cls.__get_scope(atom))\n            elif atom == 'pvar_expr':\n                functor, params = expr[i+1]\n                arity = len(params) if params is not None else 0\n                name = '{}/{}'.format(functor, arity)\n                scope.add(name)\n                break\n        return scope"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pvar_to_name(cls, pvar_expr):\n        '''Returns the name of pvariable.\n\n        Returns:\n            Name of pvariable.\n        '''\n        functor = pvar_expr[0]\n        arity = len(pvar_expr[1]) if pvar_expr[1] is not None else 0\n        return '{}/{}'.format(functor, arity)", "response": "Returns the name of the pvariable.\n            Returns :\n            Name of pvariable.\n            Returns :\n            Name of pvariable.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_client_ip(request):\n    # set the default value of the ip to be the REMOTE_ADDR if available\n    # else None\n    ip = request.META.get('REMOTE_ADDR')\n    # try to get the first non-proxy ip (not a private ip) from the\n    # HTTP_X_FORWARDED_FOR\n    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')\n    if x_forwarded_for:\n        proxies = x_forwarded_for.split(',')\n        # remove the private ips from the beginning\n        proxies = [proxy for proxy in proxies\n                   if not proxy.startswith(settings.PRIVATE_IPS_PREFIX)]\n        # take the first ip which is not a private one (of a proxy)\n        if len(proxies) > 0:\n            ip = proxies[0]\n\n    return ip", "response": "Get the client IP from the request"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef browse(self):\n        ''' Browse the history of a single file\n        adds one commit that doesn't contain changes in test_file_1.\n        there are four commits in summary, so the check for buffer line\n        count compares with 3.\n        at the end, a fifth commit must be present due to resetting the\n        file contents.\n        '''\n        check = self._check\n        marker_text = Random.string()\n        self.vim.buffer.set_content([marker_text])\n        self._save()\n        self._write_file(1)\n        self._save()\n        self._write_file2(1)\n        self._save()\n        self._write_file(2)\n        self._write_file2(1)\n        self._save()\n        self.vim.cmd('ProHistoryFileBrowse {}'.format('test_file_1'))\n        check(0, '*')\n        self.vim.vim.feedkeys('j')\n        self.vim.vim.feedkeys('j')\n        later(lambda: self.vim.buffer.content.length.should.equal(3))\n        self.vim.vim.feedkeys('s')\n        self._await_commit(0)\n        self.vim.buffer.content.should.equal(List(marker_text))", "response": "Browse the history of a single file and add one commit that doesn t contain changes in test_file_1."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self, *args, **kwargs):\n        Telnet.open(self, *args, **kwargs)\n        if self.force_ssl:\n            self._start_tls()", "response": "A version of open that uses the TelnetLib module to negotiate the Telnet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_cmds_id(*cmds):\n    tags = [cmd[2] if len(cmd) == 3 else None for cmd in cmds]\n    if [tag for tag in tags if tag != None]:\n        return tuple(tags)\n    else:\n        return None", "response": "Returns an identifier for a group of partially tagged commands."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef received_message(self, msg):\n        logger.debug(\"Received message: %s\", msg)\n        if msg.is_binary:\n            raise ValueError(\"Binary messages not supported\")\n        resps = json.loads(msg.data)\n\n        cmd_group = _get_cmds_id(*resps)\n        if cmd_group:\n            (cmds, promise) = self._cmd_groups[cmd_group]\n            promise.fulfill((cmds, resps))\n        else:\n            try:\n                self.received_unsolicited(resps)\n            except:\n                logger.exception(\"Error in unsolicited msg handler\")\n                raise", "response": "Handle receiving a message from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntagging and sends the commands to the Switchboard server returning a Promise that is fulfilled with the result.", "response": "def send_cmds(self, *cmds):\n        \"\"\"\n        Tags and sends the commands to the Switchboard server, returning\n        None.\n\n        Each cmd be a 2-tuple where the first element is the method name,\n        and the second is the arguments, e.g. (\"connect\", {\"host\": ...}).\n        \"\"\"\n        promise = aplus.Promise()\n        tagged_cmds = list(self._tag_cmds(*cmds))\n        logger.debug(\"Sending cmds: %s\", tagged_cmds)\n\n        cmd_group = _get_cmds_id(*tagged_cmds)\n        self._cmd_groups[cmd_group] = (tagged_cmds, promise)\n        self.send(json.dumps(tagged_cmds))\n        return promise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(self, x):\n        for i in range(len(self.taps_fix_reversed)):\n            self.next.mul[i] = x * self.taps_fix_reversed[i]\n            if i == 0:\n                self.next.acc[0] = self.mul[i]\n            else:\n                self.next.acc[i] = self.acc[i - 1] + self.mul[i]\n\n        self.next.out = self.acc[-1]\n        return self.out", "response": "This function is used to transform the FirusTotal amount of the log to the next log."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    logger.info(\"Options used:\")\n    for key, value in vars(args).iteritems():\n        logger.info(\"  --{} {}\".format(key.replace(\"_\", \"-\"), value))\n\n    # Checks the sample raw data\n    logger.info(\"Checking the raw data files\")\n    sample_files = check_sample_files(args.bfile + \".fam\", args.raw_dir)\n\n    # Finds the markers to extract\n    logger.info(\"Creating extraction list (autosome only)\")\n    create_extraction_file(args.bfile + \".bim\", args.out)\n\n    # Run plink\n    logger.info(\"Computing frequency using Plink\")\n    run_plink(args.bfile, args.out, args.out + \".to_extract\")\n\n    # Run bafRegress\n    logger.info(\"Running bafRegress\")\n    if args.sge:\n        run_bafRegress_sge(sample_files, args.out, args.out + \".to_extract\",\n                           args.out + \".frq\", args)\n    else:\n        run_bafRegress(sample_files, args.out, args.out + \".to_extract\",\n                       args.out + \".frq\", args)", "response": "The main function of the module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_sample_files(fam_filename, raw_dirname):\n    # Reading the sample identification number from the FAM file\n    fam_samples = None\n    with open(fam_filename, \"r\") as i_file:\n        fam_samples = {line.split()[1] for line in i_file.read().splitlines()}\n\n    # Checking the files in the raw directory\n    sample_files = set()\n    all_samples = set()\n    for filename in glob.glob(os.path.join(raw_dirname, \"*\")):\n        sample = os.path.splitext(os.path.basename(filename))[0]\n        all_samples.add(sample)\n        if sample not in fam_samples:\n            logger.warning(\"{}: sample not in FAM file\".format(sample))\n        else:\n            sample_files.add(filename)\n\n    for sample in fam_samples - all_samples:\n        logger.warning(\"{}: sample not in raw directory\".format(sample))\n\n    if len(sample_files) == 0:\n        raise ProgramError(\"no sample left for analysis\")\n\n    return sample_files", "response": "Checks the raw sample files in the FAM file and returns a set of all the sample files that are compatible with the FAM\n              file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_extraction_file(bim_filename, out_prefix):\n    o_file = None\n    try:\n        o_file = open(out_prefix + \".to_extract\", \"w\")\n    except IOError:\n        raise ProgramError(\"{}: cannot write file\".format(\n            out_prefix + \".to_extract\"\n        ))\n\n    # Reading the BIM file and extracts only the markers on autosome\n    autosomes = set(map(str, range(1, 23)))\n    nb_markers = 0\n    header = dict(zip([\"chrom\", \"name\", \"cm\", \"pos\", \"a1\", \"a2\"], range(6)))\n    with open(bim_filename, \"r\") as i_file:\n        for line in i_file:\n            row = line.rstrip(\"\\r\\n\").split()\n            if row[header[\"chrom\"]] in autosomes:\n                print >>o_file, row[header[\"name\"]]\n                nb_markers += 1\n\n    # Closing the file\n    o_file.close()\n\n    logger.info(\"  - {:,d} markers will be used for contamination \"\n                \"estimation\".format(nb_markers))", "response": "Creates an extraction file for the given BIM file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the bafRegress function.", "response": "def run_bafRegress(filenames, out_prefix, extract_filename, freq_filename,\n                   options):\n    \"\"\"Runs the bafRegress function.\n\n    :param filenames: the set of all sample files.\n    :param out_prefix: the output prefix.\n    :param extract_filename: the name of the markers to extract.\n    :param freq_filename: the name of the file containing the frequency.\n    :param options: the other options.\n\n    :type filenames: set\n    :type out_prefix: str\n    :type extract_filename: str\n    :type freq_filename: str\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # The command\n    command = [\n        \"bafRegress.py\",\n        \"estimate\",\n        \"--freqfile\", freq_filename,\n        \"--freqcol\", \"2,5\",\n        \"--extract\", extract_filename,\n        \"--colsample\", options.colsample,\n        \"--colmarker\", options.colmarker,\n        \"--colbaf\", options.colbaf,\n        \"--colab1\", options.colab1,\n        \"--colab2\", options.colab2,\n    ]\n    command.extend(filenames)\n\n    output = None\n    try:\n        output = subprocess.check_output(command, stderr=subprocess.STDOUT,\n                                         shell=False)\n    except subprocess.CalledProcessError as exc:\n        raise ProgramError(\"bafRegress.py: couldn't run \"\n                           \"bafRegress.py\\n{}\".format(exc.output))\n\n    # Saving the output\n    try:\n        with open(out_prefix + \".bafRegress\", \"w\") as o_file:\n            o_file.write(output)\n    except IOError:\n        raise ProgramError(\"{}: cannot write file\".format(\n            out_prefix + \".bafRegress\",\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_bafRegress_sge(filenames, out_prefix, extract_filename, freq_filename,\n                       options):\n    \"\"\"Runs the bafRegress function using SGE.\n\n    :param filenames: the set of all sample files.\n    :param out_prefix: the output prefix.\n    :param extract_filename: the name of the markers to extract.\n    :param freq_filename: the name of the file containing the frequency.\n    :param options: the other options.\n\n    :type filenames: set\n    :type out_prefix: str\n    :type extract_filename: str\n    :type freq_filename: str\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # Checks the environment variable for DRMAA package\n    if \"DRMAA_LIBRARY_PATH\" not in os.environ:\n        msg = \"could not load drmaa: set DRMAA_LIBRARY_PATH\"\n        raise ProgramError(msg)\n\n    # Import the drmaa package\n    try:\n        import drmaa\n    except ImportError:\n        raise ProgramError(\"drmaa is not install, install drmaa\")\n\n    # Initializing a session\n    s = drmaa.Session()\n    s.initialize()\n\n    # The base command\n    base_command = [\n        \"bafRegress.py\",\n        \"estimate\",\n        \"--freqfile\", freq_filename,\n        \"--freqcol\", \"2,5\",\n        \"--extract\", extract_filename,\n        \"--colsample\", options.colsample,\n        \"--colmarker\", options.colmarker,\n        \"--colbaf\", options.colbaf,\n        \"--colab1\", options.colab1,\n        \"--colab2\", options.colab2,\n    ]\n\n    # Creating chunks\n    chunks = [\n        list(filenames)[i: i+options.sample_per_run_for_sge]\n        for i in range(0, len(filenames), options.sample_per_run_for_sge)\n    ]\n\n    # Run for each sub task...\n    job_ids = []\n    job_templates = []\n    for i, chunk in enumerate(chunks):\n        # Creating the final command\n        command = [pipes.quote(token) for token in base_command + chunk]\n        command.append(\n            \"> {}.bafRegress_{}\".format(pipes.quote(out_prefix), i+1),\n        )\n        command = \" \".join(command)\n\n        # Creating the job template\n        jt = s.createJobTemplate()\n        jt.remoteCommand = \"bash\"\n        jt.workingDirectory = os.getcwd()\n        jt.jobEnvironment = os.environ\n        jt.args = [\"-c\", command]\n        jt.jobName = \"_bafRegress_{}\".format(i+1)\n\n        # Cluster specifics\n        if options.sge_walltime is not None:\n            jt.hardWallclockTimeLimit = options.sge_walltime\n        if options.sge_nodes is not None:\n            native_spec = \"-l nodes={}:ppn={}\".format(options.sge_nodes[0],\n                                                      options.sge_nodes[1])\n            jt.nativeSpecification = native_spec\n\n        job_ids.append(s.runJob(jt))\n        job_templates.append(jt)\n\n    # Waiting for the jobs to finish\n    had_problems = []\n    for job_id in job_ids:\n        ret_val = s.wait(job_id, drmaa.Session.TIMEOUT_WAIT_FOREVER)\n        had_problems.append(ret_val.exitStatus == 0)\n\n    # Deleting the jobs\n    for jt in job_templates:\n        s.deleteJobTemplate(jt)\n\n    # Closing the session\n    s.exit()\n\n    # Checking for problems\n    if not all(had_problems):\n        raise ProgramError(\"Some SGE jobs had errors...\")\n\n    # Merging the output files\n    o_file = None\n    try:\n        o_file = open(out_prefix + \".bafRegress\", \"w\")\n    except IOError:\n        msg = \"{}: cannot write file\".format(out_prefix + \".bafRegress\")\n        raise ProgramError(msg)\n\n    to_remove = set()\n    for i in range(len(chunks)):\n        filename = out_prefix + \".bafRegress_{}\".format(i+1)\n        if not os.path.isfile(filename):\n            raise ProgramError(\"{}: no such file\".format(filename))\n        to_remove.add(filename)\n\n        with open(filename, \"r\") as i_file:\n            if i == 0:\n                # First file, we write everything\n                o_file.write(i_file.read())\n                continue\n\n            for j, line in enumerate(i_file):\n                # Skipping first line\n                if j == 0:\n                    continue\n                o_file.write(line)\n\n    for filename in to_remove:\n        # Deleting the chunk\n        os.remove(filename)\n\n    # Closing\n    o_file.close()", "response": "Runs the bafRegress function using SGE."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_plink(in_prefix, out_prefix, extract_filename):\n    # The plink command\n    plink_command = [\n        \"plink\",\n        \"--noweb\",\n        \"--bfile\", in_prefix,\n        \"--extract\", extract_filename,\n        \"--freq\",\n        \"--out\", out_prefix,\n    ]\n    output = None\n    try:\n        output = subprocess.check_output(plink_command,\n                                         stderr=subprocess.STDOUT, shell=False)\n    except subprocess.CalledProcessError as exc:\n        msg = \"plink: couldn't run plink\\n{}\".format(exc.output)\n        raise ProgramError(msg)", "response": "Runs Plink with the geno option."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the arguments and options.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Check if we have the tped and the tfam files\n    for filename in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n        if not os.path.isfile(filename):\n            raise ProgramError(\"{}: no such file\".format(filename))\n\n    # Checking that the raw directory exists\n    if not os.path.isdir(args.raw_dir):\n        raise ProgramError(\"{}: no such directory\".format(args.raw_dir))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_dkl(f, x, samples, prior_samples, ax=None, **kwargs):\n\n    logZ = kwargs.pop('logZ', None)\n    weights = kwargs.pop('weights', None)\n    prior_weights = kwargs.pop('prior_weights', None)\n    ntrim = kwargs.pop('ntrim', None)\n    cache = kwargs.pop('cache', '')\n    prior_cache = kwargs.pop('prior_cache', '')\n    parallel = kwargs.pop('parallel', False)\n    tqdm_kwargs = kwargs.pop('tqdm_kwargs', {})\n\n    dkls = compute_dkl(f, x, samples, prior_samples,\n                       logZ=logZ, parallel=parallel,\n                       cache=cache, prior_cache=prior_cache,\n                       tqdm_kwargs=tqdm_kwargs,\n                       ntrim=ntrim, weights=weights,\n                       prior_weights=prior_weights)\n\n    if ax is None:\n        ax = plt.gca()\n    ax.plot(x, dkls, **kwargs)", "response": "r Plot the Kullback - Leibler divergence at each value of x."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_samples(f, x, samples, **kwargs):\n    logZ = kwargs.pop('logZ', None)\n    weights = kwargs.pop('weights', None)\n    ntrim = kwargs.pop('ntrim', None)\n    cache = kwargs.pop('cache', '')\n    parallel = kwargs.pop('parallel', False)\n    tqdm_kwargs = kwargs.pop('tqdm_kwargs', {})\n    if kwargs:\n        raise TypeError('Unexpected **kwargs: %r' % kwargs)\n\n    logZ, f, x, samples, weights = _check_args(logZ, f, x, samples, weights)\n\n    logZ, weights = _normalise_weights(logZ, weights, ntrim)\n\n    for i, (s, w) in enumerate(zip(samples, weights)):\n        samples[i] = _equally_weight_samples(s, w)\n\n    return fgivenx.samples.compute_samples(f, x, samples,\n                                           parallel=parallel, cache=cache,\n                                           tqdm_kwargs=tqdm_kwargs)", "response": "r Computes the samples of the function f at each x and samples."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_pmf(f, x, samples, **kwargs):\n\n    logZ = kwargs.pop('logZ', None)\n    weights = kwargs.pop('weights', None)\n    ny = kwargs.pop('ny', 100)\n    y = kwargs.pop('y', None)\n    ntrim = kwargs.pop('ntrim', 100000)\n    parallel = kwargs.pop('parallel', False)\n    cache = kwargs.pop('cache', '')\n    tqdm_kwargs = kwargs.pop('tqdm_kwargs', {})\n    if kwargs:\n        raise TypeError('Unexpected **kwargs: %r' % kwargs)\n\n    # y\n    if y is not None:\n        y = numpy.array(y, dtype='double')\n        if len(y.shape) is not 1:\n            raise ValueError(\"y should be a 1D array\")\n\n    fsamps = compute_samples(f, x, samples, logZ=logZ,\n                             weights=weights, ntrim=ntrim,\n                             parallel=parallel, cache=cache,\n                             tqdm_kwargs=tqdm_kwargs)\n\n    if y is None:\n        ymin = fsamps[~numpy.isnan(fsamps)].min(axis=None)\n        ymax = fsamps[~numpy.isnan(fsamps)].max(axis=None)\n        y = numpy.linspace(ymin, ymax, ny)\n\n    return y, fgivenx.mass.compute_pmf(fsamps, y, parallel=parallel,\n                                       cache=cache, tqdm_kwargs=tqdm_kwargs)", "response": "r Compute the probability mass function given f at a range of x samples and optional weights."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_txt_file(filepath):\n    if sys.version > '3':\n        with open(filepath,'r',encoding='utf-8') as txt_file:\n            return txt_file.readlines()\n    else:\n        with open(filepath) as txt_file:\n            return txt_file.readlines()", "response": "read text from filepath and remove linebreaks\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all slots as set", "response": "def _get_all_slots(self):\n        \"\"\"Returns all slots as set\"\"\"\n        all_slots = (getattr(cls, '__slots__', [])\n                         for cls in self.__class__.__mro__)\n        return set(slot for slots in all_slots for slot in slots)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trim(self, video_name, out, start, duration):\n        command = ['ffmpeg', '-ss', start, '-i', video_name, '-c:v', 'huffyuv',\n                   '-y', '-preset', 'veryslow', '-t', duration, out]\n        if self.verbose:\n            print 'Trimming {0} into {1}'.format(video_name, out)\n            print ' '.join(command)\n        call(command)", "response": "Trims a clip to be duration starting at start"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nskips a section of the clip", "response": "def skip(self, video_name, out, start, duration):\n        \"\"\"\n        Skips a section of the clip\n        @param video_name : name of video input file\n        @param out : name of output file\n        @param start : start time of the skip (seconds)\n        @param duration : duration of the skip (seconds)\n        \"\"\"\n        cfilter = (r\"[0:v]trim=duration={start}[av];\"\n                   r\"[0:a]atrim=duration={start}[aa];\"\n                   r\"[0:v]trim=start={offset},setpts=PTS-STARTPTS[bv];\"\n                   r\"[0:a]atrim=start={offset},asetpts=PTS-STARTPTS[ba];\"\n                   r\"[av][bv]concat[outv];[aa][ba]concat=v=0:a=1[outa]\")\\\n            .format(start=start, offset=start + duration)\\\n            .replace(' ', '')\n\n        command = ['ffmpeg', '-i', video_name,\n            '-filter_complex', cfilter, '-y',\n            '-map', '[outv]',\n            '-map', '[outa]', '-c:v', 'huffyuv', '-preset', 'veryslow',\n            out]\n\n        if self.verbose:\n            print 'Skipping {0} into {1}'.format(video_name, out)\n            print ' '.join(command)\n\n        call(command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef draw_video(self, underlay, overlay, out, x, y):\n        cfilter = r\"[0:1][1:1]amerge=inputs=2[aout];overlay=x={0}:y={1}\"\\\n            .format(x, y)\n\n        # Manually set the color space because other wise you'll have\n        # some trippy looking overlays (-pix_fmt yuv422p)\n        command = ['ffmpeg', '-i', underlay, '-i', overlay,\n                   '-c:v', 'huffyuv',\n                   '-y',\n                   '-pix_fmt', 'yuv422p',\n                   '-filter_complex', cfilter, '-map', '[aout]', out]\n\n        if self.verbose:\n            print 'Drawing video {0} on top of {1}'.format(underlay, overlay)\n            print command\n\n        call(command)", "response": "Draw one video over another video file on top of the overlay."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndrawing text over a specific file in the current directory of the neccessary video.", "response": "def draw_text(self, video_name, out, start, end, x, y, text,\n                  color='0xFFFFFF', show_background=0,\n                  background_color='0x000000', size=16):\n        \"\"\"\n        Draws text over a video\n        @param video_name : name of video input file\n        @param out : name of video output file\n        @param start : start timecode to draw text hh:mm:ss\n        @param end : end timecode to draw text hh:mm:ss\n        @param x : x position of text (px)\n        @param y : y position of text (px)\n        @param text : text content to draw\n        @param color : text color\n        @param show_background : boolean to show a background box behind the\n                                 text\n        @param background_color : color of background box\n        \"\"\"\n        cfilter = (r\"[0:0]drawtext=fontfile=/Library/Fonts/AppleGothic.ttf:\"\n                   r\"x={x}:y={y}:fontcolor='{font_color}':\"\n                   r\"box={show_background}:\"\n                   r\"boxcolor='{background_color}':\"\n                   r\"text='{text}':fontsize={size}:\"\n                   r\"enable='between(t,{start},{end})'[vout];\"\n                   r\"[0:1]apad=pad_len=0[aout]\")\\\n            .format(x=x, y=y, font_color=color,\n                    show_background=show_background,\n                    background_color=background_color, text=text, start=start,\n                    end=end, size=size)\n        command = ['ffmpeg', '-i', video_name, '-c:v', 'huffyuv', '-y',\n                   '-filter_complex', cfilter,  '-an', '-y',\n                   '-map', '[vout]',\n                   '-map', '[aout]',\n                   out]\n\n        if self.verbose:\n            print 'Drawing text \"{0}\" onto {1} output as {2}'.format(\n                text,\n                video_name,\n                out,\n            )\n            print ' '.join(command)\n\n        call(command)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw an image over the video with the specified image name.", "response": "def draw_image(self, video_name, image_name, out, start, end, x, y,\n                   verbose=False):\n        \"\"\"\n        Draws an image over the video\n        @param video_name : name of video input file\n        @param image_name: name of image input file\n        @param out : name of video output file\n        @param start : when to start overlay\n        @param end : when to end overlay\n        @param x : x pos of image\n        @param y : y pos of image\n        \"\"\"\n        cfilter = (r\"[0] [1] overlay=x={x}: y={y}:\"\n                   \"enable='between(t, {start}, {end}')\")\\\n            .format(x=x, y=y, start=start, end=end)\n\n        call(['ffmpeg', '-i', video_name, '-i', image_name, '-c:v', 'huffyuv',\n              '-y', '-preset', 'veryslow', '-filter_complex', cfilter, out])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loop(self, video_name, out, start, duration, iterations, video_length,\n             verbose=False):\n        \"\"\"\n        Loops a section of a video\n        @param video_name : name of video input file\n        @param out : name of video output file\n        @param start : start time of loop (timestamp hh:mm:ss)\n        @param duration : duration of loop section (seconds)\n        @param iterations : amount of times to loop\n        @param video_length : length of video\n        \"\"\"\n        beginning = NamedTemporaryFile(suffix='.avi')\n        # section of video that will be looped\n        loop_section = NamedTemporaryFile(suffix='.avi')\n        # collection of looped sections\n        loops = NamedTemporaryFile(suffix='.avi')\n        end = NamedTemporaryFile(suffix='.avi')\n\n        self.trim(video_name, beginning.name, '0', start)\n        self.trim(video_name, loop_section.name, start, duration)\n        self.trim(video_name, end.name, '00:00:08', video_length)\n\n        # Open text file it and write the loop clip  n times\n        with open('loop.txt', 'w') as f:\n            for i in range(1, iterations):\n                line = 'file {0}\\n'.format(loop_section.name)\n                f.write(line)\n\n        # concat the loop clip upon itself n times\n        call(['ffmpeg', '-f', 'concat',\n              '-i', 'loop.txt', '-y',\n              '-c', 'copy', loops.name])\n\n        # concat the beginning clip, combo of loops, and end clip\n        cfilter = (r\"[0:0] [0:1] [1:0] [1:1] [2:0] [2:1]\"\n                   r\"concat=n=3:v=1:a=1 [v] [a1]\")\n        call(['ffmpeg', '-i', beginning.name, '-i', loops.name, '-i', end.name,\n              '-filter_complex', cfilter, '-y', '-c:v', 'huffyuv',\n              '-map', '[v]', '-map', '[a1]', out])", "response": "This function loops a section of a video and writes the loop. txt file to out."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_field(self, types, domain, items):\n        def handle_item(fieldarg, content):\n            par = nodes.paragraph()\n            par += self.make_xref(\n                self.rolename, domain, fieldarg, nodes.strong)\n            if fieldarg in types:\n                par += nodes.Text(' : ')\n                # NOTE: using .pop() here to prevent a single type node to be\n                # inserted twice into the doctree, which leads to\n                # inconsistencies later when references are resolved\n                fieldtype = types.pop(fieldarg)\n                if (len(fieldtype) == 1 and\n                        isinstance(fieldtype[0], nodes.Text)):\n                    typename = u''.join(n.astext() for n in fieldtype)\n                    par += self.make_xref(self.typerolename, domain, typename)\n                else:\n                    par += fieldtype\n                par += nodes.Text('')\n            par += nodes.Text(' -- ')\n            par += content\n            return par\n\n        fieldname = nodes.field_name('', self.label)\n        if len(items) == 1 and self.can_collapse:\n            fieldarg, content = items[0]\n            bodynode = handle_item(fieldarg, content)\n        else:\n            bodynode = self.list_type()\n            for fieldarg, content in items:\n                bodynode += nodes.list_item('', handle_item(fieldarg, content))\n        fieldbody = nodes.field_body('', bodynode)\n        return nodes.field('', fieldname, fieldbody)", "response": "Copy + Paste of TypedField. make_field"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pseudo_parse_arglist(signode, arglist):\n        paramlist = addnodes.desc_parameterlist()\n        stack = [paramlist]\n        try:\n            for argument in arglist.split(','):\n                argument = argument.strip()\n                ends_open = 0\n                ends_close = 0\n                while argument.startswith('['):\n                    stack.append(addnodes.desc_optional())\n                    stack[-2] += stack[-1]\n                    argument = argument[1:].strip()\n                while argument.startswith(']'):\n                    stack.pop()\n                    argument = argument[1:].strip()\n                while argument.endswith(']') and not argument.endswith('[]'):\n                    ends_close += 1\n                    argument = argument[:-1].strip()\n                while argument.endswith('['):\n                    ends_open += 1\n                    argument = argument[:-1].strip()\n                if argument:\n                    stack[-1] += addnodes.desc_parameter(argument, argument)\n                while ends_open:\n                    stack.append(addnodes.desc_optional())\n                    stack[-2] += stack[-1]\n                    ends_open -= 1\n                while ends_close:\n                    stack.pop()\n                    ends_close -= 1\n            if len(stack) != 1:\n                raise IndexError\n        except IndexError:\n            # If there are too few or too many elements on the stack, just give\n            # up and treat the whole argument list as one argument, discarding\n            # the already partially populated paramlist node.\n            signode += addnodes.desc_parameterlist()\n            signode[-1] += addnodes.desc_parameter(arglist, arglist)\n        else:\n            signode += paramlist", "response": "Parse list of comma separated arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning prefix text for attribute or data directive.", "response": "def _get_attr_like_prefix(self, sig):\n        \"\"\"Return prefix text for attribute or data directive.\"\"\"\n        sig_match = chpl_attr_sig_pattern.match(sig)\n        if sig_match is None:\n            return ChapelObject.get_signature_prefix(self, sig)\n\n        prefixes, _, _, _ = sig_match.groups()\n        if prefixes:\n            return prefixes.strip() + ' '\n        elif self.objtype == 'type':\n            return 'type' + ' '\n        else:\n            return ChapelObject.get_signature_prefix(self, sig)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_proc_like_prefix(self, sig):\n        sig_match = chpl_sig_pattern.match(sig)\n        if sig_match is None:\n            return ChapelObject.get_signature_prefix(self, sig)\n\n        prefixes, _, _, _, _ = sig_match.groups()\n        if prefixes:\n            return prefixes.strip() + ' '\n        elif self.objtype.startswith('iter'):\n            return 'iter' + ' '\n        elif self.objtype in ('method', 'function'):\n            return 'proc' + ' '\n        else:\n            return ChapelObject.get_signature_prefix(self, sig)", "response": "Return prefix text for function or method directive\n            and similar."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the signature and append it to the species tree.", "response": "def handle_signature(self, sig, signode):\n        \"\"\"Parse the signature *sig* into individual nodes and append them to the\n        *signode*. If ValueError is raises, parsing is aborted and the whole\n        *sig* string is put into a single desc_name node.\n\n        The return value is the value that identifies the object. IOW, it is\n        the identifier that will be used to reference this object, datum,\n        attribute, proc, etc. It is a tuple of \"fullname\" (including module and\n        class(es)) and the classes. See also :py:meth:`add_target_and_index`.\n        \"\"\"\n        if self._is_attr_like():\n            sig_match = chpl_attr_sig_pattern.match(sig)\n            if sig_match is None:\n                raise ValueError('Signature does not parse: {0}'.format(sig))\n            func_prefix, name_prefix, name, retann = sig_match.groups()\n            arglist = None\n        else:\n            sig_match = chpl_sig_pattern.match(sig)\n            if sig_match is None:\n                raise ValueError('Signature does not parse: {0}'.format(sig))\n\n            func_prefix, name_prefix, name, arglist, retann = \\\n                sig_match.groups()\n\n        modname = self.options.get(\n            'module', self.env.temp_data.get('chpl:module'))\n        classname = self.env.temp_data.get('chpl:class')\n\n        if classname:\n            if name_prefix and name_prefix.startswith(classname):\n                fullname = name_prefix + name\n                # class name is given again in the signature\n                name_prefix = name_prefix[len(classname):].lstrip('.')\n            elif name_prefix:\n                # class name is given in the signature, but different\n                # (shouldn't happen)\n                fullname = classname + '.' + name_prefix + name\n            else:\n                # class name is not given in the signature\n                fullname = classname + '.' + name\n        else:\n            if name_prefix:\n                classname = name_prefix.rstrip('.')\n                fullname = name_prefix + name\n            else:\n                classname = ''\n                fullname = name\n\n        signode['module'] = modname\n        signode['class'] = classname\n        signode['fullname'] = fullname\n\n        sig_prefix = self.get_signature_prefix(sig)\n        if sig_prefix:\n            signode += addnodes.desc_annotation(sig_prefix, sig_prefix)\n        # if func_prefix:\n        #     signode += addnodes.desc_addname(func_prefix, func_prefix)\n        if name_prefix:\n            signode += addnodes.desc_addname(name_prefix, name_prefix)\n\n        anno = self.options.get('annotation')\n\n        signode += addnodes.desc_name(name, name)\n\n        if not arglist:\n            # If this needs an arglist, and parens were provided in the\n            # signature, add a parameterlist. Chapel supports paren-less\n            # functions and methods, which can act as computed properties. If\n            # arglist is the empty string, the signature included parens. If\n            # arglist is None, it did not include parens.\n            if self.needs_arglist() and arglist is not None:\n                # for callables, add an empty parameter list\n                signode += addnodes.desc_parameterlist()\n            if retann:\n                signode += addnodes.desc_type(retann, retann)\n            if anno:\n                signode += addnodes.desc_annotation(' ' + anno, ' ' + anno)\n            return fullname, name_prefix\n\n        self._pseudo_parse_arglist(signode, arglist)\n        if retann:\n            signode += addnodes.desc_type(retann, retann)\n        if anno:\n            signode += addnodes.desc_annotation(' ' + anno, ' ' + anno)\n        return fullname, name_prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_target_and_index(self, name_cls, sig, signode):\n        modname = self.options.get(\n            'module', self.env.temp_data.get('chpl:module'))\n        fullname = (modname and modname + '.' or '') + name_cls[0]\n        # note target\n        if fullname not in self.state.document.ids:\n            signode['names'].append(fullname)\n            signode['ids'].append(fullname)\n            signode['first'] = (not self.names)\n            self.state.document.note_explicit_target(signode)\n            objects = self.env.domaindata['chpl']['objects']\n            if fullname in objects:\n                self.state_machine.reporter.warning(\n                    'duplicate object description of %s, ' % fullname +\n                    'other instance in ' +\n                    self.env.doc2path(objects[fullname][0]) +\n                    ', use :noindex: for one of them',\n                    line=self.lineno)\n            objects[fullname] = (self.env.docname, self.objtype)\n\n        indextext = self.get_index_text(modname, name_cls)\n        if indextext:\n            self.indexnode['entries'].append(('single', indextext,\n                                              fullname, ''))", "response": "Add cross - reference IDs and entries to the index node if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        env = self.state.document.settings.env\n        modname = self.arguments[0].strip()\n        noindex = 'noindex' in self.options\n        env.temp_data['chpl:module'] = modname\n        ret = []\n        if not noindex:\n            env.domaindata['chpl']['modules'][modname] = \\\n                (env.docname, self.options.get('synopsis', ''),\n                 self.options.get('platform', ''),\n                 'deprecated' in self.options)\n\n            # Make a duplicate entry in 'objects' to facilitate searching for\n            # the module in ChapelDomain.find_obj().\n            env.domaindata['chpl']['objects'][modname] = (\n                env.docname, 'module')\n            targetnode = nodes.target('', '', ids=['module-' + modname],\n                                      ismod=True)\n            self.state.document.note_explicit_target(targetnode)\n\n            # The platform and synopsis are not printed. In fact, they are only\n            # used in the modindex currently.\n            ret.append(targetnode)\n            indextext = _('%s (module)') % modname\n            inode = addnodes.index(entries=[('single', indextext,\n                                             'module-' + modname, '')])\n            ret.append(inode)\n        return ret", "response": "Custom execution for Chapel module directive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chpl_type_name(self):\n        if not self.objtype.endswith('method'):\n            return ''\n        elif self.objtype.startswith('iter'):\n            return 'iterator'\n        elif self.objtype == 'method':\n            return 'method'\n        else:\n            return ''", "response": "Returns iterator or method depending on object type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_index_text(self, modname, name_cls):\n        name, cls = name_cls\n        add_modules = self.env.config.add_module_names\n        if self.objtype.endswith('method'):\n            try:\n                clsname, methname = name.rsplit('.', 1)\n            except ValueError:\n                if modname:\n                    return _('%s() (in module %s)') % (name, modname)\n                else:\n                    return _('%s()') % name\n            if modname and add_modules:\n                return _('%s() (%s.%s %s)') % \\\n                    (methname, modname, clsname, self.chpl_type_name)\n            else:\n                return _('%s() (%s %s)') % \\\n                    (methname, clsname, self.chpl_type_name)\n        elif self.objtype == 'attribute':\n            try:\n                clsname, attrname = name.rsplit('.', 1)\n            except ValueError:\n                if modname:\n                    return _('%s (in module %s)') % (name, modname)\n                else:\n                    return name\n            if modname and add_modules:\n                return _('%s (%s.%s attribute)') % (attrname, modname, clsname)\n            else:\n                return _('%s (%s attribute)') % (attrname, clsname)\n        else:\n            return ''", "response": "Return text for index entry based on object type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_index_text(self, modname, name_cls):\n        if self.objtype in ('class', 'record'):\n            if not modname:\n                return _('%s (built-in %s)') % (name_cls[0], self.objtype)\n            return _('%s (%s in %s)') % (name_cls[0], self.objtype, modname)\n        else:\n            return ''", "response": "Return index entry text based on object type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef before_content(self):\n        ChapelObject.before_content(self)\n        if self.names:\n            self.env.temp_data['chpl:class'] = self.names[0][0]\n            self.clsname_set = True", "response": "Called before parsing content. Push the class name onto the class name stack Used to construct the full name for members."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns text for index entry based on object type.", "response": "def get_index_text(self, modname, name_cls):\n        \"\"\"Return text for index entry based on object type.\"\"\"\n        if self.objtype.endswith('function'):\n            if not modname:\n                return _('%s() (built-in %s)') % \\\n                    (name_cls[0], self.chpl_type_name)\n            return _('%s() (in module %s)') % (name_cls[0], modname)\n        elif self.objtype in ('data', 'type', 'enum'):\n            if not modname:\n                type_name = self.objtype\n                if type_name == 'data':\n                    type_name = 'variable'\n                return _('%s (built-in %s)') % (name_cls[0], type_name)\n            return _('%s (in module %s)') % (name_cls[0], modname)\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling after parsing title and target text and creating the reference node and return the title and target text.", "response": "def process_link(self, env, refnode, has_explicit_title, title, target):\n        \"\"\"Called after parsing title and target text, and creating the reference\n        node. Alter the reference node and return it with chapel module and\n        class information, if relevant.\n        \"\"\"\n        refnode['chpl:module'] = env.temp_data.get('chpl:module')\n        refnode['chpl:class'] = env.temp_data.get('chpl:class')\n        if not has_explicit_title:\n            # Only has a meaning for the target.\n            title = title.lstrip('.')\n\n            # Only has a meaning for the title.\n            target = target.lstrip('~')\n\n            if title[0:1] == '~':\n                title = title[1:]\n                dot = title.rfind('.')\n                if dot != -1:\n                    title = title[dot+1:]\n\n        # IF the first character is a dot, search more specific names\n        # first. Else, search builtins first.\n        if target[0:1] == '.':\n            target = target[1:]\n            refnode['refspecific'] = True\n\n        return title, target"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(self, docnames=None):\n        content = {}\n\n        # list of prefixes to ignore\n        ignores = self.domain.env.config['chapeldomain_modindex_common_prefix']\n        ignores = sorted(ignores, key=len, reverse=True)\n\n        # list of all modules, sorted by module name\n        modules = sorted(iteritems(self.domain.data['modules']),\n                         key=lambda x: x[0].lower())\n\n        # sort out collapsible modules\n        prev_modname = ''\n        num_toplevels = 0\n        for modname, (docname, synopsis, platforms, deprecated) in modules:\n            # If given a list of docnames and current docname is not in it,\n            # skip this docname for the index.\n            if docnames and docname not in docnames:\n                continue\n\n            for ignore in ignores:\n                if modname.startswith(ignore):\n                    modname = modname[len(ignore):]\n                    stripped = ignore\n                    break\n            else:\n                stripped = ''\n\n            # we stripped the whole module name?\n            if not modname:\n                modname, stripped = stripped, ''\n\n            # Put the module in correct bucket (first letter).\n            entries = content.setdefault(modname[0].lower(), [])\n\n            package = modname.split('.')[0]\n            if package != modname:\n                # it's a submodule!\n                if prev_modname == package:\n                    # first submodule - make parent a group head\n                    if entries:\n                        entries[-1][1] = 1\n                elif not prev_modname.startswith(package):\n                    # submodule without parent in list, add dummy entry\n                    entries.append([stripped + package, 1, '', '', '', '', ''])\n                subtype = 2\n            else:\n                num_toplevels += 1\n                subtype = 0\n\n            qualifier = deprecated and _('Deprecated') or ''\n            entries.append([stripped + modname, subtype, docname,\n                            'module-' + stripped + modname, platforms,\n                            qualifier, synopsis])\n            prev_modname = modname\n\n        # apply heuristics when to collapse modindex at page load: only\n        # collapse if number of toplevel modules is larger than number of\n        # submodules\n        collapse = len(modules) - num_toplevels < num_toplevels\n\n        # sort by first leter\n        content = sorted(iteritems(content))\n\n        return content, collapse", "response": "Generates a list of entries for index given by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the data associated with this instance of the domain.", "response": "def clear_doc(self, docname):\n        \"\"\"Remove the data associated with this instance of the domain.\"\"\"\n        for fullname, (fn, x) in self.data['objects'].items():\n            if fn == docname:\n                del self.data['objects'][fullname]\n        for modname, (fn, x, x, x) in self.data['modules'].items():\n            if fn == docname:\n                del self.data['modules'][modname]\n        for labelname, (fn, x, x) in self.data['labels'].items():\n            if fn == docname:\n                del self.data['labels'][labelname]\n        for anonlabelname, (fn, x) in self.data['anonlabels'].items():\n            if fn == docname:\n                del self.data['anonlabels'][anonlabelname]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_obj(self, env, modname, classname, name, type_name, searchmode=0):\n        if name[-2:] == '()':\n            name = name[:-2]\n\n        if not name:\n            return []\n\n        objects = self.data['objects']\n        matches = []\n\n        newname = None\n        if searchmode == 1:\n            if type_name is None:\n                objtypes = list(self.object_types)\n            else:\n                objtypes = self.objtypes_for_role(type_name)\n            if objtypes is not None:\n                if modname and classname:\n                    fullname = modname + '.' + classname + '.' + name\n                    if (fullname in objects and\n                            objects[fullname][1] in objtypes):\n                        newname = fullname\n                if not newname:\n                    if (modname and modname + '.' + name in objects and\n                            objects[modname + '.' + name][1] in objtypes):\n                        newname = modname + '.' + name\n                    elif name in objects and objects[name][1] in objtypes:\n                        newname = name\n                    else:\n                        # \"Fuzzy\" search mode.\n                        searchname = '.' + name\n                        matches = [(oname, objects[oname]) for oname in objects\n                                   if oname.endswith(searchname) and\n                                   objects[oname][1] in objtypes]\n        else:\n            # NOTE: Search for exact match, object type is not considered.\n            if name in objects:\n                newname = name\n            elif type_name == 'mod':\n                # Only exact matches allowed for modules.\n                return []\n            elif classname and classname + '.' + name in objects:\n                newname = classname + '.' + name\n            elif modname and modname + '.' + name in objects:\n                newname = modname + '.' + name\n            elif (modname and classname and\n                    modname + '.' + classname + '.' + name in objects):\n                newname = modname + '.' + classname + '.' + name\n\n        if newname is not None:\n            matches.append((newname, objects[newname]))\n        return matches", "response": "Find a Chapel object for name possibly with module or class or record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_xref(self, env, fromdocname, builder,\n                     type_name, target, node, contnode):\n        \"\"\"Resolve the pending_xref *node* with give *type_name* and *target*. Returns\n        None if xref node can not be resolved. If xref can be resolved, returns\n        new node containing the *contnode*.\n        \"\"\"\n        # Special case the :chpl:chplref:`chplmodindex` instances.\n        if type_name == 'chplref':\n            if node['refexplicit']:\n                # Reference to anonymous label. The reference uses the supplied\n                # link caption.\n                docname, labelid = self.data['anonlabels'].get(\n                    target, ('', ''))\n                sectname = node.astext()\n            else:\n                # Reference to named label. The final node will contain the\n                # section name after the label.\n                docname, labelid, sectname = self.data['labels'].get(\n                    target, ('', '', ''))\n\n            if not docname:\n                return None\n\n            return self._make_refnode(\n                fromdocname, builder, docname, labelid, sectname, contnode)\n\n        modname = node.get('chpl:module')\n        clsname = node.get('chpl:class')\n        searchmode = 1 if node.hasattr('refspecific') else 0\n        matches = self.find_obj(env, modname, clsname, target,\n                                type_name, searchmode)\n\n        if not matches:\n            return None\n        elif len(matches) > 1:\n            env.warn_node(\n                'more than one target found for cross-reference '\n                '%r: %s' % (target, ', '.join(match[0] for match in matches)),\n                node)\n        name, obj = matches[0]\n\n        if obj[1] == 'module':\n            return self._make_module_refnode(\n                builder, fromdocname, name, contnode)\n        else:\n            return make_refnode(builder, fromdocname, obj[0], name,\n                                contnode, name)", "response": "Resolve the xref node with give type_name and target. Returns None if xref node can not be resolved."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_any_xref(self, env, fromdocname, builder, target,\n                         node, contnode):\n        \"\"\"Similar to :py:meth:`ChapelDomain.resolve_xref`, but applies to *any* or\n        similar role where type is not known. This returns a list of tuples\n        with (\"domain:role\", newnode).\n        \"\"\"\n        modname = node.get('chpl:module')\n        clsname = node.get('chpl:class')\n        results = []\n\n        # Always search in \"refspecific\" mode with the :any: role.\n        matches = self.find_obj(env, modname, clsname, target, None, 1)\n        for name, obj in matches:\n            if obj[1] == 'module':\n                results.append(('chpl:mod',\n                                self._make_module_refnode(builder, fromdocname,\n                                                          name, contnode)))\n            else:\n                results.append(\n                    ('chpl:' + self.role_for_objtype(obj[1]),\n                     make_refnode(builder, fromdocname, obj[0], name,\n                                  contnode, name)))\n\n        return results", "response": "This method is used to resolve any xref of any object in the ChapelDomain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_refnode(self, fromdocname, builder, docname, labelid, sectname,\n                      contnode, **kwargs):\n        \"\"\"Return reference node for something like ``:chpl:chplref:``.\"\"\"\n        nodeclass = kwargs.pop('nodeclass', nodes.reference)\n        newnode = nodeclass('', '', internal=True, **kwargs)\n        innernode = nodes.emphasis(sectname, sectname)\n        if docname == fromdocname:\n            newnode['refid'] = labelid\n        else:\n            # Set more info on contnode. In case the get_relative_uri call\n            # raises NoUri, the builder will then have to resolve these.\n            contnode = addnodes.pending_xref('')\n            contnode['refdocname'] = docname\n            contnode['refsectname'] = sectname\n            newnode['refuri'] = builder.get_relative_uri(fromdocname, docname)\n            if labelid:\n                newnode['refuri'] += '#' + labelid\n        newnode.append(innernode)\n        return newnode", "response": "Return a reference node for something like chpl : chplref :"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_module_refnode(self, builder, fromdocname, name, contnode):\n        # Get additional info for modules.\n        docname, synopsis, platform, deprecated = self.data['modules'][name]\n        title = name\n        if synopsis:\n            title += ': ' + synopsis\n        if deprecated:\n            title += _(' (deprecated)')\n        if platform:\n            title += ' (' + platform + ')'\n        return make_refnode(builder, fromdocname, docname,\n                            'module-' + name, contnode, title)", "response": "Helper function to generate xref node based on current environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge in data regarding docnames from a different domaindata inventory.", "response": "def merge_domaindata(self, docnames, otherdata):\n        \"\"\"Merge in data regarding *docnames* from a different domaindata inventory\n        (coming froma subprocess in a parallel build).\n        \"\"\"\n        for fullname, (fn, objtype) in otherdata['objects'].items():\n            if fn in docnames:\n                self.data['objects'][fullname] = (fn, objtype)\n        for modname, data in otherdata['modules'].items():\n            if data[0] in docnames:\n                self.data['modules'][modname] = data\n        for labelname, data in otherdata['labels'].items():\n            if data[0] in docnames:\n                self.data['labels'][labelname] = data\n        for anonlabelname, data in otherdata['anonlabels'].items():\n            if data[0] in docnames:\n                self.data['anonlabels'][anonlabelname] = data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn iterable of object descriptions which are tuple with these items", "response": "def get_objects(self):\n        \"\"\"Return iterable of \"object descriptions\", which are tuple with these items:\n\n        * `name`\n        * `dispname`\n        * `type`\n        * `docname`\n        * `anchor`\n        * `priority`\n\n        For details on each item, see\n        :py:meth:`~sphinx.domains.Domain.get_objects`.\n        \"\"\"\n        for modname, info in self.data['modules'].items():\n            yield (modname, modname, 'module', info[0], 'module-' + modname, 0)\n        for refname, (docname, type_name) in self.data['objects'].items():\n            if type_name != 'module':  # modules are already handled\n                yield (refname, refname, type_name, docname, refname, 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    logger.info(\"Options used:\")\n    for key, value in vars(args).iteritems():\n        logger.info(\"  --{} {}\".format(key.replace(\"_\", \"-\"), value))\n\n    # Reads the population file\n    logger.info(\"Reading population file\")\n    populations = read_population_file(args.population_file)\n\n    # Reads the MDS file\n    logger.info(\"Reading MDS file\")\n    mds = read_mds_file(args.mds, args.xaxis, args.yaxis, populations)\n\n    # Finds the population centers\n    logger.info(\"Finding reference population centers\")\n    centers, center_info = find_ref_centers(mds)\n\n    # Computes three clusters using KMeans and the reference cluster centers\n    logger.info(\"Finding outliers\")\n    outliers = find_outliers(mds, centers, center_info, args.outliers_of, args)\n    logger.info(\"  - There are {} outliers for the {} population\".format(\n        len(outliers),\n        args.outliers_of,\n    ))\n\n    # Printing the outlier file\n    try:\n        with open(args.out + \".outliers\", 'w') as output_file:\n            for sample_id in outliers:\n                print >>output_file, \"\\t\".join(sample_id)\n    except IOError:\n        msg = \"{}: can't write file\".format(args.out + \".outliers\")\n        raise ProgramError(msg)\n\n    # Printing the outlier population file\n    try:\n        with open(args.out + \".population_file_outliers\", \"w\") as output_file:\n            for sample_id, population in populations.iteritems():\n                if sample_id in outliers:\n                    population = \"OUTLIER\"\n                print >>output_file, \"\\t\".join(list(sample_id) + [population])\n    except IOError:\n        msg = \"{}: can't write file\".format(\n            args.out + \".population_file_outliers\",\n        )\n        raise ProgramError(msg)\n\n    # If there is a summary file in the working directory (for LaTeX), we want\n    # to modify it, because it means that this script is run after the pipeline\n    # (to modify the multiplier, for example).\n    if args.overwrite_tex:\n        summary_file = glob(os.path.join(os.getcwd(), \"*.summary.tex\"))\n        if len(summary_file) == 0:\n            logger.warning(\"No TeX summary file found\")\n        if len(summary_file) > 1:\n            raise ProgramError(\"More than one TeX summary file found\")\n        summary_file = summary_file[0]\n\n        # Overwriting\n        overwrite_tex(summary_file, len(outliers), args)", "response": "The main function of the KMeans algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef overwrite_tex(tex_fn, nb_outliers, script_options):\n    # Getting the content of the TeX file\n    content = None\n    with open(tex_fn, \"r\") as i_file:\n        content = i_file.read()\n\n    # Is there a figure\n    has_figure = re.search(\"includegraphics\", content) is not None\n\n    # Changing the first sentence\n    content, n = re.subn(\n        r\"(Using\\s[0-9,]+\\smarkers?\\sand\\sa\\smultiplier\\sof\\s)[0-9.]+\"\n        r\"(,\\sthere\\swas\\sa\\stotal\\sof\\s)[0-9,]+(\\soutliers?\\sof\\sthe\\s)\"\n        r\"\\w+(\\spopulation.)\",\n        r\"\\g<1>{}\\g<2>{:,d}\\g<3>{}\\g<4>\".format(\n            script_options.multiplier,\n            nb_outliers,\n            script_options.outliers_of,\n        ),\n        content\n    )\n    if n != 1:\n        raise ProgramError(\"{}: invalid TeX summary file\".format(tex_fn))\n\n    # Do we need to change the principal components in the text?\n    c1_c2 = {\"C1\", \"C2\"}\n    if has_figure and ({script_options.xaxis, script_options.yaxis} != c1_c2):\n        content, n = re.subn(\n            r\"(shows\\s)the\\sfirst\\stwo\\sprincipal\\scomponents(\\sof\\sthe\\sMDS\"\n            r\"\\sanalysis)\",\n            r\"\\g<1>components {} versus {}\\g<2>\".format(\n                script_options.yaxis.replace(\"C\", \"\"),\n                script_options.xaxis.replace(\"C\", \"\"),\n            ),\n            content,\n        )\n        if n != 1:\n            raise ProgramError(\"{}: invalid TeX summary file\".format(tex_fn))\n\n        content, n = re.subn(\n            r\"(MDS\\splots\\sshowing\\s)the\\sfirst\\stwo\\sprincipal\\scomponents\"\n            r\"(\\sof\\sthe\\ssource\\sdataset\\swith\\sthe\\sreference\\spanels.)\",\n            r\"\\g<1>components {} versus {}\\g<2>\".format(\n                script_options.yaxis.replace(\"C\", \"\"),\n                script_options.xaxis.replace(\"C\", \"\"),\n            ),\n            content,\n        )\n        if n != 1:\n            raise ProgramError(\"{}: invalid TeX summary file\".format(tex_fn))\n\n    if has_figure:\n        # Changing the population in the figure description\n        content, n = re.subn(\n            r\"(where\\soutliers\\sof\\sthe\\s)\\w+(\\spopulation\\sare\\sshown\\s\"\n            r\"in\\sgrey.)\",\n            r\"\\g<1>{}\\g<2>\".format(script_options.outliers_of),\n            content,\n        )\n        if n != 1:\n            raise ProgramError(\"{}: invalid TeX summary file\".format(tex_fn))\n\n        content, n = re.subn(\n            r\"(The\\soutliers\\sof\\sthe\\s)\\w+(\\spopulation\\sare\\sshown\\sin\\s\"\n            r\"grey,\\swhile\\ssamples\\sof\\sthe\\ssource\\sdataset\\sthat\\s\"\n            r\"resemble\\sthe\\s)\\w+(\\spopulation\\sare\\sshown\\sin\\sorange.\\sA\\s\"\n            r\"multiplier\\sof\\s)[0-9.]+(\\swas\\sused\\sto\\sfind\\sthe\\s)[0-9,]+(\\s\"\n            r\"outliers?.)\",\n            r\"\\g<1>{pop}\\g<2>{pop}\\g<3>{mult}\\g<4>{nb:,d}\\g<5>\".format(\n                pop=script_options.outliers_of,\n                mult=script_options.multiplier,\n                nb=nb_outliers,\n            ),\n            content,\n        )\n        if n != 1:\n            raise ProgramError(\"{}: invalid TeX summary file\".format(tex_fn))\n\n        # Changing the figure (path)\n        content, n = re.subn(\n            r\"(\\s\\\\includegraphics\\[.+\\]\\{)\\{ethnicity.outliers\\}.png(\\}\\s)\",\n            r\"\\g<1>{}\\g<2>\".format(\n                \"{\" + script_options.out + \".outliers}.\" +\n                script_options.format\n            ),\n            content,\n        )\n        if n != 1:\n            raise ProgramError(\"{}: invalid TeX summary file\".format(tex_fn))\n\n    # Saving the new content\n    with open(tex_fn, \"w\") as o_file:\n        o_file.write(content)", "response": "Overwrites the TeX summary file with new values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the outliers for a given population. :param mds: the ``mds`` information about each samples. :param centers: the centers of the three reference population clusters. :param center_info: the label of the three reference population clusters. :param ref_pop: the reference population for which we need the outliers from. :param options: the options :type mds: numpy.recarray :type centers: numpy.array :type center_info: dict :type ref_pop: str :type options: argparse.Namespace :returns: a :py:class:`set` of outliers from the ``ref_pop`` population. Perform a ``KMeans`` classification using the three centers from the three reference population cluster. Samples are outliers of the required reference population (``ref_pop``) if: * the sample is part of another reference population cluster; * the sample is an outlier of the desired reference population (``ref_pop``). A sample is an outlier of a given cluster :math:`C_j` if the distance between this sample and the center of the cluster :math:`C_j` (:math:`O_j`) is bigger than a constant times the cluster's standard deviation :math:`\\\\sigma_j`. .. math:: \\\\sigma_j = \\\\sqrt{\\\\frac{\\\\sum{d(s_i,O_j)^2}}{||C_j|| - 1}} where :math:`||C_j||` is the number of samples in the cluster :math:`C_j`, and :math:`d(s_i,O_j)` is the distance between the sample :math:`s_i` and the center :math:`O_j` of the cluster :math:`C_j`. .. math:: d(s_i, O_j) = \\\\sqrt{(x_{O_j} - x_{s_i})^2 + (y_{O_j} - y_{s_i})^2} Using a constant equals to one ensure we remove 100% of the outliers from the cluster. Using a constant of 1.6 or 1.9 ensures we remove 99% and 95% of outliers, respectively (an error rate of 1% and 5%, respectively).", "response": "def find_outliers(mds, centers, center_info, ref_pop, options):\n    \"\"\"Finds the outliers for a given population.\n\n    :param mds: the ``mds`` information about each samples.\n    :param centers: the centers of the three reference population clusters.\n    :param center_info: the label of the three reference population clusters.\n    :param ref_pop: the reference population for which we need the outliers\n                    from.\n    :param options: the options\n\n    :type mds: numpy.recarray\n    :type centers: numpy.array\n    :type center_info: dict\n    :type ref_pop: str\n    :type options: argparse.Namespace\n\n    :returns: a :py:class:`set` of outliers from the ``ref_pop`` population.\n\n    Perform a ``KMeans`` classification using the three centers from the three\n    reference population cluster.\n\n    Samples are outliers of the required reference population (``ref_pop``) if:\n\n    * the sample is part of another reference population cluster;\n    * the sample is an outlier of the desired reference population\n      (``ref_pop``).\n\n    A sample is an outlier of a given cluster :math:`C_j` if the distance\n    between this sample and the center of the cluster :math:`C_j` (:math:`O_j`)\n    is bigger than a constant times the cluster's standard deviation\n    :math:`\\\\sigma_j`.\n\n    .. math::\n        \\\\sigma_j = \\\\sqrt{\\\\frac{\\\\sum{d(s_i,O_j)^2}}{||C_j|| - 1}}\n\n    where :math:`||C_j||` is the number of samples in the cluster :math:`C_j`,\n    and :math:`d(s_i,O_j)` is the distance between the sample :math:`s_i` and\n    the center :math:`O_j` of the cluster :math:`C_j`.\n\n    .. math::\n        d(s_i, O_j) = \\\\sqrt{(x_{O_j} - x_{s_i})^2 + (y_{O_j} - y_{s_i})^2}\n\n    Using a constant equals to one ensure we remove 100% of the outliers from\n    the cluster. Using a constant of 1.6 or 1.9 ensures we remove 99% and 95%\n    of outliers, respectively (an error rate of 1% and 5%, respectively).\n\n    \"\"\"\n    # Importing matplotlib for plotting purposes\n    import matplotlib as mpl\n    if options.format != \"X11\" and mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    if options.format != \"X11\":\n        plt.ioff()\n    import matplotlib.mlab as mlab\n\n    from sklearn.cluster import KMeans\n    from sklearn.metrics.pairwise import euclidean_distances\n\n    # Formatting the data\n    data = np.array(zip(mds[\"c1\"], mds[\"c2\"]))\n\n    # Configuring and running the KMeans\n    k_means = KMeans(init=centers, n_clusters=3, n_init=1)\n    k_means.fit_predict(data)\n\n    # Creating the figure and axes\n    fig_before, axe_before = plt.subplots(1, 1)\n    fig_after, axe_after = plt.subplots(1, 1)\n    fig_outliers, axe_outliers = plt.subplots(1, 1)\n\n    # Setting the axe\n    axe_before.xaxis.set_ticks_position(\"bottom\")\n    axe_before.yaxis.set_ticks_position(\"left\")\n    axe_before.spines[\"top\"].set_visible(False)\n    axe_before.spines[\"right\"].set_visible(False)\n    axe_before.spines[\"bottom\"].set_position((\"outward\", 9))\n    axe_before.spines[\"left\"].set_position((\"outward\", 9))\n    axe_after.xaxis.set_ticks_position(\"bottom\")\n    axe_after.yaxis.set_ticks_position(\"left\")\n    axe_after.spines[\"top\"].set_visible(False)\n    axe_after.spines[\"right\"].set_visible(False)\n    axe_after.spines[\"bottom\"].set_position((\"outward\", 9))\n    axe_after.spines[\"left\"].set_position((\"outward\", 9))\n    axe_outliers.xaxis.set_ticks_position(\"bottom\")\n    axe_outliers.yaxis.set_ticks_position(\"left\")\n    axe_outliers.spines[\"top\"].set_visible(False)\n    axe_outliers.spines[\"right\"].set_visible(False)\n    axe_outliers.spines[\"bottom\"].set_position((\"outward\", 9))\n    axe_outliers.spines[\"left\"].set_position((\"outward\", 9))\n\n    # Setting the title and labels\n    axe_before.set_title(\"Before finding outliers\", weight=\"bold\")\n    axe_before.set_xlabel(options.xaxis)\n    axe_before.set_ylabel(options.yaxis)\n    axe_after.set_title(\"After finding outliers\\n($> {} \"\n                        \"\\\\sigma$)\".format(options.multiplier), weight=\"bold\")\n    axe_after.set_xlabel(options.xaxis)\n    axe_after.set_ylabel(options.yaxis)\n    axe_outliers.set_title(\"Outliers\", weight=\"bold\")\n    axe_outliers.set_xlabel(options.xaxis)\n    axe_outliers.set_ylabel(options.yaxis)\n\n    # The population name\n    ref_pop_name = [\"CEU\", \"YRI\", \"JPT-CHB\"]\n\n    # The colors\n    colors = [\"#CC0000\", \"#669900\", \"#0099CC\"]\n    outlier_colors = [\"#FFCACA\", \"#E2F0B6\", \"#C5EAF8\"]\n\n    # Plotting each of the clusters with the initial center\n    plots_before = []\n    plots_after = []\n    plots_outliers = []\n    plot_outliers = None\n    plot_not_outliers = None\n    outliers_set = set()\n    for label in xrange(3):\n        # Subsetting the data\n        subset_mds = mds[k_means.labels_ == label]\n        subset_data = data[k_means.labels_ == label]\n\n        # Plotting the cluster\n        p, = axe_before.plot(subset_mds[\"c1\"], subset_mds[\"c2\"], \"o\",\n                             mec=colors[label], mfc=colors[label], ms=2,\n                             clip_on=False)\n        plots_before.append(p)\n\n        # Plotting the cluster center (the real one)\n        axe_before.plot(centers[label][0], centers[label][1], \"o\",\n                        mec=\"#000000\", mfc=\"#FFBB33\", ms=6, clip_on=False)\n\n        # Computing the distances\n        distances = euclidean_distances(subset_data, centers[label])\n\n        # Finding the outliers (that are not in the reference populations\n        sigma = np.sqrt(np.true_divide(np.sum(distances ** 2),\n                                       len(distances) - 1))\n        outliers = np.logical_and(\n            (distances > options.multiplier * sigma).flatten(),\n            subset_mds[\"pop\"] != ref_pop_name[label],\n        )\n        logger.info(\"  - {} outliers for the {} cluster\".format(\n            np.sum(outliers),\n            ref_pop_name[label],\n        ))\n\n        # Saving the outliers\n        if ref_pop_name[label] != options.outliers_of:\n            # This is not the population we want, hence everybody is an outlier\n            # (we don't include the reference population).\n            outlier_mds = subset_mds[subset_mds[\"pop\"] != ref_pop_name[label]]\n            outliers_set |= set([(i[\"fid\"], i[\"iid\"]) for i in outlier_mds])\n\n            # Plotting all samples that are not part of the reference\n            # populations\n            axe_outliers.plot(\n                subset_mds[\"c1\"][subset_mds[\"pop\"] != ref_pop_name[label]],\n                subset_mds[\"c2\"][subset_mds[\"pop\"] != ref_pop_name[label]],\n                \"o\",\n                mec=\"#555555\",\n                mfc=\"#555555\",\n                ms=2,\n                clip_on=False,\n            )\n        else:\n            # This is the population we want, hence only the real outliers are\n            # outliers (we don't include the reference population)\n            outlier_mds = subset_mds[\n                np.logical_and(subset_mds[\"pop\"] != ref_pop_name[label],\n                               outliers)\n            ]\n\n            # Plotting the outliers\n            plot_outliers, = axe_outliers.plot(outlier_mds[\"c1\"],\n                                               outlier_mds[\"c2\"], \"o\",\n                                               mec=\"#555555\", mfc=\"#555555\",\n                                               ms=2, clip_on=False)\n\n            # Plotting the not outliers\n            plot_not_outliers, = axe_outliers.plot(\n                subset_mds[\"c1\"][np.logical_and(\n                        ~outliers,\n                        subset_mds[\"pop\"] != ref_pop_name[label]\n                )],\n                subset_mds[\"c2\"][np.logical_and(\n                    ~outliers,\n                    subset_mds[\"pop\"] != ref_pop_name[label]\n                )],\n                \"o\",\n                mec=\"#FFBB33\",\n                mfc=\"#FFBB33\",\n                ms=2,\n                clip_on=False,\n            )\n            outliers_set |= set([(i[\"fid\"], i[\"iid\"]) for i in outlier_mds])\n\n        # Plotting the cluster (without outliers)\n        p, = axe_after.plot(\n            subset_mds[~outliers][\"c1\"],\n            subset_mds[~outliers][\"c2\"],\n            \"o\",\n            mec=colors[label],\n            mfc=colors[label],\n            ms=2,\n            clip_on=False,\n        )\n        plots_after.append(p)\n\n        # Plotting the cluster (only outliers)\n        axe_after.plot(subset_mds[outliers][\"c1\"], subset_mds[outliers][\"c2\"],\n                       \"o\", mec=outlier_colors[label],\n                       mfc=outlier_colors[label], ms=2, clip_on=False)\n\n        # Plotting only the reference populations\n        p, = axe_outliers.plot(\n            subset_mds[\"c1\"][subset_mds[\"pop\"] == ref_pop_name[label]],\n            subset_mds[\"c2\"][subset_mds[\"pop\"] == ref_pop_name[label]],\n            \"o\",\n            mec=colors[label],\n            mfc=colors[label],\n            ms=2,\n            clip_on=False,\n        )\n        plots_outliers.append(p)\n\n        # Plotting the cluster center (the real one)\n        axe_after.plot(centers[label][0], centers[label][1], \"o\",\n                       mec=\"#000000\", mfc=\"#FFBB33\", ms=6)\n\n    # The legends\n    axe_before.legend(plots_before, ref_pop_name, loc=\"best\", numpoints=1,\n                      fancybox=True, fontsize=8).get_frame().set_alpha(0.5)\n    axe_after.legend(plots_after, ref_pop_name, loc=\"best\", numpoints=1,\n                     fancybox=True, fontsize=8).get_frame().set_alpha(0.5)\n    axe_outliers.legend(plots_outliers + [plot_not_outliers, plot_outliers],\n                        ref_pop_name + [\"SOURCE\", \"OUTLIERS\"], loc=\"best\",\n                        numpoints=1, fancybox=True,\n                        fontsize=8).get_frame().set_alpha(0.5)\n\n    # Saving the figure\n    fig_before.savefig(\"{}.before.{}\".format(options.out, options.format),\n                       dpi=300)\n    fig_after.savefig(\"{}.after.{}\".format(options.out, options.format),\n                      dpi=300)\n    fig_outliers.savefig(\"{}.outliers.{}\".format(options.out, options.format),\n                         dpi=300)\n\n    return outliers_set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_ref_centers(mds):\n    # Computing the centers of each of the reference clusters\n    ceu_mds = mds[mds[\"pop\"] == \"CEU\"]\n    yri_mds = mds[mds[\"pop\"] == \"YRI\"]\n    asn_mds = mds[mds[\"pop\"] == \"JPT-CHB\"]\n\n    # Computing the centers\n    centers = [[np.mean(ceu_mds[\"c1\"]), np.mean(ceu_mds[\"c2\"])],\n               [np.mean(yri_mds[\"c1\"]), np.mean(yri_mds[\"c2\"])],\n               [np.mean(asn_mds[\"c1\"]), np.mean(asn_mds[\"c2\"])]]\n\n    return np.array(centers), {\"CEU\": 0, \"YRI\": 1, \"JPT-CHB\": 2}", "response": "Finds the center of the three reference population clusters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_mds_file(file_name, c1, c2, pops):\n    mds = []\n    max_fid = 0\n    max_iid = 0\n    with open(file_name, 'rb') as input_file:\n        # Getting and checking the header\n        header_index = dict([\n            (col_name, i) for i, col_name in\n            enumerate(create_row(input_file.readline()))\n        ])\n        for col_name in {\"FID\", \"IID\", c1, c2}:\n            if col_name not in header_index:\n                msg = \"{}: no column named {}\".format(file_name, col_name)\n                raise ProgramError(msg)\n\n        for row in map(create_row, input_file):\n            # Getting the sample ID\n            sample_id = (row[header_index[\"FID\"]], row[header_index[\"IID\"]])\n\n            # Checking we have a population for this sample\n            if sample_id not in pops:\n                msg = \"{} {}: not in population file\".format(sample_id[0],\n                                                             sample_id[1])\n                raise ProgramError(msg)\n\n            # Saving the data\n            mds.append((sample_id[0], sample_id[1], row[header_index[c1]],\n                        row[header_index[c2]], pops[sample_id]))\n\n            # Cheking to find the max FID\n            if len(sample_id[0]) > max_fid:\n                max_fid = len(sample_id[0])\n            if len(sample_id[1]) > max_iid:\n                max_iid = len(sample_id[1])\n\n    # Creating the numpy array\n    mds = np.array(mds, dtype=[(\"fid\", \"a{}\".format(max_fid)),\n                               (\"iid\", \"a{}\".format(max_iid)),\n                               (\"c1\", float), (\"c2\", float),\n                               (\"pop\", \"a7\")])\n\n    return mds", "response": "Reads a MDS file and returns a numpy array with the information about the family ID individual ID and the first component ID and the second component ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_population_file(file_name):\n    pops = {}\n    required_pops = {\"CEU\", \"YRI\", \"JPT-CHB\", \"SOURCE\"}\n    with open(file_name, 'rb') as input_file:\n        for line in input_file:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n            # The data\n            sample_id = tuple(row[:2])\n            pop = row[-1]\n\n            # Checking the pop\n            if pop not in required_pops:\n                msg = (\"{}: sample {}: unknown population \"\n                       \"{}\".format(file_name, \" \".join(sample_id), pop))\n                raise ProgramError(msg)\n\n            # Saving the population file\n            pops[tuple(row[:2])] = row[-1]\n\n    return pops", "response": "Reads the population file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the arguments and options for validity.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: a :py:class:`argparse.Namespace` object containing the options\n                 of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Checking the input files\n    if not os.path.isfile(args.mds):\n        msg = \"{}: no such file\".format(args.mds)\n        raise ProgramError(msg)\n\n    if not os.path.isfile(args.population_file):\n        msg = \"{}: no such file\".format(args.population_file)\n        raise ProgramError(msg)\n\n    # Checking the chosen components\n    if args.xaxis == args.yaxis:\n        msg = \"xaxis must be different than yaxis\"\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding custom options to a parser.", "response": "def add_custom_options(parser):\n    \"\"\"Adds custom options to a parser.\n\n    :param parser: the parser to which to add options.\n\n    :type parser: argparse.ArgumentParser\n\n    \"\"\"\n    parser.add_argument(\"--outliers-of\", type=str, metavar=\"POP\",\n                        default=\"CEU\", choices=[\"CEU\", \"YRI\", \"JPT-CHB\"],\n                        help=(\"Finds the outliers of this population. \"\n                              \"[default: %(default)s]\"))\n    parser.add_argument(\"--multiplier\", type=float, metavar=\"FLOAT\",\n                        default=1.9,\n                        help=(\"To find the outliers, we look for more than \"\n                              \"x times the cluster standard deviation. \"\n                              \"[default: %(default).1f]\"))\n    parser.add_argument(\"--xaxis\", type=str, metavar=\"COMPONENT\", default=\"C1\",\n                        choices=[\"C{}\".format(i) for i in xrange(1, 11)],\n                        help=(\"The component to use for the X axis. \"\n                              \"[default: %(default)s]\"))\n    parser.add_argument(\"--yaxis\", type=str, metavar=\"COMPONENT\", default=\"C2\",\n                        choices=[\"C{}\".format(i) for i in xrange(1, 11)],\n                        help=(\"The component to use for the Y axis. \"\n                              \"[default: %(default)s]\"))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_data(cls, data):\n        messages = []\n        filename = data['checker']['filename']\n        for m in data['messages']:\n            for l in m['locations']:\n                location = l['path']\n                if not location.startswith(filename):\n                    location = filename + '/' + location\n                if l['line'] != -1:\n                    location += ':{}'.format(l['line'])\n                if l['column'] != -1:\n                    location += ':{}'.format(l['column'])\n                messages.append(\n                    cls(m['ID'], m['severity'], location, m['message'], m['suggestion'])\n                )\n        return messages", "response": "Create a list of Messages from deserialized epubcheck json output."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows the dialog with the name of the current locale.", "response": "def show(self):\r\n        \"\"\"\r\n        if the dialog is showed again or is not started with exec_\r\n        naming the done button to 'update' make more sense\r\n        because now the dialog doesn't block (anymore)\r\n        \"\"\"\r\n        self.btn_done.clicked.connect(lambda: self.btn_done.setText('update'))\r\n        QtWidgets.QDialog.show(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether all attributes are setted and have the right dtype", "response": "def check(self):\r\n        \"\"\"check whether all attributes are setted and have the right dtype\"\"\"\r\n        for name, valItem, dtype in self.values:\r\n            val = valItem.text()\r\n            if dtype:\r\n                try:\r\n                    val = dtype(val)\r\n                except:\r\n                    msgBox = QtWidgets.QMessageBox()\r\n                    msgBox.setText(\r\n                        'attribute %s has not the right dtype(%s)' %\r\n                        (name, str(dtype)))\r\n                    msgBox.exec_()\r\n            self.args[name] = val\r\n        self.accept()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the geometry before dialog is close to restore it later", "response": "def done(self, result):\r\n        \"\"\"save the geometry before dialog is close to restore it later\"\"\"\r\n        self._geometry = self.geometry()\r\n        QtWidgets.QDialog.done(self, result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget start date of a module.", "response": "def get_start_date(module, x):\n    \"\"\" \u66dc\u65e5\u306b\u3088\u308b\u6700\u521d\u306e\u6388\u696d\u306e\u65e5\u3092\u8fd4\u3059 \"\"\"\n    weekdays = ['\u6708', '\u706b', '\u6c34', '\u6728', '\u91d1', '\u571f', '\u65e5']\n    a, b = parse_module(module)\n    module = a + b[0]\n\n    d = datetime.datetime(*start_dates[module])\n    days = weekdays.index(x) - d.weekday()\n    if days < 0:\n        days += 7\n    delta = datetime.timedelta(days=days)\n    return d + delta"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_end_date(module):\n    a, b = parse_module(module)\n    module = a + b[-1]\n    return datetime.datetime(*end_dates[module])", "response": "Get end date of a module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the Trovebox HTTP client configuration.", "response": "def configure(self, **kwds):\n        \"\"\"\n        Update Trovebox HTTP client configuration.\n\n        :param api_version: Include a Trovebox API version in all requests.\n            This can be used to ensure that your application will continue\n            to work even if the Trovebox API is updated to a new revision.\n            [default: None]\n        :param ssl_verify: If true, HTTPS SSL certificates will always be\n            verified [default: True]\n        \"\"\"\n        for item in kwds:\n            self.config[item] = kwds[item]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform an HTTP GET from the specified endpoint (API path), passing parameters if given. The api_version is prepended to the endpoint, if it was specified when the Trovebox object was created. Returns the decoded JSON dictionary, and raises exceptions if an error code is received. Returns the raw response if process_response=False", "response": "def get(self, endpoint, process_response=True, **params):\n        \"\"\"\n        Performs an HTTP GET from the specified endpoint (API path),\n            passing parameters if given.\n        The api_version is prepended to the endpoint,\n            if it was specified when the Trovebox object was created.\n\n        Returns the decoded JSON dictionary, and raises exceptions if an\n            error code is received.\n        Returns the raw response if process_response=False\n        \"\"\"\n        params = self._process_params(params)\n        url = self._construct_url(endpoint)\n\n        if self.auth.consumer_key:\n            auth = requests_oauthlib.OAuth1(self.auth.consumer_key,\n                                            self.auth.consumer_secret,\n                                            self.auth.token,\n                                            self.auth.token_secret)\n        else:\n            auth = None\n\n        with requests.Session() as session:\n            session.verify = self.config[\"ssl_verify\"]\n            response = session.get(url, params=params, auth=auth)\n\n        self._logger.info(\"============================\")\n        self._logger.info(\"GET %s\" % url)\n        self._logger.info(\"---\")\n        self._logger.info(response.text[:1000])\n        if len(response.text) > 1000: # pragma: no cover\n            self._logger.info(\"[Response truncated to 1000 characters]\")\n\n        self.last_url = url\n        self.last_params = params\n        self.last_response = response\n\n        if process_response:\n            return self._process_response(response)\n        else:\n            if 200 <= response.status_code < 300:\n                return response.text\n            else:\n                raise TroveboxError(\"HTTP Error %d: %s\" %\n                                    (response.status_code, response.reason))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct the full URL to the specified endpoint", "response": "def _construct_url(self, endpoint):\n        \"\"\"Return the full URL to the specified endpoint\"\"\"\n        parsed_url = urlparse(self.host)\n        scheme = parsed_url[0]\n        host = parsed_url[1]\n        # Handle host without a scheme specified (eg. www.example.com)\n        if scheme == \"\":\n            scheme = \"http\"\n            host = self.host\n\n        if not endpoint.startswith(\"/\"):\n            endpoint = \"/\" + endpoint\n        if self.config[\"api_version\"] is not None:\n            endpoint = \"/v%d%s\" % (self.config[\"api_version\"], endpoint)\n        return urlunparse((scheme, host, endpoint, '', '', ''))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_params(self, params):\n        processed_params = {}\n        for key, value in params.items():\n            processed_params[key] = self._process_param_value(value)\n\n        return processed_params", "response": "Converts Unicode lists and booleans inside HTTP parameters into Python objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing the parameter value and returns a UTF - 8 string representation of the parameter value recursing into lists.", "response": "def _process_param_value(self, value):\n        \"\"\"\n        Returns a UTF-8 string representation of the parameter value,\n        recursing into lists.\n        \"\"\"\n        # Extract IDs from objects\n        if isinstance(value, TroveboxObject):\n            return str(value.id).encode('utf-8')\n\n        # Ensure strings are UTF-8 encoded\n        elif isinstance(value, TEXT_TYPE):\n            return value.encode(\"utf-8\")\n\n        # Handle lists\n        elif isinstance(value, list):\n            # Make a copy of the list, to avoid overwriting the original\n            new_list = list(value)\n            # Process each item in the list\n            for i, item in enumerate(new_list):\n                new_list[i] = self._process_param_value(item)\n            # new_list elements are UTF-8 encoded strings - simply join up\n            return b','.join(new_list)\n\n        # Handle booleans\n        elif isinstance(value, bool):\n            return b\"1\" if value else b\"0\"\n\n        # Unknown - just do our best\n        else:\n            return str(value).encode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict containing the Trovebox s status code and message.", "response": "def _process_response(response):\n        \"\"\"\n        Decodes the JSON response, returning a dict.\n        Raises an exception if an invalid response code is received.\n        \"\"\"\n        if response.status_code == 404:\n            raise Trovebox404Error(\"HTTP Error %d: %s\" %\n                                   (response.status_code, response.reason))\n        try:\n            json_response = response.json()\n            code = json_response[\"code\"]\n            message = json_response[\"message\"]\n        except (ValueError, KeyError):\n            # Response wasn't Trovebox JSON - check the HTTP status code\n            if 200 <= response.status_code < 300:\n                # Status code was valid, so just reraise the exception\n                raise\n            else:\n                raise TroveboxError(\"HTTP Error %d: %s\" %\n                                    (response.status_code, response.reason))\n\n        if 200 <= code < 300:\n            return json_response\n        elif (code == DUPLICATE_RESPONSE[\"code\"] and\n               DUPLICATE_RESPONSE[\"message\"] in message):\n            raise TroveboxDuplicateError(\"Code %d: %s\" % (code, message))\n        else:\n            raise TroveboxError(\"Code %d: %s\" % (code, message))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_fields_with_objects(self):\n        # Update the data with photo objects\n        if self.type is not None:\n            if self.type.startswith(\"photo\"):\n                self.data = Photo(self._client, self.data)\n            else:\n                raise NotImplementedError(\"Unrecognised activity type: %s\"\n                                          % self.type)", "response": "Convert dict fields into objects where appropriate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_print_list():\n    profiler = start_profile()\n    meth1()\n    meth2()\n    meth3()\n    meth4()\n    return end_profile(profiler, returnvalue=True)", "response": "get_print_list returns a list of all the print items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n    profiler = start_profile()\n    meth1()\n    meth2()\n    meth3()\n    meth4()\n    aggregate()\n    end_profile(profiler)\n    runsnake_profile_method(\"aggregate\", globals(), locals())", "response": "Main function for the\n    class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncrawl function to return list of crawled urls.", "response": "def crawl(self):\n        \"\"\"crawl function to return list of crawled urls.\"\"\"\n        page = Linkfetcher(self.root)\n        page.linkfetch()\n        queue = Queue()\n        for url in page.urls:\n            queue.put(url)\n        followed = [self.root]\n\n        n = 0\n\n        while True:\n            try:\n                url = queue.get()\n            except QueueEmpty:\n                break\n\n            n += 1\n\n            if url not in followed:\n                try:\n\n                    host = urllib.parse.urlparse(url)[1]\n\n                    if self.locked and re.match(\".*%s\" % self.host, host):\n                        followed.append(url)\n                        self.followed += 1\n                        page = Linkfetcher(url)\n                        page.linkfetch()\n                        for i, url in enumerate(page):\n                            if url not in self.urls:\n                                self.links += 1\n                                queue.put(url)\n                                self.urls.append(url)\n\n                        if n > self.depth and self.depth > 0:\n                            break\n                except Exception as e:\n                    print(\"ERROR: The URL '%s' can't be crawled (%s)\" % (url, e))\n                    print(format_exc())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, name, value, attrs=None):\n        value = self._values\n        return super().render(name, value, attrs)", "response": "Override the render method to replace value with our current values\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a fresh captcha and store it in the self. _question and self. _values.", "response": "def generate_captcha(self):\n        \"\"\"Generated a fresh captcha\n\n        This method randomly generates a simple captcha question. It then\n        generates a timestamp for the current time, and signs the answer\n        cryptographically to protect against tampering and replay attacks.\n        \"\"\"\n        # Generate a fresh question\n        self._question, answer = self._generate_question()\n\n        # Get the current time, then sign the answer cryptographically\n        timestamp = time.time()\n        hashed = self.hash_answer(answer, timestamp)\n\n        # Now stash all our values\n        self._values = ['', timestamp, hashed]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random arithmetic question with two integers between 1 and 10 and then returns both the question and answer.", "response": "def _generate_question(self):\n        \"\"\"Generate a random arithmetic question\n\n        This method randomly generates a simple addition, subtraction, or\n        multiplication question with two integers between 1 and 10, and then\n        returns both question (formatted as a string) and answer.\n        \"\"\"\n        x = random.randint(1, 10)\n        y = random.randint(1, 10)\n\n        operator = random.choice(('+', '-', '*',))\n        if operator == '+':\n            answer = x + y\n        elif operator == '-':\n            # Ensure we'll get a non-negative answer\n            if x < y:\n                x, y = y, x\n            answer = x - y\n        else:\n            # Multiplication is hard, make it easier\n            x = math.ceil(x/2)\n            y = math.ceil(y/2)\n\n            answer = x * y\n            # Use a prettied-up HTML multiplication character\n            operator = '&times;'\n\n        # Format the answer nicely, then mark it as safe so Django won't escape it\n        question = '{} {} {}'.format(x, operator, y)\n        return mark_safe(question), answer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hash_answer(self, answer, timestamp):\n        # Ensure our values are string before we start hashing\n        timestamp = str(timestamp)\n        answer = str(answer)\n        hashed = ''\n\n        # Hashing multiple times increases the security of the signature\n        for _ in range(ITERATIONS):\n            # We use Django's own \"salted HMAC\" for cryptographic signatures\n            hashed = salted_hmac(timestamp, answer).hexdigest()\n\n        return hashed", "response": "Cryptographically hash the answer with the provided timestamp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_file_names(samples, raw_dir, options):\n    file_names = {}\n    for sample in samples:\n        the_sample = None\n        try:\n            the_sample = sample[1]\n        except IndexError:\n            msg = (\"problematic samples file should include both family and \"\n                   \"individual IDs\")\n            raise ProgramError(msg)\n        if options.use_full_ids:\n            the_sample = options.full_ids_delimiter.join(sample)\n\n        file_name = os.path.join(raw_dir, \"{}.txt\".format(the_sample))\n        if not os.path.isfile(file_name):\n            file_name += \".gz\"\n            if not os.path.isfile(file_name):\n                msg = \"can't find file for sample {}\".format(the_sample)\n                raise ProgramError(msg)\n        file_names[the_sample] = file_name\n\n    return file_names", "response": "Check if all files are present in the raw file system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a file containing problematic samples after a sex check.", "response": "def read_problematic_samples(file_name):\n    \"\"\"Reads a file with sample IDs.\n\n    :param file_name: the name of the file containing problematic samples after\n                      sex check.\n\n    :type file_name: str\n\n    :returns: a set of problematic samples (tuple containing the family ID as\n              first element and the sample ID as last element).\n\n    Reads a file containing problematic samples after sex check. The file is\n    provided by the module :py:mod:`pyGenClean.SexCheck.sex_check`. This file\n    contains two columns, the first one being the family ID and the second one,\n    the sample ID.\n\n    \"\"\"\n    problematic_samples = set()\n    open_func = open\n    if file_name.endswith(\".gz\"):\n        open_func = gzip.open\n    with open_func(file_name, 'rb') as input_file:\n        problematic_samples = set([\n            tuple(i.rstrip(\"\\r\\n\").split(\"\\t\")) for i in input_file.readlines()\n        ])\n\n    return problematic_samples"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_baf_lrr(file_names, options):\n    # importing important stuff\n    import matplotlib as mpl\n    if options.format != \"X11\" and mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    if options.format != \"X11\":\n        plt.ioff()\n\n    # For each of the sample/files\n    for sample, file_name in file_names.iteritems():\n        data = []\n\n        # Reading the file\n        open_func = open\n        if file_name.endswith(\".gz\"):\n            open_func = gzip.open\n        with open_func(file_name, 'rb') as input_file:\n            header_index = dict([\n                (col_name, i)\n                for i, col_name in\n                enumerate(input_file.readline().rstrip(\"\\r\\n\").split(\"\\t\"))\n            ])\n            for col_name in {\"Chr\", \"Position\", \"B Allele Freq\",\n                             \"Log R Ratio\"}:\n                if col_name not in header_index:\n                    msg = \"{}: no column named {}\".format(file_name, col_name)\n                    raise ProgramError(msg)\n\n            # Reading the dat\n            for line in input_file:\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n                # We only need X and Y chromosomes\n                chromosome = encode_chromosome(row[header_index[\"Chr\"]])\n                if chromosome not in {\"X\", \"Y\"}:\n                    continue\n\n                # The position\n                position = row[header_index[\"Position\"]]\n                try:\n                    position = int(position)\n                except ValueError:\n                    msg = \"{}: impossible position {}\".format(file_name,\n                                                              position)\n                    raise ProgramError(msg)\n\n                # The BAF\n                baf = row[header_index[\"B Allele Freq\"]]\n                try:\n                    baf = float(baf)\n                except ValueError:\n                    msg = \"{}: impossible baf {}\".format(file_name, baf)\n                    raise ProgramError(msg)\n\n                # The LRR\n                lrr = row[header_index[\"Log R Ratio\"]]\n                try:\n                    lrr = float(lrr)\n                except ValueError:\n                    msg = \"{}: impossible lrr {}\".format(file_name, lrr)\n                    raise ProgramError(msg)\n\n                # Saving the data\n                data.append((chromosome, position, lrr, baf))\n\n        # Creating the numpy array\n        data = np.array(data, dtype=[(\"chr\", \"a1\"), (\"pos\", int),\n                                     (\"lrr\", float), (\"baf\", float)])\n\n        # Creating the figure and axes\n        fig, axes = plt.subplots(2, 2, figsize=(20, 8))\n        plt.subplots_adjust(left=0.05, right=0.97, wspace=0.15, hspace=0.3)\n        fig.suptitle(sample, fontsize=16, weight=\"bold\")\n\n        # Setting subplot properties\n        for ax in axes.flatten():\n            ax.xaxis.set_ticks_position(\"bottom\")\n            ax.yaxis.set_ticks_position(\"left\")\n            ax.spines[\"top\"].set_visible(False)\n            ax.spines[\"right\"].set_visible(False)\n            ax.spines[\"bottom\"].set_position((\"outward\", 9))\n            ax.spines[\"left\"].set_position((\"outward\", 9))\n\n        # Separating the axes\n        x_lrr_ax, x_baf_ax, y_lrr_ax, y_baf_ax = axes.flatten(order='F')\n\n        # Printing the X chromosome\n        curr_chr = data[\"chr\"] == \"X\"\n        x_lrr_ax.plot(data[\"pos\"][curr_chr]/1000000.0, data[\"lrr\"][curr_chr],\n                      \"o\", ms=1, mec=\"#0099CC\",\n                      mfc=\"#0099CC\")[0].set_clip_on(False)\n        x_baf_ax.plot(data[\"pos\"][curr_chr]/1000000.0, data[\"baf\"][curr_chr],\n                      \"o\", ms=1, mec=\"#669900\",\n                      mfc=\"#669900\")[0].set_clip_on(False)\n        x_lrr_ax.axhline(y=0, color=\"#000000\", ls=\"--\", lw=1.2)\n        x_baf_ax.axhline(y=0.5, color=\"#000000\", ls=\"--\", lw=1.2)\n        x_lrr_ax.set_ylabel(\"LRR\", weight=\"bold\")\n        x_baf_ax.set_ylabel(\"BAF\", weight=\"bold\")\n        x_baf_ax.set_xlabel(\"Position (Mb)\", weight=\"bold\")\n        x_lrr_ax.set_title(\"Chromosome X\", weight=\"bold\")\n\n        # Printing the X chromosome\n        curr_chr = data[\"chr\"] == \"Y\"\n        y_lrr_ax.plot(data[\"pos\"][curr_chr]/1000000.0, data[\"lrr\"][curr_chr],\n                      \"o\", ms=1, mec=\"#0099CC\",\n                      mfc=\"#0099CC\")[0].set_clip_on(False)\n        y_baf_ax.plot(data[\"pos\"][curr_chr]/1000000.0, data[\"baf\"][curr_chr],\n                      \"o\", ms=1, mec=\"#669900\",\n                      mfc=\"#669900\")[0].set_clip_on(False)\n        y_lrr_ax.axhline(y=0, color=\"#000000\", ls=\"--\", lw=1.2)\n        y_baf_ax.axhline(y=0.5, color=\"#000000\", ls=\"--\", lw=1.2)\n        y_lrr_ax.set_ylabel(\"LRR\", weight=\"bold\")\n        y_baf_ax.set_ylabel(\"BAF\", weight=\"bold\")\n        y_baf_ax.set_xlabel(\"Position (Mb)\", weight=\"bold\")\n        y_lrr_ax.set_title(\"Chromosome Y\", weight=\"bold\")\n\n        # Saving the figure\n        if options.format == \"X11\":\n            plt.show()\n        else:\n            plt.savefig(\n                \"{}_{}_lrr_baf.{}\".format(options.out, sample, options.format),\n                dpi=options.dpi,\n            )\n\n        # Closing the figure\n        plt.close(fig)", "response": "Plot the BAF and LRR of a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef checkArgs(args):\n    # Checking the input file\n    if not os.path.isfile(args.problematic_samples):\n        msg = \"{}: no such file\".format(args.problematic_samples)\n        raise ProgramError(msg)\n\n    # Checking the raw directory\n    if not os.path.isdir(args.raw_dir):\n        msg = \"{}: no such directory\".format(args.raw_dir)\n        raise ProgramError(msg)\n\n    # Checking the DPI value\n    if args.dpi < 10:\n        msg = \"{}: DPI too low\".format(args.dpi)\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options for validity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(self, c):\n        phase = Sfix(0.0, 0, -17)\n\n        abs, _, angle = self.core.main(c.real, c.imag, phase)\n\n        # get rid of CORDIC gain and extra bits\n        self.y_abs = abs * (1.0 / 1.646760)\n        self.y_angle = angle\n        return self.y_abs, self.y_angle", "response": "main method for the base class"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate(self, username=\"\", password=\"\", **kwargs):\n        try:\n            user = get_user_model().objects.filter(email__iexact=username)[0]\n            if check_password(password, user.password):\n                return user\n            else:\n                return None\n        except IndexError:\n            # No user was found, return None - triggers default login failed\n            return None", "response": "Allow users to log in with their email address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate(self, username=None, password=None, **kwargs):\n        try:\n           # Try to fetch the user by searching the username or email field\n            user = get_user_model().objects.filter(Q(username=username)|Q(email=username))[0]\n            if check_password(password, user.password):\n                return user\n            else:\n                return None\n        except Exception as e:\n            # No user was found, return None - triggers default login failed\n            return None", "response": "Allow users to log in with their email address or username."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the local action precondition expressions.", "response": "def _build_preconditions_table(self):\n        '''Builds the local action precondition expressions.'''\n        self.local_action_preconditions = dict()\n        self.global_action_preconditions = []\n        action_fluents = self.action_fluents\n        for precond in self.preconds:\n            scope = precond.scope\n            action_scope = [action for action in scope if action in action_fluents]\n            if len(action_scope) == 1:\n                name = action_scope[0]\n                self.local_action_preconditions[name] = self.local_action_preconditions.get(name, [])\n                self.local_action_preconditions[name].append(precond)\n            else:\n                self.global_action_preconditions.append(precond)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the lower and upper action bound constraint expressions.", "response": "def _build_action_bound_constraints_table(self):\n        '''Builds the lower and upper action bound constraint expressions.'''\n        self.action_lower_bound_constraints = {}\n        self.action_upper_bound_constraints = {}\n\n        for name, preconds in self.local_action_preconditions.items():\n\n            for precond in preconds:\n                expr_type = precond.etype\n                expr_args = precond.args\n\n                bounds_expr = None\n\n                if expr_type == ('aggregation', 'forall'):\n                    inner_expr = expr_args[1]\n                    if inner_expr.etype[0] == 'relational':\n                        bounds_expr = inner_expr\n                elif expr_type[0] == 'relational':\n                    bounds_expr = precond\n\n                if bounds_expr:\n                    # lower bound\n                    bound = self._extract_lower_bound(name, bounds_expr)\n                    if bound is not None:\n                        self.action_lower_bound_constraints[name] = bound\n                    else: # upper bound\n                        bound = self._extract_upper_bound(name, bounds_expr)\n                        if bound is not None:\n                            self.action_upper_bound_constraints[name] = bound"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_lower_bound(self, name: str, expr: Expression) -> Optional[Expression]:\n        '''Returns the lower bound expression of the action with given `name`.'''\n        etype = expr.etype\n        args = expr.args\n        if etype[1] in ['<=', '<']:\n            if args[1].is_pvariable_expression() and args[1].name == name:\n                return args[0]\n        elif etype[1] in ['>=', '>']:\n            if args[0].is_pvariable_expression() and args[0].name == name:\n                return args[1]\n        return None", "response": "Returns the lower bound expression of the action with given name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef non_fluents(self) -> Dict[str, PVariable]:\n        '''Returns non-fluent pvariables.'''\n        return { str(pvar): pvar for pvar in self.pvariables if pvar.is_non_fluent() }", "response": "Returns non - fluent pvariables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn state - fluent pvariables.", "response": "def state_fluents(self) -> Dict[str, PVariable]:\n        '''Returns state-fluent pvariables.'''\n        return { str(pvar): pvar for pvar in self.pvariables if pvar.is_state_fluent() }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn action - fluent pvariables.", "response": "def action_fluents(self) -> Dict[str, PVariable]:\n        '''Returns action-fluent pvariables.'''\n        return { str(pvar): pvar for pvar in self.pvariables if pvar.is_action_fluent() }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef intermediate_fluents(self) -> Dict[str, PVariable]:\n        '''Returns interm-fluent pvariables.'''\n        return { str(pvar): pvar for pvar in self.pvariables if pvar.is_intermediate_fluent() }", "response": "Returns interm - fluent pvariables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef intermediate_cpfs(self) -> List[CPF]:\n        '''Returns list of intermediate-fluent CPFs in level order.'''\n        _, cpfs = self.cpfs\n        interm_cpfs = [cpf for cpf in cpfs if cpf.name in self.intermediate_fluents]\n        interm_cpfs = sorted(interm_cpfs, key=lambda cpf: (self.intermediate_fluents[cpf.name].level, cpf.name))\n        return interm_cpfs", "response": "Returns list of intermediate - fluent CPFs in level order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn list of state - fluent CPFs.", "response": "def state_cpfs(self) -> List[CPF]:\n        '''Returns list of state-fluent CPFs.'''\n        _, cpfs = self.cpfs\n        state_cpfs = []\n        for cpf in cpfs:\n            name = utils.rename_next_state_fluent(cpf.name)\n            if name in self.state_fluents:\n                state_cpfs.append(cpf)\n        state_cpfs = sorted(state_cpfs, key=lambda cpf: cpf.name)\n        return state_cpfs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interm_fluent_ordering(self) -> List[str]:\n        '''The list of intermediate-fluent names in canonical order.\n\n        Returns:\n            List[str]: A list of fluent names.\n        '''\n        interm_fluents = self.intermediate_fluents.values()\n        key = lambda pvar: (pvar.level, pvar.name)\n        return [str(pvar) for pvar in sorted(interm_fluents, key=key)]", "response": "The list of intermediate - fluent names in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_state_fluent_ordering(self) -> List[str]:\n        '''The list of next state-fluent names in canonical order.\n\n        Returns:\n            List[str]: A list of fluent names.\n        '''\n        key = lambda x: x.name\n        return [cpf.name for cpf in sorted(self.state_cpfs, key=key)]", "response": "The list of next state - fluent names in canonical order."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the data to the carbon server.", "response": "def send(self):\n        \"\"\" self.data format: {metric_name: [(t1, val1), (t2, val2)]} \"\"\"\n        buf_sz = 500\n        to_send = {}\n\n        for mn in self.data.iterkeys():\n            while len(self.data[mn]) > 0:\n                l = len(to_send)\n                if l < buf_sz:\n                    to_send.setdefault(mn, [])\n                    to_send[mn].append(self.data[mn].pop())\n                else:\n                    try:\n                        self._send(to_send)\n                        to_send = {}\n                        to_send.setdefault(mn, [])\n                        to_send[mn].append(self.data[mn].pop())\n                    except socket.error:\n                        self.logger.error('Error sending to carbon, trying to reconnect.')\n                        self.sock = self._connect()\n\n                        # we failed to send, so put it back in the stack and try later\n                        for ent in to_send:\n                            self.data[ent[0]].append(ent[1])\n\n        try:\n            self._send(to_send)\n        except socket.error:\n            self.logger.error('Error sending to carbon, trying to reconnect.')\n            self.sock = self._connect()\n\n        # we failed to send, so put it back in the stack and try later\n        for ent in to_send:\n            self.data[ent[0]].append(ent[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the Kullback - Leibler divergence from one distribution Q to another distribution P and P are represented by a set of samples.", "response": "def DKL(arrays):\n    \"\"\"\n    Compute the Kullback-Leibler divergence from one distribution Q to another\n    P, where Q and P are represented by a set of samples.\n\n    Parameters\n    ----------\n    arrays: tuple(1D numpy.array,1D numpy.array)\n        samples defining distributions P & Q respectively\n\n    Returns\n    -------\n    float:\n        Kullback Leibler divergence.\n    \"\"\"\n    samples, prior_samples = arrays\n    samples = samples[~numpy.isnan(samples)]\n    prior_samples = prior_samples[~numpy.isnan(prior_samples)]\n    return (\n            gaussian_kde(samples).logpdf(samples)\n            - gaussian_kde(prior_samples).logpdf(samples)\n            ).mean()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_dkl(fsamps, prior_fsamps, **kwargs):\n\n    parallel = kwargs.pop('parallel', False)\n    cache = kwargs.pop('cache', '')\n    tqdm_kwargs = kwargs.pop('tqdm_kwargs', {})\n    if kwargs:\n        raise TypeError('Unexpected **kwargs: %r' % kwargs)\n\n    if cache:\n        cache = Cache(cache + '_dkl')\n        try:\n            return cache.check(fsamps, prior_fsamps)\n        except CacheException as e:\n            print(e)\n\n    zip_fsamps = list(zip(fsamps, prior_fsamps))\n    dkls = parallel_apply(DKL, zip_fsamps, parallel=parallel,\n                          tqdm_kwargs=tqdm_kwargs)\n    dkls = numpy.array(dkls)\n\n    if cache:\n        cache.save(fsamps, prior_fsamps, dkls)\n\n    return dkls", "response": "Compute the Kullback Leibler divergence for posterior and prior functions at a specific time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning fully qualified URL for the current site.", "response": "def current_site_url():\n    \"\"\"Returns fully qualified URL (no trailing slash) for the current site.\"\"\"\n    protocol = getattr(settings, 'MY_SITE_PROTOCOL', 'https')\n    port     = getattr(settings, 'MY_SITE_PORT', '')\n    url = '%s://%s' % (protocol, settings.SITE_DOMAIN)\n    if port:\n        url += ':%s' % port\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef record(self, person, event, properties=None, timestamp=None,\n               path=KISSmetrics.RECORD_PATH):\n        \"\"\"Record `event` for `person` with any `properties`.\n\n        :param person: the individual performing the `event`\n        :param event: the `event` name that was performed\n        :param properties: any additional data to include\n        :type properties: dict\n        :param timestamp: when the `event` was performed; optional for\n                          back-dating\n        :param path: HTTP endpoint to use; defaults to\n                    ``KISSmetrics.RECORD_PATH``\n\n        :returns: an HTTP response for the request\n        :rtype: `urllib3.response.HTTPResponse`\n\n        \"\"\"\n        this_request = request.record(self.key, person, event,\n                                      timestamp=timestamp,\n                                      properties=properties,\n                                      scheme=self.trk_scheme,\n                                      host=self.trk_host, path=path)\n        return self._request(this_request)", "response": "Record an event for a person with any properties."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set(self, person, properties=None, timestamp=None,\n            path=KISSmetrics.SET_PATH):\n        \"\"\"Set a property (or properties) for a `person`.\n\n        :param person: individual to associate properties with\n        :param properties: key-value pairs to associate with `person`\n        :type properties: dict\n        :param timestamp: when the `event` was performed; optional for\n                          back-dating\n        :param path: HTTP endpoint to use; defaults to\n                    ``KISSmetrics.SET_PATH``\n\n        :returns: an HTTP response for the request\n        :rtype: `urllib3.response.HTTPResponse`\n\n        \"\"\"\n        this_request = request.set(self.key, person, timestamp=timestamp,\n                                   properties=properties,\n                                   scheme=self.trk_scheme, host=self.trk_host,\n                                   path=path)\n        return self._request(this_request)", "response": "Set a property or properties for a person."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps person to identity ; actions done by one resolve to other.", "response": "def alias(self, person, identity, path=KISSmetrics.ALIAS_PATH):\n        \"\"\"Map `person` to `identity`; actions done by one resolve to other.\n\n        :param person: consider as same individual ``identity``; the\n                       source of the alias operation\n        :type person: str or unicode\n        :param identity: consider as an alias of ``person``; the target\n                         of the alias operation\n        :type identity: str or unicode\n        :param path: HTTP endpoint to use; defaults to\n                    ``KISSmetrics.ALIAS_PATH``\n\n        :returns: an HTTP response for the request\n        :rtype: `urllib3.response.HTTPResponse`\n\n        Note the direction of the mapping is ``person`` to ``identity``\n        (so \"``person`` is also known as ``identity``\" or \"``person`` =>\n        ``identity``\" when looking at it as \"``<source>`` => ``<target>``\")\n\n        When consulting the Aliasing documentation, `person` corresponds\n        to ``query_string.PERSON_PARAM`` and `identity` corresponds to\n        ``query_string.ALIAS_PARAM``.\n\n        Aliasing is not a reversible operation.  When aliasing to an\n        identity, take care not to use a session identifier or any other\n        value that is not relatively stable (a value that will not\n        change per request or per session).\n\n        For more information see the API Specifications on `Aliasing\n        <http://support.kissmetrics.com/apis/specifications.html#aliasing-users>`_.\n\n        \"\"\"\n        this_request = request.alias(self.key, person, identity,\n                                     scheme=self.trk_scheme,\n                                     host=self.trk_host, path=path)\n        return self._request(this_request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CopyRecord(record, **field_overrides):\n\n    fields = field_overrides\n    for field in record.__slots__:\n        if field in field_overrides:\n            continue\n        value = getattr(record, field)\n        if isinstance(value, RecordClass):\n            # Recurse for records.\n            new_value = CopyRecord(value)\n        else:\n            new_value = copy.copy(value)\n        fields[field] = new_value\n\n    return type(record)(**fields)", "response": "Copies a record and its fields recursively for any field that is a Record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef saveAs(self, path):\n        if not path:\n            path = self._dialogs.getSaveFileName(filter='*.csv')\n        if path:\n            self._setPath(path)\n            with open(str(self._path), 'wb') as stream:\n                writer = csv.writer(stream)\n                table = self.table()\n                for row in table:\n                    writer.writerow(row)", "response": "save to file under given name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a text string to a 2d table", "response": "def _textToTable(self, text, separator='\\t'):\n        \"\"\"\n        format csv, [[...]], ((..)) strings to a 2d table\n        \"\"\"\n        table = None\n        if text.startswith('[[') or text.startswith('(('):\n            try:\n                # maybe it's already formated as a list e.g. \"[['1','2'],[...]]\"\n                # check it:\n                t = eval(text)\n            # has to be a 2d-list:\n                if isinstance(t, list) and isinstance(t[0], list):\n                    table = t\n            except SyntaxError:\n                # not a valid list\n                pass\n        if not table:\n            # create the list from the clipboard-text\n            # therefore the text has to be formated like this:\n                # \"1\\t2\\3\\n4\\t5\\6\\n\"\n            table = text.split('\\n')\n            n = 0\n            while n < len(table):\n                sline = table[n].split(separator)\n                if sline != ['']:\n                    table[n] = sline\n                else:\n                    table.pop(n)\n                    n -= 1\n                n += 1\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readPopulations(inputFileName):\n    populations = {}\n    with open(inputFileName, \"r\") as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n\n            # Getting the informations\n            famID = row[0]\n            indID = row[1]\n            pop = row[2]\n\n            # Check if we already saw this sample\n            if (famID, indID) in populations:\n                if pop != populations[(famID, indID)]:\n                    msg = (\"{} {}: sample has multiple population ({} and \"\n                           \"{})\".format(famID, indID, pop,\n                                        populations[(famID, indID)]))\n                    raise ProgramError(msg)\n\n            # Save the population\n            populations[(famID, indID)] = pop\n\n    return populations", "response": "Reads a population file and returns a dictionary of populations for each of the samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plotMDS(data, theOrders, theLabels, theColors, theSizes, theMarkers,\n            options):\n    \"\"\"Plot the MDS data.\n\n    :param data: the data to plot (MDS values).\n    :param theOrders: the order of the populations to plot.\n    :param theLabels: the names of populations to plot.\n    :param theColors: the colors of the populations to plot.\n    :param theSizes: the sizes of the markers for each population to plot.\n    :param theMarkers: the type of markers for each population to plot.\n    :param options: the options.\n\n    :type data: list of numpy.array\n    :type theOrders: list\n    :type theLabels: list\n    :type theColors: list\n    :type theSizes: list\n    :type theMarkers: list\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # Do the import\n    import matplotlib as mpl\n    if options.format != \"X11\" and mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    if options.format != \"X11\":\n        plt.ioff()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    # The plot\n    plotObject = []\n    labels = []\n    for i, index in enumerate(theOrders):\n        tmp, = ax.plot(data[0][index], data[1][index], theMarkers[i],\n                       color=theColors[i], mec=theColors[i],\n                       markersize=theSizes[i])\n        plotObject.append(tmp)\n        labels.append(theLabels[index])\n\n    # The legend\n    prop = mpl.font_manager.FontProperties(size=10)\n    leg = ax.legend(plotObject, labels, loc=\"upper left\", numpoints=1,\n                    fancybox=True, prop=prop)\n\n    # The title and XY labels\n    ax.set_title(options.title)\n    ax.set_xlabel(options.xlabel)\n    ax.set_ylabel(options.ylabel)\n\n    if options.format == \"X11\":\n        # Show the plot\n        plt.show()\n    else:\n        fileName = options.out + \".\" + options.format\n        try:\n            plt.savefig(fileName)\n        except IOError:\n            msg = \"%(fileName)s: can't write file\" % locals()\n            raise ProgramError(msg)", "response": "Plot the MDS data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extractData(fileName, populations):\n    # The different population labels\n    possibleLabels = list(set(populations.values()))\n    nbPossibleLabels = len(possibleLabels)\n\n    c1 = [[] for i in xrange(nbPossibleLabels)]\n    c2 = [[] for i in xrange(nbPossibleLabels)]\n    with open(fileName, 'r') as inputFile:\n        headerIndex = None\n        for i, line in enumerate(inputFile):\n            row = createRowFromPlinkSpacedOutput(line)\n\n            if i == 0:\n                # This is the header\n                headerIndex = dict([(row[j], j) for j in xrange(len(row))])\n\n                for columnName in [\"FID\", \"IID\", \"C1\", \"C2\"]:\n                    if columnName not in headerIndex:\n                        msg = \"%(fileName)s: no column named \" \\\n                              \"%(columnName)s\" % locals()\n                        raise ProgramError(msg)\n\n            else:\n                # Getting the component 1 and 2\n                currC1 = row[headerIndex[\"C1\"]]\n                currC2 = row[headerIndex[\"C2\"]]\n\n                # Getting the individual informations\n                famID = row[headerIndex[\"FID\"]]\n                indID = row[headerIndex[\"IID\"]]\n\n                curLabel = \"\"\n                if (famID, indID) in populations:\n                    curLabel = populations[(famID, indID)]\n                else:\n                    continue\n\n                c1[possibleLabels.index(curLabel)].append(currC1)\n                c2[possibleLabels.index(curLabel)].append(currC2)\n\n    return (np.array(c1), np.array(c2)), possibleLabels", "response": "Extract the C1 and C2 columns for plotting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the arguments and options.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Check in input file\n    if not os.path.isfile(args.file):\n        msg = \"%s: no such file\" % args.file\n        raise ProgramError(msg)\n\n    # Check the population file\n    if args.population_file is None:\n        msg = \"population-file: no population file\"\n        raise ProgramError(msg)\n    elif not os.path.isfile(args.population_file):\n        msg = \"%s: no such file\" % args.population_file\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseArgs():  # pragma: no cover\n    # The INPUT files\n    group = parser.add_argument_group(\"Input File\")\n    group.add_argument(\"--file\", type=str, metavar=\"FILE\", required=True,\n                       help=\"The MBS file.\")\n    parser.add_argument(\"--population-file\", type=str, metavar=\"FORMAT\",\n                        required=True,\n                        help=\"A file containing population information. \"\n                             \"There must be three columns: famID, indID \"\n                             \"and population information.\")\n\n    # The graphical options\n    group = parser.add_argument_group(\"Graphical Options\")\n    addCustomOptions(group)\n\n    # The OUTPUT files\n    group = parser.add_argument_group(\"Output File\")\n    group.add_argument(\"--out\", type=str, metavar=\"FILE\",\n                       default=\"mds\",\n                       help=\"The prefix of the output files. [default: \"\n                            \"%(default)s]\")\n\n    args = parser.parse_args()\n\n    return args", "response": "Parses the command line options and arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd custom options to a parser.", "response": "def addCustomOptions(parser):\n    \"\"\"Adds custom options to a parser.\n\n    :param parser: the parser.\n\n    :type parser: argparse.parser\n\n    \"\"\"\n    parser.add_argument(\"--format\", type=str, metavar=\"FORMAT\", default=\"png\",\n                        choices=[\"png\", \"ps\", \"pdf\", \"X11\"],\n                        help=\"The output file format (png, ps, pdf, or X11 \"\n                             \"formats are available). [default: %(default)s]\")\n    parser.add_argument(\"--title\", type=str, metavar=\"STRING\",\n                        default=\"C2 in function of C1 - MDS\",\n                        help=\"The title of the MDS plot. [default: \"\n                             \"%(default)s]\")\n    parser.add_argument(\"--xlabel\", type=str, metavar=\"STRING\", default=\"C1\",\n                        help=\"The label of the X axis. [default: %(default)s]\")\n    parser.add_argument(\"--ylabel\", type=str, metavar=\"STRING\", default=\"C2\",\n                        help=\"The label of the Y axis. [default: %(default)s]\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self, options=None, **kwds):\n        option_string = self._build_option_string(options)\n        activities = self._client.get(\"/activities%s/list.json\" % option_string,\n                                      **kwds)[\"result\"]\n        activities = self._result_to_list(activities)\n        return [Activity(self._client, activity) for activity in activities]", "response": "This endpoint returns a list of activities."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef view(self, activity, **kwds):\n        result = self._client.get(\"/activity/%s/view.json\" %\n                                  self._extract_id(activity),\n                                  **kwds)[\"result\"]\n\n        # TBD: Why is the result enclosed/encoded like this?\n        result = result[\"0\"]\n        result[\"data\"] = json.loads(result[\"data\"])\n        return Activity(self._client, result)", "response": "This endpoint returns the requested activity object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_placeholder(readable_text=None):\n        name = '_interm_' + str(Cache._counter)\n        Cache._counter += 1\n\n        if readable_text is not None:\n            assert isinstance(readable_text, str)\n            name += '_' + readable_text\n\n        return name", "response": "Generate a placeholder name to use while updating WeldObject."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cache_intermediate_result(cls, result, readable_name=None):\n        from .lazy_result import LazyResult\n        assert isinstance(result, LazyResult)\n\n        dependency_name = Cache._generate_placeholder(readable_name)\n        Cache._intermediate_results[dependency_name] = result\n\n        return dependency_name", "response": "Add result to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_fake_array_input(cls, dependency, readable_name, index=None):\n        assert dependency in Cache._intermediate_results\n        assert isinstance(readable_name, str)\n\n        name = Cache._generate_placeholder(readable_name)\n\n        if index is None:\n            fake_weld_input = _FakeArray(dependency, name)\n        else:\n            assert isinstance(index, tuple)\n            fake_weld_input = _FakeStructMember(dependency, index, name)\n\n        return fake_weld_input", "response": "Create fake Weld input for the given dependency."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncaches the fake Weld input to be seen by LazyResult. evaluate_weld_input.", "response": "def cache_fake_input(cls, weld_input_id, fake_weld_input):\n        \"\"\"Cache the fake Weld input to be seen by LazyResult.evaluate\n\n        Parameters\n        ----------\n        weld_input_id : str\n            Generated when registering the fake_weld_input in WeldObject.update.\n        fake_weld_input : _FakeWeldInput\n            The fake Weld input previously generated by create_fake_array_input.\n\n        \"\"\"\n        assert isinstance(weld_input_id, str)\n        assert isinstance(fake_weld_input, _FakeWeldInput)\n\n        Cache._cache[weld_input_id] = fake_weld_input"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a fake Weld input. Evaluate its intermediate result dependency if not yet done.", "response": "def get(cls, key):\n        \"\"\"Retrieve a fake Weld input. Evaluate its intermediate result dependency if not yet done.\n\n        Parameters\n        ----------\n        key : str\n            Weld input name previously obtained through create_fake_array_input.\n\n        Returns\n        -------\n        numpy.ndarray or tuple\n            The corresponding data.\n\n        \"\"\"\n        assert isinstance(key, str)\n\n        data = cls._cache[key]\n        if isinstance(data, _FakeWeldInput):\n            data = data.retrieve()\n\n        cls._cache[key] = data\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_advices(target, advices):\n\n    interception_fn = _get_function(target)\n\n    target_advices = getattr(interception_fn, _ADVICES, [])\n    target_advices += advices\n\n    setattr(interception_fn, _ADVICES, target_advices)", "response": "Add advices to target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _remove_advices(target, advices, ctx):\n    # if ctx is not None\n    if ctx is not None:  # check if intercepted ctx is ctx\n        _, intercepted_ctx = get_intercepted(target)\n        if intercepted_ctx is None or intercepted_ctx is not ctx:\n            return\n\n    interception_fn = _get_function(target)\n\n    target_advices = getattr(interception_fn, _ADVICES, None)\n\n    if target_advices is not None:\n\n        if advices is None:\n            target_advices = []\n        else:\n            target_advices = [\n                advice for advice in target_advices if advice not in advices\n            ]\n\n        if target_advices:  # update target advices\n            setattr(interception_fn, _ADVICES, target_advices)\n\n        else:  # free target advices if necessary\n            delattr(interception_fn, _ADVICES)\n            _unapply_interception(target, ctx=ctx)", "response": "Remove advices from target."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets advices from target and target context.", "response": "def get_advices(target, ctx=None, local=False):\n    \"\"\"Get element advices.\n\n    :param target: target from where get advices.\n    :param ctx: ctx from where get target.\n    :param bool local: If ctx is not None or target is a method, if True\n        (False by default) get only target advices without resolving super\n        target advices in a super ctx.\n    :return: list of advices.\n    :rtype: list\n    \"\"\"\n\n    result = []\n    if is_intercepted(target):\n        # find ctx if not given\n        if ctx is None:\n            ctx = find_ctx(target)\n        # find advices among super ctx if same intercepted/interception\n        if ctx is not None:\n            # get target name\n            target_name = target.__name__\n            # resolve target and _target_ctx\n            _target_ctx = ctx\n            _target = getattr(_target_ctx, target_name, None)\n            # check if _target is intercepted\n            if is_intercepted(_target):\n                # get intercepted_target in order to compare with super targets\n                intercepted_target, intercepted_ctx = get_intercepted(_target)\n                # if ctx is not a class\n                if not isclass(_target_ctx):\n                    if intercepted_ctx is _target_ctx:\n                        interception_fn = _get_function(_target)\n                        advices = getattr(interception_fn, _ADVICES, [])\n                        result += advices\n                        _target_ctx = _target_ctx.__class__\n                        _target = getattr(_target_ctx, target_name, None)\n                # climb back class hierarchy tree through all super targets\n                while _target is not None and _target_ctx is not None:\n                    # check if _target is intercepted\n                    if is_intercepted(_target):\n                        # get intercepted ctx\n                        intercepted_fn, intercepted_ctx = get_intercepted(\n                            _target\n                        )\n                        # if intercepted ctx is ctx\n                        if intercepted_ctx is _target_ctx:\n                            # get advices from _target interception\n                            interception_fn = _get_function(_target)\n                            advices = getattr(interception_fn, _ADVICES, [])\n                            result += advices\n                            # update _target\n                            _target, _target_ctx = super_method(\n                                name=target_name, ctx=_target_ctx\n                            )\n                        else:  # else _target_ctx is intercepted_ctx\n                            _target_ctx = intercepted_ctx\n                            # and update _target\n                            _target = getattr(_target_ctx, target_name, None)\n                    else:  # else, intercepted_fn is _target function\n                        intercepted_fn = _get_function(_target)\n                        _target, _target_ctx = super_method(\n                            name=target_name, ctx=_target_ctx\n                        )\n                    # if intercepted are different, stop iteration\n                    if intercepted_target is not intercepted_fn:\n                        break\n\n                    if local:  # break if local has been requested\n                        break\n\n        else:\n            # get advices from interception function\n            interception_function = _get_function(target)\n            result = getattr(interception_function, _ADVICES, [])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a function that checks if a target name matches with an input regular expression.", "response": "def _namematcher(regex):\n    \"\"\"Checks if a target name matches with an input regular expression.\"\"\"\n\n    matcher = re_compile(regex)\n\n    def match(target):\n        target_name = getattr(target, '__name__', '')\n        result = matcher.match(target_name)\n        return result\n\n    return match"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weave(\n        target, advices, pointcut=None, ctx=None, depth=1, public=False,\n        pointcut_application=None, ttl=None\n):\n    \"\"\"Weave advices on target with input pointcut.\n\n    :param callable target: target from where checking pointcut and\n        weaving advices.\n    :param advices: advices to weave on target.\n    :param ctx: target ctx (class or instance).\n    :param pointcut: condition for weaving advices on joinpointe.\n        The condition depends on its type.\n    :type pointcut:\n        - NoneType: advices are weaved on target.\n        - str: target name is compared to pointcut regex.\n        - function: called with target in parameter, if True, advices will\n            be weaved on target.\n    :param int depth: class weaving depthing.\n    :param bool public: (default True) weave only on public members.\n    :param routine pointcut_application: routine which applies a pointcut when\n        required. _Joinpoint().apply_pointcut by default. Such routine has\n        to take in parameters a routine called target and its related\n        function called function. Its result is the interception function.\n    :param float ttl: time to leave for weaved advices.\n\n    :return: the intercepted functions created from input target or a tuple\n        with intercepted functions and ttl timer.\n    :rtype: list\n\n    :raises: AdviceError if pointcut is not None, not callable neither a str.\n    \"\"\"\n\n    result = []\n\n    # initialize advices\n    if isroutine(advices):\n        advices = [advices]\n\n    if advices:\n        # initialize pointcut\n        # do nothing if pointcut is None or is callable\n        if pointcut is None or callable(pointcut):\n            pass\n        # in case of str, use a name matcher\n        elif isinstance(pointcut, string_types):\n            pointcut = _namematcher(pointcut)\n        else:\n            error_msg = \"Wrong pointcut to check weaving on {0}.\"\n            error_msg = error_msg.format(target)\n            advice_msg = \"Must be None, or be a str or a function/method.\"\n            right_msg = \"Not {0}\".format(type(pointcut))\n\n            raise AdviceError(\n                \"{0} {1} {2}\".format(error_msg, advice_msg, right_msg)\n            )\n\n        if ctx is None:\n            ctx = find_ctx(elt=target)\n\n        _weave(\n            target=target, advices=advices, pointcut=pointcut, depth=depth,\n            depth_predicate=_publiccallable if public else callable, ctx=ctx,\n            intercepted=result, pointcut_application=pointcut_application\n        )\n\n        if ttl is not None:\n            kwargs = {\n                'target': target,\n                'advices': advices,\n                'pointcut': pointcut,\n                'depth': depth,\n                'public': public,\n                'ctx': ctx\n            }\n            timer = Timer(ttl, unweave, kwargs=kwargs)\n            timer.start()\n\n            result = result, timer\n\n    return result", "response": "Weave advices on target with input pointcut."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _weave(\n        target, advices, pointcut, ctx, depth, depth_predicate, intercepted,\n        pointcut_application\n):\n    \"\"\"Weave deeply advices in target.\n\n    :param callable target: target from where checking pointcut and\n        weaving advices.\n    :param advices: advices to weave on target.\n    :param ctx: target ctx (class or instance).\n    :param pointcut: condition for weaving advices on joinpointe.\n        The condition depends on its type.\n    :type pointcut:\n        - NoneType: advices are weaved on target.\n        - str: target name is compared to pointcut regex.\n        - function: called with target in parameter, if True, advices will\n            be weaved on target.\n    :param int depth: class weaving depthing.\n    :param list intercepted: list of intercepted targets.\n    :param routine pointcut_application: routine which applies a pointcut when\n        required. _Joinpoint().apply_pointcut by default. Such routine has\n        to take in parameters a routine called target and its related\n        function called function. Its result is the interception function.\n    \"\"\"\n\n    # if weaving has to be done\n    if pointcut is None or pointcut(target):\n        # get target interception function\n        interception_fn = _get_function(target)\n        # does not handle not python functions\n        if interception_fn is not None:\n            # flag which specifies if poincut has to by applied\n            # True if target is not intercepted\n            apply_poincut = not is_intercepted(target)\n            # apply poincut if not intercepted\n            if (not apply_poincut) and ctx is not None:\n                # apply poincut if ctx is not intercepted_ctx\n                intercepted_fn, intercepted_ctx = get_intercepted(target)\n                # if previous weave was done directly on the function\n                if intercepted_ctx is None:\n                    # update intercepted_ctx on target\n                    intercepted_ctx = interception_fn._intercepted_ctx = ctx\n                # if old ctx and the new one are same\n                if ctx is not intercepted_ctx:\n                    # apply pointcut\n                    apply_poincut = True\n                    # and update interception_fn\n                    interception_fn = intercepted_fn\n            # if weave has to be done\n            if apply_poincut:\n                # instantiate a new joinpoint if pointcut_application is None\n                if pointcut_application is None:\n                    pointcut_application = _Joinpoint().apply_pointcut\n                interception_fn = pointcut_application(\n                    target=target, function=interception_fn, ctx=ctx\n                )\n            # add advices to the interception function\n            _add_advices(\n                target=interception_fn, advices=advices\n            )\n            # append interception function to the intercepted ones\n            intercepted.append(interception_fn)\n\n    # search inside the target\n    elif depth > 0:  # for an object or a class, weave on methods\n        # get the right ctx\n        if ctx is None:\n            ctx = target\n        for _, member in getmembers(ctx, depth_predicate):\n            _weave(\n                target=member, advices=advices, pointcut=pointcut,\n                depth_predicate=depth_predicate, intercepted=intercepted,\n                pointcut_application=pointcut_application, depth=depth - 1,\n                ctx=ctx\n            )", "response": "Weave deeply advices on target."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weave_on(advices, pointcut=None, ctx=None, depth=1, ttl=None):\n\n    def __weave(target):\n        \"\"\"Internal weave function.\"\"\"\n        weave(\n            target=target, advices=advices, pointcut=pointcut,\n            ctx=ctx, depth=depth, ttl=ttl\n        )\n\n        return target\n\n    return __weave", "response": "Decorator for weaving advices on a target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _compute_path(self, name):\n        path = self._normalize_path(os.path.join(self.base_directory, name))\n        if not path.startswith(self.base_directory):\n            raise FileNotWithinStorageError(name)\n        return path", "response": "Compute the file path in the filesystem from the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naggregating the values of the given arrays by the given operation.", "response": "def weld_groupby_aggregate_dictmerger(arrays, weld_types, by_indices, operation):\n    \"\"\"Groups by the columns in by.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Entire DataFrame data.\n    weld_types : list of WeldType\n        Corresponding to data.\n    by_indices : list of int\n        Indices of which arrays to group by.\n    operation : {'+', '*', 'min', 'max'}\n        Aggregation.\n\n    Returns\n    -------\n    WeldObject\n        Representation of the computation.\n\n    \"\"\"\n    weld_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n\n    obj_id, weld_obj = create_weld_object(weld_struct)\n\n    all_indices = list(range(len(arrays)))\n    column_indices = list(filter(lambda x: x not in by_indices, all_indices))\n    by_weld_types = [weld_types[i] for i in by_indices]\n    column_weld_types = [weld_types[i] for i in column_indices]\n\n    by_types = struct_of('{e}', by_weld_types)\n    column_types = struct_of('{e}', column_weld_types)\n    all_types = struct_of('{e}', weld_types)\n    by_select = struct_of('e.${e}', by_indices)\n    column_select = struct_of('e.${e}', column_indices)\n    res = '{{{}}}'.format(', '.join(['e.$0.${}'.format(i) for i in range(len(by_weld_types))] +\n                                    ['e.$1.${}'.format(i) for i in range(len(column_weld_types))]))\n\n    weld_template = \"\"\"map(\n    tovec(\n        result(\n            for(\n                {arrays},\n                dictmerger[{by_types}, {column_types}, {operation}],\n                |b: dictmerger[{by_types}, {column_types}, {operation}], i: i64, e: {all_types}|\n                    merge(b, {{{by_select}, {column_select}}})\n            )\n        )\n    ),\n    |e: {{{by_types}, {column_types}}}|\n        {res}\n)\"\"\"\n\n    weld_obj.weld_code = weld_template.format(arrays=obj_id,\n                                              by_types=by_types,\n                                              column_types=column_types,\n                                              all_types=all_types,\n                                              by_select=by_select,\n                                              column_select=column_select,\n                                              operation=operation,\n                                              res=res)\n\n    return by_weld_types + column_weld_types, weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weld_groupby_aggregate(grouped_df, weld_types, by_indices, aggregation, result_type=None):\n    obj_id, weld_obj = create_weld_object(grouped_df)\n\n    all_indices = list(range(len(weld_types)))\n    column_indices = list(filter(lambda x: x not in by_indices, all_indices))\n    by_weld_types = [weld_types[i] for i in by_indices]\n    column_weld_types = [weld_types[i] for i in column_indices]\n    new_column_weld_types = column_weld_types if result_type is None else [result_type for _ in column_weld_types]\n\n    by_types = struct_of('{e}', by_weld_types)\n    column_types = struct_of('{e}', column_weld_types)\n    new_column_types = struct_of('{e}', new_column_weld_types)\n    grouped_df_types = '{{{}, {}}}'.format(by_types, column_types)\n    res = '{{{}}}'.format(', '.join(['e.$0.${}'.format(i) for i in range(len(by_weld_types))] +\n                                    ['e.$1.${}'.format(i) for i in range(len(column_weld_types))]))\n\n    weld_template = \"\"\"map(\n    tovec(\n        result(\n            for(\n                {grouped_df},\n                dictmerger[{by_types}, {new_column_types}, +],\n                |b: dictmerger[{by_types}, {new_column_types}, +], i: i64, e: {{{by_types}, vec[{column_types}]}}|\n                    {computation}\n            )\n        )\n    ),\n    |e: {{{by_types}, {new_column_types}}}|\n        {res}\n)\"\"\"\n\n    weld_template = weld_template.replace('{computation}',\n                                          _assemble_computation(aggregation,\n                                                                column_weld_types,\n                                                                new_column_weld_types),\n                                          1)\n\n    weld_obj.weld_code = weld_template.format(grouped_df=obj_id,\n                                              by_types=by_types,\n                                              column_types=column_types,\n                                              new_column_types=new_column_types,\n                                              grouped_df_types=grouped_df_types,\n                                              res=res)\n\n    return by_weld_types + new_column_weld_types, weld_obj", "response": "Perform aggregation on grouped data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    logger.info(\"Options used:\")\n    for key, value in vars(args).iteritems():\n        logger.info(\"  --{} {}\".format(key.replace(\"_\", \"-\"), value))\n\n    # Reading the tfam file\n    logger.info(\"Reading TFAM\")\n    tfam = readTFAM(args.tfile + \".tfam\")\n\n    # Find duplicated samples\n    logger.info(\"Finding duplicated samples\")\n    uniqueSamples, duplicatedSamples = findDuplicates(tfam)\n\n    # Prints the unique tfam\n    logger.info(\"Creating TFAM for unique samples\")\n    printUniqueTFAM(tfam, uniqueSamples, args.out)\n\n    # Process the TPED file\n    logger.info(\"Reading TPED (and creating TPED for unique samples)\")\n    tped, tpedSamples = processTPED(uniqueSamples, duplicatedSamples,\n                                    args.tfile + \".tped\", args.out)\n\n    if len(duplicatedSamples) == 0:\n        logger.info(\"There are no duplicates in {}.tfam\".format(args.tfile))\n        # There are no duplicated samples\n        try:\n            shutil.copy(args.out + \".unique_samples.tfam\",\n                        args.out + \".final.tfam\")\n        except IOError:\n            msg = \"%s.unique_samples.tfam: can't copy to \" \\\n                  \"%s.final.tfam\" % (args.out, args.out)\n            raise ProgramError(msg)\n        try:\n            shutil.copy(args.out + \".unique_samples.tped\",\n                        args.out + \".final.tped\")\n        except IOError:\n            msg = \"%s.unique_samples.tped: can't copy to \" \\\n                  \"%s.final.tped\" % (args.out, args.out)\n            raise ProgramError(msg)\n\n    else:\n        # We continue\n        # Compute statistics\n        logger.info(\"Computing the completion and concordance of duplicated \"\n                    \"samples\")\n        completion, concordance = computeStatistics(tped, tfam, tpedSamples,\n                                                    duplicatedSamples,\n                                                    args.out)\n\n        # Print the statistics\n        logger.info(\"Printing the statistics\")\n        completion_percentage = printStatistics(completion, concordance,\n                                                tpedSamples, duplicatedSamples,\n                                                args.out)\n\n        # Print the concordance file\n        logger.info(\"Printing the concordance file\")\n        concordance_percentage = printConcordance(concordance, args.out)\n\n        # Print the duplicated TFAM and TPED\n        logger.info(\"Creating TPED and TFAM for duplicated samples\")\n        printDuplicatedTPEDandTFAM(tped, tfam, tpedSamples, duplicatedSamples,\n                                   args.out)\n\n        # Choose the best duplicates\n        logger.info(\"Choosing the best duplicates\")\n        chosenSamples, comp, conc = chooseBestDuplicates(\n            tped,\n            tpedSamples,\n            duplicatedSamples,\n            completion_percentage,\n            concordance_percentage,\n            args.out,\n        )\n\n        # Clean the genotype of the chosen samples\n        logger.info(\"Cleaning and creating unique TPED and TFAM from \"\n                    \"duplicated samples\")\n        newTPED, newTFAM = createAndCleanTPED(\n            tped,\n            tfam,\n            tpedSamples,\n            duplicatedSamples,\n            chosenSamples,\n            args.out,\n            comp,\n            args.sample_completion_threshold,\n            conc,\n            args.sample_concordance_threshold,\n        )\n\n        # Add the chosen TPED and TFAM\n        logger.info(\"Creating final TPED and TFAM file\")\n        addToTPEDandTFAM(newTPED, newTFAM, args.out,\n                         args.out + \".unique_samples\")", "response": "This function is the main entry point for the check for duplicated samples in a tfam file. It checks for duplicated samples in a tped file and prints the statistics concordance matrix for each duplicated sample pair and the unique samples in the tped file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addToTPEDandTFAM(tped, tfam, prefix, toAddPrefix):\n    # First, writing the chosen tped\n    tpedFile = None\n    try:\n        tpedFile = open(prefix + \".chosen_samples.tped\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.chosen_samples.tped: can't write file\" % locals()\n        raise ProgramError(msg)\n    for row in tped:\n        print >>tpedFile, \"\\t\".join(row)\n    tpedFile.close()\n\n    # Second, writing the chosen tfam\n    tfamFile = None\n    try:\n        tfamFile = open(prefix + \".chosen_samples.tfam\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.chosen_samples.tfam: can't write file\" % locals()\n        raise ProgramError(msg)\n    for row in tfam:\n        print >>tfamFile, \"\\t\".join(row)\n    tfamFile.close()\n\n    # The final TFAM file (copying and appending)\n    try:\n        shutil.copyfile(toAddPrefix + \".tfam\", prefix + \".final.tfam\")\n    except IOError:\n        msg = \"%(toAddPrefix)s.tfam: can't copy to \" \\\n              \"%(prefix)s.final.tfam\" % locals()\n        raise ProgramError(msg)\n    newTFAM = None\n    try:\n        newTFAM = open(prefix + \".final.tfam\", \"a\")\n    except IOError:\n        msg = \"%(prefix)s.final.tfam: can't append\" % locals()\n        raise ProgramError(msg)\n    for row in tfam:\n        print >>newTFAM, \"\\t\".join(row)\n    newTFAM.close()\n\n    # The final TPED file\n    newTPED = None\n    try:\n        newTPED = open(prefix + \".final.tped\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.final.tped: can't write file\" % locals()\n        raise ProgramError(msg)\n    try:\n        with open(toAddPrefix + \".tped\", \"r\") as inputFile:\n            for i, line in enumerate(inputFile):\n                row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n                originalSNP = row[1]\n                toAdd = tped[i]\n                if originalSNP != toAdd[1]:\n                    msg = \"%(toAddPrefix)s.tped: not good sort\" % locals()\n                    raise ProgramError(msg)\n                row.extend(list(toAdd[4:]))\n                print >>newTPED, \"\\t\".join(row)\n    except IOError:\n        msg = \"%(toAddPrefix)s.tped: no such file\" % locals()\n        raise ProgramError(msg)\n    newTPED.close()", "response": "Append a tfile to another tfile and add the new one."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompletes a TPED for duplicated samples.", "response": "def createAndCleanTPED(tped, tfam, samples, oldSamples, chosenSamples,\n                       prefix, completion, completionT, concordance,\n                       concordanceT):\n    \"\"\"Complete a TPED for duplicate samples.\n\n    :param tped: the ``tped`` containing the duplicated samples.\n    :param tfam: the ``tfam`` containing the duplicated samples.\n    :param samples: the updated position of the samples in the ``tped``\n                    containing only duplicated samples.\n    :param oldSamples: the original duplicated sample positions.\n    :param chosenSamples: the position of the chosen samples.\n    :param prefix: the prefix of all the files.\n    :param completion: the completion of each of the duplicated samples.\n    :param completionT: the completion threshold.\n    :param concordance: the pairwise concordance of each of the duplicated\n                        samples.\n    :param concordanceT: the concordance threshold.\n\n    :type tped: :py:class:`numpy.array`\n    :type tfam: :py:class:`numpy.array`\n    :type samples: dict\n    :type oldSamples: dict\n    :type chosenSamples: dict\n    :type prefix: str\n    :type completion: :py:class:`numpy.array`\n    :type completionT: float\n    :type concordance: dict\n    :type concordanceT: float\n\n    Using a ``tped`` containing duplicated samples, it creates a ``tped``\n    containing unique samples by completing a chosen sample with the other\n    replicates.\n\n    .. note::\n        A chosen sample is not completed using bad replicates (those that\n        don't have a concordance or a completion higher than a certain\n        threshold). The bad replicates are written in the file\n        ``prefix.not_good_enough``.\n\n    \"\"\"\n    zeroedOutFile = None\n    try:\n        zeroedOutFile = open(prefix + \".zeroed_out\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.zeroed_out: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>zeroedOutFile, \"\\t\".join([\"famID\", \"indID\", \"snpID\"])\n\n    notGoodEnoughFile = None\n    try:\n        notGoodEnoughFile = open(prefix + \".not_good_enough\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.not_good_enough: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>notGoodEnoughFile, \"\\t\".join([\"origIndex\", \"dupIndex\", \"famID\",\n                                          \"indID\", \"reason\"])\n    notGoodEnoughSamples = defaultdict(set)\n\n    # Split the tped in 'snpInfo' and 'genotypes'\n    snpInfo = tped[:, :4]\n    genotypes = tped[:, 4:]\n\n    # Getting the completion and concordance indexes\n    completionSampleID = {}\n    concordanceSampleID = {}\n    for sampleID, indexes in samples.iteritems():\n        # Checking the completion\n        completionToKeep = np.where(completion[indexes] >= completionT)[0]\n        completionToRemove = np.where(completion[indexes] < completionT)[0]\n        for k in completionToRemove:\n            notGoodEnoughSamples[(str(oldSamples[sampleID][k]+1),\n                                  str(indexes[k]+1), sampleID[0],\n                                  sampleID[1])].add(\"completion\")\n\n        # Checking the concordance\n        concordanceToKeep = np.where(concordance[sampleID] >= concordanceT)[0]\n        concordanceToRemove = np.where(\n            concordance[sampleID] < concordanceT\n        )[0]\n        for k in concordanceToRemove:\n            notGoodEnoughSamples[(str(oldSamples[sampleID][k]+1),\n                                  str(indexes[k]+1), sampleID[0],\n                                  sampleID[1])].add(\"concordance\")\n\n        completionSampleID[sampleID] = completionToKeep\n        concordanceSampleID[sampleID] = concordanceToKeep\n\n    for i, curSNPgenotypes in enumerate(genotypes):\n        for sampleID, indexes in samples.iteritems():\n            # Getting the concordance and the completion\n            concordanceToKeep = concordanceSampleID[sampleID]\n            completionToKeep = completionSampleID[sampleID]\n\n            # Getting the chosen sample index\n            chosenOne = chosenSamples[sampleID]\n\n            # Getting the duplicates' genotypes\n            curGenotypes = curSNPgenotypes[indexes]\n\n            # Subsetting for the good completion and concordance\n            curGenotypes = curGenotypes[np.intersect1d(concordanceToKeep,\n                                                       completionToKeep)]\n\n            # Removing the no call from the genotypes\n            cleanedCurGenotype = curGenotypes[np.where(curGenotypes != \"0 0\")]\n\n            # Checking the number of unique genotypes\n            uniqueGenotypes = np.unique(cleanedCurGenotype)\n\n            # Checking the number of unique genotypes (except 0 0)\n            if len(uniqueGenotypes) > 1:\n                # There are more than one unique genotypes (except 0 0)\n                # len = 0 means all were 0 0\n                # len = 1 means all the same\n                # len > 1 means more than one unique genotypes\n                possibleAlleles = [\n                    set() for k in xrange(len(uniqueGenotypes))\n                ]\n                for k, geno in enumerate(uniqueGenotypes):\n                    possibleAlleles[k] |= set(geno.split(\" \"))\n                allEqual = True\n                for k in xrange(len(possibleAlleles)):\n                    for l in xrange(k+1, len(possibleAlleles)):\n                        if possibleAlleles[k] != possibleAlleles[l]:\n                            allEqual = False\n                            break\n                    if not allEqual:\n                        break\n                if not allEqual:\n                    # Changing the chosen sample's genotype to no call\n                    tped[i][chosenOne+4] = \"0 0\"\n                    print >>zeroedOutFile, \"\\t\".join([sampleID[0], sampleID[1],\n                                                      snpInfo[i][1]])\n            else:\n                # Do we want to complete the chosen sample's genotype???\n                pass\n\n    # Writing the not good enough file\n    for key, value in notGoodEnoughSamples.iteritems():\n        print >>notGoodEnoughFile, \"\\t\".join(list(key) + [\";\".join(value)])\n\n    # Closing the output files\n    zeroedOutFile.close()\n    notGoodEnoughFile.close()\n\n    # Getting the indexes to keep\n    sampleToKeep = np.array(chosenSamples.values()) + 4\n    sampleToKeep.sort()\n    toKeep = np.append(np.array(range(4)), sampleToKeep)\n\n    # Subsetting the tped\n    newTPED = tped[:, toKeep]\n\n    # Getting the indexes of the tfam\n    toKeep = []\n    for sampleID, indexes in oldSamples.iteritems():\n        i = samples[sampleID].index(chosenSamples[sampleID])\n        toKeep.append(indexes[i])\n    toKeep = np.array(toKeep)\n    toKeep.sort()\n\n    # Subsetting the tfam\n    newTFAM = tfam[toKeep]\n\n    return newTPED, newTFAM"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchooses the best duplicates according to the completion rate.", "response": "def chooseBestDuplicates(tped, samples, oldSamples, completion,\n                         concordance_all, prefix):\n    \"\"\"Choose the best duplicates according to the completion rate.\n\n    :param tped: the ``tped`` containing the duplicated samples.\n    :param samples: the updated position of the samples in the tped containing\n                    only duplicated samples.\n    :param oldSamples: the original duplicated sample positions.\n    :param completion: the completion of each of the duplicated samples.\n    :param concordance_all: the concordance of every duplicated samples.\n    :param prefix: the prefix of all the files.\n\n    :type tped: :py:class:`numpy.array`\n    :type samples: dict\n    :type oldSamples: dict\n    :type completion: :py:class:`numpy.array`\n    :type concordance_all: dict\n    :type prefix: str\n\n    :returns: a tuple where the first element is a list of the chosen samples'\n              indexes, the second on is the completion and the last one is the\n              concordance (a map).\n\n    These are the steps to find the best duplicated sample:\n\n    1. Sort the list of concordances.\n    2. Sort the list of completions.\n    3. Choose the best of the concordance and put in a set.\n    4. Choose the best of the completion and put it in a set.\n    5. Compute the intersection of the two sets. If there is one sample or\n       more, then randomly choose one sample.\n    6. If the intersection doesn't contain at least one sample, redo steps 3\n       and 4, but increase the number of chosen best by one. Redo step 5 and 6\n       (if required).\n\n    The chosen samples are written in ``prefix.chosen_samples.info``. The rest\n    are written in ``prefix.excluded_samples.info``.\n\n    \"\"\"\n    # The output files\n    chosenFile = None\n    try:\n        chosenFile = open(prefix + \".chosen_samples.info\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.chosen_samples.info: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>chosenFile, \"\\t\".join([\"origIndex\", \"dupIndex\", \"famID\", \"indID\"])\n\n    excludedFile = None\n    try:\n        excludedFile = open(prefix + \".excluded_samples.info\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.excluded_samples.info: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>excludedFile, \"\\t\".join([\"origIndex\", \"dupIndex\", \"famID\",\n                                     \"indID\"])\n\n    # For each duplicated sample\n    chosenIndexes = {}\n    sampleConcordance = {}\n    for sample, indexes in samples.iteritems():\n        # Getting the completion for those duplicated samples\n        currCompletion = completion[indexes]\n\n        # Sorting those completion\n        sortedCompletionIndexes = np.argsort(currCompletion)\n\n        # Getting the concordance\n        concordance = concordance_all[sample]\n        currConcordance = [[] for i in xrange(len(indexes))]\n        for i in xrange(len(indexes)):\n            indexToKeep = list(set(range(len(indexes))) - set([i]))\n            currConcordance[i] = np.mean(concordance[i, indexToKeep])\n        currConcordance = np.array(currConcordance)\n        if sample not in sampleConcordance:\n            sampleConcordance[sample] = currConcordance\n\n        # Sorting the concordance\n        sortedConcordanceIndexes = np.argsort(currConcordance)\n\n        # Trying to find the best duplicate to keep\n        nbToCheck = 1\n        chosenIndex = None\n        while nbToCheck <= len(indexes):\n            # Getting the `nbToCheck` best value (higher to lower)\n            completionValue = currCompletion[\n                sortedCompletionIndexes[nbToCheck*-1]\n            ]\n            concordanceValue = currConcordance[\n                sortedConcordanceIndexes[nbToCheck*-1]\n            ]\n\n            # Getting the indexes to consider\n            completionToConsider = set(\n                np.where(currCompletion >= completionValue)[0]\n            )\n            concordanceToConsider = set(\n                np.where(currConcordance >= concordanceValue)[0])\n\n            # Getting the intersection of the indexes\n            toConsider = concordanceToConsider & completionToConsider\n            if len(toConsider) >= 1:\n                chosenIndex = random.choice(list(toConsider))\n                break\n            nbToCheck += 1\n\n        if chosenIndex is None:\n            msg = \"Could not choose the best sample ID for {}\".format(sample)\n            raise ProgramError(msg)\n\n        # Printing the chosen samples\n        print >>chosenFile, \"\\t\".join([str(oldSamples[sample][chosenIndex]+1),\n                                       str(indexes[chosenIndex]+1), sample[0],\n                                       sample[1]])\n\n        # Printing the excluded samples\n        for i, index in enumerate(indexes):\n            if i != chosenIndex:\n                print >>excludedFile, \"\\t\".join([str(oldSamples[sample][i]+1),\n                                                 str(index+1), sample[0],\n                                                 sample[1]])\n\n        chosenIndexes[sample] = indexes[chosenIndex]\n\n    # Closing the output files\n    chosenFile.close()\n    excludedFile.close()\n\n    return chosenIndexes, completion, sampleConcordance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef printDuplicatedTPEDandTFAM(tped, tfam, samples, oldSamples, prefix):\n    # Print the TPED\n    outputTPED = None\n    try:\n        outputTPED = open(prefix + \".duplicated_samples.tped\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.duplicated_samples.tped: can't write \" \\\n              \"file\" % locals()\n        raise ProgramError(msg)\n    for row in tped:\n        print >>outputTPED, \"\\t\".join(row)\n    outputTPED.close()\n\n    # Print the TFAM\n    nbSamples = len(tped[0][4:])\n    newTFAM = [0 for i in xrange(nbSamples)]\n    for samples, indexes in samples.iteritems():\n        oldIndexes = oldSamples[samples]\n        for i, index in enumerate(indexes):\n            oldIndex = oldIndexes[i]\n            newTFAM[index] = tfam[oldIndex]\n    outputTFAM = None\n    try:\n        outputTFAM = open(prefix + \".duplicated_samples.tfam\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.duplicated_samples.tfam: can't write \" \\\n              \"file\" % locals()\n        raise ProgramError(msg)\n    for row in newTFAM:\n        print >>outputTFAM, \"\\t\".join(row)\n    outputTFAM.close()", "response": "Print the TPED and TFAM of the duplicated samples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the concordance of each sample.", "response": "def printConcordance(concordance, prefix):\n    \"\"\"Print the concordance.\n\n    :param concordance: the concordance of each sample.\n    :param prefix: the prefix of all the files.\n\n    :type concordance: dict\n    :type prefix: str\n\n    :returns: the concordance percentage (dict)\n\n    The concordance is the number of genotypes that are equal when comparing a\n    duplicated samples with another one, divided by the total number of\n    genotypes (excluding genotypes that are no call [*i.e.* ``0``]). If a\n    duplicated sample has 100% of no calls, the concordance will be zero.\n\n    The file ``prefix.concordance`` will contain :math:`N \\\\times N` matrices\n    for each set of duplicated samples.\n\n    \"\"\"\n    outFile = None\n    try:\n        outFile = open(prefix + \".concordance\", \"w\")\n    except IOError:\n        msg = \"%s: can't write file\" % prefix + \".concordance\"\n        raise ProgramError(msg)\n\n    concordance_percentage = {}\n    for key in concordance.iterkeys():\n        print >>outFile, \"#%s\\t%s\" % key\n\n        # Doing the division\n        none_zero = concordance[key][1] != 0\n        true_concordance = np.zeros(np.multiply(*concordance[key][1].shape))\n        true_concordance[np.ravel(none_zero)] = np.true_divide(\n            concordance[key][0][none_zero],\n            concordance[key][1][none_zero],\n        )\n        true_concordance.shape = concordance[key][1].shape\n        true_concordance = np.asmatrix(true_concordance)\n        concordance_percentage[key] = true_concordance\n\n        output = StringIO.StringIO()\n        np.savetxt(output, true_concordance, delimiter=\"\\t\", fmt=\"%.8f\")\n        print >>outFile, output.getvalue().rstrip(\"\\r\\n\")\n\n    outFile.close()\n\n    return concordance_percentage"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef printStatistics(completion, concordance, tpedSamples, oldSamples, prefix):\n\n    # Compute the completion percentage on none zero values\n    none_zero_indexes = np.where(completion[1] != 0)\n    completionPercentage = np.zeros(len(completion[0]), dtype=float)\n    completionPercentage[none_zero_indexes] = np.true_divide(\n        completion[0, none_zero_indexes],\n        completion[1, none_zero_indexes],\n    )\n\n    # The output file containing the summary statistics (for each of the\n    # duplicated samples, print the mean concordance and the completion).\n    outputFile = None\n    try:\n        outputFile = open(prefix + \".summary\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.summary: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    print >>outputFile, \"\\t\".join([\"origIndex\", \"dupIndex\", \"famID\", \"indID\",\n                                   \"% completion\", \"completion\",\n                                   \"mean concordance\"])\n    for sampleID, indexes in tpedSamples.iteritems():\n        for i, index in enumerate(indexes):\n            # The indexes\n            toPrint = [str(oldSamples[sampleID][i]+1), str(index+1)]\n            # The samples\n            toPrint.extend(list(sampleID))\n\n            # The completion\n            toPrint.append(\"%.8f\" % completionPercentage[index])\n            toPrint.append(\"%d/%d\" % (completion[0][index],\n                                      completion[1][index]))\n\n            # The concordance (not on total values = 0)\n            indexToKeep = list(set(range(len(indexes))) - set([i]))\n            values = np.ravel(\n                np.asarray(concordance[sampleID][0][i, indexToKeep])\n            )\n            total_values = np.ravel(\n                np.asarray(concordance[sampleID][1][i, indexToKeep])\n            )\n            currConcordance = np.zeros(len(indexToKeep), dtype=float)\n            none_zero_indexes = np.where(total_values != 0)\n            currConcordance[none_zero_indexes] = np.true_divide(\n                values[none_zero_indexes],\n                total_values[none_zero_indexes],\n            )\n            currConcordance = np.mean(currConcordance)\n            toPrint.append(\"%.8f\" % currConcordance)\n            print >>outputFile, \"\\t\".join(toPrint)\n\n    # Closing the output file\n    outputFile.close()\n\n    return completionPercentage", "response": "Print the statistics for each duplicated sample in a single file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef computeStatistics(tped, tfam, samples, oldSamples, prefix):\n    # The diff file containing the genotype differences between a pair of\n    # duplicated samples\n    diffOutput = None\n    try:\n        diffOutput = open(prefix + \".diff\", \"w\")\n    except IOError:\n        msg = \"%(prefix)s.diff: can't write file\" % locals()\n        raise ProgramError(msg)\n    print >>diffOutput, \"\\t\".join([\"name\", \"famID\", \"indID\", \"dupIndex_1\",\n                                   \"dupIndex_2\", \"genotype_1\", \"genotype_2\"])\n\n    # The completion data type\n    completion = np.array([[0 for i in xrange(len(tped[0][4:]))],\n                           [0 for i in xrange(len(tped[0][4:]))]])\n\n    # The concordance data type\n    concordance = {}\n    for sampleID in samples.keys():\n        nbDup = len(samples[sampleID])\n        concordance[sampleID] = [\n            np.asmatrix(np.zeros((nbDup, nbDup), dtype=int)),\n            np.asmatrix(np.zeros((nbDup, nbDup), dtype=int)),\n        ]\n\n    #####################################################################\n    # Add options for concordance only for hetero SNPs... (all samples) #\n    #####################################################################\n\n    for row in tped:\n        genotype = row[4:]\n        chromosome = row[0]\n        snpName = row[1]\n        for key, indexes in samples.iteritems():\n            for i, index in enumerate(indexes):\n                sex = tfam[oldSamples[key][i]][4]\n                genotype1 = set(genotype[index].split(\" \"))\n\n                # Updating the completion\n                if not ((chromosome == \"24\") and (sex == \"2\")):\n                    if (sex == \"1\") and (chromosome in [\"23\", \"24\"]):\n                        if (\"0\" not in genotype1) and (len(genotype1) != 2):\n                            completion[0][index] += 1\n                    elif \"0\" not in genotype1:\n                        completion[0][index] += 1\n                    completion[1][index] += 1\n\n                    # Updating the concordance\n                    for j in xrange(i + 1, len(indexes)):\n                        genotype2 = set(genotype[indexes[j]].split(\" \"))\n\n# This is for man on chr 23 and 24, if heterozygous!!! #\n# if (sex == \"1\") and (chromosome in [\"23\", \"24\"]):\n#     if (\"0\" not in genotype1) and (\"0\" not in genotype2):\n#         if (len(genotype1) != 2) and (len(genotype2) != 2):\n#             concordance[key][1][i,j] += 1\n#             concordance[key][1][j,i] += 1\n#             if genotype1 == genotype2:\n#                 concordance[key][0][i,j] += 1\n#                 concordance[key][0][j,i] += 1\n#             else:\n#                 # Print to diff file\n#                 toPrint = [snpName, key[0], key[1],\n#                            str(index+1),\n#                            str(indexes[j]+1)]\n#                 toPrint.append(\" \".join(genotype1))\n#                 if len(genotype1) == 1:\n#                     toPrint[-1] += \" %s\" % toPrint[-1]\n#                 toPrint.append(\" \".join(genotype2))\n#                 if len(genotype2) == 1:\n#                     toPrint[-1] += \" %s\" % toPrint[-1]\n#                 print >>diffOutput, \"\\t\".join(toPrint)\n#\n# elif (\"0\" not in genotype1) and (\"0\" not in genotype2):\n\n                        if (\"0\" not in genotype1) and (\"0\" not in genotype2):\n                            # Both have calls\n                            concordance[key][1][i, j] += 1\n                            concordance[key][1][j, i] += 1\n                            if genotype1 == genotype2:\n                                concordance[key][0][i, j] += 1\n                                concordance[key][0][j, i] += 1\n                            else:\n                                # Print to diff file\n                                toPrint = [snpName, key[0], key[1],\n                                           str(index+1), str(indexes[j]+1)]\n                                toPrint.append(\" \".join(genotype1))\n                                if len(genotype1) == 1:\n                                    toPrint[-1] += \" %s\" % toPrint[-1]\n                                toPrint.append(\" \".join(genotype2))\n                                if len(genotype2) == 1:\n                                    toPrint[-1] += \" %s\" % toPrint[-1]\n                                print >>diffOutput, \"\\t\".join(toPrint)\n\n    diffOutput.close()\n\n    for key in concordance.iterkeys():\n        for i in range(len(concordance[key][0])):\n            concordance[key][0][i, i] = 1\n            concordance[key][1][i, i] = 1\n\n    return completion, concordance", "response": "Computes the completion and concordance of each duplicated sample."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef processTPED(uniqueSamples, duplicatedSamples, fileName, prefix):\n    # Getting the indexes\n    uI = sorted(uniqueSamples.values())\n    dI = []\n    for item in duplicatedSamples.itervalues():\n        dI.extend(item)\n    dI.sort()\n\n    tped = []\n    outputFile = None\n    try:\n        outputFile = open(prefix + \".unique_samples.tped\", \"w\")\n    except IOError:\n        msg = \"%s: can't write to file\" % prefix + \".unique_samples.tped\"\n        raise ProgramError\n    with open(fileName, 'r') as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            snpInfo = row[:4]\n            genotype = row[4:]\n\n            # Printing the new TPED file (unique samples only)\n            print >>outputFile, \"\\t\".join(snpInfo + [genotype[i] for i in uI])\n\n            # Saving the TPED file (duplicated samples only)\n            tped.append(tuple(snpInfo + [genotype[i] for i in dI]))\n\n    # Closing the output file\n    outputFile.close()\n\n    # Updating the positions\n    updatedSamples = {}\n    for sampleID in duplicatedSamples:\n        positions = duplicatedSamples[sampleID]\n        newPositions = range(len(positions))\n        for i, pos in enumerate(positions):\n            newPositions[i] = dI.index(pos)\n        updatedSamples[sampleID] = newPositions\n\n    tped = np.array(tped)\n\n    return tped, updatedSamples", "response": "Process the TPED file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef printUniqueTFAM(tfam, samples, prefix):\n    fileName = prefix + \".unique_samples.tfam\"\n    try:\n        with open(fileName, \"w\") as outputFile:\n            for i in sorted(samples.values()):\n                print >>outputFile, \"\\t\".join(tfam[i])\n    except IOError:\n        msg = \"%(fileName)s: no such file\"\n        raise ProgramError(msg)", "response": "Prints a new TFAM file with only unique samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the duplicates in a TFAM file.", "response": "def findDuplicates(tfam):\n    \"\"\"Finds the duplicates in a TFAM.\n\n    :param tfam: representation of a ``tfam`` file.\n    :type tfam: list\n\n    :returns: two :py:class:`dict`, containing unique and duplicated samples\n              position.\n\n    \"\"\"\n    uSamples = {}\n    dSamples = defaultdict(list)\n    for i, row in enumerate(tfam):\n        sampleID = tuple(row[:2])\n        if sampleID not in uSamples:\n            # This is the first time we see this sample\n            uSamples[sampleID] = i\n        else:\n            # We have seen this sample at least once...\n            if sampleID not in dSamples:\n                # This is the second time we see this sample...\n                dSamples[sampleID].extend([uSamples[sampleID], i])\n            else:\n                # We have seen this sample multiple times\n                dSamples[sampleID].append(i)\n\n    # Removing the duplicates from the unique samples\n    for sampleID in dSamples.iterkeys():\n        if sampleID in uSamples:\n            del uSamples[sampleID]\n\n    return uSamples, dSamples"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the arguments and options for the ador program.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: a :py:class:`argparse.Namespace` object containing the options\n                 of the program.\n\n    :type args: :py:class:`argparse.Namespace`\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Checking the input files\n    for suffix in [\".tped\", \".tfam\"]:\n        fileName = args.tfile + suffix\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Checking the concordance threshold\n    if ((args.sample_concordance_threshold < 0) or\n            (args.sample_concordance_threshold > 1)):\n        msg = \"sample-concordance-threshold: must be between 0 and 1 \" \\\n              \"(not %f)\" % args.sample_concordance_threshold\n        raise ProgramError(msg)\n\n    # Checking the completion threshold\n    if ((args.sample_completion_threshold < 0) or\n            (args.sample_completion_threshold > 1)):\n        msg = \"sample-completion-threshold: must be between 0 and 1 \" \\\n              \"(not %f)\" % args.sample_completion_threshold\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default( self, o ):\n        if isinstance(o, datetime):\n            # date/time, return an ISO formatted string\n            return o.isoformat()\n        else:\n            if isinstance(o, Exception):\n                # exception, stringify it\n                return str(o)\n            else:\n                if isinstance(o, numpy.integer):\n                    # numpy ints inherit differently between Python 2 and 3\n                    # see https://bugs.python.org/issue24313\n                    return int(o)\n                else:\n                    # everything else, pass through\n                    return super(MetadataEncoder, self).default(o)", "response": "Convert an object to an ISO string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the notebook from the given file.", "response": "def _load( self, fn ):\n        \"\"\"Retrieve the notebook from the given file.\n\n        :param fn: the file name\"\"\"\n\n        # if file is empty, create an empty notebook\n        if os.path.getsize(fn) == 0:\n            self._description = None\n            self._results = dict()\n            self._pending = dict()\n        else:\n            # load the JSON object\n            with open(fn, \"r\") as f:\n                s = f.read()\n\n                # parse back into appropriate variables\n                j = json.loads(s)\n                self._description = j['description']\n                self._pending = dict(j['pending'])\n                self._results = j['results']\n\n                # perform any post-load patching\n                self.patch()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npatch the results dict. The default processes the START_TIME and END_TIME metadata fields back into Python datetime objects. This is not strictly necessary but makes notebook data structure more Pythonic.", "response": "def patch( self ):\n        \"\"\"Patch the results dict. The default processes the :attr:`Experiment.START_TIME`\n        and :attr:`Experiment.END_TIME` metadata fields back into Python `datetime` objects\n        from ISO strings. This isn't strictly necessary, but it makes notebook\n        data structure more Pythonic.\"\"\"\n\n        for k in self._results.keys():\n            ars = self._results[k]\n            for res in ars:\n                if isinstance(res, dict) and res[epyc.Experiment.METADATA][epyc.Experiment.STATUS]:\n                    # a successful, non-pending result, patch its timing metadata\n                    self._patchDatetimeMetadata(res, epyc.Experiment.START_TIME)\n                    self._patchDatetimeMetadata(res, epyc.Experiment.END_TIME)\n        ps = dict()\n        for k in self._pending.keys():\n            ps[int(k)] = self._pending[k]\n        self._pending = ps"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the notebook to the given file.", "response": "def _save( self, fn ):\n        \"\"\"Persist the notebook to the given file.\n\n        :param fn: the file name\"\"\"\n\n        # create JSON object\n        j = json.dumps({ 'description': self.description(),\n                         'pending': self._pending,\n                         'results': self._results },\n                       indent = 4,\n                       cls = MetadataEncoder)\n\n        # write to file\n        with open(fn, 'w') as f:\n            f.write(j)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Barati_high(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_.\n\n    .. math::\n        C_D = 8\\times 10^{-6}\\left[(Re/6530)^2 + \\tanh(Re) - 8\\ln(Re)/\\ln(10)\\right]\n        - 0.4119\\exp(-2.08\\times10^{43}/[Re + Re^2]^4)\n        -2.1344\\exp(-\\{[\\ln(Re^2 + 10.7563)/\\ln(10)]^2 + 9.9867\\}/Re)\n        +0.1357\\exp(-[(Re/1620)^2 + 10370]/Re)\n        - 8.5\\times 10^{-3}\\{2\\ln[\\tanh(\\tanh(Re))]/\\ln(10) - 2825.7162\\}/Re\n        + 2.4795\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number of the sphere, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is Re <= 1E6\n    This model is the wider-range model the authors developed.\n    At sufficiently low diameters or Re values, drag is no longer a phenomena.\n\n    Examples\n    --------\n    Maching example in [1]_, in a table of calculated values.\n\n    >>> Barati_high(200.)\n    0.7730544082789523\n\n    References\n    ----------\n    .. [1] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    Cd = (8E-6*((Re/6530.)**2 + tanh(Re) - 8*log(Re)/log(10.))\n    - 0.4119*exp(-2.08E43/(Re+Re**2)**4)\n    - 2.1344*exp(-((log(Re**2 + 10.7563)/log(10))**2 + 9.9867)/Re)\n    + 0.1357*exp(-((Re/1620.)**2 + 10370.)/Re)\n    - 8.5E-3*(2*log(tanh(tanh(Re)))/log(10) - 2825.7162)/Re + 2.4795)\n    return Cd", "response": "Barati - High drag coefficient of a smooth sphere."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Morsi_Alexander(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_ as described in [2]_.\n\n    .. math::\n        C_D = \\left\\{ \\begin{array}{ll}\n        \\frac{24}{Re} & \\mbox{if $Re < 0.1$}\\\\\n        \\frac{22.73}{Re}+\\frac{0.0903}{Re^2} + 3.69 & \\mbox{if $0.1 < Re < 1$}\\\\\n        \\frac{29.1667}{Re}-\\frac{3.8889}{Re^2} + 1.2220 & \\mbox{if $1 < Re < 10$}\\\\\n        \\frac{46.5}{Re}-\\frac{116.67}{Re^2} + 0.6167 & \\mbox{if $10 < Re < 100$}\\\\\n        \\frac{98.33}{Re}-\\frac{2778}{Re^2} + 0.3644 & \\mbox{if $100 < Re < 1000$}\\\\\n        \\frac{148.62}{Re}-\\frac{4.75\\times10^4}{Re^2} + 0.3570 & \\mbox{if $1000 < Re < 5000$}\\\\\n        \\frac{-490.5460}{Re}+\\frac{57.87\\times10^4}{Re^2} + 0.46 & \\mbox{if $5000 < Re < 10000$}\\\\\n        \\frac{-1662.5}{Re}+\\frac{5.4167\\times10^6}{Re^2} + 0.5191 & \\mbox{if $10000 < Re < 50000$}\\end{array} \\right.\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number of the sphere, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is Re <= 2E5.\n    Original was reviewed, and confirmed to contain the cited equations.\n\n    Examples\n    --------\n    >>> Morsi_Alexander(200)\n    0.7866\n\n    References\n    ----------\n    .. [1] Morsi, S. A., and A. J. Alexander. \"An Investigation of Particle\n       Trajectories in Two-Phase Flow Systems.\" Journal of Fluid Mechanics\n       55, no. 02 (September 1972): 193-208. doi:10.1017/S0022112072001806.\n    .. [2] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    if Re < 0.1:\n        Cd = 24./Re\n    elif Re < 1:\n        Cd = 22.73/Re + 0.0903/Re**2 + 3.69\n    elif Re < 10:\n        Cd = 29.1667/Re - 3.8889/Re**2 + 1.222\n    elif Re < 100:\n        Cd = 46.5/Re - 116.67/Re**2 + 0.6167\n    elif Re < 1000:\n        Cd = 98.33/Re - 2778./Re**2 + 0.3644\n    elif Re < 5000:\n        Cd = 148.62/Re - 4.75E4/Re**2 + 0.357\n    elif Re < 10000:\n        Cd = -490.546/Re + 57.87E4/Re**2 + 0.46\n    else:\n        Cd = -1662.5/Re + 5.4167E6/Re**2 + 0.5191\n    return Cd", "response": "Alexander method for the logarithmic tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Flemmer_Banks(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_ as described in [2]_.\n\n    .. math::\n        C_D = \\frac{24}{Re}10^E\n\n        E = 0.383Re^{0.356}-0.207Re^{0.396} - \\frac{0.143}{1+(\\log_{10} Re)^2}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number of the sphere, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is Re <= 2E5\n\n    Examples\n    --------\n    >>> Flemmer_Banks(200.)\n    0.7849169609270039\n\n    References\n    ----------\n    .. [1] Flemmer, R. L. C., and C. L. Banks. \"On the Drag Coefficient of a\n       Sphere.\" Powder Technology 48, no. 3 (November 1986): 217-21.\n       doi:10.1016/0032-5910(86)80044-4.\n    .. [2] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    E = 0.383*Re**0.356 - 0.207*Re**0.396 - 0.143/(1 + (log10(Re))**2)\n    Cd = 24./Re*10**E\n    return Cd", "response": "Calculates drag coefficient of a smooth sphere using the method in\n    [ 1 ] _ as described in [ 2 ] _."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Clift(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_ as described in [2]_.\n\n    .. math::\n        C_D = \\left\\{ \\begin{array}{ll}\n        \\frac{24}{Re} + \\frac{3}{16} & \\mbox{if $Re < 0.01$}\\\\\n        \\frac{24}{Re}(1 + 0.1315Re^{0.82 - 0.05\\log Re}) & \\mbox{if $0.01 < Re < 20$}\\\\\n        \\frac{24}{Re}(1 + 0.1935Re^{0.6305}) & \\mbox{if $20 < Re < 260$}\\\\\n        10^{[1.6435 - 1.1242\\log Re + 0.1558[\\log Re]^2} & \\mbox{if $260 < Re < 1500$}\\\\\n        10^{[-2.4571 + 2.5558\\log Re - 0.9295[\\log Re]^2 + 0.1049[\\log Re]^3} & \\mbox{if $1500 < Re < 12000$}\\\\\n        10^{[-1.9181 + 0.6370\\log Re - 0.0636[\\log Re]^2} & \\mbox{if $12000 < Re < 44000$}\\\\\n        10^{[-4.3390 + 1.5809\\log Re - 0.1546[\\log Re]^2} & \\mbox{if $44000 < Re < 338000$}\\\\\n        9.78 - 5.3\\log Re & \\mbox{if $338000 < Re < 400000$}\\\\\n        0.19\\log Re - 0.49 & \\mbox{if $400000 < Re < 1000000$}\\end{array} \\right.\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number of the sphere, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is Re <= 1E6.\n\n    Examples\n    --------\n    >>> Clift(200)\n    0.7756342422322543\n\n    References\n    ----------\n    .. [1] R. Clift, J.R. Grace, M.E. Weber, Bubbles, Drops, and Particles,\n       Academic, New York, 1978.\n    .. [2] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    if Re < 0.01:\n        Cd = 24./Re + 3/16.\n    elif Re < 20:\n        Cd = 24./Re*(1 + 0.1315*Re**(0.82 - 0.05*log10(Re)))\n    elif Re < 260:\n        Cd = 24./Re*(1 + 0.1935*Re**(0.6305))\n    elif Re < 1500:\n        Cd = 10**(1.6435 - 1.1242*log10(Re) + 0.1558*(log10(Re))**2)\n    elif Re < 12000:\n        Cd = 10**(-2.4571 + 2.5558*log10(Re) - 0.9295*(log10(Re))**2 + 0.1049*log10(Re)**3)\n    elif Re < 44000:\n        Cd = 10**(-1.9181 + 0.6370*log10(Re) - 0.0636*(log10(Re))**2)\n    elif Re < 338000:\n        Cd = 10**(-4.3390 + 1.5809*log10(Re) - 0.1546*(log10(Re))**2)\n    elif Re < 400000:\n        Cd = 29.78 - 5.3*log10(Re)\n    else:\n        Cd = 0.19*log10(Re) - 0.49\n    return Cd", "response": "A function that calculates the drag coefficient of a smooth sphere using the method in\n    [ 1 ] _ as described in [ 2 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_option_string(self, options):\n        option_string = \"\"\n        if options is not None:\n            for key in options:\n                option_string += \"/%s-%s\" % (key, options[key])\n        return self._quote_url(option_string)", "response": "Builds the option string for an API endpoint"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop of web server", "response": "def stop(host=None, port=None):\r\n    \"\"\"stop of web server\"\"\"\r\n    app.config['HOST'] = first_value(host, app.config.get('HOST',None), '0.0.0.0')\r\n    app.config['PORT'] = int(first_value(port, app.config.get('PORT',None), 5001))\r\n    if app.config['HOST'] == \"0.0.0.0\": \r\n        host=\"127.0.0.1\"\r\n    else:\r\n        host = app.config['HOST']\r\n    port = app.config['PORT']    \r\n    try:\r\n        if requests.get('http://%s:%s/api/status' % (host, port)).status_code == 200:\r\n            requests.get('http://%s:%s/api/stop' % (host,port))\r\n            print('web server is stopped', file=sys.stdinfo)\r\n        else:\r\n            print('web server is not flaskserver', file=sys.stderr)\r\n    except:\r\n        print('web server is not flaskserver or not start', file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nviewing log of web server", "response": "def log(host=None, port=None, limit=0):\r\n    \"\"\"view log of web server\"\"\"\r\n    app.config['HOST'] = first_value(host, app.config.get('HOST',None), '0.0.0.0')\r\n    app.config['PORT'] = int(first_value(port, app.config.get('PORT',None), 5001))\r\n    if app.config['HOST'] == \"0.0.0.0\": \r\n        host=\"127.0.0.1\"\r\n    else:\r\n        host = app.config['HOST']\r\n    port = app.config['PORT']    \r\n    try:\r\n        res = requests.get('http://%s:%s/api/log?limit=%s' % (host, port, limit))\r\n        if res.status_code == 200:\r\n            for record in json.loads(res.text):\r\n                if record['level'] >= 30:\r\n                    print(record['msg'], file=sys.stderr)\r\n                else:    \r\n                    print(record['msg'], file=sys.stdinfo)\r\n        else:\r\n            print('web server is not flaskserver', file=sys.stderr)\r\n    except:\r\n        print('web server is not flaskserver or not start', file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind looping against dictionary keys", "response": "def find_for_x_in_y_keys(node):\n    \"\"\"Finds looping against dictionary keys\"\"\"\n    return (\n        isinstance(node, ast.For)\n        and h.call_name_is(node.iter, 'keys')\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_if_x_retbool_else_retbool(node):\n    return (\n        isinstance(node, ast.If)\n        and isinstance(node.body[0], ast.Return)\n        and h.is_boolean(node.body[0].value)\n        and h.has_else(node)\n        and isinstance(node.orelse[0], ast.Return)\n        and h.is_boolean(node.orelse[0].value)\n    )", "response": "Finds simplifiable if condition"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_path_join_using_plus(node):\n    return (\n        isinstance(node, ast.BinOp)\n        and isinstance(node.op, ast.Add)\n        and isinstance(node.left, ast.BinOp)\n        and isinstance(node.left.op, ast.Add)\n        and isinstance(node.left.right, ast.Str)\n        and node.left.right.s in ['/', \"\\\\\"]\n    )", "response": "Finds joining path with plus"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_assign_to_builtin(node):\n\n    # The list of forbidden builtins is constant and not determined at\n    # runtime anyomre. The reason behind this change is that certain\n    # modules (like `gettext` for instance) would mess with the\n    # builtins module making this practice yield false positives.\n    if sys.version_info.major == 3:\n        builtins = {\"abs\", \"all\", \"any\", \"ascii\", \"bin\", \"bool\",\n                    \"bytearray\", \"bytes\", \"callable\", \"chr\",\n                    \"classmethod\", \"compile\", \"complex\", \"delattr\",\n                    \"dict\", \"dir\", \"divmod\", \"enumerate\", \"eval\",\n                    \"exec\", \"filter\", \"float\", \"format\", \"frozenset\",\n                    \"getattr\", \"globals\", \"hasattr\", \"hash\", \"help\",\n                    \"hex\", \"id\", \"__import__\", \"input\", \"int\",\n                    \"isinstance\", \"issubclass\", \"iter\", \"len\", \"list\",\n                    \"locals\", \"map\", \"max\", \"memoryview\", \"min\",\n                    \"next\", \"object\", \"oct\", \"open\", \"ord\", \"pow\",\n                    \"print\", \"property\", \"range\", \"repr\", \"reversed\",\n                    \"round\", \"set\", \"setattr\", \"slice\", \"sorted\",\n                    \"staticmethod\", \"str\", \"sum\", \"super\", \"tuple\",\n                    \"type\", \"vars\", \"zip\"}\n    else:\n        builtins = {\"abs\", \"all\", \"any\", \"basestring\", \"bin\", \"bool\",\n                    \"bytearray\", \"callable\", \"chr\", \"classmethod\",\n                    \"cmp\", \"compile\", \"complex\", \"delattr\", \"dict\",\n                    \"dir\", \"divmod\", \"enumerate\", \"eval\", \"execfile\",\n                    \"file\", \"filter\", \"float\", \"format\", \"frozenset\",\n                    \"getattr\", \"globals\", \"hasattr\", \"hash\", \"help\",\n                    \"hex\", \"id\", \"import__\", \"input\", \"int\",\n                    \"isinstance\", \"issubclass\", \"iter\", \"len\", \"list\",\n                    \"locals\", \"long\", \"map\", \"max\", \"memoryview\",\n                    \"min\", \"next\", \"object\", \"oct\", \"open\", \"ord\",\n                    \"pow\", \"print\", \"property\", \"range\", \"raw_input\",\n                    \"reduce\", \"reload\", \"repr\", \"reversed\", \"round\",\n                    \"set\", \"setattr\", \"slice\", \"sorted\",\n                    \"staticmethod\", \"str\", \"sum\", \"super\", \"tuple\",\n                    \"type\", \"unichr\", \"unicode\", \"vars\", \"xrange\",\n                    \"zip\"}\n\n    return (\n        isinstance(node, ast.Assign)\n        and len(builtins & set(h.target_names(node.targets))) > 0\n    )", "response": "Finds assigning to built - ins."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds silent generic exceptions", "response": "def find_silent_exception(node):\n    \"\"\"Finds silent generic exceptions\"\"\"\n    return (\n        isinstance(node, ast.ExceptHandler)\n        and node.type is None\n        and len(node.body) == 1\n        and isinstance(node.body[0], ast.Pass)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_equals_true_or_false(node):\n    return (\n        isinstance(node, ast.Compare)\n        and len(node.ops) == 1\n        and isinstance(node.ops[0], ast.Eq)\n        and any(h.is_boolean(n) for n in node.comparators)\n    )", "response": "Finds equals true or false"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind poor default args", "response": "def find_poor_default_arg(node):\n    \"\"\"Finds poor default args\"\"\"\n    poor_defaults = [\n        ast.Call,\n        ast.Dict,\n        ast.DictComp,\n        ast.GeneratorExp,\n        ast.List,\n        ast.ListComp,\n        ast.Set,\n        ast.SetComp,\n    ]\n\n    # pylint: disable=unidiomatic-typecheck\n    return (\n        isinstance(node, ast.FunctionDef)\n        and any((n for n in node.args.defaults if type(n) in poor_defaults))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_if_expression_as_statement(node):\n    return (\n        isinstance(node, ast.Expr)\n        and isinstance(node.value, ast.IfExp)\n    )", "response": "Finds an if expression as a statement"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_comprehension_as_statement(node):\n    return (\n        isinstance(node, ast.Expr)\n        and isinstance(node.value, (ast.ListComp,\n                                    ast.DictComp,\n                                    ast.SetComp))\n    )", "response": "Finds a comprehension as a statement"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_generator_as_statement(node):\n    return (\n        isinstance(node, ast.Expr)\n        and isinstance(node.value, ast.GeneratorExp)\n    )", "response": "Finds a generator as a statement"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomparing two BIM files for differences.", "response": "def compareBIMfiles(beforeFileName, afterFileName, outputFileName):\n    \"\"\"Compare two BIM files for differences.\n\n    :param beforeFileName: the name of the file before modification.\n    :param afterFileName: the name of the file after modification.\n    :param outputFileName: the name of the output file (containing the\n                           differences between the ``before`` and the ``after``\n                           files.\n\n    :type beforeFileName: str\n    :type afterFileName: str\n    :type outputFileName: str\n\n    :returns: the number of differences between the two files.\n\n    The ``bim`` files contain the list of markers in a given dataset. The\n    ``before`` file should have more markers than the ``after`` file. The\n    ``after`` file should be a subset of the markers in the ``before`` file.\n\n    \"\"\"\n    # Creating the options\n    options = Dummy()\n    options.before = beforeFileName\n    options.after = afterFileName\n    options.out = outputFileName\n\n    # Checking the options\n    CompareBIM.checkArgs(options)\n\n    # Reading the BIM files\n    beforeBIM = CompareBIM.readBIM(options.before)\n    afterBIM = CompareBIM.readBIM(options.after)\n\n    # Finding the differences\n    CompareBIM.compareSNPs(beforeBIM, afterBIM, options.out)\n\n    return beforeBIM - afterBIM"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the number of markers in a BIM file.", "response": "def computeNumberOfMarkers(inputFileName):\n    \"\"\"Count the number of marker (line) in a BIM file.\n\n    :param inputFileName: the name of the ``bim`` file.\n\n    :type inputFileName: str\n\n    :returns: the number of marker in the ``bim`` file.\n\n    \"\"\"\n    nbLine = 0\n    with open(inputFileName, \"r\") as inputFile:\n        nbLine = len(inputFile.readlines())\n\n    return nbLine"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the Hardy - Weinberg test using Plink.", "response": "def computeHWE(prefix, threshold, outPrefix):\n    \"\"\"Compute the Hardy Weinberg test using Plink.\n\n    :param prefix: the prefix of all the files.\n    :param threshold: the Hardy Weinberg threshold.\n    :param outPrefix: the prefix of the output file.\n\n    :type prefix: str\n    :type threshold: str\n    :type outPrefix: str\n\n    Uses Plink to exclude markers that failed the Hardy-Weinberg test at a\n    specified significance threshold.\n\n    \"\"\"\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", prefix, \"--hwe\", threshold,\n                    \"--make-bed\", \"--out\", outPrefix]\n    runCommand(plinkCommand)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef checkArgs(args):\n    # Check if we have the tped and the tfam files\n    for fileName in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Check the HW pvalue\n    hwValue = args.hwe\n    try:\n        hwValue = float(hwValue)\n    except ValueError:\n        msg = \"%(hwValue)s: not a valid HW value\" % locals()\n        raise ProgramError(msg)\n    if (hwValue < 0) or (hwValue > 1):\n        msg = \"%s: not a valid HW value\" % args.hwe\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkArgs(args):\n    # Check the input files\n    if not args.is_bfile and not args.is_tfile and not args.is_file:\n        msg = \"needs one input file type (--is-bfile, --is-tfile or --is-file)\"\n        raise ProgramError(msg)\n\n    if args.is_bfile and not args.is_tfile and not args.is_file:\n        for fileName in [args.ifile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\".format(fileName)\n                raise ProgramError(msg)\n\n    elif args.is_tfile and not args.is_bfile and not args.is_file:\n        for fileName in [args.ifile + i for i in [\".tped\", \".tfam\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\".format(fileName)\n                raise ProgramError(msg)\n\n    elif args.is_file and not args.is_bfile and not args.is_tfile:\n        for fileName in [args.ifile + i for i in [\".ped\", \".map\"]]:\n            if not os.path.isfile(fileName):\n                msg = \"{}: no such file\". format(fileName)\n                raise ProgramError(msg)\n\n    else:\n        msg = (\"needs only one input file type (--is-bfile, --is-tfile or \"\n               \"--is-file)\")\n        raise ProgramError(msg)\n\n    # Check that we have at least one of exclude, extract remove or keep\n    if args.exclude is None and args.extract is None and \\\n            args.remove is None and args.keep is None:\n        msg = \"needs at least one of --exclude, --extract, --remove or --keep\"\n        raise ProgramError(msg)\n\n    # Check for SNPs\n    if args.exclude is not None and args.extract is None:\n        if not os.path.isfile(args.exclude):\n            msg = \"{}: no such file\".format(args.exclude)\n            raise ProgramError(msg)\n    elif args.extract is not None and args.exclude is None:\n        if not os.path.isfile(args.extract):\n            msg = \"{}: no such file\".format(args.extract)\n            raise ProgramError(msg)\n    elif args.exclude is not None and args.extract is not None:\n        msg = \"use only one of --extract or --exclude\"\n        raise ProgramError(msg)\n\n    # Check for samples\n    if args.remove is not None and args.keep is None:\n        if not os.path.isfile(args.remove):\n            msg = \"{}: no such file\".format(args.remove)\n            raise ProgramError(msg)\n    elif args.keep is not None and args.remove is None:\n        if not os.path.isfile(args.keep):\n            msg = \"{}: no such file\".format(args.keep)\n            raise ProgramError(msg)\n    elif args.remove is not None and args.keep is not None:\n        msg = \"use only one of --keep or --remove\"\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options for the\n    program."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexpecting a series that each row is string formated Json data with the same structure", "response": "def series2df(Series, layer=2, split_sign = '_'):\n    \"\"\"expect pass a series that each row is string formated Json data with the same structure\"\"\"\n    try:\n        Series.columns\n        Series = Series.iloc[:,0]\n    except:\n        pass\n    \n    def _helper(x, layer=2):\n        try:\n            return flatten_dict(ast.literal_eval(x), layers=layer, split_sign=split_sign)\n        except:\n            try:\n                return flatten_dict(x, layers=layer, split_sign=split_sign)\n            except:\n                return x\n    \n    df=pd.DataFrame(Series.apply(_helper).tolist())\n    \n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload data from file", "response": "def load_data(self, path, *args, **kwargs):\n        \"\"\"see print instance.doc, e.g. cat=LoadFile(kind='excel')\n          read how to use cat.load_data, exec: print (cat.doc)\"\"\"\n        self.df = self._load(path,*args, **kwargs)\n        self.series = self.df.iloc[:,0]\n        print (\"Success! file length: \" +str(self.df.shape[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting data to DataFrame", "response": "def convert(self, layer=2, split_sign = '_', *args, **kwargs):\n        \"\"\"convert data to DataFrame\"\"\"\n        return series2df(self.series, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    logger.info(\"Options used:\")\n    for key, value in vars(args).iteritems():\n        logger.info(\"  --{} {}\".format(key.replace(\"_\", \"-\"), value))\n\n    # Run plink\n    logger.info(\"Running Plink to check the plate bias\")\n    executePlateBiasAnalysis(args)\n\n    # Extract significant SNPs\n    logger.info(\"Extracting significant SNPs\")\n    assocResults = extractSignificantSNPs(args.out)\n\n    # Remove significant SNPs using plink\n    logger.info(\"Computing frequency of significant SNPs\")\n    maf = computeFrequencyOfSignificantSNPs(args)\n\n    # Create the final summary file\n    logger.info(\"Creating the summary file\")\n    createSummaryFile(assocResults, maf, args.out)", "response": "The main function of the main module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the final summary file containing all the significant results.", "response": "def createSummaryFile(results, maf, prefix):\n    \"\"\"Creat the final summary file containing plate bias results.\n\n    :param results: the list of all the significant results.\n    :param maf: the minor allele frequency of the significant results.\n    :param prefix: the prefix of all the files.\n\n    :type results: list\n    :type maf: dict\n    :type prefix: str\n\n    \"\"\"\n    o_filename = prefix + \".significant_SNPs.summary\"\n    try:\n        with open(o_filename, \"w\") as o_file:\n            print >>o_file, \"\\t\".join((\"chrom\", \"pos\", \"name\", \"maf\", \"p\",\n                                       \"odds\", \"plate\"))\n            for row in results:\n                print >>o_file, \"\\t\".join((\n                    row.chrom,\n                    row.pos,\n                    row.name,\n                    maf.get(row.name, \"N/A\"),\n                    row.p,\n                    row.odds,\n                    row.plate,\n                ))\n\n    except IOError:\n        msg = \"{}: cannot write file\".format(o_filename)\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extractSignificantSNPs(prefix):\n    # The list of all assoc files\n    fileNames = glob.glob(prefix + \".*.assoc.fisher\")\n\n    # The object to save an assoc row\n    AssocRow = namedtuple(\"AssocRow\",\n                          [\"chrom\", \"pos\", \"name\", \"p\", \"odds\", \"plate\"])\n\n    snpNames = set()\n    assocResults = []\n    for fileName in fileNames:\n        # Getting the plate name\n        plateName = re.search(r\"/plate_bias\\.(\\S+)\\.assoc\\.fisher$\", fileName)\n        plateName = plateName.group(1) if plateName else \"unknown\"\n\n        try:\n            with open(fileName, 'r') as inputFile:\n                headerIndex = None\n                for line in inputFile:\n                    row = createRowFromPlinkSpacedOutput(line)\n\n                    if headerIndex is None:\n                        # This is the header line\n                        headerIndex = dict([\n                            (row[i], i) for i in xrange(len(row))\n                        ])\n                        for name in (\"CHR\", \"SNP\", \"BP\", \"P\", \"OR\"):\n                            if name not in headerIndex:\n                                msg = \"{}: missing column {}\".format(\n                                    fileName,\n                                    name,\n                                )\n                                raise ProgramError(msg)\n\n                    else:\n                        snpName = row[headerIndex[\"SNP\"]]\n                        snpNames.add(snpName)\n                        assocResults.append(AssocRow(\n                            chrom=row[headerIndex[\"CHR\"]],\n                            pos=row[headerIndex[\"BP\"]],\n                            name=snpName,\n                            p=row[headerIndex[\"P\"]],\n                            odds=row[headerIndex[\"OR\"]],\n                            plate=plateName,\n                        ))\n\n        except IOError:\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # The output file\n    outputFileName = prefix + \".significant_SNPs.txt\"\n    outputFile = None\n    try:\n        outputFile = open(outputFileName, \"w\")\n    except IOError:\n        msg = \"%(outputFileName)s: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    if len(snpNames) > 0:\n        print >>outputFile, \"\\n\".join(snpNames)\n\n    # Closing the file\n    outputFile.close()\n\n    return assocResults", "response": "Extract significant SNPs in the fisher file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef computeFrequencyOfSignificantSNPs(options):\n    # The plink command\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", options.bfile, \"--extract\",\n                    options.out + \".significant_SNPs.txt\", \"--freq\", \"--out\",\n                    options.out + \".significant_SNPs\"]\n    runCommand(plinkCommand)\n\n    # Reading the frequency file\n    maf = {}\n    with open(options.out + \".significant_SNPs.frq\", \"r\") as i_file:\n        header = {\n            name: i for i, name in\n            enumerate(createRowFromPlinkSpacedOutput(i_file.readline()))\n        }\n        for required_col in (\"SNP\", \"MAF\"):\n            if required_col not in header:\n                msg = \"{}: missing column {}\".format(\n                    script_prefix + \".significant_SNPs.frq\",\n                    required_col,\n                )\n                raise ProgramError(msg)\n\n        for line in i_file:\n            row = createRowFromPlinkSpacedOutput(line)\n            maf[row[header[\"SNP\"]]] = row[header[\"MAF\"]]\n\n    return maf", "response": "Computes the frequency of the significant markers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef executePlateBiasAnalysis(options):\n    # The plink command\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", options.bfile,\n                    \"--loop-assoc\", options.loop_assoc, \"--fisher\",\n                    \"--pfilter\", str(options.pfilter), \"--out\", options.out]\n    runCommand(plinkCommand)", "response": "Execute the plate bias analysis with Plink."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkArgs(args):\n    # Check if we have the tped and the tfam files\n    for fileName in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Check the plate bias file\n    if not os.path.isfile(args.loop_assoc):\n        msg = \"%s: no such file\" % args.loop_assoc\n        raise ProgramError(msg)\n\n    return True", "response": "Checks the arguments and options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_variant(variants, weights):\n    total = 0\n    accumulator = []\n    for w in weights:\n        total += w\n        accumulator.append(total)\n\n    r = randint(0, total - 1)\n    yield variants[bisect(accumulator, r)]", "response": "A generator that yields one random weighted selection of a list of variants and a corresponding list of weights."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the duration string which contains a human readable duration and return a datetime. timedelta object representing that duration", "response": "def parse(duration, context=None):\n    \"\"\"\n    parse the duration string which contains a human readable duration and\n    return a datetime.timedelta object representing that duration\n\n    arguments:\n        duration - the duration string following a notation like so:\n                   \"1 hour\"\n                   \"1 month and 3 days\" \"1 year 2 weeks and 75 days\"\n                   \"1 year, 75 days and 33 seconds\"\n                   ...\n                   etc\n\n        context - the context keyword argument is used to provide the current\n                  datetime context object used when calculating years and\n                  months which are dependent on the \"current time\" you're\n                  calculating the relative delta in relation to.\n    \"\"\"\n    matcher = _PATTERN.match(duration)\n\n    if matcher is None or matcher.end() < len(duration):\n        raise Exception('unsupported duration \"%s\"' % duration)\n\n    else:\n        result = timedelta()\n\n        if context is None:\n            context = datetime.now()\n\n        year = context.year\n        month = context.month\n        day = context.day\n\n        for (key, value) in matcher.groupdict().items():\n            weeks = 0\n            days = 0\n            hours = 0\n            minutes = 0\n            seconds = 0\n            milliseconds = 0\n            microseconds = 0\n\n            if value is not None:\n                value = float(value)\n                whole = int(value)\n                fraction = abs(whole - value)\n\n                if key == 'years':\n                    start = datetime(year, month, day)\n                    end = datetime(year + whole, month, day)\n\n                    # add remaining days for fraction part of year\n                    if fraction > 0:\n                        days_in_year = (datetime(year + whole, 12, 31) -\n                                        datetime(year + whole, 1, 1)).days + 1\n\n                        end += timedelta(days=(fraction * days_in_year))\n\n                    seconds = (end - start).total_seconds()\n\n                elif key == 'months':\n                    # when calculating relative months we do so in relation to\n                    # the first day of the month\n                    day = 1\n\n                    # figure out how many whole years and left over months and\n                    # then let pythons datetime do all the work\n                    years = whole // 12\n                    months = whole % 12\n\n                    end_month = month + months\n                    if end_month > 12:\n                        # detect month overflow and bump the year and calculate\n                        # the right end_month to use\n                        years += end_month // 12\n                        end_month = end_month % 12\n\n                    start = datetime(year, month, day)\n                    end = datetime(year + years, end_month, day)\n\n                    # add remaining days for fraction part of the month\n                    end_year = year + years\n                    end_month = month + months + 1\n                    if end_month > 12:\n                        # detect month overflow and bump the year and calculate\n                        # the right end_month to use\n                        end_year += end_month // 12\n                        end_month = end_month % 12\n\n                    _, end_day = calendar.monthrange(end_year, end_month)\n                    days_in_month = (datetime(end_year, end_month, end_day) -\n                                     datetime(end_year, end_month, 1)).days\n\n                    end += timedelta(days=(fraction * days_in_month))\n\n                    seconds = (end - start).total_seconds()\n\n                elif key == 'weeks':\n                    weeks = whole\n                    days = fraction * 7\n\n                elif key == 'days':\n                    days = whole\n                    hours = fraction * 24\n\n                elif key == 'hours':\n                    hours = whole\n                    minutes = fraction * 60\n\n                elif key == 'minutes':\n                    minutes = whole\n                    seconds = fraction * 60\n\n                elif key == 'seconds':\n                    seconds = whole\n                    milliseconds = fraction * 1000\n\n                elif key == 'milliseconds':\n                    milliseconds = whole\n                    microseconds = fraction * 1000\n\n                result += timedelta(weeks=weeks,\n                                    days=days,\n                                    hours=hours,\n                                    minutes=minutes,\n                                    seconds=seconds,\n                                    milliseconds=milliseconds,\n                                    microseconds=microseconds)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(argString=None):\n    # Getting and checking the options\n    args = parseArgs(argString)\n    checkArgs(args)\n\n    logger.info(\"Options used:\")\n    for key, value in vars(args).iteritems():\n        logger.info(\"  --{} {}\".format(key.replace(\"_\", \"-\"), value))\n\n    # Compute frequency using plink\n    logger.info(\"Computing the frequencies using Plink\")\n    computeFrequency(args)\n\n    # Read the freqency file\n    logger.info(\"Flagging SNPs with MAF = 0\")\n    findSnpWithMaf0(args.out + \".frq\", args.out)", "response": "The main function.\n\n    :param argString: the options.\n\n    :type argString: list\n\n    These are the steps:\n\n    1. Prints the options.\n    2. Computes the frequencies using Plinl (:py:func:`computeFrequency`).\n    3. Finds markers with MAF of 0, and saves them in a file\n       (:py:func:`findSnpWithMaf0`)."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a Plink frequency file and finds SNPs with MAF of 0 and puts them in a file.", "response": "def findSnpWithMaf0(freqFileName, prefix):\n    \"\"\"Finds SNPs with MAF of 0 and put them in a file.\n\n    :param freqFileName: the name of the frequency file.\n    :param prefix: the prefix of all the files.\n\n    :type freqFileName: str\n    :type prefix: str\n\n    Reads a frequency file from Plink, and find markers with a minor allele\n    frequency of zero.\n\n    \"\"\"\n    maf_0_set = set()\n    na_set = set()\n\n    try:\n        with open(freqFileName, \"r\") as inputFile:\n            headerIndex = None\n            for i, line in enumerate(inputFile):\n                row = createRowFromPlinkSpacedOutput(line)\n                if i == 0:\n                    # We have the header\n                    headerIndex = dict([\n                        (row[i], i) for i in xrange(len(row))\n                    ])\n                    for columnName in [\"SNP\", \"MAF\"]:\n                        if columnName not in headerIndex:\n                            msg = \"%(freqFileName)s: no column named \" \\\n                                  \"%(columnName)s\" % locals()\n                            raise ProgramError(msg)\n\n                else:\n                    # We have data\n                    snpName = row[headerIndex[\"SNP\"]]\n                    snpMAF = row[headerIndex[\"MAF\"]]\n\n                    if snpMAF == \"0\":\n                        # We want to flag this SNP\n                        maf_0_set.add(snpName)\n\n                    elif snpMAF == \"NA\":\n                        # We want to flag this SNP, because the MAF est NA\n                        na_set.add(snpName)\n\n    except IOError:\n        msg = \"%(freqFileName)s: no such file\" % locals()\n        raise ProgramError(msg)\n\n    # Creating the output files\n    if len(maf_0_set) == 0:\n        logger.info(\"  - There are no markers with MAF 0\")\n    else:\n        logger.info(\"  - There are {} markers with MAF 0\".format(\n            len(maf_0_set),\n        ))\n    outputFile = None\n    try:\n        with open(prefix + \".list\", \"w\") as output_file:\n            for marker_name in maf_0_set:\n                print >>output_file, marker_name\n    except IOError:\n        msg = \"{}.list: can't write file\".format(prefix)\n        raise ProgramError(msg)\n\n    if len(na_set) > 0:\n        logger.info(\"  - There are {} markers with NA MAF\".format(len(na_set)))\n        try:\n            with open(prefix + \".na_list\", \"w\") as output_file:\n                for marker_name in na_set:\n                    print >>output_file, marker_name\n        except IOError:\n            msg = \"{}.na_list: can't write file\".format(prefix)\n            raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_site():\n    site_name = 'bowercachesite'\n    dir_name = sys.argv[1] if len(sys.argv) > 1 else site_name\n    settings = site_name + \".settings\"\n    template_filename = resource_filename(bowercache.__name__,\n                                          'project_template')\n    cwd = os.getcwd()\n    full_dir_name = os.path.abspath(os.path.join(cwd, dir_name))\n\n    startproject_args = ['startproject', site_name]\n    if dir_name != site_name:\n        startproject_args.append(dir_name)\n\n    management.call_command(*startproject_args, template=template_filename)\n\n    # Now magically turn into manage.py!\n    os.environ[\"DJANGO_SETTINGS_MODULE\"] = settings\n    sys.path.insert(0, full_dir_name)\n\n    from django import conf\n    reload(conf)\n    reload(management)\n\n    management.call_command('collectstatic', interactive=False)\n    management.call_command('syncdb', interactive=False)\n    management.call_command('createsuperuser', username='admin',\n                            email='root@localhost', interactive=False)\n\n    os.mkdir(conf.settings.REPO_ROOT)", "response": "Initialize a Bower Cache site using the template."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(self, phase_inc):\n        self.phase_acc = self.phase_acc + phase_inc\n\n        start_x = self.INIT_X\n        start_y = Sfix(0.0, 0, -17)\n\n        x, y, phase = self.cordic.main(start_x, start_y, self.phase_acc)\n\n        self.out.real = x\n        self.out.imag = y\n\n        return self.out", "response": "main method for the cocaine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zotero_tags(parser, token):\n    default = {\n        'object': u'',\n        'vocabulary': u'dc',\n        'output_method': u'meta'\n    }\n    \n    letters = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven']\n    min_args = 1\n    max_args = len(default)\n    if min_args == 1:\n        min_pl = ''\n    else:\n        min_pl = 's'\n    if max_args == 1:\n        max_pl = ''\n    else:\n        max_pl = 's'\n    args = token.split_contents()\n    length = len(args)\n    if length < min_args + 1:\n        raise TemplateSyntaxError('%s requires at least %s argument%s.' %\n                                  (args[0], letters[min_args], min_pl))\n    elif length > max_args + 1:\n        raise TemplateSyntaxError('%s requires %s or less argument%s.' %\n                                  (args[0], letters[max_args], max_pl))\n    \n    for arg in args[1:length]:\n        i = arg.find('=')\n        if i == -1:\n            raise TemplateSyntaxError('%s syntax error: %s.' % (args[0], arg))\n        else:\n            key = arg[:i]\n            val = arg[i + 1:]\n            if not key in default.keys():\n                raise TemplateSyntaxError('%s invalid argument: %s.' %\n                                          (args[0], key))\n            else:\n                default[key] = val\n    \n    return ZoteroTagsNode(default)", "response": "Returns the code to be translated by Zotero.\n    Usage:\n        {% zotero_tags\n            object=object\n            vocabulary=vocabulary\n            output_method=output_method %}\n    Example:\n        {% zotero_tags object=document1 vocabulary=\"dc\" output_method=\"meta\" %}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef airport_codes():\n\thtml = requests.get(URL).text\n\tdata_block = _find_data_block(html)\n\n\treturn _airport_codes_from_data_block(data_block)", "response": "Get the set of airport codes that are available to be requested."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json_template(data, template_name, template_context):\n    html = render_to_string(template_name, template_context)\n    data = data or {}\n    data['html'] = html\n    return HttpResponse(json_encode(data), content_type='application/json')", "response": "Old style use JSONTemplateResponse instead of this.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking item type uniqueness field applicability and multiplicity.", "response": "def check_save(sender, **kwargs):\n    \"\"\"\n    Checks item type uniqueness, field applicability and multiplicity.\n    \"\"\"\n    tag = kwargs['instance']\n    obj = Tag.get_object(tag)\n    previous_tags = Tag.get_tags(obj)\n    \n    err_uniq = check_item_type_uniqueness(tag, previous_tags)\n    err_appl = check_field_applicability(tag)\n    err_mult = check_field_multiplicity(tag, previous_tags)\n    err_msg = generate_error_message(tag, err_uniq, err_appl, err_mult)\n    if err_uniq or err_appl or err_mult:\n        raise TypeError(err_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_item_type_uniqueness(tag, previous_tags):\n    fail = False\n    #If the tag is being created...\n    if not tag.id:\n        #... and the new item type is different from previous item types (for\n        #example, different from the first of them), fail\n        fail = previous_tags and tag.item_type != previous_tags[0].item_type\n    #If the tag is being modifying...\n    else:\n        #... but there is only one previous tag (the one that is being\n        #modifying), do not fail\n        fail = previous_tags.count() > 1 and \\\n               tag.item_type != previous_tags[0].item_type\n    return fail", "response": "Check the uniqueness of the item type for an object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_field_multiplicity(tag, previous_tags):\n    fail = False\n    #If the field is single\n    if not tag.field.multiple:\n        #If the tag is being created...\n        if not tag.id:\n            #... and the new field was already included in the previous tags,\n            #fail\n            fail = previous_tags.filter(field=tag.field)\n        #If the tag is being modifying...\n        else:\n            #... but there is only one previous tag (the one that is being\n            #modifying), do not fail\n            fail = previous_tags.filter(field=tag.field).count() > 1\n    return fail", "response": "Check the multiplicity of a field for an object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the error message for an object.", "response": "def generate_error_message(tag, err_uniq, err_appl, err_mult):\n    \"\"\"\n    Generate the error message for an object.\n    \"\"\"\n    err = []\n    if err_uniq:\n        err.append('Uniqueness restriction: item type %s' % tag.item_type)\n    if err_appl:\n        err.append('Applicability restriction: field %s' % tag.field)\n    if err_mult:\n        err.append('Multiplicity restriction: field %s' % tag.field)\n    return err"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_tags(sender, **kwargs):\n    try:\n        obj = kwargs.get('instance')\n        tags = Tag.get_tags(obj)\n        tags.delete()\n    except AttributeError:\n        pass", "response": "Delete the tags pointing to an object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noutputting Checkstyle XML reports.", "response": "def stop(self):\n        \"\"\"Output Checkstyle XML reports.\"\"\"\n        et = ET.ElementTree(self.checkstyle_element)\n        f = BytesIO()\n        et.write(f, encoding='utf-8', xml_declaration=True)\n        xml = f.getvalue().decode('utf-8')\n        if self.output_fd is None:\n            print(xml)\n        else:\n            self.output_fd.write(xml)\n        super(CheckstylePlugin, self).stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes the form data for the given fields and files.", "response": "def encode_multipart_formdata(self, fields, filename, verbose=False):\n        \"\"\"\n        fields is a sequence of (name, value) elements for regular form fields.\n        files is a sequence of (name, filename, value) elements for data\n        to be uploaded as files\n        Return (content_type, body) ready for httplib.HTTP instance\n        \"\"\"\n        BOUNDARY = '----------ThIs_Is_tHe_bouNdaRY_$'\n        CRLF = '\\r\\n'\n        content_type = 'multipart/form-data; boundary=%s' % BOUNDARY\n        if verbose is True:\n            print(('Encoding ' + filename + ' for upload...'))\n        fin = open(filename, 'rb')\n        fout = open(filename + '.b64', 'wb')\n        fout.write(bytearray('--' + BOUNDARY + CRLF, 'utf-8'))\n        fout.write(bytearray('Content-Disposition: form-data'\n                             '; name=\"file\"; filename=\"' +\n                             filename + '\"' + CRLF, \"utf-8\"))\n        fout.write(bytearray('Content-Type: application/octet-stream' + CRLF,\n                             'utf-8'))\n        fout.write(bytearray(CRLF, 'utf-8'))\n        shutil.copyfileobj(fin, fout)\n        fout.write(bytearray(CRLF, 'utf-8'))\n        fout.write(bytearray('--' + BOUNDARY + '--' + CRLF, 'utf-8'))\n        fout.write(bytearray(CRLF, 'utf-8'))\n        fout.close()\n        fin.close()\n        return content_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess the TPED and TFAM files. :param tped: the name of the ``tped`` file. :param tfam: the name of the ``tfam`` file. :param prefix: the prefix of the output files. :type tped: str :type tfam: str :type prefix: str Copies the original ``tfam`` file into ``prefix.tfam``. Then, it reads the ``tped`` file and keeps in memory two sets containing the markers which are all failed or which contains only heterozygous genotypes. It creates two output files, ``prefix.allFailed`` and ``prefix.allHetero``, containing the markers that are all failed and are all heterozygous, respectively. .. note:: All heterozygous markers located on the mitochondrial chromosome are not remove.", "response": "def processTPEDandTFAM(tped, tfam, prefix):\n    \"\"\"Process the TPED and TFAM files.\n\n    :param tped: the name of the ``tped`` file.\n    :param tfam: the name of the ``tfam`` file.\n    :param prefix: the prefix of the output files.\n\n    :type tped: str\n    :type tfam: str\n    :type prefix: str\n\n    Copies the original ``tfam`` file into ``prefix.tfam``. Then, it reads the\n    ``tped`` file and keeps in memory two sets containing the markers which are\n    all failed or which contains only heterozygous genotypes.\n\n    It creates two output files, ``prefix.allFailed`` and ``prefix.allHetero``,\n    containing the markers that are all failed and are all heterozygous,\n    respectively.\n\n    .. note::\n        All heterozygous markers located on the mitochondrial chromosome are\n        not remove.\n\n    \"\"\"\n    # Copying the tfam file\n    try:\n        shutil.copy(tfam, prefix + \".tfam\")\n    except IOError:\n        msg = \"%s: can't write file\" % prefix + \".tfam\"\n        raise ProgramError(msg)\n\n    try:\n        outputFile = open(prefix + \".tped\", \"w\")\n    except IOError:\n        msg = \"%s: can't write to file\" % prefix + \".tped\"\n        raise ProgramError(msg)\n\n    # The name of the bad SNPs\n    allFailed = set()\n    allHetero = set()\n\n    with open(tped, 'r') as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            snpInfo = row[:4]\n            chromosome = snpInfo[0]\n            genotypes = np.array([i.upper() for i in row[4:]])\n\n            # Testing the genotypes\n            uniqueGenotypes = np.unique(genotypes)\n            if len(uniqueGenotypes) == 1:\n                # We have only one kind of genotype, either all homo, all\n                # hetero or all no call\n                if uniqueGenotypes[0] == \"0 0\":\n                    # This one is a no call\n                    allFailed.add(snpInfo[1])\n                elif len(set(uniqueGenotypes[0].split(\" \"))) == 2:\n                    # There are two different alleles, hence, hetero\n                    if chromosome not in {\"26\", \"MT\"}:\n                        # The SNP is not on a mitochondrial chromosome\n                        # (because we want to keep those)\n                        allHetero.add(snpInfo[1])\n\n            # If the SNP is good (neither in allFailed or allHetero), we keep\n            # the SNP\n            if (snpInfo[1] not in allFailed) and (snpInfo[1] not in allHetero):\n                print >>outputFile, \"\\t\".join(row)\n\n    outputFile.close()\n\n    # Now printing the summary files\n    # The SNPs with no calls\n    fileName = prefix + \".allFailed\"\n    try:\n        with open(fileName, 'w') as outputFile:\n            if len(allFailed) > 0:\n                print >>outputFile, \"\\n\".join(allFailed)\n    except IOError:\n        msg = \"%(fileName)s: can't write to file\" % locals()\n        raise ProgramError(msg)\n\n    # The SNPs with only hetero calls\n    fileName = prefix + \".allHetero\"\n    try:\n        with open(fileName, 'w') as outputFile:\n            if len(allHetero) > 0:\n                print >>outputFile, \"\\n\".join(allHetero)\n    except IOError:\n        msg = \"%(fileName)s: can't write to file\" % locals()\n        raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the arguments and options.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Checking the input files\n    for suffix in [\".tped\", \".tfam\"]:\n        fileName = args.tfile + suffix\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the length of the array.", "response": "def weld_count(array):\n    \"\"\"Returns the length of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = _weld_count_code\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns operation on the elements in the array.", "response": "def weld_aggregate(array, weld_type, operation):\n    \"\"\"Returns operation on the elements in the array.\n\n    Arguments\n    ---------\n    array : WeldObject or numpy.ndarray\n        Input array.\n    weld_type : WeldType\n        Weld type of each element in the input array.\n    operation : {'+', '*', 'min', 'max'}\n        Operation to apply.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = _weld_aggregate_code\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              operation=operation)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weld_mean(array, weld_type):\n    weld_obj_sum = weld_aggregate(array, weld_type, '+')\n\n    obj_id, weld_obj = create_weld_object(array)\n    weld_obj_sum_id = get_weld_obj_id(weld_obj, weld_obj_sum)\n\n    weld_template = _weld_mean_code\n\n    weld_obj.weld_code = weld_template.format(sum=weld_obj_sum_id,\n                                              array=obj_id)\n\n    return weld_obj", "response": "Returns the mean of the array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the variance of the array.", "response": "def weld_variance(array, weld_type):\n    \"\"\"Returns the variance of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    \"\"\"\n    weld_obj_mean = weld_mean(array, weld_type)\n\n    obj_id, weld_obj = create_weld_object(array)\n    weld_obj_mean_id = get_weld_obj_id(weld_obj, weld_obj_mean)\n\n    weld_template = _weld_variance_code\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              mean=weld_obj_mean_id)\n\n    return weld_obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weld_standard_deviation(array, weld_type):\n    weld_obj_var = weld_variance(array, weld_type)\n\n    obj_id, weld_obj = create_weld_object(weld_obj_var)\n    weld_obj_var_id = get_weld_obj_id(weld_obj, weld_obj_var)\n\n    weld_template = _weld_std_code\n\n    weld_obj.weld_code = weld_template.format(var=weld_obj_var_id)\n\n    return weld_obj", "response": "Returns the sample standard deviation of the array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_expression_ID(p):\n    lookup = compa2lookup[p[2]]\n\n    try:\n        field = get_shortcut(p[1])\n    except KeyError:\n        field = p[1]\n\n    if lookup:\n        field = '%s__%s' % (field, lookup)\n\n    # In some situations (which ones?), python\n    # refuses unicode strings as dict keys for\n    # Q(**d)\n    field = str(field)\n\n    d = {field: p[3]}\n\n    p[0] = Q(**d)", "response": "expression - > FIELD operation value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cholesky(L, b, P=None):\n    '''\n    P A P' = L L'\n    '''\n\n    logger.debug('Solving system of dim {} with cholesky factors'.format(len(b)))\n\n    ## convert L and U to csr format\n    is_csr = scipy.sparse.isspmatrix_csr(L)\n    is_csc = scipy.sparse.isspmatrix_csc(L)\n\n    if not is_csr and not is_csc:\n        warnings.warn('cholesky requires L be in CSR or CSC matrix format. Converting matrix.', scipy.sparse.SparseEfficiencyWarning)\n\n    if is_csc:\n        U = L.transpose()\n    if not is_csr:\n        L = L.tocsr()\n    if not is_csc:\n        U = L.transpose().tocsr()\n\n    assert scipy.sparse.isspmatrix_csr(L)\n    assert scipy.sparse.isspmatrix_csr(U)\n\n    ## compute\n    return LU(L, U, b, P=P)", "response": "Solves a cholesky system of dimensionality b with a given factor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if incident is within date range", "response": "def _validate_incident_date_range(incident, numdays):\n    \"\"\"Returns true if incident is within date range\"\"\"\n    try:\n        datetime_object = datetime.datetime.strptime(incident.get('date'), '%m/%d/%y %I:%M %p')\n    except ValueError:\n        raise ValueError(\"Incorrect date format, should be MM/DD/YY HH:MM AM/PM\")\n    timedelta = datetime.timedelta(days=numdays)\n    today = datetime.datetime.now()\n    if today - datetime_object <= timedelta:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _incident_transform(incident):\n    return {\n        'id': incident.get('cdid'),\n        'type': incident.get('type'),\n        'timestamp': incident.get('date'),\n        'lat': incident.get('lat'),\n        'lon': incident.get('lon'),\n        'location': incident.get('address'),\n        'link': incident.get('link')\n    }", "response": "Get output dict from incident."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a git repository will add a tag for each major version.", "response": "def tag_versions(repo_path):\n    \"\"\"\n    Given a repo will add a tag for each major version.\n\n    Args:\n        repo_path(str): path to the git repository to tag.\n    \"\"\"\n    repo = dulwich.repo.Repo(repo_path)\n    tags = get_tags(repo)\n    maj_version = 0\n    feat_version = 0\n    fix_version = 0\n    last_maj_version = 0\n    last_feat_version = 0\n    result = []\n\n    for commit_sha, children in reversed(\n            get_children_per_first_parent(repo_path).items()\n    ):\n        commit = get_repo_object(repo, commit_sha)\n        maj_version, feat_version, fix_version = get_version(\n            commit=commit,\n            tags=tags,\n            maj_version=maj_version,\n            feat_version=feat_version,\n            fix_version=fix_version,\n            children=children,\n        )\n        if (\n            last_maj_version != maj_version or\n            last_feat_version != feat_version\n        ):\n            last_maj_version = maj_version\n            last_feat_version = feat_version\n            tag_name = 'refs/tags/v%d.%d' % (maj_version, feat_version)\n            if ON_PYTHON3:\n                repo[str.encode(tag_name)] = commit\n            else:\n                repo[tag_name] = commit\n\n            result.append(\n                'v%d.%d -> %s' % (maj_version, feat_version, commit_sha)\n            )\n\n    return '\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of release notes for the given repo and optionally a base revision.", "response": "def get_releasenotes(repo_path, from_commit=None, bugtracker_url=''):\n    \"\"\"\n    Given a repo and optionally a base revision to start from, will return\n    a text suitable for the relase notes announcement, grouping the bugs, the\n    features and the api-breaking changes.\n\n    Args:\n        repo_path(str): Path to the code git repository.\n        from_commit(str): Refspec of the commit to start aggregating the\n            authors from.\n        bugtracker_url(str): URL to be prepended to any bug ids found in the\n            commits.\n\n    Returns:\n        str: Release notes text.\n    \"\"\"\n    repo = dulwich.repo.Repo(repo_path)\n    tags = get_tags(repo)\n    refs = get_refs(repo)\n    maj_version = 0\n    feat_version = 0\n    fix_version = 0\n    start_including = False\n    release_notes_per_major = OrderedDict()\n\n    cur_line = ''\n    if from_commit is None:\n        start_including = True\n\n    prev_version = (maj_version, feat_version, fix_version)\n    prev_version_str = '%s.%s.%s' % prev_version\n    bugs = []\n    features = []\n    api_break_changes = []\n\n    for commit_sha, children in reversed(\n        get_children_per_first_parent(repo_path).items()\n    ):\n        commit = get_repo_object(repo, commit_sha)\n        maj_version, feat_version, fix_version = get_version(\n            commit=commit,\n            tags=tags,\n            maj_version=maj_version,\n            feat_version=feat_version,\n            fix_version=fix_version,\n            children=children,\n        )\n        version = (maj_version, feat_version, fix_version)\n        version_str = '%s.%s.%s' % version\n\n        if (\n            start_including or commit_sha.startswith(from_commit) or\n            fuzzy_matches_refs(from_commit, refs.get(commit_sha, []))\n        ):\n            start_including = True\n\n            parent_commit_type = get_commit_type(\n                commit=commit,\n                children=children,\n                tags=tags,\n                prev_version=prev_version,\n            )\n            cur_line = pretty_commit(\n                commit=commit,\n                version=version_str,\n                bugtracker_url=bugtracker_url,\n                commit_type=parent_commit_type,\n            )\n            for child in children:\n                commit_type = get_commit_type(\n                    commit=commit,\n                    tags=tags,\n                    prev_version=prev_version,\n                )\n                cur_line += pretty_commit(\n                    commit=child,\n                    version=None,\n                    commit_type=commit_type,\n                    bugtracker_url=bugtracker_url,\n                )\n\n            if parent_commit_type == 'api_break':\n                release_notes_per_major[prev_version_str] = (\n                    api_break_changes,\n                    features,\n                    bugs,\n                )\n                bugs, features, api_break_changes = [], [], []\n                api_break_changes.append(cur_line)\n            elif parent_commit_type == 'feature':\n                features.append(cur_line)\n            else:\n                bugs.append(cur_line)\n\n        prev_version = version\n        prev_version_str = version_str\n\n    release_notes_per_major[prev_version_str] = (\n        api_break_changes,\n        features,\n        bugs,\n    )\n\n    releasenotes = ''\n    for major_version, lines in reversed(release_notes_per_major.items()):\n        api_break_changes, features, bugs = lines\n        releasenotes += u'''New changes for version %s\n=================================\n\nAPI Breaking changes\n--------------------\n%s\nNew features\n------------\n%s\nBugfixes and minor changes\n--------------------------\n%s\n\n''' % (\n                major_version,\n                (\n                    '\\n'.join(reversed(api_break_changes)) or\n                    'No new API breaking changes\\n'\n                ),\n                '\\n'.join(reversed(features)) or 'No new features\\n',\n                '\\n'.join(reversed(bugs)) or 'No new bugs\\n',\n            )\n\n    return releasenotes.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _weld_unary(array, weld_type, operation):\n    if weld_type not in {WeldFloat(), WeldDouble()}:\n        raise TypeError('Unary operation supported only on scalar f32 or f64')\n\n    obj_id, weld_obj = create_weld_object(array)\n    weld_template = 'map({array}, |e: {type}| {op}(e))'\n    weld_obj.weld_code = weld_template.format(array=obj_id, type=weld_type, op=operation)\n\n    return weld_obj", "response": "Returns the result of applying operation on each element in the array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert dict fields into objects where appropriate", "response": "def _update_fields_with_objects(self):\n        \"\"\" Convert dict fields into objects, where appropriate \"\"\"\n        # Update the photo target with photo objects\n        if self.target is not None:\n            if self.target_type == \"photo\":\n                self.target = Photo(self._client, self.target)\n            else:\n                raise NotImplementedError(\"Actions can only be assigned to \"\n                                          \"Photos\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef view(self, **kwds):\n        result = self._client.action.view(self, **kwds)\n        self._replace_fields(result.get_fields())\n        self._update_fields_with_objects()", "response": "This endpoint provides a full view of the contents of the action object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstream raw result for TTY - enabled container above API 1. 6", "response": "async def _stream_raw_result(self, res):\n        ''' Stream result for TTY-enabled container above API 1.6 '''\n        async with res.context as response:\n            response.raise_for_status()\n            async for out in response.content.iter_chunked(1):\n                yield out.decode()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compareBIM(args):\n    # Creating the CompareBIM options\n    class Dummy(object):\n        pass\n    compareBIM_args = Dummy()\n    compareBIM_args.before = args.bfile + \".bim\"\n    compareBIM_args.after = args.out + \".bim\"\n    compareBIM_args.out = args.out + \".removed_snps\"\n\n    try:\n        # Checking the arguments\n        CompareBIM.checkArgs(compareBIM_args)\n\n        # Reading the BIM files\n        beforeBIM = CompareBIM.readBIM(compareBIM_args.before)\n        afterBIM = CompareBIM.readBIM(compareBIM_args.after)\n\n        # Comparing the BIM files\n        CompareBIM.compareSNPs(beforeBIM, afterBIM, compareBIM_args.out)\n    except CompareBIM.ProgramError as e:\n        raise ProgramError(\"CompareBIM: \" + e.message)", "response": "Compare two BIM files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef runPlink(options):\n    # The plink command\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", options.bfile, \"--geno\",\n                    str(options.geno), \"--make-bed\", \"--out\", options.out]\n\n    output = None\n    try:\n        output = subprocess.check_output(plinkCommand,\n                                         stderr=subprocess.STDOUT, shell=False)\n    except subprocess.CalledProcessError:\n        msg = \"plink: couldn't run plink\"\n        raise ProgramError(msg)", "response": "Runs Plink with the geno option."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the multiplicon and segments files and returns a IadhoreData object.", "response": "def read(mfile, sfile):\n    \"\"\" Returns an IadhoreData object, constructed from the passed\n        i-ADHoRe multiplicon and segments output.\n\n        - mfile (str), location of multiplicons.txt\n        - sfile (str), location of segments.txt\n    \"\"\"\n    assert os.path.isfile(mfile), \"%s multiplicon file does not exist\"\n    assert os.path.isfile(sfile), \"%s segments file does not exist\"\n    return IadhoreData(mfile, sfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dbsetup(self):\n        self._dbconn = sqlite3.connect(self._db_file)\n        # Create table for multiplicons\n        sql = '''CREATE TABLE multiplicons\n                 (id, genome_x, list_x, parent, genome_y, list_y, level,\n                  number_of_anchorpoints, profile_length, begin_x, end_x,\n                  begin_y, end_y, is_redundant)'''\n        self._dbconn.execute(sql)\n        # Create table for multiplicons ('order' appears to be reserved)\n        sql = '''CREATE TABLE segments\n                 (id, multiplicon, genome, list, first, last, ord)'''\n        self._dbconn.execute(sql)\n        self._dbconn.commit()", "response": "Create the tables for the internal database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_multiplicons(self):\n        # Parse data with csv reader\n        reader = csv.reader(open(self._multiplicon_file, 'rU'),\n                            delimiter='\\t')\n        for row in reader:\n            if reader.line_num == 1:  # skip header\n                continue\n            # Add data to SQLite db\n            sql = '''INSERT INTO multiplicons\n                     (id, genome_x, list_x, parent, genome_y, list_y, level,\n                     number_of_anchorpoints, profile_length, begin_x, end_x,\n                     begin_y, end_y, is_redundant) VALUES\n                     (?,?,?,?,?,?,?,?,?,?,?,?,?,?)'''\n            self._dbconn.execute(sql, row)\n            # Add multiplicons to tree\n            m_id = int(row[0])\n            self._multiplicon_graph.add_node(m_id)\n            if len(row[3]):\n                self._multiplicon_graph.add_edge(int(row[3]), m_id)\n        self._dbconn.commit()", "response": "Read the multiplicon output file and parse into a tree using the multiplicon networkx and an SQLite database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the segment output file and parse into an SQLite database.", "response": "def _parse_segments(self):\n        \"\"\" Read the segment output file and parse into an SQLite database.\n        \"\"\"\n        reader = csv.reader(open(self._segment_file, 'rU'),\n                            delimiter='\\t')\n        for row in reader:\n            if reader.line_num == 1:  # skip header\n                continue\n            sql = '''INSERT INTO segments\n                     (id, multiplicon, genome, list, first, last, ord)\n                     VALUES (?,?,?,?,?,?,?)'''\n            self._dbconn.execute(sql, row)\n        self._dbconn.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator of the IDs of multiplicons found at leaves of the tree.", "response": "def get_multiplicon_leaves(self, redundant=False):\n        \"\"\" Return a generator of the IDs of multiplicons found at leaves\n            of the tree (i.e. from which no further multiplicons were derived).\n\n            Arguments:\n\n            o redundant - if true, report redundant multiplicons\n        \"\"\"\n        for node in self._multiplicon_graph.nodes():\n            if not len(self._multiplicon_graph.out_edges(node)):\n                if not self.is_redundant_multiplicon(node):\n                    yield node\n                elif redundant:\n                    yield node\n                else:\n                    continue\n            else:\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_multiplicon_seeds(self, redundant=False):\n        for node in self._multiplicon_graph.nodes():\n            if not len(self._multiplicon_graph.in_edges(node)):\n                if not self.is_redundant_multiplicon(node):\n                    yield node\n                elif redundant:\n                    yield node\n                else:\n                    continue\n            else:\n                continue", "response": "Returns a generator of the IDs of multiplicons that are initial\n            seeding pairs in level 2 multiplicons."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_multiplicon_intermediates(self, redundant=False):\n        for node in self._multiplicon_graph.nodes():\n            if len(self._multiplicon_graph.in_edges(node)) and \\\n               len(self._multiplicon_graph.out_edges(node)):\n                if not self.is_redundant_multiplicon(node):\n                    yield node\n                elif redundant:\n                    yield node\n                else:\n                    continue\n            else:\n                continue", "response": "Returns a generator of the IDs of multiplicons that are neither neither\n            seeding pairs nor leaves."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_multiplicon_properties(self, value):\n        sql = '''SELECT id, parent, level, number_of_anchorpoints,\n                         profile_length, is_redundant\n                   FROM multiplicons WHERE id=:id'''\n        cur = self._dbconn.cursor()\n        cur.execute(sql, {'id': str(value)})\n        result = cur.fetchone()\n        cur.close()\n        return {'id': int(result[0]),\n                'parent': int(result[1]) if len(result[1]) else None,\n                'level': int(result[2]),\n                'number_of_anchorpoints': int(result[3]),\n                'profile_length': int(result[4]),\n                'is_redundant': True if result[5] == '-1' else False,\n                'segments': self.get_multiplicon_segments(value)}", "response": "Returns a dictionary describing multiplicon properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary describing the genome segments that have the named multiplicon contribute to the named multiplicon.", "response": "def get_multiplicon_segments(self, value):\n        \"\"\" Return a dictionary describing the genome segments that\n            contribute to the named multiplicon, keyed by genome, with\n            (start feature, end feature) tuples.\n        \"\"\"\n        sql = '''SELECT genome, first, last FROM segments\n                   WHERE multiplicon=:mp'''\n        cur = self._dbconn.cursor()\n        cur.execute(sql, {'mp': str(value)})\n        result = cur.fetchall()\n        cur.close()\n        segdict = collections.defaultdict(tuple)\n        for genome, start, end in result:\n            segdict[genome] = (start, end)\n        return segdict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_multiplicons_at_level(self, level, redundant=False):\n        sql = '''SELECT id FROM multiplicons\n                   WHERE level=:level'''\n        cur = self._dbconn.cursor()\n        cur.execute(sql, {'level': str(level)})\n        result = [int(r[0]) for r in cur.fetchall()]\n        cur.close()\n        if redundant:\n            return result\n        else:\n            return [r for r in result if not self.is_redundant_multiplicon(r)]", "response": "Return a list of multiplicons at the requested level."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_redundant_multiplicon(self, value):\n        if not hasattr(self, '_redundant_multiplicon_cache'):\n            sql = '''SELECT id FROM multiplicons WHERE is_redundant=\"-1\"'''\n            cur = self._dbconn.cursor()\n            cur.execute(sql, {'id': str(value)})\n            result = [int(r[0]) for r in cur.fetchall()]\n            self._redundant_multiplicon_cache = set(result)\n        if value in self._redundant_multiplicon_cache:\n            return True\n        else:\n            return False", "response": "Returns True if the passed multiplicon ID is redundant False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, mfile=\"multiplicons.txt\", sfile=\"segments.txt\",\n              clobber=False):\n        \"\"\" Writes multiplicon and segment files to the named locations.\n\n            - mfile, (str) location for multiplicons file\n            - sfile, (str) location for segments file\n            - clobber, (Boolean) True if we overwrite target files\n        \"\"\"\n        if not clobber:\n            if os.path.isfile(mfile):\n                raise IOError(\"Multiplicon file %s already exists.\" % mfile)\n            if os.path.isfile(sfile):\n                raise IOError(\"Segments file %s already exists.\" % sfile)\n        self._write_multiplicons(mfile)\n        self._write_segments(sfile)", "response": "Writes multiplicon and segment files to the named locations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _write_multiplicons(self, filename):\n        # Column headers\n        mhead = '\\t'.join(['id', 'genome_x', 'list_x', 'parent', 'genome_y',\n                           'list_y', 'level', 'number_of_anchorpoints',\n                           'profile_length', 'begin_x', 'end_x', 'begin_y',\n                           'end_y', 'is_redundant'])\n        with open(filename, 'w') as fhandle:\n            fhandle.write(mhead + '\\n')\n            for mrow in self.multiplicons:\n                fhandle.write('\\t'.join([str(e) for e in mrow]) + '\\n')", "response": "Write multiplicons to file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite segments to file.", "response": "def _write_segments(self, filename):\n        \"\"\" Write segments to file.\n\n            - filename, (str) location of output file\n        \"\"\"\n        # Column headers\n        shead = '\\t'.join(['id', 'multiplicon', 'genome', 'list', 'first',\n                           'last', 'order'])\n        with open(filename, 'w') as fhandle:\n            fhandle.write(shead + '\\n')\n            for mrow in self.segments:\n                fhandle.write('\\t'.join([str(e) for e in mrow]) + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multiplicons(self):\n        sql = '''SELECT * FROM multiplicons'''\n        cur = self._dbconn.cursor()\n        cur.execute(sql)\n        data = [r for r in cur.fetchall()]\n        cur.close()\n        return data", "response": "Returns a list of multiplicon tables from SQLite database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compareSNPs(before, after, outFileName):\n    # First, check that \"before\" is larger than \"after\"\n    if len(after) > len(before):\n        msg = \"there are more SNPs after than before\"\n        raise ProgramError(msg)\n\n    # Checks that all the SNPs \"after\" are in \"before\"\n    if not (after <= before):\n        msg = \"some after SNPs are not in before\"\n        raise ProgramError(msg)\n\n    # Printing the SNPs\n    try:\n        with open(outFileName, \"w\") as outputFile:\n            differences = before - after\n            if len(differences) > 0:\n                print >>outputFile, \"\\n\".join(differences)\n    except IOError:\n        msg = \"%(outFileName)s: can't write to file\" % locals()\n        raise ProgramError(msg)", "response": "Compares two set of SNPs and writes them to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a Plink BIM file and returns a set of SNPs.", "response": "def readBIM(fileName):\n    \"\"\"Reads a BIM file.\n\n    :param fileName: the name of the BIM file to read.\n\n    :type fileName: str\n\n    :returns: the set of markers in the BIM file.\n\n    Reads a Plink BIM file and extract the name of the markers. There is one\n    marker per line, and the name of the marker is in the second column. There\n    is no header in the BIM file.\n\n    \"\"\"\n    # Reading the first BIM file\n    snps = set()\n    with open(fileName, \"r\") as inputFile:\n        for line in inputFile:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            snpName = row[1]\n            snps.add(snpName)\n\n    return snps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the arguments and options.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Check the \"before\" file\n    if not args.before.endswith(\".bim\"):\n        msg = \"%s: not a BIM file (extension must be .bim)\" % args.before\n        raise ProgramError(msg)\n    elif not os.path.isfile(args.before):\n        msg = \"%s: no such file\" % args.before\n        raise ProgramError(msg)\n\n    # Check the \"after\" file\n    if not args.after.endswith(\".bim\"):\n        msg = \"%s: not a BIM file (extension must be .bim)\" % args.after\n        raise ProgramError(msg)\n    elif not os.path.isfile(args.after):\n        msg = \"%s: no such file\" % args.after\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an attribute to an object", "response": "def add_attr(self, name, value):\n        \"\"\"Add an attribute to an ``Block`` object\"\"\"\n        setattr(self, name, value)\n        self.attrs.append(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ids(self):\n        assert self.name == \"Materials\"\n        ids = list()\n        for attr in self.attrs:\n            attr_obj = getattr(self, attr)\n            if hasattr(attr_obj, 'Id'):\n                ids.append(getattr(attr_obj, 'Id'))\n        return ids", "response": "Convenience method to get the ids for Materials present"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_file(cls, fn, *args, **kwargs):\n        return AmiraHeader(get_parsed_data(fn, *args, **kwargs))", "response": "Constructor to build an AmiraHeader object from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_version():\n    try:\n        # Try with the package manager, if present\n        from pkg_resources import resource_string\n        return resource_string(__name__, \"VERSION.txt\").decode('utf8').strip()\n    except Exception:\n        # If the package manager is not present, try reading the file\n        version = os.path.join(os.path.dirname(__file__), \"VERSION.txt\")\n        with open(version, \"r\") as f:\n            return f.readlines()[0].strip()", "response": "Returns the version of formic.\n    This method retrieves the version from VERSION. txt and it should be\n    exactly the same as the version retrieved from the package manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbreak a path to a directory into a tuple consisting of the drive and list - of - folders.", "response": "def get_path_components(directory):\n    \"\"\"Breaks a path to a directory into a (drive, list-of-folders) tuple\n\n    :param directory:\n    :return: a tuple consisting of the drive (if any) and an ordered list of\n             folder names\n    \"\"\"\n    drive, dirs = os.path.splitdrive(directory)\n    folders = []\n    previous = \"\"\n    while dirs != previous and dirs != \"\":\n        previous = dirs\n        dirs, folder = os.path.split(dirs)\n        if folder != \"\":\n            folders.append(folder)\n    folders.reverse()\n    return drive, folders"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reconstitute_path(drive, folders):\n    reconstituted = os.path.join(drive, os.path.sep, *folders)\n    return reconstituted", "response": "Reverts a tuple from get_path_components into a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(pattern, casesensitive=True):\n        casesensitive = determine_casesensitive(casesensitive)\n        if \"?\" in pattern or \"*\" in pattern:\n            return FNMatcher(pattern, casesensitive)\n        else:\n            return ConstantMatcher(pattern, casesensitive)", "response": "Factory for : class:`Matcher` instances ; returns a : class:`Matcher` suitable for matching the supplied pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the pattern matches the string", "response": "def match(self, string):\n        \"\"\"Returns True if the pattern matches the string\"\"\"\n        if self.casesensitive:\n            return fnmatch.fnmatch(string, self.pattern)\n        else:\n            return fnmatch.fnmatch(string.lower(), self.pattern.lower())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match(self, string):\n        if self.casesensitive:\n            return self.pattern == os.path.normcase(string)\n        else:\n            return self.pattern.lower() == os.path.normcase(string).lower()", "response": "Returns True if the argument matches the constant."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match_iter(self, path_elements, start_at):\n        if self.length == 1:\n            return self._match_iter_single(path_elements, start_at)\n        else:\n            return self._match_iter_generic(path_elements, start_at)", "response": "A generator that searches over path_elements starting from start_at yielding for each match."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _simplify(elements):\n        simplified = []\n        previous = None\n        for element in elements:\n            if element == \"..\":\n                raise FormicError(\"Invalid glob:\"\n                                  \" Cannot have '..' in a glob: {0}\".format(\n                                      \"/\".join(elements)))\n            elif element == \".\":\n                # . in a path does not do anything\n                pass\n            elif element == \"**\" and previous == \"**\":\n                # Remove repeated \"**\"s\n                pass\n            else:\n                simplified.append(os.path.normcase(element))\n                previous = element\n\n        if simplified[-1] == \"\":\n            # Trailing slash shorthand for /**\n            simplified[-1] = \"**\"\n\n        # Ensure the pattern either:\n        #  * Starts with a \"**\", or\n        #  * Starts with the first real element of the glob\n        if simplified[0] == \"\":\n            # \"\" means the pattern started with a slash.\n            del simplified[0]\n        else:\n            if simplified[0] != \"**\":\n                simplified.insert(0, \"**\")\n\n        return simplified", "response": "Simplifies and normalizes the list of elements removing redundant and repeated elements and normalising upper case\n            so case sensitivity is resolved here."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match_directory(self, path_elements):\n\n        def match_recurse(is_start, sections, path_elements, location):\n            \"\"\"A private function for implementing the recursive search.\n\n            The function takes the first section from sections and tries to\n            match this against the elements in path_elements, starting from\n            the location'th element in that list.\n\n            If sections is empty, this is taken to mean all sections have\n            been previously matched, therefore a match has been found.\n\n            * is_start: True if this is the call starting the recursion. False if\n              this call is recursing\n            * sections: A list of the remaining sections (sections not yet matched)\n            * path_elements: A list of directory names, each element being a single directory\n            * location: index into path_elements for where the search should start\n            \"\"\"\n            if sections:\n                section = sections[0]\n                any_match = False\n                for end in section.match_iter(path_elements, location):\n                    any_match = True\n                    match = match_recurse(False, sections[1:], path_elements, end)\n                    if match | MatchType.MATCH:\n                        return match\n\n                # No match found\n                if is_start and self.bound_start and not any_match:\n                    # This this is the start of the recursion AND the pattern\n                    # is bound to the start of the path (\"/start/**\") AND this\n                    # did not match, then no subdirectories are possible either\n\n                    if len(path_elements) >= len(section.elements):\n                        return MatchType.NO_MATCH_NO_SUBDIRECTORIES\n                    else:\n                        # Optimization: Don't search subdirectories when\n                        #  i) we have an fixed start to the pattern, eg \"/Users/myuser/**\"\n                        #  ii) We have a path not matching the first, anchored, section, eg \"/usr\" or \"/Users/another\"\n                        # Need to check whether the last path element matches the corresponding element in section\n                        # If it does, return NO_MATCH (it's incomplete)\n                        # If, however, the element's don't match, then no further match is possible,\n                        # So return NO_MATCH_NO_SUBDIRECTORIES\n                        if section.length > len(path_elements) > 0:\n                            if not section.elements[len(path_elements) - 1].match(\n                                                    path_elements[-1]):\n                                return MatchType.NO_MATCH_NO_SUBDIRECTORIES\n                        return MatchType.NO_MATCH\n                else:\n                    return MatchType.NO_MATCH\n            else:\n                # Termination of the recursion after FINDING the match.\n                if len(self.sections) == 1 and self.bound_start and self.bound_end:\n                    # If this pattern is of the form \"/test/*\" it matches\n                    # just THIS directory and no subdirectories\n                    return MatchType.MATCH_BUT_NO_SUBDIRECTORIES\n                elif self.bound_end:\n                    # \"**/test/*\" matches just this directory\n                    # and allows subdirectories to also match\n                    return MatchType.MATCH\n                else:\n                    # If the pattern is not bound to the end of the path (eg\n                    # NOT \"**/term/**\") the pattern matches all subdirectories\n                    return MatchType.MATCH_ALL_SUBDIRECTORIES\n            # End of: def match_recurse(is_start, sections, path_elements, location):\n\n        if self.sections:\n            return match_recurse(True, self.sections, path_elements, 0)\n        else:\n            # Catches directory-less patterns like \"*.py\" and \"/*.py\".\n            if self.bound_start:\n                if len(path_elements) == 0:\n                    # Eg \"*/*.py\" in the root directory\n                    return MatchType.MATCH_BUT_NO_SUBDIRECTORIES\n                else:\n                    # Eg \"/*.py\" meets directory \"/test/\" - nothing happening\n                    return MatchType.NO_MATCH_NO_SUBDIRECTORIES\n            else:\n                # Eg \"**/*.py\" - match all directories\n                return MatchType.MATCH_ALL_SUBDIRECTORIES", "response": "Returns a list of path_elements elements that match the pattern."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_files(self, matched, unmatched):\n        this_match = set(self.file_filter(unmatched))\n        matched |= this_match\n        unmatched -= this_match", "response": "Moves all matching files from the set matched to the set unmatched."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing a function for __str__ and __repr__ to use", "response": "def _to_string(self):\n        \"\"\"Implemented a function for __str__ and __repr__ to use, but\n        which prevents infinite recursion when migrating to Python 3\"\"\"\n        if self.sections:\n            start = \"/\" if self.bound_start else \"**/\"\n            sections = \"/**/\".join(str(section) for section in self.sections)\n            end = \"\" if self.bound_end else \"/**\"\n        else:\n            start = \"\"\n            sections = \"\"\n            end = \"\" if self.bound_end else \"**\"\n        return \"{0}{1}{2}/{3}\".format(start, sections, end, str(self.file_pattern))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle lazy evaluation of self. all_files", "response": "def _compute_all_files(self):\n        \"\"\"Handles lazy evaluation of self.all_files\"\"\"\n        self._all_files = any(pat.all_files() for pat in self.patterns)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append(self, pattern):\n        assert isinstance(pattern, Pattern)\n        self.patterns.append(pattern)\n        if self._all_files is not None:\n            self._all_files = self._all_files or pattern.all_files()", "response": "Adds a pattern to the set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextend a : class:`PatternSet with addition patterns*", "response": "def extend(self, patterns):\n        \"\"\"Extend a :class:`PatternSet` with addition *patterns*\n\n        *patterns* can either be:\n\n        * A single :class:`Pattern`\n        * Another :class:`PatternSet` or\n        * A list of :class:`Pattern` instances\"\"\"\n        assert patterns is not None\n        if isinstance(patterns, Pattern):\n            self.append(patterns)\n            return\n\n        if isinstance(patterns, PatternSet):\n            patterns = patterns.patterns\n\n        assert all(isinstance(pat, Pattern) for pat in patterns)\n        self.patterns.extend(patterns)\n        self._all_files = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a pattern from the set.", "response": "def remove(self, pattern):\n        \"\"\"Remove a :class:`Pattern` from the :class:`PatternSet`\"\"\"\n        assert isinstance(pattern, Pattern)\n        self.patterns.remove(pattern)\n        self._all_files = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply the include and exclude filters to those files in unmatched and move them into the matched set.", "response": "def match_files(self, matched, unmatched):\n        \"\"\"Apply the include and exclude filters to those files in *unmatched*,\n        moving those that are included, but not excluded, into the *matched*\n        set.\n\n        Both *matched* and *unmatched* are sets of unqualified file names.\"\"\"\n        for pattern in self.iter():\n            pattern.match_files(matched, unmatched)\n            if not unmatched:\n                # Optimization: If we have matched all files already\n                # simply return at this point - nothing else to do\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter(self):\n        if self.patterns:\n            patterns = list(self.patterns)\n            for pattern in patterns:\n                yield pattern", "response": "An iteration generator that yields the pattern set for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the parent of the current instance of a FileSetState.", "response": "def _find_parent(self, path_elements):\n        \"\"\"Recurse up the tree of FileSetStates until we find a parent, i.e.\n        one whose path_elements member is the start of the path_element\n        argument\"\"\"\n        if not self.path_elements:\n            # Automatically terminate on root\n            return self\n        elif self.path_elements == path_elements[0:len(self.path_elements)]:\n            return self\n        else:\n            return self.parent._find_parent(path_elements)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator that returns all the PatternSets that match this directory and all its parents.", "response": "def _matching_pattern_sets(self):\n        \"\"\"Returns an iterator containing all PatternSets that match this\n        directory.\n\n        This is build by chaining the this-directory specific PatternSet\n        (self.matched_and_subdir), the local (non-inheriting) PatternSet\n        (self.matched_no_subdir) with all the inherited PatternSets\n        that match this directory and all its parents (self.match_inherit).\"\"\"\n        gather = []\n        if self.matched_and_subdir:\n            gather.append(self.matched_and_subdir.iter())\n            gather.append(self.matched_no_subdir.iter())\n        ref = self\n        while ref is not None:\n            if ref.matched_inherit:\n                gather.append(ref.matched_inherit.iter())\n            if ref.parent_has_patterns:\n                ref = ref.parent\n            else:\n                ref = None\n        return chain.from_iterable(gather)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a set of files in this directory returns all the files that match the pattern sets which match this directory.", "response": "def match(self, files):\n        \"\"\"Given a set of files in this directory, returns all the files that\n        match the :class:`Pattern` instances which match this directory.\"\"\"\n        if not files:\n            return set()\n\n        if (self.matched_inherit.all_files()\n                or self.matched_and_subdir.all_files()\n                or self.matched_no_subdir.all_files()):\n            # Optimization: one of the matched patterns matches everything\n            # So simply return it\n            return set(files)\n\n        unmatched = set(files)\n        matched = set()\n        for pattern_set in self._matching_pattern_sets():\n            pattern_set.match_files(matched, unmatched)\n            if not unmatched:\n                # Optimization: If we have matched all files already\n                # simply return at this point - nothing else to do\n                break\n\n        return matched"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if there are no possible matches for any subdirectories.", "response": "def no_possible_matches_in_subdirs(self):\n        \"\"\"Returns True if there are no possible matches for any\n        subdirectories of this :class:`FileSetState`.\n\n        When this :class:FileSetState is used for an 'include', a return of\n        `True` means we can exclude all subdirectories.\"\"\"\n        return (not self.parent_has_patterns and self.matched_inherit.empty()\n                and self.matched_and_subdir.empty() and self.unmatched.empty())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreceives the argument from the constructor and normalizes it into a list of Pattern objects.", "response": "def _preprocess(argument, casesensitive):\n        \"\"\"Receives the argument (from the constructor), and normalizes it\n        into a list of Pattern objects.\"\"\"\n        pattern_set = PatternSet()\n        if argument is not None:\n            if isinstance(argument, STRING_TYPES):\n                argument = [argument, ]\n\n            for glob in argument:\n                if isinstance(glob, str):\n                    patterns = Pattern.create(glob, casesensitive)\n                    pattern_set.extend(patterns)\n\n                elif isinstance(glob, Pattern):\n                    pattern_set.append(glob)\n\n        return pattern_set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_directory(self):\n        directory = self.directory if self.directory else os.getcwd()\n        drive, folders = get_path_components(directory)\n        return reconstitute_path(drive, folders)", "response": "Returns the directory in which the FileSet will be run."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _receive(self, root, directory, dirs, files, include, exclude):\n\n        self._received += 1\n\n        if not self.symlinks:\n            where = root + os.path.sep + directory + os.path.sep\n            files = [\n                file_name for file_name in files\n                if not os.path.islink(where + file_name)\n            ]\n\n        include = FileSetState(\"Include\", directory, include, None\n                               if include else self.include)\n        exclude = FileSetState(\"Exclude\", directory, exclude, None\n                               if exclude else self.exclude)\n\n        if exclude.matches_all_files_all_subdirs():\n            # Exclude everything and do no traverse any subdirectories\n            del dirs[0:]\n            matched = set()\n        else:\n            if include.no_possible_matches_in_subdirs():\n                # Do no traverse any subdirectories\n                del dirs[0:]\n            matched = include.match(set(files))\n            matched -= exclude.match(matched)\n\n        return matched, include, exclude", "response": "Internal function processing each yield from os. walk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef files(self):\n        directory = self.get_directory()\n        prefix = len(directory) + (0 if is_root(directory) else 1)\n\n        include = None\n        exclude = None\n        for root, dirs, files in self.walk_func(directory, followlinks=self.symlinks):\n            # Remove the constant part of the path inluding the first path sep\n            rel_dir_name = root[prefix:]\n            matched, include, exclude = self._receive(\n                directory, rel_dir_name, dirs, files, include, exclude)\n            for file_name in matched:\n                yield rel_dir_name, file_name", "response": "A generator function for iterating over the individual files of\n        the FileSet."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qualified_files(self, absolute=True):\n        prefix = self.get_directory() if absolute else \".\"\n        for rel_dir_name, file_name in self.files():\n            yield os.path.join(prefix, rel_dir_name, file_name)", "response": "An alternative generator that yields files rather than directories."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef order_qc_dir(dirnames):\n    return sorted(\n        dirnames, key=lambda dn: time.strptime(\n            os.path.basename(dn.rstrip(\"/\"))[14:],\n            \"%Y-%m-%d_%H.%M.%S\",\n        )\n    )", "response": "Order the QC directory names according to their date."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges the required files from each of the directories.", "response": "def merge_required_files(dirnames, out_dir):\n    \"\"\"Merges the required files from each of the directories.\n\n    :param dirnames: the list of directories to merge data from.\n    :param out_dir: the name of the output directory.\n\n    :type dirnames: list\n    :type out_dir: str\n\n    \"\"\"\n    # The list of files to merge\n    fn_to_merge = (\"steps_summary.tex\", \"excluded_markers.txt\",\n                   \"excluded_samples.txt\")\n\n    # Merging the files\n    for fn in fn_to_merge:\n        o_fn = os.path.join(out_dir, fn)\n        with open(o_fn, \"w\") as o_file:\n            for dn in dirnames:\n                i_fn = os.path.join(dn, fn)\n                with open(i_fn, \"r\") as i_file:\n                    o_file.write(i_file.read())\n\n    # Merging the result summary file\n    o_fn = os.path.join(out_dir, \"results_summary.txt\")\n    with open(o_fn, \"w\") as o_file:\n        for i, dn in enumerate(dirnames):\n            i_fn = os.path.join(dn, \"results_summary.txt\")\n            with open(i_fn, \"r\") as i_file:\n                if i != 0:\n                    # We skip the first 4 lines (file descriptions)\n                    [i_file.readline() for i in range(4)]\n                o_file.write(i_file.read())\n\n    # Merging the graphic paths file\n    graphic_paths = set()\n    for dn in dirnames:\n        fn = os.path.join(dn, \"graphic_paths.txt\")\n        if os.path.isfile(fn):\n            with open(fn, \"r\") as i_file:\n                graphic_paths.update({\n                    os.path.join(dn, path)\n                    for path in i_file.read().splitlines()\n                })\n    if len(graphic_paths) > 0:\n        with open(os.path.join(out_dir, \"graphic_paths.txt\"), \"w\") as o_file:\n            for path in sorted(graphic_paths):\n                print >>o_file, os.path.relpath(path, out_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_final_numbers(filename, out_dir):\n    # Copying the file\n    shutil.copy(filename, out_dir)\n\n    # Reading the number of markers and samples\n    nb_samples = None\n    nb_markers = None\n    with open(filename, \"r\") as i_file:\n        for line in i_file:\n            row = line.rstrip(\"\\r\\n\").split(\"\\t\")\n            if len(row) == 1:\n                continue\n            path, ext = os.path.splitext(row[0])\n            if ext in {\".bim\", \".tped\", \".map\"}:\n                nb_markers = row[1]\n            elif ext in {\".fam\", \".ped\", \".tfam\"}:\n                nb_samples = row[1]\n\n    assert nb_samples\n    assert nb_markers\n\n    return nb_markers, nb_samples", "response": "Copy the final_files file and get the number of markers and samples."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_summary_files(dirnames):\n    # A useful regular expression to get step number in the current directory\n    step_nb_re = re.compile(r\"^([0-9]+)_\\S+\")\n\n    # The final list of summary files\n    final_summary_files = []\n\n    # For each of the directory\n    for dn in dirnames:\n        # Getting the step directories\n        step_dir = [\n            n for n in os.listdir(dn)\n            if os.path.isdir(os.path.join(dn, n)) and step_nb_re.match(n)\n        ]\n\n        # Sorting the step directories\n        step_dir.sort(key=lambda x: int(step_nb_re.match(x).group(1)))\n\n        # Getting the name of the summary file for each of the step directory\n        step_summary_files = [\n            glob(os.path.join(dn, sn, \"*.summary.tex\")) for sn in step_dir\n        ]\n\n        # Checking we have only one summary file\n        for summary_file in step_summary_files:\n            if len(summary_file) > 1:\n                raise ProgramError(\"{}: multiple summary files\".format(\n                    os.path.join(dn, sn),\n                ))\n\n            if not summary_file:\n                raise ProgramError(\"{}: missing summary file\".format(\n                    os.apth.join(dn, sn),\n                ))\n\n        final_summary_files.extend(i[0] for i in step_summary_files)\n\n    return [os.path.abspath(fn) for fn in final_summary_files]", "response": "Gets the TeX summary files for each test in the specified list of directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the report for the given latex_summaries nb_markers and nb_samples.", "response": "def generate_report(out_dir, latex_summaries, nb_markers, nb_samples, options):\n    \"\"\"Generates the report.\n\n    :param out_dir: the output directory.\n    :param latex_summaries: the list of LaTeX summaries.\n    :param nb_markers: the final number of markers.\n    :param nb_samples: the final number of samples.\n    :param options: the list of options.\n\n    :type out_dir: str\n    :type latex_summaries: list\n    :type nb_markers: str\n    :type nb_samples: str\n    :type options: argparse.Namespace\n\n    \"\"\"\n    # Getting the graphic paths file\n    graphic_paths_fn = None\n    if os.path.isfile(os.path.join(out_dir, \"graphic_paths.txt\")):\n        graphic_paths_fn = os.path.join(out_dir, \"graphic_paths.txt\")\n\n    # We create the automatic report\n    report_name = os.path.join(out_dir, \"merged_report.tex\")\n    auto_report.create_report(\n        out_dir,\n        report_name,\n        project_name=options.report_number,\n        steps_filename=os.path.join(out_dir, \"steps_summary.tex\"),\n        summaries=latex_summaries,\n        background=options.report_background,\n        summary_fn=os.path.join(out_dir, \"results_summary.txt\"),\n        report_title=options.report_title,\n        report_author=options.report_author,\n        initial_files=os.path.join(out_dir, \"initial_files.txt\"),\n        final_files=os.path.join(out_dir, \"final_files.txt\"),\n        final_nb_markers=nb_markers,\n        final_nb_samples=nb_samples,\n        plink_version=get_plink_version(),\n        graphic_paths_fn=graphic_paths_fn,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds custom options to a parser.", "response": "def add_custom_options(parser):\n    \"\"\"Adds custom options to a parser.\n\n    :param parser: the parser to which to add options.\n\n    :type parser: argparse.ArgumentParser\n\n    \"\"\"\n    parser.add_argument(\"--report-title\", type=str, metavar=\"TITLE\",\n                        default=\"Genetic Data Clean Up\",\n                        help=\"The report title. [default: %(default)s]\")\n    parser.add_argument(\"--report-author\", type=str, metavar=\"AUTHOR\",\n                        default=\"pyGenClean\",\n                        help=\"The current project number. \"\n                             \"[default: %(default)s]\")\n    parser.add_argument(\"--report-number\", type=str, metavar=\"NUMBER\",\n                        default=\"Simple Project\",\n                        help=\"The current project author. \"\n                             \"[default: %(default)s]\")\n    parser.add_argument(\"--report-background\", type=str, metavar=\"BACKGROUND\",\n                        default=\"The aim of this project is to perform data \"\n                                \"QC prior to genetic analysis.\",\n                        help=\"Text of file containing the background section \"\n                             \"of the report.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_related_data(x, y, code, ylabel, fileName, options):\n    import matplotlib as mpl\n    if mpl.get_backend() != \"agg\":\n        mpl.use(\"Agg\")\n    import matplotlib.pyplot as plt\n    plt.ioff()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    # Setting the title, the X and Y label\n    ax.set_title((r\"%d pairs with $IBS2^\\ast_{ratio} >$ \"\n                  r\"%f\" % (len(code), options.ibs2_ratio)))\n    ax.set_xlabel(r\"$IBS2^\\ast_{ratio}$\")\n    ax.set_ylabel(ylabel)\n\n    # Plotting the data (there are 5 error codes)\n    c5, = ax.plot(x[code == \"5\"], y[code == \"5\"], \"o\", ms=3, mec=\"#669900\",\n                  mfc=\"#669900\")\n    c1, = ax.plot(x[code == \"1\"], y[code == \"1\"], \"o\", ms=3, mec=\"#CC0000\",\n                  mfc=\"#CC0000\")\n    c2, = ax.plot(x[code == \"2\"], y[code == \"2\"], \"o\", ms=3, mec=\"#0099CC\",\n                  mfc=\"#0099CC\")\n    c3, = ax.plot(x[code == \"3\"], y[code == \"3\"], \"o\", ms=3, mec=\"#FF8800\",\n                  mfc=\"#FF8800\")\n    c4, = ax.plot(x[code == \"4\"], y[code == \"4\"], \"o\", ms=3, mec=\"#9933CC\",\n                  mfc=\"#9933CC\")\n\n    # The legend\n    prop = mpl.font_manager.FontProperties(size=8)\n    leg = ax.legend([c1, c2, c3, c4, c5],\n                    [\"Full sibs (n={})\".format(np.sum(code == \"1\")),\n                     (\"Half sibs, grand-parent-child or uncle-nephew \"\n                      \"(n={})\".format(np.sum(code == \"2\"))),\n                     \"Parent-child (n={})\".format(np.sum(code == \"3\")),\n                     (\"Twins or duplicated samples \"\n                      \"(n={})\".format(np.sum(code == \"4\"))),\n                     \"Unknown (n={})\".format(np.sum(code == \"5\"))],\n                    loc=\"best\", numpoints=1, fancybox=True, prop=prop)\n    leg.get_frame().set_alpha(0.5)\n\n    # Setting the limits\n    ax.set_xlim((options.ibs2_ratio - 0.01, 1.01))\n    ax.set_ylim((-0.01, 1.01))\n\n    # Modifying the spines\n    ax.xaxis.set_ticks_position(\"bottom\")\n    ax.yaxis.set_ticks_position(\"left\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n\n    # Saving the figure\n    plt.savefig(fileName)", "response": "Plot related data for each sample pair in the order of the sample pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts related individuals according to the IBS2 ratio.", "response": "def extractRelatedIndividuals(fileName, outPrefix, ibs2_ratio_threshold):\n    \"\"\"Extract related individuals according IBS2* ratio.\n\n    :param fileName: the name of the input file.\n    :param outPrefix: the prefix of the output files.\n    :param ibs2_ratio_threshold: the ibs2 ratio threshold (tells if sample pair\n                                 is related or not).\n\n    :type fileName: str\n    :type outPrefix: str\n    :type ibs2_ratio_threshold: float\n\n    :returns: a :py:class:`numpy.recarray` data set containing (for each\n              related sample pair) the ``ibs2 ratio``, ``Z1``, ``Z2`` and the\n              type of relatedness.\n\n    Reads a ``genome`` file (provided by :py:func:`runGenome`) and extract\n    related sample pairs according to ``IBS2 ratio``.\n\n    A ``genome`` file contains at least the following information for each\n    sample pair:\n\n    * **FID1:** the family ID of the first sample in the pair.\n    * **IID1:** the individual ID of the first sample in the pair.\n    * **FID2:** the family ID of the second sample in the pair.\n    * **IID2:** the individual ID of the second sample in the pair.\n    * **Z0:** the probability that :math:`IBD = 0`.\n    * **Z1:** the probability that :math:`IBD = 1`.\n    * **Z2:** the probability that :math:`IBD = 2`.\n    * **HOMHOM:** the number of :math:`IBS = 0` SNP pairs used in ``PPC`` test.\n    * **HETHET:** the number of :math:`IBS = 2` het/het SNP pairs in ``PPC``\n      test.\n\n    The ``IBS2 ratio`` is computed using the following formula:\n\n    .. math::\n        \\\\textrm{IBS2 ratio} = \\\\frac{\\\\textrm{HETHET}}\n                                     {\\\\textrm{HOMHOM} + \\\\textrm{HETHET}}\n\n    If the ``IBS2 ratio`` is higher than the threshold, the samples in the pair\n    are related. The following values help in finding the relatedness of the\n    sample pair.\n\n    +---------------------------------------+-----------------------+------+\n    |           Values                      |        Relation       | Code |\n    +=======================================+=======================+======+\n    | :math:`0.17 \\\\leq z_0 \\\\leq 0.33` and   | Full-sibs             | 1    |\n    | :math:`0.40 \\\\leq z_1 \\\\leq 0.60`       |                       |      |\n    +---------------------------------------+-----------------------+------+\n    | :math:`0.40 \\\\leq z_0 \\\\leq 0.60` and   | Half-sibs or          | 2    |\n    | :math:`0.40 \\\\leq z_1 \\\\leq 0.60`       | Grand-parent-Child or |      |\n    |                                       | Uncle-Nephew          |      |\n    +---------------------------------------+-----------------------+------+\n    | :math:`z_0 \\\\leq 0.05` and             | Parent-Child          | 3    |\n    | :math:`z_1 \\\\geq 0.95` and             |                       |      |\n    | :math:`z_2 \\\\leq 0.05`                 |                       |      |\n    +---------------------------------------+-----------------------+------+\n    | :math:`z_0 \\\\leq 0.05` and             | Twins or Duplicated   | 4    |\n    | :math:`z_1 \\\\leq 0.05` and             | samples               |      |\n    | :math:`z_2 \\\\geq 0.95`                 |                       |      |\n    +---------------------------------------+-----------------------+------+\n\n    \"\"\"\n    # The output file\n    outputFile = None\n    try:\n        outputFile = open(outPrefix + \".related_individuals\", \"w\")\n    except IOError:\n        msg = \"%(outPrefix)s.related_individuals: can't write file\" % locals()\n        raise ProgramError(msg)\n\n    # The input file\n    inputFile = None\n    try:\n        if fileName.endswith(\".gz\"):\n            inputFile = gzip.open(fileName, 'rb')\n        else:\n            inputFile = open(fileName, 'r')\n    except IOError:\n        msg = \"{}: no such file\".format(fileName)\n        raise ProgramError(msg)\n\n    headerIndex = None\n    data = []\n    for i, line in enumerate(inputFile):\n        row = createRowFromPlinkSpacedOutput(line)\n\n        if i == 0:\n            # This is the header\n            headerIndex = dict([(colName, j) for j, colName in enumerate(row)])\n\n            # Checking columns\n            for columnName in [\"FID1\", \"IID1\", \"FID2\", \"IID2\", \"Z0\", \"Z1\",\n                               \"Z2\", \"HOMHOM\", \"HETHET\"]:\n                if columnName not in headerIndex:\n                    msg = \"{}: no culumn named {}\".format(fileName, columnName)\n                    raise ProgramError(msg)\n\n            # Writing header\n            print >>outputFile, \"\\t\".join(row + [\"IBS2_ratio\", \"status\",\n                                                 \"code\"])\n\n        else:\n            # This is data\n            homhom = row[headerIndex[\"HOMHOM\"]]\n            hethet = row[headerIndex[\"HETHET\"]]\n            try:\n                homhom = float(homhom)\n                hethet = float(hethet)\n            except ValueError:\n                msg = \"{}: invalid HOMHOM or HETHET\".format(fileName)\n                raise ProgramError(float)\n\n            # Computing IBS2* ratio\n            ibs2_ratio = hethet / (homhom + hethet)\n\n            if ibs2_ratio > ibs2_ratio_threshold:\n                # Those pairs might be related\n                # Finding the status\n                status = \"unknown\"\n                code = \"5\"\n                z0 = row[headerIndex[\"Z0\"]]\n                z1 = row[headerIndex[\"Z1\"]]\n                z2 = row[headerIndex[\"Z2\"]]\n                try:\n                    z0 = float(z0)\n                    z1 = float(z1)\n                    z2 = float(z2)\n                except ValueError:\n                    msg = \"{}: invalid value for Z0, Z1 or Z2\".format(fileName)\n                    raise ProgramError(msg)\n\n                if (z0 >= 0.17 and z0 <= 0.33) and (z1 >= 0.40 and z1 <= 0.60):\n                    # Full sibs\n                    status = \"full-sibs\"\n                    code = \"1\"\n\n                elif (z0 >= 0.4 and z0 <= 0.6) and (z1 >= 0.4 and z1 <= 0.6):\n                    # half sibs, grand-parent child, uncle nephew\n                    status = \";\".join([\"half-sibs\", \"grand-parent-child\",\n                                       \"uncle-nephew\"])\n                    code = \"2\"\n\n                elif (z0 <= 0.05) and (z1 >= 0.95) and (z2 <= 0.05):\n                    # parent child\n                    status = \"parent-child\"\n                    code = \"3\"\n\n                elif (z0 <= 0.05) and (z1 <= 0.05) and (z2 >= 0.95):\n                    # twin\n                    status = \"twins\"\n                    code = \"4\"\n\n                # Printing to file\n                print >>outputFile, \"\\t\".join(row + [str(ibs2_ratio), status,\n                                                     code])\n                data.append((ibs2_ratio, z1, z2, code))\n\n    # Closing the output and input files\n    inputFile.close()\n    outputFile.close()\n\n    # Merging the related individuals\n    merge_related_samples(outPrefix + \".related_individuals\", outPrefix, False)\n\n    # If there are no related samples, we return nothing\n    if len(data) == 0:\n        return None\n\n    # Creating the numpy array if there are related samples\n    data = np.array(data, dtype=[\n        (\"IBS2_RATIO\", float),\n        (\"Z1\", float),\n        (\"Z2\", float),\n        (\"CODE\", \"S{}\".format(max([len(i[3]) for i in data]))),\n    ])\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if there is enough SNPs in the file.", "response": "def checkNumberOfSNP(fileName, minimumNumber):\n    \"\"\"Check there is enough SNPs in the file (with minimum).\n\n    :param fileName: the name of the file.\n    :param minimumNumber: the minimum number of markers that needs to be in the\n                          file.\n\n    :type fileName: str\n    :type minimumNumber: int\n\n    :returns: ``True`` if there is enough markers in the file, ``False``\n              otherwise.\n\n    Reads the number of markers (number of lines) in a file.\n\n    \"\"\"\n    nbSNP = 0\n    try:\n        with open(fileName, 'r') as inputFile:\n            for line in inputFile:\n                nbSNP += 1\n    except IOError:\n        msg = \"{}: no such file\".format(fileName)\n        raise ProgramError(msg)\n\n    if nbSNP < minimumNumber:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef splitFile(inputFileName, linePerFile, outPrefix):\n    nbTmpFile = 1\n    nbLine = 0\n    tmpFile = None\n    try:\n        with open(inputFileName, \"r\") as inputFile:\n            for line in inputFile:\n                row = line.rstrip(\"\\r\\n\").split(\" \")\n                nbLine += 1\n\n                if tmpFile is None:\n                    try:\n                        tmpFile = open(\n                            outPrefix + \"_tmp.list%d\" % nbTmpFile,\n                            \"w\",\n                        )\n                    except IOError:\n                        msg = \"tmp.list%d: can't write file\" % nbTmpFile\n                        raise ProgramError(msg)\n\n                print >>tmpFile, \" \".join(row[:2])\n\n                if nbLine == linePerFile:\n                    nbLine = 0\n                    nbTmpFile += 1\n                    tmpFile.close()\n                    try:\n                        tmpFile = open(\n                            outPrefix + \"_tmp.list%d\" % nbTmpFile,\n                            \"w\",\n                        )\n                    except IOError:\n                        msg = \"tmp.list%d: can't write file\" % nbTmpFile\n                        raise ProgramError(msg)\n        tmpFile.close()\n\n        # Check if the number of line is zero (hence the last file is empty)\n        if nbLine == 0:\n            # We delete the last file\n            file_name = outPrefix + \"_tmp.list{}\".format(nbTmpFile)\n            if os.path.isfile(file_name):\n                os.remove(file_name)\n            nbTmpFile -= 1\n\n    except IOError:\n        msg = \"%s: no such file\" % inputFileName\n        raise ProgramError(msg)\n\n    return nbTmpFile", "response": "Splits a file into multiple files containing at most linePerFile lines."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef runGenome(bfile, options):\n    outPrefix = options.out + \".genome\"\n    if options.sge:\n        # We run genome using SGE\n        # We need to create a frequency file using plink\n        plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", bfile, \"--freq\",\n                        \"--out\", options.out + \".frequency\"]\n        runCommand(plinkCommand)\n\n        # We need to split the .fam file\n        nbJob = splitFile(bfile + \".fam\", options.line_per_file_for_sge,\n                          outPrefix)\n\n        runGenomeSGE(bfile, options.out + \".frequency.frq\", nbJob,\n                     outPrefix, options)\n\n        # Merging genome files\n        mergeGenomeLogFiles(outPrefix, nbJob)\n\n    else:\n        plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", bfile, \"--genome\",\n                        \"--genome-full\", \"--out\", outPrefix]\n        runCommand(plinkCommand)\n\n    return outPrefix + \".genome\"", "response": "Runs the genome command from plink."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging genome and log files together. :param outPrefix: the prefix of the output files. :param nbSet: The number of set of files to merge together. :type outPrefix: str :type nbSet: int :returns: the name of the output file (the ``genome`` file). After merging, the files are deleted to save space.", "response": "def mergeGenomeLogFiles(outPrefix, nbSet):\n    \"\"\"Merge genome and log files together.\n\n    :param outPrefix: the prefix of the output files.\n    :param nbSet: The number of set of files to merge together.\n\n    :type outPrefix: str\n    :type nbSet: int\n\n    :returns: the name of the output file (the ``genome`` file).\n\n    After merging, the files are deleted to save space.\n\n    \"\"\"\n    outputFile = None\n    try:\n        outputFile = open(outPrefix + \".genome\", \"w\")\n        outputLog = open(outPrefix + \".log\", \"w\")\n    except IOError:\n        msg = \"%s or %s: can't write file\" % (outPrefix + \".genome\",\n                                              outPrefix + \".log\")\n        raise ProgramError(msg)\n\n    for i in xrange(1, nbSet + 1):\n        for j in xrange(i, nbSet + 1):\n            fileName = outPrefix + \"_output.sub.%(i)d.%(j)d.genome\" % locals()\n\n            printHeader = False\n            if (i == 1) and (j == 1):\n                # This is the first file we open\n                printHeader = True\n\n            # Read file here\n            try:\n                with open(fileName, 'r') as inputFile:\n                    for nbLine, line in enumerate(inputFile):\n                        if nbLine == 0:\n                            if printHeader:\n                                outputFile.write(line)\n                        else:\n                            outputFile.write(line)\n            except IOError:\n                msg = \"%(fileName)s: no such file\" % locals()\n                raise ProgramError(msg)\n\n            # Deleting the file\n            try:\n                os.remove(fileName)\n            except IOError:\n                msg = \"%(fileName)s: can't delete the file\" % locals()\n                raise ProgramError(msg)\n\n            # Read file here\n            fileName = outPrefix + \"_output.sub.%(i)d.%(j)d.log\" % locals()\n            try:\n                with open(fileName, 'r') as inputFile:\n                    for line in inputFile:\n                        outputLog.write(line)\n            except IOError:\n                msg = \"%(fileName)s: no such file\" % locals()\n                raise ProgramError(msg)\n\n            # Deleting the file\n            try:\n                os.remove(fileName)\n            except IOError:\n                msg = \"%(fileName)s: can't delete the file\" % locals()\n                raise ProgramError(msg)\n\n    # Removing the tmp.list* files\n    try:\n        for fileName in glob.glob(outPrefix + \"_tmp.list*\"):\n            os.remove(fileName)\n    except IOError:\n        msg = \"can't delete the tmp.list* files\"\n        raise ProgramError(msg)\n\n    # Removing the output.sub.*\n    try:\n        for fileName in glob.glob(outPrefix + \"_output.sub.*\"):\n            os.remove(fileName)\n    except IOError:\n        msg = \"can't delete the output.sub.* files\"\n        raise ProgramError(msg)\n\n    # Closing the output files\n    outputFile.close()\n    outputLog.close()\n\n    return outPrefix + \".genome\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the genome command from Plink on the SGE.", "response": "def runGenomeSGE(bfile, freqFile, nbJob, outPrefix, options):\n    \"\"\"Runs the genome command from plink, on SGE.\n\n    :param bfile: the prefix of the input file.\n    :param freqFile: the name of the frequency file (from Plink).\n    :param nbJob: the number of jobs to launch.\n    :param outPrefix: the prefix of all the output files.\n    :param options: the options.\n\n    :type bfile: str\n    :type freqFile: str\n    :type nbJob: int\n    :type outPrefix: str\n    :type options: argparse.Namespace\n\n    Runs Plink with the ``genome`` options on the cluster (using SGE).\n\n    \"\"\"\n    # Add the environment variable for DRMAA package\n    if \"DRMAA_LIBRARY_PATH\" not in os.environ:\n        msg = \"could not load drmaa: set DRMAA_LIBRARY_PATH\"\n        raise ProgramError(msg)\n\n    # Import the python drmaa library\n    try:\n        import drmaa\n    except ImportError:\n        raise ProgramError(\"drmaa is not install, install drmaa\")\n\n    # Initializing a session\n    s = drmaa.Session()\n    s.initialize()\n\n    # Run for each sub task...\n    jobIDs = []\n    jobTemplates = []\n    for i in xrange(1, nbJob + 1):\n        for j in xrange(i, nbJob + 1):\n            # The command to run\n            plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", bfile,\n                            \"--read-freq\", freqFile, \"--genome\",\n                            \"--genome-full\", \"--genome-lists\",\n                            \"{}_tmp.list{}\".format(outPrefix, i),\n                            \"{}_tmp.list{}\".format(outPrefix, j), \"--out\",\n                            \"{}_output.sub.{}.{}\".format(outPrefix, i, j)]\n\n            # Creating the job template\n            jt = s.createJobTemplate()\n            jt.remoteCommand = plinkCommand[0]\n            jt.workingDirectory = os.getcwd()\n            jt.jobEnvironment = os.environ\n            jt.args = plinkCommand[1:]\n            jt.jobName = \"_plink_genome_{}_{}\".format(i, j)\n\n            # Cluster specifics\n            if options.sge_walltime is not None:\n                jt.hardWallclockTimeLimit = options.sge_walltime\n            if options.sge_nodes is not None:\n                native_spec = \"-l nodes={}:ppn={}\".format(options.sge_nodes[0],\n                                                          options.sge_nodes[1])\n                jt.nativeSpecification = native_spec\n\n            jobIDs.append(s.runJob(jt))\n            jobTemplates.append(jt)\n\n    # Waiting for the jobs to finish\n    hadProblems = []\n    for jobID in jobIDs:\n        retVal = s.wait(jobID, drmaa.Session.TIMEOUT_WAIT_FOREVER)\n        hadProblems.append(retVal.exitStatus == 0)\n\n    # Deleting the jobs\n    for jt in jobTemplates:\n        s.deleteJobTemplate(jt)\n\n    # Closing the session\n    s.exit()\n\n    # Checking for problems\n    for hadProblem in hadProblems:\n        if not hadProblem:\n            msg = \"Some SGE jobs had errors...\"\n            raise ProgramError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts markers using Plink.", "response": "def extractSNPs(snpsToExtract, options):\n    \"\"\"Extract markers using Plink.\n\n    :param snpsToExtract: the name of the file containing markers to extract.\n    :param options: the options\n\n    :type snpsToExtract: str\n    :type options: argparse.Namespace\n\n    :returns: the prefix of the output files.\n\n    \"\"\"\n    outPrefix = options.out + \".pruned_data\"\n    plinkCommand = [\"plink\", \"--noweb\", \"--bfile\", options.bfile, \"--extract\",\n                    snpsToExtract, \"--make-bed\", \"--out\", outPrefix]\n    runCommand(plinkCommand)\n    return outPrefix"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selectSNPsAccordingToLD(options):\n    # The plink command\n    outPrefix = options.out + \".pruning_\" + options.indep_pairwise[2]\n    plinkCommand = [\n        \"plink\",\n        \"--noweb\",\n        \"--bfile\", options.bfile,\n        \"--maf\", options.maf,\n        \"--indep-pairwise\",\n    ] + options.indep_pairwise + [\"--out\", outPrefix]\n\n    runCommand(plinkCommand)\n\n    # Finding the autosomal markers\n    autosomes = {str(i) for i in range(1, 23)}\n    autosomal_snps = set()\n    with open(options.bfile + \".bim\", \"r\") as i_file:\n        for line in i_file:\n            chrom, snp = line.rstrip(\"\\r\\n\").split(\"\\t\")[:2]\n            if chrom in autosomes:\n                autosomal_snps.add(snp)\n\n    # Reading the pruned markers\n    pruned_snps = None\n    with open(outPrefix + \".prune.in\", \"r\") as i_file:\n        pruned_snps = set(i_file.read().splitlines())\n\n    # Writing the pruned markers located on an autosome\n    with open(outPrefix + \".prune.in.autosomal\", \"w\") as o_file:\n        for snp in autosomal_snps & pruned_snps:\n            print >>o_file, snp\n\n    return outPrefix + \".prune.in.autosomal\"", "response": "Compute the LD using Plink."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the arguments and options for validity.", "response": "def checkArgs(args):\n    \"\"\"Checks the arguments and options.\n\n    :param args: an object containing the options of the program.\n\n    :type args: argparse.Namespace\n\n    :returns: ``True`` if everything was OK.\n\n    If there is a problem with an option, an exception is raised using the\n    :py:class:`ProgramError` class, a message is printed to the\n    :class:`sys.stderr` and the program exists with code 1.\n\n    \"\"\"\n    # Check if we have the tped and the tfam files\n    for fileName in [args.bfile + i for i in [\".bed\", \".bim\", \".fam\"]]:\n        if not os.path.isfile(fileName):\n            msg = \"%(fileName)s: no such file\" % locals()\n            raise ProgramError(msg)\n\n    # Check the indep-pairwise option\n    # The two first must be int, the last one float\n    try:\n        for i in xrange(2):\n            tmp = int(args.indep_pairwise[i])\n        tmp = float(args.indep_pairwise[2])\n    except ValueError:\n        msg = \"indep-pairwise: need INT INT FLOAT\"\n        raise ProgramError(msg)\n\n    # Check the maf value\n    tmpMAF = None\n    try:\n        tmpMAF = float(args.maf)\n    except ValueError:\n        msg = \"maf: must be a float, not %s\" % args.maf\n        raise ProgramError(msg)\n    if (tmpMAF > 0.5) or (tmpMAF < 0.0):\n        msg = \"maf: must be between 0.0 and 0.5, not %s\" % args.maf\n        raise ProgramError(msg)\n\n    # Check the number of line per file\n    if args.line_per_file_for_sge < 1:\n        msg = \"line-per-file-for-sge: must be above 0, not \" \\\n              \"%d\" % args.line_per_file_for_sge\n        raise ProgramError(msg)\n\n    # Check the minimum number of SNPs\n    if args.min_nb_snp < 1:\n        msg = \"min-nb-snp: must be above 1\"\n        raise ProgramError(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spin_once(self, polling_sec=0.010):\n        '''Read the queued data and call the callback for them.\n        You have to handle KeyboardInterrupt (\\C-c) manually.\n\n        Example:\n\n        >>> def callback(msg):\n        ...   print msg\n        >>> sub = jps.Subscriber('topic_name', callback)\n        >>> try:\n        ...   while True:\n        ...     sub.spin_once():\n        ...     time.sleep(0.1)\n        ... except KeyboardInterrupt:\n        ...   pass\n\n        '''\n        # parse all data\n        while True:\n            socks = dict(self._poller.poll(polling_sec * 1000))\n            if socks.get(self._socket) == zmq.POLLIN:\n                msg = self._socket.recv()\n                self._callback(msg)\n            else:\n                return", "response": "Read the queued data and call the callback for them."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreceive next data (block until next data", "response": "def next(self):\n        '''receive next data (block until next data)'''\n        try:\n            raw_msg = self._socket.recv()\n        except KeyboardInterrupt:\n            raise StopIteration()\n        msg, topic_name = self._strip_topic_name_if_not_wildcard(raw_msg)\n        if msg is None:\n            return self.next()\n        if self._user_callback_takes_topic_name:\n            return (self.deserialize(msg), topic_name)\n        else:\n            return self.deserialize(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening the URL with urllib. request.", "response": "def open(self):\n        \"\"\"Open the URL with urllib.request.\"\"\"\n        url = self.url\n        try:\n            request = urllib.request.Request(url)\n            handle = urllib.request.build_opener()\n        except IOError:\n            return None\n        return (request, handle)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_crawled_urls(self, handle, request):\n        try:\n            content = six.text_type(handle.open(request).read(), \"utf-8\",\n                                    errors=\"replace\")\n            soup = BeautifulSoup(content, \"html.parser\")\n            tags = soup('a')\n            for tag in tqdm(tags):\n                href = tag.get(\"href\")\n                if href is not None:\n                    url = urllib.parse.urljoin(self.url, escape(href))\n                    if url not in self:\n                        self.urls.append(url)\n\n        except urllib.request.HTTPError as error:\n            if error.code == 404:\n                logger.warning(\"ERROR: %s -> %s for %s\" % (error, error.url, self.url))\n            else:\n                logger.warning(\"ERROR: %s for %s\" % (error, self.url))\n\n        except urllib.request.URLError as error:\n            logger.warning(\"ERROR: %s for %s\" % (error, self.url))\n            raise urllib.request.URLError(\"URL entered is Incorrect\")", "response": "Get the crawled urls from the HTML content of the page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef linkfetch(self):\n        request, handle = self.open()\n        self._add_headers(request)\n        if handle:\n            self._get_crawled_urls(handle, request)", "response": "Public method to call the internal methods\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_fields_with_objects(self):\n        # Update the cover with a photo object\n        if isinstance(self.cover, dict):\n            self.cover = Photo(self._client, self.cover)\n\n        # Update the photo list with photo objects\n        try:\n            for i, photo in enumerate(self.photos):\n                if isinstance(photo, dict):\n                    self.photos[i] = Photo(self._client, photo)\n        except (AttributeError, TypeError):\n            pass", "response": "Convert dict fields into objects where appropriate"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cover_update(self, photo, **kwds):\n        result = self._client.album.cover_update(self, photo, **kwds)\n        self._replace_fields(result.get_fields())\n        self._update_fields_with_objects()", "response": "This endpoint allows you to update the cover photo of this album."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, **kwds):\n        result = self._client.album.delete(self, **kwds)\n        self._delete_fields()\n        return result", "response": "Endpoint: /album/<id>/delete.json\n\n        Deletes this album.\n        Returns True if successful.\n        Raises a TroveboxError if not."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, objects, object_type=None, **kwds):\n        result = self._client.album.add(self, objects, object_type, **kwds)\n        self._replace_fields(result.get_fields())\n        self._update_fields_with_objects()", "response": "This method adds objects to the album."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecorating the handle method with a file lock to ensure there is only ever one process running at any one time.", "response": "def handle_lock(handle):\n    \"\"\"\n    Decorate the handle method with a file lock to ensure there is only ever\n    one process running at any one time.\n    \"\"\"\n    \n    def wrapper(self, *args, **options):\n        def on_interrupt(signum, frame):\n            # It's necessary to release lockfile\n            sys.exit()\n        signal.signal(signal.SIGTERM, on_interrupt)\n\n        start_time = time.time()\n        try:\n            verbosity = int(options.get('verbosity', 0))\n        except ValueError:\n            verbosity = 0\n        logger = logging.getLogger(self.__module__)\n        if verbosity == 0:\n            logger.level = logging.WARNING\n        elif verbosity == 1:\n            logger.level = logging.INFO\n        else:\n            logger.level = logging.DEBUG\n       \n        logger.debug(\"-\" * 72)\n        \n        lock_name = self.__module__.split('.').pop()\n        lock = FileLock(os.path.join(LOCK_ROOT, lock_name))\n        \n        logger.debug(\"%s - acquiring lock...\" % lock_name)\n        try:\n            lock.acquire(LOCK_WAIT_TIMEOUT)\n        except AlreadyLocked:\n            logger.debug(\"lock already in place. quitting.\")\n            return\n        except LockTimeout:\n            logger.debug(\"waiting for the lock timed out. quitting.\")\n            return\n        logger.debug(\"acquired.\")\n        \n        try:\n            handle(self, logger, *args, **options)\n        except (KeyboardInterrupt, SystemExit):\n            pass\n        except:\n            import traceback\n            logging.warn(\"Command Failed\")\n            logging.warn('=' * 72)\n            logging.warn(traceback.format_exc())\n            logging.warn('=' * 72)\n        \n        logger.debug(\"releasing lock...\")\n        lock.release()\n        logger.debug(\"released.\")\n        \n        logger.info(\"done in %.2f seconds\" % (time.time() - start_time))\n        return\n        \n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef highlightBlock(self, text):\n\n        # I need to know where in the document we are,\n        # because our formatting info is global to\n        # the document\n        cb = self.currentBlock()\n        p = cb.position()\n\n        # The \\n is not really needed, but sometimes\n        # you are in an empty last block, so your position is\n        # **after** the end of the document.\n        text = str(self.document().toPlainText()) + '\\n'\n\n        # Yes, re-highlight the whole document.\n        # There **must** be some optimizacion possibilities\n        # but it seems fast enough.\n        highlight(text, self.lexer, self.formatter)\n\n        # Just apply the formatting to this block.\n        # For titles, it may be necessary to backtrack\n        # and format a couple of blocks **earlier**.\n        for i in range(len(str(text))):\n            try:\n                self.setFormat(i, 1, self.formatter.data[p + i])\n            except IndexError:\n                pass\n\n        # I may need to do something about this being called\n        # too quickly.\n        self.tstamp = time.time()", "response": "Takes a block applies format to the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates connect and block on the listener worker.", "response": "def main(url):\n    \"\"\"Create, connect, and block on the listener worker.\"\"\"\n    try:\n        listener = ListenerWorker(url)\n        listener.connect()\n        listener.run_forever()\n    except KeyboardInterrupt:\n        listener.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes HxRLE data stream", "response": "def hxbyterle_decode(output_size, data):\n    \"\"\"Decode HxRLE data stream\n    \n    If C-extension is not compiled it will use a (slower) Python equivalent\n    \n    :param int output_size: the number of items when ``data`` is uncompressed\n    :param str data: a raw stream of data to be unpacked\n    :return numpy.array output: an array of ``numpy.uint8``\n    \"\"\"\n    output = byterle_decoder(data, output_size)\n    assert len(output) == output_size     \n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndecodes HxZip data stream", "response": "def hxzip_decode(data_size, data):\n    \"\"\"Decode HxZip data stream\n    \n    :param int data_size: the number of items when ``data`` is uncompressed\n    :param str data: a raw stream of data to be unpacked\n    :return numpy.array output: an array of ``numpy.uint8``\n    \"\"\"\n    import zlib\n    data_stream = zlib.decompress(data)\n    output = numpy.array(struct.unpack('<{}B'.format(len(data_stream)), data_stream), dtype=numpy.uint8)\n    assert len(output) == data_size\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpack_binary(data_pointer, definitions, data):\n    \n    if data_pointer.data_dimension:\n        data_dimension = data_pointer.data_dimension\n    else:\n        data_dimension = 1 # if data_dimension is None\n        \n    if data_pointer.data_type == \"float\":\n        data_type = \"f\" * data_dimension\n    elif data_pointer.data_type == \"int\":\n        data_type = \"i\" * data_dimension # assume signed int\n    elif data_pointer.data_type == \"byte\":\n        data_type = \"b\" * data_dimension # assume signed char\n\n    # get this streams size from the definitions\n    try: \n        data_length = int(getattr(definitions, data_pointer.data_name))\n    except AttributeError:\n        # quickfix\n        \"\"\"\n        :TODO: nNodes definition fix\n        \"\"\"\n        try:\n            data_length = int(getattr(definitions, 'Nodes'))\n        except AttributeError:\n            x, y, z = definitions.Lattice\n            data_length = x * y * z\n        \n    output = numpy.array(struct.unpack('<' + '{}'.format(data_type) * data_length, data)) # assume little-endian\n    output = output.reshape(data_length, data_dimension)\n    return output", "response": "Unpacks binary data using struct. unpack."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpack_ascii(data):\n    # string: split at newlines -> exclude last list item -> strip space from each \n    numstrings = map(lambda s: s.strip(), data.split('\\n')[:-1])\n    print numstrings\n    # check if string is digit (integer); otherwise float\n    if len(numstrings) == len(filter(lambda n: n.isdigit(), numstrings)):\n        output = map(int, numstrings)\n    else:\n        output = map(float, numstrings)\n    return output", "response": "Unpacks the ASCII data into a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_contours(self):\n        contours = dict()\n        for byte_value in self.__byte_values:\n            if byte_value == 0:\n                continue\n            mask = (self.__array == byte_value) * 255\n            found_contours = find_contours(mask, 254, fully_connected='high') # a list of array\n            contours[byte_value] = ContourSet(found_contours)\n        return contours", "response": "A dictionary of lists of contours keyed by byte_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef segments(self):\n        segments = dict()\n        for i in xrange(len(self)):\n            image = self[i]\n            for z, contour in image.as_segments.iteritems():\n                for byte_value, contour_set in contour.iteritems():\n                    if byte_value not in segments:\n                        segments[byte_value] = dict()\n                    if z not in segments[byte_value]:\n                        segments[byte_value][z] = contour_set\n                    else:\n                        segments[byte_value][z] += contour_set                \n         \n        return segments", "response": "A dictionary of lists of contours keyed by z - index"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a 3D volume of the data", "response": "def to_volume(self):\n        \"\"\"Return a 3D volume of the data\"\"\"\n        if hasattr(self.header.definitions, \"Lattice\"):\n            X, Y, Z = self.header.definitions.Lattice\n        else:\n            raise ValueError(\"Unable to determine data size\")\n        \n        volume = self.decoded_data.reshape(Z, Y, X)\n        return volume"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses manifest file and build a webfont icon map.", "response": "def parse_manifest(self, fp):\n        \"\"\"\n        Open manifest JSON file and build icon map\n\n        Args:\n            fp (string or fileobject): Either manifest filepath to open or\n                manifest File object.\n\n        Returns:\n            dict: Webfont icon map. Contains:\n\n            * ``class_name``: Builded icon classname with prefix configured\n              in manifest (from parameters in Icomoon interface);\n            * ``int``: Icon integer code like ``59649``;\n            * ``hex``: Icon hexadecimal code like ``0xe901``;\n            * ``unicode``: Icon unicode like ``U+E901``;\n            * ``utf8``! Icon UTF8 code like ``\\e901``;\n        \"\"\"\n        # Given a string for file path to open\n        if isinstance(fp, string_types):\n            fp = io.open(fp, 'r', encoding='utf-8')\n\n        with fp as json_file:\n            webfont_manifest = json.load(json_file)\n\n        # Get the font set prefix to know the css classname\n        icon_prefix = webfont_manifest.get('preferences').get('fontPref').get('prefix')\n\n        # Get sorted icons\n        icons_map = OrderedDict()\n        sorted_entries = sorted(webfont_manifest.get('icons'), key=self.get_icon_key)\n        for icon_entry in sorted_entries:\n            name = icon_entry.get('properties').get('name')\n            code = icon_entry.get('properties').get('code')\n            hexa_code = hex(code)\n\n            icons_map[name] = {\n                'class_name': icon_prefix + name,\n                'int': code,\n                'hex': hexa_code,\n                'unicode': 'U+'+''.join(hex(code).split('x')[1:]).upper(),\n                'utf8': '\\\\'+''.join(hex(code).split('x')[1:]).lower(),\n            }\n\n        return icons_map"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, webfont_name, webfont_settings):\n        try:\n            webfont_settings = extend_webfont_settings(webfont_settings)\n        except IcomoonSettingsError as e:\n            msg = \"Invalid webfont settings for '{}': {}\"\n            self.errors[webfont_name] = msg.format(webfont_name, e.value)\n            return\n\n        filepath = os.path.join(webfont_settings['fontdir_path'],\n                                self.manifest_filename)\n\n        if os.path.exists(filepath):\n            self.manifests[webfont_name] = self.parse_manifest(filepath)\n        else:\n            msg = (\"\"\"Filepath for webfont <strong>{name}</strong> does not \"\"\"\n                   \"\"\"exists: <code>{filepath}</code>\"\"\")\n            self.errors[webfont_name] = msg.format(name=webfont_name,\n                                                   filepath=filepath)", "response": "Get a manifest file parse and store it."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores every defined webfonts.", "response": "def fetch(self, webfonts):\n        \"\"\"\n        Store every defined webfonts.\n\n        Webfont are stored with sort on their name.\n\n        Args:\n            webfonts (dict): Dictionnary of webfont settings from\n                ``settings.ICOMOON_WEBFONTS``.\n        \"\"\"\n        sorted_keys = sorted(webfonts.keys())\n        for webfont_name in sorted_keys:\n            self.get(webfont_name, webfonts[webfont_name])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply2parser(arguments, options, parser):\n    for args, kwargs in options:\n        parser.option(*args, **kwargs)\n    for args, kwargs in arguments:\n        parser.argument(*args, **kwargs)\n    return parser", "response": "Applies the given parser to the given arguments and options."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply2parser(cmd_proxy, parser):\n    if isinstance(cmd_proxy, CmdProxy):\n        parser_proxy = cmd_proxy.meta.parser\n        _apply2parser(\n            parser_proxy.arguments,\n            parser_proxy.options,\n            parser,\n        )\n    return parser", "response": "Applies a CmdProxy s arguments and options to a parser of argparse. AParser\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread CSV into DataFrame.", "response": "def read_csv(filepath, sep=',', header='infer', names=None, usecols=None, dtype=None, converters=None,\n             skiprows=None, nrows=None):\n    \"\"\"Read CSV into DataFrame.\n\n    Eager implementation using pandas, i.e. entire file is read at this point. Only common/relevant parameters\n    available at the moment; for full list, could use pandas directly and then convert to baloo.\n\n    Parameters\n    ----------\n    filepath : str\n    sep : str, optional\n        Separator used between values.\n    header : 'infer' or None, optional\n        Whether to infer the column names from the first row or not.\n    names : list of str, optional\n        List of column names to use. Overrides inferred header.\n    usecols : list of (int or str), optional\n        Which columns to parse.\n    dtype : dict, optional\n        Dict of column -> type to parse as.\n    converters : dict, optional\n        Dict of functions for converting values in certain columns.\n    skiprows : int, optional\n        Number of lines to skip at start of file.\n    nrows : int, optional\n        Number of rows to read.\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    pandas.read_csv : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n\n    \"\"\"\n    pd_df = pd_read_csv(filepath,\n                        sep=sep,\n                        header=header,\n                        names=names,\n                        usecols=usecols,\n                        dtype=dtype,\n                        converters=converters,\n                        skiprows=skiprows,\n                        nrows=nrows)\n\n    return DataFrame.from_pandas(pd_df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_csv(df, filepath, sep=',', header=True, index=True):\n    df.to_pandas().to_csv(filepath,\n                          sep=sep,\n                          header=header,\n                          index=index)", "response": "Save DataFrame as csv."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclassifies a set of sequences using One Codex 31mer LCA.", "response": "def kmer_lca(seqs_path: 'path to (optionally gzipped) fasta/fastq input',\n             fastq: 'input is fastq; disable autodetection' = False,\n             progress: 'show progress bar (sent to stderr)' = False):\n    '''\n    Lowest common ancestor sequence assignment using the One Codex API.\n    Streams annotated records to stdout in fasta format.\n    Taxa assigned using the One Codex 31mer LCA database.\n    '''\n    conf = tictax.config()\n    records = tictax.parse_seqs(seqs_path, fastq)\n    print('Classifying sequences\u2026', file=sys.stderr)\n    asyncio.get_event_loop().run_until_complete(tictax.oc_classify(records,\n                                                                   conf['one_codex_api_key'],\n                                                                   progress,\n                                                                   True))\n    print('\u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc \u2713\ud83d\udccc', file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef annotate_diamond(fasta_path: 'path to fasta input',\n                     diamond_path: 'path to Diamond taxonomic classification output'):\n    '''\n    Annotate fasta headers with taxonomy information from Diamond\n    '''\n    records = tictax.parse_seqs(fasta_path)\n    annotated_records = tictax.annotate_diamond(records, diamond_path)\n    SeqIO.write(annotated_records, sys.stdout, 'fasta')", "response": "Annotate fasta headers with taxonomy information from Diamond"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_taxa(fasta_path: 'path to fasta input',\n                taxids: 'comma delimited list of taxon IDs',\n                unclassified: 'pass sequences unclassified at superkingdom level >(0)' = False,\n                discard: 'discard specified taxa' = False,\n                warnings: 'show warnings' = False):\n    '''\n    Customisable filtering of tictax flavoured fasta files\n    '''\n    configure_warnings(warnings)\n    records = SeqIO.parse(fasta_path, 'fasta')\n    filtered_records = tictax.filter_taxa(records,\n                                          map(int, taxids.split(',')),\n                                          unclassified,\n                                          discard)\n    SeqIO.write(filtered_records, sys.stdout, 'fasta')", "response": "Customisable filtering of tictax flavoured fasta files"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates taxonomic count matrix from tictax classified contigs", "response": "def matrix(fasta_path: 'path to tictax annotated fasta input',\n           scafstats_path: 'path to BBMap scaftstats file'):\n    '''\n    Generate taxonomic count matrix from tictax classified contigs\n    '''\n    records = SeqIO.parse(fasta_path, 'fasta')\n    df = tictax.matrix(records, scafstats_path)\n    df.to_csv(sys.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_file(cls, file_path, validate=True):\n        return xmlmap.load_xmlobject_from_file(file_path, xmlclass=cls, validate=validate)", "response": "Creates a Python object from a XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Python object from a XML string.", "response": "def from_string(cls, xml_string, validate=True):\n        \"\"\" Creates a Python object from a XML string\n\n        :param xml_string: XML string\n        :param validate: XML should be validated against the embedded XSD definition\n        :type validate: Boolean\n        :returns: the Python object\n        \"\"\"\n        return xmlmap.load_xmlobject_from_string(xml_string, xmlclass=cls, validate=validate)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef id(self):\n        h = hashlib.new('sha512')\n        for value in (self.machine.name, self.machine.os, self.user, self.application.name,\n                      self.application.path, self.event.report_type, self.event.type,\n                      self.event.time.isoformat()):\n            h.update(str(value).encode('utf-8'))\n        for parameter in sorted(self.parameters, key=lambda k: getattr(k, 'id')):\n            h.update(parameter.value.encode('utf-8'))\n        return h.hexdigest()", "response": "Computes the signature of the record a SHA - 512 of significant values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_service(name, service_map):\n    if name in service_map:\n        service = service_map[name]\n        data = service.update()\n        if not data:\n            logger.warning('no data received for service: %s', name)\n        else:\n            data['service_name'] = service.service_name\n            CACHE[name] = dict(data=data, updated=datetime.now())\n    else:\n        logger.warning('service not found: %s', name)\n    if name in CACHE:\n        return add_time(CACHE[name])\n    return {}", "response": "Get an update from the specified service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_time(data):\n    payload = data['data']\n    updated = data['updated'].date()\n    if updated == date.today():\n        payload['last_updated'] = data['updated'].strftime('today at %H:%M:%S')\n    elif updated >= (date.today() - timedelta(days=1)):\n        payload['last_updated'] = 'yesterday'\n    elif updated >= (date.today() - timedelta(days=7)):\n        payload['last_updated'] = updated.strftime('on %A')\n    else:\n        payload['last_updated'] = updated.strftime('%Y-%m-%d')\n    return payload", "response": "Adds a friendly update time to the supplied data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dtypes(self):\n        return Series(np.array(list(self._gather_dtypes().values()), dtype=np.bytes_),\n                      self.keys())", "response": "Series of NumPy dtypes present in the DataFrame with index of column names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef columns(self):\n        return Index(np.array(self._gather_column_names(), dtype=np.bytes_), np.dtype(np.bytes_))", "response": "Returns the index of the column names present in the DataFrame in order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncasting DataFrame columns to given dtype.", "response": "def astype(self, dtype):\n        \"\"\"Cast DataFrame columns to given dtype.\n\n        Parameters\n        ----------\n        dtype : numpy.dtype or dict\n            Dtype or column_name -> dtype mapping to cast columns to. Note index is excluded.\n\n        Returns\n        -------\n        DataFrame\n            With casted columns.\n\n        \"\"\"\n        if isinstance(dtype, np.dtype):\n            new_data = OrderedDict((column.name, column.astype(dtype))\n                                   for column in self._iter())\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(dtype, dict):\n            check_inner_types(dtype.values(), np.dtype)\n\n            new_data = OrderedDict(self._data)\n            for column in self._iter():\n                column_name = column.name\n                if column_name in dtype:\n                    new_data[column_name] = column.astype(dtype[column_name])\n\n            return DataFrame(new_data, self.index)\n        else:\n            raise TypeError('Expected numpy.dtype or dict mapping column names to dtypes')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating by creating a DataFrame containing evaluated data and index.", "response": "def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        \"\"\"Evaluates by creating a DataFrame containing evaluated data and index.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with evaluated data and index.\n\n        \"\"\"\n        evaluated_index = self.index.evaluate(verbose, decode, passes, num_threads, apply_experimental)\n        evaluated_data = OrderedDict((column.name, column.evaluate(verbose, decode, passes,\n                                                                   num_threads, apply_experimental))\n                                     for column in self._iter())\n\n        return DataFrame(evaluated_data, evaluated_index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tail(self, n=5):\n        length = _obtain_length(self._length, self._data)\n\n        new_index = self.index.tail(n)\n        new_data = OrderedDict((column.name, _series_tail(column, new_index, length, n))\n                               for column in self._iter())\n\n        return DataFrame(new_data, new_index)", "response": "Return DataFrame with last n values per column."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rename(self, columns):\n        new_data = OrderedDict()\n        for column_name in self:\n            if column_name in columns.keys():\n                column = self._data[column_name]\n                new_name = columns[column_name]\n                new_data[new_name] = Series(column.values, column.index, column.dtype, new_name)\n            else:\n                new_data[column_name] = self._data[column_name]\n\n        return DataFrame(new_data, self.index)", "response": "Returns a new DataFrame with renamed columns. Currently a simplified version of Pandas rename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndropping one or more columns.", "response": "def drop(self, columns):\n        \"\"\"Drop 1 or more columns. Any column which does not exist in the DataFrame is skipped, i.e. not removed,\n        without raising an exception.\n\n        Unlike Pandas' drop, this is currently restricted to dropping columns.\n\n        Parameters\n        ----------\n        columns : str or list of str\n            Column name or list of column names to drop.\n\n        Returns\n        -------\n        DataFrame\n            A new DataFrame without these columns.\n\n        \"\"\"\n        if isinstance(columns, str):\n            new_data = OrderedDict()\n            if columns not in self._gather_column_names():\n                raise KeyError('Key {} not found'.format(columns))\n\n            for column_name in self:\n                if column_name != columns:\n                    new_data[column_name] = self._data[column_name]\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(columns, list):\n            check_inner_types(columns, str)\n\n            df = self\n            for column in columns:\n                df = df.drop(column)\n\n            return df\n        else:\n            raise TypeError('Expected columns as a str or a list of str')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a DataFrame with the aggregations optimized.", "response": "def agg(self, aggregations):\n        \"\"\"Multiple aggregations optimized.\n\n        Parameters\n        ----------\n        aggregations : list of str\n            Which aggregations to perform.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with the aggregations per column.\n\n        \"\"\"\n        check_type(aggregations, list)\n\n        df = _drop_str_columns(self)\n        if len(df._data) == 0:\n            # conforming to what pandas does\n            raise ValueError('No results')\n\n        new_index = Index(np.array(aggregations, dtype=np.bytes_), np.dtype(np.bytes_))\n        new_data = OrderedDict((column.name, _series_agg(column, aggregations, new_index))\n                               for column in df._iter())\n\n        return DataFrame(new_data, new_index)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset_index(self):\n        new_columns = OrderedDict()\n\n        new_index = default_index(_obtain_length(self._length, self._data))\n\n        new_columns.update((name, Series(data.values, new_index, data.dtype, name))\n                           for name, data in self.index._gather_data().items())\n\n        # the data/columns\n        new_columns.update((sr.name, Series(sr.values, new_index, sr.dtype, sr.name))\n                           for sr in self._iter())\n\n        return DataFrame(new_columns, new_index)", "response": "Returns a new DataFrame with the previous index as column ( s )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the index of the DataFrame to be the keys columns.", "response": "def set_index(self, keys):\n        \"\"\"Set the index of the DataFrame to be the keys columns.\n\n        Note this means that the old index is removed.\n\n        Parameters\n        ----------\n        keys : str or list of str\n            Which column(s) to set as the index.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with the index set to the column(s) corresponding to the keys.\n\n        \"\"\"\n        if isinstance(keys, str):\n            column = self._data[keys]\n            new_index = Index(column.values, column.dtype, column.name)\n\n            new_data = OrderedDict((sr.name, Series(sr.values, new_index, sr.dtype, sr.name))\n                                   for sr in self._iter())\n            del new_data[keys]\n\n            return DataFrame(new_data, new_index)\n        elif isinstance(keys, list):\n            check_inner_types(keys, str)\n\n            new_index_data = []\n            for column_name in keys:\n                column = self._data[column_name]\n                new_index_data.append(Index(column.values, column.dtype, column.name))\n            new_index = MultiIndex(new_index_data, keys)\n\n            new_data = OrderedDict((sr.name, Series(sr.values, new_index, sr.dtype, sr.name))\n                                   for sr in self._iter())\n            for column_name in keys:\n                del new_data[column_name]\n\n            return DataFrame(new_data, new_index)\n        else:\n            raise TypeError('Expected a string or a list of strings')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting the index of the DataFrame.", "response": "def sort_index(self, ascending=True):\n        \"\"\"Sort the index of the DataFrame.\n\n        Currently MultiIndex is not supported since Weld is missing multiple-column sort.\n\n        Note this is an expensive operation (brings all data to Weld).\n\n        Parameters\n        ----------\n        ascending : bool, optional\n\n        Returns\n        -------\n        DataFrame\n            DataFrame sorted according to the index.\n\n        \"\"\"\n        if isinstance(self.index, MultiIndex):\n            raise NotImplementedError('Weld does not yet support sorting on multiple columns')\n\n        return self.sort_values(self.index._gather_names(), ascending)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsorting the DataFrame by a column.", "response": "def sort_values(self, by, ascending=True):\n        \"\"\"Sort the DataFrame based on a column.\n\n        Unlike Pandas, one can sort by data from both index and regular columns.\n\n        Currently possible to sort only on a single column since Weld is missing multiple-column sort.\n        Note this is an expensive operation (brings all data to Weld).\n\n        Parameters\n        ----------\n        by : str or list of str\n            Column names to sort.\n        ascending : bool, optional\n\n        Returns\n        -------\n        DataFrame\n            DataFrame sorted according to the column.\n\n        \"\"\"\n        check_type(ascending, bool)\n        check_str_or_list_str(by)\n        by = as_list(by)\n\n        if len(by) > 1:\n            raise NotImplementedError('Weld does not yet support sorting on multiple columns')\n\n        all_data = self.reset_index()\n        by_data = all_data[by]\n\n        sorted_indices = weld_sort(by_data._gather_data_for_weld(),\n                                   by_data._gather_weld_types(),\n                                   'sort_index',\n                                   ascending=ascending)\n\n        new_index = self.index._iloc_indices(sorted_indices)\n        new_columns = list(self._iter())\n        new_column_names = [column.name for column in new_columns]\n        new_columns = [_series_iloc(column, sorted_indices, new_index) for column in new_columns]\n        new_data = OrderedDict(zip(new_column_names, new_columns))\n\n        return DataFrame(new_data, new_index)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge(self, other, how='inner', on=None, suffixes=('_x', '_y'),\n              algorithm='merge', is_on_sorted=False, is_on_unique=True):\n        \"\"\"Database-like join this DataFrame with the other DataFrame.\n\n        Currently assumes the on-column(s) values are unique!\n\n        Note there's no automatic cast if the type of the on columns differs.\n\n        Algorithms and limitations:\n\n        - Merge algorithms: merge-join or hash-join. Typical pros and cons apply when choosing between the two.\n          Merge-join shall be used on fairly equally-sized DataFrames while a hash-join would be better when\n          one of the DataFrames is (much) smaller.\n        - Limitations:\n\n          + Hash-join requires the (smaller) hashed DataFrame\n            (more precisely, the on columns) to contain no duplicates!\n          + Merge-join requires the on-columns to be sorted!\n          + For unsorted data can only sort a single column! (current Weld limitation)\n\n        - Sortedness. If the on-columns are sorted, merge-join does not require to sort the data so it can be\n          significantly faster. Do add is_on_sorted=True if this is known to be true!\n        - Uniqueness. If the on-columns data contains duplicates, the algorithm is more complicated, i.e. slow.\n          Also hash-join cannot be used on a hashed (smaller) DataFrame with duplicates. Do add is_on_unique=True\n          if this is known to be true!\n        - Setting the above 2 flags incorrectly, e.g. is_on_sorted to True when data is in fact not sorted,\n          will produce undefined results.\n\n        Parameters\n        ----------\n        other : DataFrame\n            With which to merge.\n        how : {'inner', 'left', 'right', 'outer'}, optional\n            Which kind of join to do.\n        on : str or list or None, optional\n            The columns from both DataFrames on which to join.\n            If None, will join on the index if it has the same name.\n        suffixes : tuple of str, optional\n            To append on columns not in `on` that have the same name in the DataFrames.\n        algorithm : {'merge', 'hash'}, optional\n            Which algorithm to use. Note that for 'hash', the `other` DataFrame is the one hashed.\n        is_on_sorted : bool, optional\n            If we know that the on columns are already sorted, can employ faster algorithm. If False,\n            the DataFrame will first be sorted by the on columns.\n        is_on_unique : bool, optional\n            If we know that the values are unique, can employ faster algorithm.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame containing the merge result, with the `on` columns as index.\n\n        \"\"\"\n        check_type(other, DataFrame)\n        check_type(how, str)\n        check_type(algorithm, str)\n        check_str_or_list_str(on)\n        check_inner_types(check_type(suffixes, tuple), str)\n        check_type(is_on_sorted, bool)\n        check_type(is_on_unique, bool)\n\n        # TODO: change defaults on flag & remove after implementation\n        assert is_on_unique\n\n        # TODO: this materialization/cache step could be skipped by encoding the whole sort + merge;\n        # TODO this would use the sorted on columns from weld_sort ($.1) in the join to obtain join-output-indices\n        # TODO which would then be passed through a 'translation table' (of $.0) to obtain the original indices to keep\n        if not is_on_sorted:\n            self_df = self.sort_values(on)\n            other_df = other.sort_values(on)\n        else:\n            self_df = self\n            other_df = other\n\n        self_reset = self_df.reset_index()\n        other_reset = other_df.reset_index()\n        on = _compute_on(self_df, other_df, on,\n                         self_reset._gather_column_names(),\n                         other_reset._gather_column_names())\n        self_on_cols = self_reset[on]\n        other_on_cols = other_reset[on]\n\n        if algorithm == 'merge':\n            # for left and right joins, the on columns can just be copied; no need for filter\n            def fake_filter_func(x, y, z):\n                return x\n\n            if how == 'inner':\n                index_filter_func = weld_iloc_indices\n                data_filter_func = _series_iloc\n                weld_merge_func = weld_merge_join\n            elif how in {'left', 'right'}:\n                index_filter_func = fake_filter_func\n                data_filter_func = _series_iloc_with_missing\n                weld_merge_func = weld_merge_join\n            else:\n                index_filter_func = fake_filter_func\n                data_filter_func = _series_iloc_with_missing\n                weld_merge_func = weld_merge_outer_join\n\n            weld_objects_indexes = weld_merge_func(self_on_cols._gather_data_for_weld(),\n                                                   self_on_cols._gather_weld_types(),\n                                                   other_on_cols._gather_data_for_weld(),\n                                                   other_on_cols._gather_weld_types(),\n                                                   how, is_on_sorted, is_on_unique, 'merge-join')\n\n            new_index = _compute_new_index(weld_objects_indexes, how, on,\n                                           self_on_cols, other_on_cols,\n                                           index_filter_func)\n\n            new_data = OrderedDict()\n            self_no_on = self_reset.drop(on)\n            other_no_on = other_reset.drop(on)\n            self_new_names, other_new_names = _compute_new_names(self_no_on._gather_column_names(),\n                                                                 other_no_on._gather_column_names(),\n                                                                 suffixes)\n\n            for column_name, new_name in zip(self_no_on, self_new_names):\n                new_data[new_name] = data_filter_func(self_no_on[column_name], weld_objects_indexes[0], new_index)\n\n            for column_name, new_name in zip(other_no_on, other_new_names):\n                new_data[new_name] = data_filter_func(other_no_on[column_name], weld_objects_indexes[1], new_index)\n\n            return DataFrame(new_data, new_index)\n        elif algorithm == 'hash':\n            raise NotImplementedError('Not yet supported')\n        else:\n            raise NotImplementedError('Only merge- and hash-join algorithms are supported')", "response": "This function will join two DataFrames together and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef drop_duplicates(self, subset=None, keep='min'):\n        subset = check_and_obtain_subset_columns(subset, self)\n\n        df = self.reset_index()\n        df_names = df._gather_column_names()\n        subset_indices = [df_names.index(col_name) for col_name in subset]\n\n        weld_objects = weld_drop_duplicates(df._gather_data_for_weld(),\n                                            df._gather_weld_types(),\n                                            subset_indices,\n                                            keep)\n\n        index_data = self.index._gather_data(name=None)\n        new_index = [Index(weld_objects[i], v.dtype, k)\n                     for i, k, v in zip(list(range(len(index_data))), index_data.keys(), index_data.values())]\n        if len(new_index) > 1:\n            new_index = MultiIndex(new_index, self.index._gather_names())\n        else:\n            new_index = new_index[0]\n\n        new_data = OrderedDict((sr.name, Series(obj, new_index, sr.dtype, sr.name))\n                               for sr, obj in zip(self._iter(), weld_objects[len(index_data):]))\n\n        return DataFrame(new_data, new_index)", "response": "Return a new DataFrame with duplicate rows removed optionally only considering subset columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new DataFrame with missing values removed.", "response": "def dropna(self, subset=None):\n        \"\"\"Remove missing values according to Baloo's convention.\n\n        Parameters\n        ----------\n        subset : list of str, optional\n            Which columns to check for missing values in.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with no null values in columns.\n\n        \"\"\"\n        subset = check_and_obtain_subset_columns(subset, self)\n        not_nas = [v.notna() for v in self[subset]._iter()]\n        and_filter = reduce(lambda x, y: x & y, not_nas)\n\n        return self[and_filter]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fillna(self, value):\n        if is_scalar(value):\n            new_data = OrderedDict((column.name, column.fillna(value))\n                                   for column in self._iter())\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(value, dict):\n            new_data = OrderedDict((column.name, column.fillna(value[column.name]) if column.name in value else column)\n                                   for column in self._iter())\n\n            return DataFrame(new_data, self.index)\n        else:\n            raise TypeError('Can only fill na given a scalar or a dict mapping columns to their respective scalar')", "response": "Returns a new DataFrame with missing values replaced with value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngroup by certain columns excluding index.", "response": "def groupby(self, by):\n        \"\"\"Group by certain columns, excluding index.\n\n        Simply reset_index if desiring to group by some index column too.\n\n        Parameters\n        ----------\n        by  : str or list of str\n            Column(s) to groupby.\n\n        Returns\n        -------\n        DataFrameGroupBy\n            Object encoding the groupby operation.\n\n        \"\"\"\n        check_str_or_list_str(by)\n        by = as_list(by)\n        if len(set(by)) == len(self._data):\n            raise ValueError('Cannot groupby all columns')\n\n        from .groupby import DataFrameGroupBy\n\n        return DataFrameGroupBy(self, by)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating baloo DataFrame from pandas DataFrame.", "response": "def from_pandas(cls, df):\n        \"\"\"Create baloo DataFrame from pandas DataFrame.\n\n        Parameters\n        ----------\n        df : pandas.frame.DataFrame\n\n        Returns\n        -------\n        DataFrame\n\n        \"\"\"\n        from pandas import DataFrame as PandasDataFrame, Index as PandasIndex, MultiIndex as PandasMultiIndex\n\n        check_type(df, PandasDataFrame)\n\n        if isinstance(df.index, PandasIndex):\n            baloo_index = Index.from_pandas(df.index)\n        elif isinstance(df.index, PandasMultiIndex):\n            baloo_index = MultiIndex.from_pandas(df.index)\n        else:\n            raise TypeError('Cannot convert pandas index of type={} to baloo'.format(type(df.index)))\n\n        baloo_data = OrderedDict((column_name, _series_from_pandas(df[column_name], baloo_index))\n                                 for column_name in df)\n\n        return DataFrame(baloo_data, baloo_index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert to pandas DataFrame.", "response": "def to_pandas(self):\n        \"\"\"Convert to pandas DataFrame.\n\n        Note the data is expected to be evaluated.\n\n        Returns\n        -------\n        pandas.frame.DataFrame\n\n        \"\"\"\n        from pandas import DataFrame as PandasDataFrame\n\n        pandas_index = self.index.to_pandas()\n        pandas_data = OrderedDict((column.name, column.to_pandas())\n                                  for column in self._iter())\n\n        return PandasDataFrame(pandas_data, pandas_index)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_csv(self, filepath, sep=',', header=True, index=True):\n        from ..io import to_csv\n\n        return to_csv(self, filepath, sep=sep, header=header, index=index)", "response": "Save DataFrame as csv."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a request to the babelfy api and babelfy param text set self. _data with the babelfied text as json object", "response": "def babelfy(self, text, params=None):\n        \"\"\"make a request to the babelfy api and babelfy param text\n        set self._data with the babelfied text as json object\n        \"\"\"\n        self._entities = list()\n        self._all_entities = list()\n        self._merged_entities = list()\n        self._all_merged_entities = list()\n        self._text = \" \".join(word.strip() for word in text.split())\n\n        params = params or self._params\n        params['key'] = self._api_key\n        params['text'] = self._text\n        if (sys.version < '3' and isinstance(params['text'], unicode)) or (sys.version >= '3' and isinstance(params['text'], bytes)): #pylint: disable=undefined-variable\n            params['text'] = params['text'].encode('utf-8')\n        url = BABELFY_API_URL + '?' + urlencode(params)\n\n        request = Request(url)\n        request.add_header('Accept-encoding', 'gzip')\n        response = urlopen(request)\n        if sys.version < '3':\n            buf = StringIO(response.read())\n        else:\n            buf = BytesIO(response.read())\n        f = gzip.GzipFile(fileobj=buf)\n        reader = codecs.getreader('utf-8')\n        self._data = json.load(reader(f))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_entities(self):\n        entities = list()\n\n        for result in self._data:\n            entity = dict()\n            char_fragment = result.get('charFragment')\n            start = char_fragment.get('start')\n            end = char_fragment.get('end')\n            entity['start'] = start\n            entity['end'] = end\n            entity['text'] = self._text[start: end+1]\n            if sys.version < '3' and isinstance(entity['text'], str):\n                entity['text'] = entity['test'].decode('utf-8')\n            entity['isEntity'] = True\n            for key, value in result.items():\n                entity[key] = value\n            entities.append(entity)\n        self._entities = entities", "response": "enrich the babelfied data with the text an the isEntity items\n        set self. _entities with the enriched data\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_non_entities(self):\n        def _differ(tokens):\n            inner, outer = tokens\n            not_same_start = inner.get('start') != outer.get('start')\n            not_same_end = inner.get('end') != outer.get('end')\n            return not_same_start or not_same_end\n\n        def _get_dot_token():\n            dot_token = dict()\n            dot_token['start'] = (len(self._text) - 1)\n            dot_token['end'] = dot_token['start']\n            dot_token['text'] = '.'\n            dot_token['isEntity'] = False\n            return dot_token\n\n        if self._text.endswith('.'):\n            text = self._text[:-1]\n            add_dot_token = True\n        else:\n            text = self._text\n            add_dot_token = False\n\n        index = 0\n        all_tokens = list()\n        for token in text.split():\n\n            comma_token = False\n            if token.endswith(','):\n                comma_token = True\n                token = token[:-1]\n\n            start = index\n            end = (start + len(token))\n            index += (len(token) + 1)\n\n            all_tokens.append({\n                'start': start,\n                'end': end - 1,\n                'text': self._text[start: end],\n                'isEntity': False,\n            })\n\n            if comma_token:\n                all_tokens.append({\n                    'start': index,\n                    'end': index,\n                    'text': ',',\n                    'isEntity': False,\n                })\n                index += 1\n\n        token_tuples = list(product(all_tokens, self.entities))\n        redundant = [\n            tokens[0] for tokens in token_tuples if not _differ(tokens)]\n        non_entity_tokens = [\n            item for item in all_tokens if item not in redundant]\n\n        if add_dot_token:\n            non_entity_tokens.append(_get_dot_token())\n\n        self._all_entities = sorted(\n            self._entities + non_entity_tokens, key=itemgetter('start'))", "response": "parse all non - entities in the babelfied text and set self. _all_entities with merged entity and non - entity data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_merged_entities(self):\n        self._merged_entities = list(filterfalse(\n            lambda token: self._is_wrapped(token, self.entities),\n            self.entities))", "response": "parse the merged entities"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting self. _all_merged_entities to the longest possible non - entity tokens including non - entity tokens", "response": "def _parse_all_merged_entities(self):\n        \"\"\"set self._all_merged_entities to the longest possible(wrapping)\n        tokens including non-entity tokens\n        \"\"\"\n        self._all_merged_entities = list(filterfalse(\n            lambda token: self._is_wrapped(token, self.all_entities),\n            self.all_entities))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if a token is wrapped by another token", "response": "def _wraps(self, tokens):\n        \"\"\"determine if a token is wrapped by another token\n        \"\"\"\n        def _differ(tokens):\n            inner, outer = tokens\n            not_same_start = inner.get('start') != outer.get('start')\n            not_same_end = inner.get('end') != outer.get('end')\n            return not_same_start or not_same_end\n\n        def _in_range(tokens):\n            inner, outer = tokens\n            starts_in = outer.get('start') <= inner.get('start') \\\n                <= outer.get('end')\n            ends_in = outer.get('start') <= inner.get('end') \\\n                <= outer.get('end')\n            return starts_in and ends_in\n\n        if not _differ(tokens):\n            return False\n\n        return _in_range(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if param token is wrapped by any token in tokens", "response": "def _is_wrapped(self, token, tokens):\n        \"\"\"check if param token is wrapped by any token in tokens\n        \"\"\"\n        for t in tokens:\n            is_wrapped = self._wraps((token, t))\n            if is_wrapped:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, joinpoint):\n\n        if self._enable:\n            result = self._impl(joinpoint)\n\n        else:\n            result = joinpoint.proceed()\n\n        return result", "response": "Apply this advice on input joinpoint."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_enable(target, enable=True, advice_ids=None):\n\n        advices = get_advices(target)\n\n        for advice in advices:\n            try:\n                if isinstance(Advice) \\\n                        and (advice_ids is None or advice.uuid in advice_ids):\n                    advice.enable = enable\n            except ValueError:\n                pass", "response": "Enable or disable all target Advices designated by input advice_ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef weave(target, advices, pointcut=None, depth=1, public=False):\n\n        advices = (\n            advice if isinstance(advice, Advice) else Advice(advice)\n            for advice in advices\n        )\n\n        weave(\n            target=target, advices=advices, pointcut=pointcut,\n            depth=depth, public=public\n        )", "response": "Weave advices such as Advice objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms the underlying experiment and summarise its results. Our results are the summary statistics extracted from the results of the instances of the underlying experiment that we performed. We drop from the calculations any experiments whose completion status was False, indicating an error. Our own completion status will be True unless we had an error summarising a field (usually caused by trying to summarise non-numeric data). We record the exceptions generated by any experiment we summarise under the metadata key :attr:`SummaryExperiment.UNDERLYING_EXCEPTIONS` :param params: the parameters to the underlying experiment :returns: the summary statistics of the underlying results", "response": "def do( self, params ):\n        \"\"\"Perform the underlying experiment and summarise its results.\n        Our results are the summary statistics extracted from the results of\n        the instances of the underlying experiment that we performed.\n\n        We drop from the calculations any experiments whose completion status\n        was False, indicating an error. Our own completion status will be\n        True unless we had an error summarising a field (usually caused by trying\n        to summarise non-numeric data).\n\n        We record the exceptions generated by any experiment we summarise under\n        the metadata key :attr:`SummaryExperiment.UNDERLYING_EXCEPTIONS`\n\n        :param params: the parameters to the underlying experiment\n        :returns: the summary statistics of the underlying results\"\"\"\n\n        # perform the underlying experiment\n        rc = self.experiment().run()\n        \n        # extract the result dicts as a list\n        results = rc[Experiment.RESULTS]\n        if not isinstance(results, list):\n            # force to list\n            results = [ rc ]\n\n        # extract only the successful runs\n        sresults = [ res for res in results if res[Experiment.METADATA][Experiment.STATUS] ]\n        exs = [ res[Experiment.METADATA][Experiment.EXCEPTION] for res in results if not res[Experiment.METADATA][Experiment.STATUS] ]\n       \n        # add extra values to our metadata record\n        self._metadata[self.UNDERLYING_RESULTS]            = len(results)\n        self._metadata[self.UNDERLYING_SUCCESSFUL_RESULTS] = len(sresults)\n        self._metadata[self.UNDERLYING_EXCEPTIONS]         = exs\n\n        # construct summary results\n        return self.summarise(sresults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts spreadsheet coordinates to zero - index xy coordinates. return None if input is invalid", "response": "def ss_to_xy(s: str):\n    \"\"\"convert spreadsheet coordinates to zero-index xy coordinates.\n    return None if input is invalid\"\"\"\n    result = re.match(r'\\$*([A-Z]+)\\$*([0-9]+)', s, re.I)\n    if result == None:\n        return None\n    xstring = result.group(1).upper()\n    multiplier = 1\n    x = 0\n    for i in xstring:\n        x = x * multiplier + (ord(i) - 64)\n        multiplier = multiplier * 26\n    x = x - 1\n    y = int(result.group(2))-1\n    return (x,y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open( self ):\n        if self._connection is None:\n            self._connection = sqlite3.connect(self._dbfile)", "response": "Open the database connection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef alchemyencoder(obj):\n    if isinstance(obj, datetime.date):\n        return obj.isoformat()\n    elif isinstance(obj, decimal.Decimal):\n        return float(obj)", "response": "JSON encoder function for SQLAlchemy special classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate(self, request):\n        auth = get_authorization_header(request).split()\n\n        if not auth or auth[0].lower() != b'token':\n            return None\n\n        if len(auth) == 1:\n            msg = _('Invalid auth token header. No credentials provided.')\n            raise AuthenticationFailed(msg)\n        elif len(auth) > 2:\n            msg = _('Invalid auth token.')\n            raise AuthenticationFailed(msg)\n\n        try:\n            token = urlsafe_b64decode(auth[1])\n        except ValueError:\n            msg = _('Invalid auth token.')\n            raise AuthenticationFailed(msg)\n\n        return self.authenticate_credentials(token, request)", "response": "Authenticate the request and return a two - tuple of user and token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticate_credentials(self, token: bytes, request=None):\n        user = AuthToken.get_user_for_token(token)\n\n        if user is None:\n            raise AuthenticationFailed(_('Invalid auth token.'))\n\n        if not user.is_active:\n            raise AuthenticationFailed(_('User inactive or deleted.'))\n\n        return user, token", "response": "Authenticate the token with optional request for context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new action and return it.", "response": "def create(self, target, target_type=None, **kwds):\n        \"\"\"\n        Endpoint: /action/<target_id>/<target_type>/create.json\n\n        Creates a new action and returns it.\n        The target parameter can either be an id or a Trovebox object.\n        If a Trovebox object is used, the target type is inferred\n        automatically.\n        \"\"\"\n        # Extract the target type\n        if target_type is None:\n            target_type = target.get_type()\n\n        # Extract the target ID\n        try:\n            target_id = target.id\n        except AttributeError:\n            target_id = target\n\n        result = self._client.post(\"/action/%s/%s/create.json\" %\n                                   (target_id, target_type),\n                                   **kwds)[\"result\"]\n        return Action(self._client, result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view(self, action, **kwds):\n        result = self._client.get(\"/action/%s/view.json\" %\n                                  self._extract_id(action),\n                                  **kwds)[\"result\"]\n        return Action(self._client, result)", "response": "This endpoint provides a view of all properties of an action."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set(self, key, *args):\n        return self.cache.set(self._hashed(key), *args)", "response": "Set the value of the key in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_conv(bits, bin_point, signed=False, scaling=1.0):\n    conversion_t = {}\n    conversion_t[\"bits\"] = bits\n    conversion_t[\"bin_point\"] = bin_point\n    conversion_t[\"signed\"] = signed\n    conversion_t[\"scaling\"] = scaling\n    conversion_t[\"dec_step\"] = 1.0 / (2 ** bin_point)\n    #dec_max = dec_mask * dec_step\n    conversion_t[\"dec_mask\"] = sum([2 ** i for i in range(bin_point)])\n    if bits == 8:\n        conversion_t[\"fmt\"] = \"B\"\n    elif bits == 16:\n        conversion_t[\"fmt\"] = \"H\"\n    elif bits == 32:\n        conversion_t[\"fmt\"] = \"I\"\n    else:\n        raise ConversionError(\"numer of bits not supported: \" + str(bits))\n    if signed:\n        _get_signed_params(conversion_t)\n    else:\n        _get_unsigned_params(conversion_t)\n    return conversion_t", "response": "Returns a I { conversion structure that can be applied in both directions of the given specs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef conv_from_name(name):\n    _match = re.match(r\"^(?P<signed>u?fix)_(?P<bits>\\d+)_(?P<binary>\\d+)\", \n            name, flags = re.I)\n    if not _match:\n        raise ConversionError(\"Cannot interpret name: \" + name)\n    params = _match.groupdict()\n    if params['signed'] == 'fix':\n        signed = True\n    else:\n        signed = False\n    bits = int(params['bits'])\n    binary = int(params['binary'])\n    return get_conv(bits, binary, signed)", "response": "Understand simulink syntax for fixed types and returns the proper\n    conversion structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_unsigned_params(conv):\n    conv[\"sign_mask\"] = 0\n    conv[\"int_min\"] = 0\n    conv[\"int_mask\"] = sum([2 ** i for i in range(conv[\"bin_point\"], \n        conv[\"bits\"])])\n    conv[\"int_max\"] = sum([2 ** i for i in range(conv[\"bits\"] -\n        conv[\"bin_point\"])])", "response": "Fill the sign - dependent params of the conv structure in case of unsigned \n    conversion\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfill the sign - dependent params of the conv structure in case of signed conversion", "response": "def _get_signed_params(conv):\n    \"\"\"\n    Fill the sign-dependent params of the conv structure in case of signed \n    conversion\n    @param conv: the structure to be filled\n    \"\"\"\n    conv[\"sign_mask\"] = 2 ** (conv[\"bits\"] - 1)\n    conv[\"int_min\"] = -1 * (2 ** (conv[\"bits\"] - 1 - conv[\"bin_point\"]))\n    conv[\"int_mask\"] = sum([2 ** i \n        for i in range(conv[\"bin_point\"], conv[\"bits\"] - 1)])\n    conv[\"int_max\"] = sum([2 ** i for i in range(conv[\"bits\"] -\n        conv[\"bin_point\"] - 1)])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix2real(uval, conv):\n    res = 0\n    int_val =  ((uval & conv[\"int_mask\"]) >> conv[\"bin_point\"])\n    dec_val = conv[\"dec_step\"] * (uval & conv[\"dec_mask\"])\n    if conv[\"signed\"] and (uval & conv[\"sign_mask\"] > 0):\n        res = conv[\"int_min\"] + int_val + dec_val\n    else: \n        res = int_val + dec_val\n    return (res / conv[\"scaling\"])", "response": "Convert a 32 bit unsigned int register into a real number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bin2real(binary_string, conv, endianness=\"@\"):\n    data = struct.unpack(endianness + conv[\"fmt\"], binary_string)[0]\n    return fix2real(data, conv)", "response": "Converts a binary string representing a number to its Fixed arithmetic representation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stream2real(binary_stream, conv, endianness=\"@\"):\n    size = len(binary_stream) // (conv[\"bits\"] // 8)\n    fmt = endianness + str(size) + conv[\"fmt\"]\n    data = struct.unpack(fmt, binary_stream)\n    data = [fix2real(d, conv) for d in data]\n    return data", "response": "Converts a binary stream into a sequence of real numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a real number into its fixed representation so that it can be written into a 32 bit register.", "response": "def real2fix(real, conv):\n    \"\"\"\n    Convert a real number to its fixed representation so \n    that it can be written into a 32 bit register.\n    @param real: the real number to be converted into fixed representation\n    @param conv: conv structre with conversion specs\n    @return: the fixed representation of the real number \n    @raise ConverisonError: if conv structre can't handle the real number.\n    @todo: Better error detection and management of unsupported \n    operations and arguments\n    \"\"\"\n    if not conv[\"signed\"] and real < 0:\n        raise ConversionError(\"cannot convert \" + \n                str(real) + \" to unsigned representation\")\n    if real < 0:\n        sign = 1\n        real = real - conv[\"int_min\"] \n    else:\n        sign = 0\n    int_val, dec_val = divmod(abs(real), 1)\n    int_val = int(int_val)\n    int_val = int_val & (conv[\"int_mask\"] >> conv[\"bin_point\"])\n    val = int_val\n    dec = 0\n    dec = dec_val // conv[\"dec_step\"]\n    if dec > conv[\"dec_mask\"]:\n        dec = conv[\"dec_mask\"]\n    dec_val = dec * conv[\"dec_step\"]\n    val += dec_val\n    if (val - real) > (real - val + conv[\"dec_step\"]):\n        dec -= 1\n    if sign == 1:\n        return conv[\"sign_mask\"] + ((int_val << conv[\"bin_point\"]) &\n                conv[\"int_mask\"]) + dec\n    else:\n        return ((int_val << conv[\"bin_point\"]) & conv[\"int_mask\"]) + dec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _emulated(self, timeout=None):\n\n        # A set of queues we've already tried.\n        tried = set()\n\n        while True:\n            # Get the next queue in the cycle, and try to get an item off it.\n            try:\n                queue = self.cycle.next()\n            except StopIteration:\n                raise Empty(\"No queues registered\")\n            try:\n                item = queue.get()\n            except Empty:\n                # raises Empty when we've tried all of them.\n                tried.add(queue.name)\n                if tried == self.all:\n                    raise\n            else:\n                return item, queue.name", "response": "Get the next message avaiable in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fallback_render(template, context, at_paths=None,\n                    at_encoding=anytemplate.compat.ENCODING,\n                    **kwargs):\n    \"\"\"\n    Render from given template and context.\n\n    This is a basic implementation actually does nothing and just returns\n    the content of given template file `template`.\n\n    :param template: Template file path\n    :param context: A dict or dict-like object to instantiate given\n        template file\n    :param at_paths: Template search paths\n    :param at_encoding: Template encoding\n    :param kwargs: Keyword arguments passed to the template engine to\n        render templates with specific features enabled.\n\n    :return: Rendered result string\n    \"\"\"\n    tmpl = anytemplate.utils.find_template_from_path(template, at_paths)\n    if tmpl is None:\n        raise TemplateNotFound(\"template: %s\" % template)\n\n    try:\n        return anytemplate.compat.copen(tmpl, encoding=at_encoding).read()\n    except UnicodeDecodeError:\n        return open(tmpl).read()", "response": "Fallback render method that returns the content of the given template file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_kwargs(keys, kwargs):\n    for k in keys:\n        if k in kwargs:\n            yield (k, kwargs[k])", "response": "Filter the kwargs dictionary of items in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_options(cls, kwargs, keys):\n        return dict((k, v) for k, v in filter_kwargs(keys, kwargs))", "response": "Make optional kwargs valid and optimized for each template engines."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a given template content with optional context.", "response": "def renders(self, template_content, context=None, at_paths=None,\n                at_encoding=anytemplate.compat.ENCODING, **kwargs):\n        \"\"\"\n        :param template_content: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file or None\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        kwargs = self.filter_options(kwargs, self.render_valid_options())\n        paths = anytemplate.utils.mk_template_paths(None, at_paths)\n        if context is None:\n            context = {}\n\n        LOGGER.debug(\"Render template %s... %s context, options=%s\",\n                     template_content[:10],\n                     \"without\" if context is None else \"with a\",\n                     str(kwargs))\n        return self.renders_impl(template_content, context, at_paths=paths,\n                                 at_encoding=at_encoding, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering a given template file and return the rendered string.", "response": "def render(self, template, context=None, at_paths=None,\n               at_encoding=anytemplate.compat.ENCODING, **kwargs):\n        \"\"\"\n        :param template: Template file path\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        kwargs = self.filter_options(kwargs, self.render_valid_options())\n        paths = anytemplate.utils.mk_template_paths(template, at_paths)\n        if context is None:\n            context = {}\n\n        LOGGER.debug(\"Render template %s %s context, options=%s\",\n                     template, \"without\" if context is None else \"with a\",\n                     str(kwargs))\n        return self.render_impl(template, context, at_paths=paths,\n                                at_encoding=at_encoding, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the first principle components", "response": "def PCA(Y, components):\n\t\"\"\"\n\trun PCA, retrieving the first (components) principle components\n\treturn [s0, eig, w0]\n\ts0: factors\n\tw0: weights\n\t\"\"\"\n\n\tN,D = Y.shape\n\tsv = linalg.svd(Y, full_matrices=0);\n\t[s0, w0] = [sv[0][:, 0:components], np.dot(np.diag(sv[1]), sv[2]).T[:, 0:components]]\n\tv = s0.std(axis=0)\n\ts0 /= v;\n\tw0 *= v;\n\treturn [s0, w0]\n\n\tif N>D:\n\t\tsv = linalg.svd(Y, full_matrices=0);\n\t\t[s0, w0] = [sv[0][:, 0:components], np.dot(np.diag(sv[1]), sv[2]).T[:, 0:components]]\n\t\tv = s0.std(axis=0)\n\t\ts0 /= v;\n\t\tw0 *= v;\n\t\treturn [s0, w0]\n\telse:\n\t\tK=np.cov(Y)\n\t\tsv = linalg.eigh(K)\n\t\tstd_var = np.sqrt(sv[0])\n\t\tpc = sv[1]*std_var[np.newaxis(),0]\n\t\t#import ipdb\n\t\t#ipdb.set_trace()\n\t\treturn [pc,std_var]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef PC_varExplained(Y,standardized=True):\n    # figuring out the number of latent factors\n    if standardized:\n        Y-=Y.mean(0)\n        Y/=Y.std(0)\n    covY = sp.cov(Y)\n    S,U = linalg.eigh(covY+1e-6*sp.eye(covY.shape[0]))\n    S = S[::-1]\n    rv = np.array([S[0:i].sum() for i in range(1,S.shape[0])])\n    rv/= S.sum()\n    return rv", "response": "Run PCA and calculate the cumulative fraction of variance explained\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(tex_file, output, verbose):\n    Controller(OSFileSystem(), Display(sys.stdout, verbose)).run(tex_file, output)", "response": "This function is used to run FLaP on a LaTeX project. It reads a LaTeX file and merges it into a single LaTeX file that refers to images in the same directory. It generates a flatten version of the LaTeX file that is then copied to the output directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deploy(overwrite=False):\n    check_settings()\n    if overwrite:\n        rmvirtualenv()\n    deploy_funcs = [deploy_project,deploy_templates, deploy_static, deploy_media,  deploy_webconf, deploy_wsgi]\n    if not patch_project() or overwrite:\n        deploy_funcs = [deploy_db,mkvirtualenv,pip_install_requirements] + deploy_funcs\n    for func in deploy_funcs: func()", "response": "Deploy a versioned project on the host"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setupnode(overwrite=False):\n    if not port_is_open():\n        if not skip_disable_root():\n            disable_root()\n        port_changed = change_ssh_port()\n    #avoid trying to take shortcuts if setupnode did not finish \n    #on previous execution\n    if server_state('setupnode-incomplete'):\n        env.overwrite=True\n    else: set_server_state('setupnode-incomplete')\n    upload_ssh_key()\n    restrict_ssh()\n    add_repositories()\n    upgrade_packages()\n    setup_ufw()\n    uninstall_packages()\n    install_packages()\n\n    upload_etc()\n    post_install_package()\n    setup_ufw_rules()\n    set_timezone()\n    set_server_state('setupnode-incomplete',delete=True)\n    #stop and start webservers - and reload nginx\n    for s in webserver_list():\n        stop_webserver(s)\n        start_webserver(s)", "response": "Install a baseline host. Can be run multiple times."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef splitGeno(pos,method='slidingWindow',size=5e4,step=None,annotation_file=None,cis=1e4,funct=None,out_file=None):\n    assert method in ['slidingWindow','geneWindow'], 'method not known'\n\n    # create folder if does not exists\n    out_dir, fname = os.path.split(out_file)\n    if (out_dir!='') and (not os.path.exists(out_dir)): os.makedirs(out_dir)\n\n    # calculates windows using the indicated method\n    if method=='slidingWindow':\n        nWnds,nSnps = splitGenoSlidingWindow(pos,out_file,size=size,step=step)\n    elif method=='geneWindow':\n        #out = splitGenoGeneWindow(pos,out_file,annotation_file=annotation_file,cis=cis,funct=funct)\n        pass\n\n    return nWnds,nSnps", "response": "split geno into windows and store output in csv file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef splitGenoSlidingWindow(pos,out_file,size=5e4,step=None):\n    if step is None:    step = 0.5*size\n    chroms = SP.unique(pos[:,0])\n\n    RV = []\n    wnd_i = 0\n    wnd_file = csv.writer(open(out_file,'w'),delimiter='\\t')\n    nSnps = [] \n    for chrom_i in chroms:\n        Ichrom = pos[:,0]==chrom_i\n        idx_chrom_start = SP.where(Ichrom)[0][0]\n        pos_chr = pos[Ichrom,1]\n        start = pos_chr.min()\n        pos_chr_max = pos_chr.max()\n        while 1:\n            if start>pos_chr_max: break\n            end = start+size\n            Ir = (pos_chr>=start)*(pos_chr<end)\n            _nSnps = Ir.sum()\n            if _nSnps>0:\n                idx_wnd_start = idx_chrom_start+SP.where(Ir)[0][0]\n                nSnps.append(_nSnps)\n                line = SP.array([wnd_i,chrom_i,start,end,idx_wnd_start,_nSnps],dtype=int)\n                wnd_file.writerow(line)\n                wnd_i+=1\n            start += step\n    nSnps = SP.array(nSnps)\n    return wnd_i,nSnps", "response": "Split a Geno sliding window into windows using a slide criterion."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef publish(self, daap_server, preferred_database=None):\n\n        if daap_server in self.daap_servers:\n            self.unpublish(daap_server)\n\n        # Zeroconf can advertise the information for one database only. Since\n        # the protocol supports multiple database, let the user decide which\n        # database to advertise. If none is specified, take the first one.\n        provider = daap_server.provider\n\n        try:\n            if preferred_database is not None:\n                database = provider.server.databases[preferred_database]\n            else:\n                database = provider.server.databases.values()[0]\n        except LookupError:\n            # The server may not have any databases (yet).\n            return\n\n        # The IP 0.0.0.0 tells this server to bind to all interfaces. However,\n        # Bonjour advertises itself to others, so others need an actual IP.\n        # There is definately a better way, but it works.\n        if daap_server.ip == \"0.0.0.0\":\n            addresses = []\n\n            for address in zeroconf.get_all_addresses(socket.AF_INET):\n                if not address == \"127.0.0.1\":\n                    addresses.append(socket.inet_aton(address))\n        else:\n            addresses = [socket.inet_aton(daap_server.ip)]\n\n        # Determine machine ID and database ID, depending on the provider. If\n        # the provider has no support for persistent IDs, generate a random\n        # ID.\n        if provider.supports_persistent_id:\n            machine_id = hex(provider.server.persistent_id)\n            database_id = hex(database.persistent_id)\n        else:\n            machine_id = hex(generate_persistent_id())\n            database_id = hex(generate_persistent_id())\n\n        # iTunes 11+ uses more properties, but this seems to be sufficient.\n        description = {\n            \"txtvers\": \"1\",\n            \"Password\": str(int(bool(daap_server.password))),\n            \"Machine Name\": provider.server.name,\n            \"Machine ID\": machine_id.upper(),\n            \"Database ID\": database_id.upper()\n        }\n\n        # Test is zeroconf supports multiple addresses or not. For\n        # compatibility with zeroconf 0.17.3 or less.\n        if not hasattr(zeroconf.ServiceInfo(\"\", \"\"), \"addresses\"):\n            addresses = addresses[0]\n\n        self.daap_servers[daap_server] = zeroconf.ServiceInfo(\n            type=\"_daap._tcp.local.\",\n            name=provider.server.name + \"._daap._tcp.local.\",\n            address=addresses,\n            port=daap_server.port,\n            properties=description)\n        self.zeroconf.register_service(self.daap_servers[daap_server])", "response": "Publish a given DAAP Server instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpublish(self, daap_server):\n\n        if daap_server not in self.daap_servers:\n            return\n\n        self.zeroconf.unregister_service(self.daap_servers[daap_server])\n\n        del self.daap_servers[daap_server]", "response": "Unpublish a given server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd random effects term to the term list.", "response": "def addRandomEffect(self, K=None, is_noise=False, normalize=False, Kcross=None, trait_covar_type='freeform', rank=1, fixed_trait_covar=None, jitter=1e-4):\n        \"\"\"\n        Add random effects term.\n\n        Args:\n            K:      Sample Covariance Matrix [N, N]\n            is_noise:   Boolean indicator specifying if the matrix is homoscedastic noise (weighted identity covariance) (default False)\n            normalize:  Boolean indicator specifying if K has to be normalized such that K.trace()=N.\n            Kcross:            NxNtest cross covariance for predictions\n            trait_covar_type: type of covaraince to use. Default 'freeform'. possible values are\n                            'freeform':  general semi-definite positive matrix,\n                            'fixed': fixed matrix specified in fixed_trait_covar,\n                            'diag': diagonal matrix,\n                            'lowrank': low rank matrix. The rank of the lowrank part is specified in the variable rank,\n                            'lowrank_id': sum of a lowrank matrix and a multiple of the identity. The rank of the lowrank part is specified in the variable rank,\n                            'lowrank_diag': sum of a lowrank and a diagonal matrix. The rank of the lowrank part is specified in the variable rank,\n                            'block': multiple of a matrix of ones,\n                            'block_id': sum of a multiple of a matrix of ones and a multiple of the idenity,\n                            'block_diag': sum of a multiple of a matrix of ones and a diagonal matrix,\n            rank:       rank of a possible lowrank component (default 1)\n            fixed_trait_covar:   PxP matrix for the (predefined) trait-to-trait covariance matrix if fixed type is used\n            jitter:        diagonal contribution added to trait-to-trait covariance matrices for regularization\n        \"\"\"\n        assert K is not None or is_noise, 'VarianceDecomposition:: Specify covariance structure'\n\n        if is_noise:\n            assert self.noisPos is None, 'VarianceDecomposition:: Noise term already exists'\n            K  = sp.eye(self.N)\n            Kcross = None\n            self.noisPos = self.n_randEffs\n        else:\n            assert K.shape[0]==self.N, 'VarianceDecomposition:: Incompatible shape for K'\n            assert K.shape[1]==self.N, 'VarianceDecomposition:: Incompatible shape for K'\n        if Kcross is not None:\n            assert self.Ntest is not None, 'VarianceDecomposition:: specify Ntest for predictions (method VarianceDecomposition::setTestSampleSize)'\n            assert Kcross.shape[0]==self.N, 'VarianceDecomposition:: Incompatible shape for Kcross'\n            assert Kcross.shape[1]==self.Ntest, 'VarianceDecomposition:: Incompatible shape for Kcross'\n\n        if normalize:\n            cc = covar_rescaling_factor(K) \n            K *= cc\n            if Kcross is not None: Kcross *= cc \n\n        # add random effect\n        self.sample_covars.append(K)\n        self.sample_cross_covars.append(Kcross)\n        _cov = self._buildTraitCovar(trait_covar_type=trait_covar_type, rank=rank, fixed_trait_covar=fixed_trait_covar, jitter=jitter)\n        self.trait_covars.append(_cov)\n        self.n_randEffs+=1\n\n        #TODO: define _sync function\n        self._desync()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addFixedEffect(self, F=None, A=None, Ftest=None):\n        if A is None:\n            A = sp.eye(self.P)\n        if F is None:\n            F = sp.ones((self.N,1))\n            if self.Ntest is not None:\n                Ftest = sp.ones((self.Ntest,1))\n\n        assert A.shape[1]==self.P, 'VarianceDecomposition:: A has incompatible shape'\n        assert F.shape[0]==self.N, 'VarianceDecimposition:: F has incompatible shape'\n\n        if Ftest is not None:\n            assert self.Ntest is not None, 'VarianceDecomposition:: specify Ntest for predictions (method VarianceDecomposition::setTestSampleSize)'\n            assert Ftest.shape[0]==self.Ntest, 'VarianceDecimposition:: Ftest has incompatible shape'\n            assert Ftest.shape[1]==F.shape[1], 'VarianceDecimposition:: Ftest has incompatible shape'\n\n        # add fixed effect\n        self.sample_designs.append(F)\n        self.sample_test_designs.append(Ftest)\n        self.trait_designs.append(A)\n \n        self._desync()", "response": "add fixed effect term to the model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noptimize the model by the specified initialization strategy", "response": "def optimize(self, init_method='default', inference=None, n_times=10, perturb=False, pertSize=1e-3, verbose=None):\n        \"\"\"\n        Train the model using the specified initialization strategy\n\n        Args:\n            init_method:    initialization strategy:\n                                'default': variance is equally split across the different random effect terms. For mulit-trait models the empirical covariance between traits is used\n                                'random': variance component parameters (scales) are sampled from a normal distribution with mean 0 and std 1,\n                                None: no initialization is considered. Initial parameters can be specifies by using the single covariance getTraitCovarfun() \n            inference:      inference gp method, by default algebrically efficient inference (i.e., gp2kronSum, gp2KronSumLR, gp3KronSumLR) will be used when possible.\n                            For models with high a standard inference scheme (gp_base) will be used. \n            n_times:        number of restarts to converge\n            perturb:        if true, the initial point (if random initializaiton is not being used) is perturbed with gaussian noise for each restart (default, False)\n            perturbSize:    std of the gassian noise used to perturb the initial point\n            verbose:        print if convergence is achieved and how many restarted were needed\n        \"\"\"\n        #verbose = dlimix.getVerbose(verbose)\n        assert init_method in ['default', 'random', None], 'VarianceDecomposition: specified init_method not valid'\n        if init_method=='default':  self._init_params_default()\n\n        # determine if repeats should be considered \n        if init_method is not 'random' and not perturb:     n_times = 1\n\n        # determine inference\n        if inference is None:   inference = self._det_inference()\n        else:                   self._check_inference(inference)\n        self._inference = inference\n\n        if self.gp is None:        self._initGP()\n\n        params0 = self.gp.getParams()\n        for i in range(n_times):\n            if init_method=='random':   \n                params = {'covar': sp.randn(params0['covar'].shape[0])}\n                self.gp.setParams(params)\n            elif perturb:\n                params = {'covar': params0['covar'] + pertSize * sp.randn(params0['covar'].shape[0])}\n                self.gp.setParams(params)\n            conv, info = self.gp.optimize()\n            if conv:    break\n\n        if verbose:\n            if conv==False:\n                print('No local minimum found for the tested initialization points')\n            else:\n                print(('Local minimum found at iteration %d' % i))\n\n        return conv"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getWeights(self, term_i=None):\n        assert self.init, 'GP not initialised'\n        if term_i==None:\n            if self.gp.mean.n_terms==1:\n                term_i = 0\n            else:\n                print('VarianceDecomposition: Specify fixed effect term index')\n        return self.gp.mean.B[term_i]", "response": "Returns the weights for a given fixed effect term term_i"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTraitCovar(self, term_i=None):\n        assert term_i < self.n_randEffs, 'VarianceDecomposition:: specied term out of range'\n\n        if term_i is None:\n            RV = sp.zeros((self.P,self.P))\n            for term_i in range(self.n_randEffs):\n                RV += self.getTraitCovarFun().K()\n        else:\n            assert term_i<self.n_randEffs, 'Term index non valid'\n            RV = self.getTraitCovarFun(term_i).K()\n        return RV", "response": "Returns the estimated trait covariance matrix for the specified term"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the estimated trait correlation coefficient matrix for the given term_i", "response": "def getTraitCorrCoef(self,term_i=None):\n        \"\"\"\n        Return the estimated trait correlation coefficient matrix for term_i (or the total if term_i is None)\n            To retrieve the trait covariance matrix use \\see getTraitCovar\n\n        Args:\n            term_i:     index of the random effect term we want to retrieve the correlation coefficients\n        Returns:\n            estimated trait correlation coefficient matrix\n        \"\"\"\n        cov = self.getTraitCovar(term_i)\n        stds = sp.sqrt(cov.diagonal())[:,sp.newaxis]\n        RV = cov / stds / stds.T\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the estimated variance components of all random effects on all phenotypes", "response": "def getVarianceComps(self, univariance=False):\n        \"\"\"\n        Return the estimated variance components\n\n        Args:\n            univariance:   Boolean indicator, if True variance components are normalized to sum up to 1 for each trait\n        Returns:\n            variance components of all random effects on all phenotypes [P, n_randEffs matrix]\n        \"\"\"\n        RV=sp.zeros((self.P,self.n_randEffs))\n        for term_i in range(self.n_randEffs):\n            RV[:,term_i] = self.getTraitCovar(term_i).diagonal()\n        if univariance:\n            RV /= RV.sum(1)[:,sp.newaxis]\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_params_default(self):\n        # if there are some nan -> mean impute\n        Yimp = self.Y.copy()\n        Inan = sp.isnan(Yimp)\n        Yimp[Inan] = Yimp[~Inan].mean()\n        if self.P==1:   C = sp.array([[Yimp.var()]])\n        else:           C = sp.cov(Yimp.T)\n        C /= float(self.n_randEffs)\n        for ti in range(self.n_randEffs):\n            self.getTraitCovarFun(ti).setCovariance(C)", "response": "Internal method for default parameter initialization"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _det_inference(self):\n        # 2 random effects with complete design -> gp2KronSum\n        # TODO: add check for low-rankness, use GP3KronSumLR and GP2KronSumLR when possible\n        if (self.n_randEffs==2) and (~sp.isnan(self.Y).any()):\n            rv = 'GP2KronSum'\n        else:\n            rv = 'GP'\n        return rv", "response": "Internal method for determining the inference method for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef optimize_with_repeates(self,fast=None,verbose=None,n_times=10,lambd=None,lambd_g=None,lambd_n=None):\n        verbose = dlimix.getVerbose(verbose)\n\n        if not self.init:       self._initGP(fast)\n\n        opt_list = []\n\n        fixed0 = sp.zeros_like(self.gp.getParams()['dataTerm'])\n\n        # minimize n_times\n        for i in range(n_times):\n\n            scales1 = self._getScalesRand()\n            fixed1  = 1e-1*sp.randn(fixed0.shape[0],fixed0.shape[1])\n            conv = self.trainGP(fast=fast,scales0=scales1,fixed0=fixed1,lambd=lambd,lambd_g=lambd_g,lambd_n=lambd_n)\n\n            if conv:\n                # compare with previous minima\n                temp=1\n                for j in range(len(opt_list)):\n                    if sp.allclose(abs(self.getScales()),abs(opt_list[j]['scales'])):\n                        temp=0\n                        opt_list[j]['counter']+=1\n                        break\n                if temp==1:\n                    opt = {}\n                    opt['counter'] = 1\n                    opt['LML'] = self.getLML()\n                    opt['scales'] = self.getScales()\n                    opt_list.append(opt)\n\n\n        # sort by LML\n        LML = sp.array([opt_list[i]['LML'] for i in range(len(opt_list))])\n        index   = LML.argsort()[::-1]\n        out = []\n        if verbose:\n            print(\"\\nLocal mimima\\n\")\n            print(\"n_times\\t\\tLML\")\n            print(\"------------------------------------\")\n\n        for i in range(len(opt_list)):\n            out.append(opt_list[index[i]])\n            if verbose:\n                print((\"%d\\t\\t%f\" % (opt_list[index[i]]['counter'], opt_list[index[i]]['LML'])))\n                print(\"\")\n\n        return out", "response": "Train the model with random restarts and return a list of all relative minima that have been found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getTraitCovarStdErrors(self,term_i):\n        assert self.init,        'GP not initialised'\n        assert self.fast==False, 'Not supported for fast implementation'\n\n        if self.P==1:\n            out = (2*self.getScales()[term_i])**2*self._getLaplaceCovar()[term_i,term_i]\n        else:\n            C = self.vd.getTerm(term_i).getTraitCovar()\n            n_params = C.getNumberParams()\n            par_index = 0\n            for term in range(term_i-1):\n                par_index += self.vd.getTerm(term_i).getNumberScales()\n            Sigma1 = self._getLaplaceCovar()[par_index:(par_index+n_params),:][:,par_index:(par_index+n_params)]\n            out = sp.zeros((self.P,self.P))\n            for param_i in range(n_params):\n                out += C.Kgrad_param(param_i)**2*Sigma1[param_i,param_i]\n                for param_j in range(param_i):\n                    out += 2*abs(C.Kgrad_param(param_i)*C.Kgrad_param(param_j))*Sigma1[param_i,param_j]\n        out = sp.sqrt(out)\n        return out", "response": "Returns the standard errors on trait covariance estimates for a given term."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the standard errors on the estimated variance components", "response": "def getVarianceCompStdErrors(self,univariance=False):\n        \"\"\"\n        Return the standard errors on the estimated variance components (for variance component estimates \\see getVarianceComps)\n\n        Args:\n            univariance:   Boolean indicator, if True variance components are normalized to sum up to 1 for each trait\n        Returns:\n            standard errors on variance components [P, n_randEffs matrix]\n        \"\"\"\n        RV=sp.zeros((self.P,self.n_randEffs))\n        for term_i in range(self.n_randEffs):\n            #RV[:,term_i] = self.getTraitCovarStdErrors(term_i).diagonal()\n            RV[:,term_i] = self.getTraitCovarStdErrors(term_i)\n        var = self.getVarianceComps()\n        if univariance:\n            RV /= var.sum(1)[:,sp.newaxis]\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npredicts the conditional mean of the Phenos", "response": "def predictPhenos(self,use_fixed=None,use_random=None):\n        \"\"\"\n        predict the conditional mean (BLUP)\n\n        Args:\n            use_fixed:        list of fixed effect indeces to use for predictions\n            use_random:        list of random effect indeces to use for predictions\n        Returns:\n            predictions (BLUP)\n        \"\"\"\n        assert self.noisPos is not None,      'No noise element'\n        assert self.init,               'GP not initialised'\n        assert self.Ntest is not None,        'VarianceDecomposition:: specify Ntest for predictions (method VarianceDecomposition::setTestSampleSize)'\n\n        use_fixed  = list(range(self.n_fixedEffs))\n        use_random = list(range(self.n_randEffs))\n\n        KiY = self.gp.agetKEffInvYCache()\n\n        if self.fast==False:\n            KiY = KiY.reshape(self.P,self.N).T\n\n        Ypred = sp.zeros((self.Ntest,self.P))\n\n        # predicting from random effects\n        for term_i in use_random:\n            if term_i!=self.noisPos:\n                Kstar = self.Kstar[term_i]\n                if Kstar is None:\n                    warnings.warn('warning: random effect term %d not used for predictions as it has None cross covariance'%term_i)\n                    continue\n                term  = sp.dot(Kstar.T,KiY)\n                if self.P>1:\n                    C    = self.getTraitCovar(term_i)\n                    term = sp.dot(term,C)\n                else:\n                    term *= self.getVarianceComps()[0,term_i]\n                Ypred += term\n\n        # predicting from fixed effects\n        weights = self.getWeights()\n        w_i = 0\n        for term_i in use_fixed:\n            Fstar = self.Fstar[term_i]\n            if Fstar is None:\n                warnings.warn('warning: fixed effect term %d not used for predictions as it has None test sample design'%term_i)\n                continue\n            if self.P==1:    A = sp.eye(1)\n            else:            A = self.vd.getDesign(term_i)\n            Fstar = self.Fstar[term_i]\n            W = weights[w_i:w_i+A.shape[0],0:1].T\n            term = sp.dot(Fstar,sp.dot(W,A))\n            w_i += A.shape[0]\n            Ypred += term\n\n        return Ypred"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit the dataset in n folds, predict each fold after training the model on all the others Args: seed: seed n_folds: number of folds to train the model on fullVector: Bolean indicator, if true it stops if no convergence is observed for one of the folds, otherwise goes through and returns a pheno matrix with missing values verbose: if true, prints the fold that is being used for predicitons **keywords: params to pass to the function optimize Returns: Matrix of phenotype predictions [N,P]", "response": "def crossValidation(self,seed=0,n_folds=10,fullVector=True,verbose=None,D=None,**keywords):\n        \"\"\"\n        Split the dataset in n folds, predict each fold after training the model on all the others\n\n        Args:\n            seed:        seed\n            n_folds:     number of folds to train the model on\n            fullVector:  Bolean indicator, if true it stops if no convergence is observed for one of the folds, otherwise goes through and returns a pheno matrix with missing values\n            verbose:     if true, prints the fold that is being used for predicitons\n            **keywords:  params to pass to the function optimize\n        Returns:\n            Matrix of phenotype predictions [N,P]\n        \"\"\"\n        verbose = dlimix.getVerbose(verbose)\n\n        # split samples into training and test\n        sp.random.seed(seed)\n        r = sp.random.permutation(self.Y.shape[0])\n        nfolds = 10\n        Icv = sp.floor(((sp.ones((self.Y.shape[0]))*nfolds)*r)/self.Y.shape[0])\n\n        RV = {}\n        if self.P==1:  RV['var'] = sp.zeros((nfolds,self.n_randEffs))\n        else:          RV['var'] = sp.zeros((nfolds,self.P,self.n_randEffs))\n\n        Ystar = sp.zeros_like(self.Y)\n\n        for fold_j in range(n_folds):\n\n            if verbose:\n                print((\".. predict fold %d\"%fold_j))\n\n            Itrain  = Icv!=fold_j\n            Itest   = Icv==fold_j\n            Ytrain  = self.Y[Itrain,:]\n            Ytest   = self.Y[Itest,:]\n            vc = VarianceDecomposition(Ytrain)\n            vc.setTestSampleSize(Itest.sum())\n            for term_i in range(self.n_fixedEffs):\n                F      = self.vd.getFixed(term_i)\n                Ftest  = F[Itest,:]\n                Ftrain = F[Itrain,:]\n                if self.P>1:    A = self.vd.getDesign(term_i)\n                else:           A = None\n                vc.addFixedEffect(F=Ftrain,Ftest=Ftest,A=A)\n            for term_i in range(self.n_randEffs):\n                if self.P>1:\n                    tct  = self.trait_covar_type[term_i]\n                    rank = self.rank[term_i]\n                    ftc  = self.fixed_tc[term_i]\n                    jitt = self.jitter[term_i]\n                    if tct=='lowrank_diag1' or tct=='freeform1':\n                        d = D[fold_j,:,term_i]\n                    else:\n                        d = None\n                else:\n                    tct  = None\n                    rank = None\n                    ftc  = None\n                    jitt = None\n                    d    = None\n                if term_i==self.noisPos:\n                    vc.addRandomEffect(is_noise=True,trait_covar_type=tct,rank=rank,jitter=jitt,fixed_trait_covar=ftc,d=d)\n                else:\n                    R = self.vd.getTerm(term_i).getK()\n                    Rtrain = R[Itrain,:][:,Itrain]\n                    Rcross = R[Itrain,:][:,Itest]\n                    vc.addRandomEffect(K=Rtrain,Kcross=Rcross,trait_covar_type=tct,rank=rank,jitter=jitt,fixed_trait_covar=ftc,d=d)\n            conv = vc.optimize(verbose=False,**keywords)\n            if self.P==1:\n                RV['var'][fold_j,:] = vc.getVarianceComps()[0,:]\n            else:\n                RV['var'][fold_j,:,:] = vc.getVarianceComps()\n\n            if fullVector:\n                assert conv, 'VarianceDecompositon:: not converged for fold %d. Stopped here' % fold_j\n            if conv:\n                Ystar[Itest,:] = vc.predictPhenos()\n            else:\n                warnings.warn('not converged for fold %d' % fold_j)\n                Ystar[Itest,:] = sp.nan\n\n        return Ystar,RV"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getScalesDiag(self,termx=0):\n        assert self.P>1, 'VarianceDecomposition:: diagonal init_method allowed only for multi trait models'\n        assert self.noisPos is not None, 'VarianceDecomposition:: noise term has to be set'\n        assert termx<self.n_randEffs-1, 'VarianceDecomposition:: termx>=n_randEffs-1'\n        assert self.trait_covar_type[self.noisPos] not in ['lowrank','block','fixed'], 'VarianceDecomposition:: diagonal initializaiton not posible for such a parametrization'\n        assert self.trait_covar_type[termx] not in ['lowrank','block','fixed'], 'VarianceDecimposition:: diagonal initializaiton not posible for such a parametrization'\n        scales = []\n        res = self._getH2singleTrait(self.vd.getTerm(termx).getK())\n        scaleg = sp.sqrt(res['varg'].mean())\n        scalen = sp.sqrt(res['varn'].mean())\n        for term_i in range(self.n_randEffs):\n            if term_i==termx:\n                _scales = scaleg*self.diag[term_i]\n            elif term_i==self.noisPos:\n                _scales = scalen*self.diag[term_i]\n            else:\n                _scales = 0.*self.diag[term_i]\n            if self.jitter[term_i]>0:\n                _scales = sp.concatenate((_scales,sp.array([sp.sqrt(self.jitter[term_i])])))\n            scales.append(_scales)\n        return sp.concatenate(scales)", "response": "Internal function for parameter initialization for diagonal initialization. Returns a list of the diagonal parameters for the given termx."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getScalesPairwise(self,verbose=False, initDiagonal=False):\n        var = sp.zeros((self.P,2))\n\n        if initDiagonal:\n            #1. fit single trait model\n            if verbose:\n                print('.. fit single-trait model for initialization')\n            vc = VarianceDecomposition(self.Y[:,0:1])\n            for term_i in range(self.n_randEffs):\n                if term_i==self.noisPos:\n                    vc.addRandomEffect(is_noise=True)\n                else:\n                    K = self.vd.getTerm(term_i).getK()\n                    vc.addRandomEffect(K=K)\n            scales0 = sp.sqrt(0.5)*sp.ones(2)\n\n            for p in range(self.P):\n                if verbose: print(('   .. trait %d' % p))\n                vc.setY(self.Y[:,p:p+1])\n                conv = vc.optimize(scales0=scales0)\n                if not conv:\n                    print('warning initialization not converged')\n                var[p,:] = vc.getVarianceComps()[0,:]\n\n        elif fastlmm_present:\n            if verbose:\n                print('.. fit single-trait model for initialization (using fastlmm)')\n            for p in range(self.P):\n                if verbose: print(('   .. trait %d' % p))\n                covariates = None\n                for term_i in range(self.n_randEffs):\n                    if term_i==self.noisPos:\n                        pass\n                    else:\n                        K = self.vd.getTerm(term_i).getK()\n                varY = sp.var(self.Y[:,p:p+1])\n                lmm = fastLMM(X=covariates, Y=self.Y[:,p:p+1], G=None, K=K)\n                opt = lmm.findH2(nGridH2=100)\n                h2 = opt['h2']\n                var[p,:] = h2 * varY\n                var[p,self.noisPos] = (1.0-h2) * varY\n                #import ipdb;ipdb.set_trace()\n        else:\n            if verbose:\n                print('.. random initialization of diagonal')\n            var = sp.random.randn(var.shape[0],var.shape[1])\n            var = var*var + 0.001\n        #2. fit pairwise model\n        if verbose:\n            print('.. fit pairwise model for initialization')\n        vc = VarianceDecomposition(self.Y[:,0:2])\n        for term_i in range(self.n_randEffs):\n            if term_i==self.noisPos:\n                vc.addRandomEffect(is_noise=True,trait_covar_type='freeform')\n            else:\n                K = self.vd.getTerm(term_i).getK()\n                vc.addRandomEffect(K=K,trait_covar_type='freeform')\n        rho_g = sp.ones((self.P,self.P))\n        rho_n = sp.ones((self.P,self.P))\n        for p1 in range(self.P):\n            for p2 in range(p1):\n                if verbose:\n                    print(('   .. fit pair (%d,%d)'%(p1,p2)))\n                vc.setY(self.Y[:,[p1,p2]])\n                scales0 = sp.sqrt(sp.array([var[p1,0],1e-4,var[p2,0],1e-4,var[p1,1],1e-4,var[p2,1],1e-4]))\n                conv = vc.optimize(scales0=scales0)\n                if not conv:\n                    print('warning initialization not converged')\n                Cg = vc.getTraitCovar(0)\n                Cn = vc.getTraitCovar(1)\n                rho_g[p1,p2] = Cg[0,1]/sp.sqrt(Cg.diagonal().prod())\n                rho_n[p1,p2] = Cn[0,1]/sp.sqrt(Cn.diagonal().prod())\n                rho_g[p2,p1] = rho_g[p1,p2]\n                rho_n[p2,p1] = rho_n[p1,p2]\n        #3. init\n        Cg0 = rho_g*sp.dot(sp.sqrt(var[:,0:1]),sp.sqrt(var[:,0:1].T))\n        Cn0 = rho_n*sp.dot(sp.sqrt(var[:,1:2]),sp.sqrt(var[:,1:2].T))\n        offset_g = abs(sp.minimum(sp.linalg.eigh(Cg0)[0].min(),0))+1e-4\n        offset_n = abs(sp.minimum(sp.linalg.eigh(Cn0)[0].min(),0))+1e-4\n        Cg0+=offset_g*sp.eye(self.P)\n        Cn0+=offset_n*sp.eye(self.P)\n        Lg = sp.linalg.cholesky(Cg0)\n        Ln = sp.linalg.cholesky(Cn0)\n        Cg_params0 = sp.concatenate([Lg[:,p][:p+1] for p in range(self.P)])\n        Cn_params0 = sp.concatenate([Ln[:,p][:p+1] for p in range(self.P)])\n        scales0 = sp.concatenate([Cg_params0,1e-2*sp.ones(1),Cn_params0,1e-2*sp.ones(1)])\n\n        return scales0", "response": "Internal function for parameter initialization. Uses a single trait model for initializing variances and a pairwise model for initializing correlations."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _perturbation(self):\n        if self.P>1:\n            scales = []\n            for term_i in range(self.n_randEffs):\n                _scales = sp.randn(self.diag[term_i].shape[0])\n                if self.jitter[term_i]>0:\n                    _scales  = sp.concatenate((_scales,sp.zeros(1)))\n                scales.append(_scales)\n            scales = sp.concatenate(scales)\n        else:\n            scales = sp.randn(self.vd.getNumberScales())\n        return scales", "response": "Internal function for parameter initialization\n        Returns Gaussian perturbation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getHessian(self):\n        assert self.init,        'GP not initialised'\n        assert self.fast==False, 'Not supported for fast implementation'\n\n        if self.cache['Hessian'] is None:\n            ParamMask=self.gp.getParamMask()['covar']\n            std=sp.zeros(ParamMask.sum())\n            H=self.gp.LMLhess_covar()\n            It= (ParamMask[:,0]==1)\n            self.cache['Hessian']=H[It,:][:,It]\n\n        return self.cache['Hessian']", "response": "Internal function for estimating parameter uncertainty\n        COMPUTES OF HESSIAN OF E(\\ theta ) = - log L \\ theta | X y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getLaplaceCovar(self):\n        assert self.init,        'GP not initialised'\n        assert self.fast==False, 'Not supported for fast implementation'\n\n        if self.cache['Sigma'] is None:\n            self.cache['Sigma'] = sp.linalg.inv(self._getHessian())\n        return self.cache['Sigma']", "response": "Internal function for estimating parameter uncertainty\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getModelPosterior(self,min):\n        Sigma = self._getLaplaceCovar(min)\n        n_params = self.vd.getNumberScales()\n        ModCompl = 0.5*n_params*sp.log(2*sp.pi)+0.5*sp.log(sp.linalg.det(Sigma))\n        RV = min['LML']+ModCompl\n        return RV", "response": "Returns the model posterior for the given minimum parameter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef join_tokens_to_sentences(tokens):\n    text = \"\"\n    for (entry, next_entry) in zip(tokens, tokens[1:]):\n        text += entry\n        if next_entry not in SENTENCE_STOPS:\n            text += \" \"\n\n    text += tokens[-1]\n    return text", "response": "Correctly joins tokens to multiple sentences\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split(inp_str, sep_char, maxsplit=-1, escape_char='\\\\'):\n\n    word_chars = []\n    word_chars_append = word_chars.append\n\n    inp_str_iter = iter(inp_str)\n\n    for c in inp_str_iter:\n        word_chars_append(c)\n        if c == escape_char:\n            try:\n                next_char = next(inp_str_iter)\n            except StopIteration:\n                continue\n            if next_char == sep_char:\n                word_chars[-1] = next_char\n            else:\n                word_chars.append(next_char)\n        elif c == sep_char:\n            word_chars.pop()\n            yield ''.join(word_chars)\n            maxsplit -= 1\n            if maxsplit == 0:\n                yield ''.join(inp_str_iter)\n                return\n            del word_chars[:]\n\n    yield ''.join(word_chars)", "response": "Splits a string into sub - strings of a given separator character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving all array or dictionary elements for a JSON path marker.", "response": "def _full_sub_array(data_obj, xj_path, create_dict_path):\n    \"\"\"Retrieves all array or dictionary elements for '*' JSON path marker.\n\n    :param dict|list data_obj: The current data object.\n    :param str xj_path: A json path.\n    :param bool create_dict_path create a dict path.\n    :return: tuple with two values: first is a result and second\n             a boolean flag telling if this value exists or not.\n    \"\"\"\n\n    if isinstance(data_obj, list):\n        if xj_path:\n            res = []\n            for d in data_obj:\n                val, exists = path_lookup(d, xj_path, create_dict_path)\n                if exists:\n                    res.append(val)\n            return tuple(res), True\n        else:\n            return tuple(data_obj), True\n    elif isinstance(data_obj, dict):\n        if xj_path:\n            res = []\n            for d in data_obj.values():\n                val, exists = path_lookup(d, xj_path, create_dict_path)\n                if exists:\n                    res.append(val)\n            return tuple(res), True\n        else:\n            return tuple(data_obj.values()), True\n    else:\n        return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntranslates an array path in XJ notation into an array index.", "response": "def _get_array_index(array_path):\n    \"\"\"Translates @first @last @1 @-1 expressions into an actual array index.\n\n    :param str array_path: Array path in XJ notation.\n    :rtype: int\n    :return: Array index.\n    \"\"\"\n\n    if not array_path.startswith('@'):\n        raise XJPathError('Array index must start from @ symbol.')\n    array_path = array_path[1:]\n    if array_path == 'last':\n        return -1\n    if array_path == 'first':\n        return 0\n    if array_path.isdigit() or (array_path.startswith('-')\n                                and array_path[1:].isdigit()):\n        return int(array_path)\n    else:\n        raise XJPathError('Unknown index reference', (array_path,))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _single_array_element(data_obj, xj_path, array_path, create_dict_path):\n\n    val_type, array_path = _clean_key_type(array_path)\n    array_idx = _get_array_index(array_path)\n    if data_obj and isinstance(data_obj, (list, tuple)):\n        try:\n            value = data_obj[array_idx]\n            if val_type is not None and not isinstance(value, val_type):\n                raise XJPathError('Index array \"%s\" of \"%s\" type does not '\n                                  'match expected type \"%s\"' %\n                                  (array_idx, type(value).__name__,\n                                   val_type.__name__))\n\n            if xj_path:\n                return path_lookup(value, xj_path, create_dict_path)\n            else:\n                return value, True\n        except IndexError:\n            return None, False\n    else:\n        if val_type is not None:\n            raise XJPathError('Expected the list element type, but \"%s\" found' %\n                              type(data_obj).__name__)\n        return None, False", "response": "Retrieves a single array element for a given xj_path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _split_path(xj_path):\n\n    res = xj_path.rsplit('.', 1)\n    root_key = res[0]\n    if len(res) > 1:\n        return root_key, res[1]\n    else:\n        if root_key and root_key != '.':\n            return None, root_key\n        else:\n            raise XJPathError('Path cannot be empty', (xj_path,))", "response": "Extract the last piece of XJPath."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_path(xj_path):\n\n    if not isinstance(xj_path, str):\n        raise XJPathError('XJPath must be a string')\n\n    for path in split(xj_path, '.'):\n        if path == '*':\n            continue\n        if path.startswith('@'):\n            if path == '@first' or path == '@last':\n                continue\n            try:\n                int(path[1:])\n            except ValueError:\n                raise XJPathError('Array index must be either integer or '\n                                  '@first or @last')", "response": "Validates XJ path.\n\n    :param str xj_path: XJ Path\n    :raise: XJPathError if validation fails."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving type specifier returning detected type and cleaned key name.", "response": "def _clean_key_type(key_name, escape_char=ESCAPE_SEQ):\n    \"\"\"Removes type specifier returning detected type and\n    a key name without type specifier.\n\n    :param str key_name: A key name containing type postfix.\n    :rtype: tuple[type|None, str]\n    :returns: Type definition and cleaned key name.\n    \"\"\"\n\n    for i in (2, 1):\n\n        if len(key_name) < i:\n            return None, key_name\n\n        type_v = key_name[-i:]\n\n        if type_v in _KEY_SPLIT:\n            if len(key_name) <= i:\n                return _KEY_SPLIT[type_v], ''\n\n            esc_cnt = 0\n            for pos in range(-i - 1, -len(key_name) - 1, -1):\n                if key_name[pos] == escape_char:\n                    esc_cnt += 1\n                else:\n                    break\n\n            if esc_cnt % 2 == 0:\n                return _KEY_SPLIT[type_v], key_name[:-i]\n            else:\n                return None, key_name\n\n    return None, key_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlook up a path in the data_obj.", "response": "def path_lookup(data_obj, xj_path, create_dict_path=False):\n    \"\"\"Looks up a xj path in the data_obj.\n\n    :param dict|list data_obj: An object to look into.\n    :param str xj_path: A path to extract data from.\n    :param bool create_dict_path: Create an element if type is specified.\n    :return: A tuple where 0 value is an extracted value and a second\n             field that tells if value either was found or not found.\n    \"\"\"\n\n    if not xj_path or xj_path == '.':\n        return data_obj, True\n\n    res = list(split(xj_path, '.', maxsplit=1))\n    top_key = res[0]\n    leftover = res[1] if len(res) > 1 else None\n    if top_key == '*':\n        return _full_sub_array(data_obj, leftover, create_dict_path)\n    elif top_key.startswith('@'):\n        return _single_array_element(data_obj, leftover, top_key,\n                                     create_dict_path)\n    else:\n        val_type, top_key = _clean_key_type(top_key)\n        top_key = unescape(top_key)\n        if top_key in data_obj:\n            value = data_obj[top_key]\n            if val_type is not None and not isinstance(value, val_type):\n                raise XJPathError(\n                    'Key %s expects type \"%s\", but found value type is \"%s\"' %\n                    (top_key, val_type.__name__, type(value).__name__))\n            if leftover:\n                return path_lookup(value, leftover, create_dict_path)\n            else:\n                return value, True\n        else:\n            if val_type is not None:\n                if not isinstance(data_obj, dict):\n                    raise XJPathError('Accessed object must be a dict type '\n                                      'for the key: \"%s\"' % top_key)\n                if create_dict_path:\n                    data_obj[top_key] = val_type()\n                else:\n                    return None, False\n                if leftover:\n                    return path_lookup(data_obj[top_key], leftover,\n                                       create_dict_path)\n                else:\n                    return data_obj[top_key], True\n            return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strict_path_lookup(data_obj, xj_path, force_type=None):\n\n    value, exists = path_lookup(data_obj, xj_path)\n    if exists:\n        if force_type is not None:\n            if not isinstance(value, force_type):\n                raise XJPathError('Found value is a wrong type',\n                                  (xj_path, force_type))\n        return value\n    else:\n        raise XJPathError('Path does not exist', (xj_path,))", "response": "Searches up a xj path in the data_obj."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_logging_verbosity(verbosity):\n    '''\n    Parameters\n    ----------\n    verbosity: int\n        logging verbosity level (0-4)\n\n    Returns\n    -------\n    A logging level as exported by `logging` module.\n    By default returns logging.NOTSET\n\n    Raises\n    ------\n    TypeError\n        when `verbosity` doesn't have type int\n    ValueError\n        when `verbosity` is negative\n    '''\n    if not isinstance(verbosity, int):\n        raise TypeError('Argument \"verbosity\" must have type int.')\n\n    if not verbosity >= 0:\n        raise ValueError('Argument \"verbosity\" must be a positive number.')\n    if verbosity >= len(VERBOSITY_TO_LEVELS):\n        verbosity = len(VERBOSITY_TO_LEVELS) - 1\n    return VERBOSITY_TO_LEVELS.get(verbosity)", "response": "Maps logging verbosity level to the corresponding log level."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_logging():\n    '''Configures the root logger for command line applications.\n\n    Two stream handlers will be added to the logger:\n\n        * \"out\" that will direct INFO & DEBUG messages to the standard output\n        stream\n        * \"err\" that will direct WARN, WARNING, ERROR, & CRITICAL messages to\n        the standard error stream\n\n    Note\n    ----\n    The level for individual loggers can be fine-tuned as follows (exemplified\n    for the `tmlib` logger)::\n\n        import logging\n\n        logger = logging.getLogger('tmlib')\n        logger.setLevel(logging.INFO)\n\n\n    Warning\n    -------\n    Logging should only be configured once at the main entry point of the\n    application!\n    '''\n    fmt = '[%(process)6d/%(threadName)-12s] %(asctime)s | %(levelname)-8s | %(name)-40s | %(message)s'\n    datefmt = '%Y-%m-%d %H:%M:%S'\n    formatter = logging.Formatter(fmt=fmt, datefmt=datefmt)\n\n    logger = logging.getLogger()  # returns the root logger\n\n    stderr_handler = logging.StreamHandler(stream=sys.stderr)\n    stderr_handler.name = 'err'\n    stderr_handler.setLevel(logging.WARN)\n    stderr_handler.setFormatter(formatter)\n    logger.addHandler(stderr_handler)\n\n    stdout_handler = logging.StreamHandler(stream=sys.stdout)\n    stdout_handler.name = 'out'\n    stdout_handler.setFormatter(formatter)\n    stdout_handler.setLevel(0)\n    stdout_handler.addFilter(InfoFilter())\n    logger.addHandler(stdout_handler)", "response": "Configures the root logger for command line applications."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sort_prefixes(orig, prefixes='@+'):\n    new = ''\n    for prefix in prefixes:\n        if prefix in orig:\n            new += prefix\n    return new", "response": "Returns a sorted list of prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_modes(params, mode_types=None, prefixes=''):\n    # we don't accept bare strings because we don't want to try to do\n    #   intelligent parameter splitting\n    params = list(params)\n\n    if params[0][0] not in '+-':\n        raise Exception('first param must start with + or -')\n\n    if mode_types is None:\n        mode_types = ['', '', '', '']\n\n    mode_string = params.pop(0)\n    args = params\n\n    assembled_modes = []\n    direction = mode_string[0]\n    for char in mode_string:\n        if char in '+-':\n            direction = char\n            continue\n\n        if (char in mode_types[0] or char in mode_types[1] or char in prefixes or\n                (char in mode_types[2] and direction == '+') and len(args)):\n            value = args.pop(0)\n        else:\n            value = None\n\n        assembled_modes.append([direction, char, value])\n\n    return assembled_modes", "response": "Returns a list of lists of CHANMODES - like mode types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_envfile(fpath):\n    environ = os.environ\n    env_vars = OrderedDict()\n\n    try:\n\n        with io.open(fpath) as f:\n            lines = f.readlines()\n\n    except IOError:\n        return env_vars\n\n    def drop_quotes(quote_char, val):\n        if val.startswith(quote_char) and val.endswith(quote_char):\n            val = val.strip(quote_char).strip()\n        return val\n\n    for line in lines:\n        line = line.strip()\n\n        if not line or line.startswith('#'):\n            continue\n\n        key, _, val = line.partition('=')\n\n        key = key.strip()\n        val = drop_quotes(\"'\", drop_quotes('\"', val.strip()))\n\n        if not key:\n            continue\n\n        for match in RE_TPL_VAR.findall(val):\n            var_tpl, var_name = match\n\n            var_val = environ.get(var_name)\n\n            if var_val is None:\n                var_val = env_vars.get(var_name)\n\n            if var_val is not None:\n                val = val.replace(var_tpl, var_val, 1)\n\n        env_vars[key] = val\n\n    return env_vars", "response": "Reads environment variables from a. env file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self, ip_address):\n        try:\n            return self._decode_response(\n                socket.gethostbyname(self._build_query(ip_address)))\n        except socket.gaierror:  # Not listed\n            return {\n                'days_since_last_activity': None,\n                'name': None,\n                'threat_score': 0,\n                'type': None\n            }", "response": "Query the Project Honeypot Http : BL API for the given IP address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the Http : BL query string to use", "response": "def _build_query(self, ip_address):\n        \"\"\"Returns the Http:BL query string to use\n\n        :param ip_address: IP address to query\n        :type ip_address: str\n        :returns: str\n\n        \"\"\"\n        return '{}.{}.{}'.format(\n            self.key, self._reverse_ip(ip_address), DNSBL_SUFFIX)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _decode_response(self, ip_address):\n        # Reverse the IP, reassign the octets to integers\n        vt, ts, days, rc = [int(o) for o in ip_address.split('.')[::-1]]\n\n        # 127 reflects a valid query response, all others are errors\n        if rc != 127:\n            raise ValueError('Invalid Response Code: {}'.format(rc))\n\n        # Build a list of visitor types since one IP can be multiple\n        visitor_types = []\n        if vt & COMMENT_SPAMMER:\n            visitor_types.append(COMMENT_SPAMMER)\n        if vt & HARVESTER:\n            visitor_types.append(HARVESTER)\n        if vt & SUSPICIOUS:\n            visitor_types.append(SUSPICIOUS)\n\n        # Return the response dictionary\n        return {'days_since_last_activity': days if vt else None,\n                'name': None if vt else SEARCH_ENGINES[ts],\n                'threat_score': ts if vt else None,\n                'type': visitor_types if vt else [SEARCH_ENGINE]}", "response": "Decodes a HttpBL response IP and returns a dictionary of response data structure of response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying a signed request and returns a trusted JSON data.", "response": "def verify_jwt(signed_request, expected_aud, secret, validators=[],\n               required_keys=('request.pricePoint',\n                              'request.name',\n                              'request.description',\n                              'response.transactionID'),\n               algorithms=None):\n    \"\"\"\n    Verifies a postback/chargeback JWT.\n\n    Returns the trusted JSON data from the original request.\n    When there's an error, an exception derived from\n    :class:`mozpay.exc.InvalidJWT`\n    will be raised.\n\n    This is an all-in-one function that does all verification you'd\n    need. There are some low-level functions you can use to just\n    verify certain parts of a JWT.\n\n    Arguments:\n\n    **signed_request**\n        JWT byte string.\n\n    **expected_aud**\n        The expected value for the aud (audience) of the JWT.\n        See :func:`mozpay.verify.verify_audience`.\n\n    **secret**\n        A shared secret to validate the JWT with.\n        See :func:`mozpay.verify.verify_sig`.\n\n    **validators**\n        A list of extra callables. Each one is passed a JSON Python dict\n        representing the JWT after it has passed all other checks.\n\n    **required_keys**\n        A list of JWT keys to validate. See\n        :func:`mozpay.verify.verify_keys`.\n\n    **algorithms**\n        A list of valid JWT algorithms to accept.\n        By default this will only include HS256 because that's\n        what the Firefox Marketplace uses.\n    \"\"\"\n    if not algorithms:\n        algorithms = ['HS256']\n    issuer = _get_issuer(signed_request=signed_request)\n    app_req = verify_sig(signed_request, secret, issuer=issuer,\n                         algorithms=algorithms, expected_aud=expected_aud)\n\n    # I think this call can be removed after\n    # https://github.com/jpadilla/pyjwt/issues/121\n    verify_claims(app_req, issuer=issuer)\n\n    verify_keys(app_req, required_keys, issuer=issuer)\n\n    for vl in validators:\n        vl(app_req)\n\n    return app_req"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies the claims in the JWT.", "response": "def verify_claims(app_req, issuer=None):\n    \"\"\"\n    Verify JWT claims.\n\n    All times must be UTC unix timestamps.\n\n    These claims will be verified:\n\n    - iat: issued at time. If JWT was issued more than an hour ago it is\n      rejected.\n    - exp: expiration time.\n\n    All exceptions are derived from\n    :class:`mozpay.exc.InvalidJWT`.\n    For expirations a\n    :class:`mozpay.exc.RequestExpired`\n    exception will be raised.\n    \"\"\"\n    if not issuer:\n        issuer = _get_issuer(app_req=app_req)\n    try:\n        float(str(app_req.get('exp')))\n        float(str(app_req.get('iat')))\n    except ValueError:\n        _re_raise_as(InvalidJWT,\n                     'JWT had an invalid exp (%r) or iat (%r) '\n                     % (app_req.get('exp'), app_req.get('iat')),\n                     issuer=issuer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_keys(app_req, required_keys, issuer=None):\n    if not issuer:\n        issuer = _get_issuer(app_req=app_req)\n    key_vals = []\n    for key_path in required_keys:\n        parent = app_req\n        for kp in key_path.split('.'):\n            if not isinstance(parent, dict):\n                raise InvalidJWT('JWT is missing %r: %s is not a dict'\n                                 % (key_path, kp), issuer=issuer)\n            val = parent.get(kp, None)\n            if not val:\n                raise InvalidJWT('JWT is missing %r: %s is not a valid key'\n                                 % (key_path, kp), issuer=issuer)\n            parent = val\n        key_vals.append(parent)  # last value of key_path\n    return key_vals", "response": "Verify all keys listed in required_keys and return a list of all the key values that are present in the base object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify_sig(signed_request, secret, issuer=None, algorithms=None,\n               expected_aud=None):\n    \"\"\"\n    Verify the JWT signature.\n\n    Given a raw JWT, this verifies it was signed with\n    *secret*, decodes it, and returns the JSON dict.\n    \"\"\"\n    if not issuer:\n        issuer = _get_issuer(signed_request=signed_request)\n    signed_request = _to_bytes(signed_request)\n    app_req = _get_json(signed_request)\n\n    # Check signature.\n    try:\n        jwt.decode(signed_request, secret, verify=True,\n                   algorithms=algorithms, audience=expected_aud)\n    except jwt.ExpiredSignatureError, exc:\n        _re_raise_as(RequestExpired, '%s' % exc, issuer=issuer)\n    except jwt.InvalidTokenError, exc:\n        _re_raise_as(InvalidJWT,\n                     'Signature verification failed: %s' % exc,\n                     issuer=issuer)\n    return app_req", "response": "Verify the signature of a raw JWT."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _re_raise_as(NewExc, *args, **kw):\n    etype, val, tb = sys.exc_info()\n    raise NewExc(*args, **kw), None, tb", "response": "Raise a new exception using the preserved traceback of the last one."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all the available generators.", "response": "def generators():\n    \"\"\"\n    List all the available generators.\n    \"\"\"\n    from populous import generators\n\n    base = generators.Generator\n\n    for name in dir(generators):\n        generator = getattr(generators, name)\n\n        if isinstance(generator, type) and issubclass(generator, base):\n            name = generator.__name__\n            doc = (generator.__doc__ or '').strip()\n\n            if doc:\n                click.echo(\"{} - {}\".format(name, doc))\n            else:\n                click.echo(name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef snake_case(string):\n    ''' Takes a string that represents for example a class name and returns\n    the snake case version of it. It is used for model-to-key conversion '''\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', string)\n\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()", "response": "Takes a string that represents for example a class name and returns\n    the snake case version of it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the given value or the specified default value for this field", "response": "def value_or_default(self, value):\n        ''' Returns the given value or the specified default value for this\n        field '''\n        if value is None:\n            if callable(self.default):\n                return self.default()\n            else:\n                return self.default\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_required(self, value):\n        ''' Validates the given value agains this field's 'required' property\n        '''\n        if self.required and (value is None or value==''):\n            raise MissingFieldError(self.name)", "response": "Validates the given value agains this field s required property\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recover(self, data, redis=None):\n        ''' Retrieve this field's value from the database '''\n        value = data.get(self.name)\n\n        if value is None or value == 'None':\n            return None\n\n        return str(value)", "response": "Retrieve this field s value from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the value of this field in the databse", "response": "def save(self, value, redis, *, commit=True):\n        ''' Sets this fields value in the databse '''\n        value = self.prepare(value)\n\n        if value is not None:\n            redis.hset(self.obj.key(), self.name, value)\n        else:\n            redis.hdel(self.obj.key(), self.name)\n\n        if self.index:\n            key = self.key()\n\n            if self.name in self.obj._old:\n                redis.hdel(key, self.obj._old[self.name])\n\n            if value is not None:\n                redis.hset(key, value, self.obj.id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the data obtained from a request and returns it in the apropiate format", "response": "def validate(self, value, redis):\n        '''\n        Validates data obtained from a request and returns it in the apropiate\n        format\n        '''\n        # cleanup\n        if type(value) == str:\n            value = value.strip()\n\n        value = self.value_or_default(value)\n\n        # validation\n        self.validate_required(value)\n\n        if self.regex and not re.match(self.regex, value, flags=re.ASCII):\n            raise InvalidFieldError(self.name)\n\n        if self.forbidden and value in self.forbidden:\n            raise ReservedFieldError(self.name)\n\n        if self.allowed and value not in self.allowed:\n            raise InvalidFieldError(self.name)\n\n        if self.index:\n            key = self.key()\n\n            old = debyte_string(redis.hget(key, value))\n            old_value = getattr(self.obj, self.name)\n\n            if old is not None and old != self.obj.id:\n                raise NotUniqueFieldError(self.name)\n            elif old_value != value:\n                self.obj._old[self.name] = old_value\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete this field s value from the databse. Should be implemented in special cases. Should be implemented in special cases. Should be implemented in special cases. Should be implemented in special cases. Should be implemented in special cases.", "response": "def delete(self, redis):\n        ''' Deletes this field's value from the databse. Should be implemented\n        in special cases '''\n        value = getattr(self.obj, self.name)\n        redis.srem(self.key() + ':' + value, self.obj.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init(self, value):\n        ''' hash passwords given in the constructor '''\n        value = self.value_or_default(value)\n\n        if value is None: return None\n\n        if is_hashed(value):\n            return value\n\n        return make_password(value)", "response": "hash passwords given in the constructor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self, value, redis):\n        ''' hash passwords given via http '''\n        value = super().validate(value, redis)\n\n        if is_hashed(value):\n            return value\n\n        return make_password(value)", "response": "hash passwords given via http"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self, value, redis):\n        '''\n        Validates data obtained from a request in ISO 8061 and returns it in Datetime data type\n        '''\n\n        value = self.value_or_default(value)\n\n        self.validate_required(value)\n\n        if value is None:\n            return None\n\n        if type(value) == str:\n            try:\n                value = datetime.datetime.strptime(value, '%Y-%m-%dT%H:%M:%SZ')\n            except ValueError:\n                raise InvalidFieldError(self.name)\n\n        return value", "response": "Validates the value of the key as a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fill(self, **kwargs):\n        ''' Loads the relationships into this model. They are not loaded by\n        default '''\n        setattr(self.obj, self.name, self.get(**kwargs))", "response": "Loads the relationships into this object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_acronyms(fulltext):\n    acronyms = {}\n\n    for m in ACRONYM_BRACKETS_REGEX.finditer(fulltext):\n        acronym = DOTS_REGEX.sub(\"\", m.group(1))\n        potential_expansion = fulltext[m.start() - 80:m.start()].replace(\"\\n\",\n                                                                         \" \")\n        # Strip\n        potential_expansion = re.sub(\"(\\W).(\\W)\", \"\\1\\2\", potential_expansion)\n        potential_expansion = re.sub(\"(\\w)\\(s\\)\\W\", \"\\1\", potential_expansion)\n        potential_expansion = re.sub(\"\"\"[^\\w'\"]+$\"\"\", \"\", potential_expansion)\n        potential_expansion = re.sub(\"[[(].+[\\])]\", \"\", potential_expansion)\n        potential_expansion = re.sub(\" {2,}\", \" \", potential_expansion)\n\n        # LEVEL 0: expansion between quotes\n        # Double quotes\n        match = re.search(\"\"\"\"([^\"]+)[\"]$\"\"\", potential_expansion)\n        if match is None:\n            # Single quotes\n            match = re.search(\"\"\"'([^\"]+)[']$\"\"\", potential_expansion)\n        if match is not None:\n            if acronym in match.group(1):\n                continue\n\n            pattern = \"\"\n            for char in acronym[:-1]:\n                pattern += \"%s\\w+\\W*\" % char\n            pattern += \"%s\\w+\" % acronym[-1]\n\n            if re.search(pattern, match.group(1), re.I) is not None:\n                _add_expansion_to_acronym_dict(acronym, match.group(1), 0,\n                                               acronyms)\n            continue\n\n        pattern = \"\\W(\"\n        for char in acronym[:-1]:\n            pattern += \"%s\\w+\\W+\" % char\n        pattern += \"%s\\w+)$\" % acronym[-1]\n\n        # LEVEL 1: expansion with uppercase initials\n        match = re.search(pattern, potential_expansion)\n        if match is not None:\n            _add_expansion_to_acronym_dict(\n                acronym, match.group(1), 1, acronyms)\n            continue\n\n        # LEVEL 2: expansion with initials\n        match = re.search(pattern, potential_expansion, re.I)\n        if match is not None:\n            _add_expansion_to_acronym_dict(\n                acronym, match.group(1), 2, acronyms)\n            continue\n\n        # LEVEL 3: expansion with initials and STOPLIST\n        potential_expansion_stripped = \" \".join([word for word in\n                                                 _words(potential_expansion) if\n                                                 word not in STOPLIST])\n\n        match = re.search(pattern, potential_expansion_stripped, re.I)\n        if match is not None:\n            first_expansion_word = re.search(\"\\w+\", match.group(1)).group()\n            start = potential_expansion.lower().rfind(first_expansion_word)\n            _add_expansion_to_acronym_dict(\n                acronym, potential_expansion[start:],\n                3, acronyms\n            )\n            continue\n\n        # LEVEL 4: expansion with fuzzy initials and stoplist\n        reversed_words = _words(potential_expansion_stripped)\n        reversed_words.reverse()\n\n        reversed_acronym = list(acronym.lower())\n        reversed_acronym.reverse()\n\n        index0 = 0\n        index1 = 0\n        word = \"\"\n        try:\n            while index0 < len(reversed_acronym) and index1 < len(\n                    reversed_words):\n                word = reversed_words[index1]\n                if index0 + 1 < len(reversed_words):\n                    next_word = reversed_words[index0 + 1]\n                else:\n                    next_word = \"_\"\n\n                char = reversed_acronym[index0]\n                if index0 + 1 < len(reversed_acronym):\n                    next_char = reversed_acronym[index0 + 1]\n                else:\n                    next_char = \"_\"\n\n                if char == next_char and \\\n                        word.startswith(char) and \\\n                        word.count(char) > 1 and \\\n                        not next_word.startswith(char):\n                    index0 += 2\n                    index1 += 1\n                if word.startswith(char):\n                    index0 += 1\n                    index1 += 1\n                elif char in word and \\\n                        not word.endswith(char) and \\\n                        word.startswith(next_char):\n                    index0 += 2\n                    index1 += 1\n                else:\n                    word = \"\"\n                    break\n        except IndexError:\n            word = \"\"\n\n        if not word.startswith(char):\n            word = \"\"\n\n        if word:\n            start = potential_expansion.lower().rfind(word)\n\n            _add_expansion_to_acronym_dict(acronym,\n                                           potential_expansion[start:], 4,\n                                           acronyms)\n            continue\n\n        # LEVEL 5: expansion with fuzzy initials\n        reversed_words = _words(potential_expansion.lower())\n        reversed_words.reverse()\n\n        reversed_acronym = list(acronym.lower())\n        reversed_acronym.reverse()\n\n        index0 = 0\n        index1 = 0\n        word = \"\"\n        try:\n            while index0 < len(reversed_acronym) and index1 < len(\n                    reversed_words):\n                word = reversed_words[index1]\n                if index0 + 1 < len(reversed_words):\n                    next_word = reversed_words[index0 + 1]\n                else:\n                    next_word = \"\"\n\n                char = reversed_acronym[index0]\n                if index0 + 1 < len(reversed_acronym):\n                    next_char = reversed_acronym[index0 + 1]\n                else:\n                    next_char = \"\"\n\n                if char == next_char and word.startswith(char) and \\\n                   word.count(char) > 1 and \\\n                   not next_word.startswith(char):\n                    index0 += 2\n                    index1 += 1\n                if word.startswith(char):\n                    index0 += 1\n                    index1 += 1\n                elif char in word and \\\n                        not word.endswith(char) and \\\n                        word.startswith(next_char):\n                    index0 += 2\n                    index1 += 1\n                else:\n                    word = \"\"\n                    break\n        except IndexError:\n            word = \"\"\n\n        if not word.startswith(char):\n            word = \"\"\n\n        if word:\n            start = potential_expansion.lower().rfind(word)\n            _add_expansion_to_acronym_dict(acronym,\n                                           potential_expansion[start:], 5,\n                                           acronyms)\n            continue\n\n    return acronyms", "response": "Find acronyms and expansions from the fulltext."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_expansion_to_acronym_dict(acronym, expansion, level, dictionary):\n    if len(acronym) >= len(expansion) or acronym in expansion:\n        return\n\n    for punctuation in re.findall(\"\\W\", expansion):\n        # The expansion contains non-basic punctuation. It is probable\n        # that it is invalid. Discard it.\n        if punctuation not in (\",\", \" \", \"-\"):\n            return False\n\n    if acronym in dictionary:\n        add = True\n        for stored_expansion, stored_level in dictionary[acronym]:\n            if _equivalent_expansions(stored_expansion, expansion):\n                if level < stored_level:\n                    dictionary[acronym].remove(\n                        (stored_expansion, stored_level))\n                    break\n                else:\n                    add = False\n        if add:\n            dictionary[acronym].append((expansion, level))\n            return True\n    else:\n        dictionary.setdefault(acronym, []).append((expansion, level))\n        return True\n\n    return False", "response": "Add an acronym to the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getAuth(self):\n        parameters = {\n            'service'     : 'reader',\n            'Email'       : self.username,\n            'Passwd'      : self.password,\n            'accountType' : 'GOOGLE'}\n        req = requests.post(ClientAuthMethod.CLIENT_URL, data=parameters)\n        if req.status_code != 200:\n            raise IOError(\"Error getting the Auth token, have you entered a\"\n                    \"correct username and password?\")\n        data = req.text\n        #Strip newline and non token text.\n        token_dict = dict(x.split('=') for x in data.split('\\n') if x)\n        return token_dict[\"Auth\"]", "response": "Get the Auth token from the Reader."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getToken(self):\n        headers = {'Authorization':'GoogleLogin auth=%s' % self.auth_token}\n        req = requests.get(ReaderUrl.API_URL + 'token', headers=headers)\n        if req.status_code != 200:\n            raise IOError(\"Error getting the Reader token.\")\n        return req.content", "response": "This method is used to get the Reader token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post(self, url, postParameters=None, urlParameters=None):\n        if self.authorized_client:\n            if urlParameters:\n                getString = self.getParameters(urlParameters)\n                req = urllib2.Request(url + \"?\" + getString)\n            else:\n                req = urllib2.Request(url)\n            postString = self.postParameters(postParameters)\n            resp,content = self.authorized_client.request(req, method=\"POST\", body=postString)\n            return toUnicode(content)\n        else:\n            raise IOError(\"No authorized client available.\")", "response": "Convenience method for requesting to Google with proper cookies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post(self, url, postParameters=None, urlParameters=None):\n        if not self.access_token:\n            raise IOError(\"No authorized client available.\")\n        if not self.action_token:\n            raise IOError(\"Need to generate action token.\")\n        if urlParameters is None:\n            urlParameters = {}\n        headers = {'Authorization': 'Bearer ' + self.access_token,\n                   'Content-Type': 'application/x-www-form-urlencoded'}\n        postParameters.update({'T':self.action_token})\n        request = requests.post(url + '?' + self.getParameters(urlParameters),\n                                data=postParameters, headers=headers)\n        if request.status_code != 200:\n            return None\n        else:\n            return toUnicode(request.text)", "response": "Convenience method for requesting to google with proper cookies."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimplementing libgreader s interface for authenticated GET request", "response": "def get(self, url, parameters=None):\n        \"\"\"\n        Implement libgreader's interface for authenticated GET request\n        \"\"\"\n        if self._http == None:\n            self._setupHttp()\n        uri = url + \"?\" + self.getParameters(parameters)\n        response, content = self._http.request(uri, \"GET\")\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a POST request to the specified URL.", "response": "def post(self, url, postParameters=None, urlParameters=None):\n        \"\"\"\n        Implement libgreader's interface for authenticated POST request\n        \"\"\"\n        if self._action_token == None:\n            self._action_token = self.get(ReaderUrl.ACTION_TOKEN_URL)\n\n        if self._http == None:\n            self._setupHttp()\n        uri = url + \"?\" + self.getParameters(urlParameters)\n        postParameters.update({'T':self._action_token})\n        body = self.postParameters(postParameters)\n        response, content = self._http.request(uri, \"POST\", body=body)\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse an `ELEMENT_NODE`. This calls specific `do_<tagName>` handers for different elements. If no handler is available the `generic_parse` method is called. All tagNames specified in `self.ignores` are simply ignored.", "response": "def parse_Element(self, node):\n        \"\"\"Parse an `ELEMENT_NODE`.  This calls specific\n        `do_<tagName>` handers for different elements.  If no handler\n        is available the `generic_parse` method is called.  All\n        tagNames specified in `self.ignores` are simply ignored.\n\n        \"\"\"\n        name = node.tagName\n        ignores = self.ignores\n        if name in ignores:\n            return\n        attr = \"do_%s\" % name\n        if hasattr(self, attr):\n            handlerMethod = getattr(self, attr)\n            handlerMethod(node)\n        else:\n            self.generic_parse(node)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generic_parse(self, node, pad=0):\n        npiece = 0\n        if pad:\n            npiece = len(self.pieces)\n            if pad == 2:\n                self.add_text('\\n')\n        for n in node.childNodes:\n            self.parse(n)\n        if pad:\n            if len(self.pieces) > npiece:\n                self.add_text('\\n')", "response": "A generic parser for arbitrary tags in a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_pieces(self, pieces):\n        ret = []\n        count = 0\n        for i in pieces:\n            if i == '\\n':\n                count = count + 1\n            else:\n                if i == '\";':\n                    if count:\n                        ret.append('\\n')\n                elif count > 2:\n                    ret.append('\\n\\n')\n                elif count:\n                    ret.append('\\n'*count)\n                count = 0\n                ret.append(i)\n\n        _data = \"\".join(ret)\n        ret = []\n        for i in _data.split('\\n\\n'):\n            if i == 'Parameters:':\n                ret.extend(['Parameters:\\n-----------', '\\n\\n'])\n            elif i.find('// File:') > -1: # leave comments alone.\n                ret.extend([i, '\\n'])\n            else:\n                _tmp = textwrap.fill(i.strip())\n                _tmp = self.lead_spc.sub(r'\\1\"\\2', _tmp)\n                ret.extend([_tmp, '\\n\\n'])\n        return ret", "response": "Cleans the list of strings given as pieces. It replaces multiple newlines by a maximum of 2 and returns a new list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a json response string.", "response": "def _format_json(self, ans, q):\n        \"\"\"\n        Generate a json response string.\n    \"\"\"\n        params = {}\n        try: params['indent'] = int(q.get('indent')[0])\n        except: pass\n\n        return json.dumps(ans, **params)+'\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _format(self, ans, q):\n        if 'fmt' in q:\n            fmt = q['fmt'][0]\n        else:\n            fmt = 'json'\n\n        fmt = fmt.lower()\n\n        if fmt in self._formatters:\n            return (200, self._formatters[fmt](ans, q), 'application/json')\n        else:\n            return (415,\n                'Invalid fmt request \"%s\", supported formats are: %s\\n'%\n                    (fmt, ' '.join(self._formatters.keys()),),\n                'text/plain')", "response": "Returns the response tuple according to the selected format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the taskforce version.", "response": "def version(self, path, postmap=None, **params):\n        \"\"\"\n        Return the taskforce version.\n\n        Supports standard options.\n    \"\"\"\n        q = httpd.merge_query(path, postmap)\n\n        ans = {\n            'taskforce': taskforce_version,\n            'python': '.'.join(str(x) for x in sys.version_info[:3]),\n        }\n        ans['platform'] = {\n            'system': platform.system(),\n        }\n\n        #  Add in some extra details if this is a control path.\n        #  These might give away too many details on a public\n        #  path.\n        #\n        if self._httpd.allow_control:\n            ans['platform']['platform'] = platform.platform()\n            ans['platform']['release'] = platform.release()\n\n        return self._format(ans, q)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config(self, path, postmap=None, **params):\n\n        q = httpd.merge_query(path, postmap)\n\n        ans = self._legion._config_running\n        if not ans: ans = {}\n\n        return self._format(ans, q)", "response": "Return the running configuration which almost always matches the current configuration in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tasks(self, path, postmap=None, **params):\n        q = httpd.merge_query(path, postmap)\n\n        ans = {}\n        for name, tinfo in self._legion._tasknames.items():\n            t = tinfo[0]\n            info = {}\n            conf = t.get_config()\n            if conf:\n                info['control'] = t._get(conf.get('control'))\n                info['count'] = t._get(conf.get('count'), default=1)\n                info['processes'] = []\n                for p in t._proc_state:\n                    if p is None: continue\n                    proc = {}\n                    if p.pid is not None:\n                        proc['pid'] = p.pid\n                    if p.exit_code is not None:\n                        proc['status'] = p.exit_code\n                        proc['exit'] = utils.statusfmt(p.exit_code)\n                    if p.started is not None:\n                        proc['started_t'] = p.started\n                        proc['started'] = utils.time2iso(p.started)\n                    if p.exited is not None:\n                        proc['exited_t'] = p.exited\n                        proc['exited'] = utils.time2iso(p.exited)\n                    if p.pending_sig is not None:                                               # pragma: no cover\n                        proc['exit_pending'] = True\n                    info['processes'].append(proc)\n            ans[name] = info\n\n        return self._format(ans, q)", "response": "Return the status of all tasks in the legion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_attributes(self):\n\n        return [attribute for attribute, value in self.iteritems() if issubclass(value.__class__, Attribute)]", "response": "Returns the Node attributes names."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the Node attributes.", "response": "def get_attributes(self):\n        \"\"\"\n        Returns the Node attributes.\n\n        Usage::\n\n            >>>\tnode_a = AbstractNode(\"MyNodeA\", attributeA=Attribute(value=\"A\"), attributeB=Attribute(value=\"B\"))\n            >>> node_a.get_attributes()\n            [<Attribute object at 0x7fa471d3b5e0>, <Attribute object at 0x101e6c4a0>]\n\n        :return: Attributes.\n        :rtype: list\n        \"\"\"\n\n        return [attribute for attribute in self.itervalues() if issubclass(attribute.__class__, Attribute)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns if given attribute exists in the node.", "response": "def attribute_exists(self, name):\n        \"\"\"\n        Returns if given attribute exists in the node.\n\n        Usage::\n\n            >>>\tnode_a = AbstractNode(\"MyNodeA\", attributeA=Attribute(), attributeB=Attribute())\n            >>> node_a.attribute_exists(\"attributeA\")\n            True\n            >>> node_a.attribute_exists(\"attributeC\")\n            False\n\n        :param name: Attribute name.\n        :type name: unicode\n        :return: Attribute exists.\n        :rtype: bool\n        \"\"\"\n\n        if name in self:\n            if issubclass(self[name].__class__, Attribute):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds given attribute to the node.", "response": "def add_attribute(self, name, value):\n        \"\"\"\n        Adds given attribute to the node.\n\n        Usage::\n\n            >>>\tnode_a = AbstractNode()\n            >>> node_a.add_attribute(\"attributeA\", Attribute())\n            True\n            >>> node_a.list_attributes()\n            [u'attributeA']\n\n        :param name: Attribute name.\n        :type name: unicode\n        :param value: Attribute value.\n        :type value: Attribute\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        if not issubclass(value.__class__, Attribute):\n            raise foundations.exceptions.NodeAttributeTypeError(\n                \"Node attribute value must be a '{0}' class instance!\".format(Attribute.__class__.__name__))\n\n        if self.attribute_exists(name):\n            raise foundations.exceptions.NodeAttributeExistsError(\"Node attribute '{0}' already exists!\".format(name))\n\n        self[name] = value\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove given attribute from the node.", "response": "def remove_attribute(self, name):\n        \"\"\"\n        Removes given attribute from the node.\n\n        Usage::\n\n            >>>\tnode_a = AbstractNode(\"MyNodeA\", attributeA=Attribute(), attributeB=Attribute())\n            >>> node_a.remove_attribute(\"attributeA\")\n            True\n            >>> node_a.list_attributes()\n            ['attributeB']\n\n        :param name: Attribute name.\n        :type name: unicode\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        if not self.attribute_exists(name):\n            raise foundations.exceptions.NodeAttributeExistsError(\"Node attribute '{0}' doesn't exists!\".format(name))\n\n        del self[name]\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the parent attribute of the node.", "response": "def parent(self, value):\n        \"\"\"\n        Setter for **self.__parent** attribute.\n\n        :param value: Attribute value.\n        :type value: AbstractNode or AbstractCompositeNode\n        \"\"\"\n\n        if value is not None:\n            assert issubclass(value.__class__, AbstractNode), \"'{0}' attribute: '{1}' is not a '{2}' subclass!\".format(\n                \"parent\", value, AbstractNode.__class__.__name__)\n        self.__parent = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef child(self, index):\n\n        if not self.__children:\n            return\n\n        if index >= 0 and index < len(self.__children):\n            return self.__children[index]", "response": "Returns the child associated with given index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index_of(self, child):\n\n        for i, item in enumerate(self.__children):\n            if child is item:\n                return i", "response": "Returns the given child index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_child(self, child):\n\n        self.__children.append(child)\n        child.parent = self\n        return True", "response": "Adds given child to the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_child(self, index):\n\n        if index < 0 or index > len(self.__children):\n            return\n\n        child = self.__children.pop(index)\n        child.parent = None\n        return child", "response": "Removes a child from the Node children."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert_child(self, child, index):\n\n        if index < 0 or index > len(self.__children):\n            return False\n\n        self.__children.insert(index, child)\n        child.parent = self\n        return child", "response": "Inserts given child at given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_children(self, attribute=None, reverse_order=False):\n\n        sorted_children = []\n        if attribute:\n            sortable_children = []\n            unsortable_children = []\n            for child in self.__children:\n                if child.attribute_exists(attribute):\n                    sortable_children.append(child)\n                else:\n                    unsortable_children.append(child)\n            sorted_children = sorted(sortable_children, key=lambda x: getattr(\n                x, attribute).value, reverse=reverse_order or False)\n            sorted_children.extend(unsortable_children)\n        else:\n            sorted_children = sorted(self.children, key=lambda x: (x.name), reverse=reverse_order or False)\n\n        self.__children = sorted_children\n\n        for child in self.__children:\n            child.sort_children(attribute, reverse_order)\n\n        return True", "response": "Sort the children of the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_children(self, pattern=r\".*\", flags=0, candidates=None):\n\n        if candidates is None:\n            candidates = []\n\n        for child in self.__children:\n            if re.search(pattern, child.name, flags):\n                child not in candidates and candidates.append(child)\n            child.find_children(pattern, flags, candidates)\n        return candidates", "response": "Find the children matching the given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_family(self, pattern=r\".*\", flags=0, node=None):\n\n        return [node for node in foundations.walkers.nodes_walker(node or self) if\n                re.search(pattern, node.family, flags)]", "response": "Finds the given family."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_node(self, tab_level=-1):\n\n        output = \"\"\n        tab_level += 1\n        for i in range(tab_level):\n            output += \"\\t\"\n        output += \"|----'{0}'\\n\".format(self.name)\n        for child in self.__children:\n            output += child.list_node(tab_level)\n        tab_level -= 1\n        return output", "response": "Lists the current Node and its children."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_repositories():\n    if not env.overwrite and env.LINUX_PACKAGE_REPOSITORIES == server_state('linux_package_repositories'): return\n    if env.verbosity:\n        print env.host, \"UNCOMMENTING SOURCES in /etc/apt/sources.list and adding PPAs\"\n    if contains(filename='/etc/apt/sources.list',text='#(.?)deb(.*)http:(.*)universe'):\n\n        _backup_file('/etc/apt/sources.list')\n        uncomment('/etc/apt/sources.list','#(.?)deb(.*)http:(.*)universe',use_sudo=True)\n    install_package('python-software-properties')\n    for p in env.LINUX_PACKAGE_REPOSITORIES:\n        sudo('add-apt-repository %s'% p)\n        if env.verbosity:\n            print 'added source', p\n    set_server_state('linux_package_repositories',env.LINUX_PACKAGE_REPOSITORIES)", "response": "Adds additional sources as defined in LINUX_PACKAGE_REPOSITORIES."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a user to the user list", "response": "def add_user(username='',password='',group='', site_user=False):\n    \"\"\"\n    Adds the username\n    \"\"\"\n    if group: group = '-g %s'% group\n    if not site_user:\n        run('echo %s:%s > /tmp/users.txt'% (username,password))\n    if not site_user:\n        sudo('useradd -m -s /bin/bash %s %s'% (group,username))\n        sudo('chpasswd < /tmp/users.txt')\n        sudo('rm -rf /tmp/users.txt')\n    else:\n        sudo('useradd -M -d /var/www -s /bin/bash %s'% username)\n        sudo('usermod -a -G www-data %s'% username)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef change_ssh_port():\n    host = normalize(env.host_string)[1]\n\n    after = env.port\n    before = str(env.DEFAULT_SSH_PORT)\n    \n\n    host_string=join_host_strings(env.user,host,before)\n    with settings(host_string=host_string, user=env.user):\n        if env.verbosity:\n            print env.host, \"CHANGING SSH PORT TO: \"+str(after)\n        sed('/etc/ssh/sshd_config','Port '+ str(before),'Port '+str(after),use_sudo=True)\n        if env.verbosity:\n            print env.host, \"RESTARTING SSH on\",after\n\n        sudo('/etc/init.d/ssh restart')\n        return True", "response": "Changes the default ssh port."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disable_root():\n    \n    def enter_password():\n        password1 = getpass.getpass(prompt='Enter the password for %s:'% sudo_user)\n        password2 = getpass.getpass(prompt='Re-enter the password:')\n        if password1 <> password2:\n            print env.host, 'The password was not the same'\n            enter_password()\n        return password1\n\n    (olduser,host,port) = normalize(env.host_string)\n \n    if env.verbosity and not (env.HOST_USER or env.ROLEDEFS):\n    \n        print \"\\nWOVEN will now walk through setting up your node (host).\\n\"\n\n        if env.INTERACTIVE:\n            root_user = prompt(\"\\nWhat is the default administrator account for your node?\", default=env.ROOT_USER)\n        else: root_user = env.ROOT_USER\n        if env.user <> 'root': sudo_user = env.user\n        else: sudo_user = ''\n        if env.INTERACTIVE:\n            sudo_user = prompt(\"What is the new or existing account you wish to use to setup and deploy to your node?\", default=sudo_user)\n           \n    else:\n        root_user = env.ROOT_USER\n        sudo_user = env.user\n        \n\n    original_password = env.get('HOST_PASSWORD','')\n    \n    host_string=join_host_strings(root_user,host,str(env.DEFAULT_SSH_PORT))\n    with settings(host_string=host_string, key_filename=env.key_filename, password=env.ROOT_PASSWORD):\n        if not contains('/etc/group','sudo',use_sudo=True):\n            sudo('groupadd sudo')\n\n        home_path = '/home/%s'% sudo_user\n        if not exists(home_path):\n            if env.verbosity:\n                print env.host, 'CREATING A NEW ACCOUNT WITH SUDO PRIVILEGE: %s'% sudo_user\n            if not original_password:\n\n                original_password = enter_password()\n            \n            add_user(username=sudo_user, password=original_password,group='sudo')\n\n        #Add existing user to sudo group\n        else:\n            sudo('adduser %s sudo'% sudo_user)\n        #adm group used by Ubuntu logs\n        sudo('usermod -a -G adm %s'% sudo_user)\n        #add user to /etc/sudoers\n        if not exists('/etc/sudoers.wovenbak',use_sudo=True):\n            sudo('cp -f /etc/sudoers /etc/sudoers.wovenbak')\n        sudo('cp -f /etc/sudoers /tmp/sudoers.tmp')\n        append('/tmp/sudoers.tmp', \"# Members of the sudo group may gain root privileges\", use_sudo=True)\n        append('/tmp/sudoers.tmp', \"%sudo ALL=(ALL) NOPASSWD:ALL\",  use_sudo=True)\n        sudo('visudo -c -f /tmp/sudoers.tmp')\n        sudo('cp -f /tmp/sudoers.tmp /etc/sudoers')\n        sudo('rm -rf /tmp/sudoers.tmp')\n        if env.key_filename:\n            sudo('mkdir -p /home/%s/.ssh'% sudo_user)\n            sudo('cp -f ~/.ssh/authorized_keys /home/%s/.ssh/authorized_keys'% sudo_user)\n            sudo('chown -R %s:sudo /home/%s/.ssh'% (sudo_user,sudo_user))\n            \n    env.password = original_password\n\n    #finally disable root\n    host_string=join_host_strings(sudo_user,host,str(env.DEFAULT_SSH_PORT))\n    with settings(host_string=host_string):\n        if sudo_user <> root_user and root_user == 'root':\n            if env.INTERACTIVE:\n                d_root = confirm(\"Disable the root account\", default=True)\n            else: d_root = env.DISABLE_ROOT\n            if d_root:\n                if env.verbosity:\n                    print env.host, 'DISABLING ROOT'\n                sudo(\"usermod -L %s\"% 'root')\n\n    return True", "response": "Disables root and creates a new sudo user as specified by HOST_USER or env. DEFAULT_SSH_PORT."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls all the packages and configure where necessary", "response": "def install_packages():\n    \"\"\"\n    Install a set of baseline packages and configure where necessary\n    \"\"\"\n\n    if env.verbosity:\n        print env.host, \"INSTALLING & CONFIGURING NODE PACKAGES:\"\n    #Get a list of installed packages\n    p = run(\"dpkg -l | awk '/ii/ {print $2}'\").split('\\n')\n    \n    #Remove apparmor - TODO we may enable this later\n    if env.overwrite or not server_state('apparmor-disabled') and 'apparmor' in p:\n        with settings(warn_only=True):\n            sudo('/etc/init.d/apparmor stop')\n            sudo('update-rc.d -f apparmor remove')\n            set_server_state('apparmor-disabled')\n\n    #The principle we will use is to only install configurations and packages\n    #if they do not already exist (ie not manually installed or other method)\n    env.installed_packages[env.host] = []\n    role = env.role_lookup[env.host_string]\n    packages = get_packages()\n    for package in packages:\n        if not package in p:\n            install_package(package)\n            if env.verbosity:\n                print ' * installed',package\n            env.installed_packages[env.host].append(package)\n    if env.overwrite or env.installed_packages[env.host]: #always store the latest complete list\n        set_server_state('packages_installed', packages)\n        env.installed_packages[env.host] = packages\n\n    if env.overwrite and 'apache2' in env.installed_packages[env.host]: \n            #some sensible defaults -might move to putting this config in a template\n            sudo(\"rm -f /etc/apache2/sites-enabled/000-default\")\n            sed('/etc/apache2/apache2.conf',before='KeepAlive On',after='KeepAlive Off',use_sudo=True, backup='')\n            sed('/etc/apache2/apache2.conf',before='StartServers          2', after='StartServers          1', use_sudo=True, backup='')\n            sed('/etc/apache2/apache2.conf',before='MaxClients          150', after='MaxClients          100', use_sudo=True, backup='')\n            for module in env.APACHE_DISABLE_MODULES:\n                sudo('rm -f /etc/apache2/mods-enabled/%s*'% module)\n    #Install base python packages\n    #We'll use easy_install at this stage since it doesn't download if the package\n    #is current whereas pip always downloads.\n    #Once both these packages mature we'll move to using the standard Ubuntu packages\n    if (env.overwrite or not server_state('pip-venv-wrapper-installed')) and 'python-setuptools' in packages:\n        sudo(\"easy_install virtualenv\")\n        sudo(\"easy_install pip\")\n        sudo(\"easy_install virtualenvwrapper\")\n        if env.verbosity:\n            print \" * easy installed pip, virtualenv, virtualenvwrapper\"\n        set_server_state('pip-venv-wrapper-installed')\n    if not contains(\"/home/%s/.profile\"% env.user,\"source /usr/local/bin/virtualenvwrapper.sh\"):\n        append(\"/home/%s/.profile\"% env.user, \"export WORKON_HOME=$HOME/env\")\n        append(\"/home/%s/.profile\"% env.user, \"source /usr/local/bin/virtualenvwrapper.sh\")\n\n    #cleanup after easy_install\n    sudo(\"rm -rf build\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lsb_release():\n    \n    output = run('lsb_release -a').split('\\n')\n    release = _AttributeDict({})\n    for line in output:\n        try:\n            key, value = line.split(':')\n        except ValueError:\n            continue\n        release[key.strip().replace(' ','_').lower()]=value.strip()\n   \n    if exists('/etc/debian_version'): release.base = 'debian'\n    elif exists('/etc/redhat-release'): release.base = 'redhat'\n    else: release.base = 'unknown'\n    return release", "response": "Get the linux distribution information and return in an attribute dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if the default port and user is open for business.", "response": "def port_is_open():\n    \"\"\"\n    Determine if the default port and user is open for business.\n    \"\"\"\n    with settings(hide('aborts'), warn_only=True ):\n        try:\n            if env.verbosity:\n                print \"Testing node for previous installation on port %s:\"% env.port\n            distribution = lsb_release()\n        except KeyboardInterrupt:\n            if env.verbosity:\n                print >> sys.stderr, \"\\nStopped.\"\n            sys.exit(1)\n        except: #No way to catch the failing connection without catchall? \n            return False\n        if distribution.distributor_id <> 'Ubuntu':\n            print env.host, 'WARNING: Woven has only been tested on Ubuntu >= 10.04. It may not work as expected on',distribution.description\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restrict_ssh(rollback=False):\n\n    if not rollback:\n        if server_state('ssh_restricted'):\n            return False\n\n        sshd_config = '/etc/ssh/sshd_config'\n        if env.verbosity:\n            print env.host, \"RESTRICTING SSH with \"+sshd_config\n        filename = 'sshd_config'\n        if not exists('/home/%s/.ssh/authorized_keys'% env.user): #do not pass go do not collect $200\n            print env.host, 'You need to upload_ssh_key first.'\n            return False\n        _backup_file(sshd_config)\n        context = {\"HOST_SSH_PORT\": env.HOST_SSH_PORT}\n        \n        upload_template('woven/ssh/sshd_config','/etc/ssh/sshd_config',context=context,use_sudo=True)\n        # Restart sshd\n        sudo('/etc/init.d/ssh restart')\n        \n        # The user can modify the sshd_config file directly but we save\n        proceed = True\n        if not env.key_filename and (env.DISABLE_SSH_PASSWORD or env.INTERACTIVE) and contains('/etc/ssh/sshd_config','#PasswordAuthentication no',use_sudo=True):\n            print \"WARNING: You may want to test your node ssh login at this point ssh %s@%s -p%s\"% (env.user, env.host, env.port)\n            c_text = 'Would you like to disable password login and use only ssh key authentication'\n            proceed = confirm(c_text,default=False)\n    \n        if not env.INTERACTIVE or proceed or env.DISABLE_SSH_PASSWORD:\n            #uncomments PasswordAuthentication no and restarts\n            uncomment(sshd_config,'#(\\s?)PasswordAuthentication(\\s*)no',use_sudo=True)\n            sudo('/etc/init.d/ssh restart')\n        set_server_state('ssh_restricted')\n        return True\n    else: #Full rollback\n        _restore_file('/etc/ssh/sshd_config')\n        if server_state('ssh_port_changed'):\n            sed('/etc/ssh/sshd_config','Port '+ str(env.DEFAULT_SSH_PORT),'Port '+str(env.HOST_SSH_PORT),use_sudo=True)\n            sudo('/etc/init.d/ssh restart')\n        sudo('/etc/init.d/ssh restart')\n        set_server_state('ssh_restricted', delete=True)\n        return True", "response": "Restrict SSH to a specific node"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the time zone on the server using Django settings. TIME_ZONE", "response": "def set_timezone(rollback=False):\n    \"\"\"\n    Set the time zone on the server using Django settings.TIME_ZONE\n    \"\"\"\n    if not rollback:\n        if contains(filename='/etc/timezone', text=env.TIME_ZONE, use_sudo=True):\n            return False\n        if env.verbosity:\n            print env.host, \"CHANGING TIMEZONE /etc/timezone to \"+env.TIME_ZONE\n        _backup_file('/etc/timezone')\n        sudo('echo %s > /tmp/timezone'% env.TIME_ZONE)\n        sudo('cp -f /tmp/timezone /etc/timezone')\n        sudo('dpkg-reconfigure --frontend noninteractive tzdata')\n    else:\n        _restore_fie('/etc/timezone')\n        sudo('dpkg-reconfigure --frontend noninteractive tzdata')\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upgrade_packages():\n    if env.verbosity:\n        print env.host, \"apt-get UPDATING and UPGRADING SERVER PACKAGES\"\n        print \" * running apt-get update \"\n    sudo('apt-get -qqy update')\n    if env.verbosity:\n        print \" * running apt-get upgrade\"\n        print \" NOTE: apt-get upgrade has been known in rare cases to require user input.\"\n        print \"If apt-get upgrade does not complete within 15 minutes\"\n        print \"see troubleshooting docs *before* aborting the process to avoid package management corruption.\"\n    sudo('apt-get -qqy upgrade')", "response": "update and apt - get upgrade packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upload_etc():\n    role = env.role_lookup[env.host_string]\n    packages = env.packages[role]\n    #determine the templatedir\n    if env.verbosity:\n        print \"UPLOAD ETC configuration templates\"\n    if not hasattr(env, 'project_template_dir'):\n        #the normal pattern would mean the shortest path is the main one.\n        #its probably the last listed\n        length = 1000\n        env.project_template_dir = ''\n        for dir in env.TEMPLATE_DIRS:\n            if dir:\n                len_dir = len(dir)\n                if len_dir < length:\n                    length = len_dir\n                    env.project_template_dir = dir\n\n    template_dir = os.path.join(os.path.split(os.path.realpath(__file__))[0],'templates','')\n    default_templates = _get_template_files(template_dir)\n    if env.project_template_dir: user_templates = _get_template_files(os.path.join(env.project_template_dir,''))\n    else: user_templates = set([])\n    etc_templates = user_templates | default_templates\n\n    context = {'host_ip':socket.gethostbyname(env.host)}\n    if env.overwrite or env.installed_packages[env.host]: mod_only = False\n    else: mod_only = True\n    for t in etc_templates:\n        dest = t.replace('woven','',1)\n        directory,filename = os.path.split(dest)\n        package_name = filename.split('.')[0]\n        if directory in ['/etc','/etc/init.d','/etc/init','/etc/logrotate.d','/etc/rsyslog.d']:\n            #must be replacing an existing file\n            if not exists(dest) and package_name not in packages: continue\n        elif directory == '/etc/ufw/applications.d':\n            #must be a package name\n            if filename not in packages: continue\n        elif not exists(directory, use_sudo=True): continue\n        uploaded = upload_template(t,dest,context=context,use_sudo=True, modified_only=mod_only)\n            \n        if uploaded:\n            sudo(' '.join([\"chown root:root\",dest]))\n            if 'init.d' in dest: sudo(' '.join([\"chmod ugo+rx\",dest]))\n            else: sudo(' '.join([\"chmod ugo+r\",dest]))\n            if env.verbosity:\n                print \" * uploaded\",dest", "response": "Upload all templates in the woven directory to the respective directories on the nodes\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads your ssh key for passwordless logins", "response": "def upload_ssh_key(rollback=False):\n    \"\"\"\n    Upload your ssh key for passwordless logins\n    \"\"\"\n    auth_keys = '/home/%s/.ssh/authorized_keys'% env.user\n    if not rollback:\n        local_user = getpass.getuser()\n        host = socket.gethostname()\n        u = '@'.join([local_user,host])\n        u = 'ssh-key-uploaded-%s'% u\n        if not env.overwrite and server_state(u): return\n        if not exists('.ssh'):\n            run('mkdir .ssh')\n           \n        #determine local .ssh dir\n        home = os.path.expanduser('~')\n        ssh_key = None\n        upload_key = True\n        ssh_dsa = os.path.join(home,'.ssh/id_dsa.pub')\n        ssh_rsa =  os.path.join(home,'.ssh/id_rsa.pub')\n        if env.key_filename and env.INTERACTIVE:\n                upload_key = confirm('Would you like to upload your personal key in addition to %s'% str(env.key_filename), default=True)\n        if upload_key:  \n            if os.path.exists(ssh_dsa):\n                ssh_key = ssh_dsa\n            elif os.path.exists(ssh_rsa):\n                ssh_key = ssh_rsa\n    \n        if ssh_key:\n            ssh_file = open(ssh_key,'r').read()\n            \n            if exists(auth_keys):\n                _backup_file(auth_keys)\n            if env.verbosity:\n                print env.host, \"UPLOADING SSH KEY\"\n            append(auth_keys,ssh_file) #append prevents uploading twice\n            set_server_state(u)\n        return\n    else:\n        if exists(auth_keys+'.wovenbak'):\n            _restore_file('/home/%s/.ssh/authorized_keys'% env.user)\n        else: #no pre-existing keys remove the .ssh directory\n            sudo('rm -rf /home/%s/.ssh')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate text files from the cables in in_dir and writes them to out_dir.", "response": "def generate_text_files(in_dir, out_dir, include_header=False):\n    \"\"\"\\\n    Walks through the `in_dir` and generates text versions of\n    the cables in the `out_dir`.\n    \"\"\"\n    for cable in cables_from_source(in_dir):\n        out = codecs.open(out_dir + '/' + cable.reference_id + '.txt', 'wb', encoding='utf-8')\n        out.write(cable_to_text(cable, include_header))\n        out.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the stack from given frame while excluded any symbolized frame.", "response": "def extract_stack(frame, context=10, exceptionsFrameSymbol=EXCEPTIONS_FRAME_SYMBOL):\n    \"\"\"\n    Extracts the stack from given frame while excluded any symbolized frame.\n\n    :param frame: Frame.\n    :type frame: Frame\n    :param context: Context to extract.\n    :type context: int\n    :param exceptionsFrameSymbol: Stack trace frame tag.\n    :type exceptionsFrameSymbol: unicode\n    :return: Stack.\n    :rtype: list\n    \"\"\"\n\n    decode = lambda x: unicode(x, Constants.default_codec, Constants.codec_error)\n\n    stack = []\n\n    for frame, file_name, line_number, name, context, index in inspect.getouterframes(frame, context):\n        if frame.f_locals.get(exceptionsFrameSymbol):\n            continue\n\n        stack.append((frame,\n                      decode(file_name),\n                      line_number,\n                      decode(name),\n                      context if context is not None else [],\n                      index if index is not None else -1))\n\n    return list(reversed(stack))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the arguments from given Frame.", "response": "def extract_arguments(frame):\n    \"\"\"\n    Extracts the arguments from given frame.\n\n    :param frame: Frame.\n    :type frame: object\n    :return: Arguments.\n    :rtype: tuple\n    \"\"\"\n\n    arguments = ([], None, None)\n    try:\n        source = textwrap.dedent(\"\".join(inspect.getsourcelines(frame)[0]).replace(\"\\\\\\n\", \"\"))\n    except (IOError, TypeError) as error:\n        return arguments\n\n    try:\n        node = ast.parse(source)\n    except:\n        return arguments\n\n    if not node.body:\n        return arguments\n\n    node = node.body[0]\n    if not isinstance(node, ast.FunctionDef):\n        return arguments\n\n    return [arg.id for arg in node.args.args], node.args.vararg, node.args.kwarg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_locals(trcback):\n\n    output = []\n    stack = extract_stack(get_inner_most_frame(trcback))\n    for frame, file_name, line_number, name, context, index in stack:\n        args_names, nameless, keyword = extract_arguments(frame)\n        arguments, nameless_args, keyword_args, locals = OrderedDict(), [], {}, {}\n        for key, data in frame.f_locals.iteritems():\n            if key == nameless:\n                nameless_args = map(repr, frame.f_locals.get(nameless, ()))\n            elif key == keyword:\n                keyword_args = dict((arg, repr(value)) for arg, value in frame.f_locals.get(keyword, {}).iteritems())\n            elif key in args_names:\n                arguments[key] = repr(data)\n            else:\n                locals[key] = repr(data)\n        output.append(((name, file_name, line_number), (arguments, nameless_args, keyword_args, locals)))\n    return output", "response": "Extracts the frames locals of a traceback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_exception(*args):\n\n    cls, instance, trcback = sys.exc_info()\n\n    exceptions = filter(lambda x: issubclass(type(x), BaseException), args)\n    trcbacks = filter(lambda x: issubclass(type(x), types.TracebackType), args)\n\n    cls, instance = (type(exceptions[0]), exceptions[0]) if exceptions else (cls, instance)\n    trcback = trcbacks[0] if trcbacks else trcback\n\n    return cls, instance, trcback", "response": "Extracts the exception from given arguments or from sys. exc_info."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_exception(cls, instance, trcback, context=1):\n\n    stack = extract_stack(get_inner_most_frame(trcback), context=context)\n    output = []\n    output.append(\"Traceback (most recent call last):\")\n    for frame, file_name, line_number, name, context, index in stack:\n        output.append(\"  File \\\"{0}\\\", line {1}, in {2}\".format(file_name, line_number, name))\n        for line in context:\n            output.append(\"    {0}\".format(line.strip()))\n    for line in traceback.format_exception_only(cls, instance):\n        output.append(\"{0}\".format(line))\n    return output", "response": "| Formats given exception.\n    | The code produce a similar output to :func:`traceback.format_exception` except that it allows frames to be excluded\n        from the stack if the given stack trace frame tag is found in the frame locals and set **True**.\n\n    :param cls: Exception class.\n    :type cls: object\n    :param instance: Exception instance.\n    :type instance: object\n    :param trcback: Traceback.\n    :type trcback: Traceback\n    :param context: Context being included.\n    :type context: int\n    :return: Formated exception.\n    :rtype: list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting a report using given exception.", "response": "def format_report(cls, instance, trcback, context=1):\n    \"\"\"\n    Formats a report using given exception.\n\n    :param cls: Exception class.\n    :type cls: object\n    :param instance: Exception instance.\n    :type instance: object\n    :param trcback: Traceback.\n    :type trcback: Traceback\n    :param context: Context being included.\n    :type context: int\n    :return: Formated report.\n    :rtype: tuple\n    \"\"\"\n\n    header = []\n    header.append(\"Exception in '{0}'.\".format(get_inner_most_frame(trcback).f_code.co_name))\n    header.append(\"Exception class: '{0}'.\".format(cls.__name__))\n    header.append(\"Exception description: '{0}'.\".format(instance.__doc__ and instance.__doc__.strip() or\n                                                         Constants.null_object))\n    for i, line in enumerate(str(instance).split(\"\\n\")):\n        header.append(\"Exception message line no. '{0}' : '{1}'.\".format(i + 1, line))\n\n    frames = []\n    for frame, locals in extract_locals(trcback):\n        frames.append(\"Frame '{0}' in '{1}' at line '{2}':\".format(*frame))\n        arguments, nameless_args, keyword_args, locals = locals\n        any((arguments, nameless_args, keyword_args)) and frames.append(\"{0:>40}\".format(\"Arguments:\"))\n        for key, value in arguments.iteritems():\n            frames.append(\"{0:>40} = {1}\".format(key, value))\n        for value in nameless_args:\n            frames.append(\"{0:>40}\".format(value))\n        for key, value in sorted(keyword_args.iteritems()):\n            frames.append(\"{0:>40} = {1}\".format(key, value))\n        locals and frames.append(\"{0:>40}\".format(\"Locals:\"))\n        for key, value in sorted(locals.iteritems()):\n            frames.append(\"{0:>40} = {1}\".format(key, value))\n        frames.append(\"\")\n\n    trcback = format_exception(cls, instance, trcback)\n\n    return header, frames, trcback"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprovides the base exception handler.", "response": "def base_exception_handler(*args):\n    \"\"\"\n    Provides the base exception handler.\n\n    :param \\*args: Arguments.\n    :type \\*args: \\*\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    header, frames, trcback = format_report(*extract_exception(*args))\n\n    LOGGER.error(\"!> {0}\".format(Constants.logging_separators))\n    map(lambda x: LOGGER.error(\"!> {0}\".format(x)), header)\n\n    LOGGER.error(\"!> {0}\".format(Constants.logging_separators))\n    map(lambda x: LOGGER.error(\"!> {0}\".format(x)), frames)\n\n    LOGGER.error(\"!> {0}\".format(Constants.logging_separators))\n    sys.stderr.write(\"\\n\".join(trcback))\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating a URL s existing GET parameters.", "response": "def update_parameters(url, parameters, encoding='utf8'):\n  \"\"\" Updates a URL's existing GET parameters.\n\n  :param url: a base URL to which to add additional parameters.\n  :param parameters: a dictionary of parameters, any mix of\n    unicode and string objects as the parameters and the values.\n  :parameter encoding: the byte encoding to use when passed unicode\n    for the base URL or for keys and values of the parameters dict. This\n    isnecessary because `urllib.urlencode` calls the `str()` function on all of\n    its inputs.  This raises a `UnicodeDecodeError` when it encounters a\n    unicode string with characters outside of the default ASCII charset.\n  :rtype: a string URL.\n  \"\"\"\n  # Convert  the base URL to the default encoding.\n  if isinstance(url, unicode):\n    url = url.encode(encoding)\n\n  parsed_url = urlparse.urlparse(url)\n  existing_query_parameters = urlparse.parse_qsl(parsed_url.query)\n\n  # Convert unicode parameters to the default encoding.\n  byte_parameters = []\n  for key, value in (existing_query_parameters + parameters.items()):\n    if isinstance(key, unicode):\n      key = key.encode(encoding)\n    if isinstance(value, unicode):\n      value = value.encode(encoding)\n    byte_parameters.append((key, value))\n\n  # Generate the final URL with all of the updated parameters. Read\n  # http://docs.python.org/2/library/urlparse.html#urlparse.urlparse if this is\n  # confusing.\n  return urlparse.urlunparse((\n      parsed_url.scheme,\n      parsed_url.netloc,\n      parsed_url.path,\n      parsed_url.params,\n      urlencode(byte_parameters),\n      parsed_url.fragment\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_directory(path):\n\n    try:\n        if not foundations.common.path_exists(path):\n            LOGGER.debug(\"> Creating directory: '{0}'.\".format(path))\n            os.makedirs(path)\n            return True\n        else:\n            LOGGER.debug(\"> '{0}' directory already exist, skipping creation!\".format(path))\n            return True\n    except Exception as error:\n        raise foundations.exceptions.DirectoryCreationError(\n            \"!> {0} | Cannot create '{1}' directory: '{2}'\".format(__name__, path, error))", "response": "Sets the directory path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy given file or directory to destination.", "response": "def copy(source, destination):\n    \"\"\"\n    Copies given file or directory to destination.\n\n    :param source: Source to copy from.\n    :type source: unicode\n    :param destination: Destination to copy to.\n    :type destination: unicode\n    :return: Method success.\n    :rtype: bool\n    \"\"\"\n\n    try:\n        if os.path.isfile(source):\n            LOGGER.debug(\"> Copying '{0}' file to '{1}'.\".format(source, destination))\n            shutil.copyfile(source, destination)\n        else:\n            LOGGER.debug(\"> Copying '{0}' directory to '{1}'.\".format(source, destination))\n            shutil.copytree(source, destination)\n        return True\n    except Exception as error:\n        raise foundations.exceptions.PathCopyError(\n            \"!> {0} | Cannot copy '{1}' path: '{2}'\".format(__name__, source, error))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(path):\n\n    try:\n        if os.path.isfile(path):\n            LOGGER.debug(\"> Removing '{0}' file.\".format(path))\n            os.remove(path)\n        elif os.path.isdir(path):\n            LOGGER.debug(\"> Removing '{0}' directory.\".format(path))\n            shutil.rmtree(path)\n        return True\n    except Exception as error:\n        raise foundations.exceptions.PathRemoveError(\n            \"!> {0} | Cannot remove '{1}' path: '{2}'\".format(__name__, path, error))", "response": "Removes given path.\n\n    :param path: Path to remove.\n    :type path: unicode\n    :return: Method success.\n    :rtype: bool"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_readable(path):\n\n    if os.access(path, os.R_OK):\n        LOGGER.debug(\"> '{0}' path is readable.\".format(path))\n        return True\n    else:\n        LOGGER.debug(\"> '{0}' path is not readable.\".format(path))\n        return False", "response": "Returns if given path is readable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning if given path is writable.", "response": "def is_writable(path):\n    \"\"\"\n    Returns if given path is writable.\n\n    :param path: Path to check access.\n    :type path: unicode\n    :return: Is path writable.\n    :rtype: bool\n    \"\"\"\n\n    if os.access(path, os.W_OK):\n        LOGGER.debug(\"> '{0}' path is writable.\".format(path))\n        return True\n    else:\n        LOGGER.debug(\"> '{0}' path is not writable.\".format(path))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_binary_file(file):\n\n    file_handle = open(file, \"rb\")\n    try:\n        chunk_size = 1024\n        while True:\n            chunk = file_handle.read(chunk_size)\n            if chr(0) in chunk:\n                return True\n            if len(chunk) < chunk_size:\n                break\n    finally:\n        file_handle.close()\n    return False", "response": "Returns if given file is a binary file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the path of the object.", "response": "def path(self, value):\n        \"\"\"\n        Setter for **self.__path** attribute.\n\n        :param value: Attribute value.\n        :type value: unicode\n        \"\"\"\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\"path\", value)\n        self.__path = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef content(self, value):\n\n        if value is not None:\n            assert type(value) is list, \"'{0}' attribute: '{1}' type is not 'list'!\".format(\"content\", value)\n        self.__content = value", "response": "Set the content of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cache(self, mode=\"r\", encoding=Constants.default_codec, errors=Constants.codec_error):\n\n        self.uncache()\n\n        if foundations.strings.is_website(self.__path):\n            try:\n                LOGGER.debug(\"> Caching '{0}' online file content.\".format(self.__path))\n                self.__content = urllib2.urlopen(self.__path).readlines()\n                return True\n            except urllib2.URLError as error:\n                raise foundations.exceptions.UrlReadError(\n                    \"!> {0} | '{1}' url is not readable: '{2}'.\".format(self.__class__.__name__, self.__path, error))\n        elif foundations.common.path_exists(self.__path):\n            if not is_readable(self.__path):\n                raise foundations.exceptions.FileReadError(\n                    \"!> {0} | '{1}' file is not readable!\".format(self.__class__.__name__, self.__path))\n\n            with codecs.open(self.__path, mode, encoding, errors) as file:\n                LOGGER.debug(\"> Caching '{0}' file content.\".format(self.__path))\n                self.__content = file.readlines()\n                return True\n        return False", "response": "Reads given file content and stores it in the content cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uncache(self):\n\n        LOGGER.debug(\"> Uncaching '{0}' file content.\".format(self.__path))\n\n        self.__content = []\n        return True", "response": "Uncaches the cached content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends content to defined file.", "response": "def append(self, mode=\"a\", encoding=Constants.default_codec, errors=Constants.codec_error):\n        \"\"\"\n        Appends content to defined file.\n\n        :param mode: File write mode.\n        :type mode: unicode\n        :param encoding: File encoding codec.\n        :type encoding: unicode\n        :param errors: File encoding errors handling.\n        :type errors: unicode\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        if foundations.strings.is_website(self.__path):\n            raise foundations.exceptions.UrlWriteError(\n                \"!> {0} | '{1}' url is not writable!\".format(self.__class__.__name__, self.__path))\n\n        if foundations.common.path_exists(self.__path):\n            if not is_writable(self.__path):\n                raise foundations.exceptions.FileWriteError(\n                    \"!> {0} | '{1}' file is not writable!\".format(self.__class__.__name__, self.__path))\n\n        with codecs.open(self.__path, mode, encoding, errors) as file:\n            LOGGER.debug(\"> Appending to '{0}' file content.\".format(self.__path))\n            for line in self.__content:\n                file.write(line)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self, encoding=Constants.default_codec):\n\n        if foundations.strings.is_website(self.__path):\n            raise foundations.exceptions.UrlWriteError(\n                \"!> {0} | '{1}' url is not writable!\".format(self.__class__.__name__, self.__path))\n\n        if self.uncache():\n            LOGGER.debug(\"> Clearing '{0}' file content.\".format(self.__path))\n            return self.write(encoding=encoding)\n        else:\n            return False", "response": "Clears the defined file content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cpp_best_split_full_model(X, Uy, C, S, U, noderange, delta,\n                              save_memory=False):\n    \"\"\"wrappe calling cpp splitting function\"\"\"\n    return CSP.best_split_full_model(X, Uy, C, S, U, noderange, delta)", "response": "wrappe calling cpp splitting function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef route(self, environ, start_response):\n        urls = self.url_map.bind_to_environ(environ)\n        request = WsgiRequest(environ)\n        try:\n            endpoint, args = urls.match()\n        except HTTPException as e:\n            return self.error(e.code, request)(environ, start_response)\n        else:\n            procedure = getattr(self, endpoint)\n            response = procedure(request, args)\n            return response(environ, start_response)", "response": "Route the request to the next HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef error(self, status_code, request, message=None):\n        status_code_text = HTTP_STATUS_CODES.get(status_code, 'http error')\n        status_error_tag = status_code_text.lower().replace(' ', '_')\n        custom_response_map = {\n            404: self.make_error_response(\n                status_error_tag,\n                'The requested URL {} was not found on this service.'.format(\n                    request.path\n                )\n            ),\n            400: self.make_error_response(status_error_tag, message),\n            405: self.make_error_response(\n                status_error_tag,\n                'The requested URL {} was not allowed HTTP method {}.'.format(\n                    request.path, request.method\n                )\n            ),\n        }\n        return self._raw_response(\n            status_code,\n            custom_response_map.get(\n                status_code,\n                self.make_error_response(\n                    status_error_tag, message or status_code_text\n                )\n            )\n        )", "response": "Handle error response.\n\n        :param int status_code:\n        :param request:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef auth_pair(self, force_console=False):\n        if not self.auth_valid():\n            self._get_auth(force_console)\n        return (self.user, self.password)", "response": "Return username and password tuple possibly prompting the user for them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_auth(self, force_console=False):\n        if not self.target:\n            raise ValueError(\"Unspecified target ({!r})\".format(self.target))\n        elif not force_console and self.URL_RE.match(self.target):\n            auth_url = urlparse(self.target)\n            source = 'url'\n            if auth_url.username:\n                self.user = auth_url.username\n            if auth_url.password:\n                self.password = auth_url.password\n            if not self.auth_valid():\n                source = self._get_auth_from_keyring()\n            if not self.auth_valid():\n                source = self._get_auth_from_netrc(auth_url.hostname)\n            if not self.auth_valid():\n                source = self._get_auth_from_console(self.target)\n        else:\n            source = self._get_auth_from_console(self.target)\n\n        if self.auth_valid():\n            self.source = source", "response": "Try to get login auth from known sources."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprompt for the user and password and return the realm name.", "response": "def _get_auth_from_console(self, realm):\n        \"\"\"Prompt for the user and password.\"\"\"\n        self.user, self.password = self.AUTH_MEMOIZE_INPUT.get(realm, (self.user, None))\n        if not self.auth_valid():\n            if not self.user:\n                login = getpass.getuser()\n                self.user = self._raw_input('Username for \"{}\" [{}]: '.format(realm, login)) or login\n            self.password = getpass.getpass('Password for \"{}\": '.format(realm))\n            Credentials.AUTH_MEMOIZE_INPUT[realm] = self.user, self.password\n\n        return 'console'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to find login auth in netrc file and set self. user and self. password.", "response": "def _get_auth_from_netrc(self, hostname):\n        \"\"\"Try to find login auth in ``~/.netrc``.\"\"\"\n        try:\n            hostauth = netrc(self.NETRC_FILE)\n        except IOError as cause:\n            if cause.errno != errno.ENOENT:\n                raise\n            return None\n        except NetrcParseError as cause:\n            raise  # TODO: Map to common base class, so caller has to handle less error types?\n\n        # Try to find specific `user@host` credentials first, then just `host`\n        auth = hostauth.hosts.get('{}@{}'.format(self.user or getpass.getuser(), hostname), None)\n        if not auth:\n            auth = hostauth.hosts.get(hostname, None)\n\n        if auth:\n            username, account, password = auth  # pylint: disable=unpacking-non-sequence\n            if username:\n                self.user = username\n            if password == 'base64':\n                # support for password obfuscation, prevent \"over the shoulder lookup\"\n                self.password = account.decode('base64')\n            elif password:\n                self.password = password\n\n        return 'netrc'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to get credentials using keyring.", "response": "def _get_auth_from_keyring(self):\n        \"\"\"Try to get credentials using `keyring <https://github.com/jaraco/keyring>`_.\"\"\"\n        if not keyring:\n            return None\n\n        # Take user from URL if available, else the OS login name\n        password = self._get_password_from_keyring(self.user or getpass.getuser())\n        if password is not None:\n            self.user = self.user or getpass.getuser()\n            self.password = password\n\n        return 'keyring'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef service(container, name=None):\n    def register(service):\n        container.add_service(service, name)\n        return service\n\n    return register", "response": "A decorator to register a service on a container."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef provider(container, cache, name=None):\n    def register(provider):\n        container.add_provider(provider, cache, name)\n        return provider\n\n    return register", "response": "A decorator to register a provider on a container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value registered with name and determines whether the value is a provider or a configuration setting.", "response": "def provide(self, name):\n        \"\"\"Gets the value registered with ``name`` and determines whether the\n        value is a provider or a configuration setting. The ``KeyError`` is\n        raised when the ``name`` is not found.\n\n        The registered value is interpreted as a provider if it's callable. The\n        provider is called with a single argument, the current\n        :class:`Container` object. Returns the return value of a provider or\n        the value itself in case the value is not callable.\n\n        :param name:\n            The name of the provider or configuration setting.\n        \"\"\"\n        rv = self[name]\n        return rv(self) if callable(rv) else rv"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a provider on the container.", "response": "def add_provider(self, provider, cache, name=None):\n        \"\"\"Registers a provider on the container.\n\n        :param provider:\n            Anything that's callable and expects exactly one argument, the\n            :class:`Container` object.\n        :param cache:\n            Whether to cache the return value of the provider.\n        :param name:\n            Alternative name of the provider.\n            Default: name of the callable.\n        \"\"\"\n        register_as = name or provider.__name__\n        self[register_as] = FunctionCache(provider) if cache else provider"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if the return value is cached. Always returns false if the registered value is not an instance of FunctionCache.", "response": "def is_cached(self, name):\n        \"\"\"Determines if the return value is cached. Always returns false if\n        the registered value is not an instance of :class:`FunctionCache`.\n\n        :param name:\n            The name of the provider.\n        \"\"\"\n        try:\n            cached = super(Container, self).get(name).cached\n        except AttributeError:\n            cached = False\n\n        return cached"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy the content of origin to dstPath in a safe manner.", "response": "def copy_content(origin, dstPath, blockSize, mode):\n    ''' copy the content of `origin` to `dstPath` in a safe manner.\n\n        this function will first copy the content to a temporary file\n        and then move it atomically to the requested destination.\n\n        if some error occurred during content copy or file movement\n        the temporary file will be deleted.\n    '''\n    tmpFD, tmpPath = tempfile.mkstemp(prefix=os.path.basename(dstPath) + \"_\", suffix='.tmp', dir=os.path.dirname(dstPath))\n    try:\n        try:\n            # change mode of the temp file\n            oldmask = os.umask(0)\n            try:\n                os.chmod(tmpPath, mode)\n            finally:\n                os.umask(oldmask)\n            # copy content to temporary file\n            while True:\n                chunk = origin.read(blockSize)\n                if not chunk:\n                    break\n                os.write(tmpFD, chunk)\n        finally:\n            os.close(tmpFD)\n\n        # move temporary file to actual requested destination\n        try:\n            os.rename(tmpPath, dstPath)\n        except OSError as e:\n            # on Windows if dstPath already exists at renaming time, an OSError is raised.\n            if platform.system() is 'Windows' and e.errno is errno.EEXIST:\n                pass\n            else:\n                raise\n    except:\n        os.remove(tmpPath)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self):\n\n        try:\n            # START SELENIUM GRID\n            if BROME_CONFIG['grid_runner']['start_selenium_server']:\n                self.start_selenium_server()\n\n            # Get all the browsers id\n            self.browsers_id = BROME_CONFIG['runner_args']['remote_runner'].split(',')  # noqa\n\n            # Start all the instances\n            instance_threads = []\n            for i, browser_id in enumerate(self.browsers_id):\n                browser_config = BrowserConfig(\n                    runner=self,\n                    browser_id=browser_id,\n                    browsers_config=BROME_CONFIG['browsers_config']\n                )\n\n                self.browser_configs[browser_id] = browser_config\n\n                # EC2\n                if browser_config.location == 'ec2':\n\n                    max_number_of_instance = browser_config.get(\n                        'max_number_of_instance'\n                    )\n                    nb_browser_by_instance = browser_config.get(\n                        'nb_browser_by_instance'\n                    )\n\n                    if len(self.tests) < \\\n                            max_number_of_instance * \\\n                            nb_browser_by_instance:\n\n                        nb_instance_to_launch = int(\n                            math.ceil(\n                                float(len(self.tests))/nb_browser_by_instance\n                            )\n                        )\n\n                    else:\n                        nb_instance_to_launch = max_number_of_instance\n\n                    for j in range(nb_instance_to_launch):\n                        _ec2_instance = ec2_instance.EC2Instance(\n                            runner=self,\n                            browser_config=browser_config,\n                            index=j\n                        )\n\n                        ec2_instance_thread = InstanceThread(_ec2_instance)\n                        ec2_instance_thread.start()\n\n                        instance_threads.append(ec2_instance_thread)\n\n                # VIRTUALBOX\n                elif browser_config.location == 'virtualbox':\n                    vbox_instance = virtualbox_instance.VirtualboxInstance(\n                        runner=self,\n                        browser_config=browser_config,\n                        index=i,\n                    )\n\n                    vbox_instance_thread = InstanceThread(vbox_instance)\n                    vbox_instance_thread.start()\n\n                    instance_threads.append(vbox_instance_thread)\n\n                # SAUCELABS\n                elif browser_config.location == 'saucelabs':\n\n                    if not self.instances.get(browser_id):\n                        self.instances[browser_id] = []\n\n                    self.instances[browser_id].append(\n                        saucelabs_instance.SauceLabsInstance()\n                    )\n\n                # BROWSERSTACK\n                elif browser_config.location == 'browserstack':\n\n                    if not self.instances.get(browser_id):\n                        self.instances[browser_id] = []\n\n                    self.instances[browser_id].append(\n                        browserstack_instance.BrowserstackInstance()\n                    )\n\n                # LOCALHOST\n                elif browser_config.location == 'localhost':\n\n                    max_number_of_instance = browser_config.get(\n                        'max_number_of_instance', 1\n                    )\n\n                    if len(self.tests) < max_number_of_instance:\n                        nb_instance_to_launch = len(self.tests)\n                    else:\n                        nb_instance_to_launch = max_number_of_instance\n\n                    for i in range(0, nb_instance_to_launch):\n                        if not self.instances.get(browser_id):\n                            self.instances[browser_id] = []\n\n                        self.instances[browser_id].append(\n                            localhost_instance.LocalhostInstance(\n                                self,\n                                browser_config,\n                                test_name=i\n                            )\n                        )\n\n            # MILESTONE\n            if len(instance_threads):\n                with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                    test_batch = session.query(Testbatch)\\\n                        .filter(Testbatch.mongo_id == self.test_batch_id).one()\n                    test_batch.add_milestone(\n                        'NbInstanceToSetup',\n                        {'nb': len(instance_threads)}\n                    )\n                    session.save(test_batch, safe=True)\n\n            for t in instance_threads:\n                t.join()\n\n            self.info_log(\"The test batch is now ready!\")\n\n            # MILESTONE\n            if len(instance_threads):\n                with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                    test_batch = session.query(Testbatch)\\\n                        .filter(Testbatch.mongo_id == self.test_batch_id).one()\n                    test_batch.add_milestone('InstanceSetupCompleted')\n                    session.save(test_batch, safe=True)\n\n            try:\n                self.run()\n            except:\n                tb = traceback.format_exc()\n                self.error_log(\n                    \"Exception in run of the grid runner: %s\"\n                    % str(tb)\n                )\n                raise\n\n            finally:\n                try:\n                    self.tear_down_instances()\n\n                    # MILESTONE\n                    with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                        test_batch = session.query(Testbatch)\\\n                            .filter(Testbatch.mongo_id == self.test_batch_id)\\\n                            .one()\n                        test_batch.add_milestone('InstanceTearDownCompleted')\n                        session.save(test_batch, safe=True)\n\n                    # Kill selenium server\n                    if BROME_CONFIG['grid_runner']['kill_selenium_server']:  # noqa\n                        if self.selenium_pid:\n                            self.kill_pid(self.selenium_pid)\n\n                            # MILESTONE\n                            with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                                test_batch = session.query(Testbatch)\\\n                                    .filter(Testbatch.mongo_id == self.test_batch_id).one()  # noqa\n                                test_batch.add_milestone(\n                                    'SeleniumServerKilled'\n                                )\n                                session.save(test_batch, safe=True)\n\n                    # Kill xvfb process\n                    for xvfb_pid in self.xvfb_pids:\n                        self.kill_pid(xvfb_pid)\n\n                except:\n                    tb = traceback.format_exc()\n                    self.error_log(\"Exception in finally block of the grid runner: %s\" % str(tb))  # noqa\n        except:\n            self.set_ending_timestamp()\n            tb = traceback.format_exc()\n            self.error_log(\"Exception in finally block of the grid runner: %s\" % str(tb))  # noqa\n            raise\n\n        self.info_log(\"The test batch is finished.\")", "response": "Execute the test batch batch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun all the test in the test batch", "response": "def run(self):\n        \"\"\"Run all the test in the test batch\n        \"\"\"\n\n        executed_tests = []\n        try:\n\n            active_thread = 0\n            start_thread = True\n            current_index = 0\n            active_thread_by_browser_id = {}\n\n            test_index_by_browser_id = {}\n            for browser_id in self.browsers_id:\n                test_index_by_browser_id[browser_id] = 0\n\n            self.kill_test_batch_if_necessary()\n\n            while active_thread or start_thread:\n                start_thread = False\n\n                self.kill_test_batch_if_necessary()\n\n                for browser_id in self.browsers_id:\n\n                    if active_thread_by_browser_id.get(browser_id) is None:\n                        active_thread_by_browser_id[browser_id] = 0\n                    else:\n                        current_active_thread = 0\n                        for thread in threading.enumerate():\n\n                            # Make sure that the thread is TestThread\n                            if hasattr(thread, 'test'):\n                                if thread.test._browser_config.browser_id == browser_id:  # noqa\n                                    current_active_thread += 1\n\n                        active_thread_by_browser_id[browser_id] = current_active_thread  # noqa\n\n                    for j in range(0, len(self.instances[browser_id]) - active_thread_by_browser_id[browser_id]):  # noqa\n\n                        self.kill_test_batch_if_necessary()\n\n                        if test_index_by_browser_id[browser_id] < len(self.tests):  # noqa\n                            current_index += 1\n\n                            test = self.tests[test_index_by_browser_id[browser_id]]  # noqa\n\n                            test_index_by_browser_id[browser_id] += 1\n\n                            test_ = test.Test(\n                                runner=self,\n                                test_batch_id=self.test_batch_id,\n                                browser_config=self.browser_configs[browser_id],  # noqa\n                                name=test.Test.name,\n                                index=test_index_by_browser_id[browser_id]\n                            )\n                            test_.pdriver.embed_disabled = True\n\n                            thread = TestThread(test_)\n                            thread.start()\n\n                            executed_tests.append(test_)\n\n                active_thread = len([tn for tn in threading.enumerate() if type(tn) != threading._MainThread and hasattr(tn, 'test')])  # noqa\n                # self.info_log(\"active_thread=%s\" % active_thread)\n                if active_thread:\n                    try:\n                        active_thread_test_number = len([tn for tn in threading.enumerate() if type(tn) != threading._MainThread and hasattr(tn, 'test')])  # noqa\n                        self.info_log(\"Active thread number: %s\" % active_thread_test_number)  # noqa\n                        self.info_log(\"Active thread name: %s\" % (', '.join([  # noqa\n                                \"%s-%s\" % (\n                                    th.test._browser_config.browser_id,\n                                    th.test._name\n                                ) for th in threading.enumerate() if type(th) != threading._MainThread and hasattr(th, 'test')  # noqa\n                            ])\n                        ))\n                    except Exception as e:\n                        self.error_log(\"print active exception: %s\" % str(e))\n\n                # TIMEOUT\n                now = utcnow()\n                if (self.starting_timestamp - now).total_seconds() >\\\n                        BROME_CONFIG['grid_runner']['max_running_time']:\n\n                    self.error_log(\"max_running_time reached... terminating!\")\n                    raise TestRunnerKilledException()\n\n                self.kill_test_batch_if_necessary()\n\n                sleep(10)\n\n        except TestRunnerKilledException:\n            pass\n\n        except Exception:\n            tb = traceback.format_exc()\n            self.error_log(\"Run exception: %s\" % str(tb))\n\n        self.set_ending_timestamp()\n\n        self.print_test_summary(executed_tests)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntears down all instances in the system", "response": "def tear_down_instances(self):\n        \"\"\"Tear down all instances\n        \"\"\"\n\n        self.info_log('Tearing down all instances...')\n\n        for instance in self.alive_instances:\n            instance.tear_down()\n\n        self.info_log('[Done]Tearing down all instances')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_selenium_server(self):\n\n        ip = BROME_CONFIG['grid_runner']['selenium_server_ip']\n        port = BROME_CONFIG['grid_runner']['selenium_server_port']\n\n        def is_selenium_server_is_running():\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            result = s.connect_ex((ip, port))\n            s.close()\n            return not result\n\n        if not is_selenium_server_is_running():\n            self.info_log('Starting selenium server...')\n\n            command = BROME_CONFIG['grid_runner']['selenium_server_command']\\\n                .format(\n                    **BROME_CONFIG['grid_runner']\n                )\n\n            self.info_log('Selenium hub command: %s' % command)\n\n            process = Popen(\n                command.split(' '),\n                stdout=open(os.path.join(self.runner_dir, \"hub.log\"), 'a'),\n                stderr=open(os.path.join(self.runner_dir, \"hub.log\"), 'a'),\n            )\n\n            self.selenium_pid = process.pid\n\n            self.info_log('Selenium server pid: %s' % self.selenium_pid)\n        else:\n            self.info_log('Selenium is already running.')\n\n            # Milestone\n            with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                test_batch = session.query(Testbatch)\\\n                    .filter(Testbatch.mongo_id == self.test_batch_id).one()  # noqa\n                test_batch.add_milestone(\n                    'SeleniumServerAlreadyRunning'\n                )\n                session.save(test_batch, safe=True)\n\n            return True\n\n        for i in range(30):\n            self.info_log('Waiting for the selenium server to start...')\n            result = is_selenium_server_is_running()\n\n            if result:\n                self.info_log('[Done]Selenium server is running.')\n\n                # Milestone\n                with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                    test_batch = session.query(Testbatch)\\\n                        .filter(Testbatch.mongo_id == self.test_batch_id).one()  # noqa\n                    test_batch.add_milestone(\n                        'SeleniumServerStarted'\n                    )\n                    session.save(test_batch, safe=True)\n\n                return True\n            sleep(2)\n\n        raise Exception(\"Selenium server did not start!\")", "response": "Start the selenium server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_config(self):\n\n        # LOCALHOST\n        if self.location == 'localhost':\n            if 'browserName' not in self.config.keys():\n                msg = \"Add the 'browserName' in your local_config: e.g.: 'Firefox', 'Chrome', 'Safari'\"  # noqa\n                self.runner.critical_log(msg)\n                raise BromeBrowserConfigException(msg)\n\n        # EC2\n        elif self.location == 'ec2':\n            self.validate_ec2_browser_config()\n\n        # VIRTUALBOX\n        elif self.location == 'virtualbox':\n            self.validate_virtualbox_config()", "response": "Validate that the browser config contains all the needed config."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that ec2 config is conform to the ec2 browser", "response": "def validate_ec2_browser_config(self):\n        \"\"\"Validate that the ec2 config is conform\n        \"\"\"\n\n        if self.config.get('launch', True):\n            required_keys = [\n                'browserName',\n                'platform',\n                'ssh_key_path',\n                'username',\n                'amiid',\n                'region',\n                'instance_type',\n                'security_group_ids',\n                'selenium_command'\n            ]\n        else:\n            required_keys = [\n                'browserName',\n                'platform'\n            ]\n\n        for key in required_keys:\n            if key not in self.config.keys():\n                msg = \"Add the config: %s\" % key\n                self.runner.critical_log(msg)\n                raise BromeBrowserConfigException(msg)\n\n        optional_keys = {\n            'terminate': True,\n            'launch': True,\n            'record_session': False,\n            'vnc_port': 5900,\n            'vnc_password': '',\n            'vnc_password_file': '~/.vnc/passwd',\n            'nb_browser_by_instance': 1,\n            'max_number_of_instance': 1,\n            'hub_ip': 'localhost'\n        }\n        for key, default in iter(optional_keys.items()):\n            if key not in self.config.keys():\n                self.runner.warning_log(\n                    \"Missing config: %s; using default: %s\" %\n                    (key, default)\n                )\n                self.config[key] = default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_contents(self):\n        with open(METADATA_FILE) as f:\n            lines = f.readlines()\n\n        lines = map(lambda x: x.strip(), lines)\n\n        exclude_strings = ['<begin_table>', '<end_table>']\n\n        list_of_databases_and_columns = filter(\n            lambda x: not x[0] in exclude_strings, [\n                list(value) for key, value in itertools.groupby(\n                    lines,\n                    lambda x: x in exclude_strings\n                )\n            ]\n        )\n\n        for iterator in list_of_databases_and_columns:\n            self.create_table_raw(\n                tablename=iterator[0],\n                columns=iterator[1:][:],\n            )\n\n        for i in self.tables:\n            i.load_contents()", "response": "Loads the contents of the tables into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstores the contents of tables into file.", "response": "def store_contents(self):\n        \"\"\"\n            Stores the contents of tables into file.\n        \"\"\"\n        string_buffer = os.linesep.join(\n            map(\n                lambda x: os.linesep.join(\n                    [\"<begin_table>\"] + [x.name] + x.columns + [\"<end_table>\"]\n                ),\n                self.tables\n            )\n        )\n\n        with open(METADATA_FILE, \"w\") as f:\n            f.write(string_buffer)\n\n        for i in self.tables:\n            i.store_contents()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_table(self, tablename):\n        self.tables = filter(lambda x: x.name != tablename, self.tables)", "response": "Deletes a table from the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the table who s name is tablename.", "response": "def get_table(self, tablename):\n        \"\"\"\n            Returns the table whoose name is tablename.\n        \"\"\"\n        temp = filter(lambda x: x.name == tablename, self.tables)\n        if temp == list():\n            raise Exception(\"No such table\")\n        return temp[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_column_list_prefixed(self):\n        return map(\n            lambda x: \".\".join([self.name, x]),\n            self.columns\n        )", "response": "Returns a list of column names prefixed with the name of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_column(self, column):\n        if \"(\" in str(column):\n            temp_list = column.split(\"(\")\n            key = temp_list[1].strip(\"()\")\n            func = temp_list[0].lower()\n        else:\n            key = column\n            func = None\n\n        if \".\" not in key:\n            for i in self.columns:\n                if i.split(\".\")[1] == key:\n                    key = i\n                    break\n\n        col = map(\n            lambda x: x.get(\n                key\n            ),\n            self.rows\n        )\n\n        if func is not None:\n            if func == \"sum\":\n                return [sum(col)]\n            elif func == \"max\":\n                return [max(col)]\n            elif func == \"min\":\n                return [min(col)]\n            elif func == \"avg\":\n                return [sum(col) / float(len(col))]\n            elif func == \"count\":\n                return [len(col)]\n            elif func == \"distinct\":\n                return list(set(col))\n            else:\n                raise Exception(\n                    \"Unknown function called on column\"\n                )\n\n        return col", "response": "Return the values having of column."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_row(self, key, value):\n        self.rows = filter(lambda x: x.get(key) != value, self.rows)", "response": "Deletes the rows where key = value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvert delete_row and returns the rows where key = value", "response": "def invert_delete_row(self, key, value):\n        \"\"\"\n            Inverts delete_row and returns the rows where key = value\n        \"\"\"\n        self.rows = filter(lambda x: x.get(key) == value, self.rows)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading contents of Database from a filename database. csv.", "response": "def load_contents(self):\n        \"\"\"\n            Loads contents of Database from a filename database.csv.\n        \"\"\"\n        with open(self.name + \".csv\") as f:\n            list_of_rows = f.readlines()\n\n        list_of_rows = map(\n            lambda x: x.strip(),\n            map(\n                lambda x: x.replace(\"\\\"\", \"\"),\n                list_of_rows\n            )\n        )\n\n        for row in list_of_rows:\n            self.put_row(make_row(self.columns, row.split(',')))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore the contents of the database into a filename database. csv.", "response": "def store_contents(self):\n        \"\"\"\n            Stores contests of the Database into a filename database.csv.\n        \"\"\"\n\n        string_buffer = os.linesep.join(\n            map(\n                lambda x: \",\".join(x),\n                map(\n                    lambda x: map(\n                        str,\n                        x.values()\n                    ),\n                    self.rows\n                )\n            )\n        )\n\n        with open(self.name + \".csv\", \"w\") as f:\n            f.write(string_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting Contents of Table.", "response": "def print_contents(self):\n        \"\"\"\n            Prints Contents of Table.\n        \"\"\"\n        print \"\\t\\t\\t\".join(self.columns)\n        temp_list = []\n        for i in self.columns:\n            temp_list.append(self.get_column(i))\n        for i in zip(*(temp_list)):\n            print \"\\t\\t\\t\".join(map(str, i))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef formfield_for_foreignkey(self, db_field, request=None, **kwargs):\n        field = super(CommentReplyAdmin, self).\\\n            formfield_for_foreignkey(db_field, request, **kwargs)\n        comment_id = request.GET.get(self.fk_name, None)\n\n        if db_field.name == 'canned_reply' and comment_id:\n            comment_id = comment_id.split(',')\n            comment_sites = Comment.objects.filter(id__in=comment_id)\\\n                                           .values('site')\\\n                                           .distinct()\n            field.queryset = field.queryset.filter(Q(site__in=comment_sites) |\n                                                   Q(site__isnull=True))\n        return field", "response": "Limit canned reply options to those with same site as comment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef queryset(self, request):\n        qs = super(CommentAdmin, self).queryset(request)\n        qs = qs.filter(\n            Q(user__is_staff=False) | Q(user__isnull=True),\n            is_removed=False\n        )\n        cls = getattr(self, 'cls', None)\n        if cls:\n            qs = qs.filter(classifiedcomment__cls=self.cls)\n        return qs.select_related('user', 'content_type')", "response": "Exclude replies from listing since they are displayed inline as part of the listing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef moderate_view(self, request, object_id, extra_context=None):\n        opts = self.model._meta\n        app_label = opts.app_label\n\n        view = CommentAdmin(model=Comment, admin_site=self.admin_site)\n\n        view.list_filter = ()\n        view.list_display = (\n            'comment_text',\n            'moderator_reply',\n            '_user',\n            'submit_date',\n        )\n\n        model = self.model\n        obj = get_object_or_404(model, pk=unquote(object_id))\n        request.obj = obj\n        view.change_list_template = self.change_list_template or [\n            'admin/%s/%s/moderate.html' % (app_label, opts.object_name.lower()),\n            'admin/%s/moderate.html' % app_label,\n            'admin/moderate.html'\n        ]\n        orig_has_change_permission = self.has_change_permission(request, obj)\n        if not orig_has_change_permission:\n            raise PermissionDenied\n        extra_context = {\n            'opts': opts,\n            'original': obj,\n            'orig_has_change_permission': orig_has_change_permission,\n        }\n        return view.changelist_view(request, extra_context)", "response": "Handles moderate object tool through a somewhat hacky changelist view."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_bootstrap_alert(visitor, block):\n    if 'new' in block:\n        txt = []\n        cls = block['kwargs'].get('class', '')\n        if cls:\n            cls = 'alert-%s' % cls\n        txt.append('<div class=\"alert %s\">' % cls)\n        if 'close' in block['kwargs']:\n            txt.append('<button class=\"close\" data-dismiss=\"alert\">&times;</button>')\n        text = visitor.parse_text(block['body'], 'article')\n        txt.append(text)\n        txt.append('</div>')\n        return '\\n'.join(txt)\n    else:\n        return bootstrap_alert(visitor, block)", "response": "Return a new alert in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the test batch", "response": "def execute(self):\n        \"\"\"Execute the test batch\n        \"\"\"\n\n        self.browser_config = BrowserConfig(\n            runner=self,\n            browser_id=BROME_CONFIG['runner_args']['localhost_runner'],\n            browsers_config=BROME_CONFIG['browsers_config']\n        )\n\n        try:\n            self.run()\n        except KeyboardInterrupt:\n            self.info_log(\"Test batch interrupted\")\n\n        except:\n            tb = traceback.format_exc()\n            self.error_log(\"Exception in run of the grid runner: %s\" % str(tb))\n            raise\n        finally:\n            self.terminate()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the test batch and returns the list of all the test objects that were executed.", "response": "def run(self):\n        \"\"\"Run the test batch\n        \"\"\"\n\n        self.info_log(\"The test batch is ready.\")\n\n        self.executed_tests = []\n\n        for test in self.tests:\n            localhost_instance = LocalhostInstance(\n                runner=self,\n                browser_config=self.browser_config,\n                test_name=test.Test.name\n            )\n\n            localhost_instance.startup()\n\n            with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                test_batch = session.query(Testbatch)\\\n                    .filter(Testbatch.mongo_id == self.test_batch_id).one()\n                test_batch.total_executing_tests = 1\n                session.save(test_batch, safe=True)\n\n            test_ = test.Test(\n                runner=self,\n                browser_config=self.browser_config,\n                name=test.Test.name,\n                test_batch_id=self.test_batch_id,\n                localhost_instance=localhost_instance,\n                index=1\n            )\n\n            test_.execute()\n            self.executed_tests.append(test_)\n\n            localhost_instance.tear_down()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nterminating the test batch", "response": "def terminate(self):\n        \"\"\"Terminate the test batch\n        \"\"\"\n\n        self.info_log('The test batch is finished.')\n\n        with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n            test_batch = session.query(Testbatch)\\\n                .filter(Testbatch.mongo_id == self.test_batch_id).one()\n            test_batch.ending_timestamp = utcnow()\n            test_batch.terminated = True\n            session.save(test_batch, safe=True)\n\n        self.print_test_summary(self.executed_tests)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef idaunpack(buf):\r\n    buf = bytearray(buf)\r\n\r\n    def nextval(o):\r\n        val = buf[o] ; o += 1\r\n        if val == 0xff:  # 32 bit value\r\n            val, = struct.unpack_from(\">L\", buf, o)\r\n            o += 4\r\n            return val, o\r\n        if val < 0x80:  # 7 bit value\r\n            return val, o\r\n        val <<= 8\r\n        val |= buf[o] ; o += 1\r\n        if val < 0xc000:  # 14 bit value\r\n            return val & 0x3fff, o\r\n\r\n        # 29 bit value\r\n        val <<= 8\r\n        val |= buf[o] ; o += 1\r\n        val <<= 8\r\n        val |= buf[o] ; o += 1\r\n        return val & 0x1fffffff, o\r\n\r\n    values = []\r\n    o = 0\r\n    while o < len(buf):\r\n        val, o = nextval(o)\r\n        values.append(val)\r\n    return values", "response": "Returns a list of tuple with the first two elements in the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndo a binary search in an array of objects ordered by. key and returns the index of the first element in the array that is less than or equal to k.", "response": "def binary_search(a, k):\r\n    \"\"\"\r\n    Do a binary search in an array of objects ordered by '.key'\r\n\r\n    returns the largest index for which:  a[i].key <= k\r\n\r\n    like c++: a.upperbound(k)--\r\n    \"\"\"\r\n    first, last = 0, len(a)\r\n    while first < last:\r\n        mid = (first + last) >> 1\r\n        if k < a[mid].key:\r\n            last = mid\r\n        else:\r\n            first = mid + 1\r\n    return first - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getsectioninfo(self, i):\r\n        if not 0 <= i < len(self.offsets):\r\n            return 0, 0, 0, 0\r\n\r\n        if self.offsets[i] == 0:\r\n            return 0, 0, 0, 0\r\n\r\n        self.fh.seek(self.offsets[i])\r\n        if self.fileversion < 5:\r\n            comp, size = struct.unpack(\"<BL\", self.fh.read(5))\r\n            ofs = self.offsets[i] + 5\r\n        else:\r\n            comp, size = struct.unpack(\"<BQ\", self.fh.read(9))\r\n            ofs = self.offsets[i] + 9\r\n        return comp, ofs, size, self.checksums[i]", "response": "Returns a tuple with the parameters of the specified section i in the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getpart(self, ix):\r\n        if self.offsets[ix] == 0:\r\n            return\r\n\r\n        comp, ofs, size, checksum = self.getsectioninfo(ix)\r\n\r\n        fh = FileSection(self.fh, ofs, ofs + size)\r\n        if comp == 2:\r\n            import zlib\r\n            # very old databases used a different compression scheme:\r\n            wbits = -15 if self.magic == 'IDA0' else 15\r\n\r\n            fh = makeStringIO(zlib.decompress(fh.read(size), wbits))\r\n        elif comp == 0:\r\n            pass\r\n        else:\r\n            raise Exception(\"unsupported section encoding: %02x\" % comp)\r\n        return fh", "response": "Returns a fileobject for the specified section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find(self, rel, key):\r\n\r\n        # descend tree to leaf nearest to the `key`\r\n        page = self.readpage(self.firstindex)\r\n        stack = []\r\n        while len(stack) < 256:\r\n            act, ix = page.find(key)\r\n            stack.append((page, ix))\r\n            if act != 'recurse':\r\n                break\r\n            page = self.readpage(page.getpage(ix))\r\n\r\n        if len(stack) == 256:\r\n            raise Exception(\"b-tree corrupted\")\r\n        cursor = BTree.Cursor(self, stack)\r\n\r\n        # now correct for what was actually asked.\r\n        if act == rel:\r\n            pass\r\n        elif rel == 'eq' and act != 'eq':\r\n            return None\r\n        elif rel in ('ge', 'le') and act == 'eq':\r\n            pass\r\n        elif rel in ('gt', 'ge') and act == 'lt':\r\n            cursor.next()\r\n        elif rel == 'gt' and act == 'eq':\r\n            cursor.next()\r\n        elif rel in ('lt', 'le') and act == 'gt':\r\n            cursor.prev()\r\n        elif rel == 'lt' and act == 'eq':\r\n            cursor.prev()\r\n\r\n        return cursor", "response": "Returns a cursor object for the record with the specified relation to the key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dumpfree(self):\r\n        fmt = \"L\" if self.version > 15 else \"H\"\r\n        hdrsize = 8 if self.version > 15 else 4\r\n        pn = self.firstfree\r\n        if pn == 0:\r\n            print(\"no free pages\")\r\n            return\r\n        while pn:\r\n            self.fh.seek(pn * self.pagesize)\r\n            data = self.fh.read(self.pagesize)\r\n            if len(data) == 0:\r\n                print(\"could not read FREE data at page %06x\" % pn)\r\n                break\r\n            count, nextfree = struct.unpack_from(\"<\" + (fmt * 2), data)\r\n            freepages = list(struct.unpack_from(\"<\" + (fmt * count), data, hdrsize))\r\n            freepages.insert(0, pn)\r\n            for pn in freepages:\r\n                self.fh.seek(pn * self.pagesize)\r\n                data = self.fh.read(self.pagesize)\r\n                print(\"%06x: free: %s\" % (pn, hexdump(data[:64])))\r\n            pn = nextfree", "response": "dump all free pages"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps all nodes of the current page with keys indented showing how the indent feature works", "response": "def dumpindented(self, pn, indent=0):\r\n        \"\"\"\r\n        Dump all nodes of the current page with keys indented, showing how the `indent`\r\n        feature works\r\n        \"\"\"\r\n        page = self.readpage(pn)\r\n        print(\"  \" * indent, page)\r\n        if page.isindex():\r\n            print(\"  \" * indent, end=\"\")\r\n            self.dumpindented(page.preceeding, indent + 1)\r\n            for p in range(len(page.index)):\r\n                print(\"  \" * indent, end=\"\")\r\n                self.dumpindented(page.getpage(p), indent + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dumptree(self, pn):\r\n        page = self.readpage(pn)\r\n        print(\"%06x: preceeding = %06x, reccount = %04x\" % (pn, page.preceeding, page.count))\r\n        for ent in page.index:\r\n            print(\"    %s\" % ent)\r\n        if page.preceeding:\r\n            self.dumptree(page.preceeding)\r\n            for ent in page.index:\r\n                self.dumptree(ent.page)", "response": "Walks entire tree dumping all records on each page in sequential order\r\n            is a list of all the related objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping contents of all pages in the B - tree.", "response": "def pagedump(self):\r\n        \"\"\"\r\n        dump the contents of all pages, ignoring links between pages,\r\n        this will enable you to view contents of pages which have become\r\n        lost due to datacorruption.\r\n        \"\"\"\r\n        self.fh.seek(self.pagesize)\r\n        pn = 1\r\n        while True:\r\n            try:\r\n                pagedata = self.fh.read(self.pagesize)\r\n                if len(pagedata) == 0:\r\n                    break\r\n                elif len(pagedata) != self.pagesize:\r\n                    print(\"%06x: incomplete - %d bytes ( pagesize = %d )\" % (pn, len(pagedata), self.pagesize))\r\n                    break\r\n                elif pagedata == b'\\x00' * self.pagesize:\r\n                    print(\"%06x: empty\" % (pn))\r\n                else:\r\n                    page = self.page(pagedata)\r\n\r\n                    print(\"%06x: preceeding = %06x, reccount = %04x\" % (pn, page.preceeding, page.count))\r\n                    for ent in page.index:\r\n                        print(\"    %s\" % ent)\r\n            except Exception as e:\r\n                print(\"%06x: ERROR decoding as B-tree page: %s\" % (pn, e))\r\n            pn += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prettykey(self, key):\r\n        f = list(self.decodekey(key))\r\n        f[0] = f[0].decode('utf-8')\r\n        if len(f) > 2 and type(f[2]) == bytes:\r\n            f[2] = f[2].decode('utf-8')\r\n\r\n        if f[0] == '.':\r\n            if len(f) == 2:\r\n                return \"%s%16x\" % tuple(f)\r\n            elif len(f) == 3:\r\n                return \"%s%16x %s\" % tuple(f)\r\n            elif len(f) == 4:\r\n                if f[2] == 'H' and type(f[3]) in (str, bytes):\r\n                    f[3] = f[3].decode('utf-8')\r\n                    return \"%s%16x %s '%s'\" % tuple(f)\r\n                elif type(f[3]) in (int, long):\r\n                    return \"%s%16x %s %x\" % tuple(f)\r\n                else:\r\n                    f[3] = hexdump(f[3])\r\n                    return \"%s%16x %s %s\" % tuple(f)\r\n        elif f[0] in ('N', 'n', '$'):\r\n            if type(f[1]) in (int, long):\r\n                return \"%s %x %16x\" % tuple(f)\r\n            else:\r\n                return \"%s'%s'\" % tuple(f)\r\n        elif f[0] == '-':\r\n            return \"%s %x\" % tuple(f)\r\n\r\n        return hexdump(key)", "response": "Returns the key in a readable format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prettyval(self, val):\r\n        if len(val) == self.wordsize and val[-1:] in (b'\\x00', b'\\xff'):\r\n            return \"%x\" % struct.unpack(\"<\" + self.fmt, val)\r\n        if len(val) == self.wordsize and re.search(b'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]', val, re.DOTALL):\r\n            return \"%x\" % struct.unpack(\"<\" + self.fmt, val)\r\n        if len(val) < 2 or not re.match(b'^[\\x09\\x0a\\x0d\\x20-\\xff]+.$', val, re.DOTALL):\r\n            return hexdump(val)\r\n        val = val.replace(b\"\\n\", b\"\\\\n\")\r\n        return \"'%s'\" % val.decode('utf-8', 'ignore')", "response": "Returns the value in a readable format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nodeByName(self, name):\r\n        # note: really long names are encoded differently:\r\n        #  'N'+'\\x00'+pack('Q', nameid)  => ofs\r\n        #  and  (ofs, 'N') -> nameid\r\n\r\n        # at nodebase ( 0xFF000000, 'S', 0x100*nameid )  there is a series of blobs for max 0x80000 sized names.\r\n        cur = self.btree.find('eq', self.namekey(name))\r\n        if cur:\r\n            return struct.unpack('<' + self.fmt, cur.getval())[0]", "response": "Return a nodeid by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a binary key for the nodeid tag and optional value", "response": "def makekey(self, *args):\r\n        \"\"\" return a binary key for the nodeid, tag and optional value \"\"\"\r\n        if len(args) > 1:\r\n            args = args[:1] + (args[1].encode('utf-8'),) + args[2:]\r\n        if len(args) == 3 and type(args[-1]) == str:\r\n            # node.tag.string type keys\r\n            return struct.pack(self.keyfmt[:1 + len(args)], b'.', *args[:-1]) + args[-1].encode('utf-8')\r\n        elif len(args) == 3 and type(args[-1]) == type(-1) and args[-1] < 0:\r\n            # negative values -> need lowercase fmt char\r\n            return struct.pack(self.keyfmt[:1 + len(args)] + self.fmt.lower(), b'.', *args)\r\n        else:\r\n            # node.tag.value type keys\r\n            return struct.pack(self.keyfmt[:2 + len(args)], b'.', *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes a tuple of key into a tuple of fields.", "response": "def decodekey(self, key):\r\n        \"\"\"\r\n        splits a key in a tuple, one of:\r\n           ( [ 'N', 'n', '$' ],  0,   bignameid )\r\n           ( [ 'N', 'n', '$' ],  name  )\r\n           ( '-',  id )\r\n           ( '.',  id )\r\n           ( '.',  id,  tag )\r\n           ( '.',  id,  tag, value )\r\n           ( '.',  id,  'H', name  )\r\n        \"\"\"\r\n        if key[:1] in (b'n', b'N', b'$'):\r\n            if key[1:2] == b\"\\x00\" and len(key) == 2 + self.wordsize:\r\n                return struct.unpack(\">sB\" + self.fmt, key)\r\n            else:\r\n                return key[:1], key[1:].decode('utf-8', 'ignore')\r\n        if key[:1] == b'-':\r\n            return struct.unpack(\">s\" + self.fmt, key)\r\n        if len(key) == 1 + self.wordsize:\r\n            return struct.unpack(self.keyfmt[:3], key)\r\n        if len(key) == 1 + self.wordsize + 1:\r\n            return struct.unpack(self.keyfmt[:4], key)\r\n        if len(key) == 1 + 2 * self.wordsize + 1:\r\n            return struct.unpack(self.keyfmt[:5], key)\r\n        if len(key) > 1 + self.wordsize + 1:\r\n            f = struct.unpack_from(self.keyfmt[:4], key)\r\n            return f + (key[2 + self.wordsize:], )\r\n        raise Exception(\"unknown key format\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bytes(self, *args):\r\n        if len(args) == 1 and isinstance(args[0], BTree.Cursor):\r\n            cur = args[0]\r\n        else:\r\n            cur = self.btree.find('eq', self.makekey(*args))\r\n\r\n        if cur:\r\n            return cur.getval()", "response": "return a raw value for the given arguments"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the integer stored in the specified node.", "response": "def int(self, *args):\r\n        \"\"\"\r\n        Return the integer stored in the specified node.\r\n\r\n        Any type of integer will be decoded: byte, short, long, long long\r\n\r\n        \"\"\"\r\n        data = self.bytes(*args)\r\n        if data is not None:\r\n            if len(data) == 1:\r\n                return struct.unpack(\"<B\", data)[0]\r\n            if len(data) == 2:\r\n                return struct.unpack(\"<H\", data)[0]\r\n            if len(data) == 4:\r\n                return struct.unpack(\"<L\", data)[0]\r\n            if len(data) == 8:\r\n                return struct.unpack(\"<Q\", data)[0]\r\n            print(\"can't get int from %s\" % hexdump(data))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef string(self, *args):\r\n        data = self.bytes(*args)\r\n        if data is not None:\r\n            return data.rstrip(b\"\\x00\").decode('utf-8')", "response": "Returns the string stored in node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves a name from a short and long name.", "response": "def name(self, id):\r\n        \"\"\"\r\n        resolves a name, both short and long names.\r\n        \"\"\"\r\n        data = self.bytes(id, 'N')\r\n        if not data:\r\n            print(\"%x has no name\" % id)\r\n            return\r\n        if data[:1] == b'\\x00':\r\n            nameid, = struct.unpack_from(\">\" + self.fmt, data, 1)\r\n            nameblob = self.blob(self.nodebase, 'S', nameid * 256, nameid * 256 + 32)\r\n            return nameblob.rstrip(b\"\\x00\").decode('utf-8')\r\n        return data.rstrip(b\"\\x00\").decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the blob with the given tag in the given node.", "response": "def blob(self, nodeid, tag, start=0, end=0xFFFFFFFF):\r\n        \"\"\"\r\n        Blobs are stored in sequential nodes\r\n        with increasing index values.\r\n\r\n        most blobs, like scripts start at index\r\n        0, long names start at a specified\r\n        offset.\r\n\r\n        \"\"\"\r\n        startkey = self.makekey(nodeid, tag, start)\r\n        endkey = self.makekey(nodeid, tag, end)\r\n        cur = self.btree.find('ge', startkey)\r\n        data = b''\r\n        while cur.getkey() <= endkey:\r\n            data += cur.getval()\r\n            cur.next()\r\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(self):\r\n        for seg in self.seglist:\r\n            print(\"==== %08x-%08x\" % (seg.startea, seg.endea))\r\n            if seg.endea - seg.startea < 30:\r\n                for ea in range(seg.startea, seg.endea):\r\n                    print(\"    %08x: %08x\" % (ea, self.getFlags(ea)))\r\n            else:\r\n                for ea in range(seg.startea, seg.startea + 10):\r\n                    print(\"    %08x: %08x\" % (ea, self.getFlags(ea)))\r\n                print(\"...\")\r\n                for ea in range(seg.endea - 10, seg.endea):\r\n                    print(\"    %08x: %08x\" % (ea, self.getFlags(ea)))", "response": "print first and last bits for each segment"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_segment(self, ea):\r\n        for seg in self.seglist:\r\n            if seg.startea <= ea < seg.endea:\r\n                return seg", "response": "find the segment with the given address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a numbered vowel to an accented vowel.", "response": "def _num_vowel_to_acc(vowel, tone):\n    \"\"\"Convert a numbered vowel to an accented vowel.\"\"\"\n    try:\n        return VOWEL_MAP[vowel + str(tone)]\n    except IndexError:\n        raise ValueError(\"Vowel must be one of '{}' and tone must be a tone.\".format(VOWELS))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a numbered pinyin syllable to an accented pinyin syllable.", "response": "def numbered_syllable_to_accented(syllable):\n    \"\"\"Convert a numbered pinyin syllable to an accented pinyin syllable.\n\n    Implements the following algorithm, modified from https://github.com/tsroten/zhon:\n        1. If the syllable has an 'a' or 'e', put the tone over that vowel.\n        2. If the syllable has 'ou', place the tone over the 'o'.\n        3. Otherwise, put the tone on the last vowel.\n\n    \"\"\"\n    def keep_case_replace(s, vowel, replacement):\n        accented = s.replace(vowel, replacement)\n        if syllable[0].isupper():\n            return accented[0].upper() + accented[1:]\n        return accented\n\n    tone = syllable[-1]\n    if tone == '5':\n        return re.sub('u:|v', '\\u00fc', syllable[:-1])\n    # Homogenise representation of u:\n    syl = re.sub('u:|v', '\\u00fc', syllable[:-1].lower())\n    if 'a' in syl:\n        return keep_case_replace(syl, 'a', _num_vowel_to_acc('a', tone))\n    elif 'e' in syl:\n        return keep_case_replace(syl, 'e', _num_vowel_to_acc('e', tone))\n    elif 'ou' in syl:\n        return keep_case_replace(syl, 'o', _num_vowel_to_acc('o', tone))\n    last_vowel = syl[max(map(syl.rfind, VOWELS))]  # Find last vowel index.\n    return keep_case_replace(syl, last_vowel, _num_vowel_to_acc(last_vowel, tone))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting given data to unicode string using package default settings", "response": "def to_unicode(data, encoding=Constants.default_codec, errors=Constants.codec_error):\n    \"\"\"\n    Converts given data to unicode string using package default settings, fighting **The Hell**!\n\n    Usage::\n\n        >>> to_unicode(\"myData\")\n        u'myData'\n        >>> to_unicode(\"\u6c49\u5b57/\u6f22\u5b57\")\n        u'\\u6c49\\u5b57/\\u6f22\\u5b57'\n\n    :param data: Data to convert.\n    :type data: object\n    :param encoding: File encoding codec.\n    :type encoding: unicode\n    :param errors: File encoding errors handling.\n    :type errors: unicode\n    :return: Unicode data.\n    :rtype: unicode\n    \"\"\"\n\n    if isinstance(data, type(\"\")):\n        return data\n    else:\n        try:\n            return unicode(data, encoding, errors)\n        except TypeError:\n            return unicode(str(data), encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride logging. LogRecord. msg attribute to ensure variable content is stored as unicode.", "response": "def _LogRecord_msg():\n    \"\"\"\n    Overrides logging.LogRecord.msg attribute to ensure variable content is stored as unicode.\n    \"\"\"\n\n    def _LogRecord_msgProperty(self):\n        return self.__msg\n\n    def _LogRecord_msgSetter(self, value):\n        self.__msg = to_unicode(value)\n\n    logging.LogRecord.msg = property(_LogRecord_msgProperty, _LogRecord_msgSetter)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tracer(object):\n\n    @functools.wraps(object)\n    @functools.partial(foundations.trace.validate_tracer, object)\n    def tracer_wrapper(*args, **kwargs):\n        \"\"\"\n        Traces execution.\n\n        :param \\*args: Arguments.\n        :type \\*args: \\*\n        :param \\*\\*kwargs: Keywords arguments.\n        :type \\*\\*kwargs: \\*\\*\n        :return: Object.\n        :rtype: object\n        \"\"\"\n\n        global INDENT_LEVEL\n\n        trace_name = foundations.trace.get_trace_name(object)\n\n        code = object.func_code\n        args_count = code.co_argcount\n        args_names = code.co_varnames[:args_count]\n        function_defaults = object.func_defaults or list()\n        args_defaults = dict(zip(args_names[-len(function_defaults):], function_defaults))\n\n        positional_args = map(foundations.trace.format_argument, zip(args_names, args))\n        defaulted_args = [foundations.trace.format_argument((name, args_defaults[name]))\n                          for name in args_names[len(args):] if name not in kwargs]\n        nameless_args = map(repr, args[args_count:])\n        keyword_args = map(foundations.trace.format_argument, kwargs.items())\n        TRACER_LOGGING_FUNCTION(indent_message(\"---> {0}({1}) <---\".format(trace_name,\n                                                                           \", \".join(itertools.chain(positional_args,\n                                                                                                     defaulted_args,\n                                                                                                     nameless_args,\n                                                                                                     keyword_args)))))\n\n        INDENT_LEVEL += 1\n        value = object(*args, **kwargs)\n        INDENT_LEVEL -= 1\n\n        TRACER_LOGGING_FUNCTION(indent_message(\"<--- {0} ^ {1} --->\".format(trace_name, repr(value))))\n\n        return value\n\n    return tracer_wrapper", "response": "| Traces execution.\n    | Any method / definition decorated will have it's execution traced through debug messages.\n    | Both object entry and exit are logged.\n\n    Entering in an object::\n\n        INFO    : ---> foundations.environment.get_user_application_data_directory() <<<---\n\n    Exiting from an object::\n\n        INFO   : <--- foundations.environment.get_system_application_data_directory() ^ '...' --->\n\n    :param object: Object to decorate.\n    :type object: object\n    :return: Object.\n    :rtype: object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_logger(logger=None, module=None):\n\n    logger = logging.getLogger(Constants.logger) if logger is None else logger\n    if module is None:\n        # Note: inspect.getmodule() can return the wrong module if it has been imported with different relatives paths.\n        module = sys.modules.get(inspect.currentframe().f_back.f_globals[\"__name__\"])\n    setattr(module, \"LOGGER\", logger)\n\n    foundations.trace.register_module(module)\n\n    return logger", "response": "Installs given logger in given module or default logger in caller introspected module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_logging_console_handler(logger=None, formatter=LOGGING_DEFAULT_FORMATTER):\n\n    logger = LOGGER if logger is None else logger\n    logging_console_handler = logging.StreamHandler(sys.__stdout__)\n    logging_console_handler.setFormatter(formatter)\n    logger.addHandler(logging_console_handler)\n    return logging_console_handler", "response": "Returns a logging console handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_logging_file_handler(logger=None, file=None, formatter=LOGGING_DEFAULT_FORMATTER):\n\n    logger = LOGGER if logger is None else logger\n    file = tempfile.NamedTemporaryFile().name if file is None else file\n    logging_file_handler = logging.FileHandler(file)\n    logging_file_handler.setFormatter(formatter)\n    logger.addHandler(logging_file_handler)\n    return logging_file_handler", "response": "Returns a logging file handler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a logging stream handler.", "response": "def get_logging_stream_handler(logger=None, formatter=LOGGING_DEFAULT_FORMATTER):\n    \"\"\"\n    Adds a logging stream handler to given logger or default logger using given file.\n\n    :param logger: Logger to add the handler to.\n    :type logger: Logger\n    :param file: File to verbose into.\n    :type file: unicode\n    :param formatter: Handler formatter.\n    :type formatter: Formatter\n    :return: Added handler.\n    :rtype: Handler\n    \"\"\"\n\n    logger = LOGGER if logger is None else logger\n    logging_stream_handler = logging.StreamHandler(Streamer())\n    logging_stream_handler.setFormatter(formatter)\n    logger.addHandler(logging_stream_handler)\n    return logging_stream_handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_logging_handler(handler, logger=None):\n\n    logger = LOGGER if logger is None else logger\n    logger.handlers and LOGGER.debug(\"> Stopping handler: '{0}'.\".format(handler))\n    logger.removeHandler(handler)\n    return True", "response": "Removes given logging handler from given logger."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the verbosity level of the current log.", "response": "def set_verbosity_level(verbosity_level=3, logger=None):\n    \"\"\"\n    Defines logging verbosity level.\n\n    Available verbosity levels::\n\n        0: Critical.\n        1: Error.\n        2: Warning.\n        3: Info.\n        4: Debug.\n\n    :param verbosity_level: Verbosity level.\n    :type verbosity_level: int\n    :param logger: Logger to set the verbosity level to.\n    :type logger: Logger\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    logger = LOGGER if logger is None else logger\n    if verbosity_level == 0:\n        logger.setLevel(logging.CRITICAL)\n        logging.disable(logging.ERROR)\n    elif verbosity_level == 1:\n        logger.setLevel(logging.ERROR)\n        logging.disable(logging.WARNING)\n    elif verbosity_level == 2:\n        logger.setLevel(logging.WARNING)\n        logging.disable(logging.INFO)\n    elif verbosity_level == 3:\n        logger.setLevel(logging.INFO)\n        logging.disable(logging.DEBUG)\n    elif verbosity_level == 4:\n        logger.setLevel(logging.DEBUG)\n        logging.disable(logging.NOTSET)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, message):\n\n        for handler in self.__logger.__dict__[\"handlers\"]:\n            handler.stream.write(message)\n        return True", "response": "Writes given message to all handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _do_write(self):\n        with self.lock:\n            self._commit_counter += 1\n            if self._commit_counter >= self._commit_every:\n                self._db.commit()\n                self._commit_counter = 0", "response": "Check commit counter and do a commit if need be"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_type(env_type, alias=None):\n    if isinstance(env_type, string_types):\n        env_type = TYPES[env_type]\n\n    if alias is None:\n        alias = env_type.name\n\n    TYPES[alias] = env_type\n\n    for alias in env_type.aliases:\n        TYPES[alias] = env_type\n\n    return env_type", "response": "Registers environment type.\n\n    :param str|unicode|Environment env_type: Environment type or its alias\n        (for already registered types).\n\n    :param str|unicode alias: Alias to register type under. If not set type name is used.\n\n    :rtype: Environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_once_per_node(func):\n    @wraps(func)\n    def decorated(*args, **kwargs):\n        if not hasattr(env,'patch'): env.patch = False\n        state = version_state(func.__name__)\n        if not env.patch and state:\n            verbose = \" \".join([env.host,func.__name__,\"completed. Skipping...\"])\n        elif env.patch and not state:\n            verbose = \" \".join([env.host,func.__name__,\"not previously completed. Skipping...\"])\n        else:\n            results = func(*args, **kwargs)\n            verbose =''\n            if results: set_version_state(func.__name__,object=results)\n            else: set_version_state(func.__name__)\n            return results\n        if env.verbosity and verbose: print verbose\n        return             \n          \n    return decorated", "response": "Decorator that runs a function once per node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _close(self, fd):\n        if self._mode == WF_INOTIFYX:\n            try: pynotifyx.rm_watch(self._inx_fd, fd)\n            except: pass\n        else:\n            try: os.close(fd)\n            except: pass", "response": "Close the descriptor used for a path regardless of mode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _disappeared(self, fd, path, **params):\n        log = self._getparam('log', self._discard, **params)\n\n        log.debug(\"Path %r removed or renamed, handling removal\", path)\n        self._close(fd)\n        if self._mode == WF_POLLING and fd in self._poll_stat:\n            del self._poll_stat[fd]\n        if self._mode == WF_INOTIFYX and path in self._inx_inode:\n            del self._inx_inode[path]\n        del self.fds_open[fd]\n        del self.paths_open[path]\n        if self.paths[path]:\n            try:\n                if self._add_file(path, **params):\n                    log.debug(\"Path %r immediately reappeared, pending transition skipped\", path)\n                    return\n            except Exception as e:\n                log.debug(\"Path %r reappearance check failed -- %s\", path, e)\n            log.debug(\"Path %r marked as pending\", path)\n            self.paths_pending[path] = True\n        else:\n            del self.paths[path]\n            raise Exception(\"Path %r has been removed or renamed\" % path)", "response": "Called when a file is no longer acessible."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks the status of a file.", "response": "def _poll_get_stat(self, fd, path):\n        \"\"\"\n        Check the status of an open path.  Note that we have to use stat() rather\n        than fstat() because we want to detect file removes and renames.\n    \"\"\"\n        try:\n            st = os.stat(path)\n            fstate = (st.st_mode, st.st_nlink, st.st_uid, st.st_gid, st.st_size, st.st_mtime)\n        except Exception as e:\n            log = self._getparam('log', self._discard)\n            log.debug(\"stat failed on %s -- %s\", path, e)\n            self._poll_pending[path] = time.time()\n            self._disappeared(fd, path)\n            fstate = None\n        return fstate"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a NUL to the self - pipe and return None.", "response": "def _poll_trigger(self):\n        \"\"\"\n        Trigger activity for the caller by writting a NUL to the self-pipe.\n    \"\"\"\n        try:\n            os.write(self._poll_send, '\\0'.encode('utf-8'))\n        except Exception as e:\n            log = self._getparam('log', self._discard)\n            log.debug(\"Ignoring self-pipe write error -- %s\", e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntriggering the event for the given file descriptor.", "response": "def _trigger(self, fd, **params):\n        \"\"\"\n        We need events to fire on appearance because the code\n        doesn't see the file until after it has been created.\n\n        In WF_KQUEUE mode, this simulates triggering an event by firing\n        a oneshot timer event to fire immediately (0 msecs).  Because\n        this uses the file descriptor as the timer identity and get() doesn't\n        care what filter actually fired the event, the outside world sees\n        this as a file change.\n\n        In WF_INOTIFYX mode, this triggers an event by setting IN_OPEN on\n        the inotify watch, opening the file in read-only mode, closing it,\n        and removing the IN_OPEN setting.  The file is not discovered unless\n        it can be opened so this is reliable.\n\n        In WF_POLLING mode, this resets our knowledge of the stat\n        info, and then triggers file activity to wake up the caller.\n    \"\"\"\n        log = self._getparam('log', self._discard, **params)\n        if self._mode == WF_KQUEUE:\n            try:\n                ev = select.kevent(fd, filter=select.KQ_FILTER_TIMER,\n                            flags=select.KQ_EV_ADD | select.KQ_EV_CLEAR | select.KQ_EV_ONESHOT, data=0)\n                self._kq.control([ev], 0, 0)\n                log.debug(\"Added timer event following pending file promotion\")\n            except Exception as e:\n                log.error(\"Failed to add timer event following pending file promotion -- %s\", e)\n        elif self._mode == WF_INOTIFYX:\n            if fd in self.fds_open:\n                try:\n                    path = self.fds_open[fd]\n                    nfd = pynotifyx.add_watch(self._inx_fd, path, self._inx_mask|pynotifyx.IN_OPEN)\n                    if nfd != fd:\n                        raise Exception(\"Assertion failed: IN_OPEN add_watch() set gave new wd\")\n                    tfd = os.open(path, os.O_RDONLY)\n                    try: os.close(tfd)\n                    except: pass\n                    nfd = pynotifyx.add_watch(self._inx_fd, path, self._inx_mask)\n                    if nfd != fd:\n                        raise Exception(\"Assertion failed: IN_OPEN add_watch() clear gave new wd\")\n                except Exception as e:\n                    log.error(\"Failed to trigger event via os.open() following pending file promotion -- %s\", e)\n            else:\n                log.error(\"Pending file promotion of unknown wd %d failed\", fd)\n        elif self._mode == WF_POLLING:\n            self._poll_stat[fd] = ()\n            self._poll_trigger()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a file to the system monitoring mechanism.", "response": "def _add_file(self, path, **params):\n        \"\"\"\n        Attempt to add a file to the system monitoring mechanism.\n    \"\"\"\n        log = self._getparam('log', self._discard, **params)\n        fd = None\n        try:\n            fd = os.open(path, os.O_RDONLY)\n        except Exception as e:\n            if not self.paths[path]:\n                log.error(\"Open failed on watched path %r -- %s\", path, e, exc_info=log.isEnabledFor(logging.DEBUG))\n                raise e\n            elif path in self.paths_pending:\n                log.debug(\"path %r is still pending -- %s\", path, e)\n            else:\n                self.paths_pending[path] = True\n                log.debug(\"Added %r to pending list after open failure -- %s\", path, e)\n            return False\n        if self._mode == WF_KQUEUE:\n            log.debug(\"path %s opened as fd %d\", path, fd)\n            try:\n                ev = select.kevent(fd,\n                    filter=select.KQ_FILTER_VNODE,\n                    flags=select.KQ_EV_ADD | select.KQ_EV_CLEAR,\n                    fflags=select.KQ_NOTE_WRITE | select.KQ_NOTE_ATTRIB | select.KQ_NOTE_LINK |\n                                select.KQ_NOTE_DELETE | select.KQ_NOTE_RENAME)\n                self._kq.control([ev], 0, 0)\n            except Exception as e:\n                log.error(\"kevent failed on watched path %r -- %s\", path, e)\n                try: os.close(fd)\n                except: pass\n                raise e\n\n        elif self._mode == WF_INOTIFYX:\n            #  inotify doesn't need the target paths open, so now it is known to be\n            #  accessible, close the actual fd and use the watch-descriptor as the fd.\n            #\n            #  However, due to an apparent simfs bug where inotify does not fire either\n            #  IN_DELETE_SELF or IN_MOVE_SELF, we need to record the inode so that we\n            #  can detect deletes and renames internally.  simfs is used in containers.\n            #\n            try:\n                s = os.fstat(fd)\n                self._inx_inode[path] = s.st_ino\n            except Exception as e:\n                log.error(\"fstat(%d) failed on open path %r -- %s\", fd, path, e)\n                try: os.close(fd)\n                except: pass\n                raise e\n            try: os.close(fd)\n            except: pass\n            try:\n                fd = pynotifyx.add_watch(self._inx_fd, path, self._inx_mask)\n                log.debug(\"path %s watched with wd %d\", path, fd)\n            except Exception as e:\n                log.error(\"inotify failed on watched path %r -- %s\", path, e)\n                raise e\n\n        elif self._mode == WF_POLLING:\n            log.debug(\"path %s opened as fd %d\", path, fd)\n            fstate = self._poll_get_stat(fd, path)\n            if fstate:\n                self._poll_stat[fd] = fstate\n\n        self.paths_open[path] = fd\n        self.fds_open[fd] = path\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commit(self, **params):\n        log = self._getparam('log', self._discard, **params)\n\n        #  Find all the modules that no longer need watching\n        #\n        removed = 0\n        added = 0\n        for path in list(self.paths_open):\n            if path not in self.paths:\n                fd = self.paths_open[path]\n                if self._mode == WF_KQUEUE:\n                    #  kevent automatically deletes the event when the fd is closed\n                    try:\n                        os.close(fd)\n                    except Exception as e:\n                        log.warning(\"close failed on watched file %r -- %s\", path, e)\n                elif self._mode == WF_INOTIFYX:\n                    try:\n                        pynotifyx.rm_watch(self._inx_fd, fd)\n                    except Exception as e:\n                        log.warning(\"remove failed on watched file %r -- %s\", path, e)\n                    if path in self._inx_inode:\n                        del self._inx_inode[path]\n                elif self._mode == WF_POLLING:\n                    if fd in self._poll_stat:\n                        del self._poll_stat[fd]\n                    else:\n                        log.warning(\"fd watched path %r missing from _poll_stat map\", path)\n                    try:\n                        os.close(fd)\n                    except Exception as e:\n                        log.warning(\"close failed on watched file %r -- %s\", path, e)\n                if fd in self.fds_open:\n                    del self.fds_open[fd]\n                else:\n                    log.warning(\"fd watched path %r missing from fd map\", path)\n                del self.paths_open[path]\n                log.debug(\"Removed watch for path %r\", path)\n                removed += 1\n\n        #  Find all the paths that are new and should be watched\n        #\n        fdlist = []\n        failed = []\n        last_exc = None\n        log.debug(\"%d watched path%s\", len(self.paths), ses(len(self.paths)))\n        for path in list(self.paths):\n            if path not in self.paths_open:\n                try:\n                    if not self._add_file(path, **params):\n                        continue\n                except Exception as e:\n                    last_exc = e\n                    failed.append(path)\n                    continue\n                fdlist.append(self.paths_open[path])\n\n                if path in self.paths_pending:\n                    log.debug(\"pending path %r has now appeared\", path)\n                    del self.paths_pending[path]\n                    self._trigger(self.paths_open[path], **params)\n\n                added += 1\n                log.debug(\"Added watch for path %r with ident %d\", path, self.paths_open[path])\n        if failed:\n            self._clean_failed_fds(fdlist)\n            raise Exception(\"Failed to set watch on %s -- %s\" % (str(failed), str(last_exc)))\n        log.debug(\"%d added, %d removed\", added, removed)", "response": "Rebuild kevent operations by removing open files that no longer need to be watched and adding new files that are not currently being watched."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of watched paths that affected by a successful poll call.", "response": "def get(self, **params):\n        \"\"\"\n        Return a list of watched paths that where affected by recent\n        changes, following a successful poll() return for the controlling\n        file descriptor.\n\n        If param \"timeout\" is greater than 0, the event queue will be read\n        multiple times and reads continue until a timeout occurs.\n\n        With a timeout active, if param \"limit\" is greater than 0,\n        event reads will stop when the number of changes exceeds the\n        limit.  This guarantees that the time the method will block\n        will never be greater than timeout*limit seconds.\n\n        Note that with a timeout active, multiple changes to a\n        single path will only be reported once.\n    \"\"\"\n        log = self._getparam('log', self._discard, **params)\n\n        self.last_changes = {}\n\n        timeout = self._getparam('timeout', 0, **params)\n        if not timeout or timeout < 0:\n            timeout = 0\n        limit = self._getparam('limit', None, **params)\n        if not limit or limit < 0:\n            limit = None\n\n        max_events = limit if limit else 10000\n        if self.unprocessed_event:\n            log.debug(\"Will handle unprocessed event\")\n\n        if self._mode == WF_KQUEUE:\n            evagg = {}\n            while True:\n                try:\n                    evlist = self._kq.control(None, max_events, timeout)\n                except OSError as e:\n                    if e.errno == errno.EINTR:\n                        break\n                    raise e\n                if not evlist:\n                    break\n\n                log.debug(\"kq.control() returned %d event%s\", len(evlist), ses(len(evlist)))\n                for ev in evlist:\n                    if ev.ident in self.fds_open:\n                        path = self.fds_open[ev.ident]\n                        if path in evagg:\n                            evagg[path].fflags |= ev.fflags\n                        else:\n                            evagg[path] = ev\n                if limit and len(evagg) >= limit:\n                    break\n            for path, ev in evagg.items():\n                if ev.fflags & (select.KQ_NOTE_DELETE | select.KQ_NOTE_RENAME):\n                    self._disappeared(ev.ident, path, **params)\n                self.last_changes[path] = time.time()\n                log.debug(\"Change on %r\", path)\n\n        elif self._mode == WF_INOTIFYX:\n            evagg = {}\n            while True:\n                try:\n                    evlist = pynotifyx.get_events(self._inx_fd, timeout)\n                except IOError as e:\n                    if e.errno == errno.EINTR:\n                        break\n                    raise e\n                if not evlist:\n                    break\n\n                log.debug(\"pynotifyx.get_events() returned %d event%s\", len(evlist), ses(len(evlist)))\n\n                for ev in evlist:\n                    if ev.wd in self.fds_open:\n                        path = self.fds_open[ev.wd]\n                        if path in evagg:\n                            evagg[path].mask |= ev.mask\n                        else:\n                            evagg[path] = ev\n                    elif ev.mask & pynotifyx.IN_IGNORED:\n                        log.debug(\"skipping IN_IGNORED event on unknown wd %d\", ev.wd)\n                    else:\n                        log.warning(\"attempt to handle unknown inotify event wd %d\", ev.wd)\n                if limit and len(evagg) >= limit:\n                    break\n            for path, ev in evagg.items():\n                log.debug(\"Change on %r -- %s\", path, ev.get_mask_description())\n                if ev.mask & (pynotifyx.IN_DELETE_SELF | pynotifyx.IN_MOVE_SELF):\n                    self._disappeared(ev.wd, path, **params)\n                elif ev.mask & pynotifyx.IN_ATTRIB:\n                    file_move_del = False\n                    try:\n                        s = os.stat(path)\n                        if s.st_ino != self._inx_inode[path]:\n                            file_move_del = True\n                            log.info(\"'simfs' (used with containers) bug detected -- %r moved\", path)\n                    except Exception as e:\n                        file_move_del = True\n                        log.info(\"'simfs' (used with containers) bug detected -- %r removed\", path)\n                    if file_move_del:\n                        self._disappeared(ev.wd, path, **params)\n                self.last_changes[path] = time.time()\n\n        elif self._mode == WF_POLLING:\n            #  Consume any pending data from the self-pipe.  Read\n            #  until EOF.  The fd is already non-blocking so this\n            #  terminates on zero read or any error.\n            #\n            cnt = 0\n            while True:\n                try:\n                    data = os.read(self._poll_fd, 1024)\n                    if data == '':\n                        break\n                    cnt += len(data)\n                except OSError as e:\n                    if e.errno != errno.EAGAIN:\n                        log.warning(\"Ignoring self-pipe read failure -- %s\", e)\n                    break\n                except Exception as e:\n                    log.warning(\"Ignoring self-pipe read failure -- %s\", e)\n                    break\n            log.debug(\"Self-pipe read consumed %d byte%s\", cnt, ses(cnt))\n            now = time.time()\n            for path in self._poll_pending:\n                self.last_changes[path] = self._poll_pending[path]\n            self._poll_pending = {}\n            for fd in list(self._poll_stat):\n                path = self.fds_open[fd]\n                fstate = self._poll_get_stat(fd, path)\n                if fstate is None:\n                    self.last_changes[path] = now\n                elif self._poll_stat[fd] != fstate:\n                    self._poll_stat[fd] = fstate\n                    self.last_changes[path] = now\n                    log.debug(\"Change on %r\", path)\n        else:\n            raise Exception(\"Unsupported polling mode \" + self.get_mode_name())\n        paths = list(self.last_changes)\n        paths.sort()\n        log.debug(\"Change was to %d path%s\", len(paths), ses(len(paths)))\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, paths, **params):\n        log = self._getparam('log', self._discard, **params)\n        missing = self._getparam('missing', True, **params)\n        commit = self._getparam('commit', True, **params)\n\n        if type(paths) is not list:\n            paths = [paths]\n\n        rebuild = False\n        for path in paths:\n            if path in self.paths:\n                if self.paths[path] == missing:\n                    log.info(\"Ignoring attempt to add existing path %r\", path)\n                else:\n                    log.debug(\"Changing missing state from %s to %s on existing path %r\",\n                            str(self.paths[path]), str(missing), path)\n                    self.paths[path] = missing\n            else:\n                log.debug(\"Adding path %r\", path)\n                self.paths[path] = missing\n                rebuild = True\n        if commit and rebuild:\n            self.commit(**params)", "response": "Add a path or list of paths to the list of paths being\n        watched."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, paths, **params):\n        log = self._getparam('log', self._discard, **params)\n        commit = self._getparam('commit', True, **params)\n\n        if type(paths) is not list:\n            paths = [paths]\n\n        rebuild = False\n        for path in paths:\n            if path in self.paths_pending:\n                del self.paths_pending[path]\n            if path in self.paths:\n                del self.paths[path]\n                rebuild = True\n            else:\n                log.error(\"Attempt to remove %r which was never added\", path)\n                raise Exception(\"Path %r has never been added\" % path)\n        if commit and rebuild:\n            self.commit(**params)", "response": "Remove a set of paths from the watched list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_ext(filename, ext):\n    if ext.startswith('.'):\n        ext = ext[1:]\n    stem, _ = os.path.splitext(filename)\n    return (stem + '.' + ext)", "response": "Replace extension in filename with ext."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if convert can be run and reports supporting image format fmt.", "response": "def check_imagemagick_supported_format(fmt):\n    \"\"\"\n    Return ``True`` if `convert` can be run and reports supporting image format `fmt`.\n    \"\"\"\n    try:\n        convert_output = check_output(['convert', '--version'])\n    # `subprocess` raises `OSError` if the executable is not found\n    except (CalledProcessError, OSError) as err:\n        logger.error(\n            \"Cannot run ImageMgick's `convert` program.\"\n            \" On Debian/Ubuntu, use `sudo apt-get install imagemagick`\"\n            \" to install it.\")\n        return False\n    # example `convert --version` output::\n    #\n    #     $ convert --version\n    #     Version: ImageMagick 6.9.7-4 Q16 x86_64 20170114 http://www.imagemagick.org\n    #     Copyright: (c) 1999-2017 ImageMagick Studio LLC\n    #     License: http://www.imagemagick.org/script/license.php\n    #     Features: Cipher DPC Modules OpenMP\n    #     Delegates (built-in): bzlib djvu fftw fontconfig freetype jbig jng jpeg lcms lqr ltdl lzma openexr pangocairo png tiff wmf x xml zlib\n    #\n    # the following loop will make it such that::\n    #\n    #     supported = ['bzlib', 'djvu', ...]\n    #\n    supported = []\n    for line in convert_output.split('\\n'):\n        line = line.lower()\n        if line.startswith('delegates'):\n            supported += line.split(':', 1)[1].split()\n    # allow fmt to be ``png``, ``JPEG``, ``.TIF`` etc.\n    fmt = fmt.lower()\n    if not fmt.startswith('.'):\n        fmt = '.' + fmt\n    try:\n        delegate = SUPPORTED_IMAGE_FORMATS[fmt]\n    except KeyError:\n        logger.error(\"Image format `%s` not supported by `tm_client`.\")\n        return False\n    if delegate in supported:\n        return True\n    else:\n        logger.error(\"Image format `%s` not in ImageMagick's `convert` delegates.\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget information for all experiments.", "response": "def get_experiments(self):\n        '''Gets information for all experiments.\n\n        Returns\n        -------\n        List[Dict[str, str]]\n            id, name and description for each experiment\n\n        See also\n        --------\n        :func:`tmserver.api.experiment.get_experiments`\n        :class:`tmlib.models.experiment.Experiment`\n        '''\n        logger.info('get experiments')\n        url = self._build_api_url('/experiments')\n        res = self._session.get(url)\n        res.raise_for_status()\n        return res.json()['data']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_experiment(self, workflow_type, microscope_type, plate_format,\n            plate_acquisition_mode):\n        '''Creates the experiment.\n\n        Parameters\n        ----------\n        workflow_type: str\n            workflow type\n        microscope_type: str\n            microscope type\n        plate_format: int\n            well-plate format, i.e. total number of wells per plate\n        plate_acquisition_mode: str\n            mode of image acquisition that determines whether acquisitions will\n            be interpreted as time points as part of a time series experiment\n            or as multiplexing cycles as part of a serial multiplexing\n            experiment\n\n        Returns\n        -------\n        dict\n            experiment resource representation\n\n        See also\n        --------\n        :func:`tmserver.api.experiment.create_experiment`\n        :class:`tmlib.models.experiment.ExperimentReference`\n        :class:`tmlib.models.experiment.Experiment`\n        '''\n        logger.info('create experiment \"%s\"', self.experiment_name)\n        content = {\n            'name': self.experiment_name,\n            'workflow_type': workflow_type,\n            'microscope_type': microscope_type,\n            'plate_format': plate_format,\n            'plate_acquisition_mode': plate_acquisition_mode\n        }\n        url = self._build_api_url('/experiments')\n        res = self._session.post(url, json=content)\n        res.raise_for_status()\n        data = res.json()['data']\n        self._experiment_id = data['id']\n        return data", "response": "Creates the experiment.\n\n        Parameters\n        ----------\n        workflow_type: str\n            workflow type\n        microscope_type: str\n            microscope type\n        plate_format: int\n            well-plate format, i.e. total number of wells per plate\n        plate_acquisition_mode: str\n            mode of image acquisition that determines whether acquisitions will\n            be interpreted as time points as part of a time series experiment\n            or as multiplexing cycles as part of a serial multiplexing\n            experiment\n\n        Returns\n        -------\n        dict\n            experiment resource representation\n\n        See also\n        --------\n        :func:`tmserver.api.experiment.create_experiment`\n        :class:`tmlib.models.experiment.ExperimentReference`\n        :class:`tmlib.models.experiment.Experiment`"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrenaming the experiment. Parameters ---------- See also -------- :func:`tmserver.api.experiment.update_experiment` :class:`tmlib.models.experiment.ExperimentReference`", "response": "def rename_experiment(self, new_name):\n        '''Renames the experiment.\n\n        Parameters\n        ----------\n\n        See also\n        --------\n        :func:`tmserver.api.experiment.update_experiment`\n        :class:`tmlib.models.experiment.ExperimentReference`\n        '''\n        logger.info('rename experiment \"%s\"', self.experiment_name)\n        content = {'name': new_name}\n        url = self._build_api_url(\n            '/experiments/{experiment_id}'.format(\n                experiment_id=self._experiment_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()\n        self.experiment_name = new_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the experiment. See also -------- :func:`tmserver.api.experiment.delete_experiment` :class:`tmlib.models.experiment.ExperimentReference` :class:`tmlib.models.experiment.Experiment`", "response": "def delete_experiment(self):\n        '''Deletes the experiment.\n\n        See also\n        --------\n        :func:`tmserver.api.experiment.delete_experiment`\n        :class:`tmlib.models.experiment.ExperimentReference`\n        :class:`tmlib.models.experiment.Experiment`\n        '''\n        logger.info('delete experiment \"%s\"', self.experiment_name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}'.format(\n                experiment_id=self._experiment_id\n            )\n        )\n        res = self._session.delete(url)\n        res.raise_for_status()\n        del self.__experiment_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a plate. Parameters ---------- name: str name of the plate that should be deleted See also -------- :func:`tmserver.api.plate.delete_plate` :class:`tmlib.models.plate.Plate`", "response": "def delete_plate(self, name):\n        '''Deletes a plate.\n\n        Parameters\n        ----------\n        name: str\n            name of the plate that should be deleted\n\n        See also\n        --------\n        :func:`tmserver.api.plate.delete_plate`\n        :class:`tmlib.models.plate.Plate`\n        '''\n        logger.info(\n            'delete plate \"%s\" of experiment \"%s\"',\n            name, self.experiment_name\n        )\n        plate_id = self._get_plate_id(name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/plates/{plate_id}'.format(\n                experiment_id=self._experiment_id, plate_id=plate_id\n            )\n        )\n        res = self._session.delete(url)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rename_plate(self, name, new_name):\n        '''Renames a plate.\n\n        Parameters\n        ----------\n        name: str\n            name of the plate that should be renamed\n        new_name: str\n            name that should be given to the plate\n\n        See also\n        --------\n        :func:`tmserver.api.plate.update_plate`\n        :class:`tmlib.models.plate.Plate`\n        '''\n        logger.info(\n            'rename plate \"%s\" of experiment \"%s\"',\n            name, self.experiment_name\n        )\n        plate_id = self._get_plate_id(name)\n        content = {'name': new_name}\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/plates/{plate_id}'.format(\n                experiment_id=self._experiment_id, plate_id=plate_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()", "response": "Renames a plate.\n\n        Parameters\n        ----------\n        name: str\n            name of the plate that should be renamed\n        new_name: str\n            name that should be given to the plate\n\n        See also\n        --------\n        :func:`tmserver.api.plate.update_plate`\n        :class:`tmlib.models.plate.Plate`"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrenaming an acquisition. Parameters ---------- plate_name: str name of the parent plate name: str name of the acquisition that should be renamed new_name: str name that should be given to the acquisition See also -------- :func:`tmserver.api.acquisition.update_acquisition` :class:`tmlib.models.acquisition.Acquisition`", "response": "def rename_acquisition(self, plate_name, name, new_name):\n        '''Renames an acquisition.\n\n        Parameters\n        ----------\n        plate_name: str\n            name of the parent plate\n        name: str\n            name of the acquisition that should be renamed\n        new_name: str\n            name that should be given to the acquisition\n\n        See also\n        --------\n        :func:`tmserver.api.acquisition.update_acquisition`\n        :class:`tmlib.models.acquisition.Acquisition`\n        '''\n        logger.info(\n            'rename acquisistion \"%s\" of experiment \"%s\", plate \"%s\"',\n            name, self.experiment_name, plate_name\n        )\n        content = {'name': new_name}\n        acquisition_id = self._get_acquisition_id(plate_name, name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/acquisitions/{acquisition_id}'.format(\n                experiment_id=self._experiment_id, acquisition_id=acquisition_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an acquisition. Parameters ---------- plate_name: str name of the parent plate name: str name of the acquisition that should be deleted See also -------- :func:`tmserver.api.acquisition.delete_acquisition` :class:`tmlib.models.acquisition.Acquisition`", "response": "def delete_acquisition(self, plate_name, name):\n        '''Deletes an acquisition.\n\n        Parameters\n        ----------\n        plate_name: str\n            name of the parent plate\n        name: str\n            name of the acquisition that should be deleted\n\n        See also\n        --------\n        :func:`tmserver.api.acquisition.delete_acquisition`\n        :class:`tmlib.models.acquisition.Acquisition`\n        '''\n        logger.info(\n            'delete acquisition \"%s\" of experiment \"%s\", plate \"%s\"',\n            name, self.experiment_name, plate_name\n        )\n        acquisition_id = self._get_acquisition_id(plate_name, name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/acquisitions/{acquisition_id}'.format(\n                experiment_id=self._experiment_id, acquisition_id=acquisition_id\n            )\n        )\n        res = self._session.delete(url)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_wells(self, plate_name=None):\n        '''Gets information about wells.\n\n        Parameters\n        ----------\n        plate_name: str, optional\n            name of the parent plate\n\n        Returns\n        -------\n        List[Dict[str, str]]\n            id, name and description of each well\n\n        See also\n        --------\n        :func:`tmserver.api.well.get_wells`\n        :class:`tmlib.models.well.Well`\n        '''\n        logger.info('get wells of experiment \"%s\"', self.experiment_name)\n        params = dict()\n        if plate_name is not None:\n            logger.info('filter wells for plate \"%s\"', plate_name)\n            params['plate_name'] = plate_name\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/wells'.format(\n                experiment_id=self._experiment_id\n            ),\n            params\n        )\n        res = self._session.get(url)\n        res.raise_for_status()\n        return res.json()['data']", "response": "Gets information about wells."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_microscope_files(self, plate_name, acquisition_name):\n        '''Gets status and name of files that have been registered for upload.\n\n        Parameters\n        ----------\n        plate_name: str\n            name of the parent plate\n        acquisition_name: str\n            name of the parent acquisition\n\n        Returns\n        -------\n        List[Dict[str, str]]\n            names and status of uploaded files\n\n        See also\n        --------\n        :func:`tmserver.api.acquisition.get_microscope_image_files_information`\n        :func:`tmserver.api.acquisition.get_microscope_metadata_file_information`\n        :class:`tmlib.models.acquisition.Acquisition`\n        :class:`tmlib.models.file.MicroscopeImageFile`\n        :class:`tmlib.models.file.MicroscopeMetadataFile`\n        '''\n        logger.info(\n            'get names of already uploaded files for experiment \"%s\", '\n            'plate \"%s\" and acquisition \"%s\"', self.experiment_name, plate_name,\n            acquisition_name\n        )\n        acquisition_id = self._get_acquisition_id(plate_name, acquisition_name)\n        image_files = self._get_image_files(acquisition_id)\n        metadata_files = self._get_metadata_files(acquisition_id)\n        return image_files + metadata_files", "response": "Gets status and name of files that have been uploaded for upload."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading microscope files contained in path to the experiment.", "response": "def upload_microscope_files(self, plate_name, acquisition_name,\n                                path, parallel=1, retry=5,\n                                convert=None, delete_after_upload=False,\n                                _deprecated_directory_option=False):\n        '''\n        Uploads microscope files contained in `path`.\n        If `path` is a directory, upload all files contained in it.\n\n        Parameters\n        ----------\n        plate_name: str\n            name of the parent plate\n        acquisition_name: str\n            name of the parent acquisition\n        path: str\n            path to a directory on disk where the files that should be uploaded\n            are located\n        parallel: int\n            number of parallel processes to use for upload\n        retry: int\n            number of times to retry failed uploads\n        convert: str\n            Format to convert images to during the upload process.\n            Given as a string specifying the new file extension (e.g.,\n            ``png`` or ``jpg``).  If ``None`` or the empty string,\n            no conversion takes place and files are uploaded as-is.\n        delete_after_upload: bool\n            Delete source files after successful upload.\n\n        Returns\n        -------\n        List[str]\n            names of registered files\n\n        See also\n        --------\n        :func:`tmserver.api.acquisition.add_microscope_file`\n        :class:`tmlib.models.file.MicroscopeImageFile`\n        :class:`tmlib.models.file.MicroscopeMetadataFile`\n        '''\n        if _deprecated_directory_option:\n            logger.warn(\n                \"The `--directory` option is now superfluous.\"\n                \" You can remove it from the command line.\")\n        # TODO: consider using os.walk() to screen subdirectories recursively\n        logger.info(\n            'upload microscope files for experiment \"%s\", plate \"%s\" '\n            'and acquisition \"%s\"',\n            self.experiment_name, plate_name, acquisition_name\n        )\n        if convert:\n            # FIXME: This checks that `convert` can handle the\n            # *destination* image format, but it could be lacking\n            # support for the *source* image format... But the source\n            # images are many and, in principle, they could be of many\n            # different formats...\n            if not check_imagemagick_supported_format(convert):\n                logger.fatal(\n                    \"Aborting: conversion requested\"\n                    \" but ImageMagick's `convert` not available.\")\n                return -1\n            logger.info(\"files will be converted to %s format\", convert)\n        acquisition_id = self._get_acquisition_id(plate_name, acquisition_name)\n\n        path = os.path.expandvars(os.path.expanduser(path))\n        if os.path.isdir(path):\n            filenames = [\n                f for f in os.listdir(path)\n                if (not f.startswith('.')\n                    and not os.path.isdir(os.path.join(path, f)))\n            ]\n            paths = [\n                os.path.join(path, name) for name in filenames\n            ]\n        else:\n            filenames = [ os.path.basename(path) ]\n            paths = [ path ]\n        if convert:\n            filenames_to_register = []\n            for filename in filenames:\n                # note: `ext` starts with a dot!\n                name, ext = os.path.splitext(filename)\n                if ext in SUPPORTED_IMAGE_FORMATS:\n                    filenames_to_register.append(replace_ext(filename, convert))\n                else:\n                    # no image, no change\n                    filenames_to_register.append(filename)\n        else:\n            filenames_to_register = filenames\n        registered_filenames = self._register_files_for_upload(\n            acquisition_id, filenames_to_register\n        )\n        logger.info('registered %d files', len(registered_filenames))\n\n        if convert:\n            # make temporary directory and schedule its deletion\n            convert_dir = tempfile.mkdtemp(prefix='tm_client', suffix='.d')\n            atexit.register(shutil.rmtree, convert_dir, ignore_errors=True)\n        else:\n            convert_dir = None  # unused, but still have to provide it\n\n        upload_url = self._build_api_url(\n            '/experiments/{experiment_id}/acquisitions/{acquisition_id}/microscope-file'\n            .format(experiment_id=self._experiment_id, acquisition_id=acquisition_id)\n        )\n        total = len(paths)\n        retry += 1  # make usage here consistent with CLI usage\n        while retry > 0:\n            work = [\n                # function,         *args ...\n                (self._upload_file, upload_url, path, convert,\n                                    delete_after_upload, convert_dir)\n                for path in paths\n            ]\n            outcome = self._parallelize(work, parallel)\n            # report on failures\n            paths = [path for (ok, path) in outcome if not ok]\n            failed = len(paths)\n            successful = total - failed\n            logger.info('file uploads: %d successful, %d failed', successful, failed)\n            # try again?\n            if failed == 0:\n                break\n            else:\n                retry -= 1\n                total = failed\n                logger.info('trying again to upload failed files ...')\n\n        return registered_filenames"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_microscope_files(self, plate_name, acquisition_name,\n                                path):\n        '''\n        Register microscope files contained in `path` (Server side).\n        If `path` is a directory, upload all files contained in it.\n\n        Parameters\n        ----------\n        plate_name: str\n            name of the parent plate\n        acquisition_name: str\n            name of the parent acquisition\n        path: str\n            path to a directory on disk where the files that should be uploaded\n            are located\n        Returns:\n        -------\n        List[str]\n            names of registered files\n        '''\n\n        logger.info(\n            'register microscope files for experiment \"%s\", plate \"%s\" '\n            'and acquisition \"%s\"',\n            self.experiment_name, plate_name, acquisition_name\n        )\n\n\tacquisition_id = self._get_acquisition_id(plate_name, acquisition_name)\n        register_url = self._build_api_url(\n            '/experiments/{experiment_id}/acquisitions/{acquisition_id}/register'\n            .format(experiment_id=self._experiment_id, acquisition_id=acquisition_id)\n        )\n\n        logger.debug('register files for upload')\n        url = self._build_api_url('/experiments/{experiment_id}/acquisitions/{acquisition_id}/register'.format(experiment_id=self._experiment_id, acquisition_id=acquisition_id))\n        payload = {'path': path}\n        res = self._session.post(url, json=payload)\n        res.raise_for_status()\n        return res.json()['message']", "response": "Register microscope files contained in path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrename a channel. Parameters ---------- name: str name of the channel that should be renamed new_name: str name that should be given to the channel See also -------- :func:`tmserver.api.channel.update_channel` :class:`tmlib.models.channel.Channel`", "response": "def rename_channel(self, name, new_name):\n        '''Renames a channel.\n\n        Parameters\n        ----------\n        name: str\n            name of the channel that should be renamed\n        new_name: str\n            name that should be given to the channel\n\n        See also\n        --------\n        :func:`tmserver.api.channel.update_channel`\n        :class:`tmlib.models.channel.Channel`\n        '''\n        logger.info(\n            'rename channel \"%s\" of experiment \"%s\"',\n            name, self.experiment_name\n        )\n        channel_id = self._get_channel_id(name)\n        content = {'name': new_name}\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/channels/{channel_id}'.format(\n                experiment_id=self._experiment_id, channel_id=channel_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting cycles. Returns a list of dicts containing the cycle information about each cycle.", "response": "def get_cycles(self):\n        '''Gets cycles.\n\n        Returns\n        -------\n        List[Dict[str, str]]\n            information about each cycle\n\n        See also\n        --------\n        :func:`tmserver.api.cycle.get_cycles`\n        :class:`tmlib.models.cycles.Cycle`\n        '''\n        logger.info('get cycles of experiment \"%s\"', self.experiment_name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/cycles'.format(\n                experiment_id=self._experiment_id\n            )\n        )\n        res = self._session.get(url)\n        res.raise_for_status()\n        return res.json()['data']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a channel image.", "response": "def download_channel_image(self, channel_name, plate_name,\n            well_name, well_pos_y, well_pos_x,\n            cycle_index=0, tpoint=0, zplane=0, correct=True, align =False):\n        '''Downloads a channel image.\n\n        Parameters\n        ----------\n        channel_name: str\n            name of the channel\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well\n        well_pos_x: int\n            zero-based x cooridinate of the acquisition site within the well\n        well_pos_y: int\n            zero-based y cooridinate of the acquisition site within the well\n        cycle_index: str, optional\n            zero-based cycle index (default: ``0``)\n        tpoint: int, optional\n            zero-based time point index (default: ``0``)\n        zplane: int, optional\n            zero-based z-plane index (default: ``0``)\n        correct: bool, optional\n            whether image should be corrected for illumination artifacts\n            (default: ``True``)\n\n        Note\n        ----\n        Image gets automatically aligned between cycles.\n\n        Returns\n        -------\n        numpy.ndarray[numpy.uint16 or numpy.uint8]\n            pixel/voxel array and filename\n\n        See also\n        --------\n        :func:`tmserver.api.file.get_channel_image_file`\n        :class:`tmlib.models.file.ChannelImageFile`\n        '''\n        response = self._download_channel_image(\n            channel_name, plate_name, well_name, well_pos_y, well_pos_x,\n            cycle_index=cycle_index, tpoint=tpoint, zplane=zplane,\n            correct=correct, align = align\n        )\n        data = np.frombuffer(response.content, np.uint8)\n        return cv2.imdecode(data, cv2.IMREAD_UNCHANGED)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a channel image and writes it to a PNG file on disk.", "response": "def download_channel_image_file(self, channel_name, plate_name,\n            well_name, well_pos_y, well_pos_x, cycle_index,\n            tpoint, zplane, correct, align, directory):\n        '''Downloads a channel image and writes it to a `PNG` file on disk.\n\n        Parameters\n        ----------\n        channel_name: str\n            name of the channel\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well\n        well_pos_x: int\n            zero-based x cooridinate of the acquisition site within the well\n        well_pos_y: int\n            zero-based y cooridinate of the acquisition site within the well\n        cycle_index: str\n            zero-based cycle index\n        tpoint: int\n            zero-based time point index\n        zplane: int\n            zero-based z-plane index\n        correct: bool\n            whether image should be corrected for illumination artifacts\n        align: bool\n            whether image should be aligned to the other cycles\n        directory: str\n            absolute path to the directory on disk where the file should be saved\n\n        Note\n        ----\n        Image gets automatically aligned between cycles.\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.download_channel_image`\n        '''\n        response = self._download_channel_image(\n            channel_name, plate_name, well_name, well_pos_y, well_pos_x,\n            cycle_index=cycle_index, tpoint=tpoint, zplane=zplane,\n            correct=correct, align = align\n        )\n        data = response.content\n        filename = self._extract_filename_from_headers(response.headers)\n        self._write_file(directory, os.path.basename(filename), data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a segmentation image.", "response": "def download_segmentation_image(self, mapobject_type_name,\n            plate_name, well_name, well_pos_y, well_pos_x, tpoint=0, zplane=0, align = False):\n        '''Downloads a segmentation image.\n\n        Parameters\n        ----------\n        plate_id: int\n            ID of the parent experiment\n        mapobject_type_name: str\n            name of the segmented objects\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well in which the image is located\n        well_pos_y: int\n            y-position of the site relative to the well grid\n        well_pos_x: int\n            x-position of the site relative to the well grid\n        tpoint: int, optional\n            zero-based time point index (default: ``0``)\n        zplane: int, optional\n            zero-based z-plane index (default: ``0``)\n        align: bool, optional\n            option to apply alignment to download\n\n        Returns\n        -------\n        numpy.ndarray[numpy.int32]\n            labeled image where each label encodes a segmented object\n\n        See also\n        --------\n        :func:`tmserver.api.mapobject.download_segmentations`\n        :class:`tmlib.models.mapobject.MapobjectSegmentation`\n        '''\n        response = self._download_segmentation_image(\n            mapobject_type_name, plate_name, well_name, well_pos_y, well_pos_x,\n            tpoint, zplane, align\n        )\n        return np.array(response, dtype=np.int32)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_segmentation_image_file(self, mapobject_type_name,\n            plate_name, well_name, well_pos_y, well_pos_x, tpoint, zplane, align,\n            directory):\n        '''Downloads a segmentation image and writes it to a *PNG* file on disk.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            name of the segmented objects\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well in which the image is located\n        well_pos_y: int\n            y-position of the site relative to the well grid\n        well_pos_x: int\n            x-position of the site relative to the well grid\n        tpoint: int\n            zero-based time point index\n        zplane: int\n            zero-based z-plane index\n        align: bool\n            option to apply alignment to download\n        directory: str\n            absolute path to the directory on disk where the file should be saved\n\n        Warning\n        -------\n        Due to the *PNG* file format the approach is limited to images which\n        contain less than 65536 objects.\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.download_segmentation_image`\n        '''\n        response = self._download_segmentation_image(\n            mapobject_type_name, plate_name, well_name, well_pos_y, well_pos_x,\n            tpoint, zplane, align\n        )\n        image = np.array(response, np.int32)\n        if np.max(image) >= 2**16:\n            raise ValueError(\n                'Cannot store segmentation image as PNG file because it '\n                'contains more than 65536 objects.'\n            )\n        filename = '{0}_{1}_{2}_y{3:03d}_x{4:03d}_z{5:03d}_t{6:03d}_{7}.png'.format(\n            self.experiment_name, plate_name, well_name, well_pos_y,\n            well_pos_x, zplane, tpoint, mapobject_type_name\n        )\n        data = cv2.imencode(filename, image.astype(np.uint16))[1]\n        self._write_file(directory, filename, data)", "response": "Downloads a segmentation image and writes it to a PNG file on disk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload_segmentation_image(self, mapobject_type_name,\n            plate_name, well_name, well_pos_y, well_pos_x, tpoint, zplane,\n            image):\n        '''Uploads a segmentation image.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            name of the segmented objects\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well in which the image is located\n        well_pos_y: int\n            y-position of the site relative to the well grid\n        well_pos_x: int\n            x-position of the site relative to the well grid\n        tpoint: int, optional\n            zero-based time point index (default: ``0``)\n        zplane: int, optional\n            zero-based z-plane index (default: ``0``)\n        image: numpy.ndarray[numpy.int32]\n            labeled array\n\n        Raises\n        ------\n        TypeError\n            when `image` is not provided in form of a `numpy` array\n        ValueError\n            when `image` doesn't have 32-bit unsigned integer data type\n\n        See also\n        --------\n        :func:`tmserver.api.mapobject.add_segmentations`\n        :class:`tmlib.models.mapobject.MapobjectSegmentation`\n        '''\n        if not isinstance(image, np.ndarray):\n            raise TypeError('Image must be provided in form of a numpy array.')\n        if image.dtype != np.int32:\n            raise ValueError('Image must have 32-bit integer data type.')\n        self._upload_segmentation_image(mapobject_type_name,\n            plate_name, well_name, well_pos_y, well_pos_x, tpoint, zplane,\n            image\n        )", "response": "Uploads a segmentation image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nuploading segmentation images from a PNG file.", "response": "def upload_segmentation_image_file(self, mapobject_type_name,\n            plate_name, well_name, well_pos_y, well_pos_x, tpoint, zplane,\n            filename):\n        '''Uploads segmentations from a *PNG* image file.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            name of the segmented objects\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well in which the image is located\n        well_pos_y: int\n            y-position of the site relative to the well grid\n        well_pos_x: int\n            x-position of the site relative to the well grid\n        tpoint: int, optional\n            zero-based time point index (default: ``0``)\n        zplane: int, optional\n            zero-based z-plane index (default: ``0``)\n        filename: str\n            path to the file on disk\n\n        Warning\n        -------\n        This approach will only works for images with less than 65536 objects,\n        since the *PNG* format is limited to 16-bit grayscale images.\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.upload_segmentation_image`\n        '''\n        logger.info('upload segmentation image file \"%s\"', filename)\n        if not filename.lower().endswith('png'):\n            raise IOError('Filename must have \"png\" extension.')\n        filename = os.path.expanduser(os.path.expandvars(filename))\n        image = cv2.imread(filename, cv2.IMREAD_UNCHANGED | cv2.IMREAD_ANYDEPTH)\n        self._upload_segmentation_image(\n            mapobject_type_name, plate_name, well_name, well_pos_y, well_pos_x,\n            tpoint, zplane, image.astype(np.int32)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrenaming a feature. Parameters ---------- mapobject_type_name: str name of the segmented objects type name: str name of the feature that should be renamed new_name: str name that should be given to the feature See also -------- :func:`tmserver.api.feature.update_feature` :class:`tmlib.models.feature.Feature`", "response": "def rename_feature(self, mapobject_type_name, name, new_name):\n        '''Renames a feature.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            name of the segmented objects type\n        name: str\n            name of the feature that should be renamed\n        new_name: str\n            name that should be given to the feature\n\n        See also\n        --------\n        :func:`tmserver.api.feature.update_feature`\n        :class:`tmlib.models.feature.Feature`\n        '''\n        logger.info(\n            'rename feature \"%s\" of experiment \"%s\", mapobject type \"%s\"',\n            name, self.experiment_name, mapobject_type_name\n        )\n        content = {\n            'name': new_name,\n        }\n        feature_id = self._get_feature_id(mapobject_type_name, name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/features/{feature_id}'.format(\n                experiment_id=self._experiment_id, feature_id=feature_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a feature. Parameters ---------- mapobject_type_name: str name of the segmented objects type name: str name of the feature that should be renamed See also -------- :func:`tmserver.api.feature.delete_feature` :class:`tmlib.models.feature.Feature`", "response": "def delete_feature(self, mapobject_type_name, name):\n        '''Deletes a feature.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            name of the segmented objects type\n        name: str\n            name of the feature that should be renamed\n\n        See also\n        --------\n        :func:`tmserver.api.feature.delete_feature`\n        :class:`tmlib.models.feature.Feature`\n        '''\n        logger.info(\n            'delete feature \"%s\" of experiment \"%s\", mapobject type \"%s\"',\n            name, self.experiment_name, mapobject_type_name\n        )\n        feature_id = self._get_feature_id(mapobject_type_name, name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/features/{feature_id}'.format(\n                experiment_id=self._experiment_id, feature_id=feature_id\n            )\n        )\n        res = self._session.delete(url)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrenaming a mapobject type.", "response": "def rename_mapobject_type(self, name, new_name):\n        '''Renames a mapobject type.\n\n        Parameters\n        ----------\n        name: str\n            name of the mapobject type that should be renamed\n        new_name: str\n            name that should be given to the mapobject type\n\n        See also\n        --------\n        :func:`tmserver.api.mapobject.update_mapobject_type`\n        :class:`tmlib.models.mapobject.MapobjectType`\n        '''\n        logger.info(\n            'rename mapobject type \"%s\" of experiment \"%s\"',\n            name, self.experiment_name\n        )\n        content = {'name': new_name}\n        mapobject_type_id = self._get_mapobject_type_id(name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/mapobject_types/{mapobject_type_id}'.format(\n                experiment_id=self._experiment_id,\n                mapobject_type_id=mapobject_type_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_mapobject_type(self, name):\n        '''Deletes a mapobject type.\n\n        Parameters\n        ----------\n        name: str\n            name of the mapobject type that should be renamed\n\n        See also\n        --------\n        :func:`tmserver.api.mapobject.delete_mapobject_type`\n        :class:`tmlib.models.mapobject.MapobjectType`\n        '''\n        logger.info(\n            'delete mapobject type \"%s\" of experiment \"%s\"',\n            name, self.experiment_name\n        )\n        mapobject_type_id = self._get_mapobject_type_id(name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/mapobject_types/{mapobject_type_id}'.format(\n                experiment_id=self._experiment_id,\n                mapobject_type_id=mapobject_type_id\n            )\n        )\n        res = self._session.delete(url)\n        res.raise_for_status()", "response": "Deletes a mapobject type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets features for a given object type.", "response": "def get_features(self, mapobject_type_name):\n        '''Gets features for a given object type.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            type of the segmented objects\n\n        Returns\n        -------\n        List[Dict[str, str]]\n            information about each feature\n\n        See also\n        --------\n        :func:`tmserver.api.feature.get_features`\n        :class:`tmlib.models.feature.Feature`\n        '''\n        logger.info(\n            'get features of experiment \"%s\", object type \"%s\"',\n            self.experiment_name, mapobject_type_name\n        )\n        mapobject_type_id = self._get_mapobject_type_id(mapobject_type_name)\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/mapobject_types/{mapobject_type_id}/features'.format(\n                experiment_id=self._experiment_id,\n                mapobject_type_id=mapobject_type_id\n            )\n        )\n        res = self._session.get(url)\n        res.raise_for_status()\n        return res.json()['data']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads feature values for the given mapobject type at the given plate and well.", "response": "def upload_feature_value_file(self, mapobject_type_name, plate_name,\n            well_name, well_pos_y, well_pos_x, tpoint, filename, index_col):\n        '''Uploads feature values for the given\n        :class:`MapobjectType <tmlib.models.mapobject.MapobjectType>` at the\n        specified :class:`Site <tmlib.models.site.Site>`.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            type of the segmented objects\n        plate_name: str\n            name of the plate\n        well_name: str\n            name of the well\n        well_pos_y: int\n            y-position of the site relative to the well grid\n        well_pos_x: int\n            x-position of the site relative to the well grid\n        tpoint: int\n            zero-based time point index\n        filename: str\n            path to the file on disk\n        index_col: str\n            column name containing the object labels\n\n        See also\n        --------\n        :func:`tmserver.api.feature.add_feature_values`\n        :class:`tmlib.models.feature.FeatureValues`\n        '''\n        logger.info('upload feature value file \"%s\"', filename)\n        if not filename.lower().endswith('csv'):\n            raise IOError('Filename must have \"csv\" extension.')\n        filename = os.path.expanduser(os.path.expandvars(filename))\n        data = pd.read_csv(filename, index_col=index_col)\n        self._upload_feature_values(\n            mapobject_type_name, plate_name, well_name, well_pos_y, well_pos_x,\n            tpoint, data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads feature values for the given mapobject type.", "response": "def download_feature_values(self, mapobject_type_name,\n            plate_name=None, well_name=None, well_pos_y=None, well_pos_x=None,\n            tpoint=None):\n        '''Downloads feature values for the given\n        :class:`MapobjectType <tmlib.models.mapobject.MapobjectType>`.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            type of the segmented objects\n        plate_name: str, optional\n            name of the plate\n        well_name: str, optional\n            name of the well\n        well_pos_y: int, optional\n            y-position of the site relative to the well grid\n        well_pos_x: int, optional\n            x-position of the site relative to the well grid\n        tpoint: int, optional\n            zero-based time point index\n\n        Returns\n        -------\n        pandas.DataFrame\n            *n*x*p* dataframe, where *n* are number of objects and *p* number\n            of features\n\n        See also\n        --------\n        :func:`tmserver.api.feature.get_feature_values`\n        :class:`tmlib.models.feature.FeatureValues`\n\n        Warning\n        -------\n        This will try to load all data into memory, which may be problematic\n        for large datasets.\n        '''\n        res = self._download_feature_values(\n            mapobject_type_name, plate_name, well_name, well_pos_y, well_pos_x,\n            tpoint\n        )\n        logger.debug('decode CSV data')\n        file_obj = StringIO(res.content.decode('utf-8'))\n        try:\n            return pd.read_csv(file_obj)\n        except EmptyDataError:\n            return pd.DataFrame()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload all feature values and metadata files for the given object type and stores the values and metadata files on disk.", "response": "def download_feature_values_and_metadata_files(self, mapobject_type_name,\n                                                   directory, parallel=1):\n        '''Downloads all feature values for the given object type and stores the\n        data as *CSV* files on disk.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            type of the segmented objects\n        directory: str\n            absolute path to the directory on disk where the file should be\n        parallel: int\n            number of parallel processes to use for upload\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.download_feature_values`\n        :meth:`tmclient.api.TmClient.download_object_metadata`\n        '''\n\n        def download_per_well(well):\n            logger.info(\n                'download feature data at well: plate=%s, well=%s',\n                well['plate_name'], well['name']\n            )\n            res = self._download_feature_values(\n                mapobject_type_name, well['plate_name'], well['name']\n            )\n            filename = self._extract_filename_from_headers(res.headers)\n            filepath = os.path.join(directory, os.path.basename(filename))\n            logger.info('write feature values to file: %s', filepath)\n            with open(filepath, 'wb') as f:\n                for c in res.iter_content(chunk_size=1000):\n                    f.write(c)\n\n            logger.info(\n                'download feature metadata at well: plate=%s, well=%s',\n                well['plate_name'], well['name']\n            )\n            res = self._download_object_metadata(\n                mapobject_type_name, well['plate_name'], well['name']\n            )\n            filename = self._extract_filename_from_headers(res.headers)\n            filepath = os.path.join(directory, os.path.basename(filename))\n            logger.info('write metadata to file: %s', filepath)\n            with open(filepath, 'wb') as f:\n                for c in res.iter_content(chunk_size=1000):\n                    f.write(c)\n\n        work = [(download_per_well, well) for well in self.get_wells()]\n        self._parallelize(work, parallel)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_object_metadata(self, mapobject_type_name, plate_name=None,\n            well_name=None, well_pos_y=None, well_pos_x=None, tpoint=None):\n        '''Downloads metadata for the given object type, which describes the\n        position of each segmented object on the map.\n\n        Parameters\n        ----------\n        mapobject_type_name: str\n            type of the segmented objects\n        plate_name: str, optional\n            name of the plate\n        well_name: str, optional\n            name of the well\n        well_pos_y: int, optional\n            y-position of the site relative to the well grid\n        well_pos_x: int, optional\n            x-position of the site relative to the well grid\n        tpoint: int, optional\n            zero-based time point index\n\n        Returns\n        -------\n        pandas.DataFrame\n            *n*x*p* dataframe, where *n* are number of objects and *p* number\n            of metadata attributes\n\n        See also\n        --------\n        :func:`tmserver.api.feature.get_metadata`\n        '''\n        res = self._download_object_metadata(\n            mapobject_type_name, plate_name, well_name, well_pos_y, well_pos_x,\n            tpoint\n        )\n        file_obj = StringIO(res.content.decode('utf-8'))\n        try:\n            return pd.read_csv(file_obj)\n        except EmptyDataError:\n            return pd.DataFrame()", "response": "Downloads metadata for the given object type which describes the\n            position of each segmented object on the map."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads the workflow description and writes it to a YAML file.", "response": "def download_workflow_description_file(self, filename):\n        '''Downloads the workflow description and writes it to a *YAML* file.\n\n        Parameters\n        ----------\n        filename: str\n            path to the file to which description should be written\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.download_workflow_description`\n        '''\n        description = self.download_workflow_description()\n        logger.info('write workflow description to file: %s', filename)\n        with open(filename, 'w') as f:\n            content = yaml.safe_dump(\n                description, default_flow_style=False, explicit_start=True\n            )\n            f.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_workflow_description_file(self, filename):\n        '''Uploads workflow description from a *YAML* file.\n\n        Parameters\n        ----------\n        filename: str\n            path to the file from which description should be read\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.upload_workflow_description`\n        '''\n        if (\n            not filename.lower().endswith('yml') and\n            not filename.lower().endswith('yaml')\n        ):\n            raise ResourceError('filename must have \"yaml\" or \"yml\" extension')\n        with open(filename) as f:\n            logger.info('load workflow description from file: %s', filename)\n            description = yaml.safe_load(f.read())\n        self.upload_workflow_description(description)", "response": "Uploads workflow description from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresubmitting the workflow. Parameters ---------- stage_name: str, optional name of the stage at which workflow should be resubmitted (when omitted workflow will be restarted from the beginning) description: dict, optional workflow description See also -------- :func:`tmserver.api.workflow.resubmit_workflow` :class:`tmlib.workflow.workflow.Workflow`", "response": "def resubmit_workflow(self, stage_name=None, description=None):\n        '''Resubmits the workflow.\n\n        Parameters\n        ----------\n        stage_name: str, optional\n            name of the stage at which workflow should be resubmitted\n            (when omitted workflow will be restarted from the beginning)\n        description: dict, optional\n            workflow description\n\n        See also\n        --------\n        :func:`tmserver.api.workflow.resubmit_workflow`\n        :class:`tmlib.workflow.workflow.Workflow`\n        '''\n        logger.info(\n            'resubmit workflow of experiment \"%s\"', self.experiment_name\n        )\n        content = dict()\n        if description is not None:\n            content['description'] = description\n        if stage_name is not None:\n            content['stage_name'] = stage_name\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/workflow/resubmit'.format(\n                experiment_id=self._experiment_id\n            )\n        )\n        res = self._session.post(url, json=content)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nkill the workflow. See also -------- :func:`tmserver.api.workflow.kill_workflow` :class:`tmlib.workflow.workflow.Workflow`", "response": "def kill_workflow(self):\n        '''Kills the workflow.\n\n        See also\n        --------\n        :func:`tmserver.api.workflow.kill_workflow`\n        :class:`tmlib.workflow.workflow.Workflow`\n        '''\n        logger.info('kill workflow of experiment \"%s\"', self.experiment_name)\n        content = dict()\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/workflow/kill'.format(\n                experiment_id=self._experiment_id\n            )\n        )\n        res = self._session.post(url)\n        res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_workflow_status(self, depth=2):\n        '''Gets the workflow status.\n\n        Parameters\n        ----------\n        depth: int, optional\n            query depth - in which detail status of subtasks will be queried\n\n        Returns\n        -------\n        dict\n            status information about the workflow\n\n        See also\n        --------\n        :func:`tmserver.api.workflow.get_workflow_status`\n        :func:`tmlib.workflow.utils.get_task_status`\n        :class:`tmlib.models.submission.Task`\n        '''\n        logger.info(\n            'get status for workflow of experiment \"%s\"', self.experiment_name\n        )\n        params = {'depth': depth}\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/workflow/status'.format(\n                experiment_id=self._experiment_id\n            ),\n            params\n        )\n        res = self._session.get(url)\n        res.raise_for_status()\n        return res.json()['data']", "response": "Gets the workflow status."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload_jterator_project(self, pipeline, handles):\n        '''Uploads a *jterator* project.\n\n        Parameters\n        ----------\n        pipeline: dict\n            description of the jterator pipeline\n        handles: dict, optional\n            description of each module in the jterator pipeline\n\n        See also\n        --------\n        :func:`tmserver.api.workflow.update_jterator_project`\n        :class:`tmlib.workflow.jterator.description.PipelineDescription`\n        :class:`tmlib.workflow.jterator.description.HandleDescriptions`\n        '''\n        logger.info(\n            'upload jterator project for experiment \"%s\"', self.experiment_name\n        )\n        content = {\n            'pipeline': pipeline,\n            'handles': handles\n        }\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/workflow/jtproject'.format(\n                experiment_id=self._experiment_id\n            )\n        )\n        res = self._session.put(url, json=content)\n        res.raise_for_status()", "response": "Uploads a jterator project."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload the jterator project and stores it in YAML format.", "response": "def download_jterator_project_files(self, directory):\n        '''Downloads the *jterator* project and stores it\n        on disk in YAML format. The pipeline description will be stored\n        in a ``pipeline.yaml`` file in `directory` and each handle description\n        will be stored in a ``*handles.yaml`` file and placed into a ``handles``\n        subfolder of `directory`.\n\n        Parameters\n        ----------\n        directory: str\n            path to the root folder where files should be stored\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.download_jterator_project`\n        '''\n        descriptions = self.download_jterator_project()\n        directory = os.path.expanduser(os.path.expandvars(directory))\n\n        logger.info(\n            'store jterator project description in directory: %s', directory\n        )\n        if not os.path.exists(directory):\n            raise OSError('Directory does not exit: {0}'.format(directory))\n\n        pipeline_filename = os.path.join(directory, 'pipeline.yaml')\n        logger.debug('write pipeline description to file: %s', pipeline_filename)\n        with open(pipeline_filename, 'w') as f:\n            content = yaml.safe_dump(\n                descriptions['pipeline'],\n                explicit_start=True, default_flow_style=False\n            )\n            f.write(content)\n\n        handles_subdirectory = os.path.join(directory, 'handles')\n        if not os.path.exists(handles_subdirectory):\n            logger.debug('create \"handles\" directory')\n            os.mkdir(handles_subdirectory)\n        for name, description in descriptions['handles'].items():\n            handles_filename = os.path.join(\n                handles_subdirectory, '{name}.handles.yaml'.format(name=name)\n            )\n            logger.debug(\n                'write handles description to file: %s', handles_filename\n            )\n            with open(handles_filename, 'w') as f:\n                content = yaml.safe_dump(\n                    description,\n                    explicit_start=True, default_flow_style=False\n                )\n                f.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading the jterator project description from files on disk in directory and optionally handles. yaml files in a handles subfolder of the directory.", "response": "def upload_jterator_project_files(self, directory):\n        '''Uploads the *jterator* project description from files on disk in\n        YAML format. It expects a ``pipeline.yaml`` file in `directory` and\n        optionally ``*handles.yaml`` files in a ``handles`` subfolder of\n        `directory`.\n\n        Parameters\n        ----------\n        directory: str\n            path to the root folder where files are located\n\n        See also\n        --------\n        :meth:`tmclient.api.TmClient.upload_jterator_project`\n        '''\n        logger.info(\n            'load jterator project description from directory: %s', directory\n        )\n        if not os.path.exists(directory):\n            raise OSError('Directory does not exit: {0}'.format(directory))\n\n        pipeline_filename = os.path.join(directory, 'pipeline.yaml')\n        if not os.path.exists(pipeline_filename):\n            raise OSError(\n                'Pipeline description file does not exist: {0}'.format(\n                    pipeline_filename\n                )\n            )\n        logger.debug('load pipeline filename: %s', pipeline_filename)\n        with open(pipeline_filename) as f:\n            pipeline_description = yaml.safe_load(f.read())\n\n        handles_subdirectory = os.path.join(directory, 'handles')\n        if not os.path.exists(handles_subdirectory):\n            logger.warn(\n                'handles subdirectory does not exist: %s', handles_subdirectory\n            )\n        handles_filename_pattern = os.path.join(\n            handles_subdirectory, '*.handles.yaml'\n        )\n        handles_descriptions = dict()\n        for handles_filename in glob.glob(handles_filename_pattern):\n            name = os.path.splitext(os.path.splitext(\n                os.path.basename(handles_filename)\n            )[0])[0]\n            logger.debug('load handles file: %s', handles_filename)\n            with open(handles_filename) as f:\n                handles_descriptions[name] = yaml.safe_load(f.read())\n\n        self.upload_jterator_project(\n            pipeline_description, handles_descriptions\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the status of tools jobs.", "response": "def get_tools_status(self, tool_name=None):\n        '''Gets the status of tool jobs.\n\n        Parameters\n        ----------\n        tool_name: str, optional\n            filter jobs by tool name\n\n        Returns\n        -------\n        dict\n            status information about tool jobs\n\n        See also\n        --------\n        :func:`tmserver.api.tools.get_tools_status`\n        :func:`tmlib.workflow.utils.get_task_status`\n        :class:`tmlib.models.submission.Task`\n        '''\n        logger.info(\n            'get status for tools of experiment \"%s\"', self.experiment_name\n        )\n        params = dict()\n        if tool_name is not None:\n            params['tool_name'] = tool_name\n        url = self._build_api_url(\n            '/experiments/{experiment_id}/tools/jobs'.format(\n                experiment_id=self._experiment_id\n            ),\n            params\n        )\n        res = self._session.get(url)\n        res.raise_for_status()\n        return res.json()['data']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_csv(path, out):\n    def is_berlin_cable(filename):\n        return 'BERLIN' in filename\n    writer = UnicodeWriter(open(out, 'wb'), delimiter=';')\n    writer.writerow(('Reference ID', 'Created', 'Origin', 'Subject'))\n    for cable in cables_from_source(path, predicate=is_berlin_cable):\n        writer.writerow((cable.reference_id, cable.created, cable.origin, titlefy(cable.subject)))", "response": "Walks through the path and generates the CSV file out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the DAAP server. Start by advertising the server via Bonjour. Then serve requests until CTRL + C is received.", "response": "def serve_forever(self):\n        \"\"\"\n        Run the DAAP server. Start by advertising the server via Bonjour. Then\n        serve requests until CTRL + C is received.\n        \"\"\"\n\n        # Verify that the provider has a server.\n        if self.provider.server is None:\n            raise ValueError(\n                \"Cannot start server because the provider has no server to \"\n                \"publish.\")\n\n        # Verify that the provider has a database to advertise.\n        if not self.provider.server.databases:\n            raise ValueError(\n                \"Cannot start server because the provider has no databases to \"\n                \"publish.\")\n\n        # Create WSGI server and run it.\n        self.server = WSGIServer((self.ip, self.port), application=self.app)\n\n        # Register Bonjour.\n        if self.bonjour:\n            self.bonjour.publish(self)\n\n        # Start server until finished\n        try:\n            self.server.serve_forever()\n        except KeyboardInterrupt:\n            pass\n        finally:\n            # Unregister Bonjour\n            if self.bonjour:\n                self.bonjour.unpublish(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a base declarative class", "response": "def model_base(bind_label=None, info=None):\n    \"\"\"Create a base declarative class\n    \"\"\"\n    Model = type('Model', (BaseModel,), {'__odm_abstract__': True})\n    info = {}\n    Model.__table_args__ = table_args(info=info)\n    if bind_label:\n        info['bind_label'] = bind_label\n    return Model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying models from one module to another.", "response": "def copy_models(module_from, module_to):\n    \"\"\"Copy models from one module to another\n    :param module_from:\n    :param module_to:\n    :return:\n    \"\"\"\n    module_from = get_module(module_from)\n    module_to = get_module(module_to)\n    models = get_models(module_from)\n    if models:\n        models = models.copy()\n        models.update(((t.key, t) for t in module_tables(module_from)))\n        module_to.__odm_models__ = models\n        return models"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(self, model, **attr):\n        metadata = self.metadata\n        if not isinstance(model, Table):\n            model_name = self._create_model(model, **attr)\n            if not model_name:\n                return\n            model, name = model_name\n            table = model.__table__\n            self._declarative_register[name] = model\n\n            if name in self._bases:\n                for model in self._bases.pop(name):\n                    self.register(model)\n        else:\n            table = model.tometadata(metadata)\n            model = table\n\n        # Register engine\n        engine = None\n        label = table.info.get('bind_label')\n        keys = ('%s.%s' % (label, table.key),\n                label, None) if label else (None,)\n        #\n        # Find the engine for this table\n        for key in keys:\n            engine = self.get_engine(key)\n            if engine:\n                break\n        assert engine\n        self.binds[table] = engine\n\n        return model", "response": "Register a model or a table with this mapper."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new table with the same metadata and info", "response": "def create_table(self, name, *columns, **kwargs):\n        \"\"\"Create a new table with the same metadata and info\n        \"\"\"\n        targs = table_args(**kwargs)\n        args, kwargs = targs[:-1], targs[-1]\n        return Table(name, self.metadata, *columns, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating databases for each engine and return a new Mapper.", "response": "def database_create(self, database, **params):\n        \"\"\"Create databases for each engine and return a new :class:`.Mapper`.\n        \"\"\"\n        binds = {}\n        dbname = database\n        for key, engine in self.keys_engines():\n            if hasattr(database, '__call__'):\n                dbname = database(engine)\n            assert dbname, \"Cannot create a database, no db name given\"\n            key = key if key else 'default'\n            binds[key] = self._database_create(engine, dbname)\n        return self.copy(binds)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef database_exist(self):\n        binds = {}\n        for key, engine in self.keys_engines():\n            key = key if key else 'default'\n            binds[key] = self._database_exist(engine)\n        return binds", "response": "Create databases for each engine and return a new : class :. Mapper."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary mapping engines with databases", "response": "def database_all(self):\n        \"\"\"Return a dictionary mapping engines with databases\n        \"\"\"\n        all = {}\n        for engine in self.engines():\n            all[engine] = self._database_all(engine)\n        return all"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprovide a transactional scope around a series of operations. By default, ``expire_on_commit`` is set to False so that instances can be used outside the session.", "response": "def begin(self, close=True, expire_on_commit=False, session=None,\n              commit=False, **options):\n        \"\"\"Provide a transactional scope around a series of operations.\n\n        By default, ``expire_on_commit`` is set to False so that instances\n        can be used outside the session.\n        \"\"\"\n        if not session:\n            commit = True\n            session = self.session(expire_on_commit=expire_on_commit,\n                                   **options)\n        else:\n            close = False\n        try:\n            yield session\n            if commit:\n                session.commit()\n        except Exception:\n            session.rollback()\n            raise\n        finally:\n            if close:\n                session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new database and return a new url representing a connection to the new database", "response": "def _database_create(self, engine, database):\n        \"\"\"Create a new database and return a new url representing\n        a connection to the new database\n        \"\"\"\n        logger.info('Creating database \"%s\" in \"%s\"', database, engine)\n        database_operation(engine, 'create', database)\n        url = copy(engine.url)\n        url.database = database\n        return str(url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a washing regex list.", "response": "def get_washing_regex():\n    \"\"\"Return a washing regex list.\"\"\"\n    global _washing_regex\n    if len(_washing_regex):\n        return _washing_regex\n\n    washing_regex = [\n        # Replace non and anti with non- and anti-. This allows a better\n        # detection of keywords such as nonabelian.\n        (re.compile(r\"(\\snon)[- ](\\w+)\"), r\"\\1\\2\"),\n        (re.compile(r\"(\\santi)[- ](\\w+)\"), r\"\\1\\2\"),\n        # Remove all leading numbers (e.g. 2-pion -> pion).\n        (re.compile(r\"\\s\\d-\"), \" \"),\n        # Remove multiple spaces.\n        (re.compile(r\" +\"), \" \"),\n    ]\n\n    # Remove spaces in particle names.\n    # Particles with -/+/*\n    washing_regex += [\n        (re.compile(r\"(\\W%s) ([-+*])\" % name), r\"\\1\\2\")\n        for name in (\"c\", \"muon\", \"s\", \"B\", \"D\", \"K\", \"Lambda\",\n                     \"Mu\", \"Omega\", \"Pi\", \"Sigma\", \"Tau\", \"W\", \"Xi\")\n    ]\n\n    # Particles followed by numbers\n    washing_regex += [\n        (re.compile(r\"(\\W%s) ([0-9]\\W)\" % name), r\"\\1\\2\")\n        for name in (\"a\", \"b\", \"c\", \"f\", \"h\", \"s\", \"B\", \"D\", \"H\",\n                     \"K\", \"L\", \"Phi\", \"Pi\", \"Psi\", \"Rho\", \"Stor\", \"UA\",\n                     \"Xi\", \"Z\")\n    ]\n    washing_regex += [(re.compile(r\"(\\W%s) ?\\( ?([0-9]+) ?\\)[A-Z]?\" % name),\n                       r\"\\1(\\2)\")\n                      for name in (\"CP\", \"E\", \"G\", \"O\", \"S\", \"SL\", \"SO\",\n                                   \"Spin\", \"SU\", \"U\", \"W\", \"Z\")]\n\n    # Particles with '\n    washing_regex += [(re.compile(r\"(\\W%s) ('\\W)\" % name), r\"\\1\\2\")\n                      for name in (\"Eta\", \"W\", \"Z\")]\n\n    # Particles with (N)\n    washing_regex += [(re.compile(r\"(\\W%s) ?\\( ?N ?\\)[A-Z]?\" % name), r\"\\1(N)\")\n                      for name in (\"CP\", \"GL\", \"O\", \"SL\", \"SO\", \"Sp\", \"Spin\",\n                                   \"SU\", \"U\", \"W\", \"Z\")]\n\n    # All names followed by ([0-9]{3,4})\n    washing_regex.append((re.compile(r\"([A-Za-z]) (\\([0-9]{3,4}\\)\\+?)\\s\"),\n                          r\"\\1\\2 \"))\n\n    # Some weird names followed by ([0-9]{3,4})\n    washing_regex += [(re.compile(r\"\\(%s\\) (\\([0-9]{3,4}\\))\" % name),\n                       r\"\\1\\2 \")\n                      for name in (\"a0\", \"Ds1\", \"Ds2\", \"K\\*\")]\n\n    washing_regex += [\n        # Remove all lonel operators (usually these are errors\n        # introduced by pdftotext.)\n        (re.compile(r\" [+*] \"), r\" \"),\n        # Remove multiple spaces.\n        (re.compile(r\" +\"), \" \"),\n        # Remove multiple line breaks.\n        (re.compile(r\"\\n+\"), r\"\\n\"),\n    ]\n    _washing_regex = washing_regex\n    return _washing_regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize_fulltext(fulltext):\n    # We recognize keywords by the spaces. We need these to match the\n    # first and last words of the document.\n    fulltext = \" \" + fulltext + \" \"\n\n    # Replace some weird unicode characters.\n    fulltext = replace_undesirable_characters(fulltext)\n    # Replace the greek characters by their name.\n    fulltext = _replace_greek_characters(fulltext)\n\n    washing_regex = get_washing_regex()\n\n    # Apply the regular expressions to the fulltext.\n    for regex, replacement in washing_regex:\n        fulltext = regex.sub(replacement, fulltext)\n\n    return fulltext", "response": "Return a cleaned version of the output provided by pdftotext."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cut_references(text_lines):\n    ref_sect_start = find_reference_section(text_lines)\n    if ref_sect_start is not None:\n        start = ref_sect_start[\"start_line\"]\n        end = find_end_of_reference_section(text_lines, start,\n                                            ref_sect_start[\"marker\"],\n                                            ref_sect_start[\"marker_pattern\"])\n        del text_lines[start:end + 1]\n    else:\n        current_app.logger.warning(\"Found no references to remove.\")\n        return text_lines\n\n    return text_lines", "response": "Return the text lines with the references cut."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _replace_greek_characters(line):\n    for greek_char, replacement in iteritems(_GREEK_REPLACEMENTS):\n        try:\n            line = line.replace(greek_char, replacement)\n        except UnicodeDecodeError:\n            current_app.logger.exception(\"Unicode decoding error.\")\n            return \"\"\n    return line", "response": "Replace greek characters in a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits null model to the current instance of the class.", "response": "def fitNull(self, verbose=False, cache=False, out_dir='./cache', fname=None, rewrite=False, seed=None, n_times=10, factr=1e3, init_method=None):\n        \"\"\"\n        Fit null model\n        \"\"\"\n        if seed is not None:    sp.random.seed(seed)\n\n        read_from_file = False\n        if cache:\n            assert fname is not None, 'MultiTraitSetTest:: specify fname'\n            if not os.path.exists(out_dir):\n                os.makedirs(out_dir)\n            out_file = os.path.join(out_dir,fname)\n            read_from_file = os.path.exists(out_file) and not rewrite\n\n        RV = {}\n        if read_from_file:\n            f = h5py.File(out_file,'r')\n            for key in list(f.keys()):\n                RV[key] = f[key][:]\n            f.close()\n            self.setNull(RV)\n        else:\n            start = TIME.time()\n            if self.bgRE:\n                self._gpNull = GP2KronSum(Y=self.Y, F=None, A=None, Cg=self.Cg, Cn=self.Cn, R=None, S_R=self.S_R, U_R=self.U_R)\n            else:\n                self._gpNull = GP2KronSumLR(self.Y, self.Cn, G=sp.ones((self.N,1)), F=self.F, A=self.A)\n                # freezes Cg to 0\n                n_params = self._gpNull.covar.Cr.getNumberParams()\n                self._gpNull.covar.Cr.setParams(1e-9 * sp.ones(n_params))\n                self._gpNull.covar.act_Cr = False\n            for i in range(n_times):\n                params0 = self._initParams(init_method=init_method)\n                self._gpNull.setParams(params0)\n                conv, info = self._gpNull.optimize(verbose=verbose, factr=factr)\n                if conv: break\n            if not conv:    warnings.warn(\"not converged\")\n            LMLgrad = (self._gpNull.LML_grad()['covar']**2).mean()\n            LML = self._gpNull.LML()\n            if self._gpNull.mean.n_terms==1:\n                RV['B'] = self._gpNull.mean.B[0]\n            elif self._gpNull.mean.n_terms>1:\n                warning.warn('generalize to more than 1 fixed effect term')\n            if self.bgRE:\n                RV['params0_g'] = self.Cg.getParams()\n            else:\n                RV['params0_g'] = sp.zeros_like(self.Cn.getParams())\n            RV['params0_n'] = self.Cn.getParams()\n            if self.bgRE:\n                RV['Cg'] = self.Cg.K()\n            else:\n                RV['Cg'] = sp.zeros_like(self.Cn.K())\n            RV['Cn'] = self.Cn.K()\n            RV['conv'] = sp.array([conv])\n            RV['time'] = sp.array([TIME.time()-start])\n            RV['NLL0'] = sp.array([LML])\n            RV['LMLgrad'] = sp.array([LMLgrad])\n            RV['nit'] = sp.array([info['nit']])\n            RV['funcalls'] = sp.array([info['funcalls']])\n            self.null = RV\n            if cache:\n                f = h5py.File(out_file,'w')\n                smartDumpDictHdf5(RV,f)\n                f.close()\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef optimize(self, G, params0=None, n_times=10, verbose=False, vmax=5, perturb=1e-3, factr=1e7):\n        # set params0 from null if params0 is None\n        if params0 is None:\n            if self.null is None:\n                if verbose:     print(\".. fitting null model\")\n                self.fitNull()\n            if self.bgRE:\n                params0 = sp.concatenate([self.null['params0_g'], self.null['params0_n']])\n            else:\n                params0 = self.null['params0_n']\n            params_was_None = True\n        else:\n            params_was_None = False\n        G *= sp.sqrt(self.N/(G**2).sum())\n        self._gp.covar.G = G\n        start = TIME.time()\n        for i in range(n_times):\n            if params_was_None:\n                n_params = self.Cr.getNumberParams()\n                _params0 = {'covar': sp.concatenate([1e-3*sp.randn(n_params), params0])}\n            else:\n                _params0 = {'covar': params0}\n            self._gp.setParams(_params0)\n            conv, info = self._gp.optimize(factr=factr, verbose=verbose)\n            conv *= self.Cr.K().diagonal().max()<vmax\n            conv *= self.getLMLgrad() < 0.1\n            if conv or not params_was_None: break\n        self.infoOpt = info\n        if not conv:\n            warnings.warn(\"not converged\")\n        # return value\n        RV = {}\n        if self.P>1:\n            RV['Cr']  = self.Cr.K()\n            if self.bgRE: RV['Cg']  = self.Cg.K()\n            RV['Cn']  = self.Cn.K()\n        RV['time']  = sp.array([TIME.time()-start])\n        RV['params0'] = _params0\n        RV['nit'] = sp.array([info['nit']])\n        RV['funcalls'] = sp.array([info['funcalls']])\n        RV['var']    = self.getVariances()\n        RV['conv']  = sp.array([conv])\n        RV['NLLAlt']  = sp.array([self.getNLLAlt()])\n        RV['LLR']    = sp.array([self.getLLR()])\n        RV['LMLgrad'] = sp.array([self.getLMLgrad()])\n        return RV", "response": "Optimize the model considering G"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getVariances(self):\n        var = []\n        var.append(self.Cr.K().diagonal())\n        if self.bgRE:\n            var.append(self.Cg.K().diagonal())\n        var.append(self.Cn.K().diagonal())\n        var = sp.array(var)\n        return var", "response": "get variances of the current instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fitNullTraitByTrait(self, verbose=False, cache=False, out_dir='./cache', fname=None, rewrite=False):\n        read_from_file = False\n        if cache:\n            assert fname is not None, 'MultiTraitSetTest:: specify fname'\n            if not os.path.exists(out_dir): os.makedirs(out_dir)\n            out_file = os.path.join(out_dir,fname)\n            read_from_file = os.path.exists(out_file) and not rewrite\n\n        RV = {}\n        if read_from_file:\n            f = h5py.File(out_file,'r')\n            for p in range(self.P):\n                trait_id = self.traitID[p]\n                g = f[trait_id]\n                RV[trait_id] = {}\n                for key in list(g.keys()):\n                    RV[trait_id][key] = g[key][:]\n            f.close()\n            self.nullST=RV\n        else:\n            \"\"\" create stSet and fit null column by column returns all info \"\"\"\n            if self.stSet is None:\n                y = sp.zeros((self.N,1))\n                self.stSet = MTSet(Y=y, S_R=self.S_R, U_R=self.U_R, F=self.F)\n            RV = {}\n            for p in range(self.P):\n                trait_id = self.traitID[p]\n                self.stSet.Y = self.Y[:,p:p+1]\n                RV[trait_id] = self.stSet.fitNull()\n            self.nullST = RV\n            if cache:\n                f = h5py.File(out_file,'w')\n                smartDumpDictHdf5(RV,f)\n                f.close()\n        return RV", "response": "fit null trait by trait returns all info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noptimizing trait by trait", "response": "def optimizeTraitByTrait(self, G, verbose=False, n_times=10, factr=1e3):\n        \"\"\" Optimize trait by trait \"\"\"\n        assert self.nullST is not None, 'fit null model beforehand'\n        RV = {}\n        self.infoOptST = {}\n        for p in range(self.P):\n            trait_id = self.traitID[p]\n            self.stSet.Y = self.Y[:, p:p+1]\n            self.stSet.setNull(self.nullST[trait_id])\n            RV[trait_id] = self.stSet.optimize(G, n_times=n_times, factr=factr, verbose=verbose)\n            self.infoOptST[trait_id] = self.stSet.getInfoOpt()\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialise the object into a base - level dictionary.", "response": "def serialise(self, obj):\n        \"\"\"\n        Take an object from the project or the runner and serialise it into a\n        dictionary.\n\n        Parameters\n        ----------\n        obj : object\n            An object to serialise.\n\n        Returns\n        -------\n        object\n            A serialised version of the input object.\n        \"\"\"\n\n        if isinstance(obj, (list, VariableCollection, StepCollection)):\n            return [self.serialise(element) for element in obj]\n        elif isinstance(obj, dict):\n            return {k: self.serialise(v) for k, v in obj.items()}\n        elif isinstance(obj, str):\n            return obj\n        elif isinstance(obj, (Event, Task, Variable, Step)):\n            return self.serialise(obj._asdict())\n        elif obj is None:\n            return None\n        else:\n            raise TypeError(type(obj))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new document on the ProvStore.", "response": "def create(self, prov_document, prov_format=None, refresh=False, **props):\n        \"\"\"\n        Create a document on ProvStore.\n\n        :param prov_document: The document to be stored\n        :param prov_format: The format of the document provided\n        :param bool refresh: Whether or not to load back the document after saving\n        :param dict props: Properties for this document [**name** (required), **public** = False]\n        :return: This document itself but with a reference to the newly stored document\n        :type prov_document: :py:class:`prov.model.ProvDocument` or :py:class:`str`\n        :type prov_format: :py:class:`str` or None\n        :rtype: :py:class:`provstore.document.Document`\n        :raises ImmutableDocumentException: If this instance already refers to another document\n        \"\"\"\n        if not self.abstract:\n            raise ImmutableDocumentException()\n\n        if isinstance(prov_document, ProvDocument):\n            self._prov = prov_document\n\n            prov_format = \"json\"\n            prov_document = prov_document.serialize()\n\n        self._id = self._api.post_document(prov_document, prov_format, **props)['id']\n\n        if refresh:\n            self.refresh()\n        else:\n            self._bundles = BundleManager(self._api, self)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nassociate this document with a ProvStore document.", "response": "def set(self, document_id):\n        \"\"\"\n        Associate this document with a ProvStore document without making any calls to the API.\n        :param int document_id: ID of the document on ProvStore\n        :return: self\n        \"\"\"\n        if not self.abstract:\n            raise ImmutableDocumentException()\n        self._id = document_id\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_prov(self, document_id=None):\n        if document_id:\n            if not self.abstract:\n                raise ImmutableDocumentException()\n            self._id = document_id\n\n        if self.abstract:\n            raise AbstractDocumentException()\n\n        self._prov = self._api.get_document_prov(self.id)\n        return self._prov", "response": "Load the provenance of this document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the metadata associated with the document.", "response": "def read_meta(self, document_id=None):\n        \"\"\"\n        Load metadata associated with the document\n\n        .. note::\n           This method is called automatically if needed when a property is first accessed. You will not normally have\n           to use this method manually.\n\n        :param document_id: (optional) set the document id if this is an :py:meth:`abstract` document\n        :return: self\n        \"\"\"\n        if document_id:\n            if not self.abstract:\n                raise ImmutableDocumentException()\n            self._id = document_id\n\n        if self.abstract:\n            raise AbstractDocumentException()\n\n        metadata = self._api.get_document_meta(self.id)\n\n        self._name = metadata['document_name']\n        self._public = metadata['public']\n        self._owner = metadata['owner']\n        self._created_at = parse_xsd_datetime(metadata['created_at'])\n        self._views = metadata['views_count']\n\n        self._bundles = BundleManager(self._api, self)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_bundle(self, prov_bundle, identifier):\n        if self.abstract:\n            raise AbstractDocumentException()\n\n        self._api.add_bundle(self.id, prov_bundle.serialize(), identifier)", "response": "Add a bundle to the document"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes the document and all of its bundles from ProvStore.", "response": "def delete(self):\n        \"\"\"\n        Remove the document and all of its bundles from ProvStore.\n\n        .. warning::\n           Cannot be undone.\n        \"\"\"\n        if self.abstract:\n            raise AbstractDocumentException()\n\n        self._api.delete_document(self.id)\n        self._id = None\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the name of the document as seen on ProvStore", "response": "def name(self):\n        \"\"\"\n        Name of document as seen on ProvStore\n        \"\"\"\n        if self._name:\n            return self._name\n        elif not self.abstract:\n            return self.read_meta()._name\n\n        raise EmptyDocumentException()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the public version of the document.", "response": "def public(self):\n        \"\"\"\n        Is this document visible to anyone?\n        \"\"\"\n        if self._public:\n            return self._public\n        elif not self.abstract:\n            return self.read_meta()._public\n\n        raise EmptyDocumentException()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the owner of the document.", "response": "def owner(self):\n        \"\"\"\n        Username of document creator\n        \"\"\"\n        if self._owner:\n            return self._owner\n        elif not self.abstract:\n            return self.read_meta()._owner\n\n        raise EmptyDocumentException()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef views(self):\n        if self._views:\n            return self._views\n        elif not self.abstract:\n            return self.read_meta()._views\n\n        raise EmptyDocumentException()", "response": "Returns the number of views this document has received on ProvStore"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the provenance for this document as a dictionary.", "response": "def prov(self):\n        \"\"\"\n        Provenance stored for this document as :py:class:`prov.model.ProvDocument`\n        \"\"\"\n        if self._prov:\n            return self._prov\n        elif not self.abstract:\n            return self.read_prov()\n\n        raise EmptyDocumentException()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an top level parse tree node into an AST mod.", "response": "def build_ast(self):\n        \"\"\"Convert an top level parse tree node into an AST mod.\"\"\"\n        n = self.root_node\n        if n.type == syms.file_input:\n            stmts = []\n            for i in range(len(n.children) - 1):\n                stmt = n.children[i]\n                if stmt.type == tokens.NEWLINE:\n                    continue\n                sub_stmts_count = self.number_of_statements(stmt)\n                if sub_stmts_count == 1:\n                    stmts.append(self.handle_stmt(stmt))\n                else:\n                    stmt = stmt.children[0]\n                    for j in range(sub_stmts_count):\n                        small_stmt = stmt.children[j * 2]\n                        stmts.append(self.handle_stmt(small_stmt))\n            return ast.Module(stmts)\n        elif n.type == syms.eval_input:\n            body = self.handle_testlist(n.children[0])\n            return ast.Expression(body)\n        elif n.type == syms.single_input:\n            first_child = n.children[0]\n            if first_child.type == tokens.NEWLINE:\n                # An empty line.\n                return ast.Interactive([])\n            else:\n                num_stmts = self.number_of_statements(first_child)\n                if num_stmts == 1:\n                    stmts = [self.handle_stmt(first_child)]\n                else:\n                    stmts = []\n                    for i in range(0, len(first_child.children), 2):\n                        stmt = first_child.children[i]\n                        if stmt.type == tokens.NEWLINE:\n                            break\n                        stmts.append(self.handle_stmt(stmt))\n                return ast.Interactive(stmts)\n        else:\n            raise AssertionError(\"unknown root node\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the number of AST statements contained in a node.", "response": "def number_of_statements(self, n):\n        \"\"\"Compute the number of AST statements contained in a node.\"\"\"\n        stmt_type = n.type\n        if stmt_type == syms.compound_stmt:\n            return 1\n        elif stmt_type == syms.stmt:\n            return self.number_of_statements(n.children[0])\n        elif stmt_type == syms.simple_stmt:\n            # Divide to remove semi-colons.\n            return len(n.children) // 2\n        else:\n            raise AssertionError(\"non-statement node\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef error(self, msg, n):\n        raise SyntaxError(msg, n.lineno, n.col_offset,\n                          filename=self.compile_info.filename)", "response": "Raise a SyntaxError with the lineno and col_offset set to n s."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the context of an expression to Store or Del if possible.", "response": "def set_context(self, expr, ctx):\n        \"\"\"Set the context of an expression to Store or Del if possible.\"\"\"\n        t = type(expr)\n        try:\n            # TODO: check if Starred is ok\n            if t in (ast.Attribute, ast.Name):\n                if type(ctx) == ast.Store():\n                    mis.check_forbidden_name(getattr (expr, expression_name_map[t]), expr)\n            elif t in (ast.Subscript, ast.Starred):\n                pass\n            elif t in (ast.List, ast.Tuple):\n                for elt in expr.elts:\n                    self.set_context(elt, ctx)\n            expr.ctx = ctx\n        except misc.ForbiddenNameAssignment as e:\n            self.error_ast(\"cannot assign to %s\" % (e.name,), e.node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        global CODE\n        url = self._get_auth_url()\n        webbrowser.open(url)\n        tornado.ioloop.IOLoop.current().start()\n        self.code = CODE", "response": "Starts the PrawOAuth2Server server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether a user can report abuse and renders appropriate response.", "response": "def report_comment_abuse(context, obj):\n    \"\"\"\n    Checks whether a user can report abuse (has not liked comment previously)\n    or has reported abuse previously and renders appropriate response.\n\n    If requesting user is part of the 'Moderators' group a vote equal to\n    ABUSE_CUTOFF setting will be made, thereby immediately marking the comment\n    as abusive.\n    \"\"\"\n    context.update({\n        'content_obj': obj,\n        'vote': -1,\n        'content_type': \"-\".join((obj._meta.app_label, obj._meta.module_name)),\n    })\n    return context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_keys(self, value, **kwargs):\n        self.debug_log(\"Sending keys\")\n\n        highlight = kwargs.get(\n            'highlight',\n            BROME_CONFIG['highlight']['highlight_when_element_receive_keys']  # noqa\n        )\n        \"\"\"\n        wait_until_clickable = kwargs.get(\n            'wait_until_clickable',\n            BROME_CONFIG['proxy_element']['wait_until_clickable']\n        )\n\n        if wait_until_clickable:\n            # TODO manage the raise exception better\n            self.pdriver.wait_until_clickable(\n                self.selector._selector,\n                raise_exception=True\n            )\n        \"\"\"\n\n        if highlight:\n            self.highlight(\n                style=BROME_CONFIG['highlight']['style_when_element_receive_keys']  # noqa\n            )\n\n        clear = kwargs.get('clear', False)\n\n        if clear:\n            self.clear()\n\n        if self.pdriver.bot_diary:\n            self.pdriver.bot_diary.add_auto_entry(\n                \"I typed '%s' in\" % value,\n                selector=self.selector._selector\n            )\n\n        try:\n            self._element.send_keys(value)\n        except exceptions.StaleElementReferenceException as e:\n            self.debug_log(\n                \"send_keys exception StaleElementReferenceException: %s\" % e\n            )\n            sleep(2)\n            self._element = self.pdriver.find(self.selector._selector)\n            self._element.send_keys(value)\n        except (\n                exceptions.InvalidElementStateException,\n                exceptions.WebDriverException\n                ) as e:\n            self.debug_log(\"send_keys exception: %s\" % e)\n            sleep(2)\n            self._element.send_keys(value)\n\n        return True", "response": "Send keys to the element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scp_file_remote_to_local(self, remote_path, local_path):\n\n        scp_command = [\n            'scp',\n            '-o',\n            'StrictHostKeyChecking=no',\n            '-i',\n            self.browser_config.get('ssh_key_path'),\n            '%s@%s:\"%s\"' %\n            (\n                self.browser_config.get('username'),\n                self.get_ip(),\n                remote_path\n            ),\n            local_path\n        ]\n        self.info_log(\n            \"executing command: %s\" %\n            ' '.join(scp_command)\n        )\n        p = Popen(scp_command)\n        p.wait()", "response": "Scp a remote file to local file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a command on the node and return the output and stderr", "response": "def execute_command(self, command):\n        \"\"\"Execute a command on the node\n\n        Args:\n            command (str)\n        \"\"\"\n\n        self.info_log(\"executing command: %s\" % command)\n\n        try:\n            ssh = paramiko.SSHClient()\n            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\n            k = paramiko.RSAKey.from_private_key_file(\n                self.browser_config.get('ssh_key_path')\n            )\n            ssh.connect(\n                self.private_ip,\n                username=self.browser_config.get('username'),\n                pkey=k\n            )\n\n            sleep_time = 0.1\n            stdout = []\n            stderr = []\n\n            ssh_transport = ssh.get_transport()\n            channel = ssh_transport.open_session()\n            channel.setblocking(0)\n            channel.exec_command(command)\n\n            while True:\n\n                while channel.recv_ready():\n                    stdout.append(channel.recv(1000))\n\n                while channel.recv_stderr_ready():\n                    stderr.append(channel.recv_stderr(1000))\n\n                if channel.exit_status_ready():\n                    break\n\n                sleep(sleep_time)\n\n            # ret = channel.recv_exit_status()\n            ssh_transport.close()\n\n            ssh.close()\n\n            return b''.join(stdout), b''.join(stderr)\n\n        except Exception as e:\n            msg = \"Execute_command exception: %s\" % str(e)\n            self.error_log(msg)\n            raise Exception(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the ec2 instance", "response": "def startup(self):\n        \"\"\"Startup the ec2 instance\n        \"\"\"\n        import boto.ec2\n\n        if not self.browser_config.get('launch'):\n            self.warning_log(\"Skipping launch\")\n            return True\n\n        self.info_log(\"Starting up\")\n\n        instance = None\n        try:\n\n            # KEY NAME\n            key_name = self.browser_config.get(\n                \"ssh_key_path\"\n            ).split(os.sep)[-1][:-4]\n            # SECURITY GROUP\n\n            if type(self.browser_config.get(\"security_group_ids\")) == str:\n                security_group_ids = [\n                    self.browser_config.get(\"security_group_ids\")\n                ]\n\n            elif type(self.browser_config.get(\"security_group_ids\")) == list:\n                security_group_ids = self.browser_config.get(\n                    \"security_group_ids\"\n                )\n\n            else:\n                msg = \"The config security_group_ids must be a string or a list of string\"  # noqa\n                self.critial_log(msg)\n                raise Exception(msg)\n\n            # LAUNCH INSTANCE\n            ec2 = boto.ec2.connect_to_region(self.browser_config.get(\"region\"))\n            reservation = ec2.run_instances(\n                    self.browser_config.get('amiid'),\n                    key_name=key_name,\n                    instance_type=self.browser_config.get(\"instance_type\"),\n                    security_group_ids=security_group_ids\n            )\n\n            wait_after_instance_launched = BROME_CONFIG['ec2']['wait_after_instance_launched']  # noqa\n            if wait_after_instance_launched:\n                self.info_log(\n                    \"Waiting after instance launched: %s seconds...\" %\n                    wait_after_instance_launched\n                )\n                sleep(wait_after_instance_launched)\n\n            else:\n                self.warning_log(\"Skipping waiting after instance launched\")\n\n            try:\n                instance = reservation.instances[0]\n\n            except Exception as e:\n                self.critical_log(\n                    'Instance reservation exception: %s' % str(e)\n                )\n                raise\n\n            self.instance_id = instance.id\n\n            self.info_log('Waiting for the instance to start...')\n\n            for i in range(60*5):\n                try:\n                    status = instance.update()\n                    if status == 'running':\n                        break\n\n                    else:\n                        sleep(1)\n                except Exception as e:\n                    self.error_log(\n                        'Exception while wait pending: %s' % str(e)\n                    )\n                    sleep(1)\n\n            # Wait until instance is running\n            status = instance.update()\n            if status == 'running':\n                instance.add_tag(\n                    \"Name\",\n                    \"%s-selenium-node-%s-%s\" %\n                    (\n                        self.browser_config.get('platform'),\n                        self.browser_config.get('browserName'),\n                        self.index\n                    )\n                )\n\n                self.info_log(\n                    \"New instance (%s) public ip (%s) private ip (%s)\" % (\n                        instance.id,\n                        instance.ip_address,\n                        instance.private_ip_address\n                    )\n                )\n            else:\n                msg = \"Instance status is %s and should be (running)\" % status\n                self.error_log(msg)\n                raise Exception(msg)\n\n            if BROME_CONFIG['ec2']['wait_until_system_and_instance_check_performed']:  # noqa\n                check_successful = False\n\n                for i in range(5*60):\n\n                    try:\n\n                        if not i % 60:\n                            if not type(status) == str:\n                                self.info_log(\n                                    'System_status: %s, instance_status: %s' %\n                                    (\n                                        status.system_status,\n                                        status.instance_status\n                                    )\n                                )\n\n                        status = ec2.get_all_instance_status(\n                            instance_ids=[instance.id]\n                        )[0]\n                        if status.system_status.status == u'ok' and status.instance_status.status == u'ok':  # noqa\n\n                            self.info_log('system_status: %s, instance_status: %s' % (status.system_status, status.instance_status))  # noqa\n                            check_successful = True\n                            break\n\n                    except Exception as e:\n                        self.error_log('Waiting instance ready exception: %s' % str(e))  # noqa\n                    sleep(1)\n\n                if not check_successful:\n                    msg = \"System and instance check were not successful\"\n                    self.warning_log(msg)\n                    raise Exception(msg)\n            else:\n                self.warning_log(\"Skipping wait until system and instance check performed\")  # noqa\n\n            self.info_log('Starting the selenium node server')\n\n            self.private_ip = instance.private_ip_address\n            self.public_dns = instance.public_dns_name\n            self.private_dns = instance.private_dns_name\n            self.public_ip = instance.ip_address\n\n            # LINUX\n            if self.browser_config.get('platform').lower() == \"linux\":\n                command = self.browser_config.get(\n                    \"selenium_command\"\n                ).format(**self.browser_config.config)\n                self.execute_command(command)\n\n            elif self.browser_config.get('platform').upper() == \"windows\":\n\n                # TODO this code is out of date\n                config = self.browser_config.config.copy()\n                config['instance_ip_address'] = instance.ip_address\n                command = self.browser_config(\n                    \"selenium_command\"\n                ).format(**config)\n                process = Popen(\n                    command.split(\" \"),\n                    stdout=devnull,\n                    stderr=devnull\n                )\n                self.runner.xvfb_pids.append(process.pid)\n\n            else:\n\n                msg = \"The provided platform name is not supported: select either (WINDOWS) or (LINUX)\"  # noqa\n                self.critical_log(msg)\n                raise Exception(msg)\n\n            return True\n\n        except Exception as e:\n            self.error_log('Startup exception: %s' % str(e))\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tear_down(self):\n        import boto.ec2\n\n        if not self.browser_config.get('terminate'):\n            self.warning_log(\"Skipping terminate\")\n            return\n\n        self.info_log(\"Tearing down...\")\n\n        ec2 = boto.ec2.connect_to_region(self.browser_config.get(\"region\"))\n        ec2.terminate_instances(instance_ids=[self.instance_id])", "response": "Tear down the instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the mitmproxy proxy", "response": "def start_proxy(self):\n        \"\"\"Start the mitmproxy\n        \"\"\"\n\n        self.runner.info_log(\"Starting proxy...\")\n\n        self.proxy_port = self.browser_config.get('proxy_port', 8080)\n\n        self.network_data_path = os.path.join(\n            self.runner.runner_dir,\n            'network_capture'\n        )\n        create_dir_if_doesnt_exist(self.network_data_path)\n\n        self.local_proxy_output_path = os.path.join(\n            self.network_data_path,\n            string_to_filename('%s.data' % self.testname)\n        )\n        self.local_proxy_log_path = os.path.join(\n            self.network_data_path,\n            string_to_filename('%s.mitm' % self.testname)\n        )\n\n        self.remote_proxy_output_path = string_to_filename(\n            '%s.data' % self.testname\n        )\n        self.remote_proxy_log_path = string_to_filename(\n            '%s.mitm' % self.testname\n        )\n\n        path_to_mitmproxy = self.browser_config.get(\n            \"mitmproxy:path\",\n            'mitmdump'\n        )\n\n        filter_ = self.browser_config.get(\"mitmproxy:filter\")\n        command = [\n            'DISPLAY=:0',\n            'nohup',\n            path_to_mitmproxy,\n            \"-p\",\n            \"%s\" % str(self.proxy_port),\n            \"-w\",\n            \"'%s'\" % self.remote_proxy_output_path\n        ]\n\n        if filter_:\n            command.append(filter_)\n\n        command.extend(['>', \"'%s'\" % self.remote_proxy_log_path, '2>&1'])\n        command.append('&')\n\n        self.execute_command(' '.join(command))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the proxy process.", "response": "def stop_proxy(self):\n        \"\"\"Stop the mitmproxy\n        \"\"\"\n\n        self.runner.info_log(\"Stopping proxy...\")\n\n        files = [\n            (self.remote_proxy_output_path, self.local_proxy_output_path),\n            (self.remote_proxy_log_path, self.local_proxy_log_path)\n        ]\n        for remote_file_path, local_file_path in files:\n            self.scp_file_remote_to_local(remote_file_path, local_file_path)\n\n        # kill the proxy\n        self.execute_command(\"fuser -k %s/tcp\" % str(self.proxy_port))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_caller(*caller_class, **params):\n    (frame, file, line, func, contextlist, index) = inspect.stack()[1]\n\n    try: class_name = frame.f_locals[\"self\"].__class__.__name__\n    except: class_name = None\n\n    if class_name:\n        name = class_name + '.'\n    elif caller_class != ():                                                                    # pragma: no cover\n        name = inspect.getmodule(caller_class[0]).__name__ + '.'\n    elif hasattr(inspect.getmodule(frame), '__name__'):\n        name = inspect.getmodule(frame).__name__ + '.'\n    else:                                                                                       # pragma: no cover\n        name = ''\n\n    if func == '__init__' and class_name:\n        name = class_name + '()'\n    elif name == '__main__.':                                                                   # pragma: no cover\n        name = func + '()'\n    else:\n        name += func + '()'\n\n    if 'persist_place' in params:\n        get_caller._Persist_Place = params['persist_place']\n\n    log = params.get('log', logging.getLogger())\n    if get_caller._Persist_Place or params.get('place') or log.isEnabledFor(logging.DEBUG):\n        name += ' [+{} {}]'.format(line, os.path.basename(file))\n    return name", "response": "Get the name of the caller."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef version_sort_key(version, digits=6):\n    m = re.match('^(\\w+[_-])(\\d.*)$', version)\n    if m:\n        prefix = m.group(1)\n        version = m.group(2)\n    else:\n        prefix = ''\n    key = []\n    for elem in version.split('.'):\n        try:\n            num = int(elem)\n            elem = ('%0'+str(digits)+'d') % num\n        except:\n            pass\n        key.append(elem)\n    return prefix + '.'.join(key)", "response": "Returns a canonicalized version string for the given version string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef version_cmp(ver_a, ver_b):\n    if ver_a is None and ver_b is None:\n        return 0\n    if ver_a is None:\n        return -1\n    elif ver_b is None:\n        return 1\n    try:\n        a = int(ver_a)\n        b = int(ver_b)\n        if a < b: return -1\n        elif a > b: return 1\n        else: return 0\n    except:\n        pass\n    m = re.match('^(\\w+[_-])(\\d.*)$', ver_a)\n    if m:\n        pref_a = m.group(1)\n        a = m.group(2)\n    else:\n        pref_a = ''\n        a = ver_a\n    m = re.match('^(\\w+[_-])(\\d.*)$', ver_b)\n    if m:\n        pref_b = m.group(1)\n        b = m.group(2)\n    else:\n        pref_b = ''\n        b = ver_b\n    if pref_a != pref_b:\n        if ver_a < ver_b: return -1\n        else: return 1\n    a = a.split('.')\n    b = b.split('.')\n\n    restrip = re.compile(r'[^\\d]+$')\n\n    for i in range(0, max(len(a), len(b))):\n        if i >= len(a): return -1\n        if i >= len(b): return 1\n        astr = restrip.sub('', a[i])\n        if not astr: astr = '0'\n        bstr = restrip.sub('', b[i])\n        if not bstr: bstr = '0'\n        try: aint = int(astr)\n        except: return -1                                                                       # pragma: no cover\n        try: bint = int(bstr)\n        except: return -1                                                                       # pragma: no cover\n        if aint < bint: return -1\n        elif aint > bint: return 1\n    return 0", "response": "Compares two version strings in the dotted - numeric - label format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a human readable representation of a time in a sequence of time units.", "response": "def deltafmt(delta, decimals = None):\n    \"\"\"\nReturns a human readable representation of a time with the format:\n\n    [[[Ih]Jm]K[.L]s\n\nFor example: 6h5m23s\n\nIf \"decimals\" is specified, the seconds will be output with that many decimal places.\nIf not, there will be two places for times less than 1 minute, one place for times\nless than 10 minutes, and zero places otherwise\n\"\"\"\n    try:\n        delta = float(delta)\n    except:\n        return '(bad delta: %s)' % (str(delta),)\n    if delta < 60:\n        if decimals is None:\n            decimals = 2\n        return (\"{0:.\"+str(decimals)+\"f}s\").format(delta)\n    mins = int(delta/60)\n    secs = delta - mins*60\n    if delta < 600:\n        if decimals is None:\n            decimals = 1\n        return (\"{0:d}m{1:.\"+str(decimals)+\"f}s\").format(mins, secs)\n    if decimals is None:\n        decimals = 0\n    hours = int(mins/60)\n    mins -= hours*60\n    if delta < 3600:\n        return \"{0:d}m{1:.0f}s\".format(mins, secs)\n    else:\n        return (\"{0:d}h{1:d}m{2:.\"+str(decimals)+\"f}s\").format(hours, mins, secs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef appname(path=None):\n    if path is None:\n        path = sys.argv[0]\n    name = os.path.basename(os.path.splitext(path)[0])\n    if name == 'mod_wsgi':\n        name = 'nvn_web'                                                                        # pragma: no cover\n    return name", "response": "Returns a useful application name based on the program argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn formatted text that lists the module - level and class - level hierarchy of the specified module.", "response": "def module_description(module__name__, module__doc__, module__file__):\n    \"\"\"\n    Return formatted text that lists the module-level and class-level\n    embedded documentation.  The function should be called exactly\n    as:\n\n        taskforce.utils.module_description(__name__, __doc__, __file__)\n\n    The most common use for this function is to produce the help\n    message for test code in a library module, which might look\n    something like:\n\n    if __name__ == \"__main__\":\n        import ns_utils, argparse\n\n        p = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter,\n                description=taskforce.utils.module_description(__name__, __doc__, __file__))\n\"\"\"\n    mod_name = os.path.splitext(os.path.basename(module__file__))[0]\n\n    mod_desc = (lambda x: x + '\\n' + '='*len(x) + '\\n')('Module '+mod_name) if mod_name else ''\n    for name, obj in inspect.getmembers(sys.modules[module__name__]):\n        if inspect.isclass(obj) and '__doc__' in dir(obj) and obj.__doc__:\n            mod_desc += '\\n' + (lambda x: x + '\\n' + '-'*len(x) + '\\n')('Class '+name)\n            mod_desc += obj.__doc__.lstrip()\n    return mod_desc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the signal from its name.", "response": "def signum(signame):\n    \"\"\"\n    Determine the signal from its name.  These forms are supported:\n\n        signal object (needed for python >= 3.5)\n        integer signal number\n        text signal number\n        SIGNAME (signal name in upper case)\n        signame (signal name in lower case)\n        NAME    (name without 'SIG' in upper case)\n        name    (name without 'SIG' in lower case)\n\n    In python 3.5 and above, \"signal\" is an object, so in addition\n    to mapping signal numbers and stringified numbers, this also\n    maps signal objects.\n\"\"\"\n    if signum.namemap is None:\n        #  First time through, map evrything likely to its signal number\n        #\n        signum.namemap = {}\n        for num, nam in sigmap.items():\n            signum.namemap[num] = num\n            signum.namemap[int(num)] = num\n            signum.namemap[str(num)] = num\n            signum.namemap[str(int(num))] = num\n            signum.namemap[nam.upper()] = num\n            signum.namemap[nam.lower()] = num\n            abbr = nam.replace('SIG', '', 1)\n            if abbr != nam:\n                signum.namemap[abbr.upper()] = num\n                signum.namemap[abbr.lower()] = num\n    return signum.namemap.get(signame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef statusfmt(status):\n    if status == 0:\n        msg = 'exited ok'\n    elif os.WIFSIGNALED(status):\n        msg = 'died on '+signame(os.WTERMSIG(status))\n    elif os.WIFEXITED(status) and os.WEXITSTATUS(status) > 0:\n        msg = 'exited '+str(os.WEXITSTATUS(status))\n    else:\n        msg = 'unknown exit code 0x%04x' % (status,)\n    if os.WCOREDUMP(status):\n        msg += ' (core dumped)'\n    return msg", "response": "Format an exit status as text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sys_maxfd():\n    maxfd = None\n    try:\n        maxfd = int(resource.getrlimit(resource.RLIMIT_NOFILE)[0])\n        if maxfd == resource.RLIM_INFINITY:                                                     # pragma: no cover\n            maxfd = None\n    except: pass\n    if maxfd is None:\n        maxfd = sys_maxfd.fallback_maxfd\n    return maxfd", "response": "Returns the maximum file descriptor limit."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef closeall(**params):\n    exclude_list = params.get('exclude')\n    beyond = params.get('beyond')\n    maxfd = params.get('maxfd')\n\n    if maxfd:\n        beyond = None\n    elif not beyond:\n        beyond = closeall.beyond_last_fd\n\n    excludes = {}\n    if exclude_list is not None:\n        try:\n            for s in exclude_list:\n                _pick_fd(s, excludes)\n        except:                                 # pragma: no cover\n            _pick_fd(exclude_list, excludes)\n\n    #  Find the largest excluded fd\n    exlist = list(excludes)\n    if len(exlist) > 0:\n        exlist.sort(reverse=True)\n        last_exc_fd = exlist[0]\n    else:                                       # pragma: no cover\n        last_exc_fd = None\n\n    #  Find the maximum available fd\n\n    if maxfd is True:\n        maxfd = sys_maxfd()\n\n    highest = -1\n    fd = 0\n    while True:\n        if maxfd is None:\n            if fd > highest + beyond:\n                break\n        elif fd > maxfd:\n            break\n        if not excludes.get(fd):\n            try:\n                os.close(fd)\n                highest = fd\n            except:\n                pass\n        fd += 1\n    if highest == -1:\n        return None\n    else:\n        return highest", "response": "This method closes all file descriptors in the current node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_cmd(args):\n    if args is None:\n        return ''\n    out = ''\n    if not isinstance(args, list):\n        args = [str(args)]\n    for arg in args:\n        if out != '':\n            out += ' '\n        out += pipes.quote(str(arg))\n    return out", "response": "Format the list of arguments suitable for display as a command line with\n    individual arguments quoted appropriately."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nidentify the filenos of a logging object.", "response": "def log_filenos(log, cloexec=True):\n    \"\"\"\n    Identify the filenos (unix file descriptors) of a logging object.\n    This is most commonly used to avoid closing the log file descriptors\n    after a fork so information can be logged before an exec().\n\n    To prevent conficts and potential hangs, the default is to set the\n    fcntl.FD_CLOEXEC close-on-exec flag for the file descriptors found.\n    The can be inhibited with the 'cloexec' param.\n\"\"\"\n    filenos = []\n    try:\n        for handler in log.handlers:\n            for name in dir(handler):\n                attr = getattr(handler, name, None)\n                if attr and hasattr(attr, 'fileno') and callable(attr.fileno):\n                    filenos.append(attr.fileno())\n        for fd in filenos:\n            fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n            fcntl.fcntl(fd, fcntl.F_SETFL, fl | fcntl.FD_CLOEXEC)\n    except:\n        pass\n    return filenos"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the message to the stream.", "response": "def print_email(message, app):\n    \"\"\"Print mail to stream.\n\n    Signal handler for email_dispatched signal. Prints by default the output\n    to the stream specified in the constructor of InvenioMail.\n\n    :param message: Message object.\n    :param app: Flask application object.\n    \"\"\"\n    invenio_mail = app.extensions['invenio-mail']\n    with invenio_mail._lock:\n        invenio_mail.stream.write(\n            '{0}\\n{1}\\n'.format(message.as_string(), '-' * 79))\n        invenio_mail.stream.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_app(self, app):\n        self.init_config(app)\n        if 'mail' not in app.extensions:\n            Mail(app)\n        if app.config.get('MAIL_SUPPRESS_SEND', False) or app.debug:\n            email_dispatched.connect(print_email)\n        app.extensions['invenio-mail'] = self", "response": "Initializes the Flask mail extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_config(app):\n        app.config.setdefault('MAIL_DEBUG', app.debug)\n        app.config.setdefault('MAIL_SUPPRESS_SEND', app.debug or app.testing)", "response": "Initialize configuration.\n\n        :param app: Flask application object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit a linear mixed forest of trees from the training set X and y.", "response": "def fit(self, X, y, recycle=True, **grow_params):\n\n        \"\"\"Build a linear mixed forest of trees from the training set (X, y).\n\n        Parameters\n        ----------\n        X : array-like of shape = [n_samples, n_features]\n            The training input samples.\n\n        y : array-like, shape = [n_samples] or [n_samples, 1]\n            The real valued targets\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n        if isinstance(self.kernel, str) and self.kernel == 'data':\n            self.kernel = SC.estimateKernel(X, maf=1.0/X.shape[0])\n        elif isinstance(self.kernel, str) and self.kernel == 'iid':\n            self.kernel = SP.identity(X.shape[0])\n        # Use dedicated part of data as background model\n        elif self.kernel.size == X.shape[1]:\n            tmp_ind = self.kernel\n            self.kernel = utils.estimateKernel(X[:, self.kernel],\n                                               maf=1.0/X.shape[0])\n            X = X[:, ~tmp_ind]\n        # Extract and reshape data\n        self.y = y.reshape(-1, 1)\n        self.X = X\n        self.n, self.m = self.X.shape\n        if self.delta is None:\n            self.BLUP = BLUP.BLUP()\n            if self.verbose > 1:\n                print('fitting BLUP')\n            self.BLUP.fit(XTrain=self.X, yTrain=self.y, KTrain=self.kernel,\n                          delta=self.delta)\n            if self.verbose > 1:\n                print('done fitting BLUP')\n            # Update delta if it used to be 'None'\n            self.delta = self.BLUP.delta\n        self.max_features = SP.maximum(SP.int_(self.ratio_features*self.m), 1)\n        self.var_used = SP.zeros(self.m)\n        self.log_importance = SP.zeros(self.m)\n        self.depth = 0\n\n        if self.verbose > 0:\n            print(('log(delta) fitted to ', SP.log(self.delta)))\n\n        # Initialize individual trees\n        if recycle and self.trees != []:\n            for tree in self.trees:\n                tree.cut_to_stump()\n        else:\n            n_trees = 0\n            self.trees = []\n            while n_trees < self.n_estimators:\n                if self.verbose > 1:\n                    print(('init. tree number ', n_trees))\n                subsample = self.tree_sample()\n                tree = MixedForestTree(self, subsample)\n                self.trees.append(tree)\n                n_trees += 1\n\n        # Fitting with optimal depth constraint\n        if self.fit_optimal_depth or self.update_delta:\n            self.opt_depth = 0\n            self.min_oob_err = self.get_oob_error(self.depth)\n            if self.verbose > 0:\n                print(('initial oob error is:', self.min_oob_err))\n            grow_further = True\n            curr_depth = self.depth\n            while grow_further:\n                # Updating ensemble increasing its depth by one\n                self.further(depth=self.depth+1)\n                if self.update_delta:\n                    self.delta = self.delta_update()\n                    if self.verbose > 0:\n                        print(('delta was fitted to', self.delta))\n                if self.verbose > 0:\n                    print(('depth is:', self.depth))\n                oob_err = self.get_oob_error(self.depth)\n                if self.verbose > 0:\n                    print(('oob error is:', oob_err))\n                if oob_err < self.min_oob_err:\n                    self.min_oob_err = oob_err\n                    self.opt_depth = self.depth\n                # Decide whether tree needs to be furthered\n                grow_further = (curr_depth < self.depth) and\\\n                    (self.depth < self.max_depth)\n                if self.build_to_opt_depth and (self.depth >= self.min_depth):\n                    grow_further = grow_further and\\\n                        (oob_err == self.min_oob_err)\n                    pass\n                curr_depth = self.depth\n        #####################################################\n        # Growing full tree one by one\n        else:\n            self.further(depth=self.max_depth)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict(self, X, k=None, depth=None):\n        if depth is None:\n            if self.opt_depth is not None:\n                depth = self.opt_depth\n                if self.verbose > 0:\n                    'using optimal depth to predict'\n            else:\n                depth = float('inf')\n        response = self._predict(X=X, depth=depth)\n        if k is not None:\n                mean = self.predict(X=self.X, depth=depth).reshape(-1, 1)\n                response += self.BLUP.predict(XTest=X, k=k,\n                                              mean=mean).reshape(-1)\n        return response", "response": "Predict response for X."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclears the data for the current tree entry.", "response": "def clear_data(self):\n        '''\n        Free memory\n        If many trees are grown this is an useful options since it is saving a\n        lot of memory '''\n        if self.forest.verbose > 1:\n            print('clearing up stuff')\n        self.S = None\n        self.Uy = None\n        self.U = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_X_slice(self, rmind):\n        '''get X with slicing'''\n        if self.forest.optimize_memory_use:\n            return self.forest.X[:, rmind][self.subsample]\n        else:\n            return self.X[:, rmind]", "response": "get X with slicing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract(filepath, taxonomy, output_mode, output_limit,\n            spires, match_mode, detect_author_keywords, extract_acronyms,\n            rebuild_cache, only_core_tags, no_cache):\n    \"\"\"Run keyword extraction on given PDF file for given taxonomy.\"\"\"\n    if not filepath or not taxonomy:\n        print(\"No PDF file or taxonomy given!\", file=sys.stderr)\n        sys.exit(0)\n\n    click.echo(\n        \">>> Going extract keywords from {0} as '{1}'...\".format(\n            filepath, output_mode\n        )\n    )\n    if not os.path.isfile(filepath):\n        click.echo(\n            \"Path to non-existing file\\n\",\n        )\n        sys.exit(1)\n\n    result = get_keywords_from_local_file(\n        local_file=filepath,\n        taxonomy_name=taxonomy,\n        output_mode=output_mode,\n        output_limit=output_limit,\n        spires=spires,\n        match_mode=match_mode,\n        no_cache=no_cache,\n        with_author_keywords=detect_author_keywords,\n        rebuild_cache=rebuild_cache,\n        only_core_tags=only_core_tags,\n        extract_acronyms=extract_acronyms\n    )\n    click.echo(result)", "response": "Run keyword extraction on given PDF file for given taxonomy."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build(self, name, **params):\n        log = self._getparam('log', self._discard, **params)\n\n        #  Find all the modules that no longer need watching\n        #\n        rebuild = False\n        wparams = params.copy()\n        wparams['commit'] = False\n        for path in list(self._watch.paths_open):\n            if path in self.modules:\n                continue\n            try:\n                self._watch.remove(path, **wparams)\n                rebuild = True\n            except Exception as e:\n                log.warning(\"Remove of watched module %r failed -- %s\", path, e)\n            log.debug(\"Removed watch for path %r\", path)\n\n        #  Find all the modules that are new and should be watched\n        #\n        for path in list(self.modules):\n            if path not in self._watch.paths_open:\n                try:\n                    self._watch.add(path, **wparams)\n                    rebuild = True\n                except Exception as e:\n                    log.error(\"watch failed on module %r -- %s\", path, e)\n                    continue\n        if rebuild:\n            self._watch.commit(**params)", "response": "Rebuild operations by removing open modules that are not currently being watched and adding new modules that are not currently being watched."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, **params):\n        log = self._getparam('log', self._discard, **params)\n\n        changes = {}\n        paths = self._watch.get(**params)\n\n        #  On each event, de-invert the tree to produce a\n        #  list of changes by command name.\n        #\n        for path in paths:\n            if path in self.modules:\n                for name in self.modules[path]:\n                    if name in changes:\n                        if path not in changes[name]:\n                            changes[name].append(path)\n                    else:\n                        changes[name] = [path]\n            else:\n                log.warning(\"Path %r had no matching watch entry\", path)\n        names = list(changes)\n        log.debug(\"Change was to %d name%s\", len(names), ses(len(names)))\n        names.sort()\n        resp = []\n        for name in names:\n            resp.append((name, self.names.get(name), changes[name]))\n        return resp", "response": "Get a list of commands that affected by a recent change."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a command to the list of commands being watched.", "response": "def add(self, name, command_path=None, **params):\n        \"\"\"\n        Add a command to the list of commands being watched.  \"name\"\n        should be a unique value that can be used as a dictionary\n        index.  It is typically, but not necessarily, the command\n        name.  The value is returned when the command or modules for\n        the command change and is used with the remove() method.\n\n        \"command_path\" is a path to the command executable, which\n        must be a python program.  If it includes no directory elements,\n        the \"path\" param or the system PATH will be used to find the\n        command's full path.\n\n        If \"command_path\" is not specified, \"name\" will be used.  An\n        exception is raised if the program file cannot be found.\n    \"\"\"\n        log = self._getparam('log', self._discard, **params)\n        module_path = self._getparam('module_path', sys.path, **params)\n\n        if module_path:\n            if type(module_path) is not list:\n                if module_path.find(os.pathsep) >= 0:\n                    module_path = module_path.split(os.pathsep)\n                else:\n                    module_path = [module_path]\n        else:\n            module_path = None\n        log.debug(\"module_path: %s\", str(module_path))\n\n        if not command_path:\n            command_path = name\n\n        command = None\n        if os.path.basename(command_path) == command_path:\n            #  When the command has no directory elements (ie, the base name is the same as the name)\n            #  search the system path.  Prefer a file that is both readable and executable but failing\n            #  that, accept one that is only readable.\n            #\n            path_list = self._getparam('path', os.environ['PATH'], **params).split(os.pathsep)\n            for dir in path_list:\n                path = os.path.join(dir, command_path)\n                try:\n                    if os.access(path, os.R_OK|os.X_OK):\n                        command = path\n                        break\n                except:\n                    continue\n            if command is None:\n                for dir in path_list:\n                    path = os.path.join(dir, command_path)\n                    try:\n                        if os.access(path, os.R_OK):\n                            command = path\n                            break\n                    except:\n                        continue\n        if command is None and os.access(command_path, os.R_OK):\n            command = command_path\n        if command is None:\n            log.error(\"failed to find %r\", command_path)\n            raise Exception(\"Could not locate command %r\" % (command_path,))\n        command = os.path.realpath(command)\n\n        #  It would be nice if ModuleFinder() would retain state between runs so\n        #  that it does not have to descend the tree for each command.  Unfortunately\n        #  all state appears to be held in its \"modules\" attribute which then accumulates\n        #  module references on each run_script() call.  That would wrongly attribute\n        #  modules to subsequent scripts so we have to re-instantiate the class for\n        #  each script.\n        #\n        finder = modulefinder.ModuleFinder(path=module_path)\n        finder.run_script(command)\n\n        #  If the name was used previously, remove all references\n        #\n        if name in self.names:\n            log.debug(\"Removing existing entries for %r\", name)\n            self.remove(name)\n        self.names[name] = command\n\n        #  Build an inverted list of files and associated command names, starting\n        #  with the command path itself.\n        #\n        rebuild = False\n        if command in self.modules:\n            if name in self.modules[command]:\n                log.debug(\"Name %r already present in %r\", name, command)\n            else:\n                log.debug(\"Command for %r added to %r\", name, command)\n                self.modules[command].append(name)\n        else:\n            log.debug(\"Command %r added for %r\", command, name)\n            self.modules[command] = [name]\n            rebuild = True\n        for modname, mod in list(finder.modules.items()):\n            path = mod.__file__\n            if not path:\n                log.debug(\"Skipping module %r -- no __file__ in module\", modname)\n                continue\n            path = os.path.realpath(path)\n            if path in self.modules:\n                if name in  self.modules[path]:\n                    log.debug(\"Name %r already present in %r\", name, command)\n                else:\n                    log.debug(\"%r added to %r\", name, path)\n                    self.modules[path].append(name)\n            else:\n                log.debug(\"%r added for %r\", path, name)\n                self.modules[path] = [name]\n                rebuild = True\n        if rebuild:\n            self._build(name, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, name, **params):\n        log = self._getparam('log', self._discard, **params)\n\n        if name not in self.names:\n            log.error(\"Attempt to remove %r which was never added\", name)\n            raise Exception(\"Command %r has never been added\" % (name,))\n        del self.names[name]\n        rebuild = False\n        for path in list(self.modules):\n            if name in self.modules[path]:\n                self.modules[path].remove(name)\n            if len(self.modules[path]) == 0:\n                del self.modules[path]\n                rebuild = True\n        if rebuild:\n            self._build(name, **params)", "response": "Removes a command from the watched list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns basic information about a user.", "response": "def user_info(access_token, request):\n  \"\"\" Return basic information about a user.\n\n  Limited to OAuth clients that have receieved authorization to the 'user_info'\n  scope.\n  \"\"\"\n  user = access_token.user\n  data = {\n      'username': user.username,\n      'first_name': user.first_name,\n      'last_name': user.last_name,\n      'email': user.email}\n\n  return HttpResponse(content=json.dumps(data),\n                      content_type='application/json',\n                      status=200)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the OR expression returning True if the left or right expression evaluate to True.", "response": "def evaluate(self, values):\n        \"\"\"Evaluate the \"OR\" expression\n\n        Check if the left \"or\" right expression\n        evaluate to True.\n        \"\"\"\n        return self.left.evaluate(values) or self.right.evaluate(values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding all matching data files in search_path", "response": "def find_datafile(name, search_path=('.'), codecs=get_codecs()):\n    \"\"\"\n    find all matching data files in search_path\n    search_path: path of directories to load from\n    codecs: allow to override from list of installed\n    returns array of tuples (codec_object, filename)\n    \"\"\"\n    rv = []\n\n    if isinstance(search_path, basestring):\n        search_path = (search_path,)\n\n    #print \"search path \", str(search_path)\n\n    ext = os.path.splitext(name)[1][1:]\n\n    cls = get_codec(ext)\n    if cls:\n        for each in search_path:\n            fq_filename = os.path.join(each, name)\n            if os.path.exists(fq_filename):\n                rv.append((cls, fq_filename))\n\n    for exts, obj in list(codecs.items()):\n        for ext in exts:\n            filename = \"%s.%s\" % (name, ext)\n            for each in search_path:\n                fq_filename = os.path.join(each, filename)\n                if os.path.exists(fq_filename):\n                    rv.append((obj, fq_filename))\n\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a datafile from a specific codec", "response": "def load_datafile(name, search_path=('.'), codecs=get_codecs(), **kwargs):\n    \"\"\"\n    find datafile and load them from codec\n    TODO only does the first one\n    kwargs:\n    default = if passed will return that on failure instead of throwing\n    \"\"\"\n    mod = find_datafile(name, search_path, codecs)\n    if not mod:\n        if 'default' in kwargs:\n            return kwargs['default']\n        raise IOError(\"file %s not found in search path %s\" %(name, str(search_path)))\n\n    (codec, datafile) = mod[0]\n    return codec().load(open(datafile))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the ANSI escape codes into the base base", "response": "def _set_ansi_escape_codes():\n    \"\"\"\n    Injects *ANSI* escape codes into :class:`AnsiEscapeCodes` class.\n    \"\"\"\n\n    AnsiEscapeCodes[\"reset\"] = \"\\033[0m\"\n\n    for foreground_code_name, foreground_code in FOREGROUND_ANSI_ESCAPE_CODES:\n        AnsiEscapeCodes[foreground_code_name] = \"\\033[{0}\".format(foreground_code)\n\n    for background_code_name, background_code in BACKGROUND_ANSI_ESCAPE_CODES:\n        AnsiEscapeCodes[background_code_name] = \"\\033[{0}\".format(background_code)\n\n    for background_code_name, background_code in BACKGROUND_ANSI_ESCAPE_CODES:\n        for foreground_code_name, foreground_code in FOREGROUND_ANSI_ESCAPE_CODES:\n            AnsiEscapeCodes[\"{0}{1}\".format(foreground_code_name,\n                                            \"{0}{1}\".format(background_code_name[0].upper(),\n                                                            background_code_name[1:]))] = \"\\033[{0}\\033[{1}\".format(\n                foreground_code, background_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\"\"\"\n        self.init_config(app)\n        app.cli.add_command(classifier_cmd)\n        app.extensions['invenio-classifier'] = self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a signal handler that can be used to create a new object.", "response": "def legion_create_handler(obj):\n    \"\"\"\n    Signal handlers can't be standard class methods because the signal\n    callback does not include the object reference (self).  To work\n    around this we use a closure the carry the object reference.\n\"\"\"\n    def _handler(sig, frame):\n        obj._sig_handler(sig, frame)\n\n    if '_sig_handler' not in dir(obj):                                                          # pragma: no cover\n        raise Excecption(\"Object instance has no _sig_handler method\")\n    return _handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats the context of a list of items into a single string.", "response": "def _fmt_context(arg_list, context):\n    \"\"\"\n    Iterate on performing a format operation until the formatting makes no\n    further changes.  This allows for the substitution of context values that\n    themselves have context values.  To prevent infinite loops due to direct\n    or indirect self-reference, the total number of attempts is limited.\n\n    On any error, the string formatted so far is returned.\n\n    For convenience, if passed a list, each element will be formatted and\n    the resulting list will be returned\n\"\"\"\n    if arg_list is None:\n        return arg_list\n    just_one = False\n    if not isinstance(arg_list, list):\n        arg_list = [arg_list]\n        just_one = True\n    ans = []\n    for arg in arg_list:\n        if arg is None:                                                                         # pragma: no cover\n            continue\n        for attempt in range(0, 10):\n            res = None\n            try:\n                m = _fmt_context_isvar.match(arg)\n                if m and m.group(1) in context and context[m.group(1)] is None:\n                    #  Handle case where the var is in the context will\n                    #  value None.  If this is left to formatting, it\n                    #  gets converted to the string value \"None\".\n                    #\n                    break\n                else:\n                    res = arg.format(**context)\n                    if res == arg:\n                        break\n                arg = res\n            except:\n                if res is None:\n                    #  If the formatting fails, revert to\n                    #  last successful value and stop.\n                    #\n                    res = arg\n                break\n        ans.append(res)\n    return (ans[0] if just_one else ans)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a command in a single process.", "response": "def _exec_process(cmd_list, base_context, instance=0, log=None):\n    \"\"\"\n    Process execution tool.\n\n    The forks and execs a process with args formatted according to a context.\n    This is implemented as a module function to make it available to\n    event_targets, legion and tasks.\n\n    The args are:\n\n    cmd_list    - The path and arg vector\n    context     - Task's context\n    instance    - An integer instance number used with multi-process tasks\n    log     - Logging object (default is nothing logged).\n\n    The context is used to format command args.  In addition, these values will\n    be used to change the process execution environment:\n\n    procname    - Changes the process name of the executed command (but not the path executed).\n    user        - Does a setuid for the process\n    group       - Does a setgid for the process\n    cwd     - Does a chdir before executing\n\n    The passed context is extended to include these specific runtime values which\n    are only available for cmd_list substitution.\n\n    context_prefix+'pid'        -  The process ID of the child process\n    context_prefix+'instance'   -  The instance number (0 if not provided)\n    context_prefix+'uid'        -  The numeric uid (based on 'user' if set, getuid() otherwise)\n    context_prefix+'gid'        -  The numeric gid (based on 'group' if set, getgid() otherwise)\n\"\"\"\n    if not log:                                                                                 # pragma: no cover\n        log = logging.getLogger(__name__)\n        log.addHandler(logging.NullHandler())\n\n    #  Get a copy of the context so changes here will not affect the\n    #  task's base context.\n    #\n    context = base_context.copy()\n\n    #  Make sure we have a normalized clone of the cmd_list\n    #\n    cmd_list = list(cmd_list)\n    name = context.get(context_prefix+'name', cmd_list[0])\n    log.debug(\"Starting %s instance %d\", name, instance)\n\n    procname = _fmt_context(context.get(context_prefix+'procname'), context)\n    user = _fmt_context(context.get(context_prefix+'user'), context)\n    group = _fmt_context(context.get(context_prefix+'group'), context)\n    cwd = _fmt_context(context.get(context_prefix+'cwd'), context)\n\n    #  Do the user setup early so we can throw an Exception on failure.\n    #  Identity errors are considered fatal as we do not want to run\n    #  a process at a higher priv if it was explicitly set to something\n    #  else.\n    #\n    proc_uid = os.geteuid()\n    proc_gid = os.getegid()\n    do_setuid = (proc_uid != os.getuid())\n    do_setgid = (proc_gid != os.getgid())\n    if user is not None:\n        pw = None\n        try:\n            uid = int(user)\n            try: pw = pwd.getpwuid(uid)\n            except: pass                                                                        # pragma: no cover\n        except: pass\n        if pw is None:\n            try:\n                pw = pwd.getpwnam(user)\n            except Exception as e:\n                raise TaskError(name, \"Bad user %r -- %s\" % (user, e))\n        if proc_uid != pw.pw_uid:\n            proc_uid = pw.pw_uid\n            do_setuid = True\n        if proc_gid != pw.pw_gid:\n            proc_gid = pw.pw_gid\n            do_setgid = True\n    if group is not None:\n        gr = None\n        try:\n            gid = int(group)\n            try: gr = grp.getgrgid(gid)\n            except: pass\n        except: pass\n        if gr is None:\n            try:\n                gr = grp.getgrnam(group)\n            except Exception as e:\n                raise TaskError(name, \"Bad group %r -- %s\" % (group, e))\n        if proc_uid is not None and proc_gid != gr.gr_gid:\n            log.info(\"gid for user %r (%d) overridden by group %r (%d)\", user, proc_gid, group, gr.gr_gid)\n            proc_gid = gr.gr_gid\n            do_setgid = True\n\n    if cwd is not None and not os.path.isdir(cwd):\n        raise TaskError(name, \"Directory for cwd setting '%s' does not exist\" % (cwd,))\n\n    #  Add in per-process context\n    #\n    context[context_prefix+'instance'] = instance\n    context[context_prefix+'started'] = time.time()\n    context[context_prefix+'uid'] = proc_uid\n    context[context_prefix+'gid'] = proc_gid\n\n    pid = os.fork()\n\n    #  Parent just returns pid\n    if pid > 0:\n        return pid\n\n    #  This section is processing the child.  Exceptions from this point must\n    #  never escape to outside handlers or we might create zombie init tasks.\n    #\n    try:\n        # Add the pid to the context now that we have it.\n        #\n        context[context_prefix+'pid'] = os.getpid()\n\n        #  Set up the requested process environment\n        #\n        if do_setgid:\n            try:\n                os.setgid(proc_gid)\n                log.debug(\"Setgid to %d succeeded in child '%s', instance %d\", proc_gid, name, instance)\n            except Exception as e:\n                log.error(\"Setgid to %d failed in child %r, instance %d -- %s\",\n                        proc_gid, name, instance, e, exc_info=log.isEnabledFor(logging.DEBUG))\n                os._exit(81)\n        if do_setuid:\n            try:\n                os.setuid(proc_uid)\n                log.debug(\"Setuid to %d succeeded in child '%s', instance %d\", proc_uid, name, instance)\n            except Exception as e:\n                log.error(\"Setuid to %d failed in child %r, instance %d -- %s\",\n                        proc_uid, name, instance, e, exc_info=log.isEnabledFor(logging.DEBUG))\n                os._exit(82)\n        if cwd is not None:\n            try:\n                os.chdir(cwd)\n                log.debug(\"Chdir to '%s' succeeded in child '%s', instance %d\", cwd, name, instance)\n            except Exception as e:\n                log.error(\"Chdir to '%s' failed in child %r, instance %d -- %s\",\n                        cwd, name, instance, e, exc_info=log.isEnabledFor(logging.DEBUG))\n                os._exit(83)\n\n        #  Build formatted command\n        #\n        prog = _fmt_context(cmd_list[0], context)\n        cmd = []\n        if procname:\n            cmd_list.pop(0)\n            cmd.append(_fmt_context(context['procname'], context))\n        for a in cmd_list:\n            cmd.append(_fmt_context(a, context))\n\n        log.info(\"child, Execing: %s <%s>\", prog, utils.format_cmd(cmd))\n    except Exception as e:\n        #  Log any exceptions here while we still can.  After the closeall,\n        #  bets are off.\n        #\n        log.error(\"Child processing failed for task %r, instance %d -- %s\",\n                name, instance, e, exc_info=log.isEnabledFor(logging.DEBUG))\n        os._exit(84)\n    try:\n        retain_fds = [0,1,2]\n        for log_fd in utils.log_filenos(log):\n            if log_fd not in retain_fds:\n                retain_fds.append(log_fd)\n        utils.closeall(exclude=retain_fds)\n        fd = None\n        try: os.close(0)\n        except: pass\n        try:\n            fd = os.open(std_process_dest, os.O_RDONLY)\n        except Exception as e:\n            log.error(\"child read open of %s failed -- %s\", std_process_dest, e)\n        if fd != 0:\n            log.error(\"child failed to redirect stdin to %s\", std_process_dest)\n\n        try: os.close(1)\n        except: pass\n        try:\n            fd = os.open('/dev/null', os.O_WRONLY)\n        except Exception as e:\n            log.error(\"child write open of %s failed -- %s\", std_process_dest, e)\n        if fd != 1:\n            log.error(\"child failed to redirect stdout to %s\", std_process_dest)\n\n        #  Build a fresh environment based on context, with None values excluded and\n        #  all other values as strings, formatted where appropriate:\n        #\n        env = {}\n        for tag, val in context.items():\n            if val is None:\n                continue\n            val = _fmt_context(str(val), context)\n            if val is not None:\n                env[tag] = val\n    except Exception as e:\n        #  At this point we can still send logs to stderr, so log these\n        #  too, just in case.\n        #\n        log.error(\"Child processing failed for task %r, instance %d -- %s\",\n            name, instance, e, exc_info=log.isEnabledFor(logging.DEBUG))\n        os._exit(85)\n    try:\n        try: os.close(2)\n        except: pass\n        try: os.dup(1)\n        except: pass\n\n        os.execvpe(prog, cmd, env)\n    except:\n        pass\n    #  There is no way to report an exception here, so hopefully the exit code will\n    #  be evidence enough.  When child output logging is supported, this can be reworked.\n    #\n    os._exit(86)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling executing a command - based event.", "response": "def command(self, details):\n        \"\"\"\n        Handles executing a command-based event.  This starts the command\n        as specified in the 'commands' section of the task config.\n\n        A separate event is registered to handle the command exit.  This\n        simply logs the exit status.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        if '_config_running' not in dir(self._parent) or 'commands' not in self._parent._config_running:\n            log.error(\"Event parent '%s' has no 'commands' config section\", self._name)\n            return\n        commands = self._parent._config_running['commands']\n        if self._handler_arg not in commands:\n            #  For now, at least, we implement a predefined command 'stop' if there is no\n            #  explicit stop.  This probably needs more work because it needs to handle\n            #  async commands where 'stop' would translate to a SIGTERM of the pid file.\n            #\n            if self._handler_arg == 'stop':\n                self._parent.stop()\n            else:\n                log.error(\"Event parent '%s' has no '%s' command configured\", self._name, self._handler_arg)\n            return\n        pid = _exec_process(commands[self._handler_arg], self._parent._context, log=log)\n        log.info(\"Forked pid %d for %s(%s)\", pid, self._name, self._handler_arg)\n        self._parent._legion.proc_add(event_target(self._parent, 'command_exit', key=pid, arg=self._handler_arg, log=log))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef command_exit(self, details):\n        log = self._params.get('log', self._discard)\n        pid = self._key\n        status = details\n        why = statusfmt(status)\n        if status:\n            log.warning(\"pid %d for %s(%s) %s\", pid, self._name, self._handler_arg, why)\n        else:\n            log.info(\"pid %d for %s(%s) %s\", pid, self._name, self._handler_arg, why)", "response": "Handle the event when a utility command exits."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef proc_exit(self, details):\n        log = self._params.get('log', self._discard)\n        pid = self._key\n        exit_code = details\n        why = statusfmt(exit_code)\n        proc = None\n        for p in self._parent._proc_state:\n            if pid == p.pid:\n                proc = p\n        if proc is None:\n            log.error(\"Legion reported exit of unknown pid %s for task %r which %s\", pid, self._name, why)\n            return\n\n        now = time.time()\n        proc.pid = None\n        proc.exit_code = exit_code\n        proc.exited = now\n        proc.pending_sig = None\n        proc.next_sig = None\n        self._parent._last_status = exit_code\n        extant = len(self._parent.get_pids())\n        if extant == 0:\n            self._parent._started = None\n            self._parent._stopping = None\n            self._parent._stopped = now\n            self._parent.onexit()\n        else:\n            log.debug(\"Task '%s' still has %d process%s running\", self._name, extant, ses(extant, 'es'))\n        if exit_code and not self._parent._terminated:\n            log.warning(\"Task '%s' pid %d %s -- unexpected error exit\", self._name, pid, why)\n        else:\n            log.info(\"Task '%s' pid %d %s\", self._name, pid, why)", "response": "Handle the event when one of the task processes exits."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef signal(self, details):\n        log = self._params.get('log', self._discard)\n        if '_signal' not in dir(self._parent) or not callable(getattr(self._parent, '_signal')):\n            log.error(\"Event parent '%s' has no '_signal' method\", self._name)\n            return\n        sig = utils.signum(self._handler_arg)\n        if sig is None:\n            log.error(\"Invalid signal '%s' for task '%s'\", self._handler_arg, sig._name)\n            return\n        log.info(\"sending %s to all '%s' processes\", utils.signame(sig), self._name)\n        self._parent._signal(sig)", "response": "Send a signal to all task processes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _context_defines(self, context, conf):\n        if conf and 'defines' in conf and isinstance(conf['defines'], dict):\n            context.update(conf['defines'])\n        if hasattr(self, '_legion'):\n            roles = self._legion.get_roles()\n        else:\n            roles = self.get_roles()\n        if conf and roles and 'role_defines' in conf and isinstance(conf['role_defines'], dict):\n            for role in conf['role_defines']:\n                if role in roles:\n                    context.update(conf['role_defines'][role])", "response": "Apply any defines and role_defines from the current config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying any defaults and role_defaults from the current config.", "response": "def _context_defaults(self, context, conf):\n        \"\"\"\n        Apply any defaults and role_defaults from the current config.\n        The config might be at the task level or the global (top) level.\n        The order is such that a role_defaults value will be applied before\n        a normal defaults value so if present, the role_defaults is preferred.\n    \"\"\"\n        if hasattr(self, '_legion'):\n            roles = self._legion.get_roles()\n        else:\n            roles = self.get_roles()\n        if conf and roles and 'role_defaults' in conf and isinstance(conf['role_defaults'], dict):\n            for role in conf['role_defaults']:\n                if role in roles:\n                    for tag, val in conf['role_defaults'][role].items():\n                        if tag not in context:\n                            context[tag] = val\n        if conf and 'defaults' in conf and isinstance(conf['defaults'], dict):\n            for tag, val in conf['defaults'].items():\n                if tag not in context:\n                    context[tag] = val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_list(self, value, context=None):\n        log = self._params.get('log', self._discard)\n        res = []\n        if value is None:\n            return res\n        if context is None:\n            context = self._context\n        if isinstance(value, list):\n            log.debug(\"Processing list %s\", value)\n            for v in value:\n                res.extend(self._get_list(v, context=context))\n        elif isinstance(value, dict):\n            log.debug(\"Processing dict %s\", value)\n            for k in value:\n                if k in context:\n                    res.extend(self._get_list(value[k], context=context))\n        else:\n            log.debug(\"Processing value '%s'\", value)\n            res.append(value)\n        return res", "response": "Get a list of configuration values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a context dict from the standard legion configuration.", "response": "def _context_build(self, pending=False):\n        \"\"\"\n        Create a context dict from standard legion configuration.\n\n        The context is constructed in a standard way and is passed to str.format() on configuration.\n        The context consists of the entire os.environ, the config 'defines', and a set\n        of pre-defined values which have a common prefix from 'context_prefix'.\n\n        This is similar to the task conext but without the task-specific entries.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        log.debug(\"called with pending=%s\", pending)\n        if pending:\n            conf = self._config_pending\n        else:\n            conf = self._config_running\n        if not conf:\n            log.warning(\"No config available\")\n            conf = {}\n\n        #  Build context used to format process args.\n        #\n        context = {\n            context_prefix+'host': self.host,\n            context_prefix+'fqdn': self.fqdn\n        }\n\n        #  Add the environment to the context\n        #\n        context.update(os.environ)\n\n        if conf:\n            self._context_defines(context, conf)\n            self._context_defaults(context, conf)\n        else:\n            log.warning(\"No legion config available for defines\")\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of httpd. HttpService instances which describe the HTTP services that should be started.", "response": "def _get_http_services(self, http_list):\n        \"\"\"\n        Returns a list of httpd.HttpService instances which describe the HTTP\n        services that should be started.\n\n        The is built from the settings.http section of the configuration.\n        The first element of that section is adjusted according to parameters\n        which have been passed into the legion.  If settings.http is empty or\n        missing but parameters are present, an httpd.HttpService instance will\n        built using just the parameters and the returned list will contain\n        just that entry.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        listen_param = self._params.get('http')\n        services = []\n        if len(http_list) > 0:\n            for service in http_list:\n                s = httpd.HttpService()\n                for att in ['listen', 'allow_control', 'certfile', 'timeout']:\n                    val = service.get(att)\n                    if val is not None:\n                        setattr(s, att,  _fmt_context(self._get(val), self._context))\n                services.append(s)\n        elif listen_param is not None:\n            services.append(httpd.HttpService())\n        if services:\n            if listen_param is not None:\n                log.debug(\"Service 0 listen from args: %s\", listen_param)\n                services[0].listen = listen_param\n            val = self._params.get('control')\n            if val is not None:\n                log.debug(\"Service 0 control from args: %s\", val)\n                services[0].allow_control = val\n            val = self._params.get('certfile')\n            if val is not None:\n                log.debug(\"Service 0 certfile from args: %s\", val)\n                services[0].certfile = val\n        return services"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _manage_http_servers(self):\n        log = self._params.get('log', self._discard)\n\n        if not self._config_running:\n            raise Exception('Attempt to create HTTP services before config loaded')\n        conf = self._config_running\n        need = self._get_http_services(conf['settings']['http']\n                        if 'settings' in conf and 'http' in conf['settings'] else [])\n\n        #  If the service count has changed, close all servers and rebuild from scratch.\n        #\n        if len(self._http_servers) != len(need):\n            log.info(\"HTTP services count changed from %d to %d, reconfiguring all services\",\n                        len(self._http_servers), len(need))\n            pos = 0\n            for server in self._http_servers:\n                if server:\n                    if self._pset:\n                        try: self._pset.unregister(server)\n                        except: pass\n                    try: server.close()\n                    except: pass\n                    log.debug(\"Slot %d service closed\", pos)\n                pos += 1\n            self._http_servers = []\n\n        self._http_retry = None\n        for pos in range(len(need)):\n            if len(self._http_servers) > pos:\n                if self._http_servers[pos]:\n                    if need[pos].cmp(self._http_servers[pos]._http_service):\n                        log.debug(\"No change in service slot %d: %s\", pos, need[pos])\n                        continue\n                    else:\n                        log.debug(\"Slot %d service changing from %s\", pos, self._http_servers[pos]._http_service)\n                        if self._pset:\n                            try: self._pset.unregister(self._http_servers[pos])\n                            except: pass\n                        try: self._http_servers[pos].close()\n                        except: pass\n                        self._http_servers[pos] = None\n                else:\n                    log.debug(\"No existing service in slot %d\", pos)\n            else:\n                log.debug(\"Increasing services list for slot %d\", pos)\n                self._http_servers.append(None)\n\n            #  At this point the service slot exists and is empty.  We'll attempt to fill it.\n            try:\n                server = httpd.server(need[pos], log=log)\n\n                #  Add our own attribute to retain the service information\n                #\n                server._http_service = need[pos]\n\n                manage.http(self, server, log=log)\n                status.http(self, server, log=log)\n                if self._pset:\n                    self._pset.register(server, poll.POLLIN)\n                self._http_servers[pos] = server\n                log.info(\"Slot %d service is now %s\", pos, server._http_service)\n            except Exception as e:\n                log.error(\"Failed to create server slot %d on %s -- %s\", pos, need[pos], e)\n                if not self._http_retry:\n                    self._http_retry = time.time() + service_retry_limit", "response": "This method is called by _manage_http_servers to manage the HTTP services."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the roles from the roles file.", "response": "def _load_roles(self):\n        \"\"\"\n        Load the roles, one per line, from the roles file.  This is\n        called at startup and whenever the roles file changes.\n\n        Note that it is not strictly an error for the roles file to\n        be missing but a warning is logged in case that was not\n        intended.\n\n        Returns True if there was a change in roles, False otherwise.\n        On any change, the config should be reapplied except this is\n        typically skipped at startup as the first apply() will not\n        yet have happened.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n\n        new_role_set = None\n        if self._roles_file:\n            try:\n                with open(self._roles_file, 'r') as f:\n                    new_role_set = set()\n                    for line in f:\n                        line = line.strip()\n                        if line and not re.match(r'^\\s*#', line):\n                            new_role_set.add(line)\n            except Exception as e:\n                log.warning(\"Open failed on roles file %r -- %s\", self._roles_file, e)\n        if self._role_set == new_role_set:\n            log.info(\"Roles file check gave no changes from current set '%s'\", self._fmt_set(new_role_set))\n            return False\n        elif self._role_set is None:\n            log.info(\"Roles set to: %s\", self._fmt_set(new_role_set))\n        else:\n            log.info(\"Roles changing from '%s' to '%s'\", self._fmt_set(self._role_set), self._fmt_set(new_role_set))\n        self._prev_role_set = self._role_set\n        self._role_set = new_role_set\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload all roles from the roles file and watch for future role - induced changes.", "response": "def set_roles_file(self, path):\n        \"\"\"\n        Load all roles from the roles file, and watch for future role\n        changes.  When the roles file changes, it will be read and the\n        current configuration re-applied so that any role-induced\n        changes are processed.\n\n        Once loaded, the roles are presented as a set.  If there is\n        no role file, the role set is None and role processing is\n        inhibited (all tasks are in scope).  If the file exists but\n        is empty, then the role set is the empty set, and only tasks\n        with no role list will be in scope.  Otherwise the contents\n        is parsed as a set of roles, one per line.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        if path != self._roles_file:\n            if self._roles_file:\n                log.info(\"Roles file changed from '%s' to '%s'\", self._config_file, path)\n                self.file_del(self, paths=[self._roles_file])\n            else:\n                log.info(\"Roles file set to '%s'\", path)\n            self._roles_file = path\n            self.file_add(event_target(self, 'legion_config', log=log), path)\n        return self._load_roles()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_config_file(self, path):\n        log = self._params.get('log', self._discard)\n        if path != self._config_file:\n            if self._config_file:\n                log.info(\"Config file changed from '%s' to '%s'\", self._config_file, path)\n                self.file_del(self, paths=[self._config_file])\n            else:\n                log.info(\"Config file set to '%s'\", path)\n            self._config_file = path\n            self.file_add(event_target(self, 'legion_config', log=log), path)\n        return self._load_config()", "response": "Set the config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_own_module(self, path):\n        log = self._params.get('log', self._discard)\n        self._name = path\n        self.module_add(event_target(self, 'legion_reset', key=path, log=log), path)", "response": "Set the module that this module is using to process the tree changes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef task_add(self, t, periodic=None):\n        name = t.get_name()\n        if name in self._tasknames:\n            raise TaskError(name, 'Task already exists with %d daemon%s active' %\n                            (len(self._tasknames), ses(len(self._tasknames))))\n        self._tasknames[name] = (t, periodic)\n        self._tasks.add(t)", "response": "Register a task in this legion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef task_del(self, t):\n        name = t._name\n        if name in self._tasknames:\n            del self._tasknames[name]\n        self._tasks.discard(t)\n        self._tasks_scoped.discard(t)\n        try:\n            t.stop()\n        except:\n            log = self._params.get('log', self._discard)\n            log.error(\"Failed to stop processes for task %r -- %s\", name, e, exc_info=log.isEnabledFor(logging.DEBUG))\n        for pid in t.get_pids():\n            self.proc_del(pid)", "response": "Remove a task from this legion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef task_list(self, pending=True):\n        log = self._params.get('log', self._discard)\n        tasks = [t for t in self._tasks if t.participant()]\n        requires = {}\n        for t in tasks:\n            requires[t] = t.get_requires(pending=pending)\n        done = set()\n        start_order = []\n        cycle = 0\n        while len(tasks) > len(start_order):\n            cycle += 1\n            changed = False\n            for t in tasks:\n                if t._name in done:\n                    continue\n                needs = 0\n                for req in requires[t]:\n                    if req._name in done:\n                        needs += 1\n                if needs == len(requires[t]):\n                    changed = True\n                    start_order.append(t)\n                    done.add(t._name)\n                    log.debug(\"Found '%s' in scope\", t._name)\n            if not changed:\n                log.error(\"Cycle %d failed after %s\", cycle, [t._name for t in set(tasks).difference(done)])\n                raise TaskError(None, \"At cycle %d, startup order conflict, processed %s, remaining %s\" %\n                            (cycle, done, [t._name for t in set(tasks).difference(done)]))\n        log.debug(\"Cycle %d gave %s\", cycle, [t._name for t in start_order])\n        return start_order", "response": "Return the list of scoped tasks in correct execution order."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef proc_del(self, pid):\n        if pid in self._procs:\n            del self._procs[pid]\n        else:\n            log = self._params.get('log', self._discard)\n            log.warning(\"Process %d missing from proc list during deletion\", pid)", "response": "Remove a process from the legion."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef module_add(self, ev, path=None):\n        log = self._params.get('log', self._discard)\n        key = ev.get_key()\n        if key is None:\n            raise TaskError(name, \"Attempt to register python module event with no key available\")\n        log.debug(\"Adding path %r for task %r, action %s\", path, ev.get_name(), ev._handler_name)\n        self._watch_modules.add(key, command_path=path)\n        self._module_event_map[key] = ev", "response": "Register for python module change events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef module_del(self, key):\n        if key in self._module_event_map:\n            del self._module_event_map[key]\n        if key in self._watch_modules.names:\n            self._watch_modules.remove(key)", "response": "Deregisters a module from the watchlist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_add(self, ev, paths):\n        log = self._params.get('log', self._discard)\n        if not isinstance(paths, list):\n            paths = [paths]\n        for path in paths:\n            if path not in self._file_event_map:\n                self._watch_files.add(path)\n                self._file_event_map[path] = {}\n            self._file_event_map[path][ev.get_key()] = ev\n        log.debug(\"Added event key %r, action %r to path%s: %s\", ev.get_key(), ev._handler_name, ses(len(paths)), paths)", "response": "Register for file change events."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef file_del(self, key, paths=None):\n        if paths is None:\n            paths = []\n            for path in self._file_event_map:\n                if key in self._file_event_map[path]:\n                    paths.append(path)\n        elif not isinstance(paths, list):\n            paths = [paths]\n        for path in paths:\n            if key in self._file_event_map[path]:\n                del self._file_event_map[path][key]\n            if path in self._file_event_map and not self._file_event_map[path]:\n                self._watch_files.remove(path)\n                del self._file_event_map[path]", "response": "Deregisters a task for file event changes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreap all processes that have exited.", "response": "def _reap(self):\n        \"\"\"\n        Reap all processes that have exited.  We try to reap bursts of\n        processes so that groups that cluster will tend to restart in the\n        configured order.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        try:\n            cnt = len(os.read(self._watch_child, 102400))\n            log.debug(\"%d byte%s read from self-pipe\", cnt, ses(cnt))\n        except OSError as e:\n            if e.errno != errno.EAGAIN:\n                log.error(\"Self-pipe read failed -- %s\", e)\n        except Exception as e:\n            log.error(\"Self-pipe read failed -- %s\", e)\n        reaped = False\n        while True:\n            try:\n                (pid, status) = os.waitpid(-1, os.WNOHANG)\n            except OSError as e:\n                if e.errno == errno.ECHILD:\n                    log.debug(\"No children to wait for\")\n                    pid = 0\n                else:\n                    raise e\n            if pid > 0:\n                reaped = True\n                if pid in self._procs:\n                    log.debug(\"Pid %d exited, firing event\", pid)\n                    self._procs[pid].handle(status)\n                    self.proc_del(pid)\n                else:\n                    log.error(\"Unknown pid %d %s, ignoring\", pid, statusfmt(status))\n                continue\n            else:\n                return reaped"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reset_state(self):\n        self._starting = None\n        self._started = None\n        self._suspended = None\n        self._stopping = None\n        self._terminated = None\n        self._killed = None\n        self._stopped = None\n        self._dnr = None\n        self._limit = None", "response": "Resets the internal state of the all - node process structures."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a context dict from the current task configuration.", "response": "def _context_build(self, pending=False):\n        \"\"\"\n        Create a context dict from standard task configuration.\n\n        The context is constructed in a standard way and is passed to str.format() on configuration.\n        The context consists of the entire os.environ, the config 'defines', and a set\n        of pre-defined values which have a common prefix from 'context_prefix'.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        log.debug(\"called with pending=%s\", pending)\n        if pending:\n            conf = self._config_pending\n        else:\n            conf = self._config_running\n        if not conf:\n            log.warning(\"No config available\")\n            conf = {}\n\n        #  Initially create the context as a copy of the environment.\n        #\n        context = os.environ.copy()\n\n        #  Merge in the built-in items.  It is important that these\n        #  will override any values from the environment as they will\n        #  have come from a parent instance of \"taskforce\".\n        #\n        context.update(\n            {\n                context_prefix+'instance': None,\n                context_prefix+'pid': None,\n                context_prefix+'name': self._name,\n                context_prefix+'ppid': os.getpid(),\n                context_prefix+'host': self._legion.host,\n                context_prefix+'fqdn': self._legion.fqdn\n            }\n        )\n\n        #  Add certain config values to the context\n        for tag in ['user', 'group', 'pidfile', 'cwd']:\n            if tag in conf:\n                context[context_prefix+tag] = self._get(conf[tag], context=context)\n\n        if self._legion._config_running:\n            self._context_defines(context, self._legion._config_running)\n        else:\n            log.warning(\"No legion config available for defines\")\n        self._context_defines(context, conf)\n\n        self._context_defaults(context, conf)\n        if self._legion._config_running:\n            self._context_defaults(context, self._legion._config_running)\n        else:\n            log.warning(\"No legion config available for defaults\")\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef participant(self):\n        log = self._params.get('log', self._discard)\n        context = self._context_build(pending=True)\n        conf = self._config_pending\n\n        if conf.get('control') == 'off':\n            log.debug(\"Excluding task '%s' -- control is off\", self._name)\n            return False\n\n        #  If role-set is None (but not the empty set)\n        #  then role processing is inhibited.\n        #\n        active_roles = self._legion.get_roles()\n        if active_roles is None:\n            log.debug(\"Including task '%s' -- role processing is inhibited\", self._name)\n            return True\n\n        #  If roles are present, at least one has to match the role-set.\n        #  If none are present, the task is always included.\n        #\n        roles = self._get_list(conf.get('roles'), context=context)\n\n        #  If a task has no roles listed, then it particpates\n        #  in all roles:\n        #\n        if not roles:\n            log.debug(\"Including task '%s' -- no explicit roles\", self._name)\n            return True\n\n        for role in roles:\n            if role in active_roles:\n                log.debug(\"Including task '%s' -- has role '%s'\", self._name, role)\n                return True\n        log.debug(\"Excluding task %r -- no role matches %s\", self._name, active_roles)\n        return False", "response": "Returns True if the task is part of the legion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndo all necessary event registration with the legion for events listed in the pending config. The default event action is to stop the task.", "response": "def _event_register(self, control):\n        \"\"\"\n        Do all necessary event registration with the legion for\n        events listed in the pending config.  The default event\n        action is to stop the task.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        if 'events' not in self._config_running:\n            log.debug(\"No events present for task '%s'\", self._name)\n            return\n        for event in self._config_running['events']:\n            ev_type = self._get(event.get('type'))\n            if not ev_type:\n                log.error(\"Ignoring event in task '%s' with no type\", self._name)\n                continue\n            ev = self._make_event_target(event, control)\n            if ev is None:\n                continue\n            log.debug(\"Adding event type '%s' for task '%s'\", ev_type, self._name)\n            if ev_type == 'self':\n                self._legion.file_add(ev, self.get_path())\n            elif ev_type == 'python':\n                self._legion.module_add(ev, path=self.get_path())\n            elif ev_type == 'file_change':\n                path = self._get_list(event.get('path'))\n                if path:\n                    self._legion.file_add(ev, _fmt_context(path, self._context))\n                else:\n                    log.error(\"Ignoring %s event in task '%s' with no path\", ev_type, self._name)\n            elif ev_type in ['stop', 'restart']:\n                log.debug(\"No task '%s' registration action for '%s' event\", self._name, ev_type)\n            else:\n                log.error(\"Ignoring unknown event type '%s' in task '%s'\", ev_type, self._name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _event_deregister(self):\n        log = self._params.get('log', self._discard)\n        if 'events' not in self._config_running:\n            log.debug(\"No events present for task '%s'\", self._name)\n            return\n        for event in self._config_running['events']:\n            ev_type = self._get(event.get('type'))\n            if ev_type == 'python':\n                self._legion.module_del(self._name)\n            elif ev_type == 'self':\n                self._legion.file_del(self._name)\n            elif ev_type == 'file_change':\n                self._legion.file_del(self._name)", "response": "Deregisters all legion events associated with this task."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _command_change(self):\n        log = self._params.get('log', self._discard)\n        if self._config_running is None:\n            log.debug(\"Task '%s' change - no previous config\", self._name)\n            return True\n        for elem in set(list(self._config_running) + list(self._config_pending)):\n            #  Ignore these elements as they don't affect the operation of a process\n            #  that is already running\n            #\n            if elem in ['control', 'pidfile', 'onexit', 'requires', 'start_delay']:\n                continue\n            if self._config_running.get(elem) != self._config_pending.get(elem):\n                log.debug(\"Task '%s' change - '%s' text change\", self._name, elem)\n                return True\n        new_context = self._context_build(pending=True)\n        if self._context != new_context:\n            if log.isEnabledFor(logging.DEBUG):\n                log.debug(\"Task '%s' change - context change\", self._name)\n                for tag in set(list(self._context) + list(new_context)):\n                    o = self._context.get(tag)\n                    n = new_context.get(tag)\n                    if o != n:\n                        log.debug(\"    %s: %s -> %s\", tag, o, n)\n            return True\n        log.debug(\"No changes in task '%s'\", self._name)\n        return False", "response": "Returns True if the difference between the current and pending configs represents a change to the command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a signal to one or all pids associated with this task.", "response": "def _signal(self, sig, pid=None):\n        \"\"\"\n        Send a signal to one or all pids associated with this task.  Never fails, but logs\n        signalling faults as warnings.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        if pid is None:\n            pids = self.get_pids()\n        else:\n            pids = [pid]\n        for pid in pids:\n            try:\n                os.kill(pid, sig)\n                log.debug(\"Signalled '%s' pid %d with %s\", self._name, pid, utils.signame(sig))\n            except Exception as e:\n                log.warning(\"Failed to signal '%s' pid %d with %s -- %s\", self._name, pid, utils.signame(sig), e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef onexit(self):\n        log = self._params.get('log', self._discard)\n        conf = self._config_running\n        if 'onexit' not in conf:\n            log.debug(\"Task %s has no 'onexit' processing\", self._name)\n            return\n        if self._legion.is_exiting():\n            log.debug(\"Skipping task %s 'onexit' processing because legion is exiting\", self._name)\n            return\n        item = 0\n        for op in conf['onexit']:\n            item += 1\n            if 'type' not in op:\n                log.error(\"Task %s 'onexit' item %d has no 'type'\", self._name, item)\n                continue\n            op_type = self._get(op.get('type'))\n            if op_type == 'start':\n                if 'task' not in op:\n                    log.error(\"Task %s 'onexit' item %d type '%s' has no 'task'\", self._name, item, op_type)\n                    continue\n                taskname = self._get(op.get('task'))\n                if taskname not in self._legion._tasknames:\n                    log.error(\"Task %s 'onexit' item %d type '%s' task '%s' does not exist\",\n                                        self._name, item, op_type, taskname)\n                    continue\n                task = None\n                for t in self._legion.task_list(pending=False):\n                    if taskname == t._name:\n                        task = t\n                if not task:\n                    log.error(\"Task %s 'onexit' item %d type '%s' task '%s' exists but is out of scope\",\n                                        self._name, item, op_type, taskname)\n                    continue\n                if task._config_running.get('control') not in self._legion.once_controls:\n                    log.error(\"Task %s 'onexit' item %d type '%s' task '%s' may only start 'once' tasks\",\n                                        self._name, item, op_type, taskname)\n                    continue\n                log.info(\"Task '%s' marked to restart by task '%s'\", taskname, self._name)\n                task._reset_state()\n            else:\n                log.error(\"Unknown type '%s' for task %s 'onexit' item %d\", op_type, self._name, item)\n                continue", "response": "Runs any onexit functions present in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshrinks the process pool from the number currently running to the number needed.", "response": "def _shrink(self, needed, running):\n        \"\"\"\n        Shrink the process pool from the number currently running to\n        the needed number.  The processes will be sent a SIGTERM at first\n        and if that doesn't clear the process, a SIGKILL.  Errors will\n        be logged but otherwise ignored.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        log.info(\"%d process%s running, reducing to %d process%s\", running, ses(running, 'es'), needed, ses(needed, 'es'))\n        now = time.time()\n        signalled = 0\n        for proc in self._proc_state[needed:]:\n            if proc.pid is None:\n                continue\n            if proc.pending_sig is None:\n                proc.pending_sig = signal.SIGTERM\n            if proc.next_sig is None or proc.next_sig < now:\n                self._signal(proc.pending_sig, pid=proc.pid)\n                signalled += 1\n                proc.pending_sig = signal.SIGKILL\n                proc.next_sig = now + sigkill_escalation\n            else:\n                log.debug(\"Process instance %d (pid %d) for task '%s' exit pending\",\n                        proc.instance, proc.pid, self._name)\n        log.info(\"%d process%s signalled\", signalled, ses(signalled, 'es'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state information for a task once it has completely started.", "response": "def _mark_started(self):\n        \"\"\"\n        Set the state information for a task once it has completely started.\n        In particular, the time limit is applied as of this time (ie after\n        and start delay has been taking.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n\n        now = time.time()\n        self._started = now\n\n        limit = self._config_running.get('time_limit')\n        try:\n            limit = float(_fmt_context(self._get(limit, default='0'), self._context))\n            if limit > 0:\n                log.debug(\"Applying task '%s' time limit of %s\", self._name, deltafmt(limit))\n                self._limit = now + limit\n        except Exception as e:\n            log.warn(\"Task '%s' time_limit value '%s' invalid -- %s\",\n                self._name, limit, e, exc_info=log.isEnabledFor(logging.DEBUG))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts a task, which may involve starting zero or more processes. This is indicated as an internal method because tasks are really only ever marked as startable by the configuration. Any task that should be running and is not will be started during regular manage() calls. A task set to run only once will be started only if the _stopped attribute is None. If a task requires another task, it won't be started until the required task has started, except if the required task has 'once' control, then it won't be started until the 'once' task has stopped. Currently, processes are started via direct fork/exec, with stdin/stdout/stderr all redirected from /dev/null. In future, will probably add options to redirect stdout/stderr to syslog or files. Note that processes are intentionally not detached or put in separate process groups or terminal groups. The presumption is that \"async\" and \"adopt\" tasks will handle this themselves, and we need \"wait\" tasks to not be detached. Returns True to request a shorter period before the next call, False if nothing special is needed.", "response": "def _start(self):\n        \"\"\"\n        Start a task, which may involve starting zero or more processes.\n\n        This is indicated as an internal method because tasks are really\n        only ever marked as startable by the configuration.  Any task\n        that should be running and is not will be started during regular\n        manage() calls.  A task set to run only once will be started only\n        if the _stopped attribute is None.\n\n        If a task requires another task, it won't be started until the\n        required task has started, except if the required task has 'once'\n        control, then it won't be started until the 'once' task has\n        stopped.\n\n        Currently, processes are started via direct fork/exec, with\n        stdin/stdout/stderr all redirected from /dev/null.  In future,\n        will probably add options to redirect stdout/stderr to syslog\n        or files.\n\n        Note that processes are intentionally not detached or put in\n        separate process groups or terminal groups.  The presumption is\n        that \"async\" and \"adopt\" tasks will handle this themselves, and\n        we need \"wait\" tasks to not be detached.\n\n        Returns True to request a shorter period before the next call,\n        False if nothing special is needed.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n        if self._stopping:\n            log.debug(\"%s task is stopping\", self._name)\n            return True\n        now = time.time()\n        conf = self._config_running\n        control = self._get(conf.get('control'))\n        once = (control in self._legion.once_controls)\n\n        #  Tasks with \"event\" control are immediately marked stopped as if they\n        #  ran at start.  This is the only difference between \"event\" and \"once\"\n        #  controls.\n        #\n        if control == 'event' and not self._stopped:\n            self._stopped = now\n        if self._stopped:\n            if self._dnr:\n                log.info(\"Task '%s' stopped and will now be deleted\", self._name)\n                self.close()\n                return False\n            elif once:\n                log.debug(\"'%s' task %s exited %s ago\", control, self._name, deltafmt(time.time() - self._stopped))\n                return False\n            else:\n                log.debug(\"Restarting %s, task was stopped %s ago\",\n                            self._name, deltafmt(time.time() - self._stopped))\n                self._reset_state()\n\n        start_delay = self._get(conf.get('start_delay'))\n        if start_delay:\n            try:\n                start_delay = int(start_delay)\n            except Exception as e:\n                log.error(\"Task '%s' has invalid start_delay '%s'\", self._name, start_delay)\n                start_delay = 0\n        else:\n            start_delay = 0\n        if self._starting and not self._started:\n            if now > self._starting + start_delay:\n                log.info(\"%s task marked started after %s\", self._name, deltafmt(now - self._starting))\n                self._mark_started()\n                return False\n            log.debug(\"%s task has been starting for %s of %s\",\n                    self._name, deltafmt(now - self._starting), deltafmt(start_delay))\n            return True\n\n        #  Check the required state to ensure dependencies have been started.  In the case of\n        #  'once' controls, the dependency must have already stopped, otherwise it must have\n        #  started.\n        #\n        if self._started and control != 'suspend':\n            log.debug(\"Task '%s' already started, skipping requires-check\", self._name)\n        else:\n            for req in self.get_requires():\n                if req._config_running.get('control') == 'once':\n                    if not req._stopped:\n                        if self._last_message + repetition_limit < time.time():\n                            log.info(\"Task '%s' is waiting on '%s' to complete\", self._name, req._name)\n                            self._last_message = now\n                        return True\n                else:\n                    if not req._started:\n                        if self._last_message + repetition_limit < time.time():\n                            log.info(\"Task '%s' is waiting on '%s' to start\", self._name, req._name)\n                            self._last_message = now\n                        return True\n\n        self._last_message = 0\n        if once:\n            #  \"once\" processes are immediately marked as stopping.\n            #\n            self._stopping = now\n\n        try:\n            start_command = None\n            if 'commands' in conf:\n                start_command = self._get_list(conf['commands'].get('start'))\n            if not start_command:\n                raise TaskError(self._name, \"No 'start' command in task configuration\")\n            if not isinstance(start_command, list):\n                start_command = list(start_command)\n\n            if control != 'suspend':\n                needed = self._get(conf.get('count'), default=1)\n                running = len(self.get_pids())\n                if needed < running:\n                    self._shrink(needed, running)\n                    return False\n                elif needed == running:\n                    log.debug(\"all %d needed process%s running\", running, ses(running, 'es'))\n                    return False\n\n            self._starting = now\n            if not start_delay:\n                self._mark_started()\n\n            if control == 'suspend':\n                if not self._suspended:\n                    log.debug(\"%s just moved to %r\", self._name, control)\n                    running = len(self.get_pids())\n                    if running > 0:\n                        log.debug(\"%s now %r, stopping running processes\", self._name, control)\n                        self._shrink(0, running)\n                    else:\n                        log.debug(\"%s is %r control, skipping process startup\", self._name, control)\n                        self._suspended = now\n                return False\n            else:\n                if self._suspended:\n                    log.debug(\"%s just moved to %r\", self._name, control)\n                self._suspended = None\n\n            log.debug(\"Found %d running, %d needed, starting %d\", running, needed, needed-running)\n            started = 0\n            for instance in range(needed):\n                if instance < len(self._proc_state):\n                    proc = self._proc_state[instance]\n                    if proc.pid is not None:\n                        log.debug(\"%s instance %d already started\", self._name, instance)\n                        continue\n                    if proc.started is None:\n                        proc.started = now\n                    last_start_delta = now - proc.started\n                    if last_start_delta < 0:\n                        #  This can happen when the system clock is manually set.  As one\n                        #  of the goals here is to restart ntpd when it dies due to exceeding\n                        #  the panic threshold (1000 seconds), go ahead and mark the time\n                        #  as now so the task restart will only be delayed slightly longer\n                        #  than normal.\n                        #\n                        log.warning(\"Time flowed backwards, resetting %s instance %d start time\",\n                                self._name, instance)\n                        proc.started = now\n                        continue\n                    if last_start_delta < reexec_delay:\n                        log.debug(\"%s instance %d restart skipped, last attempt %s ago\",\n                                self._name, instance, deltafmt(last_start_delta))\n                        continue\n                else:\n                    log.debug(\"%s growing instance %d\", self._name, instance)\n                    self._proc_state.append(ProcessState())\n                    proc = self._proc_state[instance]\n\n                pid = _exec_process(start_command, self._context, instance=instance, log=log)\n                log.debug(\"Forked pid %d for '%s', %d of %d now running\",\n                            pid, self._name, len(self.get_pids()), needed)\n                self._legion.proc_add(event_target(self, 'proc_exit', key=pid, log=log))\n                proc.pid = pid\n                proc.started = now\n                started += 1\n\n            log.info(\"Task %s: %d process%s scheduled to start%s\",\n                    self._name, started, ses(started, 'es'),\n                    (' with time limit %s' % (deltafmt(self._limit - now),)) if self._limit else '')\n        except Exception as e:\n            log.error(\"Failed to start task '%s' -- %s\", self._name, e, exc_info=log.isEnabledFor(logging.DEBUG))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops a task. This stops all processes for the task. The approach is to mark the task as \"stopping\" , send a SIGTERM to each process, and schedule a SIGKILL for some time later. If the legion or task is resetting and a \"restart\" event is in scope, that event will be fired rather than sending the SIGTERM. Otherwise, if a \"stop\" event is in scope, that event will be fired. In either case, the SIGKILL escalation will still occur so the recipient needs to process the event and exit promptly. Returns True to request a shorter period before the next call, False if nothing special is needed.", "response": "def stop(self, task_is_resetting=False):\n        \"\"\"\n        Stop a task.  This stops all processes for the task.  The approach\n        is to mark the task as \"stopping\" , send a SIGTERM to each process,\n        and schedule a SIGKILL for some time later.\n\n        If the legion or task is resetting and a \"restart\" event is in scope,\n        that event will be fired rather than sending the SIGTERM.  Otherwise,\n        if a \"stop\" event is in scope, that event will be fired.  In\n        either case, the SIGKILL escalation will still occur so the\n        recipient needs to process the event and exit promptly.\n\n        Returns True to request a shorter period before the next call,\n        False if nothing special is needed.\n    \"\"\"\n        log = self._params.get('log', self._discard)\n\n        if self._stopped:\n            log.debug(\"'%s' is already stopped\", self._name)\n            return False\n        now = time.time()\n        running = len(self.get_pids())\n        if self._stopping and running == 0:\n            log.debug(\"All '%s' processes are now stopped\", self._name)\n            self._reset_state()\n            self._stopped = now\n            return False\n        if self._config_running:\n            control = self._config_running.get('control')\n        else:\n            control = None\n        if self._terminated:\n            #  These are tasks that have been explicitly terminated but have not yet stopped\n            #\n            if self._killed:\n                log.warning(\"%d '%s' process%s still running %s after SIGKILL escalation\",\n                            running, self._name, ses(running, 'es'), deltafmt(now - self._killed))\n            elif self._terminated + sigkill_escalation < now:\n                log.warning(\"Excalating to SIGKILL with %d '%s' process%s still running\",\n                            running, self._name, ses(running, 'es'))\n                self._signal(signal.SIGKILL)\n                self._killed = now\n            else:\n                log.debug(\"%d '%s' process%s still running %s after being terminated\",\n                    running, self._name, ses(running, 'es'), deltafmt(now - self._terminated))\n            return True\n        if self._limit and now > self._limit:\n            #  These are tasks that have a time limit set and it has expired.\n            #  This case falls through to the stop code.\n            log.info(\"Stopping task '%s', time limit exceeded %s ago\", self._name, deltafmt(now - self._limit))\n        elif self._stopping and not self._legion.is_exiting():\n            #  These are tasks that are expected to stop soon but have not been explicitly\n            #  terminated.  These are typically tasks with 'once' or 'event' controls.\n            #  Unless there is a time limit set, they are allowed to run indefinitely\n            #\n            log.debug(\"%d '%s' '%s' process%s still running %s\",\n                    running, self._name, control, ses(running, 'es'), deltafmt(now - self._stopping))\n            return False\n\n        if not self._stopping:\n            self._stopping = now\n        self._terminated = now\n        restart_target = None\n        stop_target = None\n        resetting = self._legion.is_resetting() or task_is_resetting\n        if self._config_running:\n            for event in self._config_running.get('events', []):\n                ev_type = self._get(event.get('type'))\n                if resetting and ev_type == 'restart':\n                    restart_target = self._make_event_target(event, control)\n                elif ev_type == 'stop':\n                    stop_target = self._make_event_target(event, control)\n        if restart_target:\n            log.debug(\"Restart event on %d '%s' process%s\", running, self._name, ses(running, 'es'))\n            restart_target.handle()\n        elif stop_target:\n            log.debug(\"Stop event on %d '%s' process%s\", running, self._name, ses(running, 'es'))\n            stop_target.handle()\n        else:\n            log.debug(\"Stopping %d '%s' process%s with SIGTERM\", running, self._name, ses(running, 'es'))\n            self._signal(signal.SIGTERM)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef terminate(self):\n        log = self._params.get('log', self._discard)\n        self._dnr = time.time()\n        self.stop()\n        log.info(\"Task '%s' marked for death\", self._name)", "response": "Called when an existing task is removed from the configuration.\n        This sets a Do Not Resuscitate flag and then initiates a stop\n        sequence.  Once all processes have stopped, the task will delete\n        itself."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply(self):\n        log = self._params.get('log', self._discard)\n        if not self._config_pending:\n            raise TaskError(self._name, \"No configuration available to apply\")\n\n        control = self._config_pending.get('control')\n        if not control:\n            control = 'wait'\n\n        log.debug(\"for '%s', control '%s'\", self._name, control)\n        if self._command_change() and len(self.get_pids()) > 0:\n            self._event_deregister()\n            self.stop(task_is_resetting=True)\n\n        self._config_running = self._config_pending\n        self._context = self._context_build()\n\n        if control in self._legion.run_controls:\n            self._event_register(control)\n        return self.manage()", "response": "Applies the current configuration to the running task."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_first_key_from_value(self, value):\n\n        for key, data in self.iteritems():\n            if data == value:\n                return key", "response": "Gets the first key from given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_keys_from_value(self, value):\n\n        return [key for key, data in self.iteritems() if data == value]", "response": "Gets the keys from given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setXr(self, Xr):\n        self.Xr = Xr\n        self.gp_block.covar.G = Xr", "response": "set genotype data of the set component"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getVC(self):\n        _Cr = decompose_GxE(self.fr['Cr'])\n        RV = {}\n        for key in list(_Cr.keys()):\n            RV['var_%s' % key] = sp.array([var_CoXX(_Cr[key], self.Xr)])\n        RV['var_g'] = sp.array([var_CoXX(self.fr['Cg'], self.XXh)])\n        RV['var_n'] = sp.array([var_CoXX(self.fr['Cn'], sp.eye(self.XXh.shape[0]))])\n        return RV", "response": "Returns the Variance componenrs for the current class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estimate_chi2mixture(self, lrt):\n\n        \"\"\"\n        step 1: estimate the probability of being in component one\n        \"\"\"\n        self.mixture = 1-(lrt<=self.tol).mean()\n        n_false      = SP.sum(lrt>self.tol)\n\n        \"\"\"\n        step 2: only use the largest qmax fraction of test statistics to estimate the\n                remaining parameters\n        \"\"\"\n        n_fitting   = SP.ceil(self.qmax * n_false)\n        lrt_sorted  = -SP.sort(-lrt)[:n_fitting]\n        q           = SP.linspace(0, 1,n_false)[1:n_fitting+1]\n        log_q       = SP.log10(q)\n        \n        \"\"\"\n        step 3: fitting scale and dof by minimizing the squared error of the log10 p-values\n                with their theorietical values [uniform distribution]\n        \"\"\"\n        MSE_opt = SP.inf\n        MSE     = SP.zeros((self.n_intervals,self.n_intervals))\n\n        \n        for i,scale in enumerate(SP.linspace(self.scale_min,self.scale_max,self.n_intervals)):\n            for j,dof in enumerate(SP.linspace(self.dof_min,self.dof_max,self.n_intervals)):\n                p     = STATS.chi2.sf(lrt_sorted/scale,dof)\n                log_p = SP.log10(p)\n                MSE[i,j]   = SP.mean((log_q - log_p)**2)\n                if MSE[i,j] < MSE_opt:\n                    MSE_opt    = MSE[i,j]\n                    self.scale = scale\n                    self.dof   = dof", "response": "estimate the chi2 mixture of a random variable of degree lrt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the survival function of a mixture of a chi - squared random variable of degree d", "response": "def sf(self,lrt):\n        \"\"\"\n        computes the survival function of a mixture of a chi-squared random variable of degree\n        0 and a scaled chi-squared random variable of degree d\n        \"\"\"\n        _lrt = SP.copy(lrt)\n        _lrt[lrt<self.tol] = 0\n        pv = self.mixture*STATS.chi2.sf(_lrt/self.scale,self.dof)\n        return pv"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns all dictionary values into strings", "response": "def stringify(data):\n    \"\"\"Turns all dictionary values into strings\"\"\"\n    if isinstance(data, dict):\n        for key, value in data.items():\n            data[key] = stringify(value)\n    elif isinstance(data, list):\n        return [stringify(item) for item in data]\n    else:\n        return smart_text(data)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_app(self, app, client_id=None):\n        if not self.client_id:\n            if client_id:\n                self.client_id = client_id\n            else:\n                self.client_id = app.name", "response": "Initialize the Micropub extension if it was not given app\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nauthenticate a user via IndieAuth.", "response": "def authenticate(self, me, state=None, next_url=None):\n        \"\"\"Authenticate a user via IndieAuth.\n\n        Args:\n          me (string): the authing user's URL. if it does not begin with\n            https?://, http:// will be prepended.\n          state (string, optional): passed through the whole auth process,\n            useful if you want to maintain some state, e.g. the starting page\n            to return to when auth is complete.\n          next_url (string, optional): deprecated and replaced by the more\n            general \"state\". still here for backward compatibility.\n\n        Returns:\n          a redirect to the user's specified authorization url, or\n          https://indieauth.com/auth if none is provided.\n        \"\"\"\n        redirect_url = flask.url_for(\n            self.flask_endpoint_for_function(self._authenticated_handler),\n            _external=True)\n        return self._start_indieauth(me, redirect_url, state or next_url, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authorize(self, me, state=None, next_url=None, scope='read'):\n        redirect_url = flask.url_for(\n            self.flask_endpoint_for_function(self._authorized_handler),\n            _external=True)\n        return self._start_indieauth(\n            me, redirect_url, state or next_url, scope)", "response": "Authorize a user via Micropub."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticated_handler(self, f):\n        @functools.wraps(f)\n        def decorated():\n            resp = self._handle_authenticate_response()\n            return f(resp)\n        self._authenticated_handler = decorated\n        return decorated", "response": "Decorates the authentication callback endpoint. The endpoint should\n        take one argument a flask. ext. micropub. AuthResponse"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef authorized_handler(self, f):\n        @functools.wraps(f)\n        def decorated():\n            resp = self._handle_authorize_response()\n            return f(resp)\n        self._authorized_handler = decorated\n        return decorated", "response": "Decorates the authorization callback endpoint. The endpoint should\n        take one argument a flask. ext. micropub. AuthResponse"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_field(self, fieldname, fieldspec=whoosh_module_fields.TEXT):\n    self._whoosh.add_field(fieldname, fieldspec)\n    return self._whoosh.schema", "response": "Add a field to the index of the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_field(self, field_name):\n    self._whoosh.remove_field(field_name.strip())\n    return self._whoosh.schema", "response": "This function deletes one field from the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes all the Documents using the pk associated to them.", "response": "def delete_documents(self):\n    \"\"\"Deletes all the  documents using the  pk associated to them.\n    \"\"\"\n    pk = str(self._primary_key)\n    for doc in self._whoosh.searcher().documents():\n      if pk in doc:\n        doc_pk = str(doc[pk])\n        self._whoosh.delete_by_term(pk, doc_pk)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef charge_documents(self):\n\n    doc_count   = self._whoosh.doc_count()\n    objs        = orm.count(e for e in self._model)\n\n    field_names = set(self._schema_attrs.keys())\n    missings    = set(self._whoosh.schema.names())\n\n    for f in list(field_names - missings):\n        self.add_field(f, fields.TEXT(self.kw))\n\n    if doc_count == 0 and objs > 0:\n      writer = self._whoosh.writer()\n      for obj in orm.select(e for e in self._model):\n        attrs = {self._primary_key: obj.get_pk()}\n        for f in list(self._schema_attrs.keys()):\n          attrs[f] = str(getattr(obj, f))\n        writer.add_document(**attrs)\n      writer.commit()", "response": "This method charge documents in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, search_string, **opt):\n\n    prepped_string = self.prep_search_string(\n        search_string\n      , self.to_bool(opt.get('add_wildcards', False))\n      )\n\n    with self._whoosh.searcher() as searcher:\n      fields = opt.get('fields', self._schema.names())\n      fields = [x for x in fields if len(x) > 0]\n\n      field = opt.get('field', '')\n      if len(field) > 0:\n        if isinstance(field, str) or isinstance(field, str):\n          fields = [field]\n        elif isinstance(field, list):\n          fields = fields + field\n\n      fields = [x for x in fields if len(x) > 0]\n\n      if len(fields) == 0:\n        fields = self._schema.names()\n\n      if len(fields) > 0:\n        fields = set(fields) & set(self._schema.names())\n        fields = list(fields)\n\n      except_fields = opt.get('except_fields', [])\n      except_fields = [x for x in except_fields if len(x) > 0]\n\n      if len(except_fields) > 0:\n        fields = list(set(fields) - set(except_fields))\n\n      parser = qparser.MultifieldParser(\n          fields, self._whoosh.schema\n        , group=opt.get('group', qparser.OrGroup)\n        )\n\n      query       = parser.parse(prepped_string)\n      search_opts = self.parse_opts_searcher(opt, self._parameters)\n      results     = searcher.search(query, terms=True, **search_opts)\n\n      ma = defaultdict(set)\n      for f, term in results.matched_terms():\n        ma[f].add(term)\n\n      dic = {\n          'runtime'       : results.runtime\n        , 'cant_results'  : results.estimated_length()\n        , 'matched_terms' : {k: list(v) for k, v in list(ma.items())}\n        , 'facet_names'   : results.facet_names()\n        }\n\n      if dic['cant_results'] == 0 and self.to_bool(opt.get('something', False)):\n        opt['add_wildcards'] = True\n        opt['something']     = False\n        return self.search(search_string, **opt)\n\n      value_results = {}\n\n      for r in results:\n        params = {k:r[k] for k in self._primary_key}\n        ans = {\n            'docnum' : r.docnum\n          , 'pk'     : tuple(params.values())\n          , 'score'  : r.score\n        }\n\n        if self.to_bool(opt.get('include_entity', False)):\n          entity     = self._model.get(**params)\n          dic_entity = entity.to_dict()\n\n          if opt.get('use_dict', True):\n            ans['entity'] = dic_entity\n          else:\n            fields_missing      = set(dic_entity.keys()) - set(self._fields)\n            ans['other_fields'] = [(k, dic_entity[k]) for k in fields_missing]\n            ans['entity']       = [(k, dic_entity[k]) for k in self._fields]\n          ans['model'] = self._name\n        value_results[ans['pk']] = ans\n\n      dic[\"results\"] = list(value_results.values())\n      return dic", "response": "This function is the core function of the package. It will search the database for the given string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prep_search_string(self, search_string, add_wildcards=False):\n\n    s = search_string.strip()\n    try:\n      s = str(s)\n    except:\n      pass\n    s = s.replace('*', '')\n\n    if len(s) < self._pw.search_string_min_len:\n      raise ValueError('Search string must have at least {} characters'\n        .format(self._pw.search_string_min_len))\n    if add_wildcards:\n      s = '*{0}*'.format(re.sub('[\\s]+', '* *', s))\n    return s", "response": "Prepares the search string as a proper whoosh search string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef computeCovarianceMatrixPlink(plink_path,out_dir,bfile,cfile,sim_type='RRM'):\n\n    print(\"Using plink to create covariance matrix\")\n    cmd = '%s --bfile %s '%(plink_path,bfile)\n\n    if sim_type=='RRM':\n        # using variance standardization\n        cmd += '--make-rel square '\n    else:\n        raise Exception('sim_type %s is not known'%sim_type)\n\n    cmd+= '--out %s'%(os.path.join(out_dir,'plink'))\n\n    subprocess.call(cmd,shell=True)\n\n    # move file to specified file\n    if sim_type=='RRM':\n        old_fn = os.path.join(out_dir, 'plink.rel')\n        os.rename(old_fn,cfile+'.cov')\n\n        old_fn = os.path.join(out_dir, 'plink.rel.id')\n        os.rename(old_fn,cfile+'.cov.id')\n\n    if sim_type=='IBS':\n        old_fn = os.path.join(out_dir, 'plink.mibs')\n        os.rename(old_fn,cfile+'.cov')\n\n        old_fn = os.path.join(out_dir, 'plink.mibs.id')\n        os.rename(old_fn,cfile+'.cov.id')", "response": "Compute the covariance matrix via Plink"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the principal components using Plink", "response": "def computePCsPlink(plink_path,k,out_dir,bfile,ffile):\n    \"\"\"\n    computing the covariance matrix via plink\n    \"\"\"\n    print(\"Using plink to compute principal components\")\n    cmd = '%s --bfile %s --pca %d '%(plink_path,bfile,k)\n    cmd+= '--out %s'%(os.path.join(out_dir,'plink'))\n    subprocess.call(cmd,shell=True)\n    plink_fn = os.path.join(out_dir, 'plink.eigenvec')\n    M = sp.loadtxt(plink_fn,dtype=str)\n    U = sp.array(M[:,2:],dtype=float)\n    U-= U.mean(0)\n    U/= U.std(0)\n    sp.savetxt(ffile,U)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the prinicipal components of the PCs in a Python file.", "response": "def computePCsPython(out_dir,k,bfile,ffile):\n    \"\"\" reading in \"\"\"\n    RV = plink_reader.readBED(bfile,useMAFencoding=True)\n    X  = np.ascontiguousarray(RV['snps'])\n\n    \"\"\" normalizing markers \"\"\"\n    print('Normalizing SNPs...')\n    p_ref = X.mean(axis=0)/2.\n    X -= 2*p_ref\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        X /= sp.sqrt(2*p_ref*(1-p_ref))\n\n    hasNan = sp.any(sp.isnan(X),axis=0)\n    if sp.any(hasNan):\n        print(('%d SNPs have a nan entry. Exluding them for computing the covariance matrix.'%hasNan.sum()))\n        X  = X[:,~hasNan]\n\n    \"\"\" computing prinicipal components \"\"\"\n    U,S,Vt = ssl.svds(X,k=k)\n    U -= U.mean(0)\n    U /= U.std(0)\n    U  = U[:,::-1]\n\n    \"\"\" saving to output \"\"\"\n    np.savetxt(ffile, U, delimiter='\\t',fmt='%.6f')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the covariance matrix for a single object.", "response": "def computeCovarianceMatrixPython(out_dir,bfile,cfile,sim_type='RRM'):\n    print(\"Using python to create covariance matrix. This might be slow. We recommend using plink instead.\")\n\n    if sim_type is not 'RRM':\n        raise Exception('sim_type %s is not known'%sim_type)\n\n    \"\"\" loading data \"\"\"\n    data = plink_reader.readBED(bfile,useMAFencoding=True)\n    iid  = data['iid']\n    X = np.ascontiguousarray(data['snps'])\n    N = X.shape[1]\n    print(('%d variants loaded.'%N))\n    print(('%d people loaded.'%X.shape[0]))\n    \"\"\" normalizing markers \"\"\"\n    print('Normalizing SNPs...')\n    p_ref = X.mean(axis=0)/2.\n    X -= 2*p_ref\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        X /= sp.sqrt(2*p_ref*(1-p_ref))\n\n    hasNan = sp.any(sp.isnan(X),axis=0)\n    if sp.any(hasNan):\n        print(('%d SNPs have a nan entry. Exluding them for computing the covariance matrix.'%hasNan.sum()))\n\n    \"\"\" computing covariance matrix \"\"\"\n    print('Computing relationship matrix...')\n    K = sp.dot(X[:,~hasNan],X[:,~hasNan].T)\n    K/= 1.*N\n    print('Relationship matrix calculation complete')\n    print(('Relationship matrix written to %s.cov.'%cfile))\n    print(('IDs written to %s.cov.id.'%cfile))\n\n    \"\"\" saving to output \"\"\"\n    np.savetxt(cfile + '.cov', K, delimiter='\\t',fmt='%.6f')\n    np.savetxt(cfile + '.cov.id', iid, delimiter=' ',fmt='%s')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the first k principal components of a single BED file.", "response": "def computePCs(plink_path,k,bfile,ffile):\n    \"\"\"\n    compute the first k principal components\n\n    Input:\n    k            :   number of principal components\n    plink_path   :   plink path\n    bfile        :   binary bed file (bfile.bed, bfile.bim and bfile.fam are required)\n    ffile        :   name of output file\n    \"\"\"\n    try:\n        output = subprocess.check_output('%s --version --noweb'%plink_path,shell=True)\n        use_plink = float(output.split(' ')[1][1:-3])>=1.9\n    except:\n        use_plink = False\n\n\n    assert bfile!=None, 'Path to bed-file is missing.'\n    assert os.path.exists(bfile+'.bed'), '%s.bed is missing.'%bfile\n    assert os.path.exists(bfile+'.bim'), '%s.bim is missing.'%bfile\n    assert os.path.exists(bfile+'.fam'), '%s.fam is missing.'%bfile\n\n    # create dir if it does not exist\n    out_dir = os.path.split(ffile)[0]\n    if out_dir!='' and (not os.path.exists(out_dir)):\n        os.makedirs(out_dir)\n\n    if use_plink:\n        computePCsPlink(plink_path,k,out_dir,bfile,ffile)\n    else:\n        computePCsPython(out_dir,k,bfile,ffile)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute similarity matrix using Plink or Python.", "response": "def computeCovarianceMatrix(plink_path,bfile,cfile,sim_type='RRM'):\n    \"\"\"\n    compute similarity matrix using plink\n\n    Input:\n    plink_path   :   plink path\n    bfile        :   binary bed file (bfile.bed, bfile.bim and bfile.fam are required)\n    cfile        :   the covariance matrix will be written to cfile.cov and the corresponding identifiers\n                         to cfile.cov.id. If not specified, the covariance matrix will be written to cfile.cov and\n                         the individuals to cfile.cov.id in the current folder.\n    sim_type     :   {IBS/RRM} are supported\n    \"\"\"\n    try:\n        output    = subprocess.check_output('%s --version --noweb'%plink_path,shell=True)\n        m = re.match(b\"^PLINK v(\\d+\\.\\d+).*$\", output)\n        if m:\n            use_plink = float(m.group(1)) >= 1.9\n        else:\n            use_plink = False\n    except:\n        use_plink = False\n\n    assert bfile!=None, 'Path to bed-file is missing.'\n    assert os.path.exists(bfile+'.bed'), '%s.bed is missing.'%bfile\n    assert os.path.exists(bfile+'.bim'), '%s.bim is missing.'%bfile\n    assert os.path.exists(bfile+'.fam'), '%s.fam is missing.'%bfile\n\n    # create dir if it does not exist\n    out_dir = os.path.split(cfile)[0]\n    if out_dir!='' and (not os.path.exists(out_dir)):\n        os.makedirs(out_dir)\n\n\n    if use_plink:\n        computeCovarianceMatrixPlink(plink_path,out_dir,bfile,cfile,sim_type=sim_type)\n    else:\n        computeCovarianceMatrixPython(out_dir,bfile,cfile,sim_type=sim_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes similarity matrix using plink", "response": "def eighCovarianceMatrix(cfile):\n    \"\"\"\n    compute similarity matrix using plink\n\n    Input:\n    cfile        :   the covariance matrix will be read from cfile.cov while the eigenvalues and the eigenverctors will\n                        be written to cfile.cov.eval and cfile.cov.evec respectively\n    \"\"\"\n    # precompute eigenvalue decomposition\n    K = np.loadtxt(cfile+'.cov')\n    K+= 1e-4*sp.eye(K.shape[0])\n    S,U = la.eigh(K); S=S[::-1]; U=U[:,::-1]\n    np.savetxt(cfile+'.cov.eval',S,fmt='%.6f')\n    np.savetxt(cfile+'.cov.evec',U,fmt='%.6f')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit_null(Y,S_XX,U_XX,nfile,F):\n    mtSet = limix.MTSet(Y, S_R=S_XX, U_R=U_XX, F=F)\n\n    RV = mtSet.fitNull(cache=False)\n    params = np.array([RV['params0_g'],RV['params0_n']])\n    np.savetxt(nfile+'.p0',params)\n    np.savetxt(nfile+'.nll0',RV['NLL0'])\n    np.savetxt(nfile+'.cg0',RV['Cg'])\n    np.savetxt(nfile+'.cn0',RV['Cn'])", "response": "fit null model on a single file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the covariance matrix", "response": "def preprocess(options):\n\n    assert options.bfile!=None, 'Please specify a bfile.'\n\n    \"\"\" computing the covariance matrix \"\"\"\n    if options.compute_cov:\n       assert options.bfile!=None, 'Please specify a bfile.'\n       assert options.cfile is not None, 'Specify covariance matrix basename'\n       print('Computing covariance matrix')\n       t0 = time.time()\n       computeCovarianceMatrix(options.plink_path,options.bfile,options.cfile,options.sim_type)\n       t1 = time.time()\n       print(('... finished in %s seconds'%(t1-t0)))\n       print('Computing eigenvalue decomposition')\n       t0 = time.time()\n       eighCovarianceMatrix(options.cfile)\n       t1 = time.time()\n       print(('... finished in %s seconds'%(t1-t0)))\n\n    \"\"\" computing principal components \"\"\"\n    if options.compute_PCs>0:\n       assert options.ffile is not None, 'Specify fix effects basename for saving PCs'\n       t0 = time.time()\n       computePCs(options.plink_path,options.compute_PCs,options.bfile,options.ffile)\n       t1 = time.time()\n       print(('... finished in %s seconds'%(t1-t0)))\n\n    \"\"\" fitting the null model \"\"\"\n    if options.fit_null:\n        if options.nfile is None:\n            options.nfile = os.path.split(options.bfile)[-1]\n            warnings.warn('nfile not specifed, set to %s'%options.nfile)\n        print('Fitting null model')\n        assert options.pfile is not None, 'phenotype file needs to be specified'\n        # read pheno\n        Y = readPhenoFile(options.pfile,idx=options.trait_idx)\n        # read covariance\n        if options.cfile is None:\n            cov = {'eval':None,'evec':None}\n            warnings.warn('cfile not specifed, a one variance compoenent model will be considered')\n        else:\n            cov = readCovarianceMatrixFile(options.cfile,readCov=False)\n            assert Y.shape[0]==cov['eval'].shape[0],  'dimension mismatch'\n        # read covariates\n        F = None\n        if options.ffile is not None:\n            F = readCovariatesFile(options.ffile)\n            assert Y.shape[0]==F.shape[0], 'dimensions mismatch'\n        t0 = time.time()\n        fit_null(Y,cov['eval'],cov['evec'],options.nfile, F)\n        t1 = time.time()\n        print(('.. finished in %s seconds'%(t1-t0)))\n\n    \"\"\" precomputing the windows \"\"\"\n    if options.precompute_windows:\n        if options.wfile==None:\n            options.wfile = os.path.split(options.bfile)[-1] + '.%d'%options.window_size\n            warnings.warn('wfile not specifed, set to %s'%options.wfile)\n        print('Precomputing windows')\n        t0 = time.time()\n        pos = readBimFile(options.bfile)\n        nWnds,nSnps=splitGeno(pos,size=options.window_size,out_file=options.wfile+'.wnd')\n        print(('Number of variants:',pos.shape[0]))\n        print(('Number of windows:',nWnds))\n        print(('Minimum number of snps:',nSnps.min()))\n        print(('Maximum number of snps:',nSnps.max()))\n        t1 = time.time()\n        print(('.. finished in %s seconds'%(t1-t0)))\n\n    # plot distribution of nSnps\n    if options.plot_windows:\n        print('Plotting ditribution of number of SNPs')\n        plot_file = options.wfile+'.wnd.pdf'\n        plt = pl.subplot(1,1,1)\n        pl.hist(nSnps,30)\n        pl.xlabel('Number of SNPs')\n        pl.ylabel('Number of windows')\n        pl.savefig(plot_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_helper(app_or_project, name, directory, dist, template_dir, noadmin):\n\n    import shutil\n    if not re.search(r'^[_a-zA-Z]\\w*$', name): # If it's not a valid directory name.\n        # Provide a smart error message, depending on the error.\n        if not re.search(r'^[_a-zA-Z]', name):\n            message = 'make sure the name begins with a letter or underscore'\n        else:\n            message = 'use only numbers, letters and underscores'\n        raise CommandError(\"%r is not a valid project name. Please %s.\" % (name, message))\n    top_dir = os.path.join(directory, dist)\n    try:\n        os.mkdir(top_dir)\n    except OSError, e:\n        raise CommandError(e)\n        \n    for d, subdirs, files in os.walk(template_dir):\n        relative_dir = d[len(template_dir)+1:].replace('project_name', name)\n        if relative_dir:\n            os.mkdir(os.path.join(top_dir, relative_dir))\n        for subdir in subdirs[:]:\n            if subdir.startswith('.'):\n                subdirs.remove(subdir)\n        for f in files:\n            if not f.endswith('.py'):\n                # Ignore .pyc, .pyo, .py.class etc, as they cause various\n                # breakages.\n                continue\n            path_old = os.path.join(d, f)\n            path_new = os.path.join(top_dir, relative_dir, f.replace('project_name', name))\n            fp_old = open(path_old, 'r')\n            fp_new = open(path_new, 'w')\n            if noadmin:\n                fp_new.write(fp_old.read().replace('{{ project_name }}', name))\n            else:\n                fp_new.write(fp_old.read().replace('{{ project_name }}', name).replace('## ',''))\n            fp_old.close()\n            fp_new.close()\n            try:\n                shutil.copymode(path_old, path_new)\n                _make_writeable(path_new)\n            except OSError:\n                sys.stderr.write(style.NOTICE(\"Notice: Couldn't set permission bits on %s. You're probably using an uncommon filesystem setup. No problem.\\n\" % path_new))", "response": "Copy a Django project layout template into a distribution directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef variance_K(K, verbose=False):\n    c = SP.sum((SP.eye(len(K)) - (1.0 / len(K)) * SP.ones(K.shape)) * SP.array(K))\n    scalar = (len(K) - 1) / c\n    return 1.0/scalar", "response": "estimate the variance explained by K"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscales covariance K such that it explains unit variance", "response": "def scale_K(K, verbose=False,trace_method=True):\n    \"\"\"scale covariance K such that it explains unit variance\n    trace_method: standardize to unit trace (deafault: True)\n    \"\"\"\n    if trace_method:\n        scalar=1.0/(K.diagonal().mean())\n    else:\n        c = SP.sum((SP.eye(len(K)) - (1.0 / len(K)) * SP.ones(K.shape)) * SP.array(K))\n        scalar = (len(K) - 1) / c\n    if verbose:\n        print(('Kinship scaled by: %0.4f' % scalar))\n    K = K * scalar\n    return K"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _russianreporter_cable_ids():\n    s = urllib2.urlopen(_RR_IRI).read()\n    return set(_WL_CABLE_ID_PATTERN.findall(s))", "response": "\\ Returns a set of cable identifiers published by Russian Reporter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_square_array(arr):\n    arr = np.atleast_2d(arr)\n    if len(arr.shape) != 2 or arr.shape[0] != arr.shape[1]:\n        raise ValueError(\"Expected square array\")\n    return arr", "response": "Return arr massaged into a square array. Raises ValueError if arr cannot be massaged."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform parametric fit of the test statistics and provide permutation and test pvalues", "response": "def postprocess(options):\n    \"\"\" perform parametric fit of the test statistics and provide permutation and test pvalues \"\"\"\n\n    resdir = options.resdir\n    out_file = options.outfile\n    tol = options.tol\n\n    print('.. load permutation results')\n    file_name = os.path.join(resdir,'perm*','*.res')\n    files = glob.glob(file_name)\n    LLR0 = []\n    for _file in files:\n        print(_file)\n        LLR0.append(NP.loadtxt(_file,usecols=[6]))\n    LLR0 = NP.concatenate(LLR0)\n\n    print('.. fit test statistics')\n    t0 = time.time()\n    c2m = C2M.Chi2mixture(tol=4e-3)\n    c2m.estimate_chi2mixture(LLR0)\n    pv0 = c2m.sf(LLR0)\n    t1 = time.time()\n    print(('finished in %s seconds'%(t1-t0)))\n\n    print('.. export permutation results')\n    perm_file = out_file+'.perm'\n    RV = NP.array([LLR0,pv0]).T\n    NP.savetxt(perm_file,RV,delimiter='\\t',fmt='%.6f %.6e')\n\n    print('.. load test results')\n    file_name = os.path.join(resdir,'test','*.res')\n    files = glob.glob(file_name)\n    RV_test = []\n    for _file in files:\n        print(_file)\n        RV_test.append(NP.loadtxt(_file))\n    RV_test = NP.concatenate(RV_test)\n\n    print('.. calc pvalues')\n    pv = c2m.sf(RV_test[:,-1])[:,NP.newaxis]\n\n    print('.. export test results')\n    perm_file = out_file+'.test'\n    RV_test = NP.hstack([RV_test,pv])\n    NP.savetxt(perm_file,RV_test,delimiter='\\t',fmt='%d %d %d %d %d %d %.6e %.6e')\n\n    if options.manhattan:\n        manhattan_file = out_file+'.manhattan.jpg'\n        plot_manhattan(pv,manhattan_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef icanhaz(parser, token):\n    bits = token.contents.split()\n    if len(bits) not in [2, 3]:\n        raise template.TemplateSyntaxError(\n            \"'icanhaz' tag takes one argument: the name/id of the template\")\n    return ICanHazNode(bits[1])", "response": "Finds the ICanHaz template for the given name and renders it surrounded by\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noutputs the keywords for each source in sources.", "response": "def output_keywords_for_sources(\n        input_sources, taxonomy_name, output_mode=\"text\",\n        output_limit=None, spires=False,\n        match_mode=\"full\", no_cache=False, with_author_keywords=False,\n        rebuild_cache=False, only_core_tags=False, extract_acronyms=False,\n        **kwargs):\n    \"\"\"Output the keywords for each source in sources.\"\"\"\n    if output_limit is None:\n        output_limit = current_app.config['CLASSIFIER_DEFAULT_OUTPUT_NUMBER']\n\n    # Inner function which does the job and it would be too much work to\n    # refactor the call (and it must be outside the loop, before it did\n    # not process multiple files)\n    def process_lines():\n        if output_mode == \"text\":\n            print(\"Input file: %s\" % source)\n\n        line_nb = len(text_lines)\n        word_nb = 0\n        for line in text_lines:\n            word_nb += len(re.findall(\"\\S+\", line))\n\n        current_app.logger.info(\n            \"Remote file has %d lines and %d words.\".format(\n                line_nb, word_nb\n            )\n        )\n        return get_keywords_from_text(\n            text_lines,\n            taxonomy_name,\n            output_mode=output_mode,\n            output_limit=output_limit,\n            spires=spires,\n            match_mode=match_mode,\n            no_cache=no_cache,\n            with_author_keywords=with_author_keywords,\n            rebuild_cache=rebuild_cache,\n            only_core_tags=only_core_tags,\n            extract_acronyms=extract_acronyms\n        )\n\n    # Get the fulltext for each source.\n    for entry in input_sources:\n        current_app.logger.info(\"Trying to read input file %s.\" % entry)\n        text_lines = None\n        source = \"\"\n        if os.path.isdir(entry):\n            for filename in os.listdir(entry):\n                if filename.startswith('.'):\n                    continue\n                filename = os.path.join(entry, filename)\n                if os.path.isfile(filename):\n                    text_lines, dummy = get_plaintext_document_body(filename)\n                    if text_lines:\n                        source = filename\n                        process_lines()\n        elif os.path.isfile(entry):\n            text_lines, dummy = get_plaintext_document_body(entry)\n            if text_lines:\n                source = os.path.basename(entry)\n                process_lines()\n        else:\n            # Treat as a URL.\n            from invenio_utils.filedownload import download_url\n            local_file = download_url(entry)\n            text_lines, dummy = get_plaintext_document_body(local_file)\n            if text_lines:\n                source = entry.split(\"/\")[-1]\n                process_lines()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets keywords from a local file.", "response": "def get_keywords_from_local_file(\n        local_file, taxonomy_name, output_mode=\"text\",\n        output_limit=None, spires=False,\n        match_mode=\"full\", no_cache=False, with_author_keywords=False,\n        rebuild_cache=False, only_core_tags=False, extract_acronyms=False):\n    \"\"\"Output keywords reading a local file.\n\n    Arguments and output are the same as for :see: get_keywords_from_text().\n    \"\"\"\n    if output_limit is None:\n        output_limit = current_app.config['CLASSIFIER_DEFAULT_OUTPUT_NUMBER']\n\n    current_app.logger.info(\n        \"Analyzing keywords for local file %s.\" % local_file)\n    text_lines = text_lines_from_local_file(local_file)\n\n    return get_keywords_from_text(text_lines,\n                                  taxonomy_name,\n                                  output_mode=output_mode,\n                                  output_limit=output_limit,\n                                  spires=spires,\n                                  match_mode=match_mode,\n                                  no_cache=no_cache,\n                                  with_author_keywords=with_author_keywords,\n                                  rebuild_cache=rebuild_cache,\n                                  only_core_tags=only_core_tags,\n                                  extract_acronyms=extract_acronyms)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\",\n                           output_limit=None,\n                           spires=False, match_mode=\"full\", no_cache=False,\n                           with_author_keywords=False, rebuild_cache=False,\n                           only_core_tags=False, extract_acronyms=False):\n    \"\"\"Extract keywords from the list of strings.\n\n    :param text_lines: list of strings (will be normalized before being\n        joined into one string)\n    :param taxonomy_name: string, name of the taxonomy_name\n    :param output_mode: string - text|html|marcxml|raw\n    :param output_limit: int\n    :param spires: boolean, if True marcxml output reflect spires codes.\n    :param match_mode: str - partial|full; in partial mode only\n        beginning of the fulltext is searched.\n    :param no_cache: boolean, means loaded definitions will not be saved.\n    :param with_author_keywords: boolean, extract keywords from the pdfs.\n    :param rebuild_cache: boolean\n    :param only_core_tags: boolean\n    :return: if output_mode=raw, it will return\n        (single_keywords, composite_keywords, author_keywords, acronyms)\n        for other output modes it returns formatted string\n    \"\"\"\n    if output_limit is None:\n        output_limit = current_app.config['CLASSIFIER_DEFAULT_OUTPUT_NUMBER']\n\n    cache = get_cache(taxonomy_name)\n    if not cache:\n        set_cache(taxonomy_name,\n                  get_regular_expressions(taxonomy_name,\n                                          rebuild=rebuild_cache,\n                                          no_cache=no_cache))\n        cache = get_cache(taxonomy_name)\n    _skw = cache[0]\n    _ckw = cache[1]\n    text_lines = cut_references(text_lines)\n    fulltext = normalize_fulltext(\"\\n\".join(text_lines))\n\n    if match_mode == \"partial\":\n        fulltext = get_partial_text(fulltext)\n    author_keywords = None\n    if with_author_keywords:\n        author_keywords = extract_author_keywords(_skw, _ckw, fulltext)\n    acronyms = {}\n    if extract_acronyms:\n        acronyms = extract_abbreviations(fulltext)\n\n    single_keywords = extract_single_keywords(_skw, fulltext)\n    composite_keywords = extract_composite_keywords(\n        _ckw, fulltext, single_keywords)\n\n    if only_core_tags:\n        single_keywords = clean_before_output(\n            filter_core_keywords(single_keywords))\n        composite_keywords = filter_core_keywords(composite_keywords)\n    else:\n        # Filter out the \"nonstandalone\" keywords\n        single_keywords = clean_before_output(single_keywords)\n\n    return get_keywords_output(\n        single_keywords=single_keywords,\n        composite_keywords=composite_keywords,\n        taxonomy_name=taxonomy_name,\n        author_keywords=author_keywords,\n        acronyms=acronyms,\n        output_mode=output_mode,\n        output_limit=output_limit,\n        spires=spires,\n        only_core_tags=only_core_tags\n    )", "response": "Extract keywords from a list of text lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(infix):\n    tokens = infix.replace('(', ' ( ').replace(')', ' ) ').strip().split()\n\n    #: Holds the parsed operations\n    ops = deque()\n    #: Holds the parsed expressions\n    expressions = deque()\n\n    for token in tokens:\n        if token in TOKEN_ASSOCS:\n            while len(ops) > 0 and ops[-1] in TOKEN_ASSOCS and (\n                (TOKEN_ASSOCS[token] == ASSOC_LEFT and TOKEN_PRECS[token] <= TOKEN_PRECS[ops[-1]]) or \\\n                  (TOKEN_ASSOCS[token] == ASSOC_RIGHT and TOKEN_PRECS[token] < TOKEN_PRECS[ops[-1]])):\n                create_and_push_expression(ops.pop(), expressions)\n\n            ops.append(token)\n        elif token == '(':\n            ops.append(token)\n        elif token == ')':\n            while len(ops) > 0 and ops[-1] != '(':\n                create_and_push_expression(ops.pop(), expressions)\n\n            if len(ops) == 0:\n                raise TagExpressionError('Unclosed (')\n\n            if ops[-1] == '(':\n                ops.pop()\n        else:\n            create_and_push_expression(token, expressions)\n\n    while len(ops) > 0:\n        if ops[-1] == '(':\n            raise TagExpressionError('Unclosed )')\n        create_and_push_expression(ops.pop(), expressions)\n\n    expression = expressions.pop()\n    if len(expressions) > 0:\n        raise TagExpressionError('Not empty')\n\n    return expression", "response": "Parse the given infix string to an expression which can be evaluated with some input values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an expression from the given token and adds it to the stack of given expressions.", "response": "def create_and_push_expression(token, expressions):\n    \"\"\"Creates an expression from the given token and adds it\n    to the stack of the given expression.\n\n    In the case of \"and\" and \"or\" expressions the last expression\n    is poped from the expression stack to link it to the new\n    created one.\n    \"\"\"\n    if token == 'and':\n        right_expr = expressions.pop()\n        expressions.append(And(expressions.pop(), right_expr))\n    elif token == 'or':\n        right_expr = expressions.pop()\n        expressions.append(Or(expressions.pop(), right_expr))\n    elif token == 'not':\n        expressions.append(Not(expressions.pop()))\n    else:\n        expressions.append(Literal(token))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_to_switch(d):\n    def lookup(query):\n        return d[query]\n    lookup._always_inline_ = True\n    unrolling_items = unrolling_iterable(d.items())\n    return lookup", "response": "Convert a dictionary with integer keys to a switch statement."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mcs_to_rate(mcs, bw=20, long_gi=True):\n    if bw not in [20, 40, 80, 160]:\n        raise Exception(\"Unknown bandwidth: %d MHz\" % (bw))\n    if mcs not in MCS_TABLE:\n        raise Exception(\"Unknown MCS: %d\" % (mcs))\n\n    idx = int((math.log(bw/10, 2)-1)*2)\n    if not long_gi:\n        idx += 1\n    return MCS_TABLE[mcs][idx]", "response": "Convert MCS index to rate in Mbps."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts bit rate in Mbps to MCS index.", "response": "def rate_to_mcs(rate, bw=20, long_gi=True):\n    \"\"\"Convert bit rate to MCS index.\n\n    Args:\n        rate (float): bit rate in Mbps\n        bw (int): bandwidth, 20, 40, 80, ...\n        long_gi (bool): True if long GI is used.\n\n    Returns:\n        mcs (int): MCS index\n\n    >>> rate_to_mcs(120, bw=40, long_gi=False)\n    5\n    \"\"\"\n    if bw not in [20, 40, 80, 160]:\n        raise Exception(\"Unknown bandwidth: %d MHz\" % (bw))\n    idx = int((math.log(bw/10, 2)-1)*2)\n    if not long_gi:\n        idx += 1\n\n    for mcs, rates in MCS_TABLE.items():\n        if abs(rates[idx] - rate) < 1e-3:\n            return mcs\n\n    # failed. Try dot11a rates\n    for idx, r in enumerate(DOT11A_RATES):\n        if abs(r-rate) < 1e-3:\n            return idx\n\n    raise Exception(\"MCS not found: rate=%f, bw=%d, long_gi=%s\" %\n                    (rate, bw, long_gi))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract acronyms from the fulltext.", "response": "def extract_abbreviations(fulltext):\n    \"\"\"Extract acronyms from the fulltext.\n\n    :param fulltext: utf-8 string\n    :return: dictionary of matches in a formt {\n          <keyword object>, [matched skw or ckw object, ....]\n          }\n          or empty {}\n    \"\"\"\n    acronyms = {}\n    for k, v in get_acronyms(fulltext).items():\n        acronyms[KeywordToken(k, type='acronym')] = v\n    return acronyms"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_author_keywords(skw_db, ckw_db, fulltext):\n    akw = {}\n    for k, v in get_author_keywords(skw_db, ckw_db, fulltext).items():\n        akw[KeywordToken(k, type='author-kw')] = v\n    return akw", "response": "Find out human defined keywords in a text string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a formatted string representing the keywords in the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords. :param single_keywords: list of single keywords :param composite_keywords: list of composite keywords :param taxonomy_name: string, taxonomy name :param author_keywords: dictionary of author keywords extracted :param acronyms: dictionary of extracted acronyms :param output_mode: text|html|marc :param output_limit: int, number of maximum keywords printed (it applies to single and composite keywords separately) :param spires: boolen meaning spires output style :param only_core_tags: boolean", "response": "def get_keywords_output(single_keywords, composite_keywords, taxonomy_name,\n                        author_keywords=None, acronyms=None,\n                        output_mode=\"text\", output_limit=0, spires=False,\n                        only_core_tags=False):\n    \"\"\"Return a formatted string representing the keywords in the chosen style.\n\n    This is the main routing call, this function will\n    also strip unwanted keywords before output and limits the number\n    of returned keywords.\n\n    :param single_keywords: list of single keywords\n    :param composite_keywords: list of composite keywords\n    :param taxonomy_name: string, taxonomy name\n    :param author_keywords: dictionary of author keywords extracted\n    :param acronyms: dictionary of extracted acronyms\n    :param output_mode: text|html|marc\n    :param output_limit: int, number of maximum keywords printed (it applies\n            to single and composite keywords separately)\n    :param spires: boolen meaning spires output style\n    :param only_core_tags: boolean\n    \"\"\"\n    categories = {}\n    # sort the keywords, but don't limit them (that will be done later)\n    single_keywords_p = _sort_kw_matches(single_keywords)\n\n    composite_keywords_p = _sort_kw_matches(composite_keywords)\n\n    for w in single_keywords_p:\n        categories[w[0].concept] = w[0].type\n    for w in single_keywords_p:\n        categories[w[0].concept] = w[0].type\n\n    categories = [{'keyword': key, 'category': value}\n                  for key, value in categories.iteritems()]\n\n    complete_output = _output_complete(single_keywords_p, composite_keywords_p,\n                                       author_keywords, acronyms, spires,\n                                       only_core_tags, limit=output_limit)\n    functions = {\n        \"text\": _output_text,\n        \"marcxml\": _output_marc,\n        \"html\": _output_html,\n        \"dict\": _output_dict\n    }\n\n    if output_mode != \"raw\":\n        return functions[output_mode](complete_output, categories)\n    else:\n        if output_limit > 0:\n            return (\n                _kw(_sort_kw_matches(single_keywords, output_limit)),\n                _kw(_sort_kw_matches(composite_keywords, output_limit)),\n                author_keywords,  # this we don't limit (?)\n                _kw(_sort_kw_matches(acronyms, output_limit))\n            )\n        else:\n            return (single_keywords_p, composite_keywords_p,\n                    author_keywords, acronyms)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_marc(recid, single_keywords, composite_keywords,\n               spires=False, author_keywords=None, acronyms=None):\n    \"\"\"Create xml record.\n\n    :var recid: integer\n    :var single_keywords: dictionary of kws\n    :var composite_keywords: dictionary of kws\n    :keyword spires: please don't use, left for historical\n        reasons\n    :keyword author_keywords: dictionary of extracted keywords\n    :keyword acronyms: dictionary of extracted acronyms\n    :return: str, marxml\n    \"\"\"\n    output = ['<collection><record>\\n'\n              '<controlfield tag=\"001\">%s</controlfield>' % recid]\n\n    # no need to sort\n    single_keywords = single_keywords.items()\n    composite_keywords = composite_keywords.items()\n\n    output.append(_output_marc(\n        single_keywords,\n        composite_keywords,\n        author_keywords,\n        acronyms\n    ))\n\n    output.append('</record></collection>')\n\n    return '\\n'.join(output)", "response": "Create xml record.\n\n    :var recid: integer\n    :var single_keywords: dictionary of kws\n    :var composite_keywords: dictionary of kws\n    :keyword spires: please don't use, left for historical\n        reasons\n    :keyword author_keywords: dictionary of extracted keywords\n    :keyword acronyms: dictionary of extracted acronyms\n    :return: str, marxml"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noutputs the keywords in the MARCXML format.", "response": "def _output_marc(output_complete, categories,\n                 kw_field=None,\n                 auth_field=None,\n                 acro_field=None,\n                 provenience='Classifier'):\n    \"\"\"Output the keywords in the MARCXML format.\n\n    :var skw_matches: list of single keywords\n    :var ckw_matches: list of composite keywords\n    :var author_keywords: dictionary of extracted author keywords\n    :var acronyms: dictionary of acronyms\n    :var spires: boolean, True=generate spires output - BUT NOTE: it is\n            here only not to break compatibility, in fact spires output\n            should never be used for xml because if we read marc back\n            into the KeywordToken objects, we would not find them\n    :keyword provenience: string that identifies source (authority) that\n        assigned the contents of the field\n    :return: string, formatted MARC\n    \"\"\"\n    if kw_field is None:\n        kw_field = current_app.config[\"CLASSIFIER_RECORD_KEYWORD_FIELD\"]\n\n    if auth_field is None:\n        auth_field = current_app.config[\n            \"CLASSIFIER_RECORD_KEYWORD_AUTHOR_FIELD\"\n        ]\n\n    if acro_field is None:\n        acro_field = current_app.config[\n            \"CLASSIFIER_RECORD_KEYWORD_ACRONYM_FIELD\"\n        ]\n\n    kw_template = ('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n'\n                   '    <subfield code=\"2\">%s</subfield>\\n'\n                   '    <subfield code=\"a\">%s</subfield>\\n'\n                   '    <subfield code=\"n\">%s</subfield>\\n'\n                   '    <subfield code=\"9\">%s</subfield>\\n'\n                   '</datafield>\\n')\n\n    output = []\n\n    tag, ind1, ind2 = _parse_marc_code(kw_field)\n    for keywords in (output_complete[\"single_keywords\"],\n                     output_complete[\"core_keywords\"]):\n        for kw in keywords:\n            output.append(kw_template % (tag, ind1, ind2,\n                                         encode_for_xml(provenience),\n                                         encode_for_xml(kw), keywords[kw],\n                                         encode_for_xml(categories[kw])))\n\n    author_keywords = [keyword['author_keyword'] for keyword in\n                       output_complete[\"author_keywords\"]]\n\n    for field, keywords in ((auth_field, author_keywords),\n                            (acro_field, output_complete[\"acronyms\"])):\n        # field='' we shall not save the keywords\n        if keywords and len(keywords) and field:\n            tag, ind1, ind2 = _parse_marc_code(field)\n            for kw, info in keywords.items():\n                output.append(kw_template % (tag, ind1, ind2,\n                                             encode_for_xml(provenience),\n                                             encode_for_xml(kw), '',\n                                             encode_for_xml(categories[kw])))\n\n    return \"\".join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noutput the results obtained in text format.", "response": "def _output_text(complete_output, categories):\n    \"\"\"Output the results obtained in text format.\n\n    :return: str, html formatted output\n    \"\"\"\n    output = \"\"\n\n    for result in complete_output:\n        list_result = complete_output[result]\n        if list_result:\n            list_result_sorted = sorted(list_result,\n                                        key=lambda x: list_result[x],\n                                        reverse=True)\n            output += \"\\n\\n{0}:\\n\".format(result)\n            for element in list_result_sorted:\n                output += \"\\n{0} {1}\".format(list_result[element], element)\n\n    output += \"\\n--\"\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_singlekws(skw_matches, spires=False):\n    output = {}\n    for single_keyword, info in skw_matches:\n        output[single_keyword.output(spires)] = len(info[0])\n    output = [{'keyword': key, 'number': value}\n              for key, value in output.iteritems()]\n    return sorted(output, key=lambda x: x['number'], reverse=True)", "response": "Get single keywords.\n\n    :var skw_matches: dict of {keyword: [info,...]}\n    :keyword spires: bool, to get the spires output\n    :return: list of formatted keywords"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_compositekws(ckw_matches, spires=False):\n    output = {}\n    for composite_keyword, info in ckw_matches:\n        output[composite_keyword.output(spires)] = {\"number\": len(info[0]),\n                                                    \"details\": info[1]}\n    output = [{'keyword': key,\n               'number': value['number'],\n               'details': value['details']}\n              for key, value in output.iteritems()]\n    return sorted(output, key=lambda x: x['number'], reverse=True)", "response": "Get composite keywords.\n\n    :var ckw_matches: dict of {keyword: [info,...]}\n    :keyword spires: bool, to get the spires output\n    :return: list of formatted keywords"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a formatted list of acronyms.", "response": "def _get_acronyms(acronyms):\n    \"\"\"Return a formatted list of acronyms.\"\"\"\n    acronyms_str = {}\n    if acronyms:\n        for acronym, expansions in iteritems(acronyms):\n            expansions_str = \", \".join([\"%s (%d)\" % expansion\n                                        for expansion in expansions])\n            acronyms_str[acronym] = expansions_str\n\n    return [{'acronym': str(key), 'expansion': value.encode('utf8')}\n            for key, value in acronyms_str.iteritems()]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_fieldcodes(skw_matches, ckw_matches, spires=False):\n    fieldcodes = {}\n    output = {}\n\n    for skw, _ in skw_matches:\n        for fieldcode in skw.fieldcodes:\n            fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires))\n    for ckw, _ in ckw_matches:\n\n        if len(ckw.fieldcodes):\n            for fieldcode in ckw.fieldcodes:\n                fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires))\n        else:  # inherit field-codes from the composites\n            for kw in ckw.getComponents():\n                for fieldcode in kw.fieldcodes:\n                    fieldcodes.setdefault(fieldcode, set()).add(\n                        '%s*' % ckw.output(spires))\n                    fieldcodes.setdefault('*', set()).add(kw.output(spires))\n\n    for fieldcode, keywords in fieldcodes.items():\n        output[fieldcode] = ', '.join(keywords)\n\n    return [{'fieldcode': key, 'keywords': value}\n            for key, value in output.iteritems()]", "response": "Return the output for the field codes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_core_keywords(skw_matches, ckw_matches, spires=False):\n    output = {}\n    category = {}\n\n    def _get_value_kw(kw):\n        \"\"\"Help to sort the Core keywords.\"\"\"\n        i = 0\n        while kw[i].isdigit():\n            i += 1\n        if i > 0:\n            return int(kw[:i])\n        else:\n            return 0\n\n    for skw, info in skw_matches:\n        if skw.core:\n            output[skw.output(spires)] = len(info[0])\n            category[skw.output(spires)] = skw.type\n    for ckw, info in ckw_matches:\n        if ckw.core:\n            output[ckw.output(spires)] = len(info[0])\n        else:\n            # test if one of the components is  not core\n            i = 0\n            for c in ckw.getComponents():\n                if c.core:\n                    output[c.output(spires)] = info[1][i]\n                i += 1\n    output = [{'keyword': key, 'number': value}\n              for key, value in output.iteritems()]\n    return sorted(output, key=lambda x: x['number'], reverse=True)", "response": "Return the output for the core keywords."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_core_keywords(keywords):\n    matches = {}\n    for kw, info in keywords.items():\n        if kw.core:\n            matches[kw] = info\n    return matches", "response": "Only return keywords that are CORE."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a clean copy of the keywords data structure.", "response": "def clean_before_output(kw_matches):\n    \"\"\"Return a clean copy of the keywords data structure.\n\n    Stripped off the standalone and other unwanted elements.\n    \"\"\"\n    filtered_kw_matches = {}\n\n    for kw_match, info in iteritems(kw_matches):\n        if not kw_match.nostandalone:\n            filtered_kw_matches[kw_match] = info\n\n    return filtered_kw_matches"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _skw_matches_comparator(kw0, kw1):\n    def compare(a, b):\n        return (a > b) - (a < b)\n\n    list_comparison = compare(len(kw1[1][0]), len(kw0[1][0]))\n    if list_comparison:\n        return list_comparison\n\n    if kw0[0].isComposite() and kw1[0].isComposite():\n        component_avg0 = sum(kw0[1][1]) / len(kw0[1][1])\n        component_avg1 = sum(kw1[1][1]) / len(kw1[1][1])\n        component_comparison = compare(component_avg1, component_avg0)\n        if component_comparison:\n            return component_comparison\n\n    return compare(len(str(kw1[0])), len(str(kw0[0])))", "response": "Compare two keywords objects by the number of spans and the number of labels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning list of keywords into dictionary.", "response": "def _kw(keywords):\n    \"\"\"Turn list of keywords into dictionary.\"\"\"\n    r = {}\n    for k, v in keywords:\n        r[k] = v\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a resized version of keywords to the given length.", "response": "def _sort_kw_matches(skw_matches, limit=0):\n    \"\"\"Return a resized version of keywords to the given length.\"\"\"\n    sorted_keywords = list(skw_matches.items())\n    sorted(sorted_keywords, key=cmp_to_key(_skw_matches_comparator))\n    return limit and sorted_keywords[:limit] or sorted_keywords"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_partial_text(fulltext):\n    def _get_index(x):\n        return int(float(x) / 100 * len(fulltext))\n\n    partial_text = [\n        fulltext[_get_index(start):_get_index(end)]\n        for start, end in current_app.config[\n            \"CLASSIFIER_PARTIAL_TEXT_PERCENTAGES\"\n        ]\n    ]\n\n    return \"\\n\".join(partial_text)", "response": "Return a short version of the fulltext used with partial matching mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving keyword XML to filename.", "response": "def save_keywords(filename, xml):\n    \"\"\"Save keyword XML to filename.\"\"\"\n    tmp_dir = os.path.dirname(filename)\n    if not os.path.isdir(tmp_dir):\n        os.mkdir(tmp_dir)\n\n    file_desc = open(filename, \"w\")\n    file_desc.write(xml)\n    file_desc.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_marc_code(field):\n    field = str(field)\n    if len(field) < 4:\n        raise Exception('Wrong field code: %s' % field)\n    else:\n        field += '__'\n    tag = field[0:3]\n    ind1 = field[3].replace('_', '')\n    ind2 = field[4].replace('_', '')\n    return tag, ind1, ind2", "response": "Parse marc field and return default indicators if not filled in."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notify(request):\n    '''\n    This view gets a POST request from the Javascript part of the\n    AutoreloadPanel that contains a body that looks like::\n\n        template=/full/path/to/template.html&template=/another/template.eml:123456789&\n        media=/static/url/to/a/file:133456780&media=http://media.localhost.local/base.css\n\n    It is a list of template paths and a list of URLs that are part of the\n    static/media directories of the project. The filename might be followed by\n    a unix-epoch timestamp of the last modified date, seperated by a colon.\n\n    The view then blocks the response as long until one of the specified files\n    has a modified-time that is newer than the specified timestamp. It will\n    return a line seperated list of those changed files.\n\n    The view might also return with an empty response and status 204 (No\n    Content) if the source code that the development server runs was modified.\n    This is needed to free the current thread and allow django's runserver\n    command to reload the source code, to take those changes into account.\n    '''\n    def get_resources(names, resource_class):\n        resources = []\n        for name in names:\n            timestamp = None\n            if ':' in name:\n                name, timestamp = name.split(':', 1)\n                try:\n                    timestamp = float(timestamp)\n                except (ValueError, TypeError):\n                    timestamp = None\n            resources.append(resource_class(name, timestamp))\n        return resources\n\n    resources = get_resources(request.REQUEST.getlist('template'), Resource)\n    resources += get_resources(request.REQUEST.getlist('media'), MediaResource)\n\n    file_watcher = FileWatcher(resources)\n    suspender = Suspender()\n    updates = None\n    while not updates:\n        time.sleep(0.5)\n        # break the watching action and return a response to release the\n        # running thread. This is necessary since the looped check would\n        # prevent django from loading changed source code or quitting the\n        # development server with CTRL-C\n        if suspender.should_suspend():\n            response = HttpResponse()\n            response.status_code = 204\n            return response\n        updates = file_watcher.get_updated_files()\n    response = HttpResponse(json.dumps([\n        {'src': resource.name, 'mtime': resource.mtime}\n        for resource in updates\n    ]))\n    return response", "response": "This function is used to notify the user of a change in a file or folder. It is used to notify the user of a change in a file or folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_tree (tree, g, l):\n    runner= Ayrton (g=g, l=l)\n    return runner.run_tree (tree, 'unknown_tree')", "response": "Main entry point for remote ("}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the given code and returns the result of the function.", "response": "def run_code (self, code, file_name, argv=None):\n        if logger.parent.level<=logging.DEBUG2:  # pragma: no cover\n            logger.debug2 ('------------------')\n            logger.debug2 ('main (gobal) code:')\n            handler= logger.parent.handlers[0]\n\n            handler.acquire ()\n            dis.dis (code, file=handler.stream)\n            handler.release ()\n\n            for inst in dis.Bytecode (code):\n                if inst.opname=='LOAD_CONST':\n                    if type (inst.argval)==type (code):\n                        logger.debug ('------------------')\n                        handler.acquire ()\n                        dis.dis (inst.argval, file=handler.stream)\n                        handler.release ()\n                    elif type (inst.argval)==str:\n                        logger.debug (\"last function is called: %s\", inst.argval)\n\n        # prepare environment\n        if self.polute_globals:\n            self.globals.update (os.environ)\n\n            logger.debug (argv)\n            if argv is None:\n                argv= [ file_name ]\n            self.globals['argv']= Argv (argv)\n\n        '''\n        exec(): If only globals is provided, it must be a dictionary, which will\n        be used for both the global and the local variables. If globals and locals\n        are given, they are used for the global and local variables, respectively.\n        If provided, locals can be any mapping object. Remember that at module\n        level, globals and locals are the same dictionary. If exec gets two\n        separate objects as globals and locals, the code will be executed as if\n        it were embedded in a class definition.\n\n        If the globals dictionary does not contain a value for the key __builtins__,\n        a reference to the dictionary of the built-in module builtins is inserted\n        under that key. That way you can control what builtins are available to\n        the executed code by inserting your own __builtins__ dictionary into\n        globals before passing it to exec().\n\n        The default locals act as described for function locals() below:\n        modifications to the default locals dictionary should not be attempted.\n        Pass an explicit locals dictionary if you need to see effects of the code\n        on locals after function exec() returns.\n\n        locals(): Update and return a dictionary representing the current local\n        symbol table. Free variables are returned by locals() when it is called\n        in function blocks, but not in class blocks.\n\n        The contents of this dictionary should not be modified; changes may not\n        affect the values of local and free variables used by the interpreter.\n        '''\n        error= None\n        result= None\n        try:\n            logger.debug3 ('globals for script: %s', ayrton.utils.dump_dict (self.globals))\n            if self.params.trace:  # pragma: no cover\n                sys.settrace (self.global_tracer)\n\n            exec (code, self.globals, self.locals)\n            result= self.locals.get ('ayrton_return_value', None)\n        except Exit as e:\n            result= e.exit_value\n        except Exception as e:  # pragma: no cover\n            if self.params.pdb:\n                pdb.set_trace ()\n\n            logger.debug ('script finished by Exception')\n            logger.debug (traceback.format_exc ())\n            error= e\n        finally:  # pragma: no cover\n            sys.settrace (None)\n\n        logger.debug3 ('globals at script exit: %s', ayrton.utils.dump_dict (self.globals))\n        logger.debug3 ('locals at script exit: %s', ayrton.utils.dump_dict (self.locals))\n        logger.debug ('ayrton_return_value: %r', result)\n\n        if error is not None:\n            raise error\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nviewing decorator that checks whether the user is permitted to override (act as) users. Calls login_required in case the user is not authenticated.", "response": "def override_admin_required(view_func):\n    \"\"\"\n    View decorator that checks whether the user is permitted to override\n    (act as) users. Calls login_required in case the user is not authenticated.\n    \"\"\"\n    def wrapper(request, *args, **kwargs):\n        func_str = getattr(\n            settings, 'USERSERVICE_OVERRIDE_AUTH_MODULE',\n            'userservice.decorators.can_override_user')\n        auth_func = import_string(func_str)\n\n        if auth_func(request):\n            return view_func(request, *args, **kwargs)\n\n        return render(request, 'no_access.html', status=401)\n\n    return login_required(function=wrapper)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clone(self):\n        new_f = KalmanFilter(\n            initial_state_estimate=self._initial_state_estimate)\n        new_f._defaults = self._defaults # pylint:disable=protected-access\n        new_f.state_length = self.state_length\n        new_f.prior_state_estimates = list(self.prior_state_estimates)\n        new_f.posterior_state_estimates = list(self.posterior_state_estimates)\n        new_f.measurements = list(self.measurements)\n        new_f.process_matrices = list(self.process_matrices)\n        new_f.process_covariances = list(self.process_covariances)\n\n        return new_f", "response": "Return a shallow copy of this KalmanFilter instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict(self, control=None, control_matrix=None,\n                process_matrix=None, process_covariance=None):\n        \"\"\"\n        Predict the next *a priori* state mean and covariance given the last\n        posterior. As a special case the first call to this method will\n        initialise the posterior and prior estimates from the\n        *initial_state_estimate* and *initial_covariance* arguments passed when\n        this object was created. In this case the *process_matrix* and\n        *process_covariance* arguments are unused but are still recorded in the\n        :py:attr:`.process_matrices` and :py:attr:`.process_covariances`\n        attributes.\n\n        Args:\n            control (array or None): If specified, the control input for this\n                predict step.\n            control_matrix (array or None): If specified, the control matrix to\n                use for this time step.\n            process_matrix (array or None): If specified, the process matrix to\n                use for this time step.\n            process_covariance (array or None): If specified, the process\n                covariance to use for this time step.\n\n        \"\"\"\n        # Sanitise arguments\n        if process_matrix is None:\n            process_matrix = self._defaults['process_matrix']\n\n        if process_covariance is None:\n            process_covariance = self._defaults['process_covariance']\n\n        if control_matrix is None:\n            control_matrix = self._defaults['control_matrix']\n\n        if len(self.prior_state_estimates) == 0:\n            # Special case: first call\n            self.prior_state_estimates.append(self._initial_state_estimate)\n        else:\n            # Usual case\n            process_matrix = as_square_array(process_matrix)\n            process_covariance = as_square_array(process_covariance)\n            if process_matrix.shape[0] != process_covariance.shape[0]:\n                raise ValueError(\"Process matrix and noise have incompatible \" \\\n                    \"shapes: {} vs {}\".format(\n                        process_matrix.shape, process_covariance.shape))\n\n            if control_matrix is not None:\n                control_matrix = np.atleast_2d(control_matrix)\n            if control is not None:\n                control = np.atleast_1d(control)\n\n            # Update state mean and covariance\n            prev_posterior_mean = self.posterior_state_estimates[-1].mean\n            prev_posterior_cov = self.posterior_state_estimates[-1].cov\n\n            prior_mean = process_matrix.dot(prev_posterior_mean)\n            if control is not None:\n                prior_mean += control_matrix.dot(control)\n\n            prior_cov = process_matrix.dot(prev_posterior_cov).dot(\n                process_matrix.T) + process_covariance\n\n            self.prior_state_estimates.append(\n                MultivariateNormal(mean=prior_mean, cov=prior_cov))\n\n        # Record transition matrix\n        self.process_matrices.append(process_matrix)\n        self.process_covariances.append(process_covariance)\n\n        # Append empty list to measurements for this time step\n        self.measurements.append([])\n        self.measurement_matrices.append([])\n\n        # Seed posterior estimates with the prior one.\n        self.posterior_state_estimates.append(self.prior_state_estimates[-1])", "response": "Predict the next priori state mean and covariance given the last posterior state mean and covariance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, measurement, measurement_matrix):\n        # Sanitise input arguments\n        measurement_matrix = np.atleast_2d(measurement_matrix)\n        expected_meas_mat_shape = (measurement.mean.shape[0], self.state_length)\n        if measurement_matrix.shape != expected_meas_mat_shape:\n            raise ValueError(\"Measurement matrix is wrong shape ({}). \" \\\n                    \"Expected: {}\".format(\n                        measurement_matrix.shape, expected_meas_mat_shape))\n\n        # Add measurement list\n        self.measurements[-1].append(measurement)\n        self.measurement_matrices[-1].append(measurement_matrix)\n\n        # \"Prior\" in this case means \"before we've updated with this\n        # measurement\".\n        prior = self.posterior_state_estimates[-1]\n\n        # Compute Kalman gain\n        innovation = measurement.mean - measurement_matrix.dot(prior.mean)\n        innovation_cov = measurement_matrix.dot(prior.cov).dot(\n            measurement_matrix.T)\n        innovation_cov += measurement.cov\n        kalman_gain = prior.cov.dot(measurement_matrix.T).dot(\n            np.linalg.inv(innovation_cov))\n\n        # Update estimates\n        post = self.posterior_state_estimates[-1]\n        self.posterior_state_estimates[-1] = MultivariateNormal(\n            mean=post.mean + kalman_gain.dot(innovation),\n            cov=post.cov - kalman_gain.dot(measurement_matrix).dot(prior.cov)\n        )", "response": "Update the state of this object with the new measurement and the new matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef truncate(self, new_count):\n        self.posterior_state_estimates = self.posterior_state_estimates[:new_count]\n        self.prior_state_estimates = self.prior_state_estimates[:new_count]\n        self.measurements = self.measurements[:new_count]\n        self.process_matrices = self.process_matrices[:new_count]\n        self.process_covariances = self.process_covariances[:new_count]", "response": "Truncate the filter as if only new_count * state_count is performed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating isotopic peaks for a sum formula.", "response": "def isotopePattern(sum_formula, threshold=1e-4, rel_threshold=True, desired_prob=None):\n    \"\"\"\n    Calculates isotopic peaks for a sum formula.\n\n    :param sum_formula: text representation of an atomic composition\n    :type sum_formula: str\n    :param threshold: minimum peak abundance\n    :type threshold: float\n    :param rel_threshold: if True, threshold is relative to the highest peak, otherwise it is a probability\n    :type rel_threshold: bool\n    :param desired_prob: total probability covered by the result; if set, threshold parameter is ignored\n    :type desired_prob: float | None\n    \"\"\"\n    assert threshold >= 0 and threshold < 1\n    assert desired_prob is None or (desired_prob > 0 and desired_prob <= 1)\n\n    if desired_prob:\n        s = ims.spectrum_new_from_sf(sum_formula.encode('ascii'), desired_prob)\n    else:\n        s = ims.spectrum_new_from_sf_thr(sum_formula.encode('ascii'), threshold, rel_threshold)\n    return _new_spectrum(TheoreticalSpectrum, s)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef masses(self):\n        buf = ffi.new(\"double[]\", self.size)\n        ims.spectrum_masses(self.ptr, buf)\n        return list(buf)", "response": "returns peak masses for this image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef intensities(self):\n        buf = ffi.new(\"double[]\", self.size)\n        ims.spectrum_intensities(self.ptr, buf)\n        return list(buf)", "response": "returns peak intensities of the current set of images"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trim(self, n_peaks):\n        self.sortByIntensity()\n        ims.spectrum_trim(self.ptr, n_peaks)", "response": "Removes low - intensity peaks from the spectrum."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting peaks in raw data.", "response": "def centroids(self, window_size=5):\n        \"\"\"\n        Detects peaks in raw data.\n\n        :param mzs: sorted array of m/z values\n        :param intensities: array of corresponding intensities\n        :param window_size: size of m/z averaging window\n\n        :returns: isotope pattern containing the centroids\n        :rtype: CentroidedSpectrum\n        \"\"\"\n        self.sortByMass()\n        mzs = _cffi_buffer(self.masses, 'd')\n        intensities = _cffi_buffer(self.intensities, 'f')\n        n = self.size\n        p = ims.spectrum_new_from_raw(n, mzs.ptr, intensities.ptr, int(window_size))\n        return _new_spectrum(CentroidedSpectrum, p)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef centroids(self, instrument, min_abundance=1e-4, points_per_fwhm=25):\n        assert self.ptr != ffi.NULL\n        centroids = ims.spectrum_envelope_centroids(self.ptr, instrument.ptr,\n                                                    min_abundance, points_per_fwhm)\n        return _new_spectrum(CentroidedSpectrum, centroids)", "response": "Estimates centroided peaks for a given instrument model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef envelope(self, instrument):\n        def envelopeFunc(mz):\n            if isinstance(mz, numbers.Number):\n                return ims.spectrum_envelope(self.ptr, instrument.ptr, mz)\n            mzs = _cffi_buffer(mz, 'd')\n            n = len(mz)\n            buf = _cffi_buffer(n, 'f')\n            ret = ims.spectrum_envelope_plot(self.ptr, instrument.ptr, mzs.ptr, n, buf.ptr)\n            if ret < 0:\n                _raise_ims_exception()\n            return buf.python_data()\n\n        return envelopeFunc", "response": "Computes the isotopic envelope for a given instrument model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef charged(self, charge):\n        result = self.copy()\n        result.addCharge(charge)\n        return result", "response": "Returns a new CentroidedSpectrum with appropriately shifted electrons."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trimmed(self, n_peaks):\n        result = self.copy()\n        result.trim(n_peaks)\n        return result", "response": "Returns a copy of the current one with the given number of low intensity peaks removed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering a mako. template. Template object and return the result.", "response": "def _render(tmpl, ctx):\n    \"\"\"\n    :param tmpl: mako.template.Template object\n    :param ctx: A dict or dict-like object to instantiate given\n    \"\"\"\n    is_py3k = anytemplate.compat.IS_PYTHON_3\n    return tmpl.render_unicode(**ctx) if is_py3k else tmpl.render(**ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders given template string and return the result.", "response": "def renders_impl(self, template_content, context, at_paths=None,\n                     at_encoding=anytemplate.compat.ENCODING,\n                     **kwargs):\n        \"\"\"\n        Render given template string and return the result.\n\n        :param template_content: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        if \"filename\" in kwargs:\n            kwargs[\"filename\"] = None\n\n        kwargs[\"text\"] = template_content\n\n        if \"input_encoding\" not in kwargs:\n            kwargs[\"input_encoding\"] = at_encoding.lower()\n\n        if \"output_encoding\" not in kwargs:\n            kwargs[\"output_encoding\"] = at_encoding.lower()\n\n        if at_paths is not None:\n            paths = at_paths + self.lookup_options.get(\"directories\", [])\n            self.lookup_options[\"directories\"] = paths\n\n            lookup = mako.lookup.TemplateLookup(**self.lookup_options)\n            kwargs[\"lookup\"] = lookup\n\n        tmpl = mako.template.Template(**kwargs)\n        return _render(tmpl, context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender given template file and return the result.", "response": "def render_impl(self, template, context, at_paths=None,\n                    at_encoding=anytemplate.compat.ENCODING, **kwargs):\n        \"\"\"\n        Render given template file and return the result.\n\n        :param template: Template file path\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        if \"text\" in kwargs:\n            kwargs[\"text\"] = None\n\n        if \"input_encoding\" not in kwargs:\n            kwargs[\"input_encoding\"] = at_encoding.lower()\n\n        if \"output_encoding\" not in kwargs:\n            kwargs[\"output_encoding\"] = at_encoding.lower()\n\n        if at_paths is not None:\n            paths = at_paths + self.lookup_options.get(\"directories\", [])\n            self.lookup_options[\"directories\"] = paths\n\n            lookup = mako.lookup.TemplateLookup(**self.lookup_options)\n            kwargs[\"lookup\"] = lookup\n\n            template = anytemplate.utils.find_template_from_path(template,\n                                                                 paths)\n        # else:\n        #     template = anytemplate.utils.find_template_from_path(template)\n\n        kwargs[\"filename\"] = template\n\n        tmpl = mako.template.Template(**kwargs)\n        return _render(tmpl, context)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a twitter archive csv file and yields a list of tweets.", "response": "def read_csv(directory):\n    '''\n    Scrape a twitter archive csv, yielding tweet text.\n\n    Args:\n        directory (str): CSV file or (directory containing tweets.csv).\n        field (str): Field with the tweet's text (default: text).\n        fieldnames (list): The column names for a csv with no header. Must contain <field>.\n                            Leave as None to read CSV header (default: None).\n\n    Returns:\n        generator\n    '''\n    if path.isdir(directory):\n        csvfile = path.join(directory, 'tweets.csv')\n    else:\n        csvfile = directory\n\n    with open(csvfile, 'r') as f:\n        for tweet in csv.DictReader(f):\n            try:\n                tweet['text'] = tweet['text'].decode('utf-8')\n            except AttributeError:\n                pass\n\n            yield tweet"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_json(directory, data_files='data/js/tweets/*.js'):\n    '''\n    Scrape a twitter archive file.\n    Inspiration from https://github.com/mshea/Parse-Twitter-Archive\n    '''\n    files = path.join(directory, data_files)\n\n    for fname in iglob(files):\n        with open(fname, 'r') as f:\n            # Twitter's JSON first line is bogus\n            data = f.readlines()[1:]\n            data = \"\".join(data)\n            tweetlist = json.loads(data)\n\n        for tweet in tweetlist:\n            yield tweet", "response": "Read a JSON file and yield a list of tweets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset given namespace to given attribute.", "response": "def set_namespace(namespace, attribute, namespace_splitter=NAMESPACE_SPLITTER):\n    \"\"\"\n    Sets given namespace to given attribute.\n\n    Usage::\n\n        >>> set_namespace(\"parent\", \"child\")\n        u'parent|child'\n\n    :param namespace: Namespace.\n    :type namespace: unicode\n    :param attribute: Attribute.\n    :type attribute: unicode\n    :param namespace_splitter: Namespace splitter character.\n    :type namespace_splitter: unicode\n    :return: Namespaced attribute.\n    :rtype: unicode\n    \"\"\"\n\n    long_name = \"{0}{1}{2}\".format(namespace, namespace_splitter, attribute)\n    LOGGER.debug(\"> Namespace: '{0}', attribute: '{1}', long name: '{2}'.\".format(namespace, attribute, long_name))\n    return long_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget given attribute foundations. namespace.", "response": "def get_namespace(attribute, namespace_splitter=NAMESPACE_SPLITTER, root_only=False):\n    \"\"\"\n    Returns given attribute foundations.namespace.\n\n    Usage::\n\n        >>> get_namespace(\"grandParent|parent|child\")\n        u'grandParent|parent'\n        >>> get_namespace(\"grandParent|parent|child\", root_only=True)\n        u'grandParent'\n\n    :param attribute: Attribute.\n    :type attribute: unicode\n    :param namespace_splitter: Namespace splitter character.\n    :type namespace_splitter: unicode\n    :param root_only: Return only root foundations.namespace.\n    :type root_only: bool\n    :return: Attribute foundations.namespace.\n    :rtype: unicode\n    \"\"\"\n\n    attribute_tokens = attribute.split(namespace_splitter)\n    if len(attribute_tokens) == 1:\n        LOGGER.debug(\"> Attribute: '{0}', namespace: '{1}'.\".format(attribute, Constants.null_object))\n    else:\n        namespace = foundations.common.get_first_item(attribute_tokens) if root_only else \\\n            namespace_splitter.join(attribute_tokens[0:-1])\n        LOGGER.debug(\"> Attribute: '{0}', namespace: '{1}'.\".format(attribute, namespace))\n        return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_namespace(attribute, namespace_splitter=NAMESPACE_SPLITTER, root_only=False):\n\n    attribute_tokens = attribute.split(namespace_splitter)\n    stripped_attribute = root_only and namespace_splitter.join(attribute_tokens[1:]) or \\\n                         attribute_tokens[len(attribute_tokens) - 1]\n    LOGGER.debug(\"> Attribute: '{0}', stripped attribute: '{1}'.\".format(attribute, stripped_attribute))\n    return stripped_attribute", "response": "Removes a namespace from a given attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning given attribute leaf.", "response": "def get_leaf(attribute, namespace_splitter=NAMESPACE_SPLITTER):\n    \"\"\"\n    Returns given attribute leaf.\n\n    Usage::\n\n        >>> get_leaf(\"grandParent|parent|child\")\n        u'child'\n\n    :param attribute: Attribute.\n    :type attribute: unicode\n    :param namespace_splitter: Namespace splitter character.\n    :type namespace_splitter: unicode\n    :return: Attribute foundations.namespace.\n    :rtype: unicode\n    \"\"\"\n\n    return foundations.common.get_last_item(attribute.split(namespace_splitter))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_commodities(self):\n        if isinstance(self.available, Amount):\n            self.available = Amount(\"{0:.8f} {1}\".format(self.available.to_double(), self.currency))\n        else:\n            self.available = Amount(\"{0:.8f} {1}\".format(self.available, self.currency))\n        if isinstance(self.total, Amount):\n            self.total = Amount(\"{0:.8f} {1}\".format(self.total.to_double(), self.currency))\n        else:\n            self.total = Amount(\"{0:.8f} {1}\".format(self.total, self.currency))", "response": "Load the commodities for Amounts in this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_commodities(self):\n        if isinstance(self.amount, Amount):\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount.to_double(), self.currency))\n        else:\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount, self.currency))", "response": "Load the commodities for Amounts in this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the commodities for Amounts in this object.", "response": "def load_commodities(self):\n        \"\"\"\n        Load the commodities for Amounts in this object.\n        \"\"\"\n        if isinstance(self.fee, Amount):\n            self.fee = Amount(\"{0:.8f} {1}\".format(self.fee.to_double(), self.currency))\n        else:\n            self.fee = Amount(\"{0:.8f} {1}\".format(self.fee, self.currency))\n        if isinstance(self.amount, Amount):\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount.to_double(), self.currency))\n        else:\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount, self.currency))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef center_widget_on_screen(widget, screen=None):\n\n    screen = screen and screen or QApplication.desktop().primaryScreen()\n    desktop_width = QApplication.desktop().screenGeometry(screen).width()\n    desktop_height = QApplication.desktop().screenGeometry(screen).height()\n    widget.move(desktop_width / 2 - widget.sizeHint().width() / 2, desktop_height / 2 - widget.sizeHint().height() / 2)\n    return True", "response": "Centers given Widget on the screen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a class factory for creating a new QWidget with given ui file.", "response": "def QWidget_factory(ui_file=None, *args, **kwargs):\n    \"\"\"\n    Defines a class factory creating `QWidget <http://doc.qt.nokia.com/qwidget.html>`_ classes\n    using given ui file.\n\n    :param ui_file: Ui file.\n    :type ui_file: unicode\n    :param \\*args: Arguments.\n    :type \\*args: \\*\n    :param \\*\\*kwargs: Keywords arguments.\n    :type \\*\\*kwargs: \\*\\*\n    :return: QWidget class.\n    :rtype: QWidget\n    \"\"\"\n\n    file = ui_file or DEFAULT_UI_FILE\n    if not foundations.common.path_exists(file):\n        raise foundations.exceptions.FileExistsError(\"{0} | '{1}' ui file doesn't exists!\".format(__name__, file))\n\n    Form, Base = uic.loadUiType(file)\n\n    class QWidget(Form, Base):\n\n        \"\"\"\n        Derives from :def:`QWidget_factory` class factory definition.\n        \"\"\"\n\n        def __init__(self, *args, **kwargs):\n            \"\"\"\n            Initializes the class.\n\n            :param \\*args: Arguments.\n            :type \\*args: \\*\n            :param \\*\\*kwargs: Keywords arguments.\n            :type \\*\\*kwargs: \\*\\*\n            \"\"\"\n\n            LOGGER.debug(\"> Initializing '{0}()' class.\".format(self.__class__.__name__))\n\n            super(QWidget, self).__init__(*args, **kwargs)\n\n            self.__ui_file = file\n\n            self.__geometry = None\n\n            self.setupUi(self)\n\n        @property\n        def ui_file(self):\n            \"\"\"\n            Property for **self.__ui_file** attribute.\n\n            :return: self.__ui_file.\n            :rtype: unicode\n            \"\"\"\n\n            return self.__ui_file\n\n        @ui_file.setter\n        @foundations.exceptions.handle_exceptions(foundations.exceptions.ProgrammingError)\n        def ui_file(self, value):\n            \"\"\"\n            Setter for **self.__ui_file** attribute.\n\n            :param value: Attribute value.\n            :type value: unicode\n            \"\"\"\n\n            raise foundations.exceptions.ProgrammingError(\"{0} | '{1}' attribute is read only!\".format(\n                self.__class__.__name__, \"ui_file\"))\n\n        @ui_file.deleter\n        @foundations.exceptions.handle_exceptions(foundations.exceptions.ProgrammingError)\n        def ui_file(self):\n            \"\"\"\n            Deleter for **self.__ui_file** attribute.\n            \"\"\"\n\n            raise foundations.exceptions.ProgrammingError(\"{0} | '{1}' attribute is not deletable!\".format(\n                self.__class__.__name__, \"ui_file\"))\n\n        def show(self, setGeometry=True):\n            \"\"\"\n            Reimplements the :meth:`QWidget.show` method.\n\n            :param setGeometry: Set geometry.\n            :type setGeometry: bool\n            \"\"\"\n\n            if not setGeometry:\n                super(QWidget, self).show()\n                return\n\n            wasHidden = not self.isVisible()\n\n            if self.__geometry is None and wasHidden:\n                center_widget_on_screen(self)\n\n            super(QWidget, self).show()\n\n            if self.__geometry is not None and wasHidden:\n                self.restoreGeometry(self.__geometry)\n\n        def closeEvent(self, event):\n            \"\"\"\n            Reimplements the :meth:`QWidget.closeEvent` method.\n\n            :param event: QEvent.\n            :type event: QEvent\n            \"\"\"\n\n            self.__geometry = self.saveGeometry()\n            event.accept()\n\n    return QWidget"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_support_abstract_type(t):\n    if hasattr(t, '__origin__') and t.__origin__:\n        data_type = t.__origin__\n    else:\n        data_type = t\n    abstract_types = {\n        typing.Sequence,\n        typing.List,\n        typing.Set,\n        typing.AbstractSet,\n        typing.Mapping,\n        typing.Dict,\n    }\n    return any(type_ is data_type for type_ in abstract_types)", "response": "Check if a type is support abstract types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator over a Django Queryset ordered by the primary key.", "response": "def batched_queryset(queryset, chunksize=1000):\n    '''''\n    Iterate over a Django Queryset ordered by the primary key\n\n    This method loads a maximum of chunksize (default: 1000) rows in it's\n    memory at the same time while django normally would load all rows in it's\n    memory. Using the iterator() method only causes it to not preload all the\n    classes.\n\n    Note that the implementation of the iterator does not support ordered query sets.\n\n    Source: https://djangosnippets.org/snippets/1949/\n    '''\n    try:\n        last_pk = queryset.order_by('-pk')[0].pk\n    except IndexError:\n        # Support empty querysets\n        return\n\n    queryset = queryset.order_by('pk')\n    pk = 0\n    while pk < last_pk:\n        for row in queryset.filter(pk__gt=pk)[:chunksize]:\n            pk = row.pk\n            yield row\n        gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all VBB stop names and IDs into a Pandas dataframe.", "response": "def load_data(verbose=False):\n    \"Load all VBB stop names and IDs into a Pandas dataframe.\"\n\n    df = pd.read_csv(STOPS_PATH, usecols=['stop_id', 'stop_name'])\n    if verbose:\n        print('- Loaded %d entries from \"%s\".' % (len(df), STOPS_PATH))\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_data(df, filter_name, verbose=False):\n    \"Filter certain entries with given name.\"\n\n    # pick only entries ending with 'Berlin' in column stop_name, incl. '(Berlin)' \n    # df = df[df.stop_name.apply(lambda cell: 'Berlin' in cell)]\n    df = df[df.stop_name.apply(\n        lambda cell: filter_name.encode('utf-8') in cell)]\n\n    # remove ' (Berlin)' in column stop_name\n    # df.stop_name = df.stop_name.apply(lambda cell: re.sub(' \\(Berlin\\)', '', cell))\n\n    # remove initial 'S' and 'U' and 'S+U' in column stop_name\n    # this creates a warning!\n    # df.stop_name = df.stop_name.apply(lambda cell: re.sub('^([S\\+U]+) +(.*)', lambda m: m.groups()[1], cell))\n\n    if verbose:\n        msg = '- Filtered down to %d entries containing \"%s\".'\n        print(msg % (len(df), filter_name))\n\n    return df", "response": "Filter certain entries with given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_name_id_interactive(stop, df):\n\n    # this is very fast, but searching in a list of ca. 2900 tuples might be also\n    # fast enough, and that would mean removing some repeated preprocessing...\n\n    # pick only entries containing the given stop substring in column stop_name\n    df1 = df[df.stop_name.apply(lambda cell: stop.lower() in cell.lower())]\n    df1 = df1.sort_values(by=['stop_name'])\n    df1_len = len(df1)\n    if df1_len == 1:\n        result = {\n            'stop_id': df1.iloc[0].stop_id,\n            'stop_name': df1.iloc[0].stop_name\n        }\n        return result\n    elif df1_len > 1:\n        msg = 'Please pick one of the following matching stop names:'\n        termcolor.cprint(msg, attrs=['bold'])\n        fmt = '%%%dd. %%s' % len(str(df1_len))\n        for i, (index, _id, stop_name) in enumerate(df1.itertuples()):\n            print(fmt % (i, stop_name))\n\n        try:\n            msg = 'Please select index of desired stop '\\\n                  'in list above (0-%d): ' % (df1_len - 1)\n            msg = termcolor.colored(msg, attrs=['bold'])\n            result = raw_input(msg)\n        except KeyboardInterrupt:\n            print('')\n            return\n\n        try:\n            i = int(result)\n        except ValueError:\n            msg = \"'%s' is not an integer number.\" % result\n            termcolor.cprint(msg, 'red', attrs=['bold'])\n            return\n\n        if not 0 <= i <= df1_len - 1:\n            msg = 'Invalid index.'\n            termcolor.cprint(msg, 'red', attrs=['bold'])\n            return\n\n        result = {\n            'stop_id': df1.iloc[i].stop_id,\n            'stop_name': df1.iloc[i].stop_name\n        }\n        return result", "response": "Get VBB or BVG ID for given stop name in given table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate waiting time until the next departure time in the future.", "response": "def wait_time(departure, now=None):\n    \"\"\"\n    Calculate waiting time until the next departure time in 'HH:MM' format.\n\n    Return time-delta (as 'MM:SS') from now until next departure time in the \n    future ('HH:MM') given as (year, month, day, hour, minute, seconds). \n    Time-deltas shorter than 60 seconds are reduced to 0.\n    \"\"\"\n\n    now = now or datetime.datetime.now()\n    yn, mn, dn = now.year, now.month, now.day\n    hour, minute = map(int, departure.split(':'))\n    dt = datetime.datetime(yn, mn, dn, hour=hour, minute=minute)\n    delta = (dt - now).seconds\n    if (dt - now).days < 0:\n        delta = 0\n    if delta < 3600:\n        return '%02d:%02d' % (delta // 60, delta % 60)\n    else:\n        delta_hh = delta // 3600\n        delta_rest = delta - delta_hh * 3600\n        return '%02d:%02d:%02d' % (delta_hh, delta_rest // 60, delta_rest % 60)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_next_departures(stop, filter_line=None, num_line_groups=1, verbose=False):\n\n    # Get departures table from online service\n    # (great: we don't have to iterate over multiple pages).\n\n    url = BVG_URL_PAT % stop\n    if verbose:\n        print('- Fetching table for URL \"%s\".' % url)\n    try:\n        tables = pd.read_html(url.encode('utf-8'))\n    except urllib.error.URLError:\n        msg = 'Not connected to the internet?'\n        termcolor.cprint(msg, 'red', attrs=['bold'])\n        sys.exit(1)\n    except ValueError:\n        return []\n    table = tables[0]\n    table.columns = ['Departure', 'Line', 'Destination']\n\n    if verbose:\n        print('- Got table with %d entries for \"%s\".' % (len(table), stop))\n\n    # Cleanup\n\n    # Drop entries with '*' in column Departure...\n    # (causes trouble when resulting in an empty table!)\n    # table = table[table.Departure.apply(lambda row: \" *\" not in row)]\n    # So, instead remove '*' in column Departure...\n    table.is_copy = False # prevents SettingWithCopyWarning\n    table.Departure = table.apply(\n        lambda row: re.sub('\\s*\\*\\s*', '', row.Departure), axis=1)\n\n    # Replace regex ' +' with ' ' in column Line...\n    table.Line = table.apply(lambda row: re.sub(' +', ' ', row.Line), axis=1)\n\n    # Filter desired number of unique combinations of Line and Destination column.\n    indices = []\n    for i in range(num_line_groups):\n        try:\n            indices += sorted([tab.index.values[i] \n                for line_dest, tab in table.groupby(['Line', 'Destination'])])\n        except IndexError:\n            break\n    table = table[table.index.map(lambda x: x in indices)]\n\n    # Insert a left-most column with minutes and seconds from now \n    # until the departure time.\n    table.insert(0, \"Wait\", table.Departure.apply(lambda dep: wait_time(dep)))\n\n    # Filter on desired lines only\n    if filter_line:\n        table = table[table.Line.apply(\n            lambda cell: filter_line.lower().encode('utf-8') in cell.lower())]\n\n    return table", "response": "Get all real - time departure times for given stop and return as filtered table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_header(**header):\n    \"Display a HTTP-style header on the command-line.\"\n\n    print('%s: %s' % ('Now', header['now']))\n    print('%s: %s' % ('Stop-Name', header['name']))\n    print('%s: %s' % ('Stop-ID', header.get('id', None)))\n    print('')", "response": "Display a HTTP - style header on the command - line."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_table(args):\n    \"Output table on standard out.\"\n\n    df = load_data(verbose=args.verbose)\n    df = filter_data(df, filter_name=args.filter_name, verbose=args.verbose)\n\n    stop = re.sub(' +', ' ', args.stop)\n    if re.match('^\\d+$', stop.decode('utf-8')):\n        _id = stop\n        name = df[df.stop_id==int(_id)].stop_name.item()\n    else:\n        result = get_name_id_interactive(stop, df)\n        if not result:\n            return\n        name, _id = result['stop_name'], result['stop_id']\n\n    now = datetime.datetime.now().strftime('%H:%M:%S')\n    tab = get_next_departures(_id, filter_line=args.filter_line, \n        num_line_groups=args.num_line_groups, verbose=args.verbose)\n\n    if args.header:\n        show_header(now=now, name=name, id=_id)\n    if len(tab) > 0:\n        tabl = [row[1:]for row in tab.itertuples()]\n        print(tabulate(tabl, headers=list(tab.columns),\n            tablefmt=args.tablefmt))\n    else:\n        print('No departures found.')", "response": "Output table on standard out."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow ( print out ) current environment variables.", "response": "def show():\n    \"\"\"Show (print out) current environment variables.\"\"\"\n    env = get_environment()\n\n    for key, val in sorted(env.env.items(), key=lambda item: item[0]):\n        click.secho('%s = %s' % (key, val))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwalking through src and generates the CSV file out", "response": "def generate_csv(src, out):\n    \"\"\"\\\n    Walks through `src` and generates the CSV file `out`\n    \"\"\"\n    writer = UnicodeWriter(open(out, 'wb'), delimiter=';')\n    writer.writerow(('Reference ID', 'Created', 'Origin', 'Subject'))\n    for cable in cables_from_source(src, predicate=pred.origin_filter(pred.origin_germany)):\n        writer.writerow((cable.reference_id, cable.created, cable.origin, titlefy(cable.subject)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a single cable object.", "response": "def handle_cable(cable, handler, standalone=True):\n    \"\"\"\\\n    Emits event from the provided `cable` to the handler.\n\n    `cable`\n        A cable object.\n    `handler`\n        A ICableHandler instance.\n    `standalone`\n        Indicates if a `start` and `end` event should be\n        issued (default: ``True``).\n        If `standalone` is set to ``False``, no ``handler.start()``\n        and ``handler.end()`` event will be issued.\n    \"\"\"\n    def datetime(dt):\n        date, time = dt.split(u' ')\n        if len(time) == 5:\n            time += u':00'\n        time += u'Z'\n        return u'T'.join([date, time])\n    if standalone:\n        handler.start()\n    handler.start_cable(cable.reference_id, cable.canonical_id)\n    for iri in cable.wl_uris:\n        handler.handle_wikileaks_iri(iri)\n    handler.handle_creation_datetime(datetime(cable.created))\n    if cable.released:\n        handler.handle_release_date(cable.released[:10])\n    if cable.nondisclosure_deadline:\n        handler.handle_nondisclosure_deadline(cable.nondisclosure_deadline)\n    if cable.transmission_id:\n        handler.handle_transmission_id(cable.transmission_id)\n    if cable.subject:\n        handler.handle_subject(cable.subject)\n    if cable.summary:\n        handler.handle_summary(cable.summary)\n    if cable.comment:\n        handler.handle_comment(cable.comment)\n    handler.handle_header(cable.header)\n    handler.handle_content(cable.content)\n    handler.handle_origin(cable.origin)\n    handler.handle_classification(cable.classification)\n    handler.handle_partial(cable.partial)\n    for cat in cable.classification_categories:\n        handler.handle_classification_category(cat)\n    for classificationist in cable.classificationists:\n        handler.handle_classificationist(classificationist)\n    for signer in cable.signers:\n        handler.handle_signer(signer)\n    for tag in cable.tags:\n        handler.handle_tag(tag)\n    for iri in cable.media_uris:\n        handler.handle_media_iri(iri)\n    for rec in cable.recipients:\n        handler.handle_recipient(rec)\n    for rec in cable.info_recipients:\n        handler.handle_info_recipient(rec)\n    for ref in cable.references:\n        handler.handle_reference(ref)\n    handler.end_cable()\n    if standalone:\n        handler.end()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the given cables and sets up the handler.", "response": "def handle_cables(cables, handler):\n    \"\"\"\\\n    Issues one ``handler.start()`` event, processes all `cables` and\n    issues a ``handler.end()`` event.\n\n    `cables`\n        An iterable of Cable objects.\n    `handler`\n        The `ICableHandler` instance which should receive the events.\n    \"\"\"\n    handler.start()\n    for cable in cables:\n        handle_cable(cable, handler, False)\n    handler.end()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a view function that handles OAuth authorization requests.", "response": "def make_authorization_endpoint(missing_redirect_uri,\n                                authorization_endpoint_uri,\n                                authorization_template_name):\n  \"\"\" Returns a endpoint that handles OAuth authorization requests.\n\n\n  The template described by ``authorization_template_name`` is rendered with a\n  Django ``RequestContext`` with the following variables:\n\n  * ``form``: a Django ``Form`` that may hold data internal to the ``djoauth2``\n    application.\n  * ``client``: The :py:class:`djoauth2.models.Client` requesting access to the\n    user's scopes.\n  * ``scopes``: A list of :py:class:`djoauth2.models.Scope`, one for each of\n    the scopes requested by the client.\n  * ``form_action``: The URI to which the form should be submitted -- use this\n    value in the ``action=\"\"`` attribute on a ``<form>`` element.\n\n  :param missing_redirect_uri: a string, the URI to which to redirect the user\n      when the request is made by a client without a valid redirect URI.\n\n  :param authorization_endpoint_uri: a string, the URI of this endpoint. Used\n      by the authorization form so that the form is submitted to this same\n      endpoint.\n\n  :param authorization_template_name: a string, the name of the template to\n      render when handling authorization requests.\n\n  :rtype: A view function endpoint.\n  \"\"\"\n  @login_required\n  @require_http_methods(['GET', 'POST'])\n  def authorization_endpoint(request):\n    auth_code_generator = AuthorizationCodeGenerator(missing_redirect_uri)\n\n    try:\n      auth_code_generator.validate(request)\n    except AuthorizationError as authorization_error:\n      return auth_code_generator.make_error_redirect(authorization_error)\n\n    if request.method == 'GET':\n      return render(request, authorization_template_name, {\n          'form': Form(),\n          'client': auth_code_generator.client,\n          'scopes': auth_code_generator.valid_scope_objects,\n          'form_action': update_parameters(\n              authorization_endpoint_uri,\n              auth_code_generator.get_request_uri_parameters(as_dict=True)),\n        })\n\n    if request.method == 'POST':\n      form = Form(request)\n      if form.is_valid() and request.POST.get('user_action') == 'Accept':\n        return auth_code_generator.make_success_redirect()\n      else:\n        return auth_code_generator.make_error_redirect()\n\n  return authorization_endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating a Client s authorization request.", "response": "def validate(self, request):\n    \"\"\" Check that a Client's authorization request is valid.\n\n    If the request is invalid or malformed in any way, raises the appropriate\n    exception.  Read `the relevant section of the specification\n    <http://tools.ietf.org/html/rfc6749#section-4.1 .>`_ for descriptions of\n    each type of error.\n\n    :raises: a :py:class:`AuthorizationError` if the request is invalid.\n    \"\"\"\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1 :\n    #\n    #     The authorization server MUST support the use of the HTTP \"GET\"\n    #     method [RFC2616] for the authorization endpoint and MAY support the\n    #     use of the \"POST\" method as well.\n    #\n    if not request.method in ['GET', 'POST']:\n      raise InvalidRequest('must be GET or POST request')\n\n    if settings.DJOAUTH2_SSL_ONLY and not request.is_secure():\n      raise InvalidRequest('all requests must use TLS')\n\n    self.request = request\n    self.user = request.user\n    if not self.user.is_authenticated():\n      raise UnauthenticatedUser('user must be authenticated')\n\n    client_id = request.REQUEST.get('client_id')\n    if not client_id:\n      raise InvalidRequest('no \"client_id\" provided')\n\n    try:\n      self.client = Client.objects.get(key=client_id)\n    except Client.DoesNotExist:\n      raise InvalidRequest('\"client_id\" does not exist')\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1.2.3 :\n    #\n    #     If multiple redirection URIs have been registered, if only part of\n    #     the redirection URI has been registered, or if no redirection URI has\n    #     been registered, the client MUST include a redirection URI with the\n    #     authorization request using the \"redirect_uri\" request parameter.\n    #\n    self.request_redirect_uri = request.REQUEST.get('redirect_uri')\n    if not (self.client.redirect_uri or self.request_redirect_uri):\n      raise InvalidRequest('no \"redirect_uri\" provided or registered')\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1.2.3 :\n    #\n    #     When a redirection URI is included in an authorization request, the\n    #     authorization server MUST compare and match the value received\n    #     against at least one of the registered redirection URIs (or URI\n    #     components) as defined in [RFC3986] Section 6, if any redirection\n    #     URIs were registered.  If the client registration included the full\n    #     redirection URI, the authorization server MUST compare the two URIs\n    #     using simple string comparison as defined in [RFC3986] Section 6.2.1.\n    #\n    if (self.client.redirect_uri and\n          self.request_redirect_uri and\n          self.client.redirect_uri != self.request_redirect_uri):\n      raise InvalidRequest('\"redirect_uri\" does not matched the registered URI')\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1.2 :\n    #\n    #     The redirection endpoint URI MUST be an absolute URI as defined by\n    #     [RFC3986] Section 4.3.\n    #\n    redirect_uri = self.client.redirect_uri or self.request_redirect_uri\n    if not absolute_http_url_re.match(redirect_uri):\n      raise InvalidRequest('\"redirect_uri\" must be absolute')\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1.2 :\n    #\n    #     The endpoint URI MUST NOT include a fragment component.\n    #\n    if urlparse(redirect_uri).fragment:\n      raise InvalidRequest('\"redirect_uri\" must not contain a fragment')\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1.2.1 :\n    #\n    #     The redirection endpoint SHOULD require the use of TLS as described\n    #     in Section 1.6 when the requested response type is \"code\" or \"token\",\n    #     or when the redirection request will result in the transmission of\n    #     sensitive credentials over an open network.  This specification does\n    #     not mandate the use of TLS because at the time of this writing,\n    #     requiring clients to deploy TLS is a significant hurdle for many\n    #     client developers.  If TLS is not available, the authorization server\n    #     SHOULD warn the resource owner about the insecure endpoint prior to\n    #     redirection (e.g., display a message during the authorization\n    #     request).\n    #\n    if (settings.DJOAUTH2_SSL_ONLY and\n        urlparse(redirect_uri).scheme != 'https'):\n      raise InvalidRequest('\"redirect_uri\" must use TLS')\n\n    # Only store the redirect_uri value if it validates successfully. The\n    # 'make_error_redirect' method will use the 'missing_redirect_uri' passed\n    # to the '__init__' method if 'self.redirect_uri' is None.\n    self.redirect_uri = redirect_uri\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.1.1 :\n    #\n    #     The client informs the authorization server of the desired grant type\n    #     using the following parameter:\n    #\n    #     response_type\n    #           REQUIRED.  The value MUST be one of \"code\" for requesting an\n    #           authorization code as described by Section 4.1.1, \"token\" for\n    #           requesting an access token (implicit grant) as described by\n    #           Section 4.2.1, or a registered extension value as described by\n    #           Section 8.4.\n    #\n    # This implementation only supports the \"code\" \"response_type\".\n    response_type = request.REQUEST.get('response_type')\n    if response_type != 'code':\n      raise UnsupportedResponseType('\"response_type\" must be \"code\"')\n\n    # As recommended by http://tools.ietf.org/html/rfc6749#section-4.1.1 :\n    #\n    #     state\n    #           RECOMMENDED.  An opaque value used by the client to maintain\n    #           state between the request and callback.  The authorization\n    #           server includes this value when redirecting the user-agent back\n    #           to the client.  The parameter SHOULD be used for preventing\n    #           cross-site request forgery as described in Section 10.12.\n    #\n    # and necessary for the CSRF recommendation mandated by\n    # http://tools.ietf.org/html/rfc6749#section-10.12 :\n    #\n    #     The client MUST implement CSRF protection for its redirection URI.\n    #     This is typically accomplished by requiring any request sent to the\n    #     redirection URI endpoint to include a value that binds the request to\n    #     the user-agent's authenticated state (e.g., a hash of the session\n    #     cookie used to authenticate the user-agent).  The client SHOULD\n    #     utilize the \"state\" request parameter to deliver this value to the\n    #     authorization server when making an authorization request.\n    #\n    self.state = request.REQUEST.get('state')\n    if settings.DJOAUTH2_REQUIRE_STATE and not self.state:\n      raise InvalidRequest('\"state\" must be included')\n\n    requested_scope_string = request.REQUEST.get('scope', '')\n    if not requested_scope_string:\n      raise InvalidScope('\"scope\" must be included')\n\n    requested_scope_names = set(requested_scope_string.split(' '))\n    self.valid_scope_objects = Scope.objects.filter(\n        name__in=requested_scope_names)\n    valid_scope_names = {scope.name for scope in self.valid_scope_objects}\n    if valid_scope_names < requested_scope_names:\n      raise InvalidScope('The following scopes are invalid: {}'.format(\n          ', '.join('\"{}\"'.format(name)\n                    for name in (requested_scope_names - valid_scope_names))))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_request_uri_parameters(self, as_dict=False):\n    if not self.request:\n      raise ValueError('request must have been passed to the \"validate\" method')\n\n    return (dict if as_dict else urlencode)(self.request.REQUEST.items())", "response": "Returns the URI parameters from the request passed to the validate method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a Django HttpResponseRedirect describing the request failure.", "response": "def make_error_redirect(self, authorization_error=None):\n    \"\"\" Return a Django ``HttpResponseRedirect`` describing the request failure.\n\n    If the :py:meth:`validate` method raises an error, the authorization\n    endpoint should return the result of calling this method like so:\n\n      >>> auth_code_generator = (\n      >>>     AuthorizationCodeGenerator('/oauth2/missing_redirect_uri/'))\n      >>> try:\n      >>>   auth_code_generator.validate(request)\n      >>> except AuthorizationError as authorization_error:\n      >>>   return auth_code_generator.make_error_redirect(authorization_error)\n\n    If there is no known Client ``redirect_uri`` (because it is malformed, or\n    the Client is invalid, or if the supplied ``redirect_uri`` does not match\n    the regsitered value, or some other request failure) then the response will\n    redirect to the ``missing_redirect_uri`` passed to the :py:meth:`__init__`\n    method.\n\n    Also used to signify user denial; call this method without passing in the\n    optional ``authorization_error`` argument to return a generic\n    :py:class:`AccessDenied` message.\n\n      >>> if not user_accepted_request:\n      >>>   return auth_code_generator.make_error_redirect()\n\n    \"\"\"\n    if not self.redirect_uri:\n      return HttpResponseRedirect(self.missing_redirect_uri)\n\n    authorization_error = (authorization_error or\n                           AccessDenied('user denied the request'))\n    response_params = get_error_details(authorization_error)\n\n    # From http://tools.ietf.org/html/rfc6749#section-4.1.2.1 :\n    #\n    #     REQUIRED if the \"state\" parameter was present in the client\n    #     authorization request.  The exact value received from the\n    #     client.\n    #\n    if self.state is not None:\n      response_params['state'] = self.state\n    return HttpResponseRedirect(\n        update_parameters(self.redirect_uri, response_params))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Django HttpResponseRedirect describing the request success.", "response": "def make_success_redirect(self):\n    \"\"\" Return a Django ``HttpResponseRedirect`` describing the request success.\n\n    The custom authorization endpoint should return the result of this method\n    when the user grants the Client's authorization request. The request is\n    assumed to have successfully been vetted by the :py:meth:`validate` method.\n    \"\"\"\n    new_authorization_code = AuthorizationCode.objects.create(\n        user=self.user,\n        client=self.client,\n        redirect_uri=(self.redirect_uri if self.request_redirect_uri else None)\n    )\n    new_authorization_code.scopes = self.valid_scope_objects\n    new_authorization_code.save()\n\n    response_params = {'code': new_authorization_code.value}\n    # From http://tools.ietf.org/html/rfc6749#section-4.1.2 :\n    #\n    #     REQUIRED if the \"state\" parameter was present in the client\n    #     authorization request.  The exact value received from the\n    #     client.\n    #\n    if self.state is not None:\n      response_params['state'] = self.state\n    return HttpResponseRedirect(\n        update_parameters(self.redirect_uri, response_params))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strerror(errno):\n    from pypy.module._codecs.locale import str_decode_locale_surrogateescape\n    return str_decode_locale_surrogateescape(os.strerror(errno))", "response": "Translate an error code to a message string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if this is an exception that should better not be caught.", "response": "def async(self, space):\n        \"Check if this is an exception that should better not be caught.\"\n        return (self.match(space, space.w_SystemExit) or\n                self.match(space, space.w_KeyboardInterrupt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_application_traceback(self, space, file=None):\n        \"NOT_RPYTHON: Dump a standard application-level traceback.\"\n        if file is None:\n            file = sys.stderr\n        self.print_app_tb_only(file)\n        print >> file, self.errorstr(space)", "response": "NOT_RPYTHON : Dump a standard application - level traceback."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the application - level traceback to file.", "response": "def print_app_tb_only(self, file):\n        \"NOT_RPYTHON\"\n        tb = self._application_traceback\n        if tb:\n            import linecache\n            print >> file, \"Traceback (application-level):\"\n            while tb is not None:\n                co = tb.frame.pycode\n                lineno = tb.get_lineno()\n                fname = co.co_filename\n                if fname.startswith('<inline>\\n'):\n                    lines = fname.split('\\n')\n                    fname = lines[0].strip()\n                    try:\n                        l = lines[lineno]\n                    except IndexError:\n                        l = ''\n                else:\n                    l = linecache.getline(fname, lineno)\n                print >> file, \"  File \\\"%s\\\",\" % fname,\n                print >> file, \"line\", lineno, \"in\", co.co_name\n                if l:\n                    if l.endswith('\\n'):\n                        l = l[:-1]\n                    l = \"    \" + l.lstrip()\n                    print >> file, l\n                tb = tb.next"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a nice detailed interpreter - and application - level traceback useful to debug the interpreter.", "response": "def print_detailed_traceback(self, space=None, file=None):\n        \"\"\"NOT_RPYTHON: Dump a nice detailed interpreter- and\n        application-level traceback, useful to debug the interpreter.\"\"\"\n        if file is None:\n            file = sys.stderr\n        f = io.StringIO()\n        for i in range(len(self.debug_excs)-1, -1, -1):\n            print >> f, \"Traceback (interpreter-level):\"\n            traceback.print_tb(self.debug_excs[i][2], file=f)\n        f.seek(0)\n        debug_print(''.join(['|| ' + line for line in f.readlines()]), file)\n        if self.debug_excs:\n            from pypy.tool import tb_server\n            tb_server.publish_exc(self.debug_excs[-1])\n        self.print_app_tb_only(file)\n        print >> file, '(application-level)', self.errorstr(space)\n        if AUTO_DEBUG:\n            debug.fire(self)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_exception(self, space):\n        #\n        # This method covers all ways in which the Python statement\n        # \"raise X, Y\" can produce a valid exception type and instance.\n        #\n        # In the following table, 'Class' means a subclass of BaseException\n        # and 'inst' is an instance of either 'Class' or a subclass of it.\n        #\n        # The flow object space only deals with non-advanced case.\n        #\n        #  input (w_type, w_value)... becomes...                advanced case?\n        # ---------------------------------------------------------------------\n        #  (Class, None)              (Class, Class())                no\n        #  (Class, inst)              (inst.__class__, inst)          no\n        #  (Class, tuple)             (Class, Class(*tuple))          yes\n        #  (Class, x)                 (Class, Class(x))               no\n        #  (inst, None)               (inst.__class__, inst)          no\n        #\n        w_type = self.w_type\n        w_value = self.get_w_value(space)\n\n        if space.exception_is_valid_obj_as_class_w(w_type):\n            # this is for all cases of the form (Class, something)\n            if space.is_w(w_value, space.w_None):\n                # raise Type: we assume we have to instantiate Type\n                w_value = space.call_function(w_type)\n                w_type = self._exception_getclass(space, w_value)\n            else:\n                w_valuetype = space.exception_getclass(w_value)\n                if space.exception_issubclass_w(w_valuetype, w_type):\n                    # raise Type, Instance: let etype be the exact type of value\n                    w_type = w_valuetype\n                else:\n                    if space.isinstance_w(w_value, space.w_tuple):\n                        # raise Type, tuple: assume the tuple contains the\n                        #                    constructor args\n                        w_value = space.call(w_type, w_value)\n                    else:\n                        # raise Type, X: assume X is the constructor argument\n                        w_value = space.call_function(w_type, w_value)\n                    w_type = self._exception_getclass(space, w_value)\n            if self.w_cause:\n                # ensure w_cause is of a valid type\n                if space.is_none(self.w_cause):\n                    pass\n                else:\n                    self._exception_getclass(space, self.w_cause, \"exception causes\")\n                space.setattr(w_value, space.wrap(\"__cause__\"), self.w_cause)\n            if self._application_traceback:\n                from pypy.interpreter.pytraceback import PyTraceback\n                from pypy.module.exceptions.interp_exceptions import W_BaseException\n                tb = self._application_traceback\n                if (isinstance(w_value, W_BaseException) and\n                    isinstance(tb, PyTraceback)):\n                    # traceback hasn't escaped yet\n                    w_value.w_traceback = tb\n                else:\n                    # traceback has escaped\n                    space.setattr(w_value, space.wrap(\"__traceback__\"),\n                                  space.wrap(self.get_traceback()))\n        else:\n            # the only case left here is (inst, None), from a 'raise inst'.\n            w_inst = w_type\n            w_instclass = self._exception_getclass(space, w_inst)\n            if not space.is_w(w_value, space.w_None):\n                raise OperationError(space.w_TypeError,\n                                     space.wrap(\"instance exception may not \"\n                                                \"have a separate value\"))\n            w_value = w_inst\n            w_type = w_instclass\n\n        self.w_type = w_type\n        self._w_value = w_value", "response": "Normalize the OperationError.  In other words, fix w_type and/or\n        w_value to make sure that the __class__ of w_value is exactly w_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the PyTraceback object that is currently being used for the application.", "response": "def get_traceback(self):\n        \"\"\"Calling this marks the PyTraceback as escaped, i.e. it becomes\n        accessible and inspectable by app-level Python code.  For the JIT.\n        Note that this has no effect if there are already several traceback\n        frames recorded, because in this case they are already marked as\n        escaping by executioncontext.leave() being called with\n        got_exception=True.\n        \"\"\"\n        from pypy.interpreter.pytraceback import PyTraceback\n        tb = self._application_traceback\n        if tb is not None and isinstance(tb, PyTraceback):\n            tb.frame.mark_as_escaped()\n        return tb"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrecording a __context__ for this exception from the current frame.", "response": "def record_context(self, space, frame):\n        \"\"\"Record a __context__ for this exception from the current\n        frame if one exists.\n\n        __context__ is otherwise lazily determined from the\n        traceback. However the current frame.last_exception must be\n        checked for a __context__ before this OperationError overwrites\n        it (making the previous last_exception unavailable later on).\n        \"\"\"\n        last_exception = frame.last_exception\n        if (last_exception is not None and not frame.hide() or\n            last_exception is get_cleared_operation_error(space)):\n            # normalize w_value so setup_context can check for cycles\n            self.normalize_exception(space)\n            w_value = self.get_w_value(space)\n            w_last = last_exception.get_w_value(space)\n            w_context = setup_context(space, w_value, w_last, lazy=True)\n            space.setattr(w_value, space.wrap('__context__'), w_context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the attribute self. equation from a string representation.", "response": "def set_equation_from_string(self, equation_str, fail_silently=False,\n                                 check_equation=True):\n        \"\"\"Set equation attribute from a string.\n        \n        Checks to see that the string is well-formed, and\n        then uses sympy.sympify to evaluate.\n        \n        Args:\n          equation_str (str): A string representation (in valid Python)\n            of the equation to be added.\n          fail_silently (bool): Whether to raise sympy.SympifyError if\n            equation cannot be parsed. Useful if calling from other\n            application.\n          check_equation (bool): Whether or not to run regex check\n            on the equation_str argument.\n        \"\"\"\n        if check_equation:\n            regex_check(equation_str)\n        \n        # Create Queue to allow for timeout\n        q = multiprocessing.Queue()\n        \n        def prep(conn):\n            equation, error = None, False\n            try:\n                equation = sympy.sympify(equation_str)\n            except sympy.SympifyError:\n                error = True\n            q.put((equation, error))\n        p = multiprocessing.Process(target=prep, args=(q,))\n        p.start()\n        \n        # See if we can get the equation within 5 seconds\n        try:\n            equation, error = q.get(timeout=5)\n        except queue.Empty:\n            equation, error = None, None\n        q.close()\n        \n        # If the process is still running, kill it\n        if p.is_alive():\n            p.terminate()\n            p.join()\n        \n        # Check if error was raised in sympify call.\n        # If we don't want to fail silently, recall sympify to reraise error\n        if error and not fail_silently:\n            sympy.sympify(equation_str)\n        \n        self.equation = equation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the partial derivatives of the current instance of the class.", "response": "def _calc_partials(self):\n        \"\"\"Calculate the partial derivatives\n        \n        Uses sympy.utilities.lambdify to convert equation into\n        a function that can be easily computed.\n        \n        Raises:\n          MissingEquationError: if method is called before equation is\n            attached.\n        \"\"\"\n        if not self.equation:\n            raise self.MissingEquationError('No equation attached')\n        \n        x, y = sympy.symbols('x,y')\n        compute_func = sympy.utilities.lambdify((x, y), self.equation)\n        X, Y = np.meshgrid(self.xrange, self.yrange)\n        DX, DY = np.meshgrid(np.zeros(len(self.xrange)),\n                             np.zeros(len(self.yrange)))\n        \n        # Iterate through grid and compute function value at each point\n        # If value cannot be computed, default to 0\n        # If value can be computed, scale by sqrt of the magnitude\n        for i, a in enumerate(self.xrange):\n            for j, b in enumerate(self.yrange):\n                dx = 1\n                try:\n                    dy = compute_func(a, b)\n                    n = sqrt(dx**2 + dy**2)\n                    dy /= sqrt(n)\n                    dx /= sqrt(n)\n                    DX[j][i] = dx\n                    DY[j][i] = dy\n                except (ValueError, ZeroDivisionError):\n                    pass\n        return X, Y, DX, DY"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing the plot on the figure attribute Uses matplotlib to draw and format the chart", "response": "def make_plot(self):\n        \"\"\"Draw the plot on the figure attribute\n        \n        Uses matplotlib to draw and format the chart\n        \"\"\"\n        X, Y, DX, DY = self._calc_partials()\n        \n        # Plot the values\n        self.figure = plt.Figure()\n        axes = self.figure.add_subplot(1, 1, 1)\n        axes.quiver(X, Y, DX, DY, angles='xy', color='b', edgecolors=('k',))\n        axes.axhline(color='black')\n        axes.axvline(color='black')\n        latex = sympy.latex(self.equation)\n        axes.set_title(r'Direction field for $\\frac{dy}{dx} = %s$' % latex, y=1.01)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the data out as base64 binary", "response": "def write_data(self, output):\n        \"\"\"Write the data out as base64 binary\n        \n        Args:\n          output (file-like object): Output to write figure to.\n        \"\"\"\n        if self.figure:\n            canvas = FigureCanvas(self.figure)\n            self.figure.savefig(output, format='png', bbox_inches='tight')\n            output.seek(0)\n            return output.getvalue()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the data of the field in a format that can be converted to JSON", "response": "def make_data(self):\n        \"\"\"Return data of the field in a format that can be converted to JSON\n        \n        Returns:\n          data (dict): A dictionary of dictionaries, such that for a given x, y pair,\n            data[x][y] = {\"dx\": dx, \"dy\": dy}. Note that this is transposed from the\n            matrix representation in DX and DY\n        \"\"\"\n        X, Y, DX, DY = self._calc_partials()\n        data = {}\n        import pdb\n        for x in self.xrange:\n            data[x] = {}\n            for y in self.yrange:\n                data[x][y] = {\"dx\": DX[y, x], \"dy\": DY[y, x]}\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning data as JSON", "response": "def json_data(self):\n        \"\"\"Returns data as JSON\n        \n        Returns:\n          json_data (str): JSON representation of data, as created in make_data\n        \"\"\"\n        def stringify_keys(d):\n            if not isinstance(d, dict):\n                return d\n            return dict((str(k), stringify_keys(v)) for k, v in d.items())\n        data = self.make_data()\n        json_data = json.dumps(stringify_keys(data))\n        return json_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value of the address attribute.", "response": "def address(self, value):\n        \"\"\"\n        Setter for **self.__address** attribute.\n\n        :param value: Attribute value.\n        :type value: unicode\n        \"\"\"\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"address\", value)\n        self.__address = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the port of the .", "response": "def port(self, value):\n        \"\"\"\n        Setter for **self.__port** attribute.\n\n        :param value: Attribute value.\n        :type value: int\n        \"\"\"\n\n        if value is not None:\n            assert type(value) is int, \"'{0}' attribute: '{1}' type is not 'int'!\".format(\n                \"port\", value)\n            assert type(value) >= 0 and type(value) >= 65535, \\\n                \"'{0}' attribute: '{1}' value must be in 0-65535 range!\".format(\"port\", value)\n        self.__port = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n\n        if self.__online:\n            raise foundations.exceptions.ServerOperationError(\n                \"{0} | '{1}' TCP Server is already online!\".format(self.__class__.__name__, self))\n\n        try:\n            self.__server = SocketServer.TCPServer((self.__address, self.__port), self.__handler)\n            self.__worker = threading.Thread(target=self.__server.serve_forever)\n            self.__worker.setDaemon(True)\n            self.__worker.start()\n            self.__online = True\n            LOGGER.info(\n                \"{0} | TCP Server successfully started with '{1}' address on '{2}' port using '{3}' requests handler!\".format(\n                    self.__class__.__name__, self.__address, self.__port, self.__handler.__name__))\n            return True\n        except socket.error as error:\n            if error.errno in (errno.EADDRINUSE, errno.EADDRNOTAVAIL):\n                LOGGER.warning(\n                    \"!> {0} | Cannot start TCP Server, address is already in use on port '{1}'!\".format(\n                        self.__class__.__name__, self.__port))\n            else:\n                raise error", "response": "Starts the TCP server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the TCP server.", "response": "def stop(self, terminate=False):\n        \"\"\"\n        Stops the TCP server.\n\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        if not self.__online:\n            raise foundations.exceptions.ServerOperationError(\n                \"{0} | '{1}' TCP Server is not online!\".format(self.__class__.__name__, self))\n\n        if not terminate:\n            self.__server.shutdown()\n        else:\n            self.__server._BaseServer__shutdown_request = True\n\n        self.__server = None\n        self.__worker = None\n        self.__online = False\n\n        LOGGER.info(\"{0} | TCP Server successfully stopped!\".format(self.__class__.__name__))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure_field(self, field):\n        from .models import Indexable\n\n        # This is for reverse relations, which do not have a db column\n        if field.auto_created and field.is_relation:\n            if isinstance(field, (ForeignObjectRel, ManyToOneRel)) and issubclass(field.related_model, Indexable):\n                related_properties = field.related_model.search_objects.mapping.properties.properties.to_dict()\n                self.field(field.name, {\"type\": \"nested\", \"properties\": related_properties})\n                return\n\n        if field.get_internal_type() == \"ManyToManyField\" and issubclass(field.rel.to, Indexable):\n\n            related_properties = field.rel.to.search_objects.mapping.properties.properties.to_dict()\n            self.field(field.name, {\"type\": \"nested\", \"properties\": related_properties})\n            return\n\n        if isinstance(field, models.ForeignKey):\n            # This is a related field, so it should maybe be nested?\n\n            # We only want to nest fields when they are indexable, and not parent pointers.\n            if issubclass(field.rel.to, Indexable) and not field.rel.parent_link:\n\n                related_properties = field.rel.to.search_objects.mapping.properties.properties.to_dict()\n                self.field(field.name, {\"type\": \"nested\", \"properties\": related_properties})\n                return\n\n        db_column, attname = field.db_column, field.attname\n\n        field_args = FIELD_MAPPINGS.get(field.get_internal_type())\n        if field_args:\n            self.field(db_column or attname, field_args)\n        else:\n            raise Warning(\"Can't find {}\".format(field.get_internal_type()))", "response": "This method configures an Elasticsearch Mapping field based on a Django model field."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npoke the Rancher API. Returns a Rod object instance.", "response": "def poke(url, accesskey=None, secretkey=None, __method__='GET', **req_args):\n    \"\"\"\n    Poke the Rancher API. Returns a Rod object instance. Central starting\n    point for the cattleprod package.\n    :param url: The full Rancher URL to the API endpoint.\n    :param accesskey: The rancher access key, optional.\n    :param secretkey: The rancher secret key, optional.\n    :param __method__: Internal method, don't use!\n    :param req_args: Arguments which are passed directly to the requests API.\n    The accesskey / secretkey values have precedence before simple auth\n    objects defined in here.\n    :return: A Rod instance, or anything that the URL returns on a GET request\n    \"\"\"\n    if accesskey and secretkey:\n        req_args['auth'] = (accesskey, secretkey)\n    tmp = requests.request(__method__.lower(), url, **req_args)\n    tmp.raise_for_status()\n    if tmp.headers.get('Content-Type').find(\"json\") != -1:\n        rv = _convert_to_rod(tmp.json(), **req_args)\n    else:\n        rv = tmp.content\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag(self, tag, child='', enclose=0, newline=True, **kwargs):\n        kw = kwargs.copy()\n        _class = ''\n        if '_class' in kw:\n            _class = kw.pop('_class')\n        if 'class' in kw:\n            _class += ' ' + kw.pop('class')\n        tag_class = self.tag_class.get(tag, '')\n        if tag_class:\n            #if tag_class definition starts with '+', and combine it with original value\n            if tag_class.startswith('+'):\n                kw['class'] = tag_class[1:] + ' ' + _class.lstrip()\n            else:\n                kw['class'] = tag_class.lstrip()\n        else:\n            kw['class'] = _class.lstrip()\n            \n        #process inner and outter link\n        if tag == 'a':\n            print ('------', kw)\n            href = kw.get('href', '#')\n            if href and (href.startswith('http:') or href.startswith('https:') or href.startswith('ftp:')):\n                _cls = 'outter'\n            else:\n                _cls = 'inner'\n                kw['href'] = href\n            if kw.get('class'):\n                kw['class'] = kw['class'] + ' ' + _cls\n            else:\n                kw['class'] = _cls\n            \n        attrs = ' '.join(['%s=\"%s\"' % (x, y) for x, y in sorted(kw.items()) if y])\n        if attrs:\n            attrs = ' ' + attrs\n        nline = '\\n' if newline else ''\n        if child:\n            enclose = 2\n        if enclose == 1:\n            return '<%s%s/>%s' % (tag, attrs, nline)\n        elif enclose == 2:\n            return '<%s%s>%s</%s>%s' % (tag, attrs, child, tag, nline)\n        else:\n            return '<%s%s>%s' % (tag, attrs, nline)", "response": "Return a tag string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a param from kwargs and sets it s value to default_value", "response": "def param (self, param, kwargs, default_value=False):\n        \"\"\"gets a param from kwargs, or uses a default_value. if found, it's\n        removed from kwargs\"\"\"\n        if param in kwargs:\n            value= kwargs[param]\n            del kwargs[param]\n        else:\n            value= default_value\n        setattr (self, param, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets translation maps for our standard.", "response": "def _set_transmaps(self):\n        \"\"\"Set translation maps for our standard.\"\"\"\n        if self._std == 'ascii':\n            self._lower_chars = string.ascii_lowercase\n            self._upper_chars = string.ascii_uppercase\n\n        elif self._std == 'rfc1459':\n            self._lower_chars = (string.ascii_lowercase +\n                                 ''.join(chr(i) for i in range(123, 127)))\n            self._upper_chars = (string.ascii_uppercase +\n                                 ''.join(chr(i) for i in range(91, 95)))\n\n        elif self._std == 'rfc1459-strict':\n            self._lower_chars = (string.ascii_lowercase +\n                                 ''.join(chr(i) for i in range(123, 126)))\n            self._upper_chars = (string.ascii_uppercase +\n                                 ''.join(chr(i) for i in range(91, 94)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_std(self, std):\n        if not hasattr(self, '_std'):\n            IMap.__init__(self)\n\n        # translation based on std\n        self._std = std.lower()\n\n        # set casemapping maps\n        self._set_transmaps()\n\n        # create translations\n        if self._lower_chars:\n            self._lower_trans = str.maketrans(self._upper_chars, self._lower_chars)\n        if self._upper_chars:\n            self._upper_trans = str.maketrans(self._lower_chars, self._upper_chars)", "response": "Set the standard we ll be using."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of ourself.", "response": "def copy(self):\n        \"\"\"Return a copy of ourself.\"\"\"\n        new_dict = IDict(std=self._std)\n        new_dict.update(self.store)\n        return new_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _irc_lower(self, in_string):\n        conv_string = self._translate(in_string)\n        if self._lower_trans is not None:\n            conv_string = conv_string.translate(self._lower_trans)\n        return str.lower(conv_string)", "response": "Convert us to our lower - case equivalent given our std."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _irc_upper(self, in_string):\n        conv_string = self._translate(in_string)\n        if self._upper_trans is not None:\n            conv_string = in_string.translate(self._upper_trans)\n        return str.upper(conv_string)", "response": "Convert us to our upper - case equivalent given our std."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps exposing comment s render_comment_list tag as a view.", "response": "def list(request, content_type, id):\n    \"\"\"\n    Wrapper exposing comment's render_comment_list tag as a view.\n    \"\"\"\n    # get object\n    app_label, model = content_type.split('-')\n    ctype = ContentType.objects.get(app_label=app_label, model=model)\n    obj = ctype.get_object_for_this_type(id=id)\n\n    # setup template and return result\n    t = Template(\"{% load comments %}{% render_comment_list for object %}\")\n    context = RequestContext(request)\n    context.update({'object': obj})\n    result = t.render(context)\n    return HttpResponse(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nestimates q vlaues from a list of Pvalues m pi is the fraction of expected true null", "response": "def qvalues1(PV,m=None,pi=1.0):\n    \"\"\"estimate q vlaues from a list of Pvalues\n    this algorihm is taken from Storey, significance testing for genomic ...\n    m: number of tests, (if not len(PV)), pi: fraction of expected true null (1.0 is a conservative estimate)\n    @param PV: pvalues\n    @param m:  total number of tests if PV is not the entire array.\n    @param pi: fraction of true null\n    \"\"\"\n\n    S = PV.shape\n    PV = PV.flatten()\n    if m is None:\n        m = len(PV) * 1.0\n    else:\n        m*=1.0\n    lPV = len(PV)\n\n    #1. sort pvalues\n    PV = PV.squeeze()\n    IPV = PV.argsort()\n    PV  = PV[IPV]\n\n    #2. estimate lambda\n    if pi is None:\n        lrange = sp.linspace(0.05,0.95,max(lPV/100.0,10))\n        pil    = sp.double((PV[:,sp.newaxis]>lrange).sum(axis=0))/lPV\n        pilr   = pil/(1.0-lrange)\n        #ok, I think for SNPs this is pretty useless, pi is close to 1!\n        pi =1.0\n        #if there is something useful in there use the something close to 1\n        if pilr[-1]<1.0:\n            pi = pilr[-1]\n\n    #3. initialise q values\n    QV_ = pi * m/lPV* PV\n    QV_[-1] = min(QV_[-1],1.0)\n    #4. update estimate\n    for i in range(lPV-2,-1,-1):\n        QV_[i] = min(pi*m*PV[i]/(i+1.0),QV_[i+1])\n    #5. invert sorting\n    QV = sp.zeros_like(PV)\n    QV[IPV] = QV_\n\n    QV = QV.reshape(S)\n    return QV"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nestimate lambda form a set of PV", "response": "def estimate_lambda(pv):\n    \"\"\"estimate lambda form a set of PV\"\"\"\n    LOD2 = sp.median(st.chi2.isf(pv,1))\n    L = (LOD2/0.456)\n    return (L)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pretty_path(path, _home_re=re.compile('^' + re.escape(os.path.expanduser('~') + os.sep))):\n    path = format_filename(path)\n    path = _home_re.sub('~' + os.sep, path)\n    return path", "response": "Prettify path for humans and make it Unicode."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints a styled error message while using any arguments to format the message.", "response": "def serror(message, *args, **kwargs):\n    \"\"\"Print a styled error message, while using any arguments to format the message.\"\"\"\n    if args or kwargs:\n        message = message.format(*args, **kwargs)\n    return secho(message, fg='white', bg='red', bold=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_command(self, ctx, cmd_name):\n        cmd_name = self.MAP.get(cmd_name, cmd_name)\n        return super(AliasedGroup, self).get_command(ctx, cmd_name)", "response": "Map some aliases to their real names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_context(cls, ctx, config_paths=None, project=None):\n        if ctx.obj is None:\n            ctx.obj = Bunch()\n        ctx.obj.cfg = cls(ctx.info_name, config_paths, project=project)\n        return ctx.obj.cfg", "response": "Create a configuration object and initialize it with it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the locations of the config files in alphabetical order.", "response": "def locations(self, exists=True):\n        \"\"\" Return the location of the config file(s).\n\n            A given directory will be scanned for ``*.conf`` files, in alphabetical order.\n            Any duplicates will be eliminated.\n\n            If ``exists`` is True, only existing configuration locations are returned.\n        \"\"\"\n        result = []\n        for config_files in self.config_paths:\n            if not config_files:\n                continue\n            if os.path.isdir(config_files):\n                config_files = [os.path.join(config_files, i)\n                                for i in sorted(os.listdir(config_files))\n                                if i.endswith('.conf')]\n            else:\n                config_files = [config_files]\n            for config_file in config_files:\n                if not exists or os.path.exists(config_file):\n                    config_file = os.path.abspath(config_file)\n                    if config_file in result:\n                        result.remove(config_file)\n                    result.append(config_file)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload configuration from the defined locations.", "response": "def load(self):\n        \"\"\"Load configuration from the defined locations.\"\"\"\n        if not self.loaded:\n            self.values = configobj.ConfigObj({}, **self.DEFAULT_CONFIG_OPTS)\n            for path in self.locations():\n                try:\n                    part = configobj.ConfigObj(infile=path, **self.DEFAULT_CONFIG_OPTS)\n                except configobj.ConfigObjError as cause:\n                    raise LoggedFailure(\"Error in file '{path}': {cause}\".format(path=pretty_path(path), cause=cause))\n                self.values.merge(part)\n            self.loaded = True\n        return self.values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef section(self, ctx, optional=False):\n        values = self.load()\n        try:\n            return values[ctx.info_name]\n        except KeyError:\n            if optional:\n                return configobj.ConfigObj({}, **self.DEFAULT_CONFIG_OPTS)\n            raise LoggedFailure(\"Configuration section '{}' not found!\".format(ctx.info_name))", "response": "Return the section of the config object for a specific context."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, name, default=NO_DEFAULT):\n        values = self.load()\n        try:\n            return values[name]\n        except KeyError:\n            if default is self.NO_DEFAULT:\n                raise LoggedFailure(\"Configuration value '{}' not found in root section!\".format(name))\n            return default", "response": "Returns the specified name from the root section."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the next packet without consuming it.", "response": "def peek(self):\n        \"\"\"Get the current packet without consuming it.\n        \"\"\"\n        try:\n            self._fetch()\n            pkt = self.pkt_queue[0]\n            return pkt\n        except IndexError:\n            raise StopIteration()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self):\n        if hasattr(self, \"_executed\"):\n            return self._executed\n\n        es = connections.get_connection(self._using)\n\n        if getattr(self, \"_full\", False) is False:\n            self._executed = ShallowResponse(es.search(index=self._index,\n                                                   doc_type=self._doc_type,\n                                                   body=self.to_dict(),\n                                                   **self._params),\n                                         callbacks=self._doc_type_map)\n        else:\n            self._executed = FullResponse(es.search(index=self._index,\n                                                doc_type=self._doc_type,\n                                                body=self.to_dict(),\n                                                **self._params))\n\n        return self._executed", "response": "Execute the search and return an instance of Response wrapping all\n        the data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_paths(etc_paths = [ \"/etc/\" ]):\n    global _ETC_PATHS\n    _ETC_PATHS = []\n    for p in etc_paths:\n        _ETC_PATHS.append(os.path.expanduser(p))", "response": "Sets the paths where the configuration files will be searched"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef config_filename(filename):\n    global _ETC_PATHS\n    if filename.startswith('/'):\n        _LOGGER.info(\"using absolute path for filename \\\"%s\\\"\" % filename)\n        return filename\n\n    import os.path\n    for fpath in _ETC_PATHS:\n        current_path = \"%s/%s\" % (fpath, filename)\n        if os.path.isfile(current_path):\n            current_path = os.path.realpath(current_path)\n            _LOGGER.info(\"using path \\\"%s\\\" for filename \\\"%s\\\"\" % (current_path, filename))\n            return current_path\n\n    _LOGGER.info(\"using path \\\"%s\\\" for filename \\\"%s\\\"\" % (filename, filename))\n    return filename", "response": "Returns the full path to the config file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_config(section, variables, sink, filename = None, logvars = False):\n    global _ETC_PATHS\n    import ConfigParser\n    config = ConfigParser.ConfigParser()\n    \n    if filename is None:\n        config_files = existing_config_files()\n    else:\n        config_files = []\n        for fpath in _ETC_PATHS:\n            config_files.append(\"%s/%s\" % (fpath, filename))\n    \n    config.read(config_files)\n\n    options = {}\n    if section in config.sections():\n        options = config.options(section)\n\n    for varname, value in variables.items():\n        orig_varname = varname\n        varname = varname.lower()\n        if varname in options:\n            try:\n                if isinstance(value, bool):\n                    value = config.getboolean(section, varname)\n                elif isinstance(value, int):\n                    value = config.getint(section, varname)\n                elif isinstance(value, float):\n                    value = config.getfloat(section, varname)\n                else:\n                    value = config.get(section, varname)\n                    if len(value) > 0:\n                        value = value.split(\"#\")[0].strip()\n            except:\n                raise Exception(\"Invalid value for variable %s in config file\" % orig_varname)\n                \n        varname = varname.upper()\n        sink.__dict__[varname] = value\n        if (logvars):\n            _LOGGER.debug(\"%s=%s\" % (varname, str(value)))", "response": "Reads the configuration files and sets the values for each variable in the sink dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prov(self):\n        if not self._prov:\n            self._prov = self._api.get_bundle(self._document.id, self._id)\n\n        return self._prov", "response": "Returns the provenance of this document"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeploys to the project directory in the virtualenv", "response": "def deploy_project():\n    \"\"\"\n    Deploy to the project directory in the virtualenv\n    \"\"\"\n    \n    project_root = '/'.join([deployment_root(),'env',env.project_fullname,'project'])\n    local_dir = os.getcwd()\n    \n    if env.verbosity:\n        print env.host,\"DEPLOYING project\", env.project_fullname\n    #Exclude a few things that we don't want deployed as part of the project folder\n    rsync_exclude = ['local_settings*','*.pyc','*.log','.*','/build','/dist','/media*','/static*','/www','/public','/template*']\n\n    #make site local settings if they don't already exist\n    _make_local_sitesettings()\n    created = deploy_files(local_dir, project_root, rsync_exclude=rsync_exclude)\n    if not env.patch:\n        #hook the project into sys.path\n        pyvers = run('python -V').split(' ')[1].split('.')[0:2] #Python x.x.x\n        sitepackages = ''.join(['lib/python',pyvers[0],'.',pyvers[1],'/site-packages'])\n        link_name = '/'.join([deployment_root(),'env',env.project_fullname,sitepackages,env.project_package_name])\n        target = '/'.join([project_root,env.project_package_name])\n        run(' '.join(['ln -s',target,link_name]))\n        \n        #make sure manage.py has exec permissions\n        managepy = '/'.join([target,'sitesettings','manage.py'])\n        if exists(managepy):\n            sudo('chmod ugo+x %s'% managepy)\n    \n    return created"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deploy_sitesettings():\n    \n    sitesettings = '/'.join([deployment_root(),'env',env.project_fullname,'project',env.project_package_name,'sitesettings'])\n    local_dir = os.path.join(os.getcwd(),env.project_package_name,'sitesettings')\n \n    created = deploy_files(local_dir, sitesettings)\n    if env.verbosity and created:\n        print env.host,\"DEPLOYING sitesettings\"\n        for path in created:\n            tail = path.split('/')[-1]\n            print ' * uploaded',tail", "response": "Deploy the sitesettings to the project directory in the virtualenv"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy_templates():\n    \n    deployed = None\n    if not hasattr(env, 'project_template_dir'):\n        #the normal pattern would mean the shortest path is the main one.\n        #its probably the last listed\n        length = 1000   \n        for dir in env.TEMPLATE_DIRS:\n            if dir:\n                len_dir = len(dir)\n                if len_dir < length:\n                    length = len_dir\n                    env.project_template_dir = dir\n    \n    if hasattr(env,'project_template_dir'):\n        remote_dir = '/'.join([deployment_root(),'env',env.project_fullname,'templates'])\n        if env.verbosity:\n            print env.host,\"DEPLOYING templates\", remote_dir\n        deployed = deploy_files(env.project_template_dir,remote_dir)\n    return deployed", "response": "Deploy any templates from your shortest TEMPLATE_DIRS setting returning a list of the deployed templates"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deploy_static():\n    \n    if not env.STATIC_URL or 'http://' in env.STATIC_URL: return\n    from django.core.servers.basehttp import AdminMediaHandler\n    remote_dir = '/'.join([deployment_root(),'env',env.project_fullname,'static'])\n    m_prefix = len(env.MEDIA_URL)\n    #if app media is not handled by django-staticfiles we can install admin media by default\n    if 'django.contrib.admin' in env.INSTALLED_APPS and not 'django.contrib.staticfiles' in env.INSTALLED_APPS:\n        \n        if env.MEDIA_URL and env.MEDIA_URL == env.ADMIN_MEDIA_PREFIX[:m_prefix]:\n            print \"ERROR: Your ADMIN_MEDIA_PREFIX (Application media) must not be on the same path as your MEDIA_URL (User media)\"\n            sys.exit(1)\n        admin = AdminMediaHandler('DummyApp')\n        local_dir = admin.base_dir\n        remote_dir =  ''.join([remote_dir,env.ADMIN_MEDIA_PREFIX])\n    else:\n        if env.MEDIA_URL and env.MEDIA_URL == env.STATIC_URL[:m_prefix]:\n            print \"ERROR: Your STATIC_URL (Application media) must not be on the same path as your MEDIA_URL (User media)\"\n            sys.exit(1)\n        elif env.STATIC_ROOT:\n            local_dir = env.STATIC_ROOT\n            static_url = env.STATIC_URL[1:]\n            if static_url:\n                remote_dir = '/'.join([remote_dir,static_url])\n        else: return\n    if env.verbosity:\n        print env.host,\"DEPLOYING static\",remote_dir\n    return deploy_files(local_dir,remote_dir)", "response": "Deploy static files to the current directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deploy_media():\n    if not env.MEDIA_URL or not env.MEDIA_ROOT or 'http://' in env.MEDIA_URL: return\n    local_dir = env.MEDIA_ROOT\n    \n    remote_dir = '/'.join([deployment_root(),'public']) \n    media_url = env.MEDIA_URL[1:]\n    if media_url:\n        remote_dir = '/'.join([remote_dir,media_url])\n    if env.verbosity:\n        print env.host,\"DEPLOYING media\",remote_dir    \n    deployed = deploy_files(local_dir,remote_dir)\n    \n    #make writable for www-data for file uploads\n    sudo(\"chown -R www-data:sudo %s\" % remote_dir)\n    sudo(\"chmod -R ug+w %s\"% remote_dir)\n    return deployed", "response": "Deploy MEDIA_ROOT unversioned on host\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deploy_db(rollback=False):\n    if not rollback:\n\n        if env.DEFAULT_DATABASE_ENGINE=='django.db.backends.sqlite3':\n            db_dir = '/'.join([deployment_root(),'database'])\n            db_name = ''.join([env.project_name,'_','site_1','.db'])\n            dest_db_path = '/'.join([db_dir,db_name])\n            if exists(dest_db_path): return\n            if env.verbosity:\n                print env.host,\"DEPLOYING DEFAULT SQLITE DATABASE\"\n            if not env.DEFAULT_DATABASE_NAME:\n                print \"ERROR: A database name has not been defined in your Django settings file\"\n                sys.exit(1)\n\n            if env.DEFAULT_DATABASE_NAME[0] not in [os.path.sep,'.']: #relative path\n                db_path = os.path.join(os.getcwd(),env.project_package_name,env.DEFAULT_DATABASE_NAME)\n\n            elif env.DEFAULT_DATABASE_NAME[:2] == '..':\n                print \"ERROR: Use a full expanded path to the database in your Django settings\"\n                sys.exit(1)\n            else:\n                db_path = env.DEFAULT_DATABASE_NAME\n\n            if not db_path or not os.path.exists(db_path):\n                print \"ERROR: the database %s does not exist. \\nRun python manage.py syncdb to create your database locally first, or check your settings.\"% db_path\n                sys.exit(1)\n\n            db_name = os.path.split(db_path)[1]  \n            run('mkdir -p '+db_dir)\n            put(db_path,dest_db_path)\n            #directory and file must be writable by webserver\n            sudo(\"chown -R %s:www-data %s\"% (env.user,db_dir))\n            sudo(\"chmod -R ug+w %s\"% db_dir)\n        \n        elif env.DEFAULT_DATABASE_ENGINE=='django.db.backends.':\n            print \"ERROR: The default database engine has not been defined in your Django settings file\"\n            print \"At a minimum you must define an sqlite3 database for woven to deploy, or define a database that is managed outside of woven.\"\n            sys.exit(1)\n    elif rollback and env.DEFAULT_DATABASE_ENGINE=='django.db.backends.sqlite3':\n        if env.INTERACTIVE:\n            delete = confirm('DELETE the database on the host?',default=False)\n            if delete:\n                run('rm -f '+db_name)\n    return", "response": "Deploy a sqlite database from development\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks a request for proper authentication details.", "response": "def validate(self, request):\n    \"\"\" Checks a request for proper authentication details.\n\n    Returns a tuple of ``(access_token, error_response_arguments)``, which are\n    designed to be passed to the :py:meth:`make_error_response` method.\n\n    For example, to restrict access to a given endpoint:\n\n    .. code-block:: python\n\n        def foo_bar_resource(request, *args, **kwargs):\n          authenticator = AccessTokenAuthenticator(\n              required_scope_names=('foo', 'bar'))\n\n          access_token, error_args = authenticator.validate(request)\n          if not access_token:\n            return authenticator.make_error_response(*error_args)\n\n          # ... can now return use access_token\n\n\n    :rtype: When the request validates successfully, returns a\n        a tuple of (:py:class:`djoauth2.models.AccessToken`, ``None``).  If the\n        request fails to validate, returns a tuple of (``None``,\n        ``error_details_tuple``). The ``error_details_tuple`` is a tuple of\n        arguments to use to call the :py:func:`make_error_response` method.\n\n    \"\"\"\n    # Ensure that all of the scopes that are being checked against exist.\n    # Otherwise, raise a ValueError.\n    for name in self.required_scope_names:\n      if not Scope.objects.filter(name=name).exists():\n        raise ValueError('Scope with name \"{}\" does not exist.'.format(name))\n\n    # From http://tools.ietf.org/html/rfc6750#section-3.1 :\n    #\n    #        If the request lacks any authentication information (e.g., the\n    #        client was unaware that authentication is necessary or attempted\n    #        using an unsupported authentication method), the resource server\n    #        SHOULD NOT include an error code or other error information.\n    #\n    # In the case that the request fails to validate, this flag will\n    # be returned and should be passed to the 'make_error_response' method\n    # in order to comply with the specification and restrict error information.\n    expose_errors = False\n\n    try:\n      # From http://tools.ietf.org/html/rfc6750#section-1 :\n      #\n      #     This specification defines the use of bearer tokens over HTTP/1.1\n      #     [RFC2616] using Transport Layer Security (TLS) [RFC5246] to access\n      #     protected resources.  TLS is mandatory to implement and use with\n      #     this specification; other specifications may extend this\n      #     specification for use with other protocols.  While designed for use\n      #     with access tokens\n      #\n      # and later, from http://tools.ietf.org/html/rfc6750#section-5.3 :\n      #\n      #    Always use TLS (https):  Clients MUST always use TLS [RFC5246]\n      #    (https) or equivalent transport security when making requests with\n      #    bearer tokens.  Failing to do so exposes the token to numerous\n      #    attacks that could give attackers unintended access.\n      #\n      if settings.DJOAUTH2_SSL_ONLY and not request.is_secure():\n        raise InvalidRequest('insecure request: must use TLS')\n\n      http_authorization = request.META.get('HTTP_AUTHORIZATION', '')\n      if not http_authorization:\n        raise InvalidRequest('missing HTTP_AUTHORIZATION header')\n\n      try:\n        auth_method, auth_value = http_authorization.strip().split(' ', 1)\n      except ValueError:\n        raise InvalidRequest('malformed HTTP_AUTHORIZATION header')\n\n      if auth_method != 'Bearer':\n        raise InvalidRequest('authentication method is not \"Bearer\"')\n\n      # Used in the case that the request does not validate. See comment above.\n      # At this point in the validation, it is certain that the Client\n      # attempted to authenticate via the 'Bearer' method.\n      expose_errors = True\n\n      try:\n        access_token = AccessToken.objects.get(value=auth_value)\n      except AccessToken.DoesNotExist:\n        raise InvalidToken('access token does not exist')\n\n      if access_token.is_expired():\n        raise InvalidToken('access token is expired')\n\n      if not access_token.has_scope(*self.required_scope_names):\n        raise InsufficientScope('access token has insufficient scope')\n\n      return (access_token, None)\n\n    except AuthenticationError as validation_error:\n      return (None, (validation_error, expose_errors))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an appropriate HttpResponse for an error response.", "response": "def make_error_response(self, validation_error, expose_errors):\n    \"\"\" Return an appropriate ``HttpResponse`` on authentication failure.\n\n    In case of an error, the specification only details the inclusion of the\n    ``WWW-Authenticate`` header. Additionally, when allowed by the\n    specification, we respond with error details formatted in JSON in the body\n    of the response. For more information, read the specification:\n    http://tools.ietf.org/html/rfc6750#section-3.1 .\n\n    :param validation_error: A\n      :py:class:`djoauth2.access_token.AuthenticationError` raised by the\n      :py:meth:`validate` method.\n    :param expose_errors: A boolean describing whether or not to expose error\n      information in the error response, as described by the section of the\n      specification linked to above.\n\n    :rtype: a Django ``HttpResponse``.\n    \"\"\"\n    authenticate_header = ['Bearer realm=\"{}\"'.format(settings.DJOAUTH2_REALM)]\n\n    if not expose_errors:\n      response = HttpResponse(status=400)\n      response['WWW-Authenticate'] = ', '.join(authenticate_header)\n      return response\n\n    status_code = 401\n    error_details = get_error_details(validation_error)\n\n    if isinstance(validation_error, InvalidRequest):\n      status_code = 400\n    elif isinstance(validation_error, InvalidToken):\n      status_code = 401\n    elif isinstance(validation_error, InsufficientScope):\n      error_details['scope'] = ' '.join(self.required_scope_names)\n      status_code = 403\n\n    # TODO(peter): should we return response details as JSON? This is not\n    # touched upon by the spec and may limit use of this library.  Many\n    # programmers use other transport languaes such as YAML or XML. All of the\n    # error information is already included in the headers.\n    response = HttpResponse(content=json.dumps(error_details),\n                            content_type='application/json',\n                            status=status_code)\n\n    for key, value in error_details.iteritems():\n      authenticate_header.append('{}=\"{}\"'.format(key, value))\n\n    response['WWW-Authenticate'] = ', '.join(authenticate_header)\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport the modules with the specified names.", "response": "def import_(module, objects=None, via=None):\n    \"\"\"\n    :param module: py3 compatiable module path\n    :param objects: objects want to imported, it should be a list\n    :param via: for some py2 module, you should give the import path according the\n        objects which you want to imported\n    :return: object or module\n    \"\"\"\n    if PY3:\n        mod = __import__(module, fromlist=['*'])\n    else:\n        path = modules_mapping.get(module)\n        if not path:\n            raise Exception(\"Can't find the module %s in mappings.\" % module)\n        if isinstance(path, list):\n            if not via:\n                raise Exception(\"You should give a via parameter to enable import from py2.\")\n            path = via\n        mod = __import__(path, fromlist=['*'])\n\n    if objects:\n        if not isinstance(objects, (list, tuple)):\n            raise Exception(\"objects parameter should be a list or tuple.\")\n        r = []\n        for x in objects:\n            r.append(getattr(mod, x))\n        if len(r) > 1:\n            return tuple(r)\n        else:\n            return r[0]\n    else:\n        return mod"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rts_smooth(kalman_filter, state_count=None):\n    if state_count is None:\n        state_count = kalman_filter.state_count\n\n    state_count = int(state_count)\n    if state_count < 0 or state_count > kalman_filter.state_count:\n        raise ValueError(\"Invalid state count: {}\".format(state_count))\n\n    # No states to return?\n    if state_count == 0:\n        return []\n\n    # Initialise with final posterior estimate\n    states = [None] * state_count\n    states[-1] = kalman_filter.posterior_state_estimates[-1]\n\n    priors = kalman_filter.prior_state_estimates\n    posteriors = kalman_filter.posterior_state_estimates\n\n    # Work backwards from final state\n    for k in range(state_count-2, -1, -1):\n        process_mat = kalman_filter.process_matrices[k+1]\n        cmat = posteriors[k].cov.dot(process_mat.T).dot(\n            np.linalg.inv(priors[k+1].cov))\n\n        # Calculate smoothed state and covariance\n        states[k] = MultivariateNormal(\n            mean=posteriors[k].mean + cmat.dot(states[k+1].mean -\n                                               priors[k+1].mean),\n            cov=posteriors[k].cov + cmat.dot(states[k+1].cov -\n                                             priors[k+1].cov).dot(cmat.T)\n        )\n\n    return states", "response": "Compute the Rauch - Tung - Striebel smoothed state estimates and estimate of the covariance of the Kalman filter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_environment(default=DEVELOPMENT, detectors=None, detectors_opts=None, use_envfiles=True):\n    detectors_opts = detectors_opts or {}\n\n    if detectors is None:\n        detectors = DETECTORS.keys()\n\n    env = None\n\n    for detector in detectors:\n        opts = detectors_opts.get(detector, {})\n        detector = get_detector(detector)\n\n        detector = detector(**opts)\n        env_name = detector.probe()\n\n        if env_name:\n            env = get_type(env_name)\n            break\n\n    if env is None and default is not None:\n        env = get_type(default)\n\n    if env is not None:\n        env = env()  # type: Environment\n        use_envfiles and env.update_from_envfiles()\n\n    return env", "response": "Returns the current environment type object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_name(modulename, name=None):\n    if name is None:\n        modulename, name = modulename.rsplit(':', 1)\n    module = __import__(modulename, globals(), {}, [name])\n    return getattr(module, name)", "response": "Imports identifier name from module modulename."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a Python module from a path under a specified name.", "response": "def load_module(modulename, modulepath):\n    \"\"\" Load a Python module from a path under a specified name.\n\n        Parameters:\n            modulename (str): Fully qualified module name, e.g. ``x.y.z``.\n            modulepath (str): Filename of the module.\n\n        Returns:\n            Loaded module.\n    \"\"\"\n    if '.' in modulename:\n        modulepackage, modulebase = modulename.rsplit('.', 1)\n    else:\n        modulepackage = ''\n\n    imp.acquire_lock()\n    try:\n        # Check if module is already loaded\n        if modulename not in sys.modules:\n            # Find module on disk and try to load it\n            path, name = os.path.split(modulepath)\n            name = os.path.splitext(name)[0]\n            handle, path, info = imp.find_module(name, [path])\n            try:\n                # Load the module and put into sys.modules\n                module = imp.load_module(modulename, handle, path, info)\n                if modulepackage:\n                    setattr(sys.modules[modulepackage], modulebase, module)\n            finally:\n                # Make sure handle is closed properly\n                if handle:\n                    handle.close()\n    finally:\n        imp.release_lock()\n\n    return sys.modules[modulename]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init():\n\n    if settings.USE_L10N:\n        locale = settings.LANGUAGE_CODE.replace('-', '_')\n        try:\n            humanize.i18n.activate(locale)\n        except FileNotFoundError:\n            pass  # Just let it to the default locale\n\n    HUMANIZE_FUNC_LIST = [\n        'naturalday',\n        'naturaltime',\n        'ordinal',\n        'intword',\n        'naturaldelta',\n        'intcomma',\n        'apnumber',\n        'fractional',\n        'naturalsize',\n        'naturaldate'\n    ]\n\n    # registers all humanize functions as template tags\n    for funcname in HUMANIZE_FUNC_LIST:\n        func = getattr(humanize, funcname)\n        register.filter(funcname, func, is_safe=True)", "response": "Initialize the lib\n ArcGIS library"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kill_pid(self, pid):\n        try:\n\n            p = psutil.Process(pid)\n\n            p.terminate()\n\n            self.info_log('Killed [pid:%s][name:%s]' % (p.pid, p.name()))\n        except psutil.NoSuchProcess:\n            self.error_log('No such process: [pid:%s]' % pid)", "response": "Kill process by pid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nkilling process by process name", "response": "def kill(self, procname):\n        \"\"\"Kill by process name\n\n        Args:\n            procname (str)\n        \"\"\"\n        for proc in psutil.process_iter():\n            if proc.name() == procname:\n                self.info_log(\n                    '[pid:%s][name:%s] killed' %\n                    (proc.pid, proc.name())\n                )\n                proc.kill()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure the test batch runner logger", "response": "def configure_logger(self):\n        \"\"\"Configure the test batch runner logger\n        \"\"\"\n\n        logger_name = 'brome_runner'\n\n        self.logger = logging.getLogger(logger_name)\n\n        format_ = BROME_CONFIG['logger_runner']['format']\n\n        # Stream logger\n        if BROME_CONFIG['logger_runner']['streamlogger']:\n            sh = logging.StreamHandler()\n            stream_formatter = logging.Formatter(format_)\n            sh.setFormatter(stream_formatter)\n            self.logger.addHandler(sh)\n\n        # File logger\n        if BROME_CONFIG['logger_runner']['filelogger'] and \\\n                self.runner_dir:\n\n            self.log_file_path = os.path.join(\n                    self.runner_dir,\n                    '%s.log' % logger_name\n            )\n            self.relative_log_file_path = os.path.join(\n                    self.relative_runner_dir,\n                    '%s.log' % logger_name\n            )\n\n            fh = logging.FileHandler(\n                self.log_file_path\n            )\n            file_formatter = logging.Formatter(format_)\n            fh.setFormatter(file_formatter)\n            self.logger.addHandler(fh)\n\n        self.logger.setLevel(\n            getattr(\n                logging,\n                BROME_CONFIG['logger_runner']['level']\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smartAppend(table,name,value):\n    if name not in list(table.keys()):\n        table[name] = []\n    table[name].append(value)", "response": "helper function for smartAppend"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding value to x if key is not a page of x otherwise add value to x [ key ]", "response": "def smartSum(x,key,value):\n    \"\"\" create a new page in x if key is not a page of x\n        otherwise add value to x[key] \"\"\"\n    if key not in list(x.keys()):\n        x[key] = value\n    else:   x[key]+=value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndumps a dictionary where each page is a list or an array", "response": "def dumpDictHdf5(RV,o):\n    \"\"\" Dump a dictionary where each page is a list or an array \"\"\"\n    for key in list(RV.keys()):\n        o.create_dataset(name=key,data=SP.array(RV[key]),chunks=True,compression='gzip')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smartDumpDictHdf5(RV,o):\n    for key in list(RV.keys()):\n        if type(RV[key])==dict:\n            g = o.create_group(key)\n            smartDumpDictHdf5(RV[key],g)\n        else:\n            o.create_dataset(name=key,data=SP.array(RV[key]),chunks=True,compression='gzip')", "response": "Dump a dictionary where each page is a list or an array or still a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(filename: str, format: str = None):\n\n    path = Path(filename).resolve()\n\n    with path.open() as file:\n        data = file.read()\n\n    if format is None:\n        loader, error_class = _load_autodetect, InvalidMofileFormat\n    else:\n        try:\n            loader, error_class = formats[format]\n        except KeyError:\n            raise InvalidMofileFormat(f'Unknown file format: {format}')\n\n    try:\n        config = loader(data)\n    except error_class as e:\n        raise InvalidMofileFormat(f'Unable to load task file: {e}')\n\n    return Project(config, path.parent)", "response": "Load a task file and get a Project back."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef year_origin_filter(year_predicate=None, origin_predicate=None):\n\n    def accept(cable_id, predicate):\n        year, origin = _YEAR_ORIGIN_PATTERN.match(\n            canonicalize_id(cable_id)).groups()\n        return predicate(year, origin)\n\n    if year_predicate and origin_predicate:\n        return partial(accept, predicate=lambda y, o: year_predicate(y) \\\n                                                      and origin_predicate(o))\n    elif year_predicate:\n        return partial(accept, predicate=lambda y, o: year_predicate(y))\n    elif origin_predicate:\n        return partial(accept, predicate=lambda y, o: origin_predicate(o))\n    return lambda cable_id: True", "response": "\\ Returns a predicate for cable identifiers where year_predicate and origin_predicate must hold true."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn true if the origin is located in Europe.", "response": "def origin_europe(origin):\n    \"\"\"\\\n    Returns if the origin is located in Europe.\n\n    This holds true for the following countries:\n        * Albania\n        * Armenia\n        * Austria\n        * Azerbaijan\n        * Belarus\n        * Belgium\n        * Bulgaria\n        * Bosnia and Herzegovina\n        * Bulgaria\n        * Croatia\n        * Cyprus\n        * Czech\n        * Denmark\n        * Estonia\n        * Finland\n        * France\n        * Georgia\n        * Germany\n        * Greece\n        * Hungary\n        * Iceland\n        * Ireland\n        * Italy\n        * Kazakhstan\n        * Latvia\n        * Lithuania\n        * Luxembourg\n        * Macedonia\n        * Malta\n        * Moldova\n        * Montenegro\n        * Netherlands\n        * Normway\n        * Poland\n        * Portugal\n        * Romania\n        * Russia\n        * Serbia\n        * Slovakia\n        * Slovenia\n        * Spain\n        * Sweden\n        * Switzerland\n        * Turkey\n        * Ukraine\n        * United Kingdom\n        * Vatican (Holy See)\n\n    `origin`\n        The origin to check.\n    \"\"\"\n    return origin_albania(origin) or origin_armenia(origin) \\\n           or origin_austria(origin) or origin_azerbaijan(origin) \\\n           or origin_belarus(origin) or origin_belgium(origin) \\\n           or origin_bulgaria(origin) or origin_bosnia_and_herzegovina(origin) \\\n           or origin_bulgaria(origin) \\\n           or origin_croatia(origin) or origin_cyprus(origin) \\\n           or origin_czech(origin) or origin_denmark(origin) \\\n           or origin_estonia(origin) or origin_finland(origin) \\\n           or origin_france(origin) or origin_georgia(origin) \\\n           or origin_germany(origin) or origin_greece(origin) \\\n           or origin_hungary(origin) or origin_iceland(origin) \\\n           or origin_ireland(origin) \\\n           or origin_northern_ireland(origin) or origin_italy(origin) \\\n           or origin_kazakhstan(origin) or origin_latvia(origin) \\\n           or origin_lithuania(origin) \\\n           or origin_luxembourg(origin) or origin_macedonia(origin) \\\n           or origin_malta(origin) or origin_moldova(origin) \\\n           or origin_montenegro(origin) or origin_netherlands(origin) \\\n           or origin_norway(origin) or origin_poland(origin) \\\n           or origin_portugal(origin) or origin_romania(origin) \\\n           or origin_russia(origin) or origin_serbia(origin) \\\n           or origin_slovakia(origin) or origin_slovenia(origin) \\\n           or origin_spain(origin) or origin_sweden(origin) \\\n           or origin_switzerland(origin) or origin_turkey(origin) \\\n           or origin_ukraine(origin) or origin_united_kingdom(origin) \\\n           or origin_vatican(origin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the origin is located in North Africa.", "response": "def origin_north_africa(origin):\n    \"\"\"\\\n    Returns if the origin is located in North Africa.\n\n    Holds true for the following countries:\n        * Algeria\n        * Egypt\n        * Libya\n        * Morocco\n        * Sudan\n        * Tunisia\n\n    `origin`\n        The origin to check.\n    \"\"\"\n    return origin_egypt(origin) or origin_algeria(origin) \\\n           or origin_libya(origin) or origin_morocco(origin) \\\n           or origin_sudan(origin) or origin_tunisia(origin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the origin is located in West Africa.", "response": "def origin_west_africa(origin):\n    \"\"\"\\\n    Returns if the origin is located in West Africa.\n\n    Holds true for the following countries:\n        * Benin\n        * Burkin Faso\n        * Cape Verde\n        * C\u00f4te d'Ivoire\n        * Gambia\n        * Ghana\n        * Guinea\n        * Liberia\n        * Mali\n        * Mauritania\n        * Niger\n        * Nigeria\n        * Senegal\n        * Sierra Leone\n        * Togo\n\n    `origin`\n        The origin to check.\n    \"\"\"\n    return origin_benin(origin) or origin_burkina_faso(origin) \\\n           or origin_cape_verde(origin) or origin_cote_divoire(origin) \\\n           or origin_gambia(origin) or origin_ghana(origin) \\\n           or origin_guinea(origin) or origin_liberia(origin) \\\n           or origin_mali(origin) or origin_mauritania(origin) \\\n           or origin_niger(origin) or origin_nigeria(origin) \\\n           or origin_senegal(origin) or origin_sierra_leone(origin) \\\n           or origin_togo(origin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef origin_central_asia(origin):\n    return origin_afghanistan(origin) or origin_kazakhstan(origin) \\\n           or origin_kyrgyzstan(origin) or origin_tajikistan(origin) \\\n           or origin_turkmenistan(origin) or origin_uzbekistan(origin)", "response": "Returns True if the origin is located in Central Asia."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the origin is located in East Asia", "response": "def origin_east_asia(origin):\n    \"\"\"\\\n    Returns if the origin is located in East Asia\n\n    Holds true for the following countries:\n        * China\n        * Japan\n        * Mongolia\n        * South Korea\n        * Taiwan\n\n    `origin`\n        The origin to check.\n    \"\"\"\n    return origin_china(origin) or origin_japan(origin) \\\n           or origin_mongolia(origin) or origin_south_korea(origin) \\\n           or origin_taiwan(origin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the origin is located in Western Asia.", "response": "def origin_west_asia(origin):\n    \"\"\"\\\n    Returns if the origin is located in Western Asia.\n\n    Holds true for the following countries:\n        * Armenia\n        * Azerbaijan\n        * Bahrain\n        * Cyprus\n        * Georgia\n        * Iraq\n        * Israel\n        * Jordan\n        * Kuwait\n        * Lebanon\n        * Oman\n        * Qatar\n        * Saudi Arabia\n        * Syria\n        * Turkey\n        * United Arab Emirates\n        * Yemen\n\n    `origin`\n        The origin to check.\n    \"\"\"\n    return origin_armenia(origin) or origin_azerbaijan(origin) \\\n           or origin_bahrain(origin) or origin_cyprus(origin) \\\n           or origin_georgia(origin) or origin_georgia(origin) \\\n           or origin_iraq(origin) or origin_israel(origin) \\\n           or origin_jordan(origin) or origin_kuwait(origin) \\\n           or origin_lebanon(origin) or origin_oman(origin) \\\n           or origin_qatar(origin) or origin_saudi_arabia(origin) \\\n           or origin_syria(origin) or origin_turkey(origin) \\\n           or origin_united_arab_emirates(origin) or origin_yemen(origin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef origin_germany(origin):\n    return origin in (u'BONN', u'BERLIN', u'DUSSELDORF', u'FRANKFURT',\n                      u'HAMBURG', u'LEIPZIG', u'MUNICH')", "response": "\\ Returns if the origin is Germany."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns if the origin is Iraq.", "response": "def origin_iraq(origin):\n    \"\"\"\\\n    Returns if the origin is Iraq.\n\n    `origin`\n        The origin to check.\n    \"\"\"\n    return origin == u'BAGHDAD' \\\n           or u'BASRAH' in origin \\\n           or u'HILLAH' in origin \\\n           or u'KIRKUK' in origin \\\n           or u'MOSUL' in origin"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef origin_mexico(origin):\n    return origin in (u'CIUDADJUAREZ', u'GUADALAJARA', u'HERMOSILLO',\n                      u'MATAMOROS', u'MERIDA', u'MEXICO', u'MONTERREY',\n                      u'NOGALES',\n                      u'NUEVOLAREDO', u'TIJUANA')", "response": "\\ Returns if the origin is Mexico.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves task variables based on input variables and the default values. Raises LookupError if a variable is missing.", "response": "def resolve_variables(self, task):\n        \"\"\"\n        Resolve task variables based on input variables and the default\n        values.\n\n        Raises\n        ------\n        LookupError\n            If a variable is missing.\n        \"\"\"\n\n        variables = {**task.variables, **self.project.variables}\n\n        values = {}\n\n        for variable in variables.values():\n            value = self.variables.get(variable.name) or variable.default\n            if value is None:\n                raise LookupError(variable)\n            values[variable.name] = value\n\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfollows back or unfollow the friends/followers of user authenicated in 'api'. :api twitter_bot_utils.api.API :dry_run bool don't actually (un)follow, just report", "response": "def _autofollow(api, action, dry_run):\n    '''\n    Follow back or unfollow the friends/followers of user authenicated in 'api'.\n    :api twitter_bot_utils.api.API\n    :dry_run bool don't actually (un)follow, just report\n    '''\n    try:\n        # get the last 5000 followers\n        followers = api.followers_ids()\n\n        # Get the last 5000 people user has followed\n        friends = api.friends_ids()\n\n    except TweepError as e:\n        api.logger.error('%s: error getting followers/followers', action)\n        api.logger.error(\"%s\", e)\n        return\n\n    if action == \"unfollow\":\n        method = api.destroy_friendship\n        independent, dependent = followers, friends\n\n    elif action == \"follow\":\n        method = api.create_friendship\n        independent, dependent = friends, followers\n    else:\n        raise IndexError(\"Unknown action: {}\".format(action))\n\n    api.logger.info('%sing: found %s friends, %s followers', action, len(friends), len(followers))\n\n    # auto-following:\n    # for all my followers\n    # if i don't already follow them: create friendship\n\n    # auto-unfollowing:\n    # for all my friends\n    # if they don't follow me: destroy friendship\n    targets = [x for x in dependent if x not in independent]\n\n    for uid in targets:\n        try:\n            api.logger.info('%sing %s', action, uid)\n\n            if not dry_run:\n                method(id=uid)\n\n        except RateLimitError:\n            api.logger.warning(\"reached Twitter's rate limit, sleeping for %d minutes\", RATE_LIMIT_RESET_MINUTES)\n            sleep(RATE_LIMIT_RESET_MINUTES * 60)\n            method(id=uid)\n\n        except TweepError as e:\n            api.logger.error('error %sing on %s', action, uid)\n            api.logger.error(\"code %s: %s\", e.api_code, e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating theoretical expectations for qqplot", "response": "def _qqplot_bar(M=1000000, alphaLevel = 0.05, distr = 'log10'):\n\t\"\"\"calculate theoretical expectations for qqplot\"\"\"\n\tmRange=10**(sp.arange(sp.log10(0.5),sp.log10(M-0.5)+0.1,0.1));#should be exp or 10**?\n\tnumPts=len(mRange);\n\tbetaalphaLevel=sp.zeros(numPts);#down in the plot\n\tbetaOneMinusalphaLevel=sp.zeros(numPts);#up in the plot\n\tbetaInvHalf=sp.zeros(numPts);\n\tfor n in range(numPts):\n\t   m=mRange[n]; #numPLessThanThresh=m;\n\t   betaInvHalf[n]=st.beta.ppf(0.5,m,M-m);\n\t   betaalphaLevel[n]=st.beta.ppf(alphaLevel,m,M-m);\n\t   betaOneMinusalphaLevel[n]=st.beta.ppf(1-alphaLevel,m,M-m);\n\tbetaDown=betaInvHalf-betaalphaLevel;\n\tbetaUp=betaOneMinusalphaLevel-betaInvHalf;\n\n\ttheoreticalPvals=mRange/M;\n\treturn betaUp, betaDown, theoreticalPvals"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qqplot(pv, distr = 'log10', alphaLevel = 0.05):\n\tshape_ok = (len(pv.shape)==1) or ((len(pv.shape)==2) and pv.shape[1]==1)\n\tassert shape_ok, 'qqplot requires a 1D array of p-values'\n\n\ttests = pv.shape[0]\n\tpnull = (0.5 + sp.arange(tests))/tests\n\t# pnull = np.sort(np.random.uniform(size = tests))\n\tIpv = sp.argsort(pv)\n\n\tif distr == 'chi2':\n\t    qnull = sp.stats.chi2.isf(pnull, 1)\n\t    qemp = (sp.stats.chi2.isf(pv[Ipv],1))\n\t    xl = 'LOD scores'\n\t    yl = '$\\chi^2$ quantiles'\n\n\tif distr == 'log10':\n\t    qnull = -sp.log10(pnull)\n\t    qemp = -sp.log10(pv[Ipv])\n\n\t    xl = '-log10(P) observed'\n\t    yl = '-log10(P) expected'\n\n\tline = plt.plot(qnull, qemp, '.')[0]\n\t#plt.plot([0,qemp.m0x()], [0,qemp.max()],'r')\n\tplt.plot([0,qnull.max()], [0,qnull.max()],'r')\n\tplt.ylabel(xl)\n\tplt.xlabel(yl)\n\tif alphaLevel is not None:\n\t    if distr == 'log10':\n\t        betaUp, betaDown, theoreticalPvals = _qqplot_bar(M=tests,alphaLevel=alphaLevel,distr=distr)\n\t        lower = -sp.log10(theoreticalPvals-betaDown)\n\t        upper = -sp.log10(theoreticalPvals+betaUp)\n\t        plt.fill_between(-sp.log10(theoreticalPvals),lower,upper,color='grey',alpha=0.5)\n\t        #plt.plot(-sp.log10(theoreticalPvals),lower,'g-.')\n\t        #plt.plot(-sp.log10(theoreticalPvals),upper,'g-.')\n\treturn line", "response": "This script makes a Quantile - Quile plot of the observed and expected log - P - value distribution against the theoretical one under the null."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot a fit of a normal distribution to the data in x.", "response": "def plot_normal(x=None, mean_x=None,std_x=None,color='red',linewidth=2,alpha=1,bins=20,xlim=False,plot_mean=True,plot_std=False,plot_2std=True,figure=None,annotate=True,histogram=True):\n    \"\"\"\n    plot a fit of a normal distribution to the data in x.\n    \"\"\"\n    import pylab\n    if figure is None:\n        figure=pylab.figure()\n    if mean_x is None:\n        #fit maximum likelihood Normal distribution mean to samples X\n        mean_x = x.mean() #sample mean\n    if std_x is None:\n        #fit maximum likelihood Normal distribution standard deviation to samples X\n        std_x = x.std()   #sample standard deviation\n\n    xvals=np.arange(mean_x-5*std_x,mean_x+5*std_x,.001)\n    yvals=st.norm.pdf(xvals,mean_x,std_x)\n    #plot normal distribution:\n    ax = pylab.plot(xvals,yvals,color=color,linewidth=linewidth,alpha=alpha)\n    if x is not None and histogram:\n        #plot histogram of x-values\n        pylab.hist(x,bins,normed=True)\n\n    if plot_mean:\n        #evaluate distribution at the mean:\n        max_cdf=st.norm.pdf(mean_x,mean_x,std_x)\n        pylab.plot([mean_x,mean_x],[0,max_cdf],color=color,linewidth=linewidth,alpha=alpha,linestyle=\"--\")\n        if annotate:\n            pylab.annotate('$\\mu$', xy=(mean_x+0.6*std_x, 1.0*max_cdf),\n                horizontalalignment='center', verticalalignment='center',fontsize=15,color=color)\n    if plot_std:#plot mean +- 1*standard deviation (64% interval)\n        std_cdf=st.norm.pdf(mean_x+std_x,mean_x,std_x)\n        pylab.plot([mean_x+std_x,mean_x+std_x],[0,std_cdf],color=color,linewidth=linewidth,alpha=alpha,linestyle=\"--\")\n        pylab.plot([mean_x-std_x,mean_x-std_x],[0,std_cdf],color=color,linewidth=linewidth,alpha=alpha,linestyle=\"--\")\n        if annotate:\n            pylab.annotate('$\\mu+\\sigma$', xy=(mean_x+1.6*std_x, 1.5*std_cdf),\n                horizontalalignment='center', verticalalignment='center',fontsize=15,color=color)\n    if plot_2std:#plot mean +- 2*standard deviations (95% interval)\n        std2_cdf=st.norm.pdf(mean_x+2*std_x,mean_x,std_x)\n        pylab.plot([mean_x+2*std_x,mean_x+2*std_x],[0,std2_cdf],color=color,linewidth=linewidth,alpha=alpha,linestyle=\"--\")\n        pylab.plot([mean_x-2*std_x,mean_x-2*std_x],[0,std2_cdf],color=color,linewidth=linewidth,alpha=alpha,linestyle=\"--\")\n        if annotate:\n            pylab.annotate('$\\mu+2\\sigma$', xy=(mean_x+2.6*std_x, 1.5*std2_cdf),\n                horizontalalignment='center', verticalalignment='center',fontsize=15,color=color)\n    if xlim: #cut of unused space on y-axis\n        pylab.xlim([mean_x-4*std_x,mean_x+4*std_x])\n    return figure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsort the given list in natural order.", "response": "def natsort(l, key=None, reverse=False):\n    \"\"\"\n    Sort the given list in the way that humans expect (using natural order sorting).\n\n    :param l: An iterable of strings to sort.\n    :param key: An optional sort key similar to the one accepted by Python's\n                built in :func:`sorted()` function. Expected to produce\n                strings.\n    :param reverse: Whether to reverse the resulting sorted list.\n    :returns: A sorted list of strings.\n    \"\"\"\n    return sorted(l, key=lambda v: NaturalOrderKey(key and key(v) or v), reverse=reverse)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if an element is present in the dom or not", "response": "def is_present(self, selector):\n        \"\"\"Check if an element is present in the dom or not\n\n        This method won't check if the element is displayed or not\n        This method won't wait until the element is visible or present\n        This method won't raise any exception if the element is not present\n\n        Returns:\n            bool: True if the element is present; False otherwise\n        \"\"\"\n        self.debug_log(\"Is present (%s)\" % selector)\n\n        element = self.find(\n            selector,\n            raise_exception=False,\n            wait_until_present=False,\n            wait_until_visible=False\n        )\n        if element:\n            self.debug_log(\"is present: True\")\n            return True\n        else:\n            self.debug_log(\"is present: False\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_visible(self, selector):\n\n        self.debug_log(\"Is visible (%s)\" % selector)\n\n        element = self.find(\n            selector,\n            raise_exception=False,\n            wait_until_present=False,\n            wait_until_visible=False\n        )\n\n        if element:\n            if element.is_displayed(raise_exception=False):\n\n                element.highlight(\n                    style=BROME_CONFIG['highlight']['element_is_visible']\n                )\n\n                self.debug_log(\"is visible (%s): True\" % selector)\n\n                return True\n\n        self.debug_log(\"is visible (%s): False\" % selector)\n\n        return False", "response": "Check if an element is visible in the dom or not"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds an element with a selector", "response": "def find(self, selector, **kwargs):\n        \"\"\"Find an element with a selector\n\n        Args:\n            selector (str): the selector used to find the element\n\n        Kwargs:\n            wait_until_present (bool)\n            wait_until_visible (bool)\n            raise_exception (bool)\n\n        Returns:\n            None if no element was found\n            proxy_element is an element was found\n\n        Raises:\n            this function might raise an exception\n                depending on the raise_exception kwargs\n            or\n            the config proxy_driver:raise_exception\n        \"\"\"\n\n        self.debug_log(\"Finding element with selector: %s\" % selector)\n\n        elements = self.find_all(selector, **kwargs)\n        if len(elements):\n            self.debug_log(\"find (%s): Element found\" % (selector))\n            return elements[0]\n        else:\n            self.debug_log(\"find (%s): No element found\" % (selector))\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_last(self, selector, **kwargs):\n\n        self.debug_log(\"Finding last element with selector: %s\" % selector)\n\n        elements = self.find_all(selector, **kwargs)\n        if len(elements):\n            self.debug_log(\"find_last (%s): element found\" % selector)\n            return elements[-1]\n        else:\n            self.debug_log(\"find_last (%s): No element found\" % selector)\n            return None", "response": "Returns the last element found with a selector"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_all(self, selector, **kwargs):\n\n        self.debug_log(\"Finding elements with selector: %s\" % selector)\n\n        raise_exception = kwargs.get(\n            'raise_exception',\n            BROME_CONFIG['proxy_driver']['raise_exception']\n        )\n        self.debug_log(\"effective raise_exception: %s\" % raise_exception)\n\n        wait_until_present = kwargs.get(\n            'wait_until_present',\n            BROME_CONFIG['proxy_driver']['wait_until_present_before_find']\n        )\n\n        self.debug_log(\n            \"effective wait_until_present: %s\" % wait_until_present\n        )\n\n        wait_until_visible = kwargs.get(\n            'wait_until_visible',\n            BROME_CONFIG['proxy_driver']['wait_until_visible_before_find']\n        )\n        self.debug_log(\n            \"effective wait_until_visible: %s\" % wait_until_visible\n        )\n\n        _selector = Selector(self, selector)\n\n        found = False\n        if wait_until_visible:\n            # we don't raise exception here otherwise none visible\n            # element will always raise exception\n            # TODO find a good way to make it configurable\n            found = self.wait_until_visible(selector, raise_exception=False)\n\n        if wait_until_present and not found:\n            found = self.wait_until_present(\n                selector,\n                raise_exception=raise_exception\n            )\n            if not found:\n                self.debug_log(\"find_all (%s): No element found\" % _selector)\n                return []\n\n        try:\n            elements = getattr(\n                self._driver,\n                _selector.find_function\n            )(_selector.get_selector())\n        except exceptions.NoSuchElementException:\n            self.debug_log(\"find_all (%s): No element found\" % _selector)\n            self.print_javascript_error()\n            if raise_exception:\n                raise exceptions.NoSuchElementException(_selector)\n            else:\n                return []\n\n        if type(elements) == list:\n            if len(elements):\n                self.debug_log(\"find_all (%s): Element found\" % _selector)\n                return ProxyElementList(elements, _selector, self)\n            else:\n                msg = \"find_all (%s): No element found\" % _selector\n                self.debug_log(msg)\n                self.print_javascript_error()\n                if raise_exception:\n                    raise exceptions.NoSuchElementException(msg)\n                else:\n                    return []\n        else:\n            self.debug_log(\"find_all (%s): Element found\" % _selector)\n            return [ProxyElement(elements, _selector, self)]", "response": "Return all the elements with a selector"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_until_clickable(self, selector, **kwargs):\n        self.info_log(\"Waiting until clickable (%s)\" % selector)\n\n        timeout = kwargs.get(\n            'timeout',\n            BROME_CONFIG['proxy_driver']['default_timeout']\n        )\n        self.debug_log(\"effective timeout: %s\" % timeout)\n\n        raise_exception = kwargs.get(\n            'raise_exception',\n            BROME_CONFIG['proxy_driver']['raise_exception']\n        )\n        self.debug_log(\"effective raise_exception: %s\" % raise_exception)\n\n        _selector = Selector(self, selector)\n\n        try:\n            WebDriverWait(\n                self._driver, timeout\n            ).until(\n                EC.element_to_be_clickable(\n                    (getattr(By, _selector.find_by), _selector.get_selector()))\n            )\n            self.debug_log(\n                \"wait_until_clickable (%s): element is clickable\" % _selector\n            )\n            return True\n        except exceptions.TimeoutException:\n            msg = \"wait_until_clickable: element (%s) is still not clickable\" % _selector  # noqa\n            self.debug_log(msg)\n            self.print_javascript_error()\n            if raise_exception:\n                if self.bot_diary:\n                    self.bot_diary.add_auto_entry(\n                        \"I waited for the clickability of\",\n                        target=_selector.get_human_readable()\n                    )\n                raise exceptions.TimeoutException(msg)\n            else:\n                return False", "response": "Wait until an element is clickable"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, url):\n\n        self._driver.get(url)\n\n        if self.bot_diary:\n            self.bot_diary.add_auto_entry(\n                \"I went on\",\n                target=url,\n                take_screenshot=True\n            )\n\n        if BROME_CONFIG['proxy_driver']['intercept_javascript_error']:\n            self.init_javascript_error_interception()\n\n        return True", "response": "Navigate to a specific url and return a boolean indicating if the url was successfully routed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_javascript_error(self):\n\n        errors = self.get_javascript_error(return_type='list')\n        if errors:\n            self.info_log(\"Javascript error:\")\n            for error in errors:\n                self.info_log(error)", "response": "Print to the info log the gathered javascript error"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the gathered javascript error string", "response": "def get_javascript_error(self, return_type='string'):\n        \"\"\"Return the gathered javascript error\n\n        Args:\n            return_type: 'string' | 'list'; default: 'string'\n        \"\"\"\n\n        if BROME_CONFIG['proxy_driver']['intercept_javascript_error']:\n            js_errors = self._driver.execute_script(\n                'return window.jsErrors; window.jsErrors = [];'\n            )\n\n            if not js_errors:\n                js_errors = []\n\n            if return_type == 'list':\n                if len(js_errors):\n                    return js_errors\n                else:\n                    return []\n            else:\n                if len(js_errors):\n                    return os.linesep.join(js_errors)\n                else:\n                    return self.no_javascript_error_string\n        else:\n            if return_type == 'list':\n                return []\n            else:\n                return self.no_javascript_error_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the python debugger", "response": "def pdb(self):\n        \"\"\"Start the python debugger\n\n        Calling pdb won't do anything in a multithread context\n        \"\"\"\n        if self.embed_disabled:\n            self.warning_log(\"Pdb is disabled when runned from the grid runner because of the multithreading\")  # noqa\n            return False\n\n        if BROME_CONFIG['runner']['play_sound_on_pdb']:\n            say(BROME_CONFIG['runner']['sound_on_pdb'])\n\n        set_trace()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndragging and drop related elements.", "response": "def drag_and_drop(self, source_selector, destination_selector, **kwargs):\n        \"\"\"Drag and drop\n\n        Args:\n            source_selector: (str)\n            destination_selector: (str)\n\n        Kwargs:\n            use_javascript_dnd: bool; default:\n                config proxy_driver:use_javascript_dnd\n        \"\"\"\n        self.info_log(\n            \"Drag and drop: source (%s); destination (%s)\" %\n            (source_selector, destination_selector)\n        )\n\n        use_javascript_dnd = kwargs.get(\n            \"use_javascript_dnd\",\n            \"proxy_driver:use_javascript_dnd\"\n        )\n\n        source_el = self.find(source_selector)\n        destination_el = self.find(destination_selector)\n\n        if use_javascript_dnd:\n            try:\n                dnd_script = [\n                    \"function simulate(f,c,d,e){var b,a=null;for(b in eventMatchers)if(eventMatchers[b].test(c)){a=b;break}if(!a)return!1;document.createEvent?(b=document.createEvent(a),a=='HTMLEvents'?b.initEvent(c,!0,!0):b.initMouseEvent(c,!0,!0,document.defaultView,0,d,e,d,e,!1,!1,!1,!1,0,null),f.dispatchEvent(b)):(a=document.createEventObject(),a.detail=0,a.screenX=d,a.screenY=e,a.clientX=d,a.clientY=e,a.ctrlKey=!1,a.altKey=!1,a.shiftKey=!1,a.metaKey=!1,a.button=1,f.fireEvent('on'+c,a));return!0} var eventMatchers={HTMLEvents:/^(?:load|unload|abort|error|select|change|submit|reset|focus|blur|resize|scroll)$/,MouseEvents:/^(?:click|dblclick|mouse(?:down|up|over|move|out))$/};\",  # noqa\n                    \"var source = arguments[0],destination = arguments[1];\",\n                    \"simulate(source, 'mousedown', 0, 0);\",\n                    \"simulate(source, 'mousemove', destination.offsetLeft, destination.offsetTop);\",  # noqa\n                    \"simulate(source, 'mouseup', destination.offsetLeft, destination.offsetTop);\"  # noqa\n                ]\n                self._driver.execute_script(\n                    '\\n'.join(dnd_script),\n                    source_el._element,\n                    destination_el._element\n                )\n\n            except Exception as e:\n                self.error_log(u'drag_and_drop exception: %s' % str(e))\n                raise\n        else:\n            try:\n                ActionChains(self._driver).drag_and_drop(\n                    source_el,\n                    destination_el\n                ).perform()\n            except Exception as e:\n                self.error_log(u'drag_and_drop exception: %s' % str(e))\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef embed(self, title=''):\n        if self.embed_disabled:\n            self.warning_log(\"Embed is disabled when runned from the grid runner because of the multithreading\")  # noqa\n            return False\n\n        from IPython.terminal.embed import InteractiveShellEmbed\n\n        if BROME_CONFIG['runner']['play_sound_on_ipython_embed']:\n            say(BROME_CONFIG['runner']['sound_on_ipython_embed'])\n\n        ipshell = InteractiveShellEmbed(banner1=title)\n\n        frame = currentframe()\n        stack_depth = 1\n        for i in range(5):\n            frame = frame.f_back\n            stack_depth += 1\n            if frame.f_code.co_filename not in __file__:\n                break\n\n        msg = 'Stopped at %s and line %s;' % \\\n            (frame.f_code.co_filename, frame.f_lineno)\n\n        ipshell(msg, stack_depth=stack_depth)", "response": "Start an IPython embed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a screenshot of a node", "response": "def take_node_screenshot(self, element, screenshot_path):\n        from PIL import Image\n        \"\"\"Take a screenshot of a node\n\n        Args:\n            element (object): the proxy_element\n            screenshot_path (str): the path where the screenshot will be saved\n        \"\"\"\n\n        temp_path = os.path.join(tempdir, screenshot_path)\n\n        el_x = int(element.location['x'])\n        el_y = int(element.location['y'])\n        el_height = int(element.size['height'])\n        el_width = int(element.size['width'])\n\n        if el_height == 0 or el_width == 0:\n            self.debug_log(\"take_node_screenshot cannot be taken because element width or height equal zero\")  # noqa\n            return False\n\n        bounding_box = (\n            el_x,\n            el_y,\n            (el_x + el_width),\n            (el_y + el_height)\n        )\n\n        self._driver.save_screenshot(temp_path)\n\n        base_image = Image.open(temp_path)\n\n        cropped_image = base_image.crop(bounding_box)\n\n        base_image = base_image.resize(cropped_image.size)\n\n        base_image.paste(cropped_image, (0, 0))\n\n        base_image.save(screenshot_path)\n\n        \"\"\"\n        except Exception as e:\n            tb = traceback.format_exc()\n            print unicode(tb)\n            embed()\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef take_screenshot(self, screenshot_name=None, screenshot_path=None):\n        self.info_log(\"Taking a screenshot...\")\n\n        save_to_db = False\n        if screenshot_path:\n            self._driver.save_screenshot(screenshot_path)\n            self.debug_log(\"Screenshot taken (%s)\" % screenshot_path)\n\n        elif screenshot_name:\n            take_screenshot = True\n            if hasattr(self.runner, \"screenshot_cache\"):\n                if self.runner.screenshot_cache.get(screenshot_name):\n                    self.debug_log(\n                        \"screenshot(%s) found in cache\" % screenshot_name\n                    )\n                    take_screenshot = False\n\n            if take_screenshot:\n                if self.test_instance._runner_dir:\n                    _screenshot_name = '%s.png' % \\\n                        string_to_filename(screenshot_name)\n\n                    relative_path = os.path.join(\n                            self.test_instance._screenshot_relative_dir,\n                            _screenshot_name\n                    )\n\n                    full_path = os.path.join(\n                            self.test_instance._screenshot_dir,\n                            _screenshot_name\n                    )\n\n                    self._driver.save_screenshot(\n                        full_path\n                    )\n                    self.debug_log(\"Screenshot taken (%s)\" % full_path)\n                    save_to_db = True\n        else:\n            if self.test_instance._runner_dir:\n                screenshot_name = get_timestamp()\n                _screenshot_name = '%s.png' % screenshot_name\n\n                relative_path = os.path.join(\n                        self.test_instance._screenshot_relative_dir,\n                        _screenshot_name\n                )\n\n                full_path = os.path.join(\n                        self.test_instance._screenshot_dir,\n                        _screenshot_name\n                )\n\n                self._driver.save_screenshot(\n                    full_path\n                )\n                self.debug_log(\"Screenshot taken (%s)\" % full_path)\n                save_to_db = True\n\n        if save_to_db:\n            with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                capabilities = {\n                    'browserName': self.capabilities['browserName'],\n                    'platform': self.capabilities['platform'],\n                    'version': self.capabilities['version']\n                }\n                screenshot = Testscreenshot()\n                screenshot.browser_capabilities = capabilities\n                screenshot.browser_id = self.get_id()\n                # TODO support s3\n                screenshot.location = 'local_file_system'\n                screenshot.root_path = self.test_instance._runner.root_test_result_dir  # noqa\n                screenshot.file_path = relative_path\n                screenshot.extra_data = {}\n                screenshot.title = screenshot_name\n                screenshot.test_instance_id = self.test_instance._test_instance_id  # noqa\n                screenshot.test_batch_id = self.test_instance._test_batch_id  # noqa\n\n                session.save(screenshot, safe=True)", "response": "Take a screenshot for a specific instance of the current test instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef take_quality_screenshot(self, screenshot_name):\n        self.info_log(\"Taking a quality screenshot...\")\n\n        if self.test_instance._runner_dir:\n            _screenshot_name = '%s.png' % string_to_filename(screenshot_name)\n            relative_path = os.path.join(\n                    self.test_instance._quality_screenshot_relative_dir,\n                    _screenshot_name\n                )\n\n            full_path = os.path.join(\n                    self.test_instance._quality_screenshot_dir,\n                    _screenshot_name\n                )\n            self._driver.save_screenshot(\n                full_path\n            )\n\n            with DbSessionContext(BROME_CONFIG['database']['mongo_database_name']) as session:  # noqa\n                capabilities = {\n                    'browserName': self.capabilities['browserName'],\n                    'platform': self.capabilities['platform'],\n                    'version': self.capabilities['version']\n                }\n                quality_screenshot = Testqualityscreenshot()\n                quality_screenshot.timestamp = utcnow()\n                quality_screenshot.browser_capabilities = capabilities\n                quality_screenshot.browser_id = self.get_id()\n                quality_screenshot.file_path = relative_path\n                # TODO support s3\n                quality_screenshot.location = 'local_file_system'\n                quality_screenshot.root_path = self.test_instance._runner.root_test_result_dir  # noqa\n                quality_screenshot.extra_data = {}\n                quality_screenshot.title = screenshot_name\n                quality_screenshot.test_instance_id = self.test_instance._test_instance_id  # noqa\n                quality_screenshot.test_batch_id = self.test_instance._test_batch_id  # noqa\n\n                session.save(quality_screenshot, safe=True)\n\n            self.debug_log(\"Quality screenshot taken (%s)\" % full_path)", "response": "Take a quality screenshot for a specific a\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assert_present(self, selector, testid=None, **kwargs):\n        self.info_log(\n            \"Assert present selector(%s) testid(%s)\" % (selector, testid)\n        )\n\n        wait_until_present = kwargs.get(\n            'wait_until_present',\n            BROME_CONFIG['proxy_driver']['wait_until_present_before_assert_present']  # noqa\n        )\n        self.debug_log(\n            \"effective wait_until_present: %s\" % wait_until_present\n        )\n\n        if wait_until_present:\n            element = self.wait_until_present(selector, raise_exception=False)\n        else:\n            element = self.is_present(selector)\n\n        if element:\n            if testid is not None:\n                self.create_test_result(testid, True)\n\n            return True\n        else:\n            if testid is not None:\n                self.create_test_result(testid, False)\n\n            return False", "response": "Assert that the element is present in the dom and return True if it is the assertion succeed ; False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasserts that the element is not present in the dom.", "response": "def assert_not_present(self, selector, testid=None, **kwargs):\n        \"\"\"Assert that the element is not present in the dom\n\n        Args:\n            selector (str): the selector used to find the element\n            test_id (str): the test_id or a str\n\n        Kwargs:\n            wait_until_not_present (bool)\n\n        Returns:\n            bool: True is the assertion succeed; False otherwise.\n        \"\"\"\n        self.info_log(\n            \"Assert not present selector(%s) testid(%s)\" %\n            (selector, testid)\n        )\n\n        wait_until_not_present = kwargs.get(\n            'wait_until_not_present',\n            BROME_CONFIG['proxy_driver']['wait_until_not_present_before_assert_not_present']  # noqa\n        )\n        self.debug_log(\n            \"effective wait_until_not_present: %s\" % wait_until_not_present\n        )\n\n        if wait_until_not_present:\n            ret = self.wait_until_not_present(selector, raise_exception=False)\n        else:\n            ret = not self.is_present(selector)\n\n        if ret:\n            if testid is not None:\n                self.create_test_result(testid, True)\n\n            return True\n        else:\n            if testid is not None:\n                self.create_test_result(testid, False)\n\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assert_visible(self, selector, testid=None, **kwargs):\n        self.info_log(\n            \"Assert visible selector(%s) testid(%s)\" % (selector, testid)\n        )\n\n        highlight = kwargs.get(\n            'highlight',\n            BROME_CONFIG['highlight']['highlight_on_assertion_success']\n        )\n        self.debug_log(\"effective highlight: %s\" % highlight)\n\n        wait_until_visible = kwargs.get(\n            'wait_until_visible',\n            BROME_CONFIG['proxy_driver']['wait_until_visible_before_assert_visible']  # noqa\n        )\n        self.debug_log(\"effective wait_until_visible: %s\" % wait_until_visible)\n\n        if wait_until_visible:\n            self.wait_until_visible(selector, raise_exception=False)\n\n        element = self.find(\n            selector,\n            raise_exception=False,\n            wait_until_visible=False,\n            wait_until_present=False\n        )\n        if element and element.is_displayed(raise_exception=False):\n            if highlight:\n                element.highlight(\n                    style=BROME_CONFIG['highlight']['style_on_assertion_success']  # noqa\n                )\n            if testid is not None:\n                self.create_test_result(testid, True)\n\n            return True\n        else:\n            if testid is not None:\n                self.create_test_result(testid, False)\n\n            return False", "response": "Assert that the element is visible in the dom and that it is visible in the dom."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nasserting that the element is not visible in the dom", "response": "def assert_not_visible(self, selector, testid=None, **kwargs):\n        \"\"\"Assert that the element is not visible in the dom\n\n        Args:\n            selector (str): the selector used to find the element\n            test_id (str): the test_id or a str\n\n        Kwargs:\n            wait_until_not_visible (bool)\n            highlight (bool)\n\n        Returns:\n            bool: True is the assertion succeed; False otherwise.\n        \"\"\"\n        self.info_log(\n            \"Assert not visible selector(%s) testid(%s)\" % (selector, testid)\n        )\n\n        highlight = kwargs.get(\n            'highlight',\n            BROME_CONFIG['highlight']['highlight_on_assertion_failure']\n        )\n        self.debug_log(\"effective highlight: %s\" % highlight)\n\n        wait_until_not_visible = kwargs.get(\n            'wait_until_not_visible',\n            BROME_CONFIG['proxy_driver']['wait_until_not_visible_before_assert_not_visible']  # noqa\n        )\n        self.debug_log(\n            \"effective wait_until_not_visible: %s\" % wait_until_not_visible\n        )\n\n        if wait_until_not_visible:\n            self.wait_until_not_visible(selector, raise_exception=False)\n\n        element = self.find(\n            selector,\n            raise_exception=False,\n            wait_until_visible=False,\n            wait_until_present=False\n        )\n        if element and element.is_displayed(raise_exception=False):\n            data = self.execute_script(\n                \"return arguments[0].getBoundingClientRect();\",\n                element._element\n            )\n\n            if highlight:\n                element.highlight(\n                    style=BROME_CONFIG['highlight']['style_on_assertion_failure']  # noqa\n                )\n            if testid is not None:\n                self.create_test_result(testid, False, extra_data={\n                    'bounding_client_rect': data,\n                    'video_x_offset': self.browser_config.get('video_x_offset', 0),  # noqa\n                    'video_y_offset': self.browser_config.get('video_y_offset', 0)  # noqa\n                })\n\n            return False\n        else:\n            if testid is not None:\n                self.create_test_result(testid, True)\n\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_text_equal(self, selector, value, testid=None, **kwargs):\n        self.info_log(\n            \"Assert text equal selector(%s) testid(%s)\" % (selector, testid)\n        )\n\n        highlight = kwargs.get(\n            'highlight',\n            BROME_CONFIG['highlight']['highlight_on_assertion_success']\n        )\n        self.debug_log(\"effective highlight: %s\" % highlight)\n\n        wait_until_visible = kwargs.get(\n            'wait_until_visible',\n            BROME_CONFIG['proxy_driver']['wait_until_visible_before_assert_visible']  # noqa\n        )\n        self.debug_log(\"effective wait_until_visible: %s\" % wait_until_visible)\n\n        element = self.find(\n            selector,\n            raise_exception=False,\n            wait_until_visible=wait_until_visible\n        )\n        if element:\n            if element.text == value:\n                if highlight:\n                    element.highlight(\n                        highlight=BROME_CONFIG['highlight']['style_on_assertion_success']  # noqa\n                    )\n                if testid is not None:\n                    self.create_test_result(testid, True)\n\n                return True\n            else:\n                if highlight:\n                    element.highlight(\n                        style=BROME_CONFIG['highlight']['style_on_assertion_failure']  # noqa\n                    )\n                if testid is not None:\n                    self.create_test_result(testid, False)\n\n                return False\n        else:\n            if testid is not None:\n                self.create_test_result(testid, False)\n\n            return False", "response": "Assert that the element s text is equal to the provided value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_texts(self, reference_id, texts):\n        self.add_words(reference_id, chain(*(self._tokenize(t) for t in texts)))", "response": "Adds the words from the provided iterable texts to the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_text(self, reference_id, text):\n        self.add_words(reference_id, self._tokenize(text))", "response": "Adds the words from the provided text to the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_members(slug, owner_screen_name, limit=1e10):\n    cursor = -1\n    members = []\n    try:\n        response = twapi.request('lists/members', {'slug': slug, 'owner_screen_name': owner_screen_name, 'cursor': cursor, 'count': 5000})\n        if response.status_code in [88, 130, 420, 429]:  # rate limit\n            sys.stderr.write('Error for %s/%s: %s\\nSleeping for 5 minutes...\\n' % (owner_screen_name, slug, response.text))\n            time.sleep(301)\n        elif response.status_code != 200:\n            sys.stderr.write('Skipping bad query: %s\\n' % response.text)\n            return members\n        else:\n            items = [r['screen_name'] for r in response if 'screen_name' in r]\n            return items\n    except Exception as e:\n        sys.stderr.write('Error: %s\\nskipping...\\n' % e)\n        return members\n    return members", "response": "List all members of a list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the twitter screen_names of each id.", "response": "def lookup_handles(ids):\n    \"\"\" Fetch the twitter screen_names of each id. \"\"\"\n    names = set()\n    for id_list in [ids[100 * i:100 * i + 100] for i in range(len(ids))]:\n        if len(id_list) > 0:\n            while True:\n                r = twapi.request('users/lookup', {'user_id': ','.join([str(i) for i in id_list])})\n                if r.status_code in [88, 130, 420, 429]:  # rate limit\n                    sys.stderr.write('Sleeping off rate limit for %s: %s\\n' % (str(id_list), r.text))\n                    time.sleep(301)\n                elif r.status_code == 200:\n                    for item in r.get_iterator():\n                        names.add((item['screen_name'], item['id_str']))\n                    break\n                else:\n                    sys.stderr.write('Error: %s\\nSkipping %s...\\n' % (str(id_list), r.text))\n                    break\n\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch the twitter ids of each screen_name.", "response": "def lookup_ids(handles):\n    \"\"\" Fetch the twitter ids of each screen_name. \"\"\"\n    ids = set()\n    for handle_list in [handles[100 * i:100 * i + 100] for i in range(len(handles))]:\n        if len(handle_list) > 0:\n            while True:\n                r = twapi.request('users/lookup', {'screen_name': ','.join(handle_list)})\n                if r.status_code in [88, 130, 420, 429]:  # rate limit\n                    sys.stderr.write('Sleeping off rate limit for %s: %s\\n' % (str(handle_list), r.text))\n                    time.sleep(300)\n                elif r.status_code == 200:\n                    for item in r.get_iterator():\n                        ids.add(item['id_str'])\n                    break\n                else:\n                    sys.stderr.write('Error: %s\\nSkipping %s...\\n' % (str(handle_list), r.text))\n                    break\n\n    return ids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tweets_for_id(user_id, limit=1e10):\n    # Map id to screen_name\n    r = twapi.request('users/lookup', {'user_id': user_id})\n    if r.status_code == 200:\n        sname = [t for t in r][0]['screen_name']\n        return tweets_for_user(sname, limit)\n    else:\n        sys.stderr.write('error: %s' % str(r))", "response": "Collect the most recent 3200 tweets for this user_id sleeping to deal with rate limits."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tweets_for_user(screen_name, limit=1e10):\n    qu = Queue()\n    p = Thread(target=_tweets_for_user, args=(qu, screen_name, limit))\n    p.start()\n    p.join(910)\n    if p.is_alive():\n        sys.stderr.write('no results after 15 minutes for %s. Aborting.' % screen_name)\n        return []\n    else:\n        return qu.get()", "response": "Collect the most recent 3200 tweets for this user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator tweets from users in these locations.", "response": "def track_locations(locations):\n    \"\"\" Return an iterator tweets from users in these locations.\n    See https://dev.twitter.com/streaming/overview/request-parameters#locations\n    Params:\n        locations...list of bounding box locations of the form:\n        southwest_longitude, southwest_latitude, northeast_longitude, northeast_latitude, ...\n    \"\"\"\n    if len(locations) % 4 != 0:\n        raise Exception('length of bounding box list should be a multiple of four')\n    results = twapi.request('statuses/filter', {'locations': ','.join('%f' % l for l in locations)})\n    return results.get_iterator()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of user s followers.", "response": "def get_followers(id_=None, screen_name=None, limit=1e10):\n    \"\"\" Either id_ or screen_name must not be None. \"\"\"\n    # FIXME: DRY from _tweets_for_user\n    if not (id_ or screen_name):\n        raise Exception(\"either id_ or screen_name must not be None\")\n    if id_:\n        key = 'user_id'\n        val = id_\n    else:\n        key = 'screen_name'\n        val = screen_name\n    cursor = -1\n    followers = []\n    while len(followers) < limit:\n        try:\n            response = twapi.request('followers/ids', {key: val, 'count': 5000,\n                                                       'cursor': cursor, 'stringify_ids': True})\n            if response.status_code in [88, 130, 420, 429]:  # rate limit\n                sys.stderr.write('Error for %s: %s\\nSleeping for 5 minutes...\\n' % (val, response.text))\n                time.sleep(300)\n            elif response.status_code != 200:\n                sys.stderr.write('Skipping bad user: %s\\n' % response.text)\n                return followers\n            else:\n                result = json.loads(response.text)\n                items = [r for r in response]\n                if len(items) == 0:\n                    return followers\n                else:\n                    sys.stderr.write('fetched %d more followers for %s\\n' % (len(items), val))\n                    time.sleep(1)\n                    followers.extend(items)\n                    if len(followers) >= limit:\n                        return followers[:limit]\n                cursor = result['next_cursor']\n        except Exception as e:\n            sys.stderr.write('Error: %s\\nskipping...\\n' % e)\n            sys.stderr.write(traceback.format_exc())\n            return followers\n    return followers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure the thread using WAC.", "response": "def configure(root_url, **kwargs):\n    \"\"\"\"\n    Notice that `configure` can either apply to the default configuration or\n    `Client.config`, which is the  configuration used by the current thread\n    since `Client` inherits form `threading.local`.\n    \"\"\"\n    default = kwargs.pop('default', True)\n    kwargs['client_agent'] = 'example-client/' + __version__\n    if 'headers' not in kwargs:\n        kwargs['headers'] = {}\n    kwargs['headers']['Accept-Type'] = 'application/json'\n    if default:\n        default_config.reset(root_url, **kwargs)\n    else:\n        Client.config = wac.Config(root_url, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef classify_comment(comment, cls=None):\n    if cls not in ['spam', 'ham', 'unsure', 'reported', None]:\n        raise Exception(\"Unrecognized classifications.\")\n\n    classified_comment, cr = models.ClassifiedComment.objects.get_or_create(\n        comment=comment\n    )\n\n    if cls == 'spam' and classified_comment.cls != 'spam':\n        comment.is_removed = True\n        comment.save()\n        classified_comment.cls = cls\n        classified_comment.save()\n        return classified_comment\n\n    if cls == 'ham' and classified_comment.cls != 'ham':\n        comment.is_removed = False\n        comment.save()\n        classified_comment.cls = cls\n        classified_comment.save()\n        return classified_comment\n\n    if cls == 'unsure' and classified_comment.cls != 'unsure':\n        classified_comment.cls = cls\n        classified_comment.save()\n        return classified_comment\n\n    if cls == 'reported' and classified_comment.cls != 'reported':\n        comment.is_removed = True\n        comment.save()\n        classified_comment.cls = cls\n        classified_comment.save()\n        return classified_comment\n\n    if cls is None:\n        cls = 'unsure'\n        comment_content_type = ContentType.objects.get_for_model(comment)\n        moderator_settings = getattr(settings, 'MODERATOR', DEFAULT_CONFIG)\n        if Vote.objects.filter(\n            content_type=comment_content_type,\n            object_id=comment.id,\n            vote=-1\n        ).count() >= moderator_settings['ABUSE_CUTOFF']:\n            cls = 'reported'\n            comment.is_removed = True\n            comment.save()\n            classified_comment.cls = cls\n            classified_comment.save()\n            return classified_comment\n        else:\n            comment.is_removed = cls == 'spam'\n            comment.save()\n            classified_comment.cls = cls\n            classified_comment.save()\n            return classified_comment\n\n    return classified_comment", "response": "Classifies a single comment and returns a new object of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a cap string return a list of cap value and modifiers.", "response": "def cap_list(caps):\n    \"\"\"Given a cap string, return a list of cap, value.\"\"\"\n    out = []\n    caps = caps.split()\n\n    for cap in caps:\n        # turn modifier chars into named modifiers\n        mods = []\n\n        while len(cap) > 0 and cap[0] in cap_modifiers:\n            attr = cap[0]\n            cap = cap[1:]\n\n            mods.append(cap_modifiers[attr])\n\n        # either give string value or None if not specified\n        if '=' in cap:\n            cap, value = cap.rsplit('=', 1)\n            if value and cap.casefold() in ['sasl']:\n                value = CaseInsensitiveList(value.split(','))\n        else:\n            value = None\n\n        out.append([cap, value, mods])\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addPath(rel_path, prepend=False):\n    path = lambda *paths: os.path.abspath(\n        os.path.join(os.path.dirname(__file__), *paths)) + '/'\n    if prepend:\n      return sys.path.insert(0, path(rel_path))\n    return sys.path.append(path(rel_path))", "response": "Adds a directory to the system python path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the difference in items of two revisioned collections.", "response": "def diff(new, old):\n    \"\"\"\n    Compute the difference in items of two revisioned collections. If only\n    `new' is specified, it is assumed it is not an update. If both are set,\n    the removed items are returned first. Otherwise, the updated and edited\n    ones are returned.\n\n    :param set new: Set of new objects\n    :param set old: Set of old objects\n    :return: A tuple consisting of `(added, removed, is_update)`.\n    :rtype: tuple\n    \"\"\"\n\n    if old is not None:\n        is_update = True\n\n        removed = set(new.removed(old))\n        updated = set(new.updated(old))\n    else:\n        is_update = False\n\n        updated = new\n        removed = set()\n\n    return updated, removed, is_update"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_byte_range(byte_range, min_byte=0, max_byte=sys.maxint):\n\n    if not byte_range:\n        return min_byte, max_byte\n\n    begin = byte_range[0] or min_byte\n    end = byte_range[1] or max_byte\n\n    if end < begin:\n        raise ValueError(\"End before begin\")\n\n    if begin < min_byte:\n        raise ValueError(\"Begin smaller than min\")\n\n    if end > max_byte:\n        raise ValueError(\"End larger than max\")\n\n    return begin, end", "response": "Parse and validate a byte range."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_tree(instance, *children):\n\n    # Yield representation of self\n    yield unicode(instance)\n\n    # Iterate trough each instance child collection\n    for i, child in enumerate(children):\n        lines = 0\n\n        yield \"|\"\n        yield \"+---\" + unicode(child)\n\n        if i != len(children) - 1:\n            a = \"|\"\n        else:\n            a = \" \"\n\n        # Iterate trough all values of collection of child\n        for j, item in enumerate(child.itervalues()):\n            if j != len(child) - 1:\n                b = \"|\"\n            else:\n                b = \" \"\n\n            if j == 0:\n                yield a + \"   |\"\n\n            # Append prefix to each line\n            for k, line in enumerate(item.to_tree()):\n                lines += 1\n\n                if k == 0:\n                    yield a + \"   +---\" + line\n                else:\n                    yield a + \"   \" + b + \"   \" + line\n\n        # Add extra space if required\n        if len(children) > 1 and i == len(children) - 1 and lines > 1:\n            yield a", "response": "Generate tree structure of an instance and its children."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninvoke one or more hooks that have been registered under name. Additional arguments and keyword arguments can be provided.", "response": "def invoke_hooks(hooks, name, *args, **kwargs):\n    \"\"\"\n    Invoke one or more hooks that have been registered under `name'. Additional\n    arguments and keyword arguments can be provided.\n\n    There is no exception catching, so if a hook fails, it will disrupt the\n    chain and/or rest of program.\n    \"\"\"\n\n    callbacks = hooks.get(name, [])\n\n    for callback in callbacks:\n        callback(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findCaller(self, stack_info=False, callers=0):\n        f = logging.currentframe()\n        #On some versions of IronPython, currentframe() returns None if\n        #IronPython isn't run with -X:Frames.\n        if f is not None:\n            if callers > 0:\n                # yes we can!\n                co = f.f_code\n                logger.debug2(\"%s:%s\", co.co_filename, co.co_name)\n            f = f.f_back\n        rv = \"(unknown file)\", 0, \"(unknown function)\", None\n        countdown = callers\n        while hasattr(f, \"f_code\"):\n            co = f.f_code\n            filename = os.path.normcase(co.co_filename)\n            if callers > 0:\n                # yes we can!\n                logger.debug2(\"%s:%s\", co.co_filename, co.co_name)\n            if filename in(_srcfile, logging._srcfile):\n                f = f.f_back\n                continue\n            if countdown > 0:\n                f = f.f_back\n                countdown -= 1\n                continue\n            sinfo = None\n            if stack_info:\n                sio = io.StringIO()\n                sio.write('Stack (most recent call last):\\n')\n                traceback.print_stack(f, file=sio)\n                sinfo = sio.getvalue()\n                if sinfo[-1] == '\\n':\n                    sinfo = sinfo[:-1]\n                sio.close()\n            rv = (co.co_filename, f.f_lineno, co.co_name, sinfo)\n            break\n        return rv", "response": "Find the caller that we can note."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,\n             callers=0):\n        \"\"\"\n        Low-level logging routine which creates a LogRecord and then calls\n        all the handlers of this logger to handle the record.\n        \"\"\"\n        sinfo = None\n        if _srcfile:\n            #IronPython doesn't track Python frames, so findCaller raises an\n            #exception on some versions of IronPython. We trap it here so that\n            #IronPython can use logging.\n            try:\n                fn, lno, func, sinfo = self.findCaller(stack_info, callers)\n            except ValueError: # pragma: no cover\n                fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        else: # pragma: no cover\n            fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        if exc_info:\n            if isinstance(exc_info, BaseException):\n                exc_info = (type(exc_info), exc_info, exc_info.__traceback__)\n            elif not isinstance(exc_info, tuple):\n                exc_info = sys.exc_info()\n        record = self.makeRecord(self.name, level, fn, lno, msg, args,\n                                 exc_info, func, extra, sinfo)\n        self.handle(record)", "response": "Internal method to log a message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the file extension.", "response": "def get_file_extension(filepath):\n    \"\"\"\n    Copy if anyconfig.utils.get_file_extension is not available.\n\n    >>> get_file_extension(\"/a/b/c\")\n    ''\n    >>> get_file_extension(\"/a/b.txt\")\n    'txt'\n    >>> get_file_extension(\"/a/b/c.tar.xz\")\n    'xz'\n    \"\"\"\n    _ext = os.path.splitext(filepath)[-1]\n    if _ext:\n        return _ext[1:] if _ext.startswith('.') else _ext\n\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an item to the end of the list.", "response": "def append(self, item):\n        \"\"\"\n        Add an item to the end of the list\n        \"\"\"\n        with self.lock:\n            with self._closeable_cursor() as cursor:\n                cursor.execute('''INSERT INTO list (list_index, value) VALUES ((SELECT MAX(list_index) FROM list) + 1, ?)''', (self._coder(item), ) )\n            self._do_write()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extend(self, iterable):\n        with self.lock:\n            for item in iterable:\n                self.append(item)", "response": "Add each item from iterable to the end of the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_pcr(*args, **kwargs):\n    # Load user's token from `PCR_AUTH_TOKEN`, use public token as default if missing\n    kwargs['token'] = os.getenv(\"PCR_AUTH_TOKEN\", \"public\")\n    return fetch(DOMAIN, *args, **kwargs)['result']", "response": "Wrapper for fetch to automatically parse results from the PCR API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reference_id_from_filename(filename):\n    reference_id = os.path.basename(filename)\n    if reference_id.rfind('.htm') > 0:\n        reference_id = reference_id[:reference_id.rfind('.')]\n    #TODO: else: raise ValueError('bla bla')?\n    return reference_id", "response": "\\ Extracts the reference identifier from the provided filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reference_id_from_html(html):\n    m = _REFERENCE_ID_FROM_HTML_PATTERN.search(html)\n    if m:\n        return m.group(1)\n    raise ValueError(\"Cannot extract the cable's reference id\")", "response": "\\ Returns the reference id of the cable from the provided HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclean the provided HTML string.", "response": "def _clean_html(html):\n    \"\"\"\\\n    Removes links (``<a href=\"...\">...</a>``) from the provided HTML input.\n    Further, it replaces \"&#x000A;\" with ``\\n`` and removes \"\u00b6\" from the texts.\n    \"\"\"\n    content = html.replace(u'&#x000A;', u'\\n').replace(u'\u00b6', '')\n    content = _LINK_PATTERN.sub(u'', content)\n    content = _HTML_TAG_PATTERN.sub(u'', content)\n    content = _BACKSLASH_PATTERN.sub(u'\\n', content)\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef header_body_from_content(content):\n    m = _CLASSIFIED_BY_PATTERN.search(content)\n    idx = m and m.end() or 0\n    m = _SUMMARY_PATTERN.search(content)\n    summary_idx = m and m.start() or None\n    m = _FIRST_PARAGRAPH_PATTERN.search(content)\n    para_idx = m and m.start() or None\n    if summary_idx and para_idx:\n        idx = max(idx, min(summary_idx, para_idx))\n    elif summary_idx:\n        idx = max(summary_idx, idx)\n    elif para_idx:\n        idx = max(para_idx, idx)\n    if idx > 0:\n        return content[:idx], content[idx:]\n    return None, None", "response": "Extracts the header and message from the cable content."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the reference id created classification and origin of the cable and assigns the value to the provided cable.", "response": "def parse_meta(file_content, cable):\n    \"\"\"\\\n    Extracts the reference id, date/time of creation, the classification,\n    and the origin of the cable and assigns the value to the provided `cable`.\n    \"\"\"\n    end_idx = file_content.rindex(\"</table>\")\n    start_idx = file_content.rindex(\"<table class='cable'>\", 0, end_idx)\n    m = _META_PATTERN.search(file_content, start_idx, end_idx)\n    if not m:\n        raise ValueError('Cable table not found')\n    if len(m.groups()) != 4:\n        raise ValueError('Unexpected metadata result: \"%r\"' % m.groups())\n    # Table content: \n    # Reference ID | Created | Classification | Origin\n    ref, created, classification, origin = m.groups()\n    if cable.reference_id != ref:\n        reference_id = MALFORMED_CABLE_IDS.get(ref)\n        if reference_id != cable.reference_id:\n            reference_id = INVALID_CABLE_IDS.get(ref)\n            if reference_id != cable.reference_id:\n                raise ValueError('cable.reference_id != ref. reference_id=\"%s\", ref=\"%s\"' % (cable.reference_id, ref))\n    cable.created = created\n    cable.origin = origin\n    # classifications are usually written in upper case, but you never know.. \n    cable.classification = classification.upper()\n    # Try to find media IRIs\n    start_idx = file_content.rfind(u'Appears in these', start_idx, end_idx)\n    if start_idx > 0:\n        cable.media_uris = _MEDIA_URLS_PATTERN.findall(file_content, start_idx, end_idx)\n    return cable"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_recipients(header, reference_id=None):\n    m = _TO_PATTERN.search(header)\n    if not m:\n        if reference_id and reference_id not in _CABLES_WITHOUT_TO:\n            logger.warn('No TO header found in \"%s\", header: \"%s\"' % (reference_id, header))\n        return []\n    to_header = m.group(1)\n    return _route_recipient_from_header(to_header, reference_id)", "response": "\\ Returns the recipients of the cable as a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_info_recipients(header, reference_id=None):\n    m = _INFO_PATTERN.search(header)\n    if not m:\n        return []\n    to_header = m.group(1)\n    return _route_recipient_from_header(to_header, reference_id)", "response": "\\ Returns the informal recipients of the cable as a list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_signed_by(content, canonicalize=True):\n    s = content[-300:]\n    m = _SIGNER_PATTERN.search(s) or _SIGNER_PATTERN2.search(s)\n    if not m:\n        return []\n    signers = m.group(1)\n    tmp_signers = signers.upper()\n    if tmp_signers in (u'CONFIDENTIAL', u'UNCLASSIFIED'):\n        return []\n    if canonicalize:\n        tmp_signers = tuple(re.split(ur'\\s+', tmp_signers.strip()))\n        if tmp_signers == (u'KEEGANPAAL',): # 04TAIPEI3991\n            signers = [u'KEEGAN', u'PAAL']\n        elif tmp_signers == (u'JOHNSONKEANE',): # 05ASUNCION807\n            signers = [u'JOHNSON', u'KEANE']\n        elif tmp_signers == (u'STEWARTBALTIMORE',): # 06MUSCAT396\n            signers = [u'STEWART', u'BALTIMORE']\n        elif tmp_signers == (u'BIGUSBELL',): # 06KIRKUK112\n            signers = [u'BIGUS', u'BELL']\n        else:\n            signers = tmp_signers\n    else:\n        signers = [signers]\n    return [c14n.canonicalize_surname(s) for s in signers] if canonicalize else signers", "response": "\\ Returns an iterable of signed by signers of the cable."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses and returns the subject of a cable.", "response": "def parse_subject(content, reference_id=None, clean=True):\n    \"\"\"\\\n    Parses and returns the subject of a cable. If the cable has no subject, an\n    empty string is returned.\n    \n    `content`\n        The cable's content.\n    `reference_id`\n        The (optional) reference id of the cable. Used for error msgs\n    `clean`\n        Indicates if classification prefixes like ``(S)`` should be removed from\n        the subject (default: ``True``)\n        * (TS) for Top Secret\n        * (S) for Secret\n        * (C) for Confidential\n        * (U) for Unclassified\n        * (SBU/N) for Sensitive But Unclassified/Noforn, and\n        * (SBU) for Sensitive But Unclassified\n        Source: \n        U.S. Department of State Foreign Affairs Handbook Volume 5 Handbook 1 \u2014 Correspondence Handbook\n        5 FAH-1 H-210 -- HOW TO USE TELEGRAMS; page 2\n        <http://www.state.gov/documents/organization/89319.pdf>\n    \"\"\"\n    def to_unicodechar(match):\n        return unichr(int(match.group(1)))\n    m = _SUBJECT_MAX_PATTERN.search(content)\n    max_idx = m.start() if m else _MAX_HEADER_IDX\n    m = _SUBJECT_PATTERN.search(content, 0, max_idx)\n    if not m:\n        return u''\n    res = m.group(1).strip()\n    res = _NL_PATTERN.sub(u' ', res)\n    res = _WS_PATTERN.sub(u' ', res)\n    res = res.replace(u'US- ', u'US-')\n    res = _HTML_ENTITIES_PATTERN.sub(to_unicodechar, res)\n    if clean:\n        res = _WS_PATTERN.sub(u' ', _SLASH_ESCAPE_PATTERN.sub(u'', _BRACES_PATTERN.sub(u'', res))).strip()\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the content of a cable and returns the list of references to other cables.", "response": "def parse_references(content, year, reference_id=None, canonicalize=True):\n    \"\"\"\\\n    Returns the references to other cables as (maybe empty) list.\n    \n    `content`\n        The content of the cable.\n    `year`\n        The year when the cable was created.\n    `reference_id`\n        The reference identifier of the cable.\n    `canonicalize`\n        Indicates if the cable reference origin should be canonicalized.\n        (enabled by default)\n    \"\"\"\n    from cablemap.core.models import Reference\n    def format_year(y):\n        y = str(y)\n        if not y:\n            y = str(year)\n        if len(y) == 4:\n            return y[2:]\n        elif len(y) == 3 and y[0] == '0':\n            return y[1:]\n        return y\n    offset = 0\n    m_offset = _REF_OFFSET_PATTERN.search(content)\n    if m_offset:\n        offset = m_offset.end()\n    # 1. Try to find \"Classified By:\"\n    m_stop = _REF_STOP_PATTERN.search(content, offset)\n    # If found, use it as maximum index to search for references, otherwise use a constant\n    max_idx = m_stop and m_stop.start() or _MAX_HEADER_IDX\n    # 2. Find references\n    m_start = _REF_START_PATTERN.search(content, offset, max_idx)\n    # 3. Check if we have a paragraph in the references\n    m_stop = _REF_NOT_REF_PATTERN.search(content, m_start and m_start.end() or 0, max_idx)\n    last_end = m_start and m_start.end() or 0\n    # 4. Find the next max_idx\n    max_idx = min(m_stop and m_stop.start() or _MAX_HEADER_IDX, max_idx)\n    m_end = _REF_LAST_REF_PATTERN.search(content, last_end, max_idx)\n    while m_end:\n        last_end = m_end.end()\n        m_end = _REF_LAST_REF_PATTERN.search(content, last_end, max_idx)\n    res = []\n    if m_end and not m_start:\n        logger.warn('Found ref end but no start in \"%s\", content: \"%s\"' % (reference_id, content))\n    if m_start and last_end:\n        start = m_start.start(1)\n        end = last_end or m_start.end()\n        refs = content[start:end].replace('\\n', ' ')\n        refs = _CLEAN_REFS_PATTERN.sub('', refs)\n        for enum, y, origin, sn, alt_year in _REF_PATTERN.findall(refs):\n            if alt_year and not y:\n                y = alt_year\n            y = format_year(y)\n            origin = origin.replace(' ', '').replace(u\"'\", u'').upper()\n            if origin == 'AND' and res and res[-1].is_cable():\n                last_origin = _REF_ORIGIN_PATTERN.match(res[-1].value).group(1)\n                origin = last_origin\n                enum = enum or res[-1].value\n            elif origin.startswith('AND') and res and res[-1].is_cable(): # for references like 09 FOO 1234 AND BAR 1234\n                origin = origin[3:]\n                enum = enum or res[-1].value\n            reference = u'%s%s%d' % (y, origin, int(sn))\n            if canonicalize:\n                reference = canonicalize_id(reference)\n            length = len(reference)\n            if length < 7 or length > 25: # constants.MIN_ORIGIN_LENGTH + constants.MIN_SERIAL_LENGTH + length of year or constants.MAX_ORIGIN_LENGTH + constants.MAX_SERIAL_LENGTH + 2 (for the year) \n                continue\n            if not REFERENCE_ID_PATTERN.match(reference):\n                if 'CORRUPTION' not in reference and 'ECRET' not in reference and 'PARISPOINT' not in reference and 'TELCON' not in reference and 'FORTHE' not in reference and 'ZOCT' not in reference and 'ZSEP' not in reference and 'ZMAY' not in reference and 'ZNOV' not in reference and 'ZAUG' not in reference and 'PRIORITY' not in reference and 'ZJAN' not in reference and 'ZFEB' not in reference and 'ZJUN' not in reference and'ZJUL' not in reference and 'PREVIO' not in reference and 'SEPTEMBER' not in reference and 'ZAPR' not in reference and 'ZFEB' not in reference and 'PART' not in reference and 'ONFIDENTIAL' not in reference and 'SECRET' not in reference and 'SECTION' not in reference and 'TODAY' not in reference and 'DAILY' not in reference and 'OUTOF' not in reference and 'PROVIDING' not in reference and 'NUMBER' not in reference and 'APRIL' not in reference and 'OCTOBER' not in reference and 'MAIL' not in reference and 'DECEMBER' not in reference and 'FEBRUAY' not in reference and 'AUGUST' not in reference and 'MARCH' not in reference and 'JULY' not in reference and 'JUNE' not in reference and 'MAIL' not in reference and 'JANUARY' not in reference and '--' not in reference and 'PARAGRAPH' not in reference and 'ANDPREVIOUS' not in reference and 'UNCLAS' not in reference and 'ONMARCH' not in reference and 'ONAPRIL' not in reference and 'FEBRUARY' not in reference and 'ONMAY' not in reference and 'ONJULY' not in reference and 'ONJUNE' not in reference and 'NOVEMBER' not in reference and not 'CONFIDENTIAL' in reference:\n                    logger.debug('Ignore \"%s\". Not a valid reference identifier (%s)' % (reference, reference_id))\n                continue\n            if reference != reference_id:\n                reference = Reference(reference, consts.REF_KIND_CABLE, enum)\n                if reference not in res:\n                    res.append(reference)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the TAGS of a cable.", "response": "def parse_tags(content, reference_id=None, canonicalize=True):\n    \"\"\"\\\n    Returns the TAGS of a cable.\n    \n    Acc. to the U.S. SD every cable needs at least one tag.\n\n    `content`\n        The content of the cable.\n    `reference_id`\n        The reference identifier of the cable.\n    `canonicalize`\n        Indicates if duplicates should be removed and malformed\n        TAGs like \"ECONEFIN\" should be corrected (becomes \"ECON\", \"EFIN\").\n        ``False`` indicates that the TAGs should be returned as found in\n        cable.\n    \"\"\"\n    max_idx = _MAX_HEADER_IDX\n    m = _SUBJECT_MAX_PATTERN.search(content)\n    if m:\n        max_idx = m.start()\n    m = _SUBJECT_PATTERN.search(content, 0, max_idx)\n    if m:\n        max_idx = min(max_idx, m.start())\n    m = _TAGS_PATTERN.search(content, 0, max_idx)\n    if not m:\n        if reference_id not in _CABLES_WITHOUT_TAGS:\n            logger.debug('No TAGS found in cable ID \"%r\", content: \"%s\"' % (reference_id, content))\n        return []\n    tags = _TAGS_CLEANUP_PATTERN.sub(u' ', m.group(1))\n    min_idx = m.end()\n    if tags.endswith(',') or tags.endswith(', ') or _TAGS_CONT_NEXT_LINE_PATTERN.match(content, min_idx, max_idx):\n        m2 = _TAGS_CONT_PATTERN.match(content, m.end(), max_idx)\n        if m2:\n            tags = re.sub(ur'\\s+', u' ', u' '.join([tags, _TAGS_CLEANUP_PATTERN.sub(u' ', m2.group(1))]))\n    res = []\n    if not canonicalize:\n        return [u''.join(tag).upper() for tag in _TAG_PATTERN.findall(tags) if tag]\n    for t in _TAG_PATTERN.findall(tags):\n        tag = u''.join(t).upper().replace(u')', u'').replace(u'(', u'')\n        if tag == u'SIPDIS':  # Found in 05OTTAWA3726 and 05OTTAWA3709. I think it's an error\n            continue\n        for tag in _TAG_FIXES.get(tag, (tag,)):\n            if tag == u'ECONSOCIXR':  # 08BRASILIA1504\n                for tag in _TAG_FIXES[tag]:\n                    if not tag in res:\n                        res.append(tag)\n                continue\n            if not tag in res:\n                res.append(tag)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterable of words from the provided text.", "response": "def words(content, filter=True, predicate=None):\n    \"\"\"\\\n    Returns an iterable of words from the provided text.\n    \n    `content`\n        A text.\n    `filter`\n        Indicates if stop words and garbage like \"xxxxxx\" should be removed from\n        the word list.\n    `predicate`\n        An alternative word filter. If it is ``None`` \"xxxx\", \"---\",\n        default stop words, and words which have no min. length of 3 are filtered\n        (iff ``filter`` is set to ``True``).\n    \n    >>> list(words('Hello and goodbye ------ '))\n    ['Hello', 'goodbye']\n    >>> list(words('Hello, and goodbye ------ Subject xxxxxxxxx XXXXXXXXXXXX here'))\n    ['Hello', 'goodbye', 'Subject']\n    >>> list(words('Hello, and goodbye.How are you?'))\n    ['Hello', 'goodbye']\n    \"\"\"\n    def accept_word(word):\n        \"\"\"\\\n        Returns if the `word` is acceptable/useful\n        \n        `word`\n            The word to check.\n        \"\"\"\n        return len(word) > 2 \\\n                and word.lower() not in stop_words \\\n                and not _UNWANTED_WORDS_PATTERN.match(word)\n    words = _tokenize(content)\n    if filter or predicate:\n        if not predicate:\n            predicate = accept_word\n        return (w for w in words if predicate(w))\n    return words"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lowercased_words(content, filter=True, predicate=None):\n    return (w.lower() for w in words(content, filter, predicate))", "response": "Returns an iterable of lowercased words from the provided text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _request(self, *args, **kwargs):\n        try:\n            self.response = self.request(\n                *args, headers=self._request_headers(), **kwargs)\n        except BaseException, err:\n            code = 520\n            if hasattr(err, 'status_int'):\n                code = err.status_int  # pylint: disable=no-member\n            if hasattr(err, 'message'):\n                message = err.message\n            raise BaruwaAPIError(code, message)\n        if self.response.status_int in [200, 201, 204]:\n            body = self.response.body_string()\n            if not body:\n                body = '{\"code\":%d,\"message\":\"Completed successfully\"}' % \\\n                    self.response.status_int\n        else:\n            raise BaruwaAPIError(\n                code=self.response.status_int,\n                message=self.response.body_string())\n        return json.loads(body)", "response": "Make the request and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_users(self, page=None):\n        opts = {}\n        if page:\n            opts['page'] = page\n        return self.api_call(ENDPOINTS['users']['list'], **opts)", "response": "Get users in a page"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting domains in a page", "response": "def get_domains(self, page=None):\n        \"\"\"Get domains\"\"\"\n        opts = {}\n        if page:\n            opts['page'] = page\n        return self.api_call(ENDPOINTS['domains']['list'], **opts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_domainalias(self, domainid, aliasid):\n        return self.api_call(\n            ENDPOINTS['domainaliases']['get'],\n            dict(domainid=domainid, aliasid=aliasid))", "response": "Get a Domain alias"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_domainalias(self, domainid, data):\n        return self.api_call(\n            ENDPOINTS['domainaliases']['new'],\n            dict(domainid=domainid),\n            body=data)", "response": "Create a domain alias"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_domainalias(self, domainid, aliasid, data):\n        return self.api_call(\n            ENDPOINTS['domainaliases']['update'],\n            dict(domainid=domainid, aliasid=aliasid),\n            body=data)", "response": "Update a domain alias"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_deliveryservers(self, domainid, page=None):\n        opts = {}\n        if page:\n            opts['page'] = page\n        return self.api_call(\n            ENDPOINTS['deliveryservers']['list'],\n            dict(domainid=domainid), **opts)", "response": "Get a domains delivery servers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_deliveryserver(self, domainid, serverid):\n        return self.api_call(\n            ENDPOINTS['deliveryservers']['get'],\n            dict(domainid=domainid, serverid=serverid))", "response": "Get a delivery server"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a delivery server", "response": "def create_deliveryserver(self, domainid, data):\n        \"\"\"Create a delivery server\"\"\"\n        return self.api_call(\n            ENDPOINTS['deliveryservers']['new'],\n            dict(domainid=domainid),\n            body=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_deliveryserver(self, domainid, serverid):\n        return self.api_call(\n            ENDPOINTS['userdeliveryservers']['get'],\n            dict(domainid=domainid, serverid=serverid))", "response": "Get a user delivery server"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a user delivery server", "response": "def create_user_deliveryserver(self, domainid, data):\n        \"\"\"Create a user delivery server\"\"\"\n        return self.api_call(\n            ENDPOINTS['userdeliveryservers']['new'],\n            dict(domainid=domainid),\n            body=data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_domain_smarthost(self, domainid, serverid):\n        return self.api_call(\n            ENDPOINTS['domainsmarthosts']['get'],\n            dict(domainid=domainid, serverid=serverid))", "response": "Get a domain smarthost"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_domain_smarthost(self, domainid, data):\n        return self.api_call(\n            ENDPOINTS['domainsmarthosts']['new'],\n            dict(domainid=domainid),\n            body=data)", "response": "Create a domain smarthost"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_domain_smarthost(self, domainid, serverid, data):\n        return self.api_call(\n            ENDPOINTS['domainsmarthosts']['update'],\n            dict(domainid=domainid, serverid=serverid),\n            body=data)", "response": "Update a domain smarthost"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget Authentication servers for a domain", "response": "def get_authservers(self, domainid, page=None):\n        \"\"\"Get Authentication servers\"\"\"\n        opts = {}\n        if page:\n            opts['page'] = page\n        return self.api_call(\n            ENDPOINTS['authservers']['list'],\n            dict(domainid=domainid), **opts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an Authentication server", "response": "def get_authserver(self, domainid, serverid):\n        \"\"\"Get an Authentication server\"\"\"\n        return self.api_call(\n            ENDPOINTS['authservers']['get'],\n            dict(domainid=domainid, serverid=serverid))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_authserver(self, domainid, data):\n        return self.api_call(\n            ENDPOINTS['authservers']['new'],\n            dict(domainid=domainid),\n            body=data)", "response": "Create an Authentication server"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_relay(self, orgid, data):\n        return self.api_call(\n            ENDPOINTS['relays']['new'],\n            dict(orgid=orgid), body=data)", "response": "Create a new relay"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_relay(self, relayid, data):\n        return self.api_call(\n            ENDPOINTS['relays']['update'],\n            dict(relayid=relayid),\n            body=data)", "response": "Update the relay settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_org_smarthost(self, orgid, serverid):\n        return self.api_call(\n            ENDPOINTS['orgsmarthosts']['get'],\n            dict(orgid=orgid, serverid=serverid))", "response": "Get an organization smarthost"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an organization smarthost", "response": "def create_org_smarthost(self, orgid, data):\n        \"\"\"Create an organization smarthost\"\"\"\n        return self.api_call(\n            ENDPOINTS['orgsmarthosts']['new'],\n            dict(orgid=orgid),\n            body=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_org_smarthost(self, orgid, serverid, data):\n        return self.api_call(\n            ENDPOINTS['orgsmarthosts']['update'],\n            dict(orgid=orgid, serverid=serverid),\n            body=data)", "response": "Update an organization smarthost"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrestores a file if it exists and remove the backup", "response": "def _restore_file(path, delete_backup=True):\n    \"\"\"\n    Restore a file if it exists and remove the backup\n    \"\"\"\n    backup_base = '/var/local/woven-backup'\n    backup_path = ''.join([backup_base,path])\n    if exists(backup_path):\n        if delete_backup:\n            sudo('mv -f %s %s'% (backup_path,path))\n        else:\n            sudo('cp -f %s %s'% (backup_path,path))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_local_files(local_dir, pattern=''):\n    local_files = {}\n    \n    if pattern:\n        cwd = os.getcwd()\n        os.chdir(local_dir)\n        patterns = pattern.split('|')\n        local_list = set([])\n        for p in patterns: local_list = local_list | set(glob(p))\n        for path in local_list:\n            dir, file = os.path.split(path)\n            if os.path.isfile(path):\n                local_files[dir] = local_files.get(dir,[])+[file]\n            elif os.path.isdir(path):\n                local_files[file] = local_files.get(dir,[])\n        os.chdir(cwd)\n    return local_files", "response": "Returns a dictionary with directories as keys and filenames as values as values\n    for all files in the local_dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstages local files into a temporary local staging directory.", "response": "def _stage_local_files(local_dir, local_files={}):\n    \"\"\"\n    Either ``local_files`` and/or ``context`` should be supplied.\n    \n    Will stage a ``local_files`` dictionary of path:filename pairs where path\n    is relative to ``local_dir`` into a local tmp staging directory.\n    \n    Returns a path to the temporary local staging directory\n\n    \"\"\"\n    staging_dir = os.path.join(tempfile.mkdtemp(),os.path.basename(local_dir))\n    os.mkdir(staging_dir)\n    for root, dirs, files in os.walk(local_dir):\n        relative_tree = root.replace(local_dir,'')\n        if relative_tree:\n            relative_tree = relative_tree[1:]\n        if local_files:\n            files = local_files.get(relative_tree,[])\n        for file in files:\n            if relative_tree:\n                filepath = os.path.join(relative_tree,file)\n                if not os.path.exists(os.path.join(staging_dir,relative_tree)):\n                    os.mkdir(os.path.join(staging_dir,relative_tree))\n            else: filepath = file\n            shutil.copy2(os.path.join(root,file),os.path.join(staging_dir,filepath))\n    return staging_dir"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deploy_files(local_dir, remote_dir, pattern = '',rsync_exclude=['*.pyc','.*'], use_sudo=False):\n    #normalise paths\n    if local_dir[-1] == os.sep: local_dir = local_dir[:-1]\n    if remote_dir[-1] == '/': remote_dir = remote_dir[:-1]\n    created_list = []\n    staging_dir = local_dir\n    \n    #resolve pattern into a dir:filename dict\n    local_files = _get_local_files(local_dir,pattern)\n    #If we are only copying specific files or rendering templates we need to stage locally\n    if local_files: staging_dir = _stage_local_files(local_dir, local_files)\n    remote_staging_dir = '/home/%s/.staging'% env.user\n    if not exists(remote_staging_dir):\n        run(' '.join(['mkdir -pv',remote_staging_dir])).split('\\n')\n        created_list = [remote_staging_dir]\n    \n    #upload into remote staging\n    rsync_project(local_dir=staging_dir,remote_dir=remote_staging_dir,exclude=rsync_exclude,delete=True)\n\n    #create the final destination\n    created_dir_list = mkdirs(remote_dir, use_sudo)\n    \n    if not os.listdir(staging_dir): return created_list\n\n    func = use_sudo and sudo or run\n    #cp recursively -R from the staging to the destination and keep a list\n    remote_base_path = '/'.join([remote_staging_dir,os.path.basename(local_dir),'*'])\n    copy_file_list = func(' '.join(['cp -Ruv',remote_base_path,remote_dir])).split('\\n')\n    if copy_file_list[0]: created_list += [file.split(' ')[2][1:-1] for file in copy_file_list if file]\n\n    #cleanup any tmp staging dir\n    if staging_dir <> local_dir:\n        shutil.rmtree(staging_dir,ignore_errors=True)\n    \n    return created_list", "response": "Deploy files to a remote server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mkdirs(remote_dir, use_sudo=False):\n    func = use_sudo and sudo or run\n    result = func(' '.join(['mkdir -pv',remote_dir])).split('\\n')\n    #extract dir list from [\"mkdir: created directory `example.com/some/dir'\"]\n    if result[0]: result = [dir.split(' ')[3][1:-1] for dir in result if dir]\n    return result", "response": "Wrapper around mkdir - pv\n    \n    Wrapper around mkdir - pv\n    \n    Returns a list of directories created\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_template(filename,  destination,  context={},  use_sudo=False, backup=True, modified_only=False):\n    #Replaces the default fabric.contrib.files.upload_template\n    basename = os.path.basename(filename)\n    text = render_to_string(filename,context)\n\n    func = use_sudo and sudo or run\n    \n    #check hashed template on server first\n    if modified_only:\n        hashfile_dir, hashfile = os.path.split(destination)\n        hashfile_dir = ''.join(['/var/local/woven-backup',hashfile_dir])\n        hashfile = '%s.hashfile'% hashfile\n        hashfile_path = os.path.join(hashfile_dir, hashfile)\n        hashed = sha1(text).hexdigest()\n        if hashfile:\n            if not exists(hashfile_dir): sudo('mkdir -p %s'% hashfile_dir)\n            sudo('touch %s'% hashfile_path) #store the hash near the template\n            previous_hashed = sudo('cat %s'% hashfile_path).strip()\n            if previous_hashed == hashed:\n                return False\n            else: sudo('echo %s > %s'% (hashed, hashfile_path))\n\n    temp_destination = '/tmp/' + basename\n\n    # This temporary file should not be automatically deleted on close, as we\n    # need it there to upload it (Windows locks the file for reading while open).\n    tempfile_fd, tempfile_name = tempfile.mkstemp()\n    output = open(tempfile_name, \"w+b\")\n    \n    output.write(text)\n    output.close()\n        \n    # Upload the file.\n    put(tempfile_name, temp_destination)\n    os.close(tempfile_fd)\n    os.remove(tempfile_name)\n\n    \n    # Back up any original file (need to do figure out ultimate destination)\n    if backup:\n        to_backup = destination\n        with settings(hide('everything'), warn_only=True):\n            # Is destination a directory?\n            if func('test -f %s' % to_backup).failed:\n                # If so, tack on the filename to get \"real\" destination\n                to_backup = destination + '/' + basename\n        if exists(to_backup):\n            _backup_file(to_backup)\n    # Actually move uploaded template to destination\n    func(\"mv %s %s\" % (temp_destination, destination))\n    return True", "response": "Uploads a template text file to a remote host using the Django template api."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if version is a pre - release.", "response": "def pre_release(self):\n        \"\"\" Return true if version is a pre-release. \"\"\"\n        label = self.version_info.get('label', None)\n        pre = self.version_info.get('pre', None)\n\n        return True if (label is not None and pre is not None) else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bump(self, level='patch', label=None):\n        bump = self._bump_pre if level == 'pre' else self._bump\n        bump(level, label)", "response": "Bump version following semantic versioning rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets all levels after base_level to zero.", "response": "def zeroize_after_level(self, base_level):\n        \"\"\" Set all levels after ``base_level`` to zero. \"\"\"\n        index = _LEVELS.index(base_level) + 1\n        for level in _LEVELS[index:]:\n            self.version_info[level] = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_version(self):\n        version = '{major}.{minor}.{patch}'.format(**self.version_info)\n\n        if self.pre_release:\n            version = '{}-{label}.{pre}'.format(version, **self.version_info)\n        return version", "response": "Return complete version string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, request):\n        '''Simply list test urls\n        '''\n        data = {}\n        for router in self.routes:\n            data[router.name] = request.absolute_uri(router.path())\n        return Json(data).http_response(request)", "response": "Simply list test urls\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setParams(self,params):\n        self.params = params\n        self.clear_all()\n        self._notify()", "response": "set params of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing paramters to vector of zeros", "response": "def _initParams(self):\n         \"\"\"\n         initialize paramters to vector of zeros\n         \"\"\"\n         params = SP.zeros(self.getNumberParams())\n         self.setParams(params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_frame(buf):\n    # read header\n    while buf.available < 2:\n        yield\n\n    data = buf.read(2)\n    first_byte, second_byte = struct.unpack('!BB', data)\n\n    fin = (first_byte >> 7) & 1\n    rsv1 = (first_byte >> 6) & 1\n    rsv2 = (first_byte >> 5) & 1\n    rsv3 = (first_byte >> 4) & 1\n    opcode = first_byte & 0xf\n\n    # frame-fin = %x0 ; more frames of this message follow\n    #           / %x1 ; final frame of this message\n    # frame-rsv1 = %x0 ; 1 bit, MUST be 0 unless negotiated otherwise\n    # frame-rsv2 = %x0 ; 1 bit, MUST be 0 unless negotiated otherwise\n    # frame-rsv3 = %x0 ; 1 bit, MUST be 0 unless negotiated otherwise\n    if rsv1 or rsv2 or rsv3:\n        raise WebSocketError('Received frame with non-zero reserved bits')\n\n    if opcode > 0x7 and fin == 0:\n        raise WebSocketError('Received fragmented control frame')\n\n    if fin == 0 and opcode == OPCODE_CONTINUATION:\n        raise WebSocketError(\n            'Received new fragment frame with non-zero opcode')\n\n    has_mask = (second_byte >> 7) & 1\n    length = (second_byte) & 0x7f\n\n    # Control frames MUST have a payload length of 125 bytes or less\n    if opcode > 0x7 and length > 125:\n        raise WebSocketError(\n            \"Control frame payload cannot be larger than 125 bytes\")\n\n    # read payload\n    if length == 126:\n        while buf.available < 2:\n            yield\n\n        length = struct.unpack_from('!H', buf.read(2))[0]\n    elif length > 126:\n        while buf.available < 4:\n            yield\n\n        length = struct.unpack_from('!Q', buf.read(4))[0]\n\n    if has_mask:\n        while buf.available < 4:\n            yield\n\n        mask = buf.read(4)\n\n    if length:\n        while buf.available < length:\n            yield\n\n        payload = buf.read(length)\n    else:\n        payload = b''\n\n    if has_mask:\n        mask = [ord(i) for i in mask]\n        payload = [chr(ord(b) ^ mask[i % 4]) for i, b in enumerate(payload)]\n\n    yield fin, opcode, payload", "response": "Parse a single frame from the socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a close frame.", "response": "def make_close_message(code=1000, message=b''):\n    \"\"\"Close the websocket, sending the specified code and message.\"\"\"\n    return _make_frame(struct.pack('!H%ds' % len(message), code, message),\n                       opcode=OPCODE_CLOSE)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shell_command():\n    from flask.globals import _app_ctx_stack\n    from ptpython.repl import embed\n\n    app = _app_ctx_stack.top.app\n    ctx = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get('PYTHONSTARTUP')\n    if startup and os.path.isfile(startup):\n        with open(startup, 'r') as f:\n            eval(compile(f.read(), startup, 'exec'), ctx)\n\n    ctx.update(app.make_shell_context())\n\n    embed(globals=ctx)", "response": "Runs an interactive Python shell in the context of a given\n    Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command(self, func):\n        command = Command(func)\n        self._commands[func.__name__] = command\n        return func", "response": "Decorator to add a command function to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a command function to the registry.", "response": "def add_command(self, func, name=None, doc=None):\n        \"\"\"\n        Add a command function to the registry.\n\n        :param func: command function.\n        :param name: default name of func.\n        :param doc: description of the func.default docstring of func.\n\n        \"\"\"\n        command = Command(func, doc)\n        name = name or func.__name__\n        self._commands[name] = command"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, command=None, argv=None, help=True, exit=True):\n\n        result = 0\n        if argv is None:\n            argv = sys.argv[1:]\n\n        args = self.parse(self.doc, argv=argv, help=help, first=True)\n\n        if command is None and len(sys.argv) > 1:\n            cmd = argv[0]\n        else:\n            cmd = args.get(command, None)\n\n        if cmd in self._commands:\n            cmd = self._commands[cmd]\n            args = self.parse(cmd.doc, argv=argv, help=help)\n            args = self.process_args(args)\n            result = cmd(**args)\n\n        if exit:\n            sys.exit(result)\n        return result", "response": "Parse arguments and run the functions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that a HTTP response returned 200.", "response": "def assert_200(response, max_len=500):\n  \"\"\" Check that a HTTP response returned 200. \"\"\"\n  if response.status_code == 200:\n    return\n\n  raise ValueError(\n      \"Response was {}, not 200:\\n{}\\n{}\".format(\n          response.status_code,\n          json.dumps(dict(response.headers), indent=2),\n          response.content[:max_len]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url_as_file(url, ext=None):\n    if ext:\n        ext = '.' + ext.strip('.')  # normalize extension\n    url_hint = 'www-{}-'.format(urlparse(url).hostname or 'any')\n\n    content = requests.get(url).content\n    with tempfile.NamedTemporaryFile(suffix=ext or '', prefix=url_hint, delete=False) as handle:\n        handle.write(content)\n\n    try:\n        yield handle.name\n    finally:\n        if os.path.exists(handle.name):\n            os.remove(handle.name)", "response": "Context manager that GETs a given URL and provides it as a local file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef t_NUMBER(self, t):\n        r'(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?(kb|gb|mb|tb|pb|Kb|Gb|Mb|Tb|Pb)?'\n        if re.match(r'^(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?(kb|gb|mb|tb|pb|Kb|Gb|Mb|Tb|Pb)?$',t.value):\n            multiplyer = 1\n            try:\n                suffix = (t.value[-2:]).lower()\n                if suffix in ['kb']:\n                    multiplyer = 1024\n                elif suffix in ['mb']:\n                    multiplyer = 1024*1024\n                elif suffix in ['gb']:\n                    multiplyer = 1024*1024*1024\n                elif suffix in ['tb']:\n                    multiplyer = 1024*1024*1024*1024\n                elif suffix in ['pb']:\n                    multiplyer = 1024*1024*1024*1024*1024\n                \n                if multiplyer > 1:\n                    t.value = t.value[:-2]\n            except:\n                pass\n            \n            try:\n                f = float(t.value)\n                try:\n                    e = int(t.value)\n                except ValueError:\n                    e = f\n                    \n                if (e == f):\n                    t.value = multiplyer*e\n                else:\n                    t.value = multiplyer*f\n            except ValueError:\n                _LOGGER.error(\"el valor %s no es un numero valido\" % t.value)\n                t.value = 0\n        else:\n            t.type = 'STRING'\n            \n        return t", "response": "parses un numero de la valor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_VAR(self, t):\n        r'[a-zA-Z_][a-zA-Z0-9_]*'\n        t.type = self.reserved.get(t.value.lower(), 'VAR')\n        return t", "response": "t_VAR is a variable type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_kwl_kwl(self, p):\n        ''' kwl : kwl SEPARATOR kwl \n        '''\n        _LOGGER.debug(\"kwl -> kwl ; kwl\")\n        if p[3] is not None:\n            p[0] = p[3]\n        elif p[1] is not None:\n            p[0] = p[1]\n        else:\n            p[0] = TypedClass(None, TypedClass.UNKNOWN)", "response": "kwl = 1. 3. 1. 2. 1. 2. 1. 2. 2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_notexpr(self, p):\n        ''' expression  : NOT expression\n                        | '!' expression\n        '''\n        _LOGGER.debug(\"expresion -> ! expression\")\n        if p[2].type == TypedClass.BOOLEAN: \n            p[0] = TypedClass(not p[2].value, TypedClass.BOOLEAN)\n        else:\n            raise TypeError(\"operator invalid for this type\")", "response": "expression  : NOT expression\n                        | '!' expression"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_expression_inlist(self, p):\n        ''' expression    :   expression IN lexp \n        '''\n        _LOGGER.debug(\"expresion -> expresion IN lexp\")\n\n        if self._autodefine_vars:\n            self._init_vars(TypedList([]), p[3])\n\n        if p[3].type != TypedClass.LIST: raise TypeError(\"expected list for IN operator\")\n        \n        retval = False\n        for v in p[3].value:\n            if p[1] == v:\n                retval = True\n                break\n        \n        p[0] = TypedClass(retval, TypedClass.BOOLEAN)", "response": "expression    :   expression IN lexp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expression_invar(self, p):\n        ''' expression    :   expression IN VAR \n        '''\n        _LOGGER.debug(\"expresion -> expresion IN VAR\")\n    \n        if p[3] not in self._VAR_VALUES:\n            if self._autodefine_vars:\n                self._VAR_VALUES[p[3]] = TypedList([])\n            else:\n                raise TypeError(\"list expected for IN operator\")\n            \n        l = self._VAR_VALUES[p[3]]\n        if l.type != TypedList.LIST: raise TypeError(\"list expected for IN operator\")\n        p[3] = l\n        \n        self.p_expression_inlist(p)", "response": "Expression IN VAR IN LIST"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_expression_subsetvar(self, p):\n        ''' expression    :   expression SUBSET VAR \n        '''\n        _LOGGER.debug(\"expresion -> expresion SUBSET VAR\")\n    \n        if p[3] not in self._VAR_VALUES:\n            if self._autodefine_vars:\n                self._VAR_VALUES[p[3]] = TypedList([])\n            else:\n                raise TypeError(\"lists expected for SUBSET operator\")\n            \n        l = self._VAR_VALUES[p[3]]\n        if l.type != TypedList.LIST: raise TypeError(\"lists expected for SUBSET operator\")\n        p[3] = l\n        \n        self.p_expression_subsetlist(p)", "response": "Expression SEQVAR | |"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_term_bool(self, p):\n        ''' term    :   TRUE\n                    |   FALSE \n        '''\n        _LOGGER.debug(\"term -> TRUE/FALSE\")\n\n        if p[1].lower() == 'true':\n            p[0] = TypedClass(True, TypedClass.BOOLEAN)\n        else:\n            p[0] = TypedClass(False, TypedClass.BOOLEAN)", "response": "term    :   TRUE\n                    |   FALSE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handleMatch(self, m):\n\n        polysyllabic_chinese_word = m.group(2)\n        parent = etree.Element(JUNK_TAG)\n        for i, sound in enumerate(pinyin_regex.split_syllables(polysyllabic_chinese_word)):\n            if sound == 'r':\n                self.make_span(parent, 'r', self.erhua_class)\n            else:\n                if i > 0 and sound[0] in 'aeo':\n                    self.make_span(parent, \"'\", self.apostrophe_class)\n                accented = numbered_accented.numbered_syllable_to_accented(sound)\n                if accented == sound:\n                    raise Exception(\"Pinyin conversion error: \" + sound)\n                if self.entities:\n                    accented = self.convert_to_entities(accented)\n                self.make_span(parent, accented, self.tone_class(sound[-1]))\n        return parent", "response": "Handles a match from a Pinyin syllabic word to a Pinyin XML element."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_content(self, **content):\n\n        LOGGER.debug(\"> Adding '{0}' content to the cache.\".format(self.__class__.__name__, content))\n\n        self.update(**content)\n        return True", "response": "Adds given content to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving given content from the cache.", "response": "def remove_content(self, *keys):\n        \"\"\"\n        Removes given content from the cache.\n\n        Usage::\n\n            >>> cache = Cache()\n            >>> cache.add_content(John=\"Doe\", Luke=\"Skywalker\")\n            True\n            >>> cache.remove_content(\"Luke\", \"John\")\n            True\n            >>> cache\n            {}\n\n        :param \\*keys: Content to remove.\n        :type \\*keys: \\*\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        LOGGER.debug(\"> Removing '{0}' content from the cache.\".format(self.__class__.__name__, keys))\n\n        for key in keys:\n            if not key in self:\n                raise KeyError(\"{0} | '{1}' key doesn't exists in cache content!\".format(self.__class__.__name__, key))\n\n            del self[key]\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets given content from the cache.", "response": "def get_content(self, key):\n        \"\"\"\n        Gets given content from the cache.\n\n        Usage::\n\n            >>> cache = Cache()\n            >>> cache.add_content(John=\"Doe\", Luke=\"Skywalker\")\n            True\n            >>> cache.get_content(\"Luke\")\n            'Skywalker'\n\n        :param key: Content to retrieve.\n        :type key: object\n        :return: Content.\n        :rtype: object\n        \"\"\"\n\n        LOGGER.debug(\"> Retrieving '{0}' content from the cache.\".format(self.__class__.__name__, key))\n\n        return self.get(key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflush the content of the cache.", "response": "def flush_content(self):\n        \"\"\"\n        Flushes the cache content.\n\n        Usage::\n\n            >>> cache = Cache()\n            >>> cache.add_content(John=\"Doe\", Luke=\"Skywalker\")\n            True\n            >>> cache.flush_content()\n            True\n            >>> cache\n            {}\n\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        LOGGER.debug(\"> Flushing cache content.\".format(self.__class__.__name__))\n\n        self.clear()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nposting text to a given twitter account.", "response": "def post(arguments):\n    '''Post text to a given twitter account.'''\n    twitter = api.API(arguments)\n    params = {}\n\n    if arguments.update == '-':\n        params['status'] = sys.stdin.read()\n    else:\n        params['status'] = arguments.update\n\n    if arguments.media_file:\n        medias = [twitter.media_upload(m) for m in arguments.media_file]\n        params['media_ids'] = [m.media_id for m in medias]\n\n    try:\n        logging.getLogger(arguments.screen_name).info('status: %s', params['status'])\n        if not arguments.dry_run:\n            twitter.update_status(**params)\n\n    except tweepy.TweepError as e:\n        logging.getLogger(arguments.screen_name).error(e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sso_api_list():\n        ssourls = []\n\n        def collect(u, prefixre, prefixname):\n            _prefixname = prefixname + [u._regex, ]\n            urldisplayname = \" \".join(_prefixname)\n\n            if hasattr(u.urlconf_module, \"_MODULE_MAGIC_ID_\") \\\n                    and getattr(u.urlconf_module, \"_MODULE_MAGIC_ID_\") == MAGIC_ID:  # find aap name sso\n                ssourls.append(urldisplayname)\n\n        rooturl = import_by_path(settings.ROOT_URLCONF + \".urlpatterns\")\n        # traverse url matching tree to find the url statement including sso app,\n        # should be 1 element in the ssourls unless you assigned 1+ prefix url for sso app\n        traverse_urls(rooturl, resolverFunc=collect)\n\n        finalQ = Q()  # filter to get full url of all registered sso api\n        for prefix in ssourls:\n            finalQ |= Q(name__startswith=prefix)\n        return APIEntryPoint.objects.filter(finalQ)", "response": "return all the APIEntryPoints that are registered with the sso app"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _simplify_feature_value(self, name, value):\n        if name == 'prefix':\n            channel_modes, channel_chars = value.split(')')\n            channel_modes = channel_modes[1:]\n\n            # [::-1] to reverse order and go from lowest to highest privs\n            value = OrderedDict(list(zip(channel_modes, channel_chars))[::-1])\n\n            return value\n\n        elif name == 'chanmodes':\n            value = value.split(',')\n            return value\n\n        elif name == 'targmax':\n            max_available = {}\n            for sort in value.split(','):\n                command, limit = sort.split(':')\n                command = command.casefold()\n                max_available[command] = limit_to_number(limit)\n\n            return max_available\n\n        elif name == 'chanlimit':\n            limit_available = {}\n            for sort in value.split(','):\n                chan_types, limit = sort.split(':')\n                for prefix in chan_types:\n                    limit_available[prefix] = limit_to_number(limit)\n\n            return limit_available\n\n        elif name in _limits:\n            value = limit_to_number(value)\n            return value\n\n        else:\n            return value", "response": "Return simplified and more pythonic feature values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the Geno file into windows.", "response": "def splitGeno(self,method='slidingWindow',size=5e4,step=None,annotation_file=None,cis=1e4,funct=None,minSnps=1.,maxSnps=SP.inf,cache=False,out_dir='./cache',fname=None,rewrite=False):\n        \"\"\"\n        split into windows\n        Args:\n            method:     method used to slit the windows:\n                        'slidingWindow':    uses a sliding window\n                        'geneWindow':       uses windows centered on genes\n            size:       window size used in slidingWindow method\n            step:       moving step used in slidingWindow method\n            annotation_file:    file containing the annotation file for geneWindow method\n            minSnps:    only windows with nSnps>=minSnps are considered\n            maxSnps:    only windows with nSnps>=maxSnps are considered\n            cache:      if results need to be cashed\n            out_dir:    folder used for caching\n            fname:      name of the hdf5 file used for caching\n            rewrite:    if true, rewrite the existing cache hdf5 file\n        \"\"\"\n        self.info= {} # forget everything\n        # check if it is necessary to read form file or not\n        read_from_file = False\n        if cache:\n            assert fname is not None, 'Splitter:: specify fname'\n            if not os.path.exists(out_dir):\n                os.makedirs(out_dir)\n            out_file = os.path.join(out_dir,fname)\n            read_from_file = os.path.exists(out_file) and not rewrite\n\n        self.size = size\n\n        if read_from_file:\n            # reads from file\n            f = h5py.File(out_file,'r')\n            self._wnd_pos = f['wnd_pos'][:]\n            self._idx_wnd_start = f['idx_wnd_start'][:]\n            self._nSnps = f['nSnps'][:]\n            f.close()\n        else:\n            # calculates windows using the indicated method\n            if method=='slidingWindow':\n                self._splitGenoSlidingWindow(size=size,step=step,minSnps=minSnps,maxSnps=maxSnps)\n            elif method=='geneWindow':\n                self._splitGenoGeneWindow(annotation_file=annotation_file,cis=cis,funct=funct,minSnps=minSnps,maxSnps=maxSnps)\n\n            if cache:\n                f = h5py.File(out_file,'w')\n                f.create_dataset('wnd_pos', data=self._wnd_pos)\n                f.create_dataset('idx_wnd_start', data=self._idx_wnd_start)\n                f.create_dataset('nSnps', data=self._nSnps)\n                f.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit into windows using a slide criterion Args: size: window size step: moving step (default: 0.5*size) minSnps: only windows with nSnps>=minSnps are considered maxSnps: only windows with nSnps>=maxSnps are considered", "response": "def _splitGenoSlidingWindow(self,size=5e4,step=None,minSnps=1.,maxSnps=SP.inf):\n        \"\"\"\n        split into windows using a slide criterion\n        Args:\n            size:       window size\n            step:       moving step (default: 0.5*size)\n            minSnps:    only windows with nSnps>=minSnps are considered\n            maxSnps:    only windows with nSnps>=maxSnps are considered\n        \"\"\"\n        if step is None:    step = 0.5*size\n        chroms  = SP.unique(self.chrom)\n        wnd_pos       = []\n        idx_wnd_start = []\n        nSnps         = []\n        wnd_i = 0\n\n        nSnps = []\n        for chrom_i in chroms:\n            start = 0\n            Ichrom = self.chrom==chrom_i\n            idx_chrom_start = SP.where(Ichrom)[0][0]\n            pos_chr = self.pos[Ichrom]\n            pos_chr_max = pos_chr.max()\n            while 1:\n                if start>pos_chr_max: break\n                end = start+size\n                Ir = (self.pos>=start)*(self.pos<end)\n                _nSnps = Ir.sum()\n                if _nSnps>minSnps and _nSnps<maxSnps:\n                    wnd_pos.append([chrom_i,start,start+size])\n                    nSnps.append(_nSnps)\n                    idx_wnd_start.append(idx_chrom_start+SP.where(Ir)[0][0])\n                    wnd_i+=1\n                start += step\n        self._wnd_pos = SP.array(wnd_pos)\n        self._idx_wnd_start = SP.array(idx_wnd_start)\n        self._nSnps = SP.array(nSnps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits Geno gene windows into nSnps and Igene sets", "response": "def _splitGenoGeneWindow(self,annotation_file=None,cis=1e4,funct='protein_coding',minSnps=1.,maxSnps=SP.inf):\n        \"\"\"\n        split into windows based on genes\n        \"\"\"\n         #1. load annotation\n        assert annotation_file is not None, 'Splitter:: specify annotation file'\n        try:\n            f = h5py.File(annotation_file,'r')\n            geneID = f['geneID'][:]\n            gene_chrom = f['chrom'][:]\n            gene_start = f['start'][:]\n            gene_end = f['end'][:]\n            gene_strand = f['strand'][:]\n            gene_function = f['function'][:]\n            f.close()\n        except:\n            print('Splitter:: format annotation file not valid')\n\n        # if funct is not None, it has to be a list\n        if funct is not None and funct!=list:   funct=[funct]\n\n        windows = []\n        nSnps   = []\n        Igene   = []\n        #2. calculates windows \n        for gene_i in range(geneID.shape[0]):\n            if funct is not None:\n                if gene_function[gene_i] not in funct:\n                    Igene.append(False)\n                    continue\n            wnd = [gene_chrom[gene_i],gene_start[gene_i]-cis,gene_end[gene_i]+cis]\n            Ir = (self.chrom==wnd[0])*(self.pos>=wnd[1])*(self.pos<=wnd[2])\n            _nSnps = Ir.sum()\n            if _nSnps>=minSnps and _nSnps<=maxSnps:\n                windows.append(wnd)\n                nSnps.append(_nSnps)\n                Igene.append(True)\n            else:\n                Igene.append(False)\n        Igene = SP.array(Igene)\n        self.info['nSnps'] = SP.array(nSnps)\n        self.info['geneID']        = geneID[Igene]\n        self.info['gene_start']    = gene_start[Igene]\n        self.info['gene_end']      = gene_end[Igene]\n        self.info['gene_strand']   = gene_strand[Igene]\n        self.info['gene_function'] = gene_function[Igene]\n        return SP.array(windows)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the object is created.", "response": "def check_is_created(method):\n    \"\"\" Make sure the Object DOES have an id, already. \"\"\"\n    def check(self, *args, **kwargs):\n        if self.id is None:\n            raise NotCreatedError('%s does not exists.' %\n                                  self.__class__.__name__)\n        return method(self, *args, **kwargs)\n    return check"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_is_not_created(method):\n    def check(self, *args, **kwargs):\n        if self.id is not None:\n            raise AlreadyCreatedError('%s.id %s already exists.' %\n                                     (self.__class__.__name__, self.id))\n        return method(self, *args, **kwargs)\n    return check", "response": "Check if the object has an id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asynchronous(method):\n    def _async(*args, **kwargs):\n        GObject.idle_add(method, *args, **kwargs)\n    return _async", "response": "A decorator that returns a function that will be executed in the background."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_future(fut, *, loop=None):\n    if sys.version_info < (3, 4, 4):\n        # This is to avoid a SyntaxError on 3.7.0a2+\n        func = getattr(asyncio, \"async\")\n    else:\n        func = asyncio.ensure_future\n\n    return func(fut, loop=loop)", "response": "Wraps asyncio. ensure_future depending on the python version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_default_args(parser, version=None, include=None):\n    '''\n    Add default arguments to a parser. These are:\n        - config: argument for specifying a configuration file.\n        - user: argument for specifying a user.\n        - dry-run: option for running without side effects.\n        - verbose: option for running verbosely.\n        - quiet: option for running quietly.\n        - version: option for spitting out version information.\n\n    Args:\n        version (str): version to return on <cli> --version\n        include (Sequence): default arguments to add to cli. Default: (config, user, dry-run, verbose, quiet)\n    '''\n    include = include or ('config', 'user', 'dry-run', 'verbose', 'quiet')\n\n    if 'config' in include:\n        parser.add_argument('-c', '--config', dest='config_file', metavar='PATH', default=None,\n                            type=str, help='bots config file (json or yaml)')\n    if 'user' in include:\n        parser.add_argument('-u', '--user', dest='screen_name', type=str, help=\"Twitter screen name\")\n\n    if 'dry-run' in include:\n        parser.add_argument('-n', '--dry-run', action='store_true', help=\"Don't actually do anything\")\n\n    if 'verbose' in include:\n        parser.add_argument('-v', '--verbose', action='store_true', help=\"Run talkatively\")\n\n    if 'quiet' in include:\n        parser.add_argument('-q', '--quiet', action='store_true', help=\"Run quietly\")\n\n    if version:\n        parser.add_argument('-V', '--version', action='version', version=\"%(prog)s \" + version)", "response": "Add default arguments to a parser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the default args as a parent parser optionally adding a version", "response": "def parent(version=None, include=None):\n    '''\n    Return the default args as a parent parser, optionally adding a version\n\n    Args:\n        version (str): version to return on <cli> --version\n        include (Sequence): default arguments to add to cli. Default: (config, user, dry-run, verbose, quiet)\n    '''\n    parser = argparse.ArgumentParser(add_help=False)\n    add_default_args(parser, version=version, include=include)\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a logger to stdout.", "response": "def add_logger(name, level=None, format=None):\n    '''\n    Set up a stdout logger.\n\n    Args:\n        name (str): name of the logger\n        level: defaults to logging.INFO\n        format (str): format string for logging output.\n                      defaults to ``%(filename)-11s %(lineno)-3d: %(message)s``.\n\n    Returns:\n        The logger object.\n    '''\n    format = format or '%(filename)-11s %(lineno)-3d: %(message)s'\n    log = logging.getLogger(name)\n\n    # Set logging level.\n    log.setLevel(level or logging.INFO)\n\n    ch = logging.StreamHandler(sys.stdout)\n    ch.setFormatter(logging.Formatter(format))\n    log.addHandler(ch)\n\n    return log"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_session(self, user_agent, remote_address, client_version):\n\n        self.session_counter += 1\n        self.sessions[self.session_counter] = session = self.session_class()\n\n        # Set session properties\n        session.user_agent = user_agent\n        session.remote_address = remote_address\n        session.client_version = client_version\n\n        # Invoke hooks\n        invoke_hooks(self.hooks, \"session_created\", self.session_counter)\n\n        return self.session_counter", "response": "Create a new session."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destroy_session(self, session_id):\n\n        try:\n            del self.sessions[session_id]\n        except KeyError:\n            pass\n\n        # Invoke hooks\n        invoke_hooks(self.hooks, \"session_destroyed\", session_id)", "response": "Destroys an existing session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_next_revision(self, session_id, revision, delta):\n\n        session = self.sessions[session_id]\n        session.state = State.connected\n\n        if delta == revision:\n            # Increment revision. Never decrement.\n            session.revision = max(session.revision, revision)\n\n            # Wait for next revision to become ready.\n            self.next_revision_available.wait()\n\n        return self.revision", "response": "This method returns the next revision number for a given session id revision and delta."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self):\n\n        with self.lock:\n            # Increment revision and commit it.\n            self.revision += 1\n            self.server.commit(self.revision + 1)\n\n            # Unblock all waiting clients.\n            self.next_revision_available.set()\n            self.next_revision_available.clear()\n\n            # Check sessions to see which revision can be removed.\n            if self.sessions:\n                lowest_revision = min(\n                    session.revision for session in self.sessions.itervalues())\n\n                # Remove all old revision history\n                if lowest_revision == self.revision:\n                    self.server.clean(lowest_revision)\n\n        # Invoke hooks\n        invoke_hooks(self.hooks, \"updated\", self.revision)", "response": "Update this provider. Should be invoked when the server gets updated."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_item_data(self, session, item, byte_range=None):\n\n        # Parse byte range\n        if byte_range is not None:\n            begin, end = parse_byte_range(byte_range, max_byte=item.file_size)\n        else:\n            begin, end = 0, item.file_size\n\n        # Open the file\n        fp = open(item.file_name, \"rb+\")\n\n        if not begin:\n            return fp, item.file_type, item.file_size\n        elif begin and not end:\n            fp.seek(begin)\n            return fp, item.file_type, item.file_size\n        elif begin and end:\n            fp.seek(begin)\n\n            data = fp.read(end - begin)\n            result = cStringIO.StringIO(data)\n\n            return result, item.file_type, item.file_size", "response": "Returns a file pointer to the item file. Assumes item. file_name points to the file on disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readBIM(basefilename,usecols=None):\n    bim = basefilename+ '.bim'\n    bim = SP.loadtxt(bim,dtype=bytes,usecols=usecols)\n    return bim", "response": "helper method for speeding up read BED\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading FAM file and return as dict", "response": "def readFAM(basefilename,usecols=None):\n    \"\"\"\n    helper method for speeding up read FAM\n    \"\"\"\n    fam = basefilename+'.fam'\n    fam = SP.loadtxt(fam,dtype=bytes,usecols=usecols)\n    return fam"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef readBED(basefilename, useMAFencoding=False,blocksize = 1, start = 0, nSNPs = SP.inf, startpos = None, endpos = None, order  = 'F',standardizeSNPs=False,ipos = 2,bim=None,fam=None):\n    '''\n    read [basefilename].bed,[basefilename].bim,[basefilename].fam\n    --------------------------------------------------------------------------\n    Input:\n    basefilename    : string of the basename of [basename].bed, [basename].bim,\n                      and [basename].fam\n    blocksize       : load blocksize SNPs at a time (default 1)\n    start           : index of the first SNP to be loaded from the .bed-file\n                      (default 0)\n    nSNPs           : load nSNPs from the .bed file (default SP.inf, meaning all)\n    startpos        : starting position of the loaded genomic region[chr,bpdist]\n    endpos          : end-position of the loaded genomic region     [chr,bpdist]\n    order           : memory layout of the returned SNP array (default 'F')\n                      'F'   : Fortran-style column-major array (SNP-major)\n                      'C'   : C-style row-major array (individual-major)\n    standardizeSNPs : bool indeicator if the resulting SNP array is supposed to \n                      be zero-mean and unit-vatiance with mean imputed missing\n                      values (default False)\n    ipos            : the index of the position index to use (default 2)\n                        1 : genomic distance\n                        2 : base-pair distance\n    useMAFencoding  : if set to one, the minor allele is encoded with 2, the major allele with 0.\n                      otherwise, the plink coding is used (default False).\n    --------------------------------------------------------------------------\n    Output dictionary:\n    'rs'     : [S] array rs-numbers\n    'pos'    : [S*3] array of positions [chromosome, genetic dist, basepair dist]\n    'snps'   : [N*S] array of snp-data\n    'iid'    : [N*2] array of family IDs and individual IDs\n    --------------------------------------------------------------------------    \n    '''\n    \n    if bim is None: bim = readBIM(basefilename,usecols=(0,1,2,3))\n    if fam is None: fam = readFAM(basefilename,usecols=(0,1))\n\n    \n    rs = bim[:,1]\n    pos = SP.array(bim[:,(0,2,3)],dtype = 'float')\n\n\n    \n    if startpos is not None:\n        #pdb.set_trace()\n        i_c = pos[:,0]==startpos[0]\n        i_largerbp = pos[:,ipos]>=startpos[ipos]\n        start = which(i_c * i_largerbp)\n        while (start-1 >= 0 and pos[start-1,ipos] == startpos[ipos]):\n            start = start -1\n        i_c = pos[:,0]==endpos[0]\n        i_smallerbp = pos[:,ipos]>=endpos[ipos]\n        end = which(i_c * i_smallerbp)\n        while (end+1 < pos.shape[0] and pos[end+1,ipos] == endpos[ipos]):\n            end = end + 1\n        nSNPs = end - start\n        if (nSNPs<=0) or (end==0) or (start<=0):\n            ret = {\n                'pos':SP.zeros((0,3)),\n                'rs':SP.zeros((0)),\n                'iid':fam,\n                'snps':SP.zeros((fam.shape[0],0))\n                }\n            return ret\n        pass\n    N = fam.shape[0]\n    S = bim.shape[0]\n    S_res = min(S,start + nSNPs)\n    nSNPs = min(S-start,nSNPs)\n    #if startpos is not None:\n\t#print(\"start: \" + str(start))\n\t#print(\"end: \" + str(end))\n    #print(\"S_res: \" + str(S_res))\n    #print(\"nSNPs: \" + str(nSNPs))\n    if nSNPs<=0:\n        ret = {\n            'rs'     :rs[start:start],\n            'pos'    :pos[start:start,:],\n            #'snps'   :SNPs[0:N,start:start],\n            'snps'   :SP.zeros((N,0)),\n            'iid'    :fam\n            }\n        return ret\n    SNPs = SP.zeros(((SP.ceil(0.25*N)*4),nSNPs),order=order)\n    bed = basefilename + '.bed'\n    with open(bed, \"rb\") as f:\n        mode = f.read(2)\n        if mode != b'l\\x1b':\n            raise Exception('No valid binary PED file')\n        mode = f.read(1) #\\x01 = SNP major \\x00 = individual major\n        if mode != b'\\x01':\n            raise Exception('only SNP-major is implemented')\n        startbit = SP.ceil(0.25*N)*start+3\n        f.seek(int(startbit))\n        for blockStart in SP.arange(0,nSNPs,blocksize, dtype=int):\n            blockEnd = int(min(S,blockStart+blocksize))\n            Sblock = min(nSNPs-blockStart,blocksize)\n            nbyte = int(SP.ceil(0.25*N)*Sblock)\n            bytes = SP.array(bytearray(f.read(nbyte))).reshape((SP.ceil(0.25*N),Sblock),order='F')\n            \n            SNPs[3::4,blockStart:blockEnd][bytes>=64]=SP.nan\n            SNPs[3::4,blockStart:blockEnd][bytes>=128]=1\n            SNPs[3::4,blockStart:blockEnd][bytes>=192]=2\n            bytes=SP.mod(bytes,64)\n            SNPs[2::4,blockStart:blockEnd][bytes>=16]=SP.nan\n            SNPs[2::4,blockStart:blockEnd][bytes>=32]=1\n            SNPs[2::4,blockStart:blockEnd][bytes>=48]=2\n            bytes=SP.mod(bytes,16)\n            SNPs[1::4,blockStart:blockEnd][bytes>=4]=SP.nan\n            SNPs[1::4,blockStart:blockEnd][bytes>=8]=1\n            SNPs[1::4,blockStart:blockEnd][bytes>=12]=2\n            bytes=SP.mod(bytes,4)\n            SNPs[0::4,blockStart:blockEnd][bytes>=1]=SP.nan\n            SNPs[0::4,blockStart:blockEnd][bytes>=2]=1\n            SNPs[0::4,blockStart:blockEnd][bytes>=3]=2\n    \n    if 0: #the binary format as described in the documentation (seems wrong)\n        SNPs[3::4][bytes>=128]=SP.nan\n        SNPs[3::4][bytes>=192]=1\n        bytes=SP.mod(bytes,128)\n        SNPs[3::4][bytes>=64]+=1\n        bytes=SP.mod(bytes,64)\n        SNPs[2::4][bytes>=32]=SP.nan\n        SNPs[2::4][bytes>=48]=1\n        bytes=SP.mod(bytes,32)\n        SNPs[2::4][bytes>=16]+=1\n        bytes=SP.mod(bytes,16)\n        SNPs[1::4][bytes>=8]=SP.nan\n        SNPs[1::4][bytes>=12]=1\n        bytes=SP.mod(bytes,8)\n        SNPs[1::4][bytes>=4]+=1\n        bytes=SP.mod(bytes,4)\n        SNPs[0::4][bytes>=2]=SP.nan\n        SNPs[0::4][bytes>=3]=1\n        bytes=SP.mod(bytes,2)\n        SNPs[0::4][bytes>=1]+=1\n    snps = SNPs[0:N,:]\n\n    if useMAFencoding:\n        imaf = SP.sum(snps==2,axis=0)>SP.sum(snps==0,axis=0)\n        snps[:,imaf] = 2 - snps[:,imaf]\n        \n    if standardizeSNPs:\n        snps = standardize(snps)\n    ret = {\n            'rs'     :rs[start:S_res],\n            'pos'    :pos[start:S_res,:],\n            'snps'   :snps,\n            'iid'    :fam\n            }\n    return ret", "response": "Read a single genomic grammar from a BED file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an ip to a hex value that can be used with a hex bit mask", "response": "def ip2hex(ip):\n    '''\n    Converts an ip to a hex value that can be used with a hex bit mask\n    '''\n    parts = ip.split(\".\")\n    if len(parts) != 4: return None\n    ipv = 0\n    for part in parts:\n        try:\n            p = int(part)\n            if p < 0 or p > 255: return None\n            ipv = (ipv << 8) + p\n        except:\n            return None\n    return ipv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef str_to_ipmask(ipmask):\n    '''\n    Converts a string with the notation ip/mask (e.g. 192.168.1.1/24 or 192.168.1.1/255.255.255.0) to an hex mask\n    '''\n    v = ipmask.split(\"/\")\n    if len(v) > 2: raise Exception(\"bad mask format\")\n    mask_ip = ip2hex(v[0])\n    if mask_ip is None: raise Exception(\"bad mask format\")\n    mask = v[1] if len(v) == 2 else 32\n    try:\n        mask = (0xffffffff00000000 >> int(mask)) & 0xffffffff\n    except:\n        mask = ip2hex(v[1])\n    \n    if mask is None: raise Exception(\"bad mask format\")\n    return mask_ip, mask", "response": "Converts a string with the notation ip / mask to an hex mask"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ip_in_ip_mask(ip, mask_ip, mask):\n    '''\n    Checks whether an ip is contained in an ip subnet where the subnet is stated as an ip in the dotted format, and a hex mask\n    '''\n    ip = ip2hex(ip)\n    if ip is None: raise Exception(\"bad ip format\")\n    if (mask_ip & mask) == (ip & mask):\n        return True\n    return False", "response": "Checks whether an ip is contained in an ip subnet where the subnet is stated as an ip in the dotted format and a hex mask"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether an ip is contained in an ip subnet with a mask.", "response": "def ip_in_ipmask(ip, ipmask):\n    '''\n    Checks whether an ip is contained in an ip subnet where the subnet is a string with the notation ip/mask (e.g. 192.168.1.1/24 or 192.168.1.1/255.255.255.0)\n    '''\n    mask_ip, mask = str_to_ipmask(ipmask)\n    return ip_in_ip_mask(ip, mask_ip, mask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_mac(original_mac):\n    '''\n    Checks the format of a MAC address and returns it without double-colons and in capital letters, if it is correct. Otherwise it returns None.\n    * it accepts the format of the double colons and a single hex string\n    '''\n    mac = (original_mac.upper()).strip()\n    parts = mac.split(':')\n    if len(parts) == 6:\n        # let's think that it is a : separated mac\n        for p in parts:\n            if len(p) != 2:\n                return None\n        mac = ''.join(parts)\n    elif len(parts) > 1:\n        return None\n    for c in mac:\n        if c not in '0123456789ABCDEF':\n            return None\n    return mac", "response": "Checks the format of a MAC address and returns it without double colons and in capital letters and a single hex string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_ip(original_ip):\n    '''\n    Checks the format of an IP address and returns it if it is correct. Otherwise it returns None.\n    ''' \n    ip = original_ip.strip()\n    parts = ip.split('.')\n    if len(parts) != 4:\n        return None\n    for p in parts:\n        try:\n            p = int(p)\n            if (p < 0) or (p > 255):\n                return None\n        except:\n            return None\n    return ip", "response": "Checks the format of an IP address and returns it if it is correct. Otherwise it returns None."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_phy(self):\n        kwargs = {}\n        for attr in ['signal', 'noise', 'freq_mhz', 'fcs_error', 'rate', 'mcs',\n                     'len', 'caplen', 'epoch_ts', 'end_epoch_ts']:\n            kwargs[attr] = getattr(self, attr, None)\n        kwargs['has_fcs'] = True\n        return PhyInfo(**kwargs)", "response": "Convert this object to a PhyInfo object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _proximity_to_association(proximity):\n    # pylint:disable=invalid-name\n    # I'm afraid that the short names here are just a function of the\n    # mathematical nature of the code.\n\n    # Special case: zero-size matrix\n    if proximity.shape[0] == 0 or proximity.shape[1] == 0:\n        return proximity\n\n    # Take SVD of proximity matrix\n    U, sing_vals, Vh = np.linalg.svd(proximity)\n\n    # Count the number of non-zero singular values\n    nsv = np.count_nonzero(sing_vals)\n\n    # Trim U and Vh to match\n    U, Vh = U[:, :nsv], Vh[:nsv, :]\n\n    # Compute new matrix as if singular values were unity\n    return U.dot(Vh)", "response": "This function computes the SLH algorithm for increasing orthogonality of a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef active_version():\n    \n    link = '/'.join([deployment_root(),'env',env.project_name])\n    if not exists(link): return None\n    active = os.path.split(run('ls -al '+link).split(' -> ')[1])[1]\n    return active", "response": "Determine the current active version on the server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nactivating the version specified in env. project_version if it is different from the current active version.", "response": "def activate():\n    \"\"\"\n    Activates the version specified in ``env.project_version`` if it is different\n    from the current active version.\n    \n    An active version is just the version that is symlinked.\n    \"\"\"\n\n    env_path = '/'.join([deployment_root(),'env',env.project_fullname])\n\n    if not exists(env_path):\n        print env.host,\"ERROR: The version\",env.project_version,\"does not exist at\"\n        print env_path\n        sys.exit(1)\n\n    active = active_version()\n    servers = webserver_list()\n\n    if env.patch or active <> env.project_fullname:\n        for s in servers:\n            stop_webserver(s)\n        \n    if not env.patch and active <> env.project_fullname:\n        \n        if env.verbosity:\n            print env.host, \"ACTIVATING version\", env_path\n        \n        if not env.nomigration:\n            sync_db()\n        \n        #south migration\n        if 'south' in env.INSTALLED_APPS and not env.nomigration and not env.manualmigration:\n            migration()\n            \n        if env.manualmigration or env.MANUAL_MIGRATION: manual_migration()\n      \n        #activate sites\n        activate_sites = [''.join([d.name.replace('.','_'),'-',env.project_version,'.conf']) for d in domain_sites()]\n        if 'apache2' in get_packages():\n            site_paths = ['/etc/apache2','/etc/nginx']\n        else:\n            site_paths = ['/etc/nginx']\n        \n        #disable existing sites\n        for path in site_paths:\n            for site in _ls_sites('/'.join([path,'sites-enabled'])):\n                if site not in activate_sites:\n                    sudo(\"rm %s/sites-enabled/%s\"% (path,site))\n        \n        #activate new sites\n        for path in site_paths:\n            for site in activate_sites:\n                if not exists('/'.join([path,'sites-enabled',site])):\n                    sudo(\"chmod 644 %s\" % '/'.join([path,'sites-available',site]))\n                    sudo(\"ln -s %s/sites-available/%s %s/sites-enabled/%s\"% (path,site,path,site))\n                    if env.verbosity:\n                        print \" * enabled\", \"%s/sites-enabled/%s\"% (path,site)\n        \n        #delete existing symlink\n        ln_path = '/'.join([deployment_root(),'env',env.project_name])\n        run('rm -f '+ln_path)\n        #run post deploy hooks\n        post_exec_hook('post_deploy')\n        #activate\n        run('ln -s %s %s'% (env_path,ln_path))\n\n  \n        if env.verbosity:\n            print env.host,env.project_fullname, \"ACTIVATED\"\n    else:\n        if env.verbosity and not env.patch:\n            print env.project_fullname,\"is the active version\"\n\n    if env.patch or active <> env.project_fullname:\n        for s in servers:\n            start_webserver(s)\n        print\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync_db():\n    with cd('/'.join([deployment_root(),'env',env.project_fullname,'project',env.project_package_name,'sitesettings'])):\n        venv = '/'.join([deployment_root(),'env',env.project_fullname,'bin','activate'])\n        sites = _get_django_sites()\n        site_ids = sites.keys()\n        site_ids.sort()\n        for site in site_ids:\n            for settings_file in _sitesettings_files():\n                site_settings = '.'.join([env.project_package_name,'sitesettings',settings_file.replace('.py','')])\n                if env.verbosity:\n                    print \" * django-admin.py syncdb --noinput --settings=%s\"% site_settings\n                output = sudo(' '.join(['source',venv,'&&',\"django-admin.py syncdb --noinput --settings=%s\"% site_settings]),\n                              user='site_%s'% site)\n                if env.verbosity:\n                    print output", "response": "Runs the django syncdb command\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef manual_migration():\n    if env.INTERACTIVITY:\n        print \"A manual migration can be done two different ways:\"\n        print \"Option 1: Enter y to exit the current deployment. When migration is completed run deploy again.\"\n        print \"Option 2: run the migration in a separate shell\"\n        exit = confirm(\"Enter y to exit or accept default to complete deployment and activate the new version\",default=False)\n    else:\n        exit = True\n    if exit:\n        print \"Login to your node and run 'workon %s'\"% env.project_fullname \n        sys.exit(0)", "response": "A manual migration for a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mkvirtualenv():\n    root = '/'.join([deployment_root(),'env'])\n    path = '/'.join([root,env.project_fullname])\n    dirs_created = []\n    if env.verbosity:\n        print env.host,'CREATING VIRTUALENV', path\n    if not exists(root): dirs_created += mkdirs(root)\n    with cd(root):\n        run(' '.join([\"virtualenv\",env.project_fullname]))\n    with cd(path):\n        dirs_created += mkdirs('egg_cache')\n        sudo('chown -R %s:www-data egg_cache'% env.user)\n        sudo('chmod -R g+w egg_cache')\n        run(''.join([\"echo 'cd \",path,'/','project','/',env.project_package_name,'/sitesettings',\"' > bin/postactivate\"]))\n        sudo('chmod ugo+rwx bin/postactivate')\n\n    #Create a state\n    out = State(' '.join([env.host,'virtualenv',path,'created']))\n    out.object = dirs_created + ['bin','lib','include']\n    out.failed = False\n    return out", "response": "Create the virtualenv project environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the current or current environment and all content in it", "response": "def rmvirtualenv():\n    \"\"\"\n    Remove the current or ``env.project_version`` environment and all content in it\n    \"\"\"\n    path = '/'.join([deployment_root(),'env',env.project_fullname])\n    link = '/'.join([deployment_root(),'env',env.project_name])\n    if version_state('mkvirtualenv'):\n        sudo(' '.join(['rm -rf',path]))\n        sudo(' '.join(['rm -f',link]))\n        sudo('rm -f /var/local/woven/%s*'% env.project_fullname)\n        set_version_state('mkvirtualenv',delete=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling on current installed virtualenv version from a pip bundle [dist/project name-version].zip or pip ``req.txt``|``requirements.txt`` or a env.pip_requirements list. By default it will look for a zip bundle in the dist directory first then a requirements file. The limitations of installing requirements are that you cannot point directly to packages in your local filesystem. In this case you would bundle instead.", "response": "def pip_install_requirements():\n    \"\"\"\n    Install on current installed virtualenv version from a pip bundle [dist/project name-version].zip or pip ``req.txt``|``requirements.txt``\n    or a env.pip_requirements list.\n    \n    By default it will look for a zip bundle in the dist directory first then a requirements file.\n\n    \n    The limitations of installing requirements are that you cannot point directly to packages\n    in your local filesystem. In this case you would bundle instead.\n    \"\"\"\n    if not version_state('mkvirtualenv'):\n        print env.host,'Error: Cannot run pip_install_requirements. A virtualenv is not created for this version. Run mkvirtualenv first'\n        return\n    if env.verbosity:\n        print env.host, 'PIP INSTALLING REQUIREMENTS:'\n    \n    #Remove any pre-existing pip-log from any previous failed installation\n    pip_log_dir = '/'.join(['/home',env.user,'.pip'])\n    if exists(pip_log_dir): run('rm -f %s/*.txt'% pip_log_dir)\n    \n    #determine what req files or bundle files we need to deploy\n    if not env.PIP_REQUIREMENTS:\n        req_files = {}.fromkeys(glob('req*'))\n    else:\n        req_files = {}.fromkeys(env.PIP_REQUIREMENTS)\n    \n    for key in req_files:\n        bundle = ''.join([key.split('.')[0],'.zip'])\n        if os.path.exists(os.path.join('dist',bundle)):\n            req_files[key] = bundle\n        \n    #determine the django version\n    file_patterns =''\n    django_version = get_version()\n    svn_version = django_version.find('SVN')\n    if svn_version > -1:\n        django_version = django_version[svn_version+4:]\n        django_req = ''.join(['-e svn+http://code.djangoproject.com/svn/django/trunk@',django_version,'#egg=Django'])\n    else:\n        other_builds = ['alpha','beta','rc']\n        for b in other_builds:\n            if b in django_version:\n                print \"ERROR: Unsupported Django version\", django_version\n                print \"Define a DJANGO_REQUIREMENT pointing to the tar.gz for\",django_version\n                print \"and re-deploy, or use the official or SVN release of Django.\"\n                sys.exit(1)\n        django_req = ''.join(['Django==',django_version])\n\n    #if no requirements file exists create one\n    if not req_files:\n        f = open(\"requirements.txt\",\"w+\")\n        text = render_to_string('woven/requirements.txt', {'django':django_req})\n        f.write(text)\n        f.close()\n        if env.verbosity:\n            print \"Created local requirements.txt\"\n        req_files[\"requirements.txt\"]=''\n        \n    req_files_list = req_files.keys()\n    req_files_list.sort()\n    \n    #patterns for bundles\n    if req_files: file_patterns = '|'.join([file_patterns,'req*.zip'])\n\n    #create a pip cache & src directory\n    cache =  '/'.join([deployment_root(),'.pip','cache'])\n    src = '/'.join([deployment_root(),'.pip','src'])\n    deployed = mkdirs(cache)\n    deployed += mkdirs(src)\n    #deploy bundles and any local copy of django\n    local_dir = os.path.join(os.getcwd(),'dist')\n    remote_dir = '/'.join([deployment_root(),'env',env.project_fullname,'dist'])\n    if os.path.exists(local_dir):  \n        if file_patterns: deployed += deploy_files(local_dir, remote_dir, pattern=file_patterns)\n    \n    #deploy any requirement files\n    deployed +=  deploy_files(os.getcwd(), remote_dir, pattern = 'req*') \n    \n    #install in the env\n    out = State(' '.join([env.host,'pip install requirements']))\n    python_path = '/'.join([deployment_root(),'env',env.project_fullname,'bin','python'])\n    with settings(warn_only=True):\n        with cd(remote_dir):\n            for req in req_files_list:\n                bundle = req_files[req]\n                if bundle: req=bundle\n                if env.verbosity:\n                    print ' * installing',req\n                if '.zip' in req.lower():\n                    install = run('pip install %s -q --environment=%s --log=/home/%s/.pip/%s_pip_log.txt'%\n                                  (req, python_path, env.user, req.replace('.','_')))\n                  \n                else:\n                    install = run('pip install -q --environment=%s --src=%s --download-cache=%s --requirement=%s --log=/home/%s/.pip/%s_pip_log.txt'%\n                                  (python_path,src,cache,req, env.user,req.replace('.','_')))\n                if install.failed:\n                    out.failed =True\n                    out.stderr += ' '.join([env.host, \"ERROR INSTALLING\",req,'\\n'])\n    \n    out.object = deployed\n              \n    if out.failed:\n        print out.stderr\n        print \"Review the pip install logs at %s/.pip and re-deploy\"% deployment_root()\n        sys.exit(1)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshifts returns the leftmost element of argv and operate over iterable.", "response": "def shift (*args):\n    \"\"\"`shift()` returns the leftmost element of `argv`.\n    `shitf(integer)` return the `integer` leftmost elements of `argv` as a list.\n    `shift(iterable)` and `shift(iterable, integer)` operate over `iterable`.\"\"\"\n    if len(args) > 2:\n        raise ValueError(\"shift() takes 0, 1 or 2 arguments.\")\n\n    n = 1\n    l = ayrton.runner.globals['argv']\n\n    logger.debug2(\"%s(%d)\", args, len(args))\n    if len(args) == 1:\n        value = args[0]\n        logger.debug2(type(value))\n        if isinstance(value, int):\n            n = value\n        elif isinstance(value, Iterable):\n            l = value\n        else:\n            raise ValueError(\"First parameter must be Iterable or int().\")\n    elif len(args) == 2:\n        l, n = args\n\n    logger.debug2(\"%s(%d)\", args, len(args))\n    logger.debug(\"%s[%d]\", l, n)\n\n    if n == 1:\n        ans= l.pop(0)\n    elif n > 1:\n        ans= [ l.pop(0) for i in range(n) ]\n    else:\n        raise ValueError(\"Integer parameter must be >= 0.\")\n\n    return ans"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a renderer object for the current set of resources.", "response": "def _make_renderer(self, at_paths, at_encoding, **kwargs):\n        \"\"\"\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n        \"\"\"\n        for eopt in (\"file_encoding\", \"string_encoding\"):\n            default = self._roptions.get(eopt, at_encoding.lower())\n            self._roptions[eopt] = kwargs.get(eopt, default)\n\n        pkey = \"search_dirs\"\n        paths = kwargs.get(pkey, []) + self._roptions.get(pkey, [])\n        if at_paths is not None:\n            paths = at_paths + paths\n        self._roptions[pkey] = paths\n\n        return pystache.renderer.Renderer(**self._roptions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef renders_impl(self, template_content, context, at_paths=None,\n                     at_encoding=anytemplate.compat.ENCODING,\n                     **kwargs):\n        \"\"\"\n        Render given template string and return the result.\n\n        :param template_content: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        renderer = self._make_renderer(at_paths, at_encoding, **kwargs)\n        ctxs = [] if context is None else [context]\n\n        return renderer.render(template_content, *ctxs)", "response": "Render given template string and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender given template file and return the result.", "response": "def render_impl(self, template, context, at_paths=None,\n                    at_encoding=anytemplate.compat.ENCODING, **kwargs):\n        \"\"\"\n        Render given template file and return the result.\n\n        :param template: Template file path\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        renderer = self._make_renderer(at_paths, at_encoding, **kwargs)\n        ctxs = [] if context is None else [context]\n\n        if os.path.sep in template:  # `template` is in abs/rel-path.\n            return renderer.render_path(template, *ctxs)\n        else:\n            if template.endswith(renderer.file_extension):\n                template = os.path.splitext(template)[0]\n\n            return renderer.render_name(template, *ctxs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_arguments():\n\n    parser = argparse.ArgumentParser()\n\n    # Add options\n    parser.add_argument(\n        \"-n\", \"--number\", action=\"store\", default=1000000, type=int,\n        help=\"number of items\")\n    parser.add_argument(\n        \"-p\", \"--pause\", action=\"store_true\", help=\"pause after execution\")\n\n    # Parse command line\n    return parser.parse_args(), parser", "response": "Parse commandline arguments.\n    Parse command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n\n    # Parse arguments and configure application instance.\n    arguments, parser = parse_arguments()\n\n    # Start iterating\n    store = RevisionStore()\n    sys.stdout.write(\"Iterating over %d items.\\n\" % arguments.number)\n\n    for i in xrange(arguments.number):\n        key = chr(65 + (i % 26))\n        value = [key * (i % 26), key * (i % 13), key * (i % 5)]\n\n        store.add(key, value)\n\n    # Wait for an enter\n    if arguments.pause:\n        sys.stdout.write(\"Done!\")\n        sys.stdin.readline()", "response": "Run a benchmark for N items."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _compute_transitions(self, corpus, order=1):\n        self.transitions = defaultdict(lambda: defaultdict(int))\n\n        for corpus_entry in corpus:\n            tokens = self.tokenize(corpus_entry)\n\n            last_tokens = utils.prefilled_buffer(\n                self._start_symbol, length=self.order)\n            # count the occurrences of \"present | past\"\n            for token_value in chain(tokens, self._end_symbol):\n                for suffix in utils.get_suffixes(last_tokens):\n                    self.transitions[suffix][token_value] += 1\n\n                last_tokens.append(token_value)\n\n        self._compute_relative_probs(self.transitions)", "response": "Computes the transition probabilities of a given corpus."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compute_relative_probs(self, prob_dict):\n        for transition_counts in prob_dict.values():\n            summed_occurences = sum(transition_counts.values())\n            if summed_occurences > 0:\n                for token in transition_counts.keys():\n                    transition_counts[token] = transition_counts[\n                        token] * 1.0 / summed_occurences", "response": "computes the relative probabilities for every state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _text_generator(self, next_token=None, emit=lambda x, _, __: x, max_length=None):\n        assert next_token is not None\n        last_tokens = utils.prefilled_buffer(\n            self._start_symbol, length=self.order)\n        if hasattr(self, \"order_emissions\"):\n            order_emissions = self.order_emissions\n        else:\n            order_emissions = self.order\n        last_emissions = utils.prefilled_buffer(\n            self._start_symbol, length=order_emissions)\n        generated_tokens = []\n        while last_tokens[-1] != self._end_symbol:\n            new_token = next_token(last_tokens)\n            emission = emit(new_token, last_tokens, last_emissions)\n            last_emissions.append(emission)\n            generated_tokens.append(emission)\n            last_tokens.append(new_token)\n            # cut-off for max. emissions\n            # + 1 for the start state\n            if max_length is not None and max_length + 1 <= len(generated_tokens):\n                break\n        text = generated_tokens[:-1]\n        return text", "response": "Generates the text for the given emissions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a text from a given corpus.", "response": "def generate_text(self, max_length=None):\n        \"\"\" Generates sentences from a given corpus\n        max_length: maximum number of emissions\n        Returns:\n            Properly formatted string of generated sentences\n        \"\"\"\n        return self._text_generator(next_token=self._generate_next_token, max_length=max_length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generate_next_token_helper(self, past_states, transitions):\n        key = tuple(past_states)\n        assert key in transitions, \"%s\" % str(key)\n        return utils.weighted_choice(transitions[key].items())", "response": "Generate next token based previous states"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndispatch an event. event: name of the event (str) ev_msg: non-optional arguments dictionary. Side effects: If an EventObject is not already registered with the EventManager, a new EventObject will be created and registered.", "response": "def dispatch(self, event, ev_msg):\n        \"\"\"Dispatch an event.\n               event: name of the event (str)\n               ev_msg: non-optional arguments dictionary.\n           Side effects:\n               If an EventObject is not already registered with the EventManager,\n               a new EventObject will be created and registered.\"\"\"\n        logger.debug('dispatching: ' + event + ': ' + repr(ev_msg))\n        eo = self.events.get(event, None)\n        if eo:\n            eo.dispatch(ev_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters interest in an event.", "response": "def register(self, event, callable, priority=10):\n        \"\"\"Register interest in an event.\n               event: name of the event (str)\n               callable: the callable to be used as a callback function\n           Returns an EventReceiver object.  To unregister interest, simply\n           delete the object.\"\"\"\n        logger.debug('registered: ' + event + ': ' + repr(callable) + ' [' + repr(self) + ']')\n        return EventReceiver(event, callable, manager=self, priority=priority)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if a Status object has entities.", "response": "def has_entities(status):\n    \"\"\"\n    Returns true if a Status object has entities.\n\n    Args:\n        status: either a tweepy.Status object or a dict returned from Twitter API\n    \"\"\"\n    try:\n        if sum(len(v) for v in status.entities.values()) > 0:\n            return True\n\n    except AttributeError:\n        if sum(len(v) for v in status['entities'].values()) > 0:\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_entities(status, entitylist):\n    '''Remove entities for a list of items.'''\n    try:\n        entities = status.entities\n        text = status.text\n    except AttributeError:\n        entities = status.get('entities', dict())\n        text = status['text']\n\n    indices = [ent['indices'] for etype, entval in list(entities.items()) for ent in entval if etype in entitylist]\n    indices.sort(key=lambda x: x[0], reverse=True)\n\n    for start, end in indices:\n        text = text[:start] + text[end:]\n\n    return text", "response": "Remove entities for a list of items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace shorturls in a status with expanded urls.", "response": "def replace_urls(status):\n    '''\n    Replace shorturls in a status with expanded urls.\n\n    Args:\n        status (tweepy.status): A tweepy status object\n\n    Returns:\n        str\n    '''\n    text = status.text\n\n    if not has_url(status):\n        return text\n\n    urls = [(e['indices'], e['expanded_url']) for e in status.entities['urls']]\n    urls.sort(key=lambda x: x[0][0], reverse=True)\n\n    for (start, end), url in urls:\n        text = text[:start] + url + text[end:]\n\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshorten a string to 140 characters without breaking words.", "response": "def shorten(string, length=140, ellipsis=None):\n    '''\n    Shorten a string to 140 characters without breaking words.\n    Optionally add an ellipsis character: '\u2026' if ellipsis=True, or a given string\n    e.g. ellipsis=' (cut)'\n    '''\n    string = string.strip()\n\n    if len(string) > length:\n        if ellipsis is True:\n            ellipsis = '\u2026'\n        else:\n            ellipsis = ellipsis or ''\n\n        L = length - len(ellipsis)\n\n        return ' '.join(string[:L].split(' ')[:-1]).strip(',;:.') + ellipsis\n\n    else:\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef queryize(terms, exclude_screen_name=None):\n    '''\n    Create query from list of terms, using OR\n    but intelligently excluding terms beginning with '-' (Twitter's NOT operator).\n    Optionally add -from:exclude_screen_name.\n\n    >>> helpers.queryize(['apple', 'orange', '-peach'])\n    u'apple OR orange -peach'\n\n    Args:\n        terms (list): Search terms.\n        exclude_screen_name (str): A single screen name to exclude from the search.\n\n    Returns:\n        A string ready to be passed to tweepy.API.search\n    '''\n    ors = ' OR '.join('\"{}\"'.format(x) for x in terms if not x.startswith('-'))\n    nots = ' '.join('-\"{}\"'.format(x[1:]) for x in terms if x.startswith('-'))\n    sn = \"-from:{}\".format(exclude_screen_name) if exclude_screen_name else ''\n    return ' '.join((ors, nots, sn))", "response": "Create query from list of terms using OR\n    but intelligently excluding terms beginning with -."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshortens a string so that it fits under max_len splitting it at split.", "response": "def chomp(text, max_len=280, split=None):\n    '''\n    Shorten a string so that it fits under max_len, splitting it at 'split'.\n    Not guaranteed to return a string under max_len, as it may not be possible\n\n    Args:\n        text (str): String to shorten\n        max_len (int): maximum length. default 140\n        split (str): strings to split on (default is common punctuation: \"-;,.\")\n    '''\n    split = split or '\u2014;,.'\n    while length(text) > max_len:\n        try:\n            text = re.split(r'[' + split + ']', text[::-1], 1)[1][::-1]\n        except IndexError:\n            return text\n\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef length(text, maxval=None, encoding=None):\n    '''\n    Count the length of a str the way Twitter does,\n    double-counting \"wide\" characters (e.g. ideographs, emoji)\n\n    Args:\n        text (str): Text to count. Must be a unicode string in Python 2\n        maxval (int): The maximum encoding that will be counted as 1 character.\n            Defaults to 4351 (\u10ff GEORGIAN LETTER LABIAL SIGN, U+10FF)\n\n    Returns:\n        int\n    '''\n    maxval = maxval or 4351\n    try:\n        assert not isinstance(text, six.binary_type)\n    except AssertionError:\n        raise TypeError('helpers.length requires a unicode argument')\n    return sum(2 if ord(x) > maxval else 1 for x in unicodedata.normalize('NFC', text))", "response": "Returns the length of a unicode string in the order that it is in the alphabet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_message_to_topic(self, topic, message, correlation_id=None):\n        exchange = self.get_exchange_name(topic)\n        self._channel.exchange_declare(\n            exchange=exchange,\n            exchange_type='topic',\n            durable=True,\n        )\n        self._channel.basic_publish(\n            exchange,\n            topic,\n            self.serialize_message(message),\n            properties=self.get_properties(correlation_id=correlation_id),\n        )", "response": "Send a message to RabbitMQ based on the routing key of the topic."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a collection of all Column objects for given SQLAlchemy object.", "response": "def get_columns(mixed):\n    \"\"\"\n    Return a collection of all Column objects for given SQLAlchemy\n    object.\n    The type of the collection depends on the type of the object to return the\n    columns from.\n    ::\n        get_columns(User)\n        get_columns(User())\n        get_columns(User.__table__)\n        get_columns(User.__mapper__)\n        get_columns(sa.orm.aliased(User))\n        get_columns(sa.orm.alised(User.__table__))\n\n    :param mixed:\n        SA Table object, SA Mapper, SA declarative class, SA declarative class\n        instance or an alias of any of these objects\n    \"\"\"\n    if isinstance(mixed, sa.Table):\n        return mixed.c\n    if isinstance(mixed, sa.orm.util.AliasedClass):\n        return sa.inspect(mixed).mapper.columns\n    if isinstance(mixed, sa.sql.selectable.Alias):\n        return mixed.c\n    if isinstance(mixed, sa.orm.Mapper):\n        return mixed.columns\n    if not isclass(mixed):\n        mixed = mixed.__class__\n    return sa.inspect(mixed).columns"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef train_associations_SingleSNP(X, Y, U, S, C, numintervals, ldeltamin, ldeltamax):\n    return _core.train_associations_SingleSNP(X, Y, U, S, C, numintervals, ldeltamin, ldeltamax)", "response": "Train associations on a single SNP."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optdelta(UY, UX, S, numintervals, ldeltamin, ldeltamax, REML=False):\n    return _core.optdelta(UY, UX, S, numintervals, ldeltamin, ldeltamax, REML)", "response": "Optdelta returns the optimal delta of the given UY and UX."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef optdeltaAllY(UY, UX, S, ldeltagrid):\n    return _core.optdeltaAllY(UY, UX, S, ldeltagrid)", "response": "OptdeltaAllY - Returns the optimal Y matrix for all Ys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to compute the N - L logarithm of a single node.", "response": "def nLLeval(ldelta, UY, UX, S, REML=False):\n    \"\"\"\n    nLLeval(double ldelta, MatrixXd const & UY, MatrixXd const & UX, MatrixXd const & S, bool REML=False) -> double\n\n    Parameters\n    ----------\n    ldelta: double\n    UY: MatrixXd const &\n    UX: MatrixXd const &\n    S: MatrixXd const &\n    REML: bool\n\n    nLLeval(double ldelta, MatrixXd const & UY, MatrixXd const & UX, MatrixXd const & S) -> double\n\n    Parameters\n    ----------\n    ldelta: double\n    UY: MatrixXd const &\n    UX: MatrixXd const &\n    S: MatrixXd const &\n\n    \"\"\"\n    return _core.nLLeval(ldelta, UY, UX, S, REML)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CKroneckerLMM_optdelta(ldelta_opt, A, X, Y, S_C1, S_R1, S_C2, S_R2, ldeltamin, ldeltamax, numintervals):\n    return _core.CKroneckerLMM_optdelta(ldelta_opt, A, X, Y, S_C1, S_R1, S_C2, S_R2, ldeltamin, ldeltamax, numintervals)", "response": "CKroneckerLMM_optdelta(limix::mfloat_t & ldelta_opt, MatrixXdVec A, MatrixXdVec X, MatrixXd const & Y, VectorXd const & S_C1, VectorXd const & S_R1, VectorXd const & S_C2, VectorXd const & S_R2, limix::mfloat_t ldeltamin, limix::mfloat_t ldeltamax, limix::muint_t numintervals) -> limix::mfloat_t\n\n    Parameters\n    ----------\n    ldelta_opt: limix::mfloat_t &\n    A: limix::MatrixXdVec const &\n    X: limix::MatrixXdVec const &\n    Y: MatrixXd const &\n    S_C1: VectorXd const &\n    S_R1: VectorXd const &\n    S_C2: VectorXd const &\n    S_R2: VectorXd const &\n    ldeltamin: limix::mfloat_t\n    ldeltamax: limix::mfloat_t\n    numintervals: limix::muint_t"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef best_split_full_model(X, UTy, C, S, U, noderange, delta):\n    return _core.best_split_full_model(X, UTy, C, S, U, noderange, delta)", "response": "This function calls the best split_full_model function of the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npredicting the tree_nodes with the given mean and splitting_value.", "response": "def predict_lmm_forest(tree_nodes, left_children, right_children, best_predictor, mean, splitting_value, X, depth):\n    \"\"\"\n    predict_lmm_forest(VectorXi const & tree_nodes, VectorXi const & left_children, VectorXi const & right_children, VectorXi const & best_predictor, MatrixXd const & mean, MatrixXd const & splitting_value, MatrixXd const & X, limix::mfloat_t depth)\n\n    Parameters\n    ----------\n    tree_nodes: VectorXi const &\n    left_children: VectorXi const &\n    right_children: VectorXi const &\n    best_predictor: VectorXi const &\n    mean: MatrixXd const &\n    splitting_value: MatrixXd const &\n    X: MatrixXd const &\n    depth: limix::mfloat_t\n\n    \"\"\"\n    return _core.predict_lmm_forest(tree_nodes, left_children, right_children, best_predictor, mean, splitting_value, X, depth)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_covariance_Kgrad_x(covar, relchange=1E-5, threshold=1E-2, check_diag=True):\n        return _core.ACovarianceFunction_check_covariance_Kgrad_x(covar, relchange, threshold, check_diag)", "response": "Check the covariance of a specific class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setVarcompApprox0(self, ldeltamin0=-5, ldeltamax0=5, num_intervals0=100):\n        return _core.ALMM_setVarcompApprox0(self, ldeltamin0, ldeltamax0, num_intervals0)", "response": "set the value of varcomp0 in the current ALMM to 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setVarcompExact(self, ldeltamin=-5, ldeltamax=5, num_intervals=100):\n        return _core.ALMM_setVarcompExact(self, ldeltamin, ldeltamax, num_intervals)", "response": "set the value of the variable comprehension in the current time - domain"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setKUS(self, K, U, S):\n        return _core.CLMM_setKUS(self, K, U, S)", "response": "set the K - U and S matrix for this class"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setStr(self, name, n, value):\n        return _core.CHeaderMap_setStr(self, name, n, value)", "response": "Set the value of a key to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setSNPFilter(self, chrom, start, stop):\n        return _core.AGenotypeContainer_setSNPFilter(self, chrom, start, stop)", "response": "Set the SNP filter for the given chrom start and stop."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buildSubscriptionList(self):\n        self._clearLists()\n        unreadById = {}\n\n        if not self.userId:\n            self.getUserInfo()\n\n        unreadJson = self.httpGet(ReaderUrl.UNREAD_COUNT_URL, { 'output': 'json', })\n        unreadCounts = json.loads(unreadJson, strict=False)['unreadcounts']\n        for unread in unreadCounts:\n            unreadById[unread['id']] = unread['count']\n\n        feedsJson = self.httpGet(ReaderUrl.SUBSCRIPTION_LIST_URL, { 'output': 'json', })\n        subscriptions = json.loads(feedsJson, strict=False)['subscriptions']\n\n        for sub in subscriptions:\n            categories = []\n            if 'categories' in sub:\n                for hCategory in sub['categories']:\n                    cId = hCategory['id']\n                    if not cId in self.categoriesById:\n                        category = Category(self, hCategory['label'], cId)\n                        self._addCategory(category)\n                    categories.append(self.categoriesById[cId])\n\n            try:\n                feed = self.getFeed(sub['id'])\n                if not feed:\n                    raise\n                if not feed.title:\n                    feed.title = sub['title']\n                for category in categories:\n                    feed.addCategory(category)\n                feed.unread = unreadById.get(sub['id'], 0)\n            except:\n                feed = Feed(self,\n                            sub['title'],\n                            sub['id'],\n                            sub.get('htmlUrl', None),\n                            unreadById.get(sub['id'], 0),\n                            categories)\n            if not categories:\n                self.orphanFeeds.append(feed)\n            self._addFeed(feed)\n\n        specialUnreads = [id for id in unreadById\n                            if id.find('user/%s/state/com.google/' % self.userId) != -1]\n        for type in self.specialFeeds:\n            feed = self.specialFeeds[type]\n            feed.unread = 0\n            for id in specialUnreads:\n                if id.endswith('/%s' % type):\n                    feed.unread = unreadById.get(id, 0)\n                    break\n\n        return True", "response": "Builds a list of feeds and unread for a user. Returns true if succesful."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the feed content", "response": "def _getFeedContent(self, url, excludeRead=False, continuation=None, loadLimit=20, since=None, until=None):\n        \"\"\"\n        A list of items (from a feed, a category or from URLs made with SPECIAL_ITEMS_URL)\n\n        Returns a dict with\n         :param id: (str, feed's id)\n         :param continuation: (str, to be used to fetch more items)\n         :param items:  array of dits with :\n            - update (update timestamp)\n            - author (str, username)\n            - title (str, page title)\n            - id (str)\n            - content (dict with content and direction)\n            - categories (list of categories including states or ones provided by the feed owner)\n        \"\"\"\n        parameters = {}\n        if excludeRead:\n            parameters['xt'] = 'user/-/state/com.google/read'\n        if continuation:\n            parameters['c'] = continuation\n        parameters['n'] = loadLimit\n        if since:\n            parameters['ot'] = since\n        if until:\n            parameters['nt'] = until\n        contentJson = self.httpGet(url, parameters)\n        return json.loads(contentJson, strict=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getFeedContent(self, feed, excludeRead=False, continuation=None, loadLimit=20, since=None, until=None):\n        return self._getFeedContent(feed.fetchUrl, excludeRead, continuation, loadLimit, since, until)", "response": "Get a list of items for a particular feed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getCategoryContent(self, category, excludeRead=False, continuation=None, loadLimit=20, since=None, until=None):\n        return self._getFeedContent(category.fetchUrl, excludeRead, continuation, loadLimit, since, until)", "response": "Get the content of a particular category."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping around actual HTTP POST string for modify tags", "response": "def _modifyItemTag(self, item_id, action, tag):\n        \"\"\" wrapper around actual HTTP POST string for modify tags \"\"\"\n        return self.httpPost(ReaderUrl.EDIT_TAG_URL,\n                             {'i': item_id, action: tag, 'ac': 'edit-tags'})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a tag to an individal item.", "response": "def addItemTag(self, item, tag):\n        \"\"\"\n        Add a tag to an individal item.\n\n        tag string must be in form \"user/-/label/[tag]\"\n        \"\"\"\n        if self.inItemTagTransaction:\n            # XXX: what if item's parent is not a feed?\n            if not tag in self.addTagBacklog:\n                self.addTagBacklog[tag] = []                \n            self.addTagBacklog[tag].append({'i': item.id, 's': item.parent.id})\n            return \"OK\"\n        else:\n            return self._modifyItemTag(item.id, 'a', tag)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subscribe(self, feedUrl):\n        response = self.httpPost(\n            ReaderUrl.SUBSCRIPTION_EDIT_URL,\n            {'ac':'subscribe', 's': feedUrl})\n        # FIXME - need better return API\n        if response and 'OK' in response:\n            return True\n        else:\n            return False", "response": "Adds a feed to the top - level subscription list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getUserInfo(self):\n        userJson = self.httpGet(ReaderUrl.USER_INFO_URL)\n        result = json.loads(userJson, strict=False)\n        self.userId = result['userId']\n        return result", "response": "Returns a dictionary of user info that google stores."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the human readable date of when the user signed up for google reader.", "response": "def getUserSignupDate(self):\n        \"\"\"\n        Returns the human readable date of when the user signed up for google reader.\n        \"\"\"\n        userinfo = self.getUserInfo()\n        timestamp = int(float(userinfo[\"signupTimeSec\"]))\n        return time.strftime(\"%m/%d/%Y %H:%M\", time.gmtime(timestamp))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclearing all lists before sync", "response": "def _clearLists(self):\n        \"\"\"\n        Clear all list before sync : feeds and categories\n        \"\"\"\n        self.feedsById      = {}\n        self.feeds          = []\n        self.categoriesById = {}\n        self.categories     = []\n        self.orphanFeeds    = []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef timeout(duration):\n    if not isinstance(duration, int):\n        raise TypeError(\"timeout duration should be a positive integer\")\n    if duration <= 0:\n        raise ValueError(\"timeoutDuration should be a positive integer\")\n\n    def decorator(func):\n        def wrapped_func(*args, **kwargs):\n            try:\n                def alarm_handler(signum, stack):\n                    raise TimeoutError()\n                signal.signal(signal.SIGALRM, alarm_handler)\n                signal.alarm(duration)\n                reply = func(*args, **kwargs)\n            except TimeoutError as e:\n                raise e\n            return reply\n        return wrapped_func\n    return decorator", "response": "A decorator that forces a time limit on the execution of an external function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_task(self, name):\n\n        try:\n            return self.tasks[name]\n        except KeyError:\n            pass\n\n        similarities = []\n\n        for task_name, task in self.tasks.items():\n            ratio = SequenceMatcher(None, name, task_name).ratio()\n            if ratio >= 0.75:\n                similarities.append(task)\n\n        if len(similarities) == 1:\n            return similarities[0]\n        else:\n            raise NoSuchTaskError(similarities)", "response": "Find a task by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the command line entry point for the fabric.", "response": "def handle(self, *args, **options):\n        \"\"\"\n        Initializes the fabric environment\n        \"\"\"\n        self.style = no_style()\n        #manage.py execution specific variables\n        #verbosity 0 = No output at all, 1 = woven output only, 2 = Fabric outputlevel = everything except debug\n        state.env.verbosity = int(options.get('verbosity', 1))\n\n        #show_traceback = options.get('traceback', False)\n        state.env.INTERACTIVE = options.get('interactive')\n        \n        #Fabric options\n        #Django passes in a dictionary instead of the optparse options objects\n        for option in options:\n            state.env[option] = options[option]\n       \n        #args will be tuple. We convert it to a comma separated string for fabric\n        all_role_hosts = []\n\n        if args:\n            #subclasses can implement parse_host_args to strip out subcommands\n            comma_hosts = self.parse_host_args(*args)\n            normalized_host_list = comma_hosts.split(',')\n            for r in normalized_host_list:\n                #define a list of hosts for given roles\n                if hasattr(settings,'ROLEDEFS') and settings.ROLEDEFS.get(r): \n                    all_role_hosts+=settings.ROLEDEFS[r]\n                    state.env['roles'] = state.env['roles'] + [r]\n                #simple single host \n                else: \n                    all_role_hosts.append(r)\n            \n        #if no args are given we'll use either a 'default' roledef/role_node\n        #or as last resort we'll use a simple HOSTS list\n        elif hasattr(settings, 'ROLEDEFS') and settings.ROLEDEFS.get('default'):\n            all_role_hosts = settings.ROLEDEFS['default']\n            state.env['roles'] = ['default']\n        elif hasattr(settings,'HOSTS') and settings.HOSTS:\n            all_role_hosts = settings.HOSTS\n        else:\n            print \"Error: You must include a host or role in the command line or set HOSTS or ROLEDEFS in your settings file\"\n            sys.exit(1)\n        state.env['hosts'] = all_role_hosts\n                    \n        #This next section is taken pretty much verbatim from fabric.main\n        #so we follow an almost identical but more limited execution strategy\n        \n        #We now need to load django project woven settings into env\n        #This is the equivalent to module level execution of the fabfile.py.\n        #If we were using a fabfile.py then we would include set_env()\n\n        if int(state.env.verbosity) < 2:\n            with hide('warnings', 'running', 'stdout', 'stderr'):\n                set_env(settings,state.env.setup)\n        else: set_env(settings,state.env.setup)\n        \n        #Back to the standard execution strategy\n        # Set host list (also copy to env)\n        state.env.all_hosts = hosts = state.env.hosts\n        # If hosts found, execute the function on each host in turn\n        for host in hosts:\n            # Preserve user\n            prev_user = state.env.user\n            # Split host string and apply to env dict\n            #TODO - This section is replaced by network.interpret_host_string in Fabric 1.0\n            username, hostname, port = normalize(host)\n            state.env.host_string = host\n            state.env.host = hostname\n            state.env.user = username\n            state.env.port = port\n\n            # Actually run command\n            if int(state.env.verbosity) < 2:\n                with hide('warnings', 'running', 'stdout', 'stderr'):\n                    self.handle_host(*args, **options)\n            else:\n                self.handle_host(*args, **options)\n            # Put old user back\n            state.env.user = prev_user"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a command on the node and return the stdout and stderr", "response": "def execute_command(self, command, **kwargs):\n        \"\"\"Execute a command on the node\n\n        Args:\n            command (str)\n\n        Kwargs:\n            username (str)\n        \"\"\"\n\n        self.info_log(\"executing command: %s\" % command)\n\n        try:\n            ssh = paramiko.SSHClient()\n            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\n            username = kwargs.get(\n                'username',\n                self.browser_config.get('username')\n            )\n            password = self.browser_config.get('password')\n\n            ssh.connect(self.get_ip(), username=username, password=password)\n\n            stdin, stdout, stderr = ssh.exec_command(command)\n\n            ssh.close()\n\n            return (stdout, stderr)\n\n        except Exception as e:\n            msg = \"Execute_command exception: %s\" % str(e)\n            self.error_log(msg)\n            raise Exception(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scp_file_remote_to_local(self, remote_path, local_path):\n\n        sshadd_command = [\n            'ssh-add',\n            '/Users/pyrat/.ssh/ubuntuNode'\n        ]\n        self.info_log(\n            \"executing command: %s\" %\n            ' '.join(sshadd_command)\n        )\n        p = subprocess.Popen(sshadd_command)\n        p.wait()\n\n        scp_command = [\n            'scp',\n            '-o',\n            'StrictHostKeyChecking=no',\n            '%s@%s:\"%s\"' %\n            (\n                self.browser_config.get('username'),\n                self.get_ip(),\n                remote_path\n            ),\n            local_path\n        ]\n        self.info_log(\n            \"executing command: %s\" %\n            ' '.join(scp_command)\n        )\n        p = subprocess.Popen(scp_command)\n        p.wait()", "response": "Scp a remote file to local file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef startup(self):\n\n        # Do not launch the virtual machine\n        if not self.browser_config.get('launch', False):\n            return True\n\n        self.info_log(\"Starting up...\")\n\n        try:\n            vm_already_running_cmd = [\n                \"VBoxManage\",\n                \"showvminfo\",\n                self.browser_config.get('vbname'),\n                \"--machinereadable\",\n                \"|\",\n                \"grep\",\n                \"VMState=\",\n                \"|\",\n                \"cut\",\n                \"-d'='\",\n                \"-f2\"\n            ]\n\n            output = subprocess.check_output(\n                ' '.join(vm_already_running_cmd),\n                stderr=subprocess.STDOUT,\n                shell=True\n            ).decode('utf').strip()\n\n            print(\n                \"Is vm already running output: {output}\"\n                .format(output=output)\n            )\n\n            if output.find('running') != -1:\n                return True\n\n            # Cleanup the vbox guestproperty variable\n            subprocess.call([\n                'VBoxManage',\n                'guestproperty',\n                'delete',\n                self.browser_config.get('vbname'),\n                'wait_until_ready'\n            ])\n            subprocess.call([\n                'VBoxManage',\n                'guestproperty',\n                'delete',\n                self.browser_config.get('vbname'),\n                'hub_ip'\n            ])\n\n            startvm = [\n                \"VBoxManage\",\n                \"startvm\",\n                \"'{vbname}'\"\n                .format(\n                    vbname=self.browser_config.get('vbname')\n                ),\n                \"--type\",\n                self.browser_config.get('vbox_type', 'gui')\n            ]\n\n            out = subprocess.check_output(\n                ' '.join(startvm),\n                stderr=subprocess.STDOUT,\n                shell=True\n            )\n            self.info_log('VBoxManage output: {out}'.format(out=out))\n\n            instance_ready = False\n            # TODO should be configurable\n            timeout = 60\n\n            self.info_log('Waiting for instance to start...')\n\n            for i in range(timeout):\n                getproperty = [\n                    'VBoxManage',\n                    'guestproperty',\n                    'get',\n                    self.browser_config.get('vbname'),\n                    'wait_until_ready'\n                ]\n                output = subprocess.check_output(\n                    ' '.join(getproperty),\n                    stderr=subprocess.STDOUT,\n                    shell=True\n                ).decode('utf').strip()\n                self.info_log(\n                    'VBoxManage guestproperty output: {output}'\n                    .format(output=output)\n                )\n\n                if output.find('ready') != -1:\n                    instance_ready = True\n                    break\n\n                sleep(1)\n\n            sleep(3)\n            if instance_ready:\n                self.info_log('[Done] Instance ready...')\n            else:\n                raise Exception(\"Timeout error: the virtualbox machine is still not ready.\")  # noqa\n\n            # HUB IP\n            hub_ip = ni.ifaddresses('en0')[2][0]['addr']\n\n            self.info_log(\"Hub ip: %s\" % hub_ip)\n\n            # Start selenium on the node\n            # LINUX\n            if self.browser_config.get('platform').lower() == \"linux\":\n\n                self.info_log('Starting the selenium node server')\n\n                # Update the hub_ip browser config\n                self.browser_config.config['hub_ip'] = hub_ip\n\n                command = self.browser_config.get(\n                    \"selenium_command\"\n                ).format(**self.browser_config.config)\n                self.execute_command(command)\n\n            # WINDOWS\n            elif self.browser_config.get('platform').lower() == \"windows\":\n\n                self.info_log(\"Setting the guest property in Windows\")\n\n                # user_session.machine.set_guest_property(\n                #     \"hub_ip\", \"%s:%s\" % (hub_ip, '4444'), ''\n                # )\n\n            return True\n\n        except Exception as e:\n            self.error_log('Exception: %s' % e)\n            raise", "response": "This will launch and configure the virtual box machine\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntears down the virtual box machine.", "response": "def tear_down(self):\n        \"\"\"Tear down the virtual box machine\n        \"\"\"\n\n        if not self.browser_config.get('terminate'):\n            self.warning_log(\"Skipping terminate\")\n            return\n\n        self.info_log(\"Tearing down\")\n\n        if self.browser_config.get('platform').lower() == 'linux':\n            self.execute_command(\"shutdown -h now\", username='root')\n\n        elif self.browser_config.get('platform').lower() == 'windows':\n            self.session.console.power_down()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_video_recording(self, local_video_file_path, video_filename):\n\n        self.runner.info_log(\"Starting video recording...\")\n\n        self.local_video_recording_file_path = local_video_file_path\n        self.remote_video_recording_file_path = video_filename\n\n        self.execute_command(\n            \"./start_recording.sh '%s'\" % self.remote_video_recording_file_path\n        )", "response": "Start the video recording"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop the video recording", "response": "def stop_video_recording(self):\n        \"\"\"Stop the video recording\n        \"\"\"\n\n        self.runner.info_log(\"Stopping video recording...\")\n\n        self.execute_command(\"./stop_recording.sh\")\n        # self.runner.info_log(\"output: %s\"%output)\n\n        sleep(5)\n\n        self.scp_file_remote_to_local(\n            self.remote_video_recording_file_path,\n            self.local_video_recording_file_path\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_new_pipeline():\n\n    def new_create_pipeline(context, *args, **kwargs):\n        result = old_create_pipeline(context, *args, **kwargs)\n        result.insert(1, DAAPObjectTransformer(context))\n\n        return result\n\n    old_create_pipeline = Pipeline.create_pipeline\n    Pipeline.create_pipeline = new_create_pipeline", "response": "Installs a new pipeline that creates the object transformer for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadItems(self, excludeRead=False, loadLimit=20, since=None, until=None):\n        self.clearItems()\n        self.loadtLoadOk    = False\n        self.lastLoadLength = 0\n        self._itemsLoadedDone(self._getContent(excludeRead, None, loadLimit, since, until))", "response": "Load items and call itemsLoadedDone to transform data in objects\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads more items from the cache.", "response": "def loadMoreItems(self, excludeRead=False, continuation=None, loadLimit=20, since=None, until=None):\n        \"\"\"\n        Load more items using the continuation parameters of previously loaded items.\n        \"\"\"\n        self.lastLoadOk     = False\n        self.lastLoadLength = 0\n        if not continuation and not self.continuation:\n            return\n        self._itemsLoadedDone(self._getContent(excludeRead, continuation or self.continuation, loadLimit, since, until))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _itemsLoadedDone(self, data):\n        if data is None:\n            return\n        self.continuation   = data.get('continuation', None)\n        self.lastUpdated    = data.get('updated', None)\n        self.lastLoadLength = len(data.get('items', []))\n        self.googleReader.itemsToObjects(self, data.get('items', []))\n        self.lastLoadOk = True", "response": "Called when all items are loaded\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, cls):\n        doc_type = cls.search_objects.mapping.doc_type\n\n        self.all_models[doc_type] = cls\n        base_class = cls.get_base_class()\n        if base_class not in self.families:\n            self.families[base_class] = {}\n        self.families[base_class][doc_type] = cls\n\n        if cls.search_objects.mapping.index not in self.indexes:\n            self.indexes[cls.search_objects.mapping.index] = []\n\n        self.indexes[cls.search_objects.mapping.index].append(cls)", "response": "Adds a new PolymorphicIndexable to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_loop (copy_to, finished=None, buf_len=10240):\n    if finished is not None:\n        copy_to[finished]= None\n\n    # NOTE:\n    # os.sendfile (self.dst, self.src, None, 0)\n    # OSError: [Errno 22] Invalid argument\n    # and splice() is not available\n    # so, copy by hand\n    selector = DefaultSelector ()\n    for src in copy_to.keys ():\n        if (     not isinstance (src, int)\n                and (   getattr (src, 'fileno', None) is None\n                    or not isinstance (src.fileno(), int)) ):\n            logger.debug ('type mismatch: %s', src)\n        else:\n            logger.debug (\"registering %s for read\", src)\n            # if finished is also one of the srcs, then register() complains\n            try:\n                selector.register (src, EVENT_READ)\n            except KeyError:\n                pass\n\n    def close_file (f):\n        if f in copy_to:\n            del copy_to[f]\n\n        try:\n            selector.unregister (i)\n        except KeyError:\n            pass\n\n        close (f)\n\n    while len (copy_to)>0:\n        logger.debug (copy_to)\n\n        events= selector.select ()\n        for key, _ in events:\n            logger.debug (\"%s is ready to read\", key)\n            i= key.fileobj\n\n            # for error in e:\n            #     logger.debug ('%s error')\n                # TODO: what?\n\n            o= copy_to[i]\n\n            try:\n                data= read (i, buf_len)\n                logger.debug2 ('%s -> %s: %s', i, o, data)\n\n            # ValueError: read of closed file\n            except (OSError, ValueError) as e:\n                logger.debug ('stopping copying for %s', i)\n                logger.debug (traceback.format_exc ())\n                close_file (i)\n                break\n            else:\n                if len (data)==0:\n                    logger.debug ('stopping copying for %s, no more data', i)\n                    close_file (i)\n\n                    if finished is not None and i==finished:\n                        logger.debug ('finishing')\n                        # quite a hack :)\n                        copy_to= {}\n\n                        break\n                else:\n                    write (o, data)\n\n    selector.close ()\n    logger.debug ('over and out')", "response": "This function loops through the file - like object and copies the data into the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits a variance component model with the predefined design and the initialization and returns all the results", "response": "def fit(self,Params0=None,grad_threshold=1e-2):\n        \"\"\"\n        fit a variance component model with the predefined design and the initialization and returns all the results\n        \"\"\"\n\n        # GPVD initialization\n        lik = limix.CLikNormalNULL()\n        # Initial Params\n        if Params0==None:\n            n_params = self.C1.getNumberParams()\n            n_params+= self.C2.getNumberParams()\n            Params0 = SP.rand(n_params)\n        # MultiGP Framework\n        covar = []\n        gp    = []\n        mean  = []\n        for i in range(self.N):\n            covar.append(limix.CLinCombCF())\n            covar[i].addCovariance(self.C1)\n            covar[i].addCovariance(self.C2)\n            coeff = SP.array([self.eigen[i],1])\n            covar[i].setCoeff(coeff)\n            mean.append(limix.CLinearMean(self.Yt[:,i],SP.eye(self.P)))\n        gpVD = limix.CGPvarDecomp(covar[0],lik,mean[0],SP.ones(self.N),self.P,self.Yt,Params0)\n        for i in range(self.N):\n            gp.append(limix.CGPbase(covar[i],lik,mean[i]))\n            gp[i].setY(self.Yt[:,i])\n            gpVD.addGP(gp[i])\n                \n        # Optimization\n        gpVD.initGPs()\n        gpopt = limix.CGPopt(gpVD)\n        LML0=-1.0*gpVD.LML()\n        start_time = time.time()\n        conv = gpopt.opt()\n        time_train = time.time() - start_time\n        LML=-1.0*gpVD.LML()\n        LMLgrad = SP.linalg.norm(gpVD.LMLgrad()['covar'])\n        Params = gpVD.getParams()['covar']\n    \n        # Check whether limix::CVarianceDecomposition.train() has converged\n        if conv!=True or LMLgrad>grad_threshold or Params.max()>10:\n            print('limix::CVarianceDecomposition::train has not converged')\n            res=None\n        else:\n            res = {\n                'Params0':          Params0,\n                'Params':           Params,\n                'LML':              SP.array([LML]),\n                'LML0':             SP.array([LML0]),\n                'LMLgrad':          SP.array([LMLgrad]),\n                'time_train':       SP.array([time_train]),\n                }\n        return res\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_rate(rate):\n    if not (isinstance(rate, int) or isinstance(rate, float)):\n        raise TypeError(\"argument to set_rate is expected to be int or float\")\n    global loop_duration\n    loop_duration = 1.0/rate", "response": "Defines the ideal rate at which computation is performed"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsleeps for a dynamic duration of time as determined by set_rate and true().", "response": "def sleep():\n    \"\"\"Sleeps for a dynamic duration of time as determined by set_rate() and true().\n    \n    :raises: BeatError: if this function is called before calling set_rate() or \\\n            before calling true()\n    \"\"\"\n    if loop_duration == 0:\n        raise BeatError(\"call beat.set_rate() before calling sleep\")\n    if loop_start_time == None:\n        raise BeatError(\"call beat.true() before calling sleep\")\n    td = datetime.datetime.now() - loop_start_time\n    duration_to_sleep = loop_duration - td.total_seconds()\n    if duration_to_sleep < 0:\n        raise BeatError(\"skipping sleep. Too much work!\")\n    time.sleep(duration_to_sleep)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _normalize_encoding(encoding):\n    if encoding is None:\n        return None\n    # lower() + '_' / '-' conversion\n    encoding = encoding.replace('_', '-').lower()\n    if encoding == 'utf-8' or encoding.startswith('utf-8-'):\n        return 'utf-8'\n    for variant in ['latin-1', 'iso-latin-1', 'iso-8859-1']:\n        if (encoding == variant or\n            encoding.startswith(variant + '-')):\n            return 'iso-8859-1'\n    return encoding", "response": "returns normalized name for encoding"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the source code is UTF - 8 encoded.", "response": "def _check_for_encoding(b):\n    \"\"\"You can use a different encoding from UTF-8 by putting a specially-formatted\n    comment as the first or second line of the source code.\"\"\"\n    eol = b.find(b'\\n')\n    if eol < 0:\n        return _check_line_for_encoding(b)[0]\n    enc, again = _check_line_for_encoding(b[:eol])\n    if enc or not again:\n        return enc\n    eol2 = b.find(b'\\n', eol + 1)\n    if eol2 < 0:\n        return _check_line_for_encoding(b[eol + 1:])[0]\n    return _check_line_for_encoding(b[eol + 1:eol2])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the line contains an encoding declaration", "response": "def _check_line_for_encoding(line):\n    \"\"\"returns the declared encoding or None\"\"\"\n    i = 0\n    for i in range(len(line)):\n        if line[i] == b'#':\n            break\n        if line[i] not in b' \\t\\014':\n            return None, False  # Not a comment, don't read the second line.\n    return pytokenizer.match_encoding_declaration(line[i:]), True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_source(self, bytessrc, compile_info):\n        # Detect source encoding.\n        enc = None\n        if compile_info.flags & consts.PyCF_SOURCE_IS_UTF8:\n            enc = 'utf-8'\n\n        if compile_info.flags & consts.PyCF_IGNORE_COOKIE:\n            textsrc = bytessrc\n        elif bytessrc.startswith(b\"\\xEF\\xBB\\xBF\"):\n            bytessrc = bytessrc[3:]\n            enc = 'utf-8'\n            # If an encoding is explicitly given check that it is utf-8.\n            decl_enc = _check_for_encoding(bytessrc)\n            if decl_enc and decl_enc != \"utf-8\":\n                raise error.SyntaxError(\"UTF-8 BOM with %s coding cookie\" % decl_enc,\n                                        filename=compile_info.filename)\n            textsrc = bytessrc.decode('utf-8')\n        else:\n            enc = _normalize_encoding(_check_for_encoding(bytessrc))\n            if enc is None:\n                enc = 'utf-8'\n            try:\n                # textsrc = recode_to_utf8(self.space, bytessrc, enc)\n                textsrc = bytessrc.decode(enc)\n            except UnicodeDecodeError as e:\n                # if the codec is not found, LookupError is raised.  we\n                # check using 'is_w' not to mask potential IndexError or\n                # KeyError\n                space = self.space\n                if e.match(space, space.w_LookupError):\n                    raise error.SyntaxError(\"Unknown encoding: %s\" % enc,\n                                            filename=compile_info.filename)\n                # Transform unicode errors into SyntaxError\n                if e.match(space, space.w_UnicodeDecodeError):\n                    e.normalize_exception(space)\n                    w_message = space.str(e.get_w_value(space))\n                    raise error.SyntaxError(space.text_w(w_message))\n                raise\n\n        flags = compile_info.flags\n\n        # The tokenizer is very picky about how it wants its input.\n        source_lines = textsrc.splitlines(True)\n        if source_lines and not source_lines[-1].endswith(\"\\n\"):\n            source_lines[-1] += '\\n'\n        if textsrc and textsrc[-1] == \"\\n\":\n            flags &= ~consts.PyCF_DONT_IMPLY_DEDENT\n\n        self.prepare(_targets[compile_info.mode])\n        tp = 0\n        try:\n            try:\n                # Note: we no longer pass the CO_FUTURE_* to the tokenizer,\n                # which is expected to work independently of them.  It's\n                # certainly the case for all futures in Python <= 2.7.\n                tokens = pytokenizer.generate_tokens(source_lines, flags)\n\n                newflags, last_future_import = (\n                    future.add_future_flags(self.future_flags, tokens))\n                compile_info.last_future_import = last_future_import\n                compile_info.flags |= newflags\n                self.grammar = pygram.python_grammar\n                tokens_stream = iter(tokens)\n\n                for tp, value, lineno, column, line in tokens_stream:\n                    if self.add_token(tp, value, lineno, column, line):\n                        break\n\n                if compile_info.mode == 'single':\n                    for tp, value, lineno, column, line in tokens_stream:\n                        if tp == pygram.tokens.ENDMARKER:\n                            break\n                        if tp == pygram.tokens.NEWLINE:\n                            continue\n\n                        if tp == pygram.tokens.COMMENT:\n                            for tp, _, _, _, _ in tokens_stream:\n                                if tp == pygram.tokens.NEWLINE:\n                                    break\n                        else:\n                            new_err = error.SyntaxError\n                            msg = (\"multiple statements found while \"\n                                   \"compiling a single statement\")\n                            raise new_err(msg, lineno, column,\n                                          line, compile_info.filename)\n\n            except error.TokenError as e:\n                e.filename = compile_info.filename\n                raise\n            except error.TokenIndentationError as e:\n                e.filename = compile_info.filename\n                raise\n            except parser.ParseError as e:\n                # Catch parse errors, pretty them up and reraise them as a\n                # SyntaxError.\n                new_err = error.IndentationError\n                if tp == pygram.tokens.INDENT:\n                    msg = \"unexpected indent\"\n                elif e.expected == pygram.tokens.INDENT:\n                    msg = \"expected an indented block\"\n                else:\n                    new_err = error.SyntaxError\n                    msg = \"invalid syntax\"\n                raise new_err(msg, e.lineno, e.col_offset, e.line,\n                              compile_info.filename)\n            else:\n                tree = self.root\n        finally:\n            # Avoid hanging onto the tree.\n            self.root = None\n        if enc is not None:\n            compile_info.encoding = enc\n        return tree", "response": "Parses a Python source string into a tree of Python objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the project version into a significant part of the version.", "response": "def _parse_project_version(version=''):\n    \"\"\"\n    Returns the significant part of the version excluding the build\n       \n    The final forms returned can be\n    \n    major.minor\n    major.minor stage (spaces will be replaced with '-')\n    major.minor.stage\n    major.minor-stage\n    major.minorstage (eg 1.0rc1)\n    major.minor.maintenance\n    major.minor.maintenance-stage\n    major.minor.maintenancestage\n    \n    Anything beyond the maintenance or stage whichever is last is ignored \n    \"\"\"\n    \n    def mm_version(vers):\n        stage = ''\n        stage_sep = ''\n        finalvers = ''\n        if not vers.isdigit():\n            for num,char in enumerate(vers):\n                if char.isdigit():\n                    finalvers += str(char)\n                elif char.isalpha():\n                    stage = vers[num:]\n                    break\n                elif char in [' ','-']: #sep\n                    #We will strip spaces to avoid needing to 'quote' paths\n                    stage_sep = '-'\n                    stage = vers[num+1:]\n                    break\n        else:\n            finalvers = vers\n        #remove any final build numbers\n        if ' ' in stage:\n            stage = stage.split(' ')[0]\n        elif '-' in stage:\n            stage = stage.split('-')[0]\n        return (finalvers,stage,stage_sep)\n        \n    v = version.split('.')\n    if len(v)==1: return v[0]\n    major = v[0]\n    minor = v[1]\n    maint = ''\n    stage = ''\n    if len(v)>2 and v[2]<>'0': #(1.0.0 == 1.0)\n        maint = v[2]\n    if len(v)>3 and v[3][0].isalpha():\n        stage = v[3]\n        project_version = '.'.join([major,minor,maint,stage])\n    else:\n        #Detect stage in minor\n        minor,stage_minor,stage_minor_sep = mm_version(minor)\n        if maint: #may be maint = ''\n            maint, stage_maint, stage_maint_sep = mm_version(maint)\n        else:\n            stage_maint = ''; stage_maint_sep = ''\n        if stage_minor:\n            stage = stage_minor\n            stage_sep = stage_minor_sep\n        elif stage_maint:\n            stage = stage_maint\n            stage_sep = stage_maint_sep\n        finalvers = [major,minor]\n        if maint: finalvers.append(maint)\n        finalvers = '.'.join(finalvers)\n        if stage:\n            finalvers = stage_sep.join([finalvers,stage])\n        project_version = finalvers\n   \n    return project_version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _root_domain():\n\n    if not hasattr(env,'root_domain'):\n        cwd = os.getcwd().split(os.sep)\n        domain = ''\n        #if the first env.host has a domain name then we'll use that\n        #since there are no top level domains that have numbers in them we can test env.host\n\n        username, host, port = normalize(env.hosts[0])\n        if host[-1] in string.ascii_letters:\n            domain_parts = env.host.split('.')\n            length = len(domain_parts)\n            if length==2:\n                #assumes .com .net etc so we want the full hostname for the domain\n                domain = host\n            elif length==3 and len(domain_parts[-1])==2:\n                #assume country tld so we want the full hostname for domain\n                domain = host\n            elif length >=3:\n                #assume the first part is the hostname of the machine\n                domain = '.'.join(domain[1:])\n        #we'll just pick the first directory in the path which has a period.\n        else:\n            for d in cwd:\n                if '.' in d: \n                    domain = d\n        if not domain and env.INTERACTIVE:\n            domain = prompt('Enter the root domain for this project ',default='example.com')\n        else:\n            domain = 'example.com'\n        env.root_domain = domain\n    return env.root_domain", "response": "Return the root domain name for the current environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_settings():\n    valid=True\n    if not get_version() >= '1.0':\n        print \"FABRIC ERROR: Woven is only compatible with Fabric < 1.0\"\n        valid = False\n    if not env.MEDIA_ROOT or not env.MEDIA_URL:\n        print \"MEDIA ERROR: You must define a MEDIA_ROOT & MEDIA_URL in your settings.py\"\n        print \"even if plan to deploy your media separately to your project\"\n        valid = False\n    if not env.TEMPLATE_DIRS:\n        print \"TEMPLATES_DIRS ERROR: You must define a TEMPLATES_DIRS in your settings.py\"\n        valid=False\n    if env.DEFAULT_DATABASE_ENGINE in ['django.db.backends.','django.db.backends.dummy']:\n        print \"DATABASE SETTINGS ERROR: The default database engine has not been defined in your settings.py file\"\n        print \"At a minimum you must define an sqlite3 database for woven to deploy,\"\n        print \"or define a database backend is managed outside of woven.\"    \n        valid=False\n    if not valid: sys.exit(1)", "response": "Validate the users settings conf prior to deploy\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the environment variables for the hosts containing a new node.", "response": "def set_env(settings=None, setup_dir=''):\n    \"\"\"\n    Used in management commands or at the module level of a fabfile to\n    integrate woven project django.conf settings into fabric, and set the local current\n    working directory to the distribution root (where setup.py lives).\n    \n    ``settings`` is your django settings module to pass in\n    if you want to call this from a fabric script.\n    \n    ``setup_dir`` is an optional path to the directory containing setup.py\n    This would be used in instances where setup.py was not above the cwd\n    \n    This function is used to set the environment for all hosts\n   \n    \"\"\"\n\n    #switch the working directory to the distribution root where setup.py is\n    if hasattr(env, 'setup_path') and env.setup_path:\n        setup_path = env.setup_path\n    else:\n        with fab_settings(fabfile='setup.py'):\n            if setup_dir:\n                setup_path = os.path.join(setup_dir,'setup.py')\n            else:\n                setup_path = find_fabfile()\n            if not setup_path:\n                print 'Error: You must have a setup.py file in the current or a parent folder'\n                sys.exit(1)\n        \n    local_working_dir = os.path.split(setup_path)[0]\n    os.chdir(local_working_dir)\n    \n    setup = run_setup('setup.py',stop_after=\"init\")\n\n    if setup.get_name() == 'UNKNOWN' or setup.get_version()=='0.0.0' or not setup.packages:\n        print \"ERROR: You must define a minimum of name, version and packages in your setup.py\"\n        sys.exit(1)\n    \n    #project env variables for deployment\n    env.project_name = setup.get_name() #project_name()\n    env.project_full_version = setup.get_version()#local('python setup.py --version').rstrip()\n    env.project_version = _parse_project_version(env.project_full_version)\n    env.project_fullname = '-'.join([env.project_name,env.project_version])\n    env.project_package_name = setup.packages[0]\n    env.patch = False\n\n    #django settings are passed in by the command\n    #We'll assume that if the settings aren't passed in we're running from a fabfile\n    if not settings:\n        sys.path.insert(0,local_working_dir)\n        \n        #import global settings\n        project_settings = import_module(env.project_name+'.settings')\n    else:\n\n        project_settings = settings\n    #If sqlite is used we can manage the database on first deployment\n    env.DEFAULT_DATABASE_ENGINE = project_settings.DATABASES['default']['ENGINE']\n    env.DEFAULT_DATABASE_NAME = project_settings.DATABASES['default']['NAME']\n    \n    #overwrite with main sitesettings module\n    #just for MEDIA_URL, ADMIN_MEDIA_PREFIX, and STATIC_URL\n    #if this settings file exists\n    try:\n        site_settings = import_module('.'.join([env.project_name,'sitesettings.settings']))\n        project_settings.MEDIA_URL = site_settings.MEDIA_URL\n        project_settings.ADMIN_MEDIA_PREFIX = site_settings.ADMIN_MEDIA_PREFIX\n        project_settings.DATABASES = site_settings.DATABASES \n        if hasattr(site_settings,'STATIC_URL'):\n            project_settings.STATIC_URL = site_settings.STATIC_URL\n        else:\n            project_settings.STATIC_URL = project_settings.ADMIN_MEDIA_PREFIX\n    except ImportError:\n        pass\n\n    #update woven_env from project_settings    \n    local_settings = dir(project_settings)\n    #only get settings that woven uses\n    for setting in local_settings:\n        if setting.isupper() and hasattr(woven_env,setting):\n            s = getattr(project_settings,setting,'')\n            woven_env[setting] = s\n    \n    #upate the fabric env with all the woven settings\n    env.update(woven_env)\n    \n    #set any user/password defaults if they are not supplied\n    #Fabric would get the user from the options by default as the system user\n    #We will overwrite that\n    if woven_env.HOST_USER:\n        env.user = woven_env.HOST_USER\n    env.password = woven_env.HOST_PASSWORD\n    \n    #set the hosts if they aren't already\n    if not env.hosts: env.hosts = woven_env.HOSTS\n    if not env.roledefs: env.roledefs = woven_env.ROLEDEFS\n    \n    #reverse_lookup hosts to roles\n    role_lookup  = {}\n    for role in env.roles:\n        r_hosts = env.roledefs[role]\n        for host in r_hosts:\n            #since port is not handled by fabric.main.normalize we'll do it ourselves\n            role_lookup['%s:%s'% (host,str(woven_env.HOST_SSH_PORT))]=role\n    #now add any hosts that aren't already defined in roles\n    for host in env.hosts:\n        host_string = '%s:%s'% (host,str(woven_env.HOST_SSH_PORT))\n        if host_string not in role_lookup.keys():\n            role_lookup[host_string] = ''\n    env.role_lookup = role_lookup\n    env.hosts = role_lookup.keys()\n    \n    #remove any unneeded db adaptors - except sqlite\n    remove_backends = ['postgresql_psycopg2', 'mysql']\n    for db in project_settings.DATABASES:\n        engine = project_settings.DATABASES[db]['ENGINE'].split('.')[-1]\n        if engine in remove_backends: remove_backends.remove(engine)\n    for backend in remove_backends:\n        if backend == 'postgresql_psycopg2': rm = 'python-psycopg2'\n        elif backend == 'mysql': rm = 'python-mysqldb'\n        env.HOST_BASE_PACKAGES.remove(rm)\n\n    #packages can be just the base + extra packages\n    #or role dependent we need to just map out the packages to hosts and roles here\n    packages = {}\n    all_packages = set([])\n    for role in env.roles:\n        packages[role]=env.ROLE_PACKAGES.get(role,[])\n        if not packages[role]:\n            packages[role] = env.HOST_BASE_PACKAGES + env.HOST_EXTRA_PACKAGES\n        all_packages = set(packages[role]) | all_packages\n\n    #no role\n    packages[''] = env.HOST_BASE_PACKAGES + env.HOST_EXTRA_PACKAGES\n    all_packages = set(packages['']) | all_packages\n\n    #conveniently add gunicorn ppa\n    if 'gunicorn' in all_packages:\n        if 'ppa:bchesneau/gunicorn' not in env.LINUX_PACKAGE_REPOSITORIES:\n            env.LINUX_PACKAGE_REPOSITORIES.append('ppa:bchesneau/gunicorn')    \n\n    env.packages = packages\n    \n    #sanity check for unwanted combinations in the empty role\n    u = set(packages[''])\n    wsgi = u & set(['gunicorn','uwsgi'])\n    if wsgi and 'apache2' in u:\n        u = u - set(['apache2','libapache2-mod-wsgi'])\n\n    #Used to detect certain apps eg South, static_builder\n    env.INSTALLED_APPS = project_settings.INSTALLED_APPS\n\n    env.packages[''] = list(u)\n   \n    #per host\n    env.installed_packages = {} \n    env.uninstalled_packages = {}\n    \n    #UFW firewall rules\n    firewall_rules = {}\n    for role in env.roles:\n        firewall_rules[role]= env.ROLE_UFW_RULES.get(role,[])\n    firewall_rules['']=env.UFW_RULES\n    env.firewall_rules = firewall_rules\n    \n    #Now update the env with any settings that are not defined by woven but may\n    #be used by woven or fabric\n    env.MEDIA_ROOT = project_settings.MEDIA_ROOT\n    env.MEDIA_URL = project_settings.MEDIA_URL\n    try:\n        env.ADMIN_MEDIA_PREFIX = project_settings.ADMIN_MEDIA_PREFIX\n    except AttributeError:\n        env.ADMIN_MEDIA_PREFIX = ''\n    if not env.STATIC_URL:\n        env.STATIC_URL = project_settings.ADMIN_MEDIA_PREFIX\n    env.TEMPLATE_DIRS = project_settings.TEMPLATE_DIRS\n    \n    #Set the server /etc/timezone\n    env.TIME_ZONE = project_settings.TIME_ZONE\n    #Used to detect certain apps eg South, static_builder\n    env.INSTALLED_APPS = project_settings.INSTALLED_APPS\n    \n    #SSH key\n    if not hasattr(env,'key_filename') and not env.key_filename and env.SSH_KEY_FILENAME:\n        env.key_filename = env.SSH_KEY_FILENAME\n    elif not hasattr(env,'key_filename'):\n        env.key_filename = None\n        \n    #noinput\n    if not hasattr(env,'INTERACTIVE'):\n        env.INTERACTIVE = True\n    if not hasattr(env,'verbosity'):\n        env.verbosity = 1\n    \n    #overwrite existing settings\n    if not hasattr(env,'overwrite'):\n        env.overwrite=False\n    \n    #South integration defaults\n    env.nomigration = False\n    env.manualmigration = False\n    env.migration = ''\n    \n    env.root_disabled = False\n    \n    #Sites\n    env.sites = {}\n    env.shell = '/bin/bash --noprofile -l -c'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns any functions post install a matching package.", "response": "def post_install_package():\n    \"\"\"\n    Run any functions post install a matching package.\n    Hook functions are in the form post_install_[package name] and are\n    defined in a deploy.py file\n    \n    Will be executed post install_packages and upload_etc\n    \"\"\"\n\n    module_name = '.'.join([env.project_package_name,'deploy'])\n    funcs_run = []\n    try:\n        imported = import_module(module_name)\n        funcs = vars(imported)\n        for f in env.installed_packages[env.host]:\n            func = funcs.get(''.join(['post_install_',f.replace('.','_').replace('-','_')]))\n            if func:\n                func()\n                funcs_run.append(func)\n    except ImportError:\n        pass\n    \n    #run per app\n    for app in env.INSTALLED_APPS:\n        if app == 'woven': continue\n        module_name = '.'.join([app,'deploy'])\n        try:\n            imported = import_module(module_name)\n            funcs = vars(imported)\n            for f in env.installed_packages[env.host]:\n                func = funcs.get(''.join(['post_install_',f.replace('.','_').replace('-','_')]))\n                if func and func not in funcs_run:\n                    func()\n                    funcs_run.append(func)\n        except ImportError:\n            pass\n    #run woven last\n    import woven.deploy\n    funcs = vars(woven.deploy)\n    for f in env.installed_packages[env.host]:\n        func = funcs.get(''.join(['post_install_',f.replace('.','_').replace('-','_')]))\n        if func and func not in funcs_run: func()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a hook function defined in a deploy. py file", "response": "def post_exec_hook(hook):\n    \"\"\"\n    Runs a hook function defined in a deploy.py file\n    \"\"\"\n    #post_setupnode hook\n    module_name = '.'.join([env.project_package_name,'deploy'])\n    funcs_run = []\n    try:\n        imported = import_module(module_name)\n        func = vars(imported).get(hook)\n        if func:\n            func()\n            funcs_run.append(func)\n    except ImportError:\n        return\n\n   #run per app\n    for app in env.INSTALLED_APPS:\n        if app == 'woven': continue\n        module_name = '.'.join([app,'deploy'])\n        try:\n            imported = import_module(module_name)\n            func = vars(imported).get(hook)\n            if func and func not in funcs_run:\n                func()\n                funcs_run.append(func)\n        except ImportError:\n            pass\n    import woven.deploy\n    func = vars(woven.deploy).get(hook)\n    if func and func not in funcs_run: func()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef project_version(full_version):\n\n    project_full_version=full_version\n    v = _parse_project_version(full_version)\n    name = project_name()\n    project_fullname = '-'.join([name,v])\n\n    return _setenv(project_full_version=project_full_version, project_version=v,project_name=name,project_fullname=project_fullname)", "response": "Set the project version in the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a simple state on the server by creating a file with the desired state s name and storing the content as json strings.", "response": "def set_server_state(name,object=None,delete=False):\n    \"\"\"\n    Sets a simple 'state' on the server by creating a file\n    with the desired state's name and storing ``content`` as json strings if supplied\n    \n    returns the filename used to store state   \n    \"\"\"\n    with fab_settings(project_fullname=''):\n        return set_version_state(name,object,delete)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_version_state(name,object=None,delete=False):\n    if env.project_fullname: state_name = '-'.join([env.project_fullname,name])\n    else: state_name = name\n    with fab_settings(warn_only=True):\n        #Test for os state\n        if not exists('/var/local/woven', use_sudo=True):\n            sudo('mkdir /var/local/woven')\n    if not delete:\n        sudo('touch /var/local/woven/%s'% state_name)\n        if object <> None:\n            fd, file_path = tempfile.mkstemp()\n            f = os.fdopen(fd,'w')\n            f.write(json.dumps(object))\n            f.close()\n            put(file_path,'/tmp/%s'% state_name)\n            os.remove(file_path)\n            sudo('cp /tmp/%s /var/local/woven/%s'% (state_name,state_name))\n    else:\n        sudo('rm -f /var/local/woven/%s'% state_name)\n    return state_name", "response": "Sets a simple state on the server by creating a file holding the desired state s name + version and storing the content as json strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the server state as a python object or True", "response": "def server_state(name, no_content=False):\n    \"\"\"\n    If the server state exists return parsed json as a python object or True \n    prefix=True returns True if any files exist with ls [prefix]*\n    \"\"\"\n    with fab_settings(project_fullname=''):\n        return version_state(name, no_content=no_content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the state of a specific server", "response": "def version_state(name, prefix=False, no_content=False):\n    \"\"\"\n    If the server state exists return parsed json as a python object or True \n    prefix=True returns True if any files exist with ls [prefix]*\n    \"\"\"\n    if env.project_fullname: full_name = '-'.join([env.project_fullname,name])\n    else: full_name = name\n    current_state = False\n    state = State(full_name)\n    state_path = '/var/local/woven/%s'% full_name\n    if not prefix and not no_content and exists(state_path):\n        content = int(sudo('ls -s %s'% state_path).split()[0]) #get size\n        if content:\n            fd, file_path = tempfile.mkstemp()\n            os.close(fd)\n            get(state_path,file_path)\n            with open(file_path, \"r\") as f:\n                content = f.read()\n                object = json.loads(content)\n                current_state = object\n        else:\n            current_state = True\n    elif not prefix and no_content and exists(state_path):\n        current_state = True\n    elif prefix:\n        with fab_settings(warn_only=True): #find any version\n            current_state = sudo('ls /var/local/woven/*%s'% name)\n        if not current_state.failed:current_state = True\n      \n    return current_state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef archive(self, value):\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"archive\", value)\n            assert os.path.exists(value), \"'{0}' attribute: '{1}' file doesn't exists!\".format(\"archive\", value)\n        self.__archive = value", "response": "Sets the archive attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract(self, target):\n\n        if not foundations.common.path_exists(self.__archive):\n            raise foundations.exceptions.FileExistsError(\"{0} | '{1}' file doesn't exists!\".format(\n                self.__class__.__name__, self.__archive))\n\n        if not foundations.common.path_exists(target):\n            raise foundations.exceptions.DirectoryExistsError(\"{0} | '{1}' directory doesn't exists!\".format(\n                self.__class__.__name__, target))\n\n        archive = zipfile.ZipFile(self.__archive)\n        content = archive.namelist()\n\n        directories = [item for item in content if item.endswith(\"/\")]\n        files = [item for item in content if not item.endswith(\"/\")]\n\n        directories.sort()\n        directories.reverse()\n\n        for directory in directories:\n            not os.path.isdir(os.path.join(target, directory)) and foundations.io.set_directory(\n                os.path.join(target, directory))\n\n        for file in files:\n            LOGGER.info(\"{0} | Extracting '{1}' file!\".format(self.__class__.__name__, file))\n            with open(os.path.join(target, file), \"w\") as output:\n                buffer = StringIO(archive.read(file))\n                bufferSize = 2 ** 20\n                data = buffer.read(bufferSize)\n                while data:\n                    output.write(data)\n                    data = buffer.read(bufferSize)\n        return True", "response": "Extracts the archive file to given directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget output stream take care of characters encoding correctly.", "response": "def get_output_stream(encoding=anytemplate.compat.ENCODING,\n                      ostream=sys.stdout):\n    \"\"\"\n    Get output stream take care of characters encoding correctly.\n\n    :param ostream: Output stream (file-like object); sys.stdout by default\n    :param encoding: Characters set encoding, e.g. UTF-8\n    :return: sys.stdout can output encoded strings\n\n    >>> get_output_stream(\"UTF-8\")  # doctest: +ELLIPSIS\n    <encodings.utf_8.StreamWriter ... at 0x...>\n    \"\"\"\n    return codecs.getwriter(encoding)(ostream)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving duplicates in given list with its order kept.", "response": "def uniq(items):\n    \"\"\"Remove duplicates in given list with its order kept.\n\n    >>> uniq([])\n    []\n    >>> uniq([1, 4, 5, 1, 2, 3, 5, 10])\n    [1, 4, 5, 2, 3, 10]\n    \"\"\"\n    acc = items[:1]\n    for item in items[1:]:\n        if item not in acc:\n            acc += [item]\n\n    return acc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chaincalls(callables, obj):\n    for fun in callables:\n        if not callable(fun):\n            raise ValueError(\"Not callable: %r\" % repr(fun))\n        obj = fun(obj)\n\n    return obj", "response": "Chain the given callable objects to the object obj."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize given path in various different forms.", "response": "def normpath(path):\n    \"\"\"Normalize given path in various different forms.\n\n    >>> normpath(\"/tmp/../etc/hosts\")\n    '/etc/hosts'\n    >>> normpath(\"~root/t\")\n    '/root/t'\n    \"\"\"\n    funcs = [os.path.normpath, os.path.abspath]\n    if \"~\" in path:\n        funcs = [os.path.expanduser] + funcs\n\n    return chaincalls(funcs, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_filespec(fspec, sep=':', gpat='*'):\n    if sep in fspec:\n        tpl = (ftype, fpath) = tuple(fspec.split(sep))\n    else:\n        tpl = (ftype, fpath) = (None, fspec)\n\n    return [(fs, ftype) for fs in sorted(glob.glob(fpath))] \\\n        if gpat in fspec else [flip(tpl)]", "response": "Parse given filespec and return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a context file from stdin or stdin.", "response": "def load_context(ctx_path, ctx_type, scm=None):\n    \"\"\"\n    :param ctx_path: context file path or '-' (read from stdin)\n    :param ctx_type: context file type\n    :param scm: JSON schema file in any formats anyconfig supports, to\n        validate given context files\n    \"\"\"\n    if ctx_path == '-':\n        return loads(sys.stdin.read(), ac_parser=ctx_type, ac_schema=scm)\n\n    return load(ctx_path, ac_parser=ctx_type, ac_schema=scm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_and_load_contexts(contexts, schema=None, werr=False):\n    ctx = dict()\n    diff = None\n\n    if contexts:\n        for ctx_path, ctx_type in concat(parse_filespec(c) for c in contexts):\n            try:\n                diff = load_context(ctx_path, ctx_type, scm=schema)\n                if diff is not None:\n                    merge(ctx, diff)\n            except (IOError, OSError, AttributeError):\n                if werr:\n                    raise\n    return ctx", "response": "Parse and load contexts from a list of context files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite content to a file path.", "response": "def _write_to_filepath(content, output):\n    \"\"\"\n    :param content: Content string to write to\n    :param output: Output file path\n    \"\"\"\n    outdir = os.path.dirname(output)\n    if outdir and not os.path.exists(outdir):\n        os.makedirs(outdir)\n\n    with anytemplate.compat.copen(output, 'w') as out:\n        out.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_to_output(content, output=None,\n                    encoding=anytemplate.compat.ENCODING):\n    \"\"\"\n    :param content: Content string to write to\n    :param output: Output destination\n    :param encoding: Character set encoding of outputs\n    \"\"\"\n    if anytemplate.compat.IS_PYTHON_3 and isinstance(content, bytes):\n        content = str(content, encoding)\n\n    if output and not output == '-':\n        _write_to_filepath(content, output)\n    elif anytemplate.compat.IS_PYTHON_3:\n        print(content)\n    else:\n        print(content.encode(encoding.lower()), file=get_output_stream())", "response": "Writes content to output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes template paths from given filepath and paths list.", "response": "def mk_template_paths(filepath, paths=None):\n    \"\"\"\n    Make template paths from given filepath and paths list.\n\n    :param filepath: (Base) filepath of template file or None\n    :param paths: A list of template search paths or None\n\n    >>> mk_template_paths(\"/tmp/t.j2\", [])\n    ['/tmp']\n    >>> mk_template_paths(\"/tmp/t.j2\", [\"/etc\"])\n    ['/etc', '/tmp']\n    >>> mk_template_paths(None, [\"/etc\"])\n    ['/etc']\n    \"\"\"\n    if filepath is None:\n        return [os.curdir] if paths is None else paths\n\n    tmpldir = os.path.dirname(os.path.abspath(filepath))\n    return [tmpldir] if paths is None else paths + [tmpldir]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_template_from_path(filepath, paths=None):\n    if paths is None or not paths:\n        paths = [os.path.dirname(filepath), os.curdir]\n\n    for path in paths:\n        candidate = os.path.join(path, filepath)\n        if os.path.exists(candidate):\n            return candidate\n\n    LOGGER.warning(\"Could not find template=%s in paths=%s\", filepath, paths)\n    return None", "response": "Find a template file from a given filepath."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the first template engine that matches the filepath.", "response": "def find_engine(filepath=None, name=None):\n    \"\"\"\n    :param filepath: Template file path\n    :param name: Specify the name of template engine to use explicitly or\n        None; it will be selected automatically anyhow.\n\n    :return: Template engine class found\n    \"\"\"\n    if name is None:\n        engines = anytemplate.engine.find_by_filename(filepath)\n        if not engines:\n            raise TemplateEngineNotFound(\"filename=%s\" % str(filepath))\n\n        return engines[0]  # It should have highest priority.\n    else:\n        engine = anytemplate.engine.find_by_name(name)\n        if engine is None:\n            raise TemplateEngineNotFound(\"(template) name=%s\" % name)\n\n        return engine"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _render(template=None, filepath=None, context=None, at_paths=None,\n            at_encoding=anytemplate.compat.ENCODING, at_engine=None,\n            at_ask_missing=False, at_cls_args=None, _at_usr_tmpl=None,\n            **kwargs):\n    \"\"\"\n    Compile and render given template string and return the result string.\n\n    :param template: Template content string or None\n    :param filepath: Template file path or None\n    :param context: A dict or dict-like object to instantiate given\n        template file\n    :param at_paths: Template search paths\n    :param at_encoding: Template encoding\n    :param at_engine: Specify the name of template engine to use explicitly or\n        None to find it automatically anyhow.\n    :param at_cls_args: Arguments passed to instantiate template engine class\n    :param _at_usr_tmpl: Template file of path will be given by user later;\n        this file will be used just for testing purpose.\n    :param kwargs: Keyword arguments passed to the template engine to\n        render templates with specific features enabled.\n\n    :return: Rendered string\n    \"\"\"\n    ecls = find_engine(filepath, at_engine)\n    LOGGER.debug(\"Use the template engine: %s\", ecls.name())\n    engine = ecls() if at_cls_args is None else ecls(**at_cls_args)\n    at_paths = anytemplate.utils.mk_template_paths(filepath, at_paths)\n\n    if filepath is None:\n        (render_fn, target) = (engine.renders, template)\n    else:\n        (render_fn, target) = (engine.render, filepath)\n\n    try:\n        return render_fn(target, context=context, at_paths=at_paths,\n                         at_encoding=at_encoding, **kwargs)\n    except TemplateNotFound as exc:\n        LOGGER.warning(\"** Missing template[s]: paths=%r\", at_paths)\n        if not at_ask_missing:\n            raise TemplateNotFound(str(exc))\n\n        if _at_usr_tmpl is None:\n            _at_usr_tmpl = anytemplate.compat.raw_input(\n                \"\\nPlease enter an absolute or relative path starting \"\n                \"from '.' of missing template file\"\n                \"%s : \" % (\", \" + filepath if template is None else '')\n            ).strip()\n\n        usr_tmpl = anytemplate.utils.normpath(_at_usr_tmpl)\n        if template is None:\n            LOGGER.debug(\"Render %s instead of %s\", usr_tmpl, filepath)\n            target = usr_tmpl\n\n        return render_fn(target, context=context,\n                         at_paths=(at_paths + [os.path.dirname(usr_tmpl)]),\n                         at_encoding=at_encoding, **kwargs)\n    except Exception as exc:\n        raise CompileError(\"exc=%r, template=%s\" % (exc, target[:200]))", "response": "Compile and render given template string and return the result string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles and render given template file and return the result string.", "response": "def render(filepath, context=None, **options):\n    \"\"\"\n    Compile and render given template file and return the result string.\n\n    :param filepath: Template file path or '-'\n    :param context: A dict or dict-like object to instantiate given\n        template file\n    :param options: Optional keyword arguments such as:\n\n        - at_paths: Template search paths\n        - at_encoding: Template encoding\n        - at_engine: Specify the name of template engine to use explicitly or\n          None to find it automatically anyhow.\n        - at_cls_args: Arguments passed to instantiate template engine class\n        - other keyword arguments passed to the template engine to render\n          templates with specific features enabled.\n\n    :return: Rendered string\n    \"\"\"\n    if filepath == '-':\n        return _render(sys.stdin.read(), context=context, **options)\n\n    return _render(filepath=filepath, context=context, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender given template file and write the result string to given output.", "response": "def render_to(filepath, context=None, output=None,\n              at_encoding=anytemplate.compat.ENCODING, **options):\n    \"\"\"\n    Render given template file and write the result string to given `output`.\n    The result string will be printed to sys.stdout if output is None or '-'.\n\n    :param filepath: Template file path\n    :param context: A dict or dict-like object to instantiate given\n        template file\n    :param output: File path to write the rendered result string to or None/'-'\n        to print it to stdout\n    :param at_encoding: Template encoding\n    :param options: Optional keyword arguments such as:\n\n        - at_paths: Template search paths\n        - at_engine: Specify the name of template engine to use explicitly or\n          None to find it automatically anyhow.\n        - at_cls_args: Arguments passed to instantiate template engine class\n        - other keyword arguments passed to the template engine to render\n          templates with specific features enabled.\n    \"\"\"\n    res = render(filepath, context=context, **options)\n    anytemplate.utils.write_to_output(res, output, at_encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cable_page_by_id(reference_id):\n    global _CABLEID2MONTH\n    def wikileaks_id(reference_id):\n        if reference_id in consts.INVALID_CABLE_IDS.values():\n            for k, v in consts.INVALID_CABLE_IDS.iteritems():\n                if v == reference_id:\n                    return k\n        return reference_id\n\n    def wikileaks_url(wl_id):\n        m = _CABLEID2MONTH.get(wl_id)\n        if m is None:\n            return None\n        y = wl_id[:2]\n        y = u'19' + y if int(y) > 10 else u'20' + y\n        return u'https://wikileaks.org/cable/%s/%s/%s' % (y, m.zfill(2), wl_id)\n\n    if _CABLEID2MONTH is None:\n        with gzip.open(os.path.join(os.path.dirname(__file__), 'cable2month.csv.gz'), 'r') as f:\n            reader = csv.reader(f)\n            _CABLEID2MONTH = dict(reader)\n    wl_id = wikileaks_id(reference_id)\n    wl_url = wikileaks_url(wl_id)\n    if wl_url is None:\n        # The cable reference is not known, try to consult Cablegatesearch.\n        html = _fetch_url(_CGSN_BASE + wl_id)\n        m = _CGSN_WL_SOURCE_SEARCH(html)\n        wl_url = m.group(1) if m else None\n    if wl_url is None:\n        return None\n    return _fetch_url(wl_url)", "response": "Experimental : Returns the HTML page of the cable identified by reference_id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the provided CSV file and returns a generator with cables for each row.", "response": "def cables_from_csv(filename, predicate=None, encoding='utf-8'):\n    \"\"\"\\\n    Returns a generator with ``ICable`` instances.\n\n    Reads the provided CSV file and returns a cable for each row.\n\n    `filename`\n        Absolute path to a file to read the cables from.\n        The file must be a CSV file with the following columns:\n        <identifier>, <creation-date>, <reference-id>, <origin>, <classification-level>, <references-to-other-cables>, <header>, <body>\n        The delimiter must be a comma (``,``) and the content must be enclosed in double quotes (``\"``).\n    `predicate`\n        A predicate that is invoked for each cable reference identifier.\n        If the predicate evaluates to ``False`` the cable is ignored.\n        By default, all cables are used.\n        I.e. ``cables_from_csv('cables.csv', lambda r: r.startswith('09'))``\n        would return cables where the reference identifier starts with ``09``.\n    `encoding`\n        The file encoding (``UTF-8`` by default).\n    \"\"\"\n    return (cable_from_row(row) for row in rows_from_csv(filename, predicate, encoding))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rows_from_csv(filename, predicate=None, encoding='utf-8'):\n    pred = predicate or bool\n    with open(filename, 'rb') as f:\n        for row in _UnicodeReader(f, encoding=encoding, delimiter=',', quotechar='\"', escapechar='\\\\'):\n            ident, created, reference_id, origin, classification, references, header, body = row\n            if row and pred(reference_id):\n                yield ident, created, reference_id, origin, classification, references, header, body", "response": "\\ Returns an iterator over all rows in the provided CSV filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reference_id_parts(reference_id):\n    m = consts.REFERENCE_ID_PATTERN.match(reference_id)\n    if m:\n        return m.groups()\n    raise ValueError('Illegal reference identifier: \"%s\"' % reference_id)", "response": "\\ Returns a tuple of the parts of a Cable reference identifier or canonical identifier."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_content(content):\n    for pattern, subst in _CLEAN_PATTERNS:\n        content = pattern.sub(subst, content)\n    return content", "response": "Cleans the content of a cable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef titlefy(subject):\n    def clean_word(word):\n        return _APOS_PATTERN.sub(lambda m: u'%s%s%s' % (m.group(1), m.group(2) if not m.group(2) == ',' else u\"'\", m.group(3).lower()), word)\n    def titlefy_word(word):\n        if _is_number(word):\n            return word.lower()\n        if _TITLEFY_BIG_PATTERN.match(word):\n            return clean_word(word.upper())\n        return clean_word(_SPECIAL_WORDS.get(word, word.title()))\n    if not subject:\n        return None if subject is None else u''\n    res = []\n    append = res.append\n    wl = subject.strip().split()\n    append(titlefy_word(wl[0]))\n    for word in wl[1:]:\n        if _TITLEFY_SMALL_PATTERN.match(word):\n            if res[-1][-1] not in ':-':\n                if word == u'A' and res[-1] == u'and' and res[-2] == 'Q':\n                    # Q and A\n                    append(word.upper())\n                else:\n                    append(word.lower())\n            else:\n                append(titlefy_word(word))\n        else:\n            append(titlefy_word(word))\n    return u' '.join(res)", "response": "Titlecases the provided subject but respects common abbreviations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef oauth_scope(*scope_names):\n  authenticator = AccessTokenAuthenticator(required_scope_names=scope_names)\n\n  def scope_decorator(view_func):\n    @wraps(view_func)\n    def wrapper(request, *args, **kwargs):\n      access_token, error_response_arguments = authenticator.validate(request)\n\n      if not access_token:\n        return authenticator.make_error_response(*error_response_arguments)\n\n      return view_func(access_token, request, *args, **kwargs)\n\n    return wrapper\n\n  return scope_decorator", "response": "Decorator that restricts requests to those authorized with\n a certain scope or scopes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a Tweet object return a dict mapping field name to tokens.", "response": "def tokenize(self, tw):\n        \"\"\" Given a Tweet object, return a dict mapping field name to tokens. \"\"\"\n        toks = defaultdict(lambda: [])\n        for field in self.fields:\n            if '.' in field:\n                parts = field.split('.')\n                value = tw.js\n                for p in parts:\n                    value = value[p]\n            else:\n                value = tw.js[field]\n            toks[field].extend(self.do_tokenize(value))\n        return dict([(f, v) for f, v in toks.items()])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tokenize_fielded(self, tw):\n        toks = self.tokenize(tw)\n        for field, tokens in sorted(toks.items()):\n            for tok in tokens:\n                yield '%s___%s' % (field, tok)", "response": "Tokenize tweet and prepend field id before each token."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a base server based on the passed HttpService instance.", "response": "def server(service, log=None):\n    \"\"\"\n    Creates a threaded http service based on the passed HttpService instance.\n\n    The returned object can be watched via taskforce.poll(), select.select(), etc.\n    When activity is detected, the handle_request() method should be invoked.\n    This starts a thread to handle the request.  URL paths are handled with callbacks\n    which need to be established before any activity might occur.  If no callback\n    is registered for a given path, the embedded handler will report a 404 error.\n    Any exceptions raised by the callback result in a 500 error.\n\n    This function just instantiates either a TCPServer or UnixStreamServer based\n    on the address information in the \"host\" param.  The UnixStreamServer class\n    is used for addresses containing a \"/\", otherwise the TCPServer class is\n    used.  To create a Udom service in the current directory, use './name'.\n    If TCP is selected and no port is provided using the \":\" syntax, then\n    def_port or def_sslport  will be used as appropriate.\n\n    The BaseServer provides the code for registering HTTP handler callbacks.\n\n    Parameters:\n\n      service   - Service configuration.  See the HttpService class above.\n      log       - A 'logging' object to log errors and activity.\n\"\"\"\n    if log:\n        log = log\n    else:                                                                                       # pragma: no cover\n        log = logging.getLogger(__name__)\n        log.addHandler(logging.NullHandler())\n    if not service.timeout:                                                                     # pragma: no cover\n        service.timeout = None\n\n    if not service.listen:\n        service.listen = def_address\n\n    if service.listen.find('/') >=0 :\n        httpd = UnixStreamServer(service.listen, service.timeout, log)\n    else:\n        port = None\n        m = re.match(r'^(.*):(.*)$', service.listen)\n        if m:\n            log.debug(\"Matched host '%s', port '%s'\", m.group(1), m.group(2))\n            host = m.group(1)\n            try:\n                port = int(m.group(2))\n            except:\n                raise Exception(\"TCP listen port must be an integer\")\n        else:\n            host = service.listen\n            log.debug(\"No match, proceding with host '%s'\", host)\n        if not port:\n            port = def_sslport if service.certfile else def_port\n        httpd = TCPServer(host, port, service.timeout, log)\n    if service.certfile:\n        ciphers = ' '.join(ssl_ciphers)\n        ctx = None\n        try:\n            ctx = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\n        except AttributeError:                                                                  # pragma: no cover\n            log.warning(\"No ssl.SSLContext(), less secure connections may be allowed\")\n            pass\n        if ctx:\n            #  If ssl supports contexts, provide some tigher controls on the ssl negotiation\n            #\n            if 'OP_NO_SSLv2' in ssl.__dict__:\n                ctx.options |= ssl.OP_NO_SSLv2\n            else:                                                                               # pragma: no cover\n                log.warning(\"Implementation does not offer ssl.OP_NO_SSLv2 which may allow less secure connections\")\n            if 'OP_NO_SSLv3' in ssl.__dict__:\n                ctx.options |= ssl.OP_NO_SSLv3\n            else:                                                                               # pragma: no cover\n                log.warning(\"Implementation does not offer ssl.OP_NO_SSLv3 which may allow less secure connections\")\n            log.info(\"Certificate file: %s\", service.certfile)\n            with open(service.certfile, 'r') as f: pass\n            ctx.load_cert_chain(service.certfile)\n            ctx.set_ciphers(ciphers)\n            httpd.socket = ctx.wrap_socket(httpd.socket, server_side=True)\n        else:                                                                                   # pragma: no cover\n            httpd.socket = ssl.wrap_socket(httpd.socket, server_side=True,\n                certfile=service.certfile, ssl_version=ssl.PROTOCOL_TLSv1, ciphers=ciphers)\n    if service.allow_control:\n        httpd.allow_control = True\n    log.info(\"HTTP service %s\", str(service))\n    return httpd"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unicode(p):\n    q = {}\n    for tag in p:\n        vals = []\n        for v in p[tag]:\n            if type(v) is not str:                                                              # pragma: no cover\n                v = v.decode('utf-8')\n            vals.append(v)\n        if type(tag) is not str:                                                                # pragma: no cover\n            tag = tag.decode('utf-8')\n        q[tag] = vals\n    return q", "response": "Convert unicode to str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the query path of the URL to a dict.", "response": "def get_query(path, force_unicode=True):\n    \"\"\"\n    Convert the query path of the URL to a dict.\n    See _unicode regarding force_unicode.\n\"\"\"\n    u = urlparse(path)\n    if not u.query:\n        return {}\n    p = parse_qs(u.query)\n\n    if force_unicode:\n        p = _unicode(p)\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_query(path, postmap, force_unicode=True):\n    if postmap:\n        p = postmap.copy()\n    else:\n        p = {}\n    p.update(get_query(path, force_unicode=False))\n\n    if force_unicode:\n        p = _unicode(p)\n    return p", "response": "Merges params parsed from the URI into the POST body and returns a new dict with the values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating True if value looks like it is intended to be true.", "response": "def truthy(value):\n    \"\"\"\n    Evaluates True if \"value\" looks like it is intended to be true.  This translates\n    to an integer value greater than 0 or the first character starting with 'y'\n    or 't' (case independent).\n\"\"\"\n    if value is None or value == '':\n        return False\n    value = str(value)\n    try:\n        return (int(value) != 0)\n    except:\n        pass\n    return (truthy_true_yes.match(value) is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmp(self, other_service):\n        if not isinstance(other_service, HttpService):\n            return None\n        for att in dir(self):\n            if att == 'cmp' or att.startswith('_'):\n                continue\n            if not hasattr(other_service, att):\n                return None\n            if getattr(self, att) != getattr(other_service, att):\n                return False\n        return True", "response": "Compare with an instance of this object. Returns True if the object is comparable False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a regex for processing HTTP GET Taxonomy requests.", "response": "def register_get(self, regex, callback):\n        \"\"\"\n        Register a regex for processing HTTP GET\n        requests.  If the callback is None, any\n        existing registration is removed.\n    \"\"\"\n        if callback is None:                                                                    # pragma: no cover\n            if regex in self.get_registrations:\n                del self.get_registrations[regex]\n        else:\n            self.get_registrations[regex] = (re.compile(regex), callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a regex for processing HTTP POST requests.", "response": "def register_post(self, regex, callback):\n        \"\"\"\n        Register a regex for processing HTTP POST\n        requests.  If the callback is None, any\n        existing registration is removed.\n\n        The callback will be called as:\n\n            callback(path, postmap)\n    \"\"\"\n        if callback is None:                                                                    # pragma: no cover\n            if regex in self.post_registrations:\n                del self.post_registrations[regex]\n        else:\n            self.post_registrations[regex] = (re.compile(regex), callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serve_get(self, path, **params):\n        if path is None: return None\n\n        matched = self._match_path(path, self.get_registrations)\n        if matched is None:\n            return None\n        else:\n            return matched(path, **params)", "response": "Find a GET callback for the given HTTP path call it and return the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a POST callback for the given HTTP path, call it and return the results. The callback is called with the path used to match it, a dict of vars from the POST body and params which include the BaseHTTPRequestHandler instance. The callback must return a tuple: (code, content, content_type) If multiple registrations match the path, the one with the longest matching text will be used. Matches are always anchored at the start of the path. None is returned if no registered callback is willing to handle a path.", "response": "def serve_post(self, path, postmap, **params):\n        \"\"\"\n        Find a POST callback for the given HTTP path, call it and return\n        the results.  The callback is called with the path used to match\n        it, a dict of vars from the POST body and params which include the\n        BaseHTTPRequestHandler instance.\n\n        The callback must return a tuple:\n\n            (code, content, content_type)\n\n        If multiple registrations match the path, the one with the longest\n        matching text will be used.  Matches are always anchored at the start\n        of the path.\n\n        None is returned if no registered callback is willing to handle a path.\n    \"\"\"\n        matched = self._match_path(path, self.post_registrations)\n        if matched is None:                                                                     # pragma: no cover\n            return None\n        else:\n            return matched(path, postmap, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(**kwargs):\n    sensor = None\n    tick = 0\n    driver = DHTReader(**kwargs)\n    while not sensor and tick < TIME_LIMIT:\n        try:\n            sensor = driver.receive_data()\n        except DHTException:\n            tick += 1\n    return sensor", "response": "Get a single object from the DHT"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_url(url, extra_schemes={}):\n\n    if not url:\n        raise ValueError('url cannot be empty')\n\n    cls = None\n    res = urlsplit(url)\n\n    # check config first\n    if res.scheme in extra_schemes:\n        # TODO - nerge these with any existing and recurse\n        addr = extra_schemes[res.scheme]\n        if 'type' in addr:\n            cls = find_cls(res.scheme, extra_schemes)\n        if 'url' in addr:\n            url = addr['url']\n            if cls:\n                res = urlsplit(url)\n                return MungeURL(cls, res)\n            # TODO - nerge these with any existing and recurse\n            return parse_url(url)\n\n    if res.scheme:\n        cls = find_cls(res.scheme, extra_schemes)\n\n    # check file extension\n    if not cls:\n        (rest, sep, ext) = url.rpartition('.')\n        cls = find_cls(ext, extra_schemes)\n\n        if not cls:\n            raise ValueError('unable to find codec for %s' % url)\n\n    return MungeURL(cls, res)", "response": "parse a munge url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a nested value", "response": "def get_nested(self, *args):\n        \"\"\"\n        get a nested value, returns None if path does not exist\n        \"\"\"\n        data = self.data\n        for key in args:\n            if key not in data:\n                return None\n            data = data[key]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, config_dir=None, config_name=None, clear=False):\n\n# TODO should probably allow config_dir to be a list as well\n        # get name of config directory\n        if not config_dir:\n            config_dir = self._defaults.get('config_dir', None)\n        if not config_dir:\n            raise KeyError('config_dir not set')\n\n        # get name of config file\n        if not config_name:\n            config_name = self._defaults.get('config_name', None)\n        if not config_name:\n            raise KeyError('config_name not set')\n\n        conf_path = os.path.expanduser(config_dir)\n        if not os.path.exists(conf_path):\n            raise IOError(\"config dir not found at %s\" % (conf_path,))\n\n        config = munge.load_datafile(config_name, conf_path, default=None)\n\n        if not config:\n            raise IOError(\"config file not found in %s\" % (conf_path,))\n\n        if clear:\n            self.clear()\n\n        munge.util.recursive_update(self.data, config)\n        self._meta_config_dir = conf_path\n        return self", "response": "read the config from config_dir config_name clear if clear is True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry reading the entry - set in the specified directory", "response": "def try_read(self, config_dir=None, **kwargs):\n        \"\"\"\n        try reading without throwing an error\n        config_dir may be a list of directories to try in order, if so it\n        will return after the first successful read\n        other args will be passed direction to read()\n        \"\"\"\n        if isinstance(config_dir, basestring):\n            config_dir = (config_dir,)\n\n        for cdir in config_dir:\n            try:\n                self.read(cdir, **kwargs)\n                return cdir\n\n            except IOError as e:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, config_dir=None, config_name=None, codec=None):\n        # get name of config directory\n        if not config_dir:\n            config_dir = self._meta_config_dir\n            if not config_dir:\n                raise IOError(\"config_dir not set\")\n\n        # get name of config file\n        if not config_name:\n            config_name = self._defaults.get('config_name', None)\n        if not config_name:\n            raise KeyError('config_name not set')\n\n        if codec:\n            codec = munge.get_codec(codec)()\n        else:\n            codec = munge.get_codec(self._defaults['codec'])()\n\n        config_dir = os.path.expanduser(config_dir)\n        if not os.path.exists(config_dir):\n            os.mkdir(config_dir)\n\n        codec.dumpu(self.data, os.path.join(config_dir, 'config.' + codec.extension))", "response": "Writes the current state of the object to the config_dir using config_name\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_handler(self, *args, **options):\n        handler = get_internal_wsgi_application()\n        from django.contrib.staticfiles.handlers import StaticFilesHandler\n        return StaticFilesHandler(handler)", "response": "Returns the default WSGI handler for the runner."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating a certificate using this SSL Context", "response": "def validate_certificate(self, cert):\n        \"\"\"\n        Validate a certificate using this SSL Context\n        \"\"\"\n        store_ctx = X509.X509_Store_Context(_m2ext.x509_store_ctx_new(), _pyfree=1)\n        _m2ext.x509_store_ctx_init(store_ctx.ctx,\n                                   self.get_cert_store().store,\n                                   cert.x509, None)\n        rc = _m2ext.x509_verify_cert(store_ctx.ctx)\n        if rc < 0:\n            raise SSL.SSLError(\"Empty context\")\n        return rc != 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_iSet(Y, U_R=None, S_R=None, covs=None, Xr=None, n_perms=0, Ie=None,\n             strat=False, verbose=True):\n    \"\"\"\n    Args:\n        Y:          [N, P] phenotype matrix\n        S_R:        N vector of eigenvalues of R\n        U_R:        [N, N] eigenvector matrix of R\n        covs:       [N, K] matrix for K covariates\n        Xr:         [N, S] genotype data of the set component\n        n_perms:    number of permutations to consider\n        Ie:         N boolean context indicator\n        strat:      if True, the implementation with stratified designs is considered\n    \"\"\"\n    factr=1e7 # remove?\n    if strat:\n        assert Ie is not None, 'Ie must be specified for stratification analyses'\n        assert Y.shape[1]==1, 'Y must be Nx1 for stratification analysis'\n    else:\n        assert covs==None, 'Covariates are not supported for analysis of fully observed phenotypes'\n\n    if verbose:     print('fittng iSet')\n    if strat:\n        mtSetGxE = ISet_Strat(Y, Ie, Xr, covs=covs)\n        RV = {}\n        RV['null'] = mtSetGxE.fitNull()\n        RV['rank2'] = mtSetGxE.fitFullRank()\n        RV['rank1'] = mtSetGxE.fitLowRank()\n        RV['block'] = mtSetGxE.fitBlock()\n        RV['var'] = mtSetGxE.getVC()\n    else:\n        mtSetGxE = ISet_Full(Y=Y, S_R=S_R, U_R=U_R, Xr=Xr, factr=factr)\n        RV = {}\n        RV['null'] = mtSetGxE.fitNull()\n        RV['rank2'] = mtSetGxE.fitFullRank()\n        RV['rank1'] = mtSetGxE.fitLowRank()\n        LLR = RV['rank1']['NLLAlt'] - RV['rank2']['NLLAlt']\n        if LLR<-1e-6:\n            RV['rank2'] = mtSetGxE.fitFullRank(init_method='lr')\n        try:\n            RV['block'] = mtSetGxE.fitBlock()\n        except:\n            try:\n                RV['block'] = mtSetGxE.fitBlock(init_method='null')\n            except:\n                RV['block'] = mtSetGxE.fitBlock(init_method='null_no_opt')\n        RV['var'] = mtSetGxE.getVC()\n\n    if n_perms>0:\n        RVperm = {}\n        nulls = ['null', 'block', 'rank1']\n        tests = ['mtSet', 'iSet', 'iSet-het']\n        for test in tests:\n            RVperm[test+' LLR0'] = sp.zeros(n_perms)\n        for seed_i in range(n_perms):\n            if verbose:     print('permutation %d / %d' % (seed_i, n_perms))\n            for it, test in enumerate(tests):\n                if test=='mtSet':\n                    idxs = sp.random.permutation(Xr.shape[0])\n                    _Xr = Xr[idxs, :]\n                    df0 = fit_iSet(Y, U_R=U_R, S_R=S_R, covs=covs, Xr=_Xr, n_perms=0, Ie=Ie, strat=strat, verbose=False)\n                else:\n                    Y0 = mtSetGxE._sim_from(set_covar=nulls[it])\n                    Y0 -= Y0.mean(0)\n                    df0 = fit_iSet(Y0, U_R=U_R, S_R=S_R, covs=covs, Xr=Xr, n_perms=0, Ie=Ie, strat=strat, verbose=False)\n                RVperm[test+' LLR0'][seed_i]  = df0[test+' LLR'][0]\n\n    # output\n    LLR_mtSet = RV['null']['NLL']-RV['rank2']['NLL']\n    LLR_iSet = RV['block']['NLL']-RV['rank2']['NLL']\n    LLR_iSet_het = RV['rank1']['NLL']-RV['rank2']['NLL']\n\n    if strat:   var_keys = ['var_r_full', 'var_c', 'var_n']\n    else:       var_keys = ['var_r_full', 'var_g', 'var_n']\n    varT = sp.sum([RV['var'][key] for key in var_keys])\n    var_pers = RV['var']['var_r_block'] / varT\n    var_resc = (RV['var']['var_r_rank1'] - RV['var']['var_r_block']) / varT\n    var_het = (RV['var']['var_r_full'] - RV['var']['var_r_rank1']) / varT\n    conv = RV['null']['conv']\n    conv*= RV['block']['conv']\n    conv*= RV['rank1']['conv']\n    conv*= RV['rank2']['conv']\n\n    M = sp.array([LLR_mtSet, LLR_iSet, LLR_iSet_het, var_pers, var_resc, var_het, conv]).T\n    columns = ['mtSet LLR', 'iSet LLR', 'iSet-het LLR',\n                'Persistent Var', 'Rescaling-GxC Var', 'Heterogeneity-GxC var', 'Converged']\n    df = pd.DataFrame(M, columns=columns)\n\n    if n_perms>0:\n        return df, pd.DataFrame(RVperm)\n    return df", "response": "Fits the iSet of the current species to the set of species"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a document is a PDF file and return True if is is.", "response": "def is_pdf(document):\n    \"\"\"Check if a document is a PDF file and return True if is is.\"\"\"\n    if not executable_exists('pdftotext'):\n        current_app.logger.warning(\n            \"GNU file was not found on the system. \"\n            \"Switching to a weak file extension test.\"\n        )\n        if document.lower().endswith(\".pdf\"):\n            return True\n        return False\n\n    # Tested with file version >= 4.10. First test is secure and works\n    # with file version 4.25. Second condition is tested for file\n    # version 4.10.\n    file_output = os.popen('file ' + re.escape(document)).read()\n    try:\n        filetype = file_output.split(\":\")[-1]\n    except IndexError:\n        current_app.logger.error(\n            \"Your version of the 'file' utility seems to be unsupported.\"\n        )\n        raise IncompatiblePDF2Text('Incompatible pdftotext')\n\n    pdf = filetype.find(\"PDF\") > -1\n    # This is how it should be done however this is incompatible with\n    # file version 4.10.\n    # os.popen('file -bi ' + document).read().find(\"application/pdf\")\n    return pdf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef text_lines_from_local_file(document, remote=False):\n    try:\n        if is_pdf(document):\n            if not executable_exists(\"pdftotext\"):\n                current_app.logger.error(\n                    \"pdftotext is not available on the system.\"\n                )\n            cmd = \"pdftotext -q -enc UTF-8 %s -\" % re.escape(document)\n            out = subprocess.Popen([\"pdftotext\", \"-q\", \"-enc\", \"UTF-8\",\n                                    document, \"-\"],\n                                   universal_newlines=True,\n                                   stdout=subprocess.PIPE)\n            (stdoutdata, stderrdata) = out.communicate()\n            lines = stdoutdata.splitlines()\n            if not isinstance(stdoutdata, six.text_type):\n                # We are in Python 2. We need to cast to unicode\n                lines = [line.decode('utf8', 'replace') for line in lines]\n        else:\n            filestream = codecs.open(document, \"r\", encoding=\"utf8\",\n                                     errors=\"replace\")\n            # FIXME - we assume it is utf-8 encoded / that is not good\n            lines = [line for line in filestream]\n            filestream.close()\n    except IOError as ex1:\n        current_app.logger.error(\"Unable to read from file %s. (%s)\"\n                                 % (document, ex1.strerror))\n        return []\n\n    # Discard lines that do not contain at least one word.\n    return [line for line in lines if _ONE_WORD.search(line) is not None]", "response": "Return the fulltext of the local file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntest if an executable exists on the system.", "response": "def executable_exists(executable):\n    \"\"\"Test if an executable is available on the system.\"\"\"\n    for directory in os.getenv(\"PATH\").split(\":\"):\n        if os.path.exists(os.path.join(directory, executable)):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_plaintext_document_body(fpath, keep_layout=False):\n    textbody = []\n    status = 0\n    if os.access(fpath, os.F_OK | os.R_OK):\n        # filepath OK - attempt to extract references:\n        # get file type:\n        cmd_pdftotext = [\n            current_app.config.get(\"CLASSIFIER_PATH_GFILE\"), fpath\n        ]\n        pipe_pdftotext = subprocess.Popen(cmd_pdftotext,\n                                          stdout=subprocess.PIPE)\n        res_gfile = pipe_pdftotext.stdout.read()\n\n        if (res_gfile.lower().find(\"text\") != -1) and \\\n                (res_gfile.lower().find(\"pdf\") == -1):\n            # plain-text file: don't convert - just read in:\n            f = open(fpath, \"r\")\n            try:\n                textbody = [line.decode(\"utf-8\") for line in f.readlines()]\n            finally:\n                f.close()\n        elif (res_gfile.lower().find(\"pdf\") != -1) or \\\n                (res_gfile.lower().find(\"pdfa\") != -1):\n            # convert from PDF\n            (textbody, status) = convert_PDF_to_plaintext(fpath, keep_layout)\n        else:\n            # invalid format\n            status = 1\n    else:\n        # filepath not OK\n        status = 1\n    return (textbody, status)", "response": "Given a file - path to a full - text file return a list of unicode strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_PDF_to_plaintext(fpath, keep_layout=False):\n    if keep_layout:\n        layout_option = \"-layout\"\n    else:\n        layout_option = \"-raw\"\n    status = 0\n    doclines = []\n    # Pattern to check for lines with a leading page-break character.\n    # If this pattern is matched, we want to split the page-break into\n    # its own line because we rely upon this for trying to strip headers\n    # and footers, and for some other pattern matching.\n    p_break_in_line = re.compile(r'^\\s*\\f(.+)$', re.UNICODE)\n    # build pdftotext command:\n    cmd_pdftotext = [current_app.config.get(\"CLASSIFIER_PATH_PDFTOTEXT\"),\n                     layout_option, \"-q\",\n                     \"-enc\", \"UTF-8\", fpath, \"-\"]\n    current_app.logger.debug(\"* %s\" % ' '.join(cmd_pdftotext))\n    # open pipe to pdftotext:\n    pipe_pdftotext = subprocess.Popen(cmd_pdftotext, stdout=subprocess.PIPE)\n\n    # read back results:\n    for docline in pipe_pdftotext.stdout:\n        unicodeline = docline.decode(\"utf-8\")\n        # Check for a page-break in this line:\n        m_break_in_line = p_break_in_line.match(unicodeline)\n        if m_break_in_line is None:\n            # There was no page-break in this line. Just add the line:\n            doclines.append(unicodeline)\n        else:\n            # If there was a page-break character in the same line as some\n            # text, split it out into its own line so that we can later\n            # try to find headers and footers:\n            doclines.append(u\"\\f\")\n            doclines.append(m_break_in_line.group(1))\n\n    current_app.logger.debug(\n        \"* convert_PDF_to_plaintext found: %s lines of text\" % len(doclines)\n    )\n\n    # finally, check conversion result not bad:\n    if pdftotext_conversion_is_bad(doclines):\n        status = 2\n        doclines = []\n\n    return (doclines, status)", "response": "Convert a PDF file to text using pdftotext."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pdftotext_conversion_is_bad(txtlines):\n    # Numbers of 'words' and 'whitespaces' found in document:\n    numWords = numSpaces = 0\n    # whitespace character pattern:\n    p_space = re.compile(unicode(r'(\\s)'), re.UNICODE)\n    # non-whitespace 'word' pattern:\n    p_noSpace = re.compile(unicode(r'(\\S+)'), re.UNICODE)\n    for txtline in txtlines:\n        numWords = numWords + len(p_noSpace.findall(txtline.strip()))\n        numSpaces = numSpaces + len(p_space.findall(txtline.strip()))\n    if numSpaces >= (numWords * 3):\n        # Too many spaces - probably bad conversion\n        return True\n    else:\n        return False", "response": "Checks if conversion after pdftotext performs a bad conversion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread in similarity matrix cfile File containing the covariance matrix.", "response": "def readCovarianceMatrixFile(cfile,readCov=True,readEig=True):\n    \"\"\"\"\n    reading in similarity matrix\n\n    cfile   File containing the covariance matrix. The corresponding ID file must be specified in cfile.id)\n    \"\"\"\n    covFile = cfile+'.cov'\n    evalFile = cfile+'.cov.eval'\n    evecFile = cfile+'.cov.evec'\n\n    RV = {}\n    if readCov:\n        assert os.path.exists(covFile), '%s is missing.'%covFile\n        RV['K'] = SP.loadtxt(covFile)\n    if readEig:\n        assert os.path.exists(evalFile), '%s is missing.'%evalFile\n        assert os.path.exists(evecFile), '%s is missing.'%evecFile\n        RV['eval'] = SP.loadtxt(evalFile)\n        RV['evec'] = SP.loadtxt(evecFile)\n\n    return RV"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads in covariate file entric element - wise", "response": "def readCovariatesFile(fFile):\n    \"\"\"\"\n    reading in covariate file\n\n    cfile   file containing the fixed effects as NxP matrix\n            (N=number of samples, P=number of covariates)\n    \"\"\"\n    assert os.path.exists(fFile), '%s is missing.'%fFile\n    F = SP.loadtxt(fFile)\n    if F.ndim==1: F=F[:,SP.newaxis]\n    return F"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readPhenoFile(pfile,idx=None):\n\n    usecols = None\n    if idx!=None:\n        \"\"\" different traits are comma-seperated \"\"\"\n        usecols = [int(x) for x in idx.split(',')]\n        \n    phenoFile = pfile+'.phe'\n    assert os.path.exists(phenoFile), '%s is missing.'%phenoFile\n    Y = SP.loadtxt(phenoFile,usecols=usecols)\n    if (usecols is not None) and (len(usecols)==1): Y = Y[:,SP.newaxis]\n        \n    Y -= Y.mean(0); Y /= Y.std(0)\n    return Y", "response": "reading in phenotype file\nVIRTUAL"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread file with null model info nfile File containing null model info", "response": "def readNullModelFile(nfile):\n    \"\"\"\"\n    reading file with null model info\n\n    nfile   File containing null model info\n    \"\"\"\n\n    params0_file = nfile+'.p0'\n    nll0_file = nfile+'.nll0'\n    assert os.path.exists(params0_file), '%s is missing.'%params0_file\n    assert os.path.exists(nll0_file), '%s is missing.'%nll0_file\n    params = SP.loadtxt(params0_file)\n    NLL0 = SP.array([float(SP.loadtxt(nll0_file))])\n\n\n    if params.ndim==1:\n        rv = {'params0_g':SP.array([params[0]]),'params0_n':SP.array([params[1]]),'NLL0':NLL0}\n    else:\n        rv = {'params0_g':params[0],'params0_n':params[1],'NLL0':NLL0}\n\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads file with windows wfile File containing window info", "response": "def readWindowsFile(wfile):\n    \"\"\"\"\n    reading file with windows\n\n    wfile   File containing window info\n    \"\"\"\n    window_file = wfile+'.wnd'\n    assert os.path.exists(window_file), '%s is missing.'%window_file\n    rv = SP.loadtxt(window_file)\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the IRC colours from the start of the string and return the colour code in our format.", "response": "def extract_irc_colours(msg):\n    \"\"\"Extract the IRC colours from the start of the string.\n\n    Extracts the colours from the start, and returns the colour code in our\n    format, and then the rest of the message.\n    \"\"\"\n    # first colour\n    fore, msg = _extract_irc_colour_code(msg)\n\n    if not fore:\n        return '[]', msg\n    if not len(msg) or msg[0] != ',':\n        return '[{}]'.format(_ctos(fore)), msg\n\n    msg = msg[1:]  # strip comma\n\n    # second colour\n    back, msg = _extract_irc_colour_code(msg)\n\n    if back:\n        return '[{},{}]'.format(_ctos(fore), _ctos(back)), msg\n    else:\n        return '[{}]'.format(_ctos(fore)), ',' + msg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_girc_colours(msg, fill_last):\n    if not len(msg):\n        return '', ''\n\n    if ']' not in msg or not msg.startswith('['):\n        return '', msg\n\n    original_msg = msg\n\n    colours, msg = msg.split(']', 1)\n    colours = colours.lstrip('[')\n\n    if ',' in colours:\n        fore, back = colours.split(',')\n        if fore not in colour_name_to_code or back not in colour_name_to_code:\n            return '', original_msg\n        fore = colour_name_to_code[fore]\n        back = colour_name_to_code[back]\n        return '{},{}'.format(fore, back.zfill(2) if fill_last else back), msg\n    else:\n        if colours not in colour_name_to_code:\n            return '', original_msg\n        fore = colour_name_to_code[colours]\n        return '{}'.format(fore.zfill(2) if fill_last else fore), msg", "response": "Extract the girc - formatted colours from the start of the string and return the original string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a raw IRC message and returns a girc - escaped message.", "response": "def escape(msg):\n    \"\"\"Takes a raw IRC message and returns a girc-escaped message.\"\"\"\n    msg = msg.replace(escape_character, 'girc-escaped-character')\n    for escape_key, irc_char in format_dict.items():\n        msg = msg.replace(irc_char, escape_character + escape_key)\n\n    # convert colour codes\n    new_msg = ''\n    while len(msg):\n        if msg.startswith(escape_character + 'c'):\n            new_msg += msg[:2]\n            msg = msg[2:]\n\n            if not len(msg):\n                new_msg += '[]'\n                continue\n\n            colours, msg = extract_irc_colours(msg)\n            new_msg += colours\n        else:\n            new_msg += msg[0]\n            msg = msg[1:]\n\n    new_msg = new_msg.replace('girc-escaped-character', escape_character + escape_character)\n    return new_msg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_from_format_dict(format_dict, key):\n    if isinstance(format_dict[key], str):\n        return format_dict[key]\n    elif isinstance(format_dict[key], (list, tuple)):\n        fn_list = list(format_dict[key])\n        function = fn_list.pop(0)\n\n        if len(fn_list):\n            args = fn_list.pop(0)\n        else:\n            args = []\n\n        if len(fn_list):\n            kwargs = fn_list.pop(0)\n        else:\n            kwargs = {}\n\n        return function(*args, **kwargs)", "response": "Return a value from our format dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unescape(msg, extra_format_dict={}):\n    new_msg = ''\n\n    extra_format_dict.update(format_dict)\n\n    while len(msg):\n        char = msg[0]\n        msg = msg[1:]\n        if char == escape_character:\n            escape_key = msg[0]\n            msg = msg[1:]\n\n            # we handle this character separately, otherwise we mess up and\n            #   double escape characters while escaping and unescaping\n            if escape_key == escape_character:\n                new_msg += escape_character\n\n            elif escape_key == '{':\n                buf = ''\n                new_char = ''\n                while True:\n                    new_char = msg[0]\n                    msg = msg[1:]\n\n                    if new_char == '}':\n                        break\n                    else:\n                        buf += new_char\n\n                new_msg += _get_from_format_dict(extra_format_dict, buf)\n\n            else:\n                new_msg += _get_from_format_dict(extra_format_dict, escape_key)\n\n            if escape_key == 'c':\n                fill_last = len(msg) and msg[0] in digits\n                colours, msg = extract_girc_colours(msg, fill_last)\n                new_msg += colours\n        else:\n            new_msg += char\n\n    return new_msg", "response": "Takes a girc - escaped message and returns a raw IRC message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_formatting_codes(line, irc=False):\n    if irc:\n        line = escape(line)\n    new_line = ''\n    while len(line) > 0:\n        try:\n            if line[0] == '$':\n                line = line[1:]\n\n                if line[0] == '$':\n                    new_line += '$'\n                    line = line[1:]\n\n                elif line[0] == 'c':\n                    line = line[1:]\n                    if line[0].isdigit():\n                        line = line[1:]\n                        if line[0].isdigit():\n                            line = line[1:]\n                            if line[0] == ',':\n                                line = line[1:]\n                                if line[0].isdigit():\n                                    line = line[1:]\n                                    if line[0].isdigit():\n                                        line = line[1:]\n                        elif line[0] == ',':\n                            line = line[1:]\n                            if line[0].isdigit():\n                                line = line[1:]\n                                if line[0].isdigit():\n                                    line = line[1:]\n                    if line[0] == '[':\n                        while line[0] != ']':\n                            line = line[1:]\n                        line = line[1:]\n\n                elif line[0] == '{':\n                    if line[:3] == '{$}':\n                        new_line += '$'\n                        line = line[3:]\n                        continue\n                    while line[0] != '}':\n                        line = line[1:]\n                    line = line[1:]\n\n                else:\n                    line = line[1:]\n\n            else:\n                new_line += line[0]\n                line = line[1:]\n        except IndexError:\n            continue\n    return new_line", "response": "Remove girc control codes from the given line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getRegion(self,size=3e4,min_nSNPs=1,chrom_i=None,pos_min=None,pos_max=None):\n        if (self.chrom is None) or (self.pos is None):\n            bim = plink_reader.readBIM(self.bfile,usecols=(0,1,2,3))\n            chrom = SP.array(bim[:,0],dtype=int)\n            pos   = SP.array(bim[:,3],dtype=int)\n        else:\n            chrom = self.chrom\n            pos   = self.pos\n\n        if chrom_i is None:\n            n_chroms = chrom.max()\n            chrom_i  = int(SP.ceil(SP.rand()*n_chroms))\n\n        pos   = pos[chrom==chrom_i]\n        chrom = chrom[chrom==chrom_i]\n\n        ipos = SP.ones(len(pos),dtype=bool)\n        if pos_min is not None:\n            ipos = SP.logical_and(ipos,pos_min<pos)\n\n        if pos_max is not None:\n            ipos = SP.logical_and(ipos,pos<pos_max)\n\n        pos = pos[ipos]\n        chrom = chrom[ipos]\n\n        if size==1:\n            # select single SNP\n            idx = int(SP.ceil(pos.shape[0]*SP.rand()))\n            cis  = SP.arange(pos.shape[0])==idx\n            region = SP.array([chrom_i,pos[idx],pos[idx]])\n        else:\n            while 1:\n                idx = int(SP.floor(pos.shape[0]*SP.rand()))\n                posT1 = pos[idx]\n                posT2 = pos[idx]+size\n                if posT2<=pos.max():\n                    cis = chrom==chrom_i\n                    cis*= (pos>posT1)*(pos<posT2)\n                    if cis.sum()>min_nSNPs: break\n            region = SP.array([chrom_i,posT1,posT2])\n\n        start = SP.nonzero(cis)[0].min()\n        nSNPs  = cis.sum()\n\n        if self.X is None:\n            rv = plink_reader.readBED(self.bfile,useMAFencoding=True,start = start, nSNPs = nSNPs,bim=bim)\n            Xr = rv['snps']\n        else:\n            Xr = self.X[:,start:start+nSnps]\n\n        return Xr, region", "response": "Sample a region from the piece of genotype X chrom pos_min and pos_max."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the term for a set of SNPs in a region.", "response": "def genRegionTerm(self,X,vTot=0.1,pCausal=0.10,nCausal=None,pCommon=1.,nCommon=None,plot=False,distribution='biNormal'):\n        \"\"\"\n        Generate population structure term\n        Population structure is simulated by background SNPs\n\n        beta_pdf:        pdf used to generate the regression weights\n                          for now either Normal or fixed\n        variance:        variance of the term\n        percCausal:    percentage of causal SNPs\n        Xcausal:          set of SNPs being causal\n        \"\"\"\n        S = X.shape[1]\n\n        # number of causal, common, specific\n        if nCausal==None:\n            nCausal=int(SP.floor(pCausal*S))\n        if nCommon==None:\n            nCommon = round(pCommon*nCausal)\n        nSpecific = self.P*(nCausal-nCommon)\n\n        # common SNPs\n        if nCommon>0:\n            if distribution=='biNormal':\n                Bc  = SP.dot(genBinormal(nCommon,self.P),self.genTraitEffect(distribution=distribution))\n            elif distribution=='normal':\n                Bc  = SP.dot(self.genWeights(nCommon,self.P),self.genTraitEffect(distribution=distribution))\n            Ic  = selectRnd(nCommon,S)\n            Yc  = SP.dot(X[:,Ic],Bc)\n            Yc *= SP.sqrt(nCommon/Yc.var(0).mean())\n        else:\n\n            Yc = SP.zeros((self.N,self.P))\n\n        # indipendent signal\n        if nSpecific>0:\n            Is  = selectRnd(nSpecific,S*self.P).reshape(S,self.P)\n            if distribution=='biNormal':\n                Bi  = Is*genBinormal(S,self.P)\n            elif distribution=='normal':\n                Bi  = Is*SP.randn(S,self.P)\n            Yi  = SP.dot(X,Bi)\n            Yi *= SP.sqrt(nSpecific/(Yi.var(0).mean()*self.P))\n        else:\n            Yi = SP.zeros((self.N,self.P))\n\n\n        Y   = Yc+Yi\n        Yc *= SP.sqrt(vTot/Y.var(0).mean())\n        Yi *= SP.sqrt(vTot/Y.var(0).mean())\n\n        if plot:\n            import pylab as PL\n            PL.ion()\n            for p in range(self.P):\n                PL.subplot(self.P,1,p+1)\n                PL.plot(SP.arange(S)[Ic],Bc[:,p],'o',color='y')\n                _Is = Is[:,p]\n                if _Is.sum()>0:\n                    PL.plot(SP.arange(S)[_Is],Bi[_Is,p],'o',color='r')\n                #PL.ylim(-2,2)\n                PL.plot([0,S],[0,0],'k')\n\n        return Yc, Yi"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates bg term from a set of SNPs", "response": "def _genBgTerm_fromSNPs(self,vTot=0.5,vCommon=0.1,pCausal=0.5,plot=False):\n        \"\"\" generate  \"\"\"\n\n        if self.X is None:\n            print('Reading in all SNPs. This is slow.')\n            rv = plink_reader.readBED(self.bfile,useMAFencoding=True)\n            X  = rv['snps']\n        else:\n            X  = self.X\n\n        S  = X.shape[1]\n        vSpecific = vTot-vCommon\n\n        # select causal SNPs\n        nCausal = int(SP.floor(pCausal*S))\n        Ic = selectRnd(nCausal,S)\n        X = X[:,Ic]\n\n        # common effect\n        Bc  = SP.dot(self.genWeights(nCausal,self.P),self.genTraitEffect())\n        Yc  = SP.dot(X,Bc)\n        Yc *= SP.sqrt(vCommon/Yc.var(0).mean())\n\n        # indipendent effect\n        Bi  = SP.randn(nCausal,self.P)\n        Yi  = SP.dot(X,Bi)\n        Yi *= SP.sqrt(vSpecific/Yi.var(0).mean())\n\n        if plot:\n            import pylab as PL\n            PL.ion()\n            for p in range(self.P):\n                PL.subplot(self.P,1,p+1)\n                PL.plot(SP.arange(self.X.shape[1])[Ic],Bc[:,p],'o',color='y',alpha=0.05)\n                PL.plot(SP.arange(self.X.shape[1])[Ic],Bi[:,p],'o',color='r',alpha=0.05)\n                #PL.ylim(-2,2)\n                PL.plot([0,Ic.shape[0]],[0,0],'k')\n\n        return Yc, Yi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate background term from SNPs and XX.", "response": "def _genBgTerm_fromXX(self,vTot,vCommon,XX,a=None,c=None):\n        \"\"\"\n        generate background term from SNPs\n\n        Args:\n            vTot: variance of Yc+Yi\n            vCommon: variance of Yc\n            XX: kinship matrix\n            a: common scales, it can be set for debugging purposes\n            c: indipendent scales, it can be set for debugging purposes\n        \"\"\"\n        vSpecific = vTot-vCommon\n\n        SP.random.seed(0)\n        if c==None: c = SP.randn(self.P)\n        XX += 1e-3 * SP.eye(XX.shape[0])\n        L = LA.cholesky(XX,lower=True)\n\n        # common effect\n        R = self.genWeights(self.N,self.P)\n        A = self.genTraitEffect()\n        if a is not None: A[0,:] = a\n        Yc = SP.dot(L,SP.dot(R,A))\n        Yc*= SP.sqrt(vCommon)/SP.sqrt(Yc.var(0).mean())\n\n        # specific effect\n        R = SP.randn(self.N,self.P)\n        Yi = SP.dot(L,SP.dot(R,SP.diag(c)))\n        Yi*= SP.sqrt(vSpecific)/SP.sqrt(Yi.var(0).mean())\n\n        return Yc, Yi"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating \u00e9tuput background term", "response": "def genBgTerm(self,vTot=0.5,vCommon=0.1,pCausal=0.5,XX=None,use_XX=False,a=None,c=None,plot=False):\n        \"\"\" generate  \"\"\"\n        if use_XX:\n            if XX is None:  XX = self.XX\n            assert XX is not None, 'Simulator: set XX!'\n            Yc,Yi = self._genBgTerm_fromXX(vTot,vCommon,XX,a=a,c=c)\n        else:\n            Yc,Yi = self._genBgTerm_fromSNPs(vTot=vTot,vCommon=vCommon,pCausal=pCausal,plot=plot)\n        return Yc, Yi"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef genHidden(self,nHidden=10,vTot=0.5,vCommon=0.1):\n\n        vSpecific = vTot-vCommon\n\n        # generate hidden\n        X = self.genWeights(self.N,nHidden)\n\n        # common effect\n        H = self.genWeights(nHidden,self.P)\n        Bc = SP.dot(H,self.genTraitEffect())\n        Yc  = SP.dot(X,Bc)\n        Yc *= SP.sqrt(vCommon/Yc.var(0).mean())\n\n        # indipendent effect\n        Bi  = SP.randn(nHidden,self.P)\n        Yi  = SP.dot(X,Bi)\n        Yi *= SP.sqrt(vSpecific/Yi.var(0).mean())\n\n        return Yc,Yi", "response": "generate hidden and indipendent effects"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef realtime_comment_classifier(sender, instance, created, **kwargs):\n    # Only classify if newly created.\n    if created:\n        moderator_settings = getattr(settings, 'MODERATOR', None)\n        if moderator_settings:\n            if 'REALTIME_CLASSIFICATION' in moderator_settings:\n                if not moderator_settings['REALTIME_CLASSIFICATION']:\n                    return\n\n        # Only classify if not a reply comment.\n        if not getattr(instance, 'is_reply_comment', False):\n            from moderator.utils import classify_comment\n            classify_comment(instance)", "response": "Classifies a comment after it has been created."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_benchmark(monitor):\n    '''Run the benchmarks\n    '''\n    url = urlparse(monitor.cfg.test_url)\n    name = slugify(url.path) or 'home'\n    name = '%s_%d.csv' % (name, monitor.cfg.workers)\n    monitor.logger.info('WRITING RESULTS ON \"%s\"', name)\n    total = REQUESTS//monitor.cfg.workers\n\n    with open(name, 'w') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=FIELDNAMES)\n        writer.writeheader()\n        for pool_size in POOL_SIZES:\n            size = pool_size//monitor.cfg.workers\n            if size*monitor.cfg.workers != pool_size:\n                monitor.logger.error('Adjust workes so that pool sizes '\n                                     'can be evenly shared across them')\n                monitor._loop.stop()\n\n            # WORMUP\n            requests = [monitor.send(worker, 'run', wormup, size, total) for\n                        worker in monitor.managed_actors]\n            yield from wait(requests)\n\n            # BENCHMARK\n            requests = [monitor.send(worker, 'run', bench) for\n                        worker in monitor.managed_actors]\n            results, pending = yield from wait(requests)\n            assert not pending, 'Pending requets!'\n            results = [r.result() for r in results]\n\n            summary = {'concurrency': pool_size}\n            for name in results[0]:\n                summary[name] = reduce(add(name), results, 0)\n            writer.writerow(summary)\n\n            persec = summary['requests']/summary['time']\n            monitor.logger.info('%d concurrency - %d requests - '\n                                '%d errors - %.3f seconds - '\n                                '%.2f requests/sec',\n                                pool_size,\n                                summary['requests'],\n                                summary['errors'],\n                                summary['time'],\n                                persec)", "response": "Run the benchmarks\notope"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfill database with random number of worlds and fortune models.", "response": "def filldb(self):\n        '''Fill database\n        '''\n        from app import World, Fortune, odm, MAXINT\n\n        mapper = odm.Mapper(self.cfg.postgresql)\n        mapper.register(World)\n        mapper.register(Fortune)\n        mapper.table_create()\n\n        with mapper.begin() as session:\n            query = session.query(mapper.world)\n            N = query.count()\n            todo = max(0, MAXINT - N)\n            if todo:\n                for _ in range(todo):\n                    world = mapper.world(randomNumber=randint(1, MAXINT))\n                    session.add(world)\n\n        if todo:\n            odm.logger.info('Created %d World models', todo)\n        else:\n            odm.logger.info('%d World models already available', N)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator that walks the directory tree for files using given filters.", "response": "def files_walker(directory, filters_in=None, filters_out=None, flags=0):\n    \"\"\"\n    Defines a generator used to walk files using given filters.\n\n    Usage::\n\n        >>> for file in files_walker(\"./foundations/tests/tests_foundations/resources/standard/level_0\"):\n        ...     print(file)\n        ...\n        ./foundations/tests/tests_foundations/resources/standard/level_0/level_1/level_2/standard.sIBLT\n        ./foundations/tests/tests_foundations/resources/standard/level_0/level_1/lorem_ipsum.txt\n        ./foundations/tests/tests_foundations/resources/standard/level_0/level_1/standard.rc\n        ./foundations/tests/tests_foundations/resources/standard/level_0/standard.ibl\n        >>> for file in files_walker(\"./foundations/tests/tests_foundations/resources/standard/level_0\", (\"\\.sIBLT\",)):\n        ...     print(file)\n        ...\n        ./foundations/tests/tests_foundations/resources/standard/level_0/level_1/level_2/standard.sIBLT\n\n    :param directory: Directory to recursively walk.\n    :type directory: unicode\n    :param filters_in: Regex filters in list.\n    :type filters_in: tuple or list\n    :param filters_in: Regex filters out list.\n    :type filters_in: tuple or list\n    :param flags: Regex flags.\n    :type flags: int\n    :return: File.\n    :rtype: unicode\n    \"\"\"\n\n    if filters_in:\n        LOGGER.debug(\"> Current filters in: '{0}'.\".format(filters_in))\n\n    if filters_out:\n        LOGGER.debug(\"> Current filters out: '{0}'.\".format(filters_out))\n\n    for parent_directory, directories, files in os.walk(directory, topdown=False, followlinks=True):\n        for file in files:\n            LOGGER.debug(\"> Current file: '{0}' in '{1}'.\".format(file, directory))\n            path = foundations.strings.to_forward_slashes(os.path.join(parent_directory, file))\n            if os.path.isfile(path):\n                if not foundations.strings.filter_words((path,), filters_in, filters_out, flags):\n                    continue\n\n                LOGGER.debug(\"> '{0}' file filtered in!\".format(path))\n\n                yield path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a generator that yields all the directories and files in a given directory.", "response": "def depth_walker(directory, maximum_depth=1):\n    \"\"\"\n    Defines a generator used to walk into directories using given maximum depth.\n\n    Usage::\n\n        >>> for item in depth_walker(\"./foundations/tests/tests_foundations/resources/standard/level_0\"):\n        ...     print(item)\n        ...\n        (u'./foundations/tests/tests_foundations/resources/standard/level_0', [u'level_1'], [u'standard.ibl'])\n        (u'./foundations/tests/tests_foundations/resources/standard/level_0/level_1', [u'level_2'], [u'lorem_ipsum.txt', u'standard.rc'])\n        >>> for item in depth_walker(tests_foundations, 2):\n        ...     print(item)\n        ...\n        (u'./foundations/tests/tests_foundations/resources/standard/level_0', [u'level_1'], [u'standard.ibl'])\n        (u'./foundations/tests/tests_foundations/resources/standard/level_0/level_1', [u'level_2'], [u'lorem_ipsum.txt', u'standard.rc'])\n        (u'./foundations/tests/tests_foundations/resources/standard/level_0/level_1/level_2', [], [u'standard.sIBLT'])\n\n    :param directory: Directory to walk.\n    :type directory: unicode\n    :param maximum_depth: Maximum depth.\n    :type maximum_depth: int\n    :return: Parent directory, directories, files.\n    :rtype: tuple\n    \"\"\"\n\n    separator = os.path.sep\n    base_depth = directory.count(separator)\n\n    for parent_directory, directories, files in os.walk(directory):\n        yield parent_directory, directories, files\n        if base_depth + maximum_depth <= parent_directory.count(separator):\n            del directories[:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndefines a generator used to walk into nested dictionaries. Usage:: >>> nested_dictionary = {\"Level 1A\":{\"Level 2A\": { \"Level 3A\" : \"Higher Level\"}}, \"Level 1B\" : \"Lower level\"} >>> dictionaries_walker(nested_dictionary) <generator object dictionaries_walker at 0x10131a320> >>> for value in dictionaries_walker(nested_dictionary): ... print value (('Level 1A', 'Level 2A'), 'Level 3A', 'Higher Level') ((), 'Level 1B', 'Lower level') :param dictionary: Dictionary to walk. :type dictionary: dict :param path: Walked paths. :type path: tuple :return: Path, key, value. :rtype: tuple :note: This generator won't / can't yield any dictionaries, if you want to be able to retrieve dictionaries anyway, you will have to either encapsulate them in another object, or mutate their base class.", "response": "def dictionaries_walker(dictionary, path=()):\n    \"\"\"\n    Defines a generator used to walk into nested dictionaries.\n\n    Usage::\n\n        >>> nested_dictionary = {\"Level 1A\":{\"Level 2A\": { \"Level 3A\" : \"Higher Level\"}}, \"Level 1B\" : \"Lower level\"}\n        >>> dictionaries_walker(nested_dictionary)\n        <generator object dictionaries_walker at 0x10131a320>\n        >>> for value in dictionaries_walker(nested_dictionary):\n        ...\tprint value\n        (('Level 1A', 'Level 2A'), 'Level 3A', 'Higher Level')\n        ((), 'Level 1B', 'Lower level')\n\n    :param dictionary: Dictionary to walk.\n    :type dictionary: dict\n    :param path: Walked paths.\n    :type path: tuple\n    :return: Path, key, value.\n    :rtype: tuple\n\n    :note: This generator won't / can't yield any dictionaries, if you want to be able to retrieve dictionaries anyway,\n        you will have to either encapsulate them in another object, or mutate their base class.\n    \"\"\"\n\n    for key in dictionary:\n        if not isinstance(dictionary[key], dict):\n            yield path, key, dictionary[key]\n        else:\n            for value in dictionaries_walker(dictionary[key], path + (key,)):\n                yield value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nodes_walker(node, ascendants=False):\n\n    attribute = \"children\" if not ascendants else \"parent\"\n    if not hasattr(node, attribute):\n        return\n\n    elements = getattr(node, attribute)\n    elements = elements if isinstance(elements, list) else [elements]\n\n    for element in elements:\n        yield element\n\n        if not hasattr(element, attribute):\n            continue\n\n        if not getattr(element, attribute):\n            continue\n\n        for sub_element in nodes_walker(element, ascendants=ascendants):\n            yield sub_element", "response": "A generator that yields nodes in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the gradient of the log marginal likelihood for the given hyperparameters", "response": "def LMLgrad(self,params=None):\n        \"\"\"\n        evaluates the gradient of the log marginal likelihood for the given hyperparameters\n        \"\"\"\n        if params is not None:\n            self.setParams(params)\n        KV = self._update_cache()\n        W = KV['W']\n        LMLgrad = SP.zeros(self.covar.n_params)\n        for i in range(self.covar.n_params):\n            Kd = self.covar.Kgrad_param(i)\n            LMLgrad[i] = 0.5 * (W*Kd).sum()\n        return {'covar':LMLgrad}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_cache(self):\n        cov_params_have_changed = self.covar.params_have_changed\n\n        if cov_params_have_changed or self.Y_has_changed:\n            K = self.covar.K()\n            L = LA.cholesky(K).T# lower triangular\n            Kinv = LA.cho_solve((L,True),SP.eye(L.shape[0]))\n            alpha = LA.cho_solve((L,True),self.Y)\n            W = self.t*Kinv - SP.dot(alpha,alpha.T)\n            self._covar_cache = {}\n            self._covar_cache['K'] = K\n            self._covar_cache['Kinv'] = Kinv\n            self._covar_cache['L'] = L\n            self._covar_cache['alpha'] = alpha\n            self._covar_cache['W'] = W\n\n        return self._covar_cache", "response": "Update the internal _covar_cache dictionary with the current values of the keys K and Kinv and W."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the gradient of the class", "response": "def checkGradient(self,h=1e-6,verbose=True):\n        \"\"\" utility function to check the gradient of the gp \"\"\"\n        grad_an = self.LMLgrad()\n        grad_num = {}\n        params0 = self.params.copy()\n        for key in list(self.params.keys()):\n            paramsL = params0.copy()\n            paramsR = params0.copy()\n            grad_num[key] = SP.zeros_like(self.params[key])\n            e = SP.zeros(self.params[key].shape[0])\n            for i in range(self.params[key].shape[0]):\n                e[i] = 1\n                paramsL[key]=params0[key]-h*e\n                paramsR[key]=params0[key]+h*e\n                lml_L = self.LML(paramsL)\n                lml_R = self.LML(paramsR)\n                grad_num[key][i] = (lml_R-lml_L)/(2*h)\n                e[i] = 0\n            if verbose:\n                print(('%s:'%key))\n                print((abs(grad_an[key]-grad_num[key])))\n                print('')\n        self.setParams(params0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring a bots. yaml file for a specific user and app.", "response": "def configure(screen_name=None, config_file=None, app=None, **kwargs):\n    \"\"\"\n    Set up a config dictionary using a bots.yaml config file and optional keyword args.\n\n    Args:\n        screen_name (str): screen_name of user to search for in config file\n        config_file (str): Path to read for the config file\n        app (str): Name of the app to look for in the config file. Defaults to the one set in users.{screen_name}.\n        default_directories (str): Directories to read for the bots.yaml/json file. Defaults to CONFIG_DIRS.\n        default_bases (str): File names to look for in the directories. Defaults to CONFIG_BASES.\n    \"\"\"\n    # Use passed config file, or look for it in the default path.\n    # Super-optionally, accept a different place to look for the file\n    dirs = kwargs.pop('default_directories', None)\n    bases = kwargs.pop('default_bases', None)\n    file_config = {}\n    if config_file is not False:\n        config_file = find_file(config_file, dirs, bases)\n        file_config = parse(config_file)\n\n    # config and keys dicts\n    # Pull non-authentication settings from the file.\n    # Kwargs, user, app, and general settings are included, in that order of preference\n    # Exclude apps and users sections from config\n    config = {k: v for k, v in file_config.items() if k not in ('apps', 'users')}\n\n    user_conf = file_config.get('users', {}).get(screen_name, {})\n    app = app or user_conf.get('app')\n    app_conf = file_config.get('apps', {}).get(app, {})\n\n    # Pull user and app data from the file\n    config.update(app_conf)\n    config.update(user_conf)\n\n    # kwargs take precendence over config file\n    config.update({k: v for k, v in kwargs.items() if v is not None})\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(file_path):\n    '''Parse a YAML or JSON file.'''\n\n    _, ext = path.splitext(file_path)\n\n    if ext in ('.yaml', '.yml'):\n        func = yaml.load\n\n    elif ext == '.json':\n        func = json.load\n\n    else:\n        raise ValueError(\"Unrecognized config file type %s\" % ext)\n\n    with open(file_path, 'r') as f:\n        return func(f)", "response": "Parse a YAML or JSON file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_file(config_file=None, default_directories=None, default_bases=None):\n    '''Search for a config file in a list of files.'''\n\n    if config_file:\n        if path.exists(path.expanduser(config_file)):\n            return config_file\n        else:\n            raise FileNotFoundError('Config file not found: {}'.format(config_file))\n\n    dirs = default_directories or CONFIG_DIRS\n    dirs = [getcwd()] + dirs\n\n    bases = default_bases or CONFIG_BASES\n\n    for directory, base in product(dirs, bases):\n        filepath = path.expanduser(path.join(directory, base))\n        if path.exists(filepath):\n            return filepath\n\n    raise FileNotFoundError('Config file not found in {}'.format(dirs))", "response": "Search for a config file in a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting up Tweepy authentication using passed args or config file settings.", "response": "def setup_auth(**keys):\n    '''Set up Tweepy authentication using passed args or config file settings.'''\n    auth = tweepy.OAuthHandler(consumer_key=keys['consumer_key'], consumer_secret=keys['consumer_secret'])\n    auth.set_access_token(\n        key=keys.get('token', keys.get('key', keys.get('oauth_token'))),\n        secret=keys.get('secret', keys.get('oauth_secret'))\n    )\n    return auth"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_engines_by_priority(engines=None):\n    if engines is None:\n        engines = ENGINES\n\n    return sorted(engines, key=operator.methodcaller(\"priority\"))", "response": "Return a list of engines supported by each priority."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_by_filename(filename=None, engines=None):\n    if engines is None:\n        engines = ENGINES\n\n    if filename is None:\n        return list_engines_by_priority(engines)\n\n    return sorted((e for e in engines if e.supports(filename)),\n                  key=operator.methodcaller(\"priority\"))", "response": "Find a list of template engines that support a given template file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_by_name(name, engines=None):\n    if engines is None:\n        engines = ENGINES\n\n    for egn in engines:\n        if egn.name() == name:\n            return egn\n\n    return None", "response": "Find a template engine class specified by its name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap for tweepy. api. update_status with a 10s wait when twitter is over capacity", "response": "def update_status(self, *pargs, **kwargs):\n        \"\"\"\n        Wrapper for tweepy.api.update_status with a 10s wait when twitter is over capacity\n        \"\"\"\n        try:\n            return super(API, self).update_status(*pargs, **kwargs)\n\n        except tweepy.TweepError as e:\n            if getattr(e, 'api_code', None) == 503:\n                sleep(10)\n                return super(API, self).update_status(*pargs, **kwargs)\n            else:\n                raise e"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a file to twitter", "response": "def media_upload(self, filename, *args, **kwargs):\n        \"\"\" :reference: https://dev.twitter.com/rest/reference/post/media/upload\n            :reference https://dev.twitter.com/rest/reference/post/media/upload-chunked\n            :allowed_param:\n        \"\"\"\n        f = kwargs.pop('file', None)\n\n        mime, _ = mimetypes.guess_type(filename)\n        size = getfilesize(filename, f)\n\n        if mime in IMAGE_MIMETYPES and size < self.max_size_standard:\n            return self.image_upload(filename, file=f, *args, **kwargs)\n\n        elif mime in CHUNKED_MIMETYPES:\n            return self.upload_chunked(filename, file=f, *args, **kwargs)\n\n        else:\n            raise TweepError(\"Can't upload media with mime type %s\" % mime)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads a file to the twitter API.", "response": "def upload_chunked(self, filename, *args, **kwargs):\n        \"\"\" :reference https://dev.twitter.com/rest/reference/post/media/upload-chunked\n            :allowed_param:\n        \"\"\"\n        f = kwargs.pop('file', None)\n\n        # Media category is dependant on whether media is attached to a tweet\n        # or to a direct message. Assume tweet by default.\n        is_direct_message = kwargs.pop('is_direct_message', False)\n\n        # Initialize upload (Twitter cannot handle videos > 15 MB)\n        headers, post_data, fp = API._chunk_media('init', filename, self.max_size_chunked, form_field='media', f=f, is_direct_message=is_direct_message)\n        kwargs.update({'headers': headers, 'post_data': post_data})\n\n        # Send the INIT request\n        media_info = bind_api(\n            api=self,\n            path='/media/upload.json',\n            method='POST',\n            payload_type='media',\n            allowed_param=[],\n            require_auth=True,\n            upload_api=True\n        )(*args, **kwargs)\n\n        # If a media ID has been generated, we can send the file\n        if media_info.media_id:\n            # default chunk size is 1MB, can be overridden with keyword argument.\n            # minimum chunk size is 16K, which keeps the maximum number of chunks under 999\n            chunk_size = kwargs.pop('chunk_size', 1024 * 1024)\n            chunk_size = max(chunk_size, 16 * 2014)\n\n            fsize = getfilesize(filename, f)\n            nloops = int(fsize / chunk_size) + (1 if fsize % chunk_size > 0 else 0)\n            for i in range(nloops):\n                headers, post_data, fp = API._chunk_media('append', filename, self.max_size_chunked, chunk_size=chunk_size, f=fp, media_id=media_info.media_id, segment_index=i, is_direct_message=is_direct_message)\n                kwargs.update({ 'headers': headers, 'post_data': post_data, 'parser': RawParser() })\n                # The APPEND command returns an empty response body\n                bind_api(\n                    api=self,\n                    path='/media/upload.json',\n                    method='POST',\n                    payload_type='media',\n                    allowed_param=[],\n                    require_auth=True,\n                    upload_api=True\n                )(*args, **kwargs)\n            # When all chunks have been sent, we can finalize.\n            headers, post_data, fp = API._chunk_media('finalize', filename, self.max_size_chunked, media_id=media_info.media_id, is_direct_message=is_direct_message)\n            kwargs = {'headers': headers, 'post_data': post_data}\n\n            # The FINALIZE command returns media information\n            return bind_api(\n                api=self,\n                path='/media/upload.json',\n                method='POST',\n                payload_type='media',\n                allowed_param=[],\n                require_auth=True,\n                upload_api=True\n            )(*args, **kwargs)\n        else:\n            return media_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_media_category(is_direct_message, file_type):\n        if is_direct_message:\n            prefix = 'dm'\n        else:\n            prefix = 'tweet'\n\n        if file_type in IMAGE_MIMETYPES:\n            if file_type == 'image/gif':\n                return prefix + '_gif'\n            else:\n                return prefix + '_image'\n        elif file_type == 'video/mp4':\n            return prefix + '_video'", "response": "returns the media category name based on the file type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, url, mode='r', stdio=True):\n        # doesn't need to use config, because the object is already created\n        res = urlsplit(url)\n\n        if not res.scheme:\n            if not res.path or res.path == '-':\n                if not stdio:\n                    raise IOError(\"unable to open '%s'\" % (url,))\n\n                if 'w' in mode:\n                    return sys.stdout\n                return sys.stdin\n\n            return open(res.path, mode)\n\n        if res.scheme in ('https', 'http', 'ftp'):\n            req = requests.get(res.geturl(), stream=True)\n            # TODO error check\n            return req.raw\n            #return urllib2.urlopen(res.geturl())\n\n        raise IOError(\"unable to open '%s'\" % (url,))", "response": "opens a file or file based on the given URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadu(self, url, **kwargs):\n        return self.load(self.open(url, **kwargs), **kwargs)", "response": "Opens url and passes to load"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dumpu(self, data, url, **kwargs):\n        return self.dump(data, self.open(url, 'w', **kwargs), **kwargs)", "response": "Dump data to a file in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_end_of_reference_section(docbody,\n                                  ref_start_line,\n                                  ref_line_marker,\n                                  ref_line_marker_ptn):\n    \"\"\"Find end of reference section.\n\n    Given that the start of a document's reference section has already been\n    recognised, this function is tasked with finding the line-number in the\n    document of the last line of the reference section.\n\n    @param docbody: (list) of strings - the entire plain-text document body.\n    @param ref_start_line: (integer) - the index in docbody of the first line\n    of the reference section.\n    @param ref_line_marker: (string) - the line marker of the first reference\n    line.\n    @param ref_line_marker_ptn: (string) - the pattern used to search for a\n    reference line marker.\n    @return: (integer) - index in docbody of the last reference line\n     -- OR --\n            (None) - if ref_start_line was invalid.\n    \"\"\"\n    section_ended = False\n    x = ref_start_line\n    if type(x) is not int or x < 0 or x > len(docbody) or len(docbody) < 1:\n        # The provided 'first line' of the reference section was invalid.\n        # Either it was out of bounds in the document body, or it was not a\n        # valid integer.\n        # Can't safely find end of refs with this info - quit.\n        return None\n    # Get patterns for testing line:\n    t_patterns = get_post_reference_section_title_patterns()\n    kw_patterns = get_post_reference_section_keyword_patterns()\n\n    if None not in (ref_line_marker, ref_line_marker_ptn):\n        mk_patterns = [re.compile(ref_line_marker_ptn, re.I | re.UNICODE)]\n    else:\n        mk_patterns = get_reference_line_numeration_marker_patterns()\n\n    current_reference_count = 0\n    while x < len(docbody) and not section_ended:\n        # save the reference count\n        num_match = regex_match_list(docbody[x].strip(), mk_patterns)\n        if num_match:\n            try:\n                current_reference_count = int(num_match.group('marknum'))\n            except (ValueError, IndexError):\n                # non numerical references marking\n                pass\n        # look for a likely section title that would follow a reference section\n        end_match = regex_match_list(docbody[x].strip(), t_patterns)\n        if not end_match:\n            # didn't match a section title - try looking for keywords that\n            # suggest the end of a reference section:\n            end_match = regex_match_list(docbody[x].strip(), kw_patterns)\n        else:\n            # Is it really the end of the reference section? Check within the\n            # next 5 lines for other reference numeration markers:\n            y = x + 1\n            line_found = False\n            while y < x + 200 and y < len(docbody) and not line_found:\n                num_match = regex_match_list(docbody[y].strip(), mk_patterns)\n                if num_match and not num_match.group(0).isdigit():\n                    try:\n                        num = int(num_match.group('marknum'))\n                        if current_reference_count + 1 == num:\n                            line_found = True\n                    except ValueError:\n                        # We have the marknum index so it is\n                        # numeric pattern for references like\n                        # [1], [2] but this match is not a number\n                        pass\n                    except IndexError:\n                        # We have a non numerical references marking\n                        # we don't check for a number continuity\n                        line_found = True\n                y += 1\n            if not line_found:\n                # No ref line found-end section\n                section_ended = True\n        if not section_ended:\n            # Does this & the next 5 lines simply contain numbers? If yes, it's\n            # probably the axis scale of a graph in a fig. End refs section\n            digit_test_str = docbody[x].replace(\" \", \"\").\\\n                replace(\".\", \"\").\\\n                replace(\"-\", \"\").\\\n                replace(\"+\", \"\").\\\n                replace(u\"\\u00D7\", \"\").\\\n                replace(u\"\\u2212\", \"\").\\\n                strip()\n            if len(digit_test_str) > 10 and digit_test_str.isdigit():\n                # The line contains only digits and is longer than 10 chars:\n                y = x + 1\n                digit_lines = 4\n                num_digit_lines = 1\n                while y < x + digit_lines and y < len(docbody):\n                    digit_test_str = docbody[y].replace(\" \", \"\").\\\n                        replace(\".\", \"\").\\\n                        replace(\"-\", \"\").\\\n                        replace(\"+\", \"\").\\\n                        replace(u\"\\u00D7\", \"\").\\\n                        replace(u\"\\u2212\", \"\").\\\n                        strip()\n                    if len(digit_test_str) > 10 and digit_test_str.isdigit():\n                        num_digit_lines += 1\n                    elif len(digit_test_str) == 0:\n                        # This is a blank line. Don't count it, to accommodate\n                        # documents that are double-line spaced:\n                        digit_lines += 1\n                    y = y + 1\n                if num_digit_lines == digit_lines:\n                    section_ended = True\n            x += 1\n    return x - 1", "response": "This function finds the end of a reference section in a document body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_reference_section_beginning(fulltext):\n    sect_start = {\n        'start_line': None,\n        'end_line': None,\n        'title_string': None,\n        'marker_pattern': None,\n        'marker': None,\n        'how_found_start': None,\n    }\n\n    # Find start of refs section:\n    sect_start = find_reference_section(fulltext)\n    if sect_start is not None:\n        sect_start['how_found_start'] = 1\n    else:\n        # No references found - try with no title option\n        sect_start = find_reference_section_no_title_via_brackets(fulltext)\n        if sect_start is not None:\n            sect_start['how_found_start'] = 2\n        # Try weaker set of patterns if needed\n        if sect_start is None:\n            # No references found - try with no title option (with weaker\n            # patterns..)\n            sect_start = find_reference_section_no_title_via_dots(fulltext)\n            if sect_start is not None:\n                sect_start['how_found_start'] = 3\n            if sect_start is None:\n                # No references found - try with no title option (with even\n                # weaker patterns..)\n                sect_start = find_reference_section_no_title_via_numbers(\n                    fulltext)\n                if sect_start is not None:\n                    sect_start['how_found_start'] = 4\n\n    if sect_start:\n        current_app.logger.debug('* title %r' % sect_start['title_string'])\n        current_app.logger.debug('* marker %r' % sect_start['marker'])\n        current_app.logger.debug('* title_marker_same_line %s'\n                                 % sect_start['title_marker_same_line'])\n    else:\n        current_app.logger.debug('* could not find references section')\n    return sect_start", "response": "Get start of reference section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef path(self, value):\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"path\", value)\n            assert os.path.exists(value), \"'{0}' attribute: '{1}' file doesn't exists!\".format(\"path\", value)\n        self.__path = value", "response": "Setter for **self. __path** attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbinding given function to a class object attribute.", "response": "def bind_function(self, function):\n        \"\"\"\n        Binds given function to a class object attribute.\n\n        Usage::\n\n            >>> import ctypes\n            >>> path = \"FreeImage.dll\"\n            >>> function = LibraryHook(name=\"FreeImage_GetVersion\", arguments_types=None, return_value=ctypes.c_char_p)\n            >>> library = Library(path, bind_library=False)\n            >>> library.bind_function(function)\n            True\n            >>> library.FreeImage_GetVersion()\n            '3.15.1'\n\n        :param function: Function to bind.\n        :type function: LibraryHook\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        LOGGER.debug(\"> Binding '{0}' library '{1}' function.\".format(self.__class__.__name__, function.name))\n\n        function_object = getattr(self.__library, function.name)\n        setattr(self, function.name, function_object)\n        if function.arguments_types:\n            function_object.argtypes = function.arguments_types\n        if function.return_value:\n            function_object.restype = function.return_value\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind_library(self):\n\n        if self.__functions:\n            for function in self.__functions:\n                self.bind_function(function)\n        return True", "response": "Binds the Library using functions registered in the self. functions attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estCumPos(pos,chrom,offset = 20000000):\n    '''\n    compute the cumulative position of each variant given the position and the chromosome\n    Also return the starting cumulativeposition of each chromosome\n\n    Args:\n        pos:        scipy.array of basepair positions (on the chromosome)\n        chrom:      scipy.array of chromosomes\n        offset:     offset between chromosomes for cumulative position (default 20000000 bp)\n    \n        Returns:\n        cum_pos:    scipy.array of cumulative positions\n        chrom_pos:  scipy.array of starting cumulative positions for each chromosme\n    '''\n    chromvals = SP.unique(chrom)#SP.unique is always sorted\n    chrom_pos=SP.zeros_like(chromvals)#get the starting position of each Chrom\n    cum_pos = SP.zeros_like(pos)#get the cum_pos of each variant.\n    maxpos_cum=0\n    for i,mychrom in enumerate(chromvals):\n        chrom_pos[i] = maxpos_cum\n        i_chr=chrom==mychrom\n        maxpos = pos[i_chr].max()+offset\n        maxpos_cum+=maxpos\n        cum_pos[i_chr]=chrom_pos[i]+pos[i_chr]\n    return cum_pos,chrom_pos", "response": "compute the cumulative position of each variant given the position and the chromosome Returns the cumulative position of each variant and the starting position of each chromosome"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _imputeMissing(X, center=True, unit=True, betaNotUnitVariance=False, betaA=1.0, betaB=1.0):\n        '''\n        fill in missing values in the SNP matrix by the mean value\n        optionally center the data and unit-variance it\n\n        Args:\n            X:      scipy.array of SNP values. If dtype=='int8' the missing values are -9, \n                    otherwise the missing values are scipy.nan\n            center: Boolean indicator if data should be mean centered\n                    Not supported in C-based parser\n            unit:   Boolean indicator if data should be normalized to have unit variance\n                    Not supported in C-based parser\n            betaNotUnitVariance:    use Beta(betaA,betaB) standardization instead of unit variance \n                                    (only with C-based parser) (default: False)\n            betaA:  shape parameter for Beta(betaA,betaB) standardization (only with C-based parser)\n            betaB:  scale parameter for Beta(betaA,betaB) standardization (only with C-based parser)\n\n        Returns:\n            X:      scipy.array of standardized SNPs with scipy.float64 values\n        '''\n        typeX=X.dtype\n        if typeX!=SP.int8:\n            iNanX = X!=X\n        else:\n            iNanX = X==-9\n        if iNanX.any() or betaNotUnitVariance:\n            if cparser:\n                print(\"using C-based imputer\")\n                if X.flags[\"C_CONTIGUOUS\"] or typeX!=SP.float32:\n                    X = SP.array(X, order=\"F\", dtype=SP.float32)\n                    if typeX==SP.int8:\n                        X[iNanX]=SP.nan\n                    parser.standardize(X,betaNotUnitVariance=betaNotUnitVariance,betaA=betaA,betaB=betaB)\n                    X=SP.array(X,dtype=SP.float64)\n                else:\n                    parser.standardize(X,betaNotUnitVariance=betaNotUnitVariance,betaA=betaA,betaB=betaB)\n                X=SP.array(X,dtype=SP.float64)\n            else:\n                if betaNotUnitVariance:\n                    raise NotImplementedError(\"Beta(betaA,betaB) standardization only in C-based parser, but not found\")\n                nObsX = (~iNanX).sum(0)\n                if typeX!=SP.float64:\n                    X=SP.array(X,dtype=SP.float64)\n                X[iNanX] = 0.0\n                sumX = (X).sum(0)                \n                meanX = sumX/nObsX\n                if center:\n                    X-=meanX\n                    X[iNanX] = 0.0\n                    X_=X\n                else:\n                    mean=SP.tile(meanX,(X.shape[0],1))\n                    X[iNanX]=mean[iNanX]\n                    X_=X-mean\n                if unit:\n                    stdX = SP.sqrt((X_*X_).sum(0)/nObsX)\n                    stdX[stdX==0.0]=1.0\n                    X/=stdX\n        else:\n            if X.dtype!=SP.float64:\n                X=SP.array(X,dtype=SP.float64)\n            if center:\n                X-= X.mean(axis=0)\n            if unit:\n                stdX= X.std(axis=0)\n                stdX[stdX==0.0]=1.0\n                X/=stdX\n        return X", "response": "Fill in missing values in the matrix X by the mean value of the data and unit - variance of the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads data file and return a new object containing all the information.", "response": "def load(self,cache_genotype=False,cache_phenotype=True):\n        \"\"\"load data file\n        \n        Args:\n            cache_genotype:     load genotypes fully into memory (default: False)\n            cache_phenotype:    load phentopyes fully intro memry (default: True)        \n        \"\"\"\n        self.f = h5py.File(self.file_name,'r')\n        self.pheno = self.f['phenotype']\n        self.geno  = self.f['genotype']\n        #TODO: load all row and column headers for genotype and phenotype\n\n        #parse out thse we alwasy need for convenience\n        self.genoM = self.geno['matrix']\n\n        self.phenoM = self.pheno['matrix']\n        self.sample_ID = self.geno['row_header']['sample_ID'][:]\n        self.genoChrom = self.geno['col_header']['chrom'][:]\n        self.genoPos   = self.geno['col_header']['pos'][:]\n        if 'pos_cum' in list(self.geno['col_header'].keys()):\n            self.genoPos_cum   = self.geno['col_header']['pos_cum'][:]\n        else:\n            self.genoPos_cum = None\n        self.phenotype_ID = self.pheno['col_header']['phenotype_ID'][:]\n\n\n        #cache?\n        if cache_genotype:\n            self.genoM = self.genoM[:]\n        if cache_phenotype:\n            self.phenoM = self.phenoM[:]\n    \n        # Additional pheno col header\n        headers = list(self.pheno['col_header'].keys())\n        if 'gene_ID' in headers:\n            self.eqtl = True\n            self.geneID = self.pheno['col_header']['gene_ID'][:]\n            self.gene_pos = SP.array([self.pheno['col_header']['gene_chrom'][:],self.pheno['col_header']['gene_start'][:],self.pheno['col_header']['gene_end']],dtype='int').T\n            self.geneIDs= list(set(self.geneID))\n        else:\n            self.eqtl = False\n        if 'environment' in headers:\n            self.E  = self.pheno['col_header/environment'][:]\n            self.Es = list(set(self.E))\n        else:\n            self.E = None\n\n        #dimensions\n        self.N = self.genoM.shape[0]\n        self.S = self.genoM.shape[1]\n        self.P = self.phenoM.shape[1]\n        assert (self.genoM.shape[0]==self.phenoM.shape[0]), 'dimension missmatch'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes 0 - based genotype index from position of cumulative position.", "response": "def getGenoIndex(self,pos0=None,pos1=None,chrom=None,pos_cum0=None,pos_cum1=None):\n        \"\"\"computes 0-based genotype index from position of cumulative position. \n        Positions can be given in one out of two ways: \n        - position (pos0-pos1 on chrom)\n        - cumulative position (pos_cum0-pos_cum1)\n        If all these are None (default), then all genotypes are returned\n\n        Args:\n            pos0:       position based selection (start position)\n            pos1:       position based selection (stop position)\n            chrom:      position based selection (chromosome)\n            pos_cum0:   cumulative position based selection (start position)\n            pos_cum1:   cumulative position based selection (stop position)\n        \n        Returns:\n            i0:         genotype index based selection (start index)\n            i1:         genotype index based selection (stop index)\n        \"\"\"\n        if (pos0 is not None) & (pos1 is not None) & (chrom is not None):\n            I = self.gneoChrom==chrom\n            I = I & (self.genoPos>=p0) & (self.genoPos<p1)\n            I = SP.nonzero(I)[0]\n            i0 = I.min()\n            i1 = I.max()\n        elif (pos_cum0 is not None) & (pos_cum1 is not None):\n            I = (self.genoPos_cum>=pos_cum0) & (self.genoPos_cum<pos_cum1)\n            I = SP.nonzero(I)[0]\n            if I.size==0:\n                return None\n            i0 = I.min()\n            i1 = I.max()\n        else:\n            i0=None\n            i1=None\n        return i0,i1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getGenotypes(self,i0=None,i1=None,pos0=None,pos1=None,chrom=None,center=True,unit=True,pos_cum0=None,pos_cum1=None,impute_missing=True):\n        #position based matching?\n        if (i0 is None) and (i1 is None) and ((pos0 is not None) & (pos1 is not None) & (chrom is not None)) or ((pos_cum0 is not None) & (pos_cum1 is not None)):\n            i0,i1=self.getGenoIndex(pos0=pos0,pos1=pos1,chrom=chrom,pos_cum0=pos_cum0,pos_cum1=pose_cum1)\n        #index based matching?\n        if (i0 is not None) & (i1 is not None):\n            X = self.genoM[:,i0:i1]\n        else:\n            X = self.genoM[:,:]\n        if impute_missing:\n            X = du.imputeMissing(X,center=center,unit=unit)\n        return X", "response": "Load the genotypes for the people in the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getCovariance(self,normalize=True,i0=None,i1=None,pos0=None,pos1=None,chrom=None,center=True,unit=True,pos_cum0=None,pos_cum1=None,blocksize=None,X=None,**kw_args):\n        if X is not None:\n            K=X.dot(X.T)\n            Nsnp=X.shape[1]\n        else:\n            if (i0 is None) and (i1 is None) and ((pos0 is not None) & (pos1 is not None) & (chrom is not None)) or ((pos_cum0 is not None) & (pos_cum1 is not None)):\n                i0,i1=self.getGenoIndex(pos0=pos0,pos1=pos1,chrom=chrom,pos_cum0=pos_cum0,pos_cum1=pose_cum1)\n\n            [N,M]=self.genoM.shape\n            if blocksize is None:\n                blocksize=M\n            if i0 is None:\n                i0=0\n            if i1 is None:\n                i1=M\n            nread = i0\n            K=None\n            Nsnp=i1-i0\n            while nread<i1:\n                thisblock=min(blocksize,i1-nread)\n                X=self.getGenotypes(i0=nread,i1=(nread+thisblock),center=center,unit=unit,**kw_args)    \n                if K is None:\n                    K=X.dot(X.T)\n                else:\n                    K+=X.dot(X.T)\n                nread+=thisblock\n        if normalize:\n            K/=(K.diagonal().mean())\n        else:#divide by number of SNPs in K\n            K/=Nsnp\n        return K", "response": "calculate the empirical genotype covariance in a region"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the genotype ID for a user", "response": "def getGenoID(self,i0=None,i1=None,pos0=None,pos1=None,chrom=None,pos_cum0=None,pos_cum1=None):\n        \"\"\"get genotype IDs. \n        Optionally the indices for loading subgroups the genotype IDs for all people\n        can be given in one out of three ways: \n        - 0-based indexing (i0-i1)\n        - position (pos0-pos1 on chrom)\n        - cumulative position (pos_cum0-pos_cum1)\n        If all these are None (default), then all genotypes are returned\n\n        Args:\n            i0:         genotype index based selection (start index)\n            i1:         genotype index based selection (stop index)\n            pos0:       position based selection (start position)\n            pos1:       position based selection (stop position)\n            chrom:      position based selection (chromosome)\n            pos_cum0:   cumulative position based selection (start position)\n            pos_cum1:   cumulative position based selection (stop position)\n           \n        Returns:\n            ID:         scipy.array of genotype IDs (e.g. rs IDs)\n        \"\"\"\n        #position based matching?\n        if (i0 is None) and (i1 is None) and ((pos0 is not None) & (pos1 is not None) & (chrom is not None)) or ((pos_cum0 is not None) & (pos_cum1 is not None)):\n            i0,i1=self.getGenoIndex(pos0=pos0,pos1=pos1,chrom=chrom,pos_cum0=pos_cum0,pos_cum1=pose_cum1)\n        if \"genotype_id\" in list(self.geno.keys()):\n            if (i0 is not None) & (i1 is not None):\n                return self.geno[\"genotype_id\"][i0:i1]\n            else:\n                return self.geno[\"genotype_id\"][i0:i1]\n        else:\n            if (i0 is not None) & (i1 is not None):\n                return SP.arange(i0,i0)\n            else:\n                return SP.arange(self.genoM.shape[1])\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload Phenotypes from the database", "response": "def getPhenotypes(self,i0=None,i1=None,phenotype_IDs=None,geneIDs=None,environments=None,center=True,impute=True,intersection=False):\n        \"\"\"load Phenotypes\n        \n        Args:\n            i0:             phenotype indices to load (start individual index)\n            i1:             phenotype indices to load (stop individual index)\n            phenotype_IDs:  names of phenotypes to load\n            geneIDs:        names of genes to load\n            environments:   names of environments to load\n            impute:         imputation of missing values (default: True)\n            intersection:   restrict observation to those obseved in all phenotypes? (default: False)\n        \n        Returns:\n            Y:              phenotype values\n            Ikeep:          index of individuals in Y\n        \"\"\"\n        if phenotype_IDs is None and (geneIDs is not None or environments is not None):\n           if geneIDs is None:\n               geneIDs = self.geneIDs\n           elif type(geneIDs)!=list:\n               geneIDs = [geneIDs]\n           if environments is None:\n               environments = self.Es\n           elif type(environments)!=list:\n               environments = [environments]\n           phenotype_IDs = []\n           for env in environments:\n               for gene in geneIDs:\n                   phenotype_IDs.append('%s:%d'%(gene,env))\n\n        if phenotype_IDs is not None:\n            I = SP.array([SP.nonzero(self.phenotype_ID==n)[0][0] for n in phenotype_IDs])\n        else:\n            I = SP.arange(self.phenotype_ID.shape[0])\n        Y = SP.array(self.phenoM[:,I],dtype='float')\n        Iok = (~SP.isnan(Y))\n\n        if intersection:\n            Ikeep = Iok.all(axis=1)\n        else:\n            Ikeep = Iok.any(axis=1)\n\n        Y = Y[Ikeep]\n        Iok = Iok[Ikeep]\n\n        if center | impute:\n            for i in range(Y.shape[1]):\n                ym = Y[Iok[:,i],i].mean()\n                Y[:,i]-=ym\n                Y[~Iok[:,i],i] = ym\n                Y[:,i]/=Y[:,i].std()\n        #calculate overlap of missing values\n        return [Y,Ikeep]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getIcis_geno(self,geneID,cis_window=50E3):\n        assert self.eqtl == True, 'Only for eqtl data'\n        index = self.geneID==geneID\n        [_chrom,_gene_start,_gene_end] = self.gene_pos[index][0,:]\n        Icis = (self.genoChrom==_chrom)*(self.genoPos>=_gene_start-cis_window)*(self.genoPos<=_gene_end+cis_window)\n        return Icis", "response": "getIcis_geno - Returns a bool vec for cis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsampling a particular set of individuals (Irow) or phenotypes (Icol_pheno) or genotypes (Icol_geno) Args: Irow: indices for a set of individuals Icol_pheno: indices for a set of phenotypes Icol_geno: indices for a set of SNPs Returns: QTLdata opject holding the specified subset of the data", "response": "def subSample(self,Irow=None,Icol_geno=None,Icol_pheno=None):\n        \"\"\"sample a particular set of individuals (Irow) or phenotypes (Icol_pheno) or genotypes (Icol_geno)\n        \n        Args:\n            Irow:           indices for a set of individuals\n            Icol_pheno:     indices for a set of phenotypes\n            Icol_geno:      indices for a set of SNPs\n        \n        Returns:\n            QTLdata opject holding the specified subset of the data\n        \"\"\"\n        C = copy.copy(self)\n        if Irow is not None:\n            C.genoM = C.genoM[Irow]\n            C.phenoM = C.phenoM[Irow]\n            C.sample_ID = C.sample_ID[Irow]\n        if Icol_geno is not None:\n            C.genoM = C.genoM[:,Icol_geno]\n            C.genoPos = C.genoPos[Icol_geno]\n            C.genoChrom = C.genoChrom[Icol_geno]\n            C.genoPos_cum = C.genoPos_cum[Icol_geno]\n        if Icol_pheno is not None:\n            C.phenoM = C.phenoM[:,Icol_pheno]\n            C.phenotype_ID = C.phenotype_ID[Icol_pheno]\n            if C.eqtl:\n                C.geneID   = C.geneID[Icol_pheno]\n                C.gene_pos = C.gene_pos[Icol_pheno,:]\n                C.geneIDs  = list(set(C.geneID))\n            if C.E != None:\n                C.E  = C.E[Icol_pheno]\n                C.Es = list(set(C.E))\n\n        C.N = C.genoM.shape[0]\n        C.S = C.genoM.shape[1]\n        C.P = C.phenoM.shape[1]\n        return C"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_credentials_from_file(username):\n    '''Loads password for `username` from a file.\n\n    The file must be called ``.tm_pass`` and stored in\n    the home directory. It must provide a YAML mapping where\n    keys are usernames and values the corresponding passwords.\n\n    Parameters\n    ----------\n    username: str\n        name of the TissueMAPS user\n\n    Returns\n    -------\n    str\n        password for the given user\n\n    Raises\n    ------\n    OSError\n        when the file does not exist\n    SyntaxError\n        when the file content cannot be parsed\n    KeyError\n        when the file does not contains a password for `username`\n\n    Warning\n    -------\n    This is not safe! Passwords are stored in plain text.\n    '''\n    filename = os.path.expandvars(os.path.join('$HOME', '.tm_pass'))\n    try:\n        with open(filename) as f:\n            credentials = yaml.load(f.read())\n    except OSError as err:\n        raise OSError(\n            'No credentials file:\\n{0}'.format(filename)\n        )\n    except Exception as err:\n        raise SyntaxError(\n            'Could not be read credentials from file:\\n{0}'.format(str(err))\n        )\n    if username not in credentials:\n        raise KeyError(\n            'No credentials provided for user \"{0}\"'.format(username)\n        )\n    return credentials[username]", "response": "Loads a password for a given user from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprompts the user for password.", "response": "def prompt_for_credentials(username):\n    '''Prompt `username` for password.\n\n    Parameters\n    ----------\n    username: str\n        name of the TissueMAPS user\n\n    Returns\n    -------\n    str\n        password for the given user\n\n    '''\n    message = 'Enter password for user \"{0}\": '.format(username)\n    password = getpass.getpass(message)\n    if not password:\n        raise ValueError(\n            'No credentials provided for user \"{0}\"'.format(username)\n        )\n    return password"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a brome config with default value MimeType", "response": "def generate_brome_config():\n    \"\"\"Generate a brome config with default value\n\n    Returns:\n        config (dict)\n    \"\"\"\n\n    config = {}\n    for key in iter(default_config):\n        for inner_key, value in iter(default_config[key].items()):\n            if key not in config:\n                config[key] = {}\n\n            config[key][inner_key] = value['default']\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the browser config and look for brome specific config", "response": "def parse_brome_config_from_browser_config(browser_config):\n    \"\"\"Parse the browser config and look for brome specific config\n\n    Args:\n        browser_config (dict)\n    \"\"\"\n\n    config = {}\n\n    brome_keys = [key for key in browser_config if key.find(':') != -1]\n\n    for brome_key in brome_keys:\n        section, option = brome_key.split(':')\n        value = browser_config[brome_key]\n\n        if section not in config:\n            config[section] = {}\n\n        config[section][option] = value\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngrab XML data from Gateway and return as a dict.", "response": "def grab_xml(host, token=None):\n    \"\"\"Grab XML data from Gateway, returned as a dict.\"\"\"\n    urllib3.disable_warnings()\n    if token:\n        scheme = \"https\"\n    if not token:\n        scheme = \"http\"\n        token = \"1234567890\"\n    url = (\n            scheme + '://' + host + '/gwr/gop.php?cmd=GWRBatch&data=<gwrcmds><gwrcmd><gcmd>RoomGetCarousel</gcmd><gdata><gip><version>1</version><token>' + token + '</token><fields>name,status</fields></gip></gdata></gwrcmd></gwrcmds>&fmt=xml')\n    response = requests.get(url, verify=False)\n    parsed = xmltodict.parse(response.content, force_list={'room', 'device'})\n    parsed = parsed['gwrcmds']['gwrcmd']['gdata']['gip']['room']\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_brightness(host, did, value, token=None):\n    urllib3.disable_warnings()\n    if token:\n        scheme = \"https\"\n    if not token:\n        scheme = \"http\"\n        token = \"1234567890\"\n    url = (\n            scheme + '://' + host + '/gwr/gop.php?cmd=DeviceSendCommand&data=<gip><version>1</version><token>' + token + '</token><did>' + did + '</did><value>' + str(\n        value) + '</value><type>level</type></gip>&fmt=xml')\n    response = requests.get(url, verify=False)\n    if response.status_code == '200':\n        return True\n    else:\n        return False", "response": "Set brightness of a bulb or fixture."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning on bulb or fixture", "response": "def turn_on(host, did, token=None):\n    \"\"\"Turn on bulb or fixture\"\"\"\n    urllib3.disable_warnings()\n    if token:\n        scheme = \"https\"\n    if not token:\n        scheme = \"http\"\n        token = \"1234567890\"\n    url = (\n            scheme + '://' + host + '/gwr/gop.php?cmd=DeviceSendCommand&data=<gip><version>1</version><token>' + token + '</token><did>' + did + '</did><value>1</value></gip>&fmt=xml')\n    response = requests.get(url, verify=False)\n    if response.status_code == '200':\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngrabbing token from gateway. Press sync button before running.", "response": "def grab_token(host, email, password):\n    \"\"\"Grab token from gateway. Press sync button before running.\"\"\"\n    urllib3.disable_warnings()\n    url = ('https://' + host + '/gwr/gop.php?cmd=GWRLogin&data=<gip><version>1</version><email>' + str(email) + '</email><password>' + str(password) + '</password></gip>&fmt=xml')\n    response = requests.get(url, verify=False)\n    if '<rc>404</rc>' in response.text:\n        raise PermissionError('Not In Pairing Mode')\n    parsed = xmltodict.parse(response.content)\n    parsed = parsed['gip']['token']\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grab_bulbs(host, token=None):\n    xml = grab_xml(host, token)\n    bulbs = {}\n    for room in xml:\n        for device in room['device']:\n            bulbs[int(device['did'])] = device\n    return bulbs", "response": "Grab XML then add all bulbs to a dict. Removes room functionality"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getmap(self, path, query=None):\n        code, data, ctype = self.get(path, query)\n        if ctype != 'application/json':\n            self.log.error(\"Expecting JSON from GET of '%s', got '%s'\", self.lastpath, ctype)\n            raise HttpError(code=400, content_type='text/plain', content='Remote returned invalid content type: '+ctype)\n        try:\n            result = json.loads(data)\n        except Exception as e:                                                                  # pragma: no cover\n            self.log.error(\"Could not load JSON content from GET %r -- %s\", self.lastpath, e)\n            raise HttpError(code=400, content_type='text/plain', content='Could not load JSON content')\n        return result", "response": "A method that performs a GET request to get the map from the remote."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a POST request to the specified path.", "response": "def post(self, path, valuemap=None, query=None):\n        \"\"\"\n        Performs a POST request.  \"valuemap\" is a dict sent as \"application/x-www-form-urlencoded\".\n        \"query\" is as for get().  Return is same as get().\n    \"\"\"\n        self.lastpath = path\n        if query is not None:\n            self.lastpath += '?' + urlencode(query)\n        if valuemap:\n            self.http.request('POST', self.lastpath, urlencode(valuemap),\n                                {\"Content-type\": \"application/x-www-form-urlencoded\"})\n        else:\n            self.http.request('POST', self.lastpath, '')\n        resp = self.http.getresponse()\n        ctype = resp.getheader('Content-Type')\n        data = resp.read().decode('utf-8')\n        self.log.debug(\"Request '%s' status %d, %s length %d\", self.lastpath, resp.status, ctype, len(data))\n        if resp.status < 400:\n            return (resp.status, data, ctype)\n        else:\n            raise HttpError(code=resp.status, content_type=ctype, content=data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a POST request as per getmap.", "response": "def postmap(self, path, valuemap=None, query=None):\n        \"\"\"\n        Performs a POST request as per post() but the response content type\n        is required to be \"application/json\" and is processed as with getmap().\n    \"\"\"\n        code, data, ctype = self.post(path, valuemap, query)\n        if ctype != 'application/json':\n            self.log.error(\"Expecting JSON from POST of '%s', got '%s'\", self.lastpath, ctype)\n            raise HttpError(code=400, content_type='text/plain', content='Remote returned invalid content type: '+ctype)\n        try:\n            result = json.loads(data)\n        except Exception as e:                                                                  # pragma: no cover\n            self.log.error(\"Could not load JSON content from POST %r -- %s\", self.lastpath, e)\n            raise HttpError(code=400, content_type='text/plain', content='Could not load JSON content')\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npass - thru method to make this class behave a little like HTTPConnection", "response": "def request(self, method, url, *args):\n        \"\"\"\n        Pass-thru method to make this class behave a little like HTTPConnection\n    \"\"\"\n        return self.http.request(method, url, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the response from the HTTP connection.", "response": "def getresponse(self):\n        \"\"\"\n        Pass-thru method to make this class behave a little like HTTPConnection\n    \"\"\"\n        resp = self.http.getresponse()\n        self.log.info(\"resp is %s\", str(resp))\n        if resp.status < 400:\n            return resp\n        else:\n            errtext = resp.read()\n            content_type = resp.getheader('Content-Type', 'text/plain')\n            raise HttpError(code=resp.status, content_type=content_type, content=errtext)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an elasticsearch client object", "response": "def client(self):\n        \"\"\"Get an elasticsearch client\n        \"\"\"\n        if not hasattr(self, \"_client\"):\n            self._client = connections.get_connection(\"default\")\n        return self._client"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a mapping class for this model", "response": "def mapping(self):\n        \"\"\"Get a mapping class for this model\n\n        This method will return a Mapping class for your model, generating it using settings from a\n        `Mapping` class on your model (if one exists). The generated class is cached on the manager.\n        \"\"\"\n        if not hasattr(self, \"_mapping\"):\n            if hasattr(self.model, \"Mapping\"):\n                mapping_klass = type(\"Mapping\", (DjangoMapping, self.model.Mapping), {})\n            else:\n                mapping_klass = get_first_mapping(self.model)\n                if mapping_klass is None:\n                    mapping_klass = DjangoMapping\n            self._mapping = mapping_klass(self.model)\n        return self._mapping"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Django model instance using a document from Elasticsearch", "response": "def from_es(self, hit):\n        \"\"\"Returns a Django model instance, using a document from Elasticsearch\"\"\"\n        doc = hit.copy()\n        klass = shallow_class_factory(self.model)\n\n        # We can pass in the entire source, except when we have a non-indexable many-to-many\n        for field in self.model._meta.get_fields():\n\n            if not field.auto_created and field.many_to_many:\n                if not issubclass(field.rel.to, Indexable):\n                    if field.name in doc[\"_source\"]:\n                        del doc[\"_source\"][field.name]\n\n            # if field.one_to_many:\n            #     if field.name in doc[\"_source\"]:\n            #         del doc[\"_source\"][field.name]\n\n        # Now let's go ahead and parse all the fields\n        fields = self.mapping.properties.properties\n        for key in fields:\n            # TODO: What if we've mapped the property to a different name? Will we allow that?\n            field = fields[key]\n\n            # if isinstance(field, InnerObject):\n            #     import pdb; pdb.set_trace()\n            #     continue\n\n            if doc[\"_source\"].get(key):\n                attribute_value = doc[\"_source\"][key]\n\n                doc[\"_source\"][key] = field.to_python(attribute_value)\n\n        return klass(**doc[\"_source\"])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, **kwargs):\n        # get the doc id\n        id = None\n        if \"id\" in kwargs:\n            id = kwargs[\"id\"]\n            del kwargs[\"id\"]\n        elif \"pk\" in kwargs:\n            id = kwargs[\"pk\"]\n            del kwargs[\"pk\"]\n        else:\n            raise self.model.DoesNotExist(\"You must provide an id to find\")\n\n        # connect to es and retrieve the document\n        es = connections.get_connection(\"default\")\n\n        doc_type = self.model.search_objects.mapping.doc_type\n        index = self.model.search_objects.mapping.index\n        try:\n            doc = es.get(index=index, doc_type=doc_type, id=id, **kwargs)\n        except NotFoundError:\n            message = \"Can't find a document for {}, using id {}\".format(\n                doc_type, id)\n            raise self.model.DoesNotExist(message)\n\n        # parse and return\n        return self.from_es(doc)", "response": "Get a object from Elasticsearch by id\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh(self):\n        self.client.indices.refresh(index=self.model.search_objects.mapping.index)", "response": "Force a refresh of the Elasticsearch index"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a dictionary representation of this item formatted for Elasticsearch", "response": "def to_dict(self):\n        \"\"\"Get a dictionary representation of this item, formatted for Elasticsearch\"\"\"\n        out = {}\n\n        fields = self.__class__.search_objects.mapping.properties.properties\n\n        for key in fields:\n            # TODO: What if we've mapped the property to a different name? Will we allow that?\n\n            attribute = getattr(self, key)\n\n            field = fields[key]\n\n            # I believe this should take the highest priority.\n            if hasattr(field, \"to_es\"):\n                out[key] = field.to_es(attribute)\n\n            # First we check it this is a manager, in which case we have many related objects\n            elif isinstance(attribute, models.Manager):\n                if issubclass(attribute.model, Indexable):\n                    # TODO: We want this to have some awareness of the relevant field.\n                    out[key] = [obj.to_dict() for obj in attribute.all()]\n                else:\n                    out[key] = list(attribute.values_list(\"pk\", flat=True))\n\n            elif callable(attribute):\n                out[key] = attribute()\n\n            elif isinstance(attribute, Indexable):\n                out[key] = attribute.to_dict()\n            else:\n                out[key] = attribute\n\n            if out[key] is None:\n                del out[key]\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(self, refresh=False):\n        es = connections.get_connection(\"default\")\n        index = self.__class__.search_objects.mapping.index\n        doc_type = self.__class__.search_objects.mapping.doc_type\n        es.index(index, doc_type,\n                 id=self.pk,\n                 body=self.to_dict(),\n                 refresh=refresh)", "response": "Indexes this object using a document from to_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_index(self, refresh=False, ignore=None):\n        es = connections.get_connection(\"default\")\n        index = self.__class__.search_objects.mapping.index\n        doc_type = self.__class__.search_objects.mapping.doc_type\n        es.delete(index, doc_type, id=self.pk, refresh=refresh, ignore=ignore)", "response": "Removes the object from the index if indexed = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the doc_type of this class and all of its descendants.", "response": "def get_doc_types(cls, exclude_base=False):\n        \"\"\"Returns the doc_type of this class and all of its descendants.\"\"\"\n        names = []\n        if not exclude_base and hasattr(cls, 'search_objects'):\n            if not getattr(cls.search_objects.mapping, \"elastic_abstract\", False):\n                names.append(cls.search_objects.mapping.doc_type)\n        for subclass in cls.__subclasses__():\n            names += subclass.get_doc_types()\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a list of files into a list of tuples.", "response": "def _load_file_itr(files, encoding):\n    \"\"\"\n    :param files: A list of file paths :: [str]\n    :param encoding: Encoding, e.g. 'utf-8'\n    \"\"\"\n    for filename in files:\n        fileobj = jinja2.loaders.open_if_exists(filename)\n        if fileobj is not None:\n            try:\n                yield (fileobj.read().decode(encoding),\n                       os.path.getmtime(filename))\n            finally:\n                fileobj.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the source of a template.", "response": "def get_source(self, environment, template):\n        \"\"\".. seealso:: :meth:`jinja2.loaders.FileSystemLoader.get_source`\n        \"\"\"\n        pieces = jinja2.loaders.split_template_path(template)\n        for searchpath in self.searchpath:\n            filename = os.path.join(searchpath, *pieces)\n            if self.enable_glob:\n                files = sorted(glob.glob(filename))\n            else:\n                files = [filename]\n            contents_mtimes = list(_load_file_itr(files, self.encoding))\n            if not contents_mtimes:\n                continue\n\n            contents = ''.join(cm[0] for cm in contents_mtimes)\n            mtimes = [cm[1] for cm in contents_mtimes]\n\n            def uptodate():\n                \"\"\"function to check of these are up-to-date.\n                \"\"\"\n                try:\n                    return all(os.path.getmtime(fn) == mt for fn, mt\n                               in zip(files, mtimes))\n                except OSError:\n                    return False\n\n            return contents, filename, uptodate\n\n        raise jinja2.exceptions.TemplateNotFound(template)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender given template string and return the result.", "response": "def _render(self, template, context, is_file, at_paths=None,\n                at_encoding=ENCODING, **kwargs):\n        \"\"\"\n        Render given template string and return the result.\n\n        :param template: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param is_file: True if given `template` is a filename\n        :param at_paths: Template search paths\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments passed to jinja2.Envrionment. Please\n            note that 'loader' option is not supported because anytemplate does\n            not support to load template except for files\n\n        :return: Rendered string\n\n        \"\"\"\n        eopts = self.filter_options(kwargs, self.engine_valid_options())\n        self._env_options.update(eopts)\n\n        # Use custom loader to allow glob include.\n        loader = FileSystemExLoader(at_paths, encoding=at_encoding.lower(),\n                                    enable_glob=True)\n        env = jinja2.Environment(loader=loader, **self._env_options)\n        if kwargs:\n            context.update(kwargs)\n        try:\n            tmpl = (env.get_template if is_file else env.from_string)(template)\n            return tmpl.render(**context)\n        except jinja2.exceptions.TemplateNotFound as exc:\n            raise TemplateNotFound(str(exc))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering given template string and return the result.", "response": "def renders_impl(self, template_content, context, **opts):\n        \"\"\"\n        Render given template string and return the result.\n\n        :param template_content: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param opts: Options such as:\n            - at_paths: Template search paths\n            - at_encoding: Template encoding\n            - other keyword options passed to jinja2.Envrionment. Please note\n              that 'loader' option is not supported because anytemplate does\n              not support to load template except for files\n\n        :return: Rendered string\n\n        >>> egn = Engine()\n        >>> tmpl_s = 'a = {{ a }}, b = \"{{ b }}\"'\n        >>> ctx = {'a': 1, 'b': 'bbb'}\n        >>> egn.renders_impl(tmpl_s, ctx, at_paths=['.']) == 'a = 1, b = \"bbb\"'\n        True\n        \"\"\"\n        return self._render(template_content, context, False, **opts)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_impl(self, template, context, **opts):\n        return self._render(os.path.basename(template), context, True, **opts)", "response": "Render given template file and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estimateKronCovariances(phenos,K1r=None,K1c=None,K2r=None,K2c=None,covs=None,Acovs=None,covar_type='lowrank_diag',rank=1):\n    print(\".. Training the backgrond covariance with a GP model\")\n    vc = VAR.CVarianceDecomposition(phenos)\n    if K1r is not None:\n        vc.addRandomEffect(K1r,covar_type=covar_type,rank=rank)\n    if K2r is not None:\n        #TODO: fix this; forces second term to be the noise covariance\n        vc.addRandomEffect(is_noise=True,K=K2r,covar_type=covar_type,rank=rank)\n    for ic  in range(len(Acovs)):\n        vc.addFixedEffect(covs[ic],Acovs[ic])\n    start = time.time()\n    conv = vc.findLocalOptimum(fast=True)\n    assert conv, \"CVariance Decomposition has not converged\"\n    time_el = time.time()-start\n    print((\"Background model trained in %.2f s\" % time_el))\n    return vc", "response": "Estimate background covariance model before testing the current version of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes sure that covs and Acovs are lists", "response": "def updateKronCovs(covs,Acovs,N,P):\n    \"\"\"\n    make sure that covs and Acovs are lists\n    \"\"\"\n    if (covs is None) and (Acovs is None):\n        covs = [SP.ones([N,1])]\n        Acovs = [SP.eye(P)]\n\n    if Acovs is None or covs is None:\n        raise Exception(\"Either Acovs or covs is None, while the other isn't\")\n\n    if (type(Acovs)!=list) and (type(covs)!=list):\n        Acovs= [Acovs]\n        covs = [covs]\n    if (type(covs)!=list) or (type(Acovs)!=list) or (len(covs)!=len(Acovs)):\n        raise Exception(\"Either Acovs or covs is not a list or they missmatch in length\")\n    return covs, Acovs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndeprecate function for simple_interaction_kronecker.", "response": "def simple_interaction_kronecker_deprecated(snps,phenos,covs=None,Acovs=None,Asnps1=None,Asnps0=None,K1r=None,K1c=None,K2r=None,K2c=None,covar_type='lowrank_diag',rank=1,searchDelta=False):\n    \"\"\"\n    I-variate fixed effects interaction test for phenotype specific SNP effects.\n    (Runs multiple likelihood ratio tests and computes the P-values in python from the likelihood ratios)\n\n    Args:\n        snps:   [N x S] SP.array of S SNPs for N individuals (test SNPs)\n        phenos: [N x P] SP.array of P phenotypes for N individuals\n        covs:           list of SP.arrays holding covariates. Each covs[i] has one corresponding Acovs[i]\n        Acovs:          list of SP.arrays holding the phenotype design matrices for covariates.\n                        Each covs[i] has one corresponding Acovs[i].\n        Asnps1:         list of SP.arrays of I interaction variables to be tested for N\n                        individuals. Note that it is assumed that Asnps0 is already included.\n                        If not provided, the alternative model will be the independent model\n        Asnps0:         single SP.array of I0 interaction variables to be included in the\n                        background model when testing for interaction with Inters\n        K1r:    [N x N] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        K1c:    [P x P] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        K2r:    [N x N] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        K2c:    [P x P] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        covar_type:     type of covaraince to use. Default 'freeform'. possible values are\n                        'freeform': free form optimization,\n                        'fixed': use a fixed matrix specified in covar_K0,\n                        'diag': optimize a diagonal matrix,\n                        'lowrank': optimize a low rank matrix. The rank of the lowrank part is specified in the variable rank,\n                        'lowrank_id': optimize a low rank matrix plus the weight of a constant diagonal matrix. The rank of the lowrank part is specified in the variable rank,\n                        'lowrank_diag': optimize a low rank matrix plus a free diagonal matrix. The rank of the lowrank part is specified in the variable rank,\n                        'block': optimize the weight of a constant P x P block matrix of ones,\n                        'block_id': optimize the weight of a constant P x P block matrix of ones plus the weight of a constant diagonal matrix,\n                        'block_diag': optimize the weight of a constant P x P block matrix of ones plus a free diagonal matrix,\n        rank:           rank of a possible lowrank component (default 1)\n        searchDelta:    Boolean indicator if delta is optimized during SNP testing (default False)\n\n    Returns:\n        pv:     P-values of the interaction test\n        lrt0:   log likelihood ratio statistics of the null model\n        pv0:    P-values of the null model\n        lrt:    log likelihood ratio statistics of the interaction test\n        lrtAlt: log likelihood ratio statistics of the alternative model\n        pvAlt:  P-values of the alternative model\n    \"\"\"\n    S=snps.shape[1]\n    #0. checks\n    N  = phenos.shape[0]\n    P  = phenos.shape[1]\n\n    if K1r==None:\n        K1r = SP.dot(snps,snps.T)\n    else:\n        assert K1r.shape[0]==N, 'K1r: dimensions dismatch'\n        assert K1r.shape[1]==N, 'K1r: dimensions dismatch'\n\n    if K2r==None:\n        K2r = SP.eye(N)\n    else:\n        assert K2r.shape[0]==N, 'K2r: dimensions dismatch'\n        assert K2r.shape[1]==N, 'K2r: dimensions dismatch'\n\n    covs,Acovs = updateKronCovs(covs,Acovs,N,P)\n\n    #Asnps can be several designs\n    if (Asnps0 is None):\n        Asnps0 = [SP.ones([1,P])]\n    if Asnps1 is None:\n        Asnps1 = [SP.eye([P])]\n    if (type(Asnps0)!=list):\n        Asnps0 = [Asnps0]\n    if (type(Asnps1)!=list):\n        Asnps1 = [Asnps1]\n    assert (len(Asnps0)==1) and (len(Asnps1)>0), \"need at least one Snp design matrix for null and alt model\"\n\n    #one row per column design matrix\n    pv = SP.zeros((len(Asnps1),snps.shape[1]))\n    lrt = SP.zeros((len(Asnps1),snps.shape[1]))\n    pvAlt = SP.zeros((len(Asnps1),snps.shape[1]))\n    lrtAlt = SP.zeros((len(Asnps1),snps.shape[1]))\n\n    #1. run GP model to infer suitable covariance structure\n    if K1c==None or K2c==None:\n        vc = estimateKronCovariances(phenos=phenos, K1r=K1r, K2r=K2r, K1c=K1c, K2c=K2c, covs=covs, Acovs=Acovs, covar_type=covar_type, rank=rank)\n        K1c = vc.getEstTraitCovar(0)\n        K2c = vc.getEstTraitCovar(1)\n    else:\n        assert K1c.shape[0]==P, 'K1c: dimensions dismatch'\n        assert K1c.shape[1]==P, 'K1c: dimensions dismatch'\n        assert K2c.shape[0]==P, 'K2c: dimensions dismatch'\n        assert K2c.shape[1]==P, 'K2c: dimensions dismatch'\n\n    #2. run kroneckerLMM for null model\n    lmm = limix.CKroneckerLMM()\n    lmm.setK1r(K1r)\n    lmm.setK1c(K1c)\n    lmm.setK2r(K2r)\n    lmm.setK2c(K2c)\n    lmm.setSNPs(snps)\n    #add covariates\n    for ic  in range(len(Acovs)):\n        lmm.addCovariates(covs[ic],Acovs[ic])\n    lmm.setPheno(phenos)\n    if searchDelta:      lmm.setNumIntervalsAlt(100)\n    else:                   lmm.setNumIntervalsAlt(0)\n    lmm.setNumIntervals0(100)\n    #add SNP design\n    lmm.setSNPcoldesign(Asnps0[0])\n    lmm.process()\n    dof0 = Asnps0[0].shape[0]\n    pv0 = lmm.getPv()\n    lrt0 = ST.chi2.isf(pv0,dof0)\n    for iA in range(len(Asnps1)):\n        dof1 = Asnps1[iA].shape[0]\n        dof = dof1-dof0\n        lmm.setSNPcoldesign(Asnps1[iA])\n        lmm.process()\n        pvAlt[iA,:] = lmm.getPv()[0]\n        lrtAlt[iA,:] = ST.chi2.isf(pvAlt[iA,:],dof1)\n        lrt[iA,:] = lrtAlt[iA,:] - lrt0[0] # Don't need the likelihood ratios, as null model is the same between the two models\n        pv[iA,:] = ST.chi2.sf(lrt[iA,:],dof)\n    return pv,lrt0,pv0,lrt,lrtAlt,pvAlt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simple_interaction_kronecker(snps,phenos,covs=None,Acovs=None,Asnps1=None,Asnps0=None,K1r=None,K1c=None,K2r=None,K2c=None,covar_type='lowrank_diag',rank=1,NumIntervalsDelta0=100,NumIntervalsDeltaAlt=0,searchDelta=False):\n    S=snps.shape[1]\n    #0. checks\n    N  = phenos.shape[0]\n    P  = phenos.shape[1]\n\n    if K1r==None:\n        K1r = SP.dot(snps,snps.T)\n    else:\n        assert K1r.shape[0]==N, 'K1r: dimensions dismatch'\n        assert K1r.shape[1]==N, 'K1r: dimensions dismatch'\n\n    if K2r==None:\n        K2r = SP.eye(N)\n    else:\n        assert K2r.shape[0]==N, 'K2r: dimensions dismatch'\n        assert K2r.shape[1]==N, 'K2r: dimensions dismatch'\n\n    covs,Acovs = updateKronCovs(covs,Acovs,N,P)\n\n    #Asnps can be several designs\n    if (Asnps0 is None):\n        Asnps0 = [SP.ones([1,P])]\n    if Asnps1 is None:\n        Asnps1 = [SP.eye([P])]\n    if (type(Asnps0)!=list):\n        Asnps0 = [Asnps0]\n    if (type(Asnps1)!=list):\n        Asnps1 = [Asnps1]\n    assert (len(Asnps0)==1) and (len(Asnps1)>0), \"need at least one Snp design matrix for null and alt model\"\n\n    #one row per column design matrix\n    pv = SP.zeros((len(Asnps1),snps.shape[1]))\n    lrt = SP.zeros((len(Asnps1),snps.shape[1]))\n    pvAlt = SP.zeros((len(Asnps1),snps.shape[1]))\n    lrtAlt = SP.zeros((len(Asnps1),snps.shape[1]))\n\n    #1. run GP model to infer suitable covariance structure\n    if K1c==None or K2c==None:\n        vc = estimateKronCovariances(phenos=phenos, K1r=K1r, K2r=K2r, K1c=K1c, K2c=K2c, covs=covs, Acovs=Acovs, covar_type=covar_type, rank=rank)\n        K1c = vc.getEstTraitCovar(0)\n        K2c = vc.getEstTraitCovar(1)\n    else:\n        assert K1c.shape[0]==P, 'K1c: dimensions dismatch'\n        assert K1c.shape[1]==P, 'K1c: dimensions dismatch'\n        assert K2c.shape[0]==P, 'K2c: dimensions dismatch'\n        assert K2c.shape[1]==P, 'K2c: dimensions dismatch'\n\n    #2. run kroneckerLMM for null model\n    lmm = limix.CKroneckerLMM()\n    lmm.setK1r(K1r)\n    lmm.setK1c(K1c)\n    lmm.setK2r(K2r)\n    lmm.setK2c(K2c)\n    lmm.setSNPs(snps)\n    #add covariates\n    for ic  in range(len(Acovs)):\n        lmm.addCovariates(covs[ic],Acovs[ic])\n    lmm.setPheno(phenos)\n\n    #delta serch on alt. model?\n    if searchDelta:\n        lmm.setNumIntervalsAlt(NumIntervalsDeltaAlt)\n        lmm.setNumIntervals0_inter(NumIntervalsDeltaAlt)\n    else:\n        lmm.setNumIntervalsAlt(0)\n        lmm.setNumIntervals0_inter(0)\n\n\n    lmm.setNumIntervals0(NumIntervalsDelta0)\n    #add SNP design\n    lmm.setSNPcoldesign0_inter(Asnps0[0])\n    for iA in range(len(Asnps1)):\n        lmm.setSNPcoldesign(Asnps1[iA])\n        lmm.process()\n\n        pvAlt[iA,:] = lmm.getPv()[0]\n        pv[iA,:] = lmm.getPv()[1]\n        pv0 = lmm.getPv()[2]\n    return pv,pv0,pvAlt", "response": "Simple interaction test for fixed effects and phenotype specific SNPs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to create a KroneckerLMM code for a set of SNPs and phenotypes.", "response": "def kronecker_lmm(snps,phenos,covs=None,Acovs=None,Asnps=None,K1r=None,K1c=None,K2r=None,K2c=None,covar_type='lowrank_diag',rank=1,NumIntervalsDelta0=100,NumIntervalsDeltaAlt=0,searchDelta=False):\n    \"\"\"\n    simple wrapper for kroneckerLMM code\n\n    Args:\n        snps:   [N x S] SP.array of S SNPs for N individuals (test SNPs)\n        phenos: [N x P] SP.array of P phenotypes for N individuals\n        covs:           list of SP.arrays holding covariates. Each covs[i] has one corresponding Acovs[i]\n        Acovs:          list of SP.arrays holding the phenotype design matrices for covariates.\n                        Each covs[i] has one corresponding Acovs[i].\n        Asnps:          single SP.array of I0 interaction variables to be included in the\n                        background model when testing for interaction with Inters\n                        If not provided, the alternative model will be the independent model\n        K1r:    [N x N] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        K1c:    [P x P] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        K2r:    [N x N] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        K2c:    [P x P] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        covar_type:     type of covaraince to use. Default 'freeform'. possible values are\n                        'freeform': free form optimization,\n                        'fixed': use a fixed matrix specified in covar_K0,\n                        'diag': optimize a diagonal matrix,\n                        'lowrank': optimize a low rank matrix. The rank of the lowrank part is specified in the variable rank,\n                        'lowrank_id': optimize a low rank matrix plus the weight of a constant diagonal matrix. The rank of the lowrank part is specified in the variable rank,\n                        'lowrank_diag': optimize a low rank matrix plus a free diagonal matrix. The rank of the lowrank part is specified in the variable rank,\n                        'block': optimize the weight of a constant P x P block matrix of ones,\n                        'block_id': optimize the weight of a constant P x P block matrix of ones plus the weight of a constant diagonal matrix,\n                        'block_diag': optimize the weight of a constant P x P block matrix of ones plus a free diagonal matrix,\n        rank:           rank of a possible lowrank component (default 1)\n        NumIntervalsDelta0:  number of steps for delta optimization on the null model (100)\n        NumIntervalsDeltaAlt:number of steps for delta optimization on the alt. model (0 - no optimization)\n        searchDelta:    Boolean indicator if delta is optimized during SNP testing (default False)\n\n    Returns:\n        CKroneckerLMM object\n        P-values for all SNPs from liklelihood ratio test\n    \"\"\"\n    #0. checks\n    N  = phenos.shape[0]\n    P  = phenos.shape[1]\n\n    if K1r==None:\n        K1r = SP.dot(snps,snps.T)\n    else:\n        assert K1r.shape[0]==N, 'K1r: dimensions dismatch'\n        assert K1r.shape[1]==N, 'K1r: dimensions dismatch'\n\n    if K2r==None:\n        K2r = SP.eye(N)\n    else:\n        assert K2r.shape[0]==N, 'K2r: dimensions dismatch'\n        assert K2r.shape[1]==N, 'K2r: dimensions dismatch'\n\n    covs,Acovs = updateKronCovs(covs,Acovs,N,P)\n\n    #Asnps can be several designs\n    if Asnps is None:\n        Asnps = [SP.ones([1,P])]\n    if (type(Asnps)!=list):\n        Asnps = [Asnps]\n    assert len(Asnps)>0, \"need at least one Snp design matrix\"\n\n    #one row per column design matrix\n    pv = SP.zeros((len(Asnps),snps.shape[1]))\n\n    #1. run GP model to infer suitable covariance structure\n    if K1c==None or K2c==None:\n        vc = estimateKronCovariances(phenos=phenos, K1r=K1r, K2r=K2r, K1c=K1c, K2c=K2c, covs=covs, Acovs=Acovs, covar_type=covar_type, rank=rank)\n        K1c = vc.getEstTraitCovar(0)\n        K2c = vc.getEstTraitCovar(1)\n    else:\n        assert K1c.shape[0]==P, 'K1c: dimensions dismatch'\n        assert K1c.shape[1]==P, 'K1c: dimensions dismatch'\n        assert K2c.shape[0]==P, 'K2c: dimensions dismatch'\n        assert K2c.shape[1]==P, 'K2c: dimensions dismatch'\n\n    #2. run kroneckerLMM\n\n    lmm = limix.CKroneckerLMM()\n    lmm.setK1r(K1r)\n    lmm.setK1c(K1c)\n    lmm.setK2r(K2r)\n    lmm.setK2c(K2c)\n    lmm.setSNPs(snps)\n    #add covariates\n    for ic  in range(len(Acovs)):\n        lmm.addCovariates(covs[ic],Acovs[ic])\n    lmm.setPheno(phenos)\n\n\n    #delta serch on alt. model?\n    if searchDelta:\n        lmm.setNumIntervalsAlt(NumIntervalsDeltaAlt)\n    else:\n        lmm.setNumIntervalsAlt(0)\n    lmm.setNumIntervals0(NumIntervalsDelta0)\n\n    for iA in range(len(Asnps)):\n        #add SNP design\n        lmm.setSNPcoldesign(Asnps[iA])\n        lmm.process()\n        pv[iA,:] = lmm.getPv()[0]\n    return lmm,pv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simple_lmm(snps,pheno,K=None,covs=None, test='lrt',NumIntervalsDelta0=100,NumIntervalsDeltaAlt=0,searchDelta=False):\n    t0=time.time()\n    if K is None:\n        K=SP.eye(snps.shape[0])\n    lm = limix.CLMM()\n    lm.setK(K)\n    lm.setSNPs(snps)\n    lm.setPheno(pheno)\n    if covs is None:\n        covs = SP.ones((snps.shape[0],1))\n    lm.setCovs(covs)\n    if test=='lrt':\n        lm.setTestStatistics(0)\n    elif test=='f':\n        lm.setTestStatistics(1)\n    else:\n        print(test)\n        raise NotImplementedError(\"only f or lrt are implemented\")\n    #set number of delta grid optimizations?\n    lm.setNumIntervals0(NumIntervalsDelta0)\n    if searchDelta:\n        lm.setNumIntervalsAlt(NumIntervalsDeltaAlt)\n    else:\n        lm.setNumIntervalsAlt(0)\n    lm.process()\n    t1=time.time()\n    print((\"finished GWAS testing in %.2f seconds\" %(t1-t0)))\n    return lm", "response": "Simple linear mixed model test for all SNPs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interact_GxG(pheno,snps1,snps2=None,K=None,covs=None):\n    if K is None:\n        K=SP.eye(N)\n    N=snps1.shape[0]\n    if snps2 is None:\n        snps2 = snps1\n    return interact_GxE(snps=snps1,pheno=pheno,env=snps2,covs=covs,K=K)", "response": "Interact with GxE GXG"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef phenSpecificEffects(snps,pheno1,pheno2,K=None,covs=None,test='lrt'):\n    N=snps.shape[0]\n    if K is None:\n        K=SP.eye(N)\n    assert (pheno1.shape[1]==pheno2.shape[1]), \"Only consider equal number of phenotype dimensions\"\n    if covs is None:\n        covs = SP.ones(N,1)\n    assert (pheno1.shape[1]==1 and pheno2.shape[1]==1 and pheno1.shape[0]==N and pheno2.shape[0]==N and K.shape[0]==N and K.shape[1]==N and covs.shape[0]==N), \"shapes missmatch\"\n    Inter = SP.zeros((N*2,1))\n    Inter[0:N,0]=1\n    Inter0 = SP.ones((N*2,1))\n    Yinter=SP.concatenate((pheno1,pheno2),0)\n    Xinter = SP.tile(snps,(2,1))\n    Covitner= SP.tile(covs(2,1))\n    lm = simple_interaction(snps=Xinter,pheno=Yinter,covs=Covinter,Inter=Inter,Inter0=Inter0,test=test)\n    return lm", "response": "Univariate fixed effects interaction test for phenotype specific SNPs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simple_interaction(snps,pheno,Inter,Inter0=None,covs = None,K=None,test='lrt'):\n    N=snps.shape[0]\n    if covs is None:\n        covs = SP.ones((N,1))\n    if K is None:\n        K = SP.eye(N)\n    if Inter0 is None:\n        Inter0=SP.ones([N,1])\n    assert (pheno.shape[0]==N and K.shape[0]==N and K.shape[1]==N and covs.shape[0]==N and Inter0.shape[0]==N and Inter.shape[0]==N), \"shapes missmatch\"\n    lmi = limix.CInteractLMM()\n    lmi.setK(K)\n    lmi.setSNPs(snps)\n    lmi.setPheno(pheno)\n    lmi.setCovs(covs)\n    lmi.setInter0(Inter0)\n    lmi.setInter(Inter)\n    if test=='lrt':\n        lmi.setTestStatistics(0)\n    elif test=='f':\n        lmi.setTestStatistics(1)\n    else:\n        print(test)\n        raise NotImplementedError(\"only f or lrt are implemented\")\n    lmi.process()\n    return lmi", "response": "Simple interaction test for fixed effects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nforward LMM - Kronecker test with forward selection", "response": "def forward_lmm_kronecker(snps,phenos,Asnps=None,Acond=None,K1r=None,K1c=None,K2r=None,K2c=None,covs=None,Acovs=None,threshold = 5e-8, maxiter = 2,qvalues=False, update_covariances = False,**kw_args):\n    \"\"\"\n    Kronecker fixed effects test with forward selection\n\n    Args:\n        snps:   [N x S] SP.array of S SNPs for N individuals (test SNPs)\n        pheno:  [N x P] SP.array of 1 phenotype for N individuals\n        K:      [N x N] SP.array of LMM-covariance/kinship koefficients (optional)\n                        If not provided, then linear regression analysis is performed\n        covs:   [N x D] SP.array of D covariates for N individuals\n        threshold:      (float) P-value thrashold for inclusion in forward selection (default 5e-8)\n        maxiter:        (int) maximum number of interaction scans. First scan is\n                        without inclusion, so maxiter-1 inclusions can be performed. (default 2)\n        qvalues:        Use q-value threshold and return q-values in addition (default False)\n        update_covar:   Boolean indicator if covariances should be re-estimated after each forward step (default False)\n\n    Returns:\n        lm:             lmix LMMi object\n        resultStruct with elements:\n            iadded:         array of indices of SNPs included in order of inclusion\n            pvadded:        array of Pvalues obtained by the included SNPs in iteration\n                            before inclusion\n            pvall:   [maxiter x S] SP.array of Pvalues for all iterations\n        Optional:      corresponding q-values\n            qvadded\n            qvall\n    \"\"\"\n\n    #0. checks\n    N  = phenos.shape[0]\n    P  = phenos.shape[1]\n\n    if K1r==None:\n        K1r = SP.dot(snps,snps.T)\n    else:\n        assert K1r.shape[0]==N, 'K1r: dimensions dismatch'\n        assert K1r.shape[1]==N, 'K1r: dimensions dismatch'\n\n    if K2r==None:\n        K2r = SP.eye(N)\n    else:\n        assert K2r.shape[0]==N, 'K2r: dimensions dismatch'\n        assert K2r.shape[1]==N, 'K2r: dimensions dismatch'\n\n    covs,Acovs = updateKronCovs(covs,Acovs,N,P)\n\n    if Asnps is None:\n        Asnps = [SP.ones([1,P])]\n    if (type(Asnps)!=list):\n        Asnps = [Asnps]\n    assert len(Asnps)>0, \"need at least one Snp design matrix\"\n\n    if Acond is None:\n        Acond = Asnps\n    if (type(Acond)!=list):\n        Acond = [Acond]\n    assert len(Acond)>0, \"need at least one Snp design matrix\"\n\n    #1. run GP model to infer suitable covariance structure\n    if K1c==None or K2c==None:\n        vc = estimateKronCovariances(phenos=phenos, K1r=K1r, K2r=K2r, K1c=K1c, K2c=K2c, covs=covs, Acovs=Acovs, **kw_args)\n        K1c = vc.getEstTraitCovar(0)\n        K2c = vc.getEstTraitCovar(1)\n    else:\n        vc = None\n        assert K1c.shape[0]==P, 'K1c: dimensions dismatch'\n        assert K1c.shape[1]==P, 'K1c: dimensions dismatch'\n        assert K2c.shape[0]==P, 'K2c: dimensions dismatch'\n        assert K2c.shape[1]==P, 'K2c: dimensions dismatch'\n    t0 = time.time()\n    lm,pv = kronecker_lmm(snps=snps,phenos=phenos,Asnps=Asnps,K1r=K1r,K2r=K2r,K1c=K1c,K2c=K2c,covs=covs,Acovs=Acovs)\n\n    #get pv\n    #start stuff\n    iadded = []\n    pvadded = []\n    qvadded = []\n    time_el = []\n    pvall = SP.zeros((pv.shape[0]*maxiter,pv.shape[1]))\n    qvall = None\n    t1=time.time()\n    print((\"finished GWAS testing in %.2f seconds\" %(t1-t0)))\n    time_el.append(t1-t0)\n    pvall[0:pv.shape[0],:]=pv\n    imin= SP.unravel_index(pv.argmin(),pv.shape)\n    score=pv[imin].min()\n    niter = 1\n    if qvalues:\n        assert pv.shape[0]==1, \"This is untested with the fdr package. pv.shape[0]==1 failed\"\n        qvall = SP.zeros((maxiter,snps.shape[1]))\n        qv  = FDR.qvalues(pv)\n        qvall[0:1,:] = qv\n        score=qv[imin]\n    #loop:\n    while (score<threshold) and niter<maxiter:\n        t0=time.time()\n        pvadded.append(pv[imin])\n        iadded.append(imin)\n        if qvalues:\n            qvadded.append(qv[imin])\n        if update_covariances and vc is not None:\n            vc.addFixedTerm(snps[:,imin[1]:(imin[1]+1)],Acond[imin[0]])\n            vc.setScales()#CL: don't know what this does, but findLocalOptima crashes becahuse vc.noisPos=None\n            vc.findLocalOptima(fast=True)\n            K1c = vc.getEstTraitCovar(0)\n            K2c = vc.getEstTraitCovar(1)\n            lm.setK1c(K1c)\n            lm.setK2c(K2c)\n        lm.addCovariates(snps[:,imin[1]:(imin[1]+1)],Acond[imin[0]])\n        for i in range(len(Asnps)):\n            #add SNP design\n            lm.setSNPcoldesign(Asnps[i])\n            lm.process()\n            pv[i,:] = lm.getPv()[0]\n        pvall[niter*pv.shape[0]:(niter+1)*pv.shape[0]]=pv\n        imin= SP.unravel_index(pv.argmin(),pv.shape)\n        if qvalues:\n            qv = FDR.qvalues(pv)\n            qvall[niter:niter+1,:] = qv\n            score = qv[imin].min()\n        else:\n            score = pv[imin].min()\n        t1=time.time()\n        print((\"finished GWAS testing in %.2f seconds\" %(t1-t0)))\n        time_el.append(t1-t0)\n        niter=niter+1\n    RV = {}\n    RV['iadded']  = iadded\n    RV['pvadded'] = pvadded\n    RV['pvall']   = pvall\n    RV['time_el'] = time_el\n    if qvalues:\n        RV['qvall'] = qvall\n        RV['qvadded'] = qvadded\n    return lm,RV"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef forward_lmm(snps,pheno,K=None,covs=None,qvalues=False,threshold = 5e-8, maxiter = 2,test='lrt',**kw_args):\n\n    if K is None:\n        K=SP.eye(snps.shape[0])\n    if covs is None:\n        covs = SP.ones((snps.shape[0],1))\n\n    lm = simple_lmm(snps,pheno,K=K,covs=covs,test=test,**kw_args)\n    pvall = SP.zeros((maxiter,snps.shape[1]))\n    pv = lm.getPv()\n    pvall[0:1,:]=pv\n    imin= pv.argmin()\n    niter = 1\n    #start stuff\n    iadded = []\n    pvadded = []\n    qvadded = []\n    if qvalues:\n        assert pv.shape[0]==1, \"This is untested with the fdr package. pv.shape[0]==1 failed\"\n        qvall = SP.zeros((maxiter,snps.shape[1]))\n        qv  = FDR.qvalues(pv)\n        qvall[0:1,:] = qv\n        score=qv.min()\n    else:\n        score=pv.min()\n    while (score<threshold) and niter<maxiter:\n        t0=time.time()\n        iadded.append(imin)\n        pvadded.append(pv[0,imin])\n        if qvalues:\n            qvadded.append(qv[0,imin])\n        covs=SP.concatenate((covs,snps[:,imin:(imin+1)]),1)\n        lm.setCovs(covs)\n        lm.process()\n        pv = lm.getPv()\n        pvall[niter:niter+1,:]=pv\n        imin= pv.argmin()\n        if qvalues:\n            qv = FDR.qvalues(pv)\n            qvall[niter:niter+1,:] = qv\n            score = qv.min()\n        else:\n            score = pv.min()\n        t1=time.time()\n        print((\"finished GWAS testing in %.2f seconds\" %(t1-t0)))\n        niter=niter+1\n    RV = {}\n    RV['iadded']  = iadded\n    RV['pvadded'] = pvadded\n    RV['pvall']   = pvall\n    if qvalues:\n        RV['qvall'] = qvall\n        RV['qvadded'] = qvadded\n    return lm,RV", "response": "Simple LMM test with forward selection"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the label for a token.", "response": "def classify(self, token_type, value, lineno, column, line):\n        \"\"\"Find the label for a token.\"\"\"\n        if token_type == self.grammar.KEYWORD_TOKEN:\n            label_index = self.grammar.keyword_ids.get(value, -1)\n            if label_index != -1:\n                return label_index\n        label_index = self.grammar.token_ids.get(token_type, -1)\n        if label_index == -1:\n            raise ParseError(\"invalid token\", token_type, value, lineno, column,\n                             line)\n        return label_index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshift a non - terminal and prepare for the next state.", "response": "def shift(self, next_state, token_type, value, lineno, column):\n        \"\"\"Shift a non-terminal and prepare for the next state.\"\"\"\n        dfa, state, node = self.stack[-1]\n        new_node = Node(token_type, value, None, lineno, column)\n        node.children.append(new_node)\n        self.stack[-1] = (dfa, next_state, node)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef push(self, next_dfa, next_state, node_type, lineno, column):\n        dfa, state, node = self.stack[-1]\n        new_node = Node(node_type, None, [], lineno, column)\n        self.stack[-1] = (dfa, next_state, node)\n        self.stack.append((next_dfa, 0, new_node))", "response": "Push a terminal and adjust the current state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self):\n        dfa, state, node = self.stack.pop()\n        if self.stack:\n            self.stack[-1][2].children.append(node)\n        else:\n            self.root = node", "response": "Pop an entry off the stack and make its node a child of the last."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get(self, url, params=None):\n        self._call(self.GET, url, params, None)", "response": "Wrapper method for GET calls."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap method for POST calls.", "response": "def _post(self, url, params, uploads=None):\n        \"\"\" Wrapper method for POST calls. \"\"\"\n        self._call(self.POST, url, params, uploads)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitiate resquest to server and handle outcomes.", "response": "def _call(self, method, url, params, uploads):\n        \"\"\" Initiate resquest to server and handle outcomes. \"\"\"\n        try:\n            data = self._request(method, url, params, uploads)\n        except Exception, e:\n            self._failed_cb(e)\n        else:\n            self._completed_cb(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a request to the server and handle the response.", "response": "def _request(self, method, url, params=None, uploads=None):\n        \"\"\" Request to server and handle transfer status. \"\"\"\n        c = pycurl.Curl()\n\n        if method == self.POST:\n            c.setopt(c.POST, 1)\n            if uploads is not None:\n                if isinstance(uploads, dict):\n                    # handle single upload\n                    uploads = [uploads]\n                for upload in uploads:\n                    params += [(upload['field'],\n                               (c.FORM_FILE, upload['path']))]\n\n                c.setopt(c.HTTPPOST, params)\n            else:\n                # XXX memory leak in pyCurl/7.29.0?\n                data = urllib.urlencode(params)\n                c.setopt(c.POSTFIELDS, data)\n\n        elif method == self.GET:\n            c.setopt(c.HTTPGET, 1)\n            if params:\n                url += '?%s' % urllib.urlencode(params)\n\n        elif method == self.DELETE:\n            c.setopt(pycurl.CUSTOMREQUEST, self.DELETE)\n\n        else:\n            raise NotSupportedError(str(method))\n\n        buffer = []\n\n        def _write_cb(data):\n            buffer.append(data)\n\n        c.setopt(c.HTTPHEADER, self._hook_header(params))\n        c.setopt(pycurl.SSL_VERIFYPEER, 0)\n        c.setopt(pycurl.SSL_VERIFYHOST, 0)\n        c.setopt(c.URL, url)\n        c.setopt(c.NOPROGRESS, 0)\n        c.setopt(c.PROGRESSFUNCTION, self._updated_cb)\n        c.setopt(c.WRITEFUNCTION, _write_cb)\n        c.setopt(c.FOLLOWLOCATION, 1)\n        #c.setopt(c.VERBOSE, True)\n\n        try:\n            self.emit('started')\n            c.perform()\n        except pycurl.error, e:\n            raise TransferError(str(e))\n        else:\n            code = c.getinfo(c.HTTP_CODE)\n            if not 200 <= code < 300:\n                raise ResponseError(code)\n        finally:\n            c.close()\n\n        return ''.join(buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _completed_cb(self, data):\n        try:\n            info = json.loads(data)\n        except ValueError:\n            info = self._hook_data(data)\n        except Exception, e:\n            info = None\n            logging.error('%s: _completed_cb crashed with %s',\n                          self.__class__.__name__, str(e))\n        finally:\n            self._hook_id(info)\n            self.emit('completed', info)", "response": "Callback for when a new entry is received from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _updated_cb(self, downtotal, downdone, uptotal, updone):\n        self.emit('updated', downtotal, downdone, uptotal, updone)", "response": "Called when the update signal is received from the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _hook_id(self, info):\n        if isinstance(info, dict) and 'id' in info.keys():\n            self.id = info['id']", "response": "Extract id from info. Override for custom behaviour."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclassify all comments that have not already been classified or are unsure.", "response": "def handle(self, *args, **options):\n        \"\"\"\n        Collect all comments that hasn't already been\n        classified or are classified as unsure.\n        Order randomly so we don't rehash previously unsure classifieds\n        when count limiting.\n        \"\"\"\n        comments = Comment.objects.filter(\n            Q(classifiedcomment__isnull=True) |\n            Q(classifiedcomment__cls='unsure')).order_by('?')\n        if options['count']:\n            comments = comments[:options['count']]\n        comment_count = comments.count()\n\n        self.stdout.write('Classifying %s comments, please wait...' %\n                          comment_count)\n        self.stdout.flush()\n\n        for comment in comments:\n            classified_comment = utils.classify_comment(comment)\n            self.stdout.write('%s,' % classified_comment.cls[0])\n            self.stdout.flush()\n\n        self.stdout.write('\\nDone!\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_text(self, token, match):\n        if isinstance(self.text, MatchGroup):\n            self.text = self.text.get_group_value(token, match)", "response": "Update text from results of regex match"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_params(self, token, match):\n        for k, v in self.params.items():\n            if isinstance(v, MatchGroup):\n                self.params[k] = v.get_group_value(token, match)", "response": "Update dict of params from results of regex match"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modify_pattern(self, pattern, group):\n        pattern = group_regex.sub(r'?P<{}_\\1>'.format(self.name), pattern)\n        return r'(?P<{}>{})'.format(group, pattern)", "response": "Rename groups in regex pattern and enclose it in named group"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_group_value(self, token, match):\n        try:\n            value = match.group('{}_{}'.format(token.name, self.group))\n        except IndexError:\n            value = ''\n        return self.func(value) if callable(self.func) else value", "response": "Return value of regex match for the specified group"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_regex(self, tokens):\n        patterns = []\n        for token in tokens:\n            patterns.append(token.pattern_start)\n            if token.pattern_end:\n                patterns.append(token.pattern_end)\n        return re.compile('|'.join(patterns), re.DOTALL)", "response": "Build a compound regex from a list of tokens"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild dict of groups from list of tokens", "response": "def build_groups(self, tokens):\n        \"\"\"Build dict of groups from list of tokens\"\"\"\n        groups = {}\n        for token in tokens:\n            match_type = MatchType.start if token.group_end else MatchType.single\n            groups[token.group_start] = (token, match_type)\n            if token.group_end:\n                groups[token.group_end] = (token, MatchType.end)\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_matched_token(self, match):\n        match_groupdict = match.groupdict()\n        for group in self.groups:\n            if match_groupdict[group] is not None:\n                token, match_type = self.groups[group]\n                return (token, match_type, group)", "response": "Find which token has been matched by compound regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets params from stack of tokens", "response": "def get_params(self, token_stack):\n        \"\"\"Get params from stack of tokens\"\"\"\n        params = {}\n        for token in token_stack:\n            params.update(token.params)\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the last occurance of a token from the stack", "response": "def remove_token(self, token_stack, token):\n        \"\"\"Remove last occurance of token from stack\"\"\"\n        token_stack.reverse()\n        try:\n            token_stack.remove(token)\n            retval = True\n        except ValueError:\n            retval = False\n        token_stack.reverse()\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, text):\n        text = self.preprocess(text)\n        token_stack = []\n        last_pos = 0\n\n        # Iterate through all matched tokens\n        for match in self.regex.finditer(text):\n            # Find which token has been matched by regex\n            token, match_type, group = self.get_matched_token(match)\n\n            # Get params from stack of tokens\n            params = self.get_params(token_stack)\n\n            # Should we skip interpreting tokens?\n            skip = token_stack[-1].skip if token_stack else False\n\n            # Check for end token first\n            if match_type == MatchType.end:\n                if not skip or token_stack[-1] == token:\n                    removed = self.remove_token(token_stack, token)\n                    if removed:\n                        skip = False\n                    else:\n                        skip = True\n\n            if not skip:\n                # Append text preceding matched token\n                start_pos = match.start(group)\n                if start_pos > last_pos:\n                    yield Segment(self.postprocess(text[last_pos:start_pos]), **params)\n\n                # Actions specific for start token or single token\n                if match_type == MatchType.start:\n                    token_stack.append(token)\n                elif match_type == MatchType.single:\n                    single_params = params.copy()\n                    single_params.update(token.params)\n                    single_text = token.text if token.text is not None else match.group(group)\n                    yield Segment(single_text, token=token, match=match, **single_params)\n\n                # Move last position pointer to the end of matched token\n                last_pos = match.end(group)\n\n        # Append anything that's left\n        if last_pos < len(text):\n            params = self.get_params(token_stack)\n            yield Segment(self.postprocess(text[last_pos:]), **params)", "response": "Parse text to obtain list of Segments"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_impl(**kwargs):\n    if Template is None:\n        tmpl = kwargs.get(\"file\", None)\n        if tmpl is None:\n            tmpl = kwargs.get(\"source\", None)\n            return anytemplate.engines.base.fallback_renders(tmpl)\n\n        return anytemplate.engines.base.fallback_render(tmpl, None, **kwargs)\n\n    return Template(**kwargs).respond()", "response": "Render a single element of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef supports(cls, template_file=None):\n        if anytemplate.compat.IS_PYTHON_3:\n            cls._priority = 99\n            return False  # Always as it's not ported to python 3.\n\n        return super(Engine, cls).supports(template_file=template_file)", "response": "Returns True if the engine supports the given template file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __render(self, context, **kwargs):\n        # Not pass both searchList and namespaces.\n        kwargs[\"namespaces\"] = [context, ] + kwargs.get(\"namespaces\", []) \\\n                                           + kwargs.get(\"searchList\", [])\n        kwargs[\"searchList\"] = None\n\n        # TODO:\n        # if at_paths is not None:\n        #    paths = at_paths + self._engine_valid_opts.get(..., [])\n        #    ...\n        kwargs = self.filter_options(kwargs, self.engine_valid_options())\n        self.engine_options.update(kwargs)\n\n        return render_impl(**self.engine_options)", "response": "Render the given context with the given kwargs and return the string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender given template string and return the result.", "response": "def renders_impl(self, template_content, context, **kwargs):\n        \"\"\"\n        Render given template string and return the result.\n\n        :param template_content: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param kwargs: Keyword arguments such as:\n            - at_paths: Template search paths but it is not actually processed\n              in this module (TODO)\n            - at_encoding: Template encoding but it is not actually prcoessed\n              in this module (TODO)\n            - Other keyword arguments passed to the template engine to render\n              templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        if \"file\" in kwargs:\n            kwargs[\"file\"] = None\n\n        kwargs[\"source\"] = template_content\n\n        return self.__render(context, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender given template file and return the result.", "response": "def render_impl(self, template, context, **kwargs):\n        \"\"\"\n        Render given template file and return the result.\n\n        :param template: Template file path\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param kwargs: Keyword arguments such as:\n            - at_paths: Template search paths but it is not actually processed\n              in this module (TODO)\n            - at_encoding: Template encoding but it is not actually prcoessed\n              in this module (TODO)\n            - Other keyword arguments passed to the template engine to render\n              templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        if \"source\" in kwargs:\n            kwargs[\"source\"] = None\n\n        kwargs[\"file\"] = template\n\n        return self.__render(context, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute arXiv report - number.", "response": "def compute_arxiv_re(report_pattern, report_number):\n    \"\"\"Compute arXiv report-number.\"\"\"\n    if report_number is None:\n        report_number = r\"\\g<name>\"\n    report_re = re.compile(r\"(?<!<cds\\.REPORTNUMBER>)(?<!\\w)\" +\n                           \"(?P<name>\" + report_pattern + \")\" +\n                           old_arxiv_numbers, re.U | re.I)\n    return report_re, report_number"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds optional spaces to the word characters.", "response": "def _create_regex_pattern_add_optional_spaces_to_word_characters(word):\n    r\"\"\"Add the regex special characters (\\s*) to allow optional spaces.\n\n    :param word: (string) the word to be inserted into a regex pattern.\n    :return: (string) the regex pattern for that word with optional spaces\n                      between all of its characters.\n    \"\"\"\n    new_word = u\"\"\n    for ch in word:\n        if ch.isspace():\n            new_word += ch\n        else:\n            new_word += ch + r'\\s*'\n    return new_word"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of compiled regex patterns used to search for the title.", "response": "def get_reference_section_title_patterns():\n    \"\"\"Return a list of compiled regex patterns used to search for the title.\n\n    :return: (list) of compiled regex patterns.\n    \"\"\"\n    patterns = []\n    titles = [u'references',\n              u'references.',\n              u'r\\u00C9f\\u00E9rences',\n              u'r\\u00C9f\\u00C9rences',\n              u'reference',\n              u'refs',\n              u'r\\u00E9f\\u00E9rence',\n              u'r\\u00C9f\\u00C9rence',\n              u'r\\xb4ef\\xb4erences',\n              u'r\\u00E9fs',\n              u'r\\u00C9fs',\n              u'bibliography',\n              u'bibliographie',\n              u'citations',\n              u'literaturverzeichnis']\n    sect_marker = u'^\\s*([\\[\\-\\{\\(])?\\s*' \\\n                  u'((\\w|\\d){1,5}([\\.\\-\\,](\\w|\\d){1,5})?\\s*' \\\n                  u'[\\.\\-\\}\\)\\]]\\s*)?' \\\n                  u'(?P<title>'\n    sect_marker1 = u'^(\\d){1,3}\\s*(?P<title>'\n    line_end = r'(\\s*s\\s*e\\s*c\\s*t\\s*i\\s*o\\s*n\\s*)?)([\\)\\}\\]])?' \\\n        r'($|\\s*[\\[\\{\\(\\<]\\s*[1a-z]\\s*[\\}\\)\\>\\]]|\\:$)'\n\n    for t in titles:\n        t_ptn = re.compile(\n            sect_marker +\n            _create_regex_pattern_add_optional_spaces_to_word_characters(t) +\n            line_end, re.I | re.UNICODE)\n        patterns.append(t_ptn)\n        # allow e.g.  'N References' to be found where N is an integer\n        t_ptn = re.compile(\n            sect_marker1 +\n            _create_regex_pattern_add_optional_spaces_to_word_characters(t) +\n            line_end, re.I | re.UNICODE)\n        patterns.append(t_ptn)\n\n    return patterns"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of compiled regex patterns used to search for the marker.", "response": "def get_reference_line_numeration_marker_patterns(prefix=u''):\n    \"\"\"Return a list of compiled regex patterns used to search for the marker.\n\n    Marker of a reference line in a full-text document.\n\n    :param prefix: (string) the possible prefix to a reference line\n    :return: (list) of compiled regex patterns.\n    \"\"\"\n    title = u\"\"\n    if type(prefix) in (str, unicode):\n        title = prefix\n    g_name = u'(?P<mark>'\n    g_close = u')'\n    space = r'\\s*'\n    patterns = [\n        # [1]\n        space + title + g_name + r'\\[\\s*(?P<marknum>\\d+)\\s*\\]' + g_close,\n        # [<letters and numbers]\n        space + title + g_name + r'\\[\\s*[a-zA-Z:-]+\\+?\\s?(\\d{1,4}[A-Za-z:-]?)?\\s*\\]' + g_close,  # noqa\n        # {1}\n        space + title + g_name + r'\\{\\s*(?P<marknum>\\d+)\\s*\\}' + g_close,\n        # (1)\n        space + title + g_name + r'\\<\\s*(?P<marknum>\\d+)\\s*\\>' + g_close,\n        space + title + g_name + r'\\(\\s*(?P<marknum>\\d+)\\s*\\)' + g_close,\n        space + title + g_name + r'(?P<marknum>\\d+)\\s*\\.(?!\\d)' + g_close,\n        space + title + g_name + r'(?P<marknum>\\d+)\\s+' + g_close,\n        space + title + g_name + r'(?P<marknum>\\d+)\\s*\\]' + g_close,\n        # 1]\n        space + title + g_name + r'(?P<marknum>\\d+)\\s*\\}' + g_close,\n        # 1}\n        space + title + g_name + r'(?P<marknum>\\d+)\\s*\\)' + g_close,\n        # 1)\n        space + title + g_name + r'(?P<marknum>\\d+)\\s*\\>' + g_close,\n        # [1.1]\n        space + title + g_name + r'\\[\\s*\\d+\\.\\d+\\s*\\]' + g_close,\n        # [    ]\n        space + title + g_name + r'\\[\\s*\\]' + g_close,\n        # *\n        space + title + g_name + r'\\*' + g_close,\n    ]\n    return [re.compile(p, re.I | re.UNICODE) for p in patterns]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_post_reference_section_title_patterns():\n    compiled_patterns = []\n    thead = r'^\\s*([\\{\\(\\<\\[]?\\s*(\\w|\\d)\\s*[\\)\\}\\>\\.\\-\\]]?\\s*)?'\n    ttail = r'(\\s*\\:\\s*)?'\n    numatn = r'(\\d+|\\w\\b|i{1,3}v?|vi{0,3})[\\.\\,]{0,2}\\b'\n    roman_numbers = r'[LVIX]'\n    patterns = [\n        # Section titles\n        thead + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'appendix') + ttail,\n        thead + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'appendices') + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'acknowledgement') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'acknowledgment') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'table') + r'\\w?s?\\d?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'figure') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'list of figure') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'annex') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'discussion') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'remercie') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'index') + r's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'summary') + r's?' + ttail,\n        # Figure nums\n        r'^\\s*' + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'figure'\n        ) + numatn,\n        r'^\\s*' + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'fig') + r'\\.\\s*' + numatn,\n        r'^\\s*' + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'fig') + r'\\.?\\s*\\d\\w?\\b',\n        # Tables\n        r'^\\s*' + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'table') + numatn,\n        r'^\\s*' + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'tab') + r'\\.\\s*' + numatn,\n        r'^\\s*' + \\\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'tab') + r'\\.?\\s*\\d\\w?\\b',\n        # Other titles formats\n        r'^\\s*' + roman_numbers + r'\\.?\\s*[Cc]onclusion[\\w\\s]*$',\n        r'^\\s*Appendix\\s[A-Z]\\s*\\:\\s*[a-zA-Z]+\\s*',\n    ]\n\n    for p in patterns:\n        compiled_patterns.append(re.compile(p, re.I | re.UNICODE))\n\n    return compiled_patterns", "response": "Return a list of compiled regex patterns for the post - reference section title."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_post_reference_section_keyword_patterns():\n    compiled_patterns = []\n    patterns = [\n        u'(' + _create_regex_pattern_add_optional_spaces_to_word_characters(u'prepared') +  # noqa\n        r'|' + _create_regex_pattern_add_optional_spaces_to_word_characters(u'created') +  # noqa\n        r').*(AAS\\s*)?\\sLATEX',\n        r'AAS\\s+?LATEX\\s+?' + _create_regex_pattern_add_optional_spaces_to_word_characters(u'macros') + u'v',  # noqa\n        r'^\\s*' + _create_regex_pattern_add_optional_spaces_to_word_characters(u'This paper has been produced using'),  # noqa\n        r'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(u'This article was processed by the author using Springer-Verlag') +  # noqa\n        u' LATEX'\n    ]\n    for p in patterns:\n        compiled_patterns.append(re.compile(p, re.I | re.UNICODE))\n    return compiled_patterns", "response": "Return a list of compiled regex patterns for keywords. nll_post_reference_section_keyword. nll_post_reference_section_keyword."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh(self):\n        self._bundles = {}\n\n        bundles = self._api.get_bundles(self._document.id)\n        for bundle in bundles:\n            self._bundles[bundle['identifier']] = Bundle(self._api, self._document, bundle)\n        \n        return self", "response": "Reload list of bundles from the store"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a CTM handler from a file - like object.", "response": "def create_ctm_miohandler(fileobj, title=None, comment=None, register_prefixes=True, register_templates=True, detect_prefixes=False):\n    \"\"\"\\\n\n    \"\"\"\n    handler = CTMHandler(fileobj)\n    handler.title = title\n    handler.comment = comment\n    handler.detect_prefixes = detect_prefixes\n    if register_prefixes:\n        register_default_prefixes(handler)\n    if register_templates:\n        handler.add_association_template(u'classified', psis.CLASSIFIED_AS_TYPE, psis.CABLE_TYPE, psis.CLASSIFICATION_TYPE)\n        handler.add_association_template(u'origin', psis.SENT_BY_TYPE, psis.CABLE_TYPE, psis.SENDER_TYPE)\n        handler.add_association_template(u'references', psis.REFERENCES_TYPE, psis.SOURCE_TYPE, psis.TARGET_TYPE)\n        handler.add_association_template(u'to', psis.RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE)\n        handler.add_association_template(u'to', psis.RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE, psis.ROUTE_TYPE)\n        handler.add_association_template(u'to', psis.RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE, psis.ROUTE_TYPE, psis.PRECEDENCE_TYPE)\n        handler.add_association_template(u'to', psis.RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE, psis.ROUTE_TYPE, psis.PRECEDENCE_TYPE, psis.MCN_TYPE)\n        handler.add_association_template(u'info', psis.INFO_RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE)\n        handler.add_association_template(u'info', psis.INFO_RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE, psis.ROUTE_TYPE)\n        handler.add_association_template(u'info', psis.INFO_RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE, psis.ROUTE_TYPE, psis.PRECEDENCE_TYPE)\n        handler.add_association_template(u'info', psis.INFO_RECIPIENT_TYPE, psis.CABLE_TYPE, psis.RECIPIENT_TYPE, psis.ROUTE_TYPE, psis.PRECEDENCE_TYPE, psis.MCN_TYPE)\n        handler.add_association_template(u'tagged', psis.TAGGED_TYPE, psis.CABLE_TYPE, psis.TAG_TYPE)\n        handler.add_association_template(u'is-partial', psis.IS_PARTIAL_TYPE, psis.PARTIAL_TYPE)\n        handler.add_association_template(u'signed-by', psis.SIGNED_TYPE, psis.CABLE_TYPE, psis.SIGNER_TYPE)\n    return handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_ctm_handler(fileobj, title=u'Cablegate Topic Map', comment=u'Generated by Cablemap - https://github.com/heuer/cablemap', detect_prefixes=False):\n    return MIOCableHandler(create_ctm_miohandler(fileobj, title, comment, detect_prefixes=detect_prefixes))", "response": "Create a CableHandler instance which writes Compact Topic Maps syntax."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XTM handler.", "response": "def create_xtm_handler(fileobj, title=u'Cablegate Topic Map', comment=u'Generated by Cablemap - https://github.com/heuer/cablemap'):\n    \"\"\"\\\n    Returns a `ICableHandler` instance which writes XML Topic Maps syntax (XTM) 2.1.\n\n    `fileobj`\n        A file-like object.\n    \"\"\"\n    return MIOCableHandler(create_xtm_miohandler(fileobj, title, comment))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle a reference cable.", "response": "def _handle_reference_cable(self, reference, handler, reifier):\n        \"\"\"\\\n\n        \"\"\"\n        cable_ref = psis.cable_psi(reference.value)\n        self._assoc(psis.REFERENCES_TYPE,\n                    psis.SOURCE_TYPE, self._cable_psi,\n                    psis.TARGET_TYPE, cable_ref,\n                    reifier)\n        handler.startTopic(cable_ref)\n        handler.isa(psis.CABLE_TYPE)\n        self._name(reference.value)\n        handler.endTopic()\n        self._sent_by(psis.origin_psi_by_cable_id(reference.value), cable_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_digest(origin, algorithm=\"sha1\", block_size=None):\n    try:\n        hashM = hashlib.new(algorithm)\n    except ValueError:\n        raise ValueError('hash algorithm not supported by the underlying platform: \"{0}\"'.format(algorithm))\n\n    while True:\n        chunk = origin.read(block_size) if block_size else origin.read()\n        if not chunk:\n            break\n        hashM.update(chunk)\n    return hashM.hexdigest()", "response": "Calculate the digest of a readable object containing the contents of the object origin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_fds (self):\n        if '_in' in self.options:\n            i= self.options['_in']\n            logger.debug ('_in: %r', i)\n\n            # this condition is complex, but basically handles any type of input\n            # that is not going to be handled later in client()\n            if (     not isinstance (i, io.IOBase)      # file and such objects\n                 and type (i) not in (int, str, bytes)  # fd's and file names\n                 and i is not None                      # special value for /dev/null\n                 and not isinstance (i, Command) ):     # Command's\n                if self.options['_in_tty']:\n                    # TODO: no support yet for input from file when _in_tty\n                    # NOTE: os.openpty() returns (master, slave)\n                    # but when writing master=w, slave=r\n                    logger.debug ('_in: using tty')\n                    (master, slave)= os.openpty ()\n                    self.stdin_pipe= (slave, master)\n                else:\n                    logger.debug (\"_in:%s creates a pipe()\", type (i))\n                    self.stdin_pipe= os.pipe ()\n            elif isinstance (i, Command):\n                if i.options.get ('_out', None)==Capture:\n                    # if it's a captured command, create a pipe to feed the data\n                    logger.debug (\"_in::Command, _in._out==Capture creates a pipe()\")\n                    self.stdin_pipe= os.pipe ()\n                elif i.options.get ('_out', None)==Pipe:\n                    # if it's a piped command, use its pipe and hope it runs in the bg\n                    logger.debug (\"_in::Command uses the stdout_pipe\")\n                    self.stdin_pipe= i.stdout_pipe\n\n        logger.debug (\"stdin_pipe: %s\", self.stdin_pipe)\n\n        if '_out' in self.options:\n            if self.options['_out']==Capture:\n                if self.options['_out_tty']:\n                    if self.options['_in_tty']:\n                        # we use a copy of the pty created for the stdin\n                        logger.debug ('duping tty form _in to _out')\n                        self.stdout_pipe= (os.dup (self.stdin_pipe[1]),\n                                           os.dup (self.stdin_pipe[0]))\n                    else:\n                        # this time the order is right\n                        logger.debug ('_out: using tty')\n                        (master, slave)= os.openpty ()\n                        self.stdout_pipe= (master, slave)\n                else:\n                    logger.debug (\"_out==Capture creates a pipe()\")\n                    self.stdout_pipe= os.pipe ()\n            elif self.options['_out']==Pipe:\n                # this pipe should be picked up by the outer Command\n                logger.debug (\"_out==Pipe creates a pipe()\")\n                self.stdout_pipe= os.pipe ()\n\n        logger.debug (\"stdout_pipe: %s\", self.stdout_pipe)\n\n        if '_err' in self.options:\n            if self.options['_err']==Capture:\n                # if stdout is also Capture'd, then use the same pipe\n                if not '_out' in self.options or self.options['_out']!=Capture:\n                    # if stdout is a tty, hook to that one\n                    if self.options['_out_tty']:\n                        logger.debug ('duping tty form _out to _err')\n                        self.stderr_pipe= (os.dup (self.stdout_pipe[0]),\n                                           os.dup (self.stdout_pipe[1]))\n                    else:\n                        logger.debug (\"_err==Capture creates a pipe()\")\n                        self.stderr_pipe= os.pipe ()\n            elif self.options['_err']==Pipe:\n                # this pipe should be picked up by the outer Command\n                logger.debug (\"_err==Pipe creates a pipe()\")\n                self.stderr_pipe= os.pipe ()\n\n        logger.debug (\"stderr_pipe: %s\", self.stderr_pipe)", "response": "Create needed file descriptors before forking."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an NFA to a DFA.", "response": "def nfa_to_dfa(start, end):\n    \"\"\"Convert an NFA to a DFA(s)\n\n    Each DFA is initially a set of NFA states without labels.  We start with the\n    DFA for the start NFA.  Then we add labeled arcs to it pointing to another\n    set of NFAs (the next state).  Finally, we do the same thing to every DFA\n    that is found and return the list of states.\n    \"\"\"\n    base_nfas = set()\n    start.find_unlabeled_states(base_nfas)\n    state_stack = [DFA(base_nfas, end)]\n    for state in state_stack:\n        arcs = {}\n        for nfa in state.nfas:\n            for label, sub_nfa in nfa.arcs:\n                if label is not None:\n                    sub_nfa.find_unlabeled_states(arcs.setdefault(label, set()))\n        for label, nfa_set in arcs.items():\n            for st in state_stack:\n                if st.nfas == nfa_set:\n                    break\n            else:\n                st = DFA(nfa_set, end)\n                state_stack.append(st)\n            state.arc(st, label)\n    return state_stack"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_wiki_link(self, node):\n        urljoin = import_('urllib.parse', ['urljoin'], via='urlparse')\n\n        t = node.text[2:-2].strip()\n        type = 'wiki'\n        begin = 0\n        if t[:6].lower() == 'image:':\n            type = 'image'\n            begin = 6\n        elif t[:5].lower() == 'wiki:':\n            type = 'wiki'\n            begin = 5\n        \n        t = t[begin:]    \n        if type == 'wiki':\n            _v, caption = (t.split('|', 1) + [''])[:2]\n            name, anchor = (_v.split('#', 1) + [''])[:2]\n            if not caption:\n                caption = name\n            _prefix = self.wiki_prefix\n            if not name:\n                _prefix = ''\n                name = '#' + anchor    \n            else:\n                name = _v\n\n            return self.tag('a', caption, href=\"%s\" % urljoin(_prefix, name))\n        elif type == 'image':\n            _v = (t.split('|') + ['', '', ''])[:4]\n            filename, align, width, height = _v\n            cls = ''\n            if width:\n                if width.isdigit():\n                    cls += ' width=\"%spx\"' % width\n                else:\n                    cls += ' width=\"%s\"' % width\n            if height:\n                if height.isdigit():\n                    cls += ' height=\"%spx\"' % height\n                else:\n                    cls += ' height=\"%s\"' % height\n            \n            s = '<img src=\"%s\" %s/>' % (filename, cls)\n            if align:\n                s = '<div class=\"float%s\">%s</div>' % (align, s)\n            return s", "response": "visit wiki link node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_AF(M,major=0,minor=2):\n    if minor==2:\n        Nhet   = (M==0).sum(axis=0)\n        Nmajor = 2*(M==0).sum(axis=0)\n        Nminor = 2*(M==2).sum(axis=0)\n        af  = Nminor/sp.double(2*M.shape[0])\n    else:\n        Nmajor = (M==0).sum(axis=0)\n        Nminor = (M==1).sum(axis=0)\n        af  = Nminor/sp.double(1*M.shape[0])\n    RV = {}\n    RV['af'] = af\n    RV['Nmajor'] = Nmajor\n    RV['Nminor'] = Nminor\n    return RV", "response": "calculate minor allelel frequency by default assuming that minor == 2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_LD(M,pos,i_start=[0],max_dist=1000000):\n    RV = []\n    DIST = []\n    for start in i_start:\n        pos0 = pos[start]\n        v0  = M[:,start]\n        Iselect = sp.nonzero(sp.absolute(pos-pos0)<=max_dist)[0]\n        rv = sp.zeros(len(Iselect))\n        for i in range(len(Iselect)):\n            rv[i] = (sp.corrcoef(v0,M[:,Iselect[i]])[0,1])**2\n        #sort by distance\n        dist = sp.absolute(pos[Iselect]-pos0)\n        RV.extend(rv)\n        DIST.extend(dist)\n    RV = sp.array(RV)\n    DIST = sp.array(DIST)\n    II = DIST.argsort()\n    return [DIST[II],RV[II]]", "response": "calculate linkage disequilibrium correlations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand_one (self):\n        \"expand the more-to-the-left/outer bracket, return a list of ToExpand's\"\n        data= self.indexes.pop (0)\n\n        left_cb, right_cb= data\n        prefix= self.text[:left_cb]\n        # the body includes the {}'s\n        body= self.text[left_cb:right_cb+1]\n        postfix= self.text[right_cb+1:]\n        # print (\"pre:%r b:%r post:%r\" % (prefix, body, postfix))\n\n        # will hold the expansion of the body\n        expanded= []\n        # do not count the opening bracket\n        last= 1\n        split_here= False\n        comma_found= False\n        # index for the position in the original string of the beginning of\n        # the current body starts\n        # we need it because the indexes are based on the positions on the\n        # original string\n        base= left_cb+1\n\n        for i, c in enumerate (body):\n            if c==',' and body[i-1]!='\\\\':\n                split_here= True\n                # check if this comma belongs to a inner group\n                for l, r in self.indexes:\n                    # TODO: show that this cannot actually happen\n                    if l>right_cb:\n                        # stop searching, this pair is beyond us\n                        break\n\n                    orig_i= base+i\n                    # print (s, l, orig_i, r)\n\n                    if l<orig_i and orig_i<r:\n                        # print 'not splitting, comma @%d(%d) between {%d,%d}' % (orig_i, i, l, r)\n                        split_here= False\n                        # stop searching too\n                        break\n\n                if split_here:\n                    comma_found= True\n                    dst= body[last:i]\n                    te= ToExpand (prefix+dst+postfix)\n                    expanded.append (te)\n                    # print ('split!', expanded)\n                    last= i+1 # point to the next char, not the comma itself\n\n        # only add the last element if a comma was found\n        if comma_found:\n            # do not count the closing bracket\n            dst= body[last:-1]\n            te= ToExpand (prefix+dst+postfix)\n            expanded.append (te)\n            # print ('append', expanded)\n        else:\n            # otherwise, just leave untouched\n            # (except for the index we already removed at the beginning of this method)\n            expanded.append (self)\n\n        return expanded", "response": "expand the more - to - the - left bracket return a list of ToExpand s"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all possible suffixes of an array", "response": "def get_suffixes(arr):\n    \"\"\" Returns all possible suffixes of an array (lazy evaluated)\n    Args:\n        arr: input array\n    Returns:\n        Array of all possible suffixes (as tuples)\n    \"\"\"\n    arr = tuple(arr)\n    return [arr]\n    return (arr[i:] for i in range(len(arr)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluate_callables(data):\n    sequence = ((k, v() if callable(v) else v) for k, v in data.items())\n    return type(data)(sequence)", "response": "Evaluate any callable values in the input dictionary ;\n    returns a new dictionary containing the evaluated results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget user input from command line.", "response": "def prompt(name, default=None):\n    \"\"\"\n    Grab user input from command line.\n\n    :param name: prompt text\n    :param default: default value if no input provided.\n    \"\"\"\n\n    prompt = name + (default and ' [%s]' % default or '')\n    prompt += name.endswith('?') and ' ' or ': '\n    while True:\n        rv = raw_input(prompt)\n        if rv:\n            return rv\n        if default is not None:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prompt_pass(name, default=None):\n\n    prompt = name + (default and ' [%s]' % default or '')\n    prompt += name.endswith('?') and ' ' or ': '\n    while True:\n        rv = getpass.getpass(prompt)\n        if rv:\n            return rv\n        if default is not None:\n            return default", "response": "Prompt user for password."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prompt_bool(name, default=False, yes_choices=None, no_choices=None):\n\n    yes_choices = yes_choices or ('y', 'yes', '1', 'on', 'true', 't')\n    no_choices = no_choices or ('n', 'no', '0', 'off', 'false', 'f')\n\n    while True:\n        rv = prompt(name + '?', default and yes_choices[0] or no_choices[0])\n        if rv.lower() in yes_choices:\n            return True\n        elif rv.lower() in no_choices:\n            return False", "response": "Prompts user for boolean value from command line and converts to boolean."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prompt_choices(name, choices, default=None, no_choice=('none',)):\n\n    _choices = []\n    options = []\n\n    for choice in choices:\n        options.append(choice)\n        _choices.append(choice)\n\n    while True:\n        rv = prompt(name + '? - (%s)' % ', '.join(options), default)\n        rv = rv.lower()\n        if rv in no_choice:\n            return None\n        if rv in _choices:\n            return rv", "response": "Prompts user for user input from command line from set of available choices."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attribute_warfare(object):\n\n    def attribute_warfare_wrapper(attribute):\n        \"\"\"\n        Alterates object attributes using guerilla / monkey patching.\n\n        :param attribute: Attribute to alterate.\n        :type attribute: object\n        :return: Object.\n        :rtype: object\n        \"\"\"\n\n        setattr(object, attribute.__name__, attribute)\n        return attribute\n\n    return attribute_warfare_wrapper", "response": "Alterates object attributes using guerilla / monkey patching.\n\n    :param object: Object to alterate.\n    :type object: object\n    :return: Object.\n    :rtype: object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd any number of attributes to an existing class.", "response": "def base_warfare(name, bases, attributes):\n    \"\"\"\n    Adds any number of attributes to an existing class.\n\n    :param name: Name.\n    :type name: unicode\n    :param bases: Bases.\n    :type bases: list\n    :param attributes: Attributes.\n    :type attributes: dict\n    :return: Base.\n    :rtype: object\n    \"\"\"\n\n    assert len(bases) == 1, \"{0} | '{1}' object has multiple bases!\".format(__name__, name)\n\n    base = foundations.common.get_first_item(bases)\n    for name, value in attributes.iteritems():\n        if name != \"__metaclass__\":\n            setattr(base, name, value)\n    return base"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the object with new data.", "response": "def _update(self, data):\n        \"\"\"Update the object with new data.\"\"\"\n        for k, v in six.iteritems(data):\n            new_value = v\n            if isinstance(v, dict):\n                new_value = type(self)(v)\n            elif isinstance(v, list):\n                new_value = [(type(self)(e) if isinstance(e, dict) else e)\n                             for e in v]\n            setattr(self, k, new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rvs(self, size=1):\n        return np.random.multivariate_normal(self.mean, self.cov, size)", "response": "Convenience method to sample from this distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_message_to_topic(self, topic, message):\n        message_result = self.producer.send(topic, message)\n        self.check_for_message_exception(message_result)\n        return message_result", "response": "Send a message to a Kafka topic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nraising exception if exception is raised.", "response": "def check_for_message_exception(cls, message_result):\n        \"\"\"\n        Makes sure there isn't an error when sending the message.\n        Kafka will silently catch exceptions and not bubble them up.\n\n        Parameters\n        ----------\n        message_result : FutureRecordMetadata\n        \"\"\"\n        exception = message_result.exception\n\n        if isinstance(exception, BaseException):\n            raise exception"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_csv(in_dir, out):\n    writer = UnicodeWriter(open(out, 'wb'), delimiter=';')\n    writer.writerow(('Reference ID', 'Created', 'Origin', 'Subject'))\n    for cable in cables_from_source(in_dir):\n        writer.writerow((cable.reference_id, cable.created, cable.origin, titlefy(cable.subject)))", "response": "\\ Generates the CSV file out from the source directory in_dir."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the source attribute of the object.", "response": "def source(self, value):\n        \"\"\"\n        Setter for **self.__source** attribute.\n\n        :param value: Attribute value.\n        :type value: unicode\n        \"\"\"\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"source\", value)\n            assert os.path.exists(value), \"'{0}' attribute: '{1}' file doesn't exists!\".format(\"source\", value)\n        self.__source = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destination(self, value):\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"destination\", value)\n        self.__destination = value", "response": "Sets the destination of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count(self, value):\n\n        if value is not None:\n            assert type(value) is int, \"'{0}' attribute: '{1}' type is not 'int'!\".format(\n                \"count\", value)\n            assert value > 0, \"'{0}' attribute: '{1}' need to be exactly positive!\".format(\"count\", value)\n        self.__count = value", "response": "Sets the count of the related objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndoes the rotating backup.", "response": "def backup(self):\n        \"\"\"\n        Does the rotating backup.\n\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        LOGGER.debug(\"> Storing '{0}' file backup.\".format(self.__source))\n\n        foundations.common.path_exists(self.__destination) or foundations.io.set_directory(self.__destination)\n        destination = os.path.join(self.__destination, os.path.basename(self.__source))\n        for i in range(self.__count - 1, 0, -1):\n            sfn = \"{0}.{1}\".format(destination, i)\n            dfn = \"{0}.{1}\".format(destination, i + 1)\n            if foundations.common.path_exists(sfn):\n                if foundations.common.path_exists(dfn):\n                    foundations.io.remove(dfn)\n                os.renames(sfn, dfn)\n        foundations.common.path_exists(destination) and os.rename(destination, destination + \".1\")\n        foundations.io.copy(self.__source, destination)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of unique keys in a given hashable sequence while preserving its order.", "response": "def ordered_uniqify(sequence):\n    \"\"\"\n    Uniqifies the given hashable sequence while preserving its order.\n\n    :param sequence: Sequence.\n    :type sequence: object\n    :return: Uniqified sequence.\n    :rtype: list\n    \"\"\"\n\n    items = set()\n    return [key for key in sequence if key not in items and not items.add(key)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unpack_default(iterable, length=3, default=None):\n\n    return itertools.islice(itertools.chain(iter(iterable), itertools.repeat(default)), length)", "response": "Unpacks given iterable maintaining given length filling missing entries with given default."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dependency_resolver(dependencies):\n\n    items = dict((key, set(dependencies[key])) for key in dependencies)\n    resolved_dependencies = []\n    while items:\n        batch = set(item for value in items.values() for item in value) - set(items.keys())\n        batch.update(key for key, value in items.items() if not value)\n        resolved_dependencies.append(batch)\n        items = dict(((key, value - batch) for key, value in items.items() if value))\n    return resolved_dependencies", "response": "Resolves given dependencies.\n\n    :param dependencies: Dependencies to resolve.\n    :type dependencies: dict\n    :return: Resolved dependencies.\n    :rtype: list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn if an internet connection is available.", "response": "def is_internet_available(ips=CONNECTION_IPS, timeout=1.0):\n    \"\"\"\n    Returns if an internet connection is available.\n\n    :param ips: Address ips to check against.\n    :type ips: list\n    :param timeout: Timeout in seconds.\n    :type timeout: int\n    :return: Is internet available.\n    :rtype: bool\n    \"\"\"\n\n    while ips:\n        try:\n            urllib2.urlopen(\"http://{0}\".format(ips.pop(0)), timeout=timeout)\n            return True\n        except IndexError as error:\n            continue\n        except (urllib2.URLError, socket.error) as error:\n            continue\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the given host address.", "response": "def get_host_address(host=None, default_address=DEFAULT_HOST_IP):\n    \"\"\"\n    Returns the given host address.\n\n    :param host: Host to retrieve the address.\n    :type host: unicode\n    :param default_address: Default address if the host is unreachable.\n    :type default_address: unicode\n    :return: Host address.\n    :rtype: unicode\n    \"\"\"\n\n    try:\n        return unicode(socket.gethostbyname(host or socket.gethostname()),\n                       Constants.default_codec,\n                       Constants.codec_error)\n    except Exception as error:\n        return default_address"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the data received as keyword arguments whose name match this class attributes.", "response": "def validate(cls, **kwargs):\n        ''' Validates the data received as keyword arguments whose name match\n        this class attributes. '''\n        # errors can store multiple errors\n        # obj is an instance in case validation succeeds\n        # redis is needed for database validation\n        errors = ValidationErrors()\n        obj = cls()\n        redis = cls.get_redis()\n\n        # Check the fields\n        for fieldname, field in obj.proxy:\n            if not field.fillable:\n                value = field.default\n            else:\n                try:\n                    value = field.validate(kwargs.get(fieldname), redis)\n                except BadField as e:\n                    errors.append(e)\n                    continue\n\n            setattr(\n                obj,\n                fieldname,\n                value\n            )\n\n        # Check for custom validation rules\n        for fieldname in dir(cls):\n            rule = getattr(cls, fieldname)\n\n            if hasattr(rule, '_is_validation_rule') and rule._is_validation_rule:\n                try:\n                    rule(obj)\n                except BadField as e:\n                    errors.append(e)\n\n        # Trigger errors if any\n        if errors.has_errors():\n            raise errors\n\n        # Return the object with the new data set\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the given coralillo engine so the model uses it to communicate with the redis database", "response": "def set_engine(cls, neweng):\n        ''' Sets the given coralillo engine so the model uses it to communicate\n        with the redis database '''\n        assert isinstance(neweng, Engine), 'Provided object must be of class Engine'\n\n        if hasattr(cls, 'Meta'):\n            cls.Meta.engine = neweng\n        else:\n            class Meta:\n                engine = neweng\n\n            cls.Meta = Meta"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npersisting this object to the database.", "response": "def save(self):\n        ''' Persists this object to the database. Each field knows how to store\n        itself so we don't have to worry about it '''\n        redis = type(self).get_redis()\n        pipe = to_pipeline(redis)\n\n        pipe.hset(self.key(), 'id', self.id)\n\n        for fieldname, field in self.proxy:\n            if not isinstance(field, Relation):\n                field.save(getattr(self, fieldname), pipe, commit=False)\n\n        pipe.sadd(type(self).members_key(), self.id)\n\n        pipe.execute()\n\n        if self.notify:\n            data = json.dumps({\n                'event': 'create' if not self._persisted else 'update',\n                'data': self.to_json(),\n            })\n            redis.publish(type(self).cls_key(), data)\n            redis.publish(self.key(), data)\n\n        self._persisted = True\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, **kwargs):\n        ''' validates the given data against this object's rules and then\n        updates '''\n        redis = type(self).get_redis()\n        errors = ValidationErrors()\n\n        for fieldname, field in self.proxy:\n            if not field.fillable:\n                continue\n\n            given = kwargs.get(fieldname)\n\n            if given is None:\n                continue\n\n            try:\n                value = field.validate(kwargs.get(fieldname), redis)\n            except BadField as e:\n                errors.append(e)\n                continue\n\n            setattr(\n                self,\n                fieldname,\n                value\n            )\n\n        if errors.has_errors():\n            raise errors\n\n        return self.save()", "response": "validates the given data against this object s rules and then updates the object s attributes and returns True if the object was updated False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(cls, id):\n        ''' Retrieves an object by id. Returns None in case of failure '''\n\n        if not id:\n            return None\n\n        redis = cls.get_redis()\n        key = '{}:{}:obj'.format(cls.cls_key(), id)\n\n        if not redis.exists(key):\n            return None\n\n        obj = cls(id=id)\n        obj._persisted = True\n\n        data = debyte_hash(redis.hgetall(key))\n\n        for fieldname, field in obj.proxy:\n            value = field.recover(data, redis)\n\n            setattr(\n                obj,\n                fieldname,\n                value\n            )\n\n        return obj", "response": "Returns an object by id. Returns None in case of failure"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator over the members of this class that applies the given filters and returns only the elements matching the keys in the keys set", "response": "def q(cls, **kwargs):\n        ''' Creates an iterator over the members of this class that applies the\n        given filters and returns only the elements matching them '''\n        redis = cls.get_redis()\n\n        return QuerySet(cls, redis.sscan_iter(cls.members_key()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreloading this object so if it was updated in the database it now contains the new values", "response": "def reload(self):\n        ''' reloads this object so if it was updated in the database it now\n        contains the new values'''\n        key = self.key()\n        redis = type(self).get_redis()\n\n        if not redis.exists(key):\n            raise ModelNotFoundError('This object has been deleted')\n\n        data = debyte_hash(redis.hgetall(key))\n\n        for fieldname, field in self.proxy:\n            value = field.recover(data, redis)\n\n            setattr(\n                self,\n                fieldname,\n                value\n            )\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_or_exception(cls, id):\n        ''' Tries to retrieve an instance of this model from the database or\n        raises an exception in case of failure '''\n        obj = cls.get(id)\n\n        if obj is None:\n            raise ModelNotFoundError('This object does not exist in database')\n\n        return obj", "response": "Tries to retrieve an instance of this model from the database or raises an exception in case of failure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to retrieve an isinstance of this model from the database given a value for a defined index. Return None in case of failure", "response": "def get_by(cls, field, value):\n        ''' Tries to retrieve an isinstance of this model from the database\n        given a value for a defined index. Return None in case of failure '''\n        redis = cls.get_redis()\n        key = cls.cls_key()+':index_'+field\n\n        id = redis.hget(key, value)\n\n        if id:\n            return cls.get(debyte_string(id))\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all(cls):\n        ''' Gets all available instances of this model from the database '''\n        redis = cls.get_redis()\n\n        return list(map(\n            lambda id: cls.get(id),\n            map(\n                debyte_string,\n                redis.smembers(cls.members_key())\n            )\n        ))", "response": "Gets all available instances of this model from the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a tree index retrieves the ids atached to the given prefix and returns the set of ids that match the given string.", "response": "def tree_match(cls, field, string):\n        ''' Given a tree index, retrieves the ids atached to the given prefix,\n        think of if as a mechanism for pattern suscription, where two models\n        attached to the `a`, `a:b` respectively are found by the `a:b` string,\n        because both model's subscription key matches the string. '''\n        if not string:\n            return set()\n\n        redis = cls.get_redis()\n        prefix = '{}:tree_{}'.format(cls.cls_key(), field)\n        pieces = string.split(':')\n\n        ans =  redis.sunion(\n            prefix + ':' + ':'.join(pieces[0:i+1])\n            for i in range(len(pieces))\n        )\n\n        return sorted(map(\n            lambda id: cls.get(id),\n            map(\n                debyte_string,\n                ans\n            )\n        ), key=lambda x:x.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the redis key to access this object s values", "response": "def key(self):\n        ''' Returns the redis key to access this object's values '''\n        prefix = type(self).cls_key()\n\n        return '{}:{}:obj'.format(prefix, self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a fully qualified name for this object", "response": "def fqn(self):\n        ''' Returns a fully qualified name for this object '''\n        prefix = type(self).cls_key()\n\n        return '{}:{}'.format(prefix, self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_json(self, *, include=None):\n        ''' Serializes this model to a JSON representation so it can be sent\n        via an HTTP REST API '''\n        json = dict()\n\n        if include is None or 'id' in include or '*' in include:\n            json['id'] = self.id\n\n        if include is None or '_type' in include or '*' in include:\n            json['_type'] = type(self).cls_key()\n\n        def fieldfilter(fieldtuple):\n            return \\\n                not fieldtuple[1].private and \\\n                not isinstance(fieldtuple[1], Relation) and (\n                    include is None or fieldtuple[0] in include or '*' in include\n                )\n\n        json.update(dict(starmap(\n            lambda fn, f: (fn, f.to_json(getattr(self, fn))),\n            filter(\n                fieldfilter,\n                self.proxy\n            )\n        )))\n\n        for requested_relation in parse_embed(include):\n            relation_name, subfields = requested_relation\n\n            if not hasattr(self.proxy, relation_name):\n                continue\n\n            relation = getattr(self.proxy, relation_name)\n\n            if isinstance(relation, ForeignIdRelation):\n                item = relation.get()\n\n                if item is not None:\n                    json[relation_name] = item.to_json(include=subfields)\n                else:\n                    json[relation_name] = None\n            elif isinstance(relation, MultipleRelation):\n                json[relation_name] = list(map(lambda o: o.to_json(include=subfields), relation.get()))\n\n        return json", "response": "Serializes this model to a JSON representation so it can be sent to an HTTP REST API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self):\n        ''' Deletes this model from the database, calling delete in each field\n        to properly delete special cases '''\n        redis = type(self).get_redis()\n\n        for fieldname, field in self.proxy:\n            field.delete(redis)\n\n        redis.delete(self.key())\n        redis.srem(type(self).members_key(), self.id)\n\n        if isinstance(self, PermissionHolder):\n            redis.delete(self.allow_key())\n\n        if self.notify:\n            data = json.dumps({\n                'event': 'delete',\n                'data': self.to_json(),\n            })\n            redis.publish(type(self).cls_key(), data)\n            redis.publish(self.key(), data)\n\n        return self", "response": "Deletes this object from the database calling delete in each field\n            to properly delete special cases"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new Telegraph account.", "response": "def createAccount(self, short_name, author_name=None, author_url=None):\r\n        \"\"\"Creates Telegraph account\r\n\r\n        :param short_name: Required. Account name, helps users with several accounts remember which they are currently using.\r\n        Displayed to the user above the \"Edit/Publish\" button on Telegra.ph, other users don't see this name.\r\n        :type short_name: str\r\n\r\n        :param author_name: Optional. Default author name used when creating new articles.\r\n        :type author_name: str\r\n\r\n        :param author_url: Optional. Default profile link, opened when users click on the author's name below the title.\r\n        Can be any link, not necessarily to a Telegram profile or channel.\r\n        :type author_url: str\r\n\r\n        :returns: Account object with the regular fields and an additional access_token field.\r\n        \"\"\"\r\n        r = self.make_method(\"createAccount\", {\r\n            \"short_name\": short_name,\r\n            \"author_name\": author_name,\r\n            \"author_url\": author_url\r\n        })\r\n        self.access_token = r['access_token']\r\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to update information about a Telegraph account.", "response": "def editAccountInfo(self, short_name=None, author_name=None, author_url=None):\r\n        \"\"\"Use this method to update information about a Telegraph account.\r\n\r\n        :param short_name: Optional. New account name.\r\n        :type short_name: str\r\n\r\n        :param author_name: Optional. New default author name used when creating new articles.\r\n        :type author_name: str\r\n\r\n        :param author_url: Optional. New default profile link, opened when users click on\r\n        the author's name below the title.\r\n        Can be any link, not necessarily to a Telegram profile or channel.\r\n        :type author_url: str\r\n\r\n        :returns: Account object with the default fields.\r\n        \"\"\"\r\n        return self.make_method(\"editAccountInfo\", {\r\n            \"access_token\": self.access_token,\r\n            \"short_name\": short_name,\r\n            \"author_name\": author_name,\r\n            \"author_url\": author_url\r\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAccountInfo(self, fields=None):\r\n        return self.make_method(\"getAccountInfo\", {\r\n            \"access_token\": self.access_token,\r\n            \"fields\": json.dumps(fields) if fields else None\r\n        })", "response": "Use this method to get information about a Telegraph account."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createPage(self, title, author_name=None, author_url=None,\r\n                   content=None, html_content=None, return_content=False):\r\n        \"\"\"Use this method to create a new Telegraph page.\r\n        :param title: Required. Page title.\r\n        :type title: str\r\n\r\n        :param author_name: Optional. Author name, displayed below the article's title.\r\n        :type author_name: str\r\n\r\n        :param author_url: Optional. Profile link, opened when users click on the author's name below the title.\r\n        Can be any link, not necessarily to a Telegram profile or channel.\r\n        :type author_url: str\r\n\r\n        :param content: Required. Content of the page in NODES format.\r\n\r\n        :param html_content: Optional. Content of the page in HTML format.\r\n        :type html_content: str\r\n\r\n        :param return_content: Optional. If true, a content field will be returned in the Page object\r\n        :type return_content: bool\r\n\r\n        :returns: Page object.\r\n        \"\"\"\r\n        if content is None:\r\n            content = html_to_nodes(html_content)\r\n        return self.make_method(\"createPage\", {\r\n            \"access_token\": self.access_token,\r\n            \"title\": title,\r\n            \"author_name\": author_name,\r\n            \"author_url\": author_url,\r\n            \"content\": json.dumps(content),\r\n            \"return_content\": return_content\r\n        })", "response": "Use this method to create a new Telegraph page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef editPage(self, path, title, content=None, html_content=None,\r\n                 author_name=None, author_url=None, return_content=False):\r\n        \"\"\"Use this method to edit an existing Telegraph page.\r\n\r\n        :param path: Required. Path to the page.\r\n        :type path: str\r\n\r\n        :param title: Required. Page title.\r\n        :type title: str\r\n\r\n        :param content: Required. Content of the page in NODES format.\r\n\r\n        :param html_content: Optional. Content of the page in HTML format.\r\n        :type html_content: str\r\n\r\n        :param author_name: Optional. Author name, displayed below the article's title.\r\n        :type author_name: str\r\n\r\n        :param author_url: Optional. Profile link, opened when users click on the author's name below the title.\r\n        Can be any link, not necessarily to a Telegram profile or channel.\r\n        :type author_url: str\r\n\r\n        :param return_content: Optional. If true, a content field will be returned in the Page object.\r\n        :type return_content: bool\r\n\r\n        :returns: Page object.\r\n        \"\"\"\r\n        if content is None:\r\n            content = html_to_nodes(html_content)\r\n        if path is None:\r\n            raise TelegraphAPIException(\"Error while executing editPage: \"\r\n                                        \"PAGE_NOT_FOUND\")\r\n        r = requests.post(BASE_URL + \"editPage/\" + path, data={\r\n            \"access_token\": self.access_token,\r\n            \"title\": title,\r\n            \"content\": json.dumps(content),\r\n            \"author_name\": author_name,\r\n            \"author_url\": author_url,\r\n            \"return_content\": return_content\r\n        })\r\n        if r.json()['ok'] is not True:\r\n            raise TelegraphAPIException(\"Error while executing editPage: \" +\r\n                                        r.json()['error'])\r\n        return r.json()['result']", "response": "Use this method to edit an existing Telegraph page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getPage(self, path, return_content=True, return_html=True):\r\n        if path is None:\r\n            raise TelegraphAPIException(\"Error while executing getPage: \"\r\n                                        \"PAGE_NOT_FOUND\")\r\n        r = requests.post(BASE_URL + \"getPage/\" + path, data={\r\n            \"return_content\": return_content\r\n        })\r\n        if r.json()['ok'] is not True:\r\n            raise TelegraphAPIException(\"Error while executing getPage: \" +\r\n                                        r.json()['error'])\r\n        if return_content and return_html:\r\n            r.json()['result']['content'] = nodes_to_html(r.json()['result']['content'])\r\n        return r.json()['result']", "response": "Use this method to get a Telegraph page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPageList(self, offset=0, limit=50):\r\n\r\n        return self.make_method(\"getPageList\", {\r\n            \"access_token\": self.access_token,\r\n            \"offset\": offset,\r\n            \"limit\": limit\r\n        })", "response": "Use this method to get a list of pages belonging to a Telegraph account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getViews(self, path, year=None, month=None, day=None, hour=None):\r\n        if path is None:\r\n            raise TelegraphAPIException(\"Error while executing getViews: \"\r\n                                        \"PAGE_NOT_FOUND\")\r\n        r = requests.post(BASE_URL + \"getViews/\" + path, data={\r\n            \"year\": year,\r\n            \"month\": month,\r\n            \"day\": day,\r\n            \"hour\": hour,\r\n        })\r\n        if r.json()['ok'] is not True:\r\n            raise TelegraphAPIException(\"Error while executing getViews: \" +\r\n                                        r.json()['error'])\r\n        return r.json()['result']", "response": "Use this method to get the number of views for a Telegraph article."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init(self):\n        # remove root logger, so we can reinit\n        # TODO only remove our own\n        # TODO move to _init, let overrides use init()\n        logging.getLogger().handlers = []\n\n        if self.debug:\n            logging.basicConfig(level=logging.DEBUG, format=self.log_format_debug)\n        elif self.verbose:\n            logging.basicConfig(level=logging.INFO, format=self.log_format)\n        elif not self.quiet:\n            logging.basicConfig(level=logging.ERROR, format=self.log_format)\n        else:\n            logging.getLogger().addHandler(logging.NullHandler())", "response": "Initialize the logging module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cable_from_file(filename):\n    html = codecs.open(filename, 'rb', 'utf-8').read()\n    return cable_from_html(html, reader.reference_id_from_filename(filename))", "response": "\\ Returns a cable from the provided file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wl_uris(self):\n        def year_month(d):\n            date, time = d.split()\n            return date.split('-')[:2]\n        if not self.created:\n            raise ValueError('The \"created\" property must be provided')\n        year, month = year_month(self.created)\n        l = u'%s/%s/%s' % (year, month, self.reference_id)\n        html = l + u'.html'\n        wl_uris = []\n        append = wl_uris.append\n        for wl in _WL_CABLE_BASE_URIS:\n            append(wl + l)\n            append(wl + html)\n        return wl_uris", "response": "\\ Returns a list of cable IRIs to WikiLeaks."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate an access token endpoint.", "response": "def access_token_endpoint(request):\n  \"\"\" Generates :py:class:`djoauth2.models.AccessTokens` if provided with\n  sufficient authorization.\n\n  This endpoint only supports two grant types:\n    * ``authorization_code``: http://tools.ietf.org/html/rfc6749#section-4.1\n    * ``refresh_token``: http://tools.ietf.org/html/rfc6749#section-6\n\n  For further documentation, read http://tools.ietf.org/html/rfc6749#section-3.2\n  \"\"\"\n  # TODO(peter): somehow implement the anti-brute-force requirement specified\n  # by http://tools.ietf.org/html/rfc6749#section-2.3.1 :\n  #\n  #     Since this client authentication method involves a password, the\n  #     authorization server MUST protect any endpoint utilizing it against\n  #     brute force attacks.\n  #\n\n  try:\n    # From http://tools.ietf.org/html/rfc6749#section-3.2 :\n    #\n    #     Since requests to the token endpoint result in the transmission of\n    #     clear-text credentials (in the HTTP request and response), the\n    #     authorization server MUST require the use of TLS as described in\n    #     Section 1.6 when sending requests to the token endpoint.\n    #\n    if settings.DJOAUTH2_SSL_ONLY and not request.is_secure():\n      raise InvalidRequest('all token requests must use TLS')\n\n    # From http://tools.ietf.org/html/rfc6749#section-3.2 :\n    #\n    #     The client MUST use the HTTP \"POST\" method when making access token\n    #     requests.\n    #\n    if not request.method == 'POST':\n      raise InvalidRequest('all posts must use POST')\n\n    client_id = None\n    client_secret = None\n\n    # Allow client Authentication via HTTP Basic Authentication (\n    # http://tools.ietf.org/html/rfc2617#section-2 ) as described by\n    # http://tools.ietf.org/html/rfc6749#section-2.3.1 :\n    #\n    #     Clients in possession of a client password MAY use the HTTP Basic\n    #     authentication scheme as defined in [RFC2617] to authenticate with\n    #     the authorization server.  The client identifier is encoded using the\n    #     \"application/x-www-form-urlencoded\" encoding algorithm per Appendix\n    #     B, and the encoded value is used as the username; the client password\n    #     is encoded using the same algorithm and used as the password.  The\n    #     authorization server MUST support the HTTP Basic authentication\n    #     scheme for authenticating clients that were issued a client password.\n    #\n    # by accepting an 'Authorization' header like so:\n    #\n    #      Authorization: Basic czZCaGRSa3F0Mzo3RmpmcDBaQnIxS3REUmJuZlZkbUl3\n    #\n    # where 'czZCaGRSa3F0Mzo3RmpmcDBaQnIxS3REUmJuZlZkbUl3' is the result of\n    #\n    #     base64encode('{client_id}:{client_secret}')\n    #\n    if 'HTTP_AUTHORIZATION' in request.META:\n      try:\n        http_authorization = request.META.get('HTTP_AUTHORIZATION', '')\n        auth_method, auth_value = http_authorization.strip().split(' ', 1)\n      except ValueError:\n        raise InvalidRequest('malformed HTTP_AUTHORIZATION header')\n\n      if not auth_method == 'Basic':\n        raise InvalidRequest('unsupported HTTP_AUTHORIZATION method')\n\n      try:\n        client_id, client_secret = b64decode(auth_value).split(':')\n      except (TypeError, ValueError):\n        raise InvalidRequest('malformed HTTP_AUTHORIZATION value')\n\n\n    # The 'client_id' and 'client_secret' parameters MUST NOT be included in\n    # the request URI (GET parameters), as specified by\n    # http://tools.ietf.org/html/rfc6749#section-2.3.1 :\n    #\n    #     The parameters can only be transmitted in the request-body and MUST\n    #     NOT be included in the request URI.\n    #\n    if 'client_id' in request.GET or 'client_secret' in request.GET:\n      raise InvalidRequest(\n          'must not include \"client_id\" or \"client_secret\" in request URI')\n\n\n    # Allow Clients to authenticate via POST request data, as specified by\n    # http://tools.ietf.org/html/rfc6749#section-3.2.1 :\n    #\n    #     A client MAY use the \"client_id\" request parameter to identify itself\n    #     when sending requests to the token endpoint.  In the\n    #     \"authorization_code\" \"grant_type\" request to the token endpoint, an\n    #     unauthenticated client MUST send its \"client_id\" to prevent itself\n    #     from inadvertently accepting a code intended for a client with a\n    #     different \"client_id\".  This protects the client from substitution of\n    #     the authentication code. (It provides no additional security for the\n    #     protected resource.)\n    #\n    # Please note that this is NOT RECOMMENDED, and that the client should\n    # instead authenticate via the HTTP_AUTHORIZATION header -- see\n    # http://tools.ietf.org/html/rfc6749#section-2.3.1 :\n    #\n    #     Alternatively, the authorization server MAY support including the\n    #     client credentials in the request-body using the following parameters:\n    #\n    #     client_id\n    #           REQUIRED.  The client identifier issued to the client during\n    #           the registration process described by Section 2.2.\n    #\n    #     client_secret\n    #           REQUIRED.  The client secret.  The client MAY omit the\n    #           parameter if the client secret is an empty string.\n    #\n    #     Including the client credentials in the request-body using the two\n    #     parameters is NOT RECOMMENDED and SHOULD be limited to clients unable\n    #     to directly utilize the HTTP Basic authentication scheme (or other\n    #     password-based HTTP authentication schemes).  The parameters can only\n    #     be transmitted in the request-body and MUST NOT be included in the\n    #     request URI.\n    #\n    # In the case that the Client has already authenticated with the\n    # HTTP_AUTHORIZATION method, ensure that they do not also attempt to\n    # authenticate via POST data, as required by\n    # http://tools.ietf.org/html/rfc6749#section-2.3 :\n    #\n    #     The client MUST NOT use more than one authentication method in each\n    #     request.\n    #\n    if client_id and client_secret:\n      if 'client_id' in request.POST or 'client_secret' in request.POST:\n        raise InvalidRequest('must use only one authentication method')\n    else:\n      client_id = request.POST.get('client_id')\n      client_secret = request.POST.get('client_secret')\n\n    if not (client_id and client_secret):\n      raise InvalidRequest('no client authentication provided')\n\n    try:\n      client = Client.objects.get(key=client_id, secret=client_secret)\n    except Client.DoesNotExist:\n      raise InvalidClient('client authentication failed')\n\n    # The two supported grant types\n    grant_type = request.POST.get('grant_type')\n    if not grant_type:\n      raise InvalidRequest('no \"grant_type\" provided')\n\n    if grant_type == 'authorization_code':\n      access_token = generate_access_token_from_authorization_code(request,\n                                                                   client)\n    elif grant_type == 'refresh_token':\n      access_token = generate_access_token_from_refresh_token(request, client)\n    else:\n      raise UnsupportedGrantType(\n          '\"{}\" is not a supported \"grant_type\"'.format(grant_type))\n\n    # Successful response documentation:\n    # http://tools.ietf.org/html/rfc6749#section-5.1\n    response_data = {\n        'access_token': access_token.value,\n        'expires_in': access_token.lifetime,\n        'token_type': 'bearer', # http://tools.ietf.org/html/rfc6749#section-7.1\n        'scope': ' '.join(access_token.get_scope_names_set()),\n      }\n    if access_token.refreshable:\n      response_data['refresh_token'] = access_token.refresh_token\n\n    response = HttpResponse(content=json.dumps(response_data),\n                            content_type='application/json')\n    response.status_code = 200\n    response['Cache-Control'] = 'no-store'\n    response['Pragma'] = 'no-cache'\n    return response\n\n  except AccessTokenError as generation_error:\n    # Error response documentation:\n    # http://tools.ietf.org/html/rfc6749#section-5.2\n    error_name = getattr(generation_error,\n                         'error_name',\n                         'invalid_request')\n    error_description = str(generation_error) or 'Invalid Request.'\n    response_data = {\n        'error':  error_name,\n        'error_description': error_description,\n      }\n\n    response = HttpResponse(content=json.dumps(response_data),\n                            content_type='application/json')\n    if isinstance(generation_error, InvalidClient):\n      response.status_code = 401\n    else:\n      response.status_code = 400\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_access_token_from_authorization_code(request, client):\n  authorization_code_value = request.POST.get('code')\n  if not authorization_code_value:\n    raise InvalidRequest('no \"code\" provided')\n\n  try:\n    authorization_code = AuthorizationCode.objects.get(\n        value=authorization_code_value,\n        client=client)\n  except AuthorizationCode.DoesNotExist:\n    raise InvalidGrant(\n        '\"{}\" is not a valid \"code\"'.format(authorization_code_value))\n\n  if authorization_code.is_expired():\n    if authorization_code.invalidated:\n      for access_token in authorization_code.access_tokens.all():\n        access_token.invalidate()\n\n    raise InvalidGrant('provided \"code\" is expired')\n\n  # From http://tools.ietf.org/html/rfc6749#section-4.1.3:\n  #\n  #     redirect_uri\n  #         REQUIRED, if the \"redirect_uri\" parameter was included in the\n  #         authorization request as described in Section 4.1.1, and their\n  #         values MUST be identical.\n  #\n  # and later,\n  #\n  #     The authorization server MUST:\n  #\n  #     [ ... snip ... ]\n  #\n  #     o  ensure that the \"redirect_uri\" parameter is present if the\n  #        \"redirect_uri\" parameter was included in the initial authorization\n  #        request as described in Section 4.1.1, and if included ensure that\n  #        their values are identical.\n  #\n  # The 'redirect_uri' attribute of an AuthorizationCode will only be set if\n  # the value was included as a parameter during the related authorization\n  # request.\n  if (authorization_code.redirect_uri and\n      authorization_code.redirect_uri != request.POST.get('redirect_uri')):\n    raise InvalidRequest('\"redirect_uri\" value must match the value from '\n                         'the authorization code request')\n\n  new_access_token = AccessToken.objects.create(\n      user=authorization_code.user,\n      client=authorization_code.client)\n  new_access_token.scopes = authorization_code.scopes.all()\n  new_access_token.authorization_code = authorization_code\n  new_access_token.save()\n\n  # Mark this token as expired so that any future requests with the same token\n  # can be handled with the correct behavior. From\n  # http://tools.ietf.org/html/rfc6749#section-4.1.2 :\n\n  #     The client MUST NOT use the authorization code more than once.\n  authorization_code.invalidate()\n\n  return new_access_token", "response": "Generates an AccessToken from a request with an authorization code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_access_token_from_refresh_token(request, client):\n  refresh_token_value = request.POST.get('refresh_token')\n  if not refresh_token_value:\n    raise InvalidRequest('no \"refresh_token\" provided')\n\n  try:\n    existing_access_token = AccessToken.objects.get(\n        refresh_token=refresh_token_value,\n        client=client)\n  except AccessToken.DoesNotExist:\n    raise InvalidGrant('\"{}\" is not a valid \"refresh_token\"'.format(\n      refresh_token_value))\n\n  if existing_access_token.invalidated:\n    refresh_token_used_after_invalidation.send(\n        sender='djoauth2',\n        access_token=existing_access_token,\n        request=request)\n    raise InvalidGrant('\"{}\" is not a valid \"refresh_token\"'.format(\n      refresh_token_value))\n\n  if not existing_access_token.refreshable:\n    raise InvalidGrant('access token is not refreshable')\n\n  # The specification (http://tools.ietf.org/html/rfc6749#section-6) describes\n  # the scope parameter as follows:\n  #\n  #     scope\n  #           OPTIONAL.  The scope of the access request as described by\n  #           Section 3.3.  The requested scope MUST NOT include any\n  #           scope not originally granted by the resource owner, and if\n  #           omitted is treated as equal to the scope originally granted\n  #           by the resource owner.\n  #\n  # This opens the possibility that a Client might successfully request a\n  # subset of the existing scopes, but later in the same section comes the\n  # following:\n  #\n  #      If a new refresh token is issued, the refresh token scope MUST be\n  #      identical to that of the refresh token included by the client in the\n  #      request.\n  #\n  # Confusingly, http://tools.ietf.org/html/rfc6749#section-1.5 includes the\n  # following:\n  #\n  #     Refresh tokens are credentials used to obtain access tokens.  Refresh\n  #     tokens are issued to the client by the authorization server and are\n  #     used to obtain a new access token when the current access token becomes\n  #     invalid or expires, or to obtain additional access tokens with\n  #     identical or narrower scope (access tokens may have a shorter lifetime\n  #     and fewer permissions than authorized by the resource owner).\n  #\n  # This last section explicitly allows tokens with narrower scope than\n  # originally granted, which is in direct contradiction with the directive\n  # that the scope must be equivalent to that granted earlier.\n  #\n  # Because the specification seems to contradict itself, I tend towards\n  # observing the stricter directive (not allowing a subset of scope,) even\n  # though to me there seems to be no reason to disallow that feature. That\n  # said, I'm not sure why a client would ever ask for less scope than\n  # originally granted.\n  scope_objects = existing_access_token.scopes.all()\n  new_scope_names = request.POST.get('scope', '')\n  if new_scope_names:\n    new_scope_names = new_scope_names.split(' ')\n    if not existing_access_token.has_scope(*new_scope_names):\n      raise InvalidScope('requested scopes exceed initial grant')\n\n    scope_objects = []\n    for scope_name in new_scope_names:\n      try:\n        scope_objects.append(Scope.objects.get(name=scope_name))\n      except Scope.DoesNotExist:\n        raise InvalidScope('\"{}\" is not a valid scope'.format(scope_name))\n\n  requested_scope_string = request.POST.get('scope', '')\n  if requested_scope_string:\n    requested_scope_names = set(requested_scope_string.split(' '))\n    if not requested_scope_names == existing_access_token.get_scope_names_set():\n      raise InvalidScope('requested scopes do not match initial grant')\n\n\n  # The new AccessToken is only refreshable if at the time of refresh the\n  # server is configured to create refreshable tokens by default. It DOES NOT\n  # inherit the existing token's 'refreshability' automatically. No behavior is\n  # described in the specification; I believe this to be a sane decision.\n  new_access_token = AccessToken.objects.create(\n      user=existing_access_token.user,\n      client=existing_access_token.client)\n  new_access_token.authorization_code = existing_access_token.authorization_code\n  new_access_token.scopes = scope_objects\n  new_access_token.save()\n\n  existing_access_token.invalidate()\n\n  return new_access_token", "response": "Generates a new AccessToken from a request containing a refresh token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef help(project, task, step, variables):\n\n    task_name = step.args or variables['task']\n\n    try:\n        task = project.find_task(task_name)\n    except NoSuchTaskError as e:\n        yield events.task_not_found(task_name, e.similarities)\n        raise StopTask\n\n    text = f'# {task.name}\\n'\n    text += '\\n'\n    text += task.description\n    text += '\\n\\n'\n    text += 'Variables: {}'.format(', '.join(task.variables))\n\n    yield events.help_output(text)", "response": "Run a help step."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noption parser for the", "response": "def option_parser():\n    \"\"\"\n    :return: Option parsing object :: optparse.OptionParser\n    \"\"\"\n    defaults = dict(template_paths=[], contexts=[], schema=None, output='-',\n                    engine=None, list_engines=False, verbose=1)\n\n    psr = argparse.ArgumentParser()\n    psr.set_defaults(**defaults)\n\n    psr.add_argument(\"template\", type=str, nargs=\"?\",\n                     help=\"Template file path\")\n    psr.add_argument(\"-T\", \"--template-path\", action=\"append\",\n                     dest=\"template_paths\",\n                     help=\"Template search path can be specified multiple \"\n                          \"times. Note: Dir in which given template exists is \"\n                          \"always included in the search paths (at the end of \"\n                          \"the path list) regardless of this option. \")\n    psr.add_argument(\"-C\", \"--context\", action=\"append\", dest=\"contexts\",\n                     help=\"Specify file path and optionally its filetype, to \"\n                          \"provides context data to instantiate templates. \"\n                          \" The option argument's format is \"\n                          \" [type:]<file_name_or_path_or_glob_pattern>\"\n                          \" ex. -C json:common.json -C ./specific.yaml -C \"\n                          \"yaml:test.dat, -C yaml:/etc/foo.d/*.conf\")\n    psr.add_argument(\"-s\", \"--schema\",\n                     help=\"JSON schema file in any formats anyconfig \"\n                          \"supports, to validate context files\")\n    psr.add_argument(\"-E\", \"--engine\",\n                     help=\"Specify template engine name such as 'jinja2'\")\n    psr.add_argument(\"-L\", \"--list-engines\", action=\"store_true\",\n                     help=\"List supported template engines in your \"\n                          \"environment\")\n    psr.add_argument(\"-o\", \"--output\", help=\"Output filename [stdout]\")\n    psr.add_argument(\"-v\", \"--verbose\", action=\"store_const\", const=0,\n                     help=\"Verbose mode\")\n    psr.add_argument(\"-q\", \"--quiet\", action=\"store_const\", const=2,\n                     dest=\"verbose\", help=\"Quiet mode\")\n    return psr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_loglevel(level):\n    try:\n        return [logging.DEBUG, logging.INFO, logging.WARN][level]\n    except IndexError:\n        return logging.INFO", "response": "Set log level.\n\n    >>> assert get_loglevel(2) == logging.WARN\n    >>> assert get_loglevel(10) == logging.INFO"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n\n    psr = option_parser()\n    args = psr.parse_args(argv[1:])\n\n    if not args.template:\n        if args.list_engines:\n            ecs = anytemplate.api.list_engines()\n            print(\", \".join(\"%s (%s)\" % (e.name(), e.priority()) for e in ecs))\n            sys.exit(0)\n        else:\n            psr.print_usage()\n            sys.exit(1)\n\n    LOGGER.setLevel(get_loglevel(args.verbose))\n\n    ctx = {}\n\n    if args.contexts:\n        LOGGER.info(\"Loading contexts: %r ...\", args.contexts[:3])\n        ctx = anytemplate.utils.parse_and_load_contexts(args.contexts,\n                                                        args.schema)\n    anytemplate.api.render_to(args.template, ctx, args.output,\n                              at_paths=args.template_paths,\n                              at_engine=args.engine, at_ask_missing=True)", "response": "Entrypoint. main entry point."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the cache token and data from Redis", "response": "def get_cache_token(self, token):\n        \"\"\" Get token and data from Redis \"\"\"\n\n        if self.conn is None:\n            raise CacheException('Redis is not connected')\n\n        token_data = self.conn.get(token)\n        token_data = json.loads(token_data) if token_data else None\n\n        return token_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting Token with data in Redis", "response": "def set_cache_token(self, token_data):\n        \"\"\" Set Token with data in Redis \"\"\"\n\n        if self.conn is None:\n            raise CacheException('Redis is not connected')\n\n        token = token_data['auth_token']\n        token_expires = token_data['expires_at']\n        roles = token_data['roles']\n\n        try:\n            datetime_object = datetime.strptime(\n                token_expires, '%Y-%m-%dT%H:%M:%S.%fZ')\n        except ValueError:\n            datetime_object = datetime.strptime(\n                token_expires, '%Y-%m-%dT%H:%M:%SZ')\n\n        ttl = (datetime.utcnow().now() - datetime_object)\n        token_data = json.dumps({\n            'expires_at': token_expires,\n            'roles': roles,\n            'user': token_data['user']\n        })\n\n        self.conn.set(token, token_data, ex=ttl.seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntype and boundary check'''", "response": "def check_config(conf):\n    '''Type and boundary check'''\n    if 'fmode' in conf and not isinstance(conf['fmode'], string_types):\n        raise TypeError(TAG + \": `fmode` must be a string\")\n\n    if 'dmode' in conf and not isinstance(conf['dmode'], string_types):\n        raise TypeError(TAG + \": `dmode` must be a string\")\n\n    if 'depth' in conf:\n        if not isinstance(conf['depth'], int):\n            raise TypeError(TAG + \": `depth` must be an int\")\n        if conf['depth'] < 0:\n            raise ValueError(TAG + \": `depth` must be a positive number\")\n\n    if 'hash_alg' in conf:\n        if not isinstance(conf['hash_alg'], string_types):\n            raise TypeError(TAG + \": `hash_alg` must be a string\")\n        if conf['hash_alg'] not in ACCEPTED_HASH_ALG:\n            raise ValueError(TAG + \": `hash_alg` must be one of \" + str(ACCEPTED_HASH_ALG))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_json_format(conf):\n    '''Convert fields of parsed json dictionary to python format'''\n    if 'fmode' in conf:\n        conf['fmode'] = int(conf['fmode'], 8)\n    if 'dmode' in conf:\n        conf['dmode'] = int(conf['dmode'], 8)", "response": "Convert fields of parsed json dictionary to python format"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_json_format(conf):\n    '''Convert fields of a python dictionary to be dumped in json format'''\n    if 'fmode' in conf:\n        conf['fmode'] = oct(conf['fmode'])[-3:]\n    if 'dmode' in conf:\n        conf['dmode'] = oct(conf['dmode'])[-3:]", "response": "Convert fields of a python dictionary to be dumped in json format"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_conf(conf):\n    '''Check, convert and adjust user passed config\n\n       Given a user configuration it returns a verified configuration with\n       all parameters converted to the types that are needed at runtime.\n    '''\n    conf = conf.copy()\n    # check for type error\n    check_config(conf)\n    # convert some fileds into python suitable format\n    from_json_format(conf)\n    if 'dmode' not in conf:\n        conf['dmode'] = calc_dir_mode(conf['fmode'])\n    return conf", "response": "Check and convert and adjust user passed config\n\n       Given a user configuration it returns a verified configuration with\n       all parameters converted to the types that are needed at runtime."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _site_users():\n    userlist = sudo(\"cat /etc/passwd | awk '/site/'\").split('\\n')\n    siteuserlist = [user.split(':')[0] for user in userlist if 'site_' in user]\n    return siteuserlist", "response": "Get a list of site_n users"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists only sites in the domain_sites", "response": "def _ls_sites(path):\n    \"\"\"\n    List only sites in the domain_sites() to ensure we co-exist with other projects\n    \"\"\"\n    with cd(path):\n        sites = run('ls').split('\\n')\n        doms =  [d.name for d in domain_sites()]\n        dom_sites = []\n        for s in sites:\n            ds = s.split('-')[0]\n            ds = ds.replace('_','.')\n            if ds in doms and s not in dom_sites:\n                dom_sites.append(s)\n    return dom_sites"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sitesettings_files():\n    settings_files = []\n    sitesettings_path = os.path.join(env.project_package_name,'sitesettings')\n    if os.path.exists(sitesettings_path):\n        sitesettings = os.listdir(sitesettings_path)\n        for file in sitesettings:\n            if file == 'settings.py':\n                settings_files.append(file)\n            elif len(file)>12 and file[-12:]=='_settings.py': #prefixed settings\n                settings_files.append(file)\n    return settings_files", "response": "Get a list of sitesettings files that are available in the current project."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_django_sites():\n    deployed = version_state('deploy_project')\n    if not env.sites and 'django.contrib.sites' in env.INSTALLED_APPS and deployed:\n        with cd('/'.join([deployment_root(),'env',env.project_fullname,'project',env.project_package_name,'sitesettings'])):\n            venv = '/'.join([deployment_root(),'env',env.project_fullname,'bin','activate'])\n            #since this is the first time we run ./manage.py on the server it can be\n            #a point of failure for installations\n            with settings(warn_only=True):\n                output = run(' '.join(['source',venv,'&&',\"django-admin.py dumpdata sites --settings=%s.sitesettings.settings\"% env.project_package_name]))\n\n                if output.failed:\n                    print \"ERROR: There was an error running ./manage.py on the node\"\n                    print \"See the troubleshooting docs for hints on how to diagnose deployment issues\"\n                    if hasattr(output, 'stderr'):\n                        print output.stderr\n                    sys.exit(1)\n            output = output.split('\\n')[-1] #ignore any lines prior to the data being dumped\n            sites = json.loads(output)\n            env.sites = {}\n            for s in sites:\n                env.sites[s['pk']] = s['fields']['domain']\n    return env.sites", "response": "Get a list of sites as dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef domain_sites():\n\n    if not hasattr(env,'domains'):\n        sites = _get_django_sites()\n        site_ids = sites.keys()\n        site_ids.sort()\n        domains = []\n        \n        for id in site_ids:\n\n            for file in _sitesettings_files():\n                domain = _AttributeDict({})\n\n                if file == 'settings.py':\n                    domain.name = sites[id]\n                else: #prefix indicates subdomain\n                    subdomain = file[:-12].replace('_','.')\n                    domain.name = ''.join([subdomain,sites[id]])\n\n                domain.settings = file\n                domain.site_id = id\n                domains.append(domain)\n                \n        env.domains = domains\n        if env.domains: env.root_domain = env.domains[0].name\n        else:\n            domain.name = _root_domain(); domain.site_id = 1; domain.settings='settings.py'\n            env.domains = [domain]\n            \n    return env.domains", "response": "Get a list of domains that are available in django site - level settings. py."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeploy nginx and other wsgi server site configurations to the host", "response": "def deploy_webconf():\n    \"\"\" Deploy nginx and other wsgi server site configurations to the host \"\"\"\n    deployed = []\n    log_dir = '/'.join([deployment_root(),'log'])\n    #TODO - incorrect - check for actual package to confirm installation\n    if webserver_list():\n        if env.verbosity:\n            print env.host,\"DEPLOYING webconf:\"\n        if not exists(log_dir):\n            run('ln -s /var/log log')\n        #deploys confs for each domain based on sites app\n        if 'apache2' in get_packages():\n            deployed += _deploy_webconf('/etc/apache2/sites-available','django-apache-template.txt')\n            deployed += _deploy_webconf('/etc/nginx/sites-available','nginx-template.txt')\n        elif 'gunicorn' in get_packages():\n            deployed += _deploy_webconf('/etc/nginx/sites-available','nginx-gunicorn-template.txt')\n        \n        if not exists('/var/www/nginx-default'):\n            sudo('mkdir /var/www/nginx-default')\n        upload_template('woven/maintenance.html','/var/www/nginx-default/maintenance.html',use_sudo=True)\n        sudo('chmod ugo+r /var/www/nginx-default/maintenance.html')\n    else:\n        print env.host,\"\"\"WARNING: Apache or Nginx not installed\"\"\"\n        \n    return deployed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deploy_wsgi():\n    if 'libapache2-mod-wsgi' in get_packages():\n        remote_dir = '/'.join([deployment_root(),'env',env.project_fullname,'wsgi'])\n        wsgi = 'apache2'\n    elif 'gunicorn' in get_packages():\n        remote_dir = '/etc/init'\n        wsgi = 'gunicorn'\n    deployed = []\n    \n    #ensure project apps path is also added to environment variables as well as wsgi\n    if env.PROJECT_APPS_PATH:\n        pap = '/'.join([deployment_root(),'env',\n                        env.project_name,'project',env.project_package_name,env.PROJECT_APPS_PATH])\n        pap = ''.join(['export PYTHONPATH=$PYTHONPATH:',pap])\n        postactivate = '/'.join([deployment_root(),'env','postactivate'])\n        if not exists(postactivate):\n            append('#!/bin/bash', postactivate)\n            run('chmod +x %s'% postactivate)\n        if not contains('PYTHONPATH',postactivate):\n            append(pap,postactivate)\n        \n    if env.verbosity:\n        print env.host,\"DEPLOYING wsgi\", wsgi, remote_dir\n\n    for file in _sitesettings_files(): \n        deployed += mkdirs(remote_dir)\n        with cd(remote_dir):\n            settings_module = file.replace('.py','')\n            context = {\"deployment_root\":deployment_root(),\n                       \"user\": env.user,\n                       \"project_name\": env.project_name,\n                       \"project_package_name\": env.project_package_name,\n                       \"project_apps_path\":env.PROJECT_APPS_PATH,\n                       \"settings\": settings_module,\n                       }\n            if wsgi == 'apache2':\n                filename = file.replace('.py','.wsgi')\n                upload_template('/'.join(['woven','django-wsgi-template.txt']),\n                                filename,\n                                context,\n                            )\n            elif wsgi == 'gunicorn':\n                filename = 'gunicorn-%s.conf'% env.project_name\n                upload_template('/'.join(['woven','gunicorn.conf']),\n                                filename,\n                                context,\n                                backup=False,\n                                use_sudo=True\n                            )                \n                \n            if env.verbosity:\n                print \" * uploaded\", filename\n            #finally set the ownership/permissions\n            #We'll use the group to allow www-data execute\n            if wsgi == 'apache2':\n                sudo(\"chown %s:www-data %s\"% (env.user,filename))\n                run(\"chmod ug+xr %s\"% filename)\n            elif wsgi == 'gunicorn':\n                sudo(\"chown root:root %s\"% filename)\n                sudo(\"chmod go+r %s\"% filename)\n                \n    return deployed", "response": "deploy python wsgi file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef webserver_list():\n    p = set(get_packages())\n    w = set(['apache2','gunicorn','uwsgi','nginx'])\n    installed = p & w\n    return list(installed)", "response": "list of webserver packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reload_webservers():\n    if env.verbosity:\n        print env.host, \"RELOADING apache2\"\n    with settings(warn_only=True):\n        a = sudo(\"/etc/init.d/apache2 reload\")\n        if env.verbosity:\n            print '',a        \n    if env.verbosity:\n\n        #Reload used to fail on Ubuntu but at least in 10.04 it works\n        print env.host,\"RELOADING nginx\"\n    with settings(warn_only=True):\n        s = run(\"/etc/init.d/nginx status\")\n        if 'running' in s:\n            n = sudo(\"/etc/init.d/nginx reload\")\n        else:\n            n = sudo(\"/etc/init.d/nginx start\")\n    if env.verbosity:\n        print ' *',n\n    return True", "response": "Reload apache2 and nginx webservice tables"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_webserver(server):\n    #TODO - distinguish between a warning and a error on apache\n    if server == 'apache2':\n        with settings(warn_only=True):\n            if env.verbosity:\n                print env.host,\"STOPPING apache2\"\n            a = sudo(\"/etc/init.d/apache2 stop\")\n            if env.verbosity:\n                print '',a\n    elif server == 'gunicorn':\n        with settings(warn_only=True):\n            if env.verbosity:\n                print env.host,\"STOPPING\",\"%s-%s\"% (server,env.project_name)\n            a = sudo(\"stop %s-%s\"% (server,env.project_name))\n            if env.verbosity and a.strip():\n                print '',a\n    return True", "response": "Stop the apache2 or gunicorn webservice"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_webserver(server):\n    if server == 'apache2':\n        with settings(warn_only=True):\n            if env.verbosity:\n                print env.host,\"STARTING apache2\"\n            #some issues with pty=True getting apache to start on ec2\n            a = sudo(\"/etc/init.d/apache2 start\", pty=False)\n            if env.verbosity:\n                print '',a\n            \n        if a.failed:\n            print \"ERROR: /etc/init.d/apache2 start failed\"\n            print env.host, a\n            sys.exit(1)\n    elif server == 'nginx':\n        if env.verbosity:\n            #Reload used to fail on Ubuntu but at least in 10.04 it works\n            print env.host,\"RELOADING nginx\"\n        with settings(warn_only=True):\n            s = run(\"/etc/init.d/nginx status\")\n            if 'running' in s:\n                n = sudo(\"/etc/init.d/nginx reload\")\n            else:\n                n = sudo(\"/etc/init.d/nginx start\")\n        if env.verbosity:\n            print ' *',n\n    else:\n        if env.verbosity:\n            print env.host, \"STARTING\",\"%s-%s\"% (server,env.project_name)\n        with settings(warn_only=True):\n            n = sudo('start %s-%s'% (server,env.project_name))\n            if env.verbosity and n.strip():\n                print ' *', n\n            \n    return True", "response": "Start the webserver for the specified server"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the declared encoding or None", "response": "def match_encoding_declaration(comment):\n    \"\"\"returns the declared encoding or None\n\n    This function is a replacement for :\n    >>> py_encoding = re.compile(r\"coding[:=]\\s*([-\\w.]+)\")\n    >>> py_encoding.search(comment)\n    \"\"\"\n\n    # the coding line must be ascii\n    try:\n        comment = comment.decode('ascii')\n    except UnicodeDecodeError:\n        return None\n\n    index = comment.find('coding')\n    if index < 0:\n        return None\n    next_char = comment[index + 6]\n    if next_char not in ':=':\n        return None\n    end_of_decl = comment[index + 7:]\n    index = 0\n    for char in end_of_decl:\n        if char not in WHITESPACES:\n            break\n        index += 1\n    else:\n        return None\n    encoding = ''\n    for char in end_of_decl[index:]:\n        if char in EXTENDED_ALNUMCHARS:\n            encoding += char\n        else:\n            break\n    if encoding != '':\n        return encoding\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_url_ok(self):\n\n        response = requests.head(settings.KEYSTONE_AUTH_URL)\n        if response.status_code == 200:\n            return True\n        return False", "response": "Verify Keystone Auth URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets token_data by Keystone", "response": "def _set_token_data(self):\n        \"\"\" Set token_data by Keystone \"\"\"\n\n        if not self.token:\n            return\n\n        self._set_config_keystone(\n            settings.KEYSTONE_USERNAME, settings.KEYSTONE_PASSWORD)\n\n        token_data = self._keystone_auth.validate_token(self.token)\n\n        if not token_data:\n            self.logger.error('Invalid Token')\n            raise InvalidToken('Invalid Token')\n\n        self.token_data = token_data\n\n        if self.cache.is_redis_ok():\n            try:\n                self.cache.set_cache_token(token_data)\n            except CacheException:\n                self.logger.error('Token not setted in cache.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_config_keystone(self, username, password):\n\n        self._keystone_auth = KeystoneAuth(\n            settings.KEYSTONE_AUTH_URL, settings.KEYSTONE_PROJECT_NAME, username, password,\n            settings.KEYSTONE_USER_DOMAIN_NAME, settings.KEYSTONE_PROJECT_DOMAIN_NAME,\n            settings.KEYSTONE_TIMEOUT)", "response": "Set config to Keystone"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_token_data(self):\n\n        token_data = self._keystone_auth.conn.auth_ref\n        token = token_data['auth_token']\n        self.set_token(token)\n\n        if self.cache.is_redis_ok():\n            try:\n                self.cache.set_cache_token(token_data)\n            except CacheException:\n                self.logger.error('Token not setted in cache.')\n\n        token_data = {\n            'expires_at': token_data['expires_at'],\n            'token': token\n        }\n\n        return token_data", "response": "Get token and data from keystone"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cache(taxonomy_id):\n    if taxonomy_id in _CACHE:\n        ctime, taxonomy = _CACHE[taxonomy_id]\n\n        # check it is fresh version\n        onto_name, onto_path, onto_url = _get_ontology(taxonomy_id)\n        cache_path = _get_cache_path(onto_name)\n\n        # if source exists and is newer than the cache hold in memory\n        if os.path.isfile(onto_path) and os.path.getmtime(onto_path) > ctime:\n            current_app.logger.info(\n                'Forcing taxonomy rebuild as cached version is newer/updated.'\n            )\n            return {}  # force cache rebuild\n\n        # if cache exists and is newer than the cache hold in memory\n        if os.path.isfile(cache_path) and os.path.getmtime(cache_path) > ctime:\n            current_app.logger.info(\n                'Forcing taxonomy rebuild as source file is newer/updated.'\n            )\n            return {}\n        current_app.logger.info('Taxonomy retrieved from cache')\n        return taxonomy\n    return {}", "response": "Return the cache for the given taxonomy id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_regular_expressions(taxonomy_name, rebuild=False, no_cache=False):\n    # Translate the ontology name into a local path. Check if the name\n    # relates to an existing ontology.\n    onto_name, onto_path, onto_url = _get_ontology(taxonomy_name)\n    if not onto_path:\n        raise TaxonomyError(\"Unable to locate the taxonomy: '%s'.\"\n                            % taxonomy_name)\n\n    cache_path = _get_cache_path(onto_name)\n    current_app.logger.debug(\n        'Taxonomy discovered, now we load it '\n        '(from cache: %s, onto_path: %s, cache_path: %s)'\n        % (not no_cache, onto_path, cache_path)\n    )\n\n    if os.access(cache_path, os.R_OK):\n        if os.access(onto_path, os.R_OK):\n            if rebuild or no_cache:\n                current_app.logger.debug(\n                    \"Cache generation was manually forced.\")\n                return _build_cache(onto_path, skip_cache=no_cache)\n        else:\n            # ontology file not found. Use the cache instead.\n            current_app.logger.warning(\n                \"The ontology couldn't be located. However \"\n                \"a cached version of it is available. Using it as a \"\n                \"reference.\"\n            )\n            return _get_cache(cache_path, source_file=onto_path)\n\n        if (os.path.getmtime(cache_path) >\n                os.path.getmtime(onto_path)):\n            # Cache is more recent than the ontology: use cache.\n            current_app.logger.debug(\n                \"Normal situation, cache is older than ontology,\"\n                \" so we load it from cache\"\n            )\n            return _get_cache(cache_path, source_file=onto_path)\n        else:\n            # Ontology is more recent than the cache: rebuild cache.\n            current_app.logger.warning(\n                \"Cache '%s' is older than '%s'. \"\n                \"We will rebuild the cache\" %\n                (cache_path, onto_path)\n            )\n            return _build_cache(onto_path, skip_cache=no_cache)\n\n    elif os.access(onto_path, os.R_OK):\n        if not no_cache and\\\n                os.path.exists(cache_path) and\\\n                not os.access(cache_path, os.W_OK):\n            raise TaxonomyError('We cannot read/write into: %s. '\n                                'Aborting!' % cache_path)\n        elif not no_cache and os.path.exists(cache_path):\n            current_app.logger.warning(\n                'Cache %s exists, but is not readable!' % cache_path)\n        current_app.logger.info(\n            \"Cache not available. Building it now: %s\" % onto_path)\n        return _build_cache(onto_path, skip_cache=no_cache)\n\n    else:\n        raise TaxonomyError(\"We miss both source and cache\"\n                            \" of the taxonomy: %s\" % taxonomy_name)", "response": "Return a list of regular expressions that can be used to compile the ontology."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_remote_ontology(onto_url, time_difference=None):\n    if onto_url is None:\n        return False\n\n    dl_dir = os.path.join(\n        current_app.config[\"CLASSIFIER_WORKDIR\"] or tempfile.gettempdir(),\n        \"classifier\"\n    )\n    if not os.path.exists(dl_dir):\n        os.makedirs(dl_dir)\n\n    local_file = dl_dir + os.path.basename(onto_url)\n    remote_modif_time = _get_last_modification_date(onto_url)\n    try:\n        local_modif_seconds = os.path.getmtime(local_file)\n    except OSError:\n        # The local file does not exist. Download the ontology.\n        download = True\n        current_app.logger.info(\"The local ontology could not be found.\")\n    else:\n        local_modif_time = datetime(*time.gmtime(local_modif_seconds)[0:6])\n        # Let's set a time delta of 1 hour and 10 minutes.\n        time_difference = time_difference or timedelta(hours=1, minutes=10)\n        download = remote_modif_time > local_modif_time + time_difference\n        if download:\n            current_app.logger.info(\n                \"The remote ontology '{0}' is more recent \"\n                \"than the local ontology.\".format(onto_url)\n            )\n\n    if download:\n        if not _download_ontology(onto_url, local_file):\n            current_app.logger.warning(\n                \"Error downloading the ontology from: {0}\".format(onto_url)\n            )\n\n    return local_file", "response": "Download and store the online ontology."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_ontology(ontology):\n    onto_name = onto_path = onto_url = None\n\n    # first assume we got the path to the file\n    if os.path.exists(ontology):\n        onto_name = os.path.split(os.path.abspath(ontology))[1]\n        onto_path = os.path.abspath(ontology)\n        onto_url = \"\"\n    else:\n        # if not, try to find it in a known locations\n        discovered_file = _discover_ontology(ontology)\n        if discovered_file:\n            onto_name = os.path.split(discovered_file)[1]\n            onto_path = discovered_file\n\n            x = ontology.lower()\n            if \"http:\" in x or \"https:\" in x or \"ftp:\" in x or \"file:\" in x:\n                onto_url = ontology\n                onto_path = _get_remote_ontology(onto_url)\n            else:\n                onto_url = \"\"\n\n    return (onto_name, onto_path, onto_url)", "response": "Return the name path url to the short ontology name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch for the file in known places and return the absolute path of the file if found.", "response": "def _discover_ontology(ontology_path):\n    \"\"\"Look for the file in known places.\n\n    :param ontology: path name or url\n    :type ontology: str\n\n    :return: absolute path of a file if found, or None\n    \"\"\"\n    last_part = os.path.split(os.path.abspath(ontology_path))[1]\n    possible_patterns = [last_part, last_part.lower()]\n    if not last_part.endswith('.rdf'):\n        possible_patterns.append(last_part + '.rdf')\n    places = [os.path.join(current_app.instance_path, \"classifier\"),\n              os.path.abspath('.'),\n              os.path.join(os.path.dirname(__file__), \"classifier\")]\n\n    workdir = current_app.config.get('CLASSIFIER_WORKDIR')\n    if workdir:\n        places.append(workdir)\n\n    current_app.logger.debug(\n        \"Searching for taxonomy using string: %s\" % last_part)\n    current_app.logger.debug(\"Possible patterns: %s\" % possible_patterns)\n    for path in places:\n        try:\n            if os.path.isdir(path):\n                current_app.logger.debug(\"Listing: %s\" % path)\n                for filename in os.listdir(path):\n                    for pattern in possible_patterns:\n                        filename_lc = filename.lower()\n                        if pattern == filename_lc and\\\n                                os.path.exists(os.path.join(path, filename)):\n                            filepath = os.path.abspath(os.path.join(path,\n                                                                    filename))\n                            if (os.access(filepath, os.R_OK)):\n                                current_app.logger.debug(\n                                    \"Found taxonomy at: {0}\".format(filepath))\n                                return filepath\n                            else:\n                                current_app.logger.warning(\n                                    'Found taxonomy at: {0}, but it is'\n                                    ' not readable. Continue '\n                                    'searching...'.format(\n                                        filepath\n                                    )\n                                )\n        except OSError as os_error_msg:\n            current_app.logger.exception(\n                'OS Error when listing path \"{0}\": {1}'.format(\n                    str(path), str(os_error_msg))\n            )\n    current_app.logger.debug(\n        \"No taxonomy with pattern '{0}' found\".format(ontology_path))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the cache from a RDF taxonomy file.", "response": "def _build_cache(source_file, skip_cache=False):\n    \"\"\"Build the cached data.\n\n    Either by parsing the RDF taxonomy file or a vocabulary file.\n\n    :param source_file: source file of the taxonomy, RDF file\n    :param skip_cache: if True, build cache will not be\n        saved (pickled) - it is saved as <source_file.db>\n    \"\"\"\n    store = rdflib.ConjunctiveGraph()\n\n    if skip_cache:\n        current_app.logger.info(\"You requested not to save the cache to disk.\")\n    else:\n        cache_path = _get_cache_path(source_file)\n        cache_dir = os.path.dirname(cache_path)\n        # Make sure we have a cache_dir readable and writable.\n        if not os.path.isdir(cache_dir):\n            os.makedirs(cache_dir)\n        if os.access(cache_dir, os.R_OK):\n            if not os.access(cache_dir, os.W_OK):\n                raise TaxonomyError(\"Cache directory exists but is not\"\n                                    \" writable. Check your permissions\"\n                                    \" for: %s\" % cache_dir)\n        else:\n            raise TaxonomyError(\"Cache directory does not exist\"\n                                \" (and could not be created): %s\" % cache_dir)\n\n    timer_start = time.clock()\n\n    namespace = None\n    single_keywords, composite_keywords = {}, {}\n\n    try:\n        current_app.logger.info(\n            \"Building RDFLib's conjunctive graph from: %s\" % source_file)\n        try:\n            store.parse(source_file)\n        except urllib_error.URLError:\n            if source_file[0] == '/':\n                store.parse(\"file://\" + source_file)\n            else:\n                store.parse(\"file:///\" + source_file)\n\n    except rdflib.exceptions.Error as e:\n        current_app.logger.exception(\"Serious error reading RDF file\")\n        raise\n\n    except (xml.sax.SAXParseException, ImportError) as e:\n        # File is not a RDF file. We assume it is a controlled vocabulary.\n        current_app.logger.error(e)\n        current_app.logger.warning(\"The ontology file is probably not a valid RDF file. \\\n            Assuming it is a controlled vocabulary file.\")\n\n        filestream = open(source_file, \"r\")\n        for line in filestream:\n            keyword = line.strip()\n            kt = KeywordToken(keyword)\n            single_keywords[kt.short_id] = kt\n        if not len(single_keywords):\n            raise TaxonomyError('The ontology file is not well formated')\n\n    else:  # ok, no exception happened\n        current_app.logger.info(\"Now building cache of keywords\")\n        # File is a RDF file.\n        namespace = rdflib.Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n\n        single_count = 0\n        composite_count = 0\n\n        subject_objects = store.subject_objects(namespace[\"prefLabel\"])\n        for subject, pref_label in subject_objects:\n            kt = KeywordToken(subject, store=store, namespace=namespace)\n            if kt.isComposite():\n                composite_count += 1\n                composite_keywords[kt.short_id] = kt\n            else:\n                single_keywords[kt.short_id] = kt\n                single_count += 1\n\n    cached_data = {}\n    cached_data[\"single\"] = single_keywords\n    cached_data[\"composite\"] = composite_keywords\n    cached_data[\"creation_time\"] = time.gmtime()\n    cached_data[\"version_info\"] = {'rdflib': rdflib.__version__}\n    current_app.logger.debug(\n        \"Building taxonomy... %d terms built in %.1f sec.\" %\n        (len(single_keywords) + len(composite_keywords),\n         time.clock() - timer_start))\n\n    current_app.logger.info(\n        \"Total count of single keywords: %d \"\n        % len(single_keywords)\n    )\n    current_app.logger.info(\n        \"Total count of composite keywords: %d \"\n        % len(composite_keywords)\n    )\n\n    if not skip_cache:\n        cache_path = _get_cache_path(source_file)\n        cache_dir = os.path.dirname(cache_path)\n        current_app.logger.debug(\"Writing the cache into: %s\" % cache_path)\n        # test again, it could have changed\n        if os.access(cache_dir, os.R_OK):\n            if os.access(cache_dir, os.W_OK):\n                # Serialize.\n                filestream = None\n                try:\n                    filestream = open(cache_path, \"wb\")\n                except IOError as msg:\n                    # Impossible to write the cache.\n                    current_app.logger.error(\n                        \"Impossible to write cache to '%s'.\"\n                        % cache_path)\n                    current_app.logger.error(msg)\n                else:\n                    current_app.logger.debug(\n                        \"Writing cache to file %s\" % cache_path)\n                    cPickle.dump(cached_data, filestream, 1)\n                if filestream:\n                    filestream.close()\n\n            else:\n                raise TaxonomyError(\"Cache directory exists but is not \"\n                                    \"writable. Check your permissions \"\n                                    \"for: %s\" % cache_dir)\n        else:\n            raise TaxonomyError(\"Cache directory does not exist\"\n                                \" (and could not be created): %s\" % cache_dir)\n\n    # now when the whole taxonomy was parsed,\n    # find sub-components of the composite kws\n    # it is important to keep this call after the taxonomy was saved,\n    # because we don't  want to pickle regexes multiple times\n    # (as they are must be re-compiled at load time)\n    for kt in composite_keywords.values():\n        kt.refreshCompositeOf(single_keywords, composite_keywords,\n                              store=store, namespace=namespace)\n\n    # house-cleaning\n    if store:\n        store.close()\n\n    return (single_keywords, composite_keywords)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _capitalize_first_letter(word):\n    if word[0].isalpha():\n        # These two cases are necessary in order to get a regex pattern\n        # starting with '[xX]' and not '[Xx]'. This allows to check for\n        # colliding regex afterwards.\n        if word[0].isupper():\n            return \"[\" + word[0].swapcase() + word[0] + \"]\" + word[1:]\n        else:\n            return \"[\" + word[0] + word[0].swapcase() + \"]\" + word[1:]\n    return word", "response": "Return a regex pattern with the first letter. Accepts both lowercase and uppercase."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_punctuation(punctuation, conversion_table):\n    if punctuation in conversion_table:\n        return conversion_table[punctuation]\n    return re.escape(punctuation)", "response": "Return a regular expression for a punctuation string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a word into a plural form.", "response": "def _convert_word(word):\n    \"\"\"Return the plural form of the word if it exists.\n\n    Otherwise return the word itself.\n    \"\"\"\n    out = None\n\n    # Acronyms.\n    if word.isupper():\n        out = word + \"s?\"\n    # Proper nouns or word with digits.\n    elif word.istitle():\n        out = word + \"('?s)?\"\n    elif _contains_digit.search(word):\n        out = word\n\n    if out is not None:\n        return out\n\n    # Words with non or anti prefixes.\n    if _starts_with_non.search(word):\n        word = \"non-?\" + _capitalize_first_letter(_convert_word(word[3:]))\n    elif _starts_with_anti.search(word):\n        word = \"anti-?\" + _capitalize_first_letter(_convert_word(word[4:]))\n\n    if out is not None:\n        return _capitalize_first_letter(out)\n\n    # A few invariable words.\n    if word in current_app.config[\"CLASSIFIER_INVARIABLE_WORDS\"]:\n        return _capitalize_first_letter(word)\n\n    # Some exceptions that would not produce good results with the set of\n    # general_regular_expressions.\n    regexes = current_app.config[\"CLASSIFIER_EXCEPTIONS\"]\n    if word in regexes:\n        return _capitalize_first_letter(regexes[word])\n\n    regexes = current_app.config[\"CLASSIFIER_UNCHANGE_REGULAR_EXPRESSIONS\"]\n    for regex in regexes:\n        if regex.search(word) is not None:\n            return _capitalize_first_letter(word)\n\n    regexes = current_app.config[\"CLASSIFIER_GENERAL_REGULAR_EXPRESSIONS\"]\n    for regex, replacement in regexes:\n        stemmed = regex.sub(replacement, word)\n        if stemmed != word:\n            return _capitalize_first_letter(stemmed)\n\n    return _capitalize_first_letter(word + \"s?\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the cache using the cPickle module.", "response": "def _get_cache(cache_file, source_file=None):\n    \"\"\"Get cached taxonomy using the cPickle module.\n\n    No check is done at that stage.\n\n    :param cache_file: full path to the file holding pickled data\n    :param source_file: if we discover the cache is obsolete, we\n        will build a new cache, therefore we need the source path\n        of the cache\n    :return: (single_keywords, composite_keywords).\n    \"\"\"\n    timer_start = time.clock()\n\n    filestream = open(cache_file, \"rb\")\n    try:\n        cached_data = cPickle.load(filestream)\n        version_info = cached_data['version_info']\n        if version_info['rdflib'] != rdflib.__version__:\n            raise KeyError\n    except (cPickle.UnpicklingError, ImportError,\n            AttributeError, DeprecationWarning, EOFError):\n        current_app.logger.warning(\n            \"The existing cache in %s is not readable. \"\n            \"Removing and rebuilding it.\" % cache_file\n        )\n        filestream.close()\n        os.remove(cache_file)\n        return _build_cache(source_file)\n    except KeyError:\n        current_app.logger.warning(\n            \"The existing cache %s is not up-to-date. \"\n            \"Removing and rebuilding it.\" % cache_file\n        )\n        filestream.close()\n        os.remove(cache_file)\n        if source_file and os.path.exists(source_file):\n            return _build_cache(source_file)\n        else:\n            current_app.logger.error(\n                \"The cache contains obsolete data (and it was deleted), \"\n                \"however I can't build a new cache, the source does not \"\n                \"exist or is inaccessible! - %s\" % source_file\n            )\n    filestream.close()\n\n    single_keywords = cached_data[\"single\"]\n    composite_keywords = cached_data[\"composite\"]\n\n    # the cache contains only keys of the composite keywords, not the objects\n    # so now let's resolve them into objects\n    for kw in composite_keywords.values():\n        kw.refreshCompositeOf(single_keywords, composite_keywords)\n\n    current_app.logger.debug(\n        \"Retrieved taxonomy from cache %s created on %s\" %\n        (cache_file, time.asctime(cached_data[\"creation_time\"]))\n    )\n\n    current_app.logger.debug(\n        \"%d terms read in %.1f sec.\" %\n        (len(single_keywords) + len(composite_keywords),\n         time.clock() - timer_start)\n    )\n\n    return (single_keywords, composite_keywords)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the absolute path to the cache file.", "response": "def _get_cache_path(source_file):\n    \"\"\"Return the path where the cache should be written/located.\n\n    :param onto_name: name of the ontology or the full path\n    :return: string, abs path to the cache file\n    \"\"\"\n    local_name = os.path.basename(source_file)\n    cache_name = local_name + \".db\"\n    cache_dir = os.path.join(current_app.instance_path, \"classifier\")\n\n    if not os.path.isdir(cache_dir):\n        os.makedirs(cache_dir)\n\n    return os.path.abspath(os.path.join(cache_dir, cache_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the last modification date of the ontology.", "response": "def _get_last_modification_date(url):\n    \"\"\"Get the last modification date of the ontology.\"\"\"\n    request = requests.head(url)\n    date_string = request.headers[\"last-modified\"]\n    parsed = time.strptime(date_string, \"%a, %d %b %Y %H:%M:%S %Z\")\n    return datetime(*(parsed)[0:6])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _download_ontology(url, local_file):\n    current_app.logger.debug(\n        \"Copying remote ontology '%s' to file '%s'.\" % (url, local_file)\n    )\n    try:\n        request = requests.get(url, stream=True)\n        if request.status_code == 200:\n            with open(local_file, 'wb') as f:\n                for chunk in request.iter_content(chunk_size):\n                    f.write(chunk)\n    except IOError as e:\n        current_app.logger.exception(e)\n        return False\n    else:\n        current_app.logger.debug(\"Done copying.\")\n        return True", "response": "Download the ontology and stores it in CLASSIFIER_WORKDIR."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_searchable_regex(basic=None, hidden=None):\n    # Hidden labels are used to store regular expressions.\n    basic = basic or []\n    hidden = hidden or []\n\n    hidden_regex_dict = {}\n    for hidden_label in hidden:\n        if _is_regex(hidden_label):\n            hidden_regex_dict[hidden_label] = \\\n                re.compile(\n                    current_app.config[\"CLASSIFIER_WORD_WRAP\"]\n                    % hidden_label[1:-1]\n            )\n        else:\n            pattern = _get_regex_pattern(hidden_label)\n            hidden_regex_dict[hidden_label] = re.compile(\n                current_app.config[\"CLASSIFIER_WORD_WRAP\"] % pattern\n            )\n\n    # We check if the basic label (preferred or alternative) is matched\n    # by a hidden label regex. If yes, discard it.\n    regex_dict = {}\n    # Create regex for plural forms and add them to the hidden labels.\n    for label in basic:\n        pattern = _get_regex_pattern(label)\n        regex_dict[label] = re.compile(\n            current_app.config[\"CLASSIFIER_WORD_WRAP\"] % pattern\n        )\n\n    # Merge both dictionaries.\n    regex_dict.update(hidden_regex_dict)\n\n    return list(regex_dict.values())", "response": "Return the searchable regular expressions for the single keyword."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a regular expression of the label.", "response": "def _get_regex_pattern(label):\n    \"\"\"Return a regular expression of the label.\n\n    This takes care of plural and different kinds of separators.\n    \"\"\"\n    parts = _split_by_punctuation.split(label)\n\n    for index, part in enumerate(parts):\n        if index % 2 == 0:\n            # Word\n            if not parts[index].isdigit() and len(parts[index]) > 1:\n                parts[index] = _convert_word(parts[index])\n        else:\n            # Punctuation\n            if not parts[index + 1]:\n                # The separator is not followed by another word. Treat\n                # it as a symbol.\n                parts[index] = _convert_punctuation(\n                    parts[index],\n                    current_app.config[\"CLASSIFIER_SYMBOLS\"]\n                )\n            else:\n                parts[index] = _convert_punctuation(\n                    parts[index],\n                    current_app.config[\"CLASSIFIER_SEPARATORS\"]\n                )\n\n    return \"\".join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_taxonomy(taxonomy):\n    current_app.logger.info(\n        \"Building graph with Python RDFLib version %s\" %\n        rdflib.__version__\n    )\n\n    store = rdflib.ConjunctiveGraph()\n    store.parse(taxonomy)\n\n    current_app.logger.info(\"Graph was successfully built.\")\n\n    prefLabel = \"prefLabel\"\n    hiddenLabel = \"hiddenLabel\"\n    altLabel = \"altLabel\"\n    composite = \"composite\"\n    compositeOf = \"compositeOf\"\n    note = \"note\"\n\n    both_skw_and_ckw = []\n\n    # Build a dictionary we will reason on later.\n    uniq_subjects = {}\n    for subject in store.subjects():\n        uniq_subjects[subject] = None\n\n    subjects = {}\n    for subject in uniq_subjects:\n        strsubject = str(subject).split(\"#Composite.\")[-1]\n        strsubject = strsubject.split(\"#\")[-1]\n        if (strsubject == \"http://cern.ch/thesauri/HEPontology.rdf\" or\n                strsubject == \"compositeOf\"):\n            continue\n        components = {}\n        for predicate, value in store.predicate_objects(subject):\n            strpredicate = str(predicate).split(\"#\")[-1]\n            strobject = str(value).split(\"#Composite.\")[-1]\n            strobject = strobject.split(\"#\")[-1]\n            components.setdefault(strpredicate, []).append(strobject)\n        if strsubject in subjects:\n            both_skw_and_ckw.append(strsubject)\n        else:\n            subjects[strsubject] = components\n\n    current_app.logger.info(\"Taxonomy contains %s concepts.\" % len(subjects))\n\n    no_prefLabel = []\n    multiple_prefLabels = []\n    bad_notes = []\n    # Subjects with no composite or compositeOf predicate\n    lonely = []\n    both_composites = []\n    bad_hidden_labels = {}\n    bad_alt_labels = {}\n    # Problems with composite keywords\n    composite_problem1 = []\n    composite_problem2 = []\n    composite_problem3 = []\n    composite_problem4 = {}\n    composite_problem5 = []\n    composite_problem6 = []\n\n    stemming_collisions = []\n    interconcept_collisions = {}\n\n    for subject, predicates in iteritems(subjects):\n        # No prefLabel or multiple prefLabels\n        try:\n            if len(predicates[prefLabel]) > 1:\n                multiple_prefLabels.append(subject)\n        except KeyError:\n            no_prefLabel.append(subject)\n\n        # Lonely and both composites.\n        if composite not in predicates and compositeOf not in predicates:\n            lonely.append(subject)\n        elif composite in predicates and compositeOf in predicates:\n            both_composites.append(subject)\n\n        # Multiple or bad notes\n        if note in predicates:\n            bad_notes += [(subject, n) for n in predicates[note]\n                          if n not in ('nostandalone', 'core')]\n\n        # Bad hidden labels\n        if hiddenLabel in predicates:\n            for lbl in predicates[hiddenLabel]:\n                if lbl.startswith(\"/\") ^ lbl.endswith(\"/\"):\n                    bad_hidden_labels.setdefault(subject, []).append(lbl)\n\n        # Bad alt labels\n        if altLabel in predicates:\n            for lbl in predicates[altLabel]:\n                if len(re.findall(\"/\", lbl)) >= 2 or \":\" in lbl:\n                    bad_alt_labels.setdefault(subject, []).append(lbl)\n\n        # Check composite\n        if composite in predicates:\n            for ckw in predicates[composite]:\n                if ckw in subjects:\n                    if compositeOf in subjects[ckw]:\n                        if subject not in subjects[ckw][compositeOf]:\n                            composite_problem3.append((subject, ckw))\n                    else:\n                        if ckw not in both_skw_and_ckw:\n                            composite_problem2.append((subject, ckw))\n                else:\n                    composite_problem1.append((subject, ckw))\n\n        # Check compositeOf\n        if compositeOf in predicates:\n            for skw in predicates[compositeOf]:\n                if skw in subjects:\n                    if composite in subjects[skw]:\n                        if subject not in subjects[skw][composite]:\n                            composite_problem6.append((subject, skw))\n                    else:\n                        if skw not in both_skw_and_ckw:\n                            composite_problem5.append((subject, skw))\n                else:\n                    composite_problem4.setdefault(skw, []).append(subject)\n\n        # Check for stemmed labels\n        if compositeOf in predicates:\n            labels = (altLabel, hiddenLabel)\n        else:\n            labels = (prefLabel, altLabel, hiddenLabel)\n\n        patterns = {}\n        for label in [lbl for lbl in labels if lbl in predicates]:\n            for expression in [expr for expr in predicates[label]\n                               if not _is_regex(expr)]:\n                pattern = _get_regex_pattern(expression)\n                interconcept_collisions.setdefault(pattern, []).\\\n                    append((subject, label))\n                if pattern in patterns:\n                    stemming_collisions.append(\n                        (subject,\n                         patterns[pattern],\n                         (label, expression)\n                         )\n                    )\n                else:\n                    patterns[pattern] = (label, expression)\n\n    print(\"\\n==== ERRORS ====\")\n\n    if no_prefLabel:\n        print(\"\\nConcepts with no prefLabel: %d\" % len(no_prefLabel))\n        print(\"\\n\".join([\"   %s\" % subj for subj in no_prefLabel]))\n    if multiple_prefLabels:\n        print((\"\\nConcepts with multiple prefLabels: %d\" %\n               len(multiple_prefLabels)))\n        print(\"\\n\".join([\"   %s\" % subj for subj in multiple_prefLabels]))\n    if both_composites:\n        print((\"\\nConcepts with both composite properties: %d\" %\n               len(both_composites)))\n        print(\"\\n\".join([\"   %s\" % subj for subj in both_composites]))\n    if bad_hidden_labels:\n        print(\"\\nConcepts with bad hidden labels: %d\" % len(bad_hidden_labels))\n        for kw, lbls in iteritems(bad_hidden_labels):\n            print(\"   %s:\" % kw)\n            print(\"\\n\".join([\"      '%s'\" % lbl for lbl in lbls]))\n    if bad_alt_labels:\n        print(\"\\nConcepts with bad alt labels: %d\" % len(bad_alt_labels))\n        for kw, lbls in iteritems(bad_alt_labels):\n            print(\"   %s:\" % kw)\n            print(\"\\n\".join([\"      '%s'\" % lbl for lbl in lbls]))\n    if both_skw_and_ckw:\n        print((\"\\nKeywords that are both skw and ckw: %d\" %\n               len(both_skw_and_ckw)))\n        print(\"\\n\".join([\"   %s\" % subj for subj in both_skw_and_ckw]))\n\n    print()\n\n    if composite_problem1:\n        print(\"\\n\".join([\"SKW '%s' references an unexisting CKW '%s'.\" %\n                         (skw, ckw) for skw, ckw in composite_problem1]))\n    if composite_problem2:\n        print(\"\\n\".join([\"SKW '%s' references a SKW '%s'.\" %\n                         (skw, ckw) for skw, ckw in composite_problem2]))\n    if composite_problem3:\n        print(\"\\n\".join([\"SKW '%s' is not composite of CKW '%s'.\" %\n                         (skw, ckw) for skw, ckw in composite_problem3]))\n    if composite_problem4:\n        for skw, ckws in iteritems(composite_problem4):\n            print(\"SKW '%s' does not exist but is \" \"referenced by:\" % skw)\n            print(\"\\n\".join([\"    %s\" % ckw for ckw in ckws]))\n    if composite_problem5:\n        print(\"\\n\".join([\"CKW '%s' references a CKW '%s'.\" % kw\n                         for kw in composite_problem5]))\n    if composite_problem6:\n        print(\"\\n\".join([\"CKW '%s' is not composed by SKW '%s'.\" % kw\n                         for kw in composite_problem6]))\n\n    print(\"\\n==== WARNINGS ====\")\n\n    if bad_notes:\n        print((\"\\nConcepts with bad notes: %d\" % len(bad_notes)))\n        print(\"\\n\".join([\"   '%s': '%s'\" % _note for _note in bad_notes]))\n    if stemming_collisions:\n        print(\"\\nFollowing keywords have unnecessary labels that have \"\n              \"already been generated by Classifier.\")\n        for subj in stemming_collisions:\n            print(\"   %s:\\n     %s\\n     and %s\" % subj)\n\n    print(\"\\nFinished.\")\n    sys.exit(0)", "response": "Checks the consistency of a taxonomy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nre-check sub-parts of this keyword. This should be called after the whole RDF was processed, because it is using a cache of single keywords and if that one is incomplete, you will not identify all parts.", "response": "def refreshCompositeOf(self, single_keywords, composite_keywords,\n                           store=None, namespace=None):\n        \"\"\"Re-check sub-parts of this keyword.\n\n        This should be called after the whole RDF was processed, because\n        it is using a cache of single keywords and if that\n        one is incomplete, you will not identify all parts.\n        \"\"\"\n        def _get_ckw_components(new_vals, label):\n            if label in single_keywords:\n                new_vals.append(single_keywords[label])\n            elif ('Composite.%s' % label) in composite_keywords:\n                for l in composite_keywords['Composite.{0}'.format(label)].compositeof:  # noqa\n                    _get_ckw_components(new_vals, l)\n            elif label in composite_keywords:\n                for l in composite_keywords[label].compositeof:\n                    _get_ckw_components(new_vals, l)\n            else:\n                # One single or composite keyword is missing from the taxonomy.\n                # This is due to an error in the taxonomy description.\n                message = \"The composite term \\\"%s\\\"\"\\\n                          \" should be made of single keywords,\"\\\n                          \" but at least one is missing.\" % self.id\n                if store is not None:\n                    message += \"Needed components: %s\"\\\n                               % list(store.objects(self.id,\n                                                    namespace[\"compositeOf\"]))\n                message += \" Missing is: %s\" % label\n                raise TaxonomyError(message)\n\n        if self.compositeof:\n            new_vals = []\n            try:\n                for label in self.compositeof:\n                    _get_ckw_components(new_vals, label)\n                self.compositeof = new_vals\n            except TaxonomyError as err:\n                # the composites will be empty\n                # (better than to have confusing, partial matches)\n                self.compositeof = []\n                current_app.logger.error(err)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a User and UserKey record in the session provided.", "response": "def create_user(username, key, session):\n    \"\"\"\n    Create a User and UserKey record in the session provided.\n    Will rollback both records if any issues are encountered.\n    After rollback, Exception is re-raised.\n\n    :param username: The username for the User\n    :param key: The public key to associate with this User\n    :param session: The sqlalchemy session to use\n    :rtype: User\n    :return: the new User record\n    \"\"\"\n    try:\n        user = um.User(username=username)\n        session.add(user)\n        session.commit()\n    except Exception as e:\n        session.rollback()\n        session.flush()\n        raise e\n    try:\n        ukey = um.UserKey(key=key, keytype='public', user_id=user.id)\n        session.add(ukey)\n        session.commit()\n    except Exception as e:\n        session.rollback()\n        session.flush()\n        session.delete(user)\n        session.commit()\n        raise e\n    return user"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_definitions(dpath=\"sqlalchemy_models/_definitions.json\"):\n    command.run(AlsoChildrenWalker, module=todo, outdir=\"sqlalchemy_models\", definition_name=\"_definitions.json\",\n                relation_decision=RelationDesicion())\n    pass  # skip due to unpatched issue in alchemyjsonschema run()\n    definitions = \"\"\n    for line in open(dpath, 'r'):\n        definitions += line\n    definitions = json.loads(definitions)\n    newdef = open(dpath.replace(\"_def\", \"def\"), 'w+')\n    for name in definitions['definitions']:\n        for mod in [um, em, wm, bm]:\n            if hasattr(mod, name):\n                model = getattr(mod, name)\n                for attr in definitions['definitions'][name]['properties']:\n                    if hasattr(getattr(model, attr).property, 'columns') and \\\n                            isinstance(getattr(model, attr).property.columns[0].type, LedgerAmount):\n                        definitions['definitions'][name]['properties'][attr]['type'] = \"number\"\n    newdef.write(json.dumps(definitions, indent=2))\n    newdef.close()", "response": "Build the _def file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multiply_tickers(t1, t2):\n    t1pair = t1.market.split(\"_\")\n    t2pair = t2.market.split(\"_\")\n    assert t1pair[1] == t2pair[0]\n    market = t1pair[0] + \"_\" + t2pair[1]\n    bid = t1.bid * Amount(\"%s %s\" % (t2.bid.number(), t1.bid.commodity))\n    ask = t1.ask * Amount(\"%s %s\" % (t2.ask.number(), t1.ask.commodity))\n    high = t1.high * Amount(\"%s %s\" % (t2.high.number(), t1.high.commodity))  # meaningless\n    low = t1.low * Amount(\"%s %s\" % (t2.low.number(), t1.low.commodity))  # meaningless\n    volume = 0  # meaningless\n    last = t1.last * Amount(\"%s %s\" % (t2.last.number(), t1.last.commodity))\n    return em.Ticker(bid=bid, ask=ask, high=high, low=low, volume=volume, last=last, market=market, exchange='multiple')", "response": "Multiply two tickers. Quote currency of t1 must match base currency of t2.\n\n    :param Ticker t1: Ticker # 1\n    :param Ticker t2: Ticker # 2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_variables(args):\n\n    if args is None:\n        return {}\n\n    def parse_variable(string):\n        tokens = string.split('=')\n        name = tokens[0]\n        value = '='.join(tokens[1:])\n        return name, value\n\n    return {\n        name: value\n        for name, value in (parse_variable(v) for v in args)\n    }", "response": "Parse variables as passed on the command line. Returns a dictionary mapping variable name to the value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _calc_digest(self, origin):\n        if hasattr(origin, 'read') and hasattr(origin, 'seek'):\n            pos = origin.tell()\n            digest = hashtools.calc_digest(origin, algorithm=self._conf['hash_alg'])\n            origin.seek(pos)\n        else:\n            digest = hashtools.calc_file_digest(origin, algorithm=self._conf['hash_alg'])\n        return digest", "response": "calculate digest for the given object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies the content of origin into dstPath", "response": "def _copy_content(self, origin, dstPath):\n        \"\"\"copy the content of origin into dstPath\n\n           Due to concurrency problem, the content will be first\n           copied to a temporary file alongside `dstPath` and\n           then atomically moved to `dstPath`\n        \"\"\"\n\n        if hasattr(origin, 'read'):\n            copy_content(origin, dstPath, self.BLOCK_SIZE, self._conf['fmode'])\n        elif os.path.isfile(origin):\n            with open(origin, 'rb') as f:\n                copy_content(f, dstPath, self.BLOCK_SIZE, self._conf['fmode'])\n        else:\n            raise ValueError(\"Could not copy content, `origin` should be a path or a readable object\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, origin):\n\n        digest = self._calc_digest(origin)\n\n        if self.exists(digest):\n            self.logger.debug('Added File: [{0}] ( Already exists. Skipping transfer)'.format(digest))\n            return digest\n\n        absPath = self.get_file_path(digest)\n        absFolderPath = os.path.dirname(absPath)\n\n        # make all parent directories if they do not exist\n        self._makedirs(absFolderPath)\n        self._copy_content(origin, absPath)\n\n        self.logger.debug('Added file: \"{0}\" [{1}]'.format(digest, absPath))\n\n        return digest", "response": "Add a new element to the fsdb."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, digest):\n        # remove file\n        absPath = self.get_file_path(digest)\n        os.remove(absPath)\n\n        # clean directory tree\n        tmpPath = os.path.dirname(absPath)\n        while tmpPath != self.fsdbRoot:\n            if os.path.islink(tmpPath):\n                raise Exception('fsdb found a link in db tree: \"{0}\"'.format(tmpPath))\n            if len(os.listdir(tmpPath)) > 0:\n                break\n            os.rmdir(tmpPath)\n            tmpPath = os.path.dirname(tmpPath)\n\n        self.logger.debug('Removed file: \"{0}\" [{1}]'.format(absPath, digest))", "response": "Remove an existing file from fsdb and\n          "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exists(self, digest):\n        if not isinstance(digest, string_types):\n            raise TypeError(\"digest must be a string\")\n        return os.path.isfile(self.get_file_path(digest))", "response": "Check if a file exists under this instance of fsdb"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_file_path(self, digest):\n        relPath = Fsdb.generate_tree_path(digest, self._conf['depth'])\n        return os.path.join(self.fsdbRoot, relPath)", "response": "Retrieve the absolute path to the file with the given digest"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the integrity of the file with the given digest", "response": "def check(self, digest):\n        \"\"\"Check the integrity of the file with the given digest\n\n          Args:\n            digest -- digest of the file to check\n          Returns:\n            True if the file is not corrupted\n        \"\"\"\n        path = self.get_file_path(digest)\n        if self._calc_digest(path) != digest:\n            self.logger.warning(\"found corrupted file: '{0}'\".format(path))\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the total size in bytes of all the files handled by this instance of Fsdb.", "response": "def size(self):\n        \"\"\"Return the total size in bytes of all the files handled by this instance of fsdb.\n\n        Fsdb does not use auxiliary data structure, so this function could be expensive.\n        Look at _iter_over_paths() functions for more details.\n        \"\"\"\n        tot = 0\n        for p in self.__iter__(overPath=True):\n            tot += os.path.getsize(p)\n        return tot"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_tree_path(fileDigest, depth):\n        if(depth < 0):\n            raise Exception(\"depth level can not be negative\")\n        if(os.path.split(fileDigest)[1] != fileDigest):\n            raise Exception(\"fileDigest cannot contain path separator\")\n\n        # calculate min length for the given depth (2^1+2^2+...+2^depth+ 1)\n        min = (2**(depth + 1)) - 1\n        if(len(fileDigest) < min):\n            raise Exception(\"fileDigest too short for the given depth\")\n\n        path = \"\"\n        index = 0\n        for p in range(1, depth + 1):\n            jump = 2**p\n            path = os.path.join(path, fileDigest[index:index + jump])\n            index += jump\n        path = os.path.join(path, fileDigest[index:])\n        return path", "response": "Generate a relative path from the given fileDigest and depth"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_set(string):\n    string = string.strip()\n    if string:\n        return set(string.split(\",\"))\n    else:\n        return set()", "response": "Parse set from comma separated string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreporting error about missing minimum version constraint and exit.", "response": "def minver_error(pkg_name):\n    \"\"\"Report error about missing minimum version constraint and exit.\"\"\"\n    print(\n        'ERROR: specify minimal version of \"{}\" using '\n        '\">=\" or \"==\"'.format(pkg_name),\n        file=sys.stderr\n    )\n    sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_pip_file(path):\n    # requirement lines sorted by importance\n    # also collect other pip commands\n    rdev = dict()\n    rnormal = []\n    stuff = []\n\n    try:\n        with open(path) as f:\n            for line in f:\n                line = line.strip()\n\n                # see https://pip.readthedocs.org/en/1.1/requirements.html\n                if line.startswith('-e'):\n                    # devel requirement\n                    splitted = line.split('#egg=')\n                    rdev[splitted[1].lower()] = line\n\n                elif line.startswith('-r'):\n                    # recursive file command\n                    splitted = re.split('-r\\\\s+', line)\n                    subrdev, subrnormal, substuff = parse_pip_file(splitted[1])\n                    for k, v in subrdev.iteritems():\n                        if k not in rdev:\n                            rdev[k] = v\n                    rnormal.extend(subrnormal)\n                    result.extend(substuff)\n\n                elif line.startswith('-'):\n                    # another special command we don't recognize\n                    stuff.append(line)\n\n                else:\n                    # ordenary requirement, similary to them used in setup.py\n                    rnormal.append(line)\n    except IOError:\n        print(\n            'Warning: could not parse requirements file \"{}\"!',\n            file=sys.stderr\n        )\n\n    return rdev, rnormal, stuff", "response": "Parse pip requirements file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, endpoint: str, **kwargs) -> dict:\n\n        return self._request('GET', endpoint, **kwargs)", "response": "HTTP GET operation to API endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(self, endpoint: str, **kwargs) -> dict:\n\n        return self._request('POST', endpoint, **kwargs)", "response": "HTTP POST operation to API endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_selector(self):\n        effective_selector_list = []\n\n        for current_selector in self._selector_list:\n\n            # INLINE SELECTOR\n            if self.get_type(current_selector) != 'selector_variable':\n                effective_selector_list.append(current_selector)\n\n            # SELECTOR VARIABLE\n            else:\n                # Make sure the proxy driver have a selector dictionary\n                if self.get_type(current_selector) == 'selector_variable':\n                    if not BROME_CONFIG['selector_dict']:\n                        raise Exception(\"\"\"\n                            You must provide a selector dictionary if you want\n                            to use the selector variable type\n                        \"\"\")\n\n                # Make sure that the selector dictionary\n                # contains the selector variable\n                if self._get_selector(current_selector) \\\n                        not in BROME_CONFIG['selector_dict']:\n                    raise Exception(\"\"\"\n                        Cannot find the selector variable (%s)\n                        in the selector dictionary\n                    \"\"\" % self._get_selector(current_selector))\n\n                effective_selector = BROME_CONFIG['selector_dict'][self._get_selector(current_selector)]  # noqa\n                if type(effective_selector) is dict:\n                    current_browser_id = False\n\n                    keys = [key for key in effective_selector.keys()\n                            if key not in ['default', 'hr']]\n\n                    for key in keys:\n                        for target in key.split('|'):\n                            try:\n                                re.search(\n                                    target.lower(), self._pdriver.get_id().lower()\n                                ).group(0)\n                                current_browser_id = key\n                            except AttributeError:\n                                pass\n\n                    if current_browser_id:\n                        effective_selector_list.append(\n                            effective_selector.get(current_browser_id)\n                        )\n                    else:\n                        effective_selector_list.append(\n                            effective_selector.get('default')\n                        )\n\n                else:\n                    if self.get_type(effective_selector) in \\\n                            [value for key, value in SELECTOR_DICT.items()\n                                if key != 'selector_variable']:\n                        effective_selector_list.append(effective_selector)\n                    else:\n                        raise Exception(\"\"\"\n                            All selector need to start with either:\n                                'nm:' (name), 'xp:' (xpath), 'cn:' (classname),\n                                'id:' (id), 'cs:' (css), 'tn:' (tag name),\n                                'lt:' (link text), 'pl:' (partial link text)\n                        \"\"\")\n\n        return effective_selector_list", "response": "Resolve the selector variable in place"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_selector_type(self):\n        resolved_selector_type_list = []\n        for current_selector in self._effective_selector_list:\n            resolved_selector_type_list.append(self.get_type(current_selector))\n\n        set_ = set(resolved_selector_type_list)\n\n        # VALIDATE THAT ALL SELECTOR ARE OF THE SAME TYPE\n        if len(set_) != 1:\n            raise Exception(\"\"\"\n                If you provide a list of selector then\n                all selectors must be of the same type\n            \"\"\")\n        else:\n            return set_.pop()", "response": "Resolve the selector type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve the selenium function that will be used to find the element", "response": "def resolve_function(self):\n        \"\"\"Resolve the selenium function that will be use to find the element\n        \"\"\"\n        selector_type = self._effective_selector_type\n\n        # NAME\n        if selector_type == 'name':\n            return ('find_elements_by_name', 'NAME')\n\n        # XPATH\n        elif selector_type == 'xpath':\n            return ('find_elements_by_xpath', 'XPATH')\n\n        # CLASSNAME\n        elif selector_type == 'class_name':\n            return ('find_elements_by_class_name', 'CLASS_NAME')\n\n        # ID\n        elif selector_type == 'id':\n            return ('find_element_by_id', 'ID')\n\n        # CSS\n        elif selector_type == 'css':\n            return ('find_elements_by_css_selector', 'CSS_SELECTOR')\n\n        # TAGNAME\n        elif selector_type == 'tag_name':\n            return ('find_elements_by_tag_name', 'TAG_NAME')\n\n        # LINK TEXT\n        elif selector_type == 'link_text':\n            return ('find_elements_by_link_text', 'LINK_TEXT')\n\n        # PARTIAL LINK TEXT\n        elif selector_type == 'partial_link_text':\n            return ('find_elements_by_partial_link_text', 'PARTIAL_LINK_TEXT')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_git_tag():\n    with open(os.devnull, 'wb') as devnull:\n        version = subprocess.check_output(['git', 'describe', '--tags'], stderr=devnull)\n        version = version.rstrip()\n    if hasattr(version, 'decode'):\n        version = version.decode('utf-8')\n    return version", "response": "Read the Git project version by running git describe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cache_git_tag():\n    try:\n        version = __get_git_tag()\n        with __open_cache_file('w') as vf:\n            vf.write(version)\n    except Exception:\n        version = __default_version__\n    return version", "response": "Try to read the current version from git and cache it into the version cache file. If read successfully cache it into the version cache file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_to_pypi_version(version):\n    v = re.search('^[r,v]{0,1}(?P<final>[0-9\\.]+)(\\-(?P<pre>(a|b|rc)[0-9]+))?(\\-(?P<dev>dev[0-9]+))?(\\-(?P<post>[0-9]+))?(\\-.+)?$', version)\n    if not v:\n        return __default_version__\n\n    # https://www.python.org/dev/peps/pep-0440/#final-releases\n    version = v.group('final')\n\n    # https://www.python.org/dev/peps/pep-0440/#pre-releases\n    if v.group('pre'):\n        version += v.group('pre')\n\n    # https://www.python.org/dev/peps/pep-0440/#developmental-releases\n    if v.group('dev'):\n        version += '.%s' % v.group('dev')\n\n    # https://www.python.org/dev/peps/pep-0440/#post-releases\n    if v.group('post'):\n        version += '.post%s' % v.group('post')\n\n    return version", "response": "Convert a git tag version string into something compatible with PEP - 440 <https://www. python. org > _."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_version(pypi=False):\n    version = __default_version__\n\n    try:\n        with __open_cache_file('r') as vf:\n            version = vf.read().strip()\n    except Exception:\n        pass\n\n    try:\n        version = __get_git_tag()\n    except Exception:\n        pass\n\n    if pypi:\n        version = convert_to_pypi_version(version)\n\n    if version == __default_version__:\n        logger.warning(\"versiontag could not determine package version using cwd %s. Returning default: %s\" % (os.getcwd(), __default_version__))\n\n    return version", "response": "Get the project version string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef memoize(cache=None):\n\n    if cache is None:\n        cache = {}\n\n    def memoize_decorator(object):\n        \"\"\"\n        Implements method / definition memoization.\n\n        :param object: Object to decorate.\n        :type object: object\n        :return: Object.\n        :rtype: object\n        \"\"\"\n\n        @functools.wraps(object)\n        def memoize_wrapper(*args, **kwargs):\n            \"\"\"\n            Implements method / definition memoization.\n\n            :param \\*args: Arguments.\n            :type \\*args: \\*\n            :param \\*\\*kwargs: Keywords arguments.\n            :type \\*\\*kwargs: \\*\\*\n            :return: Object.\n            :rtype: object\n            \"\"\"\n\n            if kwargs:\n                key = args, frozenset(kwargs.iteritems())\n            else:\n                key = args\n\n            if key not in cache:\n                cache[key] = object(*args, **kwargs)\n\n            return cache[key]\n\n        return memoize_wrapper\n\n    return memoize_decorator", "response": "A memoization decorator that caches the return value of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef system_exit(object):\n\n    @functools.wraps(object)\n    def system_exit_wrapper(*args, **kwargs):\n        \"\"\"\n        Handles proper system exit in case of critical exception.\n\n        :param \\*args: Arguments.\n        :type \\*args: \\*\n        :param \\*\\*kwargs: Keywords arguments.\n        :type \\*\\*kwargs: \\*\\*\n        \"\"\"\n\n        try:\n            if object(*args, **kwargs):\n                foundations.core.exit(0)\n        except Exception as error:\n            sys.stderr.write(\"\\n\".join(foundations.exceptions.format_exception(*sys.exc_info())))\n            foundations.core.exit(1)\n\n    return system_exit_wrapper", "response": "Handles proper system exit in case of critical exception."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning if given object is read only.", "response": "def is_read_only(object):\n    \"\"\"\n    Returns if given object is read only ( built-in or extension ).\n\n    :param object: Object.\n    :type object: object\n    :return: Is object read only.\n    :rtype: bool\n    \"\"\"\n\n    try:\n        attribute = \"_trace__read__\"\n        setattr(object, attribute, True)\n        delattr(object, attribute)\n        return False\n    except (TypeError, AttributeError):\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trace_walker(module):\n\n    for name, function in inspect.getmembers(module, inspect.isfunction):\n        yield None, function\n\n    for name, cls in inspect.getmembers(module, inspect.isclass):\n        yield cls, None\n\n        for name, method in inspect.getmembers(cls, inspect.ismethod):\n            yield cls, method\n\n        for name, function in inspect.getmembers(cls, inspect.isfunction):\n            yield cls, function\n\n        for name, accessor in inspect.getmembers(cls, lambda x: type(x) is property):\n            yield cls, accessor.fget\n            yield cls, accessor.fset\n            yield cls, accessor.fdel", "response": "Returns a generator that yields the class function and method of the specified module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_object_name(object):\n\n    if type(object) is property:\n        return object.fget.__name__\n    elif hasattr(object, \"__name__\"):\n        return object.__name__\n    elif hasattr(object, \"__class__\"):\n        return object.__class__.__name__\n    else:\n        return NULL_OBJECT_NAME", "response": "Returns given object name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_trace_name(object):\n\n    global TRACE_NAMES_CACHE\n    global TRACE_WALKER_CACHE\n\n    trace_name = TRACE_NAMES_CACHE.get(object)\n    if trace_name is None:\n\n        TRACE_NAMES_CACHE[object] = trace_name = get_object_name(object)\n\n        if type(object) is property:\n            object = object.fget\n\n        module = inspect.getmodule(object)\n        if module is None:\n            return\n\n        members = TRACE_WALKER_CACHE.get(module)\n        if members is None:\n            TRACE_WALKER_CACHE[module] = members = tuple(trace_walker(module))\n\n        for (cls, member) in members:\n            if object in (cls, untracer(member)):\n                TRACE_NAMES_CACHE[object] = trace_name = \\\n                    \".\".join(map(get_object_name, filter(lambda x: x is not None, (module, cls, member))))\n                break\n\n    return trace_name", "response": "Returns given object s trace name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_method_name(method):\n\n    name = get_object_name(method)\n    if name.startswith(\"__\") and not name.endswith(\"__\"):\n        name = \"_{0}{1}\".format(get_object_name(method.im_class), name)\n    return name", "response": "Returns given method name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_tracer(*args):\n\n    object, wrapped = args\n    if is_traced(object) or is_untracable(object) or get_object_name(object) in UNTRACABLE_NAMES:\n        return object\n\n    set_tracer_hook(wrapped, object)\n    set_traced(wrapped)\n\n    return wrapped", "response": "Validate and finishes a tracer by adding mandatory extra attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tracer(object):\n\n    @functools.wraps(object)\n    @functools.partial(validate_tracer, object)\n    def tracer_wrapper(*args, **kwargs):\n        \"\"\"\n        Traces execution.\n\n        :param \\*args: Arguments.\n        :type \\*args: \\*\n        :param \\*\\*kwargs: Keywords arguments.\n        :type \\*\\*kwargs: \\*\\*\n        :return: Object.\n        :rtype: object\n        \"\"\"\n\n        code = object.func_code\n        args_count = code.co_argcount\n        args_names = code.co_varnames[:args_count]\n        function_defaults = object.func_defaults or list()\n        args_defaults = dict(zip(args_names[-len(function_defaults):], function_defaults))\n\n        positional_args = map(format_argument, zip(args_names, args))\n        defaulted_args = [format_argument((name, args_defaults[name]))\n                          for name in args_names[len(args):] if name not in kwargs]\n        nameless_args = map(repr, args[args_count:])\n        keyword_args = map(format_argument, kwargs.items())\n        sys.stdout.write(\"{0}({1})\\n\".format(get_trace_name(object),\n                                             \", \".join(itertools.chain(positional_args,\n                                                                       defaulted_args,\n                                                                       nameless_args,\n                                                                       keyword_args))))\n        return object(*args, **kwargs)\n\n    return tracer_wrapper", "response": "Decorator for logging the execution of the current log file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef untracable(object):\n\n    @functools.wraps(object)\n    def untracable_wrapper(*args, **kwargs):\n        \"\"\"\n        Marks decorated object as non tracable.\n\n        :param \\*args: Arguments.\n        :type \\*args: \\*\n        :param \\*\\*kwargs: Keywords arguments.\n        :type \\*\\*kwargs: \\*\\*\n        :return: Object.\n        :rtype: object\n        \"\"\"\n\n        return object(*args, **kwargs)\n\n    set_untracable(untracable_wrapper)\n\n    return untracable_wrapper", "response": "Decorator to mark a object as non tracable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrace given module function using given tracer.", "response": "def trace_function(module, function, tracer=tracer):\n    \"\"\"\n    Traces given module function using given tracer.\n\n    :param module: Module of the function.\n    :type module: object\n    :param function: Function to trace.\n    :type function: object\n    :param tracer: Tracer.\n    :type tracer: object\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    if is_traced(function):\n        return False\n\n    name = get_object_name(function)\n    if is_untracable(function) or name in UNTRACABLE_NAMES:\n        return False\n\n    setattr(module, name, tracer(function))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef untrace_function(module, function):\n\n    if not is_traced(function):\n        return False\n\n    name = get_object_name(function)\n    setattr(module, name, untracer(function))\n    return True", "response": "Untraces given module function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trace_method(cls, method, tracer=tracer):\n\n    if is_traced(method):\n        return False\n\n    name = get_method_name(method)\n    if is_untracable(method) or name in UNTRACABLE_NAMES:\n        return False\n\n    if is_class_method(method):\n        setattr(cls, name, classmethod(tracer(method.im_func)))\n    elif is_static_method(method):\n        setattr(cls, name, staticmethod(tracer(method)))\n    else:\n        setattr(cls, name, tracer(method))\n    return True", "response": "Traces given class method using given tracer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef untrace_method(cls, method):\n\n    if not is_traced(method):\n        return False\n\n    name = get_method_name(method)\n    if is_class_method(method):\n        setattr(cls, name, classmethod(untracer(method)))\n    elif is_static_method(method):\n        setattr(cls, name, staticmethod(untracer(method)))\n    else:\n        setattr(cls, name, untracer(method))\n    return True", "response": "Untraces given class method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace_property(cls, accessor, tracer=tracer):\n\n    if is_traced(accessor.fget) and is_traced(accessor.fset) and is_traced(accessor.fdel):\n        return False\n\n    name = get_method_name(accessor)\n    setattr(cls, name, property(tracer(accessor.fget),\n                                tracer(accessor.fset),\n                                tracer(accessor.fdel)))\n    return True", "response": "Traces given class property using given tracer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntracing given class using given tracer.", "response": "def trace_class(cls, tracer=tracer, pattern=r\".*\", flags=0):\n    \"\"\"\n    Traces given class using given tracer.\n\n    :param cls: Class to trace.\n    :type cls: object\n    :param tracer: Tracer.\n    :type tracer: object\n    :param pattern: Matching pattern.\n    :type pattern: unicode\n    :param flags: Matching regex flags.\n    :type flags: int\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    if not is_base_traced(cls) and (is_traced(cls) or is_read_only(cls)):\n        return False\n\n    for name, method in inspect.getmembers(cls, inspect.ismethod):\n        if not re.search(pattern, name, flags=flags):\n            continue\n\n        trace_method(cls, method, tracer)\n\n    for name, function in inspect.getmembers(cls, inspect.isfunction):\n        if not re.search(pattern, name, flags=flags):\n            continue\n\n        trace_method(cls, function, tracer)\n\n    for name, accessor in inspect.getmembers(cls, lambda x: type(x) is property):\n        if not re.search(pattern, name, flags=flags):\n            continue\n\n        trace_property(cls, accessor, tracer)\n\n    set_traced(cls)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrace given module members using given tracer.", "response": "def trace_module(module, tracer=tracer, pattern=r\".*\", flags=0):\n    \"\"\"\n    Traces given module members using given tracer.\n\n    :param module: Module to trace.\n    :type module: ModuleType\n    :param tracer: Tracer.\n    :type tracer: object\n    :param pattern: Matching pattern.\n    :type pattern: unicode\n    :param flags: Matching regex flags.\n    :type flags: int\n    :return: Definition success.\n    :rtype: bool\n\n    :note: Only members exported by **__all__** attribute will be traced.\n    \"\"\"\n\n    if is_traced(module):\n        return False\n\n    global REGISTERED_MODULES\n\n    for name, function in inspect.getmembers(module, inspect.isfunction):\n        if name not in module.__all__ or not re.search(pattern, name, flags=flags):\n            continue\n\n        trace_function(module, function, tracer)\n\n    for name, cls in inspect.getmembers(module, inspect.isclass):\n        if name not in module.__all__ or not re.search(pattern, name, flags=flags):\n            continue\n\n        trace_class(cls, tracer, pattern, flags)\n\n    REGISTERED_MODULES.add(module)\n\n    set_traced(module)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_module(module=None):\n\n    global REGISTERED_MODULES\n\n    if module is None:\n        # Note: inspect.getmodule() can return the wrong module if it has been imported with different relatives paths.\n        module = sys.modules.get(inspect.currentframe().f_back.f_globals[\"__name__\"])\n\n    REGISTERED_MODULES.add(module)\n    return True", "response": "Registers given module or caller introspected module in the candidates modules for tracing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_tracer(tracer=tracer, pattern=r\".*\", flags=0):\n\n    for module in REGISTERED_MODULES:\n        if not re.search(pattern, module.__name__, flags=flags):\n            continue\n\n        trace_module(module, tracer)\n    return True", "response": "Installs given tracer in the candidates modules for tracing matching given pattern."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls the tracer in the candidates modules for tracing matching given pattern. :param pattern: Matching pattern. :type pattern: unicode :param flags: Matching regex flags. :type flags: int :return: Definition success. :rtype: bool", "response": "def uninstall_tracer(pattern=r\".*\", flags=0):\n    \"\"\"\n    Installs the tracer in the candidates modules for tracing matching given pattern.\n\n    :param pattern: Matching pattern.\n    :type pattern: unicode\n    :param flags: Matching regex flags.\n    :type flags: int\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    for module in REGISTERED_MODULES:\n        if not is_traced(module):\n            continue\n\n        if not re.search(pattern, module.__name__, flags=flags):\n            continue\n\n        untrace_module(module)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef evaluate_trace_request(data, tracer=tracer):\n\n    data = ast.literal_eval(data)\n\n    if isinstance(data, str):\n        modules = dict.fromkeys(map(lambda x: x.strip(), data.split(\",\")), (None, None))\n    elif isinstance(data, list):\n        modules = dict.fromkeys(data, (None, None))\n    elif isinstance(data, dict):\n        modules = data\n\n    for module, (pattern, flags) in modules.iteritems():\n        __import__(module)\n        pattern = pattern if pattern is not None else r\".*\"\n        flags = flags if flags is not None else re.IGNORECASE\n        trace_module(sys.modules[module], tracer, pattern, flags)\n    return True", "response": "Evaluate given string trace request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_session(self):\n        '''\n        Delayed initialization of Requests Session object.\n\n        This is done in order *not* to share the Session object across\n        a multiprocessing pool.\n        '''\n        self._real_session = requests.Session()\n        # FIXME: this fails when one runs HTTPS on non-standard ports,\n        # e.g. https://tissuemaps.example.org:8443/\n        if self._port == 443:\n            logger.debug('initializing HTTPS session')\n            self._real_base_url = 'https://{host}:{port}'.format(host=self._host, port=self._port)\n            self._real_adapter = self._real_session.adapters['https://']\n            if self._ca_bundle is not None:\n                logger.debug('use CA bundle: %s', self._ca_bundle)\n                ca_bundle = os.path.expanduser(os.path.expandvars(self._ca_bundle))\n                if not os.path.exists(ca_bundle):\n                    raise OSError(\n                        'CA bundle file does not exist: {0}'.format(ca_bundle)\n                    )\n                self._real_session.verify = ca_bundle\n        else:\n            logger.debug('initializing HTTP session')\n            self._real_base_url = 'http://{host}:{port}'.format(host=self._host, port=self._port)\n            self._real_adapter = self._real_session.adapters['http://']\n        self._real_session.get(self._real_base_url)\n        self._real_session.headers.update({'Host': self._host})\n        self._login(self._username, self._password)", "response": "Initializes the Requests Session object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the full URL based on the base URL and the provided route and optional parameters.", "response": "def _build_url(self, route, params={}):\n        '''Builds the full URL based on the base URL (``http://<host>:<port>``)\n        and the provided `route`.\n\n        Parameters\n        ----------\n        route: str\n            route used by the TissueMAPS RESTful API\n        params: dict, optional\n            optional parameters that need to be included in the URL query string\n\n        Returns\n        -------\n        str\n            URL\n        '''\n        url = self._base_url + route\n        if not params:\n            logger.debug('url: %s', url)\n            return url\n        url = '{url}?{params}'.format(url=url, params=urlencode(params))\n        logger.debug('url: %s', url)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _login(self, username, password):\n        '''Authenticates a TissueMAPS user.\n\n        Parameters\n        ----------\n        username: str\n            name\n        password: str\n            password\n        '''\n        logger.debug('login in as user \"%s\"' % username)\n        url = self._build_url('/auth')\n        payload = {'username': username, 'password': password}\n        res = self._session.post(url, json=payload)\n        res.raise_for_status()\n        self._access_token = res.json()['access_token']\n        self._session.headers.update(\n            {'Authorization': 'JWT %s' % self._access_token}\n        )", "response": "Authenticates a TissueMAPS user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef force_bytes(s, encoding='utf-8', strings_only=False, errors='strict'):\n    # Handle the common case first for performance reasons.\n    if isinstance(s, bytes):\n        if encoding == 'utf-8':\n            return s\n        else:\n            return s.decode('utf-8', errors).encode(encoding, errors)\n    if strings_only and is_protected_type(s):\n        return s\n    if isinstance(s, memoryview):\n        return bytes(s)\n    if not isinstance(s, str):\n        return str(s).encode(encoding, errors)\n    else:\n        return s.encode(encoding, errors)", "response": "Force bytes to be stored as lazy objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a securely generated random string.", "response": "def get_random_string(length=12,\n                      allowed_chars='abcdefghijklmnopqrstuvwxyz'\n                                    'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'):\n    \"\"\"\n    Return a securely generated random string.\n    The default length of 12 with the a-z, A-Z, 0-9 character set returns\n    a 71-bit value. log_2((26+26+10)^12) =~ 71 bits\n    \"\"\"\n    if not using_sysrandom:\n        # This is ugly, and a hack, but it makes things better than\n        # the alternative of predictability. This re-seeds the PRNG\n        # using a value that is hard for an attacker to predict, every\n        # time a random string is required. This may change the\n        # properties of the chosen random sequence slightly, but this\n        # is better than absolute predictability.\n        random.seed(\n            hashlib.sha256(\n                ('%s%s%s' % (random.getstate(), time.time(), settings.SECRET_KEY)).encode()\n            ).digest()\n        )\n        return ''.join(random.choice(allowed_chars) for i in range(length))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the raw password matches the three - digit encoded digest.", "response": "def check_password(password, encoded, setter=None, preferred='default'):\n    \"\"\"\n    Return a boolean of whether the raw password matches the three\n    part encoded digest.\n    If setter is specified, it'll be called when you need to\n    regenerate the password.\n    \"\"\"\n    if password is None:\n        return False\n\n    preferred = bCryptPasswordHasher\n    hasher = bCryptPasswordHasher\n\n    hasher_changed = hasher.algorithm != preferred.algorithm\n    must_update = hasher_changed or preferred.must_update(encoded)\n    is_correct = hasher.verify(password, encoded)\n\n    # If the hasher didn't change (we don't protect against enumeration if it\n    # does) and the password should get updated, try to close the timing gap\n    # between the work factor of the current encoded password and the default\n    # work factor.\n    if not is_correct and not hasher_changed and must_update:\n        hasher.harden_runtime(password, encoded)\n\n    if setter and is_correct and must_update:\n        setter(password)\n    return is_correct"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_password(password, salt=None, hasher='default'):\n    if password is None:\n        return UNUSABLE_PASSWORD_PREFIX + get_random_string(UNUSABLE_PASSWORD_SUFFIX_LENGTH)\n    hasher = bCryptPasswordHasher\n\n    if not salt:\n        salt = hasher.salt()\n\n    return hasher.encode(password, salt)", "response": "Make a plain - text password into a random salt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mask_hash(hash, show=6, char=\"*\"):\n    masked = hash[:show]\n    masked += char * len(hash[show:])\n    return masked", "response": "Masks a given hash with only the first show number shown."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_data(self):\n        options=self.options\n        command = open(self.options.data_script).read()\n        self.result[\"data_script\"]=command\n        t0=time.time()\n        data=None       #fallback data\n        exec(command)   #creates variable data\n        t1=time.time()\n        print((\"Elapsed time for data reading is %.2f seconds\" % (t1-t0)))\n        self.data=data\n        return self.data", "response": "Load the data from the data_script"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_experiment(self):\n        data=self.data\n        options=self.options\n        result=self.result\n\n        command = open(self.options.experiment_script).read()\n        result[\"experiment_script\"]=command\n        t0=time.time()\n        exec(command)   #creates variable result\n        t1=time.time()\n        print((\"Elapsed time for running the experiment is %.2f seconds\" % (t1-t0)))\n        self.result=result\n        return self.result", "response": "Runs the job specified in experiment_script\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the output to disk", "response": "def write_resultfiles(self):\n        \"\"\"\n        Write the output to disk\n        \"\"\"\n        t0=time.time()\n        writer = ow.output_writer(output_dictionary=self.result)\n        if len(self.options.outpath)>=3 and self.options.outpath[-3:]==\".h5\":\n            writer.write_hdf5(filename=self.options.outpath,timestamp=self.options.timestamp)\n        else:\n            writer.write_txt(outdir=self.options.outpath,timestamp=self.options.timestamp,delimiter=self.options.delimiter,float_format=self.options.float_format)\n        t1=time.time()\n        print((\"Elapsed time for writing the output files is %.2f seconds\" % (t1-t0)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a declarative model for storing signatures related to the given cls parameter.", "response": "def generate_signature_class(cls):\n    \"\"\"\n    Generate a declarative model for storing signatures related to the given\n    cls parameter.\n\n    :param class cls: The declarative model to generate a signature class for.\n    :return: The signature class, as a declarative derived from Base.\n    \"\"\"\n    return type(\"%sSigs\" % cls.__name__, (Base,),\n                {'__tablename__': \"%s_sigs\" % cls.__tablename__,\n                 'id': sa.Column(sa.Integer,\n                                 sa.Sequence('%s_id_seq' % cls.__tablename__),\n                                 primary_key=True,\n                                 doc=\"primary key\"),\n                 'data': sa.Column(sa.Text(), nullable=False,\n                                   doc=\"The signed data\"),\n                 '%s_id' % cls.__tablename__: sa.Column(sa.Integer,\n                                                        sa.ForeignKey(\"%s.id\" % cls.__tablename__),\n                                                        nullable=False)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_session_engine(uri=None, cfg=None):\n    if uri is not None:\n        eng = sa.create_engine(uri)\n    elif cfg is not None:\n        eng = sa.create_engine(cfg.get('db', 'SA_ENGINE_URI'))\n    else:\n        raise IOError(\"unable to connect to SQL database\")\n    ses = orm.sessionmaker(bind=eng)()\n    return ses, eng", "response": "Create an sqlalchemy session and engine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_database(eng, modules=None, models=None):\n    if modules is not None:\n        for modu in modules:\n            for m in modu.__all__:\n                getattr(modu, m).metadata.create_all(eng)\n    if models is not None:\n        for mod in models:\n            mod.metadata.create_all(eng)", "response": "Setup databases using create_all."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recursive_update(a, b, **kwargs):\n    copy = kwargs.get('copy', False)\n    merge_lists = kwargs.get('merge_lists', True)\n\n    for k, v in b.items():\n        if isinstance(v, collections.Mapping):\n            if isinstance(a.get(k, None), collections.Mapping):\n                recursive_update(a[k], v, **kwargs)\n                continue\n\n        elif merge_lists and type(v) is list:\n            if type(a.get(k, None)) is list:\n                if copy:\n                    a[k].extend(deepcopy(v))\n                else:\n                    a[k].extend(v)\n                continue\n\n        # warning, clobbering\n        if copy:\n            a[k] = deepcopy(v)\n        else:\n            a[k] = v\n\n    return a", "response": "recursive dict a. update b merges dicts and lists\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ctcp_unpack_message(info):\n    verb = info['verb']\n    message = info['params'][1]\n\n    # NOTE: full CTCP dequoting and unpacking is not done here, only a subset\n    #   this is because doing the full thing breaks legitimate messages\n\n    # basics\n    infos = []\n\n    X_QUOTE = '\\\\'\n    X_DELIM = '\\x01'\n\n    # tagged data\n    messages = str(message).split(X_DELIM)\n\n    for i in range(len(messages)):\n        msg = messages[i]\n        new_info = dict(info)\n\n        if i % 2 == 0:  # is normal message)\n            if not msg:\n                continue\n            new_info['params'] = new_info['params'][:1]\n            new_info['params'].append(msg)\n        else:\n            if verb in ['privnotice', 'pubnotice']:\n                new_info['verb'] = 'ctcp_reply'\n            else:\n                new_info['verb'] = 'ctcp'\n            if ' ' in msg.lstrip():\n                new_info['ctcp_verb'], new_info['ctcp_text'] = msg.lstrip().split(' ', 1)\n            else:\n                new_info['ctcp_verb'] = msg.lstrip()\n                new_info['ctcp_text'] = ''\n\n            new_info['ctcp_verb'] = new_info['ctcp_verb'].lower()\n\n        infos.append([new_info['verb'], new_info])\n\n    # ctcp-level dequoting\n    for i in range(len(infos)):\n        if infos[i][NAME_ATTR] == 'ctcp':\n            attrs = ['ctcp_verb', 'ctcp_text']\n        else:\n            attrs = ['params']\n\n        for attr in attrs:\n            if isinstance(infos[i][INFO_ATTR][attr], (list, tuple)):\n                raw_messages = infos[i][INFO_ATTR][attr]\n            else:\n                raw_messages = [infos[i][INFO_ATTR][attr]]\n\n            messages = []\n            for raw in raw_messages:\n                unquoted = ''\n                while len(raw):\n                    char = raw[0]\n                    raw = raw[1:]\n\n                    if char == X_QUOTE:\n                        if not len(raw):\n                            continue\n                        key = raw[0]\n                        raw = raw[1:]\n\n                        if key == 'a':\n                            unquoted += X_DELIM\n                        elif key == X_QUOTE:\n                            unquoted += X_QUOTE\n                        else:\n                            unquoted += key\n                    else:\n                        unquoted += char\n                messages.append(unquoted)\n\n            if isinstance(infos[i][INFO_ATTR][attr], (list, tuple)):\n                infos[i][INFO_ATTR][attr] = messages\n            else:\n                infos[i][INFO_ATTR][attr] = messages[0]\n\n    return infos", "response": "Given a CTCP message returns events."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an RFC1459Message into an event object.", "response": "def message_to_event(direction, message):\n    \"\"\"Prepare an ``RFC1459Message`` for event dispatch.\n\n    We do this because we have to handle special things as well, such as CTCP\n    and deconstructing verbs properly.\n    \"\"\"\n    server = message.server\n\n    # change numerics into nice names\n    if message.verb in numerics:\n        message.verb = numerics[message.verb]\n    verb = message.verb.lower()\n\n    # modify public/private verbs\n    if verb == 'privmsg':\n        if server.is_channel(message.params[0]):\n            verb = 'pubmsg'\n    if verb == 'notice':\n        verb = 'privnotice'\n        if server.is_channel(message.params[0]):\n            verb = 'pubnotice'\n    elif verb == 'mode':\n        verb = 'umode'\n        if server.is_channel(message.params[0]):\n            verb = 'cmode'\n\n    # this is the same as ircreactor does\n    info = message.__dict__\n    info['direction'] = direction\n    info['verb'] = verb\n\n    if 'time' in info['tags']:\n        info['server_time'] = time.strptime(info['tags']['time'],\n                                            '%Y-%m-%dT%H:%M:%S.%fZ')\n\n    infos = [[verb, info], ]\n\n    # handle shitty ctcp\n    if verb in ('privmsg', 'pubmsg', 'privnotice', 'pubnotice'):\n        infos = ctcp_unpack_message(info)\n\n    # work on each info object separately\n    i = -1\n    while i < (len(infos) - 1):\n        i += 1\n        name = infos[i][NAME_ATTR]\n\n        # standard message attributes\n        for attr, param_map in _verb_param_map.items():\n            # escaping\n            escaped = False\n            if attr.startswith('escaped_'):\n                attr = attr.lstrip('escaped_')\n                escaped = True\n\n            for param_number, verbs in param_map.items():\n                if len(infos[i][INFO_ATTR]['params']) > param_number and name in verbs:\n                    value = infos[i][INFO_ATTR]['params'][param_number]\n                    if escaped:\n                        value = escape(value)\n                    infos[i][INFO_ATTR][attr] = value\n\n        # custom processing\n        if name == 'welcome':\n            # for servers where a low nicklen makes them silently truncate our nick\n            server.nick = server.istring(infos[i][INFO_ATTR]['nick'])\n\n        # custom message attributes\n        if name == 'ctcp':\n            if infos[i][INFO_ATTR]['ctcp_verb'] == 'action':\n                info = dict(infos[i][INFO_ATTR])\n                info['message'] = info['ctcp_text']\n                if server.is_channel(info['target']):\n                    name = 'pubaction'\n                    info['channel'] = info['target']\n                else:\n                    name = 'privaction'\n                infos.append([name, info])\n\n        if name == 'umode' and len(infos[i][INFO_ATTR]['params']) > 1:\n            modestring = infos[i][INFO_ATTR]['params'][1:]\n            modes = parse_modes(modestring)\n\n            infos[i][INFO_ATTR]['modestring'] = ' '.join(modestring).strip()\n            infos[i][INFO_ATTR]['modes'] = modes\n\n        if name == 'cmode' and len(infos[i][INFO_ATTR]['params']) > 1:\n            modestring = infos[i][INFO_ATTR]['params'][1:]\n            chanmodes = server.features.get('chanmodes')\n            prefixes = list(server.features.get('prefix').keys())\n            modes = parse_modes(modestring, chanmodes, prefixes)\n\n            infos[i][INFO_ATTR]['modestring'] = ' '.join(modestring).strip()\n            infos[i][INFO_ATTR]['modes'] = modes\n\n        if name == 'cmodeis':\n            if len(infos[i][INFO_ATTR]['params']) > 2:\n                modestring = infos[i][INFO_ATTR]['params'][2:]\n                chanmodes = server.features.get('chanmodes')\n                modes = parse_modes(modestring, chanmodes)\n\n                infos[i][INFO_ATTR]['modestring'] = ' '.join(modestring).strip()\n                infos[i][INFO_ATTR]['modes'] = modes\n            else:\n                infos[i][INFO_ATTR]['modestring'] = ''\n                infos[i][INFO_ATTR]['modes'] = []\n\n        if name == 'namreply':\n            channel_name = infos[i][INFO_ATTR]['params'][2]\n            server.info.create_channel(channel_name)\n            channel = server.info.channels.get(channel_name)\n\n            nice_names = []\n            channel_prefixes = {}\n            if len(infos[i][INFO_ATTR]['params']) > 3:\n                raw_names = infos[i][INFO_ATTR]['params'][3].split(' ')\n            else:\n                raw_names = []\n\n            for name in raw_names:\n                # InspIRCd sends us an empty last param because they are cool\n                if not len(name):\n                    continue\n\n                prefixes = ''\n                while name[0] in server.features.available['prefix'].values():\n                    prefixes += name[0]\n                    name = name[1:]\n\n                nick = NickMask(name).nick\n\n                server.info.create_user(nick)\n                nice_names.append(name)\n                server.info.create_user(name)\n                user = server.info.users.get(nick)\n                channel_prefixes[user] = prefixes\n                channel.add_user(nick, prefixes=prefixes)\n\n            infos[i][INFO_ATTR]['users'] = ','.join(nice_names)\n            infos[i][INFO_ATTR]['prefixes'] = channel_prefixes\n\n        # source / target mapping\n        for attr in ('source', 'target', 'channel'):\n            if attr in infos[i][INFO_ATTR] and infos[i][INFO_ATTR][attr]:\n                source = infos[i][INFO_ATTR][attr]\n                if server.is_channel(source):\n                    server.info.create_channel(source)\n                    infos[i][INFO_ATTR][attr] = server.info.channels.get(source)\n                elif '.' in source and server.is_server(source):\n                    server.info.create_server(source)\n                    infos[i][INFO_ATTR][attr] = server.info.servers.get(source)\n                elif server.is_nick(source):\n                    server.info.create_user(source)\n                    infos[i][INFO_ATTR][attr] = server.info.users.get(NickMask(source).nick)\n                else:  # we assume this is a user with messed up characters\n                    server.info.create_user(source)\n                    infos[i][INFO_ATTR][attr] = server.info.users.get(NickMask(source).nick)\n\n        if 'channels' in infos[i][INFO_ATTR] and infos[i][INFO_ATTR]['channels']:\n            channels = []\n            for chan in infos[i][INFO_ATTR]['channels'].split(','):\n                server.info.create_channel(chan)\n                channels.append(server.info.channels.get(chan))\n            infos[i][INFO_ATTR]['channels'] = channels\n\n        if 'users' in infos[i][INFO_ATTR] and infos[i][INFO_ATTR]['users']:\n            users = []\n            for user in infos[i][INFO_ATTR]['users'].split(','):\n                server.info.create_user(user)\n                users.append(server.info.users.get(NickMask(user).nick))\n            infos[i][INFO_ATTR]['users'] = users\n\n        # custom from_to attribute for ease in bots\n        verb = infos[i][INFO_ATTR]['verb']\n        dir = infos[i][INFO_ATTR]['direction']\n        source = infos[i][INFO_ATTR].get('source')\n        target = infos[i][INFO_ATTR].get('target')\n\n        if verb in ['pubmsg', 'pubnotice', 'pubaction']:\n            infos[i][INFO_ATTR]['from_to'] = target\n        elif verb in ['privmsg', 'privnotice', 'privaction']:\n            if dir == 'out':\n                infos[i][INFO_ATTR]['from_to'] = target\n            elif dir == 'in':\n                if 'echo-message' in server.capabilities.enabled:\n                    infos[i][INFO_ATTR]['from_to'] = target\n                else:\n                    infos[i][INFO_ATTR]['from_to'] = source\n        if 'from_to' in infos[i][INFO_ATTR] and infos[i][INFO_ATTR]['from_to'] is None:\n            del infos[i][INFO_ATTR]['from_to']\n\n        # convenience function so unnecessary messages can get ignored easily\n        infos[i][INFO_ATTR]['will_be_echod'] = False\n        if verb in ['pubmsg', 'pubnotice', 'privmsg', 'privnotice']:\n            if dir == 'out' and 'echo-message' in server.capabilities.enabled:\n                infos[i][INFO_ATTR]['will_be_echod'] = True\n\n        if 'from_to' in infos[i][INFO_ATTR] and infos[i][INFO_ATTR]['from_to'].is_server:\n            del infos[i][INFO_ATTR]['from_to']\n\n    return infos"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestimates the power of a study with the given parameters", "response": "def power(maf=0.5,beta=0.1, N=100, cutoff=5e-8):\n\t\"\"\"\n\testimate power for a given allele frequency, effect size beta and sample size N\n\n\tAssumption:\n\t\n\tz-score = beta_ML distributed as p(0) = N(0,1.0(maf*(1-maf)*N))) under the null hypothesis\n\tthe actual beta_ML is distributed as p(alt) = N( beta , 1.0/(maf*(1-maf)N) )\n\t\n\n\t\n\tArguments:\n\t\tmaf:\tminor allele frequency of the SNP\n\t\tbeta:\teffect size of the SNP\n\t\tN:\t\tsample size (number of individuals)\n\tReturns:\n\t\tpower:\tprobability to detect a SNP in that study with the given parameters\n\t\"\"\"\n\t\n\t\"\"\"\n\tstd(snp)=sqrt(2.0*maf*(1-maf)) \n\tpower = \\int \n\n\tbeta_ML = (snp^T*snp)^{-1}*snp^T*Y = cov(snp,Y)/var(snp)   \n\tE[beta_ML]\t= (snp^T*snp)^{-1}*snp^T*E[Y]  \n\t\t\t\t= (snp^T*snp)^{-1}*snp^T*snp * beta\n\t\t\t\t= beta\n\tVar[beta_ML]= (snp^T*snp)^{-1}*(snp^T*snp)*(snp^T*snp)^{-1}\n\t\t\t\t= (snp^T*snp)^{-1}\n\t\t\t\t= 1/N * var(snp)\n\t\t\t\t= 1/N * maf*(1-maf)\n\t\"\"\"\n\tassert maf>=0.0 and maf<=0.5, \"maf needs to be between 0.0 and 0.5, got %f\" % maf\n\tif beta<0.0:\n\t\tbeta=-beta\n\tstd_beta = 1.0/np.sqrt(N*(2.0 * maf*(1.0-maf)))\n\tnon_centrality = beta\n\tbeta_samples = np.random.normal(loc=non_centrality, scale=std_beta)\n\tn_grid = 100000\n\tbeta_in = np.arange(0.5/(n_grid+1.0),(n_grid-0.5)/(n_grid+1.0),1.0/(n_grid+1.0)) \n\tbeta_theoretical = ((st.norm.isf(beta_in)* std_beta) + non_centrality)\n\tpvals = st.chi2.sf( (beta_theoretical/std_beta)*(beta_theoretical/std_beta) ,1.0) \n\t\n\tpower = (pvals<cutoff).mean()\n\treturn power, pvals"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _call_cmd_line(self):\n        try:\n            logging.info(\"Calling Popen with: {}\".format(self.args))\n            p = Popen(self.args, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n        except OSError:\n            raise(RuntimeError(\"No such command found in PATH\"))\n\n        # Calling this command with newline as stdin as the\n        # iCommnads hangs waiting for user input if the password\n        # has not been set or has timed out.\n        self.stdout, self.stderr = p.communicate(\"\\n\".encode())\n        self.stdout = self.stdout.decode(\"utf-8\")\n        self.stderr = self.stderr.decode(\"utf-8\")\n        self.returncode = p.returncode", "response": "Run the command line tool."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the ASDL tree for correctness.", "response": "def check(mod):\n    \"\"\"Check the parsed ASDL tree for correctness.\n\n    Return True if success. For failure, the errors are printed out and False\n    is returned.\n    \"\"\"\n    v = Check()\n    v.visit(mod)\n\n    for t in v.types:\n        if t not in mod.types and not t in builtin_types:\n            v.errors += 1\n            uses = \", \".join(v.types[t])\n            print('Undefined type {}, used in {}'.format(t, uses))\n    return not v.errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(filename):\n    with open(filename) as f:\n        parser = ASDLParser()\n        return parser.parse(f.read())", "response": "Parse ASDL from the given file and return a Module node describing it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tokenize_asdl(buf):\n    for lineno, line in enumerate(buf.splitlines(), 1):\n        for m in re.finditer(r'\\s*(\\w+|--.*|.)', line.strip()):\n            c = m.group(1)\n            if c[0].isalpha():\n                # Some kind of identifier\n                if c[0].isupper():\n                    yield Token(TokenKind.ConstructorId, c, lineno)\n                else:\n                    yield Token(TokenKind.TypeId, c, lineno)\n            elif c[:2] == '--':\n                # Comment\n                break\n            else:\n                # Operators\n                try:\n                    op_kind = TokenKind.operator_table[c]\n                except KeyError:\n                    raise ASDLSyntaxError('Invalid operator %s' % c, lineno)\n                yield Token(op_kind, c, lineno)", "response": "Tokenize the given buffer. Yield Token objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the ASDL in the buffer and return an AST with a Module root.", "response": "def parse(self, buf):\n        \"\"\"Parse the ASDL in the buffer and return an AST with a Module root.\n        \"\"\"\n        self._tokenizer = tokenize_asdl(buf)\n        self._advance()\n        return self._parse_module()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _advance(self):\n        cur_val = None if self.cur_token is None else self.cur_token.value\n        try:\n            self.cur_token = next(self._tokenizer)\n        except StopIteration:\n            self.cur_token = None\n        return cur_val", "response": "Return the value of the current token and read the next one into the current token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bytes2iec(size, compact=False):\n    postfn = lambda text: text.replace(' ', '') if compact else text\n    if size < 0:\n        raise ValueError(\"Negative byte size value {}\".format(size))\n    if size < 1024:\n        return postfn('{:4d} bytes'.format(size))\n\n    scaled = size\n    for iec_unit in IEC_UNITS[1:]:\n        scaled /= 1024.0\n        if scaled < 1024:\n            return postfn('{:6.1f} {}'.format(scaled, iec_unit))\n\n    raise ValueError(\"Byte size value {} out of bounds\".format(size))", "response": "Converts a size value in bytes to its equivalent in IEC notation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iec2bytes(size_spec, only_positive=True):\n    scale = 1\n    try:\n        size = int(0 + size_spec)  # return numeric values as-is\n    except (TypeError, ValueError):\n        spec = size_spec.strip().lower()\n\n        for exp, iec_unit in enumerate(IEC_UNITS[1:], 1):\n            iec_unit = iec_unit.lower()\n            if spec.endswith(iec_unit):\n                spec = spec[:-len(iec_unit)]\n                scale = 2 ** (10 * exp)\n                break\n            elif spec.endswith(iec_unit[0]):\n                spec = spec[:-1]\n                scale = 2 ** (10 * exp)\n                break\n        else:\n            if spec.endswith('b'):\n                spec = spec[:-1]\n\n        try:\n            if '.' in spec:\n                size = float(spec.strip())\n            else:\n                size = int(spec.strip(), base=0)\n        except (TypeError, ValueError) as cause:\n            raise ValueError('Invalid bytes size specification {!r}: {}'.format(size_spec, cause))\n\n    if only_positive and size < 0:\n        raise ValueError('Invalid negative bytes size specification {!r}'.format(size_spec))\n\n    return int(size * scale)", "response": "Convert a size specification in IEC notation to a number of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_adjacent(numbers, indicator='..', base=0):\n    integers = list(sorted([(int(\"%s\" % i, base), i) for i in numbers]))\n    idx = 0\n    result = []\n    while idx < len(numbers):\n        end = idx + 1\n        while end < len(numbers) and integers[end-1][0] == integers[end][0] - 1:\n            end += 1\n\n        result.append(\"%s%s%s\" % (integers[idx][1], indicator, integers[end-1][1])\n                      if end > idx + 1\n                      else \"%s\" % integers[idx][1])\n        idx = end\n    return result", "response": "Merge adjacent numbers in an iterable of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the emissions and transitions probabilities of a given corpus entry.", "response": "def _compute_emissions(self, corpus, order=1):\n        \"\"\" Computes the emissions and transitions probabilities of a corpus\n            based on word types\n        Args:\n            corpus: the given corpus (a corpus_entry needs to be iterable)\n            order: the maximal Markov chain order\n        Computes:\n            self.emissions: Probabilities to emit word (token_value) at state x (token_type)\n            self.transitions_hmm: Transition probabilities to switch between states (token_type)\n            self.emissions_past: Probabilities to emit a word (token_value) at state x\n                                 (token_type) based on previous emissions (token_value)\n        \"\"\"\n        self.emissions = defaultdict(lambda: defaultdict(int))\n        self.transitions_hmm = defaultdict(lambda: defaultdict(int))\n        self.emissions_past = defaultdict(\n            lambda: defaultdict(lambda: defaultdict(int)))\n\n        for corpus_entry in corpus:\n            tokens = self.pos_tag(corpus_entry)\n\n            last_tokens = utils.prefilled_buffer(\n                self._start_symbol, length=self.order)\n            last_emissions = utils.prefilled_buffer(\n                self._start_symbol, length=self.order_emissions)\n\n            for token in chain(tokens, [[self._end_symbol] * 2]):\n                token_value = token[0]\n                token_type = token[1]\n\n                for suffix in utils.get_suffixes(last_tokens):\n                    self.transitions_hmm[suffix][token_type] += 1\n                    self.emissions[token_type][token_value] += 1\n\n                for suffix in utils.get_suffixes(last_emissions):\n                    self.emissions_past[token_type][\n                        suffix][token_value] += 1\n\n                last_tokens.append(token_type)\n                last_emissions.append(token_value)\n\n        self._compute_relative_probs(self.emissions)\n        self._compute_relative_probs(self.transitions_hmm)\n        for val in self.emissions_past.values():\n            self._compute_relative_probs(val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_text(self, generation_type='markov'):\n        assert generation_type in ['markov', 'hmm', 'hmm_past']\n        if generation_type == \"markov\":\n            return self._text_generator(next_token=self._generate_next_token)\n        elif generation_type == \"hmm\":\n            return self._text_generator(next_token=self._generate_next_token_hmm, emit=self._emitHMM)\n        elif generation_type == \"hmm_past\":\n            return self._text_generator(next_token=self._generate_next_token_hmm, emit=self._emitHMM_with_past)", "response": "Generates a string of sentences from a given corpus."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nemits a word based on previous tokens", "response": "def _emitHMM(self, token_type, past_states, past_emissions):\n        \"\"\" emits a word based on previous tokens \"\"\"\n        assert token_type in self.emissions\n        return utils.weighted_choice(self.emissions[token_type].items())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nemit a word based on previous states and emissions.", "response": "def _emitHMM_with_past(self, token_type, past_states, past_emissions):\n        \"\"\" emits a word based on previous states (=token) and previous emissions (=words)\n        The states and emissions are weighted according to their defined probabilities\n            self.prob_hmm_states and self.prob_hmm_emissions\"\"\"\n        assert token_type in self.emissions\n        states_items = [(x[0], x[1] * self.prob_hmm_states)\n                        for x in self.emissions[token_type].items()]\n        key_emissions = tuple(past_emissions)\n        if key_emissions in self.emissions_past[token_type]:\n            states_emissions = [(x[0], x[1] * self.prob_hmm_emissions) for x in self.emissions_past[\n                                token_type][tuple(past_emissions)].items()]\n            return utils.weighted_choice(states_items + states_emissions)\n        return utils.weighted_choice(states_items)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if haystack contains needle", "response": "def inurl(needles, haystack, position='any'):\n    \"\"\"convenience function to make string.find return bool\"\"\"\n\n    count = 0\n\n    # lowercase everything to do case-insensitive search\n    haystack2 = haystack.lower()\n\n    for needle in needles:\n        needle2 = needle.lower()\n        if position == 'any':\n            if haystack2.find(needle2) > -1:\n                count += 1\n        elif position == 'end':\n            if haystack2.endswith(needle2):\n                count += 1\n        elif position == 'begin':\n            if haystack2.startswith(needle2):\n                count += 1\n\n    # assessment\n    if count > 0:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sniff_link(url):\n\n    protocol = None\n    link = url.strip()\n\n    # heuristics begin\n    if inurl(['service=CSW', 'request=GetRecords'], link):\n        protocol = 'OGC:CSW'\n    elif inurl(['service=SOS', 'request=GetObservation'], link):\n        protocol = 'OGC:SOS'\n    elif inurl(['service=WCS', 'request=GetCoverage'], link):\n        protocol = 'OGC:WCS'\n    elif inurl(['service=WFS', 'request=GetFeature'], link):\n        protocol = 'OGC:WFS'\n    elif inurl(['service=WMS', 'request=GetMap'], link):\n        protocol = 'OGC:WMS'\n    elif inurl(['service=WPS', 'request=Execute'], link):\n        protocol = 'OGC:WPS'\n    elif inurl(['arcims'], link):\n        protocol = 'ESRI:ArcIMS'\n    elif inurl(['arcgis'], link):\n        protocol = 'ESRI:ArcGIS'\n    elif inurl(['mpk'], link, 'end'):\n        protocol = 'ESRI:MPK'\n    elif inurl(['opendap'], link):\n        protocol = 'OPeNDAP:OPeNDAP'\n    elif inurl(['ncss'], link):\n        protocol = 'UNIDATA:NCSS'\n    elif inurl(['cdmremote'], link):\n        protocol = 'UNIDATA:CDM'\n    elif inurl(['gml'], link, 'end'):\n        protocol = 'OGC:GML'\n    elif inurl(['htm', 'html', 'shtml'], link, 'end'):\n        protocol = 'WWW:LINK'\n    # extra tests\n    elif all([inurl(['census.gov/geo/tiger'], link),\n              inurl(['zip'], link, 'end')]):\n        protocol = 'ESRI:SHAPEFILE'\n    elif inurl(['7z', 'bz2', 'gz', 'rar', 'tar.gz', 'tgz', 'zip'],\n               link, 'end'):\n        protocol = 'WWW:DOWNLOAD'\n    elif inurl(['kml', 'kmz'], link, 'end'):\n        protocol = 'OGC:KML'\n    else:\n        LOGGER.info('No link type detected')\n\n    return protocol", "response": "detects what the URL is"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef startup(self):\n        self.runner.info_log(\"Startup\")\n\n        if self.browser_config.config.get('enable_proxy'):\n            self.start_proxy()", "response": "Start the instance\nMimeType"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntear down the instance of the current object", "response": "def tear_down(self):\n        \"\"\"Tear down the instance\n\n        This is mainly use to stop the proxy\n        \"\"\"\n        self.runner.info_log(\"Tear down\")\n\n        if self.browser_config.config.get('enable_proxy'):\n            self.stop_proxy()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_command(self, command):\n\n        self.runner.info_log(\"Executing command: %s\" % command)\n\n        process = Popen(\n                command,\n                stdout=open(os.devnull, 'w'),\n                stderr=open('runner.log', 'a'),\n        )\n\n        return process", "response": "Execute a command in a subprocess and return the process object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the mitmproxy proxy process", "response": "def start_proxy(self, port=None):\n        \"\"\"Start the mitmproxy\n        \"\"\"\n\n        self.runner.info_log(\"Starting proxy...\")\n\n        # Get a random port that is available\n        if not port:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.bind(('0.0.0.0', 0))\n            sock.listen(5)\n            self.proxy_port = sock.getsockname()[1]\n            sock.close()\n\n        network_data_path = os.path.join(\n            self.runner.runner_dir,\n            'network_capture'\n        )\n        create_dir_if_doesnt_exist(network_data_path)\n\n        self.proxy_output_path = os.path.join(\n            network_data_path,\n            string_to_filename('%s.data' % self.test_name)\n        )\n\n        path_to_mitmproxy = BROME_CONFIG['mitmproxy']['path']\n\n        if not path_to_mitmproxy:\n            raise Exception(\"\"\"\n                You need to set the mitmproxy:path config to be able\n                to the use the proxy with this browser\n            \"\"\")\n\n        filter_ = BROME_CONFIG['mitmproxy']['filter']\n        command = [\n            path_to_mitmproxy,\n            \"-p\",\n            \"%s\" % self.proxy_port,\n            \"-w\",\n            self.proxy_output_path\n        ]\n\n        if filter_:\n            command.append(filter_)\n\n        process = self.execute_command(command)\n\n        self.proxy_pid = process.pid\n\n        self.runner.info_log(\"Proxy pid: %s\" % self.proxy_pid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops the proxy process if it exists.", "response": "def stop_proxy(self):\n        \"\"\"Stop the mitmproxy\n        \"\"\"\n\n        self.runner.info_log(\"Stopping proxy...\")\n\n        if hasattr(self, 'proxy_pid'):\n            try:\n                kill_by_pid(self.proxy_pid)\n            except psutil.NoSuchProcess:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders given template string and return the result.", "response": "def renders_impl(self, template_content, context,\n                     at_encoding=anytemplate.compat.ENCODING, **kwargs):\n        \"\"\"\n        Render given template string and return the result.\n\n        :param template_content: Template content\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_encoding: Template encoding\n        :param kwargs: Keyword arguments such as:\n            - at_paths: Template search paths\n            - Other keyword arguments passed to the template engine to render\n              templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        tmpdir = os.environ.get(\"TMPDIR\", \"/tmp\")\n        res = template_content\n        try:\n            (ofd, opath) = tempfile.mkstemp(prefix=\"at-tenjin-tmpl-\",\n                                            dir=tmpdir)\n            os.write(ofd, template_content.encode(at_encoding))\n            os.close(ofd)\n\n            res = self.render_impl(opath, context, **kwargs)\n        except (IOError, OSError) as exc:\n            LOGGER.error(\"Failed to render from tempral template: %s\"\n                         \" [exc=%r]\", opath, exc)\n            raise\n        finally:\n            try:\n                os.remove(opath)\n                os.removedirs(os.path.dirname(opath))\n            except (IOError, OSError):\n                pass\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender given template file and return the result.", "response": "def render_impl(self, template, context, at_paths=None, **kwargs):\n        \"\"\"\n        Render given template file and return the result.\n\n        :param template: Template file path\n        :param context: A dict or dict-like object to instantiate given\n            template file\n        :param at_paths: Template search paths\n        :param kwargs: Keyword arguments passed to the template engine to\n            render templates with specific features enabled.\n\n        :return: Rendered string\n        \"\"\"\n        # Override the path to pass it to tenjin.Engine.\n        if at_paths is not None:\n            paths = at_paths + self.engine_options.get(\"path\", [])\n            self.engine_options[\"path\"] = paths\n\n        engine = tenjin.Engine(**self.engine_options)\n        LOGGER.warning(\"engine_options=%s\", str(self.engine_options))\n\n        kwargs = self.filter_options(kwargs, self.render_valid_options())\n        return engine.render(template, context, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates how many padding bytes needed for fmt to be aligned to align.", "response": "def calc_padding(fmt, align):\n    \"\"\"Calculate how many padding bytes needed for ``fmt`` to be aligned to\n    ``align``.\n\n    Args:\n        fmt (str): :mod:`struct` format.\n        align (int): alignment (2, 4, 8, etc.)\n\n    Returns:\n        str: padding format (e.g., various number of 'x').\n\n    >>> calc_padding('b', 2)\n    'x'\n\n    >>> calc_padding('b', 3)\n    'xx'\n    \"\"\"\n    remain = struct.calcsize(fmt) % align\n    if remain == 0:\n        return \"\"\n    return 'x' * (align - remain)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naligning the offset up to align boundary.", "response": "def align_up(offset, align):\n    \"\"\"Align ``offset`` up to ``align`` boundary.\n\n    Args:\n        offset (int): value to be aligned.\n        align (int): alignment boundary.\n\n    Returns:\n        int: aligned offset.\n\n    >>> align_up(3, 2)\n    4\n\n    >>> align_up(3, 1)\n    3\n    \"\"\"\n    remain = offset % align\n    if remain == 0:\n        return offset\n    else:\n        return offset + (align - remain)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bin_to_mac(bin, size=6):\n    if len(bin) != size:\n        raise Exception(\"Invalid MAC address: %s\" % (bin))\n    return ':'.join([binascii.hexlify(o) for o in bin])", "response": "Convert 6 bytes into a MAC string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_commodities(self):\n        base, quote = self.market.split(\"_\")\n        if isinstance(self.price, Amount):\n            self.price = Amount(\"{0:.8f} {1}\".format(self.price.to_double(), quote))\n        else:\n            self.price = Amount(\"{0:.8f} {1}\".format(self.price, quote))\n        if isinstance(self.amount, Amount):\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount.to_double(), base))\n        else:\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount, base))\n        if isinstance(self.exec_amount, Amount):\n            self.exec_amount = Amount(\"{0:.8f} {1}\".format(self.exec_amount.to_double(), base))\n        else:\n            self.exec_amount = Amount(\"{0:.8f} {1}\".format(self.exec_amount, base))", "response": "Load the commodities for Amounts in this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_commodities(self):\n        base, quote = self.market.split(\"_\")\n        if isinstance(self.bid, Amount):\n            self.bid = Amount(\"{0:.8f} {1}\".format(self.bid.to_double(), quote))\n        else:\n            self.bid = Amount(\"{0:.8f} {1}\".format(self.bid, quote))\n        if isinstance(self.ask, Amount):\n            self.ask = Amount(\"{0:.8f} {1}\".format(self.ask.to_double(), quote))\n        else:\n            self.ask = Amount(\"{0:.8f} {1}\".format(self.ask, quote))\n        if isinstance(self.high, Amount):\n            self.high = Amount(\"{0:.8f} {1}\".format(self.high.to_double(), quote))\n        else:\n            self.high = Amount(\"{0:.8f} {1}\".format(self.high, quote))\n        if isinstance(self.low, Amount):\n            self.low = Amount(\"{0:.8f} {1}\".format(self.low.to_double(), quote))\n        else:\n            self.low = Amount(\"{0:.8f} {1}\".format(self.low, quote))\n        if isinstance(self.volume, Amount):\n            self.volume = Amount(\"{0:.8f} {1}\".format(self.volume.to_double(), base))\n        else:\n            self.volume = Amount(\"{0:.8f} {1}\".format(self.volume, base))\n        if isinstance(self.last, Amount):\n            self.last = Amount(\"{0:.8f} {1}\".format(self.last.to_double(), quote))\n        else:\n            self.last = Amount(\"{0:.8f} {1}\".format(self.last, quote))", "response": "Load the commodities for Amounts in this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_commodities(self):\n        base, quote = self.market.split(\"_\")\n        if isinstance(self.price, Amount):\n            self.price = Amount(\"{0:.8f} {1}\".format(self.price.to_double(), quote))\n        else:\n            self.price = Amount(\"{0:.8f} {1}\".format(float(self.price), quote))\n        if isinstance(self.amount, Amount):\n            self.amount = Amount(\"{0:.8f} {1}\".format(self.amount.to_double(), base))\n        else:\n            self.amount = Amount(\"{0:.8f} {1}\".format(float(self.amount), base))\n        fee_currency = base if self.fee_side == 'base' else quote\n        if isinstance(self.fee, Amount):\n            self.fee = Amount(\"{0:.8f} {1}\".format(float(self.fee.to_double()), fee_currency))\n        else:\n            self.fee = Amount(\"{0:.8f} {1}\".format(float(self.fee), fee_currency))", "response": "Load the commodities for Amounts in this object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tell(self, message):\n        if self.hearing:\n            self.zone.send_message(self.id, json.dumps(message))", "response": "Send text to this entity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the system Application data directory.", "response": "def get_system_application_data_directory():\n    \"\"\"\n    Returns the system Application data directory.\n\n    Examples directories::\n\n        - 'C:\\\\Users\\\\$USER\\\\AppData\\\\Roaming' on Windows 7.\n        - 'C:\\\\Documents and Settings\\\\$USER\\\\Application Data' on Windows XP.\n        - '/Users/$USER/Library/Preferences' on Mac Os X.\n        - '/home/$USER' on Linux.\n\n    :return: User Application data directory.\n    :rtype: unicode\n    \"\"\"\n\n    if platform.system() == \"Windows\" or platform.system() == \"Microsoft\":\n        environment = Environment(\"APPDATA\")\n        return environment.get_value()\n    elif platform.system() == \"Darwin\":\n        environment = Environment(\"HOME\")\n        return os.path.join(environment.get_value(), \"Library\", \"Preferences\")\n    elif platform.system() == \"Linux\":\n        environment = Environment(\"HOME\")\n        return environment.get_value()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user_application_data_directory():\n\n    system_application_data_directory = get_system_application_data_directory()\n    if not foundations.common.path_exists(system_application_data_directory):\n        LOGGER.error(\n            \"!> Undefined or non existing system Application data directory, using 'HOME' directory as fallback!\")\n        system_application_data_directory = Environment(\"HOME\").get_value()\n\n    if not foundations.common.path_exists(system_application_data_directory):\n        temporary_directory = get_temporary_directory()\n        LOGGER.error(\"!> Undefined or non existing 'HOME' directory, using system temporary directory as fallback!\")\n        system_application_data_directory = temporary_directory\n\n    return os.path.join(system_application_data_directory, Constants.provider_directory,\n                        Constants.application_directory)", "response": "Returns the user Application data directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef variables(self, value):\n\n        if value is not None:\n            assert type(value) is dict, \"'{0}' attribute: '{1}' type is not 'dict'!\".format(\"variables\", value)\n            for key, element in value.iteritems():\n                assert type(key) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"variables\", key)\n                assert type(element) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"variables\", element)\n        self.__variables = value", "response": "Sets the variables of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds given variables to the internal dict.", "response": "def __add_variables(self, *args, **kwargs):\n        \"\"\"\n        Adds given variables to __variables attribute.\n\n        :param \\*args: Variables.\n        :type \\*args: \\*\n        :param \\*\\*kwargs: Variables : Values.\n        :type \\*\\*kwargs: \\*\n        \"\"\"\n\n        for variable in args:\n            self.__variables[variable] = None\n        self.__variables.update(kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_values(self, *args):\n\n        args and self.__add_variables(*args)\n\n        LOGGER.debug(\"> Object environment variables: '{0}'.\".format(\n            \",\".join((key for key in self.__variables if key))))\n        LOGGER.debug(\"> Available system environment variables: '{0}'\".format(os.environ.keys()))\n\n        for variable in self.__variables:\n            value = os.environ.get(variable, None)\n            self.__variables[variable] = foundations.strings.to_string(value) if value else None\n        return self.__variables", "response": "Gets environment variables values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_values(self, **kwargs):\n\n        self.__variables.update(kwargs)\n\n        for key, value in self.__variables.iteritems():\n            if value is None:\n                continue\n            LOGGER.debug(\"> Setting environment variable '{0}' with value '{1}'.\".format(key, value))\n            os.environ[key] = value\n        return True", "response": "Sets environment variables values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_value(self, variable=None):\n\n        if variable:\n            self.get_values(variable)\n            return self.__variables[variable]\n        else:\n            self.get_values()\n            return foundations.common.get_first_item(self.__variables.values())", "response": "Gets given environment variable value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, timeout=1.0):\n        self.ser.timeout = timeout\n        if self.ser is None:\n            return ''\n        return self.ser.readline()", "response": "read from modem port return null on timeout."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite string to modem returns number of bytes written", "response": "def write(self, cmd='AT'):\n        \"\"\"write string to modem, returns number of bytes written.\"\"\"\n        self.cmd_response = ''\n        self.cmd_responselines = []\n        if self.ser is None:\n            return 0\n        cmd += '\\r\\n'\n        return self.ser.write(cmd.encode())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend command wait for response. returns response from modem.", "response": "def sendcmd(self, cmd='AT', timeout=1.0):\n        \"\"\"send command, wait for response. returns response from modem.\"\"\"\n        import time\n        if self.write(cmd):\n            while self.get_response() == '' and timeout > 0:\n                time.sleep(0.1)\n                timeout -= 0.1\n        return self.get_lines()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _modem_sm(self):\n        import datetime\n\n        read_timeout = READ_IDLE_TIMEOUT\n        while self.ser:\n            try:\n                resp = self.read(read_timeout)\n            except (serial.SerialException, SystemExit, TypeError):\n                _LOGGER.debug('Unable to read from port %s', self.port)\n                break\n\n            if self.state != self.STATE_IDLE and len(resp) == 0:\n                read_timeout = READ_IDLE_TIMEOUT\n                self.set_state(self.STATE_IDLE)\n                self.incomingcallnotificationfunc(self.state)\n                continue\n\n            resp = resp.decode()\n            resp = resp.strip('\\r\\n')\n            if self.cmd_response == '':\n                self.cmd_responselines.append(resp)\n            _LOGGER.debug('mdm: %s', resp)\n\n            if resp in ['OK', 'ERROR']:\n                self.cmd_response = resp\n                continue\n\n            if resp in ['RING']:\n                if self.state == self.STATE_IDLE:\n                    self.cid_name = ''\n                    self.cid_number = ''\n                    self.cid_time = datetime.datetime.now()\n\n                self.set_state(self.STATE_RING)\n                self.incomingcallnotificationfunc(self.state)\n                read_timeout = READ_RING_TIMOUT\n                continue\n\n            if len(resp) <= 4 or resp.find('=') == -1:\n                continue\n\n            read_timeout = READ_RING_TIMOUT\n            cid_field, cid_data = resp.split('=')\n            cid_field = cid_field.strip()\n            cid_data = cid_data.strip()\n            if cid_field in ['DATE']:\n                self.cid_time = datetime.datetime.now()\n                continue\n\n            if cid_field in ['NMBR']:\n                self.cid_number = cid_data\n                continue\n\n            if cid_field in ['NAME']:\n                self.cid_name = cid_data\n                self.set_state(self.STATE_CALLERID)\n                self.incomingcallnotificationfunc(self.state)\n                _LOGGER.debug('CID: %s %s %s',\n                              self.cid_time.strftime(\"%I:%M %p\"),\n                              self.cid_name,\n                              self.cid_number)\n                try:\n                    self.write(self.cmd_callerid)\n                except serial.SerialException:\n                    _LOGGER.error('Unable to write to port %s', self.port)\n                    break\n\n            continue\n\n        self.set_state(self.STATE_FAILED)\n        _LOGGER.debug('Exiting modem state machine')\n        return", "response": "Handle modem response state machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_event(self, direction, verb, child_fn, priority=10):\n        event_managers = []\n        if direction in ('in', 'both'):\n            event_managers.append(self._events_in)\n        if direction in ('out', 'both'):\n            event_managers.append(self._events_out)\n        if direction == 'girc':\n            event_managers.append(self._girc_events)\n\n        for event_manager in event_managers:\n            event_manager.register(verb, child_fn, priority=priority)", "response": "Registers an event with all servers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_user_info(self, nick, user='*', real='*'):\n        if self.connected:\n            raise Exception(\"Can't set user info now, we're already connected!\")\n\n        # server will pickup list when they exist\n        if not self.connected:\n            self.nick = nick\n\n        self.connect_info['user'] = {\n            'nick': nick,\n            'user': user,\n            'real': real,\n        }", "response": "Sets the user info for this server to be used before connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef istring(self, in_string=''):\n        new_string = IString(in_string)\n        new_string.set_std(self.features.get('casemapping'))\n        if not self._casemap_set:\n            self._imaps.append(new_string)\n        return new_string", "response": "Return a string that uses this server s IRC casemapping."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list that uses this server s IRC casemapping.", "response": "def ilist(self, in_list=[]):\n        \"\"\"Return a list that uses this server's IRC casemapping.\n\n        All strings in this list are lowercased using the server's casemapping before inserting\n        them into the list, and the ``in`` operator takes casemapping into account.\n        \"\"\"\n        new_list = IList(in_list)\n        new_list.set_std(self.features.get('casemapping'))\n        if not self._casemap_set:\n            self._imaps.append(new_list)\n        return new_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef idict(self, in_dict={}):\n        new_dict = IDict(in_dict)\n        new_dict.set_std(self.features.get('casemapping'))\n        if not self._casemap_set:\n            self._imaps.append(new_dict)\n        return new_dict", "response": "Return a dictionary that uses this server s IRC casemapping."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to the given server.", "response": "def connect(self, *args, auto_reconnect=False, **kwargs):\n        \"\"\"Connects to the given server.\n\n        Args:\n            auto_reconnect (bool): Automatically reconnect on disconnection.\n\n        Other arguments to this function are as usually supplied to\n        :meth:`asyncio.BaseEventLoop.create_connection`.\n        \"\"\"\n        connection_info = {\n            'auto_reconnect': auto_reconnect,\n            'args': args,\n            'kwargs': kwargs,\n        }\n        self.connect_info['connection'] = connection_info\n\n        # confirm we have user info set\n        if 'user' not in self.connect_info:\n            raise Exception('`set_user_info` must be called before connecting to server.')\n\n        # create connection and run\n        connection = loop.create_connection(lambda: self,\n                                            *args, **kwargs)\n        asyncio.Task(connection)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquit from the server.", "response": "def quit(self, message=None):\n        \"\"\"Quit from the server.\"\"\"\n        if message is None:\n            message = 'Quit'\n\n        if self.connected:\n            self.send('QUIT', params=[message])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, verb, params=None, source=None, tags=None):\n        m = RFC1459Message.from_data(verb, params=params, source=source, tags=tags)\n        self._send_message(m)", "response": "Send a generic IRC message to the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends an action to the given target.", "response": "def action(self, target, message, formatted=True, tags=None):\n        \"\"\"Send an action to the given target.\"\"\"\n        if formatted:\n            message = unescape(message)\n\n        self.ctcp(target, 'ACTION', message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a privmsg to the given target.", "response": "def msg(self, target, message, formatted=True, tags=None):\n        \"\"\"Send a privmsg to the given target.\"\"\"\n        if formatted:\n            message = unescape(message)\n\n        self.send('PRIVMSG', params=[target, message], source=self.nick, tags=tags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ctcp(self, target, ctcp_verb, argument=None):\n        # we don't support complex ctcp encapsulation because we're somewhat sane\n        atoms = [ctcp_verb]\n        if argument is not None:\n            atoms.append(argument)\n        X_DELIM = '\\x01'\n        self.msg(target, X_DELIM + ' '.join(atoms) + X_DELIM, formatted=False)", "response": "Send a CTCP request to the given target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ctcp_reply(self, target, ctcp_verb, argument=None):\n        # we don't support complex ctcp encapsulation because we're somewhat sane\n        atoms = [ctcp_verb]\n        if argument is not None:\n            atoms.append(argument)\n        X_DELIM = '\\x01'\n        self.notice(target, X_DELIM + ' '.join(atoms) + X_DELIM, formatted=False)", "response": "Send a CTCP reply to the given target."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\njoin the given channel.", "response": "def join_channel(self, channel, key=None, tags=None):\n        \"\"\"Join the given channel.\"\"\"\n        params = [channel]\n        if key:\n            params.append(key)\n        self.send('JOIN', params=params, tags=tags)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef part_channel(self, channel, reason=None, tags=None):\n        params = [channel]\n        if reason:\n            params.append(reason)\n        self.send('PART', params=params, tags=tags)", "response": "Part the given channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend new modes to or requests existing modes from the given target.", "response": "def mode(self, target, mode_string=None, tags=None):\n        \"\"\"Sends new modes to or requests existing modes from the given target.\"\"\"\n        params = [target]\n        if mode_string:\n            params += mode_string\n        self.send('MODE', params=params, source=self.nick, tags=tags)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef topic(self, channel, new_topic=None, tags=None):\n        params = [channel]\n        if new_topic:\n            params += new_topic\n        self.send('TOPIC', params=params, source=self.nick, tags=tags)", "response": "Requests or sets the topic for the given channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nickserv_identify(self, password, use_nick=None):\n        if self.ready:\n            if use_nick:\n                self.msg(use_nick, 'IDENTIFY {}'.format(password))\n            else:\n                self.send('NICKSERV', params=['IDENTIFY', password])\n        else:\n            self.connect_info['nickserv'] = {\n                'password': password,\n                'use_nick': use_nick,\n            }", "response": "Identify to NickServ ( legacy mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nauthenticating to a server using SASL plain or does so on connection.", "response": "def sasl_plain(self, name, password, identity=None):\n        \"\"\"Authenticate to a server using SASL plain, or does so on connection.\n\n        Args:\n            name (str): Name to auth with.\n            password (str): Password to auth with.\n            identity (str): Identity to auth with (defaults to name).\n        \"\"\"\n        if identity is None:\n            identity = name\n\n        self.sasl('plain', name, password, identity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_executable(executable, path=None):\n  if path is None:\n    path = os.environ['PATH']\n  paths = path.split(os.pathsep)\n  base, ext = os.path.splitext(executable)\n\n  if (sys.platform == 'win32' or os.name == 'os2') and (ext != '.exe'):\n    executable = executable + '.exe'\n\n  if not os.path.isfile(executable):\n    for p in paths:\n      f = os.path.join(p, executable)\n      if os.path.isfile(f):\n        # the file exists, we have a shot at spawn working\n        return f\n    return None\n  else:\n    return executable", "response": "Tries to find the executable in the specified path. Returns the complete filename or None if not found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_message(message):\n        try:\n            return bson.dumps(message.serialize())\n        except bson.UnknownSerializerError:\n            raise SerializationError(\n                \"Unable to serialize message: {}.\".format(message)\n            )", "response": "Serializes an object. It must subclass :class:`FranzEvent`.\n\n        Parameters\n        ----------\n        message : FranzEvent\n            The object to be serialized.\n\n        Returns\n        -------\n        bytes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef measure_states(states, measurement_matrix, measurement_covariance):\n    # Sanitise input\n    measurement_matrix = np.atleast_2d(measurement_matrix)\n    measurement_covariance = np.atleast_2d(measurement_covariance)\n    measurement_dim = measurement_matrix.shape[0]\n    if measurement_covariance.shape != (measurement_dim, measurement_dim):\n        raise ValueError((\"Measurement matrix and covariance have inconsistent \"\n                          \"shapes {} and {}\").format(measurement_matrix.shape,\n                                                     measurement_covariance.shape))\n    states = np.atleast_2d(states)\n\n    # Special case: no output\n    if states.shape[0] == 0:\n        return np.zeros((0, measurement_dim))\n\n    # Measure states\n    measurement_means = measurement_matrix.dot(states.T).T\n    measurement_noises = np.random.multivariate_normal(\n        mean=np.zeros(measurement_dim), cov=measurement_covariance,\n        size=states.shape[0]\n    )\n\n    return measurement_means + measurement_noises", "response": "Measure a list of states with a measurement matrix in the presence of MEAS_DIMxMEAS_DIM in shape."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate states by simulating a linear system with constant process matrix and process noise covariance.", "response": "def generate_states(state_count, process_matrix, process_covariance,\n                    initial_state=None):\n    \"\"\"\n    Generate states by simulating a linear system with constant process matrix\n    and process noise covariance.\n\n    Args:\n        state_count (int): Number of states to generate.\n        process_matrix (array): Square array\n        process_covariance (array): Square array specifying process noise\n            covariance.\n        initial_state (array or None): If omitted, use zero-filled vector as\n            initial state.\n\n    \"\"\"\n    # Sanitise input\n    process_matrix = np.atleast_2d(process_matrix)\n    process_covariance = np.atleast_2d(process_covariance)\n    state_dim = process_matrix.shape[0]\n\n    if process_matrix.shape != (state_dim, state_dim):\n        raise ValueError(\"Process matrix has inconsistent shape: {}\".format(\n            process_matrix.shape))\n\n    if process_covariance.shape != (state_dim, state_dim):\n        raise ValueError(\"Process covariance has inconsistent shape: {}\".format(\n            process_covariance.shape))\n\n    if initial_state is None:\n        initial_state = np.zeros(process_matrix.shape[0])\n\n    states = [initial_state]\n    while len(states) < state_count:\n        states.append(\n            process_matrix.dot(states[-1]) + np.random.multivariate_normal(\n                mean=np.zeros(state_dim), cov=process_covariance\n            )\n        )\n\n    return np.vstack(states)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sing(self, number):\n\n        if type(number) != Decimal:\n            number = Decimal(str(number))\n\n        if number > self.limite:\n            msg = \"El maximo numero procesable es {} ({})\".format(self.limite,\n                                                                  self.sing(self.limite))\n            raise ValueError(msg)\n        else:\n            texto = self.__to_text(int(number))\n        texto += self.__calcular_decimales(number)\n\n        return texto", "response": "Interfaz publica para convertir numero a texto"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pick(self, selector, entity_set, min_quantity=None):\n        if isinstance(selector, int):\n            for e in entity_set:\n                if e.id == selector:\n                    return set((e,))\n        else:\n            if selector.lower() in ('self', 'me', 'myself'):\n                return set((self.entity,))\n\n            return set(\n                e for e in entity_set\n                if (e.is_('Named') and selector.lower() in e.Named.name.lower())\n                and not e.is_(Invisible)\n                and (not min_quantity or min_quantity == 1 or (e.is_(Stackable) and e.Stackable.quantity >= min_quantity))\n            )", "response": "Pick entities from a set by selector."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends text to entities nearby this one.", "response": "def emit(self, sound, exclude=set()):\n        \"\"\"Send text to entities nearby this one.\"\"\"\n        nearby = self.nearby()\n        try:\n            exclude = set(exclude)\n        except TypeError:\n            exclude = set([exclude])\n        exclude.add(self.entity)\n        listeners = nearby - exclude\n        for listener in listeners:\n            listener.tell(sound)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_nice_name(name):\n\n    chunks = re.sub(r\"(.)([A-Z][a-z]+)\", r\"\\1 \\2\", name)\n    return \" \".join(element.title() for element in re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1 \\2\", chunks).split())", "response": "Converts a string to nice string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_version_rank(version):\n\n    tokens = list(foundations.common.unpack_default(filter(any, re.split(\"\\.|-|,\", version)), length=4, default=0))\n    rank = sum((int(1000 ** i) * int(tokens[-i]) for i in range(len(tokens), 0, -1)))\n    LOGGER.debug(\"> Rank: '{0}'.\".format(rank))\n    return rank", "response": "Returns a rank of a version string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_splitext_basename(path):\n\n    basename = foundations.common.get_first_item(os.path.splitext(os.path.basename(os.path.normpath(path))))\n    LOGGER.debug(\"> Splitext basename: '{0}'.\".format(basename))\n    return basename", "response": "Extracts the basename of a path without its extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets common ancestor of given iterables.", "response": "def get_common_ancestor(*args):\n    \"\"\"\n    Gets common ancestor of given iterables.\n\n    Usage::\n\n        >>> get_common_ancestor((\"1\", \"2\", \"3\"), (\"1\", \"2\", \"0\"), (\"1\", \"2\", \"3\", \"4\"))\n        (u'1', u'2')\n        >>> get_common_ancestor(\"azerty\", \"azetty\", \"azello\")\n        u'aze'\n\n    :param \\*args: Iterables to retrieve common ancestor from.\n    :type \\*args: [iterable]\n    :return: Common ancestor.\n    :rtype: iterable\n    \"\"\"\n\n    array = map(set, zip(*args))\n    divergence = filter(lambda i: len(i) > 1, array)\n    if divergence:\n        ancestor = foundations.common.get_first_item(args)[:array.index(foundations.common.get_first_item(divergence))]\n    else:\n        ancestor = min(args)\n    LOGGER.debug(\"> Common Ancestor: '{0}'\".format(ancestor))\n    return ancestor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting common paths ancestor of given paths.", "response": "def get_common_paths_ancestor(*args):\n    \"\"\"\n    Gets common paths ancestor of given paths.\n\n    Usage::\n\n        >>> get_common_paths_ancestor(\"/Users/JohnDoe/Documents\", \"/Users/JohnDoe/Documents/Test.txt\")\n        u'/Users/JohnDoe/Documents'\n\n    :param \\*args: Paths to retrieve common ancestor from.\n    :type \\*args: [unicode]\n    :return: Common path ancestor.\n    :rtype: unicode\n    \"\"\"\n\n    path_ancestor = os.sep.join(get_common_ancestor(*[path.split(os.sep) for path in args]))\n    LOGGER.debug(\"> Common Paths Ancestor: '{0}'\".format(path_ancestor))\n    return path_ancestor"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the words from given string.", "response": "def get_words(data):\n    \"\"\"\n    Extracts the words from given string.\n\n    Usage::\n\n        >>> get_words(\"Users are: John Doe, Jane Doe, Z6PO.\")\n        [u'Users', u'are', u'John', u'Doe', u'Jane', u'Doe', u'Z6PO']\n\n    :param data: Data to extract words from.\n    :type data: unicode\n    :return: Words.\n    :rtype: list\n    \"\"\"\n\n    words = re.findall(r\"\\w+\", data)\n    LOGGER.debug(\"> Words: '{0}'\".format(\", \".join(words)))\n    return words"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering the words using the given filters.", "response": "def filter_words(words, filters_in=None, filters_out=None, flags=0):\n    \"\"\"\n    Filters the words using the given filters.\n\n    Usage::\n\n        >>> filter_words([\"Users\", \"are\", \"John\", \"Doe\", \"Jane\", \"Doe\", \"Z6PO\"], filters_in=(\"John\", \"Doe\"))\n        [u'John', u'Doe', u'Doe']\n        >>> filter_words([\"Users\", \"are\", \"John\", \"Doe\", \"Jane\", \"Doe\", \"Z6PO\"], filters_in=(\"\\w*r\",))\n        [u'Users', u'are']\n        >>> filter_words([\"Users\", \"are\", \"John\", \"Doe\", \"Jane\", \"Doe\", \"Z6PO\"], filters_out=(\"\\w*o\",))\n        [u'Users', u'are', u'Jane', u'Z6PO']\n\n    :param filters_in: Regex filters in list.\n    :type filters_in: tuple or list\n    :param filters_in: Regex filters out list.\n    :type filters_in: tuple or list\n    :param flags: Regex flags.\n    :type flags: int\n    :return: Filtered words.\n    :rtype: list\n    \"\"\"\n\n    filtered_words = []\n    for word in words:\n        if filters_in:\n            filter_matched = False\n            for filter in filters_in:\n                if not re.search(filter, word, flags):\n                    LOGGER.debug(\"> '{0}' word skipped, filter in '{1}' not matched!\".format(word, filter))\n                else:\n                    filter_matched = True\n                    break\n            if not filter_matched:\n                continue\n\n        if filters_out:\n            filter_matched = False\n            for filter in filters_out:\n                if re.search(filter, word, flags):\n                    LOGGER.debug(\"> '{0}' word skipped, filter out '{1}' matched!\".format(word, filter))\n                    filter_matched = True\n                    break\n            if filter_matched:\n                continue\n        filtered_words.append(word)\n    LOGGER.debug(\"> Filtered words: '{0}'\".format(\", \".join(filtered_words)))\n    return filtered_words"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the occurrences of data occurrences in the string.", "response": "def replace(string, data):\n    \"\"\"\n    Replaces the data occurrences in the string.\n\n    Usage::\n\n        >>> replace(\"Users are: John Doe, Jane Doe, Z6PO.\", {\"John\" : \"Luke\", \"Jane\" : \"Anakin\", \"Doe\" : \"Skywalker\",\n         \"Z6PO\" : \"R2D2\"})\n        u'Users are: Luke Skywalker, Anakin Skywalker, R2D2.'\n\n    :param string: String to manipulate.\n    :type string: unicode\n    :param data: Replacement occurrences.\n    :type data: dict\n    :return: Manipulated string.\n    :rtype: unicode\n    \"\"\"\n\n    for old, new in data.iteritems():\n        string = string.replace(old, new)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert backward slashes to forward slashes.", "response": "def to_forward_slashes(data):\n    \"\"\"\n    Converts backward slashes to forward slashes.\n\n    Usage::\n\n        >>> to_forward_slashes(\"To\\Forward\\Slashes\")\n        u'To/Forward/Slashes'\n\n    :param data: Data to convert.\n    :type data: unicode\n    :return: Converted path.\n    :rtype: unicode\n    \"\"\"\n\n    data = data.replace(\"\\\\\", \"/\")\n    LOGGER.debug(\"> Data: '{0}' to forward slashes.\".format(data))\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_backward_slashes(data):\n\n    data = data.replace(\"/\", \"\\\\\")\n    LOGGER.debug(\"> Data: '{0}' to backward slashes.\".format(data))\n    return data", "response": "Converts forward slashes to backward slashes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting Windows path to Posix path while stripping drives letters and network server slashes.", "response": "def to_posix_path(path):\n    \"\"\"\n    Converts Windows path to Posix path while stripping drives letters and network server slashes.\n\n    Usage::\n\n        >>> to_posix_path(\"c:\\\\Users\\\\JohnDoe\\\\Documents\")\n        u'/Users/JohnDoe/Documents'\n\n    :param path: Windows path.\n    :type path: unicode\n    :return: Path converted to Posix path.\n    :rtype: unicode\n    \"\"\"\n\n    posix_path = posixpath.normpath(to_forward_slashes(re.sub(r\"[a-zA-Z]:\\\\|\\\\\\\\\", \"/\", os.path.normpath(path))))\n    LOGGER.debug(\"> Stripped converted to Posix path: '{0}'.\".format(posix_path))\n    return posix_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes a path to be used in a tree tree.", "response": "def get_normalized_path(path):\n    \"\"\"\n    Normalizes a path, escaping slashes if needed on Windows.\n\n    Usage::\n\n        >>> get_normalized_path(\"C:\\\\Users/johnDoe\\\\Documents\")\n        u'C:\\\\Users\\\\JohnDoe\\\\Documents'\n\n    :param path: Path to normalize.\n    :type path: unicode\n    :return: Normalized path.\n    :rtype: unicode\n    \"\"\"\n\n    if platform.system() == \"Windows\" or platform.system() == \"Microsoft\":\n        path = os.path.normpath(path).replace(\"\\\\\", \"\\\\\\\\\")\n        LOGGER.debug(\"> Path: '{0}', normalized path.\".format(path))\n        return path\n    else:\n        path = os.path.normpath(path)\n        LOGGER.debug(\"> Path: '{0}', normalized path.\".format(path))\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if given data string is an email.", "response": "def is_email(data):\n    \"\"\"\n    Check if given data string is an email.\n\n    Usage::\n\n        >>> is_email(\"john.doe@domain.com\")\n        True\n        >>> is_email(\"john.doe:domain.com\")\n        False\n\n    :param data: Data to check.\n    :type data: unicode\n    :return: Is email.\n    :rtype: bool\n    \"\"\"\n\n    if re.match(r\"[\\w.%+-]+@[\\w.]+\\.[a-zA-Z]{2,4}\", data):\n        LOGGER.debug(\"> {0}' is matched as email.\".format(data))\n        return True\n    else:\n        LOGGER.debug(\"> {0}' is not matched as email.\".format(data))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_website(url):\n\n    if re.match(r\"(http|ftp|https)://([\\w\\-\\.]+)/?\", url):\n        LOGGER.debug(\"> {0}' is matched as website.\".format(url))\n        return True\n    else:\n        LOGGER.debug(\"> {0}' is not matched as website.\".format(url))\n        return False", "response": "Check if given url string is a website."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsample an observation s value.", "response": "def observe(self, value):\n        \"\"\"Samples an observation's value.\n\n        Args:\n            value: A numeric value signifying the value to be sampled.\n        \"\"\"\n        self._buffer.append(value)\n        if len(self._buffer) == _BUFFER_SIZE:\n            self._flush()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the value estimate for the requested quantile rank.", "response": "def query(self, rank):\n        \"\"\"Retrieves the value estimate for the requested quantile rank.\n\n        The requested quantile rank must be registered in the estimator's\n        invariants a priori!\n\n        Args:\n            rank: A floating point quantile rank along the interval [0, 1].\n\n        Returns:\n            A numeric value for the quantile estimate.\n        \"\"\"\n        self._flush()\n\n        current = self._head\n        if not current:\n          return 0\n\n        mid_rank = math.floor(rank * self._observations)\n        max_rank = mid_rank + math.floor(\n            self._invariant(mid_rank, self._observations) / 2)\n\n        rank = 0.0\n        while current._successor:\n            rank += current._rank\n            if rank + current._successor._rank + current._successor._delta > max_rank:\n                return current._value\n\n            current = current._successor\n\n        return current._value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npurging the buffer and commits all pending values into the estimator.", "response": "def _flush(self):\n        \"\"\"Purges the buffer and commits all pending values into the estimator.\"\"\"\n        self._buffer.sort()\n        self._replace_batch()\n        self._buffer = []\n        self._compress()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _replace_batch(self):\n        if not self._head:\n          self._head, self._buffer = self._record(self._buffer[0], 1, 0, None), self._buffer[1:]\n\n        rank = 0.0\n        current = self._head\n\n        for b in self._buffer:\n            if b < self._head._value:\n              self._head = self._record(b, 1, 0, self._head)\n\n            while current._successor and current._value < b:\n                rank += current._rank\n                current = current._successor\n\n            if not current._successor:\n                current._successor = self._record(b, 1, 0, None)\n\n            current._successor = self._record(b, 1, self._invariant(rank, self._observations)-1, current._successor)", "response": "Incorporates all pending values into the estimator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the delta value for the sample.", "response": "def _invariant(self, rank, n):\n        \"\"\"Computes the delta value for the sample.\"\"\"\n        minimum = n + 1\n\n        for i in self._invariants:\n            delta = i._delta(rank, n)\n            if delta < minimum:\n                minimum = delta\n\n        return math.floor(minimum)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _compress(self):\n        rank = 0.0\n        current = self._head\n\n        while current and current._successor:\n            if current._rank + current._successor._rank + current._successor._delta <= self._invariant(rank, self._observations):\n                removed = current._successor\n\n                current._value = removed._value\n                current._rank += removed._rank\n                current._delta = removed._delta\n                current._successor = removed._successor\n\n            rank += current._rank\n            current = current._successor", "response": "Prunes the cataloged observations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_corpus(src, out_dir, no_below=20, keep_words=_DEFAULT_KEEP_WORDS):\n    wordid_filename = os.path.join(out_dir, 'cables_wordids.pickle')\n    bow_filename = os.path.join(out_dir, 'cables_bow.mm')\n    tfidf_filename = os.path.join(out_dir, 'cables_tfidf.mm')\n    predicate = None # Could be set to something like pred.origin_filter(pred.origin_germany)\n    # 1. Create word dict\n    dct = Dictionary()\n    dct_handler = DictionaryHandler(dct)\n    handler = create_filter(dct_handler)\n    handle_source(src, handler, predicate)\n    dct.filter_extremes(no_below=no_below, no_above=0.1, keep_n=keep_words)\n    dct.save(wordid_filename)\n    # 2. Reiterate through the cables and create the vector space\n    corpus_handler = CorpusHandler(out_dir, dct=dct, allow_dict_updates=False)\n    handler = create_filter(corpus_handler)\n    handle_source(src, handler, predicate)\n    # 3. Load corpus\n    mm = MmCorpus(bow_filename)\n    # 4. Create TF-IDF model\n    tfidf = TfidfModel(mm, id2word=dct, normalize=True)\n    # 5. Save the TF-IDF model\n    MmCorpus.serialize(tfidf_filename, tfidf[mm], progress_cnt=10000)", "response": "Create a corpus from a list of cables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Variance componenrs for the current set of local files", "response": "def getVC(self):\n        \"\"\"\n        Variance componenrs\n        \"\"\"\n        _Cr = decompose_GxE(self.full['Cr'])\n        RV = {}\n        for key in list(_Cr.keys()):\n            RV['var_%s' % key] = sp.array([var_CoXX(_Cr[key], self.Xr)])\n        RV['var_c'] = self.full['var_c'] \n        RV['var_n'] = self.full['var_n'] \n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_attribute_compound(attribute, value=None, splitter=\"|\", binding_identifier=\"@\"):\n\n    LOGGER.debug(\"> Attribute: '{0}', value: '{1}'.\".format(attribute, value))\n\n    if type(value) is unicode:\n        if splitter in value:\n            value_tokens = value.split(splitter)\n            if len(value_tokens) >= 3 and re.search(r\"{0}\\w*\".format(binding_identifier), value_tokens[0]):\n                return AttributeCompound(name=attribute,\n                                         value=value_tokens[1].strip(),\n                                         link=value_tokens[0].strip(),\n                                         type=value_tokens[2].strip(),\n                                         alias=len(value_tokens) == 4 and value_tokens[3].strip() or None)\n        else:\n            if re.search(r\"{0}\\w*\".format(binding_identifier), value):\n                return AttributeCompound(name=attribute, value=None, link=value, type=None, alias=None)\n\n    return AttributeCompound(name=attribute, value=value, link=None, type=None, alias=None)", "response": "Returns an attribute compound."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the splitter attribute.", "response": "def splitters(self, value):\n        \"\"\"\n        Setter for **self.__splitters** attribute.\n\n        :param value: Attribute value.\n        :type value: tuple or list\n        \"\"\"\n\n        if value is not None:\n            assert type(value) in (tuple, list), \"'{0}' attribute: '{1}' type is not 'tuple' or 'list'!\".format(\n                \"splitters\", value)\n            for element in value:\n                assert type(element) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"splitters\", element)\n                assert len(element) == 1, \"'{0}' attribute: '{1}' has multiples characters!\".format(\n                    \"splitter\", element)\n                assert not re.search(r\"\\w\", element), \"'{0}' attribute: '{1}' is an alphanumeric character!\".format(\n                    \"splitter\", element)\n        self.__splitters = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the namespace splitter attribute.", "response": "def namespace_splitter(self, value):\n        \"\"\"\n        Setter for **self.__namespace_splitter** attribute.\n\n        :param value: Attribute value.\n        :type value: unicode\n        \"\"\"\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"namespace_splitter\", value)\n            assert len(value) == 1, \"'{0}' attribute: '{1}' has multiples characters!\".format(\"namespace_splitter\",\n                                                                                              value)\n            assert not re.search(r\"\\w\", value), \"'{0}' attribute: '{1}' is an alphanumeric character!\".format(\n                \"namespace_splitter\", value)\n        self.__namespace_splitter = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef comment_limiters(self, value):\n\n        if value is not None:\n            assert type(value) in (tuple, list), \"'{0}' attribute: '{1}' type is not 'tuple' or 'list'!\".format(\n                \"comment_limiters\", value)\n            for element in value:\n                assert type(element) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"comment_limiters\", element)\n        self.__comment_limiters = value", "response": "Setter for **self. __comment_limiters** attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef comment_marker(self, value):\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"comment_marker\", value)\n            assert not re.search(r\"\\w\", value), \"'{0}' attribute: '{1}' is an alphanumeric character!\".format(\n                \"comment_marker\", value)\n        self.__comment_marker = value", "response": "Setter for **self. __comment_marker** attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value of the quotation_markers attribute.", "response": "def quotation_markers(self, value):\n        \"\"\"\n        Setter for **self.__quotation_markers** attribute.\n\n        :param value: Attribute value.\n        :type value: tuple or list\n        \"\"\"\n\n        if value is not None:\n            assert type(value) in (tuple, list), \"'{0}' attribute: '{1}' type is not 'tuple' or 'list'!\".format(\n                \"quotation_markers\", value)\n            for element in value:\n                assert type(element) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"quotation_markers\", element)\n                assert len(element) == 1, \"'{0}' attribute: '{1}' has multiples characters!\".format(\"quotation_markers\",\n                                                                                                    element)\n                assert not re.search(r\"\\w\", element), \"'{0}' attribute: '{1}' is an alphanumeric character!\".format(\n                    \"quotation_markers\", element)\n        self.__quotation_markers = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raw_section_content_identifier(self, value):\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"raw_section_content_identifier\", value)\n        self.__raw_section_content_identifier = value", "response": "Setter for self. __raw_section_content_identifier attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef defaults_section(self, value):\n\n        if value is not None:\n            assert type(value) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                \"defaults_section\", value)\n        self.__defaults_section = value", "response": "Setter for **self. __defaults_section ** attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sections(self, value):\n\n        if value is not None:\n            assert type(value) in (OrderedDict, dict), \"'{0}' attribute: '{1}' type is not \\\n            'OrderedDict' or 'dict'!\".format(\"sections\", value)\n            for key, element in value.iteritems():\n                assert type(key) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"sections\", key)\n                assert type(element) in (OrderedDict, dict), \"'{0}' attribute: '{1}' type is not \\\n                'OrderedDict' or 'dict'!\".format(\"sections\", key)\n        self.__sections = value", "response": "Setter for **self. __sections** attribute."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comments(self, value):\n\n        if value is not None:\n            assert type(value) in (OrderedDict, dict), \"'{0}' attribute: '{1}' type is not \\\n            'OrderedDict' or 'dict'!\".format(\"comments\", value)\n            for key, element in value.iteritems():\n                assert type(key) is unicode, \"'{0}' attribute: '{1}' type is not 'unicode'!\".format(\n                    \"comments\", key)\n                assert type(element) in (OrderedDict, dict), \"'{0}' attribute: '{1}' type is not \\\n                'OrderedDict' or 'dict'!\".format(\"comments\", key)\n        self.__comments = value", "response": "Setter for **self. __comments** attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the parsing errors attribute.", "response": "def parsing_errors(self, value):\n        \"\"\"\n        Setter for **self.__parsing_errors** attribute.\n\n        :param value: Attribute value.\n        :type value: list\n        \"\"\"\n\n        if value is not None:\n            assert type(value) is list, \"'{0}' attribute: '{1}' type is not 'list'!\".format(\"parsing_errors\", value)\n            for element in value:\n                assert issubclass(element.__class__, foundations.exceptions.AbstractParsingError), \\\n                    \"'{0}' attribute: '{1}' is not a '{2}' subclass!\".format(\n                        \"parsing_errors\", element, foundations.exceptions.AbstractParsingError.__class__.__name__)\n        self.__parsing_errors = value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef preserve_order(self, value):\n\n        if value is not None:\n            assert type(value) is bool, \"'{0}' attribute: '{1}' type is not 'bool'!\".format(\"preserve_order\", value)\n        self.__preserve_order = value", "response": "Setter method for **self. __preserve_order** attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the content of the file and returns the parsed content as nested dictionaries.", "response": "def parse(self,\n              raw_sections=None,\n              namespaces=True,\n              strip_comments=True,\n              strip_whitespaces=True,\n              strip_quotation_markers=True,\n              raise_parsing_errors=True):\n        \"\"\"\n        Process the file content and extracts the sections / attributes\n            as nested :class:`collections.OrderedDict` dictionaries or dictionaries.\n\n        Usage::\n\n            >>> content = [\"; Comment.\\\\n\", \"Attribute 1 = \\\\\"Value A\\\\\"\\\\n\", \"Attribute 2 = \\\\\"Value B\\\\\"\\\\n\"]\n            >>> sections_file_parser = SectionsFileParser()\n            >>> sections_file_parser.content = content\n            >>> sections_file_parser.parse(strip_comments=False)\n            <foundations.parsers.SectionsFileParser object at 0x860323123>\n            >>> sections_file_parser.sections.keys()\n            [u'_defaults']\n            >>> sections_file_parser.sections[\"_defaults\"].values()\n            [u'Value A', u'Value B']\n            >>> sections_file_parser.parse(strip_comments=False, strip_quotation_markers=False)\n            <foundations.parsers.SectionsFileParser object at 0x860323123>\n            >>> sections_file_parser.sections[\"_defaults\"].values()\n            [u'\"Value A\"', u'\"Value B\"']\n            >>> sections_file_parser.comments\n            OrderedDict([(u'_defaults|#0', {u'content': u'Comment.', u'id': 0})])\n            >>> sections_file_parser.parse()\n            <foundations.parsers.SectionsFileParser object at 0x860323123>\n            >>> sections_file_parser.sections[\"_defaults\"]\n            OrderedDict([(u'_defaults|Attribute 1', u'Value A'), (u'_defaults|Attribute 2', u'Value B')])\n            >>> sections_file_parser.parse(namespaces=False)\n            <foundations.parsers.SectionsFileParser object at 0x860323123>\n            >>> sections_file_parser.sections[\"_defaults\"]\n            OrderedDict([(u'Attribute 1', u'Value A'), (u'Attribute 2', u'Value B')])\n\n        :param raw_sections: Ignored raw sections.\n        :type raw_sections: tuple or list\n        :param namespaces: Attributes and comments are namespaced.\n        :type namespaces: bool\n        :param strip_comments: Comments are stripped.\n        :type strip_comments: bool\n        :param strip_whitespaces: Whitespaces are stripped.\n        :type strip_whitespaces: bool\n        :param strip_quotation_markers: Attributes values quotation markers are stripped.\n        :type strip_quotation_markers: bool\n        :param raise_parsing_errors: Raise parsing errors.\n        :type raise_parsing_errors: bool\n        :return: SectionFileParser instance.\n        :rtype: SectionFileParser\n        \"\"\"\n\n        LOGGER.debug(\"> Reading sections from: '{0}'.\".format(self.path))\n\n        if not self.content:\n            self.read()\n\n        attributes = {} if not self.__preserve_order else OrderedDict()\n        section = self.__defaults_section\n        raw_sections = raw_sections or []\n\n        commentId = 0\n        for i, line in enumerate(self.content):\n            # Comments matching.\n            search = re.search(r\"^\\s*[{0}](?P<comment>.+)$\".format(\"\".join(self.__comment_limiters)), line)\n            if search:\n                if not strip_comments:\n                    comment = namespaces and foundations.namespace.set_namespace(section, \"{0}{1}\".format(\n                        self.__comment_marker, commentId), self.__namespace_splitter) or \\\n                              \"{0}{1}\".format(self.__comment_marker, commentId)\n                    self.__comments[comment] = {\"id\": commentId, \"content\": strip_whitespaces and\n                                                                            search.group(\n                                                                                \"comment\").strip() or search.group(\n                        \"comment\")}\n                    commentId += 1\n                continue\n\n            # Sections matching.\n            search = re.search(r\"^\\s*\\[(?P<section>.+)\\]\\s*$\", line)\n            if search:\n                section = strip_whitespaces and search.group(\"section\").strip() or search.group(\"section\")\n                if not self.__preserve_order:\n                    attributes = {}\n                else:\n                    attributes = OrderedDict()\n                rawContent = []\n                continue\n\n            if section in raw_sections:\n                rawContent.append(line)\n                attributes[self.__raw_section_content_identifier] = rawContent\n            else:\n                # Empty line matching.\n                search = re.search(r\"^\\s*$\", line)\n                if search:\n                    continue\n\n                # Attributes matching.\n                search = re.search(r\"^(?P<attribute>.+?)[{0}](?P<value>.+)$\".format(\"\".join(self.__splitters)), line) \\\n                    or re.search(r\"^(?P<attribute>.+?)[{0}]\\s*$\".format(\"\".join(self.__splitters)), line)\n                if search:\n                    attribute = search.group(\"attribute\").strip() if strip_whitespaces else search.group(\"attribute\")\n                    attribute = foundations.namespace.set_namespace(section, attribute, self.__namespace_splitter) \\\n                        if namespaces else attribute\n\n                    if len(search.groups()) == 2:\n                        value = search.group(\"value\").strip() if strip_whitespaces else search.group(\"value\")\n                        attributes[attribute] = value.strip(\"\".join(self.__quotation_markers)) \\\n                            if strip_quotation_markers else value\n                    else:\n                        attributes[attribute] = None\n                else:\n                    self.__parsing_errors.append(foundations.exceptions.AttributeStructureParsingError(\n                        \"Attribute structure is invalid: {0}\".format(line), i + 1))\n\n            self.__sections[section] = attributes\n\n        LOGGER.debug(\"> Sections: '{0}'.\".format(self.__sections))\n        LOGGER.debug(\"> '{0}' file parsing done!\".format(self.path))\n\n        if self.__parsing_errors and raise_parsing_errors:\n            raise foundations.exceptions.FileStructureParsingError(\n                \"{0} | '{1}' structure is invalid, parsing exceptions occured!\".format(self.__class__.__name__,\n                                                                                       self.path))\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if given section exists in given file.", "response": "def section_exists(self, section):\n        \"\"\"\n        Checks if given section exists.\n\n        Usage::\n\n            >>> content = [\"[Section A]\\\\n\", \"; Comment.\\\\n\", \"Attribute 1 = \\\\\"Value A\\\\\"\\\\n\", \"\\\\n\", \\\n\"[Section B]\\\\n\", \"Attribute 2 = \\\\\"Value B\\\\\"\\\\n\"]\n            >>> sections_file_parser = SectionsFileParser()\n            >>> sections_file_parser.content = content\n            >>> sections_file_parser.parse()\n            <foundations.parsers.SectionsFileParser object at 0x845683844>\n            >>> sections_file_parser.section_exists(\"Section A\")\n            True\n            >>> sections_file_parser.section_exists(\"Section C\")\n            False\n\n        :param section: Section to check existence.\n        :type section: unicode\n        :return: Section existence.\n        :rtype: bool\n        \"\"\"\n\n        if section in self.__sections:\n            LOGGER.debug(\"> '{0}' section exists in '{1}'.\".format(section, self))\n            return True\n        else:\n            LOGGER.debug(\"> '{0}' section doesn't exists in '{1}'.\".format(section, self))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attribute_exists(self, attribute, section):\n\n        if foundations.namespace.remove_namespace(attribute, root_only=True) in self.get_attributes(section,\n                                                                                                    strip_namespaces=True):\n            LOGGER.debug(\"> '{0}' attribute exists in '{1}' section.\".format(attribute, section))\n            return True\n        else:\n            LOGGER.debug(\"> '{0}' attribute doesn't exists in '{1}' section.\".format(attribute, section))\n            return False", "response": "Checks if given attribute exists in given section."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_attributes(self, section, strip_namespaces=False):\n\n        LOGGER.debug(\"> Getting section '{0}' attributes.\".format(section))\n\n        attributes = OrderedDict() if self.__preserve_order else dict()\n        if not self.section_exists(section):\n            return attributes\n\n        if strip_namespaces:\n            for attribute, value in self.__sections[section].iteritems():\n                attributes[foundations.namespace.remove_namespace(attribute, root_only=True)] = value\n        else:\n            attributes.update(self.__sections[section])\n        LOGGER.debug(\"> Attributes: '{0}'.\".format(attributes))\n        return attributes", "response": "Returns given section attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_attributes(self):\n\n        all_attributes = OrderedDict() if self.__preserve_order else dict()\n\n        for attributes in self.__sections.itervalues():\n            for attribute, value in attributes.iteritems():\n                all_attributes[attribute] = value\n        return all_attributes", "response": "Returns all sections and files attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_value(self, attribute, section, default=\"\"):\n\n        if not self.attribute_exists(attribute, section):\n            return default\n\n        if attribute in self.__sections[section]:\n            value = self.__sections[section][attribute]\n        elif foundations.namespace.set_namespace(section, attribute) in self.__sections[section]:\n            value = self.__sections[section][foundations.namespace.set_namespace(section, attribute)]\n        LOGGER.debug(\"> Attribute: '{0}', value: '{1}'.\".format(attribute, value))\n        return value", "response": "Gets requested attribute value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset requested attribute value.", "response": "def set_value(self, attribute, section, value):\n        \"\"\"\n        Sets requested attribute value.\n\n        Usage::\n\n            >>> content = [\"[Section A]\\\\n\", \"; Comment.\\\\n\", \"Attribute 1 = \\\\\"Value A\\\\\"\\\\n\", \"\\\\n\", \\\n\"[Section B]\\\\n\", \"Attribute 2 = \\\\\"Value B\\\\\"\\\\n\"]\n            >>> sections_file_parser = SectionsFileParser()\n            >>> sections_file_parser.content = content\n            >>> sections_file_parser.parse()\n            <foundations.parsers.SectionsFileParser object at 0x109304209>\n            >>> sections_file_parser.set_value(\"Attribute 3\", \"Section C\", \"Value C\")\n            True\n\n        :param attribute: Attribute name.\n        :type attribute: unicode\n        :param section: Section containing the searched attribute.\n        :type section: unicode\n        :param value: Attribute value.\n        :type value: object\n        :return: Definition success.\n        :rtype: bool\n        \"\"\"\n\n        if not self.section_exists(section):\n            LOGGER.debug(\"> Adding '{0}' section.\".format(section))\n            self.__sections[section] = OrderedDict() if self.__preserve_order else dict()\n\n        self.__sections[section][attribute] = value\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites defined file using SectionsFileParser. sections and SectionsFileParser. comments class properties content.", "response": "def write(self,\n              namespaces=False,\n              splitter=\"=\",\n              comment_limiter=(\";\"),\n              spaces_around_splitter=True,\n              space_after_comment_limiter=True):\n        \"\"\"\n        Writes defined file using :obj:`SectionsFileParser.sections` and\n            :obj:`SectionsFileParser.comments` class properties content.\n\n        Usage::\n\n            >>> sections = {\"Section A\": {\"Section A|Attribute 1\": \"Value A\"}, \\\n\"Section B\": {\"Section B|Attribute 2\": \"Value B\"}}\n            >>> sections_file_parser = SectionsFileParser(\"SectionsFile.rc\")\n            >>> sections_file_parser.sections = sections\n            >>> sections_file_parser.write()\n            True\n            >>> sections_file_parser.read()\n            u'[Section A]\\\\nAttribute 1 = Value A\\\\n\\\\n[Section B]\\\\nAttribute 2 = Value B\\\\n'\n\n        :param namespaces: Attributes are namespaced.\n        :type namespaces: bool\n        :param splitter: Splitter character.\n        :type splitter: unicode\n        :param comment_limiter: Comment limiter character.\n        :type comment_limiter: unicode\n        :param spaces_around_splitter: Spaces around attributes and value splitters.\n        :type spaces_around_splitter: bool\n        :param space_after_comment_limiter: Space after comments limiter.\n        :type space_after_comment_limiter: bool\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        self.uncache()\n\n        LOGGER.debug(\"> Setting '{0}' file content.\".format(self.path))\n        attribute_template = \"{{0}} {0} {{1}}\\n\".format(splitter) if spaces_around_splitter else \\\n            \"{{0}}{0}{{1}}\\n\".format(splitter)\n        attribute_template = foundations.strings.replace(attribute_template, {\"{{\": \"{\", \"}}\": \"}\"})\n        comment_template = space_after_comment_limiter and \"{0} {{0}}\\n\".format(comment_limiter) or \\\n                           \"{0}{{0}}\\n\".format(comment_limiter)\n        if self.__defaults_section in self.__sections:\n            LOGGER.debug(\"> Appending '{0}' default section.\".format(self.__defaults_section))\n            if self.__comments:\n                for comment, value in self.__comments.iteritems():\n                    if self.__defaults_section in comment:\n                        value = value[\"content\"] or \"\"\n                        LOGGER.debug(\"> Appending '{0}' comment with '{1}' value.\".format(comment, value))\n                        self.content.append(comment_template.format(value))\n            for attribute, value in self.__sections[self.__defaults_section].iteritems():\n                attribute = namespaces and attribute or foundations.namespace.remove_namespace(attribute,\n                                                                                               self.__namespace_splitter,\n                                                                                               root_only=True)\n                value = value or \"\"\n                LOGGER.debug(\"> Appending '{0}' attribute with '{1}' value.\".format(attribute, value))\n                self.content.append(attribute_template.format(attribute, value))\n            self.content.append(\"\\n\")\n\n        for i, section in enumerate(self.__sections):\n            LOGGER.debug(\"> Appending '{0}' section.\".format(section))\n            self.content.append(\"[{0}]\\n\".format(section))\n            if self.__comments:\n                for comment, value in self.__comments.iteritems():\n                    if section in comment:\n                        value = value[\"content\"] or \"\"\n                        LOGGER.debug(\"> Appending '{0}' comment with '{1}' value.\".format(comment, value))\n                        self.content.append(comment_template.format(value))\n            for attribute, value in self.__sections[section].iteritems():\n                if foundations.namespace.remove_namespace(attribute) == self.__raw_section_content_identifier:\n                    LOGGER.debug(\"> Appending '{0}' raw section content.\".format(section))\n                    for line in value:\n                        self.content.append(line)\n                else:\n                    LOGGER.debug(\"> Appending '{0}' section.\".format(section))\n                    attribute = namespaces and attribute or foundations.namespace.remove_namespace(attribute,\n                                                                                                   self.__namespace_splitter,\n                                                                                                   root_only=True)\n                    value = value or \"\"\n                    LOGGER.debug(\"> Appending '{0}' attribute with '{1}' value.\".format(attribute, value))\n                    self.content.append(attribute_template.format(attribute, value))\n            if i != len(self.__sections) - 1:\n                self.content.append(\"\\n\")\n        foundations.io.File.write(self)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef elements(self, value):\n\n        if value is not None:\n            assert type(value) is dict, \"'{0}' attribute: '{1}' type is not  dict'!\".format(\"elements\", value)\n        self.__elements = value", "response": "Set the elements of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the unserializers attribute.", "response": "def unserializers(self, value):\n        \"\"\"\n        Setter for **self.__unserializers** attribute.\n\n        :param value: Attribute value.\n        :type value: dict\n        \"\"\"\n\n        raise foundations.exceptions.ProgrammingError(\n            \"{0} | '{1}' attribute is read only!\".format(self.__class__.__name__, \"unserializers\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the file content.", "response": "def parse(self, raise_parsing_errors=True):\n        \"\"\"\n        Process the file content.\n\n        Usage::\n\n            >>> plist_file_parser = PlistFileParser(\"standard.plist\")\n            >>> plist_file_parser.parse()\n            True\n            >>> plist_file_parser.elements.keys()\n            [u'Dictionary A', u'Number A', u'Array A', u'String A', u'Date A', u'Boolean A', u'Data A']\n\n        :param raise_parsing_errors: Raise parsing errors.\n        :type raise_parsing_errors: bool\n        :return: Method success.\n        :rtype: bool\n        \"\"\"\n\n        LOGGER.debug(\"> Reading elements from: '{0}'.\".format(self.path))\n\n        element_tree_parser = ElementTree.iterparse(self.path)\n\n        self.__parsing_errors = []\n        for action, element in element_tree_parser:\n            unmarshal = self.__unserializers.get(element.tag)\n            if unmarshal:\n                data = unmarshal(element)\n                element.clear()\n                element.text = data\n            elif element.tag != \"plist\":\n                self.__parsing_errors.append(foundations.exceptions.FileStructureParsingError(\n                    \"Unknown element: {0}\".format(element.tag)))\n\n        if self.__parsing_errors:\n            if raise_parsing_errors:\n                raise foundations.exceptions.FileStructureParsingError(\n                    \"{0} | '{1}' structure is invalid, parsing exceptions occured!\".format(self.__class__.__name__,\n                                                                                           self.path))\n        else:\n            self.__elements = foundations.common.get_first_item(element_tree_parser.root).text\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef element_exists(self, element):\n\n        if not self.__elements:\n            return False\n\n        for item in foundations.walkers.dictionaries_walker(self.__elements):\n            path, key, value = item\n            if key == element:\n                LOGGER.debug(\"> '{0}' attribute exists.\".format(element))\n                return True\n\n        LOGGER.debug(\"> '{0}' element doesn't exists.\".format(element))\n        return False", "response": "Checks if given element exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering the list of elements using given pattern.", "response": "def filter_values(self, pattern, flags=0):\n        \"\"\"\n        | Filters the :meth:`PlistFileParser.elements` class property elements using given pattern.\n        | Will return a list of matching elements values, if you want to get only one element value, use\n            the :meth:`PlistFileParser.get_value` method instead.\n\n        Usage::\n\n            >>> plist_file_parser = PlistFileParser(\"standard.plist\")\n            >>> plist_file_parser.parse()\n            True\n            >>> plist_file_parser.filter_values(r\"String A\")\n            [u'My Value A']\n            >>> plist_file_parser.filter_values(r\"String.*\")\n            [u'My Value C', u'My Value B', u'My Value A']\n\n        :param pattern: Regex filtering pattern.\n        :type pattern: unicode\n        :param flags: Regex flags.\n        :type flags: int\n        :return: Values.\n        :rtype: list\n        \"\"\"\n\n        values = []\n        if not self.__elements:\n            return values\n\n        for item in foundations.walkers.dictionaries_walker(self.__elements):\n            path, element, value = item\n            if re.search(pattern, element, flags):\n                values.append(value)\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the given element value.", "response": "def get_value(self, element):\n        \"\"\"\n        | Returns the given element value.\n        | If multiple elements with the same name exists, only the first encountered will be returned.\n\n        Usage::\n\n            >>> plist_file_parser = PlistFileParser(\"standard.plist\")\n            >>> plist_file_parser.parse()\n            True\n            >>> plist_file_parser.get_value(\"String A\")\n            u'My Value A'\n\n        :param element: Element to get the value.\n        :type element: unicode\n        :return: Element value.\n        :rtype: object\n        \"\"\"\n\n        if not self.__elements:\n            return\n\n        values = self.filter_values(r\"^{0}$\".format(element))\n        return foundations.common.get_first_item(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the provided vector to the matrix.", "response": "def add_vector(self, vector):\n        \"\"\"\\\n        Writes the provided vector to the matrix.\n\n        `vector`\n            An iterable of ``(word-id, word-frequency)`` tuples\n        \"\"\"\n        self._num_docs+=1\n        max_id, veclen = self._mmw.write_vector(self._num_docs, vector)\n        self._num_terms = max(self._num_terms, 1 + max_id)\n        self._num_nnz += veclen"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting for an event on file descriptor fd.", "response": "def _wait_fd(conn, read=True):\n    '''Wait for an event on file descriptor ``fd``.\n\n    :param conn: file descriptor\n    :param read: wait for a read event if ``True``, otherwise a wait\n        for write event.\n\n    This function must be invoked from a coroutine with parent, therefore\n    invoking it from the main greenlet will raise an exception.\n    '''\n    current = getcurrent()\n    parent = current.parent\n    assert parent, '\"_wait_fd\" must be called by greenlet with a parent'\n    try:\n        fileno = conn.fileno()\n    except AttributeError:\n        fileno = conn\n    future = Future()\n    # When the event on fd occurs switch back to the current greenlet\n    if read:\n        future._loop.add_reader(fileno, _done_wait_fd, fileno, future, read)\n    else:\n        future._loop.add_writer(fileno, _done_wait_fd, fileno, future, read)\n    # switch back to parent greenlet\n    parent.switch(future)\n    # Back on the child greenlet. Raise error if there is one\n    future.result()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shutdown(self, message=None):\n        for name, server in self.servers.items():\n            server.quit(message)", "response": "Disconnect all servers with a message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_server(self, server_name, *args, **kwargs):\n        server = ServerConnection(name=server_name, reactor=self)\n\n        if args or kwargs:\n            server.set_connect_info(*args, **kwargs)\n\n        # register cached events\n        for verb, infos in self._event_handlers.items():\n            for info in infos:\n                server.register_event(info['direction'], verb, info['handler'],\n                                      priority=info['priority'])\n\n        self.servers[server_name] = server\n\n        return server", "response": "Create an IRC server connection slot."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndestroy the given server called internally.", "response": "def _destroy_server(self, server_name):\n        \"\"\"Destroys the given server, called internally.\"\"\"\n        try:\n            del self.servers[server_name]\n        except KeyError:\n            pass\n\n        if self.auto_close and not self.servers:\n            loop.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters this function as an event handler.", "response": "def handler(self, direction, verb, priority=10):\n        \"\"\"Register this function as an event handler.\n\n        Args:\n            direction (str): ``in``, ``out``, ``both``, ``raw``.\n            verb (str): Event name.\n            priority (int): Handler priority (lower priority executes first).\n\n        Example:\n            These handlers print out a pretty raw log::\n\n                reactor = girc.Reactor()\n\n                @reactor.handler('in', 'raw', priority=1)\n                def handle_raw_in(event):\n                    print(event['server'].name, ' ->', escape(event['data']))\n\n\n                @reactor.handler('out', 'raw', priority=1)\n                def handle_raw_out(event):\n                    print(event['server'].name, '<- ', escape(event['data']))\n        \"\"\"\n        def parent_fn(func):\n            @functools.wraps(func)\n            def child_fn(msg):\n                func(msg)\n            self.register_event(direction, verb, child_fn, priority=priority)\n            return child_fn\n        return parent_fn"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister an event with all servers.", "response": "def register_event(self, direction, verb, child_fn, priority=10):\n        \"\"\"Register an event with all servers.\n\n        Args:\n            direction (str): `in`, `out`, `both`, `raw`.\n            verb (str): Event name.\n            child_fn (function): Handler function.\n            priority (int): Handler priority (lower priority executes first).\n        \"\"\"\n        if verb not in self._event_handlers:\n            self._event_handlers[verb] = []\n\n        self._event_handlers[verb].append({\n            'handler': child_fn,\n            'direction': direction,\n            'priority': priority,\n        })\n\n        for name, server in self.servers.items():\n            server.register_event(direction, verb, child_fn, priority=priority)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nform {% alert class=error %} message {% endalert %}", "response": "def semantic_alert(visitor, block):\n    \"\"\"\n    Format:\n        \n        {% alert class=error %}\n        message\n        {% endalert %}\n    \"\"\"\n    txt = []\n    cls = block['kwargs'].get('class', '')\n    txt.append('<div class=\"ui %s message\">' % cls)\n    text = visitor.parse_text(block['body'], 'article')\n    txt.append(text)\n    txt.append('</div>')\n    return '\\n'.join(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef semantic_tabs(visitor, block):\n    import re\n    global __section__\n    \n    __section__ += 1\n    \n    r_name = re.compile(r'(^-- [^-]+ --$)', re.M)\n    def get_id():\n        global __seq__\n        \n        __seq__ += 1\n        \n        return 'tab_item_%d_%d' % (__section__, __seq__)\n    \n    txt = []\n    txt.append('<div class=\"ui tabular filter menu\">')\n    \n    body = block['body']\n    i = 0\n    items = r_name.split(body)\n    first = True\n    entries = []\n    in_tab = False #if tab processed\n    ids = []\n    while i<len(items):\n        if in_tab:\n            entries.append(items[i])\n            in_tab = False\n        if items[i].startswith('-- ') and items[i].endswith(' --'):\n            if first:\n                cls = ' class=\"active\"'\n                first = False\n            else:\n                cls = ''\n            _id = get_id()\n            ids.append(_id)\n            txt.append('<a class=\"%sitem\" data-tab=\"%s\">%s</a>' % (cls, _id, items[i][3:-3]))\n            in_tab = True\n        \n        i += 1\n    txt.append('</div>')\n    \n    txt.append('<div class=\"tab-content\">')\n    for i, x in enumerate(entries):\n        if i == 0:\n            cls = ' active'\n        else:\n            cls = ''\n        txt.append('<div class=\"ui divided inbox selection list%s tab\" data-tab=\"%s\">' % (cls, ids[i]))\n        txt.append(visitor.parse_text(x, 'article'))\n        txt.append('</div>')\n        \n    txt.append('</div>')\n    txt.append('</div>')\n    \n    return '\\n'.join(txt)", "response": "Render text as bootstrap tabs for example."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a UK postcode into outcode and incode portions.", "response": "def parse_uk_postcode(postcode, strict=True, incode_mandatory=True):\n    '''Split UK postcode into outcode and incode portions.\n\n    Arguments:\n    postcode            The postcode to be split.\n    strict              If true, the postcode will be validated according to\n                        the rules as specified at the Universal Postal Union[1]\n                        and The UK Government Data Standards Catalogue[2]. If\n                        the supplied postcode doesn't adhere to these rules a\n                        ValueError will be thrown.\n    incode_mandatory    If true, and only an outcode has been supplied, the\n                        function will throw a ValueError.\n\n    Returns:            outcode, incode\n\n    Raises:             ValueError, if postcode is longer than seven\n                        characters, or if 'strict' or 'incode_mandatory'\n                        conditions are broken - see above.\n\n    Usage example:      >>> from postcode import parse_uk_postcode\n                        >>> parse_uk_postcode('cr0 2yr')\n                        ('CR0', '2YR')\n                        >>> parse_uk_postcode('cr0')\n                        Traceback (most recent call last):\n                          File \"<interactive input>\", line 1, in ?\n                          File \"postcode.py\", line 101, in parse_uk_postcode\n                            raise ValueError('Incode mandatory')\n                        ValueError: Incode mandatory\n                        >>> parse_uk_postcode('cr0', False, False)\n                        ('CR0', '')\n\n    [1] http://www.upu.int/fileadmin/documentsFiles/activities/addressingUnit/gbrEn.pdf\n    [2] http://web.archive.org/web/20090930140939/http://www.govtalk.gov.uk/gdsc/html/noframes/PostCode-2-1-Release.htm\n    '''\n\n    postcode = postcode.replace(' ', '').upper()  # Normalize\n\n    if len(postcode) > 7:\n        raise exceptions.MaxLengthExceededError()\n\n    # Validate postcode\n    if strict:\n\n        # Try for full postcode match\n        postcode_match = POSTCODE_REGEX.match(postcode)\n        if postcode_match:\n            return postcode_match.group(1, 2)\n\n        # Try for outcode only match\n        outcode_match = STANDALONE_OUTCODE_REGEX.match(postcode)\n        if outcode_match:\n            if incode_mandatory:\n                raise exceptions.IncodeNotFoundError('Incode mandatory')\n            else:\n                return outcode_match.group(1), ''\n\n        # Try Girobank special case\n        if postcode == 'GIR0AA':\n            return 'GIR', '0AA'\n        elif postcode == 'GIR':\n            if incode_mandatory:\n                raise exceptions.IncodeNotFoundError('Incode mandatory')\n            else:\n                return 'GIR', ''\n\n        # None of the above\n        raise exceptions.InvalidPostcodeError(\n            'Value provided does not align with UK postcode rules'\n        )\n\n    # Just chop up whatever we've been given.\n    else:\n        # Outcode only\n        if len(postcode) <= 4:\n            if incode_mandatory:\n                raise exceptions.IncodeNotFoundError('Incode mandatory')\n            else:\n                return postcode, ''\n        # Full postcode\n        else:\n            return postcode[:-3], postcode[-3:]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef now_time(str=False):\n    if str:\n        return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    return datetime.datetime.now()", "response": "Get the current time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef now_date(str=False):\n    if str:\n        return datetime.datetime.now().strftime(\"%Y-%m-%d\")\n    return datetime.date.today()", "response": "Get the current date."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget milliseconds from a timedelta.", "response": "def timedelta2millisecond(td):\n    \"\"\"Get milliseconds from a timedelta.\"\"\"\n    milliseconds = td.days * 24 * 60 * 60 * 1000\n    milliseconds += td.seconds * 1000\n    milliseconds += td.microseconds / 1000\n    return milliseconds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting timedelta to different formats.", "response": "def timedelta2period(duration):\n    \"\"\"Convert timedelta to different formats.\"\"\"\n    seconds = duration.seconds\n    minutes = (seconds % 3600) // 60\n    seconds = (seconds % 60)\n    return '{0:0>2}:{1:0>2}'.format(minutes, seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a configuration that can be sent to the Hottop roaster.", "response": "def _generate_config(self):\n        \"\"\"Generate a configuration that can be sent to the Hottop roaster.\n\n        Configuration settings need to be represented inside of a byte array\n        that is then written to the serial interface. Much of the configuration\n        is static, but control settings are also included and pulled from the\n        shared dictionary.\n\n        :returns: Byte array of the prepared configuration.\n        \"\"\"\n        config = bytearray([0x00] * 36)\n        config[0] = 0xA5\n        config[1] = 0x96\n        config[2] = 0xB0\n        config[3] = 0xA0\n        config[4] = 0x01\n        config[5] = 0x01\n        config[6] = 0x24\n        config[10] = self._config.get('heater', 0)\n        config[11] = self._config.get('fan', 0)\n        config[12] = self._config.get('main_fan', 0)\n        config[16] = self._config.get('solenoid', 0)\n        config[17] = self._config.get('drum_motor', 0)\n        if self._config.get('heater', 0) > 0:\n            # Override the user here since the drum MUST be on for heat\n            config[17] = 1\n        config[18] = self._config.get('cooling_motor', 0)\n        config[35] = sum([b for b in config[:35]]) & 0xFF\n        return bytes(config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_config(self):\n        serialized = self._generate_config()\n        self._log.debug(\"Configuration has been serialized\")\n        try:\n            self._conn.flushInput()\n            self._conn.flushOutput()\n            self._conn.write(serialized)\n            return True\n        except Exception as e:\n            self._log.error(e)\n            raise Exception(e)", "response": "Send configuration data to the hottop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_checksum(self, buffer):\n        self._log.debug(\"Validating the buffer\")\n        if len(buffer) == 0:\n            self._log.debug(\"Buffer was empty\")\n            if self._conn.isOpen():\n                self._log.debug('Closing connection')\n                self._conn.close()\n            return False\n        p0 = hex2int(buffer[0])\n        p1 = hex2int(buffer[1])\n        checksum = sum([hex2int(c) for c in buffer[:35]]) & 0xFF\n        p35 = hex2int(buffer[35])\n        if p0 != 165 or p1 != 150 or p35 != checksum:\n            self._log.debug(\"Buffer checksum was not valid\")\n            return False\n        return True", "response": "Validate the checksum of the buffer response against the checksum."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_settings(self, retry=True):\n        if not self._conn.isOpen():\n            self._log.debug(\"Reopening connection\")\n            self._conn.open()\n        self._conn.flushInput()\n        self._conn.flushOutput()\n        buffer = self._conn.read(36)\n        if len(buffer) != 36:\n            self._log.debug('Buffer length (%d) did not match 36' % len(buffer))\n            if self._conn.isOpen():\n                self._log.debug('Closing connection')\n                self._conn.close()\n                self._read_settings(retry=True)\n\n        try:\n            check = self._validate_checksum(buffer)\n        except:\n            check = False\n\n        if not check and (retry and self._retry_count <= 3):\n            if self._retry_count == 3:\n                self._log.error('Retry count reached on buffer check')\n                self._read_settings(retry=False)\n            else:\n                self._retry_count += 1\n                self._read_settings(retry=True)\n\n        try:\n            settings = dict()\n            settings['heater'] = hex2int(buffer[10])\n            settings['fan'] = hex2int(buffer[11])\n            settings['main_fan'] = hex2int(buffer[12])\n            et = hex2int(buffer[23] + buffer[24])\n            settings['environment_temp'] = celsius2fahrenheit(et)\n            bt = hex2int(buffer[25] + buffer[26])\n            settings['bean_temp'] = celsius2fahrenheit(bt)\n            settings['solenoid'] = hex2int(buffer[16])\n            settings['drum_motor'] = hex2int(buffer[17])\n            settings['cooling_motor'] = hex2int(buffer[18])\n            settings['chaff_tray'] = hex2int(buffer[19])\n            self._retry_count = 0\n        except Exception:\n            self._log.error(\"Pulled a cache configuration!\")\n            settings = self._generate_config()\n        return settings", "response": "Reads the settings from the Hottop and returns a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _valid_config(self, settings):\n        if ((int(settings['environment_temp']) > self.MAX_BOUND_TEMP or\n                int(settings['environment_temp']) < self.MIN_BOUND_TEMP) or\n            (int(settings['bean_temp']) > self.MAX_BOUND_TEMP or\n                int(settings['bean_temp']) < self.MIN_BOUND_TEMP)):\n            self._log.error('Temperatures are outside of bounds')\n            return False\n        binary = ['drum_motor', 'chaff_tray', 'solenoid', 'cooling_motor']\n        for item in binary:\n            if int(settings.get(item)) not in [0, 1]:\n                self._log.error('Settings show invalid values')\n                return False\n        return True", "response": "Checks if the given settings are valid and returns a boolean indicating if it is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        self._wake_up()\n\n        while not self._q.empty():\n            self._config = self._q.get()\n\n        while not self.exit.is_set():\n            settings = self._read_settings()\n            settings['valid'] = self._valid_config(settings)\n            self._cb(settings)\n\n            if self.cooldown.is_set():\n                self._log.debug(\"Cool down process triggered\")\n                self._config['drum_motor'] = 1\n                self._config['heater'] = 0\n                self._config['solenoid'] = 1\n                self._config['cooling_motor'] = 1\n                self._config['main_fan'] = 10\n\n            if settings['valid']:\n                self._log.debug(\"Settings were valid, sending...\")\n                self._send_config()\n            time.sleep(self._config['interval'])", "response": "This function is run by the core loop of reading and writing configurations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _autodiscover_usb(self):\n        if sys.platform.startswith('win'):\n            ports = ['COM%s' % (i + 1) for i in range(256)]\n        elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n            ports = glob.glob('/dev/tty[A-Za-z]*')\n        elif sys.platform.startswith('darwin'):\n            ports = glob.glob('/dev/cu.*')\n        else:\n            raise EnvironmentError('Unsupported platform')\n\n        match = None\n        for port in ports:\n            try:\n                s = serial.Serial(port)\n                s.close()\n                if (port.find(\"/dev/cu.usbserial-\") > -1 and\n                        port.find('bluetooth') == -1):\n                    self.USB_PORT = port\n                    match = port\n                    break\n            except (OSError, serial.SerialException):\n                pass\n        return match", "response": "Attempt to find the USB adapter for the hottop."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the USB for the Hottop and return True if successful.", "response": "def connect(self, interface=None):\n        \"\"\"Connect to the USB for the hottop.\n\n        Attempt to discover the USB port used for the Hottop and then form a\n        connection using the serial library.\n\n        :returns: bool\n        :raises SerialConnectionError:\n        \"\"\"\n        if self._simulate:\n            return True\n        if not interface:\n            match = self._autodiscover_usb()\n            self._log.debug(\"Auto-discovered USB port: %s\" % match)\n        else:\n            self.USB_PORT = interface\n\n        try:\n            self._conn = serial.Serial(self.USB_PORT, baudrate=self.BAUDRATE,\n                                       bytesize=self.BYTE_SIZE,\n                                       parity=self.PARITY,\n                                       stopbits=self.STOPBITS,\n                                       timeout=self.TIMEOUT)\n        except serial.serialutil.SerialException as e:\n            raise SerialConnectionError(str(e))\n\n        self._log.debug(\"Serial connection set\")\n        if not self._conn.isOpen():\n            self._conn.open()\n            self._log.debug(\"Serial connection opened\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nestablishing a set of base controls that the user can influence.", "response": "def _init_controls(self):\n        \"\"\"Establish a set of base controls the user can influence.\n\n        :returns: None\n        \"\"\"\n        self._config['heater'] = 0\n        self._config['fan'] = 0\n        self._config['main_fan'] = 0\n        self._config['drum_motor'] = 1\n        self._config['solenoid'] = 0\n        self._config['cooling_motor'] = 0\n        self._config['interval'] = self.INTERVAL\n        self._config['environment_temp'] = 0\n        self._config['bean_temp'] = 0\n        self._config['chaff_tray'] = 1\n\n        self._roast['name'] = None\n        self._roast['input_weight'] = -1\n        self._roast['output_weight'] = -1\n        self._roast['operator'] = None\n        self._roast['start_time'] = None\n        self._roast['end_time'] = None\n        self._roast['duration'] = -1\n        self._roast['notes'] = None\n        self._roast['events'] = list()\n        self._roast['last'] = None\n        self._roast['record'] = False\n        self._roast['charge'] = None\n        self._roast['turning_point'] = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _callback(self, data):\n        local = copy.deepcopy(data)\n        output = dict()\n        output['config'] = local\n        if self._roast_start:\n            td = (now_time() - load_time(self._roast_start))\n            # Seconds since starting\n            output['time'] = ((td.total_seconds() + 60) / 60) - 1\n            self._roast['duration'] = output['time']\n            local.update({'time': output['time']})\n            output['datetime'] = now_time(str=True)\n            ct = load_time(now_time(str=True))\n            st = load_time(self._roast['start_time'])\n            self._roast['duration'] = timedelta2period(ct - st)\n\n        if self._roast['record']:\n            copied = copy.deepcopy(output)\n            self._derive_charge(copied['config'])\n            self._derive_turning_point(copied['config'])\n            self._roast['events'].append(copied)\n\n            if self._roast['last']:\n                delta = local['bean_temp'] - self._roast['last']['bean_temp']\n                output['config']['delta_bean_temp'] = delta\n            self._roast['last'] = local\n\n        if self._user_callback:\n            self._log.debug(\"Passing data back to client handler\")\n            output['roast'] = self._roast\n            output['roasting'] = self._roasting\n            if local.get('valid', True):\n                self._user_callback(output)", "response": "This function is called by the controller processing thread to process the data from the controller processing thread. It is called by the controller processing thread to process the data from the controller processing thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nderive the roast charge from the current configuration.", "response": "def _derive_charge(self, config):\n        \"\"\"Use a temperature window to identify the roast charge.\n\n        The charge will manifest as a sudden downward trend on the temperature.\n        Once found, we save it and avoid overwriting. The charge is needed in\n        order to derive the turning point.\n\n        :param config: Current snapshot of the configuration\n        :type config: dict\n        :returns: None\n        \"\"\"\n        if self._roast.get('charge'):\n            return None\n        self._window.append(config)\n        time, temp = list(), list()\n        for x in list(self._window):\n            time.append(x['time'])\n            temp.append(x['bean_temp'])\n        slope, intercept, r_value, p_value, std_err = linregress(time, temp)\n        if slope < 0:\n            self._roast['charge'] = self._roast['last']\n            self.add_roast_event({'event': 'Charge'})\n            return config\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self, func=None):\n        self._user_callback = func\n        if not self._simulate:\n            self._process = ControlProcess(self._conn, self._config, self._q,\n                                           self._log, callback=self._callback)\n        else:\n            self._process = MockProcess(self._config, self._q,\n                                        self._log, callback=self._callback)\n        self._process.start()\n        self._roasting = True", "response": "Start the roaster control process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nend the roaster control process.", "response": "def end(self):\n        \"\"\"End the roaster control process via thread signal.\n\n        This simply sends an exit signal to the thread, and shuts it down. In\n        order to stop monitoring, call the `set_monitor` method with false.\n\n        :returns: None\n        \"\"\"\n        self._process.shutdown()\n        self._roasting = False\n        self._roast['date'] = now_date(str=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset the internal roast properties.", "response": "def reset(self):\n        \"\"\"Reset the internal roast properties.\n\n        :returns: None\n        \"\"\"\n        self._roasting = False\n        self._roast_start = None\n        self._roast_end = None\n        self._roast = dict()\n        self._window = deque(list(), 5)\n        self._init_controls()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_roast_event(self, event):\n        event_time = self.get_roast_time()\n\n        def get_valid_config():\n            \"\"\"Keep grabbing configs until we have a valid one.\n\n            In rare cases, the configuration will be invalid when the user\n            registers an event. This malformation can occur across several\n            events, so we use this helper to find a valid config to associate\n            to the event while preserving the original time. Due to fast\n            interval checking, this is not liable to skew data that much and\n            it's better than extreme false data.\n            \"\"\"\n            config = self.get_roast_properties()['last']['config']\n            if not config['valid']:\n                self._log.debug(\"Invalid config at event time, retrying...\")\n                self.get_valid_config()\n            return config\n\n        event.update({'time': event_time,\n                      'config': get_valid_config()})\n        self._roast['events'].append(event)\n        return self.get_roast_properties()", "response": "Add an event to the roast log."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_interval(self, interval):\n        if type(interval) != float or type(interval) != int:\n            raise InvalidInput(\"Interval value must be of float or int\")\n        self._config['interval']", "response": "Set the polling interval for the process thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the properties of the roast.", "response": "def set_roast_properties(self, settings):\n        \"\"\"Set the properties of the roast.\n\n        :param settings: General settings for the roast setup\n        :type settings: dict\n        :returns: None\n        :raises: InvalidInput\n        \"\"\"\n        if type(settings) != dict:\n            raise InvalidInput(\"Properties value must be of dict\")\n        valid = ['name', 'input_weight', 'output_weight', 'operator', 'notes',\n                 'coffee']\n        for key, value in settings.items():\n            if key not in valid:\n                continue\n            self._roast[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_monitor(self, monitor):\n        if type(monitor) != bool:\n            raise InvalidInput(\"Monitor value must be bool\")\n        self._roast['record'] = bool2int(monitor)\n        self._q.put(self._config)\n\n        if self._roast['record']:\n            self._roast_start = now_time(str=True)\n            self._roast['start_time'] = self._roast_start\n        else:\n            self._roast_end = now_time(str=True)\n            self._roast['end_time'] = self._roast_end\n            self._roast['date'] = now_date(str=True)\n            et = load_time(self._roast['end_time'])\n            st = load_time(self._roast['start_time'])\n            self._roast['duration'] = timedelta2period(et - st)\n        return self.get_roast_properties()", "response": "Sets the monitor config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_heater(self, heater):\n        if type(heater) != int and heater not in range(0, 101):\n            raise InvalidInput(\"Heater value must be int between 0-100\")\n        self._config['heater'] = heater\n        self._q.put(self._config)", "response": "Set the heater config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the fan config.", "response": "def set_fan(self, fan):\n        \"\"\"Set the fan config.\n\n        :param fan: Value to set the fan\n        :type fan: int [0-10]\n        :returns: None\n        :raises: InvalidInput\n        \"\"\"\n        if type(fan) != int and fan not in range(0, 11):\n            raise InvalidInput(\"Fan value must be int between 0-10\")\n        self._config['fan'] = fan\n        self._q.put(self._config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_main_fan(self, main_fan):\n        if type(main_fan) != int and main_fan not in range(0, 11):\n            raise InvalidInput(\"Main fan value must be int between 0-10\")\n        self._config['main_fan'] = main_fan\n        self._q.put(self._config)", "response": "Set the main fan config."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_drum_motor(self, drum_motor):\n        if type(drum_motor) != bool:\n            raise InvalidInput(\"Drum motor value must be bool\")\n        self._config['drum_motor'] = bool2int(drum_motor)\n        self._log.debug(self._config)\n        self._q.put(self._config)", "response": "Sets the drum motor config."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_solenoid(self, solenoid):\n        if type(solenoid) != bool:\n            raise InvalidInput(\"Solenoid value must be bool\")\n        self._config['solenoid'] = bool2int(solenoid)\n        self._q.put(self._config)", "response": "Set the solenoid config."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the cooling motor configuration.", "response": "def set_cooling_motor(self, cooling_motor):\n        \"\"\"Set the cooling motor config.\n\n        :param cooling_motor: Value to set the cooling motor\n        :type cooling_motor: bool\n        :returns: None\n        :raises: InvalidInput\n        \"\"\"\n        if type(cooling_motor) != bool:\n            raise InvalidInput(\"Cooling motor value must be bool\")\n        self._config['cooling_motor'] = bool2int(cooling_motor)\n        self._q.put(self._config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_simulate(self, status):\n        if type(status) != bool:\n            raise InvalidInput(\"Status value must be bool\")\n        self._simulate = bool2int(status)", "response": "Sets the simulation status."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_filter(self, fieldname, query_func, expct_value):\n        ''' makes a filter that will be appliead to an object's property based\n        on query_func '''\n\n        def actual_filter(item):\n            value = getattr(item, fieldname)\n\n            if query_func in NULL_AFFECTED_FILTERS and value is None:\n                return False\n\n            if query_func == 'eq':\n                return value == expct_value\n            elif query_func == 'ne':\n                return value != expct_value\n            elif query_func == 'lt':\n                return value < expct_value\n            elif query_func == 'lte':\n                return value <= expct_value\n            elif query_func == 'gt':\n                return value > expct_value\n            elif query_func == 'gte':\n                return value >= expct_value\n            elif query_func == 'startswith':\n                return value.startswith(expct_value)\n            elif query_func == 'endswith':\n                return value.endswith(expct_value)\n\n        actual_filter.__doc__ = '{} {} {}'.format('val', query_func, expct_value)\n\n        return actual_filter", "response": "creates a filter that will be appliead to an object s property based\n            on query_func and expct_value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notGroup (states, *stateIndexPairs):\n    start, dead = group(states, *stateIndexPairs)\n    finish = len(states)\n    states.append([])\n    states[start].append((DEFAULT, finish))\n    return start, finish", "response": "Like group but will add a DEFAULT transition to a new start state and a new finish state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sameState (s1, s2):\n    if (len(s1[1]) != len(s2[1])) or (s1[2] != s2[2]):\n        return False\n    for arcIndex in range(0, len(s1[1])):\n        arc1 = s1[1][arcIndex]\n        arc2 = s2[1][arcIndex]\n        if arc1[:-1] != arc2[:-1]:\n            return False\n    return True", "response": "Returns True if the two lists are the same state."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinalizes the temp states and return a list of states and accepts.", "response": "def finalizeTempDfa (tempStates):\n    \"\"\"finalizeTempDfa (tempStates)\n\n    Input domain:\n    tempState := [ nfaClosure : Long, [ tempArc ], accept : Boolean ]\n    tempArc := [ label, arrow, nfaClosure ]\n\n    Output domain:\n    state := [ arcMap, accept : Boolean ]\n    \"\"\"\n    states = []\n    accepts = []\n    stateMap = {}\n    tempIndex = 0\n    for tempIndex in range(0, len(tempStates)):\n        tempState = tempStates[tempIndex]\n        if None != tempState:\n            stateMap[tempIndex] = len(states)\n            states.append({})\n            accepts.append(tempState[2])\n    for tempIndex in stateMap.keys():\n        stateBitset, tempArcs, accepting = tempStates[tempIndex]\n        newIndex = stateMap[tempIndex]\n        arcMap = states[newIndex]\n        for tempArc in tempArcs:\n            arcMap[tempArc[0]] = stateMap[tempArc[1]]\n    return states, accepts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the access_token and sets the praw instance rendite_client with a valid one.", "response": "def refresh(self, force=False):\n        \"\"\"Refreshes the `access_token` and sets the praw instance `reddit_client`\n        with a valid one.\n\n        :param force: Boolean. Refresh will be done only when last refresh was\n            done before `EXPIRY_DURATION`, which is 3500 seconds. However\n            passing `force` will overrides this and refresh operation will be\n            done everytime.\n        \"\"\"\n        if self._is_token_expired() or force:\n            tokens = self._get_refresh_access()\n            self.access_token = tokens['access_token']\n            self.refresh_token = tokens['refresh_token']\n            self._set_access_credentials()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the great circle distance between two points on the earth", "response": "def distance(self, loc):\n        \"\"\"\n        Calculate the great circle distance between two points\n        on the earth (specified in decimal degrees)\n        \"\"\"\n        assert type(loc) == type(self)\n\n        # convert decimal degrees to radians\n        lon1, lat1, lon2, lat2 = map(radians, [\n            self.lon,\n            self.lat,\n            loc.lon,\n            loc.lat,\n        ])\n\n        # haversine formula\n        dlon = lon2 - lon1\n        dlat = lat2 - lat1\n        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n        c = 2 * asin(sqrt(a))\n        r = 6371000 # Radius of earth in meters.\n        return c * r"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef renders(template_content, context, **options):\n    if options.get(\"safe\", False):\n        return string.Template(template_content).safe_substitute(context)\n    else:\n        try:\n            return string.Template(template_content).substitute(context)\n        except KeyError as exc:\n            raise anytemplate.globals.CompileError(str(exc))", "response": "Renders a string containing the content of a template."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_impl(self, template, context, **options):\n        ropts = dict((k, v) for k, v in options.items() if k != \"safe\")\n        tmpl = anytemplate.engines.base.fallback_render(template, {}, **ropts)\n        return self.renders_impl(tmpl, context, **options)", "response": "This method renders the given template file with the given context."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts an iterator to a tuple so that it can be iterated again.", "response": "def cvt_iter(a):\n    '''\n    Convert an iterator/generator to a tuple so that it can be iterated again.\n\n    E.g., convert zip in PY3.\n    '''\n    if a is None:\n        return a\n\n    if not isinstance(a, (tuple, list)):\n        # convert iterator/generator to tuple\n        a = tuple(a)\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_dict(d, cls=AttrDict): # not used\n    '''\n    recursively convert a normal Mapping `d` and it's values to a specified type\n    (defaults to AttrDict)\n    '''\n    for k, v in d.items():\n        if isinstance(v, Mapping):\n            d[k] = convert_dict(v)\n        elif isinstance(v, list):\n            for i, e in enumerate(v):\n                if isinstance(e, Mapping):\n                    v[i] = convert_dict(e)\n    return cls(d)", "response": "Convert a normal Mapping d and it s values to a specified type\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts key of various types to int or list of int", "response": "def _key_to_index(keys, key, single_only=False):\n    'convert ``key`` of various types to int or list of int'\n    if isinstance(key, int): # validate the int index\n        try:\n            keys[key]\n        except IndexError:\n            raise KeyError('Index out of range of keys: %s' % (key,))\n        if key < 0:\n            key += len(keys) # always positive index\n        return key\n#    keys = d.keys()\n    if not single_only:\n        if isinstance(key, (tuple, list)):\n            return [_key_to_index_single(keys, k) for k in key]\n\n        if isinstance(key, slice):\n            start, stop, step = key.start, key.stop, key.step\n            try:\n                MI_check_index_name(start)\n                start = keys.index(start)\n            except TypeError:\n                pass\n            try:\n                MI_check_index_name(stop)\n                stop = keys.index(stop)\n            except TypeError:\n                pass\n#            return slice(start, stop, step)\n            args = slice(start, stop, step).indices(len(keys))\n            return force_list(range(*args)) # list of indices\n    try:\n        return keys.index(key)\n    except ValueError: # not IndexError\n        raise KeyError('Key not found: %s' % (key,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a key to index or single", "response": "def convert_key_to_index(keys, key):\n    '''\n    convert ``key`` of various types to int or list of int\n\n    return index, single\n    '''\n    index = _key_to_index(keys, key)\n    single = isinstance(index, int)\n    return index, single"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _int_to_key(keys, index):\n    'Convert int ``index`` to the corresponding key in ``keys``'\n    if isinstance(index, int):\n        try:\n            return keys[index]\n        except IndexError:\n            # use KeyError rather than IndexError for compatibility\n            raise KeyError('Index out of range of keys: %s' % (index,))\n    return index", "response": "Convert int index to the corresponding key in keys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert index to key or list of keys.", "response": "def convert_index_to_keys(d, item):\n    # use a separate function rather than a method inside the class IndexDict\n    '''\n    Convert ``item`` in various types (int, tuple/list, slice, or a normal key)\n    to a single key or a list of keys.\n    '''\n\n    keys = force_list(d.keys())\n    # use KeyError for compatibility of normal use\n\n    # Warning: int item will be interpreted as the index rather than key!!\n    if isinstance(item, int):\n        item = _int_to_key(keys, item)\n        single = True\n\n    elif isinstance(item, (tuple, list)):\n        item2 = []\n        for i in item:\n            i = _int_to_key(keys, i)\n            item2.append(i)\n        item = item2\n        single = False\n\n    elif isinstance(item, slice):\n        start, stop, step = item.start, item.stop, item.step\n        # None is not interpreted as a key\n        if not isinstance(start, (NoneType, int)):\n            try:\n                start = keys.index(start)\n            except ValueError:\n                raise KeyError('%s is not in the list of keys' % (start,))\n        if not isinstance(stop, (NoneType, int)):\n            try:\n                stop = keys.index(stop)\n            except ValueError:\n                raise KeyError('%s is not in the list of keys' % (stop,))\n        item = keys[start:stop:step]\n        single = False\n\n    else:  # other types, treated as a single key\n        IndexDict_check_key_type(item)\n        single = True\n\n    return item, single"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_unique_name(name='', collection=()):\n    '''\n    Generate a unique name (str type) by appending a sequence number to\n    the original name so that it is not contained in the collection.\n    ``collection`` has a __contains__ method (tuple, list, dict, etc.)\n    '''\n    if name not in collection:\n        return name\n    i = 1\n    while True:\n        i += 1\n        name2 = '%s_%s' % (name, i)\n        if name2 not in collection:\n            return name2", "response": "Generate a unique name by appending a sequence number to the original name so that it is not contained in the collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value_len(value):\n    '''\n    Get length of ``value``. If ``value`` (eg, iterator) has no len(), convert it to list first.\n\n    return both length and converted value.\n    '''\n    try:\n        Nvalue = len(value)\n    except TypeError:\n        # convert iterator/generator to list\n        value = list(value)\n        Nvalue = len(value)\n    return Nvalue, value", "response": "Get length of value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef MI_parse_args(self, args, ingore_index2=False, allow_new=False):\n    '''\n    Parse the arguments for indexing in MIDict.\n\n    Full syntax: ``d[index1:key, index2]``.\n\n    ``index2`` can be flexible indexing (int, list, slice etc.) as in ``IndexDict``.\n\n    Short syntax:\n\n    * d[key] <==> d[key,] <==> d[first_index:key, all_indice_except_first]\n    * d[:key] <==> d[:key,] <==> d[None:key] <==> d[last_index:key, all_indice_except_last]\n    * d[key, index2] <==> d[first_index:key, index2] # this is valid\n      # only when index2 is a list or slice object\n    * d[index1:key, index2_1, index2_2, ...] <==> d[index1:key, (index2_1, index2_2, ...)]\n\n    '''\n    empty = len(self.indices) == 0\n    if empty and not allow_new:\n        raise KeyError('Item not found (dictionary is empty): %s' % (args,))\n\n    names = force_list(self.indices.keys())\n\n    Nargs = len(args) if isinstance(args, tuple) else 1\n\n    _default = object()\n    index1 = index2 = _default\n\n    if isinstance(args, tuple):\n        # easy handle of default logic (use continue/break as shortcut)\n        for _ in (1,):\n            if ingore_index2:\n                continue\n\n            if isinstance(args[0], slice):\n                index1, key = args[0].start, args[0].stop\n\n                if Nargs == 2:\n                    index2 = args[1]\n                elif Nargs > 2:\n                    index2 = args[1:]\n                break\n\n            # args[0] is not a slice\n            if Nargs > 1 and isinstance(args[1], (list, slice)):\n                if Nargs == 2:\n                    key, index2 = args\n                    break\n                else:\n                    raise KeyError('No arguments allowed after index2, found: %s' % (args[2:],))\n        else:\n            key = args\n\n    elif isinstance(args, slice):\n        index1, key = args.start, args.stop\n\n    else:\n        key = args\n\n    if empty: # allow_new is True\n        index1_last = False\n\n        exist_names = []  # list of names already passed in as arguments\n        if index1 is not _default:\n            if index1 is None: # slice syntax d[:key]\n                index1_last = True\n                index1 = _default\n            elif isinstance(index1, int):\n                raise TypeError('Index1 can not be int when dictionary '\n                                'is empty: %s' % (index1,))\n            else:\n                MI_check_index_name(index1)\n                exist_names.append(index1)\n        if index2 is not _default:\n            if isinstance(index2, (tuple, list)):\n                map(MI_check_index_name, index2)\n                exist_names.extend(index2)\n            elif isinstance(index2, (int, slice)):\n                raise TypeError('Index2 can not be int or slice when '\n                                'dictionary is empty: %s' % (index2,))\n            else:\n                MI_check_index_name(index2)\n                exist_names.append(index2)\n\n        # auto generate index names and avoid conficts with existing names\n        if index1 is _default:\n            if index1_last:\n                if len(exist_names) > 1: # index2 is specified\n                    name1 = 'index_%s' % (len(exist_names) + 1)\n                else:\n                    name1 = 'index_2'\n            else:\n                name1 = 'index_1'\n            index1 = get_unique_name(name1, exist_names)\n            exist_names.append(index1)\n\n        if index2 is _default:\n            name2 = 'index_1' if index1_last else 'index_2'\n            index2 = get_unique_name(name2, exist_names)\n\n        return index1, key, index2, index1_last\n\n    # not empty:\n\n    if index1 is _default:  # not specified\n        index1 = 0\n    elif index1 is None:  # slice syntax d[:key]\n        index1 = -1\n\n    # index1 is always returned as an int\n    index1 = _key_to_index_single(names, index1)\n\n    try:\n        item = MI_get_item(self, key, index1)\n    except KeyError:\n        if allow_new:  # new key for setitem; item_d = None\n            item = None\n        else:\n            raise KeyError('Key not found in index #%s \"%s\": %s' %\n                            (index1, names[index1], key))\n\n    if ingore_index2:  # used by delitem\n        return item\n\n    if index2 is _default:  # not specified\n        # index2 defaults to all indices except index1\n        if len(names) == 1:\n            index2 = 0  # index2 defaults to the only one index\n        else:\n            index2 = force_list(range(len(names)))\n            index2.remove(index1)\n            if len(index2) == 1:  # single index\n                index2 = index2[0]\n    else:\n        # index2 is always returned as int or list of int\n        index2 = _key_to_index(names, index2)\n\n    if item is None:  # allow_new. item and value are None\n        return index1, key, index2, None, None\n\n#    try:\n#        value = mget_list(item, index2)\n#    except IndexError:\n#        raise KeyError('Index not found: %s' % (index2,))\n\n    # no need to try since index2 is always returned as int or list of int\n    value = mget_list(item, index2)\n    return index1, key, index2, item, value", "response": "Parse the arguments for indexing in MIDict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mget_list(item, index):\n    'get mulitple items via index of int, slice or list'\n    if isinstance(index, (int, slice)):\n        return item[index]\n    else:\n        return map(item.__getitem__, index)", "response": "get mulitple items via index of int slice or list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mset_list(item, index, value):\n    'set mulitple items via index of int, slice or list'\n    if isinstance(index, (int, slice)):\n        item[index] = value\n    else:\n        map(item.__setitem__, index, value)", "response": "set mulitple items via index of int slice or list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef MI_get_item(self, key, index=0):\n    'return list of item'\n    index = _key_to_index_single(force_list(self.indices.keys()), index)\n    if index != 0:\n        key = self.indices[index][key]  # always use first index key\n    # key must exist\n    value = super(MIMapping, self).__getitem__(key)\n    N = len(self.indices)\n    if N == 1:\n        return [key]\n\n    if N == 2:\n        value = [value]\n    return [key] + value", "response": "return list of item"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces key in OrderedDict od by new key in - place.", "response": "def od_replace_key(od, key, new_key, *args, **kw):\n    '''\n    Replace key(s) in OrderedDict ``od`` by new key(s) in-place (i.e.,\n    preserving the order(s) of the key(s))\n\n    Optional new value(s) for new key(s) can be provided as a positional\n    argument (otherwise the old value(s) will be used):\n\n        od_replace_key(od, key, new_key, new_value)\n\n    To replace multiple keys, pass argument ``key`` as a list instance,\n    or explicitly pass a keyword argument ``multi=True``:\n\n        od_replace_key(od, keys, new_keys, [new_values,] multi=True)\n\n    '''\n    multi = kw.get('multi', False) or isinstance(key, list)\n\n    if multi:\n        if len(key) != len(new_key):\n            raise ValueError('Length of keys (%s) does not match '\n                             'length of new keys (%s)' % (len(key), len(new_key)))\n        if args:\n            new_value = args[0]\n            if len(new_key) != len(new_value):\n                raise ValueError('Length of new keys (%s) does not match '\n                                 'length of new values (%s)' %\n                                 (len(new_key), len(new_value)))\n            for k_old, k_new, v_new in zip(key, new_key, new_value):\n                od_replace_key(od, k_old, k_new, v_new)\n        else:\n            for k_old, k_new in zip(key, new_key):\n                od_replace_key(od, k_old, k_new)\n        return\n\n    # single key\n\n    if args:\n        value = args[0]\n\n    if new_key == key:\n        if args:\n            OrderedDict.__setitem__(od, key, value)\n        return\n\n    # new_key != key\n    if new_key in od: # new_key overwrites another existing key\n        OrderedDict.__delitem__(od, new_key)\n\n    if PY2:\n        # modify internal variables\n        _map = od._OrderedDict__map\n        link = _map[key]\n        link[2] = new_key\n        del _map[key]\n        _map[new_key] = link\n        val = dict.pop(od, key)\n        if args:\n            val = value\n        dict.__setitem__(od, new_key, val)\n\n    else:\n        # in PY3, OrderedDict is implemented in C\n        # no access to private variables __map\n        found = False\n        keys = [] # keys after key\n        for k in od:\n            if k == key:\n                found = True\n                continue\n            if found:\n                keys.append(k)\n        # warning: can not use OrderedDict.pop, which calls del self[key]\n        getitem = dict.__getitem__\n        setitem = OrderedDict.__setitem__\n        delitem = OrderedDict.__delitem__\n        v = getitem(od, key)\n        delitem(od, key)\n        if args:\n            v = value\n        setitem(od, new_key, v)\n        # shift keys to after new_key\n        for k in keys:\n            # od[k] = od.pop(k) # can not call this directly in MIDict\n            v = getitem(od, k)\n            delitem(od, k)\n            setitem(od, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreordering the keys in an OrderedDict od in - place.", "response": "def od_reorder_keys(od, keys_in_new_order): # not used\n    '''\n    Reorder the keys in an OrderedDict ``od`` in-place.\n    '''\n    if set(od.keys()) != set(keys_in_new_order):\n        raise KeyError('Keys in the new order do not match existing keys')\n    for key in keys_in_new_order:\n        od[key] = od.pop(key)\n    return od"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nseparate __setitem__ function of MIMapping", "response": "def _MI_setitem(self, args, value):\n    'Separate __setitem__ function of MIMapping'\n    indices = self.indices\n    N = len(indices)\n    empty = N == 0\n    if empty: # init the dict\n        index1, key, index2, index1_last = MI_parse_args(self, args, allow_new=True)\n        exist_names = [index1]\n        item = [key]\n        try:\n            MI_check_index_name(index2)\n            exist_names.append(index2)\n            item.append(value)\n        except TypeError:\n            Nvalue, value = get_value_len(value)\n            if len(index2) != Nvalue:\n                raise ValueError(\n                    'Number of keys (%s) based on argument %s does not match '\n                    'number of values (%s)' % (len(index2), index2, Nvalue))\n            exist_names.extend(index2)\n            item.extend(value)\n        if index1_last:\n            exist_names = exist_names[1:] + exist_names[:1]\n            item = item[1:] + item[:1]\n\n        _MI_init(self, [item], exist_names)\n        return\n\n    index1, key, index2, item, old_value = MI_parse_args(self, args, allow_new=True)\n    names = force_list(indices.keys())\n    is_new_key = item is None\n    single = isinstance(index2, int)\n\n    if single:\n        index2_list = [index2]\n        value = [value]\n        old_value = [old_value]\n    else:\n        index2_list = index2\n        Nvalue, value = get_value_len(value)\n        if len(index2_list) != Nvalue:\n            raise ValueError('Number of keys (%s) based on argument %s does not match '\n                             'number of values (%s)' % (len(index2_list), index2, Nvalue))\n        if is_new_key:\n            old_value = [None] * Nvalue  # fake it\n\n    # remove duplicate in index2_list\n    index2_d = OrderedDict()\n    for e, index in enumerate(index2_list):\n        index2_d[index] = e # order of each unique index\n    if len(index2_d) < len(index2_list): # exist duplicate indices\n        idx = index2_d.values()\n        index2_list = mget_list(index2_list, idx)\n        value = mget_list(value, idx)\n        old_value = mget_list(old_value, idx)\n\n    # check duplicate values\n    for i, v, old_v in zip(index2_list, value, old_value):\n        # index2_list may contain index1; not allow duplicate value for index1 either\n        if v in indices[i]:\n            if is_new_key or v != old_v:\n                raise ValueExistsError(v, i, names[i])\n\n    if is_new_key:\n        if set(index2_list + [index1]) != set(range(N)):\n            raise ValueError('Indices of the new item do not match existing indices')\n\n        d = {}\n        d[index1] = key\n        # index2_list may also override index1\n        d.update(zip(index2_list, value))\n        values = [d[i] for i in range(N)]  # reorder based on the indices\n        key = values[0]\n        val = values[1] if len(values) == 2 else values[1:]\n        super(MIMapping, self).__setitem__(key, val)\n        for i, v in zip(names[1:], values[1:]):\n            indices[i][v] = key\n\n    else: # not new key\n#        import pdb;pdb.set_trace()\n        key1 = item[0]\n        item2 = list(item)  # copy item first\n        mset_list(item2, index2_list, value) # index2_list may also override index1\n        key2 = item2[0]\n        val = item2[1] if len(item2) == 2 else item2[1:]\n        if key1 == key2:\n            super(MIMapping, self).__setitem__(key1, val)\n        else:\n            od_replace_key(self, key1, key2, val)\n\n        for i, v_old, v_new in zip(names[1:], item[1:], item2[1:]):\n            od_replace_key(indices[i], v_old, v_new, key2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _MI_init(self, *args, **kw):\n    '''\n    Separate __init__ function of MIMapping\n    '''\n\n    items, names = [], None\n\n    n_args = len(args)\n\n    if n_args >= 1:\n        items = args[0]\n\n        if isinstance(items, Mapping):  # copy from dict\n            if isinstance(items, MIMapping):\n                names = force_list(items.indices.keys())  # names may be overwritten by second arg\n            items = force_list(items.items())\n        else:  # try to get data from items() or keys() method\n            if hasattr(items, 'items'):\n                try:\n                    items = force_list(items.items())\n                except TypeError:  # items() may be not callalbe\n                    pass\n            else:\n                items = cvt_iter(items)\n\n    if n_args >= 2:\n        names = args[1] # may be None\n        names = cvt_iter(names)\n\n    if n_args >= 3:\n        raise TypeError('At most 2 positional arguments allowed (%s given)' % n_args)\n\n    if items:  # check item length\n        n_index = len(items[0])\n        for item in items[1:]:\n            if len(item) != n_index:\n                raise ValueError('Length of all items must equal')\n    else:\n        n_index = 0\n\n    if kw:\n        if n_index == 0:\n            n_index = 2\n        else:\n            if n_index != 2:\n                raise ValueError('Number of indices must be 2 (got %s) '\n                                 'when keyword arguments are used' % n_index)\n        items.extend(kw.items())\n\n    if n_index > 0:\n        if names is not None:\n            if len(names) != n_index:\n                raise ValueError('Length of names (%s) does not match '\n                                 'length of items (%s)' % (len(names), n_index))\n\n    if names is None:  # generate default names\n        names = ['index_%s' % (i+1) for i in range(n_index)] # starts from index_1\n    else:\n        map(MI_check_index_name, names)\n\n    self.indices = d = IdxOrdDict() # the internal dict\n    for index in names:\n        if index in d:\n            raise ValueError('Duplicate index name: %s in %s' % (index, names))\n        d[index] = AttrOrdDict()\n\n    if n_index > 0:\n        d[0] = self\n        for item in items:\n            primary_key = item[0]\n            if n_index == 1:\n                value = primary_key\n            elif n_index == 2:\n                value = item[1]\n            else:\n                value = list(item[1:]) # copy\n            # will handle duplicate\n            _MI_setitem(self, primary_key, value)", "response": "Separate __init__ function of MIMapping\nWorkItem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef MI_method_PY3(cls):\n    '''class decorator to change MIMapping method names for PY3 compatibility'''\n\n    nmspc = cls.__dict__.copy()\n    for m in ['__cmp__', 'has_key']:\n        nmspc.pop(m)\n    methods = ['keys', 'values', 'items']\n    for m in methods:\n        nmspc[m] = nmspc.pop('view' + m)\n    return type(cls)(cls.__name__, cls.__bases__, nmspc)", "response": "class decorator to change MIMapping method names for PY3 compatibility"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fromkeys(cls, keys, value=None, names=None):\n        '''\n        Create a new dictionary with keys from ``keys`` and values set to ``value``.\n\n        fromkeys() is a class method that returns a new dictionary. ``value`` defaults to None.\n\n        Length of ``keys`` must not exceed one because no duplicate values are allowed.\n\n        Optional ``names`` can be provided for index names (of length 2).\n        '''\n        N = len(keys)\n        if N > 1:\n            raise ValueError('Length of keys (%s) must not exceed one because '\n                             'no duplicate values are allowed' % (N,))\n        items = [[keys[0], value]] if N == 1 else []\n        return cls(items, names)", "response": "Create a new dictionary with keys from keys and values set to value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef itervalues(self, index=None):\n        '''\n        Iterate through values in the ``index`` (defaults to all indices\n        except the first index).\n\n        When ``index is None``, yielded values depend on the length of indices (``N``):\n\n            * if N <= 1: return\n            * if N == 2: yield values in the 2nd index\n            * if N > 2: yield values in all indices except the first index\n              (each value is a list of ``N-1`` elements)\n        '''\n        N = len(self.indices)\n\n        if index is None:\n            if N <= 1:\n                return\n            elif N == 2:\n                index = 1\n                single = True\n            else:\n                index = slice(1, None)\n                single = False\n        else:\n            index, single = convert_key_to_index(force_list(self.indices.keys()), index)\n\n        multi = not single\n\n        for key in self:\n            item = MI_get_item(self, key)\n            value = mget_list(item, index)\n            if multi:\n                value = tuple(value)  # convert list to tuple\n            yield value", "response": "Yield all the values in the specified index."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate through items in the indices ( defaults to all indices )", "response": "def iteritems(self, indices=None):\n        'Iterate through items in the ``indices`` (defaults to all indices)'\n        if indices is None:\n            indices = force_list(self.indices.keys())\n        for x in self.itervalues(indices):\n            yield x"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef todict(self, dict_type=dict, index_key=0, index_value=-1):\n        '''convert to a specific type of dict using ``index_key`` as keys\n        and ``index_value`` as values (discarding index names)'''\n        if len(self):\n            return dict_type(self.items([index_key, index_value]))\n        else:  # empty\n            return dict_type()", "response": "convert to a specific type of dict using index_key and index_value as values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self, clear_indices=False):\n        'Remove all items. index names are removed if ``clear_indices==True``.'\n        super(MIMapping, self).clear()\n        if clear_indices:\n            self.indices.clear()\n        else:\n            for index_d in self.indices[1:]:\n                index_d.clear()", "response": "Remove all items. index names are removed if clear_indices == True."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, *args, **kw):\n        '''\n        Update the dictionary with items and names::\n\n            (items, names, **kw)\n            (dict, names, **kw)\n            (MIDict, names, **kw)\n\n        Optional positional argument ``names`` is only allowed when ``self.indices``\n        is empty (no indices are set yet).\n        '''\n        if len(args) > 1 and self.indices:\n            raise ValueError('Only one positional argument is allowed when the'\n                             'index names are already set.')\n\n        if not self.indices:  # empty; init again\n            _MI_init(self, *args, **kw)\n            return\n\n        d = MIMapping(*args, **kw)\n        if not d.indices:\n            return\n\n        names = force_list(self.indices.keys())\n\n        if len(d.indices) != len(names):\n            raise ValueError('Length of update items (%s) does not match '\n                             'length of original items (%s)' %\n                             (len(d.indices), len(names)))\n\n        for key in d:\n            # use __setitem__() to handle duplicate\n            self[key] = d[key]", "response": "Update the dictionary with items and names and indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the index name of the entry.", "response": "def rename_index(self, *args):\n        '''change the index name(s).\n\n        * call with one argument:\n            1. list of new index names (to replace all old names)\n\n        * call with two arguments:\n            1. old index name(s) (or index/indices)\n            2. new index name(s)\n        '''\n        if len(args) == 1:\n            new_indices = args[0]\n            old_indices =force_list(self.indices.keys())\n        else:\n            old_indices, new_indices = args\n            old_indices, single = convert_index_to_keys(self.indices, old_indices)\n            if single:\n                old_indices, new_indices = [old_indices], [new_indices]\n\n        if len(new_indices) != len(old_indices):\n            raise ValueError('Length of update indices (%s) does not match '\n                             'existing indices (%s)' %\n                             (len(new_indices), len(old_indices)))\n\n        map(MI_check_index_name, new_indices)\n\n        if len(new_indices) != len(set(new_indices)):\n            raise ValueError('New indices names are not unique: %s' % (new_indices,))\n\n        od_replace_key(self.indices, old_indices, new_indices, multi=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reorder_indices(self, indices_order):\n        'reorder all the indices'\n        # allow mixed index syntax like int\n        indices_order, single = convert_index_to_keys(self.indices, indices_order)\n        old_indices = force_list(self.indices.keys())\n\n        if indices_order == old_indices: # no changes\n            return\n\n        if set(old_indices) != set(indices_order):\n            raise KeyError('Keys in the new order do not match existing keys')\n\n#        if len(old_indices) == 0: # already return since indices_order must equal to old_indices\n#            return\n\n        # must have more than 1 index to reorder\n        new_idx = [old_indices.index(i) for i in indices_order]\n        # reorder items\n        items = [map(i.__getitem__, new_idx) for i in self.items()]\n        self.clear(True)\n        _MI_init(self, items, indices_order)", "response": "reorder all the indices"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_index(self, values, name=None):\n        'add an index of ``name`` with the list of ``values``'\n        if len(values) != len(set(values)):\n            raise ValueError('Values in the new index are not unique')\n\n        d = self.indices\n        if len(values) != len(self) and len(values) and d:\n            raise ValueError('Length of values in added index (%s) does not match '\n                             'length of existing items (%s)' % (len(values), len(self)))\n\n        if name is None:\n            name = 'index_' + str(len(d)+1)\n            name = get_unique_name(name, d)\n        else:\n            MI_check_index_name(name)\n            if name in d:\n                raise ValueError('Duplicate index name: %s' % (name,))\n\n        if len(d) == 0:\n            items = [(v,) for v in values]\n        else:\n            items = [i+(v,) for i, v in zip(self.items(), values)]\n\n        names = force_list(d.keys()) + [name]\n\n        self.clear(True)\n        _MI_init(self, items, names)", "response": "add an index of name with the list of values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_index(self, index):\n        'remove one or more indices'\n        index_rm, single = convert_key_to_index(force_list(self.indices.keys()), index)\n        if single:\n            index_rm = [index_rm]\n\n        index_new = [i for i in range(len(self.indices)) if i not in index_rm]\n\n        if not index_new: # no index left\n            self.clear(True)\n            return\n\n        names = mget_list(force_list(self.indices.keys()), index_new)\n        items = [mget_list(i, index_new) for i in self.items()]\n        self.clear(True)\n        _MI_init(self, items, names)", "response": "remove one or more indices"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exit(exit_code=0):\n\n    LOGGER.debug(\"> {0} | Exiting current process!\".format(__name__))\n\n    LOGGER.debug(\"> Stopping logging handlers and logger!\")\n    for handler in LOGGER.handlers:\n        foundations.verbose.remove_logging_handler(handler)\n\n    sys.exit(exit_code)", "response": "Shuts down current process logging associated handlers and exits to system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for the current process exection for a user defined time.", "response": "def wait(wait_time):\n    \"\"\"\n    Halts current process exection for an user defined time.\n\n    :param wait_time: Current sleep time in seconds.\n    :type wait_time: float\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    LOGGER.debug(\"> Waiting '{0}' seconds!\".format(wait_time))\n\n    time.sleep(wait_time)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_server_app(provider, password=None, cache=True, cache_timeout=3600,\n                      debug=False):\n    \"\"\"\n    Create a DAAP server, based around a Flask application. The server requires\n    a content provider, server name and optionally, a password. The content\n    provider should return raw object data.\n\n    Object responses can be cached. This may dramatically speed up connections\n    for multiple clients. However, this is only limited to objects, not file\n    servings.\n\n    Note: in case the server is mounted as a WSGI app, make sure the server\n    passes the authorization header.\n    \"\"\"\n\n    # Create Flask App\n    app = Flask(__name__, static_folder=None)\n    app.debug = debug\n\n    # Setup cache\n    if cache:\n        if type(cache) == bool:\n            cache = SimpleCache()\n        else:\n            # Assume is a user-provided cache with a get-set method.\n            pass\n    else:\n        cache = False\n\n    #\n    # Context-aware helpers and decorators\n    #\n\n    def daap_wsgi_app(func):\n        \"\"\"\n        WSGI middleware which will modify the environment and strip 'daap://'\n        from the path. This way, Flask can route the request properly.\n        \"\"\"\n\n        @wraps(func)\n        def _inner(environment, start_response):\n            if environment[\"PATH_INFO\"].startswith(\"daap://\") or \\\n                    environment[\"PATH_INFO\"].startswith(\"http://\"):\n                environment[\"PATH_INFO\"] = \"/\" + \\\n                    environment[\"PATH_INFO\"].split(\"/\", 3)[3]\n            return func(environment, start_response)\n        return _inner\n    app.wsgi_app = daap_wsgi_app(app.wsgi_app)\n\n    def daap_trace(func):\n        \"\"\"\n        Utility method for tracing function calls. Helps debugging malicious\n        requests (e.g. protocol changes). Is only enabled when `debug` is True.\n        Normally, exceptions are caught by Flask and handled as Bad Requests.\n        Any debugging is therefore lost.\n        \"\"\"\n\n        # Do not apply when debug is False.\n        if not debug:\n            return func\n\n        @wraps(func)\n        def _inner(*args, **kwargs):\n            try:\n                start = time.time()\n                result = func(*args, **kwargs)\n                logger.debug(\n                    \"Request handling took %.6f seconds\",\n                    time.time() - start)\n\n                return result\n            except:\n                logger.exception(\n                    \"Caught exception before raising it to Flask.\")\n                raise\n\n        return _inner\n\n    def daap_unpack_args(func):\n        \"\"\"\n        Strip query string arguments and add them to the method as keyword\n        arguments. Since the query string keys are defined, values will be\n        converted to their approriate format. An exception will be thrown in\n        case a requested argument is not available, or if the value could not\n        be converted.\n        \"\"\"\n\n        # Create a function specific mapping, only for arguments appearing in\n        # the function declaration.\n        args, _, _, _ = inspect.getargspec(func)\n        mappings = [mapping for mapping in QS_MAPPING if mapping[1] in args]\n\n        @wraps(func)\n        def _inner(*args, **kwargs):\n            for key, kwarg, casting in mappings:\n                kwargs[kwarg] = casting(request.args[key])\n            return func(*args, **kwargs)\n        return _inner\n\n    def daap_authenticate(func):\n        \"\"\"\n        Check authorization header, if authorization is given. Returns 401\n        response if the authentication failed.\n        \"\"\"\n\n        # Do not apply when no password is set\n        if not password:\n            return func\n\n        @wraps(func)\n        def _inner(*args, **kwargs):\n            auth = request.authorization\n\n            if not auth or not auth.password == password:\n                return Response(None, 401, {\n                    \"WWW-Authenticate\": \"Basic realm=\\\"%s\\\"\" %\n                    provider.server.name})\n            return func(*args, **kwargs)\n        return _inner\n    app.authenticate = daap_authenticate\n\n    def daap_cache_response(func):\n        \"\"\"\n        Cache object responses if the cache has been initialized. The cache key\n        is based on the request path and the semi-constant request arguments.\n        The response is caches for as long as possible, which should not be a\n        problem if the cache is cleared if the provider has new data.\n        \"\"\"\n\n        # Do not apply when cache is False.\n        if not cache:\n            return func\n\n        @wraps(func)\n        def _inner(*args, **kwargs):\n            # Create hash key via hashlib. We use MD5 since it is slightly\n            # faster than SHA1. Note that we don't require cryptographically\n            # strong hashes -- we just want to have a short and computationally\n            # unique key.\n            key = hashlib.md5()\n\n            # Add basic info\n            key.update(func.__name__)\n            key.update(request.path)\n\n            for k, v in request.args.iteritems():\n                if k not in QS_IGNORE_CACHE:\n                    key.update(v)\n\n            # Hit the cache\n            key = key.digest()\n            value = cache.get(key)\n\n            if value is None:\n                value = func(*args, **kwargs)\n                cache.set(key, value, timeout=cache_timeout)\n            elif debug:\n                logger.debug(\"Loaded response from cache.\")\n            return value\n        return _inner\n\n    #\n    # Request handlers\n    #\n\n    @app.after_request\n    def after_request(response):\n        \"\"\"\n        Append default response headers, independent of the return type.\n        \"\"\"\n\n        response.headers[\"DAAP-Server\"] = provider.server.name\n        response.headers[\"Content-Language\"] = \"en_us\"\n        response.headers[\"Accept-Ranges\"] = \"bytes\"\n\n        return response\n\n    @app.route(\"/server-info\", methods=[\"GET\"])\n    @daap_trace\n    @daap_cache_response\n    def server_info():\n        \"\"\"\n        \"\"\"\n\n        data = responses.server_info(provider, provider.server.name, password)\n\n        return ObjectResponse(data)\n\n    @app.route(\"/content-codes\", methods=[\"GET\"])\n    @daap_trace\n    @daap_cache_response\n    def content_codes():\n        \"\"\"\n        \"\"\"\n\n        data = responses.content_codes(provider)\n\n        return ObjectResponse(data)\n\n    @app.route(\"/login\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    def login():\n        \"\"\"\n        \"\"\"\n\n        session_id = provider.create_session(\n            user_agent=request.headers.get(\"User-Agent\"),\n            remote_address=request.remote_addr,\n            client_version=request.headers.get(\n                \"Client-DAAP-Version\"))\n        data = responses.login(provider, session_id)\n\n        return ObjectResponse(data)\n\n    @app.route(\"/logout\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_unpack_args\n    def logout(session_id):\n        \"\"\"\n        \"\"\"\n\n        provider.destroy_session(session_id)\n\n        return Response(None, status=204)\n\n    @app.route(\"/activity\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_unpack_args\n    def activity(session_id):\n        \"\"\"\n        \"\"\"\n\n        return Response(None, status=200)\n\n    @app.route(\"/update\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_unpack_args\n    def update(session_id, revision, delta):\n        \"\"\"\n        \"\"\"\n\n        revision = provider.get_next_revision(session_id, revision, delta)\n\n        data = responses.update(provider, revision)\n\n        return ObjectResponse(data)\n\n    @app.route(\"/fp-setup\", methods=[\"POST\"])\n    @daap_trace\n    @daap_authenticate\n    def fp_setup():\n        \"\"\"\n        Fairplay validation, as sent by iTunes 11+. It will be unlikely this\n        will be ever implemented.\n        \"\"\"\n\n        raise NotImplementedError(\"Fairplay not supported.\")\n\n    @app.route(\"/databases\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_cache_response\n    @daap_unpack_args\n    def databases(session_id, revision, delta):\n        \"\"\"\n        \"\"\"\n\n        new, old = provider.get_databases(session_id, revision, delta)\n        added, removed, is_update = utils.diff(new, old)\n\n        data = responses.databases(\n            provider, new, old, added, removed, is_update)\n\n        return ObjectResponse(data)\n\n    @app.route(\n        \"/databases/<int:database_id>/items/<int:item_id>/extra_data/artwork\",\n        methods=[\"GET\"])\n    @daap_trace\n    @daap_unpack_args\n    def database_item_artwork(database_id, item_id, session_id):\n        \"\"\"\n        \"\"\"\n\n        data, mimetype, total_length = provider.get_artwork(\n            session_id, database_id, item_id)\n\n        # Setup response\n        response = Response(\n            data, 200, mimetype=mimetype,\n            direct_passthrough=not isinstance(data, basestring))\n\n        if total_length:\n            response.headers[\"Content-Length\"] = total_length\n\n        return response\n\n    @app.route(\n        \"/databases/<int:database_id>/groups/<int:group_id>/extra_data/\"\n        \"artwork\", methods=[\"GET\"])\n    @daap_trace\n    @daap_unpack_args\n    def database_group_artwork(database_id, group_id, session_id, revision,\n                               delta):\n        \"\"\"\n        \"\"\"\n        raise NotImplemented(\"Groups not supported.\")\n\n    @app.route(\n        \"/databases/<int:database_id>/items/<int:item_id>.<suffix>\",\n        methods=[\"GET\"])\n    @daap_trace\n    @daap_unpack_args\n    def database_item(database_id, item_id, suffix, session_id):\n        \"\"\"\n        \"\"\"\n\n        range_header = request.headers.get(\"Range\", None)\n\n        if range_header:\n            begin, end = http.parse_range_header(range_header).ranges[0]\n            data, mimetype, total_length = provider.get_item(\n                session_id, database_id, item_id, byte_range=(begin, end))\n            begin, end = (begin or 0), (end or total_length)\n\n            # Setup response\n            response = Response(\n                data, 206, mimetype=mimetype,\n                direct_passthrough=not isinstance(data, basestring))\n\n            # A streaming response with unknown content lenght, Range x-*\n            # as per RFC2616 section 14.16\n            if total_length <= 0:\n                response.headers[\"Content-Range\"] = \"bytes %d-%d/*\" % (\n                    begin, end - 1)\n            elif total_length > 0:\n                response.headers[\"Content-Range\"] = \"bytes %d-%d/%d\" % (\n                    begin, end - 1, total_length)\n                response.headers[\"Content-Length\"] = end - begin\n        else:\n            data, mimetype, total_length = provider.get_item(\n                session_id, database_id, item_id)\n\n            # Setup response\n            response = Response(\n                data, 200, mimetype=mimetype,\n                direct_passthrough=not isinstance(data, basestring))\n\n            if total_length > 0:\n                response.headers[\"Content-Length\"] = total_length\n\n        return response\n\n    @app.route(\"/databases/<int:database_id>/items\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_cache_response\n    @daap_unpack_args\n    def database_items(database_id, session_id, revision, delta, type):\n        \"\"\"\n        \"\"\"\n\n        new, old = provider.get_items(session_id, database_id, revision, delta)\n        added, removed, is_update = utils.diff(new, old)\n\n        data = responses.items(provider, new, old, added, removed, is_update)\n\n        return ObjectResponse(data)\n\n    @app.route(\"/databases/<int:database_id>/containers\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_cache_response\n    @daap_unpack_args\n    def database_containers(database_id, session_id, revision, delta):\n        \"\"\"\n        \"\"\"\n\n        new, old = provider.get_containers(\n            session_id, database_id, revision, delta)\n        added, removed, is_update = utils.diff(new, old)\n\n        data = responses.containers(\n            provider, new, old, added, removed, is_update)\n\n        return ObjectResponse(data)\n\n    @app.route(\"/databases/<int:database_id>/groups\", methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_cache_response\n    @daap_unpack_args\n    def database_groups(database_id, session_id, revision, delta, type):\n        \"\"\"\n        \"\"\"\n        raise NotImplementedError(\"Groups not supported.\")\n\n    @app.route(\n        \"/databases/<int:database_id>/containers/<int:container_id>/items\",\n        methods=[\"GET\"])\n    @daap_trace\n    @daap_authenticate\n    @daap_cache_response\n    @daap_unpack_args\n    def database_container_item(database_id, container_id, session_id,\n                                revision, delta):\n        \"\"\"\n        \"\"\"\n\n        new, old = provider.get_container_items(\n            session_id, database_id, container_id, revision, delta)\n        added, removed, is_update = utils.diff(new, old)\n\n        data = responses.container_items(\n            provider, new, old, added, removed, is_update)\n\n        return ObjectResponse(data)\n\n    # Return the app\n    return app", "response": "Create a DAAP server based around a Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncause run to be executed in a newly spawned daemon process", "response": "def spawn_daemon(fork=None, pgrpfile=None, outfile='out.txt'):\n    'causes run to be executed in a newly spawned daemon process'\n    global LAST_PGRP_PATH\n    fork = fork or os.fork\n    open(outfile, 'a').close()  # TODO: configurable output file\n    if pgrpfile and os.path.exists(pgrpfile):\n        try:\n            cur_pid = int(open(pgrpfile).read().rstrip(\"\\n\"))\n            os.killpg(cur_pid, 0)\n            raise Exception(\"arbiter still running with pid:\" + str(cur_pid))\n        except (OSError, ValueError):\n            pass\n    if fork():  # return True means we are in parent\n        return True\n    else:\n        os.setsid()  # break association with terminal via new session id\n        if fork():  # fork one more layer to ensure child will not re-acquire terminal\n            os._exit(0)\n        LAST_PGRP_PATH = pgrpfile\n        if pgrpfile:\n            with open(pgrpfile, 'w') as f:\n                f.write(str(os.getpgrp()) + \"\\n\")\n        logging.root.addHandler(SysLogHandler())\n        rotating_out = RotatingStdoutFile(outfile)\n        rotating_out.start()\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wsgiref_thread_arbiter(wsgi, host, port):\n    'probably not suitable for production use; example of threaded server'\n    import wsgiref.simple_server\n    httpd = wsgiref.simple_server.make_server(host, port, wsgi)\n    httpd.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n    def start_server():\n        server_thread = threading.Thread(target=httpd.serve_forever)\n        server_thread.daemon = True\n        server_thread.start()\n\n    def close_socket():\n        httpd.socket.close()\n\n    arbiter = Arbiter(post_fork=start_server, child_pre_exit=httpd.shutdown,\n                      parent_pre_stop=close_socket)\n    return arbiter", "response": "probably not suitable for production use ; example of threaded server"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncauses run to be executed in a thread", "response": "def spawn_thread(self):\n        'causes run to be executed in a thread'\n        self.thread = threading.Thread(target=self.run, args=(False,))\n        self.thread.daemon = True\n        self.thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spawn_daemon(self, pgrpfile=None, outfile=\"out.txt\"):\n        '''\n        Causes this arbiters run() function to be executed in a newly spawned\n        daemon process.\n\n        Parameters\n        ----------\n        pgrpfile : str, optional\n            Path at which to write a pgrpfile (file containing the process\n            group id of the daemon process and its children).\n        outfile : str, optional\n            Path to text file to write stdout and stderr of workers to.\n            (Daemonized arbiter process no longer has a stdout to write\n            to.)  Defaults to \"out.txt\".\n        '''\n        if spawn_daemon(self.fork, pgrpfile, outfile):\n            return\n        signal.signal(signal.SIGTERM, lambda signal, frame: self.stop())\n        self.run(False)", "response": "Spawns a daemon process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ensure_pgrp(self):\n        if not LAST_PGRP_PATH:  # global\n            return\n        try:\n            with open(LAST_PGRP_PATH, 'w') as f:\n                f.write(str(os.getpgrp()) + \"\\n\")\n        except IOError:\n            # raised if no permissions or disk space\n            pass", "response": "Ensures that the pgrp file is present and up to date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setY(self,Y,standardize=False):\n        assert Y.shape[0]==self.N, 'CVarianceDecomposition:: Incompatible shape'\n        assert Y.shape[1]==self.P, 'CVarianceDecomposition:: Incompatible shape'\n\n        \n        if standardize:\n            Y=preprocess.standardize(Y)\n\n        #check that missing values match the current structure\n        assert (~(SP.isnan(Y).any(axis=1))==self.Iok).all(), 'CVarianceDecomposition:: pattern of missing values needs to match Y given at initialization'\n\n        self.Y = Y\n        self.vd.setPheno(Y)\n\n        self.optimum = None\n    \n        self.cache['Sigma']   = None\n        self.cache['Hessian'] = None\n        self.cache['Lparams'] = None\n        self.cache['paramsST']= None", "response": "Set the phenotype matrix Y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addRandomEffect(self,K=None,covar_type='freeform',is_noise=False,normalize=True,Ks=None,offset=1e-4,rank=1,covar_K0=None):\n        if self.P==1:\tself.addSingleTraitTerm(K=K,is_noise=is_noise,normalize=normalize,Ks=Ks)\n        else:\t\t\tself.addMultiTraitTerm(K=K,covar_type=covar_type,is_noise=is_noise,normalize=normalize,Ks=Ks,offset=offset,rank=rank,covar_K0=covar_K0)", "response": "Add random effect term to the current TermDaemon."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a single trait term for single trait models", "response": "def addSingleTraitTerm(self,K=None,is_noise=False,normalize=True,Ks=None):\n        \"\"\"\n        add random effects term for single trait models (no trait-trait covariance matrix)\n        \n        Args:\n            K:          NxN sample covariance matrix\n            is_noise:\tbool labeling the noise term (noise term has K=eye)\n            normalize:\tif True, K and Ks are scales such that K.diagonal().mean()==1\n            Ks:\t\t\tNxN test cross covariance for predictions\n        \"\"\"\n        \n        assert self.P == 1, 'Incompatible number of traits'\n        \n        assert K!=None or is_noise, 'Specify covariance structure'\n        \n        if is_noise:\n            assert self.noisPos==None, 'noise term already exists'\n            K = SP.eye(self.Nt)\n            self.noisPos = self.n_terms\n        else:\n            assert K.shape[0]==self.Nt, 'Incompatible shape'\n            assert K.shape[1]==self.Nt, 'Incompatible shape'\n    \n        if Ks!=None:\n            assert Ks.shape[0]==self.N, 'Incompatible shape'\n\n        if normalize:\n            Norm = 1/K.diagonal().mean()\n            K *= Norm\n            if Ks!=None: Ks *= Norm\n\n        self.vd.addTerm(limix.CSingleTraitTerm(K))\n        if Ks!=None: self.setKstar(self.n_terms,Ks)\n        self.n_terms+=1\n    \n        self.gp         = None\n        self.init       = False\n        self.fast       = False\n        self.optimum    = None\n\n        self.cache['Sigma']   = None\n        self.cache['Hessian'] = None\n        self.cache['Lparams'] = None\n        self.cache['paramsST']= None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addMultiTraitTerm(self,K=None,covar_type='freeform',is_noise=False,normalize=True,Ks=None,offset=1e-4,rank=1,covar_K0=None):\n        assert self.P > 1, 'CVarianceDecomposition:: Incompatible number of traits'\n        assert K!=None or is_noise, 'CVarianceDecomposition:: Specify covariance structure'\n        assert offset>=0, 'CVarianceDecomposition:: offset must be >=0'\n\n        #TODO: check that covar_K0 is correct if fixed typeCF is used..\n\n        if is_noise:\n            assert self.noisPos==None, 'CVarianceDecomposition:: noise term already exists'\n            K = SP.eye(self.N)\n            self.noisPos = self.n_terms\n        else:\n            assert K.shape[0]==self.N, 'CVarianceDecomposition:: Incompatible shape'\n            assert K.shape[1]==self.N, 'CVarianceDecomposition:: Incompatible shape'\n\n        if Ks!=None:\n            assert Ks.shape[0]==self.N, 'CVarianceDecomposition:: Incompatible shape'\n\n        if normalize:\n            Norm = 1/K.diagonal().mean()\n            K *= Norm\n            if Ks!=None: Ks *= Norm\n\n        cov = limix.CSumCF()\n        if covar_type=='freeform':\n            cov.addCovariance(limix.CFreeFormCF(self.P))\n            L = SP.eye(self.P)\n            diag = SP.concatenate([L[i,:(i+1)] for i in range(self.P)])\n        elif covar_type=='fixed':\n            cov.addCovariance(limix.CFixedCF(covar_K0))\n            diag = SP.zeros(1)\n        elif covar_type=='diag':\n            cov.addCovariance(limix.CDiagonalCF(self.P))\n            diag = SP.ones(self.P)\n        elif covar_type=='lowrank':\n            cov.addCovariance(limix.CLowRankCF(self.P,rank))\n            diag = SP.zeros(self.P*rank)\n        elif covar_type=='lowrank_id':\n            cov.addCovariance(limix.CLowRankCF(self.P,rank))\n            cov.addCovariance(limix.CFixedCF(SP.eye(self.P)))\n            diag = SP.concatenate([SP.zeros(self.P*rank),SP.ones(1)])\n        elif covar_type=='lowrank_diag':\n            cov.addCovariance(limix.CLowRankCF(self.P,rank))\n            cov.addCovariance(limix.CDiagonalCF(self.P))\n            diag = SP.concatenate([SP.zeros(self.P*rank),SP.ones(self.P)])\n        elif covar_type=='block':\n            cov.addCovariance(limix.CFixedCF(SP.ones((self.P,self.P))))\n            diag = SP.zeros(1)\n        elif covar_type=='block_id':\n            cov.addCovariance(limix.CFixedCF(SP.ones((self.P,self.P))))\n            cov.addCovariance(limix.CFixedCF(SP.eye(self.P)))\n            diag = SP.concatenate([SP.zeros(1),SP.ones(1)])\n        elif covar_type=='block_diag':\n            cov.addCovariance(limix.CFixedCF(SP.ones((self.P,self.P))))\n            cov.addCovariance(limix.CDiagonalCF(self.P))\n            diag = SP.concatenate([SP.zeros(1),SP.ones(self.P)])\n        else:\n            assert True==False, 'CVarianceDecomposition:: covar_type not valid'\n\n        if offset>0:\n            _cov = limix.CFixedCF(SP.eye(self.P))\n            _cov.setParams(SP.array([SP.sqrt(offset)]))\n            _cov.setParamMask(SP.zeros(1))\n            cov.addCovariance(_cov)\n        self.offset.append(offset)\n\n        self.covar_type.append(covar_type)\n        self.diag.append(diag)\n\n        self.vd.addTerm(cov,K)\n        if Ks!=None: self.setKstar(self.n_terms,Ks)\n        self.n_terms+=1\n\n        self.gp      = None\n        self.init    = False\n        self.fast    = False\n        self.optimum = None\n\n        self.cache['Sigma']   = None\n        self.cache['Hessian'] = None\n        self.cache['Lparams'] = None\n        self.cache['paramsST']= None", "response": "This function adds a multi - trait random effects term to the current term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addFixedEffect(self,F=None,A=None):\n        if A==None:\n            A = SP.eye(self.P)\n        if F==None:\n            F = SP.ones((self.N,1))\n        \n        assert A.shape[1]==self.P, 'Incompatible shape'\n        assert F.shape[0]==self.N, 'Incompatible shape'\n       \n        if F.shape[1]>1:\n            for m in range(F.shape[1]):\n                self.vd.addFixedEffTerm(A,F[:,m:m+1])\n        else:\n            self.vd.addFixedEffTerm(A,F)\n\n        #TODO: what is this gp object doing, is this initialization correct?\n        self.gp      = None\n        self.init    = False\n        self.fast    = False\n        self.optimum = None\n\n        self.cache['Sigma']   = None\n        self.cache['Hessian'] = None\n        self.cache['Lparams'] = None\n        self.cache['paramsST']= None", "response": "add fixed effect to the model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initGP(self,fast=False):\n        if fast:\n            assert self.n_terms==2, 'CVarianceDecomposition: for fast inference number of terms must be == 2'\n            assert self.P>1,        'CVarianceDecomposition: for fast inference number of traits must be > 1'\n            self.vd.initGPkronSum()\n        else:\n            self.vd.initGP()\n        self.gp=self.vd.getGP()\n        self.init=True\n        self.fast=fast", "response": "Initialize the GP objetct\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the diagonal parameter for a single term model", "response": "def _getScalesDiag(self,termx=0):\n        \"\"\"\n        Uses 2 term single trait model to get covar params for initialization\n        \n        Args:\n            termx:      non-noise term terms that is used for initialization \n        \"\"\"\n        assert self.P>1, 'CVarianceDecomposition:: diagonal init_method allowed only for multi trait models' \n        assert self.noisPos!=None, 'CVarianceDecomposition:: noise term has to be set'\n        assert termx<self.n_terms-1, 'CVarianceDecomposition:: termx>=n_terms-1'\n        assert self.covar_type[self.noisPos] not in ['lowrank','block','fixed'], 'CVarianceDecimposition:: diagonal initializaiton not posible for such a parametrization'\n        assert self.covar_type[termx] not in ['lowrank','block','fixed'], 'CVarianceDecimposition:: diagonal initializaiton not posible for such a parametrization'\n        scales = []\n        res = self.estimateHeritabilities(self.vd.getTerm(termx).getK())\n        scaleg = SP.sqrt(res['varg'].mean())\n        scalen = SP.sqrt(res['varn'].mean())\n        for term_i in range(self.n_terms):\n            if term_i==termx:\n                _scales = scaleg*self.diag[term_i]\n            elif term_i==self.noisPos:\n                _scales = scalen*self.diag[term_i]\n            else:\n                _scales = 0.*self.diag[term_i]\n            if self.offset[term_i]>0:\n                _scales = SP.concatenate((_scales,SP.array([SP.sqrt(self.offset[term_i])])))\n            scales.append(_scales)\n        return SP.concatenate(scales)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getScalesRand(self):\n        if self.P>1:\n            scales = []\n            for term_i in range(self.n_terms):\n                _scales = SP.randn(self.diag[term_i].shape[0])\n                if self.offset[term_i]>0:\n                    _scales = SP.concatenate((_scales,SP.array([SP.sqrt(self.offset[term_i])])))\n                scales.append(_scales)\n            scales = SP.concatenate(scales)\n        else:\n            scales=SP.randn(self.vd.getNumberScales())\n\n        return scales", "response": "Return a vector of random scales"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns Gaussian perturbation of the current term.", "response": "def _perturbation(self):\n        \"\"\"\n        Returns Gaussian perturbation\n        \"\"\"\n        if self.P>1:\n            scales = []\n            for term_i in range(self.n_terms):\n                _scales = SP.randn(self.diag[term_i].shape[0])\n                if self.offset[term_i]>0:\n                    _scales  = SP.concatenate((_scales,SP.zeros(1)))\n                scales.append(_scales)\n            scales = SP.concatenate(scales)\n        else:\n            scales = SP.randn(self.vd.getNumberScales())\n        return scales"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrains the GMPE for the current object.", "response": "def trainGP(self,fast=False,scales0=None,fixed0=None,lambd=None):\n        \"\"\"\n        Train the gp\n       \n        Args:\n            fast:       if true and the gp has not been initialized, initializes a kronSum gp\n            scales0:\tinitial variance components params\n            fixed0:     initial fixed effect params\n        \"\"\"\n        assert self.n_terms>0, 'CVarianceDecomposition:: No variance component terms'\n\n        if not self.init:\t\tself.initGP(fast=fast)\n\n        # set lambda\n        if lambd!=None:\t\tself.gp.setLambda(lambd)\n\n        # set scales0\n        if scales0!=None:\n            self.setScales(scales0)\n        # init gp params\n        self.vd.initGPparams()\n        # set fixed0\n        if fixed0!=None:\n            params = self.gp.getParams()\n            params['dataTerm'] = fixed0\n            self.gp.setParams(params)\n\n        # LIMIX CVARIANCEDECOMPOSITION TRAINING\n        conv =self.vd.trainGP()\n        \n        self.cache['Sigma']   = None\n        self.cache['Hessian'] = None\n            \n        return conv"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrain the model using the specified initialization strategy Args: fast: if true, fast gp is initialized scales0: if not None init_method is set to manual fixed0: initial fixed effects init_method: initialization method \\in {random,diagonal,manual} termx: term for diagonal diagonalisation n_times: number of times the initialization perturb: if true, the initial point is perturbed with gaussian noise perturbSize: size of the perturbation verbose: print if convergence is achieved", "response": "def findLocalOptimum(self,fast=False,scales0=None,fixed0=None,init_method=None,termx=0,n_times=10,perturb=True,pertSize=1e-3,verbose=True,lambd=None):\n        \"\"\"\n        Train the model using the specified initialization strategy\n        \n        Args:\n            fast:\t\t    if true, fast gp is initialized\n            scales0:        if not None init_method is set to manual\n            fixed0:         initial fixed effects\n            init_method:    initialization method \\in {random,diagonal,manual} \n            termx:\t\t\tterm for diagonal diagonalisation\n            n_times:        number of times the initialization\n            perturb:        if true, the initial point is perturbed with gaussian noise\n            perturbSize:    size of the perturbation\n            verbose:        print if convergence is achieved\n        \"\"\"\n\n        if init_method==None:\n            if self.P==1:\tinit_method = 'random'\n            else:           init_method = 'diagonal'\n\n        if not self.init:\t\tself.initGP(fast=fast)\n\n        if scales0!=None and ~perturb: \tinit_method = 'manual'\n        \n        if init_method=='diagonal':\n            scales0 = self._getScalesDiag(termx=termx)\n            \n        if init_method=='diagonal' or init_method=='manual':\n            if not perturb:\t\tn_times = 1\n\n        if fixed0==None:\n            fixed0 = SP.zeros_like(self.gp.getParams()['dataTerm'])\n\n        for i in range(n_times):\n            if init_method=='random':\n                scales1 = self._getScalesRand()\n                fixed1  = pertSize*SP.randn(fixed0.shape[0],fixed0.shape[1])\n            elif perturb:\n                scales1 = scales0+pertSize*self._perturbation()\n                fixed1  = fixed0+pertSize*SP.randn(fixed0.shape[0],fixed0.shape[1])\n            else:\n                scales1 = scales0\n                fixed1  = fixed0\n            conv = self.trainGP(scales0=scales1,fixed0=fixed1,lambd=lambd)\n            if conv:    break\n    \n        if verbose:\n            if conv==False:\n                print('No local minimum found for the tested initialization points')\n            else:\n                print(('Local minimum found at iteration %d' % i))\n \n        return conv"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrain the model repeadly up to a number specified by the users with random restarts and return a list of all relative minima that have been found Args: fast: Boolean. if set to True initalize kronSumGP verbose: Boolean. If set to True, verbose output is produced. (default True) n_times: number of re-starts of the optimization. (default 10)", "response": "def findLocalOptima(self,fast=False,verbose=True,n_times=10,lambd=None):\n        \"\"\"\n        Train the model repeadly up to a number specified by the users with random restarts and\n        return a list of all relative minima that have been found \n        \n        Args:\n            fast:       Boolean. if set to True initalize kronSumGP\n            verbose:    Boolean. If set to True, verbose output is produced. (default True)\n            n_times:    number of re-starts of the optimization. (default 10)\n        \"\"\"\n        if not self.init:       self.initGP(fast)\n        \n        opt_list = []\n\n        fixed0 = SP.zeros_like(self.gp.getParams()['dataTerm'])    \n\n        # minimises n_times\n        for i in range(n_times):\n            \n            scales1 = self._getScalesRand()\n            fixed1  = 1e-1*SP.randn(fixed0.shape[0],fixed0.shape[1])\n            conv = self.trainGP(fast=fast,scales0=scales1,fixed0=fixed1,lambd=lambd)\n\n            if conv:\n                # compare with previous minima\n                temp=1\n                for j in range(len(opt_list)):\n                    if SP.allclose(abs(self.getScales()),abs(opt_list[j]['scales'])):\n                        temp=0\n                        opt_list[j]['counter']+=1\n                        break\n                if temp==1:\n                    opt = {}\n                    opt['counter'] = 1\n                    opt['LML'] = self.getLML()\n                    opt['scales'] = self.getScales()\n                    opt_list.append(opt)\n        \n        \n        # sort by LML\n        LML = SP.array([opt_list[i]['LML'] for i in range(len(opt_list))])\n        index   = LML.argsort()[::-1]\n        out = []\n        if verbose:\n            print(\"\\nLocal mimima\\n\")\n            print(\"n_times\\t\\tLML\")\n            print(\"------------------------------------\")\n            for i in range(len(opt_list)):\n                out.append(opt_list[index[i]])\n                if verbose:\n                    print((\"%d\\t\\t%f\" % (opt_list[index[i]]['counter'], opt_list[index[i]]['LML'])))\n                print(\"\")\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset scales to random variances based on the empirical trait variance", "response": "def setScales(self,scales=None,term_num=None):\n        \"\"\"\n        get random initialization of variances based on the empirical trait variance\n\n        Args:\n            scales:     if scales==None: set them randomly, \n                        else: set scales to term_num (if term_num==None: set to all terms)\n            term_num:   set scales to term_num\n        \"\"\"\n        if scales==None:\n            for term_i in range(self.n_terms):\n                n_scales = self.vd.getTerm(term_i).getNumberScales()\n                self.vd.getTerm(term_i).setScales(SP.array(SP.randn(n_scales)))\n        elif term_num==None:\n            assert scales.shape[0]==self.vd.getNumberScales(), 'incompatible shape'\n            index = 0\n            for term_i in range(self.n_terms):\n                index1 = index+self.vd.getTerm(term_i).getNumberScales()\n                self.vd.getTerm(term_i).setScales(scales[index:index1])\n                index = index1\n        else:\n            assert scales.shape[0]==self.vd.getTerm(term_num).getNumberScales(), 'incompatible shape'\n            self.vd.getTerm(term_num).setScales(scales)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getScales(self,term_i=None):\n        if term_i==None:\n            RV = self.vd.getScales()\n        else:\n            assert term_i<self.n_terms, 'Term index non valid'\n            RV = self.vd.getScales(term_i)\n        return RV", "response": "Returns the Parameters\niuhtype Returns the Parameters\niuhtype"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getEstTraitCovar(self,term_i=None):\n        assert self.P>1, 'Trait covars not defined for single trait analysis'\n        \n        if term_i==None:\n            RV=SP.zeros((self.P,self.P))\n            for term_i in range(self.n_terms): RV+=self.vd.getTerm(term_i).getTraitCovar().K()\n        else:\n            assert term_i<self.n_terms, 'Term index non valid'\n            RV = self.vd.getTerm(term_i).getTraitCovar().K()\n        return RV", "response": "Returns explicitly the estimated trait covariance matrix for a single term"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the estimated trait correlation matrix for a given term", "response": "def getEstTraitCorrCoef(self,term_i=None):\n        \"\"\"\n        Returns the estimated trait correlation matrix\n\n        Args:\n            term_i:     index of the term we are interested in\n        \"\"\"\n        cov = self.getEstTraitCovar(term_i)\n        stds=SP.sqrt(cov.diagonal())[:,SP.newaxis]\n        RV = cov/stds/stds.T\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getVariances(self):\n        if self.P>1:\n            RV=SP.zeros((self.n_terms,self.P))\n            for term_i in range(self.n_terms):\n                RV[term_i,:]=self.vd.getTerm(term_i).getTraitCovar().K().diagonal()\n        else:\n            RV=self.getScales()**2\n        return RV", "response": "Returns the estimated variances as a n_terms x P matrix\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getHessian(self):\n        assert self.init,        'GP not initialised'\n        assert self.fast==False, 'Not supported for fast implementation'\n        \n        if self.cache['Hessian']==None:\n            ParamMask=self.gp.getParamMask()['covar']\n            std=SP.zeros(ParamMask.sum())\n            H=self.gp.LMLhess_covar()\n            It= (ParamMask[:,0]==1)\n            self.cache['Hessian']=H[It,:][:,It]\n        \n        return self.cache['Hessian']", "response": "Returns the Hessian of the current GP entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Laplacian covariance matrix of the current object.", "response": "def getLaplaceCovar(self):\n        \"\"\"\n        USES LAPLACE APPROXIMATION TO CALCULATE THE COVARIANCE MATRIX OF THE OPTIMIZED PARAMETERS\n        \"\"\"\n        assert self.init,        'GP not initialised'\n        assert self.fast==False, 'Not supported for fast implementation'\n        \n        if self.cache['Sigma']==None:\n            self.cache['Sigma'] = SP.linalg.inv(self.getHessian())\n        return self.cache['Sigma']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the fisher information matrix over the parameters of the current object.", "response": "def getFisher(self):\n        \"\"\"\n        Return the fisher information matrix over the parameters\n        TO CHECK: IT DOES NOT WORK PROPERLY\n        \"\"\"\n        Ctot = self.vd.getGP().getCovar()\n        Ki = SP.linalg.inv(Ctot.K())\n        n_scales = self.vd.getNumberScales()\n        out = SP.zeros((n_scales,n_scales))\n        for m in range(n_scales):\n            out[m,m] = 0.5 * SP.trace(SP.dot(Ki,SP.dot(Ctot.Kgrad_param(m),SP.dot(Ki,Ctot.Kgrad_param(m)))))\n            for n in range(m):\n                out[m,n]=0.5 * SP.trace(SP.dot(Ki,SP.dot(Ctot.Kgrad_param(m),SP.dot(Ki,Ctot.Kgrad_param(n)))))\n                out[n,m]=out[m,n]\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getModelPosterior(self,min):\n        Sigma = self.getLaplaceCovar(min)\n        n_params = self.vd.getNumberScales()\n        ModCompl = 0.5*n_params*SP.log(2*SP.pi)+0.5*SP.log(SP.linalg.det(Sigma))\n        RV = min['LML']+ModCompl\n        return RV", "response": "Returns the model posterior for a given set of parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the empirical trait covariance matrix", "response": "def getEmpTraitCovar(self):\n        \"\"\"\n        Returns the empirical trait covariance matrix\n        \"\"\"\n        if self.P==1:\n            out=self.Y[self.Iok].var()\n        else:\n            out=SP.cov(self.Y[self.Iok].T)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the empirical trait correlation matrix", "response": "def getEmpTraitCorrCoef(self):\n        \"\"\"\n        Returns the empirical trait correlation matrix\n        \"\"\"\n        cov = self.getEmpTraitCovar()\n        stds=SP.sqrt(cov.diagonal())[:,SP.newaxis]\n        RV = cov/stds/stds.T\n        return RV"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nestimating variance components and fixed effects from a single trait model having only two terms", "response": "def estimateHeritabilities(self, K, verbose=False):\n        \"\"\"\n        estimate variance components and fixed effects\n        from a single trait model having only two terms\n        \"\"\"\n        \n        # Fit single trait model\n        varg  = SP.zeros(self.P)\n        varn  = SP.zeros(self.P)\n        fixed = SP.zeros((1,self.P))\n        \n        for p in range(self.P):\n            y = self.Y[:,p:p+1]\n            lmm = limix.CLMM()\n            lmm.setK(K)\n            lmm.setSNPs(SP.ones((K.shape[0],1)))\n            lmm.setPheno(y)\n            lmm.setCovs(SP.zeros((K.shape[0],1)))\n            lmm.setVarcompApprox0(-20, 20, 1000)\n            lmm.process()\n            delta = SP.exp(lmm.getLdelta0()[0,0])\n            Vtot  = SP.exp(lmm.getLSigma()[0,0])\n    \n            varg[p] = Vtot\n            varn[p] = delta*Vtot\n            fixed[:,p] = lmm.getBetaSNP()\n    \n            if verbose: print(p)\n    \n        sth = {}\n        sth['varg']  = varg\n        sth['varn']  = varn\n        sth['fixed'] = fixed\n\n        return sth"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setKstar(self,term_i,Ks):\n        assert Ks.shape[0]==self.N\n    \n        #if Kss!=None:\n            #assert Kss.shape[0]==Ks.shape[1]\n            #assert Kss.shape[1]==Ks.shape[1]\n\n        self.vd.getTerm(term_i).getKcf().setK0cross(Ks)", "response": "Set the kernel for predictions for the given term"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predictMean(self):\n        assert self.noisPos!=None,      'No noise element'\n        assert self.init,               'GP not initialised'\n                \n        KiY = self.gp.agetKEffInvYCache()\n                \n        if self.fast==False:\n            KiY = KiY.reshape(self.P,self.N).T\n                \n        Ymean = None\n        for term_i in range(self.n_terms):\n            if term_i!=self.noisPos:\n                Kstar = self.vd.getTerm(term_i).getKcf().Kcross(SP.zeros(1))\n                term  = SP.dot(Kstar.T,KiY)\n                if self.P>1:\n                    C    = self.getEstTraitCovar(term_i)\n                    term = SP.dot(term,C)\n                if Ymean==None:     Ymean  = term\n                else:               Ymean += term\n            \n        # to generalise\n        Ymean+=self.getFixed()[:,0]\n                \n        return Ymean", "response": "predict the conditional mean of the noise element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef safe_cd(path):\n    starting_directory = os.getcwd()\n    try:\n        os.chdir(path)\n        yield\n    finally:\n        os.chdir(starting_directory)", "response": "Changes to a directory yields and changes back."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a command through the shell.", "response": "def execute(script, *args, **kwargs):\n    \"\"\"\n    Executes a command through the shell. Spaces should breakup the args. Usage: execute('grep', 'TODO', '*')\n    NOTE: Any kwargs will be converted to args in the destination command.\n    E.g. execute('grep', 'TODO', '*', **{'--before-context': 5}) will be $grep todo * --before-context=5\n    \"\"\"\n\n    popen_args = [script] + list(args)\n    if kwargs:\n        popen_args.extend(_kwargs_to_execute_args(kwargs))\n\n    try:\n        return check_call(popen_args, shell=False)\n    except CalledProcessError as ex:\n        _print(ex)\n        sys.exit(ex.returncode)\n    except Exception as ex:\n        _print('Error: {} with script: {} and args {}'.format(ex, script, args))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_host_args(self, *args):\n        self.subcommand = None\n        new_args = args\n        try:\n            sub = args[0]\n            if sub in ['project','templates','static','media','wsgi','webconf']:\n                self.subcommand = args[0]\n                new_args = args[1:]\n        except IndexError:\n            pass\n        \n        return ','.join(new_args)", "response": "Splits out the patch subcommand and returns a comma separated list of host_strings\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an S3 URL to the given endpoint using the given bucket config.", "response": "def url_for_s3(endpoint, bucket_name, bucket_domain=None, scheme='',\n               url_style='host', cdn_domain=None, filename=None):\n    \"\"\"\n    Generates an S3 URL to the given endpoint, using the\n    given bucket config.\n\n    Example:\n    url_for_s3('static', bucket_name='my-cool-foobar-bucket',\n               scheme='https', filename='pics/logo.png')\n\n    Will return:\n    https://my-cool-foobar-bucket.s3.amazonaws.com/static/pics/logo.png\n\n    Note: this function assumes that the given resource exists on S3\n    and is publicly accessible.\n\n    Based loosely on Flask-S3's url_for().\n    \"\"\"\n\n    if not bucket_name:\n        raise ValueError('Bucket name is required when calling url_for_s3().')\n\n    if url_style == 'host':\n        url_format = '%(bucket_name)s.%(bucket_domain)s'\n    elif url_style == 'path':\n        url_format = '%(bucket_domain)s/%(bucket_name)s'\n    else:\n        raise ValueError('Invalid S3 URL style: \"%s\"'\n                         % url_style)\n\n    if bucket_domain == None:\n        bucket_domain = u's3.amazonaws.com'\n\n    bucket_path = url_format % {\n        'bucket_name': bucket_name,\n        'bucket_domain': bucket_domain,\n    }\n\n    if cdn_domain:\n        bucket_path = '%s' % cdn_domain\n\n    # The return statement below is equivalent to:\n    #\n    # urls = app.url_map.bind(bucket_path, url_scheme=scheme)\n    # return urls.build(endpoint, values=values, force_external=True)\n    #\n    # (assuming that this function receives a **values parameter\n    # instead of filename).\n    #\n    # But we do it manually instead, so we can avoid dependency on\n    # flask.current_app and werkzeug.routing.MapAdapter.\n\n    return str('%s//%s/%s%s' % (\n        scheme + (':' if scheme else ''),\n        bucket_path,\n        endpoint + ('/' if endpoint else ''),\n        filename.lstrip('/')\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _put_text(irods_path, text):\n    with tempfile.NamedTemporaryFile() as fh:\n        fpath = fh.name\n\n        try:\n            # Make Python2 compatible.\n            text = unicode(text, \"utf-8\")\n        except (NameError, TypeError):\n            # NameError: We are running Python3 => text already unicode.\n            # TypeError: text is already of type unicode.\n            pass\n\n        fh.write(text.encode(\"utf-8\"))\n        fh.flush()\n        cmd = CommandWrapper([\n            \"iput\",\n            \"-f\",\n            fpath,\n            irods_path\n        ])\n        cmd()\n    assert not os.path.isfile(fpath)", "response": "Put raw text into iRODS."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _put_obj(irods_path, obj):\n    text = json.dumps(obj, indent=2)\n    _put_text(irods_path, text)", "response": "Put python object into iRODS as JSON text."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list containing URIs in base_uri.", "response": "def list_dataset_uris(cls, base_uri, config_path):\n        \"\"\"Return list containing URIs in base_uri.\"\"\"\n        parsed_uri = generous_parse_uri(base_uri)\n        irods_path = parsed_uri.path\n\n        uri_list = []\n\n        logger.info(\"irods_path: '{}'\".format(irods_path))\n\n        for dir_path in _ls_abspaths(irods_path):\n\n            logger.info(\"dir path: '{}'\".format(dir_path))\n\n            base, uuid = os.path.split(dir_path)\n            base_uri = \"irods:{}\".format(base)\n            uri = cls.generate_uri(\n                name=None,\n                uuid=uuid,\n                base_uri=base_uri\n            )\n\n            storage_broker = cls(uri, config_path)\n\n            if storage_broker.has_admin_metadata():\n                uri_list.append(uri)\n\n        return uri_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning list of overlay names.", "response": "def list_overlay_names(self):\n        \"\"\"Return list of overlay names.\"\"\"\n        overlay_names = []\n        for fname in _ls(self._overlays_abspath):\n            name, ext = os.path.splitext(fname)\n            overlay_names.append(name)\n        return overlay_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns absolute path at which the item content can be accessed.", "response": "def get_item_abspath(self, identifier):\n        \"\"\"Return absolute path at which item content can be accessed.\n\n        :param identifier: item identifier\n        :returns: absolute path from which the item content can be accessed\n        \"\"\"\n        admin_metadata = self.get_admin_metadata()\n        uuid = admin_metadata[\"uuid\"]\n        # Create directory for the specific dataset.\n        dataset_cache_abspath = os.path.join(self._irods_cache_abspath, uuid)\n        mkdir_parents(dataset_cache_abspath)\n\n        # Get the file extension from the  relpath from the handle metadata.\n        irods_item_path = os.path.join(self._data_abspath, identifier)\n        relpath = self._get_metadata_with_cache(irods_item_path, \"handle\")\n        _, ext = os.path.splitext(relpath)\n\n        local_item_abspath = os.path.join(\n            dataset_cache_abspath,\n            identifier + ext)\n\n        if not os.path.isfile(local_item_abspath):\n            tmp_local_item_abspath = local_item_abspath + \".tmp\"\n            _get_file_forcefully(irods_item_path, tmp_local_item_abspath)\n            os.rename(tmp_local_item_abspath, local_item_abspath)\n\n        return local_item_abspath"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_structure(self):\n\n        # Ensure that the specified path does not exist and create it.\n        if _path_exists(self._abspath):\n            raise(StorageBrokerOSError(\n                \"Path already exists: {}\".format(self._abspath)\n            ))\n\n        # Make sure the parent collection exists.\n        parent, _ = os.path.split(self._abspath)\n        if not _path_exists(parent):\n            raise(StorageBrokerOSError(\n                \"No such iRODS collection: {}\".format(parent)))\n\n        _mkdir(self._abspath)\n\n        # Create more essential subdirectories.\n        essential_subdirectories = [\n            self._dtool_abspath,\n            self._data_abspath,\n            self._overlays_abspath\n        ]\n        for abspath in essential_subdirectories:\n            _mkdir_if_missing(abspath)", "response": "Create necessary structure to hold a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_item(self, fpath, relpath):\n        # Put the file into iRODS.\n        fname = generate_identifier(relpath)\n        dest_path = os.path.join(self._data_abspath, fname)\n        _cp(fpath, dest_path)\n\n        # Add the relpath handle as metadata.\n        _put_metadata(dest_path, \"handle\", relpath)\n\n        return relpath", "response": "Put an item into the local disk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_item_handles(self):\n        for abspath in self._ls_abspaths_with_cache(self._data_abspath):\n            try:\n                relpath = self._get_metadata_with_cache(abspath, \"handle\")\n                yield relpath\n            except IrodsNoMetaDataSetError:\n                pass", "response": "Return iterator over item handles."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_item_metadata(self, handle, key, value):\n        _mkdir_if_missing(self._metadata_fragments_abspath)\n\n        prefix = self._handle_to_fragment_absprefixpath(handle)\n        fpath = prefix + '.{}.json'.format(key)\n\n        _put_obj(fpath, value)", "response": "Store the given key value pair for the item associated with handle."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn dictionary containing all the metadata associated with handle.", "response": "def get_item_metadata(self, handle):\n        \"\"\"Return dictionary containing all metadata associated with handle.\n\n        In other words all the metadata added using the ``add_item_metadata``\n        method.\n\n        :param handle: handle for accessing an item before the dataset is\n                       frozen\n        :returns: dictionary containing item metadata\n        \"\"\"\n        if not self._metadata_dir_exists():\n            return {}\n\n        prefix = self._handle_to_fragment_absprefixpath(handle)\n\n        files = [f for f in self._ls_abspaths_with_cache(\n                 self._metadata_fragments_abspath)\n                 if f.startswith(prefix)]\n\n        metadata = {}\n        for f in files:\n            key = f.split('.')[-2]  # filename: identifier.key.json\n            value = _get_obj(f)\n            metadata[key] = value\n\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post_freeze_hook(self):\n        self._use_cache = False\n        self._ls_abspath_cache = {}\n        self._metadata_cache = {}\n        self._size_and_timestamp_cache = {}\n        _rm_if_exists(self._metadata_fragments_abspath)", "response": "This method is called at the end of the\n       . It is called at the end of the\n       . It is called at the end of the\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_index(self, index):\n\n    index._path = os.path.join(self.indexes_path, index._name)\n\n    if whoosh.index.exists_in(index._path):\n      _whoosh = whoosh.index.open_dir(index._path)\n    elif not os.path.exists(index._path):\n      os.makedirs(index._path)\n      _whoosh = whoosh.index.create_in(index._path, index._schema)\n    index._whoosh = _whoosh", "response": "Creates and opens index folder for given index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_index(self, index):\n\n    self._indexes[index._name] = index\n    self.create_index(index)\n    return index", "response": "Registers a given index in the internal index list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a single model for fulltext search. This basically creates a simple PonyWhoosh.Index for the model and calls self.register_index on it. Args: *fields: all the fields indexed from the model. **kw: The options for each field, sortedby, stored ...", "response": "def register_model(self, *fields, **kw):\n    \"\"\"Registers a single model for fulltext search. This basically creates\n    a simple PonyWhoosh.Index for the model and calls self.register_index on it.\n\n    Args:\n        *fields: all the fields indexed from the model.\n        **kw: The options for each field, sortedby, stored ...\n    \"\"\"\n\n    index         = PonyWhooshIndex(pw=self)\n    index._kw     = kw\n    index._fields = fields\n\n    def inner(model):\n      \"\"\"This look for the types of each field registered in the index,\n      whether if it is Numeric, datetime, boolean or just text.\n\n      Args:\n          model (PonyORM.Entity): A model defined on the database with PonyORM\n\n      Returns:\n          model (PonyORM.Entity): A model modified for handle the appropriate\n          search methods.\n      \"\"\"\n\n      index._name = model._table_\n      if not index._name:\n        index._name  = model.__name__\n\n      self._entities[index._name]     = model\n      index._schema_attrs             = {}\n      index._primary_key_is_composite = model._pk_is_composite_\n      index._primary_key              = [f.name for f in model._pk_attrs_]\n      index._primary_key_type         = 'list'\n      type_attribute                  = {}\n\n      for field in model._attrs_:\n        if field.is_relation:\n          continue\n\n        assert hasattr(field, \"name\") and hasattr(field, \"py_type\")\n\n        fname = field.name\n        if hasattr(field.name, \"__name__\"):\n            fname = field.name.__name__\n\n        stored = kw.get(\"stored\", False)\n        if fname in index._primary_key:\n            kw[\"stored\"] = True\n        # we're not supporting this kind of data\n        ftype = field.py_type.__name__\n        if ftype in ['date', 'datetime', 'datetime.date']:\n            kw[\"stored\"] = stored\n            continue\n\n        fwhoosh = fwhoosh = whoosh.fields.TEXT(**kw)\n\n        if field == model._pk_:\n            index._primary_key_type = ftype\n            fwhoosh = whoosh.fields.ID(stored=True, unique=True)\n\n        if fname in index._fields:\n          if not field.is_string:\n            if ftype in ['int', 'float']:\n              fwhoosh = whoosh.fields.NUMERIC(**kw)\n            elif ftype == 'bool':\n              fwhoosh = whoosh.fields.BOOLEAN(stored=True)\n\n        type_attribute[fname]      = ftype\n        index._schema_attrs[fname] = fwhoosh\n        kw[\"stored\"]               = stored\n\n      index._schema = whoosh.fields.Schema(**index._schema_attrs)\n\n      self.register_index(index)\n\n      def _middle_save_(obj, status):\n        \"\"\"A middle-in-middle method to intercept CRUD operations from PonyORM\n        over the current object model to update the appropriate whoosh index.\n\n        Args:\n            obj (EntityInstance): An instance of a current model.\n            status (str): Type of transaction on the database. A CRUD operation.\n\n        Returns:\n            obj (EntityInstance): The same object as the input.\n        \"\"\"\n\n        writer   = index._whoosh.writer(timeout=self.writer_timeout)\n        dict_obj = obj.to_dict()\n\n        def dumps(v):\n          if sys.version_info[0] < 3:\n            if isinstance(v, int):\n              return unicode(v)\n            if isinstance(v, float):\n              return '%.9f' % v\n            return unicode(v)\n          else:\n            if isinstance(v, int):\n              return str(v)\n            if isinstance(v, float):\n              return int(float(v))\n            return str(v)\n\n        attrs = {}\n        if sys.version_info[0] < 3:\n          for k, v in dict_obj.iteritems():\n            if k in index._schema_attrs.keys():\n              attrs[k] = dumps(v)\n        else:\n          for k, v in dict_obj.items():\n            if k in list(index._schema_attrs.keys()):\n              attrs[k] = dumps(v)\n\n        if status == 'inserted':\n          writer.add_document(**attrs)\n        elif status == 'updated':\n          writer.update_document(**attrs)\n        elif status in set(['marked_to_delete', 'deleted', 'cancelled']):\n          writer.delete_by_term(primary, attrs[primary])\n\n        writer.commit()\n        return obj._after_save_\n\n      index._model       = model\n      model._after_save_ = _middle_save_\n      model._pw_index_   = index\n      model.search       =  model._pw_index_.search\n      return model\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a compiled regular expression for sound patterns.", "response": "def _sounds_re(include_erhua=False):\n    \"\"\"Sounds are syllables + tones\"\"\"\n\n    tone = '[1-5]'\n    optional_final_erhua = '|r\\\\b' if include_erhua else ''\n    pattern = '({}{}{})'.format(_joined_syllables_re(), tone, optional_final_erhua)\n    return re.compile(pattern, re.IGNORECASE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsanitizes given python module file.", "response": "def bleach(file):\n    \"\"\"\n    Sanitizes given python module.\n\n    :param file: Python module file.\n    :type file: unicode\n    :return: Definition success.\n    :rtype: bool\n    \"\"\"\n\n    LOGGER.info(\"{0} | Sanitizing '{1}' python module!\".format(__name__, file))\n\n    source_file = File(file)\n    content = source_file.read()\n    for pattern in STATEMENTS_SUBSTITUTE:\n        matches = [match for match in re.finditer(pattern, content, re.DOTALL)]\n\n        offset = 0\n        for match in matches:\n            if any(map(lambda x: x in match.group(\"bleach\"), STATEMENT_IGNORE)):\n                continue\n\n            start, end = match.start(\"bleach\"), match.end(\"bleach\")\n            substitution = \"{0}{1}\".format(STATEMENT_UPDATE_MESSAGE,\n                                           re.sub(\"\\n\", \"\\n{0}\".format(STATEMENT_UPDATE_MESSAGE),\n                                                  match.group(\"bleach\")))\n            content = \"\".join((content[0: start + offset],\n                               substitution,\n                               content[end + offset:]))\n            offset += len(substitution) - len(match.group(\"bleach\"))\n\n    source_file.content = [content]\n    source_file.write()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mk_message(org, user, key):\n\n    m = Message()\n    m['client'] = \"taskc-py {0}\".format(__version__)\n    m['protocol'] = \"v1\"\n    m['org'] = org\n    m['user'] = user\n    m['key'] = key\n\n    return m", "response": "Make a message from the given org user and key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the message for the next log entry.", "response": "def prep_message(msg):\n    \"\"\"\n    Add the size header\n    \"\"\"\n    if six.PY3:\n        msg_out = msg.as_string().encode(\"utf-8\")\n    else:\n        msg_out = msg.as_string()\n\n    our_len = len(msg_out) + 4\n    size = struct.pack('>L', our_len)\n    # why the hell is this \"bytes\" on python3?\n\n    return size + msg_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ucast_ip_mask(ip_addr_and_mask, return_tuple=True):\n    regex_ucast_ip_and_mask = __re.compile(\"^((22[0-3])|(2[0-1][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))/((3[0-2])|([1-2]?[0-9]))$\")\n    if return_tuple:\n        while not regex_ucast_ip_and_mask.match(ip_addr_and_mask):\n            print(\"Not a good unicast IP and CIDR mask combo.\")\n            print(\"Please try again.\")\n            ip_addr_and_mask = input(\"Please enter a unicast IP address and mask in the follwing format x.x.x.x/x: \")\n        ip_cidr_split = ip_addr_and_mask.split(\"/\")\n        ip_addr = ip_cidr_split[0]\n        cidr = ip_cidr_split[1]\n        return ip_addr, cidr\n    elif not return_tuple:\n        if not regex_ucast_ip_and_mask.match(ip_addr_and_mask):\n            return False\n        else:\n            return True", "response": "Function to check if a given IP and CIDR mask is unicast and return the unicast IP and CIDR mask."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ucast_ip(ip_addr, return_tuple=True):\n    regex_ucast_ip = __re.compile(\"^((22[0-3])|(2[0-1][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))$\")\n    if return_tuple:\n        while not regex_ucast_ip.match(ip_addr):\n            print(\"Not a good unicast IP.\")\n            print(\"Please try again.\")\n            ip_addr = input(\"Please enter a unicast IP address in the following format x.x.x.x: \")\n        return ip_addr\n    elif not return_tuple:\n        if not regex_ucast_ip.match(ip_addr):\n            return False\n        else:\n            return True", "response": "Function to check if a given IP address is unicast and return the related object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mcast_ip_mask(ip_addr_and_mask, return_tuple=True):\n    regex_mcast_ip_and_mask = __re.compile(\"^(((2[2-3][4-9])|(23[0-3]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))/((3[0-2])|([1-2][0-9])|[3-9]))$\")\n    if return_tuple:\n        while not regex_mcast_ip_and_mask.match(ip_addr_and_mask):\n            print(\"Not a good multicast IP and CIDR mask combo.\")\n            print(\"Please try again.\")\n            ip_addr_and_mask = input(\"Please enter a multicast IP address and mask in the follwing format x.x.x.x/x: \")\n        ip_cidr_split = ip_addr_and_mask.split(\"/\")\n        ip_addr = ip_cidr_split[0]\n        cidr = ip_cidr_split[1]\n        return ip_addr, cidr\n    elif not return_tuple:\n        if not regex_mcast_ip_and_mask.match(ip_addr_and_mask):\n            return False\n        else:\n            return True", "response": "Function to check if a given IP and CIDR mask is good for a given multicast IP address and mask"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mcast_ip(ip_addr, return_tuple=True):\n    regex_mcast_ip = __re.compile(\"^(((2[2-3][4-9])|(23[0-3]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9])))$\")\n    if return_tuple:\n        while not regex_mcast_ip.match(ip_addr):\n            print(\"Not a good multicast IP.\")\n            print(\"Please try again.\")\n            ip_addr = input(\"Please enter a multicast IP address in the following format x.x.x.x: \")\n        return ip_addr\n    elif not return_tuple:\n        if not regex_mcast_ip.match(ip_addr):\n            return False\n        else:\n            return True", "response": "Function to check if a given IP address is multicast"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction to check if a given IP and CIDR mask is good for a given object", "response": "def ip_mask(ip_addr_and_mask, return_tuple=True):\n    \"\"\"\n    Function to check if a address and CIDR mask is good\n    Args:\n        ip_addr_and_mask: IP address and mask in the following format 192.168.1.1/24\n        return_tuple: Set to True it returns a IP and mask in a tuple, set to False returns True or False\n\n    Returns: see return_tuple for return options\n\n    \"\"\"\n    regex_ip_and_mask = __re.compile(\"^((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))/((3[0-2])|([1-2]?[0-9]))$\")\n    if return_tuple:\n        while not regex_ip_and_mask.match(ip_addr_and_mask):\n            print(\"Not a good IP and CIDR mask combo.\")\n            print(\"Please try again.\")\n            ip_addr_and_mask = input(\"Please enter a IP address and mask in the follwing format x.x.x.x/x: \")\n        ip_cidr_split = ip_addr_and_mask.split(\"/\")\n        ip_addr = ip_cidr_split[0]\n        cidr = ip_cidr_split[1]\n        return ip_addr, cidr\n    elif not return_tuple:\n        if not regex_ip_and_mask.match(ip_addr_and_mask):\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ip(ip_addr, return_tuple=True):\n    regex_ip = __re.compile(\"^((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))\\.((25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|([1-9]?[0-9]))$\")\n    if return_tuple:\n        while not regex_ip.match(ip_addr):\n            print(\"Not a good IP.\")\n            print(\"Please try again.\")\n            ip_addr = input(\"Please enter a IP address in the following format x.x.x.x: \")\n        return ip_addr\n    elif not return_tuple:\n        if not regex_ip.match(ip_addr):\n            return False\n        else:\n            return True", "response": "Function to check if a given IP address is good for a given ISO - 8601 language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cidr_check(cidr, return_cidr=True):\n    try:\n        if int(cidr) < 0 or int(cidr) > 32:\n            good_cidr = False\n        else:\n            good_cidr = True\n        if return_cidr:\n            while not good_cidr:\n                print(\"Sorry the CIDR value %s is not a valid value must be a value of 0 to 32.  Please try again.\"\n                      % (cidr,))\n                cidr = input(\"What is the mask for in CIDR format?: \")\n                if int(cidr) < 0 or int(cidr) > 32:\n                    good_cidr = False\n                else:\n                    good_cidr = True\n            return cidr\n        elif not return_cidr:\n            return good_cidr\n    except ValueError:\n        LOGGER.critical('Function cidr_check expected a number but got {item}'.format(item=cidr))\n        raise ValueError(\"The input needs to be a number!!\")", "response": "Function to verify a CIDR value for a new node in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_neighbor_ip(ip_addr, cidr=\"30\"):\n    our_octet = None\n    neighbor_octet = None\n    try:\n        ip_addr_split = ip_addr.split(\".\")\n        max_counter = 0\n        if int(cidr) == 30:\n            ranger = 4\n        elif int(cidr) == 31:\n            ranger = 2\n        while max_counter < 256:\n            try:\n                if int(ip_addr_split[3]) >= max_counter and int(ip_addr_split[3]) < (max_counter + ranger):\n                    if ranger == 4:\n                        our_octet = max_counter + 1\n                        neighbor_octet = max_counter + 2\n                        break\n                    elif ranger == 2:\n                        our_octet = max_counter\n                        neighbor_octet = max_counter + 1\n                        break   \n                max_counter += ranger\n            except UnboundLocalError:\n                print(\"The mask between the neighbors must be 30, or 31\")\n                exit(\"BAD NEIGHBOR MASK\")\n        if int(ip_addr_split[3]) == our_octet:\n            our_ip_addr = \"%s.%s.%s.%i\" % (ip_addr_split[0], ip_addr_split[1], ip_addr_split[2], our_octet)\n            neighbor_ip_addr = \"%s.%s.%s.%i\" % (ip_addr_split[0], ip_addr_split[1], ip_addr_split[2], neighbor_octet)\n        elif int(ip_addr_split[3]) == neighbor_octet:\n            neighbor_ip_addr = \"%s.%s.%s.%i\" % (ip_addr_split[0], ip_addr_split[1], ip_addr_split[2], our_octet)\n            our_ip_addr = \"%s.%s.%s.%i\" % (ip_addr_split[0], ip_addr_split[1], ip_addr_split[2], neighbor_octet)\n        else:\n            our_ip_addr = \"%s.%s.%s.%i\" % (ip_addr_split[0], ip_addr_split[1], ip_addr_split[2], our_octet)\n            neighbor_ip_addr = \"%s.%s.%s.%i\" % (ip_addr_split[0], ip_addr_split[1], ip_addr_split[2], neighbor_octet)\n        return our_ip_addr, neighbor_ip_addr\n    except IndexError:\n        LOGGER.critical('Function get_neighbor_ip IndexError ip_addr {item} cidr {cidr}'.format(item=ip_addr,\n                                                                                                cidr=cidr))\n        raise IndexError(\"You have entered invalid input, you must enter a ipv4 address\")", "response": "Function to figure out the IP s between neighbors in a tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef whole_subnet_maker(ip_addr, cidr):\n    if ucast_ip(ip_addr, False) == False and mcast_ip(ip_addr, False) == False:\n        LOGGER.critical('Function whole_subnet_maker ip_addr {item}'.format(item=ip_addr))\n        raise ValueError(\"Not a good ipv4 address\")\n    if not cidr_check(cidr, False):\n        LOGGER.critical('Function whole_subnet_maker cidr {item}'.format(item=cidr))\n        raise ValueError(\"Not a good CIDR value should be 0 to 32\")\n\n    def subnet_corrector(octet, cidr):\n        \"\"\" Function to correct a octet for a subnet \"\"\"\n        cidr_int = int(cidr)\n        octet_int = int(octet)\n        if cidr_int >= 24:\n            cidr_int = __mask_conversion[cidr_int][\"OCT4\"]\n        elif cidr_int >= 16:\n            cidr_int = __mask_conversion[cidr_int][\"OCT3\"]\n        elif cidr_int >= 8:\n            cidr_int = __mask_conversion[cidr_int][\"OCT2\"]\n        elif cidr_int >= 1:\n            cidr_int = __mask_conversion[cidr_int][\"OCT1\"]\n        cidr_count = 0\n        cidr_v = 256 - cidr_int\n        cidr_2 = 256 - cidr_int\n        while cidr_count < 300:\n            if octet_int >= cidr_count and octet_int <= cidr_2:\n                    cidr_int = cidr_count\n            cidr_count = cidr_2\n            cidr_2 = cidr_2 + cidr_v\n        return str(cidr_int)\n    ip_addr_split = ip_addr.split(\".\")\n    if int(cidr) >= 24:\n        octet = subnet_corrector(ip_addr_split[3], cidr)\n        completed = ip_addr_split[0] + \".\" + ip_addr_split[1] + \".\" + ip_addr_split[2] + \".\" + octet\n        return completed\n    elif int(cidr) >= 16:\n        octet = subnet_corrector(ip_addr_split[2], cidr)\n        completed = ip_addr_split[0] + \".\" + ip_addr_split[1] + \".\" + octet + \".0\"\n        return completed\n    elif int(cidr) >= 8:\n        octet = subnet_corrector(ip_addr_split[1], cidr)\n        completed = ip_addr_split[0] + \".\" + octet + \".0.0\"\n        return completed\n    elif int(cidr) >= 1:\n        octet = subnet_corrector(ip_addr_split[0], cidr)\n        completed = octet + \".0.0.0\"\n        return completed\n    else:\n        return \"0.0.0.0\"", "response": "Function to return a whole subnet value from a IP address and CIDR pair"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subnet_range(ip_net, cidr):\n    subnets_dict = dict()\n    subnet = whole_subnet_maker(ip_net, cidr)\n    subnets_dict['IP'] = ip_net\n    subnets_dict['NET'] = subnet\n    subnets_dict['CIDR'] = '%s/%s' % (whole_subnet_maker(ip_net, cidr), cidr)\n    if int(cidr) >= 24:\n        subnet_split = subnet.split('.')\n        first_ip = int(subnet_split[3]) + 1\n        last_ip = (int(subnet_split[3]) + 1) + (253 - int(__mask_conversion[int(cidr)]['OCT4']))\n        bcast_ip = (int(subnet_split[3]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT4']))\n        temp = '%s.%s.%s.' % (subnet_split[0], subnet_split[1], subnet_split[2])\n        subnets_dict['RANGE'] = '%s%i to %s%i' % (temp, first_ip, temp, last_ip)\n        subnets_dict['BCAST'] = '%s%i' % (temp, bcast_ip)\n        subnets_dict['MASK'] = __mask_conversion[int(cidr)]['MASK']\n        subnets_dict['INVMASK'] = __mask_conversion[int(cidr)]['INVMASK']\n        subnets_dict['CIDRVAL'] = __mask_conversion[int(cidr)]['CIDR']\n    elif int(cidr) >= 16:\n        subnet_split = subnet.split('.')\n        first_ip = int(subnet_split[2])\n        last_ip = (int(subnet_split[2]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT3']))\n        bcast_ip = (int(subnet_split[2]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT3']))\n        temp = '%s.%s.' % (subnet_split[0], subnet_split[1])\n        subnets_dict['RANGE'] = '%s%i.1 to %s%i.254' % (temp, first_ip, temp, last_ip)\n        subnets_dict['BCAST'] = '%s%i.255' % (temp, bcast_ip)\n        subnets_dict['MASK'] = __mask_conversion[int(cidr)]['MASK']\n        subnets_dict['INVMASK'] = __mask_conversion[int(cidr)]['INVMASK']\n        subnets_dict['CIDRVAL'] = __mask_conversion[int(cidr)]['CIDR']\n    elif int(cidr) >= 8:\n        subnet_split = subnet.split('.')\n        first_ip = int(subnet_split[1])\n        last_ip = (int(subnet_split[1]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT2']))\n        bcast_ip = (int(subnet_split[1]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT2']))\n        temp = '%s.' % (subnet_split[0],)\n        subnets_dict['RANGE'] = '%s%i.0.1 to %s%i.255.254' % (temp, first_ip, temp, last_ip)\n        subnets_dict['BCAST'] = '%s%i.255.255' % (temp, bcast_ip)\n        subnets_dict['MASK'] = __mask_conversion[int(cidr)]['MASK']\n        subnets_dict['INVMASK'] = __mask_conversion[int(cidr)]['INVMASK']\n        subnets_dict['CIDRVAL'] = __mask_conversion[int(cidr)]['CIDR']\n    elif int(cidr) >= 1:\n        subnet_split = subnet.split('.')\n        first_ip = int(subnet_split[0])\n        last_ip = (int(subnet_split[0]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT1']))\n        bcast_ip = (int(subnet_split[0]) + 1) + (254 - int(__mask_conversion[int(cidr)]['OCT1']))\n        subnets_dict['RANGE'] = '%i.0.0.1 to %i.255.255.254' % (first_ip, last_ip)\n        subnets_dict['BCAST'] = '%i.255.255.255' % (bcast_ip,)\n        subnets_dict['MASK'] = __mask_conversion[int(cidr)]['MASK']\n        subnets_dict['INVMASK'] = __mask_conversion[int(cidr)]['INVMASK']\n        subnets_dict['CIDRVAL'] = __mask_conversion[int(cidr)]['CIDR']\n    return subnets_dict", "response": "Function to return a subnet range value from a IP address and CIDR pair\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_subnets_longer_prefix(ip_net, cidr):\n    subnets_list = list()\n    while int(cidr) <= 32:\n        try:\n            subnets_list.append('%s/%s' % (whole_subnet_maker(ip_net, cidr), cidr))\n        except Exception as e:\n            LOGGER.critical('Function all_subnets_longer_prefix {item}'.format(item=e))\n            pass\n        cidr = str(int(cidr) + 1)\n    return subnets_list", "response": "Function to return every subnet in the list that is longer than the given CIDR"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to return every subnet in the list that is shorter than the given CIDR", "response": "def all_subnets_shorter_prefix(ip_net, cidr, include_default=False):\n    \"\"\"\n    Function to return every subnet a ip can belong to with a shorter prefix\n    Args:\n        ip_net: Unicast or Multicast IP address or subnet in the following format 192.168.1.1, 239.1.1.1\n        cidr: CIDR value of 0 to 32\n        include_default: If you want the list to inlclude the default route set to True\n\n    Returns: returns a list of subnets\n\n    \"\"\"\n    subnets_list = list()\n    if include_default:\n        while int(cidr) >= 0:\n            try:\n                subnets_list.append('%s/%s' % (whole_subnet_maker(ip_net, cidr), cidr))\n            except Exception as e:\n                LOGGER.critical('Function all_subnets_shorter_prefix {item}'.format(item=e))\n            cidr = str(int(cidr) - 1)\n    else:\n        while int(cidr) > 0:\n            try:\n                subnets_list.append('%s/%s' % (whole_subnet_maker(ip_net, cidr), cidr))\n            except Exception as e:\n                LOGGER.critical('Function all_subnets_shorter_prefix {item}'.format(item=e))\n            cidr = str(int(cidr) - 1)\n    return subnets_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_ip_address_in_subnet(ip_net, cidr):\n    ip_address_list = list()\n    if not ip_mask('{ip_net}/{cidr}'.format(ip_net=ip_net, cidr=cidr), return_tuple=False):\n        LOGGER.critical('{network} is not a valid IPv4 network'.format(network='{ip_net}/{cidr}'.format(ip_net=ip_net,\n                                                                                                        cidr=cidr)))\n        raise ValueError('{network} is not a valid IPv4 network'.format(network='{ip_net}/{cidr}'.format(ip_net=ip_net,\n                                                                                                         cidr=cidr)))\n\n    else:\n        ip_net = whole_subnet_maker(ip_net, cidr)\n        net = __ipaddress.ip_network('{ip_net}/{cidr}'.format(ip_net=ip_net, cidr=cidr))\n        for single_ip in net:\n            ip_address_list.append(str(single_ip))\n\n        return ip_address_list", "response": "Function to return every ip in a subnet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef number_check(check, return_number=True):\n    try:\n        int(check)\n        good = True\n    except ValueError:\n        LOGGER.critical('Function number_check ValueError {item}'.format(item=check))\n        good = False\n    if return_number:\n        while not good:\n            print(\"That is not a number.\")\n            print(\"Please try again.\")\n            check = input(\"Please enter a number?: \")\n            try:\n                int(check)\n                good = True\n            except ValueError:\n                LOGGER.critical('Function number_check ValueError {item}'.format(item=check))\n                good = False\n        return check\n    else:\n        return good", "response": "Function to verify item entered is a number"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_cidr_mask(lowest_mask=16):\n    if lowest_mask < 33:\n        return str(__random.randrange(lowest_mask, 33))\n\n    else:\n        LOGGER.critical('{lowest_mask} must be 32 or less.'.format(lowest_mask=lowest_mask))\n        raise ValueError('{lowest_mask} must be 32 or less.'.format(lowest_mask=lowest_mask))", "response": "Function to generate a random CIDR mask"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef random_ucast_ip():\n    first_octet = str(__random.randrange(1, 224))\n\n    def get_other_octetes():\n        return str(__random.randrange(0, 255))\n\n    return '{first_octet}.{second_octet}.{third_octet}.{fourth_octet}'.format(first_octet=first_octet,\n                                                                              second_octet=get_other_octetes(),\n                                                                              third_octet=get_other_octetes(),\n                                                                              fourth_octet=get_other_octetes())", "response": "Function to generate a random unicast ip address\n    "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_single_keywords(skw_db, fulltext):\n    timer_start = time.clock()\n\n    # single keyword -> [spans]\n    records = []\n\n    for single_keyword in skw_db.values():\n        for regex in single_keyword.regex:\n            for match in regex.finditer(fulltext):\n                # Modify the right index to put it on the last letter\n                # of the word.\n                span = (match.span()[0], match.span()[1] - 1)\n\n                # FIXME: expensive!!!\n                # Remove the previous records contained by this span\n                records = [record for record in records\n                           if not _contains_span(span, record[0])]\n\n                add = True\n                for previous_record in records:\n                    if ((span, single_keyword) == previous_record or\n                            _contains_span(previous_record[0], span)):\n                        # Match is contained by a previous match.\n                        add = False\n                        break\n\n                if add:\n                    records.append((span, single_keyword))\n\n    # TODO - change to the requested format (I will return to it later)\n\n    # List of single_keywords: {spans: single keyword}\n    single_keywords = {}\n    for span, single_keyword in records:\n        single_keywords.setdefault(single_keyword, [[]])\n        single_keywords[single_keyword][0].append(span)\n\n    current_app.logger.info(\n        \"Matching single keywords... %d keywords found \"\n        \"in %.1f sec.\" % (len(single_keywords), time.clock() - timer_start),\n    )\n    return single_keywords", "response": "Find single keywords in the fulltext."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of composite keywords bound with number of occurrences.", "response": "def get_composite_keywords(ckw_db, fulltext, skw_spans):\n    \"\"\"Return a list of composite keywords bound with number of occurrences.\n\n    :param ckw_db: list of KewordToken objects\n                   (they are supposed to be composite ones)\n    :param fulltext: string to search in\n    :param skw_spans: dictionary of already identified single keywords\n\n    :return : dictionary of matches in a format {\n            <keyword object>, [[position, position...], [info_about_matches] ],\n            ..\n            }\n    \"\"\"\n    timer_start = time.clock()\n\n    # Build the list of composite candidates\n    ckw_out = {}\n    skw_as_components = []\n\n    for composite_keyword in ckw_db.values():\n        # Counters for the composite keyword. First count is for the\n        # number of occurrences in the whole document and second count\n        # is for the human defined keywords.\n        ckw_count = 0\n        matched_spans = []\n\n        # First search in the fulltext using the regex pattern of the whole\n        # composite keyword (including the alternative labels)\n        for regex in composite_keyword.regex:\n            for match in regex.finditer(fulltext):\n                span = list(match.span())\n                span[1] -= 1\n                span = tuple(span)\n                if span not in matched_spans:\n                    ckw_count += 1\n                    matched_spans.append(span)\n\n        # Get the single keywords locations.\n        try:\n            components = composite_keyword.compositeof\n        except AttributeError:\n            current_app.logger.error(\n                \"Cached ontology is corrupted. Please \"\n                \"remove the cached ontology in your temporary file.\"\n            )\n            raise OntologyError('Cached ontology is corrupted.')\n\n        spans = []\n        try:\n            spans = [skw_spans[component][0] for component in components]\n        except KeyError:\n            # Some of the keyword components are not to be found in the text.\n            # Therefore we cannot continue because the match is incomplete.\n            pass\n\n        ckw_spans = []\n        for index in range(len(spans) - 1):\n            len_ckw = len(ckw_spans)\n            if ckw_spans:  # cause ckw_spans include the previous\n                previous_spans = ckw_spans\n            else:\n                previous_spans = spans[index]\n\n            for new_span in [(span0, colmd1) for span0 in previous_spans\n                             for colmd1 in spans[index + 1]]:\n                span = _get_ckw_span(fulltext, new_span)\n                if span is not None:\n                    ckw_spans.append(span)\n\n            # the spans must be overlapping to be included\n            if index > 0 and ckw_spans:\n                _ckw_spans = []\n                for _span in ckw_spans[len_ckw:]:  # new spans\n                    for _colmd2 in ckw_spans[:len_ckw]:\n                        s = _span_overlapping(_span, _colmd2)\n                        if s:\n                            _ckw_spans.append(s)\n                ckw_spans = _ckw_spans\n\n        for matched_span in [mspan for mspan in ckw_spans\n                             if mspan not in matched_spans]:\n            ckw_count += 1\n            matched_spans.append(matched_span)\n\n        if ckw_count:\n            # Gather the component counts.\n            component_counts = []\n            for component in components:\n                skw_as_components.append(component)\n                # Get the single keyword count.\n                try:\n                    component_counts.append(len(skw_spans[component][0]))\n                except KeyError:\n                    component_counts.append(0)\n\n            # Store the composite keyword\n            ckw_out[composite_keyword] = [matched_spans, component_counts]\n\n    # Remove the single keywords that appear as components from the list\n    # of single keywords.\n    for skw in skw_as_components:\n        try:\n            del skw_spans[skw]\n        except KeyError:\n            pass\n\n    # Remove the composite keywords that are fully present in\n    # longer composite keywords\n    _ckw_base = filter(lambda x: len(x.compositeof) == 2, ckw_out.keys())\n    _ckw_extended = sorted(\n        filter(lambda x: len(x.compositeof) > 2, ckw_out.keys()),\n        key=lambda x: len(x.compositeof))\n    if _ckw_extended:\n        candidates = []\n        for kw1 in _ckw_base:\n            s1 = set(kw1.compositeof)\n            for kw2 in _ckw_extended:\n                s2 = set(kw2.compositeof)\n                if s1.issubset(s2):\n                    candidates.append((kw1, kw2))\n                    # break  # don't stop because this keyword may be\n                    # partly contained by kw_x and kw_y\n        for i in range(len(_ckw_extended)):\n            kw1 = _ckw_extended[i]\n            s1 = set(kw1.compositeof)\n            for ii in range(i + 1, len(_ckw_extended)):\n                kw2 = _ckw_extended[ii]\n                s2 = set(kw2.compositeof)\n                if s1.issubset(s2):\n                    candidates.append((kw1, kw2))\n                    break\n        if candidates:\n            for kw1, kw2 in candidates:\n                try:\n                    match1 = ckw_out[kw1]  # subset of the kw2\n                    match2 = ckw_out[kw2]\n                except KeyError:\n                    continue\n                positions1 = match1[0]\n                for pos1 in positions1:\n                    for pos2 in match2[0]:\n                        if _span_overlapping(pos1, pos2):\n                            del positions1[positions1.index(pos1)]\n                            # if we removed all the matches also\n                            # delete the keyword\n                            if len(positions1) == 0:\n                                del ckw_out[kw1]\n                            break\n\n    current_app.logger.info(\n        \"Matching composite keywords... %d keywords found \"\n        \"in %.1f sec.\" % (len(ckw_out), time.clock() - timer_start),\n    )\n    return ckw_out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_author_keywords(skw_db, ckw_db, fulltext):\n    timer_start = time.clock()\n    out = {}\n\n    split_string = current_app.config[\n        \"CLASSIFIER_AUTHOR_KW_START\"\n    ].split(fulltext, 1)\n    if len(split_string) == 1:\n        current_app.logger.info(\n            \"No keyword marker found when matching authors.\")\n        return out\n\n    kw_string = split_string[1]\n\n    for regex in current_app.config[\"CLASSIFIER_AUTHOR_KW_END\"]:\n        parts = regex.split(kw_string, 1)\n        kw_string = parts[0]\n\n    # We separate the keywords.\n    author_keywords = current_app.config[\n        \"CLASSIFIER_AUTHOR_KW_SEPARATION\"\n    ].split(kw_string)\n\n    current_app.logger.info(\n        \"Matching author keywords... %d keywords found in \"\n        \"%.1f sec.\" % (len(author_keywords), time.clock() - timer_start)\n    )\n\n    for kw in author_keywords:\n        # If the author keyword is an acronym with capital letters\n        # separated by points, remove the points.\n        if re.match('([A-Z].)+$', kw):\n            kw = kw.replace('.', '')\n\n        # Drop trailing dots such as those in the last keyword.\n        if kw.endswith('.'):\n            kw = kw[:-1]\n\n        # First try with the keyword as such, then lower it.\n        kw_with_spaces = ' %s ' % kw\n        matching_skw = get_single_keywords(skw_db, kw_with_spaces)\n        matching_ckw = get_composite_keywords(ckw_db, kw_with_spaces,\n                                              matching_skw)\n\n        if matching_skw or matching_ckw:\n            out[kw] = (matching_skw, matching_ckw)\n            continue\n\n        lowkw = kw.lower()\n\n        matching_skw = get_single_keywords(skw_db, ' %s ' % lowkw)\n        matching_ckw = get_composite_keywords(ckw_db, ' %s ' % lowkw,\n                                              matching_skw)\n\n        out[kw] = (matching_skw, matching_ckw)\n\n    return out", "response": "Find out the human defined keywords in a text string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_ckw_span(fulltext, spans):\n    _MAXIMUM_SEPARATOR_LENGTH = max(\n        [len(_separator)\n         for _separator in\n         current_app.config[\"CLASSIFIER_VALID_SEPARATORS\"]]\n    )\n    if spans[0] < spans[1]:\n        words = (spans[0], spans[1])\n        dist = spans[1][0] - spans[0][1]\n    else:\n        words = (spans[1], spans[0])\n        dist = spans[0][0] - spans[1][1]\n\n    if dist == 0:\n        # Two keywords are adjacent. We have a match.\n        return (min(words[0] + words[1]),\n                max(words[0] + words[1]))  # FIXME: huh, this is a bug?! a sum?\n    elif dist <= _MAXIMUM_SEPARATOR_LENGTH:\n        separator = fulltext[words[0][1]:words[1][0] + 1]\n        # Check the separator.\n        if separator.strip() in current_app.config[\n                \"CLASSIFIER_VALID_SEPARATORS\"]:\n            return (min(words[0] + words[1]), max(words[0] + words[1]))\n\n    # There is no inclusion.\n    return None", "response": "Return the span of the composite keyword if it is valid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning true if span0 contains span1 False otherwise.", "response": "def _contains_span(span0, span1):\n    \"\"\"Return true if span0 contains span1, False otherwise.\"\"\"\n    if (span0 == span1 or span0[0] > span1[0] or span0[1] < span1[1]):\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if user has the given mode or higher.", "response": "def has_privs(self, user, lowest_mode='o'):\n        \"\"\"Return True if user has the given mode or higher.\"\"\"\n        if isinstance(user, User):\n            user = user.nick\n\n        user_prefixes = self.prefixes.get(user, None)\n\n        if not user_prefixes:\n            return False\n\n        mode_dict = self.s.features.available['prefix']\n\n        caught = False\n\n        for mode, prefix in mode_dict.items():\n            if mode in lowest_mode and not caught:\n                caught = True\n            elif mode not in lowest_mode and not caught:\n                continue\n\n            if prefix in user_prefixes:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a user to our internal list of nicks.", "response": "def add_user(self, nick, prefixes=None):\n        \"\"\"Add a user to our internal list of nicks.\"\"\"\n        if nick not in self._user_nicks:\n            self._user_nicks.append(nick)\n\n        self.prefixes[nick] = prefixes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if a file is a packet trace that is supported by this module.", "response": "def is_packet_trace(path):\n    \"\"\"Determine if a file is a packet trace that is supported by this module.\n\n    Args:\n        path (str): path to the trace file.\n\n    Returns:\n        bool: True if the file is a valid packet trace.\n    \"\"\"\n    path = os.path.abspath(path)\n    if not os.path.isfile(path):\n        return False\n\n    try:\n        f = open(path, 'rb')\n    except:\n        return False\n\n    magic = f.read(4)\n    f.close()\n\n    return magic in FILE_TYPE_HANDLER"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a packet trace file and return a WlTrace object.", "response": "def load_trace(path, *args, **kwargs):\n    \"\"\"Read a packet trace file, return a :class:`wltrace.common.WlTrace` object.\n\n    This function first reads the file's magic\n    (first ``FILE_TYPE_HANDLER`` bytes), and automatically determine the\n    file type, and call appropriate handler to process the file.\n\n    Args:\n        path (str): the file's path to be loaded.\n\n    Returns:\n        ``WlTrace`` object.\n    \"\"\"\n    with open(path, 'rb') as f:\n        magic = f.read(MAGIC_LEN)\n    if magic not in FILE_TYPE_HANDLER:\n        raise Exception('Unknown file magic: %s' % (binascii.hexlify(magic)))\n\n    return FILE_TYPE_HANDLER[magic](path, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_csv(path, out):\n    known_persons = ()\n    with codecs.open(os.path.join(os.path.dirname(__file__), 'person_names.txt'), 'rb', 'utf-8') as f:\n        known_persons = set((l.rstrip() for l in f))\n    writer = UnicodeWriter(open(out, 'wb'), delimiter=';')\n    for cable in cables_from_source(path):\n        content = cable.content_body\n        if not content:\n            continue\n        persons = [person for person in known_persons if person in content]\n        if persons:\n            row = [cable.reference_id]\n            row.extend(persons)\n            writer.writerow(row)", "response": "\\ Walks through the path and generates the CSV file out \\"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a 3D plot showing the values for each parameter at every step.", "response": "def chains(xs, labels=None, truths=None, truth_color=u\"#4682b4\", burn=None,\n    alpha=0.5, fig=None):\n    \"\"\"\n    Create a plot showing the walker values for each parameter at every step.\n\n    :param xs:\n        The samples. This should be a 3D :class:`numpy.ndarray` of size \n        (``n_walkers``, ``n_steps``, ``n_parameters``).\n\n    :type xs:\n        :class:`numpy.ndarray`\n\n    :param labels: [optional]\n        Labels for all the parameters.\n\n    :type labels:\n        iterable of strings or None\n\n    :param truths: [optional]\n        Reference values to indicate on the plots.\n\n    :type truths:\n        iterable of floats or None\n\n    :param truth_color: [optional]\n        A ``matplotlib`` style color for the ``truths`` markers.\n\n    :param burn: [optional]\n        Reference step to indicate on the plots.\n\n    :type burn:\n        integer or None\n\n    :param alpha: [optional]\n        Transparency of individual walker lines between zero and one.\n\n    :type alpha:\n        float\n\n    :param fig: [optional]\n        Overplot onto the provided figure object.\n\n    :type fig:\n        :class:`matplotlib.Figure` or None\n    \n    :raises ValueError:\n        If a ``fig`` is provided with the incorrect number of axes.\n\n    :returns:\n        The chain figure.\n\n    :rtype:\n        :class:`matplotlib.Figure`\n    \"\"\"\n\n    n_walkers, n_steps, K = xs.shape\n\n    if labels is not None:\n        assert len(labels) == K\n\n    if truths is not None:\n        assert len(truths) == K\n\n    factor = 2.0\n    lbdim = 0.5 * factor\n    trdim = 0.2 * factor\n    whspace = 0.10\n    width = 15.\n    height = factor*K + factor * (K - 1.) * whspace\n    dimy = lbdim + height + trdim\n    dimx = lbdim + width + trdim\n\n    if fig is None:\n        fig, axes = plt.subplots(K, 1, figsize=(dimx, dimy))\n\n    else:\n        try:\n            axes = np.array(fig.axes).reshape((1, K))\n        except:\n            raise ValueError(\"Provided figure has {0} axes, but data has \"\n                \"parameters K={1}\".format(len(fig.axes), K))\n\n    lm = lbdim / dimx\n    bm = lbdim / dimy\n    trm = (lbdim + height) / dimy\n    fig.subplots_adjust(left=lm, bottom=bm, right=trm, top=trm,\n        wspace=whspace, hspace=whspace)\n    if K == 1:\n        axes = [axes]\n\n    for k, ax in enumerate(axes):\n\n        for walker in range(n_walkers):\n            ax.plot(xs[walker, :, k], color=\"k\", alpha=alpha)\n\n        if burn is not None:\n            ax.axvline(burn, color=\"k\", linestyle=\":\")\n\n        if truths is not None:\n            ax.axhline(truths[k], color=truth_color, lw=2)\n\n        ax.set_xlim(0, n_steps)\n        if k < K - 1:\n            ax.set_xticklabels([])\n        else:\n            ax.set_xlabel(\"Step\")\n\n        ax.yaxis.set_major_locator(MaxNLocator(4))\n        [l.set_rotation(45) for l in ax.get_yticklabels()]\n        if labels is not None:\n            ax.set_ylabel(labels[k])\n            ax.yaxis.set_label_coords(-0.05, 0.5)\n\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef acceptance_fractions(mean_acceptance_fractions, burn=None, ax=None):\n\n\n    factor = 2.0\n    lbdim = 0.2 * factor\n    trdim = 0.2 * factor\n    whspace = 0.10\n    dimy = lbdim + factor + trdim\n    dimx = lbdim + factor + trdim\n\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.figure\n\n    lm = lbdim / dimx\n    bm = lbdim / dimy\n    trm = (lbdim + factor) / dimy\n    fig.subplots_adjust(left=lm, bottom=bm, right=trm, top=trm,\n        wspace=whspace, hspace=whspace)\n\n    ax.plot(mean_acceptance_fractions, color=\"k\", lw=2)\n\n    if burn is not None:\n        ax.axvline(burn, linestyle=\":\", color=\"k\")\n\n    ax.set_xlim(0, len(mean_acceptance_fractions))\n\n    ax.xaxis.set_major_locator(MaxNLocator(5))\n    [l.set_rotation(45) for l in ax.get_xticklabels()]\n    ax.yaxis.set_major_locator(MaxNLocator(5))\n    [l.set_rotation(45) for l in ax.get_yticklabels()]\n\n    ax.set_xlabel(\"Step\")\n    ax.set_ylabel(\"$\\langle{}a_f\\\\rangle$\")\n    fig.tight_layout()\n\n    return fig", "response": "Plots the mean a cceptance fractions for each MCMC step."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the autocorrelation function for each parameter of a sampler chain.", "response": "def normalised_autocorrelation_function(chain, index=0, burn=None, \n    limit=None, fig=None, figsize=None):\n    \"\"\"\n    Plot the autocorrelation function for each parameter of a sampler chain.\n\n    :param chain:\n        The sampled parameter values.\n\n    :type chain:\n        :class:`numpy.ndarray`\n\n    :param index: [optional]\n        Index to calculate the autocorrelation from.\n\n    :type index:\n        int\n\n    :param limit: [optional]\n        Maximum number of MCMC steps to display. By default half of the chain\n        will be shown.\n\n    :type limit:\n        int\n\n    :param fig: [optional]\n        Figure class to use.\n\n    :type fig:\n        :class:`matplotlib.Figure` or None\n\n    :param figsize: [optional]\n        The figure size (x-dimension, y-dimension) in inches.\n\n    :type figsize:\n        tuple or None\n    \"\"\"\n\n    factor = 2.0\n    lbdim = 0.2 * factor\n    trdim = 0.2 * factor\n    whspace = 0.10\n    dimy = lbdim + factor + trdim\n    dimx = lbdim + factor + trdim\n\n    if fig is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        ax = fig.axes[0]\n\n    lm = lbdim / dimx\n    bm = lbdim / dimy\n    trm = (lbdim + factor) / dimy\n    fig.subplots_adjust(left=lm, bottom=bm, right=trm, top=trm,\n        wspace=whspace, hspace=whspace)\n\n    # Calculate the autocorrelation function for each parameter\n    num_parameters = chain.shape[2]\n    for i in xrange(num_parameters):\n        try:\n            rho = emcee.autocorr.function(np.mean(chain[:, index:, i], axis=0))\n        except RuntimeError:\n            logger.exception(\"Error in calculating auto-correlation function \"\\\n                \"for parameter index {}\".format(i))\n        else:\n            ax.plot(rho, \"k\", lw=1)\n\n    if burn:\n        ax.axvline(burn, linestyle=\":\", color=\"k\")\n\n    ax.xaxis.set_major_locator(MaxNLocator(5))\n    [l.set_rotation(45) for l in ax.get_xticklabels()]\n    \n    ax.set_yticks([-0.5, 0, 0.5, 1.0])\n    [l.set_rotation(45) for l in ax.get_yticklabels()]\n\n    ax.axhline(0, color=\"k\")\n    ax.set_xlim(0, limit if limit is not None else chain.shape[1] - index)\n    ax.set_xlabel(\"$\\\\tau$\")\n    ax.set_ylabel(\"Auto-correlation\")\n\n    fig.tight_layout()\n\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprojecting the maximum likelihood values and sampled posterior points as spectra. :param model: The model employed. :type model: :class:`sick.models.Model` :param data: The observed spectra. :type data: iterable of :class:`sick.specutils.Spectrum1D` objects :param theta: [optional] The optimised model parameters given the data. Either theta or chain should be given. :type theta: dict :param chain: [optional] The chain of sampled parameters. :type chain: :class:`numpy.ndarray` :param extents: [optional] The wavelength extents to plot for each channel in the form of [(min_chan_1, max_chan_1), ..., (min_chan_N, max_chan_N)] :type extents: tuple or None :param uncertainties: [optional] Show uncertainty of the data points. :type uncertainties: bool :param title: [optional] Title to set for the top axes. :type title: str :param fig: [optional] Overplot onto the provided figure object. :type fig: :class:`matplotlib.Figure` or None :param figsize: [optional] The figure size (x-dimension, y-dimension) in inches. :type figsize: tuple or None :raises ValueError: If a ``fig`` is provided with the incorrect number of axes. :raise TypeError: If the ``data`` are not provided in the correct type. :returns: The projection figure. :rtype: :class:`maplotlib.Figure`", "response": "def old_projection(model, data, theta=None, chain=None, n=100, extents=None, \n    uncertainties=True, title=None, fig=None, figsize=None):\n    \"\"\"\n    Project the maximum likelihood values and sampled posterior points as \n    spectra.\n\n    :param model:\n        The model employed.\n\n    :type model:\n        :class:`sick.models.Model`\n\n    :param data:\n        The observed spectra.\n\n    :type data:\n        iterable of :class:`sick.specutils.Spectrum1D` objects\n\n    :param theta: [optional]\n        The optimised model parameters given the data. Either theta\n        or chain should be given.\n\n    :type theta:\n        dict\n\n    :param chain: [optional]\n        The chain of sampled parameters.\n\n    :type chain:\n        :class:`numpy.ndarray`    \n\n    :param extents: [optional]\n        The wavelength extents to plot for each channel in the form of \n        [(min_chan_1, max_chan_1), ..., (min_chan_N, max_chan_N)]\n    \n    :type extents:\n        tuple or None\n\n    :param uncertainties: [optional]\n        Show uncertainty of the data points.\n\n    :type uncertainties:\n        bool\n\n    :param title: [optional]\n        Title to set for the top axes.\n\n    :type title:\n        str\n\n    :param fig: [optional]\n        Overplot onto the provided figure object.\n\n    :type fig:\n        :class:`matplotlib.Figure` or None\n    \n    :param figsize: [optional]\n        The figure size (x-dimension, y-dimension) in inches.\n\n    :type figsize:\n        tuple or None\n\n    :raises ValueError:\n        If a ``fig`` is provided with the incorrect number of axes.\n\n    :raise TypeError:\n        If the ``data`` are not provided in the correct type.\n\n    :returns:\n        The projection figure.\n\n    :rtype:\n        :class:`maplotlib.Figure`\n    \"\"\"\n    if not isinstance(data, (tuple, list)) or \\\n    any([not isinstance(each, specutils.Spectrum1D) for each in data]):\n        raise TypeError(\"Data must be a list-type of Spectrum1D objects.\")\n\n    K = len(data)\n\n    factor = 2.0\n    lbdim = 0.5 * factor\n    trdim = 0.2 * factor\n    whspace = 0.10\n    width = np.max([len(each.disp) for each in data])/500.\n    height = factor*K + factor * (K - 1.) * whspace\n    dimy = lbdim + height + trdim\n    dimx = lbdim + width + trdim\n\n    if figsize is None:\n        figsize = (dimx, dimy)\n    if fig is None:\n        fig, axes = plt.subplots(K, 1, figsize=figsize)\n\n    else:\n        try:\n            axes = np.array(fig.axes).reshape((K, 1))\n        except:\n            raise ValueError(\"Provided figure has {0} axes, but data has \"\n                \"parameters K={1}\".format(len(fig.axes), K))\n\n    if chain is not None:\n\n        flat_chain = chain.reshape(-1, len(model.parameters))\n        map_theta = np.mean(flat_chain, axis=0)\n\n        try:\n            map_fluxes = model(data=data, **model._dictify_theta(map_theta))\n        except:\n            logger.warn(\"Could not draw MAP fluxes from posterior\")\n\n        if n > 0:\n            # Draw samples from sampler.chain and compute spectra for them\n            sampled_fluxes = []\n            n_samples = len(flat_chain)\n\n            for i in range(n):\n                sampled_theta = dict(zip(model.parameters,\n                    flat_chain[np.random.randint(0, n_samples)]))\n                try:\n                    sampler_flux = model(data=data, **sampled_theta)\n                except:\n                    logger.warn(\"Could not draw sample flux from posterior\")\n                    continue\n                else:\n                    sampled_fluxes.append(sampler_flux)\n        \n    elif theta is not None:\n\n        sampled_fluxes = []\n        map_fluxes = model(data=data, **model._dictify_theta(theta))\n        \n    else:\n        raise ValueError(\"either theta or chain should be given\")\n\n\n    if len(data) == 1:\n        axes = [axes]\n\n    for k, (map_flux, observed_spectrum) in enumerate(zip(map_fluxes, data)):\n\n        ax = axes[k]\n\n        # Draw the random samples from the chain\n        if n > 0:\n            for sampled_flux in sampled_fluxes:\n                ax.plot(observed_spectrum.disp, sampled_flux[k], color=\"r\",\n                    alpha=0.5, zorder=90)\n\n        # Draw the ML spectra\n        ax.plot(observed_spectrum.disp, map_flux, color=\"r\", lw=2, zorder=100)\n\n        # Plot the data\n        if uncertainties:\n            ax.fill_between(observed_spectrum.disp,\n                observed_spectrum.flux - observed_spectrum.variance**0.5,\n                observed_spectrum.flux + observed_spectrum.variance**0.5,\n                facecolor=\"#cccccc\", edgecolor=\"#666666\", zorder=-1)\n        ax.plot(observed_spectrum.disp, observed_spectrum.flux, color=\"k\",\n            zorder=10)\n\n        # By default only show common overlap between the model and data\n        if extents is None:\n            finite_data = np.isfinite(observed_spectrum.flux)\n            finite_model = np.isfinite(map_flux)\n            finite_points = (finite_model, finite_data)\n\n            x_extent = [\n                np.max([observed_spectrum.disp[s][0]  for s in finite_points]),\n                np.min([observed_spectrum.disp[s][-1] for s in finite_points]),\n            ]\n\n            indices = observed_spectrum.disp.searchsorted(x_extent)\n            finite_flux = observed_spectrum.flux[indices[0]:indices[1]]\n\n            if len(finite_flux) > 0:\n                #y_extent = [\n                #    0.9 * np.min(finite_flux[np.isfinite(finite_flux)]),\n                #    1.1 * np.max(finite_flux[np.isfinite(finite_flux)])\n                #]\n                ax.set_ylim([0.9, 1.1] * np.percentile(finite_flux[np.isfinite(finite_flux)], [0.5, 99.5]))\n\n            ax.set_xlim(x_extent)\n\n        else:\n            ax.set_xlim(extents[k][0])\n            ax.set_ylim(extents[k][1])\n\n        # Labels and ticks\n        if not (k < K - 1):\n            ax.set_xlabel(\"Wavelength, $\\lambda$ ($\\AA$)\")\n\n        ax.set_ylabel(\"Flux, $F_\\lambda$\")\n        ax.yaxis.set_label_coords(-0.05, 0.5)\n\n        ax.xaxis.set_major_locator(MaxNLocator(5))\n        ax.yaxis.set_major_locator(MaxNLocator(5))\n        [l.set_rotation(45) for l in ax.get_yticklabels()]\n\n\n    if title is not None and isinstance(title, (str, unicode)):\n        axes[0].set_title(title)\n\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_a(html, find=''):\n    links = []\n    for a in html.find_all('a'):\n        if a.get('href').find(find) != -1:\n            links.append(a)\n    return links", "response": "Finds all the a tags with find in their href"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef episode_list(a):\n    html = get_html(ROOT + a.get('href'))\n    div = html.find('div', {'class': \"list detail eplist\"})\n    links = []\n    for tag in div.find_all('a', {'itemprop': \"name\"}):\n        links.append(tag)\n    return links", "response": "List of all episodes of a season"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing an episode and returns a season and a dictionary of data related to it", "response": "def parse_episode(a):\n    \"\"\"Collects data related to an episode\"\"\"\n    d = {}\n    html = get_html(ROOT + a.get('href'))\n    d['rating'] = get_rating(html)\n    d['episode-name'], d['date'] = get_name_date(html)\n    season, d['episode-num'] = get_season_epi_num(html)\n    return season, d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a Tv Series returns the dataset as a dictionary", "response": "def parse(link):\n    \"\"\"Parses a Tv Series\n    returns the dataset as a dictionary\n    \"\"\"\n    html = get_html(link)\n\n    data = {'rating': get_rating(html),\n            'name': get_name_date(html)[0]}\n\n    div = html.find(id=\"title-episode-widget\")\n    season_tags = get_a(div, find=\"season=\")\n    episodes = {}\n    for slink in season_tags:\n        for e in episode_list(slink):\n            season, d = parse_episode(e)\n            if season in episodes:\n                episodes[season].append(d)\n            else:\n                episodes[season] = [d]\n    data['episodes'] = episodes\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds classification context to views.", "response": "def classification(request):\n    \"\"\"\n    Adds classification context to views.\n    \"\"\"\n\n    ctx = {\n        'classification_text': getattr(settings, 'CLASSIFICATION_TEXT', 'UNCLASSIFIED'),\n        'classification_text_color': getattr(settings, 'CLASSIFICATION_TEXT_COLOR', 'white'),\n        'classification_background_color': getattr(settings, 'CLASSIFICATION_BACKGROUND_COLOR', 'green'),\n        'classification_banner_enabled': getattr(settings, 'CLASSIFICATION_BANNER_ENABLED', True),\n        'classification_link': getattr(settings, 'CLASSIFICATION_LINK', None)\n    }\n\n    return ctx"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_locations(self, zone_file):\n        self._zone_file = zone_file\n        field_names = ('country', 'location', 'zone', 'comments')\n\n        data = utils.prepare_csv_read(zone_file, field_names, delimiter=r\"\t\")\n\n        for row in (x for x in data if not x['country'].startswith('#')):\n            if row['comments']:\n                row['comments'] = row['comments'].split(', ')\n            self.append(Zone(**row))", "response": "Parse zoneinfo zone description data files and return a list of zones."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_zone_file(self):\n        data = []\n        for zone in sorted(self, key=attrgetter('country')):\n            text = ['%s\t%s\t%s'\n                    % (zone.country,\n                       utils.to_iso6709(zone.latitude, zone.longitude,\n                                        format='dms')[:-1],\n                       zone.zone), ]\n            if zone.comments:\n                text.append('\t%s' % ', '.join(zone.comments))\n            data.append(''.join(text))\n        return data", "response": "Generate a zoneinfo compatible zone description table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_locations(self, data, index='WMO'):\n        self._data = data\n        data = utils.prepare_read(data)\n\n        for line in data:\n            line = line.strip()\n            chunk = line.split(';')\n            if not len(chunk) == 14:\n                if index == 'ICAO':\n                    # Some entries only have 12 or 13 elements, so we assume 13\n                    # and 14 are None.  Of the entries I've hand checked this\n                    # assumption would be correct.\n                    logging.debug('Extending ICAO %r entry, because it is '\n                                  'too short to process' % line)\n                    chunk.extend(['', ''])\n                elif index == 'WMO' and len(chunk) == 13:\n                    # A few of the WMO indexed entries are missing their RBSN\n                    # fields, hand checking the entries for 71046 and 71899\n                    # shows that they are correct if we just assume RBSN is\n                    # false.\n                    logging.debug('Extending WMO %r entry, because it is '\n                                  'too short to process' % line)\n                    chunk.append('')\n                else:\n                    raise utils.FileFormatError('NOAA')\n            if index == 'WMO':\n                identifier = ''.join(chunk[:2])\n                alt_id = chunk[2]\n            elif index == 'ICAO':\n                identifier = chunk[0]\n                alt_id = ''.join(chunk[1:3])\n            else:\n                raise ValueError('Unknown format %r' % index)\n            if alt_id in ('----', '-----'):\n                alt_id = None\n            name = chunk[3]\n            state = chunk[4] if chunk[4] else None\n            country = chunk[5]\n            wmo = int(chunk[6]) if chunk[6] else None\n            point_data = []\n            for i in chunk[7:11]:\n                if not i:\n                    point_data.append(None)\n                    continue\n                # Some entries in nsd_cccc.txt are of the format \"DD-MM-\n                # N\", so we just take the spaces to mean 0 seconds.\n                if ' ' in i:\n                    logging.debug('Fixing unpadded location data in %r entry'\n                                  % line)\n                    i = i.replace(' ', '0')\n                values = map(int, i[:-1].split('-'))\n                if i[-1] in ('S', 'W'):\n                    values = [-x for x in values]\n                point_data.append(point.utils.to_dd(*values))\n            latitude, longitude, ua_latitude, ua_longitude = point_data\n            altitude = int(chunk[11]) if chunk[11] else None\n            ua_altitude = int(chunk[12]) if chunk[12] else None\n            rbsn = False if not chunk[13] else True\n            self[identifier] = Station(alt_id, name, state, country, wmo,\n                                       latitude, longitude, ua_latitude,\n                                       ua_longitude, altitude, ua_altitude,\n                                       rbsn)", "response": "Parse the NOAA weather station data files and return a dictionary containing the location information for each object in the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake an identifier and converts it into a key usable by the cache system.", "response": "def convert_identifier_to_key(identifier):\n        \"\"\" Takes an identifier (like a username or IP address) and converts it\n            into a key usable by the cache system.\n        \"\"\"\n        key = ''.join(c for c in identifier if c.isalnum() or c in '_.-')\n        if len(key) > 230:\n            key = key[:150] + '-' + hashlib.md5(key).hexdigest()\n\n        return \"%s_accesses\" % key"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_in(val, items):\n    if isinstance(items, basestring):\n        items = items.split('|')\n    return val in items", "response": "Check if value is in items"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef captureas(parser, arg):\n    args = arg.contents.split()\n    if not 2 <= len(args) <= 3:\n        raise template.TemplateSyntaxError('\"captureas\" node requires a variable name and/or assign only')\n    nodelist = parser.parse(('endcaptureas',))\n    parser.delete_first_token()\n    return CaptureasNode(nodelist, args)", "response": "example: {% captureas myvar 1 %}content...{% endcaptureas %} - {{ myvar }}\n    result: content... - content...\n\n    example: {% captureas myvar %}content...{% endcaptureas %} - {{ myvar }}\n    result: - content..."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip(parser, arg):\n    nodelist = parser.parse(('endstrip',))\n    parser.delete_first_token()\n    return StripNode(nodelist, arg.split_contents())", "response": "Strip an arbitrary text from a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recurse(parser, token):\n    params = token.contents.split()\n    if not 2 <= len(params) <= 3:\n        raise template.TemplateSyntaxError('%s parameters error' % params[0])\n    template_nodes = parser.parse(('endrecurse',))\n    parser.delete_first_token()\n    return RecurseNode(template_nodes,\n                       template.Variable(params[1]),\n                       (params[2][1:-1] if len(params) == 3 else 'children'))", "response": "Iterate recurse data structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender paginator. <<_1_2 3 4 5 6 7 8 9 ... 55 56 57 >> # leading=9 (1..9) out=3 (55..57) << 1 2 3 ... 23 24 25 26_27_28 29 30 31 ... 55 56 57 >> # adjacent = 4 (23..26, 28..31)", "response": "def paginator(context, page, leading=8, out=3, adjacent=3, sep='...'):\n    \"\"\"\n    Render paginator.\n    <<_1_2 3 4 5 6 7 8 9 ... 55 56 57 >>  # leading=9 (1..9)  out=3 (55..57)\n    << 1 2 3 ... 23 24 25 26_27_28 29 30 31 ... 55 56 57 >>  # adjacent = 4 (23..26, 28..31)\n    \"\"\"\n    leading_pages, out_left_pages, out_right_pages, pages = [], [], [], []\n    num_pages = page.paginator.num_pages\n    is_paginated = num_pages > 1\n    if is_paginated:\n        if num_pages < leading:\n            leading_pages = [x for x in range(1, leading) if x <= num_pages]\n        elif page.number <= leading - 1:\n            leading_pages = [x for x in range(1, leading + 1)]\n            out_right_pages = [x + num_pages for x in range(-out + 1, 1) if x + num_pages > leading]\n        elif page.number > num_pages - leading + 1:\n            leading_pages = [x for x in range(num_pages - leading + 1, num_pages + 1) if x <= num_pages]\n            out_left_pages = [x for x in range(1, out + 1) if num_pages - x >= leading]\n        else:\n            leading_pages = [x for x in range(page.number - adjacent, page.number + adjacent + 1)]\n            out_right_pages = [x + num_pages for x in range(-out + 1, 1)]\n            out_left_pages = [x for x in range(1, out + 1)]\n    if out_left_pages:\n        pages.extend(out_left_pages)\n        pages.append(sep)\n    pages.extend(leading_pages)\n    if out_right_pages:\n        pages.append(sep)\n        pages.extend(out_right_pages)\n    return {\n        'page': page,\n        'pages': pages,\n        'is_paginated': is_paginated,\n        'separator': sep,\n        'request': context.get('request'),\n        'param_name': page.param_name if hasattr(page, 'param_name') else 'page',\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the list of handlers that can be used for the action.", "response": "def _get_handlers(self):\r\n        \"\"\"\r\n            \u83b7\u53d6 action.handlers\r\n\r\n            \u6dfb\u52a0\u8def\u5f84 __conf__.ACTION_DIR_NAME \u5217\u8868\u4e2d\u7684 action by ABeen \r\n        \"\"\"\r\n        # \u67e5\u627e\u6240\u6709 Handler\u3002\r\n        members = {}\r\n        for d in __conf__.ACTION_DIR_NAME:\r\n            members.update(get_members(d,\r\n                           None,\r\n                           lambda m: isclass(m) and issubclass(m, BaseHandler) and hasattr(m, \"__urls__\") and m.__urls__))\r\n\r\n        # \u5206\u89e3 __urls__ \u914d\u7f6e\u3002\r\n        handlers = [(pattern, order, h) for h in members.values() for pattern, order in h.__urls__]\r\n\r\n        # \u6392\u5e8f\u3002\r\n        # handlers.sort(cmp = cmp, key = lambda x: x[1])\r\n\r\n        try:\r\n            api_version = __conf__.API_VERSION\r\n        except Exception as e:\r\n            api_version = ''\r\n\r\n        handlers = [(api_version + pattern, handler) for pattern, _, handler in handlers]\r\n\r\n        handlers.append((r'^/(.*?)$', tornado.web.StaticFileHandler, {\"path\":\"static\", \"default_filename\":\"index.html\"}))\r\n        return handlers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_webapp(self):\r\n        settings = {\r\n            \"PORT\"          : self._port,\r\n            #\"static_path\"   : app_path(__conf__.STATIC_DIR_NAME),\r\n            #\"template_path\" : app_path(__conf__.TEMPLATE_DIR_NAME),\r\n            \"debug\"         : __conf__.DEBUG,\r\n            \"cookie_secret\" : __conf__.COOKIE_SECRET\r\n        }\r\n\r\n        self.settings.update(settings)\r\n        return WebApplication(self._handlers, **settings)", "response": "Returns a new instance of the WebApplication class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_server(self):\r\n        try:\r\n            if __conf__.DEBUG:\r\n                self._webapp.listen(self._port)\r\n            else:\r\n                server = HTTPServer(self._webapp)\r\n                server.bind(self._port)\r\n                server.start(0)\r\n\r\n            IOLoop.current().start()\r\n        except KeyboardInterrupt:\r\n            print (\"exit ...\")", "response": "Run the HTTP server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse command line arguments.", "response": "def handle_args():\n    \"\"\"\n    Default values are defined here.\n    \"\"\"\n    default_database_name = dbconfig.testdb_corpus_url.database\n    parser = argparse.ArgumentParser(\n        prog=os.path.basename(__file__),\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\n    parser.add_argument('dbname',\n                        nargs='?',\n                        default=str(default_database_name),\n                        help='Database name',\n                        )\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef string_chain(text, filters):\n        if filters is None:\n            return text\n\n        for filter_function in filters:\n            text = filter_function(text)\n\n        return text", "response": "Chain several filters after each other applies the filter on the entire string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef token_chain(text, filters):\n        if filters is None:\n            return text\n\n        sb = \"\"\n        for token in RegexFilters.WHITESPACE.split(text):\n            if not classifier_options.is_special_class_word(token):\n                token = Filters.string_chain(token, filters)\n\n            sb += token + \" \"\n\n        return sb", "response": "This function will chain several filters after each other."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges the intensity of light of the front panel of the box.", "response": "def set_display_luminosity(self, luminosity):\n        \"\"\"\n        Change the intensity of light of the front panel of the box\n        :param luminosity: must be between 0 (light off) and 100\n        :type luminosity: int\n        \"\"\"\n        if (luminosity < 0) or (luminosity > 100):\n            raise ValueError(\"Luminosity must be between 0 and 100\")\n        self.bbox_auth.set_access(BboxConstant.AUTHENTICATION_LEVEL_PRIVATE,\n                                  BboxConstant.AUTHENTICATION_LEVEL_PRIVATE)\n        self.bbox_url.set_api_name(BboxConstant.API_DEVICE, \"display\")\n        data = {'luminosity': luminosity}\n        api = BboxApiCall(self.bbox_url, BboxConstant.HTTP_METHOD_PUT, data,\n                          self.bbox_auth)\n        api.execute_api_request()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reboot(self):\n        token = self.get_token()\n        self.bbox_auth.set_access(BboxConstant.AUTHENTICATION_LEVEL_PRIVATE, BboxConstant.AUTHENTICATION_LEVEL_PRIVATE)\n        url_suffix = \"reboot?btoken={}\".format(token)\n        self.bbox_url.set_api_name(BboxConstant.API_DEVICE, url_suffix)\n        api = BboxApiCall(self.bbox_url, BboxConstant.HTTP_METHOD_POST, None,\n                          self.bbox_auth)\n        api.execute_api_request()", "response": "Reboot the device\n        Used when trying to get xDSL sync\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_token(self):\n        self.bbox_auth.set_access(BboxConstant.AUTHENTICATION_LEVEL_PRIVATE, BboxConstant.AUTHENTICATION_LEVEL_PRIVATE)\n        self.bbox_url.set_api_name(BboxConstant.API_DEVICE, \"token\")\n        api = BboxApiCall(self.bbox_url, BboxConstant.HTTP_METHOD_GET, None,\n                          self.bbox_auth)\n        resp = api.execute_api_request()\n        return resp.json()[0]['device']['token']", "response": "Get a token from the API"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all connected devices", "response": "def get_all_connected_devices(self):\n        \"\"\"\n        Get all info about devices connected to the box\n        :return: a list with each device info\n        :rtype: list\n        \"\"\"\n        self.bbox_auth.set_access(BboxConstant.AUTHENTICATION_LEVEL_PUBLIC, BboxConstant.AUTHENTICATION_LEVEL_PRIVATE)\n        self.bbox_url.set_api_name(BboxConstant.API_HOSTS, None)\n        api = BboxApiCall(self.bbox_url, BboxConstant.HTTP_METHOD_GET, None,\n                          self.bbox_auth)\n        resp = api.execute_api_request()\n        return resp.json()[0][\"hosts\"][\"list\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a device identified by ip is connected to the box", "response": "def is_device_connected(self, ip):\n        \"\"\"\n        Check if a device identified by it IP is connected to the box\n        :param ip: IP of the device you want to test\n        :type ip: str\n        :return: True is the device is connected, False if it's not\n        :rtype: bool\n        \"\"\"\n        all_devices = self.get_all_connected_devices()\n        for device in all_devices:\n            if ip == device['ipaddress']:\n                return device['active'] == 1\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef logout(self):\n        self.bbox_auth.set_access(BboxConstant.AUTHENTICATION_LEVEL_PUBLIC, BboxConstant.AUTHENTICATION_LEVEL_PUBLIC)\n        self.bbox_url.set_api_name(\"logout\", None)\n        api = BboxApiCall(self.bbox_url, BboxConstant.HTTP_METHOD_POST, None,\n                          self.bbox_auth)\n        response = api.execute_api_request()\n        if response.status_code == 200:\n            self.bbox_auth.set_cookie_id(None)\n        return not self.bbox_auth.is_authentified()", "response": "Logout the user from the box."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all stats about your xdsl connection", "response": "def get_xdsl_stats(self):\n        \"\"\"\n        Get all stats about your xDSL connection\n        :return: A dict with all stats about your xdsl connection (see API doc)\n        :rtype: dict\n        \"\"\"\n        self.bbox_auth.set_access(BboxConstant.AUTHENTICATION_LEVEL_PUBLIC, BboxConstant.AUTHENTICATION_LEVEL_PRIVATE)\n        self.bbox_url.set_api_name(BboxConstant.API_WAN, \"xdsl/stats\")\n        api = BboxApiCall(self.bbox_url, BboxConstant.HTTP_METHOD_GET, None,\n                          self.bbox_auth)\n        resp = api.execute_api_request()\n        return resp.json()[0][\"wan\"][\"xdsl\"][\"stats\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the percentage of the current used xdsl upload bandwith Instant measure can be very different from one call to another", "response": "def get_up_used_bandwith(self):\n        \"\"\"\n        Return a percentage of the current used xdsl upload bandwith\n        Instant measure, can be very different from one call to another\n        :return: 0 no bandwith is used, 100 all your bandwith is used\n        :rtype: int\n        \"\"\"\n        ip_stats_up = self.get_ip_stats()['tx']\n        percent = ip_stats_up['bandwidth']*100/ip_stats_up['maxBandwidth']\n        return int(percent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the percentage of the current used xdsl download bandwith Instant measure can be very different from one call to another Instant measure can be very different from one call to another Instant measure can be very different from one call to another", "response": "def get_down_used_bandwith(self):\n        \"\"\"\n        Return a percentage of the current used xdsl download bandwith\n        Instant measure, can be very different from one call to another\n        :return: 0 no bandwith is used, 100 all your bandwith is used\n        :rtype: int\n        \"\"\"\n        ip_stats_up = self.get_ip_stats()['rx']\n        percent = ip_stats_up['bandwidth']*100/ip_stats_up['maxBandwidth']\n        return int(percent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear the bad connection", "response": "def _clear(reason, idle_pool, using_pool, channel_pool, conn_id):\n        \"\"\"\n        clear the bad connection\n        :param reason:\n        :param idle_pool:\n        :param using_pool:\n        :param channel_pool:\n        :param conn_id:\n        :return:\n        \"\"\"\n        with _lock():\n            try:\n                idle_pool.pop(conn_id)\n                logger.info('a connection lost when not using')\n            except KeyError:\n                if using_pool.pop(conn_id, None):\n                    logger.warn('connection lost when using, should be handled later')\n                    return reason\n            finally:\n                channel_pool.pop(conn_id, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunpacking the error response from a binary string.", "response": "def from_binary_string(self, stream):\n        \"\"\"Unpack the error response from a stream.\"\"\"\n        command, code, identifier = struct.unpack(self.FORMAT, stream)\n\n        if command != self.COMMAND:\n            raise ErrorResponseInvalidCommandError()\n\n        if code not in self.CODES:\n            raise ErrorResponseInvalidCodeError()\n\n        self.code = code\n        self.name = self.CODES[code]\n        self.identifier = identifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npacks the error response to binary string and return it.", "response": "def to_binary_string(self, code, identifier):\n        \"\"\"Pack the error response to binary string and return it.\"\"\"\n        return struct.pack(self.FORMAT, self.COMMAND, code, identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhashes input_text with the algorithm choice", "response": "def hash(hash_type, input_text):\n    '''Hash input_text with the algorithm choice'''\n    hash_funcs = {'MD5' : hashlib.md5,\n                  'SHA1' : hashlib.sha1,\n                  'SHA224' : hashlib.sha224,\n                  'SHA256' : hashlib.sha256,\n                  'SHA384' : hashlib.sha384,\n                  'SHA512' : hashlib.sha512}\n    if hash_type == 'All':\n        hash_type = ['MD5', 'SHA1', 'SHA224', 'SHA256', 'SHA384', 'SHA512']\n    else:\n        hash_type = [hash_type]\n    return [{'Algorithm' : h, 'Hash' : hash_funcs[h](input_text).hexdigest()}\n            for h in hash_type]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove duplicates from a list of dictionaries preserving the order.", "response": "def dedupe_list_of_dicts(ld):\n    \"\"\"Remove duplicates from a list of dictionaries preserving the order.\n\n    We can't use the generic list helper because a dictionary isn't hashable.\n    Adapted from http://stackoverflow.com/a/9427216/374865.\n    \"\"\"\n    def _freeze(o):\n        \"\"\"Recursively freezes a dict into an hashable object.\n\n        Adapted from http://stackoverflow.com/a/21614155/374865.\n        \"\"\"\n        if isinstance(o, dict):\n            return frozenset((k, _freeze(v)) for k, v in six.iteritems(o))\n        elif isinstance(o, (list, tuple)):\n            return tuple(_freeze(v) for v in o)\n        else:\n            return o\n\n    result = []\n    seen = set()\n\n    for d in ld:\n        f = _freeze(d)\n        if f not in seen:\n            result.append(d)\n            seen.add(f)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate destination from locations.", "response": "def destination(globs, locator, distance, bearing):\n    \"\"\"Calculate destination from locations.\"\"\"\n    globs.locations.destination(distance, bearing, locator)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npulling locations from a user s config file.", "response": "def read_locations(filename):\n    \"\"\"Pull locations from a user's config file.\n\n    Args:\n        filename (str): Config file to parse\n\n    Returns:\n        dict: List of locations from config file\n    \"\"\"\n    data = ConfigParser()\n    if filename == '-':\n        data.read_file(sys.stdin)\n    else:\n        data.read(filename)\n    if not data.sections():\n        logging.debug('Config file is empty')\n\n    locations = {}\n    for name in data.sections():\n        if data.has_option(name, 'locator'):\n            latitude, longitude = utils.from_grid_locator(data.get(name,\n                                                                   'locator'))\n        else:\n            latitude = data.getfloat(name, 'latitude')\n            longitude = data.getfloat(name, 'longitude')\n        locations[name] = (latitude, longitude)\n    return locations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_csv(filename):\n    field_names = ('latitude', 'longitude', 'name')\n    data = utils.prepare_csv_read(filename, field_names, skipinitialspace=True)\n    locations = {}\n    args = []\n    for index, row in enumerate(data, 1):\n        name = '%02i:%s' % (index, row['name'])\n        locations[name] = (row['latitude'], row['longitude'])\n        args.append(name)\n    return locations, args", "response": "Pull locations from a user s CSV output format\n   .. _gpsbabel. org"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an application for URL dispatching", "response": "def make_urldispatch_application(_, **settings):\n    \"\"\" paste.app_factory interface for URLDispatcher\"\"\"\n    patterns = [p.split(\"=\", 1)\n                for p in settings['patterns'].split('\\n')\n                if p]\n    application = URLDispatcher()\n\n    for pattern, app in patterns:\n        pattern = pattern.strip()\n        app = app.strip()\n        mod, obj = app.split(\":\", 1)\n        if mod not in sys.modules:\n            __import__(mod)\n        mod = sys.modules[mod]\n        obj = getattr(mod, obj)\n        application.add_url(app, pattern, obj)\n\n    return application"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _dig(obj, *key):\n    key = _splice_index(*key)\n\n    if len(key) == 1:\n        return obj[key[0]]\n    return _dig(obj[key[0]], *key[1:])", "response": "Recursively lookup an item in a nested dictionary using an array of indexes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dig_get(obj, default, *key):\n    key = _splice_index(*key)\n\n    if len(key) == 1:\n        if isinstance(key[0], str):\n            return obj.get(key[0], default)\n        else:\n            try:\n                return obj[key[0]]\n            except IndexError:\n                return default\n\n    return _dig_get(obj[key[0]], default, *key[1:])", "response": "Recursively lookup an item in a nested dictionary using an array of indexes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dug(obj, key, value):\n    array = key.split(\".\")\n    return _dug(obj, value, *array)", "response": "Inverse of dig set a value in a dictionary using\n    dot notation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef union_setadd(dict1, dict2):\n    for key2, val2 in dict2.items():\n        # if key is in both places, do a union\n        if key2 in dict1:\n            # if dict2 val2 is a dict, assume dict1 val2 is as well\n            if isinstance(val2, dict):\n                dict1[key2] = union_setadd(dict1[key2], val2)\n            # if dict2 val2 is a list, things get uglier\n            elif isinstance(val2, list):\n                val1 = dict1[key2]\n                # both dict1/dict2 need to be lists\n                if not isinstance(val1, list):\n                    raise TypeError(\"dict1[{}] is not a list where dict2[{}] is.\".format(key2, key2))\n                # ignore zero length val2 (string or list)\n                if not len(val2):\n                    continue\n                # if val2's first element is a dict, assume they are all dicts\n                if isinstance(val2[0], dict):\n                    for xelem in range(0, len(val2)):\n                        if xelem < len(val1):\n                            val1[xelem] = union_setadd(val1[xelem], val2[xelem])\n                        else:\n                            val1.append(val2[xelem])\n                # otherwise just setadd the elements by value; order can get wonky\n                else:\n                    for elem in val2:\n                        if elem not in val1: # inefficient\n                            val1.append(elem)\n                dict1[key2] = val1\n            # any other type: just assign\n            else:\n                dict1[key2] = val2\n        # or just define it\n        else:\n            dict1[key2] = val2\n    return dict1", "response": "This function is used to add two dicts to a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _union_copy(dict1, dict2):\n\n    for key, value in dict2.items():\n        if key in dict1 and isinstance(value, dict):\n            dict1[key] = _union_copy(dict1[key], value)\n        else:\n            dict1[key] = copy.deepcopy(value)\n    return dict1", "response": "Recursively copies dict2 into dict1."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of attribute references in the condition expression.", "response": "def get_attribute_references(instring):\n    \"\"\"\n    Return a list of attribute references in the condition expression.\n\n    attribute_reference ::= relation_name \".\" attribute_name | attribute_name\n\n    :param instring: a condition expression.\n    :return: a list of attribute references.\n    \"\"\"\n    parsed = ConditionGrammar().conditions.parseString(instring)\n    result = parsed if isinstance(parsed[0], str) else parsed[0]\n    return result.attribute_reference.asList() if result.attribute_reference else []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconditioning ::= condition | condition logical_binary_op conditions Note: By default lpar and rpar arguments are suppressed.", "response": "def conditions(self):\n        \"\"\"\n        conditions ::= condition | condition logical_binary_op conditions\n        Note: By default lpar and rpar arguments are suppressed.\n        \"\"\"\n        return operatorPrecedence(\n            baseExpr=self.condition,\n            opList=[(self.not_op, 1, opAssoc.RIGHT),\n                    (self.logical_binary_op, 2, opAssoc.LEFT)],\n            lpar=self.syntax.paren_left,\n            rpar=self.syntax.paren_right)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    '''Main entry point for the bioinfo CLI.'''\n    args = docopt(__doc__, version=__version__)\n\n    if 'bam_coverage' in args:\n        bam_coverage(args['<reference>'],\n                     args['<alignments>'],\n                     int(args['<minmatch>']),\n                     min_mapq=int(args['--mapq']),\n                     min_len=float(args['--minlen']))", "response": "Entry point for the bioinfo CLI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the job from the job_dict and yield MiuraJenkinsJob objects.", "response": "def parse_job(self, run_method, options):\n        \"\"\"\n        Generates and returns a job object with the following:\n\n        * a run method, as defined in the readme\n        * a list of posix-like arguments\n        * a dictionary of data\n        * templates: a dict-like interface of (template_name, template_body) pairs\n        \"\"\"\n\n        for job_dict in run_method(options, self._data):\n\n            # unpackaging dict\n            host = job_dict['host']\n            name = job_dict['name']\n            template = job_dict['template']\n            job_data = {\n                'name': name,\n                'host': host,\n                'job_data': job_dict['job_data']\n            }\n\n            template_body = self._templates[template]\n            config_xml = specialize_content(template_body, job_data)\n\n            yield MiuraJenkinsJob(\n                self._jenkinsapi_cache[host],\n                name,\n                config_xml\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates or update the jenkins job", "response": "def upsert(self):\n        \"\"\" create or update the jenkins job \"\"\"\n        if not self.jenkins_host.has_job(self.name):\n            LOGGER.info(\"creating {0}...\".format(self.name))\n            self.jenkins_host.create_job(self.name, self.config_xml)\n        else:\n            jenkins_job = self.jenkins_host[self.name]\n            LOGGER.info(\"updating {0}...\".format(self.name))\n            jenkins_job.update_config(self.config_xml)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        if self.jenkins_host.has_job(self.name):\n            LOGGER.info(\"deleting {0}...\".format(self.name))\n            self.jenkins_host.delete_job(self.name)", "response": "delete the jenkins job"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints information about the jenkins job", "response": "def dry_run(self):\n        \"\"\" print information about the jenkins job \"\"\"\n        LOGGER.info(\"Job Info: {name} -> {host}\".format(\n            name=self.name,\n            host=self.jenkins_host.baseurl\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the first element with the specified tagname and id", "response": "def _find(self, root, tagname, id=None):\n        \"\"\"Returns the first element with the specified tagname and id\"\"\"\n        if id is None:\n            result = root.find('.//%s' % tagname)\n            if result is None:\n                raise LookupError('Cannot find any %s elements' % tagname)\n            else:\n                return result\n        else:\n            result = [\n                elem for elem in root.findall('.//%s' % tagname)\n                if elem.attrib.get('id', '') == id\n            ]\n            if len(result) == 0:\n                raise LookupError('Cannot find a %s element with id %s' % (tagname, id))\n            elif len(result) > 1:\n                raise LookupError('Found multiple %s elements with id %s' % (tagname, id))\n            else:\n                return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _append(self, node, contents):\n        if isinstance(contents, basestring):\n            if contents != '':\n                if len(node) == 0:\n                    if node.text is None:\n                        node.text = contents\n                    else:\n                        node.text += contents\n                else:\n                    last = node[-1]\n                    if last.tail is None:\n                        last.tail = contents\n                    else:\n                        last.tail += contents\n        elif et.iselement(contents):\n            contents.tail = ''\n            node.append(contents)\n        else:\n            try:\n                for content in contents:\n                    self._append(node, content)\n            except TypeError:\n                self._append(node, self._format(contents))", "response": "Adds content to a node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndocumenting the status code per handled case. Additional parameters may make it into the OpenAPI documentation per view. Examples of those parameters include examples={'application/json': <example>}. As schemata are needed in order to render the examples in the Web UI, an error will be signaled if examples= are provided without a schema= parameter. Schemas can be easily built using a specific syntax. TODO: Document the syntax here", "response": "def responds(status=status.HTTP_200_OK,\n             meaning='Undocumented status code',\n             schema=None,\n             schema_name=None,\n             **kwargs):\n    \"\"\"Documents the status code per handled case.\n\n    Additional parameters may make it into the OpenAPI documentation\n    per view. Examples of those parameters include\n    examples={'application/json': <example>}. As schemata are needed\n    in order to render the examples in the Web UI, an error will be\n    signaled if examples= are provided without a schema= parameter.\n\n    Schemas can be easily built using a specific syntax.\n\n    TODO: Document the syntax here\n\n    \"\"\"\n    # TODO: Document syntax in above docstring\n    if status is None:\n        status = 'default'\n    obj = {}\n    obj['description'] = meaning\n\n    if schema:\n        obj['schema'] = parse_schema(schema)\n\n    if schema_name:\n        obj['schema_name'] = schema_name\n\n    obj.update(kwargs)\n\n    def decorator(func):\n        # We do not return a decorator function, we just modify\n        # in-place our function to have the property that we will look\n        # forward later for.\n        if not hasattr(func, '_responses'):\n            func._responses = {}\n        func._responses[status] = obj\n        return func\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef text_input(*args, **kwargs):\n    '''\n    Get multi-line text input as a strong from a textarea form element.\n    '''\n    text_input = wtforms.TextAreaField(*args, **kwargs)\n    text_input.input_type = 'text'\n    return text_input", "response": "Get multi - line text input as a strong from a textarea form element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_input(*args, **kwargs):\n    '''\n    Get a list parsed from newline-delimited entries from a textarea\n    '''\n    list_input = wtforms.TextAreaField(*args, **kwargs)\n    list_input.input_type = 'list'\n    return list_input", "response": "Get a list parsed from newline - delimited entries from a textarea\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef line_input(*args, **kwargs):\n    '''\n    Get a single line of input as a string from a textfield\n    '''\n    line_input = wtforms.TextField(*args, **kwargs)\n    line_input.input_type = 'line'\n    return line_input", "response": "Get a single line of input as a string from a textfield\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a submit button containing the given arguments.", "response": "def submit_button(*args, **kwargs):\n    '''\n    Create a submit button\n    '''\n    submit_button = wtforms.SubmitField(*args, **kwargs)\n    submit_button.input_type = 'submit_button'\n    return submit_button"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multiple_input(*args, **kwargs):\n    '''\n    Multiline input\n    '''\n    multiline_input = wtforms.SelectMultipleField(*args, **kwargs)\n    multiline_input.input_type = 'multiline'\n    return multiline_input", "response": "Returns a Multiline input with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef checkbox_field(*args, **kwargs):\n    '''\n    Checkbox field\n    '''\n    checkbox_field = wtforms.BooleanField(*args, **kwargs)\n    checkbox_field.input_type = 'checkbox_field'\n    return checkbox_field", "response": "Returns a checkbox field with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new file field with the given args and keyword arguments.", "response": "def file_field(*args, **kwargs):\n    '''\n    File field\n    '''\n    file_field = wtforms.FileField(*args, **kwargs)\n    file_field.input_type = 'file_field'\n    return file_field"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a byte string like a QUIT command line and returns a ProxyInfo object.", "response": "def parse_line(line):\n    \"\"\"\n    Parses a byte string like:\n\n       PROXY TCP4 192.168.0.1 192.168.0.11 56324 443\\r\\n\n\n    to a `ProxyInfo`.\n    \"\"\"\n    if not line.startswith(b'PROXY'):\n        raise exc.InvalidLine('Missing \"PROXY\" prefix', line)\n    if not line.endswith(CRLF):\n        raise exc.InvalidLine('Missing \"\\\\r\\\\n\" terminal', line)\n    parts = line[:-len(CRLF)].split(b' ')\n    if len(parts) != 6:\n        raise exc.InvalidLine('Expected 6 \" \" delimited parts', line)\n\n    inet, src_addr, dst_addr = parts[1:4]\n    if inet == b'TCP4':\n        try:\n            socket.inet_pton(socket.AF_INET, src_addr)\n            socket.inet_pton(socket.AF_INET, dst_addr)\n        except socket.error:\n            raise exc.InvalidLine('Invalid INET {0} address(es)'.format(inet), line)\n    elif inet == b'TCP6':\n        try:\n            socket.inet_pton(socket.AF_INET6, src_addr)\n            socket.inet_pton(socket.AF_INET6, dst_addr)\n        except socket.error:\n            raise exc.InvalidLine('Invalid INET {0} address(es)'.format(inet), line)\n    else:\n        raise exc.InvalidLine('Unsupported INET \"{0}\"'.format(inet), line)\n    try:\n        src_port = int(parts[4])\n        dst_port = int(parts[5])\n    except (TypeError, ValueError):\n        raise exc.InvalidLine(line, 'Invalid port')\n\n    return ProxyInfo(\n        source_address=src_addr,\n        source_port=src_port,\n        destination_address=dst_addr,\n        destination_port=dst_port,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing and authenticates proxy protocol information from the request.", "response": "def proxy_protocol(self, error='raise', default=None, limit=None, authenticate=False):\n        \"\"\"\n        Parses, and optionally authenticates, proxy protocol information from\n        request. Note that ``self.request`` is wrapped by ``SocketBuffer``.\n\n        :param error:\n            How read (``exc.ReadError``) and parse (``exc.ParseError``) errors\n            are handled. One of:\n            - \"raise\" to propagate.\n            - \"unread\" to suppress exceptions and unread back to socket.\n        :param default:\n            What to return when no ``ProxyInfo`` was found. Only meaningful\n            with error \"unread\".\n        :param limit:\n            Maximum number of bytes to read when probing request for\n            ``ProxyInfo``.\n\n        :returns: Parsed ``ProxyInfo`` instance or **default** if none found.\n        \"\"\"\n        if error not in ('raise', 'unread'):\n            raise ValueError('error=\"{0}\" is not  \"raise\" or \"unread\"\"')\n        if not isinstance(self.request, SocketBuffer):\n            self.request = SocketBuffer(self.request)\n        if default == 'peer':\n            default = ProxyInfo(\n                self.client_address[0], self.client_address[1],\n                self.client_address[0], self.client_address[1],\n            )\n        try:\n            line = read_line(\n                self.request.sock,\n                self.request.buf,\n                limit=limit,\n            )\n        except exc.ReadError:\n            if error == 'raise':\n                raise\n            return default\n        try:\n            info = parse_line(line)\n        except exc.ParseError:\n            if error == 'raise':\n                raise\n            self.request.unread(line)\n            return default\n        if authenticate and not self.proxy_authenticate(info):\n            logger.info('authentication failed - %s', info)\n            return default\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_table(cls, read_throughput=5, write_throughput=5):\n        table_name = cls.get_table_name()\n\n        raw_throughput = {\n            'ReadCapacityUnits': read_throughput,\n            'WriteCapacityUnits': write_throughput\n        }\n\n        table_schema = []\n        table_definitions = []\n        seen_attrs = set()\n        for key in cls._get_keys():\n            table_schema.append(key.schema())\n            table_definitions.append(key.definition())\n            seen_attrs.add(key.name)\n\n        indexes = []\n        global_indexes = []\n        for index in cls._get_indexes():\n            if issubclass(index, GlobalIndex):\n                global_indexes.append(index.schema())\n            else:\n                indexes.append(index.schema())\n            for key in index._keys:\n                if key.name not in seen_attrs:\n                    table_definitions.append(key.definition())\n                    seen_attrs.add(key.name)\n\n        cls._get_connection().create_table(\n            table_name=table_name,\n            key_schema=table_schema,\n            attribute_definitions=table_definitions,\n            provisioned_throughput=raw_throughput,\n            local_secondary_indexes=indexes or None,\n            global_secondary_indexes=global_indexes or None\n        )", "response": "Create the table as the schema definition."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_item(cls, hash_key, range_key=None):\n        key = cls._encode_key(hash_key, range_key)\n        raw_data = cls._get_connection().get_item(cls.get_table_name(), key)\n        if 'Item' not in raw_data:\n            raise ItemNotFoundException\n        return cls.from_raw_data(raw_data['Item'])", "response": "Get an item from the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating item attributes. Currently SET and ADD actions are supported.", "response": "def update_item(cls, hash_key, range_key=None, attributes_to_set=None, attributes_to_add=None):\n        \"\"\"Update item attributes. Currently SET and ADD actions are supported.\"\"\"\n        primary_key = cls._encode_key(hash_key, range_key)\n\n        value_names = {}\n        encoded_values = {}\n        dynamizer = Dynamizer()\n\n        set_expression = ''\n        if attributes_to_set:\n            for i, key in enumerate(attributes_to_set.keys()):\n                value_name = ':s{0}'.format(i)\n                value_names[key] = value_name\n                encoded_values[value_name] = dynamizer.encode(attributes_to_set[key])\n\n            set_expression = 'SET {0}'.format(\n                ', '.join(\n                    '{key}={value_name}'.format(key=key, value_name=value_names[key]) for key in attributes_to_set\n                )\n            )\n\n        add_expression = ''\n        if attributes_to_add:\n            for i, key in enumerate(attributes_to_add.keys()):\n                value_name = ':a{0}'.format(i)\n                value_names[key] = value_name\n                encoded_values[value_name] = dynamizer.encode(attributes_to_add[key])\n            add_expression = 'ADD {0}'.format(\n                ', '.join(\n                    '{key} {value_name}'.format(key=key, value_name=value_names[key]) for key in attributes_to_add\n                )\n            )\n\n        update_expression = ' '.join([set_expression, add_expression])\n\n        cls._get_connection().update_item(\n            cls.get_table_name(),\n            primary_key,\n            update_expression=update_expression, expression_attribute_values=encoded_values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(cls, index_name=None, filter_builder=None,\n              scan_index_forward=None, limit=None, **key_conditions):\n        \"\"\"High level query API.\n\n        :param key_filter: key conditions of the query.\n        :type key_filter: :class:`collections.Mapping`\n        :param filter_builder: filter expression builder.\n        :type filter_builder: :class:`~bynamodb.filterexps.Operator`\n        \"\"\"\n        query_kwargs = {\n            'key_conditions': build_condition(key_conditions, KEY_CONDITIONS),\n            'index_name': index_name,\n            'scan_index_forward': scan_index_forward,\n            'limit': limit\n        }\n        if filter_builder:\n            cls._build_filter_expression(filter_builder, query_kwargs)\n        return ResultSet(cls, 'query', query_kwargs)", "response": "High level query API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_raw_data(cls, item_raw):\n        deserialized = {}\n        for name, value in item_raw.items():\n            attr = getattr(cls, name, None)\n            if attr is None:\n                continue\n            deserialized[name] = attr.decode(value)\n        return cls(**deserialized)", "response": "Translate the raw item data from the DynamoDBConnection\n        to the item object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a copy of the input for the run function and consume the input to free up the queue for more input. If all input is consumed, there is no need to overload this function. Input is provided as lists. To copy and consume input the following commands can be run: 1. To consume all the input >>> copy['entity'] = input['entity'][:] >>> del input['entity'][:] 2. To consume one item from the input (and pass it to run as a single item - not a list) >>> copy['entity'] = input['entity'].pop() 3. To use an item but not consume it >>> copy['entity'] = input['entity'][0] :param input: input arguments :return: copy of the input arguments", "response": "def consume_input(self, input):\n        \"\"\"\n        Make a copy of the input for the run function and consume the input to free up the queue for more input. If all\n        input is consumed, there is no need to overload this function. Input is provided as lists. To copy and consume\n        input the following commands can be run:\n\n        1. To consume all the input\n        >>> copy['entity'] = input['entity'][:]\n        >>> del input['entity'][:]\n\n        2. To consume one item from the input (and pass it to run as a single item - not a list)\n        >>> copy['entity'] = input['entity'].pop()\n\n        3. To use an item but not consume it\n        >>> copy['entity'] = input['entity'][0]\n\n        :param input: input arguments\n        :return: copy of the input arguments\n        \"\"\"\n        copy = {}\n        for key in input:\n            copy[key] = input[key][:]\n            del input[key][:]\n        return copy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new REGIDCustomField object for the given UWRegID.", "response": "def new_regid_custom_field(uwregid):\n    \"\"\"\n    Return a BridgeCustomField object for REGID\n    to be used in a POST, PATCH request\n    \"\"\"\n    return BridgeCustomField(\n        field_id=get_regid_field_id(),\n        name=BridgeCustomField.REGID_NAME,\n        value=uwregid\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a copy of the object", "response": "def copy(self):\n        \"\"\" Creates a copy of the object \"\"\"\n        variance = self.variance.copy() if self.variance is not None else None\n        headers = self.headers.copy() if self.headers is not None else None\n        return self.__class__(self.disp.copy(), self.flux.copy(),\n            variance=variance, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(cls, filename, **kwargs):\n        \n        if not os.path.exists(filename):\n            raise IOError(\"filename {0} does not exist\" .format(filename))\n        \n        if filename.lower().endswith(\".fits\") \\\n        or filename.lower().endswith(\".fits.gz\"):\n            image = fits.open(filename, **kwargs)\n            \n            header = image[0].header\n            \n            # Check for a tabular data structure\n            if len(image) > 1 and image[0].data is None:\n\n                names = [name.lower() for name in image[1].data.names]\n                dispersion_key = 'wave' if 'wave' in names else 'disp'\n                \n                disp, flux = image[1].data[dispersion_key], image[1].data['flux']\n\n                if 'error' in names or 'variance' in names:\n                    variance_key = 'error' if 'error' in names else 'variance'\n                    variance = image[1].data[variance_key]\n\n            else:\n\n                # According to http://iraf.net/irafdocs/specwcs.php ....\n                #li = a.headers['LTM1_1'] * np.arange(a.headers['NAXIS1']) + a.headers['LTV1']\n                #a.headers['CRVAL1'] + a.headers['CD1_1'] * (li - a.headers['CRPIX1'])\n\n                if np.all([key in header.keys() for key in ('CDELT1', 'NAXIS1', 'CRVAL1')]):\n                    disp = header['CRVAL1'] + (np.arange(header['NAXIS1']) \\\n                        - header.get(\"CRPIX1\", 0)) * header['CDELT1']\n            \n                if \"LTV1\" in header.keys():\n                    disp -= header['LTV1'] * header['CDELT1']\n\n                #disp -= header['LTV1'] if header.has_key('LTV1') else 0\n                flux = image[0].data\n\n                # Check for an input_variance array\n                extnames = [ext.header.get(\"EXTNAME\", None) for ext in image[1:]]\n                if \"input_variance\" in extnames:\n                    index = 1 + extnames.index(\"input_variance\")\n                    variance = image[index].data\n                    \n                else:\n                    variance = None\n            \n                # Check for logarithmic dispersion\n                if \"CTYPE1\" in header.keys() and header[\"CTYPE1\"] == \"AWAV-LOG\":\n                    disp = np.exp(disp)\n\n            # Add the headers in\n            headers = {}\n            for row in header.items():\n                key, value = row\n                \n                # Check the value is valid\n                try:\n                    str(value)\n\n                except TypeError:\n                    logger.debug(\"Skipping header key {0}\".format(key))\n                    continue\n\n                if len(key) == 0 or len(str(value)) == 0: continue\n    \n                if key in headers.keys():\n                    if not isinstance(headers[key], list):\n                        headers[key] = [headers[key]]\n                    \n                    headers[key].append(value)\n\n                else:\n                    headers[key] = value\n\n            for key, value in headers.iteritems():\n                if isinstance(value, list):\n                    headers[key] = \"\\n\".join(map(str, value))\n\n        else:\n            headers = {}\n            try:\n                disp, flux, variance = np.loadtxt(filename, unpack=True, **kwargs)\n            except:\n                disp, flux = np.loadtxt(filename, unpack=True, **kwargs)\n            \n        return cls(disp, flux, variance=variance, headers=headers)", "response": "Load a Spectrum1D from a given filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, filename, clobber=True, **kwargs):\n        \n        if os.path.exists(filename) and not clobber:\n            raise IOError(\"filename '{0}' exists and we have been asked not to\"\\\n                \" clobber it\".format(filename))\n        \n        if not filename.endswith('fits'):\n            # ASCII\n            data = np.hstack([\n                self.disp.reshape(-1, 1),\n                self.flux.reshape(-1, 1),\n                self.variance.reshape(-1, 1)\n                ])\n            return np.savetxt(filename, data, **kwargs)\n            \n        else:          \n            # Create a tabular FITS format\n            disp = fits.Column(name='disp', format='1D', array=self.disp)\n            flux = fits.Column(name='flux', format='1D', array=self.flux)\n            var = fits.Column(name='variance', format='1D', array=self.variance)\n            table_hdu = fits.new_table([disp, flux, var])\n\n            # Create Primary HDU\n            hdu = fits.PrimaryHDU()\n\n            # Update primary HDU with headers\n            for key, value in self.headers.iteritems():\n                if len(key) > 8: # To deal with ESO compatibility\n                    hdu.header.update('HIERARCH {}'.format(key), value)\n\n                try:\n                    hdu.header.update(key, value)\n                except ValueError:\n                    logger.warn(\"Could not save header key/value combination: \"\\\n                        \"{0} = {1}\".format(key, value))\n\n            # Create HDU list with our tables\n            hdulist = fits.HDUList([hdu, table_hdu])\n            return hdulist.writeto(filename, clobber=clobber, **kwargs)", "response": "Save the Spectrum1D object to a FITS file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cross_correlate(self, templates, **kwargs):\n\n        # templates can be:\n        # - a single Spectrum1D object\n        # - (template_dispersion, template_fluxes)\n\n        # templates can be a single spectrum or a tuple of (dispersion, fluxes)\n\n        if isinstance(templates, (Spectrum1D, )):\n            template_dispersion = templates.disp\n            template_fluxes = templates.flux\n\n        else:\n            template_dispersion = templates[0]\n            template_fluxes = templates[1]\n\n        return _cross_correlate(self, template_dispersion, template_fluxes,\n            **kwargs)", "response": "Cross correlate the spectrum against a set of templates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of reservations matching the passed filter.", "response": "def get_reservations(**kwargs):\n    \"\"\"\n    Return a list of reservations matching the passed filter.\n    Supported kwargs are listed at\n    http://knowledge25.collegenet.com/display/WSW/reservations.xml\n    \"\"\"\n    kwargs[\"scope\"] = \"extended\"\n    url = \"/r25ws/servlet/wrd/run/reservations.xml\"\n    if len(kwargs):\n        url += \"?%s\" % urlencode(kwargs)\n\n    return reservations_from_xml(get_resource(url))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a single column.", "response": "def process_column(self, idx, value):\n        \"Process a single column.\"\n        if value is not None:\n            value = str(value).decode(self.encoding)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_line(self, line):\n        \"Process a single complete line.\"\n        cleaned = []\n        columns = line.split(self.indel)\n        # Populate indices if not defined\n        if not self.indices:\n            self.indices = range(len(columns))\n        for i in self.indices:\n            # Support turning an in col into multiple out cols\n            out = self.process_column(i, columns[i])\n            if isinstance(out, (list, tuple)):\n                cleaned.extend(out)\n            else:\n                cleaned.append(out)\n        return self.outdel.join(cleaned) + '\\n'", "response": "Process a single complete line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading up to size bytes but always completes the last line.", "response": "def read(self, size=-1):\n        \"Reads up to size bytes, but always completes the last line.\"\n        buf = self.fin.read(size)\n        if not buf:\n            return ''\n        lines = buf.splitlines()\n        # Read the rest of the last line if necessary\n        if not buf.endswith('\\n'):\n            last = lines.pop()\n            partial = self.fin.readline()\n            lines.append(last + partial)\n        # Process the lines, concatenate them\n        lines = [self.process_line(line.rstrip('\\n')) for line in lines]\n        return ''.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_line(self, record):\n        \"Process a single record. This assumes only a single sample output.\"\n        cleaned = []\n\n        for key in self.vcf_fields:\n            out = self.process_column(key, getattr(record, key))\n            if isinstance(out, (list, tuple)):\n                cleaned.extend(out)\n            else:\n                cleaned.append(out)\n\n        for key in self.info_fields:\n            out = self.process_column(key, record.INFO.get(key, None))\n            if isinstance(out, (list, tuple)):\n                cleaned.extend(out)\n            else:\n                cleaned.append(out)\n\n        return cleaned", "response": "Process a single record. This assumes only a single sample output."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, size=-1):\n        lines = []\n        parsed_size = 0\n\n        while True:\n            line = self.readline()\n            if not line:\n                break\n            lines.append(line)\n            parsed_size += len(line)\n            if size and size > 0 and parsed_size >= size:\n                break\n\n        return ''.join(lines)", "response": "Read size bytes from the reader relative to the parsed output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readline(self, size=-1):\n        \"Ignore the `size` since a complete line must be processed.\"\n        try:\n            record = next(self.reader)\n            return self.outdel.join(self.process_line(record)) + '\\n'\n        except StopIteration:\n            return ''", "response": "Ignore the size since a complete line must be processed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a tweet and returns a list of LexicalTokens found in the original tweet.", "response": "def lexically_parse_tweet(tweet, phrase_tree):\n    \"\"\"\n    Returns list of LexicalTokens found in tweet. The list contains all the words in original tweet, but are\n    optimally grouped up to form largest matching n-grams from lexicon. If no match is found, token is added as\n    singleton.\n\n    @param tweet      Tweet to lexically parse\n    @param phrase_tree Token tree that contains all the lexical n-grams\n    @return List of LexicalTokens\n    \"\"\"\n    lexical_tokens = []\n\n    prev = 0\n\n    while True:\n        match = RegexFilters.SENTENCE_END_PUNCTUATION.search(tweet[prev:])\n        if match is None:\n            break\n        span = match.span()\n        sentence = tweet[prev:prev + span[0]]\n        punctuation = match.group(0)\n        prev += span[1]\n        lexical_tokens.extend(parse_sentence(sentence, punctuation, phrase_tree))\n\n    lexical_tokens.extend(parse_sentence(tweet[prev:], None, phrase_tree))\n\n    return lexical_tokens"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        schema = super(Schema, self).to_dict()\n        schema['$schema'] = \"http://json-schema.org/draft-04/schema#\"\n        if self._id:\n            schema['id'] = self._id\n        if self._desc:\n            schema['description'] = self._desc\n        return schema", "response": "Return the schema as a dict ready to be serialized."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef define(self, id, schema):\n        self.definitions[id] = schema\n        self._schema = None\n        return self.ref(id)", "response": "Add a schema to the list of definitions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self, data):\n        validator = self._schema.validator(self._id)\n        validator.validate(data)", "response": "Validate the data against the schema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking to make sure that the allAssembliesDir has been created, if not, make it. This will only execute for the first time an assembly has been run in this directory. Run the directory from allAssembliesDir. The self.callString instance attribute tells Meraculous to name the assembly directory self.runName. After the run is complete, create the meraculous report, passing the directory containing the run (aka self.thisAssemblyDir).", "response": "def meraculous_runner(self):\n        \"\"\"\n        Check to make sure that the allAssembliesDir has been created, if not,\n        make it. This will only execute for the first time an assembly has been\n        run in this directory.\n\n        Run the directory from allAssembliesDir. The self.callString instance\n        attribute tells Meraculous to name the assembly directory self.runName.\n\n        After the run is complete, create the meraculous report, passing the\n        directory containing the run (aka self.thisAssemblyDir).\n        \"\"\"\n        #set the dir to temp assembly dir\n        os.chdir(self.allAssembliesDir)\n\n        print(self.callString)\n        p = subprocess.run(self.callString, shell=True, stdout=subprocess.PIPE,\n                           stderr=subprocess.PIPE,\n                           universal_newlines=True)\n        output = str(p.stdout)\n        err = str(p.stderr)\n\n        #generate the report for the run\n        self._generate_report()\n\n        #exit, returning the output and err\n        return (output, err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef throttle_check(self):\n        throttle = self._meta.throttle()\n        wait = throttle.should_be_throttled(self)\n        if wait:\n            raise HttpError(\n                \"Throttled, wait {0} seconds.\".format(wait),\n                status=status.HTTP_503_SERVICE_UNAVAILABLE)", "response": "Check if the resource is throttled."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndrop the target table.", "response": "def drop_table(self, cursor, target, options):\n        \"Drops the target table.\"\n        sql = 'DROP TABLE IF EXISTS {0}'\n        cursor.execute(sql.format(self.qualified_names[target]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the target table.", "response": "def create_table(self, cursor, target, options):\n        \"Creates the target table.\"\n        cursor.execute(\n            self.create_sql[target].format(self.qualified_names[target]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_files(self, cursor, target, files, options):\n        \"Loads multiple files into the target table.\"\n        for fname in files:\n            self.load_file(cursor, target, fname, options)", "response": "Loads multiple files into the target table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing and loads a single file into the target table.", "response": "def load_file(self, cursor, target, fname, options):\n        \"Parses and loads a single file into the target table.\"\n        with open(fname) as fin:\n            log.debug(\"opening {0} in {1} load_file\".format(fname, __name__))\n            encoding = options.get('encoding', 'utf-8')\n            if target in self.processors:\n                reader = self.processors[target](fin, encoding=encoding)\n            else:\n                reader = self.default_processor(fin, encoding=encoding)\n            columns = getattr(reader, 'output_columns', None)\n            for _ in xrange(int(options.get('skip-lines', 0))):\n                fin.readline()\n            cursor.copy_from(reader, self.qualified_names[target],\n                             columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_locations(self, cells_file):\n        self._cells_file = cells_file\n        field_names = ('ident', 'latitude', 'longitude', 'mcc', 'mnc', 'lac',\n                       'cellid', 'crange', 'samples', 'created', 'updated')\n        parse_date = lambda s: datetime.datetime.strptime(s,\n                                                          '%Y-%m-%d %H:%M:%S')\n        field_parsers = (int, float, float, int, int, int, int, int, int,\n                         parse_date, parse_date)\n        data = utils.prepare_csv_read(cells_file, field_names)\n\n        for row in data:\n            try:\n                cell = dict((n, p(row[n]))\n                            for n, p in zip(field_names, field_parsers))\n            except ValueError:\n                if r\"\\N\" in row.values():\n                    # A few entries are incomplete, and when that occurs the\n                    # export includes the string \"\\N\" to denote missing\n                    # data.  We just ignore them for now\n                    logging.debug('Skipping incomplete entry %r' % row)\n                    break\n                else:\n                    raise utils.FileFormatError('opencellid.org')\n            else:\n                self[row['ident']] = Cell(**cell)", "response": "Parse the OpenCellID. org data files and return a dictionary containing the keys containing the OpenCellID. org database identifier and values consisting of the OpenCellID. org database identifier and a list of Cell objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef op_symbol(op_node):\n    ops = {\n        # TODO(nicholasbishop): other unary ops\n        ast.UAdd: '+',\n        ast.USub: '-',\n\n        # TODO(nicholasbishop): FloorDiv, Pow, LShift, RShift,\n        # BitOr, BitXor, BitAnd\n        ast.Add: '+',\n        ast.Sub: '-',\n        ast.Mult: '*',\n        ast.Div: '/',\n        ast.Mod: '%',\n\n        # Comparison\n        ast.Eq: '=',\n        ast.NotEq: '!=',\n        ast.Lt: '<',\n        ast.LtE: '<=',\n        ast.Gt: '>',\n        ast.GtE: '>=',\n    }\n    # Python3 matrix multiplication\n    if hasattr(ast, 'MatMult'):\n        ops[ast.MatMult] = '*'\n    return ops[op_node.__class__]", "response": "Get the GLSL symbol for a Python operator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntranslate Python AST into GLSL code.", "response": "def py_to_glsl(root):\n    \"\"\"Translate Python AST into GLSL code.\n\n    root: an ast.FunctionDef object\n\n    Return a list of strings, where each string is a line of GLSL\n    code.\n    \"\"\"\n    atg = AstToGlsl()\n    code = atg.visit(root)\n    return code.lines"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filedet(name, fobj=None, suffix=None):\n    name = name or (fobj and fobj.name) or suffix\n    separated = name.split('.')\n    if len(separated) == 1:\n        raise FiledetException('file name error.')\n\n    key = '.' + separated[-1]\n    return _file_type_map.get(key)", "response": "Detect file type by filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the unique items of a list in their original order preserved.", "response": "def unique_preserved_list(original_list):\n    \"\"\"\n    Return the unique items of a list in their original order.\n\n    :param original_list:\n        A list of items that may have duplicate entries.\n\n    :type original_list:\n        list\n\n    :returns:\n        A list with unique entries with the original order preserved.\n\n    :rtype:\n        list\n    \"\"\"\n    \n    seen = set()\n    seen_add = seen.add\n    return [x for x in original_list if x not in seen and not seen_add(x)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef human_readable_digit(number):\n\n    if 0 >= number:\n        return \"{0:.1f} \".format(number)\n\n    word = [\"\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n    millidx = max(0, min(len(word)-1, int(np.floor(np.log10(abs(number))/3.0))))\n    return \"{0:.1f} {1}\".format(number/10**(3*millidx), word[millidx])", "response": "Returns a human - readable digit in a human - readable string form."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nestimates the exponential auto - correlation time for all parameters in a chain.", "response": "def estimate_tau_exp(chains, **kwargs):\n    \"\"\"\n    Estimate the exponential auto-correlation time for all parameters in a chain.\n    \"\"\"\n\n    # Calculate the normalised autocorrelation function in each parameter.\n    rho = np.nan * np.ones(chains.shape[1:])\n    for i in range(chains.shape[2]):\n        try:\n            rho[:, i] = autocorr.function(np.mean(chains[:, :, i], axis=0),\n                **kwargs)\n        except:\n            continue\n\n    # Take the max rho at any step.\n    rho_max = np.max(rho, axis=1)\n\n    # Now fit the max rho with an exponential profile.\n    x = np.arange(rho_max.size)\n    func = lambda tau_exp: np.exp(-x/tau_exp)\n    chi = lambda tau_exp: func(tau_exp[0]) - rho_max # tau_exp is a list\n\n    # Start with 50% of the chain length. probably OK.\n    tau_exp, ier = leastsq(chi, [chains.shape[1]/2.])\n    return (tau_exp, rho, func(tau_exp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef estimate_tau_int(chains, **kwargs):\n    return autocorr.integrated_time(np.mean(chains, axis=0), **kwargs)", "response": "Estimate the integrated auto - correlation time for all parameters in a chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nestimate the model parameters given the data.", "response": "def estimate(self, data, full_output=False, **kwargs):\n        \"\"\"\n        Estimate the model parameters, given the data.\n        \"\"\"\n\n        # Number of model comparisons can be specified in the configuration.\n        num_model_comparisons = self._configuration.get(\"estimate\", {}).get(\n            \"num_model_comparisons\", self.grid_points.size)\n        # If it's a fraction, we need to convert that to an integer.\n        if 1 > num_model_comparisons > 0:\n            num_model_comparisons *= self.grid_points.size\n\n        # If the num_model_comparison is provided as a keyword argument, use it.\n        num_model_comparisons = kwargs.pop(\"num_model_comparisons\",\n            int(num_model_comparisons))\n\n        logger.debug(\"Number of model comparisons to make for initial estimate:\"\n            \" {0}\".format(num_model_comparisons))\n        \n        # Match the data to the model channels.\n        matched_channels, missing_channels, ignore_parameters \\\n            = self._match_channels_to_data(data)\n\n        logger.debug(\"Matched channels: {0}, missing channels: {1}, ignore \"\n            \"parameters: {2}\".format(matched_channels, missing_channels,\n                ignore_parameters))\n\n        # Load the intensities\n        t = time()\n        s = self.grid_points.size/num_model_comparisons # step size\n        grid_points = self.grid_points[::s]\n        intensities = np.memmap(\n            self._configuration[\"model_grid\"][\"intensities\"], dtype=\"float32\",\n            mode=\"r\", shape=(self.grid_points.size, self.wavelengths.size))[::s]\n        logger.debug(\"Took {:.0f} seconds to load and slice intensities\".format(\n            time() - t))\n        # Which matched, data channel has the highest S/N?\n        # (This channel will be used to estimate astrophysical parameters)\n        data, pixels_affected = self._apply_data_mask(data)\n        median_snr = dict(zip(matched_channels,\n            [np.nanmedian(spec.flux/(spec.variance**0.5)) for spec in data]))\n        median_snr.pop(None, None) # Remove unmatched data spectra\n\n        ccf_channel = self._configuration.get(\"settings\", {}).get(\"ccf_channel\",\n            max(median_snr, key=median_snr.get))\n        if ccf_channel not in matched_channels:\n            logger.warn(\"Ignoring CCF channel {0} because it was not a matched\"\n                \" channel\".format(ccf_channel))\n            ccf_channel = max(median_snr, key=median_snr.get)\n\n        logger.debug(\"Channel with peak SNR is {0}\".format(ccf_channel))\n\n        # Are there *any* continuum parameters in any matched channel?\n        any_continuum_parameters = any(map(lambda s: s.startswith(\"continuum_\"),\n            set(self.parameters).difference(ignore_parameters)))\n\n        # [TODO]: CCF MASK\n        # [TODO]: Don't require CCF if we have only continuum parameters.\n\n        z_limits = self._configuration[\"settings\"].get(\"ccf_z_limits\", None)\n\n        theta = {} # Dictionary for the estimated model parameters.\n        best_grid_index = None\n        c = speed_of_light.to(\"km/s\").value\n        for matched_channel, spectrum in zip(matched_channels, data):\n            if matched_channel is None: continue\n\n            # Do we need todo cross-correlation for this channel?\n            # We do if there are redshift parameters for this channel,\n            # or if there is a global redshift or global continuum parameters\n            #   and this channel is the highest S/N.\n            if \"z_{}\".format(matched_channel) in self.parameters \\\n            or ((any_continuum_parameters or \"z\" in self.parameters) \\\n            and matched_channel == ccf_channel):\n\n                # Get the continuum degree for this channel.\n                continuum_degree = self._configuration[\"model\"].get(\"continuum\",\n                    { matched_channel: -1 })[matched_channel]\n\n                logger.debug(\"Perfoming CCF on {0} channel with a continuum \"\n                    \"degree of {1}\".format(matched_channel, continuum_degree))\n\n                # Get model wavelength indices that match the data.\n                # get the points that are in the mask, and within the spectrum\n                # limits\n\n                # TODO: Make this CCF not model mask.\n                idx = np.where(self._model_mask() \\\n                    * (self.wavelengths >= spectrum.disp[0]) \\\n                    * (spectrum.disp[-1] >= self.wavelengths))[0]\n\n                v, v_err, R = spectrum.cross_correlate(\n                    (self.wavelengths[idx], intensities[:, idx]),\n                    #(self.wavelengths, intensities),\n                    continuum_degree=continuum_degree, z_limits=z_limits)\n\n                # Identify the best point by the CCF peak.\n                best = np.nanargmax(R)\n\n                # Now, why did we do CCF in this channel? Which model parameters\n                # should be updated?\n                if \"z_{}\".format(matched_channel) in self.parameters:\n                    theta[\"z_{}\".format(matched_channel)] = v[best] / c\n                elif \"z\" in self.parameters: \n                    # If there is a global redshift, update it.\n                    theta[\"z\"] = v[best] / c\n\n                    # Continuum parameters will be updated later, so that each\n                    # channel is checked to see if it has the highest S/N,\n                    # otherwise we might be trying to calculate continuum\n                    # parameters when we haven't done CCF on the highest S/N\n                    # spectra yet.\n\n                if matched_channel == ccf_channel:\n                    # Update astrophysical parameters.\n                    theta.update(dict(zip(grid_points.dtype.names,\n                        grid_points[best])))\n                    best_grid_index = best\n\n        # If there are continuum parameters, calculate them from the best point.\n        if any_continuum_parameters:\n            for matched_channel, spectrum in zip(matched_channels, data):\n                if matched_channel is None: continue\n\n                # The template spectra at the best point needs to be\n                # redshifted to the data, and then continuum coefficients\n                # calculated from that.\n\n                # Get the continuum degree for this channel.\n                continuum_degree = self._configuration[\"model\"].get(\"continuum\",\n                    { matched_channel: -1 })[matched_channel]\n\n            \n                # Get model wavelength indices that match the data.\n                idx = np.clip(self.wavelengths.searchsorted(\n                    [spectrum.disp[0], spectrum.disp[-1]]) + [0, 1],\n                    0, self.wavelengths.size)\n\n                # Redshift and bin the spectrum.\n                z = theta.get(\"z_{}\".format(matched_channel), theta.get(\"z\", 0))\n\n                best_intensities \\\n                    = np.copy(intensities[best_grid_index, idx[0]:idx[1]]).flatten()\n\n                # Apply model mask.\n                model_mask = self._model_mask(self.wavelengths[idx[0]:idx[1]])\n                best_intensities[~model_mask] = np.nan\n\n                best_intensities = best_intensities * specutils.sample.resample(\n                    self.wavelengths[idx[0]:idx[1]] * (1 + z), spectrum.disp)\n                \n                # Calculate the continuum coefficients for this channel.\n                continuum = spectrum.flux/best_intensities\n                finite = np.isfinite(continuum)\n\n                try:\n                    coefficients = np.polyfit(\n                        spectrum.disp[finite], continuum[finite], continuum_degree,\n                        )#w=spectrum.ivariance[finite])\n                except np.linalg.linalg.LinAlgError:\n                    logger.exception(\"Exception in initial polynomial fit\")\n                    coefficients = np.polyfit(spectrum.disp[finite], continuum[finite],\n                        continuum_degree)\n\n                # They go into theta backwards. such that coefficients[-1] is\n                # continuum_{name}_0\n                theta.update(dict(zip(\n                    [\"continuum_{0}_{1}\".format(matched_channel, i) \\\n                        for i in range(continuum_degree + 1)],\n                    coefficients[::-1]\n                )))\n\n        # Remaining parameters could be: resolving power, outlier pixels,\n        # underestimated variance.\n        remaining_parameters = set(self.parameters)\\\n            .difference(ignore_parameters)\\\n            .difference(theta)\n\n        if remaining_parameters:\n            logger.debug(\"Remaining parameters to estimate: {0}. For these we \"\n                \"will just assume reasonable initial values.\".format(\n                remaining_parameters))\n\n            for parameter in remaining_parameters:\n                if parameter == \"resolution\" \\\n                or parameter.startswith(\"resolution_\"):\n\n                    if parameter.startswith(\"resolution_\"):\n                        spectra = [data[matched_channels.index(\n                            parameter.split(\"_\")[1])]]\n                    else:\n                        spectra = [s for s in data if s is not None]\n\n                    R = [s.disp.mean()/np.diff(s.disp).mean() for s in spectra]\n\n                    # Assume oversampling rate of ~5.\n                    theta.update({ parameter: np.median(R)/5.})\n\n                elif parameter == \"ln_f\" or parameter.startswith(\"ln_f_\"):\n                    theta.update({ parameter: 0.5 }) # Not overestimated.\n\n                elif parameter in (\"Po\", \"Vo\"):\n                    theta.update({\n                        \"Po\": 0.01, # 1% outlier pixels.\n                        \"Vo\": np.mean([np.nanmedian(s.variance) for s in data]),\n                    })\n\n        logger.info(\"Initial estimate: {}\".format(theta))\n        # Having full_output = True means return the best spectra estimate.\n        if full_output:\n\n            # Create model fluxes and calculate some metric.\n            __intensities = np.copy(intensities[best_grid_index])\n\n            # Apply model masks.\n            __intensities[~self._model_mask()] = np.nan\n\n            chi_sq, dof, model_fluxes = self._chi_sq(theta, data,\n                __intensities=__intensities, __no_precomputed_binning=True)\n            del intensities\n\n            return (theta, chi_sq, dof, model_fluxes)\n\n        # Delete the reference to intensities\n        del intensities\n        return theta"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninferring the model parameters given the data.", "response": "def infer(self, data, initial_proposal=None, full_output=False,**kwargs):\n\n        \"\"\"\n        Infer the model parameters, given the data.\n        auto_convergence=True,\n        walkers=100, burn=2000, sample=2000, minimum_sample=2000,\n        convergence_check_frequency=1000, a=2.0, threads=1,\n\n        \"\"\"\n\n        # Apply data masks now so we don't have to do it on the fly.\n        data, pixels_affected = self._apply_data_mask(data)\n\n        # Any channels / parameters to ignore?\n        matched_channels, missing_channels, ignore_parameters \\\n            = self._match_channels_to_data(data)\n        parameters = [p for p in self.parameters if p not in ignore_parameters]\n        #parameters = list(set(self.parameters).difference(ignore_parameters))\n\n        logger.debug(\"Inferring {0} parameters: {1}\".format(len(parameters),\n            \", \".join(parameters)))\n\n        # What sampling behaviour will we have?\n        # - Auto-convergence:\n        #       + Sample for `minimum_sample` (default 2000, 200 walkers)\n        #       + Calculate the maximum exponential autocorrelation time for\n        #         all parameters\n        #       + For the rest of the chain, calculate the autocorrelation time\n        #       + Ensure that the number of samples we have is more than \n        #         `effectively_independent_samples` (default 100) times.\n        # - Specified convergence:\n        #       + Burn for `burn` (default 2000) steps\n        #       + Sample for `sample` (default 2000) steps\n\n        kwd = {\n            \"auto_convergence\": False, # TODO CHANGE ME\n            \"walkers\": 100,\n            \"burn\": 2000,\n            \"sample\": 2000,\n            # The minimum_sample, n_tau_exp_as_burn_in, minimum_eis are only\n            # used if auto_convergence is turned on.\n            \"minimum_sample\": 2000,\n            \"maximum_sample\": 100000,\n            \"n_tau_exp_as_burn_in\": 3,\n            \"minimum_effective_independent_samples\": 100,\n            \"check_convergence_frequency\": 1000,\n            \"a\": 2.0,\n            \"threads\": 1\n        }\n\n        # Update from the model, then update from any keyword arguments given.\n        kwd.update(self._configuration.get(\"infer\", {}).copy())\n        kwd.update(**kwargs)\n\n        # Make some checks.\n        if kwd[\"walkers\"] % 2 > 0 or kwd[\"walkers\"] < 2 * len(parameters):\n            raise ValueError(\"the number of walkers must be an even number and \"\n                \"be at least twice the number of model parameters\")\n\n        check_keywords = [\"threads\", \"a\"]\n        if kwd[\"auto_convergence\"]:\n            logger.info(\"Convergence will be estimated automatically.\")\n            check_keywords += [\"minimum_sample\", \"check_convergence_frequency\",\n                \"minimum_effective_independent_samples\", \"n_tau_exp_as_burn_in\",\n                \"maximum_sample\"]\n        \n        else:\n            check_keywords += [\"burn\", \"sample\"]\n            logger.warn(\"No convergence checks will be done!\")\n            logger.info(\"Burning for {0} steps and sampling for {1} with {2} \"\\\n                \"walkers\".format(kwd[\"burn\"], kwd[\"sample\"], kwd[\"walkers\"]))\n\n        for keyword in check_keywords:\n            if kwd[keyword] < 1:\n                raise ValueError(\"keyword {} must be a positive value\".format(\n                    keyword))\n\n        # Check for non-standard proposal scales.\n        if kwd[\"a\"] != 2.0:\n            logger.warn(\"Using proposal scale of {0:.2f}\".format(kwd[\"a\"]))\n\n        # If no initial proposal given, estimate the model parameters.\n        if initial_proposal is None:\n            initial_proposal = self.estimate(data)\n\n        # Initial proposal could be:\n        #   - an array (N_walkers, N_dimensions)\n        #   - a dictionary containing key/value pairs for the dimensions\n        if isinstance(initial_proposal, dict):\n\n            wavelengths_required = []\n            for channel, spectrum in zip(matched_channels, data):\n                if channel is None: continue\n                z = initial_proposal.get(\"z\",\n                    initial_proposal.get(\"z_{}\".format(channel), 0))\n                wavelengths_required.append(\n                    [spectrum.disp[0] * (1 - z), spectrum.disp[-1] * (1 - z)])\n\n            closest_point = [initial_proposal[p] \\\n                for p in self.grid_points.dtype.names]\n            subset_bounds = self._initialise_approximator(\n                closest_point=closest_point, \n                wavelengths_required=wavelengths_required, force=True, **kwargs)\n\n            initial_proposal = self._initial_proposal_distribution(\n                parameters, initial_proposal, kwd[\"walkers\"])\n\n        elif isinstance(initial_proposal, np.ndarray):\n            initial_proposal = np.atleast_2d(initial_proposal)\n            if initial_proposal.shape != (kwd[\"walkers\"], len(parameters)):\n                raise ValueError(\"initial proposal must be an array of shape \"\\\n                    \"(N_parameters, N_walkers) ({0}, {1})\".format(kwd[\"walkers\"],\n                        len(parameters)))\n\n        # Prepare the convolution functions.\n        self._create_convolution_functions(matched_channels, data, parameters)\n\n        # Create the sampler.\n        logger.info(\"Creating sampler with {0} walkers and {1} threads\".format(\n            kwd[\"walkers\"], kwd[\"threads\"]))\n        debug = kwargs.get(\"debug\", False)\n        sampler = emcee.EnsembleSampler(kwd[\"walkers\"], len(parameters),\n            inference.ln_probability, a=kwd[\"a\"], threads=kwd[\"threads\"],\n            args=(parameters, self, data, debug),\n            kwargs={\"matched_channels\": matched_channels})\n\n        # Regardless of whether we automatically check for convergence or not,\n        # we will still need to burn in for some minimum amount of time.\n        if kwd[\"auto_convergence\"]:\n            # Sample for `minimum_sample` period.\n            descr, iterations = \"\", kwd[\"minimum_sample\"]\n        else:\n            # Sample for `burn` period\n            descr, iterations = \"burn-in\", kwd[\"burn\"]\n\n        # Start sampling.\n        t_init = time()\n        acceptance_fractions = []\n        progress_bar = kwargs.get(\"__show_progress_bar\", True)\n        sampler, init_acceptance_fractions, pos, lnprob, rstate, init_elapsed \\\n            = self._sample(sampler, initial_proposal, iterations, descr=descr,\n                parameters=parameters, __show_progress_bar=progress_bar)\n        acceptance_fractions.append(init_acceptance_fractions)\n\n        # If we don't have to check for convergence, it's easy:\n        if not kwd[\"auto_convergence\"]:\n\n            # Save the chain and log probabilities before we reset the chain.\n            burn, sample = kwd[\"burn\"], kwd[\"sample\"]\n            converged = None # we don't know!\n            burn_chains = sampler.chain\n            burn_ln_probabilities = sampler.lnprobability\n\n            # Reset the chain.\n            logger.debug(\"Resetting chain...\")\n            sampler.reset()\n\n            # Sample the posterior.\n            sampler, prod_acceptance_fractions, pos, lnprob, rstate, t_elapsed \\\n                = self._sample(sampler, pos, kwd[\"sample\"], lnprob0=lnprob,\n                    rstate0=rstate, descr=\"production\", parameters=parameters,\n                    __show_progress_bar=progress_bar)\n\n            production_chains = sampler.chain\n            production_ln_probabilities = sampler.lnprobability\n            acceptance_fractions.append(prod_acceptance_fractions)\n\n        else:\n\n            # Start checking for convergence at a frequency\n            # of check_convergence_frequency\n            last_state = [pos, lnprob, rstate]\n            converged, total_steps = False, 0 + iterations\n            min_eis_required = kwd[\"minimum_effective_independent_samples\"]\n            while not converged and kwd[\"maximum_sample\"] > total_steps:\n                \n                # Check for convergence.\n                # Estimate the exponential autocorrelation time.\n                try:\n                    tau_exp, rho, rho_max_fit \\\n                        = utils.estimate_tau_exp(sampler.chain)\n\n                except:\n                    logger.exception(\"Exception occurred when trying to \"\n                        \"estimate the exponential autocorrelation time:\")\n\n                    logger.info(\"To recover, we are temporarily setting tau_exp\"\n                        \" to {0}\".format(total_steps))\n                    tau_exp = total_steps\n\n                logger.info(\"Estimated tau_exp at {0} is {1:.0f}\".format(\n                    total_steps, tau_exp))\n\n                # Grab everything n_tau_exp_as_burn_in times that.\n                burn = int(np.ceil(tau_exp)) * kwd[\"n_tau_exp_as_burn_in\"]\n                sample = sampler.chain.shape[1] - burn\n\n                if 1 > sample:\n                    logger.info(\"Sampler has not converged because {0}x the \"\n                        \"estimated exponential autocorrelation time of {1:.0f}\"\n                        \" is step {2}, and we are only at step {3}\".format(\n                            kwd[\"n_tau_exp_as_burn_in\"], tau_exp, burn,\n                            total_steps))\n        \n                else:\n\n                    # Calculate the integrated autocorrelation time in the \n                    # remaining sample, for every parameter.\n                    tau_int = utils.estimate_tau_int(sampler.chain[:, burn:])\n\n                    # Calculate the effective number of independent samples in \n                    # each parameter.\n                    num_effective = (kwd[\"walkers\"] * sample)/(2*tau_int)\n                    \n                    logger.info(\"Effective number of independent samples in \"\n                        \"each parameter:\")\n                    for parameter, n_eis in zip(parameters, num_effective):\n                        logger.info(\"\\t{0}: {1:.0f}\".format(parameter, n_eis))\n\n                    if num_effective.min() > min_eis_required:\n                        # Converged.\n                        converged = True\n                        logger.info(\"Convergence achieved ({0:.0f} > {1:.0f})\"\\\n                            .format(num_effective.min() > min_eis_required))\n\n                        # Separate the samples into burn and production..\n                        burn_chains = sampler.chain[:, :burn, :]\n                        burn_ln_probabilities = sampler.lnprobability[:burn]\n\n                        production_chains = sampler.chain[:, burn:, :]\n                        production_ln_probabilities = sampler.lnprobability[burn:]\n                        break\n\n                    else:\n                        # Nope.\n                        logger.info(\"Sampler has not converged because it did \"\n                            \"not meet the minimum number of effective \"\n                            \"independent samples ({0:.0f})\".format(kwd[\"n\"]))\n                \n                # Keep sampling.\n                iterations = kwd[\"check_convergence_frequency\"]\n                logger.info(\"Trying for another {0} steps\".format(iterations))\n\n                pos, lnprob, rstate = last_state\n                sampler, af, pos, lnprob, rstate, t_elapsed = self._sample(\n                    sampler, pos, iterations, lnprob0=lnprob, rstate0=rstate,\n                    descr=\"\", parameters=parameters,\n                    __show_progress_bar=progress_bar)\n\n                total_steps += iterations\n                acceptance_fractions.append(af)\n                last_state.extend(pos, lnprob, rstate)\n                del last_state[:3]\n\n            if not converged:\n                logger.warn(\"Maximum number of samples ({:.0f}) reached without\"\n                    \"convergence!\".format(kwd[\"maximum_sample\"]))\n\n        logger.info(\"Total time elapsed: {0} seconds\".format(time() - t_init))\n        \n        if sampler.pool:\n            sampler.pool.close()\n            sampler.pool.join()\n\n        # Stack burn and production information together.\n        chains = np.hstack([burn_chains, production_chains])\n        lnprobability = np.hstack([\n            burn_ln_probabilities, production_ln_probabilities])\n        acceptance_fractions = np.hstack(acceptance_fractions)\n\n        chi_sq, dof, model_fluxes = self._chi_sq(dict(zip(parameters, \n            [np.percentile(chains[:, burn:, i], 50) \n                for i in range(len(parameters))])), data)\n\n        # Convert velocity scales.\n        symbol, scale, units = self._preferred_redshift_scale\n        labels = [] + parameters\n        scales = np.ones(len(parameters))\n        if symbol != \"z\":\n            for i, parameter in enumerate(parameters):\n                if parameter == \"z\" or parameter.startswith(\"z_\"):\n                    chains[:, :, i] *= scale\n                    scales[i] = scale\n                    if \"_\" in parameter:\n                        labels[i] = \"_\".join([symbol, parameter.split(\"_\")[1:]])\n                    else:\n                        labels[i] = symbol\n                    logger.debug(\"Scaled {0} (now {1}) to units of {2}\".format(\n                        parameter, labels[i], units))\n\n        # Calculate MAP values and associated uncertainties.\n        theta = OrderedDict()\n        for i, label in enumerate(labels):\n            l, c, u = np.percentile(chains[:, burn:, i], [16, 50, 84])\n            theta[label] = (c, u-c, l-c)\n\n        # Re-arrange the chains to be in the same order as the model parameters.\n        indices = np.array([parameters.index(p) \\\n            for p in self.parameters if p in parameters])\n        chains = chains[:, :, indices]\n\n        # Remove the convolution functions.\n        if not kwargs.get(\"__keep_convolution_functions\", False):\n            self._destroy_convolution_functions()\n\n        if full_output:\n            metadata = {\n                \"burn\": burn,\n                \"walkers\": kwd[\"walkers\"],\n                \"sample\": sample,\n                \"parameters\": labels,\n                \"scales\": scales,\n                \"chi_sq\": chi_sq,\n                \"dof\": dof\n            }\n            return (theta, chains, lnprobability, acceptance_fractions, sampler,\n                metadata)\n        return theta"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_convolution_functions(self, matched_channels, data, \n        free_parameters, fixed_parameters=None):\n        \"\"\"\n        Pre-create binning matrix factories. The following options need to be\n        followed on a per-matched channel basis.\n\n        Options here are:\n\n        1) If we have no redshift or resolution parameters to solve for, then\n           we can just produce a matrix that will be multiplied in.\n           Inputs: none\n           Outputs: matrix\n\n        If fast_binning is turned on:\n\n        2) Provide the wavelengths, redshift, resolution (single value) and\n           flux. Returns the convolved, interpolated flux.\n           Inputs: flux, wavelengths (e.g., redshift), resolution\n           Outputs: normalised flux.\n\n        If fast_binning is turned off:\n\n        3) If we *just* have redshift parameters to solve for, then we can\n           produce a _BoxFactory that will take a redshift z and return\n           the matrix\n           [This function will have a LRU cacher and should be removed after]\n           Inputs: redshift\n           Outputs: matrix\n\n        4) If we have redshift parameters and resolution parameters, then we\n           can produce a _BlurryBoxFactory that will take a redshift z and\n           Resolution (or resolution coefficients!) and return a binning matrix\n           [This function will have a LRU cacher and should be removed after]\n           Inputs: redshift, Resolution parameter(s)\n           Outputs: matrix\n\n        5) If we *just* have resolution parameters to solve for, then we \n           can produce a _BlurryBoxFactory as well, because by default z=0.\n           [This function will have a LRU cacher and should be removed after]\n           Inputs: resolution parameter(s)\n           Outputs: matrix\n\n\n        Because these options require different input/outputs, and the LRU\n        cachers need to remain wrapped around simple functions, we may need a\n\n        Consistent lambda function:\n        lambda(obs_wavelength, obs_flux, z=0, *R)\n        \"\"\"\n\n        fast_binning = self._configuration.get(\"settings\", {}).get(\n            \"fast_binning\", 1)\n\n        logger.info(\"Creating convolution functions (fast_binning = {})\".format(\n            fast_binning))\n        logger.info(\"Free parameters: {}\".format(free_parameters))\n        logger.info(\"Fixed parameters: {}\".format(fixed_parameters))\n\n        if fixed_parameters is None:\n            fixed_parameters = {}\n\n        convolution_functions = []\n        for channel, spectrum in zip(matched_channels, data):\n            if channel is None:\n                convolution_functions.append(None)\n                continue\n\n            # Any redshift or resolution parameters?\n            redshift = \"z\" in free_parameters \\\n                or \"z_{}\".format(channel) in free_parameters\n            resolution = \"resolution_{}\".format(channel) in free_parameters\n\n            # Option 1.\n            # Create static binning matrices for each channel.\n            if not redshift and not resolution:\n\n                if fast_binning:\n                    logger.info(\"Doing static interpolation for channel {}\"\\\n                        .format(channel))\n                    convolution_function = lambda w, f, z, *a: \\\n                        np.interp(w, generate.wavelengths[-1], f,\n                            left=np.nan, right=np.nan)\n\n\n                else:\n\n                    logger.info(\"Creating static matrix for channel {0} because \"\\\n                        \"no redshift or resolution parameters were found\".format(\n                            channel))\n\n                    # Is there any z?\n                    z = fixed_parameters.get(\n                        \"z_{}\".format(channel), fixed_parameters.get(\"z\", 0))\n\n                    # Create the binning matrix based on the globally-scoped array\n                    # of wavelengths.\n                    matrix = specutils.sample.resample(\n                        generate.wavelengths[-1] * (1 + z),\n                        spectrum.disp)\n\n                    # Wrap in a lambda function to be consistent with other options.\n                    convolution_function = lambda w, f, *a: f * matrix\n\n            else:\n\n                # If fast_binning is turned on (default):\n                if fast_binning:\n                    \n                    # Option 2: Convolve with single kernel & interpolate.\n                    # [TODO] should w.mean()/R be squared?\n                    # px_sigma ~= ((w.mean()/R) / 2.35482)/np.diff(w).mean()\n                    # px_scale = ((w.mean()/R) / 2.35)/np.diff(w).mean()\n                    # px_scale = R_scale / R\n\n                    logger.info(\"Creating simple convolution & interpolating \"\\\n                        \"function for channel {0}\".format(channel))\n\n                    # [TODO] Account for the existing spectral resolution of the\n                    # grid.\n                    if resolution:\n                        R_scale = spectrum.disp.mean() \\\n                            / (2.35482 * np.diff(spectrum.disp).mean())\n                        \"\"\"\n                        convolution_function = lambda w, f, z, R, *a: \\\n                            np.interp(w, generate.wavelengths[-1] * (1 + z),\n                                gaussian_filter1d(f, max(0, R_scale/R),\n                                    mode=\"constant\", cval=np.nan),\n                                left=np.nan, right=np.nan)\n                        \"\"\"\n                        def convolution_function(w, f, z, R, *a):\n                            if R > 0:\n                                _ = gaussian_filter1d(f, R_scale/R)\n                            else:\n                                _ = f\n                            return np.interp(w, generate.wavelengths[-1] * (1 + z),\n                                _, left=np.nan, right=np.nan)\n\n                    else:\n                        convolution_function = lambda w, f, z, *a: \\\n                            np.interp(w, generate.wavelengths[-1] * (1 + z), f,\n                                left=np.nan, right=np.nan)\n\n                else:\n                    if redshift and not resolution:\n                        # Option 3: Produce a _BoxFactory\n                        logger.info(\"Producing a Box Factory for convolution \"\\\n                            \"in channel {}\".format(channel))\n\n                        matrix = specutils.sample._BoxFactory(\n                            spectrum.disp, generate.wavelengths[-1])\n\n                        # Wrap in a lambda function to be consistent.\n                        convolution_function = lambda w, f, z, *a: f * matrix(z)\n\n                    else:\n                        # Could be redshift and resolution, or just resolution.\n                        # Options 4 and 5: Produce a _BlurryBoxFactory\n                        logger.info(\"Producing a Blurry Box Factory for \"\\\n                            \"convolution in channel {}\".format(channel))\n\n                        matrix = specutils.sample._BlurryBoxFactory(\n                            spectrum.disp, generate.wavelengths[-1])\n\n                        # Wrap in a lambda function to be consistent.\n                        convolution_function \\\n                            = lambda w, f, z, R, *a: f * matrix(R, z)\n\n            # Append this channel's convolution function.\n            convolution_functions.append(convolution_function)\n\n        # Put the convolution functions into the global scope.\n        generate.binning_matrices.append(convolution_functions)\n        return True", "response": "Create the convolution functions for the given set of matched channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optimise(self, data, initial_theta=None, full_output=False, **kwargs):\n\n        data = self._format_data(data)\n\n        if initial_theta is None:\n            initial_theta = self.estimate(data)\n\n        # Which parameters will be optimised, and which will be fixed?\n        matched_channels, missing_channels, ignore_parameters \\\n            = self._match_channels_to_data(data)\n        #parameters = set(self.parameters).difference(ignore_parameters)\n        parameters = [p for p in self.parameters if p not in ignore_parameters]\n\n        # What model wavelength ranges will be required?\n        wavelengths_required = []\n        for channel, spectrum in zip(matched_channels, data):\n            if channel is None: continue\n            z = initial_theta.get(\"z\",\n                initial_theta.get(\"z_{}\".format(channel), 0))\n            wavelengths_required.append(\n                [spectrum.disp[0] * (1 - z), spectrum.disp[-1] * (1 - z)])\n\n        # Create the spectrum approximator/interpolator.\n        closest_point = [initial_theta[p] for p in self.grid_points.dtype.names]\n        subset_bounds = self._initialise_approximator(\n            closest_point=closest_point, \n            wavelengths_required=wavelengths_required, **kwargs)\n        \n        # Get the optimisation keyword arguments.\n        op_kwargs = self._configuration.get(\"optimise\", {}).copy()\n        op_kwargs.update(kwargs)\n\n        # Get fixed keywords.\n        fixed = op_kwargs.pop(\"fixed\", {})\n        if fixed:\n            # Remove non-parameters from the 'fixed' keywords.\n            keys = set(fixed).intersection(parameters)\n            # If the 'fixed' value is provided, use that. Otherwise if it is\n            # None then use the initial_theta value.\n            fixed = dict(zip(keys, \n                [(fixed[k], initial_theta.get(k, None))[fixed[k] is None] \\\n                    for k in keys]))\n\n            logger.info(\"Fixing keyword arguments (these will not be optimised)\"\n                \": {}\".format(fixed))\n\n        # Remove fixed parameters from the parameters to be optimised\n        #parameters = list(set(parameters).difference(fixed))\n        parameters = [p for p in parameters if p not in fixed]\n\n        # Translate input bounds.\n        nbs = (None, None) # No boundaries.\n        input_bounds = op_kwargs.pop(\"bounds\", {})\n        op_kwargs[\"bounds\"] = [input_bounds.get(p, subset_bounds.get(p, nbs)) \\\n            for p in parameters]\n        \n        # Apply data masks now so we don't have to do it on the fly.\n        masked_data, pixels_affected = self._apply_data_mask(data)\n\n        # Prepare the convolution functions.\n        self._create_convolution_functions(matched_channels, data, parameters,\n            fixed_parameters=fixed)\n\n        logger.info(\"Optimising parameters: {0}\".format(\", \".join(parameters)))\n        logger.info(\"Optimisation keywords: {0}\".format(op_kwargs))\n\n        # Create the objective function.\n        debug = kwargs.get(\"debug\", False)\n        def nlp(theta):\n            # Apply fixed keywords\n            t_ = theta.copy()\n            p_ = [] + parameters\n            for parameter, value in fixed.iteritems():\n                p_.append(parameter)\n                t_ = np.append(theta, value)\n\n            return -inference.ln_probability(t_, p_, self, data, debug,\n                matched_channels=matched_channels)\n\n        # Do the optimisation.\n        p0 = np.array([initial_theta[p] for p in parameters])\n\n        x_opt = op.minimise(nlp, p0, **op_kwargs)\n\n        # Put the result into a usable form.\n        x_opt_theta = OrderedDict(zip(parameters, x_opt))\n        x_opt_theta.update(fixed)\n\n        if full_output:\n            # Create model fluxes and calculate some metric.\n            chi_sq, dof, model_fluxes = self._chi_sq(x_opt_theta, data)\n\n\n            # Remove any prepared convolution functions.\n            self._destroy_convolution_functions()\n    \n            return (x_opt_theta, chi_sq, dof, model_fluxes)\n\n        # Remove any prepared convolution functions.\n        self._destroy_convolution_functions()\n\n        return x_opt_theta", "response": "Optimise the model parameters given the data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tcl_add_fileset_file(filename: str):\n    if filename.endswith(\".vhd\"):\n        t = \"VHDL\"\n    elif filename.endswith(\".v\") or filename.endswith(\".sv\"):\n        t = \"VERILOG\"\n    else:\n        raise NotImplementedError(\n            \"Can not resolve type of file by extension\", filename)\n    name = basename(filename)\n\n    return \"add_fileset_file %s %s PATH %s\" % (name, t, filename)", "response": "Returns the command string to add a file to the fileset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asignTopUnit(self, top, topName):\n        self._top = top\n        self.name = topName\n        pack = self._packager\n        self.model.addDefaultViews(topName, pack.iterParams(top))\n\n        for intf in pack.iterInterfaces(self._top):\n            self.registerInterface(intf)\n            if intf._isExtern:\n                self.busInterfaces.append(intf)\n\n        self.busInterfaces.sort(key=lambda x: x._name)\n        for intf in self.busInterfaces:\n            biClass = None\n            try:\n                biClass = intf._getIpCoreIntfClass()\n            except IntfIpMetaNotSpecified:\n                pass\n            if biClass is not None:\n                bi = BusInterface.fromBiClass(intf, biClass, self._packager)\n                intf._bi = bi\n                bi.busType.postProcess(self, self._packager, intf)\n\n        # generate component parameters\n        compNameParam = Parameter()\n        compNameParam.name = \"Component_Name\"\n        compNameParam.value = Value()\n        v = compNameParam.value\n        v.id = \"PARAM_VALUE.Component_Name\"\n        v.resolve = \"user\"\n        v.text = self.name\n        self.parameters.append(compNameParam)\n        # generic as parameters\n        for _p in pack.iterParams(self._top):\n            p = Parameter()\n            p.name = pack.getParamPhysicalName(_p)\n            p.value = self._packager.paramToIpValue(\n                \"PARAM_VALUE.\", _p, Value.RESOLVE_USER)\n            self.parameters.append(p)", "response": "Set the top unit as template for component\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setdefault(self, name, value):\n        ''' if the ``name`` is set, return its value.  Otherwse set ``name`` to\n            ``value`` and return ``value``'''\n        if name in self:\n            return self[name]\n        self[name] = value\n        return self[name]", "response": "Set the value of the named attribute."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a descending index for name to this index.", "response": "def ascending(self, name):\n        ''' Add a descending index for ``name`` to this index.\n\n            :param name: Name to be used in the index\n        '''\n        self.components.append((name, Index.ASCENDING))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef descending(self, name):\n        ''' Add a descending index for ``name`` to this index.\n\n            :param name: Name to be used in the index\n        '''\n        self.components.append((name, Index.DESCENDING))\n        return self", "response": "Add a descending index for name to this index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef geo2d(self, name, min=None, max=None):\n        self.components.append((name, GEO2D))\n        self.__min = min\n        self.__max = max\n        return self", "response": "Create a 2d index for the given column."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef geo_haystack(self, name, bucket_size):\n        self.components.append((name, 'geoHaystack'))\n        self.__bucket_size = bucket_size\n        return self", "response": "Create a geoHaystack index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unique(self, drop_dups=False):\n        ''' Make this index unique, optionally dropping duplicate entries.\n\n            :param drop_dups: Drop duplicate objects while creating the unique \\\n                index?  Default to ``False``\n        '''\n        self.__unique = True\n        if drop_dups and pymongo.version_tuple >= (2, 7, 5): # pragma: nocover\n            raise BadIndexException(\"drop_dups is not supported on pymongo >= 2.7.5\")\n        self.__drop_dups = drop_dups\n        return self", "response": "Make this index unique."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall the pymongo method ensure_index on the passed collection.", "response": "def ensure(self, collection):\n        ''' Call the pymongo method ``ensure_index`` on the passed collection.\n\n            :param collection: the ``pymongo`` collection to ensure this index \\\n                    is on\n        '''\n        components = []\n        for c in self.components:\n            if isinstance(c[0], Field):\n                c = (c[0].db_field, c[1])\n            components.append(c)\n\n        extras = {}\n        if self.__min is not None:\n            extras['min'] = self.__min\n        if self.__max is not None:\n            extras['max'] = self.__max\n        if self.__bucket_size is not None:\n            extras['bucket_size'] = self.__bucket_size\n        if self.__expire_after is not None:\n            extras['expireAfterSeconds'] = self.__expire_after\n\n        collection.ensure_index(components, unique=self.__unique,\n            drop_dups=self.__drop_dups, **extras)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a DocStringArg and returns the docstrings for the child object.", "response": "def factory(\n        name,\n        desc,\n        type,\n        subtypes=None,\n        required=True,\n        default=None,\n        ctor=None,\n        hide=False,\n    ):\n        \"\"\"\n        desc: >\n            Creates a DocStringArg and recursively includes child\n            docstrings if they are not JSON types.\n        args:\n            -   name: name\n                desc: The name of the argument\n                type: str\n            -   name: desc\n                desc: A description of the argument\n                type: str\n            -   name: type\n                desc: The type of the argument\n                type: str\n            -   name: subtypes\n                desc: >\n                    If @type is a list, dict or other data structure,\n                    the contained objects should be of this type.\n                    This should be a list of one item for lists, or a list\n                    of 2 items for a dict.  More than 2 items is not\n                    supported.\n                type: list\n                required: false\n                default: None\n            -   name: required\n                desc: >\n                    True if this is a mandatory argument, False if it\n                    has a default value.  If False, @default should be\n                    set appropriately.\n                type: bool\n                required: false\n                default: true\n            -   name: default\n                desc: >\n                    The default value for this argument.  This is ignored\n                    if @required == True\n                type: any\n            -   name: ctor\n                desc: >\n                    Only use if @type is a class instance and not a JSON type\n                    The constructor that the JSON object will be\n                    unmarshalled to.  Either the Class.__init__, or a\n                    factory function or factory static method.\n                    Use the full path: module.submodule.Class.__init__\n                type: str\n                required: false\n                default: None\n            -   name: hide\n                desc: >\n                    Don't display this argument to the user.  Useful for\n                    not showing arguments that are excluded from marshalling.\n                    Note that this is only a hint to the client that will\n                    render the JSON, the argument will still be sent\n                required: false\n                type: bool\n                default: false\n        returns:\n            desc: A DocStringArg instance with recursively populated\n                  @docstring attributes for child arguments\n            type: pymarshal.api_docs.docstring.DocStringArg\n        \"\"\"\n        if ctor:\n            type_assert(ctor, str)\n            module_name, cls_name, method_name = ctor.rsplit('.', 2)\n            module = importlib.import_module(module_name)\n            cls = getattr(module, cls_name)\n            method = getattr(cls, method_name)\n            docstring = DocString.from_ctor(method)\n        else:\n            docstring = None\n\n        return DocStringArg(\n            name,\n            desc,\n            type,\n            subtypes,\n            required,\n            default,\n            docstring=docstring,\n            hide=hide,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_ctor(\n        ctor,\n    ):\n        \"\"\"\n        desc: >\n            Turns a class constructor into an instance of DocString.\n            Pass in either Class.__init__, a factory function,\n            or factory static method.\n        args:\n            -   name: ctor\n                desc: The constructor method or function to use for\n                generating a DocString instance\n                type: function-or-method\n        raises:\n            -   type: AssertionError\n                desc: >\n                    When ctor does not have a docstring,\n                    or when @ctor's docstring does not match @ctor's\n                    method signature\n        \"\"\"\n        _docstring = inspect.getdoc(ctor)\n        assert _docstring is not None, \"No docstring for {}\".format(ctor)\n        obj = yaml.load(_docstring)\n        docstring = unmarshal_json(obj, DocString)\n        argspec = getargspec(ctor)\n        args, varargs, defaults = (\n            argspec.args,\n            argspec.varargs,\n            argspec.defaults,\n        )\n        if args[0] == 'self':\n            args = args[1:]\n        dargs = docstring.args\n        assert len(args) == len(dargs), (\n            \"{}: Mismatched arg counts: \\n{}\\n{}\".format(\n                ctor,\n                args,\n                dargs,\n            )\n        )\n        # Validate that the argument list matches\n        for arg1, arg2 in zip(args, dargs):\n            assert arg1 == arg2.name, (\n                \"{}: {} does not match {}\".format(\n                    ctor,\n                    arg1,\n                    arg2.name,\n                )\n            )\n        # Validate that the required arguments match\n        dreqs = dargs[:-len(defaults)] if defaults else dargs\n        for arg in dreqs:\n            assert arg.required, (\n                \"{}: {} should be required: true\".format(\n                    ctor,\n                    arg.name,\n                )\n            )\n        # Validate that the default arguments match\n        ddefaults = dargs[-len(defaults):] if defaults else []\n        for arg in ddefaults:\n            assert not arg.required, (\n                \"{}: {} should be required: false\".format(\n                    ctor,\n                    arg.name,\n                )\n            )\n        return docstring", "response": "Takes a class constructor and returns an instance of DocString."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbypass exception if some field was not decrypted.", "response": "def _bypass_non_decrypted_field_exception(self):\n        \"\"\"Bypass exception if some field was not decrypted.\"\"\"\n        if getattr(settings, 'PGPFIELDS_BYPASS_NON_DECRYPTED_FIELD_EXCEPTION', False):\n            return True\n        if getattr(settings, 'PGPFIELDS_BYPASS_FIELD_EXCEPTION_IN_MIGRATIONS', False):\n            # Since django versions <1.8 have no support of\n            # Manager.use_in_migrations, need to turn raising\n            # exception off.\n            if {'manage.py', 'migrate'}.issubset(sys.argv):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_events(**kwargs):\n    url = \"/r25ws/servlet/wrd/run/events.xml\"\n    if len(kwargs):\n        url += \"?%s\" % urlencode(kwargs)\n\n    return events_from_xml(get_resource(url))", "response": "Return a list of events matching the passed filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(cls, job_id, spider, workflow, results=None,\n               logs=None, status=JobStatus.PENDING):\n        \"\"\"Create a new entry for a scheduled crawler job.\"\"\"\n        obj = cls(\n            job_id=job_id,\n            spider=spider,\n            workflow=workflow,\n            results=results,\n            logs=logs,\n            status=status,\n        )\n        db.session.add(obj)\n        return obj", "response": "Create a new entry for a scheduled crawler job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_job(cls, job_id):\n        try:\n            return cls.query.filter_by(\n                job_id=job_id\n            ).one()\n        except NoResultFound:\n            raise CrawlerJobNotExistError(job_id)", "response": "Get a row by Job UUID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_binary_string(cls, stream):\n        offset = 0\n        length = len(stream)\n        feedbacks = []\n\n        while offset < length:\n            timestamp, token_length = struct.unpack(cls.FORMAT_PREFIX,\n                                                    stream[offset:offset+6])\n            when = datetime.fromtimestamp(timestamp)\n            offset += 6\n            token = struct.unpack('>{0}s'.format(token_length),\n                                  stream[offset:offset+token_length])[0]\n            token = binascii.hexlify(token)\n            offset += token_length\n            feedbacks.append(cls(when, token))\n\n        return feedbacks", "response": "Read all feedback information from the stream and unpack it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_binary_string(self):\n        timestamp = datetime_to_timestamp(self.when)\n        token = binascii.unhexlify(self.token)\n        return struct.pack(self.FORMAT_PREFIX + '{0}s'.format(len(token)),\n                           timestamp, len(token), token)", "response": "Pack the feedback to binary form and return it as string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_spaces(**kwargs):\n    url = \"/r25ws/servlet/wrd/run/spaces.xml\"\n    if len(kwargs):\n        url += \"?%s\" % urlencode(kwargs)\n\n    return spaces_from_xml(get_resource(url))", "response": "Return a list of spaces matching the passed filter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _manage_location(attr):\n    return property(lambda self: getattr(self, '_%s' % attr),\n                    lambda self, value: self._set_location(attr, value))", "response": "Build managed property interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string that can be used to format DM or DMS locations.", "response": "def _dms_formatter(latitude, longitude, mode, unistr=False):\n    \"\"\"Generate a human readable DM/DMS location string.\n\n    Args:\n        latitude (float): Location's latitude\n        longitude (float): Location's longitude\n        mode (str): Coordinate formatting system to use\n        unistr (bool): Whether to use extended character set\n    \"\"\"\n    if unistr:\n        chars = ('\u00b0', '\u2032', '\u2033')\n    else:\n        chars = ('\u00b0', \"'\", '\"')\n\n    latitude_dms = tuple(map(abs, utils.to_dms(latitude, mode)))\n    longitude_dms = tuple(map(abs, utils.to_dms(longitude, mode)))\n    text = []\n    if mode == 'dms':\n        text.append('%%02i%s%%02i%s%%02i%s' % chars % latitude_dms)\n    else:\n        text.append('%%02i%s%%05.2f%s' % chars[:2] % latitude_dms)\n    text.append('S' if latitude < 0 else 'N')\n    if mode == 'dms':\n        text.append(', %%03i%s%%02i%s%%02i%s' % chars % longitude_dms)\n    else:\n        text.append(', %%03i%s%%05.2f%s' % chars[:2] % longitude_dms)\n    text.append('W' if longitude < 0 else 'E')\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef speed(self):\n        if not len(self) > 1:\n            raise RuntimeError('More than one location is required')\n        try:\n            times = [i.time for i in self]\n        except AttributeError:\n            raise NotImplementedError('Not all Point objects include time '\n                                      'attribute')\n\n        return (distance / ((times[i + 1] - times[i]).seconds / 3600)\n                for i, distance in enumerate(self.distance()))", "response": "Calculate speed between points in km and h\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_tokens(self, phrase):\n\n        if len(phrase) == 1 and classifier_options.is_special_class_word(phrase[0]):\n            return True\n\n        tree = self.root\n        for token in phrase:\n            if not tree.has_child(token):\n                return False\n            tree = tree.get_child(token)\n\n        return True if tree.is_end_of_phrase() else None", "response": "Checks if a phrase or sub - phrase exists in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind word - ranges all of phrases in tokens stored in TokenTrie", "response": "def find_tracked_words(self, tokens):\n        \"\"\"\n        Finds word-ranges all of phrases in tokens stored in TokenTrie\n\n        :param tokens: Sequence of tokens to find phrases in\n        :type tokens: list of str\n        :return: List of Tokens found in tokens\n        \"\"\"\n        tracked_words = []\n\n        for i in range(len(tokens)):\n            for j in range(i + 1, len(tokens) + 1):\n                phrase = tokens[i:j]\n                status = self.has_tokens(phrase)\n\n                if status is not None:\n                    if status is True:\n                        tracked_words.append(TokenTrie.Token(phrase, i, j - 1))\n                    elif status is False:\n                        break\n\n        return tracked_words"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_optimal_allocation(self, tokens):\n        token_ranges = self.find_tracked_words(tokens)\n        token_ranges.sort()\n\n        for offset in range(1, len(token_ranges)):\n            to_be_removed = []\n            for candidate in token_ranges[offset:]:\n                for i in range(offset):\n                    if token_ranges[i].overlaps_with(candidate):\n                        to_be_removed.append(candidate)\n                        break\n\n            token_ranges = [token for token in token_ranges if token not in to_be_removed]\n\n        token_ranges.sort(key=lambda token: token.get_start_index())\n        return token_ranges", "response": "Finds longest non - overlapping word - ranges of phrases in tokens stored in TokenTrie\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntranslates a list of relational algebra trees into SQL statements.", "response": "def translate(root_list, use_bag_semantics=False):\n    \"\"\"\n    Translate a list of relational algebra trees into SQL statements.\n\n    :param root_list: a list of tree roots\n    :param use_bag_semantics: flag for using relational algebra bag semantics\n    :return: a list of SQL statements\n    \"\"\"\n    translator = (Translator() if use_bag_semantics else SetTranslator())\n    return [translator.translate(root).to_sql() for root in root_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_sql(self):\n        return self._sql_query_skeleton.format(\n            prefix=self.prefix, select=self.select_block,\n            relation=self.from_block, conditions=self.where_block)", "response": "Construct a SQL query based on the stored blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef relation(self, node):\n        return self.query(select_block=str(node.attributes),\n                          from_block=node.name)", "response": "Translate a relation node into SQLQuery."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select(self, node):\n\n        child_object = self.translate(node.child)\n        where_block = node.conditions\n        if child_object.where_block:\n              where_block = '({0}) AND ({1})'\\\n                  .format(child_object.where_block, node.conditions)\n        child_object.where_block = where_block\n        if not child_object.select_block:\n            child_object.select_block = str(node.attributes)\n        return child_object", "response": "Translate a select node into SQLQuery."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntranslates a project node into SQLQuery.", "response": "def project(self, node):\n        \"\"\"\n        Translate a project node into SQLQuery.\n        :param node: a treebrd node\n        :return: a SQLQuery object for the tree rooted at node\n        \"\"\"\n        child_object = self.translate(node.child)\n        child_object.select_block = str(node.attributes)\n        return child_object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename(self, node):\n        child_object = self.translate(node.child)\n        from_block = '({child}) AS {name}({attributes})'.format(\n            child=child_object.to_sql(), name=node.name,\n            attributes=', '.join(node.attributes.names))\n        return self.query(str(node.attributes), from_block=from_block)", "response": "Translate a rename node into SQLQuery."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate an assign node into SQLQuery.", "response": "def assign(self, node):\n        \"\"\"\n        Translate an assign node into SQLQuery.\n        :param node: a treebrd node\n        :return: a SQLQuery object for the tree rooted at node\n        \"\"\"\n        child_object = self.translate(node.child)\n        child_object.prefix = 'CREATE TEMPORARY TABLE {name}({attributes}) AS '\\\n            .format(name=node.name, attributes=', '.join(node.attributes.names))\n        return child_object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating a join node into SQLQuery.", "response": "def _join(self, node):\n        \"\"\"\n        Translate a join node into SQLQuery.\n        :param node: a treebrd node\n        :return: a SQLQuery object for the tree rooted at node\n        \"\"\"\n\n        select_block = str(node.attributes)\n        from_block = '{left} {operator} {right}'.format(\n            left=self._join_helper(node.left),\n            right=self._join_helper(node.right),\n            operator=self._get_sql_operator(node))\n\n        if node.operator == Operator.theta_join:\n            from_block = '{from_block} ON {conditions}'.format(\n                from_block=from_block,\n                conditions=node.conditions)\n\n        return self.query(select_block, from_block, '')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating a set operator node into SQLQuery.", "response": "def _set_op(self, node):\n        \"\"\"\n        Translate a set operator node into SQLQuery.\n        :param node: a treebrd node\n        :return: a SQLQuery object for the tree rooted at node\n        \"\"\"\n        select_block = str(node.attributes)\n        from_block = '({left} {operator} ALL {right}) AS {name}'.format(\n            left=self.translate(node.left).to_sql(),\n            right=self.translate(node.right).to_sql(),\n            operator=self._get_sql_operator(node), name=self._get_temp_name(node))\n        return self.query(select_block=select_block, from_block=from_block)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef can_finalise(self, step, exhausted, status):\n        return step in status and step in exhausted and status[step] == 'running' and all(in_ in exhausted[step] for in_ in step.ins)", "response": "Check if the step is running and the inputs are exhausted"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the step can next the next entry in the workflow.", "response": "def can_next(self, step, inputs, workflow, status):\n        \"\"\"\n        All the outputs are empty and status is running or finalising\n        :param step:\n        :param inputs:\n        :param workflow:\n        :param status:\n        :return:\n        \"\"\"\n        if not (step in status and status[step] in {'running', 'finalising'}):\n            return False\n        for out in step.outs:\n            if not all(inputs[consumer].is_writable(out) for consumer in workflow.get_parents(out)):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match(record, config=None):\n    if config is None:\n        current_app.logger.debug('No configuration provided. Falling back to the default configuration.')\n        config = current_app.config['MATCHER_DEFAULT_CONFIGURATION']\n\n    try:\n        algorithm, doc_type, index = config['algorithm'], config['doc_type'], config['index']\n    except KeyError as e:\n        raise KeyError('Malformed configuration: %s.' % repr(e))\n\n    source = config.get('source', [])\n    match_deleted = config.get('match_deleted', False)\n    collections = config.get('collections')\n    if not (collections is None or (\n            isinstance(collections, (list, tuple)) and\n            all(isinstance(collection, string_types) for collection in collections)\n    )):\n        raise ValueError('Malformed collections. Expected a list of strings bug got: %s' % repr(collections))\n\n    for i, step in enumerate(algorithm):\n        try:\n            queries = step['queries']\n        except KeyError:\n            raise KeyError('Malformed algorithm: step %d has no queries.' % i)\n\n        validator = _get_validator(step.get('validator'))\n\n        for j, query in enumerate(queries):\n            try:\n                body = compile(query, record, collections=collections, match_deleted=match_deleted)\n            except Exception as e:\n                raise ValueError('Malformed query. Query %d of step %d does not compile: %s.' % (j, i, repr(e)))\n\n            if not body:\n                continue\n\n            current_app.logger.debug('Sending ES query: %s' % repr(body))\n\n            if source:\n                result = es.search(index=index, doc_type=doc_type, body=body, _source=source)\n            else:\n                result = es.search(index=index, doc_type=doc_type, body=body)\n\n            for hit in result['hits']['hits']:\n                if validator(record, hit):\n                    yield hit", "response": "Given a record yield the records in INSPIRE most similar to it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging a into b", "response": "def merge(a, b, path=None):\n    \"\"\"merges b into a\n\n    >>> a={1:{\"a\":\"A\"},2:{\"b\":\"B\"}, 8:[]}\n    >>> b={2:{\"c\":\"C\"},3:{\"d\":\"D\"}}\n\n    >>> c = merge(a, b)\n    >>> c == a == {8: [], 1: {\"a\": \"A\"}, 2: {\"c\": \"C\", \"b\": \"B\"}, 3: {\"d\": \"D\"}}\n    True\n\n    >>> c = merge(a, {1: \"a\"})\n    >>> print(c[1])\n    a\n    \"\"\"\n    if path is None:\n        path = []\n    for key in b:\n        if key in a:\n            if isinstance(a[key], dict) and isinstance(b[key], dict):\n                merge(a[key], b[key], path + [str(key)])\n            elif a[key] == b[key]:\n                pass  # same leaf value\n            else:\n                a[key] = b[key]\n                # raise Exception(\"Conflict at %s (%s %s)\" % (\".\".join(path + [str(key)]),\n                #                 a[key], b[key]))\n        else:\n            a[key] = b[key]\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self, database, timezone=None, cache_size=0, auto_ensure=True, replica_set=None, *args, **kwds):\n\t\t''' `connect` is a thin wrapper around __init__ which creates the\n\t\t\tdatabase connection that the session will use.\n\n\t\t\t:param database: the database name to use.  Should be an instance of \\\n\t\t\t\t\t:class:`basestring`\n\t\t\t:param safe: The value for the \"safe\" parameter of the Session \\\n\t\t\t\tinit function\n\t\t\t:param auto_ensure: Whether to implicitly call ensure_indexes on all write \\\n\t\t\t\toperations.\n\t\t\t:param replica_set: The replica-set to use (as a string). If specified, \\\n\t\t\t\t:class:`pymongo.mongo_replica_set_client.MongoReplicaSetClient` is used \\\n\t\t\t\tinstead of :class:`pymongo.mongo_client.MongoClient`\n\t\t\t:param args: arguments for :class:`pymongo.mongo_client.MongoClient`\n\t\t\t:param kwds: keyword arguments for :class:`pymongo.mongo_client.MongoClient`\n\t\t'''\n\t\tsafe = kwds.get('safe', False)\n\t\tif 'safe' in kwds:\n\t\t\tdel kwds['safe']\n\t\tif timezone is not None:\n\t\t\tkwds['tz_aware'] = True\n\n\t\tif replica_set is not None:\n\t\t\tif 'MongoReplicaSetClient' in globals():\n\t\t\t\tconn = MongoReplicaSetClient(*args, replicaSet=replica_set, **kwds)\n\t\t\telse: # pragma: no cover\n\t\t\t\tconn = MongoClient(*args, replicaSet=replica_set, **kwds)\n\t\telse:\n\t\t\tconn = MongoClient(*args, **kwds)\n\n\t\tdb = conn[database]\n\t\treturn Session(db, timezone=timezone, safe=safe, cache_size=cache_size, auto_ensure=auto_ensure)", "response": "Connect to a database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef end(self):\n\t\t''' End the session.  Flush all pending operations and ending the\n\t\t\t*pymongo* request'''\n\t\tself.cache = {}\n\t\tif self.transactions:\n\t\t\traise TransactionException('Tried to end session with an open '\n\t\t\t\t\t\t\t\t\t   'transaction')\n\t\tif not PYMONGO_3:\n\t\t\tself.db.connection.end_request()", "response": "End the session.  Flush all pending operations and ending the\n\t\t\t*pymongo* request"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts an item into the work queue.", "response": "def insert(self, item, safe=None): # pragma: nocover\n\t\t''' [DEPRECATED] Please use save() instead. This actually calls\n\t\t\tthe underlying save function, so the name is confusing.\n\n\t\t\tInsert an item into the work queue and flushes.'''\n\t\twarnings.warn('Insert will be deprecated soon and removed in 1.0. Please use insert',\n\t\t\t\t\t  PendingDeprecationWarning)\n\t\tself.add(item, safe=safe)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an item into the queue of things to be inserted. Does not flush.", "response": "def add(self, item, safe=None):\n\t\t''' Add an item into the queue of things to be inserted.  Does not flush.'''\n\t\titem._set_session(self)\n\t\tif safe is None:\n\t\t\tsafe = self.safe\n\t\tself.queue.append(SaveOp(self.transaction_id, self, item, safe))\n\t\t# after the save op is recorded, the document has an _id and can be\n\t\t# cached\n\t\tself.cache_write(item)\n\t\tif self.autoflush:\n\t\t\treturn self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates an item in the database.", "response": "def update(self, item, id_expression=None, upsert=False, update_ops={}, safe=None, **kwargs):\n\t\t''' Update an item in the database.  Uses the on_update keyword to each\n\t\t\tfield to decide which operations to do, or.\n\n\t\t\t:param item: An instance of a :class:`~ommongo.document.Document` \\\n\t\t\t\tsubclass\n\t\t\t:param id_expression: A query expression that uniquely picks out \\\n\t\t\t\tthe item which should be updated.  If id_expression is not \\\n\t\t\t\tpassed, update uses item.mongo_id.\n\t\t\t:param upsert: Whether the update operation should be an upsert. \\\n\t\t\t\tIf the item may not be in the database yet this should be True\n\t\t\t:param update_ops: By default the operation used to update a field \\\n\t\t\t\tis specified with the on_update argument to its constructor. \\\n\t\t\t\tTo override that value, use this dictionary, with  \\\n\t\t\t\t:class:`~ommongo.document.QueryField` objects as the keys \\\n\t\t\t\tand the mongo operation to use as the values.\n\t\t\t:param kwargs: The kwargs are merged into update_ops dict to \\\n\t\t\t\tdecide which fields to update the operation for.  These can \\\n\t\t\t\tonly be for the top-level document since the keys \\\n\t\t\t\tare just strings.\n\n\t\t\t.. warning::\n\n\t\t\t\tThis operation is **experimental** and **not fully tested**,\n\t\t\t\talthough it does have code coverage.\n\t\t\t'''\n\t\tif safe is None:\n\t\t\tsafe = self.safe\n\t\tself.queue.append(UpdateDocumentOp(self.transaction_id, self, item, safe, id_expression=id_expression,\n\t\t\t\t\t\t  upsert=upsert, update_ops=update_ops, **kwargs))\n\t\tif self.autoflush:\n\t\t\treturn self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbegin a query on the database s collection for type.", "response": "def query(self, type, exclude_subclasses=False):\n\t\t''' Begin a query on the database's collection for `type`.  If `type`\n\t\t\tis an instance of basesting, the query will be in raw query mode\n\t\t\twhich will not check field values or transform returned results\n\t\t\tinto python objects.\n\n\t\t .. seealso:: :class:`~ommongo.query.Query` class'''\n\t\t# This really should be adding a query operation to the\n\t\t# queue which is then forced to execute when the results are being\n\t\t# read\n\t\tif isinstance(type, basestring):\n\t\t\ttype = FreeFormDoc(type)\n\t\treturn Query(type, self, exclude_subclasses=exclude_subclasses)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a query on the database.", "response": "def execute_query(self, query, session):\n\t\t''' Get the results of ``query``.  This method does flush in a\n\t\t\ttransaction, so any objects retrieved which are not in the cache\n\t\t\twhich would be updated when the transaction finishes will be\n\t\t\tstale '''\n\t\tself.auto_ensure_indexes(query.type)\n\n\t\tkwargs = dict()\n\t\tif query._get_fields():\n\t\t\tif PYMONGO_3: # pragma: nocover\n\t\t\t\tkwargs['projection'] = query._fields_expression()\n\t\t\telse: # pragma: nocover\n\t\t\t\tkwargs['fields'] = query._fields_expression()\n\n\t\tcollection = self.db[query.type.get_collection_name()]\n\t\t\n\t\tif query._search:\n\t\t\tindex_fields = query._createIndex\n\t\t\tif index_fields:\n\t\t\t\t# create new index\n\t\t\t\tif type(index_fields) is list:\n\t\t\t\t\tindex_list = []\n\t\t\t\t\tfor field in index_fields:\n\t\t\t\t\t\tindex_list.append ((field, pymongo.TEXT))\n\t\t\t\t\tcollection.create_index(index_list, name='search_index', default_language='english')\n\t\t\t\telse:\n\t\t\t\t\traise InvalidConfigException()\n\t\t\tcursor = collection.find(query.query, {'__index_score': {'$meta': \"textScore\"}}, **kwargs)\n\t\t\tcursor.sort([('__index_score', {'$meta': 'textScore'})])\n\t\telif query._rawquery:\n\t\t\tif query._query_type=='aggregate':\n\t\t\t\tcursor = collection.aggregate(query.query, cursor={}, **kwargs)\n\t\t\telif query._query_type=='map_reduce':\n\t\t\t\tcursor = collection.map_reduce( query._mapreduce_mapper, query._mapreduce_reducer, query._mapreduce_key, query=query._mapreduce_query)\n\t\telse:\n\t\t\tcursor = collection.find(query.query, **kwargs)\n\n\t\tif query._sort:\n\t\t\tcursor.sort(query._sort)\n\t\telif query.type.config_default_sort:\n\t\t\tcursor.sort(query.type.config_default_sort)\n\t\tif query.hints:\n\t\t\tcursor.hint(query.hints)\n\t\tif query._get_limit() is not None:\n\t\t\tcursor.limit(query._get_limit())\n\t\tif query._get_skip() is not None:\n\t\t\tcursor.skip(query._get_skip())\n\t\treturn QueryResult(session, cursor, query.type, raw_output=query._raw_output, fields=query._get_fields())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, obj, safe=None):\n\t\t'''\n\t\t\tRemove a particular object from the database.  If the object has\n\t\t\tno mongo ID set, the method just returns.  If this is a partial\n\t\t\tdocument without the mongo ID field retrieved a ``FieldNotRetrieved``\n\t\t\twill be raised\n\n\t\t\t:param obj: the object to save\n\t\t\t:param safe: whether to wait for the operation to complete.  Defaults \\\n\t\t\t\tto the session's ``safe`` value.\n\t\t'''\n\t\tif safe is None:\n\t\t\tsafe = self.safe\n\t\tremove = RemoveDocumentOp(self.transaction_id, self, obj, safe)\n\t\tself.queue.append(remove)\n\t\tif self.autoflush:\n\t\t\treturn self.flush()", "response": "This method removes a particular object from the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a remove expression. Should generally only be called implicitly.", "response": "def execute_remove(self, remove):\n\t\t''' Execute a remove expression.  Should generally only be called implicitly.\n\t\t'''\n\n\t\tsafe = self.safe\n\t\tif remove.safe is not None:\n\t\t\tsafe = remove.safe\n\n\t\tself.queue.append(RemoveOp(self.transaction_id, self, remove.type, safe, remove))\n\t\tif self.autoflush:\n\t\t\treturn self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_update(self, update, safe=False):\n\t\t''' Execute an update expression.  Should generally only be called implicitly.\n\t\t'''\n\n\t\t# safe = self.safe\n\t\t# if update.safe is not None:\n\t\t#     safe = remove.safe\n\n\t\tassert len(update.update_data) > 0\n\t\tself.queue.append(UpdateOp(self.transaction_id, self, update.query.type, safe, update))\n\t\tif self.autoflush:\n\t\t\treturn self.flush()", "response": "Execute an update expression."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear the queue of pending database operations without executing any of the pending operations.", "response": "def clear_queue(self, trans_id=None):\n\t\t''' Clear the queue of database operations without executing any of\n\t\t\t the pending operations'''\n\t\tif not self.queue:\n\t\t\treturn\n\t\tif trans_id is None:\n\t\t\tself.queue = []\n\t\t\treturn\n\n\t\tfor index, op in enumerate(self.queue):\n\t\t\tif op.trans_id == trans_id:\n\t\t\t\tbreak\n\t\tself.queue = self.queue[:index]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_collection(self, *classes):\n\t\t''' Clear all objects from the collections associated with the\n\t\t\tobjects in `*cls`. **use with caution!**'''\n\t\tfor c in classes:\n\t\t\tself.queue.append(ClearCollectionOp(self.transaction_id, self, c))\n\t\tif self.autoflush:\n\t\t\tself.flush()", "response": "Clear all objects from the collections associated with the specified classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flush(self, safe=None):\n\t\t''' Perform all database operations currently in the queue'''\n\t\tresult = None\n\t\tfor index, op in enumerate(self.queue):\n\t\t\ttry:\n\t\t\t\tresult = op.execute()\n\t\t\texcept:\n\t\t\t\tself.clear_queue()\n\t\t\t\tself.clear_cache()\n\t\t\t\traise\n\t\tself.clear_queue()\n\t\treturn result", "response": "Perform all database operations currently in the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a new copy of a document from the database.", "response": "def refresh(self, document):\n\t\t\"\"\" Load a new copy of a document from the database.  does not\n\t\t\treplace the old one \"\"\"\n\t\ttry:\n\t\t\told_cache_size = self.cache_size\n\t\t\tself.cache_size = 0\n\t\t\tobj = self.query(type(document)).filter_by(mongo_id=document.mongo_id).one()\n\t\tfinally:\n\t\t\tself.cache_size = old_cache_size\n\t\tself.cache_write(obj)\n\t\treturn obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes a document remove its _id and deserialize as a new object", "response": "def clone(self, document):\n\t\t''' Serialize a document, remove its _id, and deserialize as a new\n\t\t\tobject '''\n\n\t\twrapped = document.wrap()\n\t\tif '_id' in wrapped:\n\t\t\tdel wrapped['_id']\n\t\treturn type(document).unwrap(wrapped, session=self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patch_dynamodb_connection(**kwargs):\n    if hasattr(DynamoDBConnection, '__original_init__'):\n        return\n\n    DynamoDBConnection.__original_init__ = DynamoDBConnection.__init__\n\n    def init(self, **fkwargs):\n        fkwargs.update(kwargs)\n        self.__original_init__(**fkwargs)\n\n    DynamoDBConnection.__init__ = init", "response": "This patcher allows you to change the DynamoDB connection configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        orm.Project.objects.update(label=F('name'))\n        orm.Cohort.objects.update(label=F('name'))\n        orm.Sample.objects.update(name=F('label'))", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting your backwards methods here.", "response": "def backwards(self, orm):\n        \"Write your backwards methods here.\"\n        orm.Project.objects.update(label=None)\n        orm.Cohort.objects.update(label=None)\n        orm.Sample.objects.update(name=None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the width of barcodes in modules for a given data and character set combination.", "response": "def width(self, add_quiet_zone=False):\n        \"\"\"Return the barcodes width in modules for a given data and character set combination.\n\n        :param add_quiet_zone: Whether quiet zone should be included in the width.\n\n        :return: Width of barcode in modules, which for images translates to pixels.\n        \"\"\"\n        quiet_zone = self.quiet_zone if add_quiet_zone else 0\n        return len(self.modules) + 2 * quiet_zone"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_charset(data, charset):\n        if len(charset) > 1:\n            charset_data_length = 0\n            for symbol_charset in charset:\n                if symbol_charset not in ('A', 'B', 'C'):\n                    raise Code128.CharsetError\n                charset_data_length += 2 if symbol_charset is 'C' else 1\n            if charset_data_length != len(data):\n                raise Code128.CharsetLengthError\n        elif len(charset) == 1:\n            if charset not in ('A', 'B', 'C'):\n                raise Code128.CharsetError\n        elif charset is not None:\n            raise Code128.CharsetError", "response": "Validate that the charset is correct and throw an error if it isn t."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes the data using the character sets in charsets.", "response": "def _encode(cls, data, charsets):\n        \"\"\"Encode the data using the character sets in charsets.\n\n        :param data: Data to be encoded.\n        :param charsets: Sequence of charsets that are used to encode the barcode.\n                         Must be the exact amount of symbols needed to encode the data.\n        :return: List of the symbol values representing the barcode.\n        \"\"\"\n        result = []\n\n        charset = charsets[0]\n        start_symbol = cls._start_codes[charset]\n        result.append(cls._sym2val[charset][start_symbol])\n\n        cur = 0\n        prev_charset = charsets[0]\n        for symbol_num in range(len(charsets)):\n            charset = charsets[symbol_num]\n\n            if charset is not prev_charset:\n                # Handle a special case of there being a single A in middle of two B's or the other way around, where\n                # using a single shift character is more efficient than using two character set switches.\n                next_charset = charsets[symbol_num + 1] if symbol_num + 1 < len(charsets) else None\n                if charset == 'A' and prev_charset == next_charset == 'B':\n                    result.append(cls._sym2val[prev_charset][cls.Special.SHIFT_A])\n                elif charset == 'B' and prev_charset == next_charset == 'A':\n                    result.append(cls._sym2val[prev_charset][cls.Special.SHIFT_B])\n                else:\n                    # This is the normal case.\n                    charset_symbol = cls._char_codes[charset]\n                    result.append(cls._sym2val[prev_charset][charset_symbol])\n                    prev_charset = charset\n\n            nxt = cur + (2 if charset == 'C' else 1)\n            symbol = data[cur:nxt]\n            cur = nxt\n            result.append(cls._sym2val[charset][symbol])\n\n        result.append(cls._calc_checksum(result))\n        result.append(cls._sym2val[charset][cls.Special.STOP])\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting of the coded symbols as strings with special characters included.", "response": "def symbols(self):\n        \"\"\"List of the coded symbols as strings, with special characters included.\"\"\"\n        def _iter_symbols(symbol_values):\n            # The initial charset doesn't matter, as the start codes have the same symbol values in all charsets.\n            charset = 'A'\n\n            shift_charset = None\n            for symbol_value in symbol_values:\n                if shift_charset:\n                    symbol = self._val2sym[shift_charset][symbol_value]\n                    shift_charset = None\n                else:\n                    symbol = self._val2sym[charset][symbol_value]\n\n                if symbol in (self.Special.START_A, self.Special.CODE_A):\n                    charset = 'A'\n                elif symbol in (self.Special.START_B, self.Special.CODE_B):\n                    charset = 'B'\n                elif symbol in (self.Special.START_C, self.Special.CODE_C):\n                    charset = 'C'\n                elif symbol in (self.Special.SHIFT_A,):\n                    shift_charset = 'A'\n                elif symbol in (self.Special.SHIFT_B,):\n                    shift_charset = 'B'\n\n                yield symbol\n\n        return list(_iter_symbols(self.symbol_values))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modules(self):\n        def _iterate_modules(bars):\n            is_bar = True\n            for char in map(int, bars):\n                while char > 0:\n                    char -= 1\n                    yield 0 if is_bar else 1\n                is_bar = not is_bar\n\n        return list(_iterate_modules(self.bars))", "response": "A list of the modules in the barcode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calc_checksum(values):\n        checksum = values[0]\n        for index, value in enumerate(values):\n            checksum += index * value\n        return checksum % 103", "response": "Calculate the symbol check character."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the barcode as PIL. Image.", "response": "def image(self, height=1, module_width=1, add_quiet_zone=True):\n        \"\"\"Get the barcode as PIL.Image.\n\n        By default the image is one pixel high and the number of modules pixels wide, with 10 empty modules added to\n        each side to act as the quiet zone. The size can be modified by setting height and module_width, but if used in\n        a web page it might be a good idea to do the scaling on client side.\n\n        :param height: Height of the image in number of pixels.\n        :param module_width: A multiplier for the width.\n        :param add_quiet_zone: Whether to add 10 empty modules to each side of the barcode.\n\n        :rtype: PIL.Image\n        :return: A monochromatic image containing the barcode as black bars on white background.\n        \"\"\"\n        if Image is None:\n            raise Code128.MissingDependencyError(\"PIL module is required to use image method.\")\n\n        modules = list(self.modules)\n        if add_quiet_zone:\n            # Add ten space modules to each side of the barcode.\n            modules = [1] * self.quiet_zone + modules + [1] * self.quiet_zone\n        width = len(modules)\n\n        img = Image.new(mode='1', size=(width, 1))\n        img.putdata(modules)\n\n        if height == 1 and module_width == 1:\n            return img\n        else:\n            new_size = (width * module_width, height)\n            return img.resize(new_size, resample=Image.NEAREST)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data_url(self, image_format='png', add_quiet_zone=True):\n        memory_file = io.BytesIO()\n        pil_image = self.image(add_quiet_zone=add_quiet_zone)\n\n        # Using BMP can often result in smaller data URLs than PNG, but it isn't as widely supported by browsers as PNG.\n        # GIFs result in data URLs 10 times bigger than PNG or BMP, possibly due to lack of support for monochrome GIFs\n        # in Pillow, so they shouldn't be used.\n        if image_format == 'png':\n            # Unfortunately there is no way to avoid adding the zlib headers.\n            # Using compress_level=0 sometimes results in a slightly bigger data size (by a few bytes), but there\n            # doesn't appear to be a difference between levels 9 and 1, so let's just use 1.\n            pil_image.save(memory_file, format='png', compress_level=1)\n        elif image_format == 'bmp':\n            pil_image.save(memory_file, format='bmp')\n        else:\n            raise Code128.UnknownFormatError('Only png and bmp are supported.')\n\n        # Encode the data in the BytesIO object and convert the result into unicode.\n        base64_image = base64.b64encode(memory_file.getvalue()).decode('ascii')\n\n        data_url = 'data:image/{format};base64,{base64_data}'.format(\n            format=image_format,\n            base64_data=base64_image\n        )\n\n        return data_url", "response": "Get a data URL representing the barcode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_auth_token(self):\n        url = '/%s/oauth2/token' % getattr(\n            settings, 'RESTCLIENTS_O365_TENANT', 'test')\n        headers = {'Accept': 'application/json'}\n        data = {\n            \"grant_type\": \"client_credentials\",\n            \"client_id\": getattr(settings,\n                                 'RESTCLIENTS_O365_CLIENT_ID',\n                                 None),\n            \"client_secret\": getattr(settings,\n                                     'RESTCLIENTS_O365_CLIENT_SECRET',\n                                     None),\n            \"resource\": self._api_host\n        }\n        body = urlencode(data)\n        auth_pool = self._get_pool(self._auth_host)\n        response = get_live_url(auth_pool, 'POST', self._auth_host,\n                                url, headers=headers, body=body,\n                                service_name='o365')\n        try:\n            json_data = json.loads(response.data)\n            if response.status == 200:\n                return \"%s %s\" % (\n                    json_data['token_type'], json_data['access_token'])\n            else:\n                raise DataFailureException(\n                    url, response.status,\n                    'Auth token failure: %s - %s' % (\n                        json_data.get('error', 'unknown'),\n                        json_data.get('error_description', 'no description')))\n        except ValueError:\n            raise DataFailureException(\n                url, response.status,\n                'Auth token failure: %s' % (response.data))", "response": "Get a new authorization token from the office356 tenant and client id and client secret."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_method_from_module(module_path, method_name):\n    top_module = __import__(module_path)\n\n    module = top_module\n    # we tunnel down until we find the module we want\n    for submodule_name in module_path.split('.')[1:]:\n        module = getattr(module, submodule_name)\n\n    assert hasattr(module, method_name), \\\n        \"unable to find method {0} from module {1}. does the method exist?\".format(method_name, module_path)\n    return getattr(module, method_name)", "response": "get the run method from a python module path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_env_by_folder(folder):\n    global _default_filters\n    global _default_tests\n    env = jinja2.Environment(loader=jinja2.FileSystemLoader(folder))\n\n    for k, f in _default_filters.iteritems():\n        env.filters[k] = f\n\n    for k, f in _default_tests.iteritems():\n        env.tests[k] = f\n\n    return env", "response": "Create a Jinja2 environment by folder path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_template(template_path):\n    folder, fname = os.path.split(template_path)\n    return create_env_by_folder(folder).get_template(fname)", "response": "Get template object from absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(template_path, output_file=None, **kwargs):\n    template = get_template(template_path)\n    rendered = template.render(**kwargs)\n    if not output_file:\n        return rendered\n    with open(output_file) as f:\n        f.write(rendered)", "response": "Render a jinja2 template file and write it to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plugin(tree, file_tokens):\n    for token in file_tokens:\n        if token[0] != STRING:  # token[0] == token.type\n            continue\n        # token[1] == token.string # python 3\n        invalid_sequence_match = invalid_escape_sequence_match(token[1])\n        if invalid_sequence_match:\n            yield (\n                token[2][0],  # line_number\n                token[2][1],  # offset\n                'IES: invalid escape sequence %s' %\n                invalid_sequence_match.group(1),  # text\n                None  # check # unused\n            )", "response": "Walk the tree and detect invalid escape sequences."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove previously assigned callback. :return True in case the callback was successfully removed, False otherwise.", "response": "def unlisten(self, event, callback):\n        \"\"\"\n        Remove previously assigned callback.\n        :return True in case the callback was successfully removed, False\n        otherwise.\n        \"\"\"\n        try:\n            self.listeners[event].remove(callback)\n        except ValueError:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfire all callbacks assigned to a particular event.", "response": "def dispatchEvent(self, event, *args):\n        \"\"\"\n        Fire all callbacks assigned to a particular event. To be called by\n        derivative classes.\n        :param *args: Additional arguments to be passed to the callback\n        function.\n        \"\"\"\n        for callback in self.listeners[event]:\n            yield callback(event, self, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple of the values that pertain to this constraint.", "response": "def extract_values(self, possible_solution, use_defaults=False):\n        \"\"\"Returns a tuple of the values that pertain to this constraint.\n\n        It simply filters all values to by the variables this constraint uses.\n        \"\"\"\n        defaults = self._vardefaults if use_defaults else {}\n        values = list(self._template)\n        for i, var in enumerate(self._vars):\n            values[i] = possible_solution.get(var, defaults.get(var, NilObject()))\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an Appointee Person object", "response": "def _get_appointee(id):\n    \"\"\"\n    Return a restclients.models.hrp.AppointeePerson object\n    \"\"\"\n    url = \"%s%s.json\" % (URL_PREFIX, id)\n    response = get_resource(url)\n    return process_json(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the GNU miscfiles_City data files and return a list containing the cities in the correct format.", "response": "def import_locations(self, data):\n        \"\"\"Parse `GNU miscfiles`_ cities data files.\n\n        ``import_locations()`` returns a list containing :class:`City` objects.\n\n        It expects data files in the same format that `GNU miscfiles`_\n        provides, that is::\n\n            ID          : 1\n            Type        : City\n            Population  : 210700\n            Size        : \n            Name        : Aberdeen\n             Country    : UK\n             Region     : Scotland\n            Location    : Earth\n             Longitude  : -2.083\n             Latitude   :   57.150\n             Elevation  : \n            Date        : 19961206\n            Entered-By  : Rob.Hooft@EMBL-Heidelberg.DE\n            //\n            ID          : 2\n            Type        : City\n            Population  : 1950000\n            Size        : \n            Name        : Abidjan\n             Country    : Ivory Coast\n             Region     : \n            Location    : Earth\n             Longitude  : -3.867\n             Latitude   :    5.333\n             Elevation  : \n            Date        : 19961206\n            Entered-By  : Rob.Hooft@EMBL-Heidelberg.DE\n\n        When processed by ``import_locations()`` will return ``list`` object in\n        the following style::\n\n            [City(1, \"City\", 210700, None, \"Aberdeen\", \"UK\", \"Scotland\",\n                  \"Earth\", -2.083, 57.15, None, (1996, 12, 6, 0, 0, 0, 4,\n                  341, -1), \"Rob.Hooft@EMBL-Heidelberg.DE\"),\n             City(2, \"City\", 1950000, None, \"Abidjan\", \"Ivory Coast\", \"\",\n                  \"Earth\", -3.867, 5.333, None, (1996, 12, 6, 0, 0, 0, 4,\n                  341, -1), \"Rob.Hooft@EMBL-Heidelberg.DE\")])\n\n        Args:\n            data (iter): :abbr:`NOAA (National Oceanographic and Atmospheric Administration)`\n                station data to read\n\n        Returns:\n            list: Places as ``City`` objects\n\n        Raises:\n            TypeError: Invalid value for data\n\n        .. _GNU miscfiles: http://directory.fsf.org/project/miscfiles/\n        \"\"\"\n        self._data = data\n        if hasattr(data, 'read'):\n            data = data.read().split('//\\n')\n        elif isinstance(data, list):\n            pass\n        elif isinstance(data, basestring):\n            data = open(data).read().split('//\\n')\n        else:\n            raise TypeError('Unable to handle data of type %r' % type(data))\n\n        keys = ('identifier', 'ptype', 'population', 'size', 'name', 'country',\n                'region', 'location', 'longitude', 'latitude', 'altitude',\n                'date', 'entered')\n\n        for record in data:\n            # We truncate after splitting because the v1.4.2 datafile contains\n            # a broken separator between 229 and 230 that would otherwise break\n            # the import\n            data = [i.split(':')[1].strip() for i in record.splitlines()[:13]]\n            entries = dict(zip(keys, data))\n\n            # Entry for Utrecht has the incorrect value of 0.000 for elevation.\n            if entries['altitude'] == '0.000':\n                logging.debug(\"Ignoring `0.000' value for elevation in %r \"\n                              'entry' % record)\n                entries['altitude'] = ''\n            for i in ('identifier', 'population', 'size', 'altitude'):\n                entries[i] = int(entries[i]) if entries[i] else None\n            for i in ('longitude', 'latitude'):\n                entries[i] = float(entries[i]) if entries[i] else None\n            entries['date'] = time.strptime(entries['date'], '%Y%m%d')\n            self.append(City(**entries))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the Imgur API.", "response": "def query_api(app, client_id, imgur_id, is_album):\n    \"\"\"Query the Imgur API.\n\n    :raise APIError: When Imgur responds with errors or unexpected data.\n\n    :param sphinx.application.Sphinx app: Sphinx application object.\n    :param str client_id: Imgur API client ID to use. https://api.imgur.com/oauth2\n    :param str imgur_id: The Imgur ID to query.\n    :param bool is_album: If this ID is an album instead of an image.\n\n    :return: Parsed JSON.\n    :rtype: dict\n    \"\"\"\n    url = API_URL.format(type='album' if is_album else 'image', id=imgur_id)\n    headers = {'Authorization': 'Client-ID {}'.format(client_id)}\n    timeout = 5\n\n    # Query.\n    app.info('querying {}'.format(url))\n    try:\n        response = requests.get(url, headers=headers, timeout=timeout)\n    except (requests.exceptions.ConnectTimeout, requests.exceptions.ReadTimeout, requests.Timeout) as exc:\n        raise APIError('timed out waiting for reply from {}: {}'.format(url, str(exc)), app)\n    except requests.ConnectionError as exc:\n        raise APIError('unable to connect to {}: {}'.format(url, str(exc)), app)\n    app.debug2('Imgur API responded with: %s', response.text)\n\n    # Parse JSON.\n    try:\n        parsed = response.json()\n    except ValueError:\n        raise APIError('failed to parse JSON from {}'.format(url), app)\n\n    # Verify data.\n    if not parsed.get('success'):\n        if 'data' not in parsed:\n            message = 'no \"data\" key in JSON'\n        elif 'error' not in parsed['data']:\n            message = 'no \"error\" key in JSON'\n        else:\n            message = parsed['data']['error']\n        raise APIError('query unsuccessful from {}: {}'.format(url, message), app)\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses API response. :param dict data: Parsed JSON response from API 'data' key.", "response": "def _parse(self, data):\n        \"\"\"Parse API response.\n\n        :param dict data: Parsed JSON response from API 'data' key.\n        \"\"\"\n        self.description = data['description']\n        self.in_gallery = data['in_gallery']\n        self.mod_time = int(time.time())\n        self.title = data['title']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn number of seconds left before this instance is expired.", "response": "def seconds_remaining(self, ttl):\n        \"\"\"Return number of seconds left before Imgur API needs to be queried for this instance.\n\n        :param int ttl: Number of seconds before this is considered out of date.\n\n        :return: Seconds left before this is expired. 0 indicated update needed (no negatives).\n        :rtype: int\n        \"\"\"\n        return max(0, ttl - (int(time.time()) - self.mod_time))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh(self, app, client_id, ttl):\n        remaining = self.seconds_remaining(ttl)\n        if remaining:\n            app.debug2('Imgur ID %s still has %d seconds before needing refresh. Skipping.', self.imgur_id, remaining)\n            return\n\n        # Retrieve data.\n        response = query_api(app, client_id, self.imgur_id, self.KIND == 'album')\n\n        # Parse.\n        try:\n            return self._parse(response['data'])\n        except KeyError as exc:\n            raise APIError('unexpected JSON for {}: {}'.format(self.imgur_id, repr(exc)), app)", "response": "Refresh the current instance s attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse(self, data):\n        super(Image, self)._parse(data)\n        self.height = data['height']\n        self.type = data['type']\n        self.width = data['width']", "response": "Parse API response.\n\n        :param dict data: Parsed JSON response from API 'data' key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the filename to use for the image.", "response": "def filename(self, display_width='', display_height='', full_size=False):\n        \"\"\"Determine which resized Imgur filename to use based on the display width/height. Includes the extension.\n\n        :param str display_width: Display width from Sphinx directive options (e.g. '100px', '50%').\n        :param str display_height: Display height from Sphinx directive options (e.g. '100px', '50%').\n        :param bool full_size: Always return the original full size image filename.\n\n        :return: The filename to use in <img src=\"...\">.\n        :rtype: str\n        \"\"\"\n        extension = self.type[-3:] if self.type in ('image/png', 'image/gif') else 'jpg'\n        if extension == 'gif' or full_size:\n            return '{}.{}'.format(self.imgur_id, extension)  # Imgur doesn't animate resized versions.\n        size = 'h'  # Default is 'huge' since all Sphinx themes limit document width to < 1024px.\n        if (not display_width and not display_height) or not self.width or not self.height:\n            return '{}{}.{}'.format(self.imgur_id, size, extension)\n\n        # Parse display_width and display_height.\n        if display_width.endswith('px'):\n            width = int(display_width[:-2])\n        elif display_width.endswith('%'):\n            width = self.width * (int(display_width[:-1]) / 100.0)\n        elif display_height.endswith('px'):\n            width = (self.width * int(display_height[:-2])) / self.height\n        else:\n            width = self.width\n\n        # Determine size.\n        if width <= 160:\n            size = 't'\n        elif width <= 320:\n            size = 'm'\n        elif width <= 640:\n            size = 'l'\n        return '{}{}.{}'.format(self.imgur_id, size, extension)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing API response from API key.", "response": "def _parse(self, data):\n        \"\"\"Parse API response.\n\n        :param dict data: Parsed JSON response from API 'data' key.\n\n        :return: Image instances.\n        :rtype: list.\n        \"\"\"\n        super(Album, self)._parse(data)\n        self.cover_id = data['cover']\n        images = [Image(i['id'], i) for i in data['images']]\n        self.image_ids[:] = [i.imgur_id for i in images]\n        return images"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh(self, app, client_id, ttl):\n        return super(Album, self).refresh(app, client_id, ttl) or list()", "response": "Query the API to update this instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a child node to the current node instance.", "response": "def add_child(self, node):\n        \"\"\"Add a child node to the current node instance.\n\n        :param node: the child node instance.\n        :type node: Node\n        :returns: The new child node instance.   \n        :rtype: Node \n        \"\"\"\n        if not issubclass(node.__class__, Node):\n            raise TypeError(\"{}.add_child: arg \u00abnode\u00bb=\u00ab{}\u00bb, type {} not valid.\".format(self.__class__.__name__, node, type(node)))\n        self.childs.append(node)\n        node.parent = self\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a child node from the current node instance.", "response": "def remove_child(self, idx=None, *, name=None, node=None):\n        \"\"\"Remove a child node from the current node instance.\n\n        :param idx: Index of child node to be removed.\n        :type idx: int \n        :param name: The first child node found with \u00abname\u00bb will be removed. \n        :type name: str\n        :param node: Child node to be removed.\n        :type node: Node \n        :returns: The node that has been removed, or False if not successful.\n        :rtype: Node or False \n        \"\"\"\n        if (idx and isinstance(idx, int) and \n            -len(self.childs) <= idx < len(self.childs) ):\n                return self.childs.pop(idx)\n        if name and isinstance(name, str):\n            found_node = None\n            for _n in self.childs:\n                if _n.name == name:\n                    found_node = _n\n                    break\n            if found_node:\n                self.childs.remove(found_node)\n                return found_node\n        if node and node in self.childs:\n            self.childs.remove(node)\n            return node\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattributing indicating the absolute path for this node.", "response": "def _path(self):\n        \"\"\"Attribute indicating the absolute node path for this node. \n        \n        Note that the absolute node path starts with a forward slash \n        followed by the root node's name: e.g: \n        `/root.name/child.name/grandchild.name`\n        Warning: it should be noted that use of _path assumes  \n        that sibling nodes have unique names. If unique node paths\n        cannot be assured, use node attribute \u00ab_coord\u00bb instead.\n\n        :returns: The absolute node path for this node.\n        :rtype: str \n        \"\"\"\n        _path = pathlib.PurePosixPath(self.name)\n        _node = self\n        while _node.parent:\n            _path = _node.parent.name / _path\n            _node = _node.parent\n        _path = pathlib.posixpath.sep / _path\n        return _path.as_posix()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _coord(self):\n        _coord = []\n        _node = self\n        while _node.parent:\n            _idx = _node.parent.childs.index(_node)\n            _coord.insert(0, _idx)\n            _node = _node.parent\n        return tuple(_coord)", "response": "Attribute indicating the tree coordinates for this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_data(self, *keys, value):\n        _datadict = self.data\n        for ii, _key in enumerate(keys):\n            if ii==len(keys)-1:\n                _datadict[_key] = value\n            else:\n                if _key not in _datadict:\n                    _datadict[_key] = {}\n                _datadict = _datadict[_key]\n        return True", "response": "Set a value in the instance data dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattributes referencing the root node of the tree.", "response": "def _root(self):\n        \"\"\"Attribute referencing the root node of the tree.\n\n        :returns: the root node of the tree containing this instance.\n        :rtype: Node\n        \"\"\"\n        _n = self\n        while _n.parent:\n            _n = _n.parent\n        return _n"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattributes referencing the tree ancestors of the current node instance.", "response": "def _ancestors(self):\n        \"\"\"Attribute referencing the tree ancestors of the node instance.\n\n        :returns: list of node ancestors in sequence, first item is \n            the current node instance (`self`), the last item is root.\n        :rtype: list of Node references\n        \"\"\"\n        # return list of ancestor nodes starting with self.parent and ending with root\n        _ancestors=[]\n        _n = self\n        while _n.parent:\n            _n = _n.parent\n            _ancestors.append(_n)\n        return _ancestors"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a child node of the current instance by its name.", "response": "def get_child_by_name(self, childname):\n        \"\"\"Get a child node of the current instance by its name.\n\n        :param childname: the name of the required child node.\n        :type childname: str\n        :returns: the first child node found with name `childname`.\n        :rtype: Node or None\n        \"\"\"\n        _childs = [_child for _child in self.childs if _child.name==childname]\n        if len(_childs)>1:\n            logger.warning(\"%s.get_child_by_name: node:\u00ab%s\u00bb has more than 1 childnode with name=\u00ab%s\u00bb.\" % (self.__class__.__name__, self.name, childname))\n        if len(_childs)==0:\n            _childnode = None\n        else:\n            _childnode = _childs[0] \n        return _childnode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a node from a node path.", "response": "def get_node_by_path(self, path):\n        \"\"\"Get a node from a node path. \n\n        Warning: use of this method assumes that sibling nodes have unique names,\n        if this is not assured the `get_node_by_coord` method can be used instead.\n\n        |  Example with absolute node path: \n        |  `node.get_node_by_path('/root.name/child.name/gchild.name')`\n        |  Example with relative node path:\n        |  `node.get_node_by_path('child.name/gchild.name')`\n\n        :param path: the absolute node path, or the node path relative \n            to the current node instance.\n        :type path: str\n        :returns: the node corresponding to `path`.\n        :rtype: Node or None\n        \"\"\"\n        if path==\".\":\n            return self\n        elif path.lstrip().startswith((\".\", \"./\")) or not isinstance(path, str):\n            logger.warning(\"%s.get_node_by_path: arg \u00abpath\u00bb=\u00ab%s\u00bb, not correctly specified.\" % (self.__class__.__name__, path))\n            return None\n        _pathlist = list(filter(None, path.split(\"/\")) ) # remove blank strings\n        if path.startswith(\"/\"):\n            _node = self._root  \n            _pathlist.pop(0)  # remove rootnode name\n        else:\n            _node = self\n        for _nodename in _pathlist:\n            _node = _node.get_child_by_name(_nodename)\n            if _node is None:\n                logger.warning(\"%s.get_node_by_path: node\u00ab%s\u00bb, arg `path`=\u00ab%s\u00bb, cannot find node.\" % (self.__class__.__name__, self.name, path))\n                return None\n        return _node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a node from a node coord.", "response": "def get_node_by_coord(self, coord, relative=False):\n        \"\"\"Get a node from a node coord. \n\n        :param coord: the coordinates of the required node.\n        :type coord: tuple or list\n        :param relative: `True` if coord is relative to the node instance,\n            `False` for absolute coordinates.\n        :type relative: bool\n        :returns: the node corresponding to `coord`.\n        :rtype: Node or None\n        \"\"\"\n        if not isinstance(coord, (list, tuple)) or False in list(map(lambda i: type(i)==int, coord)):\n            logger.warning(\"%s.get_node_by_coord: node\u00ab%s\u00bb, arg \u00abcoord\u00bb=\u00ab%s\u00bb, \u00abcoord\u00bb must be list or tuple of integers.\" % (self.__class__.__name__, self.name, coord))\n            return None\n        if relative:\n            _node = self\n        else:\n            _node = self._root # _node = self.get_rootnode()\n        for idx in coord:\n            _node = _node.childs[idx]\n            if _node is None:\n                logger.warning(\"%s.get_node_by_coord: node\u00ab%s\u00bb, arg \u00abcoord\u00bb=\u00ab%s\u00bb not valid.\" % (self.__class__.__name__, self.name, coord))\n                return None\n        return _node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a node on the branch of the instance with a specific key and value.", "response": "def find_one_node(self, *keys, value, decend=True):\n        \"\"\"Find a node on the branch of the instance with a\n        `keys=data` item in the `data` dict. \n\n        Nested values are accessed by specifying the keys in sequence. \n        e.g. `node.get_data(\"country\", \"city\")` would access\n        `node.data[\"country\"][\"city\"]`\n\n        :param keys: the `data` dict key(s) referencing the required value.\n        :type keys: str \n        :param value: the value corresponding to `keys`. Note that\n            `value` is a keyword-only argument.\n        :param decend: `decend=True` traverse down the branch sub-tree  \n            starting from `self`. `decend=False` traverse up the   \n            branch from `self` towards root.\n        :type decend: bool \n        :returns: the first node found with `keys=data` in the `data` dict. \n        :rtype: Node or None \n        \"\"\"\n        if decend:\n            traversal = self\n        else:\n            traversal = self._ancestors\n        for _node in traversal:\n            _val = _node.get_data(*keys)\n            if _val == value:\n                return _node\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tree_compare(self, othertree, vntree_meta=False):\n        return SequenceMatcher(None, \n                json.dumps(self.to_treedict(vntree_meta=vntree_meta), default=str), \n                json.dumps(othertree.to_treedict(vntree_meta=vntree_meta), default=str)\n                ).ratio()", "response": "Compare the ( sub - ) tree rooted at self with another tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the tree in a pickle file.", "response": "def savefile(self, filepath=None):\n        \"\"\"Save (dump) the tree in a pickle file.\n\n        Note that this method saves the complete tree even when invoked on\n        a non-root node.\n        It is recommended to use the extension `.vnpkl` for this type of file.\n\n        :param filepath: the file path for the pickle file. \n            If `filepath=None` use `self._vnpkl_fpath` attribute, if set.\n        :type filepath: str or None        \n        :returns: `True` if successful. \n        :rtype: bool\n        \"\"\"\n        if filepath:\n            self._vnpkl_fpath = os.path.abspath(filepath)\n        # if not _pfpath:\n        #     logger.error(\"%s.save: \u00ab%s\u00bb file path \u00ab%s\u00bb not valid.\" % (self.__class__.__name__, self.name, _pfpath))\n        #     return False\n        try:\n            with open(self._vnpkl_fpath, \"wb\") as pf:\n                pickle.dump(self._root.to_treedict(), pf) \n        except Exception as err:\n            logger.error(\"%s.savefile: arg `filepath`=\u00ab%s\u00bb `self._vnpkl_fpath`=\u00ab%s\u00bb error: %s\" % (self.__class__.__name__, filepath, self._vnpkl_fpath, err))\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef openfile(cls, filepath):\n        if not os.path.isfile(filepath):\n            logger.error(\"%s.openfile: arg `filepath`=\u00ab%s\u00bb not valid.\" % (cls.__name__, filepath))\n            return False\n        try:\n            with open(filepath, \"rb\") as pf:\n                pkldata = pickle.load(pf)\n            rootnode = cls(treedict=pkldata)\n            rootnode._vnpkl_fpath = os.path.abspath(filepath)\n        except Exception as err:\n            logger.error(\"%s.openfile: data in file \u00ab%s\u00bb not valid: %s\" % (cls.__name__, filepath, err))\n            return False\n        return rootnode", "response": "Class method that opens a vntree pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclassing method that creates a tree from YAML. | # Example yamltree data: | - !Node &root | name: \"root node\" | parent: null | data: | testpara: 111 | - !Node &child1 | name: \"child node\" | parent: *root | - !Node &gc1 | name: \"grand-child node\" | parent: *child1 :param yamltree: a string of YAML describing the nodes in the tree, or the path to a file containing the data. :type yamltree: str :returns: the root node of the tree. :rtype: Node", "response": "def yaml2tree(cls, yamltree):\n        \"\"\"Class method that creates a tree from YAML.\n\n        | # Example yamltree data:\n        | - !Node &root\n        |   name: \"root node\"\n        |   parent: null\n        |   data:\n        |     testpara: 111\n        | - !Node &child1\n        |   name: \"child node\"\n        |   parent: *root\n        | - !Node &gc1\n        |   name: \"grand-child node\"\n        |   parent: *child1\n\n        :param yamltree: a string of YAML describing the nodes in the\n            tree, or the path to a file containing the data.\n        :type yamltree: str\n        :returns: the root node of the tree. \n        :rtype: Node \n        \"\"\"\n        if not cls.YAML_setup:\n            cls.setup_yaml()\n            cls.YAML_setup = True \n        if os.path.isfile(yamltree):\n            with open(yamltree) as fh:\n                yaml_data = fh.read()\n        else:\n            yaml_data = yamltree\n        list_of_nodes = yaml.safe_load(yaml_data)\n        yamltree_root = list_of_nodes[0]\n        return yamltree_root"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfile iterator that uses alternative line terminators.", "response": "def zlines(f = None, sep = \"\\0\", osep = None, size = 8192):     # {{{1\n  \"\"\"File iterator that uses alternative line terminators.\"\"\"\n  if f is None: f = sys.stdin\n  if osep is None: osep = sep\n  buf = \"\"\n  while True:\n    chars = f.read(size)\n    if not chars: break\n    buf += chars; lines = buf.split(sep); buf = lines.pop()\n    for line in lines: yield line + osep\n  if buf: yield buf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall by pika when a message is delivered from RabbitMQ.", "response": "def _on_message(channel, method, header, body):\n    \"\"\"\n    Invoked by pika when a message is delivered from RabbitMQ. The\n    channel is passed for your convenience. The basic_deliver object that\n    is passed in carries the exchange, routing key, delivery tag and\n    a redelivered flag for the message. The properties passed in is an\n    instance of BasicProperties with the message properties and the body\n    is the message that was sent.\n\n    :param pika.channel.Channel channel: The channel object\n    :param pika.Spec.Basic.Deliver method: The Deliver method\n    :param pika.Spec.BasicProperties properties: The client properties\n    :param str|unicode body: The message body\n    \"\"\"\n    print \"Message:\"\n    print \"\\t%r\" % method\n    print \"\\t%r\" % header\n    print \"\\t%r\" % body\n\n    # Acknowledge message receipt\n    channel.basic_ack(method.delivery_tag)\n\n    # when ready, stop consuming\n    channel.stop_consuming()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npublishes a message to the queue.", "response": "def publish(self, message):\n        \"\"\"\n        Publish a message to the queue.\n\n        :param str message: The message to send\n        \"\"\"\n        props = pika.BasicProperties(content_type='text/plain', delivery_mode=1)\n        self.channel.basic_publish(self._exchange,\n                                   self._routing_key,\n                                   message,\n                                   props)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npublishes a message to the queue.", "response": "def consume(self, on_message, queue):\n        \"\"\"\n        Publish a message to the queue.\n\n        :param function on_message: Function to call upon recieving a message\n        :param str queue: The queue to publish to\n        \"\"\"\n        self.channel.queue_declare(queue=queue, durable=True, exclusive=False,\n                                   auto_delete=False)\n        self.channel.queue_bind(queue=queue, exchange=self._exchange,\n                                routing_key=self._routing_key)\n        self.channel.basic_qos(prefetch_count=1)\n        # Setup up our consumer callback\n        self.channel.basic_consume(on_message, queue)\n        # This is blocking until channel.stop_consuming is called\n        # and will allow us to receive messages\n        self.channel.start_consuming()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self):\n        self._logger.info('Connecting to %s' % self._url)\n        return adapters.TornadoConnection(pika.URLParameters(self._url),\n                                          self.on_connection_open,\n                                          custom_ioloop=self._ioloop_instance)", "response": "Connects to RabbitMQ returning a connection handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_connection_open(self, unused_connection):\n        self._logger.info('Connection opened')\n        self.add_on_connection_close_callback()\n        self.open_channel()", "response": "Called by pika when a connection to RabbitMQ has been established."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_on_connection_close_callback(self):\n        self._logger.debug('Adding connection close callback')\n        self._connection.add_on_close_callback(self.on_connection_closed)", "response": "Add an on_connection_closed callback that will be invoked by pika\n        when RabbitMQ closes the connection to the publisher unexpectedly."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreconnecting to the new connection.", "response": "def reconnect(self):\n        \"\"\"\n        Invoked by the IOLoop timer if the connection is\n        closed. See the on_connection_closed method.\n        \"\"\"\n        # This is the old connection IOLoop instance, stop its ioloop\n        self._connection.ioloop.stop()\n\n        if not self._closing:\n            # Create a new connection\n            self._connection = self.connect()\n            # There is now a new connection, needs a new ioloop to run\n            self._connection.ioloop.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_channel(self):\n        self._logger.debug('Creating a new channel')\n        self._connection.channel(on_open_callback=self.on_channel_open)", "response": "Open a new channel with RabbitMQ by issuing the Channel. Open RPC\n        command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_channel_open(self, channel):\n        self._logger.debug('Channel opened')\n        self._channel = channel\n        self._channel.parent_client = self\n        self.add_on_channel_close_callback()\n        self.setup_exchange(self._exchange)", "response": "Called by pika when the channel is opened."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_on_channel_close_callback(self):\n        self._logger.info('Adding channel close callback')\n        self._channel.add_on_close_callback(self.on_channel_closed)", "response": "Add a callback that will be called when RabbitMQ unexpectedly closes the channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls by pika when RabbitMQ unexpectedly closes a channel.", "response": "def on_channel_closed(self, channel, reply_code, reply_text):\n        \"\"\"\n        Invoked by pika when RabbitMQ unexpectedly closes the channel.\n        Channels are usually closed if you attempt to do something that\n        violates the protocol, such as re-declare an exchange or queue with\n        different parameters. In this case, we'll close the connection\n        to shutdown the object.\n\n        :param pika.channel.Channel: The closed channel\n        :param int reply_code: The numeric reason the channel was closed\n        :param str reply_text: The text reason the channel was closed\n        \"\"\"\n        self._logger.warning('Channel was closed: (%s) %s', reply_code, reply_text)\n        if not self._closing:\n            self.close_connection()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninvoking by pika when RabbitMQ has finished the Exchange. Declare RPC command.", "response": "def on_exchange_declareok(self, unused_frame):\n        \"\"\"\n        Invoked by pika when RabbitMQ has finished the Exchange.Declare RPC\n        command.\n\n        :param pika.Frame.Method unused_frame: Exchange.DeclareOk response frame\n        \"\"\"\n        self._logger.debug('Exchange declared')\n        self.setup_queue(self._queue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_queue(self, queue_name):\n        self._logger.info('Declaring queue %s', queue_name)\n        self._channel.queue_declare(self.on_queue_declareok, queue_name,\n                                    durable=True, exclusive=False,\n                                    auto_delete=False)", "response": "Setup the queue on RabbitMQ by invoking the Queue. Declare RPC\n        command."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_queue_declareok(self, method_frame):\n        self._logger.debug('Binding %s to %s with %s',\n                           self._exchange, self._queue, self._routing_key)\n        self._channel.queue_bind(self.on_bindok, self._queue,\n                                 self._exchange, self._routing_key)\n        self._channel.basic_qos(prefetch_count=1)", "response": "Invoked by pika when the Queue. Declare RPC call made in\n        setup_queue has completed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close_channel(self):\n        self._logger.info('Closing the channel')\n        if self._channel:\n            self._channel.close()", "response": "Close the channel with RabbitMQ by sending a Channel. Close RPC command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close_connection(self):\n        self._logger.info('Closing connection')\n        self._closing = True\n        self._connection.close()", "response": "This method closes the connection to RabbitMQ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_bindok(self, unused_frame):\n        self._logger.info('Queue bound')\n        while not self._stopping:\n            # perform the action that publishes on this client\n            self.producer(self)\n        self._logger.info(\"producer done\")", "response": "This method is invoked by pika when the Queue. BindOk response is received from RabbitMQ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish(self, message):\n        if self._stopping:\n            return\n        self._logger.info(\"publishing\\t%s\" % message)\n        properties = pika.BasicProperties(content_type=self._content_type,\n                                          delivery_mode=1)\n\n        self._channel.basic_publish(self._exchange,\n                                    self._routing_key,\n                                    message,\n                                    properties)", "response": "Publish a message to RabbitMQ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self):\n        self._logger.info('Stopping')\n        self._stopping = True\n        self.close_connection()\n        try:\n            self._connection.ioloop.start()  # supposedly this is necessary...\n        except Exception as e:\n            pass\n        self._logger.info('Stopped')", "response": "Stop the mq publisher by closing the channel and closing the connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_consuming(self):\n        self._logger.info('Issuing consumer related RPC commands')\n        self.add_on_cancel_callback()\n        self._consumer_tag = self._channel.basic_consume(self.on_message,\n                                                         self._queue)", "response": "Starts consuming messages from RabbitMQ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a callback that will be invoked when the consumer has cancelled the consumer.", "response": "def add_on_cancel_callback(self):\n        \"\"\"\n        Add a callback that will be invoked if RabbitMQ cancels the consumer\n        for some reason. If RabbitMQ does cancel the consumer,\n        on_consumer_cancelled will be invoked by pika.\n        \"\"\"\n        self._logger.info('Adding consumer cancellation callback')\n        self._channel.add_on_cancel_callback(self.on_consumer_cancelled)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_consuming(self):\n        if self._channel:\n            self._logger.info('Sending a Basic.Cancel RPC command to RabbitMQ')\n            self._channel.basic_cancel(self.on_cancelok, self._consumer_tag)", "response": "Send a Basic. Cancel RPC command to RabbitMQ to stop consuming messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self):\n        self._logger.info('Stopping')\n        self._closing = True\n        self.stop_consuming()\n        try:\n            self._connection.ioloop.start()  # supposedly this is necessary...\n        except Exception as e:\n            pass\n        self._logger.info('Stopped')", "response": "Stop the consumer with RabbitMQ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef txt(self, txt, h=None, at_x=None, to_x=None, change_style=None, change_size=None):\n        h = h or self.height\n        self._change_props(change_style, change_size)\n        align = 'L'\n        w = None\n        if at_x is None:\n            if to_x is not None:\n                align = 'R'\n                self.oPdf.set_x(0)\n                w = to_x\n        else:\n            self.oPdf.set_x(at_x)\n        if w is None:\n            w = self.oPdf.get_string_width(txt)\n        self.oPdf.cell(w, h=h, txt=txt, align=align)", "response": "print string to defined at_x"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef num(self, num, h=None, to_x=None, format=\"%.2f\", change_style=None, change_size=None):\n        self.txt(format % num, h=h, to_x=to_x, change_style=change_style, change_size=change_size)", "response": "print a number in the log file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting string item0 to the current position and next strings to defined positions", "response": "def header(self, item0, *items):\n        \"\"\"print string item0 to the current position and next strings to defined positions\n        example: .header(\"Name\", 75, \"Quantity\", 100, \"Unit\")\n        \"\"\"\n        self.txt(item0)\n        at_x = None\n        for item in items:\n            if at_x is None:\n                at_x = item\n            else:\n                self.txt(item, at_x=at_x)\n                at_x = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving current vertical position h mm down", "response": "def down(self, h, cr=True):\n        \"\"\"moves current vertical position h mm down\n        cr True will navigate to the left margin\n        \"\"\"\n        if cr:\n            self.oPdf.ln(h=0)\n        self.oPdf.set_y(self.oPdf.get_y() + h)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_queue(self):\n        queue = AmazonSQS().create_queue(settings.RESTCLIENTS_AMAZON_QUEUE)\n        queue.set_message_class(RawMessage)\n        message = queue.read()\n        if message is None:\n            return\n\n        body = message.get_body()\n        queue.delete_message(message)\n        return body", "response": "Reads the queue and returns the message body"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kwargs_as_assignments(call_node, parent):\n    if not isinstance(call_node, ast.Call):\n        raise TypeError('node must be an ast.Call')\n\n    if len(call_node.args) > 0:\n        raise ValueError('positional args not allowed')\n\n    for keyword in call_node.keywords:\n        dst_name = keyword.arg\n\n        if dst_name.startswith('gl_'):\n            # Write to builtins directly\n            target = [ast.Name(id=keyword.arg, ctx=ast.Load())]\n        else:\n            # Non-builtins are part of an interface block\n            target = [ast.Attribute(value=parent, attr=keyword.arg,\n                                    ctx=ast.Store())]\n\n        yield NoDeclAssign(targets=target, value=keyword.value)", "response": "Yields NoDeclAssign nodes from kwargs in a Call node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmodifying FunctionDef node to directly assign instead of return.", "response": "def rewrite_return_as_assignments(func_node, interface):\n    \"\"\"Modify FunctionDef node to directly assign instead of return.\"\"\"\n    func_node = _RewriteReturn(interface).visit(func_node)\n    ast.fix_missing_locations(func_node)\n    return func_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nissues a GET request to IASystem with the given url and return a response in Collection + json format.", "response": "def get_resource(url, subdomain):\n    \"\"\"\n    Issue a GET request to IASystem with the given url\n    and return a response in Collection+json format.\n    :returns: http response with content in json\n    \"\"\"\n    headers = {\"Accept\": \"application/vnd.collection+json\"}\n    response = IASYSTEM_DAO().getURL(url, headers, subdomain)\n\n    logger.info(\"%s ==status==> %s\" % (url, response.status))\n\n    if response.status != 200:\n        logger.error(\"%s ==data==> %s\" % (url, response.data))\n        raise DataFailureException(url, response.status, response.data)\n\n    return json.loads(response.data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert int base10 to base36.", "response": "def int2base36(n):\n    \"\"\"\n    Convert int base10 to base36.\n    Back convert: int('<base36>', 36)\n    \"\"\"\n    assert isinstance(n, (int, long))\n    c = '0123456789abcdefghijklmnopqrstuvwxyz'\n    if n < 0:\n        return '-' + int2base36(-n)\n    elif n < 36:\n        return c[n]\n    b36 = ''\n    while n != 0:\n        n, i = divmod(n, 36)\n        b36 = c[i] + b36\n    return b36"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef datetime_to_dtstr(dt=None):\n    if dt is None:\n        dt = datetime.datetime.utcnow()\n    elif timezone.is_aware(dt):\n        dt = dt.astimezone(tz=pytz.UTC)\n    return int2base36(int(time.mktime(dt.timetuple()) * 1e3 + dt.microsecond / 1e3))", "response": "Convert datetime to short text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dtstr_to_datetime(dtstr, to_tz=None, fail_silently=True):\n    try:\n        dt = datetime.datetime.utcfromtimestamp(int(dtstr, 36) / 1e3)\n        if to_tz:\n            dt = timezone.make_aware(dt, timezone=pytz.UTC)\n            if to_tz != pytz.UTC:\n                dt = dt.astimezone(to_tz)\n        return dt\n    except ValueError, e:\n        if not fail_silently:\n            raise e\n        return None", "response": "Convert result from datetime_to_dtstr to datetime in timezone UTC0."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload object by name.", "response": "def load_object_by_name(obj_name):\n    \"\"\"\n    Import object by name (point-path).\n    Example:\n        MyForm = load_object_by_name('myapp.forms.MyAnyForm')\n    \"\"\"\n    parts = obj_name.split('.')\n    t = __import__('.'.join(parts[:-1]), fromlist=(parts[-1],))\n    return getattr(t, parts[-1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_datetime_aware(s, tz=None):\n    assert settings.USE_TZ\n    if isinstance(s, datetime.datetime):\n        return s\n    d = parse_datetime(s)\n    if d is None:\n        raise ValueError\n    return timezone.make_aware(d, tz or timezone.get_current_timezone())", "response": "Parse text with datetime to aware datetime."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef long_number_readable(value):\n    value = int(value)\n    if value < 1000:\n        return value\n    for m, d, inf, fnf, n in _long_number_readable_formats:\n        if value < m:\n            return ((inf if value % d == 0 else fnf) + unicode(n)).format(value / float(d))\n    return value", "response": "Convert a long number to a readable form."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a name for the current object.", "response": "def name_gen(self, as_number, k, diploid_mode):\n        \"\"\"See the sweeper_output() method doctstring for format details.\"\"\"\n        #how to add prefixes to numbers\n        #http://stackoverflow.com/a/135157\n        #         ai_d_z_g_s_k_p.config\n\n        parts =  {\"1ai\": \"{0}{1:03d}_\".format(self.as_a, as_number),\n                  \"2d\" : \"{0}_\".format(self.as_d),\n                  \"3z\" : \"ME_\",\n                  \"4g\" : \"{}_\".format(self.as_g) if self.as_g else \"\",\n                  \"5s\" : \"{}_\".format(self.as_s) if self.as_s else \"\",\n                  \"6k\" : \"k{}_\".format(k),\n                  \"7p\" : \"d{}\".format(diploid_mode)}\n        return \"\".join([parts.get(x) for x in sorted(parts)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the config parameters to a json file", "response": "def save_yaml(self, outFile):\n        \"\"\"saves the config parameters to a json file\"\"\"\n        with open(outFile,'w') as myfile:\n            print(yaml.dump(self.params), file=myfile)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sym_reads_new_config(self, newDir, sym=False, mv=False):\n        newParams = copy.copy(self)\n        for i in range(0,len(self.params[\"lib_seq\"])):\n            lib_seq = self.params[\"lib_seq\"][i]\n            #update the glob\n            newParams.params[\"lib_seq\"][i][\"globs\"] = [os.path.join(\n                newDir,os.path.basename(x)) for x in lib_seq[\"globs\"]]\n            #now update the file paths and move/symlink if necessary\n            for j in range(0, len(lib_seq[\"pairs\"])):\n                forward, reverse = lib_seq[\"pairs\"][j]\n                new_forward = os.path.join(newDir, os.path.basename(forward))\n                new_reverse = os.path.join(newDir, os.path.basename(reverse))\n                #move or symlink the files\n                if sym:\n                    for each in [new_forward, new_reverse]:\n                        if os.path.exists(each):\n                            raise ValueError(\"\"\"Attempted to make a symlink for\n                            a reads file, but it already exists. Chances are\n                            that you used the same reads for two lines in the\n                            Meraculous config file\"\"\")\n                    os.symlink(forward, new_forward)\n                    os.symlink(reverse, new_reverse)\n                #update the reads in the new config\n                newParams.params[\"lib_seq\"][i][\"pairs\"][j] = [new_forward, new_reverse]\n        return newParams", "response": "This method moves the read files and renames the globs and moves the symlinks if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a notification to the APN.", "response": "def send(self, notification):\n        \"\"\"Send prepared notification to the APN.\"\"\"\n        logger.debug('Gateway send notification')\n\n        if self.client is None:\n            raise GatewayClientNotSetError()\n\n        yield self.client.send(notification)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nforces data to become a list.", "response": "def force_list(data):\n    \"\"\"Force ``data`` to become a list.\n\n    You should use this method whenever you don't want to deal with the\n    fact that ``NoneType`` can't be iterated over. For example, instead\n    of writing::\n\n        bar = foo.get('bar')\n        if bar is not None:\n            for el in bar:\n                ...\n\n    you can write::\n\n        for el in force_list(foo.get('bar')):\n            ...\n\n    Args:\n        data: any Python object.\n\n    Returns:\n        list: a list representation of ``data``.\n\n    Examples:\n        >>> force_list(None)\n        []\n        >>> force_list('foo')\n        ['foo']\n        >>> force_list(('foo', 'bar'))\n        ['foo', 'bar']\n        >>> force_list(['foo', 'bar', 'baz'])\n        ['foo', 'bar', 'baz']\n\n    \"\"\"\n    if data is None:\n        return []\n    elif not isinstance(data, (list, tuple, set)):\n        return [data]\n    elif isinstance(data, (tuple, set)):\n        return list(data)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    parser = CommandLine()\n    #this block from here: http://stackoverflow.com/a/4042861/5843327\n    if len(sys.argv)==1:\n        parser.parser.print_help()\n        sys.exit(1)\n    parser.parse()\n    myArgs = parser.args\n    print(myArgs)\n\n    # 1. Verify that the current directory isn't already a gloTK project\n    cwd = os.path.abspath(os.getcwd())\n    if gloTK.utils.dir_is_glotk(cwd):\n        raise ValueError(\"\"\"ERROR: Are you in an empty directory? This appears\n        to be a gloTK project directory already. Please try again in a new\n        directory!\"\"\")\n\n    # 2. Reads in a meraculous config file and outputs all of the associated config\n    #    files to $PWD/glotk_info\n    configFile = ConfigParse(myArgs.inputConfig)\n    gloTK_info=os.path.join(cwd, \"gloTK_info\")\n    gloTK.utils.safe_mkdir(gloTK_info)\n    shutil.copyfile(myArgs.inputConfig, os.path.join(gloTK_info, \"project_init.config\"))\n    configFile.save_yaml(os.path.join(gloTK_info, \"input_config.yaml\"))\n\n    # 3. Make symlinks for each read pair\n    gloTK_reads = os.path.join(cwd, \"gloTK_reads\")\n    gloTK.utils.safe_mkdir(gloTK_reads)\n    reads0 = os.path.join(gloTK_reads, \"reads0\")\n    gloTK.utils.safe_mkdir(reads0)\n      # the files get saved in `project_dir/glotk_reads/reads0\n    params_new = configFile.sym_reads_new_config(reads0, sym=True)\n      # the yaml config files get saved in `project_dir/glotk_info/read_configs/`\n    read_params = os.path.join(gloTK_info, \"read_configs\")\n    gloTK.utils.safe_mkdir(read_params)\n    params_new = configFile.save_yaml(os.path.join(read_params, \"reads0.yaml\"))", "response": "This function is the main entry point for the gloTK project. It is the main entry point for the gloTK project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to the Redis server and return True if connection was successful.", "response": "def connect(self, **kwargs):\n        \"\"\"\n        Connect to the Redis Server\n\n        :param kwargs: Parameters passed directly to redis library\n        :return: Boolean indicating if connection successful\n\n        :kwarg host: Hostname of the Redis server\n        :kwarg port: Port of the Redis server\n        :kwarg password: Auth key for the Redis server\n        \"\"\"\n\n        self.__db = redis.Redis(**kwargs)\n        try:\n            self.__db.info()\n            self.connected = True\n        except redis.ConnectionError as e:\n            self.logger.error(\"Failed to connect to Redis server: \", e)\n            raise QueueNotConnectedError(e)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclears all Tasks in the queue.", "response": "def clear(self):\n        \"\"\"\n        Clear all Tasks in the queue.\n        \"\"\"\n\n        if not self.connected:\n            raise QueueNotConnectedError(\"Queue is not Connected\")\n\n        self.__db.delete(self._key)\n        self.__db.delete(self._lock_key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef qsize(self):\n        if not self.connected:\n            raise QueueNotConnectedError(\"Queue is not Connected\")\n\n        try:\n            size = self.__db.llen(self._key)\n        except redis.ConnectionError as e:\n            raise redis.ConnectionError(repr(e))\n        return size", "response": "Returns the number of items currently in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts a task into the queue.", "response": "def put(self, task):\n        \"\"\"\n        Inserts a Task into the queue\n\n        :param task: :class:`~redisqueue.AbstractTask` instance\n        :return: Boolean insert success state\n        :exception: ConnectionError if queue is not connected\n        \"\"\"\n\n        if not self.connected:\n            raise QueueNotConnectedError(\"Queue is not Connected\")\n\n        if task.unique:\n            # first lets check if we have this hash already in our queue\n            if not self.__db.sismember(self._lock_key, task.unique_hash()):\n                self.__db.sadd(self._lock_key, task.unique_hash())\n            else:\n                raise TaskAlreadyInQueueException(\n                    'Task already in Queue [{hash}]'.format(\n                        hash=task.unique_hash()))\n\n        self.__db.lpush(self._key, task.to_json())\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a Task from the queue.", "response": "def get(self, block=True, timeout=None):\n        \"\"\"\n        Get a Task from the queue\n\n        :param block: Block application until a Task is received\n        :param timeout: Timeout after n seconds\n        :return: :class:`~redisqueue.AbstractTask` instance\n        :exception: ConnectionError if queue is not connected\n        \"\"\"\n        if not self.connected:\n            raise QueueNotConnectedError(\"Queue is not Connected\")\n\n        if block:\n            payload = self.__db.brpop(self._key, timeout=timeout)\n        else:\n            payload = self.__db.rpop(self._key)\n\n        if not payload:\n            return None\n\n        task = self.task_class(payload[1])\n\n        # if task was marked as unique then\n        # remove the unique_hash from lock table\n        if task.unique:\n            self.__db.srem(self._lock_key, task.unique_hash())\n\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the Task object from a JSON string.", "response": "def from_json(self, json_data):\n        \"\"\"\n        Load JSON data into this Task\n        \"\"\"\n        try:\n            data = json_data.decode()\n        except Exception:\n            data = json_data\n        self.__dict__ = json.loads(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _single_mp_run(x, Phi, bound, max_iter, verbose=False, pad=0,\n                   random_state=None, memory=Memory(None)):\n    \"\"\" run of the RSSMP algorithm \"\"\"\n\n    rng = check_random_state(random_state)\n    pad = int(pad)\n    x = np.concatenate((np.zeros(pad), x, np.zeros(pad)))\n\n    n = x.size\n    m = Phi.doth(x).size\n    err_mse = []\n\n    # Initialisation\n    residual = np.concatenate((x.copy(), np.zeros(max(Phi.sizes) // 2)))\n\n    s = np.zeros(m)\n    x_est = np.zeros(n)\n    # Main algorithm\n    coeffs = np.zeros(m)\n    it_number = 0\n    current_lambda = 1\n    err_mse.append(linalg.norm(residual))\n\n    # Decomposition loop: stopping criteria is either SNR or iteration number\n    while (current_lambda > bound) & (it_number < max_iter):\n\n        # pick a shift at random : in each size\n        rndshifts = []\n        for scale_idx, size in enumerate(Phi.sizes):\n            shift = rng.randint(low=0, high=size // 4)\n            coeffs[scale_idx * n:(scale_idx + 1) * n] = mdct(\n                residual[shift:shift + n], size).ravel()\n            rndshifts.append(shift)\n\n        # Select a new element\n        idx = np.argmax(np.abs(coeffs))\n\n        # Update coefficients\n        s[idx] += coeffs[idx]\n\n        # Only one method now : local update via a cached waveform\n        # find scale and frequency bin of selected atom\n        mdct_wf = memory.cache(mdct_waveform)\n\n        scale_idx = idx // n\n        size = Phi.sizes[scale_idx]\n        F = n // (size // 2)\n        frame = (idx - (scale_idx * n)) % F\n        freq_bin = ((idx - (scale_idx * n))) // F\n        pos = (frame * size // 2) - size // 4 + rndshifts[scale_idx]\n        residual[pos:pos + size] -= coeffs[idx] * mdct_wf(size, freq_bin)\n\n        # also add it to the reconstruction\n        x_est[pos:pos + size] += coeffs[idx] * mdct_wf(size, freq_bin)\n\n        # error computation (err_mse)\n        err_mse.append(linalg.norm(residual))\n\n        current_lambda = np.sqrt(1 - err_mse[-1] / err_mse[-2])\n        if current_lambda <= bound:\n            x_est[pos:pos + size] -= coeffs[idx] * mdct_wf(size, freq_bin)\n        if verbose:\n            print(\"Iteration %d : Current lambda of %1.4f\" % (\n                  it_number, current_lambda))\n        it_number += 1\n\n    return x_est, err_mse", "response": "Run the RSSMP algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsingle multichannel MPL run.", "response": "def _single_multichannel_mp_run(X, Phi, bound, selection_rule, stop_crit,\n                                max_iter, verbose=False, pad=0,\n                                random_state=None, memory=Memory(None)):\n    \"\"\" run of the structured variant of the RSSMP algorithm \"\"\"\n    rng = check_random_state(random_state)\n\n    # padding as v stak\n    pad = int(pad)\n    n_channels = X.shape[0]\n    X = np.hstack((np.zeros((n_channels, pad)), X,\n                   np.zeros((n_channels, pad))))\n    n_samples = X.shape[1]\n    n_projs = Phi.doth(X).shape[1]\n    err_mse = {}\n\n    # Initialisation\n    residual = np.hstack((X.copy(), np.zeros((n_channels,\n                                              max(Phi.sizes) / 2))))\n\n    s_rep = np.zeros((n_channels, n_projs))\n    X_est = np.zeros((n_channels, n_samples))\n    # Main algorithm\n    coeffs = np.zeros((n_channels, n_projs))\n\n    it_number = 0\n    current_lambda = 1\n    for c_idx in range(n_channels):\n        err_mse[c_idx] = []\n        err_mse[c_idx].append(linalg.norm(residual[c_idx, :]))\n\n    # Decomposition loop: stopping criteria is either SNR or iteration number\n    while (current_lambda > bound) & (it_number < max_iter):\n\n        # pick a shift at random : in each size\n        rndshifts = {}\n        for c_idx in range(n_channels):\n            rndshifts[c_idx] = []\n        for s_idx, L in enumerate(Phi.sizes):\n            shift = rng.randint(low=0, high=L / 4)\n            for c_idx in range(n_channels):\n                coeffs[c_idx, s_idx * n_samples:(s_idx + 1) * n_samples] = \\\n                    mdct(residual[c_idx, shift:shift + n_samples], L).ravel()\n                rndshifts[c_idx].append(shift)\n\n        # Multichannel mode : we combine projections\n        combined = selection_rule(coeffs ** 2)\n\n        # Select a new element\n        idx = np.argmax(np.abs(combined))\n        # find scale and frequency bin of selected atom\n        s_idx = idx // n_samples\n        L = Phi.sizes[s_idx]\n        F = n_samples // (L // 2)\n        frame = (idx - (s_idx * n_samples)) % F\n        freq_bin = ((idx - (s_idx * n_samples))) // F\n\n        mdct_wf = memory.cache(mdct_waveform)\n\n        # Update coefficients and residual\n        current_lambda_array = np.zeros(n_channels)\n        for c_idx in range(n_channels):\n            s_rep[c_idx, idx] += coeffs[c_idx, idx]\n\n            # Only one method now : local update via a cached waveform\n            pos = (frame * L / 2) - L / 4 + rndshifts[c_idx][s_idx]\n            residual[c_idx, pos:pos + L] -= coeffs[c_idx, idx] * \\\n                mdct_wf(L, freq_bin)\n\n            # also add it to the reconstruction\n            X_est[c_idx, pos:pos + L] += coeffs[c_idx, idx] * \\\n                mdct_wf(L, freq_bin)\n\n            # error computation (err_mse)\n            err_mse[c_idx].append(linalg.norm(residual[c_idx, :]))\n\n            current_lambda_array[c_idx] = np.sqrt(\n                1. - err_mse[c_idx][-1] / err_mse[c_idx][-2])\n\n        current_lambda = stop_crit(current_lambda_array)\n\n        if verbose:\n            print(\"Iteration %d : Current lambda of %1.4f\" % (\n                  it_number, current_lambda))\n        it_number += 1\n\n    return X_est[:, pad: -pad], err_mse"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pad(X):\n    p_above = int(np.floor(np.log2(X.shape[1])))\n    M = 2 ** (p_above + 1) - X.shape[1]\n    X = np.hstack((np.zeros((X.shape[0], M)), X))\n\n    return X, M", "response": "add zeroes on the border to make sure the signal length is a\n    power of two"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _bird_core(X, scales, n_runs, Lambda_W, max_iter=100,\n               stop_crit=np.mean,\n               selection_rule=np.sum,\n               n_jobs=1, indep=True,\n               random_state=None, memory=Memory(None), verbose=False):\n    \"\"\"Automatically detect when noise zone has been reached and stop\n    MP at this point\n\n    Parameters\n    ----------\n    X : array, shape (n_channels, n_times)\n        The numpy n_channels-vy-N array to be denoised where n_channels is\n        number of sensors and N the dimension\n    scales : list\n        The list of MDCT scales that will be used to built the\n        dictionary Phi\n    n_runs : int\n        the number of runs (n_runs in the paper)\n    Lambda_W : float\n        bound for lambda under which a run will be stopped\n    max_iter : int\n        Maximum number of iterations (serves as alternate stopping criterion)\n    stop_crit : function\n        controls the calculation of Lambda\n    selection_rule : callable\n        controls the way multiple channel projections are combined for atom\n        selection only used if indep=False\n    n_jobs : int\n        number of jobs to run in parallel\n    indep : bool\n        True for BIRD (independent processing of each channel,\n        False for S-BIRD (structured sparsity seeked)\n    random_state : None | int | np.random.RandomState\n        To specify the random generator state (seed).\n    memory : instance of Memory\n        The object to use to cache some computations. If cachedir is None, no\n        caching is performed.\n    verbose : bool\n        verbose mode\n\n    Returns\n    -------\n    X_denoise : array, shape (n_channels, n_times)\n        denoised array of same shape as X\n    \"\"\"\n    Phi = MDCT(scales)\n    pad = int(1.5 * max(scales))\n    X_denoise = np.zeros_like(X)\n    approx = []\n    rng = check_random_state(random_state)\n    seeds = rng.randint(4294967295, size=n_runs)  # < max seed value\n\n    if n_jobs <= 0:\n        n_cores = multiprocessing.cpu_count()\n        n_jobs = min(n_cores + n_jobs + 1, n_cores)\n\n    if indep:\n        # Independent treat of each channel (plain BIRD)\n        for r, x in zip(X_denoise, X):\n            this_approx = Parallel(n_jobs=n_jobs)(\n                        delayed(_denoise)(this_seeds, x, Phi, Lambda_W,\n                                          max_iter, pad=pad, verbose=verbose,\n                                          indep=True, memory=memory)\n                                          for this_seeds in\n                                          np.array_split(seeds, n_jobs))\n            this_approx = sum(this_approx[1:], this_approx[0])\n            r[:] = sum([a[pad:-pad] for a in this_approx])\n            approx.append(this_approx)\n    else:\n        # data need to be processed jointly\n        this_approx = Parallel(n_jobs=n_jobs)(\n                        delayed(_denoise)(this_seeds, X, Phi, Lambda_W,\n                                          max_iter, pad=pad, verbose=verbose,\n                                          selection_rule=selection_rule,\n                                          indep=False, memory=memory,\n                                          stop_crit=stop_crit)\n                                          for this_seeds in\n                                          np.array_split(seeds, n_jobs))\n\n        # reconstruction by averaging\n        for jidx in range(len(this_approx)):\n            for ridx in range(len(this_approx[jidx])):\n                X_denoise += this_approx[jidx][ridx]\n\n    X_denoise /= float(n_runs)\n    return X_denoise", "response": "BIRD core function for the MDCT algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bird(X, scales, n_runs, p_above, max_iter=100, random_state=None,\n         n_jobs=1, memory=Memory(None), verbose=False):\n    \"\"\" The BIRD algorithm as described in the paper\n\n    Parameters\n    ----------\n    X : array, shape (n_channels, n_times)\n        The numpy n_channels-vy-N array to be X_denoised where n_channels\n        is number of sensors and n_times the dimension\n    scales : list\n        The list of MDCT scales that will be used to built the\n        dictionary Phi\n    n_runs : int\n        the number of runs (n_runs in the paper)\n    p_above : float\n        probability of appearance of the max above which the noise hypothesis\n        is considered false\n    max_iter : int\n        The maximum number of iterations in one pursuit.\n    random_state : None | int | np.random.RandomState\n        To specify the random generator state (seed).\n    max_iter : int\n        The maximum number of iterations in one pursuit.\n    n_jobs : int\n        The number of jobs to run in parallel.\n    memory : instance of Memory\n        The object to use to cache some computations. If cachedir is None, no\n        caching is performed.\n    verbose : bool\n        verbose mode\n\n    Returns\n    -------\n    X_denoise : array, shape (n_channels, n_times)\n        The X_denoised data.\n    \"\"\"\n    X, prepad = _pad(X)\n\n    # Computing Lambda_W(Phi, p_above)\n    N = float(X.shape[1])\n    # size of the full shift-invariant dictionary\n    M = np.sum(np.array(scales) / 2) * N\n    sigma = sqrt((1.0 - (2.0 / np.pi)) / float(N))\n    Lambda_W = sigma * sqrt(2.0) * erfinv((1.0 - p_above) ** (1.0 / float(M)))\n    print(\"Starting BIRD with MDCT dictionary of %d Atoms. \"\n          \"Lambda_W=%1.3f, n_runs=%d\" % (M, Lambda_W, n_runs))\n    X_denoised = _bird_core(X, scales, n_runs, Lambda_W, verbose=verbose,\n                            max_iter=max_iter, indep=True, n_jobs=n_jobs,\n                            random_state=random_state, memory=memory)\n    return X_denoised[:, prepad:]", "response": "This function is used to build a BIRD dictionary from the input data X."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_email_domain(email):\n    try:\n        domain = email.split('@', 1)[1].lower().strip()\n    except IndexError:\n        return\n    if domain in dju_settings.DJU_EMAIL_DOMAIN_BLACK_LIST:\n        raise ValidationError(_(u'Email with domain \"%(domain)s\" is disallowed.'),\n                              code='banned_domain', params={'domain': domain})", "response": "Validates email domain by blacklist."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Match instance for the request and constraints pair.", "response": "def match(self, request, *, root=None, path=None, methods=None):\n        \"\"\"Return match or None for the request/constraints pair.\n\n        Parameters\n        ----------\n        request: :class:`.http.Request`\n            Request instance.\n        root: str\n            HTTP path root.\n        path: str\n            HTTP path.\n        methods: list\n            HTTP methods.\n\n        Returns\n        -------\n        :class:`.Match`/None\n            Match instance (True) or None (False).\n        \"\"\"\n        match = Match()\n        if path is not None:\n            pattern = self.__get_pattern(path)\n            match = pattern.match(request.path)\n        elif root is not None:\n            pattern = self.__get_pattern(root)\n            match = pattern.match(request.path, left=True)\n        if not match:\n            return None\n        if methods:\n            methods = map(str.upper, methods)\n            if request.method not in methods:\n                return None\n        return match"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef url(self, name, *, base=None, query=None, **match):\n        if base is None:\n            base = self.service\n        for name in name.split('.'):\n            base = base[name]\n        pattern = self.__get_pattern(base.path)\n        url = pattern.format(**match)\n        if query is not None:\n            url += '?' + urlencode(query)\n        return url", "response": "Construct a url for the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling by Sphinx. .", "response": "def run(self):\n        \"\"\"Called by Sphinx.\n\n        :returns: ImgurEmbedNode and ImgurJavaScriptNode instances with config values passed as arguments.\n        :rtype: list\n        \"\"\"\n        # Get Imgur ID.\n        imgur_id = self.arguments[0]\n        if not RE_IMGUR_ID.match(imgur_id):\n            raise ImgurError('Invalid Imgur ID specified. Must be 5-10 letters and numbers. Albums prefixed with \"a/\".')\n\n        # Read from conf.py.\n        config = self.state.document.settings.env.config\n        hide_post_details = self.options.get('hide_post_details', config.imgur_hide_post_details)\n\n        return [ImgurEmbedNode(imgur_id, hide_post_details), ImgurJavaScriptNode()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        # Get Imgur ID.\n        imgur_id = self.arguments[0]\n        if not RE_IMGUR_ID.match(imgur_id):\n            raise ImgurError('Invalid Imgur ID specified. Must be 5-10 letters and numbers. Albums prefixed with \"a/\".')\n\n        # Validate directive options.\n        if imgur_id.startswith('a/') and self.options.get('target_largest', None):\n            raise ImgurError('Imgur albums (whose covers are displayed) do not support :target_largest: option.')\n\n        # Modify options.\n        if self.options.get('width', '').isdigit():\n            self.options['width'] += 'px'\n        if self.options.get('height', '').isdigit():\n            self.options['height'] += 'px'\n\n        # Read from conf.py. Unset gallery/largest/page targets if :target: is set.\n        if self.options.get('target', None):\n            self.options.pop('target_gallery', None)\n            self.options.pop('target_largest', None)\n            self.options.pop('target_page', None)\n        elif not any(self.options.get('target_' + i, None) for i in ('gallery', 'largest', 'page')):\n            config = self.state.document.settings.env.config\n            self.options.setdefault('target_gallery', config.imgur_target_default_gallery)\n            self.options.setdefault('target_largest', config.imgur_target_default_largest)\n            self.options.setdefault('target_page', config.imgur_target_default_page)\n\n        return [ImgurImageNode(imgur_id, self.options)]", "response": "Called by Sphinx.\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_auth(self):\n        if self.type_of_auth == BboxConstant.AUTHENTICATION_TYPE_LOCAL:\n            access_level_required = self.get_auth_access_needed_for_local()\n        else:\n            access_level_required = self.get_auth_access_needed_for_remote()\n\n        if access_level_required == BboxConstant.AUTHENTICATION_LEVEL_NONE:\n            return False\n        elif access_level_required == BboxConstant.AUTHENTICATION_LEVEL_PRIVATE:\n            return self.is_authentified()\n        elif access_level_required == BboxConstant.AUTHENTICATION_LEVEL_PUBLIC:\n            return True", "response": "Check if you can make a API call with your current level of authentification\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_args():\n\n    default_database_name = os.environ.get(\n        'VOEVENTDB_DBNAME',\n        dbconfig.testdb_corpus_url.database)\n    default_logfile_path = os.path.expanduser(\"~/voeventdb_packet_ingest.log\")\n\n    parser = argparse.ArgumentParser(\n        prog=os.path.basename(__file__),\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter, )\n\n    parser.description = \"\"\"\n    Ingest a packet from stdin and attempt to ingest into a voeventdb database.\n\n    Usage:\n\n      cat test.xml | voeventdb_ingest_packet.py -d mydb -l /tmp/my.log\n\n    \"\"\"\n\n    parser.add_argument('-d', '--dbname', nargs='?',\n                        default=str(default_database_name),\n                        help='Database name')\n\n    parser.add_argument('-l', '--logfile_path', nargs='?',\n                        default=default_logfile_path,\n                        )\n    return parser.parse_args()", "response": "Parse command line arguments and return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_logging(logfile_path):\n    date_fmt = \"%y-%m-%d (%a) %H:%M:%S\"\n\n    std_formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s',\n                                      date_fmt)\n\n    # Get to the following size before splitting log into multiple files:\n    log_chunk_bytesize = 5e6\n\n    info_logfile = logging.handlers.RotatingFileHandler(logfile_path,\n                                                        maxBytes=log_chunk_bytesize,\n                                                        backupCount=10)\n    info_logfile.setFormatter(std_formatter)\n    info_logfile.setLevel(logging.DEBUG)\n\n    stdout_log = logging.StreamHandler()\n    stdout_log.setLevel(logging.DEBUG)\n    stdout_log.setFormatter(std_formatter)\n\n    # Set up root logger\n    logger = logging.getLogger()\n    logger.handlers = []\n    logger.setLevel(logging.DEBUG)\n    logger.addHandler(info_logfile)\n    logger.addHandler(stdout_log)\n    logging.getLogger('iso8601').setLevel(\n        logging.ERROR)  # Suppress iso8601 debug log.\n    return logger", "response": "Setup basic and debug log files"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the result of a candidate races and returns the relevant data structures.", "response": "def process_result(self, result, tabulated, no_bots, election_slug):\n        \"\"\"\n        Processes top-level (state) results for candidate races, loads data\n        into the database  and sends alerts for winning results.\n        \"\"\"\n        # Deconstruct result in variables\n        (\n            ID,\n            RACE_ID,\n            IS_BALLOT_MEASURE,\n            ELEX_ELECTION_DATE,\n            LEVEL,\n            STATE_POSTAL,\n            REPORTING_UNIT,\n            LAST_NAME,\n            OFFICE_NAME,\n            RACE_TYPE,\n            WINNER,\n            UNCONTESTED,\n            RUNOFF,\n            VOTE_COUNT,\n            VOTE_PERCENT,\n            PRECINCTS_REPORTING,\n            PRECINCTS_REPORTING_PERCENT,\n            PRECINCTS_TOTAL,\n            PARTY,\n        ) = self.deconstruct_result(result)\n\n        # Skip ballot measures on non-state-level results\n        if IS_BALLOT_MEASURE or LEVEL != DivisionLevel.STATE:\n            return\n\n        try:\n            ap_meta = APElectionMeta.objects.get(\n                ap_election_id=RACE_ID,\n                election__election_day__slug=election_slug,\n            )\n        except ObjectDoesNotExist:\n            print(\n                \"No AP Meta found for {0} {1} {2}\".format(\n                    LAST_NAME, OFFICE_NAME, REPORTING_UNIT\n                )\n            )\n            return\n\n        id_components = ID.split(\"-\")\n        CANDIDATE_ID = \"{0}-{1}\".format(id_components[1], id_components[2])\n        if LAST_NAME == \"None of these candidates\":\n            CANDIDATE_ID = \"{0}-{1}\".format(id_components[0], CANDIDATE_ID)\n\n        try:\n            candidate_election = CandidateElection.objects.get(\n                election=ap_meta.election,\n                candidate__ap_candidate_id=CANDIDATE_ID,\n            )\n        except ObjectDoesNotExist:\n            print(\n                \"No Candidate found for {0} {1} {2}\".format(\n                    LAST_NAME, OFFICE_NAME, PARTY\n                )\n            )\n            return\n\n        candidate = candidate_election.candidate\n\n        division = Division.objects.get(\n            level__name=DivisionLevel.STATE,\n            code_components__postal=STATE_POSTAL,\n        )\n\n        filter_kwargs = {\n            \"candidate_election\": candidate_election,\n            \"division\": division,\n        }\n\n        vote_update = {}\n\n        if not ap_meta.override_ap_votes:\n            vote_update[\"count\"] = VOTE_COUNT\n            vote_update[\"pct\"] = VOTE_PERCENT\n\n        if not ap_meta.override_ap_call:\n            vote_update[\"winning\"] = WINNER\n            vote_update[\"runoff\"] = RUNOFF\n\n            if WINNER:\n                ap_meta.called = True\n\n        if ap_meta.precincts_reporting != PRECINCTS_REPORTING:\n            ap_meta.precincts_reporting = PRECINCTS_REPORTING\n            ap_meta.precincts_total = PRECINCTS_TOTAL\n            ap_meta.precincts_reporting_pct = PRECINCTS_REPORTING_PERCENT\n\n        if PRECINCTS_REPORTING_PERCENT == 1 or UNCONTESTED or tabulated:\n            ap_meta.tabulated = True\n        else:\n            ap_meta.tabulated = False\n\n        ap_meta.save()\n\n        votes = Votes.objects.filter(**filter_kwargs)\n\n        if (WINNER or RUNOFF) and not candidate_election.uncontested:\n            # If new call on contested race, send alerts\n            first = votes.first()\n\n            if not (first.winning or first.runoff) and not no_bots:\n                if ap_meta.election.party:\n                    PRIMARY_PARTY = ap_meta.election.party.label\n                else:\n                    PRIMARY_PARTY = None\n\n                # construct page URL for payload\n                if app_settings.AWS_S3_BUCKET == \"interactives.politico.com\":\n                    base_url = \"https://www.politico.com/election-results/2018\"\n                    end_path = \"\"\n                else:\n                    base_url = \"https://s3.amazonaws.com/staging.interactives.politico.com/election-results/2018\"  # noqa\n                    end_path = \"index.html\"\n\n                if RACE_TYPE == \"Runoff\":\n                    state_path = \"{}/runoff\".format(division.slug)\n                elif \"Special\" in RACE_TYPE:\n                    # first check to see if this special is on a state page\n                    events = ElectionEvent.objects.filter(\n                        division=division,\n                        election_day__slug=ELEX_ELECTION_DATE,\n                    )\n                    print(events, division, ELEX_ELECTION_DATE)\n\n                    if len(events) > 0:\n                        state_path = division.slug\n                    else:\n                        parsed = datetime.strptime(\n                            ELEX_ELECTION_DATE, \"%Y-%m-%d\"\n                        )\n                        month = parsed.strftime(\"%b\").lower()\n                        day = parsed.strftime(\"%d\")\n\n                        state_path = \"{}/special-election/{}-{}\".format(\n                            division.slug, month, day\n                        )\n                else:\n                    state_path = division.slug\n\n                url = \"{}/{}/{}\".format(base_url, state_path, end_path)\n\n                payload = {\n                    \"race_id\": RACE_ID,\n                    \"division\": division.label,\n                    \"division_slug\": division.slug,\n                    \"office\": format_office_label(\n                        candidate.race.office, division.label\n                    ),\n                    \"office_short\": short_format_office_label(\n                        candidate.race.office, division.label\n                    ),\n                    \"candidate\": \"{} {}\".format(\n                        candidate.person.first_name, candidate.person.last_name\n                    ),\n                    \"election_date\": ELEX_ELECTION_DATE,\n                    \"candidate_party\": candidate.party.ap_code,\n                    \"primary_party\": PRIMARY_PARTY,\n                    \"vote_percent\": VOTE_PERCENT,\n                    \"vote_count\": VOTE_COUNT,\n                    \"runoff\": RUNOFF,\n                    \"precincts_reporting_percent\": PRECINCTS_REPORTING_PERCENT,\n                    \"jungle\": RACE_TYPE == \"Open Primary\",\n                    \"runoff_election\": RACE_TYPE == \"Runoff\",\n                    \"special_election\": \"Special\" in RACE_TYPE,\n                    \"page_url\": url,\n                }\n\n                call_race_in_slack.delay(payload)\n                call_race_in_slackchat.delay(payload)\n                call_race_on_twitter.delay(payload)\n\n        votes.update(**vote_update)\n\n        if OFFICE_NAME == \"U.S. House\":\n            bop_body = self.bop[\"house\"]\n        elif OFFICE_NAME == \"U.S. Senate\":\n            bop_body = self.bop[\"senate\"]\n        else:\n            return\n\n        if not PARTY:\n            return\n\n        if (WINNER and not ap_meta.override_ap_call) or votes.first().winning:\n            party_slug = PARTY.lower()\n            incumbent = self.get_current_party(ap_meta.election.race)\n\n            if PARTY not in [\"Dem\", \"GOP\"]:\n                if (\n                    STATE_POSTAL in [\"VT\", \"ME\"]\n                    and OFFICE_NAME == \"U.S. Senate\"\n                ):\n                    bop_body[\"dem\"][\"total\"] += 1\n                else:\n                    bop_body[\"other\"][\"total\"] += 1\n            else:\n                bop_body[party_slug][\"total\"] += 1\n                if party_slug != incumbent:\n                    print(result, votes.first().winning)\n                    print(LAST_NAME, candidate.race.office)\n                    bop_body[party_slug][\"flips\"] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_task(name):\n\t'''Look up a task by name.'''\n\tmatches = [x for x in TASKS if x.match(name)]\n\tif matches:\n\t\treturn matches[0]", "response": "Look up a task by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _opts_to_dict(*opts):\n\t'''Convert a tuple of options returned from getopt into a dictionary.'''\n\tret = {}\n\tfor key, val in opts:\n\t\tif key[:2] == '--':\n\t\t\tkey = key[2:]\n\t\telif key[:1] == '-':\n\t\t\tkey = key[1:]\n\t\tif val == '':\n\t\t\tval = True\n\t\tret[key.replace('-','_')] = val\n\treturn ret", "response": "Convert a tuple of options returned from getopt into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string highlighted for a terminal.", "response": "def _highlight(string, color):\n\t'''Return a string highlighted for a terminal.'''\n\tif CONFIG['color']:\n\t\tif color < 8:\n\t\t\treturn '\\033[{color}m{string}\\033[0m'.format(string = string, color = color+30)\n\t\telse:\n\t\t\treturn '\\033[{color}m{string}\\033[0m'.format(string = string, color = color+82)\n\telse:\n\t\treturn string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _taskify(func):\n\t'''Convert a function into a task.'''\n\tif not isinstance(func, _Task):\n\t\tfunc = _Task(func)\n\n\t\tspec = inspect.getargspec(func.func)\n\t\tif spec.args:\n\t\t\tnum_args = len(spec.args)\n\t\t\tnum_kwargs = len(spec.defaults or [])\n\t\t\tisflag = lambda x, y: '' if x.defaults[y] is False else '='\n\n\t\t\tfunc.args = spec.args[:(num_args - num_kwargs)]\n\t\t\tfunc.defaults = {spec.args[i - num_kwargs]: spec.defaults[i] for i in range(num_kwargs)}\n\t\t\tfunc.kwargs = [key.replace('_','-') + isflag(func, key) for key in func.defaults]\n\n\t\tif not func.name.startswith('_'):\n\t\t\tTASKS.append(func)\n\n\treturn func", "response": "Convert a function into a task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a function as a task.", "response": "def task(*args, **kwargs):\n\t'''Register a function as a task, as well as applying any attributes. '''\n\n\t# support @task\n\tif args and hasattr(args[0], '__call__'):\n\t\treturn _taskify(args[0])\n\n\t# as well as @task(), @task('default'), etc.\n\telse:\n\t\tdef wrapper(func):\n\t\t\tglobal DEFAULT, SETUP, TEARDOWN\n\t\t\tfunc = _taskify(func)\n\n\t\t\tif 'default' in args:\n\t\t\t\tDEFAULT = func\n\n\t\t\tif 'setup' in args:\n\t\t\t\tSETUP = func\n\n\t\t\tif 'teardown' in args:\n\t\t\t\tTEARDOWN = func\n\n\t\t\tif 'private' in args:\n\t\t\t\tTASKS.remove(func)\n\n\t\t\tif 'method' in args:\n\t\t\t\tfunc.method = True\n\t\t\t\tfunc.args = func.args[1:]\n\n\t\t\tif 'consume' in args:\n\t\t\t\tfunc.consume = True\n\n\t\t\tif 'reqs' in kwargs:\n\t\t\t\tfunc.reqs = _tuplify(kwargs['reqs'])\n\t\t\t\tfunc.file_reqs = [req for req in func.reqs if type(req) is str]\n\t\t\t\tfunc.task_reqs = [req for req in func.reqs if type(req) is not str]\n\n\t\t\tif 'gens' in kwargs:\n\t\t\t\tfunc.gens = kwargs['gens']\n\t\t\t\tGENERATES[kwargs['gens']] = func\n\n\t\t\tif 'alias' in kwargs:\n\t\t\t\tfunc.aliases = _tuplify(kwargs['alias'])\n\n\t\t\tif 'namespace' in kwargs:\n\t\t\t\tfunc.ns = kwargs['namespace'] + '.' if kwargs['namespace'] else ''\n\n\t\t\treturn func\n\n\t\treturn wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequiring tasks or files at runtime.", "response": "def require(*reqs):\n\t'''Require tasks or files at runtime.'''\n\tfor req in reqs:\n\t\tif type(req) is str:\n\t\t\t# does not exist and unknown generator\n\t\t\tif not os.path.exists(req) and req not in GENERATES:\n\t\t\t\tabort(LOCALE['abort_bad_file'].format(req))\n\n\t\t\t# exists but unknown generator\n\t\t\tif req not in GENERATES:\n\t\t\t\treturn\n\n\t\t\t# exists and known generator\n\t\t\tif req in GENERATES:\n\t\t\t\treq = GENERATES[req]\n\n\t\tif req.valid is None:\n\t\t\tif len(req.args):\n\t\t\t\tabort(LOCALE['abort_bad_args'], req, len(req.args))\n\n\t\t\treq()\n\n\t\tif req.valid is False:\n\t\t\tabort(LOCALE['abort_bad_task'], req)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if all tasks or files are valid. Valid files exist on the disk.", "response": "def valid(*things):\n\t'''Return True if all tasks or files are valid.\n\tValid tasks have been completed already. Valid files exist on the disk.'''\n\tfor thing in things:\n\t\tif type(thing) is str and not os.path.exists(thing):\n\t\t\treturn False\n\t\tif thing.valid is None:\n\t\t\treturn False\n\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shell(command, *args):\n\t'''Pass a command into the shell.'''\n\tif args:\n\t\tcommand = command.format(*args)\n\n\tprint LOCALE['shell'].format(command)\n\n\ttry:\n\t\treturn subprocess.check_output(command, shell=True)\n\texcept subprocess.CalledProcessError, ex:\n\t\treturn ex", "response": "Pass a command into the shell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef age(*paths):\n\t'''Return the minimum age of a set of files.\n\tReturns 0 if no paths are given.\n\tReturns time.time() if a path does not exist.'''\n\tif not paths:\n\t\treturn 0\n\n\tfor path in paths:\n\t\tif not os.path.exists(path):\n\t\t\treturn time.time()\n\n\treturn min([(time.time() - os.path.getmtime(path)) for path in paths])", "response": "Return the minimum age of a set of files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise an AbortException halting task execution and exiting.", "response": "def abort(message, *args):\n\t'''Raise an AbortException, halting task execution and exiting.'''\n\tif args:\n\t\traise _AbortException(message.format(*args))\n\n\traise _AbortException(message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint all available tasks and descriptions.", "response": "def _help():\n\t'''Print all available tasks and descriptions.'''\n\tfor task in sorted(TASKS, key=lambda x: (x.ns or '000') + x.name):\n\t\ttags = ''\n\t\tif task is DEFAULT:\n\t\t\ttags += '*'\n\t\tif task is SETUP:\n\t\t\ttags += '+'\n\t\tif task is TEARDOWN:\n\t\t\ttags += '-'\n\n\t\tprint LOCALE['help_command'].format(task, tags, task.help)\n\n\t\tif task.aliases:\n\t\t\tprint LOCALE['help_aliases'].format(task.aliasstr())\n\t\tif task.reqs:\n\t\t\tprint LOCALE['help_reqs'].format(task.reqstr())\n\t\tif task.gens:\n\t\t\tprint LOCALE['help_gens'].format(task.gens)\n\t\tif task.args or task.defaults:\n\t\t\tprint LOCALE['help_args'].format(task.ns + task.name, task.kwargstr(), task.argstr())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninvoking a task with the appropriate args ; return the remaining args.", "response": "def _invoke(task, args):\n\t'''Invoke a task with the appropriate args; return the remaining args.'''\n\tkwargs = task.defaults.copy()\n\tif task.kwargs:\n\t\ttemp_kwargs, args = getopt.getopt(args, '', task.kwargs)\n\t\ttemp_kwargs = _opts_to_dict(*temp_kwargs)\n\t\tkwargs.update(temp_kwargs)\n\n\tif task.args:\n\t\tfor arg in task.args:\n\t\t\tif not len(args):\n\t\t\t\tabort(LOCALE['error_wrong_args'], task, len(task.args))\n\t\t\tkwargs.update({arg: args[0]})\n\t\t\targs = args[1:]\n\n\tif task.consume:\n\t\ttask(*args, **kwargs)\n\t\treturn []\n\telse:\n\t\ttask(**kwargs)\n\t\treturn args"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match(self, name):\n\t\t'''Compare an argument string to the task name.'''\n\t\tif (self.ns + self.name).startswith(name):\n\t\t\treturn True\n\n\t\tfor alias in self.aliases:\n\t\t\tif (self.ns + alias).startswith(name):\n\t\t\t\treturn True", "response": "Compare an argument string to the task name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconcatenates the aliases tuple into a string.", "response": "def aliasstr(self):\n\t\t'''Concatenate the aliases tuple into a string.'''\n\t\treturn ', '.join(repr(self.ns + x) for x in self.aliases)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconcatenate keyword arguments into a string.", "response": "def kwargstr(self):\n\t\t'''Concatenate keyword arguments into a string.'''\n\t\ttemp = [' [--' + k + (' ' + str(v) if v is not False else '') + ']' for k, v in self.defaults.items()]\n\t\treturn ''.join(temp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing response. :return response: Instance of django.http.Response", "response": "def emit(self):\n        \"\"\" Serialize response.\n\n        :return response: Instance of django.http.Response\n\n        \"\"\"\n        # Skip serialize\n        if not isinstance(self.response, SerializedHttpResponse):\n            return self.response\n\n        self.response.content = self.serialize(self.response.response)\n        self.response['Content-type'] = self.media_type\n        return self.response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize to JSON. :return string: serializaed JSON", "response": "def serialize(self, content):\n        \"\"\" Serialize to JSON.\n\n        :return string: serializaed JSON\n\n        \"\"\"\n        worker = JSONSerializer(\n            scheme=self.resource,\n            options=self.resource._meta.emit_options,\n            format=self.resource._meta.emit_format,\n            **self.resource._meta.emit_models\n        )\n        return worker.serialize(content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize(self, content):\n        content = super(JSONPEmitter, self).serialize(content)\n        callback = self.request.GET.get('callback', 'callback')\n        return u'%s(%s)' % (callback, content)", "response": "Serialize to JSONP.\n\n        :return string: serializaed JSONP"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(self, content):\n        worker = XMLSerializer(\n            scheme=self.resource,\n            format=self.resource._meta.emit_format,\n            options=self.resource._meta.emit_options,\n            **self.resource._meta.emit_models\n        )\n        return self.xmldoc_tpl % (\n            'true' if not self.response.error else 'false',\n            str(self.resource.api or ''),\n            int(mktime(datetime.now().timetuple())),\n            worker.serialize(content)\n        )", "response": "Serialize to XML.\n\n        :return string: serialized XML"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize(self, content):\n        if self.response.error:\n            template_name = op.join('api', 'error.%s' % self.format)\n        else:\n            template_name = (self.resource._meta.emit_template\n                             or self.get_template_path(content))\n\n        template = loader.get_template(template_name)\n\n        return template.render(RequestContext(self.request, dict(\n            content=content,\n            emitter=self,\n            resource=self.resource)))", "response": "Render Django template.\n\n        :return string: rendered content"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding template. :return string: remplate path", "response": "def get_template_path(self, content=None):\n        \"\"\" Find template.\n\n        :return string: remplate path\n\n        \"\"\"\n        if isinstance(content, Paginator):\n            return op.join('api', 'paginator.%s' % self.format)\n\n        if isinstance(content, UpdatedList):\n            return op.join('api', 'updated.%s' % self.format)\n\n        app = ''\n        name = self.resource._meta.name\n\n        if not content:\n            content = self.resource._meta.model\n\n        if isinstance(content, (Model, ModelBase)):\n            app = content._meta.app_label\n            name = content._meta.module_name\n\n        basedir = 'api'\n        if getattr(self.resource, 'api', None):\n            basedir = self.resource.api.prefix\n\n        return op.join(\n            basedir,\n            str(self.resource.api or ''), app, \"%s.%s\" % (name, self.format)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves rendered content to callback.", "response": "def serialize(self, content):\n        \"\"\" Move rendered content to callback.\n\n        :return string: JSONP\n\n        \"\"\"\n        content = super(JSONPTemplateEmitter, self).serialize(content)\n        callback = self.request.GET.get('callback', 'callback')\n        return '%s(%s)' % (callback, content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize to xml. :return string:", "response": "def serialize(self, content):\n        \"\"\" Serialize to xml.\n\n        :return string:\n\n        \"\"\"\n        return self.xmldoc_tpl % (\n            'true' if self.response.status_code == HTTP_200_OK else 'false',\n            str(self.resource.api or ''),\n            int(mktime(datetime.now().timetuple())),\n            super(XMLTemplateEmitter, self).serialize(content)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match_item(key, value, item):\n    if isinstance(value, (list, tuple)):\n        return any(match_item(key, sub_value, item) for sub_value in value)\n    else:\n        return key not in item or str(item.get(key)).lower() == str(value).lower()", "response": "Check if some item matches criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef browsers(self, browser=None, browser_version=None, device=None, os=None, os_version=None):\n        response = self.execute('GET', '/screenshots/browsers.json')\n        for key, value in list(locals().items()):\n            if key in ('self', 'response') or not value:\n                continue\n            response = [item for item in response if match_item(key, value, item)]\n        return response", "response": "Returns a list of available browser and OS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make(self, url, browsers=None, destination=None, timeout=DEFAULT_TIMEOUT, retries=DEFAULT_RETRIES, **kwargs):\n        response = self.generate(url, browsers, **kwargs)\n        return self.download(response['job_id'], destination, timeout, retries)", "response": "Generate screenshots for given url and saves it to specified destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(self, url, browsers=None, orientation=None, mac_res=None, win_res=None,\n                             quality=None, local=None, wait_time=None, callback_url=None):\n        \"\"\"\n        Generates screenshots for a URL.\n        \"\"\"\n        if isinstance(browsers, dict):\n            browsers = [browsers]\n        if browsers is None:\n            browsers = [self.default_browser]\n        data = dict((key, value) for key, value in locals().items() if value is not None and key != 'self')\n        return self.execute('POST', '/screenshots', json=data)", "response": "Generate screenshots for a URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download(self, job_id, destination=None, timeout=DEFAULT_TIMEOUT, retries=DEFAULT_RETRIES):\n        self._retries_num = 0\n        sleep(timeout)\n        self.save_many(job_id, destination, timeout, retries)\n        return self._cache", "response": "Downloads all screenshots for given job_id to destination folder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_file(self, filename, content):\n        with open(filename, 'wb') as f:\n            for chunk in content.iter_content(chunk_size=1024):\n                if chunk:\n                    f.write(chunk)", "response": "Saves the content of the content object to the local file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install(cls):\n        [os.makedirs('{}/{}'.format(cls.home, cls.dirs[d])) for d in cls.dirs]", "response": "Create the required directories in the home directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uninstall(cls):\n        if os.path.exists(cls.home):\n            shutil.rmtree(cls.home)", "response": "Remove the package manager from the system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_installed_distributions(skip=stdlib_pkgs):\n    return [d for d in pkg_resources.working_set\n            if d.key not in skip]", "response": "Returns a list of installed Distribution objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef marshal_bson(\n    obj,\n    types=BSON_TYPES,\n    fields=None,\n):\n    \"\"\" Recursively marshal a Python object to a BSON-compatible dict\n        that can be passed to PyMongo, Motor, etc...\n\n    Args:\n        obj:    object, It's members can be nested Python\n                objects which will be converted to dictionaries\n        types:  tuple-of-types, The BSON primitive types, typically\n                you would not change this\n        fields: None-list-of-str, Explicitly marshal only these fields\n    Returns:\n        dict\n    \"\"\"\n    return marshal_dict(\n        obj,\n        types,\n        fields=fields,\n    )", "response": "Recursively marshal a Python object to a BSON - compatible dict\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unmarshal_bson(\n    obj,\n    cls,\n    allow_extra_keys=True,\n    ctor=None,\n):\n    \"\"\" Unmarshal @obj into @cls\n\n    Args:\n        obj:              dict, A BSON object\n        cls:              type, The class to unmarshal into\n        allow_extra_keys: bool, False to raise an exception when extra\n                          keys are present, True to ignore\n        ctor:             None-or-static-method: Use this method as the\n                          constructor instead of __init__\n    Returns:\n        instance of @cls\n    Raises:\n        ExtraKeysError: If allow_extra_keys == False, and extra keys\n                        are present in @obj and not in @cls.__init__\n        ValueError:     If @cls.__init__ does not contain a self argument\n    \"\"\"\n    return unmarshal_dict(\n        obj,\n        cls,\n        allow_extra_keys,\n        ctor=ctor,\n    )", "response": "Unmarshalls a BSON object into a new object of the specified class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef json(\n        self,\n        include_id=False,\n        date_fmt=None,\n        object_id_fmt=str,\n    ):\n        \"\"\" Helper method to convert to MongoDB documents to JSON\n\n            This includes helpers to convert non-JSON compatible types\n            to valid JSON types.  HOWEVER, it cannot recurse into nested\n            classes.\n\n        Args:\n            include_id:    bool, True to cast _id to a str,\n                           False to omit from the result\n            date_fmt:      str-or-None:  None to cast to UNIX timestamp,\n                           str (strftime format) to convert to string,\n                           for example: '%Y-%m-%d_%H:%M:%S'\n            object_id_fmt: type, Cast the bson.ObjectId's to this format,\n                           or None to exclude.  This only applies to\n                           ObjectId variables other than _id.\n        Returns:\n            dict\n        \"\"\"\n        has_slots, d = _get_dict(self)\n        _id = self._id\n        if not include_id:\n            self._id = None\n\n        object_ids = {\n            k: v for k, v in d.items()\n            if isinstance(v, bson.ObjectId)\n        }\n\n        for k, v in object_ids.items():\n            if object_id_fmt is None:\n                setattr(self, k, None)\n            else:\n                setattr(self, k, object_id_fmt(v))\n\n        datetimes = {\n            k: v for k, v in d.items()\n            if isinstance(v, datetime.datetime)\n        }\n\n        for k, v in datetimes.items():\n            if date_fmt is None:\n                ts = (\n                    time.mktime(\n                        v.timetuple(),\n                    )\n                    + v.microsecond\n                    / 1e6\n                )\n                setattr(self, k, ts)\n            else:\n                setattr(self, k, v.strftime(date_fmt))\n\n        j = marshal_dict(\n            self,\n            JSON_TYPES,\n            'json',\n            include_id=include_id,\n            date_fmt=date_fmt,\n            object_id_fmt=object_id_fmt,\n        )\n        self._id = _id\n\n        for k, v in object_ids.items():\n            setattr(self, k, v)\n\n        for k, v in datetimes.items():\n            setattr(self, k, v)\n\n        return j", "response": "Helper method to convert to JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, request):\n        if request.method in ('POST', 'PUT', 'PATCH'):\n            content_type = self.determine_content(request)\n            if content_type:\n                split = content_type.split(';', 1)\n                if len(split) > 1:\n                    content_type = split[0]\n                content_type = content_type.strip()\n\n            parser = self._meta.parsers_dict.get(\n                content_type, self._meta.default_parser)\n            data = parser(self).parse(request)\n            return dict() if isinstance(data, basestring) else data\n        return dict()", "response": "Parse request content.\n\n        :return dict: parsed data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_content(request):\n\n        if not request.META.get('CONTENT_LENGTH', None) \\\n           and not request.META.get('TRANSFER_ENCODING', None):\n            return None\n\n        return request.META.get('CONTENT_TYPE', None)", "response": "Determine the content type of the request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef section(msg):\n    logger.info(bar(msg, position='top'))\n    try:\n        yield\n    except SectionError as e:\n        logger.error(e)\n        logger.info(bar('...skipped.', position='bottom'))\n    except SectionWarning as e:\n        logger.warning(e)\n        logger.info(bar('...skipped.', position='bottom'))\n    else:\n        logger.info(bar('...done!', position='bottom'))", "response": "Context manager that prints a top bar to stderr upon entering and a bottom bar upon exiting."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef imgur_role(name, rawtext, text, *_):\n    if not RE_IMGUR_ID.match(text):\n        message = 'Invalid Imgur ID specified. Must be 5-10 letters and numbers. Got \"{}\" from \"{}\".'\n        raise ImgurError(message.format(text, rawtext))\n    node = ImgurTextNode(name, text)\n    return [node], []", "response": "Returns a tuple of nodes that are the rst nodes that are replaced the role."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(request):\n    session = yield from app.ps.session.load(request)\n    session['random'] = random.random()\n    return session", "response": "Update a current user s session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keys(self):\n        \"Returns all the keys this object can return proper values for.\"\n        return tuple(set(self.new.keys()).union(self.old.keys()))", "response": "Returns all the keys this object can return proper values for."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef values(self):\n        \"Returns all values this object can return via keys.\"\n        return tuple(set(self.new.values()).union(self.old.values()))", "response": "Returns all values this object can return via keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the search spaces for a simple constraint size computation.", "response": "def _compute_search_spaces(self, used_variables):\n        \"\"\"Returns the size of each domain for a simple constraint size computation.\n        This is used to pick the most constraining constraint first.\n        \"\"\"\n        return tuple(len(domain) for name, domain in self._vars.iteritems())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef satisfies_constraints(self, possible_solution):\n        for c in self._constraints:\n            values = c.extract_values(possible_solution)\n            if values is None or not c(*values):\n                return False\n        return True", "response": "Return True if the given solution is satisfied by all the constraints."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_conditions(self, variables, constraints):\n        self._vars, self._constraints = variables, []\n        # build constraint objects\n        for func, variables, values in constraints:\n            c = Constraint(func, variables, values, self._compute_search_spaces(variables))\n            self._constraints.append(c)\n        # sort into most constraining first\n        self._constraints.sort()", "response": "Problem provided data.\n\n        variables = {variable-name: list-of-domain-values}\n        constraints = [(constraint_function, variable-names, default-variable-values)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator of all possible combinations of all possible set of keys.", "response": "def combinations(self):\n        \"\"\"Returns a generator of all possible combinations.\n        \"\"\"\n        keys = self._vars.keys()\n        for result in product(*self._vars.values()):\n            possible_solution = {}\n            for i, v in enumerate(result):\n                possible_solution[keys[i]] = v\n            yield possible_solution"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_conditions(self, variables, constraints):\n        self._vars, self._constraints = variables, []\n        self._constraints_for_var = {}\n        vars_constraint_count = {}\n        # build constraint objects\n        for func, variables, values in constraints:\n            c = Constraint(func, variables, values, self._compute_search_spaces(variables))\n            self._constraints.append(c)\n            for var in variables:\n                self._constraints_for_var[var] = self._constraints_for_var.get(var, []) + [c]\n                vars_constraint_count[var] = vars_constraint_count.get(var, 0) + 1\n        # sort into most constraining first\n        self._constraints.sort()\n\n        self._variable_expand_order = tuple(sorted(self._vars.keys(), key=vars_constraint_count.get, reverse=True))", "response": "Problem provided data.\n\n        variables = {variable-name: list-of-domain-values}\n        constraints = [(constraint_function, variable-names, variable-default-values)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef satisfies_constraints(self, possible_solution):\n        for c in self._constraints:\n            values = c.extract_values(possible_solution)\n            if any(type(v) is NilObject for v in values) or not c(*values):\n                return False\n        return True", "response": "Return True if the given solution is satisfied by all the constraints."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all possible solutions based on the provide solution. This assumes that the given solution is incomplete.", "response": "def derived_solutions(self, solution=None):\n        \"\"\"Returns all possible solutions based on the provide solution. This assumes\n        that the given solution is incomplete.\n\n        \"\"\"\n        solution = solution or Solution()\n        used_variables = solution.keys()\n        unused_variables = (v for v in self._variable_expand_order if v not in used_variables)\n        for var in unused_variables:\n            for value in self._vars[var]:\n                yield Solution({var: value}, solution)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the given solution s derivatives may have potential valid complete solutions.", "response": "def is_feasible(self, solution):\n        \"\"\"Returns True if the given solution's derivatives may have potential\n        valid, complete solutions.\n        \"\"\"\n        newvars = solution.new.keys()\n        for newvar in newvars:\n            for c in self._constraints_for_var.get(newvar, []):\n                values = c.extract_values(solution, use_defaults=True)\n                if not c(*values):\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a generator that returns all possible_solution given a base solution to start searching.", "response": "def _next(self, possible_solution):\n        \"\"\"Where the magic happens. Produces a generator that returns all solutions given\n        a base solution to start searching.\n        \"\"\"\n        # bail out if we have seen it already. See __iter__ to where seen is initially set.\n        # A complete solution has all its variables set to a particular value.\n        is_complete = (len(possible_solution) == len(self._vars))\n\n        if is_complete:\n            self._solutions_seen += 1\n            if self.satisfies_constraints(possible_solution):\n                yield dict(possible_solution)\n        else:\n            if self.is_feasible(possible_solution):\n                for s in self.derived_solutions(possible_solution):\n                    for solution in self._next(s):\n                        yield solution"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading all icons found in path subdirs of package.", "response": "def load_icons(appname, package=\"\"):\n    \"\"\"\n    load all icons found in path, subdirs '<package>/icons/<appname>'.\n    Package is optional.\n    \"\"\"\n    # loop over system path\n    global __icons_loaded\n    if __icons_loaded:\n        return\n    icon_paths = ['/usr/local/share/meqtrees'] + sys.path\n    for path in icon_paths:\n        path = path or '.'\n        # for each entry, try <entry>/icons/<appname>'\n        trydir = os.path.join(path, package, 'icons', appname)\n        _dprint(3, 'trying icon path', trydir)\n        try:\n            files = os.listdir(trydir)\n        except:\n            continue\n        _dprint(3, len(files), 'entries in', trydir)\n        # loop over all files\n        nicons = 0\n        for f in files:\n            (name, ext) = os.path.splitext(f);  # check extension\n            if ext in ('.png', '.xpm', '.gif'):\n                f = os.path.join(trydir, f)\n                try:\n                    pm = QPixmap(f)\n                except:\n                    _dprint(3, 'error loading icon', name, sys.exc_value())\n                    continue\n                # register pixmap as global symbol using the supplied name\n                if name in globals():\n                    globals()[name].assign(pm)\n                else:\n                    globals()[name] = QPixmapWrapper(pm)\n                nicons += 1\n                _dprint(4, 'loaded icon', f)\n            else:\n                _dprint(4, 'ignoring entry', f)\n        _dprint(1, nicons, 'icons loaded from ', trydir)\n        __icons_loaded = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assign(self, pm):\n        if isinstance(pm, QPixmap):\n            self._pm = pm\n        else:  # assume xpm string list to be decoded on-demand\n            self._xpmstr = pm\n            self._pm = None\n        self._icon = None", "response": "Reassign pixmap or xpm string array to wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pm(self):\n        if self._pm is None:\n            self._pm = QPixmap(self._xpmstr)\n        return self._pm", "response": "Get QPixmap from wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef icon(self):\n        if self._icon is None:\n            self._icon = QIcon(self.pm())\n        return self._icon", "response": "Get QIcon from wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload all icons found in path subdirs icons / appname", "response": "def _load(self):\n        \"\"\"load all icons found in path, subdirs 'icons/appname'\"\"\"\n        # loop over system path\n        if self._loaded:\n            return\n        icon_paths = ['/usr/local/share/meqtrees'] + sys.path\n        for path in icon_paths:\n            path = path or '.'\n            # for each entry, try <entry>/icons/<appname>'\n            for a, b in [('icons', self._appname), (self._appname, 'icons')]:\n                trydir = os.path.join(path, a, b)\n                _dprint(3, 'trying icon path', trydir)\n                try:\n                    files = os.listdir(trydir)\n                except:\n                    continue\n                _dprint(3, len(files), 'entries in', trydir)\n                # loop over all files\n                nicons = 0\n                for f in files:\n                    (name, ext) = os.path.splitext(f);  # check extension\n                    if ext in ('.png', '.xpm', '.gif'):\n                        f = os.path.join(trydir, f)\n                        try:\n                            pm = QPixmap(f)\n                        except:\n                            _dprint(3, 'error loading icon', name, sys.exc_value())\n                            continue\n                        # register pixmap\n                        self._pixmaps[name] = QPixmapWrapper(pm)\n                        nicons += 1\n                        _dprint(4, 'loaded icon', f)\n                    else:\n                        _dprint(4, 'ignoring entry', f)\n                _dprint(1, nicons, 'icons loaded from ', trydir)\n                self._loaded = True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_node(self, exp, schema):\n        # A relation node.\n        if len(exp) == 1 and isinstance(exp[0], str):\n            node = RelationNode(name=exp[0], schema=schema)\n\n        # An expression.\n        elif len(exp) == 1 and isinstance(exp[0], list):\n            node = self.to_node(exp[0], schema)\n\n        # Unary operators.\n        elif isinstance(exp[0], str) and self.grammar.is_unary(exp[0]):\n            child = self.to_node(exp[2:], schema)\n            node = self.create_unary_node(operator=exp[0], child=child,\n                                          param=exp[1], schema=schema)\n\n        # Assignment.\n        elif exp[1] is self.grammar.syntax.assign_op:\n            child = self.to_node(exp[2:], schema)\n            node = self.create_unary_node(operator=exp[1], child=child,\n                                          param=exp[0], schema=schema)\n\n        # Binary operators.\n        elif self.grammar.is_binary(exp[1]):\n            # Pyparsing will put different operators with the same precedence\n            # in the same list. This can be a problem when we mix operators with\n            # and without parameters (for example join). We avoid this below\n            # and build from right to left, to create the correct syntax tree.\n            if isinstance(exp[-2], str):\n                # Operator without parameters\n                op_pos = -2\n                param = None\n            else:\n                op_pos = -3\n                param = exp[-2]\n\n            operator = exp[op_pos]\n            left = self.to_node(exp[:op_pos], schema)\n            right = self.to_node(exp[-1], schema)\n            node = self.create_binary_node(operator=operator, left=left,\n                                           right=right, param=param)\n\n        else:\n            raise ValueError\n\n        return node", "response": "Converts a list of relational algebra expression names to a Node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_unary_node(self, operator, child, param=None, schema=None):\n\n        if operator == self.grammar.syntax.select_op:\n            conditions = ' '.join(flatten(param))\n            node = SelectNode(child, conditions)\n\n        elif operator == self.grammar.syntax.project_op:\n            node = ProjectNode(child, param)\n\n        elif operator == self.grammar.syntax.rename_op:\n            name = None\n            attributes = []\n            if isinstance(param[0], str):\n                name = param.pop(0)\n            if param:\n                attributes = param[0]\n            node = RenameNode(child, name, attributes, schema)\n\n        elif operator == self.grammar.syntax.assign_op:\n            name = param[0]\n            attributes = [] if len(param) < 2 else param[1]\n            node = AssignNode(child, name, attributes, schema)\n\n        else:\n            raise ValueError\n\n        return node", "response": "Create a Unary Node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a Node based on the specified operator and left and right.", "response": "def create_binary_node(self, operator, left, right, param=None):\n        \"\"\"\n        Return a Node whose type depends on the specified operator.\n\n        :param operator: A relational algebra operator (see constants.py)\n        :return: A Node.\n        \"\"\"\n\n        # Join operators\n        if operator == self.grammar.syntax.join_op:\n            node = CrossJoinNode(left, right)\n\n        elif operator == self.grammar.syntax.natural_join_op:\n            node = NaturalJoinNode(left, right)\n\n        elif operator == self.grammar.syntax.theta_join_op:\n            conditions = ' '.join(flatten(param))\n            node = ThetaJoinNode(left, right, conditions)\n\n        # Set operators\n        elif operator == self.grammar.syntax.union_op:\n            node = UnionNode(left, right)\n\n        elif operator == self.grammar.syntax.difference_op:\n            node = DifferenceNode(left, right)\n\n        elif operator == self.grammar.syntax.intersect_op:\n            node = IntersectNode(left, right)\n\n        else:\n            raise ValueError\n\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_to(self, ins):\n        input_entities = set()\n        attribute_values = set()\n        for in_ in ins:\n            if self.ATTRIBUTE not in self.entity_graph.has_a.get_descendants(in_.head.name):\n                attribute_values.update(in_.head.attributes[self.ATTRIBUTE])\n                input_entities.add(in_.head.name)\n        if len(attribute_values) == 0:\n            attribute_values = ins[0].head.attributes[self.ATTRIBUTE]\n        elif len(attribute_values) > 1:\n            raise ValueError('Unable to resolve single output attribute value for chromosome_id ({}),'.format(', '.join(attribute_values)))\n        return list(attribute_values)[0]", "response": "Resolve the output attribute value for chromosome_id. Valid values are immutable ie. the attribute key is not\n        an actual entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch_resource(url, body):\n    response = Bridge_DAO().patchURL(url, PHEADER, body)\n    log_data = \"PATCH %s %s ==status==> %s\" % (url, body, response.status)\n\n    if response.status != 200:\n        _raise_exception(log_data, url, response)\n\n    _log_resp(log_data, response.data)\n    return response.data", "response": "Patch a resource with the given json body"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nposts a resource with the given json body", "response": "def post_resource(url, body):\n    \"\"\"\n    Post resource with the given json body\n    :returns: http response data\n    \"\"\"\n    response = Bridge_DAO().postURL(url, PHEADER, body)\n    log_data = \"POST %s %s ==status==> %s\" % (url, body, response.status)\n\n    if response.status != 200 and response.status != 201:\n        # 201 Created\n        _raise_exception(log_data, url, response)\n\n    _log_resp(log_data, response.data)\n    return response.data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put_resource(url, body):\n    response = Bridge_DAO().putURL(url, PHEADER, body)\n    log_data = \"PUT %s %s ==status==> %s\" % (url, body, response.status)\n\n    if response.status != 200:\n        _raise_exception(log_data, url, response)\n\n    _log_resp(log_data, response.data)\n    return response.data", "response": "This function handles the PUT request with the given json body and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclass Decorator: \u8bbe\u7f6e\u8def\u5f84\u5339\u914d\u6a21\u5f0f\u548c\u6392\u5e8f\u5e8f\u53f7 1. \u652f\u6301\u8bbe\u7f6e\u591a\u4e2a\u94fe\u63a5\u5339\u914d\u89c4\u5219\u3002 \u53c2\u6570: pattern \u94fe\u63a5\u6b63\u5219\u5339\u914d order \u6392\u5e8f\u5e8f\u53f7 \u793a\u4f8b: @url(r\"(?i)/(index.html?)?\", 10) @url(r\"(?i)/default.html?\", 8) class IndexHandler(BaseHandler): pass", "response": "def url(pattern, order = 0):\r\n    \"\"\"\r\n        Class Decorator: \u8bbe\u7f6e\u8def\u5f84\u5339\u914d\u6a21\u5f0f\u548c\u6392\u5e8f\u5e8f\u53f7\r\n\r\n        1. \u652f\u6301\u8bbe\u7f6e\u591a\u4e2a\u94fe\u63a5\u5339\u914d\u89c4\u5219\u3002\r\n\r\n        \u53c2\u6570:\r\n            pattern     \u94fe\u63a5\u6b63\u5219\u5339\u914d\r\n            order       \u6392\u5e8f\u5e8f\u53f7\r\n\r\n        \u793a\u4f8b:\r\n            @url(r\"(?i)/(index.html?)?\", 10)\r\n            @url(r\"(?i)/default.html?\", 8)\r\n            class IndexHandler(BaseHandler):\r\n                pass\r\n    \"\"\"\r\n    def actual(handler):\r\n        if not isclass(handler) or not issubclass(handler, BaseHandler):\r\n            raise Exception(\"must be BaseHandler's sub class.\")\r\n\r\n        if not hasattr(handler, \"__urls__\"): handler.__urls__ = []\r\n        handler.__urls__.append((pattern, order))\r\n\r\n        return handler\r\n\r\n    return actual"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_string(self, template_name, **kwargs):\r\n        if hasattr(self, \"session\"): kwargs[\"session\"] = self.session\r\n        return super(BaseHandler, self).render_string(template_name, **kwargs)", "response": "Override render_string to add session to kwargs"}
