{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the current thread or in a separate thread.", "response": "def start(self, as_thread=True):\n    \"\"\"\n    Execute the future in a new thread or in the current thread as specified\n    by the *as_thread* parameter.\n\n    :param as_thread: Execute the future in a new, separate thread. If this\n      is set to :const:`False`, the future will be executed in the calling\n      thread.\n    \"\"\"\n\n    with self._lock:\n      if as_thread:\n        self.enqueue()  # Validate future state\n      if self._cancelled:\n        return\n\n      self._running = True\n      if as_thread:\n        self._thread = threading.Thread(target=self._run)\n        self._thread.start()\n        return self\n\n    self._run()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef result(self, timeout=None, do_raise=True):\n\n    with self._lock:\n      self.wait(timeout, do_raise=do_raise)\n      if self._exc_info:\n        if not do_raise:\n          return None\n        # Its more important to re-raise the exception from the worker.\n        self._exc_retrieved = True\n        reraise(*self._exc_info)\n      if self._cancelled:\n        if not do_raise:\n          return None\n        raise self.Cancelled()\n      return self._result", "response": "Returns the result of the worker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exception(self, timeout=None, do_raise=True):\n\n    with self._lock:\n      self.wait(timeout, do_raise=do_raise)\n      if not self._exc_info:\n        return None\n      self._exc_retrieved = True\n      if self._cancelled:\n        raise self.Cancelled()\n      return self._exc_info[1]", "response": "Returns the exception value by the worker or None."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cancel(self, mark_completed_as_cancelled=False):\n\n    with self._lock:\n      if not self._completed or mark_completed_as_cancelled:\n        self._cancelled = True\n      callbacks = self._prepare_done_callbacks()\n    callbacks()", "response": "Cancels the current task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_result(self, result):\n\n    with self._lock:\n      if self._enqueued:\n        raise RuntimeError('can not set result of enqueued Future')\n      self._result = result\n      self._completed = True\n      callbacks = self._prepare_done_callbacks()\n    callbacks()", "response": "Sets the result of the future."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the exception of the current object in the current node.", "response": "def set_exception(self, exc_info):\n    \"\"\"\n    This method allows you to set an exception in the future without requring\n    that exception to be raised from the futures worker. This method can be\n    called on an unbound future.\n\n    :param exc_info: Either an exception info tuple or an exception value.\n      In the latter case, the traceback will be automatically generated\n      from the parent frame.\n    :raise RuntimeError: If the future is already enqueued.\n    \"\"\"\n\n    if not isinstance(exc_info, tuple):\n      if not isinstance(exc_info, BaseException):\n        raise TypeError('expected BaseException instance')\n      try:\n        # TODO: Filld the traceback so it appears as if the exception\n        #       was actually raised by the caller? (Not sure if possible)\n        raise exc_info\n      except:\n        exc_info = sys.exc_info()\n        exc_info = (exc_info[0], exc_info[1], exc_info[2])\n\n    with self._lock:\n      if self._enqueued:\n        raise RuntimeError('can not set exception of enqueued Future')\n      self._exc_info = exc_info\n      self._completed = True\n      callbacks = self._prepare_done_callbacks()\n    callbacks()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait(self, timeout=None, do_raise=False):\n\n    if timeout is not None:\n      timeout = float(timeout)\n      start = time.clock()\n\n    with self._lock:\n      while not self._completed and not self._cancelled:\n        if timeout is not None:\n          time_left = timeout - (time.clock() - start)\n        else:\n          time_left = None\n        if time_left is not None and time_left <= 0.0:\n          if do_raise:\n            raise self.Timeout()\n          else:\n            return False\n        self._lock.wait(time_left)\n    return True", "response": "Wait for the current thread to complete."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsubmitting a function to the current node and return the future.", "response": "def submit(self, __fun, *args, **kwargs):\n    \"\"\"\n    Creates a new future and enqueues it. Returns the future.\n    \"\"\"\n\n    future = Future().bind(__fun, *args, **kwargs)\n    self.enqueue(future)\n    return future"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cancel(self, cancel_running=True, mark_completed_as_cancelled=False):\n\n    with self._lock:\n      for future in self._queue:\n        future.cancel(mark_completed_as_cancelled)\n      if cancel_running:\n        for future in self._running:\n          future.cancel(mark_completed_as_cancelled)\n      self._queue.clear()", "response": "Cancel all futures in the pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshuts down the pool.", "response": "def shutdown(self, wait=True):\n    \"\"\"\n    Shut down the pool. If *wait* is True, it will wait until all futures\n    are completed. Alternatively, you can use the #wait() method to wait\n    with timeout supported.\n    \"\"\"\n\n    with self._lock:\n      self._shutdown = True\n      self._lock.notify_all()\n    if wait:\n      self.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until all futures are completed.", "response": "def wait(self, timeout=None):\n    \"\"\"\n    Wait until all futures are completed. You should call this method only\n    after calling #shutdown(). Returns #False if all futures are complete,\n    #False if there are still some running.\n    \"\"\"\n\n    tbegin = _get_timeout_begin(timeout)\n    with self._lock:\n      while self._queue or self._running:\n        remainder = _get_timeout_remainder(tbegin, timeout)\n        if remainder is not None and remainder <= 0.0:\n          return False  # timeout\n        self._lock.wait(remainder)\n      if self._shutdown:\n        for worker in self._workers:\n          worker.join()\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of seconds that a function took along with the result", "response": "def timeit(func):\n    \"\"\"\n    Returns the number of seconds that a function took along with the result\n    \"\"\"\n\n    @wraps(func)\n    def timer_wrapper(*args, **kwargs):\n        \"\"\"\n        Inner function that uses the Timer context object\n        \"\"\"\n        with Timer() as timer:\n            result = func(*args, **kwargs)\n\n        return result, timer\n\n    return timer_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef timeout(seconds):\n    def _timeout_error(signal, frame):\n        raise TimeoutError(\"Operation did not finish within \\\n        {} seconds\".format(seconds))\n\n    def timeout_decorator(func):\n\n        @wraps(func)\n        def timeout_wrapper(*args, **kwargs):\n            signal.signal(signal.SIGALRM, _timeout_error)\n            signal.alarm(seconds)\n            try:\n                return func(*args, **kwargs)\n            finally:\n                signal.alarm(0)\n\n        return timeout_wrapper\n\n    return timeout_decorator", "response": "A decorator that can be used to timeout a function within a sequence of time."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new object in the file system.", "response": "def create(location: str, extensions_found: List[str] = None):  # -> NoParserFoundForObject:\n        \"\"\"\n        Helper method provided because we actually can't put that in the constructor, it creates a bug in Nose tests\n        https://github.com/nose-devs/nose/issues/725\n\n        :param location:\n        :param extensions_found:\n        :return:\n        \"\"\"\n        if not extensions_found:\n            return ObjectPresentMultipleTimesOnFileSystemError('Object : ' + location + ' is present multiple '\n                                                               'times on the file system.')\n        else:\n            return ObjectPresentMultipleTimesOnFileSystemError('Object : ' + location + ' is present multiple '\n                                                               'times on the file system , with extensions : ' +\n                                                               str(extensions_found) + '. Only one version of each '\n                                                               'object should be provided. If you need multiple files'\n                                                               ' to create this object, you should create a multifile'\n                                                               ' object instead (with each file having its own name and'\n                                                               ' a shared prefix)')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(location: str, simpleobjects_found = None, complexobject_attributes_found = None):  # -> ObjectNotFoundOnFileSystemError:\n        if len(complexobject_attributes_found) > 0 or len(simpleobjects_found) > 0:\n            return ObjectNotFoundOnFileSystemError('Mandatory object : ' + location + ' could not be found on the file'\n                                                   ' system, either as a multifile or as a singlefile with any '\n                                                   'extension, but it seems that this is because you have left the '\n                                                   'extension in the location name. Please remove the file extension '\n                                                   'from the location name and try again')\n        else:\n            return ObjectNotFoundOnFileSystemError('Mandatory object : ' + location + ' could not be found on the file'\n                                                   ' system, either as a multifile or as a singlefile with any '\n                                                   'extension.')", "response": "Create an object from a location."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_unique_object_contents(self, location: str) -> Tuple[bool, str, Union[str, Dict[str, str]]]:\n\n        # First check what is present on the filesystem according to the filemapping\n        simpleobjects_found = self.find_simpleobject_file_occurrences(location)\n        complexobject_attributes_found = self.find_multifile_object_children(location, no_errors=True)\n\n        # Then handle the various cases\n        if len(simpleobjects_found) > 1 \\\n                or (len(simpleobjects_found) == 1 and len(complexobject_attributes_found) > 0):\n            # the object is present several times > error\n            u = simpleobjects_found\n            u.update(complexobject_attributes_found)\n            raise ObjectPresentMultipleTimesOnFileSystemError.create(location, list(u.keys()))\n\n        elif len(simpleobjects_found) == 1:\n            # a singlefile object > create the output\n            is_single_file = True\n            ext = list(simpleobjects_found.keys())[0]\n            singlefile_object_file_path = simpleobjects_found[ext]\n            return is_single_file, ext, singlefile_object_file_path\n\n        elif len(complexobject_attributes_found) > 0:\n            # a multifile object > create the output\n            is_single_file = False\n            ext = MULTIFILE_EXT\n            if '' in complexobject_attributes_found.keys() or None in complexobject_attributes_found.keys():\n                raise IllegalContentNameError.create(location, complexobject_attributes_found[MULTIFILE_EXT])\n            return is_single_file, ext, complexobject_attributes_found\n\n        else:\n            # handle special case of multifile object with no children (if applicable)\n            if self.is_multifile_object_without_children(location):\n                is_single_file = False\n                ext = MULTIFILE_EXT\n                return is_single_file, ext, dict()\n            else:\n                # try if by any chance the issue is that location has an extension\n                loc_without_ext = splitext(location)[0]\n                simpleobjects_found = self.find_simpleobject_file_occurrences(loc_without_ext)\n                complexobject_attributes_found = self.find_multifile_object_children(loc_without_ext, no_errors=True)\n\n                # the object was not found in a form that can be parsed\n                raise ObjectNotFoundOnFileSystemError.create(location, simpleobjects_found,\n                                                             complexobject_attributes_found)", "response": "Utility method to find a unique object in the file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements classes should return a dictionary of item_name and item_location containing the named elements in this multifile object.", "response": "def find_multifile_object_children(self, parent_location: str, no_errors: bool = False) -> Dict[str, str]:\n        \"\"\"\n        Implementing classes should return a dictionary of <item_name>, <item_location> containing the named elements\n        in this multifile object.\n\n        :param parent_location: the absolute file prefix of the parent item.\n        :return: a dictionary of {item_name : item_prefix}\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_persisted_object(self, location: str, logger: Logger) -> PersistedObject:\n        #print('Checking all files under ' + location)\n        logger.debug('Checking all files under [{loc}]'.format(loc=location))\n        obj = FileMappingConfiguration.RecursivePersistedObject(location=location, file_mapping_conf=self,\n                                                                logger=logger)\n        #print('File checks done')\n        logger.debug('File checks done')\n        return obj", "response": "Creates a PersistedObject representing the object at location recursively creates all of its children\n and returns it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_multifile_object_children(self, parent_location, no_errors: bool = False) -> Dict[str, str]:\n\n        # (1) Assert that folder_path is a folder\n        if not isdir(parent_location):\n            if no_errors:\n                return dict()\n            else:\n                raise ValueError('Cannot find a multifileobject at location \\'' + parent_location + '\\' : location is '\n                                 'not a valid folder')\n\n        else:\n            # (2) List folders (multifile objects or collections)\n            all_subfolders = [dir_ for dir_ in listdir(parent_location) if isdir(join(parent_location, dir_))]\n            items = {item_name: join(parent_location, item_name) for item_name in all_subfolders}\n\n            # (3) List singlefiles *without* their extension\n            items.update({\n                          item_name: join(parent_location, item_name)\n                          for item_name in [file_name[0:file_name.rindex(EXT_SEPARATOR)]\n                                            for file_name in listdir(parent_location)\n                                            if isfile(join(parent_location, file_name))\n                                            and EXT_SEPARATOR in file_name]\n                         })\n        # (4) return all\n        return items", "response": "Find multifile object children."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if an item with this location is present as a multifile object without children.", "response": "def is_multifile_object_without_children(self, location: str) -> bool:\n        \"\"\"\n        Returns True if an item with this location is present as a multifile object without children.\n        For this implementation, this means that there is a folder without any files in it\n\n        :param location:\n        :return:\n        \"\"\"\n        return isdir(location) and len(self.find_multifile_object_children(location)) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_multifile_object_child_location(self, parent_item_prefix: str, child_name: str) -> str:\n        check_var(parent_item_prefix, var_types=str, var_name='parent_item_prefix')\n        check_var(child_name, var_types=str, var_name='item_name')\n\n        # assert that folder_path is a folder\n        if not isdir(parent_item_prefix):\n            raise ValueError(\n                'Cannot get attribute item in non-flat mode, parent item path is not a folder : ' + parent_item_prefix)\n        return join(parent_item_prefix, child_name)", "response": "This method returns the location of the child file in the multifile object folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the multifile object children of the current object.", "response": "def find_multifile_object_children(self, parent_location, no_errors: bool = False) -> Dict[str, str]:\n        \"\"\"\n        Implementation of the parent abstract method.\n\n        In this mode, each item is a set of files with the same prefix than location, separated from the\n        attribute name by the character sequence <self.separator>. The location may also be directly a folder,\n        in which case the sub items dont have a prefix.\n\n        example if location = '<parent_folder>/<file_prefix>'\n\n        parent_folder/\n        |-file_prefix<sep>singlefile_sub_item1.<ext>\n        |-file_prefix<sep>singlefile_sub_item2.<ext>\n        |-file_prefix<sep>multifile_sub_item3<sep>singlesub1.<ext>\n        |-file_prefix<sep>multifile_sub_item3<sep>singlesub2.<ext>\n\n        example if location = '<parent_folder>/\n\n        parent_folder/\n        |-singlefile_sub_item1.<ext>\n        |-singlefile_sub_item2.<ext>\n        |-multifile_sub_item3<sep>singlesub1.<ext>\n        |-multifile_sub_item3<sep>singlesub2.<ext>\n\n        :param parent_location: the absolute file prefix of the parent item. It may be a folder (special case of the\n         root folder) but typically is just a file prefix\n        :param no_errors:\n        :return: a dictionary of <item_name>, <item_path>\n        \"\"\"\n        if parent_location == '':\n            parent_location = '.'\n\n        # (1) Find the base directory and base name\n        if isdir(parent_location):  # special case: parent location is the root folder where all the files are.\n            parent_dir = parent_location\n            base_prefix = ''\n            start_with = ''\n        else:\n            parent_dir = dirname(parent_location)\n            if parent_dir is '':\n                parent_dir = '.'\n            # TODO one day we'll rather want to have a uniform definition of 'location' across filemappings\n            # Indeed as of today, location is not abstract from the file mapping implementation, since we\n            # \"just\" use basename() rather than replacing os separators with our separator:\n            base_prefix = basename(parent_location)  # --> so it should already include self.separator to be valid\n            start_with = self.separator\n\n        # (2) list children files that are singlefiles\n        content_files = [content_file for content_file in listdir(parent_dir)\n                         # -> we are in flat mode : should be a file not a folder :\n                         if isfile(join(parent_dir,content_file))\n                         # -> we are looking for children of a specific item :\n                         and content_file.startswith(base_prefix)\n                         # -> we are looking for multifile child items only :\n                         and content_file != base_prefix\n                         # -> they should start with the separator (or with nothing in case of the root folder) :\n                         and (content_file[len(base_prefix):]).startswith(start_with)\n                         # -> they should have a valid extension :\n                         and (content_file[len(base_prefix + start_with):]).count(EXT_SEPARATOR) >= 1\n                         ]\n        # (3) build the resulting dictionary of item_name > item_prefix\n        item_prefixes = dict()\n        for item_file in content_files:\n            end_name = item_file.find(self.separator, len(base_prefix + start_with))\n            if end_name == -1:\n                end_name = item_file.find(EXT_SEPARATOR, len(base_prefix + start_with))\n            item_name = item_file[len(base_prefix + start_with):end_name]\n            item_prefixes[item_name] = join(parent_dir, base_prefix + start_with + item_name)\n\n        return item_prefixes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if an item with this location is present as a multifile object without children.", "response": "def is_multifile_object_without_children(self, location: str) -> bool:\n        \"\"\"\n        Returns True if an item with this location is present as a multifile object without children.\n        For this implementation, this means that there is a file with the appropriate name but without extension\n\n        :param location:\n        :return:\n        \"\"\"\n        # (1) Find the base directory and base name\n        if isdir(location):  # special case: parent location is the root folder where all the files are.\n            return len(self.find_multifile_object_children(location)) == 0\n        else:\n            # TODO same comment than in find_multifile_object_children\n            if exists(location):\n                # location is a file without extension. We can accept that as being a multifile object without children\n                return True\n            else:\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_multifile_object_child_location(self, parent_location: str, child_name: str):\n        check_var(parent_location, var_types=str, var_name='parent_path')\n        check_var(child_name, var_types=str, var_name='item_name')\n\n        # a child location is built by adding the separator between the child name and the parent location\n        return parent_location + self.separator + child_name", "response": "This method returns the absolute file prefix for the child object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef special_links_replace(text, urls):\n    '''\n    Replace simplified Regulations and Guidelines links into actual links.\n    'urls' dictionary is expected to provide actual links to the targeted\n    Regulations and Guidelines, as well as to the PDF file.\n    '''\n    match_number = r'([A-Za-z0-9]+)' + r'(\\+*)'\n    reference_list = [(r'regulations:article:' + match_number, urls['regulations']),\n                      (r'regulations:regulation:' + match_number, urls['regulations']),\n                      (r'guidelines:article:' + match_number, urls['guidelines']),\n                      (r'guidelines:guideline:' + match_number, urls['guidelines']),\n                     ]\n    anchor_list = [(r'regulations:contents', urls['regulations'] + r'#contents'),\n                   (r'guidelines:contents', urls['guidelines'] + r'#contents'),\n                   (r'regulations:top', urls['regulations'] + r'#'),\n                   (r'guidelines:top', urls['guidelines'] + r'#'),\n                   (r'link:pdf', urls['pdf'] + '.pdf'),\n                  ]\n    retval = text\n    for match, repl in reference_list:\n        retval = re.sub(match, repl + r'#\\1\\2', retval)\n    for match, repl in anchor_list:\n        retval = re.sub(match, repl, retval)\n    return retval", "response": "Replace simplified Regulations and Guidelines links into actual links."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list2html(text):\n    '''\n    Very simple replacement for lists, no nesting, not even two lists in the\n    same 'text'... (yet sufficient for the current regulations)\n    Assumes list is in a paragraph.\n    '''\n    match = r'- (.+)\\n'\n    replace = r'<li>\\1</li>\\n'\n    text = re.sub(match, replace, text)\n    # Set start of list\n    text = text.replace('<li>', '</p><ul><li>', 1)\n    # Set end of list\n    tmp = text.rsplit('</li>', 1)\n    return '</li></ul><p>'.join(tmp)", "response": "Convert a list into an HTML list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns md links to html", "response": "def link2html(text):\n    ''' Turns md links to html '''\n    match = r'\\[([^\\]]+)\\]\\(([^)]+)\\)'\n    replace = r'<a href=\"\\2\">\\1</a>'\n    return re.sub(match, replace, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a text from md to html", "response": "def simple_md2html(text, urls):\n    ''' Convert a text from md to html '''\n    retval = special_links_replace(text, urls)\n    # Create a par break for double newlines\n    retval = re.sub(r'\\n\\n', r'</p><p>', retval)\n    # Create a visual br for every new line\n    retval = re.sub(r'\\n', r'<br />\\n', retval)\n    # Do we really need this ? Help reduce the diff to only '\\n' diff.\n    retval = re.sub(r'\"', r'&quot;', retval)\n    retval = list2html(retval)\n    return link2html(retval)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_ul(self, a_list):\n        ''' Determines if we should generate th 'ul' around the list 'a_list' '''\n        return len(a_list) > 0 and (isinstance(a_list[0], Rule) or\n                                    isinstance(a_list[0], LabelDecl))", "response": "Determines if we should generate th ul around the list a_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts version information as a dictionary from version. py.", "response": "def get_version_info():\n    \"\"\"Extract version information as a dictionary from version.py.\"\"\"\n    version_info = {}\n    with open(os.path.join(\"refcycle\", \"version.py\"), 'r') as f:\n        version_code = compile(f.read(), \"version.py\", 'exec')\n        exec(version_code, version_info)\n    return version_info"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef div_filter(key: str, value: list, format: str, meta: Any) -> Optional[list]:\n    if key != \"Div\" or format != \"latex\":\n        return None\n\n    [[_, classes, _], contents] = value\n    try:\n        alert_type = [name.split(\"-\")[1] for name in classes if \"-\" in name][0]\n    except IndexError:\n        return None\n\n    if alert_type not in ALLOWED_ALERT_TYPES.__members__:\n        return None\n\n    filtered = [RawBlock(\"latex\", rf\"\\begin{{{alert_type}box}}\")]\n    filtered.extend(contents)\n    filtered.append(RawBlock(\"latex\", rf\"\\end{{{alert_type}box}}\"))\n    return filtered", "response": "Filter the JSON value for alert divs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_div(text: str, format: Optional[str] = None) -> \"applyJSONFilters\":\n    return applyJSONFilters([div_filter], text, format=format)", "response": "Apply the dev_filter action to the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw_html_filter(key: str, value: list, format: str, meta: Any) -> Optional[list]:\n    if key == \"RawInline\" and format == \"latex\" and value[0] == \"html\":\n        if value[1] == \"<sup>\":\n            filtered = [RawInline(\"latex\", r\"\\textsuperscript{\")]\n        elif value[1] == \"</sup>\":\n            filtered = [RawInline(\"latex\", \"}\")]\n        elif value[1] == \"<sub>\":\n            filtered = [RawInline(\"latex\", r\"\\textsubscript{\")]\n        elif value[1] == \"</sub>\":\n            filtered = [RawInline(\"latex\", \"}\")]\n        else:\n            return None\n        return filtered\n\n    return None", "response": "Filter the JSON value for raw html to convert to LaTeX."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the raw_html_filter action to the text.", "response": "def convert_raw_html(text: str, format: Optional[str] = None) -> \"applyJSONFilters\":\n    \"\"\"Apply the `raw_html_filter` action to the text.\"\"\"\n    return applyJSONFilters([raw_html_filter], text, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, element):\n        key = self._transform(element)\n        if key not in self._elements:\n            self._elements[key] = element", "response": "Add an element to this set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discard(self, element):\n        key = self._transform(element)\n        if key in self._elements:\n            del self._elements[key]", "response": "Remove an element from the set. Do not raise an exception if absent."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_items_to_message(msg, log_dict):\n    out = msg\n    for key, value in log_dict.items():\n        out += \" {}={}\".format(key, value)\n    return out", "response": "Utility function to add dictionary items to a log message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndumps all recorded metrics", "response": "def dump(cls):\n        \"\"\"Output all recorded metrics\"\"\"\n        with cls.lock:\n            if not cls.instances: return\n            atexit.unregister(cls.dump)\n\n            for self in cls.instances.values():\n                self.fh.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef metric(self, name, count, elapsed):\n\n        if name is None:\n            warnings.warn(\"Ignoring unnamed metric\", stacklevel=3)\n            return\n\n        with self.lock:\n            self.writer.writerow((name, count, \"%f\"%elapsed))", "response": "A metric function that writes a single CSV file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting all recorded metrics", "response": "def dump(self):\n        \"\"\"Output all recorded metrics\"\"\"\n        with self.lock:\n            atexit.unregister(self.dump)\n            self.fh.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(parts):\n    cur_dir = os.path.abspath(os.path.dirname(__file__))\n    with codecs.open(os.path.join(cur_dir, *parts), \"rb\", \"utf-8\") as f:\n        return f.read()", "response": "Read the contents of a\n    file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_meta(meta):\n    meta_match = re.search(\n        r\"^__{meta}__ = ['\\\"]([^'\\\"]*)['\\\"]\".format(meta=meta),\n        META_FILE, re.M\n    )\n    if meta_match:\n        return meta_match.group(1)\n    raise RuntimeError(\"Unable to find __{meta}__ string.\".format(meta=meta))", "response": "Find the first __meta__ string in the META_FILE."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_clean_git(operation='operation'):\n    if os.system('git diff-index --quiet HEAD --'):\n        print(\"Unstaged or uncommitted changes detected. {} aborted.\".format(\n            operation.capitalize()))\n        sys.exit()", "response": "Verify that git has no uncommitted changes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self):\n        if self._defaults_file is not None:\n            if not os.path.exists(self._defaults_file):\n                msg = \"Unable to find defaults file: {}\".format(self._defaults_file)\n                LOGGER.error(msg)\n                raise RuntimeError(msg)\n            with open(self._defaults_file, 'r') as handle:\n                self._defaults = json.load(handle)\n                self.update(self._defaults)\n\n        if self._settings_file is None:\n            msg = \"No context file has been provided\"\n            LOGGER.error(msg)\n            raise RuntimeError(msg)\n        if not os.path.exists(self._settings_file):\n            msg = \"Unable to find settings file: {}\".format(self._settings_file)\n            LOGGER.error(msg)\n            raise RuntimeError(msg)\n        with open(self._settings_file, 'r') as handle:\n            settings = json.load(handle)\n            update(self, settings)\n\n        return", "response": "Load the defaults and settings file if specified and overlay the json file on top of that."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that a variable is in the list of types and returns a new object.", "response": "def check_var(var, var_types:Union[type, List[type]] =None, var_name=None, enforce_not_none:bool = True,\n              allowed_values:Set = None, min_value = None, min_strict:bool = False,\n              max_value = None, max_strict:bool = False, min_len:int = None, min_len_strict:bool = False,\n              max_len:int = None, max_len_strict:bool = False):\n    \"\"\"\n    Helper method to check that an object has certain properties:\n    * not none\n    * a certain type\n    * in some accepted values\n    * in some accepted range\n\n    :param var: the object to check\n    :param var_types: the type(s) to enforce. If None, type will not be enforced\n    :param var_name: the name of the varioable to be used in error messages\n    :param enforce_not_none: boolean, default True. Whether to enforce that var is not None.\n    :param allowed_values: an optional set of allowed values\n    :param min_value: an optional minimum value\n    :param min_strict: if True, only values strictly greater than the minimum value will be accepted\n    :param max_value: an optional maximum value\n    :param max_strict: if True, only values strictly lesser than the minimum value will be accepted\n    :return:\n    \"\"\"\n\n    var_name = var_name or 'object'\n\n    if enforce_not_none and (var is None):\n        # enforce not none\n        raise MissingMandatoryParameterException('Error, ' + var_name + '\" is mandatory, it should be non-None')\n\n    if not (var is None) and not (var_types is None):\n        # enforce type\n        if not isinstance(var_types, list):\n            var_types = [var_types]\n\n        match = False\n        for var_type in var_types:\n            # just in case, even though users should use FunctionType or MethodType which is the true type\n            if var_type is Callable:\n                if callable(var):\n                    match = True\n                    break\n            else:\n                if isinstance(var, var_type):\n                    match = True\n                    break\n\n        if not match:\n            raise TypeError('Error, ' + var_name + '\" should be one of type(s) ' + str(var_types) + ', found: ' + str(type(var)))\n\n    if var is not None:\n        if allowed_values is not None:\n            # enforce allowed values\n            if var not in allowed_values:\n                raise TypeError('Error, ' + var_name + '\" should be one of \"' + str(allowed_values) + '\", found: ' + str(var))\n\n        if min_value is not None:\n            # enforce min value\n            if min_strict:\n                if not (var > min_value):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" should be strictly greater than \"' + str(min_value) + '\", found: ' + str(var))\n            else:\n                if not (var >= min_value):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" should be greater than \"' + str(min_value) + '\", found: ' + str(var))\n\n        if max_value is not None:\n            # enforce max value\n            if max_strict:\n                if not (var < max_value):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" should be strictly lesser than \"' + str(max_value) + '\", found: ' + str(var))\n            else:\n                if not (var <= max_value):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" should be lesser than \"' + str(max_value) + '\", found: ' + str(var))\n\n        if min_len is not None:\n            # enforce min length\n            if min_len_strict:\n                if not (len(var) > min_len):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" length should be strictly greater than \"' + str(min_len) + '\", found: ' + str(len(var)))\n            else:\n                if not (len(var) >= min_len):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" length should be greater than \"' + str(min_len) + '\", found: ' + str(len(var)))\n\n        if max_len is not None:\n            # enforce max length\n            if max_len_strict:\n                if not (len(var) < max_len):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" length should be strictly lesser than \"' + str(max_len) + '\", found: ' + str(len(var)))\n            else:\n                if not (len(var) <= max_len):\n                    raise TypeError(\n                        'Error, ' + var_name + '\" length should be lesser than \"' + str(max_len) + '\", found: ' + str(len(var)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if an object obj has a callable method meth", "response": "def hasmethod(obj, meth):\n  \"\"\"\n    Checks if an object, obj, has a callable method, meth\n    \n    return True or False\n  \"\"\"\n  if hasattr(obj, meth):\n    return callable(getattr(obj,meth))\n  return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if object obj has a variable var", "response": "def hasvar(obj, var):\n  \"\"\"\n    Checks if object, obj has a variable var\n    \n    return True or False\n  \"\"\"\n  if hasattr(obj, var):\n    return not callable(getattr(obj, var))\n  return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getmethattr(obj, meth):\n  if hasmethod(obj, meth):\n    return getattr(obj, meth)()\n  elif hasvar(obj, meth):\n    return getattr(obj, meth)\n  return None", "response": "Returns either the variable value or the method invocation\n"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassure the object has the specified child dict", "response": "def assure_obj_child_dict(obj, var):\n  \"\"\"Assure the object has the specified child dict\n  \"\"\"\n  if not var in obj or type(obj[var]) != type({}):\n    obj[var] = {}\n  return obj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_required(f):\n\n    @wraps(f)\n    def wrapped(self, *args, **kwargs):\n        if self.directory.new:\n            raise SprinterException(\"Namespace %s is not yet installed!\" % self.namespace)\n        return f(self, *args, **kwargs)\n    return wrapped", "response": "Decorator that ensures that the namespace is not already installed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the target environment", "response": "def validate(self):\n        \"\"\" Validate the target environment \"\"\"\n        self.phase = PHASE.VALIDATE\n        self.logger.info(\"Validating %s...\" % self.namespace)\n        self.instantiate_features()\n        context_dict = {}\n        if self.target:\n            for s in self.target.formula_sections():\n                context_dict[\"%s:root_dir\" % s] = self.directory.install_directory(s)\n                context_dict['config:root_dir'] = self.directory.root_dir\n                context_dict['config:node'] = system.NODE\n                self.target.add_additional_context(context_dict)\n        for feature in self.features.run_order:\n            self.run_action(feature, 'validate', run_if_error=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear all injected files", "response": "def clear_all(self):\n        \"\"\" clear all files that were to be injected \"\"\"\n        self.injections.clear_all()\n        for config_file in CONFIG_FILES:\n            self.injections.clear(os.path.join(\"~\", config_file))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the debug log to a file", "response": "def write_debug_log(self, file_path):\n        \"\"\" Write the debug log to a file \"\"\"\n        with open(file_path, \"wb+\") as fh:\n            fh.write(system.get_system_info().encode('utf-8'))\n            # writing to debug stream\n            self._debug_stream.seek(0)\n            fh.write(self._debug_stream.read().encode('utf-8'))\n            fh.write(\"The following errors occured:\\n\".encode('utf-8'))\n            for error in self._errors:\n                fh.write((error + \"\\n\").encode('utf-8'))\n            for k, v in self._error_dict.items():\n                if len(v) > 0:\n                    fh.write((\"Error(s) in %s with formula %s:\\n\" % k).encode('utf-8'))\n                    for error in v:\n                        fh.write((error + \"\\n\").encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_manifest(self):\n        if os.path.exists(self.directory.manifest_path):\n            self.main_manifest.write(open(self.directory.manifest_path, \"w+\"))", "response": "Write the manifest to the file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef message_failure(self):\n        if not isinstance(self.main_manifest, Manifest):\n            return None\n        return self.main_manifest.get('config', 'message_failure', default=None)", "response": "return a failure message if one exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef warmup(self):\n        self.logger.debug(\"Warming up...\")\n\n        try:\n            if not isinstance(self.source, Manifest) and self.source:\n                self.source = load_manifest(self.source)\n            if not isinstance(self.target, Manifest) and self.target:\n                self.target = load_manifest(self.target)\n            self.main_manifest = self.target or self.source\n        except lib.BadCredentialsException:\n            e = sys.exc_info()[1]\n            self.logger.error(str(e))\n            raise SprinterException(\"Fatal error! Bad credentials to grab manifest!\")\n\n        if not getattr(self, 'namespace', None):\n            if self.target:\n                self.namespace = self.target.namespace\n            elif not self.namespace and self.source:\n                self.namespace = self.source.namespace\n            else:\n                raise SprinterException(\"No environment name has been specified!\")\n\n        self.directory_root = self.custom_directory_root\n\n        if not self.directory:\n            if not self.directory_root:\n                self.directory_root = os.path.join(self.root, self.namespace)\n\n            self.directory = Directory(self.directory_root,\n                                       shell_util_path=self.shell_util_path)\n\n        if not self.injections:\n            self.injections = Injections(wrapper=\"%s_%s\" % (self.sprinter_namespace.upper(),\n                                                            self.namespace),\n                                         override=\"SPRINTER_OVERRIDES\")\n        if not self.global_injections:\n            self.global_injections = Injections(wrapper=\"%s\" % self.sprinter_namespace.upper() + \"GLOBALS\",\n                                                override=\"SPRINTER_OVERRIDES\")\n        # append the bin, in the case sandboxes are necessary to\n        # execute commands further down the sprinter lifecycle\n        os.environ['PATH'] = self.directory.bin_path() + \":\" + os.environ['PATH']\n        self.warmed_up = True", "response": "This method will be called by the sprinter to warm up the sprinter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninject existing environmental config with namespace sourcing.", "response": "def _inject_config_source(self, source_filename, files_to_inject):\n        \"\"\"\n        Inject existing environmental config with namespace sourcing.\n        Returns a tuple of the first file name and path found.\n        \"\"\"\n        # src_path = os.path.join(self.directory.root_dir, source_filename)\n        # src_exec = \"[ -r %s ] && . %s\" % (src_path, src_path)\n        src_exec = \"[ -r {0} ] && . {0}\".format(os.path.join(self.directory.root_dir, source_filename))\n        # The ridiculous construction above is necessary to avoid failing tests(!)\n\n        for config_file in files_to_inject:\n            config_path = os.path.expanduser(os.path.join(\"~\", config_file))\n            if os.path.exists(config_path):\n                self.injections.inject(config_path, src_exec)\n                break\n        else:\n            config_file = files_to_inject[0]\n            config_path = os.path.expanduser(os.path.join(\"~\", config_file))\n            self.logger.info(\"No config files found to source %s, creating ~/%s!\" % (source_filename, config_file))\n            self.injections.inject(config_path, src_exec)\n\n        return (config_file, config_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinalizing the sprinter instance.", "response": "def _finalize(self):\n        \"\"\" command to run at the end of sprinter's run \"\"\"\n        self.logger.info(\"Finalizing...\")\n        self.write_manifest()\n\n        if self.directory.rewrite_config:\n            # always ensure .rc is written (sourcing .env)\n            self.directory.add_to_rc('')\n            # prepend brew for global installs\n            if system.is_osx() and self.main_manifest.is_affirmative('config', 'use_global_packagemanagers'):\n                self.directory.add_to_env('__sprinter_prepend_path \"%s\" PATH' % '/usr/local/bin')\n            self.directory.add_to_env('__sprinter_prepend_path \"%s\" PATH' % self.directory.bin_path())\n            self.directory.add_to_env('__sprinter_prepend_path \"%s\" LIBRARY_PATH' % self.directory.lib_path())\n            self.directory.add_to_env('__sprinter_prepend_path \"%s\" C_INCLUDE_PATH' % self.directory.include_path())\n            self.directory.finalize()\n\n        self.injections.commit()\n        self.global_injections.commit()\n\n        if not os.path.exists(os.path.join(self.root, \".global\")):\n            self.logger.debug(\"Global directory doesn't exist! creating...\")\n            os.makedirs(os.path.join(self.root, \".global\"))\n\n        self.logger.debug(\"Writing shell util file...\")\n        with open(self.shell_util_path, 'w+') as fh:\n            fh.write(shell_utils_template)\n\n        if self.error_occured:\n            raise SprinterException(\"Error occured!\")\n\n        if self.message_success():\n            self.logger.info(self.message_success())\n\n        self.logger.info(\"Done!\")\n        self.logger.info(\"NOTE: Please remember to open new shells/terminals to use the modified environment\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_logger(self, level=logging.INFO):\n        self._debug_stream = StringIO()\n        logger = logging.getLogger('sprinter')\n        # stdout log\n        out_hdlr = logging.StreamHandler(sys.stdout)\n        out_hdlr.setLevel(level)\n        logger.addHandler(out_hdlr)\n        # debug log\n        debug_hdlr = logging.StreamHandler(self._debug_stream)\n        debug_hdlr.setFormatter(logging.Formatter('%(asctime)s %(message)s'))\n        debug_hdlr.setLevel(logging.DEBUG)\n        logger.addHandler(debug_hdlr)\n        logger.setLevel(logging.DEBUG)\n        return logger", "response": "return a logger. if logger is none, generate a logger from stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_action(self, feature, action,\n                   run_if_error=False,\n                   raise_exception=True):\n        \"\"\" Run an action, and log it's output in case of errors \"\"\"\n        if len(self._error_dict[feature]) > 0 and not run_if_error:\n            return\n\n        error = None\n        instance = self.features[feature]\n        try:\n            getattr(instance, action)()\n        # catch a generic exception within a feature\n        except Exception as e:\n            e = sys.exc_info()[1]\n            self.logger.info(\"An exception occurred with action %s in feature %s!\" %\n                             (action, feature))\n            self.logger.debug(\"Exception\", exc_info=sys.exc_info())\n            error = str(e)\n            self.log_feature_error(feature, str(e))\n        # any error in a feature should fail immediately - unless it occurred\n        # from the remove() method in which case continue the rest of the\n        # feature removal from there\n        if error is not None and raise_exception:\n            exception_msg = \"%s action failed for feature %s: %s\" % (action, feature, error)\n            if self.phase == PHASE.REMOVE:\n                raise FormulaException(exception_msg)\n            else:\n                raise SprinterException(exception_msg)\n        return error", "response": "Run an action on the specified feature and return the error message if run_if_error is True."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _specialize(self, reconfigure=False):\n        # add in the 'root_dir' directories to the context dictionaries\n        for manifest in [self.source, self.target]:\n            context_dict = {}\n            if manifest:\n                for s in manifest.formula_sections():\n                    context_dict[\"%s:root_dir\" % s] = self.directory.install_directory(s)\n                    context_dict['config:root_dir'] = self.directory.root_dir\n                    context_dict['config:node'] = system.NODE\n                manifest.add_additional_context(context_dict)\n        self._validate_manifest()\n        for feature in self.features.run_order:\n            if not reconfigure:\n                self.run_action(feature, 'resolve')\n            # if a target doesn't exist, no need to prompt.\n            instance = self.features[feature]\n            if instance.target:\n                self.run_action(feature, 'prompt')", "response": "Add variables and specialize contexts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy source user configuration to target user configuration", "response": "def _copy_source_to_target(self):\n        \"\"\" copy source user configuration to target \"\"\"\n        if self.source and self.target:\n            for k, v in self.source.items('config'):\n                # always have source override target.\n                self.target.set_input(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngrabs the sources and target sources", "response": "def grab_inputs(self, reconfigure=False):\n        \"\"\" Resolve the source and target config section \"\"\"\n        self._copy_source_to_target()\n        if self.target:\n            self.target.grab_inputs(force=reconfigure)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to a vCenter via the API and returns a Content getTerminal object.", "response": "def connect(host, username, password, port=443, verify=False, debug=False):\n    '''\n    Connect to a vCenter via the API\n    :param host: Hostname or IP of the vCenter\n    :type host: str or unicode\n    :param username: Username\n    :type user: str or unicode\n    :param password: Password\n    :type user: str or unicode\n    :param port: Port on which the vCenter API is running (default: 443)\n    :type port: int\n    :param verify: Whether to verify SSL certs upon connection (default: False)\n    :type verify: bool\n    :param debug: Debug option (default: False)\n    :type debug: bool\n    :return: Content\n    :rtype: vim.ServiceInstanceContent\n    '''\n    context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n    if not verify:\n        # Disable warnings about unsigned certificates\n        context.verify_mode = ssl.CERT_NONE\n        requests.packages.urllib3.disable_warnings()\n\n    try:\n        si = SmartConnect(\n            host=host,\n            user=username,\n            pwd=password,\n            port=port,\n            sslContext=context\n        )\n        # Register auto disconnect\n        atexit.register(Disconnect, si)\n        # Return content\n        return si.RetrieveContent()\n    except IOError as e:\n        print('I/O error({0}): {1}'.format(e.errno, e.strerror))\n    except vmodl.MethodFault as e:\n        print('Connection could not be established', file=sys.stderr)\n        raise ConnectionError('Connection could not be established')\n        print('Caught vmodl fault: ', e.msg, file=sys.stderr)\n        if debug:\n            traceback.print_exc()\n    except Exception as e:\n        print('Caught exception:', str(e), file=sys.stderr)\n        if debug:\n            traceback.print_exc()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(ignore_file='.gitignore', git_dir='.git', additional_files=(),\n          global_=True, root_dir=None, defaults=True):\n  \"\"\"\n  Collects a list of all ignore patterns configured in a local Git repository\n  as specified in the Git documentation. See\n  https://git-scm.com/docs/gitignore#_description\n\n  The returned #IgnoreListCollection is guaranteed to contain at least one\n  #IgnoreList with #IgnoreList.root pointing to the specified *root_dir* (which\n  defaults to the parent directory of *git_dir*) as the first element.\n  \"\"\"\n\n  result = IgnoreListCollection()\n\n  if root_dir is None:\n    if git_dir is None:\n      raise ValueError(\"root_dir or git_dir must be specified\")\n    root_dir = os.path.dirname(os.path.abspath(git_dir))\n\n  def parse(filename, root=None):\n    if os.path.isfile(filename):\n      if root is None:\n        root = os.path.dirname(os.path.abspath(filename))\n      with open(filename) as fp:\n        result.parse(fp, root)\n\n  result.append(IgnoreList(root_dir))\n  if ignore_file is not None:\n    parse(ignore_file)\n  for filename in additional_files:\n    parse(filename)\n  if git_dir is not None:\n    parse(os.path.join(git_dir, 'info', 'exclude'), root_dir)\n  if global_:\n    # TODO: Read the core.excludeFiles configuration value.\n    parse(os.path.expanduser('~/.gitignore'), root_dir)\n  if defaults:\n    result.append(get_defaults(root_dir))\n  return result", "response": "Returns a list of all ignore patterns configured in a local Git repository."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef walk(patterns, dirname):\n\n  join = os.path.join\n  for root, dirs, files in os.walk(dirname, topdown=True):\n    dirs[:] = [d for d in dirs if patterns.match(join(root, d), True) != MATCH_IGNORE]\n    files[:] = [f for f in files if patterns.match(join(root, f), False) != MATCH_IGNORE]\n    yield root, dirs, files", "response": "A generator that iterates over the directory tree and returns a list of files and directories that match the given patterns."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the. gitignore file represented by the lines.", "response": "def parse(self, lines):\n    \"\"\"\n    Parses the `.gitignore` file represented by the *lines*.\n    \"\"\"\n\n    if isinstance(lines, str):\n      lines = lines.split('\\n')\n    sub = _re.sub\n    for line in lines:\n      if line.endswith('\\n'):\n        line = line[:-1]\n      line = line.lstrip()\n      if not line.startswith('#'):\n        invert = False\n        if line.startswith('!'):\n          line = line[1:]\n          invert = True\n        while line.endswith(' ') and line[-2:] != '\\ ':\n          line = line[:-1]\n        line = sub(r'\\\\([!# ])', r'\\1', line)\n        if '/' in line and not line.startswith('/'):\n          # Patterns with a slash can only be matched absolute.\n          line = '/' + line\n        self.patterns.append(Pattern(line, invert))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmatches the specified filename.", "response": "def match(self, filename, isdir):\n    \"\"\"\n    Match the specified *filename*. If *isdir* is False, directory-only\n    patterns will be ignored.\n\n    Returns one of\n\n    - #MATCH_DEFAULT\n    - #MATCH_IGNORE\n    - #MATCH_INCLUDE\n    \"\"\"\n\n    fnmatch = _fnmatch.fnmatch\n    ignored = False\n    filename = self.convert_path(filename)\n    basename = os.path.basename(filename)\n\n    for pattern in self.patterns:\n      if pattern.dir_only and not isdir:\n        continue\n      if (not ignored or pattern.invert) and pattern.match(filename):\n        if pattern.invert: # This file is definitely NOT ignored, no matter what other patterns match\n          return MATCH_INCLUDE\n        ignored = True\n    if ignored:\n      return MATCH_IGNORE\n    else:\n      return MATCH_DEFAULT"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, lines, root):\n\n    lst = IgnoreList(root)\n    lst.parse(lines)\n    self.append(lst)", "response": "Parses the given lines into the current list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match(self, filename, isdir=False):\n\n    for lst in self:\n      result = lst.match(filename, isdir)\n      if result != MATCH_DEFAULT:\n        return result\n    return MATCH_DEFAULT", "response": "Match all the ignore list s in this collection. Returns the first element that matches filename."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reply(self,message,message_type):\n        if message_type == MULTIPART:\n            raise Exception(\"Unsupported reply type\")\n            \n        super(Replier,self).send(message,message_type)", "response": "Send a reply message of the given type"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_domain(url):\n    domain_match = lib.DOMAIN_REGEX.match(url)\n    if domain_match:\n        return domain_match.group()", "response": "parse the domain from the url"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget credentials or prompt for them from options", "response": "def get_credentials(options, environment):\n    \"\"\" Get credentials or prompt for them from options \"\"\"\n    if options['--username'] or options['--auth']:\n        if not options['--username']:\n            options['<username>'] = lib.prompt(\"Please enter the username for %s...\" % environment)\n        if not options['--password']:\n            options['<password>'] = lib.prompt(\"Please enter the password for %s...\" % environment, secret=True)\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_type(self, value):\n\n    if self.null and value is None:\n      return\n    if self.type is not None and not isinstance(value, self.type):\n      msg = '{0!r} expected type {1}'\n      raise TypeError(msg.format(self.full_name, self.type.__name__))", "response": "Checks that the value is an instance of the field s type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default(self):\n\n    if self.default is not NotImplemented:\n      return self.default\n    elif self.default_factory is not None:\n      return self.default_factory()\n    else:\n      raise RuntimeError('{0!r} has no default value'.format(self.full_name))", "response": "Returns the default value of the field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef full_name(self):\n\n    entity = self.entity.__name__ if self.entity is not None else None\n    name = self.name if self.name is not None else None\n    if entity and name:\n      return entity + '.' + name\n    elif entity:\n      return entity + '.<unnamed>'\n    elif name:\n      return '<unbound>.' + name\n    else:\n      return '<unbound>.<unnamed>'", "response": "Returns the full name of the field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the full type identifier of the field.", "response": "def type_name(self):\n    \"\"\"\n    Returns the full type identifier of the field.\n    \"\"\"\n\n    res = self.type.__name__\n    if self.type.__module__ not in ('__builtin__', 'builtins'):\n      res = self.type.__module__ + '.' + res\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_subclass_from_module(module, parent_class):\n    try:\n        r = __recursive_import(module)\n        member_dict = dict(inspect.getmembers(r))\n        sprinter_class = parent_class\n        for v in member_dict.values():\n            if inspect.isclass(v) and issubclass(v, parent_class) and v != parent_class:\n                if sprinter_class is parent_class:\n                    sprinter_class = v\n        if sprinter_class is None:\n            raise SprinterException(\"No subclass %s that extends %s exists in classpath!\" % (module, str(parent_class)))\n        return sprinter_class\n    except ImportError:\n        e = sys.exc_info()[1]\n        raise e", "response": "Get a subclass of parent_class from the module at module\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __recursive_import(module_name):\n    names = module_name.split(\".\")\n    path = None\n    module = None\n    while len(names) > 0:\n        if module:\n            path = module.__path__\n        name = names.pop(0)\n        (module_file, pathname, description) = imp.find_module(name, path)\n        module = imp.load_module(name, module_file, pathname, description)\n    return module", "response": "Recursively imports the module_name and returns the module that is required by the module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef err_exit(msg, rc=1):\n    print(msg, file=sys.stderr)\n    sys.exit(rc)", "response": "Print msg to stderr and exit with rc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef popen(self, cmd):\n        process = Popen(cmd, shell=True, stdout=PIPE, env=self.env)\n        stdoutdata, stderrdata = process.communicate()\n        return process.returncode, stdoutdata", "response": "Execute an external command and return the return code and stdoutdata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a reST file into a string.", "response": "def read_file(self, infile):\n        \"\"\"Read a reST file into a string.\n        \"\"\"\n        try:\n            with open(infile, 'rt') as file:\n                return file.read()\n        except UnicodeDecodeError as e:\n            err_exit('Error reading %s: %s' % (infile, e))\n        except (IOError, OSError) as e:\n            err_exit('Error reading %s: %s' % (infile, e.strerror or e))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_file(self, html, outfile):\n        try:\n            with open(outfile, 'wt') as file:\n                file.write(html)\n        except (IOError, OSError) as e:\n            err_exit('Error writing %s: %s' % (outfile, e.strerror or e))", "response": "Write an HTML string to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_string(self, rest):\n        try:\n            html = publish_string(rest, writer_name='html')\n        except SystemExit as e:\n            err_exit('HTML conversion failed with error: %s' % e.code)\n        else:\n            if sys.version_info[0] >= 3:\n                return html.decode('utf-8')\n            return html", "response": "Convert a reST string to an HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert style information into the HTML string.", "response": "def apply_styles(self, html, styles):\n        \"\"\"Insert style information into the HTML string.\n        \"\"\"\n        index = html.find('</head>')\n        if index >= 0:\n            return ''.join((html[:index], styles, html[index:]))\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders a reST string as HTML.", "response": "def publish_string(self, rest, outfile, styles=''):\n        \"\"\"Render a reST string as HTML.\n        \"\"\"\n        html = self.convert_string(rest)\n        html = self.strip_xml_header(html)\n        html = self.apply_styles(html, styles)\n        self.write_file(html, outfile)\n        return outfile"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef publish_file(self, infile, outfile, styles=''):\n        rest = self.read_file(infile)\n        return self.publish_string(rest, outfile, styles)", "response": "Render a reST file as HTML."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupgrade the config file.", "response": "def upgrade(self):\n        \"\"\"Upgrade the config file.\n        \"\"\"\n        warn('Upgrading ' + self.filename)\n        if self.backup_config(self.filename):\n            return self.write_default_config(self.filename)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_default_config(self, filename):\n        try:\n            with open(filename, 'wt') as file:\n                file.write(DEFAULT_CONFIG)\n            return True\n        except (IOError, OSError) as e:\n            print('Error writing %s: %s' % (filename, e.strerror or e), file=sys.stderr)\n            return False", "response": "Write the default config file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset_defaults(self, config_file):\n        if not exists(config_file):\n            err_exit('No such file: %(config_file)s' % locals())\n        if not isfile(config_file):\n            err_exit('Not a file: %(config_file)s' % locals())\n        if not os.access(config_file, os.R_OK):\n            err_exit('File cannot be read: %(config_file)s' % locals())\n        self.set_defaults(config_file)", "response": "Reset the defaults for the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_defaults(self):\n        self.defaults.write()\n        self.reset_defaults(self.defaults.filename)", "response": "Create default config file and reload."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upgrade_defaults(self):\n        self.defaults.upgrade()\n        self.reset_defaults(self.defaults.filename)", "response": "Upgrade config file and reload."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_options(self, args, depth=0):\n        style_names = tuple(self.defaults.known_styles)\n        style_opts = tuple('--'+x for x in style_names)\n\n        try:\n            options, remaining_args = getopt.gnu_getopt(args, 'b:c:hls:v',\n                ('help', 'style=', 'version', 'list-styles', 'browser=',\n                 'config-file=') + style_names)\n        except getopt.GetoptError as e:\n            err_exit('viewdoc: %s\\n%s' % (e.msg, USAGE))\n\n        for name, value in options:\n            if name in ('-s', '--style'):\n                self.styles = self.defaults.known_styles.get(value, '')\n            elif name in style_opts:\n                self.styles = self.defaults.known_styles.get(name[2:], '')\n            elif name in ('-b', '--browser'):\n                self.browser = value\n            elif name in ('-l', '--list-styles'):\n                self.list = True\n            elif name in ('-h', '--help'):\n                msg_exit(HELP)\n            elif name in ('-v', '--version'):\n                msg_exit(VERSION)\n            elif name in ('-c', '--config-file') and depth == 0:\n                self.reset_defaults(expanduser(value))\n                return self.parse_options(args, depth+1)\n\n        if len(remaining_args) > 1:\n            err_exit('viewdoc: too many arguments\\n%s' % USAGE)\n\n        if not isfile(self.defaults.filename) and depth == 0:\n            self.write_defaults()\n            return self.parse_options(args, depth+1)\n\n        if self.defaults.version < CONFIG_VERSION and depth == 0:\n            self.upgrade_defaults()\n            return self.parse_options(args, depth+1)\n\n        if self.list:\n            self.list_styles()\n\n        return remaining_args", "response": "Parse command line options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint available styles and exit.", "response": "def list_styles(self):\n        \"\"\"Print available styles and exit.\n        \"\"\"\n        known = sorted(self.defaults.known_styles)\n        if not known:\n            err_exit('No styles', 0)\n        for style in known:\n            if style == self.defaults.default_style:\n                print(style, '(default)')\n            else:\n                print(style)\n        sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a reST file to HTML.", "response": "def render_file(self, filename):\n        \"\"\"Convert a reST file to HTML.\n        \"\"\"\n        dirname, basename = split(filename)\n        with changedir(dirname):\n            infile = abspath(basename)\n            outfile = abspath('.%s.html' % basename)\n            self.docutils.publish_file(infile, outfile, self.styles)\n            return outfile"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_long_description(self, dirname):\n        with changedir(dirname):\n            self.setuptools.check_valid_package()\n            long_description = self.setuptools.get_long_description()\n            outfile = abspath('.long-description.html')\n            self.docutils.publish_string(long_description, outfile, self.styles)\n            return outfile", "response": "Convert a package s long description to HTML."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen the given HTML file in a browser.", "response": "def open_in_browser(self, outfile):\n        \"\"\"Open the given HTML file in a browser.\n        \"\"\"\n        if self.browser == 'default':\n            webbrowser.open('file://%s' % outfile)\n        else:\n            browser = webbrowser.get(self.browser)\n            browser.open('file://%s' % outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        os.environ['JARN_RUN'] = '1'\n        self.python.check_valid_python()\n\n        args = self.parse_options(self.args)\n        if args:\n            arg = args[0]\n        else:\n            arg = os.curdir\n        if arg:\n            arg = expanduser(arg)\n\n        if isfile(arg):\n            outfile = self.render_file(arg)\n        elif isdir(arg):\n            outfile = self.render_long_description(arg)\n        else:\n            err_exit('No such file or directory: %s' % arg)\n\n        self.open_in_browser(outfile)", "response": "Render and display Python package documentation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef preprocess_cell(\n        self, cell: \"NotebookNode\", resources: dict, cell_index: int\n    ) -> Tuple[\"NotebookNode\", dict]:\n        \"\"\"Apply a transformation on each cell.\n\n        Parameters\n        ----------\n        cell : NotebookNode cell\n            Notebook cell being processed\n        resources : dictionary\n            Additional resources used in the conversion process.  Allows\n            preprocessors to pass variables into the Jinja engine.\n        cell_index : int\n            Index of the cell being processed (see base.py)\n\n        \"\"\"\n        # Get files directory if it has been specified\n        output_files_dir = resources.get(\"output_files_dir\", None)\n\n        # Make sure outputs key exists\n        if not isinstance(resources[\"outputs\"], dict):\n            resources[\"outputs\"] = {}\n\n        # Loop through all of the attachments in the cell\n        for name, attach in cell.get(\"attachments\", {}).items():\n            orig_name = name\n            name = re.sub(r\"%[\\w\\d][\\w\\d]\", \"-\", name)\n            for mime, data in attach.items():\n                if mime not in self.extract_output_types:\n                    continue\n\n                # Binary files are base64-encoded, SVG is already XML\n                if mime in {\"image/png\", \"image/jpeg\", \"application/pdf\"}:\n                    # data is b64-encoded as text (str, unicode),\n                    # we want the original bytes\n                    data = a2b_base64(data)\n                elif sys.platform == \"win32\":\n                    data = data.replace(\"\\n\", \"\\r\\n\").encode(\"UTF-8\")\n                else:\n                    data = data.encode(\"UTF-8\")\n\n                filename = self.output_filename_template.format(\n                    cell_index=cell_index,\n                    name=name,\n                    unique_key=resources.get(\"unique_key\", \"\"),\n                )\n\n                if output_files_dir is not None:\n                    filename = os.path.join(output_files_dir, filename)\n\n                if name.endswith(\".gif\") and mime == \"image/png\":\n                    filename = filename.replace(\".gif\", \".png\")\n\n                # In the resources, make the figure available via\n                #   resources['outputs']['filename'] = data\n                resources[\"outputs\"][filename] = data\n\n                # now we need to change the cell source so that it links to the\n                # filename instead of `attachment:`\n                attach_str = \"attachment:\" + orig_name\n                if attach_str in cell.source:\n                    cell.source = cell.source.replace(attach_str, filename)\n\n        return cell, resources", "response": "Apply a transformation on each cell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef combine_pdf_as_bytes(pdfs: List[BytesIO]) -> bytes:\n    writer = PdfWriter()\n    for pdf in pdfs:\n        writer.addpages(PdfReader(pdf).pages)\n    bio = BytesIO()\n    writer.write(bio)\n    bio.seek(0)\n    output = bio.read()\n    bio.close()\n    return output", "response": "Combine PDFs and return a byte - string with the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split(self, granularity_after_split, exclude_partial=True):\n\n        if granularity_after_split == Granularity.DAY:\n            return self.get_days()\n\n        elif granularity_after_split == Granularity.WEEK:\n            return self.get_weeks(exclude_partial)\n\n        elif granularity_after_split == Granularity.MONTH:\n            return self.get_months(exclude_partial)\n\n        elif granularity_after_split == Granularity.QUARTER:\n            return self.get_quarters(exclude_partial)\n\n        elif granularity_after_split == Granularity.HALF_YEAR:\n            return self.get_half_years(exclude_partial)\n\n        elif granularity_after_split == Granularity.YEAR:\n            return self.get_years(exclude_partial)\n\n        else:\n            raise Exception(\"Invalid granularity: %s\" % granularity_after_split)", "response": "Splits a period into a given granularity."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfits feedback calibration data to solve for values of C_fb and R_fb.", "response": "def fit_fb_calibration(df, calibration):\n    '''\n    Fit feedback calibration data to solve for values of `C_fb[:]` and\n    `R_fb[:]`.\n\n    Returns a `pandas.DataFrame` indexed by the feedback resistor/capacitance\n    index, and with the following columns:\n     - Model: Either with parasitic capacitance term or not.\n     - N: Number of samples used for fit.\n     - F: F-value\n     - p-value: p-value from Chi squared test.\n     - R_fb: Feedback resistor value based on fit.\n     - R-CI %: Confidence interval for feedback resistor value.\n     - C_fb: Feedback capacitor value based on fit (0 if no-capacitance model\n       is used).\n     - C-CI %: Confidence interval for feedback capacitance value.\n\n    __N.B.__ This function does not actually _update_ the calibration, it only\n    performs the fit.\n    See `apply_calibration`.\n    '''\n    # Set initial guesses for the feedback parameters.\n    R_fb = pd.Series([2e2, 2e3, 2e4, 2e5, 2e6])\n    C_fb = pd.Series(len(calibration.C_fb) * [50e-12])\n\n    # Error function.\n    def error(p0, df, calibration):\n        # Impedance of the reference resistor on the HV attenuator circuit.\n        Z = 10e6\n        R_fb = p0[0]\n\n        # If the parameter vector only contains one variable, the capacitance\n        # is zero\n        if len(p0) == 2:\n            C_fb = p0[1]\n        else:\n            C_fb = 0\n\n        R_hv = calibration.R_hv[df.hv_resistor.values]\n        C_hv = calibration.C_hv[df.hv_resistor.values]\n\n        # Solve feedback transfer function for the actuation voltage, _(i.e.,\n        # `V1`)_, based on the high-voltage measurements.\n        # Note that the transfer function definition depends on the hardware\n        # version.\n        V_actuation = compute_from_transfer_function(calibration.hw_version\n                                                     .major, 'V1', V2=df.V_hv,\n                                                     R1=Z, R2=R_hv, C2=C_hv,\n                                                     f=df.frequency)\n\n        # Solve feedback transfer function for the expected impedance feedback\n        # voltage, _(i.e., `V2`)_, based on the actuation voltage, the proposed\n        # values for `R2` and `C2`, and the reported `C1` value from the\n        # feedback measurements.\n        # Note that the transfer function definition depends on the hardware\n        # version.\n        # __NB__ If we do not specify a value for `R1`, a symbolic value of\n        # infinity is used.  However, in this case, we have `R1` in both the\n        # numerator and denominator.  The result is a value of zero returned\n        # regardless of the values of the other arguments.  We avoid this issue\n        # by specifying a *very large* value for `R1`.\n        # TODO Update comment if this works...\n        V_impedance = compute_from_transfer_function(calibration.hw_version\n                                                     .major, 'V2',\n                                                     V1=V_actuation,\n                                                     C1=df.test_capacitor,\n                                                     R2=R_fb, C2=C_fb,\n                                                     f=df.frequency)\n        return df.V_fb - V_impedance\n\n    # Perform a nonlinear least-squares fit of the data.\n    def fit_model(p0, df, calibration):\n        p1, cov_x, infodict, mesg, ier = scipy.optimize.leastsq(\n            error, p0, args=(df, calibration), full_output=True)\n        p1 = np.abs(p1)\n        E = error(p1, df, calibration)\n        return p1, E, cov_x\n\n    CI = []\n\n    feedback_records = []\n    # Fit feedback parameters for each feedback resistor.\n    for i in range(len(calibration.R_fb)):\n        # Only include data points for the given feedback resistor (and where\n        # `hv_resistor` is a valid index).\n        df_i = df.loc[(df.fb_resistor == i)].dropna()\n\n        if df_i.shape[0] < 2:\n            CI.append([0, 0])\n            continue\n\n        # Fit the data assuming no parasitic capacitance (model 1).\n        p0_1 = [R_fb[i]]\n        p1_1, E_1, cov_x_1 = fit_model(p0_1, df_i, calibration)\n        df_1 = (len(E_1) - len(p0_1))\n        chi2_1 = np.sum(E_1 ** 2)\n        chi2r_1 = chi2_1 / (df_1 - 1)\n\n        # fit the data including parasitic capacitance (model 2)\n        p0_2 = [R_fb[i], C_fb[i]]\n        p1_2, E_2, cov_x_2 = fit_model(p0_2, df_i, calibration)\n        df_2 = (len(E_2) - len(p0_2))\n        chi2_2 = np.sum(E_2 ** 2)\n        chi2r_2 = chi2_2 / (df_2 - 1)\n\n        # do an F-test to compare the models\n        F = (chi2_1 - chi2_2) / chi2r_2\n        p_value = scipy.stats.f.cdf(F, 1, df_2-1)\n\n        # if the p_value is > 0.95, we assume that the capacitive term is\n        # necessary\n        if p_value > .95 and cov_x_2 is not None:\n            model = 'w/Parasitic C'\n            chi2r = chi2r_2\n            R_fb_i = p1_2[0]\n            C_fb_i = p1_2[1]\n            CI.append((100 * np.sqrt(chi2r_2 * np.diag(cov_x_2)) / p1_2))\n        else:  # otherwise, set the capacitance to zero\n            model = 'w/o Parasitic C'\n            chi2r = chi2r_2\n            R_fb_i = p1_1[0]\n            C_fb_i = 0\n            if cov_x_1 is None:\n                cov_x_1 = [0]\n            CI.append((100 * np.sqrt(chi2r_1 * np.diag(cov_x_1)) /\n                       p1_1).tolist() + [0])\n        feedback_records.append([int(i), model, df_i.shape[0], R_fb_i, CI[i][0],\n                                 C_fb_i, CI[i][1], F, (1e3 * np.sqrt(chi2r)),\n                                 p_value])\n\n    calibration_df = pd.DataFrame(feedback_records,\n                                  columns=['fb_resistor', 'Model', 'N', 'R_fb', 'R-CI %',\n                                           'C_fb', 'C-CI %', 'F',\n                                           'sqrt(Chi2r*sigma^2)', 'p-value'])\n    return calibration_df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply calibration values from fit_fb_calibration result to calibration object.", "response": "def apply_calibration(df, calibration_df, calibration):\n    '''\n    Apply calibration values from `fit_fb_calibration` result to `calibration`\n    object.\n    '''\n    from dmf_control_board_firmware import FeedbackResults\n\n    for i, (fb_resistor, R_fb, C_fb) in calibration_df[['fb_resistor', 'R_fb', 'C_fb']].iterrows():\n        calibration.R_fb[int(fb_resistor)] = R_fb\n        calibration.C_fb[int(fb_resistor)] = C_fb\n\n    cleaned_df = df.dropna()\n    grouped = cleaned_df.groupby(['frequency', 'test_capacitor', 'repeat_index'])\n\n    for (f, channel, repeat_index), group in grouped:\n        r = FeedbackResults(group.V_actuation.iloc[0], f, 5.0,\n                            group.V_hv.values, group.hv_resistor.values,\n                            group.V_fb.values, group.fb_resistor.values,\n                            calibration)\n        # Update the measured capacitance values based on the updated\n        # calibration model.\n        df.loc[group.index, 'C'] = r.capacitance()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_dict(config):\n    return dict(\n        (key, getattr(config, key))\n        for key in config.values\n    )", "response": "Given a Sphinx config object return a dictionary of config\n    values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the first Repl subclass that works with this", "response": "def from_defn(cls, defn):\n        \"Return the first Repl subclass that works with this\"\n        instances = (subcl(defn) for subcl in cls.__subclasses__())\n        return next(filter(None, instances))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_definition(cls, defn, names={}):\n        repls = map(Repl.from_defn, defn.get('replace', []))\n        self = cls(repls)\n        vars(self).update(names)\n        vars(self).update(defn.get('using', {}))\n        return self", "response": "Create a new object from a dictionary containing the names and the replacement definitions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self, index, role=Qt.DisplayRole):\n        if not index.isValid():\n            return None\n        if role == Qt.DisplayRole or role == Qt.EditRole:\n            return ' '\n        if role == Qt.BackgroundColorRole:\n            color = self.color_da[index.row(), index.column()].values\n            return QtGui.QColor.fromRgbF(*color)\n        return None", "response": "Return the data for the item at the given index"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a ColormapDialog and get a colormap from the table.", "response": "def get_colormap(cls, names=[], N=10, *args, **kwargs):\n        \"\"\"Open a :class:`ColormapDialog` and get a colormap\n\n        Parameters\n        ----------\n        %(ColormapModel.parameters)s\n\n        Other Parameters\n        ----------------\n        ``*args, **kwargs``\n            Anything else that is passed to the ColormapDialog\n\n        Returns\n        -------\n        str or matplotlib.colors.Colormap\n            Either the name of a standard colormap available via\n            :func:`psy_simple.colors.get_cmap` or a colormap\n        \"\"\"\n        names = safe_list(names)\n        obj = cls(names, N, *args, **kwargs)\n        vbox = obj.layout()\n        buttons = QDialogButtonBox(\n            QDialogButtonBox.Ok | QDialogButtonBox.Cancel, parent=obj)\n        buttons.button(QDialogButtonBox.Ok).setEnabled(False)\n        vbox.addWidget(buttons)\n        buttons.accepted.connect(obj.accept)\n        buttons.rejected.connect(obj.reject)\n\n        obj.table.selectionModel().selectionChanged.connect(\n            lambda indices: buttons.button(QDialogButtonBox.Ok).setEnabled(\n                bool(indices)))\n        accepted = obj.exec_()\n        if accepted:\n            return obj.table.chosen_colormap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing a colormap dialog.", "response": "def show_colormap(cls, names=[], N=10, show=True, *args, **kwargs):\n        \"\"\"Show a colormap dialog\n\n        Parameters\n        ----------\n        %(show_colormaps.parameters.no_use_qt)s\"\"\"\n        names = safe_list(names)\n        obj = cls(names, N, *args, **kwargs)\n        vbox = obj.layout()\n        buttons = QDialogButtonBox(QDialogButtonBox.Close, parent=obj)\n        buttons.rejected.connect(obj.close)\n        vbox.addWidget(buttons)\n        if show:\n            obj.show()\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all elements in the pen", "response": "def cmd_list(args):\n    \"\"\"List all element in pen\"\"\"\n    for penlist in penStore.data:\n        puts(penlist + \" (\" + str(len(penStore.data[penlist])) + \")\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd_all(args):\n    for penlist in penStore.data:\n        puts(penlist)\n        with indent(4, '  -'):\n            for penfile in penStore.data[penlist]:\n                puts(penfile)", "response": "List all the resource types and their associated resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restclient_admin_required(view_func):\n    def wrapper(request, *args, **kwargs):\n        template = 'access_denied.html'\n        if hasattr(settings, 'RESTCLIENTS_ADMIN_AUTH_MODULE'):\n            auth_func = import_string(settings.RESTCLIENTS_ADMIN_AUTH_MODULE)\n        else:\n            context = {'error_msg': (\n                \"Your application must define an authorization function as \"\n                \"RESTCLIENTS_ADMIN_AUTH_MODULE in settings.py.\")}\n            return render(request, template, context=context, status=401)\n\n        service = args[0] if len(args) > 0 else None\n        url = args[1] if len(args) > 1 else None\n        if auth_func(request, service, url):\n            return view_func(request, *args, **kwargs)\n\n        return render(request, template, status=401)\n\n    return login_required(function=wrapper)", "response": "Decorator that checks whether the user is permitted to view proxy\n    restclients. Calls login_required in case the user is not authenticated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_file(filepath):\n    if sys.platform.startswith('darwin'):\n        subprocess.Popen(('open', filepath))\n    elif os.name == 'nt':\n        os.startfile(filepath)\n    elif os.name == 'posix':\n        subprocess.Popen(('xdg-open', filepath))", "response": "Open file with the default system app."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef destination_heuristic(data):\n    counter = collections.Counter()\n    for entry in data:\n        file_field = entry['fields'].get('file')\n        if not file_field:\n            continue\n        path = os.path.dirname(file_field)\n        counter[path] += 1\n\n    if not counter:  # No paths found\n        raise click.ClickException(\n            'Path finding heuristics failed: no paths in the database'\n        )\n\n    # Find the paths that appears most often\n    sorted_paths = sorted(counter, reverse=True)\n    groupby = itertools.groupby(sorted_paths, key=len)\n    _, group = next(groupby)\n\n    # We know that there's at least one candidate. Make sure it's\n    # the only one\n    candidate = next(group)\n    try:\n        next(group)\n    except StopIteration:\n        return candidate\n    else:\n        raise click.ClickException(\n            'Path finding heuristics failed: '\n            'there are multiple equally valid paths in the database'\n        )", "response": "A heuristic to get the folder with all other files from bib using majority\n    vote."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves an entry in place.", "response": "def remove_entry(data, entry):\n    '''\n    Remove an entry in place.\n    '''\n    file_field = entry['fields'].get('file')\n    if file_field:\n        try:\n            os.remove(file_field)\n        except IOError:\n            click.echo('This entry\\'s file was missing')\n\n    data.remove(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef string_to_basename(s):\n    '''\n    Converts to lowercase, removes non-alpha characters,\n    and converts spaces to hyphens.\n    '''\n    s = s.strip().lower()\n    s = re.sub(r'[^\\w\\s-]', '', s)\n    return re.sub(r'[\\s-]+', '-', s)", "response": "Converts to lowercase removes non - alpha characters removes spaces to hyphens."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap for click. edit that raises an error when None is returned.", "response": "def editor(*args, **kwargs):\n    '''\n    Wrapper for `click.edit` that raises an error when None is returned.\n    '''\n    result = click.edit(*args, **kwargs)\n    if result is None:\n        msg = 'Editor exited without saving, command aborted'\n        raise click.ClickException(msg)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef terms(self, facet_name, field, size=10, order=None, all_terms=False, exclude=[], regex='', regex_flags=''):\n        '''\n        Allow to specify field facets that return the N most frequent terms.\n\n        Ordering: Allow to control the ordering of the terms facets, to be ordered by count, term, reverse_count or reverse_term. The default is count.\n        All Terms: Allow to get all the terms in the terms facet, ones that do not match a hit, will have a count of 0. Note, this should not be used with fields that have many terms.\n        Excluding Terms: It is possible to specify a set of terms that should be excluded from the terms facet request result.\n        Regex Patterns: The terms API allows to define regex expression that will control which terms will be included in the faceted list.\n        '''\n\n        self[facet_name] = dict(terms=dict(field=field, size=size))\n        if order:\n            self[facet_name][terms]['order'] = order\n        if all_terms:\n            self[facet_name][terms]['all_terms'] = True\n        if exclude:\n            self[facet_name][terms]['exclude'] = exclude\n        if regex:\n            self[facet_name][terms]['regex'] = regex\n        if regex_flags:\n            self[facet_name][terms]['regex_flags'] = regex_flags\n\n        return self", "response": "Add a terms facet to the current dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef range(self, facet_name, field, ranges=[]):\n        '''\n        Range facet allow to specify a set of ranges and get both the number of docs (count) that fall within each range, and aggregated data either based on the field, or using another field.\n        http://www.elasticsearch.org/guide/reference/api/search/facets/range-facet.html\n\n        > ElasticFacet().range('range1', 'field_name', [ slice(50), slice(20,70), slice(50,-1) ])\n        {\n          \"range1\" : {\n            \"range\" : {\n                \"field\" : \"field_name\",\n                \"ranges\" : [\n                    { \"to\" : 50 },\n                    { \"from\" : 20, \"to\" : 70 },\n                    { \"from\" : 70, \"to\" : 120 },\n                    { \"from\" : 150 }\n                ]\n            }\n           }\n        }\n        '''\n\n        self[facet_name] = {'range': {'field': field, 'ranges': []}}\n        for s in ranges:\n            if not isinstance(s, slice):\n                continue\n            entry = dict()\n            if s.start:\n                entry['from'] = s.start\n            if s.stop != -1:\n                entry['to'] = s.stop\n            self[facet_name]['range']['ranges'].append(entry)\n\n        return self", "response": "This method provides a range facet that returns the number of docs that fall within each range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a GPX file into a GpxModel.", "response": "def parse_gpx(gpx_element, gpxns=None):\n    \"\"\"Parse a GPX file into a GpxModel.\n\n    Args:\n        gpx_element: The root <gpx> element of an XML document containing a\n            version attribute. GPX versions 1.0 and 1.1 are supported.\n\n        gpxns: The XML namespace for GPX in Clarke notation (i.e. delimited\n             by curly braces).\n\n    Returns:\n        A GpxModel representing the data from the supplies xml.\n\n    Raises:\n        ValueError: The supplied XML could not be parsed as GPX.\n    \"\"\"\n    gpxns = gpxns if gpxns is not None else determine_gpx_namespace(gpx_element)\n\n    if gpx_element.tag != gpxns+'gpx':\n        raise ValueError(\"No gpx root element\")\n\n    version = gpx_element.attrib['version']\n\n    if version == '1.0':\n        return parse_gpx_1_0(gpx_element, gpxns=gpxns)\n    elif version == '1.1':\n        return parse_gpx_1_1(gpx_element, gpxns=gpxns)\n    else:\n        raise ValueError(\"Cannot parse GPX version {0}\".format(version))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a backup of the file", "response": "def backup_file(filename):\n    \"\"\" create a backup of the file desired \"\"\"\n    if not os.path.exists(filename):\n        return\n\n    BACKUP_SUFFIX = \".sprinter.bak\"\n\n    backup_filename = filename + BACKUP_SUFFIX\n    shutil.copyfile(filename, backup_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inject(self, filename, content):\n        # ensure content always has one trailing newline\n        content = _unicode(content).rstrip() + \"\\n\"\n        if filename not in self.inject_dict:\n            self.inject_dict[filename] = \"\"\n        self.inject_dict[filename] += content", "response": "add the injection content to the dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commit(self):\n        self.logger.debug(\"Starting injections...\")\n        self.logger.debug(\"Injections dict is:\")\n        self.logger.debug(self.inject_dict)\n        self.logger.debug(\"Clear list is:\")\n        self.logger.debug(self.clear_set)\n        for filename, content in self.inject_dict.items():\n            content = _unicode(content)\n            self.logger.debug(\"Injecting values into %s...\" % filename)\n            self.destructive_inject(filename, content)\n        for filename in self.clear_set:\n            self.logger.debug(\"Clearing injection from %s...\" % filename)\n            self.destructive_clear(filename)", "response": "Commit the injections desired and overwrite any previous injections in the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the file has already been injected before.", "response": "def injected(self, filename):\n        \"\"\" Return true if the file has already been injected before. \"\"\"\n        full_path = os.path.expanduser(filename)\n        if not os.path.exists(full_path):\n            return False\n        with codecs.open(full_path, 'r+', encoding=\"utf-8\") as fh:\n            contents = fh.read()\n        return self.wrapper_match.search(contents) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef destructive_inject(self, filename, content):\n        content = _unicode(content)\n        backup_file(filename)\n        full_path = self.__generate_file(filename)\n        with codecs.open(full_path, 'r', encoding=\"utf-8\") as f:\n            new_content = self.inject_content(f.read(), content)\n        with codecs.open(full_path, 'w+', encoding=\"utf-8\") as f:\n            f.write(new_content)", "response": "Injects the content into the file filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the file at the file_path desired. Creates any needed directories on the way. Returns the absolute path of the file.", "response": "def __generate_file(self, file_path):\n        \"\"\"\n        Generate the file at the file_path desired. Creates any needed\n        directories on the way. returns the absolute path of the file.\n        \"\"\"\n        file_path = os.path.expanduser(file_path)\n        if not os.path.exists(os.path.dirname(file_path)):\n            self.logger.debug(\"Directories missing! Creating directories for %s...\" % file_path)\n            os.makedirs(os.path.dirname(file_path))\n        if not os.path.exists(file_path):\n            open(file_path, \"w+\").close()\n        return file_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a string exists in the file and if it is not the injected file", "response": "def in_noninjected_file(self, file_path, content):\n        \"\"\" Checks if a string exists in the file, sans the injected \"\"\"\n        if os.path.exists(file_path):\n            file_content = codecs.open(file_path, encoding=\"utf-8\").read()\n            file_content = self.wrapper_match.sub(u\"\", file_content)\n        else:\n            file_content = \"\"\n        return file_content.find(content) != -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inject_content(self, content, inject_string):\n        inject_string = _unicode(inject_string)\n        content = self.wrapper_match.sub(\"\", _unicode(content))\n        if self.override_match:\n            sprinter_overrides = self.override_match.search(content)\n            if sprinter_overrides:\n                content = self.override_match.sub(\"\", content)\n                sprinter_overrides = sprinter_overrides.groups()[0]\n            else:\n                sprinter_overrides = \"\"\n        content += \"\"\"\n%s\n%s\n%s\n\"\"\" % (self.wrapper, inject_string.rstrip(), self.wrapper)\n        if self.override_match:\n            content += sprinter_overrides.rstrip() + \"\\n\"\n        return content", "response": "Injects inject_string into a text buffer wrapped with self. wrapper comments if condition lambda is not satisfied."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_content(self, content):\n        content = _unicode(content)\n        return self.wrapper_match.sub(\"\", content)", "response": "Clear the injected content from the content buffer and return the results\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_orders_ungrouped(self):\n        for olist in self._orders.values():\n            for order in olist.orders:\n                yield order", "response": "Uses a generator to return all orders within."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_order(self, order):\n        # This key is used to group the orders based on region.\n        key = '%s_%s' % (order.region_id, order.type_id)\n        if not self._orders.has_key(key):\n            # We don't have any orders for this yet. Prep the region+item\n            # combo by instantiating a new MarketItemsInRegionList for\n            # the MarketOrders.\n            self.set_empty_region(\n                order.region_id,\n                order.type_id,\n                order.generated_at\n            )\n\n        # The MarketOrder gets stuffed into the MarketItemsInRegionList for this\n        # item+region combo.\n        self._orders[key].add_order(order)", "response": "Adds a MarketOrder instance to the list of market orders contained in this item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the empty region for the given item + type ID and generated time.", "response": "def set_empty_region(self, region_id, type_id, generated_at,\n                         error_if_orders_present=True):\n        \"\"\"\n        Prepares for the given region+item combo by instantiating a\n        :py:class:`MarketItemsInRegionList` instance, which will track\n        region ID, type ID, and generated time. This is mostly used for\n        the JSON deserialization process in case there are no orders for\n        the given region+item combo.\n\n        :param int region_id: The region ID.\n        :param int type_id: The item's type ID.\n        :param datetime.datetime generated_at: The time that the order set\n            was generated.\n        :keyword bool error_if_orders_present: If True, raise an exception if\n            an order already exists for this item+region combo when this is\n            called. This failsafe may be disabled by passing False here.\n        \"\"\"\n        key = '%s_%s' % (region_id, type_id)\n        if error_if_orders_present and self._orders.has_key(key):\n            raise ItemAlreadyPresentError(\n                \"Orders already exist for the given region and type ID. \"\n                \"Pass error_if_orders_present=False to disable this failsafe, \"\n                \"if desired.\"\n            )\n\n        self._orders[key] = MarketItemsInRegionList(\n            region_id, type_id, generated_at)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_entry(self, entry):\n        # This key is used to group the orders based on region.\n        key = '%s_%s' % (entry.region_id, entry.type_id)\n        if not self._history.has_key(key):\n            # We don't have any orders for this yet. Prep the region+item\n            # combo by instantiating a new MarketItemsInRegionList for\n            # the MarketOrders.\n            self.set_empty_region(\n                entry.region_id,\n                entry.type_id,\n                entry.generated_at\n            )\n\n        # The MarketOrder gets stuffed into the MarketItemsInRegionList for this\n        # item+region combo.\n        self._history[key].add_entry(entry)", "response": "Adds a MarketHistoryEntry instance to the list of market history entries that are contained within this instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_empty_region(self, region_id, type_id, generated_at,\n                         error_if_entries_present=True):\n        \"\"\"\n        Prepares for the given region+item combo by instantiating a\n        :py:class:`HistoryItemsInRegionList` instance, which will track\n        region ID, type ID, and generated time. This is mostly used for\n        the JSON deserialization process in case there are no orders for\n        the given region+item combo.\n\n        :param int region_id: The region ID.\n        :param int type_id: The item's type ID.\n        :param datetime.datetime generated_at: The time that the order set\n            was generated.\n        :keyword bool error_if_entries_present: If True, raise an exception if\n            an entry already exists for this item+region combo when this is\n            called. This failsafe may be disabled by passing False here.\n        \"\"\"\n        key = '%s_%s' % (region_id, type_id)\n        if error_if_entries_present and self._history.has_key(key):\n            raise ItemAlreadyPresentError(\n                \"Orders already exist for the given region and type ID. \"\n                \"Pass error_if_orders_present=False to disable this failsafe, \"\n                \"if desired.\"\n            )\n\n        self._history[key] = HistoryItemsInRegionList(\n            region_id, type_id, generated_at)", "response": "Sets the empty region for the given item + type ID and generated time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_file(self, file_name: str, lookup_dir: Path) -> Path or None:\n        '''Find a file in a directory by name. Check subdirectories recursively.\n\n        :param file_name: Name of the file\n        :lookup_dir: Starting directory\n\n        :returns: Path to the found file or None if the file was not found\n        :raises: FileNotFoundError\n        '''\n\n        self.logger.debug('Trying to find the file {file_name} inside the directory {lookup_dir}')\n\n        result = None\n\n        for item in lookup_dir.rglob('*'):\n            if item.name == file_name:\n                result = item\n                break\n        else:\n            raise FileNotFoundError(file_name)\n\n        self.logger.debug('File found: {result}')\n\n        return result", "response": "Find a file in a directory by name. Check subdirectories recursively."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _sync_repo(self, repo_url: str, revision: str or None = None) -> Path:\n        '''Clone a Git repository to the cache dir. If it has been cloned before, update it.\n\n        :param repo_url: Repository URL\n        :param revision: Revision: branch, commit hash, or tag\n\n        :returns: Path to the cloned repository\n        '''\n\n        repo_name = repo_url.split('/')[-1].rsplit('.', maxsplit=1)[0]\n        repo_path = (self._cache_path / repo_name).resolve()\n\n        self.logger.debug(f'Synchronizing with repo; URL: {repo_url}, revision: {revision}')\n\n        try:\n            self.logger.debug(f'Cloning repo {repo_url} to {repo_path}')\n\n            run(\n                f'git clone {repo_url} {repo_path}',\n                shell=True,\n                check=True,\n                stdout=PIPE,\n                stderr=STDOUT\n            )\n\n        except CalledProcessError as exception:\n            if repo_path.exists():\n                self.logger.debug('Repo already cloned; pulling from remote')\n\n                try:\n                    run(\n                        'git pull',\n                        cwd=repo_path,\n                        shell=True,\n                        check=True,\n                        stdout=PIPE,\n                        stderr=STDOUT\n                    )\n\n                except CalledProcessError as exception:\n                    self.logger.warning(str(exception))\n\n            else:\n                self.logger.error(str(exception))\n\n        if revision:\n            run(\n                f'git checkout {revision}',\n                cwd=repo_path,\n                shell=True,\n                check=True,\n                stdout=PIPE,\n                stderr=STDOUT\n            )\n\n        return repo_path", "response": "Clone a Git repository to the cache dir. If it has been cloned before update it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _shift_headings(self, content: str, shift: int) -> str:\n        '''Shift Markdown headings in a string by a given value. The shift can\n        be positive or negative.\n\n        :param content: Markdown content\n        :param shift: Heading shift\n\n        :returns: Markdown content with headings shifted by ``shift``\n        '''\n\n        def _sub(heading):\n            new_heading_level = len(heading.group('hashes')) + shift\n\n            self.logger.debug(f'Shift heading level to {new_heading_level}, heading title: {heading.group(\"title\")}')\n\n            if new_heading_level <= 6:\n                return f'{\"#\" * new_heading_level} {heading.group(\"title\")}{heading.group(\"tail\")}'\n\n            else:\n                self.logger.debug('New heading level is out of range, using bold paragraph text instead of heading')\n\n                return f'**{heading.group(\"title\")}**{heading.group(\"tail\")}'\n\n        return self._heading_pattern.sub(_sub, content)", "response": "Shift Markdown headings in a string by a given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the highest level heading in a Markdown string.", "response": "def _find_top_heading_level(self, content: str) -> int:\n        '''Find the highest level heading (i.e. having the least '#'s)\n        in a Markdown string.\n\n        :param content: Markdown content\n\n        :returns: Maximum heading level detected; if no heading is found, 0 is returned\n        '''\n\n        result = float('inf')\n\n        for heading in self._heading_pattern.finditer(content):\n            heading_level = len(heading.group('hashes'))\n\n            if heading_level < result:\n                result = heading_level\n\n            self.logger.debug(f'Maximum heading level: {result}')\n\n        return result if result < float('inf') else 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cut_from_heading_to_heading(\n            self,\n            content: str,\n            from_heading: str,\n            to_heading: str or None = None,\n            options={}\n        ) -> str:\n        '''Cut part of Markdown string between two headings, set internal heading level,\n        and remove top heading.\n\n        If only the starting heading is defined, cut to the next heading\n        of the same level.\n\n        Heading shift and top heading elimination are optional.\n\n        :param content: Markdown content\n        :param from_heading: Starting heading\n        :param to_heading: Ending heading (will not be incuded in the output)\n        :param options: ``sethead``, ``nohead``\n\n        :returns: Part of the Markdown content between headings with internal headings adjusted\n        '''\n\n        self.logger.debug(f'Cutting from heading: {from_heading}, to heading: {to_heading}, options: {options}')\n\n        from_heading_pattern = re.compile(r'^\\#{1,6}\\s+' + rf'{from_heading}\\s*$', flags=re.MULTILINE)\n\n        if not from_heading_pattern.findall(content):\n            return ''\n\n        from_heading_line = from_heading_pattern.findall(content)[0]\n        from_heading_level = len(self._heading_pattern.match(from_heading_line).group('hashes'))\n\n        self.logger.debug(f'From heading level: {from_heading_level}')\n\n        result = from_heading_pattern.split(content)[1]\n\n        if to_heading:\n            to_heading_pattern = re.compile(r'^\\#{1,6}\\s+' + rf'{to_heading}\\s*$', flags=re.MULTILINE)\n\n        else:\n            to_heading_pattern = re.compile(\n                rf'^\\#{{1,{from_heading_level}}}[^\\#]+?$',\n                flags=re.MULTILINE\n            )\n\n        result = to_heading_pattern.split(result)[0]\n\n        if not options.get('nohead'):\n            result = from_heading_line + result\n\n        if options.get('sethead'):\n            if options['sethead'] > 0:\n                result = self._shift_headings(\n                    result,\n                    options['sethead'] - from_heading_level\n                )\n\n        return result", "response": "Cut part of Markdown string between two headings set internal heading level and remove top heading."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncutting part of Markdown string from the start to a certain heading and remove top heading.", "response": "def _cut_to_heading(\n            self,\n            content: str,\n            to_heading: str or None = None,\n            options={}\n        ) -> str:\n        '''Cut part of Markdown string from the start to a certain heading,\n        set internal heading level, and remove top heading.\n\n        If not heading is defined, the whole string is returned.\n\n        Heading shift and top heading elimination are optional.\n\n        :param content: Markdown content\n        :param to_heading: Ending heading (will not be incuded in the output)\n        :param options: ``sethead``, ``nohead``\n\n        :returns: Part of the Markdown content from the start to ``to_heading``,\n            with internal headings adjusted\n        '''\n\n        self.logger.debug(f'Cutting to heading: {to_heading}, options: {options}')\n\n        content_buffer = StringIO(content)\n\n        first_line = content_buffer.readline()\n\n        if self._heading_pattern.fullmatch(first_line):\n            from_heading_line = first_line\n            from_heading_level = len(self._heading_pattern.match(from_heading_line).group('hashes'))\n            result = content_buffer.read()\n\n        else:\n            from_heading_line = ''\n            from_heading_level = self._find_top_heading_level(content)\n            result = content\n\n        self.logger.debug(f'From heading level: {from_heading_level}')\n\n        if to_heading:\n            to_heading_pattern = re.compile(r'^\\#{1,6}\\s+' + rf'{to_heading}\\s*$', flags=re.MULTILINE)\n            result = to_heading_pattern.split(result)[0]\n\n        if not options.get('nohead'):\n            result = from_heading_line + result\n\n        if options.get('sethead'):\n            if options['sethead'] > 0:\n                result = self._shift_headings(\n                    result,\n                    options['sethead'] - from_heading_level\n                )\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _adjust_image_paths(self, content: str, md_file_path: Path) -> str:\n        '''Locate images referenced in a Markdown string and replace their paths\n        with the absolute ones.\n\n        :param content: Markdown content\n        :param md_file_path: Path to the Markdown file containing the content\n\n        :returns: Markdown content with absolute image paths\n        '''\n\n        def _sub(image):\n            image_caption = image.group('caption')\n            image_path = md_file_path.parent / Path(image.group('path'))\n\n            self.logger.debug(\n                f'Updating image reference; user specified path: {image.group(\"path\")}, ' +\n                f'absolute path: {image_path}, caption: {image_caption}'\n            )\n\n            return f'![{image_caption}]({image_path.absolute().as_posix()})'\n\n        return self._image_pattern.sub(_sub, content)", "response": "Locate images referenced in a Markdown string and replace their paths\n        with the absolute ones."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntranslates the path of the corresponding Markdown file that is located inside the temporary working directory into the path of the corresponding Markdown file that is located inside the source directory .", "response": "def _get_src_file_path(self, markdown_file_path: Path) -> Path:\n        '''Translate the path of Markdown file that is located inside the temporary working directory\n        into the path of the corresponding Markdown file that is located inside the source directory\n        of Foliant project.\n\n        :param markdown_file_path: Path to Markdown file that is located inside the temporary working directory\n\n        :returns: Mapping of Markdown file path to the source directory\n        '''\n\n        path_relative_to_working_dir = markdown_file_path.relative_to(self.working_dir.resolve())\n\n        self.logger.debug(\n            'Currently processed Markdown file path relative to working dir: ' +\n            f'{path_relative_to_working_dir}'\n        )\n\n        path_mapped_to_src_dir = (\n            self.project_path.resolve() /\n            self.config['src_dir'] /\n            path_relative_to_working_dir\n        )\n\n        self.logger.debug(\n            'Currently processed Markdown file path mapped to source dir: ' +\n            f'{path_mapped_to_src_dir}'\n        )\n\n        return path_mapped_to_src_dir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve user specified path to the local included file.", "response": "def _get_included_file_path(self, user_specified_path: str, current_processed_file_path: Path) -> Path:\n        '''Resolve user specified path to the local included file.\n\n        :param user_specified_path: User specified string that represents\n            the path to a local file\n\n        :param current_processed_file_path: Path to the currently processed Markdown file\n            that contains include statements\n\n        :returns: Local path of the included file relative to the currently processed Markdown file\n        '''\n\n        self.logger.debug(f'Currently processed Markdown file: {current_processed_file_path}')\n\n        included_file_path = (current_processed_file_path.parent / user_specified_path).resolve()\n\n        self.logger.debug(f'User-specified included file path: {included_file_path}')\n\n        if (\n            self.working_dir.resolve() in current_processed_file_path.parents\n            and\n            self.working_dir.resolve() not in included_file_path.parents\n        ):\n            self.logger.debug(\n                'Currently processed file is located inside the working dir, ' +\n                'but included file is located outside the working dir. ' +\n                'So currently processed file path should be rewritten with the path of corresponding file ' +\n                'that is located inside the source dir'\n            )\n\n            included_file_path = (\n                self._get_src_file_path(current_processed_file_path).parent / user_specified_path\n            ).resolve()\n\n        else:\n            self.logger.debug(\n                'Using these paths without changes'\n            )\n\n        self.logger.debug(f'Finally, included file path: {included_file_path}')\n\n        return included_file_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_include(\n            self,\n            file_path: Path,\n            from_heading: str or None = None,\n            to_heading: str or None = None,\n            options={}\n        ) -> str:\n        '''Replace a local include statement with the file content. Necessary\n        adjustments are applied to the content: cut between certain headings,\n        strip the top heading, set heading level.\n\n        :param file_path: Path to the included file\n        :param from_heading: Include starting from this heading\n        :param to_heading: Include up to this heading (not including the heading itself)\n        :param options: ``sethead``, ``nohead``\n\n        :returns: Included file content\n        '''\n\n        self.logger.debug(\n            f'Included file path: {file_path}, from heading: {from_heading}, ' +\n            f'to heading: {to_heading}, options: {options}'\n        )\n\n        if file_path.name.startswith('^'):\n            file_path = self._find_file(file_path.name[1:], file_path.parent)\n\n        with open(file_path, encoding='utf8') as incl_file:\n            incl_content = incl_file.read()\n\n            if from_heading:\n                incl_content = self._cut_from_heading_to_heading(\n                    incl_content,\n                    from_heading,\n                    to_heading,\n                    options\n                )\n\n            else:\n                incl_content = self._cut_to_heading(\n                    incl_content,\n                    to_heading,\n                    options\n                )\n\n            incl_content = self._adjust_image_paths(incl_content, file_path)\n\n        return incl_content", "response": "Replace a local include statement with the content of the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace all include statements with the respective file contents.", "response": "def process_includes(self, markdown_file_path: Path, content: str) -> str:\n        '''Replace all include statements with the respective file contents.\n\n        :param markdown_file_path: Path to curently processed Markdown file\n        :param content: Markdown content\n\n        :returns: Markdown content with resolved includes\n        '''\n\n        markdown_file_path = markdown_file_path.resolve()\n\n        self.logger.debug(f'Processing Markdown file: {markdown_file_path}')\n\n        processed_content = ''\n\n        include_statement_pattern = re.compile(\n            rf'((?<!\\<)\\<{\"|\".join(self.tags)}(?:\\s[^\\<\\>]*)?\\>.*?\\<\\/{\"|\".join(self.tags)}\\>)',\n            flags=re.DOTALL\n        )\n\n        content_parts = include_statement_pattern.split(content)\n\n        for content_part in content_parts:\n            include_statement = self.pattern.fullmatch(content_part)\n\n            if include_statement:\n                body = self._tag_body_pattern.match(include_statement.group('body').strip())\n                options = self.get_options(include_statement.group('options'))\n\n                self.logger.debug(f'Processing include statement; body: {body}, options: {options}')\n\n                if body.group('repo'):\n                    repo = body.group('repo')\n                    repo_from_alias = self.options['aliases'].get(repo)\n\n                    revision = None\n\n                    if repo_from_alias:\n                        self.logger.debug(f'Alias found: {repo}, resolved as: {repo_from_alias}')\n\n                        if '#' in repo_from_alias:\n                            repo_url, revision = repo_from_alias.split('#', maxsplit=1)\n\n                        else:\n                            repo_url = repo_from_alias\n\n                    else:\n                        repo_url = repo\n\n                    if body.group('revision'):\n                        revision = body.group('revision')\n\n                        self.logger.debug(f'Highest priority revision specified in the include statement: {revision}')\n\n                    self.logger.debug(f'File in Git repository referenced; URL: {repo_url}, revision: {revision}')\n\n                    repo_path = self._sync_repo(repo_url, revision)\n\n                    self.logger.debug(f'Local path of the repo: {repo_path}')\n\n                    included_file_path = repo_path / body.group('path')\n\n                    self.logger.debug(f'Resolved path to the included file: {included_file_path}')\n\n                    processed_content_part = self._process_include(\n                        included_file_path,\n                        body.group('from_heading'),\n                        body.group('to_heading'),\n                        options\n                    )\n\n                else:\n                    self.logger.debug('Local file referenced')\n\n                    included_file_path = self._get_included_file_path(body.group('path'), markdown_file_path)\n\n                    self.logger.debug(f'Resolved path to the included file: {included_file_path}')\n\n                    processed_content_part = self._process_include(\n                        included_file_path,\n                        body.group('from_heading'),\n                        body.group('to_heading'),\n                        options\n                    )\n\n                if self.options['recursive'] and self.pattern.search(processed_content_part):\n                    self.logger.debug('Recursive call of include statements processing')\n\n                    processed_content_part = self.process_includes(included_file_path, processed_content_part)\n\n                if options.get('inline'):\n                    self.logger.debug('Processing included content part as inline')\n\n                    processed_content_part = re.sub(r'\\s+', ' ', processed_content_part).strip()\n\n            else:\n                processed_content_part = content_part\n\n            processed_content += processed_content_part\n\n        return processed_content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_view_from_dict(name, spec, template=None, cls=ActionsView):\n    kwargs = dict(spec)\n    if template is not None:\n        kwargs.setdefault(\"template\", template)\n    actions = load_grouped_actions(kwargs, pop_keys=True)\n    view = cls(name=name, **kwargs)\n    if isinstance(view, ActionsView):\n        view.actions.extend(actions)\n    return view", "response": "Creates a view from a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_argv(argv=copy(sys.argv)):\n\n    cfg = DotDict()\n    cfg_files = []\n\n    argv = argv[1:] # Skip command name\n    while argv:\n        arg = argv.pop(0)\n\n        # split up arg in format --arg=val\n        key_val = re.split('=| ', arg)\n        arg = key_val[0]\n        try:\n            val = key_val[1]\n        except IndexError:\n            if len(argv) > 0 and argv[0][0] != '-':\n                val = argv.pop(0)\n            else:\n                # No val available, probably a flag\n                val = None\n\n        if arg[0] == '-':\n            key = arg.lstrip('-')\n            if not val:\n                val = True\n            new_cfg = _dict_from_dotted(key, val)\n            cfg = dict_merge(cfg, new_cfg)\n        else:\n            if arg.endswith(\".yml\"):\n                cfg_files.append(arg)\n\n    return cfg, cfg_files", "response": "parse the argv as a parsed dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a key value pair like this. is. a. key val returns a dictionary like this. is. a. key", "response": "def _dict_from_dotted(key, val):\n    \"\"\"takes a key value pair like:\n    key: \"this.is.a.key\"\n    val: \"the value\"\n\n    and returns a dictionary like:\n\n    {\"this\":\n        {\"is\":\n            {\"a\":\n                {\"key\":\n                    \"the value\"\n                }\n            }\n        }\n    }\n    \"\"\"\n    split_key = key.split(\".\")\n    split_key.reverse()\n    for key_part in split_key:\n        new_dict = DotDict()\n        new_dict[key_part] = val\n        val = new_dict\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a logger for a service using the py 2. 7 dictConfig", "response": "def get_logger(name, CFG=None):\n    \"\"\"set up logging for a service using the py 2.7 dictConfig\n    \"\"\"\n\n    logger = logging.getLogger(name)\n\n    if CFG:\n        # Make log directory if it doesn't exist\n        for handler in CFG.get('handlers', {}).itervalues():\n            if 'filename' in handler:\n                log_dir = os.path.dirname(handler['filename'])\n                if not os.path.exists(log_dir):\n                    os.makedirs(log_dir)\n        try:\n            #TODO: This requires python 2.7\n            logging.config.dictConfig(CFG)\n        except AttributeError:\n            print >> sys.stderr, '\"logging.config.dictConfig\" doesn\\'t seem to be supported in your python'\n            raise\n\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_LABELDECL(self, token):\n        ur'-\\s<label>\\s*\\[(?P<label>.+?)\\]\\s*(?P<text>.+?)\\n'\n        label = token.lexer.lexmatch.group(\"label\").decode(\"utf8\")\n        text = token.lexer.lexmatch.group(\"text\").decode(\"utf8\")\n        token.value = (label, text)\n        token.lexer.lineno += 1\n        return token", "response": "t_LABELDECL token - > COMMENT COMMENT"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the article header.", "response": "def t_ARTICLEHEADER(self, token):\n        # \\xef\\xbc\\x9a is the \"fullwidth colon\" used in Japanese for instance\n        ur'\\#\\#\\s+<article-(?P<number>[A-Z0-9]+)><(?P<newtag>[a-zA-Z0-9-]+)><(?P<oldtag>[a-zA-Z0-9-]+)>[ ]*(?P<name>[^\\<]+?)(?P<sep>:\\s|\\xef\\xbc\\x9a)(?P<title>[^<\\n]+)\\n'\n        number = token.lexer.lexmatch.group(\"number\").decode(\"utf8\")\n        newtag = token.lexer.lexmatch.group(\"newtag\").decode(\"utf8\")\n        oldtag = token.lexer.lexmatch.group(\"oldtag\").decode(\"utf8\")\n        name = token.lexer.lexmatch.group(\"name\").decode(\"utf8\")\n        sep = token.lexer.lexmatch.group(\"sep\").decode(\"utf8\")\n        title = token.lexer.lexmatch.group(\"title\").decode(\"utf8\")\n        token.value = (number, newtag, oldtag, name, title, sep)\n        token.lexer.lineno += 1\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef t_STATESHEADER(self, token):\n        ur'\\#\\#\\s+<states-list>(?P<title>[^<\\n]*)\\n'\n        title = token.lexer.lexmatch.group(\"title\").decode(\"utf8\")\n        token.value = title\n        token.lexer.lineno += 1\n        return token", "response": "t_STATESHEADER token. lexer. lexmatch is a regex match for the states - list title."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef t_TEXT(self, token):\n        ur'(?P<text>[^<#\\n ].+?[^ ])(?=\\n)'\n        text = token.lexer.lexmatch.group(\"text\").decode(\"utf8\")\n        token.value = text\n        return token", "response": "Token handler for TEXT"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef t_trailingwhitespace(self, token):\n        ur'.+? \\n'\n        print \"Error: trailing whitespace at line %s in text '%s'\" % (token.lexer.lineno + 1, token.value[:-1])\n        token.lexer.lexerror = True\n        token.lexer.skip(1)", "response": "ur. +? \\ n"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_event(cls, event_name, event, method):\n        log.info('@Registry.register_event `{}` with subscriber `{}`'\n                 .format(event_name, method.__name__))\n\n        if event_name not in cls._events:\n            cls._events[event_name] = {}\n\n        if event not in cls._events[event_name]:\n            cls._events[event_name][event] = []\n\n        cls._events[event_name][event].append(method)", "response": "Register an event class on it s name with a method to process it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a default producer for events to dispatch on.", "response": "def register_producer(cls, producer):\n        \"\"\"\n        Register a default producer for events to use.\n        :param producer: the default producer to to dispatch events on.\n        \"\"\"\n        log.info('@Registry.register_producer `{}`'\n                 .format(producer.__class__.__name__))\n        cls._producer = (cls._producer or producer)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute actions in the before and before_METHOD groups", "response": "def exec_before_request_actions(actions, **kwargs):\n    \"\"\"Execute actions in the \"before\" and \"before_METHOD\" groups\n    \"\"\"\n    groups = (\"before\", \"before_\" + flask.request.method.lower())\n    return execute_actions(actions, limit_groups=groups, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exec_after_request_actions(actions, response, **kwargs):\n    current_context[\"response\"] = response\n    groups = (\"after_\" + flask.request.method.lower(), \"after\")\n    try:\n        rv = execute_actions(actions, limit_groups=groups, **kwargs)\n    except ReturnValueException as e:\n        rv = e.value\n    if rv:\n        return rv\n    return response", "response": "Executes actions of the after and after_METHOD groups. Returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the given actions and return the response.", "response": "def full_exec_request_actions(actions, func=None, render_func=None):\n    \"\"\"Full process to execute before, during and after actions.\n    If func is specified, it will be called after exec_request_actions()\n    unless a ContextExitException was raised. If render_func is specified,\n    it will be called after exec_request_actions() only if there is no\n    response. exec_after_request_actions() is always called.\n    \"\"\"\n    response = None\n    try:\n        exec_before_request_actions(actions, catch_context_exit=False)\n        exec_request_actions(actions, catch_context_exit=False)\n        if func:\n            response = func()\n    except ContextExitException as e:\n        response = e.result\n    except ReturnValueException as e:\n        response = e.value\n    if render_func and response is None:\n        response = render_func()\n    return exec_after_request_actions(actions, response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_view(url=None, methods=None, view_class=ActionsView, name=None, url_rules=None, **kwargs):\n    def decorator(f):\n        if url is not None:\n            f = expose(url, methods=methods)(f)\n\n        clsdict = {\"name\": name or f.__name__,\n                   \"actions\": getattr(f, \"actions\", None),\n                   \"url_rules\": url_rules or getattr(f, \"urls\", None)}\n\n        if isinstance(f, WithActionsDecorator):\n            f = f.func\n        clsdict['func'] = f\n\n        def constructor(self, **ctorkwargs):\n            for k, v in kwargs.items():\n                if k not in ctorkwargs or ctorkwargs[k] is None:\n                    ctorkwargs[k] = v\n            view_class.__init__(self, func=f, **ctorkwargs)\n\n        clsdict[\"__init__\"] = constructor\n        return type(f.__name__, (view_class,), clsdict)\n\n    return decorator", "response": "Decorator to transform a function into a view class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, target):\n        for rule, options in self.url_rules:\n            target.add_url_rule(rule, self.name, self.dispatch_request, **options)", "response": "Registers url_rules on the blueprint\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_action_view(self, name, url, actions, **kwargs):\n        view = ActionsView(name, url=url, self_var=self, **kwargs)\n        if isinstance(actions, dict):\n            for group, actions in actions.iteritems():\n                view.actions.extend(load_actions(actions, group=group or None))\n        else:\n            view.actions.extend(load_actions(actions))\n        self.add_view(view)\n        return view", "response": "Adds an ActionsView instance and registers it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process(exam_num: int, time: str, date: str) -> None:\n    prefix = Path(f\"exams/exam-{exam_num}\")\n\n    problems = list(prefix.glob(f\"exam-{exam_num}-{time}-[0-9].ipynb\"))\n    problems = sorted(problems, key=lambda k: k.stem[-1])\n\n    output_directory = (prefix / \"output\").resolve()\n    fw = FilesWriter(build_directory=str(output_directory))\n\n    assignment_zip_name = output_directory / f\"exam-{exam_num}-{time}.zip\"\n    solution_zip_name = output_directory / f\"exam-{exam_num}-{time}-soln.zip\"\n\n    solution_pdfs: List[BytesIO] = []\n\n    exam_date_time = datetime.strptime(time + date, \"%H%M%d-%b-%Y\")\n    res: Dict[str, Union[str, int]] = {\n        \"exam_num\": exam_num,\n        \"time\": exam_date_time.strftime(\"%I:%M %p\"),\n        \"date\": exam_date_time.strftime(\"%b. %d, %Y\"),\n        \"delete_pymarkdown\": True,\n    }\n\n    for problem in problems:\n        res[\"unique_key\"] = problem.stem\n        problem_fname = str(problem.resolve())\n        if problem.stem.endswith(\"1\"):\n\n            assignment_nb, _ = sa_nb_exp.from_filename(problem_fname, resources=res)\n\n            with ZipFile(assignment_zip_name, mode=\"a\") as zip_file:\n                zip_file.writestr(problem.name, assignment_nb)\n        else:\n            assignment_nb, _ = prob_nb_exp.from_filename(problem_fname, resources=res)\n\n            with ZipFile(assignment_zip_name, mode=\"a\") as zip_file:\n                zip_file.writestr(problem.name, assignment_nb)\n\n        solution_pdf, _ = solution_pdf_exp.from_filename(problem_fname, resources=res)\n        solution_pdfs.append(BytesIO(solution_pdf))\n\n        solution_nb, _ = solution_nb_exp.from_filename(problem_fname, resources=res)\n        with ZipFile(solution_zip_name, mode=\"a\") as zip_file:\n            zip_file.writestr(problem.name, solution_nb)\n\n    resources: Dict[str, Any] = {\n        \"metadata\": {\n            \"name\": f\"exam-{exam_num}-{time}-soln\",\n            \"path\": str(prefix),\n            \"modified_date\": datetime.today().strftime(\"%B %d, %Y\"),\n        },\n        \"output_extension\": \".pdf\",\n    }\n    fw.write(\n        combine_pdf_as_bytes(solution_pdfs), resources, f\"exam-{exam_num}-{time}-soln\"\n    )", "response": "Processes the exams in the exam_num folder for the time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(argv: Optional[Sequence[str]] = None) -> None:\n    parser = ArgumentParser(description=\"Convert Jupyter Notebook exams to PDFs\")\n    parser.add_argument(\n        \"--exam\",\n        type=int,\n        required=True,\n        help=\"Exam number to convert\",\n        dest=\"exam_num\",\n    )\n    parser.add_argument(\n        \"--time\", type=str, required=True, help=\"Time of exam to convert\"\n    )\n    parser.add_argument(\n        \"--date\", type=str, required=True, help=\"The date the exam will take place\"\n    )\n    args = parser.parse_args(argv)\n    process(args.exam_num, args.time, args.date)", "response": "Parse arguments and process the exam assignment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_profile_model():\n    auth_profile_module = getattr(settings, 'AUTH_PROFILE_MODULE', None)\n    profile_model = None\n    if auth_profile_module:\n        # get the profile model. TODO: super flacky, refactor\n        app_label, model = auth_profile_module.split('.')\n        profile_model = getattr(__import__(\"%s.models\" % app_label, \\\n                globals(), locals(), [model, ], -1), model, None)\n\n    return profile_model", "response": "Returns the user profile model"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the current status is on.", "response": "def is_on(self):\n        \"\"\"\n        Get sensor state.\n\n        Assume offline or open (worst case).\n        \"\"\"\n        return self.status not in (CONST.STATUS_OFF, CONST.STATUS_OFFLINE,\n                                   CONST.STATUS_CLOSED, CONST.STATUS_OPEN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the first yaml document as metadata.", "response": "def extract_meta(self, text):\n        \"\"\"\n        Takes input as the entire file.\n        Reads the first yaml document as metadata.\n        and the rest of the document as text\n        \"\"\"\n        first_line = True\n        metadata = []\n        content = []\n        metadata_parsed = False\n\n        for line in text.split('\\n'):\n            if first_line:\n                first_line = False\n                if line.strip() != '---':\n                    raise MetaParseException('Invalid metadata')\n                else:\n                    continue\n            if line.strip() == '' and not metadata_parsed:\n                continue\n            if line.strip() == '---' and not metadata_parsed:\n                # reached the last line\n                metadata_parsed = True\n            elif not metadata_parsed:\n                metadata.append(line)\n            else:\n                content.append(line)\n\n        content = '\\n'.join(content)\n        try:\n            metadata = yaml.load('\\n'.join(metadata))\n        except:\n            raise\n            content = text\n            metadata = yaml.load('')\n\n        return content, metadata"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_defaults(self):\n        for key, value in self.spec.items():\n            setattr(self, key.upper(), value.get(\"default\", None))", "response": "Add each model entry with it s default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_env(self):\n        for key, value in self.spec.items():\n            if value['type'] in (dict, list):\n                envar = (self.env_prefix + \"_\" + key).upper()\n                try:\n                    envvar = env.json(envar,\n                                      default=getattr(self, key.upper(), value.get('default')))\n                except ConfigurationError as _err:  #pragma: no cover\n                    print(_err)\n                    self.log.critical(f\"Error parsing json from env var. {os.environ.get(envar)}\")\n                    print(envar)\n                    raise\n            else:\n                envvar = env((self.env_prefix + \"_\" + key).upper(),\n                             default=getattr(self, key.upper(), value.get('default')),\n                             cast=value['type'])\n            setattr(self, key.upper(), envvar)", "response": "Load the environment variables from the model fron environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_args(self):\n        parser = ArgumentParser(description='',\n                                formatter_class=RawTextHelpFormatter)\n        parser.add_argument(\"--generate\", action=\"store\", dest='generate',\n                            choices=['command', 'docker-run', 'docker-compose',\n                                     'ini', 'env', 'kubernetes', 'readme', 'drone-plugin'],\n                            help=\"Generate a template \")\n        parser.add_argument(\"--settings\", action=\"store\", dest='settings',\n                            help=\"Specify a settings file. (ie settings.dev)\")\n        for key, value in self.spec.items():\n            if value['type'] in [str, int, float]:\n                parser.add_argument(f\"--{key.lower()}\", action=\"store\", dest=key,\n                                    type=value['type'],\n                                    choices=value.get(\"choices\"),\n                                    help=self.help(value))\n            elif value['type'] == bool:\n                parser.add_argument(f\"--{key.lower()}\", action=\"store\", dest=key,\n                                    type=lambda x:bool(strtobool(x)),\n                                    choices=value.get(\"choices\"),\n                                    help=self.help(value))\n            elif value['type'] == list:\n                parser.add_argument(f\"--{key.lower()}\", action=\"store\", dest=key,\n                                    nargs='+',\n                                    choices=value.get(\"choices\"),\n                                    help=self.help(value))\n            elif value['type'] == dict:\n                parser.add_argument(f\"--{key.lower()}\", action=\"store\", dest=key,\n                                    type=json.loads,\n                                    choices=value.get(\"choices\"),\n                                    help=self.help(value))\n        args, _unknown = parser.parse_known_args()\n        return args", "response": "Parse the cli args returning a dict of the args"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the args to the object", "response": "def add_args(self, args):\n        \"\"\" Add the args\n\n            Args:\n                args (namespace): The commandline args\n\n        \"\"\"\n        for key, value in vars(args).items():\n            if value is not None:\n                setattr(self, key.upper(), value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the contents of the ini file into the current object.", "response": "def load_ini(self, ini_file):\n        \"\"\" Load the contents from the ini file\n\n            Args:\n                ini_file (str): The file from which the settings should be loaded\n\n        \"\"\"\n        if ini_file and not os.path.exists(ini_file):\n            self.log.critical(f\"Settings file specified but not found. {ini_file}\")\n            sys.exit(1)\n        if not ini_file:\n            ini_file = f\"{self.cwd}/settings.ini\"\n        if os.path.exists(ini_file):\n            config = configparser.RawConfigParser(allow_no_value=True)\n            config.read(ini_file)\n            for key, value in self.spec.items():\n                entry = None\n                if value['type'] == str:\n                    entry = config.get(\"settings\", option=key.lower(), fallback=None)\n                elif value['type'] == bool:\n                    entry = config.getboolean(\"settings\", option=key.lower(), fallback=None)\n                elif value['type'] == int:\n                    entry = config.getint(\"settings\", option=key.lower(), fallback=None)\n                elif value['type'] == float:\n                    entry = config.getfloat(\"settings\", option=key.lower(), fallback=None)\n                elif value['type'] in [list, dict]:\n                    entries = config.get(\"settings\", option=key.lower(), fallback=None)\n                    if entries:\n                        try:\n                            entry = json.loads(entries)\n                        except json.decoder.JSONDecodeError as _err:  #pragma: no cover\n                            self.log.critical(f\"Error parsing json from ini file. {entries}\")\n                            sys.exit(1)\n                if entry is not None:\n                    setattr(self, key.upper(), entry)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck all required settings have been provided.", "response": "def check_required(self):\n        \"\"\" Check all required settings have been provided\n        \"\"\"\n        die = False\n        for key, value in self.spec.items():\n            if not getattr(self, key.upper()) and value['required']:\n                print(f\"{key} is a required setting. \"\n                      \"Set via command-line params, env or file. \"\n                      \"For examples, try '--generate' or '--help'.\")\n                die = True\n        if die:\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating sample settings for a specific locale", "response": "def generate(self):\n        \"\"\" Generate sample settings\n        \"\"\"\n        otype = getattr(self, 'GENERATE')\n        if otype:\n            if otype == 'env':\n                self.generate_env()\n            elif otype == \"command\":\n                self.generate_command()\n            elif otype == \"docker-run\":\n                self.generate_docker_run()\n            elif otype == \"docker-compose\":\n                self.generate_docker_compose()\n            elif otype == \"kubernetes\":\n                self.generate_kubernetes()\n            elif otype == 'ini':\n                self.generate_ini()\n            elif otype == 'readme':\n                self.generate_readme()\n            elif otype == 'drone-plugin':\n                self.generate_drone_plugin()\n\n        sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_env(self):\n        for key in sorted(list(self.spec.keys())):\n            if self.spec[key]['type'] in (dict, list):\n                value = f\"\\'{json.dumps(self.spec[key].get('example', ''))}\\'\"\n            else:\n                value = f\"{self.spec[key].get('example', '')}\"\n            print(f\"export {self.env_prefix}_{key.upper()}={value}\")", "response": "Generate sample environment variables"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a sample command for the current locale", "response": "def generate_command(self):\n        \"\"\" Generate a sample command\n        \"\"\"\n        example = []\n        example.append(f\"{sys.argv[0]}\")\n        for key in sorted(list(self.spec.keys())):\n            if self.spec[key]['type'] == list:\n                value = \" \".join(self.spec[key].get('example', ''))\n            elif self.spec[key]['type'] == dict:\n                value = f\"\\'{json.dumps(self.spec[key].get('example', ''))}\\'\"\n            else:\n                value = self.spec[key].get('example', '')\n            string = f\"     --{key.lower()} {value}\"\n            example.append(string)\n        print(\" \\\\\\n\".join(example))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_docker_run(self):\n        example = []\n        example.append(\"docker run -it\")\n        for key in sorted(list(self.spec.keys())):\n            if self.spec[key]['type'] in (dict, list):\n                value = f\"\\'{json.dumps(self.spec[key].get('example', ''))}\\'\"\n            else:\n                value = f\"{self.spec[key].get('example', '')}\"\n            string = f\"     -e {self.env_prefix}_{key.upper()}={value}\"\n            example.append(string)\n        example.append(\"     <container-name>\")\n        print(\" \\\\\\n\".join(example))", "response": "Generate a sample docker run for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_docker_compose(self):\n        example = {}\n        example['app'] = {}\n        example['app']['environment'] = []\n        for key in sorted(list(self.spec.keys())):\n            if self.spec[key]['type'] in (dict, list):\n                value = f\"\\'{json.dumps(self.spec[key].get('example', ''))}\\'\"\n            else:\n                value = f\"{self.spec[key].get('example', '')}\"\n            example['app']['environment'].append(f\"{self.env_prefix}_{key.upper()}={value}\")\n        print(yaml.dump(example, default_flow_style=False))", "response": "Generate a sample docker compose containing the current image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_ini(self):\n        example = []\n        example.append(\"[settings]\")\n        for key in sorted(list(self.spec.keys())):\n            if self.spec[key]['type'] in [list, dict]:\n                value = json.dumps(self.spec[key].get('example', ''))\n            else:\n                value = self.spec[key].get('example', '')\n            string = f\"{key.lower()}={value}\"\n            example.append(string)\n        print(\"\\n\".join(example))", "response": "Generate a sample ini file for the current locale"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_kubernetes(self):\n        example = {}\n        example['spec'] = {}\n        example['spec']['containers'] = []\n        example['spec']['containers'].append({\"name\": '', \"image\": '', \"env\": []})\n        for key, value in self.spec.items():\n            if value['type'] in (dict, list):\n                kvalue = f\"\\'{json.dumps(value.get('example', ''))}\\'\"\n            else:\n                kvalue = f\"{value.get('example', '')}\"\n            entry = {\"name\": f\"{self.env_prefix}_{key.upper()}\", \"value\": kvalue}\n            example['spec']['containers'][0]['env'].append(entry)\n        print(yaml.dump(example, default_flow_style=False))", "response": "Generate a sample kubernetes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_drone_plugin(self):\n        example = {}\n        example['pipeline'] = {}\n        example['pipeline']['appname'] = {}\n        example['pipeline']['appname']['image'] = \"\"\n        example['pipeline']['appname']['secrets'] = \"\"\n        for key, value in self.spec.items():\n            if value['type'] in (dict, list):\n                kvalue = f\"\\'{json.dumps(value.get('example', ''))}\\'\"\n            else:\n                kvalue = f\"{value.get('example', '')}\"\n            example['pipeline']['appname'][key.lower()] = kvalue\n        print(yaml.dump(example, default_flow_style=False))", "response": "Generate a sample drone plugin configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a readme with all the generators", "response": "def generate_readme(self):\n        \"\"\" Generate a readme with all the generators\n        \"\"\"\n        print(\"## Examples of settings runtime params\")\n        print(\"### Command-line parameters\")\n        print(\"```\")\n        self.generate_command()\n        print(\"```\")\n        print(\"###  Environment variables\")\n        print(\"```\")\n        self.generate_env()\n        print(\"```\")\n        print(\"###  ini file\")\n        print(\"```\")\n        self.generate_ini()\n        print(\"```\")\n        print(\"###  docker run\")\n        print(\"```\")\n        self.generate_docker_run()\n        print(\"```\")\n        print(\"###  docker compose\")\n        print(\"```\")\n        self.generate_docker_compose()\n        print(\"```\")\n        print(\"###  kubernetes\")\n        print(\"```\")\n        self.generate_kubernetes()\n        print(\"```\")\n        print(\"###  drone plugin\")\n        print(\"```\")\n        self.generate_drone_plugin()\n        print(\"```\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_exists(self, subdir, prefix, suffix):\n        real_path = os.path.join(self.STATIC_DIR, self.DIR, subdir, prefix + suffix)\n        return os.path.exists(real_path)", "response": "Returns True if the resource file exists otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_css(self, subdir, file_name_prefix):\n        suffix_maxify = '.css'\n        suffix_minify = '.min.css'\n        if self.minify and self.file_exists(subdir, file_name_prefix, suffix_minify):\n            self.resources_css.append(posixpath.join(self.DIR, subdir, file_name_prefix + suffix_minify))\n        elif self.file_exists(subdir, file_name_prefix, suffix_maxify):\n            self.resources_css.append(posixpath.join(self.DIR, subdir, file_name_prefix + suffix_maxify))\n        else:\n            file_path = os.path.join(self.STATIC_DIR, self.DIR, subdir, file_name_prefix + suffix_maxify)\n            raise IOError('Resource file not found: {0}'.format(file_path))", "response": "Adds a css file for this resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_dataframe_from_xls(desired_type: Type[T], file_path: str, encoding: str,\n                            logger: Logger, **kwargs) -> pd.DataFrame:\n    \"\"\"\n    We register this method rather than the other because pandas guesses the encoding by itself.\n\n    Also, it is easier to put a breakpoint and debug by trying various options to find the good one (in streaming mode\n    you just have one try and then the stream is consumed)\n\n    :param desired_type:\n    :param file_path:\n    :param encoding:\n    :param logger:\n    :param kwargs:\n    :return:\n    \"\"\"\n    return pd.read_excel(file_path, **kwargs)", "response": "Read a DataFrame from an Excel file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_df_or_series_from_csv(desired_type: Type[pd.DataFrame], file_path: str, encoding: str,\n                               logger: Logger, **kwargs) -> pd.DataFrame:\n    \"\"\"\n    Helper method to read a dataframe from a csv file. By default this is well suited for a dataframe with\n    headers in the first row, for example a parameter dataframe.\n\n    :param desired_type:\n    :param file_path:\n    :param encoding:\n    :param logger:\n    :param kwargs:\n    :return:\n    \"\"\"\n    if desired_type is pd.Series:\n        # as recommended in http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.from_csv.html\n        # and from http://stackoverflow.com/questions/15760856/how-to-read-a-pandas-series-from-a-csv-file\n\n        # TODO there should be a way to decide between row-oriented (squeeze=True) and col-oriented (index_col=0)\n        # note : squeeze=true only works for row-oriented, so we dont use it. We rather expect that a row-oriented\n        # dataframe would be convertible to a series using the df to series converter below\n        if 'index_col' not in kwargs.keys():\n            one_col_df = pd.read_csv(file_path, encoding=encoding, index_col=0, **kwargs)\n        else:\n            one_col_df = pd.read_csv(file_path, encoding=encoding, **kwargs)\n\n        if one_col_df.shape[1] == 1:\n            return one_col_df[one_col_df.columns[0]]\n        else:\n            raise Exception('Cannot build a series from this csv: it has more than two columns (one index + one value).'\n                            ' Probably the parsing chain $read_df_or_series_from_csv => single_row_or_col_df_to_series$'\n                            'will work, though.')\n    else:\n        return pd.read_csv(file_path, encoding=encoding, **kwargs)", "response": "Helper method to read a dataframe from a csv file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_default_pandas_parsers() -> List[AnyParser]:\n    return [SingleFileParserFunction(parser_function=read_dataframe_from_xls,\n                                     streaming_mode=False,\n                                     supported_exts={'.xls', '.xlsx', '.xlsm'},\n                                     supported_types={pd.DataFrame},\n                                     option_hints=pandas_parsers_option_hints_xls),\n            SingleFileParserFunction(parser_function=read_df_or_series_from_csv,\n                                     streaming_mode=False,\n                                     supported_exts={'.csv', '.txt'},\n                                     supported_types={pd.DataFrame, pd.Series},\n                                     option_hints=pandas_parsers_option_hints_csv),\n            ]", "response": "Utility method to return the default parsers able to parse a dictionary from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef single_row_or_col_df_to_dict(desired_type: Type[T], single_rowcol_df: pd.DataFrame, logger: Logger, **kwargs)\\\n        -> Dict[str, str]:\n    \"\"\"\n    Helper method to convert a dataframe with one row or one or two columns into a dictionary\n\n    :param desired_type:\n    :param single_rowcol_df:\n    :param logger:\n    :param kwargs:\n    :return:\n    \"\"\"\n    if single_rowcol_df.shape[0] == 1:\n        return single_rowcol_df.transpose()[0].to_dict()\n        # return {col_name: single_rowcol_df[col_name][single_rowcol_df.index.values[0]] for col_name in single_rowcol_df.columns}\n    elif single_rowcol_df.shape[1] == 2 and isinstance(single_rowcol_df.index, pd.RangeIndex):\n        # two columns but the index contains nothing but the row number : we can use the first column\n        d = single_rowcol_df.set_index(single_rowcol_df.columns[0])\n        return d[d.columns[0]].to_dict()\n    elif single_rowcol_df.shape[1] == 1:\n        # one column and one index\n        d = single_rowcol_df\n        return d[d.columns[0]].to_dict()\n    else:\n        raise ValueError('Unable to convert provided dataframe to a parameters dictionary : '\n                         'expected exactly 1 row or 1 column, found : ' + str(single_rowcol_df.shape) + '')", "response": "Helper method to convert a dataframe with one row or one or two columns into a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_default_pandas_converters() -> List[Union[Converter[Any, pd.DataFrame],\n                                                  Converter[pd.DataFrame, Any]]]:\n    \"\"\"\n    Utility method to return the default converters associated to dataframes (from dataframe to other type,\n    and from other type to dataframe)\n    :return:\n    \"\"\"\n    return [ConverterFunction(from_type=pd.DataFrame, to_type=dict, conversion_method=single_row_or_col_df_to_dict),\n            ConverterFunction(from_type=dict, to_type=pd.DataFrame, conversion_method=dict_to_df,\n                              option_hints=dict_to_single_row_or_col_df_opts),\n            ConverterFunction(from_type=pd.DataFrame, to_type=pd.Series,\n                              conversion_method=single_row_or_col_df_to_series)]", "response": "Utility method to return the default converters associated to dataframes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef full_subgraph(self, vertices):\n        subgraph_vertices = {v for v in vertices}\n        subgraph_edges = {edge\n                          for v in subgraph_vertices\n                          for edge in self._out_edges[v]\n                          if self._heads[edge] in subgraph_vertices}\n        subgraph_heads = {edge: self._heads[edge]\n                          for edge in subgraph_edges}\n        subgraph_tails = {edge: self._tails[edge]\n                          for edge in subgraph_edges}\n        return DirectedGraph._raw(\n            vertices=subgraph_vertices,\n            edges=subgraph_edges,\n            heads=subgraph_heads,\n            tails=subgraph_tails,\n        )", "response": "Return the full subgraph of this graph with the given vertices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a DirectedGraph from a collection of vertices and a mapping giving the vertices that each vertex is connected to.", "response": "def from_out_edges(cls, vertices, edge_mapper):\n        \"\"\"\n        Create a DirectedGraph from a collection of vertices and\n        a mapping giving the vertices that each vertex is connected to.\n\n        \"\"\"\n        vertices = set(vertices)\n        edges = set()\n        heads = {}\n        tails = {}\n\n        # Number the edges arbitrarily.\n        edge_identifier = itertools.count()\n        for tail in vertices:\n            for head in edge_mapper[tail]:\n                edge = next(edge_identifier)\n                edges.add(edge)\n                heads[edge] = head\n                tails[edge] = tail\n\n        return cls._raw(\n            vertices=vertices,\n            edges=edges,\n            heads=heads,\n            tails=tails,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a DirectedGraph from a collection of vertices and a collection of edge pairs giving links between the vertices and the edges.", "response": "def from_edge_pairs(cls, vertices, edge_pairs):\n        \"\"\"\n        Create a DirectedGraph from a collection of vertices\n        and a collection of pairs giving links between the vertices.\n\n        \"\"\"\n        vertices = set(vertices)\n        edges = set()\n        heads = {}\n        tails = {}\n\n        # Number the edges arbitrarily.\n        edge_identifier = itertools.count()\n        for tail, head in edge_pairs:\n            edge = next(edge_identifier)\n            edges.add(edge)\n            heads[edge] = head\n            tails[edge] = tail\n\n        return cls._raw(\n            vertices=vertices,\n            edges=edges,\n            heads=heads,\n            tails=tails,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef annotated(self):\n        annotated_vertices = {\n            vertex: AnnotatedVertex(\n                id=vertex_id,\n                annotation=six.text_type(vertex),\n            )\n            for vertex_id, vertex in zip(itertools.count(), self.vertices)\n        }\n\n        annotated_edges = [\n            AnnotatedEdge(\n                id=edge_id,\n                annotation=six.text_type(edge),\n                head=annotated_vertices[self.head(edge)].id,\n                tail=annotated_vertices[self.tail(edge)].id,\n            )\n            for edge_id, edge in zip(itertools.count(), self.edges)\n        ]\n\n        return AnnotatedGraph(\n            vertices=annotated_vertices.values(),\n            edges=annotated_edges,\n        )", "response": "Return an AnnotatedGraph with the same structure\n        as this graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the command provided in the working directory and return the result of the command.", "response": "def execute_command(working_dir, cmd, env_dict):\n    \"\"\"\n    execute_command: run the command provided in the working dir\n    specified adding the env_dict settings to the\n    execution environment\n\n    :param working_dir: path to directory to execute command\n       also gets added to the PATH\n    :param cmd: Shell command to execute\n    :param env_dict: dictionary of additional env vars to\n      be passed to the subprocess environment\n\n    \"\"\"\n    proc_env = os.environ.copy()\n    proc_env[\"PATH\"] = \"{}:{}:.\".format(proc_env[\"PATH\"], working_dir)\n    proc_env.update(env_dict)\n    proc = subprocess.Popen(\n        cmd,\n        cwd=working_dir,\n        env=proc_env,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    status = proc.wait()\n    stdout, stderr = proc.communicate()\n    if status:\n        msg = (\n            \"Non zero {} exit from command {}\\n\"\n            \"Stdout: {}\\n\"\n            \"Stderr: {}\\n\"\n        ).format(status, cmd, stdout, stderr)\n        LOGGER.error(msg)\n        raise RuntimeError(msg)\n    LOGGER.info(stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread and populate the internal object with the values from the dotfile and populate the internal object with the values from the options", "response": "def load(self):\n        \"\"\"\n        read dotfile and populate self\n        opts will override the dotfile settings,\n        make sure everything is synced in both\n        opts and this object\n\n        \"\"\"\n        if self.exists():\n            with open(self.dot_file, 'r') as handle:\n                self.update(json.load(handle))\n        if self.options['context'] is not None:\n            self['context'] = self.options['context']\n        else:\n            self.options['context'] = self['context']\n        if self.options['defaults'] is not None:\n            self['defaults'] = self.options['defaults']\n        else:\n            self.options['defaults'] = self['defaults']\n        if self.options['output'] is not None:\n            self['output'] = self.options['output']\n\n        if self.options.get('inclusive', False):\n            self['inclusive'] = True\n\n        if self.options.get('exclude', []):\n            self['exclude'].extend(self.options['exclude'])\n\n        if self['output'] is None:\n            self['output'] = os.path.join(os.getcwd(), 'dockerstache-output')\n        self['output_path'] = self.abs_output_dir()\n        self['input_path'] = self.abs_input_dir()\n        if self['context'] is not None:\n            self['context_path'] = absolute_path(self['context'])\n        if self['defaults'] is not None:\n            self['defaults_path'] = absolute_path(self['defaults'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef env_dictionary(self):\n        none_to_str = lambda x: str(x) if x else \"\"\n        return {\"DOCKERSTACHE_{}\".format(k.upper()): none_to_str(v) for k, v in six.iteritems(self)}", "response": "convert the options to this script into an an\n        env var dictionary for pre and post scripts\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the pre script if it is defined", "response": "def pre_script(self):\n        \"\"\"\n        execute the pre script if it is defined\n        \"\"\"\n        if self['pre_script'] is None:\n            return\n        LOGGER.info(\"Executing pre script: {}\".format(self['pre_script']))\n        cmd = self['pre_script']\n        execute_command(self.abs_input_dir(), cmd, self.env_dictionary())\n        LOGGER.info(\"Pre Script completed\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaying a text to speakers or to file.", "response": "def say(\n    text               = None,\n    preference_program = \"festival\",\n    background         = False,\n    silent             = True,\n    filepath           = None\n    ):\n    \"\"\"\n    Say specified text to speakers or to file, as specified. Determine the\n    program to use based on the specified program preference and availability,\n    then say the text to speakers or synthesize speech of the text and save it\n    to file, as specified.\n    \"\"\"\n    if not text:\n        if not silent:\n            print(\"text not specified\")\n        return False\n    # Determine the program to use based on program preference and program\n    # availability.\n    preference_order_programs = [\n        \"festival\",\n        \"espeak\",\n        \"pico2wave\",\n        \"deep_throat.py\"\n    ]\n    # Remove the specified preference program from the default program\n    # preferences order and prioritise it.\n    preference_order_programs.remove(preference_program)\n    preference_order_programs.insert(0, preference_program)\n    # Determine first program that is available in the programs order of\n    # preference.\n    preference_order_programs_available =\\\n        [program for program in preference_order_programs \\\n            if shijian.which(program) is not None]\n    if not preference_order_programs_available:\n        if not silent:\n            print(\"text-to-speech program unavailable\")\n        return False\n    program = preference_order_programs_available[0]\n    if program != preference_program and not silent:\n        print(\"text-to-speech preference program unavailable, using {program}\".format(program = program))\n    if program == \"festival\":\n        if not filepath:\n            command = \"\"\"\n            echo \"{text}\" | festival --tts\n            \"\"\".format(text = text)\n        else:\n            command = \"\"\"\n            echo \"{text}\" | text2wave -o {filepath}\n            \"\"\".format(text = text, filepath = filepath)\n    elif program == \"espeak\":\n        if not filepath:\n            command = \"\"\"\n            echo \"{text}\" | espeak\n            \"\"\".format(text = text)\n        else:\n            command = \"\"\"\n            echo \"{text}\" | espeak -w {filepath}\n            \"\"\".format(text = text, filepath = filepath)\n    elif program == \"pico2wave\":\n        if not filepath:\n            command = \"\"\"\n            pico2wave --wave=\"{filepath}\" \"{text}\"\n            aplay --quiet \"{filepath}\"\n            \"\"\".format(text = text, filepath = shijian.tmp_filepath() + \".wav\")\n        else:\n            command = \"\"\"\n            pico2wave --wave=\"{filepath}\" \"{text}\"\n            \"\"\".format(text = text, filepath = filepath)\n    elif program == \"deep_throat.py\":\n        if not filepath:\n            command = \"\"\"\n            echo \"{text}\" | deep_throat.py\n            \"\"\".format(text = text)\n        else:\n            command = \"\"\"\n            deep_throat.py --text=\"{text}\" --savetowavefile --outfile=\"{filepath}\"\n            \"\"\".format(text = text, filepath = filepath)\n    if filepath:\n        background = False\n    if background:\n        command = command.rstrip().rstrip(\"\\n\") + \" &\"\n    command = textwrap.dedent(command)\n    engage_command(command = command, background = background)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsays specified text to a temporary file and return the filepath.", "response": "def say_tmp_filepath(\n    text               = None,\n    preference_program = \"festival\"\n    ):\n    \"\"\"\n    Say specified text to a temporary file and return the filepath.\n    \"\"\"\n    filepath = shijian.tmp_filepath() + \".wav\"\n    say(\n        text               = text,\n        preference_program = preference_program,\n        filepath           = filepath\n    )\n    return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clacks_overhead(fn):\n    @wraps(fn)\n    def _wrapped(*args, **kw):\n        response = fn(*args, **kw)\n        response['X-Clacks-Overhead'] = 'GNU Terry Pratchett'\n        return response\n\n    return _wrapped", "response": "A decorator that will add the X - Clacks - Overhead header to the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a response that will contain the rendered PDF.", "response": "def render(self, request, template, context):\n        \"\"\"\n        Returns a response. By default, this will contain the rendered PDF, but\n        if both ``allow_force_html`` is ``True`` and the querystring\n        ``html=true`` was set it will return a plain HTML.\n        \"\"\"\n        if self.allow_force_html and self.request.GET.get('html', False):\n            html = get_template(template).render(context)\n            return HttpResponse(html)\n        else:\n            response = HttpResponse(content_type='application/pdf')\n            if self.prompt_download:\n                response['Content-Disposition'] = 'attachment; filename=\"{}\"' \\\n                    .format(self.get_download_name())\n            helpers.render_pdf(\n                template=template,\n                file_=response,\n                url_fetcher=self.url_fetcher,\n                context=context,\n            )\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind all the state access strings for every state in the DFA", "response": "def _bfs_path_states(self, graph, start):\n        \"\"\"\n        Find state access strings (DFA shortest paths for every state)\n        using BFS\n        Args:\n            graph (DFA): The DFA states\n            start (int): The DFA initial state\n        Return:\n            list: A list of all the DFA shortest paths for every state\n        \"\"\"\n        pathstates = {}\n        # maintain a queue of paths\n        queue = []\n        visited = []\n        # push the first path into the queue\n        queue.append([['', start]])\n        while queue:\n            # get the first path from the queue\n            path = queue.pop(0)\n            # get the last node from the path\n            node = path[-1][1]\n            # path found \"\"\"\n            if node.stateid not in pathstates and node.stateid != len(list(graph.states)):\n                pathstates[node.stateid] = ''.join(\n                    [mnode[0] for mnode in path])\n            visited.append(node.stateid)\n            # enumerate all adjacent nodes, construct a new path and push it\n            # into the queue\n            for arc in node.arcs:\n                char = graph.isyms.find(arc.ilabel)\n                next_state = graph[arc.nextstate]\n                if next_state.stateid not in visited:\n                    new_path = list(path)\n                    new_path.append([char, next_state])\n                    queue.append(new_path)\n        return pathstates"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the accepted states in the DFA", "response": "def _get_accepted(self, graph):\n        \"\"\"\n        Find the accepted states\n        Args:\n            graph (DFA): The DFA states\n        Return:\n            list: Returns the list of the accepted states\n        \"\"\"\n        accepted = []\n        for state in graph.states:\n            if state.final != TropicalWeight(float('inf')):\n                accepted.append(state)\n        return accepted"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a list of objects into a list of state ids.", "response": "def _object_set_to_state_list(self, objectset):\n        \"\"\"\n        Args:\n            objectset (list): A list of all the DFA states (as objects)\n        Return:\n            list: A list of all the DFA states (as identifiers)\n        \"\"\"\n        state_list = []\n        for state in list(objectset):\n            state_list.append(state.stateid)\n        return state_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the group index that the state belongs to", "response": "def _get_group_from_state(self, sid):\n        \"\"\"\n        Args:\n            sid (int): The state identifier\n        Return:\n            int: The group identifier that the state belongs\n        \"\"\"\n        for index, selectgroup in enumerate(self.groups):\n            if sid in selectgroup:\n                return index"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _reverse_to_source(self, target, group1):\n        new_group = []\n        for dst in group1:\n            new_group += target[dst]\n        return set(new_group)", "response": "Reverse the states of the state in the group1 to the source state."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npartitions the set of states in a group into two sets.", "response": "def _partition_group(self, group):\n        \"\"\"\n        Args:\n            group (list):  A group of states\n        Return:\n            tuple: A set of two groups\n        \"\"\"\n        for (group1, group2, distinguish_string) in self.bookeeping:\n            if group & group1 != set() and not group.issubset(group1):\n                new_g1 = group & group1\n                new_g2 = group - group1\n                return (new_g1, new_g2, distinguish_string)\n            if group & group2 != set() and not group.issubset(group2):\n                new_g1 = group & group2\n                new_g2 = group - group2\n                return (new_g1, new_g2, distinguish_string)\n        assert False, \"Unmatched group partition\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_using_k_equivalence(self, given_graph, sfa=False):\n        graph = DFA(self.alphabet)\n        graph.init_from_acceptor(given_graph)\n        graph.fixminimized(self.alphabet)\n\n        # Access Strings\n        self.access_strings_map = self._bfs_path_states(graph, sorted(\n            graph.states, key=attrgetter('initial'), reverse=True)[0])\n\n        # Find Q\n        set_q = set(self._object_set_to_state_list(graph.states))\n        # We will work with states addresses here instead of states stateid for\n        # more convenience\n        set_f = set(self._object_set_to_state_list(self._get_accepted(graph)))\n        # Perform P := {F, Q-F}\n        set_nf = set_q.copy() - set_f.copy()\n        self.groups = [set_f.copy(), set_nf.copy()]\n        self.bookeeping = [(set_f, set_nf, '')]\n\n        done = False\n        while not done:\n            done = True\n            new_groups = []\n            for selectgroup in self.groups:\n                # _check for each letter if it splits the current group\n                for character in self.alphabet:\n                    # print 'Testing symbol: ', c\n                    target = defaultdict(list)\n                    target_states = defaultdict(int)\n                    new_g = [set(selectgroup)]\n                    for sid in selectgroup:\n                        # _check if all transitions using c are going in a state\n                        # in the same group. If they are going on a different\n                        # group then split\n                        deststate = self._delta(graph, graph[sid], character)\n                        destgroup = self._get_group_from_state(\n                            deststate.stateid)\n                        target[destgroup].append(sid)\n                        target_states[destgroup] = deststate.stateid\n                    if len(target) > 1:\n\n                        inv_target_states = {\n                            v: k for k, v in target_states.iteritems()}\n                        new_g = [set(selectedstate) for selectedstate in target.values()]\n                        done = False\n                        # Get all the partitions of destgroups\n                        queue = [set([x for x in target_states.values()])]\n                        while queue:\n                            top = queue.pop(0)\n                            (group1, group2, distinguish_string) = self._partition_group(top)\n                            ng1 = self._reverse_to_source(\n                                target, [inv_target_states[x] for x in group1])\n                            ng2 = self._reverse_to_source(\n                                target, [inv_target_states[x] for x in group2])\n                            dist_string = character + distinguish_string\n\n                            self.bookeeping.append((ng1, ng2, dist_string))\n\n                            if len(group1) > 1:\n                                queue.append(group1)\n                            if len(group2) > 1:\n                                queue.append(group2)\n                        break\n                new_groups += new_g\n\n            # End of iteration for the k-equivalence\n            # Assign new groups and check if any change occured\n            self.groups = new_groups\n\n        sm_vector = [\n            i for (a, i) in sorted(\n                self.access_strings_map.items(),\n                key=lambda x: len(x[1]))]\n        if not sfa:\n            smi_vector = ['{}{}'.format(a, b)\n                          for b in self.alphabet for a in sm_vector]\n        else:\n            smi_vector = self._init_smi(graph, self.access_strings_map)\n        em_vector = [distinguish_string for (_, _, distinguish_string) in self.bookeeping]\n\n        return sm_vector, smi_vector, em_vector", "response": "Initialize the internal state machine for a given state machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the internal state machine and the internal state machine vectors for the given DFA states.", "response": "def initialize(self, givengraph, sfa=False):\n        \"\"\"\n        Args:\n            givengraph (DFA): The DFA states\n            sfa (bool): A boolean for chosing SFA\n        Return:\n            list, list, list: sm_vector, smi_vector, em_vector initialization vectors\n        \"\"\"\n        sm_vector, smi_vector, em_vector = self._init_using_k_equivalence(\n            givengraph, sfa)\n        return sm_vector, smi_vector, em_vector"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push(self,message,message_type):\n            \n        super(Producer,self).send(message,message_type)", "response": "Send a reply message of the given type to the given topic"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction that returns a Formatoption class for modifying the fontweight of the given base.", "response": "def label_weight(base, label_name=None, children=[], parents=[],\n                 dependencies=[]):\n    \"\"\"\n    Function that returns a Formatoption class for modifying the fontweight\n\n    This function returns a :class:`~psyplot.plotter.Formatoption` instance\n    that modifies the weight of the given `base` formatoption\n\n    Parameters\n    ----------\n    base: Formatoption\n        The base formatoption instance that is used in the\n        :class:`psyplot.Plotter` subclass to create the label. The instance\n        must have a ``texts`` attribute which stores all the\n        :class:`matplotlib.text.Text` instances.\n    label_name: str\n        The name of the label to use in the documentation. If None,\n        it will be ``key``, where ``key`` is the\n        :attr:`psyplot.plotter.Formatoption.key`` attribute of `base`\n    children: list of str\n        The childrens of the resulting formatoption class (besides the `base`\n        formatoption which is included anyway)\n    parents: list of str\n        The parents of the resulting formatoption class (besides the `base`\n        the properties formatoption from `base` (see :func:`label_props`))\n    dependencies: list of str\n        The dependencies of the formatoption\n\n    Returns\n    -------\n    Formatoption\n        The formatoption instance that modifies the fontweight of `base`\n\n    See Also\n    --------\n    label_size, label_props, Figtitle, Title\"\"\"\n    label_name = label_name or base.key\n    cl_children = children\n    cl_parents = parents\n    cl_dependencies = dependencies\n\n    class LabelWeight(Formatoption):\n        __doc__ = \"\"\"\n        Set the fontweight of the %s\n\n        Possible types\n        --------------\n        %%(fontweights)s\n\n        See Also\n        --------\n        %s, %s, %s\"\"\" % (label_name, base.key, base.key + 'size',\n                         base.key + 'props')\n        children = [base.key] + \\\n            cl_children\n        parent = [base.key + 'props'] + cl_parents\n        dependencies = cl_dependencies\n\n        group = 'labels'\n\n        name = 'Font weight of ' + (base.name or base.key)\n\n        def update(self, value):\n            for text in getattr(self, base.key).texts:\n                text.set_weight(value)\n\n        def get_fmt_widget(self, parent, project):\n            \"\"\"Get a widget with the different font weights\"\"\"\n            from psy_simple.widgets.texts import FontWeightWidget\n            return FontWeightWidget(\n                parent, self, next(iter(getattr(self, base.key).texts), None),\n                base)\n\n    return LabelWeight(base.key + 'weight')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef label_size(base, label_name=None, children=[], parents=[],\n               dependencies=[]):\n    \"\"\"\n    Function that returns a Formatoption class for modifying the fontsite\n\n    This function returns a :class:`~psyplot.plotter.Formatoption` instance\n    that modifies the size of the given `base` formatoption\n\n    Parameters\n    ----------\n    %(label_weight.parameters)s\n\n    Returns\n    -------\n    Formatoption\n        The formatoption instance that modifies the fontsize of `base`\n\n    See Also\n    --------\n    label_weight, label_props, Figtitle, Title\"\"\"\n    label_name = label_name or base.key\n    cl_children = children\n    cl_parents = parents\n    cl_dependencies = dependencies\n\n    class LabelSize(Formatoption):\n        __doc__ = \"\"\"\n        Set the size of the %s\n\n        Possible types\n        --------------\n        %%(fontsizes)s\n\n        See Also\n        --------\n        %s, %s, %s\"\"\" % (label_name, base.key, base.key + 'weight',\n                         base.key + 'props')\n        children = [base.key] + cl_children\n        parent = [base.key + 'props'] + cl_parents\n        dependencies = cl_dependencies\n\n        group = 'labels'\n\n        name = 'Font size of ' + (base.name or base.key)\n\n        def update(self, value):\n            for text in getattr(self, base.key).texts:\n                text.set_size(value)\n\n        def get_fmt_widget(self, parent, project):\n            \"\"\"Get a widget with the different font weights\"\"\"\n            from psy_simple.widgets.texts import FontSizeWidget\n            return FontSizeWidget(\n                parent, self, next(iter(getattr(self, base.key).texts), None),\n                base)\n\n    return LabelSize(base.key + 'size')", "response": "Returns a new formatoption that has the same font sizes as the base."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef label_props(base, label_name=None, children=[], parents=[],\n                dependencies=[]):\n    \"\"\"\n    Function that returns a Formatoption class for modifying the fontsite\n\n    This function returns a :class:`~psyplot.plotter.Formatoption` instance\n    that modifies the size of the given `base` formatoption\n\n    Parameters\n    ----------\n    %(label_weight.parameters)s\n    children: list of str\n        The childrens of the resulting formatoption class (besides the `base`\n        formatoption, the ``base.key + 'size'`` and ``base.key + 'weight'``\n        keys, which are included anyway (see :func:`label_size`,\n        :func:`label_weight`))\n    parents: list of str\n        The parents of the resulting formatoption class\n\n    Returns\n    -------\n    Formatoption\n        The formatoption instance that modifies the fontsize of `base`\n\n    See Also\n    --------\n    label_weight, label_props, Figtitle, Title\"\"\"\n    label_name = label_name or base.key\n    cl_children = children\n    cl_parents = parents\n    cl_dependencies = dependencies\n\n    class LabelProps(Formatoption):\n        __doc__ = \"\"\"\n        Properties of the %s\n\n        Specify the font properties of the figure title manually.\n\n        Possible types\n        --------------\n        dict\n            Items may be any valid text property\n\n        See Also\n        --------\n        %s, %s, %s\"\"\" % (label_name, base.key, base.key + 'size',\n                         base.key + 'weight')\n        children = [base.key, base.key + 'size', base.key + 'weight'] + \\\n            cl_children\n        parents = cl_parents\n        dependencies = cl_dependencies\n\n        group = 'labels'\n\n        name = 'Font properties of ' + (base.name or base.key)\n\n        def __init__(self, *args, **kwargs):\n            super(LabelProps, self).__init__(*args, **kwargs)\n            self.default_props = {}\n            self._todefault = False\n\n        def set_value(self, value, validate=True, todefault=False):\n            self._todefault = todefault\n            super(LabelProps, self).set_value(value, validate, todefault)\n\n        def update(self, fontprops):\n            fontprops = fontprops.copy()\n            # store default font properties\n            try:\n                text = next(iter(getattr(self, base.key).texts))\n            except StopIteration:\n                return\n            # TODO: This handling of the default management is not really\n            # satisfying because you run into troubles when using alternate\n            # property names (e.g. if you use 'ha' and 'horizontalalignment'\n            # at the same time)\n            if not self._todefault:\n                for key in fontprops:\n                    if key == 'bbox':\n                        default = dict(facecolor='none', edgecolor='none')\n                    else:\n                        default = getattr(text, 'get_' + key)()\n                    self.default_props.setdefault(key, default)\n            else:\n                fontprops = self.default_props.copy()\n                self.default_props.clear()\n            if 'size' not in fontprops and 'fontsize' not in fontprops:\n                fontprops['size'] = getattr(self, base.key + 'size').value\n            if 'weight' not in fontprops and 'fontweight' not in fontprops:\n                fontprops['weight'] = getattr(self, base.key + 'weight').value\n            for text in getattr(self, base.key).texts:\n                text.update(fontprops)\n            self._todefault = False\n\n        def get_fmt_widget(self, parent, project):\n            \"\"\"Get a widget with the different font weights\"\"\"\n            from psy_simple.widgets.texts import FontPropertiesWidget\n            return FontPropertiesWidget(\n                parent, self, next(iter(getattr(self, base.key).texts), None),\n                base)\n\n    return LabelProps(base.key + 'props')", "response": "Function that returns a Formatoption class for modifying the font properties of the given base."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces the attributes of the plotter data in a string s with inserted informations.", "response": "def replace(self, s, data, attrs=None):\n        \"\"\"\n        Replace the attributes of the plotter data in a string\n\n        %(replace_note)s\n\n        Parameters\n        ----------\n        s: str\n            String where the replacements shall be made\n        data: InteractiveBase\n            Data object from which to use the coordinates and insert the\n            coordinate and attribute informations\n        attrs: dict\n            Meta attributes that shall be used for replacements. If None, it\n            will be gained from `data.attrs`\n\n        Returns\n        -------\n        str\n            `s` with inserted informations\"\"\"\n        # insert labels\n        s = s.format(**self.rc['labels'])\n        # replace attributes\n        attrs = attrs or data.attrs\n        if hasattr(getattr(data, 'psy', None), 'arr_name'):\n            attrs = attrs.copy()\n            attrs['arr_name'] = data.psy.arr_name\n        s = safe_modulo(s, attrs)\n        # replace datetime.datetime like time informations\n        if isinstance(data, InteractiveList):\n            data = data[0]\n        tname = self.any_decoder.get_tname(\n            next(self.plotter.iter_base_variables), data.coords)\n        if tname is not None and tname in data.coords:\n            time = data.coords[tname]\n            if not time.values.ndim:\n                try:  # assume a valid datetime.datetime instance\n                    s = pd.to_datetime(str(time.values[()])).strftime(s)\n                except ValueError:\n                    pass\n        if six.PY2:\n            return s.decode('utf-8')\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary with all the meta attributes joined by the specified delimiter.", "response": "def get_fig_data_attrs(self, delimiter=None):\n        \"\"\"Join the data attributes with other plotters in the project\n\n        This method joins the attributes of the\n        :class:`~psyplot.InteractiveBase` instances in the project that\n        draw on the same figure as this instance does.\n\n        Parameters\n        ----------\n        delimiter: str\n            Specifies the delimiter with what the attributes are joined. If\n            None, the :attr:`delimiter` attribute of this instance or (if the\n            latter is also None), the rcParams['texts.delimiter'] item is used.\n\n        Returns\n        -------\n        dict\n            A dictionary with all the meta attributes joined by the specified\n            `delimiter`\"\"\"\n        if self.project is not None:\n            delimiter = next(filter(lambda d: d is not None, [\n                delimiter, self.delimiter, self.rc['delimiter']]))\n            figs = self.project.figs\n            fig = self.ax.get_figure()\n            if self.plotter._initialized and fig in figs:\n                ret = figs[fig].joined_attrs(delimiter=delimiter,\n                                             plot_data=True)\n            else:\n                ret = self.get_enhanced_attrs(self.plotter.plot_data)\n                self.logger.debug(\n                    'Can not get the figure attributes because plot has not '\n                    'yet been initialized!')\n            return ret\n        else:\n            return self.get_enhanced_attrs(self.plotter.plot_data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a combobox with the attributes", "response": "def get_fmt_widget(self, parent, project):\n        \"\"\"Create a combobox with the attributes\"\"\"\n        from psy_simple.widgets.texts import LabelWidget\n        return LabelWidget(parent, self, project)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_other_texts(self, remove=False):\n        fig = self.ax.get_figure()\n        # don't do anything if our figtitle is the only Text instance\n        if len(fig.texts) == 1:\n            return\n        for i, text in enumerate(fig.texts):\n            if text == self._text:\n                continue\n            if text.get_position() == self._text.get_position():\n                if not remove:\n                    text.set_text('')\n                else:\n                    del fig[i]", "response": "This method clears all other Text instances in the figure that are at the same position as this one."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a texttuple from the value in the plotter Taxonomy", "response": "def _remove_texttuple(self, pos):\n        \"\"\"Remove a texttuple from the value in the plotter\n\n        Parameters\n        ----------\n        pos: tuple (x, y, cs)\n            x and y are the x- and y-positions and cs the coordinate system\"\"\"\n        for i, (old_x, old_y, s, old_cs, d) in enumerate(self.value):\n            if (old_x, old_y, old_cs) == pos:\n                self.value.pop(i)\n                return\n        raise ValueError(\"{0} not found!\".format(pos))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the text tuple at x y with the given s and d", "response": "def _update_texttuple(self, x, y, s, cs, d):\n        \"\"\"Update the text tuple at `x` and `y` with the given `s` and `d`\"\"\"\n        pos = (x, y, cs)\n        for i, (old_x, old_y, old_s, old_cs, old_d) in enumerate(self.value):\n            if (old_x, old_y, old_cs) == pos:\n                self.value[i] = (old_x, old_y, s, old_cs, d)\n                return\n        raise ValueError(\"No text tuple found at {0}!\".format(pos))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshares the settings of this formatoption with other data objects.", "response": "def share(self, fmto, **kwargs):\n        \"\"\"Share the settings of this formatoption with other data objects\n\n        Parameters\n        ----------\n        fmto: Formatoption\n            The :class:`Formatoption` instance to share the attributes with\n        ``**kwargs``\n            Any other keyword argument that shall be passed to the update\n            method of `fmto`\n\n        Notes\n        -----\n        The Text formatoption sets the 'texts_to_remove' keyword to the\n        :attr:`_texts_to_remove` attribute of this instance (if not already\n        specified in ``**kwargs``\"\"\"\n        kwargs.setdefault('texts_to_remove', self._texts_to_remove)\n        super(Text, self).share(fmto, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, *args, **kwargs):\n\n        self.slug = uuslug(\n            self.name,\n            instance=self,\n            max_length=100,\n            separator='-',\n            start_no=2\n        )\n        if not self.uid:\n            self.uid = 'organization:{}'.format(self.slug)\n\n        super(Organization, self).save(*args, **kwargs)", "response": "Save the object to the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_variables(self, source: str, variables: dict) -> str:\n        try:\n            replaced = re.sub(\n                \"{{(.*?)}}\", lambda m: variables.get(m.group(1), \"\"), source\n            )\n        except TypeError:\n            replaced = source\n        return replaced", "response": "Replace {{ variable - name } with stored value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preprocess_cell(\n        self, cell: \"NotebookNode\", resources: dict, index: int\n    ) -> Tuple[\"NotebookNode\", dict]:\n        \"\"\"Preprocess cell.\n\n        Parameters\n        ----------\n        cell : NotebookNode cell\n            Notebook cell being processed\n        resources : dictionary\n            Additional resources used in the conversion process. Allows\n            preprocessors to pass variables into the Jinja engine.\n        cell_index : int\n            Index of the cell being processed (see base.py)\n\n        \"\"\"\n        if cell.cell_type == \"markdown\":\n            variables = cell[\"metadata\"].get(\"variables\", {})\n            if len(variables) > 0:\n                cell.source = self.replace_variables(cell.source, variables)\n                if resources.get(\"delete_pymarkdown\", False):\n                    del cell.metadata[\"variables\"]\n        return cell, resources", "response": "Preprocess cell.\n\n        Parameters\n        ----------\n        cell : NotebookNode cell\n            Notebook cell being processed\n        resources : dictionary\n            Additional resources used in the conversion process. Allows\n            preprocessors to pass variables into the Jinja engine.\n        cell_index : int\n            Index of the cell being processed (see base.py)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefaults emit method that returns codegen reg and codegen", "response": "def emit(self, ast_reg, ast_guide):\n        ''' Default emit method: visit both ASTs and return the codegen '''\n        if (ast_reg):\n            self.visit(ast_reg)\n        codegen_reg = self.codegen\n        self.codegen = self.cg_type()\n        if (ast_guide):\n            self.visit(ast_guide)\n        return (codegen_reg, self.codegen)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index_dir(self, folder):\n        folder_path = folder\n        print('Indexing folder: ' + folder_path)\n        nested_dir = {}\n        folder = folder_path.rstrip(os.sep)\n        start = folder.rfind(os.sep) + 1\n        for root, dirs, files in os.walk(folder):\n            folders = root[start:].split(os.sep)\n            # subdir = dict.fromkeys(files)\n            subdir = {}\n            for f in files:\n                # Create an entry for every markdown file\n                if os.path.splitext(f)[1] == '.md':\n                    with open(os.path.abspath(os.path.join(root, f)), encoding='utf-8') as fp:\n                        try:\n                            _, meta = self.mrk.extract_meta(fp.read())\n                        except:\n                            print(\"Skipping indexing \" + f +\"; Could not parse metadata\")\n                            meta = {'title': f}\n                            pass\n                    # Value of the entry (the key) is it's metadata\n                    subdir[f] = meta\n            parent = nested_dir\n            for fold in folders[:-1]:\n                parent = parent.get(fold)\n            # Attach the config of all children nodes onto the parent\n            parent[folders[-1]] = subdir\n        return nested_dir", "response": "Creates a nested dictionary that represents the folder structure of folder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_orders(self, orders):\n\n        result = {}\n\n        for index, order in enumerate(orders):\n            for detail, value in order.iteritems():\n                result[\"ORDER_%s[%s]\" % (detail, index)] = value\n\n        return result", "response": "Transform the list of orders into a list of arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the weighted average of the given detections and predictions.", "response": "def average_detections(detections, predictions, relative_prediction_threshold = 0.25):\n  \"\"\"average_detections(detections, predictions, [relative_prediction_threshold]) -> bounding_box, prediction\n\n  Computes the weighted average of the given detections, where the weights are computed based on the prediction values.\n\n  **Parameters:**\n\n  ``detections`` : [:py:class:`BoundingBox`]\n    The overlapping bounding boxes.\n\n  ``predictions`` : [float]\n    The predictions for the ``detections``.\n\n  ``relative_prediction_threshold`` : float between 0 and 1\n    Limits the bounding boxes to those that have a prediction value higher then ``relative_prediction_threshold * max(predictions)``\n\n  **Returns:**\n\n  ``bounding_box`` : :py:class:`BoundingBox`\n    The bounding box which has been merged from the detections\n\n  ``prediction`` : float\n    The prediction value of the bounding box, which is a weighted sum of the predictions with minimum overlap\n  \"\"\"\n  # remove the predictions that are too low\n  prediction_threshold = relative_prediction_threshold * max(predictions)\n  detections, predictions = zip(*[[d,p] for d,p in zip(detections, predictions) if p >= prediction_threshold])\n\n  # turn remaining predictions into weights\n  s = sum(predictions)\n  weights = [p/s for p in predictions]\n  # compute weighted average of bounding boxes\n  top = sum(w * b.topleft_f[0] for w, b in zip(weights, detections))\n  left = sum(w * b.topleft_f[1] for w, b in zip(weights, detections))\n  bottom = sum(w * b.bottomright_f[0] for w, b in zip(weights, detections))\n  right = sum(w * b.bottomright_f[1] for w, b in zip(weights, detections))\n\n  # compute the average prediction value\n  value = sum(w*p for w,p in zip(weights, predictions))\n\n  # return the average bounding box\n  return BoundingBox((top, left), (bottom-top, right-left)), value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detect_single_face(image, cascade = None, sampler = None, minimum_overlap=0.2, relative_prediction_threshold = 0.25):\n\n  if cascade is None:\n    cascade = default_cascade()\n  elif isinstance(cascade, str):\n    cascade = Cascade(bob.io.base.HDF5File(cascade))\n\n  if sampler is None:\n    sampler = Sampler(patch_size = cascade.extractor.patch_size, distance=2, scale_factor=math.pow(2.,-1./16.), lowest_scale=0.125)\n\n  if image.ndim == 3:\n    image = bob.ip.color.rgb_to_gray(image)\n\n  detections = []\n  predictions = []\n  # get the detection scores for the image\n  for prediction, bounding_box in sampler.iterate_cascade(cascade, image, None):\n    detections.append(bounding_box)\n    predictions.append(prediction)\n\n  if not detections:\n    return None\n\n  # compute average over the best locations\n  bb, quality = best_detection(detections, predictions, minimum_overlap, relative_prediction_threshold)\n\n  return bb, quality", "response": "Detects a single face in the given image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect all faces in the given image.", "response": "def detect_all_faces(image, cascade = None, sampler = None, threshold = 0, overlaps = 1, minimum_overlap = 0.2, relative_prediction_threshold = 0.25):\n  \"\"\"detect_all_faces(image, [cascade], [sampler], [threshold], [overlaps], [minimum_overlap], [relative_prediction_threshold]) -> bounding_boxes, qualities\n\n  Detects all faces in the given image, whose prediction values are higher than the given threshold.\n\n  If the given ``minimum_overlap`` is lower than 1, overlapping bounding boxes are grouped, with the ``minimum_overlap`` being the minimum Jaccard similarity between two boxes to be considered to be overlapping.\n  Afterwards, all groups which have less than ``overlaps`` elements are discarded (this measure is similar to the Viola-Jones face detector).\n  Finally, :py:func:`average_detections` is used to compute the average bounding box for each of the groups, including averaging the detection value (which will, hence, usually decrease in value).\n\n  **Parameters:**\n\n  ``image`` : array_like (2D aka gray or 3D aka RGB)\n    The image to detect a face in.\n\n  ``cascade`` : str or :py:class:`Cascade` or ``None``\n    If given, the cascade file name or the loaded cascade to be used to classify image patches.\n    If not given, the :py:func:`default_cascade` is used.\n\n  ``sampler`` : :py:class:`Sampler` or ``None``\n    The sampler that defines the sampling of bounding boxes to search for the face.\n    If not specified, a default Sampler is instantiated.\n\n  ``threshold`` : float\n    The threshold of the quality of detected faces.\n    Detections with a quality lower than this value will not be considered.\n    Higher thresholds will not detect all faces, while lower thresholds will generate false detections.\n\n  ``overlaps`` : int\n    The number of overlapping boxes that must exist for a bounding box to be considered.\n    Higher values will remove a lot of false-positives, but might increase the chance of a face to be missed.\n    The default value ``1`` will not limit the boxes.\n\n  ``minimum_overlap`` : float between 0 and 1\n    Groups detections based on the given minimum bounding box overlap, see :py:func:`group_detections`.\n\n  ``relative_prediction_threshold`` : float between 0 and 1\n    Limits the bounding boxes to those that have a prediction value higher then ``relative_prediction_threshold * max(predictions)``\n\n  **Returns:**\n\n  ``bounding_boxes`` : [:py:class:`BoundingBox`]\n    The bounding box containing the detected face.\n\n  ``qualities`` : [float]\n    The qualities of the ``bounding_boxes``, values greater than ``threshold``.\n  \"\"\"\n  if cascade is None:\n    cascade = default_cascade()\n  elif isinstance(cascade, str):\n    cascade = Cascade(bob.io.base.HDF5File(cascade))\n\n  if sampler is None:\n    sampler = Sampler(patch_size = cascade.extractor.patch_size, distance=2, scale_factor=math.pow(2.,-1./16.), lowest_scale=0.125)\n\n  if image.ndim == 3:\n    image = bob.ip.color.rgb_to_gray(image)\n\n  detections = []\n  predictions = []\n  # get the detection scores for the image\n  for prediction, bounding_box in sampler.iterate_cascade(cascade, image, threshold):\n    detections.append(bounding_box)\n    predictions.append(prediction)\n\n  if not detections:\n    # No face detected\n    return None\n\n  # group overlapping detections\n  if minimum_overlap < 1.:\n    detections, predictions = group_detections(detections, predictions, minimum_overlap, threshold, overlaps)\n\n    if not detections:\n      return None\n\n    # average them\n    detections, predictions = zip(*[average_detections(b, q, relative_prediction_threshold) for b,q in zip(detections, predictions)])\n\n  return detections, predictions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cycles_created_by(callable):\n    with restore_gc_state():\n        gc.disable()\n        gc.collect()\n        gc.set_debug(gc.DEBUG_SAVEALL)\n        callable()\n        new_object_count = gc.collect()\n        if new_object_count:\n            objects = gc.garbage[-new_object_count:]\n            del gc.garbage[-new_object_count:]\n        else:\n            objects = []\n        return ObjectGraph(objects)", "response": "Returns a graph of objects generated by the given callable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollect garbage and return an object graph based on collected garbage.", "response": "def garbage():\n    \"\"\"\n    Collect garbage and return an :class:`~refcycle.object_graph.ObjectGraph`\n    based on collected garbage.\n\n    The collected elements are removed from ``gc.garbage``, but are still kept\n    alive by the references in the graph.  Deleting the\n    :class:`~refcycle.object_graph.ObjectGraph` instance and doing another\n    ``gc.collect`` will remove those objects for good.\n\n    \"\"\"\n    with restore_gc_state():\n        gc.disable()\n        gc.set_debug(gc.DEBUG_SAVEALL)\n        collected_count = gc.collect()\n        if collected_count:\n            objects = gc.garbage[-collected_count:]\n            del gc.garbage[-collected_count:]\n        else:\n            objects = []\n        return ObjectGraph(objects)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objects_reachable_from(obj):\n    # Depth-first search.\n    found = ObjectGraph.vertex_set()\n    to_process = [obj]\n    while to_process:\n        obj = to_process.pop()\n        found.add(obj)\n        for referent in gc.get_referents(obj):\n            if referent not in found:\n                to_process.append(referent)\n    return ObjectGraph(found)", "response": "Returns a graph of objects reachable from obj."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the graph of all currently gc - tracked objects.", "response": "def snapshot():\n    \"\"\"Return the graph of all currently gc-tracked objects.\n\n    Excludes the returned :class:`~refcycle.object_graph.ObjectGraph` and\n    objects owned by it.\n\n    Note that a subsequent call to :func:`~refcycle.creators.snapshot` will\n    capture all of the objects owned by this snapshot.  The\n    :meth:`~refcycle.object_graph.ObjectGraph.owned_objects` method may be\n    helpful when excluding these objects from consideration.\n\n    \"\"\"\n    all_objects = gc.get_objects()\n    this_frame = inspect.currentframe()\n    selected_objects = []\n    for obj in all_objects:\n        if obj is not this_frame:\n            selected_objects.append(obj)\n    graph = ObjectGraph(selected_objects)\n    del this_frame, all_objects, selected_objects, obj\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextend the Markdown instance with this extension.", "response": "def extendMarkdown(self, md, md_globals):\n        \"\"\"\n        Every extension requires a extendMarkdown method to tell the markdown\n        renderer how use the extension.\n        \"\"\"\n        md.registerExtension(self)\n\n        for processor in (self.preprocessors or []):\n            md.preprocessors.add(processor.__name__.lower(), processor(md), '_end')\n\n        for pattern in (self.inlinepatterns or []):\n            md.inlinePatterns.add(pattern.__name__.lower(), pattern(md), '_end')\n\n        for processor in (self.postprocessors or []):\n            md.postprocessors.add(processor.__name__.lower(), processor(md), '_end')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getCustomLogger(name, logLevel, logFormat='%(asctime)s %(levelname)-9s:%(name)s:%(module)s:%(funcName)s: %(message)s'):\n  '''\n  Set up logging\n\n  :param str name: What log level to set\n  :param str logLevel: What log level to use\n  :param str logFormat: Format string for logging\n  :rtype: logger\n  '''\n  assert isinstance(logFormat, basestring), (\"logFormat must be a string but is %r\" % logFormat)\n  assert isinstance(logLevel, basestring), (\"logLevel must be a string but is %r\" % logLevel)\n  assert isinstance(name, basestring), (\"name must be a string but is %r\" % name)\n\n  validLogLevels = ['CRITICAL', 'DEBUG', 'ERROR', 'INFO', 'WARNING']\n\n  if not logLevel:\n    logLevel = 'DEBUG'\n\n  # If they don't specify a valid log level, err on the side of verbosity\n  if logLevel.upper() not in validLogLevels:\n    logLevel = 'DEBUG'\n\n  numericLevel = getattr(logging, logLevel.upper(), None)\n  if not isinstance(numericLevel, int):\n    raise ValueError(\"Invalid log level: %s\" % logLevel)\n\n  logging.basicConfig(level=numericLevel, format=logFormat)\n  logger = logging.getLogger(name)\n  return logger", "response": "Returns a custom logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmimicing mkdir - p since os module doesn t provide one.", "response": "def mkdir_p(path):\n  '''\n  Mimic `mkdir -p` since os module doesn't provide one.\n\n  :param str path: directory to create\n  '''\n  assert isinstance(path, basestring), (\"path must be a string but is %r\" % path)\n  try:\n    os.makedirs(path)\n  except OSError as exception:\n    if exception.errno != errno.EEXIST:\n      raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlimit the number of tasks that can be unlocked by the chord. unlock task.", "response": "def limit_chord_unlock_tasks(app):\n    \"\"\"\n    Set max_retries for chord.unlock tasks to avoid infinitely looping\n    tasks. (see celery/celery#1700 or celery/celery#2725)\n    \"\"\"\n    task = app.tasks['celery.chord_unlock']\n    if task.max_retries is None:\n        retries = getattr(app.conf, 'CHORD_UNLOCK_MAX_RETRIES', None)\n        task.max_retries = retries"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_exchanges(app):\n    with app.producer_or_acquire() as P:\n        # Ensure all queues are noticed and configured with their\n        # appropriate exchange.\n        for q in app.amqp.queues.values():\n            P.maybe_declare(q)", "response": "Setup result exchange to route all tasks to platform queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_app(app, throw=True):\n    success = True\n    try:\n        for func in SETUP_FUNCS:\n            try:\n                func(app)\n            except Exception:\n                success = False\n                if throw:\n                    raise\n                else:\n                    msg = \"Failed to run setup function %r(app)\"\n                    logger.exception(msg, func.__name__)\n    finally:\n        setattr(app, 'is_set_up', success)", "response": "Ensure application is set up to expected configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert(self, item, priority):\n\n        with self.lock:\n\n            self_data = self.data\n            rotate = self_data.rotate\n            self_items = self.items\n            maxlen = self._maxlen\n\n            try:\n\n                if priority <= self_data[-1][1]:\n                    self_data.append((item, priority))\n                elif priority > self_data[0][1]:\n                    self_data.appendleft((item, priority))\n                else:\n\n                    length = len(self_data) + 1\n                    mid = length // 2\n                    shift = 0\n\n                    while True:\n\n                        if priority <= self_data[0][1]:\n                            rotate(-mid)\n                            shift += mid\n                            mid //= 2\n                            if mid == 0:\n                                mid += 1\n\n                        else:\n                            rotate(mid)\n                            shift -= mid\n                            mid //= 2\n                            if mid == 0:\n                                mid += 1\n\n                        if self_data[-1][1] >= priority > self_data[0][1]:\n                            self_data.appendleft((item, priority))\n\n                            # When returning to original position, never shift\n                            # more than half length of DEPQ i.e. if length is\n                            # 100 and we rotated -75, rotate -25, not 75\n                            if shift > length // 2:\n                                shift = length % shift\n                                rotate(-shift)\n                            else:\n                                rotate(shift)\n\n                            break\n\n                try:\n                    self_items[item] += 1\n                except TypeError:\n                    self_items[repr(item)] += 1\n\n            except IndexError:\n                self_data.append((item, priority))\n                try:\n                    self_items[item] = 1\n                except TypeError:\n                    self_items[repr(item)] = 1\n\n            if maxlen is not None and maxlen < len(self_data):\n                self._poplast()", "response": "Adds item to the deque with given priority."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding item to DEPQ as highest priority.", "response": "def addfirst(self, item, new_priority=None):\n        \"\"\"Adds item to DEPQ as highest priority. The default\n        starting priority is 0, the default new priority is\n        self.high(). Performance: O(1)\"\"\"\n\n        with self.lock:\n\n            self_data = self.data\n\n            try:\n                priority = self_data[0][1]\n                if new_priority is not None:\n                    if new_priority < priority:\n                        raise ValueError('Priority must be >= '\n                                         'highest priority.')\n                    else:\n                        priority = new_priority\n            except IndexError:\n                priority = 0 if new_priority is None else new_priority\n\n            self_data.appendleft((item, priority))\n            self_items = self.items\n            maxlen = self._maxlen\n\n            try:\n                self_items[item] += 1\n            except TypeError:\n                self_items[repr(item)] += 1\n\n            if maxlen is not None and maxlen < len(self_data):\n                self._poplast()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an item to the DEPQ as lowest priority.", "response": "def addlast(self, item, new_priority=None):\n        \"\"\"Adds item to DEPQ as lowest priority. The default\n        starting priority is 0, the default new priority is\n        self.low(). Performance: O(1)\"\"\"\n\n        with self.lock:\n\n            self_data = self.data\n            maxlen = self._maxlen\n\n            if maxlen is not None and maxlen == len(self_data):\n                return\n\n            try:\n                priority = self_data[-1][1]\n                if new_priority is not None:\n                    if new_priority > priority:\n                        raise ValueError('Priority must be <= '\n                                         'lowest priority.')\n                    else:\n                        priority = new_priority\n            except IndexError:\n                priority = 0 if new_priority is None else new_priority\n\n            self_data.append((item, priority))\n            self_items = self.items\n\n            try:\n                self_items[item] += 1\n            except TypeError:\n                self_items[repr(item)] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef popfirst(self):\n\n        with self.lock:\n\n            try:\n                tup = self.data.popleft()\n            except IndexError as ex:\n                ex.args = ('DEPQ is already empty',)\n                raise\n\n            self_items = self.items\n\n            try:\n                self_items[tup[0]] -= 1\n                if self_items[tup[0]] == 0:\n                    del self_items[tup[0]]\n            except TypeError:\n                r = repr(tup[0])\n                self_items[r] -= 1\n                if self_items[r] == 0:\n                    del self_items[r]\n\n            return tup", "response": "Removes the first item from the DEPQ. Returns tuple of item and priority. Performance is O ( 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _poplast(self):\n\n        try:\n            tup = self.data.pop()\n        except IndexError as ex:\n            ex.args = ('DEPQ is already empty',)\n            raise\n\n        self_items = self.items\n\n        try:\n            self_items[tup[0]] -= 1\n            if self_items[tup[0]] == 0:\n                del self_items[tup[0]]\n        except TypeError:\n            r = repr(tup[0])\n            self_items[r] -= 1\n            if self_items[r] == 0:\n                del self_items[r]\n\n        return tup", "response": "For avoiding locking during inserting to keep maxlen"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef first(self):\n        with self.lock:\n            try:\n                return self.data[0][0]\n            except IndexError as ex:\n                ex.args = ('DEPQ is empty',)\n                raise", "response": "Gets the first item in the list. Performance is O ( 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the last item in the list. Performance is O ( 1 )", "response": "def last(self):\n        \"\"\"Gets item with lowest priority. Performance: O(1)\"\"\"\n        with self.lock:\n            try:\n                return self.data[-1][0]\n            except IndexError as ex:\n                ex.args = ('DEPQ is empty',)\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the highest priority. Performance is O ( 1 )", "response": "def high(self):\n        \"\"\"Gets highest priority. Performance: O(1)\"\"\"\n        with self.lock:\n            try:\n                return self.data[0][1]\n            except IndexError as ex:\n                ex.args = ('DEPQ is empty',)\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the lowest priority. Performance is O ( 1 )", "response": "def low(self):\n        \"\"\"Gets lowest priority. Performance: O(1)\"\"\"\n        with self.lock:\n            try:\n                return self.data[-1][1]\n            except IndexError as ex:\n                ex.args = ('DEPQ is empty',)\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nemptying DEPQ. Performance O ( 1 )", "response": "def clear(self):\n        \"\"\"Empties DEPQ. Performance: O(1)\"\"\"\n        with self.lock:\n            self.data.clear()\n            self.items.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting maxlen of the array.", "response": "def set_maxlen(self, length):\n        \"\"\"Sets maxlen\"\"\"\n        with self.lock:\n            self._maxlen = length\n            while len(self.data) > length:\n                self._poplast()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the number of occurrences of item in DEPQ. Performance is O ( 1 )", "response": "def count(self, item):\n        \"\"\"Returns number of occurrences of item in DEPQ. Performance: O(1)\"\"\"\n        try:\n            return self.items.get(item, 0)\n        except TypeError:\n            return self.items.get(repr(item), 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving occurrences of given item in ascending priority.", "response": "def remove(self, item, count=1):\n        \"\"\"Removes occurrences of given item in ascending priority. Default\n        number of removals is 1. Useful for tasks that no longer require\n        completion, inactive clients, certain algorithms, etc. Returns a\n        list of tuple(item, priority). Performance: O(n)\"\"\"\n\n        with self.lock:\n\n            try:\n                count = int(count)\n            except ValueError as ex:\n                ex.args = ('{} cannot be represented as an '\n                           'integer'.format(count),)\n                raise\n            except TypeError as ex:\n                ex.args = ('{} cannot be represented as an '\n                           'integer'.format(count),)\n                raise\n\n            removed = []\n            self_items = self.items\n\n            try:\n                item_freq = self_items[item]\n                item_repr = item\n                if item_freq == 0:\n                    return removed\n            except TypeError:\n                item_freq = self_items[repr(item)]\n                item_repr = repr(item)\n                if item_freq == 0:\n                    return removed\n\n            if count == -1:\n                count = item_freq\n\n            self_data = self.data\n            rotate = self_data.rotate\n            pop = self_data.pop\n            counter = 0\n\n            for i in range(len(self_data)):\n                if count > counter and item == self_data[-1][0]:\n                    removed.append(pop())\n                    counter += 1\n                    continue\n                rotate()\n\n            if item_freq <= count:\n                del self_items[item_repr]\n            else:\n                self_items[item_repr] -= count\n\n            return removed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DatabaseEnabled(cls):\n    if not issubclass(cls, Storable):\n        raise ValueError(\n            \"%s is not a subclass of gludb.datab.Storage\" % repr(cls)\n        )\n\n    cls.ensure_table = classmethod(_ensure_table)\n    cls.find_one = classmethod(_find_one)\n    cls.find_all = classmethod(_find_all)\n    cls.find_by_index = classmethod(_find_by_index)\n    cls.save = _save\n    cls.delete = _delete\n\n    return cls", "response": "Given a Storable class with this annotation add some persistence methods that forward to the mapped\n    database class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_playlist(self):\n        data = None\n        if self.id:\n            data = self.connection.get_item(\n                'find_playlist_by_id', playlist_id=self.id)\n        elif self.reference_id:\n            data = self.connection.get_item(\n                'find_playlist_by_reference_id',\n                reference_id=self.reference_id)\n\n        if data:\n            self._load(data)", "response": "Internal method to populate the object given the id or reference_id that has been set in the constructor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self):\n        d = self._to_dict()\n        if len(d.get('videoIds', [])) > 0:\n            if not self.id:\n                self.id = self.connection.post('create_playlist', playlist=d)\n            else:\n                data = self.connection.post('update_playlist', playlist=d)\n                if data:\n                    self._load(data)", "response": "Save a new item in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all the available playlists.", "response": "def find_all(connection=None, page_size=100, page_number=0,\n        sort_by=DEFAULT_SORT_BY, sort_order=DEFAULT_SORT_ORDER):\n        \"\"\"\n        List all playlists.\n        \"\"\"\n        return pybrightcove.connection.ItemResultSet(\"find_all_playlists\",\n            Playlist, connection, page_size, page_number, sort_by, sort_order)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists playlists by specific IDs.", "response": "def find_by_ids(ids, connection=None, page_size=100, page_number=0,\n        sort_by=DEFAULT_SORT_BY, sort_order=DEFAULT_SORT_ORDER):\n        \"\"\"\n        List playlists by specific IDs.\n        \"\"\"\n        ids = ','.join([str(i) for i in ids])\n        return pybrightcove.connection.ItemResultSet('find_playlists_by_ids',\n            Playlist, connection, page_size, page_number, sort_by, sort_order,\n            playlist_ids=ids)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_by_reference_ids(reference_ids, connection=None, page_size=100,\n        page_number=0, sort_by=DEFAULT_SORT_BY, sort_order=DEFAULT_SORT_ORDER):\n        \"\"\"\n        List playlists by specific reference_ids.\n        \"\"\"\n        reference_ids = ','.join([str(i) for i in reference_ids])\n        return pybrightcove.connection.ItemResultSet(\n            \"find_playlists_by_reference_ids\", Playlist, connection, page_size,\n            page_number, sort_by, sort_order, reference_ids=reference_ids)", "response": "List all playlists by specific reference_ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_for_player_id(player_id, connection=None, page_size=100,\n        page_number=0, sort_by=DEFAULT_SORT_BY, sort_order=DEFAULT_SORT_ORDER):\n        \"\"\"\n        List playlists for a for given player id.\n        \"\"\"\n        return pybrightcove.connection.ItemResultSet(\n            \"find_playlists_for_player_id\", Playlist, connection, page_size,\n            page_number, sort_by, sort_order, player_id=player_id)", "response": "Returns a list of all playlists for a given player id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_any_type_set(sett: Set[Type]) -> bool:\n    return len(sett) == 1 and is_any_type(min(sett))", "response": "Checks if a set of types is the singleton."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_validated_type(object_type: Type[Any], name: str, enforce_not_joker: bool = True) -> Type[Any]:\n    if object_type is object or object_type is Any or object_type is AnyObject:\n        return AnyObject\n    else:\n        # -- !! Do not check TypeVar or Union : this is already handled at higher levels --\n        if object_type is JOKER:\n            # optionally check if JOKER is allowed\n            if enforce_not_joker:\n                raise ValueError('JOKER is not allowed for object_type')\n        else:\n            # note: we dont check var earlier, since 'typing.Any' is not a subclass of type anymore\n            check_var(object_type, var_types=type, var_name=name)\n        return object_type", "response": "Utility to validate a type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_able_to_convert_detailed(self, strict: bool, from_type: Type[Any], to_type: Type[Any]) \\\n            -> Tuple[bool, bool, bool]:\n        \"\"\"\n        Utility method to check if a parser is able to convert a given type to the given type, either in\n        * strict mode : provided_type and desired_type must be equal to this converter's from_type and to_type\n        respectively (or the to_type does not match but this converter is generic\n        * inference mode (non-strict) : provided_type may be a subclass of from_type, and to_type may be a subclass\n        of desired_type\n\n        If a custom function was provided at construction time, it is called to enable converters to reject some\n        conversions based on source and/or dest type provided.\n\n        :param strict: a boolean indicating if matching should be in strict mode or not\n        :param from_type:\n        :param to_type:\n        :return: a tuple of 3 booleans : (does match?, strict source match? (None if no match), strict dest match?\n        (None if no match))\n        \"\"\"\n        # (1) first handle the easy joker+joker case\n        if from_type is JOKER and to_type is JOKER:\n            return True, None, None\n\n        # Don't validate types -- this is called too often at the initial RootParser instance creation time,\n        # and this is quite 'internal' so the risk is very low\n        #\n        # check_var(strict, var_types=bool, var_name='strict')\n        # if from_type is not JOKER:\n        #     check_var(from_type, var_types=type, var_name='from_type')\n        # if to_type is not JOKER:\n        #     check_var(to_type, var_types=type, var_name='to_type')\n\n        # -- first call custom checker if provided\n        if self.is_able_to_convert_func is not None:\n            # TODO Maybe one day, rather push the JOKER to the function ? not sure that it will be more explicit..\n            if not self.is_able_to_convert_func(strict,\n                                                from_type=None if from_type is JOKER else from_type,\n                                                to_type=None if to_type is JOKER else to_type):\n                return False, None, None\n\n        # -- from_type strict match\n        if (from_type is JOKER) or (from_type is self.from_type) or is_any_type(from_type):\n            # -- check to type strict\n            if (to_type is JOKER) or self.is_generic() or (to_type is self.to_type):\n                return True, True, True  # strict to_type match\n            # -- check to type non-strict\n            elif (not strict) and issubclass(self.to_type, to_type):\n                return True, True, False  # approx to_type match\n\n        # -- from_type non-strict match\n        elif (not strict) and issubclass(from_type, self.from_type):\n            # -- check to type strict\n            if (to_type is JOKER) or self.is_generic() or (to_type is self.to_type):\n                return True, False, True  # exact to_type match\n            # -- check to type non-strict\n            elif (not strict) and issubclass(self.to_type, to_type):\n                return True, False, False  # approx to_type match\n\n        # -- otherwise no match\n        return False, None, None", "response": "Utility method to check if a parser is able to convert a given type to a given type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef are_worth_chaining(left_converter, right_converter) -> bool:\n        if not left_converter.can_chain:\n            return False\n\n        elif not is_any_type(left_converter.to_type) and is_any_type(right_converter.to_type):\n            # we gain the capability to generate any type. So it is interesting.\n            return True\n\n        elif issubclass(left_converter.from_type, right_converter.to_type) \\\n                or issubclass(left_converter.to_type, right_converter.to_type) \\\n                or issubclass(left_converter.from_type, right_converter.from_type):\n            # Not interesting : the outcome of the chain would be not better than one of the converters alone\n            return False\n\n        # Note: we dont say that chaining a generic converter with a converter is useless. Indeed it might unlock some\n        # capabilities for the user (new file extensions, etc.) that would not be available with the generic parser\n        # targetting to_type alone. For example parsing object A from its constructor then converting A to B might\n        # sometimes be interesting, rather than parsing B from its constructor\n\n        else:\n            # interesting\n            return True", "response": "Checks if the two converters are better than one of the two."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_applicable_options(self, options: Dict[str, Dict[str, Any]]):\n        return get_options_for_id(options, self.get_id_for_options())", "response": "Returns the options that are applicable to this particular converter from the full map of options."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimplement classes should implement this method to perform the conversion itself :param desired_type: the destination type of the conversion :param source_obj: the source object that should be converter :param logger: a logger to use if any is available, or None :param options: additional options map. Implementing classes may use 'self.get_applicable_options()' to get the options that are of interest for this converter. :return:", "response": "def _convert(self, desired_type: Type[T], source_obj: S, logger: Logger, options: Dict[str, Dict[str, Any]]) -> T:\n        \"\"\"\n        Implementing classes should implement this method to perform the conversion itself\n\n        :param desired_type: the destination type of the conversion\n        :param source_obj: the source object that should be converter\n        :param logger: a logger to use if any is available, or None\n        :param options: additional options map. Implementing classes may use 'self.get_applicable_options()' to get the\n        options that are of interest for this converter.\n        :return:\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new object of type CaughtTypeError.", "response": "def create(converter_func: ConversionMethod, caught: Exception):\n        \"\"\"\n        Helper method provided because we actually can't put that in the constructor, it creates a bug in Nose tests\n        https://github.com/nose-devs/nose/issues/725\n\n        :param converter_func:\n        :param caught:\n        :return:\n        \"\"\"\n        msg = 'Caught TypeError while calling conversion function \\'' + str(converter_func.__name__) + '\\'. ' \\\n              'Note that the conversion function signature should be \\'' + conversion_method_example_signature_str \\\n              + '\\' (unpacked options mode - default) or ' + multioptions_conversion_method_example_signature_str \\\n              + ' (unpack_options = False).' \\\n              + 'Caught error message is : ' + caught.__class__.__name__ + ' : ' + str(caught)\n        return CaughtTypeError(msg).with_traceback(caught.__traceback__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndelegates to the user - provided method. Passes the appropriate part of the options according to the function name.", "response": "def _convert(self, desired_type: Type[T], source_obj: S, logger: Logger, options: Dict[str, Dict[str, Any]]) -> T:\n        \"\"\"\n        Delegates to the user-provided method. Passes the appropriate part of the options according to the\n        function name.\n\n        :param desired_type:\n        :param source_obj:\n        :param logger:\n        :param options:\n        :return:\n        \"\"\"\n        try:\n            if self.unpack_options:\n                opts = self.get_applicable_options(options)\n                if self.function_args is not None:\n                    return self.conversion_method(desired_type, source_obj, logger, **self.function_args, **opts)\n                else:\n                    return self.conversion_method(desired_type, source_obj, logger, **opts)\n            else:\n                if self.function_args is not None:\n                    return self.conversion_method(desired_type, source_obj, logger, options, **self.function_args)\n                else:\n                    return self.conversion_method(desired_type, source_obj, logger, options)\n\n        except TypeError as e:\n            raise CaughtTypeError.create(self.conversion_method, e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_able_to_convert_detailed(self, strict: bool, from_type: Type[Any], to_type: Type[Any]):\n        # check if first and last converters are happy\n        if not self._converters_list[0].is_able_to_convert(strict, from_type=from_type, to_type=JOKER):\n            return False, None, None\n        elif not self._converters_list[-1].is_able_to_convert(strict, from_type=JOKER, to_type=to_type):\n            return False, None, None\n        else:\n            # behave as usual. This is probably useless but lets be sure.\n            return super(ConversionChain, self).is_able_to_convert_detailed(strict, from_type, to_type)", "response": "Override is_able_to_convert to delegate to first and last converters of the chain and then call the parent method to do the actual conversion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the converters of the chain in order to produce the desired type.", "response": "def _convert(self, desired_type: Type[T], obj: S, logger: Logger, options: Dict[str, Dict[str, Any]]) -> T:\n        \"\"\"\n        Apply the converters of the chain in order to produce the desired result. Only the last converter will see the\n        'desired type', the others will be asked to produce their declared to_type.\n\n        :param desired_type:\n        :param obj:\n        :param logger:\n        :param options:\n        :return:\n        \"\"\"\n        for converter in self._converters_list[:-1]:\n            # convert into each converters destination type\n            obj = converter.convert(converter.to_type, obj, logger, options)\n\n        # the last converter in the chain should convert to desired type\n        return self._converters_list[-1].convert(desired_type, obj, logger, options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(as_module=False):\n    this_module = __package__\n    args = sys.argv[1:]\n\n    if as_module:\n        if sys.version_info >= (2, 7):\n            name = 'python -m ' + this_module.rsplit('.', 1)[0]\n        else:\n            name = 'python -m ' + this_module\n\n        # This module is always executed as \"python -m flask.run\" and as such\n        # we need to ensure that we restore the actual command line so that\n        # the reloader can properly operate.\n        sys.argv = ['-m', this_module] + sys.argv[1:]\n    else:\n        name = None\n\n    cli.main(args=args, prog_name=name)", "response": "This is copy / paste of flask. cli. main to instanciate our own group\n countryCode"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the Flask application.", "response": "def init_app(self, app, entry_point_group='invenio_queues.queues'):\n        \"\"\"Flask application initialization.\"\"\"\n        self.init_config(app)\n        app.extensions['invenio-queues'] = _InvenioQueuesState(\n            app,\n            app.config['QUEUES_CONNECTION_POOL'],\n            entry_point_group=entry_point_group\n        )\n        return app"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_result(result):\n\n\tif(result['Type'] == 'D'):\n\t\tprint \"\"\"There is more than one answer for this. Try making your query\\\n\t\tmore specific. For example, if you want to learn about apple the company\\\n\t\tand not apple the fruit, try something like apple inc or apple computers.  \n\t\t\"\"\"\n\t\n\telif(result['Type'] == 'A'):\n\t\tprint result['AbstractText']\n\t\tprint '\\nResults from DuckDuckGo'\n\t\n\telif(result['Type'] == 'C'):\n\t\tfor entry in result['RelatedTopics']:\n\t\t\tprint entry['Text']\n\t\t\tprint \"\\n\"\n\telse:\n\t\tprint \"I do not know how to process this query at the moment.\"", "response": "parse the result from DuckDuckGo and print the web query according to the type \n\tof result from duckduckgo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying ( user string", "response": "def query(string):\n\t\"\"\"query(user string) -- make http request to duckduckgo api, to get result\n\tin json format, then call parse_result.\n\t\"\"\"\n\turl = \"https://api.duckduckgo.com/?q=\"\n\tformating = \"&format=json\"\n\tquery_string = url+'+'.join(string)+formating\n\ttry:\n\t\tresult = json.loads(requests.get(query_string).text)\n\texcept:\n\t\tprint \"I'm sorry! Something went wrong. Maybe we could try again later.\"\n\t\treturn\n\tparse_result(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_gpx(gpx_element, gpx_extensions_parser=None,\n                   metadata_extensions_parser=None,\n                   waypoint_extensions_parser=None,\n                   route_extensions_parser=None,\n                   track_extensions_parser=None,\n                   segment_extensions_parser=None,\n                   gpxns=None):\n    \"\"\"Parse a GPX file into a GpxModel.\n\n    Args:\n        gpx_element: gpx_element: The root <gpx> element of an XML document\n            containing a version attribute. GPX versions 1.1 is supported.\n\n        gpx_extensions_parser: An optional callable which accepts an Element\n            with the 'extensions' tag and returns a list of model objects\n            representing the extensions. If not specified, extensions are\n            ignored.\n\n        metadata_extensions_parser: An optional callable which accepts an\n            Element with the 'extensions' tag and returns a list of model\n            objects representing the extensions. If not specified, extensions\n            are ignored.\n\n        waypoint_extensions_parser: An optional callable which accepts an\n            Element with the 'extensions' tag and returns a list of model\n            objects representing the extensions. If not specified, extensions\n            are ignored.\n\n        route_extensions_parser: An optional callable which accepts an Element\n            with the 'extensions' tag and returns a list of model objects\n            representing the extensions. If not specified, extensions are\n            ignored.\n\n        track_extensions_parser: An optional callable which accepts an Element\n            with the 'extensions' tag and returns a list of model objects\n            representing the extensions. If not specified, extensions are\n            ignored.\n\n        segment_extensions_parser: An optional callable which accepts an\n            Element with the 'extensions' tag and returns a list of model\n            objects representing the extensions. If not specified, extensions\n            are ignored.\n\n\n    Returns:\n        A GpxModel representing the data from the supplies xml.\n\n    Raises:\n        ValueError: The supplied XML could not be parsed as GPX.\n    \"\"\"\n    gpxns = gpxns if gpxns is not None else determine_gpx_namespace(gpx_element)\n\n    if gpx_element.tag != gpxns+'gpx':\n        raise ValueError(\"No gpx root element\")\n\n    creator = gpx_element.attrib['creator']\n    version = gpx_element.attrib['version']\n\n    if not version.startswith('1.1'):\n        raise ValueError(\"Not a GPX 1.1 file\")\n\n    metadata_element = gpx_element.find(gpxns+'metadata')\n    metadata = nullable(parse_metadata)(metadata_element, gpxns)\n\n    waypoint_elements = gpx_element.findall(gpxns+'wpt')\n    waypoints = [parse_waypoint(waypoint_element, gpxns) for waypoint_element in waypoint_elements]\n\n    route_elements = gpx_element.findall(gpxns+'rte')\n    routes = [parse_route(route_element, gpxns) for route_element in route_elements]\n\n    track_elements = gpx_element.findall(gpxns+'trk')\n    tracks = [parse_track(track_element, gpxns) for track_element in track_elements]\n\n    extensions_element = gpx_element.find(gpxns+'extensions')\n    extensions = nullable(parse_gpx_extensions)(extensions_element, gpxns)\n\n    gpx_model = GpxModel(creator, metadata, waypoints, routes, tracks,\n                         extensions)\n\n    return gpx_model", "response": "Parses a GPX file into a GpxModel object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listens_to(name, sender=None, weak=True):\n    def decorator(f):\n        if sender:\n            return signal(name).connect(f, sender=sender, weak=weak)\n        return signal(name).connect(f, weak=weak)\n    return decorator", "response": "A decorator that registers a function as a listens to a named signal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading installed packages and export the version map.", "response": "def LoadInstallations(counter):\n    \"\"\"Load installed packages and export the version map.\n\n    This function may be called multiple times, but the counters will\n    be increased each time. Since Prometheus counters are never\n    decreased, the aggregated results will not make sense.\n    \"\"\"\n    process = subprocess.Popen([\"pip\", \"list\", \"--format=json\"],\n                               stdout=subprocess.PIPE)\n    output, _ = process.communicate()\n    installations = json.loads(output)\n    for i in installations:\n        counter.labels(i[\"name\"], i[\"version\"]).inc()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef RESTrequest(*args, **kwargs):\n    verbose = kwargs.get('verbose', False)\n    force_download = kwargs.get('force', False)\n    save = kwargs.get('force', True)\n\n    # so you can copy paste from kegg\n    args = list(chain.from_iterable(a.split('/') for a in args))\n    args = [a for a in args if a]\n    request = 'http://rest.kegg.jp/' + \"/\".join(args)\n    print_verbose(verbose, \"richiedo la pagina: \" + request)\n    filename = \"KEGG_\" + \"_\".join(args)\n    try:\n        if force_download:\n            raise IOError()\n        print_verbose(verbose, \"loading the cached file \" + filename)\n        with open(filename, 'r') as f:\n            data = pickle.load(f)\n    except IOError:\n        print_verbose(verbose, \"downloading the library,it may take some time\")\n        import urllib2\n        try:\n            req = urllib2.urlopen(request)\n            data = req.read()\n            if save:\n                with open(filename, 'w') as f:\n                    print_verbose(verbose, \"saving the file to \" + filename)\n                    pickle.dump(data, f)\n        # clean the error stacktrace\n        except urllib2.HTTPError as e:\n            raise e\n    return data", "response": "return and save the blob of data that is returned by kegg without caring to the format"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _print(self, helpstr, file=None):\n    if file is None:\n        file = sys.stdout\n    encoding = self._get_encoding(file)\n    file.write(helpstr.encode(encoding, \"replace\"))", "response": "Print helpstr to file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n    self.parser = MultioptOptionParser(\n      usage=\"%prog <command> [options] [args]\",\n      prog=self.clsname,\n      version=self.version,\n      option_list=self.global_options,\n      description=self.desc_short,\n      commands=self.command_set,\n      epilog=self.footer\n    )\n    \n    try:\n      self.options, self.args = self.parser.parse_args(self.argv)    \n    except Exception, e:\n      print str(e)\n      pass\n\n    if len(self.args) < 1:\n      self.parser.print_lax_help()\n      return 2\n    \n    self.command = self.args.pop(0)\n    showHelp = False\n    \n    if self.command == 'help': \n      if len(self.args) < 1:\n        self.parser.print_lax_help()\n        return 2\n      else:\n        self.command = self.args.pop()\n        showHelp = True\n\n    if self.command not in self.valid_commands:\n      self.parser.print_cmd_error(self.command)\n      return 2\n\n    self.command_set[self.command].set_cmdname(self.command)\n    subcmd_parser = self.command_set[self.command].get_parser(self.clsname, self.version, self.global_options)\n    subcmd_options, subcmd_args = subcmd_parser.parse_args(self.args)\n\n    if showHelp:\n      subcmd_parser.print_help_long()\n      return 1\n\n    try:\n      self.command_set[self.command].func(subcmd_options, *subcmd_args)\n    except (CommandError, TypeError), e:\n      # self.parser.print_exec_error(self.command, str(e))\n      subcmd_parser.print_exec_error(self.command, str(e))\n      print \n      # @TODO show command help\n      # self.parser.print_lax_help()\n      return 2\n\n      \n    return 1", "response": "Run the multiopt command"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(self, community=None, hostfilter=None, host=None):\n        return self.send.snmp_list(community, hostfilter, host)", "response": "List the SNMP information for a specific community hostfilter or host."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, host=None, f_community=None, f_access=None, f_version=None):\n        return self.send.snmp_add(host, f_community, f_access, f_version)", "response": "Add an SNMP community string to a host."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_table(self, cls):\n        coll_name = cls.get_table_name()\n        try:\n            db = self.mongo_client.get_default_database()\n            db.create_collection(coll_name)\n        except CollectionInvalid:\n            pass  # Expected if collection already exists\n\n        # Make sure we have indexes\n        coll = self.get_collection(coll_name)\n        for idx_name in cls.index_names():\n            coll.ensure_index(idx_name)", "response": "Ensure that the table exists for the current class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new class that can represent a record with the specified fields.", "response": "def new(cls, __name, __fields, **defaults):\n    '''\n    Creates a new class that can represent a record with the\n    specified *fields*. This is equal to a mutable namedtuple.\n    The returned class also supports keyword arguments in its\n    constructor.\n\n    :param __name: The name of the recordclass.\n    :param __fields: A string or list of field names.\n    :param defaults: Default values for fields. The defaults\n      may list field names that haven't been listed in *fields*.\n    '''\n\n    name = __name\n    fields = __fields\n    fieldset = set(fields)\n\n    if isinstance(fields, str):\n      if ',' in fields:\n        fields = fields.split(',')\n      else:\n        fields = fields.split()\n    else:\n      fields = list(fields)\n\n    for key in defaults.keys():\n      if key not in fields:\n        fields.append(key)\n\n    class _record(cls):\n      __slots__ = fields\n      __defaults__ = defaults\n    _record.__name__ = name\n    return _record"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the first line is a known component name followed by a colon and then a short description of the commit.", "response": "def _check_1st_line(line, **kwargs):\n    \"\"\"First line check.\n\n    Check that the first line has a known component name followed by a colon\n    and then a short description of the commit.\n\n    :param line: first line\n    :type line: str\n    :param components: list of known component names\n    :type line: list\n    :param max_first_line: maximum length of the first line\n    :type max_first_line: int\n    :return: errors as in (code, line number, *args)\n    :rtype: list\n\n    \"\"\"\n    components = kwargs.get(\"components\", ())\n    max_first_line = kwargs.get(\"max_first_line\", 50)\n\n    errors = []\n    lineno = 1\n    if len(line) > max_first_line:\n        errors.append((\"M190\", lineno, max_first_line, len(line)))\n\n    if line.endswith(\".\"):\n        errors.append((\"M191\", lineno))\n\n    if ':' not in line:\n        errors.append((\"M110\", lineno))\n    else:\n        component, msg = line.split(':', 1)\n        if component not in components:\n            errors.append((\"M111\", lineno, component))\n\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_bullets(lines, **kwargs):\n    max_length = kwargs.get(\"max_length\", 72)\n    labels = {l for l, _ in kwargs.get(\"commit_msg_labels\", tuple())}\n\n    def _strip_ticket_directives(line):\n        return re.sub(r'( \\([^)]*\\)){1,}$', '', line)\n\n    errors = []\n    missed_lines = []\n    skipped = []\n\n    for (i, line) in enumerate(lines[1:]):\n        if line.startswith('*'):\n            dot_found = False\n            if len(missed_lines) > 0:\n                errors.append((\"M130\", i + 2))\n            if lines[i].strip() != '':\n                errors.append((\"M120\", i + 2))\n            if _strip_ticket_directives(line).endswith('.'):\n                dot_found = True\n\n            label = _re_bullet_label.search(line)\n            if label and label.group('label') not in labels:\n                errors.append((\"M122\", i + 2, label.group('label')))\n\n            for (j, indented) in enumerate(lines[i + 2:]):\n                if indented.strip() == '':\n                    break\n                if not re.search(r\"^ {2}\\S\", indented):\n                    errors.append((\"M121\", i + j + 3))\n                else:\n                    skipped.append(i + j + 1)\n                    stripped_line = _strip_ticket_directives(indented)\n                    if stripped_line.endswith('.'):\n                        dot_found = True\n                    elif stripped_line.strip():\n                        dot_found = False\n\n            if not dot_found:\n                errors.append((\"M123\", i + 2))\n\n        elif i not in skipped and line.strip():\n            missed_lines.append((i + 2, line))\n\n        if len(line) > max_length:\n            errors.append((\"M190\", i + 2, max_length, len(line)))\n\n    return errors, missed_lines", "response": "Check that the bullet point list is well formatted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_signatures(lines, **kwargs):\n    trusted = kwargs.get(\"trusted\", ())\n    signatures = tuple(kwargs.get(\"signatures\", ()))\n    alt_signatures = tuple(kwargs.get(\"alt_signatures\", ()))\n    min_reviewers = kwargs.get(\"min_reviewers\", 3)\n\n    matching = []\n    errors = []\n    signatures += alt_signatures\n\n    test_signatures = re.compile(\"^({0})\".format(\"|\".join(signatures)))\n    test_alt_signatures = re.compile(\"^({0})\".format(\"|\".join(alt_signatures)))\n    for i, line in lines:\n        if signatures and test_signatures.search(line):\n            if line.endswith(\".\"):\n                errors.append((\"M191\", i))\n            if not alt_signatures or not test_alt_signatures.search(line):\n                matching.append(line)\n        else:\n            errors.append((\"M102\", i))\n\n    if not matching:\n        errors.append((\"M101\", 1))\n        errors.append((\"M100\", 1))\n    elif len(matching) < min_reviewers:\n        pattern = re.compile('|'.join(map(lambda x: '<' + re.escape(x) + '>',\n                                          trusted)))\n        trusted_matching = list(filter(None, map(pattern.search, matching)))\n        if len(trusted_matching) == 0:\n            errors.append((\"M100\", 1))\n\n    return errors", "response": "Check that the signatures are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the format of a message.", "response": "def check_message(message, **kwargs):\n    \"\"\"Check the message format.\n\n    Rules:\n\n    - the first line must start by a component name\n    - and a short description (52 chars),\n    - then bullet points are expected\n    - and finally signatures.\n\n    :param components: compontents, e.g. ``('auth', 'utils', 'misc')``\n    :type components: `list`\n    :param signatures: signatures, e.g. ``('Signed-off-by', 'Reviewed-by')``\n    :type signatures: `list`\n    :param alt_signatures: alternative signatures, e.g. ``('Tested-by',)``\n    :type alt_signatures: `list`\n    :param trusted: optional list of reviewers, e.g. ``('john.doe@foo.org',)``\n    :type trusted: `list`\n    :param max_length: optional maximum line length (by default: 72)\n    :type max_length: int\n    :param max_first_line: optional maximum first line length (by default: 50)\n    :type max_first_line: int\n    :param allow_empty: optional way to allow empty message (by default: False)\n    :type allow_empty: bool\n    :return: errors sorted by line number\n    :rtype: `list`\n    \"\"\"\n    if kwargs.pop(\"allow_empty\", False):\n        if not message or message.isspace():\n            return []\n\n    lines = re.split(r\"\\r\\n|\\r|\\n\", message)\n    errors = _check_1st_line(lines[0], **kwargs)\n    err, signature_lines = _check_bullets(lines, **kwargs)\n    errors += err\n    errors += _check_signatures(signature_lines, **kwargs)\n\n    def _format(code, lineno, args):\n        return \"{0}: {1} {2}\".format(lineno,\n                                     code,\n                                     _messages_codes[code].format(*args))\n\n    return list(map(lambda x: _format(x[0], x[1], x[2:]),\n                    sorted(errors, key=lambda x: x[0])))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _register_pyflakes_check():\n    from flake8_isort import Flake8Isort\n    from flake8_blind_except import check_blind_except\n\n    # Resolving conflicts between pep8 and pyflakes.\n    codes = {\n        \"UnusedImport\": \"F401\",\n        \"ImportShadowedByLoopVar\": \"F402\",\n        \"ImportStarUsed\": \"F403\",\n        \"LateFutureImport\": \"F404\",\n        \"Redefined\": \"F801\",\n        \"RedefinedInListComp\": \"F812\",\n        \"UndefinedName\": \"F821\",\n        \"UndefinedExport\": \"F822\",\n        \"UndefinedLocal\": \"F823\",\n        \"DuplicateArgument\": \"F831\",\n        \"UnusedVariable\": \"F841\",\n    }\n\n    for name, obj in vars(pyflakes.messages).items():\n        if name[0].isupper() and obj.message:\n            obj.tpl = \"{0} {1}\".format(codes.get(name, \"F999\"), obj.message)\n\n    pep8.register_check(_PyFlakesChecker, codes=['F'])\n    # FIXME parser hack\n    parser = pep8.get_parser('', '')\n    Flake8Isort.add_options(parser)\n    options, args = parser.parse_args([])\n    # end of hack\n    pep8.register_check(Flake8Isort, codes=['I'])\n    pep8.register_check(check_blind_except, codes=['B90'])", "response": "Register the pyFlakes checker into PEP8 set of checks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_file_excluded(filename, excludes):\n    # check if you need to exclude this file\n    return any([exclude and re.match(exclude, filename) is not None\n                for exclude in excludes])", "response": "Check if the file should be excluded."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_pep8(filename, **kwargs):\n    options = {\n        \"ignore\": kwargs.get(\"ignore\"),\n        \"select\": kwargs.get(\"select\"),\n    }\n\n    if not _registered_pyflakes_check and kwargs.get(\"pyflakes\", True):\n        _register_pyflakes_check()\n\n    checker = pep8.Checker(filename, reporter=_Report, **options)\n    checker.check_all()\n\n    errors = []\n    for error in sorted(checker.report.errors, key=lambda x: x[0]):\n        errors.append(\"{0}:{1}: {3}\".format(*error))\n    return errors", "response": "Perform static analysis on the given file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms static analysis on the given file docstrings.", "response": "def check_pydocstyle(filename, **kwargs):\n    \"\"\"Perform static analysis on the given file docstrings.\n\n    :param filename: path of file to check.\n    :type filename: str\n    :param ignore: codes to ignore, e.g. ('D400',)\n    :type ignore: `list`\n    :param match: regex the filename has to match to be checked\n    :type match: str\n    :param match_dir: regex everydir in path should match to be checked\n    :type match_dir: str\n    :return: errors\n    :rtype: `list`\n\n    .. seealso::\n        `PyCQA/pydocstyle <https://github.com/GreenSteam/pydocstyle/>`_\n\n    \"\"\"\n    ignore = kwargs.get(\"ignore\")\n    match = kwargs.get(\"match\", None)\n    match_dir = kwargs.get(\"match_dir\", None)\n\n    errors = []\n\n    if match and not re.match(match, os.path.basename(filename)):\n        return errors\n\n    if match_dir:\n        # FIXME here the full path is checked, be sure, if match_dir doesn't\n        # match the path (usually temporary) before the actual application path\n        # it may not run the checks when it should have.\n        path = os.path.split(os.path.abspath(filename))[0]\n        while path != \"/\":\n            path, dirname = os.path.split(path)\n            if not re.match(match_dir, dirname):\n                return errors\n\n    checker = pydocstyle.PEP257Checker()\n    with open(filename) as fp:\n        try:\n            for error in checker.check_source(fp.read(), filename):\n                if ignore is None or error.code not in ignore:\n                    # Removing the colon ':' after the error code\n                    message = re.sub(\"(D[0-9]{3}): ?(.*)\",\n                                     r\"\\1 \\2\",\n                                     error.message)\n                    errors.append(\"{0}: {1}\".format(error.line, message))\n        except tokenize.TokenError as e:\n            errors.append(\"{1}:{2} {0}\".format(e.args[0], *e.args[1]))\n        except pydocstyle.AllError as e:\n            errors.append(str(e))\n\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming a license check on the given file.", "response": "def check_license(filename, **kwargs):\n    \"\"\"Perform a license check on the given file.\n\n    The license format should be commented using # and live at the top of the\n    file. Also, the year should be the current one.\n\n    :param filename: path of file to check.\n    :type filename: str\n    :param year: default current year\n    :type year: int\n    :param ignore: codes to ignore, e.g. ``('L100', 'L101')``\n    :type ignore: `list`\n    :param python_style: False for JavaScript or CSS files\n    :type python_style: bool\n    :return: errors\n    :rtype: `list`\n\n    \"\"\"\n    year = kwargs.pop(\"year\", datetime.now().year)\n    python_style = kwargs.pop(\"python_style\", True)\n    ignores = kwargs.get(\"ignore\")\n    template = \"{0}: {1} {2}\"\n\n    if python_style:\n        re_comment = re.compile(r\"^#.*|\\{#.*|[\\r\\n]+$\")\n        starter = \"# \"\n    else:\n        re_comment = re.compile(r\"^/\\*.*| \\*.*|[\\r\\n]+$\")\n        starter = \" *\"\n\n    errors = []\n    lines = []\n    file_is_empty = False\n    license = \"\"\n    lineno = 0\n    try:\n        with codecs.open(filename, \"r\", \"utf-8\") as fp:\n            line = fp.readline()\n            blocks = []\n            while re_comment.match(line):\n                if line.startswith(starter):\n                    line = line[len(starter):].lstrip()\n                    blocks.append(line)\n                    lines.append((lineno, line.strip()))\n                lineno, line = lineno + 1, fp.readline()\n            file_is_empty = line == \"\"\n            license = \"\".join(blocks)\n    except UnicodeDecodeError:\n        errors.append((lineno + 1, \"L190\", \"utf-8\"))\n        license = \"\"\n\n    if file_is_empty and not license.strip():\n        return errors\n\n    match_year = _re_copyright_year.search(license)\n    if match_year is None:\n        errors.append((lineno + 1, \"L101\"))\n    elif int(match_year.group(\"year\")) != year:\n        theline = match_year.group(0)\n        lno = lineno\n        for no, l in lines:\n            if theline.strip() == l:\n                lno = no\n                break\n        errors.append((lno + 1, \"L102\", year, match_year.group(\"year\")))\n    else:\n        program_match = _re_program.search(license)\n        program_2_match = _re_program_2.search(license)\n        program_3_match = _re_program_3.search(license)\n        if program_match is None:\n            errors.append((lineno, \"L100\"))\n        elif (program_2_match is None or\n              program_3_match is None or\n              (program_match.group(\"program\").upper() !=\n               program_2_match.group(\"program\").upper() !=\n               program_3_match.group(\"program\").upper())):\n            errors.append((lineno, \"L103\"))\n\n    def _format_error(lineno, code, *args):\n        return template.format(lineno, code,\n                               _licenses_codes[code].format(*args))\n\n    def _filter_codes(error):\n        if not ignores or error[1] not in ignores:\n            return error\n\n    return list(map(lambda x: _format_error(*x),\n                    filter(_filter_codes, errors)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_file(filename, **kwargs):\n    excludes = kwargs.get(\"excludes\", [])\n    errors = []\n\n    if is_file_excluded(filename, excludes):\n        return None\n\n    if filename.endswith(\".py\"):\n        if kwargs.get(\"pep8\", True):\n            errors += check_pep8(filename, **kwargs)\n        if kwargs.get(\"pydocstyle\", True):\n            errors += check_pydocstyle(filename, **kwargs)\n        if kwargs.get(\"license\", True):\n            errors += check_license(filename, **kwargs)\n    elif re.search(\"\\.(tpl|html)$\", filename):\n        errors += check_license(filename, **kwargs)\n    elif re.search(\"\\.(js|jsx|css|less)$\", filename):\n        errors += check_license(filename, python_style=False, **kwargs)\n\n    def try_to_int(value):\n        try:\n            return int(value.split(':', 1)[0])\n        except ValueError:\n            return 0\n\n    return sorted(errors, key=try_to_int)", "response": "Perform static analysis on a given file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_author(author, **kwargs):\n    errors = []\n\n    authors = kwargs.get(\"authors\")\n    if not authors:\n        errors.append('1:A100: ' + _author_codes['A100'])\n        return errors\n\n    exclude_author_names = kwargs.get(\"exclude_author_names\")\n    if exclude_author_names and author in exclude_author_names:\n        return []\n\n    path = kwargs.get(\"path\")\n    if not path:\n        path = os.getcwd()\n\n    for afile in authors:\n        if not os.path.exists(path + os.sep + afile):\n            errors.append('1:A101: ' + _author_codes['A101'].format(afile))\n\n    if errors:\n        return errors\n\n    status = subprocess.Popen(['grep', '-q', author] +\n                              [path + os.sep + afile for afile in authors],\n                              stdout=subprocess.PIPE,\n                              stderr=subprocess.PIPE,\n                              cwd=path).wait()\n    if status:\n        errors.append('1:A102: ' + _author_codes['A102'].format(author))\n\n    return errors", "response": "Check the presence of the author in the AUTHORS file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_options(config=None):\n    if config is None:\n        from . import config\n        config.get = lambda key, default=None: getattr(config, key, default)\n\n    base = {\n        \"components\": config.get(\"COMPONENTS\"),\n        \"signatures\": config.get(\"SIGNATURES\"),\n        \"commit_msg_template\": config.get(\"COMMIT_MSG_TEMPLATE\"),\n        \"commit_msg_labels\": config.get(\"COMMIT_MSG_LABELS\"),\n        \"alt_signatures\": config.get(\"ALT_SIGNATURES\"),\n        \"trusted\": config.get(\"TRUSTED_DEVELOPERS\"),\n        \"pep8\": config.get(\"CHECK_PEP8\", True),\n        \"pydocstyle\": config.get(\"CHECK_PYDOCSTYLE\", True),\n        \"license\": config.get(\"CHECK_LICENSE\", True),\n        \"pyflakes\": config.get(\"CHECK_PYFLAKES\", True),\n        \"ignore\": config.get(\"IGNORE\"),\n        \"select\": config.get(\"SELECT\"),\n        \"match\": config.get(\"PYDOCSTYLE_MATCH\"),\n        \"match_dir\": config.get(\"PYDOCSTYLE_MATCH_DIR\"),\n        \"min_reviewers\": config.get(\"MIN_REVIEWERS\"),\n        \"colors\": config.get(\"COLORS\", True),\n        \"excludes\": config.get(\"EXCLUDES\", []),\n        \"authors\": config.get(\"AUTHORS\"),\n        \"exclude_author_names\": config.get(\"EXCLUDE_AUTHOR_NAMES\"),\n    }\n    options = {}\n    for k, v in base.items():\n        if v is not None:\n            options[k] = v\n    return options", "response": "Build the options from the config object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding the error messages.", "response": "def run(self):\n        \"\"\"Yield the error messages.\"\"\"\n        for msg in self.messages:\n            col = getattr(msg, 'col', 0)\n            yield msg.lineno, col, (msg.tpl % msg.message_args), msg.__class__"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the checks and collect the errors.", "response": "def error(self, line_number, offset, text, check):\n        \"\"\"Run the checks and collect the errors.\"\"\"\n        code = super(_Report, self).error(line_number, offset, text, check)\n        if code:\n            self.errors.append((line_number, offset + 1, code, text, check))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprompt user for a string with a default value", "response": "def prompt(prompt_string, default=None, secret=False, boolean=False, bool_type=None):\n    \"\"\"\n    Prompt user for a string, with a default value\n\n    * secret converts to password prompt\n    * boolean converts return value to boolean, checking for starting with a Y\n    \"\"\"\n    if boolean or bool_type in BOOLEAN_DEFAULTS:\n        if bool_type is None:\n            bool_type = 'y_n'\n        default_msg = BOOLEAN_DEFAULTS[bool_type][is_affirmative(default)]\n    else:\n        default_msg = \" (default {val}): \"\n    prompt_string += (default_msg.format(val=default) if default else \": \")\n    if secret:\n        val = getpass(prompt_string)\n    else:\n        val = input(prompt_string)\n    val = (val if val else default)\n    if boolean:\n        val = val.lower().startswith('y')\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the inverse of the uncertainty matrix of a sequence", "response": "def prop_unc(jc):\r\n    \"\"\"\r\n    Propagate uncertainty.\r\n\r\n    :param jc: the Jacobian and covariance matrix\r\n    :type jc: sequence\r\n\r\n    This method is mainly designed to be used as the target for a\r\n    multiprocessing pool.\r\n    \"\"\"\r\n    j, c = jc\r\n    return np.dot(np.dot(j, c), j.T)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef partial_derivative(f, x, n, nargs, delta=DELTA):\r\n    dx = np.zeros((nargs, len(x[n])))\r\n    # scale delta by (|x| + 1.0) to avoid noise from machine precision\r\n    dx[n] += np.where(x[n], x[n] * delta, delta)\r\n    # apply central difference approximation\r\n    x_dx = zip(*[xi + (dxi, -dxi) for xi, dxi in zip(x, dx)])\r\n    return (f(x_dx[0]) - f(x_dx[1])) / dx[n] / 2.0", "response": "Calculates the partial derivative of a sequence of arguments f with respect to x."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jacobian(func, x, nf, nobs, *args, **kwargs):\r\n    nargs = len(x)  # degrees of freedom\r\n    f = lambda x_: func(x_, *args, **kwargs)\r\n    j = np.zeros((nargs, nf, nobs))  # matrix of zeros\r\n    for n in xrange(nargs):\r\n        j[n] = partial_derivative(f, x, n, nargs)\r\n        # better to transpose J once than transpose partial derivative each time\r\n        # j[:,:,n] = df.T\r\n    return j.T", "response": "Returns the jacobian of a function that returns a list of nobs times."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nflattening a 3 - D Jacobian into a 2 - D Jacobian.", "response": "def jflatten(j):\r\n    \"\"\"\r\n    Flatten 3_D Jacobian into 2-D.\r\n    \"\"\"\r\n    nobs, nf, nargs = j.shape\r\n    nrows, ncols = nf * nobs, nargs * nobs\r\n    jflat = np.zeros((nrows, ncols))\r\n    for n in xrange(nobs):\r\n        r, c = n * nf, n * nargs\r\n        jflat[r:(r + nf), c:(c + nargs)] = j[n]\r\n    return jflat"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jtosparse(j):\r\n    data = j.flatten().tolist()\r\n    nobs, nf, nargs = j.shape\r\n    indices = zip(*[(r, c) for n in xrange(nobs)\r\n                    for r in xrange(n * nf, (n + 1) * nf)\r\n                    for c in xrange(n * nargs, (n + 1) * nargs)])\r\n    return csr_matrix((data, indices), shape=(nobs * nf, nobs * nargs))", "response": "Generate sparse matrix coordinates from 3 - D Jacobian."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unc_wrapper_args(*covariance_keys):\r\n    def wrapper(f):\r\n        @wraps(f)\r\n        def wrapped_function(*args, **kwargs):\r\n            cov = kwargs.pop('__covariance__', None)  # pop covariance\r\n            method = kwargs.pop('__method__', 'loop')  # pop covariance\r\n            # covariance keys cannot be defaults, they must be in args or kwargs\r\n            cov_keys = covariance_keys\r\n            # convert args to kwargs by index\r\n            kwargs.update({n: v for n, v in enumerate(args)})\r\n            args = ()  # empty args\r\n            if None in cov_keys:\r\n                # use all keys\r\n                cov_keys = kwargs.keys()\r\n            # group covariance keys\r\n            if len(cov_keys) > 0:\r\n                # uses specified keys\r\n                x = [np.atleast_1d(kwargs.pop(k)) for k in cov_keys]\r\n            else:\r\n                # arguments already grouped\r\n                x = kwargs.pop(0)  # use first argument\r\n            # remaining args\r\n            args_dict = {}\r\n\r\n            def args_from_kwargs(kwargs_):\r\n                \"\"\"unpack positional arguments from keyword arguments\"\"\"\r\n                # create mapping of positional arguments by index\r\n                args_ = [(n, v) for n, v in kwargs_.iteritems()\r\n                         if not isinstance(n, basestring)]\r\n                # sort positional arguments by index\r\n                idx, args_ = zip(*sorted(args_, key=lambda m: m[0]))\r\n                # remove args_ and their indices from kwargs_\r\n                args_dict_ = {n: kwargs_.pop(n) for n in idx}\r\n                return args_, args_dict_\r\n\r\n            if kwargs:\r\n                args, args_dict = args_from_kwargs(kwargs)\r\n\r\n            def f_(x_, *args_, **kwargs_):\r\n                \"\"\"call original function with independent variables grouped\"\"\"\r\n                args_dict_ = args_dict\r\n                if cov_keys:\r\n                    kwargs_.update(zip(cov_keys, x_), **args_dict_)\r\n                if kwargs_:\r\n                    args_, _ = args_from_kwargs(kwargs_)\r\n                    return np.array(f(*args_, **kwargs_))\r\n                # assumes independent variables already grouped\r\n                return f(x_, *args_, **kwargs_)\r\n\r\n            # evaluate function and Jacobian\r\n            avg = f_(x, *args, **kwargs)\r\n            # number of returns and observations\r\n            if avg.ndim > 1:\r\n                nf, nobs = avg.shape\r\n            else:\r\n                nf, nobs = avg.size, 1\r\n            jac = jacobian(f_, x, nf, nobs, *args, **kwargs)\r\n            # calculate covariance\r\n            if cov is not None:\r\n                # covariance must account for all observations\r\n                # scale covariances by x squared in each direction\r\n                if cov.ndim == 3:\r\n                    x = np.array([np.repeat(y, nobs) if len(y)==1\r\n                                  else y for y in x])\r\n                    LOGGER.debug('x:\\n%r', x)\r\n                    cov = np.array([c * y * np.row_stack(y)\r\n                                    for c, y in zip(cov, x.T)])\r\n                else: # x are all only one dimension\r\n                    x = np.asarray(x)\r\n                    cov = cov * x * x.T\r\n                    assert jac.size / nf / nobs == cov.size / len(x)\r\n                    cov = np.tile(cov, (nobs, 1, 1))\r\n                # propagate uncertainty using different methods\r\n                if method.lower() == 'dense':\r\n                    j, c = jflatten(jac), jflatten(cov)\r\n                    cov = prop_unc((j, c))\r\n                # sparse\r\n                elif method.lower() == 'sparse':\r\n                    j, c = jtosparse(jac), jtosparse(cov)\r\n                    cov = j.dot(c).dot(j.transpose())\r\n                    cov = cov.todense()\r\n                # pool\r\n                elif method.lower() == 'pool':\r\n                    try:\r\n                        p = Pool()\r\n                        cov = np.array(p.map(prop_unc, zip(jac, cov)))\r\n                    finally:\r\n                        p.terminate()\r\n                # loop is the default\r\n                else:\r\n                    cov = np.array([prop_unc((jac[o], cov[o]))\r\n                                    for o in xrange(nobs)])\r\n                # dense and spares are flattened, unravel them into 3-D list of\r\n                # observations\r\n                if method.lower() in ['dense', 'sparse']:\r\n                    cov = np.array([\r\n                        cov[(nf * o):(nf * (o + 1)), (nf * o):(nf * (o + 1))]\r\n                        for o in xrange(nobs)\r\n                    ])\r\n            # unpack returns for original function with ungrouped arguments\r\n            if None in cov_keys or len(cov_keys) > 0:\r\n                return tuple(avg.tolist() + [cov, jac])\r\n            # independent variables were already grouped\r\n            return avg, cov, jac\r\n        return wrapped_function\r\n    return wrapper", "response": "A function that wraps the original function with the original function and returns the Jacobian and the covariance of the\r\nTaxonomy outputs given the specified covariance keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassign the user s query to a particular category and call the appropriate handler.", "response": "def assign_handler(query, category):\n\t\"\"\"assign_handler(query, category) -- assign the user's query to a \n\tparticular category, and call the appropriate handler.\n\t\"\"\"\n\tif(category == 'count lines'):\n\t\thandler.lines(query)\n\telif(category == 'count words'):\n\t\thandler.words(query)\n\telif(category == 'weather'):\n\t\tweb.weather(query)\n\telif(category == 'no match'):\n\t\tweb.generic(query)\n\telif(category == 'file info'):\n\t\thandler.file_info(query)\n\telif(category == 'executable'):\n\t\thandler.make_executable(query)\n\telif(category == 'search'):\n\t\thandler.search(query)\n\telif(category == 'path'):\n\t\thandler.add_to_path(query)\n\telif(category == 'uname'):\n\t\thandler.system_info(query)\n\telse:\n\t\tprint 'I\\'m not able to understand your query'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_path(query):\n\tmatch = re.search(r'/(.*/)+(\\S*(\\.[\\d\\w]{1,4})?)', query)\n\tif(os.path.isfile(match.group()) or os.path.isdir(match.group())):\n\t\treturn match.group()\n\telse:\n\t\treturn None", "response": "get_path - returns the pathname of the file or directory that matches the query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_readable_filesize(size):\n\tif(size < 1024):\n\t\treturn str(size)+' bytes'\n\ttemp = size/1024.0\n\tlevel = 1\n\twhile(temp >= 1024 and level< 3):\n\t\ttemp = temp/1024\n\t\tlevel += 1\n\tif(level == 1):\n\t\treturn str(round(temp,2))+' KB'\n\telif(level == 2):\n\t\treturn str(round(temp,2))+' MB'\n\telse:\n\t\treturn str(round(temp,2))+' GB'", "response": "get_readable_filesize - return human readable \n\tfilesize from given size in bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, svc_rec=None, hostfilter=None, compromised=False):\n        return self.send.accounts_list(svc_rec, hostfilter, compromised)", "response": "List all user accounts in the current service"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads a file to a service", "response": "def upload_file(self, service_rec=None, host_service=None, filename=None,\n                    pw_data=None, f_type=None, add_to_evidence=True):\n        \"\"\"\n        Upload a password file\n\n        :param service_rec: db.t_services.id\n        :param host_service: db.t_hosts.id\n        :param filename: Filename\n        :param pw_data: Content of file\n        :param f_type: Type of file\n        :param add_to_evidence: True/False to add to t_evidence\n        :return: (True/False, Response Message)\n        \"\"\"\n        return self.send.accounts_upload_file(service_rec, host_service, filename, pw_data, f_type, add_to_evidence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _columns_to_kwargs(conversion_table, columns, row):\n    kwdict = {}\n\n    counter = 0\n    for column in columns:\n        # Map the column name to the correct MarketHistoryEntry kwarg.\n        kwarg_name = conversion_table[column]\n        # Set the kwarg to the correct value from the row.\n        kwdict[kwarg_name] = row[counter]\n        counter += 1\n\n    return kwdict", "response": "Given a list of column names and a list of values ( a row return a dict that can be used to instantiate a MarketHistoryEntry\n    or MarketOrder object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_datetime(time_str):\n    try:\n        return dateutil.parser.parse(\n            time_str\n        ).replace(microsecond=0).astimezone(UTC_TZINFO)\n    except ValueError:\n        # This was some kind of unrecognizable time string.\n        raise ParseError(\"Invalid time string: %s\" % time_str)", "response": "Parses a date string into a UTC datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(self, po_file, source_files):\n        # Create a temporary file to write pot file\n        pot_file = tempfile.NamedTemporaryFile(mode='wb', prefix='rookout_', delete=False)\n        pot_filename = pot_file.name\n        slog.info('Create POT file [%s].', pot_filename)\n        xargs = [self._xgettext,\n                \"--package-name=main\",\n                \"--package-version=0.1\",\n                \"--default-domain=main\",\n                \"--from-code=UTF-8\",\n                \"-C\", \"-k_\",\n                \"--output\", pot_filename]\n        txt = subprocess.check_output(xargs+source_files, \n                stderr=subprocess.STDOUT, \n                universal_newlines=True)\n        if len(txt) > 0:\n            raise(ChildProcessError(txt))\n        slog.info('Start merge [%s] to [%s].', pot_filename, po_file)\n        xargs = [self._msgmerge, \"-U\", po_file, pot_filename]\n        txt = subprocess.check_output(xargs, universal_newlines=True)\n        slog.info(txt)\n        pot_file.close()\n        os.remove(pot_filename)", "response": "Merge the source_files into po_file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fmt(self, po_file, mo_file):\n        if not os.path.exists(po_file):\n            slog.error('The PO file [%s] is non-existen!'%po_file)\n            return\n        txt = subprocess.check_output([self._msgfmt, \n            '--check', \"--strict\", '--verbose', \n            \"--output-file\", mo_file, po_file], \n                stderr=subprocess.STDOUT, \n                universal_newlines=True)\n        slog.info(txt)", "response": "Format a PO file to a MAGIC file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds suffix TO THE FILENAME", "response": "def add_suffix(filename, suffix):\n        \"\"\"\n        ADD suffix TO THE filename (NOT INCLUDING THE FILE EXTENSION)\n        \"\"\"\n        path = filename.split(\"/\")\n        parts = path[-1].split(\".\")\n        i = max(len(parts) - 2, 0)\n        parts[i] = parts[i] + suffix\n        path[-1] = \".\".join(parts)\n        return \"/\".join(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of directories that match the pattern.", "response": "def find(self, pattern):\n        \"\"\"\n        :param pattern: REGULAR EXPRESSION TO MATCH NAME (NOT INCLUDING PATH)\n        :return: LIST OF File OBJECTS THAT HAVE MATCHING NAME\n        \"\"\"\n        output = []\n\n        def _find(dir):\n            if re.match(pattern, dir._filename.split(\"/\")[-1]):\n                output.append(dir)\n            if dir.is_directory():\n                for c in dir.children:\n                    _find(c)\n        _find(self)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_extension(self, ext):\n        path = self._filename.split(\"/\")\n        parts = path[-1].split(\".\")\n        if len(parts) == 1:\n            parts.append(ext)\n        else:\n            parts[-1] = ext\n\n        path[-1] = \".\".join(parts)\n        return File(\"/\".join(path))", "response": "RETURN NEW FILE WITH GIVEN EXTENSION"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_name(self, name):\n        path = self._filename.split(\"/\")\n        parts = path[-1].split(\".\")\n        if len(parts) == 1:\n            path[-1] = name\n        else:\n            path[-1] = name + \".\" + parts[-1]\n        return File(\"/\".join(path))", "response": "Set the name of the current file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a backup name for this file.", "response": "def backup_name(self, timestamp=None):\n        \"\"\"\n        RETURN A FILENAME THAT CAN SERVE AS A BACKUP FOR THIS FILE\n        \"\"\"\n        suffix = datetime2string(coalesce(timestamp, datetime.now()), \"%Y%m%d_%H%M%S\")\n        return File.add_suffix(self._filename, suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, encoding=\"utf8\"):\n        with open(self._filename, \"rb\") as f:\n            if self.key:\n                return get_module(\"mo_math.crypto\").decrypt(f.read(), self.key)\n            else:\n                content = f.read().decode(encoding)\n                return content", "response": "Reads the content of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the contents of the first file in the zip file.", "response": "def read_zipfile(self, encoding='utf8'):\n        \"\"\"\n        READ FIRST FILE IN ZIP FILE\n        :param encoding:\n        :return: STRING\n        \"\"\"\n        from zipfile import ZipFile\n        with ZipFile(self.abspath) as zipped:\n            for num, zip_name in enumerate(zipped.namelist()):\n                return zipped.open(zip_name).read().decode(encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, content, encoding='utf8'):\n        if not self.parent.exists:\n            self.parent.create()\n        with open(self._filename, \"ab\") as output_file:\n            if not is_text(content):\n                Log.error(u\"expecting to write unicode only\")\n            output_file.write(content.encode(encoding))\n            output_file.write(b\"\\n\")", "response": "append a line to the file"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a URL query parameter into a dictionary.", "response": "def url_param2value(param):\n    \"\"\"\n    CONVERT URL QUERY PARAMETERS INTO DICT\n    \"\"\"\n    if param == None:\n        return Null\n    if param == None:\n        return Null\n\n    def _decode(v):\n        output = []\n        i = 0\n        while i < len(v):\n            c = v[i]\n            if c == \"%\":\n                d = hex2chr(v[i + 1:i + 3])\n                output.append(d)\n                i += 3\n            else:\n                output.append(c)\n                i += 1\n\n        output = text_type(\"\".join(output))\n        try:\n            return json2value(output)\n        except Exception:\n            pass\n        return output\n\n    query = Data()\n    for p in param.split('&'):\n        if not p:\n            continue\n        if p.find(\"=\") == -1:\n            k = p\n            v = True\n        else:\n            k, v = p.split(\"=\")\n            v = _decode(v)\n\n        u = query.get(k)\n        if u is None:\n            query[k] = v\n        elif is_list(u):\n            u += [v]\n        else:\n            query[k] = [u, v]\n\n    return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef value2url_param(value):\n    if value == None:\n        Log.error(\"Can not encode None into a URL\")\n\n    if is_data(value):\n        value_ = wrap(value)\n        output = \"&\".join([\n            value2url_param(k) + \"=\" + (value2url_param(v) if is_text(v) else value2url_param(value2json(v)))\n            for k, v in value_.leaves()\n            ])\n    elif is_text(value):\n        output = \"\".join(_map2url[c] for c in value.encode('utf8'))\n    elif is_binary(value):\n        output = \"\".join(_map2url[c] for c in value)\n    elif hasattr(value, \"__iter__\"):\n        output = \",\".join(value2url_param(v) for v in value)\n    else:\n        output = str(value)\n    return output", "response": "Convert a value into a URL parameter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configfile_from_path(path, strict=True):\n    extension = path.split('.')[-1]\n    conf_type = FILE_TYPES.get(extension)\n    if not conf_type:\n\n        raise exc.UnrecognizedFileExtension(\n            \"Cannot parse file of type {0}. Choices are {1}.\".format(\n                extension,\n                FILE_TYPES.keys(),\n            )\n        )\n\n    return conf_type(path=path, strict=strict)", "response": "This method will return a ConfigFile object based on a file path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a Configuration object based on multiple file paths.", "response": "def configuration_from_paths(paths, strict=True):\n    \"\"\"Get a Configuration object based on multiple file paths.\n\n    Args:\n        paths (iter of str): An iterable of file paths which identify config\n            files on the system.\n        strict (bool): Whether or not to parse the files in strict mode.\n\n    Returns:\n        confpy.core.config.Configuration: The loaded configuration object.\n\n    Raises:\n        NamespaceNotRegistered: If a file contains a namespace which is not\n            defined.\n        OptionNotRegistered: If a file contains an option which is not defined\n            but resides under a valid namespace.\n        UnrecognizedFileExtension: If there is no loader for a path.\n    \"\"\"\n    for path in paths:\n\n        cfg = configfile_from_path(path, strict=strict).config\n\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_environment_var_options(config, env=None, prefix='CONFPY'):\n    env = env or os.environ\n    for section_name, section in config:\n\n        for option_name, _ in section:\n\n            var_name = '{0}_{1}_{2}'.format(\n                prefix.upper(),\n                section_name.upper(),\n                option_name.upper(),\n            )\n            env_var = env.get(var_name)\n            if env_var:\n\n                setattr(section, option_name, env_var)\n\n    return config", "response": "Sets any configuration options which have an environment var set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset any configuration options which have a CLI value set.", "response": "def set_cli_options(config, arguments=None):\n    \"\"\"Set any configuration options which have a CLI value set.\n\n    Args:\n        config (confpy.core.config.Configuration): A configuration object which\n            has been initialized with options.\n        arguments (iter of str): An iterable of strings which contains the CLI\n            arguments passed. If nothing is give then sys.argv is used.\n\n    Returns:\n        confpy.core.config.Configuration: A configuration object with CLI\n            values set.\n\n    The pattern to follow when setting CLI values is:\n\n        <section>_<option>\n\n    Each value should be lower case and separated by underscores.\n    \"\"\"\n    arguments = arguments or sys.argv[1:]\n    parser = argparse.ArgumentParser()\n    for section_name, section in config:\n\n        for option_name, _ in section:\n\n            var_name = '{0}_{1}'.format(\n                section_name.lower(),\n                option_name.lower(),\n            )\n            parser.add_argument('--{0}'.format(var_name))\n\n    args, _ = parser.parse_known_args(arguments)\n    args = vars(args)\n    for section_name, section in config:\n\n        for option_name, _ in section:\n\n            var_name = '{0}_{1}'.format(\n                section_name.lower(),\n                option_name.lower(),\n            )\n            value = args.get(var_name)\n            if value:\n\n                setattr(section, option_name, value)\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_for_missing_options(config):\n    for section_name, section in config:\n\n        for option_name, option in section:\n\n            if option.required and option.value is None:\n\n                raise exc.MissingRequiredOption(\n                    \"Option {0} in namespace {1} is required.\".format(\n                        option_name,\n                        section_name,\n                    )\n                )\n\n    return config", "response": "Iter over a configuration object and raise if any required options are not set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the options in the specified files and return a configuration object.", "response": "def parse_options(files, env_prefix='CONFPY', strict=True):\n    \"\"\"Parse configuration options and return a configuration object.\n\n    Args:\n        files (iter of str): File paths which identify configuration files.\n            These files are processed in order with values in later files\n            overwriting values in earlier files.\n        env_prefix (str): The static prefix prepended to all options when set\n            as environment variables. The default is CONFPY.\n        strict (bool): Whether or not to parse the files in strict mode.\n\n    Returns:\n        confpy.core.config.Configuration: The loaded configuration object.\n\n    Raises:\n        MissingRequiredOption: If a required option is not defined in any file.\n        NamespaceNotRegistered: If a file contains a namespace which is not\n            defined.\n        OptionNotRegistered: If a file contains an option which is not defined\n            but resides under a valid namespace.\n        UnrecognizedFileExtension: If there is no loader for a path.\n    \"\"\"\n    return check_for_missing_options(\n        config=set_cli_options(\n            config=set_environment_var_options(\n                config=configuration_from_paths(\n                    paths=files,\n                    strict=strict,\n                ),\n                prefix=env_prefix,\n            ),\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buy_product(self, product_pk):\n        if self.invoice_sales.filter(line_invoice_sales__line_order__product__pk=product_pk).exists() \\\n                or self.ticket_sales.filter(line_ticket_sales__line_order__product__pk=product_pk).exists():\n            return True\n        else:\n            return False", "response": "determina si el customer ha comprado un producto"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef template(self):\n\n        # First try props\n        if self.props.template:\n            return self.props.template\n        else:\n            # Return the wtype of the widget, and we'll presume that,\n            # like resources, there's a .html file in that directory\n            return self.wtype", "response": "Get the template from YAML or class"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, sphinx_app: Sphinx, context):\n\n        # Called from kaybee.plugins.widgets.handlers.render_widgets\n\n        builder: StandaloneHTMLBuilder = sphinx_app.builder\n        resource = sphinx_app.env.resources[self.docname]\n        context['sphinx_app'] = sphinx_app\n        context['widget'] = self\n        context['resource'] = resource\n\n        # make_context is optionally implemented on the concrete class\n        # for each widget\n        self.make_context(context, sphinx_app)\n\n        # NOTE: Can use builder.templates.render_string\n        template = self.template + '.html'\n        html = builder.templates.render(template, context)\n        return html", "response": "Given a Sphinx builder and context with sphinx_app in it generate HTML"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndescribing Class Dependency :param reg: should we register this class as well :param t: custom type as well :return:", "response": "def desc(t=None, reg=True):\n    \"\"\"\n    Describe Class Dependency\n\n    :param reg: should we register this class as well\n    :param t: custom type as well\n    :return:\n    \"\"\"\n\n    def decorated_fn(cls):\n        if not inspect.isclass(cls):\n            return NotImplemented('For now we can only describe classes')\n        name = t or camel_case_to_underscore(cls.__name__)[0]\n        if reg:\n            di.injector.register(name, cls)\n        else:\n            di.injector.describe(name, cls)\n        return cls\n\n    return decorated_fn"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the new key to this enumerated type.", "response": "def add(self, key, value=None):\n        \"\"\"\n        Adds the new key to this enumerated type.\n        \n        :param      key | <str>\n        \"\"\"\n        if value is None:\n            value = 2 ** (len(self))\n\n        self[key] = value\n        setattr(self, key, self[key])\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all the values joined together.", "response": "def all(self):\n        \"\"\"\n        Returns all the values joined together.\n        \n        :return     <int>\n        \"\"\"\n        out = 0\n        for key, value in self.items():\n            out |= value\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef base(self, value, recurse=True):\n        while value in self._bases:\n            value = self._bases[value]\n            if not recurse:\n                break\n        return value", "response": "Returns the root base for the given value from this enumeration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the display text for the value associated with the inputted text.", "response": "def displayText(self, value, blank='', joiner=', '):\n        \"\"\"\n        Returns the display text for the value associated with\n        the inputted text.  This will result in a comma separated\n        list of labels for the value, or the blank text provided if\n        no text is found.\n        \n        :param      value  | <variant>\n                    blank  | <str>\n                    joiner | <str>\n        \n        :return     <str>\n        \"\"\"\n        if value is None:\n            return ''\n\n        labels = []\n        for key, my_value in sorted(self.items(), key=lambda x: x[1]):\n            if value & my_value:\n                labels.append(self._labels.get(my_value, text.pretty(key)))\n\n        return joiner.join(labels) or blank"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extend(self, base, key, value=None):\n        new_val = self.add(key, value)\n        self._bases[new_val] = base", "response": "Adds a new definition to this enumeration and extends the given base type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromSet(self, values):\n        value = 0\n        for flag in values:\n            value |= self(flag)\n        return value", "response": "Generates a flag value based on the given set of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a pretty text version of the key for the inputted value.", "response": "def label(self, value):\n        \"\"\"\n        Returns a pretty text version of the key for the inputted value.\n\n        :param      value | <variant>\n\n        :return     <str>\n        \"\"\"\n        return self._labels.get(value) or text.pretty(self(value))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of user friendly labels.", "response": "def labels(self):\n        \"\"\"\n        Return a list of \"user friendly\" labels.\n        \n        :return     <list> [ <str>, .. ]\n        \"\"\"\n        return [self._labels.get(value) or text.pretty(key)\n                for key, value in sorted(self.items(), key=lambda x: x[1])]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setLabel(self, value, label):\n        if label:\n            self._labels[value] = label\n        else:\n            self._labels.pop(value, None)", "response": "Sets the label text for the inputted value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the text for the inputted value.", "response": "def text(self, value, default=''):\n        \"\"\"\n        Returns the text for the inputted value.\n        \n        :return     <str>\n        \"\"\"\n        for key, val in self.items():\n            if val == value:\n                return key\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a flag value based on the given set of values.", "response": "def toSet(self, flags):\n        \"\"\"\n        Generates a flag value based on the given set of values.\n\n        :param values: <set>\n\n        :return: <int>\n        \"\"\"\n        return {key for key, value in self.items() if value & flags}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef valueByLabel(self, label):\n        keys = self.keys()\n        labels = [text.pretty(key) for key in keys]\n        if label in labels:\n            return self[keys[labels.index(label)]]\n        return 0", "response": "Determines a given value based on the inputted label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing all available bubble examples", "response": "def cli(ctx, name,all):\n    \"\"\"Show example for doing some task in bubble(experimental)\"\"\"\n    ctx.gbc.say('all_example_functions',stuff=all_examples_functions, verbosity=1000)\n\n    for example in all_examples_functions:\n        if all or (name and example['name'] == name):\n            if all:\n                ctx.gbc.say('example',stuff=example, verbosity=100)\n                name = example['name']\n            #click.echo_via_pager(example['fun']())\n            click.echo(\"#\"*80)\n            click.echo(\"### start of bubble example: \"+name)\n            click.echo(\"#\"*80)\n            click.echo(example['fun']())\n            click.echo(\"#\"*80)\n            click.echo(\"### end of bubble example: \"+name)\n            click.echo(\"#\"*80)\n            click.echo()\n\n        else:\n            click.echo(\"available example: \" + example['name'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_if_alive(self):\n\n        try:\n            from urllib2 import urlopen, URLError, HTTPError\n        except ImportError:\n            from urllib.request import urlopen, URLError, HTTPError\n\n        if len(self.instance.STATUS_LINK):\n            check_url = self.instance.STATUS_LINK % ({'content_uid': self.get_content_uid()})\n        else:\n            # fallback\n            check_url = self.instance.url\n\n        try:\n            response = urlopen(check_url)\n        except (HTTPError, URLError):\n            return False\n        except ValueError:\n            raise URLError('Invalid URL: %s'.format(check_url))\n        else:\n            return True if response.code == 200 else False", "response": "Check if the content is available on the host server. Returns True if available else False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_config_file(self):\n        config_parser = SafeConfigParser()\n\n        config_parser.read(self.CONFIG_FILE)\n\n        if config_parser.has_section('handlers'):\n            self._config['handlers_package'] = config_parser.get('handlers', 'package')\n\n        if config_parser.has_section('auth'):\n            self._config['consumer_key'] = config_parser.get('auth', 'consumer_key')\n            self._config['consumer_secret'] = config_parser.get('auth', 'consumer_secret')\n            self._config['token_key'] = config_parser.get('auth', 'token_key')\n            self._config['token_secret'] = config_parser.get('auth', 'token_secret')\n\n        if config_parser.has_section('stream'):\n            self._config['user_stream'] = config_parser.get('stream', 'user_stream').lower() == 'true'\n        else:\n            self._config['user_stream'] = False\n\n        if config_parser.has_option('general', 'min_seconds_between_errors'):\n            self._config['min_seconds_between_errors'] = config_parser.get('general', 'min_seconds_between_errors')\n        if config_parser.has_option('general', 'sleep_seconds_on_consecutive_errors'):\n            self._config['sleep_seconds_on_consecutive_errors'] = config_parser.get(\n                'general', 'sleep_seconds_on_consecutive_errors')", "response": "Parse and load the configuration file and get config values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload config values from passed in CLI options.", "response": "def load_config_from_cli_arguments(self, *args, **kwargs):\n        \"\"\"\n        Get config values of passed in CLI options.\n\n        :param dict kwargs: CLI options\n        \"\"\"\n        self._load_config_from_cli_argument(key='handlers_package', **kwargs)\n        self._load_config_from_cli_argument(key='auth', **kwargs)\n        self._load_config_from_cli_argument(key='user_stream', **kwargs)\n        self._load_config_from_cli_argument(key='min_seconds_between_errors', **kwargs)\n        self._load_config_from_cli_argument(key='sleep_seconds_on_consecutive_errors', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that required config values are set.", "response": "def validate_configs(self):\n        \"\"\"\n        Check that required config are set.\n        :raises :class:`~responsebot.common.exceptions.MissingConfigError`: if a required config is missing\n        \"\"\"\n        # Check required arguments, validate values\n        for conf in self.REQUIRED_CONFIGS:\n            if conf not in self._config:\n                raise MissingConfigError('Missing required configuration %s' % conf)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, id):\n        data = self.db.get_data(self.get_path, id=id)\n        return self._build_item(**data['Data'][self.name])", "response": "Gets the dict data and builds the item object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, entity):\n        assert isinstance(entity, Entity), \" entity must have an instance of Entity\"\n        return self.__collection.save(entity.as_dict())", "response": "Maps entity to dict and returns future"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns future. Executes collection s find_one method based on keyword args maps result dict to instance", "response": "def find_one(self, **kwargs):\n        \"\"\"Returns future.\n\n        Executes collection's find_one method based on keyword args\n        maps result ( dict to instance ) and return future\n\n        Example::\n\n           manager = EntityManager(Product)\n           product_saved = yield manager.find_one(_id=object_id)\n\n         \"\"\"\n        future = TracebackFuture()\n\n        def handle_response(result, error):\n            if error:\n                future.set_exception(error)\n            else:\n                instance = self.__entity()\n                instance.map_dict(result)\n                future.set_result(instance)\n\n        self.__collection.find_one(kwargs, callback=handle_response)\n\n        return future"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all the available object types based on keyword args AttributeNames maps results to list of entity instances.", "response": "def find(self, **kwargs):\n        \"\"\"Returns List(typeof=).\n\n        Executes collection's find method based on keyword args\n        maps results ( dict to list of entity instances).\n\n        Set max_limit parameter to limit the amount of data send back through network\n\n        Example::\n\n            manager = EntityManager(Product)\n            products = yield manager.find(age={'$gt': 17}, max_limit=100)\n\n         \"\"\"\n        max_limit = None\n        if 'max_limit' in kwargs:\n            max_limit = kwargs.pop('max_limit')\n        cursor = self.__collection.find(kwargs)\n        instances = []\n        for doc in (yield cursor.to_list(max_limit)):\n            instance = self.__entity()\n            instance.map_dict(doc)\n            instances.append(instance)\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, entity):\n        assert isinstance(entity, Entity), \"Error: entity must have an instance of Entity\"\n        return self.__collection.update({'_id': entity._id}, {'$set': entity.as_dict()})", "response": "Executes collection s update method based on keyword args."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_poll(poll_id):\n    async with aiohttp.get('{api_url}/{poll_id}'.format(api_url=api_url, poll_id=poll_id)) as r:\n        return await StrawPoll(r)", "response": "Get a strawpoll object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def create_poll(title, options, multi=True, permissive=True, captcha=False, dupcheck='normal'):\n\n    query = {\n        'title': title,\n        'options': options,\n        'multi': multi,\n        'permissive': permissive,\n        'captcha': captcha,\n        'dupcheck': dupcheck\n    }\n\n    async with aiohttp.post(api_url, data=json.dumps(query)) as r:\n        return await StrawPoll(r)", "response": "Create a new poll for a single item."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nraises an exception if the request did not return a status code of 200.", "response": "def raise_status(response):\n    \"\"\"Raise an exception if the request did not return a status code of 200.\n\n    :param response: Request response body\n    \"\"\"\n    if response.status != 200:\n        if response.status == 401:\n            raise StrawPollException('Unauthorized', response)\n        elif response.status == 403:\n            raise StrawPollException('Forbidden', response)\n        elif response.status == 404:\n            raise StrawPollException('Not Found', response)\n        else:\n            response.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef results_with_percent(self):\n\n        percents = [int(float(v) / sum(self.votes) * 100) if sum(self.votes) > 0 else 0 for v in self.votes]\n        return zip(self.options, self.votes, percents)", "response": "Zip options votes and percents as integers together."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(self, results=False):\n\n        webbrowser.open(self.results_url if results else self.url)", "response": "Open the strawpoll in a browser."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntests function for DFA brzozowski algebraic method Operation", "response": "def main():\n    \"\"\"\n    Testing function for DFA brzozowski algebraic method Operation\n    \"\"\"\n    argv = sys.argv\n    if len(argv) < 2:\n        targetfile = 'target.y'\n    else:\n        targetfile = argv[1]\n    print 'Parsing ruleset: ' + targetfile,\n    flex_a = Flexparser()\n    mma = flex_a.yyparse(targetfile)\n    print 'OK'\n    print 'Perform minimization on initial automaton:',\n    mma.minimize()\n    print 'OK'\n    print 'Perform Brzozowski on minimal automaton:',\n    brzozowski_a = Brzozowski(mma)\n    mma_regex = brzozowski_a.get_regex()\n    print mma_regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _bfs_sort(self, start):\n        pathstates = {}\n        # maintain a queue of nodes to be visited. Both current and previous\n        # node must be included.\n        queue = []\n        # push the first path into the queue\n        queue.append([0, start])\n        pathstates[start.stateid] = 0\n        while queue:\n            # get the first node from the queue\n            leaf = queue.pop(0)\n            node = leaf[1]\n            pathlen = leaf[0]\n            # enumerate all adjacent nodes, construct a new path and push it\n            # into the queue\n            for arc in node.arcs:\n                next_state = self.mma[arc.nextstate]\n                if next_state.stateid not in pathstates:\n                    queue.append([pathlen + 1, next_state])\n                    pathstates[next_state.stateid] = pathlen + 1\n        orderedstatesdict = OrderedDict(\n            sorted(\n                pathstates.items(),\n                key=lambda x: x[1],\n                reverse=False))\n        for state in self.mma.states:\n            orderedstatesdict[state.stateid] = state\n        orderedstates = [x[1] for x in list(orderedstatesdict.items())]\n        return orderedstates", "response": "This function sorts the DFA states based on the BFS algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _brzozowski_algebraic_method_init(self):\n        # Initialize B\n        for state_a in self.mma.states:\n            if state_a.final:\n                self.B[state_a.stateid] = self.epsilon\n            else:\n                self.B[state_a.stateid] = self.empty\n            # Initialize A\n            for state_b in self.mma.states:\n                self.A[state_a.stateid, state_b.stateid] = self.empty\n                for arc in state_a.arcs:\n                    if arc.nextstate == state_b.stateid:\n                        self.A[state_a.stateid, state_b.stateid] = \\\n                            self.mma.isyms.find(arc.ilabel)", "response": "Initialize Brzozowski Algebraic Method"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming Brzozowski Algebraic Method", "response": "def _brzozowski_algebraic_method_solve(self):\n        \"\"\"Perform Brzozowski Algebraic Method\"\"\"\n        orderedstates = self._bfs_sort(\n            sorted(\n                self.mma.states,\n                key=attrgetter('initial'),\n                reverse=True)[0])\n        for n in range(len(orderedstates) - 1, 0, -1):\n            # print \"n:\" + repr(n)\n            if self.A[\n                    orderedstates[n].stateid,\n                    orderedstates[n].stateid] != self.empty:\n                # B[n] := star(A[n,n]) . B[n]\n                if self.B[orderedstates[n].stateid] != self.empty:\n                    self.B[orderedstates[n].stateid] = \\\n                        self.star(self.A[orderedstates[n].stateid, orderedstates[n].stateid]) \\\n                        + self.B[orderedstates[n].stateid]\n                else:\n                    self.B[orderedstates[n].stateid] = self.star(\n                        self.A[orderedstates[n].stateid, orderedstates[n].stateid])\n                for j in range(0, n):\n                    # A[n,j] := star(A[n,n]) . A[n,j]\n                    if self.A[\n                            orderedstates[n].stateid,\n                            orderedstates[j].stateid] != self.empty:\n                        self.A[\n                            orderedstates[n].stateid,\n                            orderedstates[j].stateid] = \\\n                            self.star(self.A[orderedstates[n].stateid, orderedstates[n].stateid]) \\\n                            + self.A[orderedstates[n].stateid, orderedstates[j].stateid]\n                    else:\n                        self.A[orderedstates[n].stateid, orderedstates[j].stateid] = self.star(\n                            self.A[orderedstates[n].stateid, orderedstates[n].stateid])\n            for i in range(0, n):\n                # B[i] += A[i,n] . B[n]\n                newnode = None\n                if self.A[orderedstates[i].stateid, orderedstates[n].stateid] != self.empty \\\n                        and self.B[orderedstates[n].stateid] != self.empty:\n                    newnode = self.A[orderedstates[i].stateid, orderedstates[\n                        n].stateid] + self.B[orderedstates[n].stateid]\n                elif self.A[orderedstates[i].stateid, orderedstates[n].stateid] != self.empty:\n                    newnode = self.A[\n                        orderedstates[i].stateid,\n                        orderedstates[n].stateid]\n                elif self.B[orderedstates[n].stateid] != self.empty:\n                    newnode = self.B[orderedstates[n].stateid]\n                if self.B[orderedstates[i].stateid] != self.empty:\n                    if newnode is not None:\n                        self.B[orderedstates[i].stateid] += newnode\n                else:\n                    self.B[orderedstates[i].stateid] = newnode\n                for j in range(0, n):\n                    # A[i,j] += A[i,n] . A[n,j]\n                    newnode = None\n                    if self.A[\n                            orderedstates[i].stateid,\n                            orderedstates[n].stateid] != self.empty \\\n                            and self.A[orderedstates[n].stateid, orderedstates[j].stateid] \\\n                                    != self.empty:\n                        newnode = self.A[orderedstates[i].stateid, orderedstates[\n                            n].stateid] + self.A[orderedstates[n].stateid, orderedstates[j].stateid]\n                    elif self.A[orderedstates[i].stateid, orderedstates[n].stateid] != self.empty:\n                        newnode = self.A[\n                            orderedstates[i].stateid,\n                            orderedstates[n].stateid]\n                    elif self.A[orderedstates[n].stateid, orderedstates[j].stateid] != self.empty:\n                        newnode = self.A[\n                            orderedstates[n].stateid,\n                            orderedstates[j].stateid]\n                    if self.A[\n                            orderedstates[i].stateid,\n                            orderedstates[j].stateid] != self.empty:\n                        if newnode is not None:\n                            self.A[\n                                orderedstates[i].stateid,\n                                orderedstates[j].stateid] += newnode\n                    else:\n                        self.A[\n                            orderedstates[i].stateid,\n                            orderedstates[j].stateid] = newnode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading libMultiMarkdown for usage", "response": "def load_mmd():\n    \"\"\"Loads libMultiMarkdown for usage\"\"\"\n    global _MMD_LIB\n    global _LIB_LOCATION\n    try:\n        lib_file = 'libMultiMarkdown' + SHLIB_EXT[platform.system()]\n        _LIB_LOCATION = os.path.abspath(os.path.join(DEFAULT_LIBRARY_DIR, lib_file))\n\n        if not os.path.isfile(_LIB_LOCATION):\n            _LIB_LOCATION = ctypes.util.find_library('MultiMarkdown')\n\n        _MMD_LIB = ctypes.cdll.LoadLibrary(_LIB_LOCATION)\n    except:\n        _MMD_LIB = None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding source text to include headers footers and expands Multimarkdown transclusion directives.", "response": "def _expand_source(source, dname, fmt):\n    \"\"\"Expands source text to include headers, footers, and expands Multimarkdown transclusion\n    directives.\n\n    Keyword arguments:\n    source -- string containing the Multimarkdown text to expand\n    dname -- directory name to use as the base directory for transclusion references\n    fmt -- format flag indicating which format to use to convert transclusion statements\n    \"\"\"\n    _MMD_LIB.g_string_new.restype = ctypes.POINTER(GString)\n    _MMD_LIB.g_string_new.argtypes = [ctypes.c_char_p]\n    src = source.encode('utf-8')\n    gstr = _MMD_LIB.g_string_new(src)\n\n    _MMD_LIB.prepend_mmd_header(gstr)\n    _MMD_LIB.append_mmd_footer(gstr)\n\n    manif = _MMD_LIB.g_string_new(b\"\")\n    _MMD_LIB.transclude_source.argtypes = [ctypes.POINTER(GString), ctypes.c_char_p,\n                                           ctypes.c_char_p, ctypes.c_int, ctypes.POINTER(GString)]\n    _MMD_LIB.transclude_source(gstr, dname.encode('utf-8'), None, fmt, manif)\n    manifest_txt = manif.contents.str\n    full_txt = gstr.contents.str\n    _MMD_LIB.g_string_free(manif, True)\n    _MMD_LIB.g_string_free(gstr, True)\n\n    manifest_txt = [ii for ii in manifest_txt.decode('utf-8').split('\\n') if ii]\n    return full_txt.decode('utf-8'), manifest_txt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_metadata(source, ext):\n    _MMD_LIB.has_metadata.argtypes = [ctypes.c_char_p, ctypes.c_int]\n    _MMD_LIB.has_metadata.restype = ctypes.c_bool\n    return _MMD_LIB.has_metadata(source.encode('utf-8'), ext)", "response": "Returns a flag indicating if a given block of MultiMarkdown text contains metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a string of MultiMarkdown text to the requested format.", "response": "def convert(source, ext=COMPLETE, fmt=HTML, dname=None):\n    \"\"\"Converts a string of MultiMarkdown text to the requested format.\n    Transclusion is performed if the COMPATIBILITY extension is not set, and dname is set to a\n    valid directory\n\n    Keyword arguments:\n    source -- string containing MultiMarkdown text\n    ext -- extension bitfield to pass to conversion process\n    fmt -- flag indicating output format to use\n    dname -- Path to use for transclusion - if None, transclusion functionality is bypassed\n    \"\"\"\n    if dname and not ext & COMPATIBILITY:\n        if os.path.isfile(dname):\n            dname = os.path.abspath(os.path.dirname(dname))\n        source, _ = _expand_source(source, dname, fmt)\n    _MMD_LIB.markdown_to_string.argtypes = [ctypes.c_char_p, ctypes.c_ulong, ctypes.c_int]\n    _MMD_LIB.markdown_to_string.restype = ctypes.c_char_p\n    src = source.encode('utf-8')\n    return _MMD_LIB.markdown_to_string(src, ext, fmt).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_from(fname, ext=COMPLETE, fmt=HTML):\n\n    dname = os.path.abspath(os.path.dirname(fname))\n    with open(fname, 'r') as fp:\n        src = fp.read()\n\n    return convert(src, ext, fmt, dname)", "response": "Reads in a file and performs MultiMarkdown conversion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting a manifest for a body of text with the given directory.", "response": "def manifest(txt, dname):\n    \"\"\"Extracts file manifest for a body of text with the given directory.\"\"\"\n    _, files = _expand_source(txt, dname, HTML)\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract metadata keys from the provided MultiMarkdown text.", "response": "def keys(source, ext=COMPLETE):\n    \"\"\"Extracts metadata keys from the provided MultiMarkdown text.\n\n    Keyword arguments:\n    source -- string containing MultiMarkdown text\n    ext -- extension bitfield for extracting MultiMarkdown\n    \"\"\"\n    _MMD_LIB.extract_metadata_keys.restype = ctypes.c_char_p\n    _MMD_LIB.extract_metadata_keys.argtypes = [ctypes.c_char_p, ctypes.c_ulong]\n    src = source.encode('utf-8')\n    all_keys = _MMD_LIB.extract_metadata_keys(src, ext)\n    all_keys = all_keys.decode('utf-8') if all_keys else ''\n    key_list = [ii for ii in all_keys.split('\\n') if ii]\n    return key_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the value for the specified metadata key from the given extension set.", "response": "def value(source, key, ext=COMPLETE):\n    \"\"\"Extracts value for the specified metadata key from the given extension set.\n\n    Keyword arguments:\n    source -- string containing MultiMarkdown text\n    ext -- extension bitfield for processing text\n    key -- key to extract\n    \"\"\"\n    _MMD_LIB.extract_metadata_value.restype = ctypes.c_char_p\n    _MMD_LIB.extract_metadata_value.argtypes = [ctypes.c_char_p, ctypes.c_ulong, ctypes.c_char_p]\n\n    src = source.encode('utf-8')\n    dkey = key.encode('utf-8')\n\n    value = _MMD_LIB.extract_metadata_value(src, ext, dkey)\n    return value.decode('utf-8') if value else ''"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nposting a new tweet.", "response": "def tweet(self, text, in_reply_to=None, filename=None, file=None):\n        \"\"\"\n        Post a new tweet.\n\n        :param text: the text to post\n        :param in_reply_to: The ID of the tweet to reply to\n        :param filename: If `file` param is not provided, read file from this path\n        :param file: A file object, which will be used instead of opening `filename`. `filename` is still required, for\n        MIME type detection and to use as a form field in the POST data\n        :return: Tweet object\n        \"\"\"\n\n        if filename is None:\n            return Tweet(self._client.update_status(status=text, in_reply_to_status_id=in_reply_to)._json)\n        else:\n            return Tweet(self._client.update_with_media(filename=filename, file=file,\n                                                        status=text, in_reply_to_status_id=in_reply_to)._json)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retweet(self, id):\n        try:\n            self._client.retweet(id=id)\n            return True\n        except TweepError as e:\n            if e.api_code == TWITTER_PAGE_DOES_NOT_EXISTS_ERROR:\n                return False\n            raise", "response": "Retweet a tweet in question."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tweet(self, id):\n        try:\n            return Tweet(self._client.get_status(id=id)._json)\n        except TweepError as e:\n            if e.api_code == TWITTER_TWEET_NOT_FOUND_ERROR:\n                return None\n            raise", "response": "Get an existing tweet."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a user s info.", "response": "def get_user(self, id):\n        \"\"\"\n        Get a user's info.\n\n        :param id: ID of the user in question\n        :return: User object. None if not found\n        \"\"\"\n        try:\n            return User(self._client.get_user(user_id=id)._json)\n        except TweepError as e:\n            if e.api_code == TWITTER_USER_NOT_FOUND_ERROR:\n                return None\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_tweet(self, id):\n        try:\n            self._client.destroy_status(id=id)\n            return True\n        except TweepError as e:\n            if e.api_code in [TWITTER_PAGE_DOES_NOT_EXISTS_ERROR, TWITTER_DELETE_OTHER_USER_TWEET]:\n                return False\n            raise", "response": "Delete a tweet from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef follow(self, user_id, notify=False):\n        try:\n            return User(self._client.create_friendship(user_id=user_id, follow=notify)._json)\n        except TweepError as e:\n            if e.api_code in [TWITTER_ACCOUNT_SUSPENDED_ERROR]:\n                return self.get_user(user_id)\n            raise", "response": "Follow a user.\n\n        :param user_id: ID of the user in question\n        :param notify: whether to notify the user about the following\n        :return: user that are followed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unfollow(self, user_id):\n        return User(self._client.destroy_friendship(user_id=user_id)._json)", "response": "Follow a user.\n\n        :param user_id: ID of the user in question\n        :return: The user that were unfollowed"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a list with the specified name and mode and description.", "response": "def create_list(self, name, mode='public', description=None):\n        \"\"\"\n        Create a list\n\n        :param name: Name of the new list\n        :param mode: :code:`'public'` (default) or :code:`'private'`\n        :param description: Description of the new list\n        :return: The new list object\n        :rtype: :class:`~responsebot.models.List`\n        \"\"\"\n        return List(tweepy_list_to_json(self._client.create_list(name=name, mode=mode, description=description)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndestroy a list :param list_id: list ID number :return: The destroyed list object :rtype: :class:`~responsebot.models.List`", "response": "def destroy_list(self, list_id):\n        \"\"\"\n        Destroy a list\n\n        :param list_id: list ID number\n        :return: The destroyed list object\n        :rtype: :class:`~responsebot.models.List`\n        \"\"\"\n        return List(tweepy_list_to_json(self._client.destroy_list(list_id=list_id)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_list(self, list_id, name=None, mode=None, description=None):\n        return List(tweepy_list_to_json(\n            self._client.update_list(list_id=list_id, name=name, mode=mode, description=description))\n        )", "response": "Update a list with the given name mode and description."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist the tweets of a list.", "response": "def list_timeline(self, list_id, since_id=None, max_id=None, count=20):\n        \"\"\"\n        List the tweets of specified list.\n\n        :param list_id: list ID number\n        :param since_id: results will have ID greater than specified ID (more recent than)\n        :param max_id: results will have ID less than specified ID (older than)\n        :param count: number of results per page\n        :return: list of :class:`~responsebot.models.Tweet` objects\n        \"\"\"\n        statuses = self._client.list_timeline(list_id=list_id, since_id=since_id, max_id=max_id, count=count)\n        return [Tweet(tweet._json) for tweet in statuses]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting info of specified list", "response": "def get_list(self, list_id):\n        \"\"\"\n        Get info of specified list\n\n        :param list_id: list ID number\n        :return: :class:`~responsebot.models.List` object\n        \"\"\"\n        return List(tweepy_list_to_json(self._client.get_list(list_id=list_id)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_list_member(self, list_id, user_id):\n        return List(tweepy_list_to_json(self._client.add_list_member(list_id=list_id, user_id=user_id)))", "response": "Add a user to a list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_list_member(self, list_id, user_id):\n        return List(tweepy_list_to_json(self._client.remove_list_member(list_id=list_id, user_id=user_id)))", "response": "Remove a user from a list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist users in a list", "response": "def list_members(self, list_id):\n        \"\"\"\n        List users in a list\n\n        :param list_id: list ID number\n        :return: list of :class:`~responsebot.models.User` objects\n        \"\"\"\n        return [User(user._json) for user in self._client.list_members(list_id=list_id)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_list_member(self, list_id, user_id):\n        try:\n            return bool(self._client.show_list_member(list_id=list_id, user_id=user_id))\n        except TweepError as e:\n            if e.api_code == TWITTER_USER_IS_NOT_LIST_MEMBER_SUBSCRIBER:\n                return False\n            raise", "response": "Check if a user is member of a list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubscribe to a list", "response": "def subscribe_list(self, list_id):\n        \"\"\"\n        Subscribe to a list\n\n        :param list_id: list ID number\n        :return: :class:`~responsebot.models.List` object\n        \"\"\"\n        return List(tweepy_list_to_json(self._client.subscribe_list(list_id=list_id)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unsubscribe_list(self, list_id):\n        return List(tweepy_list_to_json(self._client.unsubscribe_list(list_id=list_id)))", "response": "Unsubscribe to a list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting subscribers of a list.", "response": "def list_subscribers(self, list_id):\n        \"\"\"\n        List subscribers of a list\n\n        :param list_id: list ID number\n        :return: :class:`~responsebot.models.User` object\n        \"\"\"\n        return [User(user._json) for user in self._client.list_subscribers(list_id=list_id)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if user is a subscribed of list", "response": "def is_subscribed_list(self, list_id, user_id):\n        \"\"\"\n        Check if user is a subscribed of specified list\n\n        :param list_id: list ID number\n        :param user_id: user ID number\n        :return: :code:`True` if user is subscribed of list, :code:`False` otherwise\n        \"\"\"\n        try:\n            return bool(self._client.show_list_subscriber(list_id=list_id, user_id=user_id))\n        except TweepError as e:\n            if e.api_code == TWITTER_USER_IS_NOT_LIST_MEMBER_SUBSCRIBER:\n                return False\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform authentication with Twitter and return a client instance to communicate with Twitter", "response": "def auth(config):\n    \"\"\"\n    Perform authentication with Twitter and return a client instance to communicate with Twitter\n\n    :param config: ResponseBot config\n    :type config: :class:`~responsebot.utils.config_utils.ResponseBotConfig`\n    :return: client instance to execute twitter action\n    :rtype: :class:`~responsebot.responsebot_client.ResponseBotClient`\n    :raises: :class:`~responsebot.common.exceptions.AuthenticationError`: If failed to authenticate\n    :raises: :class:`~responsebot.common.exceptions.APIQuotaError`: If API call rate reached limit\n    \"\"\"\n    auth = tweepy.OAuthHandler(config.get('consumer_key'), config.get('consumer_secret'))\n    auth.set_access_token(config.get('token_key'), config.get('token_secret'))\n\n    api = tweepy.API(auth)\n    try:\n        api.verify_credentials()\n    except RateLimitError as e:\n        raise APIQuotaError(e.args[0][0]['message'])\n    except TweepError as e:\n        raise AuthenticationError(e.args[0][0]['message'])\n    else:\n        logging.info('Successfully authenticated as %s' % api.me().screen_name)\n\n        return ResponseBotClient(config=config, client=api)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the inputted JSON object to a python value.", "response": "def json2py(json_obj):\n    \"\"\"\n    Converts the inputted JSON object to a python value.\n    \n    :param      json_obj | <variant>\n    \"\"\"\n    for key, value in json_obj.items():\n        if type(value) not in (str, unicode):\n            continue\n\n        # restore a datetime\n        if re.match('^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}:\\d+$', value):\n            value = datetime.datetime.strptime(value, '%Y-%m-%d %H:%M:%S:%f')\n        elif re.match('^\\d{4}-\\d{2}-\\d{2}$', value):\n            year, month, day = map(int, value.split('-'))\n            value = datetime.date(year, month, day)\n        elif re.match('^\\d{2}:\\d{2}:\\d{2}:\\d+$', value):\n            hour, minute, second, micro = map(int, value.split(':'))\n            value = datetime.time(hour, minute, second, micro)\n        else:\n            found = False\n            for decoder in _decoders:\n                success, new_value = decoder(value)\n                if success:\n                    value = new_value\n                    found = True\n                    break\n\n            if not found:\n                continue\n\n        json_obj[key] = value\n    return json_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jsonify(py_data, default=None, indent=4, sort_keys=True):\n    return json.dumps(py_data, default=py2json, indent=indent, sort_keys=sort_keys)", "response": "Converts the inputted Python data to JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the inputted python object to JSON format.", "response": "def py2json(py_obj):\n    \"\"\"\n    Converts the inputted python object to JSON format.\n    \n    :param      py_obj | <variant>\n    \"\"\"\n    method = getattr(py_obj, '__json__', None)\n\n    if method:\n        return method()\n    elif type(py_obj) == datetime.datetime:\n        return py_obj.isoformat()\n    elif type(py_obj) == datetime.date:\n        return py_obj.isoformat()\n    elif type(py_obj) == datetime.time:\n        return py_obj.isoformat()\n    elif type(py_obj) == set:\n        return list(py_obj)\n    elif type(py_obj) == decimal.Decimal:\n        return str(py_obj)\n    else:\n        # look through custom plugins\n        for encoder in _encoders:\n            success, value = encoder(py_obj)\n            if success:\n                return value\n\n        opts = (py_obj, type(py_obj))\n        raise TypeError('Unserializable object {} of type {}'.format(*opts))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters an encoder and decoder method for processing a custom value.", "response": "def register(encoder=None, decoder=None):\n    \"\"\"\n    Registers an encoder method and/or a decoder method for processing\n    custom values.  Encoder and decoders should take a single argument\n    for the value to encode or decode, and return a tuple of (<bool>\n    success, <variant> value).  A successful decode or encode should\n    return True and the value.\n    \n    :param      encoder | <callable> || None\n                decoder | <callable> || None\n    \"\"\"\n    if encoder:\n        _encoders.append(encoder)\n    if decoder:\n        _decoders.append(decoder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xmlresponse(py_data):\n    xroot = ElementTree.Element('methodResponse')\n    xparams = ElementTree.SubElement(xroot, 'params')\n    xparam = ElementTree.SubElement(xparams, 'param')\n\n    type_map = {'bool': 'boolean',\n                'float': 'double',\n                'str': 'string',\n                'unicode': 'string',\n                'datetime': 'dateTime.iso8601',\n                'date': 'date.iso8601',\n                'time': 'time.iso8601'}\n\n    def xobj(xparent, py_obj):\n        # convert a list of information\n        if type(py_obj) in (tuple, list):\n            xarr = ElementTree.SubElement(xparent, 'array')\n            xdata = ElementTree.SubElement(xarr, 'data')\n            for val in py_obj:\n                xval = ElementTree.SubElement(xdata, 'value')\n                xobj(xval, val)\n\n        # convert a dictionary of information\n        elif type(py_obj) == dict:\n            xstruct = ElementTree.SubElement(xparent, 'struct')\n            for key, val in py_obj.items():\n                xmember = ElementTree.SubElement(xstruct, 'member')\n                xname = ElementTree.SubElement(xmember, 'name')\n                xname.text = key\n                xval = ElementTree.SubElement(xmember, 'value')\n                xobj(xval, val)\n\n        # convert a None value\n        elif py_obj is None:\n            ElementTree.SubElement(xparent, 'nil')\n\n        # convert a basic value\n        else:\n            typ = type(py_obj).__name__\n            typ = type_map.get(typ, typ)\n            xitem = ElementTree.SubElement(xparent, typ)\n\n            # convert a datetime/date/time\n            if isinstance(py_obj, datetime.date) or \\\n                    isinstance(py_obj, datetime.time) or \\\n                    isinstance(py_obj, datetime.datetime):\n\n                if py_obj.tzinfo and pytz:\n                    data = py_obj.astimezone(pytz.utc).replace(tzinfo=None)\n                    xitem.text = data.isoformat()\n                else:\n                    xitem.text = py_obj.isoformat()\n\n            # convert a boolean\n            elif type(py_obj) == bool:\n                xitem.text = nstr(int(py_obj))\n\n            # convert a non-string object\n            elif not type(py_obj) in (str, unicode):\n                xitem.text = nstr(py_obj)\n\n            # convert a string object\n            else:\n                xitem.text = py_obj\n\n    xobj(xparam, py_data)\n    projex.text.xmlindent(xroot)\n    return ElementTree.tostring(xroot)", "response": "Generates an XML formatted method response for the given Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_file(fname):\n    with open(fname) as input_file:\n        re_grammar = [x.strip('\\n') for x in input_file.readlines()]\n    return re_grammar", "response": "Reads the grammar file fname and returns a list of the grammar rules that are parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    if len(argv) < 3:\n        print 'Usage for getting CFG: %s CFG_fileA CFG ' % argv[0]\n        print 'Usage for getting STR: %s CFG_fileA STR ' \\\n              'Optimize[0 or 1] splitstring[0 or 1] ' % argv[0]\n        print ''\n        print 'For example: python pdacnf.py grammar.y STR 1 0'\n        print '             python pdacnf.py grammar.y STR 1 1'\n        print '             python pdacnf.py grammar.y CFG'\n        return\n\n    alphabet = createalphabet()\n\n    mode = argv[2]\n\n    optimized = 0\n    splitstring = 0\n    if mode == 'STR':\n        optimized = int(argv[3])\n        splitstring = int(argv[4])\n\n    cfgtopda = CfgPDA(alphabet)\n    print '* Parsing Grammar:',\n    mma = cfgtopda.yyparse(argv[1])\n    print 'OK'\n    print ' - Total PDA states are ' + repr(len(mma.s))\n\n    print '* Simplify State IDs:',\n    simple_a = SimplifyStateIDs()\n    mma.s, biggestid, newaccepted = simple_a.get(mma.s)\n    if newaccepted:\n        print 'OK'\n    else:\n        print 'OK'\n\n    print '* Eliminate READ states:',\n    replace = ReadReplace(mma.s, biggestid)\n    mma.s = replace.replace_read()\n    print 'OK'\n    print ' - Total PDA states now are ' + repr(len(mma.s))\n    maxstate = replace.nextstate() - 1\n\n    print '* Reduce PDA:',\n    simple_b = ReducePDA()\n    mma.s = simple_b.get(mma.s)\n    print 'OK'\n    print ' - Total PDA states now are ' + repr(len(mma.s))\n\n    print '* PDA to CFG transformation:',\n    cnfgenerator = PdaCnf(mma.s)\n    grammar = cnfgenerator.get_rules(optimized)\n    print 'OK'\n    print ' - Total CFG rules generated: ' + repr(len(grammar))\n\n    if mode == 'STR':\n        gen = CFGGenerator(CNFGenerator(grammar),\n                           optimized=optimized,\n                           splitstring=splitstring,\n                           maxstate=maxstate)\n        print gen.generate()\n    else:\n        print grammar", "response": "Function for PDA to CNF Operation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, statediag, dfaaccepted):\n\n        newstatediag = {}\n\n        newstate = PDAState()\n        newstate.id = 'AI,I'  # BECAREFUL WHEN SIMPLIFYING...\n        newstate.type = 1\n        newstate.sym = '@wrapping'\n        transitions = {}\n        transitions[(0, 0)] = [0]\n        newstate.trans = transitions\n        i = 0\n        newstatediag[i] = newstate\n        # print 'accepted:'\n        # print dfaaccepted\n        for stateid in statediag:\n            state = statediag[stateid]\n            # print state.id\n            if state.type == 2:\n                for state2id in dfaaccepted:\n                    # print state.id[1]\n                    if state.id[1] == state2id:\n                        # print 'adding...'\n                        state.trans['AI,I'] = ['@wrapping']\n                        # print state.trans\n                        break\n            i = i + 1\n            newstatediag[i] = state\n        return newstatediag", "response": "This function generates the new state and states for a given set of states."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bfs(self, graph, start):\n        newstatediag = {}\n\n        # maintain a queue of paths\n        queue = []\n        visited = []\n        # push the first path into the queue\n        queue.append(start)\n        while queue:\n            # get the first path from the queue\n            state = queue.pop(0)\n            # get the last node from the path\n            # visited\n            visited.append(state.id)\n            # enumerate all adjacent nodes, construct a new path and push it\n            # into the queue\n            for key in state.trans:\n                if state.trans[key] != []:\n                    if key not in visited:\n                        for nextstate in graph:\n                            if graph[nextstate].id == key:\n                                queue.append(graph[nextstate])\n                                break\n        i = 0\n        for state in graph:\n            if graph[state].id in visited:\n                newstatediag[i] = graph[state]\n                i = i + 1\n\n        return newstatediag", "response": "This function performs BFS operation for eliminating useless loop transitions\n            is a function that returns a list of the new state names that are used in the new state names."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a reduced list of states of the PDA with the same attributes as statediag.", "response": "def get(self, statediag):\n        \"\"\"\n        Args:\n            statediag (list): The states of the PDA\n        Returns:\n            list: A reduced list of states using BFS\n        \"\"\"\n        if len(statediag) < 1:\n            print 'PDA is empty and can not be reduced'\n            return statediag\n        newstatediag = self.bfs(statediag, statediag[0])\n        return newstatediag"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of states and states that are in the statediag and are in the order of the states that were in the statediag.", "response": "def get(self, statediag, accepted=None):\n        \"\"\"\n        Replaces complex state IDs as generated from the product operation,\n        into simple sequencial numbers. A dictionaty is maintained in order\n        to map the existed IDs.\n        Args:\n            statediag (list): The states of the PDA\n            accepted (list): the list of DFA accepted states\n        Returns:\n            list:\n        \"\"\"\n        count = 0\n        statesmap = {}\n        newstatediag = {}\n        for state in statediag:\n\n            # Simplify state IDs\n            if statediag[state].id not in statesmap:\n                statesmap[statediag[state].id] = count\n                mapped = count\n                count = count + 1\n            else:\n                mapped = statesmap[statediag[state].id]\n\n            # Simplify transitions IDs\n\n            transitions = {}\n            for nextstate in statediag[state].trans:\n                if nextstate not in statesmap:\n                    statesmap[nextstate] = count\n                    transmapped = count\n                    count = count + 1\n                else:\n                    transmapped = statesmap[nextstate]\n                transitions[transmapped] = statediag[state].trans[nextstate]\n            newstate = PDAState()\n            newstate.id = mapped\n            newstate.type = statediag[state].type\n            newstate.sym = statediag[state].sym\n            newstate.trans = transitions\n            newstatediag[mapped] = newstate\n        newaccepted = None\n        if accepted is not None:\n            newaccepted = []\n            for accepted_state in accepted :\n                if (0, accepted_state) in statesmap:\n                    newaccepted.append(statesmap[(0, accepted_state)])\n        return newstatediag, count, newaccepted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a new POP state with the same transitions.", "response": "def _generate_state(self, trans):\n        \"\"\"\n        Creates a new POP state (type - 2) with the same transitions.\n        The POPed symbol is the unique number of the state.\n        Args:\n            trans (dict): Transition dictionary\n        Returns:\n            Int: The state identifier\n        \"\"\"\n        state = PDAState()\n        state.id = self.nextstate()\n        state.type = 2\n        state.sym = state.id\n        state.trans = trans.copy()\n        self.toadd.append(state)\n        return state.id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing all READ states with a PUSH and a POP state.", "response": "def replace_read(self):\n        \"\"\"\n        Replaces all READ (type - 3) states to a PUSH (type - 1) and a POP (type - 2).\n        The actual state is replaced with the PUSH, and a new POP is created.\n        \"\"\"\n        for statenum in self.statediag:\n            state = self.statediag[statenum]\n            if state.type == 3:  # READ state\n                state.type = 1\n                destination_and_symbol = self._generate_state(state.trans)\n                state.sym = destination_and_symbol\n                state.trans = {}\n                state.trans[destination_and_symbol] = [0]\n        statenumber_identifier = len(self.statediag) + 1\n        for state in self.toadd:\n            self.statediag[statenumber_identifier] = state\n            statenumber_identifier = statenumber_identifier + 1\n        return self.statediag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert the current state to the empty set and all intemediate rules.", "response": "def insert_self_to_empty_and_insert_all_intemediate(self, optimized):\n        \"\"\"\n        For each state qi of the PDA, we add the rule Aii -> e\n        For each triplet of states qi, qj and qk, we add the rule Aij -> Aik Akj.\n        Args:\n            optimized (bool): Enable or Disable optimization - Do not produce O(n^3)\n        \"\"\"\n        for state_a in self.statediag:\n            self.rules.append('A' +repr(state_a.id) +',' + repr(state_a.id) + ': @empty_set')\n\n            # If CFG is not requested, avoid the following O(n^3) rule.\n            # It can be solved and a string can be generated faster with BFS of DFS\n\n            if optimized == 0:\n                for state_b in self.statediag:\n                    if state_b.id != state_a.id:\n                        for state_c in self.statediag:\n                            if state_c.id != state_a.id \\\n                                    and state_b.id != state_c.id:\n                                self.rules.append('A' + repr(state_a.id)\n                                                  + ',' + repr(state_c.id)\n                                                  + ': A' + repr(state_a.id)\n                                                  + ',' + repr(state_b.id)\n                                                  + ' A' + repr(state_b.id)\n                                                  + ',' + repr(state_c.id)\n                                                  + '')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_symbol_pushpop(self):\n\n        for state_a in self.statediag:\n            if state_a.type == 1:\n                found = 0\n                for state_b in self.statediag:\n                    if state_b.type == 2 and state_b.sym == state_a.sym:\n                        found = 1\n                        for j in state_a.trans:\n                            if state_a.trans[j] == [0]:\n                                read_a = ''\n                            else:\n                                new = []\n                                for selected_transition in state_a.trans[j]:\n                                    if selected_transition == ' ':\n                                        new.append('&')\n                                    else:\n                                        new.append(selected_transition)\n\n                                read_a = \" | \".join(new)\n                            for i in state_b.trans:\n                                if state_b.trans[i] == [0]:\n                                    read_b = ''\n                                else:\n                                    new = []\n                                    for selected_transition in state_b.trans[i]:\n                                        if selected_transition == ' ':\n                                            new.append('&')\n                                        else:\n                                            new.append(selected_transition)\n                                    read_b = \" | \".join(new)\n                                self.rules.append(\n                                    'A' + repr(state_a.id)\n                                    + ',' + repr(i)\n                                    + ':' + read_a\n                                    + ' A' + repr(j)\n                                    + ',' + repr(state_b.id)\n                                    + ' ' + read_b)\n                if found == 0:\n\n                    # A special case is required for State 2, where the POPed symbols\n                    # are part of the transitions array and not defined for \"sym\" variable.\n\n                    for state_b in self.statediag:\n                        if state_b.type == 2 and state_b.sym == 0:\n                            for i in state_b.trans:\n                                if state_a.sym in state_b.trans[i]:\n                                    for j in state_a.trans:\n                                        if state_a.trans[j] == [0]:\n                                            read_a = ''\n                                        else:\n                                            read_a = \" | \".join(\n                                                state_a.trans[j])\n                                        self.rules.append(\n                                            'A' + repr(state_a.id)\n                                            + ',' + repr(i)\n                                            + ':' + read_a\n                                            + ' A' + repr(j)\n                                            + ',' + repr(state_b.id))\n                                        # print\n                                        # 'A'+`state_a.id`+','+`i`+':'+read_a+'\n                                        # A'+`j`+','+`state_b.id`\n                                        found = 1\n                if found == 0:\n                    print \"ERROR: symbol \" + repr(state_a.sym) \\\n                          + \". It was not found anywhere in the graph.\"", "response": "Insert a rule Aik - > a Alj rule Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj rule B2 Aik - > a Alj b2 A"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the rules that can be used for the given entry.", "response": "def get_rules(self, optimized):\n        \"\"\"\n        Args:\n            optimized (bool): Enable or Disable optimization - Do not produce O(n^3)\n        Return:\n            list: The CFG rules\n        \"\"\"\n        self.insert_start_to_accepting()\n        # If CFG is not requested, avoid the following O(n^3) rule.\n        # It can be solved and a string can be generated faster with BFS of DFS\n\n        if optimized == 0:\n            self.insert_self_to_empty_and_insert_all_intemediate(optimized)\n        self.insert_symbol_pushpop()\n        return self.rules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprovisioning the instance with the specified parameters", "response": "def provision(self, instance_id: str, service_details: ProvisionDetails, async_allowed: bool) -> ProvisionedServiceSpec:\n        \"\"\"Provision the new instance\n        \n        see openbrokerapi documentation\n        \n        Returns:\n            ProvisionedServiceSpec\n        \"\"\"\n        \n        if service_details.plan_id == self._backend.config.UUID_PLANS_EXISTING_CLUSTER:\n            # Provision the instance on an Existing Atlas Cluster\n            \n            # Find or create the instance\n            instance = self._backend.find(instance_id)\n            \n            # Create the instance if needed\n            return self._backend.create(instance, service_details.parameters, existing=True)\n        \n        # Plan not supported\n        raise ErrPlanUnsupported(service_details.plan_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unbind(self, instance_id: str, binding_id: str, details: UnbindDetails):\n        \n        # Find the instance\n        instance = self._backend.find(instance_id)\n        \n        # Find the binding\n        binding = self._backend.find(binding_id, instance)\n        if not binding.isProvisioned():\n            # The binding does not exist\n            raise ErrBindingDoesNotExist()\n        \n        # Delete the binding\n        self._backend.unbind(binding)", "response": "Unbinds the instance and binding"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bind(self, instance_id: str, binding_id: str, details: BindDetails) -> Binding:\n        \n        # Find the instance\n        instance = self._backend.find(instance_id)\n        \n        # Find or create the binding\n        binding = self._backend.find(binding_id, instance)\n        \n        # Create the binding if needed\n        return self._backend.bind(binding, details.parameters)", "response": "Bind the instance to the binding_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the record ID of a specific IP", "response": "def _ddns(self, ip):\n        \"\"\"\n        curl -X POST https://dnsapi.cn/Record.Ddns -d 'login_token=LOGIN_TOKEN&format=json&domain_id=2317346&record_id=16894439&record_line=\u9ed8\u8ba4&sub_domain=www'\n        :return:\n        \"\"\"\n\n        headers = {\"Accept\": \"text/json\", \"User-Agent\": \"ddns/0.1.0 (imaguowei@gmail.com)\"}\n\n        data = {\n            'login_token': self.login_token,\n            'format': \"json\",\n            'domain_id': self.domain_id,\n            'record_id': self.record_id,\n            'sub_domain': self.sub_domain,\n            'record_line': '\u9ed8\u8ba4',\n            'value': ip\n        }\n\n        res = requests.post(Ddns.DNSPOD_API, data, headers=headers)\n        logger.debug(res.json())\n        return res.json()['status']['code'] == '1'"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a POST request", "response": "def post(self, path, data={}):\n        '''Perform POST Request '''\n        response = requests.post(API_URL + path, data=json.dumps(data), headers=self._set_headers())\n        return self._check_response(response, self.post, path, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, path, data={}):\n        '''Perform DELETE Request'''\n        if len(data) != 0:\n            parameter_string = ''\n            for k,v in data.items():\n                parameter_string += '{}={}'.format(k,v)\n                parameter_string += '&'\n            path += '?' + parameter_string\n\n        response = requests.delete(API_URL + path, headers=self._set_headers())\n        return self._check_response(response, self.delete, path, data)", "response": "Perform a DELETE request"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the ConfigParser object which represents the content.", "response": "def parsed(self):\n        \"\"\"Get the ConfigParser object which represents the content.\n\n        This property is cached and only parses the content once.\n        \"\"\"\n        if not self._parsed:\n\n            self._parsed = ConfigParser()\n            self._parsed.readfp(io.StringIO(self.content))\n\n        return self._parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_cache(directory, compress_level=6, value_type_is_binary=False, **kwargs):\n    cache = diskcache.Cache(\n        directory,\n        disk=CompressedDisk,\n        disk_compress_level=compress_level,\n        disk_value_type_is_binary=value_type_is_binary,\n        **kwargs\n    )\n    return cache", "response": "Create a html cache. Html string will be automatically compressed.\n\n    :param directory: path for the cache directory.\n    :param compress_level: 0 ~ 9, 9 is slowest and smallest.\n    :param kwargs: other arguments.\n    :return: a `diskcache.Cache()`"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a sequence of time items from a given timedelta", "response": "def timeticks(tdiff):\n    \"\"\"\n    NOTE do NOT use \"interval\" or ticks are misaligned!  use \"bysecond\" only!\n    \"\"\"\n    if isinstance(tdiff, xarray.DataArray):  # len==1\n        tdiff = timedelta(seconds=tdiff.values / np.timedelta64(1, 's'))\n\n    assert isinstance(tdiff, timedelta), 'expecting datetime.timedelta'\n\n    if tdiff > timedelta(hours=2):\n        return None, None\n\n    elif tdiff > timedelta(minutes=20):\n        return MinuteLocator(byminute=range(0, 60, 5)), MinuteLocator(byminute=range(0, 60, 2))\n\n    elif (timedelta(minutes=10) < tdiff) & (tdiff <= timedelta(minutes=20)):\n        return MinuteLocator(byminute=range(0, 60, 2)), MinuteLocator(byminute=range(0, 60, 1))\n\n    elif (timedelta(minutes=5) < tdiff) & (tdiff <= timedelta(minutes=10)):\n        return MinuteLocator(byminute=range(0, 60, 1)), SecondLocator(bysecond=range(0, 60, 30))\n\n    elif (timedelta(minutes=1) < tdiff) & (tdiff <= timedelta(minutes=5)):\n        return SecondLocator(bysecond=range(0, 60, 30)), SecondLocator(bysecond=range(0, 60, 10))\n\n    elif (timedelta(seconds=30) < tdiff) & (tdiff <= timedelta(minutes=1)):\n        return SecondLocator(bysecond=range(0, 60, 10)), SecondLocator(bysecond=range(0, 60, 2))\n\n    else:\n        return SecondLocator(bysecond=range(0, 60, 2)),  SecondLocator(bysecond=range(0, 60, 1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, bubble_home, config, verbose, barverbose, profile):\n\n    # Create a bubble object and remember it as the context object.\n    # From this point onwards other commands can refer to it by using the\n    # @pass_bubble decorator.\n\n    cis = ctx.invoked_subcommand\n    initing = False\n\n    if cis == 'stats':\n        nagios = False\n        try:\n            monitor = ctx.args[ctx.args.index('--monitor') + 1]\n            if monitor == 'nagios':\n                nagios = True\n        except (ValueError, IndexError):\n            pass\n        if nagios:\n            verbose = 0\n\n    BUBBLE_CLI_GLOBALS['profiling'] = profile\n    if profile:\n        start_profile()\n\n    global VERBOSE\n    VERBOSE = verbose\n\n    global VERBOSE_BAR\n    VERBOSE_BAR = barverbose\n\n    if bubble_home != '.':\n        bubble_home_abs = os.path.abspath(bubble_home)\n    else:\n        bubble_home_abs = os.path.abspath(os.getcwd())\n\n    if cis == 'init':\n        initing = True\n    if initing:\n        if not os.path.exists(bubble_home_abs):\n            os.makedirs(bubble_home_abs)\n\n    if os.path.exists(bubble_home_abs):\n        os.chdir(bubble_home_abs)\n        ctx.obj = BubbleCli(home=bubble_home_abs,\n                            verbose=verbose,\n                            verbose_bar=barverbose)\n    else:\n        click.echo('Bubble home path does not exist: ' + bubble_home_abs)\n        raise click.Abort()\n\n    BUBBLE_CLI_GLOBALS['full_command'] = ' '.join(sys.argv)\n\n    for key, value in config:\n        ctx.obj.set_config(key, value)\n    if not ctx.obj.bubble and not initing:\n        ctx.obj.say_yellow('There is no bubble in %s' %\n                           bubble_home_abs, verbosity=10)\n        ctx.obj.say('You can start one with: bubble init', verbosity=10)", "response": "Bubble command line tool for bubbling information between services."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls with each incoming fedmsg. and then we monitor to see if it has completed.", "response": "def consume(self, msg):\n        \"\"\"Called with each incoming fedmsg.\n\n        From here we trigger an rpm-ostree compose by touching a specific file\n        under the `touch_dir`. Then our `doRead` method is called with the\n        output of the rpm-ostree-toolbox treecompose, which we monitor to\n        determine when it has completed.\n        \"\"\"\n        self.log.info(msg)\n        body = msg['body']\n        topic = body['topic']\n        repo = None\n\n        if 'rawhide' in topic:\n            arch = body['msg']['arch']\n            self.log.info('New rawhide %s compose ready', arch)\n            repo = 'rawhide'\n        elif 'branched' in topic:\n            arch = body['msg']['arch']\n            branch = body['msg']['branch']\n            self.log.info('New %s %s branched compose ready', branch, arch)\n            log = body['msg']['log']\n            if log != 'done':\n                self.log.warn('Compose not done?')\n                return\n            repo = branch\n        elif 'updates.fedora' in topic:\n            self.log.info('New Fedora %(release)s %(repo)s compose ready',\n                          body['msg'])\n            repo = 'f%(release)s-%(repo)s' % body['msg']\n        else:\n            self.log.warn('Unknown topic: %s', topic)\n\n        release = self.releases[repo]\n        reactor.callInThread(self.compose, release)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a 1 - to 3 - part address spec.", "response": "def parse_addr(text):\n    \"Parse a 1- to 3-part address spec.\"\n    if text:\n        parts = text.split(':')\n        length = len(parts)\n        if length== 3:\n            return parts[0], parts[1], int(parts[2])\n        elif length == 2:\n            return None, parts[0], int(parts[1])\n        elif length == 1:\n            return None, '', int(parts[0])\n    return None, None, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a single packet and update the internal tables.", "response": "def _process(self, data):\n        \"Process a single packet and update the internal tables.\"\n        parts = data.split(':')\n        if self._debug:\n            self.error('packet: %r' % data)\n        if not parts:\n            return\n\n        # interpret the packet and update stats\n        stats = self._stats\n        key = parts[0].translate(KEY_TABLE, KEY_DELETIONS)\n        if self._key_prefix:\n            key = '.'.join([self._key_prefix, key])\n        for part in parts[1:]:\n            srate = 1.0\n            fields = part.split('|')\n            length = len(fields)\n            if length < 2:\n                continue\n            value = fields[0]\n            stype = fields[1].strip()\n\n            with stats_lock:\n                # timer (milliseconds)\n                if stype == 'ms':\n                    stats.timers[key].append(float(value if value else 0))\n\n                # counter with optional sample rate\n                elif stype == 'c':\n                    if length == 3 and fields[2].startswith('@'):\n                        srate = float(fields[2][1:])\n                    value = float(value if value else 1) * (1 / srate)\n                    stats.counts[key] += value\n                elif stype == 'g':\n                    value = float(value if value else 1)\n                    stats.gauges[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse as generic step that provides an additional remark/hint and enhance the readability/understanding without performing any check. .. code-block:: gherkin Given that today is \"April 1st\" But note that \"April 1st is Fools day (and beware)\"", "response": "def step_note_that(context, remark):\n    \"\"\"\n    Used as generic step that provides an additional remark/hint\n    and enhance the readability/understanding without performing any check.\n\n    .. code-block:: gherkin\n\n        Given that today is \"April 1st\"\n          But note that \"April 1st is Fools day (and beware)\"\n    \"\"\"\n    log = getattr(context, \"log\", None)\n    if log:\n        log.info(u\"NOTE: %s;\" % remark)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the section of the resource if any.", "response": "def section(self, resources):\n        \"\"\" Which section is this in, if any \"\"\"\n\n        section = [p for p in self.parents(resources) if p.rtype == 'section']\n        if section:\n            return section[0]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef in_navitem(self, resources, nav_href):\n\n        # The navhref might end with '/index' so remove it if so\n        if nav_href.endswith('/index'):\n            nav_href = nav_href[:-6]\n\n        return self.docname.startswith(nav_href)", "response": "Determines if the resource is in the given nav item"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn true if this resource has published date in the past", "response": "def is_published(self):\n        \"\"\" Return true if this resource has published date in the past \"\"\"\n\n        now = datetime.now()\n        published = self.props.published\n        if published:\n            return published < now\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an HTTP request. This constructs a full URL, encodes and decodes HTTP bodies, and handles invalid responses in a pythonic way. @type method: string @param method: HTTP method to use @type path: string @param path: HTTP URL path @type query: list of two-tuples @param query: query arguments to pass to urllib.urlencode @type content: str or None @param content: HTTP body content @rtype: object @return: JSON-Decoded response @raises GanetiApiError: If an invalid response is returned", "response": "def request(self, method, path, query=None, content=None):\n        \"\"\"\n        Sends an HTTP request.\n\n        This constructs a full URL, encodes and decodes HTTP bodies, and\n        handles invalid responses in a pythonic way.\n\n        @type method: string\n        @param method: HTTP method to use\n        @type path: string\n        @param path: HTTP URL path\n        @type query: list of two-tuples\n        @param query: query arguments to pass to urllib.urlencode\n        @type content: str or None\n        @param content: HTTP body content\n\n        @rtype: object\n        @return: JSON-Decoded response\n\n        @raises GanetiApiError: If an invalid response is returned\n        \"\"\"\n\n        kwargs = {\n            \"headers\": headers,\n            \"timeout\": self.timeout,\n            \"verify\": False,\n        }\n\n        if self.username and self.password:\n            kwargs[\"auth\"] = self.username, self.password\n\n        if content is not None:\n            kwargs[\"data\"] = self._json_encoder.encode(content)\n\n        if query:\n            prepare_query(query)\n            kwargs[\"params\"] = query\n\n        url = self._base_url + path\n\n        # print \"Sending request to %s %s\" % (url, kwargs)\n\n        try:\n            r = requests.request(method, url, **kwargs)\n        except requests.ConnectionError:\n            raise GanetiApiError(\"Couldn't connect to %s\" % self._base_url)\n        except requests.Timeout:\n            raise GanetiApiError(\"Timed out connecting to %s\" %\n                                 self._base_url)\n\n        if r.status_code != requests.codes.ok:\n            raise NotOkayError(str(r.status_code), code=r.status_code)\n\n        if r.content:\n            return json.loads(r.content)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n\n        version = self.request(\"get\", \"/version\")\n\n        if version != 2:\n            raise GanetiApiError(\"Can't work with Ganeti RAPI version %d\" %\n                                 version)\n\n        logging.info(\"Accessing Ganeti RAPI, version %d\" % version)\n        self.version = version\n\n        try:\n            features = self.request(\"get\", \"/2/features\")\n        except NotOkayError, noe:\n            if noe.code == 404:\n                # Okay, let's calm down, this is totally reasonable. Certain\n                # older Ganeti RAPIs don't have a list of features.\n                features = []\n            else:\n                # No, wait, panic was the correct thing to do.\n                raise\n\n        logging.info(\"RAPI features: %r\" % (features,))\n        self.features = features", "response": "Start the target cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate webdriver assign it to self. driver and run init_driver_func.", "response": "def _create_driver(self, **kwargs):\n        \"\"\"\n        Create webdriver, assign it to ``self.driver``, and run webdriver\n        initiation process, which is usually used for manual login.\n        \"\"\"\n        if self.driver is None:\n            self.driver = self.create_driver(**kwargs)\n            self.init_driver_func(self.driver)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget html of an url.", "response": "def get_html(self,\n                 url,\n                 params=None,\n                 cache_cb=None,\n                 **kwargs):\n        \"\"\"\n        Get html of an url.\n        \"\"\"\n        url = add_params(url, params)\n        cache_consumed, value = self.try_read_cache(url)\n        if cache_consumed:\n            html = value\n        else:\n            self._create_driver()\n            self.driver.get(url)\n            html = self.driver.page_source\n\n        if self.should_we_update_cache(html, cache_cb, cache_consumed):\n            self.cache.set(\n                url, html,\n                expire=kwargs.get(\"cache_expire\", self.cache_expire),\n            )\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize_time(data):\n    parsed = parser.parse(data)\n    return parsed.time().replace(tzinfo=parsed.tzinfo)", "response": "Deserialize a time instance based on the values of the data param"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling a set of packages using pip. main", "response": "def require(*args, **kwargs):\n    '''\n    Install a set of packages using pip\n    \n    This is designed to be an interface for IPython notebooks that\n    replicates the requirements.txt pip format. This lets notebooks\n    specify which versions of packages they need inside the notebook\n    itself.\n\n    This function is the general-purpose interface that lets\n    the caller specify any version string for any package.\n\n    '''\n    # If called with no arguments, returns requirements list\n    if not args and not kwargs:\n        return freeze()\n\n    # Construct array of requirements\n    requirements = list(args)\n    extra = ['{}{}'.format(kw, kwargs[kw]) for kw in kwargs]\n    requirements.extend(extra)\n    args = ['install', '-q']\n    args.extend(requirements)\n    pip.main(args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the dumpdb command.", "response": "def handle(self, *args, **options):\n        \"\"\"\n        Compares current database with a migrations.\n        \n        Creates a temporary database, applies all the migrations to it, and\n        then dumps the schema from both current and temporary, diffs them,\n        then report the diffs to the user.\n        \"\"\"\n        self.db = options.get(\"database\", DEFAULT_DB_ALIAS)\n        self.current_name = connections[self.db].settings_dict[\"NAME\"]\n        self.compare_name = options.get(\"db_name\")\n        self.lines = options.get(\"lines\")\n        self.ignore = int(options.get('ignore'))\n\n        if not self.compare_name:\n            self.compare_name = \"%s_compare\" % self.current_name\n        \n        command = NASHVEGAS.get(\"dumpdb\", \"pg_dump -s {dbname}\")\n        \n        print \"Getting schema for current database...\"\n        current_sql = Popen(\n            command.format(dbname=self.current_name),\n            shell=True,\n            stdout=PIPE\n        ).stdout.readlines()\n        \n        print \"Getting schema for fresh database...\"\n        self.setup_database()\n        connections[self.db].close()\n        connections[self.db].settings_dict[\"NAME\"] = self.compare_name\n        try:\n            call_command(\"syncdb\", interactive=False, verbosity=0, migrations=False)\n            new_sql = Popen(\n                command.format(dbname=self.compare_name).split(),\n                stdout=PIPE\n            ).stdout.readlines()\n        finally:\n            connections[self.db].close()\n            connections[self.db].settings_dict[\"NAME\"] = self.current_name\n            self.teardown_database()\n        \n        print \"Outputing diff between the two...\"\n        print \"\".join(difflib.unified_diff(normalize_sql(current_sql, self.ignore),\n                                           normalize_sql(new_sql, self.ignore),\n                                           n=int(self.lines)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngoes through the docs and replace the widgets directive with rendering", "response": "def render_widgets(kb_app: kb,\n                   sphinx_app: Sphinx,\n                   doctree: doctree,\n                   fromdocname: str,\n                   ):\n    \"\"\" Go through docs and replace widget directive with rendering \"\"\"\n\n    builder: StandaloneHTMLBuilder = sphinx_app.builder\n\n    for node in doctree.traverse(widget):\n        # Render the output\n        w = sphinx_app.env.widgets.get(node.name)\n        context = builder.globalcontext.copy()\n\n        # Add in certain globals\n        context['resources'] = sphinx_app.env.resources\n        context['references'] = sphinx_app.env.references\n        output = w.render(sphinx_app, context)\n\n        # Put the output into the node contents\n        listing = [nodes.raw('', output, format='html')]\n        node.replace_self(listing)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a string consisting of key = value substrings for each keyword argument in kwargs.", "response": "def attr_string(filterKeys=(), filterValues=(), **kwargs):\n    \"\"\"Build a string consisting of 'key=value' substrings for each keyword\n    argument in :kwargs:\n\n    @param filterKeys: list of key names to ignore\n    @param filterValues: list of values to ignore (e.g. None will ignore all\n                         key=value pairs that has that value.\n    \"\"\"\n    return ', '.join([str(k)+'='+repr(v) for k, v in kwargs.items()\n                      if k not in filterKeys and v not in filterValues])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the auth string.", "response": "def auth_string(self):\n        \"\"\"\n        Get the auth string. If the token is expired and auto refresh enabled,\n        a new token will be fetched\n\n        :return: the auth string\n        :rtype: str\n        \"\"\"\n        if not self._token:\n            self.execute()\n\n        if not self._token.expired:\n            return 'Bearer {}'.format(self._token.access_token)\n\n        if self.auto_refresh:\n            self.execute()\n            return 'Bearer {}'.format(self._token.access_token)\n\n        raise TokenExpired()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the data from a * hole instance.", "response": "async def main():\n    \"\"\"Get the data from a *hole instance.\"\"\"\n    async with aiohttp.ClientSession() as session:\n        data = Hole('192.168.0.215', loop, session)\n        await data.get_data()\n\n        # Get the raw data\n        print(json.dumps(data.data, indent=4, sort_keys=True))\n\n        print(\"Status:\", data.status)\n        print(\"Domains being blocked:\", data.domains_being_blocked)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def enable():\n    async with aiohttp.ClientSession() as session:\n        data = Hole('192.168.0.215', loop, session, api_token=API_TOKEN)\n        await data.enable()", "response": "Enable the data from a * hole instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\naudit the current state of the current PCI entry.", "response": "def audit(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Pretreatment Compliance Inspections (PCI) or Pretreatment Audits\n        collect information resulting from inspections pertaining to a Publicly\n        Owned Treatment Works (POTWs) that receive pollutants from in direct\n        dischargers.\n\n        >>> PCS().audit('insp_date', '16-MAR-01')\n        \"\"\"\n        return self._resolve_call('PCS_PCI_AUDIT', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the description of the code value of the current key - value entry.", "response": "def code_description(self, column=None, value=None, **kwargs):\n        \"\"\"\n        The Permit Compliance System (PCS) records milestones, events, and many\n        other parameters in code format. To provide text descriptions that\n        explain the code meanings, the PCS_CODE_DESC provide s complete\n        information on all types of codes, and for each type, the text\n        description of each possible code value.\n\n        >>> PCS().code_description('code', 110)\n        \"\"\"\n        return self._resolve_call('PCS_CODE_DESC', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compliance_schedule(self, column=None, value=None, **kwargs):\n        return self._resolve_call('PCS_CMPL_SCHD', column, value, **kwargs)", "response": "A sequence of activities with associated milestones which pertains to a given permit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dmr_measurement(self, column=None, value=None, **kwargs):\n        return self._resolve_call('PCS_DMR_MEASUREMENT', column, value, **kwargs)", "response": "Return the measurement of effluents reported on the Discharge Monitoring Report\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenforces an action taken against a permit facility.", "response": "def enforcement_action(self, column=None, value=None, **kwargs):\n        \"\"\"\n         A disciplinary action taken against a permit facility. The action may\n         be applicable to one or more violations.\n\n         >>> PCS().enforcement_action('ea_code', '09')\n        \"\"\"\n        return self._resolve_call('PCS_ENFOR_ACTION', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hearing(self, column=None, value=None, **kwargs):\n        return self._resolve_call('PCS_EVIDENTIARY_HEARING_EVENT', column,\n                                  value, **kwargs)", "response": "An evidentiary hearing event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget information about the industrial user.", "response": "def industrial_user(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Information from the PCI_AUDIT table pertaining to industrial users,\n        i.e. the number of significant industrial users.\n\n        >>> PCS().industrial_user('insp_date', '16-MAR-01')\n        \"\"\"\n        return self._resolve_call('PCS_INDUSTRIAL_USER_INFO', column,\n                                  value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pipe_schedule(self, column=None, value=None, **kwargs):\n        return self._resolve_call('PCS_PIPE_SCHED', column, value, **kwargs)", "response": "Schedule a permit facility for a permit facility that is governed by the permit facility that are governed by effluent limitations and monitoring and submission requirements."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the value of a sludge column.", "response": "def sludge(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Sludge information describes the volumn of sludge produced at a\n        facility, identification information on a sludge handler, and\n        classification/permitting information on a facility that handles\n        sludge, such as a pretreatment POTW.\n\n        >>> PCS().sludge('county_name', 'San Francisco')\n        \"\"\"\n        return self._resolve_call('PCS_SLUDGE', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef typify(value: Union[dict, list, set, str]):\n    if type(value) == dict:\n        return walk_values(typify, value)\n\n    if type(value) in [list, set]:\n        return list(map(typify, value))\n\n    if type(value) == str:\n        if re.match('^\\d+\\.\\d+ (STEEM|SBD|VESTS)$', value):\n            return keep_in_dict(dict(Amount(value)), ['amount', 'asset'])\n\n        if re.match('^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}$', value):\n            return parse_time(value)\n\n    return value", "response": "Enhance block operation with native types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, subnet_id):\n        # 1 : show subnet\n        subnet = self.client.describe_subnets(\n            SubnetIds=[subnet_id]).get('Subnets')[0]\n        vpc_id = subnet.get('VpcId')\n        # 2 : delete subnet\n        self.client.delete_subnet(SubnetId=subnet_id)\n        # 3 : delete vpc\n        return self.client.delete_vpc(VpcId=vpc_id)", "response": "Delete a specific vpc and all related resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self):\n\n        result = self._gen(self.optimized, self.splitstring)\n        if self.splitstring and result is not None:\n            result = result[1:]\n        return result", "response": "Generates a new random string from the start symbol\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all non existing terminals from the grammar.", "response": "def _clean_terminals(self):\n        \"\"\"\n        Because of the optimization, there are some non existing terminals\n        on the generated list. Remove them by checking for terms in form Ax,x\n        \"\"\"\n        new_terminals = []\n        for term in self.grammar.grammar_terminals:\n            x_term = term.rfind('@')\n            y_term = term.rfind('A')\n            if y_term > x_term:\n                x_term = y_term\n            ids = term[x_term + 1:].split(',')\n            if len(ids) < 2:\n                \"\"\"It'input_string a normal terminal, not a state\"\"\"\n                new_terminals.append(term)\n        self.grammar.grammar_terminals = new_terminals"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_self_to_empty(self, stateid):\n        x_term = stateid.rfind('@')\n        y_term = stateid.rfind('A')\n        if y_term > x_term:\n            x_term = y_term\n        ids = stateid[x_term + 1:].split(',')\n        if len(ids) < 2:\n            return 0\n        if ids[0] == ids[1]:\n            #    print 'empty'\n            return 1\n        return 0", "response": "This function checks if the state identifier is missing or empty."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_intemediate(self, myntr, maxstate):\n        # print 'BFS Dictionary Update - Intermediate'\n        x_term = myntr.rfind('@')\n        y_term = myntr.rfind('A')\n        if y_term > x_term:\n            x_term = y_term\n        ids = myntr[x_term + 1:].split(',')\n        if len(ids) < 2:\n            return 0\n        i = ids[0]\n        j = ids[1]\n        r = 0\n        find = 0\n        while r < maxstate:\n            if r != i and r != j:\n                if 'A' + i + ',' + \\\n                        repr(r) not in self.resolved \\\n                        and 'A' + j + ',' + repr(r) in self.resolved:\n                    self.resolved[\n                        'A' + i + ',' + repr(r)] = self.resolved[myntr] \\\n                                                   + self.resolved['A' + j + ',' + repr(r)]\n                    if self._checkfinal('A' + i + ',' + repr(r)):\n                        return self.resolved['A' + i + ',' + repr(r)]\n                    if 'A' + i + ',' + repr(r) not in self.bfs_queue:\n                        self.bfs_queue.append('A' + i + ',' + repr(r))\n                    find = 1\n                if 'A' + repr(r) + ',' + j not in self.resolved and 'A' + \\\n                        repr(r) + ',' + i in self.resolved:\n                    self.resolved[\n                        'A' + repr(r) + ',' + j] = self.resolved['A' + repr(r) + ',' + i] \\\n                                                   + self.resolved[myntr]\n                    if self._checkfinal('A' + repr(r) + ',' + j):\n                        return self.resolved['A' + repr(r) + ',' + j]\n                    if 'A' + repr(r) + ',' + j not in self.bfs_queue:\n                        self.bfs_queue.append('A' + repr(r) + ',' + j)\n                    find = 1\n            r = r + 1\n        if find == 1:\n            return 1\n        return 0", "response": "This function checks if the given Myntr is in the appropriate state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_self_replicate(self, myntr):\n        # print 'BFS Dictionary Update - Self Replicate'\n        find = 0\n        for nonterm in self.grammar.grammar_nonterminals_map:\n            for i in self.grammar.grammar_nonterminals_map[nonterm]:\n                if self.grammar.grammar_rules[i][0] not in self.resolved and not isinstance(\n                        self.grammar.grammar_rules[i][1], (set, tuple)) \\\n                        and self.grammar.grammar_rules[i][1] == myntr:\n                    self.resolved[self.grammar.grammar_rules[i][0]] = self.resolved[myntr]\n                    if self._checkfinal(self.grammar.grammar_rules[i][0]):\n                        return self.resolved[self.grammar.grammar_rules[i][0]]\n                    if self.grammar.grammar_rules[i][0] not in self.bfs_queue:\n                        self.bfs_queue.append(self.grammar.grammar_rules[i][0])\n                    find = 1\n        if find == 1:\n            return 1\n        return 0", "response": "This function checks if the current terminal is a known terminal and if so updates the internal state of the BFS dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a new random object from the nonterminal and returns it.", "response": "def _gen(self, optimized, splitstring):\n        \"\"\"Generates a new random object generated from the nonterminal\n        Args:\n            optimized (bool): mode of operation - if enabled not all\n                            CNF rules are included (mitigate O(n^3))\n            splitstring (bool): A boolean for enabling or disabling\n        Returns:\n            str: The generated string\n        \"\"\"\n        # Define Dictionary that holds resolved rules\n        # (only in form A -> terminals sequence)\n        self.resolved = {}\n        # First update Resolved dictionary by adding rules\n        # that contain only terminals (resolved rules)\n        for nt in self.grammar.grammar_nonterminals_map:\n            for i in self.grammar.grammar_nonterminals_map[nt]:\n                if self.grammar.grammar_rules[i][0] not in self.resolved\\\n                        and not isinstance(self.grammar.grammar_rules[i][1], (set, tuple)):\n                    if self.grammar.grammar_rules[i][1] != '@empty_set' \\\n                            and self.grammar.grammar_rules[i][1] in self.grammar.grammar_terminals:\n\n                        if splitstring:\n                            self.resolved[\n                                self.grammar.grammar_rules[i][0]] = self.grammar.grammar_rules[i][1]\n                        else:\n                            if self.grammar.grammar_rules[i][1] == '&':\n                                self.resolved[self.grammar.grammar_rules[i][0]] = ' '\n                            else:\n                                self.resolved[\n                                    self.grammar.grammar_rules[i][0]] = self.grammar.grammar_rules[i][1]\n                        # print 'ResolvingA '+self.g.Rules[i][0]+\": \"+\n                        # self.g.Rules[i][1]\n                        if self._checkfinal(self.grammar.grammar_rules[i][0]):\n                            return self.resolved[self.grammar.grammar_rules[i][0]]\n                        if self.grammar.grammar_rules[i][0] not in self.bfs_queue:\n                            self.bfs_queue.append(self.grammar.grammar_rules[i][0])\n                    if self.grammar.grammar_rules[i][1] == '@empty_set':\n                        self.resolved[self.grammar.grammar_rules[i][0]] = ''\n                        # print 'ResolvingB '+self.g.Rules[i][0]+\": \"\n                        self.bfs_queue.append(self.grammar.grammar_rules[i][0])\n                    if optimized and self._check_self_to_empty(\n                            self.grammar.grammar_rules[i][1]):\n                        self.resolved[self.grammar.grammar_rules[i][0]] = ''\n                        # print 'ResolvingC '+self.g.Rules[i][0]+\": \"\n                        if self.grammar.grammar_rules[i][0] not in self.bfs_queue:\n                            self.bfs_queue.append(self.grammar.grammar_rules[i][0])\n\n        # Then try to use the rules from Resolved dictionary and check\n        # if there is another rule that can be resolved.\n        # This should be done in a while loop\n        change = 1\n        while change:\n            change = 0\n            if not change:\n                ret = self._check_self_nonterminals(optimized)\n                if ret == 1:\n                    change = 1\n                elif ret != 0:\n                    return ret\n            if not change:\n                while not change and len(self.bfs_queue) > 0:\n                    myntr = self.bfs_queue.pop()\n                    ret = self._check_self_replicate(myntr)\n                    if ret == 1:\n                        change = 1\n                    elif ret != 0:\n                        return ret\n                    if optimized and self._check_intemediate(\n                            myntr, self.maxstate):\n                        change = 1\n                        break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef project_workspace_addsitedir(sitedir):\n    assert os.path.isdir(sitedir)\n    try:\n        from site import addsitedir\n    except ImportError:\n        # -- USE: Python2.7 site.py package\n        from pysite import addsitedir\n    next_package_pos = len(sys.path)\n    addsitedir(sitedir)\n\n    # -- POST-PROCESS: Move new packages from end to begin of sys.path list.\n    pos = 0\n    new_packages = sys.path[next_package_pos:]\n    del sys.path[next_package_pos:]\n    sys.path[pos:pos] = new_packages", "response": "This function adds a new site - packages directory to the project s path list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating or get a new symbol.", "response": "def create(self, name, description=None, units=None,\r\n               agg_method=\"priority_fill\", overwrite=False):\r\n        \"\"\" Create, or get if exists, a Symbol.\r\n        \r\n        Parameters\r\n        ----------\r\n        name : str\r\n            A symbol's name is a primary key, used across\r\n            the Trump ORM.\r\n        description : str, optional\r\n            An arbitrary string, used to store user information\r\n            related to the symbol.\r\n        units : str, optional\r\n            This is a string used to denote the units of the final\r\n            data Series.\r\n        agg_method : str, optional\r\n            The aggregation method, used to calculate\r\n            the final feed.  Defaults to priority_fill.\r\n        overwrite : bool, optional\r\n            Set to True, to force deletion an existing symbol.\r\n            defaults to False.\r\n            \r\n        Returns\r\n        -------\r\n        Symbol\r\n        \"\"\"\r\n        sym = self.try_to_get(name)\r\n\r\n        if sym is not None:\r\n            if overwrite:\r\n                print \"Deleting {}\".format(sym.name)\r\n                self.ses.delete(sym)\r\n                self.ses.commit()\r\n            else:\r\n                msg = 'Symbol {} already exists.\\n' + \\\r\n                      'Consider setting overwrite to True.'\r\n                msg = msg.format(name)\r\n                raise Exception(msg)\r\n\r\n        sym = Symbol(name, description, units, agg_method)\r\n        \r\n        self.ses.add(sym)\r\n\r\n        print \"Creating {}\".format(sym.name)\r\n        sym.add_alias(name)\r\n\r\n        sym.handle = SymbolHandle(sym=sym)\r\n        self.ses.commit()\r\n\r\n        return sym"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, symbol):\r\n        if isinstance(symbol, (str, unicode)):\r\n            sym = self.get(symbol)\r\n        elif isinstance(symbol, Symbol):\r\n            sym = symbol\r\n        else:\r\n            raise Exception(\"Invalid symbol {}\".format((repr(symbol))))\r\n\r\n        # Has to handle the case where the table would exist already\r\n        # and where it wouldn't.\r\n        try:\r\n            sym.datatable = Table(sym.name, Base.metadata, autoload=True)\r\n            sym.datatable.drop(self.eng, checkfirst=True)\r\n        except NoSuchTableError:\r\n            print \"No worries, {} never existed to begin with.\".format(sym.name)\r\n\r\n        self.ses.delete(sym)\r\n        self.ses.commit()", "response": "Deletes a symbol from the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exists(self, symbol):\r\n\r\n        if isinstance(symbol, str):\r\n            sym = symbol\r\n        elif isinstance(symbol, Symbol):\r\n            sym = symbol.name\r\n\r\n        syms = self.ses.query(Symbol).filter(Symbol.name == sym).all()\r\n        if len(syms) == 0:\r\n            return False\r\n        else:\r\n            return True", "response": "Checks to if a symbol exists by name. Returns True if the symbol exists False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, symbol):\r\n        syms = self.try_to_get(symbol)\r\n        if syms is None:\r\n            raise Exception(\"Symbol {} does not exist\".format(symbol))\r\n        else:\r\n            return syms", "response": "Gets a Symbol based on name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to get a specific symbol from the database.", "response": "def try_to_get(self, symbol):\r\n        \"\"\" Gets a Symbol based on name, which may or may not exist.\r\n        \r\n        Parameters\r\n        ----------\r\n        symbol : str\r\n        \r\n        Returns\r\n        -------\r\n        Symbol or None.  \r\n        \r\n        Note\r\n        ----\r\n        Use .get(), if the symbol should exist, and an exception \r\n        is needed if it doesn't.\r\n\r\n        \"\"\"\r\n        syms = self.ses.query(Symbol).filter(Symbol.name == symbol).all()\r\n        if len(syms) == 0:\r\n            return None\r\n        else:\r\n            return syms[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_meta(self, attr, value=None, stronly=False):\r\n        if stronly:\r\n            qry = self.ses.query(Symbol.name).join(SymbolMeta)\r\n        else:\r\n            qry = self.ses.query(Symbol).join(SymbolMeta)\r\n            \r\n        crits = []\r\n        \r\n        if value is None:\r\n            crits.append(SymbolMeta.attr == attr) \r\n        else:\r\n            if isinstance(value, str):\r\n                values = [value]\r\n            elif isinstance(value, (tuple, list)):\r\n                values = value\r\n            \r\n            for v in values:\r\n                crits.append(and_(SymbolMeta.attr == attr, SymbolMeta.value.like(value))) \r\n\r\n        if len(crits):\r\n            qry = qry.filter(or_(*crits))\r\n        \r\n        qry = qry.order_by(Symbol.name)\r\n\r\n        if stronly:\r\n            return [sym[0] for sym in qry.distinct()]\r\n        else:\r\n            return [sym for sym in qry.distinct()]", "response": "Search for all the symbols in the database by a specific meta attribute and optionally a value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, usrqry=None, name=False, desc=False, tags=False, meta=False, stronly=False, dolikelogic=True):\r\n        if stronly:\r\n            qry = self.ses.query(Symbol.name)\r\n        else:\r\n            qry = self.ses.query(Symbol)\r\n\r\n        if tags:\r\n            qry = qry.join(SymbolTag)\r\n        if meta:\r\n            qry = qry.join(SymbolMeta)\r\n        \r\n        if dolikelogic:\r\n            if usrqry is not None:\r\n                if '%' not in usrqry:\r\n                    usrqry = '%' + usrqry + '%'\r\n        \r\n        crits = []\r\n        if name:\r\n            crits.append(Symbol.name.like(usrqry))\r\n        if tags:\r\n            crits.append(SymbolTag.tag.like(usrqry))\r\n        if desc:\r\n            crits.append(Symbol.description.like(usrqry))\r\n        if meta:\r\n            crits.append(SymbolMeta.value.like(usrqry)) \r\n        \r\n        if len(crits):\r\n            qry = qry.filter(or_(*crits))\r\n        \r\n        qry = qry.order_by(Symbol.name)\r\n\r\n        if stronly:\r\n            return [sym[0] for sym in qry.distinct()]\r\n        else:\r\n            return [sym for sym in qry.distinct()]", "response": "Returns a list of all the available Symbols within a user - supplied string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_tag(self, tag, symbols=True, feeds=False):\r\n\r\n        syms = []\r\n        \r\n        if isinstance(tag, (str, unicode)):\r\n            tags = [tag]\r\n        else:\r\n            tags = tag\r\n\r\n        if symbols:\r\n            crits = []\r\n            for tag in tags:\r\n                if \"%\" in tag:\r\n                    crit = SymbolTag.tag.like(tag)\r\n                else:\r\n                    crit = SymbolTag.tag == tag\r\n                crits.append(crit)\r\n\r\n            qry = self.ses.query(SymbolTag)\r\n            qry = qry.filter(or_(*crits))\r\n            syms = qry.all()\r\n            \r\n            syms = [tagged.symbol for tagged in syms]\r\n        if feeds:\r\n            crits = []\r\n            for tag in tags:\r\n                if \"%\" in tag:\r\n                    crit = FeedTag.tag.like(tag)\r\n                else:\r\n                    crit = FeedTag.tag == tag\r\n                crits.append(crit)\r\n                    \r\n            qry = self.ses.query(Symbol).select_from(FeedTag)\r\n            qry = qry.join(FeedTag.feed).join(Feed.symbol)\r\n            qry = qry.filter(or_(*crits))\r\n            fds = qry.distinct()\r\n            \r\n            syms = syms + [sym for sym in fds]\r\n            return list(set(syms))\r\n        return syms", "response": "Returns a list of Symbols by searching a tag or partial tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches list of Symbol objects by querying specific metas and their respective values.", "response": "def search_meta_specific(self, **avargs):\r\n        \"\"\"Search list of Symbol objects by by querying specific \r\n        meta attributes and their respective values.\r\n        \r\n        Parameters\r\n        ----------\r\n        avargs\r\n            The attributes and values passed as key word arguments.\r\n            If more than one criteria is specified, AND logic is applied.\r\n            Appending '%' to values will use SQL's \"LIKE\" functionality.\r\n        \r\n        Example\r\n        -------\r\n        >>> sm.search_meta(geography='Canada', sector='Gov%')\r\n            \r\n        Returns\r\n        -------\r\n        List of Symbols or empty list\r\n        \"\"\"\r\n        \r\n        qry = self.ses.query(Symbol).join(SymbolMeta.symbol)\r\n\r\n\r\n        for attr, value in avargs.iteritems():\r\n            SMA = aliased(SymbolMeta)\r\n            if \"%\" in value:\r\n                acrit = SMA.value.like(value)\r\n            else:\r\n                acrit = SMA.value == value\r\n            \r\n            crit = and_(acrit, SMA.attr == attr)\r\n\r\n            qry = qry.filter(crit).join(SMA, SMA.symname == SymbolMeta.symname)\r\n\r\n        qry = qry.order_by(Symbol.name)\r\n        return qry.all()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of tags and the number of each Symbol.", "response": "def tag_counts(self):\r\n        \"\"\" Get a list of tags and the number of each.\r\n\r\n        Returns\r\n        -------\r\n        List of tuples, in order (tag, # of Symbols w/Tag)\r\n        \r\n        \"\"\"                    \r\n        qry = self.ses.query(SymbolTag.tag, func.count(SymbolTag.tag))\r\n        qry = qry.group_by(SymbolTag.tag)\r\n        qry = qry.order_by(SymbolTag.tag)\r\n        tags = list(qry.all())\r\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bulk_cache_of_tag(self, tag):\r\n\r\n        syms = self.search_tag(tag)\r\n        \r\n        name = 'Bulk Cache of Symbols tagged {}'.format(tag)\r\n        tr = TrumpReport(name)\r\n        for sym in syms:\r\n            sr = sym.cache()\r\n            tr.add_symbolreport(sr)\r\n        \r\n        return tr", "response": "Caches all the symbols tagged by a certain tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a view of the group of Symbols based on their tag.", "response": "def build_view_from_tag(self, tag):\r\n        \"\"\"\r\n        Build a view of group of Symbols based on their tag.\r\n        \r\n        Parameters\r\n        ----------\r\n        tag : str\r\n            Use '%' to enable SQL's \"LIKE\" functionality.\r\n        \r\n        Note\r\n        ----\r\n        \r\n        This function is written without SQLAlchemy,\r\n        so it only tested on Postgres.\r\n\r\n        \"\"\"\r\n        \r\n        syms = self.search_tag(tag)\r\n        \r\n        names = [sym.name for sym in syms]\r\n        \r\n        subs = [\"SELECT indx, '{}' AS symbol, final FROM {}\".format(s, s) for s in names]\r\n        \r\n        qry = \" UNION ALL \".join(subs)\r\n        \r\n        qry = \"CREATE VIEW {} AS {};\".format(tag, qry)\r\n\r\n        self.ses.execute(\"DROP VIEW IF EXISTS {};\".format(tag))\r\n        self.ses.commit()        \r\n        self.ses.execute(qry)\r\n        self.ses.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a single indexed - value pair to a symbol object.", "response": "def _add_orfs(self, which, symbol, ind, val, dt_log=None, user=None, comment=None):\r\n        \"\"\"\r\n        Appends a single indexed-value pair, to a symbol object, to be\r\n        used during the final steps of the aggregation of the datatable.\r\n\r\n        See add_override and add_fail_safe.\r\n        \r\n        Parameters\r\n        ----------\r\n        which : str\r\n            Fail Safe or Override?\r\n        symbol : Symbol or str\r\n            The Symbol to apply the fail safe\r\n        ind : obj\r\n            The index value where the fail safe should be applied\r\n        val : obj\r\n            The data value which will be used in the fail safe\r\n        dt_log : datetime\r\n            A log entry, for saving when this fail safe was created.\r\n        user : str\r\n            A string representing which user made the fail safe\r\n        comment : str\r\n            A string to store any notes related to this fail safe.\r\n        \"\"\"\r\n        if not isinstance(symbol, (str, unicode)):\r\n            symbol = symbol.name\r\n\r\n        if not dt_log:\r\n            dt_log = dt.datetime.now()\r\n\r\n        if which.lower() == 'override':\r\n            qry = self.ses.query(func.max(Override.ornum).label('max_ornum'))\r\n            override = True\r\n        elif which.lower() == 'failsafe':\r\n            qry = self.ses.query(func.max(FailSafe.fsnum).label('max_fsnum'))\r\n            override = False\r\n            \r\n        qry = qry.filter_by(symname = symbol)\r\n        \r\n        cur_num = qry.one()\r\n        \r\n        if cur_num[0] is None:\r\n            next_num = 0\r\n        else:\r\n            next_num = cur_num[0] + 1            \r\n\r\n        if override:\r\n            tmp = Override(symname=symbol,\r\n                           ind=ind,\r\n                           val=val,\r\n                           dt_log=dt_log,\r\n                           user=user,\r\n                           comment=comment,\r\n                           ornum=next_num)\r\n        else:\r\n            tmp = FailSafe(symname=symbol,\r\n                           ind=ind,\r\n                           val=val,\r\n                           dt_log=dt_log,\r\n                           user=user,\r\n                           comment=comment,\r\n                           fsnum=next_num)\r\n                                             \r\n        self.ses.add(tmp)\r\n        self.ses.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an override to the table", "response": "def add_override(self, symbol, ind, val, dt_log=None, user=None, comment=None):\r\n        \"\"\"\r\n        Appends a single indexed-value pair, to a symbol object, to be\r\n        used during the final steps of the aggregation of the datatable.\r\n\r\n        With default settings Overrides, get applied with highest priority.\r\n        \r\n        Parameters\r\n        ----------\r\n        symbol : Symbol or str\r\n            The Symbol to override\r\n        ind : obj\r\n            The index value where the override should be applied\r\n        val : obj\r\n            The data value which will be used in the override\r\n        dt_log : datetime\r\n            A log entry, for saving when this override was created.\r\n        user : str\r\n            A string representing which user made the override\r\n        comment : str\r\n            A string to store any notes related to this override.\r\n        \"\"\"\r\n        self._add_orfs('override', symbol, ind, val, dt_log, user, comment)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Dataframe with the data converted to the new units", "response": "def get_converted(self, symbol, units='CAD', system=None, tag=None):\r\n        \"\"\"\r\n        Uses a Symbol's Dataframe, to build a new Dataframe,\r\n        with the data converted to the new units\r\n        \r\n        Parameters\r\n        ----------\r\n        symbol : str or tuple of the form (Dataframe, str)\r\n            String representing a symbol's name, or a dataframe\r\n            with the data required to be converted.  If supplying a \r\n            dataframe, units must be passed.\r\n        units : str, optional\r\n            Specify the units to convert the symbol to, default to CAD \r\n        system : str, optional\r\n            If None, the default system specified at instantiation\r\n            is used.  System defines which conversion approach to take.\r\n        tag : str, optional\r\n            Tags define which set of conversion data is used.  If None, the\r\n            default tag specified at instantiation is used.  \r\n        \"\"\"\r\n        if isinstance(symbol, (str, unicode)):\r\n            sym = self.get(symbol)\r\n            df = sym.df\r\n            curu = sym.units\r\n            requ = units\r\n        elif isinstance(symbol, tuple):\r\n            df = symbol[0]\r\n            curu = symbol[1]\r\n            requ = units\r\n        else:\r\n            raise TypeError(\"Expected str or (DataFrame, str), found {}\".format(type(symbol)))\r\n        \r\n        system = system or self.default_system\r\n        tag = tag or self.default_tag\r\n        \r\n        conv = self.converters[system][tag]\r\n\r\n        newdf = conv.convert(df, curu, requ)\r\n        newdf = pd.merge(df, newdf, left_index=True, right_index=True)\r\n        newdf = newdf[df.columns[0] + \"_y\"].to_frame()\r\n        newdf.columns = df.columns\r\n        return newdf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef last_cache(self,result='COMPLETE'):\r\n        crit = and_(SymbolLogEvent.event == 'CACHE',\r\n                    SymbolLogEvent.evresult == result)\r\n        qry = self.log.filter(crit)\r\n        qry = qry.order_by(SymbolLogEvent.evtime.desc())\r\n        \r\n        t = qry.first()\r\n        \r\n        if t:\r\n            return t.evtime\r\n        else:\r\n            return None", "response": "Returns the date and time of the last cache in the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a symbol s indexing strategy", "response": "def set_indexing(self, index_template):\r\n        \"\"\"\r\n        Update a symbol's indexing strategy\r\n        \r\n        Parameters\r\n        ----------\r\n        index_template : bIndex or bIndex-like\r\n            An index template used to overwrite all \r\n            details about the symbol's current index.\r\n\r\n        \"\"\"\r\n        objs = object_session(self)\r\n        \r\n        if self.index.indimp != index_template.imp_name:\r\n            self._refresh_datatable_schema()\r\n        \r\n        self.index.name = index_template.name\r\n        self.index.indimp = index_template.imp_name\r\n        self.index.case = index_template.case\r\n        self.index.setkwargs(**index_template.kwargs)\r\n        objs.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding meta information to a Symbol.", "response": "def add_meta(self, **metadict):\r\n        \"\"\"Add meta information to a Symbol.\r\n                \r\n        Parameters\r\n        ----------\r\n        metadict \r\n            Attributes are passed as keywords, with their\r\n            associated values as strings.  For meta attributes with spaces,\r\n            use an unpacked dict.\r\n                    \r\n        \"\"\"\r\n        \r\n        objs = object_session(self)\r\n        \r\n        for attr,val in metadict.iteritems():\r\n            newmeta = SymbolMeta(self, attr, val)\r\n            self.meta.append(newmeta)\r\n            \r\n        objs.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_validator(self, val_template):\r\n        validator = val_template.validator\r\n        \r\n        args = []\r\n        for arg in SymbolValidity.argnames:\r\n            if arg in val_template.__dict__.keys():\r\n                args.append(getattr(val_template, arg))\r\n\r\n        objs = object_session(self)\r\n        qry = objs.query(func.max(SymbolValidity.vid).label('max_vid'))\r\n        qry = qry.filter_by(symname = self.name)\r\n        \r\n        cur_vid = qry.one()[0]\r\n        \r\n        if cur_vid is None:\r\n            next_vid = 0\r\n        else:\r\n            next_vid = cur_vid + 1   \r\n            \r\n       \r\n        self.validity.append(SymbolValidity(self, next_vid, validator, *args))\r\n        objs.commit()", "response": "Adds a new validator object to the Symbol."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cache(self, checkvalidity=True, staleonly=False, allowraise=True):\r\n        note = \"staleonly = {}\".format(staleonly)\r\n        self._log_an_event('CACHE','START',note)\r\n\r\n        docache = True\r\n        if staleonly:\r\n            lc = self.last_cache()\r\n            if lc:\r\n                freshthresh = self.freshthresh \r\n                \r\n                nw = dt.datetime.now()\r\n                freshness = (nw - lc).total_seconds() / 60.0\r\n\r\n                if freshness <= freshthresh:\r\n                    docache = False\r\n        \r\n        smrp = SymbolReport(self.name)\r\n        if docache:\r\n            data = []\r\n            cols = ['final', 'override_feed000', 'failsafe_feed999']\r\n    \r\n            if len(self.feeds) == 0:\r\n                err_msg = \"Symbol has no Feeds. Can't cache a feed-less Symbol.\"\r\n                raise Exception(err_msg)\r\n    \r\n            try:\r\n                datt = datadefs[self.dtype.datadef]\r\n\r\n                indtt = indexingtypes[self.index.indimp]\r\n                indkwargs = self.index.getkwargs()\r\n                indt = indtt(self.index.case, **indkwargs)\r\n                \r\n                rp = ReportPoint('datadef', 'class', datt)\r\n                smrp.add_reportpoint(rp)\r\n                \r\n                for afeed in self.feeds:\r\n                    fdrp = afeed.cache(allowraise)\r\n                    smrp.add_feedreport(fdrp)\r\n                    tmp = datt(afeed.data).converted\r\n                    tmp = indt.process_post_feed_cache(tmp)\r\n                    data.append(tmp)\r\n                    cols.append(afeed.data.name)\r\n            except:\r\n                point = \"caching\"\r\n                smrp = self._generic_exception(point, smrp, allowraise)\r\n                    \r\n            try:\r\n                data = pd.concat(data, axis=1)\r\n            except:\r\n                point = \"concatenation\"\r\n                smrp = self._generic_exception(point, smrp, allowraise)\r\n            \r\n            # We shouldn't need to do anything here, as the concatenation\r\n            # should be smooth...\r\n            \r\n#            preindlen = len(data)\r\n#\r\n#                     \r\n#            if preindlen > 0 : \r\n#                #indt = indtt(data, self.index.case, indkwargs)\r\n#                #data = indt.final_dataframe()\r\n#                data = indt.process_post_concat(data)\r\n#\r\n#                postindlen = len(data)   \r\n#                if postindlen == 0 and preindlen > 0:\r\n#                    raise Exception(\"Indexing Implementer likely poorly designed\")\r\n#            else:\r\n#                postindlen = 0\r\n            \r\n            \r\n            def build_hi_df(which, colname):\r\n                \r\n                objs = object_session(self)\r\n    \r\n                qry = objs.query(which.ind,\r\n                                 func.max(which.dt_log).label('max_dt_log'))\r\n                \r\n                qry = qry.filter_by(symname = self.name)\r\n                \r\n                grb = qry.group_by(which.ind).subquery()\r\n        \r\n                qry = objs.query(which)\r\n                ords = qry.join((grb, and_(which.ind == grb.c.ind,\r\n                                           which.dt_log == grb.c.max_dt_log))).all()\r\n            \r\n                if len(ords):\r\n                    orind = [row.ind for row in ords]\r\n                    orval = [row.val for row in ords]\r\n                    ordf = indt.build_ordf(orind, orval, colname)\r\n                else:\r\n                    ordf = pd.DataFrame(columns=[colname])\r\n                return ordf\r\n            \r\n            ordf = build_hi_df(Override, 'override_feed000')\r\n            fsdf = build_hi_df(FailSafe, 'failsafe_feed999')\r\n            \r\n            orfsdf = pd.merge(ordf, fsdf, how='outer', left_index=True, right_index=True)\r\n            data = pd.merge(orfsdf, data, how='outer', left_index=True, right_index=True)\r\n            \r\n            data = indt.process_post_orfs(data)\r\n\r\n            try:\r\n                data = data.fillna(value=pd.np.nan)\r\n                data = data[sorted_feed_cols(data)]\r\n                data['final'] = FeedAggregator(self.agg_method).aggregate(data)\r\n            except:\r\n                point = \"aggregation\"\r\n                smrp = self._generic_exception(point, smrp, allowraise)\r\n    \r\n    \r\n            # SQLAQ There are several states to deal with at this point\r\n            # A) the datatable exists but a feed has been added\r\n            # B) the datatable doesn't exist and needs to be created\r\n            # C) the datatable needs to be updated for more or less feeds\r\n            # D) the datatable_exists flag is incorrect because all edge cases\r\n            #    haven't been handled yet.\r\n            #\r\n            # My logic is that once Trump is more functional, I'll be able to\r\n            # eliminate this hacky solution.  But, SQLAlchemy might have\r\n            # a more elegant answer.  A check, of somekind prior to deletion?\r\n    \r\n            # if not self.datatable_exists:\r\n            #     self._init_datatable() #older version of _init_datatable\r\n            # delete(self.datatable).execute()\r\n            # self._init_datatable() #older version of _init_datatable\r\n    \r\n            # Is this the best way to check?\r\n            # if engine.dialect.has_table(session.connection(), self.name):\r\n            #    delete(self.datatable).execute()\r\n            self._refresh_datatable_schema()\r\n            \r\n            if len(data) > 0:\r\n                data.index.name = 'indx'\r\n                data = data.reset_index()\r\n                datarecords = data.to_dict(orient='records')\r\n                \r\n                objs = object_session(self)\r\n                objs.execute(self.datatable.insert(), datarecords)\r\n                objs.commit()\r\n            \r\n            \r\n            if checkvalidity:\r\n                try:\r\n                    isvalid, reports = self.check_validity(report=True)\r\n                    for rep in reports:\r\n                        smrp.add_reportpoint(rep)\r\n                    if not isvalid:\r\n                        raise Exception('{} is not valid'.format(self.name))\r\n                except:\r\n                    point = \"validity_check\"\r\n                    smrp = self._generic_exception(point, smrp, allowraise)\r\n            self._log_an_event('CACHE','COMPLETE', \"Fresh!\")\r\n        else:\r\n            self._log_an_event('CACHE','FRESH', \"Was still fresh\")\r\n        return smrp", "response": "Re - caches the datatable of the given Symbol."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_validity(self, checks=None, report=True):\r\n        if report:\r\n            reportpoints = []\r\n            \r\n        allchecks = []\r\n        \r\n        checks_specified=False\r\n        \r\n        if isinstance(checks, (str, unicode)):\r\n            checks = [checks]\r\n            checks_specified = True\r\n        elif isinstance(checks, (list, tuple)):\r\n            checks_specified = True\r\n        else:\r\n            checks = []\r\n            \r\n        for val in self.validity:\r\n            \r\n            if (val.validator in checks) or (not checks_specified):\r\n                ValCheck = validitychecks[val.validator]\r\n\r\n                anum = ValCheck.__init__.func_code.co_argcount - 2\r\n                \r\n                args = []\r\n                for arg in SymbolValidity.argnames:\r\n                    args.append(getattr(val, arg))\r\n                \r\n                valid = ValCheck(self.datatable_df, *args[:anum])\r\n                res = valid.result\r\n                allchecks.append(res)\r\n                \r\n                rp = ReportPoint('validation', val.validator, res, str(args[:anum]))\r\n                reportpoints.append(rp)\r\n        \r\n        if report:\r\n            return all(allchecks), reportpoints\r\n        else:\r\n            return all(allchecks)", "response": "Returns a tuple of the result of the check_all methods."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string describing a Symbol", "response": "def describe(self):\r\n        \"\"\" describes a Symbol, returns a string \"\"\"\r\n        lines = []\r\n        lines.append(\"Symbol = {}\".format(self.name))\r\n        if len(self.tags):\r\n            tgs = \", \".join(x.tag for x in self.tags)\r\n            lines.append(\"  tagged = {}\".format(tgs))\r\n        if len(self.aliases):\r\n            als = \", \".join(x.alias for x in self.aliases)\r\n            lines.append(\"  aliased = {}\".format(als))\r\n        if len(self.feeds):\r\n            lines.append(\"  feeds:\")\r\n\r\n            for fed in self.feeds:\r\n                lines.append(\"    {}. {}\".format(fed.fnum,\r\n                                                       fed.ftype))\r\n        return \"\\n\".join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a tag or tags from a symbol.", "response": "def del_tags(self, tags):\r\n        \"\"\" remove a tag or tags from a symbol \r\n        \r\n        Parameters\r\n        ----------\r\n        tags : str or [str,]\r\n            Tags to be removed\r\n        \"\"\"\r\n        # SQLA Adding a SymbolTag object, feels awkward/uneccessary.\r\n        # Should I be implementing this functionality a different way?\r\n\r\n        if isinstance(tags, (str, unicode)):\r\n            tags = [tags]\r\n\r\n        objs = object_session(self)\r\n\r\n        docommit = False\r\n        for symboltag in self.tags:\r\n            if symboltag.tag in tags:\r\n                objs.delete(symboltag)\r\n                docommit = True\r\n\r\n        \r\n        if docommit:\r\n            objs.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a tag or tags to a symbol", "response": "def add_tags(self, tags):\r\n        \"\"\" add a tag or tags to a symbol\r\n        \r\n        Parameters\r\n        ----------\r\n        tags : str or [str,]\r\n            Tags to be added\r\n        \"\"\"\r\n        # SQLA Adding a SymbolTag object, feels awkward/uneccessary.\r\n        # Should I be implementing this functionality a different way?\r\n\r\n        if isinstance(tags, (str, unicode)):\r\n            tags = [tags]\r\n\r\n        objs = object_session(self)\r\n        tmps = [SymbolTag(tag=t, sym=self) for t in tags]\r\n        objs.add_all(tmps)\r\n        objs.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _log_an_event(self, event, evresult='No Result', note='No Note'):\r\n        objs = object_session(self)\r\n        evnt = SymbolLogEvent(event, evresult, note, sym=self.name)\r\n        objs.add(evnt)\r\n        objs.commit()", "response": "log an event\r\n        \r\n        Parameters\r\n        ----------\r\n        event : string\r\n        evresult : string\r\n        note : string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a feed to the Symbols feedlist.", "response": "def add_feed(self, feedlike, **kwargs):\r\n        \"\"\" Add a feed to the Symbol\r\n        \r\n        Parameters\r\n        ----------\r\n        feedlike : Feed or bFeed-like\r\n            The feed template, or Feed object to be added.\r\n        kwargs\r\n            Munging instructions\r\n        \"\"\"\r\n        if 'fnum' in kwargs:\r\n            fnum = kwargs['fnum']\r\n            del kwargs['fnum']\r\n        else:\r\n            fnum = None\r\n\r\n        if isinstance(feedlike, bFeed):\r\n            munging = feedlike.munging\r\n            if 'munging' in kwargs:\r\n                explicit_munging = kwargs['munging'].as_odict\r\n                for key in explicit_munging:\r\n                    munging[key] = explicit_munging[key]\r\n            fed = Feed(self, feedlike.ftype,\r\n                       feedlike.sourcing,\r\n                       munging,\r\n                       feedlike.meta,\r\n                       fnum)\r\n\r\n        elif isinstance(feedlike, Feed):\r\n            fed = feedlike\r\n        else:\r\n            raise Exception(\"Invalid Feed {}\".format(repr(feedlike)))\r\n        self.feeds.append(fed)\r\n        \r\n        objs = object_session(self)\r\n        objs.add(fed)\r\n        objs.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an alias to a session.", "response": "def add_alias(self, alias):\r\n        \"\"\" Add an alias to a Symbol\r\n        \r\n        Parameters\r\n        ----------\r\n        alias : str\r\n            The alias\r\n        \"\"\"\r\n        objs = object_session(self)\r\n        \r\n        if isinstance(alias, list):\r\n            raise NotImplementedError\r\n        elif isinstanceofany(alias, (str, unicode)):\r\n            a = SymbolAlias(self, alias)\r\n            self.aliases.append(a)\r\n            objs.add(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _final_data(self):\r\n        dtbl = self.datatable\r\n\r\n        objs = object_session(self)\r\n        if isinstance(dtbl, Table):\r\n            return objs.query(dtbl.c.indx, dtbl.c.final).all()\r\n        else:\r\n            raise Exception(\"Symbol has no datatable, likely need to cache first.\")", "response": "Returns a list of tuples representing rows from the datatable s index\r\n        and final column sorted accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the max and min of the index.", "response": "def _max_min(self):\r\n        \"\"\"\r\n        Returns\r\n        -------\r\n        A tuple consisting of (max, min) of the index.\r\n        \"\"\"\r\n        dtbl = self.datatable\r\n\r\n        objs = object_session(self)\r\n        if isinstance(dtbl, Table):\r\n            return objs.query(func.max(dtbl.c.indx).label(\"max_indx\"),\r\n                              func.min(dtbl.c.indx).label(\"min_indx\")).one()\r\n        else:\r\n            raise Exception(\"Symbol has no datatable\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of tuples representing rows from all columns of the datatable sorted accordingly.", "response": "def _all_datatable_data(self):\r\n        \"\"\"\r\n        Returns\r\n        -------\r\n        A list of tuples representing rows from all columns of the datatable,\r\n        sorted accordingly.\r\n        \"\"\"\r\n        dtbl = self.datatable\r\n        objs = object_session(self)\r\n        imcols = [dtbl.c.indx, dtbl.c.final, dtbl.c.override_feed000, dtbl.c.failsafe_feed999]\r\n        cols = imcols[:3] + [c for c in dtbl.c if c not in (imcols)] + [imcols[3]]\r\n        if isinstance(dtbl, Table):\r\n            return objs.query(*cols).order_by(dtbl.c.indx).all()\r\n        else:\r\n            raise Exception(\"Symbol has no datatable\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef df(self):\r\n        data = self._final_data()\r\n        \r\n        if len(data) == 0:\r\n            adf = pd.DataFrame(columns = [self.index.name, self.name])\r\n            return adf.set_index(self.index.name)\r\n            \r\n        adf = pd.DataFrame(data)\r\n        \r\n        if len(adf.columns) != 2:\r\n            msg = \"Symbol ({}) needs to be cached prior to building a Dataframe\"\r\n            msg = msg.format(self.name)\r\n            raise Exception(msg)\r\n        adf.columns = [self.index.name, self.name]\r\n        return self._finish_df(adf, 'FINAL')", "response": "Returns a DataFrame containing the symbol s final data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef datatable_df(self):\r\n        data = self._all_datatable_data()\r\n        adf = pd.DataFrame(data)\r\n        adf.columns = self.dt_all_cols\r\n        return self._finish_df(adf, 'ALL')", "response": "returns the dataframe representation of the symbol s final data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the. datatable attribute of the object", "response": "def _init_datatable(self):\r\n        \"\"\"\r\n        Instantiates the .datatable attribute, pointing to a table in the\r\n        database that stores all the cached data\r\n        \"\"\"\r\n        try:\r\n            self.datatable = Table(self.name, Base.metadata, autoload=True)\r\n        except NoSuchTableError:\r\n            print \"Creating datatable, cause it doesn't exist\"\r\n            self.datatable = self._datatable_factory()\r\n            self.datatable.create()\r\n        self.datatable_exists = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new SQLAlchemy Table object with the appropriate number of columns given the number of feeds Principal columns given the number of data sources Principal columns given the number of feeds Principal columns given the number of data sources", "response": "def _datatable_factory(self):\r\n        \"\"\"\r\n        creates a SQLAlchemy Table object with the appropriate number of\r\n        columns given the number of feeds\r\n        \"\"\"\r\n        feed_cols = ['feed{0:03d}'.format(i + 1) for i in range(self.n_feeds)]\r\n        feed_cols = ['override_feed000'] + feed_cols + ['failsafe_feed999']\r\n\r\n        ind_sqlatyp = indexingtypes[self.index.indimp].sqlatyp\r\n        dat_sqlatyp = datadefs[self.dtype.datadef].sqlatyp\r\n\r\n        atbl = Table(self.name, Base.metadata,\r\n                     Column('indx', ind_sqlatyp, primary_key=True),\r\n                     Column('final', dat_sqlatyp),\r\n                     *(Column(fed_col, dat_sqlatyp) for fed_col in feed_cols),\r\n                     extend_existing=True)\r\n        \r\n        self.dt_feed_cols = feed_cols[:]\r\n        self.dt_all_cols = ['indx', 'final'] + feed_cols[:]\r\n        return atbl"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_handle(self, chkpnt_settings):\r\n\r\n        # Note, for now, this function is nearly identical\r\n        # to the Symbol version.  Careful when augmenting,\r\n        # to get the right one.\r\n\r\n        objs = object_session(self)\r\n\r\n        # override with anything passed in\r\n        for checkpoint in chkpnt_settings:\r\n            if checkpoint in FeedHandle.__table__.columns:\r\n                settings = chkpnt_settings[checkpoint]\r\n                setattr(self.handle, checkpoint, settings)\r\n        objs.commit()", "response": "Update a feeds s handle checkpoint settings with the contents of chkpnt_settings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_tags(self, tags):\r\n\r\n        if isinstance(tags, (str, unicode)):\r\n            tags = [tags]\r\n\r\n        objs = object_session(self)\r\n        tmps = [FeedTag(tag=t, feed=self) for t in tags]\r\n        objs.add_all(tmps)\r\n        objs.commit()", "response": "add a tag or list of tags to a Feed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initiate_browser(self):\n\n        # Create a unique tempdir for downloaded files\n        tempdir = os.getenv(TEMPDIR_ENVVAR, DEFAULT_TEMPDIR)\n        tempsubdir = uuid4().hex\n        # TODO: Remove this directory when finished!\n        self.tempdir = os.path.join(tempdir, tempsubdir)\n        try:\n            # Try and create directory before checking if it exists,\n            # to avoid race condition\n            os.makedirs(self.tempdir)\n        except OSError:\n            if not os.path.isdir(self.tempdir):\n                raise\n\n        profile = webdriver.FirefoxProfile()\n        # Set download location, avoid download dialogues if possible\n        # Different settings needed for different Firefox versions\n        # This will be a long list...\n        profile.set_preference('browser.download.folderList', 2)\n        profile.set_preference('browser.download.manager.showWhenStarting', False)\n        profile.set_preference('browser.download.manager.closeWhenDone', True)\n        profile.set_preference('browser.download.dir', self.tempdir)\n        profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/octet-stream;application/vnd.ms-excel\")\n        profile.set_preference(\"browser.helperApps.alwaysAsk.force\", False)\n        profile.set_preference(\"browser.download.manager.useWindow\", False)\n\n        self.browser = webdriver.Firefox(profile)\n\n        self.browser.get('http://webbstat.av.se')\n        detailed_cls = \"Document_TX_GOTOTAB_Avancerad\"\n        \"\"\" The button for expanded detailed options. This\n        also happens to be a good indicator as to wheter\n        all content is loaded.\n        \"\"\"\n\n        # Wait for a content element, and 3 extra seconds just in case\n        WebDriverWait(self.browser, PAGELOAD_TIMEOUT)\\\n            .until(EC.presence_of_element_located((By.CLASS_NAME,\n                                                  detailed_cls)))\n        self.browser.implicitly_wait(3)\n\n        self.browser\\\n            .find_element_by_class_name(detailed_cls)\\\n            .find_element_by_tag_name(\"td\")\\\n            .click()\n        # Wait for a content element, and 3 extra seconds just in case\n        WebDriverWait(self.browser, PAGELOAD_TIMEOUT)\\\n            .until(EC.presence_of_element_located((By.CLASS_NAME,\n                                                   detailed_cls)))\n        self.browser.implicitly_wait(3)", "response": "Initiate browser and return the unique ID of the current page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding the available dimensions for the given dataset.", "response": "def _fetch_dimensions(self, dataset):\n        \"\"\" Declaring available dimensions like this is not mandatory,\n         but nice, especially if they differ from dataset to dataset.\n\n         If you are using a built in datatype, you can specify the dialect\n         you are expecting, to have values normalized. This scraper will\n         look for Swedish month names (e.g. 'Januari'), but return them\n         according to the Statscraper standard ('january').\n        \"\"\"\n        yield Dimension(u\"region\",\n                        label=\"municipality or county\",\n                        datatype=\"region\",\n                        dialect=\"arbetsmiljoverket\")\n        yield Dimension(u\"period\",\n                        label=\"Year or month\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields a list of items from the item.", "response": "def _fetch_itemslist(self, item):\n        \"\"\" We define two collection:\n        - Number of work injuries (\"Arbetsolycka\")\n        - Number of workrelated diseases (\"Arbetssjukdom\")\n        Each contains four datasets:\n        - Per municipality and year\n        - Per county and year\n        - Per municipality and month\n        - Per municipality and year\n        \"\"\"\n        if item.is_root:\n            for c in [\"Arbetsolycka\", \"Arbetssjukdom\"]:\n                yield Collection(c, blob=(c, None, None))\n        else:\n            c = item.id\n            for r in [u\"kommun\", u\"l\u00e4n\"]:\n                for p in [u\"\u00e5r\", u\"m\u00e5nad\"]:\n                    yield Dataset(u\"%s-%s-%s\" % (c, r, p),\n                                  blob=(c, r, p),\n                                  label=u\"%s, antal per %s och %s\" % (c, r, p))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_log_record_output(category, level, message,\n                           format=None, datefmt=None, **kwargs):\n    \"\"\"\n    Create the output for a log record, like performed by :mod:`logging` module.\n\n    :param category:    Name of the logger (as string or None).\n    :param level:       Log level (as number).\n    :param message:     Log message to use.\n    :returns: Log record output (as string)\n    \"\"\"\n    if not category or (category == \"__ROOT__\"):\n        category = \"root\"\n    levelname = logging.getLevelName(level)\n    record_data = dict(name=category, levelname=levelname, msg=message)\n    record_data.update(kwargs)\n    record = logging.makeLogRecord(record_data)\n    formatter = logging.Formatter(format, datefmt=datefmt)\n    return formatter.format(record)", "response": "Create the output for a log record."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef step_I_create_logrecords_with_table(context):\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_columns([\"category\", \"level\", \"message\"])\n    for row in context.table.rows:\n        category = row[\"category\"]\n        if category == \"__ROOT__\":\n            category = None\n        level = LogLevel.parse_type(row[\"level\"])\n        message = row[\"message\"]\n        make_log_record(category, level, message)", "response": "This function creates one more log records by using a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a log record by using a table.", "response": "def step_I_create_logrecord_with_table(context):\n    \"\"\"\n    Create an log record by using a table to provide the parts.\n\n    .. seealso: :func:`step_I_create_logrecords_with_table()`\n    \"\"\"\n    assert context.table, \"REQUIRE: context.table\"\n    assert len(context.table.rows) == 1, \"REQUIRE: table.row.size == 1\"\n    step_I_create_logrecords_with_table(context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef step_command_output_should_contain_log_records(context):\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_columns([\"category\", \"level\", \"message\"])\n    format = getattr(context, \"log_record_format\", context.config.logging_format)\n    for row in context.table.rows:\n        output = LogRecordTable.make_output_for_row(row, format)\n        context.execute_steps(u'''\n            Then the command output should contain:\n                \"\"\"\n                {expected_output}\n                \"\"\"\n            '''.format(expected_output=output))", "response": "This function checks that the command output contains the specified log records."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef step_command_output_should_not_contain_log_records(context):\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_columns([\"category\", \"level\", \"message\"])\n    format = getattr(context, \"log_record_format\", context.config.logging_format)\n    for row in context.table.rows:\n        output = LogRecordTable.make_output_for_row(row, format)\n        context.execute_steps(u'''\n            Then the command output should not contain:\n                \"\"\"\n                {expected_output}\n                \"\"\"\n            '''.format(expected_output=output))", "response": "This function checks that the command output does not contain the specified log records."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that the command output contains the specified log records (in any order). .. code-block: gherkin Given I define a log record schema: | category | level | message | | root | ERROR | __LOG_MESSAGE__ | Then the command output should contain log records from categories: | category | | bar |", "response": "def step_command_output_should_contain_log_records_from_categories(context):\n    \"\"\"\n    Verifies that the command output contains the specified log records\n    (in any order).\n\n    .. code-block: gherkin\n\n        Given I define a log record schema:\n            | category | level | message |\n            | root     | ERROR | __LOG_MESSAGE__ |\n        Then the command output should contain log records from categories:\n            | category |\n            | bar      |\n    \"\"\"\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_column(\"category\")\n    record_schema = context.log_record_row_schema\n    LogRecordTable.annotate_with_row_schema(context.table, record_schema)\n    step_command_output_should_contain_log_records(context)\n    context.table.remove_columns([\"level\", \"message\"])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify that the command output contains not log records from the provided log categories (in any order). .. code-block: gherkin Given I define the log record schema: | category | level | message | | root | ERROR | __LOG_MESSAGE__ | Then the command output should not contain log records from categories: | category | | bar |", "response": "def step_command_output_should_not_contain_log_records_from_categories(context):\n    \"\"\"\n    Verifies that the command output contains not log records from\n    the provided log categories (in any order).\n\n    .. code-block: gherkin\n\n        Given I define the log record schema:\n            | category | level | message |\n            | root     | ERROR | __LOG_MESSAGE__ |\n        Then the command output should not contain log records from categories:\n            | category |\n            | bar      |\n    \"\"\"\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_column(\"category\")\n    record_schema = context.log_record_row_schema\n    LogRecordTable.annotate_with_row_schema(context.table, record_schema)\n    step_command_output_should_not_contain_log_records(context)\n    context.table.remove_columns([\"level\", \"message\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef step_file_should_contain_log_records(context, filename):\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_columns([\"category\", \"level\", \"message\"])\n    format = getattr(context, \"log_record_format\", context.config.logging_format)\n    for row in context.table.rows:\n        output = LogRecordTable.make_output_for_row(row, format)\n        context.text = output\n        step_file_should_contain_multiline_text(context, filename)", "response": "This step checks that the file xxx. log contains the specified log records."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying that the command output contains the specified log records (in any order). .. code-block: gherkin Then the file \"xxx.log\" should not contain the log records: | category | level | message | | bar | CURRENT | xxx |", "response": "def step_file_should_not_contain_log_records(context, filename):\n    \"\"\"\n    Verifies that the command output contains the specified log records\n    (in any order).\n\n    .. code-block: gherkin\n\n        Then the file \"xxx.log\" should not contain the log records:\n            | category | level   | message |\n            | bar      | CURRENT | xxx     |\n    \"\"\"\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_columns([\"category\", \"level\", \"message\"])\n    format = getattr(context, \"log_record_format\", context.config.logging_format)\n    for row in context.table.rows:\n        output = LogRecordTable.make_output_for_row(row, format)\n        context.text = output\n        step_file_should_not_contain_multiline_text(context, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefining log record configuration parameters.", "response": "def step_use_log_record_configuration(context):\n    \"\"\"\n    Define log record configuration parameters.\n\n    .. code-block: gherkin\n\n        Given I use the log record configuration:\n            | property | value |\n            | format   |       |\n            | datefmt  |       |\n    \"\"\"\n    assert context.table, \"REQUIRE: context.table\"\n    context.table.require_columns([\"property\", \"value\"])\n    for row in context.table.rows:\n        property_name = row[\"property\"]\n        value = row[\"value\"]\n        if property_name == \"format\":\n            context.log_record_format = value\n        elif property_name == \"datefmt\":\n            context.log_record_datefmt = value\n        else:\n            raise KeyError(\"Unknown property=%s\" % property_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef annotate_with_row_schema(table, row_schema):\n        for column, value in row_schema.items():\n            if column not in table.headings:\n                table.add_column(column, default_value=value)", "response": "Annotate a table of log - records with additional columns from\n        the log - record schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode binary to string.", "response": "def decode(self, binary, url, encoding=None, errors=\"strict\"):\n        \"\"\"\n        Decode binary to string.\n\n        :param binary: binary content of a http request.\n        :param url: endpoint of the request.\n        :param encoding: manually specify the encoding.\n        :param errors: errors handle method.\n\n        :return: str\n        \"\"\"\n        if encoding is None:\n            domain = util.get_domain(url)\n            if domain in self.domain_encoding_table:\n                encoding = self.domain_encoding_table[domain]\n                html = binary.decode(encoding, errors=errors)\n            else:\n                html, encoding, confidence = smart_decode(\n                    binary, errors=errors)\n                # cache domain name and encoding\n                self.domain_encoding_table[domain] = encoding\n        else:\n            html = binary.decode(encoding, errors=errors)\n\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmodifying a number pattern by specified keyword arguments.", "response": "def modify_number_pattern(number_pattern, **kwargs):\n    \"\"\"Modifies a number pattern by specified keyword arguments.\"\"\"\n    params = ['pattern', 'prefix', 'suffix', 'grouping',\n              'int_prec', 'frac_prec', 'exp_prec', 'exp_plus']\n    for param in params:\n        if param in kwargs:\n            continue\n        kwargs[param] = getattr(number_pattern, param)\n    return NumberPattern(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_currency_field(__, prec, number, locale):\n    locale = Locale.parse(locale)\n    currency = get_territory_currencies(locale.territory)[0]\n    if prec is None:\n        pattern, currency_digits = None, True\n    else:\n        prec = int(prec)\n        pattern = locale.currency_formats['standard']\n        pattern = modify_number_pattern(pattern, frac_prec=(prec, prec))\n        currency_digits = False\n    return format_currency(number, currency, pattern, locale=locale,\n                           currency_digits=currency_digits)", "response": "Formats a currency field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting a decimal field.", "response": "def format_decimal_field(__, prec, number, locale):\n    \"\"\"Formats a decimal field:\n\n    .. sourcecode::\n\n       1234 ('D') -> 1234\n       -1234 ('D6') -> -001234\n\n    \"\"\"\n    prec = 0 if prec is None else int(prec)\n    if number < 0:\n        prec += 1\n    return format(number, u'0%dd' % prec)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting a fixed - point field.", "response": "def format_float_field(__, prec, number, locale):\n    \"\"\"Formats a fixed-point field.\"\"\"\n    format_ = u'0.'\n    if prec is None:\n        format_ += u'#' * NUMBER_DECIMAL_DIGITS\n    else:\n        format_ += u'0' * int(prec)\n    pattern = parse_pattern(format_)\n    return pattern.apply(number, locale)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_number_field(__, prec, number, locale):\n    prec = NUMBER_DECIMAL_DIGITS if prec is None else int(prec)\n    locale = Locale.parse(locale)\n    pattern = locale.decimal_formats.get(None)\n    return pattern.apply(number, locale, force_frac=(prec, prec))", "response": "Formats a number field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat a percent field.", "response": "def format_percent_field(__, prec, number, locale):\n    \"\"\"Formats a percent field.\"\"\"\n    prec = PERCENT_DECIMAL_DIGITS if prec is None else int(prec)\n    locale = Locale.parse(locale)\n    pattern = locale.percent_formats.get(None)\n    return pattern.apply(number, locale, force_frac=(prec, prec))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_hexadecimal_field(spec, prec, number, locale):\n    if number < 0:\n        # Take two's complement.\n        number &= (1 << (8 * int(math.log(-number, 1 << 8) + 1))) - 1\n    format_ = u'0%d%s' % (int(prec or 0), spec)\n    return format(number, format_)", "response": "Formats a hexadeciaml field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the value according to the format specifiers.", "response": "def format_field(self, value, format_spec):\n        \"\"\"Format specifiers are described in :func:`format_field` which is a\n        static function.\n        \"\"\"\n        if format_spec:\n            spec, arg = format_spec[0], format_spec[1:]\n            arg = arg or None\n        else:\n            spec = arg = None\n        return self._format_field(spec, arg, value, self.numeric_locale)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delegate(attribute_name, method_names):\n    call_attribute_method = partial(_call_delegated_method, attribute_name)\n\n    def decorate(class_):\n        for method in method_names:\n            setattr(class_, method, partialmethod(call_attribute_method, method))\n\n        return class_\n    return decorate", "response": "Decorator factory to delegate methods to an attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing a query object for the RAPI.", "response": "def prepare_query(query):\n    \"\"\"\n    Prepare a query object for the RAPI.\n\n    RAPI has lots of curious rules for coercing values.\n\n    This function operates on dicts in-place and has no return value.\n\n    @type query: dict\n    @param query: Query arguments\n    \"\"\"\n\n    for name in query:\n        value = query[name]\n\n        # None is sent as an empty string.\n        if value is None:\n            query[name] = \"\"\n\n        # Booleans are sent as 0 or 1.\n        elif isinstance(value, bool):\n            query[name] = int(value)\n\n        # XXX shouldn't this just check for basestring instead?\n        elif isinstance(value, dict):\n            raise ValueError(\"Invalid query data type %r\" %\n                             type(value).__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a handful of items from an iterable.", "response": "def itemgetters(*args):\n    \"\"\"\n    Get a handful of items from an iterable.\n\n    This is just map(itemgetter(...), iterable) with a list comprehension.\n    \"\"\"\n\n    f = itemgetter(*args)\n\n    def inner(l):\n        return [f(x) for x in l]\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_container(self, container, **kwargs):\n        try:\n            LOG.debug('create_container() with %s is success.', self.driver)\n            return self.driver.create_container(container, **kwargs)\n        except DriverException as e:\n            LOG.exception('create_container() with %s raised\\\n                            an exception %s.', self.driver, e)", "response": "Create container with specific driver."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete container :param container: container name (Container is equivalent to Bucket term in Amazon).", "response": "def delete_container(self, container):\n        \"\"\"Delete container\n\n        :param container: container name (Container is equivalent to\n                          Bucket term in Amazon).\n        \"\"\"\n        try:\n            LOG.debug('delete_container() with %s is success.', self.driver)\n            return self.driver.delete_container(container)\n        except DriverException as e:\n            LOG.exception('delete_container() with %s raised\\\n                            an exception %s.', self.driver, e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_container(self, container, metadata, **kwargs):\n        LOG.debug('update_object() with %s is success.', self.driver)\n        return self.driver.update_container(container, metadata, **kwargs)", "response": "Update the metadata of a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads object to Amazon S3.", "response": "def upload_object(self, container, obj, contents,\n                      content_length=None, metadata=None, **kwargs):\n        \"\"\"Upload object\n\n        :param container: container name (Container is equivalent to\n                          Bucket term in Amazon).\n        :param obj: object name (Object is equivalent to\n                    Key term in Amazon).\n        :param contents: object content.\n        :param content_length(int): content length.\n        :param metadata (dict): addition infomation.\n        :param **kwargs(dict): extend args for specific driver.\n        \"\"\"\n        try:\n            LOG.debug('upload_object() with %s is success.', self.driver)\n            return self.driver.upload_object(container, obj,\n                                             contents=contents,\n                                             content_length=content_length,\n                                             metadata=metadata,\n                                             **kwargs)\n        except DriverException as e:\n            LOG.exception('upload_object() with %s raised\\\n                            an exception %s.', self.driver, e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_object(self, container, obj, **kwargs):\n        try:\n            LOG.debug('delete_object() with %s is success.', self.driver)\n            return self.driver.delete_object(container, obj, **kwargs)\n        except DriverException as e:\n            LOG.exception('download_object() with %s raised\\\n                            an exception %s.', self.driver, e)", "response": "Delete object in container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting container objects with optional prefix and delimiter.", "response": "def list_container_objects(self, container, prefix=None, delimiter=None):\n        \"\"\"List container objects\n\n        :param container: container name (Container is equivalent to\n                          Bucket term in Amazon).\n        :param prefix: prefix query\n        :param delimiter: string to delimit the queries on\n        \"\"\"\n        LOG.debug('list_container_objects() with %s is success.', self.driver)\n        return self.driver.list_container_objects(container, prefix, delimiter)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating object metadata with the specified object.", "response": "def update_object(self, container, obj, metadata, **kwargs):\n        \"\"\"Update object metadata\n\n        :param container: container name (Container is equivalent to\n                          Bucket term in Amazon).\n        :param obj: object name (Object is equivalent to\n                    Key term in Amazon).\n        :param metadata(dict): additional metadata to include in the request.\n        \"\"\"\n        try:\n            LOG.debug('update_object() with %s is success.', self.driver)\n            return self.driver.update_object(container, obj,\n                                             metadata, **kwargs)\n        except DriverException as e:\n            LOG.exception('copy_object() with %s raised\\\n                            an exception %s.', self.driver, e)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy an object from the specified container to the specified destination.", "response": "def copy_object(self, container, obj, metadata=None,\n                    destination=None, **kwargs):\n        \"\"\"Copy object\n\n        :param container: container name (Container is equivalent to\n                          Bucket term in Amazon).\n        :param obj: object name (Object is equivalent to\n                    Key term in Amazon).\n        :param destination: The container and object name of the destination\n                            object in the form of /container/object; if None,\n                            the copy will use the source as the destination.\n        :param metadata(dict): additional metadata(headers)\n                               to include in the request\n        :param **kwargs(dict): extend args for specific driver.\n        \"\"\"\n        try:\n            LOG.debug('copy_object() with %s is success.', self.driver)\n            return self.driver.copy_object(container, obj, metadata=metadata,\n                                           destination=destination, **kwargs)\n        except DriverException as e:\n            LOG.exception('copy_object() with %s raised\\\n                            an exception %s.', self.driver, e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef permission_required(*actions, obj=None, raise_exception=False):\n    def checker(user):\n        ok = False\n        if user.is_authenticated() and check_perms(user, actions, [obj]):\n            ok = True\n        if raise_exception and not ok:\n            raise PermissionDenied\n        else:\n            return ok\n\n    def decorator(view_func):\n        @wraps(view_func, assigned=available_attrs(view_func))\n        def _wrapped_view(request, *args, **kwargs):\n            if checker(request.user):\n                return view_func(request, *args, **kwargs)\n        return _wrapped_view\n    return decorator", "response": "Decorator that checks that the user has permission to perform all of the actions on the object obj."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget object fields used for calculation of django - tutelary object paths.", "response": "def get_path_fields(cls, base=[]):\n    \"\"\"Get object fields used for calculation of django-tutelary object\n    paths.\n\n    \"\"\"\n    pfs = []\n    for pf in cls.TutelaryMeta.path_fields:\n        if pf == 'pk':\n            pfs.append(base + ['pk'])\n        else:\n            f = cls._meta.get_field(pf)\n            if isinstance(f, models.ForeignKey):\n                pfs += get_path_fields(f.target_field.model, base=base + [pf])\n            else:\n                pfs.append(base + [f.name])\n    return pfs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_perms_object(obj, action):\n    def get_one(pf):\n        if isinstance(pf, str):\n            return pf\n        else:\n            return str(reduce(lambda o, f: getattr(o, f), pf, obj))\n    return Object([get_one(pf) for pf in obj.__class__.TutelaryMeta.pfs])", "response": "Get the django - tutelary path for an object based on the fields\n    listed in TutelaryMeta. pfs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a function to delegate permission object rendering to some other ( foreign key field of an object.", "response": "def make_get_perms_object(perms_objs):\n    \"\"\"Make a function to delegate permission object rendering to some\n    other (foreign key) field of an object.\n\n    \"\"\"\n    def retfn(obj, action):\n        if action in perms_objs:\n            if perms_objs[action] is None:\n                return None\n            else:\n                return get_perms_object(getattr(obj, perms_objs[action]),\n                                        action)\n        else:\n            return get_perms_object(obj, action)\n    return retfn"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef permissioned_model(cls, perm_type=None, path_fields=None, actions=None):\n    if not issubclass(cls, models.Model):\n        raise DecoratorException(\n            'permissioned_model',\n            \"class '\" + cls.__name__ + \"' is not a Django model\"\n        )\n    added = False\n    try:\n        if not hasattr(cls, 'TutelaryMeta'):\n            if perm_type is None or path_fields is None or actions is None:\n                raise DecoratorException(\n                    'permissioned_model',\n                    (\"missing argument: all of perm_type, path_fields and \" +\n                     \"actions must be supplied\")\n                )\n            added = True\n            cls.TutelaryMeta = type('TutelaryMeta', (object,),\n                                    dict(perm_type=perm_type,\n                                         path_fields=path_fields,\n                                         actions=actions))\n        cls.TutelaryMeta.pfs = ([cls.TutelaryMeta.perm_type] +\n                                get_path_fields(cls))\n        perms_objs = {}\n        for a in cls.TutelaryMeta.actions:\n            an = a\n            ap = {}\n            if isinstance(a, tuple):\n                an = a[0]\n                ap = a[1]\n            Action.register(an)\n            if isinstance(ap, dict) and 'permissions_object' in ap:\n                po = ap['permissions_object']\n                if po is not None:\n                    try:\n                        t = cls._meta.get_field(po).__class__\n                        if t not in [models.ForeignKey,\n                                     models.OneToOneField]:\n                            raise PermissionObjectException(po)\n                    except:\n                        raise PermissionObjectException(po)\n                perms_objs[an] = po\n        if len(perms_objs) == 0:\n            cls.get_permissions_object = get_perms_object\n        else:\n            cls.get_permissions_object = make_get_perms_object(perms_objs)\n        return cls\n    except:\n        if added:\n            del cls.TutelaryMeta\n        raise", "response": "Function to set up a permissioned version of a class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning arrays with equal size of item attributes from a list of sorted items for fast and convenient data processing.", "response": "def _getArrays(items, attr, defaultValue):\n    \"\"\"Return arrays with equal size of item attributes from a list of sorted\n    \"items\" for fast and convenient data processing.\n\n    :param attr: list of item attributes that should be added to the returned\n        array.\n    :param defaultValue: if an item is missing an attribute, the \"defaultValue\"\n        is added to the array instead.\n\n    :returns: {'attribute1': numpy.array([attributeValue1, ...]), ...}\n    \"\"\"\n    arrays = dict([(key, []) for key in attr])\n    for item in items:\n        for key in attr:\n            arrays[key].append(getattr(item, key, defaultValue))\n    for key in [_ for _ in viewkeys(arrays)]:\n        arrays[key] = numpy.array(arrays[key])\n\n    return arrays"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _containerSetPath(container, folderpath, specfiles):\n    if not os.path.exists(folderpath):\n        warntext = 'Error while calling \"_containerSetPath()\": The specified '\\\n                   'directory \"%s\" does not exist!' %(folderpath, )\n        warnings.warn(warntext)\n    for specfile in specfiles:\n        if specfile in container.info:\n            container.info[specfile]['path'] = folderpath\n        else:\n            warntext = 'Error while calling \"_containerSetPath()\": The '\\\n                       'specfile \"%s\" is not present in the container!'\\\n                       %(specfile, )\n            warnings.warn(warntext)", "response": "Private method to set the folderpath of the specified specfiles in the container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mzmlListAttribToTuple(oldList):\n    newList = list()\n    for oldParamList in oldList:\n        newParamLIst = [tuple(param) for param in oldParamList]\n        newList.append(newParamLIst)\n    return newList", "response": "Turns the param entries of elements in a list elements into tuples used\n    in MzmlScan. _fromJSON."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addMsrunContainers(mainContainer, subContainer):\n    typeToContainer = {'rm': 'rmc', 'ci': 'cic', 'smi': 'smic',\n                       'sai': 'saic', 'si': 'sic'\n                       }\n    for specfile in subContainer.info:\n        if specfile in mainContainer.info:\n            continue\n\n        mainContainer.addSpecfile(specfile, subContainer.info[specfile]['path'])\n        for datatype, status in listitems(subContainer.info[specfile]['status']):\n            if not status:\n                continue\n            datatypeContainer = typeToContainer[datatype]\n            dataTypeContainer = getattr(mainContainer, datatypeContainer)\n            subContainerData = getattr(subContainer,\n                                       datatypeContainer\n                                       )[specfile]\n            dataTypeContainer[specfile] = subContainerData\n            mainContainer.info[specfile]['status'][datatype] = True", "response": "Adds all specfiles from the subContainer to the mainContainer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a condensed array of items from the specified attributes.", "response": "def getArrays(self, attr=None, specfiles=None, sort=False, reverse=False,\n                  selector=None, defaultValue=None):\n        \"\"\"Return a condensed array of data selected from :class:`Si` instances\n        from ``self.sic`` for fast and convenient data processing.\n\n        :param attr: list of :class:`Si` item attributes that should be added to\n            the returned array. The attributes \"id\" and \"specfile\" are always\n            included, in combination they serve as a unique id.\n        :param defaultValue: if an item is missing an attribute, the\n            \"defaultValue\" is added to the array instead.\n        :param specfiles: filenames of ms-run files, if specified return only\n            items from those files\n        :type specfiles: str or [str, str, ...]\n        :param sort: if \"sort\" is specified the returned list of items is sorted\n            according to the :class:`Si` attribute specified by \"sort\", if the\n            attribute is not present the item is skipped.\n        :param reverse: bool, set True to reverse sort order\n        :param selector: a function which is called with each :class:`Si` item\n            and has to return True (include item) or False (discard item).\n            Default function is: ``lambda si: True``\n\n        :returns: {'attribute1': numpy.array(),\n                   'attribute2': numpy.array(),\n                   ...\n                   }\n        \"\"\"\n        selector = (lambda si: True) if selector is None else selector\n        attr = attr if attr is not None else []\n        attr = set(['id', 'specfile'] + aux.toList(attr))\n        items = self.getItems(specfiles, sort, reverse, selector)\n        return _getArrays(items, attr, defaultValue)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getItems(self, specfiles=None, sort=False, reverse=False,\n                 selector=None):\n        \"\"\"Generator that yields filtered and/or sorted :class:`Si` instances\n        from ``self.sic``.\n\n        :param specfiles: filenames of ms-run files - if specified return only\n            items from those files\n        :type specfiles: str or [str, str, ...]\n        :param sort: if \"sort\" is specified the returned list of items is sorted\n            according to the :class:`Si` attribute specified by \"sort\", if the\n            attribute is not present the item is skipped.\n        :param reverse: bool, ``True`` reverses the sort order\n        :param selector: a function which is called with each ``Si`` item\n            and returns True (include item) or False (discard item). Default\n            function is: ``lambda si: True``\n\n        :returns: items from container that passed the selector function\n        \"\"\"\n        selector = (lambda si: True) if selector is None else selector\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n        return _getItems(self.sic, specfiles, sort, reverse, selector)", "response": "Generator that yields filtered and or sorted items from the given specfiles."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addSpecfile(self, specfiles, path):\n        for specfile in aux.toList(specfiles):\n            if specfile not in self.info:\n                self._addSpecfile(specfile, path)\n            else:\n                warntext = 'Error while calling \"MsrunContainer.addSpecfile()\"'\\\n                           ': \"%s\" is already present \"MsrunContainer.info\"'\\\n                            % (specfile, )\n                warnings.warn(warntext)", "response": "Prepares the container for loading mrc files by adding specfile\n        entries to self. info."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new specfile entry to the info dict.", "response": "def _addSpecfile(self, specfile, path):\n        \"\"\"Adds a new specfile entry to MsrunContainer.info. See also\n        :class:`MsrunContainer.addSpecfile()`.\n\n        :param specfile: the name of an ms-run file\n        :param path: filedirectory used for loading and saving ``mrc`` files\n        \"\"\"\n        datatypeStatus = {'rm': False, 'ci': False, 'smi': False, 'sai': False,\n                          'si': False\n                          }\n        self.info[specfile] = {'path': path, 'status': datatypeStatus}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setPath(self, folderpath, specfiles=None):\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        _containerSetPath(self, folderpath, specfiles)", "response": "Changes the folderpath of the specified specfiles."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the specified datatypes of the specified specfiles from the msrunContainer.", "response": "def removeData(self, specfiles=None, rm=False, ci=False, smi=False,\n                   sai=False, si=False):\n        \"\"\"Removes the specified datatypes of the specfiles from the\n        msrunContainer. To completely remove a specfile use\n        :func:`MsrunContainer.removeSpecfile`, which also removes the complete\n        entry from ``self.info``.\n\n        :param specfiles: the name of an ms-run file or a list of names. If None\n            all specfiles are selected.\n        :type specfiles: None, str, [str, str]\n        :param rm: bool, True to select ``self.rmc``\n        :param ci: bool, True to select ``self.cic``\n        :param smi: bool, True to select ``self.smic``\n        :param sai: bool, True to select ``self.saic``\n        :param si: bool, True to select ``self.sic``\n        \"\"\"\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n        #TODO: add a check if specfiles are present in the container\n        typeToContainer = {'rm': 'rmc', 'ci': 'cic', 'smi': 'smic',\n                           'sai': 'saic', 'si': 'sic'\n                           }\n        datatypes = self._processDatatypes(rm, ci, smi, sai, si)\n        for specfile in specfiles:\n            for datatype in datatypes:\n                datatypeContainer = typeToContainer[datatype]\n                dataContainer = getattr(self, datatypeContainer)\n                try:\n                    del dataContainer[specfile]\n                except KeyError:\n                    pass\n                finally:\n                    self.info[specfile]['status'][datatype] = False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _processDatatypes(self, rm, ci, smi, sai, si):\n        datatypes = list()\n        for datatype, value in [('rm', rm), ('ci', ci), ('smi', smi),\n                                ('sai', sai), ('si', si)]:\n            if value:\n                datatypes.append(datatype)\n        return datatypes", "response": "Helper function that returns a list of datatype strings depending on the parameters boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, specfiles=None, rm=False, ci=False, smi=False, sai=False,\n             si=False, compress=True, path=None):\n        \"\"\"Writes the specified datatypes to ``mrc`` files on the hard disk.\n\n        .. note::\n            If ``.save()`` is called and no ``mrc`` files are present in the\n            specified path new files are generated, otherwise old files are\n            replaced.\n\n        :param specfiles: the name of an ms-run file or a list of names. If None\n            all specfiles are selected.\n        :type specfiles: None, str, [str, str]\n        :param rm: bool, True to select ``self.rmc`` (run metadata)\n        :param ci: bool, True to select ``self.cic`` (chromatogram items)\n        :param smi: bool, True to select ``self.smic`` (spectrum metadata items)\n        :param sai: bool, True to select ``self.saic`` (spectrum array items)\n        :param si: bool, True to select ``self.sic`` (spectrum items)\n        :param compress: bool, True to use zip file compression\n        :param path: filedirectory to which the ``mrc`` files are written. By\n            default the parameter is set to ``None`` and the filedirectory is\n            read from ``self.info[specfile]['path']``\n        \"\"\"\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n        datatypes = self._processDatatypes(rm, ci, smi, sai, si)\n        if len(datatypes) == 0:\n            datatypes = ['rm', 'ci', 'smi', 'sai', 'si']\n\n        for specfile in specfiles:\n            if specfile not in self.info:\n                warntext = 'Error while calling \"MsrunContainer.save()\": \"%s\" '\\\n                           'is not present in \"MsrunContainer.info\"!'\\\n                            % (specfile, )\n                warnings.warn(warntext)\n                continue\n            else:\n                msrunInfo = self.info[specfile]\n                specfilePath = msrunInfo['path'] if path is None else path\n\n            with aux.PartiallySafeReplace() as msr:\n                for datatype in datatypes:\n                    filename = specfile + '.mrc_' + datatype\n                    filepath = aux.joinpath(specfilePath, filename)\n                    with msr.open(filepath, 'w+b') as openfile:\n                        if datatype == 'rm':\n                           self._writeRmc(openfile, specfile)\n                        elif datatype == 'ci':\n                           self._writeCic(openfile, specfile, compress)\n                        elif datatype == 'si':\n                           self._writeSic(openfile, specfile, compress)\n                        elif datatype == 'smi':\n                           self._writeSmic(openfile, specfile, compress)\n                        elif datatype == 'sai':\n                           self._writeSaic(openfile, specfile, compress)", "response": "Writes the specified datatypes to the mrc files on the hard disk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the. cic file of the specified specfile to the the mrc_cic format.", "response": "def _writeCic(self, filelike, specfile, compress):\n        \"\"\"Writes the ``.cic`` container entry of the specified specfile to the\n        ``mrc_cic`` format. For details see\n         :func:`maspy.auxiliary.writeBinaryItemContainer()`\n\n        :param filelike: path to a file (str) or a file-like object\n        :param specfile: name of an ms-run file present in ``self.info``\n        :param compress: bool, True to use zip file compression\n        \"\"\"\n        aux.writeBinaryItemContainer(filelike, self.cic[specfile], compress)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the. ssic container entry of the specified specfile to the the mrc_saic format.", "response": "def _writeSaic(self, filelike, specfile, compress):\n        \"\"\"Writes the ``.ssic`` container entry of the specified specfile to the\n        ``mrc_saic`` format. For details see\n         :func:`maspy.auxiliary.writeBinaryItemContainer()`\n\n        :param filelike: path to a file (str) or a file-like object\n        :param specfile: name of an ms-run file present in ``self.info``\n        :param compress: bool, True to use zip file compression\n        \"\"\"\n        aux.writeBinaryItemContainer(filelike, self.saic[specfile], compress)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the. smic file of the specified specfile to the the mrc_smic format.", "response": "def _writeSmic(self, filelike, specfile, compress):\n        \"\"\"Writes the ``.smic`` container entry of the specified specfile to the\n        ``mrc_smic`` format. For details see\n         :func:`maspy.auxiliary.writeJsonZipfile()`\n\n        :param filelike: path to a file (str) or a file-like object\n        :param specfile: name of an ms-run file present in ``self.info``\n        :param compress: bool, True to use zip file compression\n        \"\"\"\n        aux.writeJsonZipfile(filelike, self.smic[specfile], compress)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the. sic file of the specified specfile to the the mrc_sic format.", "response": "def _writeSic(self, filelike, specfile, compress):\n        \"\"\"Writes the ``.sic`` container entry of the specified specfile to the\n        ``mrc_sic`` format. For details see\n         :func:`maspy.auxiliary.writeJsonZipfile()`\n\n        :param filelike: path to a file (str) or a file-like object\n        :param specfile: name of an ms-run file present in ``self.info``\n        :param compress: bool, True to use zip file compression\n        \"\"\"\n        aux.writeJsonZipfile(filelike, self.sic[specfile], compress)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _writeRmc(self, filelike, specfile):\n        xmlString = ETREE.tostring(self.rmc[specfile], pretty_print=True)\n        filelike.write(xmlString)", "response": "Writes the. rmc file of the specified specfile as an analyzed. rmc file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the specified datatypes from the specified MRC files on the hard disk.", "response": "def load(self, specfiles=None, rm=False, ci=False, smi=False, sai=False,\n             si=False):\n        \"\"\"Import the specified datatypes from ``mrc`` files on the hard disk.\n\n        :param specfiles: the name of an ms-run file or a list of names. If None\n            all specfiles are selected.\n        :type specfiles: None, str, [str, str]\n        :param rm: bool, True to import ``mrc_rm`` (run metadata)\n        :param ci: bool, True to import ``mrc_ci`` (chromatogram items)\n        :param smi: bool, True to import ``mrc_smi`` (spectrum metadata items)\n        :param sai: bool, True to import ``mrc_sai`` (spectrum array items)\n        :param si: bool, True to import ``mrc_si`` (spectrum items)\n        \"\"\"\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        #Select only specfiles which are present in the ``self.info``.\n        selectedSpecfiles = list()\n        for specfile in specfiles:\n            if specfile not in self.info:\n                warntext = 'Error while calling \"MsrunContainer.load()\": \"%s\" '\\\n                           'not present in MsrunContainer.info' % specfile\n                warnings.warn(warntext)\n            else:\n                selectedSpecfiles.append(specfile)\n\n        datatypes = self._processDatatypes(rm, ci, smi, sai, si)\n        if len(datatypes) == 0:\n            datatypes = ['rm', 'ci', 'smi', 'sai', 'si']\n\n        for specfile in selectedSpecfiles:\n            msrunInfo = self.info[specfile]\n            specfilePath = msrunInfo['path']\n\n            if 'rm' in datatypes:\n                rmPath = aux.joinpath(specfilePath, specfile+'.mrc_rm')\n                with open(rmPath, 'rb') as openfile:\n                    xmlString = openfile.read()\n                self.rmc[specfile] = ETREE.fromstring(xmlString)\n                msrunInfo['status']['rm'] = True\n\n            if 'ci' in datatypes:\n                ciPath = aux.joinpath(specfilePath, specfile+'.mrc_ci')\n                self.cic[specfile] = aux.loadBinaryItemContainer(ciPath,\n                                                                 Ci.jsonHook)\n                msrunInfo['status']['ci'] = True\n\n            if 'smi' in datatypes:\n                smiPath = aux.joinpath(specfilePath, specfile+'.mrc_smi')\n                with zipfile.ZipFile(smiPath, 'r') as containerZip:\n                    #Convert the zipfile data into a str object,necessary since\n                    #containerZip.read() returns a bytes object.\n                    jsonString = io.TextIOWrapper(containerZip.open('data'),\n                                                  encoding='utf-8'\n                                                  ).read()\n                self.smic[specfile] = json.loads(jsonString,\n                                                 object_hook=Smi.jsonHook\n                                                 )\n                msrunInfo['status']['smi'] = True\n\n            if 'sai' in datatypes:\n                saiPath = aux.joinpath(specfilePath, specfile+'.mrc_sai')\n                self.saic[specfile] = aux.loadBinaryItemContainer(saiPath,\n                                                                  Sai.jsonHook\n                                                                  )\n                msrunInfo['status']['sai'] = True\n\n            if 'si' in datatypes:\n                siPath = aux.joinpath(specfilePath, specfile+'.mrc_si')\n                with zipfile.ZipFile(siPath, 'r') as containerZip:\n                    #Convert the zipfile data into a str object, necessary since\n                    #containerZip.read() returns a bytes object.\n                    jsonString = io.TextIOWrapper(containerZip.open('data'),\n                                                  encoding='utf-8'\n                                                  ).read()\n                self.sic[specfile] = json.loads(jsonString,\n                                                object_hook=Si.jsonHook\n                                                )\n                msrunInfo['status']['si'] = True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _reprJSON(self):\n        return {'__Ci__': (self.id, self.specfile, self.dataProcessingRef,\n                           self.precursor, self.product, self.params,\n                           self.attrib, self.arrayInfo\n                           )\n                }", "response": "Returns a JSON serializable represenation of a Ci class instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fromJSON(cls, jsonobject):\n        newInstance = cls(jsonobject[0], jsonobject[1])\n        attribDict = {}\n        attribDict['dataProcessingRef'] = jsonobject[2]\n        attribDict['precursor'] = jsonobject[3]\n        attribDict['product'] = jsonobject[4]\n        attribDict['params'] = [tuple(param) for param in jsonobject[5]]\n        attribDict['attrib'] = jsonobject[6]\n        attribDict['arrayInfo'] = dict()\n        for arrayType, jsonEntry in viewitems(jsonobject[7]):\n            arrayEntry = {'dataProcessingRef': jsonEntry['dataProcessingRef'],\n                          'params': [tuple(_) for _ in jsonEntry['params']]\n                          }\n            attribDict['arrayInfo'][arrayType] = arrayEntry\n        for key, value in viewitems(attribDict):\n            setattr(newInstance, key, value)\n        return newInstance", "response": "Generates a new instance of a class of Ci from a decoded JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fromJSON(cls, jsonobject):\n        newInstance = cls(jsonobject[0], jsonobject[1])\n        for arrayType, jsonEntry in viewitems(jsonobject[2]):\n            arrayEntry = {'dataProcessingRef': jsonEntry['dataProcessingRef'],\n                          'params': [tuple(_) for _ in jsonEntry['params']]\n                          }\n            newInstance.arrayInfo[arrayType] = arrayEntry\n\n        return newInstance", "response": "Generates a new instance of Sai from a decoded JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a JSON serializable representation of a new version of the object.", "response": "def _reprJSON(self):\n        \"\"\"Returns a JSON serializable represenation of a ``Smi`` class\n        instance. Use :func:`maspy.core.Sai._fromJSON()` to generate a new\n        ``Smi`` instance from the return value.\n\n        :returns: a JSON serializable python object\n        \"\"\"\n        return {'__Smi__': (self.id, self.specfile, self.attributes,\n                            self.params, self.scanListParams, self.scanList,\n                            self.precursorList, self.productList\n                            )\n                }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fromJSON(cls, jsonobject):\n        newInstance = cls(None, None)\n        attribDict = {}\n        attribDict['id'] = jsonobject[0]\n        attribDict['specfile'] = jsonobject[1]\n        attribDict['attributes'] = jsonobject[2]\n        attribDict['params'] = [tuple(param) for param in jsonobject[3]]\n        attribDict['scanListParams'] = [tuple(param) for param in jsonobject[4]]\n        attribDict['scanList'] = jsonobject[5]\n        attribDict['precursorList'] = jsonobject[6]\n        attribDict['productList'] = jsonobject[7]\n        for key, value in viewitems(attribDict):\n            setattr(newInstance, key, value)\n        return newInstance", "response": "Generates a new instance of a class Smi from a decoded JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jsonHook(encoded):\n        if '__Smi__' in encoded:\n            return Smi._fromJSON(encoded['__Smi__'])\n        elif '__MzmlScan__' in encoded:\n            return MzmlScan._fromJSON(encoded['__MzmlScan__'])\n        elif '__MzmlProduct__' in encoded:\n            return MzmlProduct._fromJSON(encoded['__MzmlProduct__'])\n        elif '__MzmlPrecursor__' in encoded:\n            return MzmlPrecursor._fromJSON(encoded['__MzmlPrecursor__'])\n        else:\n            return encoded", "response": "Custom JSON decoder that allows construction of a new Smi object from a decoded JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fromJSON(cls, jsonobject):\n        newInstance = cls(None, None)\n        newInstance.__dict__.update(jsonobject)\n        return newInstance", "response": "Generates a new instance of a class Si from a decoded JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a new instance of MzmlScan from a decoded JSON object.", "response": "def _fromJSON(cls, jsonobject):\n        \"\"\"Generates a new instance of :class:`maspy.core.MzmlScan` from a\n        decoded JSON object (as generated by\n        :func:`maspy.core.MzmlScan._reprJSON()`).\n\n        :param jsonobject: decoded JSON object\n\n        :returns: a new instance of :class:`MzmlScan`\n        \"\"\"\n        scanWindowList = _mzmlListAttribToTuple(jsonobject[0])\n        params = [tuple(param) for param in jsonobject[1]]\n        return cls(scanWindowList, params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fromJSON(cls, jsonobject):\n        isolationWindow =[tuple(param) for param in jsonobject]\n        return cls(isolationWindow)", "response": "Generates a new instance of MzmlProduct from a\n        decoded JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _reprJSON(self):\n        return {'__MzmlPrecursor__': (self.spectrumRef, self.activation,\n                                      self.isolationWindow, self.selectedIonList\n                                      )\n                }", "response": "Returns a JSON serializable represenation of a MzmlPrecursor object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a new MzmlPrecursor instance from a json - encoded MzmlPrecursor object.", "response": "def _fromJSON(cls, jsonobject):\n        \"\"\"Generates a new instance of :class:`maspy.core.MzmlPrecursor` from a\n        decoded JSON object (as generated by\n        :func:`maspy.core.MzmlPrecursor._reprJSON()`).\n\n        :param jsonobject: decoded JSON object\n\n        :returns: a new instance of :class:`MzmlPrecursor`\n        \"\"\"\n        spectrumRef = jsonobject[0]\n        activation = [tuple(param) for param in jsonobject[1]]\n        isolationWindow =[tuple(param) for param in jsonobject[2]]\n        selectedIonList = _mzmlListAttribToTuple(jsonobject[3])\n        return cls(spectrumRef, activation, isolationWindow, selectedIonList)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getItems(self, specfiles=None, sort=False, reverse=False,\n                 selector=None):\n        \"\"\"Generator that yields filtered and/or sorted :class:`Sii` instances\n        from ``self.container``.\n\n        :param specfiles: filenames of ms-run files - if specified return only\n            items from those files\n        :type specfiles: str or [str, str, ...]\n        :param sort: if \"sort\" is specified the returned list of items is sorted\n            according to the :class:`Sii` attribute specified by \"sort\", if the\n            attribute is not present the item is skipped.\n        :param reverse: bool, ``True`` reverses the sort order\n        :param selector: a function which is called with each ``Sii`` item and\n            has to return True (include item) or False (discard item). By\n            default only items with ``Sii.isValid == True`` are returned.\n\n        :returns: items from container that passed the selector function\n        \"\"\"\n        selector = (lambda sii: sii.isValid) if selector is None else selector\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n        return _getListItems(self.container, specfiles, sort, reverse, selector)", "response": "Generator that yields filtered and or sorted items from the specified files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getValidItem(self, specfile, identifier):\n        for item in self.container[specfile][identifier]:\n            if item.isValid:\n                return item\n        else:\n            return None", "response": "Returns a Sii instance from self. container if it is valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _addSpecfile(self, specfile, path):\n        self.info[specfile] = {'path': path, 'qcAttr': None, 'qcCutoff': None,\n                               'qcLargerBetter': None, 'rankAttr': None,\n                               'rankLargerBetter': None\n                               }\n        self.container[specfile] = dict()", "response": "Adds a new specfile entry to the SiiContainer. info. See also\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, specfiles=None, compress=True, path=None):\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        for specfile in specfiles:\n            if specfile not in self.info:\n                warntext = 'Error while calling \"SiiContainer.save()\": \"%s\" is'\\\n                           ' not present in \"SiiContainer.info\"!'\\\n                            % (specfile, )\n                warnings.warn(warntext)\n                continue\n            else:\n                path = self.info[specfile]['path'] if path is None else path\n\n            with aux.PartiallySafeReplace() as msr:\n                filename = specfile + '.siic'\n                filepath = aux.joinpath(path, filename)\n                with msr.open(filepath, mode='w+b') as openfile:\n                    self._writeContainer(openfile, specfile, compress)", "response": "Writes the specified specfiles to the hard disk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addSiInfo(self, msrunContainer, specfiles=None,\n                  attributes=['obsMz', 'rt', 'charge']):\n        \"\"\"Transfer attributes to :class:`Sii` elements from the corresponding\n        :class`Si` in :class:`MsrunContainer.sic <MsrunContainer>`. If an\n        attribute is not present in the ``Si`` the attribute value in the\n        ``Sii``is set to ``None``.\n\n        Attribute examples: 'obsMz', 'rt', 'charge', 'tic', 'iit', 'ms1Id'\n\n        :param msrunContainer: an instance of :class:`MsrunContainer` which has\n            imported the corresponding specfiles\n        :param specfiles: the name of an ms-run file or a list of names. If None\n            all specfiles are selected.\n        :param attributes: a list of ``Si`` attributes that should be\n            transfered.\n        \"\"\"\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        for specfile in specfiles:\n            if specfile not in self.info:\n                warntext = 'Error while calling \"SiiContainer.addSiInfo()\": '\\\n                           '\"%s\" is not present in \"SiiContainer.info\"!'\\\n                            % (specfile, )\n                warnings.warn(warntext)\n            elif specfile not in msrunContainer.info:\n                warntext = 'Error while calling \"SiiContainer.addSiInfo()\": '\\\n                           '\"%s\" is not present in \"MsrunContainer.info\"'\\\n                            % (specfile, )\n                warnings.warn(warntext)\n            else:\n                for identifier in self.container[specfile]:\n                    si = msrunContainer.sic[specfile][identifier]\n                    for sii in self.container[specfile][identifier]:\n                        for attribute in attributes:\n                            setattr(sii, attribute,\n                                    getattr(si, attribute, None)\n                                    )", "response": "Add information to the corresponding Si elements in the corresponding ms - run container."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calcMz(self, specfiles=None, guessCharge=True, obsMzKey='obsMz'):\n        #TODO: important to test function, since changes were made\n        _calcMass = maspy.peptidemethods.calcPeptideMass\n        _calcMzFromMass = maspy.peptidemethods.calcMzFromMass\n        _massProton = maspy.constants.atomicMassProton\n        _guessCharge = lambda mass, mz: round(mass / (mz - _massProton), 0)\n\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        tempMasses = dict()\n        for specfile in specfiles:\n            if specfile not in self.info:\n                warntext = 'Error while calling \"SiiContainer.calcMz()\": '\\\n                           '\"%s\" is not present in \"SiiContainer.info\"!'\\\n                            % (specfile, )\n                warnings.warn(warntext)\n            else:\n                for sii in self.getItems(specfiles=specfile):\n                    peptide = sii.peptide\n                    if peptide not in tempMasses:\n                        if hasattr(sii, 'diPeptide'):\n                            tempMasses[peptide] = (_calcMass(sii.peptide1) +\n                                                   _calcMass(sii.peptide2)\n                                                   )\n                        else:\n                            tempMasses[peptide] = _calcMass(peptide)\n                    peptideMass = tempMasses[peptide]\n                    if sii.charge is not None:\n                        sii.excMz = _calcMzFromMass(peptideMass, sii.charge)\n                    elif guessCharge:\n                        guessedCharge = _guessCharge(peptideMass,\n                                                     getattr(sii, obsMzKey)\n                                                     )\n                        sii.excMz = _calcMzFromMass(peptideMass, guessedCharge)\n                        sii.charge = guessedCharge\n                    else:\n                        sii.excMz = None\n        del(tempMasses)", "response": "Calculate the exact mass for all the items in the specified ms - run file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a condensed array of data selected from the specified attribute and specfiles.", "response": "def getArrays(self, attr=None, specfiles=None, sort=False, reverse=False,\n                  selector=None, defaultValue=None):\n        \"\"\"Return a condensed array of data selected from :class:`Fi` instances\n        from ``self.container`` for fast and convenient data processing.\n\n        :param attr: list of :class:`Fi` item attributes that should be added\n            to the returned array. The attributes \"id\" and \"specfile\" are always\n            included, in combination they serve as a unique id.\n        :param defaultValue: if an item is missing an attribute, the\n            \"defaultValue\" is added to the array instead.\n        :param specfiles: filenames of ms-run files - if specified return only\n            items from those files\n        :type specfiles: str or [str, str, ...]\n        :param sort: if \"sort\" is specified the returned list of items is sorted\n            according to the :class:`Fi` attribute specified by \"sort\", if the\n            attribute is not present the item is skipped.\n        :param reverse: bool, set True to reverse sort order\n        :param selector: a function which is called with each `Fi` item and has\n            to return True (include item) or False (discard item).\n            Default function is: ``lambda si: True``. By default only items with\n            ``Fi.isValid == True`` are returned.\n\n        :returns: {'attribute1': numpy.array(),\n                   'attribute2': numpy.array(),\n                   ...\n                   }\n        \"\"\"\n        selector = (lambda fi: fi.isValid) if selector is None else selector\n        attr = attr if attr is not None else []\n        attr = set(['id', 'specfile'] + aux.toList(attr))\n        items = self.getItems(specfiles, sort, reverse, selector)\n        return _getArrays(items, attr, defaultValue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the contents of the specified specfile to the fic format.", "response": "def _writeContainer(self, filelike, specfile, compress):\n        \"\"\"Writes the ``self.container`` entry of the specified specfile to the\n        ``fic`` format.\n\n        :param filelike: path to a file (str) or a file-like object\n        :param specfile: name of an ms-run file present in ``self.info``\n        :param compress: bool, True to use zip file compression\n\n        .. note::\n            In addition it could also dump the ``self.info`` entry to the\n            zipfile with the filename ``info``, but this is not used at the\n            moment. For details see :func:`maspy.auxiliary.writeJsonZipfile()`\n        \"\"\"\n        aux.writeJsonZipfile(filelike, self.container[specfile],\n                             compress=compress\n                             )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports the specified fic files from the hard disk.", "response": "def load(self, specfiles=None):\n        \"\"\"Imports the specified ``fic`` files from the hard disk.\n\n        :param specfiles: the name of an ms-run file or a list of names. If None\n            all specfiles are selected.\n        :type specfiles: None, str, [str, str]\n        \"\"\"\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        for specfile in specfiles:\n            if specfile not in self.info:\n                warntext = 'Error while calling \"FiContainer.load()\": \"%s\" is'\\\n                           ' not present in \"FiContainer.info\"!'\\\n                            % (specfile, )\n                warnings.warn(warntext)\n                continue\n            else:\n                fiPath = aux.joinpath(self.info[specfile]['path'],\n                                      specfile+'.fic'\n                                      )\n                with zipfile.ZipFile(fiPath, 'r') as containerZip:\n                    #Convert the zipfile data into a str object, necessary since\n                    #containerZip.read() returns a bytes object.\n                    jsonString = io.TextIOWrapper(containerZip.open('data'),\n                                                  encoding='utf-8'\n                                                  ).read()\n                    #infoString = io.TextIOWrapper(containerZip.open('info'),\n                    #                              encoding='utf-8'\n                    #                              ).read()\n                self.container[specfile] = json.loads(jsonString,\n                                                      object_hook=Fi.jsonHook\n                                                      )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef removeAnnotation(self, specfiles=None):\n        if specfiles is None:\n            specfiles = [_ for _ in viewkeys(self.info)]\n        else:\n            specfiles = aux.toList(specfiles)\n\n        for specfile in aux.toList(specfiles):\n            for item in viewvalues(self.container[specfile]):\n                item.isMatched = False\n                item.isAnnotated = False\n                item.siIds = list()\n                item.siiIds = list()\n                item.peptide = None\n                item.sequence = None\n                item.bestScore = None", "response": "Removes all annotation information from the Fi elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a JSON - serializeable object representing this tree.", "response": "def as_dict(self):\n        \"\"\"Returns a JSON-serializeable object representing this tree.\"\"\"\n        def conv(v):\n            if isinstance(v, SerializableAttributesHolder):\n                return v.as_dict()\n            elif isinstance(v, list):\n                return [conv(x) for x in v]\n            elif isinstance(v, dict):\n                return {x:conv(y) for (x,y) in v.items()}\n            else:\n                return v\n        return {k.replace('_', '-'): conv(v) for (k, v) in self._attributes.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode a JSON string and inflate a node instance.", "response": "def from_json(cls, data):\n        \"\"\"Decode a JSON string and inflate a node instance.\"\"\"\n        # Decode JSON string\n        assert isinstance(data, str)\n        data = json.loads(data)\n        assert isinstance(data, dict)\n        return cls.from_dict(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the class is the _pred class", "response": "def _pred(aclass):\n    \"\"\"\n    :param aclass\n    :return: boolean\n    \"\"\"\n    isaclass = inspect.isclass(aclass)\n    return isaclass and aclass.__module__ == _pred.__module__"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the keywords from the given function.", "response": "def extract_keywords(func):\n    \"\"\"\n    Parses the keywords from the given function.\n\n    :param      func | <function>\n    \"\"\"\n    if hasattr(func, 'im_func'):\n        func = func.im_func\n\n    try:\n        return func.func_code.co_varnames[-len(func.func_defaults):]\n    except (TypeError, ValueError, IndexError):\n        return tuple()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jtag_enable(self):\n        status, _ = self.bulkCommand(_BMSG_ENABLE_JTAG)\n        if status == 0:\n            self._jtagon = True\n        elif status == 3:\n            self._jtagon = True\n            raise JTAGAlreadyEnabledError()\n        else:\n            raise JTAGEnableFailedError(\"Error enabling JTAG. Error code: %s.\" %status)", "response": "Enables JTAG output on the controller."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisabling JTAG output on the controller.", "response": "def jtag_disable(self):\n        \"\"\"\n        Disables JTAG output on the controller. JTAG operations executed\n        immediately after this function will return useless data or fail.\n\n        Usage:\n            >>> from proteusisc import getAttachedControllers, bitarray\n            >>> c = getAttachedControllers()[0]\n            >>> c.jtag_enable()\n            >>> c.write_tms_bits(bitarray(\"001011111\"), return_tdo=True)\n            >>> c.jtag_disable()\n        \"\"\"\n\n        if not self._jtagon: return\n        status, _ = self.bulkCommand(_BMSG_DISABLE_JTAG)\n        if status == 0:\n            self._jtagon = False\n        elif status == 3:\n            raise JTAGControlError(\"Error Code %s\"%status)\n\n        self.close_handle()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_tms_bits(self, data, return_tdo=False, TDI=False):\n        self._check_jtag()\n        self._update_scanchain(data)\n        self.bulkCommandDefault(_BMSG_WRITE_TMS %\n            (return_tdo, TDI, len(data).to_bytes(4, 'little')))\n        self.bulkWriteData(build_byte_align_buff(data).tobytes()[::-1])\n        tdo_bits = self._read_tdo(len(data)) if return_tdo else None\n        self._get_adv_trans_stats(0x0B, return_tdo)\n        return tdo_bits", "response": "Write TMS data over the physical scan chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites TDI bits to the physical scan chain.", "response": "def write_tdi_bits(self, buff, return_tdo=False, TMS=True):\n        \"\"\"\n        Command controller to write TDI data (with constant TMS bit)\n        to the physical scan chain. Optionally return TDO bits sent\n        back from scan the chain.\n\n        Args:\n            data - bits to send over TDI line of scan chain (bitarray)\n            return_tdo (bool) - return the devices bitarray response\n            TMS (bool) - whether TMS should send a bitarray of all 0's\n                         of same length as `data` (i.e False) or all 1's\n                         (i.e. True)\n\n        Returns:\n            None by default or the (bitarray) response of the device\n            after receiving data, if return_tdo is True.\n\n        Usage:\n            >>> from proteusisc import getAttachedControllers, bitarray\n            >>> c = getAttachedControllers()[0]\n            >>> c.jtag_enable()\n            >>> c.write_tdi_bits(bitarray(\"11111\"), return_tdo=True)\n            >>> c.jtag_disable()\n        \"\"\"\n        self._check_jtag()\n        tms_bits = bitarray([TMS]*len(buff))\n        self._update_scanchain(tms_bits)\n\n        self.bulkCommandDefault(_BMSG_WRITE_TDI %\n                    (return_tdo, TMS,  len(buff).to_bytes(4, 'little')))\n        self.bulkWriteData(build_byte_align_buff(buff).tobytes()[::-1])\n        tdo_bits = self._read_tdo(len(buff)) if return_tdo else None\n        self._get_adv_trans_stats(0x08, return_tdo)\n        return tdo_bits"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_tms_tdi_bits(self, tmsdata, tdidata, return_tdo=False):\n        self._check_jtag()\n        if len(tmsdata) != len(tdidata):\n            raise Exception(\"TMSdata and TDIData must be the same length\")\n        self._update_scanchain(tmsdata)\n        count = len(tmsdata)\n\n        t = time()\n        outdata = bitarray([val for pair in zip(tmsdata, tdidata)\n                            for val in pair])\n        outdata = build_byte_align_buff(outdata).tobytes()[::-1]\n\n        if self._scanchain and self._scanchain._print_statistics:\n            print(\"TDI/TDI DATA PREP TIME\", time()-t)#pragma: no cover\n            t = time()\n\n        self.bulkCommandDefault(_BMSG_WRITE_TMS_TDI % \\\n                  (return_tdo, count.to_bytes(4, 'little')))\n        self.bulkWriteData(outdata)\n\n        if self._scanchain and self._scanchain._print_statistics:\n            print(\"TRANSFER TIME\", time()-t)\n            t = time()\n\n        tdo_bits = self._read_tdo(count) if return_tdo else None\n\n        if self._scanchain and self._scanchain._print_statistics:\n            print(\"TDO READ TIME\", time()-t)#pragma: no cover\n\n        self._get_adv_trans_stats(0x0A, return_tdo)\n        return tdo_bits", "response": "Write TDI and TMS data to the TMS physical scan chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_tdo_bits(self, count, TMS=True, TDI=False):\n        self._check_jtag()\n        self._update_scanchain(bool(TMS))\n\n        self.bulkCommandDefault(\n            _BMSG_READ_TDO % (TMS, TDI, count.to_bytes(4, 'little')))\n        res = self._read_tdo(count)\n        self._get_adv_trans_stats(_BMSG_READ_TDO[2], True)\n        return res", "response": "Read count TDO bits from the physical scanchain and return them as a bitarray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a list of peptides from a file containing a protein database.", "response": "def importProteinDatabase(filePath, proteindb=None, decoyTag='[decoy]',\n        contaminationTag='[cont]', headerParser=None, forceId=False,\n        cleavageRule='[KR]', minLength=5, maxLength=40, missedCleavage=2,\n        ignoreIsoleucine=False, removeNtermM=True):\n    \"\"\"Generates a :class:`ProteinDatabase` by in silico digestion of proteins\n    from a fasta file.\n\n    :param filePath: File path\n    :param proteindb: optional an existing :class:`ProteinDatabase` can be\n        specified, otherwise a new instance is generated and returned\n    :param decoyTag: If a fasta file contains decoy protein entries, they should\n        be specified with a sequence tag\n    :param contaminationTag: If a fasta file contains contamination protein\n        entries, they should be specified with a sequence tag\n    :param headerParser: optional a headerParser can be specified\n        #TODO: describe how a parser looks like\n    :param forceId: bool, if True and no id can be extracted from the fasta\n        header the whole header sequence is used as a protein id instead of\n        raising an exception.\n    :param cleavageRule: cleavage rule expressed in a regular expression, see\n        :attr:`maspy.constants.expasy_rules`\n    :param missedCleavage: number of allowed missed cleavage sites\n    :param removeNtermM: bool, True to consider also peptides with the\n        N-terminal Methionine of the protein removed\n    :param minLength: int, only yield peptides with length >= minLength\n    :param maxLength: int, only yield peptides with length <= maxLength\n    :param ignoreIsoleucine: bool, if True treat Isoleucine and Leucine in\n        peptide sequences as indistinguishable\n\n    See also :func:`maspy.peptidemethods.digestInSilico`\n    \"\"\"\n    proteindb = ProteinDatabase() if proteindb is None else proteindb\n    fastaRead = _readFastaFile(filePath)\n\n    for header, sequence in fastaRead:\n        proteinTags = list()\n        if header.startswith(decoyTag):\n            isDecoy = True\n            header = header.replace(decoyTag, '')\n            proteinTags.append(decoyTag)\n        else:\n            isDecoy = False\n\n        if header.startswith(contaminationTag):\n            isCont = True\n            header = header.replace(contaminationTag, '')\n            proteinTags.append(contaminationTag)\n        else:\n            isCont = False\n\n        headerInfo = _extractFastaHeader(header, headerParser, forceId)\n        proteinId = ''.join(itertools.chain(proteinTags, [headerInfo['id']]))\n        if 'name' in headerInfo:\n            proteinName = ''.join(itertools.chain(proteinTags,\n                                                  [headerInfo['name']]\n                                                  )\n                                  )\n        else:\n            proteinName = proteinId\n\n        if proteinId not in proteindb.proteins:\n            protein = ProteinSequence(proteinId, sequence)\n            protein.name = proteinName\n            protein.fastaHeader = header\n            protein.fastaInfo = headerInfo\n            proteindb.proteins[protein.id] = protein\n\n        #Perform the insilico digestion\n        _digestion = maspy.peptidemethods.digestInSilico(sequence, cleavageRule,\n                                                         missedCleavage,\n                                                         removeNtermM,\n                                                         minLength, maxLength\n                                                         )\n\n        #Add peptides to the protein database\n        for unmodPeptide, info in _digestion:\n            if ignoreIsoleucine:\n                unmodPeptideNoIsoleucine = unmodPeptide.replace('I', 'L')\n                if unmodPeptideNoIsoleucine in proteindb.peptides:\n                    currPeptide = proteindb.peptides[unmodPeptideNoIsoleucine]\n                else:\n                    currPeptide = PeptideSequence(unmodPeptideNoIsoleucine,\n                                                  mc=info['missedCleavage']\n                                                  )\n                    proteindb.peptides[unmodPeptideNoIsoleucine] = currPeptide\n\n                if unmodPeptide not in proteindb.peptides:\n                    proteindb.peptides[unmodPeptide] = currPeptide\n            else:\n                if unmodPeptide in proteindb.peptides:\n                    currPeptide = proteindb.peptides[unmodPeptide]\n                else:\n                    currPeptide = PeptideSequence(unmodPeptide,\n                                                  mc=info['missedCleavage']\n                                                  )\n                    proteindb.peptides[unmodPeptide] = currPeptide\n\n            if proteinId not in currPeptide.proteins:\n                currPeptide.proteins.add(proteinId)\n                #TODO: change that a peptide can appear multiple times in a\n                #  protein sequence.\n                currPeptide.proteinPositions[proteinId] = (info['startPos'],\n                                                           info['endPos']\n                                                           )\n\n    #Add peptide entries to the protein entries, define wheter a peptide can be\n    #uniquely assigend to a single protein (.isUnique = True).\n    for peptide, peptideEntry in viewitems(proteindb.peptides):\n        numProteinMatches = len(peptideEntry.proteins)\n        if numProteinMatches == 1:\n            peptideEntry.isUnique = True\n        elif numProteinMatches > 1:\n            peptideEntry.isUnique = False\n        else:\n            raise Exception('No protein matches in proteindb for peptide' +\n                            'sequence: ' + peptide)\n\n        for proteinId in peptideEntry.proteins:\n            if peptideEntry.isUnique:\n                proteindb.proteins[proteinId].uniquePeptides.add(peptide)\n            else:\n                proteindb.proteins[proteinId].sharedPeptides.add(peptide)\n\n    #Check protein entries if the digestions generated at least one peptide that\n    #is uniquely assigned to the protein (.isUnique = True)\n    for proteinEntry in viewvalues(proteindb.proteins):\n        if len(proteinEntry.uniquePeptides) > 0:\n            proteinEntry.isUnique = True\n        else:\n            proteinEntry.isUnique = False\n    #Note: TODO, altough isoleucin is ignored, the protein entry should only\n    #show the actually present ILE / LEU occurence, not any possibilities\n    return proteindb"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a FASTA file and yields tuples of header and sequence entries.", "response": "def _readFastaFile(filepath):\n    \"\"\"Read a FASTA file and yields tuples of 'header' and 'sequence' entries.\n\n    :param filepath: file path of the FASTA file\n\n    :yields: FASTA entries in the format ('header', 'sequence').\n        The 'header' string does not contain the '>' and trailing white spaces.\n        The 'sequence' string does not contain trailing white spaces, a '*' at\n            the end of the sequence is removed.\n\n    See also :func:`importProteinDatabase` and\n    :func:`maspy.peptidemethods.digestInSilico`.\n    \"\"\"\n    processSequences = lambda i: ''.join([s.rstrip() for s in i]).rstrip('*')\n    processHeaderLine = lambda line: line[1:].rstrip()\n    with io.open(filepath) as openfile:\n        #Iterate through lines until the first header is encountered\n        try:\n            line = next(openfile)\n            while line[0] != '>':\n                line = next(openfile)\n            header = processHeaderLine(line)\n            sequences = list()\n        except StopIteration:\n            errorText = 'File does not contain fasta entries.'\n            raise maspy.errors.FileFormatError(errorText)\n\n        for line in openfile:\n            if line[0] == '>':\n                yield header, processSequences(sequences)\n                header = processHeaderLine(line)\n                sequences = list()\n            else:\n                sequences.append(line)\n\n        #Yield last entry\n        if sequences:\n            yield header, processSequences(sequences)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _extractFastaHeader(fastaHeader, parser=None, forceId=False):\n    if parser is None:\n        try:\n            headerInfo = pyteomics.fasta.parse(fastaHeader)\n        except pyteomics.auxiliary.PyteomicsError as pyteomicsError:\n            #If forceId is set True, it uses the whole header as an id\n            if forceId:\n                headerInfo = {'id': fastaHeader}\n            else:\n                raise pyteomicsError\n    else:\n        headerInfo = parser(fastaHeader)\n    return headerInfo", "response": "Parses a fasta header and returns extracted information in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fastaParseSgd(header):\n    rePattern = '([\\S]+)\\s([\\S]+).+(\\\".+\\\")'\n    ID, name, description = re.match(rePattern, header).groups()\n    info = {'id':ID, 'name':name, 'description':description}\n    return info", "response": "Custom parser for FASTA headers in the SGD format see\n    www. yeastgenome. org.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reprJSON(self):\n        return {'__PepSeq__': [self.sequence, self.missedCleavage,\n                               self.isUnique, list(self.proteins),\n                               self.proteinPositions]}", "response": "Returns a JSON serializable represenation of a PeptideSequence object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a new instance of : class : PeptideSequence from a decoded JSON object.", "response": "def _fromJSON(cls, jsonobject):\n        \"\"\"Generates a new instance of :class:`maspy.proteindb.PeptideSequence`\n        from a decoded JSON object (as generated by\n        :func:`maspy.proteindb.PeptideSequence._reprJSON()`).\n\n        :param jsonobject: decoded JSON object\n\n        :returns: a new instance of :class:`PeptideSequence`\n        \"\"\"\n        newInstance = cls(jsonobject[0], jsonobject[1])\n        newInstance.isUnique = jsonobject[2]\n        newInstance.proteins = set(jsonobject[3])\n        newInstance.proteinPositions = jsonobject[4]\n        return newInstance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a JSON serializable represenation of a protein sequence.", "response": "def _reprJSON(self):\n        \"\"\"Returns a JSON serializable represenation of a ``ProteinSequence``\n        class instance. Use :func:`maspy.proteindb.ProteinSequence._fromJSON()`\n        to generate a new ``ProteinSequence`` instance from the return value.\n\n        :returns: a JSON serializable python object\n        \"\"\"\n\n        jsonDict = self.__dict__\n        jsonDict['uniquePeptides'] = list(jsonDict['uniquePeptides'])\n        jsonDict['sharedPeptides'] = list(jsonDict['sharedPeptides'])\n        return {'__ProtSeq__': jsonDict}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a new instance of a class with the given JSON object.", "response": "def _fromJSON(cls, jsonobject):\n        \"\"\"Generates a new instance of :class:`maspy.proteindb.ProteinSequence`\n        from a decoded JSON object (as generated by\n        :func:`maspy.proteindb.ProteinSequence._reprJSON()`).\n\n        :param jsonobject: decoded JSON object\n\n        :returns: a new instance of :class:`ProteinSequence`\n        \"\"\"\n        newInstance = cls(None, None)\n        newInstance.__dict__.update(jsonobject)\n        newInstance.uniquePeptides = set(newInstance.uniquePeptides)\n        newInstance.sharedPeptides = set(newInstance.sharedPeptides)\n        return newInstance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, path, compress=True):\n        with aux.PartiallySafeReplace() as msr:\n            filename = self.info['name'] + '.proteindb'\n            filepath = aux.joinpath(path, filename)\n            with msr.open(filepath, mode='w+b') as openfile:\n                self._writeContainer(openfile, compress=compress)", "response": "Writes the proteins and peptides entries to the hard disk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the proteins and peptides entries to the container file.", "response": "def _writeContainer(self, filelike, compress=True):\n        \"\"\"Writes the ``.proteins`` and ``.peptides`` entries to the\n        ``proteindb`` format. In addition it also dumps the ``self.info`` entry\n        to the zipfile with the filename ``info``. For details see\n        :func:`maspy.auxiliary.writeJsonZipfile()`\n\n        :param filelike: path to a file (str) or a file-like object\n        :param compress: bool, True to use zip file compression\n        \"\"\"\n        aux.writeJsonZipfile(filelike, self.proteins, compress, 'w', 'proteins')\n        aux.writeJsonZipfile(filelike, self.peptides, compress, 'a', 'peptides')\n        zipcomp = zipfile.ZIP_DEFLATED if compress else zipfile.ZIP_STORED\n        with zipfile.ZipFile(filelike, 'a', allowZip64=True) as containerFile:\n            infodata = {key: value for key, value in\n                        viewitems(self.info) if key != 'path'\n                        }\n            containerFile.writestr('info', json.dumps(infodata, zipcomp))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the specified file from the hard disk.", "response": "def load(cls, path, name):\n        \"\"\"Imports the specified ``proteindb`` file from the hard disk.\n\n        :param path: filedirectory of the ``proteindb`` file\n        :param name: filename without the file extension \".proteindb\"\n\n        .. note:: this generates rather large files, which actually take longer\n            to import than to newly generate. Maybe saving / loading should be\n            limited to the protein database whitout in silico digestion\n            information.\n        \"\"\"\n\n        filepath = aux.joinpath(path, name + '.proteindb')\n        with zipfile.ZipFile(filepath, 'r', allowZip64=True) as containerZip:\n            #Convert the zipfile data into a str object, necessary since\n            #containerZip.read() returns a bytes object.\n            proteinsString = io.TextIOWrapper(containerZip.open('proteins'),\n                                              encoding='utf-8'\n                                              ).read()\n            peptidesString = io.TextIOWrapper(containerZip.open('peptides'),\n                                              encoding='utf-8'\n                                              ).read()\n            infoString = io.TextIOWrapper(containerZip.open('info'),\n                                          encoding='utf-8'\n                                          ).read()\n        newInstance = cls()\n        newInstance.proteins = json.loads(proteinsString,\n                                          object_hook=ProteinSequence.jsonHook)\n        newInstance.peptides = json.loads(peptidesString,\n                                          object_hook=PeptideSequence.jsonHook)\n        newInstance.info.update(json.loads(infoString))\n        return newInstance"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch keywords by shaman. KeywordFetcherGet average probabilities of keyword and language", "response": "def fetch_keywords(codedata) :\n\t\"\"\" Fetch keywords by shaman.KeywordFetcher\n\t\tGet average probabilities of keyword and language\n\t\"\"\"\n\n\t# Read row in codedata and count keywords in codes with langauge\n\ttmp = {}\n\tlanguage_counts = {}\n\n\tfor index, (language, code) in enumerate(codedata) :\n\t\tif language not in shaman.SUPPORTING_LANGUAGES :\n\t\t\tcontinue\n\n\t\tif language not in tmp :\n\t\t\ttmp[language] = {}\n\t\t\tlanguage_counts[language] = 0\n\n\t\tlanguage_counts[language] += 1\n\n\t\tfor keyword in shaman.KeywordFetcher.fetch( code ) :\n\t\t\t# if keyword exists in fetched data, add '1' to keyword data\n\t\t\ttmp[language][keyword] = tmp[language].get(keyword, 0) + 1\n\n\t\tprint('Fetch keyword %d/%d    ' % (index, len(codedata)), end='\\r')\n\n\n\t# Get dataset indexed by keyword\n\tret = {}\n\n\tfor language in tmp :\n\t\tfor keyword, count in tmp[ language ].items() :\t\n\t\t\tif keyword not in ret :\n\t\t\t\tret[ keyword ] = {}\n\n\t\t\tret[ keyword ][ language ] = (count / language_counts[ language ]) # Probability\n\n\tprint('Fetch keyword completed        ')\n\treturn ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmatch patterns by shaman. PatternMatcherGet average ratio of pattern and language", "response": "def match_patterns(codedata) :\n\t\"\"\" Match patterns by shaman.PatternMatcher\n\t\tGet average ratio of pattern and language\n\t\"\"\"\n\n\tret = {}\n\n\tfor index1, pattern in enumerate(shaman.PatternMatcher.PATTERNS) :\n\t\tprint('Matching pattern %d \"%s\"' % (index1+1, pattern))\n\n\t\tmatcher = shaman.PatternMatcher(pattern)\n\t\ttmp = {}\n\n\t\tfor index2, (language, code) in enumerate(codedata) :\n\t\t\tif language not in shaman.SUPPORTING_LANGUAGES :\n\t\t\t\tcontinue\n\n\t\t\tif len(code) <= 20 or len(code) > 100000 :\n\t\t\t\tcontinue\n\n\t\t\tif language not in tmp :\n\t\t\t\ttmp[language] = []\n\n\t\t\tratio = matcher.getratio(code)\n\t\t\ttmp[language].append(ratio)\n\n\t\t\tprint('Matching patterns %d/%d    ' % (index2, len(codedata)), end='\\r')\n\n\n\t\tret[pattern] = {}\n\t\tfor language, data in tmp.items() :\n\t\t\tret[pattern][language] = sum(tmp[language]) / max(len(tmp[language]), 1)\n\n\tprint('Matching patterns completed          ')\n\treturn ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef facility(self, column=None, value=None, **kwargs):\n        return self._resolve_call('RAD_FACILITY', column, value, **kwargs)", "response": "Get the current facility for this Radiation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the facility type of a RADInfo facility.", "response": "def facility_type(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Basic identifying information for a RADInfo facility, including\n        the improved facility information maintained by the Facility\n        Registry System (FRS). \n\n        >>> RADInfo().facility_type('cit_ref_code', '40CFR300')\n        \"\"\"\n        return self._resolve_call('RAD_FACILITY_TYPE', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef geo(self, column=None, value=None, **kwargs):\n        return self._resolve_call('RAD_GEO_LOCATION', column, value, **kwargs)", "response": "Locate a facility through geographic location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprovide relevant information about applicable regulations.", "response": "def regulation(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Provides relevant information about applicable regulations.\n\n        >>> RADInfo().regulation('title_id', 40)\n        \"\"\"\n        return self._resolve_call('RAD_REGULATION', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the regulatory program of the specified facility.", "response": "def regulatory_program(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Identifies the regulatory authority governing a facility, and, by\n        virtue of that identification, also identifies the regulatory program\n        of interest and the type of facility. \n\n        >>> RADInfo().regulatory_program('sec_cit_ref_flag', 'N')\n        \"\"\"\n        return self._resolve_call('RAD_REGULATORY_PROG', column,\n                                  value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollecting basic info about the system os python version...", "response": "def collect_basic_info():\n    \"\"\"\n    collect basic info about the system, os, python version...\n    \"\"\"\n\n    s = sys.version_info\n    _collect(json.dumps({'sys.version_info':tuple(s)}))\n    _collect(sys.version)\n    return sys.version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the ip addr list dev command raw output.", "response": "def _parse_ip_addr_show(raw_result):\n    \"\"\"\n    Parse the 'ip addr list dev' command raw output.\n\n    :param str raw_result: os raw result string.\n    :rtype: dict\n    :return: The parsed result of the show interface command in a \\\n        dictionary of the form:\n\n     ::\n\n        {\n            'os_index' : '0',\n            'dev' : 'eth0',\n            'falgs_str': 'BROADCAST,MULTICAST,UP,LOWER_UP',\n            'mtu': 1500,\n            'state': 'down',\n            'link_type' 'ether',\n            'mac_address': '00:50:56:01:2e:f6',\n            'inet': '20.1.1.2',\n            'inet_mask': '24',\n            'inet6': 'fe80::42:acff:fe11:2',\n            'inte6_mask': '64'\n        }\n    \"\"\"\n    # does link exist?\n    show_re = (\n        r'\"(?P<dev>\\S+)\"\\s+does not exist'\n    )\n    re_result = search(show_re, raw_result)\n    result = None\n\n    if not (re_result):\n        # match top two lines for serveral 'always there' variables\n        show_re = (\n            r'\\s*(?P<os_index>\\d+):\\s+(?P<dev>\\S+):\\s+<(?P<falgs_str>.*)?>.*?'\n            r'mtu\\s+(?P<mtu>\\d+).+?state\\s+(?P<state>\\w+).*'\n            r'\\s*link/(?P<link_type>\\w+)\\s+(?P<mac_address>\\S+)'\n        )\n\n        re_result = search(show_re, raw_result, DOTALL)\n        result = re_result.groupdict()\n\n        # seek inet if its there\n        show_re = (\n                r'((inet )\\s*(?P<inet>[^/]+)/(?P<inet_mask>\\d{1,2}))'\n            )\n        re_result = search(show_re, raw_result)\n        if (re_result):\n            result.update(re_result.groupdict())\n\n        # seek inet6 if its there\n        show_re = (\n                r'((?<=inet6 )(?P<inet6>[^/]+)/(?P<inet6_mask>\\d{1,2}))'\n            )\n        re_result = search(show_re, raw_result)\n        if (re_result):\n            result.update(re_result.groupdict())\n\n        # cleanup dictionary before returning\n        for key, value in result.items():\n            if value is not None:\n                if value.isdigit():\n                    result[key] = int(value)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_ip_stats_link_show(raw_result):\n\n    show_re = (\n        r'.+?RX:.*?\\n'\n        r'\\s*(?P<rx_bytes>\\d+)\\s+(?P<rx_packets>\\d+)\\s+(?P<rx_errors>\\d+)\\s+'\n        r'(?P<rx_dropped>\\d+)\\s+(?P<rx_overrun>\\d+)\\s+(?P<rx_mcast>\\d+)'\n        r'.+?TX:.*?\\n'\n        r'\\s*(?P<tx_bytes>\\d+)\\s+(?P<tx_packets>\\d+)\\s+(?P<tx_errors>\\d+)\\s+'\n        r'(?P<tx_dropped>\\d+)\\s+(?P<tx_carrier>\\d+)\\s+(?P<tx_collisions>\\d+)'\n    )\n\n    re_result = match(show_re, raw_result, DOTALL)\n    result = None\n\n    if (re_result):\n        result = re_result.groupdict()\n        for key, value in result.items():\n            if value is not None:\n                if value.isdigit():\n                    result[key] = int(value)\n\n    return result", "response": "Parse the ip - s link show dev command raw output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure an Engine Node s interface.", "response": "def interface(enode, portlbl, addr=None, up=None, shell=None):\n    \"\"\"\n    Configure a interface.\n\n    All parameters left as ``None`` are ignored and thus no configuration\n    action is taken for that parameter (left \"as-is\").\n\n    :param enode: Engine node to communicate with.\n    :type enode: topology.platforms.base.BaseNode\n    :param str portlbl: Port label to configure. Port label will be mapped to\n     real port automatically.\n    :param str addr: IPv4 or IPv6 address to add to the interface:\n     - IPv4 address and netmask to assign to the interface in the form\n     ``'192.168.20.20/24'``.\n     - IPv6 address and subnets to assign to the interface in the form\n     ``'2001::1/120'``.\n    :param bool up: Bring up or down the interface.\n    :param str shell: Shell name to execute commands.\n     If ``None``, use the Engine Node default shell.\n    \"\"\"\n    assert portlbl\n    port = enode.ports[portlbl]\n\n    if addr is not None:\n        assert ip_interface(addr)\n        cmd = 'ip addr add {addr} dev {port}'.format(addr=addr, port=port)\n        response = enode(cmd, shell=shell)\n        assert not response\n\n    if up is not None:\n        cmd = 'ip link set dev {port} {state}'.format(\n            port=port, state='up' if up else 'down'\n        )\n        response = enode(cmd, shell=shell)\n        assert not response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_ip(enode, portlbl, addr, shell=None):\n    assert portlbl\n    assert ip_interface(addr)\n    port = enode.ports[portlbl]\n\n    cmd = 'ip addr del {addr} dev {port}'.format(addr=addr, port=port)\n    response = enode(cmd, shell=shell)\n    assert not response", "response": "Remove an IP address from an Engine Node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new static route to an Engine node.", "response": "def add_route(enode, route, via, shell=None):\n    \"\"\"\n    Add a new static route.\n\n    :param enode: Engine node to communicate with.\n    :type enode: topology.platforms.base.BaseNode\n    :param str route: Route to add, an IP in the form ``'192.168.20.20/24'``\n     or ``'2001::0/24'`` or ``'default'``.\n    :param str via: Via for the route as an IP in the form\n     ``'192.168.20.20/24'`` or ``'2001::0/24'``.\n    :param shell: Shell name to execute commands. If ``None``, use the Engine\n     Node default shell.\n    :type shell: str or None\n    \"\"\"\n    via = ip_address(via)\n\n    version = '-4'\n    if (via.version == 6) or \\\n            (route != 'default' and ip_network(route).version == 6):\n        version = '-6'\n\n    cmd = 'ip {version} route add {route} via {via}'.format(\n        version=version, route=route, via=via\n    )\n\n    response = enode(cmd, shell=shell)\n    assert not response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_link_type_vlan(enode, portlbl, name, vlan_id, shell=None):\n    assert name\n    if name in enode.ports:\n        raise ValueError('Port {name} already exists'.format(name=name))\n\n    assert portlbl\n    assert vlan_id\n    port = enode.ports[portlbl]\n\n    cmd = 'ip link add link {dev} name {name} type vlan id {vlan_id}'.format(\n        dev=port, name=name, vlan_id=vlan_id)\n\n    response = enode(cmd, shell=shell)\n    assert not response, 'Cannot add virtual link {name}'.format(name=name)\n\n    enode.ports[name] = name", "response": "Add a new virtual link with the type set to VLAN."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a virtual link with the specified name.", "response": "def remove_link_type_vlan(enode, name, shell=None):\n    \"\"\"\n    Delete a virtual link.\n\n    Deletes a vlan device with the name {name}.\n    Will raise an expection if the port is not already present.\n\n    :param enode: Engine node to communicate with.\n    :type enode: topology.platforms.base.BaseNode\n    :param str name: specifies the name of the new\n     virtual device.\n    :param str shell: Shell name to execute commands. If ``None``, use the\n     Engine Node default shell.\n    \"\"\"\n    assert name\n    if name not in enode.ports:\n        raise ValueError('Port {name} doesn\\'t exists'.format(name=name))\n\n    cmd = 'ip link del link dev {name}'.format(name=name)\n\n    response = enode(cmd, shell=shell)\n    assert not response, 'Cannot remove virtual link {name}'.format(name=name)\n\n    del enode.ports[name]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing the configured parameters and stats of an interface.", "response": "def show_interface(enode, dev, shell=None):\n    \"\"\"\n    Show the configured parameters and stats of an interface.\n\n    :param enode: Engine node to communicate with.\n    :type enode: topology.platforms.base.BaseNode\n    :param str dev: Unix network device name. Ex 1, 2, 3..\n    :rtype: dict\n    :return: A combined dictionary as returned by both\n     :func:`topology_lib_ip.parser._parse_ip_addr_show`\n     :func:`topology_lib_ip.parser._parse_ip_stats_link_show`\n    \"\"\"\n    assert dev\n\n    cmd = 'ip addr list dev {ldev}'.format(ldev=dev)\n    response = enode(cmd, shell=shell)\n\n    first_half_dict = _parse_ip_addr_show(response)\n\n    d = None\n    if (first_half_dict):\n        cmd = 'ip -s link list dev {ldev}'.format(ldev=dev)\n        response = enode(cmd, shell=shell)\n        second_half_dict = _parse_ip_stats_link_show(response)\n\n        d = first_half_dict.copy()\n        d.update(second_half_dict)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_mmd(target_folder=DEFAULT_LIBRARY_DIR):\n    mmd_dir = tempfile.mkdtemp()\n    mmd_repo = pygit2.clone_repository('https://github.com/jasedit/MultiMarkdown-5', mmd_dir,\n                                       checkout_branch='fix_windows')\n    mmd_repo.init_submodules()\n    mmd_repo.update_submodules()\n    build_dir = os.path.join(mmd_dir, 'build')\n    old_pwd = os.getcwd()\n    os.chdir(build_dir)\n\n    cmake_cmd = ['cmake', '-DCMAKE_BUILD_TYPE=Release', '-DSHAREDBUILD=1', '..']\n    if platform.system() == 'Windows':\n        is_64bit = platform.architecture()[0] == '64bit'\n        generator = 'Visual Studio 14 2015{0}'.format(' Win64' if is_64bit else '')\n        cmake_cmd.insert(-1, '-G')\n        cmake_cmd.insert(-1, '{0}'.format(generator))\n    subprocess.call(cmake_cmd)\n    PLATFORM_BUILDS[platform.system()]()\n\n    lib_file = 'libMultiMarkdown' + SHLIB_EXT[platform.system()]\n    if not os.path.exists(target_folder):\n        os.mkdir(target_folder)\n    src = os.path.join(build_dir, SHLIB_PREFIX[platform.system()], lib_file)\n    dest = os.path.join(target_folder, lib_file)\n    shutil.copyfile(src, dest)\n    os.chdir(old_pwd)\n    shutil.rmtree(mmd_dir, ignore_errors=True)", "response": "Build and install the MultiMarkdown shared library."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cli(ctx, amount, index, stage, deststage, stepresult, tostep, select, where, order, position):\n    if not ctx.bubble:\n        msg = 'There is no bubble present, will not promote'\n        ctx.say_yellow(msg)\n        raise click.Abort()\n\n    if stage not in STAGES:\n        ctx.say_yellow('There is no known stage:' + stage)\n        raise click.Abort()\n    if stepresult not in exportables:\n        ctx.say_yellow('stepresult not one of: ' + ', '.join(exportables))\n        raise click.Abort()\n    ctx.gbc.say('promote:args', stuff=(ctx, amount, index, stage,\n                                       deststage, stepresult, tostep, select, where, order, position))\n    data_gen = bubble_lod_load(ctx, stepresult, stage)\n\n    ctx.gbc.say('data_gen:', stuff=data_gen, verbosity=20)\n\n    part = get_gen_slice(ctx.gbc, data_gen, amount, index)\n    ctx.gbc.say('selected part:', stuff=part, verbosity=20)\n\n    aliases = get_pairs(ctx.gbc, select, missing_colon=True)\n    if position:\n        ctx.gbc.say('adding position to selection of columns:',\n                    stuff=aliases, verbosity=20)\n        aliases.insert(0, {'key': buts('index'), 'val': 'BUBBLE_IDX'})\n        ctx.gbc.say('added position to selection of columns:',\n                    stuff=aliases, verbosity=20)\n\n    wheres = get_pairs(ctx.gbc, where)\n    # TODO: use aliases as lookup for wheres\n\n    data = tablib.Dataset()\n\n    data.headers = [sel['val'] for sel in aliases]\n    ctx.gbc.say('select wheres:' + str(wheres), verbosity=20)\n    ctx.gbc.say('select aliases:' + str(aliases), verbosity=20)\n    ctx.gbc.say('select data.headers:' + str(data.headers), verbosity=20)\n\n    # TODO: get this selecting stuff into a shared function from export\n\n    try:\n        for ditem in part:\n            row = []\n            ctx.gbc.say('curr dict', stuff=ditem, verbosity=101)\n\n            flitem = flat(ctx, ditem)\n            ctx.gbc.say('curr flat dict', stuff=flitem, verbosity=101)\n            row_ok = True\n            for wp in wheres:\n                # TODO: negative selects: k:None, k:False,k:Zero,k:Null,k:0,k:-1,k:'',k:\"\",\n                # TODO: negative selects: k:BUBBLE_NO_KEY,k:BUBBLE_NO_VAL\n\n                if not wp['val'] in str(flitem[wp['key']]):\n                    row_ok = False\n            if not row_ok:\n                continue\n\n            for sel in aliases:\n                if sel['key'] in flitem:\n                    row.append(flitem[sel['key']])\n                else:\n                    # temporary to check, not use case for buts()\n                    bnp = '____BTS_NO_PATH_'\n                    tempv = get_flat_path(ctx, flitem, sel['key'] + '.*', bnp)\n                    if tempv != bnp:\n                        row.append(tempv)\n                    else:\n                        row.append('None')\n                        # TODO maybe 'NONE', or just '' or something like:\n                        # magic.export_format_none\n\n            data.append(row)\n\n    except Exception as excpt:\n        ctx.say_red('Cannot promote data', stuff=excpt)\n        raise click.Abort()\n\n    if order:\n        olast2 = order[-2:]\n        ctx.gbc.say('order:' + order + ' last2:' + olast2, verbosity=100)\n        if olast2 not in [':+', ':-']:\n            data = data.sort(order, False)\n        else:\n            if olast2 == ':+':\n                data = data.sort(order[:-2], False)\n            if olast2 == ':-':\n                data = data.sort(order[:-2], True)", "response": "Promote data from one stage to another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting up the global import environment variables by registering the sub-folders for projex as import locations. When defining your custom manager, you will want to overload this method to do any sort of global initialization that you wish before continuing. :warning This method is called by the _setup method, and should not be called directly.", "response": "def _setup():\n        \"\"\"\n        Sets up the global import environment variables by registering the\n        sub-folders for projex as import locations.  When defining your \n        custom manager, you will want to overload this method to do any\n        sort of global initialization that you wish before continuing.\n        \n        :warning    This method is called by the _setup method, and should \n                    not be called directly.\n        \"\"\"\n        projex_path = os.getenv('PROJEX_PATH')\n        if not projex_path:\n            return\n\n        base_path = os.path.dirname(__file__)\n\n        logger.debug('Loading PROJEX_PATH: %s' % projex_path)\n\n        # load the defaults from the install directory\n        # load the paths from the environment\n        paths = projex_path.split(os.path.pathsep)\n        paths += [\n            os.path.join(base_path, 'userplug'),\n            os.path.join(base_path, 'stdplug'),\n            os.path.join(base_path, 'lib'),\n        ]\n\n        sys.path = paths + sys.path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends the inputted path to sys. path variable if it does not already exist in the sys. path variable.", "response": "def appendPath(self, path):\n        \"\"\"\n        Appends the inputted path to the end of the sys.path variable,\n        provided the path does not already exist in it.\n        \n        :param      path\n        :type       str\n        \n        :return     bool: success\n        \"\"\"\n        # normalize the path\n        path = os.path.normcase(nstr(path)).strip()\n        if path and path != '.' and path not in sys.path:\n            sys.path.append(path)\n            self._addedpaths.append(path)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expandvars(self, text, environ=None, cache=None):\n        if not environ:\n            environ = os.environ\n\n        # make sure we have data\n        if not text:\n            return ''\n\n        # check for circular dependencies\n        cache = cache or {}\n\n        # return the cleaned variable\n        output = nstr(text)\n        keys = re.findall('\\$(\\w+)|\\${(\\w+)\\}|\\%(\\w+)\\%', text)\n\n        for first, second, third in keys:\n            repl = ''\n            key = ''\n            if first:\n                repl = '$%s' % first\n                key = first\n            elif second:\n                repl = '${%s}' % second\n                key = second\n            elif third:\n                repl = '%%%s%%' % third\n                key = third\n            else:\n                continue\n\n            value = environ.get(key)\n            if value:\n                if key not in cache:\n                    cache[key] = value\n                    value = self.expandvars(value, environ, cache)\n                else:\n                    err = '%s environ variable causes an infinite loop.' % key\n                    logger.warning(err)\n                    value = cache[key]\n            else:\n                value = repl\n\n            output = output.replace(repl, value)\n\n        return os.path.expanduser(output)", "response": "Recursively expands the text variables vs. the os. path \\\n            method which only works at one level."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npushes the inputted path at the front of the sys. path variable making it the first path python uses when importing a module.", "response": "def pushPath(self, path):\n        \"\"\"\n        Pushes the inputted path at the front of the sys.path variable, making\n        it the first path python uses when importing a module.\n        \n        :param      path\n        :type       str\n        \n        :return     bool: success\n        \"\"\"\n        # normalize the path\n        path = os.path.normcase(nstr(path)).strip()\n        if path and path != '.' and path not in sys.path:\n            sys.path.append(path)\n            self._addedpaths.insert(0, path)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requires(self, *modules):\n        self._setup()\n\n        for module in modules:\n            if '-' in module:\n                parts = module.split('-')\n                module = parts[0]\n                version = '-'.join(parts)\n            else:\n                version = ''\n\n            if module in self._loadedRequires:\n                continue\n\n            self._loadedRequires.append(module)\n            path_key = 'PROJEX_%s_PATH' % nstr(module).upper()\n            env_path = os.getenv(path_key)\n\n            logger.debug('Looking up %s: %s' % (path_key, env_path))\n\n            # push the path for the particular module if found in the env\n            if env_path:\n                self.pushPath(env_path)", "response": "Registers the system paths for the modules that can be imported properly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the name in the module dictionary with the inputted replace \\ value. :param module | <str> || <module> name | <str> repl | <variant> :return <bool>", "response": "def refactor(module, name, repl):\n        \"\"\"\n        Replaces the name in the module dictionary with the inputted replace \\\n        value.\n        \n        :param      module  | <str> || <module>\n                    name    | <str>\n                    repl    | <variant>\n        \n        :return     <bool>\n        \"\"\"\n        name = nstr(name)\n\n        # import a module when refactoring based on a string\n        if isinstance(module, basestring):\n            try:\n                module = __import__(module)\n            except ImportError:\n                logger.exception('Could not import module: %s' % module)\n                return False\n\n        try:\n            glbls = module.__dict__\n        except AttributeError:\n            err = '%s cannot support refactoring.' % module.__name__\n            logger.exception(err)\n            return False\n\n        if name in glbls:\n            # refactor the value\n            glbls[name] = repl\n\n            return True\n        else:\n            err = '%s is not a member of %s.' % (name, module.__name__)\n            logger.warning(err)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current environment manager for the projex system.", "response": "def current():\n        \"\"\"\n        Returns the current environment manager for the projex system.\n        \n        :return     <EnvManager>\n        \"\"\"\n        if not EnvManager._current:\n            path = os.environ.get('PROJEX_ENVMGR_PATH')\n            module = os.environ.get('PROJEX_ENVMGR_MODULE')\n            clsname = os.environ.get('PROJEX_ENVMGR_CLASS')\n            cls = EnvManager\n\n            if module and clsname:\n                # check if the user specified an import path\n                if path:\n                    logger.info('Adding env manager path: %s' % path)\n                    sys.path.insert(0, path)\n\n                logger.info('Loading env manager: %s.%s' % (module, clsname))\n\n                try:\n                    __import__(module)\n                    mod = sys.modules[module]\n                    cls = getattr(mod, clsname)\n\n                except ImportError:\n                    logger.error('Could not import env manager %s', module)\n\n                except KeyError:\n                    logger.error('Could not import env manager %s', module)\n\n                except AttributeError:\n                    msg = '%s is not a valid class of %s' % (clsname, module)\n                    logger.error(msg)\n\n            EnvManager._current = cls()\n        return EnvManager._current"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports the module located at the given filepath.", "response": "def fileImport(filepath, ignore=None):\n        \"\"\"\n        Imports the module located at the given filepath.\n        \n        :param      filepath    | <str>\n                    ignore      | [<str>, ..] || None\n        \n        :return     <module> || None\n        \"\"\"\n        basepath, package = EnvManager.packageSplit(filepath)\n        if not (basepath and package):\n            return None\n\n        # make sure this is not part of the ignored package list\n        if ignore and package in ignore:\n            return None\n\n        basepath = os.path.normcase(basepath)\n        if basepath not in sys.path:\n            sys.path.insert(0, basepath)\n\n        logger.debug('Importing: %s' % package)\n\n        try:\n            __import__(package)\n            module = sys.modules[package]\n        except ImportError:\n            logger.exception('ImportError: %s' % package)\n            return None\n        except KeyError:\n            logger.exception('Could not find sys.modules package: %s' % package)\n            return None\n        except StandardError:\n            logger.exception('Unknown error occurred not import %s' % package)\n            return None\n\n        return module"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the python path and package information for the inputted filepath.", "response": "def packageSplit(filepath):\n        \"\"\" \n        Determines the python path, and package information for the inputted\n        filepath.\n        \n        :param      filepath  |  <str>\n        \n        :return     (<str> path, <str> package)\n        \"\"\"\n        filepath = nstr(filepath).strip().strip('.')\n        if not filepath:\n            return '', ''\n\n        basepath, module = os.path.split(nstr(filepath))\n        module = os.path.splitext(module)[0]\n        pathsplit = os.path.normpath(basepath).split(os.path.sep)\n        packagesplit = []\n\n        if module and module != '__init__':\n            packagesplit.append(module)\n\n        testpath = os.path.sep.join(pathsplit + ['__init__.py'])\n        while os.path.exists(testpath):\n            packagesplit.insert(0, pathsplit[-1])\n            pathsplit = pathsplit[:-1]\n            testpath = os.path.sep.join(pathsplit + ['__init__.py'])\n\n        return os.path.sep.join(pathsplit), '.'.join(packagesplit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(keystorerc=None, keystore=None, files=[], verbose=False):\n  '''create a keystore, compress and encrypt to file'''\n\n  config = None\n  if keystorerc:\n    config = config_reader.read(keystorerc)\n    if not config:\n      print('No configuration found.', file=sys.stderr)\n      sys.exit(-1)\n  elif keystore and len(files) > 0:\n    config = {\n      'keystore': keystore,\n      'files': files\n    }\n\n  if 'verbose' in config and config['verbose']:\n    verbose = True\n\n  keystore_path = None\n  if 'keystore' not in config:\n    print('.keystorerc needs to specify a keystore file path.', file=sys.stderr)\n    sys.exit(-1)\n\n  keystore_path = os.path.expanduser(config['keystore'])\n  if os.path.isdir(keystore_path):\n    print('keystore cannot be a folder: {}'.format(config['keystore']), file=sys.stderr)\n    sys.exit(-1)\n  elif not os.path.isfile(keystore_path):\n    # If keystore file does not exist already, attempt to create one\n    try:\n      pathlib.Path(keystore_path).touch()\n    except OSError as err:\n      print('keystore cannot be accessed: {}\\n{}'.format(config['keystore'], err), file=sys.stderr)\n      sys.exit(-1)\n\n  # iterate through keys and add them here\n\n  keystore = {}\n  try:\n    for p in config['files']:\n\n      expanded_path = os.path.expanduser(p)\n      path = pathlib.Path(expanded_path)\n      if verbose: print('Inspecting {}:'.format(expanded_path))\n\n      if not path.exists():\n        print('Error: File or folder does not exist: {}'.format(p), file=sys.stderr)\n        sys.exit(-1)\n      if path.is_dir():\n        for dirpath, dirnames, filenames in os.walk(expanded_path):\n          for name in filenames:\n            fullpath = os.path.join(dirpath, name)\n            if verbose: print('Adding {} ...'.format(fullpath))\n            with open(fullpath, 'rb') as keyfile:\n              b64_bytes = base64.encodebytes(keyfile.read()).decode('utf-8')\n              keystore[fullpath] = b64_bytes\n      elif path.is_file():\n        fullpath = expanded_path\n        if verbose: print('Adding {} ...'.format(fullpath))\n        with open(fullpath, 'rb') as keyfile:\n          b64_bytes = base64.encodebytes(keyfile.read()).decode('utf-8')\n          keystore[fullpath] = b64_bytes\n\n    if verbose: print('Added {} key(s) to keystore.\\n'.format(len(keystore)))\n\n    # prompt user for a one-time passphase for encryption\n\n    do_passphrases_match = False\n    passphrase = None\n    print('This passphrase is used to decrypt your keystore. Please remember it.')\n    while not do_passphrases_match:\n      passphrase = getpass.getpass('Please enter a passphrase: ')\n      passphrase_verify = getpass.getpass('Please verify your passphrase: ')\n      do_passphrases_match = passphrase != '' and passphrase == passphrase_verify\n      if passphrase == '':\n        print('Passphrase cannot be empty.')\n      elif not do_passphrases_match:\n        print('Passphrases do not match. Please try again.')\n    if verbose: print('Passphrase accepted. Encrypting ...')\n\n    # serialise, compress, encrypt\n\n    serial_keystore = json.dumps(keystore)\n    compressed_keystore = gzip.compress(serial_keystore.encode('utf-8'))\n    try:\n      encrypted_keystore = simplecrypt.encrypt(passphrase, compressed_keystore)\n    except simplecrypt.EncryptionException as err:\n      print('You managed to bump into a very, very rare issue with AES.\\nPlease contact the author. {}'.format(err), file=sys.stder)\n      sys.exit(-1)\n\n    # save encrypted keystore to file\n    keystore_path = os.path.expanduser(keystore_path)\n    if verbose: print('Writing to keystore file {}'.format(keystore_path))\n\n    with open(keystore_path, 'wb') as keystore_file:\n      keystore_file.write(encrypted_keystore)\n\n    if verbose: print('Keystore successfully created: ')\n    # if verbose: print(encrypted_keystore)\n\n  except KeyError as err:\n    print('.keystorerc config is missing `files` attribute: {}'.format(err), file=sys.stderr)\n    sys.exit(-1)\n  except TypeError as err:\n    print('Error: {}'.format(err), file=sys.stderr)\n    traceback.print_exc()\n    sys.exit(-1)\n  except OSError as err:\n    print('The file system gave an error: {}'.format(err), file=sys.stderr)\n    sys.exit(-1)\n  except Exception as err:\n    print('Serious error. Please report this bug to the author: {}'.format(err), file=sys.stderr)\n    sys.exit(-1)", "response": "create a keystore compress and encrypt to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\njoins all parts with domain. Example domain is https://www. python. org", "response": "def join_all(self, *parts):\n        \"\"\"\n        Join all parts with domain. Example domain: https://www.python.org\n\n        :param parts: Other parts, example: \"/doc\", \"/py27\"\n        :return: url\n        \"\"\"\n        url = util.join_all(self.domain, *parts)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_params(self, endpoint, params):\n        assert endpoint.startswith(self.domain)\n        return util.add_params(endpoint, params)", "response": "Combine query endpoint and params."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate set of requirements files for the current user", "response": "def generate_requirements_files(self, base_dir='.'):\n        \"\"\" Generate set of requirements files for config \"\"\"\n\n        print(\"Creating requirements files\\n\")\n\n        # TODO How to deal with requirements that are not simple, e.g. a github url\n\n        shared = self._get_shared_section()\n\n        requirements_dir = self._make_requirements_directory(base_dir)\n\n        for section in self.config.sections():\n            if section == 'metadata':\n                continue\n\n            requirements = {}\n            for option in self.config.options(section):\n                requirements[option] = self.config.get(section, option)\n\n            if not requirements:\n                # No need to write out an empty file\n                continue\n\n            filename = os.path.join(requirements_dir, '%s.txt' % section)\n            self._write_requirements_file(shared, section, requirements, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the default rc file sections", "response": "def _write_default_sections(self):\n        \"\"\" Starting from scratch, so create a default rc file \"\"\"\n        self.config.add_section('metadata')\n        self.config.set('metadata', 'shared', 'common')\n        self.config.add_section('common')\n        self.config.add_section('development')\n        self.config.add_section('production')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_requirements(self, input):\n\n        results = []\n\n        for line in input:\n            (package, version) = self._parse_line(line)\n            if package:\n                results.append((package, version))\n\n        return tuple(results)", "response": "Parse a list of requirements specifications."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_rc_file(self, packages):\n\n        print(\"Creating rcfile '%s'\\n\" % self.rc_filename)\n\n        # TODO bug with == in config file\n\n        if not self.config.sections():\n            self._write_default_sections()\n\n        sections = {}\n        section_text = []\n        for i, section in enumerate(self.config.sections()):\n            if section == 'metadata':\n                continue\n            sections[i] = section\n            section_text.append('%s. %s' % (i, section))\n        section_text = ' / '.join(section_text)\n\n        self._remap_stdin()\n        package_names = set()\n        lines = packages.readlines()\n        requirements = self._parse_requirements(lines)\n        for (package, version) in requirements:\n            package_names.add(package)\n            section, configured_version = self._get_option(package)\n            # Package already exists in configuration\n            if section:\n                # If there is a configured version, update it. If not, leave it unversioned.\n                if configured_version:\n                    if configured_version != version:\n                        print(\"Updating '%s' version from '%s' to '%s'\"\n                              % (package, configured_version, version))\n                        self.config.set(section, package, version)\n                continue\n\n            section = self._get_section(package, sections, section_text)\n            self._set_option(section, package, version)\n\n        for section in self.config.sections():\n            if section == 'metadata':\n                continue\n            for option in self.config.options(section):\n                if option not in package_names:\n                    print(\"Removing package '%s'\" % option)\n                    self.config.remove_option(section, option)\n\n        rc_file = open(self.rc_filename, 'w+')\n        self.config.write(rc_file)\n        rc_file.close()", "response": "Create a set of requirements files for the current configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupgrade all specified packages to latest version", "response": "def upgrade_packages(self, packages):\n        \"\"\" Upgrade all specified packages to latest version \"\"\"\n\n        print(\"Upgrading packages\\n\")\n\n        package_list = []\n        requirements = self._parse_requirements(packages.readlines())\n        for (package, version) in requirements:\n            package_list.append(package)\n\n        if package_list:\n            args = [\n                \"pip\",\n                \"install\",\n                \"-U\",\n            ]\n            args.extend(package_list)\n            subprocess.check_call(args)\n        else:\n            print(\"No packages to upgrade\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all packages that are installed but missing from packages.", "response": "def determine_extra_packages(self, packages):\n        \"\"\" Return all packages that are installed, but missing from \"packages\".\n            Return value is a tuple of the package names \"\"\"\n\n        args = [\n            \"pip\",\n            \"freeze\",\n        ]\n        installed = subprocess.check_output(args, universal_newlines=True)\n\n        installed_list = set()\n        lines = installed.strip().split('\\n')\n        for (package, version) in self._parse_requirements(lines):\n            installed_list.add(package)\n\n        package_list = set()\n        for (package, version) in self._parse_requirements(packages.readlines()):\n            package_list.add(package)\n\n        removal_list = installed_list - package_list\n        return tuple(removal_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all packages missing from list", "response": "def remove_extra_packages(self, packages, dry_run=False):\n        \"\"\" Remove all packages missing from list \"\"\"\n\n        removal_list = self.determine_extra_packages(packages)\n        if not removal_list:\n            print(\"No packages to be removed\")\n        else:\n            if dry_run:\n                print(\"The following packages would be removed:\\n    %s\\n\" %\n                      \"\\n    \".join(removal_list))\n            else:\n                print(\"Removing packages\\n\")\n                args = [\n                    \"pip\",\n                    \"uninstall\",\n                    \"-y\",\n                ]\n                args.extend(list(removal_list))\n                subprocess.check_call(args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating over self. obj list extracting selector from each element.", "response": "def _filtered_list(self, selector):\n        \"\"\"Iterate over `self.obj` list, extracting `selector` from each\n        element. The `selector` can be a simple integer index, or any valid\n        key (hashable object).\n        \"\"\"\n        res = []\n        for elem in self.obj:\n            self._append(elem, selector, res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts all values from an object.", "response": "def _extract_from_object(self, selector):\n        \"\"\"Extracts all values from `self.obj` object addressed with a `selector`.\n        Selector can be a ``slice``, or a singular value extractor in form of a\n        valid dictionary key (hashable object).\n        \n        Object (operated on) can be anything with an itemgetter or attrgetter,\n        including, but limited to `dict`, and `list`.\n        Itemgetter is preferred over attrgetter, except when called as `.key`.\n        \n        If `selector` is a singular value extractor (like a string, integer,\n        etc), a single value (for a given key) is returned if key exists, an\n        empty list if not.\n        \n        If `selector` is a ``slice``, each key from that range is extracted;\n        failing-back, again, to an empty list.\n        \"\"\"\n        if isinstance(selector, slice):\n            # we must expand the slice manually, in order to be able to apply to\n            # for example, to mapping types, or general objects\n            # (e.g. slice `4::2` will filter all even numerical keys/attrs >=4)\n            start = selector.start or 0\n            step = selector.step or 1\n            if selector.stop is None:\n                if hasattr(self.obj, \"keys\"):\n                    # filter keys by slice\n                    keys = \\\n                        [k for k in self.obj.keys() if isinstance(k, baseinteger) \\\n                            and k >= start and (k - start) % step == 0]\n                elif hasattr(self.obj, \"__len__\"):\n                    # object we slice should have a length (__len__ method),\n                    keys = xrange(start, len(self.obj), step)\n                else:\n                    # otherwise, we don't know how to slice, so just skip it,\n                    # instead of failing\n                    keys = []\n            else:\n                keys = xrange(start, selector.stop, step)\n\n        else:\n            keys = [selector]\n        \n        res = []\n        for key in keys:\n            self._append(self.obj, key, res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator over the key - value pairs in the current dictionary.", "response": "def items(self):\n        \"\"\"Behave like `dict.items` for mapping types (iterator over (key, value)\n        pairs), and like `iter` for sequence types (iterator over values).\n        \"\"\"\n        if self.empty:\n            return iter([])\n\n        val = self.value\n        if hasattr(val, \"iteritems\"):\n            return val.iteritems()\n        elif hasattr(val, \"items\"):\n            return val.items()\n        else:\n            return iter(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forceutc(t: Union[str, datetime.datetime, datetime.date, np.datetime64]) -> Union[datetime.datetime, datetime.date]:\n    # need to passthrough None for simpler external logic.\n# %% polymorph to datetime\n    if isinstance(t, str):\n        t = parse(t)\n    elif isinstance(t, np.datetime64):\n        t = t.astype(datetime.datetime)\n    elif isinstance(t, datetime.datetime):\n        pass\n    elif isinstance(t, datetime.date):\n        return t\n    elif isinstance(t, (np.ndarray, list, tuple)):\n        return np.asarray([forceutc(T) for T in t])\n    else:\n        raise TypeError('datetime only input')\n# %% enforce UTC on datetime\n    if t.tzinfo is None:  # datetime-naive\n        t = t.replace(tzinfo=UTC)\n    else:  # datetime-aware\n        t = t.astimezone(UTC)  # changes timezone, preserving absolute time. E.g. noon EST = 5PM UTC\n\n    return t", "response": "converts datetime to UTC"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_assert_failed_print_details(actual, expected):\n    try:\n        yield\n    except AssertionError:\n        # diff = difflib.unified_diff(expected.splitlines(), actual.splitlines(),\n        #                            \"expected\", \"actual\")\n        diff = difflib.ndiff(expected.splitlines(), actual.splitlines())\n        diff_text = u\"\\n\".join(diff)\n        print(u\"DIFF (+ ACTUAL, - EXPECTED):\\n{0}\\n\".format(diff_text))\n        if DEBUG:\n            print(u\"expected:\\n{0}\\n\".format(expected))\n            print(u\"actual:\\n{0}\\n\".format(actual))\n        raise", "response": "Print text details in case of assertation failed errors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_error_print_details(actual, expected):\n    try:\n        yield\n    except Exception:\n        diff = difflib.ndiff(expected.splitlines(), actual.splitlines())\n        diff_text = u\"\\n\".join(diff)\n        print(u\"DIFF (+ ACTUAL, - EXPECTED):\\n{0}\\n\".format(diff_text))\n        if DEBUG:\n            print(u\"expected:\\n{0}\\n\".format(expected))\n            print(u\"actual:\\n{0}\".format(actual))\n        raise", "response": "Print text details in case of assertation failed errors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new empty working directory and removes it from the working directory.", "response": "def step_a_new_working_directory(context):\n    \"\"\"\n    Creates a new, empty working directory\n    \"\"\"\n    command_util.ensure_context_attribute_exists(context, \"workdir\", None)\n    command_util.ensure_workdir_exists(context)\n    shutil.rmtree(context.workdir, ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef step_use_curdir_as_working_directory(context):\n    context.workdir = os.path.abspath(\".\")\n    command_util.ensure_workdir_exists(context)", "response": "Uses the current working directory as working directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step_a_file_named_filename_and_encoding_with(context, filename, encoding):\n    __encoding_is_valid = True\n    assert context.text is not None, \"ENSURE: multiline text is provided.\"\n    assert not os.path.isabs(filename)\n    assert __encoding_is_valid\n    command_util.ensure_workdir_exists(context)\n    filename2 = os.path.join(context.workdir, filename)\n    pathutil.create_textfile_with_contents(filename2, context.text, encoding)", "response": "Creates a textual file with the content provided as docstring."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step_a_file_named_filename_with(context, filename):\n    step_a_file_named_filename_and_encoding_with(context, filename, \"UTF-8\")\n\n    # -- SPECIAL CASE: For usage with behave steps.\n    if filename.endswith(\".feature\"):\n        command_util.ensure_context_attribute_exists(context, \"features\", [])\n        context.features.append(filename)", "response": "Creates a textual file with the content provided as docstring."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an empty file.", "response": "def step_an_empty_file_named_filename(context, filename):\n    \"\"\"\n    Creates an empty file.\n    \"\"\"\n    assert not os.path.isabs(filename)\n    command_util.ensure_workdir_exists(context)\n    filename2 = os.path.join(context.workdir, filename)\n    pathutil.create_textfile_with_contents(filename2, \"\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a command as subprocess collect its output and returncode.", "response": "def step_i_run_command(context, command):\n    \"\"\"\n    Run a command as subprocess, collect its output and returncode.\n    \"\"\"\n    command_util.ensure_workdir_exists(context)\n    context.command_result = command_shell.run(command, cwd=context.workdir)\n    command_util.workdir_save_coverage_files(context.workdir)\n    if False and DEBUG:\n        print(u\"run_command: {0}\".format(command))\n        print(u\"run_command.output {0}\".format(context.command_result.output))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step_it_should_pass_with(context):\n    '''\n    EXAMPLE:\n        ...\n        when I run \"behave ...\"\n        then it should pass with:\n            \"\"\"\n            TEXT\n            \"\"\"\n    '''\n    assert context.text is not None, \"ENSURE: multiline text is provided.\"\n    step_command_output_should_contain(context)\n    assert_that(context.command_result.returncode, equal_to(0),\n                context.command_result.output)", "response": "Test that the command output of the command is contained in the multiline text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef step_it_should_fail_with(context):\n    '''\n    EXAMPLE:\n        ...\n        when I run \"behave ...\"\n        then it should fail with:\n            \"\"\"\n            TEXT\n            \"\"\"\n    '''\n    assert context.text is not None, \"ENSURE: multiline text is provided.\"\n    step_command_output_should_contain(context)\n    assert_that(context.command_result.returncode, is_not(equal_to(0)))", "response": "Test that the step it should fail with the given context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step_command_output_should_contain_text(context, text):\n    '''\n    EXAMPLE:\n        ...\n        Then the command output should contain \"TEXT\"\n    '''\n    expected_text = text\n    if \"{__WORKDIR__}\" in expected_text or \"{__CWD__}\" in expected_text:\n        expected_text = textutil.template_substitute(text,\n             __WORKDIR__ = posixpath_normpath(context.workdir),\n             __CWD__     = posixpath_normpath(os.getcwd())\n        )\n    actual_output = context.command_result.output\n    with on_assert_failed_print_details(actual_output, expected_text):\n        textutil.assert_normtext_should_contain(actual_output, expected_text)", "response": "Check that the command output contains the given text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef step_command_output_should_not_contain_text(context, text):\n    '''\n    EXAMPLE:\n        ...\n        then the command output should not contain \"TEXT\"\n    '''\n    expected_text = text\n    if \"{__WORKDIR__}\" in text or \"{__CWD__}\" in text:\n        expected_text = textutil.template_substitute(text,\n             __WORKDIR__ = posixpath_normpath(context.workdir),\n             __CWD__     = posixpath_normpath(os.getcwd())\n        )\n    actual_output  = context.command_result.output\n    with on_assert_failed_print_details(actual_output, expected_text):\n        textutil.assert_normtext_should_not_contain(actual_output, expected_text)", "response": "The command output should not contain the given text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef step_command_output_should_contain_exactly_text(context, text):\n    expected_text = text\n    if \"{__WORKDIR__}\" in text or \"{__CWD__}\" in text:\n        expected_text = textutil.template_substitute(text,\n             __WORKDIR__ = posixpath_normpath(context.workdir),\n             __CWD__     = posixpath_normpath(os.getcwd())\n        )\n    actual_output  = context.command_result.output\n    textutil.assert_text_should_contain_exactly(actual_output, expected_text)", "response": "Verifies that the command output of the last command contains the expected text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile(self, prog, features=Features.ALL):\n        return LPProg(Parser(Tokenizer(prog, features), features).program(), features)", "response": "This function returns an interpreter that compiles the given program and returns a new LPProg object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cprint(self, cstr):\n        cstr = str(cstr)  # Force it to be a string\n        cstr_len = len(cstr)\n        prev_cstr_len = len(self._prev_cstr)\n        num_spaces = 0\n        if cstr_len < prev_cstr_len:\n            num_spaces = abs(prev_cstr_len - cstr_len)\n        try:\n            print(cstr + \" \" * num_spaces, end='\\r')\n            self._prev_cstr = cstr\n        except UnicodeEncodeError:\n            print('Processing...', end='\\r')\n            self._prev_cstr = 'Processing...'", "response": "Print the current line of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the SQL for all new models.", "response": "def get_sql_for_new_models(apps=None, using=DEFAULT_DB_ALIAS):\n    \"\"\"\n    Unashamedly copied and tweaked from django.core.management.commands.syncdb\n    \"\"\"\n    connection = connections[using]\n    \n    # Get a list of already installed *models* so that references work right.\n    tables = connection.introspection.table_names()\n    seen_models = connection.introspection.installed_models(tables)\n    created_models = set()\n    pending_references = {}\n    \n    if apps:\n        apps = [models.get_app(a) for a in apps]\n    else:\n        apps = models.get_apps()\n    \n    # Build the manifest of apps and models that are to be synchronized\n    all_models = [\n        (app.__name__.split('.')[-2], [\n            m\n            for m in models.get_models(app, include_auto_created=True)\n            if router.allow_syncdb(using, m)\n        ])\n        for app in apps\n    ]\n    \n    def model_installed(model):\n        opts = model._meta\n        converter = connection.introspection.table_name_converter\n        db_table_in = (converter(opts.db_table) in tables)\n        auto_create_in = (\n            opts.auto_created and\n            converter(opts.auto_created._meta.db_table) in tables\n        )\n        return not (db_table_in or auto_create_in)\n    \n    manifest = SortedDict(\n        (app_name, filter(model_installed, model_list))\n        for app_name, model_list in all_models\n    )\n    \n    statements = []\n    sql = None\n    for app_name, model_list in manifest.items():\n        for model in model_list:\n            # Create the model's database table, if it doesn't already exist.\n            sql, references = connection.creation.sql_create_model(\n                model,\n                no_style(),\n                seen_models\n            )\n            \n            seen_models.add(model)\n            created_models.add(model)\n            statements.append(\"### New Model: %s.%s\" % (\n                app_name,\n                str(model).replace(\"'>\", \"\").split(\".\")[-1]\n            ))\n            \n            for refto, refs in references.items():\n                pending_references.setdefault(refto, []).extend(refs)\n                if refto in seen_models:\n                    sql.extend(\n                        connection.creation.sql_for_pending_references(\n                            refto,\n                            no_style(),\n                            pending_references\n                        )\n                    )\n            \n            sql.extend(\n                connection.creation.sql_for_pending_references(\n                    model,\n                    no_style(),\n                    pending_references\n                )\n            )\n            statements.extend(sql)\n    \n    custom_sql = None\n    for app_name, model_list in manifest.items():\n        for model in model_list:\n            if model in created_models:\n                custom_sql = custom_sql_for_model(\n                    model,\n                    no_style(),\n                    connection\n                )\n                \n                if custom_sql:\n                    statements.extend(custom_sql)\n    \n    index_sql = None\n    for app_name, model_list in manifest.items():\n        for model in model_list:\n            if model in created_models:\n                index_sql = connection.creation.sql_indexes_for_model(\n                    model,\n                    no_style()\n                )\n                \n                if index_sql:\n                    statements.extend(index_sql)\n    \n    return statements"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_applied_migrations(databases=None):\n    if not databases:\n        databases = get_capable_databases()\n    else:\n        # We only loop through databases that are listed as \"capable\"\n        all_databases = list(get_capable_databases())\n        databases = list(\n            itertools.ifilter(lambda x: x in all_databases, databases)\n        )\n    \n    results = defaultdict(list)\n    for db in databases:\n        for x in Migration.objects.using(db).order_by(\"migration_label\"):\n            results[db].append(x.migration_label)\n    \n    return results", "response": "Returns a dictionary containing lists of all applied migrations."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_migrations(path, databases=None):\n    # database: [(number, full_path)]\n    possible_migrations = defaultdict(list)\n    \n    try:\n        in_directory = sorted(get_file_list(path))\n    except OSError:\n        import traceback\n        print \"An error occurred while reading migrations from %r:\" % path\n        traceback.print_exc()\n        return {}\n    \n    # Iterate through our results and discover which migrations are\n    # actually runnable\n    for full_path in in_directory:\n        child_path, script = os.path.split(full_path)\n        name, ext = os.path.splitext(script)\n        \n        # the database component is default if this is in the root directory\n        # is <directory> if in a subdirectory\n        if path == child_path:\n            db = DEFAULT_DB_ALIAS\n        else:\n            db = os.path.split(child_path)[-1]\n        \n        # filter by database if set\n        if databases and db not in databases:\n            continue\n        \n        match = MIGRATION_NAME_RE.match(name)\n        if match is None:\n            raise MigrationError(\"Invalid migration file prefix %r \"\n                                 \"(must begin with a number)\" % name)\n        \n        number = int(match.group(1))\n        if ext in [\".sql\", \".py\"]:\n            possible_migrations[db].append((number, full_path))\n    \n    return possible_migrations", "response": "Returns a dictionary of database - > migrations contained in path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary of database => [ migrations ] representing all pending migrations.", "response": "def get_pending_migrations(path, databases=None, stop_at=None):\n    \"\"\"\n    Returns a dictionary of database => [migrations] representing all pending\n    migrations.\n    \"\"\"\n    if stop_at is None:\n        stop_at = float(\"inf\")\n    \n    # database: [(number, full_path)]\n    possible_migrations = get_all_migrations(path, databases)\n    # database: [full_path]\n    applied_migrations = get_applied_migrations(databases)\n    # database: [full_path]\n    to_execute = defaultdict(list)\n    \n    for database, scripts in possible_migrations.iteritems():\n        applied = applied_migrations[database]\n        pending = to_execute[database]\n        for number, migration in scripts:\n            path, script = os.path.split(migration)\n            if script not in applied and number <= stop_at:\n                pending.append(script)\n    \n    return dict((k, v) for k, v in to_execute.iteritems() if v)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updateFgiAnnotationFromFi(fgiContainer, fiContainer, largerBetter):\n    for fgi in listvalues(fgiContainer.container):\n        annotations = list()\n        for specfile, fiId in zip(fgi.specfiles, fgi.featureIds):\n            fi = fiContainer.getItem(specfile, fiId)\n            if not fi.isAnnotated:\n                continue\n            annotations.append([fi.score, fi.peptide, fi.sequence])\n        annotations.sort(reverse=largerBetter)\n        if len(annotations) > 0:\n            fgi.isAnnotated = True\n            fgi.score = annotations[0][0]\n            fgi.peptide = annotations[0][1]\n            fgi.sequence = annotations[0][2]\n        else:\n            fgi.isAnnotated = False", "response": "Update the fgi. annotation field of the fgiContainer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getContGroupArrays(arrays, groupPositions, arrayKeys=None):\n    if arrayKeys is None:\n        arrayKeys = list(viewkeys(arrays))\n    matchingArrays = dict()\n    for key in arrayKeys:\n        matchingArrays[key] = arrays[key][groupPositions]\n    return matchingArrays", "response": "Convinience function to generate a subset of arrays from specified group positions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calcDistMatchArr(matchArr, tKey, mKey):\n    #Calculate all sorted list of all eucledian feature distances\n    matchArrSize = listvalues(matchArr)[0].size\n\n    distInfo = {'posPairs': list(), 'eucDist': list()}\n    _matrix = numpy.swapaxes(numpy.array([matchArr[tKey], matchArr[mKey]]), 0, 1)\n\n    for pos1 in range(matchArrSize-1):\n        for pos2 in range(pos1+1, matchArrSize):\n            distInfo['posPairs'].append((pos1, pos2))\n    distInfo['posPairs'] = numpy.array(distInfo['posPairs'])\n    distInfo['eucDist'] = scipy.spatial.distance.pdist(_matrix)\n\n    distSort = numpy.argsort(distInfo['eucDist'])\n    for key in list(viewkeys(distInfo)):\n        distInfo[key] = distInfo[key][distSort]\n\n    return distInfo", "response": "Calculates the euclidean distance of all positions in a dictionary containing at least two unique elements in the matchArr."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef proximityGrouping(matchArr, distInfo, distLimit, categoryKey):\n    #Group fi according to their proximity\n    matchArrSize = listvalues(matchArr)[0].size\n\n    linkageGroups = {p: [p] for p in range(matchArrSize)}\n    posToGroup = {p: p for p in range(matchArrSize)}\n    groupCategories = {p: set([s]) for p, s in zip(range(matchArrSize),\n                                                  matchArr[categoryKey]\n                                                  )\n                      }\n    for (pos1, pos2), dist in zip(distInfo['posPairs'], distInfo['eucDist']):\n        if dist > distLimit:\n            break\n\n        id1 = posToGroup[pos1]\n        id2 = posToGroup[pos2]\n        if groupCategories[id1].intersection(groupCategories[id2]):\n            continue\n\n        linkageGroups[id1].extend(linkageGroups[id2])\n        groupCategories[id1].update(groupCategories[id2])\n        for _pos in linkageGroups[id2]:\n            posToGroup[_pos] = id1\n        del linkageGroups[id2]\n        del groupCategories[id2]\n\n    return linkageGroups", "response": "Return a list of unique linkage ids that can be proximity grouped by distance value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a Fgi object from a LinkageGroup object.", "response": "def fiGroupFromLinkageGroup(matchArr, arrPos, groupId, timeKey, massKey):\n    \"\"\" #TODO: docstring\n    \"\"\"\n    fgi = Fgi(groupId)\n    matchArr['isAnnotated'][arrPos]\n\n    minT = numpy.min(matchArr[timeKey][arrPos])\n    maxT = numpy.max(matchArr[timeKey][arrPos])\n    minM = numpy.min(matchArr[massKey][arrPos])\n    maxM = numpy.max(matchArr[massKey][arrPos])\n\n    fgi.isValid = True\n    fgi.specfiles = matchArr['specfile'][arrPos].tolist()\n    fgi.featureIds = matchArr['id'][arrPos].tolist()\n    fgi.isAnnotated = numpy.any(matchArr['isAnnotated'][arrPos])\n    fgi.coordinates = ((minT, maxT), (minM, maxM))\n    #fgi.clusterType = clusterType\n\n    return fgi"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates feature groups from the linked features.", "response": "def generateFeatureGroups(fgiContainer, linkageGroups, matchArr, timeKey,\n                          massKey, logMassKey, massScalingFactor):\n    \"\"\" #TODO: docstring\n\n    :param fgiContainer:\n    :param linkageGroups:\n\n    :returns: a list of ids of the newly generated :class:`Fgi`\n    \"\"\"\n    #Generate feature groups from the linked features\n    newFgiIds = list()\n    for linkageGroup in viewvalues(linkageGroups):\n        fgiId = fgiContainer._getNextFgiId()\n        fgi = fiGroupFromLinkageGroup(matchArr, linkageGroup, fgiId,\n                                      timeKey, massKey\n                                      )\n        fgiContainer.container[fgiId] = fgi\n        fgi.metrics = clusterMetrics(matchArr[timeKey][linkageGroup],\n                                     matchArr[logMassKey][linkageGroup],\n                                     massScalingFactor=massScalingFactor\n                                     )\n        fgi.rt = fgi.metrics['meanTime']\n        fgi.mz = fgi.metrics['meanMass']\n        newFgiIds.append(fgiId)\n    return newFgiIds"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clusterMetrics(timeValues, massValues, massScalingFactor=1):\n    metrics = dict()\n    metrics['meanTime'] = numpy.mean(timeValues)\n    metrics['meanMass'] = numpy.mean(massValues)\n    metrics['devTime'] = timeValues - metrics['meanTime']\n    metrics['devMass'] = massValues - metrics['meanMass']\n    #metrics['devMass'] = (1-metrics['meanMass']/massValues)\n    metrics['spreadTime'] = numpy.max(timeValues) - numpy.min(timeValues)\n    metrics['spreadMass'] = numpy.max(massValues) - numpy.min(massValues)\n    #metrics['spreadMass'] = (1-numpy.min(massValues) / numpy.max(massValues))\n    metrics['devEuc'] = numpy.sqrt(numpy.power(metrics['devTime'], 2) +\n                                   numpy.power(metrics['devMass']*massScalingFactor, 2)\n                                   )\n    metrics['meanEuc'] = numpy.mean(metrics['devEuc'])\n    metrics['devTime'] = metrics['devTime'].tolist()\n    metrics['devMass'] = metrics['devMass'].tolist()\n    metrics['devEuc'] = metrics['devEuc'].tolist()\n    return metrics", "response": "This function calculates the cluster metrics for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the items of the current container.", "response": "def getItems(self, sort=False, reverse=False,  selector=None):\n        \"\"\" #TODO: docstring\n        \"\"\"\n        selector = (lambda fgi: fgi.isValid) if selector is None else selector\n        _container = {'_': self.container}\n        return _getItems(_container, '_', sort, reverse, selector)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting the specified fgic file from the hard disk.", "response": "def load(self, path, name):\n        \"\"\"Imports the specified ``fgic`` file from the hard disk.\n\n        :param path: filedirectory to which the ``fgic`` file is written.\n        :param name: filename, without file extension\n        \"\"\"\n\n        filename = name + '.fgic'\n        filepath = aux.joinpath(path, filename)\n        with zipfile.ZipFile(filepath, 'r') as containerZip:\n            #Convert the zipfile data into a str object, necessary since\n            #containerZip.read() returns a bytes object.\n            jsonString = io.TextIOWrapper(containerZip.open('data'),\n                                          encoding='utf-8'\n                                          ).read()\n            infoString = io.TextIOWrapper(containerZip.open('info'),\n                                          encoding='utf-8'\n                                          ).read()\n        self.container = json.loads(jsonString, object_hook=Fgi.jsonHook)\n        self.info.update(json.loads(infoString))\n        self._matrixTemplate = self.info['_matrixTemplate']\n        del self.info['_matrixTemplate']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateIntensities(self, fiContainer, iKey='intensity'):\n        for fgi in listvalues(self.container):\n            intensities = list()\n            specfileIds = {i: j for i, j in zip(fgi.specfiles, fgi.featureIds)}\n            for specfile in self._matrixTemplate:\n                if specfile in specfileIds:\n                    fi = fiContainer.getItem(specfile, specfileIds[specfile])\n                    intensities.append(getattr(fi, iKey))\n                else:\n                    intensities.append(None)\n            fgi.intensities = intensities", "response": "Update the intensity of all feature objects in the specified container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the first command that matches the given arguments.", "response": "def command(argv, scope):\n    \"\"\"\n    Looks up a particular command from the inputted arguments for the given \\\n    scope.\n    \n    :param      argv    | [<str>, ..]\n                scope   | <dict>\n    \n    :return     <climethod> || None\n    \"\"\"\n    if inspect.ismodule(scope):\n        scope = vars(scope)\n\n    for cmd in scope.values():\n        if not isinstance(cmd, climethod):\n            continue\n\n        if cmd.__name__ in argv:\n            return cmd\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all commands in the inputted scope.", "response": "def commands(scope):\n    \"\"\"\n    Looks up all climethod instances from the inputted scope.\n    \n    :return     [<climethod>, ..]\n    \"\"\"\n    if inspect.ismodule(scope):\n        scope = vars(scope)\n\n    return [cmd for cmd in scope.values() if isinstance(cmd, climethod)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a new interface from the inputted module.", "response": "def generate(module):\n    \"\"\"\n    Generates a new interface from the inputted module.\n    \n    :param      module | <module>\n    \n    :return     <Interface>\n    \"\"\"\n    inter = Interface(PROGRAM_NAME)\n    inter.register(module, True)\n    return inter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parser(scope, usage=''):\n    subcmds = []\n    for cmd in commands(scope):\n        subcmds.append(cmd.usage())\n\n    if subcmds:\n        subcmds.sort()\n        usage += '\\n\\nSub-Commands:\\n  '\n        usage += '\\n  '.join(subcmds)\n\n    parse = PARSER_CLASS(usage=usage)\n    parse.prog = PROGRAM_NAME\n    return parse", "response": "Generates a default parser for the inputted scope."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing any commands within the scope that match the inputted arguments.", "response": "def process(argv, scope, interface=None):\n    \"\"\"\n    Processes any commands within the scope that matches the inputted arguments.\n    If a subcommand is found, then it is run, and the system exists with the \n    return value from the command.\n    \n    :param      argv    | [<str>, ..]\n                scope   | <dict>\n    \n    :return     (<dict> options, <tuple> arguments)\n    \"\"\"\n    cmd = command(argv, scope)\n    if cmd:\n        sys.exit(cmd.run(argv))\n\n    name = PROGRAM_NAME\n    if interface:\n        name = interface.name()\n\n    _parser = parser(scope, '{0} [options] [<subcommand>] [<arg>]'.format(name))\n    options, args = _parser.parse_args(argv)\n    return options.__dict__, args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef usage(self):\n        arg_list = ' '.join(self.cmd_args).upper()\n        name = self.interface.name()\n        return '%s [options] %s %s' % (name, self.__name__, arg_list)", "response": "Returns the usage string for this method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parser(self):\n        usage = self.usage()\n        if self.__doc__:\n            usage += '\\n' + nstr(self.__doc__)\n\n        parse = PARSER_CLASS(usage=usage)\n\n        shorts = {v: k for k, v in self.short_keys.items()}\n        for key, default in self.cmd_opts.items():\n            # default key, cannot be duplicated\n            if key == 'help':\n                continue\n\n            try:\n                short = '-' + shorts[key]\n            except KeyError:\n                short = ''\n\n            if default is True:\n                action = 'store_false'\n            elif default is False:\n                action = 'store_true'\n            else:\n                action = 'store'\n\n            # add the option\n            parse.add_option(short, '--%s' % key, action=action, default=default)\n\n        return parse", "response": "Creates a parser for the method based on the documentation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, argv):\n        (opts, args) = self.parser().parse_args(argv)\n        func_args = args[args.index(self.__name__) + 1:]\n        func_kwds = opts.__dict__\n\n        return self.__call__(*func_args, **func_kwds)", "response": "Parses the inputted options and executes the method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self, obj, autogenerate=False):\n        scope = self._scope\n\n        # register a module\n        if type(obj).__name__ == 'module':\n            for key, value in vars(obj).items():\n                # register a climethod\n                if isinstance(value, climethod):\n                    value.interface = self\n                    scope[key] = value\n\n                # register a function\n                elif inspect.isfunction(value) and autogenerate:\n                    meth = climethod(value)\n                    meth.interface = self\n                    scope[key] = meth\n\n        # register a climethod\n        elif isinstance(obj, climethod):\n            obj.interface = self\n            scope[obj.__name__] = obj\n\n        # register a function\n        elif inspect.isfunction(obj) and autogenerate:\n            meth = climethod(obj)\n            meth.interface = self\n            scope[meth.__name__] = meth", "response": "Registers the inputted object to this scope."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncloning an existing bare repository to a new bare repository.", "response": "def clone(cls, srcpath, destpath, encoding='utf-8'):\n        \"\"\"Clone an existing repository to a new bare repository.\"\"\"\n        cmd = [GIT, 'clone', '--quiet', '--bare', srcpath, destpath]\n        subprocess.check_call(cmd)\n        return cls(destpath, encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(cls, path, encoding='utf-8'):\n        cmd = [GIT, 'init', '--quiet', '--bare', path]\n        subprocess.check_call(cmd)\n        return cls(path, encoding)", "response": "Create a new bare repository"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_as_dict(self):\n        def convert(val):\n            if isinstance(val, tuple):\n                return tuple(convert(v) for v in val)\n            elif isinstance(val, list):\n                return [convert(v) for v in val]\n            elif isinstance(val, (dict, ElasticDict)):\n                return {k: convert(v) for k, v in val.iteritems()}\n            else:\n                return val\n\n        return convert(self.__dict__)", "response": "u Returns self as ordinary dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_from(value):\n        def convert(val):\n            if isinstance(val, tuple):\n                return tuple(convert(v) for v in val)\n            elif isinstance(val, list):\n                return [convert(v) for v in val]\n            elif isinstance(val, (dict, ElasticDict)):\n                return ElasticDict({k: convert(v) for k, v in val.iteritems()})\n            else:\n                return val\n\n        return convert(value)", "response": "u Create an instance of ElasticDict where all nested dict()'s are replaced to ElasticDict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cache(self, dependency: Dependency, value):\n        if dependency.threadlocal:\n            setattr(self._local, dependency.name, value)\n        elif dependency.singleton:\n            self._singleton[dependency.name] = value", "response": "Stores an instance of dependency in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cached(self, dependency):\n        if dependency.threadlocal:\n            return getattr(self._local, dependency.name, None)\n        elif dependency.singleton:\n            return self._singleton.get(dependency.name)", "response": "Get a cached instance of the given dependency."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set(self, name, factory, singleton=False, threadlocal=False):\n        name = name or factory.__name__\n        factory._giveme_registered_name = name\n        dep = Dependency(name, factory, singleton, threadlocal)\n        self._registry[name] = dep", "response": "Add a dependency factory to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, name: str):\n        dep = None\n        try:\n            dep = self._registry[name]\n        except KeyError:\n            raise DependencyNotFoundError(name) from None\n        value = self.cached(dep)\n        if value is None:\n            value = dep.factory()\n            self.cache(dep, value)\n        return value", "response": "Get an instance of dependency with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an object to the injector's registry. Can be used as a decorator like so: >>> @injector.register ... def my_dependency(): ... or a plain function call by passing in a callable injector.register(my_dependency) :param function: The function or callable to add to the registry :param name: Set the name of the dependency. Defaults to the name of `function` :param singleton: When True, register dependency as a singleton, this means that `function` is called on first use and its return value cached for subsequent uses. Defaults to False :param threadlocal: When True, register dependency as a threadlocal singleton, Same functionality as ``singleton`` except :class:`Threading.local` is used to cache return values. :type function: callable :type singleton: bool :type threadlocal: bool :type name: string", "response": "def register(self, function=None, *, singleton=False, threadlocal=False, name=None):\n        \"\"\"\n        Add an object to the injector's registry.\n\n        Can be used as a decorator like so:\n        \n        >>> @injector.register\n        ... def my_dependency(): ...\n\n        or a plain function call by passing in a callable\n        injector.register(my_dependency)\n\n        :param function: The function or callable to add to the registry\n        :param name: Set the name of the dependency. Defaults to the name of `function`\n        :param singleton: When True, register dependency as a singleton, this\n            means that `function` is called on first use and its \n            return value cached for subsequent uses. Defaults to False\n        :param threadlocal: When True, register dependency as a threadlocal singleton,\n            Same functionality as ``singleton`` except :class:`Threading.local` is used\n            to cache return values.\n        :type function: callable\n        :type singleton: bool\n        :type threadlocal: bool\n        :type name: string\n        \"\"\"\n        def decorator(function=None):\n            self._set(name, function, singleton, threadlocal)\n            return function\n        if function:\n            return decorator(function)\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inject(self, function=None, **names):\n        def decorator(function):\n            @wraps(function)\n            def wrapper(*args, **kwargs):\n                sig = signature(function)\n                params = sig.parameters\n\n                bound = sig.bind_partial(*args, **kwargs)\n                bound.apply_defaults()\n\n                injected_kwargs = {}\n                for key, value in params.items():\n                    if key not in bound.arguments:\n                        name = names.get(key)\n                        if name:\n                            # Raise error when dep named explicitly\n                            # and missing\n                            injected_kwargs[key] = self.get(name)\n                        else:\n                            try:\n                                injected_kwargs[key] = self.get(key)\n                            except DependencyNotFoundError as e:\n                                warnings.warn(\n                                    ambigious_not_found_msg.format(key),\n                                    DependencyNotFoundWarning\n                                )\n                            \n                injected_kwargs.update(bound.kwargs)\n                return function(*bound.args, **injected_kwargs)\n            return wrapper\n        if function:\n            return decorator(function)\n        return decorator", "response": "Decorator that injects dependencies into the given function s arguments when called."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves dependency as instance attribute of given class.", "response": "def resolve(self, dependency):\n        \"\"\"\n        Resolve dependency as instance attribute \n        of given class.\n\n        >>> class Users:\n        ...     db = injector.resolve(user_db)\n        ...\n        ...     def get_by_id(self, user_id):\n        ...         return self.db.get(user_id)\n\n                \n        When the attribute is first accessed, it \n        will be resolved from the corresponding \n        dependency function\n        \"\"\"        \n        if isinstance(dependency, str):\n            name = dependency\n        else:\n            name = dependency._giveme_registered_name\n            \n        return DeferredProperty(\n            partial(self.get, name)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of all available apis", "response": "def _fetch_itemslist(self, current_item):\n        \"\"\" Get a all available apis\n        \"\"\"\n        if current_item.is_root:\n            html = requests.get(self.base_url).text\n            soup = BeautifulSoup(html, 'html.parser')\n            for item_html in soup.select(\".row .col-md-6\"):\n                try:\n                    label = item_html.select_one(\"h2\").text\n                except Exception:\n                    continue\n                yield API(label, blob=item_html)\n        else:\n            # parameter = current_item.parent\n            # data = requests.get(parameter.url)\n            for resource in current_item.json[\"resource\"]:\n                label = u\"{}, {}\".format(resource[\"title\"], resource[\"summary\"])\n                yield SMHIDataset(label, blob=resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fetch_data(self, dataset, query={}, include_inactive_stations=False):\n        data = []\n        parameter = dataset\n        station_dim = dataset.dimensions[\"station\"]\n        all_stations = station_dim.allowed_values\n        # Step 1: Prepare query\n        if \"station\" not in query:\n            if include_inactive_stations:\n                # Get all stations\n                query[\"station\"] = list(all_stations)\n            else:\n                # Get only active stations\n                query[\"station\"] = list(station_dim.active_stations())\n        else:\n            if not isinstance(query[\"station\"], list):\n                query[\"station\"] = [query[\"station\"]]\n            # Make sure that the queried stations actually exist\n            query[\"station\"] = [ all_stations.get_by_label(x) for x in query[\"station\"]]\n\n        if \"period\" not in query:\n            # TODO: I'd prepare to do dataset.get(\"period\").allowed_values here\n            query[\"period\"] = PERIODS\n\n        elif not isinstance(query[\"period\"], list):\n            query[\"period\"] = [query[\"period\"]]\n\n        for period in query[\"period\"]:\n            if period not in PERIODS:\n                msg = u\"{} is not an allowed period\".format(period)\n                raise Exception(msg)\n\n\n        # Step 3: Get data\n        n_queries = len(query[\"station\"]) * len(query[\"period\"])\n        counter = 0\n        print(\"Fetching data with {} queries.\".format(n_queries))\n        for station in query[\"station\"]:\n            for period in query[\"period\"]:\n                url = dataset.url\\\n                    .replace(\".json\", \"/station/{}/period/{}/data.csv\"\\\n                        .format(station.key, period))\n                print(\"/GET {} \".format(url))\n                r = requests.get(url)\n\n                if r.status_code == 200:\n                    raw_data = DataCsv().from_string(r.content).to_dictlist()\n\n                    # TODO: This is a very hard coded parse function\n                    # Expects fixed start row and number of cols\n                    for row in raw_data:\n                        #timepoint = datetime.strptime(timepoint_str, \"%Y-%m-%d %H:%M:%S\")\n                        value_col = parameter.id.split(\",\")[0]\n                        value = float(row[value_col])\n\n                        row[\"parameter\"] = parameter.id\n                        row[\"station\"] = station.label\n                        row[\"station_key\"] = station.key\n                        row[\"period\"] = period\n\n                        row.pop(value_col,None)\n\n                        datapoint = Result(value, row)\n\n                        yield datapoint\n\n                elif r.status_code == 404:\n                    print(\"Warning no data at {}\".format(url))\n                else:\n                    raise Exception(\"Connection error for {}\".format(url))", "response": "Fetch data from the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef batch(iterable, length):\n    source_iter = iter(iterable)\n    while True:\n        batch_iter = itertools.islice(source_iter, length)\n        yield itertools.chain([batch_iter.next()], batch_iter)", "response": "Returns a series of iterators across the inputted iterable method and a batch of length."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef group(iterable):\n    numbers = sorted(list(set(iterable)))\n    for _, grouper in itertools.groupby(numbers, key=lambda i, c=itertools.count(): i - next(c)):\n        subset = list(grouper)\n        yield subset[0], subset[-1]", "response": "Returns a generator that yields the min max of the inputted list of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plural(formatter, value, name, option, format):\n    # Extract the plural words from the format string.\n    words = format.split('|')\n    # This extension requires at least two plural words.\n    if not name and len(words) == 1:\n        return\n    # This extension only formats numbers.\n    try:\n        number = decimal.Decimal(value)\n    except (ValueError, decimal.InvalidOperation):\n        return\n    # Get the locale.\n    locale = Locale.parse(option) if option else formatter.locale\n    # Select word based on the plural tag index.\n    index = get_plural_tag_index(number, locale)\n    return formatter.format(words[index], value)", "response": "Returns the textension for the locale - specific pluralization rules."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a key to choose a choice from any value.", "response": "def get_choice(value):\n    \"\"\"Gets a key to choose a choice from any value.\"\"\"\n    if value is None:\n        return 'null'\n    for attr in ['__name__', 'name']:\n        if hasattr(value, attr):\n            return getattr(value, attr)\n    return str(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choose(formatter, value, name, option, format):\n    if not option:\n        return\n    words = format.split('|')\n    num_words = len(words)\n    if num_words < 2:\n        return\n    choices = option.split('|')\n    num_choices = len(choices)\n    # If the words has 1 more item than the choices, the last word will be\n    # used as a default choice.\n    if num_words not in (num_choices, num_choices + 1):\n        n = num_choices\n        raise ValueError('specify %d or %d choices' % (n, n + 1))\n    choice = get_choice(value)\n    try:\n        index = choices.index(choice)\n    except ValueError:\n        if num_words == num_choices:\n            raise ValueError('no default choice supplied')\n        index = -1\n    return formatter.format(words[index], value)", "response": "Adds simple logic to format strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_(formatter, value, name, option, format):\n    if not format:\n        return\n    if not hasattr(value, '__getitem__') or isinstance(value, string_types):\n        return\n    words = format.split(u'|', 4)\n    num_words = len(words)\n    if num_words < 2:\n        # Require at least two words for item format and spacer.\n        return\n    num_items = len(value)\n    item_format = words[0]\n    # NOTE: SmartFormat.NET treats a not nested item format as the format\n    # string to format each items.  For example, `x` will be treated as `{:x}`.\n    # But the original tells us this behavior has been deprecated so that\n    # should be removed.  So SmartFormat for Python doesn't implement the\n    # behavior.\n    spacer = u'' if num_words < 2 else words[1]\n    final_spacer = spacer if num_words < 3 else words[2]\n    two_spacer = final_spacer if num_words < 4 else words[3]\n    buf = io.StringIO()\n    for x, item in enumerate(value):\n        if x == 0:\n            pass\n        elif x < num_items - 1:\n            buf.write(spacer)\n        elif x == 1:\n            buf.write(two_spacer)\n        else:\n            buf.write(final_spacer)\n        buf.write(formatter.format(item_format, item, index=x))\n    return buf.getvalue()", "response": "Repeats the items of an array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a time that n seconds after a time.", "response": "def add_seconds(datetime_like_object, n, return_date=False):\n    \"\"\"\n    Returns a time that n seconds after a time.\n\n    :param datetimestr: a datetime object or a datetime str\n    :param n: number of seconds, value can be negative\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u8fd4\u56de\u7ed9\u5b9a\u65e5\u671fN\u79d2\u4e4b\u540e\u7684\u65f6\u95f4\u3002\n    \"\"\"\n    a_datetime = parser.parse_datetime(datetime_like_object)\n    a_datetime = a_datetime + timedelta(seconds=n)\n    if return_date:  # pragma: no cover\n        return a_datetime.date()\n    else:\n        return a_datetime"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_months(datetime_like_object, n, return_date=False):\n    a_datetime = parser.parse_datetime(datetime_like_object)\n    month_from_ordinary = a_datetime.year * 12 + a_datetime.month\n    month_from_ordinary += n\n    year, month = divmod(month_from_ordinary, 12)\n\n    # try assign year, month, day\n    try:\n        a_datetime = datetime(\n            year, month, a_datetime.day,\n            a_datetime.hour, a_datetime.minute, a_datetime.second,\n            a_datetime.microsecond, tzinfo=a_datetime.tzinfo,\n        )\n    # \u80af\u5b9a\u662f\u7531\u4e8e\u65b0\u7684\u6708\u4efd\u7684\u65e5\u5b50\u4e0d\u591f, \u6240\u4ee5\u80af\u5b9a\u662f\u6708\u5e95,\n    # \u90a3\u4e48\u76f4\u63a5\u8df3\u5230\u4e0b\u4e00\u4e2a\u6708\u7684\u7b2c\u4e00\u5929, \u518d\u56de\u9000\u4e00\u5929\n    except ValueError:\n        month_from_ordinary += 1\n        year, month = divmod(month_from_ordinary, 12)\n        a_datetime = datetime(\n            year, month, 1,\n            a_datetime.hour, a_datetime.minute, a_datetime.second,\n            a_datetime.microsecond, tzinfo=a_datetime.tzinfo,\n        )\n        a_datetime = add_days(a_datetime, -1)\n\n    if return_date:  # pragma: no cover\n        return a_datetime.date()\n    else:\n        return a_datetime", "response": "Returns a time object that n months after a time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_years(datetime_like_object, n, return_date=False):\n    a_datetime = parser.parse_datetime(datetime_like_object)\n\n    # try assign year, month, day\n    try:\n        a_datetime = datetime(\n            a_datetime.year + n, a_datetime.month, a_datetime.day,\n            a_datetime.hour, a_datetime.minute, a_datetime.second,\n            a_datetime.microsecond, tzinfo=a_datetime.tzinfo,\n        )\n    except ValueError:  # Must be xxxx-02-29\n        a_datetime = datetime(\n            a_datetime.year + n, 2, 28,\n            a_datetime.hour, a_datetime.minute,\n            a_datetime.second, a_datetime.microsecond)\n\n    if return_date:  # pragma: no cover\n        return a_datetime.date()\n    else:\n        return a_datetime", "response": "Returns a datetime object that n years after a time."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nroutes the given datetime to the latest time with the hour minute second.", "response": "def _floor_to(dt, hour, minute, second):\n    \"\"\"\n    Route the given datetime to the latest time with the hour, minute, second\n    before it.\n    \"\"\"\n    new_dt = dt.replace(hour=hour, minute=minute, second=second)\n    if new_dt <= dt:\n        return new_dt\n    else:\n        return new_dt - timedelta(days=1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _round_to(dt, hour, minute, second):\n    new_dt = dt.replace(hour=hour, minute=minute, second=second)\n    if new_dt == dt:\n        return new_dt\n    elif new_dt < dt:\n        before = new_dt\n        after = new_dt + timedelta(days=1)\n    elif new_dt > dt:\n        before = new_dt - timedelta(days=1)\n        after = new_dt\n\n    d1 = dt - before\n    d2 = after - dt\n\n    if d1 < d2:\n        return before\n    elif d1 > d2:\n        return after\n    else:\n        return before", "response": "Route the given datetime to the latest time with the hour minute second tuple before it."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrounds the given datetime to specified hour minute and second.", "response": "def round_to(dt, hour, minute, second, mode=\"round\"):\n    \"\"\"\n    Round the given datetime to specified hour, minute and second.\n\n    :param mode: 'floor' or 'ceiling'\n\n    .. versionadded:: 0.0.5\n\n        message\n\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06\u7ed9\u5b9a\u65f6\u95f4\u5bf9\u9f50\u5230\u6700\u8fd1\u7684\u4e00\u4e2a\u6307\u5b9a\u4e86\u5c0f\u65f6, \u5206\u949f, \u79d2\u7684\u65f6\u95f4\u4e0a\u3002\n    \"\"\"\n    mode = mode.lower()\n    if mode not in _round_to_options:\n        raise ValueError(\n            \"'mode' has to be one of %r!\" % list(_round_to_options.keys()))\n    return _round_to_options[mode](dt, hour, minute, second)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _log(self, content):\n        self._buffer += content\n        if self._auto_flush:\n            self.flush()", "response": "Write a string to the log"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset(self):\n        self._buffer = ''\n        self._chars_flushed = 0\n        self._game_start_timestamp = datetime.datetime.now()", "response": "Erase the log and reset the timestamp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the logfile path and filename as a string.", "response": "def logpath(self):\n        \"\"\"\n        Return the logfile path and filename as a string.\n\n        The file with name self.logpath() is written to on flush().\n\n        The filename contains the log's timestamp and the names of players in the game.\n        The logpath changes when reset() or _set_players() are called, as they change the\n        timestamp and the players, respectively.\n        \"\"\"\n        name = '{}-{}.catan'.format(self.timestamp_str(),\n                                    '-'.join([p.name for p in self._players]))\n        path = os.path.join(self._log_dir, name)\n        if not os.path.exists(self._log_dir):\n            os.mkdir(self._log_dir)\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flush(self):\n        latest = self._latest()\n        self._chars_flushed += len(latest)\n        if self._use_stdout:\n            file = sys.stdout\n        else:\n            file = open(self.logpath(), 'a')\n\n        print(latest, file=file, flush=True, end='')\n\n        if not self._use_stdout:\n            file.close()", "response": "Append the latest updates to file or optionally to stdout instead."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_game_start(self, players, terrain, numbers, ports):\n        self.reset()\n        self._set_players(players)\n        self._logln('{} v{}'.format(__name__, __version__))\n        self._logln('timestamp: {0}'.format(self.timestamp_str()))\n        self._log_players(players)\n        self._log_board_terrain(terrain)\n        self._log_board_numbers(numbers)\n        self._log_board_ports(ports)\n        self._logln('...CATAN!')", "response": "Log the start of a game."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_player_roll(self, player, roll):\n        self._logln('{0} rolls {1}{2}'.format(player.color, roll, ' ...DEUCES!' if int(roll) == 2 else ''))", "response": "Log a player s current dice tier roll"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog a buys road.", "response": "def log_player_buys_road(self, player, location):\n        \"\"\"\n        :param player: catan.game.Player\n        :param location: string, see hexgrid.location()\n        \"\"\"\n        self._logln('{0} buys road, builds at {1}'.format(\n            player.color,\n            location\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log_player_buys_settlement(self, player, location):\n        self._logln('{0} buys settlement, builds at {1}'.format(\n            player.color,\n            location\n        ))", "response": "Log the buys settlement of a player."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging the buys city of a player.", "response": "def log_player_buys_city(self, player, location):\n        \"\"\"\n        :param player: catan.game.Player\n        :param location: string, see hexgrid.location()\n        \"\"\"\n        self._logln('{0} buys city, builds at {1}'.format(\n            player.color,\n            location\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog the trades of a player with a specific port.", "response": "def log_player_trades_with_port(self, player, to_port, port, to_player):\n        \"\"\"\n        :param player: catan.game.Player\n        :param to_port: list of tuples, [(int, game.board.Terrain), (int, game.board.Terrain)]\n        :param port: catan.board.Port\n        :param to_player: list of tuples, [(int, game.board.Terrain), (int, game.board.Terrain)]\n        \"\"\"\n        self._log('{0} trades '.format(player.color))\n\n        # to_port items\n        self._log('[')\n        for i, (num, res) in enumerate(to_port):\n            if i > 0:\n                self._log(', ')\n            self._log('{0} {1}'.format(num, res.value))\n        self._log(']')\n\n        self._log(' to port {0} for '.format(port.type.value))\n\n        # to_player items\n        self._log('[')\n        for i, (num, res) in enumerate(to_player):\n            if i > 0:\n                self._log(', ')\n            self._log('{0} {1}'.format(num, res.value))\n        self._log(']')\n\n        self._log('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_player_trades_with_other_player(self, player, to_other, other, to_player):\n        self._log('{0} trades '.format(player.color))\n\n        # to_other items\n        self._log('[')\n        for i, (num, res) in enumerate(to_other):\n            if i > 0:\n                self._log(', ')\n            self._log('{0} {1}'.format(num, res.value))\n        self._log(']')\n\n        self._log(' to player {0} for '.format(other.color))\n\n        # to_player items\n        self._log('[')\n        for i, (num, res) in enumerate(to_player):\n            if i > 0:\n                self._log(', ')\n            self._log('{0} {1}'.format(num, res.value))\n        self._log(']')\n\n        self._log('\\n')", "response": "Log the trades of a player with a specific player and other."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_player_plays_knight(self, player, location, victim):\n        self._logln('{0} plays knight'.format(player.color))\n        self.log_player_moves_robber_and_steals(player, location, victim)", "response": "Log a player s plays knight."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_player_plays_road_builder(self, player, location1, location2):\n        self._logln('{0} plays road builder, builds at {1} and {2}'.format(\n            player.color,\n            location1,\n            location2\n        ))", "response": "Log the player plays road builder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs the number of plays of a given year of plenty.", "response": "def log_player_plays_year_of_plenty(self, player, resource1, resource2):\n        \"\"\"\n        :param player: catan.game.Player\n        :param resource1: catan.board.Terrain\n        :param resource2: catan.board.Terrain\n        \"\"\"\n        self._logln('{0} plays year of plenty, takes {1} and {2}'.format(\n            player.color,\n            resource1.value,\n            resource2.value\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_player_plays_monopoly(self, player, resource):\n        self._logln('{0} plays monopoly on {1}'.format(\n            player.color,\n            resource.value\n        ))", "response": "Log the number of plays monopoly on the specified player and resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs the latest end of turn.", "response": "def log_player_ends_turn(self, player):\n        \"\"\"\n        :param player: catan.game.Player\n        \"\"\"\n        seconds_delta = (datetime.datetime.now() - self._latest_timestamp).total_seconds()\n        self._logln('{0} ends turn after {1}s'.format(player.color, round(seconds_delta)))\n        self._latest_timestamp = datetime.datetime.now()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntiling are logged counterclockwise beginning from the top-left. See module hexgrid (https://github.com/rosshamish/hexgrid) for the tile layout. :param terrain: list of catan.board.Terrain objects", "response": "def _log_board_terrain(self, terrain):\n        \"\"\"\n        Tiles are logged counterclockwise beginning from the top-left.\n        See module hexgrid (https://github.com/rosshamish/hexgrid) for the tile layout.\n\n        :param terrain: list of catan.board.Terrain objects\n        \"\"\"\n        self._logln('terrain: {0}'.format(' '.join(t.value for t in terrain)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnumbering are logged counterclockwise beginning from the top-left. See module hexgrid (https://github.com/rosshamish/hexgrid) for the tile layout. :param numbers: list of catan.board.HexNumber objects.", "response": "def _log_board_numbers(self, numbers):\n        \"\"\"\n        Numbers are logged counterclockwise beginning from the top-left.\n        See module hexgrid (https://github.com/rosshamish/hexgrid) for the tile layout.\n\n        :param numbers: list of catan.board.HexNumber objects.\n        \"\"\"\n        self._logln('numbers: {0}'.format(' '.join(str(n.value) for n in numbers)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog the players and their attributes.", "response": "def _log_players(self, players):\n        \"\"\"\n        :param players: list of catan.game.Player objects\n        \"\"\"\n        self._logln('players: {0}'.format(len(players)))\n        for p in self._players:\n            self._logln('name: {0}, color: {1}, seat: {2}'.format(p.name, p.color, p.seat))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the _players attribute.", "response": "def _set_players(self, _players):\n        \"\"\"\n        Players will always be set in seat order (1,2,3,4)\n        \"\"\"\n        self._players = list()\n        _players = list(_players)\n        _players.sort(key=lambda p: p.seat)\n        for p in _players:\n            self._players.append(p)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _SetGuide(self, guideName):\n    if(guideName == epguides.EPGuidesLookup.GUIDE_NAME):\n      self._guide = epguides.EPGuidesLookup()\n    else:\n      raise Exception(\"[RENAMER] Unknown guide set for TVRenamer selection: Got {}, Expected {}\".format(guideName, epguides.EPGuidesLookup.GUIDE_NAME))", "response": "Sets the guide for the TVRenamer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list containing all unique show names from tvfile. TVFile objects.", "response": "def _GetUniqueFileShowNames(self, tvFileList):\n    \"\"\"\n    Return a list containing all unique show names from tvfile.TVFile object\n    list.\n\n    Parameters\n    ----------\n      tvFileList : list\n        List of tvfile.TVFile objects.\n\n    Returns\n    ----------\n      set\n        The set of show names from the tvfile.TVFile list.\n    \"\"\"\n    showNameList = [tvFile.fileInfo.showName for tvFile in tvFileList]\n    return(set(showNameList))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for a show ID in the database file name table or a show name from the TV library.", "response": "def _GetShowID(self, stringSearch, origStringSearch = None):\n    \"\"\"\n    Search for given string as an existing entry in the database file name\n    table or, if no match is found, as a show name from the TV guide.\n\n    If an exact match is not found in the database the user can accept\n    or decline the best match from the TV guide or can provide an alternate\n    match to lookup.\n\n    Parameters\n    ----------\n      stringSearch : string\n        String to look up in database or guide.\n\n      origStringSearch : string [optional: default = None]\n        Original search string, used by recusive function calls.\n\n    Returns\n    ----------\n      tvfile.ShowInfo or None\n        If no show id could be found this returns None, otherwise\n        it returns a tvfile.ShowInfo object containing show name\n        and show id.\n    \"\"\"\n    showInfo = tvfile.ShowInfo()\n\n    if origStringSearch is None:\n      goodlogging.Log.Info(\"RENAMER\", \"Looking up show ID for: {0}\".format(stringSearch))\n      origStringSearch = stringSearch\n\n    goodlogging.Log.IncreaseIndent()\n\n    showInfo.showID = self._db.SearchFileNameTable(stringSearch)\n\n    if showInfo.showID is None:\n      goodlogging.Log.Info(\"RENAMER\", \"No show ID match found for '{0}' in database\".format(stringSearch))\n      showNameList = self._guide.ShowNameLookUp(stringSearch)\n\n      if self._skipUserInput is True:\n        if len(showNameList) == 1:\n          showName = showNameList[0]\n          goodlogging.Log.Info(\"RENAMER\", \"Automatic selection of showname: {0}\".format(showName))\n        else:\n          showName = None\n          goodlogging.Log.Info(\"RENAMER\", \"Show skipped - could not make automatic selection of showname\")\n      else:\n        showName = util.UserAcceptance(showNameList)\n\n      if showName in showNameList:\n        libEntry = self._db.SearchTVLibrary(showName = showName)\n\n        if libEntry is None:\n          if self._skipUserInput is True:\n            response = 'y'\n          else:\n            goodlogging.Log.Info(\"RENAMER\", \"No show by this name found in TV library database. Is this a new show for the database?\")\n            response = goodlogging.Log.Input(\"RENAMER\", \"Enter 'y' (yes), 'n' (no) or 'ls' (list existing shows): \")\n            response = util.ValidUserResponse(response, ('y', 'n', 'ls'))\n\n            if response.lower() == 'ls':\n              dbLibList = self._db.SearchTVLibrary()\n              if dbLibList is None:\n                goodlogging.Log.Info(\"RENAMER\", \"TV library is empty\")\n                response = 'y'\n              else:\n                dbShowNameList = [i[1] for i in dbLibList]\n                dbShowNameStr = ', '.join(dbShowNameList)\n                goodlogging.Log.Info(\"RENAMER\", \"Existing shows in database are: {0}\".format(dbShowNameStr))\n                response = goodlogging.Log.Input(\"RENAMER\", \"Is this a new show? [y/n]: \")\n                response = util.ValidUserResponse(response, ('y', 'n'))\n          if response.lower() == 'y':\n            showInfo.showID = self._db.AddShowToTVLibrary(showName)\n            showInfo.showName = showName\n          else:\n            try:\n              dbShowNameList\n            except NameError:\n              dbLibList = self._db.SearchTVLibrary()\n              if dbLibList is None:\n                goodlogging.Log.Info(\"RENAMER\", \"No show ID found - TV library is empty\")\n                return None\n              dbShowNameList = [i[1] for i in dbLibList]\n\n            while showInfo.showID is None:\n              matchShowList = util.GetBestMatch(showName, dbShowNameList)\n              showName = util.UserAcceptance(matchShowList)\n              if showName is None:\n                goodlogging.Log.Info(\"RENAMER\", \"No show ID found - could not match to existing show\")\n                return None\n              elif showName in matchShowList:\n                showInfo.showID = self._db.SearchTVLibrary(showName = showName)[0][0]\n                showInfo.showName = showName\n\n        else:\n          showInfo.showID = libEntry[0][0]\n\n        self._db.AddToFileNameTable(origStringSearch, showInfo.showID)\n\n        goodlogging.Log.DecreaseIndent()\n        return showInfo\n      elif showName is None:\n        goodlogging.Log.DecreaseIndent()\n        return None\n      else:\n        goodlogging.Log.DecreaseIndent()\n        return self._GetShowID(showName, origStringSearch)\n    else:\n      goodlogging.Log.Info(\"RENAMER\", \"Match found: show ID = {0}\".format(showInfo.showID))\n      if origStringSearch != stringSearch:\n        self._db.AddToFileNameTable(origStringSearch, showInfo.showID)\n      goodlogging.Log.DecreaseIndent()\n      return showInfo"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetShowInfo(self, stringSearch):\n    goodlogging.Log.Info(\"RENAMER\", \"Looking up show info for: {0}\".format(stringSearch))\n    goodlogging.Log.IncreaseIndent()\n    showInfo = self._GetShowID(stringSearch)\n    if showInfo is None:\n      goodlogging.Log.DecreaseIndent()\n      return None\n    elif showInfo.showID is None:\n      goodlogging.Log.DecreaseIndent()\n      return None\n    elif showInfo.showName is None:\n      showInfo.showName = self._db.SearchTVLibrary(showID = showInfo.showID)[0][1]\n      goodlogging.Log.Info(\"RENAMER\", \"Found show name: {0}\".format(showInfo.showName))\n      goodlogging.Log.DecreaseIndent()\n      return showInfo\n    else:\n      goodlogging.Log.DecreaseIndent()\n      return showInfo", "response": "Returns a showInfo object for the given stringSearch."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove a file from old path to new path.", "response": "def _MoveFileToLibrary(self, oldPath, newPath):\n    \"\"\"\n    Move file from old file path to new file path. This follows certain\n    conditions:\n\n      - If file already exists at destination do rename inplace.\n      - If file destination is on same file system and doesn't exist rename and move.\n      - If source and destination are on different file systems do rename in-place,\n        and if forceCopy is true copy to dest and move orig to archive directory.\n\n    Parameters\n    ----------\n      oldPath : string\n        Old file path.\n\n      newPath : string\n        New file path.\n\n    Returns\n    ----------\n      boolean\n        If old and new file paths are the same or if the new file path already exists\n        this returns False. If file rename is skipped for any reason this returns None\n        otherwise if rename completes okay it returns True.\n    \"\"\"\n    if oldPath == newPath:\n      return False\n\n    goodlogging.Log.Info(\"RENAMER\", \"PROCESSING FILE: {0}\".format(oldPath))\n\n    if os.path.exists(newPath):\n      goodlogging.Log.Info(\"RENAMER\", \"File skipped - file aleady exists in TV library at {0}\".format(newPath))\n      return False\n\n    newDir = os.path.dirname(newPath)\n    os.makedirs(newDir, exist_ok=True)\n\n    try:\n      os.rename(oldPath, newPath)\n    except OSError as ex:\n      if ex.errno is errno.EXDEV:\n        goodlogging.Log.Info(\"RENAMER\", \"Simple rename failed - source and destination exist on different file systems\")\n        goodlogging.Log.Info(\"RENAMER\", \"Renaming file in-place\")\n        newFileName = os.path.basename(newPath)\n        origFileDir = os.path.dirname(oldPath)\n        renameFilePath = os.path.join(origFileDir, newFileName)\n        if oldPath != renameFilePath:\n          renameFilePath = util.CheckPathExists(renameFilePath)\n          goodlogging.Log.Info(\"RENAMER\", \"Renaming from {0} to {1}\".format(oldPath, renameFilePath))\n        else:\n          goodlogging.Log.Info(\"RENAMER\", \"File already has the correct name ({0})\".format(newFileName))\n\n        try:\n          os.rename(oldPath, renameFilePath)\n        except Exception as ex2:\n          goodlogging.Log.Info(\"RENAMER\", \"File rename skipped - Exception ({0}): {1}\".format(ex2.args[0], ex2.args[1]))\n        else:\n          if self._forceCopy is True:\n            goodlogging.Log.Info(\"RENAMER\", \"Copying file to new file system {0} to {1}\".format(renameFilePath, newPath))\n\n            try:\n              shutil.copy2(renameFilePath, newPath)\n            except shutil.Error as ex3:\n              err = ex3.args[0]\n              goodlogging.Log.Info(\"RENAMER\", \"File copy failed - Shutil Error: {0}\".format(err))\n            else:\n              util.ArchiveProcessedFile(renameFilePath, self._archiveDir)\n              return True\n          else:\n            goodlogging.Log.Info(\"RENAMER\", \"File copy skipped - copying between file systems is disabled (enabling this functionality is slow)\")\n      else:\n        goodlogging.Log.Info(\"RENAMER\", \"File rename skipped - Exception ({0}): {1}\".format(ex.args[0], ex.args[1]))\n    except Exception as ex:\n      goodlogging.Log.Info(\"RENAMER\", \"File rename skipped - Exception ({0}): {1}\".format(ex.args[0], ex.args[1]))\n    else:\n      goodlogging.Log.Info(\"RENAMER\", \"RENAME COMPLETE: {0}\".format(newPath))\n      return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new season directory name.", "response": "def _CreateNewSeasonDir(self, seasonNum):\n    \"\"\"\n    Creates a new season directory name in the form 'Season <NUM>'.\n\n    If skipUserInput is True this will be accepted by default otherwise the\n    user can choose to accept this, use the base show directory or enter\n    a different name.\n\n    Parameters\n    ----------\n      seasonNum : int\n        Season number.\n\n    Returns\n    ----------\n      string or None\n        If the user accepts the generated directory name or gives a new name\n        this will be returned. If it the user chooses to use the base\n        directory an empty string is returned. If the user chooses to skip at\n        this input stage None is returned.\n    \"\"\"\n    seasonDirName = \"Season {0}\".format(seasonNum)\n    goodlogging.Log.Info(\"RENAMER\", \"Generated directory name: '{0}'\".format(seasonDirName))\n\n    if self._skipUserInput is False:\n      response = goodlogging.Log.Input(\"RENAMER\", \"Enter 'y' to accept this directory, 'b' to use base show directory, 'x' to skip this file or enter a new directory name to use: \")\n      response = util.CheckEmptyResponse(response)\n    else:\n      response = 'y'\n\n    if response.lower() == 'b':\n      return ''\n    elif response.lower() == 'y':\n      return seasonDirName\n    elif response.lower() == 'x':\n      return None\n    else:\n      return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks up the season directory in the database.", "response": "def _LookUpSeasonDirectory(self, showID, showDir, seasonNum):\n    \"\"\"\n    Look up season directory. First attempt to find match from database,\n    otherwise search TV show directory. If no match is found in the database\n    the user can choose to accept a match from the TV show directory, enter\n    a new directory name to use or accept an autogenerated name.\n\n    Parameters\n    ----------\n      showID : int\n        Show ID number\n\n      showDir : string\n        Path to show file directory\n\n      seasonNum : int\n        Season number\n\n    Returns\n    ----------\n      string\n        Name of season directory to use. This can be a blank string to\n        use the root show directory, an autogenerated string or a user\n        given string.\n    \"\"\"\n    goodlogging.Log.Info(\"RENAMER\", \"Looking up season directory for show {0}\".format(showID))\n    goodlogging.Log.IncreaseIndent()\n\n    # Look up existing season folder from database\n    seasonDirName = self._db.SearchSeasonDirTable(showID, seasonNum)\n\n    if seasonDirName is not None:\n      goodlogging.Log.Info(\"RENAMER\", \"Found season directory match from database: {0}\".format(seasonDirName))\n    else:\n      # Look up existing season folder in show directory\n      goodlogging.Log.Info(\"RENAMER\", \"Looking up season directory (Season {0}) in {1}\".format(seasonNum, showDir))\n      if os.path.isdir(showDir) is False:\n        goodlogging.Log.Info(\"RENAMER\", \"Show directory ({0}) is not an existing directory\".format(showDir))\n        seasonDirName = self._CreateNewSeasonDir(seasonNum)\n      else:\n        matchDirList = []\n        for dirName in os.listdir(showDir):\n          subDir = os.path.join(showDir, dirName)\n          if os.path.isdir(subDir):\n            seasonResult = re.findall(\"Season\", dirName)\n            if len(seasonResult) > 0:\n              numResult = re.findall(\"[0-9]+\", dirName)\n              numResult = set(numResult)\n              if len(numResult) == 1:\n                if int(numResult.pop()) == int(seasonNum):\n                  matchDirList.append(dirName)\n\n        if self._skipUserInput is True:\n          if len(matchDirList) == 1:\n            userAcceptance = matchDirList[0]\n            goodlogging.Log.Info(\"RENAMER\", \"Automatic selection of season directory: {0}\".format(seasonDirName))\n          else:\n            userAcceptance = None\n            goodlogging.Log.Info(\"RENAMER\", \"Could not make automatic selection of season directory\")\n        else:\n          listDirPrompt = \"enter 'ls' to list all items in show directory\"\n          userAcceptance = util.UserAcceptance(matchDirList, promptComment = listDirPrompt, xStrOverride = \"to create new season directory\")\n\n        if userAcceptance in matchDirList:\n          seasonDirName = userAcceptance\n        elif userAcceptance is None:\n          seasonDirName = self._CreateNewSeasonDir(seasonNum)\n        else:\n          recursiveSelectionComplete = False\n          promptOnly = False\n          dirLookup = userAcceptance\n          while recursiveSelectionComplete is False:\n            dirList = os.listdir(showDir)\n            if dirLookup.lower() == 'ls':\n              dirLookup = ''\n              promptOnly = True\n              if len(dirList) == 0:\n                goodlogging.Log.Info(\"RENAMER\", \"Show directory is empty\")\n              else:\n                goodlogging.Log.Info(\"RENAMER\", \"Show directory contains: {0}\".format(', '.join(dirList)))\n            else:\n              matchDirList = util.GetBestMatch(dirLookup, dirList)\n              response = util.UserAcceptance(matchDirList, promptComment = listDirPrompt, promptOnly = promptOnly, xStrOverride = \"to create new season directory\")\n              promptOnly = False\n\n              if response in matchDirList:\n                seasonDirName = response\n                recursiveSelectionComplete = True\n              elif response is None:\n                seasonDirName = self._CreateNewSeasonDir(seasonNum)\n                recursiveSelectionComplete = True\n              else:\n                dirLookup = response\n\n      # Add season directory to database\n      if seasonDirName is not None:\n        self._db.AddSeasonDirTable(showID, seasonNum, seasonDirName)\n\n    goodlogging.Log.DecreaseIndent()\n    return seasonDirName"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new show directory name for TV.", "response": "def _CreateNewShowDir(self, showName):\n    \"\"\"\n    Create new directory name for show. An autogenerated choice, which is the\n    showName input that has been stripped of special characters, is proposed\n    which the user can accept or they can enter a new name to use. If the\n    skipUserInput variable is True the autogenerated value is accepted\n    by default.\n\n    Parameters\n    ----------\n      showName : string\n        Name of TV show\n\n    Returns\n    ----------\n      string or None\n        Either the autogenerated directory name, the user given directory name\n        or None if the user chooses to skip at this input stage.\n    \"\"\"\n    stripedDir = util.StripSpecialCharacters(showName)\n    goodlogging.Log.Info(\"RENAMER\", \"Suggested show directory name is: '{0}'\".format(stripedDir))\n\n    if self._skipUserInput is False:\n      response = goodlogging.Log.Input('RENAMER', \"Enter 'y' to accept this directory, 'x' to skip this show or enter a new directory to use: \")\n    else:\n      response = 'y'\n\n    if response.lower() == 'x':\n      return None\n    elif response.lower() == 'y':\n      return stripedDir\n    else:\n      return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GenerateLibraryPath(self, tvFile, libraryDir):\n    goodlogging.Log.Info(\"RENAMER\", \"Looking up library directory in database for show: {0}\".format(tvFile.showInfo.showName))\n    goodlogging.Log.IncreaseIndent()\n    showID, showName, showDir = self._db.SearchTVLibrary(showName = tvFile.showInfo.showName)[0]\n\n    if showDir is None:\n      goodlogging.Log.Info(\"RENAMER\", \"No directory match found in database - looking for best match in library directory: {0}\".format(libraryDir))\n      dirList = os.listdir(libraryDir)\n      listDir = False\n      matchName = tvFile.showInfo.showName\n      while showDir is None:\n        if len(dirList) == 0:\n          goodlogging.Log.Info(\"RENAMER\", \"TV Library directory is empty\")\n          response = None\n        else:\n          if listDir is True:\n            goodlogging.Log.Info(\"RENAMER\", \"TV library directory contains: {0}\".format(', '.join(dirList)))\n          else:\n            matchDirList = util.GetBestMatch(matchName, dirList)\n\n          listDir = False\n\n          if self._skipUserInput is True:\n            if len(matchDirList) == 1:\n              response = matchDirList[0]\n              goodlogging.Log.Info(\"RENAMER\", \"Automatic selection of show directory: {0}\".format(response))\n            else:\n              response = None\n              goodlogging.Log.Info(\"RENAMER\", \"Could not make automatic selection of show directory\")\n          else:\n            listDirPrompt = \"enter 'ls' to list all items in TV library directory\"\n            response = util.UserAcceptance(matchDirList, promptComment = listDirPrompt, promptOnly = listDir, xStrOverride = \"to create new show directory\")\n\n        if response is None:\n          showDir = self._CreateNewShowDir(tvFile.showInfo.showName)\n          if showDir is None:\n            goodlogging.Log.DecreaseIndent()\n            return tvFile\n        elif response.lower() == 'ls':\n          listDir = True\n        elif response in matchDirList:\n          showDir = response\n        else:\n          matchName = response\n\n      self._db.UpdateShowDirInTVLibrary(showID, showDir)\n\n    # Add base directory to show path\n    showDir = os.path.join(libraryDir, showDir)\n\n    goodlogging.Log.DecreaseIndent()\n\n    # Lookup and add season directory to show path\n    seasonDir = self._LookUpSeasonDirectory(showID, showDir, tvFile.showInfo.seasonNum)\n\n    if seasonDir is None:\n      return tvFile\n    else:\n      showDir = os.path.join(showDir, seasonDir)\n\n    # Call tvFile function to generate file name\n    tvFile.GenerateNewFilePath(showDir)\n\n    return tvFile", "response": "Generates a full path for a TV file in the TV library directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrename all TV files from the constructor given file list. It follows a number of key steps: 1) Extract a list of unique show titles from file name and lookup actual show names from database or TV guide. 2) Update each file with showID and showName. 3) Get episode name for all remaining files in valid list. 4) Print file details and generate new file paths. 5) Rename files. 6) List skipped and incompatible files.", "response": "def Run(self):\n    \"\"\"\n    Renames all TV files from the constructor given file list.\n\n    It follows a number of key steps:\n\n      1) Extract a list of unique show titles from file name and lookup\n         actual show names from database or TV guide.\n      2) Update each file with showID and showName.\n      3) Get episode name for all remaining files in valid list.\n      4) Print file details and generate new file paths.\n      5) Rename files.\n      6) List skipped and incompatible files.\n    \"\"\"\n    # ------------------------------------------------------------------------\n    # Get list of unique fileInfo show names and find matching actual show\n    # names from database or TV guide\n    # ------------------------------------------------------------------------\n    showNameMatchDict = {}\n    uniqueFileShowList = self._GetUniqueFileShowNames(self._fileList)\n    if len(uniqueFileShowList) > 0:\n      goodlogging.Log.Seperator()\n\n    for fileShowName in uniqueFileShowList:\n      showNameMatchDict[fileShowName] = self._GetShowInfo(fileShowName)\n      goodlogging.Log.NewLine()\n\n    # ------------------------------------------------------------------------\n    # Update each file with showID and showName\n    # ------------------------------------------------------------------------\n    incompatibleFileList = []\n    validShowFileList = []\n\n    for tvFile in self._fileList:\n      if showNameMatchDict[tvFile.fileInfo.showName] is None:\n        incompatibleFileList.append(tvFile)\n      else:\n        tvFile.showInfo.showID = showNameMatchDict[tvFile.fileInfo.showName].showID\n        tvFile.showInfo.showName = showNameMatchDict[tvFile.fileInfo.showName].showName\n        validShowFileList.append(tvFile)\n\n    # ------------------------------------------------------------------------\n    # Get episode name for all remaining files in valid list\n    # ------------------------------------------------------------------------\n    if len(validShowFileList) > 0:\n      goodlogging.Log.Seperator()\n\n    validEpisodeNameFileList = []\n\n    goodlogging.Log.Info(\"RENAMER\", \"Looking up episode names:\\n\")\n\n    for tvFile in validShowFileList:\n      tvFile.showInfo.episodeName = self._guide.EpisodeNameLookUp(tvFile.showInfo.showName, tvFile.showInfo.seasonNum, tvFile.showInfo.episodeNum)\n\n      if tvFile.showInfo.episodeName is None:\n        incompatibleFileList.append(tvFile)\n      else:\n        validEpisodeNameFileList.append(tvFile)\n\n      goodlogging.Log.Info(\"RENAMER\", \"{0} S{1}E{2}: {3}\".format(tvFile.showInfo.showName, tvFile.showInfo.seasonNum, tvFile.showInfo.episodeNum, tvFile.showInfo.episodeName))\n\n    goodlogging.Log.NewLine()\n\n    # ------------------------------------------------------------------------\n    # Print file details and generate new file paths\n    # ------------------------------------------------------------------------\n    goodlogging.Log.Seperator()\n\n    renameFileList = []\n    skippedFileList = []\n\n    goodlogging.Log.Info(\"RENAMER\", \"Generating library paths:\\n\")\n\n    if len(validEpisodeNameFileList) == 0:\n      goodlogging.Log.Info(\"RENAMER\", \"No compatible files were detected\")\n    else:\n      for tvFile in validEpisodeNameFileList:\n        tvFile.Print()\n        goodlogging.Log.NewLine()\n        if self._inPlaceRename is False:\n          tvFile = self._GenerateLibraryPath(tvFile, self._tvDir)\n        else:\n          tvFile.GenerateNewFilePath()\n\n        if tvFile.fileInfo.newPath is None:\n          incompatibleFileList.append(tvFile)\n        elif tvFile.fileInfo.origPath != tvFile.fileInfo.newPath:\n          renameFileList.append(tvFile)\n        else:\n          skippedFileList.append(tvFile)\n\n        goodlogging.Log.NewLine()\n\n      # ------------------------------------------------------------------------\n      # Rename files\n      # ------------------------------------------------------------------------\n      goodlogging.Log.Seperator()\n\n      goodlogging.Log.Info(\"RENAMER\", \"Renamable files:\\n\")\n\n      if len(renameFileList) == 0:\n        goodlogging.Log.Info(\"RENAMER\", \"No renamable files were detected\")\n      else:\n        showName = None\n        renameFileList.sort()\n\n        for tvFile in renameFileList:\n          if showName is None or showName != tvFile.showInfo.showName:\n            showName = tvFile.showInfo.showName\n            goodlogging.Log.Info(\"RENAMER\", \"{0}\".format(showName))\n          goodlogging.Log.IncreaseIndent()\n          goodlogging.Log.Info(\"RENAMER\", \"FROM: {0}\".format(tvFile.fileInfo.origPath))\n          goodlogging.Log.Info(\"RENAMER\", \"TO:   {0}\".format(tvFile.fileInfo.newPath))\n          goodlogging.Log.DecreaseIndent()\n          goodlogging.Log.NewLine()\n\n        if self._skipUserInput is False:\n          response = goodlogging.Log.Input('RENAMER', \"***WARNING*** CONTINUE WITH RENAME PROCESS? [y/n]: \")\n          response = util.ValidUserResponse(response, ('y','n'))\n        else:\n          response = 'y'\n\n        if response == 'n':\n          goodlogging.Log.Info(\"RENAMER\", \"Renaming process skipped\")\n        elif response == 'y':\n          goodlogging.Log.NewLine()\n          if self._inPlaceRename is False:\n            goodlogging.Log.Info(\"RENAMER\", \"Adding files to TV library:\\n\")\n          else:\n            goodlogging.Log.Info(\"RENAMER\", \"Renaming files:\\n\")\n          for tvFile in renameFileList:\n            self._MoveFileToLibrary(tvFile.fileInfo.origPath, tvFile.fileInfo.newPath)\n            goodlogging.Log.NewLine()\n\n    # ------------------------------------------------------------------------\n    # List skipped files\n    # ------------------------------------------------------------------------\n    if len(skippedFileList) > 0:\n      goodlogging.Log.Seperator()\n      goodlogging.Log.Info(\"RENAMER\", \"Skipped files:\")\n      goodlogging.Log.IncreaseIndent()\n      for tvFile in skippedFileList:\n        if tvFile.fileInfo.origPath == tvFile.fileInfo.newPath:\n          goodlogging.Log.Info(\"RENAMER\", \"{0} (No rename required)\".format(tvFile.fileInfo.origPath))\n        else:\n          goodlogging.Log.Info(\"RENAMER\", \"{0} (Unknown reason)\".format(tvFile.fileInfo.origPath))\n      goodlogging.Log.DecreaseIndent()\n\n    # ------------------------------------------------------------------------\n    # List incompatible files\n    # ------------------------------------------------------------------------\n    if len(incompatibleFileList) > 0:\n      goodlogging.Log.Seperator()\n      goodlogging.Log.Info(\"RENAMER\", \"Incompatible files:\")\n      goodlogging.Log.IncreaseIndent()\n      for tvFile in incompatibleFileList:\n        if tvFile.showInfo.showName is None:\n          goodlogging.Log.Info(\"RENAMER\", \"{0} (Missing show name)\".format(tvFile.fileInfo.origPath))\n        elif tvFile.showInfo.episodeName is None:\n          goodlogging.Log.Info(\"RENAMER\", \"{0} (Missing episode name)\".format(tvFile.fileInfo.origPath))\n        elif tvFile.fileInfo.newPath is None:\n          goodlogging.Log.Info(\"RENAMER\", \"{0} (Failed to create new file path)\".format(tvFile.fileInfo.origPath))\n        else:\n          goodlogging.Log.Info(\"RENAMER\", \"{0} (Unknown reason)\".format(tvFile.fileInfo.origPath))\n      goodlogging.Log.DecreaseIndent()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a function that returns the API object for the user.", "response": "def get_api_publisher(self, social_user):\n        \"\"\"\n            message: <str>\n            image: <file> as object_attachment\n            owner_id: <str>\n        \"\"\"\n\n        def _post(owner_id=None, **kwargs):\n            api = self.get_api(social_user, owner_id)\n            return api.post('{}/feed'.format(owner_id or 'me'), params=kwargs)\n\n        return _post"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef catch(ignore=[],\n          was_doing=\"something important\",\n          helpfull_tips=\"you should use a debugger\",\n          gbc=None):\n    \"\"\"\n    Catch, prepare and log error\n\n    :param exc_cls: error class\n    :param exc: exception\n    :param tb: exception traceback\n    \"\"\"\n    exc_cls, exc, tb=sys.exc_info()\n    if exc_cls in ignore:\n        msg='exception in ignorelist'\n        gbc.say('ignoring caught:'+str(exc_cls))\n        return 'exception in ignorelist'\n        \n\n    ex_message = traceback.format_exception_only(exc_cls, exc)[-1]\n    ex_message = ex_message.strip()\n    \n    # TODO: print(ex_message)\n\n    error_frame = tb\n    while error_frame.tb_next is not None:\n        error_frame = error_frame.tb_next\n\n    file = error_frame.tb_frame.f_code.co_filename\n    line = error_frame.tb_lineno\n    stack = traceback.extract_tb(tb)\n\n    formated_stack = []\n    for summary in stack:\n        formated_stack.append({\n            'file': summary[0],\n            'line': summary[1],\n            'func': summary[2],\n            'text': summary[3]\n        })\n\n    event = {\n        'was_doing':was_doing,\n        'message': ex_message,\n        'errorLocation': {\n            'file': file,\n            'line': line,\n            'full': file + ' -> ' + str(line)\n        },\n        'stack': formated_stack\n        #,\n        #'time': time.time()\n    }\n\n    try:\n        #logging.info('caught:'+pformat(event))\n        gbc.cry('caught:'+pformat(event))\n        print('Bubble3: written error to log')\n        print('Bubble3: tips for fixing this:')\n        print(helpfull_tips)\n\n    except Exception as e:\n        print('Bubble3: cant log error cause of %s' % e)", "response": "Catch and log an exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a DataSet object from a name.", "response": "def from_name(api_url, name, dry_run=False):\n        \"\"\"\n            doesn't require a token config param\n            as all of our data is currently public\n        \"\"\"\n        return DataSet(\n            '/'.join([api_url, name]).rstrip('/'),\n            token=None,\n            dry_run=dry_run\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_active_window():\n    active_win = None\n    default = wnck.screen_get_default()\n    while gtk.events_pending():\n        gtk.main_iteration(False)\n    window_list = default.get_windows()\n    if len(window_list) == 0:\n        print \"No Windows Found\"\n    for win in window_list:\n        if win.is_active():\n            active_win = win.get_name()\n    return active_win", "response": "Get the currently focused window"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self):\n\n        # get all network quota from Cloud Provider.\n        attrs = (\"networks\",\n                 \"security_groups\",\n                 \"floating_ips\",\n                 \"routers\",\n                 \"internet_gateways\")\n\n        for attr in attrs:\n            setattr(self, attr, eval(\"self.get_{}()\". format(attr)))", "response": "Get quota from Cloud Provider."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the union of one or more CSS classes as a space - separated string.", "response": "def join_css_class(css_class, *additional_css_classes):\n    \"\"\"\n    Returns the union of one or more CSS classes as a space-separated string.\n    Note that the order will not be preserved.\n    \"\"\"\n    css_set = set(chain.from_iterable(\n        c.split(' ') for c in [css_class, *additional_css_classes] if c))\n    return ' '.join(css_set)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_middlewares(self):\n        self.middleware = [DeserializeMiddleware()]\n        self.middleware += \\\n            [FuncMiddleware(hook) for hook in self.before_hooks()]\n        self.middleware.append(SerializeMiddleware())", "response": "Initialize hooks and middlewares\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_routes_and_middlewares(self):\n        self._init_middlewares()\n        self._init_endpoints()\n\n        self.app = falcon.API(middleware=self.middleware)\n        self.app.add_error_handler(Exception, self._error_handler)\n\n        for version_path, endpoints in self.catalog:\n            for route, resource in endpoints:\n                self.app.add_route(version_path + route, resource)", "response": "Initialize hooks and URI routes to resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_server_cls(self, host):\n        server_cls = simple_server.WSGIServer\n        if netutils.is_valid_ipv6(host):\n            if getattr(server_cls, 'address_family') == socket.AF_INET:\n                class server_cls(server_cls):\n                    address_family = socket.AF_INET6\n        return server_cls", "response": "Return an appropriate WSGI server class base on provided host."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlisten for HTTP requests.", "response": "def listen(self):\n        \"\"\"Self-host using 'bind' and 'port' from the WSGI config group.\"\"\"\n\n        msgtmpl = (u'Serving on host %(host)s:%(port)s')\n        host = CONF.wsgi.wsgi_host\n        port = CONF.wsgi.wsgi_port\n        LOG.info(msgtmpl,\n                 {'host': host, 'port': port})\n        server_cls = self._get_server_cls(host)\n        httpd = simple_server.make_server(host,\n                                          port,\n                                          self.app,\n                                          server_cls)\n        httpd.serve_forever()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_map(self):\n\n        # at state i is represented by the regex self.B[i]\n        for state_a in self.mma.states:\n            self.A[state_a.stateid] = {}\n            # Create a map state to state, with the transition symbols\n            for arc in state_a.arcs:\n                if arc.nextstate in self.A[state_a.stateid]:\n                    self.A[state_a.stateid][arc.nextstate].append(self.mma.isyms.find(arc.ilabel))\n                else:\n                    self.A[state_a.stateid][arc.nextstate] = [self.mma.isyms.find(arc.ilabel)]\n            if state_a.final:\n                self.A[state_a.stateid]['string'] = ['']", "response": "Initialize the map from state to state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the special set of promises for a run_instruction.", "response": "def get_promise(self):\n        \"\"\"Return the special set of promises for run_instruction.\n\n        Run Instruction has to support multiple promises (one for\n        reading data, and one for reading back the status from IR. All\n        other primitives have a single promise, so fitting multiple\n        into this system causes some API consistencies.\n\n        This should be reviewed to see if a more coherent alternative\n        is available.\n\n        \"\"\"\n        if self._promise is None:\n            promise = []\n            if self.read:\n                promise.append(TDOPromise(self._chain, 0, self.bitcount))\n            else:\n                promise.append(None)\n            if self.read_status:\n                promise.append(TDOPromise(self._chain, 0,\n                                          self.dev._desc._ir_length))\n            else:\n                promise.append(None)\n            self._promise = promise\n        return self._promise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn html for a chart", "response": "def get(self, slug, xdata, ydatasets, label, opts, style, ctype):\n        \"\"\"\n        Returns html for a chart\n        \"\"\"\n        xdataset = self._format_list(xdata)\n        width = \"100%\"\n        height = \"300px\"\n        if opts is not None:\n            if \"width\" in opts:\n                width = str(opts[\"width\"])\n            if \"height\" in opts:\n                height = str(opts[\"height\"])\n        stylestr = '<style>#container_' + slug + \\\n            ' { width:' + width + ' !important; height:' + \\\n            height + ' !important}</style>\\n'\n        html = stylestr\n        html += '<div id=\"container_' + slug + \\\n            '\"><canvas id=\"canvas_' + slug + '\"></canvas></div>\\n'\n        html += '<script>\\n'\n        html += 'var data = {\\n'\n        html += 'labels: ' + xdataset + ',\\n'\n        html += 'datasets:[\\n'\n        colors = None\n        if \"color\" in style:\n            colors = style[\"color\"]\n        i = 0\n        for dataset in ydatasets:\n            name = dataset[\"name\"]\n            data = dataset[\"data\"]\n            html += self._get_dataset(data, name, colors)\n            if i < len(ydatasets) - 1:\n                html += \",\"\n            i += 1\n        html += ']\\n'\n        html += '}\\n'\n\n        html += 'window.onload = function() {'\n        html += 'var ctx = document.getElementById(\"canvas_' + \\\n                slug + '\").getContext(\"2d\");'\n        html += 'window.myChart = new Chart(ctx, {'\n        html += 'type: \"' + ctype + '\",'\n        html += 'data: data,'\n        html += 'options: {'\n        html += 'spanGaps: false,'\n        html += 'responsive: true,'\n        html += 'maintainAspectRatio: false,'\n        if \"legend\" in opts:\n            html += 'legend: {'\n            html += 'position: \"' + opts[\"legend\"] + '\",'\n            html += '},'\n        else:\n            html += 'legend: {'\n            html += 'display: false,'\n            html += '},'\n        if \"title\" in opts:\n            html += 'title: {'\n            html += 'display: true,'\n            html += 'text: \"' + opts[\"title\"] + '\"'\n            html += '}'\n        html += '}'\n        html += '});'\n        html += '};'\n        html += '</script>\\n'\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_list(self, data):\n        dataset = \"[\"\n        i = 0\n        for el in data:\n            if pd.isnull(el):\n                dataset += \"null\"\n            else:\n                dtype = type(data[i])\n                if dtype == int or dtype == float:\n                    dataset += str(el)\n                else:\n                    dataset += '\"' + el + '\"'\n            if i < len(data) - 1:\n                dataset += ', '\n        dataset += \"]\"\n        return dataset", "response": "Format a list of items to use in javascript"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(self, status, headers=None):\n        '''\n        Respond with given status and no content\n\n        :type status: int\n        :param status: status code to return\n\n        :type headers: dict\n        :param headers: dictionary of headers to add to response\n\n        :returns: itself\n        :rtype: Rule\n        '''\n        self.response = _Response(status, headers)\n        return self", "response": "Respond with given status and no content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrespond with given status and text content.", "response": "def text(self, text, status=200, headers=None):\n        '''\n        Respond with given status and text content\n\n        :type text: str\n        :param text: text to return\n\n        :type status: int\n        :param status: status code to return\n\n        :type headers: dict\n        :param headers: dictionary of headers to add to response\n\n        :returns: itself\n        :rtype: Rule\n        '''\n        self.response = _Response(status, headers, text.encode('utf8'))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresponding with given status and JSON content. Will also set Content - Type to a specific header. Will also set Content - Type to a specific header.", "response": "def json(self, json_doc, status=200, headers=None):\n        '''\n        Respond with given status and JSON content. Will also set ``'Content-Type'`` to\n        ``'applicaion/json'`` if header is not specified explicitly\n\n        :type json_doc: dict\n        :param json_doc: dictionary to respond with converting to JSON string\n\n        :type status: int\n        :param status: status code to return\n\n        :type headers: dict\n        :param headers: dictionary of headers to add to response\n        '''\n        headers = headers or {}\n        if 'content-type' not in headers:\n            headers['content-type'] = 'application/json'\n        return self.text(json.dumps(json_doc), status, headers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if this rule matches given request parameters", "response": "def matches(self, method, path, headers, bytes=None):\n        '''\n        Checks if rule matches given request parameters\n\n        :type method: str\n        :param method: HTTP method, e.g. ``'GET'``, ``'POST'``, etc.\n            Can take any custom string\n\n        :type path: str\n        :param path: request path including query parameters,\n            e.g. ``'/users?name=John%20Doe'``\n\n        :type bytes: bytes\n        :param bytes: request body\n\n        :returns: ``True`` if this rule matches given params\n        :rtype: bool\n        '''\n        return self._expectation.matches(method, path, headers, bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef always(self, method, path=None, headers=None, text=None, json=None):\n        '''\n        Sends response every time matching parameters are found util :func:`Server.reset` is called\n\n        :type method: str\n        :param method: request method: ``'GET'``, ``'POST'``, etc. can be some custom string\n\n        :type path: str\n        :param path: request path including query parameters\n\n        :type headers: dict\n        :param headers: dictionary of headers to expect. If omitted any headers will do\n\n        :type text: str\n        :param text: request text to expect. If ommited any text will match\n\n        :type json: dict\n        :param json: request json to expect. If ommited any json will match,\n            if present text param will be ignored\n\n        :rtype: Rule\n        :returns: newly created expectation rule\n        '''\n        rule = Rule(method, path, headers, text, json)\n        return self._add_rule_to(rule, self._always_rules)", "response": "Sends response every time matching parameters are found util. Server. reset is called"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend response to matching parameters one time and removes it from list of expectations", "response": "def on(self, method, path=None, headers=None, text=None, json=None):\n        '''\n        Sends response to matching parameters one time and removes it from list of expectations\n\n        :type method: str\n        :param method: request method: ``'GET'``, ``'POST'``, etc. can be some custom string\n\n        :type path: str\n        :param path: request path including query parameters\n\n        :type headers: dict\n        :param headers: dictionary of headers to expect. If omitted any headers will do\n\n        :type text: str\n        :param text: request text to expect. If ommited any text will match\n\n        :type json: dict\n        :param json: request json to expect. If ommited any json will match,\n            if present text param will be ignored\n\n        :rtype: Rule\n        :returns: newly created expectation rule\n        '''\n        rule = Rule(method, path, headers, text, json)\n        return self._add_rule_to(rule, self._rules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a server on the port provided in the Server constructor in a separate thread.", "response": "def start(self):\n        '''\n        Starts a server on the port provided in the :class:`Server` constructor\n        in a separate thread\n\n        :rtype: Server\n        :returns: server instance for chaining\n        '''\n        self._handler = _create_handler_class(self._rules, self._always_rules)\n        self._server = HTTPServer(('', self._port), self._handler)\n        self._thread = Thread(target=self._server.serve_forever, daemon=True)\n        self._thread.start()\n        self.running = True\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self):\n        '''\n        Shuts the server down and waits for server thread to join\n        '''\n        self._server.shutdown()\n        self._server.server_close()\n        self._thread.join()\n        self.running = False", "response": "Shuts down the server and waits for the server thread to join the thread"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_no_pending(self, target_rule=None):\n        '''\n        Raises a :class:`PendingRequestsLeftException` error if server has target rule\n        non-resolved.\n\n        When target_rule argument is ommitted raises if server has any pending\n        expectations.\n\n        Useful in ``tearDown()`` test method to verify that test had correct expectations\n\n        :type target_rule: Rule\n        :param target_rule: will raise if this rule is left pending\n\n        :raises: :class:`PendingRequestsLeftException`\n        '''\n        if target_rule:\n            if target_rule in self._rules:\n                raise PendingRequestsLeftException()\n        elif self._rules:\n            raise PendingRequestsLeftException()", "response": "Raises a : class:`PendingRequestsLeftException` error if server has no pending expectations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a URL based on the inputted path and query options and fragment.", "response": "def build(path, query=None, fragment=''):\n    \"\"\"\n    Generates a URL based on the inputted path and given query options and\n    fragment.  The query should be a dictionary of terms that will be\n    generated into the URL, while the fragment is the anchor point within the\n    target path that will be navigated to.  If there are any wildcards within\n    the path that are found within the query, they will be inserted into the\n    path itself and removed from the query string.\n    \n    :example    |>>> import skyline.gui\n                |>>> skyline.gui.build_url('sky://projects/%(project)s',\n                |                          {'project': 'Test', 'asset': 'Bob'})\n                |'sky://projects/Test/?asset=Bob'\n    \n    :param      path        | <str>\n                query       | <dict> || None\n                fragment    | <str> || None\n    \n    :return     <str> | url\n    \"\"\"\n    url = nstr(path)\n\n    # replace the optional arguments in the url\n    keys = projex.text.findkeys(path)\n    if keys:\n        if query is None:\n            query = {}\n\n        opts = {}\n        for key in keys:\n            opts[key] = query.pop(key, '%({})s'.format(key))\n\n        url %= opts\n\n    # add the query\n    if query:\n        if type(query) is dict:\n            mapped_query = {}\n            for key, value in query.items():\n                mapped_query[nstr(key)] = nstr(value)\n            query_str = urllib.urlencode(mapped_query)\n        else:\n            query_str = nstr(query)\n\n        url += '?' + query_str\n\n    # include the fragment\n    if fragment:\n        url += '#' + fragment\n\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse out the information for this url and returns its components expanded out to Python objects.", "response": "def parse(url):\n    \"\"\"\n    Parses out the information for this url, returning its components\n    expanded out to Python objects.\n    \n    :param      url | <str>\n    \n    :return     (<str> path, <dict> query, <str> fragment)\n    \"\"\"\n    result = urlparse.urlparse(nstr(url))\n\n    path = result.scheme + '://' + result.netloc\n    if result.path:\n        path += result.path\n\n    query = {}\n\n    # extract the python information from the query\n    if result.query:\n        url_query = urlparse.parse_qs(result.query)\n        for key, value in url_query.items():\n            if type(value) == list and len(value) == 1:\n                value = value[0]\n\n            query[key] = value\n\n    return path, query, result.fragment"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a new scheme to the urlparser.", "response": "def register(scheme):\n    \"\"\"\n    Registers a new scheme to the urlparser.\n    \n    :param      schema | <str>\n    \"\"\"\n    scheme = nstr(scheme)\n    urlparse.uses_fragment.append(scheme)\n    urlparse.uses_netloc.append(scheme)\n    urlparse.uses_params.append(scheme)\n    urlparse.uses_query.append(scheme)\n    urlparse.uses_relative.append(scheme)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, stats):\n        \"Format stats and send to one or more Graphite hosts\"\n        buf = cStringIO.StringIO()\n        now = int(time.time())\n        num_stats = 0\n\n        # timer stats\n        pct = stats.percent\n        timers = stats.timers\n        for key, vals in timers.iteritems():\n            if not vals:\n                continue\n\n            # compute statistics\n            num = len(vals)\n            vals = sorted(vals)\n            vmin = vals[0]\n            vmax = vals[-1]\n            mean = vmin\n            max_at_thresh = vmax\n            if num > 1:\n                idx = round((pct / 100.0) * num)\n                tmp = vals[:int(idx)]\n                if tmp:\n                    max_at_thresh = tmp[-1]\n                    mean = sum(tmp) / idx\n\n            key = 'stats.timers.%s' % key\n            buf.write('%s.mean %f %d\\n' % (key, mean, now))\n            buf.write('%s.upper %f %d\\n' % (key, vmax, now))\n            buf.write('%s.upper_%d %f %d\\n' % (key, pct, max_at_thresh, now))\n            buf.write('%s.lower %f %d\\n' % (key, vmin, now))\n            buf.write('%s.count %d %d\\n' % (key, num, now))\n            num_stats += 1\n\n        # counter stats\n        counts = stats.counts\n        for key, val in counts.iteritems():\n            buf.write('stats.%s %f %d\\n' % (key, val / stats.interval, now))\n            buf.write('stats_counts.%s %f %d\\n' % (key, val, now))\n            num_stats += 1\n\n        # counter stats\n        gauges = stats.gauges\n        for key, val in gauges.iteritems():\n            buf.write('stats.%s %f %d\\n' % (key, val, now))\n            buf.write('stats_counts.%s %f %d\\n' % (key, val, now))\n            num_stats += 1\n\n        buf.write('statsd.numStats %d %d\\n' % (num_stats, now))\n\n        # TODO: add support for N retries\n\n        for host in self._hosts:\n            # flush stats to graphite\n            try:\n                sock = socket.create_connection(host)\n                sock.sendall(buf.getvalue())\n                sock.close()\n            except Exception, ex:\n                self.error(E_SENDFAIL % ('graphite', host, ex))", "response": "Format stats and send to one or more Graphite hosts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef coerce(self, value):\r\n        if isinstance(value, compat.basestring):\r\n\r\n            return value\r\n\r\n        return str(value)", "response": "Convert any value into a string representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef coerce(self, value):\r\n        if not isinstance(value, compat.basestring):\r\n\r\n            value = str(value)\r\n\r\n        if not self._re.match(value):\r\n\r\n            raise ValueError(\r\n                \"The value {0} does not match the pattern {1}\".format(\r\n                    value,\r\n                    self.pattern,\r\n                )\r\n            )\r\n\r\n        return value", "response": "Converts a value into a pattern matched string value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreceiving all passed in args kwargs and combine them together with any required params", "response": "def get_payload(self, *args, **kwargs):\n        \"\"\"Receive all passed in args, kwargs, and combine them together with any required params\"\"\"\n        if not kwargs:\n            kwargs = self.default_params\n        else:\n            kwargs.update(self.default_params)\n        for item in args:\n            if isinstance(item, dict):\n                kwargs.update(item)\n        if hasattr(self, 'type_params'):\n            kwargs.update(self.type_params(*args, **kwargs))\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def read_frame(self) -> DataFrame:\n        if self._data_frames.qsize() == 0 and self.closed:\n            raise StreamConsumedError(self.id)\n        frame = await self._data_frames.get()\n        self._data_frames.task_done()\n        if frame is None:\n            raise StreamConsumedError(self.id)\n        return frame", "response": "Read a single frame from the local buffer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a single frame from the local buffer immediately.", "response": "def read_frame_nowait(self) -> Optional[DataFrame]:\n        \"\"\"Read a single frame from the local buffer immediately.\n\n        If no frames are available but the stream is still open, returns None.\n        Otherwise, raises StreamConsumedError.\n        \"\"\"\n        try:\n            frame = self._data_frames.get_nowait()\n        except asyncio.QueueEmpty:\n            if self.closed:\n                raise StreamConsumedError(self.id)\n            return None\n        self._data_frames.task_done()\n        if frame is None:\n            raise StreamConsumedError(self.id)\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plucks(obj, selector, default=None):\n    \n    def _filter(iterable, index):\n        res = []\n        for obj in iterable:\n            try:\n                res.append(obj[index])\n            except:\n                pass\n        return res\n\n    def _int(val):\n        try:\n            return int(val)\n        except:\n            return None\n\n    def _parsekey(key):\n        m = re.match(r\"^(?P<index>-?\\d+)$\", key)\n        if m:\n            return int(m.group('index'))\n\n        m = re.match(r\"^(?P<start>-?\\d+)?\"\\\n                     r\"(:(?P<stop>-?\\d+)?(:(?P<step>-?\\d+)?)?)?$\", key)\n        if m:\n            return slice(_int(m.group('start')),\n                         _int(m.group('stop')),\n                         _int(m.group('step')))\n\n        if key == '*':\n            return slice(None)\n\n        return key\n\n    miss = False\n    for key in selector.split('.'):\n        index = _parsekey(key)\n        \n        if miss:\n            if isinstance(index, basestring):\n                obj = {}\n            else:\n                obj = []\n        \n        try:\n            if isinstance(index, basestring):\n                if isinstance(obj, list):\n                    obj = _filter(obj, index)\n                else:\n                    obj = obj[index]\n            else:\n                obj = obj[index]\n            miss = False\n        except:\n            miss = True\n    \n    if miss:\n        return default\n    else:\n        return obj", "response": "Safe itemgetter for structured objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pluck(obj, selector, default=None, skipmissing=True):\n    if not selector:\n        return obj\n    if selector[0] != '[':\n        selector = '.%s' % selector\n    wrapped_obj = pluckable(obj, default=default, skipmissing=skipmissing, inplace=True)\n    return eval(\"wrapped_obj%s.value\" % selector)", "response": "A simple wrapper around pluckable that accepts more complex\n    selectors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge(a, b, op=None, recurse_list=False, max_depth=None):\n\n    if op is None:\n        op = operator.add\n\n    if max_depth is not None:\n        if max_depth < 1:\n            return op(a, b)\n        else:\n            max_depth -= 1\n\n    if isinstance(a, dict) and isinstance(b, dict):\n        result = {}\n        for key in set(chain(a.keys(), b.keys())):\n            if key in a and key in b:\n                result[key] = merge(a[key], b[key],\n                                    op=op, recurse_list=recurse_list,\n                                    max_depth=max_depth)\n            elif key in a:\n                result[key] = deepcopy(a[key])\n            elif key in b:\n                result[key] = deepcopy(b[key])\n        return result\n\n    elif isinstance(a, list) and isinstance(b, list):\n        if recurse_list and len(a) == len(b):\n            # merge subelements\n            result = []\n            for idx in range(len(a)):\n                result.append(merge(a[idx], b[idx],\n                                    op=op, recurse_list=recurse_list,\n                                    max_depth=max_depth))\n            return result\n        else:\n            # merge lists\n            return op(a, b)\n\n    # all other merge ops should be handled by ``op``.\n    # default ``operator.add`` will handle addition of numeric types, but fail\n    # with TypeError for incompatible types (eg. str + None, etc.)\n    return op(a, b)", "response": "Immutable merge a structure with b using binary operator op on leaf nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readProfile(filename):\n  p    = profile_parser.Parser()\n  accu = TermSet()\n  file = open(filename,'r')\n  s    = file.readline()\n  while s!=\"\":\n    try:\n      accu = p.parse(s,filename)\n    except EOFError:\n      break\n    s = file.readline()\n\n  return accu", "response": "Reads a profile description file and returns a TermSet object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _param_deprecation_warning(schema, deprecated, context):\r\n    for i in deprecated:\r\n        if i in schema:\r\n                msg = 'When matching {ctx}, parameter {word} is deprecated, use __{word}__ instead'\r\n                msg = msg.format(ctx = context, word = i)\r\n                warnings.warn(msg, Warning)", "response": "Raises a warning about using the old names for some parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check(schema, data, trace=False):\r\n    if trace == True:\r\n        trace = 1\r\n    else:\r\n        trace = None\r\n    return _check(schema, data, trace=trace)", "response": "Verify some json object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntesting if a user has permission for a single action and object.", "response": "def has_perm(self, user, perm, obj=None, *args, **kwargs):\n        \"\"\"Test user permissions for a single action and object.\n\n        :param user: The user to test.\n        :type user: ``User``\n        :param perm: The action to test.\n        :type perm: ``str``\n        :param obj: The object path to test.\n        :type obj: ``tutelary.engine.Object``\n        :returns: ``bool`` -- is the action permitted?\n        \"\"\"\n        try:\n            if not self._obj_ok(obj):\n                if hasattr(obj, 'get_permissions_object'):\n                    obj = obj.get_permissions_object(perm)\n                else:\n                    raise InvalidPermissionObjectException\n            return user.permset_tree.allow(Action(perm), obj)\n        except ObjectDoesNotExist:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of permitted actions for an object or object pattern.", "response": "def permitted_actions(self, user, obj=None):\n        \"\"\"Determine list of permitted actions for an object or object\n        pattern.\n\n        :param user: The user to test.\n        :type user: ``User``\n        :param obj: A function mapping from action names to object\n                    paths to test.\n        :type obj: callable\n        :returns: ``list(tutelary.engine.Action)`` -- permitted actions.\n\n        \"\"\"\n        try:\n            if not self._obj_ok(obj):\n                raise InvalidPermissionObjectException\n            return user.permset_tree.permitted_actions(obj)\n        except ObjectDoesNotExist:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating the options and exit", "response": "def validate(self,options):\n        \"\"\"\n        Validate the options or exit()\n        \"\"\"\n        if not options.port:\n            self.parser.error(\"'port' is required\")\n        if options.port == options.monitor_port:\n            self.parser.error(\"'port' and 'monitor-port' must not be the same.\")\n        if options.buffer_size <= 0:\n            self.parser.error(\"'buffer_size' must be > 0.\")\n        try:\n            codecs.getencoder(options.char_encoding)\n        except LookupError:\n            self.parser.error(\"invalid 'char-encoding' %s\" % options.char_encoding)\n\n        if not options.host:\n           options.host = socket.gethostname()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the games in the specified resource.", "response": "def list(self, name, platform='', genre=''):\n        \"\"\" The name argument is required for this method as per the API\n        server specification. This method also provides the platform and genre\n        optional arguments as filters.\n        \"\"\"\n        data_list = self.db.get_data(self.list_path, name=name,\n                                     platform=platform, genre=genre)\n        data_list = data_list.get('Data') or {}\n        games = data_list.get('Game') or []\n        return [self._build_item(**i) for i in games]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(self):\n        data_list = self.db.get_data(self.list_path)\n        data_list = data_list.get('Data') or {}\n        platforms = (data_list.get('Platforms') or {}).get('Platform') or []\n        return [self._build_item(**i) for i in platforms]", "response": "Returns a list of all the available items for the current server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove None values from dict.", "response": "def remove_none_dict_values(obj):\n    \"\"\"\n    Remove None values from dict.\n    \"\"\"\n    if isinstance(obj, (list, tuple, set)):\n        return type(obj)(remove_none_dict_values(x) for x in obj)\n    elif isinstance(obj, dict):\n        return type(obj)((k, remove_none_dict_values(v))\n                         for k, v in obj.items()\n                         if v is not None)\n    else:\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_history(cloud_hero):\n    user_command = ' '.join(sys.argv)\n    timestamp = int(time.time())\n    command = (user_command, timestamp)\n    cloud_hero.send_history([command])", "response": "Send each command to the history endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_scenfit(instance, OS, FP, FC, EP):\n  '''returns the scenfit of data and model described by the\n  ``TermSet`` object [instance].\n  '''\n  sem = [sign_cons_prg, bwd_prop_prg]\n  if OS : sem.append(one_state_prg)\n  if FP : sem.append(fwd_prop_prg)\n  if FC : sem.append(founded_prg)\n  if EP : sem.append(elem_path_prg)\n\n\n  inst     = instance.to_file()\n  prg      = sem + scenfit + [inst]\n  coptions = '--opt-strategy=5'\n  solver   = GringoClasp(clasp_options=coptions)\n  solution = solver.run(prg,collapseTerms=True,collapseAtoms=False)\n  opt      = solution[0].score[0]\n\n  os.unlink(inst)\n  return opt", "response": "returns the scenfit of data and model described by the\n \u2013 instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of atmost nm TermSet representing scenfit labelings at most OS FP FC and EP.", "response": "def get_scenfit_labelings(instance,nm, OS, FP, FC, EP):\n  '''\n  returns a list of atmost [nm] ``TermSet`` representing scenfit labelings\n  to the system described by the ``TermSet`` object [instance].\n  '''\n  sem = [sign_cons_prg, bwd_prop_prg]\n  if OS : sem.append(one_state_prg)\n  if FP : sem.append(fwd_prop_prg)\n  if FC : sem.append(founded_prg)\n  if EP : sem.append(elem_path_prg)\n\n  inst     = instance.to_file()\n  prg      = sem + scenfit + [inst]\n  coptions = '--opt-strategy=5'\n  solver   = GringoClasp(clasp_options=coptions)\n  solution = solver.run(prg,collapseTerms=True,collapseAtoms=False)\n\n  opt      = solution[0].score[0]\n\n  prg      = prg + [show_labels_prg, show_err_prg]\n  coptions = str(nm)+' --project --opt-strategy=5 --opt-mode=optN --opt-bound='+str(opt)\n  solver2  = GringoClasp(clasp_options=coptions)\n  models   = solver2.run(prg,collapseTerms=True,collapseAtoms=False)\n\n  os.unlink(inst)\n  return models"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_opt_repairs_add_remove_edges_greedy(instance,nm, edges):\n  '''\n   only apply with elementary path consistency notion\n  '''\n\n  sem      = [sign_cons_prg, elem_path_prg, fwd_prop_prg, bwd_prop_prg]\n  inst     = instance.to_file()\n  f_edges  = TermSet(edges).to_file()\n  prg      = [ inst, f_edges, remove_edges_prg,\n               min_repairs_prg, show_rep_prg,\n             ] + sem + scenfit\n  coptions = str(nm)+' --project --opt-strategy=5 --opt-mode=optN --quiet=1'\n  solver   = GringoClasp(clasp_options=coptions)\n  models   = solver.run(prg, collapseTerms=True, collapseAtoms=False)\n  #print(models)\n  #nscenfit  = models[0].score[0]\n  #nrepscore = models[0].score[1]\n  #print('scenfit:   ', nscenfit)\n  #print('repscore:  ', nrepscore)\n\n  os.unlink(f_edges)\n  os.unlink(inst)\n  return models", "response": "get opt - repairs for a given instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the function is applicable to this .", "response": "def validate_implementation_for_auto_decode_and_soupify(func):\n    \"\"\"\n    Validate that :func:`auto_decode_and_soupify` is applicable to this\n    function. If not applicable, a ``NotImplmentedError`` will be raised.\n    \"\"\"\n    arg_spec = inspect.getargspec(func)\n    for arg in [\"response\", \"html\", \"soup\"]:\n        if arg not in arg_spec.args:\n            raise NotImplementedError(\n                (\"{func} method has to take the keyword syntax input: \"\n                 \"{arg}\").format(func=func, arg=arg)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef auto_decode_and_soupify(encoding=None, errors=decoder.ErrorsHandle.strict):\n\n    def deco(func):\n        func_hash = hash(func)\n        if not _auto_decode_and_soupify_implementation_ok_mapper \\\n                .get(func_hash, False):\n            validate_implementation_for_auto_decode_and_soupify(func)\n            _auto_decode_and_soupify_implementation_ok_mapper[func_hash] = True\n\n        def wrapper(*args, **kwargs):\n            try:\n                response = kwargs.get(\"response\")\n                html = kwargs.get(\"html\")\n                soup = kwargs.get(\"soup\")\n            except KeyError as e:\n                raise NotImplementedError(\n                    (\"{func} method has to take the keyword syntax input: \"\n                     \"{e}\").format(func=func, e=e)\n                )\n\n            if html is None:\n                binary = access_binary(response)\n                try:\n                    html = decoder.decode(\n                        binary=binary,\n                        url=response.url,\n                        encoding=encoding,\n                        errors=errors,\n                    )\n                except Exception as e:  # pragma: no cover\n                    raise DecodeError(str(e))\n                kwargs[\"html\"] = html\n\n            if soup is None:\n                soup = soupify(html)\n                kwargs[\"soup\"] = soup\n\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return deco", "response": "Decorator to automatically decode and soupify a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck to see if two values are equal to each other.", "response": "def check(a, b):\n    \"\"\"\n    Checks to see if the two values are equal to each other.\n    \n    :param      a | <str>\n                b | <str>\n    \n    :return     <bool>\n    \"\"\"\n    aencrypt = encrypt(a)\n    bencrypt = encrypt(b)\n\n    return a == b or a == bencrypt or aencrypt == b"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decodeBase64(text, encoding='utf-8'):\n    text = projex.text.toBytes(text, encoding)\n    return projex.text.toUnicode(base64.b64decode(text), encoding)", "response": "Decodes a base 64 string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decrypt(text, key=None):\n    if key is None:\n        key = ENCRYPT_KEY\n\n    bits = len(key)\n    text = base64.b64decode(text)\n    iv = text[:16]\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    return unpad(cipher.decrypt(text[16:]))", "response": "Decrypts the inputted text using the inputted key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decryptfile(filename, key=None, outfile=None, chunk=64 * 1024):\n    if key is None:\n        key = ENCRYPT_KEY\n\n    if not outfile:\n        outfile = os.path.splitext(filename)[0]\n\n    with open(filename, 'rb') as input:\n        origsize = struct.unpack('<Q', input.read(struct.calcsize('Q')))[0]\n        iv = input.read(16)\n        cipher = AES.new(key, AES.MODE_CBC, iv)\n\n        with open(outfile, 'wb') as output:\n            while True:\n                data = input.read(chunk)\n                if len(data) == 0:\n                    break\n\n                data = cipher.decrypt(data)\n                data = unpad(data)\n                output.write(data)\n                output.truncate(origsize)", "response": "Decrypts a file with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding a base 64 string.", "response": "def encodeBase64(text, encoding='utf-8'):\n    \"\"\"\n    Decodes a base 64 string.\n    \n    :param      text | <str>\n                encoding | <str>\n    \n    :return     <str>\n    \"\"\"\n    text = projex.text.toBytes(text, encoding)\n    return base64.b64encode(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencrypts the inputted text using the AES cipher.", "response": "def encrypt(text, key=None):\n    \"\"\"\n    Encrypts the inputted text using the AES cipher.  If the PyCrypto\n    module is not included, this will simply encode the inputted text to\n    base64 format.\n    \n    :param      text    | <str>\n                key     | <str>\n    \n    :return     <str>\n    \"\"\"\n    if key is None:\n        key = ENCRYPT_KEY\n\n    bits = len(key)\n    text = pad(text, bits)\n    iv = Random.new().read(16)\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    return base64.b64encode(iv + cipher.encrypt(text))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encryptfile(filename, key=None, outfile=None, chunk=64 * 1024):\n    if key is None:\n        key = ENCRYPT_KEY\n\n    if not outfile:\n        outfile = filename + '.enc'\n\n    iv = Random.new().read(16)\n    cipher = AES.new(key, AES.MODE_CBC, iv)\n    filesize = os.path.getsize(filename)\n\n    with open(filename, 'rb') as input:\n        with open(outfile, 'wb') as output:\n            output.write(struct.pack('<Q', filesize))\n            output.write(iv)\n\n            while True:\n                data = input.read(chunk)\n                if len(data) == 0:\n                    break\n\n                data = pad(data, len(key))\n                output.write(cipher.encrypt(data))", "response": "Encrypts a file with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generateKey(password, bits=32):\n    if bits == 32:\n        hasher = hashlib.sha256\n    elif bits == 16:\n        hasher = hashlib.md5\n    else:\n        raise StandardError('Invalid hash type')\n\n    return hasher(password).digest()", "response": "Generates a new encryption key based on the inputted password."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a random token based on the given parameters.", "response": "def generateToken(bits=32):\n    \"\"\"\n    Generates a random token based on the given parameters.\n    \n    :return     <str>\n    \"\"\"\n    if bits == 64:\n        hasher = hashlib.sha256\n    elif bits == 32:\n        hasher = hashlib.md5\n    else:\n        raise StandardError('Unknown bit level.')\n    return hasher(nstr(random.getrandbits(256))).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npad the inputted text to ensure it fits the proper block length for encryption.", "response": "def pad(text, bits=32):\n    \"\"\"\n    Pads the inputted text to ensure it fits the proper block length\n    for encryption.\n    \n    :param      text | <str>\n                bits | <int>\n    \n    :return     <str>\n    \"\"\"\n    return text + (bits - len(text) % bits) * chr(bits - len(text) % bits)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize a client object based on given version.", "response": "def Client(version=__version__, resource=None, provider=None, **kwargs):\n    \"\"\"Initialize client object based on given version.\n\n    :params version: version of CAL, define at setup.cfg\n    :params resource: resource type\n                     (network, compute, object_storage, block_storage)\n    :params provider: provider object\n    :params cloud_config: cloud auth config\n    :params **kwargs: specific args for resource\n    :return: class Client\n\n    HOW-TO:\n    The simplest way to create a client instance is initialization::\n\n        >> from calplus import client\n        >> calplus = client.Client(version='1.0.0',\n                               resource='compute',\n                               provider=provider_object,\n                               some_needed_args_for_ComputeClient)\n    \"\"\"\n\n    versions = _CLIENTS.keys()\n\n    if version not in versions:\n        raise exceptions.UnsupportedVersion(\n            'Unknown client version or subject'\n        )\n\n    if provider is None:\n        raise exceptions.ProviderNotDefined(\n            'Not define Provider for Client'\n        )\n\n    support_types = CONF.providers.driver_mapper.keys()\n\n    if provider.type not in support_types:\n        raise exceptions.ProviderTypeNotFound(\n            'Unknow provider.'\n        )\n\n    resources = _CLIENTS[version].keys()\n\n    if not resource:\n        raise exceptions.ResourceNotDefined(\n            'Not define Resource, choose one: compute, network,\\\n            object_storage, block_storage.'\n        )\n\n    elif resource.lower() not in resources:\n        raise exceptions.ResourceNotFound(\n            'Unknow resource: compute, network,\\\n                        object_storage, block_storage.'\n        )\n\n    LOG.info('Instantiating {} client ({})' . format(resource, version))\n\n    return _CLIENTS[version][resource](\n        provider.type, provider.config, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the accession number from commonly supported formats.", "response": "def accession(self):\n        \"\"\"\n        Parse accession number from commonly supported formats.\n\n        If the defline does not match one of the following formats, the entire\n        description (sans leading caret) will be returned.\n\n        * >gi|572257426|ref|XP_006607122.1|\n        * >gnl|Tcas|XP_008191512.1\n        * >lcl|PdomMRNAr1.2-10981.1\n        \"\"\"\n        accession = None\n        if self.defline.startswith('>gi|'):\n            match = re.match('>gi\\|\\d+\\|[^\\|]+\\|([^\\|\\n ]+)', self.defline)\n            if match:\n                accession = match.group(1)\n        elif self.defline.startswith('>gnl|'):\n            match = re.match('>gnl\\|[^\\|]+\\|([^\\|\\n ]+)', self.defline)\n            if match:\n                accession = match.group(1)\n        elif self.defline.startswith('>lcl|'):\n            match = re.match('>lcl\\|([^\\|\\n ]+)', self.defline)\n            if match:\n                accession = match.group(1)\n        return accession"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a sequence in a readable format.", "response": "def format_seq(self, outstream=None, linewidth=70):\n        \"\"\"\n        Print a sequence in a readable format.\n\n        :param outstream: if `None`, formatted sequence is returned as a\n                          string; otherwise, it is treated as a file-like\n                          object and the formatted sequence is printed to the\n                          outstream\n        :param linewidth: width for wrapping sequences over multiple lines; set\n                          to 0 for no wrapping\n        \"\"\"\n        if linewidth == 0 or len(self.seq) <= linewidth:\n            if outstream is None:\n                return self.seq\n            else:\n                print(self.seq, file=outstream)\n                return\n\n        i = 0\n        seq = ''\n        while i < len(self.seq):\n            if outstream is None:\n                seq += self.seq[i:i+linewidth] + '\\n'\n            else:\n                print(self.seq[i:i+linewidth], file=outstream)\n            i += linewidth\n        if outstream is None:\n            return seq"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasking every matcher that it can serve such filter data", "response": "def get_validator(filter_data):\n    \"\"\"\n    ask every matcher whether it can serve such filter data\n\n    :param filter_data:\n    :return:\n    \"\"\"\n    for matcher_type, m in matchers.items():\n        if hasattr(m, 'can_handle') and m.can_handle(filter_data):\n            filter_data = m.handle(filter_data)\n\n    return filter_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort(self, attr):\n        self.entries = Sorter(self.entries, self.category, attr).sort_entries()\n        return self", "response": "Sort the ratings based on an attribute"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_title(self):\n        if self.category == 'cable':\n            strings = get_strings(self.soup, 'strong')\n        else:\n            strings = get_strings(self.soup, 'b')\n\n        if len(strings) == 0:\n            strings = get_strings(self.soup, 'strong')\n\n        if len(strings) >= 1 and self.category == 'cable':\n            return strings[0]\n        elif len(strings) > 0 and 'Fast' in strings[-1]:\n            return strings[0]\n\n        return ''.join(strings)", "response": "Return the title of the cable ratings page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_json(self):\n        ratings_dict = {\n            'category': self.category,\n            'date': self.date,\n            'day': self.weekday,\n            'next week': self.next_week,\n            'last week': self.last_week,\n            'entries': self.entries,\n            'url': self.url\n        }\n        return to_json(ratings_dict)", "response": "Serialize ratings object as JSON - formatted string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of each parameter to be used for the url format.", "response": "def _get_url_params(self, shorten=True):\n        \"\"\"Returns a list of each parameter to be used for the url format.\"\"\"\n        cable = True if self.category == 'cable' else False\n        url_date = convert_month(self.date, shorten=shorten, cable=cable)\n\n        return [\n            BASE_URL,\n            self.weekday.lower(),\n            self.category + '-ratings',\n            url_date.replace(' ', '-')\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _match_show(self, show):\n        if self.show:\n            return match_list(self.show, show)\n        else:\n            return True", "response": "Match a query for a specific show or list of shows"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmatches a query for a specific network or list of networks", "response": "def _match_net(self, net):\n        \"\"\"Match a query for a specific network/list of networks\"\"\"\n        if self.network:\n            return match_list(self.network, net)\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying the ratings page matches the correct date", "response": "def _verify_page(self):\n        \"\"\"Verify the ratings page matches the correct date\"\"\"\n        title_date = self._get_date_in_title().lower()\n        split_date = self.date.lower().split()\n        split_date[0] = split_date[0][:3]\n        return all(term in title_date for term in split_date)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo a limited search for the correct url.", "response": "def _get_ratings_page(self):\n        \"\"\"Do a limited search for the correct url.\"\"\"\n        # Use current posted date to build url\n        self._build_url()\n        soup = get_soup(self.url)\n        if soup:\n            return soup\n\n        # Try building url again with unshortened month\n        self._build_url(shorten=False)\n        soup = get_soup(self.url)\n        if soup:\n            return soup\n\n        # If not page is found, use search\n        return SearchDaily(self.category, date=self.date).fetch_result()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_url(self, shorten=True):\n        self.url = URL_FORMAT.format(*self._get_url_params(shorten=shorten))", "response": "Build the url for a cable ratings page"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_entries(self):\n        data = []\n        for row in self.get_rows():\n            # Stop fetching data if limit has been met\n            if exceeded_limit(self.limit, len(data)):\n                break\n\n            entry = row.find_all('td')\n            entry_dict = {}\n\n            show = entry[0].string\n            net = entry[1].string\n            if not self._match_query(show, net):\n                continue\n\n            entry_dict['show'] = show\n            entry_dict['net'] = net\n            entry_dict['time'] = entry[2].string\n\n            if ',' in entry[3].string:\n                entry_dict['viewers'] = entry[3].string.replace(',', '.')\n            else:\n                entry_dict['viewers'] = '0.' + entry[3].string\n            entry_dict['rating'] = entry[4].string\n\n            # Add data to create cable entry\n            data.append(Entry(**entry_dict))\n\n        return data", "response": "Fetch data and parse it to build a list of cable entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the url for a broadcast ratings page", "response": "def _build_url(self, shorten=True):\n        \"\"\"Build the url for a broadcast ratings page\"\"\"\n        url_order = self._get_url_params(shorten=shorten)\n\n        # For fast ratings, switch weekday and category in url\n        if self.category != 'final':\n            url_order[1], url_order[2] = url_order[2], url_order[1]\n        self.url = URL_FORMAT.format(*url_order)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the rows from a broadcast ratings chart", "response": "def get_rows(self):\n        \"\"\"Get the rows from a broadcast ratings chart\"\"\"\n        table = self.soup.find_all('tr')[1:-3]\n        return [row for row in table if row.contents[3].string]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_entries(self):\n        current_time = ''\n\n        data = []\n        for row in self.get_rows():\n            # Stop fetching data if limit has been met\n            if exceeded_limit(self.limit, len(data)):\n                break\n\n            entry = row.find_all('td')\n            entry_dict = {}\n\n            show_time = entry[0].string\n            if show_time and show_time != current_time:\n                current_time = show_time\n            if not show_time:\n                show_time = current_time\n            entry_dict['time'] = show_time\n\n            show_string = entry[1].string.split('(')\n            show = show_string[0][:-1]\n            net = self._get_net(show_string)\n            if not self._match_query(show, net):\n                continue\n\n            entry_dict['show'] = show\n            entry_dict['net'] = net\n            entry_dict['viewers'] = entry[3].string.strip('*')\n            entry_dict['rating'], entry_dict['share'] = self._get_rating(entry)\n\n            # Add data to initialize broadcast entry\n            data.append(Entry(**entry_dict))\n\n        return data", "response": "Fetch data and parse it to build a list of broadcast entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_averages(self):\n        networks = [unescape_html(n.string) for n in self.soup.find_all('td', width='77')]\n        table = self.soup.find_all('td', style=re.compile('^font'))\n\n        # Each element is a list split as [rating, share]\n        rateshares = [r.string.split('/') for r in table[:5] if r.string]\n        viewers = [v.string for v in table[5:] if v.string]\n        averages = {}\n\n        # Load the averages dict\n        for index, network in enumerate(networks):\n            viewer = convert_float(unescape_html(viewers[index]))\n            rating = convert_float(unescape_html(rateshares[index][0]))\n            share = convert_float(unescape_html(rateshares[index][1]))\n            averages[network] = {'viewer': viewer, 'rating': rating, 'share': share}\n\n        return averages", "response": "Get the broadcast network averages for that day."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_net(self, entry):\n        try:\n            net = entry[1]\n            return net[net.find('(')+1:net.find(')')]\n        except IndexError:\n            return None", "response": "Get the network for a specific row"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_rating(self, entry):\n        r_info = ''\n        for string in entry[2].strings:\n            r_info += string\n        rating, share = r_info.split('/')\n        return (rating, share.strip('*'))", "response": "Get the rating and share for a specific row"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _visit(self, L, marked, tempmarked):\n        assert not self.is_pseudo\n        if self in tempmarked:\n            raise Exception('feature graph is cyclic')\n        if self not in marked:\n            tempmarked[self] = True\n            features = list()\n            if self.siblings is not None and self.is_toplevel:\n                features.extend(reversed(self.siblings))\n            if self.children is not None:\n                features.extend(reversed(self.children))\n            if len(features) > 0:\n                for feature in features:\n                    feature._visit(L, marked, tempmarked)\n            marked[self] = True\n            del tempmarked[self]\n            L.insert(0, self)", "response": "This function sorts the features in the feature graph and adds them to the list of features in the feature graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a child feature to this feature.", "response": "def add_child(self, child, rangecheck=False):\n        \"\"\"Add a child feature to this feature.\"\"\"\n        assert self.seqid == child.seqid, \\\n            (\n                'seqid mismatch for feature {} ({} vs {})'.format(\n                    self.fid, self.seqid, child.seqid\n                )\n            )\n        if rangecheck is True:\n            assert self._strand == child._strand, \\\n                ('child of feature {} has a different strand'.format(self.fid))\n            assert self._range.contains(child._range), \\\n                (\n                    'child of feature {} is not contained within its span '\n                    '({}-{})'.format(self.fid, child.start, child.end)\n                )\n        if self.children is None:\n            self.children = list()\n        self.children.append(child)\n        self.children.sort()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pseudoify(self):\n        assert self.is_toplevel\n        assert self.is_multi\n        assert len(self.multi_rep.siblings) > 0\n        rep = self.multi_rep\n\n        start = min([s.start for s in rep.siblings + [rep]])\n        end = max([s.end for s in rep.siblings + [rep]])\n\n        parent = Feature(None)\n        parent._pseudo = True\n        parent._seqid = self._seqid\n        parent.set_coord(start, end)\n        parent._strand = self._strand\n        for sibling in rep.siblings + [rep]:\n            parent.add_child(sibling, rangecheck=True)\n        parent.children = sorted(parent.children)\n        rep.siblings = sorted(rep.siblings)\n\n        return parent", "response": "Derive a pseudo - feature parent from the provided multi - feature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slug(self):\n        return '{:s}@{:s}[{:d}, {:d}]'.format(self.type, self.seqid,\n                                              self.start + 1, self.end)", "response": "A concise slug for this feature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_sibling(self, sibling):\n        assert self.is_pseudo is False\n        if self.siblings is None:\n            self.siblings = list()\n            self.multi_rep = self\n        sibling.multi_rep = self\n        self.siblings.append(sibling)", "response": "Add a sibling to the multi - feature representative and add a co - feature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef source(self, newsource):\n        oldsource = self.source\n        for feature in self:\n            if feature.source == oldsource:\n                feature._source = newsource", "response": "When modifying source also update children with matching source."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the type of the entry.", "response": "def type(self, newtype):\n        \"\"\"If the feature is a multifeature, update all entries.\"\"\"\n        self._type = newtype\n        if self.is_multi:\n            for sibling in self.multi_rep.siblings:\n                sibling._type = newtype"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming the feature s coordinates by the given offset.", "response": "def transform(self, offset, newseqid=None):\n        \"\"\"Transform the feature's coordinates by the given offset.\"\"\"\n        for feature in self:\n            feature._range.transform(offset)\n            if newseqid is not None:\n                feature.seqid = newseqid"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an attribute to this feature.", "response": "def add_attribute(self, attrkey, attrvalue, append=False, oldvalue=None):\n        \"\"\"\n        Add an attribute to this feature.\n\n        Feature attributes are stored as nested dictionaries.\n\n        Each feature can only have one ID, so ID attribute mapping is 'string'\n        to 'string'. All other attributes can have multiple values, so mapping\n        is 'string' to 'dict of strings'.\n\n        By default, adding an attribute that already exists will cause the old\n        value to be overwritten. If the `append` option is true, the new\n        attribute value will not overwrite the old value, but will be appended\n        as a second value. (Note: ID attributes can have only 1 value.)\n\n        If the `oldvalue` option is set, the new value will replace the old\n        value. This is necessary for updating an attribute that has multiple\n        values without completely overwriting all old values. (Note: The\n        `append` option is ignored when `oldvalue` is set.)\n        \"\"\"\n        # Handle ID/Parent relationships\n        if attrkey == 'ID':\n            if self.children is not None:\n                oldid = self.get_attribute('ID')\n                for child in self.children:\n                    child.add_attribute('Parent', attrvalue,\n                                        oldvalue=oldid)\n            self._attrs[attrkey] = attrvalue\n            if self.is_multi:\n                self.multi_rep._attrs[attrkey] = attrvalue\n                for sibling in self.multi_rep.siblings:\n                    sibling._attrs[attrkey] = attrvalue\n            return\n\n        # Handle all other attribute types\n        if oldvalue is not None:\n            if attrkey in self._attrs:\n                assert oldvalue in self._attrs[attrkey]\n                del self._attrs[attrkey][oldvalue]\n        if attrkey not in self._attrs or append is False:\n            self._attrs[attrkey] = dict()\n        self._attrs[attrkey][attrvalue] = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value of an attribute.", "response": "def get_attribute(self, attrkey, as_string=False, as_list=False):\n        \"\"\"\n        Get the value of an attribute.\n\n        By default, returns a string for ID and attributes with a single value,\n        and a list of strings for attributes with multiple values. The\n        `as_string` and `as_list` options can be used to force the function to\n        return values as a string (comma-separated in case of multiple values)\n        or a list.\n        \"\"\"\n        assert not as_string or not as_list\n        if attrkey not in self._attrs:\n            return None\n        if attrkey == 'ID':\n            return self._attrs[attrkey]\n        attrvalues = list(self._attrs[attrkey])\n        attrvalues.sort()\n        if len(attrvalues) == 1 and not as_list:\n            return attrvalues[0]\n        elif as_string:\n            return ','.join(attrvalues)\n        return attrvalues"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing an attribute string and populate a dictionary with the given attributes.", "response": "def parse_attributes(self, attrstring):\n        \"\"\"\n        Parse an attribute string.\n\n        Given a string with semicolon-separated key-value pairs, populate a\n        dictionary with the given attributes.\n        \"\"\"\n        if attrstring in [None, '', '.']:\n            return dict()\n\n        attributes = dict()\n        keyvaluepairs = attrstring.split(';')\n        for kvp in keyvaluepairs:\n            if kvp == '':\n                continue\n            key, value = kvp.split('=')\n            if key == 'ID':\n                assert ',' not in value\n                attributes[key] = value\n                continue\n            values = value.split(',')\n            valdict = dict((val, True) for val in values)\n            attributes[key] = valdict\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attribute_crawl(self, key):\n        union = set()\n        for feature in self:\n            values = feature.get_attribute(key, as_list=True)\n            if values is not None:\n                union.update(set(values))\n        return union", "response": "Get all attribute values associated with the given attribute key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve this feature s NCBI GeneID if it s present.", "response": "def ncbi_geneid(self):\n        \"\"\"\n        Retrieve this feature's NCBI GeneID if it's present.\n\n        NCBI GFF3 files contain gene IDs encoded in **Dbxref** attributes\n        (example: `Dbxref=GeneID:103504972`). This function locates and returns\n        the GeneID if present, or returns `None` otherwise.\n        \"\"\"\n        values = self.get_attribute('Dbxref', as_list=True)\n        if values is None:\n            return None\n        for value in values:\n            if value.startswith('GeneID:'):\n                key, geneid = value.split(':')\n                return geneid\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cdslen(self):\n        if self.type != 'mRNA':\n            return None\n\n        return sum([len(c) for c in self.children if c.type == 'CDS'])", "response": "Returns the length of the cds in this feature."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a querystring into keys and values", "response": "def parse_querystring(msg):\n    'parse a querystring into keys and values'\n    for part in msg.querystring.strip().lstrip('?').split('&'):\n        key, value = part.split('=')\n        yield key, value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd tags to the cluster.", "response": "def AddClusterTags(r, tags, dry_run=False):\n    \"\"\"\n    Adds tags to the cluster.\n\n    @type tags: list of str\n    @param tags: tags to add to the cluster\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n        \"tag\": tags,\n    }\n\n    return r.request(\"put\", \"/2/tags\", query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DeleteClusterTags(r, tags, dry_run=False):\n\n    query = {\n        \"dry-run\": dry_run,\n        \"tag\": tags,\n    }\n\n    return r.request(\"delete\", \"/2/tags\", query=query)", "response": "Deletes tags from the cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets information about the instances on the cluster.", "response": "def GetInstances(r, bulk=False):\n    \"\"\"\n    Gets information about instances on the cluster.\n\n    @type bulk: bool\n    @param bulk: whether to return all information about all instances\n\n    @rtype: list of dict or list of str\n    @return: if bulk is True, info about the instances, else a list of instances\n    \"\"\"\n\n    if bulk:\n        return r.request(\"get\", \"/2/instances\", query={\"bulk\": 1})\n    else:\n        instances = r.request(\"get\", \"/2/instances\")\n        return r.applier(itemgetters(\"id\"), instances)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget information about an instance.", "response": "def GetInstanceInfo(r, instance, static=None):\n    \"\"\"\n    Gets information about an instance.\n\n    @type instance: string\n    @param instance: Instance name\n    @rtype: string\n    @return: Job ID\n    \"\"\"\n\n    if static is None:\n        return r.request(\"get\", \"/2/instances/%s/info\" % instance)\n    else:\n        return r.request(\"get\", \"/2/instances/%s/info\" % instance,\n                         query={\"static\": static})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CreateInstance(r, mode, name, disk_template, disks, nics,\n                   **kwargs):\n    \"\"\"\n    Creates a new instance.\n\n    More details for parameters can be found in the RAPI documentation.\n\n    @type mode: string\n    @param mode: Instance creation mode\n    @type name: string\n    @param name: Hostname of the instance to create\n    @type disk_template: string\n    @param disk_template: Disk template for instance (e.g. plain, diskless,\n                                                file, or drbd)\n    @type disks: list of dicts\n    @param disks: List of disk definitions\n    @type nics: list of dicts\n    @param nics: List of NIC definitions\n    @type dry_run: bool\n    @keyword dry_run: whether to perform a dry run\n    @type no_install: bool\n    @keyword no_install: whether to create without installing OS(true=don't install)\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    if INST_CREATE_REQV1 not in r.features:\n        raise GanetiApiError(\"Cannot create Ganeti 2.1-style instances\")\n\n    query = {}\n\n    if kwargs.get(\"dry_run\"):\n        query[\"dry-run\"] = 1\n    if kwargs.get(\"no_install\"):\n        query[\"no-install\"] = 1\n\n    # Make a version 1 request.\n    body = {\n        _REQ_DATA_VERSION_FIELD: 1,\n        \"mode\": mode,\n        \"name\": name,\n        \"disk_template\": disk_template,\n        \"disks\": disks,\n        \"nics\": nics,\n    }\n\n    conflicts = set(kwargs.iterkeys()) & set(body.iterkeys())\n    if conflicts:\n        raise GanetiApiError(\"Required fields can not be specified as\"\n                             \" keywords: %s\" % \", \".join(conflicts))\n\n    kwargs.pop(\"dry_run\", None)\n    body.update(kwargs)\n\n    return r.request(\"post\", \"/2/instances\", query=query, content=body)", "response": "Creates a new instance in a Ganeti instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DeleteInstance(r, instance, dry_run=False):\n\n    return r.request(\"delete\", \"/2/instances/%s\" % instance,\n                     query={\"dry-run\": dry_run})", "response": "Deletes an instance from the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ActivateInstanceDisks(r, instance, ignore_size=False):\n\n    return r.request(\"put\", \"/2/instances/%s/activate-disks\" % instance,\n                     query={\"ignore_size\": ignore_size})", "response": "Activates an instance s disks."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrecreate an instance s disks.", "response": "def RecreateInstanceDisks(r, instance, disks=None, nodes=None):\n    \"\"\"Recreate an instance's disks.\n\n    @type instance: string\n    @param instance: Instance name\n    @type disks: list of int\n    @param disks: List of disk indexes\n    @type nodes: list of string\n    @param nodes: New instance nodes, if relocation is desired\n    @rtype: string\n    @return: job id\n    \"\"\"\n\n    body = {}\n\n    if disks is not None:\n        body[\"disks\"] = disks\n    if nodes is not None:\n        body[\"nodes\"] = nodes\n\n    return r.request(\"post\", \"/2/instances/%s/recreate-disks\" % instance,\n                     content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a disk to an instance.", "response": "def GrowInstanceDisk(r, instance, disk, amount, wait_for_sync=False):\n    \"\"\"\n    Grows a disk of an instance.\n\n    More details for parameters can be found in the RAPI documentation.\n\n    @type instance: string\n    @param instance: Instance name\n    @type disk: integer\n    @param disk: Disk index\n    @type amount: integer\n    @param amount: Grow disk by this amount (MiB)\n    @type wait_for_sync: bool\n    @param wait_for_sync: Wait for disk to synchronize\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    body = {\n        \"amount\": amount,\n        \"wait_for_sync\": wait_for_sync,\n    }\n\n    return r.request(\"post\", \"/2/instances/%s/disk/%s/grow\" %\n                             (instance, disk), content=body)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddInstanceTags(r, instance, tags, dry_run=False):\n\n    query = {\n        \"tag\": tags,\n        \"dry-run\": dry_run,\n    }\n\n    return r.request(\"put\", \"/2/instances/%s/tags\" % instance, query=query)", "response": "Adds tags to an instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete tags from an instance.", "response": "def DeleteInstanceTags(r, instance, tags, dry_run=False):\n    \"\"\"\n    Deletes tags from an instance.\n\n    @type instance: str\n    @param instance: instance to delete tags from\n    @type tags: list of str\n    @param tags: tags to delete\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    \"\"\"\n\n    query = {\n        \"tag\": tags,\n        \"dry-run\": dry_run,\n    }\n\n    return r.request(\"delete\", \"/2/instances/%s/tags\" % instance, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef RebootInstance(r, instance, reboot_type=None, ignore_secondaries=False,\n                   dry_run=False):\n    \"\"\"\n    Reboots an instance.\n\n    @type instance: str\n    @param instance: instance to rebot\n    @type reboot_type: str\n    @param reboot_type: one of: hard, soft, full\n    @type ignore_secondaries: bool\n    @param ignore_secondaries: if True, ignores errors for the secondary node\n            while re-assembling disks (in hard-reboot mode only)\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    \"\"\"\n\n    query = {\n        \"ignore_secondaries\": ignore_secondaries,\n        \"dry-run\": dry_run,\n    }\n\n    if reboot_type:\n        if reboot_type not in (\"hard\", \"soft\", \"full\"):\n            raise GanetiApiError(\"reboot_type must be one of 'hard',\"\n                                 \" 'soft', or 'full'\")\n        query[\"type\"] = reboot_type\n\n    return r.request(\"post\", \"/2/instances/%s/reboot\" % instance, query=query)", "response": "Reboots an instance.\n\n    @type instance: str\n    @param instance: instance to rebot\n    @type reboot_type: str\n    @param reboot_type: one of: hard, soft, full\n    @type ignore_secondaries: bool\n    @param ignore_secondaries: if True, ignores errors for the secondary node\n            while re-assembling disks (in hard-reboot mode only)\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshut down an instance.", "response": "def ShutdownInstance(r, instance, dry_run=False, no_remember=False,\n                     timeout=120):\n    \"\"\"\n    Shuts down an instance.\n\n    @type instance: str\n    @param instance: the instance to shut down\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    @type no_remember: bool\n    @param no_remember: if true, will not record the state change\n    @rtype: string\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n        \"no-remember\": no_remember,\n    }\n\n    content = {\n        \"timeout\": timeout,\n    }\n\n    return r.request(\"put\", \"/2/instances/%s/shutdown\" % instance,\n                     query=query, content=content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting up an instance.", "response": "def StartupInstance(r, instance, dry_run=False, no_remember=False):\n    \"\"\"\n    Starts up an instance.\n\n    @type instance: str\n    @param instance: the instance to start up\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    @type no_remember: bool\n    @param no_remember: if true, will not record the state change\n    @rtype: string\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n        \"no-remember\": no_remember,\n    }\n\n    return r.request(\"put\", \"/2/instances/%s/startup\" % instance, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nre-installs an instance. @type instance: str @param instance: The instance to reinstall @type os: str or None @param os: The operating system to reinstall. If None, the instance's current operating system will be installed again @type no_startup: bool @param no_startup: Whether to start the instance automatically", "response": "def ReinstallInstance(r, instance, os=None, no_startup=False, osparams=None):\n    \"\"\"\n    Reinstalls an instance.\n\n    @type instance: str\n    @param instance: The instance to reinstall\n    @type os: str or None\n    @param os: The operating system to reinstall. If None, the instance's\n            current operating system will be installed again\n    @type no_startup: bool\n    @param no_startup: Whether to start the instance automatically\n    \"\"\"\n\n    if INST_REINSTALL_REQV1 in r.features:\n        body = {\n            \"start\": not no_startup,\n        }\n        if os is not None:\n            body[\"os\"] = os\n        if osparams is not None:\n            body[\"osparams\"] = osparams\n        return r.request(\"post\", \"/2/instances/%s/reinstall\" % instance,\n                         content=body)\n\n    # Use old request format\n    if osparams:\n        raise GanetiApiError(\"Server does not support specifying OS\"\n                             \" parameters for instance reinstallation\")\n\n    query = {\n        \"nostartup\": no_startup,\n    }\n\n    if os:\n        query[\"os\"] = os\n\n    return r.request(\"post\", \"/2/instances/%s/reinstall\" % instance,\n                     query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ReplaceInstanceDisks(r, instance, disks=None, mode=REPLACE_DISK_AUTO,\n                         remote_node=None, iallocator=None, dry_run=False):\n    \"\"\"\n    Replaces disks on an instance.\n\n    @type instance: str\n    @param instance: instance whose disks to replace\n    @type disks: list of ints\n    @param disks: Indexes of disks to replace\n    @type mode: str\n    @param mode: replacement mode to use (defaults to replace_auto)\n    @type remote_node: str or None\n    @param remote_node: new secondary node to use (for use with\n            replace_new_secondary mode)\n    @type iallocator: str or None\n    @param iallocator: instance allocator plugin to use (for use with\n                                         replace_auto mode)\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    if mode not in REPLACE_DISK:\n        raise GanetiApiError(\"Invalid mode %r not one of %r\" % (mode,\n                                                                REPLACE_DISK))\n\n    query = {\n        \"mode\": mode,\n        \"dry-run\": dry_run,\n    }\n\n    if disks:\n        query[\"disks\"] = \",\".join(str(idx) for idx in disks)\n\n    if remote_node:\n        query[\"remote_node\"] = remote_node\n\n    if iallocator:\n        query[\"iallocator\"] = iallocator\n\n    return r.request(\"post\", \"/2/instances/%s/replace-disks\" % instance,\n                     query=query)", "response": "Replaces disks on an instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ExportInstance(r, instance, mode, destination, shutdown=None,\n                   remove_instance=None, x509_key_name=None,\n                   destination_x509_ca=None):\n    \"\"\"\n    Exports an instance.\n\n    @type instance: string\n    @param instance: Instance name\n    @type mode: string\n    @param mode: Export mode\n    @rtype: string\n    @return: Job ID\n    \"\"\"\n\n    body = {\n        \"destination\": destination,\n        \"mode\": mode,\n    }\n\n    if shutdown is not None:\n        body[\"shutdown\"] = shutdown\n\n    if remove_instance is not None:\n        body[\"remove_instance\"] = remove_instance\n\n    if x509_key_name is not None:\n        body[\"x509_key_name\"] = x509_key_name\n\n    if destination_x509_ca is not None:\n        body[\"destination_x509_ca\"] = destination_x509_ca\n\n    return r.request(\"put\", \"/2/instances/%s/export\" % instance, content=body)", "response": "Exports an instance.\n\n    @type instance: string\n    @param instance: Instance name\n    @type mode: string\n    @param mode: Export mode\n    @rtype: string\n    @return: Job ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmigrates an instance. @type instance: string @param instance: Instance name @type mode: string @param mode: Migration mode @type cleanup: bool @param cleanup: Whether to clean up a previously failed migration", "response": "def MigrateInstance(r, instance, mode=None, cleanup=None):\n    \"\"\"\n    Migrates an instance.\n\n    @type instance: string\n    @param instance: Instance name\n    @type mode: string\n    @param mode: Migration mode\n    @type cleanup: bool\n    @param cleanup: Whether to clean up a previously failed migration\n    \"\"\"\n\n    body = {}\n\n    if mode is not None:\n        body[\"mode\"] = mode\n\n    if cleanup is not None:\n        body[\"cleanup\"] = cleanup\n\n    return r.request(\"put\", \"/2/instances/%s/migrate\" % instance,\n                     content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo a failover of an instance.", "response": "def FailoverInstance(r, instance, iallocator=None, ignore_consistency=False,\n                     target_node=None):\n    \"\"\"Does a failover of an instance.\n\n    @type instance: string\n    @param instance: Instance name\n    @type iallocator: string\n    @param iallocator: Iallocator for deciding the target node for\n        shared-storage instances\n    @type ignore_consistency: bool\n    @param ignore_consistency: Whether to ignore disk consistency\n    @type target_node: string\n    @param target_node: Target node for shared-storage instances\n    @rtype: string\n    @return: job id\n    \"\"\"\n\n    body = {\n        \"ignore_consistency\": ignore_consistency,\n    }\n\n    if iallocator is not None:\n        body[\"iallocator\"] = iallocator\n    if target_node is not None:\n        body[\"target_node\"] = target_node\n\n\n    return r.request(\"put\", \"/2/instances/%s/failover\" % instance,\n                     content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the name of an instance.", "response": "def RenameInstance(r, instance, new_name, ip_check, name_check=None):\n    \"\"\"\n    Changes the name of an instance.\n\n    @type instance: string\n    @param instance: Instance name\n    @type new_name: string\n    @param new_name: New instance name\n    @type ip_check: bool\n    @param ip_check: Whether to ensure instance's IP address is inactive\n    @type name_check: bool\n    @param name_check: Whether to ensure instance's name is resolvable\n    \"\"\"\n\n    body = {\n        \"ip_check\": ip_check,\n        \"new_name\": new_name,\n    }\n\n    if name_check is not None:\n        body[\"name_check\"] = name_check\n\n    return r.request(\"put\", \"/2/instances/%s/rename\" % instance, content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting for a job change.", "response": "def WaitForJobChange(r, job_id, fields, prev_job_info, prev_log_serial):\n    \"\"\"\n    Waits for job changes.\n\n    @type job_id: int\n    @param job_id: Job ID for which to wait\n    \"\"\"\n\n    body = {\n        \"fields\": fields,\n        \"previous_job_info\": prev_job_info,\n        \"previous_log_serial\": prev_log_serial,\n    }\n\n    return r.request(\"get\", \"/2/jobs/%s/wait\" % job_id, content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CancelJob(r, job_id, dry_run=False):\n\n    return r.request(\"delete\", \"/2/jobs/%s\" % job_id,\n                             query={\"dry-run\": dry_run})", "response": "Cancels a job.\n\n    @type job_id: int\n    @param job_id: id of the job to delete\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetNodes(r, bulk=False):\n\n    if bulk:\n        return r.request(\"get\", \"/2/nodes\", query={\"bulk\": 1})\n    else:\n        nodes = r.request(\"get\", \"/2/nodes\")\n        return r.applier(itemgetters(\"id\"), nodes)", "response": "Gets all nodes in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef EvacuateNode(r, node, iallocator=None, remote_node=None, dry_run=False,\n                 early_release=False, mode=None, accept_old=False):\n    \"\"\"\n    Evacuates instances from a Ganeti node.\n\n    @type node: str\n    @param node: node to evacuate\n    @type iallocator: str or None\n    @param iallocator: instance allocator to use\n    @type remote_node: str\n    @param remote_node: node to evaucate to\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    @type early_release: bool\n    @param early_release: whether to enable parallelization\n    @type accept_old: bool\n    @param accept_old: Whether caller is ready to accept old-style\n        (pre-2.5) results\n\n    @rtype: string, or a list for pre-2.5 results\n    @return: Job ID or, if C{accept_old} is set and server is pre-2.5,\n        list of (job ID, instance name, new secondary node); if dry_run\n        was specified, then the actual move jobs were not submitted and\n        the job IDs will be C{None}\n\n    @raises GanetiApiError: if an iallocator and remote_node are both\n            specified\n    \"\"\"\n\n    if iallocator and remote_node:\n        raise GanetiApiError(\"Only one of iallocator or remote_node can\"\n                             \" be used\")\n\n    query = {\n        \"dry-run\": dry_run,\n    }\n\n    if iallocator:\n        query[\"iallocator\"] = iallocator\n    if remote_node:\n        query[\"remote_node\"] = remote_node\n\n    if NODE_EVAC_RES1 in r.features:\n        # Server supports body parameters\n        body = {\n            \"early_release\": early_release,\n        }\n\n        if iallocator is not None:\n            body[\"iallocator\"] = iallocator\n        if remote_node is not None:\n            body[\"remote_node\"] = remote_node\n        if mode is not None:\n            body[\"mode\"] = mode\n    else:\n        # Pre-2.5 request format\n        body = None\n\n        if not accept_old:\n            raise GanetiApiError(\"Server is version 2.4 or earlier and\"\n                                 \" caller does not accept old-style\"\n                                 \" results (parameter accept_old)\")\n\n        # Pre-2.5 servers can only evacuate secondaries\n        if mode is not None and mode != NODE_EVAC_SEC:\n            raise GanetiApiError(\"Server can only evacuate secondary instances\")\n\n        if iallocator is not None:\n            query[\"iallocator\"] = iallocator\n        if remote_node is not None:\n            query[\"remote_node\"] = remote_node\n        if query:\n            query[\"early_release\"] = 1\n\n    return r.request(\"post\", \"/2/nodes/%s/evacuate\" % node, query=query,\n                     content=body)", "response": "Evacuates instances from a Ganeti node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmigrate all primary instances from a node. @type node: str @param node: node to migrate @type mode: string @param mode: if passed, it will overwrite the live migration type, otherwise the hypervisor default will be used @type dry_run: bool @param dry_run: whether to perform a dry run @type iallocator: string @param iallocator: instance allocator to use @type target_node: string @param target_node: Target node for shared-storage instances @rtype: int @return: job id", "response": "def MigrateNode(r, node, mode=None, dry_run=False, iallocator=None,\n                target_node=None):\n    \"\"\"\n    Migrates all primary instances from a node.\n\n    @type node: str\n    @param node: node to migrate\n    @type mode: string\n    @param mode: if passed, it will overwrite the live migration type,\n            otherwise the hypervisor default will be used\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    @type iallocator: string\n    @param iallocator: instance allocator to use\n    @type target_node: string\n    @param target_node: Target node for shared-storage instances\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n    }\n\n    if NODE_MIGRATE_REQV1 in r.features:\n        body = {}\n\n        if mode is not None:\n            body[\"mode\"] = mode\n        if iallocator is not None:\n            body[\"iallocator\"] = iallocator\n        if target_node is not None:\n            body[\"target_node\"] = target_node\n\n    else:\n        # Use old request format\n        if target_node is not None:\n            raise GanetiApiError(\"Server does not support specifying\"\n                                 \" target node for node migration\")\n\n        body = None\n\n        if mode is not None:\n            query[\"mode\"] = mode\n\n    return r.request(\"post\", \"/2/nodes/%s/migrate\" % node, query=query,\n                     content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the role for a node.", "response": "def SetNodeRole(r, node, role, force=False, auto_promote=False):\n    \"\"\"\n    Sets the role for a node.\n\n    @type node: str\n    @param node: the node whose role to set\n    @type role: str\n    @param role: the role to set for the node\n    @type force: bool\n    @param force: whether to force the role change\n    @type auto_promote: bool\n    @param auto_promote: Whether node(s) should be promoted to master\n        candidate if necessary\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"force\": force,\n        \"auto_promote\": auto_promote,\n    }\n\n    return r.request(\"put\", \"/2/nodes/%s/role\" % node, query=query,\n                     content=role)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PowercycleNode(r, node, force=False):\n\n    query = {\n        \"force\": force,\n    }\n\n    return r.request(\"post\", \"/2/nodes/%s/powercycle\" % node, query=query)", "response": "Powercycles a node.\n\n    @type node: string\n    @param node: Node name\n    @type force: bool\n    @param force: Whether to force the operation\n    @rtype: string\n    @return: job id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetNodeStorageUnits(r, node, storage_type, output_fields):\n\n    query = {\n        \"storage_type\": storage_type,\n        \"output_fields\": output_fields,\n    }\n\n    return r.request(\"get\", \"/2/nodes/%s/storage\" % node, query=query)", "response": "Gets the storage units for a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmodify the parameters of storage units on a node.", "response": "def ModifyNodeStorageUnits(r, node, storage_type, name, allocatable=None):\n    \"\"\"\n    Modifies parameters of storage units on the node.\n\n    @type node: str\n    @param node: node whose storage units to modify\n    @type storage_type: str\n    @param storage_type: storage type whose units to modify\n    @type name: str\n    @param name: name of the storage unit\n    @type allocatable: bool or None\n    @param allocatable: Whether to set the \"allocatable\" flag on the storage\n                                            unit (None=no modification, True=set, False=unset)\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"storage_type\": storage_type,\n        \"name\": name,\n    }\n\n    if allocatable is not None:\n        query[\"allocatable\"] = allocatable\n\n    return r.request(\"put\", \"/2/nodes/%s/storage/modify\" % node, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef RepairNodeStorageUnits(r, node, storage_type, name):\n\n    query = {\n        \"storage_type\": storage_type,\n        \"name\": name,\n    }\n\n    return r.request(\"put\", \"/2/nodes/%s/storage/repair\" % node, query=query)", "response": "Repairs a storage unit on the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AddNodeTags(r, node, tags, dry_run=False):\n\n    query = {\n        \"tag\": tags,\n        \"dry-run\": dry_run,\n    }\n\n    return r.request(\"put\", \"/2/nodes/%s/tags\" % node, query=query,\n                     content=tags)", "response": "Adds tags to a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting tags from a node.", "response": "def DeleteNodeTags(r, node, tags, dry_run=False):\n    \"\"\"\n    Delete tags from a node.\n\n    @type node: str\n    @param node: node to remove tags from\n    @type tags: list of str\n    @param tags: tags to remove from the node\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"tag\": tags,\n        \"dry-run\": dry_run,\n    }\n\n    return r.request(\"delete\", \"/2/nodes/%s/tags\" % node, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all node groups in the cluster.", "response": "def GetGroups(r, bulk=False):\n    \"\"\"\n    Gets all node groups in the cluster.\n\n    @type bulk: bool\n    @param bulk: whether to return all information about the groups\n\n    @rtype: list of dict or str\n    @return: if bulk is true, a list of dictionaries with info about all node\n            groups in the cluster, else a list of names of those node groups\n    \"\"\"\n\n    if bulk:\n        return r.request(\"get\", \"/2/groups\", query={\"bulk\": 1})\n    else:\n        groups = r.request(\"get\", \"/2/groups\")\n        return r.applier(itemgetters(\"name\"), groups)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new node group.", "response": "def CreateGroup(r, name, alloc_policy=None, dry_run=False):\n    \"\"\"\n    Creates a new node group.\n\n    @type name: str\n    @param name: the name of node group to create\n    @type alloc_policy: str\n    @param alloc_policy: the desired allocation policy for the group, if any\n    @type dry_run: bool\n    @param dry_run: whether to peform a dry run\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n    }\n\n    body = {\n        \"name\": name,\n        \"alloc_policy\": alloc_policy\n    }\n\n    return r.request(\"post\", \"/2/groups\", query=query, content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a node group.", "response": "def DeleteGroup(r, group, dry_run=False):\n    \"\"\"\n    Deletes a node group.\n\n    @type group: str\n    @param group: the node group to delete\n    @type dry_run: bool\n    @param dry_run: whether to peform a dry run\n\n    @rtype: int\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n    }\n\n    return r.request(\"delete\", \"/2/groups/%s\" % group, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RenameGroup(r, group, new_name):\n\n    body = {\n        \"new_name\": new_name,\n    }\n\n    return r.request(\"put\", \"/2/groups/%s/rename\" % group, content=body)", "response": "Changes the name of a node group."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassign nodes to a group.", "response": "def AssignGroupNodes(r, group, nodes, force=False, dry_run=False):\n    \"\"\"\n    Assigns nodes to a group.\n\n    @type group: string\n    @param group: Node gropu name\n    @type nodes: list of strings\n    @param nodes: List of nodes to assign to the group\n\n    @rtype: int\n    @return: job id\n\n    \"\"\"\n\n    query = {\n        \"force\": force,\n        \"dry-run\": dry_run,\n    }\n\n    body = {\n        \"nodes\": nodes,\n    }\n\n    return r.request(\"put\", \"/2/groups/%s/assign-nodes\" % group, query=query,\n                     content=body)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd tags to a node group.", "response": "def AddGroupTags(r, group, tags, dry_run=False):\n    \"\"\"\n    Adds tags to a node group.\n\n    @type group: str\n    @param group: group to add tags to\n    @type tags: list of string\n    @param tags: tags to add to the group\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n\n    @rtype: string\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n        \"tag\": tags,\n    }\n\n    return r.request(\"put\", \"/2/groups/%s/tags\" % group, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes tags from a node group.", "response": "def DeleteGroupTags(r, group, tags, dry_run=False):\n    \"\"\"\n    Deletes tags from a node group.\n\n    @type group: str\n    @param group: group to delete tags from\n    @type tags: list of string\n    @param tags: tags to delete\n    @type dry_run: bool\n    @param dry_run: whether to perform a dry run\n    @rtype: string\n    @return: job id\n    \"\"\"\n\n    query = {\n        \"dry-run\": dry_run,\n        \"tag\": tags,\n    }\n\n    return r.request(\"delete\", \"/2/groups/%s/tags\" % group, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Query(r, what, fields, qfilter=None):\n\n    body = {\n        \"fields\": fields,\n    }\n\n    if qfilter is not None:\n        body[\"qfilter\"] = body[\"filter\"] = qfilter\n\n    return r.request(\"put\", \"/2/query/%s\" % what, content=body)", "response": "Queries the resources in a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef QueryFields(r, what, fields=None):\n\n    query = {}\n\n    if fields is not None:\n        query[\"fields\"] = \",\".join(fields)\n\n    return r.request(\"get\", \"/2/query/%s/fields\" % what, query=query)", "response": "Queries available fields for a resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createalphabet(alphabetinput=None):\n    if alphabetinput and os.path.isfile(alphabetinput):\n        return _load_alphabet(alphabetinput)\n    elif alphabetinput:\n        alpha = []\n        setlist = alphabetinput.split(',')\n        for alphaset in setlist:\n            a = int(alphaset.split('-')[0])\n            b = int(alphaset.split('-')[1])\n            for i in range(a, b):\n                alpha.append(str(unichr(i)))\n        return alpha\n    alpha = []\n    for i in range(32, 127):\n        alpha.append(str(unichr(i)))\n    return alpha", "response": "Creates a sample alphabet containing printable ASCII characters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _instant_search(self):\n        _keys = []\n        for k,v in self.searchables.iteritems():\n            if self.string in v:\n                _keys.append(k)\n        self.candidates.append(_keys)", "response": "Determine possible keys after a push or pop."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef best_guess(self):\n        best_guess_ever = (0, 0) # (key, string)\n        points = defaultdict(float)\n        points[0] = 0\n        if len(self.string) > 0:\n            for key in self.candidate_keys:\n                guess = self.searchables[key]\n                if guess == self.string:\n                    points[key] += 100\n                    break\n                # skip, entry longer then guess\n                if len(self.string) > len(guess):\n                    continue\n                # begins with\n                if guess.startswith(self.string):\n                    points[key] += 1\n                # contained in\n                if self.string in guess:\n                    points[key] += 1\n                # percentage of user search string in best guess\n                if points[key] > 0:\n                    points[key] += float(len(self.string))/len(guess)\n        for k,v in points.iteritems():\n            if points[best_guess_ever[0]] < points[k]:\n                best_guess_ever = (k, self.searchables[k])\n        return best_guess_ever", "response": "Return the gnomekeyring position of the closest matching\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_html_files(self, destination):\n        for root, dirs, files in os.walk(destination):\n            for f in files:\n                if f.endswith('.html'):\n                    yield os.path.join(root, f)", "response": "Find all html files in the given destination."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_after_build_all(self, builder, **extra):\n        # NOTE(vesuvium): compatibility for lektor 2.X and 3.X\n        try:\n            is_enabled = self.is_enabled(builder.build_flags)\n        except AttributeError:\n            is_enabled = self.is_enabled(builder.extra_flags)\n\n        if not is_enabled:\n            return\n\n        reporter.report_generic('Starting HTML minification')\n        for htmlfile in self.find_html_files(builder.destination_path):\n            self.minify_file(htmlfile)\n        reporter.report_generic('HTML minification finished')", "response": "Called when the build - all event is received."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninterprets a waveform file and returns a dictionary containing the time trace and the signal in the time trace.", "response": "def InterpretWaveform(raw, integersOnly=False, headersOnly=False, noTimeArray=False):\n        \"\"\"\n        Take the raw binary from a file saved from the LeCroy, read from a file using \n        the 2 lines:\n        with open(filename, \"rb\") as file:\n        raw = file.read()\n        And extracts various properties of the saved time trace.\n        \n        Parameters\n        ----------\n        raw : bytes\n            Bytes object containing the binary contents of the saved raw/trc file\n        integersOnly : bool, optional\n            If True, only returns the unprocessed integers (read from the ADC) \n            rather than the signal in volts. Defaults to False. \n        headersOnly : bool, optional\n            If True, only returns the file header. Defaults to False. \n        noTimeArray : bool, optional\n            If true returns timeStart, timeStop and timeStep and doesn't create the time array\n\n        Returns\n        -------\n        WAVEDESC : dict\n            dictionary containing some properties of the time trace and oscilloscope\n            settings extracted from the header file.\n        x : ndarray / tuple\n            The array of time values recorded by the oscilloscope or,\n            if noTimeArray is True, returns a tuplef of (timeStart, timeStop, timeStep)\n        y : ndarray\n            The array of voltage values recorded by the oscilloscope\n        integers : ndarray\n            The array of raw integers recorded from the ADC and stored in the binary file\n        MissingData : bool\n            bool stating if any data was missing\n\n\n        \"\"\"\n        MissingData = False\n        from struct import unpack\n        \n        if raw[0:1] != b'#':\n                cmd = raw.split(b',')[0]  # \"C1:WF ALL\" or similar\n                wave = raw[len(cmd)+1:]   # Remove the above command text (and trailing\n        else:\n                wave = raw\n\n        del raw\n\n#        if wave[0:1] != b'#':\n#                warnings.warn('Waveform format not as expected, time trace may be missing data')\n#                MissingData = True\n                \n        n = int(wave[1:2])          # number of digits in length of data\n        N = int(wave[2:2+n])      # number describing length of data\n\n        if wave.endswith(b'\\n'):\n                wave = wave[:-1]\n\n        wave = wave[2+n:]\n\n#        if N != len(wave):\n#                warnings.warn('Length of waveform not as expected, time trace may be missing data')\n#                MissingData = True\n                \n        # Code to parse WAVEDESC generated by parsing template, returned from scope query \"TEMPLATE?\"\n        # Note that this is not well tested and will not handle unusual settings\n        WAVEDESC = dict()\n        WAVEDESC['DESCRIPTOR_NAME'] = wave[0:16].strip(b'\\x00')\n        WAVEDESC['TEMPLATE_NAME'] = wave[16:32].strip(b'\\x00')\n        WAVEDESC['COMM_TYPE'] = {0: 'byte',1: 'word'}[unpack(b\"<H\", wave[32:34])[0]]\n        WAVEDESC['COMM_ORDER'] = {0: 'HIFIRST',1: 'LOFIRST'}[unpack(\"<H\", wave[34:36])[0]]\n        WAVEDESC['WAVE_DESCRIPTOR'] = unpack('<l', wave[36:40])[0]\n        WAVEDESC['USER_TEXT'] = unpack('<l', wave[40:44])[0]\n        WAVEDESC['RES_DESC1'] = unpack('<l', wave[44:48])[0]\n        WAVEDESC['TRIGTIME_ARRAY'] = unpack('<l', wave[48:52])[0]\n        WAVEDESC['RIS_TIME_ARRAY'] = unpack('<l', wave[52:56])[0]\n        WAVEDESC['RES_ARRAY1'] = unpack('<l', wave[56:60])[0]\n        WAVEDESC['WAVE_ARRAY_1'] = unpack('<l', wave[60:64])[0]\n        WAVEDESC['WAVE_ARRAY_2'] = unpack('<l', wave[64:68])[0]\n        WAVEDESC['RES_ARRAY2'] = unpack('<l', wave[68:72])[0]\n        WAVEDESC['RES_ARRAY3'] = unpack('<l', wave[72:76])[0]\n        WAVEDESC['INSTRUMENT_NAME'] = wave[76:92].strip(b'\\x00')\n        WAVEDESC['INSTRUMENT_NUMBER'] = unpack('<l', wave[92:96])[0]\n        WAVEDESC['TRACE_LABEL'] = wave[96:112].strip(b'\\x00')\n        WAVEDESC['RESERVED1'] = unpack('<h', wave[112:114])[0]\n        WAVEDESC['RESERVED2'] = unpack('<h', wave[114:116])[0]\n        WAVEDESC['WAVE_ARRAY_COUNT'] = unpack('<l', wave[116:120])[0]\n        WAVEDESC['PNTS_PER_SCREEN'] = unpack('<l', wave[120:124])[0]\n        WAVEDESC['FIRST_VALID_PNT'] = unpack('<l', wave[124:128])[0]\n        WAVEDESC['LAST_VALID_PNT'] = unpack('<l', wave[128:132])[0]\n        WAVEDESC['FIRST_POINT'] = unpack('<l', wave[132:136])[0]\n        WAVEDESC['SPARSING_FACTOR'] = unpack('<l', wave[136:140])[0]\n        WAVEDESC['SEGMENT_INDEX'] = unpack('<l', wave[140:144])[0]\n        WAVEDESC['SUBARRAY_COUNT'] = unpack('<l', wave[144:148])[0]\n        WAVEDESC['SWEEPS_PER_ACQ'] = unpack('<l', wave[148:152])[0]\n        WAVEDESC['POINTS_PER_PAIR'] = unpack('<h', wave[152:154])[0]\n        WAVEDESC['PAIR_OFFSET'] = unpack('<h', wave[154:156])[0]\n        WAVEDESC['VERTICAL_GAIN'] = unpack('<f', wave[156:160])[0]\n        WAVEDESC['VERTICAL_OFFSET'] = unpack('<f', wave[160:164])[0]\n        WAVEDESC['MAX_VALUE'] = unpack('<f', wave[164:168])[0]\n        WAVEDESC['MIN_VALUE'] = unpack('<f', wave[168:172])[0]\n        WAVEDESC['NOMINAL_BITS'] = unpack('<h', wave[172:174])[0]\n        WAVEDESC['NOM_SUBARRAY_COUNT'] = unpack('<h', wave[174:176])[0]\n        WAVEDESC['HORIZ_INTERVAL'] = unpack('<f', wave[176:180])[0]\n        WAVEDESC['HORIZ_OFFSET'] = unpack('<d', wave[180:188])[0]\n        WAVEDESC['PIXEL_OFFSET'] = unpack('<d', wave[188:196])[0]\n        WAVEDESC['VERTUNIT'] = wave[196:244].strip(b'\\x00')\n        WAVEDESC['HORUNIT'] = wave[244:292].strip(b'\\x00')\n        WAVEDESC['HORIZ_UNCERTAINTY'] = unpack('<f', wave[292:296])[0]\n        WAVEDESC['TRIGGER_TIME'] = wave[296:312] # Format time_stamp not implemented\n        WAVEDESC['ACQ_DURATION'] = unpack('<f', wave[312:316])[0]\n        WAVEDESC['RECORD_TYPE'] = {0: 'single_sweep',1: 'interleaved',2: 'histogram',3: 'graph',4: 'filter_coefficient',5: 'complex',6: 'extrema',7: 'sequence_obsolete',8: 'centered_RIS',9: 'peak_detect'}[unpack(\"<H\", wave[316:318])[0]]\n        WAVEDESC['PROCESSING_DONE'] = {0: 'no_processing',1: 'fir_filter',2: 'interpolated',3: 'sparsed',4: 'autoscaled',5: 'no_result',6: 'rolling',7: 'cumulative'}[unpack(\"<H\", wave[318:320])[0]]\n        WAVEDESC['RESERVED5'] = unpack('<h', wave[320:322])[0]\n        WAVEDESC['RIS_SWEEPS'] = unpack('<h', wave[322:324])[0]\n        WAVEDESC['TIMEBASE'] = {0: '1_ps/div',1: '2_ps/div',2: '5_ps/div',3: '10_ps/div',4: '20_ps/div',5: '50_ps/div',6: '100_ps/div',7: '200_ps/div',8: '500_ps/div',9: '1_ns/div',10: '2_ns/div',11: '5_ns/div',12: '10_ns/div',13: '20_ns/div',14: '50_ns/div',15: '100_ns/div',16: '200_ns/div',17: '500_ns/div',18: '1_us/div',19: '2_us/div',20: '5_us/div',21: '10_us/div',22: '20_us/div',23: '50_us/div',24: '100_us/div',25: '200_us/div',26: '500_us/div',27: '1_ms/div',28: '2_ms/div',29: '5_ms/div',30: '10_ms/div',31: '20_ms/div',32: '50_ms/div',33: '100_ms/div',34: '200_ms/div',35: '500_ms/div',36: '1_s/div',37: '2_s/div',38: '5_s/div',39: '10_s/div',40: '20_s/div',41: '50_s/div',42: '100_s/div',43: '200_s/div',44: '500_s/div',45: '1_ks/div',46: '2_ks/div',47: '5_ks/div',100: 'EXTERNAL'}[unpack(\"<H\", wave[324:326])[0]]\n        WAVEDESC['VERT_COUPLING'] = {0: 'DC_50_Ohms',1: 'ground',2: 'DC_1MOhm',3: 'ground',4: 'AC_1MOhm'}[unpack(\"<H\", wave[326:328])[0]]\n        WAVEDESC['PROBE_ATT'] = unpack('<f', wave[328:332])[0]\n        WAVEDESC['FIXED_VERT_GAIN'] = {0: '1_uV/div',1: '2_uV/div',2: '5_uV/div',3: '10_uV/div',4: '20_uV/div',5: '50_uV/div',6: '100_uV/div',7: '200_uV/div',8: '500_uV/div',9: '1_mV/div',10: '2_mV/div',11: '5_mV/div',12: '10_mV/div',13: '20_mV/div',14: '50_mV/div',15: '100_mV/div',16: '200_mV/div',17: '500_mV/div',18: '1_V/div',19: '2_V/div',20: '5_V/div',21: '10_V/div',22: '20_V/div',23: '50_V/div',24: '100_V/div',25: '200_V/div',26: '500_V/div',27: '1_kV/div'}[unpack(\"<H\", wave[332:334])[0]]\n        WAVEDESC['BANDWIDTH_LIMIT'] = {0: 'off',1: 'on'}[unpack(\"<H\", wave[334:336])[0]]\n        WAVEDESC['VERTICAL_VERNIER'] = unpack('<f', wave[336:340])[0]\n        WAVEDESC['ACQ_VERT_OFFSET'] = unpack('<f', wave[340:344])[0]\n        WAVEDESC['WAVE_SOURCE'] = {0: 'CHANNEL_1',1: 'CHANNEL_2',2: 'CHANNEL_3',3: 'CHANNEL_4',9: 'UNKNOWN'}[unpack(\"<H\", wave[344:346])[0]]\n\n        if len(wave[346:]) != WAVEDESC['WAVE_ARRAY_1']:\n                warnings.warn('Binary data not the expected length, time trace may be missing data')\n                MissingData = True\n\n        if headersOnly:\n                return WAVEDESC, MissingData\n        else:\n                from numpy import fromstring, int16, arange\n                if MissingData != True:\n                        integers = fromstring(wave[346:], dtype=int16)\n                else:\n                        integers = fromstring(wave[346:][:-1], dtype=int16)\n                        \n                if integersOnly:\n                        return (WAVEDESC, integers, MissingData)\n                elif noTimeArray:\n                        y = integers * WAVEDESC['VERTICAL_GAIN'] - WAVEDESC['VERTICAL_OFFSET']\n                        x = arange(len(integers)) * WAVEDESC['HORIZ_INTERVAL'] + WAVEDESC['HORIZ_OFFSET']\n                        timeStart = x[0]\n                        timeStop = x[-1] \n                        timeStep = x[1]-x[0]\n                        return (WAVEDESC, (timeStart, timeStop, timeStep), y, integers, MissingData)\n                        \n                else:\n                        y = integers * WAVEDESC['VERTICAL_GAIN'] - WAVEDESC['VERTICAL_OFFSET'] \n                        x = arange(len(integers)) * WAVEDESC['HORIZ_INTERVAL'] + WAVEDESC['HORIZ_OFFSET']\n                        return (WAVEDESC, x, y, integers, MissingData)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw(self, channel=1):\n                self.waitOPC()\n                self.write('COMM_FORMAT DEF9,WORD,BIN')\n                self.write('C%u:WAVEFORM?' % channel)\n                return self.read_raw()", "response": "Reads the raw binary data from the oscilloscope."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef features(entrystream, type=None, traverse=False):\n    for feature in entry_type_filter(entrystream, tag.Feature):\n        if traverse:\n            if type is None:\n                message = 'cannot traverse without a specific feature type'\n                raise ValueError(message)\n            if type == feature.type:\n                yield feature\n            else:\n                for subfeature in feature:\n                    if type == subfeature.type:\n                        yield subfeature\n        else:\n            if not type or type == feature.type:\n                yield feature", "response": "Returns an iterator over the features in the specified entry stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef window(featurestream, seqid, start=None, end=None, strict=True):\n    region = None\n    if start and end:\n        region = tag.Range(start, end)\n\n    for feature in featurestream:\n        if feature.seqid != seqid:\n            continue\n        if region:\n            if strict:\n                if region.contains(feature._range):\n                    yield feature\n            else:\n                if region.overlap(feature._range):\n                    yield feature\n        else:\n            yield feature", "response": "Yields features from a stream of features in a genomic interval."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef directives(entrystream, type=None):\n    for directive in entry_type_filter(entrystream, tag.Directive):\n        if not type or type == directive.type:\n            yield directive", "response": "Get all directives in the specified entry stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a new web server.", "response": "def cli(ctx, stage, port):\n    \"\"\"Web interface(experimental).\"\"\"\n    if not ctx.bubble:\n        ctx.say_yellow('There is no bubble present, will not listen')\n        raise click.Abort()\n    gbc = ctx.gbc\n    WEB = None\n    if stage in STAGES:\n        STAGE = ctx.cfg.CFG[stage]\n        if 'SERVER'  in STAGE:\n            SERVER=STAGE.SERVER\n            if 'WEB' in SERVER:\n                WEB=SERVER.WEB\n\n    if not WEB:\n        ctx.say_red('There is no SERVER.WEB in stage:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                       ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n    web_server = get_server(gbc, WEB, ctx.home)\n\n    try:\n        # TODO: bg &\n        # src_listening = web_server.start_web(ctx=gbc,\n        web_server.start_web(ctx=gbc,\n                             port=port,\n                             stage=stage)\n    except Exception as e:\n        ctx.say_red(\n            'cannot start web server e ' + WEB)\n        ctx.say_red(str(e))\n        raise click.Abort('cannot listen')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the plural tag index of a number on the plural rule of a locale.", "response": "def get_plural_tag_index(number, locale):\n    \"\"\"Gets the plural tag index of a number on the plural rule of a locale::\n\n       >>> get_plural_tag_index(1, 'en_US')\n       0\n       >>> get_plural_tag_index(2, 'en_US')\n       1\n       >>> get_plural_tag_index(100, 'en_US')\n       1\n\n    \"\"\"\n    locale = Locale.parse(locale)\n    plural_rule = locale.plural_form\n    used_tags = plural_rule.tags | set([_fallback_tag])\n    tag, index = plural_rule(number), 0\n    for _tag in _plural_tags:\n        if _tag == tag:\n            return index\n        if _tag in used_tags:\n            index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a list of strings to a list of certain form specified by f*.", "response": "def strings_to_(strings: Iterable[str], f: Callable) -> Iterable[Any]:\n    \"\"\"\n    Convert a list of strings to a list of certain form, specified by *f*.\n\n    :param strings: a list of string\n    :param f: a function that converts your string\n    :return: type undefined, but specified by `to_type`\n\n    .. doctest::\n\n        >>> strings_to_(['0.333', '0.667', '0.250'], float)\n        [0.333, 0.667, 0.25]\n    \"\"\"\n    if not all_string_like(strings):\n        raise TypeError('All have to be strings!')\n    # ``type(strs)`` is the container of *strs*.\n    return type(strings)(map(f, strings))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a list of strings to a list of integers.", "response": "def strings_to_integers(strings: Iterable[str]) -> Iterable[int]:\n    \"\"\"\n    Convert a list of strings to a list of integers.\n\n    :param strings: a list of string\n    :return: a list of converted integers\n\n    .. doctest::\n\n        >>> strings_to_integers(['1', '1.0', '-0.2'])\n        [1, 1, 0]\n    \"\"\"\n    return strings_to_(strings, lambda x: int(float(x)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef string_to_double_precision_float(s: str) -> float:\n    first, second, exponential = re.match(\n        \"(-?\\d*)\\.?(-?\\d*)d(-?\\d+)\", s, re.IGNORECASE).groups()\n    return float(first + '.' + second + 'e' + exponential)", "response": "Convert a string to a double precision float in Fortran file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef string_to_general_float(s: str) -> float:\n    if 'D' in s.upper():  # Possible double precision number\n        try:\n            return string_to_double_precision_float(s)\n        except ValueError:\n            raise ValueError(\n                \"The string '{0}' does not corresponds to a double precision number!\".format(s))\n    else:\n        return float(s)", "response": "Convert a string to corresponding single or double precision scientific number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef match_one_string(pattern: str, s: str, *args):\n    try:\n        # `match` is either an empty list or a list of string.\n        match, = re.findall(pattern, s)\n        if len(args) == 0:  # If no wrapper argument is given, return directly the matched string\n            return match\n        elif len(args) == 1:  # If wrapper argument is given, i.e., not empty, then apply wrapper to the match\n            wrapper, = args\n            return wrapper(match)\n        else:\n            raise TypeError(\n                'Multiple wrappers are given! Only one should be given!')\n    except ValueError:\n        print(\"Pattern \\\"{0}\\\" not found, or more than one found in string {1}!\".format(\n            pattern, s))", "response": "Match one string in a tree tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match_one_pattern(pattern: str, s: str, *args: Optional[Callable], **flags):\n    match: Optional[List[str]] = re.findall(pattern, s,\n                                            **flags)  # `match` is either an empty list or a list of strings.\n    if match:\n        if len(args) == 0:  # If no wrapper argument is given, return directly the matched string\n            return match\n        elif len(args) == 1:  # If wrapper argument is given, i.e., not empty, then apply wrapper to the match\n            wrapper, = args\n            return [wrapper(m) for m in match]\n        else:\n            raise TypeError(\n                'Multiple wrappers are given! Only one should be given!')\n    else:  # If no match is found\n        print(\"Pattern \\\"{0}\\\" not found in string {1}!\".format(pattern, s))\n        return None", "response": "Find a pattern in a certain string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if all elements of an iterable are a string.", "response": "def all_string_like(iterable: Iterable[object]) -> bool:\n    \"\"\"\n    If any element of an iterable is not a string, return `True`.\n\n    :param iterable: Can be a set, a tuple, a list, etc.\n    :return: Whether any element of an iterable is not a string.\n\n    .. doctest::\n\n        >>> all_string_like(['a', 'b', 'c', 3])\n        False\n        >>> all_string_like(('a', 'b', 'c', 'd'))\n        True\n    \"\"\"\n    return all(is_string_like(_) for _ in iterable)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef source_filename(self, docname: str, srcdir: str):\n\n        docpath = Path(srcdir, docname)\n        parent = docpath.parent\n        imgpath = parent.joinpath(self.filename)\n\n        # Does this exist?\n        if not imgpath.exists():\n            msg = f'Image does not exist at \"{imgpath}\"'\n            raise SphinxError(msg)\n\n        return imgpath", "response": "Get the full filename to referenced image"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef env_updated(self,\n                    kb_app,\n                    sphinx_app: Sphinx,\n                    sphinx_env: BuildEnvironment,\n                    resource\n                    ):\n        \"\"\" Make images and enter them in Sphinx's output writer \"\"\"\n\n        docname = resource.docname\n        srcdir = sphinx_app.env.srcdir\n        source_imgpath = self.source_filename(docname, srcdir)\n\n        # Copy the image to the Sphinx build directory\n        build_dir = sphinx_app.outdir\n        docpath = Path(docname)\n        parent = docpath.parent\n        target_imgpath = str(Path(build_dir, parent, self.filename))\n\n        # Does the target dir exist yet in the build dir? Probably not. If\n        # not, make it\n        target_dir = Path(build_dir, parent)\n        if not target_dir.exists():\n            target_dir.mkdir(parents=True, exist_ok=True)\n\n        shutil.copy(source_imgpath, target_imgpath)", "response": "Make images and enter them in Sphinx s output writer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexposing method to connect and query the EPA s API.", "response": "def call_api(self, table, column, value, **kwargs):\n        \"\"\"Exposed method to connect and query the EPA's API.\"\"\"\n        try:\n            output_format = kwargs.pop('output_format')\n        except KeyError:\n            output_format = self.output_format\n        url_list = [self.base_url, table, column,\n                    quote(value), 'rows']\n        rows_count = self._number_of_rows(**kwargs)\n        url_list.append(rows_count)\n        url_string = '/'.join(url_list)\n        xml_data = urlopen(url_string).read()\n        data = self._format_data(output_format, xml_data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _number_of_rows(self, start=0, count=100, **kwargs):\n        first = str(start)\n        last = str(start + count)\n        string_format = ':'.join([first, last])\n        return string_format", "response": "Internal method to format the number of rows the EPA API returns."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_reference(self, rtype: str, label: str):\n\n        # We are doing this instead of dictionary access in case we change\n        # the storage later to a multidict thingy for optimization.\n\n        reftype = self.data.get(rtype)\n        if reftype:\n            # The reftype might be \"python\" or \"sphinx\" or something else\n            # from an Intersphinx registry, not something internal to\n            # Kaybee.\n            return reftype[label]", "response": "Return the reference filed under rtype and label"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_reference(self, reftype: str, label: str, target):\n\n        # The self.data[reftype] dict springs into being during the\n        # register_references event handler at startup, which looks in the\n        # kb registry for all registered reference names.\n        self.data[reftype][label] = target", "response": "Add a reference object in references under rtype = target"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves and return the list of resources referenced by the object.", "response": "def resource_references(self, resource) -> Mapping[str, List[Any]]:\n        \"\"\" Resolve and return reference resources pointed to by object\n\n         Fields in resource.props can flag that they are references by\n         using the references type. This method scans the model,\n         finds any fields that are references, and returns the\n         reference resources pointed to by those references.\n\n         Note that we shouldn't get to the point of dangling references.\n         Our custom Sphinx event should raise a references error\n         during the build process (though maybe it is just a warning?)\n\n         \"\"\"\n\n        references = dict()\n        for reference_label in resource.props.references:\n            references[reference_label] = []\n\n            # Iterate over each value on this field, e.g.\n            # tags: tag1, tag2, tag3\n            for target_label in resource.props.references.get(reference_label):\n                # Ask the site to get the object\n                target = self.get_reference(reference_label, target_label)\n                references[reference_label].append(target)\n\n        return references"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the internal API call.", "response": "def start(self, retry_limit=None):\n        \"\"\"\n        Try to connect to Twitter's streaming API.\n\n        :param retry_limit: The maximum number of retries in case of failures. Default is None (unlimited)\n        :raises :class:`~tweepy.error.TweepyError`: If there's some critical API error\n        \"\"\"\n        # Run tweepy stream\n        wrapper_listener = TweepyWrapperListener(listener=self.listener)\n        stream = tweepy.Stream(auth=self.client.tweepy_api.auth, listener=wrapper_listener)\n\n        retry_counter = 0\n        while retry_limit is None or retry_counter <= retry_limit:\n            try:\n                retry_counter += 1\n                if not self.client.config.get('user_stream'):\n                    logging.info('Listening to public stream')\n                    stream.filter(follow=self.filter.follow, track=self.filter.track)\n                else:\n                    if self.filter.follow:\n                        logging.warning('Follow filters won\\'t be used in user stream')\n\n                    logging.info('Listening to user stream')\n                    stream.userstream(track=self.filter.track)\n            except AttributeError as e:\n                # Known Tweepy's issue https://github.com/tweepy/tweepy/issues/576\n                if \"'NoneType' object has no attribute 'strip'\" in str(e):\n                    pass\n                else:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming protein grouping based on protein to peptide mappings.", "response": "def mappingBasedGrouping(protToPeps):\n    \"\"\"Performs protein grouping based only on protein to peptide mappings.\n\n    :param protToPeps: dict, for each protein (=key) contains a set of\n        associated peptides (=value). For Example {protein: {peptide, ...}, ...}\n\n    #TODO: REFACTORING!!!\n\n    returns a ProteinInference object\n    \"\"\"\n    inference = ProteinInference(protToPeps)\n    pepToProts = inference.pepToProts\n\n    proteinClusters = _findProteinClusters(protToPeps, pepToProts)\n    proteins = {}\n    for clusterId, proteinCluster in enumerate(proteinClusters, 1):\n        clusterProtToPeps = {p: protToPeps[p] for p in proteinCluster}\n\n        #Find sameset proteins, define unique and non unique sameset proteins\n        #NOTE: already unique proteins could be excluded to find sameset proteins\n        samesetProteins = _findSamesetProteins(clusterProtToPeps)\n        mergedProtToPeps = _mergeProteinEntries(samesetProteins,\n                                                clusterProtToPeps)\n        mergedPepToProts = _invertMapping(mergedProtToPeps)\n        uniqueProteins = _findUniqueMappingValues(mergedPepToProts)\n        remainingProteins = set(mergedProtToPeps).difference(uniqueProteins)\n\n        # Remove subset proteins and check if remaining proteins become unique\n        subsetProteinInfo = _findSubsetProteins(remainingProteins,\n                                                mergedProtToPeps,\n                                                mergedPepToProts)\n        subsetProteins = [p for p, _ in subsetProteinInfo]\n        subsetRemovedProtToPeps = _reducedProtToPeps(mergedProtToPeps,\n                                                     subsetProteins)\n        subsetRemovedPepToProts = _invertMapping(subsetRemovedProtToPeps)\n        uniqueSubsetRemoved = _findUniqueMappingValues(subsetRemovedPepToProts)\n        remainingProteins = remainingProteins.difference(subsetProteins)\n        remainingProteins = remainingProteins.difference(uniqueSubsetRemoved)\n\n        # Find redundant proteins #\n        subsumableProteins = _findRedundantProteins(subsetRemovedProtToPeps,\n                                                    subsetRemovedPepToProts)\n        remainingNonRedundant = remainingProteins.difference(subsumableProteins)\n        groupInitiatingProteins = uniqueSubsetRemoved.union(remainingNonRedundant)\n\n        # - Generate protein groups and assign proteins to groups - #\n        #Generate protein groups\n        clusterGroupIds = set()\n        for protein in groupInitiatingProteins:\n            proteinIds = AUX.toList(protein)\n\n            groupId = inference.addProteinGroup(proteinIds[0])\n            inference.addLeadingToGroups(proteinIds, groupId)\n            clusterGroupIds.add(groupId)\n\n        #Add redundant proteins here (must be subsumable I guess)\n        for protein in subsumableProteins:\n            proteinIds = AUX.toList(protein)\n\n            connectedProteins = _mappingGetValueSet(\n                mergedPepToProts, mergedProtToPeps[protein]\n            )\n            flatConnectedProteins = _flattenMergedProteins(connectedProteins)\n            groupIds = _mappingGetValueSet(\n                inference._proteinToGroupIds, flatConnectedProteins\n            )\n            inference.addSubsumableToGroups(proteinIds, groupIds)\n            assert len(groupIds) > 1\n\n        #Add subgroup proteins to the respective groups\n        #NOTE: proteins that are only a subset of subsumable proteins are not\n        #to be added as subset proteins to a group but as subsumable proteins.\n        for protein, supersetProteins in subsetProteinInfo:\n            proteinIds = AUX.toList(protein)\n\n            #If the protein is a subset of at least one protein, that is not a\n            #subsumable protein, then it should be added to the group as subset.\n            leadingSuperProteins = supersetProteins.intersection(\n                                                    groupInitiatingProteins)\n            if leadingSuperProteins:\n                flatSupersetProteins = _flattenMergedProteins(\n                                                    leadingSuperProteins)\n                superGroupIds = _mappingGetValueSet(\n                    inference._proteinToGroupIds, flatSupersetProteins\n                )\n                inference.addSubsetToGroups(proteinIds, superGroupIds)\n            #However, if all its super proteins are subsumable, the protein\n            #itself is a subsumable protein.\n            else:\n                flatSupersetProteins = _flattenMergedProteins(supersetProteins)\n                superGroupIds = _mappingGetValueSet(\n                    inference._proteinToGroupIds, flatSupersetProteins\n                )\n                inference.addSubsumableToGroups(proteinIds, superGroupIds)\n                subsumableProteins.update(proteinIds)\n            assert superGroupIds\n\n        # - Define peptide properties - #\n        groupToPeps = dict()\n        allSubsumablePeps = set()\n        for groupId in clusterGroupIds:\n            group = inference.groups[groupId]\n            if group.subsumableProteins:\n                subsumablePeptides = _mappingGetValueSet(\n                    protToPeps, group.subsumableProteins\n                )\n                allSubsumablePeps.update(subsumablePeptides)\n\n            groupPeptides = _mappingGetValueSet(protToPeps, group.proteins)\n            groupToPeps[groupId] = groupPeptides\n        pepToGroups = _invertMapping(groupToPeps)\n\n        #Get unique peptides from peptide to protein mapping\n        uniquePeptides = _findUniqueMappingKeys(mergedPepToProts)\n        #Shared peptides have a groupPeptideCount > 1\n        nonSharedPeptides = _findUniqueMappingKeys(pepToGroups)\n        sharedPeptides = set(pepToGroups).difference(nonSharedPeptides)\n        #Subsumable peptides are peptides from subsumable proteins that\n        #are not shared peptides of multiple groups\n        subsumablePeptides = allSubsumablePeps.difference(sharedPeptides)\n        #groupUniquePeptides are the remaining ones (not shared with subsumable\n        #proteins, groupPeptideCount == 1, not unique peptides)\n        groupUniquePeptides = nonSharedPeptides.difference(subsumablePeptides)\n        groupUniquePeptides = groupUniquePeptides.difference(uniquePeptides)\n\n        inference._uniquePeptides.update(uniquePeptides)\n        inference._groupUniquePeptides.update(groupUniquePeptides)\n        inference._groupSubsumablePeptides.update(subsumablePeptides)\n        inference._sharedPeptides.update(sharedPeptides)\n\n        # - Generate protein entries and add them to the inference object - #\n        subsetProteinInfoDict = dict(subsetProteinInfo)\n        for protein, peptides in viewitems(mergedProtToPeps):\n            _uniquePeptides = peptides.intersection(uniquePeptides)\n            _groupUniquePeptides = peptides.intersection(groupUniquePeptides)\n            _subsumablePeptides = peptides.intersection(subsumablePeptides)\n            _sharedPeptides = peptides.intersection(sharedPeptides)\n            proteinIds = AUX.toList(protein)\n            for proteinId in proteinIds:\n                proteinEntry = Protein(proteinId, peptides)\n                if protein in groupInitiatingProteins:\n                    proteinEntry.isLeading = True\n                elif protein in subsumableProteins:\n                    proteinEntry.isSubsumable = True\n                if protein in subsetProteins:\n                    superset = subsetProteinInfoDict[protein]\n                    proteinEntry.isSubset = _flattenMergedProteins(superset)\n                if len(proteinIds) > 1:\n                    proteinEntry.isSameset = set(proteinIds)\n                inference.proteins[proteinId] = proteinEntry\n\n                #Add peptides to protein entry\n                proteinEntry.uniquePeptides = _uniquePeptides\n                proteinEntry.groupUniquePeptides = _groupUniquePeptides\n                proteinEntry.groupSubsumablePeptides = _subsumablePeptides\n                proteinEntry.sharedPeptides = _sharedPeptides\n\n        # - Save cluster information - #\n        for proteinId in proteinCluster:\n            inference._proteinToClusterId[proteinId] = clusterId\n        inference.clusters[clusterId] = clusterGroupIds\n\n    allProteins = set()\n    for proteinGroup in viewvalues(inference.groups):\n        allProteins.update(proteinGroup.proteins)\n        allProteins.update(proteinGroup.subsumableProteins)\n    assert len(allProteins) == len(protToPeps)\n    return inference"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _findProteinClusters(protToPeps, pepToProts):\n    clusters = list()\n    resolvingProteins = set(protToPeps)\n    while resolvingProteins:\n        protein = resolvingProteins.pop()\n        proteinCluster = set([protein])\n\n        peptides = set(protToPeps[protein])\n        parsedPeptides = set()\n\n        while len(peptides) != len(parsedPeptides):\n            for peptide in peptides:\n                proteinCluster.update(pepToProts[peptide])\n            parsedPeptides.update(peptides)\n\n            for protein in proteinCluster:\n                peptides.update(protToPeps[protein])\n        clusters.append(proteinCluster)\n        resolvingProteins = resolvingProteins.difference(proteinCluster)\n    return clusters", "response": "Find protein clusters in the specified protein to peptide mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _findSamesetProteins(protToPeps, proteins=None):\n    proteins = viewkeys(protToPeps) if proteins is None else proteins\n\n    equalEvidence = ddict(set)\n    for protein in proteins:\n        peptides = protToPeps[protein]\n        equalEvidence[tuple(sorted(peptides))].add(protein)\n    equalProteins = list()\n    for proteins in viewvalues(equalEvidence):\n        if len(proteins) > 1:\n            equalProteins.append(tuple(sorted(proteins)))\n    return equalProteins", "response": "Find proteins that are mapped to an identical set of peptides."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds proteins which peptides are a sub - set but not a same - set to other proteins.", "response": "def _findSubsetProteins(proteins, protToPeps, pepToProts):\n    \"\"\"Find proteins which peptides are a sub-set, but not a same-set to other\n    proteins.\n\n    :param proteins: iterable, proteins that are tested for being a subset\n    :param pepToProts: dict, for each peptide (=key) contains a set of parent\n        proteins (=value). For Example {peptide: {protein, ...}, ...}\n    :param protToPeps: dict, for each protein (=key) contains a set of\n        associated peptides (=value). For Example {protein: {peptide, ...}, ...}\n    :returns: a list of pairs of protein and their superset proteins.\n        [(protein, {superset protein, ...}), ...]\n    \"\"\"\n    proteinsEqual = lambda prot1, prot2: protToPeps[prot1] == protToPeps[prot2]\n\n    subGroups = list()\n    for protein in proteins:\n        peptideCounts = Counter()\n        for peptide in protToPeps[protein]:\n            proteins = pepToProts[peptide]\n            peptideCounts.update(proteins)\n        peptideCount = peptideCounts.pop(protein)\n\n        superGroups = set()\n        for sharingProtein, sharedPeptides in peptideCounts.most_common():\n            if peptideCount == sharedPeptides:\n                if not proteinsEqual(protein, sharingProtein):\n                    superGroups.add(sharingProtein)\n            else:\n                break\n        if superGroups:\n            subGroups.append((protein, superGroups))\n    return subGroups"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a set of proteins with redundant peptide evidence. After removing the redundant proteins from the \"protToPeps\" and \"pepToProts\" mapping, all remaining proteins have at least one unique peptide. The remaining proteins are a \"minimal\" set of proteins that are able to explain all peptides. However, this is not guaranteed to be the optimal solution with the least number of proteins. In addition it is possible that multiple solutions with the same number of \"minimal\" proteins exist. Procedure for finding the redundant proteins: 1. Generate a list of proteins that do not contain any unique peptides, a unique peptide has exactly one protein entry in \"pepToProts\". 2. Proteins are first sorted in ascending order of the number of peptides. Proteins with an equal number of peptides are sorted in descending order of their sorted peptide frequencies (= proteins per peptide). If two proteins are still equal, they are sorted alpha numerical in descending order according to their protein names. For example in the case of a tie between proteins \"A\" and \"B\", protein \"B\" would be removed. 3. Parse this list of sorted non unique proteins; If all its peptides have a frequency value of greater 1; mark the protein as redundant; remove its peptides from the peptide frequency count, continue with the next entry. 4. Return the set of proteins marked as redundant. :param pepToProts: dict, for each peptide (=key) contains a set of parent proteins (=value). For Example {peptide: {protein, ...}, ...} :param protToPeps: dict, for each protein (=key) contains a set of associated peptides (=value). For Example {protein: {peptide, ...}, ...} :param proteins: iterable, proteins that are tested for being redundant. If None all proteins in \"protToPeps\" are parsed. :returns: a set of redundant proteins, i.e. proteins that are not necessary to explain all peptides", "response": "def _findRedundantProteins(protToPeps, pepToProts, proteins=None):\n    \"\"\"Returns a set of proteins with redundant peptide evidence.\n\n    After removing the redundant proteins from the \"protToPeps\" and \"pepToProts\"\n    mapping, all remaining proteins have at least one unique peptide. The\n    remaining proteins are a \"minimal\" set of proteins that are able to explain\n    all peptides. However, this is not guaranteed to be the optimal solution\n    with the least number of proteins. In addition it is possible that multiple\n    solutions with the same number of \"minimal\" proteins exist.\n\n    Procedure for finding the redundant proteins:\n    1.  Generate a list of proteins that do not contain any unique peptides, a\n        unique peptide has exactly one protein entry in \"pepToProts\".\n    2.  Proteins are first sorted in ascending order of the number of peptides.\n        Proteins with an equal number of peptides are sorted in descending order\n            of their sorted peptide frequencies (= proteins per peptide).\n        If two proteins are still equal, they are sorted alpha numerical in\n        descending order according to their protein names. For example in the\n        case of a tie between proteins \"A\" and \"B\", protein \"B\" would be\n        removed.\n    3.  Parse this list of sorted non unique proteins;\n        If all its peptides have a frequency value of greater 1;\n        mark the protein as redundant; remove its peptides from the peptide\n        frequency count, continue with the next entry.\n    4.  Return the set of proteins marked as redundant.\n\n    :param pepToProts: dict, for each peptide (=key) contains a set of parent\n        proteins (=value). For Example {peptide: {protein, ...}, ...}\n    :param protToPeps: dict, for each protein (=key) contains a set of\n        associated peptides (=value). For Example {protein: {peptide, ...}, ...}\n    :param proteins: iterable, proteins that are tested for being redundant. If\n        None all proteins in \"protToPeps\" are parsed.\n    :returns: a set of redundant proteins, i.e. proteins that are not necessary\n        to explain all peptides\n    \"\"\"\n    if proteins is None:\n        proteins = viewkeys(protToPeps)\n\n    pepFrequency = _getValueCounts(pepToProts)\n    protPepCounts = _getValueCounts(protToPeps)\n\n    getCount = operator.itemgetter(1)\n    getProt = operator.itemgetter(0)\n\n    #TODO: quick and dirty solution\n    #NOTE: add a test for merged proteins\n    proteinTuples = list()\n    for protein in proteins:\n        if isinstance(protein, tuple):\n            proteinTuples.append(protein)\n        else:\n            proteinTuples.append(tuple([protein]))\n\n    sort = list()\n    for protein in sorted(proteinTuples, reverse=True):\n        if len(protein) == 1:\n            protein = protein[0]\n\n        protPepFreq = [pepFrequency[pep] for pep in protToPeps[protein]]\n        if min(protPepFreq) > 1:\n            sortValue = (len(protPepFreq)*-1, sorted(protPepFreq, reverse=True))\n            sort.append((protein, sortValue))\n    sortedProteins = map(getProt, sorted(sort, key=getCount, reverse=True))\n\n    redundantProteins = set()\n    for protein in sortedProteins:\n        for pep in protToPeps[protein]:\n            if pepFrequency[pep] <= 1:\n                break\n        else:\n            protPepFrequency = Counter(protToPeps[protein])\n            pepFrequency.subtract(protPepFrequency)\n            redundantProteins.add(protein)\n    return redundantProteins"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge the entries in the given proteinLists into a single dict.", "response": "def _mergeProteinEntries(proteinLists, protToPeps):\n    \"\"\"Returns a new \"protToPeps\" dictionary with entries merged that are\n    present in proteinLists.\n\n    NOTE:\n        The key of the merged entry is a tuple of the sorted protein keys. This\n        behaviour might change in the future; the tuple might be replaced by\n        simply one of the protein entries which is then representative for all.\n\n    :param proteinLists: a list of protein groups that will be merged\n        [{protein, ...}, ...]\n    :param protToPeps: dict, for each protein (=key) contains a set of\n        associated peptides (=value). For Example {protein: {peptide, ...}, ...}\n    :returns: dict, {protein: set([peptid, ...])}\n    \"\"\"\n    mergedProtToPeps = dict(protToPeps)\n    for proteins in proteinLists:\n        for protein in proteins:\n            peptides = mergedProtToPeps.pop(protein)\n        mergedProtein = tuple(sorted(proteins))\n        mergedProtToPeps[mergedProtein] = peptides\n    return mergedProtToPeps"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new dict that does not contain any entries present in proteins.", "response": "def _reducedProtToPeps(protToPeps, proteins):\n    \"\"\"Returns a new, reduced \"protToPeps\" dictionary that does not contain\n    entries present in \"proteins\".\n\n    :param protToPeps: dict, for each protein (=key) contains a set of\n        associated peptides (=value). For Example {protein: {peptide, ...}, ...}\n    :param proteins: a list of proteinSet\n    :returns: dict, protToPeps not containing entries from \"proteins\"\n    \"\"\"\n    return {k: v for k, v in viewitems(protToPeps) if k not in proteins}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _findUniqueMappingValues(mapping):\n    uniqueMappingValues = set()\n    for entries in viewvalues(mapping):\n        if len(entries) == 1:\n            uniqueMappingValues.update(entries)\n    return uniqueMappingValues", "response": "Find unique mapping entries that are unique for one key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds unique mapping keys that only have one entry.", "response": "def _findUniqueMappingKeys(mapping):\n    \"\"\"Find mapping keys that only have one entry (value length of 1.\n\n    :param mapping: dict, for each key contains a set of entries\n    :returns: a set of unique mapping keys\n    \"\"\"\n\n    uniqueMappingKeys = set()\n    for key, entries in viewitems(mapping):\n        if len(entries) == 1:\n            uniqueMappingKeys.add(key)\n    return uniqueMappingKeys"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a protein to peptide or peptide to a protein mapping.", "response": "def _invertMapping(mapping):\n    \"\"\"Converts a protein to peptide or peptide to protein mapping.\n\n    :param mapping: dict, for each key contains a set of entries\n\n    :returns: an inverted mapping that each entry of the values points to a set\n        of initial keys.\n    \"\"\"\n    invertedMapping = ddict(set)\n    for key, values in viewitems(mapping):\n        for value in values:\n            invertedMapping[value].add(key)\n    return invertedMapping"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a counter object ; contains for each key of the mapping the counts of the respective value element.", "response": "def _getValueCounts(mapping):\n    \"\"\"Returns a counter object; contains for each key of the mapping the counts\n    of the respective value element (= set length).\n\n    :param mapping: dict, for each key contains a set of entries.\n    :returns: a counter\n    \"\"\"\n    return Counter({k: len(v) for k, v in viewitems(mapping)})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mappingGetValueSet(mapping, keys):\n    setUnion = set()\n    for k in keys:\n        setUnion = setUnion.union(mapping[k])\n    return setUnion", "response": "Return a set of values from the mapping."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a set where merged protein entries in proteins are flattened.", "response": "def _flattenMergedProteins(proteins):\n    \"\"\"Return a set where merged protein entries in proteins are flattened.\n\n    :param proteins: an iterable of proteins, can contain merged protein entries\n        in the form of tuple([protein1, protein2]).\n    returns a set of protein entries, where all entries are strings\n    \"\"\"\n    proteinSet = set()\n    for protein in proteins:\n        if isinstance(protein, tuple):\n            proteinSet.update(protein)\n        else:\n            proteinSet.add(protein)\n    return proteinSet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getGroups(self, proteinId):\n        return [self.groups[gId] for gId in self._proteinToGroupIds[proteinId]]", "response": "Return a list of protein groups a protein is associated with."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addProteinGroup(self, groupRepresentative):\n        groupId = self._getNextGroupId()\n        self.groups[groupId] = ProteinGroup(groupId, groupRepresentative)\n        self.addLeadingToGroups(groupRepresentative, groupId)\n        return groupId", "response": "Adds a new protein group and returns the groupId."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding one or multiple leading proteins to one or multiple groups.", "response": "def addLeadingToGroups(self, proteinIds, groupIds):\n        \"\"\"Add one or multiple leading proteins to one or multiple protein\n        groups.\n\n        :param proteinIds: a proteinId or a list of proteinIds, a proteinId\n            must be a string.\n        :param groupIds: a groupId or a list of groupIds, a groupId\n            must be a string.\n        \"\"\"\n        for groupId in AUX.toList(groupIds):\n            self.groups[groupId].addLeadingProteins(proteinIds)\n            self._addProteinIdsToGroupMapping(proteinIds, groupId)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addSubsetToGroups(self, proteinIds, groupIds):\n        for groupId in AUX.toList(groupIds):\n            self.groups[groupId].addSubsetProteins(proteinIds)\n            self._addProteinIdsToGroupMapping(proteinIds, groupId)", "response": "Add one or multiple subset proteins to one or multiple groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addSubsumableToGroups(self, proteinIds, groupIds):\n        for groupId in AUX.toList(groupIds):\n            self.groups[groupId].addSubsumableProteins(proteinIds)\n            self._addProteinIdsToGroupMapping(proteinIds, groupId)", "response": "Add one or multiple subsumable proteins to one or multiple groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a groupId to one or multiple entries of the internal proteinToGroupId mapping.", "response": "def _addProteinIdsToGroupMapping(self, proteinIds, groupId):\n        \"\"\"Add a groupId to one or multiple entries of the internal\n        proteinToGroupId mapping.\n\n        :param proteinIds: a proteinId or a list of proteinIds, a proteinId\n            must be a string.\n        :param groupId: str, a groupId\n        \"\"\"\n        for proteinId in AUX.toList(proteinIds):\n            self._proteinToGroupIds[proteinId].add(groupId)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _addProteins(self, proteinIds, containerNames):\n        proteinIds = AUX.toList(proteinIds)\n        for containerName in containerNames:\n            proteinContainer = getattr(self, containerName)\n            proteinContainer.update(proteinIds)", "response": "Adds one or multiple proteinIds to the respective container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the capabilities of a primitive are enough to satisfy a requirement.", "response": "def satisfies(self, other):\n        \"\"\"Check if the capabilities of a primitive are enough to satisfy a requirement.\n\n        Should be called on a Requirement that is acting as a\n        capability of a primitive. This method returning true means\n        that the capability advertised here is enough to handle\n        representing the data described by the Requirement passed in\n        as 'other'.\n\n        Here is a chart showing what satisfies what.\n\n             other\n              A C 0 1\n           |Y N N N N\n        s A|Y Y Y Y Y\n        e C|Y - Y Y Y\n        l 0|Y * * Y N\n        f 1|Y * * N Y\n\n        ' ' = No Care\n        A = arbitrary\n        C = Constant\n        0 = ZERO\n        1 = ONE\n\n        Y = YES\n        N = NO\n        - = Could satisfy with multiple instances\n        * = Not yet determined behavior. Used for bitbanging controllers.\n\n        \"\"\"\n        if other.isnocare:\n            return True\n        if self.isnocare:\n            return False\n        if self.arbitrary:\n            return True\n        if self.constant and not other.arbitrary:\n            return True\n        if self.value is other.value and not other.arbitrary\\\n           and not other.constant:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _list(self, foldername=\"INBOX\", reverse=False, since=None):\n        folder = self.folder \\\n            if foldername == \"INBOX\" \\\n            else self._getfolder(foldername)\n\n        def sortcmp(d):\n            try:\n                return d[1].date\n            except:\n                return -1\n\n        lst = folder.items() if not since else folder.items_since(since)\n        sorted_lst = sorted(lst, key=sortcmp, reverse=1 if reverse else 0)\n        itemlist = [(folder, key, msg) for key,msg in sorted_lst]\n        return itemlist", "response": "Do structured list output."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ls(self, foldername=\"INBOX\", reverse=False, since=None, grep=None, field=None, stream=sys.stdout):\n        if foldername == \"\":\n            foldername = \"INBOX\"\n\n        msg_list = self._list(foldername, reverse, since)\n        for folder, mk, m in msg_list:\n            try:\n                # I am very unsure about this defaulting of foldername\n                output_items = (\n                    \"%s%s%s\" % (folder.folder or foldername or \"INBOX\", SEPERATOR, mk),\n                    m.date,\n                    m.get_from()[0:50] if m.get_from() else \"\", \n                    m.get_flags(),\n                    re.sub(\"\\n\", \"\", m.get_subject() or \"\")\n                    )\n\n                output_string = \"% -20s % 20s % 50s  [%s]  %s\" % output_items\n                if not grep or (grep and grep in output_string):\n                    if field:\n                        print(output_items[int(field)], file=stream)\n                    else:\n                        print(output_string, file=stream)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    # Broken pipe we can ignore\n                    return\n                self.logger.exception(\"whoops!\")\n            except Exception as e:\n                self.logger.exception(\"whoops!\")", "response": "List the contents of the INBOX folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes JSON listing of the folder.", "response": "def lisp(self, foldername=\"INBOX\", reverse=False, since=None, stream=sys.stdout):\n        \"\"\"Do JSON list of the folder to the stream.\n\n        'since' allows the listing to be date filtered since that\n        date. It should be a float, a time since epoch.\n        \"\"\"\n        def fromval(hdr):\n            if hdr:\n                return parseaddr(hdr)\n\n        for folder, mk, m in self._list(foldername, reverse, since):\n            try:\n                print(json.dumps({\n                        'folder': folder.folder or foldername or \"INBOX\",\n                        'key': \"%s%s%s\" % (folder.folder or foldername or \"INBOX\", SEPERATOR, mk),\n                        'date':  str(m.date),\n                        \"flags\": m.get_flags(),\n                        'from': fromval(m.get_from()),\n                        'subject': re.sub(\"\\n|\\'|\\\"\", _escape, m.get_subject() or \"\")\n                        }), file=stream)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    # Broken pipe we can ignore\n                    return\n                self.logger.exception(\"whoops!\")\n            except Exception as e:\n                self.logger.exception(\"whoops!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lsfolders(self, stream=sys.stdout):\n        for f in self.folder.folders():\n            print(f.folder.strip(\".\"), file=stream)", "response": "List the subfolders of this instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding the message header against each part from the message.", "response": "def _get(self, msgid):\n        \"\"\"Yields the message header against each part from the message.\"\"\"\n        foldername, msgkey = msgid.split(SEPERATOR)\n        folder = self.folder if foldername == \"INBOX\" else self._getfolder(foldername)\n        # Now look up the message\n        msg = folder[msgkey]\n        msg.is_seen = True\n        hdr = list(msg.items())\n        for p in msg.walk():\n            yield hdr,p\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the first plain part of a message.", "response": "def gettext(self, msgid, stream=sys.stdout, splitter=\"--text follows this line--\\n\"):\n        \"\"\"Get the first text part we can find and print it as a message.\n\n        This is a simple cowpath, most of the time you want the first plain part.\n\n        'msgid' is the message to be used\n        'stream' is printed to with the header, splitter, first-textpart\n        'splitter' is text used to split the header from the body, Emacs uses this\n        \"\"\"\n        for hdr,part in self._get(msgid):\n            if part.get_content_type() == \"text/plain\":\n                for name,val in hdr:\n                    # Use the subtype, since we're printing just that - tidy it up first\n                    if name.lower() == \"content-type\":\n                        val = part[\"content-type\"]\n                    val = \" \".join([l.strip() for l in val.split(\"\\n\")])\n                    print(\"%s: %s\" % (name,val), file=stream)\n                print(splitter, file=stream)\n                payload = part.get_payload(decode=True)\n                # There seems to be a problem with the parser not doing charsets for parts\n                chartype = part.get_charset() \\\n                    or _get_charset(part.get(\"Content-Type\", \"\")) \\\n                    or \"us-ascii\"\n                print(payload.decode(chartype), file=stream)\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the first part from the message and print it raw.", "response": "def getrawpart(self, msgid, stream=sys.stdout):\n        \"\"\"Get the first part from the message and print it raw.\n        \"\"\"\n        for hdr, part in self._get(msgid):\n            pl = part.get_payload(decode=True)\n            if pl != None:\n                print(pl, file=stream)\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getrawpartid(self, msgid, partid, stream=sys.stdout):\n        parts = [part for hdr,part in self._get(msgid)]\n        part = parts[int(partid)]\n        pl = part.get_payload(decode=True)\n        if pl != None:\n            print(pl, file=stream)", "response": "Get a specific part from the message and print it raw."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getraw(self, msgid, stream=sys.stdout):\n        foldername, msgkey = msgid.split(SEPERATOR)\n        folder = self.folder if foldername == \"INBOX\" else self._getfolder(foldername)\n        msg = folder[msgkey]\n        print(msg.content)", "response": "Get the whole message and print it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget and print the whole message.", "response": "def getstruct(self, msgid, as_json=False, stream=sys.stdout):\n        \"\"\"Get and print the whole message.\n\n        as_json indicates whether to print the part list as JSON or not.\n        \"\"\"\n        parts = [part.get_content_type() for hdr, part in self._get(msgid)]\n        if as_json:\n            print(json.dumps(parts), file=stream)\n        else:\n            for c in parts:\n                print(c, file=stream)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract an alphabet from the given grammar.", "response": "def _extract_alphabet(self, grammar):\n        \"\"\"\n        Extract an alphabet from the given grammar.\n        \"\"\"\n        alphabet = set([])\n        for terminal in grammar.Terminals:\n            alphabet |= set([x for x in terminal])\n        self.alphabet = list(alphabet)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mpda(self, re_grammar, splitstring=0):\n        cnfgrammar = CNFGenerator(re_grammar)\n\n        if not self.alphabet:\n            self._extract_alphabet(cnfgrammar)\n\n        cnftopda = CnfPda(self.alphabet)\n        productions = {}\n        nonterminals = []\n        nonterminals.append(cnfgrammar.init_symbol)\n        for key in list(cnfgrammar.grammar_nonterminals):\n            if key != cnfgrammar.init_symbol:\n                nonterminals.append(key)\n        for key in list(cnfgrammar.grammar_nonterminals):\n            j = 0\n            productions[key] = {}\n            # print 'testing '+key\n            for pair in cnfgrammar.grammar_rules:\n                cnf_form = list(pair)\n                if cnf_form[0] == key:\n                    productions[key][j] = {}\n                    if isinstance(cnf_form[1], type(())):\n                        #            print list(p[1])\n                        productions[key][j]['b0'] = list(cnf_form[1])[0]\n                        productions[key][j]['b1'] = list(cnf_form[1])[1]\n                    else:\n                        #           print p[1]\n                        productions[key][j]['a'] = cnf_form[1]\n                    j = j + 1\n        return cnftopda.initialize(\n            nonterminals, productions, list(\n                cnfgrammar.grammar_terminals), splitstring)", "response": "This function generates a new PDA based on the grammar rules and the grammar rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yyparse(self, cfgfile, splitstring=0):\n        re_grammar = self._read_file(cfgfile)\n        mma = self._mpda(re_grammar, splitstring)\n        return mma", "response": "This function returns the PDA generated from the CFG rules in cfgfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsorts the inputted items by their natural order, trying to extract a \\ number from them to sort by. :param a <str> b <str> :return <int> 1 || 0 || -1 :usage |>>> from projex import sorting |>>> a = [ 'test1', 'test2', 'test10', 'test20', 'test09' ] |>>> a.sort() |>>> print a |['test09', 'test1', 'test10', 'test2', 'test20'] |>>> a.sort( sorting.natural ) |>>> print a |['test1', 'test2', 'test09', 'test10', 'test20']", "response": "def natural(a, b):\n    \"\"\"\n    Sorts the inputted items by their natural order, trying to extract a \\\n    number from them to sort by.\n    \n    :param      a       <str>\n                b       <str>\n    \n    :return     <int> 1 || 0 || -1\n    \n    :usage      |>>> from projex import sorting\n                |>>> a = [ 'test1', 'test2', 'test10', 'test20', 'test09' ]\n                |>>> a.sort()\n                |>>> print a\n                |['test09', 'test1', 'test10', 'test2', 'test20']\n                |>>> a.sort( sorting.natural )\n                |>>> print a\n                |['test1', 'test2', 'test09', 'test10', 'test20']\n    \"\"\"\n    stra = nstr(a).lower()\n    strb = nstr(b).lower()\n\n    # test to see if the two are identical\n    if stra == strb:\n        return 0\n\n    # look up all the pairs of items\n    aresults = EXPR_NATURAL.findall(stra)\n    bresults = EXPR_NATURAL.findall(strb)\n\n    # make sure we have the same number of results\n    bcount = len(bresults)\n    for i in range(len(aresults)):\n        # make sure we don't exceed the number of elements in b\n        if bcount <= i:\n            break\n\n        atext, anum = aresults[i]\n        btext, bnum = bresults[i]\n\n        # compare the text components\n        if atext != btext:\n            return cmp(atext, btext)\n\n        if not anum:\n            anum = 0\n        if not bnum:\n            bnum = 0\n\n        # compare the numeric components\n        anum = int(anum)\n        bnum = int(bnum)\n        if anum != bnum:\n            return cmp(anum, bnum)\n\n    # b has less characters than a, so should sort before\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsorts the inputted items by their natural order.", "response": "def versional(a, b):\n    \"\"\"\n    Sorts the inputted items by their natural order, trying to extract a \\\n    number from them to sort by.\n    \n    :param      a       <str>\n                b       <str>\n    \n    :return     <int> 1 || 0 || -1\n    \n    :usage      |>>> from projex import sorting\n                |>>> a = [ 'test-1.1.2', 'test-1.02', 'test-1.2', 'test-1.18' ]\n                |>>> a.sort()\n                |>>> print a\n                |['test-1.02', 'test-1.1.2', 'test-1.18', 'test-1.2']\n                |>>> a.sort( sorting.natural )\n                |>>> print a\n                |['test-1.1.2', 'test-1.02', 'test-1.2', 'test-1.18']\n                |>>> a.sort( sorting.versional )\n                |>>> print a\n                |['test-1.1.2', 'test-1.02', 'test-1.18', 'test-1.2']\n    \"\"\"\n    stra = nstr(a).lower()\n    strb = nstr(b).lower()\n\n    # look up all the pairs of items\n    aresults = EXPR_VERSIONAL.findall(stra)\n    bresults = EXPR_VERSIONAL.findall(strb)\n\n    # make sure we have the same number of results\n    bcount = len(bresults)\n    for i in range(len(aresults)):\n        # make sure we don't exceed the number of elements in b\n        if bcount <= i:\n            break\n\n        atext, anum = aresults[i]\n        btext, bnum = bresults[i]\n\n        # compare the text components\n        if atext != btext:\n            return cmp(atext, btext)\n\n        if not anum:\n            anum = 0\n        if not bnum:\n            bnum = 0\n\n        # compare the numeric components\n        if atext == '.':\n            anum = int(float('.' + anum) * 10000)\n            bnum = int(float('.' + bnum) * 10000)\n        else:\n            anum = int(anum)\n            bnum = int(bnum)\n\n        if anum != bnum:\n            return cmp(anum, bnum)\n\n    # b has less characters than a, so should sort before\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef action(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_ACTION', column, value, **kwargs)", "response": "Get the current action code for this grant project."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef applicant(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_APPLICANT', column, value, **kwargs)", "response": "Return the applicant information for a grant."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprovides the Catalog of Federal Domestic Assistance codes and names.", "response": "def assistance(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Provides the Catalog of Federal Domestic Assistance (CFDA) codes and\n        names.\n        \"\"\"\n        return self._resolve_call('GIC_ASST_PGM', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authority(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_AUTHORITY', column, value, **kwargs)", "response": "Provides codes and associated authorizing statutes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the current construction of a specific resource.", "response": "def construction(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Identifies monetary, descriptive, and milestone information for\n        Wastewater Treatment construction grants.\n\n        >>> GICS().construction('complete_percent', 91)\n        \"\"\"\n        return self._resolve_call('GIC_CONSTRUCTION', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the assistance dollar amounts by eligible cost category.", "response": "def eligible_cost(self, column=None, value=None, **kwargs):\n        \"\"\"\n        The assistance dollar amounts by eligible cost category.\n\n        >>> GICS().eligible_cost('amount', 100000)\n        \"\"\"\n        return self._resolve_call('GIC_ELIGIBLE_COST', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproviding various award project and grant personnel information.", "response": "def grant(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Provides various award, project, and grant personnel information.\n\n        >>> GICS().grant('project_city_name', 'San Francisco')\n        \"\"\"\n        return self._resolve_call('GIC_GRANT', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the assistance of grants and assistance.", "response": "def grant_assistance(self, column=None, value=None, **kwargs):\n        \"\"\"Many-to-many table connecting grants and assistance.\"\"\"\n        return self._resolve_call('GIC_GRANT_ASST_PGM', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grant_authority(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_GRANT_AUTH', column, value, **kwargs)", "response": "Get a list of grants and authority."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lab_office(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_LAB_OFFICE', column, value, **kwargs)", "response": "Abbreviations names and locations of labratories and offices."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of statuses and related dates of certain grants.", "response": "def milestone(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Status codes and related dates of certain grants,\n\n        >>> GICS().milestone('milestone_date', '16-MAR-01')\n        \"\"\"\n        return self._resolve_call('GIC_MILESTONE', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef record_type(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_RECORD_TYPE', column, value, **kwargs)", "response": "Returns a string containing the code and description of the record type of the current project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the grant number for the current SRF capitalization.", "response": "def srf_cap(self, column=None, value=None, **kwargs):\n        \"\"\"\n        Fiscal dollar amounts for State Revolving Fund Capitalization\n        Grants.\n\n        >>> GICS().srf_cap('grant_number', '340001900')\n        \"\"\"\n        return self._resolve_call('GIC_SRF_CAP', column, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(self, column=None, value=None, **kwargs):\n        return self._resolve_call('GIC_STATUS', column, value, **kwargs)", "response": "Provides codes and descriptions of project milestones."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply maspy. xml. clearTag to the tag attribute of the element and all child elements recursively to all child elements.", "response": "def recClearTag(element):\n    \"\"\"Applies maspy.xml.clearTag() to the tag attribute of the \"element\" and\n    recursively to all child elements.\n\n    :param element: an :instance:`xml.etree.Element`\n    \"\"\"\n    children = element.getchildren()\n    if len(children) > 0:\n        for child in children:\n            recClearTag(child)\n    element.tag = clearTag(element.tag)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recRemoveTreeFormating(element):\n    children = element.getchildren()\n    if len(children) > 0:\n        for child in children:\n            recRemoveTreeFormating(child)\n    if element.text is not None:\n        if len(element.text.strip()) == 0:\n            element.text = None\n        else:\n            element.text = element.text.strip()\n    if element.tail is not None:\n        if len(element.tail.strip()) == 0:\n            element.tail = None\n        else:\n            element.tail = element.tail.strip()", "response": "Removes whitespace characters which are leftovers from previous xml\n    formatting."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a copy of an xml element and recursively of all child elements.", "response": "def recCopyElement(oldelement):\n    \"\"\"Generates a copy of an xml element and recursively of all\n    child elements.\n\n    :param oldelement: an instance of lxml.etree._Element\n\n    :returns: a copy of the \"oldelement\"\n\n    .. warning::\n        doesn't copy ``.text`` or ``.tail`` of xml elements\n    \"\"\"\n    newelement = ETREE.Element(oldelement.tag, oldelement.attrib)\n    if len(oldelement.getchildren()) > 0:\n        for childelement in oldelement.getchildren():\n            newelement.append(recCopyElement(childelement))\n    return newelement"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getParam(xmlelement):\n    elementTag = clearTag(xmlelement.tag)\n    if elementTag in ['userParam', 'cvParam', 'referenceableParamGroupRef']:\n        if elementTag == 'cvParam':\n            param = cvParamFromDict(xmlelement.attrib)\n        elif elementTag == 'userParam':\n            param = userParamFromDict(xmlelement.attrib)\n        else:\n            param = refParamGroupFromDict(xmlelement.attrib)\n    else:\n        param = False\n    return param", "response": "Converts an mzML xml element to a param tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting params from xmlelement", "response": "def extractParams(xmlelement):\n    \"\"\" #TODO docstring\n\n    :param xmlelement: #TODO docstring\n\n    :returns: #TODO docstring\n    \"\"\"\n    params = list()\n    children = list()\n    for child in xmlelement.getchildren():\n        param = getParam(child)\n        if param:\n            params.append(param)\n        else:\n            children.append(child)\n    return params, children"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating new mzML parameter xml elements and adds them to the parentelement as xml children elements.", "response": "def xmlAddParams(parentelement, params):\n    \"\"\"Generates new mzML parameter xml elements and adds them to the\n    'parentelement' as xml children elements.\n\n    :param parentelement: :class:`xml.etree.Element`, an mzML element\n    :param params: a list of mzML parameter tuples ('cvParam', 'userParam' or\n        'referencableParamGroup')\n    \"\"\"\n    if not params:\n        return None\n    for param in params:\n        if len(param) == 3:\n            cvAttrib = {'cvRef': param[0].split(':')[0], 'accession': param[0],\n                        'name':oboTranslator.getNameWithId(param[0])\n                        }\n            if param[1]:\n                cvAttrib.update({'value': param[1]})\n            else:\n                cvAttrib.update({'value': ''})\n            if param[2]:\n                unitName = oboTranslator.getNameWithId(param[2])\n                cvAttrib.update({'unitAccession': param[2],\n                                 'unitCvRef': param[2].split(':')[0],\n                                 'unitName': unitName\n                                 })\n            paramElement = ETREE.Element('cvParam', **cvAttrib)\n        elif len(param) == 4:\n            userAttrib = {'name': param[0]}\n            if param[1]:\n                userAttrib.update({'value': param[1]})\n            else:\n                userAttrib.update({'value': ''})\n            if param[2]:\n                userAttrib.update({'unitAccession': param[2],\n                                   'unitCvRef': param[2].split(':')[0]\n                                   })\n            if param[3]:\n                userAttrib.update({'type': param[3]})\n            paramElement = ETREE.Element('userParam', **userAttrib)\n        elif param[0] == 'ref':\n            refAttrib = {'ref': param[1]}\n            paramElement = ETREE.Element('referenceableParamGroupRef',\n                                         **refAttrib\n                                         )\n        parentelement.append(paramElement)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interpretBitEncoding(bitEncoding):\n    if bitEncoding == '64':\n        floattype = 'd' # 64-bit\n        numpyType = numpy.float64\n    elif bitEncoding == '32':\n        floattype = 'f' # 32-bit\n        numpyType = numpy.float32\n    else:\n        errorText = ''.join(['bitEncoding \\'', bitEncoding, '\\' not defined. ',\n                             'Must be \\'64\\' or \\'32\\''\n                             ])\n        raise TypeError(errorText)\n    return (floattype, numpyType)", "response": "Interprets a bit encoding of the base64 or 32 - bit float type string and a numpy array type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to decode a mzML byte array into a numpy array.", "response": "def decodeBinaryData(binaryData, arrayLength, bitEncoding, compression):\n    \"\"\"Function to decode a mzML byte array into a numpy array. This is the\n    inverse function of :func:`encodeBinaryData`. Concept inherited from\n    :func:`pymzml.spec.Spectrum._decode` of the python library `pymzML\n    <https://pymzml.github.io/>`_.\n\n    :param binaryData: #TODO: docstring\n    :param arrayLength: #TODO: docstring\n    :param binEncoding: #TODO: docstring\n    :param compression: #TODO: docstring\n\n    :returns: #TODO: docstring\n    \"\"\"\n    #TODO: should raise an error if a wrong compression is specified\n    bitEncodedData = binaryData.encode(\"utf-8\")\n    bitDecodedData = B64DEC(bitEncodedData)\n    floattype, numpyType = interpretBitEncoding(bitEncoding)\n\n    if compression == 'zlib':\n        decompressedData = zlib.decompress(bitDecodedData)\n    else:\n        decompressedData = bitDecodedData\n\n    fmt = '{endian}{arraylength}{floattype}'.format(endian='<',\n                                                    arraylength=arrayLength,\n                                                    floattype=floattype\n                                                    )\n    dataArray = numpy.array(UNPACK(fmt, decompressedData), dtype=numpyType)\n    return dataArray"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encodeBinaryData(dataArray, bitEncoding, compression):\n    #TODO: should raise an error if a wrong compression is specified\n    arrayLength = len(dataArray)\n    floattype, __ = interpretBitEncoding(bitEncoding)\n    fmt = '{endian}{arraylength}{floattype}'.format(endian='<',\n                                                    arraylength=arrayLength,\n                                                    floattype=floattype\n                                                    )\n    packedData = PACK(fmt, *dataArray)\n\n    if compression == 'zlib':\n        compressedData = zlib.compress(packedData)\n    else:\n        compressedData = packedData\n\n    encodedData = B64ENC(compressedData)\n    return encodedData, arrayLength", "response": "Function to encode a numpy. array into a mzML byte array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findBinaryDataType(params):\n    binaryDataType = None\n    cvParam = None\n    for param in params:\n        if param[0] in binaryDataArrayTypes:\n            binaryDataType = binaryDataArrayTypes[param[0]]\n            cvParam = param\n            break\n    return binaryDataType, cvParam", "response": "finds the binary data type and cvParam from the parameter list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extractBinaries(binaryDataArrayList, arrayLength):\n    extractedArrays = dict()\n    arrayInfo = dict()\n    for binaryData in binaryDataArrayList:\n        if findParam(binaryData['params'], 'MS:1000523') is not None:\n            bitEncoding = '64'\n        else:\n            bitEncoding = '32'\n        if findParam(binaryData['params'], 'MS:1000574') is not None:\n            compression = 'zlib'\n        else:\n            compression = None\n        dataType, dataTypeParam = findBinaryDataType(binaryData['params'])\n        if binaryData['binary']:\n            extractedArrays[dataType] = decodeBinaryData(binaryData['binary'],\n                                                         arrayLength,\n                                                         bitEncoding,\n                                                         compression\n                                                         )\n        else:\n            __, numpyType = interpretBitEncoding(bitEncoding)\n            extractedArrays[dataType] = numpy.array([], dtype=numpyType)\n\n        binaryData['binary'] = None\n        arrayInfo[dataType] = {'dataProcessingRef': None,\n                               'params': binaryData['params']\n                               }\n        if 'dataProcessingRef' in binaryData:\n            arrayInfo[dataType]['dataProcessingRef'] = \\\n                binaryData['dataProcessingRef']\n    return extractedArrays, arrayInfo", "response": "Extract the binary data of the next language from the list of binary data objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the next event element and tag.", "response": "def next(self):\n        \"\"\" #TODO: docstring\n\n        :returns: #TODO: docstring\n        \"\"\"\n        try:\n            self.event, self.element = next(self.iterator)\n            self.elementTag = clearTag(self.element.tag)\n        except StopIteration:\n            clearParsedElements(self.element)\n            raise StopIteration\n        return self.event, self.element, self.elementTag"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the metadata from the Mzml file.", "response": "def loadMetadata(self):\n        \"\"\" #TODO: docstring \"\"\"\n        #TODO: change that spectra dont have to be iterated to extract metadata\n        #node\n        if self._parsed:\n            raise TypeError('Mzml file already parsed.')\n        [None for _ in self._parseMzml()]\n        self._parsed = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseSpectra(self):\n        #Note: the spectra need to be iterated completely to save the\n        #metadataNode\n        if self._parsed:\n            raise TypeError('Mzml file already parsed.')\n        self._parsed = True\n        return self._parseMzml()", "response": "Parse the Mzml file and return a list of the spectra."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the MzML element and yield the xml elements.", "response": "def _parseMzml(self):\n        \"\"\" #TODO: docstring \"\"\"\n        #TODO: this is already pretty nested, reduce that eg by using a function\n        #   processRunNode\n        for event, element, elementTag in self:\n            if elementTag == 'mzML':\n                metadataNode = ETREE.Element(self.elementTag,\n                                             self.element.attrib\n                                             )\n                _, _, targetTag = next(self)\n                break\n\n        while targetTag != 'mzML':\n            if targetTag == 'run':\n                runNode = ETREE.Element('run', self.element.attrib)\n                next(self)\n                while self.event != 'end' or self.elementTag != 'run':\n                    if self.elementTag == 'spectrumList':\n                        #Add spectrumListNode\n                        specListAttrib = {'defaultDataProcessingRef':\n                                          self.element.attrib['defaultDataProcessingRef']\n                                          }\n                        specListNode = ETREE.Element('spectrumList', specListAttrib)\n                        runNode.append(specListNode)\n                        #Parse and yield spectrum xml elements\n                        while self.event != 'end' or self.elementTag != 'spectrumList':\n                            if self.event == 'end' and self.elementTag == 'spectrum':\n                                yield self.element\n                                clearParsedElements(self.element)\n                            next(self)\n                    elif self.elementTag == 'chromatogramList':\n                        #Add chromatogramListNode\n                        chromListAttrib = {'defaultDataProcessingRef':\n                                           self.element.attrib['defaultDataProcessingRef']\n                                           }\n                        chromListNode = ETREE.Element('chromatogramList',\n                                                      chromListAttrib\n                                                      )\n                        runNode.append(chromListNode)\n                        #Parse and store chromatogram xml elements\n                        while self.event != 'end' or self.elementTag != 'chromatogramList':\n                            if self.event == 'end' and self.elementTag == 'chromatogram':\n                                self.chromatogramList.append(self.element)\n                                #Alternatively also the chromatogram xml\n                                #elements could be yielded:\n                                #   yield self.element\n                                #   clearParsedElements(self.element)\n                            next(self)\n                    else:\n                        runNode.append(self.element)\n                    next(self)\n                metadataNode.append(runNode)\n                break\n            else:\n                while self.event != 'end' or self.elementTag != targetTag:\n                    next(self)\n                metadataNode.append(self.element)\n            _, _, targetTag = next(self)\n        recClearTag(metadataNode)\n        recRemoveTreeFormating(metadataNode)\n        self.metadataNode = recCopyElement(metadataNode)\n        self.openfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the partition function of the system at every point in time.", "response": "def calc_partition_function(mass, omega_array, temperature_array):\n    \"\"\"\n    Calculates the partition function of your system at each point in time.\n\n    Parameters\n    ----------\n    mass : float\n        The mass of the particle in kg\n    omega_array : array\n        array which represents omega at every point in your time trace\n        and should therefore have the same length as the Hamiltonian\n    temperature_array : array\n        array which represents the temperature at every point in your time trace\n        and should therefore have the same length as the Hamiltonian\n\n    Returns:\n    -------\n    Partition function : array\n        The Partition Function at every point in time over a given trap-frequency and temperature change.\n    \"\"\"\n    Kappa_t= mass*omega_array**2    \n    return _np.sqrt(4*_np.pi**2*_scipy.constants.Boltzmann**2*temperature_array**2/(mass*Kappa_t))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_entropy(phase_space_density_array):\n    entropy = -_scipy.constants.Boltzmann*_np.log(phase_space_density_array)\n    return entropy", "response": "Calculates the entropy of the system at every point in time by the given phase space density evolution in time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the Hamiltonian of the system.", "response": "def calc_hamiltonian(self, mass, omega_array):\n        \"\"\"\n        Calculates the standard (pot+kin) Hamiltonian of your system.\n        \n        Parameters\n        ----------\n        mass : float\n            The mass of the particle in kg\n        omega_array : array\n            array which represents omega at every point in your time trace\n            and should therefore have the same length as self.position_data\n        \n        Requirements\n        ------------\n        self.position_data : array\n            Already filtered for the degree of freedom of intrest and converted into meters. \n\n        Returns\n        -------\n        Hamiltonian : array\n            The calculated Hamiltonian\n        \"\"\"\n        Kappa_t= mass*omega_array**2\n        self.E_pot = 0.5*Kappa_t*self.position_data**2\n        self.E_kin = 0.5*mass*(_np.insert(_np.diff(self.position_data), 0, (self.position_data[1]-self.position_data[0]))*self.SampleFreq)**2\n        self.Hamiltonian = self.E_pot + self.E_kin\n        return self.Hamiltonian"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_phase_space_density(self, mass, omega_array, temperature_array):\n\n        return self.calc_hamiltonian(mass, omega_array)/calc_partition_function(mass, omega_array,temperature_array)", "response": "Calculates the phase space density of the system at every point in time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_thermodynamic_quantities(self,temperature_array):\n        beta = 1/(_scipy.constants.Boltzmann*temperature_array)\n        self.Q = self.Hamiltonian*(_np.insert(_np.diff(beta),0,beta[1]-beta[0])*self.SampleFreq)\n        self.W = self.Hamiltonian-self.Q\n        self.Delta_E_kin = _np.diff(self.E_kin)*self.SampleFreq\n        self.Delta_E_pot = _np.diff(self.E_pot)*self.SampleFreq\n        self.Delta_E = _np.diff(self.Hamiltonian)*self.SampleFreq\n        \n        return self.Q, self.W", "response": "Calculates the thermodynamic quantities of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_mean_and_variance_of_variances(self, NumberOfOscillations):\n        SplittedArraySize = int(self.SampleFreq/self.FTrap.n) * NumberOfOscillations\n        VoltageArraySize = len(self.voltage)\n        SnippetsVariances = _np.var(self.voltage[:VoltageArraySize-_np.mod(VoltageArraySize,SplittedArraySize)].reshape(-1,SplittedArraySize),axis=1)\n\n        return _np.mean(SnippetsVariances), _np.var(SnippetsVariances)", "response": "Calculates the mean and variance of a set of varainces."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters this resource s templates dir to sphinx s template paths", "response": "def register_template_directory(kb_app: kb,\n                                sphinx_app: Sphinx,\n                                sphinx_env: BuildEnvironment,\n                                docnames=List[str],\n                                ):\n    \"\"\" Add this resource's templates dir to template paths \"\"\"\n\n    template_bridge = sphinx_app.builder.templates\n\n    actions = ResourceAction.get_callbacks(kb_app)\n\n    for action in actions:\n        f = os.path.dirname(inspect.getfile(action))\n        template_bridge.loaders.append(SphinxFileSystemLoader(f))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_directives(kb_app: kb,\n                   sphinx_app: Sphinx,\n                   sphinx_env: BuildEnvironment,\n                   docnames=List[str],\n                   ):\n    \"\"\" For each resource type, register a new Sphinx directive \"\"\"\n\n    for k, v in list(kb_app.config.resources.items()):\n        sphinx_app.add_directive(k, ResourceDirective)", "response": "Add Sphinx directives for each resource type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstamp the title of the resource.", "response": "def stamp_title(kb_app: kb,\n                sphinx_app: Sphinx,\n                doctree: doctree):\n    \"\"\" Walk the tree and extra RST title into resource.title \"\"\"\n\n    # First, find out which resource this is. Won't be easy.\n    resources = sphinx_app.env.resources\n    confdir = sphinx_app.confdir\n    source = PurePath(doctree.attributes['source'])\n\n    # Get the relative path inside the docs dir, without .rst, then\n    # get the resource\n    docname = str(source.relative_to(confdir)).split('.rst')[0]\n    resource = resources.get(docname)\n\n    if resource:\n        # Stamp the title on the resource\n        title = get_rst_title(doctree)\n        resource.title = title"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_app(self, app, config_prefix=\"PYBANKID\"):\n        if \"pybankid\" not in app.extensions:\n            app.extensions[\"pybankid\"] = {}\n\n        if config_prefix in app.extensions[\"pybankid\"]:\n            raise Exception('duplicate config_prefix \"{0}\"'.format(config_prefix))\n\n        app.config.setdefault(self._config_key(\"CERT_PATH\"), \"\")\n        app.config.setdefault(self._config_key(\"KEY_PATH\"), \"\")\n        app.config.setdefault(self._config_key(\"TEST_SERVER\"), False)\n\n        # Adding the three url endpoints.\n        app.add_url_rule(\n            \"/authenticate/<personal_number>\", view_func=self._authenticate\n        )\n        app.add_url_rule(\"/sign/<personal_number>\", view_func=self._sign)\n        app.add_url_rule(\"/collect/<order_ref>\", view_func=self._collect)\n\n        if hasattr(app, \"teardown_appcontext\"):\n            app.teardown_appcontext(self.teardown)\n        else:\n            app.teardown_request(self.teardown)", "response": "Initialize the application for use with this is\nElectricity."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_exception(error):\n        response = jsonify(error.to_dict())\n        response.status_code = error.status_code\n        return response", "response": "Simple method for handling exceptions raised by PyBankID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclassing method for initiating from a PyBankID exception.", "response": "def create_from_pybankid_exception(cls, exception):\n        \"\"\"Class method for initiating from a `PyBankID` exception.\n\n        :param bankid.exceptions.BankIDError exception:\n        :return: The wrapped exception.\n        :rtype: :py:class:`~FlaskPyBankIDError`\n\n        \"\"\"\n        return cls(\n            \"{0}: {1}\".format(exception.__class__.__name__, str(exception)),\n            _exception_class_to_status_code.get(exception.__class__),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a dictionary representation of this exception.", "response": "def to_dict(self):\n        \"\"\"Create a dict representation of this exception.\n\n        :return: The dictionary representation.\n        :rtype: dict\n\n        \"\"\"\n        rv = dict(self.payload or ())\n        rv[\"message\"] = self.message\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrandomizing a sequence of integers.", "response": "def sequence(minimum, maximum):\n    \"\"\"Randomize a sequence of integers.\"\"\"\n    function = 'sequences'\n    opts = {'min': minimum,\n            'max': maximum,\n            'col': 1,\n            'format': 'plain',\n            'rnd': 'new'}\n    deal = get_http(RANDOM_URL, function, opts)\n    deal_arr = str_to_arr(deal)\n    return deal_arr"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a file path from paths and return the contents.", "response": "def read(*p):\n    \"\"\"Build a file path from paths and return the contents.\"\"\"\n    with open(os.path.join(*p), 'r') as fi:\n        return fi.read()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, processProtocol, command, env={},\n                path=None, uid=None, gid=None, usePTY=0, childFDs=None):\n        \"\"\"Form a command and start a process in the desired environment.\n        \"\"\"\n        raise NotImplementedError()", "response": "Execute a command and return a process object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, command, env={}, path=None,\n            uid=None, gid=None, usePTY=0, childFDs=None):\n        \"\"\"Execute a command and return the results of the completed run.\n        \"\"\"\n        deferred = defer.Deferred()\n        processProtocol = _SummaryProcessProtocol(deferred)\n        d = defer.maybeDeferred(self.execute, processProtocol, command, env,\n                                path, uid, gid, usePTY, childFDs)\n        d.addErrback(deferred.errback)\n        return deferred", "response": "Execute a command and return the results of the completed run."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a command and get the output of the finished process.", "response": "def getOutput(self, command, env={}, path=None,\n                  uid=None, gid=None, usePTY=0, childFDs=None):\n        \"\"\"Execute a command and get the output of the finished process.\n        \"\"\"\n        deferred = defer.Deferred()\n        processProtocol = _SummaryProcessProtocol(deferred)\n        self.execute(processProtocol, command, env,\n                     path, uid, gid, usePTY, childFDs)\n        @deferred.addCallback\n        def getStdOut(tuple_):\n            stdout, _stderr, _returnCode = tuple_\n            return stdout\n        return deferred"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getExitCode(self, command, env={}, path=None, uid=None, gid=None,\n                    usePTY=0, childFDs=None):\n        \"\"\"Execute a command and get the return code of the finished process.\n        \"\"\"\n        deferred = defer.Deferred()\n        processProtocol = _SummaryProcessProtocol(deferred)\n        self.execute(processProtocol, command, env, path, uid, gid,\n                     usePTY, childFDs)\n        @deferred.addCallback\n        def getStdOut(tuple_):\n            _stdout, _stderr, exitCode = tuple_\n            return exitCode\n        return deferred", "response": "Execute a command and get the return code of the finished process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_task(original_task):\n    task = original_task._asdict()\n\n    # Default values for inputs and outputs\n    if 'inputs' not in task or task['inputs'] is None:\n        task['inputs'] = ['*']\n\n    # Outputs list cannot be empty\n    if ('outputs' not in task or\n        task['outputs'] is None or\n            len(task['outputs']) == 0):\n        task['outputs'] = ['*']\n\n    # Convert to tuples (even for single values)\n    if not hasattr(task['inputs'], '__iter__') or isinstance(task['inputs'], str):\n        task['inputs'] = (task['inputs'],)\n    else:\n        task['inputs'] = tuple(task['inputs'])\n\n    if not hasattr(task['outputs'], '__iter__') or isinstance(task['outputs'], str):\n        task['outputs'] = (task['outputs'],)\n    else:\n        task['outputs'] = tuple(task['outputs'])\n\n    if not callable(task['fn']):\n        raise TypeError('Task function must be a callable object')\n\n    if (len(task['outputs']) > 1 and\n            not inspect.isgeneratorfunction(task['fn'])):\n        raise TypeError('Multiple outputs are only supported with \\\n                        generator functions')\n\n    if inspect.isgeneratorfunction(task['fn']):\n        if task['outputs'][0] == '*':\n            raise TypeError('Generator functions cannot be used for tasks with \\\n                             output specification \"*\"')\n    return Task(**task)", "response": "Validates a task and adds default values for missing options using the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the task and updates the workspace with the results.", "response": "def run_task(task, workspace):\n    \"\"\"\n    Runs the task and updates the workspace with results.\n\n    Parameters\n    ----------\n    task - dict\n        Task Description\n\n    Examples:\n    {'task': task_func, 'inputs': ['a', 'b'], 'outputs': 'c'}\n    {'task': task_func, 'inputs': '*', 'outputs': '*'}\n    {'task': task_func, 'inputs': ['*','a'], 'outputs': 'b'}\n\n    Returns a new workspace with results\n    \"\"\"\n    data = copy.copy(workspace)\n\n    task = validate_task(task)\n\n    # Prepare input to task\n    inputs = [input_parser(key, data) for key in task.inputs]\n\n    if inspect.isgeneratorfunction(task.fn):\n        # Multiple output task\n        # Assuming number of outputs are equal to number of return values\n        data.update(zip(task.outputs, task.fn(*inputs)))\n    else:\n        # Single output task\n        results = task.fn(*inputs)\n        if task.outputs[0] != '*':\n            results = {task.outputs[0]: results}\n        elif not isinstance(results, dict):\n            raise TypeError('Result should be a dict for output type *')\n        data.update(results)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_hook(name, workspace, hooks):\n\n    data = copy.copy(workspace)\n    for hook_listener in hooks.get(name, []):\n        # Hook functions may mutate the data and returns nothing\n        hook_listener(data)\n    return data", "response": "Runs all hooks added under the given name under the given workspace."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_task(self, fn, inputs=None, outputs=None):\n        # self.tasks.append({'task': task, 'inputs': inputs, 'outputs': outputs})\n        self.tasks.append(Task(fn, inputs, outputs))\n        return self", "response": "Adds a task to the workflow."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a function to be called for a given hook of a given name.", "response": "def add_hook(self, name, function):\n        \"\"\"\n        Adds a function to be called for hook of a given name.\n\n        The function gets entire workspace as input and\n        does not return anything.\n\n        Example:\n        def hook_fcn(workspace):\n            pass\n        \"\"\"\n        if not callable(function):\n            return ValueError('Hook function should be callable')\n        if name not in self.hooks:\n            self.hooks[name] = []\n        self.hooks[name].append(function)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dns(self):\n        dns = {\n            'elb': self.dns_elb(),\n            'elb_region': self.dns_elb_region(),\n            'global': self.dns_global(),\n            'region': self.dns_region(),\n            'instance': self.dns_instance(),\n        }\n\n        return dns", "response": "Return a dict of DNS details."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate s3 application bucket name.", "response": "def s3_app_bucket(self, include_region=False):\n        \"\"\"Generate s3 application bucket name.\n\n        Args:\n            include_region (bool): Include region in the name generation.\n        \"\"\"\n        if include_region:\n            s3_app_bucket = self.format['s3_app_region_bucket'].format(**self.data)\n        else:\n            s3_app_bucket = self.format['s3_app_bucket'].format(**self.data)\n        return s3_app_bucket"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates shared s3 application bucket name.", "response": "def shared_s3_app_bucket(self, include_region=False):\n        \"\"\"Generate shared s3 application bucket name.\n\n        Args:\n            include_region (bool): Include region in the name generation.\n        \"\"\"\n        if include_region:\n            shared_s3_app_bucket = self.format['shared_s3_app_region_bucket'].format(**self.data)\n        else:\n            shared_s3_app_bucket = self.format['shared_s3_app_bucket'].format(**self.data)\n        return shared_s3_app_bucket"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef archaius(self):\n        bucket = self.format['s3_bucket'].format(**self.data)\n        path = self.format['s3_bucket_path'].format(**self.data)\n        archaius_name = self.format['s3_archaius_name'].format(**self.data)\n        archaius = {'s3': archaius_name, 'bucket': bucket, 'path': path}\n\n        return archaius", "response": "Generate archaius bucket path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jenkins(self):\n        job_name = self.format['jenkins_job_name'].format(**self.data)\n        job = {'name': job_name}\n\n        return job", "response": "Generate jenkins job details."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the inputted plain text wiki information into HTML rich text.", "response": "def render(plain,\n           urlHandler=None,\n           templatePaths=None,\n           options=None,\n           defaultTag='div',\n           wikiStyle='basic'):\n    \"\"\"\n    Renders the inputted plain text wiki information into HTML rich text.\n    \n    :param      plain       |  <str> | \\\n                               Include some additional documentation\n                urlHandler  |  <UlrHandler> || None\n    \n    :return     <str> html\n    \"\"\"\n    if not plain:\n        return ''\n\n    __style = WIKI_STYLES.styles.get(wikiStyle, WIKI_STYLES.styles['basic'])\n\n    # process the wiki text with the mako template system\n    if not urlHandler:\n        urlHandler = UrlHandler.current()\n\n    # render the text out from mako template\n    plain = projex.makotext.render(plain,\n                                   options=options,\n                                   templatePaths=templatePaths,\n                                   silent=True)\n\n    # generate wiki doc info\n    lines = re.split('\\n\\r|\\r\\n|\\n|\\r', plain)\n    curr_section = ''\n    curr_section_level = 0\n    html = []\n    skip = []\n    nowiki_stack = []\n    nowiki_mode = 'pre'\n    code_stack = []\n    table_stack = []\n    list_stack = []\n    section_stack = []\n    toc_data = []\n    align_div = ''\n    list_indent = None\n    ignore_list_stack = False\n\n    # add the default tag\n    html.append(__style['wiki_open'].format(tag=defaultTag))\n\n    for i, line in enumerate(lines):\n        ignore_list_stack = False\n        sline = line.strip()\n\n        #----------------------------------------------------------------------\n        #                           INDENTATION CHECKS\n        #----------------------------------------------------------------------\n\n        # check to see if we are continuing a list entry\n        if list_indent:\n            line_indent = len(re.match('\\s*', line).group())\n\n            if line_indent < list_indent:\n                list_indent = None\n                html.append(__style['list_item_close'])\n            else:\n                ignore_list_stack = True\n\n                if not sline:\n                    html.append(__style['spacer'])\n                    continue\n\n        if i in skip:\n            continue\n\n        #----------------------------------------------------------------------\n        #                           ALIGNMENT\n        #----------------------------------------------------------------------\n\n        # check for a center option\n        center = EXPR_CENTER.match(sline)\n        right = EXPR_RIGHT.match(sline)\n        left = EXPR_LEFT.match(sline)\n\n        if center:\n            style = center.groups()[0]\n            line = center.groups()[1].strip()\n\n            if align_div and align_div != 'center':\n                html.append(__style['align_close'])\n                align_div = ''\n\n            if not align_div:\n                if style == '--':\n                    html.append(__style['align_center'])\n                else:\n                    html.append(__style['align_center_floated'])\n                align_div = 'center'\n\n            else:\n                html.append(__style['newline'])\n\n        # check for a right align option\n        elif right:\n            style = right.groups()[0]\n            line = right.groups()[1]\n\n            if align_div and align_div != 'right':\n                html.append(__style['align_close'])\n                align_div = ''\n\n            if not align_div:\n                if style == '--':\n                    html.append(__style['align_right'])\n                else:\n                    html.append(__style['align_right_floated'])\n                align_div = 'right'\n            else:\n                html.append(__style['newline'])\n\n        # check for a left align option\n        elif left:\n            style = left.groups()[1]\n            line = left.groups()[0]\n\n            if align_div and align_div != 'left':\n                html.append(__style['align_close'])\n                align_div = ''\n\n            if not align_div:\n                if style == '--':\n                    html.append(__style['align_left'])\n                else:\n                    html.append(__style['align_left_floated'])\n\n                align_div = 'left'\n            else:\n                html.append(__style['newline'])\n\n        # otherwise, clear alignment\n        elif align_div:\n            html.append(__style['align_close'])\n            align_div = ''\n\n        #----------------------------------------------------------------------\n        #                           INDENTATION CHECKS\n        #----------------------------------------------------------------------\n\n        # make sure we're on the same level\n        if curr_section and sline and (len(line) - len(line.lstrip())) < curr_section_level:\n            html += section_stack\n            section_stack = []\n\n            curr_section = ''\n            curr_section_level = 0\n\n        count = i\n        while sline.endswith('\\\\') and count + 1 < len(lines):\n            sline += ' ' + lines[count + 1].strip()\n            skip.append(count)\n            count += 1\n\n        #----------------------------------------------------------------------\n        #                           IGNORE WIKI INFORMATION\n        #----------------------------------------------------------------------\n\n        # check to see what is wiki protected\n        if sline.startswith('<nowiki'):\n            mode = re.search('mode=\"(\\w*)\"', sline)\n            if mode:\n                nowiki_mode = nstr(mode.group(1))\n            else:\n                nowiki_mode = None\n\n            if not ignore_list_stack:\n                html += list_stack\n                list_stack = []\n\n            html += table_stack\n            table_stack = []\n\n            if nowiki_mode is None:\n                html.append(__style['nowiki_open'])\n                nowiki_stack.append(__style['nowiki_close'])\n            else:\n                nowiki_stack.append('')\n\n            continue\n\n        elif sline == '</nowiki>':\n            html += nowiki_stack\n            nowiki_stack = []\n            continue\n\n        elif nowiki_stack:\n            if nowiki_mode == 'safe':\n                html.append(line)\n            else:\n                html.append(xml.sax.saxutils.escape(line))\n            continue\n\n        #----------------------------------------------------------------------\n        #                           TABLES\n        #----------------------------------------------------------------------\n\n        parts = line.split(' | ')\n        if len(parts) == 1:\n            html += table_stack\n            table_stack = []\n\n        # replace standard items\n        for key, repl in PRE_ESCAPE_REPLACE.items():\n            line = line.replace(key, repl)\n\n        # strip out nowiki lines\n        nowiki_dict = {}\n        count = 0\n        for section in EXPR_NOWIKI.findall(line)[::2]:\n            nowiki_dict['nowiki_%i' % count] = section\n            newtext = '%%(nowiki_%i)s' % count\n            line = line.replace('<nowiki>%s</nowiki>' % section, newtext)\n            count += 1\n\n        #----------------------------------------------------------------------\n        #                           SECTIONS\n        #----------------------------------------------------------------------\n\n        # check for a div section\n        section = EXPR_SECTION.match(sline)\n        if section:\n            html += code_stack\n            code_stack = []\n\n            name = section.group(2)\n            if name != curr_section:\n                html += section_stack\n                section_stack = []\n\n                if name not in SECTION_ALERTS:\n                    section_stack.append(__style['section_close'])\n\n                    display = projex.text.capitalizeWords(name)\n                    mapped = SECTION_MAP.get(name, display)\n\n                    html.append(__style['section_open'].format(name=name,\n                                                               title=mapped))\n                else:\n                    display = projex.text.capitalizeWords(name)\n                    mapped = SECTION_MAP.get(name, display)\n\n                    section_stack.append(__style['section_alert_close'])\n                    url, success = urlHandler.resolve('img:%s.png' % name)\n                    html.append(__style['section_alert_open'].format(name=name,\n                                                                     title=mapped))\n\n                curr_section = name\n            else:\n                html.append(__style['newline'])\n\n            sline = sline.replace(section.group(), '')\n            line = line.replace(section.group(), ' ' * len(section.group()))\n            curr_section_level = len(line) - len(line.lstrip())\n\n        #----------------------------------------------------------------------\n        #                           CODE\n        #----------------------------------------------------------------------\n\n        # check for code\n        code = EXPR_CODE.match(sline)\n        if code:\n            templ = ''\n            code_line = code.groups()[0]\n\n            if not code_stack:\n                lang = 'python'\n                lang_search = EXPR_LANG.search(code_line)\n\n                if lang_search:\n                    lang = lang_search.groups()[0]\n                    code_line = code_line.replace(lang_search.group(), '')\n\n                templ = __style['code_open'].format(lang=lang)\n                code_stack.append(__style['code_close'])\n\n            escaped = xml.sax.saxutils.escape(code_line)\n\n            if not ignore_list_stack:\n                html += list_stack\n                list_stack = []\n\n            html += table_stack\n            table_stack = []\n\n            html.append(templ + escaped)\n            continue\n\n        # exit out of the code mode\n        else:\n            html += code_stack\n            code_stack = []\n\n        #----------------------------------------------------------------------\n\n        # make sure we have no html data in the line\n        if not sline:\n            html.append(__style['paragraph_close'])\n            html.append(__style['paragraph_open'])\n            continue\n\n        # check for horizontal rules\n        if EXPR_HR.match(sline):\n            style = ''\n            html.append(__style['hr'].format(style=style))\n            continue\n\n        #----------------------------------------------------------------------\n        #                           HEADERS\n        #----------------------------------------------------------------------\n\n        # check for headers\n        header = EXPR_HEADER.match(sline)\n        if header:\n            hopen, title, hclose = header.groups()\n            hopencount = len(hopen)\n            title = title.strip()\n\n            if hopencount == len(hclose):\n                name = projex.text.underscore(title)\n                add = __style['header'].format(name=name,\n                                               title=title,\n                                               size=len(hopen))\n                spacing = '#' * hopencount\n                opts = (spacing, name, title)\n                toc_data.append('%s. [[#%s|%s]]' % opts)\n\n                if not ignore_list_stack:\n                    html += list_stack\n                    list_stack = []\n\n                html += table_stack\n                table_stack = []\n\n                html.append(add)\n                continue\n\n        line = xml.sax.saxutils.escape(line)\n\n        for key, repl in POST_ESCAPE_REPLACE.items():\n            line = line.replace(key, repl)\n\n        #----------------------------------------------------------------------\n        #                           CLASS TYPES\n        #----------------------------------------------------------------------\n\n        # resolve any class links\n        for result in EXPR_CLASS_LINK.findall(line):\n            opts = result.split()\n            for o, cls in enumerate(opts):\n                # ignore base classes, need modules\n                if '.' not in cls:\n                    continue\n\n                url, success = urlHandler.resolveClass(cls)\n                if success:\n                    opts[o] = __style['link_class'].format(url=url,\n                                                           text=cls.split('.')[-1])\n\n            info = __style['span_class'].format(crumbs=' '.join(opts))\n            line = line.replace('&lt;' + result + '&gt;', info)\n\n        #----------------------------------------------------------------------\n        #                           GENERAL FORMATTING\n        #----------------------------------------------------------------------\n\n        # replace formatting options\n        for section in EXPR_UNDERLINE.findall(line)[::2]:\n            text = __style['underline'].format(text=section)\n            line = line.replace(\"___%s___\" % section, text)\n\n        for section in EXPR_INLINE_CODE.findall(line)[::2]:\n            text = __style['inline_code'].format(text=section)\n            line = line.replace(\"`%s`\" % section, text)\n\n        for section in EXPR_STRIKEOUT.findall(line)[::2]:\n            text = __style['strikeout'].format(text=section)\n            line = line.replace(\"---%s---\" % section, text)\n\n        for section in EXPR_BOLD.findall(line)[::2]:\n            text = __style['bold'].format(text=section)\n            line = line.replace(\"'''%s'''\" % section, text)\n\n        for section in EXPR_ITALIC.findall(line)[::2]:\n            text = __style['italic'].format(text=section)\n            line = line.replace(\"''%s''\" % section, text)\n\n        #----------------------------------------------------------------------\n        #                           IMAGES\n        #----------------------------------------------------------------------\n\n        # resolve any images\n        for grp, url in EXPR_IMG.findall(line):\n            urlsplit = url.split('|')\n            last_word = re.findall('\\w+', urlsplit[0])[-1]\n\n            if len(urlsplit) == 1:\n                urlsplit.append('')\n\n            url, _ = urlHandler.resolveImage(urlsplit[0])\n            line = line.replace(grp, __style['img'].format(url=url,\n                                                           style=urlsplit[1],\n                                                           title=last_word))\n\n        #----------------------------------------------------------------------\n        #                           COLORS\n        #----------------------------------------------------------------------\n\n        # resolve any colors\n        for grp, coloring in EXPR_COLOR.findall(line):\n            splt = coloring.split('|')\n            if len(splt) == 1:\n                splt.append('')\n\n            line = line.replace(grp, __style['color'].format(color=splt[0],\n                                                             text=splt[1]))\n\n        #----------------------------------------------------------------------\n        #                           SPANS\n        #----------------------------------------------------------------------\n\n        # resolve any spans\n        for grp, coloring in EXPR_SPAN.findall(line):\n            splt = coloring.split('|')\n            if len(splt) == 1:\n                splt.append('')\n\n            templ = '<span style=\"%s\">%s</span>' % (splt[0], splt[1])\n            line = line.replace(grp, __style['span'].format(style=splt[0],\n                                                            text=splt[1]))\n\n        #----------------------------------------------------------------------\n        #                           LINKS\n        #----------------------------------------------------------------------\n\n        # resolve any external urls\n        for result in EXPR_EXTLINK.findall(line):\n            grp = result[0]\n            url = result[1]\n\n            urlsplit = url.split()\n            if len(urlsplit) == 1:\n                urlsplit.append(urlsplit[0])\n\n            url = urlsplit[0]\n            urltext = ' '.join(urlsplit[1:])\n\n            line = line.replace(grp, __style['link_ext'].format(url=url, text=urltext))\n\n        # resolve any internal urls\n        for grp, url in EXPR_INTLINK.findall(line):\n            urlsplit = url.split('|')\n            if len(urlsplit) == 1:\n                last_word = re.findall('\\w+', urlsplit[0])[-1]\n                urlsplit.append(last_word)\n\n            url = urlsplit[0]\n            title = '|'.join(urlsplit[1:])\n            found = True\n\n            tagsplit = url.split('#')\n            if len(tagsplit) == 1:\n                url = url\n                tag = ''\n            else:\n                url = tagsplit[0]\n                tag = '#'.join(tagsplit[1:])\n\n            # make sure the url exists\n            if url:\n                url, exists = urlHandler.resolve(url)\n                if not exists:\n                    found = False\n\n            # join together the resolved url and the tag\n            if tag:\n                url = url + '#' + tag\n\n            # generate the link\n            if found:\n                templ = __style['link_found'].format(url=url, text=title)\n            else:\n                templ = __style['link_not_found'].format(url=url, text=title)\n\n            line = line.replace(grp, templ)\n\n        #----------------------------------------------------------------------\n        #                           LISTS\n        #----------------------------------------------------------------------\n\n        # process lists\n        results = EXPR_LIST.match(line)\n        if results:\n            level, linetext = results.groups()\n            level_count = len(level)\n            level_type = 'unordered' if level[-1] == '*' else 'ordered'\n\n            while level_count > len(list_stack):\n                html.append(__style[level_type + '_list_open'])\n                list_stack.append(__style[level_type + '_list_close'])\n\n            while len(list_stack) > level_count:\n                html.append(list_stack[-1])\n                list_stack = list_stack[:-1]\n\n            space_line = line.replace(level + '.', ' ' * (len(level) + 1))\n            list_indent = len(re.match('\\s*', space_line).group())\n\n            html.append(__style['list_item_open'])\n            html.append(linetext)\n\n            continue\n\n        elif not ignore_list_stack:\n            html += list_stack\n            list_stack = []\n\n        #----------------------------------------------------------------------\n        #                           TABLES\n        #----------------------------------------------------------------------\n\n        parts = line.split(' | ')\n        if len(parts) > 1:\n            if not table_stack:\n                table_stack.append(__style['table_close'])\n                html.append(__style['table_open'])\n\n            cell_type = 'td'\n            styles = ''\n\n            cells = []\n            for part in parts:\n                results = EXPR_TABLE_CELL.search(part)\n\n                if not results:\n                    cells.append(__style['table_cell'].format(tag='td',\n                                                              style='',\n                                                              text=part.strip()))\n\n                else:\n                    grp, cell_type, styles = results.groups()\n\n                    if not styles:\n                        styles = ''\n                    else:\n                        styles = styles.strip('[]')\n\n                    part = part.replace(grp, '').strip()\n                    opts = (cell_type, styles, part, cell_type)\n\n                    cells.append(__style['table_cell'].format(tag=cell_type,\n                                                              style=styles,\n                                                              text=part))\n\n            line = __style['table_row'].format(text=''.join(cells))\n\n            html.append((line % nowiki_dict))\n\n        else:\n            html += table_stack\n            table_stack = []\n\n            html.append(line % nowiki_dict)\n\n    if align_div:\n        html.append(__style['align_close'])\n\n    if list_indent:\n        html.append(__style['list_item_close'])\n\n    html += table_stack\n    html += list_stack\n    html += code_stack\n    html += nowiki_stack\n    html += section_stack\n\n    html.append(__style['wiki_close'].format(tag=defaultTag))\n    html_txt = '\\n'.join(html)\n\n    # resolve any table of contents\n    for toc, options in EXPR_TOC.findall(html_txt):\n        toc_wiki = '\\n\\t'.join(toc_data)\n        toc_html = __style['toc_open']\n        toc_html += render(toc_wiki, urlHandler, templatePaths, options, 'div', wikiStyle)\n        toc_html += __style['toc_close']\n\n        html_txt = html_txt.replace(toc, toc_html)\n\n    # replace \\[ and \\] options\n    html_txt = html_txt.replace('\\[', '[').replace('\\]', ']')\n\n    return html_txt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_value_matched_by_regex(field_name, regex_matches, string):\n    try:\n        value = regex_matches.group(field_name)\n        if value is not None:\n            return value\n    except IndexError:\n        pass\n\n    raise MissingFieldError(string, field_name)", "response": "Ensure value stored in regex group exists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef positive_int(val):\n    if isinstance(val, float):\n        raise ValueError('\"{}\" must not be a float'.format(val))\n    val = int(val)\n    if val >= 0:\n        return val\n    raise ValueError('\"{}\" must be positive'.format(val))", "response": "Parse val into a positive integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing val into either None or a strictly positive integer.", "response": "def strictly_positive_int_or_none(val):\n    \"\"\"Parse `val` into either `None` or a strictly positive integer.\"\"\"\n    val = positive_int_or_none(val)\n    if val is None or val > 0:\n        return val\n    raise ValueError('\"{}\" must be strictly positive'.format(val))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef oboTermParser(filepath):\n    with io.open(filepath) as openfile:\n        lineIter = iter([i.rstrip() for i in openfile.readlines()])\n\n    #Iterate through lines until the first obo \"[Term]\" is encountered\n    try:\n        line = next(lineIter)\n        while line != '[Term]':\n            line = next(lineIter)\n        header = line #Remove\n        entryLines = list()\n    except StopIteration:\n        errorText = 'File does not contain obo \"[Term]\" entries.'\n        raise maspy.errors.FileFormatError(errorText)\n\n    for line in lineIter:\n        #Skip empty lines between entries\n        if not line:\n            continue\n        if line == '[Term]':\n            yield entryLines\n            header = line #Remove\n            entryLines = list()\n        else:\n            entryLines.append(line)\n\n    #Yield last entry\n    if entryLines:\n        yield entryLines", "response": "Read a. obo file and yield all lines from the. obo file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _attributeLinesToDict(attributeLines):\n    attributes = dict()\n    for line in attributeLines:\n        attributeId, attributeValue = line.split(':', 1)\n        attributes[attributeId.strip()] = attributeValue.strip()\n    return attributes", "response": "Converts a list of lines of obo Term to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine whether an obo Term entry is marked as obsolete.", "response": "def _termIsObsolete(oboTerm):\n    \"\"\"Determine wheter an obo 'Term' entry is marked as obsolete.\n\n    :param oboTerm: a dictionary as return by\n        :func:`maspy.ontology._attributeLinesToDict()`\n\n    :return: bool\n    \"\"\"\n    isObsolete = False\n    if u'is_obsolete' in oboTerm:\n        if oboTerm[u'is_obsolete'].lower() == u'true':\n            isObsolete = True\n    return isObsolete"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(self, filepath):\n        for attributeLines in oboTermParser(filepath):\n            oboTerm = _attributeLinesToDict(attributeLines)\n            if oboTerm['id'] not in self.oboTerms:\n                self.oboTerms[oboTerm['id']] = oboTerm            \n            else:\n                oldOboTerm = self.oboTerms[oboTerm['id']]\n                oldTermIsObsolete = _termIsObsolete(oldOboTerm)\n                newTermIsObsolete = _termIsObsolete(oboTerm)\n                if oldTermIsObsolete and not newTermIsObsolete:\n                    self.oboTerms[oboTerm['id']] = oboTerm\n                else:\n                    #At least one of two terms with identical id must be obsolete\n                    assert oldTermIsObsolete or newTermIsObsolete", "response": "Import '[Term]' entries from an. obo file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discover_handler_classes(handlers_package):\n    if handlers_package is None:\n        return\n\n    # Add working directory into PYTHONPATH to import developer packages\n    sys.path.insert(0, os.getcwd())\n\n    package = import_module(handlers_package)\n\n    # Continue searching for module if package is not a module\n    if hasattr(package, '__path__'):\n        for _, modname, _ in pkgutil.iter_modules(package.__path__):\n            import_module('{package}.{module}'.format(package=package.__name__, module=modname))\n\n    return registered_handlers", "response": "Finds handler classes within handler path module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending an HTTP request to the specified URL.", "response": "def request(self, method, path, query=None, content=None):\n        \"\"\"\n        Sends an HTTP request.\n\n        This constructs a full URL, encodes and decodes HTTP bodies, and\n        handles invalid responses in a pythonic way.\n\n        @type method: string\n        @param method: HTTP method to use\n        @type path: string\n        @param path: HTTP URL path\n        @type query: list of two-tuples\n        @param query: query arguments to pass to urllib.urlencode\n        @type content: str or None\n        @param content: HTTP body content\n\n        @rtype: object\n        @return: JSON-Decoded response\n\n        @raises GanetiApiError: If an invalid response is returned\n        \"\"\"\n\n        if not path.startswith(\"/\"):\n            raise ClientError(\"Implementation error: Called with bad path %s\"\n                              % path)\n\n        body = None\n\n        if content is not None:\n            data = self._json_encoder.encode(content)\n            body = StringProducer(data)\n\n        url = self._base_url + path\n\n        if query:\n            prepare_query(query)\n            params = urlencode(query, doseq=True)\n            url += \"?%s\" % params\n\n        log.msg(\"Sending request to %s %s %s\" % (url, self.headers, body),\n                system=\"Gentleman\")\n\n        d = self._agent.request(method, url, headers=self.headers,\n                                bodyProducer=body)\n\n        protocol = JsonResponseProtocol(d)\n\n        @d.addErrback\n        def connectionFailed(failure):\n            failure.trap(ConnectionRefusedError)\n            raise GanetiApiError(\"Connection refused!\")\n\n        @d.addCallback\n        def cb(response):\n            if response.code != 200:\n                raise NotOkayError(code=response.code)\n            response.deliverBody(protocol)\n\n        return protocol.getData()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n\n        version = yield self.request(\"get\", \"/version\")\n\n        if version != 2:\n            raise GanetiApiError(\"Can't work with Ganeti RAPI version %d\" %\n                                 version)\n\n        log.msg(\"Accessing Ganeti RAPI, version %d\" % version,\n                system=\"Gentleman\")\n        self.version = version\n\n        try:\n            features = yield self.request(\"get\", \"/2/features\")\n        except NotOkayError, noe:\n            if noe.code == 404:\n                # Okay, let's calm down, this is totally reasonable. Certain\n                # older Ganeti RAPIs don't have a list of features.\n                features = []\n            else:\n                # No, wait, panic was the correct thing to do.\n                raise\n\n        log.msg(\"RAPI features: %r\" % (features,), system=\"Gentleman\")\n        self.features = features", "response": "Start the target cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inside_try(func, options={}):\n    if six.PY2:\n        name = func.func_name\n    else:\n        name = func.__name__\n\n    @wraps(func)\n    def silenceit(*args, **kwargs):\n        \"\"\" the function func to be silenced is wrapped inside a\n        try catch and returned, exceptions are logged\n        exceptions are returned in an error dict\n        takes all kinds of arguments and passes to the original func\n        \"\"\"\n        excpt = None\n        try:\n            return func(*args, **kwargs)\n        # pylint: disable=W0703\n        # inside_try.silenceit: Catching too general exception Exception\n        # that's the idea!\n        except Exception as excpt:\n            # first tell the object in charge\n            if 'ctx' in kwargs:\n                ctx = kwargs['ctx']\n            else:\n                # otherwise tell object defined in options\n                # if we can be sure there is a context\n                ctx = get_try_option(None, 'ctx')\n\n            if not ctx:\n                # tell a new object\n                ctx = Bubble('Inside Try')\n                # ctx.set_verbose(100); #todo: move to magic\n\n            head = name + ': silenced function inside_try:Error:'\n            if get_try_option(ctx, 'count_it'):\n                ctx.gbc.cry(head + 'counting')\n            if get_try_option(ctx, 'print_it'):\n                ctx.gbc.cry(head + 'printing:' + str(excpt))\n            if get_try_option(ctx, 'print_args'):\n                ctx.gbc.cry(head + 'printing ak:' + str(excpt))\n                ctx.gbc.cry('args', stuff=args)\n                ctx.gbc.cry('kwargs', stuff=kwargs)\n            if get_try_option(ctx, 'inspect_it'):\n                ctx.gbc.cry(head + 'inspecting:', stuff=excpt)\n                for s in inspect.stack():\n                    ctx.gbc.cry(head + ':stack:', stuff=s)\n            if get_try_option(ctx, 'log_it'):\n                ctx.gbc.cry(head + 'logging')\n                for s in inspect.stack():\n                    ctx.gbc.cry(head + ':stack:', stuff=s)\n            if get_try_option(ctx, 'reraise_it'):\n                ctx.gbc.cry(head + 'reraising')\n                raise excpt\n            # always return error\n            return {'error': str(excpt),\n                    'silenced': name,\n                    'args': args,\n                    'kwargs': kwargs}\n    return silenceit", "response": "decorator to silence exceptions in the function func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        Server().start(self.options,self.handler_function, self.__class__.component_type)", "response": "Start the server and run forever."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollects all the packages and data associated with the inputted filepath.", "response": "def collect(basepath, exclude=None, processPlugins=True):\n    \"\"\"\n    Collects all the packages associated with the inputted filepath.\n    \n    :param      module | <module>\n    \n    :return     ([<str> pkg, ..], [(<str> path, <str> relpath), ..] data)\n    \"\"\"\n    if exclude is None:\n        exclude = ['.py', '.pyc', '.pyo', '.css', '.exe']\n\n    imports = []\n    datas = []\n\n    # walk the folder structure looking for all packages and data files\n    basename = os.path.basename(basepath)\n    basepath = os.path.abspath(basepath)\n    baselen = len(basepath) - len(basename)\n\n    plugfiles = []\n\n    for root, folders, files in os.walk(basepath):\n        if '.svn' in root or '.git' in root:\n            continue\n\n        # mark the plugins file for load\n        plugdata = None\n        if processPlugins and '__plugins__.py' in files:\n            filename = os.path.join(root, '__plugins__.py')\n            package = projex.packageFromPath(filename) + '.__plugins__'\n            pkgpath = projex.packageRootPath(filename)\n\n            if pkgpath not in sys.path:\n                sys.path.insert(0, pkgpath)\n\n            # import the plugins module\n            __import__(package)\n            pkg = sys.modules[package]\n\n            recurse = getattr(pkg, '__recurse__', False)\n            plugdata = {'recurse': recurse,\n                        'packages': [],\n                        'path': root}\n\n            plugfiles.append(plugdata)\n\n        # look for any recursion plugins\n        else:\n            for data in plugfiles:\n                if data['recurse'] and root.startswith(data['path']):\n                    plugdata = data\n                    break\n\n        if plugdata is not None:\n            packages = plugdata['packages']\n\n            # include package plugins\n            for folder in folders:\n                pkgpath = os.path.join(root, folder, '__init__.py')\n                if os.path.exists(pkgpath):\n                    packages.append(projex.packageFromPath(pkgpath))\n\n        for file_ in files:\n            module, ext = os.path.splitext(file_)\n\n            # look for python modules\n            if ext == '.py':\n                package_path = projex.packageFromPath(os.path.join(root, file_))\n                if not package_path:\n                    continue\n\n                if module != '__init__':\n                    package_path += '.' + module\n\n                imports.append(package_path)\n\n                # test to see if this is a plugin file\n                if plugdata is not None and module not in ('__init__',\n                                                           '__plugins__'):\n                    plugdata['packages'].append(package_path)\n\n            # look for data\n            elif ext not in exclude:\n                src = os.path.join(root, file_)\n                targ = os.path.join(root[baselen:])\n                datas.append((src, targ))\n\n    # save the plugin information\n    for plugdata in plugfiles:\n        fname = os.path.join(plugdata['path'], '__plugins__.py')\n        packages = plugdata['packages']\n\n        plugs = ',\\n'.join(map(lambda x: \"r'{0}'\".format(x), packages))\n        data = [\n            '__recurse__ = {0}'.format(plugdata['recurse']),\n            '__toc__ = [{0}]'.format(plugs)\n        ]\n\n        # write the data to the system\n        f = open(fname, 'w')\n        f.write('\\n'.join(data))\n        f.close()\n\n    return imports, datas"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_reverse(self):\n        if self.sort in FLOAT_ATTRIBUTES:\n            return True\n        elif self.sort in NONFLOAT_ATTRIBUTES:\n            return False\n        else:\n            raise InvalidSortError(self.sort)", "response": "Returns True if the sort is reverse False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the key attribute to determine how data is sorted.", "response": "def sort_func(self, entry):\n        \"\"\"Return the key attribute to determine how data is sorted.\n        Time will need to be converted to 24 hour time.\n        In instances when float attributes will have an 'n/a' string, return 0.\n        \"\"\"\n        key = entry[self.sort]\n\n        if self.sort in FLOAT_ATTRIBUTES and not isinstance(key, float):\n            return 0  # If value is 'n/a' string\n        elif self.sort == 'time':\n            return convert_time(key)\n        elif self.sort == 'date':\n            return convert_date(key)\n\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort_entries(self):\n        return sorted(self.data, key=self.sort_func, reverse=self.get_reverse())", "response": "Get whether reverse is True or False. Return the sorted data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the reduced set of visible fields to output from the form.", "response": "def visible_fields(self):\n        \"\"\"\n        Returns the reduced set of visible fields to output from the form.\n\n        This method respects the provided ``fields`` configuration _and_ exlcudes\n        all fields from the ``exclude`` configuration.\n\n        If no ``fields`` where provided when configuring this fieldset, all visible\n        fields minus the excluded fields will be returned.\n\n        :return: List of bound field instances or empty tuple.\n        \"\"\"\n\n        form_visible_fields = self.form.visible_fields()\n\n        if self.render_fields:\n            fields = self.render_fields\n        else:\n            fields = [field.name for field in form_visible_fields]\n\n        filtered_fields = [field for field in fields if field not in self.exclude_fields]\n        return [field for field in form_visible_fields if field.name in filtered_fields]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_fieldsets(self, fieldsets=None):\n        fieldsets = fieldsets or self.fieldsets\n\n        if not fieldsets:\n            raise StopIteration\n\n        # Search for primary marker in at least one of the fieldset kwargs.\n        has_primary = any(fieldset.get('primary') for fieldset in fieldsets)\n\n        for fieldset_kwargs in fieldsets:\n            fieldset_kwargs = copy.deepcopy(fieldset_kwargs)\n            fieldset_kwargs['form'] = self\n\n            if not has_primary:\n                fieldset_kwargs['primary'] = True\n                has_primary = True\n\n            yield self.get_fieldset(**fieldset_kwargs)", "response": "This method returns a generator which yields fieldset instances for the given set of fieldsets."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_binding_credentials(self, binding):\n        uri = self.clusters.get(binding.instance.get_cluster(), None)\n        \n        if not uri:\n            raise ErrClusterConfig(binding.instance.get_cluster())\n        \n        # partial credentials\n        creds = {\"username\" : self.generate_binding_username(binding),\n                \"password\" : pwgen(32, symbols=False),\n                \"database\" : binding.instance.get_dbname()}\n        \n        # uri\n        uri = uri % (\n            creds[\"username\"],\n            creds[\"password\"],\n            creds[\"database\"])\n        \n        creds[\"uri\"] = uri\n        \n        # return creds\n        return creds", "response": "Generate the credentials for the given binding."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_binding_permissions(self, binding, permissions):\n        permissions.add_roles(binding.instance.get_dbname(),\n                              [RoleSpecs.dbAdmin,\n                               RoleSpecs.readWrite])\n        return permissions", "response": "Generate Users pemissions on the database for the users."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_data_from_bin_file(fileName):\n    with open(fileName, mode='rb') as file: # b is important -> binary\n        fileContent = file.read()\n\n    (ChannelData, LenOf1Channel,\n     NumOfChannels, SampleTime) = read_data_from_bytes(fileContent)\n    \n    return ChannelData, LenOf1Channel, NumOfChannels, SampleTime", "response": "Loads the binary data stored in a. bin file and extracts the sample rate and length of the data array for each channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the binary data stored in a. bin file and returns the data array for each channel that was saved and the sample rate and length of the array.", "response": "def read_data_from_bytes(fileContent):\n    \"\"\"\n    Takes the binary data stored in the binary string provided and extracts the \n    data for each channel that was saved, along with the sample rate and length\n    of the data array.\n\n    Parameters\n    ----------\n    fileContent : bytes \n        bytes object containing the data from a .bin file exported from\n        the saleae data logger.\n    \n    Returns\n    -------\n    ChannelData : list\n        List containing a list which contains the data from each channel\n    LenOf1Channel : int\n        The length of the data in each channel\n    NumOfChannels : int\n        The number of channels saved\n    SampleTime : float\n        The time between samples (in seconds)\n    SampleRate : float\n        The sample rate (in Hz)\n    \"\"\"\n    TotalDataLen = struct.unpack('Q', fileContent[:8])[0] # Unsigned long long \n    NumOfChannels = struct.unpack('I', fileContent[8:12])[0] # unsigned Long\n    SampleTime = struct.unpack('d', fileContent[12:20])[0]\n\n    AllChannelData = struct.unpack(\"f\" * ((len(fileContent) -20) // 4), fileContent[20:])\n    #  ignore the heading bytes (= 20)\n    # The remaining part forms the body, to know the number of bytes in the body do an integer division by 4 (since 4 bytes = 32 bits = sizeof(float)\n\n    LenOf1Channel = int(TotalDataLen/NumOfChannels)\n\n    ChannelData = list(get_chunks(AllChannelData, LenOf1Channel))\n    \n    return ChannelData, LenOf1Channel, NumOfChannels, SampleTime"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninterprets the data for just 1 channel and computes the corresponding time array.", "response": "def interpret_waveform(fileContent, RelativeChannelNo):\n    \"\"\"\n    Extracts the data for just 1 channel and computes the corresponding\n    time array (in seconds) starting from 0.\n    \n    Important Note: RelativeChannelNo is NOT the channel number on the Saleae data logger \n    it is the relative number of the channel that was saved. E.g. if you \n    save channels 3, 7 and 10, the corresponding RelativeChannelNos would\n    be 0, 1 and 2.\n    \n    Parameters\n    ----------\n    fileContent : bytes \n        bytes object containing the data from a .bin file exported from\n        the saleae data logger.\n    RelativeChannelNo : int\n        The relative order/position of the channel number in the saved\n        binary file. See Important Note above!\n\n    Returns\n    -------    \n    time : ndarray\n        A generated time array corresponding to the data list\n    Data : list\n        The data from the relative channel requested\n    SampleTime : float\n        The time between samples (in seconds)\n    \"\"\"\n    (ChannelData, LenOf1Channel,\n     NumOfChannels, SampleTime) = read_data_from_bytes(fileContent)\n\n    if RelativeChannelNo > NumOfChannels-1:\n        raise ValueError(\"There are {} channels saved, you attempted to read relative channel number {}. Pick a relative channel number between {} and {}\".format(NumOfChannels, RelativeChannelNo, 0, NumOfChannels-1))\n    \n    data = ChannelData[RelativeChannelNo]\n\n    del(ChannelData)\n\n    time = _np.arange(0, SampleTime*LenOf1Channel, SampleTime)\n\n    return (0,SampleTime*LenOf1Channel,SampleTime), data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getApi():\n    api = Blueprint('health', __name__, url_prefix='/')\n\n    @api.route('health', methods=['GET'])\n    def health():\n        '''Health check'''\n        return jsonify({ \"status\" : True})\n\n    return api", "response": "Get Api for health check\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_coord_box(centre_x, centre_y, distance):\n    \"\"\"Todo: return coordinates inside a circle, rather than a square\"\"\"\n    return {\n        'top_left': (centre_x - distance, centre_y + distance),\n        'top_right': (centre_x + distance, centre_y + distance),\n        'bottom_left': (centre_x - distance, centre_y - distance),\n        'bottom_right': (centre_x + distance, centre_y - distance),\n    }", "response": "Get the square boundary coordinates for a given centre and distance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fleet_ttb(unit_type, quantity, factories, is_techno=False, is_dict=False, stasis_enabled=False):\n\n    unit_weights = {\n        UNIT_SCOUT: 1,\n        UNIT_DESTROYER: 13,\n        UNIT_BOMBER: 10,\n        UNIT_CRUISER: 85,\n        UNIT_STARBASE: 1,\n    }\n\n    govt_weight = 80 if is_dict else 100\n    prod_weight = 85 if is_techno else 100\n\n    weighted_qty = unit_weights[unit_type] * quantity\n    ttb = (weighted_qty * govt_weight * prod_weight) * (2 * factories)\n\n    # TTB is 66% longer with stasis enabled\n    return ttb + (ttb * 0.66) if stasis_enabled else ttb", "response": "Calculate the time taken to construct a given fleet node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_fasta(data):  # pragma: no cover\n    name, seq = None, []\n    for line in data:\n        line = line.rstrip()\n        if line.startswith('>'):\n            if name:\n                yield Sequence(name, ''.join(seq))\n            name, seq = line, []\n        else:\n            seq.append(line)\n    if name:\n        yield Sequence(name, ''.join(seq))", "response": "Parse a sequence file in Fasta format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve Parent and ID relationships and yield all top - level features.", "response": "def _resolve_features(self):\n        \"\"\"Resolve Parent/ID relationships and yield all top-level features.\"\"\"\n\n        for parentid in self.featsbyparent:\n            parent = self.featsbyid[parentid]\n            for child in self.featsbyparent[parentid]:\n                parent.add_child(child, rangecheck=self.strict)\n\n        # Replace top-level multi-feature reps with a pseudo-feature\n        for n, record in enumerate(self.records):\n            if not isinstance(record, Feature):\n                continue\n            if not record.is_multi:\n                continue\n            assert record.multi_rep == record\n            newrep = sorted(record.siblings + [record])[0]\n            if newrep != record:\n                for sib in sorted(record.siblings + [record]):\n                    sib.multi_rep = newrep\n                    if sib != newrep:\n                        newrep.add_sibling(sib)\n                record.siblings = None\n            parent = newrep.pseudoify()\n            self.records[n] = parent\n\n        if not self.assumesorted:\n            for seqid in self.inferred_regions:\n                if seqid not in self.declared_regions:\n                    seqrange = self.inferred_regions[seqid]\n                    srstring = '##sequence-region {:s} {:d} {:d}'.format(\n                        seqid, seqrange.start + 1, seqrange.end\n                    )\n                    seqregion = Directive(srstring)\n                    self.records.append(seqregion)\n\n        for record in sorted(self.records):\n            yield record\n        self._reset()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reset(self):\n        self.records = list()\n        self.featsbyid = dict()\n        self.featsbyparent = dict()\n        self.countsbytype = dict()", "response": "Clear internal data structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first item with a specific label.", "response": "def get_by_label(self, label):\n        \"\"\" Return the first item with a specific label,\n        or None.\n        \"\"\"\n        return next((x for x in self if x.label == label), None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getGenericAnswers(self, name, instruction, prompts):\n        responses = []\n        for prompt, _echo in prompts:\n            password = self.getPassword(prompt)\n            responses.append(password)\n\n        return defer.succeed(responses)", "response": "Called when the server requests keyboard interactive authentication"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pairwise(iterable):\n    iterator = iter(iterable)\n    try:\n        first = next(iterator)\n    except StopIteration:\n        return\n    for element in iterator:\n        yield first, element\n        first = element", "response": "Generate consecutive pairs of elements from the given iterable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pick_cert_for_twisted(netloc, possible):\n    try:\n        creds = possible[netloc]\n    except KeyError:\n        return (None, ())\n\n    key = ssl.KeyPair.load(creds.key.as_bytes(), FILETYPE_PEM)\n    return (\n        ssl.PrivateCertificate.load(\n            creds.chain.certificates[0].as_bytes(), key, FILETYPE_PEM,\n        ),\n        tuple(\n            ssl.Certificate.load(cert.as_bytes(), FILETYPE_PEM)\n            for cert\n            in creds.chain.certificates[1:]\n        ),\n    )", "response": "Pick the right client key and certificate for the given server and return it in the form Twisted wants."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pick_trust_for_twisted(netloc, possible):\n    try:\n        trust_cert = possible[netloc]\n    except KeyError:\n        return None\n\n    cert = ssl.Certificate.load(trust_cert.as_bytes(), FILETYPE_PEM)\n    return ssl.trustRootFromCertificates([cert])", "response": "Picks the right trust roots for the given server and returns it in the form Twisted wants."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an HTTPS policy from a Kubernetes configuration.", "response": "def https_policy_from_config(config):\n    \"\"\"\n    Create an ``IPolicyForHTTPS`` which can authenticate a Kubernetes API\n    server.\n\n    :param KubeConfig config: A Kubernetes configuration containing an active\n        context identifying a cluster.  The resulting ``IPolicyForHTTPS`` will\n        authenticate the API server for that cluster.\n\n    :return IPolicyForHTTPS: A TLS context which requires server certificates\n        signed by the certificate authority certificate associated with the\n        active context's cluster.\n    \"\"\"\n    server = config.cluster[\"server\"]\n    base_url = URL.fromText(native_string_to_unicode(server))\n\n    ca_certs = pem.parse(config.cluster[\"certificate-authority\"].bytes())\n    if not ca_certs:\n        raise ValueError(\"No certificate authority certificate found.\")\n    ca_cert = ca_certs[0]\n\n    try:\n        # Validate the certificate so we have early failures for garbage data.\n        ssl.Certificate.load(ca_cert.as_bytes(), FILETYPE_PEM)\n    except OpenSSLError as e:\n        raise ValueError(\n            \"Invalid certificate authority certificate found.\",\n            str(e),\n        )\n\n    netloc = NetLocation(host=base_url.host, port=base_url.port)\n    policy = ClientCertificatePolicyForHTTPS(\n        credentials={},\n        trust_roots={\n            netloc: ca_cert,\n        },\n    )\n    return policy"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authenticate_with_certificate_chain(reactor, base_url, client_chain, client_key, ca_cert):\n    if base_url.scheme != u\"https\":\n        raise ValueError(\n            \"authenticate_with_certificate() makes sense for HTTPS, not {!r}\".format(\n                base_url.scheme\n            ),\n        )\n\n    netloc = NetLocation(host=base_url.host, port=base_url.port)\n    policy = ClientCertificatePolicyForHTTPS(\n        credentials={\n            netloc: TLSCredentials(\n                chain=Chain(certificates=Certificates(client_chain)),\n                key=client_key,\n            ),\n        },\n        trust_roots={\n            netloc: ca_cert,\n        },\n    )\n    return Agent(reactor, contextFactory=policy)", "response": "Creates an Agent which can issue authenticated requests to a particular Kubernetes server using a client certificate chain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nauthenticate with a client certificate.", "response": "def authenticate_with_certificate(reactor, base_url, client_cert, client_key, ca_cert):\n    \"\"\"\n    See ``authenticate_with_certificate_chain``.\n\n    :param pem.Certificate client_cert: The client certificate to use.\n    \"\"\"\n    return authenticate_with_certificate_chain(\n        reactor, base_url, [client_cert], client_key, ca_cert,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authenticate_with_serviceaccount(reactor, **kw):\n    config = KubeConfig.from_service_account(**kw)\n    policy = https_policy_from_config(config)\n    token = config.user[\"token\"]\n    agent = HeaderInjectingAgent(\n        _to_inject=Headers({u\"authorization\": [u\"Bearer {}\".format(token)]}),\n        _agent=Agent(reactor, contextFactory=policy),\n    )\n    return agent", "response": "Create an Agent which can issue authenticated requests to a particular Kubernetes server using a service account token."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the open sesame password in the default keyring", "response": "def _auto_unlock_key_position(self):\n        \"\"\"Find the open sesame password in the default keyring\n        \"\"\"\n        found_pos = None\n        default_keyring_ids = gkr.list_item_ids_sync(self.default_keyring)\n        for pos in default_keyring_ids:\n            item_attrs = gkr.item_get_attributes_sync(self.default_keyring, pos)\n            app = 'application'\n            if item_attrs.has_key(app) and item_attrs[app] == \"opensesame\":\n                found_pos = pos\n                break\n        return found_pos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_position_searchable(self):\n        ids = gkr.list_item_ids_sync(self.keyring)\n        position_searchable = {}\n        for i in ids:\n            item_attrs = gkr.item_get_attributes_sync(self.keyring, i)\n            position_searchable[i] = item_attrs['searchable'] \n        return position_searchable", "response": "Return dict of the position and corrasponding searchable str\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _match_exists(self, searchable):\n        position_searchable = self.get_position_searchable()\n        for pos,val in position_searchable.iteritems():\n            if val == searchable:\n                return pos\n        return False", "response": "Make sure the searchable description doesn t already exist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_password(self, password, **attrs):\n        pos_of_match = self._match_exists(attrs['searchable'])\n        if pos_of_match:\n            old_password = self.get_password(pos_of_match).get_secret()\n            gkr.item_delete_sync(self.keyring, pos_of_match)\n            desc = str(int(time.time())) + \"_\" + attrs['searchable']\n            gkr.item_create_sync(self.keyring\n                                ,gkr.ITEM_GENERIC_SECRET\n                                ,desc\n                                ,{}\n                                ,old_password\n                                ,True)\n        desc = attrs['searchable']\n        pos = gkr.item_create_sync(self.keyring\n                                   ,gkr.ITEM_GENERIC_SECRET\n                                   ,desc\n                                   ,attrs\n                                   ,password\n                                   ,True)\n        return pos", "response": "Save the new password with the date prepended"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the descriptor for a given idcode.", "response": "def get_descriptor_for_idcode(idcode):\n    \"\"\"Use this method to find bsdl descriptions for devices.\n    The caching on this method drastically lower the execution\n    time when there are a lot of bsdl files and more than one\n    device. May move it into a metaclass to make it more\n    transparent.\"\"\"\n    idcode = idcode&0x0fffffff\n    id_str = \"XXXX\"+bin(idcode)[2:].zfill(28)\n\n    descr_file_path = _check_cache_for_idcode(id_str)\n    if descr_file_path:\n        with open(descr_file_path, 'r') as f:\n            dat = json.load(f)\n        if dat.get(\"_file_version\",-1) == JTAGDeviceDescription.version:\n            return JTAGDeviceDescription(dat.get('idcode'),\n                                         dat.get('name'),\n                                         dat.get('ir_length'),\n                                         dat.get('instruction_opcodes'),\n                                         dat.get('registers'),\n                                         dat.get('instruction_register_map'))\n\n    print(\"    Device detected (\"+id_str+\"). Fetching missing descriptor...\")\n    sid = get_sid(id_str)\n    details = get_details(sid)\n    attribs = decode_bsdl(sid)\n\n    #VERIFYING PARSED DATA FROM 2 SOURCES. MESSY BUT USEFUL.\n    instruction_length = 0\n    if attribs.get('INSTRUCTION_LENGTH') ==\\\n       details.get('INSTRUCTION_LENGTH'):\n        instruction_length = attribs.get('INSTRUCTION_LENGTH')\n    elif attribs.get('INSTRUCTION_LENGTH') and\\\n       details.get('INSTRUCTION_LENGTH'):\n        raise Exception(\"INSTRUCTION_LENGTH can not be determined\")\n    elif attribs.get('INSTRUCTION_LENGTH'):\n        instruction_length = attribs.get('INSTRUCTION_LENGTH')\n    else:\n        instruction_length = details.get('INSTRUCTION_LENGTH')\n\n    for instruction_name in details.get('instructions'):\n        if instruction_name not in\\\n           attribs.get('INSTRUCTION_OPCODE',[]):\n            raise Exception(\"INSTRUCTION_OPCODE sources do not match\")\n\n    #print(attribs['IDCODE_REGISTER'])\n    descr = JTAGDeviceDescription(attribs['IDCODE_REGISTER'].upper(),\n                                  details['name'], instruction_length,\n                                  attribs['INSTRUCTION_OPCODE'],\n                                  attribs['REGISTERS'],\n                                  attribs['INSTRUCTION_TO_REGISTER'])\n\n    #CACHE DESCR AS FILE!\n    if not os.path.isdir(base_descr_dir):\n        os.makedirs(base_descr_dir)\n    descr_file_path = os.path.join(base_descr_dir,\n                                   attribs['IDCODE_REGISTER']\\\n                                   .upper()+'.json')\n    with open(descr_file_path, 'w') as f:\n        json.dump(descr._dump(), f)\n\n    return descr"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a git or ssh http ( s ) url.", "response": "def parse_url(self):\n        \"\"\"Parse a git/ssh/http(s) url.\"\"\"\n        url = urlparse(self.url).path\n\n        # handle git\n        url = url.split('.git')[0]\n\n        if ':' in url:\n            url = url.split(':')[1]\n\n        # Ony capture last two list items\n        try:\n            project, repo = url.split('/')[-2:]\n        except ValueError:\n            raise ParserError('\"{}\" is not a valid repository URL.'.format(self.url))\n\n        return project, repo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fetch_dimensions(self, dataset):\n        yield Dimension(u\"school\")\n        yield Dimension(u\"year\",\n                        datatype=\"year\")\n        yield Dimension(u\"semester\",\n                        datatype=\"academic_term\",\n                        dialect=\"swedish\")  # HT/VT\n        yield Dimension(u\"municipality\",\n                        datatype=\"year\",\n                        domain=\"sweden/municipalities\")", "response": "Iterate through semesters counties and municipalities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging one or more KubeConfig objects.", "response": "def _merge_configs(configs):\n    \"\"\"\n    Merge one or more ``KubeConfig`` objects.\n\n    :param list[KubeConfig] configs: The configurations to merge.\n\n    :return KubeConfig: A single configuration object with the merged\n        configuration.\n    \"\"\"\n    result = {\n        u\"contexts\": [],\n        u\"users\": [],\n        u\"clusters\": [],\n        u\"current-context\": None,\n    }\n    for config in configs:\n        for k in {u\"contexts\", u\"users\", u\"clusters\"}:\n            try:\n                values = config.doc[k]\n            except KeyError:\n                pass\n            else:\n                result[k].extend(values)\n\n        if result[u\"current-context\"] is None:\n            try:\n                result[u\"current-context\"] = config.doc[u\"current-context\"]\n            except KeyError:\n                pass\n\n    return KubeConfig(result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _merge_configs_from_env(kubeconfigs):\n    paths = list(\n        FilePath(p)\n        for p\n        in kubeconfigs.split(pathsep)\n        if p\n    )\n    config = _merge_configs(list(\n        KubeConfig.from_file(p.path)\n        for p\n        in paths\n    ))\n    return config", "response": "Merge all of the kubeconfigs from a KUBECONFIG environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef network_kubernetes_from_context(\n        reactor, context=None, path=None, environ=None,\n        default_config_path=FilePath(expanduser(u\"~/.kube/config\")),\n):\n    \"\"\"\n    Create a new ``IKubernetes`` provider based on a kube config file.\n\n    :param reactor: A Twisted reactor which will be used for I/O and\n        scheduling.\n\n    :param unicode context: The name of the kube config context from which to\n        load configuration details.  Or, ``None`` to respect the current\n        context setting from the configuration.\n\n    :param FilePath path: The location of the kube config file to use.\n\n    :param dict environ: A environment direction in which to look up\n        ``KUBECONFIG``.  If ``None``, the real process environment will be\n        inspected.  This is used only if ``path`` is ``None``.\n\n    :return IKubernetes: The Kubernetes service described by the named\n        context.\n    \"\"\"\n    if path is None:\n        if environ is None:\n            from os import environ\n        try:\n            kubeconfigs = environ[u\"KUBECONFIG\"]\n        except KeyError:\n            config = KubeConfig.from_file(default_config_path.path)\n        else:\n            config = _merge_configs_from_env(kubeconfigs)\n    else:\n        config = KubeConfig.from_file(path.path)\n\n    if context is None:\n        context = config.doc[u\"current-context\"]\n\n    context = config.contexts[context]\n    cluster = config.clusters[context[u\"cluster\"]]\n    user = config.users[context[u\"user\"]]\n\n    if isinstance(cluster[u\"server\"], bytes):\n        base_url = URL.fromText(cluster[u\"server\"].decode(\"ascii\"))\n    else:\n        base_url = URL.fromText(cluster[u\"server\"])\n    [ca_cert] = parse(cluster[u\"certificate-authority\"].bytes())\n\n    client_chain = parse(user[u\"client-certificate\"].bytes())\n    [client_key] = parse(user[u\"client-key\"].bytes())\n\n    agent = authenticate_with_certificate_chain(\n        reactor, base_url, client_chain, client_key, ca_cert,\n    )\n\n    return network_kubernetes(\n        base_url=base_url,\n        agent=agent,\n    )", "response": "Create a new IKubernetes provider based on a kube config file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collection_location(obj):\n    # TODO kind is not part of IObjectLoader and we should really be loading\n    # apiVersion off of this object too.\n    kind = obj.kind\n    apiVersion = obj.apiVersion\n\n    prefix = version_to_segments[apiVersion]\n\n    collection = kind.lower() + u\"s\"\n\n    if IObject.providedBy(obj):\n        # Actual objects *could* have a namespace...\n        namespace = obj.metadata.namespace\n    else:\n        # Types representing a kind couldn't possible.\n        namespace = None\n\n    if namespace is None:\n        # If there's no namespace, look in the un-namespaced area.\n        return prefix + (collection,)\n\n    # If there is, great, look there.\n    return prefix + (u\"namespaces\", namespace, collection)", "response": "Get the URL for the collection of objects like obj."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enter_new_scope(ctx):\n    ctx = ctx.clone()\n    ctx.waiting_for = ctx.compiled_story().children_matcher()\n    return ctx", "response": "enter a new scope with it"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the current story part at the current context and make one step further", "response": "async def execute(ctx):\n    \"\"\"\n    execute story part at the current context\n    and make one step further\n\n    :param ctx:\n    :return:\n    \"\"\"\n    tail_depth = len(ctx.stack()) - 1\n\n    story_part = ctx.get_current_story_part()\n    logger.debug('# going to call: {}'.format(story_part.__name__))\n    waiting_for = story_part(ctx.message)\n    if inspect.iscoroutinefunction(story_part):\n        waiting_for = await waiting_for\n    logger.debug('# got result {}'.format(waiting_for))\n\n    # story part could run callable story and return its context\n    if isinstance(waiting_for, story_context.StoryContext):\n        # for such cases is very important to know `tail_depth`\n        # because story context from callable story already has\n        # few stack items above our tail\n        ctx = waiting_for.clone()\n        ctx.waiting_for = callable.WaitForReturn()\n    else:\n        ctx = ctx.clone()\n        ctx.waiting_for = waiting_for\n\n    tail_data = ctx.message['session']['stack'][tail_depth]['data']\n    tail_step = ctx.message['session']['stack'][tail_depth]['step']\n    if ctx.is_waiting_for_input():\n        if isinstance(ctx.waiting_for, callable.EndOfStory):\n            if isinstance(ctx.waiting_for.data, dict):\n                new_data = {**ctx.get_user_data(), **ctx.waiting_for.data}\n            else:\n                new_data = ctx.waiting_for.data\n            ctx.message = {\n                **ctx.message,\n                'session': {\n                    **ctx.message['session'],\n                    'data': new_data,\n                },\n            }\n            tail_step += 1\n        elif isinstance(ctx.waiting_for, loop.ScopeMatcher):\n            # jumping in a loop\n            tail_data = matchers.serialize(ctx.waiting_for)\n        elif isinstance(ctx.waiting_for, loop.BreakLoop):\n            tail_step += 1\n        else:\n            tail_data = matchers.serialize(\n                matchers.get_validator(ctx.waiting_for)\n            )\n            tail_step += 1\n\n    ctx.message = modify_stack_in_message(ctx.message,\n                                          lambda stack: stack[:tail_depth] +\n                                                        [{\n                                                            'data': tail_data,\n                                                            'step': tail_step,\n                                                            'topic': stack[tail_depth]['topic'],\n                                                        }] +\n                                                        stack[tail_depth + 1:])\n    logger.debug('# mutated ctx after execute')\n    logger.debug(ctx)\n    return ctx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iterate_storyline(ctx):\n    logger.debug('# start iterate')\n    compiled_story = ctx.compiled_story()\n    if not compiled_story:\n        return\n\n    for step in range(ctx.current_step(),\n                      len(compiled_story.story_line)):\n        ctx = ctx.clone()\n        tail = ctx.stack_tail()\n        ctx.message = modify_stack_in_message(ctx.message,\n                                              lambda stack: stack[:-1] + [{\n                                                  'data': tail['data'],\n                                                  'step': step,\n                                                  'topic': tail['topic'],\n                                              }])\n\n        logger.debug('# [{}] iterate'.format(step))\n        logger.debug(ctx)\n\n        ctx = yield ctx", "response": "iterate the last storyline from the last visited story part\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scope_in(ctx):\n    logger.debug('# scope_in')\n    logger.debug(ctx)\n    ctx = ctx.clone()\n\n    compiled_story = None\n    if not ctx.is_empty_stack():\n        compiled_story = ctx.get_child_story()\n        logger.debug('# child')\n        logger.debug(compiled_story)\n        # we match child story loop once by message\n        # what should prevent multiple matching by the same message\n        ctx.matched = True\n        ctx.message = modify_stack_in_message(ctx.message,\n                                              lambda stack: stack[:-1] + [{\n                                                  'data': matchers.serialize(callable.WaitForReturn()),\n                                                  'step': stack[-1]['step'],\n                                                  'topic': stack[-1]['topic']\n                                              }])\n\n    try:\n        if not compiled_story and ctx.is_scope_level_part():\n            compiled_story = ctx.get_current_story_part()\n    except story_context.MissedStoryPart:\n        pass\n\n    if not compiled_story:\n        compiled_story = ctx.compiled_story()\n\n    logger.debug('# [>] going deeper')\n    ctx.message = modify_stack_in_message(ctx.message,\n                                          lambda stack: stack + [\n                                              stack_utils.build_empty_stack_item(compiled_story.topic)])\n    logger.debug(ctx)\n    return ctx", "response": "build new scope on top of stack"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a string into a date object.", "response": "def str2date(self, date_str):\n        \"\"\"\n        Parse date from string.\n\n        If there's no template matches your string, Please go\n        https://github.com/MacHu-GWU/rolex-project/issues\n        submit your datetime string. I 'll update templates ASAP.\n\n        This method is faster than :meth:`dateutil.parser.parse`.\n\n        :param date_str: a string represent a date\n        :type date_str: str\n        :return: a date object\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        \u4ecestring\u89e3\u6790date\u3002\u9996\u5148\u5c1d\u8bd5\u9ed8\u8ba4\u6a21\u677f, \u5982\u679c\u5931\u8d25\u4e86, \u5219\u5c1d\u8bd5\u6240\u6709\u7684\u6a21\u677f\u3002\n        \u4e00\u65e6\u5c1d\u8bd5\u6210\u529f, \u5c31\u5c06\u5f53\u524d\u6210\u529f\u7684\u6a21\u677f\u4fdd\u5b58\u4e3a\u9ed8\u8ba4\u6a21\u677f\u3002\u8fd9\u6837\u505a\u5728\u5f53\u4f60\u5f85\u89e3\u6790\u7684\n        \u5b57\u7b26\u4e32\u975e\u5e38\u591a, \u4e14\u6a21\u5f0f\u5355\u4e00\u65f6, \u53ea\u6709\u7b2c\u4e00\u6b21\u5c1d\u8bd5\u8017\u65f6\u8f83\u591a, \u4e4b\u540e\u5c31\u975e\u5e38\u5feb\u4e86\u3002\n        \u8be5\u65b9\u6cd5\u8981\u5feb\u8fc7 :meth:`dateutil.parser.parse` \u65b9\u6cd5\u3002\n        \"\"\"\n        # try default date template\n        try:\n            a_datetime = datetime.strptime(\n                date_str, self._default_date_template)\n            return a_datetime.date()\n        except:\n            pass\n\n        # try every date templates\n        for template in date_template_list:\n            try:\n                a_datetime = datetime.strptime(date_str, template)\n                self._default_date_template = template\n                return a_datetime.date()\n            except:\n                pass\n\n        # raise error\n        raise ValueError(\"Unable to parse date from: %r!\" % date_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _str2datetime(self, datetime_str):\n        # try default datetime template\n        try:\n            a_datetime = datetime.strptime(\n                datetime_str, self._default_datetime_template)\n            return a_datetime\n        except:\n            pass\n\n        # try every datetime templates\n        for template in datetime_template_list:\n            try:\n                a_datetime = datetime.strptime(datetime_str, template)\n                self._default_datetime_template = template\n                return a_datetime\n            except:\n                pass\n\n        # raise error\n        a_datetime = parse(datetime_str)\n        self.str2datetime = parse\n\n        return a_datetime", "response": "Parse a string into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_date(self, value):\n        if isinstance(value, sixmini.string_types):\n            return self.str2date(value)\n        elif value is None:\n            raise TypeError(\"Unable to parse date from %r\" % value)\n        elif isinstance(value, sixmini.integer_types):\n            return date.fromordinal(value)\n        elif isinstance(value, datetime):\n            return value.date()\n        elif isinstance(value, date):\n            return value\n        else:\n            raise ValueError(\"Unable to parse date from %r\" % value)", "response": "A lazy method to parse anything to date."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_datetime(self, value):\n        if isinstance(value, sixmini.string_types):\n            return self.str2datetime(value)\n        elif value is None:\n            raise TypeError(\"Unable to parse datetime from %r\" % value)\n        elif isinstance(value, sixmini.integer_types):\n            return from_utctimestamp(value)\n        elif isinstance(value, float):\n            return from_utctimestamp(value)\n        elif isinstance(value, datetime):\n            return value\n        elif isinstance(value, date):\n            return datetime(value.year, value.month, value.day)\n        else:\n            raise ValueError(\"Unable to parse datetime from %r\" % value)", "response": "A lazy method to parse any value to datetime."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef define(self):\n        if len(self.states) == 0:\n            for char in self.alphabet:\n                self.add_arc(0, 0, char)\n                self[0].final = False", "response": "Define a sink state for the DFA."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_state(self):\n        sid = len(self.states)\n        self.states.append(DFAState(sid))\n        return sid", "response": "Adds a new state to the list of states"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_arc(self, src, dst, char):\n        # assert type(src) == type(int()) and type(dst) == type(int()), \\\n        #     \"State type should be integer.\"\n        # assert char in self.I\n        #\n        #print self.states\n        #print src\n        for s_idx in [src, dst]:\n            if s_idx >= len(self.states):\n                for i in range(len(self.states), s_idx + 1):\n                    self.states.append(DFAState(i))\n        for arc in self.states[src].arcs:\n            if arc.ilabel == self.isyms.__getitem__(char) or char == EPSILON:\n                self.nfa = True\n                break\n        self.states[src].arcs.append(\n            DFAArc(src, dst, self.isyms.__getitem__(char)))", "response": "Adds a new Arc\n        to the internal list of Arcs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the complement of the DFA.", "response": "def complement(self, alphabet):\n        \"\"\"\n        Returns the complement of DFA\n        Args:\n            alphabet (list): The input alphabet\n        Returns:\n            None\n        \"\"\"\n        states = sorted(self.states, key=attrgetter('initial'), reverse=True)\n        for state in states:\n            if state.final:\n                state.final = False\n            else:\n                state.final = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the state of the object from the given acceptor.", "response": "def init_from_acceptor(self, acceptor):\n        \"\"\"\n        Adds a sink state\n        Args:\n            alphabet (list): The input alphabet\n        Returns:\n            None\n        \"\"\"\n        self.states = copy.deepcopy(acceptor.states)\n        self.alphabet = copy.deepcopy(acceptor.alphabet)\n        self.osyms = copy.deepcopy(acceptor.osyms)\n        self.isyms = copy.deepcopy(acceptor.isyms)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the transducer from the text file format of OpenFST.", "response": "def load(self, txt_fst_file_name):\n        \"\"\"\n        Save the transducer in the text file format of OpenFST.\n        The format is specified as follows:\n            arc format: src dest ilabel olabel [weight]\n            final state format: state [weight]\n        lines may occur in any order except initial state must be first line\n        Args:\n            txt_fst_file_name (str): The input file\n        Returns:\n            None\n        \"\"\"\n        with open(txt_fst_file_name, 'r') as input_filename:\n            for line in input_filename:\n                line = line.strip()\n                split_line = line.split()\n                if len(split_line) == 1:\n                    self[int(split_line[0])].final = True\n                else:\n                    self.add_arc(int(split_line[0]), int(split_line[1]),\n                                 split_line[2].decode('hex'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct an unminimized DFA recognizing the intersection of the languages of two given DFAs.", "response": "def intersect(self, other):\n        \"\"\"Constructs an unminimized DFA recognizing\n        the intersection of the languages of two given DFAs.\n        Args:\n            other (DFA): The other DFA that will be used\n                         for the intersect operation\n        Returns:\n        Returns:\n            DFA: The resulting DFA\n        \"\"\"\n        operation = bool.__and__\n        self.cross_product(other, operation)\n        return  self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct an unminimized DFA recognizing the symmetric difference of the languages of two given DFAs.", "response": "def symmetric_difference(self, other):\n        \"\"\"Constructs an unminimized DFA recognizing\n        the symmetric difference of the languages of two given DFAs.\n        Args:\n            other (DFA): The other DFA that will be used\n                         for the symmetric difference operation\n        Returns:\n            DFA: The resulting DFA\n        \"\"\"\n        operation = bool.__xor__\n        self.cross_product(other, operation)\n        return  self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing an unminimized DFA recognizing the union of the languages of two given DFAs.", "response": "def union(self, other):\n        \"\"\"Constructs an unminimized DFA recognizing the union of the languages of two given DFAs.\n        Args:\n            other (DFA): The other DFA that will be used\n                         for the union operation\n        Returns:\n            DFA: The resulting DFA\n        \"\"\"\n        operation = bool.__or__\n        self.cross_product(other, operation)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _epsilon_closure(self, state):\n        closure = set([state.stateid])\n        stack = [state]\n        while True:\n            if not stack:\n                break\n            s = stack.pop()\n            for arc in s:\n                if self.isyms.find(arc.ilabel) != EPSILON or \\\n                        arc.nextstate in closure:\n                    continue\n                closure.add(arc.nextstate)\n                stack.append(self.states[arc.nextstate])\n        return closure", "response": "Returns the \\ epsilon - closure for the given state given as input."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef determinize(self):\n\n        # Compute the \\epsilon-closure for all states and save it in a diagram\n        epsilon_closure = {}\n        for state in self.states:\n            sid = state.stateid\n            epsilon_closure[sid] = self._epsilon_closure(state)\n\n        # Get a transition diagram to speed up computations\n        trans_table = {}\n        for state in self.states:\n            trans_table[state.stateid] = defaultdict(set)\n            for arc in state:\n                char = self.isyms.find(arc.ilabel)\n                trans_table[state.stateid][char].add(arc.nextstate)\n\n        # is_final function:\n        # Given a set of nfa states representing a dfa_state return 1 if the\n        # corresponding DFA state is a final state, i.e. if any of the\n        # corresponding NFA states are final.\n        is_final = lambda nfa_states, dfa_state: True \\\n            if sum([ int(nfa_states[x].final) for x in dfa_state ]) >= 1 \\\n            else False\n\n        # Precomputation is over, start executing the conversion algorithm\n        state_idx = 1\n        nfa_states = copy.deepcopy(self.states)\n        self.states = []\n        # Initialize the new DFA state list\n        self.add_state()\n        new_initial = epsilon_closure[nfa_states[0].stateid]\n        self.states[0].final = is_final(nfa_states, new_initial)\n\n        dfa_state_idx_map = { frozenset(new_initial) : 0 }\n        stack = [new_initial]\n        while True:\n            # Iterate until all added DFA states are processed.\n            if not stack:\n                break\n            # This is a set of states from the NFA\n            src_dfa_state = stack.pop()\n            src_dfa_state_idx = dfa_state_idx_map[frozenset(src_dfa_state)]\n            for char in self.alphabet:\n                # Compute the set of target states\n                target_dfa_state = set([])\n                for nfa_state in src_dfa_state:\n                    next_states = \\\n                        set([y for x in trans_table[nfa_state][char] \\\n                             for y in epsilon_closure[x] ])\n                    target_dfa_state.update(next_states)\n                # If the computed state set is not part of our new DFA add it,\n                # along with the transition for the current character.\n                if frozenset(target_dfa_state) not in dfa_state_idx_map:\n                    self.add_state()\n                    dfa_state_idx_map[frozenset(target_dfa_state)] = state_idx\n                    self.states[state_idx].final = is_final(nfa_states,\n                                                            target_dfa_state)\n                    state_idx += 1\n                    stack.append(target_dfa_state)\n\n                dst_state_idx = dfa_state_idx_map[frozenset(target_dfa_state)]\n                self.add_arc(src_dfa_state_idx, dst_state_idx, char)\n        return self", "response": "This function computes a Non Deterministic DFA into a Deterministic DFA."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvert the final states of the DFA.", "response": "def invert(self):\n        \"\"\"Inverts the DFA final states\"\"\"\n        for state in self.states:\n            if state.final:\n                state.final = False\n            else:\n                state.final = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hopcroft(self):\n\n        def _getset(testset, partition):\n            \"\"\"\n            Checks if a set is in a partition\n            Args:\n                testset (set): The examined set\n                partition (list): A list of sets\n            Returns:\n                bool: A value indicating if it is a member or not\n            \"\"\"\n            for part in partition:\n                if set(testset) == set(part):\n                    return True\n            return None\n\n        def _create_transitions_representation(graph):\n            \"\"\"\n            In order to speedup the transition iteration using\n            the alphabet, the function creates an index\n            Args:\n                graph (DFA): The input dfa\n                state (DFA state): The examined state\n            Returns:\n                dict: The generated transition map\n            \"\"\"\n            return {x.stateid:{self.isyms.find(arc.ilabel): arc.nextstate \\\n                               for arc in x} for x in graph.states}\n\n        def _create_reverse_transitions_representation(graph):\n            \"\"\"\n            In order to speedup the transition iteration using\n            the alphabet, the function creates an index\n            Args:\n                graph (DFA): The input dfa\n                state (DFA state): The examined state\n            Returns:\n                dict: The generated transition map\n            \"\"\"\n            return {x.stateid: {self.isyms.find(arc.ilabel): arc.nextstate \\\n                                for arc in x} for x in graph.states}\n\n        def _reverse_to_source(target, group1):\n            \"\"\"\n            Args:\n                target (dict): A table containing the reverse transitions for each state\n                group1 (list): A group of states\n            Return:\n                Set: A set of states for which there is a transition with the states of the group\n            \"\"\"\n            new_group = []\n            for dst in group1:\n                new_group += target[dst]\n            return set(new_group)\n\n        def _get_group_from_state(groups, sid):\n            \"\"\"\n            Args:\n                sid (int): The state identifier\n            Return:\n                int: The group identifier that the state belongs\n            \"\"\"\n            for index, selectgroup in enumerate(groups):\n                if sid in selectgroup:\n                    return index\n\n        def _delta(graph, cur_state, char):\n            \"\"\"\n            Function describing the transitions\n            Args:\n                graph (DFA): The DFA states\n                cur_state (DFA state): The DFA current state\n                char (str):: The char that will be used for the transition\n            Return:\n                DFA Node: The next state\n            \"\"\"\n            for arc in cur_state.arcs:\n                if graph.isyms.find(arc.ilabel) == char:\n                    return graph[arc.nextstate]\n\n        def _partition_group(bookeeping, group):\n            \"\"\"\n            Args:\n                group (list):  A group of states\n            Return:\n                tuple: A set of two groups\n            \"\"\"\n            for (group1, group2) in bookeeping:\n                if group & group1 != set() and not group.issubset(group1):\n                    new_g1 = group & group1\n                    new_g2 = group - group1\n                    return (new_g1, new_g2)\n                if group & group2 != set() and not group.issubset(group2):\n                    new_g1 = group & group2\n                    new_g2 = group - group2\n                    return (new_g1, new_g2)\n            assert False, \"Unmatched group partition\"\n\n        def _object_set_to_state_list(objectset):\n            \"\"\"\n            Args:\n                objectset (list): A list of all the DFA states (as objects)\n            Return:\n                list: A list of all the DFA states (as identifiers)\n            \"\"\"\n            return [state.stateid for state in objectset]\n\n        def _get_accepted(graph):\n            \"\"\"\n            Find the accepted states\n            Args:\n                graph (DFA): The DFA states\n            Return:\n                list: Returns the list of the accepted states\n            \"\"\"\n            return [state for state in graph \\\n                    if  state.final != TropicalWeight(float('inf'))]\n\n        graph = self\n\n        # Find Q\n        set_q = set(_object_set_to_state_list(graph.states))\n        # We will work with states addresses here instead of states stateid for\n        # more convenience\n        set_f = set(_object_set_to_state_list(_get_accepted(graph)))\n        # Perform P := {F, Q-F}\n        set_nf = set_q.copy() - set_f.copy()\n        groups = [set_f.copy(), set_nf.copy()]\n        bookeeping = [(set_f, set_nf)]\n\n        done = False\n        while not done:\n            done = True\n            new_groups = []\n            for selectgroup in groups:\n                # _check for each letter if it splits the current group\n                for character in self.alphabet:\n                    # print 'Testing symbol: ', c\n                    target = defaultdict(list)\n                    target_states = defaultdict(int)\n                    new_g = [set(selectgroup)]\n                    for sid in selectgroup:\n                        # _check if all transitions using c are going in a state\n                        # in the same group. If they are going on a different\n                        # group then split\n                        deststate = _delta(graph, graph[sid], character)\n                        destgroup = _get_group_from_state(groups,\n                            deststate.stateid)\n                        target[destgroup].append(sid)\n                        target_states[destgroup] = deststate.stateid\n                    if len(target) > 1:\n\n                        inv_target_states = {\n                            v: k for k, v in target_states.iteritems()}\n                        new_g = [set(selectedstate) for selectedstate in target.values()]\n                        done = False\n                        # Get all the partitions of destgroups\n                        queue = [set([x for x in target_states.values()])]\n                        while queue:\n                            top = queue.pop(0)\n                            (group1, group2) = _partition_group(bookeeping, top)\n                            ng1 = _reverse_to_source(\n                                target, [inv_target_states[x] for x in group1])\n                            ng2 = _reverse_to_source(\n                                target, [inv_target_states[x] for x in group2])\n\n                            bookeeping.append((ng1, ng2))\n\n                            if len(group1) > 1:\n                                queue.append(group1)\n                            if len(group2) > 1:\n                                queue.append(group2)\n                        break\n                new_groups += new_g\n\n            # End of iteration for the k-equivalence\n            # Assign new groups and check if any change occured\n            groups = new_groups\n\n        # Make a copy of the old states, and prepare the\n        # automaton to host the minimum states\n\n        oldstates = copy.deepcopy(self.states)\n        self.states = []\n        self.define()\n\n        def findpart(stateid, partitions):\n            \"\"\"Searches for the groupt that the state identifier\n            belongs to.\n            Args:\n                stateid (int): The state identifier\n                partitions (list): The list of the groups\n            Returns:\n                set: The group that the stateid belongs to.\n            \"\"\"\n            for group in partitions:\n                if stateid in group:\n                    return frozenset(group)\n            return frozenset(set(            ))\n\n        def add_state_if_not_exists(group, statesmap, final):\n            \"\"\"\n            Adds a new state in the final dfa. It initialy checks if\n            the group of states is already registered to the automaton.\n            If it is registered, the state identifier is returned, or\n            else, a new state is added.\n            Args:\n                group (frozenset):  The group that the state identifier belongs\n                statesmap (dict):   A dictionary that maintains the state\n                                    identifiers for each forzenset\n                final (bool):       A value indicating if the current state is\n                                    final\n            Returns:\n                int: The new state identifier\n            \"\"\"\n            if group not in statesmap:\n                sid = self.add_state()\n                self[sid].final = final\n                statesmap[group] = sid\n            return statesmap[group]\n\n        statesmap = {}\n        self.states = []\n        group = findpart(0, groups)\n        sid = add_state_if_not_exists(frozenset(list(group)), statesmap,\n                                      oldstates[0].final)\n        self[sid].initial = True\n        for group in groups:\n            if len(group) == 0:\n                continue\n            sid = add_state_if_not_exists(frozenset(group), statesmap,\n                                          oldstates[list(group)[0]].final)\n            state = next(iter(group))\n            for arc in oldstates[state]:\n                dst_group = findpart(arc.nextstate, groups)\n                dst_sid = add_state_if_not_exists(\n                    dst_group, statesmap, oldstates[arc.nextstate].final)\n                self.add_arc(sid, dst_sid, graph.isyms.find(arc.ilabel))", "response": "This function performs the Hopcroft minimization algorithm for the current DFA."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cross_product(self, dfa_2, accept_method):\n        dfa_1states = copy.deepcopy(self.states)\n        dfa_2states = dfa_2.states\n        self.states = []\n        states = {}\n\n\n        def _create_transitions_representation(graph, state):\n            \"\"\"\n            In order to speedup the transition iteration using\n            the alphabet, the function creates an index\n            Args:\n                graph (DFA): The input dfa\n                state (DFA state): The examined state\n            Returns:\n                dict: The generated transition map\n            \"\"\"\n            return {self.isyms.find(arc.ilabel): graph[arc.nextstate] for arc in state}\n\n\n        def _add_state_if_nonexistent(state_a, state_b):\n            \"\"\"\n            Adds a new state in the final dfa, which is the\n            combination of the input states. The initial and final\n            flag is also placed on the new state. If the state already\n            exists, its identifier is being returned.\n            Args:\n                state_a: The fist state identifier\n                state_b: The second state identifier\n            Returns:\n                int: The new state identifier\n            \"\"\"\n            if (state_a.stateid, state_b.stateid) not in states:\n                states[(state_a.stateid, state_b.stateid)] \\\n                    = self.add_state()\n                self[states[(state_a.stateid, state_b.stateid)]].initial \\\n                    = state_a.initial and state_b.initial\n                self[states[(state_a.stateid, state_b.stateid)]].final \\\n                    = accept_method(state_a.final, state_b.final)\n            return states[(state_a.stateid, state_b.stateid)]\n\n        for state1, state2 in product(dfa_1states, dfa_2states):\n            sid1 = _add_state_if_nonexistent(state1, state2)\n            transitions_s1 = _create_transitions_representation(dfa_1states, state1)\n            transitions_s2 = _create_transitions_representation(dfa_2states, state2)\n            for char in self.alphabet:\n                sid2 = _add_state_if_nonexistent(\n                    transitions_s1[char], transitions_s2[char])\n                self.add_arc(sid1, sid2, char)", "response": "A generalized cross - product method over two DFAs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list version of the object based on its attributes", "response": "def as_list(self):\r\n        \"\"\"\r\n        returns a list version of the object, based on it's attributes\r\n        \"\"\"\r\n        if hasattr(self, 'cust_list'):\r\n            return self.cust_list\r\n        if hasattr(self, 'attr_check'):\r\n            self.attr_check()\r\n        cls_bltns = set(dir(self.__class__))\r\n        ret = [a for a in dir(self) if a not in cls_bltns and getattr(self, a)]\r\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict version of the object based on its attributes", "response": "def as_dict(self):\r\n        \"\"\"\r\n        returns an dict version of the object, based on it's attributes\r\n        \"\"\"\r\n        if hasattr(self, 'cust_dict'):\r\n            return self.cust_dict\r\n        if hasattr(self, 'attr_check'):\r\n            self.attr_check()\r\n        cls_bltns = set(dir(self.__class__))\r\n        return {a: getattr(self, a) for a in dir(self) if a not in cls_bltns}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an odict version of the object based on its attributes.", "response": "def as_odict(self):\r\n        \"\"\"\r\n        returns an odict version of the object, based on it's attributes\r\n        \"\"\"\r\n        if hasattr(self, 'cust_odict'):\r\n            return self.cust_odict\r\n        if hasattr(self, 'attr_check'):\r\n            self.attr_check()\r\n        odc = odict()\r\n        for attr in self.attrorder:\r\n            odc[attr] = getattr(self, attr)\r\n        return odc"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a url and returns a dictionary of data with bodyLines lines", "response": "def fetch_and_parse(url, bodyLines):\n    \"\"\"Takes a url, and returns a dictionary of data with 'bodyLines' lines\"\"\"\n\n    pageHtml = fetch_page(url)\n    return parse(url, pageHtml, bodyLines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind a valid CashDiary for today from the given POS.", "response": "def find(pos, user):\n        '''\n        Get a valid CashDiary for today from the given POS, it will return:\n            - None: if no CashDiary is available today and older one was already closed\n            - New CashDiary: if no CashDiary is available today but there is an older one which it was opened\n            - Existing CashDiary: if a CashDiary is available today (open or close)\n        '''\n\n        # Get checkpoint\n        ck = dateparse.parse_time(getattr(settings, \"CASHDIARY_CLOSES_AT\", '03:00'))\n        year = timezone.now().year\n        month = timezone.now().month\n        day = timezone.now().day\n        hour = ck.hour\n        minute = ck.minute\n        second = ck.second\n        checkpoint = timezone.datetime(year, month, day, hour, minute, second)\n\n        # Get\n        cashdiary = CashDiary.objects.filter(pos=pos, opened_date__gte=checkpoint).order_by(\"-opened_date\").first()\n        if not cashdiary:\n            # No cashdiary found for today, check older one\n            oldercashdiary = CashDiary.objects.filter(pos=pos, opened_date__lt=checkpoint).order_by(\"-opened_date\").first()\n            if oldercashdiary:\n                if oldercashdiary.closed_user:\n                    cashdiary = None\n                else:\n                    # Older cashdiary is not closed, we have to close it and open a new one\n                    amount_cash = oldercashdiary.amount_cash()\n                    amount_cards = oldercashdiary.amount_cards()\n                    # The older cashdiary is still opened, we have to close it and create a new one\n                    oldercashdiary.closed_cash = amount_cash\n                    oldercashdiary.closed_cards = amount_cards\n                    oldercashdiary.closed_user = user\n                    oldercashdiary.closed_date = timezone.now()\n                    oldercashdiary.save()\n                    # Open new cashdiary\n                    cashdiary = CashDiary()\n                    cashdiary.pos = pos\n                    cashdiary.opened_cash = amount_cash\n                    cashdiary.opened_cards = amount_cards\n                    cashdiary.opened_user = user\n                    cashdiary.opened_date = timezone.now()\n                    cashdiary.save()\n            else:\n                # initial new cashdiary\n                cashdiary = CashDiary()\n                cashdiary.pos = pos\n                cashdiary.opened_cash = Decimal('0')\n                cashdiary.opened_cards = Decimal('0')\n                cashdiary.opened_user = user\n                cashdiary.opened_date = timezone.now()\n                cashdiary.save()\n\n        # Return the found CashDiary\n        return cashdiary"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_rec(source, dest):\n\n    if os.path.isdir(source):\n        for child in os.listdir(source):\n            new_dest = os.path.join(dest, child)\n            os.makedirs(new_dest, exist_ok=True)\n            copy_rec(os.path.join(source, child), new_dest)\n\n    elif os.path.isfile(source):\n        logging.info(' Copy \"{}\" to \"{}\"'.format(source, dest))\n        shutil.copy(source, dest)\n\n    else:\n        logging.info(' Ignoring \"{}\"'.format(source))", "response": "This function copies one or more files between diferent directories."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(self):\n        signed = bool(self.options() & Builder.Options.Signed)\n\n        # remove previous build information\n        buildpath = self.buildPath()\n        if not buildpath:\n            raise errors.InvalidBuildPath(buildpath)\n\n        # setup the environment\n        for key, value in self.environment().items():\n            log.info('SET {0}={1}'.format(key, value))\n            os.environ[key] = value\n\n        if os.path.exists(buildpath):\n            shutil.rmtree(buildpath)\n\n        # generate the build path for the installer\n        os.makedirs(buildpath)\n\n        # create the output path\n        outpath = self.outputPath()\n        if not os.path.exists(outpath):\n            os.makedirs(outpath)\n\n        # copy license information\n        src = self.licenseFile()\n        if src and os.path.exists(src):\n            targ = os.path.join(buildpath, 'license.txt')\n            shutil.copyfile(src, targ)\n\n        # generate revision information\n        if self.options() & Builder.Options.GenerateRevision:\n            self.generateRevision()\n\n        # generate documentation information\n        if self.options() & Builder.Options.GenerateDocs:\n            self.generateDocumentation(buildpath)\n\n        # generate setup file\n        if self.options() & Builder.Options.GenerateSetupFile:\n            setuppath = os.path.join(self.sourcePath(), '..')\n            egg = (self.options() & Builder.Options.GenerateEgg) != 0\n            self.generateSetupFile(setuppath, egg=egg)\n\n        # generate executable information\n        if self.options() & Builder.Options.GenerateExecutable:\n            if not self.generateExecutable(signed=signed):\n                return\n\n        # generate zipfile information\n        if self.options() & Builder.Options.GenerateZipFile:\n            self.generateZipFile(self.outputPath())\n\n        # generate installer information\n        if self.options() & Builder.Options.GenerateInstaller:\n            self.generateInstaller(buildpath, signed=signed)", "response": "Builds the object into the desired output information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generateExecutable(self, outpath='.', signed=False):\n        if not (self.runtime() or self.specfile()):\n            return True\n\n        if not self.distributionPath():\n            return True\n\n        if os.path.exists(self.distributionPath()):\n            shutil.rmtree(self.distributionPath())\n\n        if os.path.isfile(self.sourcePath()):\n            basepath = os.path.normpath(os.path.dirname(self.sourcePath()))\n        else:\n            basepath = os.path.normpath(self.sourcePath())\n\n        # store the plugin table of contents\n        self.generatePlugins(basepath)\n\n        # generate the specfile if necessary\n        specfile = self.specfile()\n        # generate the spec file options\n        opts = {\n            'name': self.name(),\n            'exname': self.executableName(),\n            'product': self.productName(),\n            'runtime': self.runtime(),\n            'srcpath': self.sourcePath(),\n            'buildpath': self.buildPath(),\n            'hookpaths': ',\\n'.join(wrap_str(self.hookPaths())),\n            'hiddenimports': ',\\n'.join(wrap_str(self.hiddenImports())),\n            'distpath': self.distributionPath(),\n            'platform': sys.platform,\n            'excludes': ',\\n'.join(wrap_str(self.executableExcludes()))\n        }\n\n        if not specfile:\n            datasets = []\n            for typ, data in self.executableData():\n                if typ == 'tree':\n                    args = {\n                        'path': data[0],\n                        'prefix': data[1],\n                        'excludes': ','.join(wrap_str(data[2]))\n                    }\n\n                    datasets.append(templ.SPECTREE.format(**args))\n\n                else:\n                    args = {}\n                    args.update(data)\n                    args.setdefault('type', typ)\n                    datasets.append(templ.SPECDATA.format(**args))\n\n            opts['datasets'] = '\\n'.join(datasets)\n\n            opts.update(self._executableOptions)\n\n            if self.executableCliName():\n                opts['cliname'] = self.executableCliName()\n                opts['collect'] = templ.SPECFILE_CLI.format(**opts)\n            else:\n                opts['collect'] = templ.SPECFILE_COLLECT.format(**opts)\n\n            if opts['onefile']:\n                data = templ.SPECFILE_ONEFILE.format(**opts)\n            else:\n                data = templ.SPECFILE.format(**opts)\n\n            # generate the spec file for building\n            specfile = os.path.join(self.buildPath(), self.name() + '.spec')\n            f = open(specfile, 'w')\n            f.write(data)\n            f.close()\n\n        cmd = os.path.expandvars(self.executableOption('cmd'))\n        success = cmdexec(cmd.format(spec=specfile)) == 0\n        if signed:\n            binfile = os.path.join(opts['distpath'],\n                                   opts['product'],\n                                   opts['exname'] + '.exe')\n            self.sign(binfile)\n\n        return success", "response": "Generates the executable for this builder in the output path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generateRevision(self):\n        revpath = self.sourcePath()\n        if not os.path.exists(revpath):\n            return\n\n        # determine the revision location\n        revfile = os.path.join(revpath, self.revisionFilename())\n        mode = ''\n        # test for svn revision\n        try:\n            args = ['svn', 'info', revpath]\n            proc = subprocess.Popen(args, stdout=subprocess.PIPE)\n            mode = 'svn'\n        except WindowsError:\n            try:\n                args = ['git', 'rev-parse', 'HEAD', revpath]\n                proc = subprocess.Popen(args, stdout=subprocess.PIPE)\n                mode = 'git'\n            except WindowsError:\n                return\n\n        # process SVN revision\n        rev = None\n\n        if mode == 'svn':\n            for line in proc.stdout:\n                data = re.match('^Revision: (\\d+)', line)\n                if data:\n                    rev = int(data.group(1))\n                    break\n\n        if rev is not None:\n            try:\n                f = open(revfile, 'w')\n                f.write('__revision__ = {0}\\n'.format(rev))\n                f.close()\n            except IOError:\n                pass", "response": "Generates the revision file for this builder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the installer for this builder.", "response": "def generateInstaller(self, outpath='.', signed=False):\n        \"\"\"\n        Generates the installer for this builder.\n        \n        :param      outpath | <str>\n        \"\"\"\n        log.info('Generating Installer....')\n\n        # generate the options for the installer\n        opts = {\n            'name': self.name(),\n            'exname': self.executableName(),\n            'version': self.version(),\n            'company': self.company(),\n            'language': self.language(),\n            'license': self.license(),\n            'platform': sys.platform,\n            'product': self.productName(),\n            'outpath': self.outputPath(),\n            'instpath': self.installPath(),\n            'instname': self.installName(),\n            'buildpath': self.buildPath(),\n            'srcpath': self.sourcePath(),\n            'nsis_exe': os.environ['NSIS_EXE'],\n            'signed': '',\n            'signcmd': ''\n        }\n\n        basetempl = ''\n        if self.runtime() and os.path.exists(self.distributionPath()):\n            opts['compilepath'] = os.path.join(self.distributionPath(), self.executableName())\n            basetempl = templ.NSISAPP\n\n        elif os.path.isfile(self.sourcePath()):\n            opts['compilepath'] = self.sourcePath()\n            opts['install'] = templ.NSISMODULE.format(**opts)\n            basetempl = templ.NSISLIB\n\n        else:\n            opts['compilepath'] = self.sourcePath()\n            opts['install'] = templ.NSISPACKAGE.format(**opts)\n            basetempl = templ.NSISLIB\n\n        # sign the uninstaller\n        if signed and self.signcmd():\n            cmd = self.signcmd().format(filename='', cert=self.certificate())\n            cmd = os.path.expandvars(cmd)\n            cmd = cmd.replace('\"\"', '')\n\n            opts['signed'] = '!define SIGNED'\n            opts['signcmd'] = cmd\n\n        opts.update(self._installerOptions)\n\n        # expand the plugin paths\n        pre_section_plugins = []\n        post_section_plugins = []\n        install_plugins = []\n        uninstall_plugins = []\n\n        for filename in self.installerOption('pre_section_plugins', []):\n            with open(filename, 'r') as f:\n                pre_section_plugins.append(f.read().format(**opts))\n\n        for filename in self.installerOption('post_section_plugins', []):\n            with open(filename, 'r') as f:\n                post_section_plugins.append(f.read().format(**opts))\n\n        for filename in self.installerOption('install_section_plugins', []):\n            with open(filename, 'r') as f:\n                install_plugins.append(f.read().format(**opts))\n\n        for filename in self.installerOption('uninstall_section_plugins', []):\n            with open(filename, 'r') as f:\n                uninstall_plugins.append(f.read().formst(**opts))\n\n        opts['install_plugins'] = '\\n'.join(install_plugins)\n        opts['uninstall_plugins'] = '\\n'.join(uninstall_plugins)\n        opts['pre_section_plugins'] = '\\n'.join(pre_section_plugins)\n        opts['post_section_plugins'] = '\\n'.join(post_section_plugins)\n        opts['choose_directory'] = templ.NSISCHOOSEDIRECTORY if opts['choose_dir'] else ''\n\n        req_license = self._installerOptions.pop('require_license_approval', False)\n        if req_license:\n            opts['require_license_approval'] = templ.NSISLICENSERADIO\n        else:\n            opts['require_license_approval'] = ''\n\n        outfile = os.path.join(os.path.abspath(outpath), 'autogen.nsi')\n        opts['__file__'] = outfile\n\n        # update the additional directories\n        addtl = []\n        for directory, source in self._installDirectories.items():\n            directory = os.path.expandvars(directory.format(**opts))\n            directory = os.path.normpath(directory)\n\n            if source:\n                source = os.path.expandvars(source.format(**opts))\n                source = os.path.abspath(source)\n\n                addtl.append('    SetOutPath \"{0}\"'.format(directory))\n                addtl.append('    File /nonfatal /r \"{0}\"'.format(source))\n            else:\n                addtl.append('    CreateDirectory \"{0}\"'.format(directory))\n\n        opts['addtl_commands'] = '\\n'.join(addtl)\n        data = basetempl.format(**opts)\n\n        # create the output file\n        f = open(outfile, 'w')\n        f.write(data)\n        f.close()\n\n        installerfile = os.path.join(self.outputPath(), self.installName())\n        installerfile += '-{0}.exe'.format(sys.platform)\n\n        # run the installer\n        cmd = os.path.expandvars(self.installerOption('cmd'))\n        success = cmdexec(cmd.format(script=outfile))\n\n        # sign the installer\n        if signed:\n            self.sign(installerfile)\n\n        log.info('Executing installer...')\n        cmdexec(installerfile)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generateSetupFile(self, outpath='.', egg=False):\n        outpath = os.path.abspath(outpath)\n        outfile = os.path.join(outpath, 'setup.py')\n\n        opts = {\n            'name': self.name(),\n            'distname': self.distributionName(),\n            'version': self.version(),\n            'author': self.author(),\n            'author_email': self.authorEmail(),\n            'keywords': self.keywords(),\n            'license': self.license(),\n            'brief': self.brief(),\n            'description': self.description(),\n            'url': self.companyUrl()\n        }\n\n        wrap_dict = lambda x: map(lambda k: \"r'{0}': [{1}]\".format(k[0],\n                                                                   ',\\n'.join(wrap_str(k[1]))),\n                                  x.items())\n\n        opts['dependencies'] = ',\\n'.join(wrap_str(self.dependencies()))\n        opts['classifiers'] = ',\\n'.join(wrap_str(self.classifiers()))\n\n        if os.path.isfile(self.sourcePath()):\n            basepath = os.path.normpath(os.path.dirname(self.sourcePath()))\n        else:\n            basepath = os.path.normpath(self.sourcePath())\n\n        self.generatePlugins(basepath)\n\n        exts = set()\n        for root, folders, files in os.walk(basepath):\n            for file_ in files:\n                _, ext = os.path.splitext(file_)\n                if ext not in ('.py', '.pyc', '.pyo'):\n                    exts.add('*' + ext)\n\n        exts = list(exts)\n        text = templ.SETUPFILE.format(**opts)\n\n        # generate the file\n        if not os.path.exists(outfile):\n            f = open(outfile, 'w')\n            f.write(text)\n            f.close()\n\n        # generate the manifest file\n        manfile = os.path.join(outpath, 'MANIFEST.in')\n        if not os.path.exists(manfile):\n            f = open(manfile, 'w')\n            f.write('include *.md *.txt *.ini *.cfg *.rst\\n')\n            f.write('recursive-include {0} {1}\\n'.format(self.name(), ' '.join(exts)))\n            f.close()\n\n        # generate the egg\n        if egg:\n            cmd = 'cd {0} && $PYTHON setup.py bdist_egg'.format(outpath)\n            cmd = os.path.expandvars(cmd)\n            cmdexec(cmd)", "response": "Generates the setup. py file for this builder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generateZipFile(self, outpath='.'):\n        fname = self.installName() + '.zip'\n        outfile = os.path.abspath(os.path.join(outpath, fname))\n\n        # clears out the exiting archive\n        if os.path.exists(outfile):\n            try:\n                os.remove(outfile)\n            except OSError:\n                log.warning('Could not remove zipfile: %s', outfile)\n                return False\n\n        # generate the zip file\n        zfile = zipfile.ZipFile(outfile, 'w')\n\n        # zip up all relavent fields from the code base\n        if os.path.isfile(self.sourcePath()):\n            zfile.write(self.sourcePath(), os.path.basename(self.sourcePath()))\n        else:\n            basepath = os.path.abspath(os.path.join(self.sourcePath(), '..'))\n            baselen = len(basepath) + 1\n            for root, folders, filenames in os.walk(basepath):\n                # ignore hidden folders\n                if '.svn' in root or '.git' in root:\n                    continue\n\n                # ignore setuptools build info\n                part = root[baselen:].split(os.path.sep)[0]\n                if part in ('build', 'dist') or part.endswith('.egg-info'):\n                    continue\n\n                # include files\n                for filename in filenames:\n                    ext = os.path.splitext(filename)[1]\n                    if ext in self.ignoreFileTypes():\n                        continue\n\n                    arcroot = root[baselen:].replace('\\\\', '/')\n                    arcname = os.path.join(arcroot, filename)\n                    log.info('Archiving %s...', arcname)\n                    zfile.write(os.path.join(root, filename), arcname)\n\n        zfile.close()\n        return True", "response": "Generates the zip file for this builder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef installName(self):\n        opts = {'name': self.name(), 'version': self.version()}\n        if self.revision():\n            opts['revision'] = '.{0}'.format(self.revision())\n        else:\n            opts['revision'] = ''\n\n        if self._installName:\n            return self._installName.format(**opts)\n        else:\n            return '{name}-{version}{revision}'.format(**opts)", "response": "Returns the name of the installer this builder will generate."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the license file for this builder.", "response": "def licenseFile(self):\n        \"\"\"\n        Returns the license file for this builder.\n        \n        :return     <str>\n        \"\"\"\n        if self._licenseFile:\n            return self._licenseFile\n        elif self._license:\n            f = projex.resources.find('licenses/{0}.txt'.format(self.license()))\n            return f\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads properties from the xml data.", "response": "def loadXml(self, xdata, filepath=''):\n        \"\"\"\n        Loads properties from the xml data.\n        \n        :param      xdata | <xml.etree.ElementTree.Element>\n        \"\"\"\n        # build options\n        opts = {'platform': sys.platform}\n\n        mkpath = lambda x: _mkpath(filepath, x, **opts)\n\n        # lookup environment variables\n        xenv = xdata.find('environment')\n        if xenv is not None:\n            env = {}\n            log.info('loading environment...')\n            for xkey in xenv:\n                text = xkey.text\n                if text:\n                    env[xkey.tag] = os.path.expandvars(text)\n                else:\n                    env[xkey.tag] = ''\n\n            self.setEnvironment(env)\n\n        # lookup general settings\n        xsettings = xdata.find('settings')\n        if xsettings is not None:\n            for xsetting in xsettings:\n                key = xsetting.tag\n                val = xsetting.text\n                attr = '_' + key\n                if hasattr(self, attr):\n                    setattr(self, attr, val)\n\n        # lookup options\n        xoptions = xdata.find('options')\n        if xoptions is not None:\n            options = 0\n            for xopt in xoptions:\n                key = xopt.tag\n                value = xopt.text\n\n                if value.lower() == 'true':\n                    try:\n                        options |= Builder.Options[key]\n                    except KeyError:\n                        continue\n\n            self._options = options\n\n        # lookup path options\n        xpaths = xdata.find('paths')\n        if xpaths is not None:\n            for xpath in xpaths:\n                key = xpath.tag\n                path = xpath.text\n\n                if key.endswith('Paths'):\n                    path = map(mkpath, path.split(';'))\n                else:\n                    path = mkpath(path)\n\n                setattr(self, '_' + key, path)\n\n        # lookup executable options\n        xexe = xdata.find('executable')\n        if xexe is not None:\n            exe_tags = {'runtime': '_runtime',\n                        'exe': '_executableName',\n                        'cli': '_executableCliName',\n                        'product': '_productName'}\n\n            for tag, prop in exe_tags.items():\n                xtag = xexe.find(tag)\n                if xtag is not None:\n                    value = xtag.text\n                    if value.startswith('.'):\n                        value = mkpath(value)\n\n                    setattr(self, prop, value)\n\n            # load exclude options\n            xexcludes = xexe.find('excludes')\n            if xexcludes is not None:\n                excludes = []\n                for xexclude in xexcludes:\n                    excludes.append(xexclude.text)\n                self.setExecutableExcludes(excludes)\n\n            # load build data\n            xexedata = xexe.find('data')\n            if xexedata is not None:\n                data = []\n                for xentry in xexedata:\n                    if xentry.tag == 'tree':\n                        path = xentry.get('path', '')\n                        if path:\n                            path = mkpath(path)\n                        else:\n                            path = self.sourcePath()\n\n                        prefix = xentry.get('prefix', os.path.basename(path))\n                        excludes = xentry.get('excludes', '').split(';')\n\n                        if excludes:\n                            data.append(('tree', (path, prefix, excludes)))\n                    else:\n                        for xitem in xentry:\n                            data.append((xentry.tag, xitem.attrs))\n\n                self.setExecutableData(data)\n\n            # load hidden imports\n            xhiddenimports = xexe.find('hiddenimports')\n            if xhiddenimports is not None:\n                imports = []\n                for ximport in xhiddenimports:\n                    imports.append(ximport.text)\n                self.setHiddenImports(imports)\n\n            # load options\n            xopts = xexe.find('options')\n            if xopts is not None:\n                for xopt in xopts:\n                    if xopt.text.startswith('.'):\n                        value = mkpath(xopt.text)\n                    else:\n                        value = xopt.text\n                    self._executableOptions[xopt.tag] = value\n\n        # lookup installer options\n        xinstall = xdata.find('installer')\n        if xinstall is not None:\n            install_tags = {'name': '_installName'}\n\n            for tag, prop in install_tags.items():\n                xtag = xinstall.find(tag)\n                if xtag is not None:\n                    value = xtag.text\n                    if value.startswith('.'):\n                        value = mkpath(value)\n                    setattr(self, prop, value)\n\n            xopts = xinstall.find('options')\n            if xopts is not None:\n                for xopt in xopts:\n                    if xopt.text.startswith('.'):\n                        value = mkpath(xopt.text)\n                    else:\n                        value = xopt.text\n\n                    self._installerOptions[xopt.tag] = value\n\n            xdirectories = xinstall.find('additional_directories')\n            if xdirectories is not None:\n                for xdir in xdirectories:\n                    self._installDirectories[xdir.get('path')] = xdir.get('source', '')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loadYaml(self, ydata, filepath=''):\n        # build options\n        opts = {'platform': sys.platform}\n\n        mkpath = lambda x: _mkpath(filepath, x, **opts)\n\n        # lookup environment variables\n        env = {}\n        for key, text in ydata.get('environment', {}).items():\n            if text:\n                env[key] = os.path.expandvars(text)\n            else:\n                env[key] = ''\n\n        self.setEnvironment(env)\n\n        # lookup general settings\n        for key, val in ydata.get('settings', {}).items():\n            attr = '_' + key\n            if hasattr(self, attr):\n                setattr(self, attr, val)\n\n        # lookup options\n        yoptions = ydata.get('options')\n        if yoptions is not None:\n            options = 0\n            for key, value in yoptions.items():\n                if value:\n                    try:\n                        options |= Builder.Options[key]\n                    except KeyError:\n                        continue\n\n            self._options = options\n\n        # lookup path options\n        for key, path in ydata.get('paths', {}).items():\n            if key.endswith('Paths'):\n                path = map(mkpath, path.split(';'))\n            else:\n                path = mkpath(path)\n\n            setattr(self, '_' + key, path)\n\n        # lookup executable options\n        yexe = ydata.get('executable')\n        if yexe is not None:\n            exe_tags = {'runtime': '_runtime',\n                        'exe': '_executableName',\n                        'cli': '_executableCliName',\n                        'product': '_productName'}\n\n            for tag, prop in exe_tags.items():\n                if tag in yexe:\n                    value = yexe.pop(tag)\n                    if value.startswith('.'):\n                        value = mkpath(value)\n\n                    setattr(self, prop, value)\n\n            # load exclude options\n            self.setExecutableExcludes(yexe.get('excludes', []))\n\n            # load build data\n            yexedata = yexe.get('data', {})\n            if yexedata:\n                data = []\n                for key, value in yexedata.items():\n                    if key == 'tree':\n                        path = value.get('path', '')\n                        if path:\n                            path = mkpath(path)\n                        else:\n                            path = self.sourcePath()\n\n                        prefix = value.get('prefix', os.path.basename(path))\n                        excludes = value.get('excludes', '').split(';')\n\n                        if excludes:\n                            data.append(('tree', (path, prefix, excludes)))\n\n                    else:\n                        for item in value:\n                            data.append((key, item))\n\n                self.setExecutableData(data)\n\n            # load hidden imports\n            self.setHiddenImports(yexe.get('hiddenimports', []))\n\n            # load options\n            for key, value in yexe.get('options', {}).items():\n                value = nstr(value)\n                if value.startswith('.'):\n                    value = mkpath(value)\n                self._executableOptions[key] = value\n\n        # lookup installer options\n        yinstall = ydata.get('installer')\n        if yinstall is not None:\n            install_tags = {'name': '_installName'}\n\n            for tag, prop in install_tags.items():\n                if tag in yinstall:\n                    value = yinstall.pop(tag, None)\n                    if value.startswith('.'):\n                        value = mkpath(value)\n                    setattr(self, prop, value)\n\n            for key, value in yinstall.get('options', {}).items():\n                if type(value) in (unicode, str) and value.startswith('.'):\n                    value = mkpath(value)\n\n                self._installerOptions[key] = value\n\n            for path in yinstall.get('additional_directories', []):\n                self._installDirectories[path.get('path', '')] = path.get('source', '')", "response": "Loads properties from the yaml file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsigns the given filename with the certificate associated with this builder.", "response": "def sign(self, filename):\n        \"\"\"\n        Signs the filename with the certificate associated with this builder.\n        \n        :param      filename | <str>\n        \n        :return     <bool> | success\n        \"\"\"\n        sign = self.signcmd()\n        certificate = self.certificate()\n        if not sign:\n            log.error('No signcmd defined.')\n            return False\n        elif not certificate and '{cert}' in sign:\n            log.error('No sign certificated defined.')\n            return False\n\n        log.info('Signing {0}...'.format(filename))\n        sign = os.path.expandvars(sign)\n        filename = os.path.expandvars(filename)\n        cert = os.path.expandvars(certificate)\n\n        # let the previous process finish fully, or we might get some file errors\n        time.sleep(2)\n        return cmdexec(sign.format(filename=filename, cert=cert)) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plugin(name, module=''):\n        if module:\n            mod = projex.importfile(module)\n            if mod:\n                return getattr(mod, nstr(name), None)\n\n        return Builder._plugins.get(nstr(name))", "response": "Returns the base Builder instance for the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register(plugin, name=None):\n        if name is None:\n            name = plugin.__name__\n\n        Builder._plugins[nstr(name)] = plugin", "response": "Registers the given plugin as a new one in the system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromXml(cls, xdata, filepath=''):\n        builder = cls()\n        builder.loadXml(xdata, filepath=filepath)\n        return builder", "response": "Generates a new builder from the given xml data and then loads its information."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromYaml(cls, ydata, filepath=''):\n        builder = cls()\n        builder.loadYaml(ydata, filepath=filepath)\n        return builder", "response": "Generates a new builder from the given yaml data and then returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the inputted xml file and generates a builder for it.", "response": "def fromFile(filename):\n        \"\"\"\n        Parses the inputted xml file information and generates a builder\n        for it.\n        \n        :param      filename | <str>\n        \n        :return     <Builder> || None\n        \"\"\"\n        xdata = None\n        ydata = None\n\n        # try parsing an XML file\n        try:\n            xdata = ElementTree.parse(filename).getroot()\n        except StandardError:\n            xdata = None\n\n        if xdata is None:\n            # try parsing a yaml file\n            if yaml:\n                with open(filename, 'r') as f:\n                    text = f.read()\n\n                try:\n                    ydata = yaml.load(text)\n                except StandardError:\n                    return None\n            else:\n                log.warning('Could not process yaml builder!')\n\n        # load a yaml definition\n        if type(ydata) == dict:\n            typ = ydata.get('type')\n            module = ydata.get('module')\n            builder = Builder.plugin(typ, module)\n            if builder:\n                return builder.fromYaml(ydata, os.path.dirname(filename))\n            else:\n                log.warning('Could not find builder: {0}'.format(typ))\n\n        # load an xml definition\n        elif xdata is not None:\n            typ = xdata.get('type')\n            module = xdata.get('module')\n            builder = Builder.plugin(typ, module)\n            if builder:\n                return builder.fromXml(xdata, os.path.dirname(filename))\n            else:\n                log.warning('Could not find builder: {0}'.format(typ))\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromXml(cls, xdata, filepath=''):\n        module = None\n        pkg_data = xdata.find('package')\n        if pkg_data is not None:\n            path = pkg_data.find('path').text\n            name = pkg_data.find('name').text\n\n            if filepath:\n                path = os.path.join(filepath, path)\n\n            path = os.path.abspath(path)\n            sys.path.insert(0, path)\n            sys.modules.pop(name, None)\n\n            try:\n                __import__(name)\n                module = sys.modules[name]\n            except (ImportError, KeyError):\n                return None\n        else:\n            return None\n\n        # generate the builder\n        builder = cls(module)\n        builder.loadXml(xdata, filepath=filepath)\n        return builder", "response": "Generates a new builder from the given xml data and then loads its information."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a new builder from the given xml data and then loads its information.", "response": "def fromYaml(cls, ydata, filepath=''):\n        \"\"\"\n        Generates a new builder from the given xml data and then\n        loads its information.\n        \n        :param      ydata | <xml.etree.ElementTree.Element>\n        \n        :return     <Builder> || None\n        \"\"\"\n        module = None\n        pkg_data = ydata.get('package')\n        if pkg_data is not None:\n            path = pkg_data.get('path', '')\n            name = pkg_data.get('name', '')\n\n            if filepath:\n                path = os.path.join(filepath, path)\n\n            path = os.path.abspath(path)\n            sys.path.insert(0, path)\n            sys.modules.pop(name, None)\n\n            try:\n                __import__(name)\n                module = sys.modules[name]\n            except (ImportError, KeyError):\n                return None\n        else:\n            return None\n\n        # generate the builder\n        builder = cls(module)\n        builder.loadYaml(ydata, filepath=filepath)\n        return builder"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a dictionary to an object.", "response": "def to_object(item):\n        \"\"\"\n        Convert a dictionary to an object (recursive).\n        \"\"\"\n        def convert(item): \n            if isinstance(item, dict):\n                return IterableObject({k: convert(v) for k, v in item.items()})\n            if isinstance(item, list):\n                def yield_convert(item):\n                    for index, value in enumerate(item):\n                        yield convert(value)\n                return list(yield_convert(item))\n            else:\n                return item\n\n        return convert(item)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts an object to a dictionary.", "response": "def to_dict(item):\n        \"\"\"\n        Convert an object to a dictionary (recursive).\n        \"\"\"\n        def convert(item):\n            if isinstance(item, IterableObject):\n                if isinstance(item.source, dict):\n                    return {k: convert(v.source) if hasattr(v, 'source') else convert(v) for k, v in item}\n                else:\n                    return convert(item.source)\n            elif isinstance(item, dict):\n                return {k: convert(v) for k, v in item.items()}\n            elif isinstance(item, list):\n                def yield_convert(item):\n                    for index, value in enumerate(item):\n                        yield convert(value)\n                return list(yield_convert(item))\n            else:\n                return item\n\n        return convert(item)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if an undefined - step snippet is provided for a given step", "response": "def step_undefined_step_snippet_should_exist_for(context, step):\n    \"\"\"\n    Checks if an undefined-step snippet is provided for a step\n    in behave command output (last command).\n\n    EXAMPLE:\n        Then an undefined-step snippet should exist for \"Given an undefined step\"\n    \"\"\"\n    undefined_step_snippet = make_undefined_step_snippet(step)\n    context.execute_steps(u'''\\\nThen the command output should contain:\n    \"\"\"\n    {undefined_step_snippet}\n    \"\"\"\n    '''.format(undefined_step_snippet=text_indent(undefined_step_snippet, 4)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if an undefined - step snippet is provided for a step.", "response": "def step_undefined_step_snippet_should_not_exist_for(context, step):\n    \"\"\"\n    Checks if an undefined-step snippet is provided for a step\n    in behave command output (last command).\n    \"\"\"\n    undefined_step_snippet = make_undefined_step_snippet(step)\n    context.execute_steps(u'''\\\nThen the command output should not contain:\n    \"\"\"\n    {undefined_step_snippet}\n    \"\"\"\n    '''.format(undefined_step_snippet=text_indent(undefined_step_snippet, 4)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step_undefined_step_snippets_should_exist_for_table(context):\n    assert context.table, \"REQUIRES: table\"\n    for row in context.table.rows:\n        step = row[\"Step\"]\n        step_undefined_step_snippet_should_exist_for(context, step)", "response": "Checks if undefined - step snippets are provided for a table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if undefined - step snippets are not provided for a table.", "response": "def step_undefined_step_snippets_should_not_exist_for_table(context):\n    \"\"\"\n    Checks if undefined-step snippets are not provided.\n\n    EXAMPLE:\n        Then undefined-step snippets should not exist for:\n            | Step |\n            | When an known step is used |\n            | Then another known step is used |\n    \"\"\"\n    assert context.table, \"REQUIRES: table\"\n    for row in context.table.rows:\n        step = row[\"Step\"]\n        step_undefined_step_snippet_should_not_exist_for(context, step)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def create_connection(\n    host,\n    port,\n    *,\n    loop=None,\n    secure=True,\n    ssl_context=None,\n    **kwargs,\n):\n    \"\"\"Open an HTTP/2 connection to the specified host/port.\n    \"\"\"\n    loop = loop or asyncio.get_event_loop()\n\n    secure = True if port == 443 else secure\n    connection = HTTP2ClientConnection(host, loop=loop, secure=secure)\n    if not isinstance(ssl_context, SSLContext):\n        ssl_context = default_ssl_context()\n\n    await loop.create_connection(\n        lambda: connection,\n        host=host,\n        port=port,\n        ssl=ssl_context,\n    )\n\n    return connection", "response": "Open an HTTP/2 connection to the specified host/port."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mixin (cls):\n    cls._events = {}\n    cls.bind = Pyevent.bind.__func__\n    cls.unbind = Pyevent.unbind.__func__\n    cls.trigger = Pyevent.trigger.__func__\n    return cls", "response": "A decorator which adds event methods to a class giving it the ability to bind to and trigger events\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bind (self, event, callback):\n        if self._events.has_key(event):\n            self._events[event].append(callback)\n        else:\n            self._events[event] = [callback]", "response": "Bind an event to a call function and ensure that it is called for the available entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunbind the callback from the event and ensure that it is never called", "response": "def unbind (self, event, callback):\n        \"\"\"\n        Unbind the callback from the event and ensure that it is never called\n        :param event: the event that should be unbound\n        :type event: str\n        :param callback: the function that should be unbound\n        :rtype callback: function\n        \"\"\"\n        if self._events.has_key(event) and len(self._events[event]) > 0:\n            for _callback in self._events[event]:\n                if _callback == callback:\n                    self._events[event].remove(callback)\n                if len(self._events[event]) == 0:\n                    del self._events[event]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trigger (self, event, *args, **kwargs):\n        if self._events.has_key(event):\n            for _callback in self._events[event]:\n                try:\n                    _callback(args, kwargs)\n                except TypeError:\n                    _callback()", "response": "Trigger the callbacks associated with the event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the path of the wordlist file for the given language.", "response": "def get_wordlist(lang, wl_dir, po_path):\n        #print(\"Looking for Wordlist in:\\nlang {}\\nwl_dir {}\\npo_path {}\".format(lang, wl_dir, po_path))\n        po_path = os.path.abspath(po_path)\n\n        \"\"\"\n        If wl_dir is given, there may be a file called \"<lang>.txt\". If this is\n        the case, this should be the wordlist we are looking for.\n        \"\"\"\n        if wl_dir is not None:\n            wl_path = os.path.join(wl_dir, lang + '.txt')\n            if os.path.isfile(wl_path):\n                return wl_path\n\n        \"\"\"\n        If wl_dir is not given, the wordlist should live in a file named\n        \"wordlist.txt\" either in the locales_dir for the default language or in\n        the same directory as the .po-files\n        \"\"\"\n        if po_path.endswith(\"po\"):\n            # translated language\n            po_dir = os.path.dirname(po_path)\n            for f in os.scandir(po_dir):\n                if f.name == \"wordlist.txt\":\n                    #print(\"found wordlist in\", f.path)\n                    return f.path\n            #print(\"Checked po-dir, None Found\")\n\n            \"\"\"\n            If no file was found so far, the po-files seem to lie in\n            <lang>/LC_MESSAGES, and the wordlist should be in the directory\n            above.\n            \"\"\"\n            if os.path.basename(po_dir) == \"LC_MESSAGES\":\n                for f in os.scandir(os.path.join(po_dir, \"..\")):\n                    if f.name == \"wordlist.txt\":\n                        #print(\"found wordlist in\", f.path)\n                        return f.path\n            #print(\"Checked LC_MESSAGES-dir. none found\")\n        #print(\"Checked lang-specific files\")\n\n        if os.path.isdir(po_path):\n            # default language\n            for f in os.scandir(po_path):\n                if f.name == \"wordlist.txt\":\n                    #print(\"found wordlist in\", f.path)\n                    return f.path\n        #print(\"If this shows up, no wordlist was found\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a function that reads the configuration files and returns a dictionary of the configuration files and sample files.", "response": "def _read_options(paths,fname_def=None):\r\n    \"\"\"Builds a configuration reader function\"\"\"\r\n    def reader_func(fname=fname_def, sect=None, sett=None, default=None):\r\n        \"\"\"Reads the configuration for trump\"\"\"\r\n\r\n        cur_dir = os.path.dirname(os.path.realpath(__file__))\r\n        config_dir = os.path.join(cur_dir, *paths)\r\n\r\n        config_files = [(f[:-4], f)\r\n                        for f in os.listdir(config_dir) if f[-4:] == \".cfg\"]\r\n        sample_files = [(f[:-11], f)\r\n                        for f in os.listdir(config_dir) if f[-11:] == \".cfg_sample\"]\r\n\r\n        if fname:\r\n            config_files = [f for f in config_files if f[0] == fname]\r\n            sample_files = [f for f in sample_files if f[0] == fname]\r\n\r\n\r\n        config_files = dict(config_files)\r\n        sample_files = dict(sample_files)\r\n\r\n        cfg_files = sample_files\r\n        for fn, f in config_files.iteritems():\r\n            cfg_files[fn] = f\r\n\r\n        sample_files_exposed = []\r\n\r\n        confg = {}\r\n\r\n        for src, fil in cfg_files.iteritems():\r\n            confg[src] = {}\r\n            cfpr = ConfigParser.ConfigParser()\r\n            cfpr.read(os.path.join(config_dir, fil))\r\n            for sec in cfpr.sections():\r\n                confg[src][sec] = dict(cfpr.items(sec))\r\n\r\n            if \".cfg_sample\" in fil:\r\n                sample_files_exposed.append(fil)\r\n\r\n\r\n        if len(sample_files_exposed) > 0:\r\n            msg = \", \".join(sample_files_exposed)\r\n            body = \"{} sample configuration files have been exposed. \" \\\r\n                  \"Rename *.cfg_sample to *.cfg, and populate the \" \\\r\n                  \"correct settings in the config and settings \" \\\r\n                  \"directories to avoid this warning.\"\r\n            msg = body.format(msg)\r\n            warnings.warn(msg)\r\n\r\n        keys = []\r\n\r\n        if fname:\r\n            keys.append(fname)\r\n            if sect:\r\n                keys.append(sect)\r\n                if sett:\r\n                    keys.append(sett)\r\n        try:\r\n            return get_from_nested(keys, confg)\r\n        except KeyError:\r\n            if default is not None:\r\n                return default\r\n            else:\r\n                raise\r\n\r\n    return reader_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the mass difference for alternative possible label states of a given peptide.", "response": "def returnLabelStateMassDifferences(peptide, labelDescriptor, labelState=None,\n                                    sequence=None):\n    \"\"\"Calculates the mass difference for alternative possible label states of a\n    given peptide. See also :class:`LabelDescriptor`, :func:`returnLabelState()`\n\n\n    :param peptide: Peptide to calculate alternative label states\n    :param labelDescriptor: :class:`LabelDescriptor` describes the label setup\n        of an experiment\n    :param labelState: label state of the peptide, if None it is calculated by\n        :func:`returnLabelState()`\n    :param sequence: unmodified amino acid sequence of the \"peptide\", if None\n        it is generated by :func:`maspy.peptidemethods.removeModifications()`\n\n    :returns: {alternativeLabelSate: massDifference, ...} or {} if the peptide\n        label state is -1.\n\n    .. note:: The massDifference plus the peptide mass is the expected mass of\n        an alternatively labeled peptide\n    \"\"\"\n    if labelState is None:\n        labelState = returnLabelState(peptide, labelDescriptor)\n    if sequence is None:\n        sequence = maspy.peptidemethods.removeModifications(peptide)\n\n    if labelState < 0:\n        # special case for mixed label... #\n        return dict()\n\n    # define type and number of labels of the peptide\n    labelModNumbers = dict()\n    _positions = expectedLabelPosition(peptide,\n                                       labelDescriptor.labels[labelState],\n                                       sequence=sequence)\n    for labelStateModList in viewvalues(_positions):\n        for labelMod in labelStateModList:\n            labelModNumbers.setdefault(labelMod, int())\n            labelModNumbers[labelMod] += 1\n\n    # calculate the combined labels mass of the peptide\n    labelMass = int()\n    for labelMod, modCounts in viewitems(labelModNumbers):\n        labelMass += maspy.constants.aaModMass[labelMod] * modCounts\n\n    # calculate mass differences to all other possible label states\n    labelStateMassDifferences = dict()\n    for possibleLabelState in viewkeys(labelDescriptor.labels):\n        if possibleLabelState == labelState:\n            continue\n\n        labelModNumbers = dict()\n        _positions = expectedLabelPosition(peptide,\n                                           labelDescriptor.labels[possibleLabelState],\n                                           sequence=sequence)\n        for labelStateModList in viewvalues(_positions):\n            for labelMod in labelStateModList:\n                labelModNumbers.setdefault(labelMod, int())\n                labelModNumbers[labelMod] += 1\n\n        possibleLabelMass = int()\n        for labelMod, modCounts in viewitems(labelModNumbers):\n            possibleLabelMass += maspy.constants.aaModMass[labelMod] * modCounts\n\n        possibleLabelMassDifference = possibleLabelMass - labelMass\n        labelStateMassDifferences[possibleLabelState] = possibleLabelMassDifference\n    return labelStateMassDifferences"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef returnLabelState(peptide, labelDescriptor, labelSymbols=None,\n                     labelAminoacids=None):\n    \"\"\"Calculates the label state of a given peptide for the label setup\n    described in labelDescriptor\n\n    :param peptide: peptide which label state should be calcualted\n    :param labelDescriptor: :class:`LabelDescriptor`, describes the label setup\n        of an experiment.\n    :param labelSymbols: modifications that show a label, as returned by\n        :func:`modSymbolsFromLabelInfo`.\n    :param labelAminoacids: amino acids that can bear a label, as returned by\n        :func:`modAminoacidsFromLabelInfo`.\n\n    :returns: integer that shows the label state:\n        >=0: predicted label state of the peptide\n         -1: peptide sequence can't bear any labelState modifications\n         -2: peptide modifications don't fit to any predicted labelState\n         -3: peptide modifications fit to a predicted labelState, but not all\n             predicted labelStates are distinguishable\n    \"\"\"\n    if labelSymbols is None:\n        labelSymbols = modSymbolsFromLabelInfo(labelDescriptor)\n    if labelAminoacids is None:\n        labelAminoacids = modAminoacidsFromLabelInfo(labelDescriptor)\n\n    sequence = maspy.peptidemethods.removeModifications(peptide)\n    modPositions = maspy.peptidemethods.returnModPositions(peptide,\n                                                           indexStart=0,\n                                                           removeModString=False)\n\n    labelState = None\n    #No amino acids in sequence which can bear a label modification\n    #Note: at the moment presence of excluding modifications are ignored\n    _validator = lambda seq, aa: (True if seq.find(aa) == -1 else False)\n    if all([_validator(sequence, aa) for aa in labelAminoacids]):\n        #No terminal label modifications specified by labelDescriptor\n        if 'nTerm' not in labelAminoacids and 'cTerm' not in labelAminoacids:\n            labelState = -1\n\n    # Check if the peptide mofidifcations fit to any predicted label state\n    if labelState is None:\n        peptideLabelPositions = dict()\n        for labelSymbol in labelSymbols:\n            if labelSymbol in viewkeys(modPositions):\n                for sequencePosition in modPositions[labelSymbol]:\n                    peptideLabelPositions.setdefault(sequencePosition, list())\n                    peptideLabelPositions[sequencePosition].append(labelSymbol)\n        for sequencePosition in list(viewkeys(peptideLabelPositions)):\n            peptideLabelPositions[sequencePosition] = \\\n                sorted(peptideLabelPositions[sequencePosition])\n\n        predictedLabelStates = dict()\n        for predictedLabelState, labelStateInfo in viewitems(labelDescriptor.labels):\n            expectedLabelMods = expectedLabelPosition(peptide, labelStateInfo,\n                                                      sequence=sequence,\n                                                      modPositions=modPositions)\n            predictedLabelStates[predictedLabelState] = expectedLabelMods\n            if peptideLabelPositions == expectedLabelMods:\n                #If another expectedLabel state has already been matched, then\n                #there is an ambiguity between label states ...\n                labelState = predictedLabelState\n\n    if labelState is None:\n        # Peptide mofidifcations don't fit to any predicted label state\n        labelState = -2\n    elif labelState != -1:\n        # Check if all predicted label states are distinguishable\n        _comb = set(itertools.combinations(range(len(predictedLabelStates)), 2))\n        for state1, state2 in _comb:\n            if predictedLabelStates[state1] == predictedLabelStates[state2]:\n                labelState = -3\n                break\n\n    return labelState", "response": "Calculates the label state of a given peptide for a given label setup."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set of all modiciation symbols which were used in the labelDescriptor .", "response": "def modSymbolsFromLabelInfo(labelDescriptor):\n    \"\"\"Returns a set of all modiciation symbols which were used in the\n    labelDescriptor\n\n    :param labelDescriptor: :class:`LabelDescriptor` describes the label setup\n        of an experiment\n\n    :returns: #TODO: docstring\n    \"\"\"\n    modSymbols = set()\n    for labelStateEntry in viewvalues(labelDescriptor.labels):\n        for labelPositionEntry in viewvalues(labelStateEntry['aminoAcidLabels']):\n            for modSymbol in aux.toList(labelPositionEntry):\n                if modSymbol != '':\n                    modSymbols.add(modSymbol)\n    return modSymbols"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set of all amino acids and termini which can bear a label.", "response": "def modAminoacidsFromLabelInfo(labelDescriptor):\n    \"\"\"Returns a set of all amino acids and termini which can bear a label, as\n    described in \"labelDescriptor\".\n\n    :param labelDescriptor: :class:`LabelDescriptor` describes the label setup\n        of an experiment\n\n    :returns: #TODO: docstring\n    \"\"\"\n    modAminoacids = set()\n    for labelStateEntry in viewvalues(labelDescriptor.labels):\n        for labelPositionEntry in viewkeys(labelStateEntry['aminoAcidLabels']):\n            for modAminoacid in aux.toList(labelPositionEntry):\n                if modAminoacid != '':\n                    modAminoacids.add(modAminoacid)\n    return modAminoacids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expectedLabelPosition(peptide, labelStateInfo, sequence=None,\n                          modPositions=None):\n    \"\"\"Returns a modification description of a certain label state of a peptide.\n\n    :param peptide: Peptide sequence used to calculat the expected label state\n        modifications\n    :param labelStateInfo: An entry of :attr:`LabelDescriptor.labels` that\n        describes a label state\n    :param sequence: unmodified amino acid sequence of :var:`peptide`, if None\n        it is generated by :func:`maspy.peptidemethods.removeModifications()`\n    :param modPositions: dictionary describing the modification state of\n        \"peptide\", if None it is generated by\n        :func:`maspy.peptidemethods.returnModPositions()`\n\n    :returns: {sequence position: sorted list of expected label modifications\n                  on that position, ...\n               }\n    \"\"\"\n    if modPositions is None:\n        modPositions = maspy.peptidemethods.returnModPositions(peptide,\n                                                               indexStart=0\n                                                               )\n    if sequence is None:\n        sequence = maspy.peptidemethods.removeModifications(peptide)\n\n    currLabelMods = dict()\n    for labelPosition, labelSymbols in viewitems(labelStateInfo['aminoAcidLabels']):\n        labelSymbols = aux.toList(labelSymbols)\n        if labelSymbols == ['']:\n            pass\n        elif labelPosition == 'nTerm':\n            currLabelMods.setdefault(0, list())\n            currLabelMods[0].extend(labelSymbols)\n        else:\n            for sequencePosition in aux.findAllSubstrings(sequence,\n                                                          labelPosition):\n                currLabelMods.setdefault(sequencePosition, list())\n                currLabelMods[sequencePosition].extend(labelSymbols)\n\n    if labelStateInfo['excludingModifications'] is not None:\n        for excludingMod, excludedLabelSymbol in viewitems(labelStateInfo['excludingModifications']):\n            if excludingMod not in modPositions:\n                continue\n            for excludingModPos in modPositions[excludingMod]:\n                if excludingModPos not in currLabelMods:\n                    continue\n                if excludedLabelSymbol not in currLabelMods[excludingModPos]:\n                    continue\n                if len(currLabelMods[excludingModPos]) == 1:\n                    del(currLabelMods[excludingModPos])\n                else:\n                    excludedModIndex = currLabelMods[excludingModPos].index(excludedLabelSymbol)\n                    currLabelMods[excludingModPos].pop(excludedModIndex)\n\n    for sequencePosition in list(viewkeys(currLabelMods)):\n        currLabelMods[sequencePosition] = sorted(currLabelMods[sequencePosition])\n    return currLabelMods", "response": "Returns a modification description of a certain label state of a peptide."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addLabel(self, aminoAcidLabels, excludingModifications=None):\n        if excludingModifications is not None:\n            self.excludingModifictions = True\n\n        labelEntry = {'aminoAcidLabels': aminoAcidLabels,\n                      'excludingModifications': excludingModifications\n                      }\n        self.labels[self._labelCounter] = labelEntry\n        self._labelCounter += 1", "response": "Adds a new label to the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deploy_schema_to_db(self, mode='safe', files_deployment=None, vcs_ref=None, vcs_link=None,\n                            issue_ref=None, issue_link=None, compare_table_scripts_as_int=False,\n                            config_path=None, config_dict=None, config_object=None, source_code_path=None,\n                            auto_commit=False):\n        \"\"\"\n        Deploys schema\n        :param files_deployment: if specific script to be deployed, only find them\n        :param mode:\n        :param vcs_ref:\n        :param vcs_link:\n        :param issue_ref:\n        :param issue_link:\n        :param compare_table_scripts_as_int:\n        :param config_path:\n        :param config_dict:\n        :param config_object:\n        :param source_code_path:\n        :param auto_commit:\n        :return: dictionary of the following format:\n            {\n                code: 0 if all fine, otherwise something else,\n                message: message on the output\n                function_scripts_requested: list of function files requested for deployment\n                function_scripts_deployed: list of function files deployed\n                type_scripts_requested: list of type files requested for deployment\n                type_scripts_deployed: list of type files deployed\n                view_scripts_requested: list of view files requested for deployment\n                view_scripts_deployed: list of view files deployed\n                trigger_scripts_requested: list of trigger files requested for deployment\n                trigger_scripts_deployed: list of trigger files deployed\n                table_scripts_requested: list of table files requested for deployment\n                table_scripts_deployed: list of table files deployed\n                requested_files_count: count of requested files to deploy\n                deployed_files_count: count of deployed files\n            }\n        :rtype: dict\n        \"\"\"\n\n        return_value = {}\n        if files_deployment:\n            return_value['function_scripts_requested'] = files_deployment\n            return_value['type_scripts_requested'] = []\n            return_value['view_scripts_requested'] = []\n            return_value['trigger_scripts_requested'] = []\n            return_value['table_scripts_requested'] = []\n\n        if auto_commit:\n            if mode == 'safe' and files_deployment:\n                self._logger.debug(\"Auto commit mode is on. Be careful.\")\n            else:\n                self._logger.error(\"Auto commit deployment can only be done with file \"\n                                   \"deployments and in safe mode for security reasons\")\n                raise ValueError(\"Auto commit deployment can only be done with file \"\n                                 \"deployments and in safe mode for security reasons\")\n\n        # set source code path if exists\n        self._source_code_path = self._source_code_path or source_code_path\n\n        # set configuration if either of config_path, config_dict, config_object are set.\n        # Otherwise use configuration from class initialisation\n        if config_object:\n            self._config = config_object\n        elif config_path or config_dict:\n            self._config = pgpm.lib.utils.config.SchemaConfiguration(config_path, config_dict, self._source_code_path)\n\n        # Check if in git repo\n        if not vcs_ref:\n            if pgpm.lib.utils.vcs.is_git_directory(self._source_code_path):\n                vcs_ref = pgpm.lib.utils.vcs.get_git_revision_hash(self._source_code_path)\n                self._logger.debug('commit reference to be deployed is {0}'.format(vcs_ref))\n            else:\n                self._logger.debug('Folder is not a known vcs repository')\n\n        self._logger.debug('Configuration of package {0} of version {1} loaded successfully.'\n                           .format(self._config.name, self._config.version.raw))  # TODO: change to to_string once discussed\n        # .format(self._config.name, self._config.version.to_string()))\n\n        # Get scripts\n        type_scripts_dict = self._get_scripts(self._config.types_path, files_deployment,\n                                              \"types\", self._source_code_path)\n        if not files_deployment:\n            return_value['type_scripts_requested'] = [key for key in type_scripts_dict]\n\n        function_scripts_dict = self._get_scripts(self._config.functions_path, files_deployment,\n                                                  \"functions\", self._source_code_path)\n        if not files_deployment:\n            return_value['function_scripts_requested'] = [key for key in function_scripts_dict]\n\n        view_scripts_dict = self._get_scripts(self._config.views_path, files_deployment,\n                                              \"views\", self._source_code_path)\n        if not files_deployment:\n            return_value['view_scripts_requested'] = [key for key in view_scripts_dict]\n\n        trigger_scripts_dict = self._get_scripts(self._config.triggers_path, files_deployment,\n                                                 \"triggers\", self._source_code_path)\n        if not files_deployment:\n            return_value['trigger_scripts_requested'] = [key for key in trigger_scripts_dict]\n\n        # before with table scripts only file name was an identifier. Now whole relative path the file\n        # (relative to config.json)\n        # table_scripts_dict_denormalised = self._get_scripts(self._config.tables_path, files_deployment,\n        #                                                     \"tables\", self._source_code_path)\n        # table_scripts_dict = {os.path.split(k)[1]: v for k, v in table_scripts_dict_denormalised.items()}\n        table_scripts_dict = self._get_scripts(self._config.tables_path, files_deployment,\n                                               \"tables\", self._source_code_path)\n        if not files_deployment:\n            return_value['table_scripts_requested'] = [key for key in table_scripts_dict]\n\n        if self._conn.closed:\n            self._conn = psycopg2.connect(self._connection_string, connection_factory=pgpm.lib.utils.db.MegaConnection)\n        cur = self._conn.cursor()\n\n        # be cautious, dangerous thing\n        if auto_commit:\n            self._conn.autocommit = True\n\n        # Check if DB is pgpm enabled\n        if not pgpm.lib.utils.db.SqlScriptsHelper.schema_exists(cur, self._pgpm_schema_name):\n            self._logger.error('Can\\'t deploy schemas to DB where pgpm was not installed. '\n                               'First install pgpm by running pgpm install')\n            self._conn.close()\n            sys.exit(1)\n\n        # check installed version of _pgpm schema.\n        pgpm_v_db_tuple = pgpm.lib.utils.db.SqlScriptsHelper.get_pgpm_db_version(cur, self._pgpm_schema_name)\n        pgpm_v_db = distutils.version.StrictVersion(\".\".join(pgpm_v_db_tuple))\n        pgpm_v_script = distutils.version.StrictVersion(pgpm.lib.version.__version__)\n        if pgpm_v_script > pgpm_v_db:\n            self._logger.error('{0} schema version is outdated. Please run pgpm install --upgrade first.'\n                               .format(self._pgpm_schema_name))\n            self._conn.close()\n            sys.exit(1)\n        elif pgpm_v_script < pgpm_v_db:\n            self._logger.error('Deployment script\\'s version is lower than the version of {0} schema '\n                               'installed in DB. Update pgpm script first.'.format(self._pgpm_schema_name))\n            self._conn.close()\n            sys.exit(1)\n\n        # Resolve dependencies\n        list_of_deps_ids = []\n        if self._config.dependencies:\n            _is_deps_resolved, list_of_deps_ids, _list_of_unresolved_deps = \\\n                self._resolve_dependencies(cur, self._config.dependencies)\n            if not _is_deps_resolved:\n                self._logger.error('There are unresolved dependencies. Deploy the following package(s) and try again:')\n                for unresolved_pkg in _list_of_unresolved_deps:\n                    self._logger.error('{0}'.format(unresolved_pkg))\n                self._conn.close()\n                sys.exit(1)\n\n        # Prepare and execute preamble\n        _deployment_script_preamble = pkgutil.get_data('pgpm', 'lib/db_scripts/deploy_prepare_config.sql')\n        self._logger.debug('Executing a preamble to deployment statement')\n        cur.execute(_deployment_script_preamble)\n\n        # Get schema name from project configuration\n        schema_name = ''\n        if self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.SCHEMA_SCOPE:\n            if self._config.subclass == 'versioned':\n                schema_name = '{0}_{1}'.format(self._config.name, self._config.version.raw)\n\n                self._logger.debug('Schema {0} will be updated'.format(schema_name))\n            elif self._config.subclass == 'basic':\n                schema_name = '{0}'.format(self._config.name)\n                if not files_deployment:\n                    self._logger.debug('Schema {0} will be created/replaced'.format(schema_name))\n                else:\n                    self._logger.debug('Schema {0} will be updated'.format(schema_name))\n\n        # Create schema or update it if exists (if not in production mode) and set search path\n        if files_deployment:  # if specific scripts to be deployed\n            if self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.SCHEMA_SCOPE:\n                if not pgpm.lib.utils.db.SqlScriptsHelper.schema_exists(cur, schema_name):\n                    self._logger.error('Can\\'t deploy scripts to schema {0}. Schema doesn\\'t exist in database'\n                                       .format(schema_name))\n                    self._conn.close()\n                    sys.exit(1)\n                else:\n                    pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, schema_name)\n                    self._logger.debug('Search_path was changed to schema {0}'.format(schema_name))\n        else:\n            if self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.SCHEMA_SCOPE:\n                if not pgpm.lib.utils.db.SqlScriptsHelper.schema_exists(cur, schema_name):\n                    pgpm.lib.utils.db.SqlScriptsHelper.create_db_schema(cur, schema_name)\n                elif mode == 'safe':\n                    self._logger.error('Schema already exists. It won\\'t be overriden in safe mode. '\n                                       'Rerun your script with \"-m moderate\", \"-m overwrite\" or \"-m unsafe\" flags')\n                    self._conn.close()\n                    sys.exit(1)\n                elif mode == 'moderate':\n                    old_schema_exists = True\n                    old_schema_rev = 0\n                    while old_schema_exists:\n                        old_schema_exists = pgpm.lib.utils.db.SqlScriptsHelper.schema_exists(\n                            cur, schema_name + '_' + str(old_schema_rev))\n                        if old_schema_exists:\n                            old_schema_rev += 1\n                    old_schema_name = schema_name + '_' + str(old_schema_rev)\n                    self._logger.debug('Schema already exists. It will be renamed to {0} in moderate mode. Renaming...'\n                                       .format(old_schema_name))\n                    _rename_schema_script = \"ALTER SCHEMA {0} RENAME TO {1};\\n\".format(schema_name, old_schema_name)\n                    cur.execute(_rename_schema_script)\n                    # Add metadata to pgpm schema\n                    pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                    cur.callproc('_set_revision_package'.format(self._pgpm_schema_name),\n                                 [self._config.name,\n                                  self._config.subclass,\n                                  old_schema_rev,\n                                  self._config.version.major,\n                                  self._config.version.minor,\n                                  self._config.version.patch,\n                                  self._config.version.pre])\n                    self._logger.debug('Schema {0} was renamed to {1}. Meta info was added to {2} schema'\n                                       .format(schema_name, old_schema_name, self._pgpm_schema_name))\n                    pgpm.lib.utils.db.SqlScriptsHelper.create_db_schema(cur, schema_name)\n                elif mode == 'unsafe':\n                    _drop_schema_script = \"DROP SCHEMA {0} CASCADE;\\n\".format(schema_name)\n                    cur.execute(_drop_schema_script)\n                    self._logger.debug('Dropping old schema {0}'.format(schema_name))\n                    pgpm.lib.utils.db.SqlScriptsHelper.create_db_schema(cur, schema_name)\n\n        if self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.SCHEMA_SCOPE:\n            pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, schema_name)\n\n        # Reordering and executing types\n        return_value['type_scripts_deployed'] = []\n        if len(type_scripts_dict) > 0:\n            types_script = '\\n'.join([''.join(value) for key, value in type_scripts_dict.items()])\n            type_drop_scripts, type_ordered_scripts, type_unordered_scripts = self._reorder_types(types_script)\n            if type_drop_scripts:\n                for statement in type_drop_scripts:\n                    if statement:\n                        cur.execute(statement)\n            if type_ordered_scripts:\n                for statement in type_ordered_scripts:\n                    if statement:\n                        cur.execute(statement)\n            if type_unordered_scripts:\n                for statement in type_unordered_scripts:\n                    if statement:\n                        cur.execute(statement)\n            self._logger.debug('Types loaded to schema {0}'.format(schema_name))\n            return_value['type_scripts_deployed'] = [key for key in type_scripts_dict]\n        else:\n            self._logger.debug('No type scripts to deploy')\n\n        # Executing Table DDL scripts\n        executed_table_scripts = []\n        return_value['table_scripts_deployed'] = []\n        if len(table_scripts_dict) > 0:\n            if compare_table_scripts_as_int:\n                sorted_table_scripts_dict = collections.OrderedDict(sorted(table_scripts_dict.items(),\n                                                                           key=lambda t: int(t[0].rsplit('.', 1)[0])))\n            else:\n                sorted_table_scripts_dict = collections.OrderedDict(sorted(table_scripts_dict.items(),\n                                                                           key=lambda t: t[0].rsplit('.', 1)[0]))\n\n            self._logger.debug('Running Table DDL scripts')\n            for key, value in sorted_table_scripts_dict.items():\n                pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                cur.callproc('_is_table_ddl_executed'.format(self._pgpm_schema_name), [\n                    key,\n                    self._config.name,\n                    self._config.subclass,\n                    self._config.version.major,\n                    self._config.version.minor,\n                    self._config.version.patch,\n                    self._config.version.pre\n                ])\n                is_table_executed = cur.fetchone()[0]\n                if self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.SCHEMA_SCOPE:\n                    pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, schema_name)\n                elif self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.DATABASE_SCOPE:\n                    cur.execute(\"SET search_path TO DEFAULT ;\")\n                if (not is_table_executed) or (mode == 'unsafe'):\n                    # if auto commit mode than every statement is called separately.\n                    # this is done this way as auto commit is normally used when non transaction statements are called\n                    # then this is needed to avoid \"cannot be executed from a function or multi-command string\" errors\n                    if auto_commit:\n                        for statement in sqlparse.split(value):\n                            if statement:\n                                cur.execute(statement)\n                    else:\n                        cur.execute(value)\n                    self._logger.debug(value)\n                    self._logger.debug('{0} executed for schema {1}'.format(key, schema_name))\n                    executed_table_scripts.append(key)\n                    return_value['table_scripts_deployed'].append(key)\n                else:\n                    self._logger.debug('{0} is not executed for schema {1} as it has already been executed before. '\n                                       .format(key, schema_name))\n        else:\n            self._logger.debug('No Table DDL scripts to execute')\n\n        # Executing functions\n        return_value['function_scripts_deployed'] = []\n        if len(function_scripts_dict) > 0:\n            self._logger.debug('Running functions definitions scripts')\n            for key, value in function_scripts_dict.items():\n                # if auto commit mode than every statement is called separately.\n                # this is done this way as auto commit is normally used when non transaction statements are called\n                # then this is needed to avoid \"cannot be executed from a function or multi-command string\" errors\n                if auto_commit:\n                    for statement in sqlparse.split(value):\n                        if statement:\n                            cur.execute(statement)\n                else:\n                    cur.execute(value)\n                return_value['function_scripts_deployed'].append(key)\n            self._logger.debug('Functions loaded to schema {0}'.format(schema_name))\n        else:\n            self._logger.debug('No function scripts to deploy')\n\n        # Executing views\n        return_value['view_scripts_deployed'] = []\n        if len(view_scripts_dict) > 0:\n            self._logger.debug('Running views definitions scripts')\n            for key, value in view_scripts_dict.items():\n                # if auto commit mode than every statement is called separately.\n                # this is done this way as auto commit is normally used when non transaction statements are called\n                # then this is needed to avoid \"cannot be executed from a function or multi-command string\" errors\n                if auto_commit:\n                    for statement in sqlparse.split(value):\n                        if statement:\n                            cur.execute(statement)\n                else:\n                    cur.execute(value)\n                return_value['view_scripts_deployed'].append(key)\n            self._logger.debug('Views loaded to schema {0}'.format(schema_name))\n        else:\n            self._logger.debug('No view scripts to deploy')\n\n        # Executing triggers\n        return_value['trigger_scripts_deployed'] = []\n        if len(trigger_scripts_dict) > 0:\n            self._logger.debug('Running trigger definitions scripts')\n            for key, value in trigger_scripts_dict.items():\n                # if auto commit mode than every statement is called separately.\n                # this is done this way as auto commit is normally used when non transaction statements are called\n                # then this is needed to avoid \"cannot be executed from a function or multi-command string\" errors\n                if auto_commit:\n                    for statement in sqlparse.split(value):\n                        if statement:\n                            cur.execute(statement)\n                else:\n                    cur.execute(value)\n                return_value['trigger_scripts_deployed'].append(key)\n            self._logger.debug('Triggers loaded to schema {0}'.format(schema_name))\n        else:\n            self._logger.debug('No trigger scripts to deploy')\n\n        # alter schema privileges if needed\n        if (not files_deployment) and mode != 'overwrite' \\\n                and self._config.scope == pgpm.lib.utils.config.SchemaConfiguration.SCHEMA_SCOPE:\n            pgpm.lib.utils.db.SqlScriptsHelper.revoke_all(cur, schema_name, 'public')\n            if self._config.usage_roles:\n                pgpm.lib.utils.db.SqlScriptsHelper.grant_usage_privileges(\n                    cur, schema_name, ', '.join(self._config.usage_roles))\n                self._logger.debug('User(s) {0} was (were) granted usage permissions on schema {1}.'\n                                   .format(\", \".join(self._config.usage_roles), schema_name))\n            if self._config.owner_role:\n                pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                cur.callproc('_alter_schema_owner', [schema_name, self._config.owner_role])\n                self._logger.debug('Ownership of schema {0} and all its objects was changed and granted to user {1}.'\n                                   .format(schema_name, self._config.owner_role))\n\n        # Add metadata to pgpm schema\n        pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n        cur.callproc('_upsert_package_info'.format(self._pgpm_schema_name),\n                     [self._config.name,\n                      self._config.subclass,\n                      self._config.version.major,\n                      self._config.version.minor,\n                      self._config.version.patch,\n                      self._config.version.pre,\n                      self._config.version.metadata,\n                      self._config.description,\n                      self._config.license,\n                      list_of_deps_ids,\n                      vcs_ref,\n                      vcs_link,\n                      issue_ref,\n                      issue_link])\n        self._logger.debug('Meta info about deployment was added to schema {0}'\n                           .format(self._pgpm_schema_name))\n        pgpm_package_id = cur.fetchone()[0]\n        if len(table_scripts_dict) > 0:\n            for key in executed_table_scripts:\n                cur.callproc('_log_table_evolution'.format(self._pgpm_schema_name), [key, pgpm_package_id])\n\n        # Commit transaction\n        self._conn.commit()\n\n        self._conn.close()\n\n        deployed_files_count = len(return_value['function_scripts_deployed']) + \\\n                               len(return_value['type_scripts_deployed']) + \\\n                               len(return_value['view_scripts_deployed']) + \\\n                               len(return_value['trigger_scripts_deployed']) + \\\n                               len(return_value['table_scripts_deployed'])\n\n        requested_files_count = len(return_value['function_scripts_requested']) + \\\n                                len(return_value['type_scripts_requested']) + \\\n                                len(return_value['view_scripts_requested']) + \\\n                                len(return_value['trigger_scripts_requested']) + \\\n                                len(return_value['table_scripts_requested'])\n\n        return_value['deployed_files_count'] = deployed_files_count\n        return_value['requested_files_count'] = requested_files_count\n        if deployed_files_count == requested_files_count:\n            return_value['code'] = self.DEPLOYMENT_OUTPUT_CODE_OK\n            return_value['message'] = 'OK'\n        else:\n            return_value['code'] = self.DEPLOYMENT_OUTPUT_CODE_NOT_ALL_DEPLOYED\n            return_value['message'] = 'Not all requested files were deployed'\n        return return_value", "response": "This method will deploy a specific schema to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_scripts(self, scripts_path_rel, files_deployment, script_type, project_path):\n\n        scripts_dict = {}\n        if scripts_path_rel:\n\n            self._logger.debug('Getting scripts with {0} definitions'.format(script_type))\n            scripts_dict = pgpm.lib.utils.misc.collect_scripts_from_sources(scripts_path_rel, files_deployment,\n                                                                            project_path, False, self._logger)\n            if len(scripts_dict) == 0:\n                self._logger.debug('No {0} definitions were found in {1} folder'.format(script_type, scripts_path_rel))\n        else:\n            self._logger.debug('No {0} folder was specified'.format(script_type))\n\n        return scripts_dict", "response": "Gets scripts from specified folders"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _resolve_dependencies(self, cur, dependencies):\n        list_of_deps_ids = []\n        _list_of_deps_unresolved = []\n        _is_deps_resolved = True\n        for k, v in dependencies.items():\n            pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n            cur.execute(\"SELECT _find_schema('{0}', '{1}')\"\n                        .format(k, v))\n            pgpm_v_ext = tuple(cur.fetchone()[0][1:-1].split(','))\n            try:\n                list_of_deps_ids.append(int(pgpm_v_ext[0]))\n            except:\n                pass\n            if not pgpm_v_ext[0]:\n                _is_deps_resolved = False\n                _list_of_deps_unresolved.append(\"{0}: {1}\".format(k, v))\n\n        return _is_deps_resolved, list_of_deps_ids, _list_of_deps_unresolved", "response": "Function checks if dependencies are installed in DB"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking type scripts and reorders them to avoid Type does not exist exception", "response": "def _reorder_types(self, types_script):\n        \"\"\"\n        Takes type scripts and reorders them to avoid Type doesn't exist exception\n        \"\"\"\n        self._logger.debug('Running types definitions scripts')\n        self._logger.debug('Reordering types definitions scripts to avoid \"type does not exist\" exceptions')\n        _type_statements = sqlparse.split(types_script)\n        # TODO: move up to classes\n        _type_statements_dict = {}  # dictionary that store statements with type and order.\n        type_unordered_scripts = []  # scripts to execute without order\n        type_drop_scripts = []  # drop scripts to execute first\n        for _type_statement in _type_statements:\n            _type_statement_parsed = sqlparse.parse(_type_statement)\n            if len(_type_statement_parsed) > 0:  # can be empty parsed object so need to check\n                # we need only type declarations to be ordered\n                if _type_statement_parsed[0].get_type() == 'CREATE':\n                    _type_body_r = r'\\bcreate\\s+\\b(?:type|domain)\\s+\\b(\\w+\\.\\w+|\\w+)\\b'\n                    _type_name = re.compile(_type_body_r, flags=re.IGNORECASE).findall(_type_statement)[0]\n                    _type_statements_dict[str(_type_name)] = \\\n                        {'script': _type_statement, 'deps': []}\n                elif _type_statement_parsed[0].get_type() == 'DROP':\n                    type_drop_scripts.append(_type_statement)\n                else:\n                    type_unordered_scripts.append(_type_statement)\n        # now let's add dependant types to dictionary with types\n        # _type_statements_list = []  # list of statements to be ordered\n        for _type_key in _type_statements_dict.keys():\n            for _type_key_sub, _type_value in _type_statements_dict.items():\n                if _type_key != _type_key_sub:\n                    if pgpm.lib.utils.misc.find_whole_word(_type_key)(_type_value['script']):\n                        _type_value['deps'].append(_type_key)\n        # now let's add order to type scripts and put them ordered to list\n        _deps_unresolved = True\n        _type_script_order = 0\n        _type_names = []\n        type_ordered_scripts = []  # ordered list with scripts to execute\n        while _deps_unresolved:\n            for k, v in _type_statements_dict.items():\n                if not v['deps']:\n                    _type_names.append(k)\n                    v['order'] = _type_script_order\n                    _type_script_order += 1\n                    if not v['script'] in type_ordered_scripts:\n                        type_ordered_scripts.append(v['script'])\n                else:\n                    _dep_exists = True\n                    for _dep in v['deps']:\n                        if _dep not in _type_names:\n                            _dep_exists = False\n                    if _dep_exists:\n                        _type_names.append(k)\n                        v['order'] = _type_script_order\n                        _type_script_order += 1\n                        if not v['script'] in type_ordered_scripts:\n                            type_ordered_scripts.append(v['script'])\n                    else:\n                        v['order'] = -1\n            _deps_unresolved = False\n            for k, v in _type_statements_dict.items():\n                if v['order'] == -1:\n                    _deps_unresolved = True\n        return type_drop_scripts, type_ordered_scripts, type_unordered_scripts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_table_links(self):\n        html = urlopen(self.model_url).read()\n        doc = lh.fromstring(html)\n        href_list = [area.attrib['href'] for area in doc.cssselect('map area')]\n        tables = self._inception_table_links(href_list)\n        return tables", "response": "This function will find all the available table names for that dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _inception_table_links(self, href_list):\n        tables = set()\n        for link in href_list:\n            if not link.startswith('http://'):\n                link = self.agency_url + link\n            html = urlopen(link).read()\n            doc = lh.fromstring(html)\n            area = doc.cssselect('map area')\n            if area:\n                # Then this is a model containing models.\n                tables.update((a.attrib['href'] for a in area))\n            else:\n                # The link is a table without additional models.\n                tables.update(link)\n        return tables", "response": "Returns a set of inception table links."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the available definition URLs for the columns in a table.", "response": "def find_definition_urls(self, set_of_links):\n        \"\"\"Find the available definition URLs for the columns in a table.\"\"\"\n        definition_dict = {}\n        re_link_name = re.compile('.*p_table_name=(\\w+)&p_topic.*')\n        for link in set_of_links:\n            if link.startswith('http://'):\n                table_dict = {}\n                html = urlopen(link).read()\n                doc = lh.fromstring(html)\n                unordered_list = doc.cssselect('#main ul')[-1]\n                for li in unordered_list.iterchildren():\n                    a = li.find('a')\n                    table_dict.update({a.text: a.attrib['href']})\n                link_name = re_link_name.sub(r'\\1', link).upper()\n                definition_dict.update({link_name: table_dict})\n        return definition_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an agency text file of definitions.", "response": "def create_agency(self):\n        \"\"\"Create an agency text file of definitions.\"\"\"\n        agency = self.agency\n        links = self.find_table_links()\n        definition_dict = self.find_definition_urls(links)\n        with open(agency + '.txt', 'w') as f:\n            f.write(str(definition_dict))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nloop through an agency to grab the definitions for its tables.", "response": "def loop_through_agency(self):\n        \"\"\"Loop through an agency to grab the definitions for its tables.\"\"\"\n        agency = self.agency\n        with open(agency + '.txt') as f:\n            data = eval(f.read())\n        for table in data:\n            for column in data[table]:\n                value_link = data[table][column]\n                data[table][column] = self.grab_definition(value_link)\n        data = json.dumps(data)\n        with open(agency + '_values.json', 'w') as f:\n            f.write(str(data))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef grab_definition(self, url):\n        re_description = re.compile('Description:(.+?\\\\n)')\n        re_table_name = re.compile(\"(\\w+ Table.+)\")\n        if url.startswith('//'):\n            url = 'http:' + url\n        elif url.startswith('/'):\n            url = 'http://www.epa.gov' + url\n        try:\n            html = urlopen(url).read()\n            doc = lh.fromstring(html)\n            main = doc.cssselect('#main')[0]\n            text = main.text_content()\n            definition = re_description.search(text).group(1).strip()\n        except (AttributeError, IndexError, TypeError, HTTPError):\n            print url\n        else:\n            value = re_table_name.sub('', definition)\n            return value\n        return url", "response": "Grab the column definition of a table from the EPA using a combination of regular expressions and lxml."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new Arc to the automaton.", "response": "def add_arc(self, src, dst, char):\n        \"\"\"Adds a new Arc\n        Args:\n            src (int): The source state identifier\n            dst (int): The destination state identifier\n            char (str): The character for the transition\n        Returns:\n            None\n        \"\"\"\n        if src not in self.automaton.states():\n            self.add_state()\n        arc = fst.Arc(self.isyms[char], self.osyms[char],  fst.Weight.One(self.automaton.weight_type()), dst)\n        self.automaton.add_arc(src, arc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fixminimized(self, alphabet):\n\n        insymbols = fst.SymbolTable()\n        outsymbols = fst.SymbolTable()\n        num = 1\n        for char in self.alphabet:\n            self.isyms.__setitem__(char, num)\n            self.osyms.__setitem__(char, num)\n            insymbols.add_symbol(char, num)\n            outsymbols.add_symbol(char, num)\n            num = num + 1\n        self.automaton.set_input_symbols(insymbols)\n        self.automaton.set_output_symbols(outsymbols)\n        endstate = self.add_state()\n        for state in self.states:\n            for char in alphabet:\n                found = 0\n                for arc in state.arcs:\n                    if self.isyms.find(arc.ilabel) == char:\n                        found = 1\n                        break\n                if found == 0:\n                    self.add_arc(state.stateid, endstate, char)\n        self[endstate].final = False\n\n        for char in alphabet:\n            self.add_arc(endstate, endstate, char)", "response": "Fixes the internal state of the internal state by removing unused arcs and all sink states."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the complement of the DFA.", "response": "def complement(self, alphabet):\n        \"\"\"\n        Returns the complement of DFA\n        Args:\n            alphabet (list): The input alphabet\n        Returns:\n            None\n        \"\"\"\n        self._addsink(alphabet)\n        for state in self.automaton.states():\n            if self.automaton.final(state) == fst.Weight.One(self.automaton.weight_type()):\n                self.automaton.set_final(state, fst.Weight.Zero(self.automaton.weight_type()))\n            else:\n                self.automaton.set_final(state, fst.Weight.One(self.automaton.weight_type()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a sink state from an acceptor by copying the input alphabet.", "response": "def init_from_acceptor_bycopying(self, acceptor):\n        \"\"\"\n        Adds a sink state\n        Args:\n            alphabet (list): The input alphabet\n        Returns:\n            None\n        \"\"\"\n        for state in acceptor.states:\n            for arc in state.arcs:\n                self.add_arc(state.stateid, arc.nextstate, acceptor.isyms.find(arc.ilabel))\n            if state.final:\n                print state.stateid,' is final'\n                self[state.stateid].final = True;"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs an unminimized DFA recognizing the intersection of the languages of two given DFAs.", "response": "def intersect(self, other):\n        \"\"\"Constructs an unminimized DFA recognizing\n        the intersection of the languages of two given DFAs.\n        Args:\n            other (DFA): The other DFA that will be used\n                         for the intersect operation\n        Returns:\n        Returns:\n            DFA: The resulting DFA\n        \"\"\"\n        self.automaton = fst.intersect(self.automaton, other.automaton)\n        return  self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_optparser(self):\n        p = Cmdln.get_optparser(self)\n        p.add_option(\n            \"-M\",\n            \"--maildir\",\n            action=\"store\",\n            dest=\"maildir\"\n            )\n        p.add_option(\n            \"-V\",\n            \"--verbose\",\n            action=\"store_true\",\n            dest=\"verbose\"\n            )\n        return p", "response": "Override to allow specification of the maildir"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the sub folders of the maildir", "response": "def do_lsfolders(self, subcmd, opts):\n        \"\"\"${cmd_name}: list the sub folders of the maildir.\n\n        ${cmd_usage}\n        \"\"\"\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        client.lsfolders(stream=self.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all messages in the specified folder in JSON format", "response": "def do_lisp(self, subcmd, opts, folder=\"\"):\n        \"\"\"${cmd_name}: list messages in the specified folder in JSON format\n\n        ${cmd_usage}\n        \"\"\"\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        client.lisp(\n            foldername=folder,\n            stream=self.stdout, \n            reverse=getattr(opts, \"reverse\", False),\n            since=float(getattr(opts, \"since\", -1))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_make(self, subcmd, opts, path):\n        # Do we need to make this \".path\" if it's relative?\n        d = path if path[0] == \"/\" else joinpath(self.maildir, \".\" + path)\n        os.makedirs(joinpath(d, \"cur\"))\n        os.makedirs(joinpath(d, \"new\"))\n        os.makedirs(joinpath(d, \"tmp\"))\n        os.makedirs(joinpath(d, \"store\"))", "response": "Make a maildir at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_rm(self, subcmd, opts, message):\n        maildir = self.maildir\n        client = MdClient(maildir, filesystem=self.filesystem)\n        try:\n            client.remove(message)\n        except KeyError:\n            return 1", "response": "Remove the specified message from the specified maildir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_mv(self, subcmd, opts, message, folder):\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        client.move(message, folder)", "response": "move the specified message to the specified folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the best text part of the specified message", "response": "def do_text(self, subcmd, opts, message):\n        \"\"\"${cmd_name}: get the best text part of the specified message\n\n        ${cmd_usage}\n        \"\"\"\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        client.gettext(message, self.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the complete raw message", "response": "def do_raw(self, subcmd, opts, message):\n        \"\"\"${cmd_name}: dump the complete raw message\n\n        ${cmd_usage}\n        \"\"\"\n        client = MdClient(self.maildir)\n        client.getraw(message, self.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_rawpart(self, subcmd, opts, message):\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        partid = getattr(opts, \"part\", None)\n        if not partid:\n            client.getrawpart(message, self.stdout)\n        else:\n            client.getrawpartid(message, partid, self.stdout)", "response": "Dump a part from the specified message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_struct(self, subcmd, opts, message):\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        as_json = getattr(opts, \"json\", False)\n        client.getstruct(message, as_json=as_json, stream=self.stdout)", "response": "Get the structure of the specified message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_file(self, subcmd, opts, message):\n        client = MdClient(self.maildir, filesystem=self.filesystem)\n        client.get(message, self.stdout)", "response": "Download the whole file of the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_newfilter(self, subcmd, opts):\n        from mdlib.filterprocessor import RULES\n        print(RULES, file=self.stdout)", "response": "make a new filterfile and spit it to stdout"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_storecheck(self, subcmd, opts):\n        from os.path import basename\n        from os.path import dirname\n        from os.path import exists as existspath\n        from os.path import islink\n        from os.path import join as joinpath\n        maildir = self.maildir\n        cur = joinpath(maildir, \"cur\")\n        new = joinpath(maildir, \"new\")\n        store = joinpath(maildir, \"store\")\n        \n        found_list = []\n        # Loop through the folders checking that everything maps back to the store\n        for scandir in [cur, new]:\n            for f in os.listdir(scandir):\n                filename = joinpath(scandir, f)\n                try:\n                    assert islink(filename)\n                    store_location = os.readlink(filename)\n                    assert existspath(store_location) and dirname(store_location) == store\n                except AssertionError:\n                    print(\"%s was not a link into the store\" % (\n                            \"/\".join([\n                                    filename.split(\"/\")[-2],\n                                    filename.split(\"/\")[-1]\n                                    ])\n                            ), \n                          file=self.stdout)\n                else:\n                    found_list.append(basename(store_location))\n\n        for storefile in os.listdir(store):\n            if storefile not in found_list:\n                print(\n                    \"%s found in store but not folders\" % joinpath(\"store\", storefile), \n                    file=self.stdout\n                    )", "response": "Checks the store for files that may not be in the maildirs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a form using the tape - form layout template.", "response": "def form(context, form, **kwargs):\n    \"\"\"\n    The `form` template tag will render a tape-form enabled form using the template\n    provided by `get_layout_template` method of the form using the context generated\n    by `get_layout_context` method of the form.\n\n    Usage::\n\n        {% load tapeforms %}\n        {% form my_form %}\n\n    You can override the used layout template using the keyword argument `using`::\n\n        {% load tapeforms %}\n        {% form my_form using='other_form_layout_template.html' %}\n\n    :param form: The Django form to render.\n    :return: Rendered form (errors + hidden fields + fields) as HTML.\n    \"\"\"\n\n    if not isinstance(form, (forms.BaseForm, TapeformFieldset)):\n        raise template.TemplateSyntaxError(\n            'Provided form should be a `Form` instance, actual type: {0}'.format(\n                form.__class__.__name__))\n\n    return render_to_string(\n        form.get_layout_template(kwargs.get('using', None)),\n        form.get_layout_context(),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef formfield(context, bound_field, **kwargs):\n\n    if not isinstance(bound_field, forms.BoundField):\n        raise template.TemplateSyntaxError(\n            'Provided field should be a `BoundField` instance, actual type: {0}'.format(\n                bound_field.__class__.__name__))\n\n    return render_to_string(\n        bound_field.form.get_field_template(bound_field, kwargs.get('using', None)),\n        bound_field.form.get_field_context(bound_field),\n    )", "response": "The formfield template tag will render a form field of a tape - form enabled form together with the context generated by get_field_context method of the form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wrap_as_node(self, func):\n        'wrap a function as a node'\n        name = self.get_name(func)\n\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n            'wrapped version of func'\n            message = self.get_message_from_call(*args, **kwargs)\n            self.logger.info('calling \"%s\" with %r', name, message)\n            result = func(message)\n\n            # functions can return multiple values (\"emit\" multiple times)\n            # by yielding instead of returning. Handle this case by making\n            # a list of the results and processing them all after the\n            # generator successfully exits. If we were to process them as\n            # they came out of the generator, we might get a partially\n            # processed input sent down the graph. This may be possible in\n            # the future via a flag.\n            if isinstance(result, GeneratorType):\n                results = [\n                    self.wrap_result(name, item)\n                    for item in result\n                    if item is not NoResult\n                ]\n                self.logger.debug(\n                    '%s returned generator yielding %d items', func, len(results)\n                )\n\n                [self.route(name, item) for item in results]\n                return tuple(results)\n\n            # the case of a direct return is simpler. wrap, route, and\n            # return the value.\n            else:\n                if result is NoResult:\n                    return result\n\n                result = self.wrap_result(name, result)\n                self.logger.debug(\n                    '%s returned single value %s', func, result\n                )\n                self.route(name, result)\n                return result\n\n        return wrapped", "response": "wrap a function as a node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport the modules specified in init", "response": "def resolve_node_modules(self):\n        'import the modules specified in init'\n        if not self.resolved_node_modules:\n            try:\n                self.resolved_node_modules = [\n                    importlib.import_module(mod, self.node_package)\n                    for mod in self.node_modules\n                ]\n            except ImportError:\n                self.resolved_node_modules = []\n                raise\n\n        return self.resolved_node_modules"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_message_from_call(self, *args, **kwargs):\n        '''\\\n        Get message object from a call.\n\n        :raises: :py:exc:`TypeError` (if the format is not what we expect)\n\n        This is where arguments to nodes are turned into Messages. Arguments\n        are parsed in the following order:\n\n         - A single positional argument (a :py:class:`dict`)\n         - No positional arguments and a number of keyword arguments\n        '''\n        if len(args) == 1 and isinstance(args[0], dict):\n            # then it's a message\n            self.logger.debug('called with arg dictionary')\n            result = args[0]\n        elif len(args) == 0 and kwargs != {}:\n            # then it's a set of kwargs\n            self.logger.debug('called with kwargs')\n            result = kwargs\n        else:\n            # it's neither, and we don't handle that\n            self.logger.error(\n                'get_message_from_call could not handle \"%r\", \"%r\"',\n                args, kwargs\n            )\n            raise TypeError('Pass either keyword arguments or a dictionary argument')\n\n        return self.message_class(result)", "response": "Returns a message object from a call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a named function in the graph.", "response": "def register(self, name, func, fields, subscribe_to, entry_point, ignore):\n        '''\n        Register a named function in the graph\n\n        :param name: name to register\n        :type name: :py:class:`str`\n        :param func: function to remember and call\n        :type func: callable\n\n        ``fields``, ``subscribe_to`` and ``entry_point`` are the same as in\n        :py:meth:`Router.node`.\n        '''\n        self.fields[name] = fields\n        self.functions[name] = func\n\n        self.register_route(subscribe_to, name)\n\n        if ignore:\n            self.register_ignore(ignore, name)\n\n        if entry_point:\n            self.add_entry_point(name)\n\n        self.logger.info('registered %s', name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_entry_point(self, destination):\n        '''\\\n        Add an entry point\n\n        :param destination: node to route to initially\n        :type destination: str\n        '''\n        self.routes.setdefault('__entry_point', set()).add(destination)\n        return self.routes['__entry_point']", "response": "Adds an entry point to the set of entries that this node is routing to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding routes to the routing dictionary that will be used to generate the routing dictionary for the given set of origins.", "response": "def register_route(self, origins, destination):\n        '''\n        Add routes to the routing dictionary\n\n        :param origins: a number of origins to register\n        :type origins: :py:class:`str` or iterable of :py:class:`str` or None\n        :param destination: where the origins should point to\n        :type destination: :py:class:`str`\n\n        Routing dictionary takes the following form::\n\n            {'node_a': set(['node_b', 'node_c']),\n             'node_b': set(['node_d'])}\n\n        '''\n        self.names.add(destination)\n        self.logger.debug('added \"%s\" to names', destination)\n\n        origins = origins or []  # remove None\n        if not isinstance(origins, list):\n            origins = [origins]\n\n        self.regexes.setdefault(destination, [re.compile(origin) for origin in origins])\n\n        self.regenerate_routes()\n        return self.regexes[destination]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_ignore(self, origins, destination):\n        '''\n        Add routes to the ignore dictionary\n\n        :param origins: a number of origins to register\n        :type origins: :py:class:`str` or iterable of :py:class:`str`\n        :param destination: where the origins should point to\n        :type destination: :py:class:`str`\n\n        Ignore dictionary takes the following form::\n\n            {'node_a': set(['node_b', 'node_c']),\n             'node_b': set(['node_d'])}\n\n        '''\n        if not isinstance(origins, list):\n            origins = [origins]\n\n        self.ignore_regexes.setdefault(destination, [re.compile(origin) for origin in origins])\n        self.regenerate_routes()\n\n        return self.ignore_regexes[destination]", "response": "Register routes to the ignore dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef regenerate_routes(self):\n        'regenerate the routes after a new route is added'\n        for destination, origins in self.regexes.items():\n            # we want only the names that match the destination regexes.\n            resolved = [\n                name for name in self.names\n                if name is not destination\n                and any(origin.search(name) for origin in origins)\n            ]\n\n            ignores = self.ignore_regexes.get(destination, [])\n            for origin in resolved:\n                destinations = self.routes.setdefault(origin, set())\n\n                if any(ignore.search(origin) for ignore in ignores):\n                    self.logger.info('ignoring route \"%s\" -> \"%s\"', origin, destination)\n                    try:\n                        destinations.remove(destination)\n                        self.logger.debug('removed \"%s\" -> \"%s\"', origin, destination)\n                    except KeyError:\n                        pass\n\n                    continue\n\n                if destination not in destinations:\n                    self.logger.info('added route \"%s\" -> \"%s\"', origin, destination)\n\n                destinations.add(destination)", "response": "regenerate the routes after a new route is added"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nroutes a message to all subscribers of the origin node.", "response": "def route(self, origin, message):\n        '''\\\n        Using the routing dictionary, dispatch a message to all subscribers\n\n        :param origin: name of the origin node\n        :type origin: :py:class:`str`\n        :param message: message to dispatch\n        :type message: :py:class:`emit.message.Message` or subclass\n        '''\n        # side-effect: we have to know all the routes before we can route. But\n        # we can't resolve them while the object is initializing, so we have to\n        # do it just in time to route.\n        self.resolve_node_modules()\n\n        if not self.routing_enabled:\n            return\n\n        subs = self.routes.get(origin, set())\n\n        for destination in subs:\n            self.logger.debug('routing \"%s\" -> \"%s\"', origin, destination)\n            self.dispatch(origin, destination, message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch a message to a named function", "response": "def dispatch(self, origin, destination, message):\n        '''\\\n        dispatch a message to a named function\n\n        :param destination: destination to dispatch to\n        :type destination: :py:class:`str`\n        :param message: message to dispatch\n        :type message: :py:class:`emit.message.Message` or subclass\n        '''\n        func = self.functions[destination]\n        self.logger.debug('calling %r directly', func)\n        return func(_origin=origin, **message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wrap_result(self, name, result):\n        '''\n        Wrap a result from a function with it's stated fields\n\n        :param name: fields to look up\n        :type name: :py:class:`str`\n        :param result: return value from function. Will be converted to tuple.\n        :type result: anything\n\n        :raises: :py:exc:`ValueError` if name has no associated fields\n\n        :returns: :py:class:`dict`\n        '''\n        if not isinstance(result, tuple):\n            result = tuple([result])\n\n        try:\n            return dict(zip(self.fields[name], result))\n        except KeyError:\n            msg = '\"%s\" has no associated fields'\n            self.logger.exception(msg, name)\n            raise ValueError(msg % name)", "response": "Wrap a result from a function with it s stated fields\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_name(self, func):\n        '''\n        Get the name to reference a function by\n\n        :param func: function to get the name of\n        :type func: callable\n        '''\n        if hasattr(func, 'name'):\n            return func.name\n\n        return '%s.%s' % (\n            func.__module__,\n            func.__name__\n        )", "response": "Get the name to reference a function by\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert text values into boolean values.", "response": "def coerce(self, value):\r\n        \"\"\"Convert text values into boolean values.\r\n\r\n        True values are (case insensitive): 'yes', 'true', '1'. False values\r\n        are (case insensitive): 'no', 'false', '0'.\r\n\r\n        Args:\r\n            value (str or bool): The value to coerce.\r\n\r\n        Raises:\r\n            TypeError: If the value is not a bool or string.\r\n            ValueError: If the value is not bool or an acceptable value.\r\n\r\n        Returns:\r\n            bool: The True/False value represented.\r\n        \"\"\"\r\n        if isinstance(value, bool):\r\n\r\n            return value\r\n\r\n        if not hasattr(value, 'lower'):\r\n\r\n            raise TypeError('Value is not bool or string.')\r\n\r\n        if value.lower() in ('yes', 'true', '1'):\r\n\r\n            return True\r\n\r\n        if value.lower() in ('no', 'false', '0'):\r\n\r\n            return False\r\n\r\n        raise ValueError('Could not coerce {0} to a bool.'.format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest function for PDA - DFA Diff Operation", "response": "def main():\n    \"\"\"\n    Testing function for PDA - DFA Diff Operation\n    \"\"\"\n    if len(argv) < 2:\n        print 'Usage: '\n        print '         Get A String              %s CFG_fileA FST_fileB' % argv[0]\n        return\n\n    alphabet = createalphabet()\n\n    cfgtopda = CfgPDA(alphabet)\n    print '* Parsing Grammar:',\n    mma = cfgtopda.yyparse(argv[1])\n    print 'OK'\n\n    flex_a = Flexparser(alphabet)\n    print '* Parsing Regex:',\n    mmb = flex_a.yyparse(argv[2])\n    print mmb\n    print 'OK'\n    print '* Minimize Automaton:',\n    mmb.minimize()\n    print 'OK'\n    print mmb\n    print '* Diff:',\n    ops = PdaDiff(mma, mmb, alphabet)\n    mmc = ops.diff()\n    print 'OK'\n    print '* Get String:',\n    print ops.get_string()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _delta(self, graph, cur_state, char):\n        for arc in cur_state.arcs:\n            if graph.isyms.find(arc.ilabel) == char:\n                return graph[arc.nextstate]\n        return None", "response": "Returns the delta state of the current state and the input character."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef diff(self):\n        self.mmb.complement(self.alphabet)\n        self.mmb.minimize()\n        print 'start intersection'\n        self.mmc = self._intesect()\n        print 'end intersection'\n        return self.mmc", "response": "The Difference between a PDA and a DFA"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string from the Diff resutl.", "response": "def get_string(self):\n        \"\"\"\n        Returns a string from the Diff resutl.\n        Depending on the method, either the string will\n        be generated directly from the PDA using the state\n        removal method, or the PDA will be first translated to\n        a CFG and then a string will be generated from the CFG\n        Args:\n             None\n        Returns:\n            A string from the Diff\n        \"\"\"\n        return_string = None\n        if not self.mmc:\n            return \"\"\n        method = 'PDASTRING'\n        if method == 'PDASTRING':\n            stringgen = PdaString()\n            print '* Reduce PDA using DFA BFS (remove unreachable states):'\n            newpda = self.mmc.s\n            handle = IntersectionHandling()\n            newpda = handle.get(newpda, self.mmc.accepted)\n            reduce_b = ReducePDA()\n            newpda = reduce_b.get(newpda)\n            #simply = SimplifyStateIDs()\n            #newpda, biggestid, newaccepted = simply.get(\n            #    newpda, self.mmc.accepted)\n            print \"- Total PDA states after reduction are \" + repr(len(newpda))\n            return_string = stringgen.init(newpda, self.mmc.accepted)\n            if return_string is not None:\n                return_string = return_string[0]\n        elif method == 'PDACFGSTRING':\n\n            optimized = 1\n            dt1 = datetime.datetime.fromtimestamp(time.time())\n            print '* Initiating PDA simplification'\n            print ' - Total PDA states are ' + repr(len(self.mmc.s))\n            handle = IntersectionHandling()\n            newpda = handle.get(self.mmc.s, self.mmc.accepted)\n            newpda = self.mmc.s\n            simply = SimplifyStateIDs()\n            newpda, biggestid, newaccepted = simply.get(\n                newpda, self.mmc.accepted)\n            print ' - Total PDA states after id clearence are ' + repr(len(newpda))\n            replace = ReadReplace(newpda, biggestid)\n            newpda = replace.replace_read()\n            print ' - Total PDA states after read elimination are ' + repr(len(newpda))\n            maxstate = replace.nextstate() - 1\n            print '* Reduce PDA using DFA BFS (remove unreachable states):'\n            reduce_b = ReducePDA()\n            newpda = reduce_b.get(newpda)\n            print \"- Total PDA states after reduction are \" + repr(len(newpda))\n\n            dt2 = datetime.datetime.fromtimestamp(time.time())\n            rdelta = dateutil.relativedelta.relativedelta(dt2, dt1)\n            print \"* PDA was simplyfied in %d days, %d hours, %d minutes and %d seconds\" % (\n                rdelta.days, rdelta.hours, rdelta.minutes, rdelta.seconds)\n            dt1 = datetime.datetime.fromtimestamp(time.time())\n            print '* Initiating CNF from PDA generation'\n            cnfgenerator = PdaCnf(newpda, newaccepted)\n            dt2 = datetime.datetime.fromtimestamp(time.time())\n            rdelta = dateutil.relativedelta.relativedelta(dt2, dt1)\n            print \"* CNF was generated in %d days, %d hours, %d minutes and %d seconds\" % (\n                rdelta.days, rdelta.hours, rdelta.minutes, rdelta.seconds)\n            dt1 = datetime.datetime.fromtimestamp(time.time())\n            print '* Initiating string from CFG generation'\n            grammar = cnfgenerator.get_rules(optimized)\n            print ' - Total grammar rules are ' + repr(len(grammar))\n            gen = CFGGenerator(CNFGenerator(grammar),\n                               optimized=optimized,\n                               splitstring=0,\n                               maxstate=maxstate)\n            return_string = gen.generate()\n            dt2 = datetime.datetime.fromtimestamp(time.time())\n            rdelta = dateutil.relativedelta.relativedelta(dt2, dt1)\n            print \"* A string was generated in %d days, %d hours, %d minutes and %d seconds\" % (\n                rdelta.days, rdelta.hours, rdelta.minutes, rdelta.seconds)\n\n            print return_string\n        else:\n            return_string = None\n        return return_string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery hub for list of devices and creates new device objects", "response": "def refresh_devices(self):\n        '''Queries hub for list of devices, and creates new device objects'''\n        try:\n            response = self.api.get(\"/api/v2/devices\", {'properties':'all'})\n            for device_data in response['DeviceList']:\n                self.devices.append(Device(device_data, self))\n        except APIError as e:\n            print(\"API error: \")\n            for key,value in e.data.iteritems:\n                print(str(key) + \": \" + str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries hub and refresh all details of a device and but NOT status includes grouplist not present in refresh_all_devices", "response": "def refresh_details(self):\n        '''Query hub and refresh all details of a device,\n        but NOT status, includes grouplist not present in\n        refresh_all_devices'''\n        try:\n            return self.api_iface._api_get(\"/api/v2/devices/\" + str(self.device_id))\n        except APIError as e:\n            print(\"API error: \")\n            for key,value in e.data.iteritems:\n                print(str(key) + \": \" + str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_command(self, command):\n        '''Send a command to a device'''\n        data = {\"command\": command, \"device_id\": self.device_id}\n        try:\n            response = self.api_iface._api_post(\"/api/v2/commands\", data)\n            return Command(response, self)\n        except APIError as e:\n            print(\"API error: \")\n            for key,value in e.data.iteritems:\n                print(str(key) + \": \" + str(value))", "response": "Send a command to a device"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_details(self,data):\n        '''Intakes dict of details, and sets necessary properties\n        in device'''\n        # DeviceName, IconID, HouseID, DeviceID always present\n        self.device_id = data['DeviceID']\n        self.device_name = data['DeviceName']\n        self.properties = data", "response": "Intakes dict of details and sets necessary properties\n        in device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_details(self,data):\n        '''Intakes dict of details, and sets necessary properties\n        in command'''\n        for api_name in self._properties:\n            if api_name in data:\n                setattr(self, \"_\" + api_name, data[api_name])\n            else:\n                # Only set to blank if not initialized\n                try:\n                    getattr(self, \"_\" + api_name)\n                except AttributeError:\n                    setattr(self, \"_\" + api_name, '')", "response": "Intakes dict of details and sets necessary properties\nCOOKIENAME in command"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the hub for the status of this command", "response": "def query_status(self):\n        '''Query the hub for the status of this command'''\n        try:\n            data = self.api_iface._api_get(self.link)\n            self._update_details(data)\n        except APIError as e:\n            print(\"API error: \")\n            for key,value in e.data.iteritems:\n                print(str(key) + \": \" + str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a TrackList object for this entry.", "response": "def tracks(self):\n        \"\"\"\n        Tracks list context\n\n        :return: Tracks list context\n        \"\"\"\n        if self._tracks is None:\n            self._tracks = TrackList(self.version, self.id)\n\n        return self._tracks"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of Albums by their unique IDs.", "response": "def list(self, ids, market=values.UNSET):\n        \"\"\"\n        List albums\n\n        :param List[str] ids: List of albums ids\n        :param str market: Market locale\n        :return: Page of Albums\n        :rtype: AlbumPage\n        \"\"\"\n        params = values.of({\n            'ids': ','.join(ids),\n            'market': market\n        })\n        response = self.version.request('GET', '/albums', params=params)\n        return AlbumPage(self.version, response.json(), 'albums')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string representation of the version of the attribute.", "response": "def to_string(self):\n        \"\"\"\n        stringifies version\n        :return: string of version\n        \"\"\"\n        if self.major == -1:\n            major_str = 'x'\n        else:\n            major_str = self.major\n        if self.minor == -1:\n            minor_str = 'x'\n        else:\n            minor_str = self.minor\n        if self.patch == -1:\n            patch_str = 'x'\n        else:\n            patch_str = self.patch\n        return '{0}_{1}_{2}'.format(major_str, minor_str, patch_str)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(self, binding_id, instance):\n        binding = AtlasServiceBinding.Binding(binding_id, instance)\n        self.backend.storage.populate(binding)\n        return binding", "response": "find an instance in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the new binding with the given parameters.", "response": "def bind(self, binding, parameters):\n        \"\"\" Create the binding\n        \n        Args:\n            binding (AtlasServiceBinding.Binding): Existing or New binding\n            parameters (dict): Parameters for the binding\n            \n        Returns:\n            Binding: Status\n            \n        Raises:\n            ErrBindingAlreadyExists: If binding exists but with different parameters\n        \"\"\"\n        \n        if not binding.isProvisioned():\n            # Update binding parameters\n            binding.parameters = parameters\n            \n            #  Credentials\n            creds = self.backend.config.generate_binding_credentials(binding)\n            \n            # Binding\n            p = self.backend.config.generate_binding_permissions(\n                binding,\n                DatabaseUsersPermissionsSpecs(creds[\"username\"],creds[\"password\"])\n                )\n            \n            try:\n                self.backend.atlas.DatabaseUsers.create_a_database_user(p)\n            except ErrAtlasConflict:\n                # The user already exists. This is not an issue because this is possible that we\n                # created it in a previous call that failed later on the broker.\n                pass\n            \n            self.backend.storage.store(binding)\n            \n            # Bind done\n            return Binding(BindState.SUCCESSFUL_BOUND,\n                           credentials = creds)\n        \n        elif binding.parameters == parameters:\n            if self.backend.config.isGenerateBindingCredentialsPredictible():\n                # Identical and credentials generation is predictible so we can return credentials again.\n                creds = self.backend.config.generate_binding_credentials(binding)\n                \n                return Binding(BindState.IDENTICAL_ALREADY_EXISTS,\n                               credentials = creds)\n            \n            # Identical but credentials generation is NOT predictible. So we are breaking the spec to avoid\n            # wrong data injection. In this case we trigger a conflicting parameters for the existing binding depsite\n            # this is not the case.\n            raise ErrBindingAlreadyExists()\n        \n        else:\n            # Different parameters ...\n            raise ErrBindingAlreadyExists()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nunbinds the instance from the database.", "response": "def unbind(self, binding):\n        \"\"\" Unbind the instance\n        \n        Args:\n            binding (AtlasServiceBinding.Binding): Existing or New binding\n        \"\"\"\n        \n        username = self.backend.config.generate_binding_username(binding)\n        \n        try:\n            self.backend.atlas.DatabaseUsers.delete_a_database_user(username)\n        except ErrAtlasNotFound:\n            # The user does not exist. This is not an issue because this is possible that we\n            # removed it in a previous call that failed later on the broker.\n            # This cover a manually deleted user case too.\n            pass\n\n        self.backend.storage.remove(binding)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a tuple of objects and their associated methods and properties.", "response": "def describe(items, show_methods=True, show_properties=True):\n    \"\"\"Detecting attributes, inherits and relations\n\n    :param items: list of objects to describe\n    :param show_methods: do detection of methods\n    :param show_properties: do detection of properties\n\n    Return tuple (objects, relations, inherits)\n\n\n    Where objects is list::\n\n        [{\n            'name': '<Mapper class name or table name>',\n            'cols': [\n                ('<Column type class name>', '<Column name>'),\n                ...\n            ],\n            'props': ['<Property name>'],\n            'methods': ['<Method name>', ...],\n        }, ...]\n\n\n    Relations is::\n\n        [{\n            'from': '<From mapper class name>',\n            'by': '<By mapper foreign key column name>',\n            'to': '<To mapper class name>',\n        }, ...]\n\n\n    Example usage::\n\n        import sadisplay\n        from app import models\n\n        desc = sadisplay.describe([\n            getattr(model, attr) for attr in dir(model)\n        ])\n\n        desc = sadisplay.describe([models.User, models.Group])\n    \"\"\"\n\n    class EntryItem(object):\n        \"\"\"Class adaptor for mapped classes and tables\"\"\"\n        name = None\n        methods = []\n        columns = []\n        inherits = None\n        properties = []\n        bases = tuple()\n\n        def __init__(self, mapper=None, table=None):\n\n            if mapper is not None:\n                self.name = mapper.class_.__name__\n                self.columns = mapper.columns\n                self.methods = mapper.class_.__dict__.items()\n                self.inherits = mapper.inherits\n                self.properties = mapper.iterate_properties\n                self.bases = mapper.class_.__bases__\n                self.class_ = mapper.class_\n                self.table_name = str(mapper.mapped_table)\n\n            elif table is not None:\n                self.name = table.name\n                self.table_name = table.name\n                # prepend schema if exists for foreign key matching\n                if hasattr(table, \"schema\") and table.schema:\n                    self.table_name = table.schema + \".\" + self.table_name\n                self.columns = table.columns\n            else:\n                pass\n\n        def __repr__(self):\n            return '<{s.__class__.__name__} {s.name}>'.format(s=self)\n\n        def __eq__(self, other):\n            if other.inherits or self.inherits:\n                return self.name == other.name\n            return self.table_name == other.table_name\n\n    objects = []\n    relations = []\n    inherits = []\n\n    entries = []\n    for item in items:\n        try:\n            mapper = class_mapper(item)\n        except (exc.ArgumentError, orm.exc.UnmappedClassError):\n            if isinstance(item, Table):\n                entity = EntryItem(table=item)\n            else:\n                continue\n        else:\n            entity = EntryItem(mapper=mapper)\n\n        if entity not in entries:\n            entries.append(entity)\n\n    for entry in entries:\n\n        result_item = {\n            'name': entry.name,\n            'cols': [\n                (c.type.__class__.__name__, c.name) for c in entry.columns\n            ],\n            'props': [],\n            'methods': [],\n        }\n\n        if show_methods and entry.methods:\n\n            if entry.inherits:\n                base_methods = entry.inherits.class_.__dict__.keys()\n            else:\n                # Create the DummyClass subclass of mapper bases\n                # for detecting mapper own methods\n                suffix = '%s' % str(uuid.uuid4())\n                params = {\n                    '__tablename__': 'dummy_table_%s' % suffix,\n                    'dummy_id_col': Column(Integer, primary_key=True)\n                }\n\n                DummyClass = type('Dummy%s' % suffix, entry.bases, params)\n\n                base_methods = DummyClass.__dict__.keys()\n\n            # Filter mapper methods\n            for name, func in entry.methods:\n                if name[0] != '_' and name not in base_methods:\n                    if isinstance(func, types.FunctionType):\n                        result_item['methods'].append(name)\n\n        if show_properties and entry.properties:\n            for item in entry.properties:\n                if not isinstance(item, ColumnProperty):\n                    result_item['props'].append(item.key)\n\n        # ordering\n        for key in ('methods', 'props'):\n            result_item[key].sort()\n\n        objects.append(result_item)\n\n        # Detect relations by ForeignKey\n        for col in entry.columns:\n            for fk in col.foreign_keys:\n                table = fk.column.table\n                for m in entries:\n                    try:\n                        if str(table) == str(m.table_name):\n                            relations.append({\n                                'from': entry.name,\n                                'by': col.name,\n                                'to': m.name,\n                            })\n                    except AttributeError:\n                        pass\n\n        if entry.inherits:\n\n            inh = {\n                'child': entry.name,\n                'parent': EntryItem(mapper=entry.inherits).name,\n            }\n\n            inherits.append(inh)\n\n            # Delete relation by inherits\n            for i, rel in enumerate(relations):\n                if inh['child'] == rel['from'] and inh['parent'] == rel['to']:\n                    relations.pop(i)\n\n    return objects, relations, inherits"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extension(names):\n    for name in names:\n        if not NAME_PATTERN.match(name):\n            raise ValueError('invalid extension name: %s' % name)\n    def decorator(f, names=names):\n        return Extension(f, names=names)\n    return decorator", "response": "Makes a function to be an extension."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eval_extensions(self, value, name, option, format):\n        try:\n            exts = self._extensions[name]\n        except KeyError:\n            raise ValueError('no suitable extension: %s' % name)\n        for ext in exts:\n            rv = ext(self, value, name, option, format)\n            if rv is not None:\n                return rv", "response": "Evaluates the extensions in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nannotates a feature container with a set of ms - run files and a set of ms - run files.", "response": "def matchToFeatures(fiContainer, specContainer, specfiles=None, fMassKey='mz',\n                    sMassKey='obsMz', isotopeErrorList=(0),\n                    precursorTolerance=5, toleranceUnit='ppm',\n                    rtExpansionUp=0.10, rtExpansionDown=0.05, matchCharge=True,\n                    scoreKey='pep', largerBetter=False):\n    \"\"\"Annotate :class:`Fi <maspy.core.Fi>` (Feature items) by matching\n    :class:`Si <maspy.core.Si>` (Spectrum items) or :class:`Sii\n    <maspy.core.Sii>` (Spectrum identification items).\n\n    :param fiContainer: :class:`maspy.core.FeatureContainer`, contains ``Fi``.\n    :param specContainer: :class:`maspy.core.MsrunContainer` or\n        :class:`maspy.core.SiiContainer`, contains ``Si`` or ``Sii``.\n    :param specfiles: filenames of ms-run files, if specified consider only\n        items from those files\n    :type specfiles: str, list or None\n    :param fMassKey: mass attribute key in :attr:`Fi.__dict__`\n    :param sMassKey: mass attribute key in :attr:`Si.__dict__` or\n        :attr:`Sii.__dict__` (eg 'obsMz', 'excMz')\n    :param isotopeErrorList: allowed isotope errors relative to the spectrum\n        mass, for example \"0\" or \"1\". If no feature has been matched with\n        isotope error 0, the spectrum mass is increased by the mass difference\n        of carbon isotopes 12 and 13 and matched again. The different isotope\n        error values are tested in the specified order therefore \"0\" should\n        normally be the first value of the list.\n    :type isotopeErrorList: list or tuple of int\n    :param precursorTolerance: the largest allowed mass deviation of ``Si`` or\n        ``Sii`` relative to ``Fi``\n    :param toleranceUnit: defines how the ``precursorTolerance`` is applied to\n        the mass value of ``Fi``. ``\"ppm\": mass * (1 +/- tolerance*1E-6)`` or\n        ``\"da\": mass +/- value``\n    :param rtExpansionUp: relative upper expansion of ``Fi`` retention time\n        area. ``limitHigh = Fi.rtHigh + (Fi.rtHigh - Fi.rtLow) * rtExpansionUp``\n    :param rtExpansionDown: relative lower expansion of ``Fi`` retention time\n        area. ``limitLow = Fi.rtLow - (Fi.rtHigh - Fi.rtLow) * rtExpansionDown``\n    :param matchCharge: bool, True if ``Fi`` and ``Si`` or ``Sii`` must have the\n        same ``charge`` state to be matched.\n    :param scoreKey: ``Sii`` attribute name used for scoring the identification\n        reliability\n    :param largerBetter: bool, True if higher score value means a better\n        identification reliability\n\n    .. note:\n        Concerning the feature retention area expansion. If ``Si`` or ``Sii`` is\n        matched to multiple ``Fi`` the rt expansion is removed and the matching\n        is repeated.\n\n    .. note:\n        If the ``specContainer`` is a ``SiiContainer`` then matched ``Fi`` are\n        annotated with :attr:`Sii.peptide`, if multiple ``Sii`` are matched to\n        ``Fi`` the one with the best score is used.\n\n    #TODO: this function is nested pretty badly and should maybe be rewritten\n    #TODO: replace tolerance unit \"ppm\" by tolerance mode \"relative\" and change\n        repsective calculations\n    \"\"\"\n    isotopeErrorList = aux.toList(isotopeErrorList)\n\n    if specContainer.__class__.__name__ == 'MsrunContainer':\n        listKeySpecIds = 'siIds'\n    else:\n        listKeySpecIds = 'siiIds'\n    specContainerSpecfiles = [_ for _ in viewkeys(specContainer.info)]\n\n    if specfiles is not None:\n        specfiles = aux.toList(specfiles)\n    else:\n        specfiles = [_ for _ in viewkeys(fiContainer.info)]\n    specfiles = list(set(specfiles).intersection(set(specContainerSpecfiles)))\n\n    for specfile in specfiles:\n        multiMatchCounter = int()\n        isotopeErrorMatchCounter = int()\n        specArrays = specContainer.getArrays([sMassKey, 'rt', 'charge',\n                                              'msLevel'], specfiles=specfile\n                                              )\n        featureArrays = fiContainer.getArrays(['rtHigh', 'rtLow', 'charge',\n                                               fMassKey], specfiles=specfile,\n                                               sort=fMassKey\n                                              )\n        featureArrays['rtHighExpanded'] = (featureArrays['rtHigh'] +\n                                           (featureArrays['rtHigh'] -\n                                            featureArrays['rtLow']) *\n                                           rtExpansionUp\n                                           )\n        featureArrays['rtLowExpanded'] = (featureArrays['rtLow'] -\n                                          (featureArrays['rtHigh'] -\n                                           featureArrays['rtLow']) *\n                                          rtExpansionDown\n                                          )\n\n        specFeatureDict = dict() ## key = scanNr, value = set(featureKeys)\n        featureSpecDict = dict() ## key = featureKey, value = set(scanNrs)\n\n        for specPos, specId in enumerate(specArrays['id']):\n            specZ = specArrays['charge'][specPos]\n            if specZ is None:\n                continue\n            specMass = specArrays[sMassKey][specPos]\n            specRt = specArrays['rt'][specPos]\n\n            matchComplete = False\n            isotopeErrorPos = 0\n\n            while not matchComplete:\n                isotopeError = isotopeErrorList[isotopeErrorPos]\n\n                # calculate mass limits for each isotope error\n                if toleranceUnit.lower() == 'ppm':\n                    specMassHigh = ((specMass + isotopeError * 1.003355 / specZ)\n                                    * (1 + precursorTolerance*1E-6)\n                                    )\n                    specMassLow = ((specMass + isotopeError * 1.003355 / specZ)\n                                   * (1 - precursorTolerance*1E-6)\n                                   )\n                elif toleranceUnit.lower() == 'da':\n                    specMassHigh = ((specMass + isotopeError * 1.003355 / specZ)\n                                    + precursorTolerance\n                                    )\n                    specMassLow  = ((specMass + isotopeError * 1.003355 / specZ)\n                                    - precursorTolerance\n                                    )\n\n                posL = bisect.bisect_left(featureArrays[fMassKey],\n                                          specMassLow\n                                          )\n                posR = bisect.bisect_right(featureArrays[fMassKey],\n                                           specMassHigh\n                                           )\n\n                if matchCharge:\n                    chargeMask = (featureArrays['charge'][posL:posR] == specZ)\n\n                fRtHighKey = 'rtHighExpanded'\n                fRtLowKey = 'rtLowExpanded'\n                for fRtHighKey, fRtLowKey in [('rtHighExpanded',\n                                               'rtLowExpanded'),\n                                              ('rtHigh', 'rtLow')\n                                              ]:\n                    rtMask = ((featureArrays[fRtLowKey][posL:posR] <= specRt) &\n                              (featureArrays[fRtHighKey][posL:posR] >= specRt)\n                              )\n                    if matchCharge:\n                        matchedFeatureIds = featureArrays['id'][posL:posR][rtMask & chargeMask]\n                    else:\n                        matchedFeatureIds = featureArrays['id'][posL:posR][rtMask]\n\n                    if len(matchedFeatureIds) <= 1:\n                        break\n\n                # if exactly one feature has been matched,\n                if len(matchedFeatureIds) > 0:\n                    if len(matchedFeatureIds) == 1:\n                        matchComplete = True\n                        if isotopeErrorList[isotopeErrorPos] != 0:\n                            isotopeErrorMatchCounter += 1\n                    else:\n                        #Stop if Spectrum can be matched to multiple features\n                        multiMatchCounter += 1\n                        break\n\n                isotopeErrorPos += 1\n                if isotopeErrorPos >= len(isotopeErrorList):\n                    #Stop if all allowed isotope errors have been tested\n                    break\n\n            if matchComplete:\n                for featureId in matchedFeatureIds:\n                    getattr(fiContainer.container[specfile][featureId],\n                            listKeySpecIds\n                            ).append(specId)\n                    fiContainer.container[specfile][featureId].isMatched = True\n                    specFeatureDict[specId] = featureId\n                    featureSpecDict[featureId] = specId\n\n        stats = dict()\n        stats['totalFeatures'] = len(featureArrays['id'])\n        stats['matchedFeatures'] = len(featureSpecDict)\n        stats['relMatchedFeatures'] = round(100*stats['matchedFeatures']/stats['totalFeatures'], 1)\n        stats['totalSpectra'] = len(specArrays['id'][(specArrays['msLevel'] != 1)])\n        stats['matchedSpectra'] = len(specFeatureDict)\n        stats['relMatchedSpectra'] = round(100*stats['matchedSpectra']/stats['totalSpectra'], 1)\n\n        print('------', specfile, '------')\n        print('Annotated features:\\t\\t\\t', stats['matchedFeatures'], '/', stats['totalFeatures'], '=', stats['relMatchedFeatures'], '%')\n        print('Spectra matched to features:\\t\\t', stats['matchedSpectra'], '/', stats['totalSpectra'], '=', stats['relMatchedSpectra'], '%')\n        if multiMatchCounter != 0:\n                print('Discarded because of multiple matches:\\t', multiMatchCounter)\n        if isotopeErrorMatchCounter != 0:\n                print('Isotope error matched spectra:\\t\\t', isotopeErrorMatchCounter)\n\n        #annotate feature with sii information (peptide, sequence, score)\n        if isinstance(specContainer, maspy.core.SiiContainer):\n            for featureId in viewkeys(featureSpecDict):\n                matches = list()\n                for specId in fiContainer.container[specfile][featureId].siiIds:\n                    _sii = specContainer.getValidItem(specfile, specId)\n                    score = getattr(_sii, scoreKey)\n                    peptide = _sii.peptide\n                    sequence = _sii.sequence\n                    matches.append([score, peptide, sequence])\n                matches.sort(reverse=largerBetter)\n\n                fiContainer.container[specfile][featureId].isAnnotated = True\n                fiContainer.container[specfile][featureId].score = matches[0][0]\n                fiContainer.container[specfile][featureId].peptide = matches[0][1]\n                fiContainer.container[specfile][featureId].sequence = matches[0][2]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a retention time calibration between two features in a single specfile.", "response": "def rtCalibration(fiContainer, allowedRtDev=60, allowedMzDev=2.5,\n                  reference=None, specfiles=None, showPlots=False,\n                  plotDir=None, minIntensity=1e5):\n    \"\"\"Performs a retention time calibration between :class:`FeatureItem` of multiple specfiles.\n\n    :ivar fiContainer: Perform alignment on :class:`FeatureItem` in :attr:`FeatureContainer.specfiles`\n    :ivar allowedRtDev: maxium retention time difference of two features in two runs to be matched\n    :ivar allowedMzDev: maxium relative m/z difference (in ppm) of two features in two runs to be matched\n    :ivar showPlots: boolean, True if a plot should be generated which shows to results of the calibration\n    :ivar plotDir: if not None and showPlots is True, the plots are saved to\n        this location.\n    :ivar reference: Can be used to specifically specify a reference specfile\n    :ivar specfiles: Limit alignment to those specfiles in the fiContainer\n    :ivar minIntensity: consider only features with an intensity above this value\n    \"\"\"\n    #TODO: long function, maybe split into subfunctions\n    specfiles = [_ for _ in viewkeys(fiContainer.info)] if specfiles is None else specfiles\n    matchCharge = True\n\n    refMzKey = 'mz'\n    mzKey = 'mz'\n\n    if reference is not None:\n        if reference in specfiles:\n            specfiles = [reference] + list(set(specfiles).difference(set([reference])))\n        else:\n            print('Specified reference specfile not present, using reference: ', specfiles[0])\n\n    for featureItem in fiContainer.getItems(specfiles=specfiles):\n        if not hasattr(featureItem, 'obsRt'):\n            setattr(featureItem, 'obsRt', featureItem.rt)\n\n    referenceArrays = None\n    for specfile in specfiles:\n        featureArrays = fiContainer.getArrays(['rt', 'charge', 'mz', 'intensity'],\n                                              specfiles=specfile, sort='rt'\n                                              )\n        if minIntensity is not None:\n            intensityMask = (featureArrays['intensity'] > minIntensity)\n            for key in list(viewkeys(featureArrays)):\n                featureArrays[key] = featureArrays[key][intensityMask]\n\n        if referenceArrays is None:\n            referenceArrays = featureArrays\n            if showPlots:\n                print('Reference: '+specfile)\n            continue\n\n        rtPosList = list()\n        rtDevList = list()\n        mzDevRelList = list()\n        mzDevAbsList = list()\n\n        for featurePos in range(len(featureArrays[mzKey])):\n            currRt = featureArrays['rt'][featurePos]\n            currMz = featureArrays[mzKey][featurePos]\n            currZ = featureArrays['charge'][featurePos]\n            mzLimitUp = currMz*(1+allowedMzDev*1E-6)\n            mzLimitLow = currMz*(1-allowedMzDev*1E-6)\n            rtLimitUp = currRt+allowedRtDev\n            rtLimitLow = currRt-allowedRtDev\n\n            posL = bisect.bisect_left(referenceArrays['rt'], rtLimitLow)\n            posU = bisect.bisect_right(referenceArrays['rt'], rtLimitUp)\n\n            refMask = (referenceArrays[refMzKey][posL:posU] <= mzLimitUp) & (referenceArrays[refMzKey][posL:posU] >= mzLimitLow)\n            if matchCharge:\n                refMask = refMask & (referenceArrays['charge'][posL:posU] == currZ)\n\n            currMzDev = abs(referenceArrays[refMzKey][posL:posU][refMask] - currMz)\n            bestHitMask = currMzDev.argsort()\n            for refRt, refMz in zip(referenceArrays['rt'][posL:posU][refMask][bestHitMask],\n                                    referenceArrays[refMzKey][posL:posU][refMask][bestHitMask]):\n                rtPosList.append(currRt)\n                rtDevList.append(currRt - refRt)\n                mzDevRelList.append((1 - currMz / refMz)*1E6)\n                mzDevAbsList.append(currMz - refMz)\n                break\n\n        rtPosList = numpy.array(rtPosList)\n        rtDevList = numpy.array(rtDevList)\n\n        splineInitialKnots = int(max(rtPosList) - min(rtPosList))\n        dataFit = aux.DataFit(rtDevList, rtPosList)\n        dataFit.splineInitialKnots = splineInitialKnots\n        dataFit.splineTerminalExpansion = 0.2\n        dataFit.processInput(dataAveraging='median', windowSize=10)\n        dataFit.generateSplines()\n\n        if showPlots:\n            corrDevArr = rtDevList - dataFit.corrArray(rtPosList)\n            timePoints = [min(rtPosList) + x for x in range(int(max(rtPosList)-min(rtPosList)))]\n            corrValues  = dataFit.corrArray(timePoints)\n            fig, ax = plt.subplots(3, 2, sharex=False, sharey=False, figsize=(20, 18))\n            fig.suptitle(specfile)\n            ax[0][0].hist(rtDevList, bins=100, color='grey', alpha=0.5, label='observed')\n            ax[0][0].hist(corrDevArr, bins=100, color='red', alpha=0.5, label='corrected')\n            ax[0][0].set_title('Retention time deviation')\n            ax[0][0].legend()\n            ax[0][0].set_xlim(allowedRtDev*-1, allowedRtDev)\n            ax[0][1].hist(mzDevRelList, bins=100, color='grey')\n            ax[0][1].set_title('Mz deviation [ppm]')\n            ax[1][0].scatter(rtPosList, rtDevList, color='grey', alpha=0.1, label='observed')\n            ax[1][0].plot(timePoints,corrValues, color='red', alpha=0.5, label='correction function')\n            ax[1][0].set_title('Retention time deviation over time')\n            ax[1][0].legend()\n            ax[1][0].set_ylim(allowedRtDev*-1, allowedRtDev)\n            ax[1][1].scatter(rtPosList, mzDevRelList, color='grey', alpha=0.1)\n            ax[1][1].set_title('Mz deviation over time')\n            ax[1][1].set_ylim(allowedMzDev*-1, allowedMzDev)\n            ax[2][0].scatter(rtPosList, corrDevArr, color='grey', alpha=0.1)\n            ax[2][0].set_title('Aligned retention time deviation over time')\n            ax[2][0].set_ylim(allowedRtDev*-1, allowedRtDev)\n            if plotDir is not None:\n                plotloc = aux.joinpath(plotDir, specfile+'.rtAlign.png')\n                fig.savefig(plotloc)\n            else:\n                fig.show()\n\n        featureArrays = fiContainer.getArrays(['rt'], specfiles=specfile, sort='rt')\n        featureArrays['corrRt'] = featureArrays['rt'] - dataFit.corrArray(featureArrays['rt'])\n        for featureId, corrRt, rt in zip(featureArrays['id'], featureArrays['corrRt'], featureArrays['rt']):\n            fiContainer.container[specfile][featureId].rt = corrRt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a base object that contains the show name season number and episode number.", "response": "def GetShowDetails(self):\n    \"\"\"\n    Extract show name, season number and episode number from file name.\n\n    Supports formats S<NUM>E<NUM> or <NUM>x<NUM> for season and episode numbers\n    where letters are case insensitive and number can be one or more digits. It\n    expects season number to be unique however it can handle either single or\n    multipart episodes (consecutive values only).\n\n    All information preceeding season number is used for the show name lookup. This\n    string is forced to lowercase and stripped of special characters\n\n    Returns\n    ----------\n      boolean\n        False if an incompatible file name is found, otherwise return True.\n    \"\"\"\n\n    fileName = os.path.splitext(os.path.basename(self.fileInfo.origPath))[0]\n\n    # Episode Number\n    episodeNumSubstring = set(re.findall(\"(?<=[0-9])[xXeE][0-9]+(?:[xXeE_.-][0-9]+)*\", fileName))\n\n    if len(episodeNumSubstring) != 1:\n      goodlogging.Log.Info(\"TVFILE\", \"Incompatible filename no episode match detected: {0}\".format(self.fileInfo.origPath))\n      return False\n\n    episodeNumSet = set(re.findall(\"(?<=[xXeE_.-])[0-9]+\", episodeNumSubstring.pop()))\n\n    episodeNumList = [int(i) for i in episodeNumSet]\n    episodeNumList.sort()\n\n    episodeNum = \"{0}\".format(episodeNumList[0])\n    if len(episodeNumList) > 1:\n      episodeNumReference = episodeNumList[0]\n      for episodeNumIter in episodeNumList[1:]:\n        if episodeNumIter == (episodeNumReference+1):\n          strNum = \"{0}\".format(episodeNumIter)\n          if len(strNum) == 1:\n            strNum = \"0{0}\".format(strNum)\n\n          self.showInfo.multiPartEpisodeNumbers.append(strNum)\n          episodeNumReference = episodeNumIter\n        else:\n          break\n\n    if len(episodeNum) == 1:\n      episodeNum = \"0{0}\".format(episodeNum)\n\n    self.showInfo.episodeNum = episodeNum\n\n    # Season Number\n    seasonNumSet = set(re.findall(\"[sS]([0-9]+)\", fileName))\n    preceedingS = True\n\n    if len(seasonNumSet) == 1:\n      seasonNum = seasonNumSet.pop()\n    else:\n      seasonNumSet = set(re.findall(\"([0-9]+)[xX](?:[0-9]+[xX])*\", fileName))\n      preceedingS = False\n\n      if len(seasonNumSet) == 1:\n        seasonNum = seasonNumSet.pop()\n      else:\n        goodlogging.Log.Info(\"TVFILE\", \"Incompatible filename no season match detected: {0}\".format(self.fileInfo.origPath))\n        return False\n\n    if len(seasonNum) == 1:\n      seasonNum = \"0{0}\".format(seasonNum)\n\n    self.showInfo.seasonNum = seasonNum\n\n    # Show Name\n    if preceedingS is True:\n      showNameList = re.findall(\"(.+?)\\s*[_.-]*\\s*[sS][0-9]+[xXeE][0-9]+.*\", fileName)\n    else:\n      showNameList = re.findall(\"(.+?)\\s*[_.-]*\\s*[0-9]+[xXeE][0-9]+.*\", fileName)\n\n    if len(showNameList) == 1:\n      showName = util.StripSpecialCharacters(showNameList[0].lower(), stripAll=True)\n    else:\n      goodlogging.Log.Info(\"TVFILE\", \"Incompatible filename no show name detected: {0}\".format(self.fileInfo.origPath))\n      return False\n\n    self.fileInfo.showName = showName\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GenerateNewFileName(self):\n    if self.showInfo.showName is not None and self.showInfo.seasonNum is not None and \\\n       self.showInfo.episodeNum is not None and self.showInfo.episodeName is not None:\n      ext = os.path.splitext(self.fileInfo.origPath)[1]\n      newFileName = \"{0}.S{1}E{2}\".format(self.showInfo.showName, self.showInfo.seasonNum, \\\n                                            self.showInfo.episodeNum)\n\n      for episodeNum in self.showInfo.multiPartEpisodeNumbers:\n        newFileName = newFileName + \"_{0}\".format(episodeNum)\n\n      newFileName = newFileName + \".{0}{1}\".format(self.showInfo.episodeName, ext)\n      newFileName = util.StripSpecialCharacters(newFileName)\n      return newFileName", "response": "Generates new file name from show name season number and episode number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a new file path for the current language.", "response": "def GenerateNewFilePath(self, fileDir = None):\n    \"\"\"\n    Create new file path. If a fileDir is provided it will be used otherwise\n    the original file path is used. Updates file info object with new path.\n\n    Parameters\n    ----------\n      fileDir : string [optional : default = None]\n        Optional file directory\n    \"\"\"\n    newFileName = self.GenerateNewFileName()\n    if newFileName is not None:\n      if fileDir is None:\n        fileDir = os.path.dirname(self.fileInfo.origPath)\n      self.fileInfo.newPath = os.path.join(fileDir, newFileName)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Print(self):\n    goodlogging.Log.Info(\"TVFILE\", \"TV File details are:\")\n    goodlogging.Log.IncreaseIndent()\n    goodlogging.Log.Info(\"TVFILE\", \"Original File Path      = {0}\".format(self.fileInfo.origPath))\n    if self.showInfo.showName is not None:\n      goodlogging.Log.Info(\"TVFILE\", \"Show Name (from guide)  = {0}\".format(self.showInfo.showName))\n    elif self.fileInfo.showName is not None:\n      goodlogging.Log.Info(\"TVFILE\", \"Show Name (from file)   = {0}\".format(self.fileInfo.showName))\n    if self.showInfo.seasonNum is not None and self.showInfo.episodeNum is not None:\n      goodlogging.Log.Info(\"TVFILE\", \"Season & Episode        = S{0}E{1}\".format(self.showInfo.seasonNum, self.showInfo.episodeNum))\n    if self.showInfo.episodeName is not None:\n      goodlogging.Log.Info(\"TVFILE\", \"Episode Name:           = {0}\".format(self.showInfo.episodeName))\n    if self.fileInfo.newPath is not None:\n      goodlogging.Log.Info(\"TVFILE\", \"New File Path           = {0}\".format(self.fileInfo.newPath))\n    goodlogging.Log.DecreaseIndent()", "response": "Prints contents of showInfo and FileInfo object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen a SSHSession channel and connects a ProcessProtocol to it", "response": "def connectProcess(connection, processProtocol, commandLine='', env={},\n                   usePTY=None, childFDs=None, *args, **kwargs):\n    \"\"\"Opens a SSHSession channel and connects a ProcessProtocol to it\n\n    @param connection: the SSH Connection to open the session channel on\n    @param processProtocol: the ProcessProtocol instance to connect to the process\n    @param commandLine: the command line to execute the process\n    @param env: optional environment variables to set for the process\n    @param usePTY: if set, request a PTY for the process\n    @param childFDs: custom child file descriptors for the process\n    \"\"\"\n    processOpenDeferred = defer.Deferred()\n    process = SSHProcess(processProtocol, commandLine, env, usePTY, childFDs,\n                         *args, **kwargs)\n    process.processOpen = processOpenDeferred.callback\n    process.openFailed = processOpenDeferred.errback\n\n    connection.openChannel(process)\n    return processOpenDeferred"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that returns the response from the VK API to the given user.", "response": "def get_api_publisher(self, social_user):\n        \"\"\"\n            owner_id - VK user or group\n            from_group - 1 by group, 0 by user\n            message - text\n            attachments - comma separated links or VK resources ID's\n            and other https://vk.com/dev.php?method=wall.post\n        \"\"\"\n\n        def _post(**kwargs):\n            api = self.get_api(social_user)\n            response = api.wall.post(**kwargs)\n            return response\n\n        return _post"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_api_publisher(self, social_user):\n\n        def _post(**kwargs):\n            api = self.get_api(social_user)\n            author = {\n                'group_id': kwargs.get('group_id'),\n                'user_id': kwargs.get('user_id'),\n            }\n            server_data = api.photos.getWallUploadServer(**author)\n            attachments = []\n\n            for _file in kwargs['files']:\n                upload_data = requests.post(\n                    server_data['upload_url'], files={\"photo\": _file}).json()\n                upload_data.update(author)\n                photos_data = api.photos.saveWallPhoto(**upload_data)\n                attachments.append('photo{owner_id}_{id}'.format(**photos_data[0]))\n\n            del kwargs['files']\n            kwargs['attachments'] = ','.join(attachments)\n            response = api.wall.post(**kwargs)\n\n            server_data.update(response)\n            return server_data\n\n        return _post", "response": "Returns a function that will post the user s photos to the server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when builder init event is received.", "response": "def call_builder_init(cls, kb_app, sphinx_app: Sphinx):\n        \"\"\" On builder init event, commit registry and do callbacks \"\"\"\n\n        # Find and commit docs project plugins\n        conf_dir = sphinx_app.confdir\n        plugins_dir = sphinx_app.config.kaybee_settings.plugins_dir\n        full_plugins_dir = os.path.join(conf_dir, plugins_dir)\n\n        if os.path.exists(full_plugins_dir):\n            sys.path.insert(0, conf_dir)\n            plugin_package = importlib.import_module(plugins_dir)\n            importscan.scan(plugin_package)\n        else:\n            logger.info(f'## Kaybee: No plugin dir at {plugins_dir}')\n\n        dectate.commit(kb_app)\n        for callback in cls.get_callbacks(kb_app, SphinxEvent.BI):\n            callback(kb_app, sphinx_app)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call_env_before_read_docs(cls, kb_app, sphinx_app: Sphinx,\n                                  sphinx_env: BuildEnvironment,\n                                  docnames: List[str]):\n        \"\"\" On env-read-docs, do callbacks\"\"\"\n\n        for callback in EventAction.get_callbacks(kb_app,\n                                                  SphinxEvent.EBRD):\n            callback(kb_app, sphinx_app, sphinx_env, docnames)", "response": "Call env - read - docs callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_env_doctree_read(cls, kb_app, sphinx_app: Sphinx,\n                              doctree: doctree):\n        \"\"\" On doctree-read, do callbacks\"\"\"\n\n        for callback in EventAction.get_callbacks(kb_app,\n                                                  SphinxEvent.DREAD):\n            callback(kb_app, sphinx_app, doctree)", "response": "Call env doctree - read callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when a doctree is resolved.", "response": "def call_doctree_resolved(cls, kb_app, sphinx_app: Sphinx,\n                              doctree: doctree,\n                              fromdocname: str):\n        \"\"\" On doctree-resolved, do callbacks\"\"\"\n\n        for callback in EventAction.get_callbacks(kb_app,\n                                                  SphinxEvent.DRES):\n            callback(kb_app, sphinx_app, doctree, fromdocname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the env - updated event callbacks", "response": "def call_env_updated(cls, kb_app,\n                         sphinx_app: Sphinx,\n                         sphinx_env: BuildEnvironment):\n\n        \"\"\" On the env-updated event, do callbacks \"\"\"\n        for callback in EventAction.get_callbacks(kb_app, SphinxEvent.EU):\n            callback(kb_app, sphinx_app, sphinx_env)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_env_check_consistency(cls, kb_app, builder: StandaloneHTMLBuilder,\n                                   sphinx_env: BuildEnvironment):\n        \"\"\" On env-check-consistency, do callbacks\"\"\"\n\n        for callback in EventAction.get_callbacks(kb_app,\n                                                  SphinxEvent.ECC):\n            callback(kb_app, builder, sphinx_env)", "response": "Call all env - check - consistency callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call_missing_reference(cls, kb_app, sphinx_app: Sphinx,\n                               sphinx_env: BuildEnvironment,\n                               node,\n                               contnode,\n                               ):\n        \"\"\" On doctree-resolved, do callbacks\"\"\"\n\n        for callback in EventAction.get_callbacks(kb_app,\n                                                  SphinxEvent.MR):\n            return callback(kb_app, sphinx_app, sphinx_env, node, contnode)", "response": "Called when a node is missing reference."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall all callbacks on the html page.", "response": "def call_html_page_context(cls, kb_app, sphinx_app: Sphinx,\n                               pagename: str,\n                               templatename: str,\n                               context,\n                               doctree: doctree\n                               ):\n        \"\"\" On doctree-resolved, do callbacks\"\"\"\n\n        # We need to let one, and only one, callback return the name of\n        # the template. Detect multiple and raise an exception.\n        new_templatename = None\n\n        for callback in EventAction.get_callbacks(kb_app,\n                                                  SphinxEvent.HPC):\n            # The protocol: the one controlling callback will return a value\n            # with a dictionary of {'templatename': 'sometemplate'}\n            result = callback(kb_app, sphinx_app, pagename, templatename,\n                              context,\n                              doctree)\n            if result and isinstance(result,\n                                     dict) and 'templatename' in result:\n                if new_templatename is not None:\n                    raise AssertionError('Multiple handlers returning')\n                new_templatename = result['templatename']\n\n        return new_templatename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_layout_template(self, template_name=None):\n        if template_name:\n            return template_name\n\n        if self.layout_template:\n            return self.layout_template\n\n        return defaults.LAYOUT_DEFAULT_TEMPLATE", "response": "Returns the layout template to use when rendering the form to HTML."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the template context which is used when rendering the form to HTML.", "response": "def get_layout_context(self):\n        \"\"\"\n        Returns the context which is used when rendering the form to HTML.\n\n        The generated template context will contain the following variables:\n\n        * form: `Form` instance\n        * errors: `ErrorList` instance with non field errors and hidden field errors\n        * hidden_fields: All hidden fields to render.\n        * visible_fields: All visible fields to render.\n\n        :return: Template context for form rendering.\n        \"\"\"\n        errors = self.non_field_errors()\n        for field in self.hidden_fields():\n            errors.extend(field.errors)\n\n        return {\n            'form': self,\n            'errors': errors,\n            'hidden_fields': self.hidden_fields(),\n            'visible_fields': self.visible_fields(),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_clean(self, *args, **kwargs):\n        super().full_clean(*args, **kwargs)\n        for field in self.errors:\n            if field != NON_FIELD_ERRORS:\n                self.apply_widget_invalid_options(field)", "response": "This method is hijacked to apply special treatment to invalid\n            field inputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_field_template(self, bound_field, template_name=None):\n        if template_name:\n            return template_name\n\n        templates = self.field_template_overrides or {}\n\n        template_name = templates.get(bound_field.name, None)\n        if template_name:\n            return template_name\n\n        template_name = templates.get(bound_field.field.__class__, None)\n        if template_name:\n            return template_name\n\n        if self.field_template:\n            return self.field_template\n\n        return defaults.FIELD_DEFAULT_TEMPLATE", "response": "Returns the name of the field template to use when rendering a form field to HTML."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the optional label CSS class to use when rendering a field template.", "response": "def get_field_label_css_class(self, bound_field):\n        \"\"\"\n        Returns the optional label CSS class to use when rendering a field template.\n\n        By default, returns the Form class property `field_label_css_class`. If the\n        field has errors and the Form class property `field_label_invalid_css_class`\n        is defined, its value is appended to the CSS class.\n\n        :param bound_field: `BoundField` instance to return CSS class for.\n        :return: A CSS class string or `None`\n        \"\"\"\n        class_name = self.field_label_css_class\n\n        if bound_field.errors and self.field_label_invalid_css_class:\n            class_name = join_css_class(\n                class_name, self.field_label_invalid_css_class)\n\n        return class_name or None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_field_context(self, bound_field):\n        widget = bound_field.field.widget\n        widget_class_name = widget.__class__.__name__.lower()\n\n        # Check if we have an overwritten id in widget attrs,\n        # if not use auto_id of bound field.\n        field_id = widget.attrs.get('id') or bound_field.auto_id\n        if field_id:\n            field_id = widget.id_for_label(field_id)\n\n        return {\n            'form': self,\n            'field': bound_field,\n            'field_id': field_id,\n            'field_name': bound_field.name,\n            'errors': bound_field.errors,\n            'required': bound_field.field.required,\n            'label': bound_field.label,\n            'label_css_class': self.get_field_label_css_class(bound_field),\n            'help_text': mark_safe(bound_field.help_text) if bound_field.help_text else None,\n            'container_css_class': self.get_field_container_css_class(bound_field),\n            'widget_class_name': widget_class_name,\n            'widget_input_type': getattr(widget, 'input_type', None) or widget_class_name\n        }", "response": "Returns the template context which is used when rendering a form field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_widget_options(self, field_name):\n        widget = self.fields[field_name].widget\n\n        if isinstance(widget, forms.DateInput):\n            widget.input_type = 'date'\n\n        if isinstance(widget, forms.TimeInput):\n            widget.input_type = 'time'\n\n        if isinstance(widget, forms.SplitDateTimeWidget):\n            widget.widgets[0].input_type = 'date'\n            widget.widgets[1].input_type = 'time'", "response": "Applies additional widget options like changing the input type of DateInput\n            and TimeInput to date or time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply widget template overrides if available.", "response": "def apply_widget_template(self, field_name):\n        \"\"\"\n        Applies widget template overrides if available.\n\n        The method uses the `get_widget_template` method to determine if the widget\n        template should be exchanged. If a template is available, the template_name\n        property of the widget instance is updated.\n\n        :param field_name: A field name of the form.\n        \"\"\"\n        field = self.fields[field_name]\n        template_name = self.get_widget_template(field_name, field)\n\n        if template_name:\n            field.widget.template_name = template_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the optional widget template to use when rendering the widget for a form field.", "response": "def get_widget_template(self, field_name, field):\n        \"\"\"\n        Returns the optional widget template to use when rendering the widget\n        for a form field.\n\n        Preference of template selection:\n            1. Template from `widget_template_overrides` selected by field name\n            2. Template from `widget_template_overrides` selected by widget class\n\n        By default, returns `None` which means \"use Django's default widget template\".\n\n        :param field_name: The field name to select a widget template for.\n        :param field: `Field` instance to return a widget template.\n        :return: Template name to use when rendering the widget or `None`\n        \"\"\"\n        templates = self.widget_template_overrides or {}\n\n        template_name = templates.get(field_name, None)\n        if template_name:\n            return template_name\n\n        template_name = templates.get(field.widget.__class__, None)\n        if template_name:\n            return template_name\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_widget_css_class(self, field_name):\n        field = self.fields[field_name]\n        class_name = self.get_widget_css_class(field_name, field)\n\n        if class_name:\n            field.widget.attrs['class'] = join_css_class(\n                field.widget.attrs.get('class', None), class_name)", "response": "Applies CSS classes to widgets if available."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying additional widget options for an invalid field.", "response": "def apply_widget_invalid_options(self, field_name):\n        \"\"\"\n        Applies additional widget options for an invalid field.\n\n        This method is called when there is some error on a field to apply\n        additional options on its widget. It does the following:\n\n        * Sets the aria-invalid property of the widget for accessibility.\n        * Adds an invalid CSS class, which is determined by the returned value\n          of `get_widget_invalid_css_class` method. If a CSS class is returned,\n          it is appended to the current value of the class property of the widget.\n\n        :param field_name: A field name of the form.\n        \"\"\"\n        field = self.fields[field_name]\n        class_name = self.get_widget_invalid_css_class(field_name, field)\n\n        if class_name:\n            field.widget.attrs['class'] = join_css_class(\n                field.widget.attrs.get('class', None), class_name)\n\n        field.widget.attrs['aria-invalid'] = 'true'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef use_quandl_data(self, authtoken):\n        dfs = {}\n        st = self.start.strftime(\"%Y-%m-%d\")\n        at = authtoken\n        for pair in self.pairs:\n            symbol = \"\".join(pair)\n            qsym = \"CURRFX/{}\".format(symbol)\n            dfs[symbol] = qdl.get(qsym,authtoken=at, trim_start=st)['Rate']\n            \n        self.build_conversion_table(dfs)", "response": "Use quandl data to build conversion table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef use_trump_data(self, symbols):\n        dfs = {sym.units : sym.df[sym.name] for sym in symbols}\n               \n        self.build_conversion_table(dfs)", "response": "Use trump data to build conversion table"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds conversion table from a dictionary of dataframes", "response": "def build_conversion_table(self, dataframes):\n        \"\"\"\n        Build conversion table from a dictionary of dataframes\n        \"\"\"\n        self.data = pd.DataFrame(dataframes)\n        tmp_pairs = [s.split(\"/\") for s in self.data.columns]\n        self.data.columns = pd.MultiIndex.from_tuples(tmp_pairs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a tweet matches the defined criteria", "response": "def match_tweet(self, tweet, user_stream):\n        \"\"\"\n        Check if a tweet matches the defined criteria\n\n        :param tweet: The tweet in question\n        :type tweet: :class:`~responsebot.models.Tweet`\n        :return: True if matched, False otherwise\n        \"\"\"\n        if user_stream:\n            if len(self.track) > 0:\n                return self.is_tweet_match_track(tweet)\n\n            return True\n\n        return self.is_tweet_match_track(tweet) or self.is_tweet_match_follow(tweet)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a node in the cache.", "response": "def find(self, _id, instance = None):\n        \"\"\" Find\n        \n        Args:\n            _id (str): instance id or binding Id\n            \n        Keyword Arguments:\n            instance (AtlasServiceInstance.Instance): Existing instance\n            \n        Returns:\n            AtlasServiceInstance.Instance or AtlasServiceBinding.Binding: An instance or binding. \n        \"\"\"\n        \n        if instance is None:\n            # We are looking for an instance\n            return self.service_instance.find(_id)\n        else:\n            # We are looking for a binding\n            return self.service_binding.find(_id, instance)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an instance of a specific class", "response": "def create(self, instance, parameters, existing=True):\n        \"\"\"Create an instance\n        \n        Args:\n            instance (AtlasServiceInstance.Instance): Existing or New instance\n            parameters (dict): Parameters for the instance\n            \n        Keyword Arguments:\n            existing (bool): True (use an existing cluster), False (create a new cluster)\n        \n        Returns:\n            ProvisionedServiceSpec: Status\n        \"\"\"\n        return self.service_instance.create(instance, parameters, existing)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all network on some special cloud", "response": "def index(self, req, drivers):\n        \"\"\"List all network\n        List all of netowrks on some special cloud\n        with:\n        :Param  req\n        :Type   object Request\n        \"\"\"\n        result = []\n        for driver in drivers:\n            result.append(driver.list_network(req.params))\n        data = {\n                'action': \"index\",\n                'controller': \"network\",\n                'cloud': req.environ['calplus.cloud'],\n                'result': result\n        }\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, req, driver):\n        response = driver.delete_network(req.params, id)\n        data = {\n            'action': \"delete\",\n            'controller': \"network\",\n            'id': id,\n            'cloud': req.environ['calplus.cloud'],\n            'response': response\n        }\n        return data", "response": "Delete a specific netowrk with id on special cloud\n        with : param id :Param req : Param driver object with : param req. params"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, req, driver):\n        response = driver.update_network(req.params, id)\n        data = {\n            'action': \"update\",\n            'controller': \"network\",\n            'id': id,\n            'cloud': req.environ['calplus.cloud'],\n            'response': response\n        }\n        return data", "response": "Update a specific netowrk with id on special cloud\n        with req. params."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new netowrk on special cloud", "response": "def create(self, req, driver):\n        \"\"\"Create a network\n        Create a new netowrk on special cloud\n        with:\n        :Param  req\n        :Type   object Request\n        \"\"\"\n        response = driver.create_network(req.params)\n        data = {\n            'action': \"create\",\n            'controller': \"network\",\n            'cloud': req.environ['calplus.cloud'],\n            'response': response\n        }\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets info of a specific netowrk with id on special cloud with req. params", "response": "def get(self, req, driver):\n        \"\"\"Get info of a network\n        Get info of a specific netowrk with id on special cloud\n        with:\n        :Param  req\n        :Type   object Request\n        \"\"\"\n        response = driver.get_network(req.params, id)\n        data = {\n            'action': \"get\",\n            'controller': \"network\",\n            'id': id,\n            'cloud': req.environ['calplus.cloud'],\n            'response': response\n        }\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attach_igw(self, req, driver):\n        igw = driver.get_igw(req.params)\n        if igw is None:\n            igw = driver.create_igw(req.params)\n        response = driver.attach_igw(req.params, igw)\n        data = {\n            'action': 'attach_igw',\n            'controller': 'network',\n            'id': id,\n            'cloud': req.environ['calplus.cloud'],\n            'response': response\n        }\n        return data", "response": "Attach network to Internet gateway"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattaching VPN gateway to a VPN network", "response": "def attach_vpngw(self, req, id, driver):\n        \"\"\"Attach network to VPN gateway\n        :Param  req\n        :Type   object Request\n        \"\"\"\n        vpngw = driver.get_vnpgw(req.params, id)\n        if vpngw is None:\n            vpngw = driver.create_vpngw(req.params, id)\n        response = driver.attach_vpngw(req.params, vpngw)\n        data = {\n            'action': 'attach_igw',\n            'controller': 'network',\n            'id': id,\n            'cloud': req.environ['calplus.cloud'],\n            'response': response\n        }\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect a Microsoft Exchange server to a Microsoft Exchange server.", "response": "def connectMSExchange(server):\n    \"\"\"\n    Creates a connection for the inputted server to a Microsoft Exchange server.\n\n    :param      server | <smtplib.SMTP>\n    \n    :usage      |>>> import smtplib\n                |>>> import projex.notify\n                |>>> smtp = smtplib.SMTP('mail.server.com')\n                |>>> projex.notify.connectMSExchange(smtp)\n    \n    :return     (<bool> success, <str> reason)\n    \"\"\"\n    if not sspi:\n        return False, 'No sspi module found.'\n\n    # send the SMTP EHLO command\n    code, response = server.ehlo()\n    if code != SMTP_EHLO_OKAY:\n        return False, 'Server did not respond to EHLO command.'\n\n    sspi_client = sspi.ClientAuth('NTLM')\n\n    # generate NTLM Type 1 message\n    sec_buffer = None\n    err, sec_buffer = sspi_client.authorize(sec_buffer)\n    # noinspection PyShadowingBuiltins\n    buffer = sec_buffer[0].Buffer\n    ntlm_message = base64.encodestring(buffer).replace('\\n', '')\n\n    # send NTLM Type 1 message -- Authentication Request\n    code, response = server.docmd('AUTH', 'NTLM ' + ntlm_message)\n\n    # verify the NTLM Type 2 response -- Challenge Message\n    if code != SMTP_AUTH_CHALLENGE:\n        msg = 'Server did not respond as expected to NTLM negotiate message'\n        return False, msg\n\n    # generate NTLM Type 3 message\n    err, sec_buffer = sspi_client.authorize(base64.decodestring(response))\n    # noinspection PyShadowingBuiltins\n    buffer = sec_buffer[0].Buffer\n    ntlm_message = base64.encodestring(buffer).replace('\\n', '')\n\n    # send the NTLM Type 3 message -- Response Message\n    code, response = server.docmd('', ntlm_message)\n    if code != SMTP_AUTH_OKAY:\n        return False, response\n\n    return True, ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sendEmail(sender,\n              recipients,\n              subject,\n              body,\n              attachments=None,\n              cc=None,\n              bcc=None,\n              contentType='text/html',\n              server=None,\n              useMSExchange=None,\n              encoding='utf-8',\n              raiseErrors=False):\n    \"\"\"\n    Sends an email from the inputted email address to the\n    list of given recipients with the inputted subject and\n    body.  This will also attach the inputted list of\n    attachments to the email.  The server value will default \n    to mail.<sender_domain> and you can use a ':' to specify \n    a port for the server.\n    \n    :param      sender          <str>\n    :param      recipients      <list> [ <str>, .. ]\n    :param      subject         <str>\n    :param      body            <str>\n    :param      attachments     <list> [ <str>, .. ]\n    :param      cc              <list> [ <str>, .. ]\n    :param      bcc             <list> [ <str>, .. ]\n    :param      contentType     <str>\n    :param      server          <str>\n    \n    :return     <bool> success\n    \"\"\"\n    if attachments is None:\n        attachments = []\n    if cc is None:\n        cc = []\n    if bcc is None:\n        bcc = []\n\n    if server is None:\n        server = NOTIFY_SERVER\n    if useMSExchange is None:\n        useMSExchange = NOTIFY_SERVER_MSX\n\n    # normalize the data\n    sender = nstr(sender)\n    recipients = map(nstr, recipients)\n\n    # make sure we have valid information\n    if not isEmail(sender):\n        err = errors.NotifyError('%s is not a valid email address' % sender)\n        logger.error(err)\n        return False\n\n    # make sure there are recipients\n    if not recipients:\n        err = errors.NotifyError('No recipients were supplied.')\n        logger.error(err)\n        return False\n\n    # build the server domain\n    if not server:\n        err = errors.NotifyError('No email server specified')\n        logger.error(err)\n        return False\n\n    # create the email\n    msg = MIMEMultipart(_subtype='related')\n    msg['Subject'] = projex.text.toUtf8(subject)\n    msg['From'] = sender\n    msg['To'] = ','.join(recipients)\n    msg['Cc'] = ','.join([nstr(addr) for addr in cc if isEmail(addr)])\n    msg['Bcc'] = ','.join([nstr(addr) for addr in bcc if isEmail(addr)])\n    msg['Date'] = nstr(datetime.datetime.now())\n    msg['Content-type'] = 'Multipart/mixed'\n\n    msg.preamble = 'This is a multi-part message in MIME format.'\n    msg.epilogue = ''\n\n    # build the body\n    bodyhtml = projex.text.toUtf8(body)\n    eattach = []\n\n    # include inline images\n    filepaths = re.findall('<img\\s+src=\"(file:///[^\"]+)\"[^/>]*/?>', bodyhtml)\n    for filepath in filepaths:\n        filename = filepath.replace('file:///', '')\n        if os.path.exists(filename) and filename not in attachments:\n            # replace with the attachment id\n            cid = 'cid:%s' % os.path.basename(filename)\n            bodyhtml = bodyhtml.replace(filename, cid)\n\n            # add the image to the attachments\n            fp = open(nstr(filename), 'rb')\n            msgImage = MIMEImage(fp.read())\n            fp.close()\n\n            # add the msg image to the msg\n            content_id = '<%s>' % os.path.basename(filename)\n            inline_link = 'inline; filename=\"%s\"' % os.path.basename(filename)\n            msgImage.add_header('Content-ID', content_id)\n            msgImage.add_header('Content-Disposition', inline_link)\n\n            eattach.append(msgImage)\n            attachments.append(filename)\n\n    # create the body text\n    msgText = MIMEText(bodyhtml, contentType, encoding)\n    msgText['Content-type'] = contentType\n\n    # include attachments\n    for attach in attachments:\n        fp = open(nstr(attach), 'rb')\n        txt = MIMEBase('application', 'octet-stream')\n        txt.set_payload(fp.read())\n        fp.close()\n\n        encode_base64(txt)\n        attachment = 'attachment; filename=\"%s\"' % os.path.basename(attach)\n        txt.add_header('Content-Disposition', attachment)\n        eattach.append(txt)\n\n    eattach.insert(0, msgText)\n\n    # add the attachments to the message\n    for attach in eattach:\n        msg.attach(attach)\n\n    # create the connection to the email server\n    try:\n        smtp_server = smtplib.SMTP(nstr(server))\n    except socket.gaierror, err:\n        logger.error(err)\n        if raiseErrors:\n            raise\n        return False\n    except Exception, err:\n        logger.error(err)\n        if raiseErrors:\n            raise\n        return False\n\n    # connect to a microsoft exchange server if specified\n    if useMSExchange:\n        success, response = connectMSExchange(smtp_server)\n        if not success:\n            logger.debug('Could not connect to MS Exchange: ' + response)\n\n    try:\n        smtp_server.sendmail(sender, recipients, msg.as_string())\n        smtp_server.close()\n    except Exception, err:\n        logger.error(err)\n        if raiseErrors:\n            raise\n        return False\n\n    return True", "response": "This function sends an email from the inputted email address to the inputted recipients subject and body."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an instant message to the receivers with the given user.", "response": "def sendJabber(sender,\n               password,\n               receivers,\n               body,\n               senderDomain=NOTIFY_IM_DOMAIN_SENDER,\n               receiverDomain=NOTIFY_IM_DOMAIN_RECEIVER):\n    \"\"\"\n    Sends an instant message to the inputted receivers from the\n    given user.  The senderDomain is an override to be used \n    when no domain is supplied, same for the receiverDomain.\n    \n    :param      sender          <str>\n    :param      password        <str>\n    :param      receivers       <list> [ <str>, .. ]\n    :param      body            <str>\n    :param      senderDomain    <str>   \n    :param      receiverDomain  <str>\n    \n    :return     <bool> success\n    \"\"\"\n    import xmpp\n\n    # make sure there is a proper domain as part of the sender \n    if '@' not in sender:\n        sender += '@' + senderDomain\n\n    # create a jabber user connection\n    user = xmpp.protocol.JID(sender)\n\n    # create a connection to an xmpp client\n    client = xmpp.Client(user.getDomain(), debug=[])\n    connection = client.connect(secure=0, use_srv=False)\n    if not connection:\n        text = 'Could not create a connection to xmpp (%s)' % sender\n        err = errors.NotifyError(text)\n        logger.error(err)\n        return False\n\n    # authenticate the session\n    auth = client.auth(user.getNode(), password, user.getResource())\n    if not auth:\n        text = 'Jabber not authenticated: (%s, %s)' % (sender, password)\n        err = errors.NotifyError(text)\n        logger.error(err)\n        return False\n\n    count = 0\n\n    # send the message to the inputted receivers\n    for receiver in receivers:\n        if '@' not in receiver:\n            receiver += '@' + receiverDomain\n\n        # create the message\n        msg = xmpp.protocol.Message(receiver, body)\n\n        # create the html message\n        html_http = {'xmlns': 'http://jabber.org/protocol/xhtml-im'}\n        html_node = xmpp.Node('html', html_http)\n        enc_msg = body.encode('utf-8')\n        xml = '<body xmlns=\"http://www.w3.org/1999/xhtml\">%s</body>' % enc_msg\n        html_node.addChild(node=xmpp.simplexml.XML2Node(xml))\n\n        msg.addChild(node=html_node)\n\n        client.send(msg)\n        count += 1\n\n    return count > 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_entries(self, entries: List[Tuple[str, str]], titles, resources):\n\n        self.entries = []\n        for flag, pagename in entries:\n            title = titles[pagename].children[0]\n            resource = resources.get(pagename, None)\n            if resource and hasattr(resource,\n                                    'is_published') and not \\\n                    resource.is_published:\n                continue\n            # Even if there is no resource for this tocentry, we can\n            # use the toctree info\n            self.entries.append(dict(\n                title=title, href=pagename, resource=resource\n            ))\n\n        self.result_count = len(self.entries)", "response": "Set the template data for the toc entries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, builder, context, sphinx_app: Sphinx):\n\n        context['sphinx_app'] = sphinx_app\n        context['toctree'] = self\n\n        html = builder.templates.render(self.template + '.html', context)\n        return html", "response": "Given a Sphinx builder and context with site in it generate HTML"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef associate_public_ip(self, instance_id, public_ip_id, private_ip=None):\n        return self.driver.associate_public_ip(\n            instance_id, public_ip_id, private_ip)", "response": "Associate a public IP with an external IP"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deprecatedmethod(classname='', info=''):\n\n    def decorated(func):\n        @wraps(func)\n        def wrapped(*args, **kwds):\n            frame = last_frame = None\n            try:\n                frame = inspect.currentframe()\n                last_frame = frame.f_back\n                fname = last_frame.f_code.co_filename\n                func_file = func.func_code.co_filename\n\n                opts = {\n                    'func': func.__name__,\n                    'line': last_frame.f_lineno,\n                    'file': fname,\n                    'class': classname,\n                    'info': info,\n                    'package': projex.packageFromPath(func_file)\n                }\n\n                msg = 'Deprecated method called from %(file)s, line %(line)d.' \\\n                      '\\n  %(package)s.%(class)s.%(func)s is deprecated.' \\\n                      '  %(info)s' % opts\n\n                logger.warning(errors.DeprecatedMethodWarning(msg))\n\n            finally:\n                del frame\n                del last_frame\n\n            return func(*args, **kwds)\n\n        wrapped.__name__ = func.__name__\n\n        wrapped.__doc__ = ':warning  This method is deprecated!  %s\\n\\n' % info\n        if func.__doc__:\n            wrapped.__doc__ += func.__doc__\n\n        wrapped.__dict__.update(func.__dict__)\n        wrapped.__dict__['func_type'] = 'deprecated method'\n\n        return wrapped\n\n    return decorated", "response": "A method that is deprecated."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a profile wrapper around a method to time out all the operations that it runs through. For more information, look into the hotshot Profile documentation online for the built-in Python package. :param sorting <tuple> ( <key>, .. ) :param stripDirs <bool> :param limit <int> :param path <str> :param autoclean <bool> :usage |from projex.decorators import profiler | |class A: | @profiler() # must be called as a method | def increment(amount, count = 1): | return amount + count | |a = A() |a.increment(10) |", "response": "def profiler(sorting=('tottime',), stripDirs=True,\n             limit=20, path='', autoclean=True):\n    \"\"\"\n    Creates a profile wrapper around a method to time out \n    all the  operations that it runs through.  For more \n    information, look into the hotshot Profile documentation \n    online for the built-in Python package.\n    \n    :param      sorting     <tuple> ( <key>, .. )\n    :param      stripDirs   <bool>\n    :param      limit       <int>\n    :param      path        <str>\n    :param      autoclean   <bool>\n    \n    :usage      |from projex.decorators import profiler\n                |\n                |class A:\n                |   @profiler() # must be called as a method\n                |   def increment(amount, count = 1):\n                |       return amount + count\n                |\n                |a = A()\n                |a.increment(10)\n                |\n    \"\"\"\n\n    def decorated(func):\n        \"\"\" Wrapper function to handle the profiling options. \"\"\"\n        # create a call to the wrapping\n        @wraps(func)\n        def wrapped(*args, **kwds):\n            \"\"\" Inner method for calling the profiler method. \"\"\"\n            # define the profile name\n            filename = os.path.join(path, '%s.prof' % func.__name__)\n\n            # create a profiler for the method to run through\n            prof = hotshot.Profile(filename)\n            results = prof.runcall(func, *args, **kwds)\n            prof.close()\n\n            # log the information about it\n            stats = hotshot.stats.load(filename)\n\n            if stripDirs:\n                stats.strip_dirs()\n\n            # we don't want to know about the arguments for this method\n            stats.sort_stats(*sorting)\n            stats.print_stats(limit)\n\n            # remove the file if desired\n            if autoclean:\n                os.remove(filename)\n\n            return results\n\n        return wrapped\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines a decorator method to wrap a method with a retry mechanism. The wrapped method will be attempt to be called the given number of times based on the count value, waiting the number of seconds defined by the sleep parameter. If the throw option is defined, then the given error will be thrown after the final attempt fails. :param count | <int> sleep | <int> | msecs", "response": "def retrymethod(count, sleep=0):\n    \"\"\"\n    Defines a decorator method to wrap a method with a retry mechanism.  The\n    wrapped method will be attempt to be called the given number of times based\n    on the count value, waiting the number of seconds defined by the sleep\n    parameter.  If the throw option is defined, then the given error will\n    be thrown after the final attempt fails.\n    \n    :param      count | <int>\n                sleep | <int> | msecs\n    \"\"\"\n\n    def decorated(func):\n        @wraps(func)\n        def wrapped(*args, **kwds):\n            # do the retry options\n            for i in range(count - 1):\n                try:\n                    return func(*args, **kwds)\n                except StandardError:\n                    pass\n\n                if sleep:\n                    time.sleep(sleep)\n\n            # run as standard\n            return func(*args, **kwds)\n\n        return wrapped\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_server(message_handler, options):\n    logger = logging.getLogger(__name__)\n #   if (options.debug):\n #       logger.setLevel(logging.DEBUG)\n\n#    if not options.monitor_port:\n#        logger.warning(\n#            \"Monitoring not enabled. No monitor-port option defined.\")\n#    else:\n#        threading.Thread(target=launch_monitor_server, args=(options.host, options.monitor_port, logger)).start()\n\n    # Create the server, binding to specified host on configured port\n\n#   logger.info(\n#        'Starting server on host %s port %d Python version %s.%s.%s' % ((options.host, options.port) + sys.version_info[:3]))\n#    server = ThreadedTCPServer((options.host, options.port),\n\n    # Activate the server; this will keep running until you\n    # interrupt the program with Ctrl-C\n    try:\n        while True:\n            logger.debug('waiting for more data')\n            if not message_handler.handle():\n                break\n        logger.warning(\"I/O stream closed from client\")\n\n    except KeyboardInterrupt:\n        logger.info(\"I/O stream closed from client exiting...\")\n        os._exit(142)\n\n    except:\n        logger.exception(\"Error encountered handling message\")", "response": "Launch a server for each message in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the options and exit", "response": "def validate(self, options):\n        \"\"\"\n        Validate the options or exit()\n        \"\"\"\n        try:\n            codecs.getencoder(options.char_encoding)\n        except LookupError:\n            self.parser.error(\"invalid 'char-encoding' %s\" % options.char_encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_code(url):\n    result = urlparse(url)\n    query = parse_qs(result.query)\n    return query['code']", "response": "Parse the code query parameter from the URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a user access token", "response": "def user_token(scopes, client_id=None, client_secret=None, redirect_uri=None):\n    \"\"\"\n    Generate a user access token\n\n    :param List[str] scopes: Scopes to get\n    :param str client_id: Spotify Client ID\n    :param str client_secret: Spotify Client secret\n    :param str redirect_uri: Spotify redirect URI\n    :return: Generated access token\n    :rtype: User\n    \"\"\"\n    webbrowser.open_new(authorize_url(client_id=client_id, redirect_uri=redirect_uri, scopes=scopes))\n    code = parse_code(raw_input('Enter the URL that you were redirected to: '))\n    return User(code, client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef consume_file(self, infile):\n        reader = tag.reader.GFF3Reader(infilename=infile)\n        self.consume(reader)", "response": "Load the specified GFF3 file into memory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a sequence - region directive into memory.", "response": "def consume_seqreg(self, seqreg):\n        \"\"\"Load a :code:`##sequence-region` directive into memory.\"\"\"\n        if not isinstance(seqreg, tag.directive.Directive) or \\\n                seqreg.type != 'sequence-region':\n            raise ValueError('expected ##sequence-region directive')\n        if seqreg.seqid in self.declared_regions:\n            msg = 'duplicate sequence region \"{}\"'.format(seqreg.seqid)\n            raise ValueError(msg)\n        self.declared_regions[seqreg.seqid] = seqreg.range.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a : code. feature. Feature object into memory.", "response": "def consume_feature(self, feature):\n        \"\"\"Load a :code:`Feature` object into memory.\"\"\"\n        if not isinstance(feature, tag.feature.Feature):\n            raise ValueError('expected Feature object')\n        self[feature.seqid][feature.start:feature.end] = feature\n        if feature.seqid not in self.inferred_regions:\n            self.inferred_regions[feature.seqid] = feature._range.copy()\n        newrange = self.inferred_regions[feature.seqid].merge(feature._range)\n        self.inferred_regions[feature.seqid].start = newrange.start\n        self.inferred_regions[feature.seqid].end = newrange.end"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a stream of entries into memory and consume them.", "response": "def consume(self, entrystream):\n        \"\"\"\n        Load a stream of entries into memory.\n\n        Only Feature objects and sequence-region directives are loaded, all\n        other entries are discarded.\n        \"\"\"\n        for entry in entrystream:\n            if isinstance(entry, tag.directive.Directive) and \\\n                    entry.type == 'sequence-region':\n                self.consume_seqreg(entry)\n            elif isinstance(entry, tag.feature.Feature):\n                self.consume_feature(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query(self, seqid, start, end, strict=True):\n        return sorted([\n            intvl.data for intvl in self[seqid].search(start, end, strict)\n        ])", "response": "Query the index for features in the specified range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cli(ctx, stage):\n    if not ctx.bubble:\n        ctx.say_yellow(\n            'There is no bubble present, will not show any transformer functions')\n        raise click.Abort()\n    rule_functions = get_registered_rule_functions()\n    ctx.gbc.say('before loading functions:' + str(len(rule_functions)))\n    load_rule_functions(ctx)\n    ctx.gbc.say('after loading functions:' + str(len(rule_functions)))\n    ctx.gbc.say('rule_functions:', stuff=rule_functions, verbosity=10)\n    rule_functions.set_parent(ctx.gbc)\n    for f in rule_functions:\n        ctx.say('fun: ' + f, verbosity=1)\n    ctx.gbc.say('funs: ', stuff=rule_functions.get_rule_functions(), verbosity=100)\n\n    return True", "response": "Show the functions that are available bubble system and custom."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_utctimestamp(a_datetime):\n    if a_datetime.tzinfo is None:\n        delta = a_datetime - datetime(1970, 1, 1)\n    else:\n        delta = a_datetime - datetime(1970, 1, 1, tzinfo=utc)\n    return delta.total_seconds()", "response": "Convert a datetime object to a UTC time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_utc(a_datetime, keep_utc_tzinfo=False):\n    if a_datetime.tzinfo:\n        utc_datetime = a_datetime.astimezone(utc)  # convert to utc time\n        if keep_utc_tzinfo is False:\n            utc_datetime = utc_datetime.replace(tzinfo=None)\n        return utc_datetime\n    else:\n        return a_datetime", "response": "Convert a time awared datetime to utc datetime."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a UTC datetime to a time awared local time.", "response": "def utc_to_tz(utc_datetime, tzinfo, keep_tzinfo=False):\n    \"\"\"\n    Convert a UTC datetime to a time awared local time\n\n    :param utc_datetime:\n    :param tzinfo:\n    :param keep_tzinfo:\n    \"\"\"\n    tz_awared_datetime = utc_datetime.replace(tzinfo=utc).astimezone(tzinfo)\n    if keep_tzinfo is False:\n        tz_awared_datetime = tz_awared_datetime.replace(tzinfo=None)\n    return tz_awared_datetime"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repr_data_size(size_in_bytes, precision=2):  # pragma: no cover\n    if size_in_bytes < 1024:\n        return \"%s B\" % size_in_bytes\n\n    magnitude_of_data = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"]\n    index = 0\n    while 1:\n        index += 1\n        size_in_bytes, mod = divmod(size_in_bytes, 1024)\n        if size_in_bytes < 1024:\n            break\n    template = \"{0:.%sf} {1}\" % precision\n    s = template.format(size_in_bytes + mod / 1024.0, magnitude_of_data[index])\n    return s", "response": "Return human readable string represent of a file size. Doesn t support\n    size greater than 1EB."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the current slot schema for the current item in the dialogAction.", "response": "def update_slots(self, event):\n        \"\"\"\n        :type lex_input_event: LexInputEvent\n        :return: None\n        \"\"\"\n        if isinstance(event, LexInputEvent):\n            event_slots = event.currentIntent.slots\n        elif isinstance(event, basestring) or isinstance(event, unicode) or isinstance(event, str):\n            event_slots = deepcopy(json.loads(event)['currentIntent']['slots'])\n        else:\n            event_slots = deepcopy(event['currentIntent']['slots'])\n\n        for key, val in event_slots.items():\n            if key not in self.dialogAction.slots._schema.fields:\n                field = Field(key, types.StringType())\n                self.dialogAction.slots._schema.append_field(field)\n            self.dialogAction.slots[key] = val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering the toctree and return the node contents.", "response": "def render_toctrees(kb_app: kb, sphinx_app: Sphinx, doctree: doctree,\n                    fromdocname: str):\n    \"\"\" Look in doctrees for toctree and replace with custom render \"\"\"\n\n    # Only do any of this if toctree support is turned on in KaybeeSettings.\n    # By default, this is off.\n    settings: KaybeeSettings = sphinx_app.config.kaybee_settings\n    if not settings.articles.use_toctree:\n        return\n\n    # Setup a template and context\n    builder: StandaloneHTMLBuilder = sphinx_app.builder\n    env: BuildEnvironment = sphinx_app.env\n\n    # Toctree support. First, get the registered toctree class, if any\n    registered_toctree = ToctreeAction.get_for_context(kb_app)\n    for node in doctree.traverse(toctree):\n        if node.attributes['hidden']:\n            continue\n        custom_toctree = registered_toctree(fromdocname)\n        context = builder.globalcontext.copy()\n        context['sphinx_app'] = sphinx_app\n\n        # Get the toctree entries. We only handle one level of depth for\n        # now. To go further, we need to recurse like sphinx's\n        # adapters.toctree._toctree_add_classes function\n        entries = node.attributes['entries']\n\n        # The challenge here is that some items in a toctree\n        # might not be resources in our \"database\". So we have\n        # to ask Sphinx to get us the titles.\n        custom_toctree.set_entries(entries, env.titles,\n                                   sphinx_app.env.resources)\n        output = custom_toctree.render(builder, context, sphinx_app)\n\n        # Put the output into the node contents\n        listing = [nodes.raw('', output, format='html')]\n        node.replace_self(listing)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stamp_excerpt(kb_app: kb,\n                  sphinx_app: Sphinx,\n                  doctree: doctree):\n    \"\"\" Walk the tree and extract excert into resource.excerpt \"\"\"\n\n    # First, find out which resource this is. Won't be easy.\n    resources = sphinx_app.env.resources\n    confdir = sphinx_app.confdir\n    source = PurePath(doctree.attributes['source'])\n\n    # Get the relative path inside the docs dir, without .rst, then\n    # get the resource\n    docname = str(source.relative_to(confdir)).split('.rst')[0]\n    resource = resources.get(docname)\n\n    if resource:\n        # Stamp the excerpt on the resource\n        excerpt = getattr(resource.props, 'excerpt', False)\n        auto_excerpt = getattr(resource.props, 'auto_excerpt', False)\n        if excerpt:\n            resource.excerpt = excerpt\n        elif not auto_excerpt:\n            resource.excerpt = None\n        else:\n            # Extract the excerpt based on the number of paragraphs\n            # in auto_excerpt\n            resource.excerpt = get_rst_excerpt(doctree, auto_excerpt)", "response": "Stamp the excerpt on the resource. excerpt attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract a bitarray out of a bytes array.", "response": "def bitfieldify(buff, count):\n    \"\"\"Extract a bitarray out of a bytes array.\n\n    Some hardware devices read from the LSB to the MSB, but the bit types available prefer to put pad bits on the LSB side, completely changing the data.\n\n    This function takes in bytes and the number of bits to extract\n    starting from the LSB, and produces a bitarray of those bits.\n\n    \"\"\"\n    databits = bitarray()\n    databits.frombytes(buff)\n    return databits[len(databits)-count:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npads the left side of a bitarray with 0s to align its length with byte boundaries.", "response": "def build_byte_align_buff(bits):\n    \"\"\"Pad the left side of a bitarray with 0s to align its length with byte boundaries.\n\n    Args:\n        bits: A bitarray to be padded and aligned.\n\n    Returns:\n        A newly aligned bitarray.\n    \"\"\"\n    bitmod = len(bits)%8\n    if bitmod == 0:\n        rdiff = bitarray()\n    else:\n        #KEEP bitarray\n        rdiff = bitarray(8-bitmod)\n        rdiff.setall(False)\n    return rdiff+bits"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, name, cidr, **kwargs):\n        return self.driver.create(name, cidr, **kwargs)", "response": "This function will create a user network and a VPC"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the whole word in the string.", "response": "def find_whole_word(w):\n    \"\"\"\n    Scan through string looking for a location where this word produces a match,\n    and return a corresponding MatchObject instance.\n    Return None if no position in the string matches the pattern;\n    note that this is different from finding a zero-length match at some point in the string.\n    \"\"\"\n    return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncollecting postgres scripts from source files.", "response": "def collect_scripts_from_sources(script_paths, files_deployment,  project_path='.', is_package=False, logger=None):\n    \"\"\"\n    Collects postgres scripts from source files\n    :param script_paths: list of strings or a string with a relative path to the directory containing files with scripts\n    :param files_deployment: list of files that need to be harvested. Scripts from there will only be taken\n    if the path to the file is in script_paths\n    :param project_path: path to the project source code\n    :param is_package: are files packaged with pip egg\n    :param logger: pass the logger object if needed\n    :return:\n    \"\"\"\n    logger = logger or logging.getLogger(__name__)\n    scripts_dict = {}\n    if script_paths:\n        if not isinstance(script_paths, list):  # can be list of paths or a string, anyways converted to list\n            script_paths = [script_paths]\n        if is_package:\n            for script_path in script_paths:\n                for file_info in pkg_resources.resource_listdir('pgpm', script_path):\n                    file_content = pkg_resources.resource_string('pgpm', '{0}/{1}'.format(script_path, file_info))\\\n                        .decode('utf-8')\n                    if file_content:\n                        scripts_dict[file_info] = file_content\n                        logger.debug('File {0}/{1} collected.'.format(script_path, file_info))\n                    else:\n                        logger.debug('File {0}/{1} not collected as it\\'s empty.'.format(script_path, file_info))\n        else:\n            if files_deployment:  # if specific script to be deployed, only find them\n                for list_file_name in files_deployment:\n                    list_file_full_path = os.path.join(project_path, list_file_name)\n                    if os.path.isfile(list_file_full_path):\n                        for i in range(len(script_paths)):\n                            if script_paths[i] in list_file_full_path:\n                                file_content = io.open(list_file_full_path, 'r', -1, 'utf-8-sig', 'ignore').read()\n                                if file_content:\n                                    scripts_dict[list_file_name] = file_content\n                                    logger.debug('File {0} collected.'.format(list_file_full_path))\n                                else:\n                                    logger.debug('File {0} not collected as it\\'s empty.'.format(list_file_full_path))\n                    else:\n                        logger.debug('File {0} is not found in any of {1} folders, please specify a correct path'\n                                       .format(list_file_full_path, script_paths))\n            else:\n                for script_path in script_paths:\n                    for subdir, dirs, files in os.walk(script_path):\n                        files = sorted(files)\n                        for file_info in files:\n                            if file_info != settings.CONFIG_FILE_NAME and file_info[0] != '.':\n                                file_content = io.open(os.path.join(subdir, file_info),\n                                                       'r', -1, 'utf-8-sig', 'ignore').read()\n                                if file_content:\n                                    scripts_dict[file_info] = file_content\n                                    logger.debug('File {0} collected'.format(os.path.join(subdir, file_info)))\n                                else:\n                                    logger.debug('File {0} not collected as it\\'s empty.'\n                                                 .format(os.path.join(subdir, file_info)))\n    return scripts_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, fp, headersonly=True):\n        feedparser = FeedParser(self._class)\n        feedparser._set_headersonly()\n\n        try:\n            mp = mmap.mmap(fp.fileno(), 0, access=mmap.ACCESS_READ)\n        except:\n            mp = fp\n\n        data = \"\"\n\n        # While parsing the header we can convert to us-ascii?\n        while True:\n            line = mp.readline()\n            data = data + line.decode(\"us-ascii\")\n            if line == b\"\\n\":\n                break\n        feedparser.feed(data) # mp[0:5000])\n        return feedparser.close()", "response": "Parse the data in a file and return a message structure."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an iterable of literals to an iterable of options.", "response": "def coerce(self, values):\r\n        \"\"\"Convert an iterable of literals to an iterable of options.\r\n\r\n        Args:\r\n            values (iterable or string): An iterable of raw values to convert\r\n            into options. If the value is a string is is assumed to be a\r\n            comma separated list and will be split before processing.\r\n\r\n        Returns:\r\n            iterable: An iterable of option values initialized with the raw\r\n                values from `values`.\r\n\r\n        Raises:\r\n            TypeError: If `values` is not iterable or string.\r\n            TypeError: If the underlying option raises a TypeError.\r\n            ValueError: If the underlying option raises a ValueError.\r\n        \"\"\"\r\n        if isinstance(values, compat.basestring):\r\n\r\n            values = tuple(value.strip() for value in values.split(','))\r\n\r\n        # Create a list of options to store each value.\r\n        opt_iter = tuple(copy.deepcopy(self._option) for value in values)\r\n        for opt_obj, val in compat.zip(opt_iter, values):\r\n\r\n            opt_obj.__set__(None, val)\r\n\r\n        return opt_iter"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, name, default=None):\r\n        option = self._options.get(name, None)\r\n        if option is None:\r\n\r\n            return default\r\n\r\n        return option.__get__(self)", "response": "Fetch an option from the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting an option value.", "response": "def set(self, name, value):\r\n        \"\"\"Set an option value.\r\n\r\n        Args:\r\n            name (str): The name of the option.\r\n            value: The value to set the option to.\r\n\r\n        Raises:\r\n            AttributeError: If the name is not registered.\r\n            TypeError: If the value is not a string or appropriate native type.\r\n            ValueError: If the value is a string but cannot be coerced.\r\n        \"\"\"\r\n        if name not in self._options:\r\n\r\n            raise AttributeError(\"Option {0} does not exist.\".format(name))\r\n\r\n        return self._options[name].__set__(self, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a new option under the namespace.", "response": "def register(self, name, option):\r\n        \"\"\"Register a new option with the namespace.\r\n\r\n        Args:\r\n            name (str): The name to register the option under.\r\n            option (option.Option): The option object to register.\r\n\r\n        Raises:\r\n            TypeError: If the option is not an option.Option object.\r\n            ValueError: If the name is already registered.\r\n        \"\"\"\r\n        if name in self._options:\r\n\r\n            raise ValueError(\"Option {0} already exists.\".format(name))\r\n\r\n        if not isinstance(option, opt.Option):\r\n\r\n            raise TypeError(\"Options must be of type Option.\")\r\n\r\n        self._options[name] = option"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset an option value.", "response": "def set(self, name, value):\r\n        \"\"\"Set an option value.\r\n\r\n        Args:\r\n            name (str): The name of the option.\r\n            value: The value to set the option to.\r\n\r\n        Raises:\r\n            TypeError: If the value is not a string or appropriate native type.\r\n            ValueError: If the value is a string but cannot be coerced.\r\n\r\n        If the name is not registered a new option will be created using the\r\n        option generator.\r\n        \"\"\"\r\n        if name not in self._options:\r\n\r\n            self.register(name, self._generator())\r\n\r\n        return self._options[name].__set__(self, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npulls data from Source Service Client", "response": "def cli(ctx, amount, index, query, stage):\n    \"\"\"Pull data from Source Service Client\"\"\"\n\n    if not ctx.bubble:\n        ctx.say_yellow('There is no bubble present, will not pull')\n        raise click.Abort()\n    STAGE = None\n    SRC = None\n\n    if stage in STAGES and stage in ctx.cfg.CFG:\n        STAGE = ctx.cfg.CFG[stage]\n\n    if not STAGE:\n        ctx.say_red('There is no STAGE in CFG:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                       ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n    if 'SOURCE' in STAGE:\n        SRC = STAGE.SOURCE\n    if not SRC:\n        ctx.say_red('There is no SOURCE in stage:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                       ctx.home + '/config/config.yaml')\n        raise click.Abort()\n    gbc = ctx.GLOBALS['gbc']\n    src_client = get_client(gbc, SRC.CLIENT, ctx.home)\n\n    # TODO: client get error count?\n    # make default counters\n    # client.pull(amount,index,counters)\n    # counter:#Good Bad Ugly: BUG, counters\n    # for this the client must be able to keep stats, or update stats in the pull loop.\n    # bug.counters\n\n    try:\n        sclient = src_client.BubbleClient(cfg=SRC)\n        sclient.set_parent(gbc)\n        sclient.set_verbose(ctx.get_verbose())\n    except Exception as e:\n        ctx.say_red(\n            'cannot create bubble client:' + SRC.CLIENT)\n        ctx.say_red(str(e))\n        raise click.Abort('cannot pull')\n\n    full_data = False\n    if amount == -1 and index == -1:\n        full_data = True\n\n    try:\n        if amount > 0:\n            if index < 0:\n                index = 0\n            pb_label='Pulling %d+%d '% (index,amount)\n            src_data_gen = sclient.pull(amount, index)\n        else:\n            if query:\n                pb_label='Querying:%s' % query\n                src_data_gen = [sclient.query(query)]\n                full_data = False\n            else:\n                pb_label='Pulling all'\n                src_data_gen = sclient.pull()\n    except Exception as e:\n        ctx.say_red('cannot pull from source client: ' + SRC.CLIENT)\n        ctx.say_red(str(e))\n        raise click.Abort('cannot pull')\n    click.echo()\n\n    # TODO: these actually need to be counted someway.\n    # in client,\n    # in storage,\n    # where else?\n    error_count = 0\n\n    with click.progressbar(src_data_gen,\n                           label=pb_label,\n                           show_pos=True,\n                           length=amount,\n                           show_eta=True,\n                           fill_char='\u25d0') as progress_src_data_gen:\n        pfr = bubble_lod_dump(ctx=ctx,\n                          step='pulled',\n                          stage=stage,\n                          full_data=full_data,\n                          reset=True,\n                          data_gen=progress_src_data_gen)\n    ctx.say('pulled [%d] objects' % pfr['total'])\n\n\n    stats = {}\n    stats['pulled_stat_error_count'] = error_count\n    stats['pulled_stat_total_count'] = pfr['total']\n    update_stats(ctx, stage, stats)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetCompressedFilesInDir(fileDir, fileList, ignoreDirList, supportedFormatList = ['.rar',]):\n  goodlogging.Log.Info(\"EXTRACT\", \"Parsing file directory: {0}\".format(fileDir))\n  if os.path.isdir(fileDir) is True:\n    for globPath in glob.glob(os.path.join(fileDir, '*')):\n      if os.path.splitext(globPath)[1] in supportedFormatList:\n        fileList.append(globPath)", "response": "Get all supported files from given directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\narchive all parts of multi - part compressed file.", "response": "def MultipartArchiving(firstPartExtractList, otherPartSkippedList, archiveDir, otherPartFilePath = None):\n  \"\"\"\n  Archive all parts of multi-part compressed file.\n\n  If file has been extracted (via part1) then move all subsequent parts directly to archive directory.\n  If file has not been extracted then if part >1 add to other part skipped list and only archive\n  when the first part is sent for archiving.\n\n  Parameters\n  ----------\n    firstPartExtractList : list\n      File directory to search.\n\n    otherPartSkippedList : list\n      List which any file matches will be added to.\n\n    archiveDir : list\n      List of directories to ignore in recursive lookup (currently unused).\n\n    otherPartFilePath : list [optional : default = None]\n      List of supported file formats to search for.\n  \"\"\"\n  if otherPartFilePath is None:\n    for filePath in list(otherPartSkippedList):\n      MultipartArchiving(firstPartExtractList, otherPartSkippedList, archiveDir, filePath)\n  else:\n    baseFileName = re.findall(\"(.+?)[.]part.+?rar\", otherPartFilePath)[0]\n\n    if baseFileName in firstPartExtractList:\n      util.ArchiveProcessedFile(otherPartFilePath, archiveDir)\n      if otherPartFilePath in otherPartSkippedList:\n        otherPartSkippedList.remove(otherPartFilePath)\n    elif otherPartFilePath not in otherPartSkippedList:\n      otherPartSkippedList.append(otherPartFilePath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets password for rar archive from user input.", "response": "def GetRarPassword(skipUserInput):\n  \"\"\"\n  Get password for rar archive from user input.\n\n  Parameters\n  ----------\n    skipUserInput : boolean\n      Set to skip user input.\n\n  Returns\n  ----------\n    string or boolean\n      If no password is given then returns False otherwise returns user\n      response string.\n  \"\"\"\n  goodlogging.Log.Info(\"EXTRACT\", \"RAR file needs password to extract\")\n  if skipUserInput is False:\n    prompt = \"Enter password, 'x' to skip this file or 'exit' to quit this program: \"\n    response = goodlogging.Log.Input(\"EXTRACT\", prompt)\n    response = util.CheckEmptyResponse(response)\n  else:\n    response = 'x'\n\n  if response.lower() == 'x':\n    goodlogging.Log.Info(\"EXTRACT\", \"File extraction skipped without password\")\n    return False\n  elif response.lower() == 'exit':\n    goodlogging.Log.Fatal(\"EXTRACT\", \"Program terminated by user 'exit'\")\n  else:\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if user has entered password reuse.", "response": "def CheckPasswordReuse(skipUserInput):\n  \"\"\"\n  Check with user for password reuse.\n\n  Parameters\n  ----------\n    skipUserInput : boolean\n      Set to skip user input.\n\n  Returns\n  ----------\n    int\n      Integer from -1 to 2 depending on user response.\n  \"\"\"\n  goodlogging.Log.Info(\"EXTRACT\", \"RAR files needs password to extract\")\n  if skipUserInput is False:\n    prompt = \"Enter 't' to reuse the last password for just this file, \" \\\n             \"'a' to reuse for all subsequent files, \" \\\n             \"'n' to enter a new password for this file \" \\\n             \"or 's' to enter a new password for all files: \"\n    response = goodlogging.Log.Input(\"EXTRACT\", prompt)\n    response = util.ValidUserResponse(response, ('t','a','n','s'))\n  else:\n    response = 'a'\n\n  if response.lower() == 's':\n    return -1\n  if response.lower() == 'n':\n    return 0\n  elif response.lower() == 't':\n    return 1\n  elif response.lower() == 'a':\n    return 2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate through given file list and extract all files matching the file format list from each RAR file. After sucessful extraction move RAR files to archive directory. Parameters ---------- fileList : list List of files to attempt to extract. fileFormatList : list List of file formats to extract from each RAR archive. archiveDir : string Directory to move RAR files once extract is complete. skipUserInput : boolean Set to skip any potential user input (if a single option is available it will be selected otherwise the user input will default to take no action).", "response": "def Extract(fileList, fileFormatList, archiveDir, skipUserInput):\n  \"\"\"\n  Iterate through given file list and extract all files matching the file\n  format list from each RAR file. After sucessful extraction move RAR files to\n  archive directory.\n\n  Parameters\n  ----------\n    fileList : list\n      List of files to attempt to extract.\n\n    fileFormatList : list\n      List of file formats to extract from each RAR archive.\n\n    archiveDir : string\n      Directory to move RAR files once extract is complete.\n\n    skipUserInput : boolean\n      Set to skip any potential user input (if a single option is available\n      it will be selected otherwise the user input will default to take no action).\n  \"\"\"\n  goodlogging.Log.Info(\"EXTRACT\", \"Extracting files from compressed archives\")\n  goodlogging.Log.IncreaseIndent()\n  if len(fileList) == 0:\n    goodlogging.Log.Info(\"EXTRACT\", \"No files to extract\")\n    goodlogging.Log.DecreaseIndent()\n    return None\n\n  firstPartExtractList = []\n  otherPartSkippedList = []\n\n  lastPassword = False\n  reuseLastPassword = 0\n  for filePath in fileList:\n    goodlogging.Log.Info(\"EXTRACT\", \"{0}\".format(filePath))\n    goodlogging.Log.IncreaseIndent()\n    try:\n      rarArchive = rarfile.RarFile(filePath)\n    except ImportError:\n      goodlogging.Log.Info(\"EXTRACT\", \"Unable to extract - Python needs the rarfile package to be installed (see README for more details)\")\n    except rarfile.NeedFirstVolume:\n      goodlogging.Log.Info(\"EXTRACT\", \"File skipped - this is not the first part of the RAR archive\")\n      MultipartArchiving(firstPartExtractList, otherPartSkippedList, archiveDir, filePath)\n    except BaseException as ex:\n      goodlogging.Log.Info(\"EXTRACT\", \"Unable to extract - Exception: {0}\".format(ex))\n    else:\n      dirPath = os.path.dirname(filePath)\n      fileExtracted = False\n      rarAuthentication = True\n\n      if rarArchive.needs_password():\n        if lastPassword and reuseLastPassword in (0, 1):\n          reuseLastPassword = CheckPasswordReuse(skipUserInput)\n\n        if lastPassword and reuseLastPassword in (1, 2):\n          rarArchive.setpassword(lastPassword)\n        else:\n          rarPassword = GetRarPassword(skipUserInput)\n\n          if rarPassword:\n            rarArchive.setpassword(rarPassword)\n            lastPassword = rarPassword\n          else:\n            rarAuthentication = False\n\n      if rarAuthentication:\n        for f in rarArchive.infolist():\n          if util.FileExtensionMatch(f.filename, fileFormatList):\n            goodlogging.Log.Info(\"EXTRACT\", \"Extracting file: {0}\".format(f.filename))\n\n            extractPath = os.path.join(dirPath, f.filename)\n            targetPath = os.path.join(dirPath, os.path.basename(f.filename))\n\n            if os.path.isfile(targetPath):\n              goodlogging.Log.Info(\"EXTRACT\", \"Extraction skipped - file already exists at target: {0}\".format(targetPath))\n              fileExtracted = True\n            elif os.path.isfile(extractPath):\n              goodlogging.Log.Info(\"EXTRACT\", \"Extraction skipped - file already exists at extract directory: {0}\".format(extractPath))\n              fileExtracted = True\n            else:\n              fileExtracted = DoRarExtraction(rarArchive, f, dirPath)\n\n            if os.path.isfile(extractPath) and not os.path.isfile(targetPath):\n              os.rename(extractPath, targetPath)\n              util.RemoveEmptyDirectoryTree(os.path.dirname(extractPath))\n\n      if fileExtracted is True:\n        util.ArchiveProcessedFile(filePath, archiveDir)\n\n        try:\n          firstPartFileName = re.findall('(.+?)[.]part1[.]rar', filePath)[0]\n        except IndexError:\n          pass\n        else:\n          firstPartExtractList.append(firstPartFileName)\n          MultipartArchiving(firstPartExtractList, otherPartSkippedList, archiveDir)\n\n    finally:\n      goodlogging.Log.DecreaseIndent()\n  goodlogging.Log.DecreaseIndent()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inject(function=None, **overridden_names):\n    warnings.warn(\n        (\n            'Module level `inject` decorator has been deprecated and will '\n            'be removed in a future release. '\n            'Use the Injector class instead'\n        ),\n        DeprecationWarning\n    )\n    \n    def decorator(function):        \n        @wraps(function)\n        def wrapper(*args, **kwargs):\n            signature = inspect.signature(function)\n            params = signature.parameters\n            if not params:\n                return function(*args, **kwargs)\n            for name, param in params.items():\n                if param.kind not in (param.KEYWORD_ONLY, param.POSITIONAL_OR_KEYWORD):\n                    continue\n                if name in kwargs:\n                    # Manual override, ignore it\n                    continue\n                try:\n                    resolved_name = overridden_names.get(name, name)\n                    kwargs[name] = manager.get_value(resolved_name)\n                except KeyError:\n                    pass\n            return function(*args, **kwargs)\n        return wrapper\n    if function:\n        return decorator(function)\n    else:\n        return decorator", "response": "Decorator that creates a new object and injects dependencies into given function s arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a dependency function", "response": "def register(self, func, singleton=False, threadlocal=False, name=None):\n        \"\"\"\n        Register a dependency function\n        \"\"\"\n        func._giveme_singleton = singleton\n        func._giveme_threadlocal = threadlocal\n\n        if name is None:\n            name = func.__name__\n        self._registered[name] = func\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_value(self, name):\n        factory = self._registered.get(name)\n        if not factory:\n            raise KeyError('Name not registered')\n        if factory._giveme_singleton:\n            if name in self._singletons:\n                return self._singletons[name]\n            self._singletons[name] = factory()\n            return self._singletons[name]\n        elif factory._giveme_threadlocal:\n            if hasattr(self._threadlocals, name):\n                return getattr(self._threadlocals, name)\n            setattr(self._threadlocals, name, factory())\n            return getattr(self._threadlocals, name)\n        return factory()", "response": "Get a value of a dependency factory or a live singleton instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the msConvert tool on Windows operating systems.", "response": "def execute(filelocation, args, outdir, filters=None,\n            executable='msConvert.exe'):\n    \"\"\"Execute the msConvert tool on Windows operating systems.\n\n    :param filelocation: input file path\n    :param args: str() or list(), msConvert arguments for details see the\n        msConvert help below.\n    :param outdir: path of the output directory\n    :param filters: str() or list(), specify additional parameters and filters,\n        for details see the msConvert help below.\n    :param executable: must specify the complete file path of the msConvert.exe\n        if its location is not in the ``PATH`` environment variable.\n    \"\"\"\n\n    procArgs = [executable, filelocation]\n    procArgs.extend(aux.toList(args))\n    if filters is not None:\n        for arg in aux.toList(filters):\n            procArgs.extend(['--filter', arg])\n    procArgs.extend(['-o', outdir])\n\n    ## run it ##\n    proc = subprocess.Popen(procArgs, stderr=subprocess.PIPE)\n\n    ## But do not wait till netstat finish, start displaying output immediately ##\n    while True:\n        out = proc.stderr.read(1)\n        if out == '' and proc.poll() != None:\n            break\n        if out != '':\n            sys.stdout.write(out)\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the msConvert tool on Windows operating systems.", "response": "def execute(filelocation, outformat, outdir, log=False,\n            executable='RawConverter.exe'):\n    \"\"\"Execute the msConvert tool on Windows operating systems.\n\n    :param filelocation: input file path\n    :param outformat: output format, must be one of the following: ms1, ms2, ms3, mgf\n    :param outdir: path of the output directory\n    :param log: #TODO\n    :param executable: must specify the complete file path of the RawConverter.exe\n        if its location is not in the ``PATH`` environment variable.\n\n    .. note:\n        Specifying the complete path to the executable is probably always\n        necessary because RawConverter looks for the file \"AveragineTable.txt\"\n        in the working directory.\n    \"\"\"\n    assert outformat in ['ms1', 'ms2', 'ms3', 'mgf']\n\n    args = [executable, filelocation, '--'+outformat, '--out_folder', outdir,\n            '--select_mono_prec']\n\n    ## run it ##\n    proc = subprocess.Popen(args, cwd=os.path.dirname(executable),\n                            stderr=subprocess.PIPE)\n\n    ## But do not wait till netstat finish, start displaying output immediately ##\n    while True:\n        out = proc.stderr.read(1)\n        if out == '' and proc.poll() != None:\n            break\n        if out != '':\n            sys.stdout.write(out)\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trace(fun, *a, **k):\n    @wraps(fun)\n    def tracer(*a, **k):\n        ret = fun(*a, **k)\n        print('trace:fun: %s\\n ret=%s\\n a=%s\\nk%s\\n' %\n              (str(fun), str(ret), str(a), str(k)))\n        return ret\n    return tracer", "response": "define a tracer for a rule function\n    for log and statistic purposes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timer(fun, *a, **k):\n    @wraps(fun)\n    def timer(*a, **k):\n        start = arrow.now()\n        ret = fun(*a, **k)\n        end = arrow.now()\n        print('timer:fun: %s\\n start:%s,end:%s, took [%s]' % (\n            str(fun), str(start), str(end), str(end - start)))\n        return ret\n    return timer", "response": "define a timer for a rule function\n    for log and statistic purposes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_function(self, fun=None):\n        sfun = str(fun)\n        self.say('get_function:' + sfun, verbosity=100)\n\n        if not fun:\n            return NoRuleFunction()  # dummy to execute via no_fun\n\n        if sfun in self._rule_functions:\n            return self._rule_functions[sfun]\n        else:\n            self.add_function(name=sfun,\n                              fun=self.rule_function_not_found(fun))\n            self.cry('fun(%s) not found, returning dummy' %\n                     (sfun), verbosity=10)\n            if sfun in self._rule_functions:\n                return self._rule_functions[sfun]\n            else:\n                self.rule_function_not_found(fun)", "response": "get function as RuleFunction or return a NoRuleFunction function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget function s existense", "response": "def function_exists(self, fun):\n        \"\"\" get function's existense \"\"\"\n        res = fun in self._rule_functions\n        self.say('function exists:' + str(fun) + ':' + str(res),\n                 verbosity=10)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rule_function_not_found(self, fun=None):\n        sfun = str(fun)\n        self.cry('rule_function_not_found:' + sfun)\n\n        def not_found(*a, **k):\n            return(sfun + ':rule_function_not_found', k.keys())\n        return not_found", "response": "returns a dummy function that will be added as a\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_elem_type(elem):\n    elem_type = None\n    if isinstance(elem, list):\n        if elem[0].get(\"type\") == \"radio\":\n            elem_type = \"radio\"\n        else:\n            raise ValueError(u\"Unknown element type: {}\".format(elem))\n\n    elif elem.name == \"select\":\n        elem_type = \"select\"\n\n    elif elem.name == \"input\":\n        elem_type = elem.get(\"type\")\n\n    else:\n        raise ValueError(u\"Unknown element type: {}\".format(elem))\n\n    # To be removed\n    assert elem_type is not None\n\n    return elem_type", "response": "Get elem type of soup selection\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the value attribute of the text .", "response": "def get_option_value(elem):\n    \"\"\" Get the value attribute, or if it doesn't exist the text\n        content.\n        <option value=\"foo\">bar</option> => \"foo\"\n        <option>bar</option> => \"bar\"\n        :param elem: a soup element\n    \"\"\"\n    value = elem.get(\"value\")\n    if value is None:\n        value = elem.text.strip()\n    if value is None or value == \"\":\n        msg = u\"Error parsing value from {}.\".format(elem)\n        raise ValueError(msg)\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a value from html", "response": "def parse_value(val):\n    \"\"\" Parse values from html\n    \"\"\"\n    val = val.replace(\"%\", \" \")\\\n        .replace(\" \",\"\")\\\n        .replace(\",\", \".\")\\\n        .replace(\"st\",\"\").strip()\n\n    missing = [\"Ejdeltagit\", \"N/A\"]\n    if val in missing:\n        return val\n    elif val == \"\":\n        return None\n\n    return float(val)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_html(self, url):\n        self.log.info(u\"/GET {}\".format(url))\n        r = requests.get(url)\n        if hasattr(r, 'from_cache'):\n            if r.from_cache:\n                self.log.info(\"(from cache)\")\n\n        if r.status_code != 200:\n            throw_request_err(r)\n\n        return r.content", "response": "Get html from url"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_json(self, url):\n        self.log.info(u\"/GET \" + url)\n        r = requests.get(url)\n        if hasattr(r, 'from_cache'):\n            if r.from_cache:\n                self.log.info(\"(from cache)\")\n        if r.status_code != 200:\n            throw_request_err(r)\n\n        return r.json()", "response": "Get json from url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of all regions in the xml file", "response": "def regions(self):\n        \"\"\" Get a list of all regions\n        \"\"\"\n        regions = []\n        elem = self.dimensions[\"region\"].elem\n        for option_elem in elem.find_all(\"option\"):\n            region = option_elem.text.strip()\n            regions.append(region)\n\n        return regions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the regional slug to be used in url", "response": "def _get_region_slug(self, id_or_label):\n        \"\"\" Get the regional slug to be used in url\n            \"Norrbotten\" => \"Norrbottens\"\n\n            :param id_or_label: Id or label of region\n        \"\"\"\n        #region = self.dimensions[\"region\"].get(id_or_label)\n        region = id_or_label\n        slug = region\\\n            .replace(u\" \",\"-\")\\\n            .replace(u\"\u00f6\",\"o\")\\\n            .replace(u\"\u00d6\",\"O\")\\\n            .replace(u\"\u00e4\",\"a\")\\\n            .replace(u\"\u00e5\",\"a\") + \"s\"\n\n        EXCEPTIONS = {\n            \"Jamtland-Harjedalens\": \"Jamtlands\",\n            \"Rikets\": \"Sveriges\",\n        }\n        if slug in EXCEPTIONS:\n            slug = EXCEPTIONS[slug]\n\n        return slug"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting data from a result page", "response": "def _parse_result_page(self, url, payload, only_region=False):\n        \"\"\" Get data from a result page\n            :param url: url to query\n            :param payload: payload to pass\n            :return: a dictlist with data\n        \"\"\"\n        data = []\n        try:\n\n            if only_region:\n                html = self.scraper._get_html(url)\n            else:\n                html = self.scraper._post_html(url, payload=payload)\n\n        except RequestException500:\n\n            self.scraper.log.warning(u\"Status code 500 on {} with {}\".format(url, payload))\n            return None\n\n\n        current_selection = self._get_current_selection(html)\n\n        table = Datatable(html)\n        data = []\n        for row in table.data:\n            region_or_unit_id, region_or_unit_label = row[\"region_or_unit\"]\n            if region_or_unit_label in self.regions:\n                row[\"region\"] = region_or_unit_label\n                row[\"unit\"] = None\n            else:\n                row[\"region\"] = None\n                row[\"unit\"] = region_or_unit_label\n\n            value = row[\"value\"]\n\n            row.pop(\"value\", None)\n            row.pop(\"region_or_unit\", None)\n\n            for dim in self.dimensions:\n                if dim.id not in row:\n                    row[dim.id] = current_selection[dim.id][1] # gets label\n\n\n\n            data.append(Result(value, row))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the type of the element", "response": "def elem_type(self):\n        \"\"\" :returns: \"select\"|\"radio\"|\"checkbox\"\n        \"\"\"\n        if not hasattr(self, \"_elem_type\"):\n            self._elem_type = get_elem_type(self.elem)\n        return self._elem_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of the measuers of this datatable", "response": "def measures(self):\n        \"\"\" Get a list of the measuers of this datatable\n            Measures can be \"Antal Bes\u00f6k inom 7 dagar\",\n            \"M\u00e5luppfyllelse v\u00e5rdgarantin\", etc\n        \"\"\"\n        if self._measures == None:\n            self._measures = get_unique([x[\"measure\"] for x in self.data])\n\n        return self._measures"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets values from the page.", "response": "def _parse_values(self):\n        \"\"\" Get values\n        \"\"\"\n        data = []\n        if self.has_tabs:\n            def _parse_tab_text(tab):\n                # Annoying html in tabs\n                if tab.select_one(\".visible_normal\"):\n                    return tab.select_one(\".visible_normal\").text\n                else:\n                    return tab.text\n\n            sub_table_ids = [_parse_tab_text(x) for x in self.soup.select(\".table_switch li\")]\n            sub_tables = self.soup.select(\".dataTables_wrapper\")\n            assert len(sub_tables) == len(sub_table_ids)\n            assert len(sub_tables) > 0\n\n            for measure, table in zip(sub_table_ids, sub_tables):\n                if self.has_horizontal_scroll:\n                    _data = self._parse_horizontal_scroll_table(table)\n                    for region, col, value in _data:\n                        data.append({\n                            \"region_or_unit\": region,\n                            \"select_period\": col, # Hardcode warning!\n                            \"measure\": measure,\n                            })\n\n        else:\n            if self.has_horizontal_scroll:\n                raise NotImplementedError()\n\n            if self.has_vertical_scroll:\n                table = self.soup.select_one(\"#DataTables_Table_0_wrapper\")\n                _data = self._parse_vertical_scroll_table(table)\n            else:\n                table = self.soup.select(\".chart.table.scrolling\")[-1]\n                _data = self._parse_regular_table(table)\n\n            for region, measure, value in _data:\n                data.append({\n                    \"region_or_unit\": region,\n                    \"measure\": measure,\n                    \"value\": value\n                })\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_horizontal_scroll_table(self, table_html):\n        row_labels = [parse_text(x.text) for x  in table_html.select(\".DTFC_LeftBodyWrapper tbody tr\")]\n        row_label_ids = [None] * len(row_labels)\n        cols = [parse_text(x.text) for x in table_html.select(\".dataTables_scrollHead th\")]\n        value_rows = table_html.select(\".dataTables_scrollBody tbody tr\")\n\n        values = []\n        for row_i, value_row in enumerate(value_rows):\n            row_values = [parse_value(x.text) for x in value_row.select(\"td\")]\n            values.append(row_values)\n\n        sheet = Sheet(zip(row_label_ids, row_labels), cols, values)\n\n        return sheet.long_format", "response": "Get list of dicts from horizontally scrollable table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_dictlist(self):\n        data = []\n        for row_i, row in enumerate(self.row_index):\n            for col_i, col in enumerate(self.col_index):\n                value = self.values_by_row[row_i][col_i]\n                data.append({\n                    \"row\": row,\n                    \"col\": col,\n                    \"value\": value,\n                    })\n        return data", "response": "Returns a list of dictionaries with values from the row and col indices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the configuration file is JSON format Return a boolean indicating if the file is JSON format or not", "response": "def is_json_file(filename, show_warnings = False):\n    \"\"\"Check configuration file type is JSON\n    Return a boolean indicating wheather the file is JSON format or not\n    \"\"\"\n    try:\n        config_dict = load_config(filename, file_type = \"json\")\n        is_json = True\n    except:\n        is_json = False\n    return(is_json)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_yaml_file(filename, show_warnings = False):\n    if is_json_file(filename):\n        return(False)\n    try:\n        config_dict = load_config(filename, file_type = \"yaml\")\n        if(type(config_dict) == str):\n            is_yaml = False\n        else:\n            is_yaml = True\n    except:\n        is_yaml = False\n    return(is_yaml)", "response": "Check if the configuration file is yaml format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_ini_file(filename, show_warnings = False):\n    try:\n        config_dict = load_config(filename, file_type = \"ini\")\n        if config_dict == {}:\n            is_ini = False\n        else:\n            is_ini = True\n    except:\n        is_ini = False\n    return(is_ini)", "response": "Check if the configuration file is INI format Return a boolean indicating if the file is INI format or not\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_toml_file(filename, show_warnings = False):\n    if is_yaml_file(filename):\n        return(False)\n    try:\n        config_dict = load_config(filename, file_type = \"toml\")\n        is_toml = True\n    except:\n        is_toml = False\n    return(is_toml)", "response": "Check if the given file is TOML format Return a boolean indicating if the file is TOML format or not\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config_type(filename):\n    if is_json_file(filename):\n        return(\"json\")\n    elif is_ini_file(filename):\n        return(\"ini\")\n    elif is_yaml_file(filename):\n        return(\"yaml\")\n    elif is_toml_file(filename):\n        return(\"toml\")\n    else:\n        return(False)", "response": "Get the configuration file type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(keystorerc=None, keystore=None, copyto=None, verbose=False):\n  '''decrypt and write out a keystore'''\n\n  config = None\n  if keystorerc:\n    config = config_reader.read(keystorerc)\n    if not config:\n      print('No configuration found.', file=sys.stderr)\n      sys.exit(-1)\n  elif keystore:\n    config = {\n      'keystore': keystore,\n      'files': []\n    }\n\n  if 'verbose' in config and config['verbose']:\n    verbose = True\n\n  keystore_path = None\n  if 'keystore' not in config:\n    print('.keystorerc needs to specify a keystore file path.', file=sys.stderr)\n    sys.exit(-1)\n  elif not pathlib.Path(os.path.expanduser(config['keystore'])).is_file():\n    # If keystore file does not exist, nothing to load and exits\n    print('keystore does not exist: {}'.format(config['keystore']), file=sys.stderr)\n    sys.exit(-1)\n  else:\n    keystore_path = config['keystore']\n\n  if copyto and not pathlib.Path(os.path.expanduser(copyto)).is_dir():\n    print('The folder to copy to does not exist: {}'.format(copyto), file=sys.stderr)\n    sys.exit(-1)\n\n  # load and attempt to unencrypt keystore by passphrase\n\n  encrypted_keystore = None\n  try:\n    with open(os.path.expanduser(keystore_path), 'rb') as keystore_file:\n      encrypted_keystore = keystore_file.read()\n\n    if verbose: print('Located encrypted keystore at {}.'.format(keystore_path))\n\n    decrypted = False\n    decrypted_keystore = None\n    while not decrypted:\n      try:\n        passphrase = getpass.getpass('Please enter the passphrase: ')\n        decrypted_keystore = simplecrypt.decrypt(passphrase, encrypted_keystore)\n        decrypted = True\n      except simplecrypt.DecryptionException as err:\n        print('Invalid passphrase. Please try again.')\n      except UnicodeDecodeError as err:\n        print('Keyring cannot be decrypted.\\nError: {}'.format(err), file=sys.stderr)\n        sys.exit(-1)\n\n  except OSError as err:\n    print('keystore cannot be opened: {}'.format(err), file=sys.stderr)\n    sys.exit(-1)\n\n  # attempt to uncompress the keystore\n\n  decompressed_keystore = gzip.decompress(decrypted_keystore)\n\n  # attempt to unserialise the keystore\n\n  try:\n    keystore = json.loads(decompressed_keystore)\n  except json.decoder.JSONDecodeError as err:\n    print('Please contact the author about this as this is a serious problem. {}'.format(err), file=sys.stderr)\n    sys.exit(-1)\n\n  if verbose: print('Keystore decrypted successfully.')\n\n  count = 0\n  for filepath, key in keystore.items():\n    expanded_filepath = os.path.expanduser(filepath)\n    if copyto:\n      expanded_filepath = os.path.join(copyto, os.path.basename(filepath))\n\n    confirmed = False\n    overwrite = False\n    if not pathlib.Path(expanded_filepath).exists():\n      confirmed = True\n      overwrite = True\n\n    while not confirmed:\n      overwrite = input('File {} exists. Are you sure you want to overwrite? (y)/n: '.format(expanded_filepath))\n      if overwrite == '' or overwrite == 'y' or overwrite == 'Y':\n        overwrite = True\n        confirmed = True\n      elif overwrite == 'n' or overwrite == 'N':\n        overwrite = False\n        confirmed = True\n      else:\n        print('Please enter y or n.')\n    if not overwrite:\n      continue\n\n    # key ready to be created\n    if verbose: print('Writing key to {} ...'.format(expanded_filepath))\n    try:\n      with open(expanded_filepath, 'wb') as keyfile:\n        b64_decoded = base64.decodebytes(key.encode('utf-8'))\n        keyfile.write(b64_decoded)\n      count += 1\n    except OSError as err:\n      print('File system threw an error: {}'.format(err), file=sys.stderr)\n      print('Skipping {}'.format(expanded_filepath))\n\n  if verbose: print('Keystore restored {} keys.'.format(count))", "response": "decrypt and write out a keystore"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over given apps or INSTALLED_APPS and collect the content of each s settings file.", "response": "def _collect_settings(self, apps):\n        \"\"\"\n        Iterate over given apps or INSTALLED_APPS and collect the content of each's\n        settings file, which is expected to be in JSON format.\n        \"\"\"\n        contents = {}\n        if apps:\n            for app in apps:\n                if app not in settings.INSTALLED_APPS:\n                    raise CommandError(\"Application '{0}' not in settings.INSTALLED_APPS\".format(app))\n        else:\n            apps = settings.INSTALLED_APPS\n        for app in apps:\n            module = import_module(app)\n            for module_dir in module.__path__:\n                json_file = os.path.abspath(os.path.join(module_dir, self.json_file))\n                if os.path.isfile(json_file):\n                    with open(json_file, 'r') as fp:\n                        contents[app] = json.load(fp)\n        return contents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef item_by_name(self, name):\n        for obj in self.items:\n            if obj.metadata.name == name:\n                return obj\n        raise KeyError(name)", "response": "Find an item in this collection by its name metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding the available dimensions for the given dataset.", "response": "def _fetch_dimensions(self, dataset):\n        \"\"\" Declaring available dimensions like this is not mandatory,\n         but nice, especially if they differ from dataset to dataset.\n\n         If you are using a built in datatype, you can specify the dialect\n         you are expecting, to have values normalized. This scraper will\n         look for Swedish month names (e.g. 'Januari'), but return them\n         according to the Statscraper standard ('january').\n        \"\"\"\n        yield Dimension(u\"date\", label=\"Day of the month\")\n        yield Dimension(u\"month\", datatype=\"month\", dialect=\"swedish\")\n        yield Dimension(u\"year\", datatype=\"year\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a merged dictionary from cls bases attribute attr_name. MRO defines importance.", "response": "def _dct_from_mro(cls: type, attr_name: str) -> dict:\n    \"\"\"\"Get a merged dictionary from `cls` bases attribute `attr_name`. MRO defines importance (closest = strongest).\"\"\"\n    d = {}\n    for c in reversed(cls.mro()):\n        d.update(getattr(c, attr_name, {}))\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a mapping where values are iterables yield items whose values are not used as keys first", "response": "def _sorted_items(mapping: typing.Mapping) -> typing.Generator:\n    \"\"\"Given a mapping where values are iterables, yield items whose values contained references are not used as\n    keys first:\n\n    Example:\n        >>> dct = {'two': ('two', 'one', 'foo'), 'one': ('hi', 'six', 'net'), 'six': ('three', 'four'), 'foo': ['bar']}\n        >>> for k, v in _sorted_items(dct):\n        ...     print(k, v)\n        ...\n        six ('three', 'four')\n        foo ['bar']\n        one ('hi', 'six', 'net')\n        two ('two', 'one', 'foo')\n    \"\"\"\n    to_yield = set(mapping)\n    while to_yield:\n        for key, values in mapping.items():\n            if key not in to_yield or (to_yield - {key} & set(values)):  # other keys left to yield before this one\n                continue\n            yield key, values\n            to_yield.remove(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_name_core(self, name: str):\n        self.__regex = re.compile(rf'^{self._pattern}$')\n        self.name = name", "response": "Runs whenever a new instance is initialized or sep is set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef values(self) -> typing.Dict[str, str]:\n        return {k: v for k, v in self._items if v is not None}", "response": "The field values of this object s name as a dictionary in the form of key - > value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a new name string from this object s name values.", "response": "def get_name(self, **values) -> str:\n        \"\"\"Get a new name string from this object's name values.\n\n        :param values: Variable keyword arguments where the **key** should refer to a field on this object that will\n                       use the provided **value** to build the new name.\n        \"\"\"\n        if not values and self.name:\n            return self.name\n        if values:\n            # if values are provided, solve compounds that may be affected\n            for ck, cvs in _sorted_items(self.compounds):\n                if ck in cvs and ck in values:  # redefined compound name to outer scope e.g. fifth = (fifth, sixth)\n                    continue\n                comp_values = [values.pop(cv, getattr(self, cv)) for cv in cvs]\n                if None not in comp_values:\n                    values[ck] = ''.join(rf'{v}' for v in comp_values)\n        return self._get_nice_name(**values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cast_config(cls, config: typing.Mapping[str, str]) -> typing.Dict[str, str]:\n        return {k: cls.cast(v, k) for k, v in config.items()}", "response": "Cast config to grouped regular expressions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute_primitives(self, commands):\n        for p in commands:\n            if self._scanchain and self._scanchain._debug:\n                print(\"  Executing\", p)#pragma: no cover\n            p.execute(self)", "response": "Execute a list of executable primitives on this controller and distribute the returned data to the associated TDOPromises."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn pretty version text listing all storage brokers and plugins.", "response": "def pretty_version_text():\n    \"\"\"Return pretty version text listing all plugins.\"\"\"\n    version_lines = [\"dtool, version {}\".format(dtool_version)]\n    version_lines.append(\"\\nBase:\")\n    version_lines.append(\"dtoolcore, version {}\".format(dtoolcore.__version__))\n    version_lines.append(\"dtool-cli, version {}\".format(__version__))\n\n    # List the storage broker packages.\n    version_lines.append(\"\\nStorage brokers:\")\n    for ep in iter_entry_points(\"dtool.storage_brokers\"):\n        package = ep.module_name.split(\".\")[0]\n        dyn_load_p = __import__(package)\n        version = dyn_load_p.__version__\n        storage_broker = ep.load()\n        version_lines.append(\n            \"{}, {}, version {}\".format(\n                storage_broker.key,\n                package.replace(\"_\", \"-\"),\n                version))\n\n    # List the plugin packages.\n    modules = [ep.module_name for ep in iter_entry_points(\"dtool.cli\")]\n    packages = set([m.split(\".\")[0] for m in modules])\n    version_lines.append(\"\\nPlugins:\")\n    for p in packages:\n        dyn_load_p = __import__(p)\n        version_lines.append(\n            \"{}, version {}\".format(\n                p.replace(\"_\", \"-\"),\n                dyn_load_p.__version__))\n\n    return \"\\n\".join(version_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dtool(debug):\n    level = logging.WARNING\n    if debug:\n        level = logging.DEBUG\n    logging.basicConfig(\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        level=level)", "response": "Tool to work with datasets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_nic(self, instance_id, net_id):\n        #TODO: upgrade with port_id and fixed_ip in future\n        self.client.servers.interface_attach(\n            instance_id, None, net_id, None)\n        return True", "response": "Add a Network Interface Controller to the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a Network Interface Controller", "response": "def delete_nic(self, instance_id, port_id):\n        \"\"\"Delete a Network Interface Controller\"\"\"\n        self.client.servers.interface_detach(instance_id, port_id)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_nic(self, instance_id):\n        #NOTE: interfaces a list of novaclient.v2.servers.Server\n        interfaces = self.client.servers.interface_list(instance_id)\n        return interfaces", "response": "List all Network Interface Controller"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassociate a public IP with a server", "response": "def associate_public_ip(self, instance_id, public_ip_id, private_ip=None):\n        \"\"\"Associate a external IP\"\"\"\n        floating_ip = self.client.floating_ips.get(public_ip_id)\n        floating_ip = floating_ip.to_dict()\n        address = floating_ip.get('ip')\n\n        self.client.servers.add_floating_ip(instance_id, address, private_ip)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisassociates a external IP", "response": "def disassociate_public_ip(self, public_ip_id):\n        \"\"\"Disassociate a external IP\"\"\"\n        floating_ip = self.client.floating_ips.get(public_ip_id)\n        floating_ip = floating_ip.to_dict()\n        instance_id = floating_ip.get('instance_id')\n        address = floating_ip.get('ip')\n\n        self.client.servers.remove_floating_ip(instance_id, address)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a promise into two promises at the specified index.", "response": "def split(self, bitindex):\n        \"\"\"Split a promise into two promises at the provided index.\n\n        A common operation in JTAG is reading/writing to a\n        register. During the operation, the TMS pin must be low, but\n        during the writing of the last bit, the TMS pin must be\n        high. Requiring all reads or writes to have full arbitrary\n        control over the TMS pin is unrealistic.\n\n        Splitting a promise into two sub promises is a way to mitigate\n        this issue. The final read bit is its own subpromise that can\n        be associated with a different primitive than the 'rest' of\n        the subpromise.\n\n        Returns:\n            Two TDOPromise instances: the 'Rest' and the 'Tail'.\n            The 'Rest' is the first chunk of the original promise.\n            The 'Tail' is a single bit sub promise for the final bit\n              in the operation\n\n            If the 'Rest' would have a length of 0, None is returned\n\n        \"\"\"\n        if bitindex < 0:\n            raise ValueError(\"bitindex must be larger or equal to 0.\")\n        if bitindex > len(self):\n            raise ValueError(\n                \"bitindex larger than the array's size. \"\n                \"Len: %s; bitindex: %s\"%(len(self), bitindex))\n\n        if bitindex == 0:\n            return None, self\n        if bitindex == len(self):\n            return self, None\n\n        left = TDOPromise(self._chain, self._bitstart, bitindex,\n                          _parent=self)\n        #Starts at 0 because offset is for incoming data from\n        #associated primitive, not location in parent.\n        right = TDOPromise(self._chain, 0, len(self)-bitindex,\n                          _parent=self)\n        self._components = []\n        self._addsub(left, 0)\n        self._addsub(right, bitindex)\n        return left, right"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsupplying the promise with the bits from its associated primitive s execution.", "response": "def _fulfill(self, bits, ignore_nonpromised_bits=False):\n        \"\"\"Supply the promise with the bits from its associated primitive's execution.\n\n        The fulfillment process must walk the promise chain backwards\n        until it reaches the original promise and can supply the final\n        value.\n\n        The data that comes in can either be all a bit read for every\n        bit written by the associated primitive, or (if the primitive\n        supports it), only the bits that are used by promises. The\n        ignore_nonpromised_bits flag specifies which format the\n        incoming data is in.\n\n        Args:\n            bits: A bitarray (or compatible) containing the data read from the jtag controller's TDO pin.\n            ignore_nonpromised_bits: A boolean specifying if only promised bits are being returned (and thus the 2nd index of the promise must be used for slicing the incoming data).\n\n        \"\"\"\n        if self._allsubsfulfilled():\n            if not self._components:\n                if ignore_nonpromised_bits:\n                    self._value = bits[self._bitstartselective:\n                                       self._bitstartselective +\n                                       self._bitlength]\n                else:\n                    self._value = bits[self._bitstart:self._bitend]\n            else:\n                self._value = self._components[0][0]._value\n                for sub, offset in self._components[1:]:\n                    self._value += sub._value\n            if self._parent is not None:\n                self._parent._fulfill(None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makesubatoffset(self, bitoffset, *, _offsetideal=None):\n        if _offsetideal is None:\n            _offsetideal = bitoffset\n        if bitoffset is 0:\n            return self\n        newpromise = TDOPromise(\n            self._chain,\n            self._bitstart + bitoffset,\n            self._bitlength,\n            _parent=self,\n            bitstartselective=self._bitstartselective+_offsetideal\n        )\n        self._addsub(newpromise, 0)\n        return newpromise", "response": "Create a copy of this promise with an offset and use it as this promise s child."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, promise, bitoffset, *, _offsetideal=None):\n        #This Assumes that things are added in order.\n        #Sorting or checking should likely be added.\n        if _offsetideal is None:\n            _offsetideal = bitoffset\n        if isinstance(promise, TDOPromise):\n            newpromise = promise.makesubatoffset(\n                bitoffset, _offsetideal=_offsetideal)\n            self._promises.append(newpromise)\n        elif isinstance(promise, TDOPromiseCollection):\n            for p in promise._promises:\n                self.add(p, bitoffset, _offsetideal=_offsetideal)", "response": "Adds a promise to the promise collection at an optional offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef makesubatoffset(self, bitoffset, *, _offsetideal=None):\n        if _offsetideal is None:\n            _offsetideal = bitoffset\n        if bitoffset is 0:\n            return self\n        newpromise = TDOPromiseCollection(self._chain)\n        for promise in self._promises:\n            newpromise.add(promise, bitoffset, _offsetideal=_offsetideal)\n        return newpromise", "response": "Create a copy of this collection with an offset applied to each contained promise and register each with their parent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking JIRA REST call", "response": "def call_jira_rest(self, url, user, password, method=\"GET\", data=None):\n        \"\"\"\n        Make JIRA REST call\n        :param data: data for rest call\n        :param method: type of call: GET or POST for now\n        :param url: url to call\n        :param user: user for authentication\n        :param password: password for authentication\n        :return:\n        \"\"\"\n        headers = {'content-type': 'application/json'}\n\n        self._logger.debug('Connecting to Jira to call the following REST method {0}'.format(url))\n        if method == \"GET\":\n            response = requests.get(self.base_url + url, auth=requests.auth.HTTPBasicAuth(user, password))\n        elif method == \"POST\":\n            response = requests.post(self.base_url + url, data=json.dumps(data),\n                                     auth=requests.auth.HTTPBasicAuth(user, password), headers=headers)\n        else:\n            raise ValueError('method argument supports GET or POST values only')\n        self._logger.debug('REST call successfully finalised')\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connectExec(connection, protocol, commandLine):\n    deferred = connectSession(connection, protocol)\n    @deferred.addCallback\n    def requestSubsystem(session):\n        return session.requestExec(commandLine)\n    return deferred", "response": "Connect a Protocol to a ssh exec session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connectShell(connection, protocol):\n    deferred = connectSession(connection, protocol)\n    @deferred.addCallback\n    def requestSubsystem(session):\n        return session.requestShell()\n    return deferred", "response": "Connect a Protocol to a ssh shell session"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connectSubsystem(connection, protocol, subsystem):\n    deferred = connectSession(connection, protocol)\n    @deferred.addCallback\n    def requestSubsystem(session):\n        return session.requestSubsystem(subsystem)\n    return deferred", "response": "Connect a Protocol to a ssh subsystem channel"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening a SSHSession channel and connect a Protocol to it", "response": "def connectSession(connection, protocol, sessionFactory=None, *args, **kwargs):\n    \"\"\"Open a SSHSession channel and connect a Protocol to it\n\n    @param connection: the SSH Connection to open the session channel on\n    @param protocol: the Protocol instance to connect to the session\n    @param sessionFactory: factory method to generate a SSHSession instance\n    @note: :args: and :kwargs: are passed to the sessionFactory\n    \"\"\"\n    factory = sessionFactory or defaultSessionFactory\n    session = factory(*args, **kwargs)\n    session.dataReceived = protocol.dataReceived\n    session.closed = lambda: protocol.connectionLost(connectionDone)\n\n    deferred = defer.Deferred()\n    @deferred.addCallback\n    def connectProtocolAndReturnSession(specificData):\n        protocol.makeConnection(session)\n        return session\n    session.sessionOpen = deferred.callback\n    session.openFailed = deferred.errback\n\n    connection.openChannel(session)\n\n    return deferred"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef defaultSessionFactory(env={}, usePTY=False, *args, **kwargs):\n    return SSHSession(env, usePTY, *args, **kwargs)", "response": "Create a default SSHSession instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrequesting execution of the specified commandLine and return a deferred reply.", "response": "def requestExec(self, commandLine):\n        \"\"\"Request execution of :commandLine: and return a deferred reply.\n        \"\"\"\n        data = common.NS(commandLine)\n        return self.sendRequest('exec', data, wantReply=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequest a subsystem and return a deferred reply.", "response": "def requestSubsystem(self, subsystem):\n        \"\"\"Request a subsystem and return a deferred reply.\n        \"\"\"\n        data = common.NS(subsystem)\n        return self.sendRequest('subsystem', data, wantReply=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting a pseudo - terminal allocation for a channel.", "response": "def requestPty(self, term=None, rows=0, cols=0, xpixel=0, ypixel=0, modes=''):\n        \"\"\"Request allocation of a pseudo-terminal for a channel\n\n        @param term: TERM environment variable value (e.g., vt100)\n        @param columns: terminal width, characters (e.g., 80)\n        @param rows: terminal height, rows (e.g., 24)\n        @param width: terminal width, pixels (e.g., 640)\n        @param height: terminal height, pixels (e.g., 480)\n        @param modes: encoded terminal modes\n\n        The dimension parameters are only informational.\n        Zero dimension parameters are ignored. The columns/rows dimensions\n        override the pixel dimensions (when nonzero). Pixel dimensions refer\n        to the drawable area of the window.\n        \"\"\"\n        #TODO: Needs testing!\n        term = term or os.environ.get('TERM', '')\n        data = packRequest_pty_req(term, (rows, cols, xpixel, ypixel), modes)\n        return self.sendRequest('pty-req', data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending the environment variables to the channel", "response": "def requestEnv(self, env={}):\n        \"\"\"Send requests to set the environment variables for the channel\n        \"\"\"\n        for variable, value in env.items():\n            data = common.NS(variable) + common.NS(value)\n            self.sendRequest('env', data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commandstr(command):\n    if command == CMD_MESSAGE_ERROR:\n        msg = \"CMD_MESSAGE_ERROR\"\n    elif command == CMD_MESSAGE_LIST:\n        msg = \"CMD_MESSAGE_LIST\"\n    elif command == CMD_MESSAGE_PASSWORD:\n        msg = \"CMD_MESSAGE_PASSWORD\"\n    elif command == CMD_MESSAGE_MP3:\n        msg = \"CMD_MESSAGE_MP3\"\n    elif command == CMD_MESSAGE_DELETE:\n        msg = \"CMD_MESSAGE_DELETE\"\n    elif command == CMD_MESSAGE_VERSION:\n        msg = \"CMD_MESSAGE_VERSION\"\n    elif command == CMD_MESSAGE_CDR_AVAILABLE:\n        msg = \"CMD_MESSAGE_CDR_AVAILABLE\"\n    elif command == CMD_MESSAGE_CDR:\n        msg = \"CMD_MESSAGE_CDR\"\n    else:\n        msg = \"CMD_MESSAGE_UNKNOWN\"\n    return msg", "response": "Convert command into string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncommanding for reflection database objects", "response": "def run():\n    \"\"\"Command for reflection database objects\"\"\"\n    parser = OptionParser(\n        version=__version__, description=__doc__,\n    )\n\n    parser.add_option(\n        '-u', '--url', dest='url',\n        help='Database URL (connection string)',\n    )\n\n    parser.add_option(\n        '-r', '--render', dest='render', default='dot',\n        choices=['plantuml', 'dot'],\n        help='Output format - plantuml or dot',\n    )\n\n    parser.add_option(\n        '-l', '--list', dest='list', action='store_true',\n        help='Output database list of tables and exit',\n    )\n\n    parser.add_option(\n        '-i', '--include', dest='include',\n        help='List of tables to include through \",\"',\n    )\n\n    parser.add_option(\n        '-e', '--exclude', dest='exclude',\n        help='List of tables to exlude through \",\"',\n    )\n\n    (options, args) = parser.parse_args()\n\n    if not options.url:\n        print('-u/--url option required')\n        exit(1)\n\n    engine = create_engine(options.url)\n    meta = MetaData()\n\n    meta.reflect(bind=engine)\n\n    if options.list:\n        print('Database tables:')\n        tables = sorted(meta.tables.keys())\n\n        def _g(l, i):\n            try:\n                return tables[i]\n            except IndexError:\n                return ''\n\n        for i in range(0, len(tables), 2):\n            print(' {0}{1}{2}'.format(\n                _g(tables, i),\n                ' ' * (38 - len(_g(tables, i))),\n                _g(tables, i + 1),\n            ))\n\n        exit(0)\n\n    tables = set(meta.tables.keys())\n\n    if options.include:\n        tables &= set(map(string.strip, options.include.split(',')))\n\n    if options.exclude:\n        tables -= set(map(string.strip, options.exclude.split(',')))\n\n    desc = describe(map(lambda x: operator.getitem(meta.tables, x), tables))\n    print(getattr(render, options.render)(desc))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_poll(poll_id):\n    return StrawPoll(requests.get('{api_url}/{poll_id}'.format(api_url=api_url, poll_id=poll_id)))", "response": "Get a strawpoll object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_poll(title, options, multi=True, permissive=True, captcha=False, dupcheck='normal'):\n    query = {\n        'title': title,\n        'options': options,\n        'multi': multi,\n        'permissive': permissive,\n        'captcha': captcha,\n        'dupcheck': dupcheck\n    }\n    return StrawPoll(requests.post('http://strawpoll.me/api/v2/polls', data=json.dumps(query)))", "response": "Create a new poll object with the given title options multi permissive and captcha options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef raise_status(response):\n    if response.status_code != 200:\n        if response.status_code == 401:\n            raise StrawPollException('Unauthorized', response)\n        elif response.status_code == 403:\n            raise StrawPollException('Forbidden', response)\n        elif response.status_code == 404:\n            raise StrawPollException('Not Found', response)\n        else:\n            response.raise_for_status()", "response": "Raise an exception if the request did not return a status code of 200."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refresh(self):\n        strawpoll_response = requests.get('{api_url}/{poll_id}'.format(api_url=api_url, poll_id=self.id))\n        raise_status(strawpoll_response)\n        self.status_code = strawpoll_response.status_code\n        self.response_json = strawpoll_response.json()\n        self.id = self.response_json['id']\n        self.title = self.response_json['title']\n        self.options = self.response_json['options']\n        self.votes = self.response_json['votes']\n        self.captcha = self.response_json['captcha']\n        self.dupcheck = self.response_json['dupcheck']\n        self.url = 'https://www.strawpoll.me/{id}'.format(id=self.id)\n        self.results_url = 'https://www.strawpoll.me/{id}/r'.format(id=self.id)", "response": "Refresh all class attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_json_file(self, path):\n        with open(path, \"w\") as f:\n            f.write(self.to_json())", "response": "Serialize this VariantCollection to a JSON representation and write it out to a text file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a VariantCollection from a JSON file.", "response": "def read_json_file(cls, path):\n        \"\"\"\n        Construct a VariantCollection from a JSON file.\n        \"\"\"\n        with open(path, 'r') as f:\n            json_string = f.read()\n        return cls.from_json(json_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_from(data):\n    try:\n        module, klass_name = data['__class__'].rsplit('.', 1)\n        klass = getattr(import_module(module), klass_name)\n    except (ImportError, AttributeError, KeyError):\n        # But I still haven't found what I'm looking for\n        #\n        # Waiting for three different exceptions here. KeyError will\n        # raise if can't find the \"__class__\" entry in the json `data`\n        # dictionary. ImportError happens when the module present in the\n        # dotted name can't be resolved. Finally, the AttributeError\n        # happens when we can find the module, but couldn't find the\n        # class on it.\n        return data\n    return deserialize(klass, data['__value__'])", "response": "Internal function that will be hooked to the native json. loads method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _converter(data):\n    handler = REGISTRY.get(data.__class__)\n    if handler:\n        full_name = '{}.{}'.format(\n            data.__class__.__module__,\n            data.__class__.__name__)\n        return {\n            '__class__': full_name,\n            '__value__': handler(data),\n        }\n    raise TypeError(repr(data) + \" is not JSON serializable\")", "response": "Internal function that will be passed to the native json. dumps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the response bot.", "response": "def start(self):\n        \"\"\"\n        Try to init the main sub-components (:func:`~responsebot.utils.handler_utils.discover_handler_classes`, \\\n        :func:`~responsebot.utils.auth_utils.auth`, :class:`~responsebot.responsebot_stream.ResponseBotStream`, etc.)\n        \"\"\"\n        logging.info('ResponseBot started')\n\n        handler_classes = handler_utils.discover_handler_classes(self.config.get('handlers_package'))\n        if len(handler_classes) == 0:\n            logging.warning('No handler found. Did you forget to extend BaseTweethandler? Check --handlers-module')\n\n        while True:\n            try:\n                client = auth_utils.auth(self.config)\n\n                listener = ResponseBotListener(client=client, handler_classes=handler_classes)\n\n                stream = ResponseBotStream(client=client, listener=listener)\n                stream.start()\n            except (APIQuotaError, AuthenticationError, TweepError) as e:\n                self.handle_error(e)\n            else:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle an error and return the error_log.", "response": "def handle_error(self, error):\n        \"\"\"\n        Try to detect repetitive errors and sleep for a while to avoid being marked as spam\n        \"\"\"\n        logging.exception(\"try to sleep if there are repeating errors.\")\n        error_desc = str(error)\n        now = datetime.datetime.now()\n        if error_desc not in self.error_time_log:\n            self.error_time_log[error_desc] = now\n            return\n\n        time_of_last_encounter = self.error_time_log[str(error)]\n        time_since_last_encounter = now - time_of_last_encounter\n        if time_since_last_encounter.total_seconds() > self.config.get('min_seconds_between_errors'):\n            self.error_time_log[error_desc] = now\n            return\n\n        if error_desc not in self.error_sleep_log:\n            time.sleep(self.config.get('sleep_seconds_on_consecutive_errors'))\n            self.error_sleep_log[error_desc] = 1\n        else:\n            sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a string that loosely fits ISO 8601 formatted date - time string", "response": "def parse_isodate(datestr):\n    \"\"\"Parse a string that loosely fits ISO 8601 formatted date-time string\n    \"\"\"\n    m = isodate_rx.search(datestr)\n    assert m, 'unrecognized date format: ' + datestr\n    year, month, day = m.group('year', 'month', 'day')\n    hour, minute, second, fraction = m.group('hour', 'minute', 'second', 'fraction')\n    tz, tzhh, tzmm = m.group('tz', 'tzhh', 'tzmm')\n    dt = datetime.datetime(int(year), int(month), int(day), int(hour))\n    if fraction is None:\n        fraction = 0\n    else:\n        fraction = float('0.' + fraction)\n    if minute is None:\n        dt = dt.replace(minute=int(60 * fraction))\n    else:\n        dt = dt.replace(minute=int(minute))\n        if second is None:\n            dt = dt.replace(second=int(60 * fraction))\n        else:\n            dt = dt.replace(second=int(second), microsecond=int(1000000 * fraction))\n    if tz is not None:\n        if tz[0] == 'Z':\n            offset = 0\n        else:\n            offset = datetime.timedelta(minutes=int(tzmm or 0), hours=int(tzhh))\n            if tz[0] == '-':\n                offset = -offset\n        dt = dt.replace(tzinfo=UTCOffset(offset))\n    return dt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist a file or directory in a revision.", "response": "def ls(\n        self, rev, path, recursive=False, recursive_dirs=False,\n        directory=False, report=()\n    ):\n        \"\"\"List directory or file\n\n        :param rev: The revision to use.\n        :param path: The path to list. May start with a '/' or not. Directories\n                     may end with a '/' or not.\n        :param recursive: Recursively list files in subdirectories.\n        :param recursive_dirs: Used when recursive=True, also list directories.\n        :param directory: If path is a directory, list path itself instead of\n                          its contents.\n        :param report: A list or tuple of extra attributes to return that may\n                       require extra processing. Recognized values are 'size',\n                       'target', 'executable', and 'commit'.\n\n        Returns a list of dictionaries with the following keys:\n\n        **type**\n            The type of the file: 'f' for file, 'd' for directory, 'l' for\n            symlink.\n        **name**\n            The name of the file. Not present if directory=True.\n        **size**\n            The size of the file. Only present for files when 'size' is in\n            report.\n        **target**\n            The target of the symlink. Only present for symlinks when\n            'target' is in report.\n        **executable**\n            True if the file is executable, False otherwise.    Only present\n            for files when 'executable' is in report.\n\n        Raises PathDoesNotExist if the path does not exist.\n\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log(\n        self, revrange=None, limit=None, firstparent=False, merges=None,\n        path=None, follow=False\n    ):\n        \"\"\"Get commit logs\n\n        :param revrange: Either a single revision or a range of revisions as a\n                         2-element list or tuple.\n        :param int limit: Limit the number of log entries.\n        :param bool firstparent: Only follow the first parent of merges.\n        :param bool merges: True means only merges, False means no merges,\n                            None means both merges and non-merges.\n        :param str path: Only match commits containing changes on this path.\n        :param bool follow: Follow file history across renames.\n        :returns: log information\n        :rtype: :class:`CommitLogEntry` or list of :class:`CommitLogEntry`\n\n        If revrange is None, return a list of all log entries in reverse\n        chronological order.\n\n        If revrange is a single revision, return a single log entry.\n\n        If revrange is a 2 element list [A,B] or tuple (A,B), return a list of log\n        entries starting at B and following that branch back to A or one of its\n        ancestors (not inclusive. If A is None, follow branch B back to the\n        beginning of history. If B is None, list all descendants in reverse\n        chronological order.\n\n        \"\"\"\n        raise NotImplementedError", "response": "Get the log of the given revision range."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_create(self, cloudflare_email, cloudflare_pass, unique_id=None):\n        params = {\n            'act': 'user_create',\n            'cloudflare_email': cloudflare_email,\n            'cloudflare_pass': cloudflare_pass\n        }\n        if unique_id:\n            params['unique_id'] = unique_id\n        return self._request(params)", "response": "Create new cloudflare user with selected email and id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zone_set(self, user_key, zone_name, resolve_to, subdomains):\n        params = {\n            'act': 'zone_set',\n            'user_key': user_key,\n            'zone_name': zone_name,\n            'resolve_to': resolve_to,\n            'subdomains': subdomains,\n        }\n        return self._request(params)", "response": "Create a new zone for a user associated with this user_key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_zone_set(self, user_key, zone_name):\n        params = {\n            'act': 'full_zone_set',\n            'user_key': user_key,\n            'zone_name': zone_name,\n        }\n        return self._request(params)", "response": "Create new zone and all subdomains for a user associated with this user_key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef user_auth(\n        self,\n        cloudflare_email=None,\n        cloudflare_pass=None,\n        unique_id=None\n            ):\n        \"\"\"\n        Get user_key based on either his email and password or unique_id.\n\n        :param    cloudflare_email: email associated with user\n        :type     cloudflare_email: str\n        :param    cloudflare_pass: pass associated with user\n        :type     cloudflare_pass: str\n        :param    unique_id:        unique id associated with user\n        :type     unique_id:        str\n\n        :returns:\n        :rtype:   dict\n        \"\"\"\n        if not (cloudflare_email and cloudflare_pass) and not unique_id:\n            raise KeyError(\n                'Either cloudflare_email and cloudflare_pass or unique_id must be present')\n        params = {'act': 'user_auth'}\n        if cloudflare_email and cloudflare_pass:\n            params['cloudflare_email'] = cloudflare_email\n            params['cloudflare_pass'] = cloudflare_pass\n        if unique_id:\n            params['unique_id'] = unique_id\n\n        return self._request(params)", "response": "Get user key based on either his email and password or unique_id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist zones for a user. :param user_key: key for authentication of user :type user_key: str :param limit: limit of zones shown :type limit: int :param offset: offset of zones to be shown :type offset: int :param zone_name: name of zone to lookup :type zone_name: str :param sub_id: subscription id of reseller (only for use by resellers) :type sub_id: str :param zone_status: status of zones to be shown :type zone_status: str (one of: V(active), D(deleted), ALL) :param sub_status: status of subscription of zones to be shown :type zone_name: str (one of: V(active), CNL(cancelled), ALL ) :returns: :rtype: dict", "response": "def zone_list(\n        self,\n        user_key,\n        limit=100,\n        offset=0,\n        zone_name=None,\n        sub_id=None,\n        zone_status='ALL',\n        sub_status='ALL',\n            ):\n        \"\"\"\n        List zones for a user.\n\n        :param    user_key:  key for authentication of user\n        :type     user_key:  str\n        :param    limit: limit of zones shown\n        :type     limit: int\n        :param    offset: offset of zones to be shown\n        :type     offset: int\n        :param    zone_name: name of zone to lookup\n        :type     zone_name: str\n        :param    sub_id: subscription id of reseller (only for use by resellers)\n        :type     sub_id: str\n        :param    zone_status: status of zones to be shown\n        :type     zone_status: str (one of: V(active), D(deleted), ALL)\n        :param    sub_status: status of subscription of zones to be shown\n        :type     zone_name: str (one of: V(active), CNL(cancelled), ALL )\n\n        :returns:\n        :rtype:   dict\n        \"\"\"\n        if zone_status not in ['V', 'D', 'ALL']:\n            raise ValueError('zone_status has to be V, D or ALL')\n        if sub_status not in ['V', 'CNL', 'ALL']:\n            raise ValueError('sub_status has to be V, CNL or ALL')\n        params = {\n            'act': 'zone_list',\n            'user_key': user_key,\n            'limit': limit,\n            'offset': offset,\n            'zone_status': zone_status,\n            'sub_status': sub_status\n        }\n        if zone_name:\n            params['zone_name'] = zone_name\n        if sub_id:\n            params['sub_id'] = sub_id\n\n        return self._request(params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attr_exists(self, attr):\n        gen = self.attr_gen(attr)\n        n_instances = len(list(gen))\n        if n_instances > 0:\n            return True\n        else:\n            return False", "response": "Returns True if at least on instance of the attribute is found\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef groups(self):\n        HiisiHDF._clear_cache()\n        self.CACHE['group_paths'].append('/')\n        self.visititems(HiisiHDF._is_group)\n        return HiisiHDF.CACHE['group_paths']", "response": "Method returns a list of all goup paths that are in group order"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attr_gen(self, attr):\n        HiisiHDF._clear_cache()\n        HiisiHDF.CACHE['search_attribute'] = attr\n        HiisiHDF._find_attr_paths('/', self['/']) # Check root attributes\n        self.visititems(HiisiHDF._find_attr_paths)\n        path_attr_gen = (PathValue(attr_path, self[attr_path].attrs.get(attr)) for attr_path in HiisiHDF.CACHE['attribute_paths'])\n        return path_attr_gen", "response": "Returns a generator that yields namedtuples containing path value pairs containing\n            path and value pairs containing\n            path and value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_from_filedict(self, filedict):\n        if self.mode in ['r+','w', 'w-', 'x', 'a']:\n            for h5path, path_content in filedict.iteritems():\n                if path_content.has_key('DATASET'):\n                    # If path exist, write only metadata\n                    if h5path in self:\n                        for key, value in path_content.iteritems():\n                            if key != 'DATASET':\n                                self[h5path].attrs[key] = value\n                    else:\n                        try:\n                            group = self.create_group(os.path.dirname(h5path))\n                        except ValueError:\n                            group = self[os.path.dirname(h5path)]\n                            pass # This pass has no effect?\n                        new_dataset = group.create_dataset(os.path.basename(h5path), data=path_content['DATASET'])\n                        for key, value in path_content.iteritems():\n                            if key != 'DATASET':\n                                new_dataset.attrs[key] = value\n                else:\n                    try:  \n                        group = self.create_group(h5path)\n                    except ValueError:\n                        group = self[h5path]\n                    for key, value in path_content.iteritems():\n                        group.attrs[key] = value", "response": "Create a new hdf5 file from a dictionary containing the file structure."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for a path with a key value match.", "response": "def search(self, attr, value, tolerance=0):\n        \"\"\"Find paths with a key value match\n\n        Parameters\n        ----------\n        attr : str\n            name of the attribute\n        value : str or numerical value\n            value of the searched attribute\n        \n        Keywords\n        --------\n        tolerance : float\n            tolerance used when searching for matching numerical\n            attributes. If the value of the attribute found from the file\n            differs from the searched value less than the tolerance, attributes\n            are considered to be the same.\n\n        Returns\n        -------\n        results : list\n            a list of all matching paths\n\n        Examples\n        --------\n\n        >>> for result in h5f.search('elangle', 0.5, 0.1):\n                print(result)        \n        '/dataset1/where'\n\n        >>> for result in h5f.search('quantity', 'DBZH'):\n                print(result)\n        '/dataset1/data2/what'\n        '/dataset2/data2/what'\n        '/dataset3/data2/what'\n        '/dataset4/data2/what'\n        '/dataset5/data2/what'\n        \n        \"\"\"\n        found_paths = []\n        gen = self.attr_gen(attr)\n        for path_attr_pair in gen:\n            # if attribute is numerical use numerical_value_tolerance in\n            # value comparison. If attribute is string require exact match\n            if isinstance(path_attr_pair.value, str):\n                type_name = 'str'\n            else:\n                type_name = path_attr_pair.value.dtype.name\n            if 'int' in type_name or 'float' in type_name:\n                if abs(path_attr_pair.value - value) <= tolerance:\n                    found_paths.append(path_attr_pair.path)\n            else:\n                if path_attr_pair.value == value:\n                    found_paths.append(path_attr_pair.path)\n\n        return found_paths"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extractReporterIons(ionArrays, reporterMz, mzTolerance):\n    reporterIons = {'mz': [], 'i': []}\n    for reporterMzValue in reporterMz:\n        limHi = reporterMzValue * (1+mzTolerance)\n        limLo = reporterMzValue * (1-mzTolerance)\n        loPos = bisect.bisect_left(ionArrays['mz'], limLo)\n        upPos = bisect.bisect_right(ionArrays['mz'], limHi)\n\n        matchingValues = ionArrays['mz'][loPos:upPos]\n        if matchingValues.size == 0:\n            reporterIons['i'].append(0)\n            reporterIons['mz'].append(numpy.nan)\n        elif matchingValues.size == 1:\n            reporterIons['i'].append(ionArrays['i'][loPos])\n            reporterIons['mz'].append(ionArrays['mz'][loPos])\n        else:\n            mzDeviations = numpy.abs(matchingValues-reporterMzValue)\n            minDeviationPos = numpy.argmin(mzDeviations)\n            bestMatchArrayPos = range(loPos, upPos)[minDeviationPos]\n            reporterIons['i'].append(ionArrays['i'][bestMatchArrayPos])\n            reporterIons['mz'].append(ionArrays['mz'][bestMatchArrayPos])\n\n    reporterIons['mz'] = numpy.array(reporterIons['mz'],\n                                     dtype=ionArrays['mz'].dtype\n                                     )\n    reporterIons['i'] = numpy.array(reporterIons['i'],\n                                    dtype=ionArrays['i'].dtype\n                                    )\n\n    return reporterIons", "response": "Extracts the mz and intensity values from the given ion array and returns them as a list of mz and intensity values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _correctIsotopeImpurities(matrix, intensities):\n    correctedIntensities, _ = scipy.optimize.nnls(matrix, intensities)\n    return correctedIntensities", "response": "Corrects observed reporter ion intensities for isotope - internal impurities."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize each row of the matrix that the sum of the row equals 1.", "response": "def _normalizeImpurityMatrix(matrix):\n    \"\"\"Normalize each row of the matrix that the sum of the row equals 1.\n\n    :params matrix: a matrix (2d nested list) containing numbers, each isobaric\n        channel must be present as a row.\n    :returns: a matrix containing normalized values\n    \"\"\"\n    newMatrix = list()\n    for line in matrix:\n        total = sum(line)\n        if total != 0:\n            newMatrix.append([i / total for i in line])\n        else:\n            newMatrix.append(line)\n    return newMatrix"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _padImpurityMatrix(matrix, preChannels, postChannels):\n    extendedMatrix = list()\n    lastMatrixI = len(matrix)-1\n    for i, line in enumerate(matrix):\n        prePadding = itertools.repeat(0., i)\n        postPadding = itertools.repeat(0., lastMatrixI-i)\n        newLine = list(itertools.chain(prePadding, line, postPadding))\n        extendedMatrix.append(newLine[preChannels:-postChannels])\n\n    return extendedMatrix", "response": "Align the values of an isotope impurity matrix and fill up with 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _processImpurityMatrix(self):\n        processedMatrix = _normalizeImpurityMatrix(self.impurityMatrix)\n        processedMatrix = _padImpurityMatrix(\n            processedMatrix, self.matrixPreChannels, self.matrixPostChannels\n            )\n        processedMatrix = _transposeMatrix(processedMatrix)\n        return processedMatrix", "response": "Process the impurity matrix so that it can be used to correct the observed reporter intensities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting Exception class to a Python dictionary.", "response": "def to_dict(self):\n        \"\"\"Convert Exception class to a Python dictionary.\"\"\"\n        val = dict(self.payload or ())\n        if self.message:\n            val['message'] = self.message\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef program(self):\n        statements = []\n        if self.cur_token.type == TokenTypes.NEW_LINE:\n            self.eat(TokenTypes.NEW_LINE)\n        while self.cur_token.type != TokenTypes.EOF:\n            statements += [self.statement()]\n        return Block(statements)", "response": "parse a program block"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a statement and return the next statement.", "response": "def statement(self):\n        \"\"\"\n        statement   : assign_statement\n                    | expression\n                    | control\n                    | empty\n        Feature For Loop adds:\n                    | loop\n        Feature Func adds:\n                    | func\n                    | return statement\n        \"\"\"\n        if self.cur_token.type == TokenTypes.VAR:\n            self.tokenizer.start_saving(self.cur_token)\n            self.variable()\n            peek_var = self.cur_token\n            self.tokenizer.replay()\n            self.eat()\n            if peek_var.type == TokenTypes.ASSIGN:\n                return self.assign_statement()\n            else:\n                return self.expression()\n        elif self.cur_token.type in TokenTypes.control(self.features):\n            return self.control()\n        elif self.cur_token.type in TokenTypes.loop(self.features):\n            return self.loop()\n        elif self.cur_token.type in TokenTypes.func(self.features):\n            if self.cur_token.type == TokenTypes.FUNC:\n                return self.func()\n            elif self.cur_token.type == TokenTypes.RETURN:\n                return self.return_statement()\n        self.error(\"Invalid token or unfinished statement\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assign_statement(self):\n        left = self.variable()\n        op = self.cur_token\n        self.eat(TokenTypes.ASSIGN)\n        right = self.expression()\n        smt = None\n        if Features.TYPE_ARRAY in self.features and isinstance(left, GetArrayItem):\n            # Remake this as a setitem.\n            smt = SetArrayItem(left.left, left.right, right)\n        else:\n            smt = Assign(op, left, right)\n        if self.cur_token.type == TokenTypes.SEMI_COLON:\n            self.eat(TokenTypes.SEMI_COLON)\n        return smt", "response": "Parse an assignment statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a control formula", "response": "def control(self):\n        \"\"\"\n        control    : 'if' ctrl_exp block ('elif' ctrl_exp block)* ('else' block)\n        \"\"\"\n        self.eat(TokenTypes.IF)\n        ctrl = self.expression()\n        block = self.block()\n        ifs = [If(ctrl, block)]\n        else_block = Block()\n        while self.cur_token.type == TokenTypes.ELIF:\n            self.eat(TokenTypes.ELIF)\n            ctrl = self.expression()\n            block = self.block()\n            ifs.append(If(ctrl, block))\n        if self.cur_token.type == TokenTypes.ELSE:\n            self.eat(TokenTypes.ELSE)\n            else_block = self.block()\n        return ControlBlock(ifs, else_block)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loop(self):\n        self.eat(TokenTypes.FOR_LOOP)\n        init = NoOp()\n        if self.cur_token.type != TokenTypes.SEMI_COLON:\n            init = self.assign_statement()\n        else:\n            self.eat(TokenTypes.SEMI_COLON)\n\n        ctrl = NoOp()\n        if self.cur_token.type != TokenTypes.SEMI_COLON:\n            ctrl = self.expression()\n        self.eat(TokenTypes.SEMI_COLON)\n\n        inc = NoOp()\n        if self.cur_token.type != TokenTypes.LBRACE:\n            inc = self.assign_statement()\n\n        block = self.block()\n        return ForLoop(init, ctrl, inc, block)", "response": "parse a for loop"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a function definition", "response": "def func(self):\n        \"\"\"\n        func       : func name(paramlist) block\n        \"\"\"\n        self.eat(TokenTypes.FUNC)\n        name = Var(self.cur_token)\n        self.eat(TokenTypes.VAR)\n        self.eat(TokenTypes.LPAREN)\n        sig = self.param_list()\n        self.eat(TokenTypes.RPAREN)\n        block = self.block()\n        return FunctionDef(name, Function(sig, block))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the parameter list", "response": "def param_list(self):\n        \"\"\"\n        paramlist  : var, paramlist\n        paramlist  : var\n        paramlist  :\n        \"\"\"\n        params = []\n        while self.cur_token.type == TokenTypes.VAR:\n            params.append(Var(self.cur_token))\n            self.eat(TokenTypes.VAR)\n            if self.cur_token.type == TokenTypes.COMMA:\n                self.eat(TokenTypes.COMMA)\n\n        return FunctionSig(params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an argument list", "response": "def arg_list(self, ending_char=TokenTypes.RPAREN):\n        \"\"\"\n        arglist    : expression, arglist\n        arglist    : expression\n        arglist    :\n        \"\"\"\n        args = []\n        while not self.cur_token.type == ending_char:\n            args.append(self.expression())\n            if self.cur_token.type == TokenTypes.COMMA:\n                self.eat(TokenTypes.COMMA)\n\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfeaturing Type Array adds: array : [ arglist ]", "response": "def array_const(self):\n        \"\"\"\n        Feature Type Array adds:\n        array      : [ arglist ]\n        \"\"\"\n        self.eat(TokenTypes.LBRACKET)\n        node = Array(self.arg_list(TokenTypes.RBRACKET))\n        self.eat(TokenTypes.RBRACKET)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef block(self):\n        statements = []\n        self.eat(TokenTypes.LBRACE)\n        if self.cur_token.type == TokenTypes.NEW_LINE:\n            self.eat(TokenTypes.NEW_LINE)\n        while self.cur_token.type != TokenTypes.RBRACE:\n            statements.append(self.statement())\n        self.eat(TokenTypes.RBRACE)\n        if self.cur_token.type == TokenTypes.NEW_LINE:\n            self.eat(TokenTypes.NEW_LINE)\n        return Block(statements)", "response": "Parse the next entry in the log file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\neating a variable and returns it", "response": "def variable(self):\n        \"\"\"\n        variable    : variable\n        Feature Type Array adds:\n        variable    : variable[expression]\n        Feature Type Func adds:\n        variable    : variable(arg_list)\n        \"\"\"\n        var = Var(self.cur_token)\n        self.eat(TokenTypes.VAR)\n        if Features.TYPE_ARRAY in self.features:\n            while self.cur_token.type == TokenTypes.LBRACKET:\n                self.eat(TokenTypes.LBRACKET)\n                # Start passed the logical ops.\n                expr = self.operator_expression(level=2)\n                self.eat(TokenTypes.RBRACKET)\n                var = GetArrayItem(left=var, right=expr)\n        if Features.FUNC in self.features:\n            if self.cur_token.type == TokenTypes.LPAREN:\n                self.eat(TokenTypes.LPAREN)\n                args = self.arg_list()\n                self.eat(TokenTypes.RPAREN)\n                var = Call(var, args)\n        return var"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrap_node(self, node, options):\n        '''\\\n        celery registers tasks by decorating them, and so do we, so the user\n        can pass a celery task and we'll wrap our code with theirs in a nice\n        package celery can execute.\n        '''\n        if 'celery_task' in options:\n            return options['celery_task'](node)\n\n        return self.celery_task(node)", "response": "Wrap a node in a nice\n        and return it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkpoint(key=0, unpickler=pickle.load, pickler=pickle.dump, work_dir=gettempdir(), refresh=False):\n\n    def decorator(func):\n        def wrapped(*args, **kwargs):\n            # If first arg is a string, use it directly.\n            if isinstance(key, str):\n                save_file = os.path.join(work_dir, key)\n            elif isinstance(key, Template):\n                save_file = os.path.join(work_dir, key.substitute(kwargs))\n                save_file = save_file.format(*args)\n            elif isinstance(key, types.FunctionType):\n                save_file = os.path.join(work_dir, key(args, kwargs))\n            else:\n                logging.warn('Using 0-th argument as default.')\n                save_file = os.path.join(work_dir, '{0}')\n                save_file = save_file.format(args[key])\n\n            logging.info('checkpoint@ %s' % save_file)\n\n            # cache_file doesn't exist, run the function and save output in checkpoint.\n\n            if isinstance(refresh, types.FunctionType):\n                do_refresh = refresh()\n            else:\n                do_refresh = refresh\n\n            if do_refresh or not os.path.exists(path=save_file):  # Otherwise compute it save it and return it.\n                # If the program fails, don't checkpoint.\n                try:\n                    out = func(*args, **kwargs)\n                except: # a blank raise re-raises the last exception.\n                    raise\n                else:  # If the program is successful, then go ahead and call the save function.\n                    with open(save_file, 'wb') as f:\n                        pickler(out, f)\n                        return out\n            # Otherwise, load the checkpoint file and send it.\n            else:\n                logging.info(\"Checkpoint exists. Loading from: %s\" % save_file)\n                with open(save_file, 'rb') as f:\n                    return unpickler(f)\n                    # Todo: Sending options to load/save functions.\n        return wrapped\n\n    return decorator", "response": "This utility function saves the output of a function in a separate file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the shortest string using BFS", "response": "def bfs(graph, start):\n    \"\"\"\n    Finds the shortest string using BFS\n    Args:\n        graph (DFA): The DFA states\n        start (DFA state): The DFA initial state\n    Returns:\n        str: The shortest string\n    \"\"\"\n    # maintain a queue of paths\n    queue = []\n    visited = []\n    # maintain a queue of nodes\n    # push the first path into the queue\n    queue.append([['', start]])\n    while queue:\n        # get the first path from the queue\n        path = queue.pop(0)\n        # get the last node from the path\n        node = path[-1][1]\n        if node.stateid not in visited:\n            visited.append(node.stateid)\n            # path found\n            if node.final != TropicalWeight(float('inf')):\n                return \"\".join([mnode[0] for mnode in path])\n            # enumerate all adjacent nodes, construct a new path and push\n            # it into the queue\n            for arc in node.arcs:\n                char = graph.isyms.find(arc.ilabel)\n                next_state = graph[arc.nextstate]\n                # print next_state.stateid\n                if next_state.stateid not in visited:\n                    new_path = list(path)\n                    new_path.append([char, next_state])\n                    queue.append(new_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay the arguments as a braille bar graph on standard output.", "response": "def run():\n    \"\"\"Display the arguments as a braille graph on standard output.\"\"\"\n\n    # We override the program name to reflect that this script must be run with\n    # the python executable.\n    parser = argparse.ArgumentParser(\n        prog='python -m braillegraph',\n        description='Print a braille bar graph of the given integers.'\n    )\n\n    # This flag sets the end string that we'll print. If we pass end=None to\n    # print(), it will use its default. If we pass end='', it will suppress the\n    # newline character.\n    parser.add_argument('-n', '--no-newline', action='store_const',\n                        dest='end', const='', default=None,\n                        help='do not print the trailing newline character')\n\n    # Add subparsers for the directions\n    subparsers = parser.add_subparsers(title='directions')\n\n    horizontal_parser = subparsers.add_parser('horizontal',\n                                              help='a horizontal graph')\n    horizontal_parser.set_defaults(\n        func=lambda args: horizontal_graph(args.integers)\n    )\n    horizontal_parser.add_argument('integers', metavar='N', type=int,\n                                   nargs='+', help='an integer')\n\n    vertical_parser = subparsers.add_parser('vertical',\n                                            help='a vertical graph')\n    vertical_parser.set_defaults(\n        func=lambda args: vertical_graph(args.integers, sep=args.sep)\n    )\n    vertical_parser.add_argument('integers', metavar='N', type=int, nargs='+',\n                                 help='an integer')\n\n    # The separator for groups of bars (i.e., \"lines\"). If we pass None,\n    # vertical_parser will use its default.\n    vertical_parser.add_argument('-s', '--sep', action='store', default=None,\n                                 help='separator for groups of bars')\n\n    args = parser.parse_args()\n\n    print(args.func(args), end=args.end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a random date between start and end.", "response": "def rnd_date(start=date(1970, 1, 1), end=None, **kwargs):\n    \"\"\"\n    Generate a random date between ``start`` to ``end``.\n\n    :param start: Left bound\n    :type start: string or datetime.date, (default date(1970, 1, 1))\n    :param end: Right bound\n    :type end: string or datetime.date, (default date.today())\n    :return: a datetime.date object\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u968f\u673a\u751f\u6210\u4e00\u4e2a\u4f4d\u4e8e ``start`` \u548c ``end`` \u4e4b\u95f4\u7684\u65e5\u671f\u3002\n    \"\"\"\n    if end is None:\n        end = date.today()\n    start = parser.parse_date(start)\n    end = parser.parse_date(end)\n    _assert_correct_start_end(start, end)\n    return _rnd_date(start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rnd_date_array(size, start=date(1970, 1, 1), end=None, **kwargs):\n    if end is None:\n        end = date.today()\n    start = parser.parse_date(start)\n    end = parser.parse_date(end)\n    _assert_correct_start_end(start, end)\n    return _randn(size, _rnd_date, start, end)", "response": "Returns a random date array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rnd_date_list_high_performance(size, start=date(1970, 1, 1), end=None, **kwargs):\n    if end is None:\n        end = date.today()\n    start_days = to_ordinal(parser.parse_datetime(start))\n    end_days = to_ordinal(parser.parse_datetime(end))\n    _assert_correct_start_end(start_days, end_days)\n    if has_np:  # pragma: no cover\n        return [\n            from_ordinal(days)\n            for days in np.random.randint(start_days, end_days, size)\n        ]\n    else:\n        return [\n            from_ordinal(random.randint(start_days, end_days))\n            for _ in range(size)\n        ]", "response": "Generate mass random date."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rnd_datetime(start=datetime(1970, 1, 1), end=datetime.now()):\n    start = parser.parse_datetime(start)\n    end = parser.parse_datetime(end)\n    _assert_correct_start_end(start, end)\n    return _rnd_datetime(start, end)", "response": "Generates a random datetime between start and end."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a random datetime array.", "response": "def rnd_datetime_array(size, start=datetime(1970, 1, 1), end=None):\n    \"\"\"\n    Array or Matrix of random datetime generator.\n\n    :returns: 1d or 2d array of datetime.date\n    \"\"\"\n    if end is None:\n        end = datetime.now()\n    start = parser.parse_datetime(start)\n    end = parser.parse_datetime(end)\n    _assert_correct_start_end(start, end)\n    return _randn(size, _rnd_datetime, start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef day_interval(year, month, day, milliseconds=False, return_string=False):\n    if milliseconds:  # pragma: no cover\n        delta = timedelta(milliseconds=1)\n    else:\n        delta = timedelta(seconds=1)\n\n    start = datetime(year, month, day)\n    end = datetime(year, month, day) + timedelta(days=1) - delta\n\n    if not return_string:\n        return start, end\n    else:\n        return str(start), str(end)", "response": "Return a start datetime and end datetime of a day."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef month_interval(year, month, milliseconds=False, return_string=False):\n    if milliseconds:  # pragma: no cover\n        delta = timedelta(milliseconds=1)\n    else:\n        delta = timedelta(seconds=1)\n\n    if month == 12:\n        start = datetime(year, month, 1)\n        end = datetime(year + 1, 1, 1) - delta\n    else:\n        start = datetime(year, month, 1)\n        end = datetime(year, month + 1, 1) - delta\n\n    if not return_string:\n        return start, end\n    else:\n        return str(start), str(end)", "response": "Return a start datetime and end datetime of a month."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef year_interval(year, milliseconds=False, return_string=False):\n    if milliseconds:  # pragma: no cover\n        delta = timedelta(milliseconds=1)\n    else:\n        delta = timedelta(seconds=1)\n\n    start = datetime(year, 1, 1)\n    end = datetime(year + 1, 1, 1) - delta\n\n    if not return_string:\n        return start, end\n    else:\n        return str(start), str(end)", "response": "Return a start datetime and end datetime of a year."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering a file to text using the mako template system.", "response": "def renderfile(filename,\n               options=None,\n               templatePaths=None,\n               default='',\n               silent=False):\n    \"\"\"\n    Renders a file to text using the mako template system.\n    \n    To learn more about mako and its usage, see [[www.makotemplates.org]]\n    \n    :return     <str> formatted text\n    \"\"\"\n    if not mako:\n        logger.debug('mako is not installed')\n        return default\n\n    if not mako:\n        logger.debug('mako is not installed.')\n        return default\n\n    if templatePaths is None:\n        templatePaths = []\n\n    # use the default mako templates\n    basepath = os.environ.get('MAKO_TEMPLATEPATH', '')\n    if basepath:\n        basetempls = basepath.split(os.path.pathsep)\n    else:\n        basetempls = []\n\n    templatePaths += basetempls\n\n    # include the root path\n    templatePaths.insert(0, os.path.dirname(filename))\n    templatePaths = map(lambda x: x.replace('\\\\', '/'), templatePaths)\n\n    # update the default options\n    scope = dict(os.environ)\n\n    scope['projex_text'] = projex.text\n    scope['date'] = date\n    scope['datetime'] = datetime\n    scope.update(_macros)\n    scope.update(os.environ)\n\n    if options is not None:\n        scope.update(options)\n\n    old_env_path = os.environ.get('MAKO_TEMPLATEPATH', '')\n    os.environ['MAKO_TEMPLATEPATH'] = os.path.pathsep.join(templatePaths)\n\n    logger.debug('rendering mako file: %s', filename)\n    if templatePaths:\n        lookup = mako.lookup.TemplateLookup(directories=templatePaths)\n        templ = mako.template.Template(filename=filename, lookup=lookup)\n    else:\n        templ = mako.template.Template(filename=filename)\n\n    try:\n        output = templ.render(**scope)\n    except StandardError:\n        output = default\n        if not silent:\n            logger.exception('Error rendering mako text')\n\n    os.environ['MAKO_TEMPLATEPATH'] = old_env_path\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(text,\n           options=None,\n           templatePaths=None,\n           default=None,\n           silent=False,\n           raiseErrors=False):\n    \"\"\"\n    Renders a template text to a resolved text value using the mako template\n    system.\n    \n    Provides a much more robust template option to the projex.text system.  \n    While the projex.text method can handle many simple cases with no\n    dependencies, the makotext module makes use of the powerful mako template\n    language.  This module provides a simple wrapper to the mako code.\n    \n    To learn more about mako and its usage, see [[www.makotemplates.org]]\n    \n    :param      text        <str>\n    :param      options     <dict> { <str> key: <variant> value, .. }\n    \n    :return     <str> formatted text\n    \n    :usage      |import projex.makotext\n                |options = { 'key': 10, 'name': 'eric' }\n                |template = '${name.lower()}_${key}_${date.today()}.txt'\n                |projex.makotext.render( template, options )\n    \"\"\"\n    if not mako:\n        logger.debug('mako is not installed.')\n        return text if default is None else default\n\n    if templatePaths is None:\n        templatePaths = []\n\n    # use the default mako templates\n    basepath = os.environ.get('MAKO_TEMPLATEPATH', '')\n    if basepath:\n        basetempls = basepath.split(os.path.pathsep)\n    else:\n        basetempls = []\n\n    templatePaths += basetempls\n\n    # update the default options\n    scope = dict(os.environ)\n\n    scope['projex_text'] = projex.text\n    scope['date'] = date\n    scope['datetime'] = datetime\n    scope.update(_macros)\n\n    if options is not None:\n        scope.update(options)\n\n    if templatePaths:\n        lookup = mako.lookup.TemplateLookup(directories=templatePaths)\n        try:\n            templ = mako.template.Template(text, lookup=lookup)\n        except StandardError:\n            output = text if default is None else default\n            if not silent:\n                logger.exception('Error compiling mako text')\n            return output\n    else:\n        try:\n            templ = mako.template.Template(text)\n        except StandardError:\n            output = text if default is None else default\n            if not silent:\n                logger.exception('Error compiling mako text')\n            return output\n\n    try:\n        output = templ.render(**scope)\n    except StandardError:\n        if raiseErrors:\n            raise\n        output = text if default is None else default\n        if not silent:\n            logger.exception('Error rendering mako text')\n        return output\n\n    return output", "response": "Renders a text value using the mako template system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collectfiles(path, filt=None):\n    if not os.path.isdir(path):\n        path = os.path.dirname(path)\n\n    output = []\n    for name in sorted(os.listdir(path)):\n        filepath = os.path.join(path, name)\n        if os.path.isfile(filepath):\n            if not filt or filt(name):\n                output.append((name, filepath))\n    return output", "response": "Collects some files based on the given filename."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a single milestone object given the title as str or creates a new one if it doesn t exist", "response": "def get_milestone(self, title):\n        \"\"\"\n        given the title as str, looks for an existing milestone or create a new one,\n        and return the object\n        \"\"\"\n        if not title:\n            return GithubObject.NotSet\n        if not hasattr(self, '_milestones'):\n            self._milestones = {m.title: m for m in self.repo.get_milestones()}\n\n        milestone = self._milestones.get(title)\n        if not milestone:\n            milestone = self.repo.create_milestone(title=title)\n        return milestone"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the object that is assigned to the given user login.", "response": "def get_assignee(self, login):\n        \"\"\"\n        given the user login, looks for a user in assignee list of the repo\n        and return it if was found.\n        \"\"\"\n        if not login:\n            return GithubObject.NotSet\n        if not hasattr(self, '_assignees'):\n            self._assignees = {c.login: c for c in self.repo.get_assignees()}\n        if login not in self._assignees:\n            # warning\n            print(\"{} doesn't belong to this repo. This issue won't be assigned.\".format(login))\n        return self._assignees.get(login)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sender(self, issues):\n\n        for issue in issues:\n            state = self.get_state(issue.state)\n            if issue.number:\n                try:\n                    gh_issue = self.repo.get_issue(issue.number)\n                    original_state = gh_issue.state\n                    if original_state == state:\n                        action = 'Updated'\n                    elif original_state == 'closed':\n                        action = 'Reopened'\n                    else:\n                        action = 'Closed'\n\n                    gh_issue.edit(title=issue.title,\n                                  body=issue.body,\n                                  labels=issue.labels,\n                                  milestone=self.get_milestone(issue.milestone),\n                                  assignee=self.get_assignee(issue.assignee),\n                                  state=self.get_state(issue.state)\n                                  )\n                    print('{} #{}: {}'.format(action, gh_issue.number, gh_issue.title))\n                except GithubException:\n                    print('Not found #{}: {} (ignored)'.format(issue.number, issue.title))\n                    continue\n            else:\n                gh_issue = self.repo.create_issue(title=issue.title,\n                                                  body=issue.body,\n                                                  labels=issue.labels,\n                                                  milestone=self.get_milestone(issue.milestone),\n                                                  assignee=self.get_assignee(issue.assignee))\n                print('Created #{}: {}'.format(gh_issue.number, gh_issue.title))", "response": "push a list of issues to github"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef define(self, key, value):\n        skey = nstr(key)\n        self._defaults[skey] = value\n        self[skey] = value", "response": "Defines the value for the inputted key by setting both its default and the inputted value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef toXml(self, xparent):\n        for key, value in self.items():\n            elem = ElementTree.SubElement(xparent, 'entry')\n            typ = type(elem).__name__\n\n            elem.set('key', key)\n            elem.set('type', typ)\n\n            if typ in DataSet._xmlTypes:\n                DataSet._xmlTypes[typ][0](elem, value)\n            else:\n                elem.set('value', nstr(value))", "response": "Saves the settings for this dataset to the inputted parent xml."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the settings for this dataset from the inputted parent xml.", "response": "def fromXml(cls, xparent):\n        \"\"\"\n        Loads the settings for this dataset to the inputted parent xml.\n        \n        :param      xparent | <xml.etree.ElementTree.Element>\n        \"\"\"\n        output = cls()\n\n        for xentry in xparent:\n            key = xentry.get('key')\n            if not key:\n                continue\n\n            typ = xentry.get('type', 'str')\n\n            if typ in DataSet._xmlTypes:\n                value = DataSet._xmlTypes[typ][1](xentry)\n            else:\n                value = xentry.get('value', '')\n\n            output.define(key, value)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a data type to encode or decode for xml settings.", "response": "def registerXmlType(typ, encoder, decoder):\n        \"\"\"\n        Registers a data type to encode/decode for xml settings.\n        \n        :param      typ     | <object>\n                    encoder | <method>\n                    decoder | <method>\n        \"\"\"\n        DataSet._xmlTypes[nstr(typ)] = (encoder, decoder)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap a node in a job", "response": "def wrap_node(self, node, options):\n        '''\n        we have the option to construct nodes here, so we can use different\n        queues for nodes without having to have different queue objects.\n        '''\n        job_kwargs = {\n            'queue': options.get('queue', 'default'),\n            'connection': options.get('connection', self.redis_connection),\n            'timeout': options.get('timeout', None),\n            'result_ttl': options.get('result_ttl', 500),\n        }\n\n        return job(**job_kwargs)(node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the mzML file for the specified spectrum and chromatograms.", "response": "def writeMzml(specfile, msrunContainer, outputdir, spectrumIds=None,\n              chromatogramIds=None, writeIndex=True):\n    \"\"\" #TODO: docstring\n\n    :param specfile: #TODO docstring\n    :param msrunContainer: #TODO docstring\n    :param outputdir: #TODO docstring\n    :param spectrumIds: #TODO docstring\n    :param chromatogramIds: #TODO docstring\n    \"\"\"\n    #TODO: maybe change to use aux.openSafeReplace\n    outputFile = io.BytesIO()\n\n    #TODO: perform check that specfile is present in msrunContainer and at least\n    #   the metadatanode.\n    metadataTree = msrunContainer.rmc[specfile]\n    #Generate a list of spectrum ids that should be written to mzML\n    if spectrumIds is None and specfile in msrunContainer.smic:\n        keyTuple = [(int(key), key) for key in viewkeys(msrunContainer.smic[specfile])]\n        spectrumIds = [key for _, key in sorted(keyTuple)]\n    spectrumCounts = len(spectrumIds)\n    #Generate a list of chromatogram ids that should be written to mzML\n    if chromatogramIds is None and specfile in msrunContainer.cic:\n        chromatogramIds = [cId for cId in viewkeys(msrunContainer.cic[specfile])]\n    chromatogramCounts = len(chromatogramIds)\n\n    spectrumIndexList = list()\n    chromatogramIndexList = list()\n\n    xmlFile = ETREE.xmlfile(outputFile, encoding='ISO-8859-1', buffered=False)\n    xmlWriter = xmlFile.__enter__()\n    xmlWriter.write_declaration()\n\n    nsmap = {None: 'http://psi.hupo.org/ms/mzml',\n             'xsi': 'http://www.w3.org/2001/XMLSchema-instance'\n             }\n    mzmlAttrib = {'{http://www.w3.org/2001/XMLSchema-instance}schemaLocation': \\\n                    'http://psi.hupo.org/ms/mzml http://psidev.info/files/ms/mzML/xsd/mzML1.1.0.xsd',\n                  'version': '1.1.0', 'id': metadataTree.attrib['id']\n                  }\n\n    if writeIndex:\n        xmlIndexedMzml = xmlWriter.element('indexedmzML', nsmap=nsmap)\n        xmlIndexedMzml.__enter__()\n        xmlWriter.write('\\n')\n    xmlMzml = xmlWriter.element('mzML', mzmlAttrib, nsmap=nsmap)\n    xmlMzml.__enter__()\n    xmlWriter.write('\\n')\n\n    for metadataNode in metadataTree.getchildren():\n        if metadataNode.tag != 'run':\n            xmlWriter.write(maspy.xml.recCopyElement(metadataNode),\n                            pretty_print=True\n                            )\n        else:\n            xmlRun = xmlWriter.element(metadataNode.tag, metadataNode.attrib)\n            xmlRun.__enter__()\n            xmlWriter.write('\\n')\n            for runChild in metadataNode.getchildren():\n                if runChild.tag == 'spectrumList':\n                    specDefaultProcRef = runChild.attrib['defaultDataProcessingRef']\n                elif runChild.tag == 'chromatogramList':\n                    chromDefaultProcRef = runChild.attrib['defaultDataProcessingRef']\n                else:\n                    #TODO: maybe recCopy?\n                    xmlRun.append(runChild)\n\n            #If any spectra should be written, generate the spectrumList Node.\n            if spectrumCounts > 0:\n                specListAttribs = {'count': str(spectrumCounts),\n                                   'defaultDataProcessingRef': specDefaultProcRef\n                                   }\n                xmlSpectrumList = xmlWriter.element('spectrumList',\n                                                    specListAttribs\n                                                    )\n                xmlSpectrumList.__enter__()\n                xmlWriter.write('\\n')\n\n                for index, key in enumerate(spectrumIds):\n                    smi = msrunContainer.smic[specfile][key]\n                    sai = msrunContainer.saic[specfile][key]\n                    #Store the spectrum element offset here\n                    spectrumIndexList.append((outputFile.tell(),\n                                              smi.attributes['id']\n                                              ))\n\n                    xmlSpectrum = xmlSpectrumFromSmi(index, smi, sai)\n                    xmlWriter.write(xmlSpectrum, pretty_print=True)\n\n                xmlSpectrumList.__exit__(None, None, None)\n                xmlWriter.write('\\n')\n\n            #If any chromatograms should be written, generate the\n            #chromatogramList Node.\n            if chromatogramCounts > 0:\n                chromListAttribs = {'count': str(chromatogramCounts),\n                                    'defaultDataProcessingRef': chromDefaultProcRef\n                                    }\n                xmlChromatogramList = xmlWriter.element('chromatogramList',\n                                                        chromListAttribs\n                                                        )\n                xmlChromatogramList.__enter__()\n                xmlWriter.write('\\n')\n                for index, key in enumerate(chromatogramIds):\n                    ci = msrunContainer.cic[specfile][key]\n                    #Store the chromatogram element offset here\n                    chromatogramIndexList.append((outputFile.tell(), ci.id))\n\n                    xmlChromatogram = xmlChromatogramFromCi(index, ci)\n                    xmlWriter.write(xmlChromatogram, pretty_print=True)\n                xmlChromatogramList.__exit__(None, None, None)\n                xmlWriter.write('\\n')\n\n            xmlRun.__exit__(None, None, None)\n            xmlWriter.write('\\n')\n\n    #Close the mzml node\n    xmlMzml.__exit__(None, None, None)\n    #Optional: write the indexedMzml nodes and close the indexedMzml node\n    if writeIndex:\n        xmlWriter.write('\\n')\n        indexListOffset = outputFile.tell()\n        _writeMzmlIndexList(xmlWriter, spectrumIndexList, chromatogramIndexList)\n        _writeIndexListOffset(xmlWriter, indexListOffset)\n        _writeMzmlChecksum(xmlWriter, outputFile)\n        xmlIndexedMzml.__exit__(None, None, None)\n    #Close the xml file\n    xmlFile.__exit__(None, None, None)\n    #Write the output mzML file\n    filepath = aux.joinpath(outputdir, specfile+'.mzML')\n    with open(filepath, 'wb') as openfile:\n        openfile.write(outputFile.getvalue())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _writeMzmlIndexList(xmlWriter, spectrumIndexList, chromatogramIndexList):\n    counts = 0\n    if spectrumIndexList:\n        counts += 1\n    if chromatogramIndexList:\n        counts += 1\n    if counts == 0:\n        return None\n    #Create indexList node\n    xmlIndexList = xmlWriter.element('indexList', {'count': str(counts)})\n    xmlIndexList.__enter__()\n    xmlWriter.write('\\n')\n\n    _writeIndexListElement(xmlWriter, 'spectrum', spectrumIndexList)\n    _writeIndexListElement(xmlWriter, 'chromatogram', chromatogramIndexList)\n\n    #Close indexList node\n    xmlIndexList.__exit__(None, None, None)\n    xmlWriter.write('\\n')", "response": "Write the Mzml indexList to the xmlWriter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting an index list element.", "response": "def _writeIndexListElement(xmlWriter, elementName, indexList):\n    \"\"\" #TODO: docstring\n\n    :param xmlWriter: #TODO: docstring\n    :param elementName: #TODO: docstring\n    :param indexList: #TODO: docstring\n    \"\"\"\n    if indexList:\n        xmlIndex = xmlWriter.element('index', {'name': elementName})\n        xmlIndex.__enter__()\n        xmlWriter.write('\\n')\n        for offset, indexId in indexList:\n            offsetElement = ETREE.Element('offset', {'idRef': indexId})\n            offsetElement.text = str(offset)\n            xmlWriter.write(offsetElement, pretty_print=True)\n        xmlIndex.__exit__(None, None, None)\n        xmlWriter.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the MzML checksum to the file.", "response": "def _writeMzmlChecksum(xmlWriter, outputFile):\n    \"\"\" #TODO: docstring\n\n    :param xmlWriter: #TODO: docstring\n    :param outputFile: #TODO: docstring\n    \"\"\"\n    sha = hashlib.sha1(outputFile.getvalue())\n    sha.update('<fileChecksum>')\n\n    xmlChecksumElement = ETREE.Element('fileChecksum')\n    xmlChecksumElement.text = sha.hexdigest()\n\n    xmlWriter.write(xmlChecksumElement, pretty_print=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _writeIndexListOffset(xmlWriter, offset):\n    xmlIndexListOffset = ETREE.Element('indexListOffset')\n    xmlIndexListOffset.text = str(offset)\n\n    xmlWriter.write(xmlIndexListOffset, pretty_print=True)", "response": "Write the offset to the indexListOffset element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xmlGenScanList(scanList, scanListParams):\n    numEntries = len(scanList)\n    xmlScanList = ETREE.Element('scanList', {'count': str(numEntries)})\n    maspy.xml.xmlAddParams(xmlScanList, scanListParams)\n    for scan in scanList:\n        #Note: no attributes supported\n        xmlScan = ETREE.Element('scan', {})\n        maspy.xml.xmlAddParams(xmlScan, scan['params'])\n\n        #Generate the scanWindowList entry\n        numScanWindows = len(scan['scanWindowList'])\n        if numScanWindows > 0:\n            xmlScanWindowList = ETREE.Element('scanWindowList',\n                                              {'count': str(numScanWindows)}\n                                              )\n            for scanWindow in scan['scanWindowList']:\n                xmlScanWindow = ETREE.Element('scanWindow')\n                maspy.xml.xmlAddParams(xmlScanWindow, scanWindow)\n                xmlScanWindowList.append(xmlScanWindow)\n            xmlScan.append(xmlScanWindowList)\n\n        xmlScanList.append(xmlScan)\n    return xmlScanList", "response": "Generate the XML for the scanList."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xmlGenPrecursorList(precursorList):\n    numEntries = len(precursorList)\n    xmlPrecursorList = ETREE.Element('precursorList',\n                                     {'count': str(numEntries)}\n                                     )\n    for precursor in precursorList:\n        #Note: no attributes for external referencing supported\n        precursorAttrib = {}\n        if precursor['spectrumRef'] is not None:\n            precursorAttrib.update({'spectrumRef': precursor['spectrumRef']})\n        xmlPrecursor = ETREE.Element('precursor', precursorAttrib)\n\n        #Add isolationWindow element\n        if precursor['isolationWindow'] is not None:\n            xmlIsolationWindow = ETREE.Element('isolationWindow')\n            maspy.xml.xmlAddParams(xmlIsolationWindow,\n                                   precursor['isolationWindow']\n                                   )\n            xmlPrecursor.append(xmlIsolationWindow)\n\n        #Add selectedIonList element\n        numSelectedIons = len(precursor['selectedIonList'])\n        if numSelectedIons > 0:\n            xmlSelectedIonList = ETREE.Element('selectedIonList',\n                                               {'count': str(numSelectedIons)}\n                                               )\n            for selectedIon in precursor['selectedIonList']:\n                xmlSelectedIon = ETREE.Element('selectedIon')\n                maspy.xml.xmlAddParams(xmlSelectedIon, selectedIon)\n                xmlSelectedIonList.append(xmlSelectedIon)\n            xmlPrecursor.append(xmlSelectedIonList)\n\n        #Add activation element\n        xmlActivation = ETREE.Element('activation')\n        maspy.xml.xmlAddParams(xmlActivation, precursor['activation'])\n        xmlPrecursor.append(xmlActivation)\n\n\n        xmlPrecursorList.append(xmlPrecursor)\n    return xmlPrecursorList", "response": "Generate precursor list element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a new xmlBinaryDataArrayList element for the given binaryDataInfo and binaryDataDict.", "response": "def xmlGenBinaryDataArrayList(binaryDataInfo, binaryDataDict,\n                              compression='zlib', arrayTypes=None):\n    \"\"\" #TODO: docstring\n\n    :params binaryDataInfo: #TODO: docstring\n    :params binaryDataDict: #TODO: docstring\n    :params compression: #TODO: docstring\n    :params arrayTypes: #TODO: docstring\n\n    :returns: #TODO: docstring\n    \"\"\"\n    #Note: any other value for \"compression\" than \"zlib\" results in no\n    #   compression\n    #Note: Use arrayTypes parameter to specify the order of the arrays\n    if arrayTypes is None:\n        arrayTypes = [_ for _ in viewkeys(binaryDataInfo)]\n    numEntries = len(binaryDataInfo)\n    xmlBinaryDataArrayList = ETREE.Element('binaryDataArrayList',\n                                           {'count': str(numEntries)}\n                                           )\n    for arrayType in arrayTypes:\n        _, dataTypeParam = maspy.xml.findBinaryDataType(binaryDataInfo[arrayType]['params'])\n        binaryData = binaryDataDict[arrayType]\n        bitEncoding = '64' if binaryData.dtype.str == '<f8' else '32'\n        if binaryData.size > 0:\n            binaryData, arrayLength = maspy.xml.encodeBinaryData(binaryData,\n                                                                 bitEncoding,\n                                                                 compression\n                                                                 )\n        else:\n            binaryData = ''\n            arrayLength = 0\n\n        # --- define binaryDataArray parameters --- #\n        params = list()\n        if bitEncoding == '64':\n            params.append(('MS:1000523', None, None))\n        else:\n            params.append(('MS:1000521', None, None))\n        if compression == 'zlib':\n            params.append(('MS:1000574', None, None))\n        else:\n            params.append(('MS:1000576', None, None))\n        mandatoryAccessions = ['MS:1000523', 'MS:1000521', 'MS:1000574',\n                               'MS:1000576'\n                               ]\n        for param in binaryDataInfo[arrayType]['params']:\n            if param[0] not in mandatoryAccessions:\n                params.append(param)\n\n        #Note: not all attributes supported\n        binaryDataArrayAttrib = {'encodedLength': str(len(binaryData))}\n        for attr in ['dataProcessingRef']:\n            if binaryDataInfo[arrayType][attr] is not None:\n                binaryDataArrayAttrib[attr] = binaryDataInfo[arrayType][attr]\n        xmlBinaryDataArray = ETREE.Element('binaryDataArray',\n                                           binaryDataArrayAttrib\n                                           )\n        maspy.xml.xmlAddParams(xmlBinaryDataArray, params)\n\n        xmlBinary = ETREE.Element('binary')\n        xmlBinary.text = binaryData\n        xmlBinaryDataArray.append(xmlBinary)\n        xmlBinaryDataArrayList.append(xmlBinaryDataArray)\n    return xmlBinaryDataArrayList"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate an XML Spectrum element for a given SpectrumMetadataItem instance.", "response": "def xmlSpectrumFromSmi(index, smi, sai=None, compression='zlib'):\n    \"\"\" #TODO: docstring\n\n    :param index: The zero-based, consecutive index of the spectrum in the\n        SpectrumList. (mzML specification)\n    :param smi: a SpectrumMetadataItem instance\n    :param sai: a SpectrumArrayItem instance, if none is specified no\n        binaryDataArrayList is written\n    :param compression: #TODO: docstring\n\n    :returns: #TODO: docstring\n    \"\"\"\n    if sai is not None:\n        arrayLength = [array.size for array in viewvalues(sai.arrays)]\n        if len(set(arrayLength)) != 1:\n            raise Exception('Unequal size for different array in sai.arrays')\n        else:\n            arrayLength = arrayLength[0]\n    else:\n        arrayLength = 0\n\n    spectrumAttrib = {'index': str(index), 'id': smi.attributes['id'],\n                      'defaultArrayLength': str(arrayLength)}\n\n    xmlSpectrum = ETREE.Element('spectrum', **spectrumAttrib)\n    maspy.xml.xmlAddParams(xmlSpectrum, smi.params)\n    #Add the scanList\n    if len(smi.scanList) > 0:\n        xmlSpectrum.append(xmlGenScanList(smi.scanList, smi.scanListParams))\n    if len(smi.precursorList) > 0:\n        xmlSpectrum.append(xmlGenPrecursorList(smi.precursorList))\n    if len(smi.productList) > 0:\n        xmlSpectrum.append(xmlGenProductList(smi.productList))\n    if sai is not None:\n        xmlSpectrum.append(xmlGenBinaryDataArrayList(sai.arrayInfo,\n                                                     sai.arrays,\n                                                     compression=compression\n                                                     ))\n    return xmlSpectrum"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xmlChromatogramFromCi(index, ci, compression='zlib'):\n    arrayLength = [array.size for array in viewvalues(ci.arrays)]\n    if len(set(arrayLength)) != 1:\n        raise Exception('Unequal size for different array in sai.arrays')\n    else:\n        arrayLength = arrayLength[0]\n\n    chromatogramAttrib = {'index': str(index), 'id': ci.id,\n                          'defaultArrayLength': str(arrayLength)}\n    if 'dataProcessingRef' in ci.attrib:\n        chromatogramAttrib.update({'dataProcessingRef': dataProcessingRef})\n\n    xmlChromatogram = ETREE.Element('chromatogram', **chromatogramAttrib)\n    maspy.xml.xmlAddParams(xmlChromatogram, ci.params)\n    #TODO: add appropriate functions for precursor and product\n    if ci.product is not None:\n        raise NotImplementedError()\n    if ci.precursor is not None:\n        raise NotImplementedError()\n\n    #Sort the array keys, that 'rt' is always the first, necessary for example\n    #   for the software \"SeeMS\" to properly display chromatograms.\n    arrayTypes = set(ci.arrayInfo)\n    if 'rt' in arrayTypes:\n        arrayTypes.remove('rt')\n        arrayTypes = ['rt'] + list(arrayTypes)\n    else:\n        arrayTypes = list(arrayTypes)\n\n    xmlChromatogram.append(xmlGenBinaryDataArrayList(ci.arrayInfo,\n                                                     ci.arrays,\n                                                     compression=compression,\n                                                     arrayTypes=arrayTypes\n                                                     )\n                           )\n    return xmlChromatogram", "response": "Generate an XML chromatogram from a CI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, query, until_zero=False):\n\n        if self._conn.closed:\n            self._conn = psycopg2.connect(self._connection_string, connection_factory=pgpm.lib.utils.db.MegaConnection)\n        cur = self._conn.cursor()\n\n        # be cautious, dangerous thing\n        self._conn.autocommit = True\n\n        # Check if DB is pgpm enabled\n        if not pgpm.lib.utils.db.SqlScriptsHelper.schema_exists(cur, self._pgpm_schema_name):\n            self._logger.error('Can\\'t deploy schemas to DB where pgpm was not installed. '\n                               'First install pgpm by running pgpm install')\n            self._conn.close()\n            sys.exit(1)\n\n        # check installed version of _pgpm schema.\n        pgpm_v_db_tuple = pgpm.lib.utils.db.SqlScriptsHelper.get_pgpm_db_version(cur, self._pgpm_schema_name)\n        pgpm_v_db = distutils.version.StrictVersion(\".\".join(pgpm_v_db_tuple))\n        pgpm_v_script = distutils.version.StrictVersion(pgpm.lib.version.__version__)\n        if pgpm_v_script > pgpm_v_db:\n            self._logger.error('{0} schema version is outdated. Please run pgpm install --upgrade first.'\n                               .format(self._pgpm_schema_name))\n            self._conn.close()\n            sys.exit(1)\n        elif pgpm_v_script < pgpm_v_db:\n            self._logger.error('Deployment script\\'s version is lower than the version of {0} schema '\n                               'installed in DB. Update pgpm script first.'.format(self._pgpm_schema_name))\n            self._conn.close()\n            sys.exit(1)\n\n        # Executing query\n        if until_zero:\n            self._logger.debug('Running query {0} until it returns 0 (but not more than 10000 times'\n                               .format(query))\n            proc_return_value = None\n            counter = 0\n            while proc_return_value != 0:\n                cur.execute(query)\n                proc_return_value = cur.fetchone()[0]\n                counter += 1\n                if counter > 9999:\n                    break\n        else:\n            self._logger.debug('Running query {0}'.format(query))\n            cur.execute(query)\n\n        # Commit transaction\n        self._conn.commit()\n\n        self._conn.close()\n\n        return 0", "response": "Execute a query and return the next result set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_pgpm_to_db(self, user_roles, upgrade=False):\n        if self._conn.closed:\n            self._conn = psycopg2.connect(self._connection_string, connection_factory=pgpm.lib.utils.db.MegaConnection)\n\n        cur = self._conn.cursor()\n\n        # get pgpm functions\n        functions_dict = pgpm.lib.utils.misc.collect_scripts_from_sources('lib/db_scripts/functions', False, '.', True,\n                                                                        self._logger)\n        triggers_dict = pgpm.lib.utils.misc.collect_scripts_from_sources('lib/db_scripts/triggers', False, '.', True,\n                                                                        self._logger)\n\n        # get current user\n        cur.execute(pgpm.lib.utils.db.SqlScriptsHelper.current_user_sql)\n        current_user = cur.fetchone()[0]\n\n        # check if current user is a super user\n        cur.execute(pgpm.lib.utils.db.SqlScriptsHelper.is_superuser_sql)\n        is_cur_superuser = cur.fetchone()[0]\n        if not is_cur_superuser:\n            self._logger.debug('User {0} is not a superuser. It is recommended that you connect as superuser '\n                               'when installing pgpm as some operation might need superuser rights'\n                               .format(current_user))\n\n        # Create schema if it doesn't exist\n        if pgpm.lib.utils.db.SqlScriptsHelper.schema_exists(cur, self._pgpm_schema_name):\n\n            # Executing pgpm trigger functions\n            if len(triggers_dict) > 0:\n                self._logger.info('Running functions definitions scripts')\n                self._logger.debug(triggers_dict)\n                pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                for key, value in triggers_dict.items():\n                    cur.execute(value)\n                self._logger.debug('Functions loaded to schema {0}'.format(self._pgpm_schema_name))\n            else:\n                self._logger.debug('No function scripts to deploy')\n\n            # check installed version of _pgpm schema.\n            pgpm_v_db_tuple = pgpm.lib.utils.db.SqlScriptsHelper.get_pgpm_db_version(cur, self._pgpm_schema_name)\n            pgpm_v_db = distutils.version.StrictVersion(\".\".join(pgpm_v_db_tuple))\n            pgpm_v_script = distutils.version.StrictVersion(pgpm.lib.version.__version__)\n            if pgpm_v_script > pgpm_v_db:\n                if upgrade:\n                    self._migrate_pgpm_version(cur, pgpm_v_db, pgpm_v_script, True)\n                else:\n                    self._migrate_pgpm_version(cur, pgpm_v_db, pgpm_v_script, False)\n            elif pgpm_v_script < pgpm_v_db:\n                self._logger.error('Deployment script\\'s version is lower than the version of {0} schema '\n                                   'installed in DB. Update pgpm script first.'.format(self._pgpm_schema_name))\n                self._conn.close()\n                sys.exit(1)\n            else:\n                self._logger.error('Can\\'t install pgpm as schema {0} already exists'.format(self._pgpm_schema_name))\n                self._conn.close()\n                sys.exit(1)\n\n            # Executing pgpm functions\n            if len(functions_dict) > 0:\n                self._logger.info('Running functions definitions scripts')\n                self._logger.debug(functions_dict)\n                pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                for key, value in functions_dict.items():\n                    if value:\n                        cur.execute(value)\n                self._logger.debug('Functions loaded to schema {0}'.format(self._pgpm_schema_name))\n            else:\n                self._logger.debug('No function scripts to deploy')\n\n        else:\n            # Prepare and execute preamble\n            deployment_script_preamble = pkgutil.get_data(self._main_module_name, 'lib/db_scripts/deploy_prepare_config.sql')\n            self._logger.info('Executing a preamble to install statement')\n            cur.execute(deployment_script_preamble)\n\n            # Python 3.x doesn't have format for byte strings so we have to convert\n            install_script = pkgutil.get_data(self._main_module_name, 'lib/db_scripts/install.tmpl.sql').decode('utf-8')\n            self._logger.info('Installing package manager')\n            cur.execute(install_script.format(schema_name=self._pgpm_schema_name))\n            migration_files_list = sorted(pkg_resources.resource_listdir(self._main_module_name, 'lib/db_scripts/migrations/'),\n                                          key=lambda filename: distutils.version.StrictVersion(filename.split('-')[0]))\n\n            # Executing pgpm trigger functions\n            if len(triggers_dict) > 0:\n                self._logger.info('Running functions definitions scripts')\n                self._logger.debug(triggers_dict)\n                pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                for key, value in triggers_dict.items():\n                    cur.execute(value)\n                self._logger.debug('Functions loaded to schema {0}'.format(self._pgpm_schema_name))\n            else:\n                self._logger.debug('No function scripts to deploy')\n\n            # Executing migration scripts after trigger functions\n            # as they may contain trigger definitions that use functions from pgpm\n            for file_info in migration_files_list:\n                # Python 3.x doesn't have format for byte strings so we have to convert\n                migration_script = pkg_resources.resource_string(self._main_module_name, 'lib/db_scripts/migrations/{0}'.format(file_info))\\\n                    .decode('utf-8').format(schema_name=self._pgpm_schema_name)\n                self._logger.debug('Running version upgrade script {0}'.format(file_info))\n                self._logger.debug(migration_script)\n                cur.execute(migration_script)\n\n            # Executing pgpm functions\n            if len(functions_dict) > 0:\n                self._logger.info('Running functions definitions scripts')\n                self._logger.debug(functions_dict)\n                pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                for key, value in functions_dict.items():\n                    cur.execute(value)\n                self._logger.debug('Functions loaded to schema {0}'.format(self._pgpm_schema_name))\n            else:\n                self._logger.debug('No function scripts to deploy')\n\n            # call this function to put in a migration log that there was a migration to the last version\n            # it's a hack basically due to the fact in 0.0.7-0.1.3 migration script migration info was manually inserted\n            # to avoid differences we add migration info to the last version (although it wasn't really a migration)\n            # to be refactored\n            cur.callproc('_add_migration_info', ['0.0.7', pgpm.lib.version.__version__])\n\n        # check if users of pgpm are specified\n        pgpm.lib.utils.db.SqlScriptsHelper.revoke_all(cur, self._pgpm_schema_name, 'public')\n        if not user_roles:\n            self._logger.debug('No user was specified to have permisions on _pgpm schema. '\n                               'This means only user that installed _pgpm will be able to deploy. '\n                               'We recommend adding more users.')\n        else:\n            # set default privilages to users\n            pgpm.lib.utils.db.SqlScriptsHelper.grant_default_usage_install_privileges(\n                cur, self._pgpm_schema_name, ', '.join(user_roles))\n            pgpm.lib.utils.db.SqlScriptsHelper.grant_usage_install_privileges(\n                cur, self._pgpm_schema_name, ', '.join(user_roles))\n\n        pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n        cur.callproc('_upsert_package_info',\n                     [self._pgpm_schema_name, self._pgpm_schema_subclass,\n                      self._pgpm_version.major, self._pgpm_version.minor, self._pgpm_version.patch,\n                      self._pgpm_version.pre, self._pgpm_version.metadata,\n                      'Package manager for Postgres', 'MIT'])\n        # Commit transaction\n        self._conn.commit()\n\n        self._conn.close()\n\n        return 0", "response": "Installs package manager and creates schema if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uninstall_pgpm_from_db(self):\n        drop_schema_cascade_script = 'DROP SCHEMA {schema_name} CASCADE;'\n\n        if self._conn.closed:\n            self._conn = psycopg2.connect(self._connection_string, connection_factory=pgpm.lib.utils.db.MegaConnection)\n\n        cur = self._conn.cursor()\n\n        # get current user\n        cur.execute(pgpm.lib.utils.db.SqlScriptsHelper.current_user_sql)\n        current_user = cur.fetchone()[0]\n\n        # check if current user is a super user\n        cur.execute(pgpm.lib.utils.db.SqlScriptsHelper.is_superuser_sql)\n        is_cur_superuser = cur.fetchone()[0]\n        if not is_cur_superuser:\n            self._logger.debug('User {0} is not a superuser. Only superuser can remove pgpm'\n                               .format(current_user))\n            sys.exit(1)\n\n        self._logger.debug('Removing pgpm from DB by dropping schema {0}'.format(self._pgpm_schema_name))\n        cur.execute(drop_schema_cascade_script.format(schema_name=self._pgpm_schema_name))\n\n        # Commit transaction\n        self._conn.commit()\n\n        self._conn.close()\n\n        return 0", "response": "Removes pgpm from db and all related metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _migrate_pgpm_version(self, cur, version_pgpm_db, version_pgpm_script,  migrate_or_leave):\n        migrations_file_re = r'^(.*)-(.*).tmpl.sql$'\n        migration_files_list = sorted(pkg_resources.resource_listdir(self._main_module_name, 'lib/db_scripts/migrations/'),\n                                      key=lambda filename: distutils.version.StrictVersion(filename.split('-')[0]))\n        for file_info in migration_files_list:\n            versions_list = re.compile(migrations_file_re, flags=re.IGNORECASE).findall(file_info)\n            version_a = distutils.version.StrictVersion(versions_list[0][0])\n            version_b = distutils.version.StrictVersion(versions_list[0][1])\n            if version_pgpm_script >= version_a and version_b > version_pgpm_db:\n                # Python 3.x doesn't have format for byte strings so we have to convert\n                migration_script = pkg_resources.resource_string(self._main_module_name, 'lib/db_scripts/migrations/{0}'.format(file_info))\\\n                    .decode('utf-8').format(schema_name=self._pgpm_schema_name)\n                if migrate_or_leave:\n                    self._logger.debug('Running version upgrade script {0}'.format(file_info))\n                    self._logger.debug(migration_script)\n                    cur.execute(migration_script)\n                    self._conn.commit()\n                    pgpm.lib.utils.db.SqlScriptsHelper.set_search_path(cur, self._pgpm_schema_name)\n                    cur.callproc('_add_migration_info', [versions_list[0][0], versions_list[0][1]])\n                    self._conn.commit()\n                    self._logger.debug('Successfully finished running version upgrade script {0}'.format(file_info))\n\n        if not migrate_or_leave:\n            self._logger.error('{0} schema version is outdated. Please run pgpm install --upgrade first.'\n                               .format(self._pgpm_schema_name))\n            self._conn.close()\n            sys.exit(1)", "response": "This function is used to migrate a pgpm script from one version of pgpm to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, *args, **kwargs):\n        if self.pk is None:\n            if hasattr(self, 'product'):\n                if not self.description:\n                    self.description = self.product\n                self.price_recommended = self.product.price_base\n            elif hasattr(self, 'line_order'):\n                if not self.description:\n                    self.description = self.line_order.product\n                self.price_recommended = self.line_order.price_base\n\n        if hasattr(self, 'tax') and hasattr(self, 'type_tax'):\n            self.tax = self.type_tax.tax\n\n        if hasattr(self, 'product'):\n            self.tax_label = self.product.product.tax.name\n            if self.product.code:\n                self.code = self.product.code\n            else:\n                self.code = self.product.product.code\n\n        \"\"\"\n        si al guardar una linea asociada a un documento bloqueado (lock==True), duplicar el documento en una nueva versi\u00f3n\n        \"\"\"\n        self.update_total(force_save=False)\n        if 'force_save' in kwargs:\n            kwargs.pop('force_save')\n        return super(GenLineProduct, self).save(*args, **kwargs)", "response": "Si al guardar un linea asociada a un documento bloqueado."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a document from a list of lines.", "response": "def create_document_from_another(pk, list_lines,\n                                     MODEL_SOURCE, MODEL_FINAL, MODEL_LINE_SOURCE, MODEL_LINE_FINAL,\n                                     url_reverse, related_line, related_object,\n                                     msg_error_relation, msg_error_not_found, unique):\n        \"\"\"\n        pk: pk del documento origen\n        list_lines: listado de pk de lineas de origen\n        MODEL_SOURCE: modelo del documento origen\n        MODEL_FINAL: model del documento final\n        MODEL_LINE_SOURCE: modelo de la linea origen\n        MODEL_LINE_FINAL: modelo de la linea final\n        url_reverse: url del destino\n        related_line: campo del modelo linea final en el que ir\u00e1 asignada la linea origen\n        related_object: campo del modelo linea final en el que ir\u00e1 asignado el objeto final\n        msg_error_relation: Mensaje de error indicando que las lineas ya est\u00e1n relacionadas\n        msg_error_not_found: Mensaje de error indicando que no se encuentra el objeto origen\n        unique: (True/False) Indica si puede haber m\u00e1s de una linea asociada a otras lineas\n        \"\"\"\n        context = {}\n        obj_src = MODEL_SOURCE.objects.filter(pk=pk).first()\n        if list_lines and obj_src:\n            # parse to int\n            list_lines = [int(x) for x in list_lines]\n            # list of lines objects\n            if unique:\n                create = not MODEL_LINE_FINAL.objects.filter(**{\"{}__pk__in\".format(related_line): list_lines}).exists()\n            else:\n                create = True\n\n            \"\"\"\n            si debiendo ser filas unicas no las encuentra en el modelo final, se crea el nuevo documento\n            \"\"\"\n            if create:\n                with transaction.atomic():\n                    obj_final = MODEL_FINAL()\n                    obj_final.customer = obj_src.customer\n                    obj_final.date = datetime.datetime.now()\n                    obj_final.billing_series = obj_src.billing_series\n\n                    if isinstance(obj_final, SalesOrder):\n                        obj_final.budget = obj_src\n\n                    obj_final.save()\n\n                    for lb_pk in list_lines:\n                        line_src = MODEL_LINE_SOURCE.objects.filter(pk=lb_pk).first()\n                        if line_src:\n                            line_final = MODEL_LINE_FINAL(**{\"{}_id\".format(related_object): obj_final.pk, related_line: line_src})\n                            # line_final.order = obj_final\n                            # line_final.line_budget = line_src\n                            src_list_fields = [f.name for f in line_src._meta.get_fields()]\n                            dst_list_fields = [f.name for f in line_final._meta.get_fields()]\n                            if 'product' in src_list_fields and 'product' in dst_list_fields:\n                                line_final.product = line_src.product\n                            if 'description' in src_list_fields and 'description' in dst_list_fields:\n                                line_final.description = line_src.description\n                            if 'code' in src_list_fields and 'code' in dst_list_fields:\n                                line_final.code = line_src.code\n                            # if hasattr(line_src, 'line_order') and hasattr(line_final, 'line_order'):\n                            if 'line_order' in src_list_fields and 'line_order' in dst_list_fields:\n                                line_final.line_order = line_src.line_order\n                            line_final.quantity = line_src.quantity\n                            line_final.price_base = line_src.price_base\n                            # if hasattr(line_src, 'price_recommended') and hasattr(line_final, 'price_recommended'):\n                            if 'price_recommended' in src_list_fields and 'price_recommended' in dst_list_fields:\n                                line_final.price_recommended = line_src.price_recommended\n                            line_final.tax = line_src.tax\n                            # line_final.type_tax = line_src.type_tax\n                            line_final.discount = line_src.discount\n                            if 'removed' in src_list_fields and 'removed' in dst_list_fields:\n                                line_final.removed = line_src.removed\n                            line_final.save()\n\n                            if hasattr(line_src, 'line_basket_option_sales') and line_src.line_basket_option_sales.exists():\n                                for opt_src in line_src.line_basket_option_sales.all():\n                                    opt_dst = SalesLineOrderOption()\n                                    opt_dst.line_order = line_final\n                                    opt_dst.product_option = opt_src.product_option\n                                    opt_dst.product_final = opt_src.product_final\n                                    opt_dst.quantity = opt_src.quantity\n                                    opt_dst.save()\n\n                    # bloqueamos el documento origen\n                    obj_src.lock = True\n                    obj_src.save()\n\n                    # context['url'] = reverse('ordersaless_details', kwargs={'pk': order.pk})\n                    context['url'] = \"{}#/{}\".format(reverse(url_reverse), obj_final.pk)\n                    context['obj_final'] = obj_final\n            else:\n                # _(\"Hay lineas asignadas a pedidos\")\n                context['error'] = msg_error_relation\n        else:\n            # _('Budget not found')\n            context['error'] = msg_error_not_found\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_albaran_automatic(pk, list_lines):\n        line_bd = SalesLineAlbaran.objects.filter(line_order__pk__in=list_lines).values_list('line_order__pk')\n        if line_bd.count() == 0 or len(list_lines) != len(line_bd[0]):\n            # solo aquellas lineas de pedidos que no estan ya albarandas\n            if line_bd.count() != 0:\n                for x in line_bd[0]:\n                    list_lines.pop(list_lines.index(x))\n\n            GenLineProduct.create_albaran_from_order(pk, list_lines)", "response": "create_albaran_automatic is a partir de la albaran"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an invoice from a list of lineas de pedidos.", "response": "def create_invoice_from_albaran(pk, list_lines):\n        \"\"\"\n        la pk y list_lines son de albaranes, necesitamos la info de las lineas de pedidos\n        \"\"\"\n        context = {}\n        if list_lines:\n            new_list_lines = [x[0] for x in SalesLineAlbaran.objects.values_list('line_order__pk').filter(\n                pk__in=[int(x) for x in list_lines]\n            ).exclude(invoiced=True)]\n            if new_list_lines:\n                lo = SalesLineOrder.objects.values_list('order__pk').filter(pk__in=new_list_lines)[:1]\n                if lo and lo[0] and lo[0][0]:\n                    new_pk = lo[0][0]\n                    context = GenLineProduct.create_invoice_from_order(new_pk, new_list_lines)\n                    if 'error' not in context or not context['error']:\n                        SalesLineAlbaran.objects.filter(\n                            pk__in=[int(x) for x in list_lines]\n                        ).exclude(invoiced=True).update(invoiced=True)\n                    return context\n                else:\n                    error = _('Pedido no encontrado')\n            else:\n                error = _('Lineas no relacionadas con pedido')\n        else:\n            error = _('Lineas no seleccionadas')\n        context['error'] = error\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_invoice_from_ticket(pk, list_lines):\n        context = {}\n        if list_lines:\n            new_list_lines = [x[0] for x in SalesLineTicket.objects.values_list('line_order__pk').filter(pk__in=[int(x) for x in list_lines])]\n            if new_list_lines:\n                lo = SalesLineOrder.objects.values_list('order__pk').filter(pk__in=new_list_lines)[:1]\n                if lo and lo[0] and lo[0][0]:\n                    new_pk = lo[0][0]\n                    return GenLineProduct.create_invoice_from_order(new_pk, new_list_lines)\n                else:\n                    error = _('Pedido no encontrado')\n            else:\n                error = _('Lineas no relacionadas con pedido')\n        else:\n            error = _('Lineas no seleccionadas')\n        context['error'] = error\n        return context", "response": "Creates an invoice from a list of lineas de pedidos."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_options(self, options):\n        with transaction.atomic():\n            for option in options:\n                opt = self.line_basket_option_sales.filter(\n                    product_option=option['product_option']\n                ).first()\n                if opt:  # edit\n                    change = False\n                    if opt.quantity != option['quantity']:\n                        opt.quantity = option['quantity']\n                        change = True\n                    if opt.product_final != option['product_final']:\n                        opt.product_final = option['product_final']\n                        change = True\n                    if change:\n                        opt.save()\n                else:  # new\n                    opt = SalesLineBasketOption()\n                    # raise Exception(self.pk, self.__dict__, self)\n                    # raise Exception(self.pk)\n                    opt.line_budget = SalesLineBasket.objects.get(pk=self.pk)\n                    opt.product_option = option['product_option']\n                    opt.product_final = option['product_final']\n                    opt.quantity = option['quantity']\n                    opt.save()", "response": "Set options for this line budget"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef findmodules(path, recurse=False):\n    output = set()\n    roots = set()\n    for root, folders, files in os.walk(path):\n        # add packages\n        for folder in folders:\n            pkgpath = os.path.join(root, folder, '__init__.py')\n            if os.path.exists(pkgpath):\n                output.add(packageFromPath(pkgpath))\n\n        # add modules\n        rootpth = packageRootPath(root)\n        rootpkg = packageFromPath(root)\n        roots.add(rootpth)\n        for file_ in files:\n            name, ext = os.path.splitext(file_)\n            if ext not in ('.py', '.pyo', '.pyc'):\n                continue\n\n            if name in ('__init__', '__plugins__'):\n                continue\n\n            if rootpkg:\n                output.add(rootpkg + '.' + name)\n            else:\n                output.add(name)\n\n        if not recurse:\n            break\n\n    return list(output), list(roots)", "response": "Look up the modules for the given path and returns a list of the modules and the paths that are found."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting a module specifically from a file.", "response": "def importfile(filename):\n    \"\"\"\n    Imports a module specifically from a file.\n    \n    :param      filename | <str>\n    \n    :return     <module> || None\n    \"\"\"\n    pkg = packageFromPath(filename, includeModule=True)\n    root = packageRootPath(filename)\n\n    if root not in sys.path:\n        sys.path.insert(0, root)\n\n    __import__(pkg)\n    return sys.modules[pkg]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports all the sub - modules of a package.", "response": "def importmodules(package_or_toc, ignore=None, recurse=False, silent=None):\n    \"\"\"\n    Imports all the sub-modules of a package, a useful technique for developing\n    plugins.  By default, this method will walk the directory structure looking\n    for submodules and packages.  You can also specify a __toc__ attribute\n    on the package to define the sub-modules that you want to import.\n    \n    :param      package_or_toc  | <package> || <str> filename\n                ignore          | [<str>, ..] || None\n                recurse         | <bool>\n                silent          | <bool>\n    \n    :usage      |>>> import projex\n                |>>> import projex.docgen\n                |>>> projex.importmodules(projex.docgen)\n                |[<projex.docgen.commands>, <projex.docgen.default_config>, ..]\n    \n    :return     [<module> || <package>, ..]\n    \"\"\"\n    if package_or_toc in __IMPORTED:\n        return\n\n    __IMPORTED.add(package_or_toc)\n\n    if silent is None:\n        silent = os.environ.get('PROJEX_LOG_IMPORTS', 'False').lower() != 'true'\n\n    toc = []\n    output = []\n    if ignore is None:\n        ignore = []\n\n    # import from a set toc file\n    if type(package_or_toc) in (str, unicode):\n        # import a toc file\n        if os.path.isfile(package_or_toc):\n            f = open(package_or_toc, 'r')\n            toc = f.readlines()\n            f.close()\n\n        # import from a directory\n        elif os.path.isdir(package_or_toc):\n            toc, paths = findmodules(package_or_toc, recurse=recurse)\n            for path in paths:\n                if path in sys.path:\n                    sys.path.remove(path)\n\n                sys.path.insert(0, path)\n\n        # import a module by string\n        else:\n            use_sub_modules = False\n            if package_or_toc.endswith('.*'):\n                use_sub_modules = True\n                package_or_toc = package_or_toc[:-2]\n\n            try:\n                __import__(package_or_toc)\n                module = sys.modules[package_or_toc]\n            except ImportError as err:\n                if not silent:\n                    logger.error('Unable to import module: %s', package_or_toc)\n                    logger.debug(traceback.print_exc())\n                return []\n            except KeyError:\n                if not silent:\n                    logger.error('Unable to find module: %s', package_or_toc)\n                return []\n\n            if use_sub_modules:\n                base = os.path.dirname(module.__file__)\n                for path in os.listdir(base):\n                    if path.endswith('.py') and path != '__init__.py':\n                        importmodules(package_or_toc + '.' + path.replace('.py', ''))\n                    elif os.path.isdir(os.path.join(base, path)):\n                        importmodules(package_or_toc + '.' + path)\n            else:\n                return importmodules(module)\n\n    # import from a given package\n    else:\n        toc = getattr(package_or_toc, '__toc__', [])\n\n        if not toc:\n            toc = []\n            recurse = getattr(package_or_toc, '__recurse__', False)\n            try:\n                paths = package_or_toc.__path__\n            except AttributeError:\n                try:\n                    paths = [os.path.dirname(package_or_toc.__file__)]\n                except AttributeError:\n                    paths = []\n\n            for path in paths:\n                data = findmodules(path, recurse=recurse)\n                toc += data[0]\n                for sub_path in data[1]:\n                    if sub_path in sys.path:\n                        sys.path.remove(sub_path)\n\n                    sys.path.insert(0, sub_path)\n\n            setattr(package_or_toc, '__toc__', toc)\n\n    # import using standard means (successful for when dealing with \n    for modname in sorted(toc):\n        # check against a callable ignore method\n        if callable(ignore) and ignore(modname):\n            continue\n\n        elif type(modname) in (list, tuple) and modname not in ignore:\n            continue\n\n        # ignore preset options\n        if modname.endswith('__init__'):\n            continue\n        elif modname.endswith('__plugins__'):\n            continue\n\n        try:\n            output.append(sys.modules[modname])\n            continue\n        except KeyError:\n            pass\n\n        if not silent:\n            logger.debug('Importing: %s' % modname)\n        try:\n            mod = importlib.import_module(modname)\n            sys.modules[modname] = mod\n            output.append(mod)\n        except ImportError, err:\n            if not silent:\n                logger.error('Error importing module: %s', modname)\n                logger.debug(traceback.print_exc())\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport the object with the given name from the inputted module.", "response": "def importobject(module_name, object_name):\n    \"\"\"\n    Imports the object with the given name from the inputted module.\n    \n    :param      module_name | <str>\n                object_name | <str>\n    \n    :usage      |>>> import projex\n                |>>> modname = 'projex.envmanager'\n                |>>> attr = 'EnvManager'\n                |>>> EnvManager = projex.importobject(modname, attr)\n    \n    :return     <object> || None\n    \"\"\"\n    if module_name not in sys.modules:\n        try:\n            __import__(module_name)\n        except ImportError:\n            logger.debug(traceback.print_exc())\n            logger.error('Could not import module: %s', module_name)\n            return None\n\n    module = sys.modules.get(module_name)\n    if not module:\n        logger.warning('No module %s found.' % module_name)\n        return None\n\n    if not hasattr(module, object_name):\n        logger.warning('No object %s in %s.' % (object_name, module_name))\n        return None\n\n    return getattr(module, object_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef packageRootPath(path):\n    path = nstr(path)\n    if os.path.isfile(path):\n        path = os.path.dirname(path)\n\n    parts = os.path.normpath(path).split(os.path.sep)\n    package_parts = []\n\n    for i in range(len(parts), 0, -1):\n        filename = os.path.sep.join(parts[:i] + ['__init__.py'])\n\n        if not os.path.isfile(filename):\n            break\n\n        package_parts.insert(0, parts[i - 1])\n\n    if not package_parts:\n        return path\n    return os.path.abspath(os.path.sep.join(parts[:-len(package_parts)]))", "response": "Returns the root file path that defines a Python package from the inputted\n    path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the python package path based on the inputted path.", "response": "def packageFromPath(path, includeModule=False):\n    \"\"\"\n    Determines the python package path based on the inputted path.\n    \n    :param      path | <str>\n    \n    :return     <str>\n    \"\"\"\n    path = nstr(path)\n    module = ''\n    if os.path.isfile(path):\n        path, fname = os.path.split(path)\n        if fname.endswith('.py') and fname != '__init__.py':\n            module = fname.split('.')[0]\n\n    parts = os.path.normpath(path).split(os.path.sep)\n    package_parts = []\n\n    for i in range(len(parts), 0, -1):\n        filename = os.path.sep.join(parts[:i] + ['__init__.py'])\n\n        if not os.path.isfile(filename):\n            break\n\n        package_parts.insert(0, parts[i - 1])\n\n    if includeModule and module:\n        package_parts.append(module)\n\n    return '.'.join(package_parts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the website location for the project.", "response": "def website(app=None, mode='home', subcontext='UserGuide'):\n    \"\"\"\n    Returns the website location for projex software.\n    \n    :param      app  | <str> || None\n                mode | <str> (home, docs, blog, dev)\n    \n    :return     <str>\n    \"\"\"\n    base_url = WEBSITES.get(mode, '')\n\n    if app and base_url:\n        opts = {'app': app, 'base_url': base_url}\n        base_url = SUBCONTEXT_MAP.get((mode, subcontext), base_url)\n        base_url %= opts\n\n    return base_url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if values need to be converted before they get mogrifyd", "response": "def _check_values(in_values):\n        \"\"\" Check if values need to be converted before they get mogrify'd\n        \"\"\"\n        out_values = []\n        for value in in_values:\n            # if isinstance(value, (dict, list)):\n            #     out_values.append(json.dumps(value))\n            # else:\n            out_values.append(value)\n\n        return tuple(out_values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert(self, table, data_list, return_cols='id'):\n        data_list = copy.deepcopy(data_list)  # Create deepcopy so the original list does not get modified\n        # Make sure that `data_list` is a list\n        if not isinstance(data_list, list):\n            data_list = [data_list]\n        # Make sure data_list has content\n        if len(data_list) == 0:\n            # No need to continue\n            return []\n\n        # Data in the list must be dicts (just check the first one)\n        if not isinstance(data_list[0], dict):\n            logger.critical(\"Data must be a list of dicts\")\n            # Do not return here, let the exception handle the error that will be thrown when the query runs\n\n        # Make sure return_cols is a list\n        if return_cols is None or len(return_cols) == 0 or return_cols[0] is None:\n            return_cols = ''\n        elif not isinstance(return_cols, list):\n            return_cols = [return_cols]\n\n        if len(return_cols) > 0:\n            return_cols = 'RETURNING ' + ','.join(return_cols)\n\n        try:\n            with self.getcursor() as cur:\n                query = \"INSERT INTO {table} ({fields}) VALUES {values} {return_cols}\"\\\n                        .format(table=table,\n                                fields='\"{0}\"'.format('\", \"'.join(data_list[0].keys())),\n                                values=','.join(['%s'] * len(data_list)),\n                                return_cols=return_cols,\n                                )\n                values = []\n                for row in [tuple(v.values()) for v in data_list]:\n                    values.append(_check_values(row))\n\n                query = cur.mogrify(query, values)\n                cur.execute(query)\n\n                try:\n                    return cur.fetchall()\n                except Exception:\n                    return None\n\n        except Exception as e:\n            logger.exception(\"Error inserting data\")\n            logger.debug(\"Error inserting data: {data}\".format(data=data_list))\n            raise e.with_traceback(sys.exc_info()[2])", "response": "Insert a list of items into a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a bulk upsert statement which is much faster (~6x in tests with 10k & 100k rows and n cols) for upserting data then executemany() TODO: Is there a limit of length the query can be? If so handle it.", "response": "def upsert(self, table, data_list, on_conflict_fields, on_conflict_action='update',\n               update_fields=None, return_cols='id'):\n        \"\"\"\n        Create a bulk upsert statement which is much faster (~6x in tests with 10k & 100k rows and n cols)\n        for upserting data then executemany()\n\n        TODO: Is there a limit of length the query can be? If so handle it.\n        \"\"\"\n        data_list = copy.deepcopy(data_list)  # Create deepcopy so the original list does not get modified\n        # Make sure that `data_list` is a list\n        if not isinstance(data_list, list):\n            data_list = [data_list]\n        # Make sure data_list has content\n        if len(data_list) == 0:\n            # No need to continue\n            return []\n        # Data in the list must be dicts (just check the first one)\n        if not isinstance(data_list[0], dict):\n            logger.critical(\"Data must be a list of dicts\")\n            # TODO: raise some error here rather then returning None\n            return None\n\n        # Make sure on_conflict_fields is a list\n        if not isinstance(on_conflict_fields, list):\n            on_conflict_fields = [on_conflict_fields]\n        # Make sure on_conflict_fields has data\n        if len(on_conflict_fields) == 0 or on_conflict_fields[0] is None:\n            # No need to continue\n            logger.critical(\"Must pass in `on_conflict_fields` argument\")\n            # TODO: raise some error here rather then returning None\n            return None\n\n        # Make sure return_cols is a list\n        if return_cols is None or len(return_cols) == 0 or return_cols[0] is None:\n            return_cols = ''\n        elif not isinstance(return_cols, list):\n            return_cols = [return_cols]\n\n        if len(return_cols) > 0:\n            return_cols = 'RETURNING ' + ','.join(return_cols)\n\n        # Make sure update_fields is a list/valid\n        if on_conflict_action == 'update':\n            if not isinstance(update_fields, list):\n                update_fields = [update_fields]\n            # If noting is passed in, set `update_fields` to all (data_list-on_conflict_fields)\n            if len(update_fields) == 0 or update_fields[0] is None:\n                update_fields = list(set(data_list[0].keys()) - set(on_conflict_fields))\n                # If update_fields is empty here that could only mean that all fields are set as conflict_fields\n                if len(update_fields) == 0:\n                    logger.critical(\"Not all the fields can be `on_conflict_fields` when doing an update\")\n                    # TODO: raise some error here rather then returning None\n                    return None\n\n            # If everything is good to go with the update fields\n            fields_update_tmp = []\n            for key in data_list[0].keys():\n                fields_update_tmp.append('\"{0}\"=\"excluded\".\"{0}\"'.format(key))\n            conflict_action_sql = 'UPDATE SET {update_fields}'\\\n                                  .format(update_fields=', '.join(fields_update_tmp))\n        else:\n            # Do nothing on conflict\n            conflict_action_sql = 'NOTHING'\n\n        try:\n            with self.getcursor() as cur:\n                query = \"\"\"INSERT INTO {table} ({insert_fields})\n                           VALUES {values}\n                           ON CONFLICT ({on_conflict_fields}) DO\n                           {conflict_action_sql}\n                           {return_cols}\n                        \"\"\".format(table=table,\n                                   insert_fields='\"{0}\"'.format('\",\"'.join(data_list[0].keys())),\n                                   values=','.join(['%s'] * len(data_list)),\n                                   on_conflict_fields=','.join(on_conflict_fields),\n                                   conflict_action_sql=conflict_action_sql,\n                                   return_cols=return_cols,\n                                   )\n                # Get all the values for each row and create a lists of lists\n                values = []\n                for row in [list(v.values()) for v in data_list]:\n                    values.append(_check_values(row))\n\n                query = cur.mogrify(query, values)\n\n                cur.execute(query)\n\n                try:\n                    return cur.fetchall()\n                except Exception:\n                    return None\n\n        except Exception as e:\n            logger.exception(\"Error upserting data\")\n            logger.debug(\"Error upserting data: {data}\".format(data=data_list))\n            raise e.with_traceback(sys.exc_info()[2])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, table, data_list, matched_field=None, return_cols='id'):\n        data_list = copy.deepcopy(data_list)  # Create deepcopy so the original list does not get modified\n        if matched_field is None:\n            # Assume the id field\n            logger.info(\"Matched field not defined, assuming the `id` field\")\n            matched_field = 'id'\n\n        # Make sure that `data_list` is a list\n        if not isinstance(data_list, list):\n            data_list = [data_list]\n\n        if len(data_list) == 0:\n            # No need to continue\n            return []\n\n        # Make sure return_cols is a list\n        if return_cols is None or len(return_cols) == 0 or return_cols[0] is None:\n            return_cols = ''\n        elif not isinstance(return_cols, list):\n            return_cols = [return_cols]\n\n        if len(return_cols) > 0:\n            return_cols = 'RETURNING ' + ','.join(return_cols)\n\n        # Data in the list must be dicts (just check the first one)\n        if not isinstance(data_list[0], dict):\n            logger.critical(\"Data must be a list of dicts\")\n            # Do not return here, let the exception handle the error that will be thrown when the query runs\n\n        try:\n            with self.getcursor() as cur:\n                query_list = []\n                # TODO: change to return data from the database, not just what you passed in\n                return_list = []\n                for row in data_list:\n                    if row.get(matched_field) is None:\n                        logger.debug(\"Cannot update row. Missing field {field} in data {data}\"\n                                     .format(field=matched_field, data=row))\n                        logger.error(\"Cannot update row. Missing field {field} in data\".format(field=matched_field))\n                        continue\n\n                    # Pull matched_value from data to be updated and remove that key\n                    matched_value = row.get(matched_field)\n                    del row[matched_field]\n\n                    query = \"UPDATE {table} SET {data} WHERE {matched_field}=%s {return_cols}\"\\\n                            .format(table=table,\n                                    data=','.join(\"%s=%%s\" % u for u in row.keys()),\n                                    matched_field=matched_field,\n                                    return_cols=return_cols\n                                    )\n                    values = list(row.values())\n                    values.append(matched_value)\n                    values = _check_values(values)\n\n                    query = cur.mogrify(query, values)\n                    query_list.append(query)\n                    return_list.append(matched_value)\n\n                finial_query = b';'.join(query_list)\n                cur.execute(finial_query)\n\n                try:\n                    return cur.fetchall()\n                except Exception:\n                    return None\n\n        except Exception as e:\n            logger.exception(\"Error updating data\")\n            logger.debug(\"Error updating data: {data}\".format(data=data_list))\n            raise e.with_traceback(sys.exc_info()[2])", "response": "Update the entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncloning an existing repository.", "response": "def clone(srcpath, destpath, vcs=None):\n    \"\"\"Clone an existing repository.\n\n    :param str srcpath: Path to an existing repository\n    :param str destpath: Desired path of new repository\n    :param str vcs: Either ``git``, ``hg``, or ``svn``\n    :returns VCSRepo: The newly cloned repository\n\n    If ``vcs`` is not given, then the repository type is discovered from\n    ``srcpath`` via :func:`probe`.\n\n    \"\"\"\n    vcs = vcs or probe(srcpath)\n    cls = _get_repo_class(vcs)\n    return cls.clone(srcpath, destpath)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprobing a repository for its type.", "response": "def probe(path):\n    \"\"\"Probe a repository for its type.\n\n    :param str path: The path of the repository\n    :raises UnknownVCSType: if the repository type couldn't be inferred\n    :returns str: either ``git``, ``hg``, or ``svn``\n\n    This function employs some heuristics to guess the type of the repository.\n\n    \"\"\"\n    import os\n    from .common import UnknownVCSType\n    if os.path.isdir(os.path.join(path, '.git')):\n        return 'git'\n    elif os.path.isdir(os.path.join(path, '.hg')):\n        return 'hg'\n    elif (\n        os.path.isfile(os.path.join(path, 'config')) and\n        os.path.isdir(os.path.join(path, 'objects')) and\n        os.path.isdir(os.path.join(path, 'refs')) and\n        os.path.isdir(os.path.join(path, 'branches'))\n    ):\n        return 'git'\n    elif (\n        os.path.isfile(os.path.join(path, 'format')) and\n        os.path.isdir(os.path.join(path, 'conf')) and\n        os.path.isdir(os.path.join(path, 'db')) and\n        os.path.isdir(os.path.join(path, 'locks'))\n    ):\n        return 'svn'\n    else:\n        raise UnknownVCSType(path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening an existing repository containing the given path.", "response": "def open(path, vcs=None):\n    \"\"\"Open an existing repository\n\n    :param str path: The path of the repository\n    :param vcs: If specified, assume the given repository type to avoid\n                auto-detection. Either ``git``, ``hg``, or ``svn``.\n    :raises UnknownVCSType: if the repository type couldn't be inferred\n\n    If ``vcs`` is not specified, it is inferred via :func:`probe`.\n\n    \"\"\"\n    import os\n    assert os.path.isdir(path), path + ' is not a directory'\n    vcs = vcs or probe(path)\n    cls = _get_repo_class(vcs)\n    return cls(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_attributes(self, attributes, extra=None):\n        extra = extra or ()\n        unknown_keys = set(attributes) - set(self._possible_attributes) - set(extra)\n        if unknown_keys:\n            logger.warning('%s got unknown attributes: %s' %\n                            (self.__class__.__name__, unknown_keys))", "response": "Check if attributes given to the constructor can be used to\n        instanciate a valid node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, name, strict=True):\n        if not isinstance(name, str) or name.startswith('_'):\n            raise AttributeError(self.__class__.__name__, name)\n        elif strict and name not in self._possible_attributes:\n            raise AttributeError('%s is not a valid attribute of %r.' %\n                                 (name, self))\n        elif name in self._attributes:\n            return self._attributes[name]\n        else:\n            raise exceptions.AttributeNotProvided(name)", "response": "Get an attribute of the holder ( read - only access )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the new date based on the inputted months.", "response": "def addMonths(date, months):\n    \"\"\"\n    Returns the new date based on the inputted months.\n    \n    :param      date   | <datetime.date>\n                months | <int>\n    \n    :return     <datetime.date>\n    \"\"\"\n    # map from Qt information\n    if type(date).__name__ in ('QDate', 'QDateTime', 'QTime'):\n        date = date.toPython()\n\n    mult = months / abs(months)\n    years = mult * (abs(months) / 12)\n    months = mult * (abs(months) % 12)\n\n    # calculate the new month\n    month = date.month + months\n    if month < 1:\n        years -= 1\n        month = 12 - month\n\n    elif 12 < month:\n        years += 1\n        month %= 12\n\n    # calculate the new year\n    year = date.year + years\n\n    # calculate the new day\n    check = datetime.date(year, month, 1)\n    days = daysInMonth(check)\n\n    return datetime.date(year, month, min(date.day, days))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the new date based on the inputted number of years.", "response": "def addYears(date, years):\n    \"\"\"\n    Returns the new date based on the inputted number of years.\n    \n    :param      date  | <datetime.date>\n                years | <int>\n    \n    :return     <datetime.date>\n    \"\"\"\n    # map from Qt information\n    if type(date).__name__ in ('QDate', 'QDateTime', 'QTime'):\n        date = date.toPython()\n\n    return datetime.date(date.year + years, date.month, date.day)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef daysInMonth(date):\n    # map from Qt information\n    if type(date).__name__ in ('QDate', 'QDateTime', 'QTime'):\n        date = date.toPython()\n\n    month = date.month\n\n    # look for a leap year\n    if month == 2 and not date.year % 4:\n        return 29\n\n    return DaysInMonth.get(month, -1)", "response": "Returns the number of days in the month for the given date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of days in the year for the given date.", "response": "def daysInYear(date):\n    \"\"\"\n    Returns the number of days in the year for the given date.\n    \n    :param      date | <datetime.date> || <int>\n    \n    :return     <int>\n    \"\"\"\n    # map from Qt information\n    if type(date).__name__ in ('QDate', 'QDateTime', 'QTime'):\n        date = date.toPython()\n\n    if type(date) != int:\n        year = date.year\n    else:\n        year = date\n\n    if not year % 4:\n        return 366\n    return 365"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef displayName(date, options=None, format='%b %d, %Y'):\n    # map from Qt information\n    if type(date).__name__ in ('QDate', 'QDateTime', 'QTime'):\n        date = date.toPython()\n\n    if isinstance(date, datetime.datetime):\n        time = ' @ ' + date.strftime('%I:%M%p').strip('0M').lower()\n        date = date.date()\n    else:\n        time = ''\n\n    today = datetime.date.today()\n    delta = date - today\n\n    if delta.days == 0:\n        return 'Today' + time\n    elif delta.days == -1:\n        return 'Yesterday' + time\n    elif delta.days == 1:\n        return 'Tomorrow' + time\n    elif abs(delta.days) < 8:\n        # look for different weeks\n        if date.isocalendar()[1] != today.isocalendar()[1]:\n            qualifier = 'Last ' if delta.days < 0 else 'Next '\n        else:\n            qualifier = ''\n\n        return qualifier + date.strftime('%A') + time\n    else:\n        return date.strftime(format)", "response": "Returns the display name for the inputted date"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef named(date, options=None):\n    # map from Qt information\n    if type(date).__name__ in ('QDate', 'QDateTime', 'QTime'):\n        date = date.toPython()\n\n    if options is None:\n        options = Names.all()\n\n    # use the date information\n    if isinstance(date, datetime.datetime):\n        date = date.date()\n\n    # grab today's information\n    today = datetime.date.today()\n    today_month = today.month\n    today_year, today_week, today_weekday = today.isocalendar()\n\n    # grab yesterday's information\n    yesterday = today + datetime.timedelta(days=-1)\n    tomorrow = today + datetime.timedelta(days=1)\n\n    # grab the date information\n    date_month = date.month\n    date_year, date_week, date_weekday = date.isocalendar()\n\n    # look for today\n    if today == date and Names.Today & options:\n        return Names.Today\n\n    # look for yesterday\n    elif yesterday == date and Names.Yesterday & options:\n        return Names.Yesterday\n\n    # look for tomorrow\n    elif tomorrow == date and Names.Tomorrow & options:\n        return Names.Tomorrow\n\n    # look for same year options\n    elif today_year == date_year:\n        # look for same month options\n        if today_month == date_month:\n            # look for this week\n            if today_week == date_week and Names.ThisWeek & options:\n                return Names.ThisWeek\n\n            # look for last week \n            elif today_week == date_week + 1 and Names.LastWeek & options:\n                return Names.LastWeek\n\n            # look for next week\n            elif today_week == date_week - 1 and Names.NextWeek & options:\n                return Names.NextWeek\n\n            # look for this month\n            elif Names.ThisMonth & options:\n                return Names.ThisMonth\n\n        # look for last month options\n        elif today_month == date_month + 1 and Names.LastMonth & options:\n            return Names.LastMonth\n\n        # look for next month options\n        elif today_month == date_month - 1 and Names.NextMonth & options:\n            return Names.NextMonth\n\n        # look for this year options\n        elif Names.ThisYear & options:\n            return Names.ThisYear\n\n    # look for last year options\n    elif today_year == date_year + 1 and Names.LastYear & options:\n        return Names.LastYear\n\n    # look for next year options\n    elif today_year == date_year - 1 and Names.NextYear & options:\n        return Names.NextYear\n\n    # look for past dates\n    elif date < today and Names.Past & options:\n        return Names.Past\n\n    # look for future dates\n    elif today < date and Names.Future & options:\n        return Names.Future\n\n    return Names.Sometime", "response": "Returns the best named option for the inputted date based on the inputted date name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repeating(first,\n              mode=RepeatMode.Weekly,\n              step=1,\n              flags=0,\n              startAt=None,\n              repeatUntil=None,\n              maximum=None):\n    \"\"\"\n    Returns a list of repeating dates from the inputted start date based on the\n    given mode.  If an repeatUntil date is supplied, then the results will be\n    capped once the last date is reached, otherwise, the maximum number of\n    results will be returned.\n    \n    :param      first       | <datetime.date>\n                mode        | <RepeatMode>\n                step        | <int> | value must be greater than 1\n                flags       | <RepeatFlags>\n                startAt     | <datetime.date> || None\n                repeatUntil | <datetime.date> || None\n                maximum     | <int> || None\n    \n    :return     [<datetime.date>, ..]\n    \"\"\"\n    if repeatUntil is None and maximum is None:\n        maximum = 100\n\n    # calculate the dates\n    step = max(1, step)\n    output = []\n\n    # create the start at information\n    if startAt is not None and first < startAt:\n        if mode == RepeatMode.Monthly:\n            curr = datetime.date(startAt.year, startAt.month, first.day)\n        elif mode == RepeatMode.Yearly:\n            curr = datetime.date(startAt.year, first.month, first.day)\n        else:\n            curr = first\n    else:\n        curr = first\n\n    if curr < first:\n        curr = first\n\n    # determine if any days are flagged\n    any_days = 0\n    for value in DaysOfWeek.values():\n        any_days |= value\n\n    # repeat on a daily basis\n    while True:\n        # increment daily\n        if mode == RepeatMode.Weekly:\n            # repeat for specific days\n            if flags & any_days:\n                start = curr + datetime.timedelta(days=1 - curr.isoweekday())\n                exit_loop = False\n\n                for i in range(7):\n                    day = start + datetime.timedelta(days=i)\n\n                    if day < first:\n                        continue\n\n                    elif repeatUntil is not None and repeatUntil < day:\n                        exit_loop = True\n                        break\n\n                    flag = DaysOfWeek[day.isoweekday()]\n\n                    # skip this day of the week when repeating\n                    if not (flags & flag):\n                        continue\n\n                    if startAt is None or startAt <= day:\n                        output.append(day)\n\n                if exit_loop:\n                    break\n\n            else:\n                if repeatUntil is not None and repeatUntil < curr:\n                    break\n\n                if startAt is None or startAt <= curr:\n                    output.append(curr)\n\n            curr = curr + datetime.timedelta(days=7 * step)\n\n        # break when the end first is hit\n        if repeatUntil is not None and repeatUntil < curr:\n            break\n\n        # break when the maximum is hit\n        elif maximum is not None and len(output) == maximum:\n            break\n\n        # increment weekly\n        elif mode == RepeatMode.Weekly:\n            if startAt is None or startAt <= curr:\n                output.append(curr)\n\n            curr = curr + datetime.timedelta(days=step * 7)\n\n        # increment monthly\n        elif mode == RepeatMode.Monthly:\n            if startAt is None or startAt <= curr:\n                output.append(curr)\n\n            # approximate the delta\n            curr = addMonths(curr, step)\n\n            # check to see if we're repeating on the day of the week in\n            # the month, or the actual day of the month\n            if (flags & RepeatFlags.DayOfTheWeek) != 0:\n                shift = curr.isodayofweek() - first.isoweekday()\n                curr = curr + datetime.timedelta(days=shift)\n\n        # increment yearly\n        elif mode == RepeatMode.Yearly:\n            if startAt is None or startAt <= curr:\n                output.append(curr)\n\n            curr = addYears(curr, step)\n\n    return output", "response": "Returns a list of repeating dates from the inputted start date based on the given repeat mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weekdays(start, end):\n    # don't bother calculating anything for the same inputted date\n    if start == end:\n        return int(start.isoweekday() not in (6, 7))\n    elif end < start:\n        return -weekdays(end, start)\n    else:\n        strt_weekday = start.isoweekday()\n        end_weekday = end.isoweekday()\n\n        # calculate in the positive direction\n        if end < start:\n            return -weekdays(end, start)\n\n        # calculate from the monday after the start\n        if 5 < strt_weekday:\n            start = start + datetime.timedelta(days=8 - strt_weekday)\n\n        # calculate from the friday before the end\n        if 5 < end_weekday:\n            end = end - datetime.timedelta(days=end_weekday - 5)\n\n        remainder = end.isoweekday() - start.isoweekday()\n        end = end - datetime.timedelta(days=remainder)\n\n        # if the end is now before the start, then both dates fell on a weekend\n        if end < start:\n            return 0\n\n        # otherwise, if the dates normalized to each other, then return the\n        # remainder\n        elif end == start:\n            return remainder + 1\n\n        # remove the number of weekends from the start and end dates\n        days = ((end - start).days + 1)\n        total_days = abs(days)\n        multiplier = days / total_days\n        weekends = int(round(total_days / 7.0) * 2)\n        week_days = ((total_days - weekends) + remainder) * multiplier\n\n        return week_days", "response": "Returns the number of weekdays between the inputted start and end dates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(args=None):\n    if args is None:\n        args = tag.cli.parser().parse_args()\n\n    assert args.cmd in mains\n    mainmethod = mains[args.cmd]\n    mainmethod(args)", "response": "Entry point for the tag CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _build_request(request):\n    msg = bytes([request['cmd']])\n    if 'dest' in request:\n        msg += bytes([request['dest']])\n    else:\n        msg += b'\\0'\n    if 'sha' in request:\n        msg += request['sha']\n    else:\n        for dummy in range(64):\n            msg += b'0'\n    logging.debug(\"Request (%d): %s\", len(msg), msg)\n    return msg", "response": "Build a message to transfer over the socket from a request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing example using the API.", "response": "def main():\n    \"\"\"Show example using the API.\"\"\"\n    __async__ = True\n    logging.basicConfig(format=\"%(levelname)-10s %(message)s\",\n                        level=logging.DEBUG)\n\n    if len(sys.argv) != 2:\n        logging.error(\"Must specify configuration file\")\n        sys.exit()\n    config = configparser.ConfigParser()\n    config.read(sys.argv[1])\n\n    password = config.get('default', 'password')\n    if __async__:\n        client = Client(config.get('default', 'host'),\n                        config.getint('default', 'port'), password, _callback)\n    else:\n        client = Client(config.get('default', 'host'),\n                        config.getint('default', 'port'),\n                        password)\n        status = client.messages()\n        msg = status[0]\n        print(msg)\n        print(client.mp3(msg['sha'].encode('utf-8')))\n    while True:\n        continue"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to server and send a request to get the password.", "response": "def _connect(self):\n        \"\"\"Connect to server.\"\"\"\n        self._soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._soc.connect((self._ipaddr, self._port))\n        self._soc.send(_build_request({'cmd': cmd.CMD_MESSAGE_PASSWORD,\n                                       'sha': self._password}))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a message from the server.", "response": "def _recv_msg(self):\n        \"\"\"Read a message from the server.\"\"\"\n        command = ord(recv_blocking(self._soc, 1))\n        msglen = recv_blocking(self._soc, 4)\n        msglen = ((msglen[0] << 24) + (msglen[1] << 16) +\n                  (msglen[2] << 8) + msglen[3])\n        msg = recv_blocking(self._soc, msglen)\n        return command, msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _loop(self):\n        request = {}\n        connected = False\n        while True:\n            timeout = None\n            sockets = [self.request_queue, self.signal]\n            if not connected:\n                try:\n                    self._clear_request(request)\n                    self._connect()\n                    self._soc.send(_build_request(\n                        {'cmd': cmd.CMD_MESSAGE_LIST}))\n                    self._soc.send(_build_request(\n                        {'cmd': cmd.CMD_MESSAGE_CDR_AVAILABLE}))\n                    connected = True\n                except ConnectionRefusedError:\n                    timeout = 5.0\n            if connected:\n                sockets.append(self._soc)\n\n            readable, _writable, _errored = select.select(\n                sockets, [], [], timeout)\n\n            if self.signal in readable:\n                break\n\n            if self._soc in readable:\n                # We have incoming data\n                try:\n                    command, msg = self._recv_msg()\n                    self._handle_msg(command, msg, request)\n                except (RuntimeError, ConnectionResetError):\n                    logging.warning(\"Lost connection\")\n                    connected = False\n                    self._clear_request(request)\n\n            if self.request_queue in readable:\n                request = self.request_queue.get()\n                self.request_queue.task_done()\n                if not connected:\n                    self._clear_request(request)\n                else:\n                    if (request['cmd'] == cmd.CMD_MESSAGE_LIST and\n                            self._status and\n                            (not self._callback or 'sync' in request)):\n                        self.result_queue.put(\n                            [cmd.CMD_MESSAGE_LIST, self._status])\n                        request = {}\n                    else:\n                        self._soc.send(_build_request(request))", "response": "Loop over the message queue and process the response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mp3(self, sha, **kwargs):\n        return self._queue_msg({'cmd': cmd.CMD_MESSAGE_MP3,\n                                'sha': _get_bytes(sha)}, **kwargs)", "response": "Get raw MP3 of a message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, sha, **kwargs):\n        return self._queue_msg({'cmd': cmd.CMD_MESSAGE_DELETE,\n                                'sha': _get_bytes(sha)}, **kwargs)", "response": "Delete a message from the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cdr(self, start=0, count=-1, **kwargs):\n        sha = encode_to_sha(\"{:d},{:d}\".format(start, count))\n        return self._queue_msg({'cmd': cmd.CMD_MESSAGE_CDR,\n                                'sha': sha}, **kwargs)", "response": "Request range of CDR messages"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef path(self) -> Path:\n        args = list(self._iter_translated_field_names(self.get_path_pattern_list()))\n        args.append(self.get_name())\n        return Path(*args)", "response": "A Path for this name object joining field names from self. get_path_pattern_list with this object s name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fold(self, predicate):\n        childs = {x:y.fold(predicate) for (x,y) in self._attributes.items()\n                  if isinstance(y, SerializableTypedAttributesHolder)}\n        return predicate(self, childs)", "response": "Takes a predicate and applies it to each node starting from the\n        leaves and making the return value propagate."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef the_one(cls):\n        if cls.THE_ONE is None:\n            cls.THE_ONE = cls(settings.HELP_TOKENS_INI_FILE)\n        return cls.THE_ONE", "response": "Get the single global HelpUrlExpert object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config_value(self, section_name, option, default_option=\"default\"):\n        if self.config is None:\n            self.config = configparser.ConfigParser()\n            self.config.read(self.ini_file_name)\n\n        if option:\n            try:\n                return self.config.get(section_name, option)\n            except configparser.NoOptionError:\n                log.debug(\n                    \"Didn't find a configuration option for '%s' section and '%s' option\",\n                    section_name, option,\n                )\n\n        return self.config.get(section_name, default_option)", "response": "Read a value from the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the full URL for a help token.", "response": "def url_for_token(self, token):\n        \"\"\"Find the full URL for a help token.\"\"\"\n        book_url = self.get_config_value(\"pages\", token)\n        book, _, url_tail = book_url.partition(':')\n        book_base = settings.HELP_TOKENS_BOOKS[book]\n\n        url = book_base\n\n        lang = getattr(settings, \"HELP_TOKENS_LANGUAGE_CODE\", None)\n        if lang is not None:\n            lang = self.get_config_value(\"locales\", lang)\n            url += \"/\" + lang\n\n        version = getattr(settings, \"HELP_TOKENS_VERSION\", None)\n        if version is not None:\n            url += \"/\" + version\n\n        url += \"/\" + url_tail\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the data from a file and returns the object that represents the data.", "response": "def load_data(Filepath, ObjectType='data', RelativeChannelNo=None, SampleFreq=None, PointsToLoad=-1, calcPSD=True, NPerSegmentPSD=1000000, NormaliseByMonitorOutput=False, silent=False):\n    \"\"\"\n    Parameters\n    ----------\n    Filepath : string\n        filepath to the file containing the data used to initialise\n        and create an instance of the DataObject class\n    ObjectType : string, optional\n        type to load the data as, takes the value 'default' if not specified.\n        Options are:\n        'data' : optoanalysis.DataObject\n        'thermo' : optoanalysis.thermo.ThermoObject\n    RelativeChannelNo : int, optional\n        If loading a .bin file produced by the Saneae datalogger, used to specify\n        the channel number\n        If loading a .dat file produced by the labview NI5122 daq card, used to \n        specifiy the channel number if two channels where saved, if left None with \n        .dat files it will assume that the file to load only contains one channel.\n        If NormaliseByMonitorOutput is True then specifies the monitor channel for\n        loading a .dat file produced by the labview NI5122 daq card.\n    SampleFreq : float, optional\n        If loading a .dat file produced by the labview NI5122 daq card, used to\n        manually specify the sample frequency\n    PointsToLoad : int, optional\n        Number of first points to read. -1 means all points (i.e., the complete file)\n        WORKS WITH NI5122 DATA SO FAR ONLY!!!\n    calcPSD : bool, optional\n        Whether to calculate the PSD upon loading the file, can take some time\n        off the loading and reduce memory usage if frequency space info is not required\n    NPerSegmentPSD : int, optional\n        NPerSegment to pass to scipy.signal.welch to calculate the PSD\n    NormaliseByMonitorOutput : bool, optional\n        If True the particle signal trace will be divided by the monitor output, which is\n        specified by the channel number set in the RelativeChannelNo parameter. \n        WORKS WITH NI5122 DATA SO FAR ONLY!!!\n\n    Returns\n    -------\n    Data : DataObject\n        An instance of the DataObject class contaning the data\n        that you requested to be loaded.\n\n    \"\"\"\n    if silent != True:\n        print(\"Loading data from {}\".format(Filepath))\n    ObjectTypeDict = {\n        'data' : DataObject,\n        'thermo' : optoanalysis.thermo.ThermoObject,\n        }\n    try:\n        Object = ObjectTypeDict[ObjectType]\n    except KeyError:\n        raise ValueError(\"You entered {}, this is not a valid object type\".format(ObjectType))\n    data = Object(Filepath, RelativeChannelNo, SampleFreq, PointsToLoad, calcPSD, NPerSegmentPSD, NormaliseByMonitorOutput)\n    try:\n        channel_number, run_number, repeat_number = [int(val) for val in re.findall('\\d+', data.filename)]\n        data.channel_number = channel_number\n        data.run_number = run_number\n        data.repeat_number = repeat_number\n        if _does_file_exist(data.filepath.replace(data.filename, '') + \"pressure.log\"):\n            print(\"pressure.log file exists\")\n            for line in open(data.filepath.replace(data.filename, '') + \"pressure.log\", 'r'):\n                run_number, repeat_number, pressure = line.split(',')[1:]\n                run_number = int(run_number)\n                repeat_number = int(repeat_number)\n                pressure = float(pressure)\n                if (run_number == data.run_number) and (repeat_number == data.repeat_number):\n                    data.pmbar = pressure    \n    except ValueError:\n        pass\n    try:\n        if _does_file_exist(glob(data.filepath.replace(data.filename, '*' + data.filename[20:-4] + ' - header.dat'))[0]):\n            print(\"header file exists\")\n            with open(glob(data.filepath.replace(data.filename, '*' + data.filepath[20:-4] + ' - header.dat'))[0], encoding='ISO-8859-1') as f:\n                lines = f.readlines()\n            data.pmbar = (float(lines[68][-9:-1])+float(lines[69][-9:-1]))/2\n    except (ValueError, IndexError):\n        pass\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_data_std(Channel, RunNos, RepeatNos, directoryPath='.'):\n    files = glob('{}/*'.format(directoryPath))\n    files_CorrectChannel = []\n    for file_ in files:\n        if 'CH{}'.format(Channel) in file_:\n            files_CorrectChannel.append(file_)\n    files_CorrectRunNo = []\n    for RunNo in RunNos:\n        files_match = _fnmatch.filter(\n            files_CorrectChannel, '*RUN*0{}_*'.format(RunNo))\n        for file_ in files_match:\n            files_CorrectRunNo.append(file_)\n    files_CorrectRepeatNo = []\n    for RepeatNo in RepeatNos:\n        files_match = _fnmatch.filter(\n            files_CorrectRunNo, '*REPEAT*0{}.*'.format(RepeatNo))\n        for file_ in files_match:\n            files_CorrectRepeatNo.append(file_)\n    return files_CorrectRepeatNo", "response": "Search for multiple datasets at once assuming they have a single file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload multiple datasets at once assuming they have a single file.", "response": "def multi_load_data(Channel, RunNos, RepeatNos, directoryPath='.', calcPSD=True, NPerSegmentPSD=1000000):\n    \"\"\"\n    Lets you load multiple datasets at once assuming they have a \n    filename which contains a pattern of the form:\n    CH<ChannelNo>_RUN00...<RunNo>_REPEAT00...<RepeatNo>    \n\n    Parameters\n    ----------\n    Channel : int\n        The channel you want to load\n    RunNos : sequence\n        Sequence of run numbers you want to load\n    RepeatNos : sequence\n        Sequence of repeat numbers you want to load\n    directoryPath : string, optional\n        The path to the directory housing the data\n        The default is the current directory\n\n    Returns\n    -------\n    Data : list\n        A list containing the DataObjects that were loaded. \n    \"\"\"\n    matching_files = search_data_std(Channel=Channel, RunNos=RunNos, RepeatNos=RepeatNos, directoryPath=directoryPath)\n    #data = []\n    #for filepath in matching_files_:\n    #    data.append(load_data(filepath, calcPSD=calcPSD, NPerSegmentPSD=NPerSegmentPSD))\n\n    cpu_count = _cpu_count()\n    workerPool = _Pool(cpu_count)\n    load_data_partial = _partial(load_data, calcPSD=calcPSD, NPerSegmentPSD=NPerSegmentPSD)\n    data = workerPool.map(load_data_partial, matching_files)\n    workerPool.close()\n    workerPool.terminate()\n    workerPool.join()\n       \n    #with _Pool(cpu_count) as workerPool:\n        #load_data_partial = _partial(load_data, calcPSD=calcPSD, NPerSegmentPSD=NPerSegmentPSD)\n        #data = workerPool.map(load_data_partial, files_CorrectRepeatNo)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads multiple data objects named with the LeCroy s custom naming scheme at once.", "response": "def multi_load_data_custom(Channel, TraceTitle, RunNos, directoryPath='.', calcPSD=True, NPerSegmentPSD=1000000):\n    \"\"\"\n    Lets you load multiple datasets named with the LeCroy's custom naming scheme at once.\n\n    Parameters\n    ----------\n    Channel : int\n        The channel you want to load\n    TraceTitle : string\n        The custom trace title of the files. \n    RunNos : sequence\n        Sequence of run numbers you want to load\n    RepeatNos : sequence\n        Sequence of repeat numbers you want to load\n    directoryPath : string, optional\n        The path to the directory housing the data\n        The default is the current directory\n\n    Returns\n    -------\n    Data : list\n        A list containing the DataObjects that were loaded. \n    \"\"\"\n#    files = glob('{}/*'.format(directoryPath))\n#    files_CorrectChannel = []\n#    for file_ in files:\n#        if 'C{}'.format(Channel) in file_:\n#           files_CorrectChannel.append(file_)\n#    files_CorrectRunNo = []\n#    for RunNo in RunNos:\n#        files_match = _fnmatch.filter(\n#            files_CorrectChannel, '*C{}'.format(Channel)+TraceTitle+str(RunNo).zfill(5)+'.*')\n#        for file_ in files_match:\n#            files_CorrectRunNo.append(file_)\n    matching_files = search_data_custom(Channel, TraceTitle, RunNos, directoryPath)\n    cpu_count = _cpu_count()\n    workerPool = _Pool(cpu_count)\n    # for filepath in files_CorrectRepeatNo:\n    #    print(filepath)\n    #    data.append(load_data(filepath))\n    load_data_partial = _partial(load_data, calcPSD=calcPSD, NPerSegmentPSD=NPerSegmentPSD)\n    data = workerPool.map(load_data_partial, matching_files)\n    workerPool.close()\n    workerPool.terminate()\n    workerPool.join()\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch the data for custom names in the base directory.", "response": "def search_data_custom(Channel, TraceTitle, RunNos, directoryPath='.'):\n    \"\"\"\n    Lets you create a list with full file paths of the files\n    named with the LeCroy's custom naming scheme.\n\n    Parameters\n    ----------\n    Channel : int\n        The channel you want to load\n    TraceTitle : string\n        The custom trace title of the files. \n    RunNos : sequence\n        Sequence of run numbers you want to load\n    RepeatNos : sequence\n        Sequence of repeat numbers you want to load\n    directoryPath : string, optional\n        The path to the directory housing the data\n        The default is the current directory\n\n    Returns\n    -------\n    Paths : list\n        A list containing the full file paths of the files you were looking for. \n    \"\"\"\n    files = glob('{}/*'.format(directoryPath))\n    files_CorrectChannel = []    \n    for file_ in files:\n        if 'C{}'.format(Channel) in file_:\n            files_CorrectChannel.append(file_)\n    files_CorrectRunNo = []\n    for RunNo in RunNos:\n        files_match = _fnmatch.filter(\n            files_CorrectChannel, '*C{}'.format(Channel)+TraceTitle+str(RunNo).zfill(5)+'.*')\n        for file_ in files_match:\n            files_CorrectRunNo.append(file_)\n    print(\"loading the following files: {}\".format(files_CorrectRunNo))\n    paths = files_CorrectRunNo\n    return paths"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_temp(Data_ref, Data):\n    T = 300 * ((Data.A * Data_ref.Gamma) / (Data_ref.A * Data.Gamma))\n    Data.T = T\n    return T", "response": "Calculates the temperature of a data set relative to a reference."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calc_gamma_components(Data_ref, Data):\n    A_prime = Data_ref.A/Data_ref.Gamma\n    Gamma0 = Data.A/A_prime\n    delta_Gamma = Data.Gamma - Gamma0\n    return Gamma0, delta_Gamma", "response": "Calculates the components of the Gamma and delta_Gamma for a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_curvefit(p0, datax, datay, function, **kwargs):\n    pfit, pcov = \\\n        _curve_fit(function, datax, datay, p0=p0,\n                   epsfcn=0.0001, **kwargs)\n    error = []\n    for i in range(len(pfit)):\n        try:\n            error.append(_np.absolute(pcov[i][i])**0.5)\n        except:\n            error.append(_np.NaN)\n    pfit_curvefit = pfit\n    perr_curvefit = _np.array(error)\n    return pfit_curvefit, perr_curvefit", "response": "Fits the data to a function using scipy. optimise. curve_fit\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the moving average of an array.", "response": "def moving_average(array, n=3):\n    \"\"\"\n    Calculates the moving average of an array.\n\n    Parameters\n    ----------\n    array : array\n        The array to have the moving average taken of\n    n : int\n        The number of points of moving average to take\n    \n    Returns\n    -------\n    MovingAverageArray : array\n        The n-point moving average of the input array\n    \"\"\"\n    ret = _np.cumsum(array, dtype=float)\n    ret[n:] = ret[n:] - ret[:-n]\n    return ret[n - 1:] / n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking the closest value to myNumber in myList. Returns the smallest value.", "response": "def take_closest(myList, myNumber):\n    \"\"\"\n    Assumes myList is sorted. Returns closest value to myNumber.\n    If two numbers are equally close, return the smallest number.\n\n    Parameters\n    ----------\n    myList : array\n        The list in which to find the closest value to myNumber\n    myNumber : float\n        The number to find the closest to in MyList\n\n    Returns\n    -------\n    closestValue : float\n        The number closest to myNumber in myList\n    \"\"\"\n    pos = _bisect_left(myList, myNumber)\n    if pos == 0:\n        return myList[0]\n    if pos == len(myList):\n        return myList[-1]\n    before = myList[pos - 1]\n    after = myList[pos]\n    if after - myNumber < myNumber - before:\n        return after\n    else:\n        return before"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _position_autocorrelation_fitting_eqn(t, Gamma, AngTrapFreq):\n    return _np.exp(-t*Gamma/2)* ( _np.cos(t* _np.sqrt(AngTrapFreq**2-Gamma**2/4)) + Gamma* _np.sin(t* _np.sqrt(AngTrapFreq**2-Gamma**2/4))/(2* _np.sqrt(AngTrapFreq**2-Gamma**2/4)) )", "response": "Returns the value of the autocorrelation - exponential decay of the given time - vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the autocorrelation to data.", "response": "def fit_autocorrelation(autocorrelation, time, GammaGuess, TrapFreqGuess=None, method='energy', MakeFig=True, show_fig=True):\n    \"\"\"\n    Fits exponential relaxation theory to data.\n\n    Parameters\n    ----------\n    autocorrelation : array\n        array containing autocorrelation to be fitted\n    time : array\n        array containing the time of each point the autocorrelation\n        was evaluated\n    GammaGuess : float\n        The approximate Big Gamma (in radians) to use initially\n    TrapFreqGuess : float\n        The approximate trapping frequency to use initially in Hz.\n    method : string, optional\n        To choose which autocorrelation fit is needed.\n        'position' : equation 4.20 from Tongcang Li's 2013 thesis \n                     (DOI: 10.1007/978-1-4614-6031-2)\n        'energy'   : proper exponential energy correlation decay\n                     (DOI: 10.1103/PhysRevE.94.062151)\n    MakeFig : bool, optional\n        Whether to construct and return the figure object showing\n        the fitting. defaults to True\n    show_fig : bool, optional\n        Whether to show the figure object when it has been created.\n        defaults to True\n\n    Returns\n    -------\n    ParamsFit - Fitted parameters:\n        'variance'-method : [Gamma]\n        'position'-method : [Gamma, AngularTrappingFrequency]\n    ParamsFitErr - Error in fitted parameters:\n        'varaince'-method : [GammaErr]\n        'position'-method : [GammaErr, AngularTrappingFrequencyErr]\n    fig : matplotlib.figure.Figure object\n        figure object containing the plot\n    ax : matplotlib.axes.Axes object\n        axes with the data plotted of the:\n            - initial data\n            - final fit\n    \"\"\"\n    datax = time\n    datay = autocorrelation\n\n    method = method.lower()\n    if method == 'energy':\n        p0 = _np.array([GammaGuess])\n\n        Params_Fit, Params_Fit_Err = fit_curvefit(p0,\n                                                  datax,\n                                                  datay,\n                                                  _energy_autocorrelation_fitting_eqn)\n        autocorrelation_fit = _energy_autocorrelation_fitting_eqn(_np.arange(0,datax[-1],1e-7),\n                                                                  Params_Fit[0])\n    elif method == 'position':\n        AngTrapFreqGuess = 2 * _np.pi * TrapFreqGuess\n        p0 = _np.array([GammaGuess, AngTrapFreqGuess])\n        Params_Fit, Params_Fit_Err = fit_curvefit(p0,\n                                                  datax,\n                                                  datay,\n                                                  _position_autocorrelation_fitting_eqn)\n        autocorrelation_fit = _position_autocorrelation_fitting_eqn(_np.arange(0,datax[-1],1e-7),\n                                                                    Params_Fit[0],\n                                                                    Params_Fit[1])\n        \n    if MakeFig == True:\n        fig = _plt.figure(figsize=properties[\"default_fig_size\"])\n        ax = fig.add_subplot(111)\n        ax.plot(datax*1e6, datay,\n                '.', color=\"darkblue\", label=\"Autocorrelation Data\", alpha=0.5)\n        ax.plot(_np.arange(0,datax[-1],1e-7)*1e6, autocorrelation_fit,\n                color=\"red\", label=\"fit\")\n        ax.set_xlim([0,\n                     30e6/Params_Fit[0]/(2*_np.pi)])\n        legend = ax.legend(loc=\"best\", frameon = 1)\n        frame = legend.get_frame()\n        frame.set_facecolor('white')\n        frame.set_edgecolor('white')\n        ax.set_xlabel(\"time (us)\")\n        ax.set_ylabel(r\"$\\left | \\frac{\\langle x(t)x(t+\\tau) \\rangle}{\\langle x(t)x(t) \\rangle} \\right |$\")\n        if show_fig == True:\n            _plt.show()\n        return Params_Fit, Params_Fit_Err, fig, ax\n    else:\n        return Params_Fit, Params_Fit_Err, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the PSD of the given A and OmegaTrap and Gamma values.", "response": "def PSD_fitting_eqn(A, OmegaTrap, Gamma, omega):\n    \"\"\"\n    The value of the fitting equation:\n    A / ((OmegaTrap**2 - omega**2)**2 + (omega * Gamma)**2)\n    to be fit to the PSD\n\n    Parameters\n    ----------\n    A : float\n        Fitting constant A\n        A = \u03b3**2*\u0393_0*(2*K_b*T_0)/(\u03c0*m)\n        where:\n            \u03b3 = conversionFactor\n            \u0393_0 = Damping factor due to environment\n            \u03c0 = pi\n    OmegaTrap : float\n        The trapping frequency in the axis of interest \n        (in angular frequency)\n    Gamma : float\n        The damping factor Gamma = \u0393 = \u0393_0 + \u03b4\u0393\n        where:\n            \u0393_0 = Damping factor due to environment\n            \u03b4\u0393 = extra damping due to feedback or other effects\n    omega : float\n        The angular frequency to calculate the value of the \n        fitting equation at \n\n    Returns\n    -------\n    Value : float\n        The value of the fitting equation\n    \"\"\"\n    return A / ((OmegaTrap**2 - omega**2)**2 + omega**2 * (Gamma)**2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the value of the fitting equation A with the background.", "response": "def PSD_fitting_eqn_with_background(A, OmegaTrap, Gamma, FlatBackground, omega):\n    \"\"\"\n    The value of the fitting equation:\n    A / ((OmegaTrap**2 - omega**2)**2 + (omega * Gamma)**2) + FlatBackground\n    to be fit to the PSD\n\n    Parameters\n    ----------\n    A : float\n        Fitting constant A\n        A = \u03b3**2*\u0393_0*(2*K_b*T_0)/(\u03c0*m)\n        where:\n            \u03b3 = conversionFactor\n            \u0393_0 = Damping factor due to environment\n            \u03c0 = pi\n    OmegaTrap : float\n        The trapping frequency in the axis of interest \n        (in angular frequency)\n    Gamma : float\n        The damping factor Gamma = \u0393 = \u0393_0 + \u03b4\u0393\n        where:\n            \u0393_0 = Damping factor due to environment\n            \u03b4\u0393 = extra damping due to feedback or other effects\n    FlatBackground : float\n        Adds a constant offset to the peak to account for a flat \n        noise background\n    omega : float\n        The angular frequency to calculate the value of the \n        fitting equation at \n\n    Returns\n    -------\n    Value : float\n        The value of the fitting equation\n    \"\"\"\n    return A / ((OmegaTrap**2 - omega**2)**2 + omega**2 * (Gamma)**2) + FlatBackground"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_PSD(Data, bandwidth, TrapFreqGuess, AGuess=0.1e10, GammaGuess=400, FlatBackground=None, MakeFig=True, show_fig=True):\n    AngFreqs = 2 * pi * Data.freqs\n    Angbandwidth = 2 * pi * bandwidth\n    AngTrapFreqGuess = 2 * pi * TrapFreqGuess\n\n    ClosestToAngTrapFreqGuess = take_closest(AngFreqs, AngTrapFreqGuess)\n    index_OmegaTrap = _np.where(AngFreqs == ClosestToAngTrapFreqGuess)[0][0]\n    OmegaTrap = AngFreqs[index_OmegaTrap]\n\n    f_fit_lower = take_closest(AngFreqs, OmegaTrap - Angbandwidth / 2)\n    f_fit_upper = take_closest(AngFreqs, OmegaTrap + Angbandwidth / 2)\n\n    indx_fit_lower = int(_np.where(AngFreqs == f_fit_lower)[0][0])\n    indx_fit_upper = int(_np.where(AngFreqs == f_fit_upper)[0][0])\n\n    if indx_fit_lower == indx_fit_upper:\n        raise ValueError(\"Bandwidth argument must be higher, region is too thin.\")\n    \n#    print(f_fit_lower, f_fit_upper)\n#    print(AngFreqs[indx_fit_lower], AngFreqs[indx_fit_upper])\n\n    # find highest point in region about guess for trap frequency - use that\n    # as guess for trap frequency and recalculate region about the trap\n    # frequency\n    index_OmegaTrap = _np.where(Data.PSD == max(\n        Data.PSD[indx_fit_lower:indx_fit_upper]))[0][0]\n\n    OmegaTrap = AngFreqs[index_OmegaTrap]\n\n#    print(OmegaTrap)\n\n    f_fit_lower = take_closest(AngFreqs, OmegaTrap - Angbandwidth / 2)\n    f_fit_upper = take_closest(AngFreqs, OmegaTrap + Angbandwidth / 2)\n\n    indx_fit_lower = int(_np.where(AngFreqs == f_fit_lower)[0][0])\n    indx_fit_upper = int(_np.where(AngFreqs == f_fit_upper)[0][0])\n\n    logPSD = 10 * _np.log10(Data.PSD) # putting PSD in dB\n\n    def calc_theory_PSD_curve_fit(freqs, A, TrapFreq, BigGamma, FlatBackground=None):\n        if FlatBackground == None:\n            Theory_PSD = 10 * \\\n                _np.log10(PSD_fitting_eqn(A, TrapFreq, BigGamma, freqs)) # PSD in dB\n        else:\n            Theory_PSD = 10* \\\n                _np.log10(PSD_fitting_eqn_with_background(A, TrapFreq, BigGamma, FlatBackground, freqs)) # PSD in dB\n        if A < 0 or TrapFreq < 0 or BigGamma < 0:\n            return 1e9\n        else:\n            return Theory_PSD\n\n    datax = AngFreqs[indx_fit_lower:indx_fit_upper]\n    datay = logPSD[indx_fit_lower:indx_fit_upper]\n\n    if FlatBackground == None:\n        p0 = _np.array([AGuess, OmegaTrap, GammaGuess])\n\n        Params_Fit, Params_Fit_Err = fit_curvefit(p0,\n                                                  datax,\n                                                  datay,\n                                                  calc_theory_PSD_curve_fit)\n    else:\n        p0 = _np.array([AGuess, OmegaTrap, GammaGuess, FlatBackground])\n\n        Params_Fit, Params_Fit_Err = fit_curvefit(p0,\n                                                  datax,\n                                                  datay,\n                                                  calc_theory_PSD_curve_fit)\n\n    if MakeFig == True:\n        fig = _plt.figure(figsize=properties[\"default_fig_size\"])\n        ax = fig.add_subplot(111)\n\n        if FlatBackground==None:\n            PSDTheory_fit_initial = 10 * _np.log10(\n                PSD_fitting_eqn(p0[0], p0[1],\n                                p0[2], AngFreqs))\n\n            PSDTheory_fit = 10 * _np.log10(\n                PSD_fitting_eqn(Params_Fit[0],\n                                Params_Fit[1],\n                                Params_Fit[2],\n                                AngFreqs))\n        else:\n            PSDTheory_fit_initial = 10 * _np.log10(\n                PSD_fitting_eqn_with_background(p0[0], p0[1],\n                                                p0[2], p0[3], AngFreqs))\n\n            PSDTheory_fit = 10 * _np.log10(\n                PSD_fitting_eqn_with_background(Params_Fit[0],\n                                                Params_Fit[1],\n                                                Params_Fit[2],\n                                                Params_Fit[3],\n                                                AngFreqs))\n\n        ax.plot(AngFreqs / (2 * pi), Data.PSD,\n                color=\"darkblue\", label=\"Raw PSD Data\", alpha=0.5)\n        ax.plot(AngFreqs / (2 * pi), 10**(PSDTheory_fit_initial / 10),\n                '--', alpha=0.7, color=\"purple\", label=\"initial vals\")\n        ax.plot(AngFreqs / (2 * pi), 10**(PSDTheory_fit / 10),\n                color=\"red\", label=\"fitted vals\")\n        ax.set_xlim([(OmegaTrap - 5 * Angbandwidth) / (2 * pi),\n                     (OmegaTrap + 5 * Angbandwidth) / (2 * pi)])\n        ax.plot([(OmegaTrap - Angbandwidth) / (2 * pi), (OmegaTrap - Angbandwidth) / (2 * pi)],\n                [min(10**(logPSD / 10)),\n                 max(10**(logPSD / 10))], '--',\n                color=\"grey\")\n        ax.plot([(OmegaTrap + Angbandwidth) / (2 * pi), (OmegaTrap + Angbandwidth) / (2 * pi)],\n                [min(10**(logPSD / 10)),\n                 max(10**(logPSD / 10))], '--',\n                color=\"grey\")\n        ax.semilogy()\n        legend = ax.legend(loc=\"best\", frameon = 1)\n        frame = legend.get_frame()\n        frame.set_facecolor('white')\n        frame.set_edgecolor('white')\n        ax.set_xlabel(\"Frequency (Hz)\")\n        ax.set_ylabel(\"$S_{xx}$ ($V^2/Hz$)\")\n        if show_fig == True:\n            _plt.show()\n        return Params_Fit, Params_Fit_Err, fig, ax\n    else:\n        return Params_Fit, Params_Fit_Err, None, None", "response": "Fits theory PSD to Data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the radius, mass and conversion factor and thier uncertainties. For values to be correct data must have been taken with feedback off and at pressures of around 1mbar (this is because the equations assume harmonic motion and at lower pressures the uncooled particle experiences anharmonic motion (due to exploring furthur outside the middle of the trap). When cooled the value of Gamma (the damping) is a combination of the enviromental damping and feedback damping and so is not the correct value for use in this equation (as it requires the enviromental damping). Environmental damping can be predicted though as A=const*Gamma0. By fitting to 1mbar data one can find the value of the const and therefore Gamma0 = A/const Parameters ---------- Pressure : float Pressure in mbar when the data was taken PressureErr : float Error in the Pressure as a decimal (e.g. 15% error is 0.15) A : float Fitting constant A A = \u03b3**2*2*\u0393_0*(K_b*T_0)/(\u03c0*m) where: \u03b3 = conversionFactor \u0393_0 = Damping factor due to environment \u03c0 = pi AErr : float Error in Fitting constant A Gamma0 : float The enviromental damping factor Gamma_0 = \u0393_0 Gamma0Err : float The error in the enviromental damping factor Gamma_0 = \u0393_0 Returns: Params : list [radius, mass, conversionFactor] The extracted parameters ParamsError : list [radiusError, massError, conversionFactorError] The error in the extracted parameters", "response": "def extract_parameters(Pressure, PressureErr, A, AErr, Gamma0, Gamma0Err, method=\"chang\"):\n    \"\"\"\n    Calculates the radius, mass and conversion factor and thier uncertainties.\n    For values to be correct data must have been taken with feedback off and\n    at pressures of around 1mbar (this is because the equations assume\n    harmonic motion and at lower pressures the uncooled particle experiences\n    anharmonic motion (due to exploring furthur outside the middle of the trap).\n    When cooled the value of Gamma (the damping) is a combination of the\n    enviromental damping and feedback damping and so is not the correct value\n    for use in this equation (as it requires the enviromental damping).\n    Environmental damping can be predicted though as A=const*Gamma0. By\n    fitting to 1mbar data one can find the value of the const and therefore\n    Gamma0 = A/const\n\n    Parameters\n    ----------\n    Pressure : float\n        Pressure in mbar when the data was taken\n    PressureErr : float\n        Error in the Pressure as a decimal (e.g. 15% error is 0.15) \n    A : float\n        Fitting constant A\n        A = \u03b3**2*2*\u0393_0*(K_b*T_0)/(\u03c0*m)\n        where:\n        \u03b3 = conversionFactor\n        \u0393_0 = Damping factor due to environment\n        \u03c0 = pi\n    AErr : float\n        Error in Fitting constant A\n    Gamma0 : float\n        The enviromental damping factor Gamma_0 = \u0393_0\n    Gamma0Err : float\n        The error in the enviromental damping factor Gamma_0 = \u0393_0\n\n    Returns:\n    Params : list\n        [radius, mass, conversionFactor]\n        The extracted parameters\n    ParamsError : list\n        [radiusError, massError, conversionFactorError]\n        The error in the extracted parameters\n    \"\"\"\n    Pressure = 100 * Pressure  # conversion to Pascals\n\n    rho = 1800 # as quoted by Microspheres and Nanospheres  # kgm^3\n    dm = 0.372e-9  # m O'Hanlon, 2003\n    T0 = 300  # kelvin\n    kB = Boltzmann  # m^2 kg s^-2 K-1\n    eta = 18.27e-6  # Pa s, viscosity of air\n\n    method = method.lower()\n    if method == \"rashid\":\n        radius = (0.619 * 9 * pi * eta * dm**2) / \\\n                 (_np.sqrt(2) * rho * kB * T0) * (Pressure/Gamma0)\n        \n    m_air = 4.81e-26 # molecular mass of air is 28.97 g/mol and Avogadro's Number 6.0221409^23\n    if method == \"chang\":\n        vbar = (8*kB*T0/(pi*m_air))**0.5\n        radius = 16/(rho*pi*vbar)*(Pressure/Gamma0)/4 # CORRECTION FACTOR OF 4 APPLIED!!!!\n    # see section 4.1.1 of Muddassar Rashid's 2016 Thesis for\n    # derivation of this\n    # see also page 132 of Jan Giesler's Thesis\n    err_radius = radius * \\\n        _np.sqrt(((PressureErr * Pressure) / Pressure)\n                 ** 2 + (Gamma0Err / Gamma0)**2)\n    mass = rho * ((4 * pi * radius**3) / 3)\n    err_mass = mass * 3 * err_radius / radius\n    conversionFactor = _np.sqrt(A * mass / (4 * kB * T0 * Gamma0))\n    err_conversionFactor = conversionFactor * \\\n        _np.sqrt((AErr / A)**2 + (err_mass / mass)\n                 ** 2 + (Gamma0Err / Gamma0)**2)\n    return [radius, mass, conversionFactor], [err_radius, err_mass, err_conversionFactor]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the exact z, x and y peak frequencies from approximate frequencies by finding the highest peak in the PSD \"close to\" the approximate peak frequency. By \"close to\" I mean within the range: approxFreq - bandwidth/2 to approxFreq + bandwidth/2 Parameters ---------- Data : DataObject DataObject containing the data for which you want to determine the z, x and y frequencies. zfreq : float An approximate frequency for the z peak xfreq : float An approximate frequency for the z peak yfreq : float An approximate frequency for the z peak bandwidth : float, optional The bandwidth around the approximate peak to look for the actual peak. The default value is 5000 Returns ------- trapfreqs : list List containing the trap frequencies in the following order (z, x, y)", "response": "def get_ZXY_freqs(Data, zfreq, xfreq, yfreq, bandwidth=5000):\n    \"\"\"\n    Determines the exact z, x and y peak frequencies from approximate\n    frequencies by finding the highest peak in the PSD \"close to\" the\n    approximate peak frequency. By \"close to\" I mean within the range:\n    approxFreq - bandwidth/2 to approxFreq + bandwidth/2\n\n    Parameters\n    ----------\n    Data : DataObject\n        DataObject containing the data for which you want to determine the\n        z, x and y frequencies.\n    zfreq : float\n        An approximate frequency for the z peak\n    xfreq : float\n        An approximate frequency for the z peak\n    yfreq : float\n        An approximate frequency for the z peak\n    bandwidth : float, optional\n        The bandwidth around the approximate peak to look for the actual peak. The default value is 5000\n\n    Returns\n    -------\n    trapfreqs : list\n        List containing the trap frequencies in the following order (z, x, y)\n    \"\"\"\n    trapfreqs = []\n    for freq in [zfreq, xfreq, yfreq]:\n        z_f_fit_lower = take_closest(Data.freqs, freq - bandwidth / 2)\n        z_f_fit_upper = take_closest(Data.freqs, freq + bandwidth / 2)\n        z_indx_fit_lower = int(_np.where(Data.freqs == z_f_fit_lower)[0][0])\n        z_indx_fit_upper = int(_np.where(Data.freqs == z_f_fit_upper)[0][0])\n\n        z_index_OmegaTrap = _np.where(Data.PSD == max(\n            Data.PSD[z_indx_fit_lower:z_indx_fit_upper]))[0][0]\n        # find highest point in region about guess for trap frequency\n        # use that as guess for trap frequency and recalculate region\n        # about the trap frequency\n        z_OmegaTrap = Data.freqs[z_index_OmegaTrap]\n        trapfreqs.append(z_OmegaTrap)\n    return trapfreqs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a Data object and the frequencies of the z, x and y peaks (and some optional parameters for the created filters) this function extracts the individual z, x and y signals (in volts) by creating IIR filters and filtering the Data. Parameters ---------- Data : DataObject DataObject containing the data for which you want to extract the z, x and y signals. zf : float The frequency of the z peak in the PSD xf : float The frequency of the x peak in the PSD yf : float The frequency of the y peak in the PSD FractionOfSampleFreq : integer, optional The fraction of the sample frequency to sub-sample the data by. This sometimes needs to be done because a filter with the appropriate frequency response may not be generated using the sample rate at which the data was taken. Increasing this number means the x, y and z signals produced by this function will be sampled at a lower rate but a higher number means a higher chance that the filter produced will have a nice frequency response. zwidth : float, optional The width of the pass-band of the IIR filter to be generated to filter Z. xwidth : float, optional The width of the pass-band of the IIR filter to be generated to filter X. ywidth : float, optional The width of the pass-band of the IIR filter to be generated to filter Y. filterImplementation : string, optional filtfilt or lfilter - use scipy.filtfilt or lfilter default: filtfilt timeStart : float, optional Starting time for filtering timeEnd : float, optional Ending time for filtering show_fig : bool, optional If True - plot unfiltered and filtered PSD for z, x and y. If False - don't plot anything Returns ------- zdata : ndarray Array containing the z signal in volts with time. xdata : ndarray Array containing the x signal in volts with time. ydata : ndarray Array containing the y signal in volts with time. timedata : ndarray Array containing the time data to go with the z, x, and y signal.", "response": "def get_ZXY_data(Data, zf, xf, yf, FractionOfSampleFreq=1,\n                 zwidth=10000, xwidth=5000, ywidth=5000,\n                 filterImplementation=\"filtfilt\",\n                 timeStart=None, timeEnd=None,\n                 NPerSegmentPSD=1000000,\n                 MakeFig=True, show_fig=True):\n    \"\"\"\n    Given a Data object and the frequencies of the z, x and y peaks (and some\n    optional parameters for the created filters) this function extracts the\n    individual z, x and y signals (in volts) by creating IIR filters and filtering\n    the Data.\n\n    Parameters\n    ----------\n    Data : DataObject\n        DataObject containing the data for which you want to extract the\n        z, x and y signals.\n    zf : float\n        The frequency of the z peak in the PSD\n    xf : float\n        The frequency of the x peak in the PSD\n    yf : float\n        The frequency of the y peak in the PSD\n    FractionOfSampleFreq : integer, optional\n        The fraction of the sample frequency to sub-sample the data by.\n        This sometimes needs to be done because a filter with the appropriate\n        frequency response may not be generated using the sample rate at which\n        the data was taken. Increasing this number means the x, y and z signals\n        produced by this function will be sampled at a lower rate but a higher\n        number means a higher chance that the filter produced will have a nice\n        frequency response.\n    zwidth : float, optional\n        The width of the pass-band of the IIR filter to be generated to\n        filter Z.\n    xwidth : float, optional\n        The width of the pass-band of the IIR filter to be generated to\n        filter X.\n    ywidth : float, optional\n        The width of the pass-band of the IIR filter to be generated to\n        filter Y.\n    filterImplementation : string, optional\n        filtfilt or lfilter - use scipy.filtfilt or lfilter\n        default: filtfilt\n    timeStart : float, optional\n        Starting time for filtering\n    timeEnd : float, optional\n        Ending time for filtering\n    show_fig : bool, optional\n        If True - plot unfiltered and filtered PSD for z, x and y.\n        If False - don't plot anything\n\n    Returns\n    -------\n    zdata : ndarray\n        Array containing the z signal in volts with time.\n    xdata : ndarray\n        Array containing the x signal in volts with time.\n    ydata : ndarray\n        Array containing the y signal in volts with time.\n    timedata : ndarray\n        Array containing the time data to go with the z, x, and y signal.\n    \"\"\"\n    if timeStart == None:\n        timeStart = Data.timeStart\n    if timeEnd == None:\n        timeEnd = Data.timeEnd\n\n    time = Data.time.get_array()\n\n    StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n    EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n    SAMPLEFREQ = Data.SampleFreq / FractionOfSampleFreq\n\n    if filterImplementation == \"filtfilt\":\n        ApplyFilter = scipy.signal.filtfilt\n    elif filterImplementation == \"lfilter\":\n        ApplyFilter = scipy.signal.lfilter\n    else:\n        raise ValueError(\"filterImplementation must be one of [filtfilt, lfilter] you entered: {}\".format(\n            filterImplementation))\n\n    input_signal = Data.voltage[StartIndex: EndIndex][0::FractionOfSampleFreq]\n\n    bZ, aZ = make_butterworth_bandpass_b_a(zf, zwidth, SAMPLEFREQ)\n    print(\"filtering Z\")\n    zdata = ApplyFilter(bZ, aZ, input_signal)\n\n    if(_np.isnan(zdata).any()):\n        raise ValueError(\n            \"Value Error: FractionOfSampleFreq must be higher, a sufficiently small sample frequency should be used to produce a working IIR filter.\")\n\n    bX, aX = make_butterworth_bandpass_b_a(xf, xwidth, SAMPLEFREQ)\n    print(\"filtering X\")\n    xdata = ApplyFilter(bX, aX, input_signal)\n\n    if(_np.isnan(xdata).any()):\n        raise ValueError(\n            \"Value Error: FractionOfSampleFreq must be higher, a sufficiently small sample frequency should be used to produce a working IIR filter.\")\n\n    bY, aY = make_butterworth_bandpass_b_a(yf, ywidth, SAMPLEFREQ)\n    print(\"filtering Y\")\n    ydata = ApplyFilter(bY, aY, input_signal)\n\n    if(_np.isnan(ydata).any()):\n        raise ValueError(\n            \"Value Error: FractionOfSampleFreq must be higher, a sufficiently small sample frequency should be used to produce a working IIR filter.\")\n\n    if MakeFig == True:        \n        f, PSD = scipy.signal.welch(\n            input_signal, SAMPLEFREQ, nperseg=NPerSegmentPSD)\n        f_z, PSD_z = scipy.signal.welch(zdata, SAMPLEFREQ, nperseg=NPerSegmentPSD)\n        f_y, PSD_y = scipy.signal.welch(ydata, SAMPLEFREQ, nperseg=NPerSegmentPSD)\n        f_x, PSD_x = scipy.signal.welch(xdata, SAMPLEFREQ, nperseg=NPerSegmentPSD)\n        fig, ax = _plt.subplots(figsize=properties[\"default_fig_size\"])\n        ax.plot(f, PSD)\n        ax.plot(f_z, PSD_z, label=\"z\")\n        ax.plot(f_x, PSD_x, label=\"x\")\n        ax.plot(f_y, PSD_y, label=\"y\")\n        ax.legend(loc=\"best\")\n        ax.semilogy()\n        ax.set_xlim([zf - zwidth, yf + ywidth])\n    else:\n        fig = None\n        ax = None\n    if show_fig == True:\n        _plt.show()\n    timedata = time[StartIndex: EndIndex][0::FractionOfSampleFreq]\n    return zdata, xdata, ydata, timedata, fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ZXY_data_IFFT(Data, zf, xf, yf,\n                      zwidth=10000, xwidth=5000, ywidth=5000,\n                      timeStart=None, timeEnd=None,\n                      show_fig=True):\n    \"\"\"\n    Given a Data object and the frequencies of the z, x and y peaks (and some\n    optional parameters for the created filters) this function extracts the\n    individual z, x and y signals (in volts) by creating IIR filters and filtering\n    the Data.\n\n    Parameters\n    ----------\n    Data : DataObject\n        DataObject containing the data for which you want to extract the\n        z, x and y signals.\n    zf : float\n        The frequency of the z peak in the PSD\n    xf : float\n        The frequency of the x peak in the PSD\n    yf : float\n        The frequency of the y peak in the PSD\n    zwidth : float, optional\n        The width of the pass-band of the IIR filter to be generated to\n        filter Z.\n    xwidth : float, optional\n        The width of the pass-band of the IIR filter to be generated to\n        filter X.\n    ywidth : float, optional\n        The width of the pass-band of the IIR filter to be generated to\n        filter Y.\n    timeStart : float, optional\n        Starting time for filtering\n    timeEnd : float, optional\n        Ending time for filtering\n    show_fig : bool, optional\n        If True - plot unfiltered and filtered PSD for z, x and y.\n        If False - don't plot anything\n\n    Returns\n    -------\n    zdata : ndarray\n        Array containing the z signal in volts with time.\n    xdata : ndarray\n        Array containing the x signal in volts with time.\n    ydata : ndarray\n        Array containing the y signal in volts with time.\n    timedata : ndarray\n        Array containing the time data to go with the z, x, and y signal.\n    \"\"\"\n    if timeStart == None:\n        timeStart = Data.timeStart\n    if timeEnd == None:\n        timeEnd = Data.timeEnd\n\n    time = Data.time.get_array()\n\n    StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n    EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n    SAMPLEFREQ = Data.SampleFreq\n\n    input_signal = Data.voltage[StartIndex: EndIndex]\n\n    zdata = IFFT_filter(input_signal, SAMPLEFREQ, zf -\n                        zwidth / 2, zf + zwidth / 2)\n\n    xdata = IFFT_filter(input_signal, SAMPLEFREQ, xf -\n                        xwidth / 2, xf + xwidth / 2)\n\n    ydata = IFFT_filter(input_signal, SAMPLEFREQ, yf -\n                        ywidth / 2, yf + ywidth / 2)\n\n    if show_fig == True:\n        NPerSegment = len(Data.time)\n        if NPerSegment > 1e7:\n            NPerSegment = int(1e7)\n        f, PSD = scipy.signal.welch(\n            input_signal, SAMPLEFREQ, nperseg=NPerSegment)\n        f_z, PSD_z = scipy.signal.welch(zdata, SAMPLEFREQ, nperseg=NPerSegment)\n        f_y, PSD_y = scipy.signal.welch(ydata, SAMPLEFREQ, nperseg=NPerSegment)\n        f_x, PSD_x = scipy.signal.welch(xdata, SAMPLEFREQ, nperseg=NPerSegment)\n        _plt.plot(f, PSD)\n        _plt.plot(f_z, PSD_z, label=\"z\")\n        _plt.plot(f_x, PSD_x, label=\"x\")\n        _plt.plot(f_y, PSD_y, label=\"y\")\n        _plt.legend(loc=\"best\")\n        _plt.xlim([zf - zwidth, yf + ywidth])\n        _plt.xlabel('Frequency (Hz)')\n        _plt.ylabel(r'$S_{xx}$ ($V^2/Hz$)')\n        _plt.semilogy()\n        _plt.title(\"filepath = %s\" % (Data.filepath))\n        _plt.show()\n\n    timedata = time[StartIndex: EndIndex]\n    return zdata, xdata, ydata, timedata", "response": "This function extracts the z x and y data from a Data object and the frequencies of the z x and y peaks and PSDs for the specified time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nanimating the particle s motion given the z x and y signal.", "response": "def animate(zdata, xdata, ydata,\n            conversionFactorArray, timedata,\n            BoxSize,\n            timeSteps=100, filename=\"particle\"):\n    \"\"\"\n    Animates the particle's motion given the z, x and y signal (in Volts)\n    and the conversion factor (to convert between V and nm).\n\n    Parameters\n    ----------\n    zdata : ndarray\n        Array containing the z signal in volts with time.\n    xdata : ndarray\n        Array containing the x signal in volts with time.\n    ydata : ndarray\n        Array containing the y signal in volts with time.\n    conversionFactorArray : ndarray\n        Array of 3 values of conversion factors for z, x and y (in units of Volts/Metre)\n    timedata : ndarray\n        Array containing the time data in seconds.\n    BoxSize : float\n        The size of the box in which to animate the particle - in nm\n    timeSteps : int, optional\n        Number of time steps to animate\n    filename : string, optional\n        filename to create the mp4 under (<filename>.mp4)\n\n    \"\"\"\n    timePerFrame = 0.203\n    print(\"This will take ~ {} minutes\".format(timePerFrame * timeSteps / 60))\n\n    convZ = conversionFactorArray[0] * 1e-9\n    convX = conversionFactorArray[1] * 1e-9\n    convY = conversionFactorArray[2] * 1e-9\n    \n    ZBoxStart = -BoxSize  # 1/conv*(_np.mean(zdata)-0.06)\n    ZBoxEnd = BoxSize  # 1/conv*(_np.mean(zdata)+0.06)\n    XBoxStart = -BoxSize  # 1/conv*(_np.mean(xdata)-0.06)\n    XBoxEnd = BoxSize  # 1/conv*(_np.mean(xdata)+0.06)\n    YBoxStart = -BoxSize  # 1/conv*(_np.mean(ydata)-0.06)\n    YBoxEnd = BoxSize  # 1/conv*(_np.mean(ydata)+0.06)\n\n    FrameInterval = 1  # how many timesteps = 1 frame in animation\n\n    a = 20\n    b = 0.6 * a\n    myFPS = 7\n    myBitrate = 1000000\n\n    fig = _plt.figure(figsize=(a, b))\n    ax = fig.add_subplot(111, projection='3d')\n    ax.set_title(\"{} us\".format(timedata[0] * 1000000))\n    ax.set_xlabel('X (nm)')\n    ax.set_xlim([XBoxStart, XBoxEnd])\n    ax.set_ylabel('Y (nm)')\n    ax.set_ylim([YBoxStart, YBoxEnd])\n    ax.set_zlabel('Z (nm)')\n    ax.set_zlim([ZBoxStart, ZBoxEnd])\n    ax.view_init(20, -30)\n\n    #ax.view_init(0, 0)\n\n    def setup_plot():\n        XArray = 1 / convX * xdata[0]\n        YArray = 1 / convY * ydata[0]\n        ZArray = 1 / convZ * zdata[0]\n        scatter = ax.scatter(XArray, YArray, ZArray)\n        return scatter,\n\n    def animate(i):\n        # print \"\\r {}\".format(i),\n        print(\"Frame: {}\".format(i), end=\"\\r\")\n        ax.clear()\n        ax.view_init(20, -30)\n        ax.set_title(\"{} us\".format(int(timedata[i] * 1000000)))\n        ax.set_xlabel('X (nm)')\n        ax.set_xlim([XBoxStart, XBoxEnd])\n        ax.set_ylabel('Y (nm)')\n        ax.set_ylim([YBoxStart, YBoxEnd])\n        ax.set_zlabel('Z (nm)')\n        ax.set_zlim([ZBoxStart, ZBoxEnd])\n        XArray = 1 / convX * xdata[i]\n        YArray = 1 / convY * ydata[i]\n        ZArray = 1 / convZ * zdata[i]\n        scatter = ax.scatter(XArray, YArray, ZArray)\n        ax.scatter([XArray], [0], [-ZBoxEnd], c='k', alpha=0.9)\n        ax.scatter([-XBoxEnd], [YArray], [0], c='k', alpha=0.9)\n        ax.scatter([0], [YBoxEnd], [ZArray], c='k', alpha=0.9)\n\n        Xx, Yx, Zx, Xy, Yy, Zy, Xz, Yz, Zz = [], [], [], [], [], [], [], [], []\n\n        for j in range(0, 30):\n\n            Xlast = 1 / convX * xdata[i - j]\n            Ylast = 1 / convY * ydata[i - j]\n            Zlast = 1 / convZ * zdata[i - j]\n\n            Alpha = 0.5 - 0.05 * j\n            if Alpha > 0:\n                ax.scatter([Xlast], [0 + j * 10],\n                           [-ZBoxEnd], c='grey', alpha=Alpha)\n                ax.scatter([-XBoxEnd], [Ylast], [0 - j * 10],\n                           c='grey', alpha=Alpha)\n                ax.scatter([0 - j * 2], [YBoxEnd],\n                           [Zlast], c='grey', alpha=Alpha)\n\n                Xx.append(Xlast)\n                Yx.append(0 + j * 10)\n                Zx.append(-ZBoxEnd)\n\n                Xy.append(-XBoxEnd)\n                Yy.append(Ylast)\n                Zy.append(0 - j * 10)\n\n                Xz.append(0 - j * 2)\n                Yz.append(YBoxEnd)\n                Zz.append(Zlast)\n\n            if j < 15:\n                XCur = 1 / convX * xdata[i - j + 1]\n                YCur = 1 / convY * ydata[i - j + 1]\n                ZCur = 1 / convZ * zdata[i - j + 1]\n                ax.plot([Xlast, XCur], [Ylast, YCur], [Zlast, ZCur], alpha=0.4)\n\n        ax.plot_wireframe(Xx, Yx, Zx, color='grey')\n        ax.plot_wireframe(Xy, Yy, Zy, color='grey')\n        ax.plot_wireframe(Xz, Yz, Zz, color='grey')\n\n        return scatter,\n\n    anim = _animation.FuncAnimation(fig, animate, int(\n        timeSteps / FrameInterval), init_func=setup_plot, blit=True)\n\n    _plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n    mywriter = _animation.FFMpegWriter(fps=myFPS, bitrate=myBitrate)\n    # , fps = myFPS, bitrate = myBitrate)\n    anim.save('{}.mp4'.format(filename), writer=mywriter)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef animate_2Dscatter(x, y, NumAnimatedPoints=50, NTrailPoints=20, \n    xlabel=\"\", ylabel=\"\",\n    xlims=None, ylims=None, filename=\"testAnim.mp4\", \n    bitrate=1e5, dpi=5e2, fps=30, figsize = [6, 6]):\n    \"\"\"\n    Animates x and y - where x and y are 1d arrays of x and y \n    positions and it plots x[i:i+NTrailPoints] and y[i:i+NTrailPoints]\n    against each other and iterates through i. \n\n    \"\"\"\n    fig, ax = _plt.subplots(figsize = figsize)\n\n    alphas = _np.linspace(0.1, 1, NTrailPoints)\n    rgba_colors = _np.zeros((NTrailPoints,4))\n    # for red the first column needs to be one\n    rgba_colors[:,0] = 1.0\n    # the fourth column needs to be your alphas\n    rgba_colors[:, 3] = alphas\n\n\n    scatter = ax.scatter(x[0:NTrailPoints], y[0:NTrailPoints], color=rgba_colors)\n\n    if xlims == None:\n        xlims = (min(x), max(x))\n    if ylims == None:\n        ylims = (min(y), max(y))\n\n    ax.set_xlim(xlims)\n    ax.set_ylim(ylims)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n\n    def animate(i, scatter):\n        scatter.axes.clear() # clear old scatter object\n        scatter = ax.scatter(x[i:i+NTrailPoints], y[i:i+NTrailPoints], color=rgba_colors, animated=True) \n        # create new scatter with updated data\n        ax.set_xlim(xlims)\n        ax.set_ylim(ylims)\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        return scatter,\n\n\n    ani = _animation.FuncAnimation(fig, animate, _np.arange(1, NumAnimatedPoints),\n                                  interval=25, blit=True, fargs=[scatter])\n    ani.save(filename, bitrate=bitrate, dpi=dpi, fps=fps)\n    return None", "response": "Animate x and y against each other and plots them against each other."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef IFFT_filter(Signal, SampleFreq, lowerFreq, upperFreq, PyCUDA = False):\n    if PyCUDA==True:\n        Signalfft=calc_fft_with_PyCUDA(Signal)\n    else:\n        print(\"starting fft\")\n        Signalfft = scipy.fftpack.fft(Signal)\n    print(\"starting freq calc\")\n    freqs = _np.fft.fftfreq(len(Signal)) * SampleFreq\n    print(\"starting bin zeroing\")\n    Signalfft[_np.where(freqs < lowerFreq)] = 0\n    Signalfft[_np.where(freqs > upperFreq)] = 0\n    if PyCUDA==True:\n        FilteredSignal = 2 * calc_ifft_with_PyCUDA(Signalfft)\n    else:\n        print(\"starting ifft\")\n        FilteredSignal = 2 * scipy.fftpack.ifft(Signalfft)\n    print(\"done\")\n    return _np.real(FilteredSignal)", "response": "Filter the signal using fft and IFFT"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_fft_with_PyCUDA(Signal):\n    print(\"starting fft\")\n    Signal = Signal.astype(_np.float32)\n    Signal_gpu = _gpuarray.to_gpu(Signal)\n    Signalfft_gpu = _gpuarray.empty(len(Signal)//2+1,_np.complex64)\n    plan = _Plan(Signal.shape,_np.float32,_np.complex64)\n    _fft(Signal_gpu, Signalfft_gpu, plan)\n    Signalfft = Signalfft_gpu.get() #only 2N+1 long\n    Signalfft = _np.hstack((Signalfft,_np.conj(_np.flipud(Signalfft[1:len(Signal)//2]))))\n    print(\"fft done\")\n    return Signalfft", "response": "Calculates the FFT of the passed signal using the scikit - cuda libary which relies on PyCUDA\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the inverse - Fourier transform of the passed FFT - signal by using the scikit - cuda libary which relies on PyCUDA", "response": "def calc_ifft_with_PyCUDA(Signalfft):\n    \"\"\"\n    Calculates the inverse-FFT of the passed FFT-signal by \n    using the scikit-cuda libary which relies on PyCUDA\n\n    Parameters\n    ----------\n    Signalfft : ndarray\n        FFT-Signal to be transformed into Real space\n\n    Returns\n    -------\n    Signal : ndarray\n        Array containing the ifft signal\n    \"\"\"\n    print(\"starting ifft\")\n    Signalfft = Signalfft.astype(_np.complex64)\n    Signalfft_gpu = _gpuarray.to_gpu(Signalfft[0:len(Signalfft)//2+1])\n    Signal_gpu = _gpuarray.empty(len(Signalfft),_np.float32)\n    plan = _Plan(len(Signalfft),_np.complex64,_np.float32)\n    _ifft(Signalfft_gpu, Signal_gpu, plan)\n    Signal = Signal_gpu.get()/(2*len(Signalfft)) #normalising as CUDA IFFT is un-normalised\n    print(\"ifft done\")\n    return Signal"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfilters data using by constructing a 5th order butterworth IIR filter and using scipy.signal.filtfilt, which does phase correction after implementing the filter (as IIR filter apply a phase change) Parameters ---------- Signal : ndarray Signal to be filtered SampleFreq : float Sample frequency of signal lowerFreq : float Lower frequency of bandpass to allow through filter upperFreq : float Upper frequency of bandpass to allow through filter Returns ------- FilteredData : ndarray Array containing the filtered data", "response": "def butterworth_filter(Signal, SampleFreq, lowerFreq, upperFreq):\n    \"\"\"\n    Filters data using by constructing a 5th order butterworth\n    IIR filter and using scipy.signal.filtfilt, which does\n    phase correction after implementing the filter (as IIR \n    filter apply a phase change)\n\n    Parameters\n    ----------\n    Signal : ndarray\n        Signal to be filtered\n    SampleFreq : float\n        Sample frequency of signal\n    lowerFreq : float\n        Lower frequency of bandpass to allow through filter\n    upperFreq : float\n       Upper frequency of bandpass to allow through filter\n\n    Returns\n    -------\n    FilteredData : ndarray\n        Array containing the filtered data\n    \"\"\"\n    b, a = make_butterworth_b_a(lowerFreq, upperFreq, SampleFreq)\n    FilteredSignal = scipy.signal.filtfilt(b, a, Signal)\n    return _np.real(FilteredSignal)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the b and a coefficients for a butterworth IIR filter.", "response": "def make_butterworth_b_a(lowcut, highcut, SampleFreq, order=5, btype='band'):\n    \"\"\"\n    Generates the b and a coefficients for a butterworth IIR filter.\n\n    Parameters\n    ----------\n    lowcut : float\n        frequency of lower bandpass limit\n    highcut : float\n        frequency of higher bandpass limit\n    SampleFreq : float\n        Sample frequency of filter\n    order : int, optional\n        order of IIR filter. Is 5 by default\n    btype : string, optional\n        type of filter to make e.g. (band, low, high)\n\n    Returns\n    -------\n    b : ndarray\n        coefficients multiplying the current and past inputs (feedforward coefficients)\n    a : ndarray\n        coefficients multiplying the past outputs (feedback coefficients)\n    \"\"\"\n    nyq = 0.5 * SampleFreq\n    low = lowcut / nyq\n    high = highcut / nyq\n    if btype.lower() == 'band':\n        b, a = scipy.signal.butter(order, [low, high], btype = btype)\n    elif btype.lower() == 'low':\n        b, a = scipy.signal.butter(order, low, btype = btype)\n    elif btype.lower() == 'high':\n        b, a = scipy.signal.butter(order, high, btype = btype)\n    else:\n        raise ValueError('Filter type unknown')\n    return b, a"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the b and a coefficients for a butterworth bandpass IIR filter.", "response": "def make_butterworth_bandpass_b_a(CenterFreq, bandwidth, SampleFreq, order=5, btype='band'):\n    \"\"\"\n    Generates the b and a coefficients for a butterworth bandpass IIR filter.\n\n    Parameters\n    ----------\n    CenterFreq : float\n        central frequency of bandpass\n    bandwidth : float\n        width of the bandpass from centre to edge\n    SampleFreq : float\n        Sample frequency of filter\n    order : int, optional\n        order of IIR filter. Is 5 by default\n    btype : string, optional\n        type of filter to make e.g. (band, low, high)\n\n    Returns\n    -------\n    b : ndarray\n        coefficients multiplying the current and past inputs (feedforward coefficients)\n    a : ndarray\n        coefficients multiplying the past outputs (feedback coefficients)\n    \"\"\"    \n    lowcut = CenterFreq-bandwidth/2\n    highcut = CenterFreq+bandwidth/2\n    b, a = make_butterworth_b_a(lowcut, highcut, SampleFreq, order, btype)\n    return b, a"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef IIR_filter_design(CentralFreq, bandwidth, transitionWidth, SampleFreq, GainStop=40, GainPass=0.01):\n    NyquistFreq = SampleFreq / 2\n    if (CentralFreq + bandwidth / 2 + transitionWidth > NyquistFreq):\n        raise ValueError(\n            \"Need a higher Sample Frequency for this Central Freq, Bandwidth and transition Width\")\n\n    CentralFreqNormed = CentralFreq / NyquistFreq\n    bandwidthNormed = bandwidth / NyquistFreq\n    transitionWidthNormed = transitionWidth / NyquistFreq\n    bandpass = [CentralFreqNormed - bandwidthNormed /\n                2, CentralFreqNormed + bandwidthNormed / 2]\n    bandstop = [CentralFreqNormed - bandwidthNormed / 2 - transitionWidthNormed,\n                CentralFreqNormed + bandwidthNormed / 2 + transitionWidthNormed]\n    print(bandpass, bandstop)\n    b, a = scipy.signal.iirdesign(bandpass, bandstop, GainPass, GainStop)\n    return b, a", "response": "Function to calculate the coefficients of an IIR filter in a new language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_freq_response(a, b, show_fig=True, SampleFreq=(2 * pi), NumOfFreqs=500, whole=False):\n    w, h = scipy.signal.freqz(b=b, a=a, worN=NumOfFreqs, whole=whole)\n    freqList = w / (pi) * SampleFreq / 2.0\n    himag = _np.array([hi.imag for hi in h])\n    GainArray = 20 * _np.log10(_np.abs(h))\n    PhaseDiffArray = _np.unwrap(_np.arctan2(_np.imag(h), _np.real(h)))\n\n    fig1 = _plt.figure()\n    ax1 = fig1.add_subplot(111)\n    ax1.plot(freqList, GainArray, '-', label=\"Specified Filter\")\n    ax1.set_title(\"Frequency Response\")\n    if SampleFreq == 2 * pi:\n        ax1.set_xlabel((\"$\\Omega$ - Normalized frequency \"\n                       \"($\\pi$=Nyquist Frequency)\"))\n    else:\n        ax1.set_xlabel(\"frequency (Hz)\")\n    ax1.set_ylabel(\"Gain (dB)\")\n    ax1.set_xlim([0, SampleFreq / 2.0])\n    if show_fig == True:\n        _plt.show()\n    fig2 = _plt.figure()\n    ax2 = fig2.add_subplot(111)\n    ax2.plot(freqList, PhaseDiffArray, '-', label=\"Specified Filter\")\n    ax2.set_title(\"Phase Response\")\n    if SampleFreq == 2 * pi:\n        ax2.set_xlabel((\"$\\Omega$ - Normalized frequency \"\n                       \"($\\pi$=Nyquist Frequency)\"))\n    else:\n        ax2.set_xlabel(\"frequency (Hz)\")\n\n    ax2.set_ylabel(\"Phase Difference\")\n    ax2.set_xlim([0, SampleFreq / 2.0])\n    if show_fig == True:\n        _plt.show()\n    return freqList, GainArray, PhaseDiffArray, fig1, ax1, fig2, ax2", "response": "This function takes an array of coefficients and finds the frequency response of the filter and returns the response of the filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the pulse spectral density for multiple data sets on the same axes.", "response": "def multi_plot_PSD(DataArray, xlim=[0, 500], units=\"kHz\", LabelArray=[], ColorArray=[], alphaArray=[], show_fig=True):\n    \"\"\"\n    plot the pulse spectral density for multiple data sets on the same\n    axes.\n\n    Parameters\n    ----------\n    DataArray : array-like\n        array of DataObject instances for which to plot the PSDs\n    xlim : array-like, optional\n        2 element array specifying the lower and upper x limit for which to\n        plot the Power Spectral Density\n    units : string\n        units to use for the x axis\n    LabelArray : array-like, optional\n        array of labels for each data-set to be plotted\n    ColorArray : array-like, optional\n        array of colors for each data-set to be plotted\n    show_fig : bool, optional\n       If True runs plt.show() before returning figure\n       if False it just returns the figure object.\n       (the default is True, it shows the figure)\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure object\n        The figure object created\n    ax : matplotlib.axes.Axes object\n        The axes object created\n    \"\"\"\n    unit_prefix = units[:-2] # removed the last 2 chars\n    if LabelArray == []:\n        LabelArray = [\"DataSet {}\".format(i)\n                      for i in _np.arange(0, len(DataArray), 1)]\n    if ColorArray == []:\n        ColorArray = _np.empty(len(DataArray))\n        ColorArray = list(ColorArray)\n        for i, ele in enumerate(ColorArray):\n            ColorArray[i] = None    \n\n    if alphaArray == []:\n        alphaArray = _np.empty(len(DataArray))\n        alphaArray = list(alphaArray)\n        for i, ele in enumerate(alphaArray):\n            alphaArray[i] = None    \n\n            \n    fig = _plt.figure(figsize=properties['default_fig_size'])\n    ax = fig.add_subplot(111)\n\n    for i, data in enumerate(DataArray):\n        ax.semilogy(unit_conversion(data.freqs, unit_prefix), data.PSD, label=LabelArray[i], color=ColorArray[i], alpha=alphaArray[i])\n            \n    ax.set_xlabel(\"Frequency ({})\".format(units))\n    ax.set_xlim(xlim)\n    ax.grid(which=\"major\")\n    legend = ax.legend(loc=\"best\", frameon = 1)\n    frame = legend.get_frame()\n    frame.set_facecolor('white')\n    frame.set_edgecolor('white')\n    ax.set_ylabel(\"PSD ($v^2/Hz$)\")\n\n    _plt.title('filedir=%s' % (DataArray[0].filedir))\n\n    if show_fig == True:\n        _plt.show()\n    return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the time trace for multiple data sets on the same axes.", "response": "def multi_plot_time(DataArray, SubSampleN=1, units='s', xlim=None, ylim=None, LabelArray=[], show_fig=True):\n    \"\"\"\n    plot the time trace for multiple data sets on the same axes.\n\n    Parameters\n    ----------\n    DataArray : array-like\n        array of DataObject instances for which to plot the PSDs\n    SubSampleN : int, optional\n        Number of intervals between points to remove (to sub-sample data so\n        that you effectively have lower sample rate to make plotting easier\n        and quicker.\n    xlim : array-like, optional\n        2 element array specifying the lower and upper x limit for which to\n        plot the time signal\n    LabelArray : array-like, optional\n        array of labels for each data-set to be plotted\n    show_fig : bool, optional\n       If True runs plt.show() before returning figure\n       if False it just returns the figure object.\n       (the default is True, it shows the figure) \n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure object\n        The figure object created\n    ax : matplotlib.axes.Axes object\n        The axes object created\n    \"\"\"\n    unit_prefix = units[:-1] # removed the last char\n    if LabelArray == []:\n        LabelArray = [\"DataSet {}\".format(i)\n                      for i in _np.arange(0, len(DataArray), 1)]\n    fig = _plt.figure(figsize=properties['default_fig_size'])\n    ax = fig.add_subplot(111)\n    \n    for i, data in enumerate(DataArray):\n        ax.plot(unit_conversion(data.time.get_array()[::SubSampleN], unit_prefix), data.voltage[::SubSampleN],\n                alpha=0.8, label=LabelArray[i])\n    ax.set_xlabel(\"time (s)\")\n    if xlim != None:\n        ax.set_xlim(xlim)\n    if ylim != None:\n        ax.set_ylim(ylim)\n    ax.grid(which=\"major\")\n    legend = ax.legend(loc=\"best\", frameon = 1)\n    frame = legend.get_frame()\n    frame.set_facecolor('white')\n    frame.set_edgecolor('white')\n\n    ax.set_ylabel(\"voltage (V)\")\n    if show_fig == True:\n        _plt.show()\n    return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multi_subplots_time(DataArray, SubSampleN=1, units='s', xlim=None, ylim=None, LabelArray=[], show_fig=True):\n    unit_prefix = units[:-1] # removed the last char\n    NumDataSets = len(DataArray)\n\n    if LabelArray == []:\n        LabelArray = [\"DataSet {}\".format(i)\n                      for i in _np.arange(0, len(DataArray), 1)]\n\n    fig, axs = _plt.subplots(NumDataSets, 1)\n\n    for i, data in enumerate(DataArray):\n        axs[i].plot(unit_conversion(data.time.get_array()[::SubSampleN], unit_prefix), data.voltage[::SubSampleN],\n                    alpha=0.8, label=LabelArray[i])\n        axs[i].set_xlabel(\"time ({})\".format(units))\n        axs[i].grid(which=\"major\")\n        axs[i].legend(loc=\"best\")\n        axs[i].set_ylabel(\"voltage (V)\")\n        if xlim != None:\n            axs[i].set_xlim(xlim)\n        if ylim != None:\n            axs[i].set_ylim(ylim)\n    if show_fig == True:\n        _plt.show()\n    return fig, axs", "response": "Plots the time trace on multiple axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new figure that is a single figure and a list of axes that can be plotted on one canvas.", "response": "def arrange_plots_on_one_canvas(FigureAxTupleArray, title='', SubtitleArray = [], show_fig=True):\n    \"\"\"\n    Arranges plots, given in an array of tuples consisting of fig and axs, \n    onto a subplot-figure consisting of 2 horizontal times the lenght of the\n    passed (fig,axs)-array divided by 2 vertical subplots \n\n    Parameters\n    ----------\n    FigureAxTupleArray : array-like\n        array of Tuples(fig, axs) outputted from the other plotting funtions \n        inside optoanalysis\n    title : string, optional\n        string for the global title of the overall combined figure \n    SubtitleArray : array-like, optional\n        array of titles for each figure-set to be plotted, i.e. subplots \n    show_fig : bool, optional\n       If True runs plt.show() before returning figure\n       if False it just returns the figure object.\n       (the default is True, it shows the figure) \n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure object\n        The figure object created\n    axs : list of matplotlib.axes.Axes objects\n        The list of axes object created\n    \"\"\"\n    if SubtitleArray == []:\n        SubtitleArray = [\"Plot {}\".format(i)\n                      for i in _np.arange(0, len(FigureAxTupleArray), 1)]\n    SingleFigSize = FigureAxTupleArray[0][0].get_size_inches()\n    combinedFig=_plt.figure(figsize=(2*SingleFigSize[0],_np.ceil(len(FigureAxTupleArray)/2)*SingleFigSize[1]))\n    for index in range(len(FigureAxTupleArray)):\n        individualPlot = FigureAxTupleArray[index]\n        individualPlot[0].set_size_inches((2*SingleFigSize[0],_np.ceil(len(FigureAxTupleArray)/2)*SingleFigSize[1]))\n        ax = individualPlot[1]\n        ax.set_title(SubtitleArray[index])\n        ax.remove()\n        ax.figure = combinedFig\n        ax.change_geometry(int(_np.ceil(len(FigureAxTupleArray)/2)),2,1+index)\n        combinedFig.axes.append(ax)\n        combinedFig.add_axes(ax)\n        #_plt.close(individualPlot[0])\n    combinedFig.subplots_adjust(hspace=.4)\n    combinedFig.suptitle(title)\n    if show_fig == True:\n        _plt.show()\n    return combinedFig"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_PSD(Signal, SampleFreq, NPerSegment=1000000, window=\"hann\"):\n    freqs, PSD = scipy.signal.welch(Signal, SampleFreq,\n                                    window=window, nperseg=NPerSegment)\n    PSD = PSD[freqs.argsort()]\n    freqs.sort()\n    return freqs, PSD", "response": "Calculates the pulse spectral density of a signal at a given frequency."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_autocorrelation(Signal, FFT=False, PyCUDA=False):\n    if FFT==True:\n        Signal_padded = scipy.fftpack.ifftshift((Signal-_np.average(Signal))/_np.std(Signal))\n        n, = Signal_padded.shape\n        Signal_padded = _np.r_[Signal_padded[:n//2], _np.zeros_like(Signal_padded), Signal_padded[n//2:]]\n        if PyCUDA==True:\n            f = calc_fft_with_PyCUDA(Signal_padded)\n        else:\n            f = scipy.fftpack.fft(Signal_padded)\n        p = _np.absolute(f)**2\n        if PyCUDA==True:\n            autocorr = calc_ifft_with_PyCUDA(p)\n        else:\n            autocorr = scipy.fftpack.ifft(p)\n        return _np.real(autocorr)[:n//2]/(_np.arange(n//2)[::-1]+n//2)\n    else:\n        Signal = Signal - _np.mean(Signal)\n        autocorr = scipy.signal.correlate(Signal, Signal, mode='full')\n        return autocorr[autocorr.size//2:]/autocorr[autocorr.size//2]", "response": "Calculates the autocorrelation of a given signal at a given time - domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the real and imaginary components of each element in an array and returns them in 2 resulting arrays.", "response": "def _GetRealImagArray(Array):\n    \"\"\"\n    Returns the real and imaginary components of each element in an array and returns them in 2 resulting arrays.\n\n    Parameters\n    ----------\n    Array : ndarray\n        Input array\n\n    Returns\n    -------\n    RealArray : ndarray\n        The real components of the input array\n    ImagArray : ndarray\n        The imaginary components of the input array\n    \"\"\"\n    ImagArray = _np.array([num.imag for num in Array])\n    RealArray = _np.array([num.real for num in Array])\n    return RealArray, ImagArray"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the complex conjugate of each element in an array and returns the resulting array.", "response": "def _GetComplexConjugateArray(Array):\n    \"\"\"\n    Calculates the complex conjugate of each element in an array and returns the resulting array.\n\n    Parameters\n    ----------\n    Array : ndarray\n        Input array\n\n    Returns\n    -------\n    ConjArray : ndarray\n        The complex conjugate of the input array.\n    \"\"\"\n    ConjArray = _np.array([num.conj() for num in Array])\n    return ConjArray"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fm_discriminator(Signal):\n    S_analytic = _hilbert(Signal)\n    S_analytic_star = _GetComplexConjugateArray(S_analytic)\n    S_analytic_hat = S_analytic[1:] * S_analytic_star[:-1]\n    R, I = _GetRealImagArray(S_analytic_hat)\n    fmDiscriminator = _np.arctan2(I, R)\n    return fmDiscriminator", "response": "Calculates the digital FM discriminator from a real - valued time signal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a boolean indicating if a particular point is during a collision after effect or not.", "response": "def _is_this_a_collision(ArgList):\n    \"\"\"\n    Detects if a particular point is during collision after effect (i.e. a phase shift) or not.\n\n    Parameters\n    ----------\n    ArgList : array_like\n        Contains the following elements:\n            value : float\n                value of the FM discriminator\n            mean_fmd : float\n                the mean value of the FM discriminator\n            tolerance : float\n                The tolerance in percentage that it must be away from the mean value for it\n                to be counted as a collision event.\n\n    Returns\n    -------\n    is_this_a_collision : bool\n        True if this is a collision event, false if not.\n    \"\"\"\n    value, mean_fmd, tolerance = ArgList\n    if not _approx_equal(mean_fmd, value, tolerance):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_collisions(Signal, tolerance=50):\n    fmd = fm_discriminator(Signal)\n    mean_fmd = _np.mean(fmd)\n\n    Collisions = [_is_this_a_collision(\n        [value, mean_fmd, tolerance]) for value in fmd]\n\n    return Collisions", "response": "Find the collisions in the signal from the shift in phase of the signal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncounting the number of unique collisions and gets the collision index.", "response": "def count_collisions(Collisions):\n    \"\"\"\n    Counts the number of unique collisions and gets the collision index.\n\n    Parameters\n    ----------\n    Collisions : array_like\n        Array of booleans, containing true if during a collision event, false otherwise.\n\n    Returns\n    -------\n    CollisionCount : int\n        Number of unique collisions\n    CollisionIndicies : list\n        Indicies of collision occurance\n    \"\"\"\n    CollisionCount = 0\n    CollisionIndicies = []\n    lastval = True\n    for i, val in enumerate(Collisions):\n        if val == True and lastval == False:\n            CollisionIndicies.append(i)\n            CollisionCount += 1\n        lastval = val\n    return CollisionCount, CollisionIndicies"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an org - table into a Pandas data frame containing the org - table s data.", "response": "def parse_orgtable(lines):\n    \"\"\"\n    Parse an org-table (input as a list of strings split by newline)\n    into a Pandas data frame.\n\n    Parameters\n    ----------\n    lines : string\n        an org-table input as a list of strings split by newline\n    \n    Returns\n    -------\n    dataframe : pandas.DataFrame\n        A data frame containing the org-table's data\n    \"\"\"\n    def parseline(l):\n        w = l.split('|')[1:-1]\n        return [wi.strip() for wi in w]\n    columns = parseline(lines[0])\n\n    data = []\n    for line in lines[2:]:\n        data.append(map(str, parseline(line)))\n    dataframe = _pd.DataFrame(data=data, columns=columns)\n    dataframe.set_index(\"RunNo\")\n    return dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting the 3D distribution of the time points Z X and Y.", "response": "def plot_3d_dist(Z, X, Y, N=1000, AxisOffset=0, Angle=-40, LowLim=None, HighLim=None, show_fig=True):\n    \"\"\"\n    Plots Z, X and Y as a 3d scatter plot with heatmaps of each axis pair.\n\n    Parameters\n    ----------\n    Z : ndarray\n        Array of Z positions with time\n    X : ndarray\n        Array of X positions with time\n    Y : ndarray\n        Array of Y positions with time\n    N : optional, int\n        Number of time points to plot (Defaults to 1000)\n    AxisOffset : optional, double\n        Offset to add to each axis from the data - used to get a better view\n        of the heat maps (Defaults to 0)\n    LowLim : optional, double\n        Lower limit of x, y and z axis\n    HighLim : optional, double\n        Upper limit of x, y and z axis\n    show_fig : optional, bool\n        Whether to show the produced figure before returning\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure object\n        The figure object created\n    ax : matplotlib.axes.Axes object\n        The subplot object created\n    \"\"\"\n    angle = Angle\n    fig = _plt.figure(figsize=(8, 6))\n    ax = fig.add_subplot(111, projection='3d')\n\n    y = Z[0:N]\n    x = X[0:N]\n    z = Y[0:N]\n\n    ax.scatter(x, y, z, alpha=0.3)\n\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n    zlim = ax.get_zlim()\n    if LowLim != None:\n        lowLim = LowLim - AxisOffset\n    else:\n        lowLim = min([xlim[0], ylim[0], zlim[0]]) - AxisOffset\n    if HighLim != None:\n        highLim = HighLim + AxisOffset\n    else:\n        highLim = max([xlim[1], ylim[1], zlim[1]]) + AxisOffset\n    ax.set_xlim([lowLim, highLim])\n    ax.set_ylim([lowLim, highLim])\n    ax.set_zlim([lowLim, highLim])\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"z\")\n    ax.set_zlabel(\"y\")\n    ax.view_init(30, angle)\n\n    h, yedges, zedges = _np.histogram2d(y, z, bins=50)\n    h = h.transpose()\n    normalized_map = _plt.cm.Blues(h/h.max())\n    yy, zz = _np.meshgrid(yedges, zedges)\n    xpos = lowLim # Plane of histogram\n    xflat = _np.full_like(yy, xpos) \n    p = ax.plot_surface(xflat, yy, zz, facecolors=normalized_map, rstride=1, cstride=1, shade=False)\n\n    h, xedges, zedges = _np.histogram2d(x, z, bins=50)\n    h = h.transpose()\n    normalized_map = _plt.cm.Blues(h/h.max())\n    xx, zz = _np.meshgrid(xedges, zedges)\n    ypos = highLim # Plane of histogram\n    yflat = _np.full_like(xx, ypos) \n    p = ax.plot_surface(xx, yflat, zz, facecolors=normalized_map, rstride=1, cstride=1, shade=False)\n\n    h, yedges, xedges = _np.histogram2d(y, x, bins=50)\n    h = h.transpose()\n    normalized_map = _plt.cm.Blues(h/h.max())\n    yy, xx = _np.meshgrid(yedges, xedges)\n    zpos = lowLim # Plane of histogram\n    zflat = _np.full_like(yy, zpos) \n    p = ax.plot_surface(xx, yy, zflat, facecolors=normalized_map, rstride=1, cstride=1, shade=False)\n    if show_fig == True:\n        _plt.show()\n    return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting a 3D scatter plot with the specified data.", "response": "def multi_plot_3d_dist(ZXYData, N=1000, AxisOffset=0, Angle=-40, LowLim=None, HighLim=None, ColorArray=None, alphaLevel=0.3, show_fig=True):\n    \"\"\"\n    Plots serveral Z, X and Y datasets as a 3d scatter plot with heatmaps of each axis pair in each dataset.\n\n    Parameters\n    ----------\n    ZXYData : ndarray\n        Array of arrays containing Z, X, Y data e.g. [[Z1, X1, Y1], [Z2, X2, Y2]]\n    N : optional, int\n        Number of time points to plot (Defaults to 1000)\n    AxisOffset : optional, double\n        Offset to add to each axis from the data - used to get a better view\n        of the heat maps (Defaults to 0)\n    LowLim : optional, double\n        Lower limit of x, y and z axis\n    HighLim : optional, double\n        Upper limit of x, y and z axis\n    show_fig : optional, bool\n        Whether to show the produced figure before returning\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure object\n        The figure object created\n    ax : matplotlib.axes.Axes object\n        The subplot object created\n    \"\"\"\n    if ZXYData.shape[1] != 3:\n        raise ValueError(\"Parameter ZXYData should be an array of length-3 arrays containing arrays of Z, X and Y data\")\n    if ColorArray != None:\n        if ZXYData.shape[0] != len(ColorArray):\n            raise ValueError(\"Parameter ColorArray should be the same lenth as ZXYData\")\n    else:\n        ColorArray = list(mcolours.BASE_COLORS.keys())\n        #ColorArray = ['b', 'g', 'r']\n        #    ColorMapArray = [_plt.cm.Blues, _plt.cm.Greens, _plt.cm.Reds]\n        if ZXYData.shape[0] > len(ColorArray):\n            raise NotImplementedError(\"Only {} datasets can be plotted with automatic colors\".format(len(ColorArray)))\n        \n    angle = Angle\n    fig = _plt.figure(figsize=(8, 6))\n    ax = fig.add_subplot(111, projection='3d')\n\n    for datindx, ZXY in enumerate(ZXYData):\n        y = ZXY[0][0:N]\n        x = ZXY[1][0:N]\n        z = ZXY[2][0:N]\n        ax.scatter(x, y, z, alpha=alphaLevel, color=ColorArray[datindx])\n        \n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n    zlim = ax.get_zlim()\n    if LowLim != None:\n        lowLim = LowLim - AxisOffset\n    else:\n        lowLim = min([xlim[0], ylim[0], zlim[0]]) - AxisOffset\n    if HighLim != None:\n        highLim = HighLim + AxisOffset\n    else:\n        highLim = max([xlim[1], ylim[1], zlim[1]]) + AxisOffset\n    ax.set_xlim([lowLim, highLim])\n    ax.set_ylim([lowLim, highLim])\n    ax.set_zlim([lowLim, highLim])\n\n    for datindx, ZXY in enumerate(ZXYData):\n        y = ZXY[0][0:N]\n        x = ZXY[1][0:N]\n        z = ZXY[2][0:N]\n        \n        #h, yedges, zedges = _np.histogram2d(y, z, bins=50)\n        #h = h.transpose()\n        #normalized_map = ColorMapArray[datindx](h/h.max())\n        #yy, zz = _np.meshgrid(yedges, zedges)\n        xpos = lowLim # Plane of histogram\n        #xflat = _np.full_like(yy, xpos) \n        #p = ax.plot_surface(xflat, yy, zz, facecolors=normalized_map, rstride=1, cstride=1, shade=False)\n        xflat = _np.full_like(y, xpos) \n        ax.scatter(xflat, y, z, color=ColorArray[datindx], alpha=alphaLevel)\n        \n        #h, xedges, zedges = _np.histogram2d(x, z, bins=50)\n        #h = h.transpose()\n        #normalized_map = ColorMapArray[datindx](h/h.max())\n        #xx, zz = _np.meshgrid(xedges, zedges)\n        ypos = highLim # Plane of histogram\n        #yflat = _np.full_like(xx, ypos) \n        #p = ax.plot_surface(xx, yflat, zz, facecolors=normalized_map, rstride=1, cstride=1, shade=False)\n        yflat = _np.full_like(x, ypos) \n        ax.scatter(x, yflat, z, color=ColorArray[datindx], alpha=alphaLevel)\n        \n        #h, yedges, xedges = _np.histogram2d(y, x, bins=50)\n        #h = h.transpose()\n        #normalized_map = ColorMapArray[datindx](h/h.max())\n        #yy, xx = _np.meshgrid(yedges, xedges)\n        zpos = lowLim # Plane of histogram\n        #zflat = _np.full_like(yy, zpos) \n        #p = ax.plot_surface(xx, yy, zflat, facecolors=normalized_map, rstride=1, cstride=1, shade=False)\n        zflat = _np.full_like(y, zpos) \n        ax.scatter(x, y, zflat, color=ColorArray[datindx], alpha=alphaLevel)\n    \n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"z\")\n    ax.set_zlabel(\"y\")\n    ax.view_init(30, angle)\n    \n    if show_fig == True:\n        _plt.show()\n    return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the steady state potential. Used in fit_radius_from_potentials = 100", "response": "def steady_state_potential(xdata,HistBins=100):\n    \"\"\" \n    Calculates the steady state potential. Used in \n    fit_radius_from_potentials.\n\n    Parameters\n    ----------\n    xdata : ndarray\n        Position data for a degree of freedom\n    HistBins : int\n        Number of bins to use for histogram\n        of xdata. Number of position points\n        at which the potential is calculated.\n\n    Returns\n    -------\n    position : ndarray\n        positions at which potential has been \n        calculated\n    potential : ndarray\n        value of potential at the positions above\n    \n    \"\"\"  \n    import numpy as _np\n    \n    pops=_np.histogram(xdata,HistBins)[0]\n    bins=_np.histogram(xdata,HistBins)[1]\n    bins=bins[0:-1]\n    bins=bins+_np.mean(_np.diff(bins))\n    \n    #normalise pops\n    pops=pops/float(_np.sum(pops))\n    \n    return bins,-_np.log(pops)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dynamical_potential(xdata, dt, order=3):\n    import numpy as _np\n    adata = calc_acceleration(xdata, dt)\n    xdata = xdata[2:] # removes first 2 values as differentiating twice means\n    # we have acceleration[n] corresponds to position[n-2]\n    \n    z=_np.polyfit(xdata,adata,order)\n    p=_np.poly1d(z)\n    spring_pot=_np.polyint(p)\n    return -spring_pot", "response": "Compute the dynamical potential of a single resource in a single degree of freedom at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_acceleration(xdata, dt):\n    acceleration = _np.diff(_np.diff(xdata))/dt**2\n    return acceleration", "response": "Calculates the acceleration from the position data and dt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_radius_from_potentials(z, SampleFreq, Damping, HistBins=100, show_fig=False):\n    dt = 1/SampleFreq\n    boltzmann=Boltzmann\n    temp=300 # why halved??\n    density=1800\n    SteadyStatePotnl = list(steady_state_potential(z, HistBins=HistBins))\n    yoffset=min(SteadyStatePotnl[1])\n    SteadyStatePotnl[1] -= yoffset\n\n    SpringPotnlFunc = dynamical_potential(z, dt)\n    SpringPotnl = SpringPotnlFunc(z)\n    kBT_Gamma = temp*boltzmann*1/Damping\n    \n    DynamicPotentialFunc = make_dynamical_potential_func(kBT_Gamma, density, SpringPotnlFunc)\n    FitSoln = _curve_fit(DynamicPotentialFunc, SteadyStatePotnl[0], SteadyStatePotnl[1], p0 = 50)\n    print(FitSoln)\n    popt, pcov = FitSoln\n    perr = _np.sqrt(_np.diag(pcov))\n    Radius, RadiusError = popt[0], perr[0]\n\n    mass=((4/3)*pi*((Radius*10**-9)**3))*density\n    yfit=(kBT_Gamma/mass)\n    Y = yfit*SpringPotnl\n    \n    fig, ax = _plt.subplots()\n    ax.plot(SteadyStatePotnl[0], SteadyStatePotnl[1], 'bo', label=\"Steady State Potential\")\n    _plt.plot(z,Y, 'r-', label=\"Dynamical Potential\")\n    ax.legend(loc='best')\n    ax.set_ylabel('U ($k_{B} T $ Joules)')\n    ax.set_xlabel('Distance (mV)')\n    _plt.tight_layout()\n    if show_fig == True:\n        _plt.show()\n    return Radius*1e-9, RadiusError*1e-9, fig, ax", "response": "Fits the dynamical potential to the Steady \n    State Potential by varying the Radius."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_dynamical_potential_func(kBT_Gamma, density, SpringPotnlFunc):\n    def PotentialFunc(xdata, Radius):\n        \"\"\"\n        calculates the potential given the position (in volts) \n        and the radius of the particle.\n\n        Parameters\n        ----------\n        xdata : ndarray\n            Positon data (in volts)\n        Radius : float\n            Radius in units of nm\n\n        Returns\n        -------\n        Potential : ndarray\n            Dynamical Spring Potential at positions given by xdata\n        \"\"\"\n        mass = ((4/3)*pi*((Radius*10**-9)**3))*density\n        yfit=(kBT_Gamma/mass)\n        Y = yfit*SpringPotnlFunc(xdata)\n        return Y\n    return PotentialFunc", "response": "Returns the function that calculates the potential given the position and radius of the particle."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the Conversion Factor and physical amplitude of motion between two harmonics z and z2.", "response": "def calc_z0_and_conv_factor_from_ratio_of_harmonics(z, z2, NA=0.999):\n    \"\"\"\n    Calculates the Conversion Factor and physical amplitude of motion in nms \n    by comparison of the ratio of the heights of the z signal and \n    second harmonic of z.\n\n    Parameters\n    ----------\n    z : ndarray\n        array containing z signal in volts\n    z2 : ndarray\n        array containing second harmonic of z signal in volts\n    NA : float\n        NA of mirror used in experiment\n\n    Returns\n    -------\n    z0 : float\n        Physical average amplitude of motion in nms\n    ConvFactor : float\n        Conversion Factor between volts and nms\n    \"\"\"\n    V1 = calc_mean_amp(z)\n    V2 = calc_mean_amp(z2)\n    ratio = V2/V1\n    beta = 4*ratio\n    laserWavelength = 1550e-9 # in m\n    k0 = (2*pi)/(laserWavelength)\n    WaistSize = laserWavelength/(pi*NA)\n    Zr = pi*WaistSize**2/laserWavelength\n    z0 = beta/(k0 - 1/Zr)\n    ConvFactor = V1/z0\n    T0 = 300\n    return z0, ConvFactor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_mass_from_z0(z0, w0):\n    T0 = 300\n    mFromEquipartition = Boltzmann*T0/(w0**2 * z0**2)\n    return mFromEquipartition", "response": "Calculates the mass of the particle using the equipartition\n    from the angular frequency of the z signal and angular frequency of the motion in z signal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the mass from the A parameter from fitting the damping and the Conversion factor calculated from vasp - base.", "response": "def calc_mass_from_fit_and_conv_factor(A, Damping, ConvFactor):\n    \"\"\"\n    Calculates mass from the A parameter from fitting, the damping from \n    fitting in angular units and the Conversion factor calculated from \n    comparing the ratio of the z signal and first harmonic of z.\n\n    Parameters\n    ----------\n    A : float\n        A factor calculated from fitting\n    Damping : float\n        damping in radians/second calcualted from fitting\n    ConvFactor : float\n        conversion factor between volts and nms\n\n    Returns\n    -------\n    mass : float\n        mass in kgs\n    \"\"\"\n    T0 = 300\n    mFromA = 2*Boltzmann*T0/(pi*A) * ConvFactor**2 * Damping\n    return mFromA"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget slice of time and z and zdot from timeStart to timeEnd.", "response": "def get_time_slice(time, z, zdot=None, timeStart=None, timeEnd=None):\n    \"\"\"\n    Get slice of time, z and (if provided) zdot from timeStart to timeEnd.\n\n    Parameters\n    ----------\n    time : ndarray\n        array of time values \n    z : ndarray\n        array of z values\n    zdot : ndarray, optional\n        array of zdot (velocity) values.\n    timeStart : float, optional\n        time at which to start the slice.\n        Defaults to beginnging of time trace\n    timeEnd : float, optional\n        time at which to end the slide.\n        Defaults to end of time trace\n\n    Returns\n    -------\n    time_sliced : ndarray\n        array of time values from timeStart to timeEnd\n    z_sliced : ndarray\n        array of z values from timeStart to timeEnd\n    zdot_sliced : ndarray\n        array of zdot values from timeStart to timeEnd.\n        None if zdot not provided\n\n    \"\"\"\n    if timeStart == None:\n        timeStart = time[0]\n    if timeEnd == None:\n        timeEnd = time[-1]\n\n    StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n    EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n    time_sliced = time[StartIndex:EndIndex]\n    z_sliced = z[StartIndex:EndIndex]\n\n    if zdot != None:\n        zdot_sliced = zdot[StartIndex:EndIndex]\n    else:\n        zdot_sliced = None    \n    \n    return time_sliced, z_sliced, zdot_sliced"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts an array or value to of a certain unit scale to another unit scale. Accepted units are: E - exa - 1e18 P - peta - 1e15 T - tera - 1e12 G - giga - 1e9 M - mega - 1e6 k - kilo - 1e3 m - milli - 1e-3 u - micro - 1e-6 n - nano - 1e-9 p - pico - 1e-12 f - femto - 1e-15 a - atto - 1e-18 Parameters ---------- array : ndarray Array to be converted unit_prefix : string desired unit (metric) prefix (e.g. nm would be n, ms would be m) current_prefix : optional, string current prefix of units of data (assumed to be in SI units by default (e.g. m or s) Returns ------- converted_array : ndarray Array multiplied such as to be in the units specified", "response": "def unit_conversion(array, unit_prefix, current_prefix=\"\"):\n    \"\"\"\n    Converts an array or value to of a certain \n    unit scale to another unit scale.\n\n    Accepted units are:\n    E - exa - 1e18\n    P - peta - 1e15\n    T - tera - 1e12\n    G - giga - 1e9\n    M - mega - 1e6\n    k - kilo - 1e3\n    m - milli - 1e-3\n    u - micro - 1e-6\n    n - nano - 1e-9\n    p - pico - 1e-12\n    f - femto - 1e-15\n    a - atto - 1e-18\n\n    Parameters\n    ----------\n    array : ndarray\n        Array to be converted\n    unit_prefix : string\n        desired unit (metric) prefix (e.g. nm would be n, ms would be m)\n    current_prefix : optional, string\n        current prefix of units of data (assumed to be in SI units\n        by default (e.g. m or s)\n\n    Returns\n    -------\n    converted_array : ndarray\n        Array multiplied such as to be in the units specified\n    \"\"\"\n    UnitDict = {\n        'E': 1e18,\n        'P': 1e15,\n        'T': 1e12,\n        'G': 1e9,\n        'M': 1e6,\n        'k': 1e3,\n        '': 1,\n        'm': 1e-3,\n        'u': 1e-6,\n        'n': 1e-9,\n        'p': 1e-12,\n        'f': 1e-15,\n        'a': 1e-18,\n    }\n    try:\n        Desired_units = UnitDict[unit_prefix]\n    except KeyError:\n        raise ValueError(\"You entered {} for the unit_prefix, this is not a valid prefix\".format(unit_prefix))\n    try:\n        Current_units = UnitDict[current_prefix]\n    except KeyError:\n        raise ValueError(\"You entered {} for the current_prefix, this is not a valid prefix\".format(current_prefix))\n    conversion_multiplication = Current_units/Desired_units\n    converted_array = array*conversion_multiplication\n    return converted_array"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_slices(z, freq, sample_freq, show_plot=False):\n    dt = 1/sample_freq # dt between samples\n    period = 1/freq # period of oscillation of motion\n    period_samples = round(period/dt) # integer number of discrete samples in a period\n    number_of_oscillations = int(_np.floor(len(z)/period_samples)) # number of oscillations in z trace\n\n\n    phase_slices_untransposed = _np.zeros([number_of_oscillations-1, period_samples])\n\n    phase = _np.linspace(-180, 180, period_samples) # phase assigned to samples\n\n    if show_plot == True:\n        fig, ax = _plt.subplots()\n\n    for i in range(number_of_oscillations-1): \n        # loops through number of oscillations - 1 pulling out period_samples\n        # slices and assigning them a phase from -180 to 180 degrees\n        start = i*period_samples # start index of section\n        end = (i+1)*period_samples # end index of section\n        if show_plot == True:\n            _plt.plot(phase, z[start:end]) \n        phase_slices_untransposed[i] = z[start:end] # enter z section as ith row\n    \n    phase_slices = phase_slices_untransposed.transpose() # swap rows and columns \n\n    if show_plot == True:\n        _plt.show()\n    return phase, phase_slices", "response": "Extracts the slices from the trace of a single oscillation tree and assigns them a phase to the time of the oscillation tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef histogram_phase(phase_slices, phase, histbins=200, show_plot=False):\n    counts_array = _np.zeros([len(phase), histbins])\n\n    histedges = [phase_slices.min(), phase_slices.max()]\n    for i, phase_slice in enumerate(phase_slices): # for each value of phase\n        counts, bin_edges = _np.histogram(phase_slice, bins=histbins, range=histedges) # histogram the position distribution at that phase\n        counts_array[i] = counts\n    counts_array = _np.array(counts_array)\n    counts_array_transposed = _np.transpose(counts_array).astype(float)\n\n    if show_plot == True:\n        fig = _plt.figure(figsize=(12, 6))\n        ax = fig.add_subplot(111)\n        ax.set_title('Phase Distribution')\n        ax.set_xlabel(\"phase (\u00b0)\")\n        ax.set_ylabel(\"x\")\n        _plt.imshow(counts_array_transposed, cmap='hot', interpolation='nearest', extent=[phase[0], phase[-1], histedges[0], histedges[1]])\n        ax.set_aspect('auto')\n        _plt.show()\n\n    return counts_array_transposed, bin_edges", "response": "Returns the counts of the position distribution at each phase value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_wigner(z, freq, sample_freq, histbins=200, show_plot=False):\n    \n    phase, phase_slices = extract_slices(z, freq, sample_freq, show_plot=False)\n\n    counts_array, bin_edges = histogram_phase(phase_slices, phase, histbins, show_plot=show_plot)\n\n    diff = bin_edges[1] - bin_edges[0]\n    bin_centres = bin_edges[:-1] + diff\n\n    iradon_output = _iradon_sart(counts_array, theta=phase)\n\n    #_plt.imshow(iradon_output, extent=[bin_centres[0], bin_centres[-1], bin_centres[0], bin_centres[-1]])\n    #_plt.show()\n\n    return iradon_output, bin_centres", "response": "Calculates an approximation to the wigner quasi - probability distribution of the given motion at each phase."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_wigner3d(iradon_output, bin_centres, bin_centre_units=\"\", cmap=_cm.cubehelix_r, view=(10, -45), figsize=(10, 10)):\n    fig = _plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111, projection='3d')\n\n    resid1 = iradon_output.sum(axis=0)\n    resid2 = iradon_output.sum(axis=1)\n\n    x = bin_centres # replace with x\n    y = bin_centres # replace with p (xdot/omega)\n    xpos, ypos = _np.meshgrid(x, y)\n    X = xpos\n    Y = ypos\n    Z = iradon_output\n\n    ax.set_xlabel(\"x ({})\".format(bin_centre_units))\n    ax.set_xlabel(\"y ({})\".format(bin_centre_units))\n\n    ax.scatter(_np.min(X)*_np.ones_like(y), y, resid2/_np.max(resid2)*_np.max(Z), alpha=0.7)\n    ax.scatter(x, _np.max(Y)*_np.ones_like(x), resid1/_np.max(resid1)*_np.max(Z), alpha=0.7)\n\n    # Plot the surface.\n    surf = ax.plot_surface(X, Y, Z, cmap=cmap,\n                           linewidth=0, antialiased=False)\n\n    # Customize the z axis.\n    #ax.set_zlim(-1.01, 1.01)\n    #ax.zaxis.set_major_locator(LinearLocator(10))\n    #ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n\n    # Add a color bar which maps values to colors.\n    fig.colorbar(surf, shrink=0.5, aspect=5)\n\n    ax.view_init(view[0], view[1])\n\n    return fig, ax", "response": "Plots the wigner space representation as a 3D surface plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_wigner2d(iradon_output, bin_centres, cmap=_cm.cubehelix_r, figsize=(6, 6)):\n    xx, yy = _np.meshgrid(bin_centres, bin_centres)\n    resid1 = iradon_output.sum(axis=0)\n    resid2 = iradon_output.sum(axis=1)\n    \n    wigner_marginal_seperation = 0.001\n    left, width = 0.2, 0.65-0.1 # left = left side of hexbin and hist_x\n    bottom, height = 0.1, 0.65-0.1 # bottom = bottom of hexbin and hist_y\n    bottom_h = height + bottom + wigner_marginal_seperation\n    left_h = width + left + wigner_marginal_seperation\n    cbar_pos = [0.03, bottom, 0.05, 0.02+width]\n\n    rect_wigner = [left, bottom, width, height]\n    rect_histx = [left, bottom_h, width, 0.2]\n    rect_histy = [left_h, bottom, 0.2, height]\n\n    # start with a rectangular Figure\n    fig = _plt.figure(figsize=figsize)\n\n    axWigner = _plt.axes(rect_wigner)\n    axHistx = _plt.axes(rect_histx)\n    axHisty = _plt.axes(rect_histy)\n\n    pcol = axWigner.pcolor(xx, yy, iradon_output, cmap=cmap)\n    binwidth = bin_centres[1] - bin_centres[0]\n    axHistx.bar(bin_centres, resid2, binwidth)\n    axHisty.barh(bin_centres, resid1, binwidth)\n\n    _plt.setp(axHistx.get_xticklabels(), visible=False) # sets x ticks to be invisible while keeping gridlines\n    _plt.setp(axHisty.get_yticklabels(), visible=False) # sets x ticks to be invisible while keeping gridlines\n    for tick in axHisty.get_xticklabels():\n        tick.set_rotation(-90)\n\n\n    cbaraxes = fig.add_axes(cbar_pos)  # This is the position for the colorbar\n    #cbar = _plt.colorbar(axp, cax = cbaraxes)\n    cbar = fig.colorbar(pcol, cax = cbaraxes, drawedges=False) #, orientation=\"horizontal\"\n    cbar.solids.set_edgecolor(\"face\")\n    cbar.solids.set_rasterized(True)\n    cbar.ax.set_yticklabels(cbar.ax.yaxis.get_ticklabels(), y=0, rotation=45)\n    #cbar.set_label(cbarlabel, labelpad=-25, y=1.05, rotation=0)\n\n    plotlimits = _np.max(_np.abs(bin_centres))\n    axWigner.axis((-plotlimits, plotlimits, -plotlimits, plotlimits))\n    axHistx.set_xlim(axWigner.get_xlim())\n    axHisty.set_ylim(axWigner.get_ylim())\n\n    return fig, axWigner, axHistx, axHisty, cbar", "response": "Plots the wigner space representation as a 2D heatmap."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_reduced_chi_squared(y_observed, y_model, observation_error, number_of_fitted_parameters):\n    observed = _np.array(y_observed)\n    expected = _np.array(y_model)\n    if observed.shape != expected.shape:\n        raise ValueError(\"y_observed should have same number of elements as y_model\")\n    residuals = (observed - expected)\n    z = residuals / observation_error # residuals divided by known error in measurement\n    chi2 = _np.sum(z**2) # chi squared value\n    num_of_observations = len(observed)\n    v = num_of_observations - number_of_fitted_parameters # v = number of degrees of freedom\n    chi2_reduced = chi2/v\n    return chi2_reduced", "response": "Calculates the reduced chi - squared value for a given model and observed values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_time_data(self, RelativeChannelNo=None, SampleFreq=None, PointsToLoad=-1, NormaliseByMonitorOutput=False):\n        f = open(self.filepath, 'rb')\n        raw = f.read()\n        f.close()\n        FileExtension = self.filepath.split('.')[-1]\n        if FileExtension == \"raw\" or FileExtension == \"trc\":\n            with _warnings.catch_warnings(): # supress missing data warning and raise a missing\n                # data warning from optoanalysis with the filepath\n                _warnings.simplefilter(\"ignore\")\n                waveDescription, timeParams, self.voltage, _, missingdata = optoanalysis.LeCroy.InterpretWaveform(raw, noTimeArray=True) \n            if missingdata:\n                _warnings.warn(\"Waveform not of expected length. File {} may be missing data.\".format(self.filepath))\n            self.SampleFreq = (1 / waveDescription[\"HORIZ_INTERVAL\"])\n        elif FileExtension == \"bin\":\n            if RelativeChannelNo == None:\n                raise ValueError(\"If loading a .bin file from the Saleae data logger you must enter a relative channel number to load\")\n            timeParams, self.voltage = optoanalysis.Saleae.interpret_waveform(raw, RelativeChannelNo)\n            self.SampleFreq = 1/timeParams[2]\n        elif FileExtension == \"dat\": #for importing a file written by labview using the NI5122 daq card\n            if SampleFreq == None:\n                raise ValueError(\"If loading a .dat file from the NI5122 daq card you must enter a SampleFreq\")\n            if RelativeChannelNo == None:\n                self.voltage = _np.fromfile(self.filepath, dtype='>h',count=PointsToLoad)\n            elif RelativeChannelNo != None:\n                filedata = _np.fromfile(self.filepath, dtype='>h',count=PointsToLoad)\n                if NormaliseByMonitorOutput == True:\n                    if RelativeChannelNo == 0:\n                        monitorsignal = filedata[:len(filedata):2]\n                        self.voltage = filedata[1:len(filedata):2]/monitorsignal\n                    elif RelativeChannelNo == 1:\n                        monitorsignal = filedata[1:len(filedata):2]\n                        self.voltage = filedata[:len(filedata):2]/monitorsignal\n                elif NormaliseByMonitorOutput == False:\n                    self.voltage = filedata[RelativeChannelNo:len(filedata):2]\n            timeParams = (0,(len(self.voltage)-1)/SampleFreq,1/SampleFreq)\n            self.SampleFreq = 1/timeParams[2]\n        elif FileExtension == \"tdms\": # for importing a file written by labview form the NI7961 FPGA with the RecordDataPC VI\n            if SampleFreq == None:\n                raise ValueError(\"If loading a .tdms file saved from the FPGA you must enter a SampleFreq\")\n            self.SampleFreq = SampleFreq\n            dt = 1/self.SampleFreq\n            FIFO_SIZE = 262143 # this is the maximum size of the DMA FIFO on the NI 7961 FPGA with the NI 5781 DAC card\n            tdms_file = _TdmsFile(self.filepath)\n            channel = tdms_file.object('Measured_Data', 'data')\n            data = channel.data[FIFO_SIZE:] # dump first 1048575 points of data\n            # as this is the values that had already filled the buffer\n            # from before when the record code started running\n            volts_per_unit = 2/(2**14)\n            self.voltage = volts_per_unit*data\n            timeParams = [0, (data.shape[0]-1)*dt, dt]\n        elif FileExtension == 'txt': # .txt file created by LeCroy Oscilloscope\n            data = []\n            with open(self.filepath, 'r') as csvfile:\n                reader = csv.reader(csvfile)\n                for row in reader:\n                    data.append(row)\n            data = _np.array(data[5:]).astype(float).transpose()\n            t0 = data[0][0]\n            tend = data[0][-1]\n            dt = data[0][1] - data[0][0]\n            self.SampleFreq = 1/dt\n            self.voltage = data[1]\n            del(data)\n            timeParams = [t0, tend, dt]\n        else:\n            raise ValueError(\"Filetype not supported\")\n        startTime, endTime, Timestep = timeParams\n        self.timeStart = startTime\n        self.timeEnd = endTime\n        self.timeStep = Timestep\n        self.time = frange(startTime, endTime+Timestep, Timestep)\n        return None", "response": "Loads the time and voltage data from the associated file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the time and voltage data.", "response": "def get_time_data(self, timeStart=None, timeEnd=None):\n        \"\"\"\n        Gets the time and voltage data.\n\n        Parameters\n        ----------\n        timeStart : float, optional\n            The time get data from.\n            By default it uses the first time point\n        timeEnd : float, optional\n            The time to finish getting data from.\n            By default it uses the last time point        \n\n        Returns\n        -------\n        time : ndarray\n                        array containing the value of time (in seconds) at which the\n                        voltage is sampled\n        voltage : ndarray\n                        array containing the sampled voltages\n        \"\"\"\n        if timeStart == None:\n            timeStart = self.timeStart\n            \n        if timeEnd == None:\n            timeEnd = self.timeEnd\n\n        time = self.time.get_array()\n            \n        StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n        EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n        if EndIndex == len(time) - 1:\n            EndIndex = EndIndex + 1 # so that it does not remove the last element\n\n        return time[StartIndex:EndIndex], self.voltage[StartIndex:EndIndex]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_time_data(self, timeStart=None, timeEnd=None, units='s', show_fig=True):\n        unit_prefix = units[:-1] # removed the last char\n        if timeStart == None:\n            timeStart = self.timeStart\n        if timeEnd == None:\n            timeEnd = self.timeEnd\n\n        time = self.time.get_array()\n\n        StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n        EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n        fig = _plt.figure(figsize=properties['default_fig_size'])\n        ax = fig.add_subplot(111)\n        ax.plot(unit_conversion(time[StartIndex:EndIndex], unit_prefix),\n                self.voltage[StartIndex:EndIndex])\n        ax.set_xlabel(\"time ({})\".format(units))\n        ax.set_ylabel(\"voltage (V)\")\n        ax.set_xlim([timeStart, timeEnd])\n        if show_fig == True:\n            _plt.show()\n        return fig, ax", "response": "Plot time data against voltage data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the power spectral density of the current object.", "response": "def get_PSD(self, NPerSegment=1000000, window=\"hann\", timeStart=None, timeEnd=None, override=False):\n        \"\"\"\n        Extracts the power spectral density (PSD) from the data.\n\n        Parameters\n        ----------\n        NPerSegment : int, optional\n            Length of each segment used in scipy.welch\n            default = 1000000\n\n        window : str or tuple or array_like, optional\n            Desired window to use. See get_window for a list of windows\n            and required parameters. If window is array_like it will be\n            used directly as the window and its length will be used for\n            nperseg.\n            default = \"hann\"\n\n        Returns\n        -------\n        freqs : ndarray\n                Array containing the frequencies at which the PSD has been\n                calculated\n        PSD : ndarray\n                Array containing the value of the PSD at the corresponding\n                frequency value in V**2/Hz\n        \"\"\"\n        if timeStart == None and timeEnd == None:\n            freqs, PSD = calc_PSD(self.voltage, self.SampleFreq, NPerSegment=NPerSegment)\n            self.PSD = PSD\n            self.freqs = freqs\n        else:\n            if timeStart == None:\n                timeStart = self.timeStart\n            if timeEnd == None:\n                timeEnd = self.timeEnd\n\n            time = self.time.get_array()\n                \n            StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n            EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n            if EndIndex == len(time) - 1:\n                EndIndex = EndIndex + 1 # so that it does not remove the last element\n            freqs, PSD = calc_PSD(self.voltage[StartIndex:EndIndex], self.SampleFreq, NPerSegment=NPerSegment)\n            if override == True:\n                self.freqs = freqs\n                self.PSD = PSD\n\n        return freqs, PSD"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the pulse spectral density of the current pulse entry.", "response": "def plot_PSD(self, xlim=None, units=\"kHz\", show_fig=True, timeStart=None, timeEnd=None, *args, **kwargs):\n        \"\"\"\n        plot the pulse spectral density.\n\n        Parameters\n        ----------\n        xlim : array_like, optional\n            The x limits of the plotted PSD [LowerLimit, UpperLimit]\n            Default value is [0, SampleFreq/2]\n        units : string, optional\n            Units of frequency to plot on the x axis - defaults to kHz\n        show_fig : bool, optional\n            If True runs plt.show() before returning figure\n            if False it just returns the figure object.\n            (the default is True, it shows the figure)\n\n        Returns\n        -------\n        fig : matplotlib.figure.Figure object\n            The figure object created\n        ax : matplotlib.axes.Axes object\n            The subplot object created\n        \"\"\"\n        #        self.get_PSD()\n        if timeStart == None and timeEnd == None:\n            freqs = self.freqs\n            PSD = self.PSD\n        else:\n            freqs, PSD = self.get_PSD(timeStart=timeStart, timeEnd=timeEnd)\n            \n        unit_prefix = units[:-2]\n        if xlim == None:\n            xlim = [0, unit_conversion(self.SampleFreq/2, unit_prefix)]\n        fig = _plt.figure(figsize=properties['default_fig_size'])\n        ax = fig.add_subplot(111)\n        ax.semilogy(unit_conversion(freqs, unit_prefix), PSD, *args, **kwargs)\n        ax.set_xlabel(\"Frequency ({})\".format(units))\n        ax.set_xlim(xlim)\n        ax.grid(which=\"major\")\n        ax.set_ylabel(\"$S_{xx}$ ($V^2/Hz$)\")\n        if show_fig == True:\n            _plt.show()\n        return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_area_under_PSD(self, lowerFreq, upperFreq):\n        Freq_startAreaPSD = take_closest(self.freqs, lowerFreq)\n        index_startAreaPSD = int(_np.where(self.freqs == Freq_startAreaPSD)[0][0])\n        Freq_endAreaPSD = take_closest(self.freqs, upperFreq)\n        index_endAreaPSD = int(_np.where(self.freqs == Freq_endAreaPSD)[0][0])\n        AreaUnderPSD = sum(self.PSD[index_startAreaPSD: index_endAreaPSD])\n        return AreaUnderPSD", "response": "Calculates the area under the PSD from lowerFreq to upperFreq."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the fit function for the given entry - point.", "response": "def get_fit(self, TrapFreq, WidthOfPeakToFit, A_Initial=0.1e10, Gamma_Initial=400, silent=False, MakeFig=True, show_fig=True):\n        \"\"\"\n        Function that fits to a peak to the PSD to extract the \n        frequency, A factor and Gamma (damping) factor.\n\n        Parameters\n        ----------\n        TrapFreq : float\n            The approximate trapping frequency to use initially\n            as the centre of the peak\n        WidthOfPeakToFit : float\n            The width of the peak to be fitted to. This limits the\n            region that the fitting function can see in order to\n            stop it from fitting to the wrong peak\n        A_Initial : float, optional\n            The initial value of the A parameter to use in fitting\n        Gamma_Initial : float, optional\n            The initial value of the Gamma parameter to use in fitting\n        Silent : bool, optional\n            Whether to print any output when running this function\n            defaults to False\n        MakeFig : bool, optional\n            Whether to construct and return the figure object showing\n            the fitting. defaults to True\n        show_fig : bool, optional\n            Whether to show the figure object when it has been created.\n            defaults to True\n\n        Returns\n        -------\n        A : uncertainties.ufloat\n            Fitting constant A\n            A = \u03b3**2*2*\u0393_0*(K_b*T_0)/(\u03c0*m)\n            where:\n            \u03b3 = conversionFactor\n            \u0393_0 = Damping factor due to environment\n            \u03c0 = pi\n        OmegaTrap : uncertainties.ufloat\n            The trapping frequency in the z axis (in angular frequency)\n        Gamma : uncertainties.ufloat\n            The damping factor Gamma = \u0393 = \u0393_0 + \u03b4\u0393\n            where:\n            \u0393_0 = Damping factor due to environment\n            \u03b4\u0393 = extra damping due to feedback or other effects\n        fig : matplotlib.figure.Figure object\n            figure object containing the plot\n        ax : matplotlib.axes.Axes object\n            axes with the data plotted of the:\n            - initial data\n            - smoothed data\n            - initial fit\n            - final fit\n\n        \"\"\"\n        if MakeFig == True:\n            Params, ParamsErr, fig, ax = fit_PSD(\n                self, WidthOfPeakToFit, TrapFreq, A_Initial, Gamma_Initial, MakeFig=MakeFig, show_fig=show_fig)\n        else:\n            Params, ParamsErr, _ , _ = fit_PSD(\n                self, WidthOfPeakToFit, TrapFreq, A_Initial, Gamma_Initial, MakeFig=MakeFig, show_fig=show_fig)\n\n        if silent == False:\n            print(\"\\n\")\n            print(\"A: {} +- {}% \".format(Params[0],\n                                         ParamsErr[0] / Params[0] * 100))\n            print(\n                \"Trap Frequency: {} +- {}% \".format(Params[1], ParamsErr[1] / Params[1] * 100))\n            print(\n                \"Big Gamma: {} +- {}% \".format(Params[2], ParamsErr[2] / Params[2] * 100))\n\n        self.A = _uncertainties.ufloat(Params[0], ParamsErr[0])\n        self.OmegaTrap = _uncertainties.ufloat(Params[1], ParamsErr[1])\n        self.Gamma = _uncertainties.ufloat(Params[2], ParamsErr[2])\n\n        \n        if MakeFig == True:\n            return self.A, self.OmegaTrap, self.Gamma, fig, ax\n        else:\n            return self.A, self.OmegaTrap, self.Gamma, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds approximate values for the peaks central frequency, height, and FWHM by looking for the heighest peak in the frequency range defined by the input arguments. It then uses the central frequency as the trapping frequency, peak height to approximate the A value and the FWHM to an approximate the Gamma (damping) value. Parameters ---------- lowerLimit : float The lower frequency limit of the range in which it looks for a peak upperLimit : float The higher frequency limit of the range in which it looks for a peak NumPointsSmoothing : float The number of points of moving-average smoothing it applies before fitting the peak. Silent : bool, optional Whether it prints the values fitted or is silent. show_fig : bool, optional Whether it makes and shows the figure object or not. Returns ------- OmegaTrap : ufloat Trapping frequency A : ufloat A parameter Gamma : ufloat Gamma, the damping parameter", "response": "def get_fit_from_peak(self, lowerLimit, upperLimit, NumPointsSmoothing=1, silent=False, MakeFig=True, show_fig=True):\n        \"\"\"\n        Finds approximate values for the peaks central frequency, height, \n        and FWHM by looking for the heighest peak in the frequency range defined \n        by the input arguments. It then uses the central frequency as the trapping \n        frequency, peak height to approximate the A value and the FWHM to an approximate\n        the Gamma (damping) value.\n\n        Parameters\n        ----------\n        lowerLimit : float\n            The lower frequency limit of the range in which it looks for a peak\n        upperLimit : float\n            The higher frequency limit of the range in which it looks for a peak\n        NumPointsSmoothing : float\n            The number of points of moving-average smoothing it applies before fitting the \n            peak.\n        Silent : bool, optional\n            Whether it prints the values fitted or is silent.\n        show_fig : bool, optional\n            Whether it makes and shows the figure object or not.\n\n        Returns\n        -------\n        OmegaTrap : ufloat\n            Trapping frequency\n        A : ufloat\n            A parameter\n        Gamma : ufloat\n            Gamma, the damping parameter\n        \"\"\"\n        lowerIndex = _np.where(self.freqs ==\n            take_closest(self.freqs, lowerLimit))[0][0]\n        upperIndex = _np.where(self.freqs ==\n            take_closest(self.freqs, upperLimit))[0][0]\n\n        if lowerIndex == upperIndex:\n            _warnings.warn(\"range is too small, returning NaN\", UserWarning)\n            val = _uncertainties.ufloat(_np.NaN, _np.NaN)\n            return val, val, val, val, val\n\n        MaxPSD = max(self.PSD[lowerIndex:upperIndex])\n\n        centralIndex = _np.where(self.PSD == MaxPSD)[0][0]\n        CentralFreq = self.freqs[centralIndex]\n\n        approx_A = MaxPSD * 1e16  # 1e16 was calibrated for a number of saves to be approximately the correct conversion factor between the height of the PSD and the A factor in the fitting\n\n        MinPSD = min(self.PSD[lowerIndex:upperIndex])\n\n        # need to get this on log scale\n        HalfMax = MinPSD + (MaxPSD - MinPSD) / 2\n\n        try:\n            LeftSideOfPeakIndex = _np.where(self.PSD ==\n                                            take_closest(self.PSD[lowerIndex:centralIndex], HalfMax))[0][0]\n            LeftSideOfPeak = self.freqs[LeftSideOfPeakIndex]\n        except IndexError:\n            _warnings.warn(\"range is too small, returning NaN\", UserWarning)\n            val = _uncertainties.ufloat(_np.NaN, _np.NaN)\n            return val, val, val, val, val\n\n        try:\n            RightSideOfPeakIndex = _np.where(self.PSD ==\n                                             take_closest(self.PSD[centralIndex:upperIndex], HalfMax))[0][0]\n            RightSideOfPeak = self.freqs[RightSideOfPeakIndex]\n        except IndexError:\n            _warnings.warn(\"range is too small, returning NaN\", UserWarning)\n            val = _uncertainties.ufloat(_np.NaN, _np.NaN)\n            return val, val, val, val, val\n\n        FWHM = RightSideOfPeak - LeftSideOfPeak\n\n        approx_Gamma = FWHM/4\n        try:\n            A, OmegaTrap, Gamma, fig, ax \\\n                = self.get_fit(CentralFreq,\n                               (upperLimit-lowerLimit)/2, \n                               A_Initial=approx_A,\n                               Gamma_Initial=approx_Gamma,\n                               silent=silent,\n                               MakeFig=MakeFig,\n                               show_fig=show_fig)\n        except (TypeError, ValueError) as e: \n            _warnings.warn(\"range is too small to fit, returning NaN\", UserWarning)\n            val = _uncertainties.ufloat(_np.NaN, _np.NaN)\n            return val, val, val, val, val\n        OmegaTrap = self.OmegaTrap\n        A = self.A\n        Gamma = self.Gamma\n\n        omegaArray = 2 * pi * \\\n            self.freqs[LeftSideOfPeakIndex:RightSideOfPeakIndex]\n        PSDArray = self.PSD[LeftSideOfPeakIndex:RightSideOfPeakIndex]\n\n        return OmegaTrap, A, Gamma, fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fit_auto(self, CentralFreq, MaxWidth=15000, MinWidth=500, WidthIntervals=500, MakeFig=True, show_fig=True, silent=False):\n        MinTotalSumSquaredError = _np.infty\n        for Width in _np.arange(MaxWidth, MinWidth - WidthIntervals, -WidthIntervals):\n            try:\n                OmegaTrap, A, Gamma,_ , _ \\\n                    = self.get_fit_from_peak(\n                        CentralFreq - Width / 2,\n                        CentralFreq + Width / 2,\n                        silent=True,\n                        MakeFig=False,\n                        show_fig=False)\n            except RuntimeError:\n                _warnings.warn(\"Couldn't find good fit with width {}\".format(\n                    Width), RuntimeWarning)\n                val = _uncertainties.ufloat(_np.NaN, _np.NaN)\n                OmegaTrap = val\n                A = val\n                Gamma = val\n            TotalSumSquaredError = (\n                A.std_dev / A.n)**2 + (Gamma.std_dev / Gamma.n)**2 + (OmegaTrap.std_dev / OmegaTrap.n)**2\n            #print(\"totalError: {}\".format(TotalSumSquaredError))\n            if TotalSumSquaredError < MinTotalSumSquaredError:\n                MinTotalSumSquaredError = TotalSumSquaredError\n                BestWidth = Width\n        if silent != True:\n            print(\"found best\")\n        try:\n            OmegaTrap, A, Gamma, fig, ax \\\n                = self.get_fit_from_peak(CentralFreq - BestWidth / 2,\n                                         CentralFreq + BestWidth / 2,\n                                         MakeFig=MakeFig,\n                                         show_fig=show_fig,\n                                         silent=silent)\n        except UnboundLocalError:\n            raise ValueError(\"A best width was not found, try increasing the number of widths tried by either decreasing WidthIntervals or MinWidth or increasing MaxWidth\")\n        OmegaTrap = self.OmegaTrap\n        A = self.A\n        Gamma = self.Gamma\n        self.FTrap = OmegaTrap/(2*pi)\n        return OmegaTrap, A, Gamma, fig, ax", "response": "Finds a set of peaks and runs the fit_from_peak method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calc_gamma_from_variance_autocorrelation_fit(self, NumberOfOscillations, GammaGuess=None, silent=False, MakeFig=True, show_fig=True):\n        try:\n            SplittedArraySize = int(self.SampleFreq/self.FTrap.n) * NumberOfOscillations\n        except KeyError:\n            ValueError('You forgot to do the spectrum fit to specify self.FTrap exactly.')\n        VoltageArraySize = len(self.voltage)\n        SnippetsVariances = _np.var(self.voltage[:VoltageArraySize-_np.mod(VoltageArraySize,SplittedArraySize)].reshape(-1,SplittedArraySize),axis=1)\n        autocorrelation = calc_autocorrelation(SnippetsVariances)\n        time = _np.array(range(len(autocorrelation))) * SplittedArraySize / self.SampleFreq\n\n        if GammaGuess==None:\n            Gamma_Initial = (time[4]-time[0])/(autocorrelation[0]-autocorrelation[4])\n        else:\n            Gamma_Initial = GammaGuess\n        \n        if MakeFig == True:\n            Params, ParamsErr, fig, ax = fit_autocorrelation(\n                autocorrelation, time, Gamma_Initial, MakeFig=MakeFig, show_fig=show_fig)\n        else:\n            Params, ParamsErr, _ , _ = fit_autocorrelation(\n                autocorrelation, time, Gamma_Initial, MakeFig=MakeFig, show_fig=show_fig)\n\n        if silent == False:\n            print(\"\\n\")\n            print(\n                \"Big Gamma: {} +- {}% \".format(Params[0], ParamsErr[0] / Params[0] * 100))\n\n        Gamma = _uncertainties.ufloat(Params[0], ParamsErr[0])\n        \n        if MakeFig == True:\n            return Gamma, fig, ax\n        else:\n            return Gamma, None, None", "response": "Calculates the total damping for each oscillation in the time trace and calculates the autocorrelation of each oscillation in each chunk of time trace and calculates the variance of each oscillation in each chunk of time trace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the total damping of the autocorrelation of each entry in the energy array and calculates the total damping of the autocorrelation of each entry in time.", "response": "def calc_gamma_from_energy_autocorrelation_fit(self, GammaGuess=None, silent=False, MakeFig=True, show_fig=True):\n        \"\"\"\n        Calculates the total damping, i.e. Gamma, by calculating the energy each \n        point in time. This energy array is then used for the autocorrleation. \n        The autocorrelation is fitted with an exponential relaxation function and\n        the function returns the parameters with errors.\n\n        Parameters\n        ----------\n        GammaGuess : float, optional\n            Inital guess for BigGamma (in radians)\n        silent : bool, optional\n            Whether it prints the values fitted or is silent.\n        MakeFig : bool, optional\n            Whether to construct and return the figure object showing\n            the fitting. defaults to True\n        show_fig : bool, optional\n            Whether to show the figure object when it has been created.\n            defaults to True\n\n        Returns\n        -------\n        Gamma : ufloat\n            Big Gamma, the total damping in radians\n        fig : matplotlib.figure.Figure object\n            The figure object created showing the autocorrelation\n            of the data with the fit\n        ax : matplotlib.axes.Axes object\n            The axes object created showing the autocorrelation\n            of the data with the fit\n\n        \"\"\"\n        autocorrelation = calc_autocorrelation(self.voltage[:-1]**2*self.OmegaTrap.n**2+(_np.diff(self.voltage)*self.SampleFreq)**2)\n        time = self.time.get_array()[:len(autocorrelation)]\n\n        if GammaGuess==None:\n            Gamma_Initial = (time[4]-time[0])/(autocorrelation[0]-autocorrelation[4])\n        else:\n            Gamma_Initial = GammaGuess\n        \n        if MakeFig == True:\n            Params, ParamsErr, fig, ax = fit_autocorrelation(\n                autocorrelation, time, Gamma_Initial, MakeFig=MakeFig, show_fig=show_fig)\n        else:\n            Params, ParamsErr, _ , _ = fit_autocorrelation(\n                autocorrelation, time, Gamma_Initial, MakeFig=MakeFig, show_fig=show_fig)\n\n        if silent == False:\n            print(\"\\n\")\n            print(\n                \"Big Gamma: {} +- {}% \".format(Params[0], ParamsErr[0] / Params[0] * 100))\n\n        Gamma = _uncertainties.ufloat(Params[0], ParamsErr[0])\n        \n        if MakeFig == True:\n            return Gamma, fig, ax\n        else:\n            return Gamma, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_gamma_from_position_autocorrelation_fit(self, GammaGuess=None, FreqTrapGuess=None, silent=False, MakeFig=True, show_fig=True):\n        autocorrelation = calc_autocorrelation(self.voltage)\n        time = self.time.get_array()[:len(autocorrelation)]\n\n        if GammaGuess==None:\n            Gamma_Initial = (autocorrelation[0]-autocorrelation[int(self.SampleFreq/self.FTrap.n)])/(time[int(self.SampleFreq/self.FTrap.n)]-time[0])*2*_np.pi\n        else:\n            Gamma_Initial = GammaGuess\n\n        if FreqTrapGuess==None:\n            FreqTrap_Initial = self.FTrap.n\n        else:\n            FreqTrap_Initial = FreqTrapGuess\n            \n        if MakeFig == True:\n            Params, ParamsErr, fig, ax = fit_autocorrelation(\n                autocorrelation, time, Gamma_Initial, FreqTrap_Initial, method='position', MakeFig=MakeFig, show_fig=show_fig)\n        else:\n            Params, ParamsErr, _ , _ = fit_autocorrelation(\n                autocorrelation, time, Gamma_Initial, FreqTrap_Initial, method='position', MakeFig=MakeFig, show_fig=show_fig)\n\n        if silent == False:\n            print(\"\\n\")\n            print(\n                \"Big Gamma: {} +- {}% \".format(Params[0], ParamsErr[0] / Params[0] * 100))\n            print(\n                \"Trap Frequency: {} +- {}% \".format(Params[1], ParamsErr[1] / Params[1] * 100))\n            \n        Gamma = _uncertainties.ufloat(Params[0], ParamsErr[0])\n        OmegaTrap = _uncertainties.ufloat(Params[1], ParamsErr[1])\n        \n        if MakeFig == True:\n            return Gamma, OmegaTrap, fig, ax\n        else:\n            return Gamma, OmegaTrap, None, None", "response": "Calculates the total damping of the autocorrelation of the current position - time trace and the axes of the current position - time trace."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_parameters(self, P_mbar, P_Error, method=\"chang\"):\n\n        [R, M, ConvFactor], [RErr, MErr, ConvFactorErr] = \\\n            extract_parameters(P_mbar, P_Error,\n                               self.A.n, self.A.std_dev,\n                               self.Gamma.n, self.Gamma.std_dev,\n                               method = method)\n        self.Radius = _uncertainties.ufloat(R, RErr)\n        self.Mass = _uncertainties.ufloat(M, MErr)\n        self.ConvFactor = _uncertainties.ufloat(ConvFactor, ConvFactorErr)\n\n        return self.Radius, self.Mass, self.ConvFactor", "response": "Extracts the Radius mass and Conversion factor for a particle."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_ZXY_motion(self, ApproxZXYFreqs, uncertaintyInFreqs, ZXYPeakWidths, subSampleFraction=1, NPerSegmentPSD=1000000, MakeFig=True, show_fig=True):\n        [zf, xf, yf] = ApproxZXYFreqs\n        zf, xf, yf = get_ZXY_freqs(\n            self, zf, xf, yf, bandwidth=uncertaintyInFreqs)\n        [zwidth, xwidth, ywidth] = ZXYPeakWidths\n        self.zVolts, self.xVolts, self.yVolts, time, fig, ax = get_ZXY_data(\n            self, zf, xf, yf, subSampleFraction, zwidth, xwidth, ywidth, MakeFig=MakeFig, show_fig=show_fig, NPerSegmentPSD=NPerSegmentPSD)\n        return self.zVolts, self.xVolts, self.yVolts, time, fig, ax", "response": "This function extracts the x y and z signals from the original signal and returns the x y and z signals."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter out data about a central frequency with some bandwidth using an IIR filter. Parameters ---------- freq : float The frequency of the peak of interest in the PSD FractionOfSampleFreq : integer, optional The fraction of the sample frequency to sub-sample the data by. This sometimes needs to be done because a filter with the appropriate frequency response may not be generated using the sample rate at which the data was taken. Increasing this number means the x, y and z signals produced by this function will be sampled at a lower rate but a higher number means a higher chance that the filter produced will have a nice frequency response. PeakWidth : float, optional The width of the pass-band of the IIR filter to be generated to filter the peak. Defaults to 10KHz filterImplementation : string, optional filtfilt or lfilter - use scipy.filtfilt or lfilter ifft - uses built in IFFT_filter default: filtfilt timeStart : float, optional Starting time for filtering. Defaults to start of time data. timeEnd : float, optional Ending time for filtering. Defaults to end of time data. NPerSegmentPSD : int, optional NPerSegment to pass to scipy.signal.welch to calculate the PSD PyCUDA : bool, optional Only important for the 'ifft'-method If True, uses PyCUDA to accelerate the FFT and IFFT via using your NVIDIA-GPU If False, performs FFT and IFFT with conventional scipy.fftpack MakeFig : bool, optional If True - generate figure showing filtered and unfiltered PSD Defaults to True. show_fig : bool, optional If True - plot unfiltered and filtered PSD Defaults to True. Returns ------- timedata : ndarray Array containing the time data FiletedData : ndarray Array containing the filtered signal in volts with time. fig : matplotlib.figure.Figure object The figure object created showing the PSD of the filtered and unfiltered signal ax : matplotlib.axes.Axes object The axes object created showing the PSD of the filtered and unfiltered signal", "response": "def filter_data(self, freq, FractionOfSampleFreq=1, PeakWidth=10000,\n                    filterImplementation=\"filtfilt\",\n                    timeStart=None, timeEnd=None,\n                    NPerSegmentPSD=1000000,\n                    PyCUDA=False, MakeFig=True, show_fig=True):\n        \"\"\"\n        filter out data about a central frequency with some bandwidth using an IIR filter.\n    \n        Parameters\n        ----------\n        freq : float\n            The frequency of the peak of interest in the PSD\n        FractionOfSampleFreq : integer, optional\n            The fraction of the sample frequency to sub-sample the data by.\n            This sometimes needs to be done because a filter with the appropriate\n            frequency response may not be generated using the sample rate at which\n            the data was taken. Increasing this number means the x, y and z signals\n            produced by this function will be sampled at a lower rate but a higher\n            number means a higher chance that the filter produced will have a nice\n            frequency response.\n        PeakWidth : float, optional\n            The width of the pass-band of the IIR filter to be generated to\n            filter the peak. Defaults to 10KHz\n        filterImplementation : string, optional\n            filtfilt or lfilter - use scipy.filtfilt or lfilter\n            ifft - uses built in IFFT_filter\n            default: filtfilt\n        timeStart : float, optional\n            Starting time for filtering. Defaults to start of time data.\n        timeEnd : float, optional\n            Ending time for filtering. Defaults to end of time data.\n        NPerSegmentPSD : int, optional\n            NPerSegment to pass to scipy.signal.welch to calculate the PSD\n        PyCUDA : bool, optional\n            Only important for the 'ifft'-method\n            If True, uses PyCUDA to accelerate the FFT and IFFT\n            via using your NVIDIA-GPU\n            If False, performs FFT and IFFT with conventional\n            scipy.fftpack\n        MakeFig : bool, optional\n            If True - generate figure showing filtered and unfiltered PSD\n            Defaults to True.\n        show_fig : bool, optional\n            If True - plot unfiltered and filtered PSD\n            Defaults to True.\n    \n        Returns\n        -------\n        timedata : ndarray\n            Array containing the time data\n        FiletedData : ndarray\n            Array containing the filtered signal in volts with time.\n        fig : matplotlib.figure.Figure object\n            The figure object created showing the PSD of the filtered \n            and unfiltered signal\n        ax : matplotlib.axes.Axes object\n            The axes object created showing the PSD of the filtered \n            and unfiltered signal\n        \"\"\"\n        if timeStart == None:\n            timeStart = self.timeStart\n        if timeEnd == None:\n            timeEnd = self.timeEnd\n\n        time = self.time.get_array()\n\n        StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n        EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n\n        \n        input_signal = self.voltage[StartIndex: EndIndex][0::FractionOfSampleFreq]\n        SAMPLEFREQ = self.SampleFreq / FractionOfSampleFreq\n        if filterImplementation == \"filtfilt\" or filterImplementation == \"lfilter\":\n            if filterImplementation == \"filtfilt\":\n                ApplyFilter = scipy.signal.filtfilt\n            elif filterImplementation == \"lfilter\":\n                ApplyFilter = scipy.signal.lfilter\n                \n    \n            b, a = make_butterworth_bandpass_b_a(freq, PeakWidth, SAMPLEFREQ)\n            print(\"filtering data\")\n            filteredData = ApplyFilter(b, a, input_signal)\n    \n            if(_np.isnan(filteredData).any()):\n                raise ValueError(\n                    \"Value Error: FractionOfSampleFreq must be higher, a sufficiently small sample frequency should be used to produce a working IIR filter.\")\n        elif filterImplementation == \"ifft\":\n            filteredData = IFFT_filter(input_signal, SAMPLEFREQ, freq-PeakWidth/2, freq+PeakWidth/2, PyCUDA = PyCUDA)\n        else:\n            raise ValueError(\"filterImplementation must be one of [filtfilt, lfilter, ifft] you entered: {}\".format(filterImplementation))\n    \n        if MakeFig == True:\n            f, PSD = scipy.signal.welch(\n                input_signal, SAMPLEFREQ, nperseg=NPerSegmentPSD)\n            f_filtdata, PSD_filtdata = scipy.signal.welch(filteredData, SAMPLEFREQ, nperseg=NPerSegmentPSD)\n            fig, ax = _plt.subplots(figsize=properties[\"default_fig_size\"])\n            ax.plot(f, PSD)\n            ax.plot(f_filtdata, PSD_filtdata, label=\"filtered data\")\n            ax.legend(loc=\"best\")\n            ax.semilogy()\n            ax.set_xlim([freq - PeakWidth, freq + PeakWidth])\n        else:\n            fig = None\n            ax = None\n        if show_fig == True:\n            _plt.show()\n        timedata = time[StartIndex: EndIndex][0::FractionOfSampleFreq]\n        return timedata, filteredData, fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the phase space of a peak in the PSD.", "response": "def plot_phase_space_sns(self, freq, ConvFactor, PeakWidth=10000, FractionOfSampleFreq=1, kind=\"hex\", timeStart=None, timeEnd =None, PointsOfPadding=500, units=\"nm\", logscale=False, cmap=None, marginalColor=None, gridsize=200, show_fig=True, ShowPSD=False, alpha=0.5, *args, **kwargs):\n        \"\"\"\n        Plots the phase space of a peak in the PSD.\n        \n        Parameters\n        ----------\n        freq : float\n            The frequenecy of the peak (Trapping frequency of the dimension of interest)\n        ConvFactor : float (or ufloat)\n            The conversion factor between Volts and Meters\n        PeakWidth : float, optional\n            The width of the peak. Defaults to 10KHz\n        FractionOfSampleFreq : int, optional\n            The fraction of the sample freq to use to filter the data.\n            Defaults to 1.\n        kind : string, optional\n            kind of plot to draw - pass to jointplot from seaborne\n        timeStart : float, optional\n            Starting time for data from which to calculate the phase space.\n            Defaults to start of time data.\n        timeEnd : float, optional\n            Ending time for data from which to calculate the phase space.\n            Defaults to start of time data.\n        PointsOfPadding : float, optional\n            How many points of the data at the beginning and end to disregard for plotting\n            the phase space, to remove filtering artifacts. Defaults to 500.\n        units : string, optional\n            Units of position to plot on the axis - defaults to nm\n        cmap : matplotlib.colors.ListedColormap, optional\n            cmap to use for plotting the jointplot\n        marginalColor : string, optional\n            color to use for marginal plots\n        gridsize : int, optional\n            size of the grid to use with kind=\"hex\"\n        show_fig : bool, optional\n            Whether to show the figure before exiting the function\n            Defaults to True.\n        ShowPSD : bool, optional\n            Where to show the PSD of the unfiltered and the \n            filtered signal used to make the phase space\n            plot. Defaults to False.\n\n        Returns\n        -------\n        fig : matplotlib.figure.Figure object\n            figure object containing the phase space plot\n        JP : seaborn.jointplot object\n            joint plot object containing the phase space plot\n        \"\"\"\n        if cmap == None:\n            if logscale == True:\n                cmap = properties['default_log_cmap']\n            else:\n                cmap = properties['default_linear_cmap']\n        \n        unit_prefix = units[:-1]\n\n        _, PosArray, VelArray = self.calc_phase_space(freq, ConvFactor, PeakWidth=PeakWidth, FractionOfSampleFreq=FractionOfSampleFreq, timeStart=timeStart, timeEnd=timeEnd, PointsOfPadding=PointsOfPadding, ShowPSD=ShowPSD)\n\n        _plt.close('all')\n        \n        PosArray = unit_conversion(PosArray, unit_prefix) # converts m to units required (nm by default)\n        VelArray = unit_conversion(VelArray, unit_prefix) # converts m/s to units required (nm/s by default)\n        \n        VarPos = _np.var(PosArray)\n        VarVel = _np.var(VelArray)\n        MaxPos = _np.max(PosArray)\n        MaxVel = _np.max(VelArray)\n        if MaxPos > MaxVel / (2 * pi * freq):\n            _plotlimit = MaxPos * 1.1\n        else:\n            _plotlimit = MaxVel / (2 * pi * freq) * 1.1\n\n        print(\"Plotting Phase Space\")\n\n        if marginalColor == None:\n            try:\n                marginalColor = tuple((cmap.colors[len(cmap.colors)/2][:-1]))\n            except AttributeError:\n                try:\n                    marginalColor = cmap(2)\n                except:\n                    marginalColor = properties['default_base_color']\n\n        if kind == \"hex\":    # gridsize can only be passed if kind=\"hex\"\n            JP1 = _sns.jointplot(_pd.Series(PosArray[1:], name=\"$z$ ({}) \\n filepath=%s\".format(units) % (self.filepath)),\n                                 _pd.Series(VelArray / (2 * pi * freq), name=\"$v_z$/$\\omega$ ({})\".format(units)),\n                                 stat_func=None,\n                                 xlim=[-_plotlimit, _plotlimit],\n                                 ylim=[-_plotlimit, _plotlimit],\n                                 size=max(properties['default_fig_size']),\n                                 kind=kind,\n                                 marginal_kws={'hist_kws': {'log': logscale},},\n                                 cmap=cmap,\n                                 color=marginalColor,\n                                 gridsize=gridsize,\n                                 alpha=alpha,\n                                 *args,\n                                 **kwargs,\n            )\n        else:\n            JP1 = _sns.jointplot(_pd.Series(PosArray[1:], name=\"$z$ ({}) \\n filepath=%s\".format(units) % (self.filepath)),\n                                     _pd.Series(VelArray / (2 * pi * freq), name=\"$v_z$/$\\omega$ ({})\".format(units)),\n                                 stat_func=None,\n                                 xlim=[-_plotlimit, _plotlimit],\n                                 ylim=[-_plotlimit, _plotlimit],\n                                 size=max(properties['default_fig_size']),\n                                 kind=kind,\n                                 marginal_kws={'hist_kws': {'log': logscale},},\n                                 cmap=cmap,\n                                 color=marginalColor,\n                                 alpha=alpha,                                \n                                 *args,\n                                 **kwargs,\n            )\n\n        fig = JP1.fig\n        \n        if show_fig == True:\n            print(\"Showing Phase Space\")\n            _plt.show()\n            \n        return fig, JP1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calc_phase_space(self, freq, ConvFactor, PeakWidth=10000, FractionOfSampleFreq=1, timeStart=None, timeEnd =None, PointsOfPadding=500, ShowPSD=False):\n        _, Pos, fig, ax = self.filter_data(\n            freq, FractionOfSampleFreq, PeakWidth, MakeFig=ShowPSD, show_fig=ShowPSD, timeStart=timeStart, timeEnd=timeEnd)\n        time = self.time.get_array()\n        if timeStart != None:\n            StartIndex = _np.where(time == take_closest(time, timeStart))[0][0]\n        else:\n            StartIndex = 0\n        if timeEnd != None:\n            EndIndex = _np.where(time == take_closest(time, timeEnd))[0][0]\n        else:\n            EndIndex = -1\n            \n        Pos = Pos[PointsOfPadding : -PointsOfPadding+1]\n        time = time[StartIndex:EndIndex][::FractionOfSampleFreq][PointsOfPadding : -PointsOfPadding+1]\n        \n        if type(ConvFactor) == _uncertainties.core.Variable:\n            conv = ConvFactor.n\n        else:\n            conv = ConvFactor\n        PosArray = Pos / conv # converts V to m\n        VelArray = _np.diff(PosArray) * (self.SampleFreq / FractionOfSampleFreq) # calcs velocity (in m/s) by differtiating position\n        return time, PosArray, VelArray", "response": "Calculates the position and velocity of the phase space of the specified particle in the time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_value(self, ColumnName, RunNo):\n        Value = float(self.ORGTableData[self.ORGTableData.RunNo == '{}'.format(\n            RunNo)][ColumnName])\n        \n        return Value", "response": "Returns the value of the column with the given name associated \n        with a particular run number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the steady state potential of a single object.", "response": "def steady_state_potential(xdata,HistBins=100):\n    \"\"\" \n    Calculates the steady state potential.\n\n    Parameters\n    ----------\n    xdata : ndarray\n        Position data for a degree of freedom\n    HistBins : int\n        Number of bins to use for histogram\n        of xdata. Number of position points\n        at which the potential is calculated.\n\n    Returns\n    -------\n    position : ndarray\n        positions at which potential has been \n        calculated\n    potential : ndarray\n        value of potential at the positions above\n    \n    \"\"\"  \n    import numpy as np\n    \n    pops=np.histogram(xdata,HistBins)[0]\n    bins=np.histogram(xdata,HistBins)[1]\n    bins=bins[0:-1]\n    bins=bins+np.mean(np.diff(bins))\n    \n    #normalise pops\n    pops=pops/float(np.sum(pops))\n    \n    return bins,-np.log(pops)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dynamical_potential(xdata, dt, order=3):\n    import numpy as np\n    adata = CalcAcceleration(xdata, dt)\n    xdata = xdata[2:] # removes first 2 values as differentiating twice means\n    # we have acceleration[n] corresponds to position[n-2]\n    \n    z=np.polyfit(xdata,adata,order)\n    p=np.poly1d(z)\n    spring_pot=np.polyint(p)\n    return -spring_pot", "response": "Computes the dynamical potential of a single resource at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the acceleration from the position data and dt", "response": "def CalcAcceleration(xdata, dt):\n    \"\"\"\n    Calculates the acceleration from the position\n    \n    Parameters\n    ----------\n    xdata : ndarray\n        Position data\n    dt : float\n        time between measurements\n\n    Returns\n    -------\n    acceleration : ndarray\n        values of acceleration from position \n        2 to N.\n\n    \"\"\"\n    acceleration = np.diff(np.diff(xdata))/dt**2\n    return acceleration"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FitRadius(z, SampleFreq, Damping, HistBins=100):\n    dt = 1/SampleFreq\n    boltzmann=scipy.constants.Boltzmann\n    temp=300 # why halved??\n    density=1800\n    SteadyStatePotnl = list(steady_state_potential(z, HistBins=HistBins))\n    yoffset=min(SteadyStatePotnl[1])\n    SteadyStatePotnl[1] -= yoffset\n\n    SpringPotnlFunc = dynamical_potential(z, dt)\n    SpringPotnl = SpringPotnlFunc(z)\n    kBT_Gamma = temp*boltzmann*1/Damping\n    \n    #FitSoln = least_squares(GetResiduals, 50, args=(SteadyStatePotnl, SpringPotnlFunc, kBT_Gamma), full_output=True)\n    #print(FitSoln)\n    #RADIUS = FitSoln['x'][0]\n\n    DynamicPotentialFunc = MakeDynamicPotentialFunc(kBT_Gamma, density, SpringPotnlFunc)\n    FitSoln = curve_fit(DynamicPotentialFunc, SteadyStatePotnl[0], SteadyStatePotnl[1], p0 = 50)\n    print(FitSoln)\n    popt, pcov = FitSoln\n    perr = np.sqrt(np.diag(pcov))\n    Radius, RadiusError = popt[0], perr[0]\n\n    mass=((4/3)*np.pi*((Radius*10**-9)**3))*density\n    yfit=(kBT_Gamma/mass)\n    Y = yfit*SpringPotnl\n    \n    fig, ax = plt.subplots()\n    ax.plot(SteadyStatePotnl[0], SteadyStatePotnl[1], 'bo', label=\"Steady State Potential\")\n    plt.plot(z,Y, 'r-', label=\"Dynamical Potential\")\n    ax.legend(loc='best')\n    ax.set_ylabel('U ($k_{B} T $ Joules)')\n    ax.set_xlabel('Distance (mV)')\n    plt.tight_layout()\n    plt.show()\n    return Radius, RadiusError", "response": "Fit the dynamical potential to the Steady \n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a function that calculates the potential given the position and radius of the particle.", "response": "def MakeDynamicPotentialFunc(kBT_Gamma, density, SpringPotnlFunc):\n    \"\"\"\n    Creates the function that calculates the potential given\n    the position (in volts) and the radius of the particle. \n\n    Parameters\n    ----------\n    kBT_Gamma : float\n        Value of kB*T/Gamma\n    density : float\n        density of the nanoparticle\n    SpringPotnlFunc : function\n        Function which takes the value of position (in volts)\n        and returns the spring potential\n    \n    Returns\n    -------\n    PotentialFunc : function\n        function that calculates the potential given\n        the position (in volts) and the radius of the \n        particle.\n\n    \"\"\"\n    def PotentialFunc(xdata, Radius):\n        \"\"\"\n        calculates the potential given the position (in volts) \n        and the radius of the particle.\n\n        Parameters\n        ----------\n        xdata : ndarray\n            Positon data (in volts)\n        Radius : float\n            Radius in units of nm\n\n        Returns\n        -------\n        Potential : ndarray\n            Dynamical Spring Potential at positions given by xdata\n        \"\"\"\n        mass = ((4/3)*np.pi*((Radius*10**-9)**3))*density\n        yfit=(kBT_Gamma/mass)\n        Y = yfit*SpringPotnlFunc(xdata)\n        return Y\n    return PotentialFunc"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finished(finished_status,\n             update_interval,\n             status_key,\n             edit_at_key):\n    \"\"\"\n    Create dict query for pymongo that getting all finished task.\n\n    :param finished_status: int, status code that greater or equal than this\n        will be considered as finished.\n    :param update_interval: int, the record will be updated every x seconds.\n    :param status_key: status code field key, support dot notation.\n    :param edit_at_key: edit_at time field key, support dot notation.\n\n    :return: dict, a pymongo filter.\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u72b6\u6001\u7801\u5927\u4e8e\u67d0\u4e2a\u503c, \u5e76\u4e14, \u66f4\u65b0\u65f6\u95f4\u5728\u6700\u8fd1\u4e00\u6bb5\u65f6\u95f4\u4ee5\u5185.\n    \"\"\"\n    return {\n        status_key: {\"$gte\": finished_status},\n        edit_at_key: {\n            \"$gte\": x_seconds_before_now(update_interval),\n        },\n    }", "response": "Returns a dict query for pymongo that getting all finished task."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict query for pymongo that getting all unfinished task.", "response": "def unfinished(finished_status,\n               update_interval,\n               status_key,\n               edit_at_key):\n    \"\"\"\n    Create dict query for pymongo that getting all unfinished task.\n\n    :param finished_status: int, status code that less than this\n        will be considered as unfinished.\n    :param update_interval: int, the record will be updated every x seconds.\n    :param status_key: status code field key, support dot notation.\n    :param edit_at_key: edit_at time field key, support dot notation.\n\n    :return: dict, a pymongo filter.\n\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u72b6\u6001\u7801\u5c0f\u4e8e\u67d0\u4e2a\u503c, \u6216\u8005, \u73b0\u5728\u8ddd\u79bb\u66f4\u65b0\u65f6\u95f4\u5df2\u7ecf\u8d85\u8fc7\u4e00\u5b9a\u9608\u503c.\n    \"\"\"\n    return {\n        \"$or\": [\n            {status_key: {\"$lt\": finished_status}},\n            {edit_at_key: {\"$lt\": x_seconds_before_now(update_interval)}},\n        ]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getCommandLine(self):\n        commandLine = self.precursor + self.sep if self.precursor else ''\n        commandLine += self.cd + ' ' + self.path + self.sep if self.path else ''\n        commandLine += PosixCommand.getCommandLine(self)\n        return commandLine", "response": "Return the command line for this entry point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all permission sets making use of all of a list of policy_instances.", "response": "def _policy_psets(policy_instances):\n    \"\"\"Find all permission sets making use of all of a list of policy_instances.\n    The input is an array of policy instances.\n\n    \"\"\"\n    if len(policy_instances) == 0:\n        # Special case: find any permission sets that don't have\n        # associated policy instances.\n        return PermissionSet.objects.filter(policyinstance__isnull=True)\n    else:\n        return PermissionSet.objects.filter(\n            policyinstance__policy__in=policy_instances).distinct()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_permission_set_tree(user):\n    if hasattr(user, CACHED_PSET_PROPERTY_KEY):\n        return getattr(user, CACHED_PSET_PROPERTY_KEY)\n    if user.is_authenticated():\n        try:\n            return user.permissionset.first().tree()\n        except AttributeError:\n            raise ObjectDoesNotExist\n    return PermissionSet.objects.get(anonymous_user=True).tree()", "response": "Helper to return cached permission set tree from user instance if set or an analyzed one if set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_permission_set_tree_cached(user):\n    if hasattr(user, CACHED_PSET_PROPERTY_KEY):\n        return\n    try:\n        setattr(\n            user, CACHED_PSET_PROPERTY_KEY, _get_permission_set_tree(user))\n    except ObjectDoesNotExist:  # No permission set\n        pass", "response": "Helper to cache permission set tree on user instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear_user_policies(user):\n    if user is None:\n        try:\n            pset = PermissionSet.objects.get(anonymous_user=True)\n            pset.anonymous_user = False\n            pset.save()\n        except ObjectDoesNotExist:\n            return\n    else:\n        pset = user.permissionset.first()\n    if pset:\n        pset.refresh()\n        if user is not None:\n            pset.users.remove(user)\n        if pset.users.count() == 0 and not pset.anonymous_user:\n            pset.delete()", "response": "Removes all policies assigned to a user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning a sequence of policies to a user.", "response": "def assign_user_policies(user, *policies_roles):\n    \"\"\"Assign a sequence of policies to a user (or the anonymous user is\n    ``user`` is ``None``).  (Also installed as ``assign_policies``\n    method on ``User`` model.\n\n    \"\"\"\n    clear_user_policies(user)\n    pset = PermissionSet.objects.by_policies_and_roles(policies_roles)\n    pset.refresh()\n    if user is None:\n        pset.anonymous_user = True\n    else:\n        pset.users.add(user)\n    pset.save()\n    cache.set(user_cache_key(user), None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a sequence of policies assigned to a user.", "response": "def user_assigned_policies(user):\n    \"\"\"Return sequence of policies assigned to a user (or the anonymous\n    user is ``user`` is ``None``).  (Also installed as\n    ``assigned_policies`` method on ``User`` model.\n\n    \"\"\"\n    key = user_cache_key(user)\n    cached = cache.get(key)\n    if cached is not None:\n        return cached\n\n    if user is None:\n        pset = PermissionSet.objects.filter(anonymous_user=True).first()\n    else:\n        pset = user.permissionset.first()\n    if pset is None:\n        return []\n\n    res = []\n    skip_role_policies = False\n    skip_role = None\n    skip_role_variables = None\n    for pi in pset.policyinstance_set.select_related('policy', 'role'):\n        if skip_role_policies:\n            if pi.role == skip_role and pi.variables == skip_role_variables:\n                continue\n            else:\n                skip_role_policies = False\n        if pi.role:\n            res.append(pi.role)\n            skip_role = pi.role\n            skip_role_variables = pi.variables\n            skip_role_policies = True\n        else:\n            if pi.variables != '{}':\n                res.append((pi.policy, json.loads(pi.variables)))\n            else:\n                res.append(pi.policy)\n    cache.set(key, res)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parsed(self):\n        if not self._parsed:\n\n            self._parsed = json.loads(self.content)\n\n        return self._parsed", "response": "Get the JSON dictionary object which represents the content."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cleanup_logger(self):\n        self.log_handler.close()\n        self.log.removeHandler(self.log_handler)", "response": "Clean up the logger to close out file handles."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the fedora - atomic. git repositories for a given release.", "response": "def update_configs(self, release):\n        \"\"\" Update the fedora-atomic.git repositories for a given release \"\"\"\n        git_repo = release['git_repo']\n        git_cache = release['git_cache']\n        if not os.path.isdir(git_cache):\n            self.call(['git', 'clone', '--mirror', git_repo, git_cache])\n        else:\n            self.call(['git', 'fetch', '--all', '--prune'], cwd=git_cache)\n        git_dir = release['git_dir'] = os.path.join(release['tmp_dir'],\n                                                    os.path.basename(git_repo))\n        self.call(['git', 'clone', '-b', release['git_branch'],\n                   git_cache, git_dir])\n\n        if release['delete_repo_files']:\n            for repo_file in glob.glob(os.path.join(git_dir, '*.repo')):\n                self.log.info('Deleting %s' % repo_file)\n                os.unlink(repo_file)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a mock command in the chroot for a given release", "response": "def mock_cmd(self, release, *cmd, **kwargs):\n        \"\"\"Run a mock command in the chroot for a given release\"\"\"\n        fmt = '{mock_cmd}'\n        if kwargs.get('new_chroot') is True:\n            fmt +=' --new-chroot'\n        fmt += ' --configdir={mock_dir}'\n        return self.call(fmt.format(**release).split()\n                         + list(cmd))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes our mock chroot", "response": "def init_mock(self, release):\n        \"\"\"Initialize/update our mock chroot\"\"\"\n        root = '/var/lib/mock/%s' % release['mock']\n        if not os.path.isdir(root):\n            self.mock_cmd(release, '--init')\n            self.log.info('mock chroot initialized')\n        else:\n            if release.get('mock_clean'):\n                self.mock_cmd(release, '--clean')\n                self.mock_cmd(release, '--init')\n                self.log.info('mock chroot cleaned & initialized')\n            else:\n                self.mock_cmd(release, '--update')\n                self.log.info('mock chroot updated')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a commend in the mock container for a release", "response": "def mock_chroot(self, release, cmd, **kwargs):\n        \"\"\"Run a commend in the mock container for a release\"\"\"\n        return self.mock_cmd(release, '--chroot', cmd, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the OSTree for a release", "response": "def ostree_init(self, release):\n        \"\"\"Initialize the OSTree for a release\"\"\"\n        out = release['output_dir'].rstrip('/')\n        base = os.path.dirname(out)\n        if not os.path.isdir(base):\n            self.log.info('Creating %s', base)\n            os.makedirs(base, mode=0755)\n        if not os.path.isdir(out):\n            self.mock_chroot(release, release['ostree_init'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomposing the OSTree in the mock container", "response": "def ostree_compose(self, release):\n        \"\"\"Compose the OSTree in the mock container\"\"\"\n        start = datetime.utcnow()\n        treefile = os.path.join(release['git_dir'], 'treefile.json')\n        cmd = release['ostree_compose'] % treefile\n        with file(treefile, 'w') as tree:\n            json.dump(release['treefile'], tree)\n        # Only use new_chroot for the invocation, as --clean and --new-chroot are buggy together right now\n        out, err, rcode = self.mock_chroot(release, cmd, new_chroot=True)\n        ref = None\n        commitid = None\n        for line in out.split('\\n'):\n            if ' => ' in line:\n                # This line is the: ref => commitid line\n                line = line.replace('\\n', '')\n                ref, _, commitid = line.partition(' => ')\n        self.log.info('rpm-ostree compose complete (%s), ref %s, commitid %s',\n                      datetime.utcnow() - start, ref, commitid)\n        return ref, commitid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_ostree_summary(self, release):\n        self.log.info('Updating the ostree summary for %s', release['name'])\n        self.mock_chroot(release, release['ostree_summary'])\n        return os.path.join(release['output_dir'], 'summary')", "response": "Update the ostree summary file and return a path to it"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_in(self, release):\n        tree = release['canonical_dir']\n        if os.path.exists(tree) and release.get('rsync_in_objs'):\n            out = release['output_dir']\n            if not os.path.isdir(out):\n                self.log.info('Creating %s', out)\n                os.makedirs(out)\n            self.call(release['rsync_in_objs'])\n            self.call(release['rsync_in_rest'])", "response": "Sync the canonical repo to our local working directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call(self, cmd, **kwargs):\n        if isinstance(cmd, basestring):\n            cmd = cmd.split()\n        self.log.info('Running %s', cmd)\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                             stderr=subprocess.PIPE, **kwargs)\n        out, err = p.communicate()\n        if out:\n            self.log.info(out)\n        if err:\n            if p.returncode == 0:\n                self.log.info(err)\n            else:\n                self.log.error(err)\n        if p.returncode != 0:\n            self.log.error('returncode = %d' % p.returncode)\n            raise Exception\n        return out, err, p.returncode", "response": "A simple subprocess wrapper that returns stdout stderr and return code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self, other):\n        newstart = min(self._start, other.start)\n        newend = max(self._end, other.end)\n        return Range(newstart, newend)", "response": "Merge this range with another."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the interval of overlap between this range and another.", "response": "def intersect(self, other):\n        \"\"\"\n        Determine the interval of overlap between this range and another.\n\n        :returns: a new Range object representing the overlapping interval,\n                  or `None` if the ranges do not overlap.\n        \"\"\"\n        if not self.overlap(other):\n            return None\n\n        newstart = max(self._start, other.start)\n        newend = min(self._end, other.end)\n        return Range(newstart, newend)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine whether this range overlaps with another.", "response": "def overlap(self, other):\n        \"\"\"Determine whether this range overlaps with another.\"\"\"\n        if self._start < other.end and self._end > other.start:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining whether this range contains another.", "response": "def contains(self, other):\n        \"\"\"Determine whether this range contains another.\"\"\"\n        return self._start <= other.start and self._end >= other.end"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, offset):\n        assert self._start + offset > 0, \\\n            ('offset {} invalid; resulting range [{}, {}) is '\n             'undefined'.format(offset, self._start+offset, self._end+offset))\n        self._start += offset\n        self._end += offset", "response": "Shift this range by the specified offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef behave(cmdline, cwd=\".\", **kwargs):\n    assert isinstance(cmdline, six.string_types)\n    return run(\"behave \" + cmdline, cwd=cwd, **kwargs)", "response": "Run behave as subprocess command and return process instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(cls, command, cwd=\".\", **kwargs):\n        assert isinstance(command, six.string_types)\n        command_result = CommandResult()\n        command_result.command = command\n        use_shell = cls.USE_SHELL\n        if \"shell\" in kwargs:\n            use_shell = kwargs.pop(\"shell\")\n\n        # -- BUILD COMMAND ARGS:\n        if six.PY2 and isinstance(command, six.text_type):\n            # -- PREPARE-FOR: shlex.split()\n            # In PY2, shlex.split() requires bytes string (non-unicode).\n            # In PY3, shlex.split() accepts unicode string.\n            command = codecs.encode(command, \"utf-8\")\n        cmdargs = shlex.split(command)\n\n        # -- TRANSFORM COMMAND (optional)\n        command0 = cmdargs[0]\n        real_command = cls.COMMAND_MAP.get(command0, None)\n        if real_command:\n            cmdargs0 = real_command.split()\n            cmdargs = cmdargs0 + cmdargs[1:]\n        preprocessors = cls.PREPROCESSOR_MAP.get(command0)\n        if preprocessors:\n            cmdargs = cls.preprocess_command(preprocessors, cmdargs, command, cwd)\n\n\n        # -- RUN COMMAND:\n        try:\n            process = subprocess.Popen(cmdargs,\n                            stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE,\n                            universal_newlines=True,\n                            shell=use_shell,\n                            cwd=cwd, **kwargs)\n            out, err = process.communicate()\n            if six.PY2: # py3: we get unicode strings, py2 not\n                default_encoding = 'UTF-8'\n                out = six.text_type(out, process.stdout.encoding or default_encoding)\n                err = six.text_type(err, process.stderr.encoding or default_encoding)\n            process.poll()\n            assert process.returncode is not None\n            command_result.stdout = out\n            command_result.stderr = err\n            command_result.returncode = process.returncode\n            if cls.DEBUG:\n                print(\"shell.cwd={0}\".format(kwargs.get(\"cwd\", None)))\n                print(\"shell.command: {0}\".format(\" \".join(cmdargs)))\n                print(\"shell.command.output:\\n{0};\".format(command_result.output))\n        except OSError as e:\n            command_result.stderr = u\"OSError: %s\" % e\n            command_result.returncode = e.errno\n            assert e.errno != 0\n\n        postprocessors = cls.POSTPROCESSOR_MAP.get(command0)\n        if postprocessors:\n            command_result = cls.postprocess_command(postprocessors, command_result)\n        return command_result", "response": "Runs a command and returns a CommandResult instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the name of the template that should be used for this field.", "response": "def get_field_template(self, bound_field, template_name=None):\n        \"\"\"\n        Uses a special field template for widget with multiple inputs. It only\n        applies if no other template than the default one has been defined.\n        \"\"\"\n        template_name = super().get_field_template(bound_field, template_name)\n\n        if (template_name == self.field_template and\n                isinstance(bound_field.field.widget, (\n                    forms.RadioSelect, forms.CheckboxSelectMultiple))):\n            return 'tapeforms/fields/foundation_fieldset.html'\n\n        return template_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint PDA state attributes", "response": "def printer(self):\n        \"\"\"Prints PDA state attributes\"\"\"\n        print \" ID \" + repr(self.id)\n        if self.type == 0:\n            print \" Tag: - \"\n            print \" Start State - \"\n        elif self.type == 1:\n            print \" Push \" + repr(self.sym)\n        elif self.type == 2:\n            print \" Pop State \" + repr(self.sym)\n        elif self.type == 3:\n            print \" Read State \" + repr(self.sym)\n        elif self.type == 4:\n            print \" Stop State \" + repr(self.sym)\n        for j in self.trans:\n            if len(self.trans[j]) > 1 or (len(self.trans[j]) == 1):\n                for symbol in self.trans[j]:\n                    print \" On Symbol \" + repr(symbol) + \" Transition To State \" + repr(j)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint PDA states and their attributes", "response": "def printer(self):\n        \"\"\"Prints PDA states and their attributes\"\"\"\n        i = 0\n        while i < self.n + 1:\n            print \"--------- State No --------\" + repr(i)\n            self.s[i].printer()\n            i = i + 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconsume an input string and validates if it is accepted. Returns True if the input is valid False otherwise.", "response": "def consume_input(self, mystr, stack=[], state=1, curchar=0, depth=0):\n        \"\"\"\n        Consumes an input and validates if it is accepted\n        Args:\n            mystr (str): the input string to be consumes\n            stack (list): the stack of symbols\n            state (int): the current state of the PDA\n            curchar (int): the index of the consumed character\n            depth (int): the depth of the function call in the stack\n        Returns:\n            bool: A value indicating the correct or erroneous execution\n        \"\"\"\n        mystrsplit = mystr.split(' ')\n        if self.s[state].type == 1:\n            stack.append(self.s[state].sym)\n            if len(self.s[state].trans) > 0:\n                state = self.s[state].trans[0]\n                if self.parse(\n                        mystr,\n                        stack=stack,\n                        state=state,\n                        curchar=curchar,\n                        depth=depth + 1) == 1:\n                    return True\n            return False\n        if self.s[state].type == 2:\n            if len(stack) == 0:\n                return False\n            sym = stack.pop()\n            for key in self.s[state].trans:\n                if sym in self.s[state].trans[key]:\n                    if self.parse(\n                            mystr,\n                            stack=stack,\n                            state=key,\n                            curchar=curchar,\n                            depth=depth + 1) == 1:\n                        return True\n            return False\n        if self.s[state].type == 3:\n            for key in self.s[state].trans:\n                if mystrsplit[curchar] in self.s[state].trans[key]:\n                    # print 'found '\n                    if curchar + 1 == len(mystrsplit) \\\n                            and 'closing' in self.s[key].trans:\n                        return True\n                    elif curchar + 1 == len(mystrsplit):\n                        return False\n\n                    # print 'lets try as next state the state ' + repr(key)\n                    if self.parse(\n                            mystr,\n                            stack=stack,\n                            state=key,\n                            curchar=curchar + 1,\n                            depth=depth + 1) == 1:\n                        return True\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _CreateDatabase(self):\n    goodlogging.Log.Info(\"DB\", \"Initialising new database\", verbosity=self.logVerbosity)\n\n    with sqlite3.connect(self._dbPath) as db:\n      # Configuration tables\n      db.execute(\"CREATE TABLE Config (\"\n                  \"Name TEXT UNIQUE NOT NULL, \"\n                  \"Value TEXT)\")\n\n      db.execute(\"CREATE TABLE IgnoredDir (\"\n                  \"DirName TEXT UNIQUE NOT NULL)\")\n\n      db.execute(\"CREATE TABLE SupportedFormat (\"\n                  \"FileFormat TEXT UNIQUE NOT NULL)\")\n\n      # Look-up tables\n      db.execute(\"CREATE TABLE TVLibrary (\"\n                  \"ShowID INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, \"\n                  \"ShowName TEXT UNIQUE NOT NULL, \"\n                  \"ShowDir TEXT UNIQUE)\")\n\n      db.execute(\"CREATE TABLE FileName (\"\n                  \"FileName TEXT UNIQUE NOT NULL, \"\n                  \"ShowID INTEGER, \"\n                  \"FOREIGN KEY (ShowID) REFERENCES ShowName(ShowID))\")\n\n      db.execute(\"CREATE TABLE SeasonDir (\"\n                  \"ShowID INTEGER, \"\n                  \"Season INTEGER NOT NULL, \"\n                  \"SeasonDir TEXT NOT NULL, \"\n                  \"FOREIGN KEY (ShowID) REFERENCES ShowName(ShowID),\"\n                  \"CONSTRAINT SeasonDirPK PRIMARY KEY (ShowID,Season))\")\n\n      db.commit()\n\n    goodlogging.Log.Info(\"DB\", \"Database initialisation complete\", verbosity=self.logVerbosity)", "response": "Create all tables in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ActionDatabase(self, cmd, args = None, commit = True, error = True):\n    goodlogging.Log.Info(\"DB\", \"Database Command: {0} {1}\".format(cmd, args), verbosity=self.logVerbosity)\n    with sqlite3.connect(self._dbPath) as db:\n      try:\n        if args is None:\n          result = db.execute(cmd)\n        else:\n          result = db.execute(cmd, args)\n      except sqlite3.OperationalError:\n        if error is True:\n          raise\n        return None\n      else:\n        if commit is True:\n          db.commit()\n        return result.fetchall()", "response": "Executes a SQL command on the database and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete all rows from given table without dropping table.", "response": "def _PurgeTable(self, tableName):\n    \"\"\"\n    Deletes all rows from given table without dropping table.\n\n    Parameters\n    ----------\n      tableName : string\n        Name of table.\n    \"\"\"\n    goodlogging.Log.Info(\"DB\", \"Deleting all entries from table {0}\".format(tableName), verbosity=self.logVerbosity)\n    self._ActionDatabase(\"DELETE FROM {0}\".format(tableName))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the value of the given field in the Config table and returns corresponding value.", "response": "def GetConfigValue(self, fieldName):\n    \"\"\"\n    Match given field name in Config table and return corresponding value.\n\n    Parameters\n    ----------\n      fieldName : string\n        String matching Name column in Config table.\n\n    Returns\n    ----------\n      string or None\n        If a match is found the corresponding entry in the Value column of the\n        database table is returned, otherwise None is returned (or if multiple\n        matches are found a fatal error is raised).\n    \"\"\"\n    result = self._ActionDatabase(\"SELECT Value FROM Config WHERE Name=?\", (fieldName, ))\n\n    if result is None:\n      return None\n    elif len(result) == 0:\n      return None\n    elif len(result) == 1:\n      goodlogging.Log.Info(\"DB\", \"Found database match in config table {0}={1}\".format(fieldName, result[0][0]), verbosity=self.logVerbosity)\n      return result[0][0]\n    elif len(result) > 1:\n      goodlogging.Log.Fatal(\"DB\", \"Database corrupted - multiple matches found in config table {0}={1}\".format(fieldName, result))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetConfigValue(self, fieldName, value):\n    currentConfigValue = self.GetConfigValue(fieldName)\n\n    if currentConfigValue is None:\n      goodlogging.Log.Info(\"DB\", \"Adding {0}={1} to database config table\".format(fieldName, value), verbosity=self.logVerbosity)\n      self._ActionDatabase(\"INSERT INTO Config VALUES (?,?)\", (fieldName, value))\n    else:\n      goodlogging.Log.Info(\"DB\", \"Updating {0} in database config table from {1} to {2}\".format(fieldName, currentConfigValue, value), verbosity=self.logVerbosity)\n      self._ActionDatabase(\"UPDATE Config SET Value=? WHERE Name=?\", (value, fieldName))", "response": "Set the value of a field in the Config table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _AddToSingleColumnTable(self, tableName, columnHeading, newValue):\n    match = None\n    currentTable = self._GetFromSingleColumnTable(tableName)\n\n    if currentTable is not None:\n      for currentValue in currentTable:\n        if currentValue == newValue:\n          match = True\n\n    if match is None:\n      goodlogging.Log.Info(\"DB\", \"Adding {0} to {1} table\".format(newValue, tableName), verbosity=self.logVerbosity)\n      self._ActionDatabase(\"INSERT INTO {0} VALUES (?)\".format(tableName), (newValue, ))\n    else:\n      goodlogging.Log.Info(\"DB\", \"{0} already exists in {1} table\".format(newValue, tableName), verbosity=self.logVerbosity)\n\n  ############################################################################\n  # _GetFromSingleColumnTable\n  ############################################################################\n    \"\"\"\n    Get all entries from a table containing a single column.\n\n    Parameters\n    ----------\n      tableName : string\n        Name of table to add entry to.\n\n    Returns\n    ----------\n      list or None\n        If either no table or no rows are found this returns None, otherwise a\n        list of all table entries is returned.\n    \"\"\"", "response": "Adds an entry to a table containing a single column."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddShowToTVLibrary(self, showName):\n    goodlogging.Log.Info(\"DB\", \"Adding {0} to TV library\".format(showName), verbosity=self.logVerbosity)\n\n    currentShowValues = self.SearchTVLibrary(showName = showName)\n\n    if currentShowValues is None:\n      self._ActionDatabase(\"INSERT INTO TVLibrary (ShowName) VALUES (?)\", (showName, ))\n      showID = self._ActionDatabase(\"SELECT (ShowID) FROM TVLibrary WHERE ShowName=?\", (showName, ))[0][0]\n      return showID\n    else:\n      goodlogging.Log.Fatal(\"DB\", \"An entry for {0} already exists in the TV library\".format(showName))", "response": "Add a show to the TVLibrary table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate show directory entry for given show id in TVLibrary table.", "response": "def UpdateShowDirInTVLibrary(self, showID, showDir):\n    \"\"\"\n    Update show directory entry for given show id in TVLibrary table.\n\n    Parameters\n    ----------\n      showID : int\n        Show id value.\n\n      showDir : string\n        Show directory name.\n    \"\"\"\n    goodlogging.Log.Info(\"DB\", \"Updating TV library for ShowID={0}: ShowDir={1}\".format(showID, showDir))\n    self._ActionDatabase(\"UPDATE TVLibrary SET ShowDir=? WHERE ShowID=?\", (showDir, showID))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches TVLibrary table. If none of the optonal arguments are given it looks up all entries of the table, otherwise it will look up entries which match the given arguments. Note that it only looks up based on one argument - if show directory is given this will be used, otherwise show id will be used if it is given, otherwise show name will be used. Parameters ---------- showName : string [optional : default = None] Show name. showID : int [optional : default = None] Show id value. showDir : string [optional : default = None] Show directory name. Returns ---------- list or None If no result is found this returns None otherwise it will return a the result of the SQL query as a list. In the case that the result is expected to be unique and multiple entries are return a fatal error will be raised.", "response": "def SearchTVLibrary(self, showName = None, showID = None, showDir = None):\n    \"\"\"\n    Search TVLibrary table.\n\n    If none of the optonal arguments are given it looks up all entries of the\n    table, otherwise it will look up entries which match the given arguments.\n\n    Note that it only looks up based on one argument - if show directory is\n    given this will be used, otherwise show id will be used if it is given,\n    otherwise show name will be used.\n\n    Parameters\n    ----------\n      showName : string [optional : default = None]\n        Show name.\n\n      showID : int [optional : default = None]\n        Show id value.\n\n      showDir : string [optional : default = None]\n        Show directory name.\n\n    Returns\n    ----------\n      list or None\n        If no result is found this returns None otherwise it will return a the\n        result of the SQL query as a list. In the case that the result is expected\n        to be unique and multiple entries are return a fatal error will be raised.\n    \"\"\"\n    unique = True\n    if showName is None and showID is None and showDir is None:\n      goodlogging.Log.Info(\"DB\", \"Looking up all items in TV library\", verbosity=self.logVerbosity)\n      queryString = \"SELECT * FROM TVLibrary\"\n      queryTuple = None\n      unique = False\n    elif showDir is not None:\n      goodlogging.Log.Info(\"DB\", \"Looking up from TV library where ShowDir is {0}\".format(showDir), verbosity=self.logVerbosity)\n      queryString = \"SELECT * FROM TVLibrary WHERE ShowDir=?\"\n      queryTuple = (showDir, )\n    elif showID is not None:\n      goodlogging.Log.Info(\"DB\", \"Looking up from TV library where ShowID is {0}\".format(showID), verbosity=self.logVerbosity)\n      queryString = \"SELECT * FROM TVLibrary WHERE ShowID=?\"\n      queryTuple = (showID, )\n    elif showName is not None:\n      goodlogging.Log.Info(\"DB\", \"Looking up from TV library where ShowName is {0}\".format(showName), verbosity=self.logVerbosity)\n      queryString = \"SELECT * FROM TVLibrary WHERE ShowName=?\"\n      queryTuple = (showName, )\n\n    result = self._ActionDatabase(queryString, queryTuple, error = False)\n\n    if result is None:\n      return None\n    elif len(result) == 0:\n      return None\n    elif len(result) == 1:\n      goodlogging.Log.Info(\"DB\", \"Found match in TVLibrary: {0}\".format(result), verbosity=self.logVerbosity)\n      return result\n    elif len(result) > 1:\n      if unique is True:\n        goodlogging.Log.Fatal(\"DB\", \"Database corrupted - multiple matches found in TV Library: {0}\".format(result))\n      else:\n        goodlogging.Log.Info(\"DB\", \"Found multiple matches in TVLibrary: {0}\".format(result), verbosity=self.logVerbosity)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch FileName table. Find the show id for a given file name. Parameters ---------- fileName : string File name to look up in table. Returns ---------- int or None If a match is found in the database table the show id for this entry is returned, otherwise this returns None.", "response": "def SearchFileNameTable(self, fileName):\n    \"\"\"\n    Search FileName table.\n\n    Find the show id for a given file name.\n\n    Parameters\n    ----------\n      fileName : string\n        File name to look up in table.\n\n    Returns\n    ----------\n      int or None\n        If a match is found in the database table the show id for this\n        entry is returned, otherwise this returns None.\n    \"\"\"\n    goodlogging.Log.Info(\"DB\", \"Looking up filename string '{0}' in database\".format(fileName), verbosity=self.logVerbosity)\n\n    queryString = \"SELECT ShowID FROM FileName WHERE FileName=?\"\n    queryTuple = (fileName, )\n\n    result = self._ActionDatabase(queryString, queryTuple, error = False)\n\n    if result is None:\n      goodlogging.Log.Info(\"DB\", \"No match found in database for '{0}'\".format(fileName), verbosity=self.logVerbosity)\n      return None\n    elif len(result) == 0:\n      return None\n    elif len(result) == 1:\n      goodlogging.Log.Info(\"DB\", \"Found file name match: {0}\".format(result), verbosity=self.logVerbosity)\n      return result[0][0]\n    elif len(result) > 1:\n      goodlogging.Log.Fatal(\"DB\", \"Database corrupted - multiple matches found in database table for: {0}\".format(result))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddToFileNameTable(self, fileName, showID):\n    goodlogging.Log.Info(\"DB\", \"Adding filename string match '{0}'={1} to database\".format(fileName, showID), verbosity=self.logVerbosity)\n\n    currentValues = self.SearchFileNameTable(fileName)\n\n    if currentValues is None:\n      self._ActionDatabase(\"INSERT INTO FileName (FileName, ShowID) VALUES (?,?)\", (fileName, showID))\n    else:\n      goodlogging.Log.Fatal(\"DB\", \"An entry for '{0}' already exists in the FileName table\".format(fileName))", "response": "Add entry to FileName table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching SeasonDir table. Find the season directory for a given show id and season combination. Parameters ---------- showID : int Show id for given show. seasonNum : int Season number. Returns ---------- string or None If no match is found this returns None, if a single match is found then the season directory name value is returned. If multiple matches are found a fatal error is raised.", "response": "def SearchSeasonDirTable(self, showID, seasonNum):\n    \"\"\"\n    Search SeasonDir table.\n\n    Find the season directory for a given show id and season combination.\n\n    Parameters\n    ----------\n      showID : int\n        Show id for given show.\n\n      seasonNum : int\n        Season number.\n\n    Returns\n    ----------\n      string or None\n        If no match is found this returns None, if a single match is found\n        then the season directory name value is returned. If multiple matches\n        are found a fatal error is raised.\n    \"\"\"\n    goodlogging.Log.Info(\"DB\", \"Looking up directory for ShowID={0} Season={1} in database\".format(showID, seasonNum), verbosity=self.logVerbosity)\n\n    queryString = \"SELECT SeasonDir FROM SeasonDir WHERE ShowID=? AND Season=?\"\n    queryTuple = (showID, seasonNum)\n\n    result = self._ActionDatabase(queryString, queryTuple, error = False)\n\n    if result is None:\n      goodlogging.Log.Info(\"DB\", \"No match found in database\", verbosity=self.logVerbosity)\n      return None\n    elif len(result) == 0:\n      return None\n    elif len(result) == 1:\n      goodlogging.Log.Info(\"DB\", \"Found database match: {0}\".format(result), verbosity=self.logVerbosity)\n      return result[0][0]\n    elif len(result) > 1:\n      goodlogging.Log.Fatal(\"DB\", \"Database corrupted - multiple matches found in database table for: {0}\".format(result))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a entry to SeasonDir table.", "response": "def AddSeasonDirTable(self, showID, seasonNum, seasonDir):\n    \"\"\"\n    Add entry to SeasonDir table. If a different entry for season directory\n    is found for the given show id and season number combination this raises\n    a fatal error.\n\n    Parameters\n    ----------\n      showID : int\n        Show id.\n\n      seasonNum : int\n        Season number.\n\n      seasonDir : string\n        Season directory name.\n    \"\"\"\n    goodlogging.Log.Info(\"DB\", \"Adding season directory ({0}) to database for ShowID={1}, Season={2}\".format(seasonDir, showID, seasonNum), verbosity=self.logVerbosity)\n\n    currentValue = self.SearchSeasonDirTable(showID, seasonNum)\n\n    if currentValue is None:\n      self._ActionDatabase(\"INSERT INTO SeasonDir (ShowID, Season, SeasonDir) VALUES (?,?,?)\", (showID, seasonNum, seasonDir))\n    else:\n      if currentValue == seasonDir:\n        goodlogging.Log.Info(\"DB\", \"A matching entry already exists in the SeasonDir table\", verbosity=self.logVerbosity)\n      else:\n        goodlogging.Log.Fatal(\"DB\", \"A different entry already exists in the SeasonDir table\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _PrintDatabaseTable(self, tableName, rowSelect = None):\n    goodlogging.Log.Info(\"DB\", \"{0}\".format(tableName))\n    goodlogging.Log.IncreaseIndent()\n    tableInfo = self._ActionDatabase(\"PRAGMA table_info({0})\".format(tableName))\n\n\n    dbQuery = \"SELECT * FROM {0}\".format(tableName)\n    dbQueryParams = []\n\n    if rowSelect is not None:\n      dbQuery = dbQuery + \" WHERE \" + ' AND '.join(['{0}=?'.format(i) for i, j in rowSelect])\n      dbQueryParams = [j for i, j in rowSelect]\n\n    tableData = self._ActionDatabase(dbQuery, dbQueryParams)\n    columnCount = len(tableInfo)\n\n    columnWidths = [0]*columnCount\n\n    columnHeadings = []\n    for count, column in enumerate(tableInfo):\n      columnHeadings.append(column[1])\n      columnWidths[count] = len(column[1])\n\n    for row in tableData:\n      for count, column in enumerate(row):\n        if len(str(column)) > columnWidths[count]:\n          columnWidths[count] = len(column)\n\n    printStr = \"|\"\n    for count, column in enumerate(columnWidths):\n      printStr = printStr + \" {{0[{0}]:{1}}} |\".format(count, columnWidths[count])\n\n    goodlogging.Log.Info(\"DB\", printStr.format(columnHeadings))\n    goodlogging.Log.Info(\"DB\", \"-\"*(sum(columnWidths)+3*len(columnWidths)+1))\n\n    for row in tableData:\n      noneReplacedRow = ['-' if i is None else i for i in row]\n      goodlogging.Log.Info(\"DB\", printStr.format(noneReplacedRow))\n\n    goodlogging.Log.DecreaseIndent()\n    goodlogging.Log.NewLine()\n\n    return len(tableData)", "response": "Print the contents of a database table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint all tables in the database.", "response": "def PrintAllTables(self):\n    \"\"\" Prints contents of every table. \"\"\"\n    goodlogging.Log.Info(\"DB\", \"Database contents:\\n\")\n    for table in self._tableDict.keys():\n      self._PrintDatabaseTable(table)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _UpdateDatabaseFromResponse(self, response, mode):\n    # Get tableName from user input (form TABLENAME COL1=VAL1 COL2=VAL2 etc)\n    try:\n      tableName, tableColumns = response.split(' ', 1)\n    except ValueError:\n      goodlogging.Log.Info(\"DB\", \"Database update failed - failed to extract table name from response\")\n      return None\n\n    # Check user input against known table list\n    if tableName not in self._tableDict.keys():\n      goodlogging.Log.Info(\"DB\", \"Database update failed - unkown table name: {0}\".format(tableName))\n      return None\n\n    # Build re pattern to extract column from user input (form TABLENAME COL1=VAL1 COL2=VAL2 etc)\n    rowSelect = []\n    for column in self._tableDict[tableName]:\n      colPatternList = ['(?:{0})'.format(i) for i in self._tableDict[tableName] if i != column]\n      colPatternList.append('(?:$)')\n      colPatternMatch = '|'.join(colPatternList)\n      matchPattern = '{0}.*?{1}=(.+?)\\s*(?:{2})'.format(tableName, column, colPatternMatch)\n\n      match = re.findall(matchPattern, response)\n\n      # Match should be in form [(VAL1, VAL2, VAL3, etc.)]\n      if len(match) == 1:\n        rowSelect.append((column, match[0]))\n      elif len(match) > 1:\n        goodlogging.Log.Info('DB', 'Database update failed - multiple matches found for table {0} column {1}'.format(tableName, column))\n        return None\n\n    if len(rowSelect) == 0:\n      goodlogging.Log.Info('DB', 'Database update failed - no row selection critera found in response')\n      return None\n\n    # Print selected rows\n    rowCount = self._PrintDatabaseTable(tableName, rowSelect)\n\n    # Do DELETE flow\n    if mode.upper() == 'DEL':\n      if rowCount == 0:\n        goodlogging.Log.Info(\"DB\", \"Database update failed - no rows found for given search critera: {0}\".format(response))\n        return None\n\n      deleteConfirmation = goodlogging.Log.Input(\"DB\", \"***WARNING*** DELETE THESE ROWS FROM {0} TABLE? [y/n]: \".format(tableName))\n      deleteConfirmation = util.ValidUserResponse(deleteConfirmation, ('y', 'n'))\n\n      if deleteConfirmation.lower() == 'n':\n        goodlogging.Log.Info(\"DB\", \"Database table row delete cancelled\")\n        return None\n\n      # Build delete database query (form DELETE FROM TableName WHERE COL1=?, COL2=?)\n      dbQuery = \"DELETE FROM {0}\".format(tableName) \\\n                  + \" WHERE \" \\\n                  + ' AND '.join(['{0}=?'.format(i) for i, j in rowSelect])\n      dbQueryParams = [j for i, j in rowSelect]\n\n      self._ActionDatabase(dbQuery, dbQueryParams)\n\n      goodlogging.Log.Info(\"DB\", \"Deleted {0} row(s) from database table {0}:\".format(rowCount, tableName))\n\n    # Do ADD flow\n    elif mode.upper() == 'ADD':\n      if rowCount != 0:\n        goodlogging.Log.Info(\"DB\", \"Database update failed - a row already exists for the given critera: {0}\".format(response))\n        return None\n\n      # Build insert database query (form INSERT INTO TableName (COL1, COL2) VALUES (?,?))\n      dbQuery = \"INSERT INTO {0} (\".format(tableName) \\\n                  + ', '.join(['{0}'.format(i) for i, j in rowSelect]) \\\n                  + \") VALUES (\" \\\n                  + ', '.join(['?']*len(rowSelect)) \\\n                  + \")\"\n      dbQueryParams = [j for i, j in rowSelect]\n\n      self._ActionDatabase(dbQuery, dbQueryParams)\n\n      goodlogging.Log.Info(\"DB\", \"Added row to database table {0}:\".format(tableName))\n\n    # Print resulting database table\n    self._PrintDatabaseTable(tableName)", "response": "Update the database table given a user input."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ManualUpdateTables(self):\n    goodlogging.Log.Info(\"DB\", \"Starting manual database update:\\n\")\n    updateFinished = False\n\n    # Loop until the user continues program flow or exits\n    while not updateFinished:\n      prompt = \"Enter 'ls' to print the database contents, \" \\\n                     \"'a' to add a table entry, \" \\\n                     \"'d' to delete a single table row, \" \\\n                     \"'p' to select a entire table to purge, \" \\\n                     \"'f' to finish or \" \\\n                     \"'x' to exit: \"\n      response = goodlogging.Log.Input(\"DM\", prompt)\n\n      goodlogging.Log.NewLine()\n      goodlogging.Log.IncreaseIndent()\n\n      # Exit program\n      if response.lower() == 'x':\n        goodlogging.Log.Fatal(\"DB\", \"Program exited by user response\")\n\n      # Finish updating database\n      elif response.lower() == 'f':\n        updateFinished = True\n\n      # Print database tables\n      elif response.lower() == 'ls':\n        self.PrintAllTables()\n\n      # Purge a given table\n      elif response.lower() == 'p':\n        response = goodlogging.Log.Input(\"DM\", \"Enter database table to purge or 'c' to cancel: \")\n\n        # Go back to main update selection\n        if response.lower() == 'c':\n          goodlogging.Log.Info(\"DB\", \"Database table purge cancelled\")\n\n        # Purge table\n        else:\n          if response in self._tableDict.keys():\n            self._PrintDatabaseTable(response)\n\n            deleteConfirmation = goodlogging.Log.Input(\"DB\", \"***WARNING*** DELETE ALL ROWS FROM {0} TABLE? [y/n]: \".format(response))\n            deleteConfirmation = util.ValidUserResponse(deleteConfirmation, ('y', 'n'))\n\n            if deleteConfirmation.lower() == 'n':\n              goodlogging.Log.Info(\"DB\", \"Database table purge cancelled\")\n            else:\n              self._PurgeTable(response)\n              goodlogging.Log.Info(\"DB\", \"{0} database table purged\".format(response))\n          else:\n            goodlogging.Log.Info(\"DB\", \"Unknown table name ({0}) given to purge\".format(response))\n\n      # Add new row to table\n      elif response.lower() == 'a':\n        addFinished = False\n        while not addFinished:\n          prompt = \"Enter new database row (in format TABLE COL1=VAL COL2=VAL etc) \" \\\n                    \"or 'c' to cancel: \"\n          response = goodlogging.Log.Input(\"DM\", prompt)\n\n          # Go back to main update selection\n          if response.lower() == 'c':\n            goodlogging.Log.Info(\"DB\", \"Database table add cancelled\")\n            addFinished = True\n\n          # Add row to table\n          else:\n            self._UpdateDatabaseFromResponse(response, 'ADD')\n\n      # Delete row(s) from table\n      elif response.lower() == 'd':\n        deleteFinished = False\n        while not deleteFinished:\n          prompt = \"Enter database row to delete (in format TABLE COL1=VAL COL2=VAL etc) \" \\\n                    \"or 'c' to cancel: \"\n          response = goodlogging.Log.Input(\"DM\", prompt)\n\n          # Go back to main update selection\n          if response.lower() == 'c':\n            goodlogging.Log.Info(\"DB\", \"Database table row delete cancelled\")\n            deleteFinished = True\n\n          # Delete row(s) from table\n          else:\n            self._UpdateDatabaseFromResponse(response, 'DEL')\n\n      # Unknown user input given\n      else:\n        goodlogging.Log.Info(\"DB\", \"Unknown response\")\n\n      goodlogging.Log.DecreaseIndent()\n      goodlogging.Log.NewLine()\n\n    goodlogging.Log.Info(\"DB\", \"Manual database update complete.\")\n    self.PrintAllTables()", "response": "This function allows the user to manually update the database tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_minidom_tag_value(station, tag_name):\n    tag = station.getElementsByTagName(tag_name)[0].firstChild\n    if tag:\n        return tag.nodeValue\n\n    return None", "response": "get a value from a tag"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse(data, obj_name, attr_map):\n    parsed_xml = minidom.parseString(data)\n    parsed_objects = []\n    for obj in parsed_xml.getElementsByTagName(obj_name):\n        parsed_obj = {}\n        for (py_name, xml_name) in attr_map.items():\n            parsed_obj[py_name] = _get_minidom_tag_value(obj, xml_name)\n        parsed_objects.append(parsed_obj)\n    return parsed_objects", "response": "parse xml data into a python map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_stations(self, station_type=None):\n        params = None\n        if station_type and station_type in STATION_TYPE_TO_CODE_DICT:\n            url = self.api_base_url + 'getAllStationsXML_WithStationType'\n            params = {\n                'stationType': STATION_TYPE_TO_CODE_DICT[station_type]\n            }\n        else:\n            url = self.api_base_url + 'getAllStationsXML'\n\n        response = requests.get(\n            url, params=params, timeout=10)\n\n        if response.status_code != 200:\n            return []\n\n        return self._parse_station_list(response.content)", "response": "Returns information of all stations."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all trains that are due to start in the next 10 minutes", "response": "def get_all_current_trains(self, train_type=None, direction=None):\n        \"\"\"Returns all trains that are due to start in the next 10 minutes\n        @param train_type: ['mainline', 'suburban', 'dart']\n        \"\"\"\n        params = None\n        if train_type:\n            url = self.api_base_url + 'getCurrentTrainsXML_WithTrainType'\n            params = {\n                'TrainType': STATION_TYPE_TO_CODE_DICT[train_type]\n            }\n        else:\n            url = self.api_base_url + 'getCurrentTrainsXML'\n\n        response = requests.get(\n            url, params=params, timeout=10)\n\n        if response.status_code != 200:\n            return []\n\n        trains = self._parse_all_train_data(response.content)\n\n        if direction is not None:\n            return self._prune_trains(trains, direction=direction)\n\n        return trains"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_station_by_name(self,\n                            station_name,\n                            num_minutes=None,\n                            direction=None,\n                            destination=None,\n                            stops_at=None):\n        \"\"\"Returns all trains due to serve station `station_name`.\n        @param station_code\n        @param num_minutes. Only trains within this time. Between 5 and 90\n        @param direction Filter by direction. Northbound or Southbound\n        @param destination Filter by name of the destination stations\n        @param stops_at Filber by name of one of the stops\n        \"\"\"\n        url = self.api_base_url + 'getStationDataByNameXML'\n        params = {\n            'StationDesc': station_name\n        }\n        if num_minutes:\n            url = url + '_withNumMins'\n            params['NumMins'] = num_minutes\n\n        response = requests.get(\n            url, params=params, timeout=10)\n\n        if response.status_code != 200:\n            return []\n\n        trains = self._parse_station_data(response.content)\n        if direction is not None or destination is not None:\n            return self._prune_trains(trains,\n                                      direction=direction,\n                                      destination=destination,\n                                      stops_at=stops_at)\n\n        return trains", "response": "Returns all trains due to serve station station_name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_train_stops(self, train_code, date=None):\n        if date is None:\n            date = datetime.date.today().strftime(\"%d %B %Y\")\n\n        url = self.api_base_url + 'getTrainMovementsXML'\n        params = {\n            'TrainId': train_code,\n            'TrainDate': date\n        }\n\n        response = requests.get(\n            url, params=params, timeout=10)\n\n        if response.status_code != 200:\n            return []\n\n        return self._parse_train_movement_data(response.content)", "response": "Get details for a train."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_fields(self, **kwargs):\n        for name, value in kwargs.items():\n            field = getattr(self, name)\n            field.send_keys(value)", "response": "Fills the fields referenced by kwargs keys and fill them with the value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a selector for the given page element as a tuple", "response": "def selector(self, fieldname):\n        \"\"\"Gets a selector for the given page element as a tuple\n        (by, selector)\"\"\"\n        finder = self._finders[fieldname]\n        return (finder._by, finder._selector)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authorize_url(client_id=None, redirect_uri=None, state=None, scopes=None, show_dialog=False, http_client=None):\n    params = {\n        'client_id': client_id or os.environ.get('SPOTIFY_CLIENT_ID'),\n        'redirect_uri': redirect_uri or os.environ.get('SPOTIFY_REDIRECT_URI'),\n        'state': state or str(uuid.uuid4()).replace('-', ''),\n        'scope': ' '.join(scopes) if scopes else '',\n        'show_dialog': show_dialog,\n        'response_type': 'code'\n    }\n    query = ['{}={}'.format(k, v) for k, v in params.items()]\n    return '{}?{}'.format('https://accounts.spotify.com/authorize', '&'.join(query))", "response": "Trigger authorization dialog and return the authorize url"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh the access token", "response": "def refresh(self):\n        \"\"\"\n        Refresh the access token\n        \"\"\"\n        data = {\n            'grant_type': 'refresh_token',\n            'refresh_token': self._token.refresh_token\n        }\n\n        response = self.http_client.post(self.URL, data=data, auth=(self.client_id, self.client_secret))\n        response.raise_for_status()\n        self._token = Token.from_json(response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an invariant requiring the value is an instance of cls.", "response": "def instance_of(cls):\n    \"\"\"\n    Create an invariant requiring the value is an instance of ``cls``.\n    \"\"\"\n    def check(value):\n        return (\n            isinstance(value, cls),\n            u\"{value!r} is instance of {actual!s}, required {required!s}\".format(\n                value=value,\n                actual=fullyQualifiedName(type(value)),\n                required=fullyQualifiedName(cls),\n            ),\n        )\n    return check"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef provider_of(iface):\n    def check(value):\n        return (\n            iface.providedBy(value),\n            u\"{value!r} does not provide {interface!s}\".format(\n                value=value,\n                interface=fullyQualifiedName(iface),\n            ),\n        )\n    return check", "response": "Create an invariant requiring the value provides the zope. interface\n    iface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef temp_dir(suffix='', prefix='tmp', parent_dir=None, make_cwd=False):\n    prev_cwd = os.getcwd()\n    parent_dir = parent_dir if parent_dir is None else str(parent_dir)\n    abs_path = tempfile.mkdtemp(suffix, prefix, parent_dir)\n    path = pathlib.Path(abs_path)\n    try:\n        if make_cwd:\n            os.chdir(str(abs_path))\n        yield path.resolve()\n    finally:\n        if make_cwd:\n            os.chdir(prev_cwd)\n        with temporary.util.allow_missing_file():\n            shutil.rmtree(str(abs_path))", "response": "Create a temporary directory and optionally change the current context\n    working directory to it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the specified filepath is writable.", "response": "def _isFileAccessible(filepath):\n    \"\"\"Returns True if the specified filepath is writable.\"\"\"\n    directory = os.path.dirname(filepath)\n    if not os.access(directory, os.W_OK):\n        #Return False if directory does not exist or is not writable\n        return False\n    if os.path.exists(filepath):\n        if not os.access(filepath, os.W_OK):\n            #Return False if file is not writable\n            return False\n        try:\n            openfile = os.open(filepath, os.O_WRONLY)\n            os.close(openfile)\n        except IOError:\n            #Return False if file is locked\n            return False\n    #Return True if file is writtable\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nserialize the objects contained in data to a JSON formated string and writes it to a zipfile.", "response": "def writeJsonZipfile(filelike, data, compress=True, mode='w', name='data'):\n    \"\"\"Serializes the objects contained in data to a JSON formated string and\n    writes it to a zipfile.\n\n    :param filelike: path to a file (str) or a file-like object\n    :param data: object that should be converted to a JSON formated string.\n        Objects and types in data must be supported by the json.JSONEncoder or\n        have the method ``._reprJSON()`` defined.\n    :param compress: bool, True to use zip file compression\n    :param mode: 'w' to truncate and write a new file, or 'a' to append to an\n        existing file\n    :param name: the file name that will be given to the JSON output in the\n        archive\n    \"\"\"\n    zipcomp = zipfile.ZIP_DEFLATED if compress else zipfile.ZIP_STORED\n    with zipfile.ZipFile(filelike, mode, allowZip64=True) as containerFile:\n        containerFile.writestr(name, json.dumps(data, cls=MaspyJsonEncoder),\n                               zipcomp\n                               )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes the binaryItems contained in binaryItemContainer and writes them into a zip archive.", "response": "def writeBinaryItemContainer(filelike, binaryItemContainer, compress=True):\n    \"\"\"Serializes the binaryItems contained in binaryItemContainer and writes\n    them into a zipfile archive.\n\n    Examples of binaryItem classes are :class:`maspy.core.Ci` and\n    :class:`maspy.core.Sai`. A binaryItem class has to define the function\n    ``_reprJSON()`` which returns a JSON formated string representation of the\n    class instance. In addition it has to contain an attribute ``.arrays``, a\n    dictionary which values are ``numpy.array``, that are serialized to bytes\n    and written to the ``binarydata`` file of the zip archive. See\n    :func:`_dumpArrayDictToFile()`\n\n    The JSON formated string representation of the binaryItems, together with\n    the metadata, necessary to restore serialized numpy arrays, is written\n    to the ``metadata`` file of the archive in this form:\n    ``[[serialized binaryItem, [metadata of a numpy array, ...]], ...]``\n\n    Use the method :func:`loadBinaryItemContainer()` to restore a\n    binaryItemContainer from a zipfile.\n\n    :param filelike: path to a file (str) or a file-like object\n    :param binaryItemContainer: a dictionary containing binaryItems\n    :param compress: bool, True to use zip file compression\n    \"\"\"\n    allMetadata = dict()\n    binarydatafile = io.BytesIO()\n    #Note: It would be possible to sort the items here\n    for index, binaryItem in enumerate(viewvalues(binaryItemContainer)):\n        metadataList = _dumpArrayDictToFile(binarydatafile, binaryItem.arrays)\n        allMetadata[index] = [binaryItem._reprJSON(), metadataList]\n\n    #TODO: Is seek here still necessary?\n    binarydatafile.seek(0)\n\n    zipcomp = zipfile.ZIP_DEFLATED if compress else zipfile.ZIP_STORED\n    with zipfile.ZipFile(filelike, 'w', allowZip64=True) as containerFile:\n        containerFile.writestr('metadata',\n                               json.dumps(allMetadata, cls=MaspyJsonEncoder),\n                               zipcomp\n                               )\n        containerFile.writestr('binarydata', binarydatafile.getvalue(), zipcomp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to serialize and write numpy. array contained in a dictionary to a file.", "response": "def _dumpArrayDictToFile(filelike, arrayDict):\n    \"\"\"Function to serialize and write ``numpy.array`` contained in a dictionary\n    to a file. See also :func:`_dumpArrayToFile` and :func:`_dumpNdarrayToFile`.\n\n\n    :param filelike: can be a file or a file-like object that provides the\n        methods ``.write()`` and ``.tell()``.\n    :param arrayDict: a dictionary which values are ``numpy.array``, that are\n        serialized to bytes and written to the filelike.\n\n    :returns: a list of metadata dictionaries\n        a metadata dictionary contains information necessary to restore the\n        ``numpy.arrays`` from the file and the corresponding key from the\n        arrayDict as 'arrayKey'.\n    \"\"\"\n    metadataList = list()\n    for arrayKey in sorted(arrayDict):\n        array = arrayDict[arrayKey]\n        if array.ndim == 1:\n            metadata = _dumpArrayToFile(filelike, array)\n        else:\n            metadata = _dumpNdarrayToFile(filelike, array)\n        metadata['arrayKey'] = arrayKey\n        metadataList.append(metadata)\n    return metadataList"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes a 1 - dimensional numpy. array to bytes and returns a dictionary with metadata necessary to restore the numpy. array from the file.", "response": "def _dumpArrayToFile(filelike, array):\n    \"\"\"Serializes a 1-dimensional ``numpy.array`` to bytes, writes the bytes to\n    the filelike object and returns a dictionary with metadata, necessary to\n    restore the ``numpy.array`` from the file.\n\n    :param filelike: can be a file or a file-like object that provides the\n        methods ``.write()`` and ``.tell()``.\n    :param array: a 1-dimensional ``numpy.array``\n\n    :returns: a metadata dictionary ::\n        {'start': start position in the file, 'end': end position in the file,\n         'size': size of the array, 'dtype': numpy data type of the array\n         }\n    \"\"\"\n    bytedata = array.tobytes('C')\n    start = filelike.tell()\n    end = start + len(bytedata)\n    metadata = {'start': start, 'end': end, 'size': array.size,\n                'dtype': array.dtype.name\n                }\n    filelike.write(bytedata)\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing an N - dimensional numpy. array to bytes and returns a dictionary with metadata necessary to restore the numpy. array from the file.", "response": "def _dumpNdarrayToFile(filelike, ndarray):\n    \"\"\"Serializes an N-dimensional ``numpy.array`` to bytes, writes the bytes to\n    the filelike object and returns a dictionary with metadata, necessary to\n    restore the ``numpy.array`` from the file.\n\n    :param filelike: can be a file or a file-like object that provides the\n        methods ``.write()`` and ``.tell()``.\n    :param ndarray: a N-dimensional ``numpy.array``\n\n    :returns: a metadata dictionary ::\n        {'start': start position in the file, 'end': end position in the file,\n         'size': size of the array, 'dtype': numpy data type of the array,\n         'shape': description of the array shape\n         }\n    \"\"\"\n    bytedata = ndarray.tobytes('C')\n    start = filelike.tell()\n    end = start + len(bytedata)\n    metadata = {'start': start, 'end': end, 'size': ndarray.size,\n                'dtype': ndarray.dtype.name, 'shape': ndarray.shape\n                }\n    filelike.write(bytedata)\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadBinaryItemContainer(zippedfile, jsonHook):\n    binaryItemContainer = dict()\n    with zipfile.ZipFile(zippedfile, 'r') as containerZip:\n        #Convert the zipfile data into a str object, necessary since\n        #containerZip.read() returns a bytes object.\n        metadataText = io.TextIOWrapper(containerZip.open('metadata'),\n                                        encoding='utf-8'\n                                        ).read()\n        allMetadata = json.loads(metadataText, object_hook=jsonHook)\n        metadataIndex = [str(_) for _ in sorted([int(i) for i in\n                                                 viewkeys(allMetadata)\n                                                 ])\n                         ]\n        binarydataFile = containerZip.open('binarydata')\n        for index in metadataIndex:\n            binaryItem = allMetadata[index][0]\n            for binaryMetadata in allMetadata[index][1]:\n                arrayKey = binaryMetadata['arrayKey']\n                rawdata = binarydataFile.read(binaryMetadata['end'] -\n                                              binaryMetadata['start']\n                                              )\n                array = _arrayFromBytes(rawdata, binaryMetadata)\n                binaryItem.arrays[arrayKey] = array\n            binaryItemContainer[binaryItem.id] = binaryItem\n    return binaryItemContainer", "response": "Imports binaryItems from a zipfile generated by writeBinaryItemContainer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate and returns a numpy array from raw data bytes.", "response": "def _arrayFromBytes(dataBytes, metadata):\n    \"\"\"Generates and returns a numpy array from raw data bytes.\n\n    :param bytes: raw data bytes as generated by ``numpy.ndarray.tobytes()``\n    :param metadata: a dictionary containing the data type and optionally the\n        shape parameter to reconstruct a ``numpy.array`` from the raw data\n        bytes. ``{\"dtype\": \"float64\", \"shape\": (2, 3)}``\n\n    :returns: ``numpy.array``\n    \"\"\"\n    array = numpy.fromstring(dataBytes, dtype=numpy.typeDict[metadata['dtype']])\n    if 'shape' in metadata:\n        array = array.reshape(metadata['shape'])\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef searchFileLocation(targetFileName, targetFileExtension, rootDirectory,\n                       recursive=True):\n    \"\"\"Search for a filename with a specified file extension in all subfolders\n    of specified rootDirectory, returns first matching instance.\n\n    :param targetFileName: #TODO: docstring\n    :type targetFileName: str\n    :param rootDirectory: #TODO: docstring\n    :type rootDirectory: str\n    :param targetFileExtension: #TODO: docstring\n    :type targetFileExtension: str\n    :param recursive: bool, specify whether subdirectories should be searched\n\n    :returns: a filepath (str) or None\n    \"\"\"\n    expectedFileName = targetFileName.split('.')[0] + '.' + targetFileExtension\n    targetFilePath = None\n\n    if recursive:\n        for dirpath, dirnames, filenames in os.walk(rootDirectory):\n            for filename in filenames:\n                if filename == expectedFileName:\n                    targetFilePath = joinpath(dirpath, filename)\n                    break\n            if targetFilePath is not None:\n                break\n    else:\n        for filename in os.listdir(rootDirectory):\n            filePath = joinpath(rootDirectory, filename)\n            if not os.path.isfile(filePath):\n                continue\n            if filename == expectedFileName:\n                targetFilePath = filePath\n                break\n\n    return targetFilePath", "response": "Search for a filename with a specified file extension in all subfolders\n    of specified rootDirectory returns first matching instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matchingFilePaths(targetfilename, directory, targetFileExtension=None,\n                      selector=None):\n    \"\"\"Search for files in all subfolders of specified directory, return\n    filepaths of all matching instances.\n\n    :param targetfilename: filename to search for, only the string before the\n        last \".\" is used for filename matching. Ignored if a selector function\n        is specified.\n    :param directory: search directory, including all subdirectories\n    :param targetFileExtension: string after the last \".\" in the filename, has\n        to be identical if specified. \".\" in targetFileExtension are ignored,\n        thus \".txt\" is treated equal to \"txt\".\n    :param selector: a function which is called with the value of targetfilename\n        and has to return True (include value) or False (discard value). If no\n        selector is specified, equality to targetfilename is used.\n\n    :returns: list of matching file paths (str)\n    \"\"\"\n    targetFilePaths = list()\n\n    targetfilename = os.path.splitext(targetfilename)[0]\n    targetFileExtension = targetFileExtension.replace('.', '')\n    matchExtensions = False if targetFileExtension is None else True\n    if selector is None:\n        selector = functools.partial(operator.eq, targetfilename)\n\n    for dirpath, dirnames, filenames in os.walk(directory):\n        for filename in filenames:\n            filenameNoextension = os.path.splitext(filename)[0]\n\n            if selector(filenameNoextension):\n                if matchExtensions:\n                    if not filename.endswith('.' + targetFileExtension):\n                        continue\n                targetFilePaths.append(joinpath(dirpath, filename))\n    return targetFilePaths", "response": "Search for files in all subfolders of specified directory and return a list of all matching file paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef listFiletypes(targetfilename, directory):\n    targetextensions = list()\n    for filename in os.listdir(directory):\n        if not os.path.isfile(joinpath(directory, filename)):\n            continue\n        splitname = filename.split('.')\n        basename = splitname[0]\n        extension = '.'.join(splitname[1:])\n        if basename == targetfilename:\n            targetextensions.append(extension)\n    return targetextensions", "response": "Looks for all occurences of a specified filename in a directory and returns a list of all present file extensions of this filename."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all substring starting positions in a template string.", "response": "def findAllSubstrings(string, substring):\n    \"\"\" Returns a list of all substring starting positions in string or an empty\n    list if substring is not present in string.\n\n    :param string: a template string\n    :param substring: a string, which is looked for in the ``string`` parameter.\n\n    :returns: a list of substring starting positions in the template string\n    \"\"\"\n    #TODO: solve with regex? what about '.':\n    #return [m.start() for m in re.finditer('(?='+substring+')', string)]\n    start = 0\n    positions = []\n    while True:\n        start = string.find(substring, start)\n        if start == -1:\n            break\n        positions.append(start)\n        #+1 instead of +len(substring) to also find overlapping matches\n        start += 1\n    return positions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toList(variable, types=(basestring, int, float, )):\n    if isinstance(variable, types):\n        return [variable]\n    else:\n        return variable", "response": "Converts a variable of type string int float to a list containing the\n    variable as the only element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calcDeviationLimits(value, tolerance, mode):\n    values = toList(value)\n    if mode == 'relative':\n        lowerLimit = min(values) * (1 - tolerance)\n        upperLimit = max(values) * (1 + tolerance)\n    elif mode == 'absolute':\n        lowerLimit = min(values) - tolerance\n        upperLimit = max(values) + tolerance\n    else:\n        raise Exception('mode %s not specified' %(filepath, ))\n    return lowerLimit, upperLimit", "response": "Calculates the upper and lower deviation limits for a given value and a given tolerance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef returnArrayFilters(arr1, arr2, limitsArr1, limitsArr2):\n    posL = bisect.bisect_left(arr1, limitsArr1[0])\n    posR = bisect.bisect_right(arr1, limitsArr1[1])\n    matchMask = ((arr2[posL:posR] <= limitsArr2[1]) &\n                 (arr2[posL:posR] >= limitsArr2[0])\n                 )\n    return posL, posR, matchMask", "response": "returns array filters for the order of arr1 and arr2"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies a filter to the array.", "response": "def applyArrayFilters(array, posL, posR, matchMask):\n    \"\"\"#TODO: docstring\n\n    :param array: #TODO: docstring\n    :param posL: #TODO: docstring\n    :param posR: #TODO: docstring\n    :param matchMask: #TODO: docstring\n\n    :returns: ``numpy.array``, a subset of the input ``array``.\n    \"\"\"\n    return numpy.compress(matchMask, array[posL:posR], axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef returnSplineList(dependentVar, independentVar, subsetPercentage=0.4,\n                     cycles=10, minKnotPoints=10, initialKnots=200,\n                     splineOrder=2, terminalExpansion=0.1\n                     ):\n    \"\"\" #TODO: docstring\n\n    Note: Expects sorted arrays.\n\n    :param dependentVar: #TODO: docstring\n    :param independentVar: #TODO: docstring\n    :param subsetPercentage: #TODO: docstring\n    :param cycles: #TODO: docstring\n    :param minKnotPoints: #TODO: docstring\n    :param initialKnots: #TODO: docstring\n    :param splineOrder: #TODO: docstring\n    :param terminalExpansion: expand subsets on both sides\n\n    :returns: #TODO: docstring\n    \"\"\"\n    expansions = ddict(list)\n    expansionArea = (independentVar[-1] - independentVar[0]) * terminalExpansion\n    #adds 100 data points at both ends of the dependent and independent array\n    for i in range(100):\n        expansions['indUp'].append(independentVar[-1] + expansionArea/100*i)\n        expansions['indDown'].append(independentVar[0] -\n                                     expansionArea/100*(100-i+1)\n                                     )\n        expansions['depUp'].append(dependentVar[-1])\n        expansions['depDown'].append(dependentVar[0])\n\n    dependentVar = numpy.array(expansions['depDown'] + list(dependentVar) +\n                               expansions['depUp'], dtype=numpy.float64\n                               )\n    independentVar = numpy.array(expansions['indDown'] + list(independentVar) +\n                                 expansions['indUp'], dtype=numpy.float64\n                                 )\n\n    splineList = list()\n    for cycle in range(cycles):\n        subset = sorted(random.sample(range(len(dependentVar)),\n                                      int(len(dependentVar) * subsetPercentage)\n                                      )\n                        )\n        terminalExpansion\n\n        dependentSubset = dependentVar[subset]\n        independentSubset = independentVar[subset]\n\n        minIndVar = independentSubset[minKnotPoints]\n        maxIndVar = independentSubset[-minKnotPoints]\n\n        knots = [float(i) * (maxIndVar-minIndVar) / initialKnots + minIndVar\n                 for i in range(1, initialKnots)\n                 ]\n        ## remove knots with less then minKnotPoints data points  ##\n        lastKnot = knots[0]\n        newKnotList = [lastKnot]\n        for knotPos in range(1,len(knots)):\n            nextKnot = knots[knotPos]\n            numHits = (len(independentSubset[(independentSubset >= lastKnot) &\n                       (independentSubset <= nextKnot)])\n                       )\n            if numHits >= minKnotPoints:\n                newKnotList.append(nextKnot)\n                lastKnot = nextKnot\n        knots = newKnotList\n\n        spline = LSQUnivariateSpline(independentSubset, dependentSubset, knots,\n                                     k=splineOrder)\n        splineList.append(spline)\n    return splineList", "response": "This function returns a list of random data points for a set of set of set items."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tolerantArrayMatching(referenceArray, matchArray, matchTolerance,\n                          matchUnit):\n    \"\"\"#TODO: docstring\n    Note: arrays must be sorted\n\n    :param referenceArray: #TODO: docstring\n    :param matchArray: #TODO: docstring\n    :param matchTolerance: #TODO: docstring\n    :param matchUnit: #TODO: docstring\n\n    :returns: #TODO: docstring\n\n    #TODO: change matchUnit to \"absolute\", \"relative\" and remove the \"*1e-6\"\n    \"\"\"\n    if matchUnit == 'relative':\n        lowLimMatchArr = matchArray * (1 - matchTolerance)\n        uppLimMatchArr = matchArray * (1 + matchTolerance)\n    elif matchUnit == 'ppm':\n        lowLimMatchArr = matchArray * (1 - matchTolerance*1e-6)\n        uppLimMatchArr = matchArray * (1 + matchTolerance*1e-6)\n    elif matchUnit == 'da':\n        lowLimMatchArr = matchArray - matchTolerance\n        uppLimMatchArr = matchArray + matchTolerance\n    else:\n        raise Exception('wrong matchUnit type specified (da or ppm): ',\n                        matchUnit)\n\n    lowerLimitMask = numpy.zeros_like(matchArray, dtype=int)\n    upperLimitMask = numpy.zeros_like(matchArray, dtype=int)\n\n    refPosLow = int()\n    maxReferenceValue = referenceArray[-1]\n    for matchPos, (lowerMatch, upperMatch) in enumerate(zip(lowLimMatchArr,\n                                                            uppLimMatchArr\n                                                            )\n                                                        ):\n        if lowerMatch < maxReferenceValue:\n            while referenceArray[refPosLow] < lowerMatch:\n                refPosLow += 1\n            refPosHigh = refPosLow\n            #Try except statement because this case can only happen once at the\n            #end of the array\n            try:\n                while referenceArray[refPosHigh] <= upperMatch:\n                    refPosHigh += 1\n            except IndexError:\n                refPosHigh = len(referenceArray) - 1\n            lowerLimitMask[matchPos] = refPosLow\n            upperLimitMask[matchPos] = refPosHigh\n        else:\n            refPosLow = len(referenceArray) - 1\n            refPosHigh = len(referenceArray) - 1\n            lowerLimitMask[matchPos] = refPosLow\n            upperLimitMask[matchPos] = refPosHigh\n            break\n\n    matchPos += 1\n    lowerLimitMask[matchPos:len(matchArray)] = refPosLow\n    upperLimitMask[matchPos:len(matchArray)] = refPosHigh\n\n    return lowerLimitMask, upperLimitMask", "response": "This function takes a numpy array of arrays and tolerants them into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open(self, filepath, mode='w+b'):\n        #Check if the filepath can be accessed and is writable before creating\n        #the tempfile\n        if not _isFileAccessible(filepath):\n            raise IOError('File %s is not writable' % (filepath,))\n\n        if filepath in self._files:\n            with open(self._files[filepath], mode=mode) as tmpf:\n                yield tmpf\n        else:\n            tempfilepath = None\n            with tempfile.NamedTemporaryFile(delete=False, mode=mode) as tmpf:\n                tempfilepath = tmpf.name\n                yield tmpf\n            self._files[filepath] = tempfilepath", "response": "Opens a file - will actually return a temporary file but replace the\n        original file when the context is closed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default(self, obj):\n        if hasattr(obj, '_reprJSON'):\n            return obj._reprJSON()\n        #Let the base class default method raise the TypeError\n        return json.JSONEncoder.default(self, obj)", "response": "Return the default value for a nacms. iaas. AFF4 object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef processInput(self, dataAveraging=False, windowSize=None):\n        self.dependentVar = numpy.array(self.dependentVarInput,\n                                        dtype=numpy.float64\n                                        )\n        self.independentVar = numpy.array(self.independentVarInput,\n                                          dtype=numpy.float64\n                                          )\n\n        sortMask = self.independentVar.argsort()\n        self.dependentVar = self.dependentVar[sortMask]\n        self.independentVar = self.independentVar[sortMask]\n\n        if dataAveraging:\n            averagedData = averagingData(self.dependentVar,\n                                         windowSize=windowSize,\n                                         averagingType=dataAveraging\n                                         )\n            averagedData = numpy.array(averagedData, dtype=numpy.float64)\n\n            missingNumHigh = numpy.floor((self.independentVar.size\n                                          - averagedData.size\n                                          ) / 2\n                                         )\n            missingNumLow = ((self.independentVar.size - averagedData.size)\n                             - missingNumHigh\n                             )\n\n            self.dependentVar = averagedData\n            self.independentVar = self.independentVar[missingNumLow:\n                                                      -missingNumHigh]", "response": "This method takes in the input of the assessment process and stores the result in the internal structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a list of all the spline objects for this instance.", "response": "def generateSplines(self):\n        \"\"\"#TODO: docstring\n        \"\"\"\n        _ = returnSplineList(self.dependentVar, self.independentVar,\n                             subsetPercentage=self.splineSubsetPercentage,\n                             cycles=self.splineCycles,\n                             minKnotPoints=self.splineMinKnotPoins,\n                             initialKnots=self.splineInitialKnots,\n                             splineOrder=self.splineOrder,\n                             terminalExpansion=self.splineTerminalExpansion\n                             )\n        self.splines = _"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfixing the internal state of the internal state by adding unused arcs and all sink states to the internal state.", "response": "def fixminimized(self, alphabet):\n        \"\"\"\n        After pyfst minimization,\n        all unused arcs are removed,\n        and all sink states are removed.\n        However this may break compatibility.\n        Args:\n            alphabet (list): The input alphabet\n        Returns:\n            None\n        \"\"\"\n        endstate = len(list(self.states))\n        for state in self.states:\n            for char in alphabet:\n                found = 0\n                for arc in state.arcs:\n                    if self.isyms.find(arc.ilabel) == char:\n                        found = 1\n                        break\n                if found == 0:\n                    self.add_arc(state.stateid, endstate, char)\n\n        self[endstate].final = TropicalWeight(float('inf'))\n\n        for char in alphabet:\n            self.add_arc(endstate, endstate, char)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _path_to_str(self, path):\n        inp = ''\n        for arc in path:\n            i = self.isyms.find(arc.ilabel)\n            # Ignore \\epsilon transitions both on input\n            if i != fst.EPSILON:\n                inp += i\n        return inp", "response": "Convert a path to the string representing the path\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_from_acceptor(self, acceptor):\n        states = sorted(\n            acceptor.states,\n            key=attrgetter('initial'),\n            reverse=True)\n        for state in states:\n            for arc in state.arcs:\n                itext = acceptor.isyms.find(arc.ilabel)\n                if itext in self.alphabet:\n                    self.add_arc(state.stateid, arc.nextstate, itext)\n            if state.final:\n                self[state.stateid].final = True\n            if state.initial:\n                self[state.stateid].initial = True", "response": "Adds a sink state\n            to the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the machine accepts or rejects the input.", "response": "def consume_input(self, inp):\n        \"\"\"\n        Return True/False if the machine accepts/reject the input.\n        Args:\n            inp (str): input string to be consumed\n        Returns:\n            bool: A true or false value depending on if the DFA\n                accepts the provided input\n        \"\"\"\n        cur_state = sorted(\n            self.states,\n            key=attrgetter('initial'),\n            reverse=True)[0]\n        while len(inp) > 0:\n            found = False\n            for arc in cur_state.arcs:\n                if self.isyms.find(arc.ilabel) == inp[0]:\n                    cur_state = self[arc.nextstate]\n                    inp = inp[1:]\n                    found = True\n                    break\n            if not found:\n                return False\n        return cur_state.final != TropicalWeight(float('inf'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates string_length random strings that belong to the automaton.", "response": "def random_strings(self, string_length=1):\n        \"\"\"\n        Generate string_length random strings that belong to the automaton.\n        Args:\n            string_length (integer): The size of the random string\n        Returns:\n            str: The generated string\n        \"\"\"\n        str_list = []\n        for path in self.uniform_generate(string_length):\n            str_list.append(self._path_to_str(path))\n        return str_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the machine in the openFST format in the file denoted by txt_fst_filename.", "response": "def save(self, txt_fst_filename):\n        \"\"\"\n        Save the machine in the openFST format in the file denoted by\n        txt_fst_filename.\n        Args:\n            txt_fst_filename (str): The name of the file\n        Returns:\n            None\n        \"\"\"\n        txt_fst = open(txt_fst_filename, 'w+')\n        states = sorted(self.states, key=attrgetter('initial'), reverse=True)\n        for state in states:\n            for arc in state.arcs:\n                itext = self.isyms.find(arc.ilabel)\n                otext = self.osyms.find(arc.ilabel)\n                txt_fst.write(\n                    '{}\\t{}\\t{}\\t{}\\n'.format(\n                        state.stateid,\n                        arc.nextstate,\n                        itext.encode('hex'),\n                        otext.encode('hex')))\n            if state.final:\n                txt_fst.write('{}\\n'.format(state.stateid))\n        txt_fst.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the transducer from the text file format of OpenFST.", "response": "def load(self, txt_fst_filename):\n        \"\"\"\n        Save the transducer in the text file format of OpenFST.\n        The format is specified as follows:\n            arc format: src dest ilabel olabel [weight]\n            final state format: state [weight]\n        lines may occur in any order except initial state must be first line\n        Args:\n            txt_fst_filename (string): The name of the file\n        Returns:\n            None\n        \"\"\"\n        with open(txt_fst_filename, 'r') as txt_fst:\n            for line in txt_fst:\n                line = line.strip()\n                splitted_line = line.split()\n                if len(splitted_line) == 1:\n                    self[int(splitted_line[0])].final = True\n                else:\n                    self.add_arc(int(splitted_line[0]), int(\n                        splitted_line[1]), splitted_line[2].decode('hex'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that the menu is not too long and that the menu is not too long.", "response": "def persistent_menu(menu):\n    \"\"\"\n    more: https://developers.facebook.com/docs/messenger-platform/thread-settings/persistent-menu\n\n    :param menu:\n    :return:\n    \"\"\"\n    if len(menu) > 3:\n        raise Invalid('menu should not exceed 3 call to actions')\n\n    if any(len(item['call_to_actions']) > 5 for item in menu if item['type'] == 'nested'):\n        raise Invalid('call_to_actions is limited to 5 for sub-levels')\n\n    for item in menu:\n        if len(item['title']) > 30:\n            raise Invalid('menu item title should not exceed 30 characters')\n\n        if item['type'] == 'postback' and len(item['payload']) > 1000:\n            raise Invalid('menu item payload should not exceed 1000 characters')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_text_message(text, quick_replies):\n    if len(text) > 640:\n        raise ExceedLengthException(\n            'send message text should not exceed 640 character limit',\n            limit=640,\n        )\n\n    if isinstance(quick_replies, list):\n        if len(quick_replies) > 10:\n            raise Invalid('send message quick replies should not exceed 10 limit')\n\n        for item in quick_replies:\n            if 'content_type' not in item:\n                raise Invalid('send message quick replies should have content_type')\n            if item['content_type'] == 'text':\n                if len(item['title']) > 20:\n                    raise Invalid('send message quick replies title should not exceed 20 character limit')\n                if len(item['payload']) > 1000:\n                    raise Invalid('send message quick replies payload should not exceed 1000 character limit')", "response": "Send a text message to the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    alphabet = list(string.lowercase)  # + [\"<\", \">\"]\n\n    # Create an SFA for the regular expression .*<t>.*\n    sfa = SFA(alphabet)\n\n    # sfa.add_arc(0,0,SetPredicate([ i for i in alphabet if i != \"<\" ]))\n    # sfa.add_arc(0,1,SetPredicate(list(\"<\")))\n    #\n    # sfa.add_arc(1,2,SetPredicate(list(\"t\")))\n    # sfa.add_arc(1,0,SetPredicate([ i for i in alphabet if i != \"t\" ]))\n    #\n    # sfa.add_arc(2,3,SetPredicate(list(\">\")))\n    # sfa.add_arc(2,0,SetPredicate([ i for i in alphabet if i != \">\" ]))\n    #\n    # sfa.add_arc(3,3,SetPredicate(alphabet))\n    #\n    # sfa.states[3].final = True\n\n    sfa.add_arc(0, 7, SetPredicate([i for i in alphabet if i != \"d\" and i != \"input_string\"]))\n    sfa.add_arc(1, 7, SetPredicate([i for i in alphabet if i != \"i\"]))\n    sfa.add_arc(2, 7, SetPredicate([i for i in alphabet if i != \"p\"]))\n    sfa.add_arc(3, 7, SetPredicate([i for i in alphabet if i != \"v\"]))\n    sfa.add_arc(5, 7, SetPredicate(list(alphabet)))\n    sfa.add_arc(4, 7, SetPredicate([i for i in alphabet if i != \"a\"]))\n    sfa.add_arc(6, 7, SetPredicate([i for i in alphabet if i != \"n\"]))\n    sfa.add_arc(7, 7, SetPredicate(list(alphabet)))\n\n    sfa.add_arc(0, 1, SetPredicate(list(\"d\")))\n    sfa.add_arc(1, 3, SetPredicate(list(\"i\")))\n    sfa.add_arc(3, 5, SetPredicate(list(\"v\")))\n\n    sfa.add_arc(0, 2, SetPredicate(list(\"input_string\")))\n    sfa.add_arc(2, 4, SetPredicate(list(\"p\")))\n    sfa.add_arc(4, 6, SetPredicate(list(\"a\")))\n    sfa.add_arc(6, 5, SetPredicate(list(\"n\")))\n\n    sfa.states[5].final = True\n\n    dfa = sfa.concretize()\n    # dfa.minimize()\n    dfa.save('concrete_re_sfa.dfa')\n\n    # Consume some input\n    input_string = \"koukouroukou\"\n    print 'SFA-DFA result on {}: {} - {}'.format(input_string, sfa.consume_input(input_string),\n                                                 dfa.consume_input(input_string))\n\n    input_string = \"divspan\"\n    print 'SFA-DFA result on {}: {} - {}'.format(input_string, sfa.consume_input(input_string),\n                                                 dfa.consume_input(input_string))\n\n    input_string = \"div\"\n    print 'SFA-DFA result on {}: {} - {}'.format(input_string, sfa.consume_input(input_string),\n                                                 dfa.consume_input(input_string))\n\n    input_string = \"span\"\n    print 'SFA-DFA result on {}: {} - {}'.format(input_string, sfa.consume_input(input_string),\n                                                 dfa.consume_input(input_string))", "response": "Main Function for the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_state(self):\n        sid = len(self.states)\n        self.states.append(SFAState(sid))", "response": "This function adds a new state to the list of states"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the machine accepts the input.", "response": "def consume_input(self, inp):\n        \"\"\"\n        Return True/False if the machine accepts/reject the input.\n        Args:\n            inp (str): input string to be consumed\n        Retunrs:\n            bool: A true or false value depending on if the DFA\n                accepts the provided input\n        \"\"\"\n        cur_state = self.states[0]\n        for character in inp:\n            found = False\n            for arc in cur_state.arcs:\n                if arc.guard.is_sat(character):\n                    cur_state = self.states[arc.dst_state]\n                    found = True\n                    break\n\n            if not found:\n                raise RuntimeError('SFA not complete')\n\n        return cur_state.final"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new DFA from the SFA.", "response": "def concretize(self):\n        \"\"\"\n        Transforms the SFA into a DFA\n        Args:\n            None\n        Returns:\n            DFA: The generated DFA\n        \"\"\"\n        dfa = DFA(self.alphabet)\n        for state in self.states:\n            for arc in state.arcs:\n                for char in arc.guard:\n                    dfa.add_arc(arc.src_state, arc.dst_state, char)\n\n        for i in xrange(len(self.states)):\n            if self.states[i].final:\n                dfa[i].final = True\n        return dfa"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _write(self, ret):\n        self.redis.set('{0}:{1}'.format(ret['id'], ret['jid']), json.dumps(ret))\n        self.redis.lpush('{0}:{1}'.format(ret['id'], ret['fun']), ret['jid'])\n        self.redis.sadd('minions', ret['id'])\n        self.redis.sadd('jids', ret['jid'])", "response": "Write the return data to the redis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the addons for this manager.", "response": "def _initAddons(cls, recurse=True):\n        \"\"\"\n        Initializes the addons for this manager.\n        \"\"\"\n        for addon_module in cls.addonModules(recurse):\n            projex.importmodules(addon_module)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addons(cls, recurse=True):\n        cls.initAddons()\n        prop = '_{0}__addons'.format(cls.__name__)\n        out = {}\n\n        # lookup base classes\n        if recurse:\n            for base in cls.__bases__:\n                if issubclass(base, AddonManager):\n                    out.update(base.addons(recurse))\n\n        # always use the highest level for any given key\n        out.update(getattr(cls, prop, {}))\n        return out", "response": "Returns a dictionary containing all the available addons for this mixin class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addonModules(cls, recurse=True):\n        prop = '_{0}__addon_modules'.format(cls.__name__)\n        out = set()\n\n        # lookup base classes\n        if recurse:\n            for base in cls.__bases__:\n                if issubclass(base, AddonManager):\n                    out.update(base.addonModules(recurse))\n\n        # always use the highest level for any given key\n        out.update(getattr(cls, prop, set()))\n        return out", "response": "Returns all the modules that this addon class uses to load plugins\n        from."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef byName(cls, name, recurse=True, default=None):\n        cls.initAddons()\n        prop = '_{0}__addons'.format(cls.__name__)\n        try:\n            return getattr(cls, prop, {})[name]\n        except KeyError:\n            if recurse:\n                for base in cls.__bases__:\n                    if issubclass(base, AddonManager):\n                        return base.byName(name, recurse)\n        return default", "response": "Returns the first instance of the given name in the class with the given name. If recurse is set to False then all base classes of the given name will be searched. If no match is found the default is returned."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initAddons(cls, recurse=True):\n        key = '_{0}__addons_loaded'.format(cls.__name__)\n        if getattr(cls, key, False):\n            return\n\n        cls._initAddons(recurse)\n        setattr(cls, key, True)", "response": "Initializes the addons for this class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef registerAddon(cls, name, addon, force=False):\n        prop = '_{0}__addons'.format(cls.__name__)\n        cmds = getattr(cls, prop, {})\n\n        if name in cmds and not force:\n            raise errors.AddonAlreadyExists(cls, name, addon)\n\n        cmds[name] = addon\n        try:\n            if issubclass(addon, cls):\n                setattr(addon, '_{0}__addonName'.format(addon.__name__), name)\n        except StandardError:\n            pass\n\n        setattr(cls, prop, cmds)", "response": "Registers the inputted addon to the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef registerAddonModule(cls, module):\n        prop = '_{0}__addon_modules'.format(cls.__name__)\n        mods = getattr(cls, prop, set())\n        mods.add(module)\n        setattr(cls, prop, mods)", "response": "Registers a module to use to import addon subclasses from.\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unregisterAddon(cls, name):\n        prop = '_{0}__addons'.format(cls.__name__)\n        cmds = getattr(cls, prop, {})\n        cmds.pop(name, None)", "response": "Unregisters the addon defined by the given name from the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregisterAddonModule(cls, module):\n        prop = '_{0}__addon_modules'.format(cls.__name__)\n        mods = getattr(cls, prop, set())\n        try:\n            mods.remove(module)\n        except KeyError:\n            pass", "response": "Unregisters the module to use to import addon subclasses from.\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nemit a log record.", "response": "def emit(self, record):\n        \"\"\" \n        Throws an error based on the information that the logger reported,\n        given the logging level.\n        \n        :param      record: <logging.LogRecord>\n        \"\"\"\n        if not logging.raiseExceptions:\n            return\n\n        logger = logging.getLogger(record.name)\n\n        # raise an exception based on the error logging\n        if logger.level <= record.levelno:\n            err = record.msg[0]\n            if not isinstance(err, Exception):\n                err = ProjexError(nstr(record.msg))\n\n            # log the traceback info\n            data = record.__dict__.copy()\n            data['type'] = type(err).__name__\n            msg = ERROR_MESSAGE % data\n            sys.stderr.write(msg)\n            raise err"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlisten to push and pull requests from target", "response": "def cli(ctx, stage):\n    \"\"\"listen to push requests for src and pull requests from target (experimental)\"\"\"\n\n    if not ctx.bubble:\n        ctx.say_yellow('There is no bubble present, will not listen')\n        raise click.Abort()\n\n    SRC = None\n    if stage in STAGES:\n        try:\n            SRC = ctx.cfg.CFG[stage].SOURCE\n        except KeyError:\n            pass\n\n    if not SRC:\n        ctx.say_red('There is no SOURCE in stage:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                       ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n    if 'SERVER' not in SRC:\n        ctx.say_red('There is no SOURCE.SERVER in stage:' + stage)\n        raise click.Abort()\n\n    src_server = get_server(SRC.SERVER, ctx.home)\n\n    # connect storage / pipeline to target via transform\n    # write state listening on port etc into\n    def message_handler(**m):\n        print(str(arrow.now), str(m))\n        return True, 'handled'\n\n    try:\n        # TODO: bg &\n        # src_listening = src_server.listen(cfg=SRC,\n        src_server.listen(cfg=SRC,\n                          push_handler=message_handler,\n                          pull_handler=message_handler)\n    except Exception as e:\n        ctx.say_red(\n            'cannot listen from source client bubble.clients.' + SRC.SERVER)\n        ctx.say_red(str(e))\n        raise click.Abort('cannot listen')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_field_label_css_class(self, bound_field):\n        # If we render CheckboxInputs, Bootstrap requires a different\n        # field label css class for checkboxes.\n        if isinstance(bound_field.field.widget, forms.CheckboxInput):\n            return 'form-check-label'\n\n        return super().get_field_label_css_class(bound_field)", "response": "Returns the css class for the label for the given field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the CSS class for the given field.", "response": "def get_widget_css_class(self, field_name, field):\n        \"\"\"\n        Returns 'form-check-input' if widget is CheckboxInput or 'form-control-file'\n        if widget is FileInput. For all other fields return the default value\n        from the form property (\"form-control\").\n        \"\"\"\n        # If we render CheckboxInputs, Bootstrap requires a different\n        # widget css class for checkboxes.\n        if isinstance(field.widget, forms.CheckboxInput):\n            return 'form-check-input'\n\n        # Idem for fileinput.\n        if isinstance(field.widget, forms.FileInput):\n            return 'form-control-file'\n\n        return super().get_widget_css_class(field_name, field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a message from the broker.", "response": "def handle(self):\n        \"\"\"\n        Handle a message\n        :return: True if success, False otherwise\n        \"\"\"\n\n        if self.component_type == StreamComponent.SOURCE:\n            msg = self.handler_function()\n            return self.__send(msg)\n\n        logger = self.logger\n        data = self.__receive()\n        if data is None:\n            return False\n        else:\n            logger.debug(\"Calling %s \" % self.handler_function)\n            result = self.handler_function(data.decode(self.char_encoding))\n            if self.component_type == StreamComponent.PROCESSOR:\n                logger.debug(\"Sending p3:%s %s %s\" % (PYTHON3, result, str(type(result))))\n                if not self.__send(result):\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a path into its realpath.", "response": "def realpath_with_context(path, context):\n    \"\"\"\n    Convert a path into its realpath:\n\n      * For relative path: use :attr:`context.workdir` as root directory\n      * For absolute path: Pass-through without any changes.\n\n    :param path: Filepath to convert (as string).\n    :param context: Behave context object (with :attr:`context.workdir`)\n    :return: Converted path.\n    \"\"\"\n    if not os.path.isabs(path):\n        # XXX ensure_workdir_exists(context)\n        assert context.workdir\n        path = os.path.join(context.workdir, os.path.normpath(path))\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert path into POSIX path.", "response": "def posixpath_normpath(pathname):\n    \"\"\"\n    Convert path into POSIX path:\n\n      * Normalize path\n      * Replace backslash with slash\n\n    :param pathname: Pathname (as string)\n    :return: Normalized POSIX path.\n    \"\"\"\n    backslash = '\\\\'\n    pathname2 = os.path.normpath(pathname) or \".\"\n    if backslash in pathname2:\n        pathname2 = pathname2.replace(backslash, '/')\n    return pathname2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_textfile_with_contents(filename, contents, encoding='utf-8'):\n    ensure_directory_exists(os.path.dirname(filename))\n    if os.path.exists(filename):\n        os.remove(filename)\n    outstream = codecs.open(filename, \"w\", encoding)\n    outstream.write(contents)\n    if contents and not contents.endswith(\"\\n\"):\n        outstream.write(\"\\n\")\n    outstream.flush()\n    outstream.close()\n    assert os.path.exists(filename), \"ENSURE file exists: %s\" % filename", "response": "Create a textual file with the provided contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_directory_exists(dirname, context=None):\n    real_dirname = dirname\n    if context:\n        real_dirname = realpath_with_context(dirname, context)\n    if not os.path.exists(real_dirname):\n        os.makedirs(real_dirname)\n    assert os.path.exists(real_dirname), \"ENSURE dir exists: %s\" % dirname\n    assert os.path.isdir(real_dirname),  \"ENSURE isa dir: %s\" % dirname", "response": "Ensures that a directory exists."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_identlist(self, t):\n    '''identlist : IDENT\n                  | NOT IDENT\n                  | IDENT AND identlist\n                  | NOT IDENT AND identlist              \n                  '''\n    if len(t)==5 : \n      #print(t[1],t[2],t[3],t[4])\n      t[0] = t[1]+t[2]+t[3]+t[4]\n    elif len(t)==4 : \n      #print(t[1],t[2],t[3])\n      t[0] = t[1]+t[2]+t[3]\n    elif len(t)==3 : \n      #print(t[1],t[2])\n      t[0] = t[1]+t[2]\n    elif len(t)==2 :\n      #print(t[0],t[1])\n      t[0]=t[1]\n    else:\n      print(\"Syntax error at '\",str(t),\"'\")", "response": "p_identlist is a helper function that takes a list of tuples and returns the list of objects that are in the order they appear in the list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deserialize(self, msg):\n        'deserialize output to a Python object'\n        self.logger.debug('deserializing %s', msg)\n        return json.loads(msg)", "response": "deserialize output to a Python object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append_request_id(req, resp, resource, params):\n    def get_headers(resp):\n        if hasattr(resp, 'headers'):\n            return resp.headers\n        if hasattr(resp, '_headers'):\n            return resp._headers\n        return None\n\n    if(isinstance(resp, Response) or\n       (get_headers(resp) is not None)):\n        # Extract 'x-request-id' from headers if\n        # response is a Response object.\n        request_id = get_headers(resp).get('x-request-id')\n    else:\n        # If resp is of type string or None.\n        request_id = resp\n\n    if resource.req_ids is None:\n        resource.req_ids = []\n\n    if request_id not in resource.req_ids:\n        resource.req_ids.append(request_id)", "response": "Append request id which got from response\n    header to resource. req_ids list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking unique identifiers for a given step", "response": "def make_uniq_for_step(ctx, ukeys, step, stage, full_data, clean_missing_after_seconds, to_uniq):\n    \"\"\"initially just a copy from UNIQ_PULL\"\"\"\n\n    # TODO:\n    # this still seems to work ok for Storage types json/bubble,\n    # for DS we need to reload de dumped step to uniqify\n\n    if not ukeys:\n        return to_uniq\n    else:\n        uniq_data = bubble_lod_load(ctx, step, stage)\n        ctx.say('Creating uniq identifiers for [' + step + '] information', 0)\n\n        ctx.gbc.say('uniq_data:', stuff=uniq_data, verbosity=1000)\n\n        # TODO:make: data->keyed.items\n        uniq_step_res = make_uniq(ctx=ctx,\n                                  ldict=to_uniq,\n                                  keyed=uniq_data,\n                                  uniqstr=ukeys,\n                                  tag=step,\n                                  full_data=full_data,\n                                  remove_missing_after_seconds=clean_missing_after_seconds)\n\n        ctx.gbc.say('uniq_step_res:', stuff=uniq_step_res, verbosity=1000)\n\n        to_uniq_newest = get_newest_uniq(ctx.gbc, uniq_step_res)\n\n        # TODO: selected pulled only from slice of uniq\n        # PROBLEM: slice of pull is not equal to slice of newest uniq,\n        # can only select keys from newest, from slice of pulled\n        # need a uid list from to_transform\n        # to_transform = get_gen_slice(gbc, to_transform_newest, amount, index)\n        # for now not a big problem, as with 'pump' there should be no problem\n        to_uniq = to_uniq_newest\n        # todo make keyed.items->data\n        uniq_res_list = get_uniq_list(ctx.gbc, uniq_step_res)\n        reset = True\n        pfr = bubble_lod_dump(ctx=ctx,\n                              step=step,\n                              stage=stage,\n                              full_data=full_data,\n                              reset=reset,\n                              data_gen=uniq_res_list)\n\n        ctx.gbc.say('saved uniq ' + step + ' data res:',\n                    stuff=pfr, verbosity=700)\n        return to_uniq"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all Network Interface Controller", "response": "def list_nic(self, instance_id):\n        \"\"\"List all Network Interface Controller\"\"\"\n        output = self.client.describe_instances(InstanceIds=[instance_id])\n        output = output.get(\"Reservations\")[0].get(\"Instances\")[0]\n        return output.get(\"NetworkInterfaces\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_ip(self, instance_id):\n        output = self.client.describe_instances(InstanceIds=[instance_id])\n        output = output.get(\"Reservations\")[0].get(\"Instances\")[0]\n        ips = {}\n        ips['PrivateIp'] = output.get(\"PrivateIpAddress\")\n        ips['PublicIp'] = output.get(\"PublicIpAddress\")\n        return ips", "response": "List all IPs for a given instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting function for Flex Regular Expressions to FST DFA", "response": "def main():\n    \"\"\"\n    Testing function for Flex Regular Expressions to FST DFA\n    \"\"\"\n    if len(argv) < 2:\n        print 'Usage: %s fst_file [optional: save_file]' % argv[0]\n        return\n    flex_a = Flexparser()\n    mma = flex_a.yyparse(argv[1])\n    mma.minimize()\n    print mma\n    if len(argv) == 3:\n        mma.save(argv[2])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_transitions(self):\n        states = []\n        i = 0\n        regex = re.compile('[ \\t\\n\\r:,]+')\n        found = 0  # For maintaining the state of yy_nxt declaration\n        state = 0  # For maintaining the state of opening and closing tag of yy_nxt\n        substate = 0  # For maintaining the state of opening and closing tag of each set in yy_nxt\n        mapping = []  # For writing each set of yy_next\n        cur_line = None\n        with open(self.outfile) as flex_file:\n            for cur_line in flex_file:\n                if cur_line[0:35] == \"static yyconst flex_int16_t yy_nxt[\" or cur_line[0:33] == \"static const flex_int16_t yy_nxt[\":\n                    found = 1\n                    # print 'Found yy_next declaration'\n                    continue\n                if found == 1:\n                    if state == 0 and cur_line[0:5] == \"    {\":\n                        state = 1\n                        continue\n                    if state == 1 and cur_line[0:7] == \"    } ;\":\n                        state = 0\n                        break\n\n                    if substate == 0 and cur_line[0:5] == \"    {\":\n                        mapping = []\n                        substate = 1\n                        continue\n                    if substate == 1:\n                        if cur_line[0:6] != \"    },\":\n                            cur_line = \"\".join(cur_line.split())\n                            if cur_line == '':\n                                continue\n                            if cur_line[cur_line.__len__() - 1] == ',':\n                                splitted_line = regex.split(\n                                    cur_line[:cur_line.__len__() - 1])\n                            else:\n                                splitted_line = regex.split(cur_line)\n                            mapping = mapping + splitted_line\n                            continue\n                        else:\n                            cleared = []\n                            for j in mapping:\n                                cleared.append(int(j))\n                            states.append(cleared)\n                            mapping = []\n                            substate = 0\n\n        return states", "response": "Read DFA transitions from the flex compiled file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_accept_states(self):\n        states = []\n        i = 0\n        regex = re.compile('[ \\t\\n\\r:,]+')\n        found = 0  # For maintaining the state of yy_accept declaration\n        state = 0  # For maintaining the state of opening and closing tag of yy_accept\n        mapping = [] # For writing each set of yy_accept\n        cur_line = None\n        with open(self.outfile) as flex_file:\n            for cur_line in flex_file:\n                if cur_line[0:37] == \"static yyconst flex_int16_t yy_accept\" or cur_line[0:35] == \"static const flex_int16_t yy_accept\":\n                    found = 1\n                    continue\n                if found == 1:\n                    # print x\n                    if state == 0 and cur_line[0:5] == \"    {\":\n                        mapping.append(0)  # there is always a zero there\n                        state = 1\n                        continue\n\n                    if state == 1:\n                        if cur_line[0:7] != \"    } ;\":\n                            cur_line = \"\".join(cur_line.split())\n                            if cur_line == '':\n                                continue\n                            if cur_line[cur_line.__len__() - 1] == ',':\n                                splitted_line = regex.split(\n                                    cur_line[:cur_line.__len__() - 1])\n                            else:\n                                splitted_line = regex.split(cur_line)\n                            mapping = mapping + splitted_line\n                            continue\n                        else:\n                            cleared = []\n                            for j in mapping:\n                                cleared.append(int(j))\n                            max_value = max(cleared)\n                            for i in range(0, len(cleared)):\n                                if cleared[i] > 0 and cleared[\n                                        i] < (max_value - 1):\n                                    states.append(i)\n                            return states\n        return []", "response": "Read the list of accepted states from the DFA file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a list of states from a given number of states.", "response": "def _create_states(self, states_num):\n        \"\"\"\n        Args:\n            states_num (int): Number of States\n        Returns:\n            list: An initialized list\n        \"\"\"\n        states = []\n        for i in range(0, states_num):\n            states.append(i)\n        return states"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the given key in the given dict object to the given value at the given path.", "response": "def set_path(ctx, path_str, value, data):\n    \"\"\"\n    Sets the given key in the given dict object to the given value. If the\n    given path is nested, child dicts are created as appropriate.\n    Accepts either a dot-delimited path or an array of path elements as the\n    `path` variable.\n    \"\"\"\n    ctx.gbc.say('set_path:value:' + str(value) + ' at:' + path_str + ' in:',\n                stuff=data, verbosity=1001)\n\n    path = path_str.split('.')\n    ctx.gbc.say('path:', stuff=path, verbosity=100)\n    if len(path) > 1:\n        destk = '.'.join(path[0:-1])\n        lp = path[-1]\n        ctx.gbc.say('destk:%s' % destk, verbosity=100)\n        ctx.gbc.say('last:%s' % lp, verbosity=100)\n        ctx.gbc.say('current keys:', stuff=data.keys(), verbosity=1001)\n        if len(path) > 2:\n            destk = unescape(ctx, destk)\n        if destk not in data.keys():\n            ctx.gbc.say('destk not in current keys:',\n                        stuff=data.keys(), verbosity=1001)\n            data[destk] = {}\n            ctx.gbc.say('destk not added:', stuff=data, verbosity=1001)\n\n        lp = unescape(ctx, lp)\n        data[destk][lp] = value\n        ctx.gbc.say('destk and val added:', stuff=data, verbosity=1001)\n    else:\n        path_str = unescape(ctx, path_str)\n        data[path_str] = value\n    ctx.gbc.say('set_path:res:', stuff=data, verbosity=1001)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, setkv, copyk, delk,showtype):\n\n    if not ctx.bubble:\n        ctx.say_yellow(\n            'There is no bubble present, will not show or set the config')\n        raise click.Abort()\n\n    new_cfg = flat(ctx, ctx.cfg)\n    ctx.say('current config', stuff=ctx.cfg, verbosity=10)\n    ctx.say('current flat config with meta', stuff=new_cfg, verbosity=100)\n    new_cfg_no_meta = {}\n    meta_ends = ['_doct_as_key',\n                 '_doct_level',\n                 '___bts_flat_',\n                 '___bts_flat_star_path_',\n                 '___bts_flat_star_select_']\n\n    lkeys = list(new_cfg.keys())\n    for k in lkeys:\n        addkey = True\n        # ctx.say('k:'+k)\n        if k.startswith('___bts_'):\n            addkey = False\n        for meta_end in meta_ends:\n            if k.endswith(meta_end):\n                addkey = False\n        if addkey:\n            # ctx.say('adding k:'+k)\n            new_cfg_no_meta[k] = new_cfg[k]\n        else:\n            pass\n            # ctx.say('not adding meta k:'+k)\n    ctx.say('current flat config without metakeys',\n            stuff=new_cfg_no_meta,\n            verbosity=3)\n    if not setkv and not copyk and not delk:\n        ctx.say('current configuration')\n        for k, v in new_cfg_no_meta.items():\n            tstr=''\n            if showtype:\n                tstr=' type: '+TYPES[str(type(v))]\n            ctx.say(' '+k+': '+str(v)+tstr)\n\n    modified = 0\n    if setkv:\n        for key, value,vtype in setkv:\n            ctx.say('setting k:%s,v:%s,t:%s'%(key,value,vtype))\n            vtval='VALUE_NOT_SET'\n            try:\n                if vtype==\"STRING\":\n                    vtval=str(value)\n                if vtype==\"INTEGER\":\n                    vtval=int(value)\n                if vtype==\"FLOAT\":\n                    vtval=float(value)\n                if vtype==\"BOOLEAN\":\n                    if value.lower() in TRUES:\n                        vtval=True\n                    if value.lower() in FALSES:\n                        vtval=False\n                    if vtval not in [True,False]:\n                        ctx.cry(\"boolean value must be one of (case insensitive):\",\n                                stuff={'True':TRUES,'False':FALSES})\n                        raise TypeError()\n            except Exception as e:\n                ctx.cry('cannot set k:%s,v:%s,t:%s:'%(key,value,vtype))\n                raise e\n            if vtval != 'VALUE_NOT_SET':\n                new_cfg[str(key)] = vtval\n                modified += 1\n            else:\n                ctx.cry('cannot set k:%s,v:%s,t:%s:typed value is not set yet'%(key,value,vtype))\n    if copyk:\n        for srckey, destkey in copyk:\n            if srckey.endswith('.*'):\n                src_val = get_flat_path(ctx, new_cfg, srckey)\n                for k in src_val:\n                    # TODO: use magic for sep\n                    sep = '.'\n                    new_cfg[str(destkey + sep + k)] = str(src_val[k])\n                modified += 1\n            else:\n                if srckey in new_cfg:\n                    new_cfg[str(destkey)] = new_cfg[srckey]\n                    modified += 1\n\n    if delk:\n        if delk.endswith('.*'):\n            # fix PY3: RuntimeError: dictionary changed size during iteration\n            lkeys = list(new_cfg.keys())\n            for k in lkeys:\n                if k.startswith(delk[:-2]):\n                    del(new_cfg[k])\n                    modified += 1\n\n        else:\n            if delk in new_cfg:\n                del(new_cfg[delk])\n                modified += 1\n\n    if modified:\n        ctx.say('new flat config', stuff=new_cfg, verbosity=100)\n        fat_cfg = unflat(ctx, new_cfg)\n        ctx.say('new config, #changes:'+str(modified), verbosity=3)\n        ctx.say('new config', stuff=fat_cfg, verbosity=30)\n        fat_cfg = unflat(ctx, new_cfg)\n        doct_fat_cfg = BubbleDoct(fat_cfg)\n        ctx.say('new config fat doct', stuff=doct_fat_cfg, verbosity=100)\n        res = put_config(ctx, YCFG=BubbleDoct(doct_fat_cfg))\n        ctx.say('put config res:', stuff=res, verbosity=10)\n\n    return True", "response": "Show or change the configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef coerce(self, value):\r\n        if isinstance(value, int) or isinstance(value, compat.long):\r\n\r\n            return value\r\n\r\n        return int(value)", "response": "Converts text values into integer values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_permissions(self, request):\n        objs = [None]\n        if hasattr(self, 'get_perms_objects'):\n            objs = self.get_perms_objects()\n        else:\n            if hasattr(self, 'get_object'):\n                try:\n                    objs = [self.get_object()]\n                except Http404:\n                    raise\n                except:\n                    pass\n            if objs == [None]:\n                objs = self.get_queryset()\n            if len(objs) == 0:\n                objs = [None]\n\n        if (hasattr(self, 'permission_filter_queryset') and\n           self.permission_filter_queryset is not False and\n           self.request.method == 'GET'):\n            if objs != [None]:\n                self.perms_filter_queryset(objs)\n        else:\n            has_perm = check_perms(self.request.user,\n                                   self.get_permission_required(),\n                                   objs, self.request.method)\n\n            if not has_perm:\n                msg = self.get_permission_denied_message(\n                    default=\"Permission denied.\"\n                )\n                if isinstance(msg, Sequence):\n                    msg = msg[0]\n                self.permission_denied(request, message=msg)", "response": "Permission checking for DRF."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _hashed_key(self):\n        return abs(int(hashlib.md5(\n            self.key_prefix.encode('utf8')\n        ).hexdigest(), 16)) % (10 ** (\n            self._size_mod if hasattr(self, '_size_mod') else 5))", "response": "Returns 16 - digit numeric hash of the redis key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the expiration time of the key_prefix to _time.", "response": "def expire_at(self, _time):\n        \"\"\" Sets the expiration time of :prop:key_prefix to @_time\n            @_time: absolute Unix timestamp (seconds since January 1, 1970)\n        \"\"\"\n        return self._client.expireat(self.key_prefix, round(_time))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pexpire_at(self, _time):\n        return self._client.pexpireat(self.key_prefix, round(_time))", "response": "Sets the expiration time of the key_prefix to _time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode the object using the encoding specified in the constructor.", "response": "def _decode(self, obj):\n        \"\"\" Decodes @obj using :prop:encoding if :prop:decode_responses \"\"\"\n        if self.decode_responses and isinstance(obj, bytes):\n            try:\n                return obj.decode(self.encoding)\n            except UnicodeDecodeError:\n                return obj\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _loads(self, string):\n        if not self.serialized:\n            return self._decode(string)\n        if string is not None:\n            try:\n                return self.serializer.loads(string)\n            except TypeError:\n                #: catches bytes errors with the builtin json library\n                return self.serializer.loads(self._decode(string))\n            except pickle.UnpicklingError as e:\n                #: incr and decr methods create issues when pickle serialized\n                #  It's a terrible idea for a serialized instance\n                #  to be performing incr and decr methods, but I think\n                #  it makes sense to catch the error regardless\n                decoded = self._decode(string)\n                if decoded.isdigit():\n                    return decoded\n                raise pickle.UnpicklingError(e)", "response": "loads a string into a tuple"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes the object into a string.", "response": "def _dumps(self, obj):\n        \"\"\" If :prop:serialized is True, @obj will be serialized\n            using :prop:serializer\n        \"\"\"\n        if not self.serialized:\n            return obj\n        return self.serializer.dumps(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the value of a key from the cache or the default value if the key is not found.", "response": "def get(self, key, default=None):\n        \"\"\" Gets @key from :prop:key_prefix, defaulting to @default \"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default or self._default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nincrementing the value of a key by 1.", "response": "def incr(self, key, by=1):\n        \"\"\" Increments @key by @by\n            -> #int the value of @key after the increment \"\"\"\n        return self._client.incr(self.get_key(key), by)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decr(self, key, by=1):\n        return self._client.decr(self.get_key(key), by)", "response": "Decrements the value of a key by 1. Returns 0 if no key exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of values at the specified keys.", "response": "def mget(self, *keys):\n        \"\"\" -> #list of values at the specified @keys \"\"\"\n        keys = list(map(self.get_key, keys))\n        return list(map(self._loads, self._client.mget(*keys)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the keys to their respective values", "response": "def update(self, data):\n        \"\"\" Set given keys to their respective values\n            @data: #dict or :class:RedisMap of |{key: value}| entries to set\n        \"\"\"\n        if not data:\n            return\n        _rk, _dumps = self.get_key, self._dumps\n        data = self._client.mset({\n            _rk(key): _dumps(value)\n            for key, value in data.items()})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the time to live for the key to ttl seconds. Returns True if the key was set otherwise False.", "response": "def set_ttl(self, key, ttl):\n        \"\"\" Sets time to live for @key to @ttl seconds\n            -> #bool True if the timeout was set\n        \"\"\"\n        return self._client.expire(self.get_key(key), ttl)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the time to live for the key to ttl milliseconds. Returns True if the key was set otherwise False.", "response": "def set_pttl(self, key, ttl):\n        \"\"\" Sets time to live for @key to @ttl milliseconds\n            -> #bool True if the timeout was set\n        \"\"\"\n        return self._client.pexpire(self.get_key(key), ttl)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expire_at(self, key, _time):\n        return self._client.expireat(self.get_key(key), round(_time))", "response": "Sets the expiration time of the key to _time."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop(self, key):\n        r = self[key]\n        self.remove(key)\n        return r", "response": "Removes the specified key from the instance and returns its value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the specified keys from the cache.", "response": "def remove(self, *keys):\n        \"\"\" Deletes @keys from :prop:_client\n            @*keys: keys to remove\n\n            -> #int the number of keys that were removed\n        \"\"\"\n        keys = list(map(self.get_key, keys))\n        return self._client.delete(*keys)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan(self, match=\"*\", count=1000, cursor=0):\n        cursor, data = self._client.scan(\n            cursor=cursor,\n            match=\"{}:{}\".format(self.key_prefix, match),\n            count=count)\n        return (cursor, list(map(self._decode, data)))", "response": "Returns a list of all the keys in the cache that match the given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter(self, match=\"*\", count=1000):\n        replace_this = self.key_prefix+\":\"\n        for key in self._client.scan_iter(\n           match=\"{}:{}\".format(self.key_prefix, match), count=count):\n            yield self._decode(key).replace(replace_this, \"\", 1)", "response": "Iterate over the set of keys within this instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield the set of redis keys and values within this instance.", "response": "def items(self):\n        \"\"\" Iterates the set of |{key: value}| entries in :prop:key_prefix of\n            :prop:_client\n\n            -> yields redis (key, value) #tuples within this instance\n        \"\"\"\n        cursor = '0'\n        _loads = self._loads\n        _mget = self._client.mget\n        while cursor != 0:\n            cursor, keys = self.scan(cursor=cursor)\n            if keys:\n                vals = _mget(*keys)\n                for i, key in enumerate(keys):\n                    yield (\n                        key.replace(\n                            self.key_prefix+\":\", \"\", 1),\n                        _loads(vals[i])\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all |{key value | entries in |_client |.", "response": "def clear(self, match=\"*\", count=1000):\n        \"\"\" Removes all |{key: value}| entries in :prop:key_prefix of\n            :prop:_client\n        \"\"\"\n        cursor = '0'\n        while cursor != 0:\n            cursor, keys = self.scan(cursor=cursor, match=match, count=count)\n            if keys:\n                self._client.delete(*keys)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef size(self):\n        return int(self._client.hget(self._bucket_key, self.key_prefix) or 0)", "response": "Returns the number of keys in this instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _bucket_key(self):\n        return \"{}.size.{}\".format(\n            self.prefix, (self._hashed_key//1000)\n            if self._hashed_key > 1000 else self._hashed_key)", "response": "Returns the hash bucket key for the redis key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef incr(self, key, by=1):\n        pipe = self._client.pipeline(transaction=False)\n        pipe.incr(self.get_key(key), by)\n        if key not in self:\n            pipe.hincrby(self._bucket_key, self.key_prefix, 1)\n        result = pipe.execute()\n        return result[0]", "response": "incr - Updates the value of the key in the map by the given value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the key in Redis with the given data.", "response": "def update(self, data):\n        \"\"\" :see::meth:RedisMap.update \"\"\"\n        result = None\n        if data:\n            pipe = self._client.pipeline(transaction=False)\n            for k in data.keys():\n                pipe.exists(self.get_key(k))\n            exists = pipe.execute()\n            exists = exists.count(True)\n            _rk, _dumps = self.get_key, self._dumps\n            data = {\n                _rk(key): _dumps(value)\n                for key, value in data.items()}\n            pipe.mset(data)\n            pipe.hincrby(self._bucket_key, self.key_prefix, len(data)-exists)\n            result = pipe.execute()[0]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self, match=\"*\", count=1000):\n        cursor = '0'\n        pipe = self._client.pipeline(transaction=False)\n        while cursor != 0:\n            cursor, keys = self.scan(cursor=cursor, match=match, count=count)\n            if keys:\n                pipe.delete(*keys)\n        pipe.hdel(self._bucket_key, self.key_prefix)\n        pipe.execute()\n        return True", "response": "Removes all entries from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, key, default=None):\n        result = self._loads(self._client.get(self.get_key(key)))\n        if result is not None:\n            return result\n        else:\n            return default or self._default", "response": "Gets the value of a key from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mget(self, *keys):\n        return list(map(\n            self._loads, self._client.hmget(self.key_prefix, *keys)))", "response": "Returns a list of values at the specified keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of all entries in the cache.", "response": "def all(self):\n        \"\"\" -> #dict of all |{key: value}| entries in :prop:key_prefix of\n                :prop:_client\n        \"\"\"\n        return {\n            self._decode(k): self._loads(v)\n            for k, v in self._client.hgetall(self.key_prefix).items()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the cache with the given data.", "response": "def update(self, data):\n        \"\"\" :see::meth:RedisMap.update \"\"\"\n        result = None\n        if data:\n            _dumps = self._dumps\n            data = {\n                key: _dumps(value)\n                for key, value in data.items()}\n            result = self._client.hmset(self.key_prefix, data)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans for the set of keys", "response": "def scan(self, match=\"*\", count=1000, cursor=0):\n        \"\"\" :see::meth:RedisMap.scan \"\"\"\n        cursor, results = self._client.hscan(\n            self.key_prefix, cursor=cursor, match=match, count=count)\n        return (cursor, list(map(self._decode, results)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the keys in the cache.", "response": "def iter(self, match=\"*\", count=1000):\n        \"\"\" :see::meth:RedisMap.iter \"\"\"\n        for field, value in self._client.hscan_iter(\n          self.key_prefix, match=match, count=count):\n            yield self._decode(field)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef items(self, match=\"*\", count=1000):\n        for field, value in self._client.hscan_iter(\n          self.key_prefix, match=match, count=count):\n            yield self._decode(field), self._loads(value)", "response": "Gets a generator over the items in the hash table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator over the keys of the object.", "response": "def keys(self):\n        \"\"\" :see::meth:RedisMap.keys \"\"\"\n        for field in self._client.hkeys(self.key_prefix):\n            yield self._decode(field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef values(self):\n        for val in self._client.hvals(self.key_prefix):\n            yield self._loads(val)", "response": "Yields all the values in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the value of a key from the cache.", "response": "def get(self, key, default=None):\n        \"\"\" Gets @key from :prop:key_prefix, defaulting to @default \"\"\"\n        try:\n            result = self._loads(self._client.hget(self.key_prefix, key))\n            assert result is not None\n            return result\n        except (AssertionError, KeyError):\n            return default or self._default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse_iter(self, start=None, stop=None, count=2000):\n        cursor = '0'\n        count = 1000\n        start = start if start is not None else (-1 * count)\n        stop = stop if stop is not None else -1\n        _loads = self._loads\n        while cursor:\n            cursor = self._client.lrange(self.key_prefix, start, stop)\n            for x in reversed(cursor or []):\n                yield _loads(x)\n            start -= count\n            stop -= count", "response": "Iterate over the items of the list in reverse"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove and returns the item at index. If index is None removes and returns the item at the end of the list -> item at index.", "response": "def pop(self, index=None):\n        \"\"\" Removes and returns the item at @index or from the end of the list\n            -> item at @index\n        \"\"\"\n        if index is None:\n            return self._loads(self._client.rpop(self.key_prefix))\n        elif index == 0:\n            return self._loads(self._client.lpop(self.key_prefix))\n        else:\n            _uuid = gen_rand_str(16, 24)\n            r = self[index]\n            self[index] = _uuid\n            self.remove(_uuid)\n            return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd items to the end of the list after operation", "response": "def extend(self, items):\n        \"\"\" Adds @items to the end of the list\n            -> #int length of list after operation\n        \"\"\"\n        if items:\n            if self.serialized:\n                items = list(map(self._dumps, items))\n            self._client.rpush(self.key_prefix, *items)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the item to the end of the list -> return the length of the list after operation", "response": "def append(self, item):\n        \"\"\" Adds @item to the end of the list\n            -> #int length of list after operation\n        \"\"\"\n        return self._client.rpush(self.key_prefix, self._dumps(item))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count(self, value):\n        cnt = 0\n        for x in self:\n            if x == value:\n                cnt += 1\n        return cnt", "response": "Count the number of occurences of a given value in the time\n            list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef push(self, *items):\n        if self.serialized:\n            items = list(map(self._dumps, items))\n        return self._client.lpush(self.key_prefix, *items)", "response": "Adds the given items to the end of the list. Returns the length of the list after operation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index(self, item):\n        for i, x in enumerate(self.iter()):\n            if x == item:\n                return i\n        return None", "response": "Returns the index of the item in the list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts the value before the index in the list. Returns the length of the list on success or - 1 on failure.", "response": "def insert(self, index, value):\n        \"\"\" Inserts @value before @index in the list.\n\n            @index: list index to insert @value before\n            @value: item to insert\n            @where: whether to insert BEFORE|AFTER @refvalue\n\n            -> #int new length of the list on success or -1 if refvalue is not\n                in the list.\n        \"\"\"\n        _uuid = gen_rand_str(24, 32)\n        item_at_index = self[index]\n        self[index] = _uuid\n        uuid = _uuid\n        _uuid = self._dumps(uuid)\n        pipe = self._client.pipeline(transaction=True)  # Needs to be atomic\n        pipe.linsert(\n                self.key_prefix, \"BEFORE\", _uuid, self._dumps(value))\n        pipe.linsert(\n                self.key_prefix, \"BEFORE\", _uuid, item_at_index)\n        results = pipe.execute()\n        self.remove(uuid)\n        return results[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, item, count=0):\n        self._client.lrem(self.key_prefix, count, self._dumps(item))", "response": "Removes the specified item from the list for the specified number of occurences."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter(self, start=0, count=1000):\n        cursor = '0'\n        _loads = self._loads\n        stop = start + count\n        while cursor:\n            cursor = self._client.lrange(self.key_prefix, start, stop)\n            for x in cursor or []:\n                yield _loads(x)\n            start += (count + 1)\n            stop += (count + 1)", "response": "Iterate over the items in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trim(self, start, end):\n        return self._client.ltrim(self.key_prefix, start, end)", "response": "Trim the list from start to end."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, member):\n        return self._client.sadd(self.key_prefix, self._dumps(member))", "response": "Adds a new entry to the set returning the number of members added"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, members):\n        if isinstance(members, RedisSet):\n            size = self.size\n            return (self.unionstore(\n                self.key_prefix, members.key_prefix) - size)\n        if self.serialized:\n            members = list(map(self._dumps, members))\n        if members:\n            return self._client.sadd(self.key_prefix, *members)\n        return 0", "response": "Adds members to the set returning the number of members added to the set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the union between this set and the given set of others.", "response": "def union(self, *others):\n        \"\"\" Calculates union between sets\n            @others: one or several :class:RedisSet objects or #str redis set\n                keynames\n\n            -> #set of new set members\n        \"\"\"\n        others = self._typesafe_others(others)\n        return set(map(\n            self._loads, self._client.sunion(self.key_prefix, *others)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator over the set of keys that are in the union of the given set of keys.", "response": "def unioniter(self, *others):\n        \"\"\" The same as :meth:union, but returns iterator instead of #set\n\n            @others: one or several :class:RedisSet objects or #str redis set\n                keynames\n\n            -> yields members of the resulting set\n        \"\"\"\n        others = self._typesafe_others(others)\n        for other in self._client.sunion(self.key_prefix, *others):\n            yield self._loads(other)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unionstore(self, destination, *others):\n        others = self._typesafe_others(others)\n        destination = self._typesafe(destination)\n        return self._client.sunionstore(destination, self.key_prefix, *others)", "response": "Union stores the result in the destination set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intersection(self, *others):\n        others = self._typesafe_others(others)\n        return set(map(\n            self._loads, self._client.sinter(self.key_prefix, *others)))", "response": "Calculates the intersection of all the given sets and returns the set of members that are present in all the given sets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterator over the set containing the intersection of the set with the given set of keys.", "response": "def interiter(self, *others):\n        \"\"\" The same as :meth:intersection, but returns iterator instead of #set\n\n            @others: one or several #str keynames or :class:RedisSet objects\n\n            -> yields members of the resulting set\n        \"\"\"\n        others = self._typesafe_others(others)\n        for other in self._client.sinter(self.key_prefix, *others):\n            yield self._loads(other)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef difference(self, *others):\n        others = self._typesafe_others(others)\n        return set(map(\n            self._loads, self._client.sdiff(self.key_prefix, *others)))", "response": "Calculates the difference between this set and the set of others."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef diffiter(self, *others):\n        others = self._typesafe_others(others)\n        for other in self._client.sdiff(self.key_prefix, *others):\n            yield self._loads(other)", "response": "Returns an iterator over the difference between the first set and all the others."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving a member from this set to a destination set atomically.", "response": "def move(self, member, destination):\n        \"\"\" Moves @member from this set to @destination atomically\n\n            @member: a member of this set\n            @destination: #str redis keyname or :class:RedisSet object\n\n            -> #bool True if the member was moved\n        \"\"\"\n        destination = self._typesafe(destination)\n        return self._client.smove(\n            self.key_prefix, destination, self._dumps(member))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rand(self, count=1):\n        result = self._client.srandmember(self.key_prefix, count)\n        return set(map(self._loads, result))", "response": "Gets a random set of set items from the set\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, *members):\n        if self.serialized:\n            members = list(map(self._dumps, members))\n        return self._client.srem(self.key_prefix, *members)", "response": "Removes the specified members from the set\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a set of all the members of the user.", "response": "def members(self):\n        \"\"\" -> #set of all members in the set \"\"\"\n        if self.serialized:\n            return set(map(\n                self._loads, self._client.smembers(self.key_prefix)))\n        else:\n            return set(map(\n                self._decode, self._client.smembers(self.key_prefix)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan(self, match=\"*\", count=1000, cursor=0):\n        cursor, data = self._client.sscan(\n            self.key_prefix, cursor=cursor, match=match, count=count)\n        return (cursor, set(map(self._loads, data)))", "response": "scan for the set of keys that match the given string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter(self, match=\"*\", count=1000):\n        _loads = self._loads\n        for m in self._client.sscan_iter(\n           self.key_prefix, match=\"*\", count=count):\n            yield _loads(m)", "response": "Iterate over the set members in the set that are in the set by the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef incr(self, member, by=1):\n        return self._client.zincrby(self.key_prefix, self._dumps(member), by)", "response": "Increments the value of a key within the sorted set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, *args, **kwargs):\n        if args or kwargs:\n            _dumps = self._dumps\n            zargs = list(args)\n            if args and self.serialized:\n                # args format: value, key, value, key...\n                zargs = [\n                    _dumps(x) if (i % 2 == 1 and self.serialized) else x\n                    for i, x in enumerate(args)]\n            if kwargs:\n                # kwargs format: key=value, key=value\n                zargs += [\n                    _dumps(x) if (i % 2 == 1 and self.serialized) else x\n                    for y in kwargs.items() for i, x in enumerate(reversed(y))]\n            return self._client.zadd(self.key_prefix, *zargs)", "response": "Adds member pairs to the sorted set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, data):\n        if data:\n            _dumps = self._dumps\n            zargs = [\n                _dumps(x) if (i % 2 == 1) else x\n                for y in data.items()\n                for i, x in enumerate(reversed(y))\n            ]\n            return self._client.zadd(self.key_prefix, *zargs)", "response": "Adds the data to the sorted set\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self, *members):\n        members = list(map(self._dumps, members))\n        self._client.zrem(self.key_prefix, *members)", "response": "Removes members from the sorted set"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rank(self, member):\n        if self.reversed:\n            return self._client.zrevrank(self.key_prefix, self._dumps(member))\n        return self._client.zrank(self.key_prefix, self._dumps(member))", "response": "Gets the ASC rank of the given member from the sorted set that is the highest scores have lower scores."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count(self, min, max):\n        return self._client.zcount(self.key_prefix, min, max)", "response": "Count the number of elements in the sorted set between the two given timestamps."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over the set members in the cluster.", "response": "def iter(self, start=0, stop=-1, withscores=False, reverse=None):\n        \"\"\" Return a range of values from sorted set name between\n            @start and @end sorted in ascending order unless @reverse or\n            :prop:reversed.\n\n            @start and @end: #int, can be negative, indicating the end of\n                the range.\n            @withscores: #bool indicates to return the scores along with the\n                members, as a list of |(member, score)| pairs\n            @reverse: #bool indicating whether to sort the results descendingly\n\n            -> yields members or |(member, score)| #tuple pairs\n        \"\"\"\n        reverse = reverse if reverse is not None else self.reversed\n        _loads = self._loads\n        for member in self._client.zrange(\n           self.key_prefix, start=start, end=stop, withscores=withscores,\n           desc=reverse, score_cast_func=self.cast):\n            if withscores:\n                yield (_loads(member[0]), self.cast(member[1]))\n            else:\n                yield _loads(member)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over the sorted set name with scores between min and max.", "response": "def iterbyscore(self, min='-inf', max='+inf', start=None, num=None,\n                    withscores=False, reverse=None):\n        \"\"\" Return a range of values from the sorted set name with scores\n            between @min and @max.\n\n            If @start and @num are specified, then return a slice\n            of the range.\n\n            @min: #int minimum score, or #str '-inf'\n            @max: #int minimum score, or #str '+inf'\n            @start: #int starting range position\n            @num: #int number of members to fetch\n            @withscores: #bool indicates to return the scores along with the\n                members, as a list of |(member, score)| pairs\n            @reverse: #bool indicating whether to sort the results descendingly\n\n            -> yields members or |(member, score)| #tuple pairs\n        \"\"\"\n        reverse = reverse if reverse is not None else self.reversed\n        zfunc = self._client.zrangebyscore if not reverse \\\n            else self._client.zrevrangebyscore\n        _loads = self._loads\n        for member in zfunc(\n           self.key_prefix, min=min, max=max, start=start, num=num,\n           withscores=withscores, score_cast_func=self.cast):\n            if withscores:\n                yield (_loads(member[0]), self.cast(member[1]))\n            else:\n                yield _loads(member)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a range of |tuple| objects from the sorted set name with scores between min and max.", "response": "def itemsbyscore(self, min='-inf', max='+inf', start=None, num=None,\n                     reverse=None):\n        \"\"\" Return a range of |(member, score)| pairs from the sorted set name\n            with scores between @min and @max.\n\n            If @start and @num are specified, then return a slice\n            of the range.\n\n            @min: #int minimum score, or #str '-inf'\n            @max: #int minimum score, or #str '+inf'\n            @start: #int starting range position\n            @num: #int number of members to fetch\n            @reverse: #bool indicating whether to sort the results descendingly\n\n            -> yields |(member, score)| #tuple pairs\n        \"\"\"\n        reverse = reverse if reverse is not None else self.reversed\n        for member in self.iterbyscore(\n           min, max, start, num, withscores=True, reverse=reverse):\n            yield member"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan(self, match=\"*\", count=1000, cursor=0):\n        if self.serialized:\n            cursor, data = self._client.zscan(\n                self.key_prefix, cursor=cursor, match=match, count=count)\n            return (cursor, list(map(\n                lambda x: (self._loads(x[0]), self.cast(x[1])), data)))\n        else:\n            cursor, data = self._client.zscan(\n                self.key_prefix, cursor=cursor, match=match, count=count)\n            return (cursor, list(map(\n                lambda x: (self._decode(x[0]), self.cast(x[1])), data)))", "response": ":see :: meth : RedisMap. scan"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compare_password(expected, actual):\n    if expected == actual:\n        return True, \"OK\"\n    msg = []\n    ver_exp = expected[-8:].rstrip()\n    ver_act = actual[-8:].rstrip()\n\n    if expected[:-8] != actual[:-8]:\n        msg.append(\"Password mismatch\")\n    if ver_exp != ver_act:\n        msg.append(\"asterisk_mbox version mismatch.  Client: '\" +\n                   ver_act + \"',  Server: '\" + ver_exp + \"'\")\n    return False, \". \".join(msg)", "response": "Compare two 64byte encoded passwords."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncoerces numeric list inst sha - looking bytearray", "response": "def encode_to_sha(msg):\n    \"\"\"coerce numeric list inst sha-looking bytearray\"\"\"\n    if isinstance(msg, str):\n        msg = msg.encode('utf-8')\n    return (codecs.encode(msg, \"hex_codec\") + (b'00' * 32))[:64]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_from_sha(sha):\n    if isinstance(sha, str):\n        sha = sha.encode('utf-8')\n    return codecs.decode(re.sub(rb'(00)*$', b'', sha), \"hex_codec\")", "response": "convert coerced sha back into numeric list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nputs an item to the cache.", "response": "def put(self, item, block=True, timeout=None):\n        \"\"\"put.\"\"\"\n        super().put(item, block, timeout)\n        self._putsocket.send(b'x')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, block=True, timeout=None):\n        try:\n            item = super().get(block, timeout)\n            self._getsocket.recv(1)\n            return item\n        except queue.Empty:\n            raise queue.Empty", "response": "get. Blocks until a message is available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _api_path(self, item):\n        if self.base_url is None:\n            raise NotImplementedError(\"base_url not set\")\n        path = \"/\".join([x.blob[\"id\"] for x in item.path])\n        return \"/\".join([self.base_url, path])", "response": "Get the API path for the current cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns at parse time.", "response": "def run(self):\n        \"\"\" Run at parse time.\n\n        When the documents are initially being scanned, this method runs\n        and does two things: (a) creates an instance that is added to\n        the site's widgets, and (b) leaves behind a placeholder docutils\n        node that can later be processed after the docs are resolved.\n        The latter needs enough information to retrieve the former.\n\n        \"\"\"\n\n        this_widget = self.get_widget(self.docname)\n\n        self.widgets[repr(this_widget)] = this_widget\n\n        # Now add the node to the doctree\n        widget_node = widget()\n        ids = [repr(this_widget)]\n        names = [self.name]\n        attrs = dict(ids=ids, names=names)\n        widget_node.update_basic_atts(attrs)\n        return [widget_node]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_references(kb_app: kb,\n                        sphinx_app: Sphinx,\n                        sphinx_env: BuildEnvironment,\n                        docnames: List[str]):\n    \"\"\" Walk the registry and add sphinx directives \"\"\"\n\n    references: ReferencesContainer = sphinx_app.env.references\n\n    for name, klass in kb_app.config.resources.items():\n        # Name is the value in the decorator and directive, e.g.\n        # @kb.resource('category') means name=category\n        if getattr(klass, 'is_reference', False):\n            references[name] = dict()", "response": "Register the references to the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters handlers from discovered handler classes.", "response": "def register_handlers(self, handler_classes):\n        \"\"\"\n        Create handlers from discovered handler classes\n\n        :param handler_classes: List of :class:`~responsebot.handlers.base.BaseTweetHandler`'s derived classes\n        \"\"\"\n        for handler_class in handler_classes:\n            self.handlers.append(handler_class(client=self.client))\n            logging.info('Successfully registered {handler_class}'.format(\n                handler_class=getattr(handler_class, '__name__', str(handler_class)))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_tweet(self, tweet):\n        logging.info(u'Received tweet: `{message}`'.format(message=tweet.text))\n\n        for handler in self.handlers:\n            if not handler.catch_self_tweets and self.is_self_tweet(tweet):\n                continue\n\n            if not handler.filter.match_tweet(tweet=tweet, user_stream=self.client.config.get('user_stream')):\n                continue\n\n            handler.on_tweet(tweet)", "response": "Callback to receive a tweet from the response bot stream. Tries to forward the tweet to registered handlers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_event(self, event):\n        if event.event not in TWITTER_NON_TWEET_EVENTS:\n            logging.warning(u'Received unknown twitter event {event}'.format(event=event.event))\n            return\n\n        logging.info(u'Received event {event}'.format(event=event.event))\n\n        for handler in self.handlers:\n            handler.on_event(event)", "response": "Callback to receive events from the response bot stream. Tries to forward the event to registered handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns merged filter from list of handlers", "response": "def get_merged_filter(self):\n        \"\"\"\n        Return merged filter from list of handlers\n\n        :return: merged filter\n        :rtype: :class:`~responsebot.models.TweetFilter`\n        \"\"\"\n        track = set()\n        follow = set()\n\n        for handler in self.handlers:\n            track.update(handler.filter.track)\n            follow.update(handler.filter.follow)\n\n        return TweetFilter(track=list(track), follow=list(follow))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_domain(url):\n    parse_result = urlparse(url)\n    domain = \"{schema}://{netloc}\".format(\n        schema=parse_result.scheme, netloc=parse_result.netloc)\n    return domain", "response": "Get domain part of an url."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\njoin all url components.", "response": "def join_all(domain, *parts):\n    \"\"\"\n    Join all url components.\n\n    Example::\n\n        >>> join_all(\"https://www.apple.com\", \"iphone\")\n        https://www.apple.com/iphone\n\n    :param domain: Domain parts, example: https://www.python.org\n    :param parts: Other parts, example: \"/doc\", \"/py27\"\n    :return: url\n    \"\"\"\n    l = list()\n\n    if domain.endswith(\"/\"):\n        domain = domain[:-1]\n    l.append(domain)\n\n    for part in parts:\n        for i in part.split(\"/\"):\n            if i.strip():\n                l.append(i)\n    url = \"/\".join(l)\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncombines query endpoint and params.", "response": "def add_params(endpoint, params):\n    \"\"\"\n    Combine query endpoint and params.\n\n    Example::\n\n        >>> add_params(\"https://www.google.com/search\", {\"q\": \"iphone\"})\n        https://www.google.com/search?q=iphone\n    \"\"\"\n    p = PreparedRequest()\n    p.prepare(url=endpoint, params=params)\n    if PY2:  # pragma: no cover\n        return unicode(p.url)\n    else:  # pragma: no cover\n        return p.url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate expression using the given globals and locals dictionaries as global and local namespace.", "response": "def neval(expression, globals=None, locals=None, **kwargs):\n    \"\"\"Evaluate *expression* using *globals* and *locals* dictionaries as\n    *global* and *local* namespace.  *expression* is transformed using\n    :class:`.NapiTransformer`.\"\"\"\n\n    try:\n        import __builtin__ as builtins\n    except ImportError:\n        import builtins\n\n    from ast import parse\n    from ast import fix_missing_locations as fml\n\n    try:\n        transformer = kwargs['transformer']\n    except KeyError:\n        from napi.transformers import NapiTransformer as transformer\n\n    #try:\n    node = parse(expression, '<string>', 'eval')\n    #except ImportError:\n    #    builtins.eval(expression)\n    #else:\n    if globals is None:\n        globals = builtins.globals()\n    if locals is None:\n        locals = {}\n    trans = transformer(globals=globals, locals=locals, **kwargs)\n    trans.visit(node)\n    code = compile(fml(node), '<string>', 'eval')\n    return builtins.eval(code, globals, locals)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a statement using the napi. transformers. NapiTransformer module.", "response": "def nexec(statement, globals=None, locals=None, **kwargs):\n    \"\"\"Execute *statement* using *globals* and *locals* dictionaries as\n    *global* and *local* namespace.  *statement* is transformed using\n    :class:`.NapiTransformer`.\"\"\"\n\n    try:\n        import __builtin__ as builtins\n    except ImportError:\n        import builtins\n\n    from ast import parse\n    from napi.transformers import NapiTransformer\n    from ast import fix_missing_locations as fml\n    try:\n        node = parse(statement, '<string>', 'exec')\n    except ImportError:#KeyError:\n        exec(statement)\n    else:\n        if globals is None:\n            globals = builtins.globals()\n        if locals is None:\n            locals = {}\n        trans = NapiTransformer(globals=globals, locals=locals, **kwargs)\n        trans.visit(node)\n        code = compile(fml(node), '<string>', 'exec')\n        return builtins.eval(code, globals, locals)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, oldversion):\n    # print ctx.bubble\n    path = ctx.home\n    bubble_file_name = path + '/.bubble'\n    config_file = path + '/config/config.yaml'\n\n    if file_exists(bubble_file_name):\n        pass\n    else:\n        with open(bubble_file_name, 'w') as dot_bubble:\n            dot_bubble.write('bubble=' + metadata.version)\n            dot_bubble.write('\\nconfig=' + config_file)\n\n        ctx.say_green('Initialised a  new bubble in [%s]' %\n                      click.format_filename(bubble_file_name))\n\n    create_dir(ctx, path + '/config/')\n    create_dir(ctx, path + '/logs/')\n    create_dir(ctx, path + '/export/')\n    create_dir(ctx, path + '/import/')\n    create_dir(ctx, path + '/remember/')\n    create_dir(ctx, path + '/remember/archive')\n\n    rules_file = path + '/config/rules.bubble'\n    if file_exists(bubble_file_name):\n        pass\n    else:\n        with open(rules_file, 'w') as rules:\n            rules.write(get_example_rules_bubble())\n            ctx.say_green('Created an example rules in [%s]' %\n                          click.format_filename(rules_file))\n\n    rule_functions_file = path + '/custom_rule_functions.py'\n    if file_exists(rule_functions_file):\n        pass\n    else:\n        with open(rule_functions_file, 'w') as rule_functions:\n            rule_functions.write(get_example_rule_functions())\n            ctx.say_green('Created an example rule_functions in [%s]' %\n                          click.format_filename(rule_functions_file))\n\n    ctx.say_green('Bubble upgraded')", "response": "Upgrade the current bubble"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting the files in the local maildir.", "response": "def _list_remote(store, maildir, verbose=False):\n    \"\"\"List the a maildir.\n\n    store is an abstract representation of the source maildir. \n\n    maildir is the local maildir to which mail will be pulled.\n\n    This is a generator for a reason. Because of the way ssh\n    multi-mastering works a single open TCP connection allows multiple\n    virtual ssh connections. So the encryption and tcp only has to be\n    done once.\n\n    If this command returned a list then the ssh list command would\n    have finished and the ssh connection for each message would have\n    to be made again.\n    \"\"\"\n    # This command produces a list of all files in the maildir like:\n    #   base-filename timestamp container-directory\n    command = \"\"\"echo {maildir}/{{cur,new}} | tr ' ' '\\\\n' | while read path ; do ls -1Ugo --time-style=+%s $path | sed -rne \"s|[a-zA-Z-]+[ \\t]+[0-9]+[ \\t]+[0-9]+[ \\t]+([0-9]+)[ \\t]+([0-9]+\\\\.[A-Za-z0-9]+)(\\\\.([.A-Za-z0-9-]+))*(:[2],([PRSTDF]*))*|\\\\2 \\\\1 $path|p\";done\"\"\"\n    stdout = store.cmd(command, verbose)\n    lines = stdout.split(\"\\n\")\n    for line in lines:\n        parts = line.split(\" \")\n        if len(parts) >= 3:\n            yield parts[0:3]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sshpull(host, maildir, localmaildir, noop=False, verbose=False, filterfile=None):\n    store = _SSHStore(host, maildir)\n    _pull(store, localmaildir, noop, verbose, filterfile)", "response": "Pull a maildir from the local one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filepull(maildir, localmaildir, noop=False, verbose=False, filterfile=None):\n    store = _Store(maildir)\n    _pull(store, localmaildir, noop, verbose, filterfile)", "response": "Pull one local maildir into another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering msgdata by mailfilters", "response": "def _filter(msgdata, mailparser, mdfolder, mailfilters):\n    \"\"\"Filter msgdata by mailfilters\"\"\"\n    if mailfilters:\n        for f in mailfilters:\n            msg = mailparser.parse(StringIO(msgdata))\n            rule = f(msg, folder=mdfolder)\n            if rule:\n                yield rule\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the specified command on the remote host.", "response": "def cmd(self, cmd, verbose=False):\n        \"\"\"Executes the specified command on the remote host.\n\n        The cmd must be format safe, this means { and } must be doubled, thusly:\n\n          echo /var/local/maildir/{{cur,new}}\n\n        the cmd can include the format word 'maildir' to be replaced\n        by self.directory. eg:\n\n          echo {maildir}/{{cur,new}}\n        \"\"\"\n        command = cmd.format(maildir=self.directory)\n        if verbose:\n            print(command)\n        p = Popen([\n                \"ssh\",\n                \"-T\",\n                self.host,\n                command\n                ], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n        stdout,stderr = p.communicate()\n        return stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_result(self):\n        results = self.soup.find_all('div', {'class': 'container container-small'})\n        href = None\n        is_match = False\n\n        i = 0\n        while i < len(results) and not is_match:\n            result = results[i]\n            anchor = result.find('a', {'rel': 'bookmark'})\n            is_match = self._filter_results(result, anchor)\n            href = anchor['href']\n\n            i += 1\n\n        try:\n            page = get_soup(href)\n        except (Exception):\n            page = None\n\n        # Return page if search is successful\n        if href and page:\n            return page\n        else:\n            raise PageNotFoundError(PAGE_ERROR)", "response": "Return a list of urls for each search result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _filter_results(self, result, anchor):\n        valid = True\n\n        try:\n            cat_tag = result.find('a', {'rel': 'category tag'}).string\n            title = anchor.string.lower()\n            date_tag = result.find('time').string\n        except (AttributeError, TypeError):\n            return False      \n             \n        if cat_tag != \"Daily Ratings\":\n            valid = False\n        if not date_in_range(self.date, date_tag, 5):\n            valid = False\n        if self.category == 'cable' and 'cable' not in title:\n            valid = False\n        elif self.category != 'cable' and 'cable' in title:\n            valid = False\n\n        return valid", "response": "Filter search results by checking category titles and dates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild url based on date or show.", "response": "def _build_url(self):\n        \"\"\"Build url based on searching by date or by show.\"\"\"\n        url_params = [\n            BASE_URL, self.category + ' ratings', self.day, self.year, self.month\n        ]\n\n        return SEARCH_URL.format(*url_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_response(self, url, **params):\n        data = urlencode(params)\n        url = \"%s?%s\" % (url, data)\n        headers = {'User-Agent': self.get_random_agent()}\n        request = Request(url, headers=headers, method='GET')\n\n        def open_request(request, attempts, err=None):\n            if attempts > self.request_attempts:\n                raise\n            attempts += 1\n            try:\n                with urlopen(request, timeout=self.timeout) as response:\n                    return response.read()\n            except HTTPError as err:\n                if err.getcode() < 500:\n                    raise\n                print(\"HTTPError occurred while trying to request the url \"\n                      \"%s. %s. Trying again in %s seconds...\" % (url, err,\n                                                self.seconds_between_attempts))\n                time.sleep(self.seconds_between_attempts)\n                return open_request(request, attempts, err)\n\n        attempts = 0\n        self.last_response = open_request(request, attempts)\n        return self.last_response", "response": "Giving a service path and optional specific arguments returns\n        the response string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_response(self, path, **params):\n        url = \"%s%s\" % (self.base_url, path)\n        return self._get_response(url, **params)", "response": "Giving a service path and optional specific arguments returns\n        the response string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data(self, path, **params):\n        xml = self.get_response(path, **params)\n        try:\n            return parse(xml)\n        except Exception as err:\n            print(path)\n            print(params)\n            print(err)\n            raise", "response": "Giving a service path and optional specific arguments returns\n            the XML data from the API parsed as a dict structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun on given port.", "response": "def run(self, port): # pragma: no coverage\n        \"\"\"\n        Run on given port. Parse standard options and start the http server.\n        \"\"\"\n        tornado.options.parse_command_line()\n        http_server = tornado.httpserver.HTTPServer(self)\n        http_server.listen(port)\n        tornado.ioloop.IOLoop.instance().start()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride base method to log requests to JSON UDP collector and emit a metric.", "response": "def log_request(self, handler):\n        \"\"\"\n        Override base method to log requests to JSON UDP collector and emit\n        a metric.\n        \"\"\"\n        packet = {'method': handler.request.method,\n                  'uri': handler.request.uri,\n                  'remote_ip': handler.request.remote_ip,\n                  'status': handler.get_status(),\n                  'request_time_ms': handler.request.request_time() * 1000.0,\n                  'service_id': self.service_id,\n                  'request_id': handler.request.headers.get(REQUEST_ID_HEADER,\n                                                            'undefined')\n                  }\n\n        # handler can optionally define additional data to log\n        if hasattr(handler, 'logvalues'):\n            for key, value in handler.logvalues.iteritems():\n                packet[key] = value\n\n        servicelog.log(packet)\n\n        metric = \"requests.\" + str(handler.get_status())\n        metrics.timing(metric, handler.request.request_time() * 1000.0)\n\n        super(LoggingApplication, self).log_request(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds log entry to request log info", "response": "def logvalue(self, key, value):\n        \"\"\"Add log entry to request log info\"\"\"\n        if not hasattr(self, 'logvalues'):\n            self.logvalues = {}\n        self.logvalues[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_error(self, status_code, **kwargs):\n        message = default_message = httplib.responses.get(status_code, '')\n        # HTTPError exceptions may have a log_message attribute\n        if 'exc_info' in kwargs:\n            (_, exc, _) = kwargs['exc_info']\n            if hasattr(exc, 'log_message'):\n                message = str(exc.log_message) or default_message\n        self.logvalue('halt_reason', message)\n        title = \"{}: {}\".format(status_code, default_message)\n        body = \"{}: {}\".format(status_code, message)\n        self.finish(\"<html><title>\" + title + \"</title>\"\n                    \"<body>\" + body + \"</body></html>\")", "response": "Log halt_reason in service log and output error page"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntime execution of callable and emit metric then return result.", "response": "def timeit(self, metric, func, *args, **kwargs):\n        \"\"\"Time execution of callable and emit metric then return result.\"\"\"\n        return metrics.timeit(metric, func, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef require_content_type(self, content_type):\n        if self.request.headers.get('content-type', '') != content_type:\n            self.halt(400, 'Content type must be ' + content_type)", "response": "Raises a 400 if request content type is not as specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the headers of the current object.", "response": "def set_headers(self, headers):\n        \"\"\"Set headers\"\"\"\n        for (header, value) in headers.iteritems():\n            self.set_header(header, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ensure_request_id_header(self):\n        \"Ensure request headers have a request ID. Set one if needed.\"\n        if REQUEST_ID_HEADER not in self.request.headers:\n            self.request.headers.add(REQUEST_ID_HEADER, uuid.uuid1().hex)", "response": "Ensure request headers have a request ID. Set one if needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the parameters from a file", "response": "def load_parameters(self, source):\n        \"\"\"For YML, the source it the file path\"\"\"\n        with open(source) as parameters_source:\n            loaded = yaml.safe_load(parameters_source.read())\n            for k, v in loaded.items():\n                if isinstance(v, str):\n                    loaded[k] = \"'\"+v+\"'\"\n            return loaded"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the configuration from a file.", "response": "def load_config(self, config_source, parameters_source):\n        \"\"\"For YML, the source it the file path\"\"\"\n        with open(config_source) as config_source:\n            config_raw = config_source.read()\n\n            parameters = {}\n            \"\"\"Parameteres from file\"\"\"\n            if os.path.isfile(parameters_source):\n                params = self.load_parameters(parameters_source)\n                if params is not None:\n                    parameters.update(params)\n\n            \"\"\"Overwrite parameteres with the environment variables\"\"\"\n            env_params = {}\n            env_params.update(os.environ)\n            for k, v in env_params.items():\n                if is_string(v):\n                    env_params[k] = \"'\" + v + \"'\"\n\n            parameters.update(env_params)\n\n            \"\"\"Replace the parameters\"\"\"\n            final_configuration = config_raw.format(**parameters)\n            final_configuration = yaml.safe_load(final_configuration)\n            return final_configuration if final_configuration is not None else {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_config(self, config_source, parameters_source):\n        with open(config_source) as config_source:\n            config_raw = config_source.read()\n            \"\"\"Replace the parameters\"\"\"\n            pattern = \"(%[a-zA-Z_0-9]*%)\"\n\n            self.parameters = {}\n            \"\"\"Parameteres from file\"\"\"\n            if os.path.isfile(parameters_source):\n                self.parameters.update(self.load_parameters(parameters_source))\n\n            \"\"\"Overwrite parameteres with the environment variables\"\"\"\n            self.parameters.update(os.environ)\n\n            replaced_config = re.sub(pattern=pattern, repl=self._replace_function, string=config_raw)\n            return json.loads(replaced_config)", "response": "Load the config from a file and return the config as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    if len(argv) < 2:\n        targetfile = 'target.y'\n    else:\n        targetfile = argv[1]\n    print 'Parsing ruleset: ' + targetfile,\n    flex_a = Flexparser()\n    mma = flex_a.yyparse(targetfile)\n    print 'OK'\n    print 'Perform minimization on initial automaton:',\n    mma.minimize()\n    print 'OK'\n    print 'Perform StateRemoval on minimal automaton:',\n    state_removal = StateRemoval(mma)\n    mma_regex = state_removal.get_regex()\n    print mma_regex", "response": "Testing function for DFA _Brzozowski Operation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstate Removal Operation Initialization", "response": "def _state_removal_init(self):\n        \"\"\"State Removal Operation Initialization\"\"\"\n        # First, we remove all multi-edges:\n        for state_i in self.mma.states:\n            for state_j in self.mma.states:\n                if state_i.stateid == state_j.stateid:\n                    self.l_transitions[\n                        state_i.stateid, state_j.stateid] = self.epsilon\n                else:\n                    self.l_transitions[\n                        state_i.stateid, state_j.stateid] = self.empty\n\n                for arc in state_i.arcs:\n                    if arc.nextstate == state_j.stateid:\n                        if self.l_transitions[state_i.stateid, state_j.stateid] != self.empty:\n                            self.l_transitions[state_i.stateid, state_j.stateid] \\\n                                += self.mma.isyms.find(arc.ilabel)\n                        else:\n                            self.l_transitions[state_i.stateid, state_j.stateid] = \\\n                                self.mma.isyms.find(arc.ilabel)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _state_removal_remove(self, k):\n        for state_i in self.mma.states:\n            for state_j in self.mma.states:\n                if self.l_transitions[state_i.stateid, k] != self.empty:\n                    l_ik = self.l_transitions[state_i.stateid, k]\n                else:\n                    l_ik = \"\"\n                if self.l_transitions[state_j.stateid, k] != self.empty:\n                    l_jk = self.l_transitions[state_j.stateid, k]\n                else:\n                    l_jk = \"\"\n                if self.l_transitions[k, state_i.stateid] != self.empty:\n                    l_ki = self.l_transitions[k, state_i.stateid]\n                else:\n                    l_ki = \"\"\n                if self.l_transitions[k, state_j.stateid] != self.empty:\n                    l_kj = self.l_transitions[k, state_j.stateid]\n                else:\n                    l_kj = \"\"\n\n                if self.l_transitions[state_i.stateid, state_i.stateid] != self.empty:\n                    self.l_transitions[state_i.stateid, state_i.stateid] += l_ik + \\\n                        self.star(self.l_transitions[k, k]) + l_ki\n                else:\n                    self.l_transitions[state_i.stateid, state_i.stateid] = l_ik + \\\n                        self.star(self.l_transitions[k, k]) + l_ki\n\n                if self.l_transitions[state_j.stateid, state_j.stateid] != self.empty:\n                    self.l_transitions[state_j.stateid, state_j.stateid] += l_jk + \\\n                        self.star(self.l_transitions[k, k]) + l_kj\n                else:\n                    self.l_transitions[state_j.stateid, state_j.stateid] = l_jk + \\\n                        self.star(self.l_transitions[k, k]) + l_kj\n\n                if self.l_transitions[state_i.stateid, state_j.stateid] != self.empty:\n                    self.l_transitions[state_i.stateid, state_j.stateid] += l_ik + \\\n                        self.star(self.l_transitions[k, k]) + l_kj\n                else:\n                    self.l_transitions[state_i.stateid, state_j.stateid] = l_ik + \\\n                        self.star(self.l_transitions[k, k]) + l_kj\n\n                if self.l_transitions[state_j.stateid, state_i.stateid] != self.empty:\n                    self.l_transitions[state_j.stateid, state_i.stateid] += l_jk + \\\n                        self.star(self.l_transitions[k, k]) + l_ki\n                else:\n                    self.l_transitions[state_j.stateid, state_i.stateid] = l_jk + \\\n                        self.star(self.l_transitions[k, k]) + l_ki", "response": "Internal function to remove a state from the state machine."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting from memory to format supported by tablib", "response": "def cli(ctx,\n        amount,\n        index,\n        stage,\n        stepresult,\n        formattype,\n        select,\n        where,\n        order,\n        outputfile,\n        showkeys,\n        showvalues,\n        showalways,\n        position):\n    \"\"\"Export from memory to format supported by tablib\"\"\"\n    if not ctx.bubble:\n        msg = 'There is no bubble present, will not export'\n        ctx.say_yellow(msg)\n        raise click.Abort()\n    path = ctx.home + '/'\n\n    if stage not in STAGES:\n        ctx.say_yellow('There is no known stage:' + stage)\n        raise click.Abort()\n    if stepresult not in exportables:\n        ctx.say_yellow('stepresult not one of: ' + ', '.join(exportables))\n        raise click.Abort()\n\n    data_gen = bubble_lod_load(ctx, stepresult, stage)\n\n    ctx.gbc.say('data_gen:', stuff=data_gen, verbosity=20)\n\n    part = get_gen_slice(ctx.gbc, data_gen, amount, index)\n    ctx.gbc.say('selected part:', stuff=part, verbosity=20)\n\n    aliases = get_pairs(ctx.gbc, select, missing_colon=True)\n    if position or len(aliases) == 0:\n        ctx.gbc.say('adding position to selection of columns:',\n                    stuff=aliases, verbosity=20)\n        aliases.insert(0, {'key': buts('index'), 'val': 'BUBBLE_IDX'})\n        ctx.gbc.say('added position to selection of columns:',\n                    stuff=aliases, verbosity=20)\n\n    wheres = get_pairs(ctx.gbc, where)\n    # TODO: use aliases as lookup for wheres\n\n    data = tablib.Dataset()\n\n    data.headers = [sel['val'] for sel in aliases]\n    ctx.gbc.say('select wheres:' + str(wheres), verbosity=20)\n    ctx.gbc.say('select aliases:' + str(aliases), verbosity=20)\n    ctx.gbc.say('select data.headers:' + str(data.headers), verbosity=20)\n\n    not_shown = True\n    try:\n        for ditem in part:\n            row = []\n            ctx.gbc.say('curr dict', stuff=ditem, verbosity=101)\n\n            flitem = flat(ctx, ditem)\n            ctx.gbc.say('curr flat dict', stuff=flitem, verbosity=101)\n            row_ok = True\n            for wp in wheres:\n                # TODO: negative selects: k:None, k:False,k:Zero,k:Null,k:0,k:-1,k:'',k:\"\",\n                # TODO: negative selects:\n                # k:BUBBLE_NO_KEY,k:BUBBLE_NO_VAL,k:BUBBLE_NO_KEY_OR_NO_VAL\n\n                wcheck_key=True\n                if wp['key'] not in flitem:\n                    row_ok = False\n                    wcheck_key=False\n                if wcheck_key and wp['val'] not in str(flitem[wp['key']]):\n                    row_ok = False\n            if not row_ok:\n                continue\n\n            for sel in aliases:\n                if sel['key'] in flitem:\n                    row.append(flitem[sel['key']])\n                else:\n                    # temporary to check, not use case for buts()\n                    bnp = '____BTS_NO_PATH_'\n                    tempv = get_flat_path(ctx, flitem, sel['key'] + '.*', bnp)\n                    if tempv != bnp:\n                        row.append(tempv)\n                    else:\n                        row.append('None')\n                        # TODO maybe 'NONE', or just '' or something like:\n                        # magic.export_format_none\n\n            data.append(row)\n            # todo: count keys, and show all keys in selection: i,a\n            if not_shown and showkeys:\n                if not showalways:\n                    not_shown = False\n                ks = list(flitem.keys())\n                ks.sort()\n                ctx.say(\n                    'available dict path keys from first selected dict:', verbosity=0)\n                for k in ks:\n                    ctx.say('keypath: ' + k, verbosity=0)\n                    if showvalues:\n                        ctx.say('value: ' + str(flitem[k]) + '\\n', verbosity=0)\n\n    except Exception as excpt:\n        ctx.say_red('Cannot export data', stuff=excpt)\n        raise click.Abort()\n\n    if not outputfile:\n        outputfile = path + 'export/export_' + \\\n            stepresult + '_' + stage + '.' + formattype\n\n    # todo: order key must be present in selection\n    # add to selection before\n    # and remove from result before output to format.\n    if order:\n        olast2 = order[-2:]\n        ctx.gbc.say('order:' + order + ' last2:' + olast2, verbosity=100)\n        if olast2 not in [':+', ':-']:\n            data = data.sort(order, False)\n        else:\n            if olast2 == ':+':\n                data = data.sort(order[:-2], False)\n            if olast2 == ':-':\n                data = data.sort(order[:-2], True)\n\n    # Write `spreadsheet` to disk\n    formatted = None\n    if formattype == 'yaml':\n        formatted = data.yaml\n    if formattype == 'json':\n        formatted = data.json\n    if formattype == 'csv':\n        formatted = data.csv\n\n    # TODO:\n    # if formattype == 'ldif':\n    #    formatted = data.ldif\n\n    if formattype == 'tab':\n        # standard, output, whatever tablib makes of it, ascii table\n        print(data)\n\n    if formatted:\n        enc_formatted = formatted.encode('utf-8')\n        of_path = opath.Path(outputfile)\n        of_dir = of_path.dirname()\n        if not of_dir.exists():\n            of_dir.makedirs_p()\n\n        with open(outputfile, 'wb') as f:\n            f.write(enc_formatted)\n            ctx.say_green('exported: ' + outputfile)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, *args, **kwargs):\n        stripped_name = ' '.join(\n            w for w in self.organization.name.split()\n            if w not in STOPWORDS\n        )\n\n        if not self.slug:\n            self.slug = uuslug(\n                stripped_name,\n                instance=self,\n                max_length=100,\n                separator='-',\n                start_no=2\n            )\n        self.uid = '{}_body:{}'.format(\n            self.jurisdiction.uid, slugify(stripped_name))\n\n        super(Body, self).save(*args, **kwargs)", "response": "Save the object to the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_elangles(self):\n        elang_list = list(self.attr_gen('elangle'))\n        try:\n            elevation_angles = sorted(zip(*elang_list)[1])\n            n_elangles = len(elevation_angles)\n            self.elangles = dict(zip(list(string.ascii_uppercase[:n_elangles]), elevation_angles))\n        except IndexError:\n            self.elangles = {}", "response": "Sets the values of instance variable elangles. This method creates a dictionary containing the elangles of the pvol file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_dataset(self, elangle, quantity):\n        elangle_path = None\n        try:\n            search_results = self.search('elangle', self.elangles[elangle])\n        except KeyError:\n            return None\n\n        if search_results == []:\n            print('Elevation angle {} is not found from file'.format(elangle))\n            print('File contains elevation angles:{}'.format(self.elangles))\n        else:\n            elangle_path = search_results[0]\n                    \n        if elangle_path is not None:\n            dataset_root = re.search( '^/dataset[0-9]+/', elangle_path).group(0) \n            quantity_path = None\n            search_results = self.search('quantity', quantity)\n\n            for path in search_results:\n                if dataset_root in path:\n                    quantity_path = path\n                    break\n                    \n            if quantity_path is not None:\n                dataset_path = re.search('^/dataset[0-9]+/data[0-9]/', quantity_path).group(0)            \n                dataset_path = os.path.join(dataset_path, 'data')\n                if isinstance(self[dataset_path], h5py.Dataset):\n                    self.dataset = self[dataset_path].ref\n                    return dataset_path", "response": "Selects the matching dataset and returns its path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sector(self, start_ray, end_ray, start_distance=None, end_distance=None, units='b'):\n        if self.dataset is None:\n            raise ValueError('Dataset is not selected')\n\n        # Validate parameter values        \n        ray_max, distance_max = self.dataset.shape\n        if start_ray > ray_max:\n            raise ValueError('Value of start_ray is bigger than the number of rays')\n        if start_ray < 0:\n            raise ValueError('start_ray must be non negative')\n            \n\n            \n        if start_distance is None:\n            start_distance_index = 0\n        else:\n            if units == 'b':\n                start_distance_index = start_distance\n            elif units == 'm': \n                try:\n                    rscale = next(self.attr_gen('rscale')).value\n                except:\n                    raise MissingMetadataError            \n                start_distance_index = int(start_distance / rscale)\n        if end_distance is None:\n            end_distance_index = self.dataset.shape[1]\n        else:\n            if units == 'b':\n                end_distance_index = end_distance           \n            elif units == 'm':             \n                end_distance_index = int(end_distance / rscale) \n\n        if end_ray is None:\n            sector = self.dataset[start_ray, start_distance_index:end_distance_index]\n        else:\n            if start_ray <= end_ray:\n                sector = self.dataset[start_ray:end_ray+1, start_distance_index:end_distance_index]\n            else:\n                sector1 = self.dataset[start_ray:, start_distance_index:end_distance_index]\n                sector2 = self.dataset[:end_ray+1, start_distance_index:end_distance_index]\n                sector = np.concatenate((sector1, sector2), axis=0)\n        return sector", "response": "Slices a sector from the selected dataset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_dataset(self, quantity):\n        \n        # Files with a following dataset structure.\n        # Location of 'quantity' attribute: /dataset1/data1/what\n        # Dataset path structure: /dataset1/data1/data\n        search_results = self.search('quantity', quantity)\n        try:\n            quantity_path = search_results[0]\n        except IndexError:\n            print('Attribute quantity=\\'{}\\' was not found from file'.format(quantity))\n            return None\n        full_dataset_path = quantity_path.replace('/what', '/data')\n\n        try:\n            if isinstance(self[full_dataset_path], h5py.Dataset):\n                self.dataset = self[full_dataset_path].ref\n                return full_dataset_path\n            else:\n                self.dataset = None\n                return None\n        except KeyError:\n            # Files with following dataset structure\n            # Location of 'quantity' attribute: /dataset1/what\n            # Dataset path structure: /dataset1/data1/data \n            dataset_root_path = re.search( '^/dataset[0-9]+/', quantity_path).group(0)\n            dataset_paths = self.datasets()\n            for ds_path in dataset_paths:\n                try:\n                    full_dataset_path = re.search( '^{}data[0-9]+/data'.format(dataset_root_path), ds_path).group(0)\n                    break\n                except:\n                    pass\n            if isinstance(self[full_dataset_path], h5py.Dataset):\n                self.dataset = self[full_dataset_path].ref\n                return full_dataset_path        \n            else:\n                self.dataset = None\n                return None", "response": "Selects the matching dataset and returns its path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes an HTTP request and return the response and status code.", "response": "def request(self, url, method, body=\"\", headers={}, retry=True):\n        \"\"\"Execute an HTTP request and return a dict containing the response\n        and the response status code.\n\n        Keyword arguments:\n        url -- The path to execute the result against, not including the API\n               version or project ID, with no leading /. Required.\n        method -- The HTTP method to use. Required.\n        body -- A string or file object to send as the body of the request.\n                Defaults to an empty string.\n        headers -- HTTP Headers to send with the request. Can overwrite the\n                   defaults. Defaults to {}.\n        retry -- Whether exponential backoff should be employed. Defaults\n                 to True.\n        \"\"\"\n        if headers:\n            headers = dict(list(headers.items()) + list(self.headers.items()))\n        else:\n            headers = self.headers\n\n        if not sys.version_info >= (3,) and headers:\n            headers = dict((k.encode('ascii') if isinstance(k, unicode) else k,\n                            v.encode('ascii') if isinstance(v, unicode) else v)\n                           for k, v in headers.items())\n\n        url = self.base_url + url\n        if not sys.version_info >= (3,):\n            if isinstance(url, unicode):\n                url = url.encode('ascii')\n\n        r = self._doRequest(url, method, body, headers)\n\n        retry_http_codes = [503, 504]\n        if r.status_code in retry_http_codes and retry:\n            tries = 5\n            delay = .5\n            backoff = 2\n            while r.status_code in retry_http_codes and tries > 0:\n                tries -= 1\n                time.sleep(delay)\n                delay *= backoff\n                r = self._doRequest(url, method, body, headers)\n\n        r.raise_for_status()\n\n        result = {}\n        contentType = r.headers[\"Content-Type\"]\n        if contentType is None:\n            contentType = \"text/plain\"\n        else:\n            contentType = contentType.split(\";\")[0]\n        if contentType.lower() == \"application/json\":\n            try:\n                result[\"body\"] = json.loads(r.text)\n            except:\n                result[\"body\"] = r.text\n        else:\n            result[\"body\"] = r.text\n        result[\"status\"] = r.status_code\n        result[\"resp\"] = r\n        result[\"content-type\"] = contentType\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, url, headers={}, retry=True):\n        return self.request(url=url, method=\"GET\", headers=headers,\n                retry=retry)", "response": "Execute an HTTP GET request and return a dict containing the response and the response status code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting an HTTP POST request and return a dict containing the response and the response status code.", "response": "def post(self, url, body=\"\", headers={}, retry=True):\n        \"\"\"Execute an HTTP POST request and return a dict containing the\n        response and the response status code.\n\n        Keyword arguments:\n        url -- The path to execute the result against, not including the API\n               version or project ID, with no leading /. Required.\n        body -- A string or file object to send as the body of the request.\n                Defaults to an empty string.\n        headers -- HTTP Headers to send with the request. Can overwrite the\n                   defaults. Defaults to {}.\n        retry -- Whether exponential backoff should be employed. Defaults\n                 to True.\n        \"\"\"\n        headers[\"Content-Length\"] = str(len(body))\n        return self.request(url=url, method=\"POST\", body=body, headers=headers,\n                retry=retry)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute an HTTP PATCH request and return a dict containing the response and the response status code.", "response": "def patch(self, url, body=\"\", headers={}, retry=True):\n        \"\"\"Execute an HTTP PATCH request and return a dict containing the\n        response and the response status code.\n\n        Keyword arguments:\n        url -- The path to execute the result against, not including the API\n               version or project ID, with no leading /. Required.\n        body -- A string or file object to send as the body of the request.\n                Defaults to an empty string.\n        headers -- HTTP Headers to send with the request. Can overwrite the\n                defaults. Defaults to {}.\n        retry -- Whether exponential backoff should be employed. Defaults\n                 to True.\n        \"\"\"\n        return self.request(url=url, method=\"PATCH\", body=body, headers=headers,\n                retry=retry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clone(cls, srcpath, destpath):\n        try:\n            os.makedirs(destpath)\n        except OSError as e:\n            if not e.errno == errno.EEXIST:\n                raise\n        cmd = [SVNADMIN, 'dump', '--quiet', '.']\n        dump = subprocess.Popen(\n               cmd, cwd=srcpath, stdout=subprocess.PIPE,\n               stderr=subprocess.PIPE,\n        )\n        repo = cls.create(destpath)\n        repo.load(dump.stdout)\n        stderr = dump.stderr.read()\n        dump.stdout.close()\n        dump.stderr.close()\n        dump.wait()\n        if dump.returncode != 0:\n            raise subprocess.CalledProcessError(dump.returncode, cmd, stderr)\n        return repo", "response": "Copy a main repository to a new location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(cls, path):\n        try:\n            os.makedirs(path)\n        except OSError as e:\n            if not e.errno == errno.EEXIST:\n                raise\n        cmd = [SVNADMIN, 'create', path]\n        subprocess.check_call(cmd)\n        return cls(path)", "response": "Create a new repository"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef proplist(self, rev, path=None):\n        rev, prefix = self._maprev(rev)\n        if path is None:\n            return self._proplist(str(rev), None)\n        else:\n            path = type(self).cleanPath(_join(prefix, path))\n            return self._proplist(str(rev), path)", "response": "List Subversion properties of the path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets Subversion property value of the path", "response": "def propget(self, prop, rev, path=None):\n        \"\"\"Get Subversion property value of the path\"\"\"\n        rev, prefix = self._maprev(rev)\n        if path is None:\n            return self._propget(prop, str(rev), None)\n        else:\n            path = type(self).cleanPath(_join(prefix, path))\n            return self._propget(prop, str(rev), path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump(\n        self, stream, progress=None, lower=None, upper=None,\n        incremental=False, deltas=False\n    ):\n        \"\"\"Dump the repository to a dumpfile stream.\n\n        :param stream: A file stream to which the dumpfile is written\n        :param progress: A file stream to which progress is written\n        :param lower: Must be a numeric version number\n        :param upper: Must be a numeric version number\n\n        See ``svnadmin help dump`` for details on the other arguments.\n\n        \"\"\"\n        cmd = [SVNADMIN, 'dump', '.']\n        if progress is None:\n            cmd.append('-q')\n        if lower is not None:\n            cmd.append('-r')\n            if upper is None:\n                cmd.append(str(int(lower)))\n            else:\n                cmd.append('%d:%d' % (int(lower), int(upper)))\n        if incremental:\n            cmd.append('--incremental')\n        if deltas:\n            cmd.append('--deltas')\n        p = subprocess.Popen(cmd, cwd=self.path, stdout=stream, stderr=progress)\n        p.wait()\n        if p.returncode != 0:\n            raise subprocess.CalledProcessError(p.returncode, cmd)", "response": "Dump the current version number of the current repository to a file stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(\n        self, stream, progress=None, ignore_uuid=False, force_uuid=False,\n        use_pre_commit_hook=False, use_post_commit_hook=False, parent_dir=None\n    ):\n        \"\"\"Load a dumpfile stream into the repository.\n\n        :param stream: A file stream from which the dumpfile is read\n        :param progress: A file stream to which progress is written\n\n        See ``svnadmin help load`` for details on the other arguments.\n\n        \"\"\"\n        cmd = [SVNADMIN, 'load', '.']\n        if progress is None:\n            cmd.append('-q')\n        if ignore_uuid:\n            cmd.append('--ignore-uuid')\n        if force_uuid:\n            cmd.append('--force-uuid')\n        if use_pre_commit_hook:\n            cmd.append('--use-pre-commit-hook')\n        if use_post_commit_hook:\n            cmd.append('--use-post-commit-hook')\n        if parent_dir:\n            cmd.extend(['--parent-dir', parent_dir])\n        p = subprocess.Popen(\n            cmd, cwd=self.path, stdin=stream, stdout=progress,\n            stderr=subprocess.PIPE\n        )\n        stderr = p.stderr.read()\n        p.stderr.close()\n        p.wait()\n        if p.returncode != 0:\n            raise subprocess.CalledProcessError(p.returncode, cmd, stderr)", "response": "Load a dumpfile into the repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef temp_file(\n        content=None,\n        suffix='',\n        prefix='tmp',\n        parent_dir=None):\n    \"\"\"\n    Create a temporary file and optionally populate it with content. The file\n    is deleted when the context exits.\n\n    The temporary file is created when entering the context manager and\n    deleted when exiting it.\n    >>> import temporary\n    >>> with temporary.temp_file() as temp_file:\n    ...     assert temp_file.exists()\n    >>> assert not temp_file.exists()\n\n    The user may also supply some content for the file to be populated with:\n    >>> with temporary.temp_file('hello!') as temp_file:\n    ...     with temp_file.open() as f:\n    ...         assert f.read() == 'hello!'\n\n    The temporary file can be placed in a custom directory:\n    >>> with temporary.temp_dir() as temp_dir:\n    ...     with temporary.temp_file(parent_dir=temp_dir) as temp_file:\n    ...         assert temp_file.parent == temp_dir\n\n    If, for some reason, the user wants to delete the temporary file before\n    exiting the context, that's okay too:\n    >>> with temporary.temp_file() as temp_file:\n    ...     temp_file.unlink()\n    \"\"\"\n    binary = isinstance(content, (bytes, bytearray))\n    parent_dir = parent_dir if parent_dir is None else str(parent_dir)\n    fd, abs_path = tempfile.mkstemp(suffix, prefix, parent_dir, text=False)\n    path = pathlib.Path(abs_path)\n    try:\n        try:\n            if content:\n                os.write(fd, content if binary else content.encode())\n        finally:\n            os.close(fd)\n        yield path.resolve()\n    finally:\n        with temporary.util.allow_missing_file():\n            path.unlink()", "response": "Create a temporary file and optionally populate it with content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a message to stdout if no connection string is found for deployment", "response": "def _emit_no_set_found(environment_name, product_name):\n    \"\"\"\n    writes to std out and logs if no connection string is found for deployment\n    :param environment_name:\n    :param product_name:\n    :return:\n    \"\"\"\n    sys.stdout.write(colorama.Fore.YELLOW + 'No connections found in global config file '\n                                            'in environment: {0} for product: {1}'\n                     .format(environment_name, product_name) +\n                     colorama.Fore.RESET)\n    sys.stdout.write('\\n')\n    logger.warning('No connections found in environment: {0} for product: {1}'\n                   .format(environment_name, product_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the book content", "response": "def load_content(self):\n        \"\"\"\n        Load the book content\n        \"\"\"\n\n        # get the toc file from the root file\n        rel_path = self.root_file_url.replace(os.path.basename(self.root_file_url), '')\n        self.toc_file_url = rel_path + self.root_file.find(id=\"ncx\")['href']\n        self.toc_file_soup = bs(self.book_file.read(self.toc_file_url), 'xml')\n\n        # get the book content from the toc file\n\n        for n, c in cross(self.toc_file_soup.find_all('navLabel'), self.toc_file_soup.find_all('content')):\n            content_soup = bs(self.book_file.read(rel_path + c.get('src')))\n            self.content.append({'part_name': c.text,\n                                 'source_url': c.get('src'),\n                                 'content_source': content_soup,\n                                 'content_source_body': content_soup.body,\n                                 'content_source_text': content_soup.body.text})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef digestInSilico(proteinSequence, cleavageRule='[KR]', missedCleavage=0,\n                   removeNtermM=True, minLength=5, maxLength=55):\n    \"\"\"Returns a list of peptide sequences and cleavage information derived\n    from an in silico digestion of a polypeptide.\n\n    :param proteinSequence: amino acid sequence of the poly peptide to be\n        digested\n    :param cleavageRule: cleavage rule expressed in a regular expression, see\n        :attr:`maspy.constants.expasy_rules`\n    :param missedCleavage: number of allowed missed cleavage sites\n    :param removeNtermM: booo, True to consider also peptides with the\n        N-terminal methionine of the protein removed\n    :param minLength: int, only yield peptides with length >= minLength\n    :param maxLength: int, only yield peptides with length <= maxLength\n\n    :returns: a list of resulting peptide enries. Protein positions start with\n        ``1`` and end with ``len(proteinSequence``. ::\n\n            [(peptide amino acid sequence,\n              {'startPos': int, 'endPos': int, 'missedCleavage': int}\n              ), ...\n             ]\n\n    .. note::\n        This is a regex example for specifying N-terminal cleavage at lysine\n        sites ``\\\\w(?=[K])``\n    \"\"\"\n    passFilter = lambda startPos, endPos: (endPos - startPos >= minLength and\n                                           endPos - startPos <= maxLength\n                                           )\n    _regexCleave = re.finditer(cleavageRule, proteinSequence)\n\n    cleavagePosList = set(itertools.chain(map(lambda x: x.end(), _regexCleave)))\n    cleavagePosList.add(len(proteinSequence))\n    cleavagePosList = sorted(list(cleavagePosList))\n    #Add end of protein as cleavage site if protein doesn't end with specififed\n    #cleavage positions\n    numCleavageSites = len(cleavagePosList)\n\n    if missedCleavage >= numCleavageSites:\n        missedCleavage = numCleavageSites -1\n\n    digestionresults = list()\n    #Generate protein n-terminal peptides after methionine removal\n    if removeNtermM and proteinSequence[0] == 'M':\n        for cleavagePos in range(0, missedCleavage+1):\n            startPos = 1\n            endPos = cleavagePosList[cleavagePos]\n            if passFilter(startPos, endPos):\n                sequence = proteinSequence[startPos:endPos]\n                info = dict()\n                info['startPos'] = startPos+1\n                info['endPos'] = endPos\n                info['missedCleavage'] = cleavagePos\n                digestionresults.append((sequence, info))\n\n    #Generate protein n-terminal peptides\n    if cleavagePosList[0] != 0:\n        for cleavagePos in range(0, missedCleavage+1):\n            startPos = 0\n            endPos = cleavagePosList[cleavagePos]\n            if passFilter(startPos, endPos):\n                sequence = proteinSequence[startPos:endPos]\n                info = dict()\n                info['startPos'] = startPos+1\n                info['endPos'] = endPos\n                info['missedCleavage'] = cleavagePos\n                digestionresults.append((sequence, info))\n\n    #Generate all remaining peptides, including the c-terminal peptides\n    lastCleavagePos = 0\n    while lastCleavagePos < numCleavageSites:\n        for missedCleavage in range(0, missedCleavage+1):\n            nextCleavagePos = lastCleavagePos + missedCleavage + 1\n            if nextCleavagePos < numCleavageSites:\n                startPos = cleavagePosList[lastCleavagePos]\n                endPos = cleavagePosList[nextCleavagePos]\n                if passFilter(startPos, endPos):\n                    sequence = proteinSequence[startPos:endPos]\n                    info = dict()\n                    info['startPos'] = startPos+1\n                    info['endPos'] = endPos\n                    info['missedCleavage'] = missedCleavage\n                    digestionresults.append((sequence, info))\n        lastCleavagePos += 1\n\n    return digestionresults", "response": "Returns a list of peptide sequences and cleavage information derived from an in silico digestion of a polypeptide."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the mass of a peptide sequence.", "response": "def calcPeptideMass(peptide, **kwargs):\n    \"\"\"Calculate the mass of a peptide.\n\n    :param aaMass: A dictionary with the monoisotopic masses of amino acid\n        residues, by default :attr:`maspy.constants.aaMass`\n    :param aaModMass: A dictionary with the monoisotopic mass changes of\n        modications, by default :attr:`maspy.constants.aaModMass`\n    :param elementMass: A dictionary with the masses of chemical elements, by\n        default ``pyteomics.mass.nist_mass``\n    :param peptide: peptide sequence, modifications have to be written in the\n        format \"[modificationId]\" and \"modificationId\" has to be present in\n        :attr:`maspy.constants.aaModMass`\n\n    #TODO: change to a more efficient way of calculating the modified mass, by\n    first extracting all present modifications and then looking up their masses.\n    \"\"\"\n    aaMass = kwargs.get('aaMass', maspy.constants.aaMass)\n    aaModMass = kwargs.get('aaModMass', maspy.constants.aaModMass)\n    elementMass = kwargs.get('elementMass', pyteomics.mass.nist_mass)\n\n    addModMass = float()\n    unmodPeptide = peptide\n    for modId, modMass in viewitems(aaModMass):\n        modSymbol = '[' + modId + ']'\n        numMod = peptide.count(modSymbol)\n        if numMod > 0:\n            unmodPeptide = unmodPeptide.replace(modSymbol, '')\n            addModMass += modMass * numMod\n\n    if unmodPeptide.find('[') != -1:\n        print(unmodPeptide)\n        raise Exception('The peptide contains modification, ' +\n                        'not present in maspy.constants.aaModMass'\n                        )\n\n    unmodPeptideMass = sum(aaMass[i] for i in unmodPeptide)\n    unmodPeptideMass += elementMass['H'][0][0]*2 + elementMass['O'][0][0]\n    modPeptideMass = unmodPeptideMass + addModMass\n    return modPeptideMass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef removeModifications(peptide):\n    while peptide.find('[') != -1:\n        peptide = peptide.split('[', 1)[0] + peptide.split(']', 1)[1]\n    return peptide", "response": "Removes all modifications from a peptide string and returns the amino acid sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef returnModPositions(peptide, indexStart=1, removeModString='UNIMOD:'):\n    unidmodPositionDict = dict()\n    while peptide.find('[') != -1:\n        currModification = peptide.split('[')[1].split(']')[0]\n        currPosition = peptide.find('[') - 1\n        if currPosition == -1: # move n-terminal modifications to first position\n            currPosition = 0\n        currPosition += indexStart\n\n        peptide = peptide.replace('['+currModification+']', '', 1)\n\n        if removeModString:\n            currModification = currModification.replace(removeModString, '')\n        unidmodPositionDict.setdefault(currModification,list())\n        unidmodPositionDict[currModification].append(currPosition)\n    return unidmodPositionDict", "response": "Determines the amino acid positions of all present modifications in the peptide sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the MH + value from mz and charge.", "response": "def calcMhFromMz(mz, charge):\n    \"\"\"Calculate the MH+ value from mz and charge.\n\n    :param mz: float, mass to charge ratio (Dalton / charge)\n    :param charge: int, charge state\n\n    :returns: mass to charge ratio of the mono protonated ion (charge = 1)\n    \"\"\"\n    mh = (mz * charge) - (maspy.constants.atomicMassProton * (charge-1) )\n    return mh"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the mz value from MH + and charge.", "response": "def calcMzFromMh(mh, charge):\n    \"\"\"Calculate the mz value from MH+ and charge.\n\n    :param mh: float, mass to charge ratio (Dalton / charge) of the mono\n        protonated ion\n    :param charge: int, charge state\n\n    :returns: mass to charge ratio of the specified charge state\n    \"\"\"\n    mz = (mh + (maspy.constants.atomicMassProton * (charge-1))) / charge\n    return mz"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the mz value of a peptide from its mass and charge.", "response": "def calcMzFromMass(mass, charge):\n    \"\"\"Calculate the mz value of a peptide from its mass and charge.\n\n    :param mass: float, exact non protonated mass\n    :param charge: int, charge state\n\n    :returns: mass to charge ratio of the specified charge state\n    \"\"\"\n    mz = (mass + (maspy.constants.atomicMassProton * charge)) / charge\n    return mz"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the mass of a peptide from its mz and charge.", "response": "def calcMassFromMz(mz, charge):\n    \"\"\"Calculate the mass of a peptide from its mz and charge.\n\n    :param mz: float, mass to charge ratio (Dalton / charge)\n    :param charge: int, charge state\n\n    :returns: non protonated mass (charge = 0)\n    \"\"\"\n    mass = (mz - maspy.constants.atomicMassProton) * charge\n    return mass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a process on the remote machine using SSHCommand", "response": "def execute(self, processProtocol, command, env={},\n                path=None, uid=None, gid=None, usePTY=0, childFDs=None):\n        \"\"\"Execute a process on the remote machine using SSH\n\n        @param processProtocol: the ProcessProtocol instance to connect\n        @param executable: the executable program to run\n        @param args: the arguments to pass to the process\n        @param env: environment variables to request the remote ssh server to set\n        @param path: the remote path to start the remote process on\n        @param uid: user id or username to connect to the ssh server with\n        @param gid: this is not used for remote ssh processes\n        @param usePTY: wither to request a pty for the process\n        @param childFDs: file descriptors to use for stdin, stdout and stderr\n        \"\"\"\n\n        sshCommand = (command if isinstance(command, SSHCommand)\n                      else SSHCommand(command, self.precursor, path))\n        commandLine = sshCommand.getCommandLine()\n\n        # Get connection to ssh server\n        connectionDeferred = self.getConnection(uid)\n        # spawn the remote process\n        connectionDeferred.addCallback(connectProcess, processProtocol,\n                                       commandLine, env, usePTY, childFDs)\n        return connectionDeferred"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a SSHUserAuthClient object to use for authentication", "response": "def _getUserAuthObject(self, user, connection):\n        \"\"\"Get a SSHUserAuthClient object to use for authentication\n\n        @param user: The username to authenticate for\n        @param connection: The connection service to start after authentication\n        \"\"\"\n        credentials = self._getCredentials(user)\n        userAuthObject = AutomaticUserAuthClient(user, connection, **credentials)\n        return userAuthObject"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when ssh transport requests us to verify a given host key.", "response": "def _verifyHostKey(self, hostKey, fingerprint):\n        \"\"\"Called when ssh transport requests us to verify a given host key.\n        Return a deferred that callback if we accept the key or errback if we\n        decide to reject it.\n        \"\"\"\n        if fingerprint in self.knownHosts:\n            return defer.succeed(True)\n        return defer.fail(UnknownHostKey(hostKey, fingerprint))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes variable to list.", "response": "def _to_list(var):\n    \"\"\"\n    Make variable to list.\n\n    >>> _to_list(None)\n    []\n    >>> _to_list('whee')\n    ['whee']\n    >>> _to_list([None])\n    [None]\n    >>> _to_list((1, 2, 3))\n    [1, 2, 3]\n\n    :param var: variable of any type\n    :return:    list\n    \"\"\"\n    if isinstance(var, list):\n        return var\n    elif var is None:\n        return []\n    elif isinstance(var, str) or isinstance(var, dict):\n        # We dont want to make a list out of those via the default constructor\n        return [var]\n    else:\n        try:\n            return list(var)\n        except TypeError:\n            return [var]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arguments_to_lists(function):\n    def l_function(*args, **kwargs):\n        l_args = [_to_list(arg) for arg in args]\n        l_kwargs = {}\n\n        for key, value in kwargs.items():\n            l_kwargs[key] = _to_list(value)\n        return function(*l_args, **l_kwargs)\n\n    return l_function", "response": "Decorator for a function that converts all arguments to lists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_public_members(obj):\n    return {attr: getattr(obj, attr) for attr in dir(obj)\n            if not attr.startswith(\"_\")\n            and not hasattr(getattr(obj, attr), '__call__')}", "response": "Returns a list of member - like objects that are only publically exposed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_repr(*members):\n    def decorator(cls):\n        cls.__repr__ = __repr__\n        return cls\n\n    if members:\n        # Prepare members list.\n        members_to_print = list(members)\n        for i, member in enumerate(members_to_print):\n            if isinstance(member, tuple):\n                # Check tuple dimensions.\n                length = len(member)\n                if length == 2:\n                    members_to_print[i] = (member[0],\n                                           member[1] if member[1] else repr)\n                else:\n                    raise ValueError(\"Passed tuple \" + repr(member) +\n                                     \" needs to be 2-dimensional, but has \" +\n                                     str(length) + \" dimensions.\")\n            else:\n                members_to_print[i] = (member, repr)\n\n        def __repr__(self):\n            return _construct_repr_string(self, members_to_print)\n    else:\n        def __repr__(self):\n            # Need to fetch member variables every time since they are unknown\n            # until class instantation.\n            members_to_print = get_public_members(self)\n\n            member_repr_list = ((member, repr) for member in\n                                sorted(members_to_print, key=str.lower))\n\n            return _construct_repr_string(self, member_repr_list)\n\n    return decorator", "response": "A decorator that binds an auto - generated repr - function to a class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate equality and inequality operators for the class.", "response": "def generate_eq(*members):\n    \"\"\"\n    Decorator that generates equality and inequality operators for the\n    decorated class. The given members as well as the type of self and other\n    will be taken into account.\n\n    Note that this decorator modifies the given class in place!\n\n    :param members: A list of members to compare for equality.\n    \"\"\"\n    def decorator(cls):\n        def eq(self, other):\n            if not isinstance(other, cls):\n                return False\n\n            return all(getattr(self, member) == getattr(other, member)\n                       for member in members)\n\n        def ne(self, other):\n            return not eq(self, other)\n\n        cls.__eq__ = eq\n        cls.__ne__ = ne\n        return cls\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a decorator that generates a list of ordering operators for the given members.", "response": "def generate_ordering(*members):\n    \"\"\"\n    Decorator that generates ordering operators for the decorated class based\n    on the given member names. All ordering except equality functions will\n    raise a TypeError when a comparison with an unrelated class is attempted.\n    (Comparisons with child classes will thus work fine with the capabilities\n    of the base class as python will choose the base classes comparison\n    operator in that case.)\n\n    Note that this decorator modifies the given class in place!\n\n    :param members: A list of members to compare, ordered from high priority to\n                    low. I.e. if the first member is equal the second will be\n                    taken for comparison and so on. If a member is None it is\n                    considered smaller than any other value except None.\n    \"\"\"\n    def decorator(cls):\n        def lt(self, other):\n            if not isinstance(other, cls):\n                raise TypeError(\"Comparison with unrelated classes is \"\n                                \"unsupported.\")\n\n            for member in members:\n                if getattr(self, member) == getattr(other, member):\n                    continue\n\n                if (\n                        getattr(self, member) is None or\n                        getattr(other, member) is None):\n                    return getattr(self, member) is None\n\n                return getattr(self, member) < getattr(other, member)\n\n            return False\n\n        cls.__lt__ = lt\n        return total_ordering(generate_eq(*members)(cls))\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenforce the signature of a function.", "response": "def enforce_signature(function):\n    \"\"\"\n    Enforces the signature of the function by throwing TypeError's if invalid\n    arguments are provided. The return value is not checked.\n\n    You can annotate any parameter of your function with the desired type or a\n    tuple of allowed types. If you annotate the function with a value, this\n    value only will be allowed (useful especially for None). Example:\n\n    >>> @enforce_signature\n    ... def test(arg: bool, another: (int, None)):\n    ...     pass\n    ...\n    >>> test(True, 5)\n    >>> test(True, None)\n\n    Any string value for any parameter e.g. would then trigger a TypeError.\n\n    :param function: The function to check.\n    \"\"\"\n    argspec = inspect.getfullargspec(function)\n    annotations = argspec.annotations\n    argnames = argspec.args\n\n    unnamed_annotations = {}\n    for i, arg in enumerate(argnames):\n        if arg in annotations:\n            unnamed_annotations[i] = (annotations[arg], arg)\n\n    def decorated(*args, **kwargs):\n        for i, annotation in unnamed_annotations.items():\n            if i < len(args):\n                assert_right_type(args[i], annotation[0], annotation[1])\n\n        for argname, argval in kwargs.items():\n            if argname in annotations:\n                assert_right_type(argval, annotations[argname], argname)\n\n        return function(*args, **kwargs)\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the underlying message object as a string", "response": "def as_string(self):\n        \"\"\"Get the underlying message object as a string\"\"\"\n        if self.headers_only:\n            self.msgobj = self._get_content()\n\n        # We could just use msgobj.as_string() but this is more flexible... we might need it.\n        from email.generator import Generator\n        fp = StringIO()\n        g = Generator(fp, maxheaderlen=60)\n        g.flatten(self.msgobj)\n        text = fp.getvalue()\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over the message headers.", "response": "def iteritems(self):\n        \"\"\"Present the email headers\"\"\"\n        for n,v in self.msgobj.__dict__[\"_headers\"]:\n            yield n.lower(), v\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_flag(self, flag):\n        self.folder._invalidate_cache()\n        # TODO::: turn the flag off when it's already on\n        def replacer(m):\n            return \"%s/%s.%s%s\" % (\n                joinpath(self.folder.base, self.folder.folder, \"cur\"),\n                m.group(\"key\"),\n                m.group(\"hostname\"),\n                \":2,%s\" % (\n                    \"%s%s\" % (m.group(\"flags\"), flag) if m.group(\"flags\") \\\n                        else flag\n                    )\n                )\n        newfilename = self.msgpathre.sub(replacer, self.filename)\n        self.filesystem.rename(self.filename, newfilename)\n        self.filename = newfilename", "response": "Turns the specified flag on"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_message(self, key, since=None):\n        stored = self.store[key]\n        if isinstance(stored, dict):\n            filename = stored[\"path\"]\n            folder = stored[\"folder\"]\n            if since and since > 0.0:\n                st = stat(filename)\n                if st.st_mtime < since:\n                    return None\n            stored = MdMessage(\n                key, \n                filename = filename, \n                folder = folder,\n                filesystem = folder.filesystem\n                )\n            self.store[key] = stored\n        else:\n            if since and since > 0.0:\n                st = stat(stored.filename)\n                if st.st_mtime < since:\n                    return None\n                \n        return stored", "response": "Return the MdMessage object for the key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _foldername(self, additionalpath=\"\"):\n        if not self._foldername_cache.get(additionalpath):\n            fn = joinpath(self.base, self.folder, additionalpath) \\\n                if not self.is_subfolder \\\n                else joinpath(self.base, \".%s\" % self.folder, additionalpath)\n            self._foldername_cache[additionalpath] = fn\n        return self._foldername_cache[additionalpath]", "response": "Dot decorate a folder name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a map of the subfolder objects for this folder.", "response": "def folders(self):\n        \"\"\"Return a map of the subfolder objects for this folder.\n\n        This is a snapshot of the folder list at the time the call was made. \n        It does not update over time.\n\n        The map contains MdFolder objects:\n\n          maildir.folders()[\"Sent\"]\n\n        might retrieve the folder .Sent from the maildir.\n        \"\"\"\n        entrys = self.filesystem.listdir(abspath(self._foldername()))\n        regex = re.compile(\"\\\\..*\")\n        just_dirs = dict([(d,d) for d in entrys if regex.match(d)])\n\n        folder = self._foldername()\n        filesystem = self.filesystem\n\n        class FolderList(object):\n            def __iter__(self):\n                dirs = list(just_dirs.keys())\n                dirs.sort()\n                dirs.reverse()\n                for dn in dirs:\n                    yield MdFolder(\n                        dn[1:],\n                        base=folder,\n                        subfolder=True,\n                        filesystem=filesystem\n                        )\n                return\n\n            def __list__(self):\n                return [dn[1:] for dn in just_dirs]\n\n            def __contains__(self, name):\n                return just_dirs.__contains__(\".%s\" % name)\n\n            def __getitem__(self, name):\n                return MdFolder(\n                    just_dirs[\".%s\" % name][1:],\n                    base=folder,\n                    subfolder=True,\n                    filesystem=filesystem\n                    )\n\n        f = FolderList()\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move(self, key, folder):\n        # Basically this is a sophisticated __delitem__\n        # We need the path so we can make it in the new folder\n        path, host, flags = self._exists(key)\n        self._invalidate_cache()\n\n        # Now, move the message file to the new folder\n        newpath = joinpath(\n            folder.base, \n            folder.get_name(), \n            \"cur\",     # we should probably move it to new if it's in new\n            basename(path)\n            )\n        self.filesystem.rename(path, newpath)\n        # And update the caches in the new folder\n        folder._invalidate_cache()", "response": "Move the specified key to the specified folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _muaprocessnew(self):\n        foldername = self._foldername(\"new\")\n        files = self.filesystem.listdir(foldername)\n        for filename in files:\n            if filename == \"\":\n                continue\n            curfilename = self._foldername(joinpath(\"new\", filename))\n            newfilename = joinpath(\n                self._cur,\n                \"%s:2,%s\" % (filename, \"\")\n                )\n            self.filesystem.rename(curfilename, newfilename)", "response": "Moves all new files into cur correctly flagging"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a key in a particular section and return the path hostname and flags", "response": "def _exists(self, key):\n        \"\"\"Find a key in a particular section\n\n        Searches through all the files and looks for matches with a regex.\n        \"\"\"\n        filecache, keycache = self._fileslist()\n        msg = keycache.get(key, None)\n        if msg:\n            path = msg.filename\n            meta = filecache[path]\n            return path, meta[\"hostname\"], meta.get(\"flags\", \"\")\n        raise KeyError(\"not found %s\" % key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_slices(data3d, contour=None, seeds=None, axis=0, slice_step=None,\r\n                shape=None, show=True,\r\n                flipH=False, flipV=False,\r\n                first_slice_offset=0,\r\n                first_slice_offset_to_see_seed_with_label=None,\r\n                slice_number=None\r\n                ):\r\n    \"\"\"\r\n    Show slices as tiled image\r\n\r\n    :param data3d: Input data\r\n    :param contour: Data for contouring\r\n    :param seeds: Seed data\r\n    :param axis: Axis for sliceing\r\n    :param slice_step: Show each \"slice_step\"-th slice, can be float\r\n    :param shape: tuple(vertical_tiles_number, horisontal_tiles_number), set shape of output tiled image. slice_step is\r\n    estimated if it is not set explicitly\r\n    :param first_slice_offset: set offset of first slice\r\n    :param first_slice_offset_to_see_seed_with_label: find offset to see slice with seed with defined label\r\n    :param slice_number: int, Number of showed slices. Overwrites shape and slice_step.\r\n    \"\"\"\r\n\r\n    if slice_number is not None:\r\n        slice_step = data3d.shape[axis] / slice_number\r\n    # odhad slice_step, neni li zadan\r\n    # slice_step estimation\r\n    # TODO make precise estimation (use np.linspace to indexing?)\r\n    if slice_step is None:\r\n        if shape is None:\r\n            slice_step = 1\r\n        else:\r\n            slice_step = ((data3d.shape[axis] - first_slice_offset ) / float(np.prod(shape)))\r\n\r\n\r\n\r\n    if first_slice_offset_to_see_seed_with_label is not None:\r\n        if seeds is not None:\r\n            inds = np.nonzero(seeds==first_slice_offset_to_see_seed_with_label)\r\n            # print(inds)\r\n            # take first one with defined seed\r\n            # ind = inds[axis][0]\r\n            # take most used index\r\n            ind = np.median(inds[axis])\r\n            first_slice_offset = ind % slice_step\r\n\r\n\r\n    data3d = _import_data(data3d, axis=axis, slice_step=slice_step, first_slice_offset=first_slice_offset)\r\n    contour = _import_data(contour, axis=axis, slice_step=slice_step, first_slice_offset=first_slice_offset)\r\n    seeds = _import_data(seeds, axis=axis, slice_step=slice_step, first_slice_offset=first_slice_offset)\r\n\r\n    number_of_slices = data3d.shape[axis]\r\n    # square image\r\n    #     nn = int(math.ceil(number_of_slices ** 0.5))\r\n\r\n    #     sh = [nn, nn]\r\n\r\n    # 4:3 image\r\n    meta_shape = shape\r\n    if meta_shape is None:\r\n        na = int(math.ceil(number_of_slices * 16.0 / 9.0) ** 0.5)\r\n        nb = int(math.ceil(float(number_of_slices) / na))\r\n        meta_shape = [nb, na]\r\n\r\n    dsh = __get_slice(data3d, 0, axis).shape\r\n    slimsh = [int(dsh[0] * meta_shape[0]), int(dsh[1] * meta_shape[1])]\r\n    slim = np.zeros(slimsh, dtype=data3d.dtype)\r\n    slco = None\r\n    slse = None\r\n    if seeds is not None:\r\n        slse = np.zeros(slimsh, dtype=seeds.dtype)\r\n    if contour is not None:\r\n        slco = np.zeros(slimsh, dtype=contour.dtype)\r\n    #         slse =\r\n    #     f, axarr = plt.subplots(sh[0], sh[1])\r\n\r\n    for i in range(0, number_of_slices):\r\n        cont = None\r\n        seeds2d = None\r\n        im2d = __get_slice(data3d, i, axis, flipH=flipH, flipV=flipV)\r\n        if contour is not None:\r\n            cont = __get_slice(contour, i, axis, flipH=flipH, flipV=flipV)\r\n            slco = __put_slice_in_slim(slco, cont, meta_shape, i)\r\n        if seeds is not None:\r\n            seeds2d = __get_slice(seeds, i, axis, flipH=flipH, flipV=flipV)\r\n            slse = __put_slice_in_slim(slse, seeds2d, meta_shape, i)\r\n        #         plt.axis('off')\r\n        #         plt.subplot(sh[0], sh[1], i+1)\r\n        #         plt.subplots_adjust(wspace=0, hspace=0)\r\n\r\n        slim = __put_slice_in_slim(slim, im2d, meta_shape, i)\r\n    #         show_slice(im2d, cont, seeds2d)\r\n    show_slice(slim, slco, slse)\r\n    if show:\r\n        plt.show()", "response": "Show slices as tiled image\r\nInsights"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_slice(data, slice_number, axis=0, flipH=False, flipV=False):\r\n    if axis == 0:\r\n        data2d =  data[slice_number, :, :]\r\n    elif axis == 1:\r\n        data2d = data[:, slice_number, :]\r\n    elif axis == 2:\r\n        data2d = data[:, :, slice_number]\r\n    else:\r\n        logger.error(\"axis number error\")\r\n        print(\"axis number error\")\r\n        return None\r\n\r\n    if flipV:\r\n        if data2d is not None:\r\n            data2d = data2d[-1:0:-1,:]\r\n    if flipH:\r\n        if data2d is not None:\r\n            data2d = data2d[:, -1:0:-1]\r\n    return data2d", "response": "Returns data in the specified axis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nputting one small slice in a big image", "response": "def __put_slice_in_slim(slim, dataim, sh, i):\r\n    \"\"\"\r\n    put one small slice as a tile in a big image\r\n    \"\"\"\r\n    a, b = np.unravel_index(int(i), sh)\r\n\r\n    st0 = int(dataim.shape[0] * a)\r\n    st1 = int(dataim.shape[1] * b)\r\n    sp0 = int(st0 + dataim.shape[0])\r\n    sp1 = int(st1 + dataim.shape[1])\r\n\r\n    slim[\r\n    st0:sp0,\r\n    st1:sp1\r\n    ] = dataim\r\n\r\n    return slim"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_slice(data2d, contour2d=None, seeds2d=None):\r\n\r\n    import copy as cp\r\n    # Show results\r\n\r\n    colormap = cp.copy(plt.cm.get_cmap('brg'))\r\n    colormap._init()\r\n    colormap._lut[:1:, 3] = 0\r\n\r\n    plt.imshow(data2d, cmap='gray', interpolation='none')\r\n    if contour2d is not None:\r\n        plt.contour(contour2d, levels=[0.5, 1.5, 2.5])\r\n    if seeds2d is not None:\r\n        # Show results\r\n        colormap = copy.copy(plt.cm.get_cmap('Paired'))\r\n        # colormap = copy.copy(plt.cm.get_cmap('gist_rainbow'))\r\n        colormap._init()\r\n\r\n        colormap._lut[0, 3] = 0\r\n\r\n        tmp0 = copy.copy(colormap._lut[:,0])\r\n        tmp1 = copy.copy(colormap._lut[:,1])\r\n        tmp2 = copy.copy(colormap._lut[:,2])\r\n\r\n        colormap._lut[:, 0] = sigmoid(tmp0, 0.5, 5)\r\n        colormap._lut[:, 1] = sigmoid(tmp1, 0.5, 5)\r\n        colormap._lut[:, 2] = 0# sigmoid(tmp2, 0.5, 5)\r\n        # seed 4\r\n        colormap._lut[140:220:, 1] = 0.7# sigmoid(tmp2, 0.5, 5)\r\n        colormap._lut[140:220:, 0] = 0.2# sigmoid(tmp2, 0.5, 5)\r\n        # seed 2\r\n        colormap._lut[40:120:, 1] = 1.# sigmoid(tmp2, 0.5, 5)\r\n        colormap._lut[40:120:, 0] = 0.1# sigmoid(tmp2, 0.5, 5)\r\n\r\n\r\n        # seed 2\r\n        colormap._lut[120:150:, 0] = 1.# sigmoid(tmp2, 0.5, 5)\r\n        colormap._lut[120:150:, 1] = 0.1# sigmoid(tmp2, 0.5, 5)\r\n\r\n        # my colors\r\n\r\n        # colormap._lut[1,:] = [.0,.1,.0,1]\r\n        # colormap._lut[2,:] = [.1,.1,.0,1]\r\n        # colormap._lut[3,:] = [.1,.1,.1,1]\r\n        # colormap._lut[4,:] = [.3,.3,.3,1]\r\n\r\n        plt.imshow(seeds2d, cmap=colormap, interpolation='none')", "response": "Show the data in a 2D array containing the next 2D array."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports data from numpy array or SimpleITK", "response": "def _import_data(data, axis, slice_step, first_slice_offset=0):\r\n    \"\"\"\r\n    import ndarray or SimpleITK data\r\n    \"\"\"\r\n    try:\r\n        import SimpleITK as sitk\r\n        if type(data) is sitk.SimpleITK.Image:\r\n            data = sitk.GetArrayFromImage(data)\r\n    except:\r\n        pass\r\n\r\n    data = __select_slices(data, axis, slice_step, first_slice_offset=first_slice_offset)\r\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating data for a single node.", "response": "def generate_data(shp=[16, 20, 24]):\r\n    \"\"\" Generating data \"\"\"\r\n\r\n    x = np.ones(shp)\r\n    # inserting box\r\n    x[4:-4, 6:-2, 1:-6] = -1\r\n    x_noisy = x + np.random.normal(0, 0.6, size=x.shape)\r\n    return x_noisy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index_to_coords(index, shape):\r\n    '''convert index to coordinates given the shape'''\r\n    coords = []\r\n    for i in xrange(1, len(shape)):\r\n        divisor = int(np.product(shape[i:]))\r\n        value = index // divisor\r\n        coords.append(value)\r\n        index -= value * divisor\r\n    coords.append(index)\r\n    return tuple(coords)", "response": "convert index to coordinates given the shape"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slices(img, shape=[3, 4]):\r\n    sh = np.asarray(shape)\r\n    i_max = np.prod(sh)\r\n    allimg = np.zeros(img.shape[-2:] * sh)\r\n\r\n    for i in range(0, i_max):\r\n        # i = 0\r\n        islice = round((img.shape[0] / float(i_max)) * i)\r\n        #         print(islice)\r\n        imgi = img[islice, :, :]\r\n        coords = index_to_coords(i, sh)\r\n        aic = np.asarray(img.shape[-2:]) * coords\r\n\r\n        allimg[aic[0]:aic[0] + imgi.shape[-2], aic[1]:aic[1] + imgi.shape[-1]] = imgi\r\n\r\n    #     plt.imshow(imgi)\r\n    #     print(imgi.shape)\r\n    #     print(img.shape)\r\n    return allimg", "response": "create tiled image with multiple slices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sed2(img, contour=None, shape=[3, 4]):\r\n    \"\"\"\r\n    :param img:\r\n    :param contour:\r\n    :param shape:\r\n    :return:\r\n    \"\"\"\r\n\r\n    plt.imshow(slices(img, shape), cmap='gray')\r\n    if contour is not None:\r\n        plt.contour(slices(contour, shape))", "response": "plot tiled image of multiple slices"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset visualization window :param windowC: window center :param windowW: window width :return:", "response": "def set_window(self, windowC, windowW):\r\n        \"\"\"\r\n        Sets visualization window\r\n        :param windowC: window center\r\n        :param windowW: window width\r\n        :return:\r\n        \"\"\"\r\n        if not (windowW and windowC):\r\n            windowW = np.max(self.img) - np.min(self.img)\r\n            windowC = (np.max(self.img) + np.min(self.img)) / 2.0\r\n\r\n        self.imgmax = windowC + (windowW / 2)\r\n        self.imgmin = windowC - (windowW / 2)\r\n        self.windowC = windowC\r\n        self.windowW = windowW"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rotate_to_zaxis(self, new_zaxis):\r\n\r\n        img = self._rotate_end(self.img, self.zaxis)\r\n        seeds = self._rotate_end(self.seeds, self.zaxis)\r\n        contour = self._rotate_end(self.contour, self.zaxis)\r\n\r\n        # Rotate data in depndecy on zaxispyplot\r\n        self.img = self._rotate_start(img, new_zaxis)\r\n        self.seeds = self._rotate_start(seeds, new_zaxis)\r\n        self.contour = self._rotate_start(contour, new_zaxis)\r\n        self.zaxis = new_zaxis\r\n        # import ipdb\r\n        # ipdb.set_trace()\r\n        # self.actual_slice_slider.valmax = self.img.shape[2] - 1\r\n        self.actual_slice = 0\r\n        self.rotated_back = False\r\n\r\n        # update slicer\r\n        self.fig.delaxes(self.ax_actual_slice)\r\n        self.ax_actual_slice.cla()\r\n        del(self.actual_slice_slider)\r\n        self.fig.add_axes(self.ax_actual_slice)\r\n        self.actual_slice_slider = Slider(self.ax_actual_slice, 'Slice', 0,\r\n                                          self.img.shape[2] - 1,\r\n                                          valinit=0)\r\n        self.actual_slice_slider.on_changed(self.sliceslider_update)\r\n        self.update_slice()", "response": "rotate image to new axis"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __flip(self, sliceimg):\r\n        if self.flipH:\r\n            sliceimg = sliceimg[:, -1:0:-1]\r\n\r\n        if self.flipV:\r\n            sliceimg = sliceimg [-1:0:-1,:]\r\n\r\n        return sliceimg", "response": "Flip the image if asked in self. flipV self. flipH self. flipV self. flipH self. flipV self. flipH self. flipV self. flipH self. flipV self. flipH self. flipV self. flipH self. flipV self. flipH self. flipH self. flipV self. flipH self. flipV self. flipH self. flipV self. flipH self. flipH self. flipV self. sliceimg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn list of all seeds with specific label", "response": "def get_seed_sub(self, label):\r\n        \"\"\" Return list of all seeds with specific label\r\n        \"\"\"\r\n        sx, sy, sz = np.nonzero(self.seeds == label)\r\n\r\n        return sx, sy, sz"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(self, instance_id):\n        instance = AtlasServiceInstance.Instance(instance_id, self.backend)\n        self.backend.storage.populate(instance)\n        return instance", "response": "Find an instance in the cache and populate it with data stored if it exists"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, instance, parameters, existing):\n        \n        if not instance.isProvisioned():\n            # Set parameters\n            instance.parameters = parameters\n            \n            # Existing cluster\n            if existing and not self.backend.atlas.Clusters.is_existing_cluster(instance.parameters[self.backend.config.PARAMETER_CLUSTER]):\n                # We need to use an existing cluster that is not available !\n                raise ErrClusterNotFound(instance.parameters[self.backend.config.PARAMETER_CLUSTER])\n            elif not existing:\n                # We need to create a new cluster\n                # We should not reach this code because the AtlasBroker.provision should\n                # raise an ErrPlanUnsupported before.\n                raise NotImplementedError()\n            \n            result = self.backend.storage.store(instance)\n            \n            # Provision done\n            return ProvisionedServiceSpec(ProvisionState.SUCCESSFUL_CREATED,\n                                      \"\",\n                                      str(result))\n        \n        elif instance.parameters == parameters:\n            # Identical so nothing to do\n            return ProvisionedServiceSpec(ProvisionState.IDENTICAL_ALREADY_EXISTS,\n                                        \"\",\n                                        \"duplicate\")\n        \n        else:\n            # Different parameters ...\n            raise ErrInstanceAlreadyExists()", "response": "Create the instance on the atlas backend"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, instance):\n        \n        #TODO: Really drop the database based on a policy set in `instance.parameters`.\n        #\n        #      We need :\n        #      - Set a policy in parameters of the instance (eg: policy-on-delete : retain|drop    => default to retain)\n        #      - to check that the database name `instance.get_dbname()` is not in use by another instance (shared database)\n        #      - credential on the Atlas cluster `instance.get_cluster()` to drop the database\n        #\n        \n        self.backend.storage.remove(instance)\n        \n        return DeprovisionServiceSpec(False, \"done\")", "response": "Delete the instance with the specified id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npushing the value item onto the heap maintaining the heap invariant.", "response": "def push(self, item):\n        '''Push the value item onto the heap, maintaining the heap invariant.\n        If the item is not hashable, a TypeError is raised.\n        '''\n        hash(item)\n        heapq.heappush(self._items, item)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_field_by_match(self, value, match):\n        groups = match.groups()\n        fill, align, sign, sharp, zero, width, comma, prec, type_ = groups\n        if not comma and not prec and type_ not in list('fF%'):\n            return None\n        if math.isnan(value) or math.isinf(value):\n            return None\n        locale = self.numeric_locale\n        # Format number value.\n        prefix = get_prefix(sign)\n        if type_ == 'd':\n            if prec is not None:\n                raise ValueError('precision not allowed in '\n                                 'integer format specifier')\n            string = format_number(value, 0, prefix, locale)\n        elif type_ in 'fF%':\n            format_ = format_percent if type_ == '%' else format_number\n            string = format_(value, int(prec or DEFAULT_PREC), prefix, locale)\n        else:\n            # Don't handle otherwise.\n            return None\n        if not comma:\n            # Formatted number always contains group symbols.\n            # Remove the symbols if not required.\n            string = remove_group_symbols(string, locale)\n        if not (fill or align or zero or width):\n            return string\n        # Fix a layout.\n        spec = ''.join([fill or u'', align or u'>',\n                        zero or u'', width or u''])\n        return format(string, spec)", "response": "Formats a field by a Regex match of the format spec pattern."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stdout_encode(u, default='utf-8'):\n    # from http://stackoverflow.com/questions/3627793/best-output-type-and-\n    #   encoding-practices-for-repr-functions\n    encoding = sys.stdout.encoding or default\n    return u.encode(encoding, \"replace\").decode(encoding, \"replace\")", "response": "Encodes a given string with the proper standard out encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the width of the terminal window", "response": "def get_terminal_width():\n    \"\"\" -> #int width of the terminal window \"\"\"\n    # http://www.brandonrubin.me/2014/03/18/python-snippet-get-terminal-width/\n    command = ['tput', 'cols']\n    try:\n        width = int(subprocess.check_output(command))\n    except OSError as e:\n        print(\n            \"Invalid Command '{0}': exit status ({1})\".format(\n                command[0], e.errno))\n    except subprocess.CalledProcessError as e:\n        print(\n            \"'{0}' returned non-zero exit status: ({1})\".format(\n                command, e.returncode))\n    else:\n        return width"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a random string from the specified random module.", "response": "def gen_rand_str(*size, use=None, keyspace=None):\n    \"\"\" Generates a random string using random module specified in @use within\n        the @keyspace\n\n        @*size: #int size range for the length of the string\n        @use: the random module to use\n        @keyspace: #str chars allowed in the random string\n        ..\n            from redis_structures.debug import gen_rand_str\n\n            gen_rand_str()\n            # -> 'PRCpAq'\n\n            gen_rand_str(1, 2)\n            # -> 'Y'\n\n            gen_rand_str(12, keyspace=\"abcdefg\")\n            # -> 'gaaacffbedf'\n        ..\n    \"\"\"\n    keyspace = keyspace or (string.ascii_letters + string.digits)\n    keyspace = [char for char in keyspace]\n    use = use or np.random\n    if size:\n        size = size if len(size) == 2 else (size[0], size[0] + 1)\n    else:\n        size = (6, 7)\n    return ''.join(\n        use.choice(keyspace)\n        for _ in range(use.randint(*size)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rand_readable(*size, use=None, density=6):\n    use = use or np.random\n    keyspace = [c for c in string.ascii_lowercase if c != \"l\"]\n    vowels = (\"a\", \"e\", \"i\", \"o\", \"u\")\n\n    def use_vowel(density): not use.randint(0, density)\n    if size:\n        size = size if len(size) == 2 else (size[0]-1, size[0])\n    else:\n        size = (6, 7)\n    return ''.join(\n        use.choice(vowels if use_vowel(density) else keyspace)\n        for _ in range(use.randint(*size)))", "response": "Generates a random string with readable characters using the specified random module."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the name of the object containing obj and returns as a string AttributeNames..", "response": "def get_parent_obj(obj):\n    \"\"\" Gets the name of the object containing @obj and returns as a string\n\n        @obj: any python object\n\n        -> #str parent object name or None\n        ..\n            from redis_structures.debug import get_parent_obj\n\n            get_parent_obj(get_parent_obj)\n            # -> <module 'redis_structures.debug' from>\n        ..\n    \"\"\"\n    try:\n        cls = get_class_that_defined_method(obj)\n        if cls and cls != obj:\n            return cls\n    except AttributeError:\n        pass\n    if hasattr(obj, '__module__') and obj.__module__:\n        try:\n            module = importlib.import_module(obj.__module__)\n            objname = get_obj_name(obj).split(\".\")\n            owner = getattr(module, objname[-2])\n            return getattr(owner, objname[-1])\n        except Exception:\n            try:\n                return module\n            except Exception:\n                pass\n    try:\n        assert hasattr(obj, '__qualname__') or hasattr(obj, '__name__')\n        objname = obj.__qualname__ if hasattr(obj, '__qualname__') \\\n            else obj.__name__\n        objname = objname.split(\".\")\n        assert len(objname) > 1\n        return locate(\".\".join(objname[:-1]))\n    except Exception:\n        try:\n            module = importlib.import_module(\".\".join(objname[:-1]))\n            return module\n        except Exception:\n            pass\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_obj_name(obj, full=True):\n    has_name_attr = hasattr(obj, '__name__')\n    if has_name_attr and obj.__name__ == \"<lambda>\":\n        try:\n            src = whitespace_sub(\"\", inspect.getsource(obj))\\\n                .replace(\"\\n\", \"; \").strip(\" <>\")\n        except OSError:\n            src = obj.__name__\n        return lambda_sub(\"\", src)\n    if hasattr(obj, '__qualname__') and obj.__qualname__:\n        return obj.__qualname__.split(\".\")[-1]\n    elif has_name_attr and obj.__name__:\n        return obj.__name__.split(\".\")[-1]\n    elif hasattr(obj, '__class__'):\n        return str(obj.__class__.__name__).strip(\"<>\")\n    else:\n        return str(obj.__repr__())", "response": "Gets the name of the object in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format(self):\n        _bold = bold\n        if not self.pretty:\n            _bold = lambda x: x\n        # Attach memory address and return\n        _attrs = self._format_attrs()\n        self.data = \"<{}.{}({}){}>{}\".format(\n            self.obj.__module__ if hasattr(self.obj, \"__module__\") \\\n                else \"__main__\",\n            _bold(self.obj.__class__.__name__),\n            _attrs,\n            \":{}\".format(hex(id(self.obj))) if self.address else \"\",\n            _break+self.supplemental if self.supplemental else \"\")\n        return stdout_encode(self.data)", "response": "Formats the __repr__ string containing __repr__ output\n            -> str containing __repr__ output\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate random string from the current state of the object.", "response": "def randstr(self):\n        \"\"\" -> #str result of :func:gen_rand_str \"\"\"\n        return gen_rand_str(\n            2, 10, use=self.random, keyspace=list(self.keyspace))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a random set of size from the set.", "response": "def set(self, size=1000):\n        \"\"\" Creates a random #set\n\n            @size: #int number of random values to include in the set\n\n            -> random #set\n        \"\"\"\n        get_val = lambda: self._map_type()\n        return set(get_val() for x in range(size))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a list of random values from the current set of entries.", "response": "def list(self, size=1000, tree_depth=1):\n        \"\"\" Creates a random #list\n\n            @size: #int number of random values to include in each @tree_depth\n            @tree_depth: #int dict tree dimensions size, i.e.\n                1=|[value1, value2]|\n                2=|[[value1, value2], [value1, value2]]|\n\n            -> random #list\n        \"\"\"\n        if not tree_depth: return self._map_type()\n        return list(self.deque(size, tree_depth-1) for x in range(size))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting and prints the object in a pretty way.", "response": "def pretty_print(self, obj=None):\n        \"\"\" Formats and prints @obj or :prop:obj\n\n            @obj: the object you'd like to prettify\n        \"\"\"\n        print(self.pretty(obj if obj is not None else self.obj))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the intervals as a numpy array", "response": "def array(self):\n        \"\"\" Returns :prop:intervals as a numpy array, caches\n\n            -> :class:numpy.array\n        \"\"\"\n        if self._intervals_len:\n            if self._array_len != self._intervals_len:\n                if not self._array_len:\n                    self._array = np.array(self.intervals) \\\n                        if hasattr(np, 'array') else self.intervals\n                else:\n                    self._array = np.concatenate((\n                        self._array, self.intervals), axis=0) \\\n                        if hasattr(np, 'concatenate') else \\\n                        (self._array + self.intervals)\n                self._array_len += len(self.intervals)\n                self.intervals = []\n            return self._array\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset(self):\n        self._start = 0\n        self._first_start = 0\n        self._stop = time.perf_counter()\n        self._array = None\n        self._array_len = 0\n        self.intervals = []\n        self._intervals_len = 0", "response": "Resets the time intervals"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef time(self, intervals=1, *args, _show_progress=True, _print=True,\n             _collect_garbage=False, **kwargs):\n        \"\"\" Measures the execution time of :prop:_callables for @intervals\n\n            @intervals: #int number of intervals to measure the execution time\n                of the function for\n            @*args: arguments to pass to the callable being timed\n            @**kwargs: arguments to pass to the callable being timed\n            @_show_progress: #bool whether or not to print a progress bar\n            @_print: #bool whether or not to print the results of the timing\n            @_collect_garbage: #bool whether or not to garbage collect\n                while timing\n            @_quiet: #bool whether or not to disable the print() function's\n                ability to output to terminal during the timing\n\n            -> #tuple of :class:Timer :prop:results of timing\n        \"\"\"\n        self.reset()\n        self.num_intervals = intervals\n        for func in self.progress(self._callables):\n            try:\n                #: Don't ruin all timings if just one doesn't work\n                t = Timer(\n                    func, _precision=self.precision,\n                    _parent_progressbar=self.progress)\n                t.time(\n                    intervals, *args, _print=False,\n                    _show_progress=_show_progress,\n                    _collect_garbage=_collect_garbage,\n                    **kwargs)\n            except Exception as e:\n                print(RuntimeWarning(\n                    \"{} with {}\".format(colorize(\n                        \"{} failed\".format(Look.pretty_objname(\n                            func, color=\"yellow\")), \"yellow\"), repr(e))))\n            self._callable_results.append(t)\n            self.progress.update()\n        self.info(_print=_print)\n        return self.results", "response": "Measure the execution time of all the callable s in the specified number of intervals."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(filename):\n    import os\n    here = os.path.dirname(os.path.abspath(__file__))\n    with open(os.path.join(here, filename)) as fd:\n        return fd.read()", "response": "Read a file relative to setup. py location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_version(filename):\n    import re\n    content = read(filename)\n    version_match = re.search(\n        r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\", content, re.M\n    )\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError('Unable to find version string.')", "response": "Find package version in file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind requirements in file.", "response": "def find_requirements(filename):\n    \"\"\"\n    Find requirements in file.\n    \"\"\"\n    import string\n    content = read(filename)\n    requirements = []\n    for line in content.splitlines():\n        line = line.strip()\n        if line and line[:1] in string.ascii_letters:\n            requirements.append(line)\n    return requirements"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_uuid(basedata=None):\n    if basedata is None:\n        return str(uuid.uuid4())\n    elif isinstance(basedata, str):\n        checksum = hashlib.md5(basedata).hexdigest()\n        return '%8s-%4s-%4s-%4s-%12s' % (\n            checksum[0:8], checksum[8:12], checksum[12:16], checksum[16:20], checksum[20:32])", "response": "Provides a _random_ UUID with no input or a UUID4 - format MD5 checksum of any input data provided"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_unix(cls, seconds, milliseconds=0):\n        base = list(time.gmtime(seconds))[0:6]\n        base.append(milliseconds * 1000)  # microseconds\n        return cls(*base)", "response": "Produce a full |datetime. datetime| object from a Unix timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_unix(cls, timestamp):\n        if not isinstance(timestamp, datetime.datetime):\n            raise TypeError('Time.milliseconds expects a datetime object')\n        base = time.mktime(timestamp.timetuple())\n        return base", "response": "Wrapper over time module to produce Unix epoch time as a float"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef milliseconds_offset(cls, timestamp, now=None):\n        if isinstance(timestamp, (int, float)):\n            base = timestamp\n        else:\n            base = cls.to_unix(timestamp)\n            base += (timestamp.microsecond / 1000000)\n        if now is None:\n            now = time.time()\n        return (now - base) * 1000", "response": "Offset time from a |datetime. datetime| object to now"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fixUTF8(cls, data):  # Ensure proper encoding for UA's servers...\n        for key in data:\n            if isinstance(data[key], str):\n                data[key] = data[key].encode('utf-8')\n        return data", "response": "Convert all strings to UTF - 8"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef alias(cls, typemap, base, *names):\n        cls.parameter_alias[base] = (typemap, base)\n        for i in names:\n            cls.parameter_alias[i] = (typemap, base)", "response": "Declare an alternate name for a measurement protocol parameter"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninterprets sequential arguments related to known hittypes based on declared structures", "response": "def consume_options(cls, data, hittype, args):\n        \"\"\" Interpret sequential arguments related to known hittypes based on declared structures \"\"\"\n        opt_position = 0\n        data['t'] = hittype  # integrate hit type parameter\n        if hittype in cls.option_sequence:\n            for expected_type, optname in cls.option_sequence[hittype]:\n                if opt_position < len(args) and isinstance(args[opt_position], expected_type):\n                    data[optname] = args[opt_position]\n                opt_position += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the milliseconds offset for a given hit", "response": "def hittime(cls, timestamp=None, age=None, milliseconds=None):\n        \"\"\" Returns an integer represeting the milliseconds offset for a given hit (relative to now) \"\"\"\n        if isinstance(timestamp, (int, float)):\n            return int(Time.milliseconds_offset(Time.from_unix(timestamp, milliseconds=milliseconds)))\n        if isinstance(timestamp, datetime.datetime):\n            return int(Time.milliseconds_offset(timestamp))\n        if isinstance(age, (int, float)):\n            return int(age * 1000) + (milliseconds or 0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninterpreting time - related options apply queue - time parameter as needed", "response": "def set_timestamp(self, data):\n        \"\"\" Interpret time-related options, apply queue-time parameter as needed \"\"\"\n        if 'hittime' in data:  # an absolute timestamp\n            data['qt'] = self.hittime(timestamp=data.pop('hittime', None))\n        if 'hitage' in data:  # a relative age (in seconds)\n            data['qt'] = self.hittime(age=data.pop('hitage', None))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send(self, hittype, *args, **data):\n\n        if hittype not in self.valid_hittypes:\n            raise KeyError('Unsupported Universal Analytics Hit Type: {0}'.format(repr(hittype)))\n\n        self.set_timestamp(data)\n        self.consume_options(data, hittype, args)\n\n        for item in args:  # process dictionary-object arguments of transcient data\n            if isinstance(item, dict):\n                for key, val in self.payload(item):\n                    data[key] = val\n\n        for k, v in self.params.items():  # update only absent parameters\n            if k not in data:\n                data[k] = v\n\n        data = dict(self.payload(data))\n\n        if self.hash_client_id:\n            data['cid'] = generate_uuid(data['cid'])\n\n        # Transmit the hit to Google...\n        await self.http.send(data)", "response": "Transmit a single hit to Google Analytics using the measurement protocol."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_null_assignment(self, t):\n    '''null_assignment : IDENT EQ NULL'''\n    self.accu.add(Term('obs_vlabel', [self.name,\"gen(\\\"\"+t[1]+\"\\\")\",\"0\"]))", "response": "null_assignment : IDENT EQ NULL"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_minus_assignment(self, t):\n    '''minus_assignment : IDENT EQ MINUS'''\n    self.accu.add(Term('obs_vlabel', [self.name,\"gen(\\\"\"+t[1]+\"\\\")\",\"-1\"]))", "response": "minus_assignment : IDENT EQ MINUS"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_notminus_assignment(self, t):\n    '''notminus_assignment : IDENT EQ NOTMINUS'''\n    self.accu.add(Term('obs_vlabel', [self.name,\"gen(\\\"\"+t[1]+\"\\\")\",\"notMinus\"]))", "response": "notminus_assignment : IDENT EQ NOTMINUS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_input_assignment(self, t):\n    '''input_assignment : IDENT EQ INPUT'''\n    self.accu.add(Term('input', [self.name,\"gen(\\\"\"+t[1]+\"\\\")\"]))", "response": "input_assignment : IDENT EQ INPUT"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_min_assignment(self, t):\n    '''min_assignment : IDENT EQ MIN'''\n    self.accu.add(Term('ismin', [self.name,\"gen(\\\"\"+t[1]+\"\\\")\"]))", "response": "min_assignment : IDENT EQ MIN"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_max_assignment(self, t):\n    '''max_assignment : IDENT EQ MAX'''\n    self.accu.add(Term('ismax', [self.name,\"gen(\\\"\"+t[1]+\"\\\")\"]))", "response": "max_assignment : IDENT EQ MAX"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a specific version of a service.", "response": "def get_service_version(self, service_id, mode='production', version='default'):\n        '''\n        get_service_version(self, service_id, mode='production', version='default')\n\n        | Get a specific version details of a given service. Opereto will try to fetch the requested service version. If not found, it will return the default production version. The \"actual_version\" field of the returned JSON indicates what version of the service is returned. If the actual version is null, it means that this service does not have any version at all. To make it operational, you will have to import or upload a default version.\n\n        :Parameters:\n        * *service_id* (`string`) -- Identifier of an existing service\n        * *mode* (`string`) -- development/production. Default is production\n        * *version* (`string`) -- version of the service (\"default\" is the default.\n\n        :return: json service version details\n\n        :Example:\n        .. code-block:: python\n\n           service_version = opereto_client.get_service_version(serviceId, mode='development', version='111')\n        '''\n        return self._call_rest_api('get', '/services/'+service_id+'/'+mode+'/'+version, error='Failed to fetch service information')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_service(self, service_id, specification=None, description=None, agent_mapping=None):\n        '''\n        verify_service(self, service_id, specification=None, description=None, agent_mapping=None)\n\n        | Verifies validity of service yaml\n\n        :Parameters:\n        * *service_id* (`string`) -- Identifier of an existing service\n        * *specification* (`string`) -- service specification yaml\n        * *description* (`string`) -- service description written in text or markdown style\n        * *agent_mapping* (`string`) -- agents mapping specification\n\n        :return: json service version details\n\n        :Example:\n        .. code-block:: python\n\n           spec = {\n               \"type\": \"action\",\n               \"cmd\": \"python -u run.py\",\n               \"timeout\": 600,\n               \"item_properties\": [\n                    {\"key\": \"key1\", \"type\": \"text\", \"value\": \"value1\", \"direction\": \"input\"},\n                    {\"key\": \"key2\", \"type\": \"boolean\", \"value\": True, \"direction\": \"input\"}\n                 ]\n              }\n           if opereto_client.verify_service ('hello_world', specification=spec)['errors'] == []:\n              result = True\n\n        '''\n        request_data = {'id': service_id}\n        if specification:\n            request_data['spec']=specification\n        if description:\n            request_data['description']=description\n        if agent_mapping:\n            request_data['agents']=agent_mapping\n        return self._call_rest_api('post', '/services/verify', data=request_data, error='Service [%s] verification failed'%service_id)", "response": "Verify validity of a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload_service_version(self, service_zip_file, mode='production', service_version='default', service_id=None, **kwargs):\n        '''\n        upload_service_version(self, service_zip_file, mode='production', service_version='default', service_id=None, **kwargs)\n\n        Upload a service version to Opereto\n\n        :Parameters:\n        * *service_zip_file* (`string`) -- zip file location containing service and service specification\n        * *mode* (`string`) -- production/development (default is production)\n        * *service_version* (`string`) -- Service version\n        * *service_id* (`string`) -- Service Identifier\n\n        :Keywords args:\n        * *comment* (`string`) -- comment\n\n        :Example:\n        .. code-block:: python\n\n           opereto_client.upload_service_version(service_zip_file=zip_action_file+'.zip', mode='production', service_version='111')\n\n        '''\n        files = {'service_file': open(service_zip_file,'rb')}\n        url_suffix = '/services/upload/%s'%mode\n        if mode=='production':\n            url_suffix+='/'+service_version\n        if service_id:\n            url_suffix+='/'+service_id\n        if kwargs:\n            url_suffix=url_suffix+'?'+urlencode(kwargs)\n        return self._call_rest_api('post', url_suffix, files=files, error='Failed to upload service version')", "response": "Uploads a service version to Opereto."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports a service version into Opereto from a remote repository.", "response": "def import_service_version(self, repository_json, mode='production', service_version='default', service_id=None, **kwargs):\n        '''\n        import_service_version(self, repository_json, mode='production', service_version='default', service_id=None, **kwargs)\n\n        Imports a service version into Opereto from a remote repository (GIT, SVN, AWS S3, any HTTPS repository)\n\n        :Parameters:\n        * *repository_json* (`object`) -- repository_json\n        :Example of repository JSON:\n            .. code-block:: json\n\n                #GIT source control\n                {\n                    \"repo_type\": \"git\",\n                    \"url\": \"git@bitbucket.org:my_account_name/my_project.git\",\n                    \"branch\": \"master\",\n                    \"ot_dir\": \"mydir\"\n                }\n\n                #SVN\n                {\n                    \"repo_type\": \"svn\",\n                    \"url\": \"svn://myhost/myrepo\",\n                    \"username\": \"OPTIONAL_USERNAME\",\n                    \"password\": \"OPTIONAL_PASSWORD\",\n                    \"ot_dir\": \"my_service_dir\"\n                }\n\n                # Any HTTP based remote storage\n\n                {\n                    \"repo_type\": \"http\",\n                    \"url\": \"https://www.dropbox.com/s/1234567890/MyFile.zip?dl=0\",\n                    \"username\": \"OPTIONAL_PASSWORD\",\n                    \"ot_dir\": \"my_service_dir\"\n                }\n\n                # AWS S3 Storage\n\n                {\n                    \"repo_type\": \"s3\",\n                    \"bucket\": \"my_bucket/my_service.zip\",\n                    \"access_key\": \"MY_ACCESS_KEY\",\n                    \"secret_key\": \"MY_SECRET_KEY\",\n                    \"ot_dir\": \"my_service_dir\"\n                }\n\n        * *mode* (`string`) -- production/development (default is production)\n        * *service_version* (`string`) -- Service version\n        * *service_id* (`string`) -- Service version\n\n\n        :return: status - success/failure\n\n        :Example:\n        .. code-block:: python\n\n            # for GIT\n           repository_json = {\n                \"branch\": \"master\",\n                \"ot_dir\": \"microservices/hello_world\",\n                \"repo_type\": \"git\",\n                \"url\": \"https://github.com/myCompany/my_services.git\"\n            }\n\n            opereto_client.import_service_version(repository_json, mode='production', service_version='default', service_id=self.my_service2)\n\n        '''\n        request_data = {'repository': repository_json, 'mode': mode, 'service_version': service_version, 'id': service_id}\n        url_suffix = '/services'\n        if kwargs:\n            url_suffix=url_suffix+'?'+urlencode(kwargs)\n        return self._call_rest_api('post', url_suffix, data=request_data, error='Failed to import service')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_service_version(self, service_id , service_version='default', mode='production'):\n        '''\n        delete_service(self, service_id, service_version='default', mode='production')\n\n        Deletes a Service version from Opereto\n\n        :Parameters:\n        * *service_id* (`string`) -- Service identifier\n        * *service_version* (`string`) -- Service version. Default is 'default'\n        * *mode* (`string`) -- development/production. Default is production\n\n        :return: success/failure\n\n        :Example:\n        .. code-block:: python\n\n           opereto_client.delete_service('my_service_id')\n\n        '''\n        return self._call_rest_api('delete', '/services/'+service_id+'/'+mode+'/'+service_version, error='Failed to delete service')", "response": "Delete a Service version from Opereto"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_environment_scheme(self, environment_type, environment_topology):\n        '''\n        verify_environment_scheme(self, environment_type, environment_topology)\n\n        Verifies json scheme of an environment\n\n        :Parameters:\n\n        * *environment_type* (`string`) -- Topology identifier\n        * *environment_topology* (`object`) -- Environment json to validate\n\n        :return: Success or errors in case the verification failed\n\n        :Return Example:\n        .. code-block:: json\n\n            # verification failure\n            {'errors': ['Topology key cluster_name is missing in environment specification'], 'agents': {}, 'success': False, 'warnings': []}\n\n            # verification success\n            {'errors': [], 'agents': {}, 'success': True, 'warnings': []}\n\n        :Example:\n        .. code-block:: python\n\n            environment_topology =\n            {\n                  \"cluster_name\": \"k8s-clusbbe9\",\n                  \"config_file\": {\n                    \"contexts\": [\n                      {\n                        \"name\": \"my-context\"\n                      }\n                    ],\n                    \"clusters\": [\n                      {\n                        \"name\": \"k8s-clusbbe9\"\n                      }\n                    ]\n                  }\n            }\n            environment = opereto_client.verify_environment_scheme(environment_type = 'myTopology', environment_topology = environment_topology)\n\n        '''\n        request_data = {'topology_name': environment_type, 'topology': environment_topology}\n        return self._call_rest_api('post', '/environments/verify', data=request_data, error='Failed to verify environment.')", "response": "This function is used to verify the json scheme of an environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify_environment(self, environment_id):\n        '''\n        verify_environment(self, environment_id)\n\n        Verifies validity of an existing environment\n\n        :Parameters:\n\n        * *environment_id* (`string`) -- Environment identifier\n\n        :return: Success or errors in case the verification failed\n\n        :Return Example:\n        .. code-block:: json\n\n            # verification failure\n            {'errors': ['Topology key cluster_name is missing in environment specification'], 'agents': {}, 'success': False, 'warnings': []}\n\n            # verification success\n            {'errors': [], 'agents': {}, 'success': True, 'warnings': []}\n\n        '''\n        request_data = {'id': environment_id}\n        return self._call_rest_api('post', '/environments/verify', data=request_data, error='Failed to verify environment.')", "response": "Verifies validity of an existing environment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new environment", "response": "def create_environment(self, topology_name, topology={}, id=None, **kwargs):\n        '''\n        create_environment(self, topology_name, topology={}, id=None, **kwargs)\n\n        Create a new environment\n\n        :Parameters:\n\n        * *topology_name* (`string`) -- The topology identifier. Must be provided to create an environment.\n        * *topology* (`object`) -- Topology data (must match the topology json schema)\n        * *id* (`object`) -- The environment identifier. If none provided when creating environment, Opereto will automatically assign a unique identifier.\n\n        :return: id of the created environment\n\n        '''\n        request_data = {'topology_name': topology_name,'id': id, 'topology':topology, 'add_only':True}\n        request_data.update(**kwargs)\n        return self._call_rest_api('post', '/environments', data=request_data, error='Failed to create environment')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modify_environment(self, environment_id, **kwargs):\n        '''\n        modify_environment(self, environment_id, **kwargs)\n\n        Modifies an existing environment\n\n        :Parameters:\n        * *environment_id* (`string`) -- The environment identifier\n\n        Keywords args:\n        The variables to change in the environment\n\n        :return: id of the created environment\n\n        '''\n        request_data = {'id': environment_id}\n        request_data.update(**kwargs)\n        return self._call_rest_api('post', '/environments', data=request_data, error='Failed to modify environment')", "response": "This method allows you to modify an existing environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_agents(self, start=0, limit=100, filter={}, **kwargs):\n        '''\n        search_agents(self, start=0, limit=100, filter={}, **kwargs)\n\n        Search agents\n\n        :Parameters:\n        * *start* (`int`) -- start index to retrieve from. Default is 0\n        * *limit* (`int`) -- maximum number of entities to retrieve. Default is 100\n        * *filter* (`object`) -- free text search pattern (checks in agent data and properties)\n\n        :return: List of search results or empty list\n\n        :Example:\n        .. code-block:: python\n\n           filter = {'generic': 'my Agent'}\n           search_result = opereto_client.search_agents(filter=filter)\n\n        '''\n        request_data = {'start': start, 'limit': limit, 'filter': filter}\n        request_data.update(kwargs)\n        return self._call_rest_api('post', '/search/agents', data=request_data, error='Failed to search agents')", "response": "Search agents for free text entries in the agent store."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef modify_agent_property(self, agent_id, key, value):\n        '''\n        modify_agent_property(self, agent_id, key, value)\n\n        Modifies a single single property of an agent. If the property does not exists then it is created as a custom property.\n\n        :Parameters:\n        * *agent_id* (`string`) -- Identifier of an existing agent\n        * *key* (`string`) -- Key of a property to change\n        * *value* (`string`) -- New Value of the property to change\n\n        :Example:\n        .. code-block:: python\n\n           opereto_client.modify_agent_property('my_agent_id', 'agent_new_property', 'agent value')\n\n        '''\n        return self._call_rest_api('post', '/agents/'+agent_id+'/properties', data={key: value}, error='Failed to modify agent [%s] property [%s]'%(agent_id,key))", "response": "Modify a single property of an agent."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef modify_agent_properties(self, agent_id, key_value_map={}):\n        '''\n        modify_agent_properties(self, agent_id, key_value_map={})\n\n        Modify properties of an agent. If properties do not exists, they will be created\n\n        :Parameters:\n        * *agent_id* (`string`) -- Identifier of an existing agent\n        * *key_value_map* (`object`) -- Key value map of properties to change\n        * *value* (`string`) -- New Value of the property to change\n\n        :Example:\n        .. code-block:: python\n\n           opereto_client.modify_agent_properties('my_agent_id', {\"mykey\": \"myvalue\", \"mykey2\": \"myvalue2\"})\n\n        '''\n        return self._call_rest_api('post', '/agents/'+agent_id+'/properties', data=key_value_map, error='Failed to modify agent [%s] properties'%agent_id)", "response": "Modify agent properties of an agent"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an agent based on the identifier provided.", "response": "def create_agent(self, agent_id=None, **kwargs):\n        '''\n        create_agent(self, agent_id=None, **kwargs)\n\n        | Creates an agent based on the identifier provided. \\\n        | The agent will become online when a real agent will connect using this identifier. \\\n        | However, in most cases, the agent entity is created automatically when a new agent connects to opereto. \\\n\n        :Parameters:\n        * *agent_id* (`string`) -- Identifier of an existing agent\n        :Keywords args:\n        * *name* (`string`) -- Display name to show in the UI\n        * *description* (`string`) -- A textual description of the agent\n        * *permissions* (`object`) -- Permissions on the agent\n            * *owners* (`array`) -- List of Opereto usernames that may modify and delete the agent\n            * *owners* (`array`) -- List of Opereto usernames that may run services on the agent\n        :return: id of the generated agent\n\n        :Example:\n        .. code-block:: python\n\n           opereto_client = OperetoClient()\n           opereto_client.create_agent(agent_id='xAgent', name='My new agent', description='A new created agent to be called from X machines')\n\n\n        '''\n\n        request_data = {'id': agent_id, 'add_only':True}\n        request_data.update(**kwargs)\n        return self._call_rest_api('post', '/agents'+'', data=request_data, error='Failed to create agent')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying the agent s information", "response": "def modify_agent(self, agent_id, **kwargs):\n        '''\n        modify_agent(self, agent_id, **kwargs)\n\n        | Modifies agent information (like name)\n\n        :Parameters:\n        * *agent_id* (`string`) -- Identifier of an existing agent\n\n         :Example:\n        .. code-block:: python\n\n           opereto_client = OperetoClient()\n           opereto_client.modify_agent('agentId', name='my new name')\n\n        '''\n        request_data = {'id': agent_id}\n        request_data.update(**kwargs)\n        return self._call_rest_api('post', '/agents'+'', data=request_data, error='Failed to modify agent [%s]'%agent_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new process or processes.", "response": "def create_process(self, service, agent=None, title=None, mode=None, service_version=None, **kwargs):\n        '''\n        create_process(self, service, agent=None, title=None, mode=None, service_version=None, **kwargs)\n\n        Registers a new process or processes\n\n        :Parameters:\n        * *service* (`string`) -- Service which process will be started\n        * *agent* (`string`) -- The service identifier (e.g shell_command)\n        * *title* (`string`) -- Title for the process\n        * *mode* (`string`) -- production/development\n        * *service_version* (`string`) -- Version of the service to execute\n\n        :Keywords args:\n        Json value map containing the process input properties\n\n        :return: process id\n\n        :Example:\n        .. code-block:: python\n\n           process_properties = {\"my_input_param\" : \"1\"}\n           pid = opereto_client.create_process(service='simple_shell_command', title='Test simple shell command service', agent=opereto_client.input['opereto_agent'], **process_properties)\n\n        '''\n        if not agent:\n            agent = self.input.get('opereto_agent')\n\n        if not mode:\n            mode=self.input.get('opereto_execution_mode') or 'production'\n        if not service_version:\n            service_version=self.input.get('opereto_service_version')\n\n        request_data = {'service_id': service, 'agents': agent, 'mode': mode, 's_version':service_version}\n        if title:\n            request_data['name']=title\n\n        if self.input.get('pid'):\n            request_data['pflow_id']=self.input.get('pid')\n\n        request_data.update(**kwargs)\n        ret_data= self._call_rest_api('post', '/processes', data=request_data, error='Failed to create a new process')\n\n        if not isinstance(ret_data, list):\n            raise OperetoClientError(str(ret_data))\n\n        pid = ret_data[0]\n        message = 'New process created for service [%s] [pid = %s] '%(service, pid)\n        if agent:\n            message += ' [agent = %s]'%agent\n        else:\n            message += ' [agent = any ]'\n        self.logger.info(message)\n        return str(pid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rerun_process(self, pid, title=None, agent=None):\n        '''\n        rerun_process(self, pid, title=None, agent=None)\n\n        Reruns a process\n\n        :Parameters:\n        * *pid* (`string`) -- Process id to rerun\n        * *title* (`string`) -- Title for the process\n        * *agent* (`string`) -- a valid value may be one of the following: agent identifier, agent identifiers (list) : [\"agent_1\", \"agent_2\"..], \"all\", \"any\"\n\n        :return: process id\n\n        '''\n        request_data = {}\n        if title:\n            request_data['name']=title\n        if agent:\n            request_data['agents']=agent\n\n        if self.input.get('pid'):\n            request_data['pflow_id']=self.input.get('pid')\n\n        ret_data= self._call_rest_api('post', '/processes/'+pid+'/rerun', data=request_data, error='Failed to create a new process')\n\n        if not isinstance(ret_data, list):\n            raise OperetoClientError(str(ret_data))\n\n        new_pid = ret_data[0]\n        message = 'Re-executing process [%s] [new process pid = %s] '%(pid, new_pid)\n        self.logger.info(message)\n        return str(new_pid)", "response": "rerun_process(self, pid, title=None, agent=None)\n\n        Reruns a process\n\n        :Parameters:\n        * *pid* (`string`) -- Process id to rerun\n        * *title* (`string`) -- Title for the process\n        * *agent* (`string`) -- a valid value may be one of the following: agent identifier, agent identifiers (list) : [\"agent_1\", \"agent_2\"..], \"all\", \"any\"\n\n        :return: process id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmodifying process output properties.", "response": "def modify_process_properties(self, key_value_map={}, pid=None):\n        '''\n        modify_process_properties(self, key_value_map={}, pid=None)\n\n        Modify process output properties.\n        Please note that process property key provided must be declared as an output property in the relevant service specification.\n\n        :Parameters:\n        * *key_value_map* (`object`) -- key value map with process properties to modify\n        * *pid* (`string`) -- Identifier of an existing process\n\n        :Example:\n        .. code-block:: python\n\n           process_output_properties = {\"my_output_param\" : \"1\"}\n           pid = opereto_client.create_process(service='simple_shell_command', title='Test simple shell command service')\n           opereto_client.modify_process_properties(process_output_properties, pid)\n\n        '''\n        pid = self._get_pid(pid)\n        request_data={\"properties\": key_value_map}\n        return self._call_rest_api('post', '/processes/'+pid+'/output', data=request_data, error='Failed to output properties')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modify_process_property(self, key, value, pid=None):\n        '''\n        modify_process_property(self, key, value, pid=None)\n\n        Modify process output property.\n        Please note that the process property key provided must be declared as an output property in the relevant service specification.\n\n        :Parameters:\n        * *key* (`String`) -- key of property to modify\n        * *key* (`value`) -- value of property to modify\n        * *pid* (`string`) -- Identifier of an existing process\n\n        :Example:\n        .. code-block:: python\n\n           pid = opereto_client.create_process(service='simple_shell_command', title='Test simple shell command service')\n           opereto_client.modify_process_property(\"my_output_param\", \"1\" , pid)\n\n        '''\n        pid = self._get_pid(pid)\n        request_data={\"key\" : key, \"value\": value}\n        return self._call_rest_api('post', '/processes/'+pid+'/output', data=request_data, error='Failed to modify output property [%s]'%key)", "response": "Modify the value of a process output property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modify_process_summary(self, pid=None, text='', append=False):\n        '''\n        modify_process_summary(self, pid=None, text='')\n\n        Modifies the summary text of the process execution\n\n        :Parameters:\n        * *key* (`pid`) -- Identifier of an existing process\n        * *key* (`text`) -- summary text\n        * *append* (`boolean`) -- True to append to summary. False to override it.\n\n        '''\n        pid = self._get_pid(pid)\n\n        if append:\n            current_summary =  self.get_process_info(pid).get('summary') or ''\n            modified_text = current_summary + '\\n' + text\n            text = modified_text\n\n        request_data = {\"id\": pid, \"data\": str(text)}\n        return self._call_rest_api('post', '/processes/'+pid+'/summary', data=request_data, error='Failed to update process summary')", "response": "Modify the summary text of a process execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops a running process.", "response": "def stop_process(self, pids, status='success'):\n        '''\n        stop_process(self, pids, status='success')\n\n        Stops a running process\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n        * *result* (`string`) -- the value the process will be terminated with. Any of the following possible values:  success , failure , error , warning , terminated\n\n        '''\n        if status not in process_result_statuses:\n            raise OperetoClientError('Invalid process result [%s]'%status)\n        pids = self._get_pids(pids)\n        for pid in pids:\n            self._call_rest_api('post', '/processes/'+pid+'/terminate/'+status, error='Failed to stop process')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the current status of a process.", "response": "def get_process_status(self, pid=None):\n        '''\n        get_process_status(self, pid=None)\n\n        Get current status of a process\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n\n        '''\n        pid = self._get_pid(pid)\n        return self._call_rest_api('get', '/processes/'+pid+'/status', error='Failed to fetch process status')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_process_flow(self, pid=None):\n        '''\n        get_process_flow(self, pid=None)\n\n        Get process in flow context. The response returns a sub-tree of the whole flow containing the requested process, its direct children processes, and all ancestors.\n        You can navigate within the flow backword and forward by running this call on the children or ancestors of a given process.\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n\n        '''\n        pid = self._get_pid(pid)\n        return self._call_rest_api('get', '/processes/'+pid+'/flow', error='Failed to fetch process information')", "response": "Get process in flow context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_process_rca(self, pid=None):\n        '''\n        get_process_rca(self, pid=None)\n\n        Get the RCA tree of a given failed process. The RCA tree contains all failed child processes that caused the failure of the given process.\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n\n        '''\n        pid = self._get_pid(pid)\n        return self._call_rest_api('get', '/processes/'+pid+'/rca', error='Failed to fetch process information')", "response": "Get the RCA tree of a given failed process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_process_info(self, pid=None):\n        '''\n        get_process_info(self, pid=None)\n\n        Get process general information.\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n\n        '''\n\n        pid = self._get_pid(pid)\n        return self._call_rest_api('get', '/processes/'+pid, error='Failed to fetch process information')", "response": "Get process general information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_process_log(self, pid=None, start=0, limit=1000):\n        '''\n        get_process_log(self, pid=None, start=0, limit=1000\n\n        Get process logs\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n        * *pid* (`string`) -- start index to retrieve logs from\n        * *pid* (`string`) -- maximum number of entities to retrieve\n\n        :return: Process log entries\n\n        '''\n        pid = self._get_pid(pid)\n        data = self._call_rest_api('get', '/processes/'+pid+'/log?start={}&limit={}'.format(start,limit), error='Failed to fetch process log')\n        return data['list']", "response": "Get the process log entries for a process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_process_log(self, pid, filter={}, start=0, limit=1000):\n        '''\n        search_process_log(self, pid, filter={}, start=0, limit=1000)\n\n        Search in process logs\n\n        :Parameters:\n        * *pid* (`string`) -- Identifier of an existing process\n        * *start* (`int`) -- start index to retrieve from. Default is 0\n        * *limit* (`int`) -- maximum number of entities to retrieve. Default is 100\n        * *filter* (`object`) -- free text search pattern (checks in process log data)\n\n        :return: Count of records found and list of search results or empty list\n\n        :Example:\n        .. code-block:: python\n\n           filter = {'generic': 'my product param'}\n           search_result = opereto_client.search_globals(filter=filter)\n           if search_result['total'] > 0\n              print(search_result['list'])\n        '''\n        pid = self._get_pid(pid)\n        request_data = {'start': start, 'limit': limit, 'filter': filter}\n        return self._call_rest_api('post', '/processes/' + pid + '/log/search', data=request_data,\n                                    error='Failed to search in process log')", "response": "Search in process logs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_for(self, pids=[], status_list=process_result_statuses):\n        '''\n        wait_for(self, pids=[], status_list=process_result_statuses)\n\n        Waits for a process to finish\n\n        :Parameters:\n        * *pids* (`list`) -- list of processes waiting to be finished\n        * *status_list* (`list`) -- optional - List of statuses to wait for processes to finish with\n\n        :Example:\n        .. code-block:: python\n\n           pid = opereto_client.create_process(service='simple_shell_command', title='Test simple shell command service')\n           opereto_client.wait_for([pid], ['failure', 'error'])\n           opereto_client.rerun_process(pid)\n\n        '''\n        results={}\n        pids = self._get_pids(pids)\n        for pid in pids:\n            while(True):\n                try:\n                    stat = self._call_rest_api('get', '/processes/'+pid+'/status', error='Failed to fetch process [%s] status'%pid)\n                    if stat in status_list:\n                        results[pid]=stat\n                        break\n                    time.sleep(5)\n                except requests.exceptions.RequestException as e:\n                    # reinitialize session using api call decorator\n                    self.session=None\n                    raise e\n        return results", "response": "Waits for a process to finish and returns a dict of process ids and status codes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_to_start(self, pids=[]):\n        '''\n        wait_to_start(self, pids=[])\n\n        Wait for processes to start\n\n        :Parameters:\n        * *pids* (`list`) -- list of processes to wait to start\n\n        '''\n        actual_pids = self._get_pids(pids)\n        return self.wait_for(pids=actual_pids, status_list=process_result_statuses+['in_process'])", "response": "Wait for processes to start"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for processes to finish", "response": "def wait_to_end(self, pids=[]):\n        '''\n        wait_to_end(self, pids=[])\n\n        Wait for processes to finish\n\n        :Parameters:\n        * *pids* (`list`) -- list of processes to wait to finish\n\n        '''\n        actual_pids = self._get_pids(pids)\n        return self.wait_for(pids=actual_pids, status_list=process_result_statuses)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a pre - defined run time parameter value for a process.", "response": "def get_process_runtime_cache(self, key, pid=None):\n        '''\n        get_process_runtime_cache(self, key, pid=None)\n\n        Get a pre-defined run time parameter value\n\n        :Parameters:\n        * *key* (`string`) -- Identifier of the runtime cache\n        * *pid* (`string`) -- Identifier of an existing process\n\n        '''\n        value = None\n        pid = self._get_pid(pid)\n        value = self._call_rest_api('get', '/processes/'+pid+'/cache?key=%s'%key, error='Failed to fetch process runtime cache')\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a process s runtime cache.", "response": "def set_process_runtime_cache(self, key, value, pid=None):\n        '''\n        set_process_runtime_cache(self, key, value, pid=None)\n\n        Set a process run time parameter\n\n        :Parameters:\n        * *key* (`string`) -- parameter key\n        * *key* (`value`) -- parameter value\n        * *key* (`pid`) -- optional - Identifier of an existing process\n\n        '''\n        pid = self._get_pid(pid)\n        self._call_rest_api('post', '/processes/'+pid+'/cache', data={'key': key, 'value': value}, error='Failed to modify process runtime cache')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef modify_product(self, product_id, name=None, description=None, attributes={}):\n        '''\n        modify_product(self, product_id, name=None, description=None, attributes={})\n\n        Modify an existing product\n\n        :Parameters:\n        * *product_id* (`string`) -- identifier of an existing product\n        * *name* (`string`) -- name of the product\n        * *description* (`string`) -- product description\n        * *attributes* (`object`) -- product attributes to modify\n\n        '''\n        request_data = {'id': product_id}\n        if name: request_data['name']=name\n        if description: request_data['description']=description\n        if attributes: request_data['attributes']=attributes\n        return self._call_rest_api('post', '/products', data=request_data, error='Failed to modify a new product')", "response": "Modify an existing product in the current version of the base product."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self):\n        for entry in self._instream:\n            if isinstance(entry, Feature):\n                for feature in entry:\n                    if feature.num_children > 0 or feature.is_multi:\n                        if feature.is_multi and feature != feature.multi_rep:\n                            continue\n                        self.feature_counts[feature.type] += 1\n                        fid = '{}{}'.format(feature.type,\n                                            self.feature_counts[feature.type])\n                        feature.add_attribute('ID', fid)\n                    else:\n                        feature.drop_attribute('ID')\n            if isinstance(entry, Sequence) and not self._seq_written:\n                print('##FASTA', file=self.outfile)\n                self._seq_written = True\n            print(repr(entry), file=self.outfile)", "response": "Pull features from the instream and write them to the output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a datetime object to a year - day - of - year tuple.", "response": "def datetime2yeardoy(time: Union[str, datetime.datetime]) -> Tuple[int, float]:\n    \"\"\"\n    Inputs:\n    T: Numpy 1-D array of datetime.datetime OR string for dateutil.parser.parse\n\n    Outputs:\n    yd: yyyyddd four digit year, 3 digit day of year (INTEGER)\n    utsec: seconds from midnight utc\n    \"\"\"\n    T = np.atleast_1d(time)\n\n    utsec = np.empty_like(T, float)\n    yd = np.empty_like(T, int)\n    for i, t in enumerate(T):\n        if isinstance(t, np.datetime64):\n            t = t.astype(datetime.datetime)\n        elif isinstance(t, str):\n            t = parse(t)\n\n        utsec[i] = datetime2utsec(t)\n        yd[i] = t.year*1000 + int(t.strftime('%j'))\n\n    return yd.squeeze()[()], utsec.squeeze()[()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a yeardate to a datetime object.", "response": "def yeardoy2datetime(yeardate: int,\n                     utsec: Union[float, int] = None) -> datetime.datetime:\n    \"\"\"\n    Inputs:\n    yd: yyyyddd four digit year, 3 digit day of year (INTEGER 7 digits)\n\n    outputs:\n    t: datetime\n\n    http://stackoverflow.com/questions/2427555/python-question-year-and-day-of-year-to-date\n    \"\"\"\n    if isinstance(yeardate, (tuple, list, np.ndarray)):\n        if utsec is None:\n            return np.asarray([yeardoy2datetime(y) for y in yeardate])\n        elif isinstance(utsec, (tuple, list, np.ndarray)):\n            return np.asarray([yeardoy2datetime(y, s) for y, s in zip(yeardate, utsec)])\n\n    yeardate = int(yeardate)\n\n    yd = str(yeardate)\n    if len(yd) != 7:\n        raise ValueError('yyyyddd expected')\n\n    year = int(yd[:4])\n    assert 0 < year < 3000, 'year not in expected format'\n\n    dt = datetime.datetime(year, 1, 1) + datetime.timedelta(days=int(yd[4:]) - 1)\n    assert isinstance(dt, datetime.datetime)\n\n    if utsec is not None:\n        dt += datetime.timedelta(seconds=utsec)\n\n    return dt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a datetime. datetime object to a doy year and year", "response": "def date2doy(time: Union[str, datetime.datetime]) -> Tuple[int, int]:\n    \"\"\"\n    < 366 for leap year too. normal year 0..364.  Leap 0..365.\n    \"\"\"\n\n    T = np.atleast_1d(time)\n\n    year = np.empty(T.size, dtype=int)\n    doy = np.empty_like(year)\n\n    for i, t in enumerate(T):\n        yd = str(datetime2yeardoy(t)[0])\n\n        year[i] = int(yd[:4])\n        doy[i] = int(yd[4:])\n\n    assert ((0 < doy) & (doy < 366)).all(), 'day of year must be 0 < doy < 366'\n\n    return doy, year"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef datetime2gtd(time: Union[str, datetime.datetime, np.datetime64],\n                 glon: Union[float, List[float], np.ndarray] = np.nan) -> Tuple[int, float, float]:\n    \"\"\"\n    Inputs:\n    time: Numpy 1-D array of datetime.datetime OR string for dateutil.parser.parse\n    glon: Numpy 2-D array of geodetic longitudes (degrees)\n\n    Outputs:\n    iyd: day of year\n    utsec: seconds from midnight utc\n    stl: local solar time\n    \"\"\"\n# %%\n    T = np.atleast_1d(time)\n    glon = np.asarray(glon)\n    doy = np.empty_like(T, int)\n    utsec = np.empty_like(T, float)\n    stl = np.empty((T.size, *glon.shape))\n\n    for i, t in enumerate(T):\n        if isinstance(t, str):\n            t = parse(t)\n        elif isinstance(t, np.datetime64):\n            t = t.astype(datetime.datetime)\n        elif isinstance(t, (datetime.datetime, datetime.date)):\n            pass\n        else:\n            raise TypeError('unknown time datatype {}'.format(type(t)))\n# %% Day of year\n        doy[i] = int(t.strftime('%j'))\n# %% seconds since utc midnight\n        utsec[i] = datetime2utsec(t)\n\n        stl[i, ...] = utsec[i] / 3600. + glon / 15.\n\n    return doy, utsec, stl", "response": "Convert a datetime object to a date and time array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef datetime2utsec(t: Union[str, datetime.date, datetime.datetime, np.datetime64]) -> float:\n    if isinstance(t, (tuple, list, np.ndarray)):\n        return np.asarray([datetime2utsec(T) for T in t])\n    elif isinstance(t, datetime.date) and not isinstance(t, datetime.datetime):\n        return 0.\n    elif isinstance(t, np.datetime64):\n        t = t.astype(datetime.datetime)\n    elif isinstance(t, str):\n        t = parse(t)\n\n    return datetime.timedelta.total_seconds(t - datetime.datetime.combine(t.date(),\n                                                                          datetime.datetime.min.time()))", "response": "converts datetime to utc seconds since THIS DAYS MIDNIGHT\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yeardec2datetime(atime: float) -> datetime.datetime:\n# %%\n    if isinstance(atime, (float, int)):  # typically a float\n\n        year = int(atime)\n        remainder = atime - year\n        boy = datetime.datetime(year, 1, 1)\n        eoy = datetime.datetime(year + 1, 1, 1)\n        seconds = remainder * (eoy - boy).total_seconds()\n\n        T = boy + datetime.timedelta(seconds=seconds)\n        assert isinstance(T, datetime.datetime)\n    elif isinstance(atime[0], float):\n        return np.asarray([yeardec2datetime(t) for t in atime])\n    else:\n        raise TypeError('expecting float, not {}'.format(type(atime)))\n\n    return T", "response": "Convert a year to a datetime object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a datetime into a float. The integer part of the float should be preserved.", "response": "def datetime2yeardec(time: Union[str, datetime.datetime, datetime.date]) -> float:\n    \"\"\"\n    Convert a datetime into a float. The integer part of the float should\n    represent the year.\n    Order should be preserved. If adate<bdate, then d2t(adate)<d2t(bdate)\n    time distances should be preserved: If bdate-adate=ddate-cdate then\n    dt2t(bdate)-dt2t(adate) = dt2t(ddate)-dt2t(cdate)\n    \"\"\"\n    if isinstance(time, str):\n        t = parse(time)\n    elif isinstance(time, datetime.datetime):\n        t = time\n    elif isinstance(time, datetime.date):\n        t = datetime.datetime.combine(time, datetime.datetime.min.time())\n    elif isinstance(time, (tuple, list, np.ndarray)):\n        return np.asarray([datetime2yeardec(t) for t in time])\n    else:\n        raise TypeError('unknown input type {}'.format(type(time)))\n\n    year = t.year\n\n    boy = datetime.datetime(year, 1, 1)\n    eoy = datetime.datetime(year + 1, 1, 1)\n\n    return year + ((t - boy).total_seconds() / ((eoy - boy).total_seconds()))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randomdate(year: int) -> datetime.date:\n    if calendar.isleap(year):\n        doy = random.randrange(366)\n    else:\n        doy = random.randrange(365)\n\n    return datetime.date(year, 1, 1) + datetime.timedelta(days=doy)", "response": "gives random date in year"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of names of arguments to __init__ method of this object s class.", "response": "def init_arg_names(obj):\n    \"\"\"\n    Names of arguments to __init__ method of this object's class.\n    \"\"\"\n    # doing something wildly hacky by pulling out the arguments to\n    # __init__ or __new__ and hoping that they match fields defined on the\n    # object\n    try:\n        init_code = obj.__init__.__func__.__code__\n    except AttributeError:\n        try:\n            init_code = obj.__new__.__func__.__code__\n        except AttributeError:\n            # if object is a namedtuple then we can return its fields\n            # as the required initial args\n            if hasattr(obj, \"_fields\"):\n                return obj._fields\n            else:\n                raise ValueError(\"Cannot determine args to %s.__init__\" % (obj,))\n\n    arg_names = init_code.co_varnames[:init_code.co_argcount]\n    # drop self argument\n    nonself_arg_names = arg_names[1:]\n    return nonself_arg_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a Python function into a serializable representation.", "response": "def function_to_serializable_representation(fn):\n    \"\"\"\n    Converts a Python function into a serializable representation. Does not\n    currently work for methods or functions with closure data.\n    \"\"\"\n    if type(fn) not in (FunctionType, BuiltinFunctionType):\n        raise ValueError(\n            \"Can't serialize %s : %s, must be globally defined function\" % (\n                fn, type(fn),))\n\n    if hasattr(fn, \"__closure__\") and fn.__closure__ is not None:\n        raise ValueError(\"No serializable representation for closure %s\" % (fn,))\n\n    return {\"__module__\": get_module_name(fn), \"__name__\": fn.__name__}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_to_serializable_repr(x):\n    # list of JSON representations of hashable objects which were\n    # used as keys in this dictionary\n    serialized_key_list = []\n    serialized_keys_to_names = {}\n    # use the class of x rather just dict since we might want to convert\n    # derived classes such as OrderedDict\n    result = type(x)()\n    for (k, v) in x.items():\n        if not isinstance(k, string_types):\n            # JSON does not support using complex types such as tuples\n            # or user-defined objects with implementations of __hash__ as\n            # keys in a dictionary so we must keep the serialized\n            # representations of such values in a list and refer to indices\n            # in that list\n            serialized_key_repr = to_json(k)\n            if serialized_key_repr in serialized_keys_to_names:\n                k = serialized_keys_to_names[serialized_key_repr]\n            else:\n                k = index_to_serialized_key_name(len(serialized_key_list))\n                serialized_keys_to_names[serialized_key_repr] = k\n                serialized_key_list.append(serialized_key_repr)\n        result[k] = to_serializable_repr(v)\n    if len(serialized_key_list) > 0:\n        # only include this list of serialized keys if we had any non-string\n        # keys\n        result[SERIALIZED_DICTIONARY_KEYS_FIELD] = serialized_key_list\n    return result", "response": "Recursively convert values of dictionary x to serializable representations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreconstructing a dictionary by recursively reconstructing all keys and values and then converting them to a nested dictionary.", "response": "def from_serializable_dict(x):\n    \"\"\"\n    Reconstruct a dictionary by recursively reconstructing all its keys and\n    values.\n\n    This is the most hackish part since we rely on key names such as\n    __name__, __class__, __module__ as metadata about how to reconstruct\n    an object.\n\n    TODO: It would be cleaner to always wrap each object in a layer of type\n    metadata and then have an inner dictionary which represents the flattened\n    result of to_dict() for user-defined objects.\n    \"\"\"\n    if \"__name__\" in x:\n        return _lookup_value(x.pop(\"__module__\"), x.pop(\"__name__\"))\n\n    non_string_key_objects = [\n        from_json(serialized_key)\n        for serialized_key\n        in x.pop(SERIALIZED_DICTIONARY_KEYS_FIELD, [])\n    ]\n    converted_dict = type(x)()\n    for k, v in x.items():\n        serialized_key_index = parse_serialized_keys_index(k)\n        if serialized_key_index is not None:\n            k = non_string_key_objects[serialized_key_index]\n\n        converted_dict[k] = from_serializable_repr(v)\n    if \"__class__\" in converted_dict:\n        class_object = converted_dict.pop(\"__class__\")\n        if \"__value__\" in converted_dict:\n            return class_object(converted_dict[\"__value__\"])\n        elif hasattr(class_object, \"from_dict\"):\n            return class_object.from_dict(converted_dict)\n        else:\n            return class_object(**converted_dict)\n    return converted_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an object to a dictionary.", "response": "def to_dict(obj):\n    \"\"\"\n    If value wasn't isn't a primitive scalar or collection then it needs to\n    either implement to_dict (instances of Serializable) or has member\n    data matching each required arg of __init__.\n    \"\"\"\n    if isinstance(obj, dict):\n        return obj\n    elif hasattr(obj, \"to_dict\"):\n        return obj.to_dict()\n    try:\n        return simple_object_to_dict(obj)\n    except:\n        raise ValueError(\n            \"Cannot convert %s : %s to dictionary\" % (\n                obj, type(obj)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_serializable_repr(x):\n    t = type(x)\n    if isinstance(x, list):\n        return list_to_serializable_repr(x)\n    elif t in (set, tuple):\n        return {\n            \"__class__\": class_to_serializable_representation(t),\n            \"__value__\": list_to_serializable_repr(x)\n        }\n    elif isinstance(x, dict):\n        return dict_to_serializable_repr(x)\n    elif isinstance(x, (FunctionType, BuiltinFunctionType)):\n        return function_to_serializable_representation(x)\n    elif type(x) is type:\n        return class_to_serializable_representation(x)\n    else:\n        state_dictionary = to_serializable_repr(to_dict(x))\n        state_dictionary[\"__class__\"] = class_to_serializable_representation(\n            x.__class__)\n        return state_dictionary", "response": "Convert an instance of Serializable or a primitive collection containing\n            such instances into serializable types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_rules_bubble(self, srules=''):\n\n        if not isinstance(srules, str):\n            self.cry('convert_rules_bubble: cannot convert srules of type,' +\n                     'list of rules ==> [] :' + str(type(srules)),\n                     stuff=srules,\n                     verbosity=10)\n            return []\n\n        if not srules:\n            self.say('convert_rules_bubble: cannot convert empty srules',\n                     verbosity=10)\n            return []  # no rules\n\n        lines = srules.splitlines()\n        self.say('convert_rules_bubble:lines', stuff=lines, verbosity=10)\n\n        line_number = 0\n        rules = []\n        for r in lines:\n            line_number += 1\n            # todo: do we wan't this in a configuration, yes! add magic!\n            # in util.escaped it's defined as an escape\n            # but for rules it is best to define a magic value something like\n            # BMGC.TRANSFORMER.RULES_SEPERATOR  #seems better option for\n            # or\n            # BMGC.TRANSFORMER_RULES_SEPERATOR  #seems simpler\n            # BMGC should implement a sane default magic for undefined values.\n\n            r = r.strip()\n            if not r.endswith('>>>'):\n                continue\n            if not r.startswith('>>>'):\n                continue\n\n            parts = [p.strip() for p in r.split('>>>')]\n\n            rule = None\n            lp = len(parts)\n            if lp == 3:\n                rule = Rule(input=parts[1],\n                            src_nr=line_number)\n            if lp == 4:\n                rule = Rule(input=parts[1],\n                            fun=parts[2],\n                            src_nr=line_number)\n            if lp == 5:\n                rule = Rule(input=parts[1],\n                            fun=parts[2],\n                            output=parts[3],\n                            src_nr=line_number)\n            if lp == 6:\n                rule = Rule(input=parts[1],\n                            fun=parts[2],\n                            output=parts[3],\n                            depend=parts[4],\n                            src_nr=line_number)\n            if lp == 7:\n                rule = Rule(input=parts[1],\n                            fun=parts[2],\n                            output=parts[3],\n                            depend=parts[4],\n                            name=parts[5],\n                            src_nr=line_number)\n\n            if rule:\n                rules.append(rule)\n            else:\n                self.cry(\n                    'parts not 3..7 rule with parts[' + str(lp) +\n                    '] from line:[' + str(line_number) + ']\\n\\'' + r + '\\'',\n                    verbosity=10)\n\n        for r in rules:\n            r.set_parent(self)\n        self._rules = rules\n        self.say('convert_rules_bubble:res:rules', stuff=rules, verbosity=10)\n        return rules", "response": "converts a string containing the rules in bubble format to internal list of dictonary based rules"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncombines the rest and push states.", "response": "def _combine_rest_push(self):\n        \"\"\"Combining Rest and Push States\"\"\"\n        new = []\n        change = 0\n        # DEBUG\n        # logging.debug('Combining Rest and Push')\n        i = 0\n        examinetypes = self.quickresponse_types[3]\n        for state in examinetypes:\n            if state.type == 3:\n                for nextstate_id in state.trans.keys():\n                    found = 0\n                    # if nextstate_id != state.id:\n                    if nextstate_id in self.quickresponse:\n                        examines = self.quickresponse[nextstate_id]\n                        for examine in examines:\n                            if examine.id == nextstate_id and examine.type == 1:\n                                temp = PDAState()\n                                temp.type = 1\n                                temp.sym = examine.sym\n                                temp.id = state.id\n                                for nextnextstate_id in examine.trans:\n                                    # if nextnextstate_id != examine.id :\n\n                                    for x_char in state.trans[nextstate_id]:\n                                        for z_char in examine.trans[\n                                                nextnextstate_id]:\n                                            if nextnextstate_id not in temp.trans:\n                                                temp.trans[\n                                                    nextnextstate_id] = []\n                                            if x_char != 0 and z_char != 0:\n                                                temp.trans[\n                                                    nextnextstate_id].append(x_char + z_char)\n                                                # DEBUGprint 'transition is now\n                                                # '+x_char +' + '+ z_char\n                                            elif x_char != 0 and z_char == 0:\n                                                temp.trans[\n                                                    nextnextstate_id].append(x_char)\n                                                # DEBUGprint 'transition is now\n                                                # '+x_char\n                                            elif x_char == 0 and z_char != 0:\n                                                temp.trans[\n                                                    nextnextstate_id].append(z_char)\n                                                # DEBUGprint 'transition is now\n                                                # '+z_char\n                                            elif x_char == 0 and z_char == 0:\n                                                temp.trans[\n                                                    nextnextstate_id].append(0)\n                                                # DEBUGprint 'transition is now\n                                                # empty'\n                                            else:\n                                                pass\n                                found = 1\n                                new.append(temp)\n\n                    if found == 1:\n                        # print 'Lets combine one with id '+`state.id`+'(rest)\n                        # and one with id '+`nextstate_id`+'(push)'\n                        change = 1\n                        # del(state.trans[nextstate_id])\n            i = i + 1\n        if change == 0:\n            return []\n        else:\n            return new"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check(self, accepted):\n        # logging.debug('A check is now happening...')\n        # for key in self.statediag[1].trans:\n        #    logging.debug('transition to '+`key`+\" with \"+self.statediag[1].trans[key][0])\n        total = []\n        if 1 in self.quickresponse:\n            total = total + self.quickresponse[1]\n        if (1, 0) in self.quickresponse:\n            total = total + self.quickresponse[(1, 0)]\n        for key in total:\n            if (key.id == 1 or key.id == (1, 0)) and key.type == 3:\n                if accepted is None:\n                    if 2 in key.trans:\n                        # print 'Found'\n                        return key.trans[2]\n                else:\n                    for state in accepted:\n                        if (2, state) in key.trans:\n                            # print 'Found'\n                            return key.trans[(2, state)]\n        return -1", "response": "check for string existence"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef printer(self):\n        for key in self.statediag:\n            if key.trans is not None and len(key.trans) > 0:\n                print '****** ' + repr(key.id) + '(' + repr(key.type)\\\n                      + ' on sym ' + repr(key.sym) + ') ******'\n                print key.trans", "response": "Prints the current state of the tables"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(self, states, accepted):\n        self.statediag = []\n        for key in states:\n            self.statediag.append(states[key])\n        self.quickresponse = {}\n        self.quickresponse_types = {}\n        self.quickresponse_types[0] = []\n        self.quickresponse_types[1] = []\n        self.quickresponse_types[2] = []\n        self.quickresponse_types[3] = []\n        self.quickresponse_types[4] = []\n        for state in self.statediag:\n            if state.id not in self.quickresponse:\n                self.quickresponse[state.id] = [state]\n            else:\n                self.quickresponse[state.id].append(state)\n            self.quickresponse_types[state.type].append(state)\n        # self.printer()\n        # raw_input('next stepA?')\n        return self._stage(accepted, 0)", "response": "Initialize the indexing dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(filelocation, outpath, executable, args=None, switchArgs=None):\n    procArgs = ['java', '-jar', executable]\n    procArgs.extend(['-output_path', outpath])\n    if args is not None:\n        for arg in args:\n            procArgs.extend(['-'+arg[0], arg[1]])\n    if switchArgs is not None:\n        procArgs.extend(['-'+arg for arg in switchArgs])\n\n    procArgs.extend(aux.toList(filelocation))\n\n    ## run it ##\n    proc = subprocess.Popen(procArgs, stderr=subprocess.PIPE)\n\n    ## But do not wait till netstat finish, start displaying output immediately ##\n    while True:\n        out = proc.stderr.read(1)\n        if out == '' and proc.poll() != None:\n            break\n        if out != '':\n            sys.stdout.write(out)\n            sys.stdout.flush()", "response": "Executes the dinosaur tool on Windows operating systems."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_example():\n    cmd_args = sys.argv[1:]\n    parser = argparse.ArgumentParser(description='Confpy example generator.')\n    parser.add_argument(\n        '--module',\n        action='append',\n        help='A python module which should be imported.',\n    )\n    parser.add_argument(\n        '--file',\n        action='append',\n        help='A python file which should be evaled.',\n    )\n    parser.add_argument(\n        '--format',\n        default='JSON',\n        choices=('JSON', 'INI'),\n        help='The output format of the configuration file.',\n    )\n\n    args = parser.parse_args(cmd_args)\n\n    for module in args.module or ():\n\n        __import__(module)\n\n    for source_file in args.file or ():\n\n        cfg = pyfile.PythonFile(path=source_file).config\n\n    cfg = config.Configuration()\n\n    print(example.generate_example(cfg, ext=args.format))", "response": "This utility will load some number of Python modules which are assumed\n    and generate a configuration file example."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of bits in the array with the specified value.", "response": "def count(self, val=True):\n        \"\"\"Get the number of bits in the array with the specified value.\n\n        Args:\n            val: A boolean value to check against the array's value.\n\n        Returns:\n            An integer of the number of bits in the array equal to val.\n        \"\"\"\n        return sum((elem.count(val) for elem in self._iter_components()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare(self, *, primef, reqef):\n        #TODO remove bitarray copies!\n        if not primef.satisfies(reqef):\n            raise Exception(\"Compiler error. Requested effect can not be \"\n                            \"satisfied by primitive capabilities\")\n        assertPreferFalse = reqef == ZERO or primef == ARBITRARY or\\\n                            (reqef == NOCARE and primef == ZERO)\n        testBitarrayFalse = reqef==ZERO or\\\n                            (reqef==NOCARE and primef==ZERO)\n        testBitarrayTrue = reqef==ONE or (reqef==NOCARE and primef==ONE)\n        assert not (testBitarrayTrue and testBitarrayFalse)\n\n        #print(\"DATA\", self)\n        #print(\"ORIG\", [\"%s(%s:%s)\"%\n        #       (type(elem.value).__name__,\n        #        elem.value._val if isinstance(elem.value,\n        #                                      ConstantBitarray)\\\n        #        else \"_\", len(elem.value))\n        #       for elem in self._llhead.iternexttill(self._lltail)])\n\n        if self._offset or self._tailoffset:\n            if self._is_single_llnode:\n                if isinstance(self._llhead.value, (ConstantBitarray,\n                                             NoCareBitarray,\n                                             PreferFalseBitarray)):\n                    oldnode = self._llhead\n                    if self._offset == 0:\n                        oldnode.prev = None\n                    if self._tailoffset == 0:\n                        oldnode.next = None\n                    self._llhead = _DLLNode(\n                        oldnode.value[self._offset:\\\n                                      self._offset+self._tailbitsused])\n                    self._lltail = self._llhead\n                    self._offset = 0\n                    self._tailbitsused = self._taillen\n\n                elif isinstance(self._llhead.value, bitarray):\n                    if testBitarrayFalse or testBitarrayTrue:\n                        oldnode = self._llhead\n                        newval = oldnode.value[self._offset:\n                                               self._offset+self._tailbitsused]\n                        if testBitarrayFalse:\n                            if not newval.any():\n                                newval = ConstantBitarray(False, len(newval))\n                            else:\n                                raise Exception(\"bitarray in data contains a 1\")\n                        if testBitarrayTrue:\n                            if newval.all():\n                                newval = ConstantBitarray(True, len(newval))\n                            else:\n                                raise Exception(\"bitarray in data contains a 0\")\n\n                        self._llhead = _DLLNode(newval)\n                        self._lltail = self._llhead\n                        self._offset = 0\n                        self._tailbitsused = self._taillen\n\n            else: #IF HEAD IS NOT TAIL; OFFSET OR TAILOFFSET\n                if self._offset:\n                    if isinstance(self._llhead.value,\n                                  (ConstantBitarray, NoCareBitarray,\n                                   PreferFalseBitarray)):\n                        oldhead = self._llhead\n                        self._llhead = _DLLNode(\n                            oldhead.value[self._offset:])\n                        self._llhead.next = oldhead.next\n                        oldhead.next = None\n                        self._offset = 0\n                    elif isinstance(self._llhead.value, bitarray):\n                        oldhead = self._llhead\n                        newval = oldhead.value[self._offset:]\n                        if testBitarrayFalse:\n                            if not newval.any():\n                                newval = ConstantBitarray(False, len(newval))\n                            else:\n                                raise Exception(\"bitarray in data contains a 1\")\n                        if testBitarrayTrue:\n                            if newval.all():\n                                newval = ConstantBitarray(True, len(newval))\n                            else:\n                                raise Exception(\"bitarray in data contains a 0\")\n\n                        self._llhead = _DLLNode(newval)\n                        self._llhead.next = oldhead.next\n                        oldhead.next = None\n                        self._offset = 0\n\n                if self._tailoffset:#IF HEAD IS NOT TAIL AND TAILOFFSET\n                    if isinstance(self._lltail.value,\n                                  (ConstantBitarray, NoCareBitarray,\n                                   PreferFalseBitarray)):\n                        oldtail = self._lltail\n                        self._lltail = _DLLNode(\n                            oldtail.value[:self._tailbitsused])\n                        self._lltail.prev = oldtail.prev\n                        oldtail.prev = None\n                        self._tailbitsused = self._taillen\n                    elif isinstance(self._lltail.value, bitarray):\n                        oldtail = self._lltail\n                        newval = oldtail.value[:self._tailbitsused]\n                        if testBitarrayFalse:\n                            if not newval.any():\n                                newval = ConstantBitarray(False, len(newval))\n                            else:\n                                raise Exception(\"bitarray in data contains a 1\")\n                        if testBitarrayTrue:\n                            if newval.all():\n                                newval = ConstantBitarray(True, len(newval))\n                            else:\n                                raise Exception(\"bitarray in data contains a 0\")\n\n                        self._lltail = _DLLNode(newval)\n                        self._lltail.prev = oldtail.prev\n                        oldtail.prev = None\n                        self._tailbitsused = self._taillen\n\n\n        for elem in self._llhead.iternexttill(self._lltail):\n            if isinstance(elem.value, PreferFalseBitarray):\n                if assertPreferFalse:\n                    elem._value = ConstantBitarray(False, len(elem.value))\n                else:\n                    elem._value = NoCareBitarray(len(elem.value))\n            if isinstance(elem.value, bitarray):\n                if testBitarrayFalse:\n                    if not elem.value.any():\n                        elem.value = ConstantBitarray(False,\n                                                      len(elem.value))\n                    else:\n                        raise Exception(\"bitarray in data contains a 1\")\n                if testBitarrayTrue:\n                    if elem.value.all():\n                        elem.value = ConstantBitarray(True,\n                                                      len(elem.value))\n                    else:\n                        raise Exception(\"bitarray in data contains a 0\")\n\n\n        #print(\"TRAN\", [\"%s(%s:%s)\"%\n        #       (type(elem.value).__name__,\n        #        elem.value._val if isinstance(elem.value,\n        #                                      ConstantBitarray)\\\n        #        else \"_\", len(elem.value))\n        #       for elem in self._llhead.iternexttill(self._lltail)])\n\n\n\n        if not self._is_single_llnode and\\\n           (self._lltail.next is not self._llhead or\\\n            (self._offset == 0 and self._tailbitsused == self._taillen)\n            ):\n            self._do_merge(stoponfail=False)\n\n        #print(\"\\033[1mPOST\", \"+ \".join([\"%s%s(%s:%s)\\033[0m\"%\n        #       ('\\033[91m' if isinstance(elem.value, bitarray) else\n        #        ('\\033[94m' if isinstance(elem.value,\n        #                            (NoCareBitarray, PreferFalseBitarray))\n        #         else '\\033[92m'),type(elem.value).__name__,\n        #        elem.value._val if isinstance(elem.value,\n        #                                      ConstantBitarray)\\\n        #        else (elem.value.to01() if isinstance(elem.value,\n        #                                              bitarray)\n        #              else \"_\"), len(elem.value))\n        #       for elem in self._llhead.iternexttill(self._lltail)]))\n        if self._is_single_llnode and self._offset == 0 and\\\n           self._tailbitsused == self._taillen:\n            if isinstance(self._llhead.value, (NoCareBitarray,\n                                               PreferFalseBitarray)):\n                return ConstantBitarray(False, len(self._llhead.value))\n            return self._llhead.value\n        return self", "response": "This method is used to prepare the composite bitarray for processing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _api_group_for_type(cls):\n    _groups = {\n        (u\"v1beta1\", u\"Deployment\"): u\"extensions\",\n        (u\"v1beta1\", u\"DeploymentList\"): u\"extensions\",\n        (u\"v1beta1\", u\"ReplicaSet\"): u\"extensions\",\n        (u\"v1beta1\", u\"ReplicaSetList\"): u\"extensions\",\n    }\n    key = (\n        cls.apiVersion,\n        cls.__name__.rsplit(u\".\")[-1],\n    )\n    group = _groups.get(key, None)\n    return group", "response": "Determines which Kubernetes API group a particular PClass is likely to be to\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef response(request, status, obj):\n    request.setResponseCode(status)\n    request.responseHeaders.setRawHeaders(\n        u\"content-type\", [u\"application/json\"],\n    )\n    body = dumps_bytes(obj)\n    return body", "response": "Generate a response.\n\n    :param IRequest request: The request being responsed to.\n    :param int status: The response status code to set.\n    :param obj: Something JSON-dumpable to write into the response body.\n\n    :return bytes: The response body to write out.  eg, return this from a\n        *render_* method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, collection_name, obj):\n        obj = self.agency.before_create(self, obj)\n        new = self.agency.after_create(self, obj)\n        updated = self.transform(\n            [collection_name],\n            lambda c: c.add(new),\n        )\n        return updated", "response": "Create a new object in the named collection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace(self, collection_name, old, new):\n        self.agency.before_replace(self, old, new)\n        updated = self.transform(\n            [collection_name],\n            lambda c: c.replace(old, new),\n        )\n        return updated", "response": "Replace an existing object with a new version of it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, collection_name, obj):\n        updated = self.transform(\n            [collection_name],\n            lambda c: obj.delete_from(c),\n        )\n        return updated", "response": "Delete an existing object from the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of connections that satisfy the filter by environment product and unique_name_list", "response": "def get_list_connections(self, environment, product, unique_name_list=None, is_except=False):\n        \"\"\"\n        Gets list of connections that satisfy the filter by environment, product and (optionally) unique DB names\n        :param environment: Environment name\n        :param product: Product name\n        :param unique_name_list: list of unique db aliases\n        :param is_except: take the connections with aliases provided or, the other wat around, take all the rest\n        :return: list of dictionaries with connections\n        \"\"\"\n        return_list = []\n        for item in self.connection_sets:\n            if unique_name_list:\n                if item['unique_name']:\n                    if is_except:\n                        if item['environment'] == environment and item['product'] == product and \\\n                                (item['unique_name'] not in unique_name_list):\n                            return_list.append(item)\n                    elif not is_except:\n                        if item['environment'] == environment and item['product'] == product and \\\n                                (item['unique_name'] in unique_name_list):\n                            return_list.append(item)\n            else:\n                if item['environment'] == environment and item['product'] == product:\n                    return_list.append(item)\n        return return_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_address():\n    global STATSD_ADDR\n    connection_string = os.getenv('STATSD')\n    if connection_string:\n        url = urlparse.urlparse(connection_string)\n        STATSD_ADDR = (url.hostname, url.port)\n    else:\n        STATSD_ADDR = (os.getenv('STATSD_HOST', 'localhost'),\n                       int(os.getenv('STATSD_PORT', 8125)))", "response": "Set the address of the current node from the environment variable STATSD_ADDR"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _send(key, value, metric_type):\n    if STATSD_PREFIX:\n        key = '.'.join([STATSD_PREFIX, key])\n    try:\n        STATSD_SOCKET.sendto('{0}:{1}|{2}'.format(key,\n                                                  value,\n                                                  metric_type).encode(),\n                             STATSD_ADDR)\n    except socket.error:\n        LOGGER.exception(SOCKET_ERROR)", "response": "Send the specified value to the statsd daemon via UDP without a direct socket connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlets users select language", "response": "def _get_lang(self, *args, **kwargs):\n        \"\"\" Let users select language\n        \"\"\"\n        if \"lang\" in kwargs:\n            if kwargs[\"lang\"] in self._available_languages:\n                self.lang = kwargs[\"lang\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notify(self, msg, color='green', notify='true', message_format='text'):\n        self.message_dict = {\n            'message': msg,\n            'color': color,\n            'notify': notify,\n            'message_format': message_format,\n        }\n        if not self.debug:\n            return requests.post(\n                self.notification_url,\n                json.dumps(self.message_dict),\n                headers=self.headers\n            )\n        else:\n            print('HipChat message: <{}>'.format(msg))\n            return []", "response": "Send a message to the HipChat room"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning tests using trial", "response": "def trial(path=TESTS_PATH, coverage=False):\n    \"\"\"Run tests using trial\n    \"\"\"\n    args = ['trial']\n    if coverage:\n        args.append('--coverage')\n    args.append(path)\n    print args\n    local(' '.join(args))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_result_value(self, value, dialect):\n        if value is not None:\n            cmd = \"value = {}\".format(value)\n            exec(cmd)\n        return value", "response": "When SQLAlchemy gets the string representation from a ReprObjType\n        column it converts it to the python equivalent via exec."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_regex(separator):\n    return re.compile(r'(?:' + re.escape(separator) + r')?((?:[^' +\n                      re.escape(separator) + r'\\\\]|\\\\.)+)')", "response": "Utility function to create regexp for matching escaped separators\n    in strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomments stripper for JSON.", "response": "def strip_comments(text):\n    \"\"\"Comment stripper for JSON.\n\n    \"\"\"\n    regex = r'\\s*(#|\\/{2}).*$'\n    regex_inline = r'(:?(?:\\s)*([A-Za-z\\d\\.{}]*)|((?<=\\\").*\\\"),?)(?:\\s)*(((#|(\\/{2})).*)|)$'  # noqa\n    lines = text.split('\\n')\n\n    for index, line in enumerate(lines):\n        if re.search(regex, line):\n            if re.search(r'^' + regex, line, re.IGNORECASE):\n                lines[index] = \"\"\n            elif re.search(regex_inline, line):\n                lines[index] = re.sub(regex_inline, r'\\1', line)\n\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters an action to be used in the list of permitted actions.", "response": "def register(action):\n        \"\"\"Action registration is used to support generating lists of\n        permitted actions from a permission set and an object pattern.\n        Only registered actions will be returned by such queries.\n\n        \"\"\"\n        if isinstance(action, str):\n            Action.register(Action(action))\n        elif isinstance(action, Action):\n            Action.registered.add(action)\n        else:\n            for a in action:\n                Action.register(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if a given action on a given object is allowed.", "response": "def allow(self, act, obj=None):\n        \"\"\"Determine where a given action on a given object is allowed.\n\n        \"\"\"\n        objc = obj.components if obj is not None else []\n        try:\n            return self.tree[act.components + objc] == 'allow'\n        except KeyError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining permitted actions for a given object pattern.", "response": "def permitted_actions(self, obj=None):\n        \"\"\"Determine permitted actions for a given object pattern.\n\n        \"\"\"\n        return [a for a in Action.registered\n                if self.allow(a, obj(str(a)) if obj is not None else None)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubscribing to a new item in the internal list of liveupdates.", "response": "def subscribe(ws):\n    \"\"\"WebSocket endpoint, used for liveupdates\"\"\"\n    while ws is not None:\n        gevent.sleep(0.1)\n        try:\n            message = ws.receive()  # expect function name to subscribe to\n            if message:\n                stream.register(ws, message)\n        except WebSocketError:\n            ws = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the current scope is not breaking a loop.", "response": "def could_scope_out(self):\n        \"\"\"\n        could bubble up from current scope\n\n        :return:\n        \"\"\"\n        return not self.waiting_for or \\\n               isinstance(self.waiting_for, callable.EndOfStory) or \\\n               self.is_breaking_a_loop()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_child_story(self):\n        logger.debug('# get_child_story')\n        \"\"\"\n        try child story that match message and get scope of it\n        :return:\n        \"\"\"\n        story_loop = self.compiled_story()\n        if hasattr(story_loop, 'children_matcher') and not self.matched:\n            return self.get_story_scope_child(story_loop)\n\n        story_part = self.get_current_story_part()\n\n        if not hasattr(story_part, 'get_child_by_validation_result'):\n            logger.debug('# does not have get_child_by_validation_result')\n            return None\n\n        if isinstance(self.waiting_for, forking.SwitchOnValue):\n            logger.debug('# switch on value')\n            return story_part.get_child_by_validation_result(self.waiting_for.value)\n\n        # for some base classes we could try validate result direct\n        child_story = story_part.get_child_by_validation_result(self.waiting_for)\n        if child_story:\n            logger.debug('# child_story')\n            logger.debug(child_story)\n            return child_story\n\n        stack_tail = self.stack_tail()\n        if stack_tail['data'] is not None and not self.matched:\n            validator = matchers.deserialize(stack_tail['data'])\n            logger.debug('# validator')\n            logger.debug(validator)\n            logger.debug('# self.message')\n            logger.debug(self.message)\n            validation_result = validator.validate(self.message)\n            logger.debug('# validation_result')\n            logger.debug(validation_result)\n            res = story_part.get_child_by_validation_result(validation_result)\n            logger.debug('# res')\n            logger.debug(res)\n            # or we validate message\n            # but can't find right child story\n            # maybe we should use independent validators for each story here\n            if res is None:\n                return self.get_story_scope_child(story_part)\n            else:\n                return res\n\n        return None", "response": "try child story that match message and get scope of it"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_waiting_for_input(self):\n        return self.waiting_for and \\\n               not isinstance(self.waiting_for, forking.SwitchOnValue) and \\\n               not is_base_type(self.waiting_for)", "response": "Returns True if the current entry is waiting for input."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the alias for the item.", "response": "def alias(self):\n        \"\"\" If the _alias cache is None, just build the alias from the item\n        name.\n        \"\"\"\n        if self._alias is None:\n            if self.name in self.aliases_fix:\n                self._alias = self.aliases_fix[self.name]\n            else:\n                self._alias = self.name.lower()\\\n                                  .replace(' ', '-')\\\n                                  .replace('(', '')\\\n                                  .replace(')', '')\n        return self._alias"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the config file and return the global config dict", "response": "def load_configs(self, conf_file):\n        \"\"\"\n        Assumes that the config file does not have any sections, so throw it all in global\n        \"\"\"\n        with open(conf_file) as stream:\n            lines = itertools.chain((\"[global]\",), stream)\n            self._config.read_file(lines)\n        return self._config['global']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove quotes from a list of configuration items.", "response": "def remove_quotes(self, configs):\n        \"\"\"\n        Because some values are wraped in single quotes\n        \"\"\"\n        for key in configs:\n            value = configs[key]\n            if value[0] == \"'\" and value[-1] == \"'\":\n                configs[key] = value[1:-1]\n        return configs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsorting a list of dictionaries by multiple keys.", "response": "def multikey_sort(items, columns):\n    \"\"\"Source: https://stackoverflow.com/questions/1143671/python-sorting-list-of-dictionaries-by-multiple-keys\n    \"\"\"\n    comparers = [\n        ((itemgetter(col[1:].strip()), -1) if col.startswith('-') else (itemgetter(col.strip()), 1))\n        for col in columns\n    ]\n\n    def cmp(a, b):\n        return (a > b) - (a < b)\n\n    def comparer(left, right):\n        comparer_iter = (\n            cmp(fn(left), fn(right)) * mult\n            for fn, mult in comparers\n        )\n        return next((result for result in comparer_iter if result), 0)\n    return sorted(items, key=cmp_to_key(comparer))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncatching and replace invalid path chars [ replace with ]", "response": "def sanitize(string):\n    \"\"\"\n    Catch and replace invalid path chars\n    [replace, with]\n    \"\"\"\n    replace_chars = [\n        ['\\\\', '-'], [':', '-'], ['/', '-'],\n        ['?', ''], ['<', ''], ['>', ''],\n        ['`', '`'], ['|', '-'], ['*', '`'],\n        ['\"', '\\''], ['.', ''], ['&', 'and']\n    ]\n    for ch in replace_chars:\n        string = string.replace(ch[0], ch[1])\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunks_of(max_chunk_size, list_to_chunk):\n    for i in range(0, len(list_to_chunk), max_chunk_size):\n        yield list_to_chunk[i:i + max_chunk_size]", "response": "Yields the list with a max size of max_chunk_size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_into(max_num_chunks, list_to_chunk):\n    max_chunk_size = math.ceil(len(list_to_chunk) / max_num_chunks)\n    return chunks_of(max_chunk_size, list_to_chunk)", "response": "Yields the list with a max total size of max_num_chunks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef norm_path(path):\n    # path = os.path.normcase(path)\n    path = os.path.expanduser(path)\n    path = os.path.expandvars(path)\n    path = os.path.normpath(path)\n    return path", "response": "Normalizes path for os with vars expanded out\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a hashed directory structure using the hashed filename", "response": "def create_hashed_path(base_path, name, depth=2):\n    \"\"\"\n    Create a directory structure using the hashed filename\n    :return: string of the path to save to not including filename/ext\n    \"\"\"\n    if depth > 16:\n        logger.warning(\"depth cannot be greater then 16, setting to 16\")\n        depth = 16\n\n    name_hash = hashlib.md5(str(name).encode('utf-8')).hexdigest()\n    if base_path.endswith(os.path.sep):\n        save_path = base_path\n    else:\n        save_path = base_path + os.path.sep\n    for i in range(1, depth + 1):\n        end = i * 2\n        start = end - 2\n        save_path += name_hash[start:end] + os.path.sep\n\n    return {'path': save_path,\n            'hash': name_hash,\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_path(path, is_dir=False):\n    path = norm_path(path)\n    path_check = path\n    if not is_dir:\n        path_check = os.path.dirname(path)\n\n    does_path_exists = os.path.exists(path_check)\n\n    if does_path_exists:\n        return path\n\n    try:\n        os.makedirs(path_check)\n    except OSError:\n        pass\n\n    return path", "response": "Create the path if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsourcing https://github.com/tomasbasham/ratelimit/tree/0ca5a616fa6d184fa180b9ad0b6fd0cf54c46936 Need to make a few changes that included having num_calls be a float Prevent a method from being called if it was previously called before a time widows has elapsed. Keyword Arguments: num_calls (float): Maximum method invocations within a period. Must be greater than 0. every (float): A dampening factor (in seconds). Can be any number greater than 0. Return: function: Decorated function that will forward method invocations if the time window has elapsed.", "response": "def rate_limited(num_calls=1, every=1.0):\n    \"\"\"\n    Source: https://github.com/tomasbasham/ratelimit/tree/0ca5a616fa6d184fa180b9ad0b6fd0cf54c46936\n    Need to make a few changes that included having num_calls be a float\n\n    Prevent a method from being called\n    if it was previously called before\n    a time widows has elapsed.\n\n    Keyword Arguments:\n        num_calls (float): Maximum method invocations within a period. Must be greater than 0.\n        every (float): A dampening factor (in seconds). Can be any number greater than 0.\n\n    Return:\n        function: Decorated function that will forward method invocations if the time window has elapsed.\n\n    \"\"\"\n    frequency = abs(every) / float(num_calls)\n    def decorator(func):\n        \"\"\"\n        Extend the behaviour of the following\n        function, forwarding method invocations\n        if the time window hes elapsed.\n        Arguments:\n            func (function): The function to decorate\n\n        Returns:\n            function: Decorated function\n\n        \"\"\"\n\n        # To get around issues with function local scope\n        # and reassigning variables, we wrap the time\n        # within a list. When updating the value we're\n        # not reassigning `last_called`, which would not\n        # work, but instead reassigning the value at a\n        # particular index.\n        last_called = [0.0]\n\n        # Add thread safety\n        lock = threading.RLock()\n\n        def wrapper(*args, **kargs):\n            \"\"\"Decorator wrapper function\"\"\"\n            with lock:\n                elapsed = time.time() - last_called[0]\n                left_to_wait = frequency - elapsed\n                if left_to_wait > 0:\n                    time.sleep(left_to_wait)\n                last_called[0] = time.time()\n            return func(*args, **kargs)\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rate_limited_old(max_per_second):\n    lock = threading.Lock()\n    min_interval = 1.0 / max_per_second\n\n    def decorate(func):\n        last_time_called = time.perf_counter()\n\n        @wraps(func)\n        def rate_limited_function(*args, **kwargs):\n            lock.acquire()\n            nonlocal last_time_called\n            try:\n                elapsed = time.perf_counter() - last_time_called\n                left_to_wait = min_interval - elapsed\n                if left_to_wait > 0:\n                    time.sleep(left_to_wait)\n\n                return func(*args, **kwargs)\n            finally:\n                last_time_called = time.perf_counter()\n                lock.release()\n\n        return rate_limited_function\n\n    return decorate", "response": "Decorator to rate limit the number of time until the function is called."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef timeit(stat_tracker_func, name):\n    def _timeit(func):\n        def wrapper(*args, **kw):\n            start_time = time.time()\n            result = func(*args, **kw)\n            stop_time = time.time()\n            stat_tracker_func(name, stop_time - start_time)\n\n            return result\n        return wrapper\n\n    return _timeit", "response": "Decorator to time a function that will send out the data to the stat_tracker_func and the name of the stat_tracker_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a proxy url and break it up to its parts", "response": "def get_proxy_parts(proxy):\n    \"\"\"\n    Take a proxy url and break it up to its parts\n    \"\"\"\n    proxy_parts = {'schema': None,\n                   'user': None,\n                   'password': None,\n                   'host': None,\n                   'port': None,\n                   }\n    # Find parts\n    results = re.match(proxy_parts_pattern, proxy)\n    if results:\n        matched = results.groupdict()\n        for key in proxy_parts:\n            proxy_parts[key] = matched.get(key)\n\n    else:\n        logger.error(\"Invalid proxy format `{proxy}`\".format(proxy=proxy))\n\n    if proxy_parts['port'] is None:\n        proxy_parts['port'] = '80'\n\n    return proxy_parts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_html_tag(input_str='', tag=None):\n    result = input_str\n    if tag is not None:\n        pattern = re.compile('<{tag}[\\s\\S]+?/{tag}>'.format(tag=tag))\n        result = re.sub(pattern, '', str(input_str))\n\n    return result", "response": "Removes the html tag from a string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an ordered dictionary of handle and report points.", "response": "def asodict(self, handlepoints=True, reportpoints=True):\n        \"\"\"Returns an ordered dictionary of handle/report points\"\"\"\n        out = odict()\n        if handlepoints:\n            for hp in self.handlepoints:\n                out[hp.hpoint] = hp.trace\n        if reportpoints:\n            for rp in self.reportpoints:\n                if not (rp.rpoint in out):\n                    out[rp.rpoint] = odict()\n                out[rp.rpoint][self.attribute] = {'value' : rp.value, 'extended': rp.extended}\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef asodict(self, freports=True, handlepoints=True, reportpoints=True):\n        out = odict()\n        if freports:\n            for fr in self.freports:\n                out[fr.num] = {'tstamp' : fr.tstamp, \n                               'report' : fr.asodict(handlepoints, reportpoints)}           \n        if handlepoints:\n            for hp in self.handlepoints:\n                out[hp.hpoint] = hp.trace\n        if reportpoints:\n            for rp in self.reportpoints:\n                if not (rp.rpoint in out):\n                    out[rp.rpoint] = odict()\n                out[rp.rpoint][self.attribute] = {'value' : rp.value, 'extended': rp.extended}\n        return out", "response": "Returns an ordered dictionary of feed handle and report points"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ip_between(ip, start, finish):\n\n    if is_IPv4Address(ip) and is_IPv4Address(start) and is_IPv4Address(finish):\n        return IPAddress(ip) in IPRange(start, finish)\n    else:\n        return False", "response": "Checks to see if IP is between start and finish"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking to see if an IP address is used for local communications within a private network as specified by RFC 1918", "response": "def is_rfc1918(ip):\n    \"\"\"Checks to see if an IP address is used for local communications within\n    a private network as specified by RFC 1918\n    \"\"\"\n    if ip_between(ip, \"10.0.0.0\", \"10.255.255.255\"):\n        return True\n    elif ip_between(ip, \"172.16.0.0\", \"172.31.255.255\"):\n        return True\n    elif ip_between(ip, \"192.168.0.0\", \"192.168.255.255\"):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking to see if an IP address is reserved for special purposes.", "response": "def is_reserved(ip):\n    \"\"\"Checks to see if an IP address is reserved for special purposes. This includes\n    all of the RFC 1918 addresses as well as other blocks that are reserved by\n    IETF, and IANA for various reasons.\n\n    https://en.wikipedia.org/wiki/Reserved_IP_addresses\n    \"\"\"\n    if ip_between(ip, \"0.0.0.0\", \"0.255.255.255\"):\n        return True\n    elif ip_between(ip, \"10.0.0.0\", \"10.255.255.255\"):\n        return True\n    elif ip_between(ip, \"100.64.0.0\", \"100.127.255.255\"):\n        return True\n    elif ip_between(ip, \"127.0.0.0\", \"127.255.255.255\"):\n        return True\n    elif ip_between(ip, \"169.254.0.0\", \"169.254.255.255\"):\n        return True\n    elif ip_between(ip, \"172.16.0.0\", \"172.31.255.255\"):\n        return True\n    elif ip_between(ip, \"192.0.0.0\", \"192.0.0.255\"):\n        return True\n    elif ip_between(ip, \"192.0.2.0\", \"192.0.2.255\"):\n        return True\n    elif ip_between(ip, \"192.88.99.0\", \"192.88.99.255\"):\n        return True\n    elif ip_between(ip, \"192.168.0.0\", \"192.168.255.255\"):\n        return True\n    elif ip_between(ip, \"198.18.0.0\", \"198.19.255.255\"):\n        return True\n    elif ip_between(ip, \"198.51.100.0\", \"198.51.100.255\"):\n        return True\n    elif ip_between(ip, \"203.0.113.0\", \"203.0.113.255\"):\n        return True\n    elif ip_between(ip, \"224.0.0.0\", \"255.255.255.255\"):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns true for valid hashes false for invalid.", "response": "def is_hash(fhash):\n    \"\"\"Returns true for valid hashes, false for invalid.\"\"\"\n\n    # Intentionally doing if/else statement for ease of testing and reading\n    if re.match(re_md5, fhash):\n        return True\n    elif re.match(re_sha1, fhash):\n        return True\n    elif re.match(re_sha256, fhash):\n        return True\n    elif re.match(re_sha512, fhash):\n        return True\n    elif re.match(re_ssdeep, fhash):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates GeoJSON for given IP address", "response": "def ip_to_geojson(ipaddress, name=\"Point\"):\n    \"\"\"Generate GeoJSON for given IP address\"\"\"\n\n    geo = ip_to_geo(ipaddress)\n\n    point = {\n        \"type\": \"FeatureCollection\",\n        \"features\": [\n            {\n                \"type\": \"Feature\",\n                \"properties\": {\n                    \"name\": name\n                },\n                \"geometry\": {\n                    \"type\": \"Point\",\n                    \"coordinates\": [\n                        geo[\"longitude\"],\n                        geo[\"latitude\"]\n                    ]\n                }\n            }\n        ]\n    }\n\n    return point"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates GeoJSON for given IP addresses", "response": "def ips_to_geojson(ipaddresses):\n    \"\"\"Generate GeoJSON for given IP address\"\"\"\n\n    features = []\n\n    for ipaddress in ipaddresses:\n        geo = gi.record_by_addr(ipaddress)\n\n        features.append({\n            \"type\": \"Feature\",\n            \"properties\": {\n                \"name\": ipaddress\n            },\n            \"geometry\": {\n                \"type\": \"Point\",\n                \"coordinates\": [\n                    geo[\"longitude\"],\n                    geo[\"latitude\"]\n                ]\n            }\n        })\n\n    points = {\n        \"type\": \"FeatureCollection\",\n        \"features\": features\n    }\n\n    return points"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of the dns names that point to a given ipaddress using StatDNS API", "response": "def reverse_dns_sna(ipaddress):\n    \"\"\"Returns a list of the dns names that point to a given ipaddress using StatDNS API\"\"\"\n\n    r = requests.get(\"http://api.statdns.com/x/%s\" % ipaddress)\n\n    if r.status_code == 200:\n        names = []\n\n        for item in r.json()['answer']:\n            name = str(item['rdata']).strip(\".\")\n            names.append(name)\n\n        return names\n    elif r.json()['code'] == 503:\n        # NXDOMAIN - no PTR record\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vt_ip_check(ip, vt_api):\n    if not is_IPv4Address(ip):\n        return None\n\n    url = 'https://www.virustotal.com/vtapi/v2/ip-address/report'\n    parameters = {'ip': ip, 'apikey': vt_api}\n    response = requests.get(url, params=parameters)\n    try:\n        return response.json()\n    except ValueError:\n        return None", "response": "Checks VirusTotal for occurrences of an IP address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck VirusTotal for occurrences of a domain name", "response": "def vt_name_check(domain, vt_api):\n    \"\"\"Checks VirusTotal for occurrences of a domain name\"\"\"\n    if not is_fqdn(domain):\n        return None\n\n    url = 'https://www.virustotal.com/vtapi/v2/domain/report'\n    parameters = {'domain': domain, 'apikey': vt_api}\n    response = requests.get(url, params=parameters)\n    try:\n        return response.json()\n    except ValueError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vt_hash_check(fhash, vt_api):\n    if not is_hash(fhash):\n        return None\n\n    url = 'https://www.virustotal.com/vtapi/v2/file/report'\n    parameters = {'resource': fhash, 'apikey': vt_api}\n    response = requests.get(url, params=parameters)\n    try:\n        return response.json()\n    except ValueError:\n        return None", "response": "Checks VirusTotal for occurrences of a file hash"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ipinfo_ip_check(ip):\n    if not is_IPv4Address(ip):\n        return None\n\n    response = requests.get('http://ipinfo.io/%s/json' % ip)\n    return response.json()", "response": "Checks ipinfo. io for basic WHOIS - type data on an IP address"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck IPVoid. com for info on an IP address", "response": "def ipvoid_check(ip):\n    \"\"\"Checks IPVoid.com for info on an IP address\"\"\"\n    if not is_IPv4Address(ip):\n        return None\n\n    return_dict = {}\n    headers = {'User-Agent': useragent}\n    url = 'http://ipvoid.com/scan/%s/' % ip\n    response = requests.get(url, headers=headers)\n    data = BeautifulSoup(response.text)\n    if data.findAll('span', attrs={'class': 'label label-success'}):\n        return None\n    elif data.findAll('span', attrs={'class': 'label label-danger'}):\n        for each in data.findAll('img', alt='Alert'):\n            detect_site = each.parent.parent.td.text.lstrip()\n            detect_url = each.parent.a['href']\n            return_dict[detect_site] = detect_url\n\n    return return_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck URLVoid. com for info on a domain", "response": "def urlvoid_check(name, api_key):\n    \"\"\"Checks URLVoid.com for info on a domain\"\"\"\n    if not is_fqdn(name):\n        return None\n\n    url = 'http://api.urlvoid.com/api1000/{key}/host/{name}'.format(key=api_key, name=name)\n    response = requests.get(url)\n    tree = ET.fromstring(response.text)\n    if tree.find('./detections/engines'):\n        return [e.text for e in tree.find('./detections/engines')]\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef urlvoid_ip_check(ip):\n    if not is_IPv4Address(ip):\n        return None\n\n    return_dict = {}\n    headers = {'User-Agent': useragent}\n    url = 'http://urlvoid.com/ip/%s/' % ip\n    response = requests.get(url, headers=headers)\n    data = BeautifulSoup(response.text)\n    h1 = data.findAll('h1')[0].text\n    if h1 == 'Report not found':\n        return None\n    elif re.match('^IP', h1):\n        return_dict['bad_names'] = []\n        return_dict['other_names'] = []\n        for each in data.findAll('img', alt='Alert'):\n            return_dict['bad_names'].append(each.parent.text.strip())\n        for each in data.findAll('img', alt='Valid'):\n            return_dict['other_names'].append(each.parent.text.strip())\n\n    return return_dict", "response": "Checks URLVoid. com for info on an IP address"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dshield_ip_check(ip):\n    if not is_IPv4Address(ip):\n        return None\n\n    headers = {'User-Agent': useragent}\n    url = 'https://isc.sans.edu/api/ip/'\n    response = requests.get('{0}{1}?json'.format(url, ip), headers=headers)\n    return response.json()", "response": "Checks dshield for info on an IP address"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx,\n        amount,\n        index,\n        stage):\n    \"\"\"Push data to  Target Service Client\"\"\"\n\n    if not ctx.bubble:\n        ctx.say_yellow('There is no bubble present, will not push')\n        raise click.Abort()\n\n    TGT = None\n    transformed = True\n    STAGE = None\n\n    if stage in STAGES and  stage in ctx.cfg.CFG:\n        STAGE = ctx.cfg.CFG[stage]\n    if not STAGE:\n        ctx.say_red('There is no STAGE in CFG:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                        ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n\n    if 'TARGET' in STAGE:\n        TGT = STAGE.TARGET\n    if 'TRANSFORM' in STAGE:\n        transformed = True\n    else:\n        transformed = False\n\n    if not transformed:\n        ctx.say_yellow(\"\"\"There is no transform defined in the configuration, will not transform,\nusing the results of step 'pulled' instead of 'push'\n\"\"\")\n\n    if not TGT:\n        ctx.say_red('There is no TARGET in: ' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                       ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n    tgt_client = get_client(ctx.gbc, TGT.CLIENT, ctx.home)\n\n    try:\n        tclient = tgt_client.BubbleClient(cfg=TGT)\n        tclient.set_parent(ctx.gbc)\n        tclient.set_verbose(ctx.get_verbose())\n    except Exception as e:\n        ctx.say_red('cannot create bubble client:' + TGT.CLIENT)\n        ctx.say_red(str(e))\n        raise click.Abort('can not push')\n\n    step_to_load = 'push'\n    if not transformed:\n        step_to_load = 'pulled'\n    data_gen = bubble_lod_load(ctx, step_to_load, stage)\n\n    full_data = False\n    if amount == -1 and index == -1:\n        full_data = True\n    to_push = get_gen_slice(ctx.gbc, data_gen, amount, index)\n\n    error_count = Counter()\n    total_count = Counter()\n\n    pushres = do_yielding_push(ctx=ctx,\n                               to_push=to_push,\n                               tclient=tclient,\n                               total_counter=total_count,\n                               error_counter=error_count)\n    pfr = bubble_lod_dump(ctx=ctx,\n                          step='pushed',\n                          stage=stage,\n                          full_data=full_data,\n                          reset=True,\n                          data_gen=pushres)\n\n    ctx.say('pushed [%d] objects' % pfr['total'])\n\n    stats = {}\n    stats['pushed_stat_error_count'] = error_count.get_total()\n    stats['pushed_stat_total_count'] = total_count.get_total()\n    update_stats(ctx, stage, stats)\n\n    return True", "response": "Push data to target service client"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the version for this plugin satisfies the given expression.", "response": "def validate(version, comparison):\n    \"\"\"\n    Returns whether or not the version for this plugin satisfies the\n    inputted expression.  The expression will follow the dependency\n    declaration rules associated with setuptools in Python.  More\n    information can be found at\n    \n    [https://pythonhosted.org/setuptools/setuptools.html#declaring-dependencies]\n    \n    :param      version     | <str>\n                expression  | <str>\n    \n    :return     <bool>\n    \"\"\"\n    # match any\n    if not comparison:\n        return True\n    \n    # loop through all available\n    opts = comparison.split(',')\n    expr = re.compile('(==|!=|<=|>=|<|>)(.*)')\n    for opt in opts:\n        try:\n            test, value = expr.match(opt.strip()).groups()\n        except StandardError:\n            raise errors.InvalidVersionDefinition(opt)\n        \n        value = value.strip()\n        \n        # test for an exact match\n        if test == '==':\n            if value == version:\n                return True\n        \n        # test for negative exact matches\n        elif test == '!=':\n            if value == version:\n                return False\n        \n        # test for range conditions\n        elif test == '<':\n            if vercmp(version, value) != -1:\n                return False\n        elif test == '<=':\n            if vercmp(version, value) not in (-1, 0):\n                return False\n        elif test == '>':\n            if vercmp(value, version) != -1:\n                return False\n        elif test == '>=':\n            if vercmp(value, version) not in (-1, 0):\n                return False\n    \n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _full_kind(details):\n    kind = details[u\"kind\"]\n    if details.get(u\"group\") is not None:\n        kind += u\".\" + details[u\"group\"]\n    return kind", "response": "Determine the full kind of a failure based on the details."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef RemoveEmptyDirectoryTree(path, silent = False, recursion = 0):\n  if not silent and recursion is 0:\n    goodlogging.Log.Info(\"UTIL\", \"Starting removal of empty directory tree at: {0}\".format(path))\n  try:\n    os.rmdir(path)\n  except OSError:\n    if not silent:\n      goodlogging.Log.Info(\"UTIL\", \"Removal of empty directory tree terminated at: {0}\".format(path))\n    return\n  else:\n    if not silent:\n      goodlogging.Log.Info(\"UTIL\", \"Directory deleted: {0}\".format(path))\n    RemoveEmptyDirectoryTree(os.path.dirname(path), silent, recursion + 1)", "response": "Removes the empty directory tree at the given path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if path exists.", "response": "def CheckPathExists(path):\n  \"\"\"\n  Check if path exists, if it does add number to path (incrementing until\n  a unique path is found).\n\n  Parameters\n  ----------\n    path : string\n      Path of directory to try.\n\n  Returns\n  ----------\n    string\n      Path of unique directory.\n  \"\"\"\n  i = 0\n  root, ext = os.path.splitext(path)\n  while os.path.exists(path):\n    i = i + 1\n    goodlogging.Log.Info(\"UTIL\", \"Path {0} already exists\".format(path))\n    path = \"{0}_{1}\".format(root, i) + ext\n  return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef StripSpecialCharacters(string, stripAll = False):\n  goodlogging.Log.Info(\"UTIL\", \"Stripping any special characters from {0}\".format(string), verbosity=goodlogging.Verbosity.MINIMAL)\n  string = string.strip()\n  string = re.sub('[&]', 'and', string)\n  string = re.sub(r'[@#$%^&*{};:,/<>?\\\\|`~=+\u00b1\u00a7\u00a3]', '', string)\n  string = re.sub('\\s\\s+', ' ', string)\n\n  if stripAll:\n    string = re.sub('[_.-]', '', string)\n    string = re.sub('\\s', '', string)\n\n  goodlogging.Log.Info(\"UTIL\", \"New string is: {0}\".format(string), verbosity=goodlogging.Verbosity.MINIMAL)\n  return string", "response": "Strips any special characters from a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a user response is in a list of valid options.", "response": "def ValidUserResponse(response, validList):\n  \"\"\"\n  Check if user response is in a list of valid entires.\n  If an invalid response is given re-prompt user to enter\n  one of the valid options. Do not proceed until a valid entry\n  is given.\n\n  Parameters\n  ----------\n    response : string\n      Response string to check.\n\n    validList : list\n      A list of valid responses.\n\n  Returns\n  ----------\n    string\n      A valid response string.\n  \"\"\"\n  if response in validList:\n    return response\n  else:\n    prompt = \"Unknown response given - please reenter one of [{0}]: \".format('/'.join(validList))\n    response = goodlogging.Log.Input(\"DM\", prompt)\n    return ValidUserResponse(response, validList)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprompt user to select a valid entry from a given list of entries.", "response": "def UserAcceptance(\n  matchList,\n  recursiveLookup = True,\n  promptComment = None,\n  promptOnly = False,\n  xStrOverride = \"to skip this selection\"\n):\n  \"\"\"\n  Prompt user to select a entry from a given match list or to enter a new\n  string to look up. If the match list is empty user must enter a new string\n  or exit.\n\n  Parameters\n  ----------\n    matchList : list\n      A list of entries which the user can select a valid match from.\n\n    recursiveLookup : boolean [optional: default = True]\n      Allow user to enter a new string to look up.\n\n    promptComment : string [optional: default = None]\n      Add an additional comment on the end of the prompt message.\n\n    promptOnly : boolean [optional: default = False]\n      Set to true if match list is expected to be empty. In which case\n      the presence of an empty match list will not be mentioned and user\n      will be expected to enter a new response to look up.\n\n    xStrOverride : string [optional: default = \"to skip this selection\"]\n      Override the string for 'x' response. This can be used if\n      the behaviour of the 'x' response is changed.\n\n  Returns\n  ----------\n    string or None\n      Either a entry from matchList, another valid response or a new\n      string to look up. If match list is empty and recursive lookup is\n      disabled or if the user response is 'x' this will return None.\n  \"\"\"\n  matchString = ', '.join(matchList)\n\n  if len(matchList) == 1:\n    goodlogging.Log.Info(\"UTIL\", \"Match found: {0}\".format(matchString))\n    prompt = \"Enter 'y' to accept this match or e\"\n  elif len(matchList) > 1:\n    goodlogging.Log.Info(\"UTIL\", \"Multiple possible matches found: {0}\".format(matchString))\n    prompt = \"Enter correct match from list or e\"\n  else:\n    if promptOnly is False:\n      goodlogging.Log.Info(\"UTIL\", \"No match found\")\n    prompt = \"E\"\n    if not recursiveLookup:\n      return None\n\n  if recursiveLookup:\n    prompt = prompt + \"nter a different string to look up or e\"\n\n  prompt = prompt + \"nter 'x' {0} or enter 'exit' to quit this program\".format(xStrOverride)\n\n  if promptComment is None:\n    prompt = prompt + \": \"\n  else:\n    prompt = prompt + \" ({0}): \".format(promptComment)\n\n  while(1):\n    response = goodlogging.Log.Input('UTIL', prompt)\n\n    if response.lower() == 'exit':\n      goodlogging.Log.Fatal(\"UTIL\", \"Program terminated by user 'exit'\")\n    if response.lower() == 'x':\n      return None\n    elif response.lower() == 'y' and len(matchList) == 1:\n      return matchList[0]\n    elif len(matchList) > 1:\n      for match in matchList:\n        if response.lower() == match.lower():\n          return match\n    if recursiveLookup:\n      return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetBestMatch(target, matchList):\n  bestMatchList = []\n\n  if len(matchList) > 0:\n    ratioMatch = []\n    for item in matchList:\n      ratioMatch.append(GetBestStringMatchValue(target, item))\n\n    maxRatio = max(ratioMatch)\n    if maxRatio > 0.8:\n      matchIndexList = [i for i, j in enumerate(ratioMatch) if j == maxRatio]\n\n      for index in matchIndexList:\n        if maxRatio == 1 and len(matchList[index]) == len(target):\n          return [matchList[index], ]\n        else:\n          bestMatchList.append(matchList[index])\n\n  return bestMatchList", "response": "This function returns the list of potential matches which are the same size string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetBestStringMatchValue(string1, string2):\n  # Ignore case\n  string1 = string1.lower()\n  string2 = string2.lower()\n\n  # Ignore non-alphanumeric characters\n  string1 = ''.join(i for i in string1 if i.isalnum())\n  string2 = ''.join(i for i in string2 if i.isalnum())\n\n  # Finding best match value between string1 and string2\n  if len(string1) == 0 or len(string2) == 0:\n    bestRatio = 0\n  elif len(string1) == len(string2):\n    match = difflib.SequenceMatcher(None, string1, string2)\n    bestRatio = match.ratio()\n  else:\n    if len(string1) > len(string2):\n      shortString = string2\n      longString = string1\n    else:\n      shortString = string1\n      longString = string2\n\n    match = difflib.SequenceMatcher(None, shortString, longString)\n    bestRatio = match.ratio()\n\n    for block in match.get_matching_blocks():\n      subString = longString[block[1]:block[1]+block[2]]\n      subMatch = difflib.SequenceMatcher(None, shortString, subString)\n      if(subMatch.ratio() > bestRatio):\n        bestRatio = subMatch.ratio()\n\n  return(bestRatio)", "response": "Returns the value of the highest matching substring between two strings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef WebLookup(url, urlQuery=None, utf8=True):\n\n  goodlogging.Log.Info(\"UTIL\", \"Looking up info from URL:{0} with QUERY:{1})\".format(url, urlQuery), verbosity=goodlogging.Verbosity.MINIMAL)\n  response = requests.get(url, params=urlQuery)\n  goodlogging.Log.Info(\"UTIL\", \"Full url: {0}\".format(response.url), verbosity=goodlogging.Verbosity.MINIMAL)\n  if utf8 is True:\n    response.encoding = 'utf-8'\n  if(response.status_code == requests.codes.ok):\n    return(response.text)\n  else:\n    response.raise_for_status()", "response": "This function will look up webpage at given url with optional query string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove file from given file path to given archive directory.", "response": "def ArchiveProcessedFile(filePath, archiveDir):\n  \"\"\"\n  Move file from given file path to archive directory. Note the archive\n  directory is relative to the file path directory.\n\n  Parameters\n  ----------\n    filePath : string\n      File path\n\n    archiveDir : string\n      Name of archive directory\n  \"\"\"\n  targetDir = os.path.join(os.path.dirname(filePath), archiveDir)\n  goodlogging.Log.Info(\"UTIL\", \"Moving file to archive directory:\")\n  goodlogging.Log.IncreaseIndent()\n  goodlogging.Log.Info(\"UTIL\", \"FROM: {0}\".format(filePath))\n  goodlogging.Log.Info(\"UTIL\", \"TO:   {0}\".format(os.path.join(targetDir, os.path.basename(filePath))))\n  goodlogging.Log.DecreaseIndent()\n  os.makedirs(targetDir, exist_ok=True)\n  try:\n    shutil.move(filePath, targetDir)\n  except shutil.Error as ex4:\n    err = ex4.args[0]\n    goodlogging.Log.Info(\"UTIL\", \"Move to archive directory failed - Shutil Error: {0}\".format(err))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self,text):\n\t#print text\n\tself.s.write(text)\n\ttime.sleep(0.001*len(text))", "response": "Send a string to the PiLite"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_wait(self,text):\n\tself.send(text)\n\ttime.sleep(len(text)*PiLite.COLS_PER_CHAR*self.speed/1000.0)", "response": "Send a string to the PiLite sleep until the message has been sent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the display speed", "response": "def set_speed(self,speed):\n\t\"\"\"Set the display speed.  The parameters is the number of milliseconds\n\tbetween each column scrolling off the display\"\"\"\n\tself.speed=speed\n\tself.send_cmd(\"SPEED\"+str(speed))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the frame buffer.", "response": "def set_fb_pic(self,pattern):\n\t\"\"\"Set the \"frame buffer\".  This allows \"nice\" string to be sent,\n\tbecause it first removes all whitespace, then transposes so that the X\n\tand Y axes are swapped, so what is seen in the file matches what will be\n\tseen on the screen.  Also '.' and '*' can be used in place of 0 and 1.\n\t\"\"\"\n\tpattern=''.join(pattern.split()) # Remove whitespace\n\tpattern=pattern.replace('*','1')\n\tpattern=pattern.replace('.','0')\n\tfb=''\n\tfor x in range(14):\n\t    for y in range(9):\n\t\tfb+=pattern[y*14+x]\n\tself.set_fb(fb)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the frame buffer to a random pattern", "response": "def set_fb_random(self):\n\t\"\"\"Set the \"frame buffer\" to a random pattern\"\"\"\n\tpattern=''.join([random.choice(['0','1']) for i in xrange(14*9)])\n\tself.set_fb(pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_pixel(self,x,y,state):\n\tself.send_cmd(\"P\"+str(x+1)+\",\"+str(y+1)+\",\"+state)", "response": "Set pixel at x y to state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay character char with its top left at x y", "response": "def display_char(self,x,y,char):\n\t\"\"\"Display character \"char\" with its top left at \"x,y\"\n\t\"\"\"\n\tself.send_cmd(\"T\"+str(x+1)+\",\"+str(y+1)+\",\"+char)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef the_magic_mapping_function(peptides, fastaPath, importAttributes=None,\n        ignoreUnmapped=True):\n    \"\"\"Returns a dictionary mapping peptides to protein group leading proteins.\n\n    :param peptides: a set of peptide sequences\n    :param fastaPath: FASTA file path\n    :param importAttributes: dict, can be used to override default parameters\n        passed to the function maspy.proteindb.importProteinDatabase().\n        Default attribtues are:\n        {'cleavageRule': '[KR]', 'removeNtermM': True, 'ignoreIsoleucine': True,\n         forceId': True, 'headerParser': PROTEINDB.fastaParserSpectraClusterPy}\n    :param ignoreUnmapped: bool, if True ignores peptides that cannot be mapped\n        to any protein present in the FASTA file\n\n    :returns: dict, {peptide: set([groupLeaders1, ...])}\n        where groupLeaders is a string joining all leading proteins of a group\n        with a \";\", for example {'peptide': {\"protein1;proetin2;protein3\"}}\n    \"\"\"\n\n    missedCleavage = max([p.count('K') + p.count('R') for p in peptides]) - 1\n    minLength = min([len(p) for p in peptides])\n    maxLength = max([len(p) for p in peptides])\n    defaultAttributes = {\n        'cleavageRule': '[KR]', 'minLength': minLength, 'maxLength': maxLength,\n        'removeNtermM': True,  'ignoreIsoleucine': True,\n        'missedCleavage': missedCleavage, 'forceId': True,\n        'headerParser': PROTEINDB.fastaParserSpectraClusterPy,\n    }\n    if importAttributes is not None:\n        defaultAttributes.update(importAttributes)\n\n    proteindb = PROTEINDB.importProteinDatabase(fastaPath, **defaultAttributes)\n\n    #This could be automated by adding a function to the inference module\n    proteinToPeptides = ddict(set)\n    for peptide in peptides:\n        #ignore any peptide that's not mapped if \"ignoreUnmapped\" is True\n        try:\n            peptideDbEntry = proteindb.peptides[peptide]\n        except KeyError as exception:\n            if ignoreUnmapped:\n                continue\n            else:\n                exceptionText = 'No protein mappings for peptide \"'+peptide+'\"'\n                raise KeyError(exceptionText)\n\n        for protein in peptideDbEntry.proteins:\n            proteinToPeptides[protein].add(peptide)\n\n    #Generate the ProteinInference instance\n    inference = INFERENCE.mappingBasedGrouping(proteinToPeptides)\n\n    peptideGroupMapping = dict()\n    for peptide in peptides:\n        groupLeaders = set()\n        for proteinId in inference.pepToProts[peptide]:\n            for proteinGroup in inference.getGroups(proteinId):\n                groupLeaders.add(';'.join(sorted(proteinGroup.leading)))\n        peptideGroupMapping[peptide] = groupLeaders\n\n    return peptideGroupMapping", "response": "This function returns a dictionary mapping peptides to protein group leading proteins."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the inputted text to camel humps by joining all the words capital letters toegether", "response": "def camelHump(text):\n    \"\"\"\n    Converts the inputted text to camel humps by joining all\n    capital letters toegether (The Quick, Brown, \n    Fox.Tail -> TheQuickBrownFoxTail)\n    \n    :param:      text        <str>       text to be changed\n    \n    :return:     <str>\n    \n    :usage:      |import projex.text\n                |print projex.text.camelHump('The,Quick, Brown, Fox.Tail')\n    \"\"\"\n    # make sure the first letter is upper case\n    output = ''.join([word[0].upper() + word[1:] for word in words(text)])\n    if output:\n        output = output[0].lower() + output[1:]\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncapitalize the word using the normal string capitalization method.", "response": "def capitalize(text):\n    \"\"\"\n    Capitalizes the word using the normal string capitalization \n    method, however if the word contains only capital letters and \n    numbers, then it will not be affected.\n    \n    :param      text                    |   <str>\n    \n    :return     <str>\n    \"\"\"\n    text = nativestring(text)\n    if EXPR_CAPITALS.match(text):\n        return text\n    return text.capitalize()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the inputted text to the standard classname format", "response": "def classname(text):\n    \"\"\"\n    Converts the inputted text to the standard classname format (camel humped\n    with a capital letter to start.\n    \n    :return     <str>\n    \"\"\"\n    if not text:\n        return text\n\n    text = camelHump(text)\n    return text[0].upper() + text[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encoded(text, encoding=DEFAULT_ENCODING):\n    # already a string item\n    if type(text) == bytes_type:\n        return text\n\n    elif type(text) != unicode_type:\n        # convert a QString value\n        if type(text).__name__ == 'QString':\n            if encoding == 'utf-8':\n                return unicode_type(text.toUtf8(), 'utf-8')\n            elif encoding == 'latin-1':\n                return unicode_type(text.toLatin1(), 'latin-1')\n            elif encoding == 'ascii':\n                return unicode_type(text.toAscii(), 'ascii')\n            else:\n                return unicode_type(text, encoding)\n\n        # convert a standard item\n        else:\n            try:\n                return bytes_type(text)\n            except StandardError:\n                return '????'\n\n    if encoding:\n        try:\n            return text.encode(encoding)\n        except StandardError:\n            return text.encode(encoding, errors='ignore')\n\n    else:\n        for enc in SUPPORTED_ENCODINGS:\n            try:\n                return text.encode(enc)\n            except StandardError:\n                pass\n\n    return '????'", "response": "Encodes the inputted unicode string variable with the given encoding type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nattempt to decode the inputted unicode string using the encoding specified in SUPPORTED_ENCODINGS.", "response": "def decoded(text, encoding=DEFAULT_ENCODING):\n    \"\"\"\n    Attempts to decode the inputted unicode/string variable using the\n    given encoding type.  If no encoding is provided, then it will attempt\n    to use one of the ones available from the default list.\n    \n    :param      text     | <variant>\n                encoding | <str> || None\n    \n    :return     <unicode>\n    \"\"\"\n    # unicode has already been decoded\n    if type(text) == unicode_type:\n        return text\n\n    elif type(text) != bytes_type:\n        try:\n            return unicode_type(text)\n        except StandardError:\n            try:\n                text = bytes_type(text)\n            except StandardError:\n                msg = u'<< projex.text.decoded: unable to decode ({0})>>'\n                return msg.format(repr(text))\n\n    if encoding:\n        try:\n            return text.decode(encoding)\n        except StandardError:\n            pass\n\n    for enc in SUPPORTED_ENCODINGS:\n        try:\n            return text.decode(enc)\n        except StandardError:\n            pass\n\n    return u'????'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the inputted value to a native python string - type format.", "response": "def nativestring(val, encodings=None):\n    \"\"\"\n    Converts the inputted value to a native python string-type format.\n    \n    :param      val         | <variant>\n                encodings   | (<str>, ..) || None\n    \n    :sa         decoded\n    \n    :return     <unicode> || <str>\n    \"\"\"\n    # if it is already a native python string, don't do anything\n    if type(val) in (bytes_type, unicode_type):\n        return val\n\n    # otherwise, attempt to return a decoded value\n    try:\n        return unicode_type(val)\n    except StandardError:\n        pass\n\n    try:\n        return bytes_type(val)\n    except StandardError:\n        return decoded(val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string that contains all the words from a text and joins them together with the inputted separator.", "response": "def joinWords(text, separator=''):\n    \"\"\"\n    Collects all the words from a text and joins them together\n    with the inputted separator.\n    \n    :sa         [[#words]]\n    \n    :param      text        <str>\n    :param      separator   <str>\n    \n    :return     <str>\n    \n    :usage      |import projex\n                |print projex.joinWords('This::is.a testTest','-')\n    \"\"\"\n    text = nativestring(text)\n    output = separator.join(words(text.strip(separator)))\n\n    # no need to check for bookended items when its an empty string\n    if not separator:\n        return output\n\n    # look for beginning characters\n    begin = re.match('^\\%s+' % separator, text)\n    if begin:\n        output = begin.group() + output\n\n        # make sure to not double up\n        if begin.group() == text:\n            return output\n\n    # otherwise, look for the ending results\n    end = re.search('\\%s+$' % separator, text)\n    if end:\n        output += end.group()\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the inputted word to the plural form of it.", "response": "def pluralize(word, count=None, format=u'{word}'):\n    \"\"\"\n    Converts the inputted word to the plural form of it.  This method works\n    best if you use the inflect module, as it will just pass along the\n    request to inflect.plural  If you do not have that module, then a simpler\n    and less impressive pluralization technique will be used.\n    \n    :sa         https://pypi.python.org/pypi/inflect\n    \n    :param      word | <str>\n    \n    :return     <str>\n    \"\"\"\n    if count == 1:\n        return word\n    elif count is not None:\n        return format.format(word=word, count=count)\n\n    word = nativestring(word)\n    if inflect_engine:\n        return format.format(word=inflect_engine.plural(word))\n\n    all_upper = EXPR_UPPERCASE.match(word) is not None\n\n    # go through the different plural expressions, searching for the\n    # proper replacement\n    for expr, plural in PLURAL_RULES:\n        results = expr.match(word)\n        if results:\n            result_dict = results.groupdict()\n            single = result_dict.get('single', '')\n\n            # check if its capitalized\n            if all_upper:\n                return format.format(word=single + plural.upper())\n            else:\n                return format.format(word=single + plural)\n\n    # by default, just include 's' at the end\n    if all_upper:\n        return format.format(word=word + 'S')\n    return format.format(word=word + 's')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(text, options, processed=None):\n    output = unicode_type(text)\n    expr = re.compile('(\\[+([^\\[\\]]+)\\]\\]?)')\n    results = expr.findall(output)\n    curr_date = datetime.datetime.now()\n    options_re = re.compile('(\\w+)\\(?([^\\)]+)?\\)?')\n\n    if processed is None:\n        processed = []\n\n    for repl, key in results:\n        # its possible to get multiple items for processing\n        if repl in processed:\n            continue\n\n        # record the repl value as being processed\n        processed.append(repl)\n\n        # replace template templates\n        if repl.startswith('[[') and repl.endswith(']]'):\n            output = output.replace(repl, '[%s]' % key)\n            continue\n\n        # determine the main key and its options\n        splt = key.split('::')\n        key = splt[0]\n        prefs = splt[1:]\n        value = None\n\n        # use the inputted options\n        if key in options:\n            # extract the value\n            value = options[key]\n\n            # format a float\n            if type(value) in (float, int):\n                if prefs:\n                    value = prefs[0] % value\n                else:\n                    value = nativestring(value)\n\n            # convert date time values\n            elif type(value) in (datetime.datetime,\n                                 datetime.date,\n                                 datetime.time):\n                if not prefs:\n                    date_format = '%m/%d/%y'\n                else:\n                    date_format = prefs[0]\n                    prefs = prefs[1:]\n\n                value = value.strftime(nativestring(date_format))\n\n            else:\n                value = render(options[key], options, processed)\n\n        # look for the built-in options\n        elif key == 'date':\n            value = curr_date\n\n            if not prefs:\n                date_format = '%m/%d/%y'\n            else:\n                date_format = prefs[0]\n                prefs = prefs[1:]\n\n            value = value.strftime(nativestring(date_format))\n\n        # otherwise, continue\n        else:\n            continue\n\n        # apply the prefs to the value\n        if value and prefs:\n\n            for pref in prefs:\n                result = options_re.match(pref)\n                pref, opts = result.groups()\n\n                if opts:\n                    opts = [opt.strip() for opt in opts.split(',')]\n                else:\n                    opts = []\n\n                if 'lower' == pref:\n                    value = value.lower()\n                elif 'upper' == pref:\n                    value = value.upper()\n                elif 'upper_first' == pref:\n                    value = value[0].upper() + value[1:]\n                elif 'lower_first' == pref:\n                    value = value[0].lower() + value[1:]\n                elif 'camelHump' == pref:\n                    value = camelHump(value)\n                elif 'underscore' == pref:\n                    value = underscore(value)\n                elif 'capitalize' == pref:\n                    value = capitalize(value)\n                elif pref in ('pluralize', 'plural'):\n                    value = pluralize(value)\n                elif 'words' == pref:\n                    value = ' '.join(words(value))\n                elif 'pretty' == pref:\n                    value = pretty(value)\n\n                elif 'replace' == pref:\n                    if len(opts) == 2:\n                        value = value.replace(opts[0], opts[1])\n                    else:\n                        logger.warning('Invalid options for replace: %s',\n                                       ', '.join(opts))\n\n                elif 'slice' == pref:\n                    if len(opts) == 2:\n                        value = value[int(opts[0]):int(opts[1])]\n                    else:\n                        logger.warning('Invalid options for slice: %s',\n                                       ', '.join(opts))\n\n                elif 'lstrip' == pref:\n                    if not opts:\n                        value = value.lstrip()\n                    else:\n                        for k in opts:\n                            if value.startswith(k):\n                                value = value[len(k):]\n\n                elif 'rstrip' == pref:\n                    if not opts:\n                        value = value.rstrip()\n                    else:\n                        for k in opts:\n                            if value.endswith(k):\n                                value = value[:-len(k)]\n\n        output = output.replace(repl, value)\n\n    return output", "response": "Renders the given text with the given options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef safe_eval(value):\n    if not isinstance(value, (str, unicode)):\n        return value\n\n    try:\n        return CONSTANT_EVALS[value]\n    except KeyError:\n        try:\n            return ast.literal_eval(value)\n        except StandardError:\n            return value", "response": "Converts the inputted text value to a standard python value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit the inputted text up into sections.", "response": "def sectioned(text, sections=1):\n    \"\"\"\n    Splits the inputted text up into sections.\n    \n    :param      text | <str>\n                sections | <int>\n        \n    :return     <str>\n    \"\"\"\n    text = nativestring(text)\n    if not text:\n        return ''\n    count = len(text) / max(1, sections)\n    return ' '.join([text[i:i + count] for i in range(0, len(text), count)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef singularize(word):\n    word = toUtf8(word)\n    if inflect_engine:\n        result = inflect_engine.singular_noun(word)\n        if result is False:\n            return word\n        return result\n\n    # go through the different plural expressions, searching for the\n    # proper replacement\n    if word.endswith('ies'):\n        return word[:-3] + 'y'\n    elif word.endswith('IES'):\n        return word[:-3] + 'Y'\n    elif word.endswith('s') or word.endswith('S'):\n        return word[:-1]\n\n    return word", "response": "This method converts the inputted word to the single form of it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stemmed(text):\n    terms = re.split('\\s*', toAscii(text))\n\n    output = []\n    for term in terms:\n        # ignore apostrophe's\n        if term.endswith(\"'s\"):\n            stripped_term = term[:-2]\n        else:\n            stripped_term = term\n\n        single_term = singularize(stripped_term)\n\n        if term in COMMON_TERMS or stripped_term in COMMON_TERMS or single_term in COMMON_TERMS:\n            continue\n\n        output.append(single_term)\n\n    return output", "response": "Returns a list of simplified and stemmed down terms for the inputted text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip out the HTML tags from the inputted text returning the basic text.", "response": "def stripHtml(html, joiner=''):\n    \"\"\"\n    Strips out the HTML tags from the inputted text, returning the basic\n    text.  This algorightm was found on\n    [http://stackoverflow.com/questions/753052/strip-html-from-strings-in-python StackOverflow].\n    \n    :param      html | <str>\n    \n    :return     <str>\n    \"\"\"\n    stripper = HTMLStripper()\n    stripper.feed(html.replace('<br>', '\\n').replace('<br/>', '\\n'))\n    return stripper.text(joiner)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef truncate(text, length=50, ellipsis='...'):\n    text = nativestring(text)\n    return text[:length] + (text[length:] and ellipsis)", "response": "Returns a truncated version of the inputted text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toBytes(text, encoding=DEFAULT_ENCODING):\n    if not text:\n        return text\n\n    if not isinstance(text, bytes_type):\n        text = text.encode(encoding)\n\n    return text", "response": "Converts the inputted text to base string bytes array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toUnicode(data, encoding=DEFAULT_ENCODING):\n    if isinstance(data, unicode_type):\n        return data\n\n    if isinstance(data, bytes_type):\n        return unicode_type(data, encoding=encoding)\n\n    if hasattr(data, '__iter__'):\n        try:\n            dict(data)\n        except TypeError:\n            pass\n        except ValueError:\n            return (toUnicode(i, encoding) for i in data)\n        else:\n            if hasattr(data, 'items'):\n                data = data.items()\n\n            return dict(((toUnicode(k, encoding), toUnicode(v, encoding)) for k, v in data))\n    return data", "response": "Converts the inputted data to unicode format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the text in the alphabetical order.", "response": "def underscore(text, lower=True):\n    \"\"\"\n    Splits all the words from the inputted text into being\n    separated by underscores\n    \n    :sa         [[#joinWords]]\n    \n    :param      text        <str>\n    \n    :return     <str>\n    \n    :usage      |import projex.text\n                |print projex.text.underscore('TheQuick, Brown, Fox')\n    \"\"\"\n    out = joinWords(text, '_')\n    if lower:\n        return out.lower()\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xmlindent(elem, level=0, spacer='  '):\n    i = \"\\n\" + level * spacer\n    if len(elem):\n        if not elem.text or not elem.text.strip():\n            elem.text = i + spacer\n        if not elem.tail or not elem.tail.strip():\n            elem.tail = i\n        for elem in elem:\n            xmlindent(elem, level + 1)\n        if not elem.tail or not elem.tail.strip():\n            elem.tail = i\n    else:\n        if level and (not elem.tail or not elem.tail.strip()):\n            elem.tail = i", "response": "Indents the inputted XML element based on the given indent level."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef words(text):\n    stext = nativestring(text)\n    if not stext:\n        return []\n\n    # first, split all the alphanumeric characters up\n    phrases = EXPR_PHRASE.findall(stext)\n\n    # second, split all the camel humped words\n    output = []\n    for phrase in phrases:\n        output += EXPR_WORD.findall(phrase)\n\n    return output", "response": "Extracts a list of words from the inputted text and returns them as a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_json(data):\n    return json.dumps(data, default=lambda x: x.__dict__, sort_keys=True, indent=4)", "response": "Return data as a JSON string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves certain characters from a string.", "response": "def convert_string(string, chars=None):\n    \"\"\"Remove certain characters from a string.\"\"\"\n    if chars is None:\n        chars = [',', '.', '-', '/', ':', '  ']\n\n    for ch in chars:\n        if ch in string:\n            string = string.replace(ch, ' ')\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a time string into 24 - hour time.", "response": "def convert_time(time):\n    \"\"\"Convert a time string into 24-hour time.\"\"\"\n    split_time = time.split()\n    try:\n        # Get rid of period in a.m./p.m.\n        am_pm = split_time[1].replace('.', '')\n        time_str = '{0} {1}'.format(split_time[0], am_pm)\n    except IndexError:\n        return time\n    try:\n        time_obj = datetime.strptime(time_str, '%I:%M %p')\n    except ValueError:\n        time_obj = datetime.strptime(time_str, '%I %p')\n\n    return time_obj.strftime('%H:%M %p')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting month name to a string.", "response": "def convert_month(date, shorten=True, cable=True):\n    \"\"\"Replace month by shortening or lengthening it.\n\n    :param shorten: Set to True to shorten month name.\n    :param cable: Set to True if category is Cable.\n    \"\"\"\n    month = date.split()[0].lower()\n    if 'sept' in month:\n        shorten = False if cable else True\n\n    try:\n        if shorten:\n            month = SHORT_MONTHS[MONTHS.index(month)]\n        else:\n            month = MONTHS[SHORT_MONTHS.index(month)]\n    except ValueError:\n        month = month.title()\n\n    return '{0} {1}'.format(month, ' '.join(date.split()[1:]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_date(date):\n    date = convert_month(date, shorten=False)\n    clean_string = convert_string(date)\n    return datetime.strptime(clean_string, DATE_FMT.replace('-',''))", "response": "Convert string to datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef date_in_range(date1, date2, range):\n    date_obj1 = convert_date(date1)\n    date_obj2 = convert_date(date2)\n    return (date_obj2 - date_obj1).days <= range", "response": "Check if two date objects are within a specific range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inc_date(date_obj, num, date_fmt):\n    return (date_obj + timedelta(days=num)).strftime(date_fmt)", "response": "Increment the date by a certain number and return the date object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequest the page and return the soup.", "response": "def get_soup(url):\n    \"\"\"Request the page and return the soup.\"\"\"\n    html = requests.get(url, stream=True, headers=HEADERS)\n    if html.status_code != 404:\n        return BeautifulSoup(html.content, 'html.parser')\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if all words in a word list are in the string.", "response": "def match_list(query_list, string):\n    \"\"\"Return True if all words in a word list are in the string.\n\n    :param query_list: list of words to match\n    :param string: the word or words to be matched against\n    \"\"\"\n    # Get rid of 'the' word to ease string matching\n    match = False\n    index = 0\n    string = ' '.join(filter_stopwords(string))\n\n    if not isinstance(query_list, list):\n        query_list = [query_list]\n\n    while index < len(query_list):\n        query = query_list[index]\n        words_query = filter_stopwords(query)\n        match = all(word in string for word in words_query)\n        if match:\n            break\n\n        index += 1\n\n    return match"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter out stop words and return as a list of words", "response": "def filter_stopwords(phrase):\n    \"\"\"Filter out stop words and return as a list of words\"\"\"\n    if not isinstance(phrase, list):\n        phrase = phrase.split()\n\n    stopwords = ['the', 'a', 'in', 'to']\n    return [word.lower() for word in phrase if word.lower() not in stopwords]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef safe_unicode(string):\n    if not PY3:\n        uni = string.replace(u'\\u2019', \"'\")\n        return uni.encode('utf-8')\n        \n    return string", "response": "If Python 2 replace non - ascii characters and return encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all the string children from an html tag.", "response": "def get_strings(soup, tag):\n    \"\"\"Get all the string children from an html tag.\"\"\"\n    tags = soup.find_all(tag)\n    strings = [s.string for s in tags if s.string]\n    return strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _bld_op(self, op, num, **kwargs):\r\n        kwargs['other'] = num        \r\n        setattr(self, op, {'mtype': pab, 'kwargs': kwargs})", "response": "implements pandas an operator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, request, *args, **kwargs):\n        cart = ShoppingCartProxy(request)\n        return JsonResponse(cart.get_products(onlypublic=request.GET.get('onlypublic', True)))", "response": "Get all products in the shopping cart"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds new product to the current shopping cart", "response": "def post(self, request, *args, **kwargs):\n        \"\"\"\n        Adds new product to the current shopping cart\n        \"\"\"\n        POST = json.loads(request.body.decode('utf-8'))\n\n        if 'product_pk' in POST and 'quantity' in POST:\n            cart = ShoppingCartProxy(request)\n            cart.add(\n                product_pk=int(POST['product_pk']),\n                quantity=int(POST['quantity'])\n            )\n            return JsonResponse(cart.products)\n\n        return HttpResponseBadRequest()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dispatch(self, *args, **kwargs):\n        self.__line_pk = kwargs.get('pk', None)\n        \"\"\"\n        if SalesLineBasketOption.objects.filter(line_budget__pk=self.__line_pk).exists():\n            self.form_class = LineBasketFormPack\n            self.__is_pack = True\n        else:\n            self.__is_pack = False\n        \"\"\"\n        return super(LinesUpdateModalBasket, self).dispatch(*args, **kwargs)", "response": "This method is used to set the form_class attribute of LineBasketFormPack to True if the line budget exists and is_pack = False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_form(self, form_class=None):\n        # form_kwargs = super(LineBasketUpdateModal, self).get_form_kwargs(*args, **kwargs)\n        form = super(LinesUpdateModalBasket, self).get_form(form_class)\n        initial = form.initial\n        initial['type_tax'] = self.object.product_final.product.tax.pk\n        initial['tax'] = self.object.tax_basket\n        initial['price'] = float(self.object.price_base_basket) * (1 + (self.object.tax_basket / 100))\n        \"\"\"\n        if self.__is_pack:\n            options = []\n            lang = get_language_database()\n\n            for option in SalesLineBasketOption.objects.filter(line_budget__pk=self.__line_pk):\n                initial['packs[{}]'.format(option.product_option.pk)] = option.product_final.pk\n                a = {\n                    'id': option.product_option.pk,\n                    'label': getattr(option.product_option, lang).name,\n                    'products': list(option.product_option.products_pack.all().values('pk').annotate(name=F('{}__name'.format(lang)))),\n                    'selected': option.product_final.pk,\n                }\n                options.append(a)\n            # compatibility with GenForeignKey\n            initial['packs'] = json.dumps({'__JSON_DATA__': options})\n        \"\"\"\n        return form", "response": "Returns the form to update the basket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate and save the order.", "response": "def form_valid(self, form):\n        # lb = SalesLines.objects.filter(pk=self.__line_pk).first()\n\n        # product_old = lb.product_final\n        product_pk = self.request.POST.get(\"product_final\", None)\n        quantity = self.request.POST.get(\"quantity\", None)\n        product_final = ProductFinal.objects.filter(pk=product_pk).first()\n        \"\"\"\n        if product:\n            is_pack = product.is_pack()\n        else:\n            is_pack = False\n        \"\"\"\n        if product_final and quantity:\n            reason = form.data['reason']\n            if reason:\n                reason_obj = ReasonModification.objects.filter(pk=reason).first()\n                if reason_obj:\n                    try:\n                        with transaction.atomic():\n                            result = super(LinesUpdateModalBasket, self).form_valid(form)\n\n                            reason_basket = ReasonModificationLineBasket()\n                            reason_basket.basket = self.object.basket\n                            reason_basket.reason = reason_obj\n                            reason_basket.line = self.object\n                            reason_basket.user = get_current_user()\n                            reason_basket.quantity = self.object.quantity\n                            reason_basket.save()\n                            return result\n                    except ValidationError as e:\n                        errors = form._errors.setdefault(\"product_final\", ErrorList())\n                        errors.append(e)\n                        return super(LinesUpdateModalBasket, self).form_invalid(form)\n                else:\n                    errors = form._errors.setdefault(\"reason\", ErrorList())\n                    errors.append(_(\"Reason of modification invalid\"))\n                    return super(LinesUpdatelOrder, self).form_invalid(form)\n            else:\n                errors = form._errors.setdefault(\"reason\", ErrorList())\n                errors.append(_(\"Reason of modification invalid\"))\n                return super(LinesUpdatelOrder, self).form_invalid(form)\n\n            \"\"\"\n            if is_pack:\n                options = product.productfinals_option.filter(active=True)\n                options_pack = []\n                for option in options:\n                    field = 'packs[{}]'.format(option.pk)\n                    opt = self.request.POST.get(field, None)\n                    if opt:\n                        opt_product = ProductFinal.objects.filter(pk=opt).first()\n                        if opt_product:\n                            options_pack.append({\n                                'product_option': option,\n                                'product_final': opt_product,\n                                'quantity': quantity\n                            })\n                        else:\n                            errors = form._errors.setdefault(field, ErrorList())\n                            errors.append(_(\"Product Option invalid\"))\n                            return super(LinesUpdateModalBasket, self).form_invalid(form)\n                    else:\n                        errors = form._errors.setdefault(field, ErrorList())\n                        errors.append(_(\"Option invalid\"))\n                        return super(LinesUpdateModalBasket, self).form_invalid(form)\n            \"\"\"\n        else:\n            errors = form._errors.setdefault(\"product_final\", ErrorList())\n            errors.append((_(\"Product invalid\"), quantity, product_final))\n            return super(LinesUpdateModalBasket, self).form_invalid(form)\n\n        \"\"\"\n        ret = super(LinesUpdateModalBasket, self).form_valid(form)\n        if product_old != self.object.product:\n            self.object.remove_options()\n        if is_pack:\n            self.object.set_options(options_pack)\n        return ret\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a signal at the dispatcher.", "response": "def register_signal(alias: str, signal: pyqtSignal):\n        \"\"\"\n        Used to register signal at the dispatcher. Note that you can not use alias that already exists.\n\n        :param alias: Alias of the signal. String.\n        :param signal: Signal itself. Usually pyqtSignal instance.\n        :return:\n        \"\"\"\n        if SignalDispatcher.signal_alias_exists(alias):\n            raise SignalDispatcherError('Alias \"' + alias + '\" for signal already exists!')\n\n        SignalDispatcher.signals[alias] = signal"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters handler at the dispatcher.", "response": "def register_handler(alias: str, handler: callable):\n        \"\"\"\n        Used to register handler at the dispatcher.\n\n        :param alias: Signal alias to match handler to.\n        :param handler: Handler. Some callable.\n        :return:\n        \"\"\"\n        if SignalDispatcher.handlers.get(alias) is None:\n            SignalDispatcher.handlers[alias] = [handler]\n        else:\n            SignalDispatcher.handlers.get(alias).append(handler)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dispatch():\n        aliases = SignalDispatcher.signals.keys()\n\n        for alias in aliases:\n            handlers = SignalDispatcher.handlers.get(alias)\n            signal = SignalDispatcher.signals.get(alias)\n\n            if signal is None or handlers.__len__() == 0:\n                continue\n\n            for handler in handlers:\n                signal.connect(handler)", "response": "This method runs the wheel. It is used to connect signal with handlers based on the aliases."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef signal_alias_exists(alias: str) -> bool:\n        if SignalDispatcher.signals.get(alias):\n            return True\n\n        return False", "response": "Checks if a signal alias exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handler_alias_exists(alias: str) -> bool:\n        if SignalDispatcher.handlers.get(alias):\n            return True\n\n        return False", "response": "Checks if handler alisa exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_function_data(minion, jid):\n    redis = Redis(connection_pool=redis_pool)\n    data = redis.get('{0}:{1}'.format(minion, jid))\n    return Response(response=data, status=200, mimetype=\"application/json\")", "response": "AJAX access for loading function details."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_api_publisher(self, social_user):\n\n        def _post(**kwargs):\n            api = self.get_api(social_user)\n            from pudb import set_trace; set_trace()\n            # api.group.getInfo('uids'='your_group_id', 'fields'='members_count')\n            #response = api.wall.post(**kwargs)\n            return response\n\n        return _post", "response": "Get the function that returns the response from the API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an SCM version number. Try svn and git.", "response": "def _get_rev(self, fpath):\n        \"\"\"\n        Get an SCM version number. Try svn and git.\n        \"\"\"\n        rev = None\n        \n        try:\n            cmd = [\"git\", \"log\", \"-n1\", \"--pretty=format:\\\"%h\\\"\", fpath]\n            rev = Popen(cmd, stdout=PIPE, stderr=PIPE).communicate()[0]\n        except:\n            pass\n        \n        if not rev:\n            try:\n                cmd = [\"svn\", \"info\", fpath]\n                svninfo = Popen(cmd,\n                                stdout=PIPE,\n                                stderr=PIPE).stdout.readlines()\n                for info in svninfo:\n                    tokens = info.split(\":\")\n                    if tokens[0].strip() == \"Last Changed Rev\":\n                        rev = tokens[1].strip()\n            except:\n                pass\n        \n        return rev"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting all pending migrations across all capable databases and emits post - sync signal.", "response": "def execute_migrations(self, show_traceback=True):\n        \"\"\"\n        Executes all pending migrations across all capable\n        databases\n        \"\"\"\n        all_migrations = get_pending_migrations(self.path, self.databases)\n        \n        if not len(all_migrations):\n            sys.stdout.write(\"There are no migrations to apply.\\n\")\n        \n        for db, migrations in all_migrations.iteritems():\n            connection = connections[db]\n            \n            # init connection\n            cursor = connection.cursor()\n            cursor.close()\n                        \n            for migration in migrations:\n                migration_path = self._get_migration_path(db, migration)\n                \n                with Transactional():\n                    sys.stdout.write(\n                        \"Executing migration %r on %r....\" %\n                        (migration, db)\n                    )\n                    created_models = self._execute_migration(\n                        db,\n                        migration_path,\n                        show_traceback=show_traceback\n                    )\n\n                    emit_post_sync_signal(\n                        created_models=created_models,\n                        verbosity=self.verbosity,\n                        interactive=self.interactive,\n                        db=db,\n                    )\n            \n            if self.load_initial_data:\n                sys.stdout.write(\n                    \"Running loaddata for initial_data fixtures on %r.\\n\" % db\n                )\n                call_command(\n                    \"loaddata\",\n                    \"initial_data\",\n                    verbosity=self.verbosity,\n                    database=db,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(self, *args, **options):\n        self.do_list = options.get(\"do_list\")\n        self.do_execute = options.get(\"do_execute\")\n        self.do_create = options.get(\"do_create\")\n        self.do_create_all = options.get(\"do_create_all\")\n        self.do_seed = options.get(\"do_seed\")\n        self.load_initial_data = options.get(\"load_initial_data\", True)\n        self.args = args\n        \n        if options.get(\"path\"):\n            self.path = options.get(\"path\")\n        else:\n            default_path = self._get_default_migration_path()\n            self.path = getattr(\n                settings, \"NASHVEGAS_MIGRATIONS_DIRECTORY\", default_path\n            )\n        \n        self.verbosity = int(options.get(\"verbosity\", 1))\n        self.interactive = options.get(\"interactive\")\n        self.databases = options.get(\"databases\")\n        \n        # We only use the default alias in creation scenarios (upgrades\n        # default to all databases)\n        if self.do_create and not self.databases:\n            self.databases = [DEFAULT_DB_ALIAS]\n        \n        if self.do_create and self.do_create_all:\n            raise CommandError(\"You cannot combine --create and --create-all\")\n        \n        self.init_nashvegas()\n        \n        if self.do_create_all:\n            self.create_all_migrations()\n        elif self.do_create:\n            assert len(self.databases) == 1\n            self.create_migrations(self.databases[0])\n        \n        if self.do_execute:\n            self.execute_migrations()\n        \n        if self.do_list:\n            self.list_migrations()\n        \n        if self.do_seed:\n            self.seed_migrations()", "response": "Handles the command - line interface for the nashvegas migration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if given directory is a git repository and returns True if it is git repo and False otherwise", "response": "def is_git_directory(path='.'):\n    \"\"\"\n    Checks if given directory is a git repository\n    :param path: path to check\n    :return: True if it's a git repo and False otherwise\n    \"\"\"\n    try:\n        dulwich.repo.Repo.discover(path)\n    except dulwich.errors.NotGitRepository:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets git remote url", "response": "def get_git_remote_url(path='.', remote='origin'):\n    \"\"\"\n    Get git remote url\n    :param path: path to repo\n    :param remote:\n    :return: remote url or exception\n    \"\"\"\n    return dulwich.repo.Repo.discover(path).get_config()\\\n        .get((b'remote', remote.encode('utf-8')), b'url').decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates plantuml class diagram", "response": "def plantuml(desc):\n    \"\"\"Generate plantuml class diagram\n\n    :param desc: result of sadisplay.describe function\n\n    Return plantuml class diagram string\n    \"\"\"\n\n    classes, relations, inherits = desc\n\n    result = [\n        '@startuml',\n        'skinparam defaultFontName Courier',\n    ]\n\n    for cls in classes:\n        # issue #11 - tabular output of class members (attrs)\n        # http://stackoverflow.com/a/8356620/258194\n\n        # build table\n        class_desc = []\n        # table columns\n        class_desc += [(i[1], i[0]) for i in cls['cols']]\n        # class properties\n        class_desc += [('+', i) for i in cls['props']]\n        # methods\n        class_desc += [('%s()' % i, '') for i in cls['methods']]\n\n        result.append(\n            'Class %(name)s {\\n%(desc)s\\n}' % {\n                'name': cls['name'],\n                'desc': '\\n'.join(tabular_output(class_desc)),\n            }\n        )\n\n    for item in inherits:\n        result.append(\"%(parent)s <|-- %(child)s\" % item)\n\n    for item in relations:\n        result.append(\"%(from)s <--o %(to)s: %(by)s\" % item)\n\n    result += [\n        'right footer generated by sadisplay v%s' % __version__,\n        '@enduml',\n    ]\n\n    return '\\n\\n'.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dot(desc, color, title=\"Trump's ORM\"):\n\n    classes, relations, inherits = desc\n\t\n    CLASS_TEMPLATE = \"\"\"\n        %(name)s [label=<\n        <TABLE BGCOLOR=\"{ncolor}\" BORDER=\"0\"\n            CELLBORDER=\"0\" CELLSPACING=\"0\">\n                <TR><TD COLSPAN=\"2\" CELLPADDING=\"4\"\n                        ALIGN=\"CENTER\" BGCOLOR=\"{ncolor}\"\n                ><FONT FACE=\"Helvetica Bold\" COLOR=\"black\"\n                >%(name)s</FONT></TD></TR>%(cols)s%(props)s%(methods)s\n        </TABLE>\n    >]\n    \"\"\".format(**color)\n\n    COLUMN_TEMPLATE = \"\"\"<TR><TD ALIGN=\"LEFT\" BORDER=\"0\"\n        BGCOLOR=\"{ccolor}\"\n        ><FONT FACE=\"Bitstream Vera Sans\">%(name)s</FONT\n        ></TD><TD BGCOLOR=\"{ccolor}\" ALIGN=\"RIGHT\"\n        ><FONT FACE=\"Bitstream Vera Sans\">%(type)s</FONT\n        ></TD></TR>\"\"\".format(**color)\n\n    PROPERTY_TEMPLATE = \"\"\"<TR><TD ALIGN=\"LEFT\" BORDER=\"0\"\n        BGCOLOR=\"{pcolor}\"\n        ><FONT FACE=\"Bitstream Vera Sans\">%(name)s</FONT></TD\n        ><TD BGCOLOR=\"{pcolor}\" ALIGN=\"RIGHT\"\n        ><FONT FACE=\"Bitstream Vera Sans\">PROP</FONT\n        ></TD></TR>\"\"\".format(**color)\n\n    METHOD_TEMPLATE = \"\"\"<TR><TD ALIGN=\"LEFT\" BORDER=\"0\"\n        BGCOLOR=\"{mcolor}\"\n        ><FONT FACE=\"Bitstream Vera Sans\">%(name)s()</FONT></TD\n        ><TD BGCOLOR=\"{mcolor}\" ALIGN=\"RIGHT\"\n        ><FONT FACE=\"Bitstream Vera Sans\">METH</FONT\n        ></TD></TR>\"\"\".format(**color)\n\n    EDGE_INHERIT = \"\\tedge [\\n\\t\\tarrowhead = empty\\n\\t]\"\n    INHERIT_TEMPLATE = \"\\t%(child)s -> %(parent)s \\n\"\n\n    EDGE_REL = \"\\tedge [\\n\\t\\tarrowhead = ediamond\\n\\t\\tarrowtail = open\\n\\t]\"\n    RELATION_TEMPLATE = \"\\t\\\"%(from)s\\\" -> \\\"%(to)s\\\" [label = \\\"%(by)s\\\"]\"\n\n    result = [\"\"\"\n        digraph G {\n            label = \"%s\";\n            fontname = \"Bitstream Vera Sans\"\n            fontsize = 12\n\n            node [\n                fontname = \"Bitstream Vera Sans\"\n                fontsize = 8\n                shape = \"plaintext\"\n            ]\n\n            edge [\n                fontname = \"Bitstream Vera Sans\"\n                fontsize = 8\n            ]\n    \"\"\" % title]\n\n    for cls in classes:\n        cols = ' '.join([\n            COLUMN_TEMPLATE % {'type': c[0], 'name': c[1]} for c in cls['cols']\n        ])\n        props = ' '.join([\n            PROPERTY_TEMPLATE % {'name': p} for p in cls['props']\n        ])\n        methods = ' '.join([\n            METHOD_TEMPLATE % {'name': m} for m in cls['methods']\n        ])\n        renderd = CLASS_TEMPLATE % {\n            'name': cls['name'],\n            'cols': cols,\n            'props': props,\n            'methods': methods,\n        }\n\n        result.append(renderd)\n\n    result += [EDGE_INHERIT]\n    for item in inherits:\n        result.append(INHERIT_TEMPLATE % item)\n\n    result += [EDGE_REL]\n    for item in relations:\n        result.append(RELATION_TEMPLATE % item)\n\n    result += [\n        '}'\n    ]\n\n    return '\\n'.join(result)", "response": "Generate a DOT file of the current locale."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns true if the resource has this rtype with this label", "response": "def is_reference_target(resource, rtype, label):\n    \"\"\" Return true if the resource has this rtype with this label \"\"\"\n\n    prop = resource.props.references.get(rtype, False)\n    if prop:\n        return label in prop"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sources(self, resources):\n\n        rtype = self.rtype  # E.g. category\n        label = self.props.label  # E.g. category1\n        result = [\n            resource\n            for resource in resources.values()\n            if is_reference_target(resource, rtype, label)\n        ]\n        return result", "response": "Filter resources based on which have this reference"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing Kaybee as a Sphinx extension", "response": "def setup(app: Sphinx):\n    \"\"\" Initialize Kaybee as a Sphinx extension \"\"\"\n\n    # Scan for directives, first in the system, second in the docs project\n    importscan.scan(plugins)\n    dectate.commit(kb)\n\n    app.add_config_value('kaybee_settings', KaybeeSettings(), 'html')\n    bridge = 'kaybee.plugins.postrenderer.config.KaybeeBridge'\n    app.config.template_bridge = bridge\n\n    app.connect('env-updated', flush_everything)\n    app.connect(SphinxEvent.BI.value,\n                # pragma nocover\n                lambda sphinx_app: EventAction.call_builder_init(\n                    kb, sphinx_app)\n                )\n    app.connect(SphinxEvent.EPD.value,\n                # pragma nocover\n                lambda sphinx_app, sphinx_env,\n                       docname: EventAction.call_purge_doc(\n                    kb, sphinx_app, sphinx_env, docname)\n                )\n\n    app.connect(SphinxEvent.EBRD.value,\n                # pragma nocover\n                lambda sphinx_app, sphinx_env,\n                       docnames: EventAction.call_env_before_read_docs(\n                    kb, sphinx_app, sphinx_env, docnames)\n                )\n\n    app.connect(SphinxEvent.DREAD.value,\n                # pragma nocover\n                lambda sphinx_app,\n                       doctree: EventAction.call_env_doctree_read(\n                    kb, sphinx_app, doctree)\n                )\n\n    app.connect(SphinxEvent.DRES.value,\n                # pragma nocover\n                lambda sphinx_app, doctree,\n                       fromdocname: EventAction.call_doctree_resolved(\n                    kb, sphinx_app, doctree, fromdocname)\n                )\n\n    app.connect(SphinxEvent.EU.value,\n                # pragma nocover\n                lambda sphinx_app, sphinx_env: EventAction.call_env_updated(\n                    kb, sphinx_app, sphinx_env)\n                )\n\n    app.connect(SphinxEvent.HCP.value,\n                # pragma nocover\n                lambda sphinx_app: EventAction.call_html_collect_pages(\n                    kb, sphinx_app)\n                )\n\n    app.connect(SphinxEvent.ECC.value,\n                # pragma nocover\n                lambda sphinx_builder,\n                       sphinx_env: EventAction.call_env_check_consistency(\n                    kb, sphinx_builder, sphinx_env)\n                )\n\n    app.connect(SphinxEvent.MR.value,\n                # pragma nocover\n                lambda sphinx_app, sphinx_env, node,\n                       contnode: EventAction.call_missing_reference(\n                    kb, sphinx_app, sphinx_env, node, contnode)\n                )\n\n    app.connect(SphinxEvent.HPC.value,\n                # pragma nocover\n                lambda sphinx_app, pagename, templatename, context,\n                       doctree: EventAction.call_html_page_context(\n                    kb, sphinx_app, pagename, templatename, context, doctree)\n                )\n\n    return dict(\n        version=__version__,\n        parallel_read_safe=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef icon(self):\n        path = self._icon\n        if not path:\n            return ''\n\n        path = os.path.expandvars(os.path.expanduser(path))\n        if path.startswith('.'):\n            base_path = os.path.dirname(self.filepath())\n            path = os.path.abspath(os.path.join(base_path, path))\n\n        return path", "response": "Returns the absolute path of the icon file for this plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the plugin path for this class to the given path.", "response": "def addPluginPath(cls, pluginpath):\n        \"\"\"\n        Adds the plugin path for this class to the given path.  The inputted\n        pluginpath value can either be a list of strings, or a string\n        containing paths separated by the OS specific path separator (':' on\n        Mac & Linux, ';' on Windows)\n        \n        :param      pluginpath | [<str>, ..] || <str>\n        \"\"\"\n        prop_key = '_%s__pluginpath' % cls.__name__\n        curr_path = getattr(cls, prop_key, None)\n        if not curr_path:\n            curr_path = []\n            setattr(cls, prop_key, curr_path)\n\n        if isinstance(pluginpath, basestring):\n            pluginpath = pluginpath.split(os.path.pathsep)\n\n        for path in pluginpath:\n            if not path:\n                continue\n\n            path = os.path.expanduser(os.path.expandvars(path))\n            paths = path.split(os.path.pathsep)\n\n            if len(paths) > 1:\n                cls.addPluginPath(paths)\n            else:\n                curr_path.append(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pluginRegisterType(cls):\n        default = Plugin.Type.Module\n        default |= Plugin.Type.Package\n        default |= Plugin.Type.RegistryFile\n\n        return getattr(cls, '_%s__pluginRegisterType', default)", "response": "Returns the register type for this plugin class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadPlugins(cls):\n        plugs = getattr(cls, '_%s__plugins' % cls.__name__, None)\n        if plugs is not None:\n            return\n\n        plugs = {}\n        setattr(cls, '_%s__plugins' % cls.__name__, plugs)\n        typ = cls.pluginRegisterType()\n\n        for path in cls.pluginPath():\n            base_package = projex.packageFromPath(path)\n            base_path = os.path.normpath(projex.packageRootPath(path))\n\n            # make sure it is at the front of the path\n            if base_path in sys.path:\n                sys.path.remove(base_path)\n\n            sys.path.insert(0, base_path)\n            processed = ['__init__']\n\n            # load support for registries\n            if typ & Plugin.Type.RegistryFile:\n                files = glob.glob(os.path.join(path, '*/register.xml'))\n                for file_ in files:\n                    name = os.path.normpath(file_).split(os.path.sep)[-2]\n                    processed.append(name)\n\n                    try:\n                        proxy = PluginProxy.fromFile(cls, file_)\n                        cls.register(proxy)\n\n                    except Exception, e:\n                        name = projex.text.pretty(name)\n                        err = Plugin(name)\n                        err.setError(e)\n                        err.setFilepath(file_)\n\n                        cls.register(err)\n\n                        # log the error\n                        msg = \"%s.plugin('%s') failed to load from %s.\"\n                        logger.warning(msg % (cls.__name__, name, file_))\n                        logger.error(e)\n\n            # load support for packages\n            if typ & Plugin.Type.Package:\n                files = glob.glob(os.path.join(path, '*/__init__.py'))\n                for file_ in files:\n                    name = os.path.normpath(file_).split(os.path.sep)[-2]\n                    if name in processed:\n                        continue\n\n                    processed.append(name)\n                    package = '.'.join([base_package, name]).strip('.')\n                    if not package:\n                        continue\n\n                    try:\n                        __import__(package)\n\n                    except Exception, e:\n                        name = projex.text.pretty(name)\n                        err = Plugin(name)\n                        err.setError(e)\n                        err.setFilepath(file_)\n\n                        cls.register(err)\n\n                        # log the error\n                        msg = \"%s.plugin('%s') failed to load from %s.\"\n                        logger.warning(msg % (cls.__name__, name, file_))\n                        logger.error(e)\n\n            # load support for modules\n            if typ & Plugin.Type.Module:\n                files = glob.glob(os.path.join(path, '*.py'))\n                for file_ in files:\n                    name = os.path.basename(file_).split('.')[0]\n                    if name in processed:\n                        continue\n\n                    processed.append(name)\n                    package = '.'.join([base_package, name]).strip('.')\n                    if not package:\n                        continue\n\n                    try:\n                        __import__(package)\n\n                    except Exception, e:\n                        name = projex.text.pretty(name)\n                        err = Plugin(name)\n                        err.setError(e)\n                        err.setFilepath(file_)\n\n                        cls.register(err)\n\n                        # log the error\n                        msg = \"%s.plugin('%s') failed to load from %s.\"\n                        logger.warning(msg % (cls.__name__, name, file_))\n                        logger.error(e)", "response": "Loads the plugins from the inputted paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plugin(cls, name):\n        cls.loadPlugins()\n        plugs = getattr(cls, '_%s__plugins' % cls.__name__, {})\n        return plugs.get(nstr(name))", "response": "Returns the plugin based on the inputted name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the names of the plugins for a given class.", "response": "def pluginNames(cls, enabled=True):\n        \"\"\"\n        Returns the names of the plugins for a given class.\n        \n        :param      enabled     | <bool> || None\n        \n        :return     [<str>, ..]\n        \"\"\"\n        return map(lambda x: x.name(), cls.plugins(enabled))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plugins(cls, enabled=True):\n        cls.loadPlugins()\n        plugs = getattr(cls, '_%s__plugins' % cls.__name__, {}).values()\n        if enabled is None:\n            return plugs\n\n        return filter(lambda x: x.isEnabled() == enabled, plugs)", "response": "Returns the list of plugins for the given class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(cls, plugin):\n        plugs = getattr(cls, '_%s__plugins' % cls.__name__, None)\n        if plugs is None:\n            cls.loadPlugins()\n\n        plugs = getattr(cls, '_%s__plugins' % cls.__name__, {})\n\n        if plugin.name() in plugs:\n            inst = plugs[plugin.name()]\n\n            # assign the plugin instance to the proxy\n            if isinstance(inst, PluginProxy) and \\\n                    not isinstance(plugin, PluginProxy) and \\\n                    not inst._instance:\n                inst._instance = plugin\n                return True\n\n            return False\n\n        plugs[plugin.name()] = plugin\n        setattr(cls, '_%s__plugins' % cls.__name__, plugs)\n        return True", "response": "Registers the given plugin instance to this system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setPluginPath(cls, pluginpath):\n        setattr(cls, '_%s__pluginpath' % cls.__name__, None)\n        cls.addPluginPath(pluginpath)", "response": "Sets the plugin path for this class to the given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadInstance(self):\n        if self._loaded:\n            return\n\n        self._loaded = True\n        module_path = self.modulePath()\n\n        package = projex.packageFromPath(module_path)\n        path = os.path.normpath(projex.packageRootPath(module_path))\n\n        if path in sys.path:\n            sys.path.remove(path)\n\n        sys.path.insert(0, path)\n\n        try:\n            __import__(package)\n\n        except Exception, e:\n            err = Plugin(self.name(), self.version())\n            err.setError(e)\n            err.setFilepath(module_path)\n\n            self._instance = err\n\n            self.setError(e)\n\n            msg = \"%s.plugin('%s') errored loading instance from %s\"\n            opts = (self.proxyClass().__name__, self.name(), module_path)\n            logger.warning(msg % opts)\n            logger.error(e)", "response": "Loads the plugin from the registry file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modulePath(self):\n        base_path = os.path.dirname(self.filepath())\n        module_path = self.importPath()\n\n        module_path = os.path.expanduser(os.path.expandvars(module_path))\n        if module_path.startswith('.'):\n            module_path = os.path.abspath(os.path.join(base_path, module_path))\n\n        return module_path", "response": "Returns the absolute path of the module that this proxy plugin is imported from."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromFile(cls, filepath):\n        xdata = ElementTree.parse(nstr(filepath))\n        xroot = xdata.getroot()\n\n        # collect variable information\n        name = xroot.get('name')\n        ver = float(xroot.get('version', '1.0'))\n\n        if not name:\n            name = os.path.basename(filepath).split('.')\n            if name == '__init__':\n                name = os.path.normpath(filepath).split(os.path.sep)[-2]\n            name = projex.text.pretty(name)\n\n        icon = xroot.get('icon', './icon.png')\n\n        ximport = xroot.find('import')\n        if ximport is not None:\n            importpath = ximport.get('path', './__init__.py')\n        else:\n            importpath = './__init__.py'\n\n        params = {'description': '', 'author': '', 'email': '', 'url': ''}\n        for param, default in params.items():\n            xdata = xroot.find(param)\n            if xdata is not None:\n                params[param] = xdata.text\n\n        # generate the proxy information\n        proxy = PluginProxy(cls, name, ver)\n        proxy.setImportPath(importpath)\n        proxy.setDescription(params['description'])\n        proxy.setAuthor(params['author'])\n        proxy.setEmail(params['email'])\n        proxy.setUrl(params['url'])\n        proxy.setFilepath(filepath)\n\n        return proxy", "response": "Creates a new instance of the class from the inputted registry file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_resource_json(resource_json):\n\n    for a in ('parent_docname', 'parent', 'template', 'repr', 'series'):\n        if a in resource_json:\n            del resource_json[a]\n\n    props = resource_json['props']\n    for prop in (\n            'acquireds', 'style', 'in_nav', 'nav_title', 'weight',\n            'auto_excerpt'):\n        if prop in props:\n            del props[prop]\n\n    return resource_json", "response": "Clean up the resource json so that it is smaller."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resources_to_json(resources):\n    return {\n        docname: clean_resource_json(resource.__json__(resources))\n        for (docname, resource)\n        in resources.items()\n    }", "response": "Make a JSON representation of the resources db"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef references_to_json(resources, references):\n\n    dump_references = {}\n    for reftype, refvalue in references.items():\n        dump_references[reftype] = {}\n        for label, reference_resource in refvalue.items():\n            target_count = len(reference_resource.get_sources(resources))\n            dump_references[reftype][label] = dict(\n                count=target_count,\n                docname=reference_resource.docname\n            )\n\n    return dump_references", "response": "Convert a dictionary of references to JSON"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a http get request.", "response": "def get(self,\n            url,\n            params=None,\n            cache_cb=None,\n            **kwargs):\n        \"\"\"\n        Make http get request.\n\n        :param url:\n        :param params:\n        :param cache_cb: (optional) a function that taking requests.Response\n            as input, and returns a bool flag, indicate whether should update the cache.\n        :param cache_expire: (optional).\n        :param kwargs: optional arguments.\n        \"\"\"\n        if self.use_random_user_agent:\n            headers = kwargs.get(\"headers\", dict())\n            headers.update({Headers.UserAgent.KEY: Headers.UserAgent.random()})\n            kwargs[\"headers\"] = headers\n\n        url = add_params(url, params)\n\n        cache_consumed, value = self.try_read_cache(url)\n        if cache_consumed:\n            response = requests.Response()\n            response.url = url\n            response._content = value\n        else:\n            response = self.ses.get(url, **kwargs)\n\n        if self.should_we_update_cache(response, cache_cb, cache_consumed):\n            self.cache.set(\n                url, response.content,\n                expire=kwargs.get(\"cache_expire\", self.cache_expire),\n            )\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the html of an url.", "response": "def get_html(self,\n                 url,\n                 params=None,\n                 cache_cb=None,\n                 decoder_encoding=None,\n                 decoder_errors=url_specified_decoder.ErrorsHandle.strict,\n                 **kwargs):\n        \"\"\"\n        Get html of an url.\n        \"\"\"\n        response = self.get(\n            url=url,\n            params=params,\n            cache_cb=cache_cb,\n            **kwargs\n        )\n        return url_specified_decoder.decode(\n            binary=response.content,\n            url=response.url,\n            encoding=decoder_encoding,\n            errors=decoder_errors,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload binary content to destination.", "response": "def download(self,\n                 url,\n                 dst,\n                 params=None,\n                 cache_cb=None,\n                 overwrite=False,\n                 stream=False,\n                 minimal_size=-1,\n                 maximum_size=1024 ** 6,\n                 **kwargs):\n        \"\"\"\n        Download binary content to destination.\n\n        :param url: binary content url\n        :param dst: path to the 'save_as' file\n        :param cache_cb: (optional) a function that taking requests.Response\n            as input, and returns a bool flag, indicate whether should update the cache.\n        :param overwrite: bool,\n        :param stream: bool, whether we load everything into memory at once, or read\n            the data chunk by chunk\n        :param minimal_size: default -1, if response content smaller than\n          minimal_size, then delete what just download.\n        :param maximum_size: default 1GB, if response content greater than\n          maximum_size, then delete what just download.\n        \"\"\"\n        response = self.get(\n            url,\n            params=params,\n            cache_cb=cache_cb,\n            stream=stream,\n            **kwargs\n        )\n\n        if not overwrite:  # pragma: no cover\n            if os.path.exists(dst):\n                raise OSError(\"'%s' exists!\" % dst)\n\n        if stream:\n            chunk_size = 1024 * 1024\n            downloaded_size = 0\n            with atomic_write(dst, mode=\"wb\") as f:\n                for chunk in response.iter_content(chunk_size):\n                    if not chunk:  # pragma: no cover\n                        break\n                    f.write(chunk)\n                    downloaded_size += chunk_size\n                if (downloaded_size < minimal_size) or (downloaded_size > maximum_size):\n                    self.raise_download_oversize_error(\n                        url, downloaded_size, minimal_size, maximum_size)\n        else:\n            content = response.content\n            downloaded_size = sys.getsizeof(content)\n            if (downloaded_size < minimal_size) or (downloaded_size > maximum_size):\n                self.raise_download_oversize_error(\n                    url, downloaded_size, minimal_size, maximum_size)\n            else:\n                with atomic_write(dst, mode=\"wb\") as f:\n                    f.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef option(*args, **kwargs):\n    def decorate_sub_command(method):\n        \"\"\"create and add sub-command options\"\"\"\n        if not hasattr(method, \"optparser\"):\n            method.optparser = SubCmdOptionParser()\n        method.optparser.add_option(*args, **kwargs)\n        return method\n    def decorate_class(klass):\n        \"\"\"store toplevel options\"\"\"\n        assert _forgiving_issubclass(klass, Cmdln)\n        _inherit_attr(klass, \"toplevel_optparser_options\", [], cp=lambda l: l[:])\n        klass.toplevel_optparser_options.append( (args, kwargs) )\n        return klass\n        \n    #XXX Is there a possible optimization for many options to not have a\n    #    large stack depth here?\n    def decorate(obj):\n        if _forgiving_issubclass(obj, Cmdln):\n            return decorate_class(obj)\n        else:\n            return decorate_sub_command(obj)\n    return decorate", "response": "Decorator to add an option to the optparser argument of a Cmdln\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _inherit_attr(klass, attr, default, cp):\n    if attr not in klass.__dict__:\n        if hasattr(klass, attr):\n            value = cp(getattr(klass, attr))\n        else:\n            value = default\n        setattr(klass, attr, value)", "response": "Inherit the attribute from the base class by copying attr from base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nforgive version of issubclass", "response": "def _forgiving_issubclass(derived_class, base_class):\n    \"\"\"Forgiving version of ``issubclass``\n\n    Does not throw any exception when arguments are not of class type\n    \"\"\"\n    return (type(derived_class) is ClassType and \\\n            type(base_class) is ClassType and \\\n            issubclass(derived_class, base_class))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _dispatch_cmd(self, handler, argv):\n        co_argcount = handler.__func__.__code__.co_argcount\n        if co_argcount == 2:   # handler ::= do_foo(self, argv)\n            return handler(argv)\n        elif co_argcount >= 3: # handler ::= do_foo(self, subcmd, opts, ...)\n            try:\n                optparser = handler.optparser\n            except AttributeError:\n                optparser = handler.__func__.optparser = SubCmdOptionParser()\n            assert isinstance(optparser, SubCmdOptionParser)\n\n            # apply subcommand options' defaults from config files, if any.\n            subcmd = handler.__name__.split('do_', 1)[1]\n            optparser.set_defaults(**self.get_option_defaults(subcmd))\n            \n            optparser.set_cmdln_info(self, argv[0])\n            try:\n                opts, args = optparser.parse_args(argv[1:])\n            except StopOptionProcessing:\n                #TODO: this doesn't really fly for a replacement of\n                #      optparse.py behaviour, does it?\n                return 0 # Normal command termination\n\n            try:\n                return handler(argv[0], opts, *args)\n            except TypeError:\n                _, ex, _ = sys.exc_info()\n                # Some TypeError's are user errors:\n                #   do_foo() takes at least 4 arguments (3 given)\n                #   do_foo() takes at most 5 arguments (6 given)\n                #   do_foo() takes exactly 5 arguments (6 given)\n                #   do_foo() takes exactly 5 positional arguments (6 given)\n                # Raise CmdlnUserError for these with a suitably\n                # massaged error message.\n                tb = sys.exc_info()[2] # the traceback object\n                if tb.tb_next is not None:\n                    # If the traceback is more than one level deep, then the\n                    # TypeError do *not* happen on the \"handler(...)\" call\n                    # above. In that we don't want to handle it specially\n                    # here: it would falsely mask deeper code errors.\n                    raise\n                msg = ex.args[0]\n                match = _INCORRECT_NUM_ARGS_RE.search(msg)\n                if match:\n                    msg = list(match.groups())\n                    msg[1] = int(msg[1]) - 3\n                    if msg[1] == 1:\n                        msg[2] = msg[2].replace(\"arguments\", \"argument\")\n                    msg[3] = int(msg[3]) - 3\n                    msg = ''.join(map(str, msg))\n                    raise CmdlnUserError(msg)\n                else:\n                    raise\n        else:\n            raise CmdlnError(\"incorrect argcount for %s(): takes %d, must \"\n                             \"take 2 for 'argv' signature or 3+ for 'opts' \"\n                             \"signature\" % (handler.__name__, co_argcount))", "response": "Introspect the sub - command handler signature to determine how to dispatch the command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timecalMs1DataMedian(msrunContainer, specfile, calibrationData,\n                         minDataPoints=50, deviationKey='relDev'):\n    \"\"\"Generates a calibration value for each MS1 scan by calculating the median\n    deviation\n\n    :param msrunContainer: intance of :class:`maspy.core.MsrunContainer`\n    :param specfile: filename of an ms-run file, used to generate an calibration\n        value for each MS1 spectrum item.\n    :param calibrationData: a dictionary of ``numpy.arrays`` containing\n        calibration data, as returned by :func:`aquireMs1CalibrationData()`\n    :param minDataPoints: The minimal number of data points necessary to\n        calculate the calibration value, default value is \"50\". The calibration\n        value for each scan is calulated as the median of all calibration data\n        points present for this scan. However, if the number of data points is\n        less then specified by ``minDataPoints` the data points of the\n        preceeding and subsequent scans are added until the minimal number of\n        data points is reached.\n    :param deviationKey: the ``calibrationData`` key which contains the\n        calibration data that should be used.\n\n    :returns: a dictionary containing the calibration values for each MS1\n        ``Si``. ``{si.id: {'calibValue': float, 'n': int, 'data': list}``\n    \"\"\"\n    corrData = dict()\n    _posDict = dict()\n    pos = 0\n    for si in msrunContainer.getItems(specfiles=specfile, sort='rt',\n                                      selector=lambda si: si.msLevel==1\n                                      ):\n        corrData[si.id] =  {'calibValue': float(), 'n': int(), 'data': list()}\n        _posDict[pos] = si.id\n        pos += 1\n\n    for siId, deviation in zip(calibrationData['siId'],\n                               calibrationData[deviationKey]):\n        corrData[siId]['data'].append(deviation)\n        corrData[siId]['n'] += 1\n\n    for pos in range(len(corrData)):\n        entry = corrData[_posDict[pos]]\n\n        _data = [entry['data']]\n        _n = entry['n']\n        expansion = 0\n        while _n < minDataPoints:\n            expansion += 1\n            try:\n                expData = corrData[_posDict[pos+expansion]]['data']\n                _data.append(expData)\n                _n += corrData[_posDict[pos+expansion]]['n']\n            except KeyError:\n                pass\n            try:\n                expData = corrData[_posDict[pos-expansion]]['data']\n                _data.append(expData)\n                _n += corrData[_posDict[pos-expansion]]['n']\n            except KeyError:\n                pass\n\n        if len(entry['data']) > 0:\n            median = numpy.median(entry['data'])\n            factor = 1\n        else:\n            median = float()\n            factor = 0\n\n        for expData in _data[1:]:\n            if len(expData) > 0:\n                median += numpy.median(expData) * 0.5\n                factor += 0.5\n        median = median / factor\n        entry['calibValue'] = median\n    return corrData", "response": "Generates a calibration value for each MS1 spectrum item in the specified ms - run file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies the calibration values to the MS1 ion m - z arrays in order to correct for a time dependent m - z error.", "response": "def applyTimeCalMs1(msrunContainer, specfile, correctionData, **kwargs):\n    \"\"\"Applies correction values to the MS1 ion m/z arrays in order to correct\n    for a time dependent m/z error.\n\n    :param msrunContainer: intance of :class:`maspy.core.MsrunContainer`,\n        containing the :class:`maspy.core.Sai` items of the \"specfile\".\n    :param specfile: filename of an ms-run file to which the m/z calibration\n        should be applied\n    :param correctionData: a dictionary containing the calibration values for\n        each MS1 ``Si``, as returned by :func:`timecalMs1DataMedian()`.\n        ``{si.id: {'calibValue': float}``\n    :param toleranceMode: \"relative\" or \"absolute\"\n        Specifies how the ``massTolerance`` value is applied, by default\n        \"relative\".\n    \"\"\"\n    toleranceMode = kwargs.get('toleranceMode', 'relative')\n\n    if toleranceMode == 'relative':\n        for siId in correctionData:\n            calibValue = correctionData[siId]['calibValue']\n            msrunContainer.saic[specfile][siId].arrays['mz'] *= (1 + calibValue)\n    elif toleranceMode == 'absolute':\n        for siId in correctionData:\n            calibValue = correctionData[siId]['calibValue']\n            msrunContainer.saic[specfile][siId].arrays['mz'] += calibValue\n    else:\n        raise Exception('#TODO: a proper exception text')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a correction function to the MS1 ion m/z arrays in order to correct for a m dependent m - z error.", "response": "def applyMassCalMs1(msrunContainer, specfile, dataFit, **kwargs):\n    \"\"\"Applies a correction function to the MS1 ion m/z arrays in order to\n    correct for a m/z dependent m/z error.\n\n    :param msrunContainer: intance of :class:`maspy.core.MsrunContainer`,\n        containing the :class:`maspy.core.Sai` items of the \"specfile\".\n    :param specfile: filename of an ms-run file to which the m/z calibration\n        should be applied\n    :param dataFit: a :class:`maspy.auxiliary.DataFit` object, containing\n        processed calibration data.\n    :param toleranceMode: \"relative\" or \"absolute\"\n        Specifies how the ``massTolerance`` value is applied, by default\n        \"relative\".\n    \"\"\"\n    toleranceMode = kwargs.get('toleranceMode', 'relative')\n\n    if toleranceMode == 'relative':\n        for si in msrunContainer.getItems(specfile,\n                                          selector=lambda si: si.msLevel==1):\n            mzArr = msrunContainer.saic[specfile][si.id].arrays['mz']\n            corrArr = dataFit.corrArray(mzArr)\n            mzArr *= (1 + corrArr)\n    elif toleranceMode == 'absolute':\n        for si in msrunContainer.getItems(specfile,\n                                          selector=lambda si: si.msLevel==1):\n            mzArr = msrunContainer.saic[specfile][si.id].arrays['mz']\n            corrArr = dataFit.corrArray(mzArr)\n            mzArr += corrArr\n    else:\n        raise Exception('#TODO: a proper exception text')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make(self, key, content):\n        pass\n        self.say('make a new key>>>' + key + '>>>with>>>:' + str(content))\n        if key.isdigit():\n            i = int(key)  # list index [p]\n            self.say('extending parent list to contain index:' + key)\n            # make a list with size\n            return self._list(i, content)\n        else:\n            return self._dict(key, content)", "response": "make a new entry in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the given key in the given dict object to the given value.", "response": "def set_path(self, data, path, value):\n        \"\"\"\n        Sets the given key in the given dict object to the given value. If the\n        given path is nested, child dicts are created as appropriate.\n        Accepts either a dot-delimited path or an array of path elements as the\n        `path` variable.\n        \"\"\"\n        self.say('set_path:value:' + str(value) +\n                 ' at:' + str(path) + ' in:' + str(data))\n\n        if isinstance(path, str):\n            path = path.split('.')\n        if len(path) > 1:\n            self.set_path(data.setdefault(path[0], {}), path[1:], value)\n        else:\n            data[path[0]] = value\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_genericpage(cls, kb_app):\n\n        # Presumes the registry has been committed\n        q = dectate.Query('genericpage')\n        klasses = sorted(q(kb_app), key=lambda args: args[0].order)\n        if not klasses:\n            # The site doesn't configure a genericpage,\n            return Genericpage\n        else:\n            return klasses[0][1]", "response": "Return the one class if configured otherwise default"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buy_product(self, product_pk):\n        if self.invoice_sales.filter(lines_sales__product_final__pk=product_pk).exists() \\\n                or self.ticket_sales.filter(lines_sales__product_final__pk=product_pk).exists():\n            return True\n        else:\n            return False", "response": "determina si el customer ha comprado un producto"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a ticket from a list of lines.", "response": "def create_ticket_from_albaran(pk, list_lines):\n        MODEL_SOURCE = SalesAlbaran\n        MODEL_FINAL = SalesTicket\n        url_reverse = 'CDNX_invoicing_ticketsaless_list'\n        # type_doc\n        msg_error_relation = _(\"Hay lineas asignadas a ticket\")\n        msg_error_not_found = _('Sales albaran not found')\n        msg_error_line_not_found = _('Todas las lineas ya se han pasado a ticket')\n\n        return SalesLines.create_document_from_another(pk, list_lines,\n                                                       MODEL_SOURCE, MODEL_FINAL, url_reverse,\n                                                       msg_error_relation, msg_error_not_found, msg_error_line_not_found,\n                                                       False)\n        \"\"\"\n        context = {}\n        if list_lines:\n            new_list_lines = SalesLines.objects.filter(\n                pk__in=[int(x) for x in list_lines]\n            ).exclude(\n                invoice__isnull=True\n            ).values_list('pk')\n\n            if new_list_lines:\n                new_pk = SalesLines.objects.values_list('order__pk').filter(pk__in=new_list_lines).first()\n                if new_pk:\n                    context = SalesLines.create_ticket_from_order(new_pk, new_list_lines)\n                    return context\n                else:\n                    error = _('Pedido no encontrado')\n            else:\n                error = _('Lineas no relacionadas con pedido')\n        else:\n            error = _('Lineas no seleccionadas')\n        context['error'] = error\n        return context\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a SalesInvoice from a list of lines.", "response": "def create_invoice_from_albaran(pk, list_lines):\n        MODEL_SOURCE = SalesAlbaran\n        MODEL_FINAL = SalesInvoice\n        url_reverse = 'CDNX_invoicing_invoicesaless_list'\n        # type_doc\n        msg_error_relation = _(\"Hay lineas asignadas a facturas\")\n        msg_error_not_found = _('Sales albaran not found')\n        msg_error_line_not_found = _('Todas las lineas ya se han pasado a facturas')\n\n        return SalesLines.create_document_from_another(pk, list_lines,\n                                                       MODEL_SOURCE, MODEL_FINAL, url_reverse,\n                                                       msg_error_relation, msg_error_not_found, msg_error_line_not_found,\n                                                       False)\n        \"\"\"\n        context = {}\n        if list_lines:\n            new_list_lines = SalesLines.objects.filter(\n                pk__in=[int(x) for x in list_lines]\n            ).exclude(\n                invoice__isnull=False\n            )\n\n            if new_list_lines:\n                new_pk = new_list_lines.first()\n                if new_pk:\n                    context = SalesLines.create_invoice_from_order(\n                        new_pk.order.pk,\n                        [x['pk'] for x in new_list_lines.values('pk')])\n                    return context\n                else:\n                    error = _('Pedido no encontrado')\n            else:\n                error = _('Lineas no relacionadas con pedido')\n        else:\n            error = _('Lineas no seleccionadas')\n        context['error'] = error\n        return context\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_invoice_from_ticket(pk, list_lines):\n        MODEL_SOURCE = SalesTicket\n        MODEL_FINAL = SalesInvoice\n        url_reverse = 'CDNX_invoicing_invoicesaless_list'\n        # type_doc\n        msg_error_relation = _(\"Hay lineas asignadas a facturas\")\n        msg_error_not_found = _('Sales ticket not found')\n        msg_error_line_not_found = _('Todas las lineas ya se han pasado a facturas')\n\n        return SalesLines.create_document_from_another(pk, list_lines,\n                                                       MODEL_SOURCE, MODEL_FINAL, url_reverse,\n                                                       msg_error_relation, msg_error_not_found, msg_error_line_not_found,\n                                                       False)\n        \"\"\"\n                                context = {}\n                                if list_lines:\n                                    new_list_lines = SalesLines.objects.filter(\n                                        pk__in=[int(x) for x in list_lines]\n                                    ).exclude(\n                                        invoice__isnull=True\n                                    )\n                                    if new_list_lines:\n                                        new_pk = new_list_lines.first()\n                                        if new_pk:\n                                            context = SalesLines.create_invoice_from_order(\n                                                new_pk.order.pk,\n                                                [x['pk'] for x in new_list_lines.values('pk')])\n                                            return context\n                                        else:\n                                            error = _('Pedido no encontrado')\n                                    else:\n                                        error = _('Lineas no relacionadas con pedido')\n                                else:\n                                    error = _('Lineas no seleccionadas')\n                                context['error'] = error\n                                return context\n                        \"\"\"", "response": "Create a SalesLines object from a list of lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli(ctx):\n    manfile = bubble_lib_dir+os.sep+'extras'+os.sep+'Bubble.1.gz'\n    mancmd = [\"/usr/bin/man\", manfile]\n    try:\n        return subprocess.call(mancmd)\n    except Exception as e:\n        print('cannot run man with bubble man page')\n        print('you can always have a look at: '+manfile)", "response": "Shows the man page packed inside the bubble tool"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(self, func, key, timeout=None):\n        '''Wraps a function call with cache.\n\n        Args:\n            func (function): the function to call.\n            key (str): the cache key for this call.\n            timeout (int): the cache timeout for the key (the\n                           unit of this parameter depends on\n                           the cache class you use, for example,\n                           if you use the classes from werkzeug,\n                           then timeout is in seconds.)\n\n        Returns:\n            The return value of calling func\n        '''\n        result = self.get(key)\n        if result == NONE_RESULT:\n            return None\n        if result is None:\n            result = func()\n            self.set(\n                key,\n                result if result is not None else NONE_RESULT,\n                timeout\n            )\n        return result", "response": "Wraps a function call with cache.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncaches return value of multiple calls. Args: key_pattern (str): the key pattern to use for generating keys for caches of the decorated function. func (function): the function to call. all_args (list): a list of args to be used to make calls to the function. timeout (int): the cache timeout Returns: A list of the return values of the calls. Example:: def add(a, b): return a + b cache.map(key_pat, add, [(1, 2), (3, 4)]) == [3, 7]", "response": "def map(self, key_pattern, func, all_args, timeout=None):\n        '''Cache return value of multiple calls.\n\n        Args:\n            key_pattern (str): the key pattern to use for generating\n                               keys for caches of the decorated function.\n            func (function): the function to call.\n            all_args (list): a list of args to be used to make calls to\n                             the function.\n            timeout (int): the cache timeout\n\n        Returns:\n            A list of the return values of the calls.\n\n        Example::\n\n            def add(a, b):\n                return a + b\n\n            cache.map(key_pat, add, [(1, 2), (3, 4)]) == [3, 7]\n        '''\n        results = []\n        keys = [\n            make_key(key_pattern, func, args, {})\n            for args in all_args\n        ]\n        cached = dict(zip(keys, self.get_many(keys)))\n        cache_to_add = {}\n        for key, args in zip(keys, all_args):\n            val = cached[key]\n            if val is None:\n                val = func(*args)\n                cache_to_add[key] = val if val is not None else NONE_RESULT\n            if val == NONE_RESULT:\n                val = None\n            results.append(val)\n        if cache_to_add:\n            self.set_many(cache_to_add, timeout)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default_ssl_context() -> ssl.SSLContext:\n    ctx = ssl.create_default_context(purpose=ssl.Purpose.SERVER_AUTH)\n\n    # OP_NO_SSLv2, OP_NO_SSLv3, and OP_NO_COMPRESSION are already set by default\n    # so we just need to disable the old versions of TLS.\n    ctx.options |= (ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1)\n\n    # ALPN and NPN allow upgrades from HTTP/1.1, but these extensions are only\n    # supported by recent versions of OpenSSL. Try to set them up, but don't cry\n    # if they fail.\n    try:\n        ctx.set_alpn_protocols([\"h2\", \"http/1.1\"])\n    except NotImplementedError:\n        pass\n\n    try:\n        ctx.set_npn_protocols([\"h2\", \"http/1.1\"])\n    except NotImplementedError:\n        pass\n\n    return ctx", "response": "Creates an SSL context suitable for use with HTTP 2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _window_open(self, stream_id: int):\n        stream = self._get_stream(stream_id)\n        return await stream.window_open.wait()", "response": "Wait until the identified stream s flow control window is open."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send_data(\n        self,\n        stream_id: int,\n        data: bytes,\n        end_stream: bool = False,\n    ):\n        \"\"\"Send data, respecting the receiver's flow control instructions. If\n        the provided data is larger than the connection's maximum outbound\n        frame size, it will be broken into several frames as appropriate.\n        \"\"\"\n        if self.closed:\n            raise ConnectionClosedError\n        stream = self._get_stream(stream_id)\n        if stream.closed:\n            raise StreamClosedError(stream_id)\n\n        remaining = data\n        while len(remaining) > 0:\n            await asyncio.gather(\n                self._writable.wait(),\n                self._window_open(stream.id),\n            )\n\n            remaining_size = len(remaining)\n            window_size = self._h2.local_flow_control_window(stream.id)\n            max_frame_size = self._h2.max_outbound_frame_size\n\n            send_size = min(remaining_size, window_size, max_frame_size)\n            if send_size == 0:\n                continue\n\n            logger.debug(\n                f'[{stream.id}] Sending {send_size} of {remaining_size} '\n                f'bytes (window {window_size}, frame max {max_frame_size})'\n            )\n\n            to_send = remaining[:send_size]\n            remaining = remaining[send_size:]\n            end = (end_stream is True and len(remaining) == 0)\n\n            self._h2.send_data(stream.id, to_send, end_stream=end)\n            self._flush()\n\n            if self._h2.local_flow_control_window(stream.id) == 0:\n                stream.window_open.clear()", "response": "Send data to the receiver."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading data from the specified stream until it is closed by the remote peer.", "response": "async def read_data(self, stream_id: int) -> bytes:\n        \"\"\"Read data from the specified stream until it is closed by the remote\n        peer. If the stream is never ended, this never returns.\n        \"\"\"\n        frames = [f async for f in self.stream_frames(stream_id)]\n        return b''.join(frames)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def read_frame(self, stream_id: int) -> bytes:\n        stream = self._get_stream(stream_id)\n        frame = await stream.read_frame()\n        if frame.flow_controlled_length > 0:\n            self._acknowledge_data(frame.flow_controlled_length, stream_id)\n        return frame.data", "response": "Read a single frame of data from the specified stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get_pushed_stream_ids(self, parent_stream_id: int) -> List[int]:\n        if parent_stream_id not in self._streams:\n            logger.error(\n                f'Parent stream {parent_stream_id} unknown to this connection'\n            )\n            raise NoSuchStreamError(parent_stream_id)\n        parent = self._get_stream(parent_stream_id)\n\n        await parent.pushed_streams_available.wait()\n        pushed_streams_ids = self._pushed_stream_ids[parent.id]\n\n        stream_ids: List[int] = []\n        if len(pushed_streams_ids) > 0:\n            stream_ids.extend(pushed_streams_ids)\n            pushed_streams_ids.clear()\n            parent.pushed_streams_available.clear()\n\n        return stream_ids", "response": "Return a list of all streams pushed by the remote peer that are\n        children of the specified stream."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef populate(self, obj):\n        \n        # query\n        if type(obj) is AtlasServiceInstance.Instance:\n            query = { \"instance_id\" : obj.instance_id, \"binding_id\" : { \"$exists\" : False } }\n        elif type(obj) is AtlasServiceBinding.Binding:\n            query = { \"binding_id\" : obj.binding_id, \"instance_id\" : obj.instance.instance_id }\n        else:\n            raise ErrStorageTypeUnsupported(type(obj))\n        \n        # find\n        try:\n            result = self.broker.find_one(query)\n        except:\n            raise ErrStorageMongoConnection(\"Populate Instance or Binding\")\n        \n        if result is not None:\n            obj.parameters = result[\"parameters\"]\n            \n            # Flags the obj to provisioned\n            obj.provisioned = True\n        else:\n            # New\n            obj.provisioned = False", "response": "Populate the object with the information from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores an object into the MongoDB storage for caching", "response": "def store(self, obj):\n        \"\"\" Store \n        \n        Store an object into the MongoDB storage for caching\n        \n        Args:\n            obj (AtlasServiceBinding.Binding or AtlasServiceInstance.Instance): instance or binding\n            \n        Returns:\n            ObjectId: MongoDB _id\n        \n        Raises:\n            ErrStorageMongoConnection: Error during MongoDB communication.\n            ErrStorageTypeUnsupported: Type unsupported.\n            ErrStorageStore : Failed to store the binding or instance.\n        \"\"\"\n        \n        # query\n        if type(obj) is AtlasServiceInstance.Instance:\n            query = { \"instance_id\" : obj.instance_id, \"database\" : obj.get_dbname(), \"cluster\": obj.get_cluster(), \"parameters\" : obj.parameters }\n        elif type(obj) is AtlasServiceBinding.Binding:\n            query = { \"binding_id\" : obj.binding_id, \"parameters\" : obj.parameters, \"instance_id\": obj.instance.instance_id }\n        else:\n            raise ErrStorageTypeUnsupported(type(obj))\n        \n        # insert\n        try:\n            result = self.broker.insert_one(query)\n        except:\n            raise ErrStorageMongoConnection(\"Store Instance or Binding\")\n        \n        if result is not None:\n            # Flags the obj to provisioned\n            obj.provisioned = True\n            return result.inserted_id\n        \n        raise ErrStorageStore()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves an object from the MongoDB storage for caching", "response": "def remove(self, obj):\n        \"\"\" Remove \n        \n        Remove an object from the MongoDB storage for caching\n        \n        Args:\n            obj (AtlasServiceBinding.Binding or AtlasServiceInstance.Instance): instance or binding\n            \n        Raises:\n            ErrStorageTypeUnsupported: Type unsupported.\n        \"\"\"\n        if type(obj) is AtlasServiceInstance.Instance:\n            self.remove_instance(obj)\n        elif type(obj) is AtlasServiceBinding.Binding:\n            self.remove_binding(obj)\n        else:\n            raise ErrStorageTypeUnsupported(type(obj))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_instance(self, instance):\n        \n        # query\n        query = { \"instance_id\" : instance.instance_id, \"binding_id\" : { \"$exists\" : False } }\n        \n        # delete the instance\n        try:\n            result = self.broker.delete_one(query)\n        except:\n            raise ErrStorageMongoConnection(\"Remove Instance\")\n        \n        # return the result\n        if result is not None and result.deleted_count == 1:\n            instance.provisioned = False\n        else:\n            raise ErrStorageRemoveInstance(instance.instance_id)", "response": "Remove an instance from the MongoDB storage for caching\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_binding(self, binding):\n        \n        # query\n        query = { \"binding_id\" : binding.binding_id, \"instance_id\" : binding.instance.instance_id }\n        \n        # delete the binding\n        try:\n            result = self.broker.delete_one(query)\n        except:\n            raise ErrStorageMongoConnection(\"Remove Binding\")\n\n        # return the result\n        if result is not None and result.deleted_count == 1:\n            binding.provisioned = False\n        else:\n            raise ErrStorageRemoveBinding(binding.binding_id)", "response": "Remove an object from the MongoDB storage for caching\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle(self, request, buffer_size):\n\n        if self.component_type == StreamComponent.SOURCE:\n            msg = self.handler_function()\n            return self.__send(request, msg)\n\n        logger = self.logger\n\n        data = self.__receive(request, buffer_size)\n        if data is None:\n            return False\n        else:\n            logger.debug(data.split(self.TERMINATOR))\n            for message in data.split(self.TERMINATOR)[:-1]:\n                logger.debug(message)\n                result = self.handler_function(message)\n                if self.component_type == StreamComponent.PROCESSOR:\n                    if not self.__send(request, result):\n                        return False\n        return True", "response": "Handle a message from the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling a message from the server.", "response": "def handle(self, request, buffer_size):\n        \"\"\"\n        Handle a message\n        :param request: the request socket.\n        :param buffer_size: the buffer size.\n        :return: True if success, False otherwise\n        \"\"\"\n        logger = self.logger\n\n        data = self.__receive(request, buffer_size)\n        if data is None:\n            return False\n        else:\n            arr = array('B',data)\n            for message in split_array(arr,StxEtxHandler.ETX):\n                if message[0] == StxEtxHandler.STX:\n                    message = message[1:]\n                logger.debug(message)\n                result = self.handler_function(bytearray(message))\n                if self.component_type == StreamComponent.PROCESSOR:\n                    if not self.__send(request, result):\n                        return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle(self, request, buffer_size):\n        logger = self.logger\n        msg = self.__receive(request, buffer_size)\n        if msg is None:\n            return False\n\n        result = self.handler_function(msg)\n\n        if self.component_type == StreamComponent.PROCESSOR:\n            return self.__send(request, result)\n        return True", "response": "Handle a message from the socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef importMzml(filepath, msrunContainer=None, siAttrFromSmi=None, specfilename=None):\n    #TODO: docstring\n    siAttrFromSmi = defaultFetchSiAttrFromSmi if siAttrFromSmi is None else siAttrFromSmi\n    if msrunContainer is None:\n        msrunContainer = maspy.core.MsrunContainer()\n\n    basename = os.path.basename(filepath)\n    dirname = os.path.dirname(filepath)\n    filename, extension = os.path.splitext(basename)\n    specfilename = filename if specfilename is None else specfilename\n\n    #Check if the specified file is valid for an import\n    if not os.path.isfile(filepath):\n        raise IOError('File does not exist: %s' % filepath)\n    elif extension.lower() != '.mzml':\n        raise IOError('Filetype is not \"mzml\": %s' % filepath)\n    elif specfilename in msrunContainer.info:\n        print(specfilename, 'already present in the msrunContainer, aborting import.')\n        return None\n\n    mzmlReader = maspy.xml.MzmlReader(filepath)\n    masterContainer = {'rm': str(), 'ci': {}, 'si': {}, 'sai': {}, 'smi': {}}\n    #Dictionary recording which MS2 scans follow a MS1 scan\n    ms1Record = ddict(list)\n\n    for xmlSpectrum in mzmlReader.parseSpectra():\n        smi, binaryDataArrayList = smiFromXmlSpectrum(xmlSpectrum, specfilename)\n        #Generate SpectrumItem\n        si = maspy.core.Si(smi.id, smi.specfile)\n        si.isValid = True\n        siAttrFromSmi(smi, si)\n        if si.msLevel > 1:\n            si.precursorId = si.precursorId.split('scan=')[1] #TODO: change to use regex to extract from known vendor format\n            ms1Record[si.precursorId].append(si.id)\n        else:\n            ms1Record[si.id] #Touch the ddict to add the MS1 id, if it is not already present\n        #Generate SpectrumArrayItem\n        sai = maspy.core.Sai(smi.id, smi.specfile)\n        sai.arrays, sai.arrayInfo = maspy.xml.extractBinaries(binaryDataArrayList,\n                                                              smi.attributes['defaultArrayLength'])\n        #Store all items in the appropriate containers\n        masterContainer['smi'][smi.id] = smi\n        masterContainer['si'][smi.id] = si\n        masterContainer['sai'][smi.id] = sai\n\n    for siId, msnIdList in viewitems(ms1Record):\n        #Ignore KeyError if the spectrum is not present in the mzML file for whatever reason\n        try:\n            setattr(masterContainer['si'][siId], 'msnIdList', msnIdList)\n        except KeyError:\n            pass\n\n    for xmlChromatogram in mzmlReader.chromatogramList:\n        ci = ciFromXml(xmlChromatogram, specfilename)\n        masterContainer['ci'][ci.id] = ci\n    masterContainer['rm'] = mzmlReader.metadataNode\n\n    msrunContainer._addSpecfile(specfilename, dirname)\n    msrunContainer.rmc[specfilename] = masterContainer['rm']\n    msrunContainer.info[specfilename]['status']['rm'] = True\n    msrunContainer.smic[specfilename] = masterContainer['smi']\n    msrunContainer.info[specfilename]['status']['smi'] = True\n    msrunContainer.sic[specfilename] = masterContainer['si']\n    msrunContainer.info[specfilename]['status']['si'] = True\n    msrunContainer.saic[specfilename] = masterContainer['sai']\n    msrunContainer.info[specfilename]['status']['sai'] = True\n    msrunContainer.cic[specfilename] = masterContainer['ci']\n    msrunContainer.info[specfilename]['status']['ci'] = True\n\n    return msrunContainer", "response": "This function takes a mzml file and returns a new mzml item in the msrunContainer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef defaultFetchSiAttrFromSmi(smi, si):\n    for key, value in viewitems(fetchSpectrumInfo(smi)):\n        setattr(si, key, value)\n    for key, value in viewitems(fetchScanInfo(smi)):\n        setattr(si, key, value)\n    if si.msLevel > 1:\n        for key, value in viewitems(fetchParentIon(smi)):\n            setattr(si, key, value)", "response": "Default method to extract attributes from a spectrum metadata item and add them to a spectrum item and\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting an mzml file and converts it to MsrunContainer file", "response": "def convertMzml(mzmlPath, outputDirectory=None):\n    \"\"\"Imports an mzml file and converts it to a MsrunContainer file\n\n    :param mzmlPath: path of the mzml file\n    :param outputDirectory: directory where the MsrunContainer file should be written\n    if it is not specified, the output directory is set to the mzml files directory.\n    \"\"\"\n    outputDirectory = outputDirectory if outputDirectory is not None else os.path.dirname(mzmlPath)\n    msrunContainer = importMzml(mzmlPath)\n    msrunContainer.setPath(outputDirectory)\n    msrunContainer.save()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepareSiiImport(siiContainer, specfile, path, qcAttr, qcLargerBetter,\n                     qcCutoff, rankAttr, rankLargerBetter):\n    \"\"\"Prepares the ``siiContainer`` for the import of peptide spectrum matching\n    results. Adds entries to ``siiContainer.container`` and to\n    ``siiContainer.info``.\n\n    :param siiContainer: instance of :class:`maspy.core.SiiContainer`\n    :param specfile: unambiguous identifier of a ms-run file. Is also used as\n        a reference to other MasPy file containers.\n    :param path: folder location used by the ``SiiContainer`` to save and load\n        data to the hard disk.\n    :param qcAttr: name of the parameter to define a ``Sii`` quality cut off.\n        Typically this is some sort of a global false positive estimator,\n        for example a 'false discovery rate' (FDR).\n    :param qcLargerBetter: bool, True if a large value for the ``.qcAttr`` means\n        a higher confidence.\n    :param qcCutOff: float, the quality threshold for the specifed ``.qcAttr``\n    :param rankAttr: name of the parameter used for ranking ``Sii`` according\n        to how well they match to a fragment ion spectrum, in the case when\n        their are multiple ``Sii`` present for the same spectrum.\n    :param rankLargerBetter: bool, True if a large value for the ``.rankAttr``\n        means a better match to the fragment ion spectrum.\n\n    For details on ``Sii`` ranking see :func:`applySiiRanking()`\n\n    For details on ``Sii`` quality validation see :func:`applySiiQcValidation()`\n    \"\"\"\n    if specfile not in siiContainer.info:\n        siiContainer.addSpecfile(specfile, path)\n    else:\n        raise Exception('...')\n\n    siiContainer.info[specfile]['qcAttr'] = qcAttr\n    siiContainer.info[specfile]['qcLargerBetter'] = qcLargerBetter\n    siiContainer.info[specfile]['qcCutoff'] = qcCutoff\n    siiContainer.info[specfile]['rankAttr'] = rankAttr\n    siiContainer.info[specfile]['rankLargerBetter'] = rankLargerBetter", "response": "Prepares the siiContainer for the import of peptide spectrum matching\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addSiiToContainer(siiContainer, specfile, siiList):\n    for sii in siiList:\n        if sii.id not in siiContainer.container[specfile]:\n            siiContainer.container[specfile][sii.id] = list()\n        siiContainer.container[specfile][sii.id].append(sii)", "response": "Adds the Sii elements contained in the siiList to the appropriate\n    list in siiContainer. container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply the ranking of all Sii entries in a MasPy file to the internal structure of the SiiContainer.", "response": "def applySiiRanking(siiContainer, specfile):\n    \"\"\"Iterates over all Sii entries of a specfile in siiContainer and sorts Sii\n    elements of the same spectrum according to the score attribute specified in\n    ``siiContainer.info[specfile]['rankAttr']``. Sorted Sii elements are then\n    ranked  according to their sorted position, if multiple Sii have the same\n    score, all get the same rank and the next entries rank is its list position.\n\n    :param siiContainer: instance of :class:`maspy.core.SiiContainer`\n    :param specfile: unambiguous identifier of a ms-run file. Is also used as\n        a reference to other MasPy file containers.\n    \"\"\"\n    attr = siiContainer.info[specfile]['rankAttr']\n    reverse = siiContainer.info[specfile]['rankLargerBetter']\n    for itemList in listvalues(siiContainer.container[specfile]):\n        sortList = [(getattr(sii, attr), sii) for sii in itemList]\n        itemList = [sii for score, sii in sorted(sortList, reverse=reverse)]\n\n        #Rank Sii according to their position\n        lastValue = None\n        for itemPosition, item in enumerate(itemList, 1):\n            if getattr(item, attr) != lastValue:\n                rank = itemPosition\n            item.rank = rank\n            lastValue = getattr(item, attr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef applySiiQcValidation(siiContainer, specfile):\n    attr = siiContainer.info[specfile]['qcAttr']\n    cutOff = siiContainer.info[specfile]['qcCutoff']\n    if siiContainer.info[specfile]['qcLargerBetter']:\n        evaluator = lambda sii: getattr(sii, attr) >= cutOff and sii.rank == 1\n    else:\n        evaluator = lambda sii: getattr(sii, attr) <= cutOff and sii.rank == 1\n\n    for itemList in listvalues(siiContainer.container[specfile]):\n        #Set the .isValid attribute of all Sii to False\n        for sii in itemList:\n            sii.isValid = False\n\n        #Validate the first Sii\n        sii = itemList[0]\n        if evaluator(sii):\n            sii.isValid = True", "response": "Applies validation to all Sii entries of a specfile in siiContainer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readPercolatorResults(filelocation, specfile, psmEngine):\n    if psmEngine not in ['comet', 'msgf', 'xtandem']:\n        raise Exception('PSM search engine not supported: ', psmEngine)\n    itemList = list()\n\n    #Note: regarding headerline, xtandem seperates proteins with ';',\n    #msgf separates proteins with a tab\n    with io.open(filelocation, 'r', encoding='utf-8') as openfile:\n        lines = openfile.readlines()\n\n    headerDict = dict([[y,x] for (x,y) in\n                       enumerate(lines[0].strip().split('\\t'))\n                       ])\n    scanEntryList = list()\n    for line in lines[1:]:\n        if len(line.strip()) == 0:\n            continue\n        fields = line.strip().split('\\t')\n\n        if psmEngine in ['comet', 'msgf']:\n            scanNr = fields[headerDict['PSMId']].split('_')[-3]\n        elif psmEngine in ['xtandem']:\n            scanNr = fields[headerDict['PSMId']].split('_')[-2]\n\n        peptide = fields[headerDict['peptide']]\n        if peptide.find('.') != -1:\n            peptide = peptide.split('.')[1]\n        #Change to the new unimod syntax\n        peptide = peptide.replace('[UNIMOD:', '[u:')\n        sequence = maspy.peptidemethods.removeModifications(peptide)\n\n        qValue = fields[headerDict['q-value']]\n        score = fields[headerDict['score']]\n        pep = fields[headerDict['posterior_error_prob']]\n\n        sii = maspy.core.Sii(scanNr, specfile)\n        sii.peptide = peptide\n        sii.sequence = sequence\n        sii.qValue = float(qValue)\n        sii.score = float(score)\n        sii.pep = float(pep)\n        sii.isValid = False\n\n        itemList.append(sii)\n    return itemList", "response": "Reads percolator PSM results from a txt file and returns a list of Sii elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting peptide spectrum matches from a percolator result file.", "response": "def importPercolatorResults(siiContainer, filelocation, specfile, psmEngine,\n                            qcAttr='qValue', qcLargerBetter=False,\n                            qcCutoff=0.01, rankAttr='score',\n                            rankLargerBetter=True):\n    \"\"\"Import peptide spectrum matches (PSMs) from a percolator result file,\n    generate :class:`Sii <maspy.core.Sii>` elements and store them in the\n    specified :class:`siiContainer <maspy.core.SiiContainer>`. Imported ``Sii``\n    are ranked according to a specified attribute and validated if they surpass\n    a specified quality threshold.\n\n    :param siiContainer: imported PSM results are added to this instance of\n        :class:`siiContainer <maspy.core.SiiContainer>`\n    :param filelocation: file path of the percolator result file\n    :param specfile: unambiguous identifier of a ms-run file. Is also used as\n        a reference to other MasPy file containers.\n    :param psmEngine: PSM search engine used for peptide spectrum matching\n        before percolator. For details see :func:`readPercolatorResults()`.\n        Possible values are 'comet', 'xtandem', 'msgf'.\n    :param qcAttr: name of the parameter to define a quality cut off. Typically\n        this is some sort of a global false positive estimator (eg FDR)\n    :param qcLargerBetter: bool, True if a large value for the ``.qcAttr`` means\n        a higher confidence.\n    :param qcCutOff: float, the quality threshold for the specifed ``.qcAttr``\n    :param rankAttr: name of the parameter used for ranking ``Sii`` according\n        to how well they match to a fragment ion spectrum, in the case when\n        their are multiple ``Sii`` present for the same spectrum.\n    :param rankLargerBetter: bool, True if a large value for the ``.rankAttr``\n        means a better match to the fragment ion spectrum\n\n    For details on ``Sii`` ranking see :func:`applySiiRanking()`\n\n    For details on ``Sii`` quality validation see :func:`applySiiQcValidation()`\n    \"\"\"\n\n    path = os.path.dirname(filelocation)\n    siiList = readPercolatorResults(filelocation, specfile, psmEngine)\n    prepareSiiImport(siiContainer, specfile, path, qcAttr, qcLargerBetter,\n                     qcCutoff, rankAttr, rankLargerBetter)\n    addSiiToContainer(siiContainer, specfile, siiList)\n    applySiiRanking(siiContainer, specfile)\n    applySiiQcValidation(siiContainer, specfile)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readMsgfMzidResults(filelocation, specfile=None):\n    readSpecfile = True if specfile is None else False\n\n    unimod = pyteomics.mass.mass.Unimod()\n    _tempMods = dict()\n    mzid_refs = pyteomics.mzid.read(filelocation, retrieve_refs=True,\n                                    iterative=False)\n\n    siiList = list()\n    for mzidEntry in mzid_refs:\n        mzidSii = mzidEntry['SpectrumIdentificationItem'][0]\n        scanNumber = str(int(mzidEntry['scan number(s)']))\n        if readSpecfile:\n            specfile = os.path.splitext(mzidEntry['name'])[0]\n\n        sii = maspy.core.Sii(scanNumber, specfile)\n        sii.isValid = mzidSii['passThreshold']\n        sii.rank = mzidSii['rank']\n        sii.eValue = mzidSii['MS-GF:EValue']\n        sii.charge = mzidSii['chargeState']\n        sii.sequence = mzidSii['PeptideSequence']\n        sii.specEValue = mzidSii['MS-GF:SpecEValue']\n        sii.score = numpy.log10(sii.eValue)*-1\n\n        if 'Modification' in mzidSii:\n            modifications = list()\n            for modEntry in mzidSii['Modification']:\n                try:\n                    modSymbolMaspy = _tempMods[modEntry['name']]\n                except KeyError:\n                    unimodEntry = unimod.by_title(modEntry['name'])\n                    if len(unimodEntry) != 0:\n                        modSymbol = 'u:'+str(unimodEntry['record_id'])\n                    else:\n                        modSymbol = modEntry['name']\n                    modSymbolMaspy = '[' + modSymbol + ']'\n                    _tempMods[modEntry['name']] = modSymbolMaspy\n                modifications.append((modEntry['location'], modSymbolMaspy))\n            modifications.sort(key=ITEMGETTER(0))\n\n            _lastPos = 0\n            _peptide = list()\n            for pos, mod in modifications:\n                 _peptide.extend((sii.sequence[_lastPos:pos], mod))\n                 _lastPos = pos\n            _peptide.append(sii.sequence[_lastPos:])\n\n            sii.peptide = ''.join(_peptide)\n        else:\n            sii.peptide = sii.sequence\n        siiList.append(sii)\n    return siiList", "response": "Reads a mzIdentML file and returns a list of Sii objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports PSM matches from a MS - GF + mzIdentML file and store them in the mzIDXML file.", "response": "def importMsgfMzidResults(siiContainer, filelocation, specfile=None,\n                          qcAttr='eValue', qcLargerBetter=False, qcCutoff=0.01,\n                          rankAttr='score', rankLargerBetter=True):\n    \"\"\"Import peptide spectrum matches (PSMs) from a MS-GF+ mzIdentML file,\n    generate :class:`Sii <maspy.core.Sii>` elements and store them in the\n    specified :class:`siiContainer <maspy.core.SiiContainer>`. Imported ``Sii``\n    are ranked according to a specified attribute and validated if they surpass\n    a specified quality threshold.\n\n    :param siiContainer: imported PSM results are added to this instance of\n        :class:`siiContainer <maspy.core.SiiContainer>`\n    :param filelocation: file path of the percolator result file\n    :param specfile: optional, unambiguous identifier of a ms-run file. Is also\n        used as a reference to other MasPy file containers. If specified the\n        attribute ``.specfile`` of all ``Sii`` is set to this value, else\n        it is read from the mzIdentML file.\n    :param qcAttr: name of the parameter to define a quality cut off. Typically\n        this is some sort of a global false positive estimator (eg FDR)\n    :param qcLargerBetter: bool, True if a large value for the ``.qcAttr`` means\n        a higher confidence.\n    :param qcCutOff: float, the quality threshold for the specifed ``.qcAttr``\n    :param rankAttr: name of the parameter used for ranking ``Sii`` according\n        to how well they match to a fragment ion spectrum, in the case when\n        their are multiple ``Sii`` present for the same spectrum.\n    :param rankLargerBetter: bool, True if a large value for the ``.rankAttr``\n        means a better match to the fragment ion spectrum\n\n    For details on ``Sii`` ranking see :func:`applySiiRanking()`\n\n    For details on ``Sii`` quality validation see :func:`applySiiQcValidation()`\n    \"\"\"\n    path = os.path.dirname(filelocation)\n    siiList = readMsgfMzidResults(filelocation, specfile)\n\n    #If the mzIdentML file contains multiple specfiles, split the sii elements\n    # up according to their specified \"specfile\" attribute.\n    specfiles = ddict(list)\n    if specfile is None:\n        for sii in siiList:\n            specfiles[sii.specfile].append(sii)\n    else:\n        specfiles[specfile] = siiList\n\n    for specfile in specfiles:\n        _siiList = specfiles[specfile]\n\n        prepareSiiImport(siiContainer, specfile, path, qcAttr, qcLargerBetter,\n                         qcCutoff, rankAttr, rankLargerBetter)\n        addSiiToContainer(siiContainer, specfile, _siiList)\n        applySiiRanking(siiContainer, specfile)\n        applySiiQcValidation(siiContainer, specfile)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting peptide features from a featureXml file.", "response": "def importPeptideFeatures(fiContainer, filelocation, specfile):\n    \"\"\" Import peptide features from a featureXml file, as generated for example\n    by the OpenMS node featureFinderCentroided, or a features.tsv file by the\n    Dinosaur command line tool.\n\n    :param fiContainer: imported features are added to this instance of\n        :class:`FeatureContainer <maspy.core.FeatureContainer>`.\n    :param filelocation: Actual file path\n    :param specfile: Keyword (filename) to represent file in the\n        :class:`FeatureContainer`. Each filename can only occure once, therefore\n        importing the same filename again is prevented.\n    \"\"\"\n    if not os.path.isfile(filelocation):\n        warnings.warn('The specified file does not exist %s' %(filelocation, ))\n        return None\n    elif (not filelocation.lower().endswith('.featurexml') and\n          not filelocation.lower().endswith('.features.tsv')\n          ):\n        #TODO: this is depricated as importPeptideFeatues\n        #is not longer be used solely for featurexml\n        print('Wrong file extension, %s' %(filelocation, ))\n    elif specfile in fiContainer.info:\n        print('%s is already present in the SiContainer, import interrupted.'\n              %(specfile, )\n              )\n        return None\n\n    #Prepare the file container for the import\n    fiContainer.addSpecfile(specfile, os.path.dirname(filelocation))\n\n    #import featurexml file\n    if filelocation.lower().endswith('.featurexml'):\n        featureDict = _importFeatureXml(filelocation)\n        for featureId, featureEntryDict in viewitems(featureDict):\n            rtArea = set()\n            for convexHullEntry in featureEntryDict['convexHullDict']['0']:\n                rtArea.update([convexHullEntry[0]])\n\n            fi = maspy.core.Fi(featureId, specfile)\n            fi.rt = featureEntryDict['rt']\n            fi.rtArea = max(rtArea) - min(rtArea)\n            fi.rtLow = min(rtArea)\n            fi.rtHigh = max(rtArea)\n            fi.charge = featureEntryDict['charge']\n            fi.mz = featureEntryDict['mz']\n            fi.mh = maspy.peptidemethods.calcMhFromMz(featureEntryDict['mz'],\n                                                      featureEntryDict['charge'])\n            fi.intensity = featureEntryDict['intensity']\n            fi.quality = featureEntryDict['overallquality']\n            fi.isMatched = False\n            fi.isAnnotated = False\n            fi.isValid = True\n\n            fiContainer.container[specfile][featureId] = fi\n\n    #import dinosaur tsv file\n    elif filelocation.lower().endswith('.features.tsv'):\n        featureDict = _importDinosaurTsv(filelocation)\n        for featureId, featureEntryDict in viewitems(featureDict):\n            fi = maspy.core.Fi(featureId, specfile)\n            fi.rt = featureEntryDict['rtApex']\n            fi.rtArea = featureEntryDict['rtEnd'] - featureEntryDict['rtStart']\n            fi.rtFwhm = featureEntryDict['fwhm']\n            fi.rtLow = featureEntryDict['rtStart']\n            fi.rtHigh = featureEntryDict['rtEnd']\n            fi.charge = featureEntryDict['charge']\n            fi.numScans  = featureEntryDict['nScans']\n            fi.mz = featureEntryDict['mz']\n            fi.mh = maspy.peptidemethods.calcMhFromMz(featureEntryDict['mz'],\n                                                      featureEntryDict['charge'])\n            fi.intensity = featureEntryDict['intensitySum']\n            fi.intensityApex = featureEntryDict['intensityApex']\n            #Note: not used keys:\n            #mostAbundantMz nIsotopes nScans averagineCorr mass massCalib\n\n            fi.isMatched = False\n            fi.isAnnotated = False\n            fi.isValid = True\n\n            fiContainer.container[specfile][featureId] = fi"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _importFeatureXml(filelocation):\n    with io.open(filelocation, 'r', encoding='utf-8') as openFile:\n        readingFeature = False\n        readingHull = False\n        featureDict = dict()\n\n        for i, line in enumerate(openFile):\n            line = line.strip()\n            if readingFeature == True:\n                if line.find('<convexhull') != -1:\n                    readingHull = True\n                    hullNr = line.split('<convexhull nr=\\\"')[1].split('\\\">')[0]\n                    hullList = list()\n                elif readingHull == True:\n                    if line.find('<pt') != -1:\n                        x = float(line.split('x=\\\"')[1].split('\\\"')[0])\n                        y = float(line.split('y=\\\"')[1].split('\\\"')[0])\n                        # x = retentiontime, y = m/z\n                        #retentionTimeList.append(x)\n                        hullList.append([x,y])\n                    elif line.find('</convexhull>') != -1:\n                        featureDict[featureKey]['convexHullDict'][hullNr] = hullList\n                        readingHull = False\n\n                elif line.find('<position dim=\\\"0\\\">') != -1:\n                    featureDict[featureKey]['dim0'] = float(line.split('<position dim=\\\"0\\\">')[1].split('</position>')[0])\n                elif line.find('<position dim=\\\"1\\\">') != -1:\n                    featureDict[featureKey]['dim1'] = float(line.split('<position dim=\\\"1\\\">')[1].split('</position>')[0])\n                elif line.find('<intensity>') != -1:\n                    featureDict[featureKey]['intensity'] = float(line.split('<intensity>')[1].split('</intensity>')[0])\n                elif line.find('<overallquality>') != -1:\n                    featureDict[featureKey]['overallquality'] = float(line.split('<overallquality>')[1].split('</overallquality>')[0])\n                elif line.find('<charge>') != -1:\n                    featureDict[featureKey]['charge'] = int( line.split('<charge>')[1].split('</charge>')[0] )\n\n                elif line.find('<userParam') != -1:\n                    if line.find('name=\\\"label\\\"') != -1:\n                        featureDict[featureKey]['label'] = line.split('value=\\\"')[1].split('\\\"/>')[0]\n                    elif line.find('name=\\\"score_fit\\\"') != -1:\n                        featureDict[featureKey]['score_fit'] = float(line.split('value=\\\"')[1].split('\\\"/>')[0])\n                    elif line.find('name=\\\"score_correlation\\\"') != -1:\n                        featureDict[featureKey]['score_correlation'] = float(line.split('value=\\\"')[1].split('\\\"/>')[0])\n                    elif line.find('name=\\\"FWHM\\\"') != -1:\n                        featureDict[featureKey]['FWHM'] = float(line.split('value=\\\"')[1].split('\\\"/>')[0])\n                    elif line.find('name=\\\"spectrum_index\\\"') != -1:\n                        featureDict[featureKey]['spectrum_index'] = line.split('value=\\\"')[1].split('\\\"/>')[0]\n                    elif line.find('name=\\\"spectrum_native_id\\\"') != -1:\n                        featureDict[featureKey]['spectrum_native_id'] = line.split('value=\\\"')[1].split('\\\"/>')[0]\n\n                elif line.find('</feature>') != -1:\n                    #mzList = list()\n                    #for retentionTime,mz in featureDict[featureKey]['convexHullDict']['0']:\n                    #    mzList.append(mz)\n                    featureDict[featureKey]['rt'] = featureDict[featureKey]['dim0']#numpy.median(retentionTimeList)\n                    featureDict[featureKey]['mz'] = featureDict[featureKey]['dim1']#numpy.median(mzList)\n\n                    readingFeature == False\n\n            if line.find('<feature id') != -1:\n                readingFeature = True\n                featureKey = line.split('<feature id=\\\"')[1].split('\\\">')[0]\n                featureDict[featureKey] = dict()\n                featureDict[featureKey]['convexHullDict'] = dict()\n                #retentionTimeList = list()\n    return featureDict", "response": "Reads a featureXml file and returns a dictionary of featureKey - > featureValue"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a Dinosaur tsv file and returns a dictionary of featureKey1 attribute1 attribute2 and attribute2 values.", "response": "def _importDinosaurTsv(filelocation):\n    \"\"\"Reads a Dinosaur tsv file.\n\n    :returns: {featureKey1: {attribute1:value1, attribute2:value2, ...}, ...}\n\n    See also :func:`importPeptideFeatures`\n    \"\"\"\n    with io.open(filelocation, 'r', encoding='utf-8') as openFile:\n        #NOTE: this is pretty similar to importing percolator results, maybe unify in a common function\n        lines = openFile.readlines()\n        headerDict = dict([[y,x] for (x,y) in enumerate(lines[0].strip().split('\\t'))])\n        featureDict = dict()\n        for linePos, line in enumerate(lines[1:]):\n            featureId = str(linePos)\n            fields = line.strip().split('\\t')\n            entryDict = dict()\n            for headerName, headerPos in viewitems(headerDict):\n                entryDict[headerName] = float(fields[headerPos])\n                if headerName in ['rtApex', 'rtEnd', 'rtStart', 'fwhm']:\n                    #Covnert to seconds\n                    entryDict[headerName] *= 60\n                elif headerName in ['charge', 'intensitySum', 'nIsotopes', 'nScans', 'intensityApex']:\n                    entryDict[headerName] = int(entryDict[headerName])\n            featureDict[featureId] = entryDict\n    return featureDict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rst_to_html(input_string: str) -> str:\n\n    overrides = dict(input_encoding='unicode', doctitle_xform=True,\n                     initial_header_level=1)\n    parts = publish_parts(\n        writer_name='html',\n        source=input_string,\n        settings_overrides=overrides\n    )\n    return parts['html_body']", "response": "Given a string of RST use docutils to generate html"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving some RST extract what docutils thinks is the title", "response": "def get_rst_title(rst_doc: Node) -> Optional[Any]:\n    \"\"\" Given some RST, extract what docutils thinks is the title \"\"\"\n\n    for title in rst_doc.traverse(nodes.title):\n        return title.astext()\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_rst_excerpt(rst_doc: document, paragraphs: int = 1) -> str:\n\n    texts = []\n    for count, p in enumerate(rst_doc.traverse(paragraph)):\n        texts.append(p.astext())\n        if count + 1 == paragraphs:\n            break\n    return ' '.join(texts)", "response": "Given an rst document parse and return a portion of the rst document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requires_password_auth(fn):\n    def wrapper(self, *args, **kwargs):\n        self.auth_context = HAPI.auth_context_password\n        return fn(self, *args, **kwargs)\n    return wrapper", "response": "Decorator for methods that requires the instance to be authenticated with a password"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef requires_api_auth(fn):\n    def wrapper(self, *args, **kwargs):\n        self.auth_context = HAPI.auth_context_hapi\n        return fn(self, *args, **kwargs)\n    return wrapper", "response": "Decorator for methods that requires the instance to be authenticated with a HAPI token"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a postdata - style response into usable data", "response": "def parse(response):\n        \"\"\"Parse a postdata-style response format from the API into usable data\"\"\"\n\n        \"\"\"Split a a=1b=2c=3 string into a dictionary of pairs\"\"\"\n        tokens = {r[0]: r[1] for r in [r.split('=') for r in response.split(\"&\")]}\n\n        # The odd dummy parameter is of no use to us\n        if 'dummy' in tokens:\n            del tokens['dummy']\n\n        \"\"\"\n        If we have key names that end in digits, these indicate the result set contains multiple sets\n        For example, planet0=Hoth&x=1&y=-10&planet1=Naboo&x=9&y=13 is actually data for two planets\n\n        Elements that end in digits (like tag0, tag1 for planets) are formatted like (tag0_1, tag1_1), so we rstrip\n        underscores afterwards.\n        \"\"\"\n        if re.match('\\D\\d+$', tokens.keys()[0]):\n            # Produce a list of dictionaries\n            set_tokens = []\n            for key, value in tokens:\n                key = re.match('^(.+\\D)(\\d+)$', key)\n                # If the key isn't in the format (i.e. a failsafe), skip it\n                if key is not None:\n                    if key.group(1) not in set_tokens:\n                        set_tokens[key.group(1)] = {}\n\n                    set_tokens[key.group(1)][key.group(0).rstrip('_')] = value\n            tokens = set_tokens\n\n        return tokens"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_chain(self):\n        if not self._hasinit:\n            self._hasinit = True\n            self._devices = []\n\n            self.jtag_enable()\n            while True:\n                # pylint: disable=no-member\n                idcode = self.rw_dr(bitcount=32, read=True,\n                                    lastbit=False)()\n                if idcode in NULL_ID_CODES: break\n                dev = self.initialize_device_from_id(self, idcode)\n                if self._debug:\n                    print(dev)\n                self._devices.append(dev)\n                if len(self._devices) >= 128:\n                    raise JTAGTooManyDevicesError(\"This is an arbitrary \"\n                        \"limit to deal with breaking infinite loops. If \"\n                        \"you have more devices, please open a bug\")\n\n            self.jtag_disable()\n\n            #The chain comes out last first. Reverse it to get order.\n            self._devices.reverse()", "response": "Autodetect the devices attached to the Controller and initialize a JTAGDevice for each."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fitted_lv1_prim(self, reqef, bitcount):\n        res = self._fitted_lv1_prim_cache.get(reqef)\n        if res:\n            return res\n        prim = self.get_best_lv1_prim(reqef, bitcount)\n        dispatcher = PrimitiveLv1Dispatcher(self, prim, reqef)\n        self._fitted_lv1_prim_cache[reqef] = dispatcher\n        return dispatcher", "response": "Get the best matching PrimitiveLv1Dispatcher for the requested request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _UserUpdateConfigValue(self, configKey, strDescriptor, isDir = True, dbConfigValue = None):\n    newConfigValue = None\n\n    if dbConfigValue is None:\n      prompt = \"Enter new {0} or 'x' to exit: \".format(strDescriptor)\n    else:\n      prompt = \"Enter 'y' to use existing {0}, enter a new {0} or 'x' to exit: \".format(strDescriptor)\n\n    while newConfigValue is None:\n      response = goodlogging.Log.Input(\"CLEAR\", prompt)\n\n      if response.lower() == 'x':\n        sys.exit(0)\n      elif dbConfigValue is not None and response.lower() == 'y':\n        newConfigValue = dbConfigValue\n      elif not isDir:\n        newConfigValue = response\n        self._db.SetConfigValue(configKey, newConfigValue)\n      else:\n        if os.path.isdir(response):\n          newConfigValue = os.path.abspath(response)\n          self._db.SetConfigValue(configKey, newConfigValue)\n        else:\n          goodlogging.Log.Info(\"CLEAR\", \"{0} is not recognised as a directory\".format(response))\n\n    return newConfigValue", "response": "Update the config value for the given config field in the database table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the value of a given config field from database table.", "response": "def _GetConfigValue(self, configKey, strDescriptor, isDir = True):\n    \"\"\"\n    Get configuration value from database table. If no value found user\n    will be prompted to enter one.\n\n    Parameters\n    ----------\n      configKey : string\n        Name of config field.\n\n      strDescriptor : string\n        Description of config field.\n\n      isDir : boolean [optional : default = True]\n        Set to True if config value is\n        expected to be a directory path.\n\n    Returns\n    ----------\n      string\n        Value for given config field in database.\n    \"\"\"\n    goodlogging.Log.Info(\"CLEAR\", \"Loading {0} from database:\".format(strDescriptor))\n    goodlogging.Log.IncreaseIndent()\n    configValue = self._db.GetConfigValue(configKey)\n\n    if configValue is None:\n      goodlogging.Log.Info(\"CLEAR\", \"No {0} exists in database\".format(strDescriptor))\n      configValue = self._UserUpdateConfigValue(configKey, strDescriptor, isDir)\n    else:\n      goodlogging.Log.Info(\"CLEAR\", \"Got {0} {1} from database\".format(strDescriptor, configValue))\n\n\n    if not isDir or os.path.isdir(configValue):\n      goodlogging.Log.Info(\"CLEAR\", \"Using {0} {1}\".format(strDescriptor, configValue))\n      goodlogging.Log.DecreaseIndent()\n      return configValue\n    else:\n      goodlogging.Log.Info(\"CLEAR\", \"Exiting... {0} is not recognised as a directory\".format(configValue))\n      sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _UserUpdateSupportedFormats(self, origFormatList = []):\n    formatList = list(origFormatList)\n\n    inputDone = None\n    while inputDone is None:\n      prompt = \"Enter new format (e.g. .mp4, .avi), \" \\\n                             \"'r' to reset format list, \" \\\n                             \"'f' to finish or \" \\\n                             \"'x' to exit: \"\n      response = goodlogging.Log.Input(\"CLEAR\", prompt)\n\n      if response.lower() == 'x':\n        sys.exit(0)\n      elif response.lower() == 'f':\n        inputDone = 1\n      elif response.lower() == 'r':\n        formatList = []\n      else:\n        if response is not None:\n          if(response[0] != '.'):\n            response = '.' + response\n          formatList.append(response)\n\n    formatList = set(formatList)\n    origFormatList = set(origFormatList)\n\n    if formatList != origFormatList:\n      self._db.PurgeSupportedFormats()\n      for fileFormat in formatList:\n        self._db.AddSupportedFormat(fileFormat)\n\n    return formatList", "response": "User has selected a new format list and if they are not already present in the database then they will be purged and added to the database table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of supported formats from database table.", "response": "def _GetSupportedFormats(self):\n    \"\"\"\n    Get supported format values from database table. If no values found user\n    will be prompted to enter values for this table.\n\n    Returns\n    ----------\n      string\n        List of supported formats from database table.\n    \"\"\"\n    goodlogging.Log.Info(\"CLEAR\", \"Loading supported formats from database:\")\n    goodlogging.Log.IncreaseIndent()\n    formatList = self._db.GetSupportedFormats()\n\n    if formatList is None:\n      goodlogging.Log.Info(\"CLEAR\", \"No supported formats exist in database\")\n      formatList = self._UserUpdateSupportedFormats()\n    else:\n      goodlogging.Log.Info(\"CLEAR\", \"Got supported formats from database: {0}\".format(formatList))\n\n    goodlogging.Log.Info(\"CLEAR\", \"Using supported formats: {0}\".format(formatList))\n    goodlogging.Log.DecreaseIndent()\n    return formatList"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _UserUpdateIgnoredDirs(self, origIgnoredDirs = []):\n    ignoredDirs = list(origIgnoredDirs)\n\n    inputDone = None\n    while inputDone is None:\n      prompt = \"Enter new directory to ignore (e.g. DONE), \" \\\n                           \"'r' to reset directory list, \" \\\n                           \"'f' to finish or \" \\\n                           \"'x' to exit: \"\n      response = goodlogging.Log.Input(\"CLEAR\", prompt)\n\n      if response.lower() == 'x':\n        sys.exit(0)\n      elif response.lower() == 'f':\n        inputDone = 1\n      elif response.lower() == 'r':\n        ignoredDirs = []\n      else:\n        if response is not None:\n          ignoredDirs.append(response)\n\n    ignoredDirs = set(ignoredDirs)\n    origIgnoredDirs = set(origIgnoredDirs)\n\n    if ignoredDirs != origIgnoredDirs:\n      self._db.PurgeIgnoredDirs()\n      for ignoredDir in ignoredDirs:\n        self._db.AddIgnoredDir(ignoredDir)\n\n    return list(ignoredDirs)", "response": "User wants to add ignored directories to the database table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetIgnoredDirs(self):\n    goodlogging.Log.Info(\"CLEAR\", \"Loading ignored directories from database:\")\n    goodlogging.Log.IncreaseIndent()\n    ignoredDirs = self._db.GetIgnoredDirs()\n\n    if ignoredDirs is None:\n      goodlogging.Log.Info(\"CLEAR\", \"No ignored directories exist in database\")\n      ignoredDirs = self._UserUpdateIgnoredDirs()\n    else:\n      goodlogging.Log.Info(\"CLEAR\", \"Got ignored directories from database: {0}\".format(ignoredDirs))\n\n    if self._archiveDir not in ignoredDirs:\n      ignoredDirs.append(self._archiveDir)\n\n    goodlogging.Log.Info(\"CLEAR\", \"Using ignored directories: {0}\".format(ignoredDirs))\n    goodlogging.Log.DecreaseIndent()\n    return ignoredDirs", "response": "Get ignored directories from database table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving all configuration variables from the database.", "response": "def _GetDatabaseConfig(self):\n    \"\"\"\n    Get all configuration from database.\n\n    This includes values from the Config table as well as populating lists\n    for supported formats and ignored directories from their respective\n    database tables.\n    \"\"\"\n    goodlogging.Log.Seperator()\n    goodlogging.Log.Info(\"CLEAR\", \"Getting configuration variables...\")\n    goodlogging.Log.IncreaseIndent()\n\n    # SOURCE DIRECTORY\n    if self._sourceDir is None:\n      self._sourceDir = self._GetConfigValue('SourceDir', 'source directory')\n\n    # TV DIRECTORY\n    if self._inPlaceRename is False and self._tvDir is None:\n      self._tvDir = self._GetConfigValue('TVDir', 'tv directory')\n\n    # ARCHIVE DIRECTORY\n    self._archiveDir = self._GetConfigValue('ArchiveDir', 'archive directory', isDir = False)\n\n    # SUPPORTED FILE FORMATS\n    self._supportedFormatsList = self._GetSupportedFormats()\n\n    # IGNORED DIRECTORIES\n    self._ignoredDirsList = self._GetIgnoredDirs()\n\n    goodlogging.Log.NewLine()\n    goodlogging.Log.Info(\"CLEAR\", \"Configuation is:\")\n    goodlogging.Log.IncreaseIndent()\n    goodlogging.Log.Info(\"CLEAR\", \"Source directory = {0}\".format(self._sourceDir))\n    goodlogging.Log.Info(\"CLEAR\", \"TV directory = {0}\".format(self._tvDir))\n    goodlogging.Log.Info(\"CLEAR\", \"Supported formats = {0}\".format(self._supportedFormatsList))\n    goodlogging.Log.Info(\"CLEAR\", \"Ignored directory list = {0}\".format(self._ignoredDirsList))\n    goodlogging.Log.ResetIndent()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetArgs(self):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-s', '--src', help='override database source directory')\n    parser.add_argument('-d', '--dst', help='override database destination directory')\n\n    parser.add_argument('-e', '--extract', help='enable extracting of rar files', action=\"store_true\")\n\n    parser.add_argument('-c', '--copy', help='enable copying between file systems', action=\"store_true\")\n    parser.add_argument('-i', '--inplace', help='rename files in place', action=\"store_true\")\n\n    parser.add_argument('-u', '--update_db', help='provides option to update existing database fields', action=\"store_true\")\n    parser.add_argument('-p', '--print_db', help='print contents of database', action=\"store_true\")\n\n    parser.add_argument('-n', '--no_input', help='automatically accept or skip all user input', action=\"store_true\")\n    parser.add_argument('-nr', '--no_input_rename', help='automatically accept or skip user input for guide lookup and rename', action=\"store_true\")\n    parser.add_argument('-ne', '--no_input_extract', help='automatically accept or skip user input for extraction', action=\"store_true\")\n\n    parser.add_argument('--debug', help='enable full logging', action=\"store_true\")\n    parser.add_argument('--tags', help='enable tags on log info', action=\"store_true\")\n\n    parser.add_argument('--test', help='run with test database', action=\"store_true\")\n    parser.add_argument('--reset', help='resets database', action=\"store_true\")\n\n    args = parser.parse_args()\n\n    if args.test:\n      self._databasePath = 'test.db'\n\n    if args.no_input or args.no_input_rename:\n      self._skipUserInputRename = True\n\n    if args.no_input or args.no_input_extract:\n      self._skipUserInputExtract = True\n\n    if args.reset:\n      goodlogging.Log.Info(\"CLEAR\", \"*WARNING* YOU ARE ABOUT TO DELETE DATABASE {0}\".format(self._databasePath))\n      response = goodlogging.Log.Input(\"CLEAR\", \"Are you sure you want to proceed [y/n]? \")\n      if response.lower() == 'y':\n        if(os.path.isfile(self._databasePath)):\n          os.remove(self._databasePath)\n      else:\n        sys.exit(0)\n\n    if args.inplace:\n      self._inPlaceRename = True\n\n    if args.copy:\n      self._crossSystemCopyEnabled = True\n\n    if args.tags:\n      goodlogging.Log.tagsEnabled = 1\n\n    if args.debug:\n      goodlogging.Log.verbosityThreshold = goodlogging.Verbosity.MINIMAL\n\n    if args.update_db:\n      self._dbUpdate = True\n\n    if args.print_db:\n      self._dbPrint = True\n\n    if args.extract:\n      self._enableExtract = True\n\n    if args.src:\n      if os.path.isdir(args.src):\n        self._sourceDir = args.src\n      else:\n        goodlogging.Log.Fatal(\"CLEAR\", 'Source directory argument is not recognised as a directory: {}'.format(args.src))\n\n    if args.dst:\n      if os.path.isdir(args.dst):\n        self._tvDir = args.dst\n      else:\n        goodlogging.Log.Fatal(\"CLEAR\", 'Target directory argument is not recognised as a directory: {}'.format(args.dst))", "response": "Parse command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _GetSupportedFilesInDir(self, fileDir, fileList, supportedFormatList, ignoreDirList):\n    goodlogging.Log.Info(\"CLEAR\", \"Parsing file directory: {0}\".format(fileDir))\n    if os.path.isdir(fileDir) is True:\n      for globPath in glob.glob(os.path.join(fileDir, '*')):\n        if util.FileExtensionMatch(globPath, supportedFormatList):\n          newFile = tvfile.TVFile(globPath)\n          if newFile.GetShowDetails():\n            fileList.append(newFile)\n        elif os.path.isdir(globPath):\n          if(os.path.basename(globPath) in ignoreDirList):\n            goodlogging.Log.Info(\"CLEAR\", \"Skipping ignored directory: {0}\".format(globPath))\n          else:\n            self._GetSupportedFilesInDir(globPath, fileList, supportedFormatList, ignoreDirList)\n        else:\n          goodlogging.Log.Info(\"CLEAR\", \"Ignoring unsupported file or folder: {0}\".format(globPath))\n    else:\n      goodlogging.Log.Info(\"CLEAR\", \"Invalid non-directory path given to parse\")", "response": "Recursively gets all supported files in a given directory tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Run(self):\n    self._GetArgs()\n\n    goodlogging.Log.Info(\"CLEAR\", \"Using database: {0}\".format(self._databasePath))\n    self._db = database.RenamerDB(self._databasePath)\n\n    if self._dbPrint or self._dbUpdate:\n      goodlogging.Log.Seperator()\n      self._db.PrintAllTables()\n\n      if self._dbUpdate:\n        goodlogging.Log.Seperator()\n        self._db.ManualUpdateTables()\n\n    self._GetDatabaseConfig()\n\n    if self._enableExtract:\n      goodlogging.Log.Seperator()\n\n      extractFileList = []\n      goodlogging.Log.Info(\"CLEAR\", \"Parsing source directory for compressed files\")\n      goodlogging.Log.IncreaseIndent()\n      extract.GetCompressedFilesInDir(self._sourceDir, extractFileList, self._ignoredDirsList)\n      goodlogging.Log.DecreaseIndent()\n\n      goodlogging.Log.Seperator()\n      extract.Extract(extractFileList, self._supportedFormatsList, self._archiveDir, self._skipUserInputExtract)\n\n    goodlogging.Log.Seperator()\n\n    tvFileList = []\n    goodlogging.Log.Info(\"CLEAR\", \"Parsing source directory for compatible files\")\n    goodlogging.Log.IncreaseIndent()\n    self._GetSupportedFilesInDir(self._sourceDir, tvFileList, self._supportedFormatsList, self._ignoredDirsList)\n    goodlogging.Log.DecreaseIndent()\n\n    tvRenamer = renamer.TVRenamer(self._db,\n                                  tvFileList,\n                                  self._archiveDir,\n                                  guideName = 'EPGUIDES',\n                                  tvDir = self._tvDir,\n                                  inPlaceRename = self._inPlaceRename,\n                                  forceCopy = self._crossSystemCopyEnabled,\n                                  skipUserInput = self._skipUserInputRename)\n    tvRenamer.Run()", "response": "Main entry point for ClearManager class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(ctx, amount, index, stage):\n    if not ctx.bubble:\n        ctx.say_yellow('There is no bubble present, will not transform')\n        raise click.Abort()\n\n    path = ctx.home + '/'\n\n    STAGE = None\n    RULES = None\n    UNIQ_KEYS_PULL = None\n    UNIQ_KEYS_PUSH = None\n    CLEAN_MISSING_AFTER_SECONDS = None\n    if stage in STAGES and stage in ctx.cfg.CFG:\n        STAGE = ctx.cfg.CFG[stage]\n    if not STAGE:\n        ctx.say_red('There is no STAGE in CFG:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n        ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n    if 'TRANSFORM' in STAGE:\n         TRANSFORM = ctx.cfg.CFG[stage].TRANSFORM\n    else:\n         ctx.say_yellow(\"\"\"There is no transform defined in the configuration, will not transform,\nwhen pushing the results of step 'pulled' will be read instead of 'push'\n\"\"\")\n         raise click.Abort()\n\n    if 'RULES' in TRANSFORM:\n        RULES = TRANSFORM.RULES\n    if 'UNIQ_KEYS_PULL' in TRANSFORM:\n        UNIQ_KEYS_PULL = TRANSFORM.UNIQ_KEYS_PULL\n    if 'UNIQ_KEYS_PUSH' in TRANSFORM:\n        UNIQ_KEYS_PUSH = TRANSFORM.UNIQ_KEYS_PUSH\n    if 'CLEAN_MISSING_AFTER_SECONDS' in TRANSFORM:\n        CLEAN_MISSING_AFTER_SECONDS = TRANSFORM.CLEAN_MISSING_AFTER_SECONDS\n\n    if not RULES:\n        ctx.say_red('There is no TRANSFORM.RULES in stage:' + stage)\n        ctx.say_yellow('please check configuration in ' +\n                       ctx.home + '/config/config.yaml')\n        raise click.Abort()\n\n    full_data = False\n    if amount == -1 and index == -1:\n        full_data = True\n\n    data_gen = bubble_lod_load(ctx, 'store', stage)\n    stored_data = {}\n    for stored_data_item in data_gen:\n        stored_data = stored_data_item\n        break  # first_only\n\n    ctx.gbc.say('stored:', stuff=stored_data, verbosity=150)\n\n    cfgdict = {}\n    cfgdict['CFG'] = ctx.cfg.CFG\n    cfgdict['GENERAL_BUBBLE_CONTEXT'] = ctx.GLOBALS['gbc']\n    cfgdict['ARGS'] = {'stage': stage,\n                       'path': path}\n\n    if type(RULES) == str and RULES.endswith('.bubble'):\n        rules = get_bubble(ctx.gbc, path + RULES)\n        rule_type = 'bubble'\n        transformer = Transformer(rules=rules,\n                                  rule_type=rule_type,\n                                  store=stored_data,\n                                  config=cfgdict,\n                                  bubble_path=path,\n                                  verbose=ctx.get_verbose())\n\n    src_data = bubble_lod_load(ctx, 'pulled', stage)\n\n    to_transform = get_gen_slice(ctx.gbc, src_data, amount, index)\n    ctx.gbc.say('sliced to transform:', stuff=to_transform, verbosity=50)\n\n    if UNIQ_KEYS_PULL:\n        to_transform = make_uniq_for_step(ctx=ctx,\n                                          ukeys=UNIQ_KEYS_PULL,\n                                          step='uniq_pull',\n                                          stage=stage,\n                                          full_data=full_data,\n                                          clean_missing_after_seconds=CLEAN_MISSING_AFTER_SECONDS,\n                                          to_uniq=to_transform)\n\n    ctx.gbc.say('transformer to transform', stuff=to_transform, verbosity=295)\n\n    transformed_count = Counter()\n\n    error_count = Counter()\n    result = do_yielding_transform(ctx,\n                                   transformer,\n                                   to_transform,\n                                   transformed_count,\n                                   error_count)\n\n    ##########################################################################\n    pfr = bubble_lod_dump(ctx=ctx,\n                          step='push',\n                          stage=stage,\n                          full_data=full_data,\n                          reset=True,\n                          data_gen=result)\n    ctx.say('transformed [%d] objects' % pfr['total'])\n\n    # closing the store, to be sure, get store after yielding transform has\n    # completed\n    store = transformer.get_store()\n    ctx.gbc.say('transformer persistant storage', stuff=store, verbosity=1000)\n\n    pfr = bubble_lod_dump(ctx=ctx,\n                          step='store',\n                          stage=stage,\n                          full_data=full_data,\n                          reset=True,\n                          data_gen=[store])\n    ctx.say('pulled [%d] objects' % pfr['total'])\n    ctx.gbc.say('transformer all done :transformed_count:%d,error_count:%d' %\n                (transformed_count.get_total(), error_count.get_total()),\n                verbosity=10)\n\n    if UNIQ_KEYS_PUSH:\n        make_uniq_for_step(ctx=ctx,\n                           ukeys=UNIQ_KEYS_PUSH,\n                           step='uniq_push',\n                           stage=stage,\n                           full_data=full_data,\n                           clean_missing_after_seconds=CLEAN_MISSING_AFTER_SECONDS,\n                           to_uniq=result)\n        # TODO: check if to_uniq can be loaded inside make_uniq\n        # the result of the transform is a generator and should be 'empty' already\n        # by the previous dump of the results.\n\n    stats = {}\n    stats['transformed_stat_error_count'] = error_count.get_total()\n    stats['transformed_stat_transformed_count'] = transformed_count.get_total()\n\n    update_stats(ctx, stage, stats)\n\n    return True", "response": "Get the transform data for a specific stage"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _merge_prims(prims, *, debug=False, stagenames=None, stages=None):\n    if isinstance(prims, FrameSequence):\n        merged_prims = FrameSequence(prims._chain)\n    else:\n        merged_prims = []\n    working_prim = prims[0]\n    i = 1\n    logging_tmp = []\n\n    while i < len(prims):\n        tmp = prims[i]\n        res = working_prim.merge(tmp)\n        if res is not None:\n            working_prim = res\n            if debug:#pragma: no cover\n                logging_tmp.append(\n                    [p.snapshot() for p in\n                     merged_prims+[working_prim]])\n        else:\n            merged_prims.append(working_prim)\n            working_prim = tmp\n        i += 1\n    merged_prims.append(working_prim)\n    if debug:#pragma: no cover\n        stages.append(logging_tmp)\n        stagenames.append(\"Merge intermediate states\")\n\n    return merged_prims", "response": "Helper method to greedily combine the prims or Frames into a single list of Primitives or Frames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compile_device_specific_prims(self, debug=False,\n                                       stages=None, stagenames=None):\n        \"\"\"Using the data stored in the CommandQueue, Extract and align compatible sequences of Primitives and compile/optimize the Primitives down into a stream of Level 2 device agnostic primitives.\n\n        BACKGROUND:\n        Device Specific primitives present a special opportunity for\n        optimization. Many JTAG systems program one device on the\n        chain at a time. But because all devices on a JTAG chain are\n        sent information at once, NO-OP instructions are sent to these\n        other devices.\n\n        When programming multiple devices, Sending these NO-OPS is a\n        missed opportunity for optimization. Instead of configuring\n        one device at a time, it is more efficient to collect\n        instructions for all deices, and align them so multiple\n        devices can be configured at the same time.\n\n        WAT THIS METHOD DOES:\n        This method takes in a list of Primitives, groups the device\n        specific primitives by target device, aligns the sequences of\n        device instructions, and expands the aligned sequences into a\n        flat list of device agnostic primitives.\n\n        Args:\n            debug: A boolean for if debug information should be generated.\n            stages: A list to be edited by this method to store snapshots of the compilation state. Used if debug is True.\n            stagenames: A list of strings describing each debug snapshot of the compiilation process. Used if debug is True.\n\n        \"\"\"\n        ############### GROUPING BY EXEC BOUNDARIES!################\n\n        fences = []\n        fence = [self[0]]\n        for p in self[1:]:\n            if type(fence[0])._layer == type(p)._layer and\\\n               isinstance(fence[0], DeviceTarget) == \\\n                  isinstance(p, DeviceTarget):\n                fence.append(p)\n            else:\n                fences.append(fence)\n                fence = [p]\n        fences.append(fence)\n\n        if debug: #pragma: no cover\n            formatted_fences = []\n            for fence in fences:\n                formatted_fence = [p.snapshot() for p in fence]\n                formatted_fences.append(formatted_fence)\n                formatted_fences.append([])\n            stages.append(formatted_fences[:-1]) #Ignore trailing []\n            stagenames.append(\"Fencing off execution boundaries\")\n\n        ############## SPLIT GROUPS BY DEVICE TARGET! ##############\n\n        split_fences = []\n        for fence in fences:\n            tmp_chains = {}\n            for p in fence:\n                k = p._device_index \\\n                    if isinstance(p, DeviceTarget) else \"chain\"\n                subchain = tmp_chains.setdefault(k, []).append(p)\n            split_fences.append(list(tmp_chains.values()))\n\n        if debug:#pragma: no cover\n            formatted_split_fences = []\n            for fence in split_fences:\n                for group in fence:\n                    formatted_split_fences.append([p.snapshot()\n                                                   for p in group])\n                formatted_split_fences.append([])\n            stages.append(formatted_split_fences[:-1])\n            stagenames.append(\"Grouping prims of each boundary by \"\n                              \"target device\")\n\n        ############## ALIGN SEQUENCES AND PAD FRAMES ##############\n        #FIRST DEV REQUIRED LINE\n        grouped_fences = [\n            FrameSequence(self._chain, *fence).finalize()\n            for f_i, fence in enumerate(split_fences)\n        ]\n\n        if debug:#pragma: no cover\n            formatted_grouped_fences = []\n            for fence in grouped_fences:\n                formatted_grouped_fences += fence.snapshot() + [[]]\n            stages.append(formatted_grouped_fences[:-1])\n            stagenames.append(\"Aligning and combining each group dev \"\n                              \"prim stream\")\n\n        ################## RECOMBINE FRAME GROUPS ##################\n\n        ingested_chain = grouped_fences[0]\n        for fence in grouped_fences[1:]:\n            ingested_chain += fence\n\n        if debug:#pragma: no cover\n            stages.append(ingested_chain.snapshot())\n            stagenames.append(\"Recombining sanitized exec boundaries\")\n\n        ###################### POST INGESTION ######################\n        ################ Flatten out LV3 Primitives ################\n        while(any((f._layer == 3 for f in ingested_chain))):\n            ################# COMBINE COMPATIBLE PRIMS #################\n            ingested_chain = _merge_prims(ingested_chain)\n\n            if debug:#pragma: no cover\n                stages.append(ingested_chain.snapshot())\n                stagenames.append(\"Combining compatible lv3 prims.\")\n\n            ################ TRANSLATION TO LOWER LAYER ################\n            sm = JTAGStateMachine(self._chain._sm.state)\n            expanded_prims = FrameSequence(self._chain)\n            for f in ingested_chain:\n                if f._layer == 3:\n                    expanded_prims += f.expand_macro(sm)\n                else:\n                    expanded_prims.append(f)\n            expanded_prims.finalize()\n            ingested_chain = expanded_prims\n\n            if self._fsm is None:\n                self._fsm = sm\n            assert self._fsm == sm, \"Target %s != Actual %s\"%\\\n                (self._fsm.state, sm.state)\n\n            if debug:#pragma: no cover\n                stages.append(ingested_chain.snapshot())\n                stagenames.append(\"Expanding lv3 prims\")\n\n\n        ############## Flatten out Dev LV2 Primitives ##############\n        while(any((isinstance(f._valid_prim, DeviceTarget)\n                   for f in ingested_chain))):\n            ################# COMBINE COMPATIBLE PRIMS #################\n            ingested_chain = _merge_prims(ingested_chain)\n\n            if debug:#pragma: no cover\n                stages.append(ingested_chain.snapshot())\n                stagenames.append(\"Merging Device Specific Prims\")\n\n            ################ TRANSLATION TO LOWER LAYER ################\n\n            sm = JTAGStateMachine(self._chain._sm.state)\n            expanded_prims = FrameSequence(self._chain)\n            for f in ingested_chain:\n                if issubclass(f._prim_type, DeviceTarget):\n                    expanded_prims += f.expand_macro(sm)\n                else:\n                    f[0].apply_tap_effect(sm)\n                    expanded_prims.append(f)\n            expanded_prims.finalize()\n            ingested_chain = expanded_prims\n            if self._fsm is None:\n                self._fsm = sm\n            assert self._fsm == sm, \"Target %s != Actual %s\"%\\\n                 (self._fsm.state, sm.state)\n\n            if debug:#pragma: no cover\n                stages.append(ingested_chain.snapshot())\n                stagenames.append(\"Expanding Device Specific Prims\")\n\n        ############ Convert FrameSequence to flat array ###########\n        flattened_prims = [f._valid_prim for f in ingested_chain]\n        if debug:#pragma: no cover\n            stages.append([[p.snapshot() for p in flattened_prims]])\n            stagenames.append(\"Converting format to single stream.\")\n\n        return flattened_prims", "response": "This method extracts and aligns compatible sequences of Primitives and compiles them into a flat list of device agnostic primitives."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flush(self):\n        self.stages = []\n        self.stagenames = []\n\n        if not self.queue:\n            return\n\n        if self.print_statistics:#pragma: no cover\n            print(\"LEN OF QUENE\", len(self))\n            t = time()\n\n        if self._chain._collect_compiler_artifacts:\n            self._compile(debug=True, stages=self.stages,\n                          stagenames=self.stagenames)\n        else:\n            self._compile()\n\n        if self.debug:\n            print(\"ABOUT TO EXEC\", self.queue)#pragma: no cover\n\n        if self.print_statistics:#pragma: no cover\n            print(\"COMPILE TIME\", time()-t)\n            print(\"TOTAL BITS OF ALL PRIMS\", sum(\n                (p.count for p in self.queue if hasattr(p, 'count'))))\n            t = time()\n\n        self._chain._controller._execute_primitives(self.queue)\n\n        if self.print_statistics:\n            print(\"EXECUTE TIME\", time()-t)#pragma: no cover\n\n        self.queue = []\n        self._chain._sm.state = self._fsm.state", "response": "Force the queue of Primitives to compile execute on the Controller and fulfill promises with the data returned."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninvoke the Server health endpoint", "response": "def Ping(self, request, context):\n        \"\"\"\n        Invoke the Server health endpoint\n        :param request: Empty\n        :param context: the request context\n        :return: Status message 'alive'\n        \"\"\"\n        status =  processor_pb2.Status()\n        status.message='alive'\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the request and return the response.", "response": "def Process(self, request, context):\n        \"\"\"\n        Invoke the Grpc Processor, delegating to the handler_function. If the handler_function has a single argument,\n        pass the Message payload. If two arguments, pass the payload and headers as positional arguments:\n        handler_function(payload, headers). If the handler function return is not of type(Message), create a new Message using\n        the original header values (new id and timestamp).\n\n        :param request: the message\n        :param context: the request context\n        :return: response message\n        \"\"\"\n        logger.debug(request)\n        message = Message.__from_protobuf_message__(request)\n        sig = getfullargspec(self.handler_function)\n        if len(sig.args) == 2:\n            result = self.handler_function(message.payload, message.headers)\n        elif len(sig.args) == 1:\n            result = self.handler_function(message.payload)\n        else:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details('wrong number of arguments for handler function - must be 1 or 2')\n            raise RuntimeError('wrong number of arguments for handler function - must be 1 or 2')\n\n        if self.component_type == StreamComponent.PROCESSOR:\n            if type(result) == Message:\n                return result.__to_protobuf_message__()\n            else:\n                headers = MessageHeaders()\n                headers.copy(message.headers)\n                return Message(result, headers).__to_protobuf_message__()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompare text as written to the log output", "response": "def step_impl(context):\n    \"\"\"Compares text as written to the log output\"\"\"\n    expected_lines = context.text.split('\\n')\n    assert len(expected_lines) == len(context.output)\n    for expected, actual in zip(expected_lines, context.output):\n        print('--\\n\\texpected: {}\\n\\tactual: {}'.format(expected, actual))\n        assert expected == actual"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the EPGUIDES allshows csv file and sets self. _showTitleList and self. _showIDList.", "response": "def _ParseShowList(self, checkOnly=False):\n    \"\"\"\n    Read self._allShowList as csv file and make list of titles and IDs.\n\n    Parameters\n    ----------\n      checkOnly : boolean [optional : default = False]\n          If checkOnly is True this will only check to ensure the column\n          headers can be extracted correctly.\n    \"\"\"\n    showTitleList = []\n    showIDList = []\n\n    csvReader = csv.reader(self._allShowList.splitlines())\n    for rowCnt, row in enumerate(csvReader):\n      if rowCnt == 0:\n        # Get header column index\n        for colCnt, column in enumerate(row):\n          if column == 'title':\n            titleIndex = colCnt\n          if column == self.ID_LOOKUP_TAG:\n            lookupIndex = colCnt\n      else:\n        try:\n          showTitleList.append(row[titleIndex])\n          showIDList.append(row[lookupIndex])\n        except UnboundLocalError:\n          goodlogging.Log.Fatal(\"EPGUIDE\", \"Error detected in EPGUIDES allshows csv content\")\n        else:\n          if checkOnly and rowCnt > 1:\n            return True\n    self._showTitleList = showTitleList\n    self._showIDList = showIDList\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetAllShowList(self):\n    today = datetime.date.today().strftime(\"%Y%m%d\")\n    saveFile = '_epguides_' + today + '.csv'\n    saveFilePath = os.path.join(self._saveDir, saveFile)\n    if os.path.exists(saveFilePath):\n      # Load data previous saved to file\n      with open(saveFilePath, 'r') as allShowsFile:\n        self._allShowList = allShowsFile.read()\n    else:\n      # Download new list from EPGUIDES and strip any leading or trailing whitespace\n      self._allShowList = util.WebLookup(self.ALLSHOW_IDLIST_URL).strip()\n\n      if self._ParseShowList(checkOnly=True):\n        # Save to file to avoid multiple url requests in same day\n        with open(saveFilePath, 'w') as allShowsFile:\n          goodlogging.Log.Info(\"EPGUIDE\", \"Adding new EPGUIDES file: {0}\".format(saveFilePath), verbosity=self.logVerbosity)\n          allShowsFile.write(self._allShowList)\n\n        # Delete old copies of this file\n        globPattern = '_epguides_????????.csv'\n        globFilePath = os.path.join(self._saveDir, globPattern)\n        for filePath in glob.glob(globFilePath):\n          if filePath != saveFilePath:\n            goodlogging.Log.Info(\"EPGUIDE\", \"Removing old EPGUIDES file: {0}\".format(filePath), verbosity=self.logVerbosity)\n            os.remove(filePath)", "response": "Reads and parses the EPGUIDES all show list from the server and stores it in self. _allShowList."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetShowID(self, showName):\n    self._GetTitleList()\n    self._GetIDList()\n\n    for index, showTitle in enumerate(self._showTitleList):\n      if showName == showTitle:\n        return self._showIDList[index]\n    return None", "response": "Returns the show id for a given show name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting csv show data from epguides html source.", "response": "def _ExtractDataFromShowHtml(self, html):\n    \"\"\"\n    Extracts csv show data from epguides html source.\n\n    Parameters\n    ----------\n      html : string\n        Block of html text\n\n    Returns\n    ----------\n       string\n        Show data extracted from html text in csv format.\n    \"\"\"\n    htmlLines = html.splitlines()\n    for count, line in enumerate(htmlLines):\n      if line.strip() == r'<pre>':\n        startLine = count+1\n      if line.strip() == r'</pre>':\n        endLine = count\n\n    try:\n      dataList = htmlLines[startLine:endLine]\n      dataString = '\\n'.join(dataList)\n      return dataString.strip()\n    except:\n      raise Exception(\"Show content not found - check EPGuides html formatting\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetEpisodeName(self, showID, season, episode):\n    # Load data for showID from dictionary\n    showInfo = csv.reader(self._showInfoDict[showID].splitlines())\n    for rowCnt, row in enumerate(showInfo):\n      if rowCnt == 0:\n        # Get header column index\n        for colCnt, column in enumerate(row):\n          if column == 'season':\n            seasonIndex = colCnt\n          if column == 'episode':\n            episodeIndex = colCnt\n          if column == 'title':\n            titleIndex = colCnt\n      else:\n        # Iterate rows until matching season and episode found\n        try:\n          int(row[seasonIndex])\n          int(row[episodeIndex])\n        except ValueError:\n          # Skip rows which don't provide integer season or episode numbers\n          pass\n        else:\n          if int(row[seasonIndex]) == int(season) and int(row[episodeIndex]) == int(episode):\n            goodlogging.Log.Info(\"EPGUIDE\", \"Episode name is {0}\".format(row[titleIndex]), verbosity=self.logVerbosity)\n            return row[titleIndex]\n    return None", "response": "Get episode name from epguides show info."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ShowNameLookUp(self, string):\n    goodlogging.Log.Info(\"EPGUIDES\", \"Looking up show name match for string '{0}' in guide\".format(string), verbosity=self.logVerbosity)\n    self._GetTitleList()\n    showName = util.GetBestMatch(string, self._showTitleList)\n    return(showName)", "response": "This function will look up the best match for the given string in the epguides show titles."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef EpisodeNameLookUp(self, showName, season, episode):\n    goodlogging.Log.Info(\"EPGUIDE\", \"Looking up episode name for {0} S{1}E{2}\".format(showName, season, episode), verbosity=self.logVerbosity)\n    goodlogging.Log.IncreaseIndent()\n    showID = self._GetShowID(showName)\n    if showID is not None:\n      try:\n        self._showInfoDict[showID]\n      except KeyError:\n        goodlogging.Log.Info(\"EPGUIDE\", \"Looking up info for new show: {0}(ID:{1})\".format(showName, showID), verbosity=self.logVerbosity)\n        urlData = util.WebLookup(self.EPISODE_LOOKUP_URL, {self.EP_LOOKUP_TAG: showID})\n        self._showInfoDict[showID] = self._ExtractDataFromShowHtml(urlData)\n      else:\n        goodlogging.Log.Info(\"EPGUIDE\", \"Reusing show info previous obtained for: {0}({1})\".format(showName, showID), verbosity=self.logVerbosity)\n      finally:\n        episodeName = self._GetEpisodeName(showID, season, episode)\n        goodlogging.Log.DecreaseIndent()\n        return episodeName\n    goodlogging.Log.DecreaseIndent()", "response": "Look up the episode name corresponding to the given show name season number and episode number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncloning an existing bare repository to a new bare repository.", "response": "def clone(cls, srcpath, destpath):\n        \"\"\"Clone an existing repository to a new bare repository.\"\"\"\n        # Mercurial will not create intermediate directories for clones.\n        try:\n            os.makedirs(destpath)\n        except OSError as e:\n            if not e.errno == errno.EEXIST:\n                raise\n        cmd = [HG, 'clone', '--quiet', '--noupdate', srcpath, destpath]\n        subprocess.check_call(cmd)\n        return cls(destpath)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new repository", "response": "def create(cls, path):\n        \"\"\"Create a new repository\"\"\"\n        cmd = [HG, 'init', path]\n        subprocess.check_call(cmd)\n        return cls(path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef private_path(self):\n        path = os.path.join(self.path, '.hg', '.private')\n        try:\n            os.mkdir(path)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        return path", "response": "Get the path to a directory which can be used to store arbitrary data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets list of bookmarks", "response": "def bookmarks(self):\n        \"\"\"Get list of bookmarks\"\"\"\n        cmd = [HG, 'bookmarks']\n        output = self._command(cmd).decode(self.encoding, 'replace')\n        if output.startswith('no bookmarks set'):\n            return []\n        results = []\n        for line in output.splitlines():\n            m = bookmarks_rx.match(line)\n            assert m, 'unexpected output: ' + line\n            results.append(m.group('name'))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef content(self):\n        if not self._content:\n\n            self._content = self._read()\n\n        return self._content", "response": "Get the contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a Configuration object from the file contents.", "response": "def config(self):\n        \"\"\"Get a Configuration object from the file contents.\"\"\"\n        conf = config.Configuration()\n        for namespace in self.namespaces:\n\n            if not hasattr(conf, namespace):\n\n                if not self._strict:\n\n                    continue\n\n                raise exc.NamespaceNotRegistered(\n                    \"The namespace {0} is not registered.\".format(namespace)\n                )\n\n            name = getattr(conf, namespace)\n\n            for item, value in compat.iteritems(self.items(namespace)):\n\n                if not hasattr(name, item):\n\n                    if not self._strict:\n\n                        continue\n\n                    raise exc.OptionNotRegistered(\n                        \"The option {0} is not registered.\".format(item)\n                    )\n\n                setattr(name, item, value)\n\n        return conf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read(self):\n        with open(self.path, 'r') as file_handle:\n\n            content = file_handle.read()\n\n        # Py27 INI config parser chokes if the content provided is not unicode.\n        # All other versions seems to work appropriately. Forcing the value to\n        # unicode here in order to resolve this issue.\n        return compat.unicode(content)", "response": "Open the file and return its contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def ask(self, body, quick_replies=None, options=None, user=None):\n        await self.send_text_message_to_all_interfaces(\n            recipient=user,\n            text=body,\n            quick_replies=quick_replies,\n            options=options,\n        )\n        return any.Any()", "response": "simple ask with predefined quick replies\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsay something to user", "response": "async def say(self, body, user, options):\n        \"\"\"\n        say something to user\n\n        :param body:\n        :param user:\n        :return:\n        \"\"\"\n        return await self.send_text_message_to_all_interfaces(\n            recipient=user, text=body, options=options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def send_audio(self, url, user, options=None):\n        tasks = [interface.send_audio(user, url, options) for _, interface in self.interfaces.items()]\n        return [body for body in await asyncio.gather(*tasks)]", "response": "send audio message\n\n        :param url: link to the audio file\n        :param user: target user\n        :param options:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a text message to all interfaces.", "response": "async def send_text_message_to_all_interfaces(self, *args, **kwargs):\n        \"\"\"\n        TODO:\n        we should know from where user has come and use right interface\n        as well right interface can be chosen\n\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        logger.debug('async_send_text_message_to_all_interfaces')\n        tasks = [interface.send_text_message(*args, **kwargs)\n                 for _, interface in self.interfaces.items()]\n\n        logger.debug('  tasks')\n        logger.debug(tasks)\n\n        res = [body for body in await asyncio.gather(*tasks)]\n        logger.debug('  res')\n        logger.debug(res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(self, protocolFactory):\n        deferred = self._startProcess()\n        deferred.addCallback(self._connectRelay, protocolFactory)\n        deferred.addCallback(self._startRelay)\n        return deferred", "response": "Starts a process and connects a protocol to it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the relay process.", "response": "def _startProcess(self):\n        \"\"\"Use the inductor to start the process we want to relay data from.\n        \"\"\"\n        connectedDeferred = defer.Deferred()\n        processProtocol = RelayProcessProtocol(connectedDeferred)\n        self.inductor.execute(processProtocol, *self.inductorArgs)\n        return connectedDeferred"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect the protocol we want to relay to the process.", "response": "def _connectRelay(self, process, protocolFactory):\n        \"\"\"Set up and connect the protocol we want to relay to the process.\n        This method is automatically called when the process is started,\n        and we are ready to relay through it.\n        \"\"\"\n        try:\n            wf = _WrappingFactory(protocolFactory)\n            connector = RelayConnector(process, wf, self.timeout,\n                                       self.inductor.reactor)\n            connector.connect()\n        except:\n            return defer.fail()\n        # Return a deferred that is called back when the protocol is connected.\n        return wf._onConnection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _startRelay(self, client):\n        process = client.transport.connector.process\n        # Relay any buffered data that was received from the process before\n        # we got connected and started relaying.\n        for _, data in process.data:\n            client.dataReceived(data)\n        process.protocol = client\n\n        @process._endedDeferred.addBoth\n        def stopRelay(reason):\n            \"\"\"Stop relaying data. Called when the process has ended.\n            \"\"\"\n            relay = client.transport\n            relay.loseConnection(reason)\n            connector = relay.connector\n            connector.connectionLost(reason)\n\n        # Pass through the client protocol.\n        return client", "response": "Start relaying data between the process and the protocol."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connectRelay(self):\n        self.protocol = self.connector.buildProtocol(None)\n        self.connected = True\n        self.protocol.makeConnection(self)", "response": "Builds the target protocol and connects it to the relay transport."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef childDataReceived(self, childFD, data):\n        protocol = getattr(self, 'protocol', None)\n        if protocol:\n            protocol.dataReceived(data)\n        else:\n            self.data.append((childFD, data))", "response": "Relay data received on any file descriptor to the process\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish(self, user, provider, obj, comment, **kwargs):\n        '''\n            user - django User or UserSocialAuth instance\n            provider - name of publisher provider\n            obj - sharing object\n            comment - string\n        '''\n        social_user = self._get_social_user(user, provider)\n        backend = self.get_backend(social_user, provider, context=kwargs)\n        return backend.publish(obj, comment)", "response": "Publish an object to a social user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check(self, user, provider, permission, **kwargs):\n        '''\n            user - django User or UserSocialAuth instance\n            provider - name of publisher provider\n            permission - if backend maintains check permissions\n                            vk - binary mask in int format\n                            facebook - scope string\n        '''\n        try:\n            social_user = self._get_social_user(user, provider)\n            if not social_user:\n                return False\n\n        except SocialUserDoesNotExist:\n            return False\n\n        backend = self.get_backend(social_user, provider, context=kwargs)\n        return backend.check(permission)", "response": "Check if a user has permission on a social user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing a byte image buffer.", "response": "def recognize_byte(self, image, timeout=10):\n        \"\"\"Process a byte image buffer.\"\"\"\n        result = []\n\n        alpr = subprocess.Popen(\n            self._cmd,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.DEVNULL\n        )\n\n        # send image\n        try:\n            # pylint: disable=unused-variable\n            stdout, stderr = alpr.communicate(input=image, timeout=10)\n            stdout = io.StringIO(str(stdout, 'utf-8'))\n        except subprocess.TimeoutExpired:\n            _LOGGER.error(\"Alpr process timeout!\")\n            alpr.kill()\n            return None\n\n        tmp_res = {}\n        while True:\n            line = stdout.readline()\n            if not line:\n                if len(tmp_res) > 0:\n                    result.append(tmp_res)\n                break\n\n            new_plate = self.__re_plate.search(line)\n            new_result = self.__re_result.search(line)\n\n            # found a new plate\n            if new_plate and len(tmp_res) > 0:\n                result.append(tmp_res)\n                tmp_res = {}\n                continue\n\n            # found plate result\n            if new_result:\n                try:\n                    tmp_res[new_result.group(1)] = float(new_result.group(2))\n                except ValueError:\n                    continue\n\n        _LOGGER.debug(\"Process alpr with result: %s\", result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef finished(finished_status,\n             update_interval,\n             table,\n             status_column,\n             edit_at_column):\n    \"\"\"\n    Create text sql statement query for sqlalchemy that getting all finished task.\n\n    :param finished_status: int, status code that greater or equal than this\n        will be considered as finished.\n    :param update_interval: int, the record will be updated every x seconds.\n\n    :return: sqlalchemy text sql statement.\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u72b6\u6001\u7801\u5927\u4e8e\u67d0\u4e2a\u503c, \u5e76\u4e14, \u66f4\u65b0\u65f6\u95f4\u5728\u6700\u8fd1\u4e00\u6bb5\u65f6\u95f4\u4ee5\u5185.\n    \"\"\"\n    sql = select([table]).where(\n        and_(*[\n            status_column >= finished_status,\n            edit_at_column >= x_seconds_before_now(update_interval)\n        ])\n    )\n    return sql", "response": "Create sqlalchemy text sql statement that gets all finished task."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates sqlalchemy text sql statement that gets all unfinished tasks.", "response": "def unfinished(finished_status,\n               update_interval,\n               table,\n               status_column,\n               edit_at_column):\n    \"\"\"\n    Create text sql statement query for sqlalchemy that getting all unfinished task.\n\n    :param finished_status: int, status code that less than this\n        will be considered as unfinished.\n    :param update_interval: int, the record will be updated every x seconds.\n\n    :return: sqlalchemy text sql statement.\n\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u72b6\u6001\u7801\u5c0f\u4e8e\u67d0\u4e2a\u503c, \u6216\u8005, \u73b0\u5728\u8ddd\u79bb\u66f4\u65b0\u65f6\u95f4\u5df2\u7ecf\u8d85\u8fc7\u4e00\u5b9a\u9608\u503c.\n    \"\"\"\n    sql = select([table]).where(\n        or_(*[\n            status_column < finished_status,\n            edit_at_column < x_seconds_before_now(update_interval)\n        ])\n    )\n    return sql"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_nearest(x, x0) -> Tuple[int, Any]:\n    x = np.asanyarray(x)  # for indexing upon return\n    x0 = np.atleast_1d(x0)\n# %%\n    if x.size == 0 or x0.size == 0:\n        raise ValueError('empty input(s)')\n\n    if x0.ndim not in (0, 1):\n        raise ValueError('2-D x0 not handled yet')\n# %%\n    ind = np.empty_like(x0, dtype=int)\n\n    # NOTE: not trapping IndexError (all-nan) becaues returning None can surprise with slice indexing\n    for i, xi in enumerate(x0):\n        if xi is not None and (isinstance(xi, (datetime.datetime, datetime.date, np.datetime64)) or np.isfinite(xi)):\n            ind[i] = np.nanargmin(abs(x-xi))\n        else:\n            raise ValueError('x0 must NOT be None or NaN to avoid surprising None return value')\n\n    return ind.squeeze()[()], x[ind].squeeze()[()]", "response": "This function finds the nearest value in x0 to x0."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring that a behave resource exists as attribute in the behave context.", "response": "def ensure_context_attribute_exists(context, name, default_value=None):\n    \"\"\"\n    Ensure a behave resource exists as attribute in the behave context.\n    If this is not the case, the attribute is created by using the default_value.\n    \"\"\"\n    if not hasattr(context, name):\n        setattr(context, name, default_value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure that the workdir exists.", "response": "def ensure_workdir_exists(context):\n    \"\"\"\n    Ensures that the work directory exists.\n    In addition, the location of the workdir is stored as attribute in\n    the context object.\n    \"\"\"\n    ensure_context_attribute_exists(context, \"workdir\", None)\n    if not context.workdir:\n        context.workdir = os.path.abspath(WORKDIR)\n    pathutil.ensure_directory_exists(context.workdir)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mean_fill(adf):\n        ordpt = adf.values[0]\n        if not pd.isnull(ordpt):\n            return ordpt\n\n        fdmn = adf.iloc[1:-1].mean()\n        if not pd.isnull(fdmn):\n            return fdmn\n\n        flspt = adf.values[-1]\n        if not pd.isnull(flspt):\n            return flspt\n\n        return nan", "response": "Calculates the mean of the entries in the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the median value of the current instance of the class.", "response": "def median_fill(adf):\n        \"\"\" Looks at each row, and chooses the median. Honours\n        the Trump override/failsafe logic. \"\"\"\n        ordpt = adf.values[0]\n        if not pd.isnull(ordpt):\n            return ordpt\n\n        fdmn = adf.iloc[1:-1].median()\n        if not pd.isnull(fdmn):\n            return fdmn\n\n        flspt = adf.values[-1]\n        if not pd.isnull(flspt):\n            return flspt\n\n        return nan"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef most_populated(adf):\n\n        # just look at the feeds, ignore overrides and failsafes:\n        feeds_only = adf[adf.columns[1:-1]]\n\n        # find the most populated feed\n        cnt_df = feeds_only.count()\n        cnt = cnt_df.max()\n        selected_feeds = cnt_df[cnt_df == cnt]\n\n        # if there aren't any feeds, the first feed will work...\n        if len(selected_feeds) == 0:\n            pre_final = adf['feed001'] # if they are all empty\n                                  # they should all be\n                                  # equally empty\n        else:\n            #if there's one or more, take the highest priority one\n            pre_final = adf[selected_feeds.index[0]]\n\n\n        # create the final, applying the override and failsafe logic...\n        final_df = pd.concat([adf.override_feed000,\n                              pre_final,\n                              adf.failsafe_feed999], axis=1)\n        final_df = final_df.apply(_row_wise_priority, axis=1)\n        return final_df", "response": "Return a DataFrame with the most populated entry - set entries."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a DataFrame with the most recent entry point.", "response": "def most_recent(adf):\n        \"\"\"\n        Looks at each column, and chooses the feed with the most recent data\n        point. Honours the Trump override/failsafe logic. \"\"\"\n        # just look at the feeds, ignore overrides and failsafes:\n        feeds_only = adf[adf.columns[1:-1]]\n\n        # find the feeds with the most recent data...\n        feeds_with_data = feeds_only.dropna(how='all')\n        selected_feeds = feeds_with_data.T.dropna().index\n\n        # if there aren't any feeds, the first feed will work...\n        if len(selected_feeds) == 0:\n            pre_final = adf['feed001'] # if there all empyty\n                                  # they should all be\n                                  # equally empty\n        else:\n            #if there's one or more, take the highest priority one\n            pre_final = adf[selected_feeds[0]]\n\n\n        # create the final, applying the override and failsafe logic...\n        final_df = pd.concat([adf.override_feed000,\n                              pre_final,\n                              adf.failsafe_feed999], axis=1)\n        final_df = final_df.apply(_row_wise_priority, axis=1)\n        return final_df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a Trump table from the given ADF file.", "response": "def build_tri(adf):\n        \"\"\"\n        Looks at each column, and chooses the feed with the most recent data\n        point. Honours the Trump override/failsafe logic. \"\"\"\n        # just look at the capital (price), in \"feed one\", and income (dividend), in \"feed two\"\n        \n        cap, inc = adf.columns[1:3]\n        \n        data = adf[[cap,inc]]\n\n        # find the feeds with the most recent data...\n        inc_pct = data[inc].div(data[cap].shift(1))\n        \n        cap_pct = data[cap].pct_change(1)\n        \n        pre_final = inc_pct + cap_pct\n        \n        # create the final, applying the override and failsafe logic...\n        final_df = pd.concat([adf.override_feed000,\n                              pre_final,\n                              adf.failsafe_feed999], axis=1)\n        final_df = final_df.apply(_row_wise_priority, axis=1)\n        return final_df"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send_audio(self, url, user, options=None):\n        return await self.chat.send_audio(url, user, options)", "response": "send audio message\n\n        :param url: link to the audio file\n        :param user: target user\n        :param options:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a middleware to the list of middlewares", "response": "def use(self, middleware):\n        \"\"\"\n        attache middleware\n\n        :param middleware:\n        :return:\n        \"\"\"\n\n        logger.debug('use')\n        logger.debug(middleware)\n\n        self.middlewares.append(middleware)\n\n        di.injector.register(instance=middleware)\n        di.bind(middleware, auto=True)\n\n        # TODO: should use DI somehow\n        if check_spec(['send_text_message'], middleware):\n            self.chat.add_interface(middleware)\n\n        return middleware"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a key entry based on numerical indexes into subtree lists.", "response": "def del_by_idx(tree, idxs):\n    \"\"\"\n    Delete a key entry based on numerical indexes into subtree lists.\n    \"\"\"\n    if len(idxs) == 0:\n        tree['item'] = None\n        tree['subtrees'] = []\n    else:\n        hidx, tidxs = idxs[0], idxs[1:]\n        del_by_idx(tree['subtrees'][hidx][1], tidxs)\n        if len(tree['subtrees'][hidx][1]['subtrees']) == 0:\n            del tree['subtrees'][hidx]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest for path domination.", "response": "def dominates(p, q):\n    \"\"\"\n    Test for path domination.  An individual path element *a*\n    dominates another path element *b*, written as *a* >= *b* if\n    either *a* == *b* or *a* is a wild card.  A path *p* = *p1*, *p2*,\n    ..., *pn* dominates another path *q* = *q1*, *q2*, ..., *qm* if\n    *n* == *m* and, for all *i*, *pi* >= *qi*.\n\n    \"\"\"\n    return (len(p) == len(q) and\n            all(map(lambda es: es[0] == es[1] or es[0] == '*', zip(p, q))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a key path in the tree matching wildcards.", "response": "def find(self, key, perfect=False):\n        \"\"\"\n        Find a key path in the tree, matching wildcards.  Return value for\n        key, along with index path through subtree lists to the result.  Throw\n        ``KeyError`` if the key path doesn't exist in the tree.\n\n        \"\"\"\n        return find_in_tree(self.root, key, perfect)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npurging unreachable dominated key paths before inserting a new key.", "response": "def _purge_unreachable(self, key):\n        \"\"\"\n        Purge unreachable dominated key paths before inserting a new key\n        path.\n\n        \"\"\"\n        dels = []\n        for p in self:\n            if dominates(key, p):\n                dels.append(p)\n        for k in dels:\n            _, idxs = find_in_tree(self.root, k, perfect=True)\n            del_by_idx(self.root, idxs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(self, name, namespace):\n        if name in self._NAMESPACES:\n\n            raise ValueError(\"Namespace {0} already exists.\".format(name))\n\n        if not isinstance(namespace, ns.Namespace):\n\n            raise TypeError(\"Namespaces must be of type Namespace.\")\n\n        self._NAMESPACES[name] = namespace", "response": "Register a new namespace with the Configuration object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromSearch(text):\n    terms = []\n    for term in nstr(text).split(','):\n        # assume if no *'s then the user wants to search anywhere as keyword\n        if '*' not in term:\n            term = '*%s*' % term\n\n        term = term.replace('*', '.*')\n        terms.append('^%s$' % term)\n\n    return '|'.join(terms)", "response": "Generates a regular expression from simple search terms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow basic stats for a single bubble", "response": "def cli(ctx, monitor, full, stage):\n    \"\"\"Basic statistics\"\"\"\n    if not ctx.bubble:\n        msg = 'There is no bubble present, will not search stats'\n        if monitor:\n            ctx.say_yellow('Unknown - ' + msg, 0)\n            raise SystemExit(3)\n        else:\n            ctx.say_yellow(msg)\n        raise click.Abort()\n\n    stats = {}\n    stats_found = False\n    flowing_full = False\n    flowing_decrease = False\n    flowing_increase = False\n    errors = False\n\n    loader = bubble_lod_load(ctx, 'stats', stage)\n    lod_gen = _find_lod_gen(ctx, loader)\n    if lod_gen:\n        last_stats = {}\n        ctx.say('lod_gen', stuff=lod_gen)\n        for stats_data in lod_gen:\n            last_stats = stats_data\n        if last_stats:\n            ctx.say('found last_stats:', stuff=last_stats, verbosity=10)\n\n    try:\n        ctx.say('trying:last stats:', stuff=last_stats, verbosity=10)\n        if last_stats:\n            l = last_stats\n            stats['pull_err'] = k0(l, 'pulled_stat_error_count')\n            stats['pull_total'] = k0(l, 'pulled_stat_total_count')\n\n            stats['trans_err'] = k0(l, 'transformed_stat_error_count')\n            stats['trans_total'] = k0(l, 'transformed_stat_total_count')\n\n            stats['push_err'] = k0(l, 'pushed_stat_error_count')\n            stats['push_total'] = k0(l, 'pushed_stat_total_count')\n            stats_found = True\n        else:\n            stats_found = False\n\n        ctx.say('stats:', stuff=stats, verbosity=10)\n\n        if stats_found and stats['pull_err'] > 0 or \\\n                stats['trans_err'] > 0 or \\\n                stats['push_err'] > 0:\n            errors = True\n        if stats_found and stats['pull_total'] == stats['trans_total'] and \\\n                stats['trans_total'] == stats['push_total']:\n            flowing_full = True\n        if stats_found and stats['pull_total'] >= stats['trans_total'] >= stats['push_total']:\n            flowing_decrease = True\n        if stats_found and stats['pull_total'] <= stats['trans_total'] <= stats['push_total']:\n            flowing_increase = True\n    except KeyError as stat_key_error:\n        errors = True\n        ctx.gbc.cry('cannot create status from last stats', stuff=stat_key_error)\n\n    if full:\n        ctx.say_yellow('Stats full')\n        ctx.say_yellow('Full flow:' + str(flowing_full))\n        ctx.say_yellow('Flowing decrease:' + str(flowing_decrease))\n        ctx.say_yellow('Flowing increase:' + str(flowing_increase))\n        ctx.say_yellow('Errors:' + str(errors))\n        ctx.say_yellow('totals:')\n        ctx.say_yellow(pf(stats, indent=8))\n\n    if monitor == 'nagios' or full:\n\n        \"\"\"\n        for Numeric Value Service Status Status Description, please see:\n        https://nagios-plugins.org/doc/guidelines.html#AEN78\n        0 OK The plugin was able to check the service and\n          it appeared to be functioning properly\n        1 Warning The plugin was able to check the service,\n          but it appeared to be above some \"warning\" threshold or did not appear to be working properly\n        2 Critical The plugin detected that either the service was not running or\n          it was above some \"critical\" threshold\n        3 Unknown Invalid command line arguments were supplied to the plugin or\n          low-level failures internal to the plugin (such as unable to fork, or open a tcp socket)\n          that prevent it from performing the specified operation. Higher-level errors (such as name resolution errors,\n          socket timeouts, etc) are outside of the control of plugins and\n          should generally NOT be reported as UNKNOWN states.\n\n        http://nagios.sourceforge.net/docs/3_0/perfdata.html\n        http://nagios.sourceforge.net/docs/3_0/pluginapi.html\n        \"\"\"\n        if stats_found:\n            templ_nagios = 'pull: %d %d transform: %d  %d push: %d %d '\n            res_nagios = templ_nagios % (stats['pull_total'],\n                                         stats['pull_err'],\n                                         stats['trans_total'],\n                                         stats['trans_err'],\n                                         stats['push_total'],\n                                         stats['push_err']\n                                         )\n        else:\n            res_nagios = 'Cannot find or read stats'\n\n        if not stats_found:\n            print('Unknown - ' + res_nagios)\n            raise SystemExit(3)\n            # return\n\n        if not errors and flowing_full:\n            print('Ok - ' + res_nagios)\n            return\n\n        # magister and databyte with amount\n        if not errors and flowing_decrease:\n            print('Ok - ' + res_nagios)\n            return\n\n        if not errors and not flowing_full:\n            print('Warning - ' + res_nagios)\n            raise SystemExit(1)\n            # return\n\n        if errors:\n            print('Critical - ' + res_nagios)\n            raise SystemExit(2)\n            # return\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ast_smart(val):\n\n    if isinstance(val, Number):\n        return Num(n=val)\n    elif isinstance(val, basestring):\n        return Str(s=val)\n    else:\n        return ast_name(str(val))", "response": "Return a suitable subclass of ast. AST for storing numbers\n    or strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef napi_compare(left, ops, comparators, **kwargs):\n\n    values = []\n    for op, right in zip(ops, comparators):\n        value = COMPARE[op](left, right)\n        values.append(value)\n        left = right\n    result = napi_and(values, **kwargs)\n    if isinstance(result, ndarray):\n        return result\n    else:\n        return bool(result)", "response": "Make pairwise comparisons of comparators."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform element - wise logical and operation on arrays.", "response": "def napi_and(values, **kwargs):\n    \"\"\"Perform element-wise logical *and* operation on arrays.\n\n    If *values* contains a non-array object with truth_ value **False**, the\n    outcome will be an array of **False**\\s with suitable shape without arrays\n    being evaluated. Non-array objects with truth value **True** are omitted.\n\n    If array shapes do not match (after squeezing when enabled by user),\n    :exc:`ValueError` is raised.\n\n    This function uses :obj:`numpy.logical_and` or :obj:`numpy.all`.\"\"\"\n\n    arrays = []\n    result = None\n    shapes = set()\n\n    for value in values:\n        if isinstance(value, ndarray) and value.shape:\n            arrays.append(value)\n            shapes.add(value.shape)\n        elif not value:\n            result = value\n\n    if len(shapes) > 1 and kwargs.get('sq', kwargs.get('squeeze', False)):\n        shapes.clear()\n        for i, a in enumerate(arrays):\n            a = arrays[i] = a.squeeze()\n            shapes.add(a.shape)\n        if len(shapes) > 1:\n            raise ValueError('array shape mismatch, even after squeezing')\n\n    if len(shapes) > 1:\n        raise ValueError('array shape mismatch')\n\n    shape = shapes.pop() if shapes else None\n\n    if result is not None:\n        if shape:\n            return numpy.zeros(shape, bool)\n        else:\n            return result\n    elif arrays:\n        sc = kwargs.get('sc', kwargs.get('shortcircuit', 0))\n        if sc and numpy.prod(shape) >= sc:\n            return short_circuit_and(arrays, shape)\n        elif len(arrays) == 2:\n            return numpy.logical_and(*arrays)\n        else:\n            return numpy.all(arrays, 0)\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef napi_or(values, **kwargs):\n\n    arrays = []\n    result = None\n    shapes = set()\n\n    for value in values:\n        if isinstance(value, ndarray) and value.shape:\n            arrays.append(value)\n            shapes.add(value.shape)\n        elif value:\n            result = value\n\n    if len(shapes) > 1 and kwargs.get('squeeze', kwargs.get('sq', False)):\n        shapes.clear()\n        for i, a in enumerate(arrays):\n            a = arrays[i] = a.squeeze()\n            shapes.add(a.shape)\n        if len(shapes) > 1:\n            raise ValueError('array shape mismatch, even after squeezing')\n\n    if len(shapes) > 1:\n        raise ValueError('array shape mismatch')\n\n    shape = shapes.pop() if shapes else None\n\n    if result is not None:\n        if shape:\n            return numpy.ones(shape, bool)\n        else:\n            return result\n    elif arrays:\n        sc = kwargs.get('sc', kwargs.get('shortcircuit', 0))\n        if sc and numpy.prod(shape) >= sc:\n            return short_circuit_or(arrays, shape)\n        elif len(arrays) == 2:\n            return numpy.logical_or(*arrays)\n        else:\n            return numpy.any(arrays, 0)\n    else:\n        return value", "response": "Perform element - wise logical or operation on arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces chained comparisons with calls to napi_compare.", "response": "def visit_Compare(self, node):\n        \"\"\"Replace chained comparisons with calls to :func:`.napi_compare`.\"\"\"\n\n        if len(node.ops) > 1:\n            func = Name(id=self._prefix + 'napi_compare', ctx=Load())\n            args = [node.left,\n                    List(elts=[Str(op.__class__.__name__)\n                               for op in node.ops], ctx=Load()),\n                    List(elts=node.comparators, ctx=Load())]\n            node = Call(func=func, args=args, keywords=self._kwargs)\n            fml(node)\n        self.generic_visit(node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing logical operations with calls to napi. napi", "response": "def visit_BoolOp(self, node):\n        \"\"\"Replace logical operations with calls to :func:`.napi_and` or\n        :func:`.napi_or`.\"\"\"\n\n        if isinstance(node.op, And):\n            func = Name(id=self._prefix + 'napi_and', ctx=Load())\n        else:\n            func = Name(id=self._prefix + 'napi_or', ctx=Load())\n        args = [List(elts=node.values, ctx=Load())]\n        node = Call(func=func, args=args, keywords=self._kwargs)\n        fml(node)\n        self.generic_visit(node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninterferes with not operation to numpy. logical_not.", "response": "def visit_UnaryOp(self, node):\n        \"\"\"Interfere with ``not`` operation to :func:`numpy.logical_not`.\"\"\"\n\n        if isinstance(node.op, Not):\n            self._debug('UnaryOp', node.op, incr=1)\n            operand = self[node.operand]\n            self._debug('|-', operand, incr=2)\n            tn = self._tn()\n            result = numpy.logical_not(operand)\n            self._debug('|_', result, incr=2)\n            self[tn] = result\n            return ast_name(tn)\n        else:\n            return self.generic_visit(node)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninterfering with boolean operations and use numpy. all and numpy. any functions for and or operations.", "response": "def visit_BoolOp(self, node):\n        \"\"\"Interfere with boolean operations and use :func:`numpy.all` and\n        :func:`numpy.any` functions for ``and`` and ``or`` operations.\n        *axis* argument to these functions is ``0``.\"\"\"\n\n        self._incr()\n        self._debug('BoolOp', node.op)\n        if isinstance(node.op, And):\n            result = self._and(node)\n        else:\n            result = self._or(node)\n        self._debug('|_', result, incr=1)\n        self._decr()\n        return self._return(result, node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator that yields all DNS records for the given domain.", "response": "def rec_load_all(self, zone):\n        \"\"\"\n        Lists all DNS records for the given domain\n        :param zone: the domain for which records are being retrieved\n        :type zone: str\n        :return:\n        :rtype: generator\n        \"\"\"\n        has_more = True\n        current_count = 0\n        while has_more:\n            records = self._request({\n                'a': 'rec_load_all',\n                'o': current_count,\n                'z': zone\n            })\n            try:\n                has_more = records['response']['recs']['has_more']\n                current_count += records['response']['recs']['count']\n                for record in records['response']['recs']['objs']:\n                    yield record\n            except KeyError:\n                has_more = False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zone_ips(self, zone, hours=24, ip_class=None, geo=False):\n        params = {\n            'a': 'zone_ips',\n            'z': zone,\n            'hours': hours,\n            'class': ip_class,\n        }\n        if geo:\n            params['geo'] = geo\n        return self._request(params)", "response": "Retrieve IP addresses of recent visitors in a zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rec_new(self, zone, record_type, name, content, ttl=1, priority=None, service=None, service_name=None,\n                protocol=None, weight=None, port=None, target=None):\n        \"\"\"\n        Create a DNS record for the given zone\n        :param zone: domain name\n        :type zone: str\n        :param record_type: Type of DNS record. Valid values are [A/CNAME/MX/TXT/SPF/AAAA/NS/SRV/LOC]\n        :type record_type: str\n        :param name: name of the DNS record\n        :type name: str\n        :param content: content of the DNS record\n        :type content: str\n        :param ttl: TTL of the DNS record in seconds. 1 = Automatic, otherwise, value must in between 120 and\n            4,294,967,295 seconds.\n        :type ttl: int\n        :param priority: [applies to MX/SRV] MX record priority.\n        :type priority: int\n        :param service: Service for SRV record\n        :type service: str\n        :param service_name: Service Name for SRV record\n        :type service_name: str\n        :param protocol: Protocol for SRV record. Values are [_tcp/_udp/_tls].\n        :type protocol: str\n        :param weight: Weight for SRV record.\n        :type weight: int\n        :param port: Port for SRV record\n        :type port: int\n        :param target: Target for SRV record\n        :type target: str\n        :return:\n        :rtype: dict\n        \"\"\"\n        params = {\n            'a': 'rec_new',\n            'z': zone,\n            'type': record_type,\n            'name': name,\n            'content': content,\n            'ttl': ttl\n        }\n        if priority is not None:\n            params['prio'] = priority\n        if service is not None:\n            params['service'] = service\n        if service_name is not None:\n            params['srvname'] = service_name\n        if protocol is not None:\n            params['protocol'] = protocol\n        if weight is not None:\n            params['weight'] = weight\n        if port is not None:\n            params['port'] = port\n        if target is not None:\n            params['target'] = target\n        return self._request(params)", "response": "Create a new DNS record for the given zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rec_edit(self, zone, record_type, record_id, name, content, ttl=1, service_mode=None, priority=None,\n                 service=None, service_name=None, protocol=None, weight=None, port=None, target=None):\n        \"\"\"\n        Edit a DNS record for the given zone.\n        :param zone: domain name\n        :type zone: str\n        :param record_type: Type of DNS record. Valid values are [A/CNAME/MX/TXT/SPF/AAAA/NS/SRV/LOC]\n        :type record_type: str\n        :param record_id: DNS Record ID. Available by using the rec_load_all call.\n        :type record_id: int\n        :param name: Name of the DNS record\n        :type name: str\n        :param content: The content of the DNS record, will depend on the the type of record being added\n        :type content: str\n        :param ttl: TTL of record in seconds. 1 = Automatic, otherwise, value must in between 120 and 4,294,967,295\n            seconds.\n        :type ttl: int\n        :param service_mode: [applies to A/AAAA/CNAME] Status of CloudFlare Proxy, 1 = orange cloud, 0 = grey cloud.\n        :type service_mode: int\n        :param priority: [applies to MX/SRV] MX record priority.\n        :type priority: int\n        :param service: Service for SRV record\n        :type service: str\n        :param service_name: Service Name for SRV record\n        :type service_name: str\n        :param protocol: Protocol for SRV record. Values are [_tcp/_udp/_tls].\n        :type protocol: str\n        :param weight: Weight for SRV record.\n        :type weight: int\n        :param port: Port for SRV record\n        :type port: int\n        :param target: Target for SRV record\n        :type target: str\n        :return:\n        :rtype: dict\n        \"\"\"\n        params = {\n            'a': 'rec_edit',\n            'z': zone,\n            'type': record_type,\n            'id': record_id,\n            'name': name,\n            'content': content,\n            'ttl': ttl\n        }\n        if service_mode is not None:\n            params['service_mode'] = service_mode\n        if priority is not None:\n            params['prio'] = priority\n        if service is not None:\n            params['service'] = service\n        if service_name is not None:\n            params['srvname'] = service_name\n        if protocol is not None:\n            params['protocol'] = protocol\n        if weight is not None:\n            params['weight'] = weight\n        if port is not None:\n            params['port'] = port\n        if target is not None:\n            params['target'] = target\n        return self._request(params)", "response": "Edit a DNS record for the given zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the sequence of transitions that would move this state machine instance to a target state.", "response": "def calc_transition_to_state(self, newstate):\n        \"\"\"Given a target state, generate the sequence of transitions that would move this state machine instance to that target state.\n\n        Args:\n            newstate: A str state name to calculate the path to.\n\n        Returns:\n            A bitarray containing the bits that would transition this\n            state machine to the target state. The bits read from right\n            to left. For efficiency, this retulting bitarray is cached.\n            Do not edit this bitarray, or it will cause undefined\n            behavior.\n        \"\"\"\n        cached_val = JTAGStateMachine._lookup_cache.\\\n                     get((self.state, newstate))\n        if cached_val:\n            return cached_val\n\n        if newstate not in self.states:\n            raise ValueError(\"%s is not a valid state for this state \"\n                             \"machine\"%newstate)\n\n        path = self._find_shortest_path(self._statestr, newstate)\n        if not path:\n            raise ValueError(\"No path to the requested state.\")\n        res = self._get_steps_from_nodes_path(path)\n        res.reverse()\n        JTAGStateMachine._lookup_cache[(self.state, newstate)] = res\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprompting the user to set the value for this item.", "response": "def prompt(self, error=''):\n        \"\"\"\n        Prompts the user to set the value for this item.\n        \n        :return     <bool> | success\n        \"\"\"\n        if self.hidden:\n            return True\n\n        cmd = [self.label]\n\n        if self.default is not None:\n            cmd.append('(default: {0})'.format(self.default))\n        elif not self.required:\n            cmd.append('(default: )')\n\n        if self.type == 'bool':\n            cmd.append('(y/n)')\n\n        if self.choices:\n            print 'Choices:'\n            for choice in self.choices:\n                print choice\n        if error:\n            print error\n\n        value = raw_input(' '.join(cmd) + ':')\n        if value == '':\n            value = self.default\n\n        if self.type == 'bool':\n            if value == 'y':\n                value = True\n            elif value == 'n':\n                value = False\n            else:\n                value = self.default\n\n        if value is None and self.required:\n            return self.prompt('{0} is required.')\n\n        if self.regex and not re.match(self.regex, value):\n            error = '{0} must match {1}'.format(self.name, self.regex)\n            return self.prompt(error)\n\n        self.value = value\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild the scaffold out to the given filepath with the chosen structure.", "response": "def build(self, outpath, structure=None):\n        \"\"\"\n        Builds this scaffold out to the given filepath with the \n        chosen structure.\n        \n        :param      outpath   | <str>\n                    structure | <xml.etree.ElementTree.Element> || None\n\n        :return     <bool> | success\n        \"\"\"\n        if not os.path.exists(outpath):\n            return False\n\n        opts = {'scaffold': self}\n\n        if structure is not None:\n            xstruct = structure\n        else:\n            xstruct = self.structure()\n\n        if zipfile.is_zipfile(self.source()):\n            zfile = zipfile.ZipFile(self.source(), 'r')\n        else:\n            zfile = None\n            base = os.path.dirname(self.source())\n\n        # build the structure information\n        # noinspection PyShadowingNames\n        def build_level(root, xlevel):\n            # ignore the entry\n            if xlevel.get('enabled', 'True') == 'False':\n                return\n\n            # create a folder\n            if xlevel.tag == 'folder':\n                name = makotext.render(xlevel.get('name'), opts)\n                dirname = os.path.join(root, name)\n                if not os.path.exists(dirname):\n                    os.mkdir(dirname)\n\n                for xchild in xlevel:\n                    build_level(dirname, xchild)\n\n            # create a file\n            elif xlevel.tag == 'file':\n                name = makotext.render(xlevel.get('name'), opts)\n                fname = os.path.join(root, name)\n\n                # create from a template\n                templ = xlevel.get('templ')\n                if templ:\n                    if zfile:\n                        templ_str = zfile.read('templ/{0}'.format(templ))\n                    else:\n                        templ_path = os.path.join(base, 'templ', templ)\n                        templ_str = open(templ_path, 'r').read()\n\n                    rendered = makotext.render(templ_str, opts)\n                    rendered = rendered.replace('\\r\\n', '\\r')\n\n                    f = open(fname, 'w')\n                    f.write(rendered)\n                    f.close()\n\n                # create a blank file\n                else:\n                    f = open(fname, 'w')\n                    f.close()\n\n        for xlevel in xstruct:\n            build_level(outpath, xlevel)\n\n        if zfile:\n            zfile.close()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, template, fail='## :todo: add {template}'):\n        try:\n            return self._templates[template].render(scaffold=self)\n        except KeyError:\n            return fail.format(template=template)", "response": "Renders the value for the given template name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the scaffold option generation for this scaffold in the given path.", "response": "def run(self, path=None):\n        \"\"\"\n        Runs the scaffold option generation for this scaffold in the given\n        path.  If no path is supplied, then the current path is used.\n        \n        :param      path | <str> || None\n        \"\"\"\n        if path is None:\n            path = '.'\n\n        for prop in self._properties.values():\n            if not prop.prompt():\n                return False\n\n        return self.build(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the structure for this scaffold.", "response": "def structure(self):\n        \"\"\"\n        Returns the structure for this scaffold.\n        \n        :return     <xml.etree.ElementTree.Element> || None\n        \"\"\"\n        opts = {'scaffold': self}\n\n        # build from a zip file\n        if zipfile.is_zipfile(self.source()):\n            zfile = zipfile.ZipFile(self.source(), 'r')\n            try:\n                contents = zfile.read('structure.xml')\n                contents = makotext.render(contents, opts)\n                zfile.close()\n                return ElementTree.fromstring(contents)\n            except StandardError:\n                logger.exception('Failed to load structure.')\n                zfile.close()\n                return None\n\n        else:\n            try:\n                filename = os.path.join(os.path.dirname(self.source()),\n                                        'structure.xml')\n                xdata = open(filename, 'r').read()\n                xdata = makotext.render(xdata, opts)\n                return ElementTree.fromstring(xdata)\n            except StandardError:\n                logger.exception('Failed to load structure.')\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef template(self, key):\n        try:\n            return self._templates[key]\n        except KeyError:\n            return Template.Plugins[key]", "response": "Returns the template associated with this scaffold."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uifile(self):\n        output = ''\n\n        # build from a zip file\n        if zipfile.is_zipfile(self.source()):\n            zfile = zipfile.ZipFile(self.source(), 'r')\n            if 'properties.ui' in zfile.namelist():\n                tempdir = tempfile.gettempdir()\n                output = os.path.join(tempdir,\n                                      '{0}_properties.ui'.format(self.name()))\n\n                f = open(output, 'w')\n                f.write(zfile.read('properties.ui'))\n                f.close()\n            zfile.close()\n\n        else:\n            uifile = os.path.join(os.path.dirname(self.source()),\n                                  'properties.ui')\n            if os.path.exists(uifile):\n                output = uifile\n\n        return output", "response": "Returns the uifile for this scaffold."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(filename):\n        # parse a zipped file\n        if zipfile.is_zipfile(filename):\n            zfile = zipfile.ZipFile(filename, 'r')\n            try:\n                xml = ElementTree.fromstring(zfile.read('scaffold.xml'))\n            except StandardError:\n                logger.exception('Failed to load scaffold: {0}'.format(filename))\n                zfile.close()\n                return None\n            zfile.close()\n\n        # parse a standard xml file\n        else:\n            try:\n                xml = ElementTree.parse(filename).getroot()\n            except StandardError:\n                logger.exception('Failed to load scaffold: {0}'.format(filename))\n                return None\n\n        # generate a scaffold\n        scaffold = Scaffold()\n        scaffold.setSource(filename)\n        scaffold.setName(xml.get('name', 'Missing'))\n        scaffold.setGroup(xml.get('group', 'Default'))\n        scaffold.setLanguage(xml.get('lang', 'Python'))\n        scaffold.setIcon(xml.get('icon', ''))\n\n        # define properties\n        xprops = xml.find('properties')\n        if xprops is not None:\n            for xprop in xprops:\n                scaffold.addProperty(Property.fromXml(xprop))\n\n        return scaffold", "response": "Loads the scaffold from the given XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef displayhook(value):\n    global _displayhooks\n    new_hooks = []\n\n    for hook_ref in _displayhooks:\n        hook = hook_ref()\n        if hook:\n            hook(value)\n            new_hooks.append(hook_ref)\n\n    _displayhooks = new_hooks\n\n    sys.__displayhook__(value)", "response": "Runs all of the registered display hook methods with the given value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef excepthook(cls, error, trace):\n    global _excepthooks\n    new_hooks = []\n\n    for hook_ref in _excepthooks:\n        hook = hook_ref()\n        if hook:\n            hook(cls, error, trace)\n            new_hooks.append(hook_ref)\n\n    _excepthook = new_hooks\n    sys.__excepthook__(cls, error, trace)", "response": "Runs all of the registered exception hook methods with the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats the inputted class error and traceback information to the standard output commonly found in Python interpreters.", "response": "def formatExcept(cls, error, trace):\n    \"\"\"\n    Formats the inputted class, error, and traceback information to the standard\n    output commonly found in Python interpreters.\n    \n    :param      cls     | <type>\n                error   | <str>\n                trace   | <traceback>\n    \n    :return     <str>\n    \"\"\"\n    clsname = cls.__name__ if cls else 'UnknownError'\n    tb = 'Traceback (most recent call last):\\n'\n    tb += ''.join(traceback.format_tb(trace))\n    tb += '{0}: {1}'.format(clsname, error)\n    return tb"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a function to be called on hook queue.", "response": "def registerDisplay(func):\n    \"\"\"\n    Registers a function to the display hook queue to be called on hook.\n    Look at the sys.displayhook documentation for more information.\n    \n    :param      func | <callable>\n    \"\"\"\n    setup()\n    ref = weakref.ref(func)\n    if ref not in _displayhooks:\n        _displayhooks.append(ref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef registerExcept(func):\n    setup()\n    ref = weakref.ref(func)\n    if ref not in _excepthooks:\n        _excepthooks.append(ref)", "response": "Registers a function to be called on the except hook queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a function to be called on sys. stderr.", "response": "def registerStdErr(func):\n    \"\"\"\n    Registers a function to the print hook queue to be called on hook.\n    This method will also override the current sys.stdout variable with a new\n    <StreamHooks> instance.  This will preserve any current sys.stdout \n    overrides while providing a hookable class for linking multiple methods to.\n    \n    :param      func | <callable>\n    \"\"\"\n    if not isinstance(sys.stderr, StreamHooks):\n        sys.stderr = StreamHooks(sys.stderr)\n\n    ref = weakref.ref(func)\n    if ref not in sys.stderr.hooks:\n        sys.stderr.hooks.append(ref)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a function to be called on the print hook queue.", "response": "def registerStdOut(func):\n    \"\"\"\n    Registers a function to the print hook queue to be called on hook.\n    This method will also override the current sys.stdout variable with a new\n    <StreamHooks> instance.  This will preserve any current sys.stdout \n    overrides while providing a hookable class for linking multiple methods to.\n    \n    :param      func | <callable>\n    \"\"\"\n    if not isinstance(sys.stdout, StreamHooks):\n        sys.stdout = StreamHooks(sys.stdout)\n\n    ref = weakref.ref(func)\n    if ref not in sys.stdout.hooks:\n        sys.stdout.hooks.append(ref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup():\n    global _displayhooks, _excepthooks\n    if _displayhooks is not None:\n        return\n\n    _displayhooks = []\n    _excepthooks = []\n\n    # store any current hooks\n    if sys.displayhook != sys.__displayhook__:\n        _displayhooks.append(weakref.ref(sys.displayhook))\n\n    if sys.excepthook != sys.__excepthook__:\n        _excepthooks.append(weakref.ref(sys.excepthook))\n\n    # replace the current hooks\n    sys.displayhook = displayhook\n    sys.excepthook = excepthook", "response": "Initializes the hook queues for the system module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregisterStdOut(func):\n    try:\n        sys.stdout.hooks.remove(weakref.ref(func))\n    except (AttributeError, ValueError):\n        pass", "response": "Unregisters a function from sys. stdout. hooks."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses an ISO8601 datetime string into a datetime. datetime object.", "response": "def _parse_iso8601(text):\n    \"\"\"\n    Maybe parse an ISO8601 datetime string into a datetime.\n\n    :param text: Either a ``unicode`` string to parse or any other object\n        (ideally a ``datetime`` instance) to pass through.\n\n    :return: A ``datetime.datetime`` representing ``text``.  Or ``text`` if it\n        was anything but a ``unicode`` string.\n    \"\"\"\n    if isinstance(text, unicode):\n        try:\n            return parse_iso8601(text)\n        except ValueError:\n            raise CheckedValueTypeError(\n                None, (datetime,), unicode, text,\n            )\n    # Let pyrsistent reject it down the line.\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a specific resource from a path.", "response": "def from_path(cls, spec_path):\n        \"\"\"\n        Load a specification from a path.\n\n        :param FilePath spec_path: The location of the specification to read.\n        \"\"\"\n        with spec_path.open() as spec_file:\n            return cls.from_document(load(spec_file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_behavior_for_pclass(self, definition, cls):\n        if definition in self._pclasses:\n            raise AlreadyCreatedClass(definition)\n        if definition not in self.definitions:\n            raise NoSuchDefinition(definition)\n        self._behaviors.setdefault(definition, []).append(cls)", "response": "Adds a behavior to the Python class for the given definition."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize this specification to a JSON - compatible object representing a Swagger specification.", "response": "def to_document(self):\n        \"\"\"\n        Serialize this specification to a JSON-compatible object representing a\n        Swagger specification.\n        \"\"\"\n        return dict(\n            info=thaw(self.info),\n            paths=thaw(self.paths),\n            definitions=thaw(self.definitions),\n            securityDefinitions=thaw(self.securityDefinitions),\n            security=thaw(self.security),\n            swagger=thaw(self.swagger),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a pyrsistent. PClass subclass representing the Swagger definition with the given name.", "response": "def pclass_for_definition(self, name):\n        \"\"\"\n        Get a ``pyrsistent.PClass`` subclass representing the Swagger definition\n        in this specification which corresponds to the given name.\n\n        :param unicode name: The name of the definition to use.\n\n        :return: A Python class which can be used to represent the Swagger\n            definition of the given name.\n        \"\"\"\n        while True:\n            try:\n                cls = self._pclasses[name]\n            except KeyError:\n                try:\n                    original_definition = self.definitions[name]\n                except KeyError:\n                    raise NoSuchDefinition(name)\n\n                if \"$ref\" in original_definition:\n                    # Identify definitions that are merely a reference to\n                    # another and restart processing.  There is some\n                    # duplication of logic between this and the $ref handling\n                    # in _ClassModel.  It would be nice to eliminate this\n                    # duplication.\n                    name = original_definition[u\"$ref\"]\n                    assert name.startswith(u\"#/definitions/\")\n                    name = name[len(u\"#/definitions/\"):]\n                    continue\n\n                definition = self.transform_definition(name, original_definition)\n                kind = self._identify_kind(definition)\n                if kind is None:\n                    raise NotClassLike(name, definition)\n                generator = getattr(self, \"_model_for_{}\".format(kind))\n                model = generator(name, definition)\n                bases = tuple(self._behaviors.get(name, []))\n                cls = model.pclass(bases)\n                self._pclasses[name] = cls\n            return cls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a _ClassModel object that represents the given name and definition.", "response": "def _model_for_CLASS(self, name, definition):\n        \"\"\"\n        Model a Swagger definition that is like a Python class.\n\n        :param unicode name: The name of the definition from the\n            specification.\n\n        :param pyrsistent.PMap definition: A Swagger definition to categorize.\n            This will be a value like the one found at\n            ``spec[\"definitions\"][name]``.\n        \"\"\"\n        return _ClassModel.from_swagger(\n            self.pclass_for_definition,\n            name,\n            definition,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the pyrsistent field reflecting this attribute and its type model.", "response": "def pclass_field_for_attribute(self):\n        \"\"\"\n        :return: A pyrsistent field reflecting this attribute and its type model.\n        \"\"\"\n        return self.type_model.pclass_field_for_type(\n            required=self.required,\n            default=self.default,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_swagger(cls, pclass_for_definition, name, definition):\n        return cls(\n            name=name,\n            doc=definition.get(u\"description\", name),\n            attributes=cls._attributes_for_definition(\n                pclass_for_definition,\n                definition,\n            ),\n        )", "response": "Create a new _ClassModel from a single Swagger definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pclass(self, bases):\n        def discard_constant_fields(cls, **kwargs):\n            def ctor():\n                return super(huh, cls).__new__(cls, **kwargs)\n            try:\n                return ctor()\n            except AttributeError:\n                if u\"kind\" in kwargs or u\"apiVersion\" in kwargs:\n                    kwargs.pop(\"kind\", None)\n                    kwargs.pop(\"apiVersion\", None)\n                    return ctor()\n                raise\n\n\n        def lt_pclass(self, other):\n            if isinstance(other, self.__class__):\n                return sorted(self.serialize().items()) < sorted(other.serialize().items())\n            return NotImplemented\n\n\n        def eq_pclass(self, other):\n            if isinstance(other, self.__class__):\n                return sorted(self.serialize().items()) == sorted(other.serialize().items())\n            return NotImplemented\n\n\n        content = {\n            attr.name: attr.pclass_field_for_attribute()\n            for attr\n            in self.attributes\n        }\n        content[\"__doc__\"] = nativeString(self.doc)\n        content[\"serialize\"] = _serialize_with_omit\n        content[\"__new__\"] = discard_constant_fields\n        content[\"__lt__\"] = lt_pclass\n        content[\"__eq__\"] = eq_pclass\n        content[\"__hash__\"] = PClass.__hash__\n        content = total_ordering(content)\n        huh = type(nativeString(self.name), bases + (PClass,), content)\n        return huh", "response": "Create a new class representing this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_behavior_for_pclass(self, cls):\n        kind = cls.__name__\n        for version in sorted(self.versions):\n            try:\n                self.spec.add_behavior_for_pclass(self.full_name(version, kind), cls)\n            except NoSuchDefinition:\n                pass\n            else:\n                return None\n        raise NoSuchDefinition(kind)", "response": "Adds a behavior for a particular Python class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing obj to JSON formatted bytes.", "response": "def dumps_bytes(obj):\n    \"\"\"\n    Serialize ``obj`` to JSON formatted ``bytes``.\n    \"\"\"\n    b = dumps(obj)\n    if isinstance(b, unicode):\n        b = b.encode(\"ascii\")\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef native_string_to_bytes(s, encoding=\"ascii\", errors=\"strict\"):\n    if not isinstance(s, str):\n        raise TypeError(\"{} must be type str, not {}\".format(s, type(s)))\n    if str is bytes:\n        # Python 2\n        return s\n    else:\n        # Python 3\n        return s.encode(encoding=encoding, errors=errors)", "response": "Convert native string s to bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef native_string_to_unicode(s, encoding=\"ascii\", errors=\"strict\"):\n    if not isinstance(s, str):\n        raise TypeError(\"{} must be type str, not {}\".format(s, type(s)))\n    if str is unicode:\n        # Python 3\n        return s\n    else:\n        # Python 2\n        return s.decode(encoding=encoding, errors=errors)", "response": "Convert native string s to unicode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nallow serializing datetime objects to JSON", "response": "def datetime_handler(x):\n    \"\"\" Allow serializing datetime objects to JSON \"\"\"\n    if isinstance(x, datetime.datetime) or isinstance(x, datetime.date):\n        return x.isoformat()\n    raise TypeError(\"Unknown type\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the object to the database.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        **uid**: :code:`party:{apcode}`\n        \"\"\"\n        self.uid = 'party:{}'.format(slugify(self.ap_code))\n        if not self.slug:\n            if self.organization:\n                self.slug = slugify(self.organization.name)\n            else:\n                self.slug = slugify(self.label)\n        super(Party, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parsed(self):\n        if not self._parsed:\n\n            self._parsed = compile(self.content, self.path, 'exec')\n\n        return self._parsed", "response": "Get the code object which represents the compiled Python file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing version number from version. py file", "response": "def get_version():\n    \"\"\"\n    parse __init__.py for version number instead of importing the file\n    see http://stackoverflow.com/questions/458550/standard-way-to-embed-version-into-python-package\n    \"\"\"\n    version_file = os.path.join(PKG, 'lib/version.py')\n    ver_str_line = open(version_file, \"rt\").read()\n    version_regex = r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]'\n    mo = re.search(version_regex, ver_str_line, re.M)\n    if mo:\n        return mo.group(1)\n    else:\n        raise RuntimeError('Unable to find version string in %s.'\n                           % (version_file,))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _chunk(iterable, size):\n    # We're going to use some star magic to chunk the iterable. We create a\n    # copy of the iterator size times, then pull a value from each to form a\n    # chunk. The last chunk may have some trailing Nones if the length of the\n    # iterable isn't a multiple of size, so we filter them out.\n\n    args = (iter(iterable),) * size\n\n    return (\n        # pylint: disable=star-args\n        itertools.takewhile(lambda x: x is not None, group)\n        for group in itertools.zip_longest(*args)\n    )", "response": "Split an iterable into chunks of a fixed size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _matrix_add_column(matrix, column, default=0):\n    height_difference = len(column) - len(matrix)\n\n    # The width of the matrix is the length of its longest row.\n    width = max(len(row) for row in matrix) if matrix else 0\n\n    # For now our offset is 0. We may need to shift our column down later.\n    offset = 0\n\n    # If we need extra rows, add them to the top of the matrix.\n    if height_difference > 0:\n        for _ in range(height_difference):\n            matrix.insert(0, [default] * width)\n\n    # If the column is shorter, we'll need to shift it down.\n    if height_difference < 0:\n        offset = -height_difference\n        #column = ([default] * offset) + column\n\n    for index, value in enumerate(column):\n        # The row index is the index in the column plus our offset.\n        row_index = index + offset\n        row = matrix[row_index]\n\n        # If this row is short, pad it with default values.\n        width_difference = width - len(row)\n        row.extend([default] * width_difference)\n\n        row.append(value)", "response": "Given a matrix as a list of lists add a column to the right filling in\n    with a default value if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vertical_graph(*args, sep='\\n'):\n    lines = []\n\n    # If the arguments were passed as a single iterable, pull it out.\n    # Otherwise, just use them as-is.\n    if len(args) == 1:\n        bars = args[0]\n    else:\n        bars = args\n\n    # Make sure we use the default when needed\n    if sep is None:\n        sep = '\\n'\n\n    # Break the bars into groups of four, one for each row in the braille\n    # blocks.\n    for bar_group in _chunk(bars, 4):\n        line = []\n\n        for braille_row, bar_value in enumerate(bar_group):\n            # The number of full braille blocks needed to draw this bar. Each\n            # block is two dots wide.\n            full_blocks_needed = bar_value // 2\n\n            # The number of braille blocks needed to draw this bar. The second\n            # term accounts for a possible half row.\n            blocks_needed = full_blocks_needed + (bar_value % 2)\n\n            # The number of braille blocks we'll need to append to the current\n            # line to accomodate this bar\n            extra_blocks_needed = blocks_needed - len(line)\n\n            # If we need extra blocks, add them.\n            if extra_blocks_needed > 0:\n                line.extend([_BRAILLE_EMPTY_BLOCK] * extra_blocks_needed)\n\n            # Fill in the majority of the bar with full braille rows (two dots).\n            for block_index in range(full_blocks_needed):\n                line[block_index] += _BRAILLE_FULL_ROW[braille_row]\n\n            # If the bar's value is odd, we'll need to add a single dot at the\n            # end.\n            if bar_value % 2:\n                line[full_blocks_needed] += _BRAILLE_HALF_ROW[braille_row]\n\n        # Wrap up this line by converting all the code points to characters\n        # and concatenating them.\n        lines.append(''.join(chr(code) for code in line))\n\n    # Join all the lines to make the final graph\n    return sep.join(lines)", "response": "r Returns a vertical bar graph of the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck to see if the callback pointers are still valid or not.", "response": "def isValid(self):\n        \"\"\"\n        Checks to see if the callback pointers are still valid or not.\n        \n        :return     <bool>\n        \"\"\"\n        if self._callback_func_ref is not None and self._callback_func_ref():\n            if self._callback_self_ref is None or self._callback_self_ref():\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears all the callbacks for a particular signal.", "response": "def clear(self, signal=None):\n        \"\"\"\n        Clears either all the callbacks or the callbacks for a particular\n        signal.\n        \n        :param      signal | <variant> || None\n        \"\"\"\n        if signal is not None:\n            self._callbacks.pop(signal, None)\n        else:\n            self._callbacks.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self, signal, slot):\n        if self.isConnected(signal, slot):\n            return False\n\n        callback = Callback(slot)\n        self._callbacks.setdefault(signal, [])\n        self._callbacks[signal].append(callback)\n        return True", "response": "Creates a new connection between the inputted signal and slot."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbreaks the connection between the inputted signal and the given slot.", "response": "def disconnect(self, signal, slot):\n        \"\"\"\n        Breaks the connection between the inputted signal and the given slot.\n        \n        :param      signal | <variant>\n                    slot   | <callable>\n        \n        :return     <bool> | connection broken\n        \"\"\"\n        sig_calls = self._callbacks.get(signal, [])\n        for callback in sig_calls:\n            if callback == slot:\n                sig_calls.remove(callback)\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isConnected(self, signal, slot):\n        sig_calls = self._callbacks.get(signal, [])\n        for callback in sig_calls:\n            if callback == slot:\n                return True\n        return False", "response": "Returns if the given signal is connected to the inputted slot."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nemitting the given signal with the inputted args.", "response": "def emit(self, signal, *args):\n        \"\"\"\n        Emits the given signal with the inputted args.  This will go through\n        its list of connected callback slots and call them.\n        \n        :param      signal | <variant>\n                    *args  | variables\n        \"\"\"\n        callbacks = self._callbacks.get(signal, [])\n        new_callbacks = []\n        for callback in callbacks:\n            # clear out deleted pointers\n            if not callback.isValid():\n                continue\n\n            new_callbacks.append(callback)\n\n            try:\n                callback(*args)\n            except StandardError:\n                logger.exception('Error occurred during callback.')\n\n        self._callbacks[signal] = new_callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_example(config, ext='json'):\n    template_name = 'example.{0}'.format(ext.lower())\n    template = ENV.get_template(template_name)\n    return template.render(config=config)", "response": "Generate an example file based on the given configuration object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n\n        rtype = self.name\n        resource_content = '\\n'.join(self.content)\n        resource_class = ResourceDirective.get_resource_class(rtype)\n        this_resource = resource_class(self.docname, rtype, resource_content)\n\n        # Add this resource to the site\n        self.resources[this_resource.docname] = this_resource\n\n        # Don't need to return a resource \"node\", the document is the node\n        return []", "response": "Runs at parse time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef importProteinDatabase(filePath, proteindb=None, headerParser=None,\n        forceId=False, decoyTag='[decoy]', contaminationTag='[cont]',\n        ignoreIsoleucine=False,  cleavageRule='[KR]', minLength=5, maxLength=40,\n        missedCleavage=0, removeNtermM=False):\n    \"\"\"Generates a :class:`ProteinDatabase` by in silico digestion of proteins\n    from a fasta file.\n\n    :param filePath: File path\n    :param proteindb: optional an existing :class:`ProteinDatabase` can be\n        specified, otherwise a new instance is generated and returned\n    :param decoyTag: If a fasta file contains decoy protein entries, they should\n        be specified with a sequence tag\n    :param contaminationTag: If a fasta file contains contamination protein\n        entries, they should be specified with a sequence tag\n    :param headerParser: optional, allows specifying an individual headerParser\n    :param forceId: bool, if True and no id can be extracted from the fasta\n        header the whole header sequence is used as a protein id instead of\n        raising an exception.\n    :param cleavageRule: cleavage rule expressed in a regular expression, see\n        :attr:`maspy.constants.expasy_rules`\n    :param missedCleavage: number of allowed missed cleavage sites\n    :param removeNtermM: bool, True to consider also peptides with the\n        N-terminal Methionine of the protein removed\n    :param minLength: int, only yield peptides with length >= minLength\n    :param maxLength: int, only yield peptides with length <= maxLength\n    :param ignoreIsoleucine: bool, if True treat Isoleucine and Leucine in\n        peptide sequences as indistinguishable\n\n    See also :func:`maspy.peptidemethods.digestInSilico`\n    \"\"\"\n    if proteindb is None:\n        proteindb = ProteinDatabase(ignoreIsoleucine=ignoreIsoleucine)\n\n    # - Add protein entries to the protein database - #\n    for fastaHeader, sequence in _readFastaFile(filePath):\n        #TODO: function, make protein entry or something like this.\n        header, isDecoy = _removeHeaderTag(fastaHeader, decoyTag)\n        header, isContaminant = _removeHeaderTag(header, contaminationTag)\n\n        headerInfo = _parseFastaHeader(header, headerParser, forceId)\n        proteinId = _idFromHeaderInfo(headerInfo, isDecoy, decoyTag)\n        proteinName = _nameFromHeaderInfo(headerInfo, isDecoy, decoyTag)\n\n        if not isDecoy:\n            isDecoy = _proteinTagPresent(header, decoyTag)\n        if not isContaminant:\n            isContaminant = _proteinTagPresent(header, contaminationTag)\n\n        proteindb._addProtein(\n            proteinId, proteinName, sequence, fastaHeader, headerInfo,\n            isDecoy=isDecoy, isContaminant=isContaminant\n        )\n\n    # - Perform an insilico digestion and add peptides to the proteindb - #\n    for proteinId in proteindb.proteins:\n        sequence = proteindb.proteins[proteinId].sequence\n        digestInfo = maspy.peptidemethods.digestInSilico(\n            sequence, cleavageRule, missedCleavage, removeNtermM,\n            minLength, maxLength\n        )\n        for sequence, info in digestInfo:\n            proteindb._addPeptide(sequence, proteinId, info)\n\n    #Define wheter a peptide is unique to one protein entry\n    for peptide, peptideEntry in viewitems(proteindb.peptides):\n        if len(peptideEntry.proteins) == 1:\n            peptideEntry.isUnique = True\n        else:\n            peptideEntry.isUnique = False\n\n    #Add peptide as shared or unique to its protein entries\n    for peptide, peptideEntry in viewitems(proteindb.peptides):\n        for proteinId in peptideEntry.proteins:\n            if peptideEntry.isUnique:\n                proteindb.proteins[proteinId].uniquePeptides.add(peptide)\n            else:\n                proteindb.proteins[proteinId].sharedPeptides.add(peptide)\n\n    #Define unique proteins, i.e. have at least one unique peptide\n    for proteinEntry in viewvalues(proteindb.proteins):\n        if len(proteinEntry.uniquePeptides) > 0:\n            proteinEntry.isUnique = True\n        else:\n            proteinEntry.isUnique = False\n\n    return proteindb", "response": "Generates a new instance of the class : class : ProteinDatabase class from a file path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a tag from the beginning of a header string.", "response": "def _removeHeaderTag(header, tag):\n    \"\"\"Removes a tag from the beginning of a header string.\n\n    :param header: str\n    :param tag: str\n    :returns: (str, bool), header without the tag and a bool that indicates\n        wheter the tag was present.\n    \"\"\"\n    if header.startswith(tag):\n        tagPresent = True\n        header = header[len(tag):]\n    else:\n        tagPresent = False\n    return header, tagPresent"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a fasta header and returns extracted information in a dictionary.", "response": "def _parseFastaHeader(fastaHeader, parser=None, forceId=False):\n    \"\"\"Parses a fasta header and returns extracted information in a dictionary.\n\n    Unless a custom parser is specified, a ``Pyteomics`` function is used, which\n    provides parsers for the formats of UniProtKB, UniRef, UniParc and  UniMES\n    (UniProt Metagenomic and Environmental Sequences), described at\n    `www.uniprot.org <http://www.uniprot.org/help/fasta-headers>_`.\n\n    :param fastaHeader: str, protein entry header from a fasta file\n    :param parser: is a function that takes a fastaHeader string and returns a\n        dictionary, containing at least the key \"id\". If None the parser\n        function from pyteomics ``pyteomics.fasta.parse()`` is used.\n    :param forceId: bool, if True and no id can be extracted from the fasta\n        header the whole header sequence is used as a protein id instead of\n        raising an exception.\n\n    :returns: dict, describing a fasta header. Minimally contains an 'id' key.\n    \"\"\"\n    if parser is None:\n        try:\n            headerInfo = pyteomics.fasta.parse(fastaHeader)\n        except pyteomics.auxiliary.PyteomicsError as raisedPyteomicsError:\n            #If forceId is set True, the whole header is used as id\n            if forceId:\n                headerInfo = {'id': fastaHeader}\n            else:\n                raise raisedPyteomicsError\n    else:\n        headerInfo = parser(fastaHeader)\n    return headerInfo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a protein id from a headerInfo dict.", "response": "def _idFromHeaderInfo(headerInfo, isDecoy, decoyTag):\n    \"\"\"Generates a protein id from headerInfo. If \"isDecoy\" is True, the\n    \"decoyTag\" is added to beginning of the generated protein id.\n\n    :param headerInfo: dict, must contain a key \"id\"\n    :param isDecoy: bool, determines if the \"decoyTag\" is added or not.\n    :param decoyTag: str, a tag that identifies decoy / reverse protein entries.\n    :returns: str, protein id\n    \"\"\"\n    proteinId = headerInfo['id']\n    if isDecoy:\n        proteinId = ''.join((decoyTag, proteinId))\n\n    return proteinId"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a protein name from a dictionary containing a headerInfo.", "response": "def _nameFromHeaderInfo(headerInfo, isDecoy, decoyTag):\n    \"\"\"Generates a protein name from headerInfo. If \"isDecoy\" is True, the\n    \"decoyTag\" is added to beginning of the generated protein name.\n\n    :param headerInfo: dict, must contain a key \"name\" or \"id\"\n    :param isDecoy: bool, determines if the \"decoyTag\" is added or not.\n    :param decoyTag: str, a tag that identifies decoy / reverse protein entries.\n    :returns: str, protein name\n    \"\"\"\n    if 'name' in headerInfo:\n        proteinName = headerInfo['name']\n    else:\n        proteinName = headerInfo['id']\n    if isDecoy:\n        proteinName = ''.join((decoyTag, proteinName))\n\n    return proteinName"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new protein entry to the cache", "response": "def _addProtein(self, proteinId, proteinName, sequence, fastaHeader,\n                    headerInfo, isDecoy=False, isContaminant=False):\n        \"\"\"#TODO\"\"\"\n        proteinEntry = ProteinEntry(\n            proteinId, proteinName, sequence, fastaHeader, headerInfo,\n            isDecoy=isDecoy, isContaminant=isContaminant\n        )\n        self.proteins[proteinEntry.id] = proteinEntry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a peptide to the protein database.", "response": "def _addPeptide(self, sequence, proteinId, digestInfo):\n        \"\"\"Add a peptide to the protein database.\n\n        :param sequence: str, amino acid sequence\n        :param proteinId: str, proteinId\n        :param digestInfo: dict, contains information about the in silico digest\n            must contain the keys 'missedCleavage', 'startPos' and 'endPos'\n        \"\"\"\n        stdSequence = self.getStdSequence(sequence)\n\n        if stdSequence not in self.peptides:\n            self.peptides[stdSequence] = PeptideEntry(\n                stdSequence, mc=digestInfo['missedCleavage']\n            )\n        if sequence not in self.peptides:\n            self.peptides[sequence] = self.peptides[stdSequence]\n\n        if proteinId not in self.peptides[stdSequence].proteins:\n            #FUTURE: peptide can appear at multiple positions per protein.\n            #peptideEntry.addSource(proteinId, startPos, endPos)\n            self.peptides[stdSequence].proteins.add(proteinId)\n            self.peptides[stdSequence].proteinPositions[proteinId] = (\n                                    digestInfo['startPos'], digestInfo['endPos']\n                                    )\n            self.proteins[proteinId].peptides.add(sequence)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef options(self, parser, env):\n        super(LeakDetectorPlugin, self).options(parser, env)\n        parser.add_option(\"--leak-detector-level\", action=\"store\",\n                          default=env.get('NOSE_LEAK_DETECTOR_LEVEL'),\n                          dest=\"leak_detector_level\",\n                          help=\"Level at which to detect leaks and report memory deltas \"\n                               \"(0=None, 1=Dir, 2=Module, 3=TestCaseClass, 4=Test)\")\n\n        parser.add_option(\"--leak-detector-report-delta\", action=\"store_true\",\n                          default=env.get('NOSE_LEAK_DETECTOR_REPORT_DELTA'),\n                          dest=\"leak_detector_report_delta\",\n                          help=\"\")\n\n        parser.add_option(\"--leak-detector-patch-mock\", action=\"store_true\",\n                          default=env.get('NOSE_LEAK_DETECTOR_PATCH_MOCK', True),\n                          dest=\"leak_detector_patch_mock\",\n                          help=\"\")\n\n        parser.add_option(\"--leak-detector-add-traceback\", action=\"store_true\",\n                          default=env.get('NOSE_LEAK_DETECTOR_SAVE_TRACEBACK', False),\n                          dest=\"leak_detector_save_traceback\",\n                          help=\"\")\n\n        parser.add_option(\"--leak-detector-ignore-pattern\", action=\"append\",\n                          default=(list(filter(operator.truth,\n                                               env.get('NOSE_LEAK_DETECTOR_IGNORE_PATTERNS',\n                                                       '').split(','))) or\n                                   ['NOSE_LEAK_DETECTOR_IGNORE']),\n                          dest=\"leak_detector_ignore_patterns\",\n                          help=\"\")", "response": "Add options to command line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbind deps to instance", "response": "def bind(self, instance, auto=False):\n        \"\"\"\n        Bind deps to instance\n\n        :param instance:\n        :param auto: follow update of DI and refresh binds once we will get something new\n        :return:\n        \"\"\"\n        methods = [\n            (m, cls.__dict__[m])\n            for cls in inspect.getmro(type(instance))\n            for m in cls.__dict__ if inspect.isfunction(cls.__dict__[m])\n            ]\n\n        try:\n            deps_of_endpoints = [(method_ptr, self.entrypoint_deps(method_ptr))\n                                 for (method_name, method_ptr) in methods]\n\n            for (method_ptr, method_deps) in deps_of_endpoints:\n                if len(method_deps) > 0:\n                    method_ptr(instance, **method_deps)\n        except KeyError:\n            pass\n\n        if auto and instance not in self.current_scope.get_auto_bind_list():\n            self.current_scope.auto_bind(instance)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmap dict_entity to current instance", "response": "def map_dict(self, dict_entity):\n        \"\"\" map dict_entity to current instance(self) \"\"\"\n        self.dict_entity = dict_entity\n        Entity.map(self, self.dict_entity)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_dict(self):\n        odict = OrderedDict()\n        for name in self._order:\n            attr_value = getattr(self, name)\n            if isinstance(attr_value, List):\n                _list = []\n                for item in attr_value:\n                    _list.append((item.as_dict() if isinstance(item, Entity) else item))\n                    odict[name] = _list\n            elif isinstance(attr_value, Entity):\n                odict[name] = attr_value.as_dict()\n            else:\n                odict[name] = getattr(self, name)\n        return odict", "response": "create a dict based on class attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generateParams(rawfilepath, outputpath, isolationWindow, coElute):\n    output = str()\n    #Basic options\n    output = '\\n'.join([output, ' = '.join(['datapath', rawfilepath])])\n    output = '\\n'.join([output, ' = '.join(['logfilepath', outputpath])])\n    output = '\\n'.join([output, ' = '.join(['outputpath', outputpath])])\n    #Advanced options\n    output = '\\n'.join([output, ' = '.join(['co-elute', str(coElute)])])\n    output = '\\n'.join([output, ' = '.join(['input_format', 'raw'])])\n    output = '\\n'.join([output, ' = '.join(['isolation_width',\n                                            str(isolationWindow)]\n                                            )])\n    output = '\\n'.join([output, ' = '.join(['mars_threshold', '-0.5'])])\n    output = '\\n'.join([output, ' = '.join(['ipv_file', '.\\IPV.txt'])])\n    output = '\\n'.join([output, ' = '.join(['trainingset', 'EmptyPath'])])\n    #Internal Switches\n    output = '\\n'.join([output, ' = '.join(['output_mars_y', '0'])])\n    output = '\\n'.join([output, ' = '.join(['delete_msn', '0'])])\n    output = '\\n'.join([output, ' = '.join(['output_mgf', '1'])])\n    output = '\\n'.join([output, ' = '.join(['output_pf', '0'])])\n    output = '\\n'.join([output, ' = '.join(['debug_mode', '0'])])\n    output = '\\n'.join([output, ' = '.join(['check_activationcenter', '1'])])\n    output = '\\n'.join([output, ' = '.join(['output_all_mars_y', '0'])])\n    output = '\\n'.join([output, ' = '.join(['rewrite_files', '0'])])\n    output = '\\n'.join([output, ' = '.join(['export_unchecked_mono', '0'])])\n    output = '\\n'.join([output, ' = '.join(['cut_similiar_mono', '1'])])\n    output = '\\n'.join([output, ' = '.join(['mars_model', '4'])])\n    output = '\\n'.join([output, ' = '.join(['output_trainingdata', '0'])])\n\n    return output", "response": "Generates a string containing the parameters for a pParse parameter file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef writeParams(rawfilepath, outputpath, isolationWindow, coElute=0):\n    paramText = generateParams(rawfilepath, outputpath, isolationWindow,\n                               coElute)\n    filename, fileext = os.path.splitext(os.path.basename(rawfilepath))\n    paramPath = aux.joinpath(outputpath, filename+'.pparse.para')\n    with open(paramPath, 'wb') as openfile:\n        openfile.write(paramText)\n    return paramPath", "response": "Generate and write a pParse parameter file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes pParse with the specified parameter file.", "response": "def execute(paramPath, executable='pParse.exe'):\n    \"\"\"Execute pParse with the specified parameter file.\n\n    :param paramPath: location of the pParse parameter file\n    :param executable: must specify the complete file path of the pParse.exe\n        if its location is not in the ``PATH`` environment variable.\n\n    :returns: :func:`subprocess.Popen` return code, 0 if pParse was executed\n        successful\n    \"\"\"\n    procArgs = [executable, paramPath]\n\n    ## run it ##\n    proc = subprocess.Popen(procArgs, stderr=subprocess.PIPE)\n\n    ## But do not wait till netstat finish, start displaying output immediately ##\n    while True:\n        out = proc.stderr.read(1)\n        if out == '' and proc.poll() != None:\n            break\n        if out != '':\n            sys.stdout.write(out)\n            sys.stdout.flush()\n\n    return proc.returncode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cleanUpPparse(outputpath, rawfilename, mgf=False):\n    extensions = ['csv', 'ms1', 'ms2', 'xtract']\n    filename, fileext = os.path.splitext(os.path.basename(rawfilename))\n    additionalFiles = [aux.joinpath(outputpath, 'pParsePlusLog.txt'),\n                       aux.joinpath(outputpath, filename+'.pparse.para'),\n                       ]\n\n    for ext in extensions:\n        filepath = aux.joinpath(outputpath, '.'.join([filename, ext]))\n        if os.path.isfile(filepath):\n            print('Removing file: ', filepath)\n            os.remove(filepath)\n    for filepath in additionalFiles:\n        if os.path.isfile(filepath):\n            print('Removing file: ', filepath)\n            os.remove(filepath)\n    if mgf:\n        for _filename in os.listdir(outputpath):\n            _basename, _fileext = os.path.splitext(_filename)\n            if _fileext.lower() != '.mgf':\n                continue\n            if _basename.find(basename) != -1 and _basename != basename:\n                filepath = aux.joinpath(outputpath, _filename)\n                print('Removing file: ', filepath)\n                os.remove(filepath)", "response": "Delete temporary files generated by pParse and remove the files that are not generated by pParse."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef launch_server(message_handler, options):\n    logger = logging.getLogger(__name__)\n    if (options.debug):\n        logger.setLevel(logging.DEBUG)\n\n    if not options.monitor_port:\n        logger.warning(\n            \"Monitoring not enabled. No monitor-port option defined.\")\n    else:\n        threading.Thread(target=launch_monitor_server, args=(options.host, options.monitor_port, logger)).start()\n\n    # Create the server, binding to specified host on configured port\n\n    logger.info(\n        'Starting server on host %s port %d Python version %s.%s.%s' % ((options.host, options.port) + sys.version_info[:3]))\n    server = ThreadedTCPServer((options.host, options.port),\n                       StreamHandler.create_handler(message_handler,\n                                                    options.buffer_size,\n                                                    logger))\n\n    # Activate the server; this will keep running until you\n    # interrupt the program with Ctrl-C\n    try:\n        server.serve_forever()\n    except KeyboardInterrupt:\n        logger.info(\"Ctrl-C, exiting...\")\n        os._exit(142)", "response": "Launch a message server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_monitor_server(host, port, logger):\n    logger.info('Starting monitor server on host %s port %d' % (host, port))\n    server = ThreadedTCPServer((host, port), MonitorHandler)\n    server.serve_forever()", "response": "Launch a monitor server on the given host and port."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclasses variables used here since the framework creates an instance for each connection :param message_handler: the MessageHandler used to process each message. :param buffer_size: the TCP buffer size. :param logger: the global logger. :return: this class.", "response": "def create_handler(cls, message_handler, buffer_size, logger):\n        \"\"\"\n        Class variables used here since the framework creates an instance for each connection\n\n        :param message_handler: the MessageHandler used to process each message.\n        :param buffer_size: the TCP buffer size.\n        :param logger: the global logger.\n        :return: this class.\n        \"\"\"\n        cls.BUFFER_SIZE = buffer_size\n        cls.message_handler = message_handler\n        cls.logger = logger\n\n        cls.message_handler.logger = logging.getLogger(message_handler.__class__.__name__)\n        cls.message_handler.logger.setLevel(logger.level)\n        return cls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle(self):\n        logger = StreamHandler.logger\n        logger.debug(\"handling requests with message handler %s \" % StreamHandler.message_handler.__class__.__name__)\n\n        message_handler = StreamHandler.message_handler\n\n        try:\n            while True:\n                logger.debug('waiting for more data')\n                if not message_handler.handle(self.request, StreamHandler.BUFFER_SIZE):\n                    break\n\n            logger.warning(\"connection closed from %s\" % (self.client_address[0]))\n            self.request.close()\n        except:\n            logger.exception(\"connection closed from %s\" % (self.client_address[0]))\n        finally:\n            self.request.close()", "response": "Handle the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receiveError(self, reasonCode, description):\n        error = disconnectErrors.get(reasonCode, DisconnectError)\n        self.connectionClosed(error(reasonCode, description))\n        SSHClientTransport.receiveError(self, reasonCode, description)", "response": "Called when we receive a disconnect error message from the other node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef traceback_string():\n    tb_string = None\n    exc_type, exc_value, exc_traceback = traceback.sys.exc_info()\n    if exc_type is not None:\n        display_lines_list = [str(exc_value)] + traceback.format_tb(exc_traceback)\n        tb_string = \"\\n\".join(display_lines_list)\n    return tb_string", "response": "Helper function that formats the most recent traceback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookup_path(bin_name):\n    paths = ('/usr/local/sbin/', '/usr/local/bin/', '/usr/sbin/', '/usr/bin/')\n    for p in paths:\n        fq_path = p + bin_name\n        found = os.path.isfile(fq_path) and os.access(fq_path, os.X_OK)\n        if found:\n            return fq_path\n    return False", "response": "Looks for a path to the external binaries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_message_handler(self, message_handlers):\n        encoder = self.options.encoder\n        try:\n            return message_handlers[encoder]\n        except KeyError:\n            raise NotImplementedError('No RequestHandler defined for given encoder (%s).' % encoder)", "response": "Create a MessageHandler for the configured encoder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle(self, event):\n        callback = getattr(self, 'on_{event}'.format(event=event.event), None)\n        callback(event)", "response": "Entry point to handle user events."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbatch = StorageBatch.objects.filter(pk=form.data['batch']).first() if not batch: errors = form._errors.setdefault(\"batch\", ErrorList()) errors.append(_(\"Batch invalid\")) return super(LineAlbaranCreate, self).form_invalid(form)", "response": "def form_valid(self, form):\n        if self.__pk:\n            obj = PurchasesAlbaran.objects.get(pk=self.__pk)\n            self.request.albaran = obj\n            form.instance.albaran = obj\n\n        form.instance.validator_user = self.request.user\n\n        raise Exception(\"revisar StorageBatch\")\n        \"\"\"\n        batch = StorageBatch.objects.filter(pk=form.data['batch']).first()\n        if not batch:\n            errors = form._errors.setdefault(\"batch\", ErrorList())\n            errors.append(_(\"Batch invalid\"))\n            return super(LineAlbaranCreate, self).form_invalid(form)\n        \"\"\"\n\n        # comprueba si el producto comprado requiere un valor de atributo especial\n        product_final = ProductFinal.objects.filter(pk=form.data['product']).first()\n        feature_special_value = None\n        if not product_final:\n            errors = form._errors.setdefault(\"feature_special_value\", ErrorList())\n            errors.append(_(\"Product not selected\"))\n            return super(LineAlbaranCreate, self).form_invalid(form)\n        elif product_final.product.feature_special:\n            # es obligatorio la informacion de caracteristicas especiales\n            if 'feature_special_value' not in form.data or not form.data['feature_special_value']:\n                errors = form._errors.setdefault(\"feature_special_value\", ErrorList())\n                errors.append(_(\"Product needs information of feature special\"))\n                return super(LineAlbaranCreate, self).form_invalid(form)\n            else:\n                feature_special_value = list(set(filter(None, form.data['feature_special_value'].split('\\n'))))\n                try:\n                    quantity = int(float(form.data['quantity']))\n                except ValueError:\n                    errors = form._errors.setdefault(\"quantity\", ErrorList())\n                    errors.append(_(\"Quantity is not valid\"))\n                    return super(LineAlbaranCreate, self).form_invalid(form)\n\n                if product_final.product.feature_special.unique:\n                    # mismo numero de caracteristicas que de cantidades\n                    # si el feature special esta marcado como 'unico'\n                    if len(feature_special_value) != quantity:\n                        errors = form._errors.setdefault(\"feature_special_value\", ErrorList())\n                        errors.append(_(\"Quantity and values of feature special not equals\"))\n                        return super(LineAlbaranCreate, self).form_invalid(form)\n                    # no existen las caracteristicas especiales dadas de alta en el sistema\n                    elif ProductUnique.objects.filter(product_final=product_final, value__in=feature_special_value).exists():\n                        errors = form._errors.setdefault(\"feature_special_value\", ErrorList())\n                        errors.append(_(\"Some value of feature special exists\"))\n                        return super(LineAlbaranCreate, self).form_invalid(form)\n                elif len(feature_special_value) != 1:\n                    errors = form._errors.setdefault(\"feature_special_value\", ErrorList())\n                    errors.append(_(\"The special feature must be unique for all products\"))\n                    return super(LineAlbaranCreate, self).form_invalid(form)\n        try:\n            with transaction.atomic():\n                # save line albaran\n                result = super(LineAlbaranCreate, self).form_valid(form)\n\n                raise Exception(\"Cambiar ProductStock por ProductUnique\")\n                \"\"\"\n                if self.object.status != PURCHASE_ALBARAN_LINE_STATUS_REJECTED:\n                    # prepare stock\n                    ps = ProductStock()\n                    ps.product_final = product_final\n                    ps.line_albaran = self.object\n                    ps.batch = batch\n                    # save stock\n                    ps.quantity = self.object.quantity\n                    ps.save()\n\n                    if feature_special_value:\n                        # prepare product feature special\n                        if product_final.product.feature_special.unique:\n                            pfs = ProductUnique()\n                            pfs.product_final = product_final\n                            # save product featureSpecial and stock\n                            for fs in feature_special_value:\n                                pfs.pk = None\n                                pfs.value = fs\n                                pfs.save()\n\n                        else:\n                            pfs = ProductUnique.objects.filter(\n                                value=feature_special_value[0],\n                                product_final=product_final\n                            ).first()\n                            if pfs:\n                                pfs.stock_real += self.object.quantity\n                            else:\n                                pfs = ProductUnique()\n                                pfs.product_final = product_final\n                                pfs.value = feature_special_value[0]\n                                pfs.stock_real = self.object.quantity\n                            pfs.save()\n                    else:\n                        # product unique by default\n                        pfs = ProductUnique.objects.filter(product_final=product_final).first()\n                        if not pfs:\n                            pfs = ProductUnique()\n                            pfs.product_final = product_final\n                            pfs.stock_real = self.object.quantity\n                        else:\n                            pfs.stock_real += self.object.quantity\n                        pfs.save()\n                \"\"\"\n                return result\n        except IntegrityError as e:\n            errors = form._errors.setdefault(\"product\", ErrorList())\n            errors.append(_(\"Integrity Error: {}\".format(e)))\n            return super(LineAlbaranCreate, self).form_invalid(form)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_form(self, form_class=None):\n        form = super(LineAlbaranUpdate, self).get_form(form_class)\n\n        raise Exception(\"Cambiar ProductStock por ProductUnique\")\n        \"\"\"\n        ps = ProductStock.objects.filter(line_albaran=self.object).first()\n        if ps:\n            # initial field\n            form.fields['storage'].initial = ps.batch.zone.storage\n            form.fields['zone'].initial = ps.batch.zone\n            form.fields['batch'].initial = ps.batch\n        \"\"\"\n        return form", "response": "Returns the form for updating the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the primary mRNA and discard all others.", "response": "def _emplace_pmrna(mrnas, parent, strict=False):\n    \"\"\"Retrieve the primary mRNA and discard all others.\"\"\"\n    mrnas.sort(key=lambda m: (m.cdslen, m.get_attribute('ID')))\n    pmrna = mrnas.pop()\n    if strict:\n        parent.children = [pmrna]\n    else:\n        parent.children = [c for c in parent.children if c not in mrnas]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the primary transcript and discard all others.", "response": "def _emplace_transcript(transcripts, parent):\n    \"\"\"Retrieve the primary transcript and discard all others.\"\"\"\n    transcripts.sort(key=lambda t: (len(t), t.get_attribute('ID')))\n    pt = transcripts.pop()\n    parent.children = [pt]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef primary_mrna(entrystream, parenttype='gene'):\n    for entry in entrystream:\n        if not isinstance(entry, tag.Feature):\n            yield entry\n            continue\n\n        for parent in tag.select.features(entry, parenttype, traverse=True):\n            mrnas = [f for f in parent.children if f.type == 'mRNA']\n            if len(mrnas) == 0:\n                continue\n            _emplace_pmrna(mrnas, parent)\n        yield entry", "response": "Yields all entries that have a single mRNA as a representative for each protein - coding gene."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking for multiple transcript types and if possible select one.", "response": "def _get_primary_type(ttypes, parent, logstream=stderr):\n    \"\"\"Check for multiple transcript types and, if possible, select one.\"\"\"\n    if len(ttypes) > 1:\n        if logstream:  # pragma: no branch\n            message = '[tag::transcript::primary_transcript]'\n            message += ' WARNING: feature {:s}'.format(parent.slug)\n            message += ' has multiple associated transcript types'\n            message += ' {}'.format(ttypes)\n            print(message, file=logstream)\n        if 'mRNA' not in ttypes:\n            message = (\n                'cannot resolve multiple transcript types if \"mRNA\" is'\n                ' not one of those types {}'.format(ttypes)\n            )\n            raise Exception(message)\n        ttypes = ['mRNA']\n    return ttypes[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nselect a single transcript as a representative for each gene. This function is a generalization of the `primary_mrna` function that attempts, under certain conditions, to select a single transcript as a representative for each gene. If a gene encodes multiple transcript types, one of those types must be **mRNA** or the function will complain loudly and fail. For mRNAs, the primary transcript is selected according to translated length. For all other transcript types, the length of the transcript feature itself is used. I'd be eager to hear suggestions for alternative selection criteria. Like the `primary_mrna` function, this function **does not** return only transcript features. It **does** modify gene features to ensure that each has at most one transcript feature. >>> reader = tag.GFF3Reader(tag.pkgdata('psyllid-mixed-gene.gff3.gz')) >>> gene_filter = tag.select.features(reader, type='gene') >>> trans_filter = tag.transcript.primary_transcript(gene_filter) >>> for gene in trans_filter: ... assert gene.num_children == 1 In cases where the direct children of a gene feature have heterogenous types, the `primary_mrna` function will only discard mRNA features. This function, however, will discard all direct children of the gene that are not the primary transcript, including non-transcript children. This is a retty subtle distinction, and anecdotal experience suggests that cases in which the distinction actually matters are extremely rare.", "response": "def primary_transcript(entrystream, parenttype='gene', logstream=stderr):\n    \"\"\"\n    Select a single transcript as a representative for each gene.\n\n    This function is a generalization of the `primary_mrna` function that\n    attempts, under certain conditions, to select a single transcript as a\n    representative for each gene. If a gene encodes multiple transcript types,\n    one of those types must be **mRNA** or the function will complain loudly\n    and fail.\n\n    For mRNAs, the primary transcript is selected according to translated\n    length. For all other transcript types, the length of the transcript\n    feature itself is used. I'd be eager to hear suggestions for alternative\n    selection criteria.\n\n    Like the `primary_mrna` function, this function **does not** return only\n    transcript features. It **does** modify gene features to ensure that each\n    has at most one transcript feature.\n\n    >>> reader = tag.GFF3Reader(tag.pkgdata('psyllid-mixed-gene.gff3.gz'))\n    >>> gene_filter = tag.select.features(reader, type='gene')\n    >>> trans_filter = tag.transcript.primary_transcript(gene_filter)\n    >>> for gene in trans_filter:\n    ...     assert gene.num_children == 1\n\n    In cases where the direct children of a gene feature have heterogenous\n    types, the `primary_mrna` function will only discard mRNA features. This\n    function, however, will discard all direct children of the gene that are\n    not the primary transcript, including non-transcript children. This is a\n    retty subtle distinction, and anecdotal experience suggests that cases in\n    which the distinction actually matters are extremely rare.\n    \"\"\"\n    for entry in entrystream:\n        if not isinstance(entry, tag.Feature):\n            yield entry\n            continue\n\n        for parent in tag.select.features(entry, parenttype, traverse=True):\n            if parent.num_children == 0:\n                continue\n\n            transcripts = defaultdict(list)\n            for child in parent.children:\n                if child.type in type_terms:\n                    transcripts[child.type].append(child)\n\n            if len(transcripts) == 0:\n                continue\n\n            ttypes = list(transcripts.keys())\n            ttype = _get_primary_type(ttypes, parent)\n            transcript_list = transcripts[ttype]\n\n            if ttype == 'mRNA':\n                _emplace_pmrna(transcript_list, parent, strict=True)\n            else:\n                _emplace_transcript(transcript_list, parent)\n\n        yield entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a docname path pick apart and return name of parent", "response": "def parse_parent(docname):\n    \"\"\" Given a docname path, pick apart and return name of parent \"\"\"\n\n    lineage = docname.split('/')\n    lineage_count = len(lineage)\n\n    if docname == 'index':\n        # This is the top of the Sphinx project\n        parent = None\n    elif lineage_count == 1:\n        # This is a non-index doc in root, e.g. about\n        parent = 'index'\n    elif lineage_count == 2 and lineage[-1] == 'index':\n        # This is blog/index, parent is the root\n        parent = 'index'\n    elif lineage_count == 2:\n        # This is blog/about\n        parent = lineage[0] + '/index'\n    elif lineage[-1] == 'index':\n        # This is blog/sub/index\n        parent = '/'.join(lineage[:-2]) + '/index'\n    else:\n        # This should be blog/sub/about\n        parent = '/'.join(lineage[:-1]) + '/index'\n\n    return parent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit the path in name and get parents", "response": "def parents(self, resources):\n        \"\"\" Split the path in name and get parents \"\"\"\n\n        if self.docname == 'index':\n            # The root has no parents\n            return []\n        parents = []\n        parent = resources.get(self.parent)\n        while parent is not None:\n            parents.append(parent)\n            parent = resources.get(parent.parent)\n        return parents"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a list of resources and a property name return the ID of the property that was acquired.", "response": "def acquire(self, resources, prop_name):\n        \"\"\" Starting with self, walk until you find prop or None \"\"\"\n\n        # Instance\n        custom_prop = getattr(self.props, prop_name, None)\n        if custom_prop:\n            return custom_prop\n\n        # Parents...can't use acquire as have to keep going on acquireds\n        for parent in self.parents(resources):\n            acquireds = parent.props.acquireds\n            if acquireds:\n                # First try in the per-type acquireds\n                rtype_acquireds = acquireds.get(self.rtype)\n                if rtype_acquireds:\n                    prop_acquired = rtype_acquireds.get(prop_name)\n                    if prop_acquired:\n                        return prop_acquired\n\n                # Next in the \"all\" section of acquireds\n                all_acquireds = acquireds.get('all')\n                if all_acquireds:\n                    prop_acquired = all_acquireds.get(prop_name)\n                    if prop_acquired:\n                        return prop_acquired\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the template from YAML hierarchy or class", "response": "def template(self, resources):\n        \"\"\" Get the template from: YAML, hierarchy, or class \"\"\"\n\n        template_name = self.acquire(resources, 'template')\n        if template_name:\n            return template_name\n        else:\n            # We're putting an exception for \"resource\", the built-in\n            # rtype/directive. We want it to work out-of-the-box without\n            # requiring an _templates/resource.html in the docs project.\n            # Instead, use the page.html the ships with Sphinx.\n            if self.rtype == 'resource':\n                return 'page'\n            else:\n                return self.rtype"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlook for a list prop with an item where key == value", "response": "def find_prop_item(self, prop_name, prop_key, prop_value):\n        \"\"\" Look for a list prop with an item where key == value \"\"\"\n        # Image props are a sequence of dicts. We often need one of them.\n        # Where one of the items has a dict key matching a value, and if\n        # nothing matches, return None\n\n        prop = getattr(self.props, prop_name, None)\n        if prop:\n            return next(\n                (p for p in prop\n                 if getattr(p, prop_key) == prop_value),\n                None\n            )\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default() :\n\t\tif Shaman._default_instance is not None :\n\t\t\treturn Shaman._default_instance\n\n\t\twith open((os.path.dirname(__file__) or '.') + '/data/trained.json') as file :\n\t\t\ttset = json.loads(file.read())\n\n\t\tShaman._default_instance = Shaman(tset)\n\t\treturn Shaman._default_instance", "response": "Get default shaman instance by data. json"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect language with code", "response": "def detect(self, code) :\n\t\t\"\"\" Detect language with code\n\t\t\"\"\"\n\t\t\n\t\tkeywords = KeywordFetcher.fetch( code )\n\t\tprobabilities = {}\n\n\t\tfor keyword in keywords :\n\t\t\tif keyword not in self.trained_set['keywords'] :\n\t\t\t\tcontinue\n\n\t\t\tdata = self.trained_set['keywords'][keyword]\n\t\t\tp_avg = sum(data.values()) / len(data) # Average probability of all languages\n\n\t\t\tfor language, probability in data.items() :\n\t\t\t\t# By Na\u00efve Bayes Classification\n\t\t\t\tp = probability / p_avg\n\n\t\t\t\tprobabilities[ language ] = probabilities.get(language, 0) + math.log(1 + p)\n\n\n\t\tfor pattern, data in self.trained_set['patterns'].items() :\n\t\t\tmatcher = PatternMatcher(pattern)\n\t\t\tp0 = matcher.getratio(code)\n\t\t\t\n\t\t\tfor language, p_avg in data.items() :\n\t\t\t\tif language not in probabilities :\n\t\t\t\t\tcontinue\n\n\t\t\t\tp = 1 - abs(p_avg - p0)\n\t\t\t\tprobabilities[ language ] *= p\n\t\t\t\t\n\n\t\t# Convert `log` operated probability to percentile\n\t\tsum_val = 0\n\t\tfor language, p in probabilities.items() :\n\t\t\tsum_val += math.pow(math.e / 2, p)\n\n\t\tfor language, p in probabilities.items() :\n\t\t\tprobabilities[language] = math.pow(math.e / 2, p) / sum_val * 100\n\n\t\treturn sorted(probabilities.items(), key=lambda a: a[1], reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching keywords by Code", "response": "def fetch(code) :\n\t\t\"\"\" Fetch keywords by Code\n\t\t\"\"\"\n\t\tret = {}\n\n\t\tcode = KeywordFetcher._remove_strings(code)\n\t\tresult = KeywordFetcher.prog.findall(code)\n\n\t\tfor keyword in result :\n\t\t\tif len(keyword) <= 1: continue # Ignore single-length word\n\t\t\tif keyword.isdigit(): continue # Ignore number\n\n\t\t\tif keyword[0] == '-' or keyword[0] == '*' : keyword = keyword[1:] # Remove first char if string is starting by '-' or '*' (Pointer or Negative numbers)\n\t\t\tif keyword[-1] == '-' or keyword[-1] == '*' : keyword = keyword[0:-1] # Remove last char if string is finished by '-' or '*'\n\n\t\t\tif len(keyword) <= 1: continue\n\n\t\t\tret[ keyword ] = ret.get(keyword, 0) + 1 # `ret[ keyword ] += 1` with initial value\n\n\t\treturn ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove strings in code", "response": "def _remove_strings(code) :\n\t\t\"\"\" Remove strings in code\n\t\t\"\"\"\n\t\tremoved_string = \"\"\n\t\tis_string_now = None\n\t\t\n\t\tfor i in range(0, len(code)-1) :\n\t\t\tappend_this_turn = False\n\n\t\t\tif code[i] == \"'\" and (i == 0 or code[i-1] != '\\\\') :\n\t\t\t\tif is_string_now == \"'\" :\n\t\t\t\t\tis_string_now = None\n\n\t\t\t\telif is_string_now == None :\n\t\t\t\t\tis_string_now = \"'\"\n\t\t\t\t\tappend_this_turn = True\n\n\t\t\telif code[i] == '\"' and (i == 0 or code[i-1] != '\\\\') :\n\t\t\t\tif is_string_now == '\"' :\n\t\t\t\t\tis_string_now = None\n\n\t\t\t\telif is_string_now == None :\n\t\t\t\t\tis_string_now = '\"'\n\t\t\t\t\tappend_this_turn = True\n\n\n\t\t\tif is_string_now == None or append_this_turn == True :\n\t\t\t\tremoved_string += code[i]\n\n\t\treturn removed_string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getratio(self, code) :\n\t\tif len(code) == 0 : return 0\n\n\t\tcode_replaced = self.prog.sub('', code)\n\t\treturn (len(code) - len(code_replaced)) / len(code)", "response": "Get ratio of code and pattern matched\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads an XML property that is a child of the root data being loaded.", "response": "def loadXmlProperty(self, xprop):\n        \"\"\"\n        Loads an XML property that is a child of the root data being loaded.\n\n        :param      xprop | <xml.etree.ElementTree.Element>\n        \"\"\"\n        if xprop.tag == 'property':\n            value = self.dataInterface().fromXml(xprop[0])\n            self._xmlData[xprop.get('name', '')] = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert this object to XML.", "response": "def toXml(self, xparent=None):\n        \"\"\"\n        Converts this object to XML.\n\n        :param      xparent | <xml.etree.ElementTree.Element> || None\n\n        :return     <xml.etree.ElementTree.Element>\n        \"\"\"\n        if xparent is None:\n            xml = ElementTree.Element('object')\n        else:\n            xml = ElementTree.SubElement(xparent, 'object')\n\n        xml.set('class', self.__class__.__name__)\n        for name, value in self._xmlData.items():\n            xprop = ElementTree.SubElement(xml, 'property')\n            xprop.set('name', name)\n            XmlDataIO.toXml(value, xprop)\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fromXml(cls, xml):\n        clsname = xml.get('class')\n        if clsname:\n            subcls = XmlObject.byName(clsname)\n            if subcls is None:\n                inst = MissingXmlObject(clsname)\n            else:\n                inst = subcls()\n        else:\n            inst = cls()\n\n        inst.loadXml(xml)\n        return inst", "response": "Restores an object from XML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the inputted element to a Python object by looking through the IO addons for the element s tag and then loading it into a Python object.", "response": "def fromXml(cls, elem):\n        \"\"\"\n        Converts the inputted element to a Python object by looking through\n        the IO addons for the element's tag.\n        \n        :param      elem | <xml.etree.ElementTree.Element>\n        \n        :return     <variant>\n        \"\"\"\n        if elem is None:\n            return None\n\n        addon = cls.byName(elem.tag)\n        if not addon:\n            raise RuntimeError('{0} is not a supported XML tag'.format(elem.tag))\n\n        return addon.load(elem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the inputted element to a Python object by looking through the IO addons for the element s tag and then saving it to the XML file.", "response": "def toXml(cls, data, xparent=None):\n        \"\"\"\n        Converts the inputted element to a Python object by looking through\n        the IO addons for the element's tag.\n        \n        :param      data     | <variant>\n                    xparent | <xml.etree.ElementTree.Element> || None\n        \n        :return     <xml.etree.ElementTree.Element>\n        \"\"\"\n        if data is None:\n            return None\n\n        # store XmlObjects separately from base types\n        if isinstance(data, XmlObject):\n            name = 'object'\n        else:\n            name = type(data).__name__\n\n        addon = cls.byName(name)\n        if not addon:\n            raise RuntimeError('{0} is not a supported XML tag'.format(name))\n\n        return addon.save(data, xparent)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the data into the XML element tree.", "response": "def save(self, data, xparent=None):\n        \"\"\"\n        Parses the element from XML to Python.\n        \n        :param      data    | <variant>\n                    xparent | <xml.etree.ElementTree.Element> || None\n        \n        :return     <xml.etree.ElementTree.Element>\n        \"\"\"\n        if xparent is not None:\n            elem = ElementTree.SubElement(xparent, 'bool')\n        else:\n            elem = ElementTree.Element('bool')\n\n        elem.text = nstr(data)\n        return elem"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the inputted dict tag to Python.", "response": "def load(self, elem):\n        \"\"\"\n        Converts the inputted dict tag to Python.\n        \n        :param      elem | <xml.etree.ElementTree>\n        \n        :return     <dict>\n        \"\"\"\n        self.testTag(elem, 'dict')\n\n        out = {}\n        for xitem in elem:\n            key = xitem.get('key')\n            try:\n                value = XmlDataIO.fromXml(xitem[0])\n            except IndexError:\n                value = None\n            out[key] = value\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the dictionary to XML.", "response": "def save(self, data, xparent=None):\n        \"\"\"\n        Parses the element from XML to Python.\n        \n        :param      data    | <variant>\n                    xparent | <xml.etree.ElementTree.Element> || None\n        \n        :return     <xml.etree.ElementTree.Element>\n        \"\"\"\n        if xparent is not None:\n            elem = ElementTree.SubElement(xparent, 'dict')\n        else:\n            elem = ElementTree.Element('dict')\n\n        for key, value in sorted(data.items()):\n            xitem = ElementTree.SubElement(elem, 'item')\n            xitem.set('key', nstr(key))\n            XmlDataIO.toXml(value, xitem)\n\n        return elem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the inputted list tag to Python.", "response": "def load(self, elem):\n        \"\"\"\n        Converts the inputted list tag to Python.\n        \n        :param      elem | <xml.etree.ElementTree>\n        \n        :return     <list>\n        \"\"\"\n        self.testTag(elem, 'list')\n        out = []\n        for xitem in elem:\n            out.append(XmlDataIO.fromXml(xitem))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the XML data to a Python list element.", "response": "def save(self, data, xparent=None):\n        \"\"\"\n        Parses the element from XML to Python.\n        \n        :param      data    | <variant>\n                    xparent | <xml.etree.ElementTree.Element> || None\n        \n        :return     <xml.etree.ElementTree.Element>\n        \"\"\"\n        if xparent is not None:\n            elem = ElementTree.SubElement(xparent, 'list')\n        else:\n            elem = ElementTree.Element('list')\n\n        for item in data:\n            XmlDataIO.toXml(item, elem)\n\n        return elem"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the inputted set tag to Python.", "response": "def load(self, elem):\n        \"\"\"\n        Converts the inputted set tag to Python.\n        \n        :param      elem | <xml.etree.ElementTree>\n        \n        :return     <set>\n        \"\"\"\n        self.testTag(elem, 'set')\n        out = set()\n        for xitem in elem:\n            out.add(XmlDataIO.fromXml(xitem))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the inputted string tag to Python.", "response": "def load(self, elem):\n        \"\"\"\n        Converts the inputted string tag to Python.\n        \n        :param      elem | <xml.etree.ElementTree>\n        \n        :return     <str>\n        \"\"\"\n        self.testTag(elem, 'str')\n        return elem.text if elem.text is not None else ''"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef template_substitute(text, **kwargs):\n    for name, value in kwargs.items():\n        placeholder_pattern = \"{%s}\" % name\n        if placeholder_pattern in text:\n            text = text.replace(placeholder_pattern, value)\n    return text", "response": "Replace placeholders in text by using the data mapping."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves empty lines from a string.", "response": "def text_remove_empty_lines(text):\n    \"\"\"\n    Whitespace normalization:\n\n      - Strip empty lines\n      - Strip trailing whitespace\n    \"\"\"\n    lines = [ line.rstrip()  for line in text.splitlines()  if line.strip() ]\n    return \"\\n\".join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text_normalize(text):\n    # if not isinstance(text, str):\n    if isinstance(text, bytes):\n        # -- MAYBE: command.ouput => bytes, encoded stream output.\n        text = codecs.decode(text)\n    lines = [ line.strip()  for line in text.splitlines()  if line.strip() ]\n    return \"\\n\".join(lines)", "response": "Whitespace normalization:\n\n      - Strip empty lines\n      - Strip leading whitespace  in a line\n      - Strip trailing whitespace in a line\n      - Normalize line endings"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wva(values, weights):\n        assert len(values) == len(weights) and len(weights) > 0\n        return sum([mul(*x) for x in zip(values, weights)]) / sum(weights)", "response": "Calculates a weighted average of the values and weights"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mode_interactive(options):\n    articles = set()\n    failures = set()\n\n    url = input('Enter a URL: ')\n    while url != '':\n        article = _get_article(url=url, bodyLines=options.bodyLines, debug=options.debug)\n        if (article):\n            articles.add(article)\n        else:\n            failures.add(url)\n        url = input('Enter a URL (press enter to end): ')\n\n    _output(articles, options.outputFile, failures, options.failureFile)", "response": "Interactive mode for fetching a list of articles from the server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mode_clipboard_watch(options):\n    articles = set()\n    failures = set()\n\n    print('Hello, this is news-scraper. Copy a URL to start!')\n    print('To quit, press CTRL+C in this window.\\n')\n    url = pyperclip.paste()\n    while True:\n        try:\n            tmp_value = pyperclip.paste()\n            if tmp_value != url:\n                url = tmp_value\n                print('Fetching article...')\n                if options.debug:\n                    print(\"Value changed: %s\" % str(url)[:100])\n\n                article = _get_article(url=url, bodyLines=options.bodyLines, debug=options.debug)\n                if (article):\n                    articles.add(article)\n                else:\n                    failures.add(url)\n                    time.sleep(0.2)\n        except KeyboardInterrupt:\n            break\n\n    _output(articles, options.outputFile, failures, options.failureFile)", "response": "Watch for a new string on the clipboard and fetch it"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_one_to_many_job(parent_class=None,\n                            get_unfinished_kwargs=None,\n                            get_unfinished_limit=None,\n                            parser_func=None,\n                            parser_func_kwargs=None,\n                            build_url_func_kwargs=None,\n                            downloader_func=None,\n                            downloader_func_kwargs=None,\n                            post_process_response_func=None,\n                            post_process_response_func_kwargs=None,\n                            process_item_func_kwargs=None,\n                            logger=None,\n                            sleep_time=None):\n    \"\"\"\n    A standard one-to-many crawling workflow.\n\n    :param parent_class:\n    :param get_unfinished_kwargs:\n    :param get_unfinished_limit:\n    :param parser_func: html parser function.\n    :param parser_func_kwargs: other keyword arguments for ``parser_func``\n    :param build_url_func_kwargs: other keyword arguments for\n        ``parent_class().build_url(**build_url_func_kwargs)``\n    :param downloader_func: a function that taking ``url`` as first arg, make\n        http request and return response/html.\n    :param downloader_func_kwargs: other keyword arguments for ``downloader_func``\n    :param post_process_response_func: a callback function taking response/html\n        as first argument. You can put any logic in it. For example, you can\n        make it sleep if you detect that you got banned.\n    :param post_process_response_func_kwargs: other keyword arguments for\n        ``post_process_response_func``\n    :param process_item_func_kwargs: other keyword arguments for\n        ``ParseResult().process_item(**process_item_func_kwargs)``\n    :param logger:\n    :param sleep_time: default 0, wait time before making each request.\n    \"\"\"\n    # prepare arguments\n    get_unfinished_kwargs = prepare_kwargs(get_unfinished_kwargs)\n    parser_func_kwargs = prepare_kwargs(parser_func_kwargs)\n    build_url_func_kwargs = prepare_kwargs(build_url_func_kwargs)\n    downloader_func_kwargs = prepare_kwargs(downloader_func_kwargs)\n    post_process_response_func_kwargs = prepare_kwargs(\n        post_process_response_func_kwargs)\n    process_item_func_kwargs = prepare_kwargs(process_item_func_kwargs)\n\n    if post_process_response_func is None:\n        def post_process_response_func(response, **kwargs):\n            pass\n\n    if not isinstance(logger, SpiderLogger):\n        raise TypeError\n\n    if sleep_time is None:\n        sleep_time = 0\n\n    # do the real job\n    query_set = parent_class.get_all_unfinished(**get_unfinished_kwargs)\n    if get_unfinished_limit is not None:\n        query_set = query_set.limit(get_unfinished_limit)\n    todo = list(query_set)\n    logger.log_todo_volumn(todo)\n\n    for parent_instance in todo:\n        url = parent_instance.build_url(**build_url_func_kwargs)\n        logger.log_to_crawl_url(url)\n\n        logger.log_sleeper(sleep_time)\n        time.sleep(sleep_time)\n\n        try:\n            response_or_html = downloader_func(url, **downloader_func_kwargs)\n            if isinstance(response_or_html, string_types):\n                parser_func_kwargs[\"html\"] = response_or_html\n            else:\n                parser_func_kwargs[\"response\"] = response_or_html\n            post_process_response_func(\n                response_or_html, **post_process_response_func_kwargs)\n        except Exception as e:\n            logger.log_error(e)\n            continue\n\n        try:\n            parse_result = parser_func(\n                parent=parent_instance,\n                **parser_func_kwargs\n            )\n            parse_result.process_item(**process_item_func_kwargs)\n            logger.log_status(parse_result)\n        except Exception as e:\n            logger.log_error(e)\n            continue", "response": "This function executes a single one - to - many crawling job."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse psycopg2 consumable connection string into a dictionary with connection string parts.", "response": "def parse_connection_string_psycopg2(connection_string):\n    \"\"\"\n    parses psycopg2 consumable connection string\n    :param connection_string:\n    :return: return dictionary with connection string parts\n    \"\"\"\n    conn_prepared = {}\n    conn_parsed = urlparse(connection_string)\n    if not conn_parsed.hostname:\n        _re_dbstr = re.compile(r'\\bhost=(?P<host>[0-9a-zA-Z_.!@#$%^&*()~]+)|'\n                               r'dbname=(?P<dbname>[0-9a-zA-Z_.!@#$%^&*()~]+)|'\n                               r'port=(?P<port>[0-9a-zA-Z_.!@#$%^&*()~]+)|'\n                               r'user=(?P<user>[0-9a-zA-Z_.!@#$%^&*()~]+)|'\n                               r'password=(?P<password>[0-9a-zA-Z_.!@#$%^&*()~]+)\\b', re.IGNORECASE)\n        for match in _re_dbstr.finditer(connection_string):\n            match_dict = match.groupdict()\n            if match_dict['host']:\n                conn_prepared['host'] = match_dict['host']\n            if match_dict['port']:\n                conn_prepared['port'] = match_dict['port']\n            if match_dict['dbname']:\n                conn_prepared['dbname'] = match_dict['dbname']\n            if match_dict['user']:\n                conn_prepared['user'] = match_dict['user']\n            if match_dict['password']:\n                conn_prepared['password'] = match_dict['password']\n    else:\n        conn_prepared = {\n            'host': conn_parsed.hostname,\n            'port': conn_parsed.port,\n            'dbname': conn_parsed.path,\n            'user': conn_parsed.username,\n            'password': conn_parsed.password\n        }\n\n    return conn_prepared"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pgpm_db_version(cls, cur, schema_name='_pgpm'):\n        cls.set_search_path(cur, schema_name)\n        cur.execute(\"SELECT _find_schema('{0}', '{1}')\"\n                    .format(schema_name, 'x'))\n        # TODO: make it work with the way it's written below. currently throws error as func returns record\n        # without column list\n        # cur.callproc('_find_schema', [schema_name, 'x'])\n        pgpm_v_ext = tuple(cur.fetchone()[0][1:-1].split(','))\n\n        return pgpm_v_ext[2], pgpm_v_ext[3], pgpm_v_ext[4]", "response": "returns current version of pgpm schema\n        returns tuple of major minor and patch components of version\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_db_schema(cls, cur, schema_name):\n        create_schema_script = \"CREATE SCHEMA {0} ;\\n\".format(schema_name)\n        cur.execute(create_schema_script)", "response": "Create Postgres schema script and execute it on cursor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grant_usage_privileges(cls, cur, schema_name, roles):\n        cur.execute('GRANT USAGE ON SCHEMA {0} TO {1};'\n                    'GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA {0} TO {1};'\n                    .format(schema_name, roles))", "response": "Grant usage privileges to all functions in schema_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef grant_usage_install_privileges(cls, cur, schema_name, roles):\n        cur.execute('GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA {0} TO {1};'\n                    'GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA {0} TO {1};'\n                    'GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA {0} TO {1};'\n                    .format(schema_name, roles))", "response": "Grant usage install privileges to the given schema."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grant_default_usage_install_privileges(cls, cur, schema_name, roles):\n        cur.execute('ALTER DEFAULT PRIVILEGES IN SCHEMA {0} '\n                    'GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO {1};'\n                    'ALTER DEFAULT PRIVILEGES IN SCHEMA {0} GRANT EXECUTE ON FUNCTIONS TO {1};'\n                    'ALTER DEFAULT PRIVILEGES IN SCHEMA {0} '\n                    'GRANT USAGE, SELECT ON SEQUENCES TO {1};'\n                    .format(schema_name, roles))", "response": "Grant default usage install privileges to the schema."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrevoking all privileges from schema tables sequences and functions for a specific role", "response": "def revoke_all(cls, cur, schema_name, roles):\n        \"\"\"\n        Revoke all privileges from schema, tables, sequences and functions for a specific role\n        \"\"\"\n        cur.execute('REVOKE ALL ON SCHEMA {0} FROM {1};'\n                    'REVOKE ALL ON ALL TABLES IN SCHEMA {0} FROM {1};'\n                    'REVOKE ALL ON ALL SEQUENCES IN SCHEMA {0} FROM {1};'\n                    'REVOKE ALL ON ALL FUNCTIONS IN SCHEMA {0} FROM {1};'.format(schema_name, roles))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schema_exists(cls, cur, schema_name):\n        cur.execute(\"SELECT EXISTS (SELECT schema_name FROM information_schema.schemata WHERE schema_name = '{0}');\"\n                    .format(schema_name))\n        return cur.fetchone()[0]", "response": "Check if schema exists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pandas(self):\n        if self._pandas is None:\n            self._pandas = pd.DataFrame().from_records(self.list_of_dicts)\n        return self._pandas", "response": "Return a Pandas dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate(self, dialect):\n        new_resultset = copy(self)\n        new_resultset.dialect = dialect\n\n        for result in new_resultset:\n            for dimensionvalue in result.dimensionvalues:\n                dimensionvalue.value = dimensionvalue.translate(dialect)\n        return new_resultset", "response": "Return a copy of this ResultSet in a different dialect."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects any new results to the resultset.", "response": "def append(self, val):\n        \"\"\"Connect any new results to the resultset.\n\n        This is where all the heavy lifting is done for creating results:\n         - We add a datatype here, so that each result can handle\n        validation etc independently. This is so that scraper authors\n        don't need to worry about creating and passing around datatype objects.\n         - As the scraper author yields result objects, we append them to\n        a resultset.\n         - This is also where we normalize dialects.\n        \"\"\"\n        val.resultset = self\n        val.dataset = self.dataset\n\n        # Check result dimensions against available dimensions for this dataset\n        if val.dataset:\n            dataset_dimensions = self.dataset.dimensions\n            for k, v in val.raw_dimensions.items():\n                if k not in dataset_dimensions:\n                    d = Dimension(k)\n                else:\n                    d = dataset_dimensions[k]\n\n                # Normalize if we have a datatype and a foreign dialect\n                normalized_value = unicode(v)\n                if d.dialect and d.datatype:\n                    if d.dialect in d.datatype.dialects:\n                        for av in d.allowed_values:\n                            # Not all allowed_value have all dialects\n                            if unicode(v) in av.dialects.get(d.dialect, []):\n                                normalized_value = av.value\n                                # Use first match\n                                # We do not support multiple matches\n                                # This is by design.\n                                break\n\n                # Create DimensionValue object\n                if isinstance(v, DimensionValue):\n                    dim = v\n                    v.value = normalized_value\n                else:\n                    if k in dataset_dimensions:\n                        dim = DimensionValue(normalized_value, d)\n                    else:\n                        dim = DimensionValue(normalized_value, Dimension())\n\n                val.dimensionvalues.append(dim)\n\n            # Add last list of dimension values to the ResultSet\n            # They will usually be the same for each result\n            self.dimensionvalues = val.dimensionvalues\n\n        super(ResultSet, self).append(val)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef allowed_values(self):\n        if self._allowed_values is None:\n            self._allowed_values = ValueList()\n            for val in self.scraper._fetch_allowed_values(self):\n                if isinstance(val, DimensionValue):\n                    self._allowed_values.append(val)\n                else:\n                    self._allowed_values.append(DimensionValue(val,\n                                                               Dimension()))\n        return self._allowed_values", "response": "Return a list of allowed values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append(self, val):\n        val.scraper = self.scraper\n        val._collection_path = copy(self.collection._collection_path)\n        val._collection_path.append(val)\n        super(ItemList, self).append(val)", "response": "Connect any new items to the scraper."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _move_here(self):\n        cu = self.scraper.current_item\n        # Already here?\n        if self is cu:\n            return\n        # A child?\n        if cu.items and self in cu.items:\n            self.scraper.move_to(self)\n            return\n        # A parent?\n        if self is cu.parent:\n            self.scraper.move_up()\n        # A sibling?\n        if self.parent and self in self.parent.items:\n            self.scraper.move_up()\n            self.scraper.move_to(self)\n            return\n        # Last resort: Move to top and all the way down again\n        self.scraper.move_to_top()\n        for step in self.path:\n            self.scraper.move_to(step)", "response": "Move the cursor to this item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a hash for the current query.", "response": "def _hash(self):\n        \"\"\"Return a hash for the current query.\n\n        This hash is _not_ a unique representation of the dataset!\n        \"\"\"\n        dump = dumps(self.query, sort_keys=True)\n        if isinstance(dump, str):\n            dump = dump.encode('utf-8')\n        return md5(dump).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of Dimension objects for this dataset.", "response": "def dimensions(self):\n        \"\"\"Available dimensions, if defined.\"\"\"\n        # First of all: Select this dataset\n        if self.scraper.current_item is not self:\n            self._move_here()\n\n        if self._dimensions is None:\n            self._dimensions = DimensionList()\n            for d in self.scraper._fetch_dimensions(self):\n                d.dataset = self\n                d.scraper = self.scraper\n                self._dimensions.append(d)\n        return self._dimensions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shape(self):\n        if not self.data:\n            return (0, 0)\n        return (len(self.data), len(self.dimensions))", "response": "Compute the shape of the dataset as ( rows cols )."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on(cls, hook):\n        def decorator(function_):\n            cls._hooks[hook].append(function_)\n            return function_\n        return decorator", "response": "Decorator to add a hook to the class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving to the top item.", "response": "def move_to_top(self):\n        \"\"\"Move to root item.\"\"\"\n        self.current_item = self.root\n        for f in self._hooks[\"top\"]:\n            f(self)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_up(self):\n        if self.current_item.parent is not None:\n            self.current_item = self.current_item.parent\n\n        for f in self._hooks[\"up\"]:\n            f(self)\n        if self.current_item is self.root:\n            for f in self._hooks[\"top\"]:\n                f(self)\n        return self", "response": "Move up one level in the hierarchy unless already on top."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_to(self, id_):\n        if self.items:\n            try:\n                self.current_item = self.items[id_]\n            except (StopIteration, IndexError, NoSuchItem):\n                raise NoSuchItem\n            for f in self._hooks[\"select\"]:\n                f(self, id_)\n        return self", "response": "Select a child item by id ( str reference or index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef descendants(self):\n        for i in self.current_item.items:\n            self.move_to(i)\n            if i.type == TYPE_COLLECTION:\n                for c in self.children:\n                    yield c\n            else:\n                yield i\n            self.move_up()", "response": "Recursively return every dataset below current item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforming misleading name for descendants.", "response": "def children(self):\n        \"\"\"Former, misleading name for descendants.\"\"\"\n        from warnings import warn\n        warn(\"Deprecated. Use Scraper.descendants.\", DeprecationWarning)\n        for descendant in self.descendants:\n            yield descendant"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unicode string that can be used as a legal python identifier.", "response": "def make_python_name(s, default=None, number_prefix='N',encoding=\"utf-8\"):\n    \"\"\"Returns a unicode string that can be used as a legal python identifier.\n\n    :Arguments:\n      *s*\n         string\n      *default*\n         use *default* if *s* is ``None``\n      *number_prefix*\n         string to prepend if *s* starts with a number\n    \"\"\"\n    if s in ('', None):\n        s = default\n    s = str(s)\n    s = re.sub(\"[^a-zA-Z0-9_]\", \"_\", s)\n    if not re.match('\\d', s) is None:\n        s = number_prefix+s\n    return unicode(s, encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn data as numpy. recarray.", "response": "def recarray(self):\n        \"\"\"Returns data as :class:`numpy.recarray`.\"\"\"\n        return numpy.rec.fromrecords(self.records, names=self.names)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ningest the contents of the directory of yaml files into a database", "response": "def ingest(self):\n        \"\"\"\n        *ingest the contents of the directory of yaml files into a database*\n\n        **Return:**\n            - None\n\n        **Usage:**\n\n            To import an entire directory of yaml files into a database, use the following:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import yaml_to_database\n            yaml2db = yaml_to_database(\n                log=log,\n                settings=settings,\n                dbConn=dbConn,\n                pathToInputDir=\"/path/to/yaml/directory\",\n                deleteFiles=False\n            ) \n            yaml2db.ingest() \n        \"\"\"\n        self.log.debug('starting the ``ingest`` method')\n\n        for d in os.listdir(self.pathToInputDir):\n            if os.path.isfile(os.path.join(self.pathToInputDir, d)) and \"yaml\" in d.lower():\n                self.add_yaml_file_content_to_database(\n                    filepath=os.path.join(self.pathToInputDir, d),\n                    deleteFile=self.deleteFiles\n                )\n\n        self.log.debug('completed the ``ingest`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data_type(self, data_type):\n        allowed_values = [\"string\", \"number\", \"date\", \"color\"]\n        if data_type is not None and data_type not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `data_type` ({0}), must be one of {1}\"\n                .format(data_type, allowed_values)\n            )\n\n        self._data_type = data_type", "response": "Sets the data_type of this Option."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_option(cls, option, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_option_with_http_info(option, **kwargs)\n        else:\n            (data) = cls._create_option_with_http_info(option, **kwargs)\n            return data", "response": "Create Option\n\n        Create a new Option\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_option(option, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Option option: Attributes of option to create (required)\n        :return: Option\n                 If the method is called asynchronously,\n                 returns the request thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete an instance of Option by its ID.", "response": "def delete_option_by_id(cls, option_id, **kwargs):\n        \"\"\"Delete Option\n\n        Delete an instance of Option by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_option_by_id(option_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_id: ID of option to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_option_by_id_with_http_info(option_id, **kwargs)\n        else:\n            (data) = cls._delete_option_by_id_with_http_info(option_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind Option by its ID Return single instance of Option by its ID.", "response": "def get_option_by_id(cls, option_id, **kwargs):\n        \"\"\"Find Option\n\n        Return single instance of Option by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_option_by_id(option_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_id: ID of option to return (required)\n        :return: Option\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_option_by_id_with_http_info(option_id, **kwargs)\n        else:\n            (data) = cls._get_option_by_id_with_http_info(option_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists Options AttributeNames This method returns a list of Options AttributeNames", "response": "def list_all_options(cls, **kwargs):\n        \"\"\"List Options\n\n        Return a list of Options\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_options(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Option]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_options_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_options_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing all attributes of an option in the option store.", "response": "def replace_option_by_id(cls, option_id, option, **kwargs):\n        \"\"\"Replace Option\n\n        Replace all attributes of Option\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_option_by_id(option_id, option, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_id: ID of option to replace (required)\n        :param Option option: Attributes of option to replace (required)\n        :return: Option\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_option_by_id_with_http_info(option_id, option, **kwargs)\n        else:\n            (data) = cls._replace_option_by_id_with_http_info(option_id, option, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_option_by_id(cls, option_id, option, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_option_by_id_with_http_info(option_id, option, **kwargs)\n        else:\n            (data) = cls._update_option_by_id_with_http_info(option_id, option, **kwargs)\n            return data", "response": "Update Option by ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_callable_signature_as_string(the_callable):\n    args, varargs, varkw, defaults = inspect.getargspec(the_callable)\n    tmp_args = list(args)\n    args_dict = {}\n    if defaults:\n        defaults = list(defaults)\n    else:\n        defaults = []\n    while defaults:\n        args_dict[tmp_args.pop()] = defaults.pop()\n\n    while tmp_args:\n        args_dict[tmp_args.pop()] = None\n\n    args_list = []\n    for arg in args:\n        if args_dict[arg] is not None:\n            args_list.append(\"%s=%s\" % (arg, repr(args_dict[arg])))\n        else:\n            args_list.append(arg)\n\n    if varargs:\n        args_list.append(\"*%s\" % varargs)\n\n    if varkw:\n        args_list.append(\"**%s\" % varkw)\n\n    args_string = ', '.join(args_list)\n\n    return \"def %s(%s)\" % (the_callable.__name__, args_string)", "response": "Return a string representing a callable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_callable_documentation(the_callable):\n    return wrap_text_in_a_box(\n        title=get_callable_signature_as_string(the_callable),\n        body=(getattr(the_callable, '__doc__') or 'No documentation').replace(\n            '\\n', '\\n\\n'),\n        style='ascii_double')", "response": "Return a string with the callable signature and its docstring."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_extension_method(ext, base, *args, **kwargs):\n    bound_method = create_bound_method(ext.plugin, base)\n    setattr(base, ext.name.lstrip('_'), bound_method)", "response": "Register the given extension method as a public attribute of the given base."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef token_auto_auth(func):\n\n    @functools.wraps(func)\n    def wrapper(self, *args, **kwargs):\n        try:\n            response = func(self, *args, **kwargs)\n\n        # If auth failure occurs, attempt to re-authenticate and replay once at most.\n        except errors.AuthFailure:\n\n            # Request to have authentication refreshed.\n            self._client.auth._refresh()\n\n            # Replay original request.\n            response = func(self, *args, **kwargs)\n\n        return response\n\n    # TODO(TheDodd): match func call signature and docs.\n    return wrapper", "response": "Decorator for token auto - authentication."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the user authentication.", "response": "def check_auth(args, role=None):\n    \"\"\"Check the user authentication.\"\"\"\n    users = boto3.resource(\"dynamodb\").Table(os.environ['people'])\n    if not (args.get('email', None) and args.get('api_key', None)):\n        mesg = \"Invalid request: `email` and `api_key` are required\"\n        return {'success': False, 'message': mesg}\n    user = users.get_item(Key={'email': args.get('email')})\n    if 'Item' not in user:\n        return {'success': False, 'message': 'User does not exist.'}\n    user = user['Item']\n    if user['api_key'] != args['api_key']:\n        return {'success': False, 'message': 'API key was invalid.'}\n    if role:\n        if user['role'] not in role:\n            mesg = 'User is not authorized to make this change.'\n            return {'success': False, 'message': mesg}\n    return {'success': True, 'message': None, 'user': user}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn path to directory containing this package s theme.", "response": "def get_theme_dir():\n    \"\"\"\n    Returns path to directory containing this package's theme.\n    \n    This is designed to be used when setting the ``html_theme_path``\n    option within Sphinx's ``conf.py`` file.\n    \"\"\"\n    return os.path.abspath(os.path.join(os.path.dirname(__file__), \"theme\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_discount_promotion(cls, discount_promotion, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_discount_promotion_with_http_info(discount_promotion, **kwargs)\n        else:\n            (data) = cls._create_discount_promotion_with_http_info(discount_promotion, **kwargs)\n            return data", "response": "Create a new DiscountPromotion\n                "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a DiscountPromotion by its ID.", "response": "def delete_discount_promotion_by_id(cls, discount_promotion_id, **kwargs):\n        \"\"\"Delete DiscountPromotion\n\n        Delete an instance of DiscountPromotion by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_discount_promotion_by_id(discount_promotion_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str discount_promotion_id: ID of discountPromotion to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_discount_promotion_by_id_with_http_info(discount_promotion_id, **kwargs)\n        else:\n            (data) = cls._delete_discount_promotion_by_id_with_http_info(discount_promotion_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind DiscountPromotion by ID Return single instance of DiscountPromotion", "response": "def get_discount_promotion_by_id(cls, discount_promotion_id, **kwargs):\n        \"\"\"Find DiscountPromotion\n\n        Return single instance of DiscountPromotion by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_discount_promotion_by_id(discount_promotion_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str discount_promotion_id: ID of discountPromotion to return (required)\n        :return: DiscountPromotion\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_discount_promotion_by_id_with_http_info(discount_promotion_id, **kwargs)\n        else:\n            (data) = cls._get_discount_promotion_by_id_with_http_info(discount_promotion_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_all_discount_promotions(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_discount_promotions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_discount_promotions_with_http_info(**kwargs)\n            return data", "response": "List DiscountPromotions\n        Return a list of DiscountPromotions\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace all attributes of DiscountPromotion clf and return the new DiscountPromotion clf", "response": "def replace_discount_promotion_by_id(cls, discount_promotion_id, discount_promotion, **kwargs):\n        \"\"\"Replace DiscountPromotion\n\n        Replace all attributes of DiscountPromotion\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_discount_promotion_by_id(discount_promotion_id, discount_promotion, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str discount_promotion_id: ID of discountPromotion to replace (required)\n        :param DiscountPromotion discount_promotion: Attributes of discountPromotion to replace (required)\n        :return: DiscountPromotion\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_discount_promotion_by_id_with_http_info(discount_promotion_id, discount_promotion, **kwargs)\n        else:\n            (data) = cls._replace_discount_promotion_by_id_with_http_info(discount_promotion_id, discount_promotion, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_discount_promotion_by_id(cls, discount_promotion_id, discount_promotion, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_discount_promotion_by_id_with_http_info(discount_promotion_id, discount_promotion, **kwargs)\n        else:\n            (data) = cls._update_discount_promotion_by_id_with_http_info(discount_promotion_id, discount_promotion, **kwargs)\n            return data", "response": "Update attributes of a discount promotion by ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_code_readable(s):\r\n\r\n    s = s if isinstance(s, str) else str(s)\r\n\r\n    MAP = {\",\": \",\\n\", \"{\": \"{\\n \", \"}\": \"\\n}\"}\r\n\r\n    ll = []\r\n\r\n    state = \"open\"\r\n    flag_single = False\r\n    flag_double = False\r\n    flag_backslash = False\r\n    for ch in s:\r\n        if flag_backslash:\r\n            flag_backslash = False\r\n            continue\r\n\r\n        if ch == \"\\\\\":\r\n            flag_backslash = True\r\n            continue\r\n\r\n        if flag_single:\r\n            if ch == \"'\":\r\n                flag_single = False\r\n        elif not flag_double and ch == \"'\":\r\n            flag_single = True\r\n\r\n        if flag_double:\r\n            if ch == '\"':\r\n                flag_double = False\r\n        elif not flag_single and ch == '\"':\r\n            flag_double = True\r\n\r\n        if flag_single or flag_double:\r\n            ll.append(ch)\r\n        else:\r\n            ll.append(MAP.get(ch, ch))\r\n\r\n    return \"\".join(ll)", "response": "Returns a string that can be printed to the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits a string into fixed - length chunks.", "response": "def chunk_string(string, length):\r\n    \"\"\"\r\n    Splits a string into fixed-length chunks.\r\n\r\n    This function returns a generator, using a generator comprehension. The\r\n    generator returns the string sliced, from 0 + a multiple of the length\r\n    of the chunks, to the length of the chunks + a multiple of the length\r\n    of the chunks.\r\n\r\n    Reference: http://stackoverflow.com/questions/18854620\r\n    \"\"\"\r\n    return (string[0 + i:length + i] for i in range(0, len(string), length))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef seconds2str(seconds):\r\n\r\n    if seconds < 0:\r\n        return \"{0:.3g}s\".format(seconds)\r\n    elif math.isnan(seconds):\r\n        return \"NaN\"\r\n    elif math.isinf(seconds):\r\n        return \"Inf\"\r\n\r\n    m, s = divmod(seconds, 60)\r\n    h, m = divmod(m, 60)\r\n    if h >= 1:\r\n        return \"{0:g}h {1:02g}m {2:.3g}s\".format(h, m, s)\r\n    elif m >= 1:\r\n        return \"{0:02g}m {1:.3g}s\".format(m, s)\r\n    else:\r\n        return \"{0:.3g}s\".format(s)", "response": "Returns string such as 1h 05m 55s."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_fits_keys_dict(keys):\r\n\r\n    key_dict = {}\r\n    new_keys = []\r\n    for key in keys:\r\n        # converts to valid FITS key according to reference [1] above\r\n        fits_key = valid_fits_key(key)\r\n        num_digits = 1\r\n        i = -1\r\n        i_max = 9\r\n        while fits_key in new_keys:\r\n            i += 1\r\n            if i > i_max:\r\n                i = 0\r\n                i_max = i_max * 10 + 9\r\n                num_digits += 1\r\n            fits_key = fits_key[:(8 - num_digits)] + ((\"%0{0:d}d\".format(num_digits)) % i)\r\n\r\n        key_dict[key] = fits_key\r\n        new_keys.append(fits_key)\r\n\r\n    return key_dict", "response": "Returns a dictionary to translate to unique FITS header keys up to 8 characters long and can only contain 8 characters long and the keyword names can only contain 8 characters long and the underscore and the underscore."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef valid_fits_key(key):\r\n\r\n    ret = re.sub(\"[^A-Z0-9\\-_]\", \"\", key.upper())[:8]\r\n    if len(ret) == 0:\r\n        raise RuntimeError(\"key '{0!s}' has no valid characters to be a key in a FITS header\".format(key))\r\n    return ret", "response": "Makes a valid FITS header"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates string_ must evaluate to list of strings. Also converts field names to uppercase", "response": "def eval_fieldnames(string_, varname=\"fieldnames\"):\r\n    \"\"\"Evaluates string_, must evaluate to list of strings. Also converts field names to uppercase\"\"\"\r\n    ff = eval(string_)\r\n    if not isinstance(ff, list):\r\n        raise RuntimeError(\"{0!s} must be a list\".format(varname))\r\n    if not all([isinstance(x, str) for x in ff]):\r\n        raise RuntimeError(\"{0!s} must be a list of strings\".format(varname))\r\n    ff = [x.upper() for x in ff]\r\n    return ff"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef module_to_dict(module):\r\n\r\n    lot = [(key, module.__getattribute__(key)) for key in module.__all__]\r\n    ret = dict(lot)\r\n    return ret", "response": "Creates a dictionary whose keys are module. all__\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strip_accents(s):\n    nfkd = unicodedata.normalize('NFKD', unicode(s))\n    return u''.join(ch for ch in nfkd if not unicodedata.combining(ch))", "response": "Strip accents from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the given string to a URL slug.", "response": "def slugify(s):\n    \"\"\"\n    Converts the given string to a URL slug.\n    \"\"\"\n    s = strip_accents(s.replace(\"'\", '').lower())\n    return re.sub('[^a-z0-9]+', ' ', s).strip().replace(' ', '-')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode_qwikcord(packet, channel=1):\n    val = str(packet.get('val', ''))\n    if len(val) != 16:\n        return None\n    if channel == 1:\n        return int(val[6:12], 16)  # CTavg\n    return int(val[12:], 16)", "response": "Extract the qwikcord current measurements from val ( CTavg CTsum )."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding a door sensor.", "response": "def decode_door(packet, channel=1):\n    \"\"\"Decode a door sensor.\"\"\"\n    val = str(packet.get(QSDATA, ''))\n    if len(val) == 6 and val.startswith('46') and channel == 1:\n        return val[-1] == '0'\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_imod(packet, channel=1):\n    val = str(packet.get(QSDATA, ''))\n    if len(val) == 8 and val.startswith('4e'):\n        try:\n            _map = ((5, 1), (5, 2), (5, 4), (4, 1), (5, 1), (5, 2))[\n                channel - 1]\n            return (int(val[_map[0]], 16) & _map[1]) == 0\n        except IndexError:\n            return None\n    return None", "response": "Decode an 4 channel imod. May support 6 channels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a value for a specific QSID.", "response": "def set_value(self, qsid, new):\n        # Set value & encode new to be passed to QSUSB\n        \"\"\"Set a value.\"\"\"\n        try:\n            dev = self[qsid]\n        except KeyError:\n            raise KeyError(\"Device {} not found\".format(qsid))\n        if new < 0:\n            new = 0\n        if new == dev.value:\n            return\n\n        if dev.is_dimmer:\n            new = _MAX if new > (_MAX * .9) else new\n        else:  # QSType.relay and any other\n            new = _MAX if new > 0 else 0\n\n        def success():\n            \"\"\"Success closure to update value.\"\"\"\n            self[qsid].value = new\n            _LOGGER.debug(\"set success %s=%s\", qsid, new)\n            self._cb_value_changed(self, qsid, new)\n\n        newqs = round(math.pow(round(new / _MAX * 100), 1 / self.dim_adj))\n        _LOGGER.debug(\"%s hass=%s --> %s\", qsid, new, newqs)\n        self._cb_set_qsvalue(qsid, newqs, success)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_devices(self, devices):\n        for qspacket in devices:\n            try:\n                qsid = qspacket[QS_ID]\n            except KeyError:\n                _LOGGER.debug(\"Device without ID: %s\", qspacket)\n                continue\n\n            if qsid not in self:\n                self[qsid] = QSDev(data=qspacket)\n\n            dev = self[qsid]\n            dev.data = qspacket\n            # Decode value from QSUSB\n            newqs = _legacy_status(qspacket[QS_VALUE])\n            if dev.is_dimmer:\n                # Adjust dimmer exponentially to get a smoother effect\n                newqs = min(round(math.pow(newqs, self.dim_adj)), 100)\n            newin = round(newqs * _MAX / 100)\n            if abs(dev.value - newin) > 1:  # Significant change\n                _LOGGER.debug(\"%s qs=%s  -->  %s\", qsid, newqs, newin)\n                dev.value = newin\n                self._cb_value_changed(self, qsid, newin)", "response": "Update values from response of URL_DEVICES callback if changed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef geist_replay(wrapped, instance, args, kwargs):\n    path_parts = []\n    file_parts = []\n\n    if hasattr(wrapped, '__module__'):\n        module = wrapped.__module__\n        module_file = sys.modules[module].__file__\n        root, _file = os.path.split(module_file)\n        path_parts.append(root)\n        _file, _ = os.path.splitext(_file)\n        file_parts.append(_file)\n    if hasattr(wrapped, '__objclass__'):\n        file_parts.append(wrapped.__objclass__.__name__)\n    elif hasattr(wrapped, '__self__'):\n        file_parts.append(wrapped.__self__.__class__.__name__)\n    file_parts.append(wrapped.__name__ + '.log')\n    path_parts.append('_'.join(file_parts))\n    filename = os.path.join(*path_parts)\n\n    if is_in_record_mode():\n        platform_backend = get_platform_backend()\n        backend = RecordingBackend(\n            source_backend=platform_backend,\n            recording_filename=filename\n        )\n    else:\n        backend = PlaybackBackend(\n            recording_filename=filename\n        )\n    gui = GUI(backend)\n    return wrapped(gui, *args, **kwargs)", "response": "Wraps a test of other function and injects a Geist GUI which will\n    enable replay mode"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reverse_cyk_transforms(root):\n        # type: (Nonterminal) -> Nonterminal\n        \"\"\"\n        Reverse transformation made to grammar before CYK.\n        Performs following steps:\n        - transform from chomsky normal form\n        - restore unit rules\n        - restore epsilon rules\n        :param root: Root node of the parsed tree.\n        :return: Restored parsed tree.\n        \"\"\"\n        root = InverseContextFree.transform_from_chomsky_normal_form(root)\n        root = InverseContextFree.unit_rules_restore(root)\n        root = InverseContextFree.epsilon_rules_restore(root)\n        return root", "response": "Reverse the cyk transformation made to grammar before CYK."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsolve the p parameter from mu and b.", "response": "def _geom_solve_p_from_mu(mu, b):\n    \"\"\"\n    For the geom_uptrunc, given mu and b, return p.\n    Ref: Harte 2011, Oxford U Press. Eq. 7.50.\n    \"\"\"\n\n    def p_eq(x, mu, b):\n        x, mu, b = Decimal(x), Decimal(mu), Decimal(b)\n        return ( (x / (1 - x)) - ((b + 1) / (x**-b - 1)) - mu )\n\n    # x here is the param raised to the k_agg power, or 1 - p\n    return 1 - optim.brentq(p_eq, 1e-16, 100, args=(mu, b), disp=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate p parameter for truncated negative binomial logarithmic logarithm", "response": "def _nbinom_ztrunc_p(mu, k_agg):\n        \"\"\" Calculates p parameter for truncated negative binomial\n\n        Function given in Sampford 1955, equation 4\n\n        Note that omega = 1 / 1 + p in Sampford\n        \"\"\"\n\n        p_eq = lambda p, mu, k_agg: (k_agg * p) / (1 - (1 + p)**-k_agg) - mu\n\n        # The upper bound needs to be large. p will increase with increasing mu\n        # and decreasing k_agg\n        p = optim.brentq(p_eq, 1e-10, 1e10, args=(mu, k_agg))\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ln_choose(n, k_agg):\n    '''\n    log binomial coefficient with extended gamma factorials. n and k_agg may be\n    int or array - if both array, must be the same length.\n\n    '''\n    gammaln = special.gammaln\n    return gammaln(n + 1) - (gammaln(k_agg + 1) + gammaln(n - k_agg + 1))", "response": "log binomial coefficient with extended gamma factorials. n and k_agg may be int array - must be the same length."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _solve_k_from_mu(data, k_array, nll, *args):\n    # TODO: See if a root finder like fminbound would work with Decimal used in\n    # logpmf method (will this work with arrays?)\n\n    nll_array = np.zeros(len(k_array))\n\n    for i in range(len(k_array)):\n        nll_array[i] = nll(data, k_array[i], *args)\n\n    min_nll_idx = np.argmin(nll_array)\n\n    return k_array[min_nll_idx]", "response": "Solve k_array for given args Return k_agg from searching some k_range."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _trunc_logser_solver(bins, b):\n\n    if bins == b:\n        p = 0\n\n    else:\n        BOUNDS = [0, 1]\n        DIST_FROM_BOUND = 10 ** -15\n        m = np.array(np.arange(1, np.int(b) + 1))\n        y = lambda x: np.sum(x ** m / b * bins) - np.sum((x ** m) / m)\n        p = optim.bisect(y, BOUNDS[0] + DIST_FROM_BOUND,\n                   min((sys.float_info[0] / bins) ** (1 / b), 2),\n                   xtol=1.490116e-08, maxiter=1000)\n    return p", "response": "This function solves the logser problem for truncated logseries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving the lam from mu and b.", "response": "def _expon_solve_lam_from_mu(mu, b):\n    \"\"\"\n    For the expon_uptrunc, given mu and b, return lam.\n    Similar to geom_uptrunc\n    \"\"\"\n\n    def lam_eq(lam, mu, b):\n        # Small offset added to denominator to avoid 0/0 erors\n        lam, mu, b = Decimal(lam), Decimal(mu), Decimal(b)\n        return ( (1 - (lam*b + 1) * np.exp(-lam*b)) /\n                 (lam - lam * np.exp(-lam*b) + Decimal(1e-32)) - mu )\n\n    return optim.brentq(lam_eq, -100, 100, args=(mu, b), disp=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking rank distribution using both ppf and brute force.", "response": "def _make_rank(dist_obj, n, mu, sigma, crit=0.5, upper=10000, xtol=1):\n    \"\"\"\n    Make rank distribution using both ppf and brute force.\n\n    Setting crit = 1 is equivalent to just using the ppf\n\n    Parameters\n    ----------\n    {0}\n\n    \"\"\"\n    qs = (np.arange(1, n + 1) - 0.5) / n\n    rank = np.empty(len(qs))\n\n    brute_ppf = lambda val, prob: prob - dist_obj.cdf(val, mu, sigma)\n\n    qs_less = qs <= crit\n    ind = np.sum(qs_less)\n\n    # Use ppf if qs are below crit\n    rank[qs_less] = dist_obj.ppf(qs[qs_less], mu, sigma)\n\n    # Use brute force if they are above\n    for i, tq in enumerate(qs[~qs_less]):\n\n        j = ind + i\n        try:\n            # TODO: Use an adaptable lower bound to increase speed\n            rank[j] = np.abs(np.ceil(optim.brentq(brute_ppf, -1, upper,\n                                        args=(tq,), xtol=xtol)))\n\n        except ValueError:\n\n            # If it is above the upper bound set all remaining values\n            # to the previous value\n            rank[j:] = np.repeat(rank[j - 1], len(rank[j:]))\n            break\n\n    return rank"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mean_var(vals, pmf):\n\n    mean = np.sum(vals * pmf)\n    var = np.sum(vals ** 2 * pmf) - mean ** 2\n    return mean, var", "response": "Calculates the mean and variance from vals and pmf"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rank(self, n, *args):\n        return self.ppf((np.arange(1, n+1) - 0.5) / n, *args)", "response": "Rank the set of entries in the log"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rvs_alt(self, *args, **kwargs):\n        l = kwargs.get('l', 1)\n        b = kwargs.get('b', 1e5)\n        size = kwargs.get('size', 1)\n\n        model_cdf = self.cdf(np.arange(l, b + 1), *args)\n\n        unif_rands = np.random.random(size)\n        model_rands = np.array([np.where(tx <= model_cdf)[0][0] + l\n                            for tx in unif_rands])\n\n        return model_rands", "response": "Generate random set of random values for the current set of unifferent models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_mle(self, data, b=None):\n        # Take mean of data as MLE of distribution mean, then calculate p\n        mu = np.mean(data)\n        if not b:\n            b = np.sum(data)\n        p = _geom_solve_p_from_mu_vect(mu, b)\n\n        # Just return float, not len 1 array\n        if len(np.atleast_1d(p)) == 1:\n            return float(p), b\n        else:\n            return p, b", "response": "Fits the p - value of the p - value of the object with the MLE of the distribution."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the MLE function to the user - specified data.", "response": "def fit_mle(self, data, init_vals=(80, 80)):\n        \"\"\"%(super)s\n        In addition to data, can take init_vals which allows the user to\n        specify initial values for (alpha, theta) during the optimization.\n\n        \"\"\"\n\n        if len(data) > 1:\n            mu = np.mean(data)\n            var = np.var(data)\n            theta0 = var / mu\n            alpha0 = mu / theta0\n        else:\n            alpha0 = init_vals[0]\n            theta0 = init_vals[1]\n\n        def mle(params):\n            return -np.sum(np.log(self.pmf(data, params[0], params[1])))\n\n        # Bounded fmin?\n        alpha, theta = optim.fmin(mle, x0=[alpha0, theta0], disp=0)\n\n        return alpha, theta"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfits the mle to the data", "response": "def fit_mle(self, data, k_array=np.arange(0.1, 100, 0.1)):\n        \"\"\"%(super)s\n\n        In addition to data, gives an optional keyword argument k_array\n        containing the values to search for k_agg. A brute force search is then\n        used to find the parameter k_agg.\n\n        \"\"\"\n        # todo: check and mention in docstring biases of mle for k_agg\n        data = np.array(data)\n        mu = np.mean(data)\n        return mu, _solve_k_from_mu(data, k_array, nbinom_nll, mu)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_args(self, mu, k_agg, return_p=False):\n        if return_p:\n            return nbinom_ztrunc_p(mu, k_agg), k_agg\n        else:\n            return mu, k_agg", "response": "This function translates the arguments used to define the cluster identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_mle(self, data, k_agg0=0.5):\n\n        mu = np.mean(data)\n\n        def mle(k):\n\n            return -np.sum(np.log(self.pmf(data, mu, k)))\n\n        k = optim.fmin(mle, x0=k_agg0, disp=0)\n\n        return mu, k[0]", "response": "Fits the MLE function to obtain the minimum log likelihood of the log likelihood of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_mle(self, data, b=None):\n\n        data = np.array(data)\n        length = len(data)\n\n        if not b:\n            b = np.sum(data)\n\n        return _trunc_logser_solver(length, b), b", "response": "Fits the logser solver to the data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rank(self, n, mu, sigma, crit=.5, upper=10000, xtol=1):\n\n        return _make_rank(self, n, mu, sigma, crit=crit, upper=upper,\n                                                                    xtol=xtol)", "response": "Rank the object in the sequence with the given mu and sigma."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit_mle(self, data, b=None):\n        # Take mean of data as MLE of distribution mean, then calculate p\n        mu = np.mean(data)\n        if not b:\n            b = np.sum(data)\n        lam = _expon_solve_lam_from_mu_vect(mu, b)\n\n        # Just return float, not len 1 array\n        if len(np.atleast_1d(lam)) == 1:\n            return float(lam), b\n        else:\n            return lam, b", "response": "Fits the MLE of the distribution to the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit_mle(self, data, fix_mean=False):\n\n        if not fix_mean:\n            sigma, _, scale = stats.lognorm.fit(data, floc=0)\n            return np.log(scale), sigma\n\n        else:\n            mean = np.mean(data)\n\n            # MLE fxn to be optmimized\n            mle = lambda sigma, x, mean: -1 *\\\n                                    np.sum(self._pdf_w_mean(x, mean, sigma))\n\n            sigma = optim.fmin(mle, np.array([np.std(np.log(data), ddof=1)]),\n                                            args=(data, mean), disp=0)[0]\n\n            return self.translate_args(mean, sigma)", "response": "Fits the MLE of the object to the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the pdf of a lognormal distribution with parameters mean and sigma.", "response": "def _pdf_w_mean(self, x, mean, sigma):\n        \"\"\"\n        Calculates the pdf of a lognormal distribution with parameters mean\n        and sigma\n\n        Parameters\n        ----------\n        mean : float or ndarray\n            Mean of the lognormal distribution\n        sigma : float or ndarray\n            Sigma parameter of the lognormal distribution\n\n        Returns\n        -------\n        : float or ndarray\n            pdf of x\n        \"\"\"\n\n        # Lognorm pmf with mean for optimization\n        mu, sigma = self.translate_args(mean, sigma)\n        return self.logpdf(x, mu, sigma)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef union_join(left, right, left_as='left', right_as='right'):\n    attrs = {}\n    attrs.update(get_object_attrs(right))\n    attrs.update(get_object_attrs(left))\n    attrs[left_as] = left\n    attrs[right_as] = right\n    if isinstance(left, dict) and isinstance(right, dict):\n        return attrs\n    else:\n        joined_class = type(left.__class__.__name__ + right.__class__.__name__, (Union,),\n                            {})\n        return joined_class(attrs)", "response": "Join two objects together in a sum - type and return the resulting object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setKeyButton( self, btnId, keyCallback, bounceTime = DEF_BOUNCE_TIME_NORMAL, pullUpDown = GPIO.PUD_UP, event = GPIO.BOTH ):\n        GPIO.setup( btnId, GPIO.IN, pull_up_down=pullUpDown)\n        # The keyCallback is None means setting keybutton in query mode, \n        # then uses readKeyButton for get keybutton status\n        # event can be { RISING, FALLING, BOTH }\n        if keyCallback != None:\n            try:\n                GPIO.add_event_detect( btnId, event, callback=keyCallback, bouncetime=bounceTime )\n            except:\n                pass\n        pass", "response": "Set a key button."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef removeKeyButtonEvent(self, buttons= [] ):\n        for i in range( 0, len(buttons)-1 ):\n            GPIO.remove_event_detect( buttons[i] )", "response": "Remove key button event callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configKeyButtons( self, enableButtons = [], bounceTime = DEF_BOUNCE_TIME_NORMAL, pullUpDown = GPIO.PUD_UP, event = GPIO.BOTH ):\n        for key in enableButtons:\n            self.setKeyButton( key[\"id\"], key[\"callback\"], bounceTime, pullUpDown, event )\n        pass", "response": "Configure multi key buttons IO and event on same time."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matches_from_list(item,options,fuzzy=90,fname_match=True,fuzzy_fragment=None,guess=False):\n    '''Returns the members of ``options`` that best matches ``item``. Will prioritize\n    exact matches, then filename-style matching, then fuzzy matching. Returns a tuple of item,\n    index, match type, and fuzziness (if applicable)\n    \n         :item:             string to match\n         :options:          list of examples to test against\n         :fuzzy:            integer (out of 100) describing how close to match string\n         :fname_match:      use filename globbing to match files?\n         :fuzzy_fragment:   if not ``None``, will accept substring matches of\n                            at least ``fuzzy_fragment`` fuzziness\n         :guess:            if ``True``, shortcut for setting ``fuzzy`` and ``min_fragment``\n                            to very lenient options\n    '''\n    matches = []\n    \n    if guess:\n        fuzzy = min(fuzzy,80)\n        fuzzy_fragment = min(fuzzy_fragment,70)\n    \n    option_not_in = lambda item,match_list: all([x[0]!=item for x in match_list])\n    \n    # Exact matches\n    if item in options:\n        matches += [(options[i],i,'exact',None) for i in xrange(len(options)) if options[i].lower()==item.lower()]\n        # If we have exact matches, don't bother with fuzzy matching\n        return matches\n    \n    # Filename-style matches\n    if fname_match:\n        matches += [(x,options.index(x),'fname',None) for x in fnmatch.filter(options,item) if option_not_in(x,matches)]\n    \n    # Fuzzy matches\n    if fuzzy:\n        sub_matches = []\n        for i in xrange(len(options)):\n            r = fuzz.ratio(item.lower(),options[i].lower())\n            if r>=fuzzy and option_not_in(options[i],matches):\n                sub_matches.append((r,i))\n        matches += [(options[x[1]],x[1],'fuzzy',x[0]) for x in sorted(sub_matches)]\n    \n    # Fragment matches\n    if fuzzy_fragment:\n        sub_matches = []\n        for i in xrange(len(options)):\n            r = fuzz.partial_ratio(item.lower(),options[i].lower())\n            if r>=fuzzy_fragment and option_not_in(options[i],matches):\n                sub_matches.append((r,i))\n        matches += [(options[x[1]],x[1],'fuzzy_fragment',x[0]) for x in sorted(sub_matches)]\n    \n    return matches", "response": "Returns the members of options that best matches item. Will prioritize exact matches filename - style matching then fuzzy matching."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef best_match_from_list(item,options,fuzzy=90,fname_match=True,fuzzy_fragment=None,guess=False):\n    '''Returns the best match from :meth:`matches_from_list` or ``None`` if no good matches'''\n    matches = matches_from_list(item,options,fuzzy,fname_match,fuzzy_fragment,guess)\n    if len(matches)>0:\n        return matches[0]\n    return None", "response": "Returns the best match from a list of options"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns just the best item or None", "response": "def best_item_from_list(item,options,fuzzy=90,fname_match=True,fuzzy_fragment=None,guess=False):\n    '''Returns just the best item, or ``None``'''\n    match = best_match_from_list(item,options,fuzzy,fname_match,fuzzy_fragment,guess)\n    if match:\n        return match[0]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating HLK - SW16 Client class.", "response": "async def create_hlk_sw16_connection(port=None, host=None,\n                                     disconnect_callback=None,\n                                     reconnect_callback=None, loop=None,\n                                     logger=None, timeout=None,\n                                     reconnect_interval=None):\n    \"\"\"Create HLK-SW16 Client class.\"\"\"\n    client = SW16Client(host, port=port,\n                        disconnect_callback=disconnect_callback,\n                        reconnect_callback=reconnect_callback,\n                        loop=loop, logger=logger,\n                        timeout=timeout, reconnect_interval=reconnect_interval)\n    await client.setup()\n\n    return client"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting timeout for date keep alive.", "response": "def _reset_timeout(self):\n        \"\"\"Reset timeout for date keep alive.\"\"\"\n        if self._timeout:\n            self._timeout.cancel()\n        self._timeout = self.loop.call_later(self.client.timeout,\n                                             self.transport.close)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets timeout for command execution.", "response": "def reset_cmd_timeout(self):\n        \"\"\"Reset timeout for command execution.\"\"\"\n        if self._cmd_timeout:\n            self._cmd_timeout.cancel()\n        self._cmd_timeout = self.loop.call_later(self.client.timeout,\n                                                 self.transport.close)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_lines(self):\n        while b'\\xdd' in self._buffer:\n            linebuf, self._buffer = self._buffer.rsplit(b'\\xdd', 1)\n            line = linebuf[-19:]\n            self._buffer += linebuf[:-19]\n            if self._valid_packet(line):\n                self._handle_raw_packet(line)\n            else:\n                self.logger.warning('dropping invalid data: %s',\n                                    binascii.hexlify(line))", "response": "Assemble incoming data into per - line packets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_raw_packet(self, raw_packet):\n        if raw_packet[1:2] == b'\\x1f':\n            self._reset_timeout()\n            year = raw_packet[2]\n            month = raw_packet[3]\n            day = raw_packet[4]\n            hour = raw_packet[5]\n            minute = raw_packet[6]\n            sec = raw_packet[7]\n            week = raw_packet[8]\n            self.logger.debug(\n                'received date: Year: %s, Month: %s, Day: %s, Hour: %s, '\n                'Minute: %s, Sec: %s, Week %s',\n                year, month, day, hour, minute, sec, week)\n        elif raw_packet[1:2] == b'\\x0c':\n            states = {}\n            changes = []\n            for switch in range(0, 16):\n                if raw_packet[2+switch:3+switch] == b'\\x01':\n                    states[format(switch, 'x')] = True\n                    if (self.client.states.get(format(switch, 'x'), None)\n                            is not True):\n                        changes.append(format(switch, 'x'))\n                        self.client.states[format(switch, 'x')] = True\n                elif raw_packet[2+switch:3+switch] == b'\\x02':\n                    states[format(switch, 'x')] = False\n                    if (self.client.states.get(format(switch, 'x'), None)\n                            is not False):\n                        changes.append(format(switch, 'x'))\n                        self.client.states[format(switch, 'x')] = False\n            for switch in changes:\n                for status_cb in self.client.status_callbacks.get(switch, []):\n                    status_cb(states[switch])\n            self.logger.debug(states)\n            if self.client.in_transaction:\n                self.client.in_transaction = False\n                self.client.active_packet = False\n                self.client.active_transaction.set_result(states)\n                while self.client.status_waiters:\n                    waiter = self.client.status_waiters.popleft()\n                    waiter.set_result(states)\n                if self.client.waiters:\n                    self.send_packet()\n                else:\n                    self._cmd_timeout.cancel()\n            elif self._cmd_timeout:\n                self._cmd_timeout.cancel()\n        else:\n            self.logger.warning('received unknown packet: %s',\n                                binascii.hexlify(raw_packet))", "response": "Parse a raw packet and update the state of the current state of the current state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_packet(self):\n        waiter, packet = self.client.waiters.popleft()\n        self.logger.debug('sending packet: %s', binascii.hexlify(packet))\n        self.client.active_transaction = waiter\n        self.client.in_transaction = True\n        self.client.active_packet = packet\n        self.reset_cmd_timeout()\n        self.transport.write(packet)", "response": "Write next packet in send queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_packet(command):\n        frame_header = b\"\\xaa\"\n        verify = b\"\\x0b\"\n        send_delim = b\"\\xbb\"\n        return frame_header + command.ljust(17, b\"\\x00\") + verify + send_delim", "response": "Format packet to be sent."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connection_lost(self, exc):\n        if exc:\n            self.logger.error('disconnected due to error')\n        else:\n            self.logger.info('disconnected because of close/abort.')\n        if self.disconnect_callback:\n            asyncio.ensure_future(self.disconnect_callback(), loop=self.loop)", "response": "Log when connection is lost."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def setup(self):\n        while True:\n            fut = self.loop.create_connection(\n                lambda: SW16Protocol(\n                    self,\n                    disconnect_callback=self.handle_disconnect_callback,\n                    loop=self.loop, logger=self.logger),\n                host=self.host,\n                port=self.port)\n            try:\n                self.transport, self.protocol = \\\n                    await asyncio.wait_for(fut, timeout=self.timeout)\n            except asyncio.TimeoutError:\n                self.logger.warning(\"Could not connect due to timeout error.\")\n            except OSError as exc:\n                self.logger.warning(\"Could not connect due to error: %s\",\n                                    str(exc))\n            else:\n                self.is_connected = True\n                if self.reconnect_callback:\n                    self.reconnect_callback()\n                break\n            await asyncio.sleep(self.reconnect_interval)", "response": "Setup the connection with automatic retry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self):\n        self.reconnect = False\n        self.logger.debug(\"Shutting down.\")\n        if self.transport:\n            self.transport.close()", "response": "Shut down the connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def handle_disconnect_callback(self):\n        self.is_connected = False\n        if self.disconnect_callback:\n            self.disconnect_callback()\n        if self.reconnect:\n            self.logger.debug(\"Protocol disconnected...reconnecting\")\n            await self.setup()\n            self.protocol.reset_cmd_timeout()\n            if self.in_transaction:\n                self.protocol.transport.write(self.active_packet)\n            else:\n                packet = self.protocol.format_packet(b\"\\x1e\")\n                self.protocol.transport.write(packet)", "response": "Handle a disconnect callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_status_callback(self, callback, switch):\n        if self.status_callbacks.get(switch, None) is None:\n            self.status_callbacks[switch] = []\n        self.status_callbacks[switch].append(callback)", "response": "Register a callback which will fire when state changes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send(self, packet):\n        fut = self.loop.create_future()\n        self.waiters.append((fut, packet))\n        if self.waiters and self.in_transaction is False:\n            self.protocol.send_packet()\n        return fut", "response": "Add packet to send queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def status(self, switch=None):\n        if switch is not None:\n            if self.waiters or self.in_transaction:\n                fut = self.loop.create_future()\n                self.status_waiters.append(fut)\n                states = await fut\n                state = states[switch]\n            else:\n                packet = self.protocol.format_packet(b\"\\x1e\")\n                states = await self._send(packet)\n                state = states[switch]\n        else:\n            if self.waiters or self.in_transaction:\n                fut = self.loop.create_future()\n                self.status_waiters.append(fut)\n                state = await fut\n            else:\n                packet = self.protocol.format_packet(b\"\\x1e\")\n                state = await self._send(packet)\n        return state", "response": "Get current relay status."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the value stored in weakref.", "response": "def value(self, item):\n        # type: (Any) -> Any\n        \"\"\"\n        Return value stored in weakref.\n        :param item: Object from which get the value.\n        :return: Value stored in the weakref, otherwise original value.\n        :raise TreeDeletedException: when weakref is already deleted.\n        \"\"\"\n        if isinstance(item, weakref.ReferenceType):\n            if item() is None:\n                raise TreeDeletedException()\n            return item()\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all occurrences of the parameter.", "response": "def remove_all(self, item):\n        # type: (Any) -> None\n        \"\"\"\n        Remove all occurrence of the parameter.\n        :param item: Value to delete from the WeakList.\n        \"\"\"\n        item = self.ref(item)\n        while list.__contains__(self, item):\n            list.remove(self, item)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index of the item in the WeakList.", "response": "def index(self, item, **kwargs):\n        # type: (Any, dict) -> int\n        \"\"\"\n        Get index of the parameter.\n        :param item: Item for which get the index.\n        :return: Index of the parameter in the WeakList.\n        \"\"\"\n        return list.index(self, self.ref(item), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert the item at the specific index.", "response": "def insert(self, index, item):\n        # type: (int, Any) -> None\n        \"\"\"\n        Insert item at the specific index.\n        :param index: Index where to insert the item.\n        :param item: Item to insert.\n        \"\"\"\n        return list.insert(self, index, self.ref(item))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sort(self, *, key: Optional[Callable[[Any], Any]] = None, reverse: bool = False) -> None:\n        return list.sort(self, key=self._sort_key(key), reverse=reverse)", "response": "Sort the list by the given key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_feed(self, datasource_id):\n        info = self.__metadb.one(\n            \"\"\"\n            SELECT to_json(ds) as datasource\n                 , to_json(fc) as connector\n                 , to_json(fct) as connector_type\n                 , to_json(ctp) as connector_type_preset\n                 , json_build_object('email', u.email, 'full_name', u.full_name) as author_user\n              FROM meta.feed_datasource ds\n              LEFT JOIN meta.feed_connector fc \n                     ON fc.id=ds.connector_id\n              LEFT JOIN meta.feed_connector_type fct \n                     ON fct.id=fc.connector_type_id\n              LEFT JOIN meta.feed_connector_type_preset ctp \n                     ON ctp.id=ds.connector_type_preset_id\n              LEFT JOIN meta.user_list u \n                     ON u.id=ds.author_user_id\n             WHERE ds.id = :datasource_id::uuid\n            \"\"\",\n            {\"datasource_id\": datasource_id}\n        )\n        return FeedDataSource(**info)", "response": "\u041f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0435\u043a \u0444\u0438\u0434\u0430\n        \u043d\u0430\u0441\u0442\u0440\u043e\u0435\u043a \u0434\u043b\u044f \u0444\u0438\u0434\u0430\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef datasource_process(self, datasource_id):\n        # TODO \u0412\u044b\u043f\u0438\u043b\u0438\u0442\u044c \u043f\u043e\u0442\u043e\u043c \u043a\u043b\u0430\u0441\u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u0434\u0440\u0443\u0433\u043e\u0433\u043e\n        # TODO \u0431\u0435\u0437 applicationId \u043d\u0435 \u0432\u044b\u0431\u0438\u0440\u0430\u044e\u0442\u0441\u044f \u043f\u043e\u043b\u044f \u0441\u0443\u0449\u043d\u043e\u0441\u0442\u0435\u0439. \u041f\u043e\u0434\u0443\u043c\u0430\u0442\u044c \u043d\u0430 \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u044d\u0442\u043e \u041d\u0415 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\n        response = self.__app.native_api_call('feed', 'datasource/' + datasource_id + '/process?applicationId=1', {},\n                                              self.__options, False, None, False, http_method=\"POST\")\n        return json.loads(response.text)", "response": "deprecated\n        \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u0442 \u043d\u0430\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u044b\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0432 \u0444\u0438\u0434\u0435\n        :param datasource_id: uuid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the relative path of the current directory to the git repository", "response": "def _delta_dir():\n    \"\"\"returns the relative path of the current directory to the git\n    repository.\n    This path will be added the 'filename' path to find the file.\n    It current_dir is the git root, this function returns an empty string.\n\n    Keyword Arguments:\n        <none>\n\n    Returns:\n        str -- relative path of the current dir to git root dir\n               empty string if current dir is the git root dir\n    \"\"\"\n    repo = Repo()\n    current_dir = os.getcwd()\n    repo_dir = repo.tree().abspath\n    delta_dir = current_dir.replace(repo_dir, '')\n    if delta_dir:\n        return delta_dir + '/'\n    else:\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef commit(filename):\n    try:\n        repo = Repo()\n        # gitcmd = repo.git\n        # gitcmd.commit(filename)\n        index = repo.index\n        index.commit(\"Updated file: {0}\".format(filename))\n    except Exception as e:\n        print(\"exception while commit: %s\" % e.message)", "response": "Commit a specified file\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a file to the git repo", "response": "def add_file_to_repo(filename):\n    \"\"\"Add a file to the git repo\n\n    This method does the same than a ::\n\n        $ git add filename\n\n    Keyword Arguments:\n        :filename: (str) -- name of the file to commit\n\n    Returns:\n        <nothing>\n    \"\"\"\n    try:\n        repo = Repo()\n        index = repo.index\n        index.add([_delta_dir() + filename])\n    except Exception as e:\n        print(\"exception while gitadding file: %s\" % e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset_to_last_commit():\n    try:\n        repo = Repo()\n        gitcmd = repo.git\n        gitcmd.reset(hard=True)\n    except Exception:\n        pass", "response": "reset a modified file to his last commit status"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the commit history for a given filename.", "response": "def commit_history(filename):\n    \"\"\"Retrieve the commit history for a given filename.\n\n    Keyword Arguments:\n        :filename: (str) -- full name of the file\n\n    Returns:\n        list of dicts -- list of commit\n                if the file is not found, returns an empty list\n    \"\"\"\n    result = []\n    repo = Repo()\n    for commit in repo.head.commit.iter_parents(paths=_delta_dir() + filename):\n        result.append({'date':\n                       datetime.fromtimestamp(commit.committed_date +\n                                              commit.committer_tz_offset),\n                       'hexsha': commit.hexsha})\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_committed_file(gitref, filename):\n    repo = Repo()\n    commitobj = repo.commit(gitref)\n\n    blob = commitobj.tree[_delta_dir() + filename]\n    return blob.data_stream.read()", "response": "Retrieve the content of a file in an old commit and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an asset from the cache.", "response": "def get(self, key, _else=None):\n        \"\"\"The method to get an assets value\n        \"\"\"\n        with self._lock:\n            self.expired()\n            # see if everything expired\n            try:\n                value = self._dict[key].get()\n                return value\n            except KeyError:\n                return _else\n            except ValueError:\n                return _else"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(self, key, value, expires=None, future=None):\n        # assert the values above\n        with self._lock:\n            try:\n                self._dict[key].set(value, expires=expires, future=future)\n            except KeyError:\n                self._dict[key] = moment(value, expires=expires, future=future, lock=self._lock)\n            return value", "response": "Set a value for a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef values(self):\n        self.expired()\n        values = []\n        for key in self._dict.keys():\n            try:\n                value = self._dict[key].get()\n                values.append(value)\n            except:\n                continue\n        return values", "response": "Will only return the current values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_key(self, key):\n        if key in self._dict:\n            try: \n                self[key]\n                return True\n            except ValueError:\n                return False\n            except KeyError:\n                return False\n        return False", "response": "Does the key exist? This method will check to see if it has expired too."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts some meta - data from a DICOM file and store in a DB.", "response": "def dicom2db(file_path, file_type, is_copy, step_id, db_conn, sid_by_patient=False, pid_in_vid=False,\n             visit_in_path=False, rep_in_path=False):\n    \"\"\"Extract some meta-data from a DICOM file and store in a DB.\n\n    Arguments:\n    :param file_path: File path.\n    :param file_type: File type (should be 'DICOM').\n    :param is_copy: Indicate if this file is a copy.\n    :param step_id: Step ID\n    :param db_conn: Database connection.\n    :param sid_by_patient: Rarely, a data set might use study IDs which are unique by patient\n    (not for the whole study).\n    E.g.: LREN data. In such a case, you have to enable this flag. This will use PatientID + StudyID as a session ID.\n    :param pid_in_vid: Rarely, a data set might mix patient IDs and visit IDs. E.g. : LREN data. In such a case, you\n    to enable this flag. This will try to split PatientID into VisitID and PatientID.\n    :param visit_in_path: Enable this flag to get the visit ID from the folder hierarchy instead of DICOM meta-data\n    (e.g. can be useful for PPMI).\n    :param rep_in_path: Enable this flag to get the repetition ID from the folder hierarchy instead of DICOM meta-data\n    (e.g. can be useful for PPMI).\n    :return: A dictionary containing the following IDs : participant_id, visit_id, session_id, sequence_type_id,\n    sequence_id, repetition_id, file_id.\n    \"\"\"\n    global conn\n    conn = db_conn\n\n    tags = dict()\n    logging.info(\"Extracting DICOM headers from '%s'\" % file_path)\n\n    try:\n        dcm = dicom.read_file(file_path)\n        dataset = db_conn.get_dataset(step_id)\n\n        tags['participant_id'] = _extract_participant(dcm, dataset, pid_in_vid)\n        if visit_in_path:\n            tags['visit_id'] = _extract_visit_from_path(\n                dcm, file_path, pid_in_vid, sid_by_patient, dataset, tags['participant_id'])\n        else:\n            tags['visit_id'] = _extract_visit(dcm, dataset, tags['participant_id'], sid_by_patient, pid_in_vid)\n        tags['session_id'] = _extract_session(dcm, tags['visit_id'])\n        tags['sequence_type_id'] = _extract_sequence_type(dcm)\n        tags['sequence_id'] = _extract_sequence(tags['session_id'], tags['sequence_type_id'])\n        if rep_in_path:\n            tags['repetition_id'] = _extract_repetition_from_path(dcm, file_path, tags['sequence_id'])\n        else:\n            tags['repetition_id'] = _extract_repetition(dcm, tags['sequence_id'])\n        tags['file_id'] = extract_dicom(file_path, file_type, is_copy, tags['repetition_id'], step_id)\n    except InvalidDicomError:\n        logging.warning(\"%s is not a DICOM file !\" % step_id)\n    except IntegrityError:\n        # TODO: properly deal with concurrency problems\n        logging.warning(\"A problem occurred with the DB ! A rollback will be performed...\")\n        conn.db_session.rollback()\n    return tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregularize function for the base class.", "response": "def regularized_function(x,y,func,bins=None,range=None):\n    \"\"\"Compute func() over data aggregated in bins.\n\n    (x,y) --> (x', func(Y'))  with Y' = {y: y(x) where x in x' bin}\n\n    First the data is collected in bins x' along x and then func is applied to\n    all data points Y' that have been collected in the bin.\n\n    :Arguments:\n       x\n          abscissa values (for binning)\n       y\n          ordinate values (func is applied)\n       func\n          a numpy ufunc that takes one argument, func(Y')\n       bins\n          number or array\n       range\n          limits (used with number of bins)\n\n    :Returns:\n       F,edges\n          function and edges (midpoints = 0.5*(edges[:-1]+edges[1:]))\n    \"\"\"\n    _x = numpy.asarray(x)\n    _y = numpy.asarray(y)\n\n    # setup of bins from numpy.histogram\n    if (range is not None):\n        mn, mx = range\n        if (mn > mx):\n            raise ValueError('max must be larger than min in range parameter.')\n\n    if not numpy.iterable(bins):\n        if range is None:\n            range = (_x.min(), _x.max())\n        mn, mx = [float(mi) for mi in range]\n        if mn == mx:\n            mn -= 0.5\n            mx += 0.5\n        bins = numpy.linspace(mn, mx, bins+1, endpoint=True)\n    else:\n        bins = numpy.asarray(bins)\n        if (numpy.diff(bins) < 0).any():\n            raise ValueError('bins must increase monotonically.')\n\n    sorting_index = numpy.argsort(_x)\n    sx = _x[sorting_index]\n    sy = _y[sorting_index]\n\n    # boundaries in SORTED data that demarcate bins; position in bin_index is the bin number\n    bin_index = numpy.r_[sx.searchsorted(bins[:-1], 'left'),\n                         sx.searchsorted(bins[-1], 'right')]\n\n    # naive implementation: apply operator to each chunk = sy[start:stop] separately\n    #\n    # It's not clear to me how one could effectively block this procedure (cf\n    # block = 65536 in numpy.histogram) because there does not seem to be a\n    # general way to combine the chunks for different blocks, just think of\n    # func=median\n    F = numpy.zeros(len(bins)-1)  # final function\n    F[:] = [func(sy[start:stop]) for start,stop in izip(bin_index[:-1],bin_index[1:])]\n    return F,bins"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms parsed tree for grammar with removed unit rules.", "response": "def unit_rules_restore(root):\n    # type: (Nonterminal) -> Nonterminal\n    \"\"\"\n    Transform parsed tree for grammar with removed unit rules.\n    The unit rules will be returned back to the tree.\n    :param root: Root of the parsed tree.\n    :return: Modified tree.\n    \"\"\"\n    items = Traversing.post_order(root)\n    items = filter(lambda x: isinstance(x, ReducedUnitRule), items)\n    for rule in items:\n        parent_nonterm = rule.from_symbols[0]  # type: Nonterminal\n        # restore chain of unit rules\n        for r in rule.by_rules:\n            created_rule = r()  # type: Rule\n            parent_nonterm._set_to_rule(created_rule)\n            created_rule._from_symbols.append(parent_nonterm)\n            created_nonterm = r.toSymbol()  # type: Nonterminal\n            created_rule._to_symbols.append(created_nonterm)\n            created_nonterm._set_from_rule(created_rule)\n            parent_nonterm = created_nonterm\n        # restore last rule\n        last_rule = rule.end_rule()  # type: Rule\n        last_rule._from_symbols.append(parent_nonterm)\n        parent_nonterm._set_to_rule(last_rule)\n        for ch in rule.to_symbols:  # type: Nonterminal\n            ch._set_from_rule(last_rule)\n            last_rule._to_symbols.append(ch)\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the remaining bytes in the buffer.", "response": "def remaining_bytes(self, meta=True):\n        \"\"\"\n        Returns the remaining, unread bytes from the buffer.\n        \"\"\"\n        pos, self._pos = self._pos, len(self.buffer)\n        return self.buffer[pos:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode the packet off the byte string and returns a Packet object.", "response": "def decode(self, bytes):\n        \"\"\"\n        Decodes the packet off the byte string.\n        \"\"\"\n\n        self.buffer = bytes\n        self._pos = 0\n\n        Packet = identifier.get_packet_from_id(self._read_variunt())\n\n        # unknown packets will be None from the identifier\n        if Packet is None:\n            return None\n\n        packet = Packet()\n        packet.ParseFromString(self.remaining_bytes())\n        return packet"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode(self, packet):\n\n        id = identifier.get_packet_id(packet)\n        if id is None:\n            raise EncoderException('unknown packet')\n\n        self._write_variunt(id)\n        self._write(packet.SerializeToString())\n\n        return bytes(self.buffer)", "response": "Encodes a single packet into a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, data):\n\n        # todo: copy-paste code from representation.validate -> refactor\n\n        if data is None:\n            return None\n\n        prototype = {}\n        errors = {}\n\n        # create and populate the prototype\n        for field_name, field_spec in self.spec.fields.items():\n            try:\n                value = self._create_value(data, field_name, self.spec)\n            except ValidationError, e:\n                if field_name not in self.default_create_values:\n                    if hasattr(e, 'message_dict'):\n                        # prefix error keys with top level field name\n                        errors.update(dict(zip(\n                            [field_name + '.' + key for key in e.message_dict.keys()],\n                            e.message_dict.values())))\n                    else:\n                        errors[field_name] = e.messages\n            else:\n                key_name = self.property_name_map[field_name]\n                prototype[key_name] = value\n\n        # check extra fields\n        if self.prevent_extra_fields:\n            extras = set(data.keys()) - set(self.property_name_map.keys())\n            if extras:\n                errors[', '.join(extras)] = ['field(s) not allowed']\n\n        # if errors, raise ValidationError\n        if errors:\n            raise ValidationError(errors)\n\n        # return dict or object based on the prototype\n        _data = deepcopy(self.default_create_values)\n        _data.update(prototype)\n        if self.klass:\n            instance = self.klass()\n            instance.__dict__.update(prototype)\n            return instance\n        else:\n            return prototype", "response": "Create object from the given data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize(self, entity, request=None):\n\n        def should_we_insert(value, field_spec):\n            return value not in self.missing or field_spec.required\n\n        errors = {}\n        ret = {}\n\n        for field_name, field_spec in self.spec.fields.items():\n            value = self._get_value_for_serialization(entity, field_name, field_spec)\n            func = self._get_serialize_func(field_name, self.spec)\n            try:\n                # perform serialization\n                value = func(value, entity, request)\n                if should_we_insert(value, field_spec):\n                    ret[field_name] = value\n            except ValidationError, e:\n                if hasattr(e, 'message_dict'):\n                    # prefix error keys with top level field name\n                    errors.update(dict(zip(\n                        [field_name + '.' + key for key in e.message_dict.keys()],\n                        e.message_dict.values())))\n                else:\n                    errors[field_name] = e.messages\n\n        if errors:\n            raise ValidationError(errors)\n\n        return None if ret == {} else ret", "response": "Serialize the entity into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_value(self, data, name, spec):\n\n        field = getattr(self, 'create_' + name, None)\n        if field:\n            # this factory has a special creator function for this field\n            return field(data, name, spec)\n        value = data.get(name)\n        return spec.fields[name].clean(value)", "response": "Create the value for a field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_serialize_func(self, name, spec):\n        func = getattr(self, 'serialize_' + name, None)\n        if func:\n            # this factory has a special serializer function for this field\n            return func\n        func = getattr(spec.fields[name], 'serialize', None)\n        if func:\n            return func\n        return lambda value, entity, request: value", "response": "Return the function that is used for serialization."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the value of the field in the entity.", "response": "def _get_value_for_serialization(self, data, name, spec):\n        \"\"\" Return the value of the field in entity (or ``None``). \"\"\"\n        name = self.property_name_map[name]\n        return getattr(data, name, None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating property name map based on aliases.", "response": "def _create_mappings(self, spec):\n        \"\"\" Create property name map based on aliases. \"\"\"\n        ret = dict(zip(set(spec.fields), set(spec.fields)))\n        ret.update(dict([(n, s.alias) for n, s in spec.fields.items() if s.alias]))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_substrings(s):\n    ''' yields all substrings of a string '''\n    join = ''.join\n    for i in range(1, len(s) + 1):\n        for sub in window(s, i):\n            yield join(sub)", "response": "yields all substrings of a string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef equivalent_release_for_product(self, product):\n        releases = self._default_manager.filter(\n            version__startswith=self.major_version() + '.',\n            channel=self.channel, product=product).order_by('-version')\n        if not getattr(settings, 'DEV', False):\n            releases = releases.filter(is_public=True)\n        if releases:\n            return sorted(\n                sorted(releases, reverse=True,\n                       key=lambda r: len(r.version.split('.'))),\n                reverse=True, key=lambda r: r.version.split('.')[1])[0]", "response": "Returns the release for a specified product with the same\n        channel and major version with the highest minor version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notes(self, public_only=False):\n        tag_index = dict((tag, i) for i, tag in enumerate(Note.TAGS))\n        notes = self.note_set.order_by('-sort_num', 'created')\n        if public_only:\n            notes = notes.filter(is_public=True)\n        known_issues = [n for n in notes if n.is_known_issue_for(self)]\n        new_features = sorted(\n            sorted(\n                (n for n in notes if not n.is_known_issue_for(self)),\n                key=lambda note: tag_index.get(note.tag, 0)),\n            key=lambda n: n.tag == 'Fixed' and n.note.startswith(self.version),\n            reverse=True)\n\n        return new_features, known_issues", "response": "Retrieve a list of Note instances that should be shown for this release."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict all data about the release", "response": "def to_dict(self):\n        \"\"\"Return a dict all all data about the release\"\"\"\n        data = model_to_dict(self, exclude=['id'])\n        data['title'] = unicode(self)\n        data['slug'] = self.slug\n        data['release_date'] = self.release_date.date().isoformat()\n        data['created'] = self.created.isoformat()\n        data['modified'] = self.modified.isoformat()\n        new_features, known_issues = self.notes(public_only=False)\n        for note in known_issues:\n            note.tag = 'Known'\n        data['notes'] = [n.to_dict(self) for n in chain(new_features, known_issues)]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of only the basic data about the release", "response": "def to_simple_dict(self):\n        \"\"\"Return a dict of only the basic data about the release\"\"\"\n        return {\n            'version': self.version,\n            'product': self.product,\n            'channel': self.channel,\n            'is_public': self.is_public,\n            'slug': self.slug,\n            'title': unicode(self),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef playToneList(self, playList = None):\n        if playList == None: return False\n        for t in playList:\n            self.playTone(t[\"freq\"], t[\"reps\"], t[\"delay\"], t[\"muteDelay\"])\n\n        self.stopTone()\n        return True", "response": "Play a tone from a list of tones."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all(self, instance):\n        url = self._url.format(instance=instance)\n        response = requests.get(url, **self._default_request_kwargs)\n        data = self._get_response_data(response)\n        return self._concrete_acl_list(data)", "response": "Get all ACLs associated with the specified instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an ACL entry for the specified instance.", "response": "def create(self, instance, cidr_mask, description, **kwargs):\n        \"\"\"Create an ACL entry for the specified instance.\n\n        :param str instance: The name of the instance to associate the new ACL entry with.\n        :param str cidr_mask: The IPv4 CIDR mask for the new ACL entry.\n        :param str description: A short description for the new ACL entry.\n        :param collector kwargs: (optional) Additional key=value pairs to be supplied to the\n            creation payload. **Caution:** fields unrecognized by the API will cause this request\n            to fail with a 400 from the API.\n        \"\"\"\n        # Build up request data.\n        url = self._url.format(instance=instance)\n        request_data = {\n            'cidr_mask': cidr_mask,\n            'description': description\n        }\n        request_data.update(kwargs)\n\n        # Call to create an instance.\n        response = requests.post(\n            url,\n            data=json.dumps(request_data),\n            **self._default_request_kwargs\n        )\n\n        # Log outcome of instance creation request.\n        if response.status_code == 200:\n            logger.info('Successfully created a new ACL for instance {} with: {}.'\n                        .format(instance, request_data))\n        else:\n            logger.info('Failed to create a new ACL for instance {} with: {}.'\n                        .format(instance, request_data))\n\n        data = self._get_response_data(response)\n        return self._concrete_acl(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an ACL by ID belonging to the instance specified by name.", "response": "def get(self, instance, acl):\n        \"\"\"Get an ACL by ID belonging to the instance specified by name.\n\n        :param str instance: The name of the instance from which to fetch the ACL.\n        :param str acl: The ID of the ACL to fetch.\n        :returns: An :py:class:`Acl` object, or None if ACL does not exist.\n        :rtype: :py:class:`Acl`\n        \"\"\"\n        base_url = self._url.format(instance=instance)\n        url = '{base}{aclid}/'.format(base=base_url, aclid=acl)\n        response = requests.get(url, **self._default_request_kwargs)\n        data = self._get_response_data(response)\n        return self._concrete_acl(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting an ACL by ID belonging to the instance specified by name.", "response": "def delete(self, instance, acl):\n        \"\"\"Delete an ACL by ID belonging to the instance specified by name.\n\n        :param str instance: The name of the instance on which the ACL exists.\n        :param str acll: The ID of the ACL to delete.\n        \"\"\"\n        base_url = self._url.format(instance=instance)\n        url = '{base}{aclid}/'.format(base=base_url, aclid=acl)\n        response = requests.delete(url, **self._default_request_kwargs)\n\n        if response.status_code == 200:\n            logger.info('Successfully deleted ACL {}'.format(acl))\n        else:\n            logger.info('Failed to delete ACL {}'.format(acl))\n            logger.info('Response: [{0}] {1}'.format(response.status_code, response.content))\n            raise errors.ObjectRocketException('Failed to delete ACL.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _concrete_acl_list(self, acl_docs):\n        if not acl_docs:\n            return []\n\n        return list(filter(None, [self._concrete_acl(acl_doc=doc) for doc in acl_docs]))", "response": "Concretize a list of ACL documents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef first(pipe, items=1):\n    ''' first is essentially the next() function except it's second argument\n        determines how many of the first items you want. If items is more than\n        1 the output is an islice of the generator. If items is 1, the first\n        item is returned\n    '''\n    pipe = iter(pipe)\n    return next(pipe) if items == 1 else islice(pipe, 0, items)", "response": "first is essentially the next function except it s second argument\n    determines how many of the first items you want."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new State", "response": "def create_state(cls, state, **kwargs):\n        \"\"\"Create State\n\n        Create a new State\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_state(state, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param State state: Attributes of state to create (required)\n        :return: State\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_state_with_http_info(state, **kwargs)\n        else:\n            (data) = cls._create_state_with_http_info(state, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_state_by_id(cls, state_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_state_by_id_with_http_info(state_id, **kwargs)\n        else:\n            (data) = cls._delete_state_by_id_with_http_info(state_id, **kwargs)\n            return data", "response": "Delete an instance of State by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_state_by_id(cls, state_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_state_by_id_with_http_info(state_id, **kwargs)\n        else:\n            (data) = cls._get_state_by_id_with_http_info(state_id, **kwargs)\n            return data", "response": "Find State by ID Return single instance of State by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_states(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_states_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_states_with_http_info(**kwargs)\n            return data", "response": "List all states in a specific locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing all attributes of State AttributeNames", "response": "def replace_state_by_id(cls, state_id, state, **kwargs):\n        \"\"\"Replace State\n\n        Replace all attributes of State\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_state_by_id(state_id, state, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str state_id: ID of state to replace (required)\n        :param State state: Attributes of state to replace (required)\n        :return: State\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_state_by_id_with_http_info(state_id, state, **kwargs)\n        else:\n            (data) = cls._replace_state_by_id_with_http_info(state_id, state, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates attributes of State", "response": "def update_state_by_id(cls, state_id, state, **kwargs):\n        \"\"\"Update State\n\n        Update attributes of State\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_state_by_id(state_id, state, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str state_id: ID of state to update. (required)\n        :param State state: Attributes of state to update. (required)\n        :return: State\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_state_by_id_with_http_info(state_id, state, **kwargs)\n        else:\n            (data) = cls._update_state_by_id_with_http_info(state_id, state, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_list_of_dictionaries_into_database_tables(\n        dbConn,\n        log,\n        dictList,\n        dbTableName,\n        uniqueKeyList=[],\n        dateModified=False,\n        dateCreated=True,\n        batchSize=2500,\n        replace=False,\n        dbSettings=False):\n    \"\"\"insert list of dictionaries into database tables\n\n    **Key Arguments:**\n        - ``dbConn`` -- mysql database connection\n        - ``log`` -- logger\n        - ``dictList`` -- list of python dictionaries to add to the database table\n        - ``dbTableName`` -- name of the database table\n        - ``uniqueKeyList`` -- a list of column names to append as a unique constraint on the database\n        - ``dateModified`` -- add the modification date as a column in the database\n        - ``dateCreated`` -- add the created date as a column in the database\n        - ``batchSize`` -- batch the insert commands into *batchSize* batches\n        - ``replace`` -- repalce row if a duplicate is found\n        - ``dbSettings`` -- pass in the database settings so multiprocessing can establish one connection per process (might not be faster)\n\n    **Return:**\n        - None\n\n    **Usage:**\n\n        .. code-block:: python\n\n            from fundamentals.mysql import insert_list_of_dictionaries_into_database_tables\n            insert_list_of_dictionaries_into_database_tables(\n                dbConn=dbConn,\n                log=log,\n                dictList=dictList,\n                dbTableName=\"test_insert_many\",\n                uniqueKeyList=[\"col1\", \"col3\"],\n                dateModified=False,\n                batchSize=2500\n            )\n    \"\"\"\n\n    log.debug(\n        'completed the ````insert_list_of_dictionaries_into_database_tables`` function')\n\n    global count\n    global totalCount\n    global globalDbConn\n    global sharedList\n\n    reDate = re.compile('^[0-9]{4}-[0-9]{2}-[0-9]{2}T')\n\n    if dbSettings:\n        globalDbConn = dbSettings\n    else:\n        globalDbConn = dbConn\n\n    if len(dictList) == 0:\n        log.warning(\n            'the dictionary to be added to the database is empty' % locals())\n        return None\n\n    if len(dictList):\n        convert_dictionary_to_mysql_table(\n            dbConn=dbConn,\n            log=log,\n            dictionary=dictList[0],\n            dbTableName=dbTableName,\n            uniqueKeyList=uniqueKeyList,\n            dateModified=dateModified,\n            reDatetime=reDate,\n            replace=replace,\n            dateCreated=dateCreated)\n        dictList = dictList[1:]\n\n    dbConn.autocommit(False)\n\n    if len(dictList):\n\n        total = len(dictList)\n        batches = int(total / batchSize)\n\n        start = 0\n        end = 0\n        sharedList = []\n        for i in range(batches + 1):\n            end = end + batchSize\n            start = i * batchSize\n            thisBatch = dictList[start:end]\n            sharedList.append((thisBatch, end))\n\n        totalCount = total + 1\n        ltotalCount = totalCount\n\n        print \"Starting to insert %(ltotalCount)s rows into %(dbTableName)s\" % locals()\n\n        print dbSettings\n\n        if dbSettings == False:\n\n            fmultiprocess(\n                log=log,\n                function=_insert_single_batch_into_database,\n                inputArray=range(len(sharedList)),\n                dbTableName=dbTableName,\n                uniqueKeyList=uniqueKeyList,\n                dateModified=dateModified,\n                replace=replace,\n                batchSize=batchSize,\n                reDatetime=reDate,\n                dateCreated=dateCreated\n            )\n\n        else:\n            fmultiprocess(log=log, function=_add_dictlist_to_database_via_load_in_file,\n                          inputArray=range(len(sharedList)), dbTablename=dbTableName,\n                          dbSettings=dbSettings, dateModified=dateModified)\n\n        sys.stdout.write(\"\\x1b[1A\\x1b[2K\")\n        print \"%(ltotalCount)s / %(ltotalCount)s rows inserted into %(dbTableName)s\" % locals()\n\n    log.debug(\n        'completed the ``insert_list_of_dictionaries_into_database_tables`` function')\n    return None", "response": "insert list of dictionaries into database tables"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert a single batch into the database", "response": "def _insert_single_batch_into_database(\n        batchIndex,\n        log,\n        dbTableName,\n        uniqueKeyList,\n        dateModified,\n        replace,\n        batchSize,\n        reDatetime,\n        dateCreated):\n    \"\"\"*summary of function*\n\n    **Key Arguments:**\n        - ``batchIndex`` -- the index of the batch to insert\n        - ``dbConn`` -- mysql database connection\n        - ``log`` -- logger\n\n    **Return:**\n        - None\n\n    **Usage:**\n        .. todo::\n\n            add usage info\n            create a sublime snippet for usage\n\n        .. code-block:: python \n\n            usage code            \n    \"\"\"\n    log.debug('starting the ``_insert_single_batch_into_database`` function')\n\n    global totalCount\n    global globalDbConn\n    global sharedList\n\n    batch = sharedList[batchIndex]\n\n    reDate = reDatetime\n\n    if isinstance(globalDbConn, dict):\n        # SETUP ALL DATABASE CONNECTIONS\n\n        dbConn = database(\n            log=log,\n            dbSettings=globalDbConn,\n            autocommit=False\n        ).connect()\n    else:\n        dbConn = globalDbConn\n\n    count = batch[1]\n    if count > totalCount:\n        count = totalCount\n    ltotalCount = totalCount\n\n    inserted = False\n    while inserted == False:\n\n        if not replace:\n            insertVerb = \"INSERT IGNORE\"\n        else:\n            insertVerb = \"INSERT IGNORE\"\n\n        uniKeys = set().union(*(d.keys() for d in batch[0]))\n        tmp = []\n        tmp[:] = [m.replace(\" \", \"_\").replace(\n            \"-\", \"_\") for m in uniKeys]\n        uniKeys = tmp\n\n        myKeys = '`,`'.join(uniKeys)\n        vals = [tuple([None if d[k] in [\"None\", None] else str(d[k])\n                       for k in uniKeys]) for d in batch[0]]\n        valueString = (\"%s, \" * len(vals[0]))[:-2]\n        insertCommand = insertVerb + \"\"\" INTO `\"\"\" + dbTableName + \\\n            \"\"\"` (`\"\"\" + myKeys + \"\"\"`, dateCreated) VALUES (\"\"\" + \\\n            valueString + \"\"\", NOW())\"\"\"\n\n        if not dateCreated:\n            insertCommand = insertCommand.replace(\n                \", dateCreated)\", \")\").replace(\", NOW())\", \")\")\n\n        dup = \"\"\n        if replace:\n            dup = \" ON DUPLICATE KEY UPDATE \"\n            for k in uniKeys:\n                dup = \"\"\"%(dup)s %(k)s=values(%(k)s),\"\"\" % locals()\n            dup = \"\"\"%(dup)s updated=1, dateLastModified=NOW()\"\"\" % locals()\n\n        insertCommand = insertCommand + dup\n\n        insertCommand = insertCommand.replace('\\\\\"\"', '\\\\\" \"')\n        insertCommand = insertCommand.replace('\"\"', \"null\")\n        insertCommand = insertCommand.replace('\"None\"', 'null')\n\n        message = \"\"\n        # log.debug('adding new data to the %s table; query: %s' %\n        # (dbTableName, addValue))\n        try:\n            message = writequery(\n                log=log,\n                sqlQuery=insertCommand,\n                dbConn=dbConn,\n                Force=True,\n                manyValueList=vals\n            )\n        except:\n            theseInserts = []\n            for aDict in batch[0]:\n\n                insertCommand, valueTuple = convert_dictionary_to_mysql_table(\n                    dbConn=dbConn,\n                    log=log,\n                    dictionary=aDict,\n                    dbTableName=dbTableName,\n                    uniqueKeyList=uniqueKeyList,\n                    dateModified=dateModified,\n                    returnInsertOnly=True,\n                    replace=replace,\n                    reDatetime=reDate,\n                    skipChecks=True\n                )\n                theseInserts.append(valueTuple)\n\n            message = \"\"\n            # log.debug('adding new data to the %s table; query: %s' %\n            # (dbTableName, addValue))\n            message = writequery(\n                log=log,\n                sqlQuery=insertCommand,\n                dbConn=dbConn,\n                Force=True,\n                manyValueList=theseInserts\n            )\n\n        if message == \"unknown column\":\n            for aDict in batch:\n                convert_dictionary_to_mysql_table(\n                    dbConn=dbConn,\n                    log=log,\n                    dictionary=aDict,\n                    dbTableName=dbTableName,\n                    uniqueKeyList=uniqueKeyList,\n                    dateModified=dateModified,\n                    reDatetime=reDate,\n                    replace=replace\n                )\n        else:\n            inserted = True\n\n        dbConn.commit()\n\n    log.debug('completed the ``_insert_single_batch_into_database`` function')\n    return \"None\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates directory if that does not exist.", "response": "def make_directory(path):\n        \"\"\" Create directory if that not exists. \"\"\"\n        try:\n            makedirs(path)\n            logging.debug('Directory created: {0}'.format(path))\n\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_file(self, from_path, to_path):\n        if not op.exists(op.dirname(to_path)):\n            self.make_directory(op.dirname(to_path))\n\n        shutil.copy(from_path, to_path)\n        logging.debug('File copied: {0}'.format(to_path))", "response": "Copy file from one location to another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading self. params from configuration.", "response": "def params(self):\n        \"\"\" Read self params from configuration. \"\"\"\n        parser = JinjaInterpolationNamespace()\n        parser.read(self.configuration)\n        return dict(parser['params'] or {})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscan directory for templates.", "response": "def scan(cls, path):\n        \"\"\" Scan directory for templates. \"\"\"\n        result = []\n        try:\n            for _p in listdir(path):\n                try:\n                    result.append(Template(_p, op.join(path, _p)))\n                except ValueError:\n                    continue\n        except OSError:\n            pass\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        templates = self.prepare_templates()\n        if self.params.interactive:\n            keys = list(self.parser.default)\n            for key in keys:\n                if key.startswith('_'):\n                    continue\n                prompt = \"{0} (default is \\\"{1}\\\")? \".format(\n                    key, self.parser.default[key])\n\n                if _compat.PY2:\n                    value = raw_input(prompt.encode('utf-8')).decode('utf-8')\n                else:\n                    value = input(prompt.encode('utf-8'))\n\n                value = value.strip()\n                if value:\n                    self.parser.default[key] = value\n\n        self.parser.default['templates'] = tt = ','.join(\n            t.name for t in templates)\n        logging.warning(\"Paste templates: {0}\".format(tt))\n        self.make_directory(self.params.TARGET)\n\n        logging.debug(\"\\nDefault context:\\n----------------\")\n        logging.debug(\n            ''.join('{0:<15} {1}\\n'.format(*v)\n                    for v in self.parser.default.items())\n        )\n        return [t.paste(\n            **dict(self.parser.default.items())) for t in templates]", "response": "Prepare and paste self templates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iterate_templates(self):\n        return [t for dd in self.dirs for t in Template.scan(dd)]", "response": "Iterate self starter templates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump the files in the given array into the local drive.", "response": "def _dump_files_to_local_drive(bodies, theseUrls, log):\n    \"\"\"\n    *takes the files stored in memory and dumps them to the local drive*\n\n    ****Key Arguments:****\n      - ``bodies`` -- array of file data (currently stored in memory)\n      - ``theseUrls`` -- array of local files paths to dump the file data into\n      - ``log`` -- the logger\n\n    **Return:**\n      - ``None``\n    \"\"\"\n    j = 0\n    log.debug(\"attempting to write file data to local drive\")\n    log.debug('%s URLS = %s' % (len(theseUrls), str(theseUrls),))\n    for body in bodies:\n        try:\n            if theseUrls[j]:\n                with open(theseUrls[j], 'w') as f:\n                    f.write(body)\n                f.close()\n            j += 1\n        except Exception, e:\n            log.error(\n                \"could not write downloaded file to local drive - failed with this error %s: \" %\n                (str(e),))\n            return -1\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_shortcuts(self):\n        '''\n        .. versionchanged:: 0.14\n            Add keyboard shortcuts to set neighbouring electrode states based\n            on directional input using ``<Control>`` key plus the corresponding\n            direction (e.g., ``<Control>Up``)\n        '''\n        def control_protocol(command):\n            if self.plugin is not None:\n                self.plugin.execute_async('microdrop.gui.protocol_controller',\n                                          command)\n\n        def actuate_direction(direction):\n            if self.plugin is not None:\n                self.plugin.execute_async('microdrop.electrode_controller_plugin',\n                                          'set_electrode_direction_states',\n                                          direction=direction)\n\n        # Tie shortcuts to protocol controller commands (next, previous, etc.)\n        shortcuts = {'<Control>r': lambda *args:\n                     control_protocol('run_protocol'),\n                     '<Control>z': lambda *args: self.undo(),\n                     '<Control>y': lambda *args: self.redo(),\n                     'A': lambda *args: control_protocol('first_step'),\n                     'S': lambda *args: control_protocol('prev_step'),\n                     'D': lambda *args: control_protocol('next_step'),\n                     'F': lambda *args: control_protocol('last_step'),\n                     '<Control>Up': lambda *args: actuate_direction('up'),\n                     '<Control>Down': lambda *args: actuate_direction('down'),\n                     '<Control>Left': lambda *args: actuate_direction('left'),\n                     '<Control>Right': lambda *args:\n                     actuate_direction('right')}\n        register_shortcuts(self.widget.parent, shortcuts)", "response": "Register keyboard shortcuts to set neighbouring electrode states based on directional input using the corresponding ArcGIS keyboard command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cleanup_video(self):\n        '''\n        .. versionchanged:: 0.6.1\n            Log terminated video source process ID.\n        '''\n        if self.video_source_process is not None:\n            self.video_source_process.terminate()\n            logger.info('Terminated video process: %s',\n                        self.video_source_process.pid)\n            self.video_source_process = None", "response": "Cleanup the video source process."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the selected electrode state.", "response": "def on_canvas_slave__electrode_selected(self, slave, data):\n        '''\n        .. versionchanged:: 0.11\n            Clear any temporary routes (drawn while mouse is down) from routes\n            list.\n\n        .. versionchanged:: 0.11.3\n            Clear temporary routes by setting ``df_routes`` property of\n            :attr:`canvas_slave`.\n        '''\n        if self.plugin is None:\n            return\n        # XXX Negative `route_i` corresponds to temporary route being\n        # drawn.  Since electrode selection terminates route drawing, clear any\n        # rows corresponding to negative `route_i` values from the routes\n        # table.\n        slave.df_routes = slave.df_routes.loc[slave.df_routes.route_i >=\n                                              0].copy()\n        state = self.canvas_slave.electrode_states.get(data['electrode_id'], 0)\n        self.plugin.execute_async('microdrop.electrode_controller_plugin',\n                                  'set_electrode_states',\n                                  electrode_states=pd\n                                  .Series([not state],\n                                          index=[data['electrode_id']]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess pair of selected electrodes.", "response": "def on_canvas_slave__electrode_pair_selected(self, slave, data):\n        '''\n        Process pair of selected electrodes.\n\n        For now, this consists of finding the shortest path between the two\n        electrodes and appending it to the list of droplet routes for the\n        current step.\n\n        Note that the droplet routes for a step are stored in a frame/table in\n        the `DmfDeviceController` step options.\n\n\n        .. versionchanged:: 0.11\n            Clear any temporary routes (drawn while mouse is down) from routes\n            list.\n\n        .. versionchanged:: 0.11.3\n            Clear temporary routes by setting ``df_routes`` property of\n            :attr:`canvas_slave`.\n        '''\n        import networkx as nx\n\n        source_id = data['source_id']\n        target_id = data['target_id']\n\n        if self.canvas_slave.device is None or self.plugin is None:\n            return\n        # XXX Negative `route_i` corresponds to temporary route being\n        # drawn.  Since electrode pair selection terminates route drawing,\n        # clear any rows corresponding to negative `route_i` values from the\n        # routes table.\n        slave.df_routes = slave.df_routes.loc[slave.df_routes.route_i >=\n                                              0].copy()\n        try:\n            shortest_path = self.canvas_slave.device.find_path(source_id,\n                                                               target_id)\n            self.plugin.execute_async('droplet_planning_plugin',\n                                      'add_route', drop_route=shortest_path)\n        except nx.NetworkXNoPath:\n            logger.error('No path found between %s and %s.', source_id,\n                         target_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws temporary route currently being formed and update routes table by setting df_routes property of self. canvas_slave. df_routes.", "response": "def on_canvas_slave__route_electrode_added(self, slave, electrode_id):\n        '''\n        .. versionchanged:: 0.11\n            Draw temporary route currently being formed.\n\n        .. versionchanged:: 0.11.3\n            Update routes table by setting ``df_routes`` property of\n            :attr:`canvas_slave`.\n        '''\n        logger.debug('Route electrode added: %s', electrode_id)\n        if slave._route.electrode_ids is None:\n            return\n        df_route = pd.DataFrame([[-1, e, i] for i, e in\n                                 enumerate(slave._route.electrode_ids)],\n                                columns=['route_i', 'electrode_i',\n                                         'transition_i'])\n        # XXX Negative `route_i` corresponds to temporary route being\n        # drawn.  Append row entries for temporary route to existing routes\n        # table.\n        df_routes = slave.df_routes.loc[slave.df_routes.route_i >= 0].copy()\n        self.canvas_slave.df_routes = pd.concat([df_routes, df_route])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ping_hub(self):\n        '''\n        Attempt to ping the ZeroMQ plugin hub to verify connection is alive.\n\n        If ping is successful, record timestamp.\n        If ping is unsuccessful, call `on_heartbeat_error` method.\n        '''\n        if self.plugin is not None:\n            try:\n                self.plugin.execute(self.plugin.hub_name, 'ping', timeout_s=1,\n                                    silent=True)\n            except IOError:\n                self.on_heartbeat_error()\n            else:\n                self.heartbeat_alive_timestamp = datetime.now()\n                logger.debug('Hub connection alive as of %s',\n                             self.heartbeat_alive_timestamp)\n                return True", "response": "Ping ZeroMQ plugin hub to verify connection is alive."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_electrode_states_updated(self, states):\n        '''\n        .. versionchanged:: 0.12\n            Refactor to use :meth:`on_electrode_states_set`.\n        '''\n        states['electrode_states'] = \\\n            states['electrode_states'].combine_first(self.canvas_slave\n                                                     .electrode_states)\n        self.on_electrode_states_set(states)", "response": "Update the list of electrodes in the master."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering and draw updated ** static ** electrode actuations layer on canvas.", "response": "def on_electrode_states_set(self, states):\n        '''\n        Render and draw updated **static** electrode actuations layer on\n        canvas.\n        '''\n        if (self.canvas_slave.electrode_states\n                .equals(states['electrode_states'])):\n            return\n\n        self.canvas_slave.electrode_states = states['electrode_states']\n\n        surface = self.canvas_slave.render_static_electrode_state_shapes()\n        self.canvas_slave.set_surface('static_electrode_state_shapes', surface)\n        self.canvas_slave.cairo_surface = flatten_surfaces(self.canvas_slave\n                                                           .df_surfaces)\n        gobject.idle_add(self.canvas_slave.draw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_dynamic_electrode_states_set(self, states):\n        '''\n        Render and draw updated **dynamic** electrode actuations layer on\n        canvas.\n\n\n        .. versionadded:: 0.12\n        '''\n        self.canvas_slave._dynamic_electrodes = states\n\n        surface = self.canvas_slave.render_dynamic_electrode_state_shapes()\n        self.canvas_slave.set_surface('dynamic_electrode_state_shapes',\n                                      surface)\n        self.canvas_slave.cairo_surface = flatten_surfaces(self.canvas_slave\n                                                           .df_surfaces)\n        gobject.idle_add(self.canvas_slave.draw)", "response": "Render and draw updated dynamic electrode actuations layer on\nMimeType."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_canvas_slave__routes_set(self, slave, df_routes):\n        '''\n        .. versionadded:: 0.11.3\n        '''\n        self.canvas_slave.set_surface('routes',\n                                      self.canvas_slave.render_routes())\n        self.canvas_slave.cairo_surface = flatten_surfaces(self.canvas_slave\n                                                           .df_surfaces)\n        gtk.idle_add(self.canvas_slave.draw)", "response": "Set the routes in the canvas slave."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a global command.", "response": "def on_canvas_slave__global_command(self, slave, group, command, data):\n        '''\n        .. versionadded:: 0.13\n\n            Execute global command (i.e., command not tied to a specific\n            electrode or route).\n        '''\n        def command_callback(reply):\n            _L().debug('%s.%s()', group, command)\n            # Decode content to raise error, if necessary.\n            try:\n                decode_content_data(reply)\n            except Exception:\n                _L().error('Global command error.', exc_info=True)\n        self.plugin.execute_async(group, command, callback=command_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_string_version(name,\n                       default=DEFAULT_STRING_NOT_FOUND,\n                       allow_ambiguous=True):\n    \"\"\"\n    Get string version from installed package information.\n\n    It will return :attr:`default` value when the named package is not\n    installed.\n\n    Parameters\n    -----------\n    name : string\n        An application name used to install via setuptools.\n    default : string\n        A default returning value used when the named application is not\n        installed yet\n    allow_ambiguous : boolean\n        ``True`` for allowing ambiguous version information.\n        Turn this argument to ``False`` if ``get_string_version`` report wrong\n        version.\n\n    Returns\n    --------\n    string\n        A version string or not found message (:attr:`default`)\n\n    Examples\n    --------\n    >>> import re\n    >>> v = get_string_version('app_version', allow_ambiguous=True)\n    >>> re.match('^\\d+.\\d+\\.\\d+', v) is not None\n    True\n    >>> get_string_version('distribution_which_is_not_installed')\n    'Please install this application with setup.py'\n    \"\"\"\n    # get filename of callar\n    callar = inspect.getouterframes(inspect.currentframe())[1][1]\n    if callar.startswith('<doctest'):\n        # called from doctest, find written script file\n        callar = inspect.getouterframes(inspect.currentframe())[-1][1]\n    # get version info from distribution\n    try:\n        di = get_distribution(name)\n        installed_directory = os.path.join(di.location, name)\n        if not callar.startswith(installed_directory) and not allow_ambiguous:\n            # not installed, but there is another version that *is*\n            raise DistributionNotFound\n    except DistributionNotFound:\n        return default\n    else:\n        return di.version", "response": "Get string version from installed package information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple version from installed package information for easy handling.", "response": "def get_tuple_version(name,\n                      default=DEFAULT_TUPLE_NOT_FOUND,\n                      allow_ambiguous=True):\n    \"\"\"\n    Get tuple version from installed package information for easy handling.\n\n    It will return :attr:`default` value when the named package is not\n    installed.\n\n    Parameters\n    -----------\n    name : string\n        An application name used to install via setuptools.\n    default : tuple\n        A default returning value used when the named application is not\n        installed yet\n    allow_ambiguous : boolean\n        ``True`` for allowing ambiguous version information.\n\n    Returns\n    --------\n    string\n        A version tuple\n\n    Examples\n    --------\n    >>> v = get_tuple_version('app_version', allow_ambiguous=True)\n    >>> len(v) >= 3\n    True\n    >>> isinstance(v[0], int)\n    True\n    >>> isinstance(v[1], int)\n    True\n    >>> isinstance(v[2], int)\n    True\n    >>> get_tuple_version('distribution_which_is_not_installed')\n    (0, 0, 0)\n    \"\"\"\n    def _prefer_int(x):\n        try:\n            return int(x)\n        except ValueError:\n            return x\n    version = get_string_version(name, default=default,\n                                 allow_ambiguous=allow_ambiguous)\n    # convert string version to tuple version\n    # prefer integer for easy handling\n    if isinstance(version, tuple):\n        # not found\n        return version\n    return tuple(map(_prefer_int, version.split('.')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets string and tuple versions from installed package information.", "response": "def get_versions(name,\n                 default_string=DEFAULT_STRING_NOT_FOUND,\n                 default_tuple=DEFAULT_TUPLE_NOT_FOUND,\n                 allow_ambiguous=True):\n    \"\"\"\n    Get string and tuple versions from installed package information\n\n    It will return :attr:`default_string` and :attr:`default_tuple` values when\n    the named package is not installed.\n\n    Parameters\n    -----------\n    name : string\n        An application name used to install via setuptools.\n    default : string\n        A default returning value used when the named application is not\n        installed yet\n    default_tuple : tuple\n        A default returning value used when the named application is not\n        installed yet\n    allow_ambiguous : boolean\n        ``True`` for allowing ambiguous version information.\n\n    Returns\n    --------\n    tuple\n        A version string and version tuple\n\n    Examples\n    --------\n    >>> import re\n    >>> v1, v2 = get_versions('app_version', allow_ambiguous=True)\n    >>> isinstance(v1, str)\n    True\n    >>> isinstance(v2, tuple)\n    True\n    >>> get_versions('distribution_which_is_not_installed')\n    ('Please install this application with setup.py', (0, 0, 0))\n    \"\"\"\n    version_string = get_string_version(name, default_string, allow_ambiguous)\n    version_tuple = get_tuple_version(name, default_tuple, allow_ambiguous)\n    return version_string, version_tuple"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_toSymbol(cls):\n        # type: (_MetaRule) -> object\n        \"\"\"\n        Get symbol from which the rule is rewrote.\n        :param cls: Rule for which return the symbol.\n        :return: Symbol from which the rule is rewrote.\n        :raise RuleNotDefinedException: If the rule is not defined.\n        :raise CantCreateSingleRuleException: If the rule consists of more rules.\n        :raise NotASingleSymbolException: If number of symbols on the left is more.\n        \"\"\"\n        if cls._traverse:\n            raise RuleNotDefinedException(cls)\n        if len(cls.rules) > 1:\n            raise CantCreateSingleRuleException(cls)\n        right = cls.rules[0][1]\n        if len(right) > 1:\n            raise NotASingleSymbolException(right)\n        return right[0]", "response": "Get the symbol from which the rule is rewrote."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_fromSymbol(cls):\n        # type: (_MetaRule) -> object\n        \"\"\"\n        Get symbol to which the rule is rewrote.\n        :param cls: Rule for which return the symbol.\n        :return: Symbol to which the rule is rewrote.\n        :raise RuleNotDefinedException: If the rule is not defined.\n        :raise CantCreateSingleRuleException: If the rule consists of more rules.\n        :raise NotASingleSymbolException: If number of symbols on the right is more.\n        \"\"\"\n        if cls._traverse:\n            raise RuleNotDefinedException(cls)\n        if len(cls.rules) > 1:\n            raise CantCreateSingleRuleException(cls)\n        left = cls.rules[0][0]\n        if len(left) > 1:\n            raise NotASingleSymbolException(left)\n        return left[0]", "response": "Get the symbol from the rule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the right part of the rule.", "response": "def _get_right(cls):\n        # type: (_MetaRule) -> List[object]\n        \"\"\"\n        Get right part of the rule.\n        :param cls: Rule for which return the right side.\n        :return: Symbols on the right side of the array.\n        :raise RuleNotDefinedException: If the rule is not defined.\n        :raise CantCreateSingleRuleException: If the rule consists of more rules.\n        :raise NotASingleSymbolException: If number of symbols on the left is more.\n        \"\"\"\n        if cls._traverse:\n            return [cls.toSymbol]\n        if len(cls.rules) > 1:\n            raise CantCreateSingleRuleException(cls)\n        return cls.rules[0][1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the left part of the rule.", "response": "def _get_left(cls):\n        # type: (_MetaRule) -> List[object]\n        \"\"\"\n        Get left part of the rule.\n        :param cls: Rule for which return the left side.\n        :return: Symbols on the left side of the array.\n        :raise RuleNotDefinedException: If the rule is not defined.\n        :raise CantCreateSingleRuleException: If the rule consists of more rules.\n        :raise NotASingleSymbolException: If number of symbols on the left is more.\n        \"\"\"\n        if cls._traverse:\n            return [cls.fromSymbol]\n        if len(cls.rules) > 1:\n            raise CantCreateSingleRuleException(cls)\n        return cls.rules[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the rule for which return the rule.", "response": "def _get_rule(cls):\n        # type: (_MetaRule) -> (List[object], List[object])\n        \"\"\"\n        Get rule on the Rule class.\n        :param cls: Rule for which return the rule.\n        :return: Rule inside the Rule class.\n        :raise RuleNotDefinedException: If the rule is not defined.\n        :raise CantCreateSingleRuleException: If the rule consists of more rules.\n        :raise NotASingleSymbolException: If number of symbols on the left is more.\n        \"\"\"\n        if cls._traverse:\n            return (cls.left, cls.right)\n        if len(cls.rules) > 1:\n            raise CantCreateSingleRuleException(cls)\n        return cls.rules[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_rules(cls):\n        # type: (_MetaRule) -> List[(List[object], List[object])]\n        \"\"\"\n        Get rules on the Rule class.\n        :param cls: Rule for which return the rules.\n        :return: Rules inside the Rule class.\n        :raise RuleNotDefinedException: If the rule is not defined.\n        :raise CantCreateSingleRuleException: If the rule consists of more rules.\n        :raise NotASingleSymbolException: If number of symbols on the left is more.\n        \"\"\"\n        cls._traverse = True\n        r = cls.rule\n        cls._traverse = False\n        return [r]", "response": "Returns the rules for the given class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate one side of the rule.", "response": "def _controlSide(cls, side, grammar):\n        # type: (_MetaRule, List[object], Grammar) -> None\n        \"\"\"\n        Validate one side of the rule.\n        :param side: Iterable side of the rule.\n        :param grammar: Grammar on which to validate.\n        :raise RuleSyntaxException: If invalid syntax is use.\n        :raise UselessEpsilonException: If useless epsilon is used.\n        :raise TerminalDoesNotExistsException: If terminal does not exists in the grammar.\n        :raise NonterminalDoesNotExistsException: If nonterminal does not exists in the grammar.\n        \"\"\"\n        if not isinstance(side, list):\n            raise RuleSyntaxException(cls, 'One side of rule is not enclose by list', side)\n        if len(side) == 0:\n            raise RuleSyntaxException(cls, 'One side of rule is not define', side)\n        if EPS in side and len(side) > 1:\n            raise UselessEpsilonException(cls)\n        for symb in side:\n            if isclass(symb) and issubclass(symb, Nonterminal):\n                if symb not in grammar.nonterminals:\n                    raise NonterminalDoesNotExistsException(cls, symb, grammar)\n            elif symb is EPS:\n                continue\n            elif symb not in grammar.terminals:\n                raise TerminalDoesNotExistsException(cls, symb, grammar)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating the class s rules.", "response": "def validate(cls, grammar):\n        # type: (_MetaRule, Grammar) -> None\n        \"\"\"\n        Perform rules validation of the class.\n        :param grammar: Grammar on which to validate.\n        :raise RuleSyntaxException: If invalid syntax is used.\n        :raise UselessEpsilonException: If epsilon used in rules in useless.\n        :raise TerminalDoesNotExistsException: If terminal does not exists in the grammar.\n        :raise NonterminalDoesNotExistsException: If nonterminal does not exists in the grammar.\n        \"\"\"\n        # check if the rule is not defined multiple times\n        defined = set(dir(cls))\n        if 'rules' in defined and len(defined & {'rule', 'left', 'right', 'toSymbol', 'fromSymbol'}) > 0 or \\\n                'rule' in defined and len(defined & {'left', 'right', 'toSymbol', 'fromSymbol'}) > 0 or \\\n                'left' in defined and 'fromSymbol' in defined or \\\n                'right' in defined and 'toSymbol' in defined:\n            raise MultipleDefinitionException(cls, 'Rule is defined multiple times')\n        # check if the rule is defined properly\n        all = cls.rules\n        if not isinstance(all, list):\n            raise RuleSyntaxException(cls, 'Rules property is not enclose in list')\n        for rule in all:\n            if not isinstance(rule, tuple):\n                raise RuleSyntaxException(cls, 'One of the rules is not enclose in tuple', rule)\n            if len(rule) != 2:\n                raise RuleSyntaxException(cls, 'One of the rules does not have define left and right part', rule)\n            left = rule[0]\n            right = rule[1]\n            cls._controlSide(left, grammar)\n            cls._controlSide(right, grammar)\n            if left == [EPS] and right == [EPS]:\n                raise UselessEpsilonException(cls)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise an exception if function argument is empty.", "response": "def no_empty_value(func):\n    \"\"\"Raises an exception if function argument is empty.\"\"\"\n    @wraps(func)\n    def wrapper(value):\n        if not value:\n            raise Exception(\"Empty value not allowed\")\n        return func(value)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts human boolean - like values to Python boolean.", "response": "def to_bool(value):\n    \"\"\"Converts human boolean-like values to Python boolean.\n\n    Falls back to :class:`bool` when ``value`` is not recognized.\n\n    :param value: the value to convert\n    :returns: ``True`` if value is truthy, ``False`` otherwise\n    :rtype: bool\n    \"\"\"\n    cases = {\n        '0': False,\n        'false': False,\n        'no': False,\n\n        '1': True,\n        'true': True,\n        'yes': True,\n    }\n    value = value.lower() if isinstance(value, basestring) else value\n    return cases.get(value, bool(value))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_to_etree(d, root):\n    def _to_etree(d, node):\n        if d is None or len(d) == 0:\n            return\n        elif isinstance(d, basestring):\n            node.text = d\n        elif isinstance(d, dict):\n            for k, v in d.items():\n                assert isinstance(k, basestring)\n                if k.startswith('#'):\n                    assert k == '#text'\n                    assert isinstance(v, basestring)\n                    node.text = v\n                elif k.startswith('@'):\n                    assert isinstance(v, basestring)\n                    node.set(k[1:], v)\n                elif isinstance(v, list):\n                    # No matter the child count, their parent will be the same.\n                    sub_elem = etree.SubElement(node, k)\n\n                    for child_num, e in enumerate(v):\n                        if e is None:\n                            if child_num == 0:\n                                # Found the first occurrence of an empty child,\n                                # skip creating of its XML repr, since it would be\n                                # the same as ``sub_element`` higher up.\n                                continue\n                            # A list with None element means an empty child node\n                            # in its parent, thus, recreating tags we have to go\n                            # up one level.\n                            # <node><child/></child></node> <=> {'node': 'child': [None, None]}\n                            _to_etree(node, k)\n                        else:\n                            # If this isn't first child and it's a complex\n                            # value (dict), we need to check if it's value\n                            # is equivalent to None.\n                            if child_num != 0 and not (isinstance(e, dict) and not all(e.values())):\n                                # At least one child was None, we have to create\n                                # a new parent-node, which will not be empty.\n                                sub_elem = etree.SubElement(node, k)\n                            _to_etree(e, sub_elem)\n                else:\n                    _to_etree(v, etree.SubElement(node, k))\n        elif etree.iselement(d):\n            # Supports the case, when we got an empty child and want to recreate it.\n            etree.SubElement(d, node)\n        else:\n            raise AttributeError('Argument is neither dict nor basestring.')\n\n    _to_etree(d, root)\n    return root", "response": "u Converts a dict to lxml. etree object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraversing a dictionary recursively and save path", "response": "def objwalk(self, obj, path=(), memo=None):\n        \"\"\"Traverse a dictionary recursively and save path\n\n        Taken from:\n  http://code.activestate.com/recipes/577982-recursively-walk-python-objects/\n\"\"\"\n\n        # dual python 2/3 compatability, inspired by the \"six\" library\n        string_types = (str, unicode) if str is bytes else (str, bytes)\n        iteritems = lambda mapping: getattr(mapping, 'iteritems', mapping.items)()\n\n        if memo is None:\n            memo = set()\n        iterator = None\n        if isinstance(obj, Mapping):\n            iterator = iteritems\n        elif isinstance(obj, (Sequence, Set)) and not isinstance(obj, string_types):\n            iterator = enumerate\n        if iterator:\n            if id(obj) not in memo:\n                memo.add(id(obj))\n                for path_component, value in iterator(obj):\n                    for result in self.objwalk(value, path + (path_component,), memo):\n                        yield result\n                memo.remove(id(obj))\n        else:\n            yield path, obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_cache_dir(directory):\n    global cache_dir\n\n    if directory is None:\n        cache_dir = None\n        return\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    if not os.path.isdir(directory):\n        raise ValueError(\"not a directory\")\n    cache_dir = directory", "response": "Set the directory to cache JSON responses from most API endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an ElementTree from elem_or_name updated it with text and attributes.", "response": "def create_element_tree(elem_or_name=None, text=None, **attribute_kwargs):\n    \"\"\"\n    Creates an ElementTree from elem_or_name, updated it with text and attributes.\n    If elem_or_name is None, a permanently empty ElementTree is returned.\n    :param elem_or_name: an Element or the name of the root element tag\n    :param text: optional text with which to update the root element\n    :param attribute_kwargs: optional attributes to add to the root element\n    :return: a new ElementTree with the specified root and attributes\n    \"\"\"\n\n    if elem_or_name is None:\n        return ElementTree()\n\n    is_elem = isinstance(elem_or_name, ElementType)\n    element = elem_or_name if is_elem else Element(elem_or_name)\n\n    if text is not None:\n        element.text = text\n\n    element.attrib.update(attribute_kwargs)\n\n    return ElementTree(element)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear only children from the parsed parent or named element.", "response": "def clear_children(parent_to_parse, element_path=None):\n    \"\"\"\n    Clears only children (not text or attributes) from the parsed parent\n    or named element.\n    \"\"\"\n\n    element = get_element(parent_to_parse, element_path)\n\n    if element is None:\n        return parent_to_parse\n    else:\n        elem_txt = element.text\n        elem_atr = element.attrib\n\n        element.clear()\n\n        element.text = elem_txt\n        element.attrib = elem_atr\n\n    return element"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_element(parent_to_parse, element_path=None):\n\n    element = get_element(parent_to_parse, element_path)\n\n    if element is None:\n        return parent_to_parse\n    else:\n        element.clear()\n\n    return element", "response": "Clears the specified element from the parsed parent node or named element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_element(from_element, to_element=None, path_to_copy=None):\n\n    from_element = get_element(from_element, path_to_copy)\n    dest_element = get_element(to_element, path_to_copy)\n\n    if from_element is None:\n        return None\n\n    if dest_element is None:\n        if path_to_copy is None:\n            dest_element = Element(from_element.tag)\n        else:\n            dest_element = insert_element(Element(from_element.tag), 0, path_to_copy)\n\n    dest_element.tag = from_element.tag\n    dest_element.text = from_element.text\n    dest_element.tail = from_element.tail\n    dest_element.attrib = from_element.attrib\n\n    copied_children = []\n\n    for elem in from_element:\n        copied_children.append(copy_element(elem))\n\n    for idx, child in enumerate(copied_children):\n        dest_element.insert(idx, child)\n\n    return dest_element", "response": "Copies the element at path_to_copy in from_element to to_element and returns the new element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_element_tree(parent_to_parse):\n\n    if isinstance(parent_to_parse, ElementTree):\n        return parent_to_parse\n\n    element = get_element(parent_to_parse)\n\n    return ElementTree() if element is None else ElementTree(element)", "response": "Get the element tree from the parent element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an element from the parent or parsed from a Dictionary XML string or file.", "response": "def get_element(parent_to_parse, element_path=None):\n    \"\"\"\n    :return: an element from the parent or parsed from a Dictionary, XML string\n    or file. If element_path is not provided the root element is returned.\n    \"\"\"\n\n    if parent_to_parse is None:\n        return None\n\n    elif isinstance(parent_to_parse, ElementTree):\n        parent_to_parse = parent_to_parse.getroot()\n\n    elif hasattr(parent_to_parse, 'read'):\n        parent_to_parse = string_to_element(parent_to_parse.read())\n\n    elif isinstance(parent_to_parse, STRING_TYPES):\n        parent_to_parse = string_to_element(parent_to_parse)\n\n    elif isinstance(parent_to_parse, dict):\n        parent_to_parse = dict_to_element(parent_to_parse)\n\n    if parent_to_parse is None:\n        return None\n    elif not isinstance(parent_to_parse, ElementType):\n        element_type = type(parent_to_parse).__name__\n        raise TypeError('Invalid element type: {0}'.format(element_type))\n\n    return parent_to_parse.find(element_path) if element_path else parent_to_parse"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_remote_element(url, element_path=None):\n\n    content = None\n\n    if url is None:\n        return content\n    elif _FILE_LOCATION_REGEX.match(url):\n        with open(url, 'rb') as xml:\n            content = xml.read()\n    else:\n        try:\n            urllib = getattr(six_moves, 'urllib')\n            remote = urllib.request.urlopen(url)\n            content = remote.read()\n        finally:\n            # For Python 2 compliance: fails in `with` block (no `__exit__`)\n            remote.close()\n\n    return get_element(strip_namespaces(content), element_path)", "response": "Get the element from the remote file or URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning true if the element is empty.", "response": "def element_is_empty(elem_to_parse, element_path=None):\n    \"\"\"\n    Returns true if the element is None, or has no text, tail, children or attributes.\n    Whitespace in the element is stripped from text and tail before making the determination.\n    \"\"\"\n\n    element = get_element(elem_to_parse, element_path)\n\n    if element is None:\n        return True\n\n    is_empty = (\n        (element.text is None or not element.text.strip()) and\n        (element.tail is None or not element.tail.strip()) and\n        (element.attrib is None or not len(element.attrib)) and\n        (not len(element.getchildren()))\n    )\n\n    return is_empty"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert_element(elem_to_parse, elem_idx, elem_path, elem_txt=u'', **attrib_kwargs):\n\n    element = get_element(elem_to_parse)\n\n    if element is None or not elem_path:\n        return None\n\n    if not elem_idx:\n        elem_idx = 0\n\n    if elem_path and XPATH_DELIM in elem_path:\n        tags = elem_path.split(XPATH_DELIM)\n\n        if element_exists(element, elem_path):\n\n            # Get the next to last element in the XPATH\n            parent = get_element(element, XPATH_DELIM.join(tags[:-1]))\n\n            # Insert the new element as sibling to the last one\n            return insert_element(parent, elem_idx, tags[-1], elem_txt, **attrib_kwargs)\n\n        else:\n            this_elem = element\n            last_idx = len(tags) - 1\n\n            # Iterate over tags from root to leaf\n            for idx, tag in enumerate(tags):\n                next_elem = get_element(this_elem, tag)\n\n                # Insert missing elements in the path or continue\n                if next_elem is None:\n\n                    # Apply text and index to last element only\n                    if idx == last_idx:\n                        next_elem = insert_element(this_elem, elem_idx, tag, elem_txt, **attrib_kwargs)\n                    else:\n                        next_elem = insert_element(this_elem, 0, tag, u'', **attrib_kwargs)\n\n                this_elem = next_elem\n\n            return this_elem\n\n    subelem = Element(elem_path, attrib_kwargs)\n    subelem.text = elem_txt\n\n    element.insert(elem_idx, subelem)\n\n    return subelem", "response": "Inserts an element into elem_to_parse at elem_idx."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_element(parent_to_parse, element_path, clear_empty=False):\n\n    element = get_element(parent_to_parse)\n    removed = []\n\n    if element is None or not element_path:\n        return None\n\n    if element_exists(element, element_path):\n        if XPATH_DELIM not in element_path:\n            for subelem in get_elements(element, element_path):\n                removed.append(subelem)\n                element.remove(subelem)\n        else:\n            xpath_segments = element_path.split(XPATH_DELIM)\n            parent_segment = XPATH_DELIM.join(xpath_segments[:-1])\n            last_segment = xpath_segments[-1]\n\n            for parent in get_elements(element, parent_segment):\n                rem = remove_element(parent, last_segment)\n                removed.extend(rem if isinstance(rem, list) else [rem])\n\n            if clear_empty:\n                removed.extend(remove_empty_element(element, parent_segment))\n\n    return removed[0] if len(removed) == 1 else (removed or None)", "response": "Removes the element with the given path from the specified parent element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_elements(parent_to_parse, element_paths, clear_empty=False):\n\n    element = get_element(parent_to_parse)\n    removed = []\n\n    if element is None or not element_paths:\n        return removed\n\n    if isinstance(element_paths, string_types):\n        rem = remove_element(element, element_paths, clear_empty)\n        removed.extend(rem if isinstance(rem, list) else [rem])\n    else:\n        for xpath in element_paths:\n            rem = remove_element(element, xpath, clear_empty)\n            removed.extend(rem if isinstance(rem, list) else [rem])\n\n    return removed", "response": "Removes all elements named after each elements_or_paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all empty elements in the element tree with the given element_name from the parent tree and returns a list of lists.", "response": "def remove_empty_element(parent_to_parse, element_path, target_element=None):\n    \"\"\"\n    Searches for all empty sub-elements named after element_name in the parsed element,\n    and if it exists, removes them all and returns them as a list.\n    \"\"\"\n\n    element = get_element(parent_to_parse)\n    removed = []\n\n    if element is None or not element_path:\n        return removed\n\n    if target_element:\n\n        # Always deal with just the element path\n        if not element_path.endswith(target_element):\n            element_path = XPATH_DELIM.join([element_path, target_element])\n        target_element = None\n\n    if XPATH_DELIM not in element_path:\n\n        # Loop over and remove empty sub-elements directly\n        for subelem in get_elements(element, element_path):\n            if element_is_empty(subelem):\n                removed.append(subelem)\n                element.remove(subelem)\n    else:\n        # Parse target element from last node in element path\n        xpath_segments = element_path.split(XPATH_DELIM)\n        element_path = XPATH_DELIM.join(xpath_segments[:-1])\n        target_element = xpath_segments[-1]\n\n        # Loop over children and remove empty ones directly\n        for parent in get_elements(element, element_path):\n            for child in get_elements(parent, target_element):\n                if element_is_empty(child):\n                    removed.append(child)\n                    parent.remove(child)\n\n            # Parent may be empty now: recursively remove empty elements in XPATH\n            if element_is_empty(parent):\n                if len(xpath_segments) == 2:\n                    removed.extend(remove_empty_element(element, xpath_segments[0]))\n                else:\n                    next_element_path = XPATH_DELIM.join(xpath_segments[:-2])\n                    next_target_element = parent.tag\n\n                    removed.extend(remove_empty_element(element, next_element_path, next_target_element))\n\n    return removed"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all elements by name from the parsed parent element.", "response": "def get_elements(parent_to_parse, element_path):\n    \"\"\"\n    :return: all elements by name from the parsed parent element.\n    :see: get_element(parent_to_parse, element_path)\n    \"\"\"\n\n    element = get_element(parent_to_parse)\n\n    if element is None or not element_path:\n        return []\n\n    return element.findall(element_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets an attribute from the element if it has the attribute", "response": "def get_element_attribute(elem_to_parse, attrib_name, default_value=u''):\n    \"\"\"\n    :return: an attribute from the parsed element if it has the attribute,\n    otherwise the default value\n    \"\"\"\n\n    element = get_element(elem_to_parse)\n\n    if element is None:\n        return default_value\n\n    return element.attrib.get(attrib_name, default_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the attributes of the element if it has any.", "response": "def get_element_attributes(parent_to_parse, element_path=None):\n    \"\"\"\n    :return: all the attributes for the parsed element if it has any, or an empty dict\n    \"\"\"\n\n    element = get_element(parent_to_parse, element_path)\n\n    return {} if element is None else element.attrib"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_element_attributes(elem_to_parse, **attrib_kwargs):\n\n    element = get_element(elem_to_parse)\n\n    if element is None:\n        return element\n\n    if len(attrib_kwargs):\n        element.attrib.update(attrib_kwargs)\n\n    return element.attrib", "response": "Adds the specified key value pairs to the element s attributes and returns the updated set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_element_attributes(elem_to_parse, *args):\n\n    element = get_element(elem_to_parse)\n\n    if element is None:\n        return element\n\n    if len(args):\n        attribs = element.attrib\n        return {key: attribs.pop(key) for key in args if key in attribs}\n\n    return {}", "response": "Removes the specified keys from the element s attributes and returns a dict containing the attributes that have been removed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the tail of the parent element if it exists.", "response": "def get_element_tail(parent_to_parse, element_path=None, default_value=u''):\n    \"\"\"\n    :return: text following the parsed parent element if it exists,\n    otherwise the default value.\n    :see: get_element(parent_to_parse, element_path)\n    \"\"\"\n\n    parent_element = get_element(parent_to_parse, element_path)\n\n    if parent_element is None:\n        return default_value\n\n    if parent_element.tail:\n        return parent_element.tail.strip() or default_value\n\n    return default_value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the text value of the parent element if it has a text value.", "response": "def get_element_text(parent_to_parse, element_path=None, default_value=u''):\n    \"\"\"\n    :return: text from the parsed parent element if it has a text value,\n    otherwise the default value.\n    :see: get_element(parent_to_parse, element_path)\n    \"\"\"\n\n    parent_element = get_element(parent_to_parse, element_path)\n\n    if parent_element is None:\n        return default_value\n\n    if parent_element.text:\n        return parent_element.text.strip() or default_value\n\n    return default_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_elements_attributes(parent_to_parse, element_path=None, attrib_name=None):\n\n    attrs = _get_elements_property(parent_to_parse, element_path, 'attrib')\n\n    if not attrib_name:\n        return attrs\n\n    return [attr[attrib_name] for attr in attrs if attrib_name in attr]", "response": "Get the attributes of the elements at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassigns the text following the parsed parent element and then returns it.", "response": "def set_element_tail(parent_to_parse, element_path=None, element_tail=u''):\n    \"\"\"\n    Assigns the text following the parsed parent element and then returns it.\n    If element_path is provided and doesn't exist, it is inserted with element_tail.\n    :see: get_element(parent_to_parse, element_path)\n    \"\"\"\n\n    return _set_element_property(parent_to_parse, element_path, _ELEM_TAIL, element_tail)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_element_text(parent_to_parse, element_path=None, element_text=u''):\n\n    return _set_element_property(parent_to_parse, element_path, _ELEM_TEXT, element_text)", "response": "Assigns a string value to the parsed parent element and then returns it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_element_property(parent_to_parse, element_path, prop_name, value):\n\n    element = get_element(parent_to_parse)\n\n    if element is None:\n        return None\n\n    if element_path and not element_exists(element, element_path):\n        element = insert_element(element, 0, element_path)\n\n    if not isinstance(value, string_types):\n        value = u''\n\n    setattr(element, prop_name, value)\n\n    return element", "response": "Assign the value to the parsed parent element and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_elements_tail(parent_to_parse, element_path=None, tail_values=None):\n\n    if tail_values is None:\n        tail_values = []\n\n    return _set_elements_property(parent_to_parse, element_path, _ELEM_TAIL, tail_values)", "response": "Assigns tail values to each of the elements parsed from the parent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassign an array of text values to each of the elements parsed from the parent.", "response": "def set_elements_text(parent_to_parse, element_path=None, text_values=None):\n    \"\"\"\n    Assigns an array of text values to each of the elements parsed from the parent. The\n    text values are assigned in the same order they are provided.\n    If there are less values then elements, the remaining elements are skipped; but if\n    there are more, new elements will be inserted for each with the remaining text values.\n    \"\"\"\n\n    if text_values is None:\n        text_values = []\n\n    return _set_elements_property(parent_to_parse, element_path, _ELEM_TEXT, text_values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_elements_property(parent_to_parse, element_path, prop_name, values):\n\n    element = get_element(parent_to_parse)\n\n    if element is None or not values:\n        return []\n\n    if isinstance(values, string_types):\n        values = [values]\n\n    if not element_path:\n        return [_set_element_property(element, None, prop_name, values[0])]\n\n    elements = get_elements(element, element_path)\n    affected = []\n\n    for idx, val in enumerate(values):\n        if idx < len(elements):\n            next_elem = elements[idx]\n        else:\n            next_elem = insert_element(element, idx, element_path)\n\n        affected.append(\n            _set_element_property(next_elem, None, prop_name, val)\n        )\n\n    return affected", "response": "Assigns an array of string values to each of the elements parsed from the parent element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_to_element(element_as_dict):\n\n    if element_as_dict is None:\n        return None\n    elif isinstance(element_as_dict, ElementTree):\n        return element_as_dict.getroot()\n    elif isinstance(element_as_dict, ElementType):\n        return element_as_dict\n    elif not isinstance(element_as_dict, dict):\n        raise TypeError('Invalid element dict: {0}'.format(element_as_dict))\n\n    if len(element_as_dict) == 0:\n        return None\n\n    try:\n        converted = Element(\n            element_as_dict[_ELEM_NAME],\n            element_as_dict.get(_ELEM_ATTRIBS, {})\n        )\n\n        converted.tail = element_as_dict.get(_ELEM_TAIL, u'')\n        converted.text = element_as_dict.get(_ELEM_TEXT, u'')\n\n        for child in element_as_dict.get(_ELEM_CHILDREN, []):\n            converted.append(dict_to_element(child))\n\n    except KeyError:\n        raise SyntaxError('Invalid element dict: {0}'.format(element_as_dict))\n\n    return converted", "response": "Converts a dictionary object to an element."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element_to_dict(elem_to_parse, element_path=None, recurse=True):\n\n    element = get_element(elem_to_parse, element_path)\n\n    if element is not None:\n        converted = {\n            _ELEM_NAME: element.tag,\n            _ELEM_TEXT: element.text,\n            _ELEM_TAIL: element.tail,\n            _ELEM_ATTRIBS: element.attrib,\n            _ELEM_CHILDREN: []\n        }\n\n        if recurse is True:\n            for child in element:\n                converted[_ELEM_CHILDREN].append(element_to_dict(child, recurse=recurse))\n\n        return converted\n\n    return {}", "response": "Converts an element losslessly to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an XML element to a dict with all the XML data but without preserving structure.", "response": "def element_to_object(elem_to_parse, element_path=None):\n    \"\"\"\n    :return: the root key, and a dict with all the XML data, but without preserving structure, for instance:\n\n    <elem val=\"attribute\"><val>nested text</val><val prop=\"attr\">nested dict text</val>nested dict tail</elem>\n    {'elem': {\n        'val': [\n            u'nested text',\n            {'prop': u'attr', 'value': [u'nested dict text', u'nested dict tail']},\n            u'attribute'\n        ]\n    }}\n    \"\"\"\n\n    if isinstance(elem_to_parse, STRING_TYPES) or hasattr(elem_to_parse, 'read'):\n        # Always strip namespaces if not already parsed\n        elem_to_parse = strip_namespaces(elem_to_parse)\n\n    if element_path is not None:\n        elem_to_parse = get_element(elem_to_parse, element_path)\n\n    element_tree = get_element_tree(elem_to_parse)\n    element_root = element_tree.getroot()\n    root_tag = u'' if element_root is None else element_root.tag\n\n    return root_tag, {root_tag: _element_to_object(element_root)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an XML element to a string.", "response": "def element_to_string(element, include_declaration=True, encoding=DEFAULT_ENCODING, method='xml'):\n    \"\"\" :return: the string value of the element or element tree \"\"\"\n\n    if isinstance(element, ElementTree):\n        element = element.getroot()\n    elif not isinstance(element, ElementType):\n        element = get_element(element)\n\n    if element is None:\n        return u''\n\n    element_as_string = tostring(element, encoding, method).decode(encoding=encoding)\n    if include_declaration:\n        return element_as_string\n    else:\n        return strip_xml_declaration(element_as_string)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string value to an element.", "response": "def string_to_element(element_as_string, include_namespaces=False):\n    \"\"\" :return: an element parsed from a string value, or the element as is if already parsed \"\"\"\n\n    if element_as_string is None:\n        return None\n    elif isinstance(element_as_string, ElementTree):\n        return element_as_string.getroot()\n    elif isinstance(element_as_string, ElementType):\n        return element_as_string\n    else:\n        element_as_string = _xml_content_to_string(element_as_string)\n\n    if not isinstance(element_as_string, string_types):\n        # Let cElementTree handle the error\n        return fromstring(element_as_string)\n    elif not strip_xml_declaration(element_as_string):\n        # Same as ElementTree().getroot()\n        return None\n    elif include_namespaces:\n        return fromstring(element_as_string)\n    else:\n        return fromstring(strip_namespaces(element_as_string))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over the elements of the parent_to_parse and apply element_function to each of the sub - elements in parent_to_parse.", "response": "def iter_elements(element_function, parent_to_parse, **kwargs):\n    \"\"\"\n    Applies element_function to each of the sub-elements in parent_to_parse.\n    The passed in function must take at least one element, and an optional\n    list of kwargs which are relevant to each of the elements in the list:\n        def elem_func(each_elem, **kwargs)\n    \"\"\"\n\n    parent = get_element(parent_to_parse)\n\n    if not hasattr(element_function, '__call__'):\n        return parent\n\n    for child in ([] if parent is None else parent):\n        element_function(child, **kwargs)\n\n    return parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the elements in the XML file and apply element_function to each of the sub - elements in the XML file.", "response": "def iterparse_elements(element_function, file_or_path, **kwargs):\n    \"\"\"\n    Applies element_function to each of the sub-elements in the XML file.\n    The passed in function must take at least one element, and an optional\n    list of **kwarg which are relevant to each of the elements in the list:\n        def elem_func(each_elem, **kwargs)\n\n    Implements the recommended cElementTree iterparse pattern, which is\n    efficient for reading in a file, making changes and writing it again.\n    \"\"\"\n\n    if not hasattr(element_function, '__call__'):\n        return\n\n    file_path = getattr(file_or_path, 'name', file_or_path)\n    context = iter(iterparse(file_path, events=('start', 'end')))\n    root = None  # Capture root for Memory management\n\n    # Start event loads child; by the End event it's ready for processing\n\n    for event, child in context:\n        if root is None:\n            root = child\n        if event == 'end':  # Ensures the element has been fully read\n            element_function(child, **kwargs)\n            root.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove all namespaces from the XML file or string passed in.", "response": "def strip_namespaces(file_or_xml):\n    \"\"\"\n    Removes all namespaces from the XML file or string passed in.\n    If file_or_xml is not a file or string, it is returned as is.\n    \"\"\"\n\n    xml_content = _xml_content_to_string(file_or_xml)\n    if not isinstance(xml_content, string_types):\n        return xml_content\n\n    # This pattern can have overlapping matches, necessitating the loop\n    while _NAMESPACES_FROM_DEC_REGEX.search(xml_content) is not None:\n        xml_content = _NAMESPACES_FROM_DEC_REGEX.sub(r'\\1', xml_content)\n\n    # Remove namespaces at the tag level\n    xml_content = _NAMESPACES_FROM_TAG_REGEX.sub(r'\\1', xml_content)\n\n    # Remove namespaces at the attribute level\n    xml_content = _NAMESPACES_FROM_ATTR_REGEX.sub(r'\\1\\3', xml_content)\n\n    return xml_content"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef strip_xml_declaration(file_or_xml):\n\n    xml_content = _xml_content_to_string(file_or_xml)\n    if not isinstance(xml_content, string_types):\n        return xml_content\n\n    # For Python 2 compliance: replacement string must not specify unicode u''\n    return _XML_DECLARATION_REGEX.sub(r'', xml_content, 1)", "response": "Removes XML declaration line from file or string passed in."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_element(elem_to_parse, file_or_path, encoding=DEFAULT_ENCODING):\n\n    xml_header = '<?xml version=\"1.0\" encoding=\"{0}\"?>'.format(encoding)\n\n    get_element_tree(elem_to_parse).write(file_or_path, encoding, xml_header)", "response": "Writes the contents of the element to file_or_path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef floating_point_to_datetime(day, fp_time):\n    result = datetime(year=day.year, month=day.month, day=day.day)\n    result += timedelta(minutes=math.ceil(60 * fp_time))\n    return result", "response": "Convert a floating point time to a datetime."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate adhan times given the parameters. This function will compute the adhan times for a certain location on certain day. The method for calculating the prayers as well as the time for Asr can also be specified. The timezone offset naively adds the specified number of hours to each time that is returned. :param day: The datetime.date to calculate for :param location: 2-tuple of floating point coordiantes for latitude and longitude of location in degrees :param parameters: A dictionary-like object of parameters for computing adhan times. Commonly used calculation methods are available in the adhan.methods module :param timezone_offset: The number of hours to add to each prayer time to account for timezones. Can be floating point", "response": "def adhan(day, location, parameters, timezone_offset=0):\n    \"\"\"Calculate adhan times given the parameters.\n\n    This function will compute the adhan times for a certain location on\n    certain day. The method for calculating the prayers as well as the time for\n    Asr can also be specified. The timezone offset naively adds the specified\n    number of hours to each time that is returned.\n\n    :param day: The datetime.date to calculate for\n    :param location: 2-tuple of floating point coordiantes for latitude and\n                     longitude of location in degrees\n    :param parameters: A dictionary-like object of parameters for computing\n                       adhan times. Commonly used calculation methods are\n                       available in the adhan.methods module\n    :param timezone_offset: The number of hours to add to each prayer time\n                            to account for timezones. Can be floating point\n\n    \"\"\"\n    latitude, longitude = location\n\n    #\n    # To reduce a little repetitiveness, using a partial function that has the\n    # day and latitude already set\n    #\n    time_at_sun_angle = partial(\n        compute_time_at_sun_angle,\n        day=day,\n        latitude=latitude\n    )\n\n    zuhr_time = compute_zuhr_utc(day, longitude)\n\n    shuruq_time = zuhr_time - time_at_sun_angle(angle=SUNRISE_ANGLE)\n    maghrib_time = zuhr_time + time_at_sun_angle(angle=SUNSET_ANGLE)\n\n    fajr_time = zuhr_time - time_at_sun_angle(angle=parameters['fajr_angle'])\n\n    #\n    # Most methods define Isha as a certain angle the sun has to be below\n    # the horizon, but some methods define it as a certain number of minutes\n    # after Maghrib\n    #\n    if parameters.get('isha_delay', None):\n        isha_time = maghrib_time + parameters['isha_delay']\n    else:\n        isha_time = (\n            zuhr_time +\n            time_at_sun_angle(angle=parameters['isha_angle'])\n        )\n\n    #\n    # Default to standard Asr method if not specified\n    #\n    asr_multiplier = parameters.get('asr_multiplier', ASR_STANDARD)\n    asr_time = zuhr_time + time_at_shadow_length(\n        day=day, latitude=latitude, multiplier=asr_multiplier\n    )\n\n    offset = timedelta(minutes=60 * timezone_offset)\n    return {\n        'fajr': floating_point_to_datetime(day, fajr_time) + offset,\n        'zuhr': floating_point_to_datetime(day, zuhr_time) + offset,\n        'shuruq': floating_point_to_datetime(day, shuruq_time) + offset,\n        'asr': floating_point_to_datetime(day, asr_time) + offset,\n        'maghrib': floating_point_to_datetime(day, maghrib_time) + offset,\n        'isha': floating_point_to_datetime(day, isha_time) + offset,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_BLB():\r\n    rc(\"figure\", facecolor=\"white\")\r\n    rc('font', family = 'serif', size=10) #, serif = 'cmr10')\r\n    rc('xtick', labelsize=10)\r\n    rc('ytick', labelsize=10)\r\n    rc('axes', linewidth=1)\r\n    rc('xtick.major', size=4, width=1)\r\n    rc('xtick.minor', size=2, width=1)\r\n    rc('ytick.major', size=4, width=1)\r\n    rc('ytick.minor', size=2, width=1)", "response": "Sets some formatting options in Matplotlib."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_figure_size(fig, width, height):\r\n    dpi = float(fig.get_dpi())\r\n    fig.set_size_inches(float(width) / dpi, float(height) / dpi)", "response": "Sets MatPlotLib figure width and height in pixels"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new ZipCodesGeoZone with the specified attributes.", "response": "def create_zip_codes_geo_zone(cls, zip_codes_geo_zone, **kwargs):\n        \"\"\"Create ZipCodesGeoZone\n\n        Create a new ZipCodesGeoZone\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_zip_codes_geo_zone(zip_codes_geo_zone, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param ZipCodesGeoZone zip_codes_geo_zone: Attributes of zipCodesGeoZone to create (required)\n        :return: ZipCodesGeoZone\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_zip_codes_geo_zone_with_http_info(zip_codes_geo_zone, **kwargs)\n        else:\n            (data) = cls._create_zip_codes_geo_zone_with_http_info(zip_codes_geo_zone, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete an instance of ZipCodesGeoZone by its ID.", "response": "def delete_zip_codes_geo_zone_by_id(cls, zip_codes_geo_zone_id, **kwargs):\n        \"\"\"Delete ZipCodesGeoZone\n\n        Delete an instance of ZipCodesGeoZone by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_zip_codes_geo_zone_by_id(zip_codes_geo_zone_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str zip_codes_geo_zone_id: ID of zipCodesGeoZone to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, **kwargs)\n        else:\n            (data) = cls._delete_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_zip_codes_geo_zone_by_id(cls, zip_codes_geo_zone_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, **kwargs)\n        else:\n            (data) = cls._get_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, **kwargs)\n            return data", "response": "Find ZipCodesGeoZone by ID Return single instance of ZipCodesGeoZone by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting ZipCodesGeoZones Return a list of ZipCodesGeoZones", "response": "def list_all_zip_codes_geo_zones(cls, **kwargs):\n        \"\"\"List ZipCodesGeoZones\n\n        Return a list of ZipCodesGeoZones\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_zip_codes_geo_zones(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[ZipCodesGeoZone]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_zip_codes_geo_zones_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_zip_codes_geo_zones_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace all attributes of ZipCodesGeoZone by ID", "response": "def replace_zip_codes_geo_zone_by_id(cls, zip_codes_geo_zone_id, zip_codes_geo_zone, **kwargs):\n        \"\"\"Replace ZipCodesGeoZone\n\n        Replace all attributes of ZipCodesGeoZone\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_zip_codes_geo_zone_by_id(zip_codes_geo_zone_id, zip_codes_geo_zone, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str zip_codes_geo_zone_id: ID of zipCodesGeoZone to replace (required)\n        :param ZipCodesGeoZone zip_codes_geo_zone: Attributes of zipCodesGeoZone to replace (required)\n        :return: ZipCodesGeoZone\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, zip_codes_geo_zone, **kwargs)\n        else:\n            (data) = cls._replace_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, zip_codes_geo_zone, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_zip_codes_geo_zone_by_id(cls, zip_codes_geo_zone_id, zip_codes_geo_zone, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, zip_codes_geo_zone, **kwargs)\n        else:\n            (data) = cls._update_zip_codes_geo_zone_by_id_with_http_info(zip_codes_geo_zone_id, zip_codes_geo_zone, **kwargs)\n            return data", "response": "Update attributes of ZipCodesGeoZone by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind all fields and return them as a dictionary.", "response": "def get_declared_fields(bases, attrs):\n    \"\"\" Find all fields and return them as a dictionary.\n\n    note:: this function is copied and modified\n        from django.forms.get_declared_fields\n    \"\"\"\n\n    def is_field(prop):\n        return isinstance(prop, forms.Field) or \\\n            isinstance(prop, BaseRepresentation)\n\n    fields = [(field_name, attrs.pop(field_name)) for field_name, obj in attrs.items() if is_field(obj)]\n    # add fields from base classes:\n    for base in bases[::-1]:\n        if hasattr(base, 'base_fields'):\n            fields = base.base_fields.items() + fields\n    return dict(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the data for the record set.", "response": "def validate(self, data=None):\n        \"\"\" Validate the data\n\n        Check also that no extra properties are present.\n\n        :raises: ValidationError if the data is not valid.\n        \"\"\"\n\n        errors = {}\n\n        data = self._getData(data)\n\n        # validate each field, one by one\n        for name, field in self.fields.items():\n            try:\n                field.clean(data.get(name))\n            except ValidationError, e:\n                errors[name] = e.messages\n            except AttributeError, e:\n                raise ValidationError('data should be of type dict but is %s' % (type(data),))\n\n        # check for extra fields\n        extras = set(data.keys()) - set(self.fields.keys())\n        if extras:\n            errors[', '.join(extras)] = ['field(s) not allowed']\n\n        # if errors, raise ValidationError\n        if errors:\n            raise ValidationError(errors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the data is acceptable and return it.", "response": "def _getData(self, data):\n        \"\"\" Check that data is acceptable and return it.\n\n        Default behavior is that the data has to be of type `dict`. In derived\n        classes this method could for example allow `None` or empty strings and\n        just return empty dictionary.\n\n        :raises: ``ValidationError`` if data is missing or wrong type\n        :return: the data to be validated\n        \"\"\"\n\n        if not isinstance(data, dict):\n            raise ValidationError(\n                'data is not a valid dictionary: %s' % (str(type(data)),))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lambda_handler(event, context):\n    users = boto3.resource(\"dynamodb\").Table(os.environ['people'])\n    auth = check_auth(event, role=[\"admin\"])\n    if not auth['success']:\n        return auth\n    user_email = event.get('user_email', None)\n    if not user_email:\n        msg = \"Missing user_email parameter in your request.\"\n        return {'success': False, 'message': msg}\n    user_role = event.get('user_role', None)\n    if not user_role:\n        msg = \"Missing user role: `admin`, `analyst`\"\n        return {'success': False, 'message': msg}\n    user_name = event.get('user_name', '')\n    seed = random.randint(100000000, 999999999)\n    hash_key = \"{}{}\".format(user_email, seed)\n    api_key = hashlib.sha256(hash_key).hexdigest()\n    if auth.get('init', False):\n        user_role = 'admin'\n    else:\n        user_role = user_role\n    obj = {'email': user_email, 'name': user_name, 'api_key': api_key,\n           'role': user_role}\n    response = users.put_item(Item=obj)\n    return obj", "response": "Main handler for the get_user_list_item function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a redis connection to the current instance.", "response": "def get_connection(self, internal=False):\n        \"\"\"Get a live connection to this instance.\n\n        :param bool internal: Whether or not to use a DC internal network connection.\n\n        :rtype: :py:class:`redis.client.StrictRedis`\n        \"\"\"\n        # Determine the connection string to use.\n        connect_string = self.connect_string\n        if internal:\n            connect_string = self.internal_connect_string\n\n        # Stripe Redis protocol prefix coming from the API.\n        connect_string = connect_string.strip('redis://')\n        host, port = connect_string.split(':')\n\n        # Build and return the redis client.\n        return redis.StrictRedis(host=host, port=port, password=self._password)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_cached(self, path, cache_name, **kwargs):\n        if gw2api.cache_dir and gw2api.cache_time and cache_name:\n            cache_file = os.path.join(gw2api.cache_dir, cache_name)\n            if mtime(cache_file) >= time.time() - gw2api.cache_time:\n                with open(cache_file, \"r\") as fp:\n                    tmp = json.load(fp)\n                return self.make_response(tmp[\"data\"], tmp[\"meta\"])\n        else:\n            cache_file = None\n\n        meta, data = self._get(path, **kwargs)\n\n        if cache_file:\n            with open(cache_file, \"w\") as fp:\n                json.dump({\"meta\": meta, \"data\": data}, fp, indent=2)\n\n        return self.make_response(data, meta)", "response": "Request a resource form the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    for text in [\n        \"how are you\",\n        \"ip address\",\n        \"restart\",\n        \"run command\",\n        \"rain EGPF\",\n        \"reverse SSH\"\n        ]:\n        print(\"\\nparse text: \" + text + \"\\nWait 3 seconds, then parse.\")\n        time.sleep(3)\n        response = megaparsex.multiparse(\n            text         = text,\n            parsers      = [\n                           megaparsex.parse,\n                           parse_networking\n                           ],\n            help_message = \"Does not compute. I can report my IP address and I \"\n                           \"can restart my script.\"\n        )\n        if type(response) is megaparsex.confirmation:\n            while response.confirmed() is None:\n                response.test(\n                    text = megaparsex.get_input(\n                        prompt = response.prompt() + \" \"\n                    )\n                )\n            if response.confirmed():\n                print(response.feedback())\n                response.run()\n            else:\n                print(response.feedback())\n        elif type(response) is megaparsex.command:\n            output = response.engage_command(\n                command    = megaparsex.get_input(\n                    prompt = response.prompt() + \" \"\n                ),\n                background = False\n            )\n            if output:\n                print(\"output:\\n{output}\".format(output = output))\n        else:\n            print(response)", "response": "Main function for the main function of the main function of the main function of the main function of the main function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the ID of a protocol buffer packet. Returns None if no ID was found.", "response": "def get_packet_id(self, packet):\n        \"\"\"\n        Returns the ID of a protocol buffer packet. Returns None\n        if no ID was found.\n        \"\"\"\n\n        for p in self._packets:\n            if isinstance(packet, p['cls']):\n                return p['id']\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints information about the DataFrame df to a file or to the prompt.", "response": "def summarize(df,preview_rows = 8,\n            display_max_cols = None,display_width = None,\n            output_path = None, output_safe = True,to_folder = False): \n    \"\"\" Prints information about the DataFrame to a file or to the prompt.\n\n    Parameters\n    ----------\n    df - DataFrame\n        The DataFrame to summarize\n    preview_rows - int, default 5\n        Amount of rows to preview from the head and tail of the DataFrame\n    display_max_cols - int, default None\n        Maximum amount of columns to display. If set to None, all columns will be displayed.\n        If set to 0, only as many as fit in the screen's width will be displayed\n    display_width - int, default None\n        Width of output. Can be width of file or width of console for printing.\n        Set to None for pandas to detect it from console.\n    output_path - path-like, default None\n        If not None, this will be used as the path of the output file, and this\n        function will print to a file instead of to the prompt\n    output_safe - boolean, default True\n        If True and output_file is not None, this function will not overwrite any\n        existing files.\n    output_csv: boolean, default False\n        If True, will output to a directory with name of output_path with all data in \n        csv format. WARNING: If set to true, this function will overwrite existing files\n        in the directory with the following names: \n            ['Preview.csv','Describe.csv','Info.csv','Percentile Details.csv',\n             'Missing Values Summary.csv','Potential Outliers.csv','Correlation Matrix.csv']\n    \"\"\"\n    assert type(df) is pd.DataFrame\n    \n    # Reformat displays\n    initial_settings = pd_settings(display_max_cols, None, display_width)\n\n    # --------Values of data-----------\n    df_preview = _io.preview(df,preview_rows)\n    df_desc_num, df_desc_cat = detailed_desc(df)\n    percent_values = stats.percentiles(df)\n    potential_outliers = stats.df_outliers(df).dropna(axis = 1,how = 'all')\n    potential_outliers = potential_outliers if _utils.rows(potential_outliers) else None\n    corr_values = regstats.corr_matrix(df)\n\n    # ----------Build lists------------\n    \n    title_list = \\\n    ['Preview','Describe (Numerical)','Describe (Categorical)','Percentile Details',\n     'Potential Outliers','Correlation Matrix']\n    info_list = \\\n    [df_preview,df_desc_num, df_desc_cat,percent_values,\n     potential_outliers,corr_values]\n    error_list = [None,'No numerical data.','All numerical data.','No numerical data.',\n                  'No potential outliers.','No categorical, bool, or numerical data.']\n    \n    # ----------Build output------------\n    \n    output = ''\n    for title, value,error_text in zip(title_list,info_list,error_list):\n        if value is None:\n            value = \"{} skipped: {}\".format(title,error_text)\n        if str(value).endswith('\\n'):\n            value = value[:-1]\n        output+='{}\\n{}\\n\\n'.format(_io.title_line(title),value)\n\n    # ----------Send to file/print to console------------\n    if output_path is None: \n        # Potentially could change this to allow for output_safe to work with directories\n         print(output)\n    else:\n        if not to_folder:\n            print('Outputting to file...')\n            _io.output_to_file(output,output_path,output_safe)\n        else:\n            print('Outputting to folder...')\n            if not os.path.exists(output_path):\n                os.mkdir(output_path)\n            for title, value,error_text in zip(title_list,info_list,error_list):\n                if value is None:\n                    print(\"{} skipped: {}\".format(title,error_text))\n                else:\n                    file_dir = os.path.join(output_path,\"{}.csv\".format(title))\n                    if type(value) is pd.DataFrame:\n                        # Eventually add a check to see if file exists\n                        value.to_csv(file_dir)\n                    else:\n                        _io.output_to_file(value,file_dir,False) \n                        # Change to output_safe when directory output_safe is implemented\n        print('Done!')\n\n    # Reset display settings\n    pd_settings(*initial_settings)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef destruct(particles, index):\n\n    mat = np.zeros((2**particles, 2**particles))\n\n    flipper = 2**index\n    for i in range(2**particles):\n        ispin = btest(i, index)\n        if ispin == 1:\n            mat[i ^ flipper, i] = phase(i, index)\n    return csr_matrix(mat)", "response": "Fermion annihilation operator in matrix representation for a indexed\n       particle in a bounded N - particle fermion fock space"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens audio output. set pin mode to ALT0 Open Audio output. set pin mode to AUDIO", "response": "def on(self):\n        \"\"\"!\n        \\~english\n        Open Audio output. set pin mode to ALT0\n        @return a boolean value. if True means open audio output is OK otherwise failed to open.\n\n        \\~chinese\n        \u6253\u5f00\u97f3\u9891\u8f93\u51fa\u3002 \u5c06\u5f15\u811a\u6a21\u5f0f\u8bbe\u7f6e\u4e3aALT0\n        @return \u5e03\u5c14\u503c\u3002 \u5982\u679c True \u8868\u793a\u6253\u5f00\u97f3\u9891\u8f93\u51fa\u6210\u529f\uff0c\u5426\u5219\u4e0d\u6210\u529f\u3002\n        \"\"\"\n        isOK = True\n        try:\n            if self.channelR!=None:\n                sub.call([\"gpio\", \"-g\", \"mode\", \"{}\".format(self.channelR), self.PIN_MODE_AUDIO ])\n        except:\n            isOK = False\n            print(\"Open audio right channel failed.\")\n\n        try:\n            if self.channelL!=None:\n                sub.call([\"gpio\",\"-g\",\"mode\", \"{}\".format(self.channelL), self.PIN_MODE_AUDIO ])\n        except:\n            isOK = False\n            print(\"Open audio left channel failed.\")\n\n        return isOK"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose audio output. set pin mode to output", "response": "def off(self):\n        \"\"\"!\n        \\~english\n        Close Audio output. set pin mode to output\n        @return a boolean value. if True means close audio output is OK otherwise failed to close.\n\n        \\~chinese\n        \u5173\u95ed\u97f3\u9891\u8f93\u51fa\u3002 \u5c06\u5f15\u811a\u6a21\u5f0f\u8bbe\u7f6e\u4e3a\u8f93\u51fa\n        @return \u5e03\u5c14\u503c\u3002 \u5982\u679c\u4e3a True \u5173\u95ed\u97f3\u9891\u8f93\u51fa\u6210\u529f\uff0c\u5426\u5219\u5173\u95ed\u4e0d\u6210\u529f\u3002\n        \"\"\"\n        isOK = True\n        try:\n            if self.channelR!=None:\n                sub.call([\"gpio\",\"-g\",\"mode\", \"{}\".format(self.channelR), self.PIN_MODE_OUTPUT ])\n        except:\n            isOK = False\n            print(\"Close audio right channel failed.\")\n\n        try:\n            if self.channelL!=None:\n                sub.call([\"gpio\",\"-g\",\"mode\", \"{}\".format(self.channelL), self.PIN_MODE_OUTPUT ])\n        except:\n            isOK = False\n            print(\"Close audio left channel failed.\")\n        return isOK"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_database_url(url):\n\n    if url == 'sqlite://:memory:':\n        # this is a special case, because if we pass this URL into\n        # urlparse, urlparse will choke trying to interpret \"memory\"\n        # as a port number\n        return {\n            'ENGINE': DATABASE_SCHEMES['sqlite'],\n            'NAME': ':memory:'\n        }\n        # note: no other settings are required for sqlite\n\n    # otherwise parse the url as normal\n    config = {}\n\n    url = urlparse.urlparse(url)\n\n    # Remove query strings.\n    path = url.path[1:]\n    path = path.split('?', 2)[0]\n\n    # if we are using sqlite and we have no path, then assume we\n    # want an in-memory database (this is the behaviour of sqlalchemy)\n    if url.scheme == 'sqlite' and path == '':\n        path = ':memory:'\n\n    # Update with environment configuration.\n    config.update({\n        'NAME': path or '',\n        'USER': url.username or '',\n        'PASSWORD': url.password or '',\n        'HOST': url.hostname or '',\n        'PORT': url.port or '',\n    })\n\n    if url.scheme in DATABASE_SCHEMES:\n        config['ENGINE'] = DATABASE_SCHEMES[url.scheme]\n\n    return config", "response": "Parses a database URL into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns configured DATABASE dictionary from DATABASE_URL.", "response": "def config(name='DATABASE_URL', default='sqlite://:memory:'):\n    \"\"\"Returns configured DATABASE dictionary from DATABASE_URL.\"\"\"\n    config = {}\n    s = env(name, default)\n    if s:\n        config = parse_database_url(s)\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef json_unicode_to_utf8(data):\n    if isinstance(data, unicode):\n        return data.encode('utf-8')\n    elif isinstance(data, dict):\n        newdict = {}\n        for key in data:\n            newdict[json_unicode_to_utf8(\n                key)] = json_unicode_to_utf8(data[key])\n        return newdict\n    elif isinstance(data, list):\n        return [json_unicode_to_utf8(elem) for elem in data]\n    else:\n        return data", "response": "Change all strings in a JSON structure to UTF - 8."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a textfile using json to build a python object representation", "response": "def json_decode_file(filename):\n    \"\"\"\n    Parses a textfile using json to build a python object representation\n    \"\"\"\n    seq = open(filename).read()\n    # The JSON standard has no comments syntax. We have to remove them\n    # before feeding python's JSON parser\n    seq = json_remove_comments(seq)\n    # Parse all the unicode stuff to utf-8\n    return json_unicode_to_utf8(json.loads(seq))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wash_for_js(text):\n    from invenio_utils.html import escape_javascript_string\n    if isinstance(text, six.string_types):\n        return '\"%s\"' % escape_javascript_string(\n            text,\n            escape_for_html=False,\n            escape_CDATA=False,\n            escape_script_tag_with_quote=None)\n    else:\n        return text", "response": "Wash text for JavaScript."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _post_init(self):\n        try:\n            return self.postinit()\n        except Exception as exc:\n            return self._onerror(Result.from_exception(exc, uuid=self.uuid))", "response": "A post init trigger"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if all required parameters are set", "response": "def check_required_params(self):\n        \"\"\" Check if all required parameters are set\"\"\"\n        for param in self.REQUIRED_FIELDS:\n            if param not in self.params:\n                raise ValidationError(\"Missing parameter: {}\".format(param))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _onsuccess(self, result):\n        if KSER_METRICS_ENABLED == \"yes\":\n            KSER_TASKS_STATUS.labels(\n                __hostname__, self.__class__.path, 'SUCCESS'\n            ).inc()\n        if result:\n            result = self.result + result\n        else:\n            result = self.result\n        logger.info(\n            \"{}.Success: {}[{}]: {}\".format(\n                self.__class__.__name__, self.__class__.path, self.uuid, result\n            ),\n            extra=dict(\n                kmsg=Message(\n                    self.uuid, entrypoint=self.__class__.path,\n                    params=self.params, metadata=self.metadata\n                ).dump(),\n                kresult=ResultSchema().dump(result) if result else dict()\n            )\n        )\n        return self.onsuccess(result)", "response": "To execute on execution success\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unsafe_execute(self, result=None):\n        if result:\n            self.result += result\n\n        self._prerun()\n        return self._onsuccess(self._postrun(self._run()))", "response": "un - wrapped execution can raise excepetion\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap to make sure that the execution return a result", "response": "def execute(self, result=None):\n        \"\"\" Execution 'wrapper' to make sure that it return a result\n\n        :return: Execution result\n        :rtype: kser.result.Result\n        \"\"\"\n        try:\n            return self.unsafe_execute(result=result)\n        except Exception as exc:\n            return self._onerror(Result.from_exception(exc, uuid=self.uuid))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts this entrypoint to a Kafka message.", "response": "def to_Message(self, result=None):\n        \"\"\" Entrypoint -> Message\n\n        :param kser.result.Result result: Execution result\n        :return: Kafka message\n        :rtype kser.schemas.Message\n        \"\"\"\n        return Message(\n            uuid=self.uuid, entrypoint=self.__class__.path, params=self.params,\n            result=result if result else self.result, metadata=self.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_Message(cls, kmsg):\n        return cls(\n            uuid=kmsg.uuid, params=kmsg.params, result=kmsg.result,\n            metadata=kmsg.metadata\n        )", "response": "Creates an Entrypoint object from a Kafka message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_as(self, filename=None):\n        if filename is None:\n            filename = self.filename\n        if filename is None:\n            filename = self.default_filename\n        if filename is None:\n            raise RuntimeError(\"Class '{}' has no default filename\".format(self.__class__.__name__))\n        self._do_save_as(filename)\n        self.filename = filename", "response": "Dumps the contents of the object into a file on disk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload file and registers filename as attribute.", "response": "def load(self, filename=None):\n        \"\"\"Loads file and registers filename as attribute.\"\"\"\n        assert not self.__flag_loaded, \"File can be loaded only once\"\n        if filename is None:\n            filename = self.default_filename\n        assert filename is not None, \\\n            \"{0!s} class has no default filename\".format(self.__class__.__name__)\n\n        # Convention: trying to open empty file is an error,\n        # because it could be of (almost) any type.\n\n        size = os.path.getsize(filename)\n        if size == 0:\n            raise RuntimeError(\"Empty file: '{0!s}'\".format(filename))\n\n        self._test_magic(filename)\n        self._do_load(filename)\n        self.filename = filename\n        self.__flag_loaded = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_default(self):\n        import f311\n        if self.default_filename is None:\n            raise RuntimeError(\"Class '{}' has no default filename\".format(self.__class__.__name__))\n        fullpath = f311.get_default_data_path(self.default_filename, class_=self.__class__)\n        self.load(fullpath)\n        self.filename = None", "response": "Initializes the object with its default values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef availability(self, availability):\n        allowed_values = [\"available\", \"comingSoon\", \"retired\"]\n        if availability is not None and availability not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `availability` ({0}), must be one of {1}\"\n                .format(availability, allowed_values)\n            )\n\n        self._availability = availability", "response": "Sets the availability of this Product."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the stock_status of this Product.", "response": "def stock_status(self, stock_status):\n        \"\"\"Sets the stock_status of this Product.\n\n\n        :param stock_status: The stock_status of this Product.\n        :type: str\n        \"\"\"\n        allowed_values = [\"available\", \"alert\", \"unavailable\"]\n        if stock_status is not None and stock_status not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `stock_status` ({0}), must be one of {1}\"\n                .format(stock_status, allowed_values)\n            )\n\n        self._stock_status = stock_status"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new Product AttributeNames", "response": "def create_product(cls, product, **kwargs):\n        \"\"\"Create Product\n\n        Create a new Product\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_product(product, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Product product: Attributes of product to create (required)\n        :return: Product\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_product_with_http_info(product, **kwargs)\n        else:\n            (data) = cls._create_product_with_http_info(product, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_product_by_id(cls, product_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_product_by_id_with_http_info(product_id, **kwargs)\n        else:\n            (data) = cls._delete_product_by_id_with_http_info(product_id, **kwargs)\n            return data", "response": "Delete an instance of Product by its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_product_by_id(cls, product_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_product_by_id_with_http_info(product_id, **kwargs)\n        else:\n            (data) = cls._get_product_by_id_with_http_info(product_id, **kwargs)\n            return data", "response": "Find Product by ID Return single instance of Product by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting Products Return a list of Products", "response": "def list_all_products(cls, **kwargs):\n        \"\"\"List Products\n\n        Return a list of Products\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_products(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Product]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_products_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_products_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_product_by_id(cls, product_id, product, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_product_by_id_with_http_info(product_id, product, **kwargs)\n        else:\n            (data) = cls._replace_product_by_id_with_http_info(product_id, product, **kwargs)\n            return data", "response": "Replace all attributes of Product\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_product_by_id(cls, product_id, product, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_product_by_id_with_http_info(product_id, product, **kwargs)\n        else:\n            (data) = cls._update_product_by_id_with_http_info(product_id, product, **kwargs)\n            return data", "response": "Update attributes of Product\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint just one that returns what you give it instead of None", "response": "def print(*a):\n    \"\"\" print just one that returns what you give it instead of None \"\"\"\n    try:\n        _print(*a)\n        return a[0] if len(a) == 1 else a\n    except:\n        _print(*a)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a unicode regular expression from a pattern.", "response": "def pattern2re(pattern):\n    \"\"\"Makes a unicode regular expression from a pattern.\n\n    Returns ``(start, full_re, int_re)`` where:\n\n     * `start` is either empty or the subdirectory in which to start searching,\n     * `full_re` is a regular expression object that matches the requested\n       files, i.e. a translation of the pattern\n     * `int_re` is either None of a regular expression object that matches\n       the requested paths or their ancestors (i.e. if a path doesn't match\n       `int_re`, no path under it will match `full_re`)\n\n    This uses extended patterns, where:\n\n      * a slash '/' always represents the path separator\n      * a backslash '\\' escapes other special characters\n      * an initial slash '/' anchors the match at the beginning of the\n        (relative) path\n      * a trailing '/' suffix is removed\n      * an asterisk '*'  matches a sequence of any length (including 0) of any\n        characters (except the path separator)\n      * a '?' matches exactly one character (except the path separator)\n      * '[abc]' matches characters 'a', 'b' or 'c'\n      * two asterisks '**' matches one or more path components (might match '/'\n        characters)\n    \"\"\"\n    pattern_segs = filter(None, pattern.split('/'))\n\n    # This anchors the first component either at the start of the string or at\n    # the start of a path component\n    if not pattern:\n        return '', re.compile(''), None\n    elif '/' in pattern:\n        full_regex = '^'  # Start at beginning of path\n        int_regex = []\n        int_regex_done = False\n        start_dir = []\n        start_dir_done = False\n    else:\n        full_regex = '(?:^|/)'  # Skip any number of full components\n        int_regex = None\n        int_regex_done = True\n        start_dir = []\n        start_dir_done = True\n\n    # Handles each component\n    for pnum, pat in enumerate(pattern_segs):\n        comp = patterncomp2re(pat)\n\n        # The first component is already anchored\n        if pnum > 0:\n            full_regex += '/'\n        full_regex += comp\n\n        if not int_regex_done:\n            if pat == '**':\n                int_regex_done = True\n            else:\n                int_regex.append(comp)\n                if not start_dir_done and no_special_chars.match(pat):\n                    start_dir.append(pat)\n                else:\n                    start_dir_done = True\n\n    full_regex = re.compile(full_regex.rstrip('/') + '$')\n    if int_regex is not None:\n        n = len(int_regex)\n        int_regex_s = ''\n        for i, c in enumerate(reversed(int_regex)):\n            if i == n - 1:  # Last iteration (first component)\n                int_regex_s = '^(?:%s%s)?' % (c, int_regex_s)\n            elif int_regex_s:\n                int_regex_s = '(?:/%s%s)?' % (c, int_regex_s)\n            else:  # First iteration (last component)\n                int_regex_s = '(?:/%s)?' % c\n        int_regex = re.compile(int_regex_s + '$')\n    start_dir = '/'.join(start_dir)\n    return start_dir, full_regex, int_regex"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _to_backend(self, p):\n        if isinstance(p, self._cmp_base):\n            return p.path\n        elif isinstance(p, self._backend):\n            return p\n        elif self._backend is unicode and isinstance(p, bytes):\n            return p.decode(self._encoding)\n        elif self._backend is bytes and isinstance(p, unicode):\n            return p.encode(self._encoding,\n                            'surrogateescape' if PY3 else 'strict')\n        else:\n            raise TypeError(\"Can't construct a %s from %r\" % (\n                            self.__class__.__name__, type(p)))", "response": "Converts a Path object to the correct path representation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parent(self):\n        p = self._lib.dirname(self.path)\n        p = self.__class__(p)\n        return p", "response": "The parent directory of this path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit this path into a pair ( drive location.", "response": "def split_root(self):\n        \"\"\"Splits this path into a pair (drive, location).\n\n        Note that, because all paths are normalized, a root of ``'.'`` will be\n        returned for relative paths.\n        \"\"\"\n        if not PY3 and hasattr(self._lib, 'splitunc'):\n            root, rest = self._lib.splitunc(self.path)\n            if root:\n                if rest.startswith(self._sep):\n                    root += self._sep\n                    rest = rest[1:]\n                return self.__class__(root), self.__class__(rest)\n        root, rest = self._lib.splitdrive(self.path)\n        if root:\n            if rest.startswith(self._sep):\n                root += self._sep\n                rest = rest[1:]\n            return self.__class__(root), self.__class__(rest)\n        if self.path.startswith(self._sep):\n            return self.__class__(self._sep), self.__class__(rest[1:])\n        return self.__class__(''), self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a relative path leading from this one to the given dest.", "response": "def rel_path_to(self, dest):\n        \"\"\"Builds a relative path leading from this one to the given `dest`.\n\n        Note that these paths might be both relative, in which case they'll be\n        assumed to start from the same directory.\n        \"\"\"\n        dest = self.__class__(dest)\n\n        orig_list = self.norm_case()._components()\n        dest_list = dest._components()\n\n        i = -1\n        for i, (orig_part, dest_part) in enumerate(zip(orig_list, dest_list)):\n            if orig_part != self._normcase(dest_part):\n                up = ['..'] * (len(orig_list) - i)\n                return self.__class__(*(up + dest_list[i:]))\n\n        if len(orig_list) <= len(dest_list):\n            if len(dest_list) > i + 1:\n                return self.__class__(*dest_list[i + 1:])\n            else:\n                return self.__class__('')\n        else:\n            up = ['..'] * (len(orig_list) - i - 1)\n            return self.__class__(*up)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lies_under(self, prefix):\n        orig_list = self.norm_case()._components()\n        pref_list = self.__class__(prefix).norm_case()._components()\n\n        return (len(orig_list) >= len(pref_list) and\n                orig_list[:len(pref_list)] == pref_list)", "response": "Indicates if the prefix is a parent of this path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a pair of file descriptor and absolute path.", "response": "def tempfile(cls, suffix='', prefix=None, dir=None, text=False):\n        \"\"\"Returns a new temporary file.\n\n        The return value is a pair (fd, path) where fd is the file descriptor\n        returned by :func:`os.open`, and path is a :class:`~rpaths.Path` to it.\n\n        :param suffix: If specified, the file name will end with that suffix,\n            otherwise there will be no suffix.\n\n        :param prefix: Is specified, the file name will begin with that prefix,\n            otherwise a default prefix is used.\n\n        :param dir: If specified, the file will be created in that directory,\n            otherwise a default directory is used.\n\n        :param text: If true, the file is opened in text mode. Else (the\n            default) the file is opened in binary mode.  On some operating\n            systems, this makes no difference.\n\n        The file is readable and writable only by the creating user ID.\n        If the operating system uses permission bits to indicate whether a\n        file is executable, the file is executable by no one. The file\n        descriptor is not inherited by children of this process.\n\n        The caller is responsible for deleting the file when done with it.\n        \"\"\"\n        if prefix is None:\n            prefix = tempfile.template\n        if dir is not None:\n            # Note that this is not safe on Python 2\n            # There is no work around, apart from not using the tempfile module\n            dir = str(Path(dir))\n        fd, filename = tempfile.mkstemp(suffix, prefix, dir, text)\n        return fd, cls(filename).absolute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tempdir(cls, suffix='', prefix=None, dir=None):\n        if prefix is None:\n            prefix = tempfile.template\n        if dir is not None:\n            # Note that this is not safe on Python 2\n            # There is no work around, apart from not using the tempfile module\n            dir = str(Path(dir))\n        dirname = tempfile.mkdtemp(suffix, prefix, dir)\n        return cls(dirname).absolute()", "response": "Returns a new temporary directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a relative path leading from this path to dest.", "response": "def rel_path_to(self, dest):\n        \"\"\"Builds a relative path leading from this one to another.\n\n        Note that these paths might be both relative, in which case they'll be\n        assumed to be considered starting from the same directory.\n\n        Contrary to :class:`~rpaths.AbstractPath`'s version, this will also\n        work if one path is relative and the other absolute.\n        \"\"\"\n        return super(Path, self.absolute()).rel_path_to(Path(dest).absolute())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all the files in this directory.", "response": "def listdir(self, pattern=None):\n        \"\"\"Returns a list of all the files in this directory.\n\n        The special entries ``'.'`` and ``'..'`` will not be returned.\n\n        :param pattern: A pattern to match directory entries against.\n        :type pattern: NoneType | Callable | Pattern | unicode | bytes\n        \"\"\"\n        files = [self / self.__class__(p) for p in os.listdir(self.path)]\n        if pattern is None:\n            pass\n        elif callable(pattern):\n            files = filter(pattern, files)\n        else:\n            if isinstance(pattern, backend_types):\n                if isinstance(pattern, bytes):\n                    pattern = pattern.decode(self._encoding, 'replace')\n                start, full_re, _int_re = pattern2re(pattern)\n            elif isinstance(pattern, Pattern):\n                start, full_re = pattern.start_dir, pattern.full_regex\n            else:\n                raise TypeError(\"listdir() expects pattern to be a callable, \"\n                                \"a regular expression or a string pattern, \"\n                                \"got %r\" % type(pattern))\n            # If pattern contains slashes (other than first and last chars),\n            # listdir() will never match anything\n            if start:\n                return []\n            files = [f for f in files if full_re.search(f.unicodename)]\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recursedir(self, pattern=None, top_down=True, follow_links=False,\n                   handle_errors=None):\n        \"\"\"Recursively lists all files under this directory.\n\n        :param pattern: An extended patterns, where:\n\n            * a slash '/' always represents the path separator\n            * a backslash '\\' escapes other special characters\n            * an initial slash '/' anchors the match at the beginning of the\n              (relative) path\n            * a trailing '/' suffix is removed\n            * an asterisk '*'  matches a sequence of any length (including 0)\n              of any characters (except the path separator)\n            * a '?' matches exactly one character (except the path separator)\n            * '[abc]' matches characters 'a', 'b' or 'c'\n            * two asterisks '**' matches one or more path components (might\n              match '/' characters)\n        :type pattern: NoneType | Callable | Pattern | unicode | bytes\n\n        :param follow_links: If False, symbolic links will not be followed (the\n            default). Else, they will be followed, but directories reached\n            through different names will *not* be listed multiple times.\n\n        :param handle_errors: Can be set to a callback that will be called when\n            an error is encountered while accessing the filesystem (such as a\n            permission issue). If set to None (the default), exceptions will be\n            propagated.\n        \"\"\"\n        if not self.is_dir():\n            raise ValueError(\"recursedir() called on non-directory %s\" % self)\n\n        start = ''\n        int_pattern = None\n        if pattern is None:\n            pattern = lambda p: True\n        elif callable(pattern):\n            pass\n        else:\n            if isinstance(pattern, backend_types):\n                if isinstance(pattern, bytes):\n                    pattern = pattern.decode(self._encoding, 'replace')\n                start, full_re, int_re = pattern2re(pattern)\n            elif isinstance(pattern, Pattern):\n                start, full_re, int_re = \\\n                    pattern.start_dir, pattern.full_regex, pattern.int_regex\n            else:\n                raise TypeError(\"recursedir() expects pattern to be a \"\n                                \"callable, a regular expression or a string \"\n                                \"pattern, got %r\" % type(pattern))\n            if self._lib.sep != '/':\n                pattern = lambda p: full_re.search(\n                    unicode(p).replace(self._lib.sep, '/'))\n                if int_re is not None:\n                    int_pattern = lambda p: int_re.search(\n                        unicode(p).replace(self._lib.sep, '/'))\n            else:\n                pattern = lambda p: full_re.search(unicode(p))\n                if int_re is not None:\n                    int_pattern = lambda p: int_re.search(unicode(p))\n        if not start:\n            path = self\n        else:\n            path = self / start\n            if not path.exists():\n                return []\n            elif not path.is_dir():\n                return [path]\n        return path._recursedir(pattern=pattern, int_pattern=int_pattern,\n                                top_down=top_down, seen=set(),\n                                path=self.__class__(start),\n                                follow_links=follow_links,\n                                handle_errors=handle_errors)", "response": "Recursively lists all files under this directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mkdir(self, name=None, parents=False, mode=0o777):\n        if name is not None:\n            return (self / name).mkdir(parents=parents, mode=mode)\n        if self.exists():\n            return\n        if parents:\n            os.makedirs(self.path, mode)\n        else:\n            os.mkdir(self.path, mode)\n        return self", "response": "Creates that directory or a directory under this one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rmdir(self, parents=False):\n        if parents:\n            os.removedirs(self.path)\n        else:\n            os.rmdir(self.path)", "response": "Removes this directory, provided it is empty.\n\n        Use :func:`~rpaths.Path.rmtree` if it might still contain files.\n\n        :param parents: If set to True, it will also destroy every empty\n            directory above it until an error is encountered."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename(self, new, parents=False):\n        if parents:\n            os.renames(self.path, self._to_backend(new))\n        else:\n            os.rename(self.path, self._to_backend(new))", "response": "Renames this path to the given new location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copyfile(self, target):\n        shutil.copyfile(self.path, self._to_backend(target))", "response": "Copies this file to the given target location."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy the mode of this file on the target file.", "response": "def copymode(self, target):\n        \"\"\"Copies the mode of this file on the `target` file.\n\n        The owner is not copied.\n        \"\"\"\n        shutil.copymode(self.path, self._to_backend(target))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy the permissions times and flags from this to the target.", "response": "def copystat(self, target):\n        \"\"\"Copies the permissions, times and flags from this to the `target`.\n\n        The owner is not copied.\n        \"\"\"\n        shutil.copystat(self.path, self._to_backend(target))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, target):\n        shutil.copy(self.path, self._to_backend(target))", "response": "Copies this file to the target."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copytree(self, target, symlinks=False):\n        shutil.copytree(self.path, self._to_backend(target), symlinks)", "response": "Recursively copies this directory to the target location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, mode='r', name=None, **kwargs):\n        if name is not None:\n            return io.open((self / name).path, mode=mode, **kwargs)\n        else:\n            return io.open(self.path, mode=mode, **kwargs)", "response": "Opens this file or a file under this directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rewrite(self, mode='r', name=None, temp=None, tempext='~', **kwargs):\n        if name is not None:\n            pathr = self / name\n        else:\n            pathr = self\n        for m in 'war+':\n            mode = mode.replace(m, '')\n\n        # Build options\n        common_kwargs = {}\n        readable_kwargs = {}\n        writable_kwargs = {}\n        for key, value in kwargs.items():\n            if key.startswith('read_'):\n                readable_kwargs[key[5:]] = value\n            elif key.startswith('write_'):\n                writable_kwargs[key[6:]] = value\n            else:\n                common_kwargs[key] = value\n        readable_kwargs = dict_union(common_kwargs, readable_kwargs)\n        writable_kwargs = dict_union(common_kwargs, writable_kwargs)\n\n        with pathr.open('r' + mode, **readable_kwargs) as readable:\n            if temp is not None:\n                pathw = Path(temp)\n            else:\n                pathw = pathr + tempext\n            try:\n                pathw.remove()\n            except OSError:\n                pass\n            writable = pathw.open('w' + mode, **writable_kwargs)\n            try:\n                yield readable, writable\n            except Exception:\n                # Problem, delete writable\n                writable.close()\n                pathw.remove()\n                raise\n            else:\n                writable.close()\n        # Alright, replace\n        pathr.copymode(pathw)\n        pathr.remove()\n        pathw.rename(pathr)", "response": "r Replaces this file with new content."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest if the given path matches the pattern.", "response": "def matches(self, path):\n        \"\"\"Tests if the given path matches the pattern.\n\n        Note that the unicode translation of the patch is matched, so\n        replacement characters might have been added.\n        \"\"\"\n        path = self._prepare_path(path)\n        return self.full_regex.search(path) is not None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntests whether the given path may contain the given pattern.", "response": "def may_contain_matches(self, path):\n        \"\"\"Tests whether it's possible for paths under the given one to match.\n\n        If this method returns None, no path under the given one will match the\n        pattern.\n        \"\"\"\n        path = self._prepare_path(path)\n        return self.int_regex.search(path) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads an HTML document or file from the web at a given URL.", "response": "def _fetch(url,):\n    \"\"\"\n    *Retrieve an HTML document or file from the web at a given URL*\n\n    **Key Arguments:**\n      - ``url`` -- the URL of the document or file\n\n    **Return:**\n      - ``url`` -- the URL of the document or file, or None if an error occured\n      - ``body`` -- the text content of the HTML document.\n    \"\"\"\n    import logging as log\n    import socket\n    from eventlet import Timeout\n    from eventlet.green import urllib2\n    import sys\n\n    # TRY AND DOWNLOAD X TIMES BEFORE QUITING\n    tries = 10\n    count = 1\n    downloaded = False\n    while count < tries and downloaded == False:\n        try:\n            log.debug('downloading ' + url.get_full_url())\n            body = urllib2.urlopen(url).read()\n            downloaded = True\n        except socket.timeout, e:\n            print \"timeout on URL, trying again\"\n            count += 1\n        except Exception, e:\n            if \"[Errno 60]\" in str(e):\n                log.warning('timeout on URL, trying again' % locals())\n                count += 1\n            if \"Error 502\" in str(e):\n                log.warning('proxy error on URL, trying again' % locals())\n                count += 1\n            else:\n                log.warning(\n                    \"could not download \" + url.get_full_url() + \" : \" + str(e) + \"\\n\")\n                url = None\n                body = None\n                downloaded = True\n\n    return url, body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Freedom information for the nation s nation.", "response": "async def freedom(self, root):\n        \"\"\"Nation's `Freedoms`: three basic indicators of the nation's\n        Civil Rights, Economy, and Political Freedom, as expressive\n        adjectives.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of :class:`collections.OrderedDict` with \\\n        keys and values of str\n            Keys being, in order: ``Civil Rights``, ``Economy``, and\n            ``Political Freedom``.\n        \"\"\"\n        elem = root.find('FREEDOM')\n        result = OrderedDict()\n\n        result['Civil Rights'] = elem.find('CIVILRIGHTS').text\n        result['Economy'] = elem.find('ECONOMY').text\n        result['Political Freedom'] = elem.find('POLITICALFREEDOM').text\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the freedom scores of the nation s nation.", "response": "async def freedomscores(self, root):\n        \"\"\"Nation's `Freedoms`: three basic indicators of the nation's\n        Civil Rights, Economy, and Political Freedom, as percentages.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of :class:`collections.OrderedDict` with \\\n        keys of str and values of int\n            Keys being, in order: ``Civil Rights``, ``Economy``, and\n            ``Political Freedom``.\n        \"\"\"\n        elem = root.find('FREEDOMSCORES')\n        result = OrderedDict()\n\n        result['Civil Rights'] = int(elem.find('CIVILRIGHTS').text)\n        result['Economy'] = int(elem.find('ECONOMY').text)\n        result['Political Freedom'] = int(elem.find('POLITICALFREEDOM').text)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the nation s government expenditure as percentages.", "response": "async def govt(self, root):\n        \"\"\"Nation's government expenditure, as percentages.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of :class:`collections.OrderedDict` with \\\n        keys of str and values of float\n            Keys being, in order: ``Administration``, ``Defense``,\n            ``Education``, ``Environment``, ``Healthcare``, ``Industry``,\n            ``International Aid``, ``Law & Order``, ``Public Transport``,\n            ``Social Policy``, ``Spirituality``, and ``Welfare``.\n        \"\"\"\n        elem = root.find('GOVT')\n        result = OrderedDict()\n\n        result['Administration'] = float(elem.find('ADMINISTRATION').text)\n        result['Defense'] = float(elem.find('DEFENCE').text)  # match the web UI\n        result['Education'] = float(elem.find('EDUCATION').text)\n        result['Environment'] = float(elem.find('ENVIRONMENT').text)\n        result['Healthcare'] = float(elem.find('HEALTHCARE').text)\n        result['Industry'] = float(elem.find('COMMERCE').text)  # Don't ask\n        result['International Aid'] = float(elem.find('INTERNATIONALAID').text)\n        result['Law & Order'] = float(elem.find('LAWANDORDER').text)\n        result['Public Transport'] = float(elem.find('PUBLICTRANSPORT').text)\n        result['Social Policy'] = float(elem.find('SOCIALEQUALITY').text)  # Shh\n        result['Spirituality'] = float(elem.find('SPIRITUALITY').text)\n        result['Welfare'] = float(elem.find('WELFARE').text)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def sectors(self, root):\n        elem = root.find('SECTORS')\n        result = OrderedDict()\n\n        result['Black Market (estimated)'] = float(elem.find('BLACKMARKET').text)\n        result['Government'] = float(elem.find('GOVERNMENT').text)\n        result['Private Industry'] = float(elem.find('INDUSTRY').text)\n        result['State-Owned Industry'] = float(elem.find('PUBLIC').text)\n        return result", "response": "Get the sectors of the nation s economy as percentages."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def deaths(self, root):\n        return {\n            elem.get('type'): float(elem.text)\n            for elem in root.find('DEATHS')\n        }", "response": "Returns a dict of all the deaths in the nation as percentages."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def endorsements(self, root):\n        text = root.find('ENDORSEMENTS').text\n        return [Nation(name) for name in text.split(',')] if text else []", "response": "Regional neighbours endorsing the nation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accept(self):\n        return self._issue._nation._accept_issue(self._issue.id, self._id)", "response": "Accept the option.\n\n        Returns ------- an awaitable of issueResult"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_all_promotions(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_promotions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_promotions_with_http_info(**kwargs)\n            return data", "response": "List Promotions\n        Return a list of Promotions\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to upgrade all packages installed with user only", "response": "def pip_upgrade_all_user(line):\n    \"\"\"Attempt to upgrade all packages installed with --user\"\"\"\n    import pip\n    for dist in pip.get_installed_distributions(user_only=True):\n        do_pip([\"install\", \"--upgrade\", \"--user\", dist.project_name])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pip_upgrade_all(line):\n    from pip import get_installed_distributions\n    user = set(d.project_name for d in get_installed_distributions(user_only=True))\n    all = set(d.project_name for d in get_installed_distributions())\n    for dist in all - user:\n        do_pip([\"install\", \"--upgrade\", dist])\n    for dist in  user:\n        do_pip([\"install\", \"--upgrade\", \"--user\", dist])", "response": "Attempt to upgrade all packages"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enc_name_descr(name, descr, color=a99.COLOR_DESCR):\r\n    return enc_name(name, color)+\"<br>\"+descr", "response": "Encodes html given name and description."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstyle checkboxes in the given widget.", "response": "def style_checkboxes(widget):\r\n    \"\"\"\r\n    Iterates over widget children to change checkboxes stylesheet.\r\n\r\n    The default rendering of checkboxes does not allow to tell a focused one\r\n    from an unfocused one.\r\n    \"\"\"\r\n\r\n    ww = widget.findChildren(QCheckBox)\r\n    for w in ww:\r\n        w.setStyleSheet(\"QCheckBox:focus {border: 1px solid #000000;}\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_return_space(event, callable_):\r\n    if event.type() == QEvent.KeyPress:\r\n        if event.key() in [Qt.Key_Return, Qt.Key_Space]:\r\n            callable_()\r\n            return True\r\n    return False", "response": "Checks if event corresponds to Return or Space being pressed and calls callable_ if so."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclears and resizes a table widget.", "response": "def reset_table_widget(t, rowCount, colCount):\r\n    \"\"\"Clears and resizes a table widget.\"\"\"\r\n    t.reset()\r\n    t.horizontalHeader().reset()\r\n    t.clear()\r\n    t.sortItems(-1)\r\n    t.setRowCount(rowCount)\r\n    t.setColumnCount(colCount)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows an editor modal form for the parameters object.", "response": "def show_edit_form(obj, attrs=None, title=\"\", toolTips=None):\r\n    \"\"\"Shows parameters editor modal form.\r\n\r\n    Arguments:\r\n       obj: object to extract attribute values from, or a dict-like\r\n       attrs: list of attribute names\r\n       title:\r\n       toolTips:\r\n    \"\"\"\r\n\r\n    if attrs is None:\r\n        if hasattr(obj, \"keys\"):\r\n            attrs = list(obj.keys())\r\n        else:\r\n            raise RuntimeError(\"attrs is None and cannot determine it from obj\")\r\n\r\n    specs = []\r\n    for i, name in enumerate(attrs):\r\n        # Tries as attribute, then as key\r\n        try:\r\n            value = obj.__getattribute__(name)\r\n        except AttributeError:\r\n            value = obj[name]\r\n\r\n        if value is None:\r\n            value = \"\"  # None becomes str\r\n\r\n        dict_ = {\"value\": value}\r\n\r\n        if toolTips is not None:\r\n            dict_[\"toolTip\"] = toolTips[i]\r\n            dict_[\"tooltip\"] = toolTips[i]\r\n\r\n        specs.append((name, dict_))\r\n    form = XParametersEditor(specs=specs, title=title)\r\n    r = form.exec_()\r\n    return r, form"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef place_left_top(window, width=None, height=None):\r\n\r\n    if width is None:\r\n        width = window.width()\r\n    if height is None:\r\n        height = window.height()\r\n\r\n    window.setGeometry(_DESKTOP_OFFSET_LEFT, _DESKTOP_OFFSET_TOP, width, height)", "response": "Places window in top left corner of screen."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef place_center(window, width=None, height=None):\r\n    screenGeometry = QApplication.desktop().screenGeometry()\r\n\r\n    w, h = window.width(), window.height()\r\n\r\n    if width is not None or height is not None:\r\n        w = width if width is not None else w\r\n        h = height if height is not None else h\r\n        window.setGeometry(0, 0, w, h)\r\n\r\n    x = (screenGeometry.width() - w) / 2\r\n    y = (screenGeometry.height() - h) / 2\r\n    window.move(x, y)", "response": "Places window in the center of the screen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsnapping window to left of desktop.", "response": "def snap_left(window, width=None):\r\n    \"\"\"Snaps window to left of desktop.\r\n    Arguments:\r\n      window -- a QWidget\r\n      width=None -- window width, in case you want to change it (if not passed, not changed)\r\n    \"\"\"\r\n    if not width:\r\n        width = window.width()\r\n    rect = QApplication.desktop().screenGeometry()\r\n    window.setGeometry(_DESKTOP_OFFSET_LEFT, _DESKTOP_OFFSET_TOP, width, rect.height())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsnapping window to right of desktop.", "response": "def snap_right(window, width=None):\r\n    \"\"\"Snaps window to right of desktop.\r\n    Arguments:\r\n      window -- a QWidget\r\n      width=None -- window width, in case you want to change it (if not passed, not changed)\r\n    \"\"\"\r\n    if not width:\r\n        width = window.width()\r\n    rect = QApplication.desktop().screenGeometry()\r\n    window.setGeometry(rect.width()-width, _DESKTOP_OFFSET_TOP, width, rect.height())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_matplotlib_layout(widget, flag_toolbar=True):\r\n    fig = plt.figure()\r\n    canvas = FigureCanvas(fig)\r\n    #        self.canvas.mpl_connect('button_press_event', self.on_plot_click)\r\n    layout = QVBoxLayout(widget)\r\n    if flag_toolbar:\r\n        toolbar = NavigationToolbar2QT(canvas, widget)\r\n        layout.addWidget(toolbar)\r\n    layout.addWidget(canvas)\r\n    a99.set_margin(layout, 0)\r\n\r\n    return fig, canvas, layout", "response": "Returns figure toolbar layout sets widget"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_icon(keyword):\r\n\r\n    filename = a99.get_path( \"icons\", keyword + \".png\")\r\n    if not os.path.isfile(filename):\r\n        raise FileNotFoundError(\"File '{}' does not exist\".format(filename))\r\n    return QIcon(filename)", "response": "Returns a QIcon object for the given keyword."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_QApplication(args=[]):\r\n    global _qapp\r\n    if _qapp is None:\r\n        QCoreApplication.setAttribute(Qt.AA_X11InitThreads)\r\n        _qapp = QApplication(args)\r\n\r\n    return _qapp", "response": "Returns the QApplication instance creating it is does not yet exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef table_info_to_parameters(table_info):\r\n\r\n    # Example of item in table_info:\r\n    #   MyDBRow([('cid', 0), ('name', 'id'), ('type', 'integer'), ('notnull', 0), ('dflt_value', None), ('pk', 1)])\r\n\r\n    opbj = a99.Parameters()\r\n    for field_info in table_info.values():\r\n        p = a99.Parameter()\r\n        if field_info.type == \"integer\":\r\n            p.type = int\r\n        elif field_info.type == \"real\":\r\n            p.type = float\r\n        else:\r\n            p.type = str\r\n\r\n        p.name = field_info.name\r\n        if field_info.dflt_value is not None:\r\n            p.value = field_info.dflt_value\r\n        opbj.params.append(p)\r\n    return opbj", "response": "Converts a list of MyDBRow into a parameters. Parameters object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a QFrame formatted in a particular way", "response": "def get_frame():\r\n    \"\"\"Returns a QFrame formatted in a particular way\"\"\"\r\n    ret = QFrame()\r\n    ret.setLineWidth(1)\r\n    ret.setMidLineWidth(0)\r\n    ret.setFrameShadow(QFrame.Sunken)\r\n    ret.setFrameShape(QFrame.Box)\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a checkbox s checked property + signal blocking + value + signal blocking + value", "response": "def set_checkbox_value(w, value):\r\n    \"\"\"\r\n    Sets a checkbox's \"checked\" property + signal blocking + value tolerance\r\n\r\n    Args:\r\n        w: QCheckBox instance\r\n        value: something that can be converted to a bool\r\n    \"\"\"\r\n    save = w.blockSignals(True)\r\n    try:\r\n        w.setChecked(bool(value))\r\n    finally:\r\n        w.blockSignals(save)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_signal(self, signal):\r\n        self.__signals.append(signal)\r\n        if self.__connected:\r\n            # Connects signal if the current state is \"connected\"\r\n            self.__connect_signal(signal)", "response": "Adds input signal to connected signals. Internally connects the signal to a control slot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting all signals and slots.", "response": "def connect_all(self):\r\n        \"\"\"[Re-]connects all signals and slots.\r\n\r\n        If already in \"connected\" state, ignores the call.\r\n        \"\"\"\r\n        if self.__connected:\r\n            return  # assert not self.__connected, \"connect_all() already in \\\"connected\\\" state\"\r\n        with self.__lock:\r\n            for signal in self.__signals:\r\n                self.__connect_signal(signal)\r\n            if self.__slot is not None:\r\n                self.__sigDelayed.connect(self.__slot, Qt.QueuedConnection)\r\n            self.__connected = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisconnects all signals and slots.", "response": "def disconnect_all(self):\r\n        \"\"\"Disconnects all signals and slots.\r\n\r\n        If already in \"disconnected\" state, ignores the call.\r\n        \"\"\"\r\n        if not self.__connected:\r\n            return  # assert self.__connected, \"disconnect_all() already in \\\"disconnected\\\" state\"\r\n        self.__disconnecting = True\r\n        try:\r\n            for signal in self.__signals:\r\n                signal.disconnect(self.__signalReceived)\r\n            if self.__slot is not None:\r\n                self.__sigDelayed.disconnect(self.__slot)\r\n            self.__connected = False\r\n        finally:\r\n            self.__disconnecting = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls by the event loop when a new message is received.", "response": "def __signalReceived(self, *args):\r\n        \"\"\"Received signal. Cancel previous timer and store args to be forwarded later.\"\"\"\r\n        if self.__disconnecting:\r\n            return\r\n        with self.__lock:\r\n            self.__args = args\r\n            if self.__rateLimit == 0:\r\n                self.__timer.stop()\r\n                self.__timer.start((self.__delay * 1000) + 1)\r\n            else:\r\n                now = time.time()\r\n                if self.__lastFlushTime is None:\r\n                    leakTime = 0\r\n                else:\r\n                    lastFlush = self.__lastFlushTime\r\n                    leakTime = max(0, (lastFlush + (1.0 / self.__rateLimit)) - now)\r\n\r\n                self.__timer.stop()\r\n                # Note: original was min() below.\r\n                timeout = (max(leakTime, self.__delay) * 1000) + 1\r\n                self.__timer.start(timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __flush(self):\r\n        if self.__args is None or self.__disconnecting:\r\n            return False\r\n        #self.emit(self.signal, *self.args)\r\n        self.__sigDelayed.emit(self.__args)\r\n        self.__args = None\r\n        self.__timer.stop()\r\n        self.__lastFlushTime = time.time()\r\n        return True", "response": "Send the next queued signal."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving any extra details from indicators.", "response": "def clean_indicators(indicators):\n    \"\"\"Remove any extra details from indicators.\"\"\"\n    output = list()\n    for indicator in indicators:\n        strip = ['http://', 'https://']\n        for item in strip:\n            indicator = indicator.replace(item, '')\n        indicator = indicator.strip('.').strip()\n        parts = indicator.split('/')\n        if len(parts) > 0:\n            indicator = parts.pop(0)\n        output.append(indicator)\n    output = list(set(output))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hash_values(values, alg=\"md5\"):\n    import hashlib\n    if alg not in ['md5', 'sha1', 'sha256']:\n        raise Exception(\"Invalid hashing algorithm!\")\n\n    hasher = getattr(hashlib, alg)\n    if type(values) == str:\n        output = hasher(values).hexdigest()\n    elif type(values) == list:\n        output = list()\n        for item in values:\n            output.append(hasher(item).hexdigest())\n    return output", "response": "Hash a list of values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the indicators against known whitelists.", "response": "def check_whitelist(values):\n    \"\"\"Check the indicators against known whitelists.\"\"\"\n    import os\n    import tldextract\n    whitelisted = list()\n    for name in ['alexa.txt', 'cisco.txt']:\n        config_path = os.path.expanduser('~/.config/blockade')\n        file_path = os.path.join(config_path, name)\n        whitelisted += [x.strip() for x in open(file_path, 'r').readlines()]\n    output = list()\n    for item in values:\n        ext = tldextract.extract(item)\n        if ext.registered_domain in whitelisted:\n            continue\n        output.append(item)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncaching indicators that were successfully sent to avoid dups.", "response": "def cache_items(values):\n    \"\"\"Cache indicators that were successfully sent to avoid dups.\"\"\"\n    import os\n    config_path = os.path.expanduser('~/.config/blockade')\n    file_path = os.path.join(config_path, 'cache.txt')\n    if not os.path.isfile(file_path):\n        file(file_path, 'w').close()\n    written = [x.strip() for x in open(file_path, 'r').readlines()]\n    handle = open(file_path, 'a')\n    for item in values:\n        # Because of the option to submit in clear or hashed, we need to make\n        # sure we're not re-hashing before adding.\n        if is_hashed(item):\n            hashed = item\n        else:\n            hashed = hash_values(item)\n\n        if hashed in written:\n            continue\n        handle.write(hashed + \"\\n\")\n    handle.close()\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prune_cached(values):\n    import os\n    config_path = os.path.expanduser('~/.config/blockade')\n    file_path = os.path.join(config_path, 'cache.txt')\n    if not os.path.isfile(file_path):\n        return values\n    cached = [x.strip() for x in open(file_path, 'r').readlines()]\n    output = list()\n    for item in values:\n        hashed = hash_values(item)\n        if hashed in cached:\n            continue\n        output.append(item)\n    return output", "response": "Remove the items that have already been cached."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_logger(name):\n    import logging\n    import sys\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    shandler = logging.StreamHandler(sys.stdout)\n    fmt = \"\"\n    fmt += '\\033[1;32m%(levelname)-5s %(module)s:%(funcName)s():'\n    fmt += '%(lineno)d %(asctime)s\\033[0m| %(message)s'\n    fmtr = logging.Formatter(fmt)\n    shandler.setFormatter(fmtr)\n    logger.addHandler(shandler)\n    return logger", "response": "Get a logging instance we can use."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_whitelists():\n    import csv\n    import grequests\n    import os\n    import StringIO\n    import zipfile\n    mapping = {\n        'http://s3.amazonaws.com/alexa-static/top-1m.csv.zip': {\n            'name': 'alexa.txt'\n        }, 'http://s3-us-west-1.amazonaws.com/umbrella-static/top-1m.csv.zip': {\n            'name': 'cisco.txt'\n        }\n    }\n    rs = (grequests.get(u) for u in mapping.keys())\n    responses = grequests.map(rs)\n    for r in responses:\n        data = zipfile.ZipFile(StringIO.StringIO(r.content)).read('top-1m.csv')\n        stream = StringIO.StringIO(data)\n        reader = csv.reader(stream, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n        items = [row[1].strip() for row in reader]\n        stream.close()\n\n        config_path = os.path.expanduser('~/.config/blockade')\n        file_path = os.path.join(config_path, mapping[r.url]['name'])\n        handle = open(file_path, 'w')\n        for item in items:\n            if item.count('.') == 0:\n                continue\n            handle.write(item + \"\\n\")\n        handle.close()\n    return True", "response": "Download approved top 1M lists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mode(self, mode):\n        allowed_values = [\"test\", \"live\"]\n        if mode is not None and mode not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `mode` ({0}), must be one of {1}\"\n                .format(mode, allowed_values)\n            )\n\n        self._mode = mode", "response": "Sets the mode of this BraintreeGateway."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_braintree_gateway(cls, braintree_gateway, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_braintree_gateway_with_http_info(braintree_gateway, **kwargs)\n        else:\n            (data) = cls._create_braintree_gateway_with_http_info(braintree_gateway, **kwargs)\n            return data", "response": "Create a new BraintreeGateway with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_braintree_gateway_by_id(cls, braintree_gateway_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_braintree_gateway_by_id_with_http_info(braintree_gateway_id, **kwargs)\n        else:\n            (data) = cls._delete_braintree_gateway_by_id_with_http_info(braintree_gateway_id, **kwargs)\n            return data", "response": "Delete an instance of BraintreeGateway by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds BraintreeGateway by its ID Return single instance of BraintreeGateway with the specified ID.", "response": "def get_braintree_gateway_by_id(cls, braintree_gateway_id, **kwargs):\n        \"\"\"Find BraintreeGateway\n\n        Return single instance of BraintreeGateway by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_braintree_gateway_by_id(braintree_gateway_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str braintree_gateway_id: ID of braintreeGateway to return (required)\n        :return: BraintreeGateway\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_braintree_gateway_by_id_with_http_info(braintree_gateway_id, **kwargs)\n        else:\n            (data) = cls._get_braintree_gateway_by_id_with_http_info(braintree_gateway_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_all_braintree_gateways(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_braintree_gateways_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_braintree_gateways_with_http_info(**kwargs)\n            return data", "response": "List all BraintreeGateways in a specific language"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace all attributes of BraintreeGateway with new attributes", "response": "def replace_braintree_gateway_by_id(cls, braintree_gateway_id, braintree_gateway, **kwargs):\n        \"\"\"Replace BraintreeGateway\n\n        Replace all attributes of BraintreeGateway\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_braintree_gateway_by_id(braintree_gateway_id, braintree_gateway, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str braintree_gateway_id: ID of braintreeGateway to replace (required)\n        :param BraintreeGateway braintree_gateway: Attributes of braintreeGateway to replace (required)\n        :return: BraintreeGateway\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_braintree_gateway_by_id_with_http_info(braintree_gateway_id, braintree_gateway, **kwargs)\n        else:\n            (data) = cls._replace_braintree_gateway_by_id_with_http_info(braintree_gateway_id, braintree_gateway, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_braintree_gateway_by_id(cls, braintree_gateway_id, braintree_gateway, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_braintree_gateway_by_id_with_http_info(braintree_gateway_id, braintree_gateway, **kwargs)\n        else:\n            (data) = cls._update_braintree_gateway_by_id_with_http_info(braintree_gateway_id, braintree_gateway, **kwargs)\n            return data", "response": "Update attributes of BraintreeGateway by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndiagnose the data in a single resource tree.", "response": "def diagnose(df,preview_rows = 2,\n            display_max_cols = 0,display_width = None): \n    \"\"\" Prints information about the DataFrame pertinent to data cleaning.\n\n    Parameters\n    ----------\n    df - DataFrame\n        The DataFrame to summarize\n    preview_rows - int, default 5\n        Amount of rows to preview from the head and tail of the DataFrame\n    display_max_cols - int, default None\n        Maximum amount of columns to display. If set to None, all columns will be displayed.\n        If set to 0, only as many as fit in the screen's width will be displayed\n    display_width - int, default None\n        Width of output. Can be width of file or width of console for printing.\n        Set to None for pandas to detect it from console.\n    \"\"\"\n    assert type(df) is pd.DataFrame\n    # Diagnose problems with the data formats that can be addressed in cleaning\n    \n     # Get initial display settings\n    initial_max_cols = pd.get_option('display.max_columns')\n    initial_max_rows = pd.get_option('display.max_rows')\n    initial_width = pd.get_option('display.width')\n\n    # Reformat displays\n    pd.set_option('display.max_columns', display_max_cols)\n    pd.set_option('display.max_rows',None)\n    if display_width is not None:\n            pd.set_option('display.width',display_width)\n\n    # --------Values of data-----------\n    df_preview = _io.preview(df,preview_rows)\n    \n    df_info = _io.get_info(df,verbose = True, max_cols = display_max_cols, \n                               memory_usage = 'deep',null_counts = True)\n    \n    dtypes = stats.dtypes_summary(df).apply(_io.format_row,args = [_utils.rows(df)],axis = 1)\n    \n    potential_outliers = stats.df_outliers(df).dropna(axis = 1,how = 'all')\n    potential_outliers = potential_outliers if _utils.rows(potential_outliers) \\\n                    else None\n\n    # ----------Build lists------------\n    \n    title_list = \\\n    ['Preview','Info',\n     'Data Types Summary','Potential Outliers']\n    info_list = \\\n    [df_preview,df_info,\n     dtypes,potential_outliers]\n    error_list = [None,None,\n                  None,'No potential outliers.']\n    \n    # ----------Build output------------\n    \n    output = ''\n    for title, value,error_text in zip(title_list,info_list,error_list):\n        if value is None:\n            value = \"{} skipped: {}\".format(title,error_text)\n        if str(value).endswith('\\n'):\n            value = value[:-1]\n        output+='{}\\n{}\\n\\n'.format(_io.title_line(title),value)\n\n    # ----------Send to file/print to console------------\n        # Potentially could change this to allow for output_safe to work with directories\n    print(output)\n\n    # Reset display settings\n    pd.set_option('display.max_columns', initial_max_cols)\n    pd.set_option('display.max_rows', initial_max_rows)\n    pd.set_option('display.width', initial_width)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cut_spectrum(sp, l0, lf):\n\n    if l0 >= lf:\n        raise ValueError(\"l0 must be lower than lf\")\n    idx0 = np.argmin(np.abs(sp.x - l0))\n    idx1 = np.argmin(np.abs(sp.x - lf))\n    out = copy.deepcopy(sp)\n    out.x = out.x[idx0:idx1]\n    out.y = out.y[idx0:idx1]\n    return out", "response": "Returns a new Spectrum instance that is cut by a given wavelength interval leaving origina intact"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new grammar with nongenerating nonterminals removed.", "response": "def remove_nongenerating_nonterminals(grammar, inplace=False):\n    # type: (Grammar, bool) -> Grammar\n    \"\"\"\n    Remove nongenerating symbols from the grammar.\n    Nongenerating symbols are symbols, that don't generate sequence of terminals.\n    For example never ending recursion.\n    :param grammar: Grammar where to remove nongenerating symbols.\n    :param inplace: True if transformation should be performed in place. False by default.\n    :return: Grammar without nongenerating symbols.\n    \"\"\"\n    # copy if required\n    if inplace is False:\n        grammar = copy(grammar)\n    # create working sets\n    generates = grammar.terminals.copy()\n    generates.add(EPSILON)\n    rules = grammar.rules.copy()\n    # iterate until the set doesn't change\n    while True:\n        # create set for the next iteration\n        additional = generates.copy()\n        # iterate over unprocessed rules\n        for rule in rules.copy():\n            rightPart = rule.right\n            allIn = True\n            # check if all symbols on the right part of rule are in generates set\n            for symbol in rightPart:\n                if symbol not in generates:\n                    allIn = False\n                    break\n            # Symbol is missing so rule is not process\n            if not allIn:\n                continue\n            # Rule is process - remove it from processing rules and make symbol as generating\n            additional.add(rule.fromSymbol)\n            rules.remove(rule)\n            # end of rules iterations\n        # ff current and previous iterations are same, than end iterations\n        if additional == generates:\n            break\n        # swap sets from previous and current iterations\n        generates = additional\n    # remove nonterms that are not generating\n    nongenerating = grammar.nonterminals.difference(generates)\n    grammar.nonterminals.remove(*nongenerating)\n    # return the grammar\n    return grammar"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nskips the first item in the list", "response": "def skip_first(pipe, items=1):\n    ''' this is an alias for skip to parallel the dedicated skip_last function\n        to provide a little more readability to the code. the action of actually\n        skipping does not occur until the first iteration is done\n    '''\n    pipe = iter(pipe)\n    for i in skip(pipe, items):\n        yield i"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(self, query=None, **kwargs):\n        url = self.getUrl()\n        if query is not None:\n            if isinstance(query, queries.SlickQuery):\n                url = url + \"?\" + urlencode(query.to_dict())\n            elif isinstance(query, dict):\n                url = url + \"?\" + urlencode(query)\n        elif len(kwargs) > 0:\n            url = url + \"?\" + urlencode(kwargs)\n\n        # hopefully when we discover what problems exist in slick to require this, we can take the loop out\n        for retry in range(3):\n            try:\n                self.logger.debug(\"Making request to slick at url %s\", url)\n                r = requests.get(url)\n                self.logger.debug(\"Request returned status code %d\", r.status_code)\n                if r.status_code is 200:\n                    retval = []\n                    objects = r.json()\n                    for dct in objects:\n                        retval.append(self.model.from_dict(dct))\n                    return retval\n                else:\n                    self.logger.error(\"Slick returned an error when trying to access %s: status code %s\" % (url, str(r.status_code)))\n                    self.logger.error(\"Slick response: \", pprint.pformat(r))\n                    \n            except BaseException as error:\n                self.logger.warn(\"Received exception while connecting to slick at %s\", url, exc_info=sys.exc_info())\n        raise SlickCommunicationError(\n            \"Tried 3 times to request data from slick at url %s without a successful status code.\", url)", "response": "This method returns a list of model objects from the slick server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef findOne(self, query=None, mode=FindOneMode.FIRST, **kwargs):\n        results = self.find(query, **kwargs)\n        if len(results) is 0:\n            return None\n        elif len(results) is 1 or mode == FindOneMode.FIRST:\n            return results[0]\n        elif mode == FindOneMode.LAST:\n            return results[-1]", "response": "Perform a find and return a maximum of one result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the specified object from the slick.", "response": "def get(self):\n        \"\"\"Get the specified object from slick.  You specify which one you want by providing the id as a parameter to\n        the parent object.  Example:\n        slick.projects(\"4fd8cd95e4b0ee7ba54b9885\").get()\n        \"\"\"\n        url = self.getUrl()\n\n        # hopefully when we discover what problems exist in slick to require this, we can take the loop out\n        for retry in range(3):\n            try:\n                self.logger.debug(\"Making request to slick at url %s\", url)\n                r = requests.get(url)\n                self.logger.debug(\"Request returned status code %d\", r.status_code)\n                if r.status_code is 200:\n                    return self.model.from_dict(r.json())\n                else:\n                    self.logger.debug(\"Body of what slick returned: %s\", r.text)\n            except BaseException as error:\n                self.logger.warn(\"Received exception while connecting to slick at %s\", url, exc_info=sys.exc_info())\n        raise SlickCommunicationError(\n            \"Tried 3 times to request data from slick at url %s without a successful status code.\", url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the object with the specified data from slick.", "response": "def update(self):\n        \"\"\"Update the specified object from slick.  You specify the object as a parameter, using the parent object as\n        a function.  Example:\n        proj = slick.projects.findByName(\"foo\")\n        ... update proj here\n        slick.projects(proj).update()\n        \"\"\"\n        obj = self.data\n        url = self.getUrl()\n\n        # hopefully when we discover what problems exist in slick to require this, we can take the loop out\n        last_stats_code = None\n        last_body = None\n        for retry in range(3):\n            try:\n                json_data = obj.to_json()\n                self.logger.debug(\"Making request to slick at url %s, with data: %s\", url, json_data)\n                r = requests.put(url, data=json_data, headers=json_content)\n                self.logger.debug(\"Request returned status code %d\", r.status_code)\n                if r.status_code is 200:\n                    return self.model.from_dict(r.json())\n                else:\n                    last_stats_code = r.status_code\n                    last_body = r.text\n                    self.logger.warn(\"Slick status code: %d\", r.status_code)\n                    self.logger.warn(\"Body of what slick returned: %s\", r.text)\n            except BaseException as error:\n                self.logger.warn(\"Received exception while connecting to slick at %s\", url, exc_info=sys.exc_info())\n                traceback.print_exc()\n        raise SlickCommunicationError(\n            \"Tried 3 times to request data from slick at url %s without a successful status code.  Last status code: %d, body: %s\", url, last_stats_code, last_body)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self):\n        obj = self.data\n        self.data = None\n        url = self.getUrl()\n\n        # hopefully when we discover what problems exist in slick to require this, we can take the loop out\n        for retry in range(3):\n            try:\n                json_data = obj.to_json()\n                self.logger.debug(\"Making request to slick at url %s, with data: %s\", url, json_data)\n                r = requests.post(url, data=json_data, headers=json_content)\n                self.logger.debug(\"Request returned status code %d\", r.status_code)\n                if r.status_code is 200:\n                    return self.model.from_dict(r.json())\n                else:\n                    self.logger.debug(\"Body of what slick returned: %s\", r.text)\n            except BaseException as error:\n                self.logger.warn(\"Received exception while connecting to slick at %s\", url, exc_info=sys.exc_info())\n        raise SlickCommunicationError(\n            \"Tried 3 times to request data from slick at url %s without a successful status code.\", url)", "response": "Create the object in the project and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self):\n        url = self.getUrl()\n\n        # hopefully when we discover what problems exist in slick to require this, we can take the loop out\n        for retry in range(3):\n            try:\n                self.logger.debug(\"Making DELETE request to slick at url %s\", url)\n                r = requests.delete(url)\n                self.logger.debug(\"Request returned status code %d\", r.status_code)\n                if r.status_code is 200:\n                    return None\n                else:\n                    self.logger.debug(\"Body of what slick returned: %s\", r.text)\n            except BaseException as error:\n                self.logger.warn(\"Received exception while connecting to slick at %s\", url, exc_info=sys.exc_info())\n        raise SlickCommunicationError(\n            \"Tried 3 times to request data from slick at url %s without a successful status code.\", url)", "response": "Remove or delete the specified object from the slick."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload a local file to slick and return the ID of the new file.", "response": "def upload_local_file(self, local_file_path, file_obj=None):\n        \"\"\"Create a Stored File and upload it's data.  This is a one part do it all type method.  Here is what\n        it does:\n            1. \"Discover\" information about the file (mime-type, size)\n            2. Create the stored file object in slick\n            3. Upload (chunked) all the data in the local file\n            4. re-fetch the stored file object from slick, and return it\n        \"\"\"\n        if file_obj is None and not os.path.exists(local_file_path):\n            return\n        storedfile = StoredFile()\n        storedfile.mimetype = mimetypes.guess_type(local_file_path)[0]\n        storedfile.filename = os.path.basename(local_file_path)\n        if file_obj is None:\n            storedfile.length = os.stat(local_file_path).st_size\n        else:\n            file_obj.seek(0,os.SEEK_END)\n            storedfile.length = file_obj.tell()\n            file_obj.seek(0)\n        storedfile = self(storedfile).create()\n        md5 = hashlib.md5()\n        url = self(storedfile).getUrl() + \"/addchunk\"\n        if file_obj is None:\n            with open(local_file_path, 'rb') as filecontents:\n                upload_chunks(url, storedfile, filecontents)\n        else:\n            upload_chunks(url, storedfile, file_obj)\n        return self(storedfile).update()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_vector_value(self, var_name, value):\n        self.particle[var_name] = convert_3vector_to_dict(value)\n\n        for coord in self.particle[var_name].keys():\n            new_value = Distribution(self.particle[var_name][coord])\n            self.particle[var_name][coord] = new_value", "response": "Private method to set the value of a variable in the particle."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets next events from the genie file", "response": "def _get_next_events(self, material):\n        \"\"\"Get next events from Genie ROOT file\n\n        Looks over the generator\"\"\"\n\n        f = ROOT.TFile(self.filenames[material])\n        try:\n            t = f.Get('gst')\n            n = t.GetEntries()\n        except:\n            self.log.critical('Could not open the ROOT file with Genie events')\n            raise\n\n        for i in range(n):\n            t.GetEntry(i)\n            next_events = []\n\n            position = convert_3vector_to_dict([self.particle['position']['x'].get_cache(),\n                                                self.particle['position']['y'].get_cache(),\n                                                self.particle['position']['z'].get_cache()])\n\n            lepton_event = {}\n            if t.El ** 2 - (t.pxl ** 2 + t.pyl ** 2 + t.pzl ** 2) < 1e-7:\n                lepton_event['pid'] = self.particle[\n                                      'pid'].get()  # Either NC or ES\n            else:\n                lepton_event['pid'] = lookup_cc_partner(\n                    self.particle['pid'].get())\n\n            # units: GeV -> MeV\n            momentum_vector = [1000 * x for x in [t.pxl, t.pyl, t.pzl]]\n\n            lepton_event['momentum'] = convert_3vector_to_dict(momentum_vector)\n\n            lepton_event['position'] = position\n\n            next_events.append(lepton_event)\n\n            for j in range(t.nf):  # nf, number final hadronic states\n                hadron_event = {}\n                hadron_event['pid'] = t.pdgf[j]\n                hadron_event['position'] = position\n\n                # units: GeV -> MeV\n                momentum_vector = [1000 * x for x in [t.pxf[j], t.pyf[j], t.pzf[j]]]\n\n                hadron_event['momentum'] = convert_3vector_to_dict(momentum_vector)\n\n                next_events.append(hadron_event)\n\n            event_type = {}\n\n            event_type['vertex'] = position\n\n            to_save = {} # maps our names to Genie gst names\n            to_save['incoming_neutrino'] = 'neu'\n            to_save['neutrino_energy'] = 'Ev'\n            to_save['target_material'] = 'tgt'\n\n            for key, value in to_save.iteritems():\n                self.log.info('%s : %s' % (key, str(t.__getattr__(value))))\n                event_type[key] = t.__getattr__(value)\n\n            self.log.debug('Event type:')\n            for my_type in ['qel', 'res', 'dis', 'coh', 'dfr',\n                            'imd', 'nuel', 'em']:\n                if t.__getattr__(my_type) == 1:\n                    self.log.debug('\\t%s', my_type)\n                event_type[my_type] = t.__getattr__(my_type)\n\n            self.log.debug('Propogator:')\n            for prop in ['nc', 'cc']:\n                if t.__getattr__(prop) == 1:\n                    self.log.debug('\\t%s', prop)\n                event_type[prop] = t.__getattr__(prop)\n\n            yield next_events, event_type\n\n        f.Close()\n        os.remove(self.filenames[material])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat and return the specified exception information as a string.", "response": "def formatException(self, record):\n        \"\"\"\n        Format and return the specified exception information as a string.\n        :type record logging.LogRecord\n        :rtype: dict\n        \"\"\"\n        if record.exc_info is None:\n            return {}\n\n        (exc_type, exc_message, trace) = record.exc_info\n\n        return {\n            'e': {\n                'class': str(type(exc_type).__name__),  # ZeroDivisionError\n                'message': str(exc_message),  # integer division or modulo by zero\n                'trace': list(traceback.format_tb(trace)),\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, val):     \n\n      key, token, formatted_key, formatted_token = self.next_formatted_pair()\n\n      if self.has_key(key):\n         raise KeyInsertError(key)\n\n      if self.has_token(token):\n         raise TokenInsertError(token)\n\n      # Memcache is down or read-only\n\n      if not self._mc.add(formatted_key, (val, token)):\n         raise KeyInsertError(key, 'key could not be stored')\n\n      if not self._mc.add(formatted_token, key):\n         raise TokenInsertError(token, 'token could not be stored')\n\n      return Pair(key, token)", "response": "Inserts a value into the cache and returns a Pair object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pip_install(*args):\n    '''\n    Run pip install ...\n\n    Explicitly ignores user's config.\n    '''\n    pip_cmd = os.path.join(os.path.dirname(sys.executable), 'pip')\n    with set_env('PIP_CONFIG_FILE', os.devnull):\n        cmd = [pip_cmd, 'install'] + list(args)\n        print_command(cmd)\n        subprocess.call(cmd, stdout=sys.stdout, stderr=sys.stderr)", "response": "Run pip install ...\n\n    Explicitly ignores user's config."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef indent_text(text,\n                nb_tabs=0,\n                tab_str=\"  \",\n                linebreak_input=\"\\n\",\n                linebreak_output=\"\\n\",\n                wrap=False):\n    r\"\"\"Add tabs to each line of text.\n\n    :param text: the text to indent\n    :param nb_tabs: number of tabs to add\n    :param tab_str: type of tab (could be, for example \"\\t\", default: 2 spaces\n    :param linebreak_input: linebreak on input\n    :param linebreak_output: linebreak on output\n    :param wrap: wethever to apply smart text wrapping.\n        (by means of wrap_text_in_a_box)\n    :return: indented text as string\n    \"\"\"\n    if not wrap:\n        lines = text.split(linebreak_input)\n        tabs = nb_tabs * tab_str\n        output = \"\"\n        for line in lines:\n            output += tabs + line + linebreak_output\n        return output\n    else:\n        return wrap_text_in_a_box(body=text, style='no_border',\n                                  tab_str=tab_str, tab_num=nb_tabs)", "response": "r Indents text in a node - level page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wrap_text_in_a_box(body='', title='', style='double_star', **args):\n    def _wrap_row(row, max_col, break_long):\n        \"\"\"Wrap a single row.\"\"\"\n        spaces = _RE_BEGINNING_SPACES.match(row).group()\n        row = row[len(spaces):]\n        spaces = spaces.expandtabs()\n        return textwrap.wrap(row, initial_indent=spaces,\n                             subsequent_indent=spaces, width=max_col,\n                             break_long_words=break_long)\n\n    def _clean_newlines(text):\n        text = _RE_LONELY_NEWLINES.sub(' \\n', text)\n        return _RE_NEWLINES_CLEANER.sub(lambda x: x.group()[:-1], text)\n\n    body = unicode(body, 'utf-8')\n    title = unicode(title, 'utf-8')\n\n    astyle = dict(CFG_WRAP_TEXT_IN_A_BOX_STYLES['__DEFAULT'])\n    if style in CFG_WRAP_TEXT_IN_A_BOX_STYLES:\n        astyle.update(CFG_WRAP_TEXT_IN_A_BOX_STYLES[style])\n    astyle.update(args)\n\n    horiz_sep = astyle['horiz_sep']\n    border = astyle['border']\n    tab_str = astyle['tab_str'] * astyle['tab_num']\n    max_col = max(astyle['max_col'] -\n                  len(border[3]) - len(border[4]) - len(tab_str), 1)\n    min_col = astyle['min_col']\n    prefix = astyle['prefix']\n    suffix = astyle['suffix']\n    force_horiz = astyle['force_horiz']\n    break_long = astyle['break_long']\n\n    body = _clean_newlines(body)\n    tmp_rows = [_wrap_row(row, max_col, break_long)\n                for row in body.split('\\n')]\n    body_rows = []\n    for rows in tmp_rows:\n        if rows:\n            body_rows += rows\n        else:\n            body_rows.append('')\n    if not ''.join(body_rows).strip():\n        # Concrete empty body\n        body_rows = []\n\n    title = _clean_newlines(title)\n    tmp_rows = [_wrap_row(row, max_col, break_long)\n                for row in title.split('\\n')]\n    title_rows = []\n    for rows in tmp_rows:\n        if rows:\n            title_rows += rows\n        else:\n            title_rows.append('')\n    if not ''.join(title_rows).strip():\n        # Concrete empty title\n        title_rows = []\n\n    max_col = max([len(row) for row in body_rows + title_rows] + [min_col])\n\n    mid_top_border_len = max_col + \\\n        len(border[3]) + len(border[4]) - len(border[0]) - len(border[2])\n    mid_bottom_border_len = max_col + \\\n        len(border[3]) + len(border[4]) - len(border[5]) - len(border[7])\n    top_border = border[0] + \\\n        (border[1] * mid_top_border_len)[:mid_top_border_len] + border[2]\n    bottom_border = border[5] + \\\n        (border[6] * mid_bottom_border_len)[:mid_bottom_border_len] + \\\n        border[7]\n    if isinstance(horiz_sep, tuple) and len(horiz_sep) == 3:\n        horiz_line = horiz_sep[0] + \\\n            (horiz_sep[1] * (max_col + 2))[:(max_col + 2)] + horiz_sep[2]\n    else:\n        horiz_line = border[3] + (horiz_sep * max_col)[:max_col] + border[4]\n\n    title_rows = [tab_str + border[3] + row +\n                  ' ' * (max_col - len(row)) +\n                  border[4] for row in title_rows]\n    body_rows = [tab_str + border[3] + row +\n                 ' ' * (max_col - len(row)) + border[4] for row in body_rows]\n\n    ret = []\n    if top_border:\n        ret += [tab_str + top_border]\n    ret += title_rows\n    if title_rows or force_horiz:\n        ret += [tab_str + horiz_line]\n    ret += body_rows\n    if bottom_border:\n        ret += [tab_str + bottom_border]\n    return (prefix + '\\n'.join(ret) + suffix).encode('utf-8')", "response": "r Return a nicely formatted text box."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wait_for_user(msg=\"\"):\n    if '--yes-i-know' in sys.argv:\n        return\n    print(msg)\n    try:\n        answer = raw_input(\"Please confirm by typing 'Yes, I know!': \")\n    except KeyboardInterrupt:\n        print()\n        answer = ''\n    if answer != 'Yes, I know!':\n        sys.stderr.write(\"ERROR: Aborted.\\n\")\n        sys.exit(1)\n    return", "response": "Print MSG and a confirmation prompt."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to guess the minimum encoding of the given text using the given charsets.", "response": "def guess_minimum_encoding(text, charsets=('ascii', 'latin1', 'utf8')):\n    \"\"\"Try to guess the minimum charset that is able to represent.\n\n    Try to guess the minimum charset that is able to represent the given\n    text using the provided charsets. text is supposed to be encoded in utf8.\n    Returns (encoded_text, charset) where charset is the first charset\n    in the sequence being able to encode text.\n    Returns (text_in_utf8, 'utf8') in case no charset is able to encode text.\n\n    @note: If the input text is not in strict UTF-8, then replace any\n        non-UTF-8 chars inside it.\n    \"\"\"\n    text_in_unicode = text.decode('utf8', 'replace')\n    for charset in charsets:\n        try:\n            return (text_in_unicode.encode(charset), charset)\n        except (UnicodeEncodeError, UnicodeDecodeError):\n            pass\n    return (text_in_unicode.encode('utf8'), 'utf8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode_for_xml(text, wash=False, xml_version='1.0', quote=False):\n    text = text.replace('&', '&amp;')\n    text = text.replace('<', '&lt;')\n    if quote:\n        text = text.replace('\"', '&quot;')\n    if wash:\n        text = wash_for_xml(text, xml_version=xml_version)\n    return text", "response": "Encode special characters in a text so that it would be XML - compliant."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves any character which isn t a allowed characters for XML.", "response": "def wash_for_xml(text, xml_version='1.0'):\n    \"\"\"Remove any character which isn't a allowed characters for XML.\n\n    The allowed characters depends on the version\n    of XML.\n\n        - XML 1.0:\n            <http://www.w3.org/TR/REC-xml/#charsets>\n        - XML 1.1:\n            <http://www.w3.org/TR/xml11/#charsets>\n\n    :param text: input string to wash.\n    :param xml_version: version of the XML for which we wash the\n        input. Value for this parameter can be '1.0' or '1.1'\n    \"\"\"\n    if xml_version == '1.0':\n        return RE_ALLOWED_XML_1_0_CHARS.sub(\n            '', unicode(text, 'utf-8')).encode('utf-8')\n    else:\n        return RE_ALLOWED_XML_1_1_CHARS.sub(\n            '', unicode(text, 'utf-8')).encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a binary string with incorrect characters washed away.", "response": "def wash_for_utf8(text, correct=True):\n    \"\"\"Return UTF-8 encoded binary string with incorrect characters washed away.\n\n    :param text: input string to wash (can be either a binary or Unicode string)\n    :param correct: whether to correct bad characters or throw exception\n    \"\"\"\n    if isinstance(text, unicode):\n        return text.encode('utf-8')\n\n    errors = \"ignore\" if correct else \"strict\"\n    return text.decode(\"utf-8\", errors).encode(\"utf-8\", errors)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nice_number(number, thousands_separator=',', max_ndigits_after_dot=None):\n    if isinstance(number, float):\n        if max_ndigits_after_dot is not None:\n            number = round(number, max_ndigits_after_dot)\n        int_part, frac_part = str(number).split('.')\n        return '%s.%s' % (nice_number(int(int_part), thousands_separator),\n                          frac_part)\n    else:\n        chars_in = list(str(number))\n        number = len(chars_in)\n        chars_out = []\n        for i in range(0, number):\n            if i % 3 == 0 and i != 0:\n                chars_out.append(thousands_separator)\n            chars_out.append(chars_in[number - i - 1])\n        chars_out.reverse()\n        return ''.join(chars_out)", "response": "Return nicely printed number NUMBER in language LN using THOUSANDS_SEPARATOR character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove line breaks from input.", "response": "def remove_line_breaks(text):\n    \"\"\"Remove line breaks from input.\n\n    Including unicode 'line separator', 'paragraph separator',\n    and 'next line' characters.\n    \"\"\"\n    return unicode(text, 'utf-8').replace('\\f', '').replace('\\n', '') \\\n        .replace('\\r', '').replace(u'\\xe2\\x80\\xa8', '') \\\n        .replace(u'\\xe2\\x80\\xa9', '').replace(u'\\xc2\\x85', '') \\\n        .encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_to_unicode(text, default_encoding='utf-8'):\n    if not text:\n        return \"\"\n    try:\n        return text.decode(default_encoding)\n    except (UnicodeError, LookupError):\n        pass\n    detected_encoding = None\n    if CHARDET_AVAILABLE:\n        # We can use chardet to perform detection\n        res = chardet.detect(text)\n        if res['confidence'] >= 0.8:\n            detected_encoding = res['encoding']\n    if detected_encoding is None:\n        # No chardet detection, try to make a basic guess\n        dummy, detected_encoding = guess_minimum_encoding(text)\n    return text.decode(detected_encoding)", "response": "Decode input text into Unicode representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_latex2unicode(text, kb_file=None):\n    if kb_file is None:\n        kb_file = get_kb_filename()\n    # First decode input text to Unicode\n    try:\n        text = decode_to_unicode(text)\n    except UnicodeDecodeError:\n        text = unicode(wash_for_utf8(text))\n    # Load translation table, if required\n    if CFG_LATEX_UNICODE_TRANSLATION_CONST == {}:\n        _load_latex2unicode_constants(kb_file)\n    # Find all matches and replace text\n    for match in CFG_LATEX_UNICODE_TRANSLATION_CONST['regexp_obj'] \\\n            .finditer(text):\n        # If LaTeX style markers {, } and $ are before or after the\n        # matching text, it will replace those as well\n        text = re.sub(\"[\\{\\$]?%s[\\}\\$]?\" % (re.escape(match.group()),),\n                      CFG_LATEX_UNICODE_TRANSLATION_CONST[\n                          'table'][match.group()],\n                      text)\n    # Return Unicode representation of translated text\n    return text", "response": "Translate LaTeX text to Unicode using the given KB."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads LaTeX2Unicode translation table dictionary and regular expression object from KB to a global dictionary.", "response": "def _load_latex2unicode_constants(kb_file=None):\n    \"\"\"Load LaTeX2Unicode translation table dictionary.\n\n    Load LaTeX2Unicode translation table dictionary and regular\n    expression object from KB to a global dictionary.\n\n    :param kb_file: full path to file containing latex2unicode translations.\n                    Defaults to CFG_ETCDIR/bibconvert/KB/latex-to-unicode.kb\n    :type kb_file: string\n\n    :return: dict of type: {'regexp_obj': regexp match object,\n                            'table': dict of LaTeX -> Unicode mappings}\n    :rtype: dict\n    \"\"\"\n    if kb_file is None:\n        kb_file = get_kb_filename()\n\n    try:\n        data = open(kb_file)\n    except IOError:\n        # File not found or similar\n        sys.stderr.write(\n            \"\\nCould not open LaTeX to Unicode KB file. \"\n            \"Aborting translation.\\n\")\n        return CFG_LATEX_UNICODE_TRANSLATION_CONST\n    latex_symbols = []\n    translation_table = {}\n    for line in data:\n        # The file has form of latex|--|utf-8. First decode to Unicode.\n        line = line.decode('utf-8')\n        mapping = line.split('|--|')\n        translation_table[mapping[0].rstrip('\\n')] = mapping[1].rstrip('\\n')\n        latex_symbols.append(re.escape(mapping[0].rstrip('\\n')))\n    data.close()\n    CFG_LATEX_UNICODE_TRANSLATION_CONST[\n        'regexp_obj'] = re.compile(\"|\".join(latex_symbols))\n    CFG_LATEX_UNICODE_TRANSLATION_CONST['table'] = translation_table"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xml_entities_to_utf8(text, skip=('lt', 'gt', 'amp')):\n    def fixup(m):\n        text = m.group(0)\n        if text[:2] == \"&#\":\n            # character reference\n            try:\n                if text[:3] == \"&#x\":\n                    return unichr(int(text[3:-1], 16)).encode(\"utf-8\")\n                else:\n                    return unichr(int(text[2:-1])).encode(\"utf-8\")\n            except ValueError:\n                pass\n        else:\n            # named entity\n            if text[1:-1] not in skip:\n                try:\n                    text = unichr(\n                        html_entities.name2codepoint[text[1:-1]]) \\\n                        .encode(\"utf-8\")\n                except KeyError:\n                    pass\n        return text  # leave as is\n    return re.sub(\"&#?\\w+;\", fixup, text)", "response": "Translate HTML or XML character references to UTF - 8."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_accents(x):\n    x = re_latex_lowercase_a.sub(\"a\", x)\n    x = re_latex_lowercase_ae.sub(\"ae\", x)\n    x = re_latex_lowercase_oe.sub(\"oe\", x)\n    x = re_latex_lowercase_e.sub(\"e\", x)\n    x = re_latex_lowercase_i.sub(\"i\", x)\n    x = re_latex_lowercase_o.sub(\"o\", x)\n    x = re_latex_lowercase_u.sub(\"u\", x)\n    x = re_latex_lowercase_y.sub(\"x\", x)\n    x = re_latex_lowercase_c.sub(\"c\", x)\n    x = re_latex_lowercase_n.sub(\"n\", x)\n    x = re_latex_uppercase_a.sub(\"A\", x)\n    x = re_latex_uppercase_ae.sub(\"AE\", x)\n    x = re_latex_uppercase_oe.sub(\"OE\", x)\n    x = re_latex_uppercase_e.sub(\"E\", x)\n    x = re_latex_uppercase_i.sub(\"I\", x)\n    x = re_latex_uppercase_o.sub(\"O\", x)\n    x = re_latex_uppercase_u.sub(\"U\", x)\n    x = re_latex_uppercase_y.sub(\"Y\", x)\n    x = re_latex_uppercase_c.sub(\"C\", x)\n    x = re_latex_uppercase_n.sub(\"N\", x)\n\n    # convert input into Unicode string:\n    try:\n        y = unicode(x, \"utf-8\")\n    except Exception:\n        return x  # something went wrong, probably the input wasn't UTF-8\n    # asciify Latin-1 lowercase characters:\n    y = re_unicode_lowercase_a.sub(\"a\", y)\n    y = re_unicode_lowercase_ae.sub(\"ae\", y)\n    y = re_unicode_lowercase_oe.sub(\"oe\", y)\n    y = re_unicode_lowercase_e.sub(\"e\", y)\n    y = re_unicode_lowercase_i.sub(\"i\", y)\n    y = re_unicode_lowercase_o.sub(\"o\", y)\n    y = re_unicode_lowercase_u.sub(\"u\", y)\n    y = re_unicode_lowercase_y.sub(\"y\", y)\n    y = re_unicode_lowercase_c.sub(\"c\", y)\n    y = re_unicode_lowercase_n.sub(\"n\", y)\n    y = re_unicode_lowercase_ss.sub(\"ss\", y)\n    # asciify Latin-1 uppercase characters:\n    y = re_unicode_uppercase_a.sub(\"A\", y)\n    y = re_unicode_uppercase_ae.sub(\"AE\", y)\n    y = re_unicode_uppercase_oe.sub(\"OE\", y)\n    y = re_unicode_uppercase_e.sub(\"E\", y)\n    y = re_unicode_uppercase_i.sub(\"I\", y)\n    y = re_unicode_uppercase_o.sub(\"O\", y)\n    y = re_unicode_uppercase_u.sub(\"U\", y)\n    y = re_unicode_uppercase_y.sub(\"Y\", y)\n    y = re_unicode_uppercase_c.sub(\"C\", y)\n    y = re_unicode_uppercase_n.sub(\"N\", y)\n    # return UTF-8 representation of the Unicode string:\n    return y.encode(\"utf-8\")", "response": "u Strip accents in the input phrase X."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef slugify(text, delim=u'-'):\n    result = []\n    for word in _punct_re.split(text.lower()):\n        result.extend(unidecode(word).split())\n    return unicode(delim.join(result))", "response": "Generate an ASCII - only slug."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_diff(original, modified, prefix='', suffix='',\n              prefix_unchanged=' ',\n              suffix_unchanged='',\n              prefix_removed='-',\n              suffix_removed='',\n              prefix_added='+',\n              suffix_added=''):\n    \"\"\"Return the diff view between original and modified strings.\n\n    Function checks both arguments line by line and returns a string\n    with a:\n    - prefix_unchanged when line is common to both sequences\n    - prefix_removed when line is unique to sequence 1\n    - prefix_added when line is unique to sequence 2\n    and a corresponding suffix in each line\n    :param original: base string\n    :param modified: changed string\n    :param prefix: prefix of the output string\n    :param suffix: suffix of the output string\n    :param prefix_unchanged: prefix of the unchanged line\n    :param suffix_unchanged: suffix of the unchanged line\n    :param prefix_removed: prefix of the removed line\n    :param suffix_removed: suffix of the removed line\n    :param prefix_added: prefix of the added line\n    :param suffix_added: suffix of the added line\n\n    :return: string with the comparison of the records\n    :rtype: string\n    \"\"\"\n    import difflib\n    differ = difflib.Differ()\n\n    result = [prefix]\n    for line in differ.compare(modified.splitlines(), original.splitlines()):\n        if line[0] == ' ':\n            # Mark as unchanged\n            result.append(\n                prefix_unchanged + line[2:].strip() + suffix_unchanged)\n        elif line[0] == '-':\n            # Mark as removed\n            result.append(prefix_removed + line[2:].strip() + suffix_removed)\n        elif line[0] == '+':\n            # Mark as added/modified\n            result.append(prefix_added + line[2:].strip() + suffix_added)\n\n    result.append(suffix)\n    return '\\n'.join(result)", "response": "Return the diff between original and modified strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _copy_attr(self, module, varname, cls, attrname=None):\n\n        if not hasattr(module, varname):\n            raise RuntimeError(\"Variable '{}' not found\".format(varname))\n\n        obj = getattr(module, varname)\n\n        if not isinstance(obj, cls):\n            raise RuntimeError(\n                \"Expecting fobj to be a {}, not a '{}'\".format(cls.__name__, obj.__class__.__name__))\n\n        if attrname is None:\n            attrname = varname\n\n        setattr(self, attrname, obj)", "response": "Copy an attribute from module object to self. Raises if object not of expected class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __check_to_permit(self, entry_type, entry_filename):\n\n        rules = self.__filter_rules[entry_type]\n\n        # Should explicitly include?\n        for pattern in rules[fss.constants.FILTER_INCLUDE]:\n            if fnmatch.fnmatch(entry_filename, pattern):\n                _LOGGER_FILTER.debug(\"Entry explicitly INCLUDED: [%s] [%s] \"\n                                     \"[%s]\", \n                                     entry_type, pattern, entry_filename)\n\n                return True\n\n        # Should explicitly exclude?\n        for pattern in rules[fss.constants.FILTER_EXCLUDE]:\n            if fnmatch.fnmatch(entry_filename, pattern):\n                _LOGGER_FILTER.debug(\"Entry explicitly EXCLUDED: [%s] [%s] \"\n                                     \"[%s]\", \n                                     entry_type, pattern, entry_filename)\n\n                return False\n\n        # Implicitly include.\n\n        _LOGGER_FILTER.debug(\"Entry IMPLICITLY included: [%s] [%s]\", \n                             entry_type, entry_filename)\n\n        return True", "response": "Checks if the entry should be permitted by the filter rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_next_item(self):\n\n        # Try to pop something off the local input-queue.\n\n        try:\n            return self.__local_input_q.get(block=False)\n        except queue.Empty:\n            pass\n\n        # Try to pop something off the external input-queue.\n\n        return self.input_q.get(block=False)", "response": "Get the next item from the input - queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index_nearest(array, value):\r\n    idx = (np.abs(array-value)).argmin()\r\n    return idx", "response": "Returns the index of nearest value in array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef BSearch(a, x, lo=0, hi=None):\r\n    if len(a) == 0: return -1\r\n    hi = hi if hi is not None else len(a)\r\n    pos = bisect_left(a, x, lo, hi)\r\n    return pos if pos != hi and a[pos] == x else -1", "response": "Returns the index of x in a or - 1 if x is not in a."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef BSearchRound(a, x, lo=0, hi=None):\r\n    if len(a) == 0: return -1\r\n    hi = hi if hi is not None else len(a)\r\n    pos = bisect_left(a, x, lo, hi)\r\n\r\n    if pos >= hi:\r\n        return hi - 1\r\n    elif a[pos] == x or pos == lo:\r\n        return pos\r\n    else:\r\n        return pos - 1 if x - a[pos - 1] <= a[pos] - x else pos", "response": "Returns index of a that is closest to x."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef BSearchCeil(a, x, lo=0, hi=None):\r\n    if len(a) == 0: return -1\r\n    hi = hi if hi is not None else len(a)\r\n    pos = bisect_left(a, x, lo, hi)\r\n    return pos if pos < hi else -1", "response": "Returns the index of the first element in a that is greater than or equal to x."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the highest i such as a [ lo hi ) < x.", "response": "def BSearchFloor(a, x, lo=0, hi=None):\r\n    \"\"\"Returns highest i such as a[i] <= x, or -1 if x < all elements in a\r\n\r\n    So, if x is in between two elements in a, this function will return the\r\n    index of the lower element, hence \"Floor\".\r\n\r\n    Arguments:\r\n      a -- ordered numeric sequence\r\n      x -- element to search within a\r\n      lo -- lowest index to consider in search\r\n      hi -- highest index to consider in search\"\"\"\r\n    if len(a) == 0: return -1\r\n    hi = hi if hi is not None else len(a)\r\n    pos = bisect_left(a, x, lo, hi)\r\n    return pos - 1 if pos >= hi \\\r\n        else (pos if x == a[pos] else (pos - 1 if pos > lo else -1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef FindNotNaNBackwards(x, i):\r\n    while i >= 0:\r\n        if not np.isnan(x[i]):\r\n            return i\r\n        i -= 1\r\n    return -1", "response": "Returns the position of the first non - NaN element in x which is not NaN."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current World Census data.", "response": "def census(self, *scales):\n        \"\"\"Current World Census data.\n\n        By default returns data on today's featured World Census\n        scale, use arguments to get results on specific scales.  In\n        order to request data on all scales at once you can do\n        ``x.census(*range(81))``.\n\n        Parameters\n        ----------\n        scales : int\n            World Census scales, integers between 0 and 85 inclusive.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of a list of :class:`CensusScaleCurrent`\n        \"\"\"\n        params = {'mode': 'score+rank+rrank+prank+prrank'}\n        if scales:\n            params['scale'] = '+'.join(str(x) for x in scales)\n\n        @api_query('census', **params)\n        async def result(_, root):\n            return [\n                CensusScaleCurrent(scale_elem)\n                for scale_elem in root.find('CENSUS')\n            ]\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of history World Census records for this NationStates Census record.", "response": "def censushistory(self, *scales):\n        \"\"\"Historical World Census data.\n\n        Was split into its own method for the sake of simplicity.\n\n        By default returns data on today's featured World Census\n        scale, use arguments to get results on specific scales.  In\n        order to request data on all scales at once you can do\n        ``x.censushistory(*range(81))``.\n\n        Returns data for the entire length of history NationStates\n        stores.  There is no way to override that.\n\n        Parameters\n        ----------\n        scales : int\n            World Census scales, integers between 0 and 85 inclusive.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of a list of :class:`CensusScaleHistory`\n        \"\"\"\n        params = {'mode': 'history'}\n        if scales:\n            params['scale'] = '+'.join(str(x) for x in scales)\n\n        @api_query('census', **params)\n        async def result(_, root):\n            return [\n                CensusScaleHistory(scale_elem)\n                for scale_elem in root.find('CENSUS')\n            ]\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def censusranks(self, scale):\n        order = count(1)\n        for offset in count(1, 20):\n            census_ranks = await self._get_censusranks(\n                scale=scale, start=offset)\n            for census_rank in census_ranks:\n                assert census_rank.rank == next(order)\n                yield census_rank\n            if len(census_ranks) < 20:\n                break", "response": "Iterate through nations ranked on the World Census scale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecompressing and deserialize string into Python object via marshal.", "response": "def loads(astring):\n        \"\"\"Decompress and deserialize string into Python object via marshal.\"\"\"\n        try:\n            return marshal.loads(zlib.decompress(astring))\n        except zlib.error as e:\n            raise SerializerError(\n                'Cannot decompress object (\"{}\")'.format(str(e))\n            )\n        except Exception as e:\n            # marshal module does not provide a proper Exception model\n            raise SerializerError(\n                'Cannot restore object (\"{}\")'.format(str(e))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loads(astring):\n        try:\n            return pickle.loads(zlib.decompress(astring))\n        except zlib.error as e:\n            raise SerializerError(\n                'Cannot decompress object (\"{}\")'.format(str(e))\n            )\n        except pickle.UnpicklingError as e:\n            raise SerializerError(\n                'Cannot restore object (\"{}\")'.format(str(e))\n            )", "response": "Decompress and deserialize string into Python object via pickle."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecompress and deserialize string into a Python object via pickle.", "response": "def loads(astring):\n        \"\"\"Decompress and deserialize string into a Python object via pickle.\"\"\"\n        try:\n            return pickle.loads(lzma.decompress(astring))\n        except lzma.LZMAError as e:\n            raise SerializerError(\n                'Cannot decompress object (\"{}\")'.format(str(e))\n            )\n        except pickle.UnpicklingError as e:\n            raise SerializerError(\n                'Cannot restore object (\"{}\")'.format(str(e))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self, path_expression, mode=UXP, values=None, ifunc=lambda x: x):\n        # keys = path_expression if isinstance(path_expression, six.string_types) else path_expression[-1]\n\n        path_and_value_list = iterutils.search(\n            self.data,\n            path_expression=path_expression,\n            required_values=values,\n            exact=(mode[1] == \"x\"))\n\n        return self.__return_value(path_and_value_list, mode, ifunc)", "response": "search for the given path expression in the data set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall during processing of source data", "response": "def __visit_index_path(self, src, p, k, v):\n        \"\"\"\n            Called during processing of source data\n        \"\"\"\n        cp = p + (k,)\n        self.path_index[cp] = self.indexed_obj_factory(p, k, v, self.path_index.get(cp))\n        if cp in self.path_index:\n            # if self.path_index[cp].assert_val_equals(v):\n            #     raise ValueError('unexpected value change at path_index[{}]'.format(cp))\n            self.path_index[cp].add_src(src)\n        else:\n            self.path_index[cp] = Flobject(val=v, path=cp, srcs=set([src]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn path to default data directory for the given module and class.", "response": "def get_default_data_path(*args, module=None, class_=None, flag_raise=True):\n    \"\"\"\n    Returns path to default data directory\n\n    Arguments 'module' and 'class' give the chance to return path relative to package other than\n    f311.filetypes\n\n    Args:\n        module: Python module object. It is expected that this module has a sub-subdirectory\n                named 'data/default'\n        class_: Python class object to extract path information from. If this argument is used,\n                it will be expected that the class \"root\" package will have a sub-subdirectory\n                named 'data/default'. Argument 'class_' **has precedence over argument 'module'**\n        flag_raise: raises error if file is not found. This can be turned off for whichever purpose\n    \"\"\"\n    if module is None:\n        module = __get_filetypes_module()\n\n    if class_ is not None:\n        pkgname =  class_.__module__\n        mseq = pkgname.split(\".\")\n        if len(mseq) < 2 or mseq[1] != \"filetypes\":\n            raise ValueError(\"Invalid module name for class '{}': '{}' \"\n                             \"(must be '(...).filetypes[.(...)]')\".format(class_.__name__, pkgname))\n        # gets \"root\" module object\n        # For example, if pkgname is \"pyfant.filetypes.filemain\", module below will be\n        # the \"pyfant\" module object\n        module = sys.modules[mseq[0]]\n    module_path = os.path.split(module.__file__)[0]\n    p = os.path.abspath(os.path.join(module_path, \"data\", \"default\", *args))\n\n    if flag_raise:\n        if not os.path.isfile(p):\n            raise RuntimeError(\"Path not found '{}'\".format(p))\n\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_default_data_file(filename, module=None):\n    if module is None:\n        module = __get_filetypes_module()\n    fullpath = get_default_data_path(filename, module=module)\n    shutil.copy(fullpath, \".\")", "response": "Copies file from default data directory to local directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_display(self):\n        self.display_num = 2\n        while os.path.isdir(XVFB_PATH % (self.display_num,)):\n            self.display_num += 1", "response": "Find a usable display which doesn t have an existing Xvfb file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the attribute of an element.", "response": "def getattr(self, key, default=None, callback=None):\n        u\"\"\"Getting the attribute of an element.\n\n        >>> xml = etree.Element('root')\n        >>> xml.text = 'text'\n        >>> Node(xml).getattr('text')\n        'text'\n        >>> Node(xml).getattr('text', callback=str.upper)\n        'TEXT'\n        >>> Node(xml).getattr('wrong_attr', default='default')\n        'default'\n        \"\"\"\n        value = self._xml.text if key == 'text' else self._xml.get(key, default)\n        return callback(value) if callback else value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, default=None, callback=None):\n        value = self._xml.text if self._xml.text else default\n        return callback(value) if callback else value", "response": "u \"\"\"Returns leaf s value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_str(self, pretty_print=False, encoding=None, **kw):\n        if kw.get('without_comments') and not kw.get('method'):\n            kw.pop('without_comments')\n            kw['method'] = 'c14n'\n            kw['with_comments'] = False\n        return etree.tostring(\n            self._xml,\n            pretty_print=pretty_print,\n            encoding=encoding,\n            **kw\n        )", "response": "u Converts a node with all of its children to a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, **kwargs):\n        for key, value in kwargs.items():\n            helper = helpers.CAST_DICT.get(type(value), str)\n            tag = self._get_aliases().get(key, key)\n\n            elements = list(self._xml.iterchildren(tag=tag))\n            if elements:\n                for element in elements:\n                    element.text = helper(value)\n            else:\n                element = etree.Element(key)\n                element.text = helper(value)\n                self._xml.append(element)\n                self._aliases = None", "response": "u Updates or creates a new simple node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sget(self, path, default=NONE_NODE):\n        attrs = str(path).split(\".\")\n        text_or_attr = None\n        last_attr = attrs[-1]\n        # Case of getting text or attribute\n        if last_attr == '#text' or last_attr.startswith('@'):\n            # #text => text, @attr => attr\n            text_or_attr = last_attr[1:]\n            attrs = attrs[:-1]\n            # When getting #text and @attr we want default value to be None.\n            if default is NONE_NODE:\n                default = None\n\n        my_object = self\n        for attr in attrs:\n            try:\n                if isinstance(my_object, (list, tuple)) and re.match('^\\-?\\d+$', attr):\n                    my_object_next = my_object[int(attr)]\n                else:\n                    my_object_next = getattr(my_object, attr)\n                my_object = my_object_next\n            except (AttributeError, KeyError, IndexError):\n                return default\n\n        # Return #text or @attr\n        if text_or_attr:\n            try:\n                return my_object.getattr(text_or_attr)\n            except AttributeError:\n                # myObject can be a list.\n                return None\n        else:\n            return my_object", "response": "u Returns a value from a node in the mappet at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, tag, value):\n        child_tags = {child.tag for child in self._xml}\n\n        if tag in child_tags:\n            raise KeyError('Node {} already exists in XML tree.'.format(tag))\n\n        self.set(tag, value)", "response": "Create a node with the given tag and value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, name, value):\n        try:\n            # Searches for a node to assign to.\n            element = next(self._xml.iterchildren(tag=name))\n        except StopIteration:\n            # There is no such node in the XML tree. We create a new one\n            # with current root as parent (self._xml).\n            element = etree.SubElement(self._xml, name)\n\n        if isinstance(value, dict):\n            self.assign_dict(element, value)\n        elif isinstance(value, (list, tuple, set)):\n            self.assign_sequence_or_set(element, value)\n        else:\n            # Literal value.\n            self.assign_literal(element, value)\n\n        # Clear the aliases.\n        self._aliases = None", "response": "Assigns a new XML structure to the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nassigns a Python dict to a lxml node.", "response": "def assign_dict(self, node, xml_dict):\n        \"\"\"Assigns a Python dict to a ``lxml`` node.\n\n        :param node: A node to assign the dict to.\n        :param xml_dict: The dict with attributes/children to use.\n        \"\"\"\n        new_node = etree.Element(node.tag)\n\n        # Replaces the previous node with the new one\n        self._xml.replace(node, new_node)\n\n        # Copies #text and @attrs from the xml_dict\n        helpers.dict_to_etree(xml_dict, new_node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the lxml object to a dict.", "response": "def to_dict(self, **kw):\n        u\"\"\"Converts the lxml object to a dict.\n\n        possible kwargs:\n            without_comments: bool\n        \"\"\"\n        _, value = helpers.etree_to_dict(self._xml, **kw).popitem()\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_last_modified_date(*args, **kwargs):\n    try:\n        latest_note = Note.objects.latest()\n        latest_release = Release.objects.latest()\n    except ObjectDoesNotExist:\n        return None\n\n    return max(latest_note.modified, latest_release.modified)", "response": "Returns the date of the last modified Note or Release."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if sys path hints the install is running on ios", "response": "def using_ios_stash():\n    ''' returns true if sys path hints the install is running on ios '''\n    print('detected install path:')\n    print(os.path.dirname(__file__))\n    module_names = set(sys.modules.keys())\n    return 'stash' in module_names or 'stash.system' in module_names"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npad an image to the specified size.", "response": "def pad_bin_image_to_shape(image, shape):\r\n    \"\"\"\r\n    Padd image to size :shape: with zeros\r\n    \"\"\"\r\n    h, w = shape\r\n    ih, iw = image.shape\r\n    assert ih <= h\r\n    assert iw <= w\r\n    if iw < w:\r\n        result = numpy.hstack((image, numpy.zeros((ih, w - iw), bool)))\r\n    else:\r\n        result = image\r\n    if ih < h:\r\n        result = numpy.vstack((result, numpy.zeros((h - ih, w), bool)))\r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef best_convolution(bin_template, bin_image,\r\n                     tollerance=0.5, overlap_table=OVERLAP_TABLE):\r\n    \"\"\"\r\n    Selects and applies the best convolution method to find template in image.\r\n\r\n    Returns a list of matches in (width, height, x offset, y offset)\r\n    format (where the x and y offsets are from the top left corner).\r\n\r\n    As the images are binary images, we can utilise the extra bit space in the\r\n    float64's by cutting the image into tiles and stacking them into variable\r\n    grayscale values.\r\n\r\n    This allows converting a sparse binary image into a dense(r) grayscale one.\r\n    \"\"\"\r\n\r\n    template_sum = numpy.count_nonzero(bin_template)\r\n    th, tw = bin_template.shape\r\n    ih, iw = bin_image.shape\r\n    if template_sum == 0 or th == 0 or tw == 0:\r\n        # If we don't have a template\r\n        return []\r\n    if th > ih or tw > iw:\r\n        # If the template is bigger than the image\r\n        return []\r\n\r\n    # How many cells can we split the image into?\r\n    max_vert_cells = ih // th\r\n    max_hor_cells = iw // th\r\n\r\n    # Try to work out how many times we can stack the image\r\n    usable_factors = {n: factors for n, factors in overlap_table.iteritems()\r\n                      if ((template_sum + 1) ** (n)) < ACCURACY_LIMIT}\r\n    overlap_options = [(factor, n // factor)\r\n                       for n, factors in usable_factors.iteritems()\r\n                       for factor in factors\r\n                       if (factor <= max_vert_cells and\r\n                           n // factor <= max_hor_cells)]\r\n    if not overlap_options:\r\n        # We can't stack the image\r\n        return convolution(bin_template, bin_image, tollerance=tollerance)\r\n    best_overlap = min(overlap_options,\r\n                       key=lambda x: ((ih // x[0] + th) * (iw // x[1] + tw)))\r\n    return overlapped_convolution(bin_template, bin_image,\r\n                                  tollerance=tollerance, splits=best_overlap)", "response": "Selects and applies a best convolution method to find template in image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef overlapped_convolution(bin_template, bin_image,\r\n                           tollerance=0.5, splits=(4, 2)):\r\n    \"\"\"\r\n    As each of these images are hold only binary values, and RFFT2 works on\r\n    float64 greyscale values, we can make the convolution more efficient by\r\n    breaking the image up into :splits: sectons. Each one of these sections\r\n    then has its greyscale value adjusted and then stacked.\r\n\r\n    We then apply the convolution to this 'stack' of images, and adjust the\r\n    resultant position matches.\r\n    \"\"\"\r\n    th, tw = bin_template.shape\r\n    ih, iw = bin_image.shape\r\n    hs, ws = splits\r\n    h = ih // hs\r\n    w = iw // ws\r\n    count = numpy.count_nonzero(bin_template)\r\n    assert count > 0\r\n    assert h >= th\r\n    assert w >= tw\r\n\r\n    yoffset = [(i * h, ((i + 1) * h) + (th - 1)) for i in range(hs)]\r\n    xoffset = [(i * w, ((i + 1) * w) + (tw - 1)) for i in range(ws)]\r\n\r\n    # image_stacks is Origin (x,y), array, z (height in stack)\r\n    image_stacks = [((x1, y1), bin_image[y1:y2, x1:x2], float((count + 1) ** (num)))\r\n                    for num, (x1, x2, y1, y2) in\r\n                    enumerate((x1, x2, y1, y2) for (x1, x2)\r\n                              in xoffset for (y1, y2) in yoffset)]\r\n\r\n    pad_h = max(i.shape[0] for _, i, _ in image_stacks)\r\n    pad_w = max(i.shape[1] for _, i, _ in image_stacks)\r\n\r\n    # rfft metrics must be an even size - why ... maths?\r\n    pad_w += pad_w % 2\r\n    pad_h += pad_h % 2\r\n\r\n    overlapped_image = sum_2d_images(pad_bin_image_to_shape(i, (pad_h, pad_w))\r\n                                     * num for _, i, num in image_stacks)\r\n    #print \"Overlap splits %r, Image Size (%d,%d),\r\n    #Overlapped Size (%d,%d)\"  % (splits,iw,ih,pad_w,pad_h)\r\n\r\n    # Calculate the convolution of the FFT's of the overlapped image & template\r\n    convolution_freqs = (rfft2(overlapped_image) *\r\n                         rfft2(bin_template[::-1, ::-1],\r\n                               overlapped_image.shape))\r\n\r\n    # Reverse the FFT to find the result overlapped image\r\n    convolution_image = irfft2(convolution_freqs)\r\n    # At this point, the maximum point in convolution_image should be the\r\n    # bottom right (why?) of the area of greatest match\r\n\r\n    results = set()\r\n    for (x, y), _, num in image_stacks[::-1]:\r\n        test = convolution_image / num\r\n        filtered = ((test >= (count - tollerance)) &\r\n                   (test <= (count + tollerance)))\r\n        match_points = numpy.transpose(numpy.nonzero(filtered))  # bottom right\r\n        for (fy, fx) in match_points:\r\n            if fx < (tw - 1) or fy < (th - 1):\r\n                continue\r\n            results.add((x + fx - (tw - 1), y + fy - (th - 1)))\r\n        convolution_image %= num\r\n    return list(results)", "response": "This function is used to make a convolution of two images into a single image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of best to worst binary splits along the x and y axis.", "response": "def get_partition_scores(image, min_w=1, min_h=1):\r\n    \"\"\"Return list of best to worst binary splits along the x and y axis.\r\n\r\n    \"\"\"\r\n    h, w = image.shape[:2]\r\n    if w == 0 or h == 0:\r\n        return []\r\n    area = h * w\r\n    cnz = numpy.count_nonzero\r\n    total = cnz(image)\r\n    if total == 0 or area == total:\r\n        return []\r\n    if h < min_h * 2:\r\n        y_c = []\r\n    else:\r\n        y_c = [(-abs((count / ((h - y) * w)) - ((total - count) / (y * w))),\r\n                y, 0)\r\n               for count, y in ((cnz(image[y:]), y)\r\n                                for y in range(min_h, image.shape[0] - min_h))]\r\n    if w < min_w * 2:\r\n        x_c = []\r\n    else:\r\n        x_c = [(-abs((count / (h * (w - x))) - ((total - count) / (h * x))),\r\n                x, 1)\r\n               for count, x in ((cnz(image[:, x:]), x)\r\n                                for x in range(min_w, image.shape[1] - min_w))]\r\n    return sorted(x_c + y_c)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a bsp of pos axis and nodes where leaf nodes are found at that depth.", "response": "def binary_partition_image(image, min_w=1, min_h=1, depth=0, max_depth=-1):\r\n    \"\"\"Return a bsp of [pos, axis, [before_node, after_node]] nodes where leaf\r\n    nodes == None.\r\n\r\n    If max_depth < 0 this function will continue until all leaf nodes have\r\n    been found, if it is >= 0 leaf nodes will be created at that depth.\r\n\r\n    min_w and min_h are the minimum width or height of a partition.\r\n\r\n    \"\"\"\r\n    if max_depth >= 0 and depth >= max_depth:\r\n        return None\r\n    partition = get_best_partition(image, min_w=min_w, min_h=min_h)\r\n    if partition is None:\r\n        return None\r\n    pos, axis = partition\r\n    if axis == 0:\r\n        p1 = binary_partition_image(\r\n            image[pos:], min_w, min_h, depth + 1, max_depth)\r\n        p2 = binary_partition_image(\r\n            image[:pos], min_w, min_h, depth + 1, max_depth)\r\n    elif axis == 1:\r\n        p1 = binary_partition_image(\r\n            image[:, pos:], min_w, min_h, depth + 1, max_depth)\r\n        p2 = binary_partition_image(\r\n            image[:, :pos], min_w, min_h, depth + 1, max_depth)\r\n    return [pos, axis, [p1, p2]]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a threshold where the fraction of pixels above the threshold is closest to the desired density.", "response": "def find_threshold_near_density(img, density, low=0, high=255):\r\n    \"\"\"Find a threshold where the fraction of pixels above the threshold\r\n    is closest to density where density is (count of pixels above\r\n    threshold / count of pixels).\r\n\r\n    The highest threshold closest to the desired density will be returned.\r\n\r\n    Use low and high to exclude undesirable thresholds.\r\n\r\n    :param img: target image\r\n    :type img: 2d :class:`numpy.ndarray`\r\n    :param density: target density\r\n    :type density: float between 0.0 and 1.0\r\n    :param low: min threshold to test\r\n    :type low: ubyte\r\n    :param migh: max threshold to test\r\n    :type low: ubyte\r\n    :rtype: ubyte\r\n\r\n    \"\"\"\r\n    size = numpy.size(img)\r\n    densities = []\r\n    last_t = None\r\n    while True:\r\n        t = ((high - low) // 2) + low\r\n        if t == last_t:\r\n            densities.sort(key=lambda x: (abs(x[0] - density), 256 - x[1]))\r\n            return densities[0][1]\r\n        else:\r\n            last_t = t\r\n        d = numpy.count_nonzero(img > t) / size\r\n        densities.append((d, t))\r\n        if d < density:\r\n            high = t\r\n        elif d >= density:  # search away from low\r\n            low = t"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_greys_using_image(image, target):\r\n    maskbase = numpy.array(range(256), dtype=numpy.uint8)\r\n    mask = numpy.where(numpy.in1d(maskbase, numpy.unique(image)), maskbase, 0)\r\n    return mask[target]", "response": "Filter out any values in target not in image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a schema view which renders Swagger.", "response": "def get_swagger_view(title=None, url=None, generator_class=SchemaGenerator):\n    \"\"\"\n    Returns schema view which renders Swagger/OpenAPI.\n    \"\"\"\n    return schemas.get_schema_view(\n        title=title,\n        url=url,\n        renderer_classes=[\n            CoreJSONRenderer,\n            renderers.OpenAPIRenderer,\n            renderers.SwaggerUIRenderer],\n        generator_class=generator_class)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __init_defaults(self, config):\n\n        provider = self.__provider\n\n        if provider == 'sqlite':\n            config.setdefault('dbname', ':memory:')\n            config.setdefault('create_db',  True)\n        elif provider == 'mysql':\n            config.setdefault('port', 3306)\n            config.setdefault('charset', 'utf8')\n        elif provider == 'postgres':\n            config.setdefault('port', 5432)\n        elif provider == 'oracle':\n            config.setdefault('port', 1521)\n        else:\n            raise ValueError('Unsupported provider \"{}\"'.format(provider))\n\n        if provider != 'sqlite':\n            config.setdefault('host', 'localhost')\n            config.setdefault('user', None)\n            config.setdefault('password', None)\n            config.setdefault('dbname', None)", "response": "Initializes the default connection settings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload(self, file_descriptor, settings):\n        multipart_form_data = {\n            'file': file_descriptor\n        }\n        params = {\"settings\": json.dumps(settings)}\n        dr = self.__app.native_api_call('media', 'upload', params, self.__options, True, multipart_form_data, False, http_path=\"/api/meta/v1/\", http_method='POST',\n                                        connect_timeout_sec=60 * 10)\n        return json.loads(dr.text)", "response": "\u0412\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442 \u0444\u0430\u0439\u043b \u0432 \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0439 \u0434\u0435\u0441\u043a\u0440\u0438\u043f\u0442\u043e\u0440\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download(self, media_id, as_stream=False):\n        response = self.__app.native_api_call('media', 'd/' + media_id, {}, self.__options, False, None, as_stream, http_path=\"/api/meta/v1/\", http_method='GET')\n        return response", "response": "Downloads the metadata for a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef info(self, media_id):\n        dr = self.__app.native_api_call('media', 'i/' + media_id, {}, self.__options, False, None, False, http_path=\"/api/meta/v1/\", http_method='GET')\n        return json.loads(dr.text)", "response": "\u041f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043f\u043e \u0444\u0430\u0439\u043b\u0443\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_order(cls, order, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_order_with_http_info(order, **kwargs)\n        else:\n            (data) = cls._create_order_with_http_info(order, **kwargs)\n            return data", "response": "Create a new Order\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_order_by_id(cls, order_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_order_by_id_with_http_info(order_id, **kwargs)\n        else:\n            (data) = cls._delete_order_by_id_with_http_info(order_id, **kwargs)\n            return data", "response": "Delete an order by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds Order by ID Return single instance of Order by its ID.", "response": "def get_order_by_id(cls, order_id, **kwargs):\n        \"\"\"Find Order\n\n        Return single instance of Order by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_order_by_id(order_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_id: ID of order to return (required)\n        :return: Order\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_order_by_id_with_http_info(order_id, **kwargs)\n        else:\n            (data) = cls._get_order_by_id_with_http_info(order_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_orders(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_orders_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_orders_with_http_info(**kwargs)\n            return data", "response": "List Orders\nAttributeNames Returns a list of Orders\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace all attributes of order with the same ID", "response": "def replace_order_by_id(cls, order_id, order, **kwargs):\n        \"\"\"Replace Order\n\n        Replace all attributes of Order\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_order_by_id(order_id, order, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_id: ID of order to replace (required)\n        :param Order order: Attributes of order to replace (required)\n        :return: Order\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_order_by_id_with_http_info(order_id, order, **kwargs)\n        else:\n            (data) = cls._replace_order_by_id_with_http_info(order_id, order, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating attributes of an order", "response": "def update_order_by_id(cls, order_id, order, **kwargs):\n        \"\"\"Update Order\n\n        Update attributes of Order\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_order_by_id(order_id, order, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_id: ID of order to update. (required)\n        :param Order order: Attributes of order to update. (required)\n        :return: Order\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_order_by_id_with_http_info(order_id, order, **kwargs)\n        else:\n            (data) = cls._update_order_by_id_with_http_info(order_id, order, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def newnations(self, root):\n        return [aionationstates.Nation(n)\n                for n in root.find('NEWNATIONS').text.split(',')]", "response": "Most recently founded nations from newest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def regions(self, root):\n        return [aionationstates.Region(r)\n                for r in root.find('REGIONS').text.split(',')]", "response": "List all the regions in the Aionation API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef regionsbytag(self, *tags):\n        if len(tags) > 10:\n            raise ValueError('You can specify up to 10 tags')\n        if not tags:\n            raise ValueError('No tags specified')\n\n        # We don't check for invalid tags here because the behaviour is\n        # fairly intuitive - quering for a non-existent tag returns no\n        # regions, excluding it returns all of them.\n        @api_query('regionsbytag', tags=','.join(tags))\n        async def result(_, root):\n            text = root.find('REGIONS').text\n            return ([aionationstates.Region(r) for r in text.split(',')]\n                    if text else [])\n        return result(self)", "response": "Returns a list of all regions with any of the named tags."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a specific dispatch by id.", "response": "def dispatch(self, id):\n        \"\"\"Dispatch by id.\n\n        Parameters\n        ----------\n        id : int\n            Dispatch id.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of :class:`Dispatch`\n\n        Raises\n        ------\n        :class:`NotFound`\n            If a dispatch with the requested id doesn't exist.\n        \"\"\"\n        @api_query('dispatch', dispatchid=str(id))\n        async def result(_, root):\n            elem = root.find('DISPATCH')\n            if not elem:\n                raise NotFound(f'No dispatch found with id {id}')\n            return Dispatch(elem)\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind dispatches by certain criteria.", "response": "def dispatchlist(self, *, author=None, category=None,\n                     subcategory=None, sort='new'):\n        \"\"\"Find dispatches by certain criteria.\n\n        Parameters\n        ----------\n        author : str\n            Name of the nation authoring the dispatch.\n        category : str\n            Dispatch's primary category.\n        subcategory : str\n            Dispatch's secondary category.\n        sort : str\n            Sort order, 'new' or 'best'.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of a list of :class:`DispatchThumbnail`\n        \"\"\"\n        params = {'sort': sort}\n        if author:\n            params['dispatchauthor'] = author\n        # Here we do need to ensure that our categories are valid, cause\n        # NS just ignores the categories it doesn't recognise and returns\n        # whatever it feels like.\n        if category and subcategory:\n            if (category not in dispatch_categories or\n                    subcategory not in dispatch_categories[category]):\n                raise ValueError('Invalid category/subcategory')\n            params['dispatchcategory'] = f'{category}:{subcategory}'\n        elif category:\n            if category not in dispatch_categories:\n                raise ValueError('Invalid category')\n            params['dispatchcategory'] = category\n        else:\n            raise ValueError('Cannot request subcategory without category')\n\n        @api_query('dispatchlist', **params)\n        async def result(_, root):\n            return [\n                DispatchThumbnail._from_elem(elem)\n                for elem in root.find('DISPATCHLIST')\n            ]\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a poll with a given id.", "response": "def poll(self, id):\n        \"\"\"Poll with a given id.\n\n        Parameters\n        ----------\n        id : int\n            Poll id.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of :class:`Poll`\n\n        Raises\n        ------\n        :class:`NotFound`\n            If a poll with the requested id doesn't exist.\n        \"\"\"\n        @api_query('poll', pollid=str(id))\n        async def result(_, root):\n            elem = root.find('POLL')\n            if not elem:\n                raise NotFound(f'No poll found with id {id}')\n            return Poll(elem)\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting data about banners by their ids.", "response": "def banner(self, *ids, _expand_macros=None):\n        \"\"\"Get data about banners by their ids.\n\n        Macros in banners' names and descriptions are not expanded.\n\n        Parameters\n        ----------\n        *ids : str\n           Banner ids.\n\n        Returns\n        -------\n        an :class:`ApiQuery` of a list of :class:`Banner`\n\n        Raises\n        ------\n        :class:`NotFound`\n            If any of the provided ids is invalid.\n        \"\"\"\n        async def noop(s):\n            return s\n\n        _expand_macros = _expand_macros or noop\n\n        @api_query('banner', banner=','.join(ids))\n        async def result(_, root):\n            banners = [await Banner(elem, _expand_macros)\n                       for elem in root.find('BANNERS')]\n            if not len(banners) == len(ids):\n                raise NotFound('one of the banner ids provided is invalid')\n            return banners\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send_telegram(self, *, client_key, telegram_id,\n                            telegram_key, recepient):\n        \"\"\"A basic interface to the Telegrams API.\n\n        Parameters\n        ----------\n        client_key : str\n            Telegrams API Client Key.\n        telegram_id : int or str\n            Telegram id.\n        telegram_key : str\n            Telegram key.\n        recepient : str\n            Name of the nation you want to telegram.\n\n        Returns\n        -------\n        an awaitable\n        \"\"\"\n        params = {\n            'a': 'sendTG',\n            'client': client_key,\n            'tgid': str(telegram_id),\n            'key': telegram_key,\n            'to': recepient\n        }\n        return await self._call_api(params)", "response": "Send a Telegram to a specific user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates through all happenings in the current locale.", "response": "async def happenings(self, *, nations=None, regions=None, filters=None,\n                         beforeid=None, beforetime=None):\n        \"\"\"Iterate through happenings from newest to oldest.\n\n        Parameters\n        ----------\n        nations : iterable of str\n            Nations happenings of which will be requested.  Cannot be\n            specified at the same time with ``regions``.\n        regions : iterable of str\n            Regions happenings of which will be requested.  Cannot be\n            specified at the same time with ``nations``.\n        filters : iterable of str\n            Categories to request happenings by.  Available filters\n            are: ``law``, ``change``, ``dispatch``, ``rmb``,\n            ``embassy``, ``eject``, ``admin``, ``move``, ``founding``,\n            ``cte``, ``vote``, ``resolution``, ``member``, and ``endo``.\n        beforeid : int\n            Only request happenings before this id.\n        beforetime : :class:`datetime.datetime`\n            Only request happenings that were emitted before this\n            moment.\n\n        Returns\n        -------\n        an asynchronous iterator yielding any of the classes from \\\n        the :mod:`~aionationstates.happenings` module\n        \"\"\"\n        while True:\n            happening_bunch = await self._get_happenings(\n                nations=nations, regions=regions, filters=filters,\n                beforeid=beforeid, beforetime=beforetime\n            )\n            for happening in happening_bunch:\n                yield happening\n            if len(happening_bunch) < 100:\n                break\n            beforeid = happening_bunch[-1].id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def new_happenings(self, poll_period=30, *, nations=None,\n                             regions=None, filters=None):\n        \"\"\"Iterate through new happenings as they arrive::\n\n            async for happening in \\\\\n                    world.new_happenings(region='the north pacific'):\n                # Your processing code here\n                print(happening.text)  # As an example\n\n        Guarantees that:\n\n        * Every happening is generated from the moment the generator\n          is started;\n        * No happening is generated more than once;\n        * Happenings are generated in order from oldest to newest.\n\n        Parameters\n        ----------\n        poll_period : int\n            How long to wait between requesting the next portion of\n            happenings, in seconds.  Note that this should only be\n            tweaked for latency reasons, as the function gives a\n            guarantee that all happenings will be generated.\n\n            Also note that, regardless of the ``poll_period`` set, all\n            of the code in your loop body still has to execute (likely\n            several times) before a new portion of happenings can be\n            requested.  Consider wrapping your happening-processing code\n            in a coroutine and launching it as a task from the loop body\n            if you suspect this might become an issue.\n\n            Requests made by this generator are, of course, subject to\n            the API rate limit, and if the limiter has to temporarily\n            block new requests the time spent waiting will be added on\n            top of ``poll_period``.\n        nations : iterable of str\n            Nations happenings of which will be requested.  Cannot be\n            specified at the same time with ``regions``.\n        regions : iterable of str\n            Regions happenings of which will be requested.  Cannot be\n            specified at the same time with ``nations``.\n        filters : iterable of str\n            Categories to request happenings by.  Available filters\n            are: ``law``, ``change``, ``dispatch``, ``rmb``,\n            ``embassy``, ``eject``, ``admin``, ``move``, ``founding``,\n            ``cte``, ``vote``, ``resolution``, ``member``, and ``endo``.\n\n        Returns\n        -------\n        an asynchronous iterator yielding any of the classes from \\\n        the :mod:`~aionationstates.happenings` module\n        \"\"\"\n        try:\n            # We only need the happenings from this point forwards\n            last_id = (await self._get_happenings(\n                nations=nations, regions=regions, filters=filters,\n                limit=1))[0].id\n        except IndexError:\n            # Happenings before this point have all been deleted\n            last_id = 0\n\n        while True:\n            # Sleep before the loop body to avoid wasting the first request\n            await sleep(poll_period)\n\n            # I don't think there's a cleaner solution, sadly.\n            happenings = []\n            async for happening in self.happenings(\n                    nations=nations, regions=regions, filters=filters):\n                if happening.id <= last_id:\n                    break\n                happenings.append(happening)\n\n            with suppress(IndexError):\n                last_id = happenings[0].id\n\n            for happening in reversed(happenings):\n                yield happening", "response": "Iterate through new happenings as they arrive."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the normalisation coefficients of potential match positions Then normalises the correlation at these positions and returns them as a dictionary of match positions", "response": "def normalise_correlation(image_tile_dict, transformed_array, template, normed_tolerance=1):\n    \"\"\"Calculates the normalisation coefficients of potential match positions\n       Then normalises the correlation at these positions, and returns them\n       if they do indeed constitute a match\n    \"\"\"\n    template_norm = np.linalg.norm(template)\n    image_norms = {(x,y):np.linalg.norm(image_tile_dict[(x,y)])*template_norm for (x,y) in image_tile_dict.keys()}\n    match_points = image_tile_dict.keys()\n    # for correlation, then need to transofrm back to get correct value for division\n    h, w = template.shape\n    #points_from_transformed_array = [(match[0] + h - 1, match[1] + w - 1) for match in match_points]\n    image_matches_normalised = {match_points[i]:transformed_array[match_points[i][0], match_points[i][1]]/image_norms[match_points[i]] for i in range(len(match_points))}\n    result = {key:value for key, value in image_matches_normalised.items() if np.round(value, decimals=3) >= normed_tolerance}\n    return result.keys()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __init_os_api(self):\n        loader = loading.get_plugin_loader('password')\n        auth = loader.load_from_options(auth_url=self._os_auth_url,\n                                        username=self._os_username,\n                                        password=self._os_password,\n                                        project_name=self._os_tenant_name)\n        sess = session.Session(auth=auth)\n        self.nova_client = nova_client.Client(self.nova_api_version, session=sess)\n        self.neutron_client = neutron_client.Client(session=sess)\n        self.glance_client = glance_client.Client('2', session=sess)\n        self.cinder_client = cinder_client.Client('2', session=sess)", "response": "Initializes the client objects for talking to OpenStack API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop_instance(self, instance_id):\n        instance = self._load_instance(instance_id)\n        instance.delete()\n        del self._instances[instance_id]", "response": "Stops the instance gracefully."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving all IP addresses associated to a given instance.", "response": "def get_ips(self, instance_id):\n        \"\"\"Retrieves all IP addresses associated to a given instance.\n\n        :return: tuple (IPs)\n        \"\"\"\n        instance = self._load_instance(instance_id)\n        IPs = sum(instance.networks.values(), [])\n        return IPs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_instance_running(self, instance_id):\n\n        # Here, it's always better if we update the instance.\n        instance = self._load_instance(instance_id, force_reload=True)\n        return instance.status == 'ACTIVE'", "response": "Checks if the instance is up and running."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_keypair(self, name, public_key_path, private_key_path):\n\n        # Read key. We do it as first thing because we need it either\n        # way, to check the fingerprint of the remote keypair if it\n        # exists already, or to create a new keypair.\n        pkey = None\n        try:\n            pkey = DSSKey.from_private_key_file(private_key_path)\n        except PasswordRequiredException:\n            warn(\"Unable to check key file `{0}` because it is encrypted with a \"\n                 \"password. Please, ensure that you added it to the SSH agent \"\n                 \"with `ssh-add {1}`\"\n                 .format(private_key_path, private_key_path))\n        except SSHException:\n            try:\n                pkey = RSAKey.from_private_key_file(private_key_path)\n            except PasswordRequiredException:\n                warn(\"Unable to check key file `{0}` because it is encrypted with a \"\n                     \"password. Please, ensure that you added it to the SSH agent \"\n                     \"with `ssh-add {1}`\"\n                     .format(private_key_path, private_key_path))\n            except SSHException:\n                raise KeypairError('File `%s` is neither a valid DSA key '\n                                   'or RSA key.' % private_key_path)\n\n        try:\n            # Check if a keypair `name` exists on the cloud.\n            keypair = self.nova_client.keypairs.get(name)\n\n            # Check if it has the correct keypair, but only if we can read the local key\n            if pkey:\n                fingerprint = str.join(\n                    ':', (i.encode('hex') for i in pkey.get_fingerprint()))\n                if fingerprint != keypair.fingerprint:\n                    raise KeypairError(\n                        \"Keypair `%s` is present but has \"\n                        \"different fingerprint. Aborting!\" % name)\n            else:\n                warn(\"Unable to check if the keypair is using the correct key.\")\n        except NotFound:\n            log.warning(\n                \"Keypair `%s` not found on resource `%s`, Creating a new one\",\n                name, self._os_auth_url)\n\n            # Create a new keypair\n            with open(os.path.expanduser(public_key_path)) as f:\n                key_material = f.read()\n                try:\n                    self.nova_client.keypairs.create(name, key_material)\n                except Exception as ex:\n                    log.error(\n                        \"Could not import key `%s` with name `%s` to `%s`\",\n                        name, public_key_path, self._os_auth_url)\n                    raise KeypairError(\n                        \"could not create keypair `%s`: %s\" % (name, ex))", "response": "Checks if the keypair exists on the cloud and if not creates a new one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_instance(self, instance_id, force_reload=True):\n        if force_reload:\n            try:\n                # Remove from cache and get from server again\n                vm = self.nova_client.servers.get(instance_id)\n            except NotFound:\n                raise InstanceNotFoundError(\n                    \"Instance `{instance_id}` not found\"\n                    .format(instance_id=instance_id))\n            # update caches\n            self._instances[instance_id] = vm\n            self._cached_instances[instance_id] = vm\n\n        # if instance is known, return it\n        if instance_id in self._instances:\n            return self._instances[instance_id]\n\n        # else, check (cached) list from provider\n        if instance_id not in self._cached_instances:\n            # Refresh the cache, just in case\n            self._cached_instances = dict(\n                (vm.id, vm) for vm in self.nova_client.servers.list())\n\n        if instance_id in self._cached_instances:\n            inst = self._cached_instances[instance_id]\n            self._instances[instance_id] = inst\n            return inst\n\n        # If we reached this point, the instance was not found neither\n        # in the caches nor on the website.\n        raise InstanceNotFoundError(\n            \"Instance `{instance_id}` not found\"\n            .format(instance_id=instance_id))", "response": "Load an instance from the server cache or from the cloud provider."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallocating a floating IP address to the given instance.", "response": "def _allocate_address(self, instance, network_ids):\n        \"\"\"\n        Allocates a floating/public ip address to the given instance.\n\n        :param instance: instance to assign address to\n\n        :param list network_id: List of IDs (as strings) of networks where to\n        request allocation the floating IP.\n\n        :return: public ip address\n        \"\"\"\n        with OpenStackCloudProvider.__node_start_lock:\n            try:\n                # Use the `novaclient` API (works with python-novaclient <8.0.0)\n                free_ips = [ip for ip in self.nova_client.floating_ips.list() if not ip.fixed_ip]\n                if not free_ips:\n                    free_ips.append(self.nova_client.floating_ips.create())\n            except AttributeError:\n                # Use the `neutronclient` API\n                #\n                # for some obscure reason, using `fixed_ip_address=None` in the\n                # call to `list_floatingips()` returns *no* results (not even,\n                # in fact, those with `fixed_ip_address: None`) whereas\n                # `fixed_ip_address=''` acts as a wildcard and lists *all* the\n                # addresses... so filter them out with a list comprehension\n                free_ips = [ip for ip in\n                            self.neutron_client.list_floatingips(fixed_ip_address='')['floatingips']\n                            if ip['fixed_ip_address'] is None]\n                if not free_ips:\n                    # FIXME: OpenStack Network API v2 requires that we specify\n                    # a network ID along with the request for a floating IP.\n                    # However, ElastiCluster configuration allows for multiple\n                    # networks to be connected to a VM, but does not give any\n                    # hint as to which one(s) should be used for such requests.\n                    # So we try them all, ignoring errors until one request\n                    # succeeds and hope that it's the OK. One can imagine\n                    # scenarios where this is *not* correct, but: (1) these\n                    # scenarios are unlikely, and (2) the old novaclient code\n                    # above has not even had the concept of multiple networks\n                    # for floating IPs and no-one has complained in 5 years...\n                    allocated_ip = None\n                    for network_id in network_ids:\n                        log.debug(\n                            \"Trying to allocate floating IP on network %s ...\", network_id)\n                        try:\n                            allocated_ip = self.neutron_client.create_floatingip({\n                                'floatingip': {'floating_network_id':network_id}})\n                        except BadNeutronRequest as err:\n                            log.debug(\n                                \"Failed allocating floating IP on network %s: %s\",\n                                network_id, err)\n                        if allocated_ip:\n                            free_ips.append(allocated_ip)\n                            break\n                        else:\n                            continue  # try next network\n            if free_ips:\n                ip = free_ips.pop()\n            else:\n                raise RuntimeError(\n                    \"Could not allocate floating IP for VM {0}\"\n                    .format(vm.id))\n            instance.add_floating_ip(ip)\n        return ip.ip"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the message lodged.", "response": "async def post(self):\n        \"\"\"Get the message lodged.\n\n        Returns\n        -------\n        an :class:`aionationstates.ApiQuery` of :class:`aionationstates.Post`\n        \"\"\"\n        post = (await self.region._get_messages(\n            fromid=self._post_id, limit=1))[0]\n        assert post.id == self._post_id\n        return post"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the resolution voted on.", "response": "async def resolution(self):\n        \"\"\"Get the resolution voted on.\n\n        Returns\n        -------\n        awaitable of :class:`aionationstates.ResolutionAtVote`\n            The resolution voted for.\n\n        Raises\n        ------\n        aionationstates.NotFound\n            If the resolution has since been passed or defeated.\n        \"\"\"\n        resolutions = await asyncio.gather(\n            aionationstates.ga.resolution_at_vote,\n            aionationstates.sc.resolution_at_vote,\n        )\n        for resolution in resolutions:\n            if (resolution is not None\n                    and resolution.name == self.resolution_name):\n                return resolution\n        raise aionationstates.NotFound"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the proposal in question.", "response": "async def proposal(self):\n        \"\"\"Get the proposal in question.\n\n        Actually just the first proposal with the same name, but the\n        chance of a collision is tiny.\n\n        Returns\n        -------\n        awaitable of :class:`aionationstates.Proposal`\n            The proposal submitted.\n\n        Raises\n        ------\n        aionationstates.NotFound\n            If the proposal has since been withdrawn or promoted.\n        \"\"\"\n        proposals = await aionationstates.wa.proposals()\n        for proposal in proposals:\n            if (proposal.name == self.proposal_name):\n                return proposal\n        raise aionationstates.NotFound"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_free_shipping_promotion(cls, free_shipping_promotion, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_free_shipping_promotion_with_http_info(free_shipping_promotion, **kwargs)\n        else:\n            (data) = cls._create_free_shipping_promotion_with_http_info(free_shipping_promotion, **kwargs)\n            return data", "response": "Create a new FreeShippingPromotion\n clf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete FreeShippingPromotion by ID.", "response": "def delete_free_shipping_promotion_by_id(cls, free_shipping_promotion_id, **kwargs):\n        \"\"\"Delete FreeShippingPromotion\n\n        Delete an instance of FreeShippingPromotion by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_free_shipping_promotion_by_id(free_shipping_promotion_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_promotion_id: ID of freeShippingPromotion to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, **kwargs)\n        else:\n            (data) = cls._delete_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind FreeShippingPromotion by ID Return single instance of FreeShippingPromotion with the given ID.", "response": "def get_free_shipping_promotion_by_id(cls, free_shipping_promotion_id, **kwargs):\n        \"\"\"Find FreeShippingPromotion\n\n        Return single instance of FreeShippingPromotion by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_free_shipping_promotion_by_id(free_shipping_promotion_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_promotion_id: ID of freeShippingPromotion to return (required)\n        :return: FreeShippingPromotion\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, **kwargs)\n        else:\n            (data) = cls._get_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists FreeShippingPromotions This method returns a list of FreeShippingPromotions", "response": "def list_all_free_shipping_promotions(cls, **kwargs):\n        \"\"\"List FreeShippingPromotions\n\n        Return a list of FreeShippingPromotions\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_free_shipping_promotions(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[FreeShippingPromotion]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_free_shipping_promotions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_free_shipping_promotions_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace FreeShippingPromotion by ID", "response": "def replace_free_shipping_promotion_by_id(cls, free_shipping_promotion_id, free_shipping_promotion, **kwargs):\n        \"\"\"Replace FreeShippingPromotion\n\n        Replace all attributes of FreeShippingPromotion\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_free_shipping_promotion_by_id(free_shipping_promotion_id, free_shipping_promotion, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_promotion_id: ID of freeShippingPromotion to replace (required)\n        :param FreeShippingPromotion free_shipping_promotion: Attributes of freeShippingPromotion to replace (required)\n        :return: FreeShippingPromotion\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, free_shipping_promotion, **kwargs)\n        else:\n            (data) = cls._replace_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, free_shipping_promotion, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates FreeShippingPromotion by ID", "response": "def update_free_shipping_promotion_by_id(cls, free_shipping_promotion_id, free_shipping_promotion, **kwargs):\n        \"\"\"Update FreeShippingPromotion\n\n        Update attributes of FreeShippingPromotion\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_free_shipping_promotion_by_id(free_shipping_promotion_id, free_shipping_promotion, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_promotion_id: ID of freeShippingPromotion to update. (required)\n        :param FreeShippingPromotion free_shipping_promotion: Attributes of freeShippingPromotion to update. (required)\n        :return: FreeShippingPromotion\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, free_shipping_promotion, **kwargs)\n        else:\n            (data) = cls._update_free_shipping_promotion_by_id_with_http_info(free_shipping_promotion_id, free_shipping_promotion, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend the specified electrode to the route.", "response": "def append(self, electrode_id):\n        '''\n        Append the specified electrode to the route.\n\n        The route is not modified (i.e., electrode is not appended) if\n        electrode is not connected to the last electrode in the existing route.\n\n        Parameters\n        ----------\n        electrode_id : str\n            Electrode identifier.\n        '''\n        do_append = False\n\n        if not self.electrode_ids:\n            do_append = True\n        elif self.device.shape_indexes.shape[0] > 0:\n            source = self.electrode_ids[-1]\n            target = electrode_id\n            if not (source == target):\n                source_id, target_id = self.device.shape_indexes[[source,\n                                                                  target]]\n                try:\n                    if self.device.adjacency_matrix[source_id, target_id]:\n                        # Electrodes are connected, so append target to current\n                        # route.\n                        do_append = True\n                except IndexError:\n                    logger.warning('Electrodes `%s` and `%s` are not '\n                                   'connected.', source, target)\n\n        if do_append:\n            self.electrode_ids.append(electrode_id)\n        return do_append"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the current set of routes.", "response": "def df_routes(self, value):\n        '''\n        .. versionadded:: 0.11.3\n        '''\n        self._df_routes = value\n        try:\n            self.emit('routes-set', self._df_routes.copy())\n        except TypeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_ui(self):\n        '''\n        .. versionchanged:: 0.9\n            Update device registration in real-time while dragging video\n            control point to new position.\n\n        .. versionchanged:: 0.12\n            Add ``dynamic_electrode_state_shapes`` layer to show dynamic\n            electrode actuations.\n        '''\n        super(DmfDeviceCanvas, self).create_ui()\n        self.video_sink = VideoSink(*[self.socket_info[k]\n                                      for k in ['transport', 'host', 'port']])\n        # Initialize video sink socket.\n        self.video_sink.reset()\n        # Required to have key-press and key-release events trigger.\n        self.widget.set_flags(gtk.CAN_FOCUS)\n        self.widget.add_events(gtk.gdk.KEY_PRESS_MASK |\n                               gtk.gdk.KEY_RELEASE_MASK)\n        # Create initial (empty) cairo surfaces.\n        surface_names = ('background', 'shapes', 'connections', 'routes',\n                         'channel_labels', 'static_electrode_state_shapes',\n                         'dynamic_electrode_state_shapes', 'registration')\n        self.df_surfaces = pd.DataFrame([[self.get_surface(), 1.]\n                                         for i in xrange(len(surface_names))],\n                                        columns=['surface', 'alpha'],\n                                        index=pd.Index(surface_names,\n                                                       name='name'))\n\n        def _update_registration(event):\n            try:\n                start_event = self.start_event.copy()\n                self.start_event = event.copy()\n                self.emit('point-pair-selected', {'start_event': start_event,\n                                                  'end_event': event})\n            except AttributeError:\n                # Mouse button was released, causing `self.start_event` to be\n                # `None` before event was handled here.\n                pass\n\n        # Debounce calls to `_update_registration` function to prevent too many\n        # calls being triggered from mouse movement events.\n        update_registration = debounce.Debounce(_update_registration, wait=10)\n\n        def _on_mouse_move(area, event):\n            # XXX Need to make a copy of the event here since the original\n            # event will be deallocated before the debounced\n            # `update_registration` function is called.\n            event = event.copy()\n\n            if self.mode == 'register_video' and self.start_event is not None:\n                update_registration(event.copy())\n\n        # Connect video registration update event to mouse movement event.\n        self.widget.connect(\"motion_notify_event\", _on_mouse_move)", "response": "Create the UI for this device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts a new Cairo surface into the internal data frame.", "response": "def insert_surface(self, position, name, surface, alpha=1.):\n        '''\n        Insert Cairo surface as new layer.\n\n\n        Args\n        ----\n\n            position (int) : Index position to insert layer at.\n            name (str) : Name of layer.\n            surface (cairo.Context) : Surface to render.\n            alpha (float) : Alpha/transparency level in the range `[0, 1]`.\n        '''\n        if name in self.df_surfaces.index:\n            raise NameError('Surface already exists with `name=\"{}\"`.'\n                            .format(name))\n        self.df_surfaces.loc[name] = surface, alpha\n\n        # Reorder layers such that the new surface is placed at the specified\n        # layer position (relative to the background surface).\n        surfaces_order = self.df_surfaces.index.values.tolist()\n        surfaces_order.remove(name)\n        base_index = surfaces_order.index('background') + 1\n        if position < 0:\n            position = len(surfaces_order) + position\n        surfaces_order.insert(base_index + position, name)\n        self.reorder_surfaces(surfaces_order)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append_surface(self, name, surface, alpha=1.):\n        '''\n        Append Cairo surface as new layer on top of existing layers.\n\n        Args\n        ----\n\n            name (str) : Name of layer.\n            surface (cairo.ImageSurface) : Surface to render.\n            alpha (float) : Alpha/transparency level in the range `[0, 1]`.\n        '''\n        self.insert_surface(position=self.df_surfaces.index.shape[0],\n                            name=name, surface=surface, alpha=alpha)", "response": "Append a Cairo surface to the end of the existing layers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_surface(self, name):\n        '''\n        Remove layer from rendering stack and flatten remaining layers.\n\n        Args\n        ----\n\n            name (str) : Name of layer.\n        '''\n        self.df_surfaces.drop(name, axis=0, inplace=True)\n\n        # Order of layers may have changed after removing a layer. Trigger\n        # refresh of surfaces.\n        self.reorder_surfaces(self.df_surfaces.index)", "response": "Removes a layer from rendering stack and flatten remaining layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clone_surface(self, source_name, target_name, target_position=-1,\n                      alpha=1.):\n        '''\n        Clone surface from existing layer to a new name, inserting new surface\n        at specified position.\n\n        By default, new surface is appended as the top surface layer.\n\n        Args\n        ----\n\n            source_name (str) : Name of layer to clone.\n            target_name (str) : Name of new layer.\n        '''\n        source_surface = self.df_surfaces.surface.ix[source_name]\n        source_width = source_surface.get_width()\n        source_height = source_surface.get_height()\n        source_format = source_surface.get_format()\n\n        target_surface = cairo.ImageSurface(source_format, source_width,\n                                            source_height)\n        target_cairo_context = cairo.Context(target_surface)\n        target_cairo_context.set_source_surface(source_surface, 0, 0)\n        target_cairo_context.paint()\n        self.insert_surface(target_position, target_name, target_surface,\n                            alpha)", "response": "Clone a surface from an existing layer to a new name inserting a new surface at specified position."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders dynamic electrode states.", "response": "def render_dynamic_electrode_state_shapes(self):\n        '''\n        Render **dynamic** states reported by the electrode controller.\n\n        **Dynamic** electrode states are only applied while a protocol is\n        running -- _not_ while in real-time programming mode.\n\n        See also :meth:`render_electrode_shapes()`.\n\n\n        .. versionadded:: 0.12\n        '''\n        df_shapes = self.canvas.df_canvas_shapes.copy()\n        # Only include shapes for electrodes reported as actuated.\n        on_electrodes = self._dynamic_electrodes[self._dynamic_electrodes > 0]\n        df_shapes = (df_shapes.set_index('id').loc[on_electrodes.index]\n                     .reset_index())\n\n        return self.render_electrode_shapes(df_shapes=df_shapes,\n                                            shape_scale=0.75,\n                                            # Lignt blue\n                                            fill=(136 / 255.,\n                                                  189 / 255.,\n                                                  230 / 255.))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_static_electrode_state_shapes(self):\n        '''\n        Render **static** states reported by the electrode controller.\n\n        **Static** electrode states are applied while a protocol is **running**\n        _or_ while **real-time** control is activated.\n\n        See also :meth:`render_electrode_shapes()`.\n\n\n        .. versionadded:: 0.12\n        '''\n        df_shapes = self.canvas.df_canvas_shapes.copy()\n        if self.electrode_states.shape[0]:\n            df_shapes['state'] = self.electrode_states.ix[df_shapes.id].values\n        else:\n            df_shapes['state'] = 0\n        df_shapes = df_shapes.loc[df_shapes.state > 0].dropna(subset=['state'])\n\n        return self.render_electrode_shapes(df_shapes=df_shapes)", "response": "Render static electrode states."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering the electrode states shapes.", "response": "def render_electrode_shapes(self, df_shapes=None, shape_scale=0.8,\n                                fill=(1, 1, 1)):\n        '''\n        Render electrode state shapes.\n\n        By default, draw each electrode shape filled white.\n\n        See also :meth:`render_shapes()`.\n\n        Parameters\n        ----------\n        df_shapes = : pandas.DataFrame\n\n\n        .. versionadded:: 0.12\n        '''\n        surface = self.get_surface()\n        if df_shapes is None:\n            if hasattr(self.canvas, 'df_canvas_shapes'):\n                df_shapes = self.canvas.df_canvas_shapes\n            else:\n                return surface\n        if 'x_center' not in df_shapes or 'y_center' not in df_shapes:\n            # No center points have been computed for shapes.\n            return surface\n\n        cairo_context = cairo.Context(surface)\n\n        df_shapes = df_shapes.copy()\n        # Scale shapes to leave shape edges uncovered.\n        df_shapes[['x', 'y']] = (df_shapes[['x_center', 'y_center']] +\n                                 df_shapes[['x_center_offset',\n                                            'y_center_offset']].values *\n                                 shape_scale)\n\n        for path_id, df_path_i in (df_shapes.groupby(self.canvas\n                                                     .shape_i_columns)[['x',\n                                                                        'y']]):\n            # Use attribute lookup for `x` and `y`, since it is considerably\n            # faster than `get`-based lookup using columns name strings.\n            vertices_x = df_path_i.x.values\n            vertices_y = df_path_i.y.values\n            cairo_context.move_to(vertices_x[0], vertices_y[0])\n            for x, y in itertools.izip(vertices_x[1:], vertices_y[1:]):\n                cairo_context.line_to(x, y)\n            cairo_context.close_path()\n\n            # Draw filled shape to indicate actuated electrode state.\n            cairo_context.set_source_rgba(*fill)\n            cairo_context.fill()\n        return surface"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering static electrode shapes.", "response": "def render_shapes(self, df_shapes=None, clip=False):\n        '''\n        Render static electrode shapes (independent of actuation state).\n\n        If video is enabled, draw white outline for each electrode (no fill).\n\n        If video is disabled, draw white outline for each electrode and fill\n        blue.\n\n        See also :meth:`render_electrode_state_shapes()`.\n        '''\n        surface = self.get_surface()\n        if df_shapes is None:\n            if hasattr(self.canvas, 'df_canvas_shapes'):\n                df_shapes = self.canvas.df_canvas_shapes\n            else:\n                return surface\n\n        cairo_context = cairo.Context(surface)\n\n        for path_id, df_path_i in (df_shapes\n                                   .groupby(self.canvas\n                                            .shape_i_columns)[['x', 'y']]):\n            # Use attribute lookup for `x` and `y`, since it is considerably\n            # faster than `get`-based lookup using columns name strings.\n            vertices_x = df_path_i.x.values\n            vertices_y = df_path_i.y.values\n            cairo_context.move_to(vertices_x[0], vertices_y[0])\n            for x, y in itertools.izip(vertices_x[1:], vertices_y[1:]):\n                cairo_context.line_to(x, y)\n            cairo_context.close_path()\n\n            if self.enabled:\n                # Video is enabled.\n\n                # Draw white border around electrode.\n                line_width = 1\n                if path_id not in self.electrode_channels.index:\n                    #         on  off on  off\n                    dashes = [10, 10]\n                    color = (1, 0, 1)\n                    line_width *= 2\n                else:\n                    dashes = []\n                    color = (1, 1, 1)\n                cairo_context.set_dash(dashes)\n                cairo_context.set_line_width(line_width)\n                cairo_context.set_source_rgb(*color)\n                cairo_context.stroke()\n            else:\n                # Video is enabled.  Fill electrode blue.\n                color = ((0, 0, 1) if path_id in self.electrode_channels.index\n                         else (1, 0, 1))\n                cairo_context.set_source_rgb(*color)\n                cairo_context.fill_preserve()\n                # Draw white border around electrode.\n                cairo_context.set_line_width(1)\n                cairo_context.set_source_rgba(1, 1, 1)\n                cairo_context.stroke()\n        return surface"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_registration(self):\n        '''\n        Render pinned points on video frame as red rectangle.\n        '''\n        surface = self.get_surface()\n        if self.canvas is None or self.df_canvas_corners.shape[0] == 0:\n            return surface\n\n        corners = self.df_canvas_corners.copy()\n        corners['w'] = 1\n\n        transform = self.canvas.shapes_to_canvas_transform\n        canvas_corners = corners.values.dot(transform.T.values).T\n\n        points_x = canvas_corners[0]\n        points_y = canvas_corners[1]\n\n        cairo_context = cairo.Context(surface)\n        cairo_context.move_to(points_x[0], points_y[0])\n        for x, y in zip(points_x[1:], points_y[1:]):\n            cairo_context.line_to(x, y)\n        cairo_context.line_to(points_x[0], points_y[0])\n        cairo_context.set_source_rgb(1, 0, 0)\n        cairo_context.stroke()\n        return surface", "response": "Render pinned points on video frame as red rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render(self):\n        '''\n        .. versionchanged:: 0.12\n            Add ``dynamic_electrode_state_shapes`` layer to show dynamic\n            electrode actuations.\n        '''\n        # Render each layer and update data frame with new content for each\n        # surface.\n        surface_names = ('background', 'shapes', 'connections', 'routes',\n                         'channel_labels', 'static_electrode_state_shapes',\n                         'dynamic_electrode_state_shapes', 'registration')\n        for k in surface_names:\n            self.set_surface(k, getattr(self, 'render_' + k)())\n        self.emit('surfaces-reset', self.df_surfaces)\n        self.cairo_surface = flatten_surfaces(self.df_surfaces)", "response": "Render each electrode in the data frame and update the data frame with new content."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_route(self, df_route, cr, color=None, line_width=None):\n        '''\n        Draw a line between electrodes listed in a route.\n\n        Arguments\n        ---------\n\n         - `df_route`:\n             * A `pandas.DataFrame` containing a column named `electrode_i`.\n             * For each row, `electrode_i` corresponds to the integer index of\n               the corresponding electrode.\n         - `cr`: Cairo context.\n         - `color`: Either a RGB or RGBA tuple, with each color channel in the\n           range [0, 1].  If `color` is `None`, the electrode color is set to\n           white.\n        '''\n        df_route_centers = (self.canvas.df_shape_centers\n                            .ix[df_route.electrode_i][['x_center',\n                                                       'y_center']])\n        df_endpoint_marker = (.6 * self.get_endpoint_marker(df_route_centers)\n                              + df_route_centers.iloc[-1].values)\n\n        # Save cairo context to restore after drawing route.\n        cr.save()\n        if color is None:\n            # Colors from [\"Show me the numbers\"][1].\n            #\n            # [1]: http://blog.axc.net/its-the-colors-you-have/\n            # LiteOrange = rgb(251,178,88);\n            # MedOrange = rgb(250,164,58);\n            # LiteGreen = rgb(144,205,151);\n            # MedGreen = rgb(96,189,104);\n            color_rgb_255 = np.array([96,189,104, .8 * 255])\n            color = (color_rgb_255 / 255.).tolist()\n        if len(color) < 4:\n            color += [1.] * (4 - len(color))\n        cr.set_source_rgba(*color)\n        cr.move_to(*df_route_centers.iloc[0])\n        for electrode_i, center_i in df_route_centers.iloc[1:].iterrows():\n            cr.line_to(*center_i)\n        if line_width is None:\n            line_width = np.sqrt((df_endpoint_marker.max().values -\n                                  df_endpoint_marker.min().values).prod()) * .1\n        cr.set_line_width(4)\n        cr.stroke()\n\n        cr.move_to(*df_endpoint_marker.iloc[0])\n        for electrode_i, center_i in df_endpoint_marker.iloc[1:].iterrows():\n            cr.line_to(*center_i)\n        cr.close_path()\n        cr.set_source_rgba(*color)\n        cr.fill()\n        # Restore cairo context after drawing route.\n        cr.restore()", "response": "Draw a line between electrodes listed in a route."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when any mouse button is pressed.", "response": "def on_widget__button_press_event(self, widget, event):\n        '''\n        Called when any mouse button is pressed.\n\n\n        .. versionchanged:: 0.11\n            Do not trigger `route-electrode-added` event if `ALT` key is\n            pressed.\n        '''\n        if self.mode == 'register_video' and event.button == 1:\n            self.start_event = event.copy()\n            return\n        elif self.mode == 'control':\n            shape = self.canvas.find_shape(event.x, event.y)\n\n            if shape is None: return\n            state = event.get_state()\n            if event.button == 1:\n                # Start a new route.\n                self._route = Route(self.device)\n                self._route.append(shape)\n                self.last_pressed = shape\n                if not (state & gtk.gdk.MOD1_MASK):\n                    # `<Alt>` key is not held down.\n                    self.emit('route-electrode-added', shape)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when any mouse button is released.", "response": "def on_widget__button_release_event(self, widget, event):\n        '''\n        Called when any mouse button is released.\n\n\n        .. versionchanged:: 0.11.3\n            Always reset pending route, regardless of whether a route was\n            completed.  This includes a) removing temporary routes from routes\n            table, and b) resetting the state of the current route electrode\n            queue.  This fixes\n            https://github.com/sci-bots/microdrop/issues/256.\n        '''\n        event = event.copy()\n        if self.mode == 'register_video' and (event.button == 1 and\n                                              self.start_event is not None):\n            self.emit('point-pair-selected', {'start_event': self.start_event,\n                                              'end_event': event.copy()})\n            self.start_event = None\n            return\n        elif self.mode == 'control':\n            # XXX Negative `route_i` corresponds to temporary route being\n            # drawn.  Since release of mouse button terminates route drawing,\n            # clear any rows corresponding to negative `route_i` values from\n            # the routes table.\n            self.df_routes = self.df_routes.loc[self.df_routes.route_i >=\n                                                0].copy()\n            shape = self.canvas.find_shape(event.x, event.y)\n\n            if shape is not None:\n                electrode_data = {'electrode_id': shape, 'event': event.copy()}\n                if event.button == 1:\n                    if gtk.gdk.BUTTON1_MASK == event.get_state():\n                        if self._route.append(shape):\n                            self.emit('route-electrode-added', shape)\n                        if len(self._route.electrode_ids) == 1:\n                            # Single electrode, so select electrode.\n                            self.emit('electrode-selected', electrode_data)\n                        else:\n                            # Multiple electrodes, so select route.\n                            route = self._route\n                            self.emit('route-selected', route)\n                    elif (event.get_state() == (gtk.gdk.MOD1_MASK |\n                                                gtk.gdk.BUTTON1_MASK) and\n                        self.last_pressed != shape):\n                        # `<Alt>` key was held down.\n                        self.emit('electrode-pair-selected',\n                                {'source_id': self.last_pressed,\n                                 'target_id': shape, 'event': event.copy()})\n                    self.last_pressed = None\n                elif event.button == 3:\n                    # Create right-click pop-up menu.\n                    menu = self.create_context_menu(event, shape)\n\n                    # Display menu popup\n                    menu.popup(None, None, None, event.button, event.time)\n            # Clear route.\n            self._route = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a context menu for the given event and shape.", "response": "def create_context_menu(self, event, shape):\n        '''\n        Parameters\n        ----------\n        event : gtk.gdk.Event\n            GTK mouse click event.\n        shape : str\n            Electrode shape identifier (e.g., `\"electrode028\"`).\n\n        Returns\n        -------\n        gtk.Menu\n            Context menu.\n\n\n        .. versionchanged:: 0.13\n            - Deprecate hard-coded commands (e.g., clear electrodes, clear\n              routes).\n            - Add anonymous global commands section at head of menu (i.e.,\n              commands not specific to an electrode or route).\n            - Add \"Electrode\" and \"Route(s)\" sub-menus.\n        '''\n        routes = self.df_routes.loc[self.df_routes.electrode_i == shape,\n                                    'route_i'].astype(int).unique().tolist()\n\n        def _connect_callback(menu_item, command_signal, group, command, data):\n            callback_called = threading.Event()\n\n            def _callback(signal, widget, *args):\n                if callback_called.is_set():\n                    return\n                callback_called.set()\n\n                _L().debug('`%s`: %s %s %s', signal, group, command, data)\n                gtk.idle_add(self.emit, command_signal, group, command, data)\n            menu_item.connect('activate', ft.partial(_callback, 'activate'))\n            menu_item.connect('button-press-event',\n                              ft.partial(_callback, 'button-press-event'))\n\n            if group is not None:\n                menu_item.set_tooltip_text(group)\n\n        menu = gtk.Menu()\n\n        # Add menu items/groups for registered global commands.\n        if self.global_commands:\n            data = {'event': event.copy()}\n            command_signal = 'global-command'\n\n            for group, commands in self.global_commands.iteritems():\n                for command, title in commands.iteritems():\n                    menu_item_j = gtk.MenuItem(title)\n                    menu.append(menu_item_j)\n\n                    _connect_callback(menu_item_j, command_signal, group,\n                                      command, data)\n\n        # Add menu items/groups for registered electrode commands.\n        if self.electrode_commands:\n            separator = gtk.SeparatorMenuItem()\n            menu.append(separator)\n\n            # Add electrode sub-menu.\n            menu_e = gtk.Menu()\n            menu_head_e = gtk.MenuItem('_Electrode')\n            menu_head_e.set_submenu(menu_e)\n            menu_head_e.set_use_underline(True)\n            menu.append(menu_head_e)\n\n            command_signal = 'electrode-command'\n            data = {'electrode_id': shape, 'event': event.copy()}\n\n            for group, commands in self.electrode_commands.iteritems():\n                for command, title in commands.iteritems():\n                    menu_item_j = gtk.MenuItem(title)\n                    menu_e.append(menu_item_j)\n                    _connect_callback(menu_item_j, command_signal, group,\n                                      command, data)\n\n        # Add menu items/groups for registered route commands.\n        if routes and self.route_commands:\n            # TODO: Refactor electrode/route command menu code to reduce code\n            # duplication (i.e., DRY).\n            separator = gtk.SeparatorMenuItem()\n            menu.append(separator)\n\n            # Add route sub-menu.\n            menu_r = gtk.Menu()\n            menu_head_r = gtk.MenuItem('_Route(s)')\n            menu_head_r.set_submenu(menu_r)\n            menu_head_r.set_use_underline(True)\n            menu.append(menu_head_r)\n\n            command_signal = 'route-command'\n            data = {'route_ids': routes, 'event': event.copy()}\n            for group, commands in self.route_commands.iteritems():\n                for command, title in commands.iteritems():\n                    menu_item_j = gtk.MenuItem(title)\n                    menu_r.append(menu_item_j)\n\n                    _connect_callback(menu_item_j, command_signal, group,\n                                      command, data)\n\n        menu.show_all()\n        return menu"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when mouse pointer is moved within drawing area.", "response": "def on_widget__motion_notify_event(self, widget, event):\n        '''\n        Called when mouse pointer is moved within drawing area.\n\n\n        .. versionchanged:: 0.11\n            Do not trigger `route-electrode-added` event if `ALT` key is\n            pressed.\n        '''\n        if self.canvas is None:\n            # Canvas has not been initialized.  Nothing to do.\n            return\n        elif event.is_hint:\n            pointer = event.window.get_pointer()\n            x, y, mod_type = pointer\n        else:\n            x = event.x\n            y = event.y\n        shape = self.canvas.find_shape(x, y)\n\n        # Grab focus to [enable notification on key press/release events][1].\n        #\n        # [1]: http://mailman.daa.com.au/cgi-bin/pipermail/pygtk/2003-August/005770.html\n        self.widget.grab_focus()\n\n        if shape != self.last_hovered:\n            if self.last_hovered is not None:\n                # Leaving shape\n                self.emit('electrode-mouseout', {'electrode_id':\n                                                 self.last_hovered,\n                                                 'event': event.copy()})\n                self.last_hovered = None\n            elif shape is not None:\n                # Entering shape\n                self.last_hovered = shape\n\n                if self._route is not None:\n                    if self._route.append(shape) and not (event.get_state() &\n                                                          gtk.gdk.MOD1_MASK):\n                        # `<Alt>` key was not held down.\n                        self.emit('route-electrode-added', shape)\n\n                self.emit('electrode-mouseover', {'electrode_id':\n                                                  self.last_hovered,\n                                                  'event': event.copy()})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_global_command(self, command, title=None, group=None):\n        '''\n        .. versionadded:: 0.13\n\n\n        Register global command (i.e., not specific to electrode or route).\n\n        Add global command to context menu.\n        '''\n        commands = self.global_commands.setdefault(group, OrderedDict())\n        if title is None:\n            title = (command[:1].upper() + command[1:]).replace('_', ' ')\n        commands[command] = title", "response": ".. versionadded:: 0.13\n\n\n        Register global command (i.e., not specific to electrode or route).\n\n        Add global command to context menu."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister electrode command. Add electrode plugin command to context menu.", "response": "def register_electrode_command(self, command, title=None, group=None):\n        '''\n        Register electrode command.\n\n        Add electrode plugin command to context menu.\n        '''\n        commands = self.electrode_commands.setdefault(group, OrderedDict())\n        if title is None:\n            title = (command[:1].upper() + command[1:]).replace('_', ' ')\n        commands[command] = title"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters route command. Add route plugin command to context menu.", "response": "def register_route_command(self, command, title=None, group=None):\n        '''\n        Register route command.\n\n        Add route plugin command to context menu.\n        '''\n        commands = self.route_commands.setdefault(group, OrderedDict())\n        if title is None:\n            title = (command[:1].upper() + command[1:]).replace('_', ' ')\n        commands[command] = title"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all Gateways in a specific language", "response": "def list_all_gateways(cls, **kwargs):\n        \"\"\"List Gateways\n\n        Return a list of Gateways\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_gateways(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Gateway]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_gateways_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_gateways_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_of_dictionaries_to_mysql_inserts(\n        log,\n        datalist,\n        tableName):\n    \"\"\"Convert a python list of dictionaries to pretty csv output\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``datalist`` -- a list of dictionaries\n        - ``tableName`` -- the name of the table to create the insert statements for\n\n    **Return:**\n        - ``output`` -- the mysql insert statements (as a string)\n\n    **Usage:**\n\n        .. code-block:: python \n\n            from fundamentals.files import list_of_dictionaries_to_mysql_inserts\n            mysqlInserts = list_of_dictionaries_to_mysql_inserts(\n                log=log,\n                datalist=dataList,\n                tableName=\"my_new_table\"\n            )\n            print mysqlInserts\n\n        this output the following:\n\n        .. code-block:: plain\n\n            INSERT INTO `testing_table` (a_newKey,and_another,dateCreated,uniqueKey2,uniquekey1) VALUES (\"cool\" ,\"super cool\" ,\"2016-09-14T13:17:26\" ,\"burgers\" ,\"cheese\")  ON DUPLICATE KEY UPDATE  a_newKey=\"cool\", and_another=\"super cool\", dateCreated=\"2016-09-14T13:17:26\", uniqueKey2=\"burgers\", uniquekey1=\"cheese\" ;\n            ...\n            ...\n    \"\"\"\n    log.debug('starting the ``list_of_dictionaries_to_mysql_inserts`` function')\n\n    if not len(datalist):\n        return \"NO MATCH\"\n\n    inserts = []\n\n    for d in datalist:\n        insertCommand = convert_dictionary_to_mysql_table(\n            log=log,\n            dictionary=d,\n            dbTableName=\"testing_table\",\n            uniqueKeyList=[],\n            dateModified=False,\n            returnInsertOnly=True,\n            replace=True,\n            batchInserts=False\n        )\n        inserts.append(insertCommand)\n\n    output = \";\\n\".join(inserts) + \";\"\n\n    log.debug('completed the ``list_of_dictionaries_to_mysql_inserts`` function')\n    return output", "response": "Convert a python list of dictionaries to a list of MySQL insert statements"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a deferred that will fire after the request is finished.", "response": "def after(self):\n        \"\"\"\n        Return a deferred that will fire after the request is finished.\n\n        Returns:\n\n            Deferred: a new deferred that will fire appropriately\n\n        \"\"\"\n\n        d = Deferred()\n        self._after_deferreds.append(d)\n        return d.chain"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef after_response(self, request, fn, *args, **kwargs):\n\n        self._requests[id(request)][\"callbacks\"].append((fn, args, kwargs))", "response": "Call the given callable after the given request has its response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_degbandshalffill():\n    ulim = [3.45, 5.15, 6.85, 8.55]\n    bands = range(1, 5)\n    for band, u_int in zip(bands, ulim):\n        name = 'Z_half_'+str(band)+'band'\n        dop = [0.5]\n        data = ssplt.calc_z(band, dop, np.arange(0, u_int, 0.1),0., name)\n        plt.plot(data['u_int'], data['zeta'][0, :, 0], label='$N={}$'.format(str(band)))\n\n    ssplt.label_saves('Z_half_multiorb.png')", "response": "Plot of Quasiparticle weight for degenerate\n       half - filled bands showing the Mott transition"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting of Quasiparticle weight for N degenerate bands under selected doping", "response": "def plot_dop(bands, int_max, dop, hund_cu, name):\n    \"\"\"Plot of Quasiparticle weight for N degenerate bands\n       under selected doping shows transition only at half-fill\n       the rest are metallic states\"\"\"\n    data = ssplt.calc_z(bands, dop, np.arange(0, int_max, 0.1), hund_cu, name)\n    ssplt.plot_curves_z(data, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_dop_phase(bands, int_max, hund_cu):\n    name = 'Z_dop_phase_'+str(bands)+'bands_U'+str(int_max)+'J'+str(hund_cu)\n    dop = np.sort(np.hstack((np.linspace(0.01,0.99,50),\n                    np.arange(1./2./bands, 1, 1/2/bands))))\n    data = ssplt.calc_z(bands, dop, np.arange(0, int_max, 0.1), hund_cu, name)\n\n    ssplt.imshow_z(data, name)\n    ssplt.surf_z(data, name)", "response": "Phase plot of Quasiparticle weight for N degenerate bands under doping"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_store_credit(cls, store_credit, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_store_credit_with_http_info(store_credit, **kwargs)\n        else:\n            (data) = cls._create_store_credit_with_http_info(store_credit, **kwargs)\n            return data", "response": "Create a new StoreCredit\n clf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_store_credit_by_id(cls, store_credit_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_store_credit_by_id_with_http_info(store_credit_id, **kwargs)\n        else:\n            (data) = cls._delete_store_credit_by_id_with_http_info(store_credit_id, **kwargs)\n            return data", "response": "Delete an instance of StoreCredit by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_store_credit_by_id(cls, store_credit_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_store_credit_by_id_with_http_info(store_credit_id, **kwargs)\n        else:\n            (data) = cls._get_store_credit_by_id_with_http_info(store_credit_id, **kwargs)\n            return data", "response": "Find StoreCredit by ID Return single instance of StoreCredit"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_all_store_credits(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_store_credits_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_store_credits_with_http_info(**kwargs)\n            return data", "response": "List StoreCredits\n        Return a list of StoreCredits\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace StoreCredit by ID and attributes", "response": "def replace_store_credit_by_id(cls, store_credit_id, store_credit, **kwargs):\n        \"\"\"Replace StoreCredit\n\n        Replace all attributes of StoreCredit\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_store_credit_by_id(store_credit_id, store_credit, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_credit_id: ID of storeCredit to replace (required)\n        :param StoreCredit store_credit: Attributes of storeCredit to replace (required)\n        :return: StoreCredit\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_store_credit_by_id_with_http_info(store_credit_id, store_credit, **kwargs)\n        else:\n            (data) = cls._replace_store_credit_by_id_with_http_info(store_credit_id, store_credit, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate attributes of StoreCredit by ID", "response": "def update_store_credit_by_id(cls, store_credit_id, store_credit, **kwargs):\n        \"\"\"Update StoreCredit\n\n        Update attributes of StoreCredit\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_store_credit_by_id(store_credit_id, store_credit, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_credit_id: ID of storeCredit to update. (required)\n        :param StoreCredit store_credit: Attributes of storeCredit to update. (required)\n        :return: StoreCredit\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_store_credit_by_id_with_http_info(store_credit_id, store_credit, **kwargs)\n        else:\n            (data) = cls._update_store_credit_by_id_with_http_info(store_credit_id, store_credit, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_mouse_motion(x, y, dx, dy):\n    mouse.x, mouse.y = x, y\n    mouse.move()\n    window.update_caption(mouse)", "response": "Mouse motion event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_mouse_drag(x, y, dx, dy, buttons, modifiers):\n    mouse.x, mouse.y = x, y\n    mouse.move()", "response": "Mouse drag event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_mouse_press(x, y, button, modifiers):\n    if button == MouseKeyCode.LEFT:\n        mouse.press()\n    elif button == MouseKeyCode.RIGHT:\n        mouse.right_press()\n\n    # \u5224\u65ad\u662f\u5426\u6709\u56fe\u5f62\u7684\u70b9\u51fb\u4e8b\u4ef6\u88ab\u89e6\u53d1\u4e86\n    shapes = list(all_shapes)\n    while shapes:\n        shape = shapes.pop()\n        if(shape._press and shape_clicked(shape)):\n            shape._press()", "response": "Mouse press event handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister any extensions under the given namespace.", "response": "def _register_extensions(self, namespace):\n        \"\"\"Register any extensions under the given namespace.\"\"\"\n\n        # Register any extension classes for this class.\n        extmanager = ExtensionManager(\n            'extensions.classes.{}'.format(namespace),\n            propagate_map_exceptions=True\n        )\n\n        if extmanager.extensions:\n            extmanager.map(util.register_extension_class, base=self)\n\n        # Register any extension methods for this class.\n        extmanager = ExtensionManager(\n            'extensions.methods.{}'.format(namespace),\n            propagate_map_exceptions=True\n        )\n        if extmanager.extensions:\n            extmanager.map(util.register_extension_method, base=self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef acls(self):\n        if self._acls is None:\n            self._acls = InstanceAcls(instance=self)\n        return self._acls", "response": "The instance ACLs operations layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all ACLs for this instance.", "response": "def all(self):\n        \"\"\"Get all ACLs for this instance.\"\"\"\n        return self._instance._client.acls.all(self._instance.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an ACL for this instance.", "response": "def create(self, cidr_mask, description, **kwargs):\n        \"\"\"Create an ACL for this instance.\n\n        See :py:meth:`Acls.create` for call signature.\n        \"\"\"\n        return self._instance._client.acls.create(\n            self._instance.name,\n            cidr_mask,\n            description,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, acl):\n        return self._instance._client.acls.get(self._instance.name, acl)", "response": "Get the ACL specified by ID belonging to this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if num is an actual number or an object that converts to one", "response": "def is_number(num, if_bool=False):\n    \"\"\" :return: True if num is either an actual number, or an object that converts to one \"\"\"\n\n    if isinstance(num, bool):\n        return if_bool\n    elif isinstance(num, int):\n        return True\n    try:\n        number = float(num)\n        return not (isnan(number) or isinf(number))\n    except (TypeError, ValueError):\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an encoder for a basic varint value.", "response": "def _VarintDecoder(mask):\n  \"\"\"Return an encoder for a basic varint value (does not include tag).\n\n  Decoded values will be bitwise-anded with the given mask before being\n  returned, e.g. to limit them to 32 bits.  The returned decoder does not\n  take the usual \"end\" parameter -- the caller is expected to do bounds checking\n  after the fact (often the caller can defer such checking until later).  The\n  decoder returns a (value, new_pos) pair.\n  \"\"\"\n\n  def DecodeVarint(buffer, pos):\n    result = 0\n    shift = 0\n    while 1:\n      if pos > len(buffer) -1:\n        raise NotEnoughDataException( \"Not enough data to decode varint\" )\n      b = buffer[pos]\n      result |= ((b & 0x7f) << shift)\n      pos += 1\n      if not (b & 0x80):\n        result &= mask\n        return (result, pos)\n      shift += 7\n      if shift >= 64:\n        raise _DecodeError('Too many bytes when decoding varint.')\n\n  return DecodeVarint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nliking _VarintDecoder but decodes signed values.", "response": "def _SignedVarintDecoder(mask):\n  \"\"\"Like _VarintDecoder() but decodes signed values.\"\"\"\n\n\n  def DecodeVarint(buffer, pos):\n    result = 0\n    shift = 0\n    while 1:\n      if pos > len(buffer) -1:\n        raise NotEnoughDataException(  \"Not enough data to decode varint\" )\n      b = local_ord(buffer[pos])\n      result |= ((b & 0x7f) << shift)\n      pos += 1\n      if not (b & 0x80):\n        if result > 0x7fffffffffffffff:\n          result -= (1 << 64)\n          result |= ~mask\n        else:\n          result &= mask\n        return (result, pos)\n      shift += 7\n      if shift >= 64:\n        raise _DecodeError('Too many bytes when decoding varint.')\n\n  return DecodeVarint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the size of a varint value.", "response": "def varintSize(value):\n  \"\"\"Compute the size of a varint value.\"\"\"\n  if value <= 0x7f: return 1\n  if value <= 0x3fff: return 2\n  if value <= 0x1fffff: return 3\n  if value <= 0xfffffff: return 4\n  if value <= 0x7ffffffff: return 5\n  if value <= 0x3ffffffffff: return 6\n  if value <= 0x1ffffffffffff: return 7\n  if value <= 0xffffffffffffff: return 8\n  if value <= 0x7fffffffffffffff: return 9\n  return 10"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signedVarintSize(value):\n  if value < 0: return 10\n  if value <= 0x7f: return 1\n  if value <= 0x3fff: return 2\n  if value <= 0x1fffff: return 3\n  if value <= 0xfffffff: return 4\n  if value <= 0x7ffffffff: return 5\n  if value <= 0x3ffffffffff: return 6\n  if value <= 0x1ffffffffffff: return 7\n  if value <= 0xffffffffffffff: return 8\n  if value <= 0x7fffffffffffffff: return 9\n  return 10", "response": "Compute the size of a signed varint value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _VarintEncoder():\n\n  local_chr = chr\n  def EncodeVarint(write, value):\n    bits = value & 0x7f\n    value >>= 7\n    while value:\n      write(0x80|bits)\n      bits = value & 0x7f\n      value >>= 7\n    return write(bits)\n\n  return EncodeVarint", "response": "Returns an encoder for a basic varint value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _SignedVarintEncoder():\n\n  local_chr = chr\n  def EncodeSignedVarint(write, value):\n    if value < 0:\n      value += (1 << 64)\n    bits = value & 0x7f\n    value >>= 7\n    while value:\n      write(0x80|bits)\n      bits = value & 0x7f\n      value >>= 7\n    return write(bits)\n\n  return EncodeSignedVarint", "response": "Returns an encoder for a basic signed varint value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine whether a value satisfies a query.", "response": "def match(value, query):\n    \"\"\"\n    Determine whether a value satisfies a query.\n    \"\"\"\n    if type(query) in [str, int, float, type(None)]:\n        return value == query\n    elif type(query) == dict and len(query.keys()) == 1:\n        for op in query:\n            if op == \"$eq\": return value == query[op]\n            elif op == \"$lt\": return value < query[op]\n            elif op == \"$lte\": return value <= query[op]\n            elif op == \"$gt\": return value > query[op]\n            elif op == \"$gte\": return value >= query[op]\n            elif op == \"$ne\": return value != query[op]\n            elif op == \"$in\": return value in query[op]\n            elif op == \"$nin\": return value not in query[op]\n            else: GeoQLError(\"Not a valid query operator: \" + op)\n    else:\n        raise GeoQLError(\"Not a valid query: \" + str(query))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef features_properties_null_remove(obj):\n    features = obj['features']\n    for i in tqdm(range(len(features))):\n        if 'properties' in features[i]:\n            properties = features[i]['properties']\n            features[i]['properties'] = {p:properties[p] for p in properties if properties[p] is not None}\n    return obj", "response": "Remove any properties of features that have a null value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing tag strings of all features in the collection into a Python dictionary if possible.", "response": "def features_tags_parse_str_to_dict(obj):\n    \"\"\"\n    Parse tag strings of all features in the collection into a Python\n    dictionary, if possible.\n    \"\"\"\n    features = obj['features']\n    for i in tqdm(range(len(features))):\n        tags = features[i]['properties'].get('tags')\n        if tags is not None:\n            try:\n                tags = json.loads(\"{\" + tags.replace(\"=>\", \":\") + \"}\")\n            except:\n                try:\n                    tags = eval(\"{\" + tags.replace(\"=>\", \":\") + \"}\")\n                except:\n                    tags = None\n        if type(tags) == dict:\n            features[i]['properties']['tags'] = {k:tags[k] for k in tags}\n        elif tags is None and 'tags' in features[i]['properties']:\n            del features[i]['properties']['tags']\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef features_keep_by_property(obj, query):\n    features_keep = []\n    for feature in tqdm(obj['features']):\n        if all([match(feature['properties'].get(prop), qry) for (prop, qry) in query.items()]):\n            features_keep.append(feature)\n    obj['features'] = features_keep\n    return obj", "response": "Filter all features in a collection by retaining only those that satisfy the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef features_keep_within_radius(obj, center, radius, units):\n    features_keep = []\n    for feature in tqdm(obj['features']):\n        if all([getattr(geopy.distance.vincenty((lat,lon), center), units) < radius for (lon,lat) in geojson.utils.coords(feature)]):\n            features_keep.append(feature)\n    obj['features'] = features_keep\n    return obj", "response": "Filter all features in a collection by retaining only those that fall within the specified radius."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef features_keep_using_features(obj, bounds):\n    # Build an R-tree index of bound features and their shapes.\n    bounds_shapes = [\n        (feature, shapely.geometry.shape(feature['geometry'])) \n        for feature in tqdm(bounds['features'])\n        if feature['geometry'] is not None\n      ]\n    index = rtree.index.Index()\n    for i in tqdm(range(len(bounds_shapes))):\n        (feature, shape) = bounds_shapes[i]\n        index.insert(i, shape.bounds)\n\n    features_keep = []\n    for feature in tqdm(obj['features']):\n        if 'geometry' in feature and 'coordinates' in feature['geometry']:\n            coordinates = feature['geometry']['coordinates']\n            if any([\n                shape.contains(shapely.geometry.Point(lon, lat))\n                for (lon, lat) in coordinates\n                for (feature, shape) in [bounds_shapes[i]\n                for i in index.nearest((lon,lat,lon,lat), 1)]\n              ]):\n                features_keep.append(feature)\n                continue\n    obj['features'] = features_keep\n    return obj", "response": "Filter all features in a collection by retaining only those that fall within the features in the second collection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef features_node_edge_graph(obj):\n    points = {}\n    features = obj['features']\n    for feature in tqdm(obj['features']):\n        for (lon, lat) in geojson.utils.coords(feature):\n            points.setdefault((lon, lat), 0)\n            points[(lon, lat)] += 1\n    points = [p for (p, c) in points.items() if c > 1]\n    features = [geojson.Point(p) for p in points]\n\n    # For each feature, split it into \"edge\" features\n    # that occur between every point.\n    for f in tqdm(obj['features']):\n        seqs = []\n        seq = []\n        for point in geojson.utils.coords(f):\n            if len(seq) > 0:\n                seq.append(point)\n            if point in points:\n                seq.append(point)\n                if len(seq) > 1 and seq[0] in points:\n                    seqs.append(seq)\n                    seq = [point]\n        for seq in seqs:\n            features.append(geojson.Feature(geometry={\"coordinates\":seq, \"type\":f['geometry']['type']}, properties=f['properties'], type=f['type']))\n\n    obj['features'] = features\n    return obj", "response": "Transform the features into a more graph - like structure by\n    appropriately splitting the features into two - point edge features that connect Point nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new sqlite3. Connection object with _dict_factory as row factory", "response": "def get_conn(filename):\r\n    \"\"\"Returns new sqlite3.Connection object with _dict_factory() as row factory\"\"\"\r\n    conn = sqlite3.connect(filename)\r\n    conn.row_factory = _dict_factory\r\n    return conn"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conn_is_open(conn):\r\n    if conn is None:\r\n        return False\r\n\r\n    try:\r\n        get_table_names(conn)\r\n        return True\r\n\r\n        # # Idea taken from\r\n        # # http: // stackoverflow.com / questions / 1981392 / how - to - tell - if -python - sqlite - database - connection - or -cursor - is -closed\r\n        # conn.execute(\"select id from molecule limit 1\")\r\n        # return True\r\n    except sqlite3.ProgrammingError as e:\r\n        # print(e)\r\n        return False", "response": "Tests sqlite3 connection returns T or F"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cursor_to_data_header(cursor):\r\n    n = 0\r\n    data, header = [], {}\r\n    for row in cursor:\r\n        if n == 0:\r\n            header = row.keys()\r\n        data.append(row.values())\r\n    return data, list(header)", "response": "Fetches all rows from query (\"cursor\") and returns a pair of data and header"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list element or None if no such element exists.", "response": "def find(self, **kwargs):\r\n        \"\"\"\r\n        Finds row matching specific field value\r\n\r\n        Args:\r\n            **kwargs: (**only one argument accepted**) fielname=value, e.g., formula=\"OH\"\r\n\r\n        Returns: list element or None\r\n        \"\"\"\r\n\r\n        if len(kwargs) != 1:\r\n            raise ValueError(\"One and only one keyword argument accepted\")\r\n\r\n        key = list(kwargs.keys())[0]\r\n        value = list(kwargs.values())[0]\r\n        ret = None\r\n        for row in self.values():\r\n            if row[key] == value:\r\n                ret = row\r\n                break\r\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new user record using POST", "response": "def post(self, data, request, id):\n        \"\"\" Create a new resource using POST \"\"\"\n        if id:\n            # can't post to individual user\n            raise errors.MethodNotAllowed()\n        user = self._dict_to_model(data)\n        user.save()\n        # according to REST, return 201 and Location header\n        return Response(201, None, {\n            'Location': '%s%d' % (reverse('user'), user.pk)})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, request, id):\n        if id:\n            return self._get_one(id)\n        else:\n            return self._get_all()", "response": "Get one or all users"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, data, request, id):\n        if not id:\n            # can't update the whole container\n            raise errors.MethodNotAllowed()\n        userdata = self._dict_to_model(data)\n        userdata.pk = id\n        try:\n            userdata.save(force_update=True)\n        except DatabaseError:\n            # can't udpate non-existing user\n            raise errors.NotFound()", "response": "Update a single user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, request, id):\n        if not id:\n            # can't delete the whole container\n            raise errors.MethodNotAllowed()\n        try:\n            models.User.objects.get(pk=id).delete()\n        except models.User.DoesNotExist:\n            # we never had it, so it's definitely deleted\n            pass", "response": "Delete a single user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets one user from db and turn into dict", "response": "def _get_one(self, id):\n        \"\"\" Get one user from db and turn into dict \"\"\"\n        try:\n            return self._to_dict(models.User.objects.get(pk=id))\n        except models.User.DoesNotExist:\n            raise errors.NotFound()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all users from db and turn into list of dicts", "response": "def _get_all(self):\n        \"\"\" Get all users from db and turn into list of dicts \"\"\"\n        return [self._to_dict(row) for row in models.User.objects.all()]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dict_to_model(self, data):\n\n        try:\n            # we can do this because we have same fields\n            # in the representation and in the model:\n            user = models.User(**data)\n        except TypeError:\n            # client sent bad data\n            raise errors.BadRequest()\n        else:\n            return user", "response": "Create a user model instance based on the received data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the captures for a given uuid optional value withTitles = yes", "response": "def captures(self, uuid, withTitles=False):\n        \"\"\"Return the captures for a given uuid\n            optional value withTitles=yes\"\"\"\n        picker = lambda x: x.get('capture', [])\n        return self._get((uuid,), picker, withTitles='yes' if withTitles else 'no')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uuid(self, type, val):\n        picker = lambda x: x.get('uuid', x)\n        return self._get((type, val), picker)", "response": "Return the item - uuid for a identifier"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching across all or specific field.", "response": "def search(self, q, field=None, page=None, per_page=None):\n        \"\"\"Search across all (without field) or in specific field\n        (valid fields at http://www.loc.gov/standards/mods/mods-outline.html)\"\"\"\n\n        def picker(results):\n            if type(results['result']) == list:\n                return results['result']\n            else:\n                return [results['result']]\n\n        return self._get(('search',), picker, q=q, field=field, page=page, per_page=per_page)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a mods record for a given uuid", "response": "def mods(self, uuid):\n        \"\"\"Return a mods record for a given uuid\"\"\"\n        picker = lambda x: x.get('mods', {})\n        return self._get(('mods', uuid), picker)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_datetext_to_dategui(datetext, ln=None, secs=False):\n    assert ln is None, 'setting language is not supported'\n    try:\n        datestruct = convert_datetext_to_datestruct(datetext)\n        if datestruct == datestruct_default:\n            raise ValueError\n\n        if secs:\n            output_format = \"d MMM Y, H:mm:ss\"\n        else:\n            output_format = \"d MMM Y, H:mm\"\n        dt = datetime.fromtimestamp(time.mktime(datestruct))\n        return babel_format_datetime(dt, output_format)\n    except ValueError:\n        return _(\"N/A\")", "response": "Convert a text string to a dategui formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the datetext from the given year month and day.", "response": "def get_datetext(year, month, day):\n    \"\"\"year=2005, month=11, day=16 => '2005-11-16 00:00:00'\"\"\"\n    input_format = \"%Y-%m-%d\"\n    try:\n        datestruct = time.strptime(\"%i-%i-%i\" % (year, month, day),\n                                   input_format)\n        return strftime(datetext_format, datestruct)\n    except:\n        return datetext_default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_i18n_day_name(day_nb, display='short', ln=None):\n    ln = default_ln(ln)\n    _ = gettext_set_language(ln)\n    if display == 'short':\n        days = {0: _(\"Sun\"),\n                1: _(\"Mon\"),\n                2: _(\"Tue\"),\n                3: _(\"Wed\"),\n                4: _(\"Thu\"),\n                5: _(\"Fri\"),\n                6: _(\"Sat\")}\n    else:\n        days = {0: _(\"Sunday\"),\n                1: _(\"Monday\"),\n                2: _(\"Tuesday\"),\n                3: _(\"Wednesday\"),\n                4: _(\"Thursday\"),\n                5: _(\"Friday\"),\n                6: _(\"Saturday\")}\n\n    return days[day_nb]", "response": "Get the string representation of a weekday internationalized\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a non - numeric representation of a month internationalized.", "response": "def get_i18n_month_name(month_nb, display='short', ln=None):\n    \"\"\"Get a non-numeric representation of a month, internationalized.\n\n    @param month_nb: number of month, (1 based!)\n                     =>1=jan,..,12=dec\n    @param ln: language for output\n    @return: the string representation of month\n    \"\"\"\n    ln = default_ln(ln)\n    _ = gettext_set_language(ln)\n    if display == 'short':\n        months = {0: _(\"Month\"),\n                  1: _(\"Jan\"),\n                  2: _(\"Feb\"),\n                  3: _(\"Mar\"),\n                  4: _(\"Apr\"),\n                  5: _(\"May\"),\n                  6: _(\"Jun\"),\n                  7: _(\"Jul\"),\n                  8: _(\"Aug\"),\n                  9: _(\"Sep\"),\n                  10: _(\"Oct\"),\n                  11: _(\"Nov\"),\n                  12: _(\"Dec\")}\n    else:\n        months = {0: _(\"Month\"),\n                  1: _(\"January\"),\n                  2: _(\"February\"),\n                  3: _(\"March\"),\n                  4: _(\"April\"),\n                  5: _(\"May \"),  # trailing space distinguishes short/long form\n                  6: _(\"June\"),\n                  7: _(\"July\"),\n                  8: _(\"August\"),\n                  9: _(\"September\"),\n                  10: _(\"October\"),\n                  11: _(\"November\"),\n                  12: _(\"December\")}\n    return months[month_nb].strip()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_day_selectbox(name, selected_day=0, ln=None):\n    ln = default_ln(ln)\n    _ = gettext_set_language(ln)\n    out = \"<select name=\\\"%s\\\">\\n\" % name\n    for i in range(0, 32):\n        out += \"  <option value=\\\"%i\\\"\" % i\n        if (i == selected_day):\n            out += \" selected=\\\"selected\\\"\"\n        if (i == 0):\n            out += \">%s</option>\\n\" % _(\"Day\")\n        else:\n            out += \">%i</option>\\n\" % i\n    out += \"</select>\\n\"\n    return out", "response": "Creates an HTML menu for day selection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an HTML menu for month selection.", "response": "def create_month_selectbox(name, selected_month=0, ln=None):\n    \"\"\"Creates an HTML menu for month selection. Value of selected field is\n    numeric.\n\n    @param name: name of the control, your form will be sent with name=value...\n    @param selected_month: preselect a month. use 0 for the Label 'Month'\n    @param ln: language of the menu\n    @return: html as string\n    \"\"\"\n    ln = default_ln(ln)\n    out = \"<select name=\\\"%s\\\">\\n\" % name\n\n    for i in range(0, 13):\n        out += \"<option value=\\\"%i\\\"\" % i\n        if (i == selected_month):\n            out += \" selected=\\\"selected\\\"\"\n        out += \">%s</option>\\n\" % get_i18n_month_name(i, ln)\n    out += \"</select>\\n\"\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an HTML menu for year selection.", "response": "def create_year_selectbox(name, from_year=-1, length=10, selected_year=0,\n                          ln=None):\n    \"\"\"Creates an HTML menu (dropdownbox) for year selection.\n\n    @param name: name of control( i.e. name of the variable you'll get)\n    @param from_year: year on which to begin. if <0 assume it is current year\n    @param length: number of items in menu\n    @param selected_year: initial selected year (if in range), else: label is\n                          selected\n    @param ln: language\n    @return: html as string\n    \"\"\"\n    ln = default_ln(ln)\n    _ = gettext_set_language(ln)\n    if from_year < 0:\n        from_year = time.localtime()[0]\n    out = \"<select name=\\\"%s\\\">\\n\" % name\n    out += '  <option value=\"0\"'\n    if selected_year == 0:\n        out += ' selected=\"selected\"'\n    out += \">%s</option>\\n\" % _(\"Year\")\n    for i in range(from_year, from_year + length):\n        out += \"<option value=\\\"%i\\\"\" % i\n        if (i == selected_year):\n            out += \" selected=\\\"selected\\\"\"\n        out += \">%i</option>\\n\" % i\n    out += \"</select>\\n\"\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_runtime_limit(value, now=None):\n\n    def extract_time(value):\n        value = _RE_RUNTIMELIMIT_HOUR.search(value).groupdict()\n        return timedelta(hours=int(value['hours']),\n                         minutes=int(value['minutes']))\n\n    def extract_weekday(value):\n        key = value[:3].lower()\n        try:\n            return {\n                'mon': 0,\n                'tue': 1,\n                'wed': 2,\n                'thu': 3,\n                'fri': 4,\n                'sat': 5,\n                'sun': 6,\n            }[key]\n        except KeyError:\n            raise ValueError(\"%s is not a good weekday name.\" % value)\n\n    if now is None:\n        now = datetime.now()\n\n    today = now.date()\n    g = _RE_RUNTIMELIMIT_FULL.search(value)\n    if not g:\n        raise ValueError('\"%s\" does not seem to be correct format for '\n                         'parse_runtime_limit() '\n                         '[Wee[kday]] [hh[:mm][-hh[:mm]]]).' % value)\n    pieces = g.groupdict()\n\n    if pieces['weekday_begin'] is None:\n        # No weekday specified. So either today or tomorrow\n        first_occasion_day = timedelta(days=0)\n        next_occasion_delta = timedelta(days=1)\n    else:\n        # If given 'Mon' then we transform it to 'Mon-Mon'\n        if pieces['weekday_end'] is None:\n            pieces['weekday_end'] = pieces['weekday_begin']\n\n        # Day range\n        weekday_begin = extract_weekday(pieces['weekday_begin'])\n        weekday_end = extract_weekday(pieces['weekday_end'])\n\n        if weekday_begin <= today.weekday() <= weekday_end:\n            first_occasion_day = timedelta(days=0)\n        else:\n            days = (weekday_begin - today.weekday()) % 7\n            first_occasion_day = timedelta(days=days)\n\n        weekday = (now + first_occasion_day).weekday()\n        if weekday < weekday_end:\n            # Fits in the same week\n            next_occasion_delta = timedelta(days=1)\n        else:\n            # The week after\n            days = weekday_begin - weekday + 7\n            next_occasion_delta = timedelta(days=days)\n\n    if pieces['hour_begin'] is None:\n        pieces['hour_begin'] = '00:00'\n    if pieces['hour_end'] is None:\n        pieces['hour_end'] = '00:00'\n\n    beginning_time = extract_time(pieces['hour_begin'])\n    ending_time = extract_time(pieces['hour_end'])\n\n    if not ending_time:\n        ending_time = beginning_time + timedelta(days=1)\n    elif beginning_time and ending_time and beginning_time > ending_time:\n        ending_time += timedelta(days=1)\n\n    start_time = real_datetime.combine(today, real_time(hour=0, minute=0))\n    current_range = (\n        start_time + first_occasion_day + beginning_time,\n        start_time + first_occasion_day + ending_time\n    )\n    if now > current_range[1]:\n        current_range = tuple(t + next_occasion_delta for t in current_range)\n\n    future_range = (\n        current_range[0] + next_occasion_delta,\n        current_range[1] + next_occasion_delta\n    )\n    return current_range, future_range", "response": "Parses the value of the VALUE parameter and returns a tuple of two valid time ranges."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to guess the datetime contained in a string of unknow format.", "response": "def guess_datetime(datetime_string):\n    \"\"\"Try to guess the datetime contained in a string of unknow format.\n\n    @param datetime_string: the datetime representation.\n    @type datetime_string: string\n    @return: the guessed time.\n    @rtype: L{time.struct_time}\n    @raises ValueError: in case it's not possible to guess the time.\n    \"\"\"\n    if CFG_HAS_EGENIX_DATETIME:\n        try:\n            return Parser.DateTimeFromString(datetime_string).timetuple()\n        except ValueError:\n            pass\n    else:\n        for format in (None, '%x %X', '%X %x', '%Y-%M-%dT%h:%m:%sZ'):\n            try:\n                return time.strptime(datetime_string, format)\n            except ValueError:\n                pass\n    raise ValueError(\"It is not possible to guess the datetime format of %s\" %\n                     datetime_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a function that returns a time estimation that will take a total amount of items to compute", "response": "def get_time_estimator(total):\n    \"\"\"Given a total amount of items to compute, return a function that,\n    if called every time an item is computed (or every step items are computed)\n    will give a time estimation for how long it will take to compute the whole\n    set of itmes. The function will return two values: the first is the number\n    of seconds that are still needed to compute the whole set, the second value\n    is the time in the future when the operation is expected to end.\n    \"\"\"\n    t1 = time.time()\n    count = [0]\n\n    def estimate_needed_time(step=1):\n        count[0] += step\n        t2 = time.time()\n        t3 = 1.0 * (t2 - t1) / count[0] * (total - count[0])\n        return t3, t3 + t1\n    return estimate_needed_time"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a pretty date string for the current date.", "response": "def pretty_date(ugly_time=False, ln=None):\n    \"\"\"Get a datetime object or a int() Epoch timestamp and return a pretty\n    string like 'an hour ago', 'Yesterday', '3 months ago', 'just now', etc.\n    \"\"\"\n\n    ln = default_ln(ln)\n    _ = gettext_set_language(ln)\n\n    now = real_datetime.now()\n\n    if isinstance(ugly_time, six.string_types):\n        # try to convert it to epoch timestamp\n        date_format = '%Y-%m-%d %H:%M:%S.%f'\n        try:\n            ugly_time = time.strptime(ugly_time, date_format)\n            ugly_time = int(time.mktime(ugly_time))\n        except ValueError:\n            # doesn't match format, let's try to guess\n            try:\n                ugly_time = int(guess_datetime(ugly_time))\n            except ValueError:\n                return ugly_time\n            ugly_time = int(time.mktime(ugly_time))\n\n    # Initialize the time period difference\n    if isinstance(ugly_time, int):\n        diff = now - real_datetime.fromtimestamp(ugly_time)\n    elif isinstance(ugly_time, real_datetime):\n        diff = now - ugly_time\n    elif not ugly_time:\n        diff = now - now\n    second_diff = diff.seconds\n    day_diff = diff.days\n\n    if day_diff < 0:\n        return ''\n\n    if day_diff == 0:\n        if second_diff < 10:\n            return _(\"just now\")\n        if second_diff < 60:\n            return str(second_diff) + _(\" seconds ago\")\n        if second_diff < 120:\n            return _(\"a minute ago\")\n        if second_diff < 3600:\n            return str(second_diff / 60) + _(\" minutes ago\")\n        if second_diff < 7200:\n            return _(\"an hour ago\")\n        if second_diff < 86400:\n            return str(second_diff / 3600) + _(\" hours ago\")\n    if day_diff == 1:\n        return _(\"Yesterday\")\n    if day_diff < 7:\n        return str(day_diff) + _(\" days ago\")\n    if day_diff < 31:\n        if day_diff / 7 == 7:\n            return _(\"Last week\")\n        else:\n            return str(day_diff / 7) + _(\" weeks ago\")\n    if day_diff < 365:\n        if day_diff / 30 == 1:\n            return _(\"Last month\")\n        else:\n            return str(day_diff / 30) + _(\" months ago\")\n    if day_diff / 365 == 1:\n        return _(\"Last year\")\n    else:\n        return str(day_diff / 365) + _(\" years ago\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if dst is locally enabled at this time", "response": "def get_dst(date_obj):\n    \"\"\"Determine if dst is locally enabled at this time\"\"\"\n    dst = 0\n    if date_obj.year >= 1900:\n        tmp_date = time.mktime(date_obj.timetuple())\n        # DST is 1 so reduce time with 1 hour.\n        dst = time.localtime(tmp_date)[-1]\n    return dst"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef utc_to_localtime(\n        date_str,\n        fmt=\"%Y-%m-%d %H:%M:%S\",\n        input_fmt=\"%Y-%m-%dT%H:%M:%SZ\"):\n    \"\"\"\n    Convert UTC to localtime\n\n    Reference:\n     - (1) http://www.openarchives.org/OAI/openarchivesprotocol.html#Dates\n     - (2) http://www.w3.org/TR/NOTE-datetime\n\n    This function works only with dates complying with the\n    \"Complete date plus hours, minutes and seconds\" profile of\n    ISO 8601 defined by (2), and linked from (1).\n\n    Eg:    1994-11-05T13:15:30Z\n    \"\"\"\n    date_struct = datetime.strptime(date_str, input_fmt)\n    date_struct += timedelta(hours=get_dst(date_struct))\n    date_struct -= timedelta(seconds=time.timezone)\n    return strftime(fmt, date_struct)", "response": "Convert UTC to localtime"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute transcriptome - wide nJSD between reference and query expression profiles.", "response": "def njsd_all(network, ref, query, file, verbose=True):\n    \"\"\"Compute transcriptome-wide nJSD between reference and query expression profiles.\n    Attribute:\n        network (str): File path to a network file.\n        ref (str): File path to a reference expression file.\n        query (str): File path to a query expression file.\n    \"\"\"\n    graph, gene_set_total = util.parse_network(network)\n    ref_gene_expression_dict = util.parse_gene_expression(ref, mean=True)\n    query_gene_expression_dict = util.parse_gene_expression(query, mean=False)\n    maximally_ambiguous_gene_experession_dict = util.get_maximally_ambiguous_network(query_gene_expression_dict)\n    gene_set_present = set(query_gene_expression_dict.keys())\n\n    with open(file, 'w') as outFile:\n        print('nJSD_NT', 'nJSD_TA', 'tITH', sep='\\t', file=outFile)\n\n    normal_to_tumor_njsd = entropy.njsd(network=graph,\n                                        ref_gene_expression_dict=ref_gene_expression_dict,\n                                        query_gene_expression_dict=query_gene_expression_dict,\n                                        gene_set=gene_set_present)\n\n    tumor_to_ambiguous_njsd = entropy.njsd(network=graph,\n                                           ref_gene_expression_dict=maximally_ambiguous_gene_experession_dict,\n                                           query_gene_expression_dict=query_gene_expression_dict,\n                                           gene_set=gene_set_present)\n    tITH = normal_to_tumor_njsd / (normal_to_tumor_njsd + tumor_to_ambiguous_njsd)\n\n    with open(file, 'a') as outFile:\n        print(normal_to_tumor_njsd, tumor_to_ambiguous_njsd, tITH, sep='\\t', file=outFile)\n    return normal_to_tumor_njsd / (normal_to_tumor_njsd + tumor_to_ambiguous_njsd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef njsd_geneset(network, ref, query, gene_set, file, verbose=True):\n    graph, gene_set_total = util.parse_network(network)\n    ref_gene_expression_dict = util.parse_gene_expression(ref, mean=True)\n    query_gene_expression_dict = util.parse_gene_expression(query, mean=False)\n    group_gene_set_dict = util.parse_gene_set(gene_set)\n    maximally_ambiguous_gene_experession_dict = util.get_maximally_ambiguous_network(query_gene_expression_dict)\n    gene_set_present = set(query_gene_expression_dict.keys())\n\n    with open(file, 'w') as outFile:\n        print('Gene_set_ID', 'nJSD_NT', 'nJSD_TA', 'tITH', sep='\\t', file=outFile)\n\n    for group, gene_set in group_gene_set_dict.items():\n        gene_set_to_be_analyzed = gene_set.intersection(gene_set_present)\n        # If no genes are available for the group, just ignore it.\n        if len(gene_set_to_be_analyzed) == 0:\n            logger.warning('%s has no genes available for analysis. Ignoring the group.' % group)\n            continue\n\n        # If every gene has a single neighbor, just ignore it.\n        if all([graph.degree(gene) == 1 for gene in gene_set_to_be_analyzed]):\n            logger.warning('%s has no genes with enough neighbors. Ignoring the group.' % group)\n            continue\n\n        normal_to_tumor_njsd = entropy.njsd(network=graph,\n                                            ref_gene_expression_dict=ref_gene_expression_dict,\n                                            query_gene_expression_dict=query_gene_expression_dict,\n                                            gene_set=gene_set)\n\n        tumor_to_ambiguous_njsd = entropy.njsd(network=graph,\n                                               ref_gene_expression_dict=maximally_ambiguous_gene_experession_dict,\n                                               query_gene_expression_dict=query_gene_expression_dict,\n                                               gene_set=gene_set)\n\n        tITH = normal_to_tumor_njsd / (normal_to_tumor_njsd + tumor_to_ambiguous_njsd)\n        with open(file, 'a') as outFile:\n            print(group, normal_to_tumor_njsd, tumor_to_ambiguous_njsd, tITH, sep='\\t', file=outFile)", "response": "Compute the nJSD between a reference expression and a gene set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new Collection AttributeNames", "response": "def create_collection(cls, collection, **kwargs):\n        \"\"\"Create Collection\n\n        Create a new Collection\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_collection(collection, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Collection collection: Attributes of collection to create (required)\n        :return: Collection\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_collection_with_http_info(collection, **kwargs)\n        else:\n            (data) = cls._create_collection_with_http_info(collection, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_collection_by_id(cls, collection_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_collection_by_id_with_http_info(collection_id, **kwargs)\n        else:\n            (data) = cls._delete_collection_by_id_with_http_info(collection_id, **kwargs)\n            return data", "response": "Delete an instance of Collection by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_collection_by_id(cls, collection_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_collection_by_id_with_http_info(collection_id, **kwargs)\n        else:\n            (data) = cls._get_collection_by_id_with_http_info(collection_id, **kwargs)\n            return data", "response": "Find Collection by ID Return single instance of Collection by its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_all_collections(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_collections_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_collections_with_http_info(**kwargs)\n            return data", "response": "List Collections\n        Return a list of Collections\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_collection_by_id(cls, collection_id, collection, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_collection_by_id_with_http_info(collection_id, collection, **kwargs)\n        else:\n            (data) = cls._replace_collection_by_id_with_http_info(collection_id, collection, **kwargs)\n            return data", "response": "Replace all attributes of Collection\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_collection_by_id(cls, collection_id, collection, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_collection_by_id_with_http_info(collection_id, collection, **kwargs)\n        else:\n            (data) = cls._update_collection_by_id_with_http_info(collection_id, collection, **kwargs)\n            return data", "response": "Update attributes of Collection\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setupModule(\n            self):\n        \"\"\"\n        *The setupModule method*\n\n        **Return:**\n            - ``log`` -- a logger\n            - ``dbConn`` -- a database connection to a test database (details from yaml settings file)\n            - ``pathToInputDir`` -- path to modules own test input directory\n            - ``pathToOutputDir`` -- path to modules own test output directory\n        \"\"\"\n        import pymysql as ms\n        ## VARIABLES ##\n        logging.config.dictConfig(yaml.load(self.loggerConfig))\n        log = logging.getLogger(__name__)\n        connDict = yaml.load(self.dbConfig)\n        dbConn = ms.connect(\n            host=connDict['host'],\n            user=connDict['user'],\n            passwd=connDict['password'],\n            db=connDict['db'],\n            use_unicode=True,\n            charset='utf8',\n            local_infile=1,\n            client_flag=ms.constants.CLIENT.MULTI_STATEMENTS,\n            connect_timeout=3600\n        )\n        dbConn.autocommit(True)\n\n        return log, dbConn, self.pathToInputDir, self.pathToOutputDir", "response": "This method sets up the module that will be used to run the test."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_call(self, actual_call, stubbed_call):\n        self._actual_calls.append(actual_call)\n        use_call = stubbed_call or actual_call\n        return use_call.return_value", "response": "Extends Stub call handling behavior to be callable by default."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat the arguments of a call as a string.", "response": "def formatted_args(self):\n        \"\"\"Format call arguments as a string.\n\n        This is used to make test failure messages more helpful by referring\n        to calls using a string that matches how they were, or should have been\n        called.\n\n        >>> call = Call('arg1', 'arg2', kwarg='kwarg')\n        >>> call.formatted_args\n        \"('arg1', 'arg2', kwarg='kwarg')\"\n\n        \"\"\"\n        arg_reprs = list(map(repr, self.args))\n        kwarg_reprs = ['%s=%s' % (k, repr(v)) for k, v in self.kwargs.items()]\n        return '(%s)' % ', '.join(arg_reprs + kwarg_reprs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef passing(self, *args, **kwargs):\n        self.args = args\n        self.kwargs = kwargs\n        return self", "response": "Assign expected call args and kwargs to this call. Returns self for the common case of chaining a call to Call. returns"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if data and third party tools are available.", "response": "def check(self):\n        \"\"\" Check if data and third party tools are available\n\n        :raises: RuntimeError\n        \"\"\"\n\n        #for path in self.path.values():\n        #    if not os.path.exists(path):\n        #        raise RuntimeError(\"File '{}' is missing\".format(path))\n\n        for tool in ('cd-hit', 'prank', 'hmmbuild', 'hmmpress', 'hmmscan', 'phmmer', 'mafft', 'meme'):\n            if not self.pathfinder.exists(tool):\n                raise RuntimeError(\"Dependency {} is missing\".format(tool))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bubble_to_dot(bblfile:str, dotfile:str=None, render:bool=False,\n                  oriented:bool=False):\n    \"\"\"Write in dotfile a graph equivalent to those depicted in bubble file\"\"\"\n    tree = BubbleTree.from_bubble_file(bblfile, oriented=bool(oriented))\n    return tree_to_dot(tree, dotfile, render=render)", "response": "Write in dotfile a graph equivalent to those depicted in bubble file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite in bblfile a graph equivalent to those depicted in bubble file", "response": "def bubble_to_gexf(bblfile:str, gexffile:str=None, oriented:bool=False):\n    \"\"\"Write in bblfile a graph equivalent to those depicted in bubble file\"\"\"\n    tree = BubbleTree.from_bubble_file(bblfile, oriented=bool(oriented))\n    gexf_converter.tree_to_file(tree, gexffile)\n    return gexffile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite in jsdir a graph equivalent to those depicted in bubble file", "response": "def bubble_to_js(bblfile:str, jsdir:str=None, oriented:bool=False, **style):\n    \"\"\"Write in jsdir a graph equivalent to those depicted in bubble file\"\"\"\n    js_converter.bubble_to_dir(bblfile, jsdir, oriented=bool(oriented), **style)\n    return jsdir"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tree_to_dot(tree:BubbleTree, dotfile:str=None, render:bool=False):\n    graph = tree_to_graph(tree)\n    path = None\n    if dotfile:  # first save the dot file.\n        path = graph.save(dotfile)\n    if render:  # secondly, show it.\n        # As the dot file is known by the Graph object,\n        # it will be placed around the dot file.\n        graph.view()\n    return path", "response": "Write in dotfile a graph equivalent to those depicted in bubble file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tree_to_graph(bbltree:BubbleTree) -> Graph or Digraph:\n    GraphObject = Digraph if bbltree.oriented else Graph\n    def create(name:str):\n        \"\"\"Return a graphviz graph figurating a powernode\"\"\"\n        ret = GraphObject('cluster_' + name)\n        # dirty hack to get links between clusters: add a blank node inside\n        # so the subgraph don't take it's name directly, but the blank node do.\n        # ret.body.append('label = \"{}\"'.format(name))  # replaced by:\n        ret.node(name, style='invis', shape='point')\n        # ret.body.append('style=plaintext')\n        ret.body.append('color=lightgrey')\n        ret.body.append('label=\"\"')\n        ret.body.append('shape=ellipse')\n        ret.body.append('penwidth=2')\n        ret.body.append('pencolor=black')\n        return ret\n    nodes = frozenset(bbltree.nodes())\n    subgraphs = {}\n    # build for each powernode the associated subgraph, and add its successors\n    for powernode in bbltree.powernodes():\n        if powernode not in subgraphs:\n            subgraphs[powernode] = create(powernode)\n        for succ in bbltree.inclusions[powernode]:\n            if succ not in subgraphs:\n                if succ not in nodes:\n                    subgraphs[succ] = create(succ)\n                else:\n                    subgraphs[powernode].node(succ)\n    # add to Graph instances the Graph of successors as subgraphs \n    for powernode, succs in bbltree.inclusions.items():\n        for succ in succs:\n            if succ not in nodes:\n                subgraphs[powernode].subgraph(subgraphs[succ])\n    # build the final graph by adding to it subgraphs of roots\n    graph = GraphObject('graph', graph_attr={'compound': 'true'})\n    for root in bbltree.roots:\n        if root in subgraphs:\n            graph.subgraph(subgraphs[root])\n    # add the edges to the final graph\n    for source, targets in bbltree.edges.items():\n        for target in targets:\n            if source <= target:\n                attrs = {}\n                if source not in nodes:\n                    attrs.update({'ltail': 'cluster_' + source})\n                if target not in nodes:\n                    attrs.update({'lhead': 'cluster_' + target})\n                graph.edge(source, target, **attrs)\n    # print(graph)  # debug line\n    # graph.view()  # debug line\n    return graph", "response": "Convert a BubbleTree instance to a graphviz. Graph instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fill(self, term_dict, terms):\n        # type: (Dict[int, Set[Type[Rule]]], Any) -> None\n        \"\"\"\n        Fill first row of the structure witch nonterminal directly rewritable to terminal.\n        :param term_dict: Dictionary of rules directly rewritable to terminal.\n        Key is hash of terminal, value is set of rules with key terminal at the right side.\n        :param terms: Input sequence of terminal.\n        \"\"\"\n        for i in range(len(terms)):\n            t = terms[i]\n            self._field[0][i] += term_dict[hash(t)]", "response": "Fill the internal structure witch nonterminal directly rewritable to terminal."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of rules at specific position in the structure.", "response": "def rules(self, x, y):\n        # type: (int, int) -> List[Type[Rule]]\n        \"\"\"\n        Get rules at specific position in the structure.\n        :param x: X coordinate\n        :param y: Y coordinate\n        :return: List of rules\n        \"\"\"\n        return [r for r in self._field[y][x]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all positions that can be combined to get word parsed at specified position.", "response": "def positions(self, x, y):\n        # type: (int, int) -> List[(Point, Point)]\n        \"\"\"\n        Get all positions, that can be combined to get word parsed at specified position.\n        :param x: X coordinate.\n        :param y: Y coordinate.\n        :return: List of tuples with two Point instances.\n        \"\"\"\n        return [(Point(x, v), Point(x + 1 + v, y - 1 - v)) for v in range(y)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef put(self, x, y, rules):\n        # type: (int, int, List[PlaceItem]) -> None\n        \"\"\"\n        Set possible rules at specific position.\n        :param x: X coordinate.\n        :param y: Y coordinate.\n        :param rules: Value to set.\n        \"\"\"\n        self._field[y][x] = rules", "response": "Set possible rules at specific position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef froze_it(cls):\r\n    cls._frozen = False\r\n\r\n    def frozensetattr(self, key, value):\r\n        if self._frozen and not hasattr(self, key):\r\n            raise AttributeError(\"Attribute '{}' of class '{}' does not exist!\"\r\n                  .format(key, cls.__name__))\r\n        else:\r\n            object.__setattr__(self, key, value)\r\n\r\n    def init_decorator(func):\r\n        @wraps(func)\r\n        def wrapper(self, *args, **kwargs):\r\n            func(self, *args, **kwargs)\r\n            self._frozen = True\r\n        return wrapper\r\n\r\n    cls.__setattr__ = frozensetattr\r\n    cls.__init__ = init_decorator(cls.__init__)\r\n\r\n    return cls", "response": "A class decorator that marks the object as frozen."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn string that is shorter than str() and not contain newline", "response": "def one_liner_str(self):\r\n        \"\"\"Returns string (supposed to be) shorter than str() and not contain newline\"\"\"\r\n        assert self.less_attrs is not None, \"Forgot to set attrs class variable\"\r\n        s_format = \"{}={}\"\r\n        s = \"; \".join([s_format.format(x, self.__getattribute__(x)) for x in self.less_attrs])\r\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\r\n        ret = OrderedDict()\r\n        for attrname in self.attrs:\r\n            ret[attrname] = self.__getattribute__(attrname)\r\n        return ret", "response": "Returns an OrderedDict whose keys are self. attrs and whose values are self. attrs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_list(self):\r\n\r\n        ret = OrderedDict()\r\n        for attrname in self.attrs:\r\n            ret[attrname] = self.__getattribute__(attrname)\r\n        return ret", "response": "Returns a list containing values of attributes listed in self. attrs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield count_items_in_chunk items from list_", "response": "def chunks(list_, count_items_in_chunk):\n    \"\"\"\n    \u0440\u0430\u0437\u0431\u0438\u0442\u044c list (l) \u043d\u0430 \u043a\u0443\u0441\u043a\u0438 \u043f\u043e n \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432\n\n    :param list_:\n    :param count_items_in_chunk:\n    :return:\n    \"\"\"\n    for i in range(0, len(list_), count_items_in_chunk):\n        yield list_[i:i + count_items_in_chunk]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pretty_json(obj):\n    return json.dumps(obj, sort_keys=True, indent=4, separators=(',', ': '), ensure_ascii=False)", "response": "Pretty json - > json"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes a JWT string into a list of sub - items.", "response": "def decode_jwt(input_text, secure_key):\n    \"\"\"\n    \u0420\u0430\u0441\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0441\u0442\u0440\u043e\u043a\u0438 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043a\u043b\u044e\u0447\u0430\n    :param input_text: \u0438\u0441\u0445\u043e\u0434\u043d\u0430\u044f \u0441\u0442\u0440\u043e\u043a\u0430\n    :param secure_key: \u0441\u0435\u043a\u0440\u0435\u0442\u043d\u044b\u0439 \u043a\u043b\u044e\u0447\n    :return:\n    \"\"\"\n    if input_text is None:\n        return None\n\n    encoded = (input_text.split(\":\")[1]).encode('utf-8')\n    decoded = jwt.decode(encoded, secure_key)\n    return decoded['sub']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a request to the url.", "response": "def send_request(url, method, data, \n\targs, params, headers, cookies, timeout, is_json, verify_cert):\n\t\"\"\"\n\tForge and send HTTP request.\n\t\"\"\"\n\t## Parse url args\n\tfor p in args:\n\t\turl = url.replace(':' + p, str(args[p]))\n\n\ttry:\n\t\tif data:\n\t\t\tif is_json:\n\t\t\t\theaders['Content-Type'] = 'application/json'\n\t\t\t\tdata = json.dumps(data)\n\n\t\t\trequest = requests.Request(\n\t\t\t\tmethod.upper(), url, data=data, params=params, \n\t\t\t\theaders=headers, cookies=cookies\n\t\t\t)\n\t\telse:\n\t\t\trequest = requests.Request(\n\t\t\t\tmethod.upper(), url, params=params, headers=headers, \n\t\t\t\tcookies=cookies\n\t\t\t)\n\n\t\t## Prepare and send HTTP request.\n\t\tsession = requests.Session()\n\t\tsession.verify = verify_cert\n\t\tr = session.send(request.prepare(), timeout=timeout)\n\t\tsession.close()\n\n\texcept requests.exceptions.Timeout:\n\t\treturn {\n\t\t\t'data': {}, \n\t\t\t'cookies': CookieJar(),\n\t\t\t'content_type': '', \n\t\t\t'status': 0, \n\t\t\t'is_json': False,\n\t\t\t'timeout': True\n\t\t}\n\n\ttry:\n\t\tcontent_type = r.headers.get('Content-Type', 'application/json')\n\t\tresponse = r.json()\n\t\tisjson = True\n\t\t\n\texcept json.decoder.JSONDecodeError:\n\t\tcontent_type = r.headers.get('Content-Type', 'text/html')\n\t\tresponse = r.text\n\t\tisjson = False\n\n\treturn {\n\t\t'data': response,\n\t\t'cookies': r.cookies,\n\t\t'content_type': content_type, \n\t\t'status': r.status_code,\n\t\t'is_json': isjson,\n\t\t'timeout': False\n\t}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef neighbors(self) -> List['Node']:\r\n        self._load_neighbors()\r\n        return [edge.source if edge.source != self else edge.target\r\n                for edge in self._neighbors.values()]", "response": "Returns a list of nodes that are connected to this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new neighbor to the node.", "response": "def add_neighbor(self, edge: \"Edge\") -> None:\r\n        \"\"\"\r\n        Adds a new neighbor to the node.\r\n\r\n        Arguments:\r\n            edge (Edge): The edge that would connect this node with its neighbor.\r\n        \"\"\"\r\n        if edge is None or (edge.source != self and edge.target != self):\r\n            return\r\n\r\n        if edge.source == self:\r\n            other: Node = edge.target\r\n        elif edge.target == self:\r\n            other: Node = edge.source\r\n        else:\r\n            raise ValueError(\"Tried to add a neighbor with an invalid edge.\")\r\n\r\n        edge_key: Tuple(int, int) = edge.key\r\n\r\n        # The graph is considered undirected, check neighbor existence accordingly.\r\n        if self._neighbors.get(edge_key) or self._neighbors.get((edge_key[1], edge_key[0])):\r\n            return  # The neighbor is already added.\r\n\r\n        self._neighbors[edge_key] = edge\r\n        self.dispatch_event(NeighborAddedEvent(other))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading all neighbors of the node from the local database if needed.", "response": "def _load_neighbors(self) -> None:\r\n        \"\"\"\r\n        Loads all neighbors of the node from the local database and\r\n        from the external data source if needed.\r\n        \"\"\"\r\n        if not self.are_neighbors_cached:\r\n            self._load_neighbors_from_external_source()\r\n            db: GraphDatabaseInterface = self._graph.database\r\n            db_node: DBNode = db.Node.find_by_name(self.name)\r\n            db_node.are_neighbors_cached = True\r\n            db.session.commit()\r\n            self.are_neighbors_cached = True\r\n        if not self._are_neighbors_loaded:\r\n            self._load_neighbors_from_database()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_neighbors_from_database(self) -> None:\r\n        self._are_neighbors_loaded = True\r\n\r\n        graph: Graph = self._graph\r\n        neighbors: List[DBNode] = graph.database.Node.find_by_name(self.name).neighbors\r\n        nodes: NodeList = graph.nodes\r\n\r\n        for db_node in neighbors:\r\n            graph.add_node(db_node.name, db_node.external_id)\r\n            neighbor: Node = nodes.get_node_by_name(db_node.name)\r\n            graph.add_edge(self, neighbor, 1, False)", "response": "Loads the neighbors of the node from the local database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef key(self) -> Tuple[int, int]:\r\n        return self._source.index, self._target.index", "response": "Returns the unique identifier of the edge in the source and target nodes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_node_by_name(self, node_name: str, external_id: Optional[str] = None) -> None:\r\n        if node_name is None:\r\n            return\r\n\r\n        node_name = node_name.strip()\r\n        if len(node_name) == 0:\r\n            return\r\n\r\n        node: Node = self.get_node_by_name(node_name, external_id=external_id)\r\n        if node is None:\r\n            self._internal_add_node(node_name=node_name,\r\n                                    external_id=external_id,\r\n                                    are_neighbors_cached=False,\r\n                                    add_to_cache=True)", "response": "Adds a new node to the graph if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_node(self, index: int) -> Optional[Node]:\r\n        return self._nodes.get(index)", "response": "Returns the node with the given index if such a node currently exists in the node list or None otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the node with the given name if it exists in the database or in the database cache.", "response": "def get_node_by_name(self, node_name: str,\r\n                         can_validate_and_load: bool = False,\r\n                         external_id: Optional[str] = None) -> Optional[Node]:\r\n        \"\"\"\r\n        Returns the node with the given name if it exists either in the graph\r\n        or in its database cache or `None` otherwise.\r\n\r\n        Arguments:\r\n            node_name (str): The name of the node to return.\r\n            can_validate_and_load (bool): Whether `self._graph.get_authentic_node_name(node_name)`\r\n                                          can be called to validate the node name and add the node\r\n                                          to the graph if the node name is valid.\r\n            external_id (Optional[str]): An optional external ID that is used only if there no node\r\n                                         with the given name in the graph or in the cache and\r\n                                         `can_validate_and_load` is `True`.\r\n\r\n        Returns:\r\n            The node with the given name if it exists either in the graph\r\n            or in its database cache, `None` otherwise.\r\n        \"\"\"\r\n        node: Node = self._node_name_map.get(node_name)\r\n        if node is not None:\r\n            return node\r\n\r\n        db_node: DBNode = self._graph.database.Node.find_by_name(node_name)\r\n        if db_node is None:\r\n            if can_validate_and_load:\r\n                node_name = self._graph.get_authentic_node_name(node_name)\r\n                if node_name is not None:\r\n                    node = self._node_name_map.get(node_name)\r\n                    if node is not None:\r\n                        return node\r\n\r\n                    db_node = self._graph.database.Node.find_by_name(node_name)\r\n                    if db_node is None:\r\n                        self._internal_add_node(node_name=node_name,\r\n                                                external_id=external_id,\r\n                                                are_neighbors_cached=False,\r\n                                                add_to_cache=True)\r\n                    else:\r\n                        self._internal_add_node(node_name=db_node.name,\r\n                                                external_id=db_node.external_id,\r\n                                                are_neighbors_cached=db_node.are_neighbors_cached,\r\n                                                add_to_cache=False)\r\n            else:\r\n                return None\r\n        else:\r\n            self._internal_add_node(node_name=db_node.name,\r\n                                    external_id=db_node.external_id,\r\n                                    are_neighbors_cached=db_node.are_neighbors_cached,\r\n                                    add_to_cache=False)\r\n\r\n        node = self._node_name_map.get(node_name)\r\n\r\n        # Trying to load the cached neighbors of the created node from the database could\r\n        # cause a very-very-very deep recursion, so don't even think about doing it here.\r\n\r\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a node to the graph without checking whether it already exists or not.", "response": "def _internal_add_node(self,\r\n                           node_name: str,\r\n                           external_id: Optional[str] = None,\r\n                           are_neighbors_cached: bool = False,\r\n                           add_to_cache: bool = False) -> None:\r\n        \"\"\"\r\n        Adds a node with the given name to the graph without checking whether it already exists or not.\r\n\r\n        Arguments:\r\n            node_name (str): The name of the node to add.\r\n            external_id (Optional[str]): The external ID of the node.\r\n            are_neighbors_cached (bool): Whether the neighbors of the node have already been cached.\r\n            add_to_cache (bool): Whether the node should also be created in the local cache.\r\n        \"\"\"\r\n        index: int = len(self)\r\n        node: Node = self._create_node(index, node_name, external_id)\r\n        node.are_neighbors_cached = are_neighbors_cached\r\n        self._nodes[index] = node\r\n        self._node_name_map[node_name] = node\r\n\r\n        if add_to_cache:\r\n            db: GraphDatabaseInterface = self._graph.database\r\n            db_node: DBNode = db.Node.find_by_name(node.name)\r\n            if db_node is None:\r\n                db_node = db.Node(node.name, node.external_id)\r\n                db_node.are_neighbors_cached = False\r\n                db.session.add(db_node)\r\n                db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of edges in the current container ordered by the time of the edge.", "response": "def edge_list(self) -> List[Edge]:\r\n        \"\"\"\r\n        The ordered list of edges in the container.\r\n        \"\"\"\r\n        return [edge for edge in sorted(self._edges.values(), key=attrgetter(\"key\"))]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_edge(self,\r\n                 source: Node,\r\n                 target: Node,\r\n                 weight: float = 1,\r\n                 save_to_cache: bool = True) -> None:\r\n        \"\"\"\r\n        Adds an edge to the edge list that will connect the specified nodes.\r\n\r\n        Arguments:\r\n            source (Node): The source node of the edge.\r\n            target (Node): The target node of the edge.\r\n            weight (float): The weight of the created edge.\r\n            save_to_cache (bool): Whether the edge should be saved to the local database.\r\n        \"\"\"\r\n        if not isinstance(source, Node):\r\n            raise TypeError(\"Invalid source: expected Node instance, got {}.\".format(source))\r\n        if not isinstance(target, Node):\r\n            raise TypeError(\"Invalid target: expected Node instance, got {}.\".format(target))\r\n\r\n        if source.index == target.index or\\\r\n           self.get_edge_by_index(source.index, target.index) is not None:\r\n            return\r\n\r\n        self._edges[(source.index, target.index)] = Edge(source, target, weight)\r\n\r\n        if save_to_cache:\r\n            should_commit: bool = False\r\n            database: GraphDatabaseInterface = self._graph.database\r\n            db_edge: DBEdge = database.Edge.find_by_name(source.name, target.name)\r\n            if db_edge is None:\r\n                database.session.add(database.Edge(source.name, target.name, weight))\r\n                should_commit = True\r\n            elif db_edge.weight != weight:\r\n                db_edge.weight = weight\r\n                should_commit = True\r\n\r\n            if should_commit:\r\n                database.session.commit()", "response": "Adds an edge to the edge list that will connect the specified nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_edge(self, source: Node, target: Node) -> Optional[Edge]:\r\n        return self.get_edge_by_index(source.index, target.index)", "response": "Returns the edge that connects two nodes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the edge with the specified indices or None if no such edge exists.", "response": "def get_edge_by_index(self, source_index: int, target_index: int) -> Optional[Edge]:\r\n        \"\"\"\r\n        Returns the edge connecting the nodes with the specified indices if such an edge exists.\r\n\r\n        Arguments:\r\n            source_index (int): The index of one of the endpoints of queried edge.\r\n            target_index (int): The index of the other endpoint of the queried edge.\r\n\r\n        Returns:\r\n            The edge connecting the nodes with the specified indices\r\n            or `None` if no such node exists.\r\n        \"\"\"\r\n        edge = self._edges.get((source_index, target_index))\r\n        if edge is not None:\r\n            return edge\r\n        return self._edges.get((target_index, source_index))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the edge connecting the nodes with the specified names if such an edge exists or None if no such edge exists.", "response": "def get_edge_by_name(self, source_name: str, target_name: str) -> Optional[Edge]:\r\n        \"\"\"\r\n        Returns the edge connecting the nodes with the specified names if such an edge exists.\r\n\r\n        Arguments:\r\n            source_name (str): The name of one of the endpoints of queried edge.\r\n            target_name (str): The name of the other endpoint of the queried edge.\r\n\r\n        Returns:\r\n            The edge connecting the nodes with the specified names\r\n            or `None` if no such node exists.\r\n        \"\"\"\r\n        nodes: NodeList = self._graph.nodes\r\n        source: Optional[Node] = nodes.get_node_by_name(source_name)\r\n        if source is None:\r\n            return None\r\n        target: Optional[Node] = nodes.get_node_by_name(target_name)\r\n        if target is None:\r\n            return None\r\n        return self.get_edge_by_index(source.index, target.index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an edge between two nodes.", "response": "def add_edge(self, source: Node,\r\n                 target: Node,\r\n                 weight: float = 1,\r\n                 save_to_cache: bool = True) -> None:\r\n        \"\"\"\r\n        Adds an edge between the specified nodes of the graph.\r\n\r\n        Arguments:\r\n            source (Node): The source node of the edge to add.\r\n            target (Node): The target node of the edge to add.\r\n            weight (float): The weight of the edge.\r\n            save_to_cache (bool): Whether the edge should be saved to the local database. This\r\n                                  argument is necessary (and `False`) when we load edges from\r\n                                  the local cache.\r\n        \"\"\"\r\n        if self._edges.get_edge(source, target) is not None:\r\n            return\r\n\r\n        self._edges.add_edge(\r\n            source=source,\r\n            target=target,\r\n            weight=weight,\r\n            save_to_cache=save_to_cache\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_edge_by_index(self, source_index: int, target_index: int,\r\n                          weight: float, save_to_cache: bool = True) -> None:\r\n        \"\"\"\r\n        Adds an edge between the nodes with the specified indices to the graph.\r\n\r\n        Arguments:\r\n            source_index (int): The index of the source node of the edge to add.\r\n            target_index (int): The index of the target node of the edge to add.\r\n            weight (float): The weight of the edge.\r\n            save_to_cache (bool): Whether the edge should be saved to the local database. This\r\n                                  argument is necessary (and `False`) when we load edges from\r\n                                  the local cache.\r\n        \"\"\"\r\n        source: Node = self._nodes.get_node(source_index)\r\n        target: Node = self._nodes.get_node(target_index)\r\n        if source is None or target is None:\r\n            return\r\n\r\n        self.add_edge(\r\n            source=source,\r\n            target=target,\r\n            weight=weight,\r\n            save_to_cache=save_to_cache\r\n        )", "response": "Adds an edge between the nodes with the specified indices to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_node(self, node_name: str, external_id: Optional[str] = None) -> None:\r\n        self._nodes.add_node_by_name(node_name, external_id)", "response": "Adds a node to the set of nodes in the current set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_authentic_node_name(self, node_name: str) -> Optional[str]:\r\n        node: Node = self._nodes.get_node_by_name(node_name)\r\n        return node.name if node is not None else None", "response": "Returns the exact authentic node name for the given node name or None if no such node exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake text and separates it into a list of words", "response": "def separate(text):\n    '''Takes text and separates it into a list of words'''\n    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n    words = text.split()\n    standardwords = []\n    for word in words:\n        newstr = ''\n        for char in word:\n            if char in alphabet or char in alphabet.upper():\n               newstr += char\n        if newstr != '':\n            standardwords.append(newstr)\n    return map(lambda x: x.lower(),standardwords)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eliminate_repeats(text):\n    '''Returns a list of words that occur in the text. Eliminates stopwords.'''\n    \n    bannedwords = read_file('stopwords.txt')\n    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n    words = text.split()\n    standardwords = []\n    for word in words:\n        newstr = ''\n        for char in word:\n            if char in alphabet or char in alphabet.upper():\n               newstr += char\n        if newstr not in standardwords and newstr != '' and newstr not in bannedwords:\n            standardwords.append(newstr)\n        \n    return map(lambda x: x.lower(),standardwords)", "response": "Returns a list of words that occur in the text. Eliminates stopwords."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wordcount(text):\n    '''Returns the count of the words in a file.'''\n    bannedwords = read_file('stopwords.txt')\n    wordcount = {}\n    separated = separate(text)\n    for word in separated:\n        if word not in bannedwords:\n            if not wordcount.has_key(word):\n                wordcount[word] = 1\n            else:\n                wordcount[word] += 1\n    return wordcount", "response": "Returns the count of the words in a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges a dictionary into a list of tuples.", "response": "def tuplecount(text):\n    '''Changes a dictionary into a list of tuples.'''\n    worddict = wordcount(text)\n    countlist = []\n    for key in worddict.keys():\n        countlist.append((key,worddict[key]))\n    countlist = list(reversed(sorted(countlist,key = lambda x: x[1])))\n    return countlist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a log error message to the log.", "response": "def add_log_error(self, x, flag_also_show=False, E=None):\r\n        \"\"\"Delegates to parent form\"\"\"\r\n        self.parent_form.add_log_error(x, flag_also_show, E)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_log(self, x, flag_also_show=False):\r\n        self.parent_form.add_log(x, flag_also_show)", "response": "Adds a log entry to the log table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_md5(filename):\n    if os.path.exists(filename):\n        blocksize = 65536\n        try:\n            hasher = hashlib.md5()\n        except BaseException:\n            hasher = hashlib.new('md5', usedForSecurity=False)\n        with open(filename, 'rb') as afile:\n            buf = afile.read(blocksize)\n            while len(buf) > 0:  # pylint: disable=len-as-condition\n                hasher.update(buf)\n                buf = afile.read(blocksize)\n        return hasher.hexdigest()\n\n    return ''", "response": "Get a file s MD5"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a string s MD5", "response": "def get_md5(string):\n    \"\"\"Get a string's MD5\"\"\"\n    try:\n        hasher = hashlib.md5()\n    except BaseException:\n        hasher = hashlib.new('md5', usedForSecurity=False)\n    hasher.update(string)\n    return hasher.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deploy_signature(source, dest, user=None, group=None):\n    move(source, dest)\n    os.chmod(dest, 0644)\n    if user and group:\n        try:\n            uid = pwd.getpwnam(user).pw_uid\n            gid = grp.getgrnam(group).gr_gid\n            os.chown(dest, uid, gid)\n        except (KeyError, OSError):\n            pass", "response": "Deploy a signature fole"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the local version of a signature", "response": "def get_local_version(sigdir, sig):\n    \"\"\"Get the local version of a signature\"\"\"\n    version = None\n    filename = os.path.join(sigdir, '%s.cvd' % sig)\n    if os.path.exists(filename):\n        cmd = ['sigtool', '-i', filename]\n        sigtool = Popen(cmd, stdout=PIPE, stderr=PIPE)\n        while True:\n            line = sigtool.stdout.readline()\n            if line and line.startswith('Version:'):\n                version = line.split()[1]\n                break\n            if not line:\n                break\n        sigtool.wait()\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying a signature file", "response": "def verify_sigfile(sigdir, sig):\n    \"\"\"Verify a signature file\"\"\"\n    cmd = ['sigtool', '-i', '%s/%s.cvd' % (sigdir, sig)]\n    sigtool = Popen(cmd, stdout=PIPE, stderr=PIPE)\n    ret_val = sigtool.wait()\n    return ret_val == 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload signature from hostname", "response": "def download_sig(opts, sig, version=None):\n    \"\"\"Download signature from hostname\"\"\"\n    code = None\n    downloaded = False\n    useagent = 'ClamAV/0.101.1 (OS: linux-gnu, ARCH: x86_64, CPU: x86_64)'\n    manager = PoolManager(\n        headers=make_headers(user_agent=useagent),\n        cert_reqs='CERT_REQUIRED',\n        ca_certs=certifi.where(),\n        timeout=Timeout(connect=10.0, read=60.0)\n    )\n    if version:\n        path = '/%s.cvd' % sig\n        filename = os.path.join(opts.workdir, '%s.cvd' % sig)\n    else:\n        path = '/%s.cdiff' % sig\n        filename = os.path.join(opts.workdir, '%s.cdiff' % sig)\n    try:\n        req = manager.request('GET', 'http://%s%s' % (opts.hostname, path))\n    except BaseException as msg:\n        error(\"Request error: %s\" % msg)\n    data = req.data\n    code = req.status\n    if req.status == 200:\n        with open(filename, 'w') as handle:\n            handle.write(data)\n        downloaded = os.path.exists(filename)\n    return downloaded, code"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_record(opts):\n    count = 1\n    for passno in range(1, 5):\n        count = passno\n        info(\"[+] \\033[92mQuerying TXT record:\\033[0m %s pass: %s\" %\n             (opts.txtrecord, passno))\n        record = get_txt_record(opts.txtrecord)\n        if record:\n            info(\"=> Query returned: %s\" % record)\n            break\n        else:\n            info(\"=> Txt record query failed, sleeping 5 secs\")\n            time.sleep(5)\n    if not record:\n        error(\"=> Txt record query failed after %d tries\" % count)\n        sys.exit(3)\n    return record", "response": "Get record from TXT record"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_sig(queue):\n    while True:\n        options, sign, vers = queue.get()\n        info(\"[+] \\033[92mChecking signature version:\\033[0m %s\" % sign)\n        localver = get_local_version(options.mirrordir, sign)\n        remotever = vers[sign]\n        if localver is None or (localver and int(localver) < int(remotever)):\n            info(\"=> Update required local: %s => remote: %s\" %\n                 (localver, remotever))\n            info(\"=> Downloading signature: %s\" % sign)\n            status, code = download_sig(options, sign, remotever)\n            if status:\n                info(\"=> Downloaded signature: %s\" % sign)\n                copy_sig(sign, options, 0)\n            else:\n                if code == 404:\n                    error(\"=> \\033[91mSignature:\\033[0m %s not found\" % sign)\n                error(\"=> \\033[91mDownload failed:\\033[0m %s code: %d\"\n                      % (sign, code))\n        else:\n            info(\n                \"=> No update required L: %s => R: %s\" % (localver, remotever))\n        queue.task_done()", "response": "update signature of all the items in the queue"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_diff(opts, sig):\n    for _ in range(1, 6):\n        info(\"[+] \\033[92mDownloading cdiff:\\033[0m %s\" % sig)\n        status, code = download_sig(opts, sig)\n        if status:\n            info(\"=> Downloaded cdiff: %s\" % sig)\n            copy_sig(sig, opts, 1)\n        else:\n            if code == 404:\n                error(\"=> \\033[91mSignature:\\033[0m %s not found\" % sig)\n            error(\"=> \\033[91mDownload failed:\\033[0m %s code: %d\"\n                  % (sig, code))", "response": "Update the diff of the current cdiff with the new one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_dns_file(opts, record):\n    info(\"[+] \\033[92mUpdating dns.txt file\\033[0m\")\n    filename = os.path.join(opts.mirrordir, 'dns.txt')\n    localmd5 = get_file_md5(filename)\n    remotemd5 = get_md5(record)\n    if localmd5 != remotemd5:\n        create_file(filename, record)\n        info(\"=> dns.txt file updated\")\n    else:\n        info(\"=> No update required L: %s => R: %s\" % (localmd5, remotemd5))", "response": "Create the DNS record file"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads the cdiff files from the queue until the file is found", "response": "def download_diffs(queue):\n    \"\"\"Download the cdiff files\"\"\"\n    while True:\n        options, signature_type, localver, remotever = queue.get()\n        for num in range(int(localver), int(remotever) + 1):\n            sig_diff = '%s-%d' % (signature_type, num)\n            filename = os.path.join(options.mirrordir, '%s.cdiff' % sig_diff)\n            if not os.path.exists(filename):\n                update_diff(options, sig_diff)\n        queue.task_done()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n    parser = OptionParser()\n    parser.add_option('-a', '--hostname',\n                      help='ClamAV source server hostname',\n                      dest='hostname',\n                      type='str',\n                      default='db.de.clamav.net')\n    parser.add_option('-r', '--text-record',\n                      help='ClamAV Updates TXT record',\n                      dest='txtrecord',\n                      type='str',\n                      default='current.cvd.clamav.net')\n    parser.add_option('-w', '--work-directory',\n                      help='Working directory',\n                      dest='workdir',\n                      type='str',\n                      default='/var/spool/clamav-mirror')\n    parser.add_option('-d', '--mirror-directory',\n                      help='The mirror directory',\n                      dest='mirrordir',\n                      type='str',\n                      default='/srv/www/clamav')\n    parser.add_option('-u', '--user',\n                      help='Change file owner to this user',\n                      dest='user',\n                      type='str',\n                      default='nginx')\n    parser.add_option('-g', '--group',\n                      help='Change file group to this group',\n                      dest='group',\n                      type='str',\n                      default='nginx')\n    parser.add_option('-l', '--locks-directory',\n                      help='Lock files directory',\n                      dest='lockdir',\n                      type='str',\n                      default='/var/lock/subsys')\n    parser.add_option('-v', '--verbose',\n                      help='Display verbose output',\n                      dest='verbose',\n                      action='store_true',\n                      default=False)\n    options, _ = parser.parse_args()\n    try:\n        lockfile = os.path.join(options.lockdir, 'clamavmirror')\n        with open(lockfile, 'w+') as lock:\n            fcntl.lockf(lock, fcntl.LOCK_EX | fcntl.LOCK_NB)\n            work(options)\n    except IOError:\n        info(\"=> Another instance is already running\")\n        sys.exit(254)", "response": "Entry point for clamav - master."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies a resource from src to dest", "response": "def copy_resource(src, dest):\n    \"\"\"\n    To copy package data to destination\n    \"\"\"\n    package_name = \"yass\"\n    dest = (dest + \"/\" + os.path.basename(src)).rstrip(\"/\")\n    if pkg_resources.resource_isdir(package_name, src):\n        if not os.path.isdir(dest):\n            os.makedirs(dest)\n        for res in pkg_resources.resource_listdir(__name__, src):\n            copy_resource(src + \"/\" + res, dest)\n    else:\n        if not os.path.isfile(dest) \\\n                and os.path.splitext(src)[1] not in [\".pyc\"]:\n            with open(dest, \"wb\") as f:\n                f.write(pkg_resources.resource_string(__name__, src))\n        else:\n            print(\"File exists: %s \" % dest)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npublishing the site to the given endpoint", "response": "def publish(endpoint, purge_files, rebuild_manifest, skip_upload):\n    \"\"\"Publish the site\"\"\"\n    print(\"Publishing site to %s ...\" % endpoint.upper())\n\n    yass = Yass(CWD)\n    target = endpoint.lower()\n\n    sitename = yass.sitename\n    if not sitename:\n        raise ValueError(\"Missing site name\")\n\n    endpoint = yass.config.get(\"hosting.%s\" % target)\n    if not endpoint:\n        raise ValueError(\"%s endpoint is missing in the config\" % target.upper())\n\n    if target == \"s3\":\n        p = publisher.S3Website(sitename=sitename,\n                                aws_access_key_id=endpoint.get(\"aws_access_key_id\"),\n                                aws_secret_access_key=endpoint.get(\"aws_secret_access_key\"),\n                                region=endpoint.get(\"aws_region\"))\n\n        if not p.website_exists:\n            print(\">>>\")\n            print(\"Setting S3 site...\")\n            if p.create_website() is True:\n                # Need to give it enough time to create it\n                # Should be a one time thing\n                time.sleep(10)\n                p.create_www_website()\n                print(\"New bucket created: %s\" % p.sitename)\n\n        if rebuild_manifest:\n            print(\">>>\")\n            print(\"Rebuilding site's manifest...\")\n            p.create_manifest_from_s3_files()\n\n        if purge_files is True or endpoint.get(\"purge_files\") is True:\n            print(\">>>\")\n            print(\"Purging files...\")\n            exclude_files = endpoint.get(\"purge_exclude_files\", [])\n            p.purge_files(exclude_files=exclude_files)\n\n        if not skip_upload:\n            print(\">>>\")\n            print(\"Uploading your site...\")\n            p.upload(yass.build_dir)\n        else:\n            print(\">>>\")\n            print(\"WARNING: files upload was skipped because of the use of --skip-upload\")\n\n        print(\"\")\n        print(\"Yass! Your site has been successfully published to: \")\n        print(p.website_endpoint_url)\n\n    footer()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new site directory and init Yass", "response": "def create_site(sitename):\n    \"\"\"Create a new site directory and init Yass\"\"\"\n    sitepath = os.path.join(CWD, sitename)\n    if os.path.isdir(sitepath):\n        print(\"Site directory '%s' exists already!\" % sitename)\n    else:\n        print(\"Creating site: %s...\" % sitename)\n        os.makedirs(sitepath)\n        copy_resource(\"skel/\", sitepath)\n        stamp_yass_current_version(sitepath)\n        print(\"Site created successfully!\")\n        print(\"CD into '%s' and run 'yass serve' to view the site\" % sitename)\n\n    footer()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init():\n    yass_conf = os.path.join(CWD, \"yass.yml\")\n    if os.path.isfile(yass_conf):\n        print(\"::ALERT::\")\n        print(\"It seems like Yass is already initialized here.\")\n        print(\"If it's a mistake, delete 'yass.yml' in this directory\")\n    else:\n        print(\"Init Yass in %s ...\" % CWD)\n        copy_resource(\"skel/\", CWD)\n        stamp_yass_current_version(CWD)\n        print(\"Yass init successfully!\")\n        print(\"Run 'yass serve' to view the site\")\n\n    footer()", "response": "Initialize Yass in the current directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_page(pagename):\n    page = pagename.lstrip(\"/\").rstrip(\"/\")\n    _, _ext = os.path.splitext(pagename)\n\n    # If the file doesn't have an extension, we'll just create one\n    if not _ext or _ext == \"\":\n        page += \".jade\"\n\n    if not page.endswith(PAGE_FORMAT):\n        error(\"Can't create '%s'\" % page)\n        print(\"Invalid filename format\")\n        print(\"Filename must be in: '%s'\" % \" | \".join(PAGE_FORMAT))\n    else:\n        engine = Yass(CWD)\n        markup = \"jade\"\n        if page.endswith(\".md\"):\n            markup = \"md\"\n        if page.endswith(\".html\"):\n            markup = \"html\"\n\n        dest_file = os.path.join(engine.pages_dir, page)\n        dest_dir = os.path.dirname(dest_file)\n\n        content = TPL_HEADER\n        content += TPL_BODY[markup]\n\n        if os.path.isfile(dest_file):\n            error(\"File exists already\")\n            print(\"Location: %s\" % dest_file)\n\n        else:\n            if not os.path.isdir(dest_dir):\n                os.makedirs(dest_dir)\n            with open(dest_file, \"w\") as f:\n                f.write(content)\n\n            print(\"New page created: '%s'\" % page)\n            print(\"Location: %s\" % dest_file)\n\n\n    footer()", "response": "Create a new page"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the location of the player converted to world coordinates.", "response": "def get_map_location(self):\n        \"\"\"Get the location of the player, converted to world coordinates.\n\n        :return: a tuple (x, y, z).\n\n        \"\"\"\n        map_data = self.get_map()\n        (bounds_e, bounds_n), (bounds_w, bounds_s) = map_data[\"continent_rect\"]\n        (map_e, map_n), (map_w, map_s) = map_data[\"map_rect\"]\n\n        assert bounds_w < bounds_e\n        assert bounds_n < bounds_s\n        assert map_w < map_e\n        assert map_n < map_s\n\n        meters_to_inches = 39.3701\n        x, y, z = self.fAvatarPosition\n\n        map_x = bounds_w + ((x * meters_to_inches - map_w) /\n                            (map_e - map_w) * (bounds_e - bounds_w))\n        map_y = bounds_n + ((-z * meters_to_inches - map_n) /\n                            (map_s - map_n) * (bounds_s - bounds_n))\n        map_z = y * meters_to_inches\n\n        return map_x, map_y, map_z"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a graph that contains a set of vertices that are represnting a point.", "response": "def CreateVertices(self, points):\n        \"\"\"\n        Returns a dictionary object with keys that are 2tuples\n        represnting a point.\n        \"\"\"\n        gr = digraph()\n\n        for z, x, Q in points:\n            node = (z, x, Q)\n            gr.add_nodes([node])\n\n        return gr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the directed edges for each point in the graph.", "response": "def CreateDirectedEdges(self, points, gr, layer_width):\n        \"\"\"\n        Take each key (ie. point) in the graph and for that point\n        create an edge to every point downstream of it where the weight\n        of the edge is the tuple (distance, angle)\n        \"\"\"\n        for z0, x0, Q0 in points:\n            for z1, x1, Q1 in points:\n                dz = z1 - z0  # no fabs because we check arrow direction\n                if dz > 0.0:  # make sure arrow in right direction\n                    if dz - layer_width < distance_threshold:  # only adjacents\n                        dx = math.fabs(x1 - x0)\n\n                        if dx > 5 * bar_width:\n                            continue\n\n                        # Weights are negative to in order to use shortest path\n                        # algorithms on the graph.\n                        weight = -1 * math.hypot(dz, dx)\n\n                        edge = ((z0, x0, Q0), (z1, x1, Q1))\n\n                        gr.add_edge(edge, wt=weight)\n\n        # Ensure that it is already transitively reduced\n        assert len(critical.transitive_edges(gr)) == 0\n\n        return gr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetFarthestNode(self, gr, node):\n        # Remember: weights are negative\n        distance = minmax.shortest_path_bellman_ford(gr, node)[1]\n\n        # Find the farthest node, which is end of track\n        min_key = None\n        for key, value in distance.iteritems():\n            if min_key is None or value < distance[min_key]:\n                min_key = key\n\n        return min_key", "response": "Get the farthest track entry for a given node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls the given callback if or when the connected deferred succeeds.", "response": "def on_success(self, fn, *args, **kwargs):\n        \"\"\"\n        Call the given callback if or when the connected deferred succeeds.\n\n        \"\"\"\n\n        self._callbacks.append((fn, args, kwargs))\n\n        result = self._resulted_in\n        if result is not _NOTHING_YET:\n            self._succeed(result=result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _succeed(self, result):\n\n        for fn, args, kwargs in self._callbacks:\n            fn(result, *args, **kwargs)\n        self._resulted_in = result", "response": "Called when the result of the job is successfully completed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a random person name", "response": "def random_name(num_surnames=2):\r\n    \"\"\"\r\n    Returns a random person name\r\n\r\n    Arguments:\r\n      num_surnames -- number of surnames\r\n    \"\"\"\r\n    a = []\r\n\r\n    # Prefix\r\n    if random.random() < _PROB_PREF:\r\n        a.append(_prefixes[random.randint(0, len(_prefixes) - 1)])\r\n\r\n    # Forename\r\n    a.append(_forenames[random.randint(0, len(_forenames) - 1)])\r\n\r\n    # Surnames\r\n    for i in range(num_surnames):\r\n        a.append(_surnames[random.randint(0, len(_surnames) - 1)])\r\n\r\n    # Suffix\r\n    if random.random() < _PROB_SUFF:\r\n        a.append(_suffixes[random.randint(0, len(_suffixes) - 1)])\r\n\r\n    return \" \".join(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_free_shipping_coupon(cls, free_shipping_coupon, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_free_shipping_coupon_with_http_info(free_shipping_coupon, **kwargs)\n        else:\n            (data) = cls._create_free_shipping_coupon_with_http_info(free_shipping_coupon, **kwargs)\n            return data", "response": "Create a new FreeShippingCoupon with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_free_shipping_coupon_by_id(cls, free_shipping_coupon_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, **kwargs)\n        else:\n            (data) = cls._delete_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, **kwargs)\n            return data", "response": "Delete an instance of FreeShippingCoupon by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds FreeShippingCoupon by its ID Return single instance of FreeShippingCoupon with the given ID.", "response": "def get_free_shipping_coupon_by_id(cls, free_shipping_coupon_id, **kwargs):\n        \"\"\"Find FreeShippingCoupon\n\n        Return single instance of FreeShippingCoupon by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_free_shipping_coupon_by_id(free_shipping_coupon_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_coupon_id: ID of freeShippingCoupon to return (required)\n        :return: FreeShippingCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, **kwargs)\n        else:\n            (data) = cls._get_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting FreeShippingCoupons Return a list of FreeShippingCoupons", "response": "def list_all_free_shipping_coupons(cls, **kwargs):\n        \"\"\"List FreeShippingCoupons\n\n        Return a list of FreeShippingCoupons\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_free_shipping_coupons(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[FreeShippingCoupon]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_free_shipping_coupons_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_free_shipping_coupons_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces FreeShippingCoupon by ID and return the updated FreeShippingCoupon object.", "response": "def replace_free_shipping_coupon_by_id(cls, free_shipping_coupon_id, free_shipping_coupon, **kwargs):\n        \"\"\"Replace FreeShippingCoupon\n\n        Replace all attributes of FreeShippingCoupon\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_free_shipping_coupon_by_id(free_shipping_coupon_id, free_shipping_coupon, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_coupon_id: ID of freeShippingCoupon to replace (required)\n        :param FreeShippingCoupon free_shipping_coupon: Attributes of freeShippingCoupon to replace (required)\n        :return: FreeShippingCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, free_shipping_coupon, **kwargs)\n        else:\n            (data) = cls._replace_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, free_shipping_coupon, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_free_shipping_coupon_by_id(cls, free_shipping_coupon_id, free_shipping_coupon, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, free_shipping_coupon, **kwargs)\n        else:\n            (data) = cls._update_free_shipping_coupon_by_id_with_http_info(free_shipping_coupon_id, free_shipping_coupon, **kwargs)\n            return data", "response": "Update attributes of FreeShippingCoupon by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the Configuration schema information from a file", "response": "def fetch_config(filename):\n    \"\"\"Fetch the Configuration schema information\n\n    Finds the schema file, loads the file and reads the JSON, then converts to a dictionary that is returned\n    \"\"\"\n\n    #  This trick gets the directory of *this* file Configuration.py thus\n    # allowing to find the schema files relative to this file.\n    dir_name = get_source_dir()\n\n    # Append json\n    filename = os.path.join('json', filename)\n\n    fileobj = open(os.path.join(dir_name, filename), 'r')\n    my_dict = json.loads(fileobj.read())\n    return my_dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef populate_args_level(schema, parser):\n    for key, value in schema['properties'].iteritems():\n        if key == 'name':\n            continue\n\n        arg = '--%s' % key\n        desc = value['description']\n\n        if 'type' in value:\n            if value['type'] == 'string':\n                if 'enum' in value:\n                    parser.add_argument(arg, help=desc, type=str,\n                        choices=value['enum'])\n                else:\n                    parser.add_argument(arg, help=desc, type=str)\n            elif value['type'] == 'number':\n                parser.add_argument(arg, help=desc, type=float)\n            elif value['type'] == 'integer':\n                parser.add_argument(arg, help=desc, type=int)\n            elif str(value['type']) == 'array':\n                assert value['minItems'] == value['maxItems']\n\n                if value['items']['type'] != 'number':\n                    raise NotImplementedError(\"Only float arrays work\")\n                parser.add_argument(arg, help=desc, type=float,\n                    nargs=value['maxItems'], metavar='N')\n            elif value['type'] == 'object':\n                #group = parser.add_argument_group(key, value['description'])\n                #populate_args_level(value, group)\n                pass", "response": "Use a schema to populate a command line argument parser"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bulk_send(self, topic, kmsgs, timeout=60):\n\n        try:\n            for kmsg in kmsgs:\n                self.client.send(\n                    topic, self._onmessage(kmsg).dumps().encode(\"UTF-8\")\n                )\n            self.client.flush(timeout=timeout)\n            return Result(stdout=\"{} message(s) sent\".format(len(kmsgs)))\n\n        except Exception as exc:\n            return Result.from_exception(exc)", "response": "Send a batch of messages to a kafka topic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, topic, kmsg, timeout=60):\n        result = Result(uuid=kmsg.uuid)\n        try:\n            self.client.produce(\n                topic, self._onmessage(kmsg).dumps().encode(\"UTF-8\")\n            )\n            result.stdout = \"Message {}[{}] sent\".format(\n                kmsg.entrypoint, kmsg.uuid\n            )\n            self.client.flush()\n\n        except Exception as exc:\n            result = Result.from_exception(exc, kmsg.uuid)\n\n        finally:\n            if result.retcode < 300:\n                return self._onsuccess(kmsg=kmsg, result=result)\n            else:\n                return self._onerror(kmsg=kmsg, result=result)", "response": "Send a message to the given kafka topic."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef file_strip_ext(\n        afile,\n        skip_version=False,\n        only_known_extensions=False,\n        allow_subformat=True):\n    \"\"\"\n    Strip in the best way the extension from a filename.\n\n    >>> file_strip_ext(\"foo.tar.gz\")\n    'foo'\n    >>> file_strip_ext(\"foo.buz.gz\")\n    'foo.buz'\n    >>> file_strip_ext(\"foo.buz\")\n    'foo'\n    >>> file_strip_ext(\"foo.buz\", only_known_extensions=True)\n    'foo.buz'\n    >>> file_strip_ext(\"foo.buz;1\", skip_version=False,\n    ... only_known_extensions=True)\n    'foo.buz;1'\n    >>> file_strip_ext(\"foo.gif;icon\")\n    'foo'\n    >>> file_strip_ext(\"foo.gif;icon\", only_know_extensions=True,\n    ... allow_subformat=False)\n    'foo.gif;icon'\n\n    @param afile: the path/name of a file.\n    @type afile: string\n    @param skip_version: whether to skip a trailing \";version\".\n    @type skip_version: bool\n    @param only_known_extensions: whether to strip out only known extensions or\n        to consider as extension anything that follows a dot.\n    @type only_known_extensions: bool\n    @param allow_subformat: whether to consider also subformats as part of\n        the extension.\n    @type allow_subformat: bool\n    @return: the name/path without the extension (and version).\n    @rtype: string\n    \"\"\"\n    import os\n    afile = afile.split(';')\n    if len(afile) > 1 and allow_subformat and not afile[-1].isdigit():\n        afile = afile[0:-1]\n    if len(afile) > 1 and skip_version and afile[-1].isdigit():\n        afile = afile[0:-1]\n    afile = ';'.join(afile)\n    nextfile = _extensions.sub('', afile)\n    if nextfile == afile and not only_known_extensions:\n        nextfile = os.path.splitext(afile)[0]\n    while nextfile != afile:\n        afile = nextfile\n        nextfile = _extensions.sub('', afile)\n    return nextfile", "response": "This function strips out the extension from a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef guess_extension(amimetype, normalize=False):\n    ext = _mimes.guess_extension(amimetype)\n    if ext and normalize:\n        # Normalize some common magic mis-interpreation\n        ext = {'.asc': '.txt', '.obj': '.bin'}.get(ext, ext)\n        from invenio.legacy.bibdocfile.api_normalizer import normalize_format\n        return normalize_format(ext)\n    return ext", "response": "Tries to guess the extension for a mimetype."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all possible guesses about the content of the file.", "response": "def get_magic_guesses(fullpath):\n    \"\"\"\n    Return all the possible guesses from the magic library about\n    the content of the file.\n\n    @param fullpath: location of the file\n    @type fullpath: string\n    @return: guesses about content of the file\n    @rtype: tuple\n    \"\"\"\n    if CFG_HAS_MAGIC == 1:\n        magic_cookies = _get_magic_cookies()\n        magic_result = []\n        for key in magic_cookies.keys():\n            magic_result.append(magic_cookies[key].file(fullpath))\n        return tuple(magic_result)\n    elif CFG_HAS_MAGIC == 2:\n        magic_result = []\n        for key in ({'mime': False, 'mime_encoding': False},\n                    {'mime': True, 'mime_encoding': False},\n                    {'mime': False, 'mime_encoding': True}):\n            magic_result.append(_magic_wrapper(fullpath, **key))\n        return tuple(magic_result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the regular expression to match all the known extensions.", "response": "def extensions(self):\n        \"\"\"\n        Generate the regular expression to match all the known extensions.\n\n        @return: the regular expression.\n        @rtype: regular expression object\n        \"\"\"\n        _tmp_extensions = self.mimes.encodings_map.keys() + \\\n            self.mimes.suffix_map.keys() + \\\n            self.mimes.types_map[1].keys() + \\\n            cfg['CFG_BIBDOCFILE_ADDITIONAL_KNOWN_FILE_EXTENSIONS']\n        extensions = []\n        for ext in _tmp_extensions:\n            if ext.startswith('.'):\n                extensions.append(ext)\n            else:\n                extensions.append('.' + ext)\n        extensions.sort()\n        extensions.reverse()\n        extensions = set([ext.lower() for ext in extensions])\n        extensions = '\\\\' + '$|\\\\'.join(extensions) + '$'\n        extensions = extensions.replace('+', '\\\\+')\n        return re.compile(extensions, re.I)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __deserialize(self, data, klass):\n        if data is None:\n            return None\n\n        if type(klass) == str:\n            from tradenity.resources.paging import Page\n            if klass.startswith('page['):\n                sub_kls = re.match('page\\[(.*)\\]', klass).group(1)\n                return Page([self.__deserialize(sub_data, sub_kls)\n                            for sub_data in data[\"items\"]], self.__deserialize_page_info(data[\"__meta\"]))\n            if klass.startswith('list['):\n                sub_kls = re.match('list\\[(.*)\\]', klass).group(1)\n                return [self.__deserialize(sub_data, sub_kls)\n                        for sub_data in data]\n\n            if klass.startswith('dict('):\n                sub_kls = re.match('dict\\(([^,]*), (.*)\\)', klass).group(2)\n                return {k: self.__deserialize(v, sub_kls)\n                        for k, v in six.iteritems(data)}\n\n            # convert str to class\n            if klass in self.NATIVE_TYPES_MAPPING:\n                klass = self.NATIVE_TYPES_MAPPING[klass]\n            else:\n                klass = getattr(tradenity.resources, klass)\n\n        if klass in self.PRIMITIVE_TYPES:\n            return self.__deserialize_primitive(data, klass)\n        elif klass == object:\n            return self.__deserialize_object(data)\n        elif klass == datetime.date:\n            return self.__deserialize_date(data)\n        elif klass == datetime.datetime:\n            return self.__deserialize_datatime(data)\n        else:\n            return self.__deserialize_model(data, klass)", "response": "Deserializes dict list or str into an object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_params_for_auth(self, headers, querys, auth_settings):\n        if self.auth_token_holder.token is not None:\n            headers[Configuration.AUTH_TOKEN_HEADER_NAME] = self.auth_token_holder.token\n        else:\n            headers['Authorization'] = self.configuration.get_basic_auth_token()", "response": "Updates header and query params based on authentication settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, service):\n        try:\n            map(self.start_class, service.depends)\n            if service.is_running():\n                return\n            if service in self.failed:\n                log.warning(\"%s previously failed to start\", service)\n                return\n            service.start()\n        except Exception:\n            log.exception(\"Unable to start service %s\", service)\n            self.failed.add(service)", "response": "Start the service catching and logging exceptions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting all services of a given class.", "response": "def start_class(self, class_):\n        \"\"\"\n        Start all services of a given class. If this manager doesn't already\n        have a service of that class, it constructs one and starts it.\n        \"\"\"\n        matches = filter(lambda svc: isinstance(svc, class_), self)\n        if not matches:\n            svc = class_()\n            self.register(svc)\n            matches = [svc]\n        map(self.start, matches)\n        return matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops all services of a given class", "response": "def stop_class(self, class_):\n        \"Stop all services of a given class\"\n        matches = filter(lambda svc: isinstance(svc, class_), self)\n        map(self.stop, matches)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a directory suitable for writing log files.", "response": "def log_root(self):\n        \"\"\"\n        Find a directory suitable for writing log files. It uses sys.prefix\n        to use a path relative to the root. If sys.prefix is /usr, it's the\n        system Python, so use /var/log.\n        \"\"\"\n        var_log = (\n            os.path.join(sys.prefix, 'var', 'log')\n            .replace('/usr/var', '/var')\n        )\n        if not os.path.isdir(var_log):\n            os.makedirs(var_log)\n        return var_log"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget more data from the file.", "response": "def _get_more_data(self, file, timeout):\n        \"\"\"\n        Return data from the file, if available. If no data is received\n        by the timeout, then raise RuntimeError.\n        \"\"\"\n        timeout = datetime.timedelta(seconds=timeout)\n        timer = Stopwatch()\n        while timer.split() < timeout:\n            data = file.read()\n            if data:\n                return data\n        raise RuntimeError(\"Timeout\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naugments the current environment with the PYTHONUSERBASE environment and PIP_USER environment variables.", "response": "def _run_env(self):\n        \"\"\"\n        Augment the current environment providing the PYTHONUSERBASE.\n        \"\"\"\n        env = dict(os.environ)\n        env.update(\n            getattr(self, 'env', {}),\n            PYTHONUSERBASE=self.env_path,\n            PIP_USER=\"1\",\n        )\n        self._disable_venv(env)\n        return env"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _disable_venv(self, env):\n        venv = env.pop('VIRTUAL_ENV', None)\n        if venv:\n            venv_path, sep, env['PATH'] = env['PATH'].partition(os.pathsep)", "response": "Disable virtualenv and venv in the environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_env(self):\n        root = path.Path(os.environ.get('SERVICES_ROOT', 'services'))\n        self.env_path = (root / self.name).abspath()\n        cmd = [\n            self.python,\n            '-c', 'import site; print(site.getusersitepackages())',\n        ]\n        out = subprocess.check_output(cmd, env=self._run_env)\n        site_packages = out.decode().strip()\n        path.Path(site_packages).makedirs_p()", "response": "Create a PEP - 3370 environment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new StatesGeoZone with the given attributes", "response": "def create_states_geo_zone(cls, states_geo_zone, **kwargs):\n        \"\"\"Create StatesGeoZone\n\n        Create a new StatesGeoZone\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_states_geo_zone(states_geo_zone, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param StatesGeoZone states_geo_zone: Attributes of statesGeoZone to create (required)\n        :return: StatesGeoZone\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_states_geo_zone_with_http_info(states_geo_zone, **kwargs)\n        else:\n            (data) = cls._create_states_geo_zone_with_http_info(states_geo_zone, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_states_geo_zone_by_id(cls, states_geo_zone_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_states_geo_zone_by_id_with_http_info(states_geo_zone_id, **kwargs)\n        else:\n            (data) = cls._delete_states_geo_zone_by_id_with_http_info(states_geo_zone_id, **kwargs)\n            return data", "response": "Delete an instance of StatesGeoZone by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind StatesGeoZone by ID Return single instance of StatesGeoZone by its ID.", "response": "def get_states_geo_zone_by_id(cls, states_geo_zone_id, **kwargs):\n        \"\"\"Find StatesGeoZone\n\n        Return single instance of StatesGeoZone by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_states_geo_zone_by_id(states_geo_zone_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str states_geo_zone_id: ID of statesGeoZone to return (required)\n        :return: StatesGeoZone\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_states_geo_zone_by_id_with_http_info(states_geo_zone_id, **kwargs)\n        else:\n            (data) = cls._get_states_geo_zone_by_id_with_http_info(states_geo_zone_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_all_states_geo_zones(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_states_geo_zones_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_states_geo_zones_with_http_info(**kwargs)\n            return data", "response": "List StatesGeoZones\n        Return a list of StatesGeoZones\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_states_geo_zone_by_id(cls, states_geo_zone_id, states_geo_zone, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_states_geo_zone_by_id_with_http_info(states_geo_zone_id, states_geo_zone, **kwargs)\n        else:\n            (data) = cls._replace_states_geo_zone_by_id_with_http_info(states_geo_zone_id, states_geo_zone, **kwargs)\n            return data", "response": "Replace all attributes of StatesGeoZone by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_states_geo_zone_by_id(cls, states_geo_zone_id, states_geo_zone, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_states_geo_zone_by_id_with_http_info(states_geo_zone_id, states_geo_zone, **kwargs)\n        else:\n            (data) = cls._update_states_geo_zone_by_id_with_http_info(states_geo_zone_id, states_geo_zone, **kwargs)\n            return data", "response": "Update attributes of StatesGeoZone by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compaction(self, request_compaction=False):\n        url = self._service_url + 'compaction/'\n\n        if request_compaction:\n            response = requests.post(url, **self._instances._default_request_kwargs)\n        else:\n            response = requests.get(url, **self._instances._default_request_kwargs)\n\n        return response.json()", "response": "Retrieve a report on or request compaction for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an authenticated connection to this instance.", "response": "def get_authenticated_connection(self, user, passwd, db='admin', ssl=True):\n        \"\"\"Get an authenticated connection to this instance.\n\n        :param str user: The username to use for authentication.\n        :param str passwd: The password to use for authentication.\n        :param str db: The name of the database to authenticate against. Defaults to ``'Admin'``.\n        :param bool ssl: Use SSL/TLS if available for this instance. Defaults to ``True``.\n        :raises: :py:class:`pymongo.errors.OperationFailure` if authentication fails.\n        \"\"\"\n        # Attempt to establish an authenticated connection.\n        try:\n            connection = self.get_connection(ssl=ssl)\n            connection[db].authenticate(user, passwd)\n            return connection\n\n        # Catch exception here for logging, then just re-raise.\n        except pymongo.errors.OperationFailure as ex:\n            logger.exception(ex)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of shards belonging to this instance.", "response": "def shards(self, add_shard=False):\n        \"\"\"Get a list of shards belonging to this instance.\n\n        :param bool add_shard: A boolean indicating whether to add a new shard to the specified\n            instance.\n        \"\"\"\n        url = self._service_url + 'shards/'\n        if add_shard:\n            response = requests.post(url, **self._instances._default_request_kwargs)\n        else:\n            response = requests.get(url, **self._instances._default_request_kwargs)\n\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets stats for this instance.", "response": "def new_relic_stats(self):\n        \"\"\"\n        Get stats for this instance.\n        \"\"\"\n        if self._new_relic_stats is None:\n            # if this is a sharded instance, fetch shard stats in parallel\n            if self.type == 'mongodb_sharded':\n                shards = [Shard(self.name, self._service_url + 'shards/',\n                                self._client, shard_doc)\n                          for shard_doc in self.shards().get('data')]\n                fs = []\n                with futures.ThreadPoolExecutor(len(shards)) as executor:\n                    for shard in shards:\n                        fs.append(executor.submit(shard.get_shard_stats))\n                    futures.wait(fs, timeout=None, return_when=futures.ALL_COMPLETED)\n                stats_this_second = self._rollup_shard_stats_to_instance_stats(\n                    {shard.name: future.result() for (shard, future) in zip(shards, fs)})\n                # power nap\n                time.sleep(1)\n                # fetch again\n                fs = []\n                with futures.ThreadPoolExecutor(len(shards)) as executor:\n                    for shard in shards:\n                        fs.append(executor.submit(shard.get_shard_stats))\n                    futures.wait(fs, timeout=None, return_when=futures.ALL_COMPLETED)\n                stats_next_second = self._rollup_shard_stats_to_instance_stats(\n                    {shard.name: future.result() for (shard, future) in zip(shards, fs)})\n                self._new_relic_stats = self._compile_new_relic_stats(stats_this_second, stats_next_second)\n            else:\n                # fetch stats like we did before (by hitting new_relic_stats API resource)\n                response = requests.get('{}{}'.format(self._url,\n                                        'new-relic-stats'),\n                                        **self._instances._default_request_kwargs)\n                self._new_relic_stats = json.loads(response.content).get(\n                    'data') if response.status_code == 200 else {}\n        return self._new_relic_stats"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrolling up all shard stats to instance level stats :param shard_stats: dict of {shard_name: shard level stats}", "response": "def _rollup_shard_stats_to_instance_stats(self, shard_stats):\n        \"\"\"\n        roll up all shard stats to instance level stats\n\n        :param shard_stats: dict of {shard_name: shard level stats}\n        \"\"\"\n        instance_stats = {}\n        opcounters_per_node = []\n\n        # aggregate replication_lag\n        instance_stats['replication_lag'] = max(map(lambda s: s['replication_lag'], shard_stats.values()))\n\n        aggregate_server_statistics = {}\n        for shard_name, stats in shard_stats.items():\n            for statistic_key in stats.get('shard_stats'):\n                if statistic_key != 'connections' and statistic_key in aggregate_server_statistics:\n                    aggregate_server_statistics[statistic_key] = util.sum_values(aggregate_server_statistics[statistic_key],\n                                                                                 stats.get('shard_stats')[statistic_key])\n                else:\n                    aggregate_server_statistics[statistic_key] = stats.get('shard_stats')[statistic_key]\n\n            # aggregate per_node_stats into opcounters_per_node\n            opcounters_per_node.append({shard_name: {member: node_stats['opcounters']\n                                                     for member, node_stats in stats.get('per_node_stats').items()}})\n\n        instance_stats['opcounters_per_node'] = opcounters_per_node\n        instance_stats['aggregate_server_statistics'] = aggregate_server_statistics\n        return instance_stats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute some stats that have more than one aggregated stats and other stats that have more aggregated stats", "response": "def _compile_new_relic_stats(self, stats_this_second, stats_next_second):\n        \"\"\"\n        from instance 'stats_this_second' and instance 'stats_next_second', compute some per\n        second stats metrics and other aggregated metrics\n\n        :param dict stats_this_second:\n        :param dict stats_next_second:\n        :return: compiled instance stats that has metrics\n\n        {'opcounters_per_node_per_second': {...},\n         'server_statistics_per_second': {...},\n         'aggregate_server_statistics': {...},\n         'replication_lag': 0.0,\n         'aggregate_database_statistics': {}\n         }\n        \"\"\"\n        server_statistics_per_second = {}\n        opcounters_per_node_per_second = []\n        for subdoc in [\"opcounters\", \"network\"]:\n            first_doc = stats_this_second['aggregate_server_statistics'][subdoc]\n            second_doc = stats_next_second['aggregate_server_statistics'][subdoc]\n            keys = set(first_doc.keys()) | set(second_doc.keys())\n            server_statistics_per_second[subdoc] = {key: int(second_doc[key]) - int(first_doc[key]) for key in keys if isinstance(first_doc[key], int)}\n        for node1, node2 in zip(stats_this_second['opcounters_per_node'], stats_next_second['opcounters_per_node']):\n            node_opcounters_per_second = {}\n            for repl, members in node2.items():\n                node_opcounters_per_second[repl] = {}\n                for member, ops in members.items():\n                    node_opcounters_per_second[repl][member] = {}\n                    for op, count in ops.items():\n                        node_opcounters_per_second[repl][member][op] = count - node1[repl][member][op]\n            opcounters_per_node_per_second.append(node_opcounters_per_second)\n\n        return {'opcounters_per_node_per_second': opcounters_per_node_per_second,\n                'server_statistics_per_second': server_statistics_per_second,\n                'aggregate_server_statistics': stats_next_second.get('aggregate_server_statistics'),\n                'replication_lag': stats_next_second.get('replication_lag'),\n                'aggregate_database_statistics': self.get_aggregate_database_stats()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets information on this instance s stepdown window.", "response": "def get_stepdown_window(self):\n        \"\"\"Get information on this instance's stepdown window.\"\"\"\n        url = self._service_url + 'stepdown/'\n        response = requests.get(url, **self._instances._default_request_kwargs)\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_stepdown_window(self, start, end, enabled=True, scheduled=True, weekly=True):\n        # Ensure a logical start and endtime is requested.\n        if not start < end:\n            raise TypeError('Parameter \"start\" must occur earlier in time than \"end\".')\n\n        # Ensure specified window is less than a week in length.\n        week_delta = datetime.timedelta(days=7)\n        if not ((end - start) <= week_delta):\n            raise TypeError('Stepdown windows can not be longer than 1 week in length.')\n\n        url = self._service_url + 'stepdown/'\n        data = {\n            'start': int(start.strftime('%s')),\n            'end': int(end.strftime('%s')),\n            'enabled': enabled,\n            'scheduled': scheduled,\n            'weekly': weekly,\n        }\n\n        response = requests.post(\n            url,\n            data=json.dumps(data),\n            **self._instances._default_request_kwargs\n        )\n        return response.json()", "response": "Set the stepdown window for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_connection(self, ssl):\n\n        # Use SSL/TLS if requested and available.\n        connect_string = self.connect_string\n        if ssl and self.ssl_connect_string:\n            connect_string = self.ssl_connect_string\n\n        return pymongo.MongoClient(connect_string)", "response": "Get a live connection to this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget stats for this mongodb shard", "response": "def get_shard_stats(self):\n        \"\"\"\n        :return: get stats for this mongodb shard\n        \"\"\"\n        return requests.get(self._stats_url, params={'include_stats': True},\n                            headers={'X-Auth-Token': self._client.auth._token}\n                            ).json()['data']['stats']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the brand of this PaymentCard.", "response": "def brand(self, brand):\n        \"\"\"Sets the brand of this PaymentCard.\n\n\n        :param brand: The brand of this PaymentCard.\n        :type: str\n        \"\"\"\n        allowed_values = [\"visa\", \"mastercard\", \"americanExpress\", \"discover\"]\n        if brand is not None and brand not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `brand` ({0}), must be one of {1}\"\n                .format(brand, allowed_values)\n            )\n\n        self._brand = brand"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new PaymentCard with the given attributes. This method creates a new PaymentCard with the given attributes.", "response": "def create_payment_card(cls, payment_card, **kwargs):\n        \"\"\"Create PaymentCard\n\n        Create a new PaymentCard\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_payment_card(payment_card, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param PaymentCard payment_card: Attributes of paymentCard to create (required)\n        :return: PaymentCard\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_payment_card_with_http_info(payment_card, **kwargs)\n        else:\n            (data) = cls._create_payment_card_with_http_info(payment_card, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting an instance of PaymentCard by its ID.", "response": "def delete_payment_card_by_id(cls, payment_card_id, **kwargs):\n        \"\"\"Delete PaymentCard\n\n        Delete an instance of PaymentCard by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_payment_card_by_id(payment_card_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str payment_card_id: ID of paymentCard to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_payment_card_by_id_with_http_info(payment_card_id, **kwargs)\n        else:\n            (data) = cls._delete_payment_card_by_id_with_http_info(payment_card_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_payment_card_by_id(cls, payment_card_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_payment_card_by_id_with_http_info(payment_card_id, **kwargs)\n        else:\n            (data) = cls._get_payment_card_by_id_with_http_info(payment_card_id, **kwargs)\n            return data", "response": "Find PaymentCard by ID Return single instance of PaymentCard"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist PaymentCards Returns a list of PaymentCards", "response": "def list_all_payment_cards(cls, **kwargs):\n        \"\"\"List PaymentCards\n\n        Return a list of PaymentCards\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_payment_cards(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[PaymentCard]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_payment_cards_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_payment_cards_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_payment_card_by_id(cls, payment_card_id, payment_card, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_payment_card_by_id_with_http_info(payment_card_id, payment_card, **kwargs)\n        else:\n            (data) = cls._replace_payment_card_by_id_with_http_info(payment_card_id, payment_card, **kwargs)\n            return data", "response": "Replace PaymentCard by ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_payment_card_by_id(cls, payment_card_id, payment_card, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_payment_card_by_id_with_http_info(payment_card_id, payment_card, **kwargs)\n        else:\n            (data) = cls._update_payment_card_by_id_with_http_info(payment_card_id, payment_card, **kwargs)\n            return data", "response": "Update attributes of PaymentCard by ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rec2csv(r, filename):\n    names = r.dtype.names\n    def translate(x):\n        if x is None or str(x).lower == \"none\":\n            x = \"\"\n        return str(x)\n    with open(filename, \"w\") as csv:\n        csv.write(\",\".join([str(x) for x in names])+\"\\n\")\n        for data in r:\n            csv.write(\",\".join([translate(x) for x in data])+\"\\n\")\n    #print \"Wrote CSV table %r\" % filename\n    return filename", "response": "Export a recarray r to a CSV file filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquote special characters for LaTeX.", "response": "def latex_quote(s):\n    \"\"\"Quote special characters for LaTeX.\n\n    (Incomplete, currently only deals with underscores, dollar and hash.)\n    \"\"\"\n    special = {'_':r'\\_', '$':r'\\$', '#':r'\\#'}\n    s = str(s)\n    for char,repl in special.items():\n        new = s.replace(char, repl)\n        s = new[:]\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rec2latex(r, filename, empty=\"\"):\n    with open(filename, \"w\") as latex:\n        latex.write(s_rec2latex(r, empty=empty))\n    return filename", "response": "Export a recarray r to a LaTeX table in filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef s_rec2latex(r, empty=\"\"):\n    latex = \"\"\n    names = r.dtype.names\n    def translate(x):\n        if x is None or str(x).lower == \"none\":\n            x = empty\n        return latex_quote(x)\n    latex += r\"\\begin{tabular}{%s}\" % (\"\".join([\"c\"]*len(names)),) + \"\\n\"  # simple c columns\n    latex += r\"\\hline\"+\"\\n\"\n    latex += \" & \".join([latex_quote(x) for x in names])+r\"\\\\\"+\"\\n\"\n    latex += r\"\\hline\"+\"\\n\"\n    for data in r:\n        latex += \" & \".join([translate(x) for x in data])+r\"\\\\\"+\"\\n\"\n    latex += r\"\\hline\"+\"\\n\"\n    latex += r\"\\end{tabular}\"+\"\\n\"\n    return latex", "response": "Export a recarray r to a LaTeX table in a string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the bubble representation of given power graph and push it into given file.", "response": "def tree_to_file(tree:'BubbleTree', outfile:str):\n    \"\"\"Compute the bubble representation of given power graph,\n    and push it into given file.\"\"\"\n    with open(outfile, 'w') as fd:\n        fd.write(tree_to_bubble(tree))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lines_from_tree(tree, nodes_and_set:bool=False) -> iter:\n    NODE = 'NODE\\t{}'\n    INCL = 'IN\\t{}\\t{}'\n    EDGE = 'EDGE\\t{}\\t{}\\t1.0'\n    SET  = 'SET\\t{}'\n\n    if nodes_and_set:\n        for node in tree.nodes():\n            yield NODE.format(node)\n\n        for node in tree.powernodes():\n            yield SET.format(node)\n\n    for node, includeds in tree.inclusions.items():\n        for included in includeds:\n            yield INCL.format(included, node)\n\n    for node, succs in tree.edges.items():\n        for succ in succs:\n            yield EDGE.format(node, succ)", "response": "Yields a generator of lines of bubble describing given BubbleTree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_python(self):\n        if isinstance(self.data, str):\n            return self.data.strip().lower() == 'true'\n        if isinstance(self.data, int):\n            return self.data > 0\n        return bool(self.data)", "response": "Convert the data to a boolean."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the API call headers for the given app.", "response": "def get_api_call_headers(app):\n    \"\"\"\n    \u0413\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u0442 \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043a\u0438 \u0434\u043b\u044f API \u0437\u0430\u043f\u0440\u043e\u0441\u0430.\n    \u0422\u0443\u0442 \u0436\u0435 \u043f\u043e\u0434\u043a\u043b\u0430\u0434\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f\n\n    :type app: metasdk.MetaApp\n    \"\"\"\n    headers = {\n        \"content-type\": \"application/json;charset=UTF-8\",\n        \"User-Agent\": app.user_agent,\n    }\n    if not app.developer_settings:\n        raise AuthError({\"message\": \"\u0414\u043b\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b SDK \u043d\u0443\u0436\u043d\u043e \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u044c \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430\", \"url\": \"https://apps.devision.io/page?a=63&p=3975\"})\n    headers.update(app.developer_settings.get('api_headers'))\n    return headers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_filename_from_url(log, url):\n    ## > IMPORTS ##\n    import re\n    # EXTRACT THE FILENAME FROM THE URL\n    try:\n        log.debug(\"extracting filename from url \" + url)\n        reEoURL = re.compile('([\\w\\.]*)$')\n        filename = reEoURL.findall(url)[0]\n        # log.debug(filename)\n        if(len(filename) == 0):\n            filename = 'untitled.html'\n        if not (re.search('\\.', filename)):\n            filename = filename + '.html'\n    except Exception as e:\n        filename = None\n        # print url\n        log.warning(\"could not extracting filename from url : \" + str(e) + \"\\n\")\n\n    return filename", "response": "extract the filename from a URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild an ApiClient object from the developer settings.", "response": "def build_from_developer_settings(api_name: str, api_version: str):\n        \"\"\"\n        :param api_name: Example hello\n        :param api_version: Example v1, v2alpha\n        :return: ApiClient\n        \"\"\"\n        developer_settings = read_developer_settings()\n\n        api_host = \"http://\" + api_name + \".apis.devision.io\"\n        return ApiClient(\n            host=api_host,\n            api_version=api_version,\n            access_token=None,\n            refresh_token=developer_settings['refreshToken'],\n            client_id=developer_settings['clientId'],\n            client_secret=developer_settings['clientSecret'],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_formdata(self, valuelist):\n        if valuelist:\n            time_str = u' '.join(valuelist)\n            try:\n                timetuple = time.strptime(time_str, self.format)\n                self.data = datetime.time(*timetuple[3:6])\n            except ValueError:\n                self.data = None\n                raise", "response": "Process the data field."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_csrf_token(self, field):\n        if current_app.testing:\n            return\n        super(InvenioBaseForm, self).validate_csrf_token(field)", "response": "Disable CRSF proection during testing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the exchange word vectors from the database and return the dataset.", "response": "def load_exchange_word_vectors(\n    filename                 = \"database.db\",\n    maximum_number_of_events = None\n    ):\n    \"\"\"\n    Load exchange data and return dataset.\n    \"\"\"\n    log.info(\"load word vectors of database {filename}\".format(\n        filename = filename\n    ))\n    # Ensure that the database exists.\n    if not os.path.isfile(filename):\n        log.info(\"database {filename} nonexistent\".format(\n            filename = filename\n        ))\n        program.terminate()\n        raise Exception\n    # Access the database.\n    database = access_database(filename = filename)\n    # Access or create the exchanges table.\n    table_exchanges = database[\"exchanges\"]\n    # Access exchanges.\n    table_name = \"exchanges\"\n    # Create a datavision dataset.\n    data = datavision.Dataset()\n    # progress\n    progress = shijian.Progress()\n    progress.engage_quick_calculation_mode()\n    number_of_entries = len(database[table_name])\n    index = 0\n    for index_entry, entry in enumerate(database[table_name].all()):\n        if maximum_number_of_events is not None and\\\n            index >= int(maximum_number_of_events):\n            log.info(\n                \"loaded maximum requested number of events \" +\n                \"({maximum_number_of_events})\\r\".format(\n                    maximum_number_of_events = maximum_number_of_events\n                )\n            )\n            break\n        #unique_identifier = str(entry[\"id\"])\n        utteranceWordVector = str(entry[\"utteranceWordVector\"])\n        responseWordVector = str(entry[\"responseWordVector\"])\n        if utteranceWordVector != \"None\" and responseWordVector != \"None\":\n            index += 1\n\n            utteranceWordVector = eval(\"np.\" + utteranceWordVector.replace(\"float32\", \"np.float32\"))\n            responseWordVector  = eval(\"np.\" + responseWordVector.replace(\"float32\", \"np.float32\"))\n            data.variable(index = index, name = \"utteranceWordVector\", value = utteranceWordVector)\n            data.variable(index = index, name = \"responseWordVector\",  value = responseWordVector )\n\n            #utteranceWordVector = list(eval(\"np.\" + utteranceWordVector.replace(\"float32\", \"np.float32\")))\n            #responseWordVector  = list(eval(\"np.\" + responseWordVector.replace(\"float32\", \"np.float32\")))\n            #for index_component, component in enumerate(utteranceWordVector):\n            #    data.variable(index = index, name = \"uwv\" + str(index_component), value = component)\n            #for index_component, component in enumerate(responseWordVector):\n            #    data.variable(index = index, name = \"rwv\" + str(index_component), value = component)\n\n        print progress.add_datum(fraction = index_entry / number_of_entries),\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading HEP data and return dataset.", "response": "def load_HEP_data(\n    ROOT_filename            = \"output.root\",\n    tree_name                = \"nominal\",\n    maximum_number_of_events = None\n    ):\n    \"\"\"\n    Load HEP data and return dataset.\n    \"\"\"\n    ROOT_file        = open_ROOT_file(ROOT_filename)\n    tree             = ROOT_file.Get(tree_name)\n    number_of_events = tree.GetEntries()\n    data             = datavision.Dataset()\n\n    progress = shijian.Progress()\n    progress.engage_quick_calculation_mode()\n    # counters\n    number_of_events_loaded = 0\n\n    log.info(\"\")\n\n    index = 0\n    for event in tree:\n\n        if maximum_number_of_events is not None and\\\n            number_of_events_loaded >= int(maximum_number_of_events):\n            log.info(\n                \"loaded maximum requested number of events \" +\n                \"({maximum_number_of_events})\\r\".format(\n                    maximum_number_of_events = maximum_number_of_events\n                )\n            )\n            break\n        print progress.add_datum(fraction = (index + 2) / number_of_events),\n\n        if select_event(event):\n            index += 1\n            #event.GetReadEntry()\n            #data.variable(index = index, name = \"eventNumber\",        value = event.eventNumber)\n            data.variable(index = index, name = \"el_1_pt\",            value = event.el_pt[0])\n            #data.variable(index = index, name = \"el_1_eta\",           value = event.el_eta[0])\n            #data.variable(index = index, name = \"el_1_phi\",           value = event.el_phi[0])\n            ##data.variable(index = index, name = \"jet_1_pt\",           value = event.jet_pt[0])\n            #data.variable(index = index, name = \"jet_1_eta\",          value = event.jet_eta[0])\n            #data.variable(index = index, name = \"jet_1_phi\",          value = event.jet_phi[0])\n            ##data.variable(index = index, name = \"jet_1_e\",            value = event.jet_e[0])\n            ##data.variable(index = index, name = \"jet_2_pt\",           value = event.jet_pt[1])\n            #data.variable(index = index, name = \"jet_2_eta\",          value = event.jet_eta[1])\n            #data.variable(index = index, name = \"jet_2_phi\",          value = event.jet_phi[1])\n            ##data.variable(index = index, name = \"jet_2_e\",            value = event.jet_e[1])\n            #data.variable(index = index, name = \"nJets\",              value = event.nJets)\n            ##data.variable(index = index, name = \"nBTags\",             value = event.nBTags)\n            ##data.variable(index = index, name = \"nLjets\",             value = event.nLjets)\n            ##data.variable(index = index, name = \"ljet_1_m\",           value = event.ljet_m[0])\n            #data.variable(index = index, name = \"met\",                value = event.met_met)\n            #data.variable(index = index, name = \"met_phi\",            value = event.met_phi)\n            #data.variable(index = index, name = \"Centrality_all\",     value = event.Centrality_all)\n            #data.variable(index = index, name = \"Mbb_MindR\",          value = event.Mbb_MindR)\n            #data.variable(index = index, name = \"ljet_tau21\",         value = event.ljet_tau21),\n            #data.variable(index = index, name = \"ljet_tau32\",         value = event.ljet_tau32),\n            #data.variable(index = index, name = \"Aplan_bjets\",        value = event.Aplan_bjets),\n            #data.variable(index = index, name = \"H4_all\",             value = event.H4_all),\n            #data.variable(index = index, name = \"NBFricoNN_6jin4bin\", value = event.NBFricoNN_6jin4bin),\n            #data.variable(index = index, name = \"NBFricoNN_6jin3bex\", value = event.NBFricoNN_6jin3bex),\n            #data.variable(index = index, name = \"NBFricoNN_5jex4bin\", value = event.NBFricoNN_5jex4bin),\n            #data.variable(index = index, name = \"NBFricoNN_3jex3bex\", value = event.NBFricoNN_3jex3bex),\n            #data.variable(index = index, name = \"NBFricoNN_4jin3bex\", value = event.NBFricoNN_4jin3bex),\n            #data.variable(index = index, name = \"NBFricoNN_4jin4bin\", value = event.NBFricoNN_4jin4bin)\n\n            number_of_events_loaded += 1\n\n    log.info(\"\")\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_event(\n    event     = None,\n    selection = \"ejets\"\n    ):\n    \"\"\"\n    Select a HEP event.\n    \"\"\"\n    if selection == \"ejets\":\n        # Require single lepton.\n        # Require >= 4 jets.\n        if \\\n            0 < len(event.el_pt) < 2 and \\\n            len(event.jet_pt) >= 4 and \\\n            len(event.ljet_m) >= 1:\n            return True\n        else:\n            return False", "response": "Select a HEP event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_sentiments(\n        self,\n        username = None\n        ):\n        \"\"\"\n        This function returns a list of all sentiments of the tweets of a\n        specified user.\n        \"\"\"\n        try:\n           return [tweet.sentiment for tweet in self if tweet.username == username]\n        except:\n            log.error(\"error -- possibly no username specified\")\n            return None", "response": "This function returns a list of all sentiments of the tweets of a specific user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new StripeGateway with the specified attributes.", "response": "def create_stripe_gateway(cls, stripe_gateway, **kwargs):\n        \"\"\"Create StripeGateway\n\n        Create a new StripeGateway\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_stripe_gateway(stripe_gateway, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param StripeGateway stripe_gateway: Attributes of stripeGateway to create (required)\n        :return: StripeGateway\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_stripe_gateway_with_http_info(stripe_gateway, **kwargs)\n        else:\n            (data) = cls._create_stripe_gateway_with_http_info(stripe_gateway, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes an instance of StripeGateway by its ID.", "response": "def delete_stripe_gateway_by_id(cls, stripe_gateway_id, **kwargs):\n        \"\"\"Delete StripeGateway\n\n        Delete an instance of StripeGateway by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_stripe_gateway_by_id(stripe_gateway_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str stripe_gateway_id: ID of stripeGateway to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_stripe_gateway_by_id_with_http_info(stripe_gateway_id, **kwargs)\n        else:\n            (data) = cls._delete_stripe_gateway_by_id_with_http_info(stripe_gateway_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding StripeGateway by ID Return single instance of StripeGateway by its ID.", "response": "def get_stripe_gateway_by_id(cls, stripe_gateway_id, **kwargs):\n        \"\"\"Find StripeGateway\n\n        Return single instance of StripeGateway by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_stripe_gateway_by_id(stripe_gateway_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str stripe_gateway_id: ID of stripeGateway to return (required)\n        :return: StripeGateway\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_stripe_gateway_by_id_with_http_info(stripe_gateway_id, **kwargs)\n        else:\n            (data) = cls._get_stripe_gateway_by_id_with_http_info(stripe_gateway_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist StripeGateways Return a list of StripeGateways", "response": "def list_all_stripe_gateways(cls, **kwargs):\n        \"\"\"List StripeGateways\n\n        Return a list of StripeGateways\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_stripe_gateways(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[StripeGateway]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_stripe_gateways_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_stripe_gateways_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_stripe_gateway_by_id(cls, stripe_gateway_id, stripe_gateway, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_stripe_gateway_by_id_with_http_info(stripe_gateway_id, stripe_gateway, **kwargs)\n        else:\n            (data) = cls._replace_stripe_gateway_by_id_with_http_info(stripe_gateway_id, stripe_gateway, **kwargs)\n            return data", "response": "Replace all attributes of StripeGateway by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates attributes of StripeGateway by ID", "response": "def update_stripe_gateway_by_id(cls, stripe_gateway_id, stripe_gateway, **kwargs):\n        \"\"\"Update StripeGateway\n\n        Update attributes of StripeGateway\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_stripe_gateway_by_id(stripe_gateway_id, stripe_gateway, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str stripe_gateway_id: ID of stripeGateway to update. (required)\n        :param StripeGateway stripe_gateway: Attributes of stripeGateway to update. (required)\n        :return: StripeGateway\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_stripe_gateway_by_id_with_http_info(stripe_gateway_id, stripe_gateway, **kwargs)\n        else:\n            (data) = cls._update_stripe_gateway_by_id_with_http_info(stripe_gateway_id, stripe_gateway, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_underline(s, char=\"=\", indents=0):\r\n\r\n    n = len(s)\r\n    ind = \" \" * indents\r\n    return [\"{}{}\".format(ind, s), \"{}{}\".format(ind, char*n)]", "response": "Returns a dashed line below string s"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_h1(s, format=\"text\", indents=0):\r\n\r\n    _CHAR = \"=\"\r\n    if format.startswith(\"text\"):\r\n        return format_underline(s, _CHAR, indents)\r\n    elif format.startswith(\"markdown\"):\r\n        return [\"# {}\".format(s)]\r\n    elif format.startswith(\"rest\"):\r\n        return format_underline(s, _CHAR, 0)", "response": "Returns a list of strings in format text\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_h2(s, format=\"text\", indents=0):\r\n\r\n    _CHAR = \"-\"\r\n    if format.startswith(\"text\"):\r\n        return format_underline(s, _CHAR, indents)\r\n    elif format.startswith(\"markdown\"):\r\n        return [\"## {}\".format(s)]\r\n    elif format.startswith(\"rest\"):\r\n        return format_underline(s, _CHAR, 0)", "response": "Encloses string in format text\r\n    Returns string in format markdown"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencloses string in format text Returns string in format markdown", "response": "def format_h3(s, format=\"text\", indents=0):\r\n    \"\"\"\r\n    Encloses string in format text\r\n\r\n    Args, Returns: see format_h1()\r\n    \"\"\"\r\n\r\n    _CHAR = \"~\"\r\n    if format.startswith(\"text\"):\r\n        return format_underline(s, _CHAR, indents)\r\n    elif format.startswith(\"markdown\"):\r\n        return [\"### {}\".format(s)]\r\n    elif format.startswith(\"rest\"):\r\n        return format_underline(s, _CHAR, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenclose string in format text Returns string in format markdown", "response": "def format_h4(s, format=\"text\", indents=0):\r\n    \"\"\"\r\n    Encloses string in format text\r\n\r\n    Args, Returns: see format_h1()\r\n    \"\"\"\r\n\r\n    _CHAR = \"^\"\r\n    if format.startswith(\"text\"):\r\n        return format_underline(s, _CHAR, indents)\r\n    elif format.startswith(\"markdown\"):\r\n        return [\"#### {}\".format(s)]\r\n    elif format.startswith(\"rest\"):\r\n        return format_underline(s, _CHAR, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef question(question, options, default=None):\r\n\r\n    # Make sure options is a list\r\n    options_ = [x for x in options]\r\n\r\n    if default is not None and default not in options_:\r\n        raise ValueError(\"Default option '{}' is not in options {}.\".format(default, options))\r\n\r\n    oto = \"/\".join([x.upper() if x == default else x.lower() for x in options_])  # to show\r\n    ocomp = [x.lower() for x in options_]  # to be used in comparison\r\n\r\n    while True:\r\n        ans = input(\"{} ({})? \".format(question, oto)).lower()\r\n        if ans == \"\" and default is not None:\r\n            ret = default\r\n            break\r\n        elif ans in ocomp:\r\n            ret = options_[ocomp.index(ans)]\r\n            break\r\n    return ret", "response": "Ask a question with case - insensitive options of answers\r\n getTerminalMessages"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef yesno(question, default=None):\r\n\r\n    if default is not None:\r\n        if isinstance(default, bool):\r\n            pass\r\n        else:\r\n            default_ = default.upper()\r\n            if default_ not in ('Y', 'YES', 'N', 'NO'):\r\n                raise RuntimeError(\"Invalid default value: '{}'\".format(default))\r\n            default = default_ in ('Y', 'YES')\r\n\r\n    while True:\r\n        ans = input(\"{} ({}/{})? \".format(question, \"Y\" if default == True else \"y\",\r\n                                         \"N\" if default == False else \"n\")).upper()\r\n        if ans == \"\" and default is not None:\r\n            ret = default\r\n            break\r\n        elif ans in (\"N\", \"NO\"):\r\n            ret = False\r\n            break\r\n        elif ans in (\"Y\", \"YES\"):\r\n            ret = True\r\n            break\r\n    return ret", "response": "Asks a yes or no question and returns a boolean indicating if the user answered yes or no."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef menu(title, options, cancel_label=\"Cancel\", flag_allow_empty=False, flag_cancel=True, ch='.'):\r\n\r\n  num_options, flag_ok = len(options), 0\r\n  option = None  # result\r\n  min_allowed = 0 if flag_cancel else 1  # minimum option value allowed (if option not empty)\r\n\r\n  while True:\r\n    print(\"\")\r\n    for line in format_box(title, ch):\r\n        print(\"  \"+line)\r\n    for i, s in enumerate(options):\r\n      print((\"  {0:d} - {1!s}\".format(i+1, s)))\r\n    if flag_cancel: print((\"  0 - << (*{0!s}*)\".format(cancel_label)))\r\n    try:\r\n        s_option = input('? ')\r\n    except KeyboardInterrupt:\r\n        raise\r\n    except:\r\n        print(\"\")\r\n\r\n    n_try = 0\r\n    while True:\r\n      if n_try >= 10:\r\n        print('You are messing up!')\r\n        break\r\n\r\n      if len(s_option) == 0 and flag_allow_empty:\r\n        flag_ok = True\r\n        break\r\n\r\n      try:\r\n        option = int(s_option)\r\n        if min_allowed <= option <= num_options:\r\n          flag_ok = True\r\n          break\r\n      except ValueError:\r\n        print(\"Invalid integer value!\")\r\n\r\n      print((\"Invalid option, range is [{0:d}, {1:d}]!\".format(0 if flag_cancel else 1, num_options)))\r\n\r\n      n_try += 1\r\n      s_option = input(\"? \")\r\n\r\n    if flag_ok:\r\n      break\r\n  return option", "response": "Text menu.\r\n\r\n  Arguments:\r\n    title -- menu title, to appear at the top\r\n    options -- sequence of strings\r\n    cancel_label='Cancel' -- label to show at last \"zero\" option\r\n    flag_allow_empty=0 -- Whether to allow empty option\r\n    flag_cancel=True -- whether there is a \"0 - Cancel\" option\r\n    ch=\".\" -- character to use to draw frame around title\r\n\r\n  Returns:\r\n    option -- an integer: None; 0-Back/Cancel/etc; 1, 2, ...\r\n\r\n  Adapted from irootlab menu.m"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_box(title, ch=\"*\"):\r\n    lt = len(title)\r\n    return [(ch * (lt + 8)),\r\n            (ch * 3 + \" \" + title + \" \" + ch * 3),\r\n            (ch * (lt + 8))\r\n           ]", "response": "Returns a list of strings with the given title in a box."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_progress(i, n):\r\n    if n == 0:\r\n        fraction = 0\r\n    else:\r\n        fraction = float(i)/n\r\n    LEN_BAR = 25\r\n    num_plus = int(round(fraction*LEN_BAR))\r\n    s_plus = '+'*num_plus\r\n    s_point = '.'*(LEN_BAR-num_plus)\r\n    return '[{0!s}{1!s}] {2:d}/{3:d} - {4:.1f}%'.format(s_plus, s_point, i, n, fraction*100)", "response": "Returns a string containing a progress bar a percentage etc."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender ExeInfo object in specified format", "response": "def _format_exe_info(py_len, exeinfo, format, indlevel):\r\n    \"\"\"Renders ExeInfo object in specified format\"\"\"\r\n    ret = []\r\n    ind = \" \" * indlevel * NIND if format.startswith(\"text\") else \"\"\r\n    if format == \"markdown-list\":\r\n        for si in exeinfo:\r\n            ret.append(\"  - `{0!s}`: {1!s}\".format(si.filename, si.description))\r\n    if format == \"rest-list\":\r\n        for si in exeinfo:\r\n            ret.append(\"* ``{0!s}``: {1!s}\".format(si.filename, si.description))\r\n    elif format == \"markdown-table\":\r\n        mask = \"%-{0:d}s | %s\".format(py_len+2 )\r\n        ret.append(mask % (\"Script name\", \"Purpose\"))\r\n        ret.append(\"-\" * (py_len + 3) + \"|\" + \"-\" * 10)\r\n        for si in exeinfo:\r\n            ret.append(mask % (\"`{0!s}`\".format(si.filename), si.description))\r\n    elif format == \"text\":\r\n        sbc = 1  # spaces between columns\r\n        for si in exeinfo:\r\n            ss = textwrap.wrap(si.description, 79 - py_len - sbc - indlevel*NIND)\r\n            for i, s in enumerate(ss):\r\n                if i == 0:\r\n                    filecolumn = si.filename + \" \" + (\".\" * (py_len - len(si.filename)))\r\n                else:\r\n                    filecolumn = \" \" * (py_len + 1)\r\n\r\n                ret.append(\"{}{}{}{}\".format(ind, filecolumn, \" \"*sbc, s))\r\n    ret.append(\"\")\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_exe_info(exeinfo, format=\"text\", indlevel=0):\r\n\r\n    py_len = max([len(si.filename) for si in exeinfo])\r\n\r\n    sisi_gra = [si for si in exeinfo if si.flag_gui == True]\r\n    sisi_cmd = [si for si in exeinfo if si.flag_gui == False]\r\n    sisi_none = [si for si in exeinfo if si.flag_gui is None]\r\n\r\n    def get_title(x):\r\n        return format_h4(x, format, indlevel*NIND) + [\"\"]\r\n\r\n    ret = []\r\n    if len(sisi_gra) > 0:\r\n        ret.extend(get_title(\"Graphical applications\"))\r\n        ret.extend(_format_exe_info(py_len, sisi_gra, format, indlevel + 1))\r\n    if len(sisi_cmd) > 0:\r\n        ret.extend(get_title(\"Command-line tools\", ))\r\n        ret.extend(_format_exe_info(py_len, sisi_cmd, format, indlevel + 1))\r\n    if len(sisi_none) > 0:\r\n        ret.extend(_format_exe_info(py_len, sisi_none, format, indlevel + 1))\r\n\r\n    return ret, py_len", "response": "Returns a list of strings that can be printed at the console at the specified level."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef markdown_table(data, headers):\r\n\r\n    maxx = [max([len(x) for x in column]) for column in zip(*data)]\r\n    maxx = [max(ll) for ll in zip(maxx, [len(x) for x in headers])]\r\n    mask = \" | \".join([\"%-{0:d}s\".format(n) for n in maxx])\r\n\r\n    ret = [mask % headers]\r\n\r\n    ret.append(\" | \".join([\"-\"*n for n in maxx]))\r\n    for line in data:\r\n        ret.append(mask % line)\r\n    return ret", "response": "Returns a list of strings that can be used as a table in markdown."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert multirow cells to a list of lists and informs the number of lines of each row.", "response": "def expand_multirow_data(data):\r\n    \"\"\"\r\n    Converts multirow cells to a list of lists and informs the number of lines of each row.\r\n\r\n    Returns:\r\n         tuple: new_data, row_heights\r\n    \"\"\"\r\n\r\n    num_cols = len(data[0]) # number of columns\r\n\r\n    # calculates row heights\r\n    row_heights = []\r\n    for mlrow in data:\r\n        row_height = 0\r\n        for j, cell in enumerate(mlrow):\r\n            row_height = max(row_height, 1 if not isinstance(cell, (list, tuple)) else len(cell))\r\n        row_heights.append(row_height)\r\n    num_lines = sum(row_heights) # line != row (rows are multiline)\r\n\r\n    # rebuilds table data\r\n    new_data = [[\"\"]*num_cols for i in range(num_lines)]\r\n    i0 = 0\r\n    for row_height, mlrow in zip(row_heights, data):\r\n        for j, cell in enumerate(mlrow):\r\n            if not isinstance(cell, (list, tuple)):\r\n                cell = [cell]\r\n\r\n            for incr, x in enumerate(cell):\r\n                new_data[i0+incr][j] = x\r\n\r\n        i0 += row_height\r\n\r\n    return new_data, row_heights"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a reStructuredText table with the given data and headers.", "response": "def rest_table(data, headers):\r\n    \"\"\"\r\n    Creates reStructuredText table (grid format), allowing for multiline cells\r\n\r\n    Arguments:\r\n      data -- [((cell000, cell001, ...), (cell010, cell011, ...), ...), ...]\r\n      headers -- sequence of strings: (header0, header1, ...)\r\n\r\n    **Note** Tolerant to non-strings\r\n\r\n    **Note** Cells may or may not be multiline\r\n\r\n    >>> rest_table([[\"Eric\", \"Idle\"], [\"Graham\", \"Chapman\"], [\"Terry\", \"Gilliam\"]], [\"Name\", \"Surname\"])\r\n    \"\"\"\r\n\r\n    num_cols = len(headers)\r\n    new_data, row_heights = expand_multirow_data(data)\r\n    new_data = [[str(x) for x in row] for row in new_data]\r\n    col_widths = [max([len(x) for x in col]) for col in zip(*new_data)]\r\n    col_widths = [max(cw, len(s)) for cw, s in zip(col_widths, headers)]\r\n\r\n    if any([x == 0 for x in col_widths]):\r\n        raise RuntimeError(\"Column widths ({}) has at least one zero\".format(col_widths))\r\n\r\n    num_lines = sum(row_heights) # line != row (rows are multiline)\r\n\r\n    # horizontal lines\r\n    hl0 = \"+\"+\"+\".join([\"-\"*(n+2) for n in col_widths])+\"+\"\r\n    hl1 = \"+\"+\"+\".join([\"=\"*(n+2) for n in col_widths])+\"+\"\r\n\r\n    frmtd = [\"{0:{1}}\".format(x, width) for x, width in zip(headers, col_widths)]\r\n    ret = [hl0, \"| \"+\" | \".join(frmtd)+\" |\", hl1]\r\n\r\n    i0 = 0\r\n    for i, row_height in enumerate(row_heights):\r\n        if i > 0:\r\n            ret.append(hl0)\r\n        for incr in range(row_height):\r\n            frmtd = [\"{0:{1}}\".format(x, width) for x, width in zip(new_data[i0+incr], col_widths)]\r\n            ret.append(\"| \"+\" | \".join(frmtd)+\" |\")\r\n        i0 += row_height\r\n\r\n    ret.append(hl0)\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concept_adapter(obj, request):\n    '''\n    Adapter for rendering a :class:`skosprovider.skos.Concept` to json.\n\n    :param skosprovider.skos.Concept obj: The concept to be rendered.\n    :rtype: :class:`dict`\n    '''\n    p = request.skos_registry.get_provider(obj.concept_scheme.uri)\n    language = request.params.get('language', request.locale_name)\n    label = obj.label(language)\n    return {\n        'id': obj.id,\n        'type': 'concept',\n        'uri': obj.uri,\n        'label': label.label if label else None,\n        'concept_scheme': {\n            'uri': obj.concept_scheme.uri,\n            'labels': obj.concept_scheme.labels\n        },\n        'labels': obj.labels,\n        'notes': obj.notes,\n        'sources': obj.sources,\n        'narrower': _map_relations(obj.narrower, p, language),\n        'broader': _map_relations(obj.broader, p, language),\n        'related': _map_relations(obj.related, p, language),\n        'member_of': _map_relations(obj.member_of, p, language),\n        'subordinate_arrays':  _map_relations(obj.subordinate_arrays, p, language),\n        'matches': obj.matches\n    }", "response": "Returns a dict representation of a concept."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary representation of a skos. Collection object.", "response": "def collection_adapter(obj, request):\n    '''\n    Adapter for rendering a :class:`skosprovider.skos.Collection` to json.\n\n    :param skosprovider.skos.Collection obj: The collection to be rendered.\n    :rtype: :class:`dict`\n    '''\n    p = request.skos_registry.get_provider(obj.concept_scheme.uri)\n    language = request.params.get('language', request.locale_name)\n    label = obj.label(language)\n    return {\n        'id': obj.id,\n        'type': 'collection',\n        'uri': obj.uri,\n        'label': label.label if label else None,\n        'concept_scheme': {\n            'uri': obj.concept_scheme.uri,\n            'labels': obj.concept_scheme.labels\n        },\n        'labels': obj.labels,\n        'notes': obj.notes,\n        'sources': obj.sources,\n        'members': _map_relations(obj.members, p, language),\n        'member_of': _map_relations(obj.member_of, p, language),\n        'superordinates':  _map_relations(obj.superordinates, p, language)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _map_relations(relations, p, language='any'):\n    '''\n    :param: :class:`list` relations: Relations to be mapped. These are\n        concept or collection id's.\n    :param: :class:`skosprovider.providers.VocabularyProvider` p: Provider\n        to look up id's.\n    :param string language: Language to render the relations' labels in\n    :rtype: :class:`list`\n    '''\n    ret = []\n    for r in relations:\n        c = p.get_by_id(r)\n        if c:\n            ret.append(_map_relation(c, language))\n        else:\n            log.warning(\n                'A relation references a concept or collection %d in provider %s that can not be found. Please check the integrity of your data.' %\n                (r, p.get_vocabulary_id())\n            )\n    return ret", "response": "Returns a list of the relations in the given language."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmapping a relation to a single resource.", "response": "def _map_relation(c, language='any'):\n    \"\"\"\n    Map related concept or collection, leaving out the relations.\n\n    :param c: the concept or collection to map\n    :param string language: Language to render the relation's label in\n    :rtype: :class:`dict`\n    \"\"\"\n    label = c.label(language)\n    return {\n        'id': c.id,\n        'type': c.type,\n        'uri': c.uri,\n        'label': label.label if label else None\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef note_adapter(obj, request):\n    '''\n    Adapter for rendering a :class:`skosprovider.skos.Note` to json.\n\n    :param skosprovider.skos.Note obj: The note to be rendered.\n    :rtype: :class:`dict`\n    '''\n    return {\n        'note': obj.note,\n        'type': obj.type,\n        'language': obj.language,\n        'markup': obj.markup\n    }", "response": "Returns a dict representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tag(\n        log,\n        filepath,\n        tags=False,\n        rating=False,\n        wherefrom=False):\n    \"\"\"Add tags and ratings to your macOS files and folders\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``filepath`` -- the path to the file needing tagged\n        - ``tags`` -- comma or space-separated string, or list of tags. Use `False` to leave file tags as they are. Use \"\" or [] to remove tags. Default *False*.\n        - ``rating`` -- a rating to add to the file. Use 0 to remove rating or `False` to leave file rating as it is. Default *False*.\n        - ``wherefrom`` -- add a URL to indicate where the file come from. Use `False` to leave file location as it is. Use \"\" to remove location. Default *False*.\n\n    **Return:**\n        - None\n\n    **Usage:**\n\n        To add any combination of tags, rating and a source URL to a file on macOS, use the following:\n\n        .. code-block:: python \n\n            from fundamentals.files.tag import tag\n            tag(\n                log=log,\n                filepath=\"/path/to/my.file\",\n                tags=\"test,tags, fundamentals\",\n                rating=3,\n                wherefrom=\"http://www.thespacedoctor.co.uk\"\n            )\n    \"\"\"\n    log.debug('starting the ``tag`` function')\n\n    if isinstance(tags, list):\n        tags = (\" \").join(tags)\n\n    if tags and len(tags):\n        tags = tags.replace(\",\", \" \")\n        tags = \"<string>\" + tags.replace(\"  \", \" \").replace(\n            \"  \", \" \").replace(\" \", \"</string><string>\") + \"</string>\"\n\n    if tags != False:\n        now = datetime.now()\n        now = now.strftime(\"%Y%m%dt%H%M%S%f\")\n        tagPlist = \"/tmp/fund-%(now)s-tags.plist\" % locals()\n        # GENERATE THE TAGS PLIST FILE\n        try:\n            writeFile = codecs.open(\n                tagPlist, encoding='utf-8', mode='w')\n        except IOError, e:\n            message = 'could not open the file %s' % (tagPlist,)\n            raise IOError(message)\n        writeFile.write(\"\"\"\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<array>\n%(tags)s \n</array>\n</plist>\"\"\" % locals())\n        writeFile.close()\n\n        # CONVERT PLIST TO BINARY\n        cmd = \"\"\"plutil -convert binary1 %(tagPlist)s\"\"\" % locals(\n        )\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n        log.debug('output: %(stdout)s' % locals())\n        log.debug('output: %(stderr)s' % locals())\n\n        # ASSIGN TAGS TO FILE\n        cmd = 'xattr -wx \"com.apple.metadata:_kMDItemUserTags\" \"`xxd -ps %(tagPlist)s`\" \"%(filepath)s\"' % locals(\n        )\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n        log.debug('output: %(stdout)s' % locals())\n        log.debug('output: %(stderr)s' % locals())\n\n        # DELETE PLIST\n        os.remove(tagPlist)\n\n    if rating != False:\n\n        ratingsContainer = os.path.dirname(__file__) + \"/resources/ratings/\"\n        ratingPlist = \"%(ratingsContainer)s%(rating)s.plist\" % locals(\n        )\n\n        # ASSIGN RATING TO FILE\n        cmd = 'xattr -wx \"com.apple.metadata:kMDItemStarRating\" \"`xxd -ps %(ratingPlist)s`\" \"%(filepath)s\"' % locals(\n        )\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n        log.debug('output: %(stdout)s' % locals())\n        log.debug('output: %(stderr)s' % locals())\n        cmd = 'xattr -wx \"org.openmetainfo:kMDItemStarRating\" \"`xxd -ps %(ratingPlist)s`\" \"%(filepath)s\"' % locals(\n        )\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n        log.debug('output: %(stdout)s' % locals())\n        log.debug('output: %(stderr)s' % locals())\n\n    if wherefrom != False:\n\n        if len(wherefrom):\n            wherefrom = \"<string>%(wherefrom)s</string>\" % locals()\n\n        # DAYONE LINK\n        now = datetime.now()\n        now = now.strftime(\"%Y%m%dt%H%M%S%f\")\n        urlPlist = \"/tmp/fund-%(now)s-url.plist\" % locals()\n        # GENERATE THE WHEREFROM PLIST FILE\n        try:\n            writeFile = codecs.open(\n                urlPlist, encoding='utf-8', mode='w')\n        except IOError, e:\n            message = 'could not open the file %s' % (urlPlist,)\n            raise IOError(message)\n        writeFile.write(\"\"\"\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n%(wherefrom)s\n</plist>\"\"\" % locals())\n        writeFile.close()\n\n        # ASSIGN WHEREFORM TO FILE\n        cmd = 'xattr -wx \"com.apple.metadata:kMDItemURL\" \"`xxd -ps %(urlPlist)s`\" \"%(filepath)s\"' % locals(\n        )\n        # cmd = 'xattr -wx \"com.apple.metadata:kMDItemURL\" \"`plutil -convert binary1 %(urlPlist)s -o - | xxd -p`\" \"%(filepath)s\"' % locals()\n\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n        log.debug('output URL: %(stdout)s' % locals())\n        log.debug('output URL: %(stderr)s' % locals())\n\n        now = datetime.now()\n        now = now.strftime(\"%Y%m%dt%H%M%S%f\")\n        urlPlist = \"/tmp/fund-%(now)s-url.plist\" % locals()\n        # GENERATE THE WHEREFROM PLIST FILE\n        try:\n            writeFile = codecs.open(\n                urlPlist, encoding='utf-8', mode='w')\n        except IOError, e:\n            message = 'could not open the file %s' % (urlPlist,)\n            raise IOError(message)\n        writeFile.write(\"\"\"\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<array>\n%(wherefrom)s\n</array>\n</plist>\"\"\" % locals())\n        writeFile.close()\n\n        # ASSIGN WHEREFORM TO FILE\n        cmd = 'xattr -wx \"com.apple.metadata:kMDItemWhereFroms\" \"`xxd -ps %(urlPlist)s`\" \"%(filepath)s\"' % locals(\n        )\n        p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n        stdout, stderr = p.communicate()\n        log.debug('output URL: %(stdout)s' % locals())\n        log.debug('output URL: %(stderr)s' % locals())\n\n        # DELETE PLIST\n        # os.remove(urlPlist)\n\n    log.debug('completed the ``tag`` function')\n    return None", "response": "Add tags and ratings to the macOS files and folders of the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding indicators to the remote instance.", "response": "def add_indicators(self, indicators=list(), private=False, tags=list()):\n        \"\"\"Add indicators to the remote instance.\"\"\"\n        if len(indicators) == 0:\n            raise Exception(\"No indicators were identified.\")\n        self.logger.debug(\"Checking {} indicators\".format(len(indicators)))\n        cleaned = clean_indicators(indicators)\n        self.logger.debug(\"Cleaned {} indicators\".format(len(cleaned)))\n        whitelisted = check_whitelist(cleaned)\n        self.logger.debug(\"Non-whitelisted {} indicators\".format(len(whitelisted)))\n        indicators = prune_cached(whitelisted)\n        hashed = hash_values(indicators)\n        self.logger.debug(\"Non-cached {} indicators\".format(len(indicators)))\n        self.logger.debug(\"Processing {} indicators\".format(len(indicators)))\n        request_count = int(math.ceil(len(indicators)/100.0))\n        if request_count == 0:\n            mesg = \"[!] No indicators were left to process after \"\n            mesg += \"cleaning, whitelisting and checking the cache.\"\n            return {'message': mesg}\n        stats = {'success': 0, 'failure': 0, 'requests': request_count,\n                 'written': 0}\n        mesg = \"{} indicators found, making {} requests\"\n        self.logger.debug(mesg.format(len(indicators), request_count))\n\n        if private:\n            indicators = hashed\n\n        if type(tags) == str:\n            tags = [t.strip().lower() for t in tags.split(',')]\n\n        start, end = (0, 100)\n        for i, idx in enumerate(range(0, request_count)):\n            if idx > 0:\n                time.sleep(3)  # Ensure we never trip the limit\n                self.logger.debug(\"Waiting 3 seconds before next request.\")\n            to_send = {'indicators': indicators[start:end], 'tags': tags}\n            r = self._send_data('POST', 'admin', 'add-indicators', to_send)\n            start, end = (end, end + 100)\n            if not r['success']:\n                stats['failure'] += 1\n                continue\n            stats['success'] += 1\n            stats['written'] += r['writeCount']\n            cache_items(to_send['indicators'])\n        msg = \"\"\n        msg += \"{written} indicators written using {requests} requests: \"\n        msg += \"{success} success, {failure} failure\"\n        stats['message'] = msg.format(**stats)\n        return stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists indicators available on the remote instance.", "response": "def get_indicators(self):\n        \"\"\"List indicators available on the remote instance.\"\"\"\n        response = self._get('', 'get-indicators')\n        response['message'] = \"%i indicators:\\n%s\" % (\n            len(response['indicators']),\n            \"\\n\".join(response['indicators'])\n        )\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts obj to unicode if it can be converted", "response": "def to_unicode(obj, encoding='utf-8'):\n    \"\"\"Convert obj to unicode (if it can be be converted)\n\n    from http://farmdev.com/talks/unicode/\"\"\"\n    if isinstance(obj, basestring):\n        if not isinstance(obj, unicode):\n            obj = unicode(obj, encoding)\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef besttype(x, encoding=\"utf-8\", percentify=True):\n    def unicodify(x):\n        return to_unicode(x, encoding)\n    def percent(x):\n        try:\n            if x.endswith(\"%\"):\n                x = float(x[:-1]) / 100.\n            else:\n                raise ValueError\n        except (AttributeError, ValueError):\n            raise ValueError\n        return x\n\n    x = unicodify(x)  # make unicode as soon as possible\n    try:\n        x = x.strip()\n    except AttributeError:\n        pass\n    m = re.match(r\"\"\"(?P<quote>['\"])(?P<value>.*)(?P=quote)$\"\"\", x)  # matches \"<value>\" or '<value>' where <value> COULD contain \" or '!\n    if m is None:\n        # not a quoted string, try different types\n        for converter in int, float, percent, unicodify:   # try them in increasing order of lenience\n            try:\n                return converter(x)\n            except ValueError:\n                pass\n    else:\n        # quoted string\n        x = unicodify(m.group('value'))\n    return x", "response": "Convert string x to the most useful type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _onsuccess(cls, kmsg, result):\n        logger.info(\n            \"{}.Success: {}[{}]: {}\".format(\n                cls.__name__, kmsg.entrypoint, kmsg.uuid, result\n            ),\n            extra=dict(\n                kmsg=kmsg.dump(),\n                kresult=ResultSchema().dump(result) if result else dict()\n            )\n        )\n        return cls.onsuccess(kmsg, result)", "response": "To execute on success"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _onerror(cls, kmsg, result):\n        logger.error(\n            \"{}.Failed: {}[{}]: {}\".format(\n                cls.__name__, kmsg.entrypoint, kmsg.uuid, result\n            ),\n            extra=dict(\n                kmsg=kmsg.dump(),\n                kresult=ResultSchema().dump(result) if result else dict()\n            )\n        )\n        return cls.onerror(kmsg, result)", "response": "To execute on execution failure\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls onmessage method of the Kafka class", "response": "def _onmessage(cls, kmsg):\n        \"\"\" Call on received message\n\n        :param kser.schemas.Message kmsg: Kafka message\n        :return: Kafka message\n        :rtype: kser.schemas.Message\n        \"\"\"\n        logger.debug(\n            \"{}.ReceivedMessage {}[{}]\".format(\n                cls.__name__, kmsg.entrypoint, kmsg.uuid\n            ),\n            extra=dict(kmsg=kmsg.dump())\n        )\n        return cls.onmessage(kmsg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a new entrypoint with the kser. entry. Entrypoint class.", "response": "def register(cls, name, entrypoint):\n        \"\"\" Register a new entrypoint\n\n        :param str name: Key used by messages\n        :param kser.entry.Entrypoint entrypoint: class to load\n        :raises ValidationError: Invalid entry\n        \"\"\"\n        if not issubclass(entrypoint, Entrypoint):\n            raise ValidationError(\n                \"Invalid type for entry '{}', MUST implement \"\n                \"kser.entry.Entrypoint\".format(name),\n                extra=dict(entrypoint=name)\n            )\n        cls.ENTRYPOINTS[name] = entrypoint\n        logger.debug(\"{}.Registered: {}\".format(cls.__name__, name))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef interval_condition(value, inf, sup, dist):\n    return (value > inf - dist and value < sup + dist)", "response": "Checks if value belongs to the interval [ inf sup + dist )."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nearest_point(query, root_id, get_properties, dist_fun=euclidean_dist):\n\n    k = len(query)\n    dist = math.inf\n\n    nearest_node_id = None\n\n    # stack_node: stack of identifiers to nodes within a region that\n    # contains the query.\n    # stack_look: stack of identifiers to nodes within a region that\n    # does not contains the query.\n    stack_node = deque([root_id])\n    stack_look = deque()\n\n    while stack_node or stack_look:\n\n        if stack_node:\n            node_id = stack_node.pop()\n            look_node = False\n        else:\n            node_id = stack_look.pop()\n            look_node = True\n\n        point, region, axis, active, left, right = get_properties(node_id)\n\n        # Should consider this node?\n        # As it is within a region that does not contains the query, maybe\n        # there is no chance to find a closer node in this region\n        if look_node:\n            inside_region = True\n            for i in range(k):\n                inside_region &= interval_condition(query[i], region[i][0],\n                                                    region[i][1], dist)\n            if not inside_region:\n                continue\n\n        # Update the distance only if the node is active.\n        if active:\n            node_distance = dist_fun(query, point)\n            if nearest_node_id is None or dist > node_distance:\n                nearest_node_id = node_id\n                dist = node_distance\n\n        if query[axis] < point[axis]:\n            side_node = left\n            side_look = right\n        else:\n            side_node = right\n            side_look = left\n\n        if side_node is not None:\n            stack_node.append(side_node)\n\n        if side_look is not None:\n            stack_look.append(side_look)\n\n    return nearest_node_id, dist", "response": "This method finds the nearest point in the tree that minimizes the distance to the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deactivate(self, node_id):\n        node = self.node_list[node_id]\n        self.node_list[node_id] = node._replace(active=False)", "response": "Deactivates the node identified by node_id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, point, data=None):\n        assert len(point) == self.k\n\n        if self.size == 0:\n            if self.region is None:\n                self.region = [[-math.inf, math.inf]] * self.k\n            axis = 0\n            return self.new_node(point, self.region, axis, data)\n\n        # Iteratively descends to one leaf\n        current_id = 0\n        while True:\n            parent_node = self.node_list[current_id]\n            axis = parent_node.axis\n            if point[axis] < parent_node.point[axis]:\n                next_id, left = parent_node.left, True\n            else:\n                next_id, left = parent_node.right, False\n\n            if next_id is None:\n                break\n\n            current_id = next_id\n\n        # Get the region delimited by the parent node\n        region = parent_node.region[:]\n        region[axis] = parent_node.region[axis][:]\n\n        # Limit to the child's region\n        limit = parent_node.point[axis]\n\n        # Update reference to the new node\n        if left:\n            self.node_list[current_id] = parent_node._replace(left=self.size)\n            region[axis][1] = limit\n        else:\n            self.node_list[current_id] = parent_node._replace(right=self.size)\n            region[axis][0] = limit\n\n        return self.new_node(point, region, (axis + 1) % self.k, data)", "response": "Insert a new node in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_nearest_point(self, query, dist_fun=euclidean_dist):\n        def get_properties(node_id):\n            return self.node_list[node_id][:6]\n\n        return nearest_point(query, 0, get_properties, dist_fun)", "response": "Find the nearest point in the tree that minimizes the distance to the query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting one or several releases to public", "response": "def set_to_public(self, request, queryset):\n        \"\"\" Set one or several releases to public \"\"\"\n        queryset.update(is_public=True, modified=now())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting the data. In derived classes, it is usually better idea to override ``_format_data()`` than this method. :param response: devil's ``Response`` object or the data itself. May also be ``None``. :return: django's ``HttpResponse`` todo: this shouldn't change the given response. only return the formatted response.", "response": "def format(self, response):\n        \"\"\" Format the data.\n\n        In derived classes, it is usually better idea to override\n        ``_format_data()`` than this method.\n\n        :param response: devil's ``Response`` object or the data\n                         itself. May also be ``None``.\n        :return: django's ``HttpResponse``\n\n        todo: this shouldn't change the given response. only return the\n        formatted response.\n        \"\"\"\n\n        res = self._prepare_response(response)\n        res.content = self._format_data(res.content, self.charset)\n        return self._finalize_response(res)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self, data, charset=None):\n\n        charset = charset or self.charset\n        return self._parse_data(data, charset)", "response": "Parse the data and return a dict of the naccesstoken entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decode_data(self, data, charset):\n\n        try:\n            return smart_unicode(data, charset)\n        except UnicodeDecodeError:\n            raise errors.BadRequest('wrong charset')", "response": "Decode string data.\n\n        :returns: unicode string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_data(self, data, charset):\n\n        return self._decode_data(data, charset) if data else u''", "response": "Parse the data into a dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _finalize_response(self, response):\n\n        res = HttpResponse(content=response.content,\n                           content_type=self._get_content_type())\n        # status_code is set separately to allow zero\n        res.status_code = response.code\n        return res", "response": "Convert the response object into django s HttpResponse object"}
